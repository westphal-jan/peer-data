{"id": "0809.3618", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Sep-2008", "title": "Robust Near-Isometric Matching via Structured Learning of Graphical Models", "abstract": "Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by \"almost isometric\" transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times.", "histories": [["v1", "Sun, 21 Sep 2008 23:23:26 GMT  (2074kb,D)", "http://arxiv.org/abs/0809.3618v1", "11 pages, 9 figures"]], "COMMENTS": "11 pages, 9 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["julian john mcauley", "tib\u00e9rio s caetano", "alexander j smola"], "accepted": true, "id": "0809.3618"}, "pdf": {"name": "0809.3618.pdf", "metadata": {"source": "CRF", "title": "Robust Near-Isometric Matching via Structured Learning of Graphical Models", "authors": ["Julian J. McAuley", "Tib\u00e9rio S. Caetano", "Alexander J. Smola"], "emails": [], "sections": [{"heading": null, "text": "Models of near-rigid shape fit are typically based on distance-related characteristics to infer similarities consistent with isometric assumptions. However, real shapes from image datasets, even if expected to be related to each other through \"almost isometric\" transformations, are indeed subject not only to noise, but also to some degree to deviations in appearance and scale. In this paper, we present a graphic model that parameterizes features of appearance, distance, and angle, and we learn all the parameters involved through structured predictions. The result is a model of near-rigid shape fit that is robust in that it is able to capture the potentially limited but still important size and appearance variations. Our experimental results show significant improvements over recent successful models while maintaining similar runtimes."}, {"heading": "1 Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Shape Matching", "text": "\"Shape matching\" can mean many different things, depending on the exact type of query you are interested in. Here, we examine the case of identifying a template shape (S T) in a target scene (U). [2] We assume that we know S, i.e. the points in the template that we want to query in the scene. Typically, both T and U correspond to a series of \"boundary points\" that come from a pair of images (common approaches include [6, 20,21,22]). However, for each point t-T and u-U, certain uncommon features are extracted (here referred to by \u03c6 (t), \u03c6 (u)), which contain local information about the image at that point [5, 6]. If y: S \u2192 U is a generic mapping that represents a potential match, the goal is to find a mapping y that minimizes the total distances between the corresponding features, i.e. e.y = f (S) armin = y-y-y (1) (y-y)."}, {"heading": "2.2 Graphical Models", "text": "In isometric matching settings, one might suspect that it may not be necessary to include all paired relationships in the quadratic mapping. Indeed, a recent paper [14] has shown that if only the distances encoded by the graphic model shown in Figure 1 (above) are taken into account (nodes represent points in S and states represent points in U), an exact probable conclusion in such a model can optimally solve the isometric problem. That is, an energy function of the2Here T is the set of all points in the template scene, whereas S corresponds to the points in which we are interested. It is also important to note that we treat S as an ordered object in our setting."}, {"heading": "2.3 Discriminative Structured Learning", "text": "In practice, we can be very high dimensional, and which components are \"important\" depends on the specific properties of the matched shapes. Therefore, we present a parameter that controls the relative implications of the different feature components. Note: It should be interpreted as s (i + 1). (i.e.) The points form a loop. (5) Where we parameterise the matching criteria ourselves. (si + 1, si + 2, y), y (si + 1), y (si + 1), y (si + 2). (6) (y) (y) is an image from S to U, a third feature is vector. (si), y), y (si + 1), y (si + 2)."}, {"heading": "3 Our Model", "text": "Although the model of [14] isometric matching problems is optimally solved, it does not provide any guarantees for near-isometric problems, since it only takes into account those compatibilities that form cliques in our graphical model. However, we are often only interested in the boundary of the object: if we look at the method shown in Figure 2, it seems to capture precisely the important dependencies; adding additional dependencies between distant points (such as the tail and the head of the duck) would be unlikely to contribute to this model. In this sense, we introduce three new features (for the brevity we use to capture precisely the important dependencies (si): 6 additional dependencies between distant points (such as the tail and the head of the duck) = (s1) \u2212 d1 (s2) \u2212 d1 (y1, y2) 2) 2, where d1 (a, b) is the distance between one and a b, scaled according to the width of the target."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 House Data", "text": "In our first experiment, we compare our method with those of the [14] and [18]. Both papers report on the performance of their methods on the CMU \"house sequence\" - a sequence of 111 images of a toy house, with 30 limits identified in each frame. [18] However, as in [18], we calculate the characteristics of the Shape Context for each of the 30 points [5].6In fact, even in cases where a single-step approach was comprehensible (such as the experiment in Section 4.1), we found that the two-step approach worked better. Typically, we need much less regularity during the second stage, possibly because the characteristics of higher order are heterogenetical. 7http: / / vascmu.edu / html / motion / index.htmlIn addition to the non-uniform model of [18], a model based on square features is presented, which also determines the structure of the graphics."}, {"heading": "4.2 Synthetic Data", "text": "For this experiment, our \"shape\" consists of 25 dots randomly distributed on the silhouette of the painting shown in Figure 7 (note that this shape has less structure than those in our other experiments, due to the random order of the dots).In addition to the dots on our shape, a number of outliers are randomly distributed on the silhouette. 10 Training, testing and validation images are then generated by random interference of the X and Y coordinates of these dots between \u2212 / 2 and / 2 pixels, with Epsilon between 0 and 20. This results in 45 image pairs for training, validation and testing. This experiment aims to investigate the robustness of our approach to noise and outliers, as well as the effect of choosing different values for p.9The results of this experiment are shown in Figure 8 that the \"point matching\" method is shown only for zero outliers, as the method becomes intractable."}, {"heading": "4.3 Bikes Data", "text": "For our final experiment, we used images of bicycles from the Caltech 256 dataset [29]. Bikes are relatively rigid objects, which means that the match is logical because of their shape. Although the images in this dataset are fairly well aligned, they are subject to reflection, as well as some scaling and shear. For each image in the dataset, we automatically recognized landmarks, and six dots on the frame were labeled by hand (see Figure 9). Only shapes in which these points of interest were not obscured were used, and we only took images that had a background; in total, we labeled 44 images. The first image was used as the \"template,\" the other 43 were used as targets. This is how we learn to map bicycles along the lines of the template chosen. First, we described the SIFT landmarks and the characteristics so that they typically represent several hundred landmarks."}, {"heading": "5 Discussion and Future Work", "text": "While our model seems well motivated when applied to the problem of \"shape\" matching (i.e. when the shape has a clearly defined boundary), we clearly make a compromise when applying our model to the more general problem of the matching point pattern. In such cases, we are at a disadvantage because we only capture a fraction of the desired dependencies, but we are at an advantage because our model is accurate, and also because it is able to capture properties of higher order of the scene. Interestingly, we found that the accuracy of our model alone does not offset this limitation, which shows the surprising result that the scale-invariant features of third order are able to capture a lot of additional information that is not available in lower places. One hurdle facing our approach is that we do not identify occurrences (either because of the interface detector that we do not identify a part of the shape, or simply because of a part of the shape is missing)."}, {"heading": "6 Conclusion", "text": "We have presented a model of near-isometric fit that is robust to typical additional variations of form. This is achieved by performing structured learning in a graphical model that encodes features with multiple different types of invariance so that we can directly learn a \"compound invariance,\" rather than taking the exclusive assumption of isometric invariance for granted. Our experiments have shown that structured learning with a principle-based graphical model that encodes both the rigid form and non-isometric variations offers substantial improvements while maintaining competitiveness in terms of runtime."}], "references": [{"title": "Shape matching and object recognition using shape contexts", "author": ["S. Belongie", "J. Malik", "J. Puzicha"], "venue": "IEEE Trans. on PAMI, vol. 24, no. 4, pp. 509\u2013522, 2002.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2002}, {"title": "Shape contexts enable efficient retrieval of similar shapes", "author": ["G. Mori", "S. Belongie", "J. Malik"], "venue": "CVPR, 2001, pp. 723\u2013730.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2001}, {"title": "Estimating human body configurations using shape context matching", "author": ["G. Mori", "J. Malik"], "venue": "ECCV, 2002, pp. 666\u2013680.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2002}, {"title": "Recognizing objects in range data using regional point descriptors", "author": ["A. Frome", "D. Huber", "R. Kolluri", "T. Bulow", "J. Malik"], "venue": "ECCV, 2004.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2004}, {"title": "Matching with shape contexts", "author": ["S. Belongie", "J. Malik"], "venue": "CBAIVL00, 2000, pp. 20\u201326.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "Object recognition from local scaleinvariant features", "author": ["D.G. Lowe"], "venue": "ICCV, 1999, pp. 1150\u20131157.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1999}, {"title": "Pictorial structures for object recognition", "author": ["P.F. Felzenszwalb", "D.P. Huttenlocher"], "venue": "IJCV, vol. 61, no. 1, pp. 55\u201379, 2005.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2005}, {"title": "Hierarchical matching of deformable shapes", "author": ["P.F. Felzenszwalb", "J.D. Schwartz"], "venue": "CVPR, 2007.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning methods for generic object recognition with invariance to pose and lighting", "author": ["Y. LeCun", "F.J. Huang", "L. Bottou"], "venue": "CVPR, vol. 02, pp. 97\u2013104, 2004.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Shape-based recognition of wiry objects", "author": ["O. Carmichael", "M. Hebert"], "venue": "IEEE Trans. on PAMI, vol. 26, no. 12, pp. 1537\u20131552, 2004.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Multiple View Geometry in Computer Vision, 2nd ed", "author": ["R.I. Hartley", "A. Zisserman"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Robust registration of 2d and 3d point sets", "author": ["A. Fitzgibbon"], "venue": "British Machine Vision Conference, 2001.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2001}, {"title": "Graphical models and point pattern matching", "author": ["T.S. Caetano", "T. Caelli", "D. Schuurmans", "D.A.C. Barone"], "venue": "IEEE Trans. on PAMI, vol. 28, no. 10, pp. 1646\u2013 1663, 2006.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "Graph rigidity, cyclic belief propagation and point pattern matching", "author": ["J.J. McAuley", "T.S. Caetano", "M.S. Barbosa"], "venue": "IEEE Trans. on PAMI, in press \u2013 2008.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "Balanced graph matching", "author": ["T. Cour", "P. Srinivasan", "J. Shi"], "venue": "NIPS, 2006.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Shape matching and object recognition using low distortion correspondence", "author": ["A.C. Berg", "T.L. Berg", "J. Malik"], "venue": "CVPR, 2005.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2005}, {"title": "A spectral technique for correspondence problems using pairwise constraints", "author": ["M. Leordeanu", "M. Hebert"], "venue": "ICCV, 2005, pp. 1482\u20131489.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning graph matching", "author": ["T. Caetano", "L. Cheng", "Q. Le", "A. Smola"], "venue": "ICCV, 2007, pp. 1\u20138.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Smoothing-based optimization", "author": ["M. Leordeanu", "M. Hebert"], "venue": "Proceedings of CVPR, June 2008.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "A computational approach to edge detection", "author": ["J. Canny"], "venue": "RCV, 1987, pp. 184\u2013203.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1987}, {"title": "Using Canny\u2019s criteria to derive a recursively implemented optimal edge detector", "author": ["R. Deriche"], "venue": "IJCV, vol. 1, no. 2, pp. 167\u2013187, 1987.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1987}, {"title": "A new class of corner finder", "author": ["S. Smith"], "venue": "BMVC, 1992, pp. 139\u2013148.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1992}, {"title": "Message errors in belief propagation", "author": ["A.T. Ihler", "J.W. Fisher", "A.S. Willsky"], "venue": "Advances in Neural Information Processing Systems, 2005, pp. 609\u2013616.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2005}, {"title": "Correctness of local probability propagation in graphical models with loops", "author": ["Y. Weiss"], "venue": "Neural Computation, vol. 12, no. 1, pp. 1\u201341, 2000.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2000}, {"title": "On the optimality of solutions of the max-product belief-propagation algorithm in arbitrary graphs", "author": ["Weiss", "Freeman"], "venue": "IEEE Transactions on Information Theory, vol. 47, 2001.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2001}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "T. Joachims", "Y. Altun"], "venue": "ICML, 2004.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2004}, {"title": "A scalable modular convex solver for regularized risk minimization", "author": ["C. Teo", "Q. Le", "A. Smola", "S. Vishwanathan"], "venue": "KDD, 2007. 10", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Scale and affine invariant interest point detectors", "author": ["K. Mikolajczyk", "C. Schmid"], "venue": "vol. 60, no. 1, pp. 63\u201386, October 2004.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Caltech- 256 object category dataset", "author": ["G. Griffin", "A. Holub", "P. Perona"], "venue": "California Institute of Technology, Tech. Rep. 7694, 2007. [Online]. Available: http://authors.library.caltech.edu/7694 11", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4].", "startOffset": 104, "endOffset": 116}, {"referenceID": 1, "context": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4].", "startOffset": 104, "endOffset": 116}, {"referenceID": 2, "context": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4].", "startOffset": 104, "endOffset": 116}, {"referenceID": 3, "context": "Matching shapes in images has many applications, including image retrieval, alignment, and registration [1, 2, 3, 4].", "startOffset": 104, "endOffset": 116}, {"referenceID": 4, "context": "[5, 6].", "startOffset": 0, "endOffset": 6}, {"referenceID": 5, "context": "[5, 6].", "startOffset": 0, "endOffset": 6}, {"referenceID": 10, "context": "Some traditional methods for related settings focus on optimisation over the space of rigid transformations so as to minimise least-squares criteria [11,12].", "startOffset": 149, "endOffset": 156}, {"referenceID": 11, "context": "Some traditional methods for related settings focus on optimisation over the space of rigid transformations so as to minimise least-squares criteria [11,12].", "startOffset": 149, "endOffset": 156}, {"referenceID": 12, "context": "Recently, this class of problems has been approached from a different perspective, as direct optimisation over the space of correspondences [13].", "startOffset": 140, "endOffset": 144}, {"referenceID": 6, "context": "Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].", "startOffset": 67, "endOffset": 80}, {"referenceID": 7, "context": "Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].", "startOffset": 67, "endOffset": 80}, {"referenceID": 8, "context": "Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].", "startOffset": 67, "endOffset": 80}, {"referenceID": 9, "context": "Some notable approaches deviate from this norm \u2013 see (for example) [7, 8, 9, 10].", "startOffset": 67, "endOffset": 80}, {"referenceID": 13, "context": "More recently, these methods have been made substantially faster [14].", "startOffset": 65, "endOffset": 69}, {"referenceID": 14, "context": "Other lines of work that optimise directly over the correspondence space are those based on Graph Matching, which explicitly model all pairwise compatibilities and solve for the best match with some relaxation (since the Graph Matching problem is NP-hard for general pairwise compatibilities) [15, 16, 17].", "startOffset": 293, "endOffset": 305}, {"referenceID": 15, "context": "Other lines of work that optimise directly over the correspondence space are those based on Graph Matching, which explicitly model all pairwise compatibilities and solve for the best match with some relaxation (since the Graph Matching problem is NP-hard for general pairwise compatibilities) [15, 16, 17].", "startOffset": 293, "endOffset": 305}, {"referenceID": 16, "context": "Other lines of work that optimise directly over the correspondence space are those based on Graph Matching, which explicitly model all pairwise compatibilities and solve for the best match with some relaxation (since the Graph Matching problem is NP-hard for general pairwise compatibilities) [15, 16, 17].", "startOffset": 293, "endOffset": 305}, {"referenceID": 17, "context": "Recently, it was shown both in [18] and in [19] that if some form of structured optimisation is used to optimise graph matching scores, relaxed quadratic assignment predictors can improve the power of pairwise features.", "startOffset": 31, "endOffset": 35}, {"referenceID": 18, "context": "Recently, it was shown both in [18] and in [19] that if some form of structured optimisation is used to optimise graph matching scores, relaxed quadratic assignment predictors can improve the power of pairwise features.", "startOffset": 43, "endOffset": 47}, {"referenceID": 0, "context": "Here we study the case of identifying an instance of a template shape (S \u2286 T ) in a target scene (U) [1].", "startOffset": 101, "endOffset": 104}, {"referenceID": 5, "context": "Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).", "startOffset": 120, "endOffset": 133}, {"referenceID": 19, "context": "Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).", "startOffset": 120, "endOffset": 133}, {"referenceID": 20, "context": "Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).", "startOffset": 120, "endOffset": 133}, {"referenceID": 21, "context": "Typically both T and U correspond to a set of \u2018landmark\u2019 points, taken from a pair of images (common approaches include [6, 20,21,22]).", "startOffset": 120, "endOffset": 133}, {"referenceID": 4, "context": "For each point t \u2208 T and u \u2208 U , a certain set of unary features are extracted (here denoted by \u03c6(t), \u03c6(u)), which contain local information about the image at that point [5, 6].", "startOffset": 171, "endOffset": 177}, {"referenceID": 5, "context": "For each point t \u2208 T and u \u2208 U , a certain set of unary features are extracted (here denoted by \u03c6(t), \u03c6(u)), which contain local information about the image at that point [5, 6].", "startOffset": 171, "endOffset": 177}, {"referenceID": 17, "context": "(3)) in [18].", "startOffset": 8, "endOffset": 12}, {"referenceID": 13, "context": "In fact a recent paper [14] has shown that if only the distances as encoded by the graphical model depicted in figure 1 (top) are taken into account (nodes represent points in S and states represent points in U), exact probabilistic inference in such a model can solve the isometric problem optimally.", "startOffset": 23, "endOffset": 27}, {"referenceID": 13, "context": "Figure 1: Top: The graphical model introduced in [14].", "startOffset": 49, "endOffset": 53}, {"referenceID": 22, "context": "(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom).", "startOffset": 149, "endOffset": 161}, {"referenceID": 23, "context": "(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom).", "startOffset": 149, "endOffset": 161}, {"referenceID": 24, "context": "(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom).", "startOffset": 149, "endOffset": 161}, {"referenceID": 13, "context": "(4) Although the graphical model in figure 1 (top) does not form a single loop (a condition typically required for convergence of belief propagation [23, 24, 25]), [14] show that it is sufficient that the clique graph forms a single loop in order to guarantee convergence to the optimal assignment (figure 1, bottom).", "startOffset": 164, "endOffset": 168}, {"referenceID": 13, "context": "Furthermore, it is shown in [14] that the number of iterations required before convergence is small in practice.", "startOffset": 28, "endOffset": 32}, {"referenceID": 13, "context": "Note that in order to guarantee convergence, we do not require any specific form for the potentials, except that no assignment has infinite cost [14].", "startOffset": 145, "endOffset": 149}, {"referenceID": 25, "context": "Typically, one uses the squared L2 norm, \u2016\u03b8\u201622, to penalise non-smooth choices of \u03b8 [26].", "startOffset": 84, "endOffset": 88}, {"referenceID": 25, "context": "Here we capitalise on recent advances in large-margin structured estimation [26], which consist of obtaining convex relaxations of this problem.", "startOffset": 76, "endOffset": 80}, {"referenceID": 25, "context": "Without going into the details of the solution (see, for example, [26,27]), it can be shown that a convex relaxation of this problem can be obtained, which is given by", "startOffset": 66, "endOffset": 73}, {"referenceID": 26, "context": "Without going into the details of the solution (see, for example, [26,27]), it can be shown that a convex relaxation of this problem can be obtained, which is given by", "startOffset": 66, "endOffset": 73}, {"referenceID": 25, "context": "This process is known as \u2018column generation\u2019 [26,27].", "startOffset": 45, "endOffset": 52}, {"referenceID": 26, "context": "This process is known as \u2018column generation\u2019 [26,27].", "startOffset": 45, "endOffset": 52}, {"referenceID": 13, "context": "Although the model of [14] solves isometric matching problems optimally, it provides no guarantees for near -isometric problems, as it only considers those compatibilities which form cliques in our graphical model.", "startOffset": 22, "endOffset": 26}, {"referenceID": 13, "context": "\u03a61 is exactly the feature used in [14], and is invariant to isometric transformations (rotation, reflection, and translation); \u03a62 and \u03a63 capture triangle similarity, and are thus also invariant to scale.", "startOffset": 34, "endOffset": 38}, {"referenceID": 5, "context": "In practice, landmark detectors often identify several hundred points [6, 28], which is clearly impractical for an O(|S||U|) method (|U| is the number of landmarks in the target scene).", "startOffset": 70, "endOffset": 77}, {"referenceID": 27, "context": "In practice, landmark detectors often identify several hundred points [6, 28], which is clearly impractical for an O(|S||U|) method (|U| is the number of landmarks in the target scene).", "startOffset": 70, "endOffset": 77}, {"referenceID": 17, "context": "To address this, we adopt a two stage learning approach: in the first stage, we learn only unary compatibilities, exactly as is done in [18].", "startOffset": 136, "endOffset": 140}, {"referenceID": 13, "context": "In our first experiment, we compare our method to those of [14] and [18].", "startOffset": 59, "endOffset": 63}, {"referenceID": 17, "context": "In our first experiment, we compare our method to those of [14] and [18].", "startOffset": 68, "endOffset": 72}, {"referenceID": 17, "context": "As in [18], we compute the Shape Context features for each of the 30 points [5].", "startOffset": 6, "endOffset": 10}, {"referenceID": 4, "context": "As in [18], we compute the Shape Context features for each of the 30 points [5].", "startOffset": 76, "endOffset": 79}, {"referenceID": 17, "context": "html In addition to the unary model of [18], a model based on quadratic assignment is also presented, in which pairwise features are determined using the adjacency structure of the graphs.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "As in [14], we compare pairs of images with a fixed baseline (separation between frames).", "startOffset": 6, "endOffset": 10}, {"referenceID": 17, "context": "In figure 5, we see that the running time of our method is similar to the quadratic assignment method of [18].", "startOffset": 105, "endOffset": 109}, {"referenceID": 17, "context": "8Interestingly, the quadratic method of [18] performs worse than their unary method; this is likely because the relative scale of the unary and quadratic features is badly tuned before learning, and is indeed similar to what the authors report.", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "Furthermore, the results we present for the method of [18] after learning are much better than what the authors report \u2013 in that paper, the unary features are scaled using a pointwise exponent (\u2212 exp(\u2212|\u03c6a \u2212 \u03c6b|)), whereas we found that scaling the features linearly (|\u03c6a \u2212 \u03c6b|) worked better.", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "replicating exactly the experiment from [18], but including only the limited dependencies captured by our model.", "startOffset": 40, "endOffset": 44}, {"referenceID": 17, "context": "In this experiment, the model of [18] performed better than ours; this indicates that the benefit of using an exact algorithm does not exceed the cost of capturing only limited dependencies.", "startOffset": 33, "endOffset": 37}, {"referenceID": 17, "context": "The quadratic assignment method of [18] is not shown for this experiment, as the adjacency information in the graph is not robust to random error, or the addition of outliers (it performed far worse than the techniques shown).", "startOffset": 35, "endOffset": 39}, {"referenceID": 17, "context": "9Note that setting p = 1 essentially recovers the linear method of [18].", "startOffset": 67, "endOffset": 71}, {"referenceID": 13, "context": "Figure 8: Comparison of our technique against that of [14] (\u2018point matching\u2019), and [18] (\u2018linear\u2019).", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "Figure 8: Comparison of our technique against that of [14] (\u2018point matching\u2019), and [18] (\u2018linear\u2019).", "startOffset": 83, "endOffset": 87}, {"referenceID": 13, "context": "Figure 4: Comparison of our technique against that of [14] (\u2018point matching\u2019), and [18] (\u2018linear\u2019, \u2018quadratic\u2019).", "startOffset": 54, "endOffset": 58}, {"referenceID": 17, "context": "Figure 4: Comparison of our technique against that of [14] (\u2018point matching\u2019), and [18] (\u2018linear\u2019, \u2018quadratic\u2019).", "startOffset": 83, "endOffset": 87}, {"referenceID": 17, "context": "Figure 5: The running time and performance of our method, compared to those of [18] (note that the method of [14] has running time identical to our method).", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "Figure 5: The running time and performance of our method, compared to those of [18] (note that the method of [14] has running time identical to our method).", "startOffset": 109, "endOffset": 113}, {"referenceID": 28, "context": "For our final experiment, we used images of bicycles from the Caltech 256 Dataset [29].", "startOffset": 82, "endOffset": 86}, {"referenceID": 5, "context": "Initially, we used the SIFT landmarks and features as described in [6].", "startOffset": 67, "endOffset": 70}, {"referenceID": 27, "context": "In [28], the authors report that the SIFT features can provide good matches in such cases, as long as landmarks are chosen which are locally invariant to affine transformations.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "Centre: The target image, and the match (in red) using unary features with the affine invariant/SIFT model of [28] after learning (endpoint error = 0.", "startOffset": 110, "endOffset": 114}, {"referenceID": 5, "context": "SIFT [6] Affine invariant/SIFT [28] unary training: 0.", "startOffset": 5, "endOffset": 8}, {"referenceID": 27, "context": "SIFT [6] Affine invariant/SIFT [28] unary training: 0.", "startOffset": 31, "endOffset": 35}], "year": 2017, "abstractText": "Models for near-rigid shape matching are typically based on distance-related features, in order to infer matches that are consistent with the isometric assumption. However, real shapes from image datasets, even when expected to be related by \u201calmost isometric\u201d transformations, are actually subject not only to noise but also, to some limited degree, to variations in appearance and scale. In this paper, we introduce a graphical model that parameterises appearance, distance, and angle features and we learn all of the involved parameters via structured prediction. The outcome is a model for near-rigid shape matching which is robust in the sense that it is able to capture the possibly limited but still important scale and appearance variations. Our experimental results reveal substantial improvements upon recent successful models, while maintaining similar running times.", "creator": "LaTeX with hyperref package"}}}