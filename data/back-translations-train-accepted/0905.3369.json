{"id": "0905.3369", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2009", "title": "Learning nonlinear dynamic models", "abstract": "We present a novel approach for learning nonlinear dynamic models, which leads to a new set of tools capable of solving problems that are otherwise difficult. We provide theory showing this new approach is consistent for models with long range structure, and apply the approach to motion capture and high-dimensional video data, yielding results superior to standard alternatives.", "histories": [["v1", "Wed, 20 May 2009 18:08:18 GMT  (223kb)", "http://arxiv.org/abs/0905.3369v1", null], ["v2", "Wed, 3 Jun 2009 20:29:16 GMT  (223kb)", "http://arxiv.org/abs/0905.3369v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["john langford", "ruslan salakhutdinov", "tong zhang 0001"], "accepted": true, "id": "0905.3369"}, "pdf": {"name": "0905.3369.pdf", "metadata": {"source": "CRF", "title": "Learning Nonlinear Dynamic Models", "authors": ["John Langford"], "emails": ["jl@yahoo-inc.com", "rsalakhu@cs.toronto.edu", "tongz@rci.rutgers.edu"], "sections": [{"heading": null, "text": "ar Xiv: 090 5.33 69v1 [cs.AI] 20 M"}, {"heading": "1. Introduction", "text": "The notion of hidden states appears in many non-stationary models of the world, such as Hidden Markov Models (HMMs), which have discrete states, and Kalman filters, which have continuous states. Figure 1 shows a general dynamic model with observation xt and unobserved hidden state yt. However, the system is characterized by a state transition probability based on all observations X1: t = {x1,.), and a state for observing probability P (xt | yt). The method for predicting future events under such a dynamic model is to have a posterior distribution over the hidden state yt + 1, based on all observations X1: t = {x1,., xt} until the time. The prediction of future events can be updated with the formula: P (yt + 1: t)."}, {"heading": "2. Sufficient Posterior Representation", "text": "Instead of starting with a probability model, our approach directly tackles the problem of predicting yt + k, based on X1: 1. In addition, the prediction depends only on the rear distribution P (yt + 1 | X1: t). Therefore, we can solve the prediction problem as long as we can estimate and update this rear distribution. (Many modern, supervised learning algorithms are universal in the sense that they can learn arbitrary representation in the large sample limitation. In our approach, it is assumed that the rear P (yt + 1 | X1: t) learning model can be approximated by a family of distribution models, in the sense that they have an arbitrary representation in the large sample limitation. In our approach, it is assumed that the rear P (yt + 1 | X1: t) learning model can be approximated by a family of distribution models that are approximated by distribution models within the large sample limitation."}, {"heading": "3. Learning SPR-DM", "text": "The basic idea of our algorithm is to use a bottleneck approach to construct an implicit definition of state, along with the development of state space and projection operators, to answer various natural questions that we could ask."}, {"heading": "3.1. Training", "text": "There are two parts to understanding the training process: the first is the trained architecture, and the second is the exact method of training this architecture. Note that our architecture is essentially functional rather than representative."}, {"heading": "3.1.1. Architecture", "text": "To understand these graphs, it is essential to understand that the arrows are not graphical models. Instead, they are a representation of what information is used to predict what other information is. We distinguish observations and hidden \"states\" as double circles and circles to make clear what is observed and what is not. The first prediction problem solved in Fig. 3, left panel, provides our initial definition of the state. Essentially, the state is \"this information that summarizes the first observation in predicting the second observation.\" Compared with a conventional dynamic model, the quantity s2 can be a sufficient statistic of the state posterior after integration x1 and the development of a step or intermediate mixture. This ambiguity is fundamental, but essential. The second prediction problem is the state development shown in Fig."}, {"heading": "3.1.2. Method", "text": "Training of A is straightforward. Training of C is complicated by the fact that the samples appear in multiple time steps, but otherwise are straightforward given the other components. In order to deal with multiple time steps, it is important for our correctness verification in Section 4.2 that the observation matches the time steps. Training of D is also easy in light of everything else (and again, we will need the timeline as part of the update for correctness verification). The most difficult thing to train is B, since a change from B can cascade over multiple time steps. The method we have chosen uses both local and global information to provide a fast, approximately optimal solution.1. Initialization: Learn Bt, Ct based on time steps t = 1 and conditioning to the previous learning value. Multi-task learning or initialization with previous solutions can be applied to improve convergence. In our experiments, we initialize Bt, Ct based on the parametic values and 3."}, {"heading": "3.2. Testing", "text": "We imagine testing the algorithm by asking questions such as: What is the probability that the observation will give xt \u2032 what is known up to now t \u2032 > t? This is done by using A (x1) to obtain s2, then using B (xi, si) to develop the state st. Then, the time interval of t \u2032 \u2212 t is divided into factors of 2 and the corresponding state projection operators Di are applied to the state, leading to a prediction for st \u2032 \u2212 1."}, {"heading": "4. Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Computation", "text": "The calculation requirements depend on the exact training method. For the initialization step, the training of A, Bt and Ct requires only O (nT) examples. Training Di can only be performed with O (nT log2 T) examples. For the iterative methods, learning B usually requires an additional factor of T per iteration."}, {"heading": "4.2. Consistency", "text": "We show that, under reasonable assumptions, the SPR-DM model can be learned in the infinite limitation of the dynamic limitation based on our algorithms. Due to the space limitation, we consider only the non-agnostic situation in which the SPR-DM model is exact, that is, the functions A, B, C used in our learning algorithm contain the correct functions. The agnostic setting in which the SPR-DM model is only approximately correct can be analyzed using disturbance techniques (e.g. for linear systems, this happens in (Hsu et al, 2008)). Although such an analysis is useful, the basic insight is identical to the non-agnostic analysis, which is considered here as inductive. We consider the following limitations in the SPR-DM model. We assume that the model is unchangeable: distribution via xt (general definition, we can be extended to other vector functions)."}, {"heading": "5. Experiments", "text": "In this section, we present experimental results on two sets of data containing high-dimensional, highly structured sequence data: the first set of data is the motion capture data from the CMU Graphics Lab Motion Capture Database; the second set is the Weizmann dataset 2, which contains video sequences of nine human subjects performing various actions."}, {"heading": "5.1. Details of Training", "text": "While the framework introduced allows us to use many available nonlinear monitored learning algorithms, in our experiments we use the following parametric forms for our operators: s2 = A (x1) = \u03c3 (A x1 + b), st = B (xt \u2212 1, st \u2212 1) = \u03c3 (B 1 xt \u2212 1 + B 2 st \u2212 1 + b), x t = C st + a, st + 2j = Dj (st) = D j st + d, where \u03c3 (y) = 1 / (1 + exp (\u2212 y) is the logistic function applied componentwise: {C, B, A, Dij, a, b, d} are the model parameters with a, b and d representing the bias terms. For both datasets, the values of {Bt, Ct} were initialized during the initialization step on the average parameter values of previous timepens3."}, {"heading": "5.2. Motion Capture Data", "text": "The human motion data consists of sequences of 3D joint angles plus body orientation and translation. The data set was pre-processed to be invariant to isometries (Taylor et al., 2006), and includes various running styles, including normal, drunk, graceful, gangly, sexy, dinosaur, chicken and strong. We randomly divided the data into 30 training sequences and 8 test sequences, each with a length of 50. Training data were further randomly divided into the 25 training sequences and 5 validation sequences. Each time step was represented by a vector of 58 real numbers. The data set was also standardized to have an average of zero, scaled by a single number, so that the variance over each dimension was equal to 1 on average. The dimensionality of the hidden state was shown on 20. Figure 4 shows the average test predictor with squared losses, with the foreseeable horizon of M2."}, {"heading": "5.3. Modeling Video", "text": "The results of the Motion Capture dataset show that a non-linear model can outperform linear and HMM models in making far-reaching predictions. In this section, we present results of the Weizmann dataset, which is much more difficult than the Motion Capture dataset. The Weizmann dataset contains video sequences of nine human subjects performing various actions, including waving with one hand, waving with two hands, jumping and bending. Each video sequence was preprocessed by placing a bounding box around a person performing an action. Subsequently, the dataset was reduced to 29 \u00d7 16 images, each step represented by a vector of 464 real numbers. We randomly divided the data into 36 training sessions (30 training and 6 validation) and 10 test sequences, each of the length 50. The dataset was also normalized to zero mean and variance 1. The dimension of the hidden state of a non-authoritative model was also shown to be particularly strong at 50."}, {"heading": "6. Conclusions", "text": "In this paper, we presented a new approach to learning nonlinear dynamic systems and demonstrated that it performs well compared to standard models such as HMMs or linear predictors on fairly hard high-dimensional time series datasets. We believe that the framework presented opens up a whole new set of devices for nonlinear dynamic modeling, removing several obstacles in the traditional approach that requires heavy human design, and enabling the automatic use of established monitored learning algorithms for nonlinear dynamic models."}, {"heading": "Acknowledgments", "text": "This work was done when Ruslan Salakhutdinov visited Yahoo. Tong Zhang is partially supported by the NSFgrant DMS-0706805."}], "references": [{"title": "A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking", "author": ["M.S. Arulampalam", "S. Maskell", "N. Gordon", "T. Clapp"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Arulampalam et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Arulampalam et al\\.", "year": 2002}, {"title": "Mixture Kalman filters", "author": ["R. Chen", "J.S. Liu"], "venue": "Journal of the Royal Statistical Society: Series B,", "citeRegEx": "Chen and Liu,? \\Q2000\\E", "shortCiteRegEx": "Chen and Liu", "year": 2000}, {"title": "Searchbased structured prediction", "author": ["H. Daume", "J. Langford", "D. Marcu"], "venue": "Machine Learning Journal", "citeRegEx": "Daume et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Daume et al\\.", "year": 2009}, {"title": "Novel approach to nonlinear/non-Gaussian Bayesian state estimation", "author": ["N.J. Gordon", "D.J. Salmond", "A. Smith"], "venue": "IEE Proceedings Part F. (pp. 107\u2013113)", "citeRegEx": "Gordon et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 1993}, {"title": "A spectral algorithm for learning hidden markov models. http://arxiv.org/abs/0811.4413", "author": ["D. Hsu", "S.M. Kakade", "T. Zhang"], "venue": null, "citeRegEx": "Hsu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2008}, {"title": "Approximately optimal approximate reinforcement learning", "author": ["S. Kakade", "J. Langford"], "venue": "Int. Conference on Machine Learning (pp. 267\u2013274)", "citeRegEx": "Kakade and Langford,? \\Q2002\\E", "shortCiteRegEx": "Kakade and Langford", "year": 2002}, {"title": "Learning nonlinear dynamical systems using the em algorithm", "author": ["S. Roweis", "Z. Ghahramani"], "venue": "In S. Haykin (Ed.), Kalman filtering and neural networks,", "citeRegEx": "Roweis and Ghahramani,? \\Q2001\\E", "shortCiteRegEx": "Roweis and Ghahramani", "year": 2001}, {"title": "Modeling human motion using binary latent variables. Advances in Neural Information Processing Systems (pp. 1345\u20131352)", "author": ["G.W. Taylor", "G.E. Hinton", "S.T. Roweis"], "venue": null, "citeRegEx": "Taylor et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Taylor et al\\.", "year": 2006}, {"title": "Bayesian forecasting and dynamic models (2nd ed.)", "author": ["M. West", "J. Harrison"], "venue": null, "citeRegEx": "West and Harrison,? \\Q1997\\E", "shortCiteRegEx": "West and Harrison", "year": 1997}, {"title": "Parametric hidden markov models for gesture recognition", "author": ["A.D. Wilson", "A.F. Bobick"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Wilson and Bobick,? \\Q1999\\E", "shortCiteRegEx": "Wilson and Bobick", "year": 1999}], "referenceMentions": [{"referenceID": 4, "context": "of certain hidden Markov models can be achieved in polynomial time (Hsu et al., 2008).", "startOffset": 67, "endOffset": 85}, {"referenceID": 3, "context": "For example, in the particle filtering approach (Gordon et al., 1993; Arulampalam et al., 2002), one uses a finite number of samples to represent the posterior distribution and the samples are then updated as observations arrive.", "startOffset": 48, "endOffset": 95}, {"referenceID": 0, "context": "For example, in the particle filtering approach (Gordon et al., 1993; Arulampalam et al., 2002), one uses a finite number of samples to represent the posterior distribution and the samples are then updated as observations arrive.", "startOffset": 48, "endOffset": 95}, {"referenceID": 2, "context": "The precise method of stochastic mixing used in the experiments is equivalent to applying the derivative update with probability \u03b1 and not update with probability 1 \u2212 \u03b1, which is a computational and representational improvement over Searn (Daume et al., 2009).", "startOffset": 239, "endOffset": 259}, {"referenceID": 4, "context": ", for linear systems, this is done in (Hsu et al., 2008)).", "startOffset": 38, "endOffset": 56}, {"referenceID": 7, "context": "The dataset was preprocessed to be invariant to isometries (Taylor et al., 2006), and contains various walking styles, including normal, drunk, graceful, gangly, sexy, dinosaur, chicken, and strong.", "startOffset": 59, "endOffset": 80}], "year": 2017, "abstractText": "We present a novel approach for learning nonlinear dynamic models, which leads to a new set of tools capable of solving problems that are otherwise difficult. We provide theory showing this new approach is consistent for models with long range structure, and apply the approach to motion capture and highdimensional video data, yielding results superior to standard alternatives.", "creator": null}}}