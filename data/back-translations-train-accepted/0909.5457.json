{"id": "0909.5457", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Sep-2009", "title": "Guaranteed Rank Minimization via Singular Value Projection", "abstract": "Minimizing the rank of a matrix subject to affine constraints is a fundamental problem with many important applications in machine learning and statistics. In this paper we propose a simple and fast algorithm SVP (Singular Value Projection) for rank minimization with affine constraints (ARMP) and show that SVP recovers the minimum rank solution for affine constraints that satisfy the \"restricted isometry property\". Our results improve upon a recent breakthrough by Recht, Fazel and Parillo (RFP07) in three significant ways:", "histories": [["v1", "Wed, 30 Sep 2009 14:44:54 GMT  (41kb)", "http://arxiv.org/abs/0909.5457v1", null], ["v2", "Mon, 19 Oct 2009 19:32:44 GMT  (49kb)", "http://arxiv.org/abs/0909.5457v2", "An earlier version of this paper was submitted to NIPS-2009 on June 5, 2009"], ["v3", "Mon, 19 Oct 2009 21:21:57 GMT  (49kb)", "http://arxiv.org/abs/0909.5457v3", "An earlier version of this paper was submitted to NIPS-2009 on June 5, 2009"]], "reviews": [], "SUBJECTS": "cs.LG cs.IT math.IT", "authors": ["prateek jain 0002", "raghu meka", "inderjit s dhillon"], "accepted": true, "id": "0909.5457"}, "pdf": {"name": "0909.5457.pdf", "metadata": {"source": "CRF", "title": "Guaranteed Rank Minimization via Singular Value Projection", "authors": ["Raghu Meka", "Prateek Jain", "Inderjit S. Dhillon"], "emails": ["inderjit}@cs.utexas.edu"], "sections": [{"heading": null, "text": "ar Xiv: 090 9.54 57v1 [cs.LG] 3 0SE p"}, {"heading": "1 Introduction", "text": "In this paper, we examine general affinity for minimization (ARMP) or alternative MIGs (X). However, the general affinity for manipulating is of considerable practical interest and many important machine learning problems such as matrix completion, most known methods for ARMP were heuristic in nature with few known rigorous guarantees. The most commonly used heuristic solution to the problem is the assumption of a factorization of X and the optimization of the resulting non-convex problem."}, {"heading": "2 Singular Value Projection (SVP)", "text": "(1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1. (1). (1). (1). (1). (1. (1). (1). (1). (1). (1). (1). (1). (1.). (1.). (1.). (1.). (1.).). (1.). (1.). (1.).). (1.). (1.). (1.).). (1.).).). (1.). (1.). (1.).). (1.).). (1.). (1.).). (1.).). (1.).). (1.).). (1.). (1.).).). (1.).).). (1.).). (1.).). (1.).).). (1.). (1.).). (1.).). (1.).).). (1."}, {"heading": "4 Matrix Completion", "text": "The first non-vial solution for MCP was recently obtained by Candes and KKP. (RFP07) The first non-vial solution for MCP is that of Recht et al. (RFP07) The first non-vial solution for MCP. (RCP) The first non-vial solution for MCP. (RCP) The first non-vial solution for MCP. (RCP) The first non-vial solution for MCP. (RCP) The first non-vial solution for MCP. (RCP) The first non-vial solution for MCP. (RP) The first non-vial solution for MCP. (RCP) The first non-vial solution for MCP. (RFP07) The first non-vial solution for MCP. (RCP) The first non-vial solution for MCP. (RCP) The first non-vial solution for MCP."}, {"heading": "5 Computational Issues and Related Work", "text": "s algorithm based on the linear reduction of Bregman iteration. [CCS08] For example, a singular Value Thresholding (SVT) based on Uzawa's algorithm has been proposed. [MGC09].Toh and Yun [TY09], Ji and Ye [TY09] proposed methods for optimizing the trace norm. While the methods for optimizing the soft thresholds are significant."}, {"heading": "6 Experimental Results", "text": "In this section, we will empirically analyze our SVP method for affinity minimization and low-granulate matrix completion problems. For both problems, we will present empirical results on synthetic and real data sets. For ARMP, we will compare our method with the track standard-based method of singular value threshold (SVT) [CCS08]. Note that [CCS08] represents the SVT method in the context of the matrix completion problem, but it can be easily customized for ARMP. For matrix completion, we will compare with SVT, the spectral matrix completion (SMC) and the regulated alternating minimization of the smallest squares (ALS). We will use our own implementation of SVT for ARMP and ALS, while we will use the code provided by the respective authors for SVT and SMC for matrix completion."}, {"heading": "6.1 Affine Rank Minimization", "text": "First, we compare our method with SVT on random ARMP instances. We generate random matrices X-Rn \u00b7 n of different sizes n and fixed rank k = 5. Then we generate d = 6kn random affine constraint matrices Ai, 1 \u2264 i \u2264 d and calculate b = A (X). Figure 3 (a) compares the computational time needed for SVP and SVT to achieve a relative error (\u2261 A (X) \u2212 b \u00b2 2 / x b \u00b2 2) of 10 \u2212 3. Our method requires much less iterations and is significantly faster than SVT. Next, we evaluate our method for the problem of matrix reconstruction from random measurements. As in Recht et al. [RFP07], we use the MIT logo as a test image for the reconstruction. The MIT logo we use is a 38 x 73 image and ranks 4. For reconstruction, we create random measurement matrices Ai and TFP07."}, {"heading": "6.2 Matrix Completion", "text": "Next, we evaluate our method using different matrix completion methods for low-level random matrices and uniform samples. We generate a random k-matrix X-Rn-n and generate random Bernoulli samples with the probability P. Figure 4 compares the time taken by various methods to produce an average square error (RMSE) of 10 \u2212 3. For this experiment, we generate random matrices of different sizes and corrupt about 10% of samples by adding large Gaussian noise. Figure 5 records the behavior of our method when there are outliers in the samples. Note that SVT is particularly sensitive to failed matrices of different sizes and corrupt about 10% of samples by adding large Gaussian noise. Figure 5 records errors that occur by different methods and take time as n increases from 500 to 5000. Note that SVT is particularly sensitive to failed matrices of different sizes and causes RVP."}, {"heading": "7 Conclusion and Future Work", "text": "Most of this work, with the exception of Keshavan et al. [KOM09], relies on the loosening of the ranking constraint by the trace standard and provides guarantees for restoring the optimal solution under certain additional assumptions. However, trace-standard relaxation methods are typically difficult to analyze and are relatively expensive in practice. In this paper, we propose a simple and natural algorithm based on iterative hard thresholds. We give a simple analysis of our algorithm for the affine-rank minimization problem that satisfies the limited isometry property and guarantee geometric convergence even in the presence of noise. Intermediate steps in our algorithm are less compromising than the current methods of art."}, {"heading": "Acknowledgments", "text": "This research was supported by NSF funding CCF-0431257, NSF-ITR funding IIS-0325116 and NSF funding CCF-0728879."}], "references": [{"title": "Studies in Linear and Nonlinear Programming", "author": ["K. Arrow", "L. Hurwicz", "H. Uzawa"], "venue": "Stanford University Press, Stanford", "citeRegEx": "AHU58", "shortCiteRegEx": null, "year": 1958}, {"title": "Applied and Computational Harmonic Analysis", "author": ["Thomas Blumensath", "Mike E. Davies. Iterative hard thresholding for compressed sensing"], "venue": "27(3):265 \u2013 274,", "citeRegEx": "BD09", "shortCiteRegEx": null, "year": 2009}, {"title": "Fast online svd revisions for lightweight recommender systems", "author": ["Matthew Brand"], "venue": "In SIAM International Conference on Data Mining.", "citeRegEx": "Bra03", "shortCiteRegEx": null, "year": 2003}, {"title": "and Zuowei Shen", "author": ["Jian-Feng Cai", "Emmanuel J. Candes"], "venue": "A singular value thresholding algorithm for matrix completion,", "citeRegEx": "CCS08", "shortCiteRegEx": null, "year": 2008}, {"title": "Cand\u00e8s and Yaniv Plan", "author": ["J Emmanuel"], "venue": "Matrix completion with noise,", "citeRegEx": "CP09", "shortCiteRegEx": null, "year": 2009}, {"title": "Cand\u00e8s and Benjamin Recht", "author": ["J Emmanuel"], "venue": "Exact matrix completion via convex optimization,", "citeRegEx": "CR08", "shortCiteRegEx": null, "year": 2008}, {"title": "Sparse and low-rank matrix decompositions", "author": ["V. Chandrasekaran", "S. Sanghavi", "P. Parrilo", "A. Willsky"], "venue": "IFAC Symposium on System Identification.", "citeRegEx": "CSPW09", "shortCiteRegEx": null, "year": 2009}, {"title": "Cand\u00e8s and Terence Tao", "author": ["J Emmanuel"], "venue": "The power of convex relaxation: Near-optimal matrix completion,", "citeRegEx": "CT09", "shortCiteRegEx": null, "year": 2009}, {"title": "Arlington", "author": ["M. Fazel", "H. Hindi", "S. Boyd. A rank minimization heuristic with application to minimum order system approximation. In American Control Conference"], "venue": "Virginia.", "citeRegEx": "FHB01", "shortCiteRegEx": null, "year": 2001}, {"title": "Advances in linear matrix inequality methods in control: advances in design and control", "author": ["Karolos M. Grigoriadis", "Eric B. Beran. Alternating projection algorithms for linear matrix inequalities problems with rank constraints"], "venue": "pages 251\u2013267,", "citeRegEx": "GB00", "shortCiteRegEx": null, "year": 2000}, {"title": "Gradient descent with sparsification: an iterative algorithm for sparse recovery with restricted isometry property", "author": ["Rahul Garg", "Rohit Khandekar"], "venue": "ICML.", "citeRegEx": "GK09", "shortCiteRegEx": null, "year": 2009}, {"title": "An accelerated gradient method for trace norm minimization", "author": ["Shuiwang Ji", "Jieping Ye"], "venue": "ICML.", "citeRegEx": "JY09", "shortCiteRegEx": null, "year": 2009}, {"title": "and Andrea Montanari", "author": ["Raghunandan H. Keshavan", "Sewoong Oh"], "venue": "Matrix completion from a few entries,", "citeRegEx": "KOM09", "shortCiteRegEx": null, "year": 2009}, {"title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model", "author": ["Yehuda Koren"], "venue": "KDD, pages 426\u2013434.", "citeRegEx": "Kor08", "shortCiteRegEx": null, "year": 2008}, {"title": "In ICDM", "author": ["Yehuda Koren M. Bell. Scalable collaborative filtering with jointly derived neighborhood interpolation weights"], "venue": "pages 43\u201352.", "citeRegEx": "MB07", "shortCiteRegEx": null, "year": 2007}, {"title": "and L", "author": ["S. Ma", "D. Goldfarb"], "venue": "Chen. Fixed point and bregman iterative methods for matrix rank minimization,", "citeRegEx": "MGC09", "shortCiteRegEx": null, "year": 2009}, {"title": "In ICML", "author": ["Raghu Meka", "Prateek Jain", "Constantine Caramanis", "Inderjit S. Dhillon. Rank minimization via online learning"], "venue": "pages 656\u2013663.", "citeRegEx": "MJCD08", "shortCiteRegEx": null, "year": 2008}, {"title": "Parrilo", "author": ["Benjamin Recht", "Maryam Fazel", "Pablo A"], "venue": "Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization,", "citeRegEx": "RFP07", "shortCiteRegEx": null, "year": 2007}, {"title": "Taylor & Francis", "author": ["Robert E. Skelton", "T. Iwasaki", "K.M. Grigoriadis. A Unified Algebric Approach to Control Design"], "venue": "Inc., Bristol, PA, USA,", "citeRegEx": "SIG97", "shortCiteRegEx": null, "year": 1997}, {"title": "and Y", "author": ["J. Wright", "A. Ganesh", "S. Rao"], "venue": "Ma. Robust principal component analysis: Exact recovery of corrupted low-rank matrices by convex optimization,", "citeRegEx": "WGRM09", "shortCiteRegEx": null, "year": 2009}, {"title": "Bernstein inequalities (probability theory) \u2014 wikipedia", "author": ["Wikipedia"], "venue": "the free encyclopedia,", "citeRegEx": "Wik09", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 17, "context": "Our results improve upon a recent breakthrough by Recht, Fazel and Parillo [RFP07] in three significant ways: 1) our method (SVP) is significantly simpler to analyse and easier to implement, 2) we give geometric convergence guarantees for SVP and, as demonstrated empiricially, SVP is significantly faster on real-world and synthetic problems, 3) we give optimality and geometric convergence guarantees even for the noisy version of ARMP.", "startOffset": 75, "endOffset": 82}, {"referenceID": 16, "context": "Unfortunately, ARMP is NP-hard in general and is also NP-hard to approximate ([MJCD08]).", "startOffset": 78, "endOffset": 86}, {"referenceID": 9, "context": "The most commonly used heuristic for the problem is to assume a factorization of X and optimize the resulting non-convex problem by alternating minimization [Bra03, Kor08, MB07], alternative projections [GB00] or alternating LMIs [SIG97].", "startOffset": 203, "endOffset": 209}, {"referenceID": 18, "context": "The most commonly used heuristic for the problem is to assume a factorization of X and optimize the resulting non-convex problem by alternating minimization [Bra03, Kor08, MB07], alternative projections [GB00] or alternating LMIs [SIG97].", "startOffset": 230, "endOffset": 237}, {"referenceID": 8, "context": "Another common approach is to relax the rank constraint to a convex function such as the trace-norm or the log determinant [FHB01], [FHB03].", "startOffset": 123, "endOffset": 130}, {"referenceID": 16, "context": "[MJCD08] proposed online learning based methods for ARMP.", "startOffset": 0, "endOffset": 8}, {"referenceID": 17, "context": "In a recent breakthrough, Recht, Fazel and Parillo [RFP07] obtained the first non-trivial exactrecovery results for ARMP obtaining guaranteed rank minimization for affine transformations A that satisfy a restricted isometry property (RIP).", "startOffset": 51, "endOffset": 58}, {"referenceID": 1, "context": "Our analysis of SVP is motivated by the recent work in the field of conpressed sensing by Blumensath and Davies [BD09], Garg and Khandekar [GK09].", "startOffset": 112, "endOffset": 118}, {"referenceID": 10, "context": "Our analysis of SVP is motivated by the recent work in the field of conpressed sensing by Blumensath and Davies [BD09], Garg and Khandekar [GK09].", "startOffset": 139, "endOffset": 145}, {"referenceID": 17, "context": "[RFP07]: we only require \u03b42k < 1/3 as opposed to \u03b45k < 1/10 required by Recht et al.", "startOffset": 0, "endOffset": 7}, {"referenceID": 17, "context": "[RFP07] only address the case of exact measurements.", "startOffset": 0, "endOffset": 7}, {"referenceID": 5, "context": "Recently, Candes and Recht [CR08], Candes and Tao [CT09] and Keshavan et al.", "startOffset": 27, "endOffset": 33}, {"referenceID": 7, "context": "Recently, Candes and Recht [CR08], Candes and Tao [CT09] and Keshavan et al.", "startOffset": 50, "endOffset": 56}, {"referenceID": 12, "context": "[KOM09] obtained the first non-trivial results for low-rank matrix completion under a few additional assumptions.", "startOffset": 0, "endOffset": 7}, {"referenceID": 3, "context": "[CCS08], are quite expensive in practice and not very tolerant to noise.", "startOffset": 0, "endOffset": 7}, {"referenceID": 5, "context": "We demonstrate empirically that for a suitable step-size, SVP significantly outperforms the methods of [CR08], [CT09], [CCS08], [KOM09] in accuracy, computational time and tolerance to noise.", "startOffset": 103, "endOffset": 109}, {"referenceID": 7, "context": "We demonstrate empirically that for a suitable step-size, SVP significantly outperforms the methods of [CR08], [CT09], [CCS08], [KOM09] in accuracy, computational time and tolerance to noise.", "startOffset": 111, "endOffset": 117}, {"referenceID": 3, "context": "We demonstrate empirically that for a suitable step-size, SVP significantly outperforms the methods of [CR08], [CT09], [CCS08], [KOM09] in accuracy, computational time and tolerance to noise.", "startOffset": 119, "endOffset": 126}, {"referenceID": 12, "context": "We demonstrate empirically that for a suitable step-size, SVP significantly outperforms the methods of [CR08], [CT09], [CCS08], [KOM09] in accuracy, computational time and tolerance to noise.", "startOffset": 128, "endOffset": 135}, {"referenceID": 7, "context": "Furthermore, our experiments strongly suggest (see Figure 1) that guarantees similar to those of [CT09], [KOM09] hold for SVP, achieving exact recovery for incoherent matrices from an almost optimal number of entries1.", "startOffset": 97, "endOffset": 103}, {"referenceID": 12, "context": "Furthermore, our experiments strongly suggest (see Figure 1) that guarantees similar to those of [CT09], [KOM09] hold for SVP, achieving exact recovery for incoherent matrices from an almost optimal number of entries1.", "startOffset": 105, "endOffset": 112}, {"referenceID": 17, "context": "[RFP07] do not directly apply to MCP.", "startOffset": 0, "endOffset": 7}, {"referenceID": 5, "context": "The first non-trivial results for MCP were obtained recently by Candes and Recht [CR08], Keshavan et al.", "startOffset": 81, "endOffset": 87}, {"referenceID": 12, "context": "[KOM09] and Candes and Tao [CT09].", "startOffset": 0, "endOffset": 7}, {"referenceID": 7, "context": "[KOM09] and Candes and Tao [CT09].", "startOffset": 27, "endOffset": 33}, {"referenceID": 20, "context": "We need Bernstein\u2019s inequality [Wik09] stated below.", "startOffset": 31, "endOffset": 38}, {"referenceID": 3, "context": "[CCS08] proposed a Singular Value Thresholding (SVT) algorithm which is based on Uzawa\u2019s algorithm[AHU58].", "startOffset": 0, "endOffset": 7}, {"referenceID": 0, "context": "[CCS08] proposed a Singular Value Thresholding (SVT) algorithm which is based on Uzawa\u2019s algorithm[AHU58].", "startOffset": 98, "endOffset": 105}, {"referenceID": 15, "context": "[MGC09].", "startOffset": 0, "endOffset": 7}, {"referenceID": 11, "context": "Toh and Yun [TY09], Ji and Ye [JY09] proposed Nesterov\u2019s projected gradient based methods for optimizing the trace-norm.", "startOffset": 30, "endOffset": 36}, {"referenceID": 4, "context": "Also, though minimizing the trace-norm does most likely approximate the low-rank solution even in the presence of noise (see [CP09] for instance), noise poses considerable computational challenges for trace-norm optimization.", "startOffset": 125, "endOffset": 131}, {"referenceID": 5, "context": "For the case of low-rank matrix completion, Candes and Recht [CR08] obtained the first nontrivial results for the problem obtaining guaranteed completion for incoherent matrices X\u2217 and randomly sampled entries \u03a9.", "startOffset": 61, "endOffset": 67}, {"referenceID": 7, "context": "Building on the work of Candes and Recht, Candes and Tao [CT09] obtained the near-optimal bound of |\u03a9| \u2265 min(C\u03bc4k2n log n,C\u03bc2kn log n) for exact-recovery via trace-norm minimization.", "startOffset": 57, "endOffset": 63}, {"referenceID": 3, "context": "However, the analysis of Candes and Recht, Candes and Tao is considerably complicated and minimizing trace-norm, even when using methods taylored for matrix-completion such as those of [CCS08], is relatively expensive in practice.", "startOffset": 185, "endOffset": 192}, {"referenceID": 12, "context": "[KOM09] obtained exact-recovery from uniformly sampled \u03a9 with |\u03a9| \u2265 C(\u03bc, k)n log n using different technqiues.", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "[CSPW09] andWright et al.", "startOffset": 0, "endOffset": 8}, {"referenceID": 19, "context": "[WGRM09].", "startOffset": 0, "endOffset": 8}, {"referenceID": 19, "context": "[WGRM09] show that the low-rank matrix completion problem can be reduced to the low-rank plus sparse decomposition problem.", "startOffset": 0, "endOffset": 8}, {"referenceID": 3, "context": "singular value thresholding (SVT) method [CCS08].", "startOffset": 41, "endOffset": 48}, {"referenceID": 3, "context": "Note that although [CCS08] presents SVT method in the context of matrix completion problem, however it can be easily adapted for ARMP.", "startOffset": 19, "endOffset": 26}, {"referenceID": 12, "context": "For matrix completion we compare against SVT, the spectral matrix completion (SMC) method of [KOM09], and regularized alternating least squares minimization (ALS).", "startOffset": 93, "endOffset": 100}, {"referenceID": 17, "context": "[RFP07], we use the MIT logo as the test image for reconstruction.", "startOffset": 0, "endOffset": 7}, {"referenceID": 12, "context": "[KOM09], rely on relaxing the rank constraint with trace-norm and give guarantees for recovering the optimal", "startOffset": 0, "endOffset": 7}, {"referenceID": 6, "context": "Other directions include application of our methods to other problems of similar flavour such as the low-rank plus sparse matrix decomposition [CSPW09], or other matrix completion type problems like minimum dimensionality embedding using partial distance observations [FHB03] and low-rank kernel learning [MJCD08].", "startOffset": 143, "endOffset": 151}, {"referenceID": 16, "context": "Other directions include application of our methods to other problems of similar flavour such as the low-rank plus sparse matrix decomposition [CSPW09], or other matrix completion type problems like minimum dimensionality embedding using partial distance observations [FHB03] and low-rank kernel learning [MJCD08].", "startOffset": 305, "endOffset": 313}], "year": 2017, "abstractText": "Minimizing the rank of a matrix subject to affine constraints is a fundamental problem with many important applications in machine learning and statistics. In this paper we propose a simple and fast algorithm SVP (Singular Value Projection) for rank minimization with affine constraints (ARMP) and show that SVP recovers the minimum rank solution for affine constraints that satisfy the restricted isometry property. We show robustness of our method to noise with a strong geometric convergence rate even for noisy measurements. Our results improve upon a recent breakthrough by Recht, Fazel and Parillo [RFP07] in three significant ways: 1) our method (SVP) is significantly simpler to analyse and easier to implement, 2) we give geometric convergence guarantees for SVP and, as demonstrated empiricially, SVP is significantly faster on real-world and synthetic problems, 3) we give optimality and geometric convergence guarantees even for the noisy version of ARMP. In addition, we address the practically important problem of low-rank matrix completion, which can be seen as a special case of ARMP. However, the affine constraints defining the matrix-completion problem do not obey the restricted isometry property in general. We empirically demonstrate that our algorithm recovers low-rank incoherent matrices from an almost optimal number of uniformly sampled entries. We make partial progress towards proving exact recovery and provide some intuition for the performance of SVP applied to matrix completion by showing a more restricted isometry property. Our algorithm outperforms existing methods, such as those of [RFP07, CR08, CT09, CCS08, KOM09], for ARMP and the matrix-completion problem by an order of magnitude and is also significantly more robust to noise.", "creator": "LaTeX with hyperref package"}}}