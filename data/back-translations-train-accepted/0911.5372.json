{"id": "0911.5372", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Nov-2009", "title": "Maximin affinity learning of image segmentation", "abstract": "Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation. Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates. However, this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph. We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure. The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation. By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph, we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning. Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs, which are predictive of the pixel-pair connectivity.", "histories": [["v1", "Sat, 28 Nov 2009 04:58:38 GMT  (1062kb,D)", "http://arxiv.org/abs/0911.5372v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG cs.NE", "authors": ["srinivas c turaga", "kevin l briggman", "moritz helmstaedter", "winfried denk", "h sebastian seung"], "accepted": true, "id": "0911.5372"}, "pdf": {"name": "0911.5372.pdf", "metadata": {"source": "CRF", "title": "Maximin affinity learning of image segmentation", "authors": ["Srinivas C. Turaga", "Kevin L. Briggman"], "emails": ["sturaga@mit.edu"], "sections": [{"heading": null, "text": "Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped, and then partitioning the graph to achieve segmentation. Machine learning has been applied to the affinity classifier to create affinity graphs that are good in the sense of minimizing edge misclassification rates. However, this error size is only indirectly related to the quality of segmentations generated by the eventual partitioning of the affinity graph. We present the first machine learning algorithm to create a classifier to generate affinity graphs that are good in the sense of generating segmentations that directly minimize the edge index, a known segmentation performance. The Rand Index measures the segmentation performance by quantifying the connectivity of image pixelar pairings based on the segmentation algorithm we are using to easily determine the threshold pairment algorithm."}, {"heading": "1 Introduction", "text": "In this context, it should be noted that this project is a project which is, first and foremost, a project which focuses on the needs of the people."}, {"heading": "2 Partitioning a thresholded affinity graph by connected components", "text": "Our class of segmentation algorithms is constructed by combining a classifier and a graph partitioner (see Figure 1). The classifier is used to generate the weights of an affinity graph. The nodes of the graph are image pixels, and the edges are between the next adjacent pairs of pixels. The weights of the edges are called affinities. A high affinity means that the two pixels tend to belong to the same segment. The classifier calculates the affinity of each edge that surrounds the edge.The graph partitioner first oscillates the affinity curve by removing all edges with weights that are less than a threshold. The associated components of this threshold affinity graph are the segments of the image.For this class of segmentation algorithms, it is obvious that a single misclassified edge of the affinity graph graph graph graph graph is it."}, {"heading": "3 The Rand index quantifies segmentation performance", "text": "Image segmentation can be considered a special case of the general problem of clustering, since image segments are aggregations of image pixels. Long ago, Rand proposed an index of similarity between two image pixels [18]. Recently, it was suggested that the border index should be applied to image segmentation [23]. Define a segmentation S as mapping a segment label si to each pixel i. The indicator function \u043c (si, sj) is 1 if the pixels i and j belong to the same segment (si = sj) and 0 otherwise. In the face of two segmentations S and S of an image with N pixels, define the function1 \u2212 RI (S, S) = (N 2) \u2212 1 if the pixels i < j (si, sj) \u2212."}, {"heading": "4 Connectivity and maximin affinity", "text": "To apply the Rand Index to train our classifier, we need a simple way to relate the indicator function. To do this, let us introduce the concept of maximum affinity defined for each pair of pixels in an affinity graph (the definition is universally applicable to each weighted graph), let us introduce Aklbe the affinity of pixels k and l. Let us introduce the concept of maximum affinity defined for each pair of pixels in an affinity graph (the definition is universally applicable to each weighted graph), let Aklbe the affinity of pixels k and l. Let P ij be the set of all paths in the graph linking pixels i and j. For each path P in pij there is an edge (or edges) with minimal affinity."}, {"heading": "5 Optimizing the Rand index by learning maximin affinities", "text": "Since affinities and maximum affinities are both functions of image I and the classification parameters W, we write them as Aij (I; W) and A * ij (I; W). < (4) of the previous section, the margin index of Eq. (1) performs the form1 \u2212 RI (S, I; W) = (N 2) \u2212 1 \u00b2 i < (S) \u2212 H (I, sj) \u2212 H (A) ij (I; W) \u2212 \u03b8 (I) \u2212 \u03b8 (V) -\u03b8). Since it is a discontinuous function of the maximum affinities, we do the usual relaxation by replacing the standard function (si, sj) \u2212 H (I; W) \u2212 \u03b8 ij (W) \u2212 \u03b8) | with a continuous loss function l (si, sj), A (S), ij (S), I)."}, {"heading": "6 Online stochastic gradient descent", "text": "The calculation of the cost function or its gradient requires the determination of the maximum edges for all pixel pairs. Such a batch calculation could be used for the gradient learning. However, online stochastic gradientlearning is often more efficient than batch learning [13]. Online learning performs a gradient update of the parameters after each pixel pair and is described in the box. Maximin affinity learning 1. Select a random pair of (not necessarily the closest neighbor) pixels i and j from a randomly drawn training image I.2. Find a maximum edge mm (i, j) 3. Make the gradient update: W + \u03b7 ddW l (si, sj), Amm (i; W) Standard affinity learning 1. Select a random pair of the next edge mm (i, j) 3. Make the gradient update: W + \u03b7 ddW (si, j), jaffinity 1."}, {"heading": "7 Application to electron microscopic images of neurons", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1 Electron microscopic images of neural tissue", "text": "By 3D imaging of sufficiently high-resolution brain tissue and identifying synapses and tracking all axons and dendrites in these images, it is in principle possible to reconstruct connectomes and complete \"wiring diagrams\" for a brain or a piece of brain [19, 4, 21]. Axons can be smaller than 100 nm in diameter, requiring electron microscopy (EM) [19]. At such high spatial resolution, only one cubic millimeter of brain tissue yields image sizes on a teravoxel scale. Recent advances in automation make it possible to capture such images [19, 4, 21] but image analysis remains a challenge. Detecting axons and dendrites is a very large image segmentation problem requiring high accuracy. The images used in this study originate from the inner plexiform layer of the canine mesh and were captured with the aid of Srosmiface electron."}, {"heading": "7.2 Training convolutional networks for affinity classification", "text": "Any classifier that provides a smooth function of its parameters can be used for maximum affinity learning. We have used Convolutionary Networks (CN), but our method is not limited to this choice. Convolutionary Networks have previously proven effective for similar EM images of brain tissue [11]. We trained two identical four-layer CNs, one with standard affinity learning and the second with MALIS. The CNs contained 5 feature cards in each layer with sigmoid nonlinearity. All filters in the CN were 5 x 5 x 5 in size. This resulted in an affinity classifier that uses a 17 x 17 x 17 cubic spot to classify an affinity edge. We used the square loss function l (x, x) = x \u00b7 max (0, 1 \u2212 x \u00b2 \u2212 m) 2 + (1 \u2212 x) \u00b7 max (1 \u2212 x) \u00b7 affinity classifier that forms an affinity edge function."}, {"heading": "7.3 Maximin learning leads to dramatic improvement in segmentation performance", "text": "After the formation of the standard and MALIS affinity classifiers, we created affinity graphs for the training and test images. In principle, the training algorithm proposes a uniform threshold for chart partitioning. In practice, one can generate a full spectrum of segmentations that lead from supersegmentation to subsegmentation by varying the threshold parameter. In Fig. 3, we plot the edge index for segmentation resulting from a series of thresholds. In images with a large number of segments, most pixel pairs are separated from each other, resulting in a large imbalance in the number of connected and unconnected pixel pairs. This is reflected in the fact that the edge index has over 95% for both segmentation algorithms. While this imbalance between positive and negative examples does not represent a significant problem for the formation of affinity classification, it is difficult to make comparisons between the components we can only put together for the interpretation of the components."}, {"heading": "8 Discussion", "text": "In this thesis, we have trained an affinity classifier to create affinity graphs that result in excellent segmentation when partitioned by the simple graph partitioning algorithm of the threshold followed by connected components. The key to good performance is the formation of a segmentation-based cost function and the use of a powerful traceable classifier to predict affinity graphs. After training, our segmentation algorithm is fast. Unlike classic graph-based segmentation algorithms, where the partitioning phase dominates, our partitioning algorithm is simple and can partition diagrams linearly proportional to the number of edges in the graph. We also do not require prior knowledge of the number of image segments or image segment sizes to determine at test times, unlike other graph partitioning algorithms [7, Minimum Formalities] which are used on our trees to determine ularchal, ultraskin, maximum algorithms."}, {"heading": "Acknowledgements", "text": "SCT and HSS were supported in part by the Howard Hughes Medical Institute and the Gatsby Charitable Foundation."}], "references": [{"title": "Boundary extraction in natural images using ultrametric contour maps", "author": ["P. Arbelaez"], "venue": "Proc. POCV,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning spectral clustering, with application to speech separation", "author": ["F. Bach", "M. Jordan"], "venue": "The Journal of Machine Learning Research, 7:1963\u20132001,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Fast approximate energy minimization via graph cuts", "author": ["Y. Boykov", "O. Veksler", "R. Zabih"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 23(11):1222\u20131239,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "Towards neural circuit reconstruction with volume electron microscopy techniques", "author": ["K.L. Briggman", "W. Denk"], "venue": "Curr Opin Neurobiol, 16(5):562\u201370,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2006}, {"title": "Serial block-face scanning electron microscopy to reconstruct three-dimensional tissue nanostructure", "author": ["W. Denk", "H. Horstmann"], "venue": "PLoS Biol, 2(11):e329,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2004}, {"title": "Supervised learning of edges and object boundaries", "author": ["P. Doll\u00e1r", "Z. Tu", "S. Belongie"], "venue": "CVPR, June", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Efficient Graph-Based Image Segmentation", "author": ["P. Felzenszwalb", "D. Huttenlocher"], "venue": "International Journal of Computer Vision, 59(2):167\u2013181,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Clustering with the connectivity kernel", "author": ["B. Fischer", "V. Roth", "J. Buhmann"], "venue": "Advances in Neural Information Processing Systems 16: Proceedings of the 2003 Conference. Bradford Book,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning affinity functions for image segmentation: combining patch-based and gradient-based approaches", "author": ["C. Fowlkes", "D. Martin", "J. Malik"], "venue": "Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on, 2,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "Multiscale conditional random fields for image labeling", "author": ["X. He", "R. Zemel", "M. Carreira-Perpinan"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition, volume 2. IEEE Computer Society; 1999,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2004}, {"title": "Supervised learning of image restoration with convolutional networks", "author": ["V. Jain", "J. Murray", "F. Roth", "S. Turaga", "V. Zhigulin", "K. Briggman", "M. Helmstaedter", "W. Denk", "H. Seung"], "venue": "ICCV 2007,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Discriminative random fields: a discriminative framework for contextual interaction in classification", "author": ["S. Kumar", "M. Hebert"], "venue": "Computer Vision, 2003. Proceedings. Ninth IEEE International Conference on, pages 1150\u20131157,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Efficient backprop", "author": ["Y. LeCun", "L. Bottou", "G. Orr", "K. M\u00fcller"], "venue": "Lecture notes in computer science, pages 9\u201350,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1998}, {"title": "Using contours to detect and localize junctions in natural images", "author": ["M. Maire", "P. Arbelaez", "C. Fowlkes", "J. Malik"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition, 2008. CVPR 2008, pages 1\u20138,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2008}, {"title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics", "author": ["D. Martin", "C. Fowlkes", "D. Tal", "J. Malik"], "venue": "Proc. Eighth Int\u2019l Conf. Computer Vision, volume 2, pages 416\u2013423,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2001}, {"title": "Learning to detect natural image boundaries using local brightness, color, and texture cues", "author": ["D.R. Martin", "C.C. Fowlkes", "J. Malik"], "venue": "IEEE Trans Pattern Anal Mach Intell, 26(5):530\u2013549, May", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Learning segmentation by random walks", "author": ["M. Meila", "J. Shi"], "venue": "ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS, pages 873\u2013879,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2001}, {"title": "Objective criteria for the evaluation of clustering methods", "author": ["W. Rand"], "venue": "Journal of the American Statistical association, pages 846\u2013850,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1971}, {"title": "Reading the Book of Memory: Sparse Sampling versus Dense Mapping of Connectomes", "author": ["H. Seung"], "venue": "Neuron, 62(1):17\u201329,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Normalized cuts and image segmentation", "author": ["J. Shi", "J. Malik"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(8):888\u2013905,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2000}, {"title": "Circuit reconstruction tools today", "author": ["S.J. Smith"], "venue": "Curr Opin Neurobiol, 17(5):601\u2013608, Oct", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Image parsing: Unifying segmentation, detection, and recognition", "author": ["Z. Tu", "X. Chen", "A. Yuille", "S. Zhu"], "venue": "International Journal of Computer Vision, 63(2):113\u2013140,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2005}, {"title": "Toward objective evaluation of image segmentation algorithms", "author": ["R. Unnikrishnan", "C. Pantofaru", "M. Hebert"], "venue": "IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTEL- LIGENCE, pages 929\u2013944,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 14, "context": "Supervised learning has emerged as a serious contender in the field of image segmentation, ever since the creation of training sets of images with \u201cground truth\u201d segmentations provided by humans, such as the Berkeley Segmentation Dataset [15].", "startOffset": 238, "endOffset": 242}, {"referenceID": 17, "context": "Our objective function is the Rand index [18], which has recently been proposed as a quantitative measure of segmentation performance [23].", "startOffset": 41, "endOffset": 45}, {"referenceID": 22, "context": "Our objective function is the Rand index [18], which has recently been proposed as a quantitative measure of segmentation performance [23].", "startOffset": 134, "endOffset": 138}, {"referenceID": 8, "context": "Affinity classifiers were previously trained to minimize the number of misclassified affinity edges [9, 16].", "startOffset": 100, "endOffset": 107}, {"referenceID": 15, "context": "Affinity classifiers were previously trained to minimize the number of misclassified affinity edges [9, 16].", "startOffset": 100, "endOffset": 107}, {"referenceID": 16, "context": "There have been attempts to train affinity classifiers to produce good segmentations when partitioned by normalized cuts [17, 2].", "startOffset": 121, "endOffset": 128}, {"referenceID": 1, "context": "There have been attempts to train affinity classifiers to produce good segmentations when partitioned by normalized cuts [17, 2].", "startOffset": 121, "endOffset": 128}, {"referenceID": 1, "context": "The work of Bach and Jordan [2] is the closest to our work.", "startOffset": 28, "endOffset": 31}, {"referenceID": 15, "context": "In other related work, classifiers have been trained to optimize performance at detecting image pixels that belong to object boundaries [16, 6, 14].", "startOffset": 136, "endOffset": 147}, {"referenceID": 5, "context": "In other related work, classifiers have been trained to optimize performance at detecting image pixels that belong to object boundaries [16, 6, 14].", "startOffset": 136, "endOffset": 147}, {"referenceID": 13, "context": "In other related work, classifiers have been trained to optimize performance at detecting image pixels that belong to object boundaries [16, 6, 14].", "startOffset": 136, "endOffset": 147}, {"referenceID": 9, "context": "There are also methods for supervised learning of image labeling using Markov or conditional random fields [10].", "startOffset": 107, "endOffset": 111}, {"referenceID": 11, "context": "In the cases where probabilistic random field models have been used for image parsing and segmentation, the models have either been simplistic for tractability reasons [12] or have been trained piecemeal.", "startOffset": 168, "endOffset": 172}, {"referenceID": 21, "context": "[22] separately train low-level discriminative modules based on a boosting classifier, and train high-level modules of their algorithm to model the joint distribution of the image and the labeling.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "More sophisticated algorithms, such as spectral clustering [20] or graph cuts [3], might be more robust to misclassifications of one or a few edges of the affinity graph.", "startOffset": 59, "endOffset": 63}, {"referenceID": 2, "context": "More sophisticated algorithms, such as spectral clustering [20] or graph cuts [3], might be more robust to misclassifications of one or a few edges of the affinity graph.", "startOffset": 78, "endOffset": 81}, {"referenceID": 16, "context": "So far learning based on more sophisticated graph partitioning methods has fallen short of this goal [17, 2].", "startOffset": 101, "endOffset": 108}, {"referenceID": 1, "context": "So far learning based on more sophisticated graph partitioning methods has fallen short of this goal [17, 2].", "startOffset": 101, "endOffset": 108}, {"referenceID": 17, "context": "Long ago, Rand proposed an index of similarity between two clusterings [18].", "startOffset": 71, "endOffset": 75}, {"referenceID": 22, "context": "Recently it has been proposed that the Rand index be applied to image segmentations [23].", "startOffset": 84, "endOffset": 88}, {"referenceID": 7, "context": "Maximin affinities can be computed efficiently using minimum spanning tree algorithms [8].", "startOffset": 86, "endOffset": 89}, {"referenceID": 8, "context": "where the sum is over all nearest neighbor pixel pairs \u3008i, j\u3009 and c is the number of nearest neighbors [9].", "startOffset": 103, "endOffset": 106}, {"referenceID": 12, "context": "learning is often more efficient than batch learning [13].", "startOffset": 53, "endOffset": 57}, {"referenceID": 8, "context": "For comparison, we also show the standard affinity learning [9].", "startOffset": 60, "endOffset": 63}, {"referenceID": 18, "context": "By 3d imaging of brain tissue at sufficiently high resolution, as well as identifying synapses and tracing all axons and dendrites in these images, it is possible in principle to reconstruct connectomes, complete \u201cwiring diagrams\u201d for a brain or piece of brain [19, 4, 21].", "startOffset": 261, "endOffset": 272}, {"referenceID": 3, "context": "By 3d imaging of brain tissue at sufficiently high resolution, as well as identifying synapses and tracing all axons and dendrites in these images, it is possible in principle to reconstruct connectomes, complete \u201cwiring diagrams\u201d for a brain or piece of brain [19, 4, 21].", "startOffset": 261, "endOffset": 272}, {"referenceID": 20, "context": "By 3d imaging of brain tissue at sufficiently high resolution, as well as identifying synapses and tracing all axons and dendrites in these images, it is possible in principle to reconstruct connectomes, complete \u201cwiring diagrams\u201d for a brain or piece of brain [19, 4, 21].", "startOffset": 261, "endOffset": 272}, {"referenceID": 18, "context": "Axons can be narrower than 100 nm in diameter, necessitating the use of electron microscopy (EM) [19].", "startOffset": 97, "endOffset": 101}, {"referenceID": 18, "context": "Recent advances in automation are making it possible to collect such images [19, 4, 21], but image analysis remains a challenge.", "startOffset": 76, "endOffset": 87}, {"referenceID": 3, "context": "Recent advances in automation are making it possible to collect such images [19, 4, 21], but image analysis remains a challenge.", "startOffset": 76, "endOffset": 87}, {"referenceID": 20, "context": "Recent advances in automation are making it possible to collect such images [19, 4, 21], but image analysis remains a challenge.", "startOffset": 76, "endOffset": 87}, {"referenceID": 4, "context": "The images used for this study were from the inner plexiform layer of the rabbit retina, and were taken using Serial Block-Face Scanning Electron Microscopy [5].", "startOffset": 157, "endOffset": 160}, {"referenceID": 10, "context": "Convolutional networks have previously been shown to be effective for similar EM images of brain tissue [11].", "startOffset": 104, "endOffset": 108}, {"referenceID": 6, "context": "We also do not require any prior knowledge of the number of image segments or image segment sizes at test time, in contrast to other graph partitioning algorithms [7, 20].", "startOffset": 163, "endOffset": 170}, {"referenceID": 19, "context": "We also do not require any prior knowledge of the number of image segments or image segment sizes at test time, in contrast to other graph partitioning algorithms [7, 20].", "startOffset": 163, "endOffset": 170}, {"referenceID": 6, "context": "Felzenszwalb and Huttenlocher [7] describe a graph partitioning algorithm based on a minimum spanning tree computation which resembles our segmentation algorithm, in part.", "startOffset": 30, "endOffset": 33}, {"referenceID": 0, "context": "The Ultrametric Contour Map algorithm [1] generates hierarchical segmentations nearly identical those generated by varying the threshold of our graph partitioning algorithm.", "startOffset": 38, "endOffset": 41}], "year": 2009, "abstractText": "Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation. Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates. However, this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph. We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure. The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation. By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph, we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning. Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs, which are predictive of the pixel-pair connectivity.", "creator": "LaTeX with hyperref package"}}}