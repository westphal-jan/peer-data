{"id": "1006.2588", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2010", "title": "Agnostic Active Learning Without Constraints", "abstract": "We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classification.", "histories": [["v1", "Mon, 14 Jun 2010 02:03:12 GMT  (31kb)", "http://arxiv.org/abs/1006.2588v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alina beygelzimer", "daniel j hsu", "john langford", "tong zhang 0001"], "accepted": true, "id": "1006.2588"}, "pdf": {"name": "1006.2588.pdf", "metadata": {"source": "CRF", "title": "Agnostic Active Learning Without Constraints", "authors": ["Alina Beygelzimer", "Daniel Hsu", "John Langford", "Tong Zhang"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 100 6.25 88v1 [cs.LG] 1 4Ju n20 10"}, {"heading": "1 Introduction", "text": "In fact, it is not so that it is a pure experiment, but rather an attempt to behave in the way, as it is customary in the real world. (...) In the real world, it is so that people in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real world, in the real"}, {"heading": "1.1 Related Work", "text": "As already mentioned, our work is closely linked to the previous work of [DHM07] and [TPMS], both of which draw on the work of [CAL94] and [TPMS]."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Learning Model", "text": "Let D be a distribution over X \u00b7 Y, where X is the input space and Y = {\u00b1 1} is the label. Let (X, Y) the label X \u00b7 Y be a pair of random variables with a common distribution D. An active learner receives a sequence (X1, Y1), (X2, Y2),.. of i.i.d. copies of (X, Y), with the label Yi hidden, unless it is explicitly queried. Let's use the abbreviation a1: k to denote a sequence (a1, a2,..., ak) (so k = 0 corresponds to the empty sequence). Let H be a series of hypotheses ranging from X to Y. For simplicity, let's assume that H is finite, but not entirely agree with any single x-X label over an x-X, h label as h label."}, {"heading": "2.2 Importance Weighted Active Learning", "text": "As part of the important, weighted active learning (IWAL) of [BDL09], an active learner looks at the unlabeled data X1, X2,.. individually. After each new Xi point, the learner determines a probability Pi [0, 1]. Then, a coin with bias Pi is flipped over, and the Yi label is queried when and only when the coin appears. The query probability Pi can be queried from all previous unlabeled examples X1: i \u2212 1, any previously queried labeling, any coin change in the past, and the current unlabeled Xi.Formally, an IWAL algorithm specifies a rejection threshold p: (X \u2212 Y \u00d7 X \u00d7 0, 1})."}, {"heading": "2.3 Importance Weighted Estimators", "text": "For a function f: X \u00b7 Y \u2192 R, we define the weighted estimator of the importance of E [f (X, Y)] from Z1: n (X \u00b7 Y \u00b7 {0, 1}) n to bef (Z1: n): = 1nn \u2211 i = 1Qi Pi \u00b7 f (Xi, Yi).Note that this quantity only depends on a denomination Yi if it is queried (i.e. only if Qi = 1; it also depends only on Xi if Qi = 1).Our refusal threshold is based on a specialization of this estimator, in particular on the weighted empirical error number of a hypothesis herr (h, Z1: n): = 1nn weighted i = 1Qi Pi \u00b7 1 [h (Xi) 6 = Yi =.In the notation of the algorithm 1, this is equivalent to err (h, Sn): = 1n empii (Yi > Pi \u00b7 Pi \u00b7 1 = 1 \u00b7 Pi)."}, {"heading": "3 A Deviation Bound for Importance Weighted Estimators", "text": "As already mentioned, the rejection threshold used by our algorithm is based on weighted error estimates (Wi, Z1: n). Although these estimates are unbiased, they are only reliable if the variance is not too large. To get a handle on this, we need a deviation that is intended for weighted estimators. This is complicated by two factors that exclude simple applications of some standard boundaries: 1. The weighted samples (Xi, Yi, 1 / Pi) (or equivalent, the deviation from importance (Xi, Yi, Qi) are not i.d. This is because the query probability Pi (and thus the importance of 1 / Pi) is generally bound by Z1 \u2212 1 and Xi.2. The effective range and variance of each term in the estimator are themselves random variables.To solve these problems, we develop a deviation that is bound by a martinal technique of [Zha05]."}, {"heading": "4 Algorithm", "text": "First, we give a deviation for the meaning weighted errors of the hypotheses in a finite hypothesis class H (1), applicable to all n \u2265 1. It is a simple sequence of theorem 1 and connection boundaries; the shape of the boundary motivates certain algorithmic decisions, which are described below. Tagma 1. Select any procedure (0, 1). For all n n n n n n n n n n n n n + n log2 n) n (n + 1) | H | / \u03b4) n (log (n | H | / \u03b4) n) n). (3) Leave (Z1, Z2,..) The sequence of random variables specified in Section 2.2 is using a reject threshold p: (X \u00d7 Y \u00b7 {0, 1})."}, {"heading": "5 Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Correctness", "text": "We first demonstrate a consistency guarantee for algorithm 1, which limits the generalization error of the meaning-weighted empirical error minimizer. In fact, the proof sets a lower limit for the query probabilities Pi \u2265 1 / 2 for Xi, so that hn (Xi) 6 = h * (Xi) provides an intuitive characterization of the weight landscape induced by the weights 1 / pi. Theorem 2. The following applies with probability of at least 1 \u2212 \u03b4. For all n \u2265 1.0 \u2264 err (hn) \u2212 err (h *) \u2264 err (hn, Z1: n \u2212 1) \u2212 err (h *) \u2212 err (h, Z1: n \u2212 1) + \u221a 2C0 lognn \u2212 1. This implies that for all n \u2265 1.0 \u2264 err (hn) \u2212 err (h *) \u2264 err (h *) \u2264 err (h *) \u2012 err (h *) \u2012 err (h) \u2212 1) \u2212 lognn \u2212 1 + 2C0 logn \u2212 1. This implies that for all n \u2265 1.0 err (h) \u2212 err (h) conditions \u2264 err (h *) \u2264 err (h) \u2212 err (h) \u2212 1) \u2212 err (h) \u2212 r (h) \u2212 r (h) \u2212 r (h) \u2212 lognn \u2212 1."}, {"heading": "5.2 Label Complexity Analysis", "text": "The key to proof is to set empirical error differences and their deviations in relation to the probability of a label query, which is mediated by the coefficient of inconsistency, a quantity first used by [Han07] to analyze the complexity of the label algorithm A2 of [BBL06], the coefficient of inconsistency is defined by the coefficient of inconsistency (h, H, D), a quantity first used by [Han07] to analyze the complexity of the label algorithm A2 of [BBL06], and the coefficient of inconsistency is defined by the coefficient of inconsistency (h, H, D)."}, {"heading": "5.3 Analysis under Low Noise Conditions", "text": "Some recent work on active learning has focused on improved labeling complexity under certain noise conditions [CN06, BBZ07, CN07, Han09, Kol09]. Specifically, it is assumed that constants \u0394 > 0 and 0 < \u03b1 \u2264 1 exist, so that Pr (h (X) 6 = h \u0445 (X) \u2264 (err (h) \u2212 err (h)) \u03b1 (5) for all h-H. This is related to Tsybakov's low noise state [Tsy04]. Essentially, this condition requires that low-risk hypotheses are not too far from the optimal hypothesis when done under the discrepancy metric Pr (h) 6 = h (X). Under this condition, Lemma 3 can be improved, which in turn produces the following theorems. Theorem 4 assumes that for a certain value of laboratory 1 and 0 < vice versa, the condition < all of H-equality applies."}, {"heading": "6 Experiments", "text": "Although agnostic learning is typically intractable in the worst-case scenario, empirical risk minimization can serve as a useful abstraction for many practical monitored learning algorithms in non-worst-case scenarios. In this sense, we conducted a preliminary experimental evaluation of algorithm 1, which was implemented using a popular algorithm for learning decision trees instead of the required ERM oracle. Specifically, we are using Weka v3.6.2 \"s J48 algorithm (with standard parameters) to select the hypothesis hk in each round k; to create the\" alternative \"hypothesis h \u2032 k, we are merely modifying the decision tree hk by changing the designation of the node used to predict on xk. Both methods are clearly heuristic, but they are similar in spirit to the required optimizations. We have set C0 = 8 and c1 = c2 = 1 - these can be considered as tuning parameters C0, with aggressiveness controlled."}, {"heading": "6.1 Data Sets", "text": "We constructed two binary classification tasks using MNIST and KDDCUP99 datasets. For MNIST, we randomly selected 4000 training sessions 3s and 5s for training (using the 3s as a positive class) and used all of the tests 3s and 5s from 1902 for the test. For KDDCUP99, we randomly selected 5000 examples for training and another 5000 for testing. In both cases, we reduced the dimension of the data to 25 using PCA. To demonstrate the versatility of our algorithm, we also conducted a multi-level classification experiment, using the entire MNIST dataset (all ten digits, i.e. 60000 training dates and 10000 test dates), which required changing the selection of h'k: We forced h'k (xk) 6 = hk (xk) by reducing the prediction node designation for xk to the next best designation. We used A to reduce the dimension to 40."}, {"heading": "6.2 Results", "text": "We investigated the test error as a function of (i) the number of unmarked data seen, and (ii) the number of labels requested. We compared the performance of the active learner described above with that of a passive learner (who queries each label so that (i) and (ii) are the same) using J48 using standard parameters. In all three cases, the test error was roughly the same for both active and passive learners depending on the number of unmarked data. This is consistent with the consistency guarantee in Theorem 2. We note that this is a fundamental property that is not fulfilled by many active learning algorithms (this problem is discussed further in [DH08]). In terms of the test error as a function of the labels requested (Figure 2), the active learner had minimal improvements over the passive learner on the binary MNIST task, but a significant improvement over the passive learner on the DIST task."}, {"heading": "7 Conclusion", "text": "This paper represents a new active learning algorithm based on error minimization oracles, a departure from the version space approach of previous work. The algorithm presented here motivates mathematically comprehensible and effective methods of active learning with many classification training algorithms. The general algorithmic template applies to any training algorithm that (i) works through approximate error minimization and (ii) where the cost of changing a class prediction (measured from sample errors) can be estimated. Furthermore, we believe that while these properties are approximate or heuristically valid, the active learning algorithm created is \"safe\" in the sense that it ultimately approaches the same solution as a passively monitored learning algorithm. Consequently, we believe that this approach can be widely applied to reduce the cost of labeling in situations where labeling is expendable."}, {"heading": "A Proof of Deviation Bound for Importance Weighted Estimators", "text": "The techniques here are mostly developed in [Zha05]; for completeness we have elaborated on the findings for our respective application. (Z1: i), E [exp (n: i), e [exp (n: i), i = 1lnEi (n: i), i = 1lnEi (n: i), i (n: i), i = 1lnEi (n: i), Pr (n: i) \u2212 \u2212 \u2212 i]))), i = 1.Proof. A simple induction on n.Lemma 5. for all t: 0, \u03bb R, n: 1, and functionals [n: i), i (n: i), i (Z1: i), Pr (n: i), i \u2212 n: i = 1lnEi [exp (n: i),."}, {"heading": "B Remaining Proofs", "text": "In this section we use the notation \u03b5k: = C0 log (k + 1) / k.B.1 Proof of Lemma 2By Induction on n. Trivial for n = 1 (since p (empty sequence, x) = 1 for all x-X), i.e. fix any n-q 2 and take as the inductive hypothesis pn \u2212 1 = p (z1: n \u2212 2, x) \u2265 1 / (n \u2212 1) n \u2212 1 for all (z1: n \u2212 2, x). (X \u00b7 Y \u00b7 {0, 1}) n \u2212 2 \u00b7 n \u2212 2 for all (z1: 0, 1} n \u2212 \u2212 \u2212 1 for all (z1: n \u2212 2, x)."}], "references": [{"title": "The nonstochastic multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "SIAM Journal of Computing,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Active learning for misspecified generalized linear models", "author": ["F. Bach"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Bach.,? \\Q2006\\E", "shortCiteRegEx": "Bach.", "year": 2006}, {"title": "Agnostic active learning", "author": ["M.-F. Balcan", "A. Beygelzimer", "J. Langford"], "venue": "In Twenty-Third International Conference on Machine Learning,", "citeRegEx": "Balcan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2006}, {"title": "Margin based active learning", "author": ["M.-F. Balcan", "A. Broder", "T. Zhang"], "venue": "In Twentieth Annual Conference on Learning Theory,", "citeRegEx": "Balcan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2007}, {"title": "Importance weighted active learning", "author": ["A. Beygelzimer", "S. Dasgupta", "J. Langford"], "venue": "In Twenty-Sixth International Conference on Machine Learning,", "citeRegEx": "Beygelzimer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2009}, {"title": "Improving generalization with active learning", "author": ["D. Cohn", "L. Atlas", "R. Ladner"], "venue": "Machine Learning,", "citeRegEx": "Cohn et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 1994}, {"title": "Upper and lower bounds for active learning", "author": ["R. Castro", "R. Nowak"], "venue": "In Allerton Conference on Communication, Control and Computing,", "citeRegEx": "Castro and Nowak.,? \\Q2006\\E", "shortCiteRegEx": "Castro and Nowak.", "year": 2006}, {"title": "Minimax bounds for active learning", "author": ["R. Castro", "R. Nowak"], "venue": "In Twentieth Annual Conference on Learning Theory,", "citeRegEx": "Castro and Nowak.,? \\Q2007\\E", "shortCiteRegEx": "Castro and Nowak.", "year": 2007}, {"title": "Coarse sample complexity bounds for active learning", "author": ["S. Dasgupta"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Dasgupta.,? \\Q2005\\E", "shortCiteRegEx": "Dasgupta.", "year": 2005}, {"title": "Hierarchical sampling for active learning", "author": ["S. Dasgupta", "D. Hsu"], "venue": "In Twenty-Fifth International Conference on Machine Learning,", "citeRegEx": "Dasgupta and Hsu.,? \\Q2008\\E", "shortCiteRegEx": "Dasgupta and Hsu.", "year": 2008}, {"title": "A general agnostic active learning algorithm", "author": ["S. Dasgupta", "D. Hsu", "C. Monteleoni"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Dasgupta et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2007}, {"title": "Active learning for smooth problems", "author": ["E. Friedman"], "venue": "In Twenty-Second Annual Conference on Learning Theory,", "citeRegEx": "Friedman.,? \\Q2009\\E", "shortCiteRegEx": "Friedman.", "year": 2009}, {"title": "A bound on the label complexity of agnostic active learning", "author": ["S. Hanneke"], "venue": "In Twenty-Fourth International Conference on Machine Learning,", "citeRegEx": "Hanneke.,? \\Q2007\\E", "shortCiteRegEx": "Hanneke.", "year": 2007}, {"title": "Adaptive rates of convergence in active learning", "author": ["S. Hanneke"], "venue": "In Twenty-Second Annual Conference on Learning Theory,", "citeRegEx": "Hanneke.,? \\Q2009\\E", "shortCiteRegEx": "Hanneke.", "year": 2009}, {"title": "Active learning in the non-realizable case", "author": ["M. K\u00e4\u00e4ri\u00e4inen"], "venue": "In Seventeenth International Conference on Algorithmic Learning Theory,", "citeRegEx": "K\u00e4\u00e4ri\u00e4inen.,? \\Q2006\\E", "shortCiteRegEx": "K\u00e4\u00e4ri\u00e4inen.", "year": 2006}, {"title": "Rademacher complexities and bounding the excess risk in active learning", "author": ["V. Koltchinskii"], "venue": null, "citeRegEx": "Koltchinskii.,? \\Q2009\\E", "shortCiteRegEx": "Koltchinskii.", "year": 2009}, {"title": "Reinforcement Learning: An Introduction", "author": ["R. .S. Sutton", "A.G. Barto"], "venue": null, "citeRegEx": "Sutton and Barto.,? \\Q1998\\E", "shortCiteRegEx": "Sutton and Barto.", "year": 1998}, {"title": "Covariate shift adaptation by importance weighted cross validation", "author": ["M. Sugiyama", "M. Krauledat", "K.-R. M\u00fcller"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Sugiyama et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sugiyama et al\\.", "year": 2007}, {"title": "Active learning for misspecified models", "author": ["M. Sugiyama"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Sugiyama.,? \\Q2005\\E", "shortCiteRegEx": "Sugiyama.", "year": 2005}, {"title": "Optimal aggregation of classifiers in statistical learning", "author": ["A.B. Tsybakov"], "venue": "Annals of Statistics,", "citeRegEx": "Tsybakov.,? \\Q2004\\E", "shortCiteRegEx": "Tsybakov.", "year": 2004}, {"title": "Sufficient conditions for agnostic active learnable", "author": ["L. Wang"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Wang.,? \\Q2009\\E", "shortCiteRegEx": "Wang.", "year": 2009}, {"title": "Data dependent concentration bounds for sequential prediction algorithms", "author": ["T. Zhang"], "venue": "In Eighteenth Annual Conference on Learning Theory,", "citeRegEx": "Zhang.,? \\Q2005\\E", "shortCiteRegEx": "Zhang.", "year": 2005}], "referenceMentions": [], "year": 2010, "abstractText": "We present and analyze an agnostic active learning algorithm that works without keeping a version space. This is unlike all previous approaches where a restricted set of candidate hypotheses is maintained throughout learning, and only hypotheses from this set are ever returned. By avoiding this version space approach, our algorithm sheds the computational burden and brittleness associated with maintaining version spaces, yet still allows for substantial improvements over supervised learning for classification.", "creator": "LaTeX with hyperref package"}}}