{"id": "1009.2009", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Sep-2010", "title": "Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data", "abstract": "Inspired by the hierarchical hidden Markov models (HHMM), we present the hierarchical semi-Markov conditional random field (HSCRF), a generalisation of embedded undirectedMarkov chains tomodel complex hierarchical, nestedMarkov processes. It is parameterised in a discriminative framework and has polynomial time algorithms for learning and inference. Importantly, we consider partiallysupervised learning and propose algorithms for generalised partially-supervised learning and constrained inference. We demonstrate the HSCRF in two applications: (i) recognising human activities of daily living (ADLs) from indoor surveillance cameras, and (ii) noun-phrase chunking. We show that the HSCRF is capable of learning rich hierarchical models with reasonable accuracy in both fully and partially observed data cases.", "histories": [["v1", "Fri, 10 Sep 2010 13:25:05 GMT  (97kb)", "http://arxiv.org/abs/1009.2009v1", "56 pages, short version presented at NIPS'08"]], "COMMENTS": "56 pages, short version presented at NIPS'08", "reviews": [], "SUBJECTS": "stat.ML cs.AI", "authors": ["tran the truyen", "dinh q phung", "hung hai bui", "svetha venkatesh"], "accepted": true, "id": "1009.2009"}, "pdf": {"name": "1009.2009.pdf", "metadata": {"source": "CRF", "title": "Hierarchical Semi-Markov Conditional Random Fields for Recursive Sequential Data", "authors": ["Tran The Truyen", "Dinh Q. Phung", "Svetha Venkatesh"], "emails": ["thetruyen.tran@postgrad.curtin.edu.au", "D.Phung@curtin.edu.au", "S.Venkatesh@curtin.edu.au", "bui@ai.sri.com"], "sections": [{"heading": null, "text": "ar Xiv: 100 9,20 09v1 [Inspired by the Hierarchical Hidden Markov Models (HHMM), we present the Hierarchical Semi-Markov Conditional Random Field (HSCRF), a generalization of embedded undirected Markov chains for modeling complex hierarchical, nested Markov processes. It is parameterized within a discriminatory framework and has polynomial time algorithms for learning and inference. Importantly, we look at Partial Monitored Learning and propose algorithms for generalized Partial Monitored Learning and Restricted Consequences. We demonstrate the HSCRF in two applications: (i) the recognition of human activities of daily life (ADLs) from surveillance cameras and (ii) the chunking of noun phrases. We show that the HSCRF is capable of learning rich hierarchical models with appropriate accuracy in both fully and partially observed data.Content"}, {"heading": "1 Introduction 3", "text": "* Hung Bui is supported by the Defense Advanced Research Projects Agency (DARPA) under contract number FA8750-07-D-0185 / 0004. Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA or the Air Force Research Laboratory (AFRL)."}, {"heading": "2 Related Work 5", "text": "2.1 Hierarchical modeling of stochastic processes.......... 5 2.2 Hidden Markov Hierarchical Models............................. 6 2.3 Conditional Random Fields.............................................................................................................."}, {"heading": "3 Model Definition of HSCRF 9", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4 Asymmetric Inside-Outside Algorithm 13", "text": "4.1 Building blocks and conditional independence............... 134.1.1 Contextual Markov ceilings................. 13 4.1.2 Conditional independence....................... 14 4.1.3 Symmetrical masses inside / outside............... 15 4.1.4 Asymmetrical masses inside / outside......................... 174.2 Computer masses inside...................................."}, {"heading": "5 The Generalised Viterbi Algorithm 23", "text": "5.1 Calculation of maximum common potential, maximum states and time indices..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "6 Parameter Estimation 26", "text": "6.1 Log Linear Parameterization......................... 27 6.2 ESS for State Persistence Functions................... 27 6.3 ESS for Transition Functions................................................................. 29 6.5 ESS for Ending Functions........................."}, {"heading": "7 Partially Observed Data in Learning and Inference 31", "text": "7.1 Restricted AIO Algorithm.................. 32 7.2 Restricted Viterbi Algorithm.................... 33 7.3 Complexity Analysis..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "8 Numerical Scaling 34", "text": "8.1 Scaling of symmetrical / asymmetrical inner masses........ 35 8.2 Scaling of symmetrical / asymmetrical outer masses........ 36"}, {"heading": "9 Applications 36", "text": "9.1 Detection of indoor activities.................. 36 POS tagging and noun chunking......... 3710 Conclusions 39"}, {"heading": "A Proofs 42", "text": "A.1 Proof of propositions 1 and 2.......................... 42 A.2 Proof of proposition 3.................."}, {"heading": "B Computing the State Marginals of HSCRF 44", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C Semi-Markov CRFs as Special Case of HSCRFs 45", "text": ".........................................................................................................................."}, {"heading": "1 Introduction", "text": "In this context, it is important that the individual countries do not outdo each other, but that they outdo each other. In this sense, it is important that the individual countries do not outdo each other, but that they outdo each other and outdo each other. In this sense, it is necessary that the individual countries outdo each other. In this sense, it is necessary that the individual countries outdo each other. In this sense, it is necessary that the individual countries outdo each other. In this sense, it is also necessary that the individual countries outdo each other. In this sense, it is necessary that the individual countries outdo themselves. In this sense, it is also necessary that the individual countries outdo each other."}, {"heading": "2 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Hierarchical Modelling of Stochastic Processes", "text": "Hierarchical modeling of stochastic processes can largely be categorized as either graphic models that extend the flat hidden Markov models (HMM) (e.g. stratified HMM (Oliver et al., 2004), abstract HMM (Bui et al., 2002), hierarchical HMM (Fine et al., 1998; Bui et al., 2004), abstract HMM (Bui et al., 2002) or gram-based models (e.g. PCFG (Pereira et al., 1992)), all generative. Recent developments in discriminatory hierarchical structures include the expansion of flat CRFs (e.g. dynamic CRFs (Sutton et al., 2007), hierarchical CRFs (Liao et al., 2007; Kumar and Hebert, 2005), and conditional learning of grammatics (e.g. Miyao and Tsujii, 2002; non-hierarchical, et al)."}, {"heading": "2.2 Hierarchical Hidden Markov Models", "text": "Hierarchical HMMs are generalizations of HMMs (Rabiner, 1989) in the way in which a state in an HHMM can be a sub-HHMM. Thus, a HHMM is a nested Markov chain. In the model of temporal evolution, when a child ends Markov chain, it returns control to its parent. Nothing of the terminated child chain is advanced. Thus, the parent state abstracts everything that belongs to it. After receiving the return control, the parent then either passes to a new parent (given that the grandparent is not yet finished), or ends. Figure 1 illustrates the state transition diagram of a two-stage HHMM model. At the top level, there are two parent states {A, B}. Parenthood A has three children, i.e. ch (A), 2, 3} and B has four, i.e. ch (B) ch (B) has four, i.e. B)."}, {"heading": "2.3 Conditional Random Fields", "text": "The graph in which V is the set of recesses, and E is the set of recesses (QR) is the set of edges (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR) (QR)"}, {"heading": "3 Model Definition of HSCRF", "text": "In fact, it is a matter of a way in which people are able to decide for themselves how they want to live. (...) In fact, it is a matter of people being able to decide for themselves what they want. (...) In fact, it is a matter of people being able to decide for themselves. (...) It is a matter of people being able to decide for themselves. (...) It is a matter of people being able to decide for themselves. (...) It is a matter of people being able to decide for themselves. (...) It is a matter of people being able to decide for themselves. (...) It is as if they are able to decide for themselves. (...) It is as if they are able to decide for themselves. (...)"}, {"heading": "4 Asymmetric Inside-Outside Algorithm", "text": "This section describes a central inference engine called the Asymmetric Inside-Outside (AIO) algorithm, which has been partly adopted from the generative, directed counterpart of HHMMs in Bui et al., 2004. We now show how to calculate the building blocks needed for most inference and learning assignments.4.1 Building Blocks and Conditional Independence"}, {"heading": "4.1.1 Contextual Markov blankets", "text": "In this subsection, we define elements that are building blocks for conclusions and learning, which are identified by the corresponding boundaries. Let us introduce two types of boundaries: the contextual symmetrical and asymmetrical Markov ceiling (definition 1. A symmetrical Markov ceiling at level d for a state s (starting with i and ending with j) is the following definition: d, si: j = (x d i: s, e d: D i \u2212 1 = 1, e d: D j = 1, e: d i \u2212 1 = 0) (10) definition 2. Let x, si: j be a symmetrical Markov ceiling, we define D, s i: j: j as sequence d, si: j = (x d + 1: D i: j \u2212 1) (definition 2. Let x: d: D i: d = mmd)."}, {"heading": "4.1.2 Conditional independence", "text": "Considering these two definitions, we have the following suggestions of conditional dependency. Proposal 1. Sentence, si: j and II: j and II: j and II: j and II: j are conditionally independent: d, si: jPr (2), s: j, s: j, s: j, si: j = Pr (2), s: j, Pr (3), s: j, s: j, s: j, d: si: j), si: j) (20), Pr (4), s: i: j, s: j: j: j (4), s: j (4), s: j: j, s: j (4), s: j c: j) (20), pr (4), s: j, s: j: j (4) c: j (4 c), c: j: c (4), j: c: c (4), j: c: c (4), j: c: c (4), j: c: c (4), j: c (4), j: c: c (4), j: c: c (4), j: c: c (4), j: c: c: c (4), j: c: c (4), j: c: c: c (4, j: c: c (4), j: c: c: c (4), j: c: c: c (4, c: c: c (4), j: c: c: c (4, c: c (4), c: c: c: c: c (4, j: c: c: c (4), j: c: c: c: c: c: c (4, j: c: c: c: c (4), j: c: c: c: c: c (4, j: c: c (4), j: c: c: c: c: c (4, j: c: c: c: c: c: c), j: c: c: c (4, j: c: c: c: c: c: c: c (4, c: c: c: c), j:"}, {"heading": "4.1.3 Symmetric Inside/Outside Masses", "text": "From Equation 12 we have: [D], [S], [S], [D], [S], [S], [S], [S], [S], [S], [S), [S), [S], [S], [S], [S], [S], S [S), S [S), S [S), S [S), S [S), S [S), S [S), S [S), S [S), S [S), S [S), S [S), S [S), S [S [S), S [S], S [S], S [S], S [S), S [S [S), S [S], S [S), S [S), S [S), S [S), S [S], S [S), S [S [S], S [S], S [S], S [S [S], S [S], S [S), S [S [S], S [S], S [S], S [S [S], S [S), S [S [S], S [S], S [S], S [S [S], S [S], S [S), S [S [S], S [S], S [S], S [S], S [S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S [S], S], S [S], S [S], S [S], S], S [S], S [S], S [S], S [S], S], S [S], S], S [S [S], S [S], S], S [S], S [S"}, {"heading": "4.1.4 Asymmetric Inside/Outside Masses", "text": "Remember that we introduced the concept of the asymmetric Markov hull, si: j (u), which separates the two masses, si: j (u) and i: j (u), into a common potential. Similarly, we group all the local contextual clique potentials associated with the masses, si: j (u) and i: j (u) into a common potential. Similarly, we group all the local potentials associated with the masses, s i: j (u) and i: j (u), si: j (u) into a common potential. Note that the asymmetric hull, si: j (u), the asymmetric inner mass, si: j (u) and the asymmetric potential Rd, si: y.Definition 6. Given the asymmetric Markov hull, si: j (u), the asymmetric inner mass, si: j (etu) and the asymmetric mass, j: the mass, and the asymmetric si (outside)."}, {"heading": "4.2 Computing Inside Masses", "text": "In this section we will show how to calculate the pair recursively: within the mass and asymmetrically within the mass. The basic idea is to exploit the decomposition within the asymmetrical Markov ceiling. As shown in Figure 11, an outer asymmetrical Markov ceiling can be split into a subasymmetrical Markov ceiling and a symmetrical ceiling."}, {"heading": "4.2.1 Computing asymmetric inside mass from inside mass", "text": "Suppose that within the asymmetric Markov definition d, si: j (u) = j (u), the child u = v = v = v (i, j) and ends at j, i.e. xd + 1t: j = u, e + 1 t: j \u2212 1 = 0 and e + 1: D \u2212 1 t = 1. Consider two cases: t > i and t = i.Case 1. For t > i, and the asymmetric definition of v = xd + 1t \u2212 1. We have two smaller definitions within the definition d, si: j (u): the symmetric definition d + 1, u t: j associated with the child u = x d + 1 t: j, and the asymmetric definition d: si (v) associated with the child v ending at t \u2212 1."}, {"heading": "4.2.2 Computing inside mass from asymmetric inside mass", "text": "Note the relationship between the asymmetrical Markov ceiling, si: j (u) and the symmetrical ceiling, si: j, where d < D. When e d = 1, i.e. the parent s ends on j, si: j (u), si: j (u), in d, s i: j with u = x d + 1 j. Then we have decomposition processes, i: j (u), u = x d + 1 j) and in c: d, s i: j (u), i: j = (i: d, s: j (u), e d j = 1, u = x d + 1 j), which lead to factoration processes, si: j (u: j), s i: j (u), E d: d, s u: j (43), where the state potential Ed, su, j, d = (e: j), and in d: c = 1)."}, {"heading": "4.3 Computing Outside Masses", "text": "In this subsection, we show how to recursively calculate the symmetrical outer mass and the asymmetrical outer mass. We use the same ceiling substitution as in Section 4.2, but this time the view is reversed because we are interested in quantities outside the ceilings. For example, outside the inner symmetrical Markov ceiling in Figure 11, there is an outer asymmetrical ceiling and another subasymmetrical ceiling on the left."}, {"heading": "4.3.1 Computing asymmetric outside mass from outside mass", "text": "Let us examine the variables as follows: D, s: j (u) associated with the asymmetric Markov context: v = v = v, si: j (u), for d [1, D \u2212 1] and 1 \u2264 i \u2264 j \u2264 T (see definition 4); for j < T, assuming that there is an outer asymmetric Markov constellation, si: t (v) for some v + S d + 1 and [j + 1, T], and a symmetric Markov constellation: d + 1, vj + 1: t to the right of d, s i: j (u). Given these constellations, we have the decomposition of d, si: j (u) = (i: t), s i: t (v), vj + 1: t to the right of d: t, x d + 1 j = u), resulting in the following factorisational contexts: d, si: (u)."}, {"heading": "4.3.2 Computing outside mass from asymmetric outside mass", "text": "5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5"}, {"heading": "5 The Generalised Viterbi Algorithm", "text": "By definition, the MAP assignment is the maximizer of the conditional distribution given by an observation sequence z\u043eMAP = argmax \u0445 Pr (\u0442 | z) = argmax \u0445 \u0445 [\u0443, z] (52). To illustrate, let us drop the notation z and assume that it is implicitly present. The process of calculating the MAP assignment is very similar to that of calculating the partition function. This similarity results essentially from the relationship between the sum product and the maximum product algorithm (a generalization of the Viterbi algorithm) of Pearl (1988) and from the fact that within / asymmetrical internal procedures described in Section 4.2 is a sum product version. We just need to convert all sums into corresponding maximizations. The algorithm is a two-step procedure: \u2022 In the first step, the maximum common potential is calculated and local maximum states and end states are stored by way."}, {"heading": "5.1 Computing the Maximum Joint Potential, Maximal States and", "text": "Time indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indicator indic"}, {"heading": "5.2 Decoding the MAP Assignment", "text": "The procedure of the traceability process is contrary to the procedure of the Max product. Specifically, we start at the root and proceed from top to bottom and from right to left. The goal is to identify the segment that is farthest to the right at each level. Formally, a segment is a triple (s, i, j), where s is the segment designation, and i and j are start and end time indices, respectively. From the maximum within \u2206 max, d, si: j at level d, we identify the best child u and its end time j from equation 59. This results in the maximum asymmetric within \u03b1max, d, si: j (u). Then we search for the best child v that passes to u under the same parent in equation 61. Since the beginning time t for u has been determined, the end time for v t \u2212 1. We now have a segment (u, t, j) at level d + 1. The procedure repeats itself until we reach the beginning time for the parent."}, {"heading": "6 Parameter Estimation", "text": "In this section, we will discuss the problem of parameter estimation by maximizing the (conditional) probability of data. Typically, for a given problem, we need a parametric form, and we need a numerical method to accomplish the optimization task. Here, we use the log-linear parameterization commonly used in the CRF setting. Let's remember from Section 2.3 that estimating parameters of log-linear models using gradient-based methods requires the calculation of attribute expectations or expected sufficient statistics (ESS). For our HSCRFs, we need to calculate four types of ESS that correspond to persistence, state transition, state initialization, and state end."}, {"heading": "6.1 Log-Linear Parameterisation", "text": "In our HSCRF setting, there is a feature vector fd\u03c3 (\u03c3, z) = u > u (71), which is associated with any kind of contextual clique, in which \u03c6 (\u03c3d, z) = percp (w'p, z). Thus, the features are only active in the context in which the corresponding contextual cliques appear. For the contextual state persistence clique, the features contain the duration of the state, the start time i and the end time j of the state. Other feature types include the time index in which the features are triggered. In particular, Rd, s, zi: j = exp (w'p persist, d'p, s persist (i, z))) (68) Ad, s, zu, v, i = exp (w'p (w'p transit, d's)."}, {"heading": "6.2 ESS for State-Persistence Features", "text": "Recall from section 6.1 that the function for the persistence of the state fd = i = i = II = II = II = II = II (I, j) is active only in the context in which the equation 72 can be rewritten. (77) The indicator function in the RHS ensures that the function fd, s\u03c3persist (i, j) is active only when there is a persistence of the Markov plane, si: j in the assignment of the II, si: i, j) the function fd (i, j) the function fd: the elements i: i, j) the function d: the equation i: i: i: i (i, j) the equation d: the equation fd: the (i, j) the function fd: the elements i: i: j (i, j) the function d: the elements i: i (i, j) the function d: we, the equation i: i: i, the equation i: i, the i: i, the equation i: i, the d: (d), the: we, the equation (d: the: we, the equation: i: i, the: i: i, the equation: i: i, the: i: i, the: i: i, the: i: i: i, the equation, the: i: i, the: i: i, the equation (d: we, the: we, the equation: i: we, the: i: i, the equation: i: i: i, the: i: i, the: i: i: i, the equation, the: i: i: i, the: i: i: i: i: i, the equation, the: i: i: i: i: i: i, the equation, the (i: i: i: i: i: i: i: i), the equation, the equation, the: i: i: i: i: i: i: i: i: i, the equation, the equation, the (i: i: i: i: i: i: i: i: i: i: i: i: i, the equation, the: i: i: i,"}, {"heading": "6.3 ESS for Transition Features", "text": "Remember that in Section 6.1 we define fd, s\u03c3transit, u, v (t) as a function (which in the context cttransit = (ed \u2212 1t = 0, e \u2212 \u2212 1) in which the child state does its work at the time t and transits to the child state vd (that is, sd \u2212 1 is still running). Therefore, we can rewrite Equation 73: asF d, s transit, u, v (n) = [1, T \u2212 1] f, s transit, u, s, s transit, u, [c transit] =. [1, T \u2212 1] f transit, s transit, u, v (t). [1, s transit]. [c transit]. [c transit]. [c transit]. [s]."}, {"heading": "6.4 ESS for Initialisation Features", "text": "Remember that in Section 6.1 we define fd, s\u03c3init, u (i) as a function at level d that is triggered when a parent s at level d initializes a child u at level d + 1. In this case, the cinit = (edi \u2212 1 = 1) context must be activated for i > 1. Therefore, we can rewrite the following property: asF d, s \u03c3init, u (i)."}, {"heading": "6.5 ESS for Ending Features", "text": "Remember that in Section 6.1 we define fd, s, u (j) = i (j) as a function that is activated when a child returns control to its parents at level d + 1 and time j. This event also allows the context cend = (edj = 1). Therefore, we can expect the following property E [fd, s, s, s, s, u (cend) [cend] [1, T] f d, s, u (j) p [cend] p, si [cend] p, si (97) Now we consider the following property expectE [fd, s, s, s, s, u (cend) [cend] [cend] fd, s, s, s, s, s, c, s, s, c, c, c, c, c, c, s, c, c, c, c, c, c, c, c, s, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c."}, {"heading": "7 Partially Observed Data in Learning and Inference", "text": "In this section, we expand the AIO to cover the cases where these assumptions do not apply. In particular, it may happen that the training data is not fully labeled, possibly due to a lack of labeling resources. In this case, the learning algorithm should be robust enough to handle missing labels. On the other hand, we can sometimes obtain high-quality labels from external sources during inference, which requires the inference algorithm to respond to this data."}, {"heading": "7.1 The Constrained AIO algorithm", "text": "In this section, we look at the general case when we have procedures for calculating blocks such as blocks such as blocks such as blocks such as blocks such as blocks such as blocks such as blocks such as blocks such as blocks such as blocks such as blocks such as blocks such as blocks or blocks such as blocks such as blocks, blocks or blocks such as blocks. Since our HSCRF is also an exponential model, it shares the same calculation required for the general blocks (equations 6 and 7). We need to calculate four quantities: the partial log partition function Z (z), the partition function and the \"free\" ESS has been calculated in sections 4 and 6 respectively. This section describes the other two quantities. Let's leave the set of visible labels as (x, e, e, e) where x, e, the visible set of state variables is and e is the visible set of indicators."}, {"heading": "7.2 The Constrained Viterbi Algorithm", "text": "Remember that in general, the Viterbi algorithm described in Section 5 is to find the most likely configuration (max. configuration MAP = argmaxample Pr.). If some variables are designated as such, it is not necessary to estimate them. Now, the task is to estimate the most likely configuration of the hidden variable h under the following names: hMAP = argmax h Pr. (h.) = argmax h Pr. (h.) = argmax h. (h.), z) (107) It turns out that the limited MAP configuration is identical to the standard MAP except that we must respect the designated variables. Since the Viterbi algorithm is only the max product version of the AIO, the limited Viterbi configuration can be modified as follows: Equerbi-i configuration: Equerbi configuration can be modified in the same way as the limited version of the AIO (Section 7.O)."}, {"heading": "7.3 Complexity Analysis", "text": "The complexity of the restricted AIO and the restricted Viterbi has an upper limit of O (T 3) if no labels are specified. It also has a lower limit of O (T) if all end indicators are known and the model is reduced to the default tree-structured graphical model. In general, the more labels are available, the less complexity there is and we can expect subcubic timing."}, {"heading": "8 Numerical Scaling", "text": "In previous sections, we have derived AIO-based inference and learning algorithms for both unrestricted and restricted models, and the quantities calculated by these algorithms, such as the inner / outer masses, often include summation of exponentially large positive potentials. The potentials, when estimated from the data, are often not directed upwards, which leads to the fact that the mass size in the sequence length T increases exponentially, exceeding the numerical capacity of most machines for moderate T. In this section, we present a scaling method to reduce this numerical overflow problem, which can be traced back to the message transmission method of the pearl (Pearl, 1988; Yedidia et al., 2005). Our AIO algorithms can be considered as a generalization of the message transmission problem, where the inner masses play the role of the inner messages. In the Pearl method, we reduce the number step by normalizing the size of the message flow, by comparing it to the idea of each flow."}, {"heading": "8.1 Scaling the Symmetric/Asymmetric Inside Masses", "text": "Before we get to the algorithmic details, let us come back to Equation 44. If we scale the asymmetric factors within the mass down, si: j (u) will be scaled down by a factor down by the same factor. Similarly, as we scaled down by the same factor from Equation 40 + 1, si: j (u) = j (u) = j (u) = j (110), the symmetric inner mass will be scaled down by the same factor. Similarly, as we scaled down from Equation 40 + 1 (u) = j (u) = j (i + 1) v) v) Sd + 1\u03b1d, si: t \u2212 1 (v)."}, {"heading": "8.2 Scaling the Symmetric/Asymmetric Outside Masses", "text": "Similarly, we can work out the set of factors from the derivation of symmetrical / asymmetrical outer masses, since these masses depend exclusively on the inner masses as building blocks. In other words, after we have completed the scaling of the inner masses, we can calculate the scaled outer masses directly, using the same set of equations described in Section 4.3. The algorithm is summarized in Figure 19. Note that the sequence of performing the loops in this case differs from that of Figure 12."}, {"heading": "9 Applications", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9.1 Recognising Indoor Activities", "text": "In fact, the fact is that most of us are able to survive on our own, in the way in which they are able, in the way in which they are able, in the way in which they are able, in the way in which they are able, in the way in which they are able, in the way in which they are able, in the way in which they are able, in the way in which they are able, in the way in which they are able to assert themselves, in the way in which they are able, in the way in which they are able to change the world."}, {"heading": "9.2 POS Tagging and Noun-Phrase Chunking", "text": "The data comes from the CoNLL 2000 collaborative task (Sang and Buchholz, 2000), in which 8926 English sentences from the Wall Street Journal corpus are used for training only and 2012 sentences for testing. However, each word in a pre-processed sentence is labeled by two labels: the part of the language (POS) and the noun-phrase (NP). There are 48 different POS labels and 3 NP labels for the beginning of a noun phrase, I-NP for within a noun phrase or O for others. Each noun phrase generally has more than one word. To reduce the computing burden, we reduce the POS tags to 5 groups: noun, verb, adjective, adverb and others. Since in our HSCRFs we do not explicitly indicate which is node."}, {"heading": "10 Conclusions", "text": "In this paper, we have presented a novel model called Hierarchical Semi-Markov Conditional Random Field, which extends the standard CRFs to integrate hierarchical and multi-level semantics. We have developed a graphical model-like dynamic representation of HSCRF, which appears similar to the DBN representation of HHMMs in (Murphy and Paskin, 2002) and in some ways resembles a dynamic factor graph (Kschischang et al., 2001). However, it is not exactly the standard graphical model, because the contextual cliques in HSCRFs are not fixed during inferencing. We have derived efficient algorithms for learning and inferencing, in particular the ability to learn and draw conclusions with partially given labels. We have shown the capacity of HSCRFs on home video surveillance data and the flat particles of English texts in which the CRFS information is inherent."}, {"heading": "A Proofs", "text": "Considering a distribution of the FormPr (x) = 1Z [x] (119), in which x = (xa, xs, xb), if there is a factoring idea [x] = [xa, xs], then xa and xb [s] are conditionally independently given xs.Proof: We want to prove that Pr (xa, xb] = [xs] [s] [xa, xs] [xs] [xs] [xs] [xa, xb] [s] [xs] [xa, xb] [s] [s] [xa, xb] [s] [s] [xa, xb] [s] [xs] [xs], xs [xs] [xs], xs [xs] [xs, xs] s [xs], s [xs] s, [xs] s, [xs] s, [xs] s, [xs] s, [xs, xs] s [xs, xs] s, s [xs, xs] s, s [xs] s, s [xs, xs] s, s [xs] s, s [xs, xs] s, s [xs, xs] s, xs, xs, xs] s [s, xs, xs] s [xs, xs] s, xs, xs, xs, xs, xs] s [s] s, xs, xs [s] s, xs, xs, xs, xs] s, xs, xs [s, xs, xs] s, xs, xs [s] s, xs, xs, xs [s] s, xs, xs, xs, xs] s, xs [s] s, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs, xs [s, xs, xs"}, {"heading": "B Computing the State Marginals of HSCRF", "text": "We are interested in calculating the margins of the state variables Pr (xdt) = I (j) = I (j) = I (j) = I (c). We have Pr (xdt) = II (xdt) = IV (xdt) = V (132) Let s = X) and assume that the state s begins at i and ends at j and at t [i, j]. For each configuration that respects this assumption, we have the factorisation of equation 24, which states that equation 24, the equation begins at T and ends at T."}, {"heading": "C Semi-Markov CRFs as Special Case of HSCRFs", "text": "In this appendix, we first describe the Semi-Markov CRF (SemiCRF) (SemiCRF) (Sarawagi and Cohen, 2004) in our HSCRF framework and show how to convert a SemiCRF to an HSCRF. Then, under the light of the HSCRF conclusion, we show how to modify the original SemiCRF context to handle (a) partial monitoring and restricted inferences, and (b) numerical scaling to avoid abundance. Changes are of interest to their own leg.C.1 SemiCRF as an interesting flat segment model that generalizes the CRF chain. In the SemiCRF framework, the Markov process operates at the segment level, where a segment is non-Markovian chain of nodes. However, a chain of segments is a Markov chain, as each segment can have potentially arbitrary lengths, inference in SemiCRFs segments is more involved than the chain of CRs."}], "references": [{"title": "Policy recognition in the abstract hidden Markov model", "author": ["H.H. Bui", "S. Venkatesh", "G. West"], "venue": "Journal of Artificial Intelligence Research, 17, 451\u2013499.", "citeRegEx": "Bui et al\\.,? 2002", "shortCiteRegEx": "Bui et al\\.", "year": 2002}, {"title": "Hierarchical hidden Markov models with general state hierarchy", "author": ["H.H. Bui", "D.Q. Phung", "S. Venkatesh"], "venue": "D. L. McGuinness and G. Ferguson, editors, Proceedings of the 19th National Conference on Artificial Intelligence (AAAI), pages 324\u2013329, San Jose, CA.", "citeRegEx": "Bui et al\\.,? 2004", "shortCiteRegEx": "Bui et al\\.", "year": 2004}, {"title": "Log-linear models for wide-coverage CCG parsing", "author": ["S. Clark", "J.R. Curran"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 97\u2013104.", "citeRegEx": "Clark and Curran,? 2003", "shortCiteRegEx": "Clark and Curran", "year": 2003}, {"title": "Discriminative training methods for hidden Markov models: Theory and experiments with the perceptron algorithm", "author": ["M. Collins"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Collins,? 2002", "shortCiteRegEx": "Collins", "year": 2002}, {"title": "The hierarchical hidden Markov model: Analysis and applications", "author": ["S. Fine", "Y. Singer", "N. Tishby"], "venue": "Machine Learning, 32(1), 41\u201362.", "citeRegEx": "Fine et al\\.,? 1998", "shortCiteRegEx": "Fine et al\\.", "year": 1998}, {"title": "Factor graphs and the sum-product algorithm", "author": ["F.R. Kschischang", "B.J. Frey", "H.A. Loeliger"], "venue": "IEEE Transactions on Information Theory, 47(2), 498\u2013519.", "citeRegEx": "Kschischang et al\\.,? 2001", "shortCiteRegEx": "Kschischang et al\\.", "year": 2001}, {"title": "A hierarchical field framework for unified contextbased classification", "author": ["S. Kumar", "M. Hebert"], "venue": "Proceedings of the IEEE International Conference on Computer Vision (ICCV), volume 2, pages 1284\u20131291.", "citeRegEx": "Kumar and Hebert,? 2005", "shortCiteRegEx": "Kumar and Hebert", "year": 2005}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F. Pereira"], "venue": "Proceedings of the International Conference on Machine learning (ICML), pages 282\u2013289.", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Graphical Models", "author": ["S. Lauritzen"], "venue": "Oxford Science Publications.", "citeRegEx": "Lauritzen,? 1996", "shortCiteRegEx": "Lauritzen", "year": 1996}, {"title": "Extracting places and activities from GPS traces using hierarchical conditional random fields", "author": ["L. Liao", "D. Fox", "H. Kautz"], "venue": "The International Journal of Robotics Research, 26(1), 119\u2013134.", "citeRegEx": "Liao et al\\.,? 2007", "shortCiteRegEx": "Liao et al\\.", "year": 2007}, {"title": "Foundations of Statistical Natural Language Processing", "author": ["C.D. Manning", "H. Sch\u00fctze"], "venue": "MIT Press.", "citeRegEx": "Manning and Sch\u00fctze,? 1999", "shortCiteRegEx": "Manning and Sch\u00fctze", "year": 1999}, {"title": "Maximum entropy estimation for feature forests", "author": ["Y. Miyao", "J. Tsujii"], "venue": "Proceedings of Human Language Technology Conference (HLT).", "citeRegEx": "Miyao and Tsujii,? 2002", "shortCiteRegEx": "Miyao and Tsujii", "year": 2002}, {"title": "Dynamic Bayesian Networks: Representation, Inference and Learning", "author": ["K. Murphy"], "venue": "Ph.D. thesis, Computer Science Division, University of California, Berkeley.", "citeRegEx": "Murphy,? 2002", "shortCiteRegEx": "Murphy", "year": 2002}, {"title": "Linear time inference in hierarchical HMMs", "author": ["K. Murphy", "M. Paskin"], "venue": "Advances in Neural Information Processing Systems (NIPS), volume 2, pages 833\u2013 840. MIT Press.", "citeRegEx": "Murphy and Paskin,? 2002", "shortCiteRegEx": "Murphy and Paskin", "year": 2002}, {"title": "Learning and detecting activities from movement trajectories using the hierarchical hidden Markov models", "author": ["N. Nguyen", "D. Phung", "S. Venkatesh", "H.H. Bui"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 2, pages 955\u2013960, San Diego, CA.", "citeRegEx": "Nguyen et al\\.,? 2005", "shortCiteRegEx": "Nguyen et al\\.", "year": 2005}, {"title": "Layered representations for learning and inferring office activity from multiple sensory channels", "author": ["N. Oliver", "A. Garg", "E. Horvitz"], "venue": "Computer Vision and Image Understanding, 96(2), 163\u2013180.", "citeRegEx": "Oliver et al\\.,? 2004", "shortCiteRegEx": "Oliver et al\\.", "year": 2004}, {"title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference", "author": ["J. Pearl"], "venue": "Morgan Kaufmann, San Francisco, CA.", "citeRegEx": "Pearl,? 1988", "shortCiteRegEx": "Pearl", "year": 1988}, {"title": "Inside-outside reestimation from partially bracketed corpora", "author": ["F. Pereira", "Y. Schabes"], "venue": "Proceedings of the Meeting of the Association for Computational Linguistics (ACL), pages 128\u2013135.", "citeRegEx": "Pereira and Schabes,? 1992", "shortCiteRegEx": "Pereira and Schabes", "year": 1992}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": "Proceedings of the IEEE, 77(2), 257\u2013286.", "citeRegEx": "Rabiner,? 1989", "shortCiteRegEx": "Rabiner", "year": 1989}, {"title": "Introduction to the CoNLL-2000 shared task: Chunking", "author": ["Sang", "E.F.T.K.", "S. Buchholz"], "venue": "Proceedings of the 2nd Workshop on Learning Language in Logic and the 4th Conference on Computational Natural Language Learning, volume 7, pages 127\u2013132, Lisbon, Portugal. http://www.cnts.ua.ac.be/conll2000/chunking/.", "citeRegEx": "Sang et al\\.,? 2000", "shortCiteRegEx": "Sang et al\\.", "year": 2000}, {"title": "Semi-Markov conditional random fields for information extraction", "author": ["S. Sarawagi", "W.W. Cohen"], "venue": "B. L. Saul LK, Weiss Y, editor, Advances in Neural Information Processing Systems 17, pages 1185\u20131192. MIT Press, Cambridge, Massachusetts.", "citeRegEx": "Sarawagi and Cohen,? 2004", "shortCiteRegEx": "Sarawagi and Cohen", "year": 2004}, {"title": "Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data", "author": ["C. Sutton", "A. McCallum", "K. Rohanimanesh"], "venue": "Journal of Machine Learning Research, 8, 693\u2013723.", "citeRegEx": "Sutton et al\\.,? 2007", "shortCiteRegEx": "Sutton et al\\.", "year": 2007}, {"title": "Discriminative probabilistic models for relational data", "author": ["B. Taskar", "A. Pieter", "D. Koller"], "venue": "Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence (UAI), pages 485\u201349. Morgan Kaufmann.", "citeRegEx": "Taskar et al\\.,? 2002", "shortCiteRegEx": "Taskar et al\\.", "year": 2002}, {"title": "Max-margin Markov networks", "author": ["B. Taskar", "C. Guestrin", "D. Koller"], "venue": "S. Thrun, L. Saul, and B. Sch\u00f6lkopf, editors, Advances in Neural Information Processing Systems 16. MIT Press, Cambridge, MA.", "citeRegEx": "Taskar et al\\.,? 2004", "shortCiteRegEx": "Taskar et al\\.", "year": 2004}, {"title": "AdaBoost.MRF: Boosted Markov random forests and application to multilevel activity recognition", "author": ["T.T. Truyen", "D.Q. Phung", "H.H. Bui", "S. Venkatesh"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Truyen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Truyen et al\\.", "year": 2006}, {"title": "Accelerated training of conditional random fields with stochastic gradient methods", "author": ["S.V.N. Vishwanathan", "N.N. Schraudolph", "M.W. Schmidt", "K.P. Murphy"], "venue": "Proceedings of the International Conference on Machine learning (ICML), pages 969\u2013976.", "citeRegEx": "Vishwanathan et al\\.,? 2006", "shortCiteRegEx": "Vishwanathan et al\\.", "year": 2006}, {"title": "Constructing free-energy approxima", "author": ["J. Yedidia", "W. Freeman", "Y. Weiss"], "venue": null, "citeRegEx": "Yedidia et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Yedidia et al\\.", "year": 2005}, {"title": "Semi-Markov CRFs as Special Case of HSCRFs In this Appendix we first describe the semi-Markov CRF (SemiCRF) (Sarawagi and Cohen, 2004) in our HSCRF framework and show how to convert a SemiCRF into an HSCRF. Then under the light of HSCRF inference we show how to modify the original Semi", "author": [], "venue": null, "citeRegEx": "1.,? \\Q2004\\E", "shortCiteRegEx": "1.", "year": 2004}], "referenceMentions": [{"referenceID": 15, "context": "see (Oliver et al., 2004)).", "startOffset": 4, "endOffset": 25}, {"referenceID": 4, "context": "A more restricted version known as hierarchical hidden Markov model (HHMM) (Fine et al., 1998) offers clearer representation in that the depth is fixed and the semantic levels are well defined.", "startOffset": 75, "endOffset": 94}, {"referenceID": 7, "context": "This line of research has recently attracted much interest, largely triggered by the introduction of the conditional random field (CRF) (Lafferty et al., 2001).", "startOffset": 136, "endOffset": 159}, {"referenceID": 8, "context": "see (Lauritzen, 1996)) which effectively encodes hierarchical and temporal semantics.", "startOffset": 4, "endOffset": 21}, {"referenceID": 1, "context": "For parameter learning, an efficient algorithm based on the Asymmetric Inside-Outside of (Bui et al., 2004) is introduced.", "startOffset": 89, "endOffset": 107}, {"referenceID": 15, "context": ", the layered HMM (Oliver et al., 2004), the abstract HMM (Bui et al.", "startOffset": 18, "endOffset": 39}, {"referenceID": 0, "context": ", 2004), the abstract HMM (Bui et al., 2002), hierarchical HMM (HHMM) (Fine et al.", "startOffset": 26, "endOffset": 44}, {"referenceID": 4, "context": ", 2002), hierarchical HMM (HHMM) (Fine et al., 1998; Bui et al., 2004), DBN (Murphy, 2002)) or grammarbased models (e.", "startOffset": 33, "endOffset": 70}, {"referenceID": 1, "context": ", 2002), hierarchical HMM (HHMM) (Fine et al., 1998; Bui et al., 2004), DBN (Murphy, 2002)) or grammarbased models (e.", "startOffset": 33, "endOffset": 70}, {"referenceID": 12, "context": ", 2004), DBN (Murphy, 2002)) or grammarbased models (e.", "startOffset": 13, "endOffset": 27}, {"referenceID": 17, "context": ", PCFG (Pereira and Schabes, 1992)).", "startOffset": 7, "endOffset": 34}, {"referenceID": 21, "context": "dynamic CRFs (DCRF) (Sutton et al., 2007), hierarchical CRFs (Liao et al.", "startOffset": 20, "endOffset": 41}, {"referenceID": 9, "context": ", 2007), hierarchical CRFs (Liao et al., 2007; Kumar and Hebert, 2005)) and conditional learning of the grammars (e.", "startOffset": 27, "endOffset": 70}, {"referenceID": 6, "context": ", 2007), hierarchical CRFs (Liao et al., 2007; Kumar and Hebert, 2005)) and conditional learning of the grammars (e.", "startOffset": 27, "endOffset": 70}, {"referenceID": 11, "context": "see (Miyao and Tsujii, 2002; Clark and Curran, 2003)).", "startOffset": 4, "endOffset": 52}, {"referenceID": 2, "context": "see (Miyao and Tsujii, 2002; Clark and Curran, 2003)).", "startOffset": 4, "endOffset": 52}, {"referenceID": 18, "context": "2 Hierarchical Hidden Markov Models Hierarchical HMMs are generalisations of HMMs (Rabiner, 1989) in the way that a state in an HHMM may be a sub-HHMM.", "startOffset": 82, "endOffset": 97}, {"referenceID": 13, "context": "The temporal evolution of the HHMM can be represented as a dynamic Bayesian network, which was first done in (Murphy and Paskin, 2002).", "startOffset": 109, "endOffset": 134}, {"referenceID": 7, "context": "Conditional random fields (CRFs) (Lafferty et al., 2001) define a conditional distribution given the observation z as follows", "startOffset": 33, "endOffset": 56}, {"referenceID": 21, "context": "(DCRFs) (Sutton et al., 2007), segmental sequences as in Semi-Markov CRFs (SemiCRFs) (Sarawagi and Cohen, 2004), and relational data (Taskar et al.", "startOffset": 8, "endOffset": 29}, {"referenceID": 20, "context": ", 2007), segmental sequences as in Semi-Markov CRFs (SemiCRFs) (Sarawagi and Cohen, 2004), and relational data (Taskar et al.", "startOffset": 63, "endOffset": 89}, {"referenceID": 22, "context": ", 2007), segmental sequences as in Semi-Markov CRFs (SemiCRFs) (Sarawagi and Cohen, 2004), and relational data (Taskar et al., 2002).", "startOffset": 111, "endOffset": 132}, {"referenceID": 3, "context": "The second category investigates learning schemes other than maximum likelihood, for example perceptron (Collins, 2002) and SVM (Taskar et al.", "startOffset": 104, "endOffset": 119}, {"referenceID": 23, "context": "The second category investigates learning schemes other than maximum likelihood, for example perceptron (Collins, 2002) and SVM (Taskar et al., 2004).", "startOffset": 128, "endOffset": 149}, {"referenceID": 12, "context": "DCRFs are basically the conditional, undirected version of the Dynamic Bayesian Networks (Murphy, 2002).", "startOffset": 89, "endOffset": 103}, {"referenceID": 1, "context": "The shared topology has been investigated in the context of HHMMs in (Bui et al., 2004).", "startOffset": 69, "endOffset": 87}, {"referenceID": 8, "context": "Remarks: The temporal model of HSCRFs presented here is not a standard graphical model (Lauritzen, 1996) since the connectivity (and therefore the clique structures) is not fixed.", "startOffset": 87, "endOffset": 104}, {"referenceID": 1, "context": "structure HHMMs (Bui et al., 2004), the unrolled temporal representation is an undirected graph and the model distribution is formulated in a discriminative way.", "startOffset": 16, "endOffset": 34}, {"referenceID": 13, "context": "Furthermore, the state persistence potentials capture duration information that is not available in the dynamic DBN representation of the HHMMs in (Murphy and Paskin, 2002).", "startOffset": 147, "endOffset": 172}, {"referenceID": 22, "context": "In the way the potentials are introduced it may first appear to resemble the clique templates in the discriminative relational Markov networks (RMNs) (Taskar et al., 2002).", "startOffset": 150, "endOffset": 171}, {"referenceID": 1, "context": "4 Asymmetric Inside-Outside Algorithm This section describes a core inference engine called Asymmetric Inside-Outside (AIO) algorithm, which is partly adapted from the generative, directed counter part of HHMMs in (Bui et al., 2004).", "startOffset": 214, "endOffset": 232}, {"referenceID": 16, "context": "This similarity comes from the relation between the sum-product and max-product algorithm (a generalisation of the Viterbi algorithm) of Pearl (1988), and from the fact that inside/asymmetric inside procedures described in Section 4.", "startOffset": 137, "endOffset": 150}, {"referenceID": 16, "context": "The idea can be traced back to the Pearl\u2019s message-passing procedure (Pearl, 1988; Yedidia et al., 2005).", "startOffset": 69, "endOffset": 104}, {"referenceID": 26, "context": "The idea can be traced back to the Pearl\u2019s message-passing procedure (Pearl, 1988; Yedidia et al., 2005).", "startOffset": 69, "endOffset": 104}, {"referenceID": 1, "context": "In the context of HHMMs with which the numerical underflow problem is associated, the similar idea has been proposed in (Bui et al., 2004), which we adapt to our overflow problem.", "startOffset": 120, "endOffset": 138}, {"referenceID": 14, "context": "The data, which was captured in (Nguyen et al., 2005), and subsequently used to evaluate DCRFs in (Truyen et al.", "startOffset": 32, "endOffset": 53}, {"referenceID": 24, "context": ", 2005), and subsequently used to evaluate DCRFs in (Truyen et al., 2006), has 90 sequences, each of which corresponds to one of 3 the persistent activities: (1) preparing short-meal, (2) having snack and (3) preparing normal-meal.", "startOffset": 52, "endOffset": 73}, {"referenceID": 24, "context": "embedded in state-persistence potentials) at the bottom level, we use the same features as in (Truyen et al., 2006).", "startOffset": 94, "endOffset": 115}, {"referenceID": 21, "context": "We extract raw features from the text in the way similar to that in (Sutton et al., 2007).", "startOffset": 68, "endOffset": 89}, {"referenceID": 21, "context": "Furthermore, we use the contextual window of 5 instead of 7 as in (Sutton et al., 2007).", "startOffset": 66, "endOffset": 87}, {"referenceID": 20, "context": "For comparison, we implement a DCRF, a simple sequential CRF (SCRF), and a semi-Markov CRF (SemiCRF) (Sarawagi and Cohen, 2004).", "startOffset": 101, "endOffset": 127}, {"referenceID": 21, "context": "However, the set shared by the SCRF and the SemiCRF is a little more elaborate since it takes the POS tags into account (Sutton et al., 2007).", "startOffset": 120, "endOffset": 141}, {"referenceID": 25, "context": "For learning, we use a simple online stochastic gradient ascent method since it has been shown to work relatively well and fast in CRFs (Vishwanathan et al., 2006).", "startOffset": 136, "endOffset": 163}, {"referenceID": 21, "context": "This does not share the observation made in (Sutton et al., 2007).", "startOffset": 44, "endOffset": 65}, {"referenceID": 21, "context": "However, we use a much smaller POS tag set than (Sutton et al., 2007) does.", "startOffset": 48, "endOffset": 69}], "year": 2010, "abstractText": "Inspired by the hierarchical hidden Markov models (HHMM), we present the hierarchical semi-Markov conditional random field (HSCRF), a generalisation of embedded undirected Markov chains to model complex hierarchical, nested Markov processes. It is parameterised in a discriminative framework and has polynomial time algorithms for learning and inference. Importantly, we consider partiallysupervised learning and propose algorithms for generalised partially-supervised learning and constrained inference. We demonstrate the HSCRF in two applications: (i) recognising human activities of daily living (ADLs) from indoor surveillance cameras, and (ii) noun-phrase chunking. We show that the HSCRF is capable of learning rich hierarchical models with reasonable accuracy in both fully and partially observed data cases.", "creator": "LaTeX with hyperref package"}}}