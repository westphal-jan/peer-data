{"id": "1011.4362", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2010", "title": "Should one compute the Temporal Difference fix point or minimize the Bellman Residual? The unified oblique projection view", "abstract": "We investigate projection methods, for evaluating a linear approximation of the value function of a policy in a Markov Decision Process context. We consider two popular approaches, the one-step Temporal Difference fix-point computation (TD(0)) and the Bellman Residual (BR) minimization. We describe examples, where each method outperforms the other. We highlight a simple relation between the objective function they minimize, and show that while BR enjoys a performance guarantee, TD(0) does not in general. We then propose a unified view in terms of oblique projections of the Bellman equation, which substantially simplifies and extends the characterization of (schoknecht,2002) and the recent analysis of (Yu &amp; Bertsekas, 2008). Eventually, we describe some simulations that suggest that if the TD(0) solution is usually slightly better than the BR solution, its inherent numerical instability makes it very bad in some cases, and thus worse on average.", "histories": [["v1", "Fri, 19 Nov 2010 08:20:30 GMT  (333kb)", "http://arxiv.org/abs/1011.4362v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["bruno scherrer"], "accepted": true, "id": "1011.4362"}, "pdf": {"name": "1011.4362.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["scherrer@loria.fr"], "sections": [{"heading": null, "text": "ar Xiv: 101 1.43 62v1 [cs.AI] 19 Nov 2IntroductionWe look at linear approximations of the value function of politics in the context of Markov decision-making processes (MDP), focusing on two popular methods: the calculation of the projected fixed point of temporal difference (TD (0), abbreviated to TD), Antos et al. (2008); Farahmand et al. (2008); Sutton et al. (2009) recently presented as a minimization of the average square projected Bellman Appearing in Proceedings of the 27th International Conference on Machine Learning, Haifa, Israel, 2010. Copyright 2010 by the author / owner (s). Equation and minimization of the average quare Bellman Residual (BR). In this article we present some new analytical and empirical data that shed some light on both approaches."}, {"heading": "1. Framework and Notations", "text": "We assume that there is a state in which the system gives a reward, in which there is the instantaneous reward function, and 0 < 1 is a discount factor. The value in this state is defined as the total expected return: v (i): = limN (i). - E (ik) kr (ik). We write the N (n) n stochastic matrix, whose elements are pij. v) can be regarded as a vector of the RN. v) is known as the unique fixed point of the Bellman operator: T: = r +. We write the N (n) stochastic matrix, whose elements are pij."}, {"heading": "2. Two simple examples", "text": "Example 1: Let's just consider case r1 = 01This is not necessary to solve the case. Let's call the rewards r1 and r2. Onethus has v (1) = 1: 1 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2) -2 (2) -2 (2) -2 (2) -2 (2) -2) -2 (2) -2 (2) -2 (2) -2 (2) -2) -2 (2) -2) This example was proposed by Bertsekas & Tsitsiklis to show that the values of the iteration may differ if the samples are not generated by the stationary distribution of politics."}, {"heading": "3. A Relation and Stability Issues", "text": "Although several papers have been compared and considered (Schoknecht, 2002; Lagoudakis & Parr, 2003; Munos, 2003; Yu & Bertsekas, 2008), the following simple fact is that to our knowledge it can never be emphasized per se: The BR is an upper limit of the TD error, and more accurately: D & T is the upper limit of the TD error, and more accurately: D & T is the upper limit of the TD error, the upper limit of the TD error, the upper limit of the TD error, the upper limit of the TD error."}, {"heading": "4. The unified oblique projection view", "text": "In the TD approach we consider the finding of the fixed point of the composition of an orthogonal projection (D = VP = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK UK = UK = UK UK = UK UK = UK UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK = UK ="}, {"heading": "5. An Empirical Comparison", "text": "In order to further compare the TD and BR projections, we have made some empirical comparisons which we will now describe. We consider spaces of dimensions n = 2, 3,.., 30. For each n, we consider projections of dimensions k = 1, 2,.., n. For each pair (n, k) we generate 20 random projections of size (n, k) and random weight vectors (the last state is).10 Each entry is a random uniform number between -1 and 1.The reward is a random vector."}, {"heading": "6. Conclusion and Future Work", "text": "We have presented the TD fixed points and BR minimization methods for approximating the value of some MDP fixation results. We have described two original examples: in the former, the BR method is consistently better than the TD method, while the latter (which generalizes the spirit of the Sutton et al example) is best treated by TD. Proposition 1 highlights the close relationship between the objective criteria that correspond to the two methods. It shows that minimizing the BR method implies minimizing the TD error and some additional \"appropriateness\" that is crucial for numerical stability. Our main contribution, detailed in Proposition 2, offers a new perspective for comparing the two projection methods, and potential ideas for alternatives. Both TD and BR can be characterized as solving a projected fixed point equation, and this is new to our knowledge for BR. Also, the solutions to both methods are some objective projections."}], "references": [{"title": "Learning near-optimal policies with bellman-residual minimization based fitted policy iteration and a single sample path", "author": ["A. Antos", "C. Szepesv\u00e1ri", "R. Munos"], "venue": "Machine Learning,", "citeRegEx": "Antos et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Antos et al\\.", "year": 2008}, {"title": "Neurodynamic Programming", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "Athena Scientific,", "citeRegEx": "Bertsekas and Tsitsiklis,? \\Q1996\\E", "shortCiteRegEx": "Bertsekas and Tsitsiklis", "year": 1996}, {"title": "Regularized policy iteration", "author": ["A.M. Farahmand", "M. Ghavamzadeh", "C. Szepesv\u00e1ri", "S. Mannor"], "venue": "In NIPS,", "citeRegEx": "Farahmand et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Farahmand et al\\.", "year": 2008}, {"title": "Stable function approximation in dynamic programming", "author": ["G. Gordon"], "venue": "In ICML,", "citeRegEx": "Gordon,? \\Q1995\\E", "shortCiteRegEx": "Gordon", "year": 1995}, {"title": "Max-norm projections for factored mdps", "author": ["C. Guestrin", "D. Koller", "R. Parr"], "venue": "In IJCAI,", "citeRegEx": "Guestrin et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Guestrin et al\\.", "year": 2001}, {"title": "Error bounds for approximate policy iteration", "author": ["R. Munos"], "venue": "In ICML,", "citeRegEx": "Munos,? \\Q2003\\E", "shortCiteRegEx": "Munos", "year": 2003}, {"title": "Finite-time bounds for fitted value iteration", "author": ["R. Munos", "C. Szepesv\u00e1ri"], "venue": "JMLR, 9:815\u2013857,", "citeRegEx": "Munos and Szepesv\u00e1ri,? \\Q2008\\E", "shortCiteRegEx": "Munos and Szepesv\u00e1ri", "year": 2008}, {"title": "Iterative Methods for Sparse Linear Systems, 2nd edition", "author": ["Y. Saad"], "venue": null, "citeRegEx": "Saad,? \\Q2003\\E", "shortCiteRegEx": "Saad", "year": 2003}, {"title": "Optimality of reinforcement learning algorithms with linear function approximation", "author": ["R. Schoknecht"], "venue": "In NIPS, pp", "citeRegEx": "Schoknecht,? \\Q2002\\E", "shortCiteRegEx": "Schoknecht", "year": 2002}, {"title": "Fast gradient-descent methods for temporaldifference learning with linear function approximation", "author": ["R.S. Sutton", "H.R. Maei", "D. Precup", "S. Bhatnagar", "D. Silver", "C. Szepesv\u00e1ri", "E. Wiewiora"], "venue": "In ICML,", "citeRegEx": "Sutton et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 2009}, {"title": "The many proofs of an identity on the norm of oblique projections", "author": ["D.B. Szyld"], "venue": "Numerical Algorithms,", "citeRegEx": "Szyld,? \\Q2006\\E", "shortCiteRegEx": "Szyld", "year": 2006}, {"title": "Minkowski Geometry", "author": ["A.C. Thompson"], "venue": null, "citeRegEx": "Thompson,? \\Q1996\\E", "shortCiteRegEx": "Thompson", "year": 1996}, {"title": "An analysis of temporal-difference learning with function approximation", "author": ["J.N. Tsitsiklis", "B. Van Roy"], "venue": "IEEE Transactions on Automatic Control,", "citeRegEx": "Tsitsiklis and Roy,? \\Q1997\\E", "shortCiteRegEx": "Tsitsiklis and Roy", "year": 1997}, {"title": "Tight performance bounds on greedy policies based on imperfect value functions", "author": ["R.J. Williams", "L.C. Baird"], "venue": "Technical report,", "citeRegEx": "Williams and Baird,? \\Q1993\\E", "shortCiteRegEx": "Williams and Baird", "year": 1993}, {"title": "New error bounds for approximations from projected linear equations", "author": ["H. Yu", "D.P. Bertsekas"], "venue": "Technical Report C-2008-43,", "citeRegEx": "Yu and Bertsekas,? \\Q2008\\E", "shortCiteRegEx": "Yu and Bertsekas", "year": 2008}], "referenceMentions": [{"referenceID": 8, "context": "We then propose a unified view in terms of oblique projections of the Bellman equation, which substantially simplifies and extends the characterization of Schoknecht (2002) and the recent analysis of Yu & Bertsekas (2008).", "startOffset": 155, "endOffset": 173}, {"referenceID": 8, "context": "We then propose a unified view in terms of oblique projections of the Bellman equation, which substantially simplifies and extends the characterization of Schoknecht (2002) and the recent analysis of Yu & Bertsekas (2008). Eventually, we describe some simulations that suggest that if the TD(0) solution is usually slightly better than the BR solution, its inherent numerical instability makes it very bad in some cases, and thus worse on average.", "startOffset": 155, "endOffset": 222}, {"referenceID": 0, "context": "We focus on two popular methods: the computation of the projected Temporal Difference fixed point (TD(0), TD for short), which Antos et al. (2008); Farahmand et al.", "startOffset": 127, "endOffset": 147}, {"referenceID": 0, "context": "We focus on two popular methods: the computation of the projected Temporal Difference fixed point (TD(0), TD for short), which Antos et al. (2008); Farahmand et al. (2008); Sutton et al.", "startOffset": 127, "endOffset": 172}, {"referenceID": 0, "context": "We focus on two popular methods: the computation of the projected Temporal Difference fixed point (TD(0), TD for short), which Antos et al. (2008); Farahmand et al. (2008); Sutton et al. (2009) have recently presented as the minimization of the mean-square projected Bellman", "startOffset": 127, "endOffset": 194}, {"referenceID": 8, "context": "Section 4 contains the main contribution of this paper: we describe a unified view in terms of oblique projections of the Bellman equation, which simplifies and extends the characterization of Schoknecht (2002) and the recent analysis of Yu & Bertsekas (2008).", "startOffset": 193, "endOffset": 211}, {"referenceID": 8, "context": "Section 4 contains the main contribution of this paper: we describe a unified view in terms of oblique projections of the Bellman equation, which simplifies and extends the characterization of Schoknecht (2002) and the recent analysis of Yu & Bertsekas (2008). Eventually, Section 5 presents some simulations, that address the following practical questions: which of the method gives the best approximation? and how useful is our analysis for selecting it a priori?", "startOffset": 193, "endOffset": 260}, {"referenceID": 0, "context": "As pointed out by Antos et al. (2008); Farahmand et al.", "startOffset": 18, "endOffset": 38}, {"referenceID": 0, "context": "As pointed out by Antos et al. (2008); Farahmand et al. (2008); Sutton et al.", "startOffset": 18, "endOffset": 63}, {"referenceID": 0, "context": "As pointed out by Antos et al. (2008); Farahmand et al. (2008); Sutton et al. (2009), when the inverse exists, the above computation is equivalent to minimizing for v\u0302 \u2208 span (\u03a6) the TD error ETD(v\u0302) := \u2016v\u0302 \u2212\u03a0T v\u0302\u2016\u03be down to 0.", "startOffset": 18, "endOffset": 85}, {"referenceID": 8, "context": "Note that in this case, the above inverse always exists (Schoknecht, 2002).", "startOffset": 56, "endOffset": 74}, {"referenceID": 9, "context": "This observation lead Sutton et al. (2009) to propose original off-policy gradient algorithms for computing the TD solution.", "startOffset": 22, "endOffset": 43}, {"referenceID": 9, "context": "Example 2 Sutton et al. (2009) recently described a 3-state MDP example where the TD method computes the best projection while BR does not.", "startOffset": 10, "endOffset": 31}, {"referenceID": 8, "context": "Though several works have compared and considered both methods (Schoknecht, 2002; Lagoudakis & Parr, 2003; Munos, 2003; Yu & Bertsekas, 2008), the following simple fact has, to our knowledge, never been emphasized per se:", "startOffset": 63, "endOffset": 141}, {"referenceID": 5, "context": "Though several works have compared and considered both methods (Schoknecht, 2002; Lagoudakis & Parr, 2003; Munos, 2003; Yu & Bertsekas, 2008), the following simple fact has, to our knowledge, never been emphasized per se:", "startOffset": 63, "endOffset": 141}, {"referenceID": 4, "context": "A complementary view on the potential instability of TD, has been referred to as a norm incompatibility issue (Bertsekas & Tsitsiklis, 1996; Guestrin et al., 2001), and can be revisited through the notion of concentration coefficient.", "startOffset": 110, "endOffset": 163}, {"referenceID": 4, "context": "Mainly because it is computationnally easier than doing a max-norm minimization, see however (Guestrin et al., 2001) for an attempt of doing max-norm projection.", "startOffset": 93, "endOffset": 116}, {"referenceID": 5, "context": "The proof is a consequence of Jensen\u2019s inequality and the arguments are very close to the ones in (Munos, 2003).", "startOffset": 98, "endOffset": 111}, {"referenceID": 5, "context": "See (Munos, 2003) for more discussion on this coefficient.", "startOffset": 4, "endOffset": 17}, {"referenceID": 11, "context": "1+ \u221a N 2 (Thompson, 1996) and it can be shown 8 that \u2016P\u2016\u03be \u2264 \u221a", "startOffset": 9, "endOffset": 25}, {"referenceID": 3, "context": "Another notable such exception is when \u2016\u03a0\u2016max = 1, as in the so-called \u201caverager\u201d approximation (Gordon, 1995).", "startOffset": 96, "endOffset": 110}, {"referenceID": 5, "context": "The argument for the first inequality involves Jensen\u2019s inequality and is again close to what is done in (Munos, 2003).", "startOffset": 105, "endOffset": 118}, {"referenceID": 10, "context": "(Szyld, 2006)).", "startOffset": 0, "endOffset": 13}, {"referenceID": 8, "context": "Proposition 2 is closely related to the work of (Schoknecht, 2002), in which the author derived the following characterization of the TD and BR solutions:", "startOffset": 48, "endOffset": 66}, {"referenceID": 8, "context": "Proposition 4 (Schoknecht (2002)) The TD fix point computation and the BR minimization are orthogonal projections of the value v respectively induced by the seminorm \u2016\u00b7\u2016QTD 9 with QTD = L\u2032\u039e\u03a6\u03a6\u2032\u039eL and by the norm \u2016 \u00b7 \u2016QBR with QBR = L\u2032\u039eL.", "startOffset": 15, "endOffset": 33}, {"referenceID": 8, "context": "The work of Schoknecht (2002) suggests that TD and BR are optimal for different criteria, since both look for some v\u0302 \u2208 span (\u03a6) that minimizes \u2016v\u0302 \u2212 v\u2016 for some (semi)norm \u2016 \u00b7 \u2016.", "startOffset": 12, "endOffset": 30}, {"referenceID": 8, "context": "The analysis we propose is unified for TD and BR (and even extends to potential new methods through other choices of the parameter X), while the results in (Schoknecht, 2002) and (Yu & Bertsekas, 2008) are proved independently for each method.", "startOffset": 156, "endOffset": 174}, {"referenceID": 9, "context": "We have described two original examples: in the former, the BR method is consistently better than the TD method, while the latter (which generalizes the spirit of the example of Sutton et al. (2009)) is best treated by TD.", "startOffset": 178, "endOffset": 199}, {"referenceID": 7, "context": "We have discussed the close relations of our results with those of Schoknecht (2002) and Yu & Bertsekas (2008), and argued that our work simplifies and extends them.", "startOffset": 67, "endOffset": 85}, {"referenceID": 7, "context": "We have discussed the close relations of our results with those of Schoknecht (2002) and Yu & Bertsekas (2008), and argued that our work simplifies and extends them.", "startOffset": 67, "endOffset": 111}, {"referenceID": 7, "context": "Saad (2003)).", "startOffset": 0, "endOffset": 12}], "year": 2009, "abstractText": "We investigate projection methods, for evaluating a linear approximation of the value function of a policy in a Markov Decision Process context. We consider two popular approaches, the one-step Temporal Difference fix-point computation (TD(0)) and the Bellman Residual (BR) minimization. We describe examples, where each method outperforms the other. We highlight a simple relation between the objective function they minimize, and show that while BR enjoys a performance guarantee, TD(0) does not in general. We then propose a unified view in terms of oblique projections of the Bellman equation, which substantially simplifies and extends the characterization of Schoknecht (2002) and the recent analysis of Yu & Bertsekas (2008). Eventually, we describe some simulations that suggest that if the TD(0) solution is usually slightly better than the BR solution, its inherent numerical instability makes it very bad in some cases, and thus worse on average.", "creator": "gnuplot 4.2 patchlevel 5 "}}}