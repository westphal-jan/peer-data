{"id": "1105.1033", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-May-2011", "title": "Adaptively Learning the Crowd Kernel", "abstract": "We introduce an algorithm that, given n objects, learns a similarity matrix over all n^2 pairs, from crowdsourced data alone. The algorithm samples responses to adaptively chosen triplet-based relative-similarity queries. Each query has the form \"is object 'a' more similar to 'b' or to 'c'?\" and is chosen to be maximally informative given the preceding responses. The output is an embedding of the objects into Euclidean space (like MDS); we refer to this as the \"crowd kernel.\"", "histories": [["v1", "Thu, 5 May 2011 11:03:03 GMT  (3710kb,D)", "https://arxiv.org/abs/1105.1033v1", "9 pages, 7 figures, Accepted to the 28th, International Conference on Machine Learning, 2011"], ["v2", "Sat, 25 Jun 2011 21:54:08 GMT  (3805kb,D)", "http://arxiv.org/abs/1105.1033v2", "9 pages, 7 figures, Accepted to the 28th International Conference on Machine Learning (ICML), 2011"]], "COMMENTS": "9 pages, 7 figures, Accepted to the 28th, International Conference on Machine Learning, 2011", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["omer tamuz", "ce liu", "serge j belongie", "ohad shamir", "adam kalai"], "accepted": true, "id": "1105.1033"}, "pdf": {"name": "1105.1033.pdf", "metadata": {"source": "META", "title": "Adaptively Learning the Crowd Kernel", "authors": ["Omer Tamuz", "Ce Liu"], "emails": ["omertamuz@weizmann.ac.il", "celiu@microsoft.com", "sjb@cs.ucsd.edu", "ohadsh@microsoft.com", "adum@microsoft.com"], "sections": [{"heading": null, "text": "The algorithm randomly responds to adaptively selected triplet-based queries for relative similarity. Each query is in the form of \"is object a more similar to b or c?\" and is selected to be as informative as possible in light of the previous answers. The result is an embedding of the objects in the Euclidean space (such as MDS); we call this the \"crowd kernel.\" SVMs show that the crowd kernel captures prominent and subtle features across a number of domains, such as \"striped\" between necklaces and \"vowel versus consonant\" between letters."}, {"heading": "1. Introduction", "text": "It is a question of the success of machine learning in a new domain and, in these cases, the determination of a good \"similarity function\" between objects (or alternatively the definition of good objects \"properties\").With such a \"kernel,\" a number of interesting tasks can be performed, for example, the search for a suitable system for searching for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object, the search for a suitable object and the search for another, the search for a suitable object and the search for a suitable object."}, {"heading": "1.1. Human kernels versus machine kernels", "text": "Most of the work in machine learning focuses on \"machine kernels,\" which are computed by computers from the raw data (e.g. pixels) themselves. Additional work employs human experiments to try to learn cores based on machine features, i.e., to assume human similarity assessments based on features that can be derived from machines. In contrast, when a kernel is learned by human subjects alone (whether it is data from an individual or a crowd), there is no need for machine features that are recognized only by ID - the images themselves are hidden by our system and are presented only to humans. The primary advantage of machine cores is that they can immediately generalize to new data, while each additional object in our system needs to be added, at a cost of about $0.15.2 per second, working with a human kernel has two primary advantages."}, {"heading": "2. Benefits of adaptation", "text": "First, we give a high degree of intuition as to why the adaptive selection of triples can yield better grain approximations than randomly selected triples. Consider n objects organized in a rooted tree with n leaves, for example, inspired by phylogenic trees with animal species. 4 Let us say that the similarity between objects in the tree diagram decreases in distance, and also that objects are uniformly randomly drawn from the classes represented by the leaves of the tree. If we ignore the details of how one would recognize that two objects are in the same leaf or sub-tree, it becomes clear that a non-adaptive method would have to ask questions in order to determine the leaves to which n objects belong (or at least to determine which objects are in the same leaves), because an expected query per object is required until only a second object is selected from the same leaf."}, {"heading": "3. Related work", "text": "Agarwal et al. (2007) is probably the most similar work in which they learn a kernel matrix from triple similarity comparisons, as we do. However, the triple information they are looking at is chosen randomly (not adaptively), and their particular adaptation algorithm differs in3While this fraction of the match appears small, it corresponds to about 25% \"noise,\" for example, if 75% of people said that a is more b than c, then two random people would be 0.752 = 0.56.4This example is based on a tree metric and not on a euclidean work. Note, however, that any tree with \"leaves\" can be embedded in a one-dimensional Euclidean space in which euclimatism literacy, where a climatic distance based on a common margin is not more active information."}, {"heading": "4. Preliminaries", "text": "The set of n objects is denoted by [n] = {1, 2,., n}. For a, b, c [n], a comparison or comparison is of the form \"more similar to b or c.\" We refer to a as the head of the triple. We write pabc for the probability that a random crowd member a is more similar to b, so pabc + p a cb = 1. The n objects are assumed to be d-dimensional euclidean representation, and therefore the data can be regarded as matrix M. (Ma denotes the series correspondingly a, and the similarity matrix K-Rn is defined as d-dimensional euclidean representation, and therefore the data can be regarded as matrix M-Rn \u00b7 d.) The goal is to learn M. (It is easy to go back and forth between positive semidefinitive (PSD) K and M."}, {"heading": "5. Our algorithm", "text": "Our algorithm works in phases. In the first phase, it queries a certain number of random triples, comparing each object a [n] with random pairs of different b, c. (Note that we never present a triple, where a = b or a = c except for quality control purposes.) Then it matches the results into a matrix M-Rn \u00b7 d (equivalent, matches K 0) using the model of relative similarity described below. Then it uses our adaptive selection algorithm for random triples with head a. \u2022 For t = 1, 2,.., T: - Fit Kt for each element, the adaptive selection algorithm generates more triples. \u2022 For each element a [n], crowd-source labels for random triples with head a are described. \u2022 For t = 1, 2,.., T: - Fit Kt for the data collected so far using section 5.1 (d-dimensions)."}, {"heading": "5.1. Relative similarity model", "text": "The relative similarity model is motivated by the scale variance observed in many perceptual systems (see e.g. Chater & Brown, 1999).A simple scale invariant proposal assumes p-abc = \u03b4ac \u03b4ab + \u03b4ac. Such a model must also be regulated, otherwise it would have a (n2) degree of freedom. One can regulate by the rank of K or Kii = 1. Due to the scale invariance of the model, however, this latter limitation has no reduced complexity. In particular, it should be noted that halving or doubling the matrix M does not alter probabilities. Therefore, parentage algorithms can lead to very small, large, or numerically unstable solutions. To address this model, we modify the model as follows: p-abc = digit + digit 2b + digit + digit + digit + digit + digit + digit + digit + digit + digit + digit + digit + digit + digit + digit = digit = digit-1, which we do not directly adapt to digit 1."}, {"heading": "6. Adaptive selection algorithm", "text": "The idea is to capture the uncertainty about the location of an object by a probability distribution over points in Rd, and then to ask the question that maximizes the gain of information. Given a number of previous comparisons of n objects, we generate a new triple for each object a = 1, 2,.., n, to compare a with, as follows. First, we embed the objects in Rd, as described above, using the available comparisons. First, we use a seed of randomly selected triple objects for this purpose. Later, we use all available comparisons - the initial random and the acquired information. 5For high-dimensional problems, we perform a gradient descent from K. Specifically, we start with K0 = I, we calculate Kt + 1 = B (K) to use all available comparisons - the initial random and acquired information."}, {"heading": "6.1. Optimization guarantee", "text": "The relative similarity model is attractive in that it fits well with the data, suggests good triples, and also represents interesting features on the data. Unfortunately, the model itself is not convex. We now give a justification for why the descent of the gradient should not remain trapped in local minima. As is sometimes the case with learning, it is easier to analyze an online version of the algorithm, i.e. a stochastic descent of the gradient. We assume here that the sequence of the triples is presented in order: the learner says Kt + 1 on the basis of (a1, b1, c1, y1),.., (at, bt, ct, yt). The loss on the iteration t is \"t (Kt) = log 1 / p, where p is the probability that the relative model with Kt is assigned to the correct descent."}, {"heading": "6.2. The logistic model: A convex alternative", "text": "As a small digression, we explain why the choice of the probability model is particularly important for adaptive learning. Consider the following logistic model: This model is a natural mixture of logistic regression and MDS.p \u0441abc = eKabeKab + eKac = 11 + eKac \u2212 Kab. (2) Note that log 1 + eKac \u2212 Kab is a convex function of K-Rn \u00b7 n. Therefore, the problem of minimizing its empirical protocol loss via a convex sentence is a convex optimization problem. Note that the logistic model matches the data well and reproduces interesting features such as vowel / consonant or strictness. However, empirically, it performs poorly when deciding which threefold to ask. Note that the logistic model (and any generalized linear model) chooses extreme comparisons where the inner products are as large as possible."}, {"heading": "7. System parameters & quality control", "text": "Each task consists of 50 comparisons, and the user interface is optimized to perform it with 50 mouse clicks (and without scrolling), with an average completion time of about 2 minutes. This payment was determined based on employee feedback. Initial experiments yielded a high percentage of seemingly random answers, but upon closer inspection, the vast majority of these bad results came from a small number of people. To improve quality control, we set a limit on the maximum number of tasks a single user could perform in a day, and selected users who completed at least 48 tasks with a 95% approval rating, with each task comprising 20% triples, where there was enormous agreement among users. These \"gold standard\" triples were also generated automatically and proved to be an effective method of detecting and significantly reducing fraud. The system is implemented with Python, Matlab, and C, and runs fully automatically or uniquely under Windows."}, {"heading": "7.1. Question phrasing and crowd alignment", "text": "One interesting problem is how to frame similarity questions. On the one hand, giving users carte blanche and just asking \"is b more similar than c\" seems to be the purest way of doing it. On the other hand, users complained about these tasks in the feedback and often asked what we meant by similarity. Furthermore, different users will inevitably rate different characteristics differently when making comparisons. Others may feel that the question is impossible to answer. Consider the question as follows: \"Who would be more likely to confuse one: b or c remotely?\" For all two people, there is probably a certain distance at which one confuses oneself with the other, so that the question seems easier to answer for some people."}, {"heading": "8. Experiments and Applications", "text": "We are experimenting with four sets of data: (1) twenty-six images of the lowercase Roman alphabet (Calibri script) (2) 223 images of country flags from flagpedia.net, (3) 433 images of floor tiles from Amazon.com, and (4) 300 product images from an online tie store also hosted on Amazon.com. We are also looking at a hand-selected \"mixed\" set of data consisting of 225 images: 75 images, 75 tiles, and 75 flags. Surprisingly, it seems that about 30-40 triples per object are sufficient for these data sets to learn the crowd kernel well, according to the 20Q metric described below. Figure 2 shows the results on the mixed data set and compares the 20Q metric trained to random vs. adaptive triples. For both adaptive and random questions, about 60% more random queries are required for certain levels of performance than are expected from a set of adaptive or very small data."}, {"heading": "8.1. 20 Questions Metric", "text": "Since an application of such systems is the search, i.e. the search for an object that a user knows what it looks like (we assume that the user can answer queries as if he even knows what the image of the load looks like), it is natural to ask how well we \"carved\" the desired object after a certain number of questions. Metric 20 Questions (20Q) uses two independent parts of the system, an evaluator and an estimator. First, the evaluator randomly and secretly selects an object in the database, x. The estimator knows the database, but not which object x was selected. The estimator is allowed to query 20 triples (as in the game \"20 Questions\") with header x, whereupon he creates a ranking of items in the database, from the most probable to the least probable. Then the evaluator reveals the identity of x and thus his position in the ordered order of precedence, whereby the metric is the average log of the random position of the target in that list."}, {"heading": "8.2. Using the Kernel for Classification", "text": "The learned cores can be used in a linear classifier, e.g. in a support vector machine, which helps to clarify what characteristics humans used in labeling the data. In the experiments below, a unique subset of images were labeled with binary \u00b1 classes. For example, we omitted the letter y in labeling vowels and consonants (y was actually classified as a consonant, and c was incorrectly classified as a vowel), and we selected only fully striped or unstriped flags for flag stripe classification. The SVM-Light package (Joachims, 1998) was used with standard parameters, and the results of its leave-one-out classification (LOO) are shown in Figure 8."}, {"heading": "8.3. Visual Search", "text": "Considering n images, their embedding in Rd and the associated probability model for triples, we would like to help a user find either a particular object he has in mind, or something similar. We do this by playing \"20 questions\" with 8- or 9x queries generated by an adaptive selection algorithm very similar to the one described in Section 6. We thank Sham Kakade and Varun Kanade for helpful discussions. Serge Belongie's research is partly funded by ONR MURI Grant N00014-08-1-0638 and NSF Grant AGS-0941760."}, {"heading": "A. Proof of Theorem 1", "text": "There is a sequence of examples (x1, x \"1, y1, y1), (x2, y1), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (x2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2,\" (2), (2), (2), (2, \"(2), (2), (2,\" (2), (2, \",\" (2), (2), (2, \",\", \"(2),\", \"(2), (2,\", \"(2), (2), (2), (2, (2), (2), (2, (2), (2), (), (2), (2),\", \",\" (2, \"),\" (2, \"),\" (2, \"),\" (2, \"), (2,\"), (2, \"),\" (2, (), \"), (2, (2), (), (2), (2), (2), (2), (2, (), (2), (2), (2), (), (2, (2), (2, (), (2), (2), (2, (), (2, (), (2), (2), (2, (2), (, (),\"), (, (2), (, (2), (2), (2), (2), (, \"), (2), (2), (, (, (2), (2),\"), (2), ("}], "references": [{"title": "Generalized non-metric multidimensional scaling", "author": ["Agarwal", "Sameer", "Wills", "Josh", "Cayton", "Lawrence", "Lanckriet", "Gert", "Kriegman", "David", "Belongie", "Serge"], "venue": null, "citeRegEx": "Agarwal et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2007}, {"title": "Scale-invariance as a unifying psychological principle", "author": ["N Chater", "Brown", "G D"], "venue": "Cognition, 69(3):B17\u2013", "citeRegEx": "Chater et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Chater et al\\.", "year": 1999}, {"title": "Generalized sparse metric learning with relative comparisons", "author": ["Huang", "Kaizhu", "Ying", "Yiming", "Campbell", "Colin"], "venue": "Knowledge and Information Systems, pp", "citeRegEx": "Huang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2010}, {"title": "Making large-scale svm learning practical. LS8-Report 24, Universit\u00e4t Dortmund", "author": ["Joachims", "Thorsten"], "venue": "LS VIII-Report,", "citeRegEx": "Joachims and Thorsten.,? \\Q1998\\E", "shortCiteRegEx": "Joachims and Thorsten.", "year": 1998}, {"title": "Practical large-scale optimization for max-norm regularization", "author": ["Lee", "Jason", "Recht", "Ben", "Salakhutdinov", "Ruslan", "Srebro", "Nathan", "Tropp", "Joel"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Lee et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2010}, {"title": "Heterogeneous embedding for subjective artist similarity", "author": ["B. McFee", "G.R.G. Lanckriet"], "venue": "In Tenth International Symposium for Music Information Retrieval", "citeRegEx": "McFee and Lanckriet,? \\Q2009\\E", "shortCiteRegEx": "McFee and Lanckriet", "year": 2009}, {"title": "Learning a distance metric from relative comparisons", "author": ["Schultz", "Matthew", "Joachims", "Thorsten"], "venue": "In Advances in Neural Information Processing Systems (NIPS). MIT Press,", "citeRegEx": "Schultz et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Schultz et al\\.", "year": 2003}, {"title": "Rank, tracenorm and max-norm", "author": ["Srebro", "Nathan", "Shraibman", "Adi"], "venue": "In COLT, pp", "citeRegEx": "Srebro et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2005}, {"title": "Distance metric learning, with application to clustering with side-information", "author": ["Xing", "Eric P", "Ng", "Andrew Y", "Jordan", "Michael I", "Russell", "Stuart"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Xing et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Xing et al\\.", "year": 2003}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["Zinkevich", "Martin"], "venue": null, "citeRegEx": "Zinkevich and Martin.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich and Martin.", "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "The problem of capturing and extrapolating a human notion of perceptual similarity has received increasing attention in recent years including areas such as vision (Agarwal et al., 2007), audition (McFee & Lanckriet, 2009), information retrieval (Schultz & Joachims, 2003) and a variety of others represented in the UCI Datasets (Xing et al.", "startOffset": 164, "endOffset": 186}, {"referenceID": 8, "context": ", 2007), audition (McFee & Lanckriet, 2009), information retrieval (Schultz & Joachims, 2003) and a variety of others represented in the UCI Datasets (Xing et al., 2003; Huang et al., 2010).", "startOffset": 150, "endOffset": 189}, {"referenceID": 2, "context": ", 2007), audition (McFee & Lanckriet, 2009), information retrieval (Schultz & Joachims, 2003) and a variety of others represented in the UCI Datasets (Xing et al., 2003; Huang et al., 2010).", "startOffset": 150, "endOffset": 189}, {"referenceID": 0, "context": "Agarwal et al. (2007) is probably the most similar work, in which they learn a kernel matrix from triples of similarity comparisons, as we do.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "Projection to the closest element of B is a quadratic program which can be solved via a number of existing techniques (Srebro & Shraibman, 2005; Lee et al., 2010).", "startOffset": 118, "endOffset": 162}], "year": 2011, "abstractText": "We introduce an algorithm that, given n objects, learns a similarity matrix over all n pairs, from crowdsourced data alone. The algorithm samples responses to adaptively chosen triplet-based relative-similarity queries. Each query has the form \u201cis object a more similar to b or to c?\u201d and is chosen to be maximally informative given the preceding responses. The output is an embedding of the objects into Euclidean space (like MDS); we refer to this as the \u201ccrowd kernel.\u201d SVMs reveal that the crowd kernel captures prominent and subtle features across a number of domains, such as \u201cis striped\u201d among neckties and \u201cvowel vs. consonant\u201d among letters.", "creator": "LaTeX with hyperref package"}}}