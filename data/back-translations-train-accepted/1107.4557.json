{"id": "1107.4557", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jul-2011", "title": "Finding Deceptive Opinion Spam by Any Stretch of the Imagination", "abstract": "Consumers increasingly rate, review and research products online. Consequently, websites containing consumer reviews are becoming targets of opinion spam. While recent work has focused primarily on manually identifiable instances of opinion spam, in this work we study deceptive opinion spam---fictitious opinions that have been deliberately written to sound authentic. Integrating work from psychology and computational linguistics, we develop and compare three approaches to detecting deceptive opinion spam, and ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset. Based on feature analysis of our learned models, we additionally make several theoretical contributions, including revealing a relationship between deceptive opinions and imaginative writing.", "histories": [["v1", "Fri, 22 Jul 2011 16:02:06 GMT  (23kb)", "http://arxiv.org/abs/1107.4557v1", "11 pages, 5 tables, data available at:this http URL"]], "COMMENTS": "11 pages, 5 tables, data available at:this http URL", "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["myle ott", "yejin choi", "claire cardie", "jeffrey t hancock"], "accepted": true, "id": "1107.4557"}, "pdf": {"name": "1107.4557.pdf", "metadata": {"source": "CRF", "title": "Finding Deceptive Opinion Spam by Any Stretch of the Imagination", "authors": ["Myle Ott Yejin Choi", "Claire Cardie", "Jeffrey T. Hancock"], "emails": ["myleott@cs.cornell.edu", "ychoi@cs.cornell.edu", "cardie@cs.cornell.edu", "jth34@cornell.edu"], "sections": [{"heading": null, "text": "ar Xiv: 110 7.45 57v1 [cs.CL] 2 2Ju l 2Consumers are increasingly evaluating, evaluating and researching online products (Jansen, 2010; Litvin et al., 2008). As a result, consumer review websites are becoming targets of opinion spam. While the most recent work focuses primarily on manually identifiable cases of opinion spam, in this work we investigate misleading opinion spam - fictitious opinions deliberately written to sound authentic. By integrating work from psychology and computer linguistics, we develop and compare three approaches to detecting misleading opinion spam and ultimately develop a classifier that is almost 90% accurate based on our gold standard opinion spam dataset. Based on the feature analysis of our learned models, we also make several theoretical contributions, including the discovery of a relationship between misleading opinion and imaginative writing."}, {"heading": "1 Introduction", "text": "In fact, most of us are able to move to a different world, to move to a different world."}, {"heading": "2 Related Work", "text": "Spam has historically been studied in the contexts of e-mail (Drucker et al., 2002) and web (Gyongyi et al., 2004; Ntoulas et al., 2006). Recently, researchers have also begun to look at opinion spam (Jindal and Liu, 2008; Wu et al., 2010; Yoo and Gretzel, 2009).Jindal and Liu (2008) find that opinion spam is both widespread and different in nature from e-mail or web spam. Using product evaluation data and in the absence of gold standard deceptions, they exert models based on features based on the review text, the receptor, and the product to differentiate between duplicate opinion 7 (as deceptive spam) and non-duplicate opinions (considered truthful). Wu et al al al al al al al al al al al al al al al al al al al al al al al al al. (2010) they propose an alternative strategy to detection of opinion 7 (as deceptive spam) in the contexts of e-mail (Drucker et al., 2002) and web (Gyongyi et al., 2004; Ntoulas et al., 2006)."}, {"heading": "3 Dataset Construction and Human Performance", "text": "While truthful opinions are ubiquitous online, deceptive opinions are difficult to obtain without recourse to heuristic methods (Jindal and Liu, 2008; Wu et al., 2010). In this section, we report on our efforts to collect the first publicly available spam data set of gold-standard misleading opinions (and validate them with human judgement), and following the work of Yoo and Gretzel (2009), we compare truthful and misleading positive reviews for hotels found on TripAdvisor. Below, we provide details of the deceptive opinion collection methods (Section 3.1) and truthful opinions (Section 3.2) from the 20 hotels using Amazon Mechanical Turk10 (AMT)."}, {"heading": "3.1 Deceptive opinions via Mechanical Turk", "text": "Crowdsourcing services such as AMT have made large-scale data annotations and survey efforts financially affordable by giving anyone with basic programming skills access to a marketplace of anonymous online workers (known as Turks) willing to do small tasks. To ensure that opinions are written by unique authors, we allow only one submission per Turk. We also limit our task to Turks who are in the United States and maintain an approval rate of at least 90%. Turks are allowed to work on HIT for a maximum of 30 minutes and are paid for an accepted submission. Each HIT presents the Turk with the name and website of a hotel. The HIT instructions ask Turks to assume that they are working for the hotel's marketing department, and to pretend that their boss wants to write them a fake review (as if they were a sufficient review on the website)."}, {"heading": "3.2 Truthful opinions from TripAdvisor", "text": "For truthful reviews, we scan all 6,977 reviews from the 20 most popular Chicago hotels on TripAdvisor. From these, we remove: \u2022 3,130 reviews without 5 stars; \u2022 41 reviews without English; 13 \u2022 75 reviews with less than 150 characters, as misleading design reviews are considered unreasonably short if they contain less than 150 characters. \u2022 1,607 reviews written by first-time authors - new users who have not previously posted an opinion on TripAdvisor - as these opinions are more likely to contain opinion spam, which would reduce the integrity of our truthful rating data (Wu et al., 2010)."}, {"heading": "3.3 Human performance", "text": "In fact, there is only one way to achieve what we have set out to achieve, and that is in the way we envisaged it."}, {"heading": "4 Automated Approaches to Deceptive Opinion Spam Detection", "text": "We will consider three automated approaches to detecting misleading opinion spam, each of which uses classifiers (described in Section 4.4) based on the data set of Section 3. The features of each strategy are outlined here."}, {"heading": "4.1 Genre identification", "text": "Research in computational linguistics has shown that the frequency distribution of Part-of-Speech (POS) tags in a text often depends on the genre of the text (Biber et al., 1999; Rayson et al., 2001). In our genre identification approach to detecting misleading opinion spam, we test whether there is such a relationship between truthful and misleading reviews by constructing features for each review based on the frequency of each POS tag. 15 These features should also provide a good starting point for comparing our other automated approaches."}, {"heading": "4.2 Psycholinguistic deception detection", "text": "The Linguistic Inquiry and Word Count (LIWC) software (Pennebaker et al., 2007) is a popular automated text analysis tool widely used in the social sciences. It has been used to determine personality.15We use the Stanford parser (Klein and Manning, 2003) to obtain the relative frequency of POS features (Mairesse et al., 2007) to study the dynamics of tutoring (Cade et al., 2010), and, most pertinently, to analyze deception (Hancock et al., 2008; Mihalcea and Strapparava, 2009; Vrij et al., 2007). While LIWC does not contain a text classifier, we can create one with features derived from the LIWC edition. Specifically, LIWC counts and groups the number of instances of nearly 4,500 key words into 80 psychologically significant dimensions, we can construct one feature for each of the LIWC."}, {"heading": "4.3 Text categorization", "text": "Unlike the other strategies that have just been discussed, our approach to text categorization in deception detection allows us to model both content and contexts with n-gram characteristics. Specifically, we are looking at the following three n-gram characteristic sets, the corresponding characteristics being small and without trunk: UNIGRAMS, BIGRAMS +, TRIGRAMS +, where the + superscript indicates that the characteristic set subsumes the previous attribute set."}, {"heading": "4.4 Classifiers", "text": "Features from the three approaches just presented are used to train Na\u00efve Bayes and Support VectorMachine classifiers, both of whom have performed well in related work (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Zhou et al., 2008).For a document ~ x, with label y, the Na\u00efve Bayes (NB) classifier gives us the following rule of decision: y = argmax c Pr (y = c) \u00b7 Pr (~ x | y = c) (1) If the class is previously uniform, for example, when the classes are balanced (as in our case), (1) the maximum probability classifier (Peng and Schuurmans, 2003) can be simplified: y = argmax c Pr (~ x | y = c) (2) sub (2), both the NB classifiers used by Mihalcea and Strapparava."}, {"heading": "5 Results and Discussion", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "6 Conclusion and Future Work", "text": "By doing so, we have shown that the detection of misleading opinion spam goes far beyond the capabilities of human judges, most of whom act roughly randomly. Accordingly, we have introduced three automated approaches to detecting misleading opinion spam, based on insights from research in computational linguistics and psychology. We find that while standard n-gram-based text categorization is the best approach to individual recognition, a combination approach with psycholinguistically motivated traits and n-gram traits may work slightly better. Finally, we have made several theoretical contributions. In particular, our results suggest the importance of taking into account both context (e.g. BIGRAMS +) and the underlying motivations for deception, rather than strictly adhering to a universal set of deceptive clues (e.g. LIWC)."}, {"heading": "Acknowledgments", "text": "This work was supported in part by National Science Foundation grants BCS-0624277, BCS0904822, HSD-0624267, IIS-0968450, and NSCC0904822, as well as a gift from Google and the Jack Kent Cooke Foundation. We also thank in alphabetical order Rachel Boochever, Cristian DanescuNiculescu-Mizil, Alicia Granstein, Ulrike Gretzel, Danielle Kirshenblat, Lillian Lee, Bin Lu, Jack Newton, Melissa Sackler, Mark Thomas, and Angie Yoo, as well as members of the Cornell NLP Seminar Group and the ACL reviewers for their insightful comments, suggestions, and advice on various aspects of this work."}], "references": [{"title": "Amazon mechanical turk for subjectivity word sense disambiguation", "author": ["C. Akkaya", "A. Conrad", "J. Wiebe", "R. Mihalcea."], "venue": "Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazons Mechanical Turk, Los Angeles,", "citeRegEx": "Akkaya et al\\.,? 2010", "shortCiteRegEx": "Akkaya et al\\.", "year": 2010}, {"title": "Longman grammar of spoken and written English, volume 2", "author": ["D. Biber", "S. Johansson", "G. Leech", "S. Conrad", "E. Finegan", "R. Quirk."], "venue": "MIT Press.", "citeRegEx": "Biber et al\\.,? 1999", "shortCiteRegEx": "Biber et al\\.", "year": 1999}, {"title": "Accuracy of deception judgments", "author": ["C.F. Bond", "B.M. DePaulo."], "venue": "Personality and Social Psychology Review, 10(3):214.", "citeRegEx": "Bond and DePaulo.,? 2006", "shortCiteRegEx": "Bond and DePaulo.", "year": 2006}, {"title": "Interpersonal deception theory", "author": ["D.B. Buller", "J.K. Burgoon."], "venue": "Communication Theory, 6(3):203\u2013 242.", "citeRegEx": "Buller and Burgoon.,? 1996", "shortCiteRegEx": "Buller and Burgoon.", "year": 1996}, {"title": "An exploration of off topic conversation", "author": ["W.L. Cade", "B.A. Lehman", "A. Olney."], "venue": "Human Language Technologies: The 2010 Annual Conference of", "citeRegEx": "Cade et al\\.,? 2010", "shortCiteRegEx": "Cade et al\\.", "year": 2010}, {"title": "An empirical study of smoothing techniques for language modeling", "author": ["S.F. Chen", "J. Goodman."], "venue": "Proceedings of the 34th annual meeting on Association for Computational Linguistics, pages 310\u2013318. Association for Computational Linguistics.", "citeRegEx": "Chen and Goodman.,? 1996", "shortCiteRegEx": "Chen and Goodman.", "year": 1996}, {"title": "How opinions are received by online communities: a case study on amazon.com helpfulness votes", "author": ["C. Danescu-Niculescu-Mizil", "G. Kossinets", "J. Kleinberg", "L. Lee"], "venue": "In Proceedings of the 18th international conference on World wide web,", "citeRegEx": "Danescu.Niculescu.Mizil et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Danescu.Niculescu.Mizil et al\\.", "year": 2009}, {"title": "Support vector machines for spam categorization", "author": ["H. Drucker", "D. Wu", "V.N. Vapnik."], "venue": "Neural Networks, IEEE Transactions on, 10(5):1048\u20131054.", "citeRegEx": "Drucker et al\\.,? 2002", "shortCiteRegEx": "Drucker et al\\.", "year": 2002}, {"title": "Apples-to-Apples in Cross-Validation Studies: Pitfalls in Classifier Performance Measurement", "author": ["G. Forman", "M. Scholz."], "venue": "ACM SIGKDD Explorations, 12(1):49\u201357.", "citeRegEx": "Forman and Scholz.,? 2009", "shortCiteRegEx": "Forman and Scholz.", "year": 2009}, {"title": "Combating web spam with trustrank", "author": ["Z. Gy\u00f6ngyi", "H. Garcia-Molina", "J. Pedersen."], "venue": "Proceedings of the Thirtieth international conference on Very large data bases-Volume 30, pages 576\u2013587. VLDB Endowment.", "citeRegEx": "Gy\u00f6ngyi et al\\.,? 2004", "shortCiteRegEx": "Gy\u00f6ngyi et al\\.", "year": 2004}, {"title": "On lying and being lied to: A linguistic analysis of deception in computer-mediated communication", "author": ["J.T. Hancock", "L.E. Curry", "S. Goorha", "M. Woodworth."], "venue": "Discourse Processes, 45(1):1\u201323.", "citeRegEx": "Hancock et al\\.,? 2008", "shortCiteRegEx": "Hancock et al\\.", "year": 2008}, {"title": "Online product research", "author": ["J. Jansen."], "venue": "Pew Internet & American Life Project Report.", "citeRegEx": "Jansen.,? 2010", "shortCiteRegEx": "Jansen.", "year": 2010}, {"title": "Opinion spam and analysis", "author": ["N. Jindal", "B. Liu."], "venue": "Proceedings of the international conference on Web search and web data mining, pages 219\u2013230. ACM.", "citeRegEx": "Jindal and Liu.,? 2008", "shortCiteRegEx": "Jindal and Liu.", "year": 2008}, {"title": "Text categorization with support vector machines: Learning with many relevant features", "author": ["T. Joachims."], "venue": "Machine Learning: ECML-98, pages 137\u2013142.", "citeRegEx": "Joachims.,? 1998", "shortCiteRegEx": "Joachims.", "year": 1998}, {"title": "Making large-scale support vector machine learning practical", "author": ["T. Joachims."], "venue": "Advances in kernel methods, page 184. MIT Press.", "citeRegEx": "Joachims.,? 1999", "shortCiteRegEx": "Joachims.", "year": 1999}, {"title": "Reality monitoring", "author": ["M.K. Johnson", "C.L. Raye."], "venue": "Psychological Review, 88(1):67\u201385.", "citeRegEx": "Johnson and Raye.,? 1981", "shortCiteRegEx": "Johnson and Raye.", "year": 1981}, {"title": "Automatically assessing review helpfulness", "author": ["S.M. Kim", "P. Pantel", "T. Chklovski", "M. Pennacchiotti."], "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 423\u2013 430. Association for Computational Linguistics.", "citeRegEx": "Kim et al\\.,? 2006", "shortCiteRegEx": "Kim et al\\.", "year": 2006}, {"title": "Accurate unlexicalized parsing", "author": ["D. Klein", "C.D. Manning."], "venue": "Proceedings of the 41st Annual Meeting on Association for Computational LinguisticsVolume 1, pages 423\u2013430. Association for Computational Linguistics.", "citeRegEx": "Klein and Manning.,? 2003", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "The measurement of observer agreement for categorical data", "author": ["J.R. Landis", "G.G. Koch."], "venue": "Biometrics, 33(1):159.", "citeRegEx": "Landis and Koch.,? 1977", "shortCiteRegEx": "Landis and Koch.", "year": 1977}, {"title": "Detecting product review spammers using rating behaviors", "author": ["E.P. Lim", "V.A. Nguyen", "N. Jindal", "B. Liu", "H.W. Lauw."], "venue": "Proceedings of the 19th ACM international conference on Information and knowledge management, pages 939\u2013948. ACM.", "citeRegEx": "Lim et al\\.,? 2010", "shortCiteRegEx": "Lim et al\\.", "year": 2010}, {"title": "Electronic word-of-mouth in hospitality and tourism management", "author": ["S.W. Litvin", "R.E. Goldsmith", "B. Pan."], "venue": "Tourism management, 29(3):458\u2013468.", "citeRegEx": "Litvin et al\\.,? 2008", "shortCiteRegEx": "Litvin et al\\.", "year": 2008}, {"title": "Using linguistic cues for the automatic recognition of personality in conversation and text", "author": ["F. Mairesse", "M.A. Walker", "M.R. Mehl", "R.K. Moore."], "venue": "Journal of Artificial Intelligence Research, 30(1):457\u2013500.", "citeRegEx": "Mairesse et al\\.,? 2007", "shortCiteRegEx": "Mairesse et al\\.", "year": 2007}, {"title": "The lie detector: Explorations in the automatic recognition of deceptive language", "author": ["R. Mihalcea", "C. Strapparava."], "venue": "Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 309\u2013312. Association for Computational Linguistics.", "citeRegEx": "Mihalcea and Strapparava.,? 2009", "shortCiteRegEx": "Mihalcea and Strapparava.", "year": 2009}, {"title": "Lying words: Predicting deception from linguistic styles", "author": ["M.L. Newman", "J.W. Pennebaker", "D.S. Berry", "J.M. Richards."], "venue": "Personality and Social Psychology Bulletin, 29(5):665.", "citeRegEx": "Newman et al\\.,? 2003", "shortCiteRegEx": "Newman et al\\.", "year": 2003}, {"title": "Detecting spam web pages through content analysis", "author": ["A. Ntoulas", "M. Najork", "M. Manasse", "D. Fetterly."], "venue": "Proceedings of the 15th international conference on World Wide Web, pages 83\u201392. ACM.", "citeRegEx": "Ntoulas et al\\.,? 2006", "shortCiteRegEx": "Ntoulas et al\\.", "year": 2006}, {"title": "Learning to recommend helpful hotel reviews", "author": ["M.P. O\u2019Mahony", "B. Smyth"], "venue": "In Proceedings of the third ACM conference on Recommender systems,", "citeRegEx": "O.Mahony and Smyth.,? \\Q2009\\E", "shortCiteRegEx": "O.Mahony and Smyth.", "year": 2009}, {"title": "Combining naive Bayes and n-gram language models for text classification", "author": ["F. Peng", "D. Schuurmans."], "venue": "Advances in Information Retrieval, pages 547\u2013 547.", "citeRegEx": "Peng and Schuurmans.,? 2003", "shortCiteRegEx": "Peng and Schuurmans.", "year": 2003}, {"title": "The development and psychometric properties of LIWC2007", "author": ["J.W. Pennebaker", "C.K. Chung", "M. Ireland", "A. Gonzales", "R.J. Booth."], "venue": "Austin, TX, LIWC. Net.", "citeRegEx": "Pennebaker et al\\.,? 2007", "shortCiteRegEx": "Pennebaker et al\\.", "year": 2007}, {"title": "Estimating labels from label proportions", "author": ["N. Quadrianto", "A.J. Smola", "T.S. Caetano", "Q.V. Le."], "venue": "The Journal of Machine Learning Research, 10:2349\u2013 2374.", "citeRegEx": "Quadrianto et al\\.,? 2009", "shortCiteRegEx": "Quadrianto et al\\.", "year": 2009}, {"title": "Grammatical word class variation within the British National Corpus sampler", "author": ["P. Rayson", "A. Wilson", "G. Leech."], "venue": "Language and Computers, 36(1):295\u2013 306.", "citeRegEx": "Rayson et al\\.,? 2001", "shortCiteRegEx": "Rayson et al\\.", "year": 2001}, {"title": "Generalized additive models for location, scale and shape", "author": ["R.A. Rigby", "D.M. Stasinopoulos."], "venue": "Journal of the Royal Statistical Society: Series C (Applied Statistics), 54(3):507\u2013554.", "citeRegEx": "Rigby and Stasinopoulos.,? 2005", "shortCiteRegEx": "Rigby and Stasinopoulos.", "year": 2005}, {"title": "Machine learning in automated text categorization", "author": ["F. Sebastiani."], "venue": "ACM computing surveys (CSUR), 34(1):1\u201347.", "citeRegEx": "Sebastiani.,? 2002", "shortCiteRegEx": "Sebastiani.", "year": 2002}, {"title": "Modeling statistical properties of written text", "author": ["M.\u00c1. Serrano", "A. Flammini", "F. Menczer."], "venue": "PloS one, 4(4):5372.", "citeRegEx": "Serrano et al\\.,? 2009", "shortCiteRegEx": "Serrano et al\\.", "year": 2009}, {"title": "SRILM-an extensible language modeling toolkit", "author": ["A. Stolcke."], "venue": "Seventh International Conference on Spoken Language Processing, volume 3, pages 901\u2013 904. Citeseer.", "citeRegEx": "Stolcke.,? 2002", "shortCiteRegEx": "Stolcke.", "year": 2002}, {"title": "Cues to deception and ability to detect lies as a function of police interview styles", "author": ["A. Vrij", "S. Mann", "S. Kristen", "R.P. Fisher."], "venue": "Law and human behavior, 31(5):499\u2013518.", "citeRegEx": "Vrij et al\\.,? 2007", "shortCiteRegEx": "Vrij et al\\.", "year": 2007}, {"title": "Outsmarting the liars: The benefit of asking unanticipated questions", "author": ["A. Vrij", "S. Leal", "P.A. Granhag", "S. Mann", "R.P. Fisher", "J. Hillman", "K. Sperry."], "venue": "Law and human behavior, 33(2):159\u2013166.", "citeRegEx": "Vrij et al\\.,? 2009", "shortCiteRegEx": "Vrij et al\\.", "year": 2009}, {"title": "Detecting lies and deceit: Pitfalls and opportunities", "author": ["A. Vrij."], "venue": "Wiley-Interscience.", "citeRegEx": "Vrij.,? 2008", "shortCiteRegEx": "Vrij.", "year": 2008}, {"title": "Credibility improves topical blog post retrieval", "author": ["W. Weerkamp", "M. De Rijke."], "venue": "ACL-08: HLT, pages 923\u2013931.", "citeRegEx": "Weerkamp and Rijke.,? 2008", "shortCiteRegEx": "Weerkamp and Rijke.", "year": 2008}, {"title": "Automatically assessing the post quality in online discussions on software", "author": ["M. Weimer", "I. Gurevych", "M. M\u00fchlh\u00e4user."], "venue": "Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 125\u2013128. Association", "citeRegEx": "Weimer et al\\.,? 2007", "shortCiteRegEx": "Weimer et al\\.", "year": 2007}, {"title": "Distortion as a validation criterion in the identification of suspicious reviews", "author": ["G. Wu", "D. Greene", "B. Smyth", "P. Cunningham."], "venue": "Technical report, UCD-CSI2010-04, University College Dublin.", "citeRegEx": "Wu et al\\.,? 2010", "shortCiteRegEx": "Wu et al\\.", "year": 2010}, {"title": "Comparison of Deceptive and Truthful Travel Reviews", "author": ["K.H. Yoo", "U. Gretzel."], "venue": "Information and Communication Technologies in Tourism 2009, pages 37\u201347.", "citeRegEx": "Yoo and Gretzel.,? 2009", "shortCiteRegEx": "Yoo and Gretzel.", "year": 2009}, {"title": "A comparison of classification methods for predicting deception in computermediated communication", "author": ["L. Zhou", "J.K. Burgoon", "D.P. Twitchell", "T. Qin", "J.F. Nunamaker Jr."], "venue": "Journal of Management Information Systems, 20(4):139\u2013166.", "citeRegEx": "Zhou et al\\.,? 2004", "shortCiteRegEx": "Zhou et al\\.", "year": 2004}, {"title": "A Statistical Language Modeling Approach to Online Deception Detection", "author": ["L. Zhou", "Y. Shi", "D. Zhang."], "venue": "IEEE Transactions on Knowledge and Data Engineering, 20(8):1077\u20131081.", "citeRegEx": "Zhou et al\\.,? 2008", "shortCiteRegEx": "Zhou et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 11, "context": "Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008).", "startOffset": 65, "endOffset": 100}, {"referenceID": 20, "context": "Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008).", "startOffset": 65, "endOffset": 100}, {"referenceID": 12, "context": ", advertisements, questions, and other irrelevant or nonopinion text (Jindal and Liu, 2008).", "startOffset": 69, "endOffset": 91}, {"referenceID": 13, "context": "Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al.", "startOffset": 167, "endOffset": 201}, {"referenceID": 31, "context": "Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al.", "startOffset": 167, "endOffset": 201}, {"referenceID": 10, "context": "Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al., 2008; Newman et al., 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al.", "startOffset": 413, "endOffset": 456}, {"referenceID": 23, "context": "Specifically, we view the task as: (a) a standard text categorization task, in which we use n-gram\u2013based classifiers to label opinions as either deceptive or truthful (Joachims, 1998; Sebastiani, 2002); (b) an instance of psycholinguistic deception detection, in which we expect deceptive statements to exemplify the psychological effects of lying, such as increased negative emotion and psychological distancing (Hancock et al., 2008; Newman et al., 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al.", "startOffset": 413, "endOffset": 456}, {"referenceID": 1, "context": ", 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al., 1999; Rayson et al., 2001).", "startOffset": 168, "endOffset": 209}, {"referenceID": 29, "context": ", 2003); and, (c) a problem of genre identification, in which we view deceptive and truthful writing as sub-genres of imaginative and informative writing, respectively (Biber et al., 1999; Rayson et al., 2001).", "startOffset": 168, "endOffset": 209}, {"referenceID": 2, "context": "In contrast, we find deceptive opinion spam detection to be well beyond the capabilities of most human judges, who perform roughly at-chance\u2014a finding that is consistent with decades of traditional deception detection research (Bond and DePaulo, 2006).", "startOffset": 227, "endOffset": 251}, {"referenceID": 35, "context": "We also present findings that are consistent with recent work highlighting the difficulties that liars have encoding spatial information (Vrij et al., 2009).", "startOffset": 137, "endOffset": 156}, {"referenceID": 7, "context": "Spam has historically been studied in the contexts of e-mail (Drucker et al., 2002), and the Web (Gy\u00f6ngyi et al.", "startOffset": 61, "endOffset": 83}, {"referenceID": 9, "context": ", 2002), and the Web (Gy\u00f6ngyi et al., 2004; Ntoulas et al., 2006).", "startOffset": 21, "endOffset": 65}, {"referenceID": 24, "context": ", 2002), and the Web (Gy\u00f6ngyi et al., 2004; Ntoulas et al., 2006).", "startOffset": 21, "endOffset": 65}, {"referenceID": 12, "context": "Recently, researchers have began to look at opinion spam as well (Jindal and Liu, 2008; Wu et al., 2010; Yoo and Gretzel, 2009).", "startOffset": 65, "endOffset": 127}, {"referenceID": 39, "context": "Recently, researchers have began to look at opinion spam as well (Jindal and Liu, 2008; Wu et al., 2010; Yoo and Gretzel, 2009).", "startOffset": 65, "endOffset": 127}, {"referenceID": 40, "context": "Recently, researchers have began to look at opinion spam as well (Jindal and Liu, 2008; Wu et al., 2010; Yoo and Gretzel, 2009).", "startOffset": 65, "endOffset": 127}, {"referenceID": 39, "context": "Wu et al. (2010) propose an alternative strategy for detecting deceptive opinion spam in the absence", "startOffset": 0, "endOffset": 17}, {"referenceID": 22, "context": "Newman et al. (2003), and later Mihalcea and Strapparava (2009), ask participants to give both their true and untrue views on personal issues (e.", "startOffset": 0, "endOffset": 21}, {"referenceID": 22, "context": "(2003), and later Mihalcea and Strapparava (2009), ask participants to give both their true and untrue views on personal issues (e.", "startOffset": 18, "endOffset": 50}, {"referenceID": 38, "context": "Lastly, automatic approaches to determining review quality have been studied\u2014directly (Weimer et al., 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al.", "startOffset": 86, "endOffset": 107}, {"referenceID": 6, "context": ", 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al., 2009; Kim et al., 2006; O\u2019Mahony and Smyth, 2009) and credibil-", "startOffset": 44, "endOffset": 126}, {"referenceID": 16, "context": ", 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al., 2009; Kim et al., 2006; O\u2019Mahony and Smyth, 2009) and credibil-", "startOffset": 44, "endOffset": 126}, {"referenceID": 25, "context": ", 2007), and in the contexts of helpfulness (Danescu-Niculescu-Mizil et al., 2009; Kim et al., 2006; O\u2019Mahony and Smyth, 2009) and credibil-", "startOffset": 44, "endOffset": 126}, {"referenceID": 12, "context": "While truthful opinions are ubiquitous online, deceptive opinions are difficult to obtain without resorting to heuristic methods (Jindal and Liu, 2008; Wu et al., 2010).", "startOffset": 129, "endOffset": 168}, {"referenceID": 39, "context": "While truthful opinions are ubiquitous online, deceptive opinions are difficult to obtain without resorting to heuristic methods (Jindal and Liu, 2008; Wu et al., 2010).", "startOffset": 129, "endOffset": 168}, {"referenceID": 12, "context": "While truthful opinions are ubiquitous online, deceptive opinions are difficult to obtain without resorting to heuristic methods (Jindal and Liu, 2008; Wu et al., 2010). In this section, we report our efforts to gather (and validate with human judgments) the first publicly available opinion spam dataset with gold-standard deceptive opinions. Following the work of Yoo and Gretzel (2009), we compare truthful and deceptive positive reviews for hotels found on TripAdvisor.", "startOffset": 130, "endOffset": 389}, {"referenceID": 12, "context": "It has been hypothesized that popular offerings are less likely to become targets of deceptive opinion spam, since the relative impact of the spam in such cases is small (Jindal and Liu, 2008; Lim et al., 2010).", "startOffset": 170, "endOffset": 210}, {"referenceID": 19, "context": "It has been hypothesized that popular offerings are less likely to become targets of deceptive opinion spam, since the relative impact of the spam in such cases is small (Jindal and Liu, 2008; Lim et al., 2010).", "startOffset": 170, "endOffset": 210}, {"referenceID": 39, "context": "\u2022 1,607 reviews written by first-time authors\u2014 new users who have not previously posted an opinion on TripAdvisor\u2014since these opinions are more likely to contain opinion spam, which would reduce the integrity of our truthful review data (Wu et al., 2010).", "startOffset": 237, "endOffset": 254}, {"referenceID": 32, "context": "Work by Serrano et al. (2009) suggests that a log-normal distribution is appropriate for modeling document lengths.", "startOffset": 8, "endOffset": 30}, {"referenceID": 12, "context": "First, there are few other baselines for our classification task; indeed, related studies (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009) have only considered a random guess baseline.", "startOffset": 90, "endOffset": 144}, {"referenceID": 22, "context": "First, there are few other baselines for our classification task; indeed, related studies (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009) have only considered a random guess baseline.", "startOffset": 90, "endOffset": 144}, {"referenceID": 0, "context": "While a similar effect has been observed previously (Akkaya et al., 2010), there remains no universal solution.", "startOffset": 52, "endOffset": 73}, {"referenceID": 30, "context": "We use the R package GAMLSS (Rigby and Stasinopoulos, 2005) to fit the left-truncated log-normal distribution.", "startOffset": 28, "endOffset": 59}, {"referenceID": 36, "context": "Furthermore, all three judges suffer from truth-bias (Vrij, 2008), a common finding in deception detection research in which human judges are more likely to classify an opinion as truthful than deceptive.", "startOffset": 53, "endOffset": 65}, {"referenceID": 36, "context": "We suspect that agreement among our human judges is so low precisely because humans are poor judges of deception (Vrij, 2008), and therefore they perform nearly at-chance respective to one another.", "startOffset": 113, "endOffset": 125}, {"referenceID": 18, "context": "While there is no precise rule for interpreting kappa scores, Landis and Koch (1977) suggest that scores in the range (0.", "startOffset": 62, "endOffset": 85}, {"referenceID": 1, "context": "Work in computational linguistics has shown that the frequency distribution of part-of-speech (POS) tags in a text is often dependent on the genre of the text (Biber et al., 1999; Rayson et al., 2001).", "startOffset": 159, "endOffset": 200}, {"referenceID": 29, "context": "Work in computational linguistics has shown that the frequency distribution of part-of-speech (POS) tags in a text is often dependent on the genre of the text (Biber et al., 1999; Rayson et al., 2001).", "startOffset": 159, "endOffset": 200}, {"referenceID": 27, "context": "The Linguistic Inquiry and Word Count (LIWC) software (Pennebaker et al., 2007) is a popular automated text analysis tool used widely in the social sciences.", "startOffset": 54, "endOffset": 79}, {"referenceID": 17, "context": "We use the Stanford Parser (Klein and Manning, 2003) to obtain the relative POS frequencies.", "startOffset": 27, "endOffset": 52}, {"referenceID": 21, "context": "traits (Mairesse et al., 2007), to study tutoring dynamics (Cade et al.", "startOffset": 7, "endOffset": 30}, {"referenceID": 4, "context": ", 2007), to study tutoring dynamics (Cade et al., 2010), and, most relevantly, to analyze deception (Hancock et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 10, "context": ", 2010), and, most relevantly, to analyze deception (Hancock et al., 2008; Mihalcea and Strapparava, 2009; Vrij et al., 2007).", "startOffset": 52, "endOffset": 125}, {"referenceID": 22, "context": ", 2010), and, most relevantly, to analyze deception (Hancock et al., 2008; Mihalcea and Strapparava, 2009; Vrij et al., 2007).", "startOffset": 52, "endOffset": 125}, {"referenceID": 34, "context": ", 2010), and, most relevantly, to analyze deception (Hancock et al., 2008; Mihalcea and Strapparava, 2009; Vrij et al., 2007).", "startOffset": 52, "endOffset": 125}, {"referenceID": 41, "context": "While other features have been considered in past deception detection work, notably those of Zhou et al. (2004), early experiments found LIWC features to perform best.", "startOffset": 93, "endOffset": 112}, {"referenceID": 12, "context": "Features from the three approaches just introduced are used to train Na\u0131\u0308ve Bayes and Support Vector Machine classifiers, both of which have performed well in related work (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Zhou et al., 2008).", "startOffset": 172, "endOffset": 245}, {"referenceID": 22, "context": "Features from the three approaches just introduced are used to train Na\u0131\u0308ve Bayes and Support Vector Machine classifiers, both of which have performed well in related work (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Zhou et al., 2008).", "startOffset": 172, "endOffset": 245}, {"referenceID": 42, "context": "Features from the three approaches just introduced are used to train Na\u0131\u0308ve Bayes and Support Vector Machine classifiers, both of which have performed well in related work (Jindal and Liu, 2008; Mihalcea and Strapparava, 2009; Zhou et al., 2008).", "startOffset": 172, "endOffset": 245}, {"referenceID": 26, "context": "When the class prior is uniform, for example when the classes are balanced (as in our case), (1) can be simplified to the maximum likelihood classifier (Peng and Schuurmans, 2003):", "startOffset": 152, "endOffset": 179}, {"referenceID": 33, "context": "(2008), we use the SRI Language Modeling Toolkit (Stolcke, 2002) to estimate individual language models, Pr(~x | y = c), for truthful and deceptive opinions.", "startOffset": 49, "endOffset": 64}, {"referenceID": 5, "context": "We consider all three n-gram feature sets, namely UNIGRAMS, BIGRAMS, and TRIGRAMS , with corresponding language models smoothed using the interpolated Kneser-Ney method (Chen and Goodman, 1996).", "startOffset": 169, "endOffset": 193}, {"referenceID": 21, "context": "Under (2), both the NB classifier used by Mihalcea and Strapparava (2009) and the language model classifier used by Zhou et al.", "startOffset": 42, "endOffset": 74}, {"referenceID": 21, "context": "Under (2), both the NB classifier used by Mihalcea and Strapparava (2009) and the language model classifier used by Zhou et al. (2008) are equivalent.", "startOffset": 42, "endOffset": 135}, {"referenceID": 21, "context": "Under (2), both the NB classifier used by Mihalcea and Strapparava (2009) and the language model classifier used by Zhou et al. (2008) are equivalent. Thus, following Zhou et al. (2008), we use the SRI Language Modeling Toolkit (Stolcke, 2002) to estimate individual language models, Pr(~x | y = c), for truthful and deceptive opinions.", "startOffset": 42, "endOffset": 186}, {"referenceID": 14, "context": "We use SVM (Joachims, 1999) to train our linear SVM models on all three approaches and", "startOffset": 11, "endOffset": 27}, {"referenceID": 8, "context": ", from the aggregate true positive, false positive and false negative rates, as suggested by Forman and Scholz (2009). Human performance is repeated here for JUDGE 1, JUDGE 2 and the SKEPTIC meta-judge, although they cannot be directly compared since the 160-opinion subset on which they are assessed only corresponds to the first cross-validation fold.", "startOffset": 93, "endOffset": 118}, {"referenceID": 28, "context": "The deception detection strategies described in Section 4 are evaluated using a 5-fold nested crossvalidation (CV) procedure (Quadrianto et al., 2009), where model parameters are selected for each test fold based on standard CV experiments on the training folds.", "startOffset": 125, "endOffset": 150}, {"referenceID": 36, "context": "untrained humans often focus on unreliable cues to deception (Vrij, 2008).", "startOffset": 61, "endOffset": 73}, {"referenceID": 15, "context": "This result is best explained by theories of reality monitoring (Johnson and Raye, 1981), which suggest that truthful and deceptive opinions might be classified into informative and imaginative genres, respectively.", "startOffset": 64, "endOffset": 88}, {"referenceID": 3, "context": "However, that deceptive opinions contain more superlatives is not unexpected, since deceptive writing (but not necessarily imaginative writing in general) often contains exaggerated language (Buller and Burgoon, 1996; Hancock et al., 2008).", "startOffset": 191, "endOffset": 239}, {"referenceID": 10, "context": "However, that deceptive opinions contain more superlatives is not unexpected, since deceptive writing (but not necessarily imaginative writing in general) often contains exaggerated language (Buller and Burgoon, 1996; Hancock et al., 2008).", "startOffset": 191, "endOffset": 239}, {"referenceID": 13, "context": "This result is best explained by theories of reality monitoring (Johnson and Raye, 1981), which suggest that truthful and deceptive opinions might be classified into informative and imaginative genres, respectively. Work by Rayson et al. (2001) has found strong distributional differences between informative and imaginative writing, namely that the former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs,17 adverbs,18 pronouns, and pre-determiners.", "startOffset": 65, "endOffset": 245}, {"referenceID": 13, "context": "This result is best explained by theories of reality monitoring (Johnson and Raye, 1981), which suggest that truthful and deceptive opinions might be classified into informative and imaginative genres, respectively. Work by Rayson et al. (2001) has found strong distributional differences between informative and imaginative writing, namely that the former typically consists of more nouns, adjectives, prepositions, determiners, and coordinating conjunctions, while the latter consists of more verbs,17 adverbs,18 pronouns, and pre-determiners. Indeed, we find that the weights learned by POSSVM (found in Table 4) are largely in agreement with these findings, notably except for adjective and adverb superlatives, the latter of which was found to be an exception by Rayson et al. (2001). However, that deceptive opinions contain more superlatives is not unexpected, since deceptive writing (but not necessarily imaginative writing in general) often contains exaggerated language (Buller and Burgoon, 1996; Hancock et al.", "startOffset": 65, "endOffset": 789}, {"referenceID": 29, "context": "Based on work by Rayson et al. (2001), we expect weights on the left to be positive (predictive of truthful opinions), and weights on the right to be negative (predictive of deceptive opinions).", "startOffset": 17, "endOffset": 38}, {"referenceID": 15, "context": "In agreement with theories of reality monitoring (Johnson and Raye, 1981), we observe that truthful opinions tend to include more sensorial and concrete language than deceptive opinions; in", "startOffset": 49, "endOffset": 73}, {"referenceID": 34, "context": "This finding is also supported by recent work by Vrij et al. (2009) suggesting that liars have considerable difficultly encoding spatial information into their lies.", "startOffset": 49, "endOffset": 68}, {"referenceID": 10, "context": "We also acknowledge several findings that, on the surface, are in contrast to previous psycholinguistic studies of deception (Hancock et al., 2008; Newman et al., 2003).", "startOffset": 125, "endOffset": 168}, {"referenceID": 23, "context": "We also acknowledge several findings that, on the surface, are in contrast to previous psycholinguistic studies of deception (Hancock et al., 2008; Newman et al., 2003).", "startOffset": 125, "endOffset": 168}, {"referenceID": 3, "context": "This pattern makes sense when one considers the goal of our deceivers, namely to create a positive review (Buller and Burgoon, 1996).", "startOffset": 106, "endOffset": 132}, {"referenceID": 23, "context": "Deception has also previously been associated with decreased usage of first person singular, an effect attributed to psychological distancing (Newman et al., 2003).", "startOffset": 142, "endOffset": 163}], "year": 2011, "abstractText": "Consumers increasingly rate, review and research products online (Jansen, 2010; Litvin et al., 2008). Consequently, websites containing consumer reviews are becoming targets of opinion spam. While recent work has focused primarily on manually identifiable instances of opinion spam, in this work we study deceptive opinion spam\u2014fictitious opinions that have been deliberately written to sound authentic. Integrating work from psychology and computational linguistics, we develop and compare three approaches to detecting deceptive opinion spam, and ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset. Based on feature analysis of our learned models, we additionally make several theoretical contributions, including revealing a relationship between deceptive opinions and imaginative writing.", "creator": "dvips(k) 5.98 Copyright 2009 Radical Eye Software"}}}