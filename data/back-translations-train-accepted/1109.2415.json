{"id": "1109.2415", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2011", "title": "Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization", "abstract": "We consider the problem of optimizing the sum of a smooth convex function and a non-smooth convex function using proximal-gradient methods, where an error is present in the calculation of the gradient of the smooth term or in the proximity operator with respect to the non-smooth term. We show that both the basic proximal-gradient method and the accelerated proximal-gradient method achieve the same convergence rate as in the error-free case, provided that the errors decrease at appropriate rates.Using these rates, we perform as well as or better than a carefully chosen fixed error level on a set of structured sparsity problems.", "histories": [["v1", "Mon, 12 Sep 2011 09:45:02 GMT  (134kb,D)", "http://arxiv.org/abs/1109.2415v1", null], ["v2", "Thu, 1 Dec 2011 16:06:06 GMT  (120kb,D)", "http://arxiv.org/abs/1109.2415v2", "Neural Information Processing Systems (2011)"]], "reviews": [], "SUBJECTS": "cs.LG math.OC", "authors": ["mark w schmidt", "nicolas le roux", "francis r bach"], "accepted": true, "id": "1109.2415"}, "pdf": {"name": "1109.2415.pdf", "metadata": {"source": "CRF", "title": "Convergence Rates of Inexact Proximal-Gradient Methods for Convex Optimization", "authors": ["Mark Schmidt", "Nicolas Le Roux"], "emails": ["mark.schmidt@inria.fr", "nicolas@le-roux.name", "francis.bach@ens.fr"], "sections": [{"heading": "1 Introduction", "text": "(the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the) (the (the) (the) (the) (the (the) (the) (the) (the) (the (the) (the) (the (the) (the) (the (the) (the) (the (the) (the) (the (the) (the (the) (the) (the (the) (the (the) (the) (the) (the (the (the) (the) (the) (the (the (the) (the) (the) (the) (the) (the (the (the (the) (the (the) (the (the (the) (the (the) (the) (the (the (the) (the) (the (the) (the) (the (the) ((the) (the) (the) (the) (the) (the) (the (the (the) ((the (the) (the) (the) ((the) (the (the) ((the) (the (the) (the) (the) (("}, {"heading": "2 Related Work", "text": "In this year, it has come to the point where one sees oneself in a position to live in a country in which most people are able to move into another world, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they, in which they live, in which they"}, {"heading": "3 Notation and Assumptions", "text": "In this paper, we assume that the smooth function g in (1) is convex and differentiable, and we assume that its gradient g is \"Lipschitz continuous with constant L, which means that we have a smooth g\" (x) -g \"(y) -y for all x and y in Rd.\" However, this is a standard assumption for differentiable optimization, see [28, \u00a7 2.1.1]. If g is doubly differentiable, this corresponds to the assumption that the eigenvalues of its Hessian are limited by L. For the evidence in sections 4.3 and 4.4, we also assume that g is a strongly convex function (see [28, \u00a7 2.1.3], which means that for all x and y in Rd we haveg (y) > g (x) > g, \"x,\" y \u2212 x. \""}, {"heading": "4 Convergence Rates of Inexact Proximal-Gradient Methods", "text": "In this section we present the analysis of convergence rates of inaccurate proximal gradient methods depending on the sequence of solving accuracies of the proximal problems (\u03b5k) and the sequence of orders of magnitude of errors in the gradient calculations."}, {"heading": "4.1 Basic proximal-gradient method with errors in the convex case", "text": "First, let us consider the basic proximal gradient method in the case of the convex: Proposition 1 (Basic Proximal Gradient Method with Errors - Convexity) Suppose that \u2022 g is convex and has an L-Lipschitz continuous gradient; \u2022 h is a lower semi-continuous eigenconvex function; \u2022 the function f = g + h reaches its minimum at a certain x-convergence; \u2022 We iterate recursion (3) with yk = xk; \u2022 xk is a \u03b5k-optimal solution to the proximal problem (2) in the sense of (4). Note: For all k > 1, convergence (1k \u00b2 i = 1 xi) \u2212 f (x \u00b2) 6 L2k (x \u00b2) + 2Ak + 2Bk + 2Bk) 2, (5) with convergence, convergence is not possible, (5) with Ak = \u00b2."}, {"heading": "4.2 Accelerated proximal-gradient method with errors in the convex case", "text": "We will now focus on a basic variant of the algorithm where \u03b2k is set to (k \u2212 1) / (k + 2) [30]: Proposition 2 (Accelerated Proximal Gradient Method with Errors). \u2022 The function f = g + h reaches its minimum with a certain x method with Errors. \u2022 We iterate the recursion (3) with yk = xk + k \u2212 1k \u2212 2 (xk \u2212 xk \u2212 1). \u2022 xk is an optimal solution to the proximal problem (2)."}, {"heading": "4.3 Basic proximal-gradient method with errors in the strongly convex case", "text": "In the case where g is strongly convex, it is possible to obtain linear convergence rates that depend on the ratio \u03b3 = \u00b5L, as opposed to the sublinear convergence rates discussed above. Specifically, we obtain the following convergence rate for the iterations of the basic proximal convergence method for strongly convex targets: Proposition 3 (basic proximal convergence method with errors - strong convergence) Suppose \u2022 g is strongly convex and has an L-tip continuous gradient; \u2022 h is a lower semi-continuous eigenconvex function; \u2022 the function f = g + h reaches its minimum at a certain x-shaped Rn; \u2022 We iterate the convergence (3) with yk = xk; \u2022 xk is a co-optimal solution to the proximal problem (2) in the sense of (4). Then we have for all convergence > 1 & xx \u2212 convergence."}, {"heading": "4.4 Accelerated proximal-gradient method with errors in the strongly convex case", "text": "Finally, we will consider the accelerated proximal gradient algorithm when g is strongly convex. We will focus on a basic variant of the algorithm where \u03b2k is set to (1 \u2212 270 \u03b3) / (1 \u2212 270 \u03b3) [28, paragraph 2.2.1]: Proposition 4 (Accelerated proximal gradient method with errors - Strong convexity) Suppose that \u2022 g is strongly convex and has an L-lipschitz continuous gradient; \u2022 h is a lower semi-continuous eigenconvex function; \u2022 The function f = g + h reaches its minimum for a specific x problem."}, {"heading": "5 Experiments", "text": "We tested the basic inexact proximal gradients and accelerated proximal gradients, as in this case no exact methods are known. We tested the basic inexact proximal gradients and accelerated proximal gradients methods on the CUR-like factorization optimization problems introduced in [31] to get an approximate proximal gradient method. We tested the basic proximal gradients and accelerated proximal gradient methods on the basis of the CUR-like factorization optimization problems on the basis of CUR-like factorization optimization problems on the basis of CUR-like factorization optimization problems introduced in the UR methodology. We tested the basic proximalization methods on the basis of CUR-like factorization optimization problems."}, {"heading": "6 Discussion", "text": "An alternative to imprecise proximal methods for solving structured sparsity problems are smoothing methods [33] and alternative direction methods [34]. However, a major disadvantage of these two approaches is that the iterations are not sparse, so they cannot take advantage of the sparseness of the problem when executing the algorithm. In contrast, the method proposed in this paper has the attractive property of tending to generate sparse iterations. Moreover, the accelerated smoothing method only has a convergence rate of O (1 / k), and the performance of alternative direction methods is often sensitive to the exact choice of its penalty parameter. On the other hand, our analysis suggests that the use of a sequence of errors such as O (1 / k\u03b1) is sufficiently large, the practical performance of imprecise proximal gradients methods are sensitive to the exact choice of this sequence. Although we do not have the use of our results in the framework of a structured sparsity problem to illustrate the degree problem."}, {"heading": "Acknowledgements", "text": "Mark Schmidt, Nicolas Le Roux and Francis Bach are partly supported by the European Research Council (SIERRA-ERC-239993)."}, {"heading": "Appendix: Proofs of the propositions", "text": "We first prove a dilemma used for the propositions. Lemma 1 > Suppose the non-negative sequence uk fulfills the following recursion for all k > 1: u2k 6 Bk + k \u00b2 i = 1 \u03bbiui, with {Bk} an increasing sequence, B0 > u20 and \u03bbi > 0 for all i. We assume that it applies to k > 1, and we label it with vk \u2212 1 = max {u1,., uk \u2212 1}. Thus, from the recursion we obtain (uk \u2212 k / 2) properties of k = 0 (by assuming). We assume that it applies to k \u2212 1, namely with vk \u2212 1 = max {u1,., uk \u2212 1}."}, {"heading": "6.1 Basic proximal-gradient method with errors in the convex case", "text": "Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212. \u2212 Proof. \u2212 Proof. \u2212. \u2212. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212 Proof. \u2212"}, {"heading": "6.1.1 Bounding \u2016xi \u2212 x\u2217\u2016", "text": "We must now limit the quantities in Eq. (9), which are positive due to the optimality of f (x), to Eq. (9). We now have the possibility to use Lemma 1 (using A = x0 \u2212 x) and 2 + 2L k = 1 \u03b5i + 2 k = 1 [(egg) and 2 k = 1 [(egg) L + 2\u03b5i L) to obtain the quantity. (Ei) L + 2\u03b5i L = 1 (egg). We can now use Lemma 1 (using A = x0 \u2212 x) to obtain the quantity. (Ei) L + 2\u03b5i = 1 (egg)."}, {"heading": "6.1.2 Bounding the function values", "text": "Now that we have a common border for all countries with i 6 k, we can superficially delimit the right side of equation (9) by using only terms that depend on the terms \"x0\" \u2212 x, \"ei\" and \"i.\" In fact, discarding L2 \"xk\" -x \"2,\" which is positive, becomes equation (9) \"i\" = 1 [f (xi) \u2212 f (x)] 6 L 2 \"x0 \u2212 x\" 2 + LBk + LAk (Ak + x0 \u2212 x \"2Bk + Ak) 6 L2\" x0 \u2212 x \"2 + LBk + 2LA2k\" x0 \u2212 x \"2\" (1k \"i = 1 xi) \u2212 f (x) 6\" k \"i\" (x0 \u2212 k) = 1 \"b\" (2k \")."}, {"heading": "6.2 Accelerated proximal-gradient method with errors in the convex case", "text": "We now give the proof of proposition 2.Proof defining \u03b8k = 2 / (k + 1) < vk = 1 + > & k (xk \u2212 xk \u2212 1), we can update for yk \u2212 k = (1 \u2212 k + 1) xk + 1vk because (1 \u2212 k + 1) xk + 1vk because (1 \u2212 k + 1) xk + 1vk = (1 \u2212 2k \u2212 2) xk \u2212 k + 2 [xk \u2212 k + 12 (xk \u2212 1)] (xk \u2212 k + 2vk because (xk \u2212 1) 2k \u2212 f (xk \u2212 1), xk \u2212 k \u2212 k \u2212 k \u2212 2 (xk \u2212 1 + 1) [xk \u2212 k \u2212 k + 12 (xk \u2212 k \u2212 12)] (xk \u2212 k \u2212 \u2212 k \u2212 \u2212 1)] [xk \u2212 k \u2212 k \u2212 k \u2212 k \u2212 1), xk \u2212 k \u2212 k \u2212 k \u2212 \u2212 k \u2212 \u2212 k \u2212 \u2212 k \u2212 \u2212 \u2212 \u2212 k, xk \u2212 k \u2212 k \u2212 k \u2212 -1), we can update for yk \u2212 k = (1 \u2212 k + 1) xk \u2212 k + 1vk + 1vk = (1 \u2212 k \u2212 1), we can update for xk \u2212 k \u2212 k \u2212 k \u2212 k + 1vk + 1vk = (1 \u2212 k \u2212 1), we can update for yk \u2212 k \u2212 k \u2212 k \u2212 k + 1vk = (1 \u2212 k \u2212 k \u2212 1)."}, {"heading": "6.2.1 Bounding \u2016vi \u2212 x\u2217\u2016", "text": "We must now look at the quantities in the terms \"x0\" x \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i.\" i. \".\". \".\""}, {"heading": "6.2.2 Bounding the function values", "text": "If we drop Ld2 in Equation (13) (because it is positive), we have to do it with (xk) - f (x) 6 Ld2 (x0 \u2212 x) 2 + 2B + 2A + 2A + 2A + 2A + 2A + 2B + 2K]) 6 Ld2 (x0 \u2212 x) 2 + 2B + 2A + 2K + 2K + 2K + 4A + 2K + 2K + 2B + 2K) 6 Ld2 (x0 \u2212 x) + 2A (x0 \u2212 x) + 2K + 2K) 2 and 1Kd2 (f (xk) \u2212 f (x)) 6L2 (x0 \u2212 x + 2A + 2K) 2."}, {"heading": "6.3 Basic proximal-gradient method with errors in the strongly convex case", "text": "The following is the proof for the proposition 3. \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k k k k k k k k k k k k k k k k k k k k k k k k k k k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k k k \u2212 k \u2212 k \u2212 k \u2212 k k \u2212 k \u2212 k \u2212 k \u2212 k k \u2212 k \u2212 k \u2212 k \u2212 k k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k \u2212 k k k \u2212 k \u2212 k k k k k k k k k k k k k k k k k k k k k k k k \u2212 k k k k k k k k k k k \u2212 k k k k k k \u2212 k \u2212 k k k k k k k k k k k k k k \u2212 k"}, {"heading": "6.4 Accelerated proximal-gradient method with errors in the strongly convex case", "text": "We now give the proof for Proposition 4.Proof We have (after [28]) xk \u2212 k \u2212 k = 1 \u2212 1 + 1 L g (yk \u2212 1). We define \u2212 2k = (1 \u2212 \u2212 \u2212 \u2212 k). \u2212 1 + 1 + 1 l \u2212 kvk = xk \u2212 1 (xk \u2212 1) l (xk \u2212 1) l (xk \u2212 1) l (xk \u2212 1) l (xk \u2212 1) l (xk \u2212 xk \u2212 \u2212 k). If we decide, then this sum (xk + 1 \u2212 k) l (xk \u2212 1) l (xk \u2212 f (xk \u2212 1) results."}, {"heading": "6.4.1 Bounding \u2016vi \u2212 x\u2217\u2016", "text": "We will now use Lemma 1 to bind the value of \"vk\" - x \"t\" -. Since \"vk\" - x \"t\" 2 is limited by \"vk\" (with \"v\") (with \"v.\" (15)), we can \"vk\" - x \"v\" 2 \"6\" (1 \"p\" l \") k [\u03b40 + k\" t = 1 \"p\" (1 \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"\" p \"\" p \"t\" p \"p\" p \"p\" \"p\" p \"\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" \"p\" p \"p\" \"p\" p \"\" p \"t\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" \"p\" p \"p\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" \"p\" p \"\" p \"p\" p \"p\" p \"p\" p \"\" p \"p\" p \"\" \"p\" p \"p\" p \"\" p \"p\" p \"\" p \"p\" p \"p\""}, {"heading": "6.4.2 Bounding the function values", "text": "The labelling Ak = 1 fic = 1 fic + 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 1 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 1 c = 1 c = 1 c = 0 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c c = 2 c c = 2 c = 2 c c = 2 c = 2 c c = 2 c = 2 c = 2 c c = 2 c c = 2 c = 2 c = 2 c = 2 c c = 2 c = 2 c = 2 c = 2 c = 2 c c = 2 c = 2 c = 2 c = 2 c = 2 c = 2 c c = 2 c = 2 c c = 2 c = 2 c = 2 c c = 2 c = 2 c c = 2 c = 2 c = 2 c = 2 c = 1 c = 1 c = 1 c = 2 c = 2 c = 1 c = 2 c c = 1 c = 2 c = 2 c c = 1 c = 1 c c = 1 c = 2 c = 2 c = 1 c c c = 1 c = 2 c c c = 1 c = 1 c = 1 c = 1 c = 1 c = 2 c c = 1 c = 1 c = 1 c = 1 c = 2 c = 1 c c = 2 c c c c = 1 c = 2 c c c c = 1 c = 1 c = 2 c c = 1 c = 2 c c = 1 c = 2 c = 2 c c c c c c = 1 c c = 1 c = 2 c c = 2 c c c c c c c c = 2 c c c c c = 2 c c c c c c = 1 c c c c c c c = 1 c c c c"}], "references": [{"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences, 2(1):183\u2013202", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "Gradient methods for minimizing composite objective function", "author": ["Y. Nesterov"], "venue": "CORE Discussion Papers, ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Regression shrinkage and selection via the Lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society: Series B, 58(1):267\u2013288", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1996}, {"title": "Atomic decomposition by basis pursuit", "author": ["S.S. Chen", "D.L. Donoho", "M.A. Saunders"], "venue": "SIAM Journal on Scientific Computing, 20(1):33\u201361", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1998}, {"title": "Sparse reconstruction by separable approximation", "author": ["S.J. Wright", "R.D. Nowak", "M.A.T. Figueiredo"], "venue": "IEEE Transactions on Signal Processing, 57(7):2479\u20132493", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Convex optimization with sparsityinducing norms", "author": ["F. Bach", "R. Jenatton", "J. Mairal", "G. Obozinski"], "venue": "S. Sra, S. Nowozin, and S.J. Wright, editors, Optimization for Machine Learning. MIT Press", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Total variation projection with first order schemes", "author": ["J. Fadili", "G. Peyr\u00e9"], "venue": "IEEE Transactions on Image Processing, 20(3):657\u2013669", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "Graph-structured multi-task regression and an efficient optimization method for general fused Lasso", "author": ["X. Chen", "S. Kim", "Q. Lin", "J.G. Carbonell", "E.P. Xing"], "venue": "arXiv:1005.3579v1", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["J.-F. Cai", "E.J. Cand\u00e8s", "Z. Shen"], "venue": "SIAM Journal on Optimization, 20(4)", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Fixed point and Bregman iterative methods for matrix rank minimization", "author": ["S. Ma", "D. Goldfarb", "L. Chen"], "venue": "Mathematical Programming, 128(1):321\u2013353", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Group Lasso with overlap and graph Lasso", "author": ["L. Jacob", "G. Obozinski", "J.-P. Vert"], "venue": "ICML", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Proximal methods for sparse hierarchical dictionary learning", "author": ["R. Jenatton", "J. Mairal", "G. Obozinski", "F. Bach"], "venue": "ICML", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Fast Newton-type methods for total variation regularization", "author": ["A. Barbero", "S. Sra"], "venue": "ICML", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Fast overlapping group Lasso", "author": ["J. Liu", "J. Ye"], "venue": "arXiv:1009.0306v1", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "Convex structure learning in log-linear models: Beyond pairwise potentials", "author": ["M. Schmidt", "K. Murphy"], "venue": "AISTATS", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "A unified framework of descent algorithms for nonlinear programs and variational inequalities", "author": ["M. Patriksson"], "venue": "PhD thesis, Department of Mathematics, Link\u00f6ping University, Sweden", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1995}, {"title": "Solving monotone inclusions via compositions of nonexpansive averaged operators", "author": ["P.L. Combettes"], "venue": "Optimization, 53(5-6):475\u2013504", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2004}, {"title": "Efficient online and batch learning using forward backward splitting", "author": ["J. Duchi", "Y. Singer"], "venue": "JMLR, 10:2873\u20132898", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2009}, {"title": "Sparse online learning via truncated gradient", "author": ["J. Langford", "L. Li", "T. Zhang"], "venue": "JMLR, 10:777\u2013801", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Smooth optimization with approximate gradient", "author": ["A. d\u2019Aspremont"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Estimate sequence methods: extensions and approximations", "author": ["M. Baes"], "venue": "Ifor internal report, ETH Zurich, Switzerland", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "First-order methods of smooth convex optimization with inexact oracle", "author": ["O. Devolder", "F. Glineur", "Y. Nesterov"], "venue": "CORE Discussion Papers, ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "Convergence rate of incremental subgradient algorithms", "author": ["A. Nedic", "D. Bertsekas"], "venue": "Stochastic Optimization: Algorithms and Applications, pages 263\u2013304", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2000}, {"title": "Error bounds and convergence analysis of feasible descent methods: A general approach", "author": ["Z.-Q. Luo", "P. Tseng"], "venue": "Annals of Operations Research, 46-47(1):157\u2013178", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1993}, {"title": "Hybrid deterministic-stochastic methods for data fitting", "author": ["M.P. Friedlander", "M. Schmidt"], "venue": "arXiv:1104.2373", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Monotone operators and the proximal point algorithm", "author": ["R.T. Rockafellar"], "venue": "SIAM Journal on Control and Optimization, 14(5):877\u2013898", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1976}, {"title": "New proximal point algorithms for convex minimization", "author": ["O. G\u00fcler"], "venue": "SIAM Journal on Optimization, 2(4):649\u2013664", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1992}, {"title": "Introductory Lectures on Convex Optimization: A Basic Course", "author": ["Y. Nesterov"], "venue": "Springer", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2004}, {"title": "Convex optimization theory", "author": ["D.P. Bertsekas"], "venue": "Athena Scientific", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2009}, {"title": "On accelerated proximal gradient methods for convex-concave optimization", "author": ["P. Tseng"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2008}, {"title": "Convex and network flow optimization for structured sparsity", "author": ["J. Mairal", "R. Jenatton", "G. Obozinski", "F. Bach"], "venue": "arXiv:1104.1872v1", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2011}, {"title": "A Dykstra-like algorithm for two monotone operators", "author": ["H.H. Bauschke", "P.L. Combettes"], "venue": "Pacific Journal of Optimization, 4(3):383\u2013391", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2008}, {"title": "Smooth minimization of non-smooth functions", "author": ["Y. Nesterov"], "venue": "Mathematical Programming, 103(1):127\u2013152", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Proximal splitting methods in signal processing", "author": ["P.L. Combettes", "J.C. Pesquet"], "venue": "arXiv:0912.3522v4", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2010}, {"title": "Tree-reweighted belief propagation algorithms and approximate ML estimation by pseudo-moment matching", "author": ["M.J. Wainwright", "T.S. Jaakkola", "A.S. Willsky"], "venue": "AISTATS", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2003}, {"title": "Online learning with kernels", "author": ["J. Kivinen", "A.J. Smola", "R.C. Williamson"], "venue": "IEEE Transactions on Signal Processing, 52(8):2165\u20132176", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2004}, {"title": "Subsampling algorithms for semidefinite programming", "author": ["A. d\u2019Aspremont"], "venue": "arXiv:0803.1990v5,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Projected Newton-type methods in machine learning", "author": ["M. Schmidt", "D. Kim", "S. Sra"], "venue": "S. Sra, S. Nowozin, and S Wright, editors, Optimization for Machine Learning. MIT Press", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "Convex Analysis and Optimization", "author": ["D.P. Bertsekas", "A. Nedi\u0107", "A.E. Ozdaglar"], "venue": "Athena Scientific", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "Proximal-gradient methods and accelerated proximal-gradient methods [1, 2] are among the most important methods for taking advantage of the structure of many of the nonsmooth optimization problems that arise in practice.", "startOffset": 68, "endOffset": 74}, {"referenceID": 1, "context": "Proximal-gradient methods and accelerated proximal-gradient methods [1, 2] are among the most important methods for taking advantage of the structure of many of the nonsmooth optimization problems that arise in practice.", "startOffset": 68, "endOffset": 74}, {"referenceID": 2, "context": "One of the most well-studied instances of this type of problem is `1-regularized least squares [3, 4], minimize x\u2208Rd \u2016Ax\u2212 b\u2016 + \u03bb\u2016x\u20161,", "startOffset": 95, "endOffset": 101}, {"referenceID": 3, "context": "One of the most well-studied instances of this type of problem is `1-regularized least squares [3, 4], minimize x\u2208Rd \u2016Ax\u2212 b\u2016 + \u03bb\u2016x\u20161,", "startOffset": 95, "endOffset": 101}, {"referenceID": 0, "context": "While classical subgradient methods only achieve an error level on the objective function of O(1/ \u221a k) after k iterations, proximal-gradient methods have an error of O(1/k) while accelerated proximal-gradient methods futher reduce this to O(1/k2) [1, 2].", "startOffset": 247, "endOffset": 253}, {"referenceID": 1, "context": "While classical subgradient methods only achieve an error level on the objective function of O(1/ \u221a k) after k iterations, proximal-gradient methods have an error of O(1/k) while accelerated proximal-gradient methods futher reduce this to O(1/k2) [1, 2].", "startOffset": 247, "endOffset": 253}, {"referenceID": 4, "context": "We can efficiently compute an analytic solution to this problem for several notable choices of h, including the case of `1-regularization and disjoint group `1-regularization [5, 6].", "startOffset": 175, "endOffset": 181}, {"referenceID": 5, "context": "We can efficiently compute an analytic solution to this problem for several notable choices of h, including the case of `1-regularization and disjoint group `1-regularization [5, 6].", "startOffset": 175, "endOffset": 181}, {"referenceID": 6, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 130, "endOffset": 136}, {"referenceID": 7, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 130, "endOffset": 136}, {"referenceID": 8, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 223, "endOffset": 230}, {"referenceID": 9, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 223, "endOffset": 230}, {"referenceID": 10, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 318, "endOffset": 326}, {"referenceID": 11, "context": "This includes important problems such as total-variation regularization and its generalizations like the graph-guided fused-LASSO [7, 8], nuclearnorm regularization and other regularizers on the singular values of matrices [9, 10], and different formulations of overlapping group `1-regularization with general groups [11, 12].", "startOffset": 318, "endOffset": 326}, {"referenceID": 6, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 392, "endOffset": 399}, {"referenceID": 12, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 392, "endOffset": 399}, {"referenceID": 8, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 558, "endOffset": 565}, {"referenceID": 9, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 558, "endOffset": 565}, {"referenceID": 11, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 742, "endOffset": 754}, {"referenceID": 13, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 742, "endOffset": 754}, {"referenceID": 14, "context": "Despite the difficulty in computing the exact proximity operator for these regularizers, efficient methods have been developed to compute approximate proximity operators in all of these cases; accelerated projected gradient and Newton-like methods that work with a smooth dual problem have been used to compute approximate proximity operators in the context of total-variation regularization [7, 13], Krylov subspace methods and low-rank representations have been used to compute approximate proximity operators in the context of nuclear-norm regularization [9, 10], and variants of Dykstra\u2019s algorithm (and related dual methods) have been used to compute approximate proximity operators in the context of overlapping group `1-regularization [12, 14, 15].", "startOffset": 742, "endOffset": 754}, {"referenceID": 15, "context": "It is known that proximal-gradient methods that use an approximate proximity operator converge under only weak assumptions [16, 17]; we briefly review this and other related work in the next section.", "startOffset": 123, "endOffset": 131}, {"referenceID": 16, "context": "It is known that proximal-gradient methods that use an approximate proximity operator converge under only weak assumptions [16, 17]; we briefly review this and other related work in the next section.", "startOffset": 123, "endOffset": 131}, {"referenceID": 6, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 12, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 8, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 9, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 13, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 14, "context": "However, despite the many recent works showing impressive empirical performance of (accelerated) proximal-gradient methods that use an approximate proximity operator [7, 13, 9, 10, 14, 15], we are not aware of any theoretical analysis on how the error in the calculation of the proximity operator affects the convergence rate of proximal-gradient methods.", "startOffset": 166, "endOffset": 188}, {"referenceID": 17, "context": "For example, when the ek are independent, zero-mean, and finitevariance random variables then proximal-gradient methods achieve the (optimal) error level of O(1/ \u221a k) [18, 19].", "startOffset": 167, "endOffset": 175}, {"referenceID": 18, "context": "For example, when the ek are independent, zero-mean, and finitevariance random variables then proximal-gradient methods achieve the (optimal) error level of O(1/ \u221a k) [18, 19].", "startOffset": 167, "endOffset": 175}, {"referenceID": 19, "context": "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.", "startOffset": 235, "endOffset": 247}, {"referenceID": 20, "context": "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.", "startOffset": 235, "endOffset": 247}, {"referenceID": 21, "context": "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.", "startOffset": 235, "endOffset": 247}, {"referenceID": 22, "context": "Several authors have recently analyzed the case of a fixed deterministic error in the gradient, and shown that accelerated gradient methods achieve the optimal convergence rate up to some accuracy that depends on the fixed error level [20, 21, 22], while the earlier work of [23] analyzes the gradient method in the context of a fixed error level.", "startOffset": 275, "endOffset": 279}, {"referenceID": 23, "context": "Other authors have analyzed the convergence rate of the gradient and projected-gradient methods with a decreasing sequence of errors [24, 25], but this analysis does not consider the important class of accelerated gradient methods.", "startOffset": 133, "endOffset": 141}, {"referenceID": 24, "context": "Other authors have analyzed the convergence rate of the gradient and projected-gradient methods with a decreasing sequence of errors [24, 25], but this analysis does not consider the important class of accelerated gradient methods.", "startOffset": 133, "endOffset": 141}, {"referenceID": 21, "context": "In contrast, the analysis of [22] allows a decreasing sequence of errors without assuming strong convexity (though convergence rates in this context are not explicitly mentioned) and considers the accelerated projectedgradient method.", "startOffset": 29, "endOffset": 33}, {"referenceID": 20, "context": "The analysis of [21] considers errors in both the gradient and projection operators for accelerated projected-gradient methods, but this analysis requires that the domain of the function is compact.", "startOffset": 16, "endOffset": 20}, {"referenceID": 25, "context": "In the context of proximal-point algorithms, there is a substantial literature on using inexact proximity operators with a decreasing sequence of errors, dating back to the seminal work of Rockafeller [26].", "startOffset": 201, "endOffset": 205}, {"referenceID": 26, "context": "Accelerated proximal-point methods with a decreasing sequence of errors have also been examined, beginning with [27].", "startOffset": 112, "endOffset": 116}, {"referenceID": 15, "context": "For example, we can establish that inexact proximal-gradient methods converge under some minor closedness assumptions on the mapping induced by the approximate proximity operator, and the assumption that the algorithm used to compute the inexact proximity operator achieves sufficient descent on problem (2) compared to the previous iteration xk\u22121 [16].", "startOffset": 348, "endOffset": 352}, {"referenceID": 16, "context": "Convergence of inexact proximalgradient methods can also be established under the assumption that the norms of the errors are summable [17].", "startOffset": 135, "endOffset": 139}, {"referenceID": 6, "context": "Indeed, as pointed out by [7], even convergence of the accelerated proximalgradient method has not been established under an inexact proximity operator.", "startOffset": 26, "endOffset": 29}, {"referenceID": 6, "context": "This gap in the theory is one of the reasons why the authors of [7] chose to use the non-accelerated variant of the proximal-gradient algorithm.", "startOffset": 64, "endOffset": 67}, {"referenceID": 11, "context": ", see [12] for the case of overlapping group `1-regularization).", "startOffset": 6, "endOffset": 10}, {"referenceID": 29, "context": "We focus on a basic variant of the algorithm where \u03b2k is set to (k \u2212 1)/(k + 2) [30]: Proposition 2 (Accelerated proximal-gradient method with errors) Assume that", "startOffset": 80, "endOffset": 84}, {"referenceID": 21, "context": "Hence, as also discussed in [22], unlike in the error-free case the accelerated method may not necessarily be better than the basic method because it is more sensitive to errors in the computation.", "startOffset": 28, "endOffset": 32}, {"referenceID": 30, "context": "We tested the basic inexact proximal-gradient and accelerated proximal-gradient methods on the CUR-like factorization optimization problem introduced in [31] to approximate a", "startOffset": 153, "endOffset": 157}, {"referenceID": 30, "context": "In [31], the authors used an accelerated proximal-gradient method and chose p = \u221e since under this choice the proximity operator can be computed exactly.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "In this case, it is possible to very quickly compute an approximate proximity operator using the block coordinate descent (BCD) algorithm presented in [12], which is equivalent to the proximal variant of Dykstra\u2019s algorithm introduced by [32].", "startOffset": 151, "endOffset": 155}, {"referenceID": 31, "context": "In this case, it is possible to very quickly compute an approximate proximity operator using the block coordinate descent (BCD) algorithm presented in [12], which is equivalent to the proximal variant of Dykstra\u2019s algorithm introduced by [32].", "startOffset": 238, "endOffset": 242}, {"referenceID": 30, "context": "In our experiments, we used the four data sets examined by [31]1 and we choose \u03bbrow = .", "startOffset": 59, "endOffset": 63}, {"referenceID": 32, "context": "An alternative to inexact proximal methods for solving structured sparsity problems are smoothing methods [33] and alternating direction methods [34].", "startOffset": 106, "endOffset": 110}, {"referenceID": 33, "context": "An alternative to inexact proximal methods for solving structured sparsity problems are smoothing methods [33] and alternating direction methods [34].", "startOffset": 145, "endOffset": 149}, {"referenceID": 6, "context": "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.", "startOffset": 195, "endOffset": 201}, {"referenceID": 7, "context": "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.", "startOffset": 195, "endOffset": 201}, {"referenceID": 8, "context": "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.", "startOffset": 219, "endOffset": 226}, {"referenceID": 9, "context": "Although we have illustrated the use of our results in the context of a structured sparsity problem, inexact proximal-gradient methods are also used in other applications such as total-variation [7, 8] and nuclear-norm [9, 10] regularization.", "startOffset": 219, "endOffset": 226}, {"referenceID": 34, "context": "For example, errors in the calculation of the gradien arise when fitting undirected graphical models and using an iterative method to approximate the gradient of the log-partition function [35].", "startOffset": 189, "endOffset": 193}, {"referenceID": 35, "context": "Other examples include using a reduced set of training examples within kernel methods [36], or subsampling to solve semidefinite programming problems [37].", "startOffset": 86, "endOffset": 90}, {"referenceID": 36, "context": "Other examples include using a reduced set of training examples within kernel methods [36], or subsampling to solve semidefinite programming problems [37].", "startOffset": 150, "endOffset": 154}, {"referenceID": 1, "context": "It would be interesting to extend methods for estimating L in the exact case [2] to the case of inexact algorithms.", "startOffset": 77, "endOffset": 80}, {"referenceID": 37, "context": "Finally, we note that there has been recent interest in inexact proximal Newton-like methods [38], and it would be interesting to analyze the effect of errors on the convergence rates of these methods.", "startOffset": 93, "endOffset": 97}, {"referenceID": 0, "context": "Choosing z = \u03b8kx \u2217 + (1\u2212 \u03b8k)xk\u22121 gives f(xk) 6 \u03b5k + f(\u03b8kx \u2217 + (1\u2212 \u03b8)xk\u22121) + L \u3008xk \u2212 yk\u22121, \u03b8kx + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009+ L 2 \u2016xk \u2212 yk\u22121\u2016 + \u3008ek + Lfk, \u03b8kx + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009 6 \u03b5k + \u03b8kf(x \u2217) + (1\u2212 \u03b8k)f(xk\u22121) + L \u3008xk \u2212 yk\u22121, \u03b8kx + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009+ L 2 \u2016xk \u2212 yk\u22121\u2016 + \u3008ek + Lfk, \u03b8kx + (1\u2212 \u03b8k)xk\u22121 \u2212 xk\u3009 (10) using the convexity of f and the fact that \u03b8k is in [0, 1].", "startOffset": 352, "endOffset": 358}, {"referenceID": 27, "context": "12 of [28] = (1\u2212 2\u03bc L+ \u03bc )\u2016xk\u22121 \u2212 x\u2217\u20162 + 1 L ( 1 L \u2212 2 L+ \u03bc ) \u2016g(xk\u22121)\u2212 g\u2032(x\u2217)\u20162 6 (1\u2212 2\u03bc L+ \u03bc )\u2016xk\u22121 \u2212 x\u2217\u20162 + \u03bc2 L ( 1 L \u2212 2 L+ \u03bc )\u2016xk\u22121 \u2212 x\u2217\u20162 using the negativity of 1 L \u2212 2 L+\u03bc and the strong convexity of g = ( 1\u2212 \u03bc L )2 \u2016xk\u22121 \u2212 x\u2217\u20162.", "startOffset": 6, "endOffset": 10}, {"referenceID": 27, "context": "Proof We have (following [28]) xk = yk\u22121 \u2212 1 L g(yk\u22121) .", "startOffset": 25, "endOffset": 29}], "year": 2017, "abstractText": "We consider the problem of optimizing the sum of a smooth convex function and a non-smooth convex function using proximal-gradient methods, where an error is present in the calculation of the gradient of the smooth term or in the proximity operator with respect to the non-smooth term. We show that both the basic proximal-gradient method and the accelerated proximal-gradient method achieve the same convergence rate as in the error-free case, provided that the errors decrease at appropriate rates. Using these rates, we perform as well as or better than a carefully chosen fixed error level on a set of structured sparsity problems.", "creator": "LaTeX with hyperref package"}}}