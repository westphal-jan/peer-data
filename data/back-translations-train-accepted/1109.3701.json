{"id": "1109.3701", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Sep-2011", "title": "Active Ranking using Pairwise Comparisons", "abstract": "This paper examines the problem of ranking a collection of objects using pairwise comparisons (rankings of two objects). In general, the ranking of $n$ objects can be identified by standard sorting methods using $n log_2 n$ pairwise comparisons. We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons. Specifically, we assume that the objects can be embedded into a $d$-dimensional Euclidean space and that the rankings reflect their relative distances from a common reference point in $R^d$. We show that under this assumption the number of possible rankings grows like $n^{2d}$ and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than $d log n$ adaptively selected pairwise comparisons, on average. If instead the comparisons are chosen at random, then almost all pairwise comparisons must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the pairwise comparisons are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis.", "histories": [["v1", "Fri, 16 Sep 2011 19:35:13 GMT  (212kb,D)", "http://arxiv.org/abs/1109.3701v1", "13 pages, an extended version of our accepted paper with the same title that will appear at NIPS 2011"], ["v2", "Sat, 10 Dec 2011 01:02:14 GMT  (216kb,D)", "http://arxiv.org/abs/1109.3701v2", "17 pages, an extended version of our NIPS 2011 paper. The new version revises the argument of the robust section and slightly modifies the result there to give it more impact"]], "COMMENTS": "13 pages, an extended version of our accepted paper with the same title that will appear at NIPS 2011", "reviews": [], "SUBJECTS": "cs.LG cs.IT math.IT stat.ML", "authors": ["kevin g jamieson", "robert d nowak"], "accepted": true, "id": "1109.3701"}, "pdf": {"name": "1109.3701.pdf", "metadata": {"source": "CRF", "title": "Active Ranking using Pairwise Comparisons", "authors": ["Kevin G. Jamieson", "Robert D. Nowak"], "emails": ["kgjamieson@wisc.edu", "nowak@engr.wisc.edu"], "sections": [{"heading": "1 Introduction", "text": "iSe rf\u00fc ide eeisrVnlrtee\u00fcgr rf\u00fc ide eeisrmtlrVnree\u00fceegnn nvo eeisn rf\u00fc ide eeisrVrtee\u00fcgn ni rde eeisrmtlrgne\u00fceaeegnlrVnlrteeegnln rf\u00fc ide eeisrmnlrrrrrrf\u00fc eeisrteeegnln nln nlrrf\u00fc ide eeisrrrf\u00fc \"eSrf\u00fc\" eaeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee"}, {"heading": "1.1 Problem statement", "text": "The goal is to learn the ranking by using the reference for the comparisons of formqi: = {\u0445i \u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441"}, {"heading": "2 Motivation and related work", "text": "The problem of learning a ranking from a few pairs of comparisons is motivated by what we perceive as a significant gap in the theory of ranking and permutation. Most of the work in the ranking assumes a passive approach to learning; pairs of comparisons or partial rankings are collected in a random or non-adaptive manner and then aggregated to obtain a complete ranking (cf. [12, 13, 14, 15]). However, this can be quite inefficient in terms of the number of pairs of comparisons or partial rankings required to learn the (full) ranking. This inefficiency has recently been noted in the related field of social choice theory [16]. Furthermore, empirical evidence suggests that even under complex ranking models, the adaptive selection of pairs of comparisons can reduce the number needed to learn the ranking [17]. It is cause for concern as it is too expensive and time-consuming to maintain in many applications."}, {"heading": "3 Geometry of rankings from pairwise comparisons", "text": "The embedding assumption A1 leads to geometric interpretations of the ranking problem developed in this paragraph. The pair-wise comparison qi, j can be considered a member query: Is \u03b8i before \u03b8j classified in the (complete) ranking problem? The geometric interpretation is that qi, j asks whether the reference point r\u03c3 is closer to object \u03b8i or the object \u03b8j in Rd. Consider the connecting line between \u03b8i and \u03b8j in Rd. The hyperplane that bisects this line and is orthogonal to it defines two semispaces: one that is closer to succi and the other the points closer to \u03b8j. Qi, j is thus a member query about in which half-space plane R\u043c is located, and there is an equivalence between each query, each object pair and the corresponding bisectional hyperplane. The set of all possible pair-wise comparison queries can be represented as (n) distinct semispace queries about which half-space plane R\u043c is located in, and each of these half-rows is represented by a rank-level."}, {"heading": "3.1 Counting the number of possible rankings", "text": "The following calculus determines the cardinality of the precedence, An, d, assuming A1. Lemma 1. [7] Suppose A1-2. Letter Q (n, d) denotes the number of d cells defined by the hyper-plane arrangement of paired comparisons between these objects (i.e. Q (n, d) = | n, d |). Q (n, d) corresponds to the recursionQ (n, d) = Q (n \u2212 1, d) + (n \u2212 1) Q (n \u2212 1, d \u2212 1), where Q (1, d) = 1 and Q (n, 0) = 1. (3) In the hyper-plane arrangement induced by the n objects in d dimensions, each hyperplane is separated from each other and divided into Q (n \u2212 1, d \u2212 1) subsets or (d \u2212 1) cells. The recursion is obtained by looking at the addition of an object at a given time."}, {"heading": "3.2 Lower bounds on query complexity", "text": "Theorem 1. Let's start from A1-2. To reconstruct an arbitrary ranking, each algorithm requires at least log2 (2d log2 n) pair-wise comparisons. Proof. Consequently, we reach this lower limit. For example, in the one-dimensional case (d = 1) the objects can be ordered and the binary search can be used to select pair-wise comparison queries. \u2212 If each query provides a complete bit of information about the ranking, then we reach this lower limit."}, {"heading": "3.3 Inefficiency of random queries", "text": "The geometric representation of the ranking problem shows that the random selection of pair-wise comparison queries is inefficient compared to the lower limit above. To see this, let us assume that m-queries were uniformly randomly selected from the possible (n 2). The answers to m-queries narrow the set of possible rankings to a d-cell in Rd. This d-cell may consist of one or more d-cells in the partition induced by all queries. If it contains more than one of the partition cells, then the underlying ranking order is ambiguous. Theorem 2. Suppose N = (n 2). Suppose that m-wise comparison is uniformly selected from the possible (n 2) without substitution. Then, for all positive integers N \u2265 m, the probability that the m queries result in a unique ranking is equal (m) (m d)."}, {"heading": "4 Analysis of sequential algorithm for query selection", "text": "Let us now consider the basic sequential operation of the algorithm in Figure 1. Suppose we have k \u2212 1 of the n objects in the precedence order. Let us call these objects 1 to k \u2212 1. With this, we place the reference frame within a d cell (defined by the label of the comparison queries between objects 1,..., k \u2212 1). Let us call this d cell Ck \u2212 1. Let us suppose we randomly select another object and call it k. A comparison query between object k and one of objects 1.... k \u2212 1 can only be informative (i.e. ambiguous) if the associated hyperplane intersects this d cell Ck \u2212 1 (see Figure 2). If k is significantly larger than d, then it turns out that the cell Ck \u2212 1 is probably quite small and the probability that one of the queries Ck \u2212 1 intersects is very low; in fact, the probability is in the order of 1 / 2 k1."}, {"heading": "4.1 Hyperplane-point duality", "text": "Consider a hyperplane h = (h0, h1,.., hd) with (d + 1) parameters in Rd and a point p = (p1,..., pd) that is not on the hyperplane. Check into which hemispace p falls, i.e. h1p1 + h2p2 + \u00b7 \u00b7 \u00b7 + hdpd + h0 0 0, has a dual interpretation: h is a point in Rd + 1 and p is a hyperplane in Rd + 1 that passes through the origin (i.e. with d-free parameters). Remember that any possible ranking can be represented by a reference point r\u0445 Rd. Our problem is to determine the precedence or equivalent vector of the responses to (n 2) queries represented by hyperplanes in Rd."}, {"heading": "4.2 Characterization of an ambiguous query", "text": "The characterization of an ambiguous query has interpretations in both primary and dual space. We will now describe the dual interpretation that will be decisive for our analysis of the sequential algorithm of Figure 1. Definition 3. [8] Let S be a finite subset of Rd and let S + + \u0441S be points labeled + 1 and S \u2212 = S\\ S + be points labeled \u2212 1 and let x be any other point except the origin. If there are two homogeneous linear separators of S + and S \u2212 that assign different designations to the point x, then the label of x should be ambiguous with respect to S. Lemma 2. [8, Lemma 1] The label of x is ambiguous with respect to S, if and only if S + and S \u2212 are homogeneous, then linearly separated by a (d \u2212 1) -dimensional subspace containing x."}, {"heading": "4.3 The probability that a query is ambiguous", "text": "An essential component of the sequential algorithm of Figure 1 is the original random order of objects Q = Q cells; any sequence in which it could view objects is equally probable; this allows us to present a non-trivial fact about the partial order of the first k cells observed in this order. Lemma 3. Suppose that the number of possible rankings of these k objects is then just as probable as the subset of k cells. Consider the subset of k cells as equally probable. Proof. Let us label a k partition of k cells such that all (n k) d cells induced by k objects are equal to 1 \u2264 k cells. In the n partition, each d cell is equal and equal to 1 / Q cells."}, {"heading": "5 Robust sequential algorithm for query selection", "text": "We extend the algorithm of Figure 1 to situations where the answer to each query is only likely to be correct. If the correct name of a query qi, j is yi, j, we designate the possibly incorrect answer of Yi, j. The probability that Yi, j = yi, j is at least 1 \u2212 p, p < 1 / 2. The robust algorithm works in the same way as the algorithm in Figure 1, except that in case of ambiguous queries several (equivalent) queries occur and a decision is based on majority decision. This voting procedure allows us to construct a ranking (or partial ranking) that is most likely correct by requesting only O (d log2 n) queries, where the additional log factor comes from the vote. First, consider the case in which each query can be repeated to obtain multiple independent answers (votes) for each query."}, {"heading": "6 Empirical results", "text": "In this section, we present empirical results for both the approximate algorithm of Figure 1 and the robust algorithm of Section 5. For the noiseless algorithm, n = 100 points representing the objects to be ranked were uniformly randomly simulated. [0, 1] d for d = 1, 10, 20,., 100. The reference was simulated by the same distribution. 25 times for each value of the experiment was repeated using a new simulation of points and the reference. As answers are noiseless, accurate identification of the ranking is guaranteed. Figure 3 plots the number of queries requested with the lower limit of theorem 1 for the reference. The number of queries requested never exceeds the lower limit corresponding to the result of theorem. The robust algorithm in Section 5 was evaluated with a symmetrical similarity matrix."}, {"heading": "A Appendix", "text": "The computational complexity of the algorithm in Figure 1 = Q = 1 is determined by the complexity of testing whether a query is ambiguous or not, and how often we perform this test. As written in Figure 1, the complexity of each test would be performed O (n2) times. But, if the binary type is used instead of the linear search, this can be reduced to n log2 n and, in fact, this is implemented in our simulations and the proofs of the main results. The complexity of each test is polynomial in the number of queries requested, because each is a linear constraint. As our results show that no more than O (d log n) queries are requested, the overall complexity is not greater than O (n poly (d) poly (log n)).A.2 Proof Corollary 1Proof."}], "references": [{"title": "The Art of Computer Programming", "author": ["D. Knuth"], "venue": "Volume 3: Sorting and Searching. Addison- Wesley", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1998}, {"title": "Perceptual feature identification for active sonar echoes", "author": ["Scott Philips", "James Pitton", "Les Atlas"], "venue": "OCEANS", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Partial order embedding with multiple kernels", "author": ["B. McFee", "G. Lanckriet"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning, pages 721\u2013728. ACM", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "A latent space model for rank data", "author": ["I. Gormley", "T. Murphy"], "venue": "Statistical Network Analysis: Models, Issues, and New Directions, pages 90\u2013102", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Multidimensional scaling", "author": ["M.A.A. Cox", "T.F. Cox"], "venue": "Handbook of data visualization, pages 315\u2013347", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Information-based complexity", "author": ["J.F. Traub"], "venue": "John Wiley and Sons Ltd.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2003}, {"title": "A theory of data", "author": ["C.H. Coombs"], "venue": "Psychological review, 67(3):143\u2013159", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1960}, {"title": "Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition", "author": ["T.M. Cover"], "venue": "IEEE transactions on electronic computers, 14(3):326\u2013334", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1965}, {"title": "Analysis of perceptron-based active learning", "author": ["S. Dasgupta", "A.T. Kalai", "C. Monteleoni"], "venue": "The Journal of Machine Learning Research, 10:281\u2013299", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Theoretical foundations of active learning", "author": ["S. Hanneke"], "venue": "PhD thesis, Citeseer", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Generalized teaching dimensions and the query complexity of learning", "author": ["Tibor Heged\u00fcs"], "venue": "In Proceedings of the eighth annual conference on Computational learning theory,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1995}, {"title": "An efficient boosting algorithm for combining preferences", "author": ["Y. Freund", "R. Iyer", "R.E. Schapire", "Y. Singer"], "venue": "The Journal of Machine Learning Research, 4:933\u2013969", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning to rank using gradient descent", "author": ["C. Burges", "T. Shaked", "E. Renshaw", "A. Lazier", "M. Deeds", "N. Hamilton", "G. Hullender"], "venue": "Proceedings of the 22nd international conference on Machine learning, pages 89\u201396. ACM", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2005}, {"title": "A regression framework for learning ranking functions using relative relevance judgments", "author": ["Z. Zheng", "K. Chen", "G. Sun", "H. Zha"], "venue": "Proceedings of the 30th annual international ACM SI- GIR conference on Research and development in information retrieval, pages 287\u2013294. ACM", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2007}, {"title": "Support vector learning for ordinal regression", "author": ["R. Herbrich", "T. Graepel", "K. Obermayer"], "venue": "Artificial Neural Networks, 1999. ICANN 99. Ninth International Conference on (Conf. Publ. No. 470), volume 1, pages 97\u2013102. IET", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1999}, {"title": "Robust approximation and incremental elicitation in voting protocols", "author": ["T. Lu", "C. Boutilier"], "venue": "IJCAI-11, Barcelona", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Extensions of gaussian processes for ranking: semi-supervised and active learning", "author": ["W. Chu", "Z. Ghahramani"], "venue": "Learning to Rank, page 29", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2005}, {"title": "Multidimensional unfolding: Determining the dimensionality of ranked preference data", "author": ["J.F. Bennett", "W.L. Hays"], "venue": "Psychometrika, 25(1):27\u201343", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1960}, {"title": "Analyzing and modeling rank data", "author": ["J.I. Marden"], "venue": "Chapman & Hall/CRC", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1995}], "referenceMentions": [{"referenceID": 0, "context": "In fact, this lower bound can be achieved with a standard adaptive sorting algorithm like binary sort [1].", "startOffset": 102, "endOffset": 105}, {"referenceID": 1, "context": "This may be a reasonable assumption in many applications, and for instance the audio dataset used in our experiments is believed to have a 2 or 3 dimensional embedding [2].", "startOffset": 168, "endOffset": 171}, {"referenceID": 2, "context": "Many have studied the problem of finding an embedding of objects from data [3, 4, 5].", "startOffset": 75, "endOffset": 84}, {"referenceID": 3, "context": "Many have studied the problem of finding an embedding of objects from data [3, 4, 5].", "startOffset": 75, "endOffset": 84}, {"referenceID": 4, "context": "Many have studied the problem of finding an embedding of objects from data [3, 4, 5].", "startOffset": 75, "endOffset": 84}, {"referenceID": 5, "context": "However, because such situations are not representative of what is typically encountered, we analyze the problem in the framework of the average-case analysis [6].", "startOffset": 159, "endOffset": 162}, {"referenceID": 6, "context": "Geometrical interpretations of our problem derive from the seminal works of [7] in ranking and [8] in learning.", "startOffset": 76, "endOffset": 79}, {"referenceID": 7, "context": "Geometrical interpretations of our problem derive from the seminal works of [7] in ranking and [8] in learning.", "startOffset": 95, "endOffset": 98}, {"referenceID": 8, "context": "These dependencies invalidate many of the typical analyses of such problems [9, 10].", "startOffset": 76, "endOffset": 83}, {"referenceID": 9, "context": "These dependencies invalidate many of the typical analyses of such problems [9, 10].", "startOffset": 76, "endOffset": 83}, {"referenceID": 10, "context": "One popular method of analysis in exact learning involves the use of something called the extended teaching dimension [11].", "startOffset": 118, "endOffset": 122}, {"referenceID": 11, "context": "[12, 13, 14, 15]).", "startOffset": 0, "endOffset": 16}, {"referenceID": 12, "context": "[12, 13, 14, 15]).", "startOffset": 0, "endOffset": 16}, {"referenceID": 13, "context": "[12, 13, 14, 15]).", "startOffset": 0, "endOffset": 16}, {"referenceID": 14, "context": "[12, 13, 14, 15]).", "startOffset": 0, "endOffset": 16}, {"referenceID": 15, "context": "This inefficiency was recently noted in the related area of social choice theory [16].", "startOffset": 81, "endOffset": 85}, {"referenceID": 16, "context": "Furthermore, empirical evidence suggests that, even under complex ranking models, adaptively selecting pairwise comparisons can reduce the number needed to learn the ranking [17].", "startOffset": 174, "endOffset": 178}, {"referenceID": 11, "context": "The problem of learning a general function f : R \u2192 R using just pairwise comparisons that correctly ranks the objects embedded in R has previously been studied in the passive setting [12, 13, 14, 15].", "startOffset": 183, "endOffset": 199}, {"referenceID": 12, "context": "The problem of learning a general function f : R \u2192 R using just pairwise comparisons that correctly ranks the objects embedded in R has previously been studied in the passive setting [12, 13, 14, 15].", "startOffset": 183, "endOffset": 199}, {"referenceID": 13, "context": "The problem of learning a general function f : R \u2192 R using just pairwise comparisons that correctly ranks the objects embedded in R has previously been studied in the passive setting [12, 13, 14, 15].", "startOffset": 183, "endOffset": 199}, {"referenceID": 14, "context": "The problem of learning a general function f : R \u2192 R using just pairwise comparisons that correctly ranks the objects embedded in R has previously been studied in the passive setting [12, 13, 14, 15].", "startOffset": 183, "endOffset": 199}, {"referenceID": 6, "context": "This is a standard model used in multidimensional unfolding and psychometrics [7, 18].", "startOffset": 78, "endOffset": 85}, {"referenceID": 17, "context": "This is a standard model used in multidimensional unfolding and psychometrics [7, 18].", "startOffset": 78, "endOffset": 85}, {"referenceID": 6, "context": "[7] Assume A1-2.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Let S be a finite subset of R and let S \u2282 S be points labeled +1 and S\u2212 = S \\ S be the points labeled \u22121 and let x be any other point except the origin.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "For the noiseless algorithm, n = 100 points, representing the objects to be ranked, were uniformly at random simulated from the unit hypercube [0, 1] for d = 1, 10, 20, .", "startOffset": 143, "endOffset": 149}, {"referenceID": 1, "context": "The analysis of this dataset in [2] suggests that the relationship between signals can be well approximated by an embedding in 2 or 3 dimensions.", "startOffset": 32, "endOffset": 35}, {"referenceID": 4, "context": "We used non-metric multidimensional scaling [5] to find an embedding of the signals: \u03b81, .", "startOffset": 44, "endOffset": 47}, {"referenceID": 18, "context": "Using the popular Kendell-Tau distance d(y, \u0177) = ( n 2 )\u22121\u2211 i<j 1{y (k) i,j 6= \u0177 (k) i,j } [20] for each object k, we denote the average of this metric over all objects by d(y, \u0177) and report this statistic and the number of queries requested in Table 1.", "startOffset": 91, "endOffset": 95}], "year": 2017, "abstractText": "This paper examines the problem of ranking a collection of objects using pairwise comparisons (rankings of two objects). In general, the ranking of n objects can be identified by standard sorting methods using n log2 n pairwise comparisons. We are interested in natural situations in which relationships among the objects may allow for ranking using far fewer pairwise comparisons. Specifically, we assume that the objects can be embedded into a d-dimensional Euclidean space and that the rankings reflect their relative distances from a common reference point in R. We show that under this assumption the number of possible rankings grows like n and demonstrate an algorithm that can identify a randomly selected ranking using just slightly more than d log n adaptively selected pairwise comparisons, on average. If instead the comparisons are chosen at random, then almost all pairwise comparisons must be made in order to identify any ranking. In addition, we propose a robust, error-tolerant algorithm that only requires that the pairwise comparisons are probably correct. Experimental studies with synthetic and real datasets support the conclusions of our theoretical analysis.", "creator": "LaTeX with hyperref package"}}}