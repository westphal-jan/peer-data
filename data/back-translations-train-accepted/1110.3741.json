{"id": "1110.3741", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Oct-2011", "title": "Multi-criteria Anomaly Detection using Pareto Depth Analysis", "abstract": "We consider the problem of identifying patterns in a data set that exhibit anomalous behavior, often referred to as anomaly detection. In most anomaly detection algorithms, the dissimilarity between data samples is calculated by a single criterion. When dissimilarities are calculated by multiple criteria, one might perform anomaly detection using a linear combination of the multiple dissimilarities. If the importance of the different criteria are not known in advance, the algorithm may need to be executed multiple times with different choices of weights in the linear combination, perhaps selected by grid search.", "histories": [["v1", "Mon, 17 Oct 2011 17:48:22 GMT  (619kb)", "https://arxiv.org/abs/1110.3741v1", "17 pages"], ["v2", "Tue, 6 Nov 2012 22:12:52 GMT  (642kb)", "http://arxiv.org/abs/1110.3741v2", "To appear in NIPS 2012"], ["v3", "Mon, 7 Jan 2013 17:18:42 GMT  (642kb)", "http://arxiv.org/abs/1110.3741v3", "Removed an unnecessary line from Algorithm 1"]], "COMMENTS": "17 pages", "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.DB stat.ML", "authors": ["ko-jen hsiao", "kevin s xu 0001", "jeff calder", "alfred o hero iii"], "accepted": true, "id": "1110.3741"}, "pdf": {"name": "1110.3741.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["coolmark@umich.edu", "xukevin@umich.edu", "jcalder@umich.edu", "hero@umich.edu"], "sections": [{"heading": null, "text": "ar Xiv: 111 0.37 41v3 [cs.LG] 7 Jan 2"}, {"heading": "1 Introduction", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "2 Related work", "text": "In fact, we are able to go in search of a solution that is capable of finding a solution that meets the needs of the individual."}, {"heading": "3 Pareto depth analysis", "text": "The PDA method proposed in this paper uses the concept of Pareto-optimization, which has been studied in many fields of application in economics, computer science and social sciences, among others. [16] We introduce Pareto-optimization and define the concept of a Pareto-front. Consider the following problem: Given n items designated by the sentence S, and K-criteria to evaluate each item that is minimized by the functions f1,...., fK, select x-S that minimizes [f1 (x). A minimizer can be found by combining the K-criteria using a linear combination of items and finding the minimum of the combination. (Different options of (non-negative) x-x weights in the linear combination could lead to different minimizers."}, {"heading": "3.1 Mathematical properties of Pareto fronts", "text": "The distribution of the number of points on the first Pareto front was first examined in its secondary context by Barndorff Nielsen and Sobel. (We will look here at properties of the first Pareto front that are relevant to the PDA anomaly and therefore have not yet been considered in the literature.) We will look at properties of the first Pareto front that are relevant to the PDA anomaly. (We will opt for a measurable amount of A-Rd, we will denote by FA the points on the first Pareto front of Y1,.. Yn belonging to A., we will denote F1 of F and use the cardinality of F. (In the general Pareto framework, points Y1,.)"}, {"heading": "4 Multi-criteria anomaly detection", "text": "Suppose that a training set XN = {X1,.., XN} of the nominal data samples is available. Suppose that K > 1 is given different evaluation criteria. Each criterion is associated with a measure for calculating inequalities. Name the inequality between Xi and Xj, which is calculated from the measure corresponding to the lth criterion by dl (i, j). We define a dyad by Dij = [d1 (i, j),.., dK (i, j)] T-RK +, i-section {1,.., j-section {1,.,., N}\\ i. Each dyad dij corresponds to a connection between the samples Xi and Xj. Therefore, there are different dyads altogether (N, j)."}, {"heading": "4.1 Pareto fronts of dyads", "text": "For each sample Xn, there are N \u2212 1 dyads that correspond to their connections with the other N \u2212 1 samples. Define the set of N \u2212 1 dyads associated with Xn by Dn. If most dyads in Dn are on shallow Pareto fronts, then the differences between Xn and the other N \u2212 1 samples are small under a combination of criteria. Thus, Xn} is probably a nominal sample. This is the basic idea of the proposed multi-criteria detection method with PDA.We construct Pareto fronts F1,.., FM of the dyads from the training set, where the total number of fronts M is the required number of fronts, so that each dyad is a member of a front. If a test sample X is obtained, we create new dyads that correspond to connections between X and the training samples."}, {"heading": "4.2 Anomaly detection using depths of dyads", "text": "In k-NN based anomaly detection algorithms such as those mentioned in Section 2, the anomaly score is a function of k's closest neighbors to a test sample. By several criteria, one could define an anomaly score by scalarization. From the probabilistic properties of the Pareto fronts discussed in Section 3.1, we know that Pareto methods identify more Pareto-optimal points than linear scalarization methods and significantly more Pareto-optimal points than a single weight for scalarization. However, this motivates us to develop a multi-criterial anomaly score using Pareto fronts. We start with the observation from Figure 1 that dyads corresponding to a nominal test sample are located near flatter fronts than dyads corresponding to an anomalous test sample. Each test sample is linked to s new dynamics, where the dynamics associated with dynamics dynamics have dynamics where the dynamics have the dynamics."}, {"heading": "5 Experiments", "text": "We compare the PDA method with four other neighborhood-based criteria detection algorithms mentioned in Section 2. For these methods, we use linear combinations of criteria with different weights, selected by grid search, to compare performance with the PDA."}, {"heading": "5.1 Simulated data with four criteria", "text": "4. The anomalous samples are located directly outside this hypercube. There are four classes of anomalous distributions. Each class differs from the nominal distribution in one of the four dimensions; the distribution in the anomalous dimension is uniform to [1, 1.1]. We take 300 training samples from the nominal distribution, followed by 100 test samples from a mixture of nominal and anomalous distributions with a probability of 0.05. The four criteria for this experiment correspond to the quadratic differences in each dimension. When the criteria are combined with linear combinations, the combined measure of inequality is reduced to a weighted quadratic euclidean distance. The different methods are evaluated on the basis of the receiver characteristic (ROC) and the range under the curve (AUC). The mean AUCs (with standard deviations from 1 to 1 in each case) is best evaluated on the basis of the simular deviations."}, {"heading": "5.2 Pedestrian trajectories", "text": "We now present an experiment on a real dataset containing thousands of DA paths in an open area monitored by a video camera. Each path is approached by a cubic spline curve with seven control points [21]. We represent a path with l-time samples byT = [x1 x2.. xl y2.. yl], where [xt, yt] denotes the position of a pedestrian in a time step. We use two criteria to calculate the inequality between the trajectories byT = [x1 x2.."}, {"heading": "6 Conclusion", "text": "In this paper, we proposed a new method for the detection of multi-criterion anomalies, using pareto depth analysis to calculate the anomaly value of a test sample by examining the pareto front depths of dyads corresponding to the test sample. Dyads corresponding to an anomalous sample tended to be located at deeper fronts, compared to dyads corresponding to a nominal sample. Instead of selecting a specific weighting or conducting a grid search for weights for different deviations, the proposed method can efficiently detect anomalies in a way that scales linearly in the number of criteria. We also provided a theorem stating that the pareto approach is asymptotically better than linear combinations of criteria. Numerical studies confirmed our theoretical predictions of the performance benefits of PDA on simulated and real data."}, {"heading": "Acknowledgments", "text": "We thank Zhaoshi Meng for his help in marking the footpaths and Daniel DeWoskin for his suggestion of a fast algorithm for calculating Pareto fronts according to two criteria. This work was partially supported by the ARO grant W911NF-09-1-0310."}, {"heading": "Appendix A Proofs of Theorems 1 and 2", "text": "(1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1)) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1)) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1)) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1 (1) (1) (1) (1 (1) (1 (1) (1) (1) (1 (1) (1 (1) (1 (1) (1) (1) (1) (1 (1) (1) (1 (1) (1) (1 (1) (1) (1 (1 (1) (1) (1) (1 (1"}, {"heading": "Appendix B Experimental support for Theorems 1 and 2", "text": "The independence of Y1,.. Yn is built into the assumptions of theorems 1 and 2, but it is clear that dyads (as constructed in section 4) are not independent. Each dyad Di, j represents a connection between two independent examples Xi and Xj. Thus, while there are O (N2) dyads, each dyad is independent of all other dyads except for a series of size differences O (N). Since theorems 1 and 2 clearly do not deal with asymptotic results, this suggests that they should apply to the dyads, although they are not i.i.d. In this section we present some experimental results that support these non-rigorous states. We first took samples uniformly in [0, 1] 2 and compressed the dyads that correspond to the two criteria."}, {"heading": "Appendix C Implementation of PDA anomaly detector", "text": "The question is whether we divide the number of dimensions included in the calculation into two criteria. [22] The Pareto fronts are constructed by non-dominated sorting. In section C.1 we present a fast algorithm for non-dominated sorting in two criteria; for more than two criteria we use the non-dominated variety by Deb et al. [22] This constructs all Pareto fronts by non-dominated sorting. The test phase involves creating dyads between the test sample and the kl-next training sample in criterion l, which requires O (mKN) flops."}, {"heading": "Appendix D Additional discussion on pedestrian trajectories experiment", "text": "Remember that the two criteria used are walking speed and trajectory shape. Anomalous trajectories may have abnormal velocities or shapes (or both), so that some abnormal trajectories in Figure 6 do not look abnormal in shape alone. We find that the heuristics proposed in Section C.2 to select ki's in this experiment work quite well, as in Figure 7. Specifically, the AUC obtained using the parameters selected by the proposed heuristics is very close to the AUC obtained using the optimal parameters not known in advance. As discussed in Section 5.2, it is also higher than the AUCs of all single criterion anomaly detection methods, even under the best choice of weights."}], "references": [{"title": "A survey of outlier detection methodologies. Artificial Intelligence Review 22(2):85\u2013126", "author": ["V.J. Hodge", "J. Austin"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "Anomaly detection: A survey", "author": ["V. Chandola", "A. Banerjee", "V. Kumar"], "venue": "ACM Computing Surveys", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Pareto-based multiobjective machine learning: An overview and case studies", "author": ["Y. Jin", "B. Sendhoff"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Pareto-optimal methods for gene ranking", "author": ["A.O. Hero III", "G. Fleury"], "venue": "The Journal of VLSI Signal Processing", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2004}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["A. Blum", "T. Mitchell"], "venue": "In Proceedings of the 11th Annual Conference on Computational Learning Theory", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1998}, {"title": "A co-regularization approach to semisupervised learning with multiple views", "author": ["V. Sindhwani", "P. Niyogi", "M. Belkin"], "venue": "In Proceedings of the Workshop on Learning with Multiple Views,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "Multi-view learning in the presence of view disagreement", "author": ["C.M. Christoudias", "R. Urtasun", "T. Darrell"], "venue": "In Proceedings of the Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Multiple kernel learning algorithms", "author": ["M. G\u00f6nen", "E. Alpayd\u0131n"], "venue": "Journal of Machine Learning Research 12(Jul):2211\u20132268", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Nearest-neighbor clutter removal for estimating features in spatial point processes", "author": ["S. Byers", "A.E. Raftery"], "venue": "Journal of the American Statistical Association", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Fast outlier detection in high dimensional spaces", "author": ["F. Angiulli", "C. Pizzuti"], "venue": "In Proceedings of the 6th European Conference on Principles of Data Mining and Knowledge Discovery", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2002}, {"title": "A geometric framework for unsupervised anomaly detection: Detecting intrusions in unlabeled data", "author": ["E. Eskin", "A. Arnold", "M. Prerau", "L. Portnoy", "S. Stolfo"], "venue": "In Applications of Data Mining in Computer Security", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2002}, {"title": "LOF: Identifying density-based local outliers", "author": ["M.M. Breunig", "H.-P. Kriegel", "R.T. Ng", "J. Sander"], "venue": "In Proceedings of the ACM SIGMOD International Conference on Management of Data", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Geometric entropy minimization (GEM) for anomaly detection and localization", "author": ["III A.O. Hero"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Efficient anomaly detection using bipartite k-NN graphs", "author": ["K. Sricharan", "A.O. Hero III"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Anomaly detection with score functions based on nearest neighbor graphs", "author": ["M. Zhao", "V. Saligrama"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Multicriteria optimization. Lecture Notes in Economics and Mathematical Systems 491", "author": ["M. Ehrgott"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2000}, {"title": "On the distribution of the number of admissible points in a vector random sample", "author": ["O. Barndorff-Nielsen", "M. Sobel"], "venue": "Theory of Probability and its Applications,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1966}, {"title": "Maximal points and Gaussian fields. Unpublished. URL http://www.math.illinois.edu/ \u0303ymb/ps/by4.pdf", "author": ["Y. Baryshnikov", "J.E. Yukich"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2005}, {"title": "Statistical models of pedestrian behaviour in the Forum. Master\u2019s thesis, University of Edinburgh", "author": ["B. Majecka"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "A fast elitist non-dominated sorting genetic algorithm for multi-objective optimization: NSGA-II", "author": ["K. Deb", "S. Agrawal", "A. Pratap"], "venue": "Meyarivan", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2000}, {"title": "Maximum k-chains in planar point sets: Combinatorial structure and algorithms", "author": ["S. Felsner", "L. Wernisch"], "venue": "SIAM Journal on Computing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1999}, {"title": "A tutorial on spectral clustering", "author": ["U. von Luxburg"], "venue": "Statistics and Computing", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Anomaly detection is an important problem that has been studied in a variety of areas and used in diverse applications including intrusion detection, fraud detection, and image processing [1, 2].", "startOffset": 188, "endOffset": 194}, {"referenceID": 1, "context": "Anomaly detection is an important problem that has been studied in a variety of areas and used in diverse applications including intrusion detection, fraud detection, and image processing [1, 2].", "startOffset": 188, "endOffset": 194}, {"referenceID": 2, "context": "Several machine learning methods utilizing Pareto optimality have previously been proposed; an overview can be found in [3].", "startOffset": 120, "endOffset": 123}, {"referenceID": 3, "context": "Hero and Fleury [4] introduced a method for gene ranking using Pareto fronts that is related to our approach.", "startOffset": 16, "endOffset": 19}, {"referenceID": 4, "context": "Another related area is multi-view learning [5, 6], which involves learning from data represented by multiple sets of features, commonly referred to as \u201cviews\u201d.", "startOffset": 44, "endOffset": 50}, {"referenceID": 5, "context": "Another related area is multi-view learning [5, 6], which involves learning from data represented by multiple sets of features, commonly referred to as \u201cviews\u201d.", "startOffset": 44, "endOffset": 50}, {"referenceID": 6, "context": "The problem of view disagreement, where samples take different classes in different views, has recently been investigated [7].", "startOffset": 122, "endOffset": 125}, {"referenceID": 7, "context": "A similar area is that of multiple kernel learning [8], which is typically applied to supervised learning problems, unlike the unsupervised anomaly detection setting we consider.", "startOffset": 51, "endOffset": 54}, {"referenceID": 0, "context": "Hodge and Austin [1] and Chandola et al.", "startOffset": 17, "endOffset": 20}, {"referenceID": 1, "context": "[2] both provide extensive surveys of different anomaly detection methods and applications.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "Byers and Raftery [9] proposed to use the distance between a sample and its kth-nearest neighbor as the anomaly score for the sample; similarly, Angiulli and Pizzuti [10] and Eskin et al.", "startOffset": 18, "endOffset": 21}, {"referenceID": 9, "context": "Byers and Raftery [9] proposed to use the distance between a sample and its kth-nearest neighbor as the anomaly score for the sample; similarly, Angiulli and Pizzuti [10] and Eskin et al.", "startOffset": 166, "endOffset": 170}, {"referenceID": 10, "context": "[11] proposed to the use the sum of the distances between a sample and its k nearest neighbors.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] used an anomaly score based on the local density of the k nearest neighbors of a sample.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Hero [13] and Sricharan and Hero [14] introduced non-parametric adaptive anomaly detection methods using geometric entropy minimization, based on random k-point minimal spanning trees and bipartite k-nearest neighbor (k-NN) graphs, respectively.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "Hero [13] and Sricharan and Hero [14] introduced non-parametric adaptive anomaly detection methods using geometric entropy minimization, based on random k-point minimal spanning trees and bipartite k-nearest neighbor (k-NN) graphs, respectively.", "startOffset": 33, "endOffset": 37}, {"referenceID": 14, "context": "Zhao and Saligrama [15] proposed an anomaly detection algorithm k-LPE using local p-value estimation (LPE) based on a k-NN graph.", "startOffset": 19, "endOffset": 23}, {"referenceID": 15, "context": "The PDA method proposed in this paper utilizes the notion of Pareto optimality, which has been studied in many application areas in economics, computer science, and the social sciences among others [16].", "startOffset": 198, "endOffset": 202}, {"referenceID": 16, "context": "1 Mathematical properties of Pareto fronts The distribution of the number of points on the first Pareto front was first studied by BarndorffNielsen and Sobel in their seminal work [17].", "startOffset": 180, "endOffset": 184}, {"referenceID": 15, "context": "A common approach in multi-objective optimization is linear scalarization [16], which constructs a new single criterion as a convex combination of the d criteria.", "startOffset": 74, "endOffset": 78}, {"referenceID": 17, "context": "It has recently come to our attention that Theorem 1 appears in a more general form in an unpublished manuscript of Baryshnikov and Yukich [19].", "startOffset": 139, "endOffset": 143}, {"referenceID": 0, "context": ", Yn be independent and uniformly distributed on [0, 1].", "startOffset": 49, "endOffset": 55}, {"referenceID": 16, "context": "A proof that E|F| = lnn + O(1) as n \u2192 \u221e can be found in [17].", "startOffset": 56, "endOffset": 60}, {"referenceID": 0, "context": "The nominal distribution is given by the uniform distribution on the hypercube [0, 1].", "startOffset": 79, "endOffset": 85}, {"referenceID": 18, "context": "We now present an experiment on a real data set that contains thousands of pedestrians\u2019 trajectories in an open area monitored by a video camera [20].", "startOffset": 145, "endOffset": 149}, {"referenceID": 0, "context": "0 t(1\u2212 at +O(bt))dt, \u03bb \u2208 [0, 1], a, b > 0.", "startOffset": 25, "endOffset": 31}, {"referenceID": 0, "context": "For (x, y) \u2208 [0, 1] let Dx,y be the event that Y1 = (x, y) and (x, y) \u2208 F .", "startOffset": 13, "endOffset": 19}, {"referenceID": 0, "context": "Define A = { (u, v) \u2208 [0, 1] | 0 < u < x, y < v < 2y \u2212 uy x }", "startOffset": 22, "endOffset": 28}, {"referenceID": 0, "context": ", and B = { (u, v) \u2208 [0, 1] | x < u < 1, 0 < v < 2y \u2212 uy x }", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "We first drew samples uniformly in [0, 1] and computed the dyads corresponding to the two criteria |\u2206x| and |\u2206y|, which denote the absolute differences between the x and y coordinates, respectively.", "startOffset": 35, "endOffset": 41}, {"referenceID": 0, "context": "Figure 4: 990 dyads constructed with two different sets of criteria from 45 samples uniformly distributed in [0, 1].", "startOffset": 109, "endOffset": 115}, {"referenceID": 0, "context": "The domain of the resulting dyads is again the box [0, 1], as shown in Figure 4(a), so this experiment tests Theorem 2.", "startOffset": 51, "endOffset": 57}, {"referenceID": 0, "context": "A somewhat contrived example involves the criteria |\u2206x| + |\u2206y| and |\u2206x| \u2212 |\u2206y|, which, when applied to uniformly sampled data on [0, 1], yields dyads sampled on a diamond domain, as shown in Figure 4(b).", "startOffset": 129, "endOffset": 135}, {"referenceID": 19, "context": "[22] that constructs all of the Pareto fronts using O(KN) comparisons in the worst case.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[22] takes O(n) time and requires O(n) memory, where n = ( N 2 )", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "It has recently come to our attention that an O(n lnn) algorithm exists for the canonical anti-chain partition problem [23], which is equivalent to non-dominated sorting in two criteria, and can also be used to quickly construct the Pareto fronts.", "startOffset": 119, "endOffset": 123}, {"referenceID": 21, "context": "This method of choosing k to retain connectivity has been used as a heuristic in other unsupervised learning problems, such as spectral clustering [24].", "startOffset": 147, "endOffset": 151}], "year": 2013, "abstractText": "We consider the problem of identifying patterns in a data set that exhibit anomalous behavior, often referred to as anomaly detection. In most anomaly detection algorithms, the dissimilarity between data samples is calculated by a single criterion, such as Euclidean distance. However, in many cases there may not exist a single dissimilarity measure that captures all possible anomalous patterns. In such a case, multiple criteria can be defined, and one can test for anomalies by scalarizing the multiple criteria using a linear combination of them. If the importance of the different criteria are not known in advance, the algorithm may need to be executed multiple times with different choices of weights in the linear combination. In this paper, we introduce a novel non-parametric multi-criteria anomaly detection method using Pareto depth analysis (PDA). PDA uses the concept of Pareto optimality to detect anomalies under multiple criteria without having to run an algorithm multiple times with different choices of weights. The proposed PDA approach scales linearly in the number of criteria and is provably better than linear combinations of the criteria.", "creator": "LaTeX with hyperref package"}}}