{"id": "1112.6209", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Dec-2011", "title": "Building high-level features using large scale unsupervised learning", "abstract": "We consider the problem of building detectors for high-level concepts using only unsupervised feature learning. For example, we would like to understand if it is possible to learn a face detector using only unlabeled images downloaded from the internet. To answer this question, we trained a simple feature learning algorithm on a large dataset of images (10 million images, each image is 200x200). The simulation is performed on a cluster of 1000 machines with fast network hardware for one week. Extensive experimental results reveal surprising evidence that such high-level concepts can indeed be learned using only unlabeled data and a simple learning algorithm.", "histories": [["v1", "Thu, 29 Dec 2011 00:26:54 GMT  (2624kb,D)", "http://arxiv.org/abs/1112.6209v1", null], ["v2", "Tue, 22 May 2012 08:12:49 GMT  (2978kb,D)", "http://arxiv.org/abs/1112.6209v2", null], ["v3", "Tue, 12 Jun 2012 05:12:56 GMT  (2978kb,D)", "http://arxiv.org/abs/1112.6209v3", null], ["v4", "Wed, 11 Jul 2012 04:40:33 GMT  (2978kb,D)", "http://arxiv.org/abs/1112.6209v4", null], ["v5", "Thu, 12 Jul 2012 04:32:50 GMT  (2978kb,D)", "http://arxiv.org/abs/1112.6209v5", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["quoc v le", "marc'aurelio ranzato", "rajat monga", "matthieu devin", "greg corrado", "kai chen 0010", "jeffrey dean", "andrew y ng"], "accepted": true, "id": "1112.6209"}, "pdf": {"name": "1112.6209.pdf", "metadata": {"source": "CRF", "title": "Building high-level features using large scale unsupervised learning", "authors": ["Quoc V. Le", "Rajat Monga", "Matthieu Devin", "Greg Corrado", "Kai Chen", "Marc\u2019Aurelio Ranzato", "Jeff Dean", "Andrew Y. Ng"], "emails": ["qvl@google.com", "rajatmonga@google.com", "mdevin@google.com", "gcorrado@google.com", "kaichen@google.com", "ranzato@google.com", "jeff@google.com", "ayng@google.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of these algorithms are capable of developing at low levels, such as \"edge\" or \"blob.\" The focus of this work is on creating concepts that relate to high levels."}, {"heading": "2 Dataset constructions", "text": "To avoid duplication, each video contributes only one image to the dataset. Each image has 200x200 pixels and three RGB channels, and then we bleach each image by entwining it with permanently installed cores outside the environment on each channel (similar to local contrast normalization) [13]. This dataset is compiled with the goal of representing the experience of a one-and-a-half-year-old unsupervised baby. In particular, if each image represents 5 seconds, our dataset of 10 million images can be up to 1.5 years long. To verify the percentage of faces in the dataset, we also have a face detector in openCV.31 This argument, often attributed to G. Hinton and cited as motivation in [22], is somewhat widespread in neuroscience. 2This differs from the work of [19], which trained their model on images from a class. 3http / intentional / intentional / distorted / modified areas where we have control over the most diverse images."}, {"heading": "3 Algorithm", "text": "It is about the question to what extent people are able to outdo themselves and the question to what extent they are able to outdo themselves. (...) It is about the question to what extent people are able to outdo themselves. (...) It is about the question to what extent people are able to outdo themselves. (...) It is about the question to what extent people are able to outdo themselves. (...) It is about the question to what extent they are able to outdo themselves. (...) It is about the question to what extent people are able to outdo themselves. (...) It is about the question to what extent they are able to outdo themselves. (...) It is about the question to what extent they are able to outdo themselves. \""}, {"heading": "4 Test set", "text": "The test set consists of 37,000 images sampled from two sets of data: Labeled Faces In the Wild [10] and ImageNet [4]. There are 13026 faces sampled from non-aligned Labeled Faces in The Wild.6 The rest are distractor objects randomly sampled from ImageNet. These images are resized to 80x80, padded with zeros, and placed in the center of the 200x200 image. Placement is done in such a way that i) all images are aligned and of the same size, and ii) the central pixel of the 80x80 image is at (100.80) in the larger image (see Figure 2). In later sections, we will assess how the learned characteristics change with respect to changes in the position and scale of the object within the larger image. 6http: / / vis-www.cs.umass.edu / lfw / lfw.tgzIn Figure 4, we show the individual test areas of the active areas in relation to the tabs."}, {"heading": "5 Experiment protocols", "text": "After training, we used this test set to measure the performance of each neuron in classifying faces against random distractions. We found its maximum activation value and minimum activation value for each neuron. Then, we selected 20 equally large thresholds from maximum to minimum. For each neuron, we selected the best classification accuracy out of 20 thresholds."}, {"heading": "6 Classification results", "text": "The classification accuracy of the best neuron in a three-layer network is 82.5% for a test set of 37,000 images. There are 13026 faces in the test set, so the rate of all negative neurons in a three-layer network is only 64.8%. The best neuron in a single-layer network achieves only 71% accuracy. The best linear filter among 30,000 randomly sampled filters in the training set achieves only 74%. We visualize histograms of activation values for facial images and random images in Figure 5. It turns out that even with completely blank data, the neuron learns to distinguish between faces and random deflectors. In particular, when we give a face as an input image, the neuron tends to fire with an activation value greater than the threshold, 10. On the other hand, when we give a random image as an input image, the neuron tends to fire with an activation value less than 10."}, {"heading": "7 Visualization", "text": "In the following, we show the most responsive stimuli of the best neuron. By means of reverse correlation and averaging, we also show the averaged image of the most responsive stimuli. 77This visualization technique is also used to visualize the receptive fields of simple cells (see [3] for an example)."}, {"heading": "8 Invariance properties", "text": "In the following, we select a set of 10 facial images and then perform simple transformations, scaling and translation. Next, we want to test how sensitive the neuron is to the changes. In the following, we present the average response to ten images of the best neuron in terms of changes in scale (Figure 7) and translation (Figure 8). Results show that the neuron is quite resilient to these changes (especially scaling)."}, {"heading": "9 Control experiment", "text": "In the previous section, we reported that our neuron achieves an accuracy of 82.5% in classifying faces against random distractions. What if we remove all images that have faces? We performed the control experiment by running an open CV face detector and removing those training images that contain faces. The best neuron using the same architecture drops to 73% classification accuracy, which is as low as random filters taken from the training set as reported in Section 6."}, {"heading": "10 Conclusion", "text": "In this paper, we focus on the simulation of a simple version of a \"grandmother cell\" with unmarked data, combining ideas from recently developed algorithms. To train on large and realistic images, we implemented the algorithm using MapReduce with both types of parallelism: data parallelism and model parallelism. The algorithm was trained on a cluster of 1000 machines and the results show that it is possible to achieve certain properties of these highly selective neurons with only unmarked data. Thank you: We thank Adam Coates, Tom Dean, Andrew Saxe, Jon Shlens for insightful discussions and help with the project."}], "references": [{"title": "Greedy layerwise training of deep networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["A. Coates", "H. Lee", "A.Y. Ng"], "venue": "AISTATS 14", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "Theoretical Neuroscience: Computational and Mathematical Modeling of Neural Systems", "author": ["P. Dayan", "L.F. Abbott"], "venue": "MIT Press", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2001}, {"title": "ImageNet: A Large-Scale Hierarchical Image Database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei-Fei"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "Stimulus-selective properties of inferior temporal neurons in the macaque", "author": ["R. Desimone", "T. Albright", "C. Gross", "C. Bruce"], "venue": "The Journal of Neuroscience", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1984}, {"title": "Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position", "author": ["K. Fukushima", "S. Miyake"], "venue": "Pattern Recognition, pages 455\u2013469", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1982}, {"title": "Measuring invariances in deep networks", "author": ["I. Goodfellow", "Q.V. Le", "A. Saxe", "H. Lee", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2009}, {"title": "Layer-wise analysis of deep networks with gaussian kernels", "author": ["M.B. Gregoire Montavon", "K.-R. Muller"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Y.W. Teh"], "venue": "Neural Computation", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2006}, {"title": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "author": ["G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned-Miller"], "venue": "Technical Report", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Receptive fields of single neurons in the the cat\u2019s visual cortex", "author": ["D.H. Hubel", "T. Wiesel"], "venue": "Journal of Physiology", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1959}, {"title": "Receptive fields", "author": ["D.H. Hubel", "T. Wiesel"], "venue": "binocular interaction and functional architecture in the cat\u2019s visual cortex. Journal of Physiology", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1962}, {"title": "Natural Image Statistics", "author": ["A. Hyv\u00e4rinen", "J. Hurri", "P.O. Hoyer"], "venue": "Springer", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "ICA with Reconstruction Cost for Efficient Overcomplete Feature Learning", "author": ["Q.V. Le", "A. Karpenko", "J. Ngiam", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Tiled convolutional neural networks", "author": ["Q.V. Le", "J. Ngiam", "Z. Chen", "D. Chia", "P.W. Koh", "A.Y. Ng"], "venue": "NIPS", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning hierarchical spatio-temporal features for action recognition with independent subspace analysis", "author": ["Q.V. Le", "W. Zou", "S.Y. Yeung", "A.Y. Ng"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Gradient based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceeding of the IEEE", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1998}, {"title": "Efficient sparse coding algorithms", "author": ["H. Lee", "A. Battle", "R. Raina", "A.Y. Ng"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2007}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A. Ng"], "venue": "International Conference on Machine Learning", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images", "author": ["B. Olshausen", "D. Field"], "venue": "Nature", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1996}, {"title": "Invariant visual representation by single neurons in the human brain", "author": ["R. Quiroga", "L. Reddy", "G. Kreiman", "C. Koch", "I. Fried"], "venue": "Nature", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "Self-taught learning: Transfer learning from unlabelled data", "author": ["R. Raina", "A. Battle", "H. Lee", "B. Packer", "A. Ng"], "venue": "International Conference on Machine Learning", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2007}, {"title": "Large-scale deep unsupervised learning using graphics processors", "author": ["R. Raina", "A. Madhavan", "A.Y. Ng"], "venue": "International Conference on Machine Learning", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2009}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M. Ranzato", "F.J. Huang", "Y. Boureau", "Y. LeCun"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2007}, {"title": "Hierarchical models of object recognition in cortex", "author": ["M. Riesenhuber", "T. Poggio"], "venue": "Nature Neuroscience", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1999}], "referenceMentions": [{"referenceID": 8, "context": ", RBMs [9], Autoencoders [1], Sparse Coding [18], Kmeans [2], ISA [16].", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": ", RBMs [9], Autoencoders [1], Sparse Coding [18], Kmeans [2], ISA [16].", "startOffset": 25, "endOffset": 28}, {"referenceID": 17, "context": ", RBMs [9], Autoencoders [1], Sparse Coding [18], Kmeans [2], ISA [16].", "startOffset": 44, "endOffset": 48}, {"referenceID": 1, "context": ", RBMs [9], Autoencoders [1], Sparse Coding [18], Kmeans [2], ISA [16].", "startOffset": 57, "endOffset": 60}, {"referenceID": 15, "context": ", RBMs [9], Autoencoders [1], Sparse Coding [18], Kmeans [2], ISA [16].", "startOffset": 66, "endOffset": 70}, {"referenceID": 4, "context": "\u201d This class of cells have been argued to exist in the brain with the role of detecting faces and hands [5] or specific people [21] (e.", "startOffset": 104, "endOffset": 107}, {"referenceID": 20, "context": "\u201d This class of cells have been argued to exist in the brain with the role of detecting faces and hands [5] or specific people [21] (e.", "startOffset": 127, "endOffset": 131}, {"referenceID": 22, "context": "To scale the model to large images, we use the idea of local receptive fields [23, 15] and many levels of parallelism: model parallelism (parameters are distributed across machines) and data parallelism (data are distributed across machines).", "startOffset": 78, "endOffset": 86}, {"referenceID": 14, "context": "To scale the model to large images, we use the idea of local receptive fields [23, 15] and many levels of parallelism: model parallelism (parameters are distributed across machines) and data parallelism (data are distributed across machines).", "startOffset": 78, "endOffset": 86}, {"referenceID": 6, "context": "This further confirms the power of deep networks in learning invariant feature representations [7, 8].", "startOffset": 95, "endOffset": 101}, {"referenceID": 7, "context": "This further confirms the power of deep networks in learning invariant feature representations [7, 8].", "startOffset": 95, "endOffset": 101}, {"referenceID": 12, "context": "We then whiten each image by convolving it with fixed on-center off-surround kernels on each channel (similar to local contrast normalization) [13].", "startOffset": 143, "endOffset": 147}, {"referenceID": 21, "context": "Hinton and cited as motivations in [22], is somewhat widely held in neuroscience.", "startOffset": 35, "endOffset": 39}, {"referenceID": 18, "context": "This is different from the work of [19] who trained their model on images from one class.", "startOffset": 35, "endOffset": 39}, {"referenceID": 19, "context": "Our work is inspired by recent successful algorithms in unsupervised feature learning and deep learning [20, 9, 1, 24, 18].", "startOffset": 104, "endOffset": 122}, {"referenceID": 8, "context": "Our work is inspired by recent successful algorithms in unsupervised feature learning and deep learning [20, 9, 1, 24, 18].", "startOffset": 104, "endOffset": 122}, {"referenceID": 0, "context": "Our work is inspired by recent successful algorithms in unsupervised feature learning and deep learning [20, 9, 1, 24, 18].", "startOffset": 104, "endOffset": 122}, {"referenceID": 23, "context": "Our work is inspired by recent successful algorithms in unsupervised feature learning and deep learning [20, 9, 1, 24, 18].", "startOffset": 104, "endOffset": 122}, {"referenceID": 17, "context": "Our work is inspired by recent successful algorithms in unsupervised feature learning and deep learning [20, 9, 1, 24, 18].", "startOffset": 104, "endOffset": 122}, {"referenceID": 19, "context": "In particular, in their seminal work, Olshausen and Field [20] discovered sparse coding, an unsupervised learning principle, that yields receptive fields having properties like those of V1 simple cells.", "startOffset": 58, "endOffset": 62}, {"referenceID": 10, "context": "These properties in turn were characterized by [11, 12].", "startOffset": 47, "endOffset": 55}, {"referenceID": 11, "context": "These properties in turn were characterized by [11, 12].", "startOffset": 47, "endOffset": 55}, {"referenceID": 19, "context": "A shortcoming of early approaches such as sparse coding [20] is that their architectures are shallow and typically shown to capture simple variations (or learned features such as edge detectors).", "startOffset": 56, "endOffset": 60}, {"referenceID": 8, "context": "This issue is tackled by recent work of [9, 1, 19] who extend sparse coding to build hierarchies of feature representations.", "startOffset": 40, "endOffset": 50}, {"referenceID": 0, "context": "This issue is tackled by recent work of [9, 1, 19] who extend sparse coding to build hierarchies of feature representations.", "startOffset": 40, "endOffset": 50}, {"referenceID": 18, "context": "This issue is tackled by recent work of [9, 1, 19] who extend sparse coding to build hierarchies of feature representations.", "startOffset": 40, "endOffset": 50}, {"referenceID": 18, "context": "In particular, Lee et al [19] have shown that a convolutional DBNs, trained on images of faces, can learn a decent face detector.", "startOffset": 25, "endOffset": 29}, {"referenceID": 14, "context": "Our algorithm is built upon these ideas, especially [15].", "startOffset": 52, "endOffset": 56}, {"referenceID": 16, "context": "To scale these autoencoders to large images, we use a simple idea known as local receptive fields [17, 23, 19, 15].", "startOffset": 98, "endOffset": 114}, {"referenceID": 22, "context": "To scale these autoencoders to large images, we use a simple idea known as local receptive fields [17, 23, 19, 15].", "startOffset": 98, "endOffset": 114}, {"referenceID": 18, "context": "To scale these autoencoders to large images, we use a simple idea known as local receptive fields [17, 23, 19, 15].", "startOffset": 98, "endOffset": 114}, {"referenceID": 14, "context": "To scale these autoencoders to large images, we use a simple idea known as local receptive fields [17, 23, 19, 15].", "startOffset": 98, "endOffset": 114}, {"referenceID": 16, "context": "thermore, to achieve spatial invariances, we employ a technique known as pooling [17, 19].", "startOffset": 81, "endOffset": 89}, {"referenceID": 18, "context": "thermore, to achieve spatial invariances, we employ a technique known as pooling [17, 19].", "startOffset": 81, "endOffset": 89}, {"referenceID": 24, "context": "This style of stacking a series of uniform structures is reminiscent of HMAX [25] and Neocognition [6] approaches.", "startOffset": 77, "endOffset": 81}, {"referenceID": 5, "context": "This style of stacking a series of uniform structures is reminiscent of HMAX [25] and Neocognition [6] approaches.", "startOffset": 99, "endOffset": 102}, {"referenceID": 13, "context": "This optimization problem is also known as reconstruction Topographic Independent Component Analysis [14].", "startOffset": 101, "endOffset": 105}, {"referenceID": 16, "context": "Unlike previous convolutional methods [17, 19], local receptive fields in our model are untied: the weights are different for different locations in the image.", "startOffset": 38, "endOffset": 46}, {"referenceID": 18, "context": "Unlike previous convolutional methods [17, 19], local receptive fields in our model are untied: the weights are different for different locations in the image.", "startOffset": 38, "endOffset": 46}, {"referenceID": 14, "context": "In addition to being more biologically feasible, this lets us learn more invariant features other than translational invariances [15].", "startOffset": 129, "endOffset": 133}, {"referenceID": 16, "context": "There are many types of pooling such as mean pooling, max pooling [17] and square-squareroot pooling [15] but in this work we will use the last type of pooling because it allows the learning of invariant features [13, 15].", "startOffset": 66, "endOffset": 70}, {"referenceID": 14, "context": "There are many types of pooling such as mean pooling, max pooling [17] and square-squareroot pooling [15] but in this work we will use the last type of pooling because it allows the learning of invariant features [13, 15].", "startOffset": 101, "endOffset": 105}, {"referenceID": 12, "context": "There are many types of pooling such as mean pooling, max pooling [17] and square-squareroot pooling [15] but in this work we will use the last type of pooling because it allows the learning of invariant features [13, 15].", "startOffset": 213, "endOffset": 221}, {"referenceID": 14, "context": "There are many types of pooling such as mean pooling, max pooling [17] and square-squareroot pooling [15] but in this work we will use the last type of pooling because it allows the learning of invariant features [13, 15].", "startOffset": 213, "endOffset": 221}, {"referenceID": 13, "context": "html In [14], the encoding weights and the decoding weights are tied: W1 = W2.", "startOffset": 8, "endOffset": 12}, {"referenceID": 9, "context": "The test set consists of 37000 images sampled from two datasets: Labeled Faces In the Wild [10] and ImageNet [4].", "startOffset": 91, "endOffset": 95}, {"referenceID": 3, "context": "The test set consists of 37000 images sampled from two datasets: Labeled Faces In the Wild [10] and ImageNet [4].", "startOffset": 109, "endOffset": 112}, {"referenceID": 2, "context": "This visualization technique is also used to visualize the receptive fields of simple cells (see [3] for an example).", "startOffset": 97, "endOffset": 100}], "year": 2013, "abstractText": "We consider the problem of building detectors for high-level concepts using only unsupervised feature learning. For example, we would like to understand if it is possible to learn a face detector using only unlabeled images downloaded from the internet. To answer this question, we trained a simple feature learning algorithm on a large dataset of images (10 million images, each image is 200x200). The simulation is performed on a cluster of 1000 machines with fast network hardware for one week. Extensive experimental results reveal surprising evidence that such high-level concepts can indeed be learned using only unlabeled data and a simple learning algorithm.", "creator": "LaTeX with hyperref package"}}}