{"id": "1202.3323", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Feb-2012", "title": "Mirror Descent Meets Fixed Share (and feels no regret)", "abstract": "We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002). These algorithms use weight sharing schemes to perform as well as the best sequence of experts with a limited number of changes. Here we show, with a common, general, and simpler analysis, that weight sharing in fact achieves much more than what it was designed for. We use it to simultaneously prove new shifting regret bounds for online convex optimization on the simplex in terms of the total variation distance as well as new bounds for the related setting of adaptive regret. Finally, we exhibit the first logarithmic shifting bounds for exp-concave loss functions on the simplex.", "histories": [["v1", "Wed, 15 Feb 2012 14:39:42 GMT  (45kb)", "http://arxiv.org/abs/1202.3323v1", null], ["v2", "Thu, 27 Sep 2012 19:39:42 GMT  (40kb)", "http://arxiv.org/abs/1202.3323v2", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["nicol\u00f2 cesa-bianchi", "pierre gaillard", "g\u00e1bor lugosi", "gilles stoltz"], "accepted": true, "id": "1202.3323"}, "pdf": {"name": "1202.3323.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Pierre Gaillard", "Gilles Stoltz"], "emails": ["NICOLO.CESA-BIANCHI@UNIMI.IT", "PIERRE.GAILLARD@ENS.FR", "GABOR.LUGOSI@UPF.EDU", "GILLES.STOLTZ@ENS.FR"], "sections": [{"heading": null, "text": "ar Xiv: 120 2.33 23v1 [cs.LG]"}, {"heading": "1. Introduction", "text": "In fact, most of us are able to play by the rules we have set ourselves in order to make them a reality."}, {"heading": "2. Preliminaries", "text": "We first define the sequential learning framework we work with. Although our results are not taken into account in the general constellation of online optimization, we present them in the, somewhat simpler, online linear optimization. In Section 6, we point out how these results can be generalized. Online linear optimization can be presented as a repetitive game between the forecaster and the environment as follows. We use the tool p + 1 to characterize the simplex-based linear optimization. For each round t = 1.,., T, 1. Forecaster selects p.,.,. p.,. p.,. d. d,. d.)."}, {"heading": "3. Shifting bounds", "text": "In this area, we are able to go in search of a solution. (...) In this area, we are looking for a solution. (...) In this area, we are looking for a solution. (...) In this area, we are looking for a solution. (...) In this area, we are looking for a solution. (...) In other areas, we are looking for a solution. (...) In other areas, we are looking for a solution. (...) In other areas, we are looking for a solution. (...) In other areas, we are looking for a solution. (...) In other areas, we are looking for a solution. (...) In other areas, we are looking for a solution. (...) In other areas, we are looking for a solution. (...)"}, {"heading": "3.1. Fixed-share update", "text": "We are now analyzing a specific instance of generalized share algorithms that correspond to the updated share algorithms. (1) We are analyzing a specific instance of generalized share algorithms. (1) We are analyzing a specific instance of generalized share algorithms. (1) We are analyzing a specific instance of generalized share algorithms. (1) We are analyzing the distribution algorithms. (1) We are analyzing the distribution algorithms. (1) We are analyzing the distribution algorithms. (1) We are analyzing the distribution algorithms. (1) We are analyzing the distribution algorithms. (1) We are analyzing the distribution algorithms. (1) We are analyzing the distribution algorithms. (1) We are analyzing the distribution algorithms. (1) We are analyzing (1) the distribution algorithms."}, {"heading": "3.2. Sparse sequences: Bousquet-Warmuth updates", "text": "In this section, we show that their algorithms work very well indeed, and that the quantities (uT1) are much larger than the quantities (uT1)., uT, which are \"regular\" - that is, m (uT1), defined in (2) is small - and \"sparse\" in the sense that the quantities (uT1) are much larger than the quantities (uT1)., T ui, NEW LOOK AT SHIFTING REGRETis small. Note that the Qt can be provided for all t, then two interesting ceilings."}, {"heading": "4. Adaptive regret", "text": "Next, we will show how the results of the previous section, e.g. Proposition 2, imply guarantees with respect to adaptive regret - an idea introduced by Hazan and Seshadhri (2009) as follows: For \u03c40-adaptive regret of a forecaster, the \u03c40-adaptive regret of a forecaster becomes R\u03c40-adaptT = max [r, s]. [1, T] s + 1-r 6 \u03c40 {s \u2211 t = rp. \u2212 t \u2212 min q) ds. (10) Adaptive regret is an alternative method of measuring a forecaster's performance against a changing environment. It is a direct observation that adaptive regret also leads to shifts in the limits of regret (in relation to hard shifts). Here, we will show that these two terms of regret share an even closer connection, as they can both be considered examples of the same alma mater, e.g. Proposition 2.Hazan and all functions are essentially fixed."}, {"heading": "In particular, when \u03b7 and \u03b1 are chosen optimally (depending on \u03c40 and T )", "text": "For 1 6 r 6 s 6 T and q.d, the regret on the right side of (10) corresponds to the regret that is taken into account in sentence 2 against the sequence uT1, which is used as ut = q for t = r,..., s and 0 = (0,.., 0) for the remaining t. for r > 2, this sequence is such that DTV (ur, ur \u2212 1) = DTV (q, 0) = 1 and DTV (us + 1, us) = DTV (0, q) = 0 that m (uT1) = 1, while for r = 1, we have the sequence 1 = 1 and m (uT1) = 0. In all cases, m (uT1) gives + q.1 = 1. Specifying the sequence results in the so defined 2nd"}, {"heading": "5. Online tuning of the parameters", "text": "The above-mentioned forecasters need their parameters, which are adjusted according to different quantities (including the time horizon T). (We show here how the trick of Auer and al. (2002) to have these parameters over time can be extended to our setting. (For the sake of specificity, we are focusing on fixed share updating, i.e., algorithm 1 runs with the update (3). We replace steps 3 and 4 of its description with the loss and the shared update vj, t + 1 = p. (1) We focus on fixed share updating, i.e., algorithm 1 runs with the update (3). We replace steps 3 and 4 of its description with the loss and the shared update vj, t + 1 = p. (1) vj, t + 1, (11) for all."}, {"heading": "6. Online convex optimization and exp-concave loss functions", "text": "By using a default reduction, the results of the previous sections can be applied to the online-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t"}, {"heading": "6.1. Exp-concave loss functions", "text": "(1)..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "Appendix A. Proof of Proposition 8", "text": "We first have Lemma \u2212 n \u2212 n \u2212 n \u2212 n \u2212 n \u2212 n \u2212 n \u2212 n \u2212 n \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t \u2212 t (1) t (1) t \u2212 t (1) t (1) t \u2212 t (1) t (1 t) t (1 t) t \u2212 t (1 t) t (1 t) t (1 t) t (1 t) t \u2212 t (1 t) t, 1 t (1 t) t (1 t) t (1 t) t \u2212 t (1 t) t (1 t) t), 1 t (1 t) t (1 t) t \u2212 t (1 t) t (1 t) t (1 t), 1 t (1 t) t (1 t), 1 t (1 t (1 t) t (1 t), 1 t (1 t) t (1 t (1 t), 1 t (1 t (1) t (1 t) t \u2212 t (1 t), 1 t (1 (1 t) t (1 t) t (1 t (1) t (1 (1 t), 1 t (t) t (1 (t) t (1 (t), 1 (t) t (1 (t) t (1 (t), 1 (t), 1 (t (t), 1 (t), 1 (t (t), 1 (t (t), 1 (t), 1 (1 (t), 1 (t), 1 (t), 1 (t (t), 1 (1 (t), 1 (t), 1 (1 (t), 1 (t), 1 (t), 1 ("}, {"heading": "Appendix B. Proof of Proposition 11", "text": "Evidence By defining the Exp concavity and applying Jensen's inequality to the distribution Pt over (\u2206 d) t with densityrt1 7 \u2212 \u2192 1E [e \u2212 \u03b70Lt \u2212 1) e \u2212 \u03b70Lt \u2212 1 (rt \u2212 1) \u00b7 1with respect to the marginal distribution of P over (\u2206 d) t, we have this exp (\u2212) \u2212 E \u2212 \u2212 \u2212 t (p \u00b2 t)) = exp (\u2212 0 \u00b2 t (Et [Qt])) > Et [exp (\u2212 t (Qt))) = E [e \u2212 0Lt (Q t) \u2212 1)."}], "references": [{"title": "Adaptive and self-confident on-line learning algorithms", "author": ["P. Auer", "N. Cesa-Bianchi", "C. Gentile"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Universal portfolios with and without transaction costs", "author": ["A. Blum", "A. Kalai"], "venue": "In Proceedings of the 10th Annual Conference on Learning Theory (COLT),", "citeRegEx": "Blum and Kalai.,? \\Q1997\\E", "shortCiteRegEx": "Blum and Kalai.", "year": 1997}, {"title": "From extermal to internal regret", "author": ["A. Blum", "Y. Mansour"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Blum and Mansour.,? \\Q2007\\E", "shortCiteRegEx": "Blum and Mansour.", "year": 2007}, {"title": "Tracking a small set of experts by mixing past posteriors", "author": ["O. Bousquet", "M.K. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bousquet and Warmuth.,? \\Q2002\\E", "shortCiteRegEx": "Bousquet and Warmuth.", "year": 2002}, {"title": "Prediction, learning, and games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "Efficient projections onto the l1\u2013ball for learning in high dimensions", "author": ["J. Duchi", "S. Shalev-Shwartz", "Y. Singer", "T. Chandra"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "Duchi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2008}, {"title": "Tracking the best of many experts", "author": ["A. Gy\u00f6rgy", "T. Linder", "G. Lugosi"], "venue": "In Proceedings of the 18th Annual Conference on Learning Theory (COLT),", "citeRegEx": "Gy\u00f6rgy et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Gy\u00f6rgy et al\\.", "year": 2005}, {"title": "Efficient learning algorithms for changing environment", "author": ["E. Hazan", "C. Seshadhri"], "venue": "Proceedings of the 26th International Conference of Machine Learning (ICML),", "citeRegEx": "Hazan and Seshadhri.,? \\Q2009\\E", "shortCiteRegEx": "Hazan and Seshadhri.", "year": 2009}, {"title": "Tracking the best expert", "author": ["M. Herbster", "M. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "Herbster and Warmuth.,? \\Q1998\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 1998}, {"title": "Tracking the best linear predictor", "author": ["M. Herbster", "M. Warmuth"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Herbster and Warmuth.,? \\Q2001\\E", "shortCiteRegEx": "Herbster and Warmuth.", "year": 2001}, {"title": "Derandomizing stochastic prediction strategies", "author": ["V. Vovk"], "venue": "Machine Learning,", "citeRegEx": "Vovk.,? \\Q1999\\E", "shortCiteRegEx": "Vovk.", "year": 1999}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "In Proceedings of the 20th International Conference on Machine Learning,", "citeRegEx": "Zinkevich.,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich.", "year": 2003}], "referenceMentions": [{"referenceID": 7, "context": "Abstract We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002).", "startOffset": 99, "endOffset": 127}, {"referenceID": 3, "context": "Abstract We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002). These algorithms use weight sharing schemes to perform as well as the best sequence of experts with a limited number of changes.", "startOffset": 154, "endOffset": 182}, {"referenceID": 4, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006).", "startOffset": 116, "endOffset": 144}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers.", "startOffset": 148, "endOffset": 179}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift.", "startOffset": 148, "endOffset": 605}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called \u201ctracking the best expert\u201d \u2014see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al.", "startOffset": 148, "endOffset": 1175}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called \u201ctracking the best expert\u201d \u2014see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al.", "startOffset": 148, "endOffset": 1188}, {"referenceID": 3, "context": "typically computed in terms of the p-norm of the difference of consecutive elements in the comparison sequence \u2014see Herbster and Warmuth (2001) and Cesa-Bianchi and Lugosi (2006). In this paper we focus on the important special case when S is the simplex, and investigate the online mirror descent with entropic regularizers. This family includes popular algorithms such as exponentially weighted average (EWA), Winnow, and exponentiated gradient. Proving general shifting bounds in this case is difficult due to the behavior of the regularizer at the boundary of the simplex. Herbster and Warmuth (2001) show shifting bounds for mirror descent with entropic regularizers using a 1-norm to measure the shift. In order to keep mirror descent from choosing points too close to the simplex boundary, they use a complex dynamic projection technique. When the comparison sequence is restricted to the corners of the simplex (which is the setting of prediction with expert advice), then the shift is naturally defined to be the number times the trajectory moves to a different corner. This problem is often called \u201ctracking the best expert\u201d \u2014see, e.g., Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al.", "startOffset": 148, "endOffset": 1217}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al.", "startOffset": 73, "endOffset": 101}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting.", "startOffset": 73, "endOffset": 123}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting.", "startOffset": 73, "endOffset": 252}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex.", "startOffset": 73, "endOffset": 329}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002).", "startOffset": 73, "endOffset": 739}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance.", "startOffset": 73, "endOffset": 771}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance. The generalization of the \u201csmall expert set\u201d result in Bousquet and Warmuth (2002) leads us to obtain better bounds when the sequence against which the regret is measured is sparse.", "startOffset": 73, "endOffset": 949}, {"referenceID": 3, "context": ", Herbster and Warmuth (1998); Vovk (1999); Herbster and Warmuth (2001); Bousquet and Warmuth (2002); Gy\u00f6rgy et al. (2005), and it is well known that EWA with weight sharing, which corresponds to the fixedshare algorithm of Herbster and Warmuth (1998), achieves a good shifting bound in this setting. Bousquet and Warmuth (2002) introduce a generalization of the fixed-share algorithm, and prove various shifting bounds for any trajectory in the simplex. However, their bounds are expressed using a quantity that corresponds to a proper shift only for trajectories on the simplex corners. Our analysis unifies, generalizes (and simplifies) the previously quite different proof techniques and algorithms used in Herbster and Warmuth (1998) and Bousquet and Warmuth (2002). Our bounds are expressed in terms of a notion of shift based on the total variation distance. The generalization of the \u201csmall expert set\u201d result in Bousquet and Warmuth (2002) leads us to obtain better bounds when the sequence against which the regret is measured is sparse. When the trajectory is restricted to the corners of the simplex, we recover, and occasionally improve, the known shifting bounds for prediction with expert advice. Besides, our analysis also captures the setting of adaptive regret, a related notion of regret introduced by Hazan and Seshadhri (2009). It was known that shifting regret and adaptive regret had some connections but this connection is now seen to be even tighter, as both regrets can be viewed as instances of the same alma mater regret, which we minimize.", "startOffset": 73, "endOffset": 1348}, {"referenceID": 2, "context": "In the now classical results on tracking the best expert (as in Herbster and Warmuth 1998; Vovk 1999; Herbster and Warmuth 2001; Bousquet and Warmuth 2002), this regularity is measured as the number of times qt 6= qt+1 (henceforth referred to as \u201chard shifts\u201d). The main results of this paper show not only that these results may be generalized to obtain bounds in terms of \u201csofter\u201d regularity measures but that the same algorithms that were proposed with hard shift tracking in mind achieve such, perhaps surprisingly good, performance. Building on the general formulation introduced in Section 2, we derive such regret bounds for the fixed-share algorithm of Herbster and Warmuth (1998) and for the algorithms of Bousquet and Warmuth (2002).", "startOffset": 129, "endOffset": 689}, {"referenceID": 2, "context": "In the now classical results on tracking the best expert (as in Herbster and Warmuth 1998; Vovk 1999; Herbster and Warmuth 2001; Bousquet and Warmuth 2002), this regularity is measured as the number of times qt 6= qt+1 (henceforth referred to as \u201chard shifts\u201d). The main results of this paper show not only that these results may be generalized to obtain bounds in terms of \u201csofter\u201d regularity measures but that the same algorithms that were proposed with hard shift tracking in mind achieve such, perhaps surprisingly good, performance. Building on the general formulation introduced in Section 2, we derive such regret bounds for the fixed-share algorithm of Herbster and Warmuth (1998) and for the algorithms of Bousquet and Warmuth (2002). In fact, it is advantageous to extend our analysis so that we not only compare the performance of the forecaster with sequences q1, .", "startOffset": 129, "endOffset": 743}, {"referenceID": 2, "context": "Of particular interest is the case when \u2016ut\u20161 \u2208 [0, 1] which is the setting of \u201ctime selection functions\u201d (see Blum and Mansour 2007, Section 6). In particular, considering sequences \u2016ut\u20161 \u2208 {0, 1} that include the zero vector will provide us a simple way of deriving \u201cadaptive\u201d regret bounds, a notion introduced by Hazan and Seshadhri (2009). The first regret bounds derived below measure the regularity of the sequence u1 = (u1, .", "startOffset": 111, "endOffset": 344}, {"referenceID": 8, "context": "Despite seemingly different statements, this update in Algorithm 1 can be seen to lead exactly to the fixed-share algorithm of Herbster and Warmuth (1998) for prediction with expert advice.", "startOffset": 127, "endOffset": 155}, {"referenceID": 3, "context": "Sparse sequences: Bousquet-Warmuth updates Bousquet and Warmuth (2002) proposed forecasters that are able to efficiently compete with the best sequence of experts among all those sequences that only switch a bounded number of times and also take a small number of different values.", "startOffset": 43, "endOffset": 71}, {"referenceID": 3, "context": "Thus, n(u1 ) generalizes the notion of sparsity of Bousquet and Warmuth (2002). Here we consider a family of shared updates of the form p\u0302j,t = (1\u2212 \u03b1)vj,t + \u03b1 wj,t Zt , 0 6 \u03b1 6 1 , (7) where the wj,t are nonnegative weights that may depend on past and current pre-weights and Zt = \u2211d i=1 wi,t is a normalization constant.", "startOffset": 51, "endOffset": 79}, {"referenceID": 3, "context": "Thus, n(u1 ) generalizes the notion of sparsity of Bousquet and Warmuth (2002). Here we consider a family of shared updates of the form p\u0302j,t = (1\u2212 \u03b1)vj,t + \u03b1 wj,t Zt , 0 6 \u03b1 6 1 , (7) where the wj,t are nonnegative weights that may depend on past and current pre-weights and Zt = \u2211d i=1 wi,t is a normalization constant. Shared updates of this form were proposed by Bousquet and Warmuth (2002, Sections 3 and 5.2). Apart from generalizing the regret bounds of Bousquet and Warmuth (2002), we believe that the analysis given below is significantly simpler and more transparent.", "startOffset": 51, "endOffset": 489}, {"referenceID": 3, "context": "We now generalize Corollaries 8 and 9 of Bousquet and Warmuth (2002) by showing two specific instances of the generic update (7) that satisfy (8).", "startOffset": 41, "endOffset": 69}, {"referenceID": 3, "context": "In contrast, the corresponding algorithm of Bousquet and Warmuth (2002), using the updates p\u0302j,t = (1\u2212\u03b1)vj,t+\u03b1S t \u2211 s6t\u22121(s\u2212t)vj,s or p\u0302j,t = (1\u2212\u03b1)vj,t+\u03b1S t maxs6t\u22121(s\u2212t)vj,s, where St denote normalization factors, needs to maintain O(dT ) weights with a naive implementation, and O(d lnT ) weights with a more sophisticated one.", "startOffset": 44, "endOffset": 72}, {"referenceID": 7, "context": ", Proposition 2, imply guarantees in terms of adaptive regret \u2014a notion introduced by Hazan and Seshadhri (2009) as follows.", "startOffset": 86, "endOffset": 113}, {"referenceID": 6, "context": "Hazan and Seshadhri (2009) essentially considered the case of online convex optimization with exp-concave loss function (see Section 6 below).", "startOffset": 0, "endOffset": 27}, {"referenceID": 6, "context": "Hazan and Seshadhri (2009) essentially considered the case of online convex optimization with exp-concave loss function (see Section 6 below). In case of general convex functions, they also mentioned that the greedy projection forecaster of Zinkevich (2003) \u2014i.", "startOffset": 0, "endOffset": 258}, {"referenceID": 5, "context": ", Duchi et al. (2008). We now show that the simpler fixed-share algorithm has a similar adaptive regret bound.", "startOffset": 2, "endOffset": 22}, {"referenceID": 0, "context": "We show here how the trick of Auer et al. (2002) of having these parameters vary over time can be extended to our setting.", "startOffset": 30, "endOffset": 49}, {"referenceID": 3, "context": ") Bousquet and Warmuth (2002) study shifting regret for exp-concave loss functions.", "startOffset": 2, "endOffset": 30}, {"referenceID": 6, "context": "Hazan and Seshadhri (2009) constructed algorithms with T\u2013 adaptive regret of the order of O(ln T ) and running in time poly(d, log T ).", "startOffset": 0, "endOffset": 27}, {"referenceID": 6, "context": "Hazan and Seshadhri (2009) constructed algorithms with T\u2013 adaptive regret of the order of O(ln T ) and running in time poly(d, log T ). They also constructed different algorithms with T\u2013adaptive regret bounded by O(lnT )) and running time poly(d, T ). Next, we show the first logarithmic shifting bounds for exp-concave loss functions. However, we only do so against sequences q1 of elements in \u2206d, i.e., we offer here no general bound in terms of linear vectors u1 that would unify here as well the view between tracking bounds and adaptive regret bounds. Besides, we get shifting bounds only in terms of hard shifts s(q1 ) = \u2223t = 2, . . . , T : qt 6= qt\u22121 }\u2223\u2223 . Obviously, getting unifying bounds in terms of soft shifts of sequences u1 of linear vectors is an important open question, which we leave for future research. To get our bound, we mix ideas of Herbster and Warmuth (1998) and Blum and Kalai (1997).", "startOffset": 0, "endOffset": 886}, {"referenceID": 1, "context": "To get our bound, we mix ideas of Herbster and Warmuth (1998) and Blum and Kalai (1997). We define a prior over the sequences of convex weight vectors as the distribution of the following homogeneous Markov chain Q1, Q2, .", "startOffset": 66, "endOffset": 88}], "year": 2017, "abstractText": "We investigate extensions of well-known online learning algorithms such as fixed-share of Herbster and Warmuth (1998) or the methods proposed by Bousquet and Warmuth (2002). These algorithms use weight sharing schemes to perform as well as the best sequence of experts with a limited number of changes. Here we show, with a common, general, and simpler analysis, that weight sharing in fact achieves much more than what it was designed for. We use it to simultaneously prove new shifting regret bounds for online convex optimization on the simplex in terms of the total variation distance as well as new bounds for the related setting of adaptive regret. Finally, we exhibit the first logarithmic shifting bounds for exp-concave loss functions on the simplex.", "creator": "LaTeX with hyperref package"}}}