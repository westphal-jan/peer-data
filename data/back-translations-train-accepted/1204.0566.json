{"id": "1204.0566", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Apr-2012", "title": "The Kernelized Stochastic Batch Perceptron", "abstract": "We present a novel approach for training kernel Support Vector Machines, establish learning runtime guarantees for our method that are better then those of any other known kernelized SVM optimization approach, and show that our method works well in practice compared to existing alternatives.", "histories": [["v1", "Tue, 3 Apr 2012 00:33:53 GMT  (505kb)", "https://arxiv.org/abs/1204.0566v1", null], ["v2", "Thu, 21 Jun 2012 12:14:24 GMT  (1043kb)", "http://arxiv.org/abs/1204.0566v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["andrew cotter", "shai shalev-shwartz", "nathan srebro"], "accepted": true, "id": "1204.0566"}, "pdf": {"name": "1204.0566.pdf", "metadata": {"source": "META", "title": "The Kernelized Stochastic Batch Perceptron", "authors": ["Andrew Cotter"], "emails": ["cotter@ttic.edu", "shais@cs.huji.ac.il", "nati@ttic.edu"], "sections": [{"heading": null, "text": "ar Xiv: 120 4.05 66v2 [cs.LG] 2 1Ju n"}, {"heading": "1. Introduction", "text": "In fact, it has been shown in recent years that he is able to hide and that he is able to assert himself in a position."}, {"heading": "2. Setup and Formulations", "text": "The formation of an SVM amounts to finding a vector w that defines a classifier x 7. (< w, \u03a6 (x) >), which on the one hand has a small standard (corresponding to a large classification range) and on the other hand has a small training error, which is measured by the average difference loss on the learning sample. (a) = max (0, 1 \u2212 a) is the difference loss. This is captured by the following bi-criterional optimization problems: min w, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p)."}, {"heading": "3. The Stochastic Batch Perceptron", "text": "In this section we will develop the stochastic batch perceptron. We consider problem 2.3 to be an optimization of the variable w with a single constraint, namely: f (w) = max. 0.1T = min p-nn = 1pi (yi < w, \u03a6 (xi) > + economii) (3.1) Note that we have replaced the minimization of the training indexes i in problem 2.3 with an equivalent minimization via the probability simplex. Target f (w) is a concave function of w, and we maximize it across a convex constraint, and so this is a convex optimization problem. Target f (w) is a convex function of w, and we maximize it across a convex constraint."}, {"heading": "3.1. Warmup: The Separable Case", "text": "The target is then: f (w) = min iyi < w, p (xi) > p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p (p) p, p, p, p, p, p, p, p, p, p, p (p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p (p) p (p) p (p) p, p (p) p (p) p (p) p, p (p) p (p, p (p) p, p (p) p (p, p, p, p (p) p, p (p) p, p (p, p, p, p, p) p (p, p, p, p (p) p, p, p (p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p (p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p (p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p,"}, {"heading": "3.3. Kernelized Implementation", "text": "In a kernelized SVM, w is an element of an implicit space and cannot be explicitly represented. Therefore, we represent w as w = \u2211 n = 1 \u03b1iyi\u03a6 (xi) and do not capture w itself, but rather the coefficients \u03b1i. Our stochastic gradient estimates are always in the form yi\u03a6 (xi) for an index i. One step in this direction is simply to increase the corresponding number of core evaluations per iteration. We could calculate all answers ci for each iteration as ci = \u2211 n j = 1 \u03b1jyiyjK (xi, xj), but this would require a square number of core evaluations per iteration. Instead, as is usually the case with kernelized SVM implementations, we keep the answers ci at hand, and after each stochastic gradient step of the form w \u00b2 w + \u03b7yj\u0438 (xj) we update the answers as: ci + activicijK (xi, xj) (3.4)."}, {"heading": "3.4. Putting it Together", "text": "We are now ready to summarize the SBP algorithm. Starting with w (0) = 0 (so that both \u03b1 (0) and all answers are equal to zero), each iteration proceeds as follows: 1. Find p \u00b2 by determining the \"water level\" from the re-sponses (Section 3.2) and projecting P \u00b2 onto the unit sphere and apportioning these indexes equally. 2. First, increase the number j \u00b2 p \u00b2 and update the answers as in Equation 3.4, then calculate w \u00b2 (Section 3.3) and scale \u03b1 and c by min (1, 1 / 2). Updating the answers as in Equation 3.4 will result in updating the answers as in Equation 3.4 by requiring O (scaling the kernel evaluations as in Equation 3.3) and scaling \u03b1 and c by min (1 / 2).Updating the answers as in Equation 3.4 requires O \u00b2 kernel evaluations (the mathematically most expensive part) and all other operations require O (scaling the kernel and the answers as in Part 3.1), as in Part 3.1 / O."}, {"heading": "3.5. Learning Runtime", "text": "The previous section has given us the runtime for obtaining some sub-optimality of problem 2.3. However, since the sub-optimality in this goal is not directly comparable to the sub-optimality of other scalarizations, e.g. problem 2.2, we are following Bottou & Bousquet (2008); Shalev-Shwartz & Srebro (2008), and analyzing the runtime required to achieve a desired generalization performance, instead, to achieve some optimization accuracy with respect to the empirical optimization problem. Note that our true learning goal is to find a predictor with low generalization errors L0 / 1 (w) = Pr (x, y) {y < w (x) > \u2264 0} with respect to an unknown distribution over x, y based on a training set that i.i.d. We assume that there are some (unknown) predictors that give standard and low expected losses (L)."}, {"heading": "3.6. Including an Unregularized Bias", "text": "It is possible to use the SBP to form SVMs with a prejudice concept, i.e., when looking for a predictor of the form x 7 \u2192 (< w, \u03a6 (x) > + b). We then proceed to stochastic gradient steps: f (w) = (3.9) max b-R, 0 1 T-0, 0 T-0 min p-3, i = 1pi (yi < w, \u03a6 (xi) > + yib + \u0441i) Lemma 3.1 still holds, but we now need to find minimax optimal p-3, p-3 and b-3. This can be achieved by a modified \"water filling\" with two tanks, one of which contains the positively classified examples and the other containing the negatively classified examples. As in the case without unregulated bias, this can be achieved in O (n) time - see Annex B for details."}, {"heading": "4. Relationship to Other Methods", "text": "We discuss the relationship between the SBP and several other SVM optimization approaches, highlight similarities and significant differences, and compare their performance guarantees."}, {"heading": "4.1. SIMBA", "text": "Recently, Hazan et al. (2011) introduced SIMBA, a method for training linear SVMs based on the same \"slack bound\" scalarization (problem 2.3) that we use here. SIMBA also completely optimizes the slack variables with each iteration, but differs in that the SBP iteration is not fully optimized via the distribution p (as the SBP does), but updates p by means of a stochastic mirror descend.The SBP theoretical warranty (Lemma 3.2) is then updated accordingly better by a logarithmic factor (compared with Hazan et al. (2011, theorem 4.3). All other properties are similarly more \"thorough\" than a SIMBA iteration. The SBP theoretical warranty (Lemma 3.2) is correspondingly better by a logarithmic factor (compared with Hazan et al.). (Theorem 4.3), the SBP iteration is more similar to the Iteration in SBP."}, {"heading": "4.2. Pegasos and SGD on L\u0302(w)", "text": "Pegasos (Shalev-Shwartz et al., 2011) is an SGD method for optimizing the regularized scalarization of problem 2.2. Alternatively, SGD can be performed on the basis of the constraint that applies in this example, and provide similar learning guarantees (e.g. (Zhang, 2004). At each iteration, these algorithms randomly select an example from the training set. If the margin constraint is violated on the example, w is updated by adding a scaled version of yi\u03a6 (xi) to the example. Then, w is scaled and possibly projected back to the actual update that is performed on each iteration.The main difference is that in Pegasos and the related SGD approaches, examples are selected that randomly search the SBP approaches, as opposed to the SBP approaches, which are random samples from the series of violating examinations. In a linear SVM, the SGD sets are the SGD and SGZ sets only."}, {"heading": "4.3. Dual Decomposition Methods", "text": "Many of the most popular packages for optimizing kernel SVMs, including LIBSVM (Chang & Lin, 2001) and SVM-Light (Joachims, 1998), use dual decompositional approaches. This family of algorithms operates on dual scalarization 2.2, specified by: max. \u03b1 [0, 1\u03bbn] nn \u00b2 i = 1\u03b1i \u2212 12n \u00b2 i, j = 1\u03b1i\u03b1jyiyjK (xi, xj) (4.1), iteratively selecting a small set of dual variables \u03b1i and then optimizing over these variables, while fixing all other dual variables. In an extreme case, SMO (Platt, 1998) uses a smallest possible size approach (two problems with unregulated bias, one with no problems), and most dual decomposition approaches rely on access to all ci responses (as in the SBP) and employ some heuristic variables that are selected."}, {"heading": "4.4. Stochastic Dual Coordinate Ascent", "text": "Another variant of the dual decomposition approach is to randomly select a single \u03b1i for each iteration and update it to optimize Equation 4.1 (Hsieh et al., 2008). The advantage is that we do not have to use all the answers for each iteration, so that if it is easy to calculate responses to demand, as in the case of linear SVMs, any SDCA iteration can be calculated temporally O (d) (Hsieh et al., 2008). In a sense, SDCA refers to SMO in a manner similar to Pegasos to the SBP: SDCA and Pegasos are preferable for linear SVMs because they randomly select work points; SMO and SBP choose work points based on more information (namely the answers), which are unnecessarily expensive to calculate in the linear case, but, as discussed above, are essentially \"free,\" as they randomly select work points; namely, select SMCO and SBP's answers are best for the SBP and SBP's answers (i.e., the SBP's answers are based on the SBP and the SBP's), whereas the SBP's answers are (i.e. the SCO's and SBP's), respectively, the SBP's answers are best."}, {"heading": "4.5. The Online Perceptron", "text": "So far, we have only considered the problem of optimizing the bi-criterion SVM goal of problem 2.1. However, since the online perctron achieves the same form of learning guarantee (although it does not optimize the bi-criterion goal), it is reasonable to consider it as good. The online perctron makes a single pass over the training set. At each iteration, the number of errors made by the perctron in the sequence of examples is added (i.e. yi < w, \u03a6 (xi) > \u2264 0), then added in w. Let M be the number of errors made by the perctron in the sequence of examples. Support vectors are only added when a mistake is made, and so any iteration of the perctron is involved in most M-kernel ratings. Therefore, the total runtime is Mass. While the Perceptron is an online learning algorithm, it can also be used for generalization."}, {"heading": "5. Experiments", "text": "We compared the SBP with other SVM optimization approaches based on the datasets in Table 2. We compared Pegasos (Shalev-Shwartz et al., 2011), SDCA (Hsieh et al., 2008), and SMO (Platt, 1998) with a second heuristic error analysis for the selection of operating points (Fan et al., 2005). These approaches work on the regularized formulation of problem 2.2 or their dual (problem 4.1). To enable comparison, the parameter for the SBP was derived from the second-order error in the selection of operating points (Fan et al., 2005)."}, {"heading": "6. Summary and Discussion", "text": "The Stochastic Batch Perceptron is a novel approach to the training of kernelized SVMs. The SBP performs empirically well and, as summarized in Table 1, our runtime guarantee for the SBP is the best of all existing guarantees for kernelized SVM training. An interesting open question is whether this runtime is optimal, i.e. whether an algorithm based solely on black box kernel access needs to perform kernel evaluations (((L + B) 3 or 4 / E). As with other stochastic gradient methods, deciding when to stop SBP optimization is an open question. The most practical approach seems to be to stop when a holdout error stabilizes. We should note that even with methods where the duality gap can be exploited (e.g. SMO), this criterion is often too strict, and the use of crusty criteria can improve training times."}, {"heading": "Blum, M., Floyd, R. W., Pratt, V., Rivest, R. L., and", "text": "Tarjan, R. E. Time limits for selection. JCSS, 7 (4): 448-461, August 1973.Bottou, L. and Bousquet, O. The trade-offs of large scale learning. In NIPS '08, pp. 161-168, 2008.Cesa-Bianchi, N., Conconi, A., and Gentile, C. On the generalization of on-line learning algorithms. IEEE Trans. on Inf. Theory, 50: 2050-2057, 2001.Chang, C-C. and Lin, C-J. LIBSVM: a library for support vector machines, 2001. Software available at http: / / www.csie.ntu.edu.tw / ~ cjlin / libsvm.Chen, P-H., Fan, R-E., and Lin, C-J. A study on smo-type decomposition methods for support vector machines. IEEE Transactions on Neural Networks, 17 (4): 893-2006."}, {"heading": "Collins, M., Globerson, A., Koo, T., Carreras, X., and", "text": "Bartlett, P. Exponentiated gradient algorithms for conditional random fields and max-margin markov net-works. JMLR, 9: 1775-1822, 2008.Fan, R-E., Chen, P-S., and Lin, C-J. Working set selection using second order information for training support vector machines. JMLR, 6: 1889-1918, 2005.Hazan, E., Koren, T., and Srebro, N. Beating SGD: Learning SVMs in sublinear time. In NIPS '11, 2011."}, {"heading": "Hsieh, C-J., Chang, K-W., Lin, C-J., Keerthi, S. S., and", "text": "Sundararajan, S. A method for deriving two coordinates for large-scale linear SVM. In ICML '08, pp. 408-415, 2008.Hush, D., Kelly, P., Scovel, C., and Steinwart, I. QP algorithms with guaranteed accuracy and runtime for supporting vector machines. JMLR, 7: 733-769, 2006.Joachims, T. The practical implementation of large-scale supportive vector learning methods. In Scho \ufffd lkopf, B., Burges, C., and Smola, A. J. (ed.), Advances in Kernel Methods - Support Vector Learning. MIT Press, 1998.Kakade, S. M. and Tewari, A. On the generalization capability of strongly convex online programming algorithms. In NIPS' 09, 2009."}, {"heading": "Nguyen, D D, Matsumoto, K., Takishima, Y., and", "text": "Hashimoto, K. Condensed vector machines: fast learning machine for large amounts of data. Trans. Neur. Netw., 21 (12): 1903-1914, December 2010.Platt, J. C. Fast training of support vector machines for sequential minimum optimization. In Scholkopf, B., Burges, C., and Smola, A. J. (eds.), Advances in Kernel Methods - Support Vector Learning. MIT Press, 1998.Rahimi, A. and Recht, B. Random features for large scale kernel machines. In NIPS '07, 2007.Scovel, C., Hush, D., and Steinwart, I. Approximate duality. JOTA, 2008.Shalev-Shwartz, S. Online Learning: Theory, Algorithms, and Applications. Dissertation, The Hebrew University of Jerusalem, July 2007.Shalev-Shwartz, S. and Srebro, SVM: Inverse Training 2008 ICL."}, {"heading": "Shalev-Shwartz, S., Singer, Y., Srebro, N., and Cotter,", "text": "A. Pegasos: Primal Estimated sub-GrAdient SOlver for SVM. Mathematical Programming, 127 (1): 3-30, March 2011."}, {"heading": "Srebro, N., Sridharan, K., and Tewari, A. Smoothness,", "text": "In ICML '04, 2004.Zinkevich, M. Online convex programming and generalized infinitesimal gradient ascent. In ICML' 03, 2003."}, {"heading": "A. Additional Experiments", "text": "While our focus in this work is on optimizing the kernel SVM objectively, and not on the broader problem of large-scale learning, one may wonder how well the SBP problem can be converted into techniques that speed up the formation of the kernel SVM by approximating it. Such a problem can then be optimized using one of the many existing fast linear SVM solvers such as Pegasos, SDCA, or SIMBA. Unlike methods (such as the SBP) that rely only on black box kernel accesses, Rahimi and right-projection techniques can only be applied to a specific class of kernel functions (shift-invariant kernels), of which the Gaussian kernel is a member.For d-dimensional feature vectors, and the use of a Gaussian kernel with parameters 2, Rahimi, and Rahi technology."}, {"heading": "C. Proofs of Lemmas 3.1 and 3.2", "text": "In the definition of f, for each v-round: f (w + v) = max. (f + v) = max. (f + v) = max. (f + v) = max. (f + v) = max. (f + v) = max. (f + v) = max. (f + v) = max. (f + v) = max. (f + v) = max. (f + v) = max. (f): max. (f + v) max. (f): max. (f). (f + v). (f). (f): max. (f). (f). (f): max. (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f): max. (f). (f). (f). (f). (f)."}, {"heading": "D. Data-Laden Analyses", "text": "We begin by limiting the sample size n, which is necessary to guarantee good generalization performance (in relation to the 0 / 1 loss) for a classifier that is \"suboptimal\" in terms of empirical hinge loss. Consider the expected 0 / 1 and hinge losses: L0 / 1 (w) = Ex, y [1y < w, x > 0] L (w) = Ex, y [max (0, 1 \u2212 y < w, x >)] Let us be an arbitrary linear classifier and assume that we derive a formation set of size n, with n given by the following equation, for the parameters B \u00b2 u \u00b2 and vice versa: L \u00b2 (0, 1) and L \u00b2 (u)."}, {"heading": "D.1. Stochastic Batch Perceptron", "text": "We will present here a more cautious derivation of the main result of Section 3,5, which is the generalization performance of the SBP. Theorem D.2. Let u be an arbitrary linear classifier in the RKHS, let.: K (x, x) \u2264 r2 with probability 1. There exist values of the training size n, iteration count T and parameter \u03bd such that Algorithm 1 find a solution w = p = p = p (xi) satisfying: L0 / 1 (w) \u2264 r2 with probability 1. Algorithm 2 Divide-and-conquer algorithm for finding the \"water level.\" The partition function selects a pivot value from the array it receives as argument (the median would be ideal), places all values less than the array, all values than the array, all more at the array, and returns of the index of the pivot value."}, {"heading": "D.2. Pegasos / SGD on L\u0302", "text": "If we get the result of a call to the Pegasos algorithm (Shalev-Shwartz et al., 2011) without a projection step, then the analysis by Kakade & Tewari (2009, Corollary 7) will allow us to bind the suboptimality in relation to an arbitrary reference classification (D.3), with the probability that one will perform the following number of iterations, then the resulting solution will be in the regularized objective. (D.3) 84r2 logT.3 logT.3 implies that one will perform the following number of iterations, then the resulting number of iterations will be. (2-suboptimal in the regularized objective, with the probability of 1 \u2212 2)."}, {"heading": "D.3. Perceptron", "text": "Analysis of the time-honored online algorithm is typically presented as if the number of errors made by the algorithm with respect to the loss of the best classifier is limited. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < &"}, {"heading": "E. Convergence rates of dual optimization methods", "text": "In this section we discuss existing analyses of dual optimisation methods. First, we highlight possible gaps between dual sub-optimality and primary sub-optimality. In order to relate existing analyses in the literature of dual sub-optimality, we have to find a way to establish a connection between dual sub-optimality and primary sub-optimality. We do this using a result from Scovel et al. (2008), and on the basis of this result, we derive convergence rates from the primary sub-optimality. In this section, the \"SVM problem\" is regarded as a controlled target of the problem 2.2. Let us label the primary target with: P (w) = 2-W-W-W-W-W-W-W-W-W-W-W-W-W-W-W-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D"}, {"heading": "E.1. Dual gap vs. Primal gap", "text": "Several authors analyzed the convergence rate of the dual optimization algorithms. For example, Hsieh et al. (2008); Collins et al. (2008) analyzed the convergence rate of SDCA and Chen et al. (2006) analyzed the convergence rate of SMO-type dual decomposition methods. However, in both cases, the number of iterations required to analyze the dual sub-optimization rate in most cases requires. This is not satisfactory, since our goal is to understand how many iterations are required to achieve a primary sub-optimization analysis in most cases. In fact, the following problem shows that a guarantee for a small dual sub-optimization distribution is a trivial guarantee for the primary sub-optimality.Lemma E.1. For each individual sub-optimization distribution, there is an SVM problem with a dual solution that is absolutely accurate, while the universally distributive is primal."}], "references": [{"title": "The tradeoffs of large scale learning", "author": ["L. Bottou", "O. Bousquet"], "venue": "In NIPS\u201908,", "citeRegEx": "Bottou and Bousquet,? \\Q2008\\E", "shortCiteRegEx": "Bottou and Bousquet", "year": 2008}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "IEEE Trans. on Inf. Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2001}, {"title": "LIBSVM: a library for support vector machines", "author": ["Chang", "C-C", "Lin", "C-J"], "venue": null, "citeRegEx": "Chang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2001}, {"title": "Working set selection using second order information for training support vector machines", "author": ["Fan", "R-E", "Chen", "P-S", "Lin", "C-J"], "venue": null, "citeRegEx": "Fan et al\\.,? \\Q1889\\E", "shortCiteRegEx": "Fan et al\\.", "year": 1889}, {"title": "Beating SGD: Learning SVMs in sublinear time", "author": ["E. Hazan", "T. Koren", "N. Srebro"], "venue": "In NIPS\u201911,", "citeRegEx": "Hazan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2011}, {"title": "A dual coordinate descent method for large-scale linear SVM", "author": ["Hsieh", "C-J", "Chang", "K-W", "Lin", "S.S. Keerthi", "S. Sundararajan"], "venue": "In ICML\u201908,", "citeRegEx": "Hsieh et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hsieh et al\\.", "year": 2008}, {"title": "QP algorithms with guaranteed accuracy and run time for support vector machines", "author": ["D. Hush", "P. Kelly", "C. Scovel", "I. Steinwart"], "venue": null, "citeRegEx": "Hush et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hush et al\\.", "year": 2006}, {"title": "Making large-scale support vector machine learning practical", "author": ["T. Joachims"], "venue": null, "citeRegEx": "Joachims,? \\Q1998\\E", "shortCiteRegEx": "Joachims", "year": 1998}, {"title": "On the generalization ability of online strongly convex programming algorithms", "author": ["S.M. Kakade", "A. Tewari"], "venue": "In NIPS\u201909,", "citeRegEx": "Kakade and Tewari,? \\Q2009\\E", "shortCiteRegEx": "Kakade and Tewari", "year": 2009}, {"title": "Condensed vector machines: learning fast machine for large data", "author": ["D D Nguyen", "K. Matsumoto", "Y. Takishima", "K. Hashimoto"], "venue": "Trans. Neur. Netw.,", "citeRegEx": "Nguyen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2010}, {"title": "Random features for large-scale kernel machines", "author": ["A. Rahimi", "B. Recht"], "venue": "In NIPS\u201907,", "citeRegEx": "Rahimi and Recht,? \\Q2007\\E", "shortCiteRegEx": "Rahimi and Recht", "year": 2007}, {"title": "Online Learning: Theory, Algorithms, and Applications", "author": ["S. Shalev-Shwartz"], "venue": "PhD thesis,", "citeRegEx": "Shalev.Shwartz,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz", "year": 2007}, {"title": "SVM optimization: Inverse dependence on training set size", "author": ["S. Shalev-Shwartz", "N. Srebro"], "venue": "In ICML\u201908,", "citeRegEx": "Shalev.Shwartz and Srebro,? \\Q2008\\E", "shortCiteRegEx": "Shalev.Shwartz and Srebro", "year": 2008}, {"title": "Pegasos: Primal Estimated sub-GrAdient SOlver for SVM", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter"], "venue": "Mathematical Programming,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}, {"title": "Smoothness, low-noise and fast rates", "author": ["N. Srebro", "K. Sridharan", "A. Tewari"], "venue": "In NIPS\u201910,", "citeRegEx": "Srebro et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2010}, {"title": "Solving large scale linear prediction problems using stochastic gradient descent algorithms", "author": ["T. Zhang"], "venue": "In ICML\u201904,", "citeRegEx": "Zhang,? \\Q2004\\E", "shortCiteRegEx": "Zhang", "year": 2004}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "In ICML\u201903,", "citeRegEx": "Zinkevich,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich", "year": 2003}, {"title": "Dual gap vs. Primal gap Several authors analyzed the convergence rate of dual optimization algorithms", "author": ["D(\u03b1) = D\u2217 E"], "venue": "For example, Hsieh et al", "citeRegEx": "E.1.,? \\Q2008\\E", "shortCiteRegEx": "E.1.", "year": 2008}, {"title": "analyzed the convergence rate of SMO-type dual decomposition methods. In both cases, the number of iterations required so that the dual sub-optimality will be at most \u01eb is analyzed", "author": ["SDCA", "Chen"], "venue": null, "citeRegEx": "SDCA and Chen,? \\Q2006\\E", "shortCiteRegEx": "SDCA and Chen", "year": 2006}, {"title": "combined explicit convergence rate analysis of the dual sub-optimality of certain decomposition methods with Theorem E.2. The end result is an algorithm with a bound of O(n) on the number", "author": ["k. Hush"], "venue": null, "citeRegEx": "Hush,? \\Q2006\\E", "shortCiteRegEx": "Hush", "year": 2006}], "referenceMentions": [{"referenceID": 13, "context": "The SBP is fundamentally different from Pegasos (Shalev-Shwartz et al., 2011) and other stochastic gradient approaches to the problem of training SVMs, in", "startOffset": 48, "endOffset": 77}, {"referenceID": 4, "context": "In particular, we use the \u201cslack constrained\u201d scalarized optimization problem introduced by Hazan et al. (2011) where we seek to maximize the classification margin, subject to a constraint on the total amount of \u201cslack\u201d, i.", "startOffset": 92, "endOffset": 112}, {"referenceID": 11, "context": "In order to compare the SBP runtime to the runtime of other SVM optimization algorithms, which typically work on different scalarizations of the bi-criterion problem, we follow Bottou & Bousquet (2008); Shalev-Shwartz & Srebro (2008) and compare the runtimes required to ensure a generalization error of L\u2217 + \u01eb, assuming the existence of some unknown predictor u with norm \u2016u\u2016 and expected hinge loss L\u2217.", "startOffset": 203, "endOffset": 234}, {"referenceID": 4, "context": "We instead consider the \u201cslack constrained\u201d scalarization (Hazan et al., 2011), where we maximize the \u201cmargin\u201d subject to a constraint of \u03bd on the total allowed \u201cslack\u201d, corresponding to the average error.", "startOffset": 58, "endOffset": 78}, {"referenceID": 10, "context": "2, we follow Bottou & Bousquet (2008); Shalev-Shwartz & Srebro (2008), and analyze the runtime required to achieve a desired generalization performance, instead of that to achieve a certain optimization accuracy on the empirical optimization problem.", "startOffset": 39, "endOffset": 70}, {"referenceID": 4, "context": "Following Hazan et al. (2011), and based on the generalization guarantees of Srebro et al.", "startOffset": 10, "endOffset": 30}, {"referenceID": 4, "context": "Following Hazan et al. (2011), and based on the generalization guarantees of Srebro et al. (2010), using a sample of size:", "startOffset": 10, "endOffset": 98}, {"referenceID": 4, "context": "SIMBA Recently, Hazan et al. (2011) presented SIMBA, a method for training linear SVMs based on the same \u201cslack constrained\u201d scalarization (Problem 2.", "startOffset": 16, "endOffset": 36}, {"referenceID": 13, "context": "Pegasos and SGD on L\u0302(w) Pegasos (Shalev-Shwartz et al., 2011) is a SGD method optimizing the regularized scalarization of Problem 2.", "startOffset": 33, "endOffset": 62}, {"referenceID": 15, "context": "(Zhang, 2004)).", "startOffset": 0, "endOffset": 13}, {"referenceID": 7, "context": "Dual Decomposition Methods Many of the most popular packages for optimizing kernel SVMs, including LIBSVM (Chang & Lin, 2001) and SVM-Light (Joachims, 1998), use dualdecomposition approaches.", "startOffset": 140, "endOffset": 156}, {"referenceID": 6, "context": "To the best of our knowledge, the most satisfying analysis for a dual decomposition method is the one given in Hush et al. (2006). In terms of learning runtime, this analysis yields a runtime of \u00d5 (", "startOffset": 111, "endOffset": 130}, {"referenceID": 5, "context": "1 (Hsieh et al., 2008).", "startOffset": 2, "endOffset": 22}, {"referenceID": 5, "context": "The advantage here is that we do not need to use all of the responses at each iteration, so that if it is easy to calculate responses on-demand, as in the case of linear SVMs, each SDCA iteration can be calculated in time O(d) (Hsieh et al., 2008).", "startOffset": 227, "endOffset": 247}, {"referenceID": 1, "context": "(Cesa-Bianchi et al., 2001)).", "startOffset": 0, "endOffset": 27}, {"referenceID": 1, "context": "(Cesa-Bianchi et al., 2001)), and is therefore valid only for a single pass over the data.", "startOffset": 0, "endOffset": 27}, {"referenceID": 13, "context": "We compared to Pegasos (Shalev-Shwartz et al., 2011), SDCA (Hsieh et al.", "startOffset": 23, "endOffset": 52}, {"referenceID": 5, "context": ", 2011), SDCA (Hsieh et al., 2008), and SMO (Platt, 1998) with a second order heuristic for working point selection (Fan et al.", "startOffset": 14, "endOffset": 34}, {"referenceID": 3, "context": ", 2008), and SMO (Platt, 1998) with a second order heuristic for working point selection (Fan et al., 2005). These approaches work on the regularized formulation of Problem 2.2 or its dual (Problem 4.1). To enable comparison, the parameter \u03bd for the SBP was derived from \u03bb as \u2016\u0175\u2217\u2016 \u03bd = 1 n \u2211n i=1 l (yi \u3008w\u2217,\u03a6 (xi)\u3009), where \u0175\u2217 is the known (to us) optimum. We first compared the methods on a SVM formulation without an unregularized bias, since Pegasos and SDCA do not naturally handle one. So that this comparison would be implementation-independent, we measure performance in terms of the number of kernel evaluations. As can be seen in Figure 2, the SBP outperforms Pegasos and SDCA, as predicted by the upper bounds. The SMO algorithm has a dramatically different performance profile, in line with the known analysis: it makes relatively little progress, in terms of generalization error, until it reaches a certain critical point, after which it converges rapidly. Unlike the other methods, terminating SMO early in order to obtain a cruder solution does not appear to be advisable. We also compared to the online Perceptron algorithm. Although use of the Perceptron is justified for nonseparable data only if run for a single pass over the training set, we did continue running for multiple passes. The Perceptron\u2019s generalization performance is similar to that of the SBP for the first epoch, but the SBP continues improving over additional passes. As discussed in Section 4.5, the Perceptron is unsafe and might overfit after the first epoch, an effect which is clearly visible on the Adult dataset. To give a sense of actual runtime, we compared our implementation of the SBP to the SVM package LIBSVM, running on an Intel E7500 processor. We Source code is available from http://ttic.uchicago.edu/~cotter/projects/SBP allowed an unregularized bias (since that is what LIBSVM uses), and used the parameters in Table 2. For these experiments, we replaced the Reuters dataset with the version of the Forest dataset used by Nguyen et al. (2010), using their parameters.", "startOffset": 90, "endOffset": 2049}, {"referenceID": 13, "context": "Pegasos / SGD on L\u0302 If w is the result of a call to the Pegasos algorithm (Shalev-Shwartz et al., 2011) without a projection step, then the analysis of Kakade & Tewari (2009, Corollary 7) permits us to bound the suboptimality relative to an arbitrary reference classifier u, with probability 1\u2212 \u03b4, as:", "startOffset": 74, "endOffset": 103}, {"referenceID": 11, "context": "To see this, we\u2019ll follow Shalev-Shwartz & Srebro (2008) by decomposing the suboptimality in the empirical hinge loss as:", "startOffset": 26, "endOffset": 57}, {"referenceID": 11, "context": "If we run the online Perceptron algorithm for a single pass over the dataset, then Corollary 5 of (Shalev-Shwartz, 2007) gives the following mistake bound, for M being the set of iterations on which a", "startOffset": 98, "endOffset": 120}, {"referenceID": 1, "context": "Cesa-Bianchi et al. (2001)) would likely improve this term to log 1 \u03b4 .", "startOffset": 0, "endOffset": 27}, {"referenceID": 5, "context": "For example, Hsieh et al. (2008); Collins et al.", "startOffset": 13, "endOffset": 33}, {"referenceID": 5, "context": "For example, Hsieh et al. (2008); Collins et al. (2008) analyzed the convergence rate of SDCA and Chen et al.", "startOffset": 13, "endOffset": 56}, {"referenceID": 5, "context": "For example, Hsieh et al. (2008); Collins et al. (2008) analyzed the convergence rate of SDCA and Chen et al. (2006) analyzed the convergence rate of SMO-type dual decomposition methods.", "startOffset": 13, "endOffset": 117}, {"referenceID": 5, "context": "Hush et al. (2006) combined explicit convergence rate analysis of the dual sub-optimality of certain decomposition methods with Theorem E.", "startOffset": 0, "endOffset": 19}, {"referenceID": 5, "context": "Hsieh et al. (2008) analyzed the convergence rate of SDCA and derived a bound on the duality suboptimality after performing T iterations.", "startOffset": 0, "endOffset": 20}], "year": 2012, "abstractText": "We present a novel approach for training kernel Support Vector Machines, establish learning runtime guarantees for our method that are better then those of any other known kernelized SVM optimization approach, and show that our method works well in practice compared to existing alternatives.", "creator": "LaTeX with hyperref package"}}}