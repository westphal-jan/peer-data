{"id": "1205.0622", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-May-2012", "title": "No-Regret Learning in Extensive-Form Games with Imperfect Recall", "abstract": "Counterfactual Regret Minimization (CFR) is an efficient no-regret learning algorithm for decision problems modeled as extensive games. CFR's regret bounds depend on the requirement of perfect recall: players always remember information that was revealed to them and the order in which it was revealed. In games without perfect recall, however, CFR's guarantees do not apply. In this paper, we present the first regret bound for CFR when applied to a general class of games with imperfect recall. In addition, we show that CFR applied to any abstraction belonging to our general class results in a regret bound not just for the abstract game, but for the full game as well. We verify our theory and show how imperfect recall can be used to trade a small increase in regret for a significant reduction in memory in three domains: die-roll poker, phantom tic-tac-toe, and Bluff.", "histories": [["v1", "Thu, 3 May 2012 05:54:14 GMT  (79kb,D)", "http://arxiv.org/abs/1205.0622v1", "21 pages, 4 figures, expanded version of article to appear in Proceedings of the Twenty-Ninth International Conference on Machine Learning"]], "COMMENTS": "21 pages, 4 figures, expanded version of article to appear in Proceedings of the Twenty-Ninth International Conference on Machine Learning", "reviews": [], "SUBJECTS": "cs.GT cs.AI", "authors": ["marc lanctot", "richard g gibson", "neil burch", "michael bowling"], "accepted": true, "id": "1205.0622"}, "pdf": {"name": "1205.0622.pdf", "metadata": {"source": "CRF", "title": "No-Regret Learning in Extensive-Form Games with Imperfect Recall", "authors": ["Marc Lanctot", "Richard Gibson", "Neil Burch", "Martin Zinkevich", "Michael Bowling"], "emails": [], "sections": [{"heading": null, "text": "The limits of regretting the CFR depend on the requirement for a perfect memory: players always remember the information that was revealed to them and the order in which it was revealed. In games without perfect memory, however, the CFR guarantees do not apply. In this article, we present the first regret that applies to CFR when applied to a general class of games with imperfect memory. Furthermore, we show that applying CFR to any abstraction that belongs to our general class leads to a regret that applies not only to the abstract game, but also to the whole game. We test our theory and show how an imperfect memory can be used to trade a small increase in regret for a significant reduction in memory in three areas: die-roll poker, phantom tic-tac-toe and bluff."}, {"heading": "1 Introduction", "text": "In this case, a typical goal is to minimize remorse by using a past sequence of strategies against the best stationary strategies of the past. In this paper, we look at the problem of minimizing remorse in a large game. A common approach to achieving low regret in large games is the Counterfactual Regret Minimization (CFR)."}, {"heading": "2 Background", "text": "An extensive game with imperfect information [Osborne and Rubinstein, 1994] is a tuple < N, A, H, Z, P, DP, U, I >, where N is a finite set of players. A is a finite set of actions. H is a finite set of stories: a subset of information that contain a set of elements in A. A (h) prefix of a story h \"is a story h,\" where h \"begins with the sequence h\"; we denote prefix stories of h. \"For each h\" H, \"define A (h) = {a: a set of elements in A, ha\" H, \"the set of valid actions in history h.\""}, {"heading": "3 Example: Die-Roll Poker", "text": "We are now introducing a game that we will use as a running example throughout the game.Die Roll Poker (DRP) is a simplified two-player poker game in which dice is used instead of cards.At the beginning, each player places a chip in the pot. There are two betting rounds in which the players roll a private six-sided dice at the beginning of each hand.The game has imperfect information, as players do not see the outcome of the dice of the opponent's hands.During a betting round, a player may fold (forfeits the game), call (equals the current bet) or raise (increases the current bet) by a fixed number of chips, with a maximum of two raises per hand.In the first round, raises are worth two chips, while in the second round raises are worth four chips. If both players have not folded by the end of the second round, there is a showdown in which the player with the largest sum of his two dice, the rigidity of the DRP is only two perfect DRP each, and the DRP is a perfect memory of each game."}, {"heading": "4 Counterfactual Regret Minimization", "text": "Considering a sequence of strategy profiles \u03c31, \u03c32, \u03c3T, the (external) remorse for player i, RTi = maximum remorse for player i, RTI = maximum remorse for player i, RTI = maximum remorse for player i, RTI = maximum remorse for player i, RTI = maximum remorse for all time steps t, 2,..., T). An algorithm minimizes remorse or is a no-remorse algorithm for player i, if the average positive remorse approach would have reached zero; i.e., limT \u2192 R T, + i / T = 0, where x + = max {x, 0}. With no regrets it is a desirable property. For example, it is known that in a zero-sum game both players have average regrets, then the average of the strategy profiles generated is a 2 -nil equality."}, {"heading": "5 CFR with Imperfect Recall", "text": "In this section, we examine the application of CFR to games with imperfect memory. We begin by showing that CFR minimizes regret for a game class we call \"well-shaped games.\" We then present a limit on average regret for a more general class of imperfect memory games we call \"lopsided well-shaped games.\""}, {"heading": "5.1 Well-formed Games", "text": "For games I, A, H, P, P, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E,"}, {"heading": "5.2 Skew Well-formed Games", "text": "We are introducing a generalisation of well-shaped games to which a regret can still be derived. (Definition 3) For a game (Definition 3) and a complete recall (Regret 3), let us say that this game is a skew well-formed game in relation to the game if it applies to all i-N, I-I, I-I, I-I, I-II, I-II, II-II, II-II, I-II, I-II, I-II, I-II, I-II, I-II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II,"}, {"heading": "6 Empirical Evaluation", "text": "To complement our theoretical results, we apply CFR to both players simultaneously in several zero-sum games that are not perfect (abstract) games, and measure the sum of average regret for both players in a perfect refinement of the callback (the full game). Along with the small DRP domain and its variants, we also consider the challenging areas of phantom-tac-toe and bluff that we are now describing. Phantom-tac-toe, phantom-tac-toe (PTTT) is played on a 3-by-3 board, initially empty, the goal being to claim three squares along the same row, column, or diagonal. However, in PTTT, the actions of the players are private. Each move attempts to seize a square of their choice. If they fail because the opponent has seized that square on an earlier move, the player tries to occupy an alternative square until they are successful."}, {"heading": "6.1 Results", "text": "We look at several different imperfect abstractions for DRP, skew-DRP (\u03b4), PTTT, and bluff. For DRP games, we apply DRP-IR and skew-DRP-IR (\u03b4) respectively, as described in Section 5. Our PTTT and bluff experiments, however, also examine the effects of the imperfect recall beyond skew-shaped games. In the complete, perfect recall of PTTT, each player remembers the sequence of all failed and successful moves throughout the game. In our first abstract game, FOSF, players forget the sequence of successive failures within the same round. Clearly, there is an isomorphistic sequence between two merged sets of information sets that I remember (I), as the sequence of actions does not affect the available future moves."}, {"heading": "7 Discussion", "text": "In this section we discuss the following question: To minimize our regret, how important it is to meet each individual state of definition 2? Skew well-formed games and Theorem 8 show that one can relax condition (i) of definition 2 and still derive a bound on the average regret. (iii) well-formed games and Theorem 8 show that one can relax condition (i) of definition 2 and still derive a bound on the average regret. In addition, most of our PTTT and bluff abstractions from the previous section do not satisfy condition (iii), but CFR still reliable results. This suggests that it may be possible to loosen the state (iii) in a similar way (i)."}, {"heading": "8 Conclusion", "text": "We have given the first set of theoretical guarantees for CFR in imperfect recall games. We have defined well-shaped and distorted well-shaped games and set limits on the average regret resulting from the application of CFR to such games. Furthermore, our theory shows that in a full, perfect recall game we can achieve a low average regret when we use CFR in an abstract version of the game, provided the abstract game is obliquely well-formed (with or without imperfect memory). Our DRP experiments confirm these theoretical results, while our PTTT and Bluff experiments suggest that it may be possible to bind remorse in other types of imperfect recall games."}, {"heading": "Acknowledgments", "text": "We would like to thank the Computer Poker Research Group at the University of Alberta for their helpful discussions that contributed to this work, which was supported by NSERC, Alberta Innovates - Technology Futures and the use of computer resources from WestGrid and Compute Canada."}, {"heading": "Appendix A", "text": "In this section, we will propose theorems 1 and 2 of the policy paper. Note that by defining the counterfactual value (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max. (max.) (max.) (max.) (max.) (max.) (max. (max.) (max.) (max. (max.) (max.) (max. (max.) (max.) (max. (max.) (max.) (max. (max.) (max.) (max.) (max.) (max. (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max.) (max) (max.) (max) (max.) (max) (max) (max) (max.) (max) (max. (max) (max) (max) (max) (max) (max. (max) (max) (max) (max) (max) (max) (max) (max) (max. (max.) (max) (max) (max) (max) (max. (max) (max. (max) (max) (max) (max) (max) (max.) (max. (max) (max) (max.) (max.) (max) (max.) (max) (max.) (max) (max.) (max) (max.) (max) (max) (. (max) (max) (."}, {"heading": "Appendix B", "text": "In this section, we consider an alternative extension of well-shaped games that loosen the state (iv) of definition 2. (FR) For a subset of stories S'Hi, definieDi (S) = well-shaped games that loosen the state (iv) of definition 2. (FR) For a subset of information that emerges from any story in S'Hi, defineDi (S) = well-shaped strategies, say, that it is an almost well-shaped game with respect to all i'N, I'Ii, I'Ii, I'Ii, I's, I's, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II, II,"}], "references": [{"title": "A simple adaptive procedure leading to correlated", "author": ["Sergiu Hart", "Andreu Mas-Colell"], "venue": "equilibrium. Econometrica,", "citeRegEx": "Hart and Mas.Colell.,? \\Q2000\\E", "shortCiteRegEx": "Hart and Mas.Colell.", "year": 2000}, {"title": "Behavior strategies, mixed strategies and perfect recall", "author": ["Mamoru Kaneko", "J. Jude Kline"], "venue": "International Journal of Game Theory,", "citeRegEx": "Kaneko and Kline.,? \\Q1995\\E", "shortCiteRegEx": "Kaneko and Kline.", "year": 1995}, {"title": "The complexity of two-person zero-sum games in extensive form", "author": ["Daphne Koller", "Nimrod Megiddo"], "venue": "Games and Economic Behavior,", "citeRegEx": "Koller and Megiddo.,? \\Q1992\\E", "shortCiteRegEx": "Koller and Megiddo.", "year": 1992}, {"title": "Fast algorithms for finding randomized strategies in game trees", "author": ["Daphne Koller", "Nimrod Megiddo", "Bernhard von Stengel"], "venue": "In Proceedings of the 26th ACM Symposium on Theory of Computing (STOC", "citeRegEx": "Koller et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Koller et al\\.", "year": 1994}, {"title": "Extensive games and the problem of information", "author": ["Harold W. Kuhn"], "venue": "Contributions to the Theory of Games,", "citeRegEx": "Kuhn.,? \\Q1953\\E", "shortCiteRegEx": "Kuhn.", "year": 1953}, {"title": "Monte carlo sampling for regret minimization in extensive games. Technical Report TR09-15", "author": ["Marc Lanctot", "Kevin Waugh", "Martin Zinkevich", "Michael Bowling"], "venue": "University of Alberta,", "citeRegEx": "Lanctot et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lanctot et al\\.", "year": 2009}, {"title": "Approximating optimal Dudo play with fixedstrategy iteration counterfactual regret minimization", "author": ["Todd W. Neller", "Steven Hnath"], "venue": "In Computers and Games,", "citeRegEx": "Neller and Hnath.,? \\Q2011\\E", "shortCiteRegEx": "Neller and Hnath.", "year": 2011}, {"title": "A Course in Game Theory", "author": ["Martin J. Osborne", "Ariel Rubinstein"], "venue": null, "citeRegEx": "Osborne and Rubinstein.,? \\Q1994\\E", "shortCiteRegEx": "Osborne and Rubinstein.", "year": 1994}, {"title": "On the interpretation of decision problems with imperfect recall", "author": ["Michele Piccione", "Ariel Rubinstein"], "venue": "In Proceedings of the 6th Conference on Theoretical Aspects of Rationality and Knowledge,", "citeRegEx": "Piccione and Rubinstein.,? \\Q1996\\E", "shortCiteRegEx": "Piccione and Rubinstein.", "year": 1996}, {"title": "Abstraction pathologies in extensive games", "author": ["Kevin Waugh", "Dave Schnizlein", "Michael Bowling", "Duane Szafron"], "venue": "In he Eight International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "Waugh et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Waugh et al\\.", "year": 2009}, {"title": "A practical use of imperfect recall", "author": ["Kevin Waugh", "Martin Zinkevich", "Michael Johanson", "Morgan Kan", "David Schnizlein", "Michael Bowling"], "venue": "In Proceedings of SARA 2009: The Eighth Symposium on Abstraction, Reformulation and Approximation,", "citeRegEx": "Waugh et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Waugh et al\\.", "year": 2009}, {"title": "Regret minimization in games with incomplete information", "author": ["Martin Zinkevich", "Michael Johanson", "Michael Bowling", "Carmelo Piccione"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Zinkevich et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zinkevich et al\\.", "year": 2008}, {"title": "We now use Lemma A to prove Theorems 1 and 2: Theorem 2. If \u0393 is skew well-formed with respect to \u0393\u0306, then the average regret in \u0393\u0306", "author": [], "venue": "(Zinkevich et al.,", "citeRegEx": "\u221a,? \\Q2008\\E", "shortCiteRegEx": "\u221a", "year": 2008}], "referenceMentions": [{"referenceID": 11, "context": "A common approach to achieving low regret in extensive games is the Counterfactual Regret Minimization (CFR) [Zinkevich et al., 2008] algorithm.", "startOffset": 109, "endOffset": 133}, {"referenceID": 4, "context": "In games with perfect recall, every mixed strategy (probability distribution over pure strategies) has a utility-equivalent behavioral strategy (probability distribution over actions at each decision point) [Kuhn, 1953].", "startOffset": 207, "endOffset": 219}, {"referenceID": 1, "context": "property [Kaneko and Kline, 1995], it is not true for imperfect recall games in general [Piccione and Rubinstein, 1996].", "startOffset": 9, "endOffset": 33}, {"referenceID": 8, "context": "property [Kaneko and Kline, 1995], it is not true for imperfect recall games in general [Piccione and Rubinstein, 1996].", "startOffset": 88, "endOffset": 119}, {"referenceID": 2, "context": "In addition, the decision problem of determining if a player can assure themself a certain payoff in an imperfect recall game is NPcomplete [Koller and Megiddo, 1992].", "startOffset": 140, "endOffset": 166}, {"referenceID": 3, "context": "Two-player zero-sum games can be solved by constructing an appropriate linear program [Koller et al., 1994] or minimizing regret [Zinkevich et al.", "startOffset": 86, "endOffset": 107}, {"referenceID": 11, "context": ", 1994] or minimizing regret [Zinkevich et al., 2008], provided the game has perfect recall.", "startOffset": 29, "endOffset": 53}, {"referenceID": 3, "context": "Without perfect recall, however, the problem becomes exponential in the worst case [Koller et al., 1994].", "startOffset": 83, "endOffset": 104}, {"referenceID": 7, "context": "An extensive-form game \u0393 with imperfect information [Osborne and Rubinstein, 1994] is a tuple \u3008N,A,H,Z, P, \u03c3c, u, I\u3009, where N is a finite set of players.", "startOffset": 52, "endOffset": 82}, {"referenceID": 11, "context": "This is because perfect recall implies that the regret is bounded by the sum of the positive parts of the immediate counterfactual regrets [Zinkevich et al., 2008], R i \u2264 \u2211", "startOffset": 139, "endOffset": 163}, {"referenceID": 6, "context": "In Bluff, we use abstractions described by Neller and Hnath (2011) that force players to forget everything except the last r bids.", "startOffset": 43, "endOffset": 67}, {"referenceID": 11, "context": "In addition, under \u03c3 , the counterfactual value of the pass 1Similar to Zinkevich et al. (2008), we used the chance sampling variant of CFR.", "startOffset": 72, "endOffset": 96}], "year": 2012, "abstractText": "Counterfactual Regret Minimization (CFR) is an efficient no-regret learning algorithm for decision problems modeled as extensive games. CFR\u2019s regret bounds depend on the requirement of perfect recall: players always remember information that was revealed to them and the order in which it was revealed. In games without perfect recall, however, CFR\u2019s guarantees do not apply. In this paper, we present the first regret bound for CFR when applied to a general class of games with imperfect recall. In addition, we show that CFR applied to any abstraction belonging to our general class results in a regret bound not just for the abstract game, but for the full game as well. We verify our theory and show how imperfect recall can be used to trade a small increase in regret for a significant reduction in memory in three domains: die-roll poker, phantom tic-tac-toe, and Bluff.", "creator": "LaTeX with hyperref package"}}}