{"id": "1206.1898", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2012", "title": "A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function", "abstract": "We propose a novel Bayesian approach to solve stochastic optimization problems that involve finding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of first, doing inference over the function space and second, finding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior where the natural parameter corresponds to a given kernel function and the sufficient statistic is composed of the observed function values. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function.", "histories": [["v1", "Sat, 9 Jun 2012 01:57:02 GMT  (391kb)", "https://arxiv.org/abs/1206.1898v1", "8 pages, 4 figures"], ["v2", "Sat, 10 Nov 2012 18:09:17 GMT  (977kb)", "http://arxiv.org/abs/1206.1898v2", "9 pages, 5 figures"]], "COMMENTS": "8 pages, 4 figures", "reviews": [], "SUBJECTS": "stat.ML cs.AI math.ST stat.TH", "authors": ["pedro a ortega", "jordi grau-moya", "tim genewein", "david balduzzi", "daniel a braun"], "accepted": true, "id": "1206.1898"}, "pdf": {"name": "1206.1898.pdf", "metadata": {"source": "CRF", "title": "A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function", "authors": ["Pedro A. Ortega", "Tim Genewein", "Daniel A. Braun"], "emails": ["pedro.ortega@tuebingen.mpg.de", "jordi.grau@tuebingen.mpg.de", "tim.genewein@tuebingen.mpg.de", "david.balduzzi@tuebingen.mpg.de", "daniel.braun@tuebingen.mpg.de"], "sections": [{"heading": null, "text": "ar Xiv: 120 6,18 98v2 ["}, {"heading": "1 Introduction", "text": "Historically, the fields of statistical inference and stochastic optimization have often developed their own specific methods and approaches, but lately there has been a growing interest in applying inference-based methods to optimization problems, and vice versa. [1-4] Here, we are looking at stochastic optimization problems, where we observe noise-laden values from an unknown nonlinear function, and we want to find the input that maximizes the expected value of this function.The problem is as follows. Consider section X as metric space. Consider a stochastic function f: X R, which maps a checkpoint x: X to real values y: R, characterized by the conditional pdf P (y | x). Consider the mean function f (x): = E [y | x] = [yP (y | x) dy. (1) The goal is to model the optimal test point x: = argx max (x)."}, {"heading": "2 Description of the Model", "text": "Our model is intuitively simple and easy to implement. Let h (x) > R is an estimate of the mean f (x) constructed from the data Dt: = {(xi, yi) ti = 1 (Figure 1a, left).This estimate can be easily converted into a posterior pdf above the location of the maximum by first multiplying it with a precision parameter \u03b1 > 0 and then taking the normalized exponential number (Figure 1a, right) P (x).exp {\u03b1 \u00b7 h (x)}.In this transformation, the precision parameter \u03b1 controls the certainty we have about our estimate of the maximizing argument: xi \u00b2 0 expresses almost no certainty, while the rationality for precision is: the more distinct inputs we test, the higher precision x x - the verification of accuracy - the verification of the same (or similar) inputs that only provide local information and therefore should not increase our simple knowledge about the global and therefore the maximum."}, {"heading": "3 Derivation of the Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Function-Based, Indirect Model", "text": "Our first task is to derive an indirect Bayesian model for the optimal test point that builds its estimate of the underlying functional space. Let G be the set of hypotheses and assume that each hypothesis g-G corresponds to a stochastic mapping g: X R. Let P (g) be the priority 2 over G and let the probability be P (yt) | g, {xt}) = T P (yt | g, xt). Then the back of g is given by P (yt, {xt}) = P (yt, {xt}) = P (g) P (yt) | g, (xt, {xt) P (yt) | T (yt) P (yt, xt)."}, {"heading": "3.2 Domain-Based, Direct Model", "text": "We want to arrive at a Bayesian model that circumvents the integration step proposed by (5) and directly models the location of the optimal test point x *. The following theorem explains how this direct model relates to the previous model. Theorem 1. The Bayesian model for the optimal test point x * is therefore derived from P (x *) = (x *) P (g) dg (formerly) P (yt | x *), xt, Dt \u2212 1) P (yt | g) P (yt | g, xt) P (g).t \u2212 1 k = 1 P (yk). t \u2212 1 P (g)."}, {"heading": "3.3 Abstract Properties of the Likelihood Function", "text": "There is a way to explicitly circumvent the modeling of the function space if we make a few additional assumptions. We assume that the mean function g * * is continuous and has a unique maximum, and the decisive finding is that the value of the mean function g * within a sufficiently small neighborhood of x * is greater than the value outside (see Figure 2a). We assume that for each competing g > 0 and each z * X the open g * sphere is centered on Z. The functions in G fulfill the following properties: a. Continuity: Each function g * G is such that their mean g * is continuous and delimited. b. Maximum: For each x x x x x * X, the functions g * G (x *) are such that for all g > 0 and all z / x * B \u00b2 values x x are equal."}, {"heading": "3.4 Likelihood and Conjugate Prior", "text": "Following our previous discussion, we propose the following probability model: Given the previous data Dt \u2212 1 and one checkpoint xt \u00b7 X, the probability of observation yt-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-"}, {"heading": "4 Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Parameters.", "text": "We have investigated the influence of the parameters on the resulting posterior probability distribution. Figure 3 shows how the choice of precision \u03c1 and nuclear width \u03c3 influence the shape of the posterior probability density. We have used the Gaussian nucleus K (x, x *) = exp {\u2212 12\u03c32 (x \u2212 x *) 2}. (10) In this figure, 7 data points are drawn as y \u0445 N (f (x), 0.3), with the mean function isf (x) = cos (2x + 32\u03c0) + sin (6x + 3 2\u03c0). (11) The functions K0 and y0 were selected as K0 (x) = 1 and y0 (x) = \u2212 12\u044520 (x \u2212 \u00b50) 2, (12) where the latter is the logarithm of a Gaussian with an average \u00b50 = 1.5 and a variance \u044520 = 5. The choice of a higher value leads to sharper updates, while higher values for the posterior lower density produce."}, {"heading": "4.2 Application to Optimization.", "text": "We used the model to optimize the same function (11) as in our preliminary tests, but with higher additive noise equal to one. This is done by scanning the next test point directly from the posterior density above the optimal position P (x-Dt) and then using the resulting pair (xt, yt) to recursively refresh the model. Essentially, this method corresponds to the Bayian Control Rule / Thompson sampling [12, 13]. We compared our method against a Gaussian process optimization method using an upper confidence bound (UCB) criterion [10]. The parameters for the GP-UCB were set to the following values: observation noise \u03c3n = 0.3 and length scale 0.3. For the constant we derive from exploration and exploitation, we followed theorem 1 in [10], the states = 2 log | UCB / 628 with 0.5 offences."}, {"heading": "5 Discussion & Conclusions", "text": "We have proposed a novel Bayesian approach to model the position of the maximizing test point of a noisy, nonlinear function - a much more difficult problem. In particular, we have derived a probability function that belongs to the exponential family by assuming a form of symmetry in the functional space, which in turn enabled us to indicate a prior distribution over the optimal test point. Our proposed model is very efficient compared to Gaussian process-based (cubic) or UCB-based models (expensive compression of argmax), and the evaluation time of posterior density scales square in the size of the data. This is due to the calculation of the effective number of previously seen test sites - the core regressor requires linear compression time. In MCMC steps, the effective number of test sites cannot be associated with the proposed method for long to update the most important observations."}], "references": [{"title": "A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "author": ["E. Brochu", "V. Cora", "N. de Freitas"], "venue": "Technical Report TR-2009-023,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Approximate inference and stochastic optimal control", "author": ["K. Rawlik", "M. Toussaint", "S. Vijayakumar"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Probabilistic Constrained Optimization: Methodology and Applications, chapter Statistical Inference of Stochastic Optimization Problems, pages 282\u2013304", "author": ["A. Shapiro"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2000}, {"title": "Optimal control as a graphical model inference problem", "author": ["H.J. Kappen", "V. G\u00f3mez", "M. Opper"], "venue": "Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Stochastic Approximation Algorithms and Applications", "author": ["H.J. Kushner", "G.G. Yin"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}, {"title": "Application of bayesian approach to numerical methods of global and stochastic optimization", "author": ["J. Mockus"], "venue": "Journal of Global Optimization,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1994}, {"title": "Practical Bayesian Optimization", "author": ["D. Lizotte"], "venue": "Phd thesis, University of Alberta,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "Efficient global optimization of expensive blackbox functions", "author": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global Optimization,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1998}, {"title": "Gaussian processes for global optimization", "author": ["M.A. Osborne", "R. Garnett", "S.J. Roberts"], "venue": "In 3rd International Conference on Learning and Intelligent Optimization", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "The Elements of Statistical Learning", "author": ["T. Hastie", "R. Tbshirani", "J. Friedman"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Simulation studies in optimistic Bayesian sampling in contextualbandit problems", "author": ["B.C. May", "D.S. Leslie"], "venue": "Technical Report 11:02,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "A minimum relative entropy principle for learning and acting", "author": ["P.A. Ortega", "D.A. Braun"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 1, "context": "Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 2, "context": "Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 3, "context": "Recently, however, there has been a growing interest in applying inference-based methods to optimization problems and vice versa [1\u20134].", "startOffset": 129, "endOffset": 134}, {"referenceID": 4, "context": "Classic approaches to solve this problem are often based on stochastic approximation methods [5].", "startOffset": 93, "endOffset": 96}, {"referenceID": 5, "context": "Within the context of statistical inference, Bayesian optimization methods have been developed where a prior distribution over the space of functions is assumed and uncertainty is tracked during the entire optimization process [6, 7].", "startOffset": 227, "endOffset": 233}, {"referenceID": 6, "context": "Within the context of statistical inference, Bayesian optimization methods have been developed where a prior distribution over the space of functions is assumed and uncertainty is tracked during the entire optimization process [6, 7].", "startOffset": 227, "endOffset": 233}, {"referenceID": 7, "context": "In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10].", "startOffset": 128, "endOffset": 134}, {"referenceID": 8, "context": "In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10].", "startOffset": 128, "endOffset": 134}, {"referenceID": 9, "context": "In particular, non-parametric Bayesian approaches such as Gaussian Processes have been applied for derivative-free optimization [8, 9], also within the context of the continuum-armed bandit problem [10].", "startOffset": 198, "endOffset": 202}, {"referenceID": 10, "context": "In (3), the mean function f\u0304 is estimated with a kernel regressor [11], and the total effective number of locations is calculated as the sum of the prior locations \u03be and the number of distinct locations in the data Dt.", "startOffset": 66, "endOffset": 70}, {"referenceID": 11, "context": "Essentially, this procedure corresponds to Bayesian control rule/Thompson sampling [12, 13].", "startOffset": 83, "endOffset": 91}, {"referenceID": 12, "context": "Essentially, this procedure corresponds to Bayesian control rule/Thompson sampling [12, 13].", "startOffset": 83, "endOffset": 91}, {"referenceID": 9, "context": "We compared our method against a Gaussian Process optimization method using an upper confidence bound (UCB) criterion [10].", "startOffset": 118, "endOffset": 122}, {"referenceID": 9, "context": "For the constant that trades off exploration and exploitation we followed Theorem 1 in [10] which states \u03b2t = 2 log(|D|t\u03c0/6\u03b4) with \u03b4 = 0.", "startOffset": 87, "endOffset": 91}], "year": 2012, "abstractText": "We propose a novel Bayesian approach to solve stochastic optimization problems that involve fnding extrema of noisy, nonlinear functions. Previous work has focused on representing possible functions explicitly, which leads to a two-step procedure of first, doing inference over the function space and second, finding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end, we devise a non-parametric conjugate prior based on a kernel regressor. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function. We illustrate the effectiveness of our model by optimizing a noisy, high-dimensional, non-convex objective function.", "creator": "LaTeX with hyperref package"}}}