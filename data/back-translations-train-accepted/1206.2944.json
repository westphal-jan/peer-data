{"id": "1206.2944", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Jun-2012", "title": "Practical Bayesian Optimization of Machine Learning Algorithms", "abstract": "Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a \"black art\" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.", "histories": [["v1", "Wed, 13 Jun 2012 21:23:15 GMT  (295kb,D)", "http://arxiv.org/abs/1206.2944v1", null], ["v2", "Wed, 29 Aug 2012 06:36:23 GMT  (295kb,D)", "http://arxiv.org/abs/1206.2944v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["jasper snoek", "hugo larochelle", "ryan p adams"], "accepted": true, "id": "1206.2944"}, "pdf": {"name": "1206.2944.pdf", "metadata": {"source": "CRF", "title": "PRACTICAL BAYESIAN OPTIMIZATION OF MACHINE LEARNING ALGORITHMS", "authors": ["Jasper Snoek", "Hugo Larochelle", "Ryan P. Adams"], "emails": [], "sections": [{"heading": "PRACTICAL BAYESIAN OPTIMIZATION OF MACHINE LEARNING ALGORITHMS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "By Jasper Snoek, Hugo Larochelle and Ryan P. Adams", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "University of Toronto, Universite\u0301 de Sherbrooke and Harvard University", "text": "This year, it is time to go in search of a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution and that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution. \""}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a \u201cblack art\u201d that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm\u2019s generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.", "creator": "LaTeX with hyperref package"}}}