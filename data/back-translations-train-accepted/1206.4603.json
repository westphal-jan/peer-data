{"id": "1206.4603", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Latent Collaborative Retrieval", "abstract": "Retrieval tasks typically require a ranking of items given a query. Collaborative filtering tasks, on the other hand, learn to model user's preferences over items. In this paper we study the joint problem of recommending items to a user with respect to a given query, which is a surprisingly common task. This setup differs from the standard collaborative filtering one in that we are given a query x user x item tensor for training instead of the more traditional user x item matrix. Compared to document retrieval we do have a query, but we may or may not have content features (we will consider both cases) and we can also take account of the user's profile. We introduce a factorized model for this new task that optimizes the top-ranked items returned for the given query and user. We report empirical results where it outperforms several baselines.", "histories": [["v1", "Mon, 18 Jun 2012 14:41:20 GMT  (223kb)", "http://arxiv.org/abs/1206.4603v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.IR cs.AI", "authors": ["jason weston", "chong wang", "ron j weiss", "adam berenzweig"], "accepted": true, "id": "1206.4603"}, "pdf": {"name": "1206.4603.pdf", "metadata": {"source": "META", "title": "Latent Collaborative Retrieval", "authors": ["Jason Weston", "Chong Wang", "Ron Weiss"], "emails": ["jweston@google.com", "chongw@cs.princeton.edu", "ronw@google.com", "madadam@google.com"], "sections": [{"heading": "1. Introduction", "text": "There is a growing number of applications that fit seamlessly into the traditional query and recommendation tasks. For example, when users purchase a product online, they should also make it a personal sensation problem. Another related process is the automatic creation of music tracks. Users can request the creation of Proceedings of the Machine Learning, Edinburgh, Scotland, United Kingdom."}, {"heading": "2. Method", "text": "We define a scoring function for a given query, a user and a specific element: fFULL (Q, u, d) = Rqudwhere R is a \"Q,\" \"U\" and \"tensor,\" where Q is the (finite) set of possible queries, U is, however, the set of users and D is the set of items. Each given element of the tensor is the \"relevance score\" of a particular item in relation to a given query and a given user, where a high score corresponds to high relevance. Typically, m training examples are given {qi, ui, di)} i = 1,..., m."}, {"heading": "3. Prior Work and Connections", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Connections to matrix factorization for collaborative filtering", "text": "Specifically, Singular Value Decomposition (SVD) and Non-Negative Matrix Factorization (NMF) (Billsus & Pazzani, 1998; Lee & Seung, 2001) are two popular choices; the main two differences between our approach and these general matrix factorization techniques are that (i) every recommendation we make is sown with a query (i.e., the collaborative retrieval task), and (ii) for collaborative retrieval tasks we are interested in the most returned items, so that our method is optimized for that goal. Most collaborative filtering does not take into account a ranking type loss that optimizes the top-k, but is a notable exception (Weimer et al., 2007). They do not take into account tensor factorizations (before factorizations)."}, {"heading": "3.2. Connections to matrix factorization and information retrieval", "text": "In this case, latent semantic indexing (Deerwester et al., 1990) and related methods such as LDA (Lead et al., 2003) are unattended methods that select a low-dimensional representation of words. Parameterization of these models is a specific case of our models. If we look at our model from Equation (5), we remove the influence of the user model, i.e. we use Uu = I and Vu = 0 a standard document retrieval model: fDR (q) > W > QWD (d), but we remove the influence of the user model, i.e. we use Uu = I and Vu = 0 a standard document retrieval model."}, {"heading": "4. Experiments", "text": "Traditional collaborative filter datasets such as the Netflix Challenge dataset and information retrieval datasets such as LETOR cannot be used in the Collaborative Retrieval Framework because they lack either the query or the necessary user information, so we will use the three datasets described below."}, {"heading": "4.1. Lastfm Dataset", "text": "We used the \"Last.fm Dataset - 1K users\" dataset available at http: / / www.dtic.upf.edu / \u0445 ocelma / MusicRecommendationDataset / lastfm-1K.html. This dataset contains (user, timestamp, artist, song) tuples collected from the Last.fm API (www.lastfm.com), representing the listening history (as of May 5, 2009) for 992 users and 176,948 artists. Two artists of the same user played in a row are considered a query object \u00d7 triple, reflecting the task of playlisting, where a user selects a seed track and the machine automatically generates a list of tracks. We consider two artists to be \"consecutive\" when played within one hour of each other (over the timestamp), otherwise we ignore the pair. One of five days in total (so that the data is separated for this test, and the remaining data is validated for the 43K)."}, {"heading": "4.2. Playlist head and tail datasets", "text": "The first extracted dataset (\"Head\" dataset) consists of 46,000 users and 943,284 tracks from 146,369 artists (each artist appears at least 10 times), and the data is divided into 17M training triples for training, 172,000 for validation, and 1.7M for testing. The above \"Head\" dataset can be created for artists where we have enough training data. However, a user may want to perform the query with a query or element for which we have no tendencies or training data at all (i.e., the cold start problem), in which case content-based feature approaches are the only option."}, {"heading": "4.3. Baselines", "text": "We compare Singular Value Decomposition (SVD) and Non-Negative Matrix Factorization (NMF), both popular methods for collaborative filtering tasks; for SVD, we use the Matlab implementation; for NMF, we use the implementation at http: / / www. csie.ntu.edu.tw / \u0445 cjlin / nmf /. Standard SVD and NMF work on matrices, not tensors, so we compare our method to these tasks (where we only look at item matrices or only item matrices) and to the \u00d7 item matrices query; for the \u00d7 item tensor, we consider the following generalization of SVD or NMF: f (q, u, i) = (q) > U > QIVQIB (d) + item matrices (u) > U > UIVUIZ (d) matrix matrix. That is, we run two user (SVD or NF) matrix through one SVD matrix and one NF matrix."}, {"heading": "4.4. Evaluation", "text": "For each given query q, user u, item i triple, we calculate f (q, u, i) with the given algorithm for each possible item i and sort them first by the largest item. For user item or query item tasks, the setup is the same, except q or u is not used in all competing models. The evaluation value for a given item i is then calculated based on where item i appears in the ranking. We measure callback @ k, which is 1 if item i appears in the uppermost k, and 0 otherwise. We report center callback @ k for the entire test set. Note that per query (the element i of the triples) we only consider one positive example of precision @ k = callback @ k / k."}, {"heading": "4.5. LastFM dataset Results", "text": "Detailed results where we have set the embedding dimension of all methods to n = 50 are in Table 1. Results for other decisions of n are in Table 4. For all three tasks (Query \u00b7 Item, User \u00b7 Item and Query \u00b7 Item), the LCR SVD and NMF are superior for each of the above k. Furthermore, our full LCR query \u00b7 User \u00b7 Item model (c.f. Equation 2, Ui unlimited) performs improved results compared to both (i) competing methods, including the LCR itself, which do not take both query and user into account; and (ii) the LCR itself (and other methods), which do not model the query and the user in a common optimization function (i.e. the LCR query x item)."}, {"heading": "4.6. Playlist dataset results", "text": "The playlist dataset is larger and has both collaborative filter type data and content-based features. The results are in Table 3. They again show an improvement in performance for LCR over the SVD and NMF base data for the query and item task, although collaborative filtering is not applicable to the user task. (We have also tried to combine both collaborative filtering and content-based information on the header dataset, but we did not observe an increase in performance over collaborative filtering alone, probably because the content-based features on the end dataset are not strong enough, which is not really a cosmic filter and content-based information on the end dataset)."}, {"heading": "5. Conclusion", "text": "As with collaborative filtering, the task is to evaluate items given to a user, but crucially, we can consider a query term ac-count. As with document queries, we get a query and the task is to evaluate items, but crucially, we also consider the user in the form of a user query item tensor of training data. We proposed a novel learning algorithm for this task, which learns a factored model to classify the items given by the query and the user, and which has shown that collaborative queries empirically outperform some standard methods. Collaborative queries are rapidly becoming an important task, and we expect this to be a well-researched field."}], "references": [{"title": "Polynomial semantic indexing", "author": ["B. Bai", "J. Weston", "D. Grangier", "R. Collobert", "K. Sadamasa", "Y. Qi", "C. Cortes", "M. Mohri"], "venue": null, "citeRegEx": "Bai et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bai et al\\.", "year": 2009}, {"title": "Learning collaborative information filters", "author": ["D. Billsus", "M.J. Pazzani"], "venue": "In ICML,", "citeRegEx": "Billsus and Pazzani,? \\Q1998\\E", "shortCiteRegEx": "Billsus and Pazzani", "year": 1998}, {"title": "Indexing by latent semantic analysis", "author": ["Deerwester", "Scott", "Dumais", "Susan T", "Furnas", "George W", "Landauer", "Thomas K", "Harshman", "Richard"], "venue": "JASIS,", "citeRegEx": "Deerwester et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Deerwester et al\\.", "year": 1990}, {"title": "Content-based retrieval of music and audio", "author": ["J.T. Foote"], "venue": "In SPIE, pp", "citeRegEx": "Foote,? \\Q1997\\E", "shortCiteRegEx": "Foote", "year": 1997}, {"title": "Foundations of the parafac procedure: models and conditions for an", "author": ["R.A. Harshman"], "venue": "explanatory\u201d multimodal factor analysis", "citeRegEx": "Harshman,? \\Q1970\\E", "shortCiteRegEx": "Harshman", "year": 1970}, {"title": "Improving social bookmark search using personalised latent variable language models", "author": ["M. Harvey", "I. Ruthven", "M.J. Carman"], "venue": "In WSDM,", "citeRegEx": "Harvey et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Harvey et al\\.", "year": 2011}, {"title": "Large margin rank boundaries for ordinal regression", "author": ["R. Herbrich", "T. Graepel", "K. Obermayer"], "venue": "Advances in large margin classifiers,", "citeRegEx": "Herbrich et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Herbrich et al\\.", "year": 2000}, {"title": "Optimizing search engines using clickthrough data", "author": ["T. Joachims"], "venue": "In Proceedings of the eighth ACM SIGKDD,", "citeRegEx": "Joachims,? \\Q2002\\E", "shortCiteRegEx": "Joachims", "year": 2002}, {"title": "Multiverse recommendation: n-dimensional tensor factorization for context-aware collaborative filtering", "author": ["A. Karatzoglou", "X. Amatriain", "L. Baltrunas", "N. Oliver"], "venue": "RecSys \u201910,", "citeRegEx": "Karatzoglou et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Karatzoglou et al\\.", "year": 2010}, {"title": "Algorithms for non-negative matrix factorization", "author": ["D.D. Lee", "H.S. Seung"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Lee and Seung,? \\Q2001\\E", "shortCiteRegEx": "Lee and Seung", "year": 2001}, {"title": "Using probabilistic latent semantic analysis for personalized web search", "author": ["C. Lin", "G.R. Xue", "H.J. Zeng", "Y. Yu"], "venue": "Web Technologies Research and DevelopmentAPWeb", "citeRegEx": "Lin et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2005}, {"title": "Response prediction using collaborative filtering with hierarchies and side-information", "author": ["A.K. Menon", "K.P. Chitrapura", "S. Garg", "D. Agarwal", "N. Kota"], "venue": "In SIGKDD,", "citeRegEx": "Menon et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Menon et al\\.", "year": 2011}, {"title": "Pairwise interaction tensor factorization for personalized tag recommendation", "author": ["S. Rendle", "L. Schmidt-Thieme"], "venue": "In WSDM,", "citeRegEx": "Rendle and Schmidt.Thieme,? \\Q2010\\E", "shortCiteRegEx": "Rendle and Schmidt.Thieme", "year": 2010}, {"title": "Tensor framework and combined symmetry for hypertext mining", "author": ["S. Saha", "CA Murthy", "S.K. Pal"], "venue": "Fundamenta Informaticae,", "citeRegEx": "Saha et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Saha et al\\.", "year": 2009}, {"title": "Web-scale multimedia analysis: Does content matter", "author": ["M. Slaney"], "venue": "Multimedia, IEEE,", "citeRegEx": "Slaney,? \\Q2011\\E", "shortCiteRegEx": "Slaney", "year": 2011}, {"title": "Web-page summarization using clickthrough data", "author": ["J.T. Sun", "D. Shen", "H.J. Zeng", "Q. Yang", "Y. Lu", "Z. Chen"], "venue": "In SIGIR,", "citeRegEx": "Sun et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2005}, {"title": "Some mathematical notes on three-mode factor analysis", "author": ["L.R. Tucker"], "venue": "Psychometrika, 31(3):279\u2013311,", "citeRegEx": "Tucker,? \\Q1966\\E", "shortCiteRegEx": "Tucker", "year": 1966}, {"title": "Ranking with ordered weighted pairwise classification", "author": ["Usunier", "Nicolas", "Buffoni", "David", "Gallinari", "Patrick"], "venue": "In ICML, pp. 1057\u20131064,", "citeRegEx": "Usunier et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Usunier et al\\.", "year": 2009}, {"title": "Collaborative topic modeling for recommending scientific articles", "author": ["C. Wang", "D.M. Blei"], "venue": "In 17th ACM SIGKDD,", "citeRegEx": "Wang and Blei,? \\Q2011\\E", "shortCiteRegEx": "Wang and Blei", "year": 2011}, {"title": "Cofirank-maximum margin matrix factorization for collaborative ranking", "author": ["M. Weimer", "A. Karatzoglou", "Q. Le", "A Smola"], "venue": null, "citeRegEx": "Weimer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Weimer et al\\.", "year": 2007}, {"title": "Large scale image annotation: Learning to rank with joint word-image embeddings", "author": ["J. Weston", "S. Bengio", "N. Usunier"], "venue": "In ECML,", "citeRegEx": "Weston et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2010}, {"title": "Large-scale music annotation and retrieval: Learning to rank in joint semantic spaces", "author": ["J. Weston", "S. Bengio", "P. Hamel"], "venue": "In Journal of New Music Research,", "citeRegEx": "Weston et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2012}, {"title": "Temporal collaborative filtering with bayesian probabilistic tensor factorization", "author": ["L. Xiong", "X. Chen", "T.K. Huang", "J. Schneider", "J.G. Carbonell"], "venue": "In Proceedings of SIAM Data", "citeRegEx": "Xiong et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Xiong et al\\.", "year": 2010}, {"title": "A support vector method for optimizing average precision", "author": ["Yue", "Yisong", "T. Finley", "F. Radlinski", "T. Joachims"], "venue": "In SIGIR,", "citeRegEx": "Yue et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yue et al\\.", "year": 2007}, {"title": "Collaborative filtering meets mobile recommendation: A user-centered approach", "author": ["V.W. Zheng", "B. Cao", "Y. Zheng", "X. Xie", "Q. Yang"], "venue": "In AAAI,", "citeRegEx": "Zheng et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zheng et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 6, "context": "A standard loss function that is often used for retrieval is the margin ranking criterion (Herbrich et al., 2000; Joachims, 2002), in particular it was used for learning factorized document retrieval models in Bai et al.", "startOffset": 90, "endOffset": 129}, {"referenceID": 7, "context": "A standard loss function that is often used for retrieval is the margin ranking criterion (Herbrich et al., 2000; Joachims, 2002), in particular it was used for learning factorized document retrieval models in Bai et al.", "startOffset": 90, "endOffset": 129}, {"referenceID": 0, "context": ", 2000; Joachims, 2002), in particular it was used for learning factorized document retrieval models in Bai et al. (2009). Let us first write the predictions of our model for all items in the database as a vector f\u0304(q, u) where the i index is f\u0304i(q, u) = f(q, u, i).", "startOffset": 104, "endOffset": 122}, {"referenceID": 17, "context": "To instead focus on the top of the ranked list of returned items we employ a recently introduced loss function that has been developed for document retrieval (Usunier et al., 2009; Weston et al., 2010; 2012).", "startOffset": 158, "endOffset": 207}, {"referenceID": 20, "context": "To instead focus on the top of the ranked list of returned items we employ a recently introduced loss function that has been developed for document retrieval (Usunier et al., 2009; Weston et al., 2010; 2012).", "startOffset": 158, "endOffset": 207}, {"referenceID": 17, "context": "This is useful when one wants to optimize precision at k for a variety of different values of k at once (Usunier et al., 2009).", "startOffset": 104, "endOffset": 126}, {"referenceID": 20, "context": "We optimize this function by stochastic gradient descent (SGD) following the authors of (Weston et al., 2010), that is samples are drawn at random, and a gradient step is made for each draw.", "startOffset": 88, "endOffset": 109}, {"referenceID": 20, "context": "(Weston et al., 2010; Bai et al., 2009).", "startOffset": 0, "endOffset": 39}, {"referenceID": 0, "context": "(Weston et al., 2010; Bai et al., 2009).", "startOffset": 0, "endOffset": 39}, {"referenceID": 19, "context": "Most collaborative filtering work does not consider a ranking type loss that optimizes the top k, but one notable exception is (Weimer et al., 2007).", "startOffset": 127, "endOffset": 148}, {"referenceID": 16, "context": "There are several ways to factorize a tensor, some classical ways are Tucker decomposition (Tucker, 1966) and PARAFAC (Harshman, 1970).", "startOffset": 91, "endOffset": 105}, {"referenceID": 4, "context": "There are several ways to factorize a tensor, some classical ways are Tucker decomposition (Tucker, 1966) and PARAFAC (Harshman, 1970).", "startOffset": 118, "endOffset": 134}, {"referenceID": 11, "context": "Several collaborative filtering techniques have considered tensor factorisations before, in particular for taking into account user context features like tags (Rendle & SchmidtThieme, 2010), web pages (Menon et al., 2011), age and gender (Karatzoglou et al.", "startOffset": 201, "endOffset": 221}, {"referenceID": 8, "context": ", 2011), age and gender (Karatzoglou et al., 2010), time (Xiong et al.", "startOffset": 24, "endOffset": 50}, {"referenceID": 22, "context": ", 2010), time (Xiong et al., 2010) or user location for mobile phone recommendation (Zheng et al.", "startOffset": 14, "endOffset": 34}, {"referenceID": 24, "context": ", 2010) or user location for mobile phone recommendation (Zheng et al., 2010) but not, to our knowledge, for the collaborative retrieval task.", "startOffset": 57, "endOffset": 77}, {"referenceID": 2, "context": "In that case, Latent Semantic Indexing (Deerwester et al., 1990), and related methods such as LDA (Blei et al.", "startOffset": 39, "endOffset": 64}, {"referenceID": 0, "context": "More recently, factorized models that are supervised to the task of document retrieval have been proposed, for example Polynomial Semantic Indexing (PSI) (Bai et al., 2009).", "startOffset": 154, "endOffset": 172}, {"referenceID": 20, "context": "Methods for annotating images (Weston et al., 2010) and labeling songs with tags (Weston et al.", "startOffset": 30, "endOffset": 51}, {"referenceID": 21, "context": ", 2010) and labeling songs with tags (Weston et al., 2012) have been proposed that do use the WARP loss we employ in this paper.", "startOffset": 37, "endOffset": 58}, {"referenceID": 23, "context": "(Yue et al., 2007).", "startOffset": 0, "endOffset": 18}, {"referenceID": 5, "context": "Finally, our models are applicable to the task of \u201cpersonalized search\u201d where some topic model approaches have recently been studied (Harvey et al., 2011; Lin et al., 2005; Sun et al., 2005; Saha et al., 2009).", "startOffset": 133, "endOffset": 209}, {"referenceID": 10, "context": "Finally, our models are applicable to the task of \u201cpersonalized search\u201d where some topic model approaches have recently been studied (Harvey et al., 2011; Lin et al., 2005; Sun et al., 2005; Saha et al., 2009).", "startOffset": 133, "endOffset": 209}, {"referenceID": 15, "context": "Finally, our models are applicable to the task of \u201cpersonalized search\u201d where some topic model approaches have recently been studied (Harvey et al., 2011; Lin et al., 2005; Sun et al., 2005; Saha et al., 2009).", "startOffset": 133, "endOffset": 209}, {"referenceID": 13, "context": "Finally, our models are applicable to the task of \u201cpersonalized search\u201d where some topic model approaches have recently been studied (Harvey et al., 2011; Lin et al., 2005; Sun et al., 2005; Saha et al., 2009).", "startOffset": 133, "endOffset": 209}, {"referenceID": 3, "context": "MFCCs take advantage of source/filter deconvolution from the cepstral transform and perceptually-realistic compression of spectra from the Mel pitch scale and have been used widely in music and speech (Foote, 1997; Rabiner & Juang, 1993).", "startOffset": 201, "endOffset": 237}, {"referenceID": 2, "context": "For content-based features we also compare to LSI (Deerwester et al., 1990) and using cosine similarity.", "startOffset": 50, "endOffset": 75}, {"referenceID": 14, "context": "(We also attempted to combine both collaborative filtering and content-based information on the head dataset, but we observed no gain in performance over collaborative filtering alone, probably because the content-based features are not strong enough, which is not really a surprising result (Slaney, 2011)).", "startOffset": 292, "endOffset": 306}], "year": 2012, "abstractText": "Retrieval tasks typically require a ranking of items given a query. Collaborative filtering tasks, on the other hand, learn to model user\u2019s preferences over items. In this paper we study the joint problem of recommending items to a user with respect to a given query, which is a surprisingly common task. This setup differs from the standard collaborative filtering one in that we are given a query \u00d7 user \u00d7 item tensor for training instead of the more traditional user \u00d7 item matrix. Compared to document retrieval we do have a query, but we may or may not have content features (we will consider both cases) and we can also take account of the user\u2019s profile. We introduce a factorized model for this new task that optimizes the top-ranked items returned for the given query and user. We report empirical results where it outperforms several baselines.", "creator": "LaTeX with hyperref package"}}}