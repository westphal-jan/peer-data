{"id": "1206.4607", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Distributed Tree Kernels", "abstract": "In this paper, we propose the distributed tree kernels (DTK) as a novel method to reduce time and space complexity of tree kernels. Using a linear complexity algorithm to compute vectors for trees, we embed feature spaces of tree fragments in low-dimensional spaces where the kernel computation is directly done with dot product. We show that DTKs are faster, correlate with tree kernels, and obtain a statistically similar performance in two natural language processing tasks.", "histories": [["v1", "Mon, 18 Jun 2012 14:44:09 GMT  (380kb)", "http://arxiv.org/abs/1206.4607v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["fabio massimo zanzotto", "lorenzo dell'arciprete"], "accepted": true, "id": "1206.4607"}, "pdf": {"name": "1206.4607.pdf", "metadata": {"source": "META", "title": "Distributed Tree Kernels", "authors": ["Fabio Massimo Zanzotto", "Lorenzo Dell\u2019Arciprete"], "emails": ["FABIO.MASSIMO.ZANZOTTO@UNIROMA2.IT", "LORENZO.DELLARCIPRETE@GMAIL.COM"], "sections": [{"heading": "1. Introduction", "text": "In fact, most people who stay in the city go into a different world, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live."}, {"heading": "2. Challenges for Distributed Tree Kernels", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Notation and Basic Idea", "text": "Tree kernels (TK) (Collins & Duffy, 2001) are proposed as efficient methods to imply compute dot products in feature spaces Rm of tree fragments. A direct calculation in these high-dimensional spaces is impractical. Given two trees, T1 and T2 in T, tree cores TK (T1, T2) perform the weighted counting of common subtrees. (TK, T2) Vectors ~ T encoding trees T as forests of active tree fragments F (T). Each dimension ~ T1 and ~ T2 in Rm, i.e. TK (T1, T2) T1 \u00b7 T2 \u00b7 T2 (1) Vectors ~ T encode trees T as forests of active tree fragments F (T)."}, {"heading": "2.2. Distributed Trees, Distributed Tree Fragments, and Expected Properties", "text": "Distributed tree cores are faster than distributed tree cores. Here we examine the properties required for neglect, so that DTKs are also approximate calculations of TKs, i.e.: DTK (T1, T2) \u2248 TK (T1, T2) (4) To derive these properties and describe function F, we show the relationships between the traditional function I: T \u2192 Rm, which maps trees in forests of tree fragments, in the tree fragments space, I: T \u2192 Rm, which embeds tree fragments in the orthogonal base of Rm, the linear embedding function f: Rm \u2192 Rd, which maps trees in a smaller vector; T = f (~ T), and our newly defined function F: Equation 2 represents vectors representing vectors ~ T in relation to the orthogonal base of Rm."}, {"heading": "3. Computing Distributed Tree Fragments and Distributed Trees", "text": "Johnson-Lindenstrauss Lemma (JLL) (Johnson & Lindenstrauss, 1984) guarantees that the embedding function f: Rm \u2192 Rd exists. It also indicates the relationship between the desired approximation of property 2 (near orthogonal vectors) and the required dimension d of the target space for a certain value of dimension m. This relationship influences how good DTKs approximate TKs (Equation 4) are. Knowing that f exists, we are confronted with the following problems: \u2022 Building a function f that directly calculates the distributed tree fragment; \u03c4 i from tree fragment \u03c4i (Section 3.2); \u2022 Showing that distributed trees; T = F-K (T) can be efficiently calculated (Section 3.1). Once the above problems are solved, we must empirically show that Equation (4) is satisfied and that the calculation of DTKs is more efficient than the calculation of TKs. These latter points are discussed in the experimental section."}, {"heading": "3.1. Computing Distributed Tree Fragments from Trees", "text": "This section introduces the function f \u0441 for distributed tree fragments and shows that the proposed function f \u0441 (\u03c4i) fulfills properties 1 and 2 using an ideal vector composition function."}, {"heading": "3.1.1. REPRESENTING TREES AS VECTORS", "text": "To ensure that these basic vectors are statistically almost orthonormal, their elements (; n) are randomly drawn from a normal distribution. (; n) The actual node vectors depend on the node names, so that; n1 =; n2 if L (n1) = L (n2), where L (\u00b7) is the node name Lemma in (Dasgupta & Gupta, 1999). (Tree structure can be uniquely represented in a \"flat\" format.) The tree structure can be represented using parenthetic notation."}, {"heading": "3.1.2. THE IDEAL VECTOR COMPOSITION FUNCTION", "text": "Here we present the ideal properties of the vector composition function, so that this function has the two desired properties. The definition of the ideal composition function follows: Definition 2 The ideal composition function is: Rd \u00b7 Rd \u2192 Rd so that the following properties are given; a,; b; c,; d \u00b2 N, a scalar sand is a vector; t, which by application results in an arbitrary number of vectors in N: 2.1 Non-commutativity with a very high degree k12.2 Non-associativity:; a (; b; c; c) 6 = (; a; b); c 2.3 Bilinearity: I) (; a +; b); c =; a; c +; b; cII); c (; a +; b); c (; c; c; c; c; c; c; bIII) (s; a; < b)."}, {"heading": "3.1.3. PROPERTIES OF DISTRIBUTED TREE FRAGMENTS", "text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "3.2. Recursive Algorithm for Distributed Trees", "text": "We focus on the space of tree fragments implicitly defined in Collins & Duffy, 2001. This attribute space refers to sub-trees as any sub-graph containing more than one node, with the caveat that whole (not partial) rule productions must be included. We want to show that the associated distributed trees can be recursively calculated using a dynamic programming algorithm without enumerating the sub-trees. We first define the recursive function and then show that it calculates exactly DTs."}, {"heading": "3.2.1. RECURSIVE FUNCTION", "text": "The structural recursive formulation for the calculation of distributed trees; T is the following:; T = \u2211 n \u03afN (T) s (n) (6), where N (T) is the node set of tree T and s (n) is the sum of distributed vectors for the sub-trees of T rooted in nodes n. Function s (n) is recursively defined as: \u2022 s (n) = ~ 0 if n is a terminal node. \u2022 s (n) =; n (; c1 + \u221a \u03bbs (c1)).... (; cm + \u02da s (cm) if n is a node with children c1.... cm.As with classical TK, the decay factor \u03bb decreases the weight of large tree fragments in the final core value. With dynamic programming, the temporal complexity of this function is linear O (| N (T) |) and the spatial complexity d (where d is the size of the vectors in Rd)."}, {"heading": "3.2.2. THE RECURSIVE FUNCTION COMPUTES DISTRIBUTED TREES", "text": "The total theorem we need is the following definition. Theorem 3 Given the ideal vector composition function, the equivalence between equation (5) and equation (6) applies, i.e.: T = experiential value n (T) s (n) = experiential value F (T) \u03c9if (\u03c4i). Accordingly (Collins & Duffy, 2001), the contribution of the tree fragment to TC is considered experiential value for the subtrees rooted in n (see theorem 5). Definition 3 Let n be a tree node T. We define R (n) = experiential value f) = experiential value f (1). We demonstrate theorem 3 by showing that the weighted sum of vectors for the subtrees is rooted in n (see theorem 5).Definition 3 Let n be a tree node T. We define R (n) = experiential value f) = 1experiential value."}, {"heading": "4. Comparative Analysis of Computational Complexity", "text": "Here we compare their complexity with the traditional tree kernels (TK) (Collins & Duffy, 2001), the fast tree kernels (FTK) (Moschitti, 2006), the fast tree kernels plus feature selection (FTK + FS) (Pighin & Moschitti, 2010) and the approximate tree kernels (ATK) (Rieck et al., 2010).In the introduction we discussed the basic characteristics of these kernels. Table 4 reports on the temporal and spatial complexity of the kernels in learning and classification. DTK is clearly competitive compared to other methods, as both complexities are constant, corresponding to the size d of the reduced feature space. In these two phases, the kernels are applied many times by the learning algorithms."}, {"heading": "5. Empirical Analysis and Experimental Evaluation", "text": "In this section, we propose two approaches to the ideal composition function, examine its appropriateness in terms of ideal properties, evaluate whether these concrete basic composition functions yield effective DTKs, and finally evaluate the calculation efficiency by comparing the average execution times of TKs and DTKs. In the following experiments, we focus on a reduced space Rd with d = 8192."}, {"heading": "5.1. Approximating Ideal Basic Composition Function", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1.1. CONCRETE COMPOSITION FUNCTIONS", "text": "We consider two possible approximate values for the ideal composition function: the mixed \u03b3 product and the mixed circular folding. These functions are defined as:; a; b = \u03b3 \u00b7 p1 (; a) p2 (; b); a; b = p1 (; a) p2 (; b), where: the elemental product between vectors and the circular folding (as in distributed representations in (plate, 1995) is between vectors; p1 and p2 are two different permutations of the vector elements; and \u03b3 is a scalar normalization parameter calculated as the average norm of the elemental product of two vectors."}, {"heading": "5.1.2. EMPIRICAL EVALUATIONS OF PROPERTIES", "text": "The two permutation functions, p1 and p2, guarantee Prop. 2,1, for a high degree k, and Prop. 2,2. Property 2,3 is inherited from elementary product and circular folding. Properties 2,4, 2,5 and 2,6 can only be approximated. Therefore, we carried out tests to evaluate the appropriateness of the two functions considered. Property 2,4 applies approximately to the maintenance of the approximate standard, while factor \u03b3 is used to maintain the standard. We empirically evaluated this property. Figure 2 (a) shows the average standard for the composition of an increasing number of basic vectors (i.e. vectors with uniform standard) with the two basic composition functions. The function behaves much better than the property. Properties 2,5 and 2,6 were tested by measuring the similarity of vectors d."}, {"heading": "5.2. Evaluating Distributed Tree Kernels: Direct and Task-based Comparison", "text": "In this section, we will examine whether DTKs with the two specific composition functions, DTK and DTK, roughly correspond to the original TK (as in Eq.4). We will conduct two sets of tests: (1) a direct comparison, in which we will directly examine the correlation between DTK and TK values; and (2) a task-based comparison, in which we will compare the performance of DTK with that of TK in two tasks of natural language processing, namely question classification (QC) and text recognition (RTE)."}, {"heading": "5.2.1. EXPERIMENTAL SET-UP", "text": "For the experiments, we used standard datasets for the two NLP tasks of QC and RTE.For QC, we used a standard question classification training and testset2, with the test set being the 500 TREC 2001 test questions. To measure task performance, we used a question multiclassifier by combining n binary SVMs according to the ONE vs ALL scheme, with the final output class being the one associated with the most likely prediction.For RTE, we looked at the corpora, which ranges from the first challenge to the fifth (Dagan et al., 2006) (Dagan et al.), with the exception of the fourth, which has no formation set. These sets are called RTE1-5. The Dev / test distribution for RTE13 and RTE5, respectively, is 567 / 800 / 800, 800 / 800 and 600 T-H pairs. We used these sets for the traditional task of the pair-based load detection function (Level S), where a load detection function (pair of the S) becomes a load function (pair of the S, where a pair of the pair x, or a pair of the S)."}, {"heading": "5.2.2. CORRELATION BETWEEN TK AND DTK", "text": "As the first measure of the ability of DTK to emulate the classical TK, we considered the correlation of the Spearman values calculated on the parse trees for the sets in QC and RTE corpora. Table 2 reports on results and shows that the DTK is not sufficient TK for \u03bb = 1. This highlights the difficulty of DTKs to handle pairs of large active forests correctly, i.e. trees with many subtrees with weights by 1. The correlation improves dramatically when the parameter \u03bb is reduced. We can conclude that the DTKs are efficient TK for the2The QC set at http: / / l2r.cs.uiuc.edu / \u02dc cogcomp / Data / QA / QC / \u03bb 0.6. These values are relevant for the applications, as we will also see in the next section. 5.2.3. TASK-BASED COMPARISONWe conducted both QU and RTE experiments for different values of parameters."}, {"heading": "6. Conclusion", "text": "In this paper, we proposed distributed tree cores (DTKs) as an approach to reduce the computational complexity of tree cores. As we have an ideal function for vector composition, we have formally demonstrated that high-dimensional spaces of tree fragments can be embedded in low-dimensional spaces where tree cores can be directly calculated using dot products. We have empirically shown that we can approximate the ideal function for vector composition. The resulting DTKs correlate with original tree cores, achieve similar results in two natural language processing tasks, and are ultimately faster."}], "references": [{"title": "Convolution kernels for natural language", "author": ["Collins", "Michael", "Duffy", "Nigel"], "venue": "In NIPS, pp", "citeRegEx": "Collins et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Collins et al\\.", "year": 2001}, {"title": "The pascal recognising textual entailment challenge", "author": ["Dagan", "Ido", "Glickman", "Oren", "Magnini", "Bernardo"], "venue": "In Quionero-Candela et al.(ed.),", "citeRegEx": "Dagan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Dagan et al\\.", "year": 2005}, {"title": "Incorporation of application layer protocol syntax into anomaly detection", "author": ["D\u00fcssel", "Patrick", "Gehl", "Christian", "Laskov", "Pavel", "Rieck", "Konrad"], "venue": "In ICISS,", "citeRegEx": "D\u00fcssel et al\\.,? \\Q2008\\E", "shortCiteRegEx": "D\u00fcssel et al\\.", "year": 2008}, {"title": "Automatic Labeling of Semantic Roles", "author": ["Gildea", "Daniel", "Jurafsky"], "venue": "Computational Linguistics,", "citeRegEx": "Gildea et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gildea et al\\.", "year": 2002}, {"title": "Mining significant tree patterns in carbohydrate sugar", "author": ["Hashimoto", "Kosuke", "Takigawa", "Ichigaku", "Shiga", "Motoki", "Kanehisa", "Minoru", "Mamitsuka", "Hiroshi"], "venue": "chains. Bioinformatics,", "citeRegEx": "Hashimoto et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2008}, {"title": "Convolution kernels on discrete structures", "author": ["Haussler", "David"], "venue": "Tech. Rept., Univ. of California at Santa Cruz,", "citeRegEx": "Haussler and David.,? \\Q1999\\E", "shortCiteRegEx": "Haussler and David.", "year": 1999}, {"title": "Extensions of lipschitz mappings into a hilbert space", "author": ["W. Johnson", "J. Lindenstrauss"], "venue": "Contemp. Math.,", "citeRegEx": "Johnson and Lindenstrauss,? \\Q1984\\E", "shortCiteRegEx": "Johnson and Lindenstrauss", "year": 1984}, {"title": "Learning to recognize features of valid textual entailments", "author": ["MacCartney", "Bill", "Grenager", "Trond", "de Marneffe", "MarieCatherine", "Cer", "Daniel", "Manning", "Christopher D"], "venue": "In NAACL,", "citeRegEx": "MacCartney et al\\.,? \\Q2006\\E", "shortCiteRegEx": "MacCartney et al\\.", "year": 2006}, {"title": "Making tree kernels practical for natural language learning", "author": ["Moschitti", "Alessandro"], "venue": "In EACL, Trento, Italy,", "citeRegEx": "Moschitti and Alessandro.,? \\Q2006\\E", "shortCiteRegEx": "Moschitti and Alessandro.", "year": 2006}, {"title": "Fast and effective kernels for relational learning from texts", "author": ["Moschitti", "Alessandro", "Zanzotto", "Fabio Massimo"], "venue": null, "citeRegEx": "Moschitti et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Moschitti et al\\.", "year": 2007}, {"title": "On reverse feature engineering of syntactic tree kernels", "author": ["Pighin", "Daniele", "Moschitti", "Alessandro"], "venue": "In CoNLL, Uppsala,", "citeRegEx": "Pighin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Pighin et al\\.", "year": 2010}, {"title": "Holographic reduced representations", "author": ["T.A. Plate"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Plate,? \\Q1995\\E", "shortCiteRegEx": "Plate", "year": 1995}, {"title": "Semantic role labeling using different syntactic views", "author": ["Pradhan", "Sameer", "Ward", "Wayne", "Hacioglu", "Kadri", "Martin", "James H", "Jurafsky", "Daniel"], "venue": "In ACL,", "citeRegEx": "Pradhan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2005}, {"title": "Approximate tree kernels", "author": ["Rieck", "Konrad", "Krueger", "Tammo", "Brefeld", "Ulf", "M\u00fcller", "KlausRobert"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Rieck et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rieck et al\\.", "year": 2010}, {"title": "An introduction to random indexing", "author": ["Sahlgren", "Magnus"], "venue": "In Workshop of Methods and Applications of Semantic Indexing at TKE, Copenhagen,", "citeRegEx": "Sahlgren and Magnus.,? \\Q2005\\E", "shortCiteRegEx": "Sahlgren and Magnus.", "year": 2005}, {"title": "Mapping kernels for trees", "author": ["Shin", "Kilho", "Cuturi", "Marco", "Kuboyama", "Tetsuji"], "venue": "In ICML,", "citeRegEx": "Shin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shin et al\\.", "year": 2011}, {"title": "A tree kernel to analyse phylogenetic profiles", "author": ["Vert", "Jean-Philippe"], "venue": "Bioinformatics, 18(suppl 1):S276\u2013S284,", "citeRegEx": "Vert and Jean.Philippe.,? \\Q2002\\E", "shortCiteRegEx": "Vert and Jean.Philippe.", "year": 2002}, {"title": "Distributed structures and distributional meaning", "author": ["Zanzotto", "Fabio Massimo", "Dell\u2019Arciprete", "Lorenzo"], "venue": "In Proceedings of the Workshop on Distributional Semantics and Compositionality,", "citeRegEx": "Zanzotto et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zanzotto et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 4, "context": "Thus, many areas \u2013 for example, biology (Vert, 2002; Hashimoto et al., 2008), computer security (D\u00fcssel et al.", "startOffset": 40, "endOffset": 76}, {"referenceID": 2, "context": ", 2008), computer security (D\u00fcssel et al., 2008), and natural language processing (Collins & Duffy, 2001; Gildea & Jurafsky, 2002; Pradhan et al.", "startOffset": 27, "endOffset": 48}, {"referenceID": 12, "context": ", 2008), and natural language processing (Collins & Duffy, 2001; Gildea & Jurafsky, 2002; Pradhan et al., 2005; MacCartney et al., 2006) \u2013 fostered extensive research in methods for learning classifiers that leverage on these data structures.", "startOffset": 41, "endOffset": 136}, {"referenceID": 7, "context": ", 2008), and natural language processing (Collins & Duffy, 2001; Gildea & Jurafsky, 2002; Pradhan et al., 2005; MacCartney et al., 2006) \u2013 fostered extensive research in methods for learning classifiers that leverage on these data structures.", "startOffset": 41, "endOffset": 136}, {"referenceID": 15, "context": "Different tree kernels modeling different feature spaces have been proposed (see (Shin et al., 2011) for a survey), but a primary research focus is the reduction of their execution time.", "startOffset": 81, "endOffset": 100}, {"referenceID": 13, "context": "tences that hardly go beyond the hundreds of nodes (Rieck et al., 2010).", "startOffset": 51, "endOffset": 71}, {"referenceID": 13, "context": "Then, for the classification, either the selection is directly encoded in the kernel computation by selecting subtrees headed by specific node labels (Rieck et al., 2010) or the smaller selected space is made explicit (Pighin & Moschitti, 2010).", "startOffset": 150, "endOffset": 170}, {"referenceID": 15, "context": "The third direction exploits dynamic programming on the whole training and application sets of instances (Shin et al., 2011).", "startOffset": 105, "endOffset": 124}, {"referenceID": 13, "context": "We here compare their complexity with respect to the traditional tree kernels (TK) (Collins & Duffy, 2001), the fast tree kernels (FTK) (Moschitti, 2006), the fast tree kernels plus feature selection (FTK+FS) (Pighin & Moschitti, 2010), and the approximate tree kernels (ATK) (Rieck et al., 2010).", "startOffset": 276, "endOffset": 296}, {"referenceID": 11, "context": "where: \u2297 is the element-wise product between vectors and is the circular convolution (as for distributed representations in (Plate, 1995)) between vectors; p1 and p2 are two different permutations of the vector elements; and \u03b3 is a normalization scalar parameter, computed as the average norm of the element-wise product of two vectors.", "startOffset": 124, "endOffset": 137}], "year": 2012, "abstractText": "In this paper, we propose the distributed tree kernels (DTK) as a novel method to reduce time and space complexity of tree kernels. Using a linear complexity algorithm to compute vectors for trees, we embed feature spaces of tree fragments in low-dimensional spaces where the kernel computation is directly done with dot product. We show that DTKs are faster, correlate with tree kernels, and obtain a statistically similar performance in two natural language processing tasks.", "creator": "LaTeX with hyperref package"}}}