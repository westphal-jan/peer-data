{"id": "1206.4634", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Artist Agent: A Reinforcement Learning Approach to Automatic Stroke Generation in Oriental Ink Painting", "abstract": "Oriental ink painting, called Sumi-e, is one of the most appealing painting styles that has attracted artists around the world. Major challenges in computer-based Sumi-e simulation are to abstract complex scene information and draw smooth and natural brush strokes. To automatically find such strokes, we propose to model the brush as a reinforcement learning agent, and learn desired brush-trajectories by maximizing the sum of rewards in the policy search framework. We also provide elaborate design of actions, states, and rewards tailored for a Sumi-e agent. The effectiveness of our proposed approach is demonstrated through simulated Sumi-e experiments.", "histories": [["v1", "Mon, 18 Jun 2012 15:14:24 GMT  (4113kb)", "http://arxiv.org/abs/1206.4634v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG cs.GR stat.ML", "authors": ["ning xie 0003", "hirotaka hachiya", "masashi sugiyama"], "accepted": true, "id": "1206.4634"}, "pdf": {"name": "1206.4634.pdf", "metadata": {"source": "META", "title": "Artist Agent: A Reinforcement Learning Approach to Automatic Stroke Generation in Oriental Ink Painting", "authors": ["Ning Xie", "Hirotaka Hachiya", "Masashi Sugiyama"], "emails": ["XIE@SG.CS.TITECH.AC.JP", "HACHIYA@SG.CS.TITECH.AC.JP", "SUGI@CS.TITECH.AC.JP"], "sections": [{"heading": "1. Introduction", "text": "In this paper we focus on oriental ink painting, which uses few strokes to convey significant information about the scene. An artist can draw brushstrokes in different layers in different styles. The appearance of the artist is determined by the shape of the brush stroke. The shape of the brush stroke is determined by the shape of the brush stroke."}, {"heading": "2. Formulation of Automatic Stroke Generation", "text": "In this section we formulate the problem of automatic stroke generation as a problem of reinforcement learning (RL)."}, {"heading": "2.1. Markov Decision Process", "text": "Let us formulate the procedure of pulling a stroke as a Markov decision-making process (MDP) consisting of a tuple (S, A, pI, pT, R), where S is a series of continuous states, A is a series of continuous actions, pI is the probability density of the initial state, pT (s \u00b2 | s, a) is the transition probability density from the current state s \u00b2 S to the next state s \u00b2 S when a certain state takes action. Let h = (s1, a1,...) is an immediate reward function for the transition from s \u00b2 to s \u00b2 by taking action. Let it be (a \u00b2 s; \u03b8) a stochastic policy with parameter sets representing the conditional probability density of taking action s. Let h = (s1, a1,...) be an immediate reward function for the transition from s \u00b2 to s \u00b2 by taking action."}, {"heading": "2.2. Policy Gradient Method", "text": "To solve the above RL problem, we use a political gradient algorithm (Williams, 1992) = > J = > J = > J, i.e., the political parameter is updated by the gradient rise. (2001) The gradient is updated by the gradient rise. (2001) The gradient is updated by the gradient rise. (2001) The gradient is updated by the gradient rise. (2001) The so-called log trick is used. (2001) R (h) dh = p (h) dh = p (h) dh = p (h). (2001) T (2001) T (h) dh = p (h)."}, {"heading": "3. Design of MDP for Brush Agent", "text": "In this section, we give a specific design of the state space S, action space A and the immediate reward function R (s, a, s \u2032) for our brush agent to learn soft and natural brushstrokes. To this end, we first extract the boundary of a specific object and then calculate the medial axis M as shown in Figure 2."}, {"heading": "3.1. Design of Actions", "text": "In order to create elegant brushstrokes, the brush agent should move within the prescribed boundaries (see Figure 1 (a)).Since proper coverage of the entire desired region is the most important issue, we treat the movement of the brush as the primary action (Action 1).Action a sets the angle of the speed vector of the brush agent relative to the medial axis. The action is determined by the Gaussian principle function. In practical applications, the brush agent should be able to handle arbitrary strokes on different scales. In order to achieve a stable performance on different scales, we change the speed of the brush movement relative to the scale of the current impression. The other actions (Measures 2, 3 and 4) are automatically optimized to fulfill the assumption that the tip of the brush agent should touch one side of the boundary; in the meantime, the brush agent should be proportional to the scale of the current impression, while the lower side of the brush agent on the other side should remain to reach the new boundary."}, {"heading": "3.2. Design of States", "text": "We use the global measurement (the pose configuration of a surface impression under the global Cartesian coordinate) and the relative state (the brush agent pose and the locomotion information in relation to the local environment).The relative state is calculated on the basis of the global measurements. Thus, while both the global measurement and the relative state should be considered as a state in the sense of an MDP, for the calculation of yield and a policy we use only the relative state, which allows the agent to learn a drawing policy that can be generalized to new shapes.Our relative spatial design consists of two parts: the current environment shape and the coming form. More precisely, our state space is expressed by six characteristics s = (\u03c9, p, p, p, 2, l) > (see Figures 2 and 3), where \u2022 the relative spatial design consists of two parts: the environment shape and the emerging form."}, {"heading": "3.3. Design of Immediate Rewards", "text": "We design the reward function so that the smoother the brush stroke is, the higher the reward. To this end, we define the reward function asR (st, at, st + 1) = 0 if ft = ft + 1 or l = 0,1 + (| \u03ba1 (t) | + | \u03ba2 (t) |) / 2 \u03bb1E (t) position + \u03bb2E (t) attitude otherwise. That is, the immediate reward is zero if the brush is blocked by a boundary as ft = ft + 1 or the brush goes backwards into a region already covered by previous footprints fi (i < t + 1)."}, {"heading": "3.4. Design of Training Sessions for Brush Agent", "text": "Given an appropriately designed MDP, the last step is to design training courses, which is also very important in order to make the brush agent useful in practice.First, we propose to train the agent on the basis of partial shapes, not the entire shapes. An advantage of this local training strategy is that various local shapes can be generated from a single entire shape, which significantly increases the number and variation of training patterns. Another advantage is that the generalization ability to new shapes can be improved, because even if the overall profile of a new shape is very different from that of the training data, the new shape can contain similar local shapes as in Figure 4 (a).To provide a wide variety of local shapes to the agent as training data, we have prepared an in-house stroke library. This library contains 80 digitized real brush strokes, which are often used in oriental ink painting. See Figure 4 (c) for some examples. We extracted the form and placed them in a queue of information."}, {"heading": "4. Experiments", "text": "In this section we report on experimental results."}, {"heading": "4.1. Setup", "text": "We train the policy of the brush agent based on the form shown in Figure 4 (c) through our training strategy introduced in Section 3.4. The parameter of the initial policy is set to \u03b8 = (\u00b5 >, \u03c3) > = (0, 0, 0, 0, 0, 2) > according to previous domain knowledge. The agent collects N = 300 episodic samples with trajectory length T = 32. The discount factor is set to \u03b3 = 0.99. The learning rate \u03b5 is set to 0.1 / 2, 0, 0, 2) >. We examine the average return over 10 studies as a function of policy update iterations. The return on each study is calculated over 300 training episodes."}, {"heading": "4.2. Results", "text": "Figure 6 shows examples of render and brush path results in the political training process. Table 1 shows the performance of strategies learned through our RL method and the DP method (Xie et al., 2011) on an Intel Core i7 2.70 GHz. According to the discussion in Xie et al. (2011), the performance of the DP method depends on the structure of the parameter in the energy function and the number of candidates in the DP search space. However, it is difficult to manually find the optimal parameters in practice. Table 1 lists results obtained through the DP method with the change in the number of candidates at each step of the DP search space. Results of the expected return and the execution time vary significantly depending on the number of candidates."}, {"heading": "5. Related Works", "text": "In this section, we give a brief overview of the current state of the art in the creation of brush drawings using two approaches: physics-based painting and dash-based rendering."}, {"heading": "5.1. Physics-Based Painting", "text": "This approach aims to reproduce a real painting process and give the user an intuitive and natural feeling when holding a mouse or a pen-like device. Several previous works dealt with the modeling of brush shapes, their dynamics and their interaction with the paper, as well as the simulation of color dispersion and absorption by the paper. Among the first representative works are the hairy brushes (Strassmann, 1986) and the physics-based models (Saito & Nakajima, 1999; Chu & Tai, 2004; Chu et al., 2010).These virtual brushes are suitable for interactive use to draw different styles of brush strokes. Despite the extensive research literature, the automatic control of a virtual brush with six degrees of freedom - three for the cartesian coordinates and three for its angular orientation (pitch, roll and yaw) - in addition to the dynamics of brush strokes, the complex and existing physical models are simplifications in the palette."}, {"heading": "5.2. Stroke-Based Rendering", "text": "In many situations, it is desirable to automatically convert real images into ink paintings, especially if the user has no painting experience and is only interested in the painting results rather than the painting process. However, the skeletal stroke method (Hsu & Lee, 1994) generates brushstrokes from the 2D paths, which are determined either by user interaction or automatic extraction from real images. However, the main difficulty is to specify and vary the width of strokes along the path and the texture of the strokes. One of the solutions is the manual setting of the stroke back (Guo & Kunii, 2003) by the user. One limitation of such methods is that setting the values at each checkpoint is time consuming. Contour controlled methods (Xie et al., 2011) can successfully produce strokes in desired shapes. However, there are several strict limitations: (I) When cropping the boundary region in slices at each step, the cross sections should not overlap."}, {"heading": "6. Conclusions", "text": "In this work, we applied reinforcement learning to oriental ink painting and enabled the automatic generation of smooth and natural brush strokes in any shapes. Our contributions include careful drafting of actions, states, immediate rewards and training. One of the key ideas was to design the brush agent's state space in such a way that it is relative to its environment form, which allows us to learn a general drawing strategy independent of a particular overall shape. Another important idea was to train the brush agent on site in the given shape. This significantly contributed to improving the generalization capability of new shapes, because even if a new shape differs significantly from the training data as a whole, it contains similar local shapes. Experimental results showed that our RL method offers better performance with considerably less computing time than the existing DP methods and our RL agent successfully draws new complex shapes with smooth and natural brush strokes."}, {"heading": "Acknowledgments", "text": "The authors thank the anonymous reviewers for their helpful comments. Ning Xie was supported by MEXT Scholarship, Hirotaka Hachiya from FIRST Program and Masashi Sugiyama from MEXT KAKENHI 23120004."}], "references": [{"title": "Finding the medial axis of a simple polygon in linear time", "author": ["F. Chin", "J. Snoeyink", "A.W. Cao"], "venue": "Discrete & Computational Geometry,", "citeRegEx": "Chin et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Chin et al\\.", "year": 1995}, {"title": "Real-time painting with an expressive virtual Chinese brush", "author": ["N. Chu", "Tai", "C.-L"], "venue": "IEEE Computer Graphics and Applications,", "citeRegEx": "Chu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Chu et al\\.", "year": 2004}, {"title": "Detailpreserving paint modeling for 3D brushes", "author": ["N. Chu", "W. Baxter", "Wei", "L.-Y", "N. Govindaraju"], "venue": "In Proceedings of the 8th International Symposium on Non-Photorealistic Animation and Rendering,", "citeRegEx": "Chu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chu et al\\.", "year": 2010}, {"title": "Nijimi\u201d rendering algorithm for creating quality black ink paintings", "author": ["Q. Guo", "T.L. Kunii"], "venue": "In Proceedings of Computer Graphics International,", "citeRegEx": "Guo and Kunii,? \\Q2003\\E", "shortCiteRegEx": "Guo and Kunii", "year": 2003}, {"title": "Painterly rendering with curved brush strokes of multiple sizes", "author": ["A. Hertzmann"], "venue": "In Proceedings of SIGGRAPH,", "citeRegEx": "Hertzmann,? \\Q1998\\E", "shortCiteRegEx": "Hertzmann", "year": 1998}, {"title": "Drawing and animation using skeletal strokes", "author": ["S.C. Hsu", "H.H. Lee"], "venue": "In Proceedings of SIGGRAPH,", "citeRegEx": "Hsu and Lee,? \\Q1994\\E", "shortCiteRegEx": "Hsu and Lee", "year": 1994}, {"title": "Policy gradient methods for robotics", "author": ["J. Peters", "S. Schaal"], "venue": "In International Conference on Intelligent Robots and Systems,", "citeRegEx": "Peters and Schaal,? \\Q2006\\E", "shortCiteRegEx": "Peters and Schaal", "year": 2006}, {"title": "3D physics-based brush model for painting", "author": ["S. Saito", "M. Nakajima"], "venue": "In Proceedings of SIGGRAPH, Conference Abstracts and Applications,", "citeRegEx": "Saito and Nakajima,? \\Q1999\\E", "shortCiteRegEx": "Saito and Nakajima", "year": 1999}, {"title": "An algorithm for automatic painterly rendering based on local source image approximation", "author": ["M. Shiraishi", "Y. Yamaguchi"], "venue": "In Proceedings of the 1st International Symposium on Non-Photorealistic Animation and Rendering,", "citeRegEx": "Shiraishi and Yamaguchi,? \\Q2000\\E", "shortCiteRegEx": "Shiraishi and Yamaguchi", "year": 2000}, {"title": "Hairy brushes", "author": ["S. Strassmann"], "venue": "In Proceedings of SIGGRAPH, pp", "citeRegEx": "Strassmann,? \\Q1986\\E", "shortCiteRegEx": "Strassmann", "year": 1986}, {"title": "Reinforcement Learning: An Introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": null, "citeRegEx": "Sutton and Barto,? \\Q1998\\E", "shortCiteRegEx": "Sutton and Barto", "year": 1998}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["R.J. Williams"], "venue": "Machine Learning,", "citeRegEx": "Williams,? \\Q1992\\E", "shortCiteRegEx": "Williams", "year": 1992}, {"title": "Contour-driven Sumi-e rendering of real photos", "author": ["N. Xie", "H. Laga", "S. Saito", "M. Nakajima"], "venue": "Computers & Graphics,", "citeRegEx": "Xie et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Xie et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 4, "context": "Unlike western styles, such as water-color, pastel, and oil painting, which place overlapped strokes into multiple layers (Hertzmann, 1998; Shiraishi & Yamaguchi, 2000), oriental ink painting uses few strokes to convey significant information about the scene.", "startOffset": 122, "endOffset": 168}, {"referenceID": 12, "context": "Xie et al. (2011) formulated the problem of drawing brush strokes as minimization of an accumulated energy of moving the brush and used the Dynamic Programming (DP) approach to obtain optimal brush strokes.", "startOffset": 0, "endOffset": 18}, {"referenceID": 11, "context": "Secondly, we propose to formulate stroke drawing by a Markov decision process (MDP) (Sutton & Barto, 1998) and apply a policy gradient method (Williams, 1992) to learn a (local) optimal drawing policy.", "startOffset": 142, "endOffset": 158}, {"referenceID": 11, "context": "We use a policy gradient algorithm (Williams, 1992) to solve the above RL problem.", "startOffset": 35, "endOffset": 51}, {"referenceID": 0, "context": "In the training scheme, the initial position of the first episode is chosen to be the start point S of the medial axis (Chin et al., 1995), and the direction to move is chosen to be the goal point G as illustrated in Figure 4(b).", "startOffset": 119, "endOffset": 138}, {"referenceID": 12, "context": "Table 1 shows the performance of policies learned by our RL method and the DP method (Xie et al., 2011) on an Intel Core i7 2.", "startOffset": 85, "endOffset": 103}, {"referenceID": 12, "context": "Table 1 shows the performance of policies learned by our RL method and the DP method (Xie et al., 2011) on an Intel Core i7 2.70 GHz. According to the discussion in Xie et al. (2011), the performance of the DP method depends on the setup of the parameter in the energy function and the Table 1.", "startOffset": 86, "endOffset": 183}, {"referenceID": 9, "context": "Among the first stream, early representative works include the hairy brushes (Strassmann, 1986) and the physics-based models (Saito & Nakajima, 1999; Chu & Tai, 2004; Chu et al.", "startOffset": 77, "endOffset": 95}, {"referenceID": 2, "context": "Among the first stream, early representative works include the hairy brushes (Strassmann, 1986) and the physics-based models (Saito & Nakajima, 1999; Chu & Tai, 2004; Chu et al., 2010).", "startOffset": 125, "endOffset": 184}, {"referenceID": 2, "context": "Some of them rely on GPU acceleration for satisfactory speed performance (Chu et al., 2010).", "startOffset": 73, "endOffset": 91}, {"referenceID": 12, "context": "Contour-driven methods (Xie et al., 2011) can successfully generate strokes in desired shapes.", "startOffset": 23, "endOffset": 41}], "year": 2012, "abstractText": "Oriental ink painting, called Sumi-e, is one of the most appealing painting styles that has attracted artists around the world. Major challenges in computer-based Sumi-e simulation are to abstract complex scene information and draw smooth and natural brush strokes. To automatically generate such strokes, we propose to model a brush as a reinforcement learning agent, and learn desired brush-trajectories by maximizing the sum of rewards in the policy search framework. We also elaborate on the design of actions, states, and rewards tailored for a Sumi-e agent. The effectiveness of our proposed approach is demonstrated through simulated Sumi-e experiments.", "creator": "LaTeX with hyperref package"}}}