{"id": "1206.4636", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Modeling Latent Variable Uncertainty for Loss-based Learning", "abstract": "We consider the problem of parameter estimation using weakly supervised datasets, where a training sample consists of the input and a partially specified annotation, which we refer to as the output. The missing information in the annotation is modeled using latent variables. Previous methods overburden a single distribution with two separate tasks: (i) modeling the uncertainty in the latent variables during training; and (ii) making accurate predictions for the output and the latent variables during testing. We propose a novel framework that separates the demands of the two tasks using two distributions: (i) a conditional distribution to model the uncertainty of the latent variables for a given input-output pair; and (ii) a delta distribution to predict the output and the latent variables for a given input. During learning, we encourage agreement between the two distributions by minimizing a loss-based dissimilarity coefficient. Our approach generalizes latent SVM in two important ways: (i) it models the uncertainty over latent variables instead of relying on a pointwise estimate; and (ii) it allows the use of loss functions that depend on latent variables, which greatly increases its applicability. We demonstrate the efficacy of our approach on two challenging problems---object detection and action detection---using publicly available datasets.", "histories": [["v1", "Mon, 18 Jun 2012 15:15:13 GMT  (185kb)", "http://arxiv.org/abs/1206.4636v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["m pawan kumar", "benjamin packer", "daphne koller"], "accepted": true, "id": "1206.4636"}, "pdf": {"name": "1206.4636.pdf", "metadata": {"source": "CRF", "title": "Modeling Latent Variable Uncertainty for Loss-based Learning", "authors": ["M. Pawan Kumar", "Ben Packer"], "emails": ["pawan.kumar@ecp.fr", "bpacker@cs.stanford.edu", "koller@cs.stanford.edu"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them are able to survive on their own, and they are able to survive on their own if they do not put themselves in a position to survive on their own."}, {"heading": "2. Related Work", "text": "The most commonly used method for learning the parameters of an lvm is the em algorithm (Dempster et al., 1977; Sundberg, 1974) or its many variants (Gelman et al., 1995).While the em algorithm has an elegant probabilistic interpretation of maximizing the likelihood of ground-level results, it marginalizes the latent variables, making it unsuitable for problems requiring accurate prediction of latent variables, and does not employ a user-specific loss function to assess the quality of the solution by the user. The most closely related work to our approach is lsvm (Felzenszwalb et al., 2008; Yu & Joachims, 2009) and its recently proposed generalization called maxmargin min-entropy models (or m3e for short)."}, {"heading": "3. Preliminaries", "text": "Notation: We designate the input by x-X, the output by y-Y and the latent variables by h-H. The training data set D = {si = (xi, yi), i = 1, \u00b7 \u00b7, n} consists of n input-output pairs (or samples) si.We designate the parameters of the delta distribution, which predicts the output and the latent variables for a given input, as w. The parameters of the conditional distribution of the latent variables given to the input and output are called phenomena. We assume that the user specifies a loss function (y1, h1, y2, h2), which measures the difference between (y1, h1) and (y2, h2) coefficiencies. Similar to previous approaches, we assume that we specify the difference (y1, h1, y2, h2, h2, h2, etc."}, {"heading": "4. Loss-based Learning Framework", "text": "Using the above notation and definitions, we will now present the details of our learning framework, beginning with the description of the distributions represented by lvm."}, {"heading": "4.1. Distributions", "text": "We want to address two different tasks: (i) accurately modelling the distribution of latent variables for a particular input-output pair; (ii) accurately predicting the output and latent variables for a given input (where accuracy is measured by a user-defined loss); rather than treating these two tasks with a single distribution, we define two separate distributions, each of which is focused on a single task. (3) Here, we define a delta distribution parameterized by w, the output and the latent variables according to the following rule: (y (w), h (w)) = argmax (y, h) w (x, y, h)."}, {"heading": "4.2. The Learning Objective", "text": "Considering a dataset D and a loss function \u2206 (\u00b7), we suggest that we learn the parameters hi (hi-i values) in such a way that they minimize the corresponding dissimilarity coefficient across all training samples. Before delving into the details, we give a broad overview of our objective functioning. For a fixed w, if the predicted performance yi (w) is similar to the basic truth output yi, our goal encourages the probability of the corresponding latent variables, that is, P\u03b8 (hi (w) | si), and other similar latent variables that should be high. If the predicted performance yi (w) is dissimilar to the basic truth output yi, our goal encourages the diversity coefficient of the corresponding distribution, that is P\u03b8 (si), to be high. In other words, for a correctly predicted sample, the conditional distribution is peaky, while for an erroneously predicted sample the conditional variant is flat while the conditional sample is conditional distribution."}, {"heading": "4.3. Upper Bound on the Learning Objective", "text": "While the objective (8) is smooth and differentiable, it is in fact very uneven in the most commonly used problems of the loss function; the irregularity of the lens leads to a difficult optimization problem, which leaves the learner vulnerable to poor local minimum solutions. To overcome this deficiency, we minimize an upper limit of the object, similar to the lsvm formulation (Yu & Joachims, 2009). Specifically, we tie in the term Hi (w, \u03b8), which depends on the use of the upper LSW function being defined as a subsequent function."}, {"heading": "5. Optimization", "text": "While the upper limit derived in the previous section still leads to a non-smooth and non-convex optimization problem, we obtain an approximate solution using the block coordinate decrease. Starting from an initial estimate of the parameters, we alternately repair one of the two sets of parameters (either w or \u03b8) while optimizing problem (11) against the other set of parameters. The process ends when the decrease of the object falls below the value C, where C is the hyperparameter of the problem (11) and \u0439 is a user-specified tolerance. The following subsections provide details of the optimization for each set of parameters."}, {"heading": "5.1. Optimization over w", "text": "The following observation provides us with an efficient algorithm for the issues raised above. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem that we cannot solve. (c) We have a problem. (c) We have a problem. (c) We have a problem. (c) We have a problem. (c) We have a problem. (c) We have a problem. (c) We have a problem."}, {"heading": "5.2. Optimization over \u03b8", "text": "For a fixed w, problem (11) can be interpreted as a constant problem 3. Thus, the fixed parameter quantity is based on the following objective 1n (n \u2211 i = 1Hi (w, \u03b8) \u2212 \u03b2Hi (\u03b8))), (15) where the divergence coefficients Hi (w, \u03b8) and Hi (\u03b8) are effectively defined in Equation (8). To gain an understanding of the above objective, let us consider a simple 0 / 1 loss (that is, the loss is 0 if both initial quantities are equal and both latent variables are equal, otherwise 1). If yi (w) = yi, that is, w predicts the correct output of the sample si, then the first term of the aforementioned objective dominates the second. In this case, the number of parameters is encouraged to assign a high probability to the predicted latent variables (w), and other similar latent variables in order to minimize the target."}, {"heading": "6. Experiments", "text": "Specifically, we show how our approach, which models uncertainty in the values of the latent variables during training, exceeds previous loss-based learning frameworks, namely lsvm and ilsvm, which estimate only the most likely mapping of the latent variables. All three methods used in our experiments have a common hyperparameter C (the relative weight for the upper limits), which we vary to take values from the sentence {10 \u2212 4, 10 \u2212 3, \u00b7 \u00b7 \u00b7, 102}. In addition, two other hyperparameters are introduced in our framework: J (the relative weight for the regulation of Ali) and \u03b2 (the hyperparameter for Rao's dissimilarity coefficient). In all our experiments, we use J = 0.1 and \u03b2 = 0.1. However, we can achieve better results if we set these hyperparameters carefully. The tolerance value for all methods was 1 \u2212 10."}, {"heading": "6.1. Object Detection", "text": "The objective of this application is to learn a differentiated viewpoint that defines the category of real, real, real, reproductive, reproductive, reproductive, reproductive, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing, reproducing"}, {"heading": "6.2. Action Detection", "text": "The goal of this application is to learn human action models that predict the action class (for example, \"running\" or \"jumping\") and the location of the person in an image. Similar to object recognition, a fully monitored dataset would require an annotation of each training image with the \"Loss of Person\" field. Instead, we use image-level labels that indicate what action is performed by a person in the image. Formally, the input x for each sample is an image. The output y descriptor is the Poselet descriptor (Maji et al., 2011) of the bounding box. We look at about 20 putative bounding boxes for each image that are automatically generated with a standard person detector."}, {"heading": "7. Discussion", "text": "Our framework consists of two distributions: a conditional distribution that captures uncertainty in the latent variables, and a delta distribution that predicts output and latent variable values. We learn the parameters of the distributions by minimizing a loss-based inequality coefficient between the two distributions for all samples in the training dataset. We demonstrate empirically the utility of our approach over previous loss-based learning frameworks based on publicly available datasets of two challenging problems - object detection and action detection. The proposed optimization requires the calculation of the expected loss. i (y, h | \u03b8) (shown in Equation (7))) if we attach the delta distribution and the loss-related subgradients gt gt gt gt gt gt gt (shown in Equation (17)) when learning conditional distribution. In special cases (for example, low tree width models), these conditions can be accurately calculated."}, {"heading": "Blaschko, M., Vedaldi, A., and Zisserman, A. Simultaneous", "text": "Object recognition and low surveillance ranking. In NIPS, 2010.Dalal, N. and Triggs, B. Histograms of oriented gradients for human recognition. In CVPR, 2005.Dempster, A., Laird, N., and Rubin, D. Maximum probability due to incomplete EM algorithm data. Journal of Royal Statistical Society, 1977."}, {"heading": "Everingham, M., Van Gool, L., Williams, C., Winn, J.,", "text": "and Zisserman, A. The Challenge of Visual Object Classes (VOC) by PASCAL. IJCV, 2010."}, {"heading": "Felzenszwalb, P., McAllester, D., and Ramanan, D. A", "text": "In CVPR, 2008. Gelman, A., Carlin, J., Stern, H., and Rubin, D. Bayesian Data Analysis. Chapman and Hall, 1995."}, {"heading": "Joachims, T., Finley, T., and Yu, C.-N. Cutting-plane", "text": "Training for structural SVMs. Machine Learning, 2009.Kumar, M. P., Packer, B., and Koller, D. Self-determined learning for latent variable models. In NIPS, 2010."}, {"heading": "Kumar, M. P., Turki, H., Preston, D., and Koller, D.", "text": "Learning specific class segmentation from different data. ICCV, 2011."}, {"heading": "Maji, S., Bourdev, L., and Malik, J. Action recognition", "text": "from a distributed representation of pose and appearance. In CVPR, 2011."}, {"heading": "Miller, K., Kumar, M. P., Packer, B., Goodman, D., and", "text": "Koller, D. Max-margin min-entropy models. In AISTATS, 2012.Rao, C. Diversity and Dissimilarity coefficient: A unified approach. Theoretical Population Biology, 1982."}, {"heading": "Shalev-Shwartz, S., Singer, Y., and Srebro, N. Pegasos:", "text": "Primarily estimated sub-gradient solver for SVM. In ICML, 2009.Sundberg, R. Theory of maximum probability for incomplete data from an exponential family. Scandinavian Journal of Statistics, 1974.Tsochantaridis, I., Hofmann, T., Altun, Y., and Joachims, T. Support of vector machine learning for interdependent and structured production spaces. In ICML, 2004.Yu, C.-N. and Joachims, T. Learning structural SVMs with latent variables. In ICML, 2009."}], "references": [{"title": "Simultaneous object detection and ranking with weak supervision", "author": ["M. Blaschko", "A. Vedaldi", "A. Zisserman"], "venue": "In NIPS,", "citeRegEx": "Blaschko et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Blaschko et al\\.", "year": 2010}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "In CVPR,", "citeRegEx": "Dalal and Triggs,? \\Q2005\\E", "shortCiteRegEx": "Dalal and Triggs", "year": 2005}, {"title": "Maximum likelihood from incomplete data via the EM algorithm", "author": ["A. Dempster", "N. Laird", "D. Rubin"], "venue": "Journal of Royal Statistical Society,", "citeRegEx": "Dempster et al\\.,? \\Q1977\\E", "shortCiteRegEx": "Dempster et al\\.", "year": 1977}, {"title": "The PASCAL visual object classes (VOC) challenge", "author": ["M. Everingham", "L. Van Gool", "C. Williams", "J. Winn", "A. Zisserman"], "venue": null, "citeRegEx": "Everingham et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Everingham et al\\.", "year": 2010}, {"title": "A discriminatively trained, multiscale, deformable part model", "author": ["P. Felzenszwalb", "D. McAllester", "D. Ramanan"], "venue": "In CVPR,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2008}, {"title": "Bayesian Data Analysis", "author": ["A. Gelman", "J. Carlin", "H. Stern", "D. Rubin"], "venue": null, "citeRegEx": "Gelman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Gelman et al\\.", "year": 1995}, {"title": "Cutting-plane training for structural SVMs", "author": ["T. Joachims", "T. Finley", "Yu", "C.-N"], "venue": "Machine Learning,", "citeRegEx": "Joachims et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Joachims et al\\.", "year": 2009}, {"title": "Self-paced learning for latent variable models", "author": ["M.P. Kumar", "B. Packer", "D. Koller"], "venue": "In NIPS,", "citeRegEx": "Kumar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2010}, {"title": "Learning specific-class segmentation from diverse data", "author": ["M.P. Kumar", "H. Turki", "D. Preston", "D. Koller"], "venue": "In ICCV,", "citeRegEx": "Kumar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2011}, {"title": "Action recognition from a distributed representation of pose and appearance", "author": ["S. Maji", "L. Bourdev", "J. Malik"], "venue": "In CVPR,", "citeRegEx": "Maji et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Maji et al\\.", "year": 2011}, {"title": "Max-margin min-entropy models", "author": ["K. Miller", "M.P. Kumar", "B. Packer", "D. Goodman", "D. Koller"], "venue": "In AISTATS,", "citeRegEx": "Miller et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2012}, {"title": "Diversity and dissimilarity coefficients: A unified approach", "author": ["C. Rao"], "venue": "Theoretical Population Biology,", "citeRegEx": "Rao,? \\Q1982\\E", "shortCiteRegEx": "Rao", "year": 1982}, {"title": "Pegasos: Primal estimated sub-gradient solver for SVM", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro"], "venue": "In ICML,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2009}, {"title": "Maximum likelihood theory for incomplete data from an exponential family", "author": ["R. Sundberg"], "venue": "Scandinavian Journal of Statistics,", "citeRegEx": "Sundberg,? \\Q1974\\E", "shortCiteRegEx": "Sundberg", "year": 1974}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "Y. Altun", "T. Joachims"], "venue": "In ICML,", "citeRegEx": "Tsochantaridis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2004}, {"title": "Learning structural SVMs with latent variables", "author": ["Yu", "C.-N", "T. Joachims"], "venue": "In ICML,", "citeRegEx": "Yu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 11, "context": "In order to make the two distributions as similar as possible, we minimize a regularized upper bound on a loss-based dissimilarity measure (Rao, 1982) between the distributions.", "startOffset": 139, "endOffset": 150}, {"referenceID": 2, "context": "The most commonly used method for learning the parameters of an lvm is the em algorithm (Dempster et al., 1977; Sundberg, 1974), or its many variants (Gelman et al.", "startOffset": 88, "endOffset": 127}, {"referenceID": 13, "context": "The most commonly used method for learning the parameters of an lvm is the em algorithm (Dempster et al., 1977; Sundberg, 1974), or its many variants (Gelman et al.", "startOffset": 88, "endOffset": 127}, {"referenceID": 5, "context": ", 1977; Sundberg, 1974), or its many variants (Gelman et al., 1995).", "startOffset": 46, "endOffset": 67}, {"referenceID": 4, "context": "The most related works to our approach are lsvm (Felzenszwalb et al., 2008; Yu & Joachims, 2009) and its recently proposed generalization called maxmargin min-entropy models (or m3e for short) (Miller et al.", "startOffset": 48, "endOffset": 96}, {"referenceID": 10, "context": ", 2008; Yu & Joachims, 2009) and its recently proposed generalization called maxmargin min-entropy models (or m3e for short) (Miller et al., 2012).", "startOffset": 125, "endOffset": 146}, {"referenceID": 0, "context": "While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection.", "startOffset": 94, "endOffset": 206}, {"referenceID": 4, "context": "While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection.", "startOffset": 94, "endOffset": 206}, {"referenceID": 7, "context": "While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection.", "startOffset": 94, "endOffset": 206}, {"referenceID": 10, "context": "While such loss functions are useful, and in fact have been successfully employed in practice (Blaschko et al., 2010; Felzenszwalb et al., 2008; Kumar et al., 2010; Miller et al., 2012; Yu & Joachims, 2009), they cannot model several important problems, including the two employed in our experiments\u2014object detection and action detection.", "startOffset": 94, "endOffset": 206}, {"referenceID": 8, "context": "In our earlier work (Kumar et al., 2011), we proposed an iterative lsvm strategy (or ilsvm for short) with the aim of using a general loss function.", "startOffset": 20, "endOffset": 40}, {"referenceID": 11, "context": "We refer the reader to (Rao, 1982) for details.", "startOffset": 23, "endOffset": 34}, {"referenceID": 11, "context": "Note that Rao (1982) fixed \u03b2 = 0.", "startOffset": 10, "endOffset": 21}, {"referenceID": 11, "context": "Note that Rao (1982) fixed \u03b2 = 0.5 in order to ensure that the dissimilarity coefficient is symmetric for Pi and Pj . However, dissimilarity coefficients do not necessarily have to be symmetric (for example, the well-known Kullback-Liebler divergence is non-symmetric); hence we use the more general version shown in equation (2). Rao (1982) showed that the above formulation generalizes other commonly used dissimilarity coefficients such as the Mahalanobis distance and the Gini-Simpson index.", "startOffset": 10, "endOffset": 342}, {"referenceID": 6, "context": "There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004).", "startOffset": 69, "endOffset": 150}, {"referenceID": 12, "context": "There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004).", "startOffset": 69, "endOffset": 150}, {"referenceID": 14, "context": "There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004).", "startOffset": 69, "endOffset": 150}, {"referenceID": 7, "context": "We can also solve problem (13) using the selfpaced learning algorithm (Kumar et al., 2010), which can potentially improve the performance of our framework.", "startOffset": 70, "endOffset": 90}, {"referenceID": 6, "context": "There are several efficient algorithms for problem (14), for example (Joachims et al., 2009; Shalev-Shwartz et al., 2009; Tsochantaridis et al., 2004). In this work, we use the 1-slack reformulation method proposed by Joachims et al. (2009). We can also solve problem (13) using the selfpaced learning algorithm (Kumar et al.", "startOffset": 70, "endOffset": 241}, {"referenceID": 7, "context": "However, we note that several important problems in machine learning can be formulated using latent variables whose space is sufficiently small to allow for exact computations of the expected loss, including motif finding (Yu & Joachims, 2009), image classification (Kumar et al., 2010; Miller et al., 2012), digit recognition (Kumar et al.", "startOffset": 266, "endOffset": 307}, {"referenceID": 10, "context": "However, we note that several important problems in machine learning can be formulated using latent variables whose space is sufficiently small to allow for exact computations of the expected loss, including motif finding (Yu & Joachims, 2009), image classification (Kumar et al., 2010; Miller et al., 2012), digit recognition (Kumar et al.", "startOffset": 266, "endOffset": 307}, {"referenceID": 7, "context": ", 2012), digit recognition (Kumar et al., 2010), and the two problems used in our experiments, namely object detection and action detection.", "startOffset": 27, "endOffset": 47}, {"referenceID": 8, "context": "Our overall approach is similar in flavor to the ilsvm algorithm (Kumar et al., 2011), which iterates over the following two steps until convergence: (i) obtain the value of the latent variables for all training samples using the current estimate of the parameters; (ii) update the parameters by solving an lsvm, where the loss function is measured using the latent variables estimated in the first step instead of the true latent variables.", "startOffset": 65, "endOffset": 85}, {"referenceID": 7, "context": "Similar to previous works (Kumar et al., 2010; Miller et al., 2012), the joint feature vectors \u03a8(x,y,h) and \u03a6(x,y,h) are defined using the hog descriptor (Dalal & Triggs, 2005; Felzenszwalb et al.", "startOffset": 26, "endOffset": 67}, {"referenceID": 10, "context": "Similar to previous works (Kumar et al., 2010; Miller et al., 2012), the joint feature vectors \u03a8(x,y,h) and \u03a6(x,y,h) are defined using the hog descriptor (Dalal & Triggs, 2005; Felzenszwalb et al.", "startOffset": 26, "endOffset": 67}, {"referenceID": 4, "context": ", 2012), the joint feature vectors \u03a8(x,y,h) and \u03a6(x,y,h) are defined using the hog descriptor (Dalal & Triggs, 2005; Felzenszwalb et al., 2008) extracted using the pixels of the bounding box.", "startOffset": 94, "endOffset": 143}, {"referenceID": 3, "context": "where O(h1,h2) \u2208 [0, 1] is the ratio of the area of the intersection and the area of the union of the two bounding boxes (Everingham et al., 2010).", "startOffset": 121, "endOffset": 146}, {"referenceID": 0, "context": "We note that a similar experimental setup was also used by Blaschko et al. (2010).", "startOffset": 59, "endOffset": 82}, {"referenceID": 7, "context": "We use images of 6 different mammals (approximately 45 images per mammal) that have been previously employed for image classification (Kumar et al., 2010; Miller et al., 2012).", "startOffset": 134, "endOffset": 175}, {"referenceID": 10, "context": "We use images of 6 different mammals (approximately 45 images per mammal) that have been previously employed for image classification (Kumar et al., 2010; Miller et al., 2012).", "startOffset": 134, "endOffset": 175}, {"referenceID": 9, "context": "The joint feature vectors are the Poselet descriptor (Maji et al., 2011) of the bounding box.", "startOffset": 53, "endOffset": 72}, {"referenceID": 4, "context": "We consider approximately 20 putative bounding boxes for each image, which are obtained automatically using a standard person detector (Felzenszwalb et al., 2008).", "startOffset": 135, "endOffset": 162}, {"referenceID": 3, "context": "We use the pascal voc 2011 \u2018trainval\u2019 dataset (Everingham et al., 2010), which consists of approximately 2500 images of 10 different action classes.", "startOffset": 46, "endOffset": 71}], "year": 2012, "abstractText": "We consider the problem of parameter estimation using weakly supervised datasets, where a training sample consists of the input and a partially specified annotation, which we refer to as the output. The missing information in the annotation is modeled using latent variables. Previous methods overburden a single distribution with two separate tasks: (i) modeling the uncertainty in the latent variables during training; and (ii) making accurate predictions for the output and the latent variables during testing. We propose a novel framework that separates the demands of the two tasks using two distributions: (i) a conditional distribution to model the uncertainty of the latent variables for a given input-output pair; and (ii) a delta distribution to predict the output and the latent variables for a given input. During learning, we encourage agreement between the two distributions by minimizing a loss-based dissimilarity coefficient. Our approach generalizes latent svm in two important ways: (i) it models the uncertainty over latent variables instead of relying on a pointwise estimate; and (ii) it allows the use of loss functions that depend on latent variables, which greatly increases its applicability. We demonstrate the efficacy of our approach on two challenging problems\u2014object detection and action detection\u2014using publicly available datasets.", "creator": "dvips(k) 5.99 Copyright 2010 Radical Eye Software"}}}