{"id": "1206.4637", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Learning to Identify Regular Expressions that Describe Email Campaigns", "abstract": "This paper addresses the problem of inferring a regular expression from a given set of strings that resembles, as closely as possible, the regular expression that a human expert would have written to identify the language. This is motivated by our goal of automating the task of postmasters of an email service who use regular expressions to describe and blacklist email spam campaigns. Training data contains batches of messages and corresponding regular expressions that an expert postmaster feels confident to blacklist. We model this task as a learning problem with structured output spaces and an appropriate loss function, derive a decoder and the resulting optimization problem, and a report on a case study conducted with an email service.", "histories": [["v1", "Mon, 18 Jun 2012 15:15:28 GMT  (542kb)", "http://arxiv.org/abs/1206.4637v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG cs.CL stat.ML", "authors": ["paul prasse", "christoph sawade", "niels landwehr", "tobias scheffer"], "accepted": true, "id": "1206.4637"}, "pdf": {"name": "1206.4637.pdf", "metadata": {"source": "META", "title": "Learning to Identify Regular Expressions that Describe Email Campaigns", "authors": ["Paul Prasse", "Christoph Sawade", "Niels Landwehr", "Tobias Scheffer"], "emails": ["prasse@cs.uni-potsdam.de", "sawade@cs.uni-potsdam.de", "landwehr@cs.uni-potsdam.de", "scheffer@cs.uni-potsdam.de"], "sections": [{"heading": "1. Introduction", "text": "Grammar is passed to nodes of a bot network, which generate messages by randomly instantiating the grammar. Email service providers can easily select elements of new email campaigns by collecting messages in spam traps or typing into known bot networks. If messages from multiple campaigns are collected in a common spam trap, clustering tools can reliably separate campaigns (Haider & Scheffer, 2009). However, likely cluster descriptions that use a sack-of-word representation are associated with the risk of false positives, and itAppearing at the 29th International Conference on Machine Learning, Edinburgh, UK, 2012. Copyright 2012 by the author (s) / owner (s).it is difficult for a person to determine whether they actually characterize the right amount of messages.Regular expressions."}, {"heading": "2. Regular Expressions", "text": "A regular expression is either a letter from an alphabet or a regular expression in which an operator is applied to one or more argumentation expressions."}, {"heading": "3. Problem Setting", "text": "Once we have established the syntax and semantics of regular expressions, we will now turn to the problem. An unknown distribution p (x, y) generates regular expressions y (x, y), which are elements of the language L (y). In our motivational application, the strings x are emails sampled by a bot network, and the y are regular expressions that an expert postmaster believes to identify the campaign template, and feels confident to detect the deviation of the presumption y from the presumption y for batch x. In our application, postmasters will not use an expression to blacklist the campaign unless they consider it to be comprehensible and neatly written, and believe that it is the campaign function."}, {"heading": "4. Identifying Regular Expressions", "text": "We model fw as a linear discriminant function wT\u0442 (x, y) for a common representation of the characteristics of the input x and the output y (Tsochantaridis et al., 2005): fw (x) = arg max y \u0441\u0441\u0442\u043e\u0441wT\u0442 (x, y). (5)"}, {"heading": "4.1. Joint Feature Representation", "text": "The common properties of a regular expression y are defined by properties that indicate a specific nesting of regular expression operators - for example, whether a concatenation occurs within a disjunction. Formally, we first define a binary vector (y) = Jy = y1. (ykK. Jy = y1.).ykK Jy = [y1.).yk] K Jy = y. \"yk\" My properties initially comprise a binary vector (y1? K + 1 K Jy = y1.).yk. \"K.\".jy \".\" yk. \"K\".jy \".S.\" S. \"S\" S \"S.\" S \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S \"S.\" S \"S\" S \"S.\" S \"S.\" S. \"S.\" S \"S\" S \"S.\" S \"S\" S \"S\" S \"S\" S \"S.\" S \"S\" S. \"S.\" S \"S.\" S \"S\" S \"S.\" S. \"S\" S. \"S\" S \"S\" S \"S\" S \"S.\" S. \"S\" S. \"S\" S \"S\" S. \"S.\" S \"S\" S \"S.\" S \"S\" S \"S.\" S \"S\" S \"S\" S \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S \"S\" S \"S.\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S.\" S \"S\" S \"S.\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S\" S \"S"}, {"heading": "4.2. Decoding", "text": "It is not only the way in which we move in the world, but also the way in which we move in the world, and the way in which we move in the world, in which we move in the world, in which we move in the world, in which we move in the world, in which we live in the world, in which we live in the world, in which we live in the world, in which we live in the world, in which we live in the world, in which we live in the world, in which we live in the world, in which we live in the world, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live, in which we live in which we live, in which we live, in which we live in which we live, in which we live in which we live, in which we live in which we live, in which we live in which we live, in which we live in which we live, in which we live in which we live, in which we live in which we live, in which we live in which we live in which we live, in which we live in which we live, in which we live in which we live, in which we live in which we live in which we live, in which we live in which we live, in which we live in which we live in which we live, we live in which we live in which we live, we live in which we live in which we live, in which we live in which we live in which we live, we live in which we live in which we live, in which we live in which we live in which we live, we live in which we live, we live in which we live in which we live, in which we live in which we live, we live in which we live in which we live, in which we live in which we live, we live in which we live in which we live,"}, {"heading": "4.3. Optimization Problem", "text": "We will now address the process of minimizing regularized risk defined in Equation 4. (...) We will now address the process of minimizing regularized risk defined in Equation 4. (...) We will address the loss (...) in Equation 4 (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (... (...) (...) (...) (... (...) (...) (...) (... (...) (...) (...) (... (...) (...) (...) (...) (... (...) (...) (...) (... (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...). (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (... (...) (...) (...) (...) (... (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...)"}, {"heading": "5. Case Study", "text": "We investigate whether postmasters accept the output of REx-SVM to blacklist mailing campaigns during the regular operation of a commercial email service, and evaluate how accurately REx-SVM and reference methods identify the extensions of mailing campaigns."}, {"heading": "5.1. Evaluation by Postmasters", "text": "REx-SVM is built on the ESP dataset, which contains 158 stacks of 12,763 e-mails and corresponding regular expressions collected by the e-mail service provider; the model is used; the user interface presents newly discovered stacks of spam e-mails along with the regular expression assumed by REx-SVM during the regular operation of the service to a postmaster; the postmaster is tasked with blacklisting campaigns using suitable regular expressions; during the study, the postmasters created 188 regular expressions, of which they generated 169 expressions (89%) by copying a substring of the automatically generated expression; we observe that postmasters prefer to describe only a portion of the message that they find characteristic of the campaign, while REx-SVM describes the entirety of the messages; in 12 cases, the postmasters edited the string (89%) by writing a substring of the message they found characteristic for the campaign, while REx-SVM describes the entirety of the messages."}, {"heading": "5.2. Spam Filtering Performance", "text": "We evaluate the ability of REx-SVM and Baselines to identify the exact extension of email campaigns. We use the arrangement of strings in X as a baseline. In addition, ReLIE (Li et al., 2008) searches for a regular expression that matches the emails in the input batch and does not match the additional negative examples by applying a set of transformation rules. We use the arrangement of the input batch as a starting point. ReLIE receives an additional 10,000 emails that are not part of each batch as negative data. An additional content-based filter used by the vendor is designed for several million spam and non-spam emails. To be able to measure false-positive rates, emails that are not part of a campaign are incorrectly included. We combine the ESP data with an additional 135,000 non-spam emails, including from the vendor."}, {"heading": "6. Related Work", "text": "Gold (1967) demonstrates that it is impossible to accurately identify a regular language from a finite number of positive examples. Our idea of minimizing an expected difference between presumption and target language through distribution of input strings reflects a more statistically inspired notion of learning. Also, in our problem definition, the learner has access to string pairs and corresponding regular expressions. Most work on regular language identification focuses on learning automatons (Denis, 2001; Clark & Thollard, 2004). While these problems are theoretically identical, converting generated automatons into regular expressions can lead to long-winded terms that are not suitable for human comprehension (Fernau, 2009). Some work focuses on limited classes, such as expressions in which each symbol occurs most of the time (Bex et al, 2008), disjunction-free expressions (Bra-zma, 1993), and disjunctions of disjunction-free expressions (Fernau, 2009)."}, {"heading": "7. Conclusions", "text": "In addition to the language identification paradigm, we present the problem of learning to map a set of strings to a regular target expression. Training data consists of stacks of strings and corresponding expressions. We formulate this problem as a learning problem with structured output spaces and construct a corresponding loss function. We derive the resulting optimization problem and design a decoder that seeks a space for specializing in maximum alignment. From our case study, we conclude that REx-SVM delivers a high true positive rate at a false positive rate that is more than an order of magnitude lower than that of a commercial content-based filter. The system is used by a commercial e-mail service provider and complements content-based and IP address-based filtering."}, {"heading": "Acknowledgments", "text": "This work was financed by a grant from STRATO AG."}, {"heading": "Bex, G., Gelade, W., Neven, F., and Vansummeren, S.", "text": "Learning deterministic regular expressions for drawing schema conclusions from XML data. In Proceeding of the International World Wide Web Conference, 2008."}, {"heading": "Bra\u0304zma, A. Efficient identification of regular expressions", "text": "from representative examples. In Proceedings of the Annual Conference on Computational Learning Theory, 1993.Cesa-Bianchi, N., Gentile, C., and Zaniboni, L. Incremental Algorithms for Hierarchical Classification. Machine Learning, 7: 31-54, 2006."}, {"heading": "Clark, A. and Thollard, F. Pac-learnability of probabilistic", "text": "Machine Learning Research, 5: 473-497, 2004.Denis, F. Learning regular languages from simple positive examples. Machine Learning, 44: 27-66, 2001.Dube, D. and Feeley, M. Efficient construction of a parse tree from a regular expression. Acta Informatica, 37 (2): 121- 144, 2000.Fernau, H. Algorithms for learning regular expressions from positive data. Information and Computation, 207 (4): 521-541, 2009.Gold, E. M. Border language identification. Information and control, 10: 447-474, 1967.Haider, P. and Scheffer, T. Bayesian clustering for email campaign detection. In Proceeding of the International Conference on Machine Learning, 2009.Hirschberg, D. A linear space algorithm for calculating maximum common sub-sequences. Communication of the ACM, 18 (6): 341-343, 1975."}, {"heading": "Li, Y., Krishnamurthy, R., Raghavan, S., Vaithyanathan,", "text": "S., and Jagadish, H. V. Regular expression learning for information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, 2008."}, {"heading": "Shalev-Shwartz, S., Singer, Y., Srebro, N., and Cotter, A.", "text": "Pegasos: Primarily Estimated Sub-Gradient Solver for svm. Mathematical Programming, 127 (1): 1-28, 2011.Tsochantaridis, I., Joachims, T., Hofmann, T., and Altun, Y. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 6: 1453-1484, 2005.Wang, L. and Jiang, T. On the complexity of multiple sequence alignment. Journal of Computational Biology, 1 (4): 337-348, 1994."}, {"heading": "Xie, Y., Yu, F., Achan, K., Panigrahy, R., Hulten, G., and", "text": "Osipkov, I. Spamming Botnets: Signatures and Properties. In Proceedings of the ACM SIGCOMM Conference, 2008."}], "references": [{"title": "Learning deterministic regular expressions for the inference of schemas from XML data", "author": ["G. Bex", "W. Gelade", "F. Neven", "S. Vansummeren"], "venue": "In Proceeding of the International World Wide Web Conference,", "citeRegEx": "Bex et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bex et al\\.", "year": 2008}, {"title": "Efficient identification of regular expressions from representative examples", "author": ["A. Br\u0101zma"], "venue": "In Proceedings of the Annual Conference on Computational Learning Theory,", "citeRegEx": "Br\u0101zma,? \\Q1993\\E", "shortCiteRegEx": "Br\u0101zma", "year": 1993}, {"title": "Incremental algorithms for hierarchical classification", "author": ["N. Cesa-Bianchi", "C. Gentile", "L. Zaniboni"], "venue": "Machine Learning,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2006}, {"title": "Pac-learnability of probabilistic deterministic finite state automata", "author": ["A. Clark", "F. Thollard"], "venue": "Machine Learning Research,", "citeRegEx": "Clark and Thollard,? \\Q2004\\E", "shortCiteRegEx": "Clark and Thollard", "year": 2004}, {"title": "Learning regular languages from simple positive examples", "author": ["F. Denis"], "venue": "Machine Learning,", "citeRegEx": "Denis,? \\Q2001\\E", "shortCiteRegEx": "Denis", "year": 2001}, {"title": "Efficiently building a parse tree from a regular expression", "author": ["D. Dub\u00e9", "M. Feeley"], "venue": "Acta Informatica,", "citeRegEx": "Dub\u00e9 and Feeley,? \\Q2000\\E", "shortCiteRegEx": "Dub\u00e9 and Feeley", "year": 2000}, {"title": "Algorithms for learning regular expressions from positive data", "author": ["H. Fernau"], "venue": "Information and Computation,", "citeRegEx": "Fernau,? \\Q2009\\E", "shortCiteRegEx": "Fernau", "year": 2009}, {"title": "Language identification in the limit", "author": ["E.M. Gold"], "venue": "Information and Control,", "citeRegEx": "Gold,? \\Q1967\\E", "shortCiteRegEx": "Gold", "year": 1967}, {"title": "Bayesian clustering for email campaign detection", "author": ["P. Haider", "T. Scheffer"], "venue": "In Proceeding of the International Conference on Machine Learning,", "citeRegEx": "Haider and Scheffer,? \\Q2009\\E", "shortCiteRegEx": "Haider and Scheffer", "year": 2009}, {"title": "A linear space algorithm for computing maximal common subsequences", "author": ["D. Hirschberg"], "venue": "Communications of the ACM,", "citeRegEx": "Hirschberg,? \\Q1975\\E", "shortCiteRegEx": "Hirschberg", "year": 1975}, {"title": "Regular expression learning for information extraction", "author": ["Y. Li", "R. Krishnamurthy", "S. Raghavan", "S. Vaithyanathan", "H.V. Jagadish"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Li et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Li et al\\.", "year": 2008}, {"title": "Pegasos: primal estimated sub-gradient solver for svm", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter"], "venue": "Mathematical Programming,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}, {"title": "Large margin methods for structured and interdependent output variables", "author": ["I. Tsochantaridis", "T. Joachims", "T. Hofmann", "Y. Altun"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Tsochantaridis et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2005}, {"title": "On the complexity of multiple sequence alignment", "author": ["L. Wang", "T. Jiang"], "venue": "Journal of Computational Biology,", "citeRegEx": "Wang and Jiang,? \\Q1994\\E", "shortCiteRegEx": "Wang and Jiang", "year": 1994}, {"title": "Spamming botnets: signatures and characteristics", "author": ["Y. Xie", "F. Yu", "K. Achan", "R. Panigrahy", "G. Hulten", "I. Osipkov"], "venue": "In Proceedings of the ACM SIGCOMM Conference,", "citeRegEx": "Xie et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Xie et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 12, "context": "We model fw as a linear discriminant function w\u03a8(x,y) for a joint feature representation of the input x and output y (Tsochantaridis et al., 2005):", "startOffset": 117, "endOffset": 146}, {"referenceID": 9, "context": "A maximal alignment of two strings can be determined efficiently using Hirschberg\u2019s algorithm (Hirschberg, 1975) which is an instance of dynamic programming.", "startOffset": 94, "endOffset": 112}, {"referenceID": 12, "context": "To obtain a convex optimization problem, we upper-bound the loss by its hinged version, following the margin-rescaling approach (Tsochantaridis et al., 2005):", "startOffset": 128, "endOffset": 157}, {"referenceID": 11, "context": "Hence, the solution is unique and can be found efficiently by cutting plane methods as Pegasos (Shalev-Shwartz et al., 2011) or SVM (Tsochantaridis et al.", "startOffset": 95, "endOffset": 124}, {"referenceID": 12, "context": ", 2011) or SVM (Tsochantaridis et al., 2005).", "startOffset": 15, "endOffset": 44}, {"referenceID": 10, "context": "In addition, ReLIE (Li et al., 2008) searches for a regular expression that matches the emails in the input batch and does not match any of the additional negative examples by applying a set of transformation rules; we use the alignment of the input batch as starting point.", "startOffset": 19, "endOffset": 36}, {"referenceID": 4, "context": "Most work of identification of regular languages focuses on learning automata (Denis, 2001; Clark & Thollard, 2004).", "startOffset": 78, "endOffset": 115}, {"referenceID": 6, "context": "While these problems are identical in theory, transforming generated automata into regular expressions can lead to lengthy terms that do not lend themselves to human comprehension (Fernau, 2009).", "startOffset": 180, "endOffset": 194}, {"referenceID": 0, "context": "Some work focuses on restricted classes, such as expressions in which each symbol occurs at most k times (Bex et al., 2008), disjunction-free expressions (Br\u0101zma, 1993), and disjunctions of left-aligned disjunction-free expressions (Fernau, 2009).", "startOffset": 105, "endOffset": 123}, {"referenceID": 1, "context": ", 2008), disjunction-free expressions (Br\u0101zma, 1993), and disjunctions of left-aligned disjunction-free expressions (Fernau, 2009).", "startOffset": 38, "endOffset": 52}, {"referenceID": 6, "context": ", 2008), disjunction-free expressions (Br\u0101zma, 1993), and disjunctions of left-aligned disjunction-free expressions (Fernau, 2009).", "startOffset": 116, "endOffset": 130}, {"referenceID": 10, "context": "The ReLIE-algorithm (Li et al., 2008) (used as a reference method in our experiments) learns regular expressions from positive and negative examples given an initial expression by applying a set of transformation rules as long as this improves the separation of positive and negative examples.", "startOffset": 20, "endOffset": 37}], "year": 2012, "abstractText": "This paper addresses the problem of inferring a regular expression from a given set of strings that resembles, as closely as possible, the regular expression that a human expert would have written to identify the language. This is motivated by our goal of automating the task of postmasters of an email service who use regular expressions to describe and blacklist email spam campaigns. Training data contains batches of messages and corresponding regular expressions that an expert postmaster feels confident to blacklist. We model this task as a learning problem with structured output spaces and an appropriate loss function, derive a decoder and the resulting optimization problem, and a report on a case study conducted with an email service.", "creator": "LaTeX with hyperref package"}}}