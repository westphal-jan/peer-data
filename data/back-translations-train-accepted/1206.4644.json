{"id": "1206.4644", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Groupwise Constrained Reconstruction for Subspace Clustering", "abstract": "Reconstruction based subspace clustering methods compute a self reconstruction matrix over the samples and use it for spectral clustering to obtain the final clustering result. Their success largely relies on the assumption that the underlying subspaces are independent, which, however, does not always hold in the applications with increasing number of subspaces. In this paper, we propose a novel reconstruction based subspace clustering model without making the subspace independence assumption. In our model, certain properties of the reconstruction matrix are explicitly characterized using the latent cluster indicators, and the affinity matrix used for spectral clustering can be directly built from the posterior of the latent cluster indicators instead of the reconstruction matrix. Experimental results on both synthetic and real-world datasets show that the proposed model can outperform the state-of-the-art methods.", "histories": [["v1", "Mon, 18 Jun 2012 15:19:22 GMT  (554kb)", "http://arxiv.org/abs/1206.4644v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["ruijiang li", "bin li", "cheng jin", "xiangyang xue"], "accepted": true, "id": "1206.4644"}, "pdf": {"name": "1206.4644.pdf", "metadata": {"source": "META", "title": "Groupwise Constrained Reconstruction for Subspace Clustering", "authors": ["Ruijiang Li", "Bin Li", "Ke Zhang", "Xiangyang Xue"], "emails": ["rjli@fudan.edu.cn", "bin.li-1@uts.edu.au", "k_zhang@fudan.edu.cn", "jc@fudan.edu.cn", "xyxue@fudan.edu.cn"], "sections": [{"heading": "1. Introduction", "text": "This year, it has reached the point where it will be able to draw on a wide range of investment strategies, \"he said.\" It is very important that we are able to develop a broad range of investment strategies, \"he said."}, {"heading": "2. Background", "text": "In this section we give a brief introduction to the earlier work on clustering in subspace."}, {"heading": "2.1. Non-Reconstruction Based", "text": "The final cluster result is achieved by using the factor matrix. These methods are not robust against noise and outliers and will fail if the sub-spaces are dependent; this approach makes fewer assumptions about the sub-spaces and success is guaranteed if certain conditions are fulfilled; the main problem with the algebraic approach is that the computational complexity is high (exponential in relation to the number of sub-spaces and their dimensions); this approach makes fewer assumptions about the sub-spaces and success is guaranteed if the sub-spaces are subordinated under certain conditions.The main problem with the algebraic approach is that the computational complexity is high (exponential in relation to the number of sub-spaces and their dimensions)."}, {"heading": "2.2. Reconstruction Based", "text": "Reconstruction-based methods usually consist of the following two steps: 1) Find a reconstruction for all samples, in the form that each sample is approximated by the weighted sum of the other samples in the dataset. (2) The optimization problem in Eq. (2) is solved to approximate the reconstruction weight matrix W.min W '(X \u2212 XW) + outlook (W) (2) s.t. wii = 0where the term l (\u00b7): RD \u00b7 N 7 \u2192 R measures the error by approximating xi with its reconstruction weight matrix W.min W' (X \u2212 XW). (\u00b7): RN \u00b7 N \u00b7 N 7 \u2192 R is used for regulation, and \u03c9 is a compromise parameter. 2) Applicable spectral cluster algorithm to obtain the final cluster problem result from the reconstruction weightW = i wjixj. (Usually, the reconstruction force W | is used in the norm weighting W | |"}, {"heading": "3. Groupwise Constrained Reconstruction Model", "text": "Consider a cluster task in which we want to group N samples designated by X = [x1, x2, \u00b7 \u00b7, xN] \u0433RD \u00b7 N, intoK cluster, where N is the number of samples, D is the sample dimensionality, and xi-RD is the i-th sample. Let z = [z1; z2; \u00b7; zN] be the cluster indicator vector, where zi-i {1, 2, \u00b7 \u00b7, K} indicates that the sample xi is taken from the zi-th cluster. The aim of cluster formation is to find the cluster indicators z, so that for each k-th sample {1, 2, \u00b7 \u00b7, K} the samples in the k-th cluster, i.e. {xi-zi = k} Ni = 1, lie in the same linear space. This goal is the quite1Nuclear standard."}, {"heading": "3.1. Model", "text": "Following the idea of reconstruction based on partial space clusters, the group-by-group limited reconstruction model (GCR) is mainly based on p (X | W) in Eq. (3) to quantify the reconstruction, p (X | W, \u03c3) = N = 1 N (xi | q) 6 = i wjixj, \u03c3 2 i) (3), where N (\u00b5, \u03a3) is the reconstruction error for the i-th sample and variance \u03a3, wji is the element in the j-th row, i-th column of matrixW, RN \u00b7 N \u00b7 N \u00b7 N \u00b7 N > 0 is a random variable measuring the reconstruction error for the i-th sample, and nel = [\u03c31], wji is the element in the j-th row, i-th column of matrixW \u00b7 RN. We place an inverse gamma mainly on the two models: p (2i) = IG."}, {"heading": "3.2. Obtaining the Final Clustering Result", "text": "We use the Gibbs sampling algorithm (MacKay, 2003) to approximate the posterior distribution q (z). In each epoch, the Gibbs sampler updates zi iteratively to a sample consisting of p (zi | z \u00b2 i, X) = p (z | X) p (z \u00b2 i | X) q (z \u00b2), where z \u00b2 i = {zj | j 6 = i}. Direct implementation results in the temporal complexity of O (N2D3) for each epoch. Fortunately, the complexity can be reduced to O (N2D + KD2) by updating the ranking 1. At the end of each epoch, we collect the values of all cluster indicators as a sample of z (N2D3)."}, {"heading": "3.3. When K \u2192 +\u221e", "text": "For this reason, we refer to the GCR model with K \u2192 + if each sample forms its own cluster. This strategy is analogous to the infinite Gaussian mixture model with the Dirichlet process (Rasmussen, 1999). For this reason, we refer to the GCR model with K \u2192 if each sample forms its own cluster. This strategy is analogous to the infinite Gaussian model with the Dirichlet process (Rasmussen, 1999). For this reason, we refer to the GCR model with K \u2192 + if each sample forms its own cluster. This strategy is analogous to the infinite Gaussian mixture model with the Dirichlet process (Rasmussen, 1999)."}, {"heading": "3.4. Hyperparameters", "text": "\u03b20: In the course of our experiment, \u03b20 is always set to 1, \u03bb and \u03bd for the Dirichlet distribution: From equation (4) we see that \u03bb and \u03bd control the reconstruction quality. In accordance with the property of the inverse gamma distribution, we have E (\u03c3 \u2212 1i) = 1 \u03bb and Var (\u03c3 \u2212 1i) = 2 \u03bb2\u03bd. Therefore, it makes sense to set a smaller number when the dataset is less loud, and to set a smaller number when the variance of the reconstruction quality for different samples is greater (e.g. the dataset has more outliers). In our experiments, these two parameters are matched to different datasets. \u03b1H and \u03b1L: According to Equation (5) \u03c32i \u03b1H and \u04452i \u03b1L directly influence the size of wji. Since E (2001 \u2212 1i) = 1 \u03bb, we can determine the size of wji and the distribution of wjin comparison with W (10v = 10p = 1 \u03bb)."}, {"heading": "4. Experimental Results", "text": "In this section, we compare our methods with the other three reconstruction-based cluster methods in the subspace: LRR (Liu et al., 2010), SSC (Elhamifar & Vidal, 2009) and SSQP (Wang et al., 2011). In our evaluation, the quality of cluster formation is measured by the accuracy calculated as the maximum percentage of agreement between the cluster result and the basic truth. For GCR, the MAP estimate is used directly as the final cluster result; for GCR-DP, we first calculate the probable affinity matrix according to Eq. (8), then we use NCut (Shi & Malik, 2000) to obtain the final cluster result. For MCMC, we treat G (0) = 1% (X + I) \u2212 1% (RN \u00d7 N) as the affinity matrix, and the result of spectral clustering is interpreted as initializability."}, {"heading": "4.1. Synthetic Datasets", "text": "We use synthetic data sets to investigate how these reconstruction-based methods work if the assumption of partial space independence mentioned in Section 1 is violated. Synthetic data containing K subspaces are generated as follows: 1) Generate a matrix B, R2 x 50, from which each column is drawn from a Gaussian distribution N (\u00b7 | 0, I2). 2) Generate y1-Rnk for the k-th cluster containing nk samples, whose elements are drawn to [\u2212 1, 1] regardless of the even distribution. Then, generate y2 = tan 16k17Ky1 (avoiding tan \u03c0 2). Finally, create the nk samples in the k-th cluster as [y1, y2] B and RnK \u00d7 50. All experiments are repeated here five times."}, {"heading": "4.1.1. Violation of Subspace Independence Assumption", "text": "For K = 2, 3, \u00b7 \u00b7 \u00b7, 8, we create 7 data sets according to the steps above. For these synthetic data sets, the l.h.s. of Equation (1) is 2, and the r.h.s. of Equation (1) is K. Thus, the degree of violation of the subareous independence assumption increases with increasing K. The results are reported in Figure 3 (a). As we can see, LRR and SSC perform well when the subareous independence assumption holds (K = 2) or is slightly violated (K = 3). However, their performance decreases significantly with increasing degree of violation, although their parameters are matched to different K. In contrast, GCR and GCR-DP are able to maintain high performance, although the degree of violation continues to increase. In the case of K = 8, we compare the affinity matrices generated by these reconstruction methods, as Figure 4 shows."}, {"heading": "4.1.2. Increasing Portion of Noisy Samples", "text": "Consider the case where samples exist that differ from the exact positions in the sub-spaces. Following the steps above, we create a data set with 2 sub-spaces, each containing 50 samples. We add Gaussian noises N (\u00b7 | 0, 3) to 0%, 5%, \u00b7 \u00b7 \u00b7, 40% of the samples. The results of the 9 data sets are shown in Figure 3 (b).The results show that our methods and LRR are able to maintain a high accuracy, although a large proportion of the samples deviate from their ideal position.The success of LRR is based on the L2,1 standard, which is used for the loss date in the equation. (2) While the success of GCR and GCR-DP can be based on the model in which each sample has its own parameter \u03c3i to measure the reconstruction error. SSC performs less well and its performance remains acceptable if the noise level is low."}, {"heading": "4.2. Hopkins 155 Dataset", "text": "We evaluate our models on the basis of the Hopkins 155 motion dataset, which consists of 155 sequences, each containing the coordinates of about 39 \u2212 550 points of 2 or 3 movements. The task is to group the points into clusters according to their movements for each sequence. Since the coordinates of the points from a single motion are in an affine subspace with dimensionality of no more than 4 (Elhamifar & Vidal, 2009), we project the coordinates in each sequence with PCA into 4r dimensions, where r is the number of movements in the sequence, and then add 1 as the last dimension of each sample.The results are presented in Table 1. This dataset contains a small number of latent subspaces, and the results of the compared methods do not differ significantly."}, {"heading": "4.3. MSRC Dataset", "text": "In the MSRC dataset, 591 images are provided with manually labeled image segmentation results (each region receives a label, and there are 23 labels in total). In the following (Cheng et al., 2011), we group for each image the superpixels, which are small spots in an over-segmented result, using cluster methods in the subspace. The basic truth (cluster label) for a superpixel is given as the label of the region to which it belongs. In our experiment, 100 superpixels are extracted for each image using the method described in (Mori et al., 2004), and each superpixel is represented with the RGB color histogram characteristic of dimensionality 768. We discard all superpixels with the label \"background\" and then discard the images that contain only one label. Finally, we get 459 images. For each image, the average number of superpixels is 91.3, and the number of clusters range from 95% to 6. We use this three-dimensional S method."}, {"heading": "4.4. Human Face Dataset", "text": "This database contains 2414 cropped frontal facial images of 38 subjects under different illumination, and the grouping of these images can be treated as a cluster problem, since in (Ho et al., 2003) it is shown that the images for a fixed face under different illumination can be modelled approximately with a low-dimensional subspace. To evaluate the performance of all these methods, we form 7 tasks, each of which contains the images of randomly selected subjects {3, 4, \u00b7 \u00b7, 9}. We reduce the images to 42 x 48 and then use PCA to reduce the dimensionality of the raw characteristics to 30. We repeat the experiment five times and show the results in Figure 5. The performance of GCR and GCR-DP is better than the other three methods. In particular, with the number of sub-spaces that increase the discrepancy between the l.h.s. and Qrs., the spaces (SSR) increase as a result, the figure (SGB) and the figure (SGB) of the figure (1) and the figure (SGB) decrease."}, {"heading": "5. Conclusion and Discussion", "text": "Compared to other reconstruction-based methods, our models are no longer based on the assumption of subspace independence, which is usually violated in applications where the number of subspaces continues to increase. Based on the synthetic data sets, we show that existing reconstruction-based methods suffer from the violation of the subspace independence assumption, while the affinity matrix generated by our model, which is composed of the base of the latent cluster indicators, is more sophisticated and more discriminatory in the discovery of the latent clusters. On the three real data sets, our methods show promising results. Besides the problem of clustering in subspaces, the idea of group-based constraints can also be applied to other problems related to graph construction. For example, in semi-supervised learning (SSL) the constraints can be modified so that a sample can only be reconstructed by its neighbors in the euposterior structure."}, {"heading": "Acknowledgements", "text": "This work was partially supported by the 973 Program (2010CB327906), the Shanghai Leading Academic Discipline Project (B114), the PhD Fund of the Chinese Ministry of Education (20100071120033) and the Shanghai Municipal F & D Foundation (08dz1500109). Bin Li thanks UTS Early Career Researcher Grants."}], "references": [{"title": "Multi-task low-rank affinity pursuit for image segmentation", "author": ["B. Cheng", "G. Liu", "J. Wang", "Z. Huang", "S. Yan"], "venue": "In ICCV,", "citeRegEx": "Cheng et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cheng et al\\.", "year": 2011}, {"title": "A multibody factorization method for independently moving objects", "author": ["J.P. Costeira", "T. Kanade"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Costeira and Kanade,? \\Q1998\\E", "shortCiteRegEx": "Costeira and Kanade", "year": 1998}, {"title": "Sparse subspace clustering", "author": ["E. Elhamifar", "R. Vidal"], "venue": "In CVPR, pp", "citeRegEx": "Elhamifar and Vidal,? \\Q2009\\E", "shortCiteRegEx": "Elhamifar and Vidal", "year": 2009}, {"title": "Approaches for bayesian variable selection", "author": ["E.I. George", "R.E. Mcculloch"], "venue": "Statistica Sinica, pp", "citeRegEx": "George and Mcculloch,? \\Q1997\\E", "shortCiteRegEx": "George and Mcculloch", "year": 1997}, {"title": "From few to many: Illumination cone models for face recognition under variable lighting and pose", "author": ["A.S. Georghiades", "P.N. Belhumeur", "D.J. Kriegman"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Georghiades et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Georghiades et al\\.", "year": 2001}, {"title": "Motion segmentation by subspace separation and model selection", "author": ["K. Kanatani"], "venue": "In ICCV, pp", "citeRegEx": "Kanatani,? \\Q2001\\E", "shortCiteRegEx": "Kanatani", "year": 2001}, {"title": "Robust subspace segmentation by low-rank representation", "author": ["G. Liu", "Z. Lin", "Y. Yu"], "venue": "In ICML, pp", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Segmentation of multivariate mixed data via lossy data coding and compression", "author": ["Y. Ma", "H. Derksen", "W. Hong", "J. Wright"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Ma et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2007}, {"title": "Information theory, inference, and learning algorithms", "author": ["D.J.C. MacKay"], "venue": null, "citeRegEx": "MacKay,? \\Q2003\\E", "shortCiteRegEx": "MacKay", "year": 2003}, {"title": "Recovering human body configurations: Combining segmentation and recognition", "author": ["G. Mori", "X. Ren", "A.A. Efros", "J. Malik"], "venue": "In CVPR", "citeRegEx": "Mori et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Mori et al\\.", "year": 2004}, {"title": "Robust algebraic segmentation of mixed rigid-body and planar motions from two views", "author": ["S. Rao", "A.Y. Yang", "S. Sastry", "Y. Ma"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Rao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rao et al\\.", "year": 2010}, {"title": "The infinite gaussian mixture model", "author": ["C.E. Rasmussen"], "venue": "In NIPS, pp", "citeRegEx": "Rasmussen,? \\Q1999\\E", "shortCiteRegEx": "Rasmussen", "year": 1999}, {"title": "Nonlinear dimensionality reduction by locally linear embedding", "author": ["S.T. Roweis", "L.K. Saul"], "venue": null, "citeRegEx": "Roweis and Saul,? \\Q2000\\E", "shortCiteRegEx": "Roweis and Saul", "year": 2000}, {"title": "Normalized cuts and image segmentation", "author": ["J. Shi", "J. Malik"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Shi and Malik,? \\Q2000\\E", "shortCiteRegEx": "Shi and Malik", "year": 2000}, {"title": "Mixtures of probabilistic principal component analyzers", "author": ["M.E. Tipping", "C.M. Bishop"], "venue": "Neural computation,", "citeRegEx": "Tipping and Bishop,? \\Q1999\\E", "shortCiteRegEx": "Tipping and Bishop", "year": 1999}, {"title": "Motion segmentation with missing data using powerfactorization and gpca", "author": ["R. Vidal", "R.I. Hartley"], "venue": "In CVPR", "citeRegEx": "Vidal and Hartley,? \\Q2004\\E", "shortCiteRegEx": "Vidal and Hartley", "year": 2004}, {"title": "Generalized principal component analysis (gpca)", "author": ["R. Vidal", "Ma", "Yi", "S. Sastry"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Vidal et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Vidal et al\\.", "year": 2005}, {"title": "Efficient subspace segmentation via quadratic programming", "author": ["S. Wang", "X. Yuan", "T. Yao", "S. Yan", "J. Shen"], "venue": "In AAAI,", "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Discriminative k-means for clustering", "author": ["J. Ye", "Z. Zhao", "M. Wu"], "venue": "In NIPS,", "citeRegEx": "Ye et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ye et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 5, "context": "In the last decade, a number of subspace clustering methods have been proposed with successful applications in the areas including motion segmentation (Kanatani, 2001; Vidal & Hartley, 2004; Elhamifar & Vidal, 2009), image clustering under different illuminations (Ho et al.", "startOffset": 151, "endOffset": 215}, {"referenceID": 6, "context": "based, algebraic based, statistically modelling, and reconstruction based, among which the reconstruction based approach has been proved most effective and has drawn much attention recently (Elhamifar & Vidal, 2009; Liu et al., 2010; Wang et al., 2011).", "startOffset": 190, "endOffset": 252}, {"referenceID": 17, "context": "based, algebraic based, statistically modelling, and reconstruction based, among which the reconstruction based approach has been proved most effective and has drawn much attention recently (Elhamifar & Vidal, 2009; Liu et al., 2010; Wang et al., 2011).", "startOffset": 190, "endOffset": 252}, {"referenceID": 5, "context": "Matrix factorization based methods Costeira & Kanade (1998); Kanatani (2001) approximate the data matrix with the product of two matrices, one containing the bases and the other containing the factors.", "startOffset": 61, "endOffset": 77}, {"referenceID": 16, "context": "The algebraic based General Principle Component Analysis (GPCA) (Vidal et al., 2005) fits the samples with a polynomial, with the gradient of a point orthogonal to the subspace containing it.", "startOffset": 64, "endOffset": 84}, {"referenceID": 10, "context": "In (Rao et al., 2010), Robust Algebraic Segmentation (RAS) is proposed to handle the data with outliers, but the complexity issue still remains.", "startOffset": 3, "endOffset": 21}, {"referenceID": 7, "context": "Agglomerative Lossy Compression (ALC) (Ma et al., 2007) searches the latent subspaces by minimizing an objective containing certain information criteria with an agglomerative strategy.", "startOffset": 38, "endOffset": 55}, {"referenceID": 6, "context": "In Low-Rank Representation (LRR) (Liu et al., 2010), nuclear norm \u2016W \u2016\u2217 is used to encourage W to have a low rank structure1, and l2,1 norm is used as the `(\u00b7) term in Eq.", "startOffset": 33, "endOffset": 51}, {"referenceID": 17, "context": "In SSQP (Wang et al., 2011), the authors choose \u03a9(W ) = \u2225\u2225W>W\u2225\u2225 1 , meanwhile force W to be non-negative.", "startOffset": 8, "endOffset": 27}, {"referenceID": 18, "context": "different from the objective of traditional clustering methods, in which the variance of inter-cluster samples are minimized, such as K-means; or the \u201cdifference\u201d of clusters are maximized, such as Discriminative Clustering (Ye et al., 2007).", "startOffset": 224, "endOffset": 241}, {"referenceID": 8, "context": "We use the Gibbs Sampling algorithm (MacKay, 2003) to approximate the posterior distribution q(z).", "startOffset": 36, "endOffset": 50}, {"referenceID": 11, "context": "This strategy is in analogy with the Infinite Gaussian Mixture Model with Dirichlet Process (Rasmussen, 1999).", "startOffset": 92, "endOffset": 109}, {"referenceID": 6, "context": "In this section, we compare our methods with the other three reconstruction based subspace clustering methods: LRR (Liu et al., 2010), SSC (Elhamifar & Vidal, 2009) and SSQP (Wang et al.", "startOffset": 115, "endOffset": 133}, {"referenceID": 17, "context": ", 2010), SSC (Elhamifar & Vidal, 2009) and SSQP (Wang et al., 2011).", "startOffset": 48, "endOffset": 67}, {"referenceID": 0, "context": "Following (Cheng et al., 2011), for each image, we group the superpixels, which are small patches in an over-segmented result, with subspace clustering methods.", "startOffset": 10, "endOffset": 30}, {"referenceID": 9, "context": "In our experiment, 100 superpixels are extracted for each image with the method described in (Mori et al., 2004), and each superpixel is represented with the RGB Color Histogram feature of dimensionality 768.", "startOffset": 93, "endOffset": 112}, {"referenceID": 4, "context": "We also evaluate our method on the Extended Yale Database B (Georghiades et al., 2001).", "startOffset": 60, "endOffset": 86}], "year": 2012, "abstractText": "Reconstruction based subspace clustering methods compute a self reconstruction matrix over the samples and use it for spectral clustering to obtain the final clustering result. Their success largely relies on the assumption that the underlying subspaces are independent, which, however, does not always hold in the applications with increasing number of subspaces. In this paper, we propose a novel reconstruction based subspace clustering model without making the subspace independence assumption. In our model, certain properties of the reconstruction matrix are explicitly characterized using the latent cluster indicators, and the affinity matrix used for spectral clustering can be directly built from the posterior of the latent cluster indicators instead of the reconstruction matrix. Experimental results on both synthetic and realworld datasets show that the proposed model can outperform the state-of-the-art methods.", "creator": "LaTeX with hyperref package"}}}