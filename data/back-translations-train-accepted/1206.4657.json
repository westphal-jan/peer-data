{"id": "1206.4657", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Projection-free Online Learning", "abstract": "The computational bottleneck in applying online learning to massive data sets is usually the projection step. We present efficient online learning algorithms that eschew projections in favor of much more efficient linear optimization steps using the Frank-Wolfe technique. We obtain a range of regret bounds for online convex optimization, with better bounds for specific cases such as stochastic online smooth convex optimization.", "histories": [["v1", "Mon, 18 Jun 2012 15:26:34 GMT  (359kb)", "http://arxiv.org/abs/1206.4657v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["elad hazan", "satyen kale"], "accepted": true, "id": "1206.4657"}, "pdf": {"name": "1206.4657.pdf", "metadata": {"source": "META", "title": "Projection-free Online Learning", "authors": ["Elad Hazan", "Satyen Kale"], "emails": ["ehazan@ie.technion.ac.il", "sckale@us.ibm.com"], "sections": [{"heading": null, "text": "In addition to the computational advantage, other desirable features of our algorithms are that they are parameter-free in stochastic cases and produce sparse decisions. We apply our algorithms to computationally intensive collaborative filtering applications and show the theoretical improvements clearly visible on standard data sets."}, {"heading": "1. Introduction", "text": "In fact, most of them are able to reform themselves in the way that they do it: in the way that they do it, in the way that they do it, in the way that they do it, in the way that they do it, in the way that they do it."}, {"heading": "1.1. Some Appropriate Convex Domains", "text": "In several interesting online learning scenarios, the underlying decision-makers are not classified as \"practically efficient.\" We have listed several interesting examples of such decision sets below. The number of matrices with limited trace standard is a common basis for decision-making for applications such as matrix complexity and collaborative filtering. For example, the number of matrices in the matrix standard is limited by some parameters. Calculation of the projection of a matrix X requires the calculation of O (nm2) time in the general adoption of M (n).Linear optimizations with respect to the calculation of individuals in the matrix-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-norm-"}, {"heading": "1.2. Discussion of Main Result", "text": "Our main conclusion is that assuming that it is possible to do linear optimization over the convex domain efficiently, we can obtain good algorithms (in the sense of sublinear regret) for online convex optimization over the domain by using an online version of the classic Frank & Wolfe algorithm (Frank & Wolfe, 1956).The above statement needs clarification: Zinkevich (2003) shows (via his online gradient descent algorithm) that it is possible to do online convex optimization by solving a square program over the domain per step. Since square optimization at least does not require any of which we are aware, except (Sanyal et al., 2011) for the specific case of 3 dimensions. reduced to a polynomial number of linear optimizations over the ellipsoid algorithm, we can perform online convex optimization."}, {"heading": "1.3. Related Work", "text": "The work closest to us is that of Kalai & Vempala (2005): they provide an algorithm (previously considered by Hannan (1957)) for linear online optimization that performs a linear optimization over the decision determined in each iteration; the striking feature of their work is that they are able to show optimal O (\u221a T) limits even for adverse costs, although the limitation of their work is that the algorithm works specifically for linear cost functions only; they also provide lazy versions of their algorithm by carefully correlating the randomness of iteration to iteration; in comparison, our algorithm has a very natural lazy implementation (simply replace the previous decision point with a new one with an explicitly specified probability) that we believe is much simpler; our results build on the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), which have the function of a single-wool excise and a friction-free function."}, {"heading": "2. Preliminaries", "text": "We assume that it is possible to minimize a linear function, vice-versa. The problem of interest is the online convector optimization (see the overview of Hazan (2011) for more details). (See the overview of Hazan (2011). (See the overview of Hazan (2011) for more details.) Iterative in each round t = 1, 2,...., T a learner is obliged to produce a point xt of a convex, compact quantity K-Rn. (Regret: = 1), an opponent produces a convex cost function ft: K-R, and the learner suffers the cost (xt). The goal of the learner is to produce points xt, so that the Regret: = 1 ft (xt) -K-Rn (xt) -K-Rx-R), is sublinear in T. If the cost functions are stochastical, the regret is possible using the expected cost function f = E [instead of] the actual cost function we assume that it is measured by K and D."}, {"heading": "3. Algorithm and Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Algorithm.", "text": "Algorithm 1 Online Frank-Wolfe (OFW) 1: Input parameter: constant a \u2265 0. 2: Initialize arbitrary x1. 3: for t = 1, 2,..., T do 4: Play text and ft. 5: Ft = 1 t \u2211 t \u03c4 = 1f\u03c4. 6: Calculation vt \u2190 arg minx \u0445 K {ced Ft (xt) \u00b7 x}. 7: Text + 1 = (1 \u2212 t \u2212 a) xt + t \u2212 avt. 8: End for"}, {"heading": "3.2. Analysis.", "text": "Define \u2206 t = Ft (xt) \u2212 Ft (x \u0445 t), where the limits of regret all result from the following general proposition: Theorem 3.1. Suppose that for t = 1, 2,..., T the function ft is strongly convex for some constants b = 1, 1 / 2 and B \u2265 0 L-Lipschitz, Bt \u2212 b-smooth and for some constants b = 1, 1 / 2 and St \u2212 s. Then, in the algorithm we have 1 for all t \u2264 Ct \u2212 d, for the two following values of C and d: (C, d) = (max {9D2B, 3LD}, 1 + b2) and (C, d) = (max {9D2B, 362 / Lb}, L3 + L3)."}, {"heading": "In either case, this bound is obtained by setting a =", "text": "d \u2212 b in algorithm 1.Proof. First, we find that d \u2264 1 and a \u2264 0 are in both cases since b (\u2212 1, 1 / 2] and s since b (\u2212 1, 1), so that t \u2212 \u2212 a (0, 1) and thus all iterates are in K. We prove the problem by inducing t to both values of C and d. So the statement applies to t = 1 since f1 is L-Lipschitz, so that C \u2212 LD (x1 \u2212 x) 1 (x1) \u2212 f1 (x) = 1 (x). So we assume that for some t (x1), for some t (x1), not (x2) and not (x2) we do not (x2)."}, {"heading": "4. Regret Bounds", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Stochastic Costs", "text": "Now suppose that the cost functions ft i.i.d. are sampled from an unknown distribution, and leave f \u0445 = E [ft] and leave x \u0445 = arg minx \u0445 K f \u043a (x)."}, {"heading": "4.1.1. Smooth Stochastic Costs", "text": "Theorem 4.1. For \u03b2-smooth stochastic convex loss functions ft there is an algorithm, so that with probability at least 1 \u2212 \u03b4 its regret is limited as follows: \u2211 Tt = 1f-convex loss functions ft, so that the algorithm can be applied to functions ft with the parameter settings that we now specify. Firstly, ft is \u03b2-smooth, so that we can set B = \u03b2 and b = 0. Since we do not make assumptions about the strong convexity of ft, we can set S = 0 and s = 0. For these settings, the optimal values are d = 1 + b2 = 1 / 2, a = d \u2212 b = impexe probability, and C = max \u2212 impexe, and s = 0."}, {"heading": "4.1.2. Non-smooth Stochastic Costs", "text": "Theorem 4,3. For non-smooth stochastic convex loss functions ft, there is such an algorithm with a probability of at least 1 \u2212 \u03b4, its regret is limited as follows: View Tt = 1f - (xt) \u2212 f * (x *) = O (\u221a nLDT 2 / 3 + LD - nT log (T). Proof. For non-smooth stochastic loss functions ft, the algorithm is applied to the \"calming\" of ft, i.e. the functions f \u00b2 t, \u03b4t for \u0441t = \u221a nDt \u2212 1 / 3. The function f \u00b2 t, \u03b4t is nL \u00b2 t = (\u221a nL / D) t1 / 3smooth, i.e. B = nL / D and b = \u2212 1 / 3. Since we make assumptions about the strong convexity of f \u00b2 t, we can use S = 0, and s = 0."}, {"heading": "4.2. Adversarial Cost Functions", "text": "For all x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "5. Experiments", "text": "It is about the question of whether and to what extent it is about a way and a way in which it is about a way and a way in which it is about, in which it is about the question, whether and to what extent it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way and a way in which it is about a way"}, {"heading": "6. Conclusions and Open Problems", "text": "In this paper, we have presented an efficient algorithmic scheme for online convex optimization that performs a linear optimization per iteration instead of a square optimization. Advantages over traditional gradient descent techniques are speed of implementation, parameter independence, explicit sample scheme for iteration, sparseness, and natural laziness in implementation. The disadvantage is that the detectable limits of regret are not always optimal. The big open problem is to improve the limits of regret or to show lower limits on the number of linear optimizations needed to achieve optimal regret with just one linear optimization operation per iteration."}], "references": [{"title": "Online linear optimization and adaptive routing", "author": ["B. Awerbuch", "R.D. Kleinberg"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Awerbuch and Kleinberg,? \\Q2008\\E", "shortCiteRegEx": "Awerbuch and Kleinberg", "year": 2008}, {"title": "Exact matrix completion via convex optimization", "author": ["E. Candes", "B. Recht"], "venue": "Foundations of Computational Mathematics,", "citeRegEx": "Candes and Recht,? \\Q2009\\E", "shortCiteRegEx": "Candes and Recht", "year": 2009}, {"title": "Coresets, sparse greedy approximation, and the Frank-Wolfe algorithm", "author": ["K.L. Clarkson"], "venue": "ACM Trans. Algorithms,", "citeRegEx": "Clarkson,? \\Q2010\\E", "shortCiteRegEx": "Clarkson", "year": 2010}, {"title": "Online convex optimization in the bandit setting: gradient descent without a gradient", "author": ["A. Flaxman", "A.T. Kalai", "H.B. McMahan"], "venue": "In SODA,", "citeRegEx": "Flaxman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Flaxman et al\\.", "year": 2005}, {"title": "An algorithm for quadratic programming", "author": ["M. Frank", "P. Wolfe"], "venue": "Naval Research Logistics Quarterly,", "citeRegEx": "Frank and Wolfe,? \\Q1956\\E", "shortCiteRegEx": "Frank and Wolfe", "year": 1956}, {"title": "Eigentaste: A constant time collaborative filtering algorithm", "author": ["K.Y. Goldberg", "T. Roeder", "D. Gupta", "C. Perkins"], "venue": "Inf. Retr.,", "citeRegEx": "Goldberg et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2001}, {"title": "Approximation to bayes risk in repeated play", "author": ["J. Hannan"], "venue": "Contributions to the Theory of Games, III: 97\u2013139,", "citeRegEx": "Hannan,? \\Q1957\\E", "shortCiteRegEx": "Hannan", "year": 1957}, {"title": "Sparse approximate solutions to semidefinite programs", "author": ["E. Hazan"], "venue": "In LATIN, pp", "citeRegEx": "Hazan,? \\Q2008\\E", "shortCiteRegEx": "Hazan", "year": 2008}, {"title": "The convex optimization approach to regret minimization", "author": ["E. Hazan"], "venue": "Optimization for machine learning,", "citeRegEx": "Hazan,? \\Q2011\\E", "shortCiteRegEx": "Hazan", "year": 2011}, {"title": "Learning rotations with little regret", "author": ["E. Hazan", "S. Kale", "M.K. Warmuth"], "venue": "In COLT, pp", "citeRegEx": "Hazan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2010}, {"title": "Convex optimization without projection", "author": ["M. Jaggi"], "venue": "steps. CoRR,", "citeRegEx": "Jaggi,? \\Q2011\\E", "shortCiteRegEx": "Jaggi", "year": 2011}, {"title": "A simple algorithm for nuclear norm regularized problems", "author": ["M. Jaggi", "M. Sulovsk\u00fd"], "venue": "In ICML, pp", "citeRegEx": "Jaggi and Sulovsk\u00fd,? \\Q2010\\E", "shortCiteRegEx": "Jaggi and Sulovsk\u00fd", "year": 2010}, {"title": "Efficient algorithms for online decision problems", "author": ["A. Kalai", "S. Vempala"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Kalai and Vempala,? \\Q2005\\E", "shortCiteRegEx": "Kalai and Vempala", "year": 2005}, {"title": "Practical large-scale optimization for max-norm regularization", "author": ["J. Lee", "B. Recht", "R. Salakhutdinov", "N. Srebro", "J.A. Tropp"], "venue": "In NIPS, pp", "citeRegEx": "Lee et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2010}, {"title": "Faster parametric submodular function minimization algorithm and applications", "author": ["K. Nagano"], "venue": "Mathematical Engineering Technical Reports,", "citeRegEx": "Nagano,? \\Q2007\\E", "shortCiteRegEx": "Nagano", "year": 2007}, {"title": "Collaborative filtering in a non-uniform world: Learning with the weighted trace norm", "author": ["R. Salakhutdinov", "N. Srebro"], "venue": "In NIPS,", "citeRegEx": "Salakhutdinov and Srebro,? \\Q2010\\E", "shortCiteRegEx": "Salakhutdinov and Srebro", "year": 2010}, {"title": "Stochastic convex optimization", "author": ["S. Shalev-Shwartz", "O. Shamir", "N. Srebro", "K. Sridharan"], "venue": "In COLT,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2009}, {"title": "Collaborative filtering with the trace norm: Learning, bounding, and transducing", "author": ["O. Shamir", "S. Shalev-Shwartz"], "venue": "JMLR - Proceedings Track,", "citeRegEx": "Shamir and Shalev.Shwartz,? \\Q2011\\E", "shortCiteRegEx": "Shamir and Shalev.Shwartz", "year": 2011}, {"title": "Smoothness, low noise and fast rates", "author": ["N. Srebro", "K. Sridharan", "A. Tewari"], "venue": "In NIPS, pp", "citeRegEx": "Srebro et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2010}, {"title": "Problem 65-1, a least squares estimate of satellite attitude", "author": ["G. Wahba"], "venue": "SIAM Review,", "citeRegEx": "Wahba,? \\Q1965\\E", "shortCiteRegEx": "Wahba", "year": 1965}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["M. Zinkevich"], "venue": "In ICML, pp", "citeRegEx": "Zinkevich,? \\Q2003\\E", "shortCiteRegEx": "Zinkevich", "year": 2003}], "referenceMentions": [{"referenceID": 20, "context": "Within this paradigm, the Online Gradient Descent algorithm of Zinkevich (2003), and its close cousin Stochastic Gradient Descent, have been successfully applied to many problems in theory and practice.", "startOffset": 63, "endOffset": 80}, {"referenceID": 14, "context": "Computing a projection on K is therefore a difficult operation (although polynomial time, see (Nagano, 2007)).", "startOffset": 94, "endOffset": 108}, {"referenceID": 9, "context": "This set K arises in the online learning of rotations problem (Hazan et al., 2010).", "startOffset": 62, "endOffset": 82}, {"referenceID": 19, "context": "However, linear optimization on K is a classic problem known as Wahba\u2019s problem (Wahba, 1965), and can be solved using one singular value decomposition.", "startOffset": 80, "endOffset": 93}, {"referenceID": 11, "context": "Computing a projection on K is therefore a difficult operation (although polynomial time, see (Nagano, 2007)). Linear optimization over K is very easy however: there is a simple greedy algorithm (see, e.g. Schrijver (2003)), amounting to sorting the coordinates of the objective vector, which solves it in O(n log(n)) time.", "startOffset": 95, "endOffset": 223}, {"referenceID": 20, "context": "The above statement needs clarification: Zinkevich (2003) shows (via his Online Gradient Descent algorithm) that it is possible to do online convex optimization solving one quadratic program over the domain per step.", "startOffset": 41, "endOffset": 58}, {"referenceID": 6, "context": "They give an algorithm (previously considered by Hannan (1957)) for online linear optimization which performs one linear optimization over the decision set in each iteration.", "startOffset": 49, "endOffset": 63}, {"referenceID": 2, "context": "Our results build upon the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), who worked out the Frank-Wolfe technique for the problem of minimizing a single, static smooth convex cost function over a convex domain.", "startOffset": 35, "endOffset": 51}, {"referenceID": 2, "context": "Our results build upon the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), who worked out the Frank-Wolfe technique for the problem of minimizing a single, static smooth convex cost function over a convex domain.", "startOffset": 35, "endOffset": 65}, {"referenceID": 2, "context": "Our results build upon the work of Clarkson (2010), Hazan (2008) and Jaggi (2011), who worked out the Frank-Wolfe technique for the problem of minimizing a single, static smooth convex cost function over a convex domain.", "startOffset": 35, "endOffset": 82}, {"referenceID": 7, "context": "The problem of interest is online convex optimization (see the survey of Hazan (2011) for more details).", "startOffset": 73, "endOffset": 86}, {"referenceID": 3, "context": "(Flaxman et al., 2005)) be:", "startOffset": 0, "endOffset": 22}, {"referenceID": 16, "context": "In (Shalev-Shwartz et al., 2009), Theorem 5, the following is proved:", "startOffset": 3, "endOffset": 32}, {"referenceID": 10, "context": "Candes & Recht (2009), Jaggi & Sulovsk\u00fd (2010), Srebro et al.", "startOffset": 23, "endOffset": 47}, {"referenceID": 10, "context": "Candes & Recht (2009), Jaggi & Sulovsk\u00fd (2010), Srebro et al. (2010),", "startOffset": 23, "endOffset": 69}, {"referenceID": 5, "context": "Jester1 (Goldberg et al., 2001): first 100000 ratings in [\u221210, 10] by 24983 users on 100 jokes.", "startOffset": 8, "endOffset": 31}], "year": 2012, "abstractText": "The computational bottleneck in applying online learning to massive data sets is usually the projection step. We present efficient online learning algorithms that eschew projections in favor of much more efficient linear optimization steps using the Frank-Wolfe technique. We obtain a range of regret bounds for online convex optimization, with better bounds for specific cases such as stochastic online smooth convex optimization. Besides the computational advantage, other desirable features of our algorithms are that they are parameter-free in the stochastic case and produce sparse decisions. We apply our algorithms to computationally intensive applications of collaborative filtering, and show the theoretical improvements to be clearly visible on standard datasets.", "creator": "LaTeX with hyperref package"}}}