{"id": "1206.4681", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "LPQP for MAP: Putting LP Solvers to Better Use", "abstract": "MAP inference for general energy functions remains a challenging problem. While most efforts are channeled towards improving the linear programming (LP) based relaxation, this work is motivated by the quadratic programming (QP) relaxation. We propose a novel MAP relaxation that penalizes the Kullback-Leibler divergence between the LP pairwise auxiliary variables, and QP equivalent terms given by the product of the unaries. We develop two efficient algorithms based on variants of this relaxation. The algorithms minimize the non-convex objective using belief propagation and dual decomposition as building blocks. Experiments on synthetic and real-world data show that the solutions returned by our algorithms substantially improve over the LP relaxation.", "histories": [["v1", "Mon, 18 Jun 2012 15:40:11 GMT  (409kb)", "http://arxiv.org/abs/1206.4681v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["patrick pletscher", "sharon wulff"], "accepted": true, "id": "1206.4681"}, "pdf": {"name": "1206.4681.pdf", "metadata": {"source": "META", "title": "LPQP for MAP: Putting LP Solvers to Better Use", "authors": ["Patrick Pletscher", "Sharon Wulff"], "emails": ["pletscher@inf.ethz.ch", "sharon.wulff@inf.ethz.ch"], "sections": [{"heading": "1. Introduction", "text": "The problem we have is that most people are able to move without fear of violence."}, {"heading": "2. Background and Notation", "text": "For an undirected graph G = (V, E), the MAP problem is to assign each node in the graph to a class or category, so that the total assignment minimizes any associated energy. Let xi designate a discrete variable with a finite domain Xi1 that represents the assignment of the i-th node. The MAP problem is defined as asmin x x x x x x x V \u03b8i (xi) + \u2211 (i, j) \u0109ij (xi, xj). (1) Where these are universal and pairwise potential functions associated with the node and edge assignments. Problem (1) can be expressed as a holistic square program using a K-ary encoding: min. i-V-Ti \u00b5i + \u0445Ti (i, jj)."}, {"heading": "2.1. Linear Programming Relaxation", "text": "The LP approach (Schlesinger, 1976; Wainwright & Jordan, 2008) is based on a convex relaxation of (2), which includes an additional variable for each edge; proper local marginalization is forced by sum constraints; the LP reads asmin \u00b5 LG, i-V-Ti, (i, j), E-Ti, (3) with LG, the local marginal polytopic: LG = \u00b5, (i, j); the LP reads asmin \u00b5, i-V, (i, j), E-Ti, (i, j), E-K, (i, j), the local marginal polytopic: (i, j)."}, {"heading": "2.2. Quadratic Programming Relaxation", "text": "An alternative locking of the integer-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p"}, {"heading": "3. Combined LP and QP Relaxation", "text": "We propose to optimize a target that is a combination of LP and QP relaxations. We maintain the auxiliary variables \u00b5ij of paired terms, but force these variables to agree with the product of the simple limits \u00b5i and \u00b5j. The extent to which the restriction is enforced is determined by the parameter \u03c1.We focus on the Kullback-Leibler (KL) divergence as a tightening function, due to the probable nature of the comparative boundary terms. For probability distributions p and q of a discrete random variable, their KL divergence to beDKL (p, q) divergence is used as a tightening function."}, {"heading": "4. LPQP Algorithms", "text": "In this section, we derive two algorithms for the non-convex LPQP lens in (5), the penalty expressions in (6) and (7) being different."}, {"heading": "4.1. Difference of Convex Functions (DC)", "text": "The convex-concave method (CCCP) (Yuille & Rangarajan, 2003) can be applied to a limited optimization problem where the target is not convex, provided that the target has a decomposition into a convex and a concave part. In our setting, we would like to find a decomposition of the formmin-convexified target, which is achieved by linearizing the convexified target (\u00b5): \u00b5t + 1 = argmin-convexified target (\u00b5). The CCCP algorithm proceeds by iteratively solving a convexified target, which is achieved by linearizing the convexified target (\u00b5): \u00b5t + 1 = argmin-convexified target (\u00b5) \u2212 \u00b5T-convexified target (\u00b5t). (8) The decomposition of the two linearized targets and the gradient-exified target (\u00b5) are achieved by an iventilated target (\u00b5)."}, {"heading": "4.2. Algorithm Overview", "text": "The general scheme of proposed LPQP algorithms is shown in algorithm 1. The algorithm consists of two loops. The inner loop solves the DC problem for a fixed penalty parameter \u03c1, whereas the outer loop gradually increases the value of \u03c1.algorithm 1 LPQP algorithm scheme for MAP. Required: G = (V, E), \u03b8. 1: initialize the problem uniformly with LG, \u03c1 = 0. 2: repeat 3: t = 0, \u00b50 = \u00b5. 4: repeat 5: \u00b5t + 1 = argmino."}, {"heading": "4.3. Uniform Weighting", "text": "The convex sub-problem we get in the CCCP step with the uniform weighting function (6) is given by min. (9) if it is a modification of the unary potentials by an additional gradient derived from the linear part of DC decomposition (8). (3) The configurations with low probability in the previous iteration t are vigorously discouraged. (5) The convex problem in (9) is solved by the modification of the unary potentials. (5) Configurations with low probability in the previous iteration t are vigorously discouraged. (5) The convex problem in (6) is triggered by the standard product belief propagation. (6) Configurations with low probability in the previous iteration t are vigorously discouraged. (5) The convex problem in (9) is triggered by the standard product belief propagation."}, {"heading": "4.4. Tree-based Weighting", "text": "The konvexe partial problem that corresponds to the CCCP step, with the issue of tree-based weighting (7), is where we define the entropy of a tree by hatree (\u00b5): = p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-CCp-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-p-"}, {"heading": "4.5. Entropy-augmented LP Solvers", "text": "Recently, several papers (Jojic et al., 2010; Savchynskyy et al., 2011) have suggested smoothing out the LP target by adding a term that favors entropic marginalies.The merit of this additional term lies in overcoming the unevenness of the lens. Ultimately, to solve the original LP, these entropy-augmented solvers gradually reduce the entropy concept. Of course, the convergence of these algorithms is relatively rapid at first. This line of research goes back to Nesterov's work on fast gradient methods (Nesterov, 1983).The proposed LPQP solvers behave the opposite in terms of the smoothness of the object. Rather, the influence of the entropy concept is increased by the progression of the algorithm, which leads to favorable convergence characteristics."}, {"heading": "5. Experiments", "text": "We use LPQP-U to refer to the implementation of uniform weighting penalty, and LPQP-T for tree-based weighting. In experiments where the graph did not exhibit natural decomposition, we used a deepest search algorithm to greedily perform tree decomposition for LPQP-T. Benchmarked Methods We compare the performance of LPQP-U and LPQP-T, both of which are LP relations, with the widely used MAP algorithms, tree-weighted belief propagation (TRWS) (Kolmogorov, 2006), and Max Product LP (MPLP) (Sontag et al., 2008), both of which are LP relations. For both algorithms, we used the implementation provided by the authors. These algorithms represent different trade-offs in performance. TRWS is a highly efficient measurement algorithm for standard LP relaxation. It is much faster than LP."}, {"heading": "5.1. Synthetic Potts Model Data", "text": "We follow a similar experimental setup as in (Ravikumar et al., 2010).The graph is a 4-nearest adjacent grid of different sizes. We used M = 60, 90, 120, where M is the lattice side length, and M2 is the total number of variables. We used K = 2 and K = 5 for the number of states. The unary potentials were randomly defined as the signal-to-noise ratio between the signals. The paired potentials are uniform (xi, xj), set to punish any agreement or discrepancy of the labels by an amount that affects the uniform (\u2212 1, 1).We use the MPLP (xi, xj) = 0, if xi 6 = xj and otherwise. In this experiment we choose the usual composition of the uniform (\u2212 1, 1)."}, {"heading": "5.2. Protein Design & Prediction", "text": "The problem of protein inference discussed in (Yanover et al., 2006) consists of two tasks: protein side chain prediction and protein design. For the protein prediction task, it was shown in (Yanover et al., 2006) that LP relaxation is not narrow for only 30 of the 370 protein prediction gradients. For 28 of them, the true MAP was calculated using general integer pro-programming techniques, Figure 3 visualizes the results in these cases. LPQP was applied for this task in (Sontag et al., 2008) to the global minimum of about 2 / 3 of these more difficult instances and achieved the global optimum in all remaining 340 cases. LPQP found the global optimum in all but three cases (results are not shown). MPLP was applied to this task (Sontag et al., 2008) and achieved the global optimum in all instances: MPL7 instances."}, {"heading": "5.3. Decision Tree Fields", "text": "As a final experiment, we apply our LPQP algorithm to the recently published data set \"Hard Discrete Energy Minimization Instances\" (Nowozin et al., 2011), which is available on the authors \"website. The task is to fill or paint a hidden area in a binary image of Chinese handwritten characters, see Figure 4. The data set consists of 100 instances of energy minimization and contains approximate MAP solutions obtained using simulated annealing inference (SA inference), which works better than TRWS. In 43 cases, the LPQP algorithm achieved better solutions than the previously known solutions. Figure 4 illustrates some of the cases where the LPQP algorithm leads to a better solution. We observed that the SA solutions seem to hallucinate too much regularity."}, {"heading": "51.6 46.4 45.9 43.5 42.5", "text": "The evaluation of the three algorithms is as follows: LPQP-U: 0.84, SA: 0.74 and TRWS: 0.21. We failed to apply MPLP because the tightening was not successful."}, {"heading": "6. Conclusions", "text": "We present a new formulation for MAP inference in graphical models, which combines the relaxation terms LP and QP by a KL divergence measure. The resulting problem, although not convex, leads to efficient algorithms based on known LP solvers."}, {"heading": "Acknowledgments", "text": "We would like to thank Joachim Buhmann, Andreas Krause, Cheng Soon Ong and Christian Sigg for their insightful discussions. In part, the work was supported by the NCCR-MICS, a centre of the Swiss National Science Foundation, under funding number 51NF40-111400."}], "references": [{"title": "A fast iterative shrinkagethresholding algorithm for linear inverse problems", "author": ["A Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "Beck and Teboulle,? \\Q2009\\E", "shortCiteRegEx": "Beck and Teboulle", "year": 2009}, {"title": "Dual decomposition for marginal inference", "author": ["J. Domke"], "venue": "In AAAI,", "citeRegEx": "Domke,? \\Q2011\\E", "shortCiteRegEx": "Domke", "year": 2011}, {"title": "Norm-product belief propagation: Primal-dual message-passing for approximate inference", "author": ["T Hazan", "A. Shashua"], "venue": "IEEE TIT,", "citeRegEx": "Hazan and Shashua,? \\Q2010\\E", "shortCiteRegEx": "Hazan and Shashua", "year": 2010}, {"title": "Accelerated dual decomposition for MAP inference", "author": ["V Jojic", "S Gould", "D. Koller"], "venue": "In ICML,", "citeRegEx": "Jojic et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jojic et al\\.", "year": 2010}, {"title": "MAP-Inference for Highly-Connected Graphs with DC-Programming", "author": ["J Kappes", "C. Schnoerr"], "venue": "In DAGM,", "citeRegEx": "Kappes and Schnoerr,? \\Q2008\\E", "shortCiteRegEx": "Kappes and Schnoerr", "year": 2008}, {"title": "Convergent tree-reweighted message passing for energy minimization", "author": ["V. Kolmogorov"], "venue": null, "citeRegEx": "Kolmogorov,? \\Q2006\\E", "shortCiteRegEx": "Kolmogorov", "year": 2006}, {"title": "MRF optimization via dual decomposition: Message-passing revisited", "author": ["N Komodakis", "N Paragios", "G. Tziritas"], "venue": "In In ICCV,", "citeRegEx": "Komodakis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Komodakis et al\\.", "year": 2007}, {"title": "Message-Passing Algorithms for Quadratic Programming Formulations of MAP Estimation", "author": ["A Kumar", "S. Zilberstein"], "venue": "In UAI,", "citeRegEx": "Kumar and Zilberstein,? \\Q2011\\E", "shortCiteRegEx": "Kumar and Zilberstein", "year": 2011}, {"title": "MessagePassing Algorithms for MAP Estimation Using DC Programming", "author": ["A Kumar", "S Zilberstein", "M. Toussaint"], "venue": "In AISTATS,", "citeRegEx": "Kumar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2012}, {"title": "A method of solving a convex programming problem with convergence rate o(1/k)", "author": ["Y. Nesterov"], "venue": "Soviet. Math. Dokl.,", "citeRegEx": "Nesterov,? \\Q1983\\E", "shortCiteRegEx": "Nesterov", "year": 1983}, {"title": "Decision tree fields", "author": ["S Nowozin", "C Rother", "S Bagon", "T Sharp", "B Yao", "P. Kohli"], "venue": "In ICCV, pp", "citeRegEx": "Nowozin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nowozin et al\\.", "year": 2011}, {"title": "Quadratic Programming Relaxations for Metric Labeling and Markov Random Field MAP Estimation", "author": ["P Ravikumar", "J. Lafferty"], "venue": "In ICML,", "citeRegEx": "Ravikumar and Lafferty,? \\Q2006\\E", "shortCiteRegEx": "Ravikumar and Lafferty", "year": 2006}, {"title": "Message-passing for graph-structured linear programs: Proximal methods and rounding schemes", "author": ["P Ravikumar", "A Agarwal", "Wainwright", "M J"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Ravikumar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ravikumar et al\\.", "year": 2010}, {"title": "A study of Nesterov\u2019s scheme for Lagrangian decomposition and MAP labeling", "author": ["B Savchynskyy", "J H Kappes", "S Schmidt", "C. Schn\u00f6rr"], "venue": "In CVPR,", "citeRegEx": "Savchynskyy et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Savchynskyy et al\\.", "year": 2011}, {"title": "Syntactic analysis of two-dimensional visual signals in noisy conditions", "author": ["Schlesinger", "M I"], "venue": "Kibernetika,", "citeRegEx": "Schlesinger and I.,? \\Q1976\\E", "shortCiteRegEx": "Schlesinger and I.", "year": 1976}, {"title": "Tightening LP relaxations for MAP using message-passing", "author": ["D Sontag", "T Meltzer", "A Globerson", "Y Weiss", "T. Jaakkola"], "venue": "In UAI, pp", "citeRegEx": "Sontag et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sontag et al\\.", "year": 2008}, {"title": "Graphical Models, Exponential Families, and Variational Inference", "author": ["M J Wainwright", "Jordan", "M I"], "venue": null, "citeRegEx": "Wainwright et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wainwright et al\\.", "year": 2008}, {"title": "Linear programming relaxations and belief propagation \u2013 an empirical study", "author": ["C Yanover", "T Meltzer", "Y. Weiss"], "venue": null, "citeRegEx": "Yanover et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Yanover et al\\.", "year": 2006}, {"title": "The concave-convex procedure", "author": ["A L Yuille", "A. Rangarajan"], "venue": "Neural Computation,", "citeRegEx": "Yuille and Rangarajan,? \\Q2003\\E", "shortCiteRegEx": "Yuille and Rangarajan", "year": 2003}], "referenceMentions": [{"referenceID": 15, "context": "The work in (Sontag et al., 2008) proposes to tighten the polytope by including summation constraints over larger subsets of variables.", "startOffset": 12, "endOffset": 33}, {"referenceID": 8, "context": "Finally, in concurrent work Kumar et al. (2012) propose a hybrid LP and QP approach to MAP, similar to our formulation discussed in the next section.", "startOffset": 28, "endOffset": 48}, {"referenceID": 6, "context": "Dual Decomposition The dual decomposition framework (Bertsekas, 1999; Komodakis et al., 2007), can be applied to an optimization problem provided that the objective can be decomposed into several subproblems, also known in the literature as the slave problems.", "startOffset": 52, "endOffset": 93}, {"referenceID": 1, "context": "A dual decomposition of problem (11), was carried out in (Domke, 2011).", "startOffset": 57, "endOffset": 70}, {"referenceID": 13, "context": "A similar solution was demonstrated in (Savchynskyy et al., 2011), on a more restricted decomposition.", "startOffset": 39, "endOffset": 65}, {"referenceID": 3, "context": "Entropy-augmented LP Solvers Recently, several works (Jojic et al., 2010; Savchynskyy et al., 2011) proposed to smooth the LP objective by adding a term that favors entropic marginals.", "startOffset": 53, "endOffset": 99}, {"referenceID": 13, "context": "Entropy-augmented LP Solvers Recently, several works (Jojic et al., 2010; Savchynskyy et al., 2011) proposed to smooth the LP objective by adding a term that favors entropic marginals.", "startOffset": 53, "endOffset": 99}, {"referenceID": 9, "context": "This line of research originates in Nesterov\u2019s work on fast gradient methods (Nesterov, 1983).", "startOffset": 77, "endOffset": 93}, {"referenceID": 5, "context": "Benchmarked Methods We compare the performance of LPQP-U and LPQP-T with the widely used MAP algorithms, tree-reweighted belief propagation (TRWS) (Kolmogorov, 2006) and max-product LP (MPLP) (Sontag et al.", "startOffset": 147, "endOffset": 165}, {"referenceID": 15, "context": "Benchmarked Methods We compare the performance of LPQP-U and LPQP-T with the widely used MAP algorithms, tree-reweighted belief propagation (TRWS) (Kolmogorov, 2006) and max-product LP (MPLP) (Sontag et al., 2008), both of which are LP relaxations.", "startOffset": 192, "endOffset": 213}, {"referenceID": 12, "context": "Synthetic Potts Model Data We follow a similar experimental setup as in (Ravikumar et al., 2010).", "startOffset": 72, "endOffset": 96}, {"referenceID": 17, "context": "The protein inference problem discussed in (Yanover et al., 2006), consists of two tasks: protein side-chain prediction and protein design.", "startOffset": 43, "endOffset": 65}, {"referenceID": 17, "context": "For the protein prediction task, it was shown in (Yanover et al., 2006) that only for 30 out of the 370 protein prediction instances, the LP relaxation is not tight.", "startOffset": 49, "endOffset": 71}, {"referenceID": 15, "context": "MPLP was applied to this task in (Sontag et al., 2008), and achieved the global optimum on all instances.", "startOffset": 33, "endOffset": 54}, {"referenceID": 10, "context": "As a last experiment we apply our LPQP algorithm to the recently published \u201chard discrete energy minimization instances\u201d dataset (Nowozin et al., 2011), available on the authors webpage.", "startOffset": 129, "endOffset": 151}, {"referenceID": 10, "context": "Middle: solutions from (Nowozin et al., 2011) obtained by simulated annealing.", "startOffset": 23, "endOffset": 45}], "year": 2012, "abstractText": "MAP inference for general energy functions remains a challenging problem. While most efforts are channeled towards improving the linear programming (LP) based relaxation, this work is motivated by the quadratic programming (QP) relaxation. We propose a novel MAP relaxation that penalizes the Kullback-Leibler divergence between the LP pairwise auxiliary variables, and QP equivalent terms given by the product of the unaries. We develop two efficient algorithms based on variants of this relaxation. The algorithms minimize the non-convex objective using belief propagation and dual decomposition as building blocks. Experiments on synthetic and real-world data show that the solutions returned by our algorithms substantially improve over the LP relaxation.", "creator": "LaTeX with hyperref package"}}}