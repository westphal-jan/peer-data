{"id": "1206.4685", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jun-2012", "title": "Sparse-GEV: Sparse Latent Space Model for Multivariate Extreme Value Time Serie Modeling", "abstract": "In many applications of time series models, such as climate analysis and social media analysis, we are often interested in extreme events, such as heatwave, wind gust, and burst of topics. These time series data usually exhibit a heavy-tailed distribution rather than a Gaussian distribution. This poses great challenges to existing approaches due to the significantly different assumptions on the data distributions and the lack of sufficient past data on extreme events. In this paper, we propose the Sparse-GEV model, a latent state model based on the theory of extreme value modeling to automatically learn sparse temporal dependence and make predictions. Our model is theoretically significant because it is among the first models to learn sparse temporal dependencies among multivariate extreme value time series. We demonstrate the superior performance of our algorithm to the state-of-art methods, including Granger causality, copula approach, and transfer entropy, on one synthetic dataset, one climate dataset and two Twitter datasets.", "histories": [["v1", "Mon, 18 Jun 2012 15:42:15 GMT  (1348kb)", "http://arxiv.org/abs/1206.4685v1", "ICML2012"]], "COMMENTS": "ICML2012", "reviews": [], "SUBJECTS": "stat.ME cs.LG stat.AP", "authors": ["yan liu 0002", "mohammad taha bahadori", "hongfei li"], "accepted": true, "id": "1206.4685"}, "pdf": {"name": "1206.4685.pdf", "metadata": {"source": "META", "title": "Sparse-GEV: Sparse Latent Space Model for Multivariate Extreme Value Time Series Modeling", "authors": ["Yan Liu", "Mohammad Taha Bahadori", "Hongfei Li"], "emails": ["liho@us.ibm.com"], "sections": [{"heading": "1. Introduction", "text": "This year, the time has come for us to be able to conquer a new country, where people are able to find a new home, where they are able to find a new home, where they are able to find a new home, where they are able to find a new home, where they are able to find a new home, in which they are able to find a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home, in which they are looking for a new home."}, {"heading": "2. Methodology", "text": "Before delving into the details of our model, we first briefly examine the extreme value theory (Coles, 2001). If there are sequences of constants at > 0 and bm like Pr (Mm \u2212 bm at \u2264 z) and Mm = max {X1, \u00b7 \u00b7, Xm} for a non-degenerated distribution function G, then G should belong to the generalized extreme value families (GEV), namely G (z) = exp {\u2212 1 / 2) for a non-degenerated distribution function G, where \u00b5 (\u2212 3) is the maximum distribution parameter."}, {"heading": "2.1. Model Description", "text": "Given multivariate time series data, our goal is to develop an effective model that can restore the temporal dependence between extreme time series (block maxima or peaks above the threshold) and make accurate predictions of future extreme events. In order to achieve a robust and interpretable model, a natural choice is to capture the temporal dependence using linear models; however, this cannot be achieved directly via extreme value variables, as their temporal dependence is obviously non-linear. To solve the problem, we propose latent models in which the location parameters of GEV distributions are latent variables and the temporal dependence between extreme value variables is captured by the latent variables using dynamic linear models. We select the location parameters because they capture the mode of extreme value variables and can be modeled reasonably well by linear dependencies. Formally, let us leave the \u00b51,"}, {"heading": "2.2. Inference and Learning", "text": "In view of the existence of hidden variables in the sparse GEV model, the direct maximization of the probability as in eq (6) is not feasible. Therefore, we apply the generalized EM algorithm to solve the problem. Next, we use the Gumbel distribution as an example to show how we can make efficient conclusions and learning processes in the proposed model. In the EM algorithm, we optimize the following function by two steps: Q (\u03b2), c; \u03b2old, \u03c3old, cold) = \u2212 P \u2211 i = 1 T + 1 obstructed (\u03c3i) \u2212 E {| X, \u03b2old, \u03c3old, cold} [xit \u2212 \u00b5it + exp \u2212 Rapp, old) + 12 (\u00b5it) = 1 T + 1 T + 1 T + 1 obstructed (\u03c3i) \u2212 E {| X, \u03b2old, \u03c3old, cold} [xit \u2212 \u00b5it \u2212 Rapp, old) + 12 (\u00b5it) = 1 T + 1 T + 1 hampered (\u03c3i) \u2212 E {X, \u03b2old, \u03c3old, \u03c3old, cold, cold} [xit \u2212 \u00b5it \u2212 Rapp, cold) + 12 (\u00b5it)"}, {"heading": "2.3. Prediction", "text": "In order to make predictions about the future value of extreme events, e.g. xiT + 1, we can first estimate the mean value of \u00b5-iT + 1 based on the samples from the posterior distribution with the learned parameters based on the extreme time series up to time T. Based on the model defined in eq (4), we can predict xiT + 1 asx-iT + 1 = \u00b5-i-T + 1 + \u03b3E\u03c3 i, where \u00b5-iT + 1 = c i + \u2211 L l = 1 \u2211 P j = 1 \u03b2 i j, l\u00b5-j T \u2212 l + 1 and \u03b3E (\u2248 0.5771) is the owl constant."}, {"heading": "2.4. Scalability", "text": "The computational complexity of Sparse-GEV depends on two factors: the number of EM iterations required for convergence, and the scalability of E-Step and M-Step. In Section 5, we show empirically that EM normally converges within a small number of iterations. In M-Step, there are efficient solvers for both equations, but the problems for different time series are independent and can be implemented in parallel. Particle filtering in E-Step is known to be efficient for scanning time series, mainly for three reasons: (i) it requires only one iteration to generate the samples, (ii) the generated samples are independent, no baking period or decoupling is required, and (iii) the scanning procedures at different locations are independent of each other and can be implemented in parallel. Therefore, our algorithm is scalable and could easily be applied to practical applications."}, {"heading": "3. Related Work and Discussions", "text": "Recently, several advanced approaches have been studied to reveal the temporal dependence of time series data, including Lasso-Granger (Arnold et al., 2007), Transferentropy (Schreiber, 2000), and the Copula approach (Liu et al., 2009).In this section, we discuss how these algorithms can be applied to the analysis of extreme time series and their links to Sparse-GEV."}, {"heading": "3.1. Related Work", "text": "It is the time in which people in the world, in which the world, in which the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world, the world,"}, {"heading": "3.2. Connections to existing algorithms", "text": "The Copula approach uses the marginal distribution of time series to shift the observations to another space and assumes a linear dependence in the new space. Sparse-GEV discovers the Granger causality relationship between the latent variables from which the observations were generated. Indeed, when the data are distributed according to Gaussian linear models, the transfer entropy is equivalent to the Granger causality relationship (Barnett et al., 2009). For high-dimensional time series, the number of observations is much smaller than the parameters of the model. The Lasso-Granger algorithm benefits from the variable selection properties of lasso."}, {"heading": "4. Experiment Results", "text": "To evaluate the effectiveness of our algorithm, we conduct experiments on four datasets, including a synthetic dataset, a weather dataset, and two Twitter datasets. The experiment results are evaluated both by how well we uncover the time dependency diagrams, and by how accurately we can predict the future value of extreme events based on the learned time dependency."}, {"heading": "4.1. Datasets", "text": "\"We have generated eight synthetic datasets, each consisting of nine time series with different temporal velocities, one of which is shown in Figure 1 (a). Time series T = 40 are generated in two steps: (i) A series of observations of the location variables is generated according to eq (4), using which the distribution ratios of N (0.2, 0.05), the coefficients of the stationary time series are set to 0.1 and the time delay of L (2). (ii) The observations x, how the distributions are marked with the corresponding location parameters. (i)"}, {"heading": "4.2. Performance Comparison", "text": "In fact it is true that most people who live in the United States are able to survive on their own, \"he said.\" But it is not true that they are able to survive on their own. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "4.3. Parameter Sensitivity Assessment", "text": "Like other latent state models, the Sparse GEV model has many parameters that could significantly affect its performance. In our last experiment, we evaluate the parameter sensitivity. Figure 4 (a) shows that in a wide range of values for the regulation parameter \u03bb, the learning accuracy of the diagram remains unchanged and little effort in selecting the regulation parameter leads to optimal performance. Figure 4 (b) suggests that our algorithm approaches the optimal point in less than 10 EM iterations. Figure 4 (c) illustrates the effect of the phenomenon on the performance of Sparse GEV. Small quantities of \u03c4 lead to a smoother estimate of E [\u00b5 | X], while higher values lead to a sensitive estimate (hence E [\u00b5 | X] closely aligned to the observation time series). This observation suggests that we monitor the sample mean of the latent value and should select a latent one that enables us to calculate it."}, {"heading": "5. Conclusion", "text": "In order to estimate the parameters of the model, we develop an iterative search algorithm based on the generalized EM algorithm and sampling with particle filtering. In extensive experiments, we show that Sparse-GEV outperforms the most modern algorithms such as copula and transfer entropy. For future work, we are interested in the theoretical analysis of the consistency of the Sparse-GEV model."}, {"heading": "Acknowledgement", "text": "We thank the anonymous reviewers for their valuable comments. This research was supported by the NSF research grant IIS-1134990."}], "references": [{"title": "Temporal causal modeling with graphical Granger methods", "author": ["A. Arnold", "Y. Liu", "N. Abe"], "venue": "In Proceedings of SIGKDD,", "citeRegEx": "Arnold et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Arnold et al\\.", "year": 2007}, {"title": "Granger causality and transfer entropy are equivalent for gaussian variables", "author": ["L. Barnett", "A.B. Barrett", "A.K. Seth"], "venue": "Phys. Rev. Lett.,", "citeRegEx": "Barnett et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Barnett et al\\.", "year": 2009}, {"title": "Nonparametric Entropy Estimation: An Overview", "author": ["J. Beirlant", "E.J. Dudewicz", "L. Gy\u00f6rfi", "E.C. Meulen"], "venue": "International Journal of the Mathematical Statistics Sciences,", "citeRegEx": "Beirlant et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Beirlant et al\\.", "year": 1997}, {"title": "Statistics of extremes: Theory and applications", "author": ["J. Beirlant", "Y. Goegebeur", "J. Segers", "J. Teugels"], "venue": "New York: Wiley,", "citeRegEx": "Beirlant et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Beirlant et al\\.", "year": 2004}, {"title": "Time Series Analysis, Forecasting and Control", "author": ["G. Box", "G. Jenkins", "G. Reinsel"], "venue": "Holden-Day, Incorporated,", "citeRegEx": "Box et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Box et al\\.", "year": 1990}, {"title": "An Introduction to Statistical Modeling of Extreme Values", "author": ["S. Coles"], "venue": null, "citeRegEx": "Coles.,? \\Q2001\\E", "shortCiteRegEx": "Coles.", "year": 2001}, {"title": "Modeling extremes of areal rainfall process", "author": ["S. Coles", "J.A. Tawn"], "venue": "Journal of the Royal Statistical Society. Series B.,", "citeRegEx": "Coles and Tawn.,? \\Q1996\\E", "shortCiteRegEx": "Coles and Tawn.", "year": 1996}, {"title": "A tutorial on particle filtering and smoothing", "author": ["A. Doucet", "A.M. Johansen"], "venue": "Fifteen years later. The Oxford Handbook of Nonlinear Filtering,", "citeRegEx": "Doucet and Johansen.,? \\Q2009\\E", "shortCiteRegEx": "Doucet and Johansen.", "year": 2009}, {"title": "Granger causality and path diagrams for multivariate time series", "author": ["E. Michael"], "venue": "J. of Econometrics,", "citeRegEx": "Michael.,? \\Q2007\\E", "shortCiteRegEx": "Michael.", "year": 2007}, {"title": "Correlation and dependence in risk management: properties and pitfalls", "author": ["P. Embrechts", "A. Mcneil", "D. Straumann"], "venue": "In Risk Management: Value at Risk and Beyond,", "citeRegEx": "Embrechts et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Embrechts et al\\.", "year": 2002}, {"title": "Inference for clusters of extreme values", "author": ["C.A. Ferro", "J. Segers"], "venue": "Journal of the Royal Statistical Society. Series B.,", "citeRegEx": "Ferro and Segers.,? \\Q2003\\E", "shortCiteRegEx": "Ferro and Segers.", "year": 2003}, {"title": "Sparse inverse covariance estimation with the graphical lasso", "author": ["J. Friedman", "T. Hastie", "R. Tibshirani"], "venue": null, "citeRegEx": "Friedman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2008}, {"title": "Testing for causality: A personal viewpoint", "author": ["C. Granger"], "venue": "Journal of Economic Dynamics and Control,", "citeRegEx": "Granger.,? \\Q1980\\E", "shortCiteRegEx": "Granger.", "year": 1980}, {"title": "Time Series Analysis", "author": ["J. Hamilton"], "venue": null, "citeRegEx": "Hamilton.,? \\Q1994\\E", "shortCiteRegEx": "Hamilton.", "year": 1994}, {"title": "Time-varying models for extreme values", "author": ["G. Huerta", "B. Sanso"], "venue": "Environmental and Ecological Statistics,", "citeRegEx": "Huerta and Sanso.,? \\Q2007\\E", "shortCiteRegEx": "Huerta and Sanso.", "year": 2007}, {"title": "Randomization tests for distinguishing social influence and homophily effects", "author": ["T. La Fond", "J. Neville"], "venue": "In Proceedings of WWW,", "citeRegEx": "Fond and Neville.,? \\Q2010\\E", "shortCiteRegEx": "Fond and Neville.", "year": 2010}, {"title": "Claims prediction with dependence using copula models", "author": ["Y.K. Leong", "E.A. Valdez"], "venue": "Insurance: Mathematics and Economics,", "citeRegEx": "Leong and Valdez.,? \\Q2005\\E", "shortCiteRegEx": "Leong and Valdez.", "year": 2005}, {"title": "The nonparanormal: Semiparametric estimation of high dimensional undirected graphs", "author": ["H. Liu", "J.D. Lafferty", "L.A. Wasserman"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Liu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "Grouped graphical Granger modeling for gene expression regulatory networks discovery", "author": ["A. Lozano", "N. Abe", "Y. Liu", "S. Rosset"], "venue": "In Proceedings of ISMB,", "citeRegEx": "Lozano et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lozano et al\\.", "year": 2009}, {"title": "Spatial-temporal causal modeling for climate change attribution", "author": ["A. Lozano", "H. Li", "A. Niculescu-Mizil", "Y. Liu", "C. Perlich", "J. Hosking", "N. Abe"], "venue": "In Proceedings of KDD,", "citeRegEx": "Lozano et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lozano et al\\.", "year": 2009}, {"title": "High-Dimensional Graphs and Variable Selection with the Lasso", "author": ["N. Meinshausen", "P. B\u00fchlmann"], "venue": "The Annals of Statistics,", "citeRegEx": "Meinshausen and B\u00fchlmann.,? \\Q2006\\E", "shortCiteRegEx": "Meinshausen and B\u00fchlmann.", "year": 2006}, {"title": "Robustly Estimating the Flow Direction of Information in Complex Physical Systems", "author": ["G. Nolte", "A. Ziehe", "V. Nikulin", "A. Schl\u00f6gl", "N. Kr\u00e4mer", "T. Brismar", "K.-R. M\u00fcller"], "venue": "Physical Review Letters,", "citeRegEx": "Nolte et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Nolte et al\\.", "year": 2008}, {"title": "Disk aware discord discovery: finding unusual time series in terabyte sized datasets", "author": ["D. Yankov", "E. Keogh", "U. Rebbapragada"], "venue": "Knowl. Inf. Syst.,", "citeRegEx": "Yankov et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Yankov et al\\.", "year": 2008}, {"title": "Measuring Information Transfer", "author": ["T. Schreiber"], "venue": "Physical Review Letters,", "citeRegEx": "Schreiber.,? \\Q2000\\E", "shortCiteRegEx": "Schreiber.", "year": 2000}, {"title": "Algorithms for Large Scale Markov Blanket Discovery", "author": ["I. Tsamardinos", "C.F. Aliferis", "E. Statnikov"], "venue": "In Proceedings of FLAIRS,", "citeRegEx": "Tsamardinos et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Tsamardinos et al\\.", "year": 2003}, {"title": "Coordinate descent algorithms for lasso penalized regression", "author": ["T-T. Wu", "K. Lange"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "Wu and Lange.,? \\Q2008\\E", "shortCiteRegEx": "Wu and Lange.", "year": 2008}], "referenceMentions": [{"referenceID": 13, "context": "Time series analysis and modeling have been extensively studied in the literature and successfully found applications across domains (Box & Jenkins, 1990; Hamilton, 1994).", "startOffset": 133, "endOffset": 170}, {"referenceID": 12, "context": "Many algorithms are proposed to automatically recover the temporal structures, such as autocorrelation, crosscorrelations (Box & Jenkins, 1990), randomization test (Edgington & Onghena, 2007), Granger causality (Granger, 1980), transfer entropy (Beirlant et al.", "startOffset": 211, "endOffset": 226}, {"referenceID": 2, "context": "Many algorithms are proposed to automatically recover the temporal structures, such as autocorrelation, crosscorrelations (Box & Jenkins, 1990), randomization test (Edgington & Onghena, 2007), Granger causality (Granger, 1980), transfer entropy (Beirlant et al., 1997; Barnett et al., 2009), and so on.", "startOffset": 245, "endOffset": 290}, {"referenceID": 1, "context": "Many algorithms are proposed to automatically recover the temporal structures, such as autocorrelation, crosscorrelations (Box & Jenkins, 1990), randomization test (Edgington & Onghena, 2007), Granger causality (Granger, 1980), transfer entropy (Beirlant et al., 1997; Barnett et al., 2009), and so on.", "startOffset": 245, "endOffset": 290}, {"referenceID": 5, "context": "The statistical approach we can utilize to solve these important problems is the theory of extreme value modeling (Coles, 2001; Beirlant et al., 2004), which provides a natural family of probability distributions for modeling the magnitude of the largest (or smallest) of a large number of events, and a canonical stochastic process model (Coles, 2001) for the occurrence of events above a very high (or below a very low) threshold.", "startOffset": 114, "endOffset": 150}, {"referenceID": 3, "context": "The statistical approach we can utilize to solve these important problems is the theory of extreme value modeling (Coles, 2001; Beirlant et al., 2004), which provides a natural family of probability distributions for modeling the magnitude of the largest (or smallest) of a large number of events, and a canonical stochastic process model (Coles, 2001) for the occurrence of events above a very high (or below a very low) threshold.", "startOffset": 114, "endOffset": 150}, {"referenceID": 5, "context": ", 2004), which provides a natural family of probability distributions for modeling the magnitude of the largest (or smallest) of a large number of events, and a canonical stochastic process model (Coles, 2001) for the occurrence of events above a very high (or below a very low) threshold.", "startOffset": 196, "endOffset": 209}, {"referenceID": 5, "context": "Preliminaries Before diving into the details of our model, we first briefly review the extreme value theory (Coles, 2001).", "startOffset": 108, "endOffset": 121}, {"referenceID": 5, "context": ", xT }, we define the joint 1 In extreme value theory, two main sets of methods, the Block Maxima method and the Peaks over Thresholds method have been developed to model extreme values (Coles, 2001).", "startOffset": 186, "endOffset": 199}, {"referenceID": 0, "context": "Very recently, a few advanced approaches have been explored to uncover temporal dependence from time series data, including Lasso-Granger (Arnold et al., 2007), transfer entropy (Schreiber, 2000), and the copula approach (Liu et al.", "startOffset": 138, "endOffset": 159}, {"referenceID": 23, "context": ", 2007), transfer entropy (Schreiber, 2000), and the copula approach (Liu et al.", "startOffset": 26, "endOffset": 43}, {"referenceID": 17, "context": ", 2007), transfer entropy (Schreiber, 2000), and the copula approach (Liu et al., 2009).", "startOffset": 69, "endOffset": 87}, {"referenceID": 0, "context": "Granger causality In (Arnold et al., 2007), the Lasso-Ganger algorithm, an effective and efficient approach to learn sparse temporal graphs, is developed by combining Granger causality with sparse neighborhood selection using L1-penalized regression.", "startOffset": 21, "endOffset": 42}, {"referenceID": 23, "context": "In the Transfer entropy framework (Schreiber, 2000), time series x is thought to be a cause of another time series x if the values of x in the past significantly decrease the uncertainty in the future values of x given its past.", "startOffset": 34, "endOffset": 51}, {"referenceID": 24, "context": "Since the transfer entropy is a pairwise quantity, we can use its output as input to a graph learning algorithm, for example, IAMB (Tsamardinos et al., 2003), to uncover the temporal dependency among multiple time series.", "startOffset": 131, "endOffset": 157}, {"referenceID": 9, "context": "Copula Approach The copula approach has been proposed for dependency analysis of time series with non-Gaussian marginal distributions (Embrechts et al., 2002).", "startOffset": 134, "endOffset": 158}, {"referenceID": 17, "context": "It has been used for forecast in time series (Leong & Valdez, 2005) and learning sparase dependency structures (Liu et al., 2009).", "startOffset": 111, "endOffset": 129}, {"referenceID": 11, "context": "algorithm (Friedman et al., 2008).", "startOffset": 10, "endOffset": 33}, {"referenceID": 1, "context": "In fact, when the data are distributed according to Gaussian linear model, transfer entropy is equivalent to Granger causality (Barnett et al., 2009).", "startOffset": 127, "endOffset": 149}, {"referenceID": 0, "context": "(Meinshausen & B\u00fchlmann, 2006) show that the Lasso variable selection loss, and subsequently the Lasso-Granger\u2019s loss (Arnold et al., 2007), vanishes with an exponential rate.", "startOffset": 118, "endOffset": 139}, {"referenceID": 17, "context": "For the copula approach, (Liu et al., 2009) show that when copula-based model is the true model, the copula-based structure learning algorithm with non-parametric estimation of marginals converges to", "startOffset": 25, "endOffset": 43}, {"referenceID": 2, "context": "The performance of transfer entropy heavily relies on the accuracy of entropy estimations, which require a large number of observations, especially for high dimensional distributions, to achieve robust estimation (Beirlant et al., 1997).", "startOffset": 213, "endOffset": 236}], "year": 2012, "abstractText": "In many applications of time series models, such as climate analysis and social media analysis, we are often interested in extreme events, such as heatwave, wind gust, and burst of topics. These time series data usually exhibit a heavy-tailed distribution rather than a Gaussian distribution. This poses great challenges to existing approaches due to the significantly different assumptions on the data distributions and the lack of sufficient past data on extreme events. In this paper, we propose the Sparse-GEV model, a latent state model based on the theory of extreme value modeling to automatically learn sparse temporal dependence and make predictions. Our model is theoretically significant because it is among the first models to learn sparse temporal dependencies among multivariate extreme value time series. We demonstrate the superior performance of our algorithm to the state-of-art methods, including Granger causality, copula approach, and transfer entropy, on one synthetic dataset, one climate dataset and two Twitter datasets.", "creator": "LaTeX with hyperref package"}}}