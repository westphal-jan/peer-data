{"id": "1206.6380", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring", "abstract": "In this paper we address the following question: Can we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?. An algorithm based on the Langevin equation with stochastic gradients (SGLD) was previously proposed to solve this, but its mixing rate was slow. By leveraging the Bayesian Central Limit Theorem, we extend the SGLD algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an efficient optimizer during burn-in.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (470kb)", "http://arxiv.org/abs/1206.6380v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.CO stat.ML", "authors": ["sungjin ahn", "anoop korattikara balan", "max welling"], "accepted": true, "id": "1206.6380"}, "pdf": {"name": "1206.6380.pdf", "metadata": {"source": "META", "title": "Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring", "authors": ["Sungjin Ahn", "Anoop Korattikara", "Max Welling"], "emails": ["SUNGJIA@ICS.UCI.EDU", "AKORATTI@ICS.UCI.EDU", "WELLING@ICS.UCI.EDU"], "sections": [{"heading": "1. Motivation", "text": "If a dataset contains one billion datasets (which is not unusual nowadays), the MCMC algorithms will not even have produced a single (burn-in) sample if a clever learning algorithm based on stochastic gradients is already making pretty good predictions. Indeed, the fascinating results of Bottou and Bousquet (2008) seem to suggest that the number of bits per unit of calculation, an algorithm as simple as stochastic gradients, is almost optimal. We argue that the methods that are useful in an age when datasets are growing at an exponential rate must embrace the ideas of stochastic optimization."}, {"heading": "2. Preliminaries", "text": "We start with some notations, definitions and precursors. We have a large data set XN consisting of N i.i.d. data points {x1... xN} and we use a family of distributions parameterized by \u03b8-RD to model the distribution of xi's. We choose a prior distribution p (\u03b8) and are interested in obtaining samples from the back distribution, p (\u03b8 | XN), p (\u03b8-RD). As is common in asymptotic theory, we will also use some frequentistic concepts in the development of our method. We assume that the true data generating distribution is in our family of models and designate the true parameters that the XN dataset generated with voltage 0. We designate the score or gradient of the log probability."}, {"heading": "3. Stochastic Gradient Fisher Scoring", "text": "We are now ready to derive our stochastic gradient Fisher scoring algorithm (SGFS), starting from the Stochastic Gradient Langevin Dynamics (SGLD) (Welling & Teh, 2011) algorithm described in Section 3.1. SGLD can accurately take samples from the back, but suffers from a low mixing rate. In Section 3.2, we show that it is easy to construct a Markov chain that can take samples from a normal approximation of the back section at any mixing rate. We will then combine these methods to develop our stochastic gradient Fisher scoring algorithm (SGFS) in Section 3.3."}, {"heading": "3.1. Stochastic Gradient Langevin Dynamics", "text": "The SGLD algorithm has the following update equation: \u03b8t + 1 \u2190 \u03b8t + C2 {\u0433log p (\u03b8t; Xtn)} + \u03bdwhere \u03bd \u0445 N (0, C) (1) Here is the step size, C is called the preconditioning matrix (Girolami & Calderhead, 2010) and \u03bd is a random variable representing the injected Gaussian noise. The gradient of the protocol likelihoodGN (\u03b8; XN) over the entire dataset is calculated by scaling the mean gradient gn (\u03b8t; X t n) calculated from a mini-BatchXtn = {xt1... xtn} of size n N. Welling & Teh (2011) showed that Eqn. (1) samples are generated from the posterior distribution when the step size is calculated as opposed to zero."}, {"heading": "3.2. Sampling from the Approximate Posterior", "text": "Since it is not clear how to use Eqn. (1) at high step sizes, we will turn away from the Langevin dynamics and explore a different approach. As mentioned in Section 2, the posterior distribution of a normal distribution N (\u03b80, I \u2212 1N) approaches as the size of the dataset becomes very large. It is easy to construct a Markov chain that makes a sample of this approach to the posterior at each step size. We will now show that the following actualization equation achieves this: Vict + 1 Product + C2 {\u2212 IN (Vict \u2212 Victor 0)} + Spectrum, with N (0, C \u2212 24 CINC) (2) The actualization is an affine transformation of Vict plus injected independent Gaussian noise, \u03c9. If Vict exhibits a Gaussian distribution, then I \u2212 a variation of I \u00b7 and I \u00b7 I \u00b7 \u00b7 \u00b7 I \u00b7 \u00b7 \u00b7 I \u00b7 \u00b7 I \u00b7 \u00b7 I \u00b7 \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I, independent independent gausal noise, then I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I \u00b7 I."}, {"heading": "3.3. Stochastic Gradient Fisher Scoring", "text": "In practical problems, both methods are important, and the extreme systems dictated by the two above are very limiting. If the rear part of the system is close to Gaussian (as is usually the case), we would like to take advantage of the high mixing rate, if the rear part is slightly closer to Gaussian, we can start by assuming a high mixing rate, but slow down the mixing rate to capture the non-Gaussian structure when more computation becomes available. In other words, one should be free to manage the right trade between sampling accuracy and mixing rate."}, {"heading": "4. Computational Efficiency", "text": "The biggest advantage over standard MCMC algorithms is clearly the fact that we use stochastic minibatches instead of the entire dataset for each iteration. However, for a model with a large number of parameters, another source of significant computational effort is the calculation of the D \u00d7 D matrix \u03b3NI, t + 4B and the multiplication of its inverse by the resulting mean gradient. A numerically more stable alternative is the updating of the Cholesky factors (Seeger, 2004). If even this is not feasible, you can reduce the computing complexity per iteration to O (nD2) using the ShermanMorrison-Woodbury equation. A numerically more stable alternative is the updating of the Cholesky factors (Seeger, 2004)."}, {"heading": "5. Experiments", "text": "In the following, we report on experimental results in which we test SGFSf, SGFS-d, SGLD, SGD, and HMC on three different models: logistic regression, neural networks, and discriminatory RBMs. The experiments have the following common practice: increments for SGD and SGLD are always selected by cross-validation for at least five settings; the minibatch size n is set to either 300 or 500, but the results are not sensitive to the exact value as long as it is large enough to maintain the central limit set (typically n > 100 is recommended)."}, {"heading": "5.1. Logistic Regression", "text": "A logistic regression model (LR) was trained on the MNIST dataset for the binary classification of two digits 7 and 9 based on a total of 10,000 data items. We used a 50-dimensional random projection of the original characteristics and performed SGFS with \u03bb = 1. However, we used B = \u03b3IN and tested the algorithm for a number of alpha values (where Alpha = 2 \u221a). We ranked the algorithm for 3,000 burn-in iterations and then collected 100,000 samples. We compared the algorithm with Hamiltonian Monte Carlo sampling (Neal, 1993) and with SGLD (Welling & Teh, 2011). For HMC, the \"leapfrogstep\" size was adjusted during burn-in, so that the acceptance ratio was about 0.8. For SGLD, we also used a range of fixed boot sizes. In Figure 1, we show 2-d marginal comparisons of these FS MC to a long FS in the distribution."}, {"heading": "5.2. SGFS on Neural Networks", "text": "We also applied our methods to a three-layer neural network (NN) with logistic activation functions. In the following, we describe the classification results for two data sets."}, {"heading": "5.2.1. HERITAGE HEALTH PRIZE (HHP)", "text": "The goal of this contest is to predict how many days between [0 \u2212 15] a person will remain in a hospital since his / her last three years of hospitalization were logged 2. We used the same characteristics as the team's marketers who won the first milestone prize. By integrating first and second year data, we obtained 147,473 data points with 139 feature dimensions and then randomly selected 70% for training and the rest for testing. NNs with 30 hidden units were used because more hidden units did not noticeably improve results. Although we used \u03b1 = 6 for SGFS-d, there was no significant difference in values in the range 3 \u2264 1 \u2264 6. However, \u03b1 < 3 did not work for this data set because many hidden units had values. For SGD, we used increments from a polynomial annealing plan SGFS-d, which has a (b + t) value. Since the training error value was slowly decreasing to 100.5 = this G1 \u2212 1, this value was valid for 10461."}, {"heading": "5.2.2. CHARACTER RECOGNITION", "text": "To test with SGFS-f, we used inputs from 20-dimensional random projections and 30 hidden units, so that the number of parameters equals 940. Furthermore, we increased the mini margin size to 2,000 to reduce the time required for a good approximation to the 940 x 940 covariance matrix. The classification error averaged across the samples is shown in Figure 3 (right), where we used a small regulation parameter of \u03bb = 0.001 for all methods, as overhaul was not a problem. SGFS uses \u03b1 = 2, while for SGD and SGLD the increments from 10 \u2212 3 to 10 \u2212 7 were annealed using a = 1, b = 1000 and \u03b3 = 1."}, {"heading": "5.3. Discriminative Restricted Boltzmann Machine (DRBM)", "text": "We have written down the flags, that we will be able to change the world, \"he told the German Press Agency in an interview with the German Press Agency.\" We have repeatedly pinned ourselves on the flags in the past, \"he told the German Press Agency.\" We have written down the flags, that we will be able to change the world. \"Unless,\" the fiction, \"that\" the fiction, \"that\" the fiction, \"the\" the \"the,\" the \"the,\" the \"the,\" the \"the,\" the \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the,\" the, \"the, the,\" the, \"the,\" the, the, \"the, the,\" the, the, the, the, the, \"the, the, the, the, the, the,\" the, \"the,\" the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the"}, {"heading": "6. Conclusions", "text": "We have introduced a novel method, the Stochastic Gradient Fisher Scoring (SGFS) for approximate Bayesian learning processes. The main idea is to use stochastic gradients in the Langevin equation and use the central limit theorem to estimate the noise caused by the subsampling process. \u2022 Unlike traditional MCMC methods, SGFS is fast because it uses only stochastic gradients based on small mini-batches to take samples. \u2022 Unlike stochastic gradient lineage, SGFS samples (approximately) from posterior distribution lead to the following desirable properties. \u2022 Unlike GFS samples from a Gaussian approximation to the posterior distribution of the SGFS, SGFS samples from posterior distribution (which is correct for Fisher \u2192 Kong) for large step sizes. \u2022 Unlike GGFS samples from a posterior distribution of a Gaussian phase, SGFS is associated with a time-conditioner of a Gaussian phase."}, {"heading": "Acknowledgements", "text": "This material is based on work supported by the National Science Foundation under grant numbers 0447903, 0914783, 0928427."}], "references": [{"title": "A tutorial on adaptive mcmc", "author": ["C. Andrieu", "J. Thoms"], "venue": "Statistics and Computing,", "citeRegEx": "Andrieu and Thoms,? \\Q2009\\E", "shortCiteRegEx": "Andrieu and Thoms", "year": 2009}, {"title": "Stochastic approximation with two time scales", "author": ["V.S. Borkar"], "venue": "Systems and Control Letters,", "citeRegEx": "Borkar,? \\Q1997\\E", "shortCiteRegEx": "Borkar", "year": 1997}, {"title": "The tradeoffs of large scale learning", "author": ["L. Bottou", "O. Bousquet"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bottou and Bousquet,? \\Q2008\\E", "shortCiteRegEx": "Bottou and Bousquet", "year": 2008}, {"title": "Riemann manifold langevin and hamiltonian monte carlo", "author": ["M. Girolami", "B. Calderhead"], "venue": "Journal of the Royal Statistical Society B,", "citeRegEx": "Girolami and Calderhead,? \\Q2010\\E", "shortCiteRegEx": "Girolami and Calderhead", "year": 2010}, {"title": "Classification using discriminative Restricted Boltzmann Machines", "author": ["H. Larochelle", "Y. Bengio"], "venue": "In Proceedings of the 25 International Conference on Machine learning,", "citeRegEx": "Larochelle and Bengio,? \\Q2008\\E", "shortCiteRegEx": "Larochelle and Bengio", "year": 2008}, {"title": "Asymptotic methods in statistical decision theory", "author": ["L.M. Le Cam"], "venue": null, "citeRegEx": "Cam,? \\Q1986\\E", "shortCiteRegEx": "Cam", "year": 1986}, {"title": "Probabilistic inference using markov chain monte carlo methods", "author": ["R.M. Neal"], "venue": "Technical Report CRG-TR-93-1,", "citeRegEx": "Neal,? \\Q1993\\E", "shortCiteRegEx": "Neal", "year": 1993}, {"title": "A stochastic quasiNewton method for online convex optimization", "author": ["N.N. Schraudolph", "J. Yu", "S. G\u00fcnter"], "venue": "Proc. 11 Intl. Conf. Artificial Intelligence and Statistics (AIstats),", "citeRegEx": "Schraudolph et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Schraudolph et al\\.", "year": 2007}, {"title": "Maximum likelihood estimation using the empirical fisher information matrix", "author": ["W.A. Scott"], "venue": "Journal of Statistical Computation and Simulation,", "citeRegEx": "Scott,? \\Q2002\\E", "shortCiteRegEx": "Scott", "year": 2002}, {"title": "Low rank updates for the cholesky decomposition", "author": ["M. Seeger"], "venue": "Technical report, University of California Berkeley,", "citeRegEx": "Seeger,? \\Q2004\\E", "shortCiteRegEx": "Seeger", "year": 2004}, {"title": "Bayesian learning via stochastic gradient langevin dynamics", "author": ["M. Welling", "Y.W. Teh"], "venue": "In Proceedings of the 28th International Conference on Machine Learning (ICML),", "citeRegEx": "Welling and Teh,? \\Q2011\\E", "shortCiteRegEx": "Welling and Teh", "year": 2011}], "referenceMentions": [{"referenceID": 2, "context": "In fact, the intriguing results of Bottou and Bousquet (2008) seem to indicate that in terms of \u201cnumber of bits learned per unit of computation\u201d, an algorithm as simple as stochastic gradient descent is almost optimally efficient.", "startOffset": 35, "endOffset": 62}, {"referenceID": 10, "context": "A first attempt in this direction was proposed by Welling and Teh (2011) where the authors show that (uncorrected) Langevin dynamics with stochastic gradients (SGLD) will sample from the correct posterior distribution when the stepsizes are annealed to zero at a certain rate.", "startOffset": 50, "endOffset": 73}, {"referenceID": 10, "context": "A first attempt in this direction was proposed by Welling and Teh (2011) where the authors show that (uncorrected) Langevin dynamics with stochastic gradients (SGLD) will sample from the correct posterior distribution when the stepsizes are annealed to zero at a certain rate. While SGLD succeeds in (asymptotically) generating samples from the posterior at O(n) computational cost with (n N) it\u2019s mixing rate is unnecessarily slow. This can be traced back to its lack of a proper pre-conditioner: SGLD takes large steps in directions of small variance and reversely, small steps in directions of large variance which hinders convergence of the Markov chain. Our work builds on top of Welling and Teh (2011). We leverage the \u201cBayesian Central Limit Theorem\u201d which states that when N is large (and under certain conditions) the posterior will be well approximated by a normal distribution.", "startOffset": 50, "endOffset": 708}, {"referenceID": 7, "context": "(Schraudolph et al., 2007)) but in such a way that the randomness introduced in the subsampling process is used to sample from the posterior distribution when we arrive at its mode.", "startOffset": 0, "endOffset": 26}, {"referenceID": 8, "context": "(Scott, 2002).", "startOffset": 0, "endOffset": 13}, {"referenceID": 1, "context": "The theory of adaptive MCMC (Andrieu & Thoms, 2009) or two time scale stochastic approximations (Borkar, 1997) might hold the key to such a proof which we leave for future work.", "startOffset": 96, "endOffset": 110}, {"referenceID": 10, "context": "where we would stop changing \u00ce1) after a fixed number of iterations) this would according to the results from Welling and Teh (2011) lead to a valid Markov chain for posterior sampling.", "startOffset": 110, "endOffset": 133}, {"referenceID": 9, "context": "A more numerically stable alternative is to update Cholesky factors (Seeger, 2004).", "startOffset": 68, "endOffset": 82}, {"referenceID": 6, "context": "We compare the algorithm to Hamiltonian Monte Carlo sampling (Neal, 1993) and to SGLD (Welling & Teh, 2011).", "startOffset": 61, "endOffset": 73}, {"referenceID": 6, "context": "Autocorrelation time is defined as 1 + 2 \u2211\u221e s=1 \u03c1(s) with \u03c1(s) the autocorrelation at lag s Neal (1993).", "startOffset": 92, "endOffset": 104}], "year": 2012, "abstractText": "In this paper we address the following question: \u201cCan we approximately sample from a Bayesian posterior distribution if we are only allowed to touch a small mini-batch of data-items for every sample we generate?\u201d. An algorithm based on the Langevin equation with stochastic gradients (SGLD) was previously proposed to solve this, but its mixing rate was slow. By leveraging the Bayesian Central Limit Theorem, we extend the SGLD algorithm so that at high mixing rates it will sample from a normal approximation of the posterior, while for slow mixing rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic gradients) and as such an efficient optimizer during burn-in.", "creator": "LaTeX with hyperref package"}}}