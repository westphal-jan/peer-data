{"id": "1206.6389", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Poisoning Attacks against Support Vector Machines", "abstract": "We investigate a family of poisoning attacks against Support Vector Machines (SVM). Such attacks inject specially crafted training data that increases the SVM's test error. Central to the motivation for these attacks is the fact that most learning algorithms assume that their training data comes from a natural or well-behaved distribution. However, this assumption does not generally hold in security-sensitive settings. As we demonstrate, an intelligent adversary can, to some extent, predict the change of the SVM's decision function due to malicious input and use this ability to construct malicious data.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (504kb)", "http://arxiv.org/abs/1206.6389v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"], ["v2", "Fri, 20 Jul 2012 12:33:21 GMT  (184kb,D)", "http://arxiv.org/abs/1206.6389v2", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"], ["v3", "Mon, 25 Mar 2013 10:16:36 GMT  (184kb,D)", "http://arxiv.org/abs/1206.6389v3", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG cs.CR stat.ML", "authors": ["battista biggio", "blaine nelson", "pavel laskov"], "accepted": true, "id": "1206.6389"}, "pdf": {"name": "1206.6389.pdf", "metadata": {"source": "META", "title": "Poisoning Attacks against Support Vector Machines", "authors": ["Battista Biggio", "Blaine Nelson", "Pavel Laskov"], "emails": ["battista.biggio@diee.unica.it", "blaine.nelson@wsii.uni-tuebingen.de", "pavel.laskov@uni-tuebingen.de"], "sections": [{"heading": null, "text": "The proposed attack uses a gradient ascent strategy, in which the gradient is calculated based on the properties of the optimal solution of the SVM. This method can be cornered and allows to construct the entrance space attack even for nonlinear nuclei. We have experimentally demonstrated that our gradient ascent method reliably identifies good local maxima of the non-convex validation error interface, which significantly increases the test error of the classifier."}, {"heading": "1. Introduction", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to put themselves into another world, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they are able to put themselves into another world, in which they are able to put themselves into another world, in which they are able to move, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which they live, in which they, in which they,"}, {"heading": "2. Poisoning attack on SVM", "text": "We assume that the SVM was trained on the basis of a dataset Dtr = {xi, yi} ni = 1, xi-Rd. According to standard notation, K denotes the matrix of core values between two dot sets, Q = yy > K denotes the labeled version of K and \u03b1 the dual variables of SVM corresponding to the respective training points. Depending on the value of \u03b1i, the training points are denoted as edge support vectors (0 < \u03b1i < C, set S), error support vectors (\u03b1i = C, set E) and reserve points (\u03b1i = 0, set R). Subsequently, the lower case letters s, e, r are used to indicate the corresponding parts of vectors or matrices; e.g. Qss denotes the edge support vector submatrix of Q."}, {"heading": "2.1. Main derivation", "text": "For a poisoning attack, the target of the attacker is to find a point (xc, yc) whose addition to Dtr reduces the classification accuracy of the SVM to a maximum. Choosing the attack point is arbitrary, but fixed. We refer to the class of this chosen designation as the attack category and the other than the attacked class.The attacker assumes that he has a validation dataset of Dval = {xk, yk} mk = 1 and maximizes the loss that has arisen on Dval by the SVM. (xc, yc): max xc L (xc) = m: k = 1 \u2212 ykfxc) mk = 1 (gk) + (1) In this section, we assume the role of the attacker and develop a method to optimize xc with this object.First, we explicitly take into account all conditions influenced by Qc."}, {"heading": "2.2. Kernelization", "text": "Equation (10) shows that the gradient of the objective function with iteration k can depend on the target point x (p) c = x (p \u2212 1) c + tu only by the gradients of the matrix Q. This depends in particular on the selected kernel. We report below on the expressions of these gradients for three common cores. \u2022 Linear kernel: \u2202 Kic \u2202 u = \u2202 (xi \u00b7 x (p) c) \u2202 u = txi \u2022 polynomial kernel: \u2202 Kic \u2202 u = \u2202 (xi \u00b7 x (p) c + R) d 20s u = d (xi \u00b7 x (p) c + R) d \u2212 1txi \u2022 RBF kernel: 20s Kic \u2202 u = \u0430 e \u2212 \u03b3 2 | | xi \u2212 xc | 2 16th u = K (xi, x (p) c).The dependence on x (p) c (and hence on u) in the small gradients that cannot be replaced by an approximation to c (linear) is sufficient."}, {"heading": "2.3. Poisoning Attack Algorithm", "text": "The algorithmic details of the method described in Section 2.1 are initialized in Algorithm 1. In this algorithm, the attack vector x (0) c is initialized by cloning any point from the attacked class and flipping its label. In principle, each point is sufficiently deep within the attack point of the attacking class canAlgorithm 1 Poisoning Attack against SVM Input: Dtr, the training data; Dval, the validation data; yc, the class designation of the attack point; x (0) c, the initial attack point; t, the step size. Output: xc, the final attack point.1: {\u03b1i, b} \u2190 learn an SVM on Dtr. 2: k \u2190 0: 3: Repeat the SVM solution on Dtr."}, {"heading": "3. Experiments", "text": "The experimental evaluation presented in the following sections shows the behavior of our proposed method on an artificial two-dimensional dataset and evaluates its effectiveness on the classical MNIST dataset for handwritten digit recognition."}, {"heading": "3.1. Artificial data", "text": "First, we consider a two-dimensional data generation model in which each class follows a Gaussian distribution with mean and covariance matrices given by \u00b5 \u2212 = [\u2212 1.5, 0], \u00b5 + = [1.5, 0], \u03a3 \u2212 = \u03a3 + = 0.6I. The points from the negative distribution are randomly assigned the label \u2212 1 (shown as red in the following numbers) and otherwise + 1 (shown as blue) for this purpose, a random point of the blue class is selected and its label is inverted to serve as the starting point for our method. Our gradient ascent method is then used to refine this attack until its final state is fulfilled. The attack path is represented as a black line in Fig. 1 for the linear core (top two plots) and the BF range."}, {"heading": "3.2. Real data", "text": "In fact, the fact is that most of them will be able to be in a position to be in what they are in."}, {"heading": "4. Conclusions and Future Work", "text": "The poisoning attack in this paper is the first step towards the safety analysis of the SVM with respect to the acquired data. Although our Graded Ascent Method is probably a robust algorithmic method, it has a surprisingly large impact on the empirical classification. The presented attack method also shows the possibility of assessing the effects of transformations in the entrance area. Such influences can facilitate the practical implementation of evasive strategies."}, {"heading": "Acknowledgments", "text": "This work was supported by a grant awarded to B. Biggio by the Region Autonoma della Sardegna, PO Sardegna FSE 2007-2013, L.R. 7 / 2007 \"Promotion of scientific research and technological innovation in Sardinia.\" The authors would also like to recognize the Alexander von Humboldt Foundation and the Heisenberg Scholarship of the German Research Foundation (DFG) for the financial support of this research."}], "references": [{"title": "Can machine learning be secure", "author": ["Barreno", "Marco", "Nelson", "Blaine", "Sears", "Russell", "Joseph", "Anthony D", "J.D. Tygar"], "venue": "In Proceedings of the ACM Symposium on Information, Computer and Communications Security (ASIACCS),", "citeRegEx": "Barreno et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Barreno et al\\.", "year": 2006}, {"title": "The security of machine learning", "author": ["Barreno", "Marco", "Nelson", "Blaine", "Joseph", "Anthony D", "J.D. Tygar"], "venue": "Machine Learning,", "citeRegEx": "Barreno et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Barreno et al\\.", "year": 2010}, {"title": "Multiple classifier systems for robust classifier design in adversarial environments", "author": ["Biggio", "Battista", "Fumera", "Giorgio", "Roli", "Fabio"], "venue": "International Journal of Machine Learning and Cybernetics,", "citeRegEx": "Biggio et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Biggio et al\\.", "year": 2010}, {"title": "Statistical fraud detection: A review", "author": ["Bolton", "Richard J", "Hand", "David J"], "venue": "Journal of Statistical Science,", "citeRegEx": "Bolton et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Bolton et al\\.", "year": 2002}, {"title": "Nash equilibria of static prediction games", "author": ["Br\u00fcckner", "Michael", "Scheffer", "Tobias"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Br\u00fcckner et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Br\u00fcckner et al\\.", "year": 2009}, {"title": "Incremental and decremental support vector machine learning", "author": ["Cauwenberghs", "Gert", "Poggio", "Tomaso"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Cauwenberghs et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Cauwenberghs et al\\.", "year": 2001}, {"title": "Detection and analysis of drive-by-download attacks and malicious JavaScript code", "author": ["M. Cova", "C. Kruegel", "G. Vigna"], "venue": "In International Conference on World Wide Web (WWW), pp", "citeRegEx": "Cova et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cova et al\\.", "year": 2010}, {"title": "ZOZZLE: Fast and precise in-browser JavaScript malware detection", "author": ["C. Curtsinger", "B. Livshits", "B. Zorn", "C. Seifert"], "venue": "In USENIX Security Symposium,", "citeRegEx": "Curtsinger et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Curtsinger et al\\.", "year": 2011}, {"title": "Learning to classify with missing and corrupted features", "author": ["O. Dekel", "O. Shamir", "L. Xiao"], "venue": "Machine Learning,", "citeRegEx": "Dekel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2010}, {"title": "A sense of self for unix processes", "author": ["Forrest", "Stephanie", "Hofmeyr", "Steven A", "Somayaji", "Anil", "Longstaff", "Thomas A"], "venue": "In Proceedings of the IEEE Symposium on Security and Privacy,", "citeRegEx": "Forrest et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Forrest et al\\.", "year": 1996}, {"title": "Nightmare at test time: Robust learning by feature deletion", "author": ["A. Globerson", "S. Roweis"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Globerson and Roweis,? \\Q2006\\E", "shortCiteRegEx": "Globerson and Roweis", "year": 2006}, {"title": "Online anomaly detection under adversarial impact", "author": ["Kloft", "Marius", "Laskov", "Pavel"], "venue": "In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Kloft et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kloft et al\\.", "year": 2010}, {"title": "Static detection of malicious JavaScript-bearing PDF documents", "author": ["Laskov", "Pavel", "\u0160rndi\u0107", "Nedim"], "venue": "In Proceedings of the Annual Computer Security Applications Conference (ACSAC),", "citeRegEx": "Laskov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Laskov et al\\.", "year": 2011}, {"title": "Handbook of matrices", "author": ["L\u00fctkepohl", "Helmut"], "venue": null, "citeRegEx": "L\u00fctkepohl and Helmut.,? \\Q1996\\E", "shortCiteRegEx": "L\u00fctkepohl and Helmut.", "year": 1996}, {"title": "SpamBayes: Effective open-source, Bayesian based, email classification system", "author": ["Meyer", "Tony A", "Whateley", "Brendon"], "venue": "In Proceedings of the Conference on Email and Anti-Spam (CEAS),", "citeRegEx": "Meyer et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Meyer et al\\.", "year": 2004}, {"title": "Cujo: Efficient detection and prevention of drive-by-download attacks", "author": ["K. Rieck", "T. Kr\u00fcger", "A. Dewald"], "venue": "In Proceedings of the Annual Computer Security Applications Conference (ACSAC),", "citeRegEx": "Rieck et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Rieck et al\\.", "year": 2010}, {"title": "A behaviorbased approach to securing email systems. In Mathematical Methods, Models and Architectures for Computer Networks", "author": ["Stolfo", "Salvatore J", "Hershkop", "Shlomo", "Wang", "Ke", "Nimeskern", "Olivier", "Hu", "Chia-Wei"], "venue": "Security. Springer-Verlag,", "citeRegEx": "Stolfo et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Stolfo et al\\.", "year": 2003}, {"title": "Convex learning with invariances", "author": ["C.H. Teo", "A. Globerson", "S. Roweis", "A. Smola"], "venue": "In Advances in Neural Information Proccessing Systems (NIPS),", "citeRegEx": "Teo et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Teo et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "In fact, learning approaches have already been used or proposed as solutions to a number of such security-sensitive tasks including spam, worm, intrusion and fraud detection (Meyer & Whateley, 2004; Biggio et al., 2010; Stolfo et al., 2003; Forrest et al., 1996; Bolton & Hand, 2002; Cova et al., 2010; Rieck et al., 2010; Curtsinger et al., 2011; Laskov & \u0160rndi\u0107, 2011).", "startOffset": 174, "endOffset": 370}, {"referenceID": 16, "context": "In fact, learning approaches have already been used or proposed as solutions to a number of such security-sensitive tasks including spam, worm, intrusion and fraud detection (Meyer & Whateley, 2004; Biggio et al., 2010; Stolfo et al., 2003; Forrest et al., 1996; Bolton & Hand, 2002; Cova et al., 2010; Rieck et al., 2010; Curtsinger et al., 2011; Laskov & \u0160rndi\u0107, 2011).", "startOffset": 174, "endOffset": 370}, {"referenceID": 9, "context": "In fact, learning approaches have already been used or proposed as solutions to a number of such security-sensitive tasks including spam, worm, intrusion and fraud detection (Meyer & Whateley, 2004; Biggio et al., 2010; Stolfo et al., 2003; Forrest et al., 1996; Bolton & Hand, 2002; Cova et al., 2010; Rieck et al., 2010; Curtsinger et al., 2011; Laskov & \u0160rndi\u0107, 2011).", "startOffset": 174, "endOffset": 370}, {"referenceID": 6, "context": "In fact, learning approaches have already been used or proposed as solutions to a number of such security-sensitive tasks including spam, worm, intrusion and fraud detection (Meyer & Whateley, 2004; Biggio et al., 2010; Stolfo et al., 2003; Forrest et al., 1996; Bolton & Hand, 2002; Cova et al., 2010; Rieck et al., 2010; Curtsinger et al., 2011; Laskov & \u0160rndi\u0107, 2011).", "startOffset": 174, "endOffset": 370}, {"referenceID": 15, "context": "In fact, learning approaches have already been used or proposed as solutions to a number of such security-sensitive tasks including spam, worm, intrusion and fraud detection (Meyer & Whateley, 2004; Biggio et al., 2010; Stolfo et al., 2003; Forrest et al., 1996; Bolton & Hand, 2002; Cova et al., 2010; Rieck et al., 2010; Curtsinger et al., 2011; Laskov & \u0160rndi\u0107, 2011).", "startOffset": 174, "endOffset": 370}, {"referenceID": 7, "context": "In fact, learning approaches have already been used or proposed as solutions to a number of such security-sensitive tasks including spam, worm, intrusion and fraud detection (Meyer & Whateley, 2004; Biggio et al., 2010; Stolfo et al., 2003; Forrest et al., 1996; Bolton & Hand, 2002; Cova et al., 2010; Rieck et al., 2010; Curtsinger et al., 2011; Laskov & \u0160rndi\u0107, 2011).", "startOffset": 174, "endOffset": 370}, {"referenceID": 17, "context": "In response to the threat of adversarial data manipulation, several proposed learning methods explicitly account for certain types of corrupted data (Globerson & Roweis, 2006; Teo et al., 2008; Br\u00fcckner & Scheffer, 2009; Dekel et al., 2010).", "startOffset": 149, "endOffset": 240}, {"referenceID": 8, "context": "In response to the threat of adversarial data manipulation, several proposed learning methods explicitly account for certain types of corrupted data (Globerson & Roweis, 2006; Teo et al., 2008; Br\u00fcckner & Scheffer, 2009; Dekel et al., 2010).", "startOffset": 149, "endOffset": 240}, {"referenceID": 0, "context": "Poisoning attacks have been previously studied only for simple anomaly detection methods (Barreno et al., 2006; Rubinstein et al., 2009; Kloft & Laskov, 2010).", "startOffset": 89, "endOffset": 158}], "year": 2012, "abstractText": "We investigate a family of poisoning attacks against Support Vector Machines (SVM). Such attacks inject specially crafted training data that increases the SVM\u2019s test error. Central to the motivation for these attacks is the fact that most learning algorithms assume that their training data comes from a natural or well-behaved distribution. However, this assumption does not generally hold in security-sensitive settings. As we demonstrate, an intelligent adversary can, to some extent, predict the change of the SVM\u2019s decision function due to malicious input and use this ability to construct malicious data. The proposed attack uses a gradient ascent strategy in which the gradient is computed based on properties of the SVM\u2019s optimal solution. This method can be kernelized and enables the attack to be constructed in the input space even for non-linear kernels. We experimentally demonstrate that our gradient ascent procedure reliably identifies good local maxima of the non-convex validation error surface, which significantly increases the classifier\u2019s test error.", "creator": "LaTeX with hyperref package"}}}