{"id": "1206.6395", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Convergence Rates for Differentially Private Statistical Estimation", "abstract": "Differential privacy is a cryptographically-motivated definition of privacy which has gained significant attention over the past few years. Differentially private solutions enforce privacy by adding random noise to a function computed over the data, and the challenge in designing such algorithms is to control the added noise in order to optimize the privacy-accuracy-sample size tradeoff.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (346kb)", "http://arxiv.org/abs/1206.6395v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG cs.CR stat.ML", "authors": ["kamalika chaudhuri", "daniel j hsu"], "accepted": true, "id": "1206.6395"}, "pdf": {"name": "1206.6395.pdf", "metadata": {"source": "CRF", "title": "Convergence Rates for Differentially Private Statistical Estimation", "authors": ["Kamalika Chaudhuri", "Daniel Hsu"], "emails": ["kamalika@cs.ucsd.edu", "dahsu@microsoft.com"], "sections": [{"heading": null, "text": "This paper examines differential-private statistical estimates and shows upper and lower limits of convergence rates of differentiated private approaches to statistical estimators. Our results show a formal link between differential privacy and the concept of Gross Error Sensitivity (GES) in robust statistics by showing that the convergence rate of any differentiated private approach to an estimator that is correct across a large class of distributions must grow with the GES of the estimator. We then set an upper limit for the convergence rate of a differentiated private approach to an estimator with limited reach and limited GES. We show that the marginal condition is necessary if we want to ensure a strict form of differential privacy."}, {"heading": "1. Introduction", "text": "It is a strong, cryptographically motivated definition of privacy that has attracted significant attention over the past few years (McSherry & Mironov, 2009; appearing in Proceedings of the 29th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012). Copyright 2012 by author (s) / owner (s). Chaudhuri et al., 2011; Friedman & Schuster, 2010; Mohammed et al., 2011) In differentiated private solutions, privacy is guaranteed by ensuring that the participation of an individual in a database does not alter the outcome of a private algorithm by much random noise. This is typically achieved by either adding to the sensitive input data or issuing some functions, such as a classifier, calculated on the sensitive data. While this guarantees privacy for most statistical and machine learning tasks, there is a subsequent loss of statistical efficiency in terms of the number of samples needed to challenge accuracy."}, {"heading": "2. Preliminaries", "text": "The aim of this work is to investigate the conditions under which we can find private approaches to estimators. The concept of privacy we use is differential privacy (Dwork et al., 2006b; a).Definition 1. A (randomized) algorithm A, which is values in a range S (\u03b1, \u03b4) -differential private if for all S S S, and all data sets D and D \u00b2, which differ in a single entry, PrA (D).S] \u2264 e\u03b1PrA [A \u2032).PrA [\u00b7] is the distribution to S [\u00b7] caused by the output of A given data sets. A (randomized) algorithm A is \u03b1-differentiated private if they (\u03b1, 0) -differentiated private.Here we are."}, {"heading": "3. Lower Bounds", "text": "We begin by setting lower limits for the convergence rate of each differentiated private approach to a statistical functional T (F)."}, {"heading": "3.1. Lower Bounds based on Gross Error Sensitivity", "text": "We first show a lower limit on the error of all (\u03b1, \u03b4) different private approximations to T with respect to the gross error sensitivity of T at a distribution F. Theorem 1: \u2212 \u2212 \u2212 See all possible (0, 0, 0, 0, 23). Let F be the family of all distributions over X, and let A use any (1, 0, 0) differential private algorithms. For all n-N and all F-F there is a radius of 0 = 1 n \u00b7 d ln 2 2\u03b1 e and a distribution G-F with dTV (F, G)."}, {"heading": "3.2. Lower Bounds as a Function of Range", "text": "Is the boundary in theorem 1 narrow? In other words, if T has a boundary for GES, can we calculate exact private approximations of T (F) for all distributions F over a range? Next, we show that at least for (\u03b1, 0) differential privacy theorem 1 is not narrow; if we want to calculate differentiated private and accurate estimates of T (F) for all distributions F \u2212 n in a family in which T (F) can assume any value in a range, then the sample size must grow as a function of (F). Theorem 2: Let F be a family of distributions over X, and let A be arbitrary (\u03b1, 0) -differentiated private algorithms. Supply for all. There is some F-shaped solution that is such that T (F) exists."}, {"heading": "4. Upper Bounds", "text": "In this section we show that limited GES and limited range are sufficient conditions for the existence of a (\u03b1, \u03b4) differential private approximation to T. Our approximation uses the smooth sensitivity method of Nissim et al. (2007), for which we provide a new statistical analysis in Section 4.1 (Theorem 3). We also provide a specific analysis for the case of linear functionality in Appendix B.Let dH (D, D) denote the hamming distance between D and D (the number of entries in which D and D differ), and remember the following definitions from Nissim et al. (2007). Definition 4. Local sensitivity of a function: Rn \u2192 R for a dataset D-Rn, denoted by LS (B, D), isLS (B, D), isLS (D) \u2212 dH (D) \u2212 notal (D)."}, {"heading": "4.1. Estimator Based on Smooth Sensitivity", "text": "For a statistical functionality T, AT is the randomized estimator given by AT (Fn): = T (Fn) + SS\u03b2 (\u03b1, \u03b4) (T, Fn) \u00b7 2\u03b1 \u00b7 Z (3), where \u03b2 (\u03b1, \u03b4): = \u03b12 ln (1 / \u03b4) and Z is an independent random variable drawn from the standard laplace density pZ (z). AT essentially calculates T (Fn) and adds zero mean noise, using the scale determined by privacy parameters and smooth sensitivity. Computing SS\u03b2 (\u03b1, \u03b4) (T, Fn) can generally be considered a challenge -see Nissim et al. (2007); our result thus demonstrates an upper limit. The following guarantee is due to Nissim et al (2007)."}, {"heading": "4.2. Bounding the Smooth Sensitivity", "text": "Evidence of anamnesis 3 (see Appendix C) is based on the following problem, which has a high probability of SS\u03b2 (T, Fn) under conditions 1 and 2. Lemma 1. (In all probability, quantity is in state 1, and quantity is in state 2.5. (T, Fn) \u2264 max. (2) We now provide a method for constructing private approximations to M estimators that meet certain conditions. Unlike our estimators in section 4.1, these estimators are computationally efficient; however, they apply only to a more limited class of estimators. (M estimator) Anamnesis is given as a solution to the equation. (Fn) These estimators are applicable only to a more limited class of estimators. (M estimators)"}, {"heading": "6. Conclusions", "text": "The main findings shown here suggest that brobustness can be used as a criterion for the development of differentiated private statistical estimators, and also highlight the obstacles faced by even robust estimators when the parameter space is very large or unlimited. While our lower limits may seem pessimistic, they apply to estimators who are successful for a broad class of distributions. One way to avoid our lower limits would be to use priors that allow an estimator to perform well on some input distributions but not well on others; a future direction of research is to investigate how this can help to design private estimators more differentiated."}], "references": [{"title": "Privacy, accuracy, and consistency too: a holistic solution to contingency table release", "author": ["B. Barak", "K. Chaudhuri", "C. Dwork", "S. Kale", "F. McSherry", "K. Talwar"], "venue": "In PODS,", "citeRegEx": "Barak et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Barak et al\\.", "year": 2007}, {"title": "Practical privacy: the SuLQ framework", "author": ["A. Blum", "C. Dwork", "F. McSherry", "K. Nissim"], "venue": "In PODS,", "citeRegEx": "Blum et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Blum et al\\.", "year": 2005}, {"title": "Sample complexity bounds for differentially private learning", "author": ["K. Chaudhuri", "D. Hsu"], "venue": "In COLT,", "citeRegEx": "Chaudhuri and Hsu,? \\Q2011\\E", "shortCiteRegEx": "Chaudhuri and Hsu", "year": 2011}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A. Sarwate"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Chaudhuri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2011}, {"title": "Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator", "author": ["A. Dvoretzky", "J. Kiefer", "J. Wolfowitz"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "Dvoretzky et al\\.,? \\Q1956\\E", "shortCiteRegEx": "Dvoretzky et al\\.", "year": 1956}, {"title": "Differential privacy and robust statistics", "author": ["C. Dwork", "J. Lei"], "venue": "In STOC,", "citeRegEx": "Dwork and Lei,? \\Q2009\\E", "shortCiteRegEx": "Dwork and Lei", "year": 2009}, {"title": "Our data, ourselves: Privacy via distributed noise generation", "author": ["C. Dwork", "K. Kenthapadi", "F. McSherry", "I. Mironov", "M. Naor"], "venue": "In EUROCRYPT,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["C. Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "In TCC,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "Data mining with differential privacy", "author": ["A. Friedman", "A. Schuster"], "venue": "In KDD,", "citeRegEx": "Friedman and Schuster,? \\Q2010\\E", "shortCiteRegEx": "Friedman and Schuster", "year": 2010}, {"title": "Composition attacks and auxiliary information in data privacy", "author": ["S.R. Ganta", "S.P. Kasiviswanathan", "A. Smith"], "venue": "In KDD,", "citeRegEx": "Ganta et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ganta et al\\.", "year": 2008}, {"title": "Robust Statistics - The Approach", "author": ["F.R. Hampel", "E.M. Ronchetti", "P.J. Rousseeuw", "W.A. Stahel"], "venue": "Based on Influence Functions. Wiley,", "citeRegEx": "Hampel et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Hampel et al\\.", "year": 1986}, {"title": "On the geometry of differential privacy", "author": ["M. Hardt", "K. Talwar"], "venue": "In STOC,", "citeRegEx": "Hardt and Talwar,? \\Q2010\\E", "shortCiteRegEx": "Hardt and Talwar", "year": 2010}, {"title": "The tight constant in the DvoretzkyKiefer-Wolfowitz inequality", "author": ["P. Massart"], "venue": "Annals of Probability,", "citeRegEx": "Massart,? \\Q1990\\E", "shortCiteRegEx": "Massart", "year": 1990}, {"title": "Differentially private recommender systems: building privacy into the net", "author": ["F. McSherry", "I. Mironov"], "venue": "In KDD,", "citeRegEx": "McSherry and Mironov,? \\Q2009\\E", "shortCiteRegEx": "McSherry and Mironov", "year": 2009}, {"title": "Mechanism design via differential privacy", "author": ["F. McSherry", "K. Talwar"], "venue": "In FOCS,", "citeRegEx": "McSherry and Talwar,? \\Q2007\\E", "shortCiteRegEx": "McSherry and Talwar", "year": 2007}, {"title": "Differentially private data release for data mining", "author": ["N. Mohammed", "R. Chen", "B.C.M. Fung", "P.S. Yu"], "venue": "In KDD,", "citeRegEx": "Mohammed et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Mohammed et al\\.", "year": 2011}, {"title": "Smooth sensitivity and sampling in private data analysis", "author": ["K. Nissim", "S. Raskhodnikova", "A. Smith"], "venue": "In STOC,", "citeRegEx": "Nissim et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nissim et al\\.", "year": 2007}, {"title": "Learning in a large function space: Privacy-preserving mechanisms for svm learning", "author": ["Rubinstein", "Benjamin I. P", "Bartlett", "Peter L", "Huang", "Ling", "Taft", "Nina"], "venue": "CoRR, abs/0911.5708,", "citeRegEx": "Rubinstein et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Rubinstein et al\\.", "year": 2009}, {"title": "Privacy-preserving statistical estimation with optimal convergence rates", "author": ["A. Smith"], "venue": "In STOC,", "citeRegEx": "Smith,? \\Q2011\\E", "shortCiteRegEx": "Smith", "year": 2011}, {"title": "Differential privacy for clinical trial data: Preliminary evaluations", "author": ["D. Vu", "A. Slavkovic"], "venue": "In Data Mining Workshops,", "citeRegEx": "Vu and Slavkovic,? \\Q2009\\E", "shortCiteRegEx": "Vu and Slavkovic", "year": 2009}], "referenceMentions": [{"referenceID": 18, "context": "Previous work (Smith, 2011) on differentially private statistical estimation shows how to construct differentially private approximations to estimators which have asymptotic normality guarantees under fairly mild conditions.", "startOffset": 14, "endOffset": 27}, {"referenceID": 16, "context": "Our approximation preserves (\u03b1, \u03b4)-differential privacy, a relaxation of \u03b1differential privacy, and is based on the smoothed sensitivity method (Nissim et al., 2007).", "startOffset": 144, "endOffset": 165}, {"referenceID": 0, "context": ", 2006b), and has been used since in many works on privacy (e.g., Blum et al., 2005; Barak et al., 2007; Nissim et al., 2007; McSherry & Mironov, 2009; Chaudhuri et al., 2011).", "startOffset": 59, "endOffset": 175}, {"referenceID": 16, "context": ", 2006b), and has been used since in many works on privacy (e.g., Blum et al., 2005; Barak et al., 2007; Nissim et al., 2007; McSherry & Mironov, 2009; Chaudhuri et al., 2011).", "startOffset": 59, "endOffset": 175}, {"referenceID": 3, "context": ", 2006b), and has been used since in many works on privacy (e.g., Blum et al., 2005; Barak et al., 2007; Nissim et al., 2007; McSherry & Mironov, 2009; Chaudhuri et al., 2011).", "startOffset": 59, "endOffset": 175}, {"referenceID": 9, "context": ", 2006b) and is resistant to many attacks (Ganta et al., 2008) that succeed against some other definitions of privacy.", "startOffset": 42, "endOffset": 62}, {"referenceID": 18, "context": "In further work, Smith (2011) shows how to construct a differentially private approximationAT to certain types of statistical estimators T , and establishes asymptotic normality of his estimator provided certain conditions on T hold.", "startOffset": 17, "endOffset": 30}, {"referenceID": 18, "context": "In further work, Smith (2011) shows how to construct a differentially private approximationAT to certain types of statistical estimators T , and establishes asymptotic normality of his estimator provided certain conditions on T hold. We in contrast focus on finite sample bounds, with an aim towards characterizing the statistical properties of estimators that determine how closely they can be approximated with differential privacy. Lei (2011) considers M-estimation, and provides a simple and elegant differentially-private Mestimator which is statistically consistent.", "startOffset": 17, "endOffset": 446}, {"referenceID": 10, "context": "B-robustness has been studied in the robust statistics literature (Hampel et al., 1986; Huber, 1981), and plug-in estimators for B-robust functionals are considered to be resistant to outliers and changes in the input.", "startOffset": 66, "endOffset": 100}, {"referenceID": 16, "context": "Our approximation uses the smooth-sensitivity method of Nissim et al. (2007), for which we provide a new statistical analysis in Section 4.", "startOffset": 56, "endOffset": 77}, {"referenceID": 16, "context": "Our approximation uses the smooth-sensitivity method of Nissim et al. (2007), for which we provide a new statistical analysis in Section 4.1 (Theorem 3). We also provide a specific analysis for the case of linear functionals in Appendix B. Let dH(D,D \u2032) denote the Hamming distance between D and D\u2032 (the number of entries in which D and D\u2032 differ), and recall the following definitions from Nissim et al. (2007).", "startOffset": 56, "endOffset": 412}, {"referenceID": 16, "context": "Computing SS\u03b2(\u03b1,\u03b4)(T, Fn) in general can be computationally challenging \u2013see Nissim et al. (2007); our result thus demonstrates an upper bound.", "startOffset": 77, "endOffset": 98}, {"referenceID": 16, "context": "The following guarantee is due to Nissim et al. (2007).", "startOffset": 34, "endOffset": 55}, {"referenceID": 3, "context": "Previous works (Chaudhuri et al., 2011) and (Rubinstein et al.", "startOffset": 15, "endOffset": 39}, {"referenceID": 17, "context": ", 2011) and (Rubinstein et al., 2009) have provided differentially private and computationally efficient algorithms for M estimation under assumptions that are very similar", "startOffset": 12, "endOffset": 37}, {"referenceID": 16, "context": "The algorithm in Rubinstein et al. (2009), and one of the algorithms in Chaudhuri et al.", "startOffset": 17, "endOffset": 42}, {"referenceID": 3, "context": "(2009), and one of the algorithms in Chaudhuri et al. (2011) are based on the sensitivity method, while the main algorithm in Chaudhuri et al.", "startOffset": 37, "endOffset": 61}, {"referenceID": 3, "context": "(2009), and one of the algorithms in Chaudhuri et al. (2011) are based on the sensitivity method, while the main algorithm in Chaudhuri et al. (2011) is based on an objective perturbation method.", "startOffset": 37, "endOffset": 150}, {"referenceID": 3, "context": "(2009), and one of the algorithms in Chaudhuri et al. (2011) are based on the sensitivity method, while the main algorithm in Chaudhuri et al. (2011) is based on an objective perturbation method. While both algorithms are computationally efficient, both require explicit regularization. This is problematic in practice because determining the regularization parameter privately through differentially-private parameter-tuning requires extra data \u2013 for a more detailed discussion of this issue, see Chaudhuri et al. (2011). In contrast, our algorithm is based on the Exponential Mechanism, and does not have an explicit regularization parameter; instead we assume that \u03a8\u2032 is smooth, and our guarantees depend on the value of the derivative \u03a8\u2032(F, T\u03c8(F )).", "startOffset": 37, "endOffset": 522}], "year": 2012, "abstractText": "Differential privacy is a cryptographicallymotivated definition of privacy which has gained significant attention over the past few years. Differentially private solutions enforce privacy by adding random noise to a function computed over the data, and the challenge in designing such algorithms is to control the added noise in order to optimize the privacyaccuracy-sample size tradeoff. This work studies differentially-private statistical estimation, and shows upper and lower bounds on the convergence rates of differentially private approximations to statistical estimators. Our results reveal a formal connection between differential privacy and the notion of Gross Error Sensitivity (GES) in robust statistics, by showing that the convergence rate of any differentially private approximation to an estimator that is accurate over a large class of distributions has to grow with the GES of the estimator. We then provide an upper bound on the convergence rate of a differentially private approximation to an estimator with bounded range and bounded GES. We show that the bounded range condition is necessary if we wish to ensure a strict form of differential privacy.", "creator": "pdftk 1.44 - www.pdftk.com"}}}