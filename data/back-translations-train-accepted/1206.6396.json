{"id": "1206.6396", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Joint Optimization and Variable Selection of High-dimensional Gaussian Processes", "abstract": "Maximizing high-dimensional, non-convex functions through noisy observations is a notoriously hard problem, but one that arises in many applications. In this paper, we tackle this challenge by modeling the unknown function as a sample from a high-dimensional Gaussian process (GP) distribution. Assuming that the unknown function only depends on few relevant variables, we show that it is possible to perform joint variable selection and GP optimization. We provide strong performance guarantees for our algorithm, bounding the sample complexity of variable selection, and as well as providing cumulative regret bounds. We further provide empirical evidence on the effectiveness of our algorithm on several benchmark optimization problems.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (572kb)", "http://arxiv.org/abs/1206.6396v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["bo chen", "rui m castro", "andreas krause 0001"], "accepted": true, "id": "1206.6396"}, "pdf": {"name": "1206.6396.pdf", "metadata": {"source": "META", "title": "Joint Optimization and Variable Selection of High-dimensional Gaussian Processes", "authors": ["Bo Chen", "Rui M. Castro"], "emails": ["bchen3@caltech.edu", "rmcastro@tue.nl", "krausea@ethz.ch"], "sections": [{"heading": "1. Introduction", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "2. Model and Problem Statement", "text": "We assume that this function depends only on a subset of the domain variables, which we call active variables or active dimensions, referred to by A {1,.., D}. We are particularly interested in the case in which the set of active dimensions is relatively small in relation to the extrinsic dimension, namely d = \u2212 A | D. Without some regularity assumptions on f, optimization would be hopeless. We opt for the smoothness model of f, assuming that it is a sample of a Gaussian Process x (GP, Rasmussen & Williams (2006)) with zero meanings and a squaredeposit potential2, assuming that it is a sample from a Gaussian Process x."}, {"heading": "3. Variable Selection", "text": "We propose a two-step method for variable selection and function optimization, which is linked by the correct selection of certain parameters as described below. Variable selection is done using a hierarchical diagonal sampling level (HDS). After identifying active variables, we apply the GP-UCB algorithm (Srinivas et al., 2010) to optimize the considered active variables."}, {"heading": "3.1. Hierarchical Diagonal Sampling", "text": "In a nutshell, the HDS algorithm recursively splits the set of variables into two sets of the same size and continues to divide the sets containing more active variables. Specifically, HDS constructs a tree in which each node corresponds to a set of variables, meaning that each node can be uniquely identified by a subset of {1,.., D}. Each node that is not a leaf \u2212 has two children, corresponding to two disjunctional subsets of dimensions, each with half the size of the parent node. Each node in this tree can be defined in one of three states: active nodes contain at least one active dimension, inactive nodes are guaranteed (w.h.p) to contain no active dimensions, and for indefinite nodes we have insufficient evidence to draw any conclusions about their effectiveness. All nodes start indefinitely, but as more samples are collected, either one node becomes active, which implies that one of its groups is active, or at least one of its children is active."}, {"heading": "3.2. Finite Difference Sequential Likelihood Ratio Test (FDT)", "text": "We are looking at two hypotheses: the null hypothesis H0: I do not contain an active variable; the alternative H1: I do contain at least one active variable. However, let's start by looking at a non-sequential test approach to this problem. Finite Difference Testing: The key idea is this: If the node I does not contain active variables, then fI (x) should be constant, if the node I contains active variables, fI (x) should have a significant amount of variation because we vary vary x. Below, we formalize this intuition. Suppose we choose two random points x and x \u00b2, independently of each other. Hypothesis tests for GP active learning were proposed by Krause & Guestrin (2007). However, their approach does not apply to our variable selection setting."}, {"heading": "3.3. GP Seq. Likelihood Ratio Test (GPT)", "text": "Instead of making a dependency assumption, one can explicitly model the correlation between samples. (Knowledge of the underlying hypothesis completely determines the data distribution, as it follows a GP with known covariance structure determined by AI, a, where this kernel depends on a, the number of active variables in I. To avoid explicit dependence on node I when its identity is clear from the context, we first focus on a single node I. Given previous observations of x1: t \u2212 1 and y1: t \u2212 1, we can calculate the posterior distribution of yI t taking into account the respective hypothesis. yI t | xt: t: t \u2212 1, y1: t \u2212 1 \u00b2. N (\u00b5ta), (xt) 2).\u00b5ta (x).\u00b5ta (x)."}, {"heading": "4. Optimization", "text": "In principle, different algorithms can be used for this purpose. We consider the GP-UCB algorithm (Srinivas et al., 2010). GP-UCB is a greedy algorithm that iteratively selects the sample + 1 = argmax x. [\u2212 1,1] D\u00b5t (x) + \u03b2 1 / 2 t (x), where \u00b5t (x) and \u03c3 2 t (x) are the posterior mean and the variance at the input x, caused by the first samples x1,..., xt and the associated observations y1,. \u03b21., \u03b2T is an appropriate sequence of constants for accounting exploration (selection of uncertain x with large variance) and exploitation (selection x with large means), as specified in detail by Srinivas et al. (2010)."}, {"heading": "5. Experiments and Results", "text": "We compare HDS with a natural baseline called coordinate-wise sampling (CWS) = 10 optimized search results. CWS calculates finite differences along each dimension separately using the same number of samples and prints the dimensions with the greatest variance. We consider the case where the test function is a sample from a GP with a square exponential core to successfully restore all active dimensions. This favors the CWS algorithm compared to HDS functions sampled from a GP: We distinguish the total number of dimensions D {10, 20, 80, 200}, 2n, 0, 1, 0.25, 0.36}, and compare FDT, GPT, and CWS in terms of accuracy (recovery probability). Thresholds {1, 0} were optimized using rasters."}, {"heading": "6. Conclusions", "text": "We proposed HDS for variable selection and analyzed its sample complexity for the properties of a modular hypotheses subprogram. For a classic (non-sequential) subprogram, we demonstrated the limitations of sample complexity, which implied strong end-to-end performance guarantees for high-dimensional GP optimization. We also investigated two practical alternatives based on sequential hypotheses and demonstrated their effectiveness in several high-dimensional optimization problems. We believe our results provide important insights for solving high-dimensional optimization problems under uncertainty. Recognition. This work was supported in part by SNF funding 200021 137971, NSF IIS \u2212 0953413 and DARPA MSEE FA8650-11-17156."}], "references": [{"title": "Onlineto-confidence-set conversions and application to sparse stochastic bandits", "author": ["Y. Abbasi-Yadkori", "D. P\u00e1l", "C. Szepesv\u00e1ri"], "venue": "In AISTATS,", "citeRegEx": "Abbasi.Yadkori et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Abbasi.Yadkori et al\\.", "year": 2012}, {"title": "A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "author": ["E. Brochu", "V.M. Cora", "N. de Freitas"], "venue": "Arxiv preprint arXiv:1012.2599,", "citeRegEx": "Brochu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Brochu et al\\.", "year": 2010}, {"title": "Bandit theory meets compressed sensing for high dimensional stochastic linear bandit", "author": ["A. Carpentier", "R Munos"], "venue": null, "citeRegEx": "Carpentier and Munos,? \\Q2012\\E", "shortCiteRegEx": "Carpentier and Munos", "year": 2012}, {"title": "For most large underdetermined systems of linear equations the minimal l1-norm solution is also the sparsest solution", "author": ["D.L. Donoho"], "venue": "Communications on pure and applied mathematics,", "citeRegEx": "Donoho,? \\Q2006\\E", "shortCiteRegEx": "Donoho", "year": 2006}, {"title": "Towards gaussian processbased optimization with finite time horizon", "author": ["D. Ginsbourger", "R. Riche"], "venue": "Adv. ModelOr. Design & Analysis, pp", "citeRegEx": "Ginsbourger and Riche,? \\Q2010\\E", "shortCiteRegEx": "Ginsbourger and Riche", "year": 2010}, {"title": "Distilled sensing: Adaptive sampling for sparse detection and estimation", "author": ["J. Haupt", "R. Castro", "R. Nowak"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Haupt et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Haupt et al\\.", "year": 2011}, {"title": "Nonmyopic active learning of gaussian processes: An exploration\u2013exploitation approach", "author": ["A. Krause", "C. Guestrin"], "venue": "In ICML,", "citeRegEx": "Krause and Guestrin,? \\Q2007\\E", "shortCiteRegEx": "Krause and Guestrin", "year": 2007}, {"title": "Rodeo: sparse, greedy nonparametric regression", "author": ["J. Lafferty", "L. Wasserman"], "venue": "The Annals of Statistics,", "citeRegEx": "Lafferty and Wasserman,? \\Q2008\\E", "shortCiteRegEx": "Lafferty and Wasserman", "year": 2008}, {"title": "Automatic gait optimization with Gaussian process regression", "author": ["D. Lizotte", "T. Wang", "M. Bowling", "D. Schuurmans"], "venue": "In IJCAI, pp", "citeRegEx": "Lizotte et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Lizotte et al\\.", "year": 2007}, {"title": "Bayesian interpolation", "author": ["D.J.C. MacKay"], "venue": "Neural computation,", "citeRegEx": "MacKay,? \\Q1992\\E", "shortCiteRegEx": "MacKay", "year": 1992}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": null, "citeRegEx": "Rasmussen and Williams,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen and Williams", "year": 2006}, {"title": "Sequential analysis: tests and confidence intervals", "author": ["D. Siegmund"], "venue": null, "citeRegEx": "Siegmund,? \\Q1985\\E", "shortCiteRegEx": "Siegmund", "year": 1985}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "In ICML,", "citeRegEx": "Srinivas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "J Royal Stat Soc B, pp", "citeRegEx": "Tibshirani,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani", "year": 1996}], "referenceMentions": [{"referenceID": 8, "context": "This problem occurs in various domains, for instance when learning optimal control strategies for robots (Lizotte et al., 2007), or when optimizing industrial processes that depend on many variables.", "startOffset": 105, "endOffset": 127}, {"referenceID": 13, "context": "For example, Lasso (Tibshirani, 1996) tackles this combinatorial problem using an continuous approximation, which has been shown to be optimal under certain conditions (Donoho, 2006).", "startOffset": 19, "endOffset": 37}, {"referenceID": 3, "context": "For example, Lasso (Tibshirani, 1996) tackles this combinatorial problem using an continuous approximation, which has been shown to be optimal under certain conditions (Donoho, 2006).", "startOffset": 168, "endOffset": 182}, {"referenceID": 3, "context": "For example, Lasso (Tibshirani, 1996) tackles this combinatorial problem using an continuous approximation, which has been shown to be optimal under certain conditions (Donoho, 2006). Alternative models have been proposed to handle non-linear response functions. Automatic Relevance Determination (ARD, MacKay (1992)) is a Bayesian variable selection procedure that imposes a Gaussian prior on the bandwidths of the variables, which can be combined with a GP likelihood to handle non-linear functions.", "startOffset": 169, "endOffset": 317}, {"referenceID": 5, "context": "Also bearing similarities to our work is Distilled Sensing (Haupt et al., 2011), which attempts to quickly identify large portions of the variable space that are irrelevant, therefore reducing the search complexity as more data is collected, and effectively shedding the dependency on the extrinsic dimension.", "startOffset": 59, "endOffset": 79}, {"referenceID": 1, "context": "One line of work called Bayesian global optimization (Ginsbourger & Riche, 2010; Brochu et al., 2010) assumes the unknown function is sampled from a GP.", "startOffset": 53, "endOffset": 101}, {"referenceID": 12, "context": "In particular, the GP-UCB (Srinivas et al., 2010) algorithm has been shown to have sub-linear regret and work well emprically.", "startOffset": 26, "endOffset": 49}, {"referenceID": 0, "context": "Recently, the problem of joint variable selection and linear optimization has been tackled by (Abbasi-Yadkori et al., 2012), who exploit sparsity to alleviate the curse of dimensionality.", "startOffset": 94, "endOffset": 123}, {"referenceID": 12, "context": "After the identification of active variables, we apply the GP-UCB algorithm (Srinivas et al., 2010) to optimize over the variables deemed active.", "startOffset": 76, "endOffset": 99}, {"referenceID": 11, "context": "We now employ sequential hypothesis testing using the sequential likelihood ratio test (SLRT) as described in Siegmund (1985). This is an incremental procedure that sequentially computes the log likelihood ratio (LLR) between two hypotheses, and makes a decision once this ratio crosses two predetermined boundaries.", "startOffset": 110, "endOffset": 126}, {"referenceID": 12, "context": "We consider the GP-UCB algorithm (Srinivas et al., 2010).", "startOffset": 33, "endOffset": 56}, {"referenceID": 12, "context": ", \u03b2T is an appropriate sequence of constants for balancing exploration (choosing uncertain x with large variance) and exploitation (choosing x with large means), as specified in detail by Srinivas et al. (2010). For GP-UCB, strong performance guarantees are known: In particular, Theorem 2 of Srinivas et al.", "startOffset": 188, "endOffset": 211}, {"referenceID": 12, "context": ", \u03b2T is an appropriate sequence of constants for balancing exploration (choosing uncertain x with large variance) and exploitation (choosing x with large means), as specified in detail by Srinivas et al. (2010). For GP-UCB, strong performance guarantees are known: In particular, Theorem 2 of Srinivas et al. (2010) bounds the cumulative regret of GP-UCB in terms of the maximum information gain \u03b3T obtainable by observing f at an arbitrary set of T inputs x1:T .", "startOffset": 188, "endOffset": 316}, {"referenceID": 12, "context": "When HDS is successful, Theorem 2 of Srinivas et al. (2010) guarantees a sub-linear regret bound for GP-UCB.", "startOffset": 37, "endOffset": 60}], "year": 2012, "abstractText": "Maximizing high-dimensional, non-convex functions through noisy observations is a notoriously hard problem, but one that arises in many applications. In this paper, we tackle this challenge by modeling the unknown function as a sample from a high-dimensional Gaussian process (GP) distribution. Assuming that the unknown function only depends on few relevant variables, we show that it is possible to perform joint variable selection and GP optimization. We provide strong performance guarantees for our algorithm, bounding the sample complexity of variable selection, and as well as providing cumulative regret bounds. We further provide empirical evidence on the effectiveness of our algorithm on several benchmark optimization problems.", "creator": "LaTeX with hyperref package"}}}