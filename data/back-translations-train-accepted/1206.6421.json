{"id": "1206.6421", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Structured Learning from Partial Annotations", "abstract": "Structured learning is appropriate when predicting structured outputs such as trees, graphs, or sequences. Most prior work requires the training set to consist of complete trees, graphs or sequences. Specifying such detailed ground truth can be tedious or infeasible for large outputs. Our main contribution is a large margin formulation that makes structured learning from only partially annotated data possible. The resulting optimization problem is non-convex, yet can be efficiently solve by concave-convex procedure (CCCP) with novel speedup strategies. We apply our method to a challenging tracking-by-assignment problem of a variable number of divisible objects. On this benchmark, using only 25% of a full annotation we achieve a performance comparable to a model learned with a full annotation. Finally, we offer a unifying perspective of previous work using the hinge, ramp, or max loss for structured learning, followed by an empirical comparison on their practical performance.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (921kb)", "http://arxiv.org/abs/1206.6421v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["xinghua lou", "fred a hamprecht"], "accepted": true, "id": "1206.6421"}, "pdf": {"name": "1206.6421.pdf", "metadata": {"source": "META", "title": "Structured Learning from Partial Annotations", "authors": ["Xinghua Lou", "Fred A. Hamprecht"], "emails": ["xinghua.lou@iwr.uni-heidelberg.de", "fred.hamprecht@iwr.uni-heidelberg.de"], "sections": [{"heading": "1. Introduction", "text": "Considering a training set, structured learning extracts rules that allow the prediction of complex, structured outcomes from structured input. It has improved the conceptual clarity of various tasks such as image segmentation, graph matching, word alignment, grammatical marking, prediction of protein structures or cell tracking and increased their performance (see Bakir et al., 2006). However, most classic structured learning algorithms require a strong prerequisite: the training data with complex structure must be fully commented in order to apply this prediction. Published in the proceedings of the 29th International Conference on Machine Learning, Edinburgh, Scotland, United Kingdom, 2012. Copyright 2012 by the author / owner. Algorithms. This results in expensive, time-consuming data preparation and makes retraining very difficult. In this paper, we examine the problem of structured learning from partial comments. Our contributions are the suggestion of the new \"bridge function\" (Section 3.2), a synthesis of the large section (4), a large section (1), and a large section (4)."}, {"heading": "1.1. Prior Art", "text": "We build on important previous work on classifying multi-class systems with ambiguous labels, where each training sample has an exact, unknown label c *. However, the training set only includes one set of applicant labels c * for each observation, with c * c *. (Jin & Ghahramani, 2002) suggesting an EM-like algorithm that estimates the distribution of labels iteratively and classifies this distribution as previous. Recently (Cour et al., 2011), we proposed a convex loss for partial labels, which in turn resembles the one-for-all loss (Zhang, 2004). We will extend this loss to structured data and its properties in Section 3.2.This work is also closely related (Section 3.3) to structured learning with latent Variables (Yu & Joachims, 2009; Girshick et al., 2011)."}, {"heading": "2. Structured Learning from Partial Annotations", "text": "We want to learn from a partially commented training set {(xn, y \u0445 n) and Xn \u00b7 Yn: n = 1,..., N}. Here, xn is a structured input from a room Xn1. y * is a partially commented structured output that divides the structured output range Y into two groups: Y *, Y *, Y *, Y *, Y *, Y *. Y * includes all output that is compatible with a partial annotation y *, while Y * includes all structured output that is not compatible with the partial annotation, see fig. 1."}, {"heading": "3. Large Margin Learning from Partial Annotations", "text": "The aim of learning is to find a parameter vector w that minimizes the weighted sum of a regularization term and the empirical loss: min wJ (w): = \u03bb\u0442 (w) + 1N N \u2211 n = 1 L (xn, y \u0445 n; w), (1) The particular choice of regularization and loss function leads to different learning methods, whereby the square norm or hinge loss leads to a struktSVM (Tsochantaridis et al., 2006), which is particularly popular with structured output learning. In the following, we propose two formulations for learning with a large learning margin from partial annotations. The first is a formal generalization of one-against-learning to-1 indication that the cardinality of spaces Xn, Yn is typically different for each input. Structured data is instructive, but not practicable in practice."}, {"heading": "3.1. Formulation I: One-Versus-All", "text": "The recently proposed \"Convex loss for partial labels\" (CLPL) (Cour et al., 2011) has favorable properties, including convexity, consistency, and demonstrably high performance for flat (unstructured) results. The use of notations in Table 1, CLPL can therefore be expressed as Lclpl (x, c; w) = l (1 | c; p) = l (x, c; w) + f (x, c; w). (2) Generalizing this loss to structured results givesLclpl \u2212 sl (x, y \u2212 sl; w) = l 1 | Y (x, y; w)."}, {"heading": "3.2. Formulation II: Pairwise Comparison", "text": "When formulated as a conventional multi-class learning problem, structured learning must distinguish a correct structured output from an exponential number of misstructured outputs. As a way out, structSVM (Tsochantaridis et al., 2006) penalizes small or negative margins (differences) between the score of the correct structured output and the highest score of all misstructured outputs. We follow the same argument by constructing a loss function that penalizes small margins between the current prediction (maximizer of the first term in loss below) and the best scoring incorrect prediction (maximizer of the second term in the following loss function): Lpair (x, y; w) = l (max y, y; w) \u2212 max y, Y \u2022 f (x, y; w) Note that this loss function is not convex, unlike the CLPL in Equation 3."}, {"heading": "3.3. Connection to structSVMs with Latent Variables", "text": "Although the loss in Eq.4 was motivated by multi-level learning with ambiguous terms, it has a very similar structure to the loss defined in the context of structured learning with latent variables. Specifically (Yu & Joachims, 2009), the problem is addressed when a learning sample (x, z *, h) consists of both observed variables z * Z and unknown hidden variables h * H. They suggest a hinged loss with latent variables: hinge (x, z *; w) = max (z, h)."}, {"heading": "3.4. Synthesis of Loss Functions", "text": "In fact, several other related loss functions have been proposed recently, including ramp and maximum losses. They can be summarized using a generic formulation: Lgeneric (x, y *; w) = closest ramp and maximum loss functions, as their members make a positive contribution to the loss. Accordingly, YR refers to a \"reward room\" because it contains the correct configuration and makes a negative contribution. Table 2 provides a summary of related loss functions and shows how they fit into our generic formulation. These loss functions have different characteristics. For example, although required for maximum losses and bridge losses, the operator can be dropped for ramp and hinge losses, provided it is a positive function."}, {"heading": "3.5. Large Margin Learning Objective", "text": "With a clear definition of the loss function in Equation 6, we now set about defining the learning target function. Let's take each loss function in Table 2 and insert it in Equation 1. We obtain our learning target asmin w\u03bb\u0442 (w) + 1N \u2211 n max y-YPn [f (xn, yn; w) + \u0445 (y-n, y)] P (w), convex \u2212 1 N-n max y-YRn [f (xn, y; w)] R (w), konvex (7) s.t. Any loss must be non-negative. Equation 8 is a subtraction of two convex functions, namely quantitative (w) + P (w) \u2212 R (w). Note that such structured learning problems are generally computationally expensive, because the maximizations contained therein must be solved with each iteration of the update w for each training test."}, {"heading": "4. Optimization with Bound Recycling", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Convex-Concave Problem and CCCP", "text": "The difference between two convex functions forms a convective optimization problem that can be solved by the CCCP method (Yuille & Rangarajan, 2003). In short, CCCP iterates between two steps: Step 1: At iteration t, estimate a linear upper limit for the concave function \u2212 R (w) using its subgradient at wt, namely v = \u2212 \u2202 wR (wt). Then < vt, w \u2212 wt > \u2212 R (wt) \u2265 \u2212 R (w), \u0445w (8) Step 2: Update the model at wt + 1 = argminwJ (w): = < vt, w \u2212 vt, w >. (9) The method is guaranteed to converge to a local minimum or saddle point (Yuille & Rangarajan, 2003). (Yu & Joachims, 2009) used this strategy to optimize its structured SVM with latable proximal velocity ()."}, {"heading": "4.2. Speeding Up CCCP with Bounds Recycling", "text": "iDe eeisrcnh-eaeaJnlhsrdcnlhUeaeaeaitnlhc nvo eeisn rf\u00fc ide eeisrcnh-eaeaeaJnlhsrcnlhsrteeaeaeaJnlrh-eaJnlhc-eaJnlhc-eaeaHnlhc) (.) D \"i\" s, \"he says."}, {"heading": "4.3. Solving Model Update in the Dual", "text": "In order to construct a lower boundary approximation for P (w), we follow the bundling minimization method of (Teo et al., 2010). In short, in some places we calculate the subgradient of P (w) and the corresponding offset, a = 1N, n, wf (xn, y, wk) (11) b = 1N, n [f (x, y, wk) + (y, y, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w."}, {"heading": "4.4. Pseudocode and Implementation Details", "text": "Pseudo code of our optimization method is presented in algorithm 1. We use t to index CCCP iterations and k to index lower limits. Line 8 shows the accumulation of limits that are reused each time in line 9. The approximation gap is the margin between the original target J, t (w) and its lower approximation, i.e. the minimum value of Eq. 13. We refer readers to (Teo et al., 2010) for more details. Finally, the algorithm ends when the decrease of target J, t (w) between two consecutive CCCP iterations is less than some thresholds. Matlab code is available to the public at http: / / xinghua-lou.org / research /.It is important to note that the non-negativity restriction on any empirical loss must not be violated."}, {"heading": "5. Experiments", "text": "Robust tracking is essential for molecular, cell, and developmental biology, among others. Recently (Lou & Hamprecht, 2011), structured cell tracking learning has been proposed that allows learning the parameters of an energy function from manually annotated tracks, resulting in significantly improved performance, especially when the number of parameters becomes too large. However, your learning strategy is based on classically structured learning and requires exhaustive assignments of image pairs, which is a tedious task at best and becomes impossible when faced with major problems."}, {"heading": "5.1. Model, Data and Comparison Setup", "text": "(Lou & Hamprecht, 2011) formulate tracking by assignment as a limited problem of binary energy minimization; a prior detection step finds potential cells / targets in two consecutive frames; on the basis of these detections, a series of possible events (such as motion, division, etc.) is compiled, which are described by \u03c6ec, c. \"The indicator variables yec, c\" indicate whether an event will be realized or not. Many events are mutually exclusive according to conservation laws: each detected cell must have a unique history and fate. In summary, taking into account the learned parameters w, a predicted tracking is achieved as a minimizer of min y f (x, y; w): = \"e\" e \"e\" E \"c\" c \"c\" c \"c\" c \"c\" c \"c. <\" c, \"c,\" c, \"c,\" we > yec, \"c\" (16) s.t \"c\" c \"c,\" c, \"c,\" c. \""}, {"heading": "5.2. Comparison to Structured Perceptron and Full Annotation", "text": "To make all the experiments comparable, the same precision (i.e. the approximation gap, see algorithm 1) was used for bundling minimizations and the method proposed here. Structured perceptron with partial annotations was trained until the task loss became zero and no early termination was used. Surprisingly, the model learned from partial annotations."}, {"heading": "5.3. Comparison of Surrogate Losses", "text": "Table 3 shows a comparison of different loss functions w.r.t. Predictive accuracy and runtime for the partially commented data. We see that bridge (here proposed) and hinge loss provide a very similar predictive performance, with slightly faster runtime of the former. Surprisingly, both ramp and maximum loss, despite their very similar formulations, show much lower accuracy (three times higher test losses), but allow for two or three times faster training. Let us remember that Table 2 shows the crucial difference between maximum / ramp loss and hinge / bridge loss: the former searches throughout the space for the best configuration, while the latter only searches within a subspace consistent with the partial comment. Our result suggests that restricting the search to a feasible subspace compatible with the available annotations is critical to the accuracy of the learned model. To support this argument, we modify the search for the partial loss of the available ramp \u2212 is crucial for the accuracy of the learnable model."}, {"heading": "5.4. Comparison of Optimization Strategy", "text": "We compare our optimization strategy with the CCCP method of (Yu & Joachims, 2009), which does not use the limits of recycling and adaptive precision proposed here. In a lesion study, we also examine the effects of omitting the limits of recycling or / and adaptive precision. Fig.5 shows the convergence of objective function. All optimization methods converge with the same objective value. By using both limits of recycling and adaptive precision, we achieve an acceleration of about a factor 5. Note that we (Yu & Joachims, 2009) have implemented the CCCP method according to the BMRM method (Teo et al., 2010), whose complexity O (1) is actually better than that of the approximate bundling method used in the original paper O (1 3). Fig.6 shows the total number of limits calculated using CCCP Iterations."}, {"heading": "6. Conclusions and Outlook", "text": "We come to the conclusion that structured learning from partial annotations is practically possible. If the loss function and optimization strategy are chosen correctly, the model learned from partial annotations has an accuracy that is well comparable to the accuracy from exhaustive annotations.Overall, we experience a fundamental trade-off: In our experiments, successful learning from partial annotations becomes 0 200 400 600 800 1000 1200 00.511.51019 1227Runtime (s) O bjec tive Fun ctio n (Yu & Joachims, 2009) Our w / only Bounds Recycling Ours w / only Adaptive Precision Ours with BothFigure 5. Deciphering the objective function. 0 5 15 20 25 30 35010020030300400500600700CCCP IterationN umbe rof Bou nds Add (Yu & Joachims, 2009) Our w / only Bounds Recycling Ours w / Bounds Recyure Figure with BothFigure BothFigure."}], "references": [{"title": "Maximum margin semi-supervised learning for structured variables", "author": ["Y. Altun", "D. McAllester", "M. Belkin"], "venue": "In NIPS,", "citeRegEx": "Altun et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Altun et al\\.", "year": 2006}, {"title": "Predicting Structured Data", "author": ["G. Bakir", "T. Hofmann", "B. Schoelkopf", "A.J. Smola", "B. Taskar", "S.V.N. Vishwanathan"], "venue": null, "citeRegEx": "Bakir et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bakir et al\\.", "year": 2006}, {"title": "Tighter bounds for structured estimation", "author": ["C.B. Do", "Q. Le", "C.H. Teo", "O. Chapelle", "A. Smola"], "venue": "In NIPS,", "citeRegEx": "Do et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Do et al\\.", "year": 2008}, {"title": "Learning from partially annotated sequences", "author": ["E. Fernandes", "U. Brefeld"], "venue": "In ECML/PKDD,", "citeRegEx": "Fernandes and Brefeld,? \\Q2011\\E", "shortCiteRegEx": "Fernandes and Brefeld", "year": 2011}, {"title": "Object Detection with Grammar Models", "author": ["R.B. Girshick", "P.F. Felzenszwalb", "D. McAllester"], "venue": "In NIPS,", "citeRegEx": "Girshick et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Girshick et al\\.", "year": 2011}, {"title": "Learning from Candidate Labeling Sets", "author": ["L. Jie", "F. Orabona"], "venue": "In NIPS,", "citeRegEx": "Jie and Orabona,? \\Q2010\\E", "shortCiteRegEx": "Jie and Orabona", "year": 2010}, {"title": "Learning with Multiple Labels", "author": ["R. Jin", "Z. Ghahramani"], "venue": "In NIPS,", "citeRegEx": "Jin and Ghahramani,? \\Q2002\\E", "shortCiteRegEx": "Jin and Ghahramani", "year": 2002}, {"title": "Proximity control in bundle methods for convex nondifferentiable minimization", "author": ["K.C. Kiwiel"], "venue": "Math Program,", "citeRegEx": "Kiwiel,? \\Q1990\\E", "shortCiteRegEx": "Kiwiel", "year": 1990}, {"title": "Learning to model spatial dependency: Semi-supervised discriminative random fields", "author": ["C.H. Lee", "S. Wang", "F. Jiao", "D. Schuurmans", "R. Greiner"], "venue": "In NIPS,", "citeRegEx": "Lee et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2006}, {"title": "Structured learning for cell tracking", "author": ["X. Lou", "F.A. Hamprecht"], "venue": "In NIPS,", "citeRegEx": "Lou and Hamprecht,? \\Q2011\\E", "shortCiteRegEx": "Lou and Hamprecht", "year": 2011}, {"title": "Generalization Bounds and Consistency for Latent Structural Probit and Ramp Loss", "author": ["D. McAllester", "J. Keshet"], "venue": "In NIPS,", "citeRegEx": "McAllester and Keshet,? \\Q2011\\E", "shortCiteRegEx": "McAllester and Keshet", "year": 2011}, {"title": "Direct loss minimization for structured prediction", "author": ["McAllester", "David", "Hazan", "Tamir", "Keshet", "Joseph"], "venue": "In NIPS,", "citeRegEx": "McAllester et al\\.,? \\Q2010\\E", "shortCiteRegEx": "McAllester et al\\.", "year": 2010}, {"title": "More data means less inference: A pseudo-max approach to structured learning", "author": ["D. Sontag", "O. Meshi", "T.S. Jaakkola", "A. Globerson"], "venue": "In NIPS,", "citeRegEx": "Sontag et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sontag et al\\.", "year": 2010}, {"title": "Bundle methods for regularized risk", "author": ["C.H. Teo", "S.V.N. Vishwanthan", "A.J. Smola", "Q.V. Le"], "venue": "minimization. JMLR,", "citeRegEx": "Teo et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Teo et al\\.", "year": 2010}, {"title": "Large Margin Methods for Structured and Interdependent Output Variables", "author": ["I. Tsochantaridis", "T. Joachims", "T. Hofmann", "Y. Altun"], "venue": null, "citeRegEx": "Tsochantaridis et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2006}, {"title": "Structured output regression for detection with partial truncation", "author": ["A. Vedaldi", "A. Zisserman"], "venue": "In NIPS,", "citeRegEx": "Vedaldi and Zisserman,? \\Q2009\\E", "shortCiteRegEx": "Vedaldi and Zisserman", "year": 2009}, {"title": "A discriminative latent model of object classes and attributes", "author": ["Y. Wang", "G. Mori"], "venue": "In ECCV,", "citeRegEx": "Wang and Mori,? \\Q2010\\E", "shortCiteRegEx": "Wang and Mori", "year": 2010}, {"title": "Discriminative unsupervised learning of structured predictors", "author": ["L. Xu", "D. Wilkinson", "F. Southey", "D. Schuurmans"], "venue": "In ICML,", "citeRegEx": "Xu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2006}, {"title": "Learning Structural SVMs with Latent Variables", "author": ["C.N.J. Yu", "T. Joachims"], "venue": "In ICML,", "citeRegEx": "Yu and Joachims,? \\Q2009\\E", "shortCiteRegEx": "Yu and Joachims", "year": 2009}, {"title": "The Concave-Convex Procedure", "author": ["A.L. Yuille", "A. Rangarajan"], "venue": "Neural Comput,", "citeRegEx": "Yuille and Rangarajan,? \\Q2003\\E", "shortCiteRegEx": "Yuille and Rangarajan", "year": 2003}, {"title": "Statistical Analysis of Some Multi-category Large Margin Classification", "author": ["T. Zhang"], "venue": "Methods. JMLR,", "citeRegEx": "Zhang,? \\Q2004\\E", "shortCiteRegEx": "Zhang", "year": 2004}, {"title": "Latent hierarchical structural learning for object detection", "author": ["L.L. Zhu", "Y. Chen", "A. Yuille", "W. Freeman"], "venue": "In CVPR,", "citeRegEx": "Zhu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2010}, {"title": "Transductive support vector machines for structured variables", "author": ["A. Zien", "U. Brefeld", "T. Scheffer"], "venue": "In ICML,", "citeRegEx": "Zien et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zien et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 1, "context": "It has improved conceptual clarity of, and boosted performance in, different tasks such as image segmentation, graph matching, word alignment, grammatical tagging, protein structure prediction or cell tracking (see (Bakir et al., 2006) and references therein).", "startOffset": 215, "endOffset": 235}, {"referenceID": 20, "context": ", 2011) proposed convex loss for partial labels, which in turn resembles the one-versus-all loss (Zhang, 2004).", "startOffset": 97, "endOffset": 110}, {"referenceID": 4, "context": "3) to structured learning with latent variables (Yu & Joachims, 2009; Girshick et al., 2011).", "startOffset": 48, "endOffset": 92}, {"referenceID": 0, "context": "Finally, note that structured learning from partial annotations is different from semi-supervised or unsupervised structured learning (Altun et al., 2006; Xu et al., 2006; Zien et al., 2007).", "startOffset": 134, "endOffset": 190}, {"referenceID": 17, "context": "Finally, note that structured learning from partial annotations is different from semi-supervised or unsupervised structured learning (Altun et al., 2006; Xu et al., 2006; Zien et al., 2007).", "startOffset": 134, "endOffset": 190}, {"referenceID": 22, "context": "Finally, note that structured learning from partial annotations is different from semi-supervised or unsupervised structured learning (Altun et al., 2006; Xu et al., 2006; Zien et al., 2007).", "startOffset": 134, "endOffset": 190}, {"referenceID": 14, "context": "The particular choice of regularizer and loss function leads to different learning methods, with the squared norm and hinge loss, respectively, yielding a structSVM (Tsochantaridis et al., 2006), which is particularly popular in structured output learning.", "startOffset": 165, "endOffset": 194}, {"referenceID": 8, "context": "To circumvent this limitation, one could use pseudo-likelihood (maximizing the margin is similar to maximizing the likelihood ratio) to approximate this expectation as in (Lee et al., 2006).", "startOffset": 171, "endOffset": 189}, {"referenceID": 12, "context": "However, a recent study shows that this is only possible when the distribution of training sample is rich enough (Sontag et al., 2010).", "startOffset": 113, "endOffset": 134}, {"referenceID": 14, "context": "As a way out, structSVM (Tsochantaridis et al., 2006) penalizes small or negative margins (differences) between the score of the correct structured output and the highest score among any of the wrong structured outputs.", "startOffset": 24, "endOffset": 53}, {"referenceID": 14, "context": "(Tsochantaridis et al., 2006) suggest to adjust the penalty levied for high-scoring wrong predictions according to just how wrong they are, as measured by a user-defined task loss function \u2206(y\u2217, y).", "startOffset": 0, "endOffset": 29}, {"referenceID": 21, "context": "Loss Y Y Appeared in Literature hinge Y Y\u2217 (Yu & Joachims, 2009; Fernandes & Brefeld, 2011; Zhu et al., 2010; Vedaldi & Zisserman, 2009; Wang & Mori, 2010) ramp Y Y (Do et al.", "startOffset": 43, "endOffset": 155}, {"referenceID": 2, "context": ", 2010; Vedaldi & Zisserman, 2009; Wang & Mori, 2010) ramp Y Y (Do et al., 2008; Girshick et al., 2011) max Y\u25e6 Y (Jie & Orabona, 2010) bridge Y\u25e6 Y\u2217 This paper", "startOffset": 63, "endOffset": 103}, {"referenceID": 4, "context": ", 2010; Vedaldi & Zisserman, 2009; Wang & Mori, 2010) ramp Y Y (Do et al., 2008; Girshick et al., 2011) max Y\u25e6 Y (Jie & Orabona, 2010) bridge Y\u25e6 Y\u2217 This paper", "startOffset": 63, "endOffset": 103}, {"referenceID": 20, "context": "We refer the readers to (Zhang, 2004; McAllester & Keshet, 2011; McAllester et al., 2010) for more theoretical analysis on hinge/ramp loss.", "startOffset": 24, "endOffset": 89}, {"referenceID": 11, "context": "We refer the readers to (Zhang, 2004; McAllester & Keshet, 2011; McAllester et al., 2010) for more theoretical analysis on hinge/ramp loss.", "startOffset": 24, "endOffset": 89}, {"referenceID": 7, "context": "(Yu & Joachims, 2009) used this strategy to optimize their structured SVM with latent variables, with a proximal bundle method (Kiwiel, 1990) for Step 2.", "startOffset": 127, "endOffset": 141}, {"referenceID": 4, "context": "(Girshick et al., 2011) and (Jie & Orabona, 2010) coined a similar procedure and applied stochastic gradient descent to speed up the training.", "startOffset": 0, "endOffset": 23}, {"referenceID": 14, "context": "Structured learning is computationally expensive due to the repetitive maximization problems one has to solve at every iteration to compute the subgradients (Tsochantaridis et al., 2006; Teo et al., 2010).", "startOffset": 157, "endOffset": 204}, {"referenceID": 13, "context": "Structured learning is computationally expensive due to the repetitive maximization problems one has to solve at every iteration to compute the subgradients (Tsochantaridis et al., 2006; Teo et al., 2010).", "startOffset": 157, "endOffset": 204}, {"referenceID": 13, "context": "To construct a lower bound approximation for P (w), we follow the bundle minimization method from (Teo et al., 2010).", "startOffset": 98, "endOffset": 116}, {"referenceID": 14, "context": "n [f(x, \u0177;wk) + \u2206(y \u2217, \u0177)]\u2212 \u3008a,wk\u3009 (12) where \u0177 = arg maxy\u2208YP [f(x, y;wk) + \u2206(y \u2217, y)] is the expensive augmented inference problem (Tsochantaridis et al., 2006).", "startOffset": 132, "endOffset": 161}, {"referenceID": 13, "context": "Very similar to Theorem 2 in (Teo et al., 2010).", "startOffset": 29, "endOffset": 47}, {"referenceID": 13, "context": "We refer the readers to (Teo et al., 2010) for more details.", "startOffset": 24, "endOffset": 42}, {"referenceID": 13, "context": "Note that we implemented (Yu & Joachims, 2009)\u2019s CCCP procedure using the BMRM method (Teo et al., 2010) whose complexity O( 1 ) is actually better than that of the proximal bundle method used in the original paper, O( 1 3 ).", "startOffset": 86, "endOffset": 104}], "year": 2012, "abstractText": "Structured learning is appropriate when predicting structured outputs such as trees, graphs, or sequences. Most prior work requires the training set to consist of complete trees, graphs or sequences. Specifying such detailed ground truth can be tedious or infeasible for large outputs. Our main contribution is a large margin formulation that makes structured learning from only partially annotated data possible. The resulting optimization problem is non-convex, yet can be efficiently solve by concave-convex procedure (CCCP) with novel speedup strategies. We apply our method to a challenging trackingby-assignment problem of a variable number of divisible objects. On this benchmark, using only 25% of a full annotation we achieve a performance comparable to a model learned with a full annotation. Finally, we offer a unifying perspective of previous work using the hinge, ramp, or max loss for structured learning, followed by an empirical comparison on their practical performance.", "creator": "LaTeX with hyperref package"}}}