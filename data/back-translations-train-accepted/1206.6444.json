{"id": "1206.6444", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Statistical linear estimation with penalized estimators: an application to reinforcement learning", "abstract": "Motivated by value function estimation in reinforcement learning, we study statistical linear inverse problems, i.e., problems where the coefficients of a linear system to be solved are observed in noise. We consider penalized estimators, where performance is evaluated using a matrix-weighted two-norm of the defect of the estimator measured with respect to the true, unknown coefficients. Two objective functions are considered depending whether the error of the defect measured with respect to the noisy coefficients is squared or unsquared. We propose simple, yet novel and theoretically well-founded data-dependent choices for the regularization parameters for both cases that avoid data-splitting. A distinguishing feature of our analysis is that we derive deterministic error bounds in terms of the error of the coefficients, thus allowing the complete separation of the analysis of the stochastic properties of these errors. We show that our results lead to new insights and bounds for linear value function estimation in reinforcement learning.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (311kb)", "http://arxiv.org/abs/1206.6444v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["bernardo \u00e1vila pires", "csaba szepesv\u00e1ri"], "accepted": true, "id": "1206.6444"}, "pdf": {"name": "1206.6444.pdf", "metadata": {"source": "META", "title": "Statistical linear estimation with penalized estimators: an application to reinforcement learning", "authors": ["Bernardo \u00c1vila Pires", "Csaba Szepesv\u00e1ri"], "emails": ["bpires@ualberta.ca", "szepesva@cs.ualberta.ca"], "sections": [{"heading": "1. Introduction", "text": "Let us look at a real rated m \u00b7 d matrix, b be a real rated m-dimensional vector, M be an m \u00b7 m positive semidefined matrix, and consider the loss function LM: Rd \u2192 R defined byLM (s). We call this problem a statistically weighted two-dimensional analysis. We look at the problem of finding a minimizer of this loss when one instead has access to their respective \"noisy\" versions. We call this problem a statistically linear inverse problem. Our main motivation to better understand this problem is the so-called least-squares approach to an appreciation in reinforcement of learning, the aim of which is to estimate the function of an appreciation."}, {"heading": "1.1. Goals", "text": "In this work, our goal will be to derive exact, uniform, fast, highly probable oracle imbalances for the estimation methods we are investigating. (This is our goal to prove that for our choice of an estimator, both the value and quality of the given qualities (0 < 3, with the probability of 1 \u2212 3, LM (with the probability of 1 \u2212 4) \u2264 inf. (2) 2Regression is a special case of appreciation (scepesva) ri, for some reasonable norms. (The above is called an oracle, which measures the performance of inequality since the loss) is compared with that of an \"oracle,\" which has access to the true loss function. (The above oracle is an oracle of inequality since the performance of inequality (as measured by the loss) is compared with that of an \"oracle.\""}, {"heading": "2. Value-estimation in Markov Reward Processes", "text": "The purpose of this section is to show how our results can be applied in the context of appreciation in Markov Reward Processes = x =. Consider a Markov Reward Process (MRP) (X0, R1, X1, R2,.) is a stochastic process (Xt, Rt + 1), while the distribution of the reward Rt + 1 is entirely determined by Xt and Xt + 1. Bellt + 1 gives the story Ht = (X0, R1, X1, X1, X1, R2, R2,. The distribution of the state Xt + 1 is entirely determined by Xt and Xt + 1. Bellt + 1 gives the story Ht + 1. Denote by PM the distribution of (Rt + 1, Xt)."}, {"heading": "3. Results", "text": "In this section, we specify our main results for statistical linear inverse problems. We begin with a few few definitions. For real numbers a, b we use a \"B\" to denote max (a, b). < The operator norm of a matrix S with respect to the Euclidean norm \"B\" is known to fulfill \"S\" 2 = \"B.\" In what follows, we fix a vector norm \"B.\" We define the errors of a matrix S with respect to the following respective qualities: let \"A. =\" M 12 (A \u2212 A), \"\" B, \"\" \"B,\" \"\" \"M\" 12 (b \u2212 b), \"B,\" \"\" B, \"\" B, \"B,\" B, \"B,\" B, \"B,\" B, B, B, B, B, B, B."}, {"heading": "3.1. Minimizing the unsquared penalized loss", "text": "In this section we present the results for the unsquared, punished loss. Choose whether inequality should be a norm of d-dimensional Euclidean space."}, {"heading": "3.2. Minimizing the squared penalized loss", "text": "A more \"traditional\" estimator uses the square of the empirical loss function: instead of what we are able to handle lasso-like procedures, we have chosen to avoid squaring the norm of inequality. Furthermore, squaring this term is more convenient for the evidentiary techniques we use. Expanding our results for other types of penalties, especially for lasso-like procedures, remains for future work.Unlike the previous case, where the loss function and the norm were both unsquared, in this case the selection of the regulation parameter will be more complicated. In practice, an estimate is often used to select the best value of the candidates from a finite number of candidates on an exponential grid. Here, we propose a procedure that avoids splitting the data, but uses the unsquared penalized loss with the same data."}, {"heading": "4. Value-estimation in Markov Reward Processes: Results", "text": "Let us now return to the estimates in Markov Reward Processes (1 / 2). We consider the projected Bellman error lens (LM) as not given. (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LP). (LP). (LP). L. (LP). (LP). L. (LP). (LP). (LP). (LP). (LP.). (LP.). (LP.). (LP.). (LP. (LP). (LP.). (LP.). (LP.). (LP.). (LP.). (LP.). (LP.). (LP.). (LP. (LP.). (LP.). (LP.). (LP.). (LP.). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM). (LM)."}, {"heading": "4.1. Related work", "text": "IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV IV"}, {"heading": "5. Conclusion and future work", "text": "In fact, it is a pure disinfectant, capable of defeating the disease without being able to suffocate it."}, {"heading": "Acknowledgements", "text": "This work was supported by AITF and NSERC."}], "references": [{"title": "Inverse Problems and High-dimensional Estimation", "author": ["P. Alquier", "E. Gautier", "G. Stoltz"], "venue": "SpringerVerlag.", "citeRegEx": "Alquier et al\\.,? 2011", "shortCiteRegEx": "Alquier et al\\.", "year": 2011}, {"title": "Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path", "author": ["A. Antos", "C. Szepesv\u00e1ri", "R. Munos"], "venue": "Machine Learning, 71(1):89\u2013129.", "citeRegEx": "Antos et al\\.,? 2008", "shortCiteRegEx": "Antos et al\\.", "year": 2008}, {"title": "Square-root Lasso: Pivotal recovery of sparse signals via conic programming", "author": ["A. Belloni", "V. Chernozhukov", "L. Wang"], "venue": "arXiv, stat.ME. Published in: Biometrika (2011) 98(4): 791-806.", "citeRegEx": "Belloni et al\\.,? 2010", "shortCiteRegEx": "Belloni et al\\.", "year": 2010}, {"title": "NeuroDynamic Programming", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": "Athena Scientific, Belmont, MA.", "citeRegEx": "Bertsekas and Tsitsiklis,? 1996", "shortCiteRegEx": "Bertsekas and Tsitsiklis", "year": 1996}, {"title": "Simultaneous analysis of lasso and dantzig selector", "author": ["P. Bickel", "Y. Ritov", "A. Tsybakov"], "venue": "The Annals of Statistics, 37(4):1705\u20131732.", "citeRegEx": "Bickel et al\\.,? 2009", "shortCiteRegEx": "Bickel et al\\.", "year": 2009}, {"title": "Linear least-squares algorithms for temporal difference learning", "author": ["S.J. Bradtke", "A.G. Barto"], "venue": "Machine Learning, 22:33\u201357.", "citeRegEx": "Bradtke and Barto,? 1996", "shortCiteRegEx": "Bradtke and Barto", "year": 1996}, {"title": "Statistics for HighDimensional Data: Methods, Theory and Applications", "author": ["P. B\u00fchlmann", "S. Geer"], "venue": "Springer Series in Statistics. Springer.", "citeRegEx": "B\u00fchlmann and Geer,? 2011", "shortCiteRegEx": "B\u00fchlmann and Geer", "year": 2011}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "IEEE Transactions on Information Theory, 50:2050\u2013 2057.", "citeRegEx": "Cesa.Bianchi et al\\.,? 2004", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2004}, {"title": "Regularized policy iteration", "author": ["A. Farahmand", "M. Ghavamzadeh", "C. Szepesv\u00e1ri", "S. Mannor"], "venue": "Koller, D., Schuurmans, D., Bengio, Y., and Bottou, L., editors, NIPS-21, pages 441\u2013448. MIT Press.", "citeRegEx": "Farahmand et al\\.,? 2009", "shortCiteRegEx": "Farahmand et al\\.", "year": 2009}, {"title": "Regularized least-squares regression: Learning from a beta-mixing sequence", "author": ["A. Farahmand", "C. Szepesv\u00e1ri"], "venue": "Journal of Statistical Planning and Inference (in press), 142(2):493\u2013505.", "citeRegEx": "Farahmand and Szepesv\u00e1ri,? 2011", "shortCiteRegEx": "Farahmand and Szepesv\u00e1ri", "year": 2011}, {"title": "LSTD with random projections", "author": ["M. Ghavamzadeh", "A. Lazaric", "Maillard", "O.-A.", "R. Munos"], "venue": "Advances in Neural Information Processing Systems, 23:721\u2013729.", "citeRegEx": "Ghavamzadeh et al\\.,? 2010", "shortCiteRegEx": "Ghavamzadeh et al\\.", "year": 2010}, {"title": "Finite-sample analysis of Lasso-TD", "author": ["M. Ghavamzadeh", "A. Lazaric", "R. Munos", "M. Hoffman"], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML), pages 1177\u20131184.", "citeRegEx": "Ghavamzadeh et al\\.,? 2011", "shortCiteRegEx": "Ghavamzadeh et al\\.", "year": 2011}, {"title": "An Introduction to the Mathematical Theory of Inverse Problems", "author": ["A. Kirsch"], "venue": "Springer, 2nd edition.", "citeRegEx": "Kirsch,? 2011", "shortCiteRegEx": "Kirsch", "year": 2011}, {"title": "Oracle inequalities in empirical risk minimization and sparse recovery problems", "author": ["V. Koltchinskii"], "venue": "Springer.", "citeRegEx": "Koltchinskii,? 2011", "shortCiteRegEx": "Koltchinskii", "year": 2011}, {"title": "Regularization and feature selection in least-squares temporal difference learning", "author": ["J.Z. Kolter", "A.Y. Ng"], "venue": "Bottou, L. and Littman, M., editors, ICML 2009, pages 521\u2013528. ACM.", "citeRegEx": "Kolter and Ng,? 2009", "shortCiteRegEx": "Kolter and Ng", "year": 2009}, {"title": "Finite-sample analysis of LSTD", "author": ["A. Lazaric", "M. Ghavamzadeh", "R. Munos"], "venue": "Proceedings of the 27th International Conference on Machine Learning (ICML), pages 615\u2013622.", "citeRegEx": "Lazaric et al\\.,? 2010", "shortCiteRegEx": "Lazaric et al\\.", "year": 2010}, {"title": "Apprentissage S\u00e9quentiel: Bandits, Statistique et Renforcement", "author": ["Maillard", "O.-A."], "venue": "PhD thesis, Universit\u00e9 des Sciences et des Technologies de Lille.", "citeRegEx": "Maillard and O..A.,? 2011", "shortCiteRegEx": "Maillard and O..A.", "year": 2011}, {"title": "Compressed leastsquares regression", "author": ["Maillard", "O.-A.", "R. Munos"], "venue": "NIPS, pages 1213\u20131221.", "citeRegEx": "Maillard et al\\.,? 2009", "shortCiteRegEx": "Maillard et al\\.", "year": 2009}, {"title": "Regularization Approaches in Learning Theory", "author": ["L. Rosasco"], "venue": "PhD thesis, DISI, Universit\u00e0 di Genova.", "citeRegEx": "Rosasco,? 2006", "shortCiteRegEx": "Rosasco", "year": 2006}, {"title": "Concentration of measure inequalities for markov chains and \u03c6-mixing processes", "author": ["Samson", "P.-M."], "venue": "The Annals of Probability, 28(1):416\u2013461.", "citeRegEx": "Samson and P..M.,? 2000", "shortCiteRegEx": "Samson and P..M.", "year": 2000}, {"title": "Should one compute the temporal difference fix point or minimize the Bellman residual? The unified oblique projection view", "author": ["B. Scherrer"], "venue": "F\u00fcrnkranz, J. and Joachims, T., editors, ICML 2010, pages 959\u2013966.", "citeRegEx": "Scherrer,? 2010", "shortCiteRegEx": "Scherrer", "year": 2010}, {"title": "Support Vector Machines", "author": ["I. Steinwart", "A. Christmann"], "venue": "Springer, 1st edition.", "citeRegEx": "Steinwart and Christmann,? 2008", "shortCiteRegEx": "Steinwart and Christmann", "year": 2008}, {"title": "Reinforcement Learning: An Introduction", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "Bradford Book. MIT Press, Cambridge, Massachusetts.", "citeRegEx": "Sutton and Barto,? 1998", "shortCiteRegEx": "Sutton and Barto", "year": 1998}, {"title": "Algorithms for Reinforcement Learning", "author": ["C. Szepesv\u00e1ri"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan & Claypool Publishers.", "citeRegEx": "Szepesv\u00e1ri,? 2010", "shortCiteRegEx": "Szepesv\u00e1ri", "year": 2010}, {"title": "Regression shrinkage and selection via the Lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society. Series B, 58(1):267\u2013288.", "citeRegEx": "Tibshirani,? 1996", "shortCiteRegEx": "Tibshirani", "year": 1996}, {"title": "Introduction to the non-asymptotic analysis of random matrices", "author": ["R. Vershynin"], "venue": "arxiv, math.PR.", "citeRegEx": "Vershynin,? 2010", "shortCiteRegEx": "Vershynin", "year": 2010}, {"title": "Learning from examples as an inverse problem", "author": ["E.D. Vito", "L. Rosasco", "A. Caponnetto", "U.D. Giovannini", "F. Odone"], "venue": "Journal of Machine Learning Research, 6(1):883.", "citeRegEx": "Vito et al\\.,? 2006", "shortCiteRegEx": "Vito et al\\.", "year": 2006}, {"title": "Rates of convergence for empirical processes of stationary mixing sequences", "author": ["B. Yu"], "venue": "The Annals of Probability, 22(1):94\u2013116.", "citeRegEx": "Yu,? 1994", "shortCiteRegEx": "Yu", "year": 1994}, {"title": "Error bounds for approximations from projected linear equations", "author": ["H. Yu", "D. Bertsekas"], "venue": "Mathematics of Operations Research, 35(2):306\u2013329.", "citeRegEx": "Yu and Bertsekas,? 2010", "shortCiteRegEx": "Yu and Bertsekas", "year": 2010}], "referenceMentions": [{"referenceID": 5, "context": "The leastsquares approach originates from the work of Bradtke and Barto (1996), who proposed to find the parameter-", "startOffset": 54, "endOffset": 79}, {"referenceID": 1, "context": ", (Antos et al., 2008; Ghavamzadeh et al., 2010; Lazaric et al., 2010; Ghavamzadeh et al., 2011)).", "startOffset": 2, "endOffset": 96}, {"referenceID": 10, "context": ", (Antos et al., 2008; Ghavamzadeh et al., 2010; Lazaric et al., 2010; Ghavamzadeh et al., 2011)).", "startOffset": 2, "endOffset": 96}, {"referenceID": 15, "context": ", (Antos et al., 2008; Ghavamzadeh et al., 2010; Lazaric et al., 2010; Ghavamzadeh et al., 2011)).", "startOffset": 2, "endOffset": 96}, {"referenceID": 11, "context": ", (Antos et al., 2008; Ghavamzadeh et al., 2010; Lazaric et al., 2010; Ghavamzadeh et al., 2011)).", "startOffset": 2, "endOffset": 96}, {"referenceID": 8, "context": "The nonparametric variant has also received some attention (Farahmand et al., 2009; Maillard, 2011).", "startOffset": 59, "endOffset": 99}, {"referenceID": 3, "context": ", the books by Bertsekas and Tsitsiklis (1996); Sutton and Barto (1998); Szepesv\u00e1ri (2010).", "startOffset": 15, "endOffset": 47}, {"referenceID": 3, "context": ", the books by Bertsekas and Tsitsiklis (1996); Sutton and Barto (1998); Szepesv\u00e1ri (2010).", "startOffset": 15, "endOffset": 72}, {"referenceID": 3, "context": ", the books by Bertsekas and Tsitsiklis (1996); Sutton and Barto (1998); Szepesv\u00e1ri (2010).", "startOffset": 15, "endOffset": 91}, {"referenceID": 11, "context": "Furthermore, we think that the problem of linear estimation is interesting on its own due to its mathematical elegance and its applicability beyond value function estimation (a number of specific linear inverse problems, ranging from computer tomography to time series analysis, are discussed in the books by Kirsch (2011) and Alquier et al.", "startOffset": 309, "endOffset": 323}, {"referenceID": 0, "context": "Furthermore, we think that the problem of linear estimation is interesting on its own due to its mathematical elegance and its applicability beyond value function estimation (a number of specific linear inverse problems, ranging from computer tomography to time series analysis, are discussed in the books by Kirsch (2011) and Alquier et al. (2011)).", "startOffset": 327, "endOffset": 349}, {"referenceID": 23, "context": "Regression is a special case of value function estimation (Szepesv\u00e1ri, 2010).", "startOffset": 58, "endOffset": 76}, {"referenceID": 22, "context": ") (Sutton and Barto, 1998).", "startOffset": 2, "endOffset": 26}, {"referenceID": 5, "context": ", Xn+1), the LSTD algorithm of Bradtke and Barto (1996) finds an approximate solution to the Bellman equation by solving the linear system", "startOffset": 31, "endOffset": 56}, {"referenceID": 5, "context": "This method can be derived as an instrumental variable method to find an approximate fixed point of T (Bradtke and Barto, 1996) or as a Bubnov-Galerkin method (Yu and Bertsekas, 2010).", "startOffset": 102, "endOffset": 127}, {"referenceID": 28, "context": "This method can be derived as an instrumental variable method to find an approximate fixed point of T (Bradtke and Barto, 1996) or as a Bubnov-Galerkin method (Yu and Bertsekas, 2010).", "startOffset": 159, "endOffset": 183}, {"referenceID": 3, "context": "3 The linear system (4) can be shown to be consistent (Bertsekas and Tsitsiklis, 1996).", "startOffset": 54, "endOffset": 86}, {"referenceID": 1, "context": "When M = C\u22121, C = E [ \u03c6(Xt)\u03c6(Xt) >], LM (\u00b7) becomes identical to the so-called projected Bellman error loss which can also be written as LM (\u03b8) = \u2016\u03a0\u03c6,\u03bc(TW\u03b8 \u2212 W\u03b8)\u2016\u03bc,2, where \u03bc is the steady-state distribution underlying PM , \u2016 \u00b7 \u2016\u03bc,2 is the weighted L(\u03bc)-norm over X and \u03a0 : L(X , \u03bc) \u2192 L(X , \u03bc) is the projection on the linear space spanned by \u03c6 with respect to the \u2016\u00b7\u2016\u03bc,2-norm (Antos et al., 2008).", "startOffset": 377, "endOffset": 397}, {"referenceID": 20, "context": "4 For a discussion of how well W\u03b8\u2217 approximates V the reader is directed to consult the paper by Scherrer (2010) and the references therein.", "startOffset": 97, "endOffset": 113}, {"referenceID": 27, "context": "bounded, and if we assume appropriate mixing, such as exponential \u03b2-mixing (Yu, 1994), or when the Markov chain (Xt)t\u22650 forgets its past sufficiently rapidly (Samson, 2000).", "startOffset": 75, "endOffset": 85}, {"referenceID": 21, "context": ", (Steinwart and Christmann, 2008)) gives a bound that scales with the \u201crange\u201d of N = \u2016M(\u03c6(Xt) \u2212 \u03b3\u03c6(X\u0303t+1))\u03c6(Xt)\u2016F .", "startOffset": 2, "endOffset": 34}, {"referenceID": 25, "context": "d standard normal entries, the maximum eigenvalue is O( \u221a d) (Vershynin, 2010).", "startOffset": 61, "endOffset": 78}, {"referenceID": 25, "context": "d standard normal entries, the maximum eigenvalue is O( \u221a d) (Vershynin, 2010). Furthermore, note that if the basis functions are correlated, or if they are sparse, the dimension will not necessarily appear linearly in the bound either. For a discussion of when to expect a milder dependence of the norm of \u03c6 on d, the interested reader may consult the paper by Maillard and Munos (2009).", "startOffset": 62, "endOffset": 388}, {"referenceID": 15, "context": "Lazaric et al. (2010) for their (unregularized) path-wise LSTD method obtain", "startOffset": 0, "endOffset": 22}, {"referenceID": 10, "context": "Non-uniform, slow rates can be extracted from the paper by Ghavamzadeh et al. (2010) for LSTD with random projections.", "startOffset": 59, "endOffset": 85}, {"referenceID": 10, "context": "More recently, for the so-called Lasso-TD method, Ghavamzadeh et al. (2011) showed non-uniform", "startOffset": 50, "endOffset": 76}, {"referenceID": 5, "context": "We have recovered `-penalized variations of LSTD (Bradtke and Barto, 1996) for value function estimation in MRPs.", "startOffset": 49, "endOffset": 74}, {"referenceID": 4, "context": ", (Bickel et al., 2009; Koltchinskii, 2011; B\u00fchlmann and Geer, 2011) and the references therein), as well as in the reinforcement learning setting (Kolter and Ng, 2009; Ghavamzadeh et al.", "startOffset": 2, "endOffset": 68}, {"referenceID": 13, "context": ", (Bickel et al., 2009; Koltchinskii, 2011; B\u00fchlmann and Geer, 2011) and the references therein), as well as in the reinforcement learning setting (Kolter and Ng, 2009; Ghavamzadeh et al.", "startOffset": 2, "endOffset": 68}, {"referenceID": 6, "context": ", (Bickel et al., 2009; Koltchinskii, 2011; B\u00fchlmann and Geer, 2011) and the references therein), as well as in the reinforcement learning setting (Kolter and Ng, 2009; Ghavamzadeh et al.", "startOffset": 2, "endOffset": 68}, {"referenceID": 14, "context": ", 2009; Koltchinskii, 2011; B\u00fchlmann and Geer, 2011) and the references therein), as well as in the reinforcement learning setting (Kolter and Ng, 2009; Ghavamzadeh et al., 2010; 2011; Maillard, 2011), mainly because it allows for non-trivial performance bounds even when the dimension d of the parameter vector is comparable to the sample size n (or even larger than n) provided that the true parameter vector is sparse (i.", "startOffset": 131, "endOffset": 200}, {"referenceID": 10, "context": ", 2009; Koltchinskii, 2011; B\u00fchlmann and Geer, 2011) and the references therein), as well as in the reinforcement learning setting (Kolter and Ng, 2009; Ghavamzadeh et al., 2010; 2011; Maillard, 2011), mainly because it allows for non-trivial performance bounds even when the dimension d of the parameter vector is comparable to the sample size n (or even larger than n) provided that the true parameter vector is sparse (i.", "startOffset": 131, "endOffset": 200}, {"referenceID": 2, "context": "If we use \u2016 \u00b7\u2016 as the `-norm, we recover procedures similar to the square-root Lasso (Belloni et al., 2010) and the Lasso (Tibshirani, 1996) for the estimators studied in Sections 3.", "startOffset": 85, "endOffset": 107}, {"referenceID": 24, "context": ", 2010) and the Lasso (Tibshirani, 1996) for the estimators studied in Sections 3.", "startOffset": 22, "endOffset": 40}, {"referenceID": 11, "context": "The theory of Inverse Problems is very pertinent to this work, and it is important to study our results under the light of those shown in Chapter 2 of Kirsch (2011); Alquier et al.", "startOffset": 151, "endOffset": 165}, {"referenceID": 0, "context": "The theory of Inverse Problems is very pertinent to this work, and it is important to study our results under the light of those shown in Chapter 2 of Kirsch (2011); Alquier et al. (2011). The existing knowledge of inverse prob-", "startOffset": 166, "endOffset": 188}, {"referenceID": 18, "context": "The idea of having learning problems as inverse problems is not new; Rosasco (2006); Vito et al.", "startOffset": 69, "endOffset": 84}, {"referenceID": 18, "context": "The idea of having learning problems as inverse problems is not new; Rosasco (2006); Vito et al. (2006) study regression in Hilbert spaces as an inverse problem.", "startOffset": 69, "endOffset": 104}], "year": 2012, "abstractText": "Motivated by value function estimation in reinforcement learning, we study statistical linear inverse problems, i.e., problems where the coefficients of a linear system to be solved are observed in noise. We consider penalized estimators, where performance is evaluated using a matrix-weighted two-norm of the defect of the estimator measured with respect to the true, unknown coefficients. Two objective functions are considered depending whether the error of the defect measured with respect to the noisy coefficients is squared or unsquared. We propose simple, yet novel and theoretically well-founded data-dependent choices for the regularization parameters for both cases that avoid datasplitting. A distinguishing feature of our analysis is that we derive deterministic error bounds in terms of the error of the coefficients, thus allowing the complete separation of the analysis of the stochastic properties of these errors. We show that our results lead to new insights and bounds for linear value function estimation in reinforcement learning.", "creator": "LaTeX with hyperref package"}}}