{"id": "1206.6456", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Lognormal and Gamma Mixed Negative Binomial Regression", "abstract": "In regression analysis of counts, a lack of simple and efficient algorithms for posterior computation has made Bayesian approaches appear unattractive and thus underdeveloped. We propose a lognormal and gamma mixed negative binomial (NB) regression model for counts, and present efficient closed-form Bayesian inference; unlike conventional Poisson models, the proposed approach has two free parameters to include two different kinds of random effects, and allows the incorporation of prior information, such as sparsity in the regression coefficients. By placing a gamma distribution prior on the NB dispersion parameter r, and connecting a lognormal distribution prior with the logit of the NB probability parameter p, efficient Gibbs sampling and variational Bayes inference are both developed. The closed-form updates are obtained by exploiting conditional conjugacy via both a compound Poisson representation and a Polya-Gamma distribution based data augmentation approach. The proposed Bayesian inference can be implemented routinely, while being easily generalizable to more complex settings involving multivariate dependence structures. The algorithms are illustrated using real examples.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (477kb)", "http://arxiv.org/abs/1206.6456v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "stat.AP cs.LG stat.ME", "authors": ["mingyuan zhou", "lingbo li", "david b dunson", "lawrence carin"], "accepted": true, "id": "1206.6456"}, "pdf": {"name": "1206.6456.pdf", "metadata": {"source": "META", "title": "Lognormal and Gamma Mixed Negative Binomial Regression", "authors": ["Mingyuan Zhou", "Lingbo Li", "David Dunson"], "emails": ["mz1@ee.duke.edu", "ll83@duke.edu", "dunson@stat.duke.edu", "lcarin@ee.duke.edu"], "sections": [{"heading": "1. Introduction", "text": "In numerous scientific studies, the answer variable is a number y = 0, 1, 2, 2, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 8, 8, 5, 6, 6, 6, 6, 7, 6, 7, 7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,"}, {"heading": "2. Regression Models for Counts", "text": "The most basic regression model for the counts is the Poisson regression model (Long, 1997; Cameron & Trivedi, 1998; Winkelmann, 2008), which can be expressed asyi \u0445 Pois (\u03bbi), \u03bbi = exp (xTi \u03b2) (1), where xi = [1, xi1, \u00b7 \u00b7, xiP] T is the covariate vector for the sample i. The Newton-Raphson method can be used to iteratively find the MLE of \u03b2 (Long, 1997). A serious limitation of the Poisson regression model is that it assumes the same dispersion, i.e. E [yi | xi] = Var [yi | xi] = exp (xTi \u03b2). In practice, however, the counted data are often over-dispersed due to heterogeneity and contagion [Vyar] of the [Eyar] law (Winxi, 2008)."}, {"heading": "2.1. The Negative Binomial Regression Model", "text": "The NB regression model (Long, 1997; Cameron & Trivedi, 1998; Winkelmann, 2008; Hilbe, 2007) is constructed by setting a gamma before i asi \u0445 gamma (r, 1 / r) = rr\u0442 (r) i r \u2212 1e \u2212 r i (5), where E [i] = 1 and Var [i] = r \u2212 1. By excluding i in (2), we have a NB distribution parameter that is expressed by mean \u00b5i = exp (x T i \u03b2) and inverse dispersion parameters \u03c6 (the counterpart of r) as fY (yi) = 1 (\u03c6 \u2212 1 + yi) yi!"}, {"heading": "2.2. The Lognormal-Poisson Regression Model", "text": "A lognormal Poisson regression model (Breslow, 1984; Long, 1997; Agresti, 2002; Winkelmann, 2008) can be constructed by placing a lognormal before i asi \u0445 lnN (0, \u03c32) (8), where E [i] = e\u03c3 2 / 2 and Var [i] = e \u03c32 (e\u03c3 2 \u2212 1). Us-ing (3) and (4) we have E [yi | xi] = exp (xTi \u03b2 + \u03c32 / 2) (9) Var [yi | xi] = E [yi | xi] + (e\u03c3 2 \u2212 1) E2 [yi | xi]. (10) Compared to the NB model, there is no analytical form for the distribution of yi when i is marginalized and the MLE is less easy to calculate, making it less frequently used. However, Winkelmann (2008) proposes to re-evaluate the lognormal Poisson model, since it virtually fits in the Dean theory."}, {"heading": "3. The Lognormal and Gamma Mixed Negative Binomial Regression Model", "text": "In order to explicitly model the uncertainty of the estimate and integrate prior information, Bayesian approaches appear to be attractive (\u03b2 \u03b2 = 1). However, since the number of counts is severely limited by the lack of efficient conclusions, since the conjugation before the regression coefficient \u03b2 in the Poisson and NB models is unknown (Winkelmann, 2008), and the conjugate before the NB dispersion parameter r is also unknown. To solve these problems, we propose a lognormal and gamma mixed NB regression model for counts, referred to here as the LGNB model, in which a lognormal previous LGNB model (0, \u03c32) is set to the multiplicative random effect term i and a gamma preceding model i. Denoting pi = eebo1 + eeboi = exp (xTi \u03b2) i is 1 + exp (Tgit \u03b2), we \u2212 pgit (Ti) and \u2212 B (\u2212 pi)."}, {"heading": "3.1. Model Properties and Model Comparison", "text": "Based on the laws of total expectation and total variance and moments of NB distribution, we have the following: E [yi | xi] = E i [E [yi | xi, i] = exp (x T i \u03b2 + \u03c3 2 / 2 + ln r) (16) Var [yi | xi] = E i [Var [yi | xi, i]] + Var i [E [yi | xi, i]] = E [yi | xi] + (e\u03c3 2 (1 + r \u2212 1) \u2212 1) E2 [yi | xi]. (17) We define the quasi-dispersion level as the coefficient associated with the mean square term in the variance. As shown in (7) and (10), there is no clear proof that the same effects occur in the NB model and in the NB = (e\u03c3 2 \u2212 1) when the two types of inequality 1 and inequality 1 are equal."}, {"heading": "4. Default Bayesian Analysis Using Data Augmentation", "text": "As discussed in Section 3, the LGNB model has the advantage of having two free parameters to include both types of random effects. We show below that it has an additional advantage, since standard Bayesian analysis can be performed using two new data augmentation approaches, with closed-form solutions and analytical update equations available for both Gibbs sampling and VB inference. One augmentation approach concerns the inference of the NB dispersion parameter r using the compound Poisson representation, and the other concerns the inference of regression coefficients \u03b2 using the Polya gamma distribution."}, {"heading": "4.1. Inferring the Dispersion Parameter Under the Compound Poisson Representation", "text": "We focus first on the conclusion of the NB dispersion parameter r and assume that we know {pi} i = 1, N and h, neglecting the remaining part of the LGNB model at this time. We comment here that the novel Bayesian inference developed here can be applied to all other scenarios for which a hybrid Monte Carlo and Metropolis Hastings algorithm has been developed in Williamson et al. (2010) and Zhou et al. (2012), but for which no VB solutions have been developed. As proved in Quenouille (1949), y'NB (r, p) can also be generated from a composite Poisson distribution asy = L '= 1 u', L ', Pois \u2212 r \u2212 pamma, y'iid Log (p)."}, {"heading": "4.1.1. Gibbs Sampling for r", "text": "If we remember (18), we can also use the random sum yi = = = j = = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1 (1) = 1) = 1 (1) = 1 (1) = 1 (1) = 1) = 1 (1) = 1 = 1 (1) = 1 (1) = 1 (1) = 1) = 1 (1 = 1) = 1 ("}, {"heading": "4.1.2. Variational Bayes Inference for r", "text": "Using VB inference (Bishop & Tipping, 2000; Beal, 2003) we approach the rear p (r, L | X) with Q (r, L) = Qr (r) = Qr (r) = 1QLi (Li), and we have QLi (Li) = yi = 0 Rr (yi, j) \u03b4j (27) Qr (r) = Gamma (a, 1 / h). (28) where < x > = E [x], r = exp (< ln r >), x (x) is the digamma function and < ln r > = a (a) \u2212 ln h, < Li > = yi j = 1 Rr (yi, j) j (29) a = a0 + N (i = 1 < Li >, h = h \u2212 N (a) < ln (1 \u2212 pi) > (b)."}, {"heading": "4.2. Inferring the Regression Coefficients Using the Polya-Gamma Distribution", "text": "(31) We have E\u03c9i [exp (\u2212 sustainGamma (PG) distribution (Polson & Scott, 2011) as\u03c9i and PG (yi + r, 0). (31) We have E\u03c9i [exp (\u2212 sustainGamma) 2i / 2)] = cosh \u2212 (yi + r) (yi + 2). Thus, the probability of an \"i in\" (11) can be expressed as \"i\" (e\u03c9i) [exp (\u2212 invest2i / 2) yi + r = 2 \u2212 (yi + r) exp (yi \u2212 r 2) coshyi + r (\u0445i / 2) \u041aexp (yi \u2212 r 2) e\u03c9i [exp (\u2212 invest2i / 2) yi + r = 2 \u2212 (yi + r) exmimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimimi"}, {"heading": "4.3. Gibbs Sampling Inference", "text": "(1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1 (1) (1) (1) (1) (1) (1 (1) (1) (1) (1 (1) (1 (1) (1) (1) (1 (1) (1 (1) (1) (1) (1 (1) (1) (1 (1 (1) (1 (1) (1) (1 (1) (1) (1 (1 (1) (1 (1) (1) (1"}, {"heading": "4.4. Variational Bayes Inference", "text": "Using VB conclusions (Bishop & Tipping, 2000; Beal, 2003) we can use Q = > < p = < p = < p = < p = < p = < p = 0; p = 0; p = 0; p = 0; p = 0; p (r) as in (28), Qp (p) as in (28), Qp (p) as in (PG) = 1; p (p), Qp (p) as in (4), Qp (p) as in (4), Qp (p) as in (4), Qp (p) as in (4), Qp (p) as in (1 / g), Qp (p) as in (p), Gamma (b), 1 / g) as in (p)."}, {"heading": "5. Example Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Univariate Count Data Analysis", "text": "The conclusion of the NB dispersion parameter r itself plays an important role not only in NB-VB regression (Lawless, 1987; Angle\u03b2, 2008), but also in the analysis of univariable counting data (Bliss & Fisher, 1953; Clark & Perry, 1989; Saha & Paul, 2005; Lloyd-Smith, 2007), and it is also derived from some recently proposed latent variable models for counting matrix factorization (Williamson et al., 2010; Zhou et al., 2012).Therefore, it is of interest to evaluate the proposed Gibbs closed-form samples and VB conclusions for this parameter alone before introducing regression analysis (Williamson et al., 2010; Zhou et al., 2012)."}, {"heading": "5.2. Regression Analysis of Counts", "text": "We test the full LGNB model on two real-world examples, compared to the Poisson, NB, lognormalPoisson and inverse Gaussian Poisson (IG-Poisson) regression models. However, the NASCAR Dataset3, analyzed in Winner, consists of 151 NASCAR races during the 1975-1979 season. The response variable is the number of lead changes in a race, and the covariates of a race include the number of laps, the number of drivers and the length of the track (in miles). The MotorIns dataset4, analyzed in Dean et al. (1989), consists of the number of Swedish third-party motor insurance claims in 1977. Included in the data are the total number of insured claims for cars in each of the 315 risk groups, defined by a combination of DISTANCE, BONUS and MAKE factor levels. The number of insured automobile years for each group is also given."}, {"heading": "6. Conclusions", "text": "A lognormal and a gamma-mixed negative binomial regression model (LGNB) is proposed for regression analysis of over-dispersed counts. Efficient closed Gibbs sample and VB inference are both presented by using the composite Poisson representation and a data augmentation approach based on polya-gamma distributions.Model characteristics are used in comparison to the Poisson, NB and Lognormal Poisson.Since the univariate lognormal Poisson regression model can easily be generalized for regression analysis of correlated counts, the derivatives and Hessian matrices of the parameters are used to construct multivariate normal proposals in a metropolitan Hastings algorithm (Chib et al, 1998; Chib & Winkelmann, 2001; Ma et al., 2008; Winkelmann et al, Williye2005, 2008), the modified Nyesian model is proposed for LGNecelem; the modified Necelian model is proposed for LGNecelem."}, {"heading": "Acknowledgements", "text": "The research reported here has been partially supported by DARPA under the MSEE program."}], "references": [{"title": "Tractable nonparametric Bayesian inference in Poisson processes with Gaussian process intensities", "author": ["R. Adams", "I. Murray", "D. MacKay"], "venue": "In ICML,", "citeRegEx": "Adams et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Adams et al\\.", "year": 2009}, {"title": "Categorical Data Analysis", "author": ["A. Agresti"], "venue": "Wiley-Interscience, 2nd edition,", "citeRegEx": "Agresti,? \\Q2002\\E", "shortCiteRegEx": "Agresti", "year": 2002}, {"title": "An introduction to MCMC for machine learning", "author": ["C. Andrieu", "N. de Freitas", "A. Doucet", "M.I. Jordan"], "venue": "Machine Learning,", "citeRegEx": "Andrieu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2003}, {"title": "Integer-valued L\u00e9vy processes and low latency financial econometrics", "author": ["O.E. Barndorff-Nielsen", "D.G. Pollard", "N. Shephard"], "venue": null, "citeRegEx": "Barndorff.Nielsen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Barndorff.Nielsen et al\\.", "year": 2010}, {"title": "Variational Algorithms for Approximate Bayesian Inference", "author": ["M.J. Beal"], "venue": "PhD thesis,", "citeRegEx": "Beal,? \\Q2003\\E", "shortCiteRegEx": "Beal", "year": 2003}, {"title": "Variational relevance vector machines", "author": ["C.M. Bishop", "M.E. Tipping"], "venue": "In UAI,", "citeRegEx": "Bishop and Tipping,? \\Q2000\\E", "shortCiteRegEx": "Bishop and Tipping", "year": 2000}, {"title": "Correlated topic models", "author": ["D. Blei", "J.D. Lafferty"], "venue": "In NIPS,", "citeRegEx": "Blei and Lafferty,? \\Q2005\\E", "shortCiteRegEx": "Blei and Lafferty", "year": 2005}, {"title": "Fitting the negative binomial distribution to biological data", "author": ["C.I. Bliss", "R.A. Fisher"], "venue": null, "citeRegEx": "Bliss and Fisher,? \\Q1953\\E", "shortCiteRegEx": "Bliss and Fisher", "year": 1953}, {"title": "Bayesian inference for the negative binomial distribution via polynomial expansions", "author": ["E.T. Bradlow", "B.G.S. Hardie", "P.S. Fader"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "Bradlow et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Bradlow et al\\.", "year": 2002}, {"title": "Extra-Poisson variation in log-linear models", "author": ["N.E. Breslow"], "venue": "J. Roy. Statist. Soc., C,", "citeRegEx": "Breslow,? \\Q1984\\E", "shortCiteRegEx": "Breslow", "year": 1984}, {"title": "Regression Analysis of Count Data", "author": ["A.C. Cameron", "P.K. Trivedi"], "venue": null, "citeRegEx": "Cameron and Trivedi,? \\Q1998\\E", "shortCiteRegEx": "Cameron and Trivedi", "year": 1998}, {"title": "Markov chain Monte Carlo analysis of correlated count data", "author": ["S. Chib", "R. Winkelmann"], "venue": "Journal of Business & Economic Statistics,", "citeRegEx": "Chib and Winkelmann,? \\Q2001\\E", "shortCiteRegEx": "Chib and Winkelmann", "year": 2001}, {"title": "Posterior simulation and Bayes factors in panel count data models", "author": ["S Chib", "E Greenberg", "R. Winkelmann"], "venue": "Journal of Econometrics,", "citeRegEx": "Chib et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Chib et al\\.", "year": 1998}, {"title": "A mixed Poisson-inverse-Gaussian regression model", "author": ["C. Dean", "J.F. Lawless", "G.E. Willmot"], "venue": "Canadian Journal of Statistics,", "citeRegEx": "Dean et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Dean et al\\.", "year": 1989}, {"title": "On exact simulation algorithms for some distributions related to Jacobi theta functions", "author": ["L. Devroye"], "venue": "Statistics & Probability Letters,", "citeRegEx": "Devroye,? \\Q2009\\E", "shortCiteRegEx": "Devroye", "year": 2009}, {"title": "Negative Binomial Regression", "author": ["J.M. Hilbe"], "venue": null, "citeRegEx": "Hilbe,? \\Q2007\\E", "shortCiteRegEx": "Hilbe", "year": 2007}, {"title": "Negative binomial and mixed Poisson regression", "author": ["J.F. Lawless"], "venue": "Canadian Journal of Statistics,", "citeRegEx": "Lawless,? \\Q1987\\E", "shortCiteRegEx": "Lawless", "year": 1987}, {"title": "Maximum likelihood estimation of the negative binomial dispersion parameter for highly overdispersed data, with applications to infectious diseases", "author": ["J.O. Lloyd-Smith"], "venue": "PLoS ONE,", "citeRegEx": "Lloyd.Smith,? \\Q2007\\E", "shortCiteRegEx": "Lloyd.Smith", "year": 2007}, {"title": "Regression Models for Categorical and Limited Dependent Variables", "author": ["S.J. Long"], "venue": null, "citeRegEx": "Long,? \\Q1997\\E", "shortCiteRegEx": "Long", "year": 1997}, {"title": "A multivariate Poisson-lognormal regression model for prediction of crash counts by severity, using Bayesian methods", "author": ["J. Ma", "K.M. Kockelman", "P. Damien"], "venue": "Accident Analysis and Prevention,", "citeRegEx": "Ma et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2008}, {"title": "Generalized linear models", "author": ["P. McCullagh", "J.A. Nelder"], "venue": null, "citeRegEx": "McCullagh and Nelder,? \\Q1989\\E", "shortCiteRegEx": "McCullagh and Nelder", "year": 1989}, {"title": "Elliptical slice sampling", "author": ["I. Murray", "R.P. Adams", "D.J.C. MacKay"], "venue": "In AISTATS,", "citeRegEx": "Murray et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Murray et al\\.", "year": 2010}, {"title": "The discrete infinite logistic normal distribution for mixed-membership modeling", "author": ["J. Paisley", "C. Wang", "D.M. Blei"], "venue": "In AISTATS,", "citeRegEx": "Paisley et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Paisley et al\\.", "year": 2011}, {"title": "Default Bayesian analysis for multi-way tables: a data-augmentation approach", "author": ["N.G. Polson", "J.G. Scott"], "venue": null, "citeRegEx": "Polson and Scott,? \\Q2011\\E", "shortCiteRegEx": "Polson and Scott", "year": 2011}, {"title": "A relation between the logarithmic, Poisson, and negative binomial series", "author": ["M.H. Quenouille"], "venue": null, "citeRegEx": "Quenouille,? \\Q1949\\E", "shortCiteRegEx": "Quenouille", "year": 1949}, {"title": "Gaussian process modulated renewal processes", "author": ["V. Rao", "Y.W. Teh"], "venue": "In NIPS,", "citeRegEx": "Rao and Teh,? \\Q2011\\E", "shortCiteRegEx": "Rao and Teh", "year": 2011}, {"title": "Bias-corrected maximum likelihood estimator of the negative binomial dispersion parameter", "author": ["K. Saha", "S. Paul"], "venue": null, "citeRegEx": "Saha and Paul,? \\Q2005\\E", "shortCiteRegEx": "Saha and Paul", "year": 2005}, {"title": "Sparse Bayesian learning and the relevance vector machine", "author": ["M.E. Tipping"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Tipping,? \\Q2001\\E", "shortCiteRegEx": "Tipping", "year": 2001}, {"title": "The IBP compound Dirichlet process and its application to focused topic modeling", "author": ["S. Williamson", "C. Wang", "Heller", "Katherine A", "D.M. Blei"], "venue": "In ICML,", "citeRegEx": "Williamson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Williamson et al\\.", "year": 2010}, {"title": "Econometric Analysis of Count Data", "author": ["R. Winkelmann"], "venue": null, "citeRegEx": "Winkelmann,? \\Q2008\\E", "shortCiteRegEx": "Winkelmann", "year": 2008}, {"title": "Case Study \u2013 Negative Binomial Regression, NASCAR Lead Changes 1975-1979", "author": ["L. Winner"], "venue": "URL http://www. stat.ufl.edu/~winner/cases/nb_nascar.doc", "citeRegEx": "Winner,? \\Q2012\\E", "shortCiteRegEx": "Winner", "year": 2012}, {"title": "Betanegative binomial process and Poisson factor analysis", "author": ["M. Zhou", "L. Hannah", "D. Dunson", "L. Carin"], "venue": "In AISTATS,", "citeRegEx": "Zhou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 27, "context": "In addition, we may wish to impose a sparse prior in the regression coefficients for counts, which is demonstrated to be beneficial for regression analysis of both Gaussian and binary data (Tipping, 2001).", "startOffset": 189, "endOffset": 204}, {"referenceID": 18, "context": "The regression analysis of counts is commonly performed under the Poisson or NB likelihoods, whose parameters are usually estimated by finding the maximum of the nonlinear log likelihood (Long, 1997; Cameron & Trivedi, 1998; Agresti, 2002; Winkelmann, 2008).", "startOffset": 187, "endOffset": 257}, {"referenceID": 1, "context": "The regression analysis of counts is commonly performed under the Poisson or NB likelihoods, whose parameters are usually estimated by finding the maximum of the nonlinear log likelihood (Long, 1997; Cameron & Trivedi, 1998; Agresti, 2002; Winkelmann, 2008).", "startOffset": 187, "endOffset": 257}, {"referenceID": 29, "context": "The regression analysis of counts is commonly performed under the Poisson or NB likelihoods, whose parameters are usually estimated by finding the maximum of the nonlinear log likelihood (Long, 1997; Cameron & Trivedi, 1998; Agresti, 2002; Winkelmann, 2008).", "startOffset": 187, "endOffset": 257}, {"referenceID": 17, "context": "In addition, the MLE of the NB dispersion parameter r often lacks robustness and may be severely biased or even fail to converge if the sample size is small, the mean is small or if r is large (Saha & Paul, 2005; Lloyd-Smith, 2007).", "startOffset": 193, "endOffset": 231}, {"referenceID": 8, "context": "For instance, for the NB dispersion parameter r, the only available closed-form Bayesian solution relies on approximating the ratio of two gamma functions using a polynomial expansion (Bradlow et al., 2002); and for the regression coefficients \u03b2, Bayesian solutions usually involve computationally intensive Metropolis-Hastings algorithms, since the conjugate prior for \u03b2 is not known under the Poisson and NB likelihoods (Chib et al.", "startOffset": 184, "endOffset": 206}, {"referenceID": 12, "context": ", 2002); and for the regression coefficients \u03b2, Bayesian solutions usually involve computationally intensive Metropolis-Hastings algorithms, since the conjugate prior for \u03b2 is not known under the Poisson and NB likelihoods (Chib et al., 1998; Chib & Winkelmann, 2001; Winkelmann, 2008).", "startOffset": 223, "endOffset": 285}, {"referenceID": 29, "context": ", 2002); and for the regression coefficients \u03b2, Bayesian solutions usually involve computationally intensive Metropolis-Hastings algorithms, since the conjugate prior for \u03b2 is not known under the Poisson and NB likelihoods (Chib et al., 1998; Chib & Winkelmann, 2001; Winkelmann, 2008).", "startOffset": 223, "endOffset": 285}, {"referenceID": 18, "context": "The most basic regression model for counts is the Poisson regression model (Long, 1997; Cameron & Trivedi, 1998; Winkelmann, 2008), which can be expressed as", "startOffset": 75, "endOffset": 130}, {"referenceID": 29, "context": "The most basic regression model for counts is the Poisson regression model (Long, 1997; Cameron & Trivedi, 1998; Winkelmann, 2008), which can be expressed as", "startOffset": 75, "endOffset": 130}, {"referenceID": 18, "context": "The Newton-Raphson method can be used to iteratively find the MLE of \u03b2 (Long, 1997).", "startOffset": 71, "endOffset": 83}, {"referenceID": 29, "context": "In practice, however, count data are often overdispersed, due to heterogeneity and contagion (Winkelmann, 2008).", "startOffset": 93, "endOffset": 111}, {"referenceID": 29, "context": "To model overdispersed counts, the Poisson regression model can be modified as yi \u223c Pois(\u03bbi), \u03bbi = exp(xi \u03b2) i (2) where i is a nonnegative multiplicative random-effect term to model individual heterogeneity (Winkelmann, 2008).", "startOffset": 208, "endOffset": 226}, {"referenceID": 18, "context": "The NB regression model (Long, 1997; Cameron & Trivedi, 1998; Winkelmann, 2008; Hilbe, 2007) is constructed by placing a gamma prior on i as i \u223c Gamma(r, 1/r) = r \u0393(r) i r\u22121e\u2212r i (5) where E[ i] = 1 and Var[ i] = r\u22121.", "startOffset": 24, "endOffset": 92}, {"referenceID": 29, "context": "The NB regression model (Long, 1997; Cameron & Trivedi, 1998; Winkelmann, 2008; Hilbe, 2007) is constructed by placing a gamma prior on i as i \u223c Gamma(r, 1/r) = r \u0393(r) i r\u22121e\u2212r i (5) where E[ i] = 1 and Var[ i] = r\u22121.", "startOffset": 24, "endOffset": 92}, {"referenceID": 15, "context": "The NB regression model (Long, 1997; Cameron & Trivedi, 1998; Winkelmann, 2008; Hilbe, 2007) is constructed by placing a gamma prior on i as i \u223c Gamma(r, 1/r) = r \u0393(r) i r\u22121e\u2212r i (5) where E[ i] = 1 and Var[ i] = r\u22121.", "startOffset": 24, "endOffset": 92}, {"referenceID": 16, "context": "The MLEs of \u03b2 and \u03c6 can be found numerically with the Newton-Raphson method (Lawless, 1987).", "startOffset": 76, "endOffset": 91}, {"referenceID": 9, "context": "A lognormal-Poisson regression model (Breslow, 1984; Long, 1997; Agresti, 2002; Winkelmann, 2008) can be constructed by placing a lognormal prior on i as i \u223c lnN (0, \u03c3) (8)", "startOffset": 37, "endOffset": 97}, {"referenceID": 18, "context": "A lognormal-Poisson regression model (Breslow, 1984; Long, 1997; Agresti, 2002; Winkelmann, 2008) can be constructed by placing a lognormal prior on i as i \u223c lnN (0, \u03c3) (8)", "startOffset": 37, "endOffset": 97}, {"referenceID": 1, "context": "A lognormal-Poisson regression model (Breslow, 1984; Long, 1997; Agresti, 2002; Winkelmann, 2008) can be constructed by placing a lognormal prior on i as i \u223c lnN (0, \u03c3) (8)", "startOffset": 37, "endOffset": 97}, {"referenceID": 29, "context": "A lognormal-Poisson regression model (Breslow, 1984; Long, 1997; Agresti, 2002; Winkelmann, 2008) can be constructed by placing a lognormal prior on i as i \u223c lnN (0, \u03c3) (8)", "startOffset": 37, "endOffset": 97}, {"referenceID": 13, "context": "The inverse Gaussian distribution prior can also be placed on i to construct a heavier-tailed alternative to the NB model (Dean et al., 1989), whose density functions are shown to be virtually identical to the lognormal-Poisson model (Winkelmann, 2008).", "startOffset": 122, "endOffset": 141}, {"referenceID": 29, "context": ", 1989), whose density functions are shown to be virtually identical to the lognormal-Poisson model (Winkelmann, 2008).", "startOffset": 100, "endOffset": 118}, {"referenceID": 28, "context": "However, Winkelmann (2008) suggests to reevaluate the lognormal-Poisson model, since it is appealing in theory and may fit the data better.", "startOffset": 9, "endOffset": 27}, {"referenceID": 29, "context": "Bayesian analysis of counts, however, is seriously limited by the lack of efficient inference, as the conjugate prior for the regression coefficients \u03b2 is unknown under the Poisson and NB likelihoods (Winkelmann, 2008), and the conjugate prior for the NB dispersion parameter r is also unknown.", "startOffset": 200, "endOffset": 218}, {"referenceID": 27, "context": "If we marginalize out \u03b1p in (13), we obtain a Student-t prior for \u03b2p, the sparsity-promoting prior used in Tipping (2001); Bishop & Tipping (2000) for regression analysis of both Gaussian and binary data.", "startOffset": 107, "endOffset": 122}, {"referenceID": 27, "context": "If we marginalize out \u03b1p in (13), we obtain a Student-t prior for \u03b2p, the sparsity-promoting prior used in Tipping (2001); Bishop & Tipping (2000) for regression analysis of both Gaussian and binary data.", "startOffset": 107, "endOffset": 147}, {"referenceID": 28, "context": "We comment here that the novel Bayesian inference developed here can be applied to any other scenarios where the conditional posterior of r is proportional to \u220fN i=1 NB(yi; r, pi)Gamma(r; a0, 1/h), for which a hybrid Monte Carlo and a Metropolis-Hastings algorithms had been developed in Williamson et al. (2010) and Zhou et al.", "startOffset": 288, "endOffset": 313}, {"referenceID": 28, "context": "We comment here that the novel Bayesian inference developed here can be applied to any other scenarios where the conditional posterior of r is proportional to \u220fN i=1 NB(yi; r, pi)Gamma(r; a0, 1/h), for which a hybrid Monte Carlo and a Metropolis-Hastings algorithms had been developed in Williamson et al. (2010) and Zhou et al. (2012), but VB solutions were not yet developed.", "startOffset": 288, "endOffset": 336}, {"referenceID": 24, "context": "As proved in Quenouille (1949), y \u223c NB(r, p) can also be generated from a compound Poisson distribution as", "startOffset": 13, "endOffset": 31}, {"referenceID": 3, "context": "where Log(p) corresponds to the logarithmic distribution (Barndorff-Nielsen et al., 2010) with fU (k) = \u2212p/[k ln(1 \u2212 p)], k \u2208 {1, 2, .", "startOffset": 57, "endOffset": 89}, {"referenceID": 4, "context": "Using VB inference (Bishop & Tipping, 2000; Beal, 2003), we approximate the posterior p(r,L|X) with Q(r,L) = Qr(r) \u220fN i=1QLi(Li), and we have", "startOffset": 19, "endOffset": 55}, {"referenceID": 14, "context": "Note that a PG distributed random variable can be generated from an infinite sum of weighted iid gamma random variables (Devroye, 2009; Polson & Scott, 2011).", "startOffset": 120, "endOffset": 157}, {"referenceID": 4, "context": "Using VB inference (Bishop & Tipping, 2000; Beal, 2003), we approximate the posterior distribution with Q = Q\u03c8(\u03c8)Q\u03b2(\u03b2)Qr(r)Qh(h)Q\u03c6(\u03c6) \u220fP p=0Q\u03b1p(\u03b1p) \u220fN i=1[QLi(Li)Q\u03c9i(\u03c9i)].", "startOffset": 19, "endOffset": 55}, {"referenceID": 2, "context": "To calculate \u3008ln(1+ei)\u3009 in (41) and \u3008 tanh(\u03c8i/2) 2\u03c8i \u3009 in (47), we use the Monte Carlo integration algorithm (Andrieu et al., 2003).", "startOffset": 109, "endOffset": 131}, {"referenceID": 16, "context": "The inference of the NB dispersion parameter r by itself plays an important role not only for the NB regression (Lawless, 1987; Winkelmann, 2008) but also for univariate count data analysis (Bliss & Fisher, 1953; Clark & Perry, 1989; Saha & Paul, 2005; Lloyd-Smith, 2007), and it also arises in some recently proposed latent variable models for count matrix factorization (Williamson et al.", "startOffset": 112, "endOffset": 145}, {"referenceID": 29, "context": "The inference of the NB dispersion parameter r by itself plays an important role not only for the NB regression (Lawless, 1987; Winkelmann, 2008) but also for univariate count data analysis (Bliss & Fisher, 1953; Clark & Perry, 1989; Saha & Paul, 2005; Lloyd-Smith, 2007), and it also arises in some recently proposed latent variable models for count matrix factorization (Williamson et al.", "startOffset": 112, "endOffset": 145}, {"referenceID": 17, "context": "The inference of the NB dispersion parameter r by itself plays an important role not only for the NB regression (Lawless, 1987; Winkelmann, 2008) but also for univariate count data analysis (Bliss & Fisher, 1953; Clark & Perry, 1989; Saha & Paul, 2005; Lloyd-Smith, 2007), and it also arises in some recently proposed latent variable models for count matrix factorization (Williamson et al.", "startOffset": 190, "endOffset": 271}, {"referenceID": 28, "context": "The inference of the NB dispersion parameter r by itself plays an important role not only for the NB regression (Lawless, 1987; Winkelmann, 2008) but also for univariate count data analysis (Bliss & Fisher, 1953; Clark & Perry, 1989; Saha & Paul, 2005; Lloyd-Smith, 2007), and it also arises in some recently proposed latent variable models for count matrix factorization (Williamson et al., 2010; Zhou et al., 2012).", "startOffset": 372, "endOffset": 416}, {"referenceID": 31, "context": "The inference of the NB dispersion parameter r by itself plays an important role not only for the NB regression (Lawless, 1987; Winkelmann, 2008) but also for univariate count data analysis (Bliss & Fisher, 1953; Clark & Perry, 1989; Saha & Paul, 2005; Lloyd-Smith, 2007), and it also arises in some recently proposed latent variable models for count matrix factorization (Williamson et al., 2010; Zhou et al., 2012).", "startOffset": 372, "endOffset": 416}, {"referenceID": 13, "context": "The MotorIns dataset, analyzed in Dean et al. (1989), consists of Swedish third-party motor insurance claims in 1977.", "startOffset": 34, "endOffset": 53}, {"referenceID": 13, "context": "The MotorIns dataset, analyzed in Dean et al. (1989), consists of Swedish third-party motor insurance claims in 1977. Included in the data are the total number of claims for automobiles insured in each of the 315 risk groups, defined by a combination of DISTANCE, BONUS, and MAKE factor levels. The number of insured automobile-years for each group is also given. As in Dean et al. (1989), a 19 dimensional covariate vector is constructed for each group to represent levels of the factors.", "startOffset": 34, "endOffset": 389}, {"referenceID": 13, "context": "The MotorIns dataset, analyzed in Dean et al. (1989), consists of Swedish third-party motor insurance claims in 1977. Included in the data are the total number of claims for automobiles insured in each of the 315 risk groups, defined by a combination of DISTANCE, BONUS, and MAKE factor levels. The number of insured automobile-years for each group is also given. As in Dean et al. (1989), a 19 dimensional covariate vector is constructed for each group to represent levels of the factors. To test goodness-of-fit, we use the Pearson residuals, a metric widely used in GLMs (McCullagh & Nelder, 1989), calculated as The inverse dispersion parameter \u03c6 = 1/0.9947 = 1.005 is mistakenly reported as the dispersion parameter r in Clark & Perry (1989) at Line 15, Page 314.", "startOffset": 34, "endOffset": 747}, {"referenceID": 28, "context": "The MLEs for the Poisson and NB models are wellknown and the update equations can be found in Winner; Winkelmann (2008). The MLE results for the IGPoisson model on the MotorIns data were reported in Dean et al.", "startOffset": 102, "endOffset": 120}, {"referenceID": 13, "context": "The MLE results for the IGPoisson model on the MotorIns data were reported in Dean et al. (1989). For the lognormal-Poisson model, no standard MLE algorithms are available and we choose Metropolis-Hastings (M-H) algorithms for parameter estimation.", "startOffset": 78, "endOffset": 97}, {"referenceID": 29, "context": "These observations also support the claim in (Winkelmann, 2008) that the lognormal-Poisson model should be reevaluated since it is appealing in theory and may fit the data better.", "startOffset": 45, "endOffset": 63}, {"referenceID": 12, "context": "As the univariate lognormal-Poisson regression model can be easily generalized to regression analysis of correlated counts, in which the derivatives and Hessian matrixes of parameters are used to construct multivariate normal proposals in a MetropolisHastings algorithm (Chib et al., 1998; Chib & Winkelmann, 2001; Ma et al., 2008; Winkelmann, 2008), the proposed LGNB model can be conveniently modified for multivariate count regression, in which we may be able to derive closed-form Gibbs sampling and VB inference.", "startOffset": 270, "endOffset": 349}, {"referenceID": 19, "context": "As the univariate lognormal-Poisson regression model can be easily generalized to regression analysis of correlated counts, in which the derivatives and Hessian matrixes of parameters are used to construct multivariate normal proposals in a MetropolisHastings algorithm (Chib et al., 1998; Chib & Winkelmann, 2001; Ma et al., 2008; Winkelmann, 2008), the proposed LGNB model can be conveniently modified for multivariate count regression, in which we may be able to derive closed-form Gibbs sampling and VB inference.", "startOffset": 270, "endOffset": 349}, {"referenceID": 29, "context": "As the univariate lognormal-Poisson regression model can be easily generalized to regression analysis of correlated counts, in which the derivatives and Hessian matrixes of parameters are used to construct multivariate normal proposals in a MetropolisHastings algorithm (Chib et al., 1998; Chib & Winkelmann, 2001; Ma et al., 2008; Winkelmann, 2008), the proposed LGNB model can be conveniently modified for multivariate count regression, in which we may be able to derive closed-form Gibbs sampling and VB inference.", "startOffset": 270, "endOffset": 349}, {"referenceID": 0, "context": "As the log Gaussian process can be used to model the intensity of the Poisson process, whose inference remains a major challenge (M\u00f8ller et al., 1998; Adams et al., 2009; Murray et al., 2010; Rao & Teh, 2011), we may link the log Gaussian process to the", "startOffset": 129, "endOffset": 208}, {"referenceID": 21, "context": "As the log Gaussian process can be used to model the intensity of the Poisson process, whose inference remains a major challenge (M\u00f8ller et al., 1998; Adams et al., 2009; Murray et al., 2010; Rao & Teh, 2011), we may link the log Gaussian process to the", "startOffset": 129, "endOffset": 208}, {"referenceID": 28, "context": "Furthermore, the NB distribution is shown to be important for the factorization of a term-document count matrix (Williamson et al., 2010; Zhou et al., 2012), and the multinomial logit has been used to model correlated topics in topic modeling (Blei & Lafferty, 2005; Paisley et al.", "startOffset": 112, "endOffset": 156}, {"referenceID": 31, "context": "Furthermore, the NB distribution is shown to be important for the factorization of a term-document count matrix (Williamson et al., 2010; Zhou et al., 2012), and the multinomial logit has been used to model correlated topics in topic modeling (Blei & Lafferty, 2005; Paisley et al.", "startOffset": 112, "endOffset": 156}, {"referenceID": 22, "context": ", 2012), and the multinomial logit has been used to model correlated topics in topic modeling (Blei & Lafferty, 2005; Paisley et al., 2011).", "startOffset": 94, "endOffset": 139}], "year": 2012, "abstractText": "In regression analysis of counts, a lack of simple and efficient algorithms for posterior computation has made Bayesian approaches appear unattractive and thus underdeveloped. We propose a lognormal and gamma mixed negative binomial (NB) regression model for counts, and present efficient closed-form Bayesian inference; unlike conventional Poisson models, the proposed approach has two free parameters to include two different kinds of random effects, and allows the incorporation of prior information, such as sparsity in the regression coefficients. By placing a gamma distribution prior on the NB dispersion parameter r, and connecting a lognormal distribution prior with the logit of the NB probability parameter p, efficient Gibbs sampling and variational Bayes inference are both developed. The closed-form updates are obtained by exploiting conditional conjugacy via both a compound Poisson representation and a Polya-Gamma distribution based data augmentation approach. The proposed Bayesian inference can be implemented routinely, while being easily generalizable to more complex settings involving multivariate dependence structures. The algorithms are illustrated using real examples.", "creator": "LaTeX with hyperref package"}}}