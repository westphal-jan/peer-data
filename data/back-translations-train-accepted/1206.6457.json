{"id": "1206.6457", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Exponential Regret Bounds for Gaussian Process Bandits with Deterministic Observations", "abstract": "This paper analyzes the problem of Gaussian process (GP) bandits with deterministic observations. The analysis uses a branch and bound algorithm that is related to the UCB algorithm of (Srinivas et al, 2010). For GPs with Gaussian observation noise, with variance strictly greater than zero, Srinivas et al proved that the regret vanishes at the approximate rate of $O(1/\\sqrt{t})$, where t is the number of observations. To complement their result, we attack the deterministic case and attain a much faster exponential convergence rate. Under some regularity assumptions, we show that the regret decreases asymptotically according to $O(e^{-\\frac{\\tau t}{(\\ln t)^{d/4}}})$ with high probability. Here, d is the dimension of the search space and tau is a constant that depends on the behaviour of the objective function near its global maximum.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (295kb)", "http://arxiv.org/abs/1206.6457v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012). arXiv admin note: substantial text overlap witharXiv:1203.2177"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012). arXiv admin note: substantial text overlap witharXiv:1203.2177", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["nando de freitas", "alexander j smola", "masrour zoghi"], "accepted": true, "id": "1206.6457"}, "pdf": {"name": "1206.6457.pdf", "metadata": {"source": "META", "title": "Exponential Regret Bounds for Gaussian Process Bandits with Deterministic Observations", "authors": ["Nando de Freitas", "Alex J. Smola"], "emails": ["nando@cs.ubc.ca", "alex@smola.org", "mzoghi@cs.ubc.ca"], "sections": [{"heading": null, "text": "(1 \u221a t), where t is the number of observations. To supplement their result, we attack the deterministic case and achieve a much faster exponential convergence rate. Under some regularity assumptions, we show that regret decreases asymp-totically after O (e \u2212 \u03c4t (ln t) d / 4) with a high probability."}, {"heading": "1. Introduction", "text": "In fact, it is so that most of them are able to survive themselves, and that they do not. (...) It is not as if they were able to survive themselves. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...)\" It is as if. \"(...). (...)\" (...). \"(It is.\" (...). \"(It is.\" (...). \"It is.\" (...). \"It is.\" (... \"It is.\" (...). \"It is.\" (... \"It is.\" (...). \"It is.\" (... \"It is.\" (...). \"It is.\" (... \"It is.\" (... \"It is.\" (...). \"It is.\" (... \"It is.\" (... \"It is.\" (...). \"It is.\" (... \"It is.\" It is. \"(...\" It is. \"(...\" It is. \"(...).\" It is. (... \"It is. (...\" It is. \"it is.\" (... \"is.\" It is. (... \"It is.\"). \"it is. (...\" is. \"it is.\" it. (... \"). (it is. (it.\" is. \"It is. (it.\"). (it is. \"). (it is. (it.\" it is. (it is. \"). (it is. (it.\" it is. (it is. (it.). (it.). (it.). (it is. (it is. (it is.). (it is. (it is.). (it is. (it is. (it is.).). (it is. (it is."}, {"heading": "2. Gaussian process bandits", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Gaussian processes", "text": "As in (Srinivas et al., 2010), the objective function is distributed according to a Gaussian process: f (x) \u0445 GP (m (\u00b7), \u0445 (\u00b7, \u00b7))). (1) For the sake of simplicity and without loss of generality, we assume that the previous mean disappears, i.e., m (\u00b7) = 0. There are many choices for the covariance nucleus. An obvious choice is the anisotropic kernel, which has a vector of known hyperparameters (Ras-Mussen & Williams, 2006): p (xi, xj) = 1 (xi \u2212 xj) > D (xi \u2212 xj))))), (2), which is an isotropic kernel and D is a diagonal matrix with positive hyperparameters (Ras-Mussen & Williams, 2006): p (xi, xj) = 1 (xi \u2212 xj) > D (xi \u2212 xj), 2006), Williams is a muscle matrix (x), and a muscle matrix (D)."}, {"heading": "2.2. Surrogates for optimization", "text": "Assuming that the objective function f is sampled by a general practitioner, one can use a combination of the posterior predictive mean and the variance given by equations (3) to construct replacement functions that tell us where to try next. In this case, we use the UCB combination given by \u00b5t (x) + Bt\u03c3t (x), where {Bt} \u221e t = 1 is a sequence of numbers specified by the algorithm. This replacement function is much easier to optimize than the original objective function, since it is optimized by selecting points at which the mean is high (exploitation) and where the variance is large (exploration). Since the replacement function has an analytical expression that is easy to evaluate, it is much easier to optimize than the original objective function. Other popular replacement functions that are constructed on the basis of sufficient statistics of the general practitioner, include the probability of 2010, and the improvement we expect for 2009."}, {"heading": "2.3. Our algorithm", "text": "The main idea of our algorithm (algorithm 1) is to draw the boundary set by the UCB surrogate function to f by scanning the search space more and more closely and decreasing this space as more and more of the UCB surrogate function. (Figure 2 illustrates this intuition.) Specifically, the algorithm consists of two iterative stages. During the first stage, the function is scanned at enough points in L (the red crosses in Figure 3) until each point in the search space is contained within a simplex of the search space. (Figure 2) The algorithm consists of two iterative stages. (Figure 3) until each point in the search space is within a simplex of the diameter. (Figure 3) Such regions are reached by finding points where the UCB is lower than the LCB (the completion of the coloured region in the same panel as the remaining points)."}, {"heading": "3. Analysis", "text": "We begin our analysis by showing that the posterior prediction variance is small in view of sufficient sites examined. Specifically, the following approximate result is demonstrated in the supplementary material: sentence 1 (limit of variance) Let us: Rd \u00b7 Rd \u2192 R be a nucleus four times differentiable along the diagonal, where Q is defined as in part 2 of term 5, and f \u0445 GP (0, \u0445 (\u00b7, \u00b7))) a sample of the corresponding general practitioner. If f is sampled at points x1: T = {x1,..., xT}, which form a \u03b4 coverage of a subset of D Rd, then the resulting posterior prediction deviation \u03c3T satisfiessup D \u03c3T \u2264 Q\u03b424 results."}, {"heading": "3.1. Finiteness of regret", "text": "After showing that the variance disappears according to the square of the resolution of the grid of sampled points, we will now show that this estimate implies an exponential asymptotic disappearance of regret encountered by our branch-and-bottom algorithm. (This is set forth in our main theorem mentioned below and proven in the supplementary material. (Remember that D \u2212 Rd is a non-empty, compact subset and f \u2212 a sample from the GP (0, x, \u00b7))) to D. In addition, in what follows, we will find the global maximum by xM: = argmax x x x, and the regret by r (xt) = f (xM) \u2212 f (xt) \u2212 f (xt) to D: the global maximum xM: the global maximum by xM: x x x, then the regret by r (xM) \u2212 f (xt) \u2212 f (xt) \u2212 xt (f \u2212 xt)."}, {"heading": "3.2. Remarks on the main theorem", "text": "This section contains a discussion of the assumptions about objective function in Theorem 2 and an overview of the evidence, the full details of which are given in the appendix."}, {"heading": "3.2.1. On the statement of Theorem 2", "text": "A few remarks on the assumptions and conclusion of the main theorem are fine: A. Relationship between the local and global assumptions to f: The theorem has two seemingly independent limitations on the function f: the global GP before and the local behavior near the global maximum. However, in many interesting cases, the local state almost certainly follows from the global state. Two such circumstances are if it is a mate \u0301 rn nucleus with \u03bd > 2 (including the square exponential nucleus) or if it is differentiable six times. In both cases, the sample f is almost certainly doubly differentiable, in the former case by (Adler & Taylor, 2007, theorem 1.4.2) and (Stein, 1999, \u00a7 2.6) and in the latter situation by (Ghosal & Roy, 2006, theorem 5). If the global maximum xM is inside D, the Hessian of f will almost certainly not be singular at xM."}, {"heading": "3.2.2. Outline of the proof of Theorem 2", "text": "The starting point for the proof is the observation that one can use the posterior predictive agent and the standard deviation of the general practitioner to obtain a high probability envelope around the objective function (see Lemma 8 in the appendix). Given that the thickness of this envelope is determined by the height of the posterior predictive standard deviation, \u03c3, we can use the limit given by Proposition 1 to show that one can asymptotically quickly dispense with large portions of the search area, as shown in Figure 2.A disturbing component of algorithm 1 is the step at which twice as dense must be sampled in each iteration, since the number of samples can grow exponentially, thereby cancelling any hope of exponentially decreasing repentance. However, this is the point at which the assumption of local behavior in the vicinity of the global maximum becomes relevant. Since Proposition 1 tells us that each time the function is doubled, we can amplify the gap so that the gap is amplified by 4."}, {"heading": "3.2.3. Further remarks on the GP prior", "text": "Let us go back a moment and ask whether it would be possible to make a similar reasoning under different circumstances. To answer this, one must identify the key elements of the evidence, which are as follows: A. A mechanism for calculating an envelope with a high probability of lying around the objective function (see Lemma 8); B. An estimate that shows that the thickness of the envelope decreases rapidly as the function is sampled more and more densely (see Proposal 1), so that the search space can shrink under reasonable assumptions about the behavior of the function near the summit. The reason we impose on a family physician is that he gives us property A, while our assumption of smoothness on the core guarantees property. However, family physicians are only one way to obtain these characteristics, and they do this essentially by creating local estimates of the Lipschitz constant based on the observed values of the objective function in the proximity, and perhaps including similar estimates of the SOPTI over local lipops in 2011."}, {"heading": "4. Discussion", "text": "In this paper, we propose a modification of the UCB algorithm of the (Srinivas et al., 2010), which deals with noise freefall. The main difference is that the original algorithm achieves an O (t \u2212 1 2) rate of convergence to the repentance minimizer, we get an exponential rate in the number of function evaluations. In other words, the noise-free problem is significantly simpler, statistically speaking, than the loud case. The main difference is that we do not need to invest samples in noise reduction to determine whether our observations deviate far from their expectations, which allows us to discard parts of the search space where the maximum is very unlikely, in comparison to this (Srinivas et al., 2010). We show that this additional step leads to a significant improvement in regret achieved by the algorithm."}, {"heading": "Acknowledgements", "text": "We are very grateful to the anonymous reviewers for their excellent feedback. This research was supported by NSERC and the Institute for Computing, Information and Cognitive Systems (ICICS) of UBC."}], "references": [{"title": "Fast learning rates for plug-in classifiers", "author": ["Audibert", "J.-Y", "A.B. Tsybakov"], "venue": "Annals of Statistics,", "citeRegEx": "Audibert et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2007}, {"title": "Agnostic active learning", "author": ["Balcan", "M.-F", "A. Beygelzimer", "J. Langford"], "venue": "J. Comput. Syst. Sci,", "citeRegEx": "Balcan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2009}, {"title": "Active preference learning with discrete choice data", "author": ["E. Brochu", "N. de Freitas", "A. Ghosh"], "venue": "In NIPS, pp", "citeRegEx": "Brochu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Brochu et al\\.", "year": 2007}, {"title": "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "author": ["E. Brochu", "V.M. Cora", "N. de Freitas"], "venue": "Technical Report TR-2009-023,", "citeRegEx": "Brochu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Brochu et al\\.", "year": 2009}, {"title": "On exact learning halfspaces with random consistent hypothesis oracle", "author": ["N.H. Bshouty", "E. Wattad"], "venue": "In International Conference on Algorithmic Learning Theory, pp", "citeRegEx": "Bshouty and Wattad,? \\Q2006\\E", "shortCiteRegEx": "Bshouty and Wattad", "year": 2006}, {"title": "Convergence rates of efficient global optimization algorithms", "author": ["A.D. Bull"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bull,? \\Q2011\\E", "shortCiteRegEx": "Bull", "year": 2011}, {"title": "Analysis of perceptron-based active learning", "author": ["S. Dasgupta", "A.T. Kalai", "C. Monteleoni"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Dasgupta et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2009}, {"title": "Bayesian optimization for sensor set selection", "author": ["R. Garnett", "M.A. Osborne", "S.J. Roberts"], "venue": "In ACM/IEEE International Conference on Information Processing in Sensor Networks,", "citeRegEx": "Garnett et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Garnett et al\\.", "year": 2010}, {"title": "Posterior consistency of Gaussian process prior for nonparametric binary regression", "author": ["S. Ghosal", "A. Roy"], "venue": "Ann. Stat.,", "citeRegEx": "Ghosal and Roy,? \\Q2006\\E", "shortCiteRegEx": "Ghosal and Roy", "year": 2006}, {"title": "Parameter space exploration with Gaussian process trees", "author": ["R.B. Gramacy", "H.K.H. Lee", "W. MacReady"], "venue": "In ICML, pp", "citeRegEx": "Gramacy et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Gramacy et al\\.", "year": 2004}, {"title": "Global optimization of univariate Lipschitz functions: I. survey and properties", "author": ["P. Hansen", "B. Jaumard", "S. Lu"], "venue": "Mathematical Programming,", "citeRegEx": "Hansen et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Hansen et al\\.", "year": 1992}, {"title": "Portfolio allocation for Bayesian optimization", "author": ["M. Hoffman", "E. Brochu", "N. de Freitas"], "venue": "In UAI, pp", "citeRegEx": "Hoffman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 2011}, {"title": "Automated configuration of mixed integer programming solvers", "author": ["F. Hutter", "H.H. Hoos", "K. Leyton-Brown"], "venue": "In Proceedings of CPAIOR-10,", "citeRegEx": "Hutter et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hutter et al\\.", "year": 2010}, {"title": "Practical Bayesian Optimization", "author": ["D. Lizotte"], "venue": "PhD thesis, University of Alberta,", "citeRegEx": "Lizotte,? \\Q2008\\E", "shortCiteRegEx": "Lizotte", "year": 2008}, {"title": "Optimistic Bayesian sampling in contextual-bandit problems", "author": ["B. May", "N. Korda", "A. Lee", "D. Leslie"], "venue": null, "citeRegEx": "May et al\\.,? \\Q2010\\E", "shortCiteRegEx": "May et al\\.", "year": 2010}, {"title": "The Bayesian approach to global optimization", "author": ["J. Mo\u010dkus"], "venue": "In System Modeling and Optimization,", "citeRegEx": "Mo\u010dkus,? \\Q1982\\E", "shortCiteRegEx": "Mo\u010dkus", "year": 1982}, {"title": "Optimistic optimization of a deterministic function without the knowledge of its smoothness", "author": ["R. Munos"], "venue": "In NIPS,", "citeRegEx": "Munos,? \\Q2011\\E", "shortCiteRegEx": "Munos", "year": 2011}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": null, "citeRegEx": "Rasmussen and Williams,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen and Williams", "year": 2006}, {"title": "Global versus local search in constrained optimization of computer models", "author": ["M. Schonlau", "W.J. Welch", "D.R. Jones"], "venue": "Lecture Notes-Monograph Series,", "citeRegEx": "Schonlau et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Schonlau et al\\.", "year": 1998}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S.M. Kakade", "M. Seeger"], "venue": "In ICML,", "citeRegEx": "Srinivas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Interpolation of Spatial Data: Some Theory for Kriging", "author": ["M.L. Stein"], "venue": null, "citeRegEx": "Stein,? \\Q1999\\E", "shortCiteRegEx": "Stein", "year": 1999}, {"title": "Statistical Learning Theory", "author": ["V. Vapnik"], "venue": null, "citeRegEx": "Vapnik,? \\Q1998\\E", "shortCiteRegEx": "Vapnik", "year": 1998}, {"title": "Convergence properties of the expected improvement algorithm with fixed mean and covariance functions", "author": ["E. Vazquez", "J. Bect"], "venue": "J. of Statistical Planning and Inference,", "citeRegEx": "Vazquez and Bect,? \\Q2010\\E", "shortCiteRegEx": "Vazquez and Bect", "year": 2010}], "referenceMentions": [{"referenceID": 19, "context": "The analysis uses a branch and bound algorithm that is related to the UCB algorithm of (Srinivas et al., 2010).", "startOffset": 87, "endOffset": 110}, {"referenceID": 19, "context": "For GPs with Gaussian observation noise, with variance strictly greater than zero, (Srinivas et al., 2010) proved that the regret vanishes at the approximate", "startOffset": 83, "endOffset": 106}, {"referenceID": 15, "context": "We refer the reader to (Mo\u010dkus, 1982; Schonlau et al., 1998; Gramacy et al., 2004; Brochu et al., 2007; Lizotte, 2008; Martinez\u2013Cantin et al., 2009; Garnett et al., 2010) for practical examples.", "startOffset": 23, "endOffset": 170}, {"referenceID": 18, "context": "We refer the reader to (Mo\u010dkus, 1982; Schonlau et al., 1998; Gramacy et al., 2004; Brochu et al., 2007; Lizotte, 2008; Martinez\u2013Cantin et al., 2009; Garnett et al., 2010) for practical examples.", "startOffset": 23, "endOffset": 170}, {"referenceID": 9, "context": "We refer the reader to (Mo\u010dkus, 1982; Schonlau et al., 1998; Gramacy et al., 2004; Brochu et al., 2007; Lizotte, 2008; Martinez\u2013Cantin et al., 2009; Garnett et al., 2010) for practical examples.", "startOffset": 23, "endOffset": 170}, {"referenceID": 2, "context": "We refer the reader to (Mo\u010dkus, 1982; Schonlau et al., 1998; Gramacy et al., 2004; Brochu et al., 2007; Lizotte, 2008; Martinez\u2013Cantin et al., 2009; Garnett et al., 2010) for practical examples.", "startOffset": 23, "endOffset": 170}, {"referenceID": 13, "context": "We refer the reader to (Mo\u010dkus, 1982; Schonlau et al., 1998; Gramacy et al., 2004; Brochu et al., 2007; Lizotte, 2008; Martinez\u2013Cantin et al., 2009; Garnett et al., 2010) for practical examples.", "startOffset": 23, "endOffset": 170}, {"referenceID": 7, "context": "We refer the reader to (Mo\u010dkus, 1982; Schonlau et al., 1998; Gramacy et al., 2004; Brochu et al., 2007; Lizotte, 2008; Martinez\u2013Cantin et al., 2009; Garnett et al., 2010) for practical examples.", "startOffset": 23, "endOffset": 170}, {"referenceID": 12, "context": "An example of this is the configuration of CPLEX parameters in mixed-integer programming (Hutter et al., 2010).", "startOffset": 89, "endOffset": 110}, {"referenceID": 10, "context": "on f , which requires the change in the value of f(x), as the point x moves around, to be smaller than a constant multiple of the distance traveled by x (Hansen et al., 1992).", "startOffset": 153, "endOffset": 174}, {"referenceID": 3, "context": "A solution to this problem is to approximate f with a surrogate function that provides a good upper bound for f and which is easier to calculate and optimize (Brochu et al., 2009).", "startOffset": 158, "endOffset": 179}, {"referenceID": 19, "context": "This surrogate function has been studied extensively in the literature and this paper relies heavily on the ideas put forth in the paper by Srinivas et al (Srinivas et al., 2010), in which the algorithm consists of repeated optimization of the UCB surrogate function after each sample.", "startOffset": 155, "endOffset": 178}, {"referenceID": 19, "context": "One key difference between our setting and that of (Srinivas et al., 2010) is that, whereas we assume that the value of the function can be observed exactly, for the analysis presented in (Srinivas et al.", "startOffset": 51, "endOffset": 74}, {"referenceID": 19, "context": ", 2010) is that, whereas we assume that the value of the function can be observed exactly, for the analysis presented in (Srinivas et al., 2010) it is necessary for the noise to be non-trivial (and Gaussian) because the main quantity that is used in the estimates, namely information gain, cf.", "startOffset": 121, "endOffset": 144}, {"referenceID": 16, "context": "The paper whose results are most similar to ours is (Munos, 2011), but there are some key differences in the methodology, analysis and obtained rates.", "startOffset": 52, "endOffset": 65}, {"referenceID": 16, "context": "For instance, we are interested in cumulative regret, whereas the results of (Munos, 2011) are proven for finite stop-time regret.", "startOffset": 77, "endOffset": 90}, {"referenceID": 16, "context": "regret rate O ( e \u2212 \u03c4t (ln t)d/4 ) , whereas the DOO algorithm in (Munos, 2011) has regret rate O(e\u2212t) if the Hessian is known and the SOO algorithm has regret rate O(e\u2212 \u221a ) if the Hessian is unknown.", "startOffset": 66, "endOffset": 79}, {"referenceID": 16, "context": "In addition, the algorithms in (Munos, 2011) can handle functions that behave like \u2212c\u2016x \u2212 xM\u2016 near the maximum (cf.", "startOffset": 31, "endOffset": 44}, {"referenceID": 5, "context": "This problem was also studied by (Vazquez & Bect, 2010) and (Bull, 2011), but using the Expected Improvement surrogate instead of UCB.", "startOffset": 60, "endOffset": 72}, {"referenceID": 19, "context": "As in (Srinivas et al., 2010), the objective function is distributed according to a Gaussian process prior:", "startOffset": 6, "endOffset": 29}, {"referenceID": 3, "context": "We refer the reader to (Brochu et al., 2009; May et al., 2010; Hoffman et al., 2011) for details on these.", "startOffset": 23, "endOffset": 84}, {"referenceID": 14, "context": "We refer the reader to (Brochu et al., 2009; May et al., 2010; Hoffman et al., 2011) for details on these.", "startOffset": 23, "endOffset": 84}, {"referenceID": 11, "context": "We refer the reader to (Brochu et al., 2009; May et al., 2010; Hoffman et al., 2011) for details on these.", "startOffset": 23, "endOffset": 84}, {"referenceID": 16, "context": ", 2011) and (Munos, 2011), in which case one would be able to dispense with the GP assumption and get similar performance.", "startOffset": 12, "endOffset": 25}, {"referenceID": 19, "context": "In this paper we proposed a modification of the UCB algorithm of (Srinivas et al., 2010) which addresses the noise free case.", "startOffset": 65, "endOffset": 88}, {"referenceID": 19, "context": "This allows us to discard pieces of the search space where the maximum is very unlikely to be, when compared to (Srinivas et al., 2010).", "startOffset": 112, "endOffset": 135}, {"referenceID": 16, "context": "(Munos, 2011), where regions of the space are deemed as less worthy of probing as time goes on.", "startOffset": 0, "endOffset": 13}, {"referenceID": 6, "context": "Our results mirror the observation in active learning that noise free and large margin learning of half spaces can be achieved much more rapidly than identifying a linear separator in the noisy case (Bshouty & Wattad, 2006; Dasgupta et al., 2009).", "startOffset": 199, "endOffset": 246}, {"referenceID": 21, "context": "This is also reflected in classical uniform convergence results for supervised learning (Audibert & Tsybakov, 2007; Vapnik, 1998) where the achievable rate depends on the decay of probability mass near the margin.", "startOffset": 88, "endOffset": 129}, {"referenceID": 1, "context": "An indication of what might be possible can be found in (Balcan et al., 2009), where regions of the version space are eliminated once they can be excluded with sufficiently high probability.", "startOffset": 56, "endOffset": 77}], "year": 2012, "abstractText": "This paper analyzes the problem of Gaussian process (GP) bandits with deterministic observations. The analysis uses a branch and bound algorithm that is related to the UCB algorithm of (Srinivas et al., 2010). For GPs with Gaussian observation noise, with variance strictly greater than zero, (Srinivas et al., 2010) proved that the regret vanishes at the approximate rate of O ( 1 \u221a t ) , where t is the number of observations. To complement their result, we attack the deterministic case and attain a much faster exponential convergence rate. Under some regularity assumptions, we show that the regret decreases asymptotically according to O ( e \u2212 \u03c4t (ln t)d/4 ) with high probability. Here, d is the dimension of the search space and \u03c4 is a constant that depends on the behaviour of the objective function near its global maximum.", "creator": "LaTeX with hyperref package"}}}