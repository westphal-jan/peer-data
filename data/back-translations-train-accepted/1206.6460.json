{"id": "1206.6460", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Output Space Search for Structured Prediction", "abstract": "We consider a framework for structured prediction based on search in the space of complete structured outputs. Given a structured input, an output is produced by running a time-bounded search procedure guided by a learned cost function, and then returning the least cost output uncovered during the search. This framework can be instantiated for a wide range of search spaces and search procedures, and easily incorporates arbitrary structured-prediction loss functions. In this paper, we make two main technical contributions. First, we define the limited-discrepancy search space over structured outputs, which is able to leverage powerful classification learning algorithms to improve the search space quality. Second, we give a generic cost function learning approach, where the key idea is to learn a cost function that attempts to mimic the behavior of conducting searches guided by the true loss function. Our experiments on six benchmark domains demonstrate that using our framework with only a small amount of search is sufficient for significantly improving on state-of-the-art structured-prediction performance.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (134kb)", "http://arxiv.org/abs/1206.6460v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG cs.AI stat.ML", "authors": ["janardhan rao doppa", "alan fern", "prasad tadepalli"], "accepted": true, "id": "1206.6460"}, "pdf": {"name": "1206.6460.pdf", "metadata": {"source": "CRF", "title": "Output Space Search for Structured Prediction", "authors": ["Janardhan Rao Doppa", "Alan Fern", "Prasad Tadepalli"], "emails": ["DOPPA@EECS.OREGONSTATE.EDU", "AFERN@EECS.OREGONSTATE.EDU", "TADEPALL@EECS.OREGONSTATE.EDU"], "sections": [{"heading": "1. Introduction", "text": "Structured prediction involves learning a predictor that can deliver complex structured results as complex structured inputs are available. Consider, for example, the problem of image scene labelling, where structured input is an image and structured output is a semantic labelling of image regions. We will examine a new search-based approach to structured predictions, which involves first defining a combinatorial search space through complete structured input that allows the output area to be exceeded. Next, given a structural appearance in the proceedings of the 29th International Conference on Machine Learning, Edinburgh, Scotland, UK, 2012, a state-structured input, a state-based search strategy (e.g. the best initial or greedy search) guided by a learned cost function, is used to explore the space of results for a specific time limit. The least costly expenditures revealed by the search are returned as predictions."}, {"heading": "2. Comparison to Related Work", "text": "In fact, most of them are able to survive and survive on their own, while others are able to survive and survive on their own."}, {"heading": "3. Problem Setup", "text": "A structured prediction problem specifies a space for structured input X, a space for structured output Y, and a nonnegative loss function L: X \u00d7 Y \u00d7 Y 7 \u2192 such that L (x, y \u2032, y) is the loss associated with the label of a certain input x by output y \u2032 if the actual output y is. We have a number of input / output pairs drawn from an unknown target distribution, and the goal is to return a function / predictor of structured input to output whose predicted output has low expected losses in terms of distribution. Since our algorithms are learning cost functions via input / output pairs, we assume the availability of a feature function: X \u00d7 Y 7 \u2192 n, which calculates an n-dimensional feature vector for any pairing. Output Space Search. We consider a framework for structured prediction based on state search, based on the search, in the search space, and the output y are more structured."}, {"heading": "4. Search Spaces Over Complete Outputs", "text": "In this section we describe two search spaces with structured results: 1) the flipbit space, a simple baseline, and 2) the LDS space, which should improve the baseline. We begin by describing recurring classifiers used to define both spaces."}, {"heading": "4.1. Recurrent Classifiers", "text": "A recursive classifier constructs structured outputs based on a series of discrete decisions. This is formalized for a particular structured prediction problem by defining a suitable primitive search space. It is a 5x < I, A, s, f, T >, where I am a function that maps an input x to an initial search node, A is a finite set of actions (or operators), s is the successor function that maps each search node and action to a subsequent search node, f is a feature function of search nodes to real feature vectors, and T is the terminal state predicate that maps search nodes to {1, 0}, indicating whether the node is a terminal or not. Each terminal node in the search space corresponds to a complete structured output, while non-terminal nodes correlate to a partially structured note."}, {"heading": "4.2. Flipbit Search Space", "text": "The Flipbit search space is a simple full-output basespace that uses a given recurring classifier h for bootstrapping the search. Each search state is represented by a sequence of actions in primitive space ending in a terminal node that represents a complete output. The initial search state corresponds to the actions selected by the classifier, so that I (x) is equal to (x, h (x)), where h (x) is the output generated by the recurring classifier. Search steps generated by the successor function can change the value of an action at any arbitrary sequence position in the parent state. In the case of a sequence label problem, this corresponds to the initialization of the recurring classifier output and then the search by turning over individual labels. Flipbit space is often used by local search techniques (without classifier initialization) and is similar to the \"search space\" underlying the sampling."}, {"heading": "4.3. Limited-Discrepancy Search Space (LDS)", "text": "The motivation behind our LDS room is to use the recurring classifier more aggressively to improve the quality of the search space. LDS was originally introduced in the context of problem solving with heuristic search (Harvey & Ginsberg, 1995).To put LDS into context, we will describe it in terms of using a classifier for structured predictions that specify a primitive search space. If the learned classifier is accurate, then the number of erroneous action selections will be relatively small. However, a small number of errors can propagate and cause the bad outcomes.The key idea behind LDS is that the classifier response to the small number of critical errors has been corrected, then a much better output will be produced. LDS performs a (flat) search in the space of possible corrections."}, {"heading": "4.4. Search Space Quality", "text": "In fact, it is so that it is an \"error\" which is directly attributable to the \"quality\" of the LDS search space, in which the quality of the search for the objective is to be found. (...) It is so that the distribution according to the objective of the LDS search space is to be looked for according to the objective of the objective. (...) It is so that the distribution according to the objective of the LDS search space is according to the objective of the LDS search space. (...) It is as if the distribution according to the objective of the LDS search space is according to the objective. (...) It is as if the distribution according to the objective of the LDS search space is according to the objective of the LDS search space. (...) It is as if it is required according to the objective of the LDS search space. (... It is as if it is looked for according to the objective of the LDS.) It is as if it is searched for according to the objective of the LDS. (... It is as if it is searched for according to the objective of the LDS.)"}, {"heading": "5. Cost Function Learning", "text": "In this section, we describe a generic framework for cost functions that is applicable to a wide range of search spaces and search strategies. This approach is motivated by our observation that for a variety of structured prediction problems, we can uncover a high quality of results if we can conduct the search for the output space by using the loss function in relation to the target output quantity. Since the target output quantity is not available at the test date, we aim to learn a cost function that mimics the search behavior of the loss function on the training data. With an appropriate choice of the hypotheses space of cost functions, good performance on the training data translates into good performance on the test data. We now precisely define the notion of \"leading the search\" with a loss function. If the loss function can be called arbitrarily by the search method, then adjusting its performance would require the cost function to approximate it, which is unnecessary in most cases."}, {"heading": "6. Summary of Overall Approach", "text": "Our approach consists of two main components, a recurring classifier and a cost function, and we train them one after the other. First, we train the recurring classifier as described in Section 4.1. Then, with this trained classifier, we define one of the two search spaces on the complete output S (either Flipbit or LDS) for each training input x (see Section 4). Second, we train the cost function to calculate the results for a specific combination of search space on the complete output S and a search procedure P as in Section 5. At test time, we use the learned recurring classifier and the cost function to make predictions as follows. For each test entry x, we define the search space on the complete output S using the recurring classifier and execute the search procedure P in that search space guided by the cost function for a specified period of time. We return the best cost output y, which is revealed as a prediction for x during the search."}, {"heading": "7. Experiments and Results", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "8. Summary and Future Work", "text": "We examined a general framework for structured prediction based on the search for complete results; we demonstrated how powerful classifiers can be used to define an effective search space across complete results; and gave a generic approach to learning cost functions to evaluate the results for any combination of search space and search strategy; our experimental results showed that a very low search effort is required to improve the performance of our framework and confirm the effectiveness of our framework; future work will include studying robust training approaches to reduce the spread of errors when the cost function is not feasible; and eliminating scalability issues."}, {"heading": "Acknowledgements", "text": "This work was supported by NSF grants IIS 0964705, IIS 0958482, IIS-1018490 and DARPA contract FA8750-09C-0179."}], "references": [{"title": "A comparison of ID3 and backpropagation for english text-tospeech", "author": ["Dietterich", "Thomas G", "Hild", "Hermann", "Bakiri", "Ghulum"], "venue": "mapping. MLJ,", "citeRegEx": "Dietterich et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Dietterich et al\\.", "year": 1995}, {"title": "The generalized A", "author": ["Felzenszwalb", "Pedro F", "McAllester", "David A"], "venue": "architecture. JAIR,", "citeRegEx": "Felzenszwalb et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2007}, {"title": "Approximate policy iteration with a policy language bias: Solving relational Markov decision processes", "author": ["Fern", "Alan", "Yoon", "Sung Wook", "Givan", "Robert"], "venue": "JAIR, 25:75\u2013118,", "citeRegEx": "Fern et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Fern et al\\.", "year": 2006}, {"title": "Search-based structured prediction", "author": ["Hal Daum\u00e9 III", "Langford", "John", "Marcu", "Daniel"], "venue": "MLJ, 75(3):297\u2013325,", "citeRegEx": "III et al\\.,? \\Q2009\\E", "shortCiteRegEx": "III et al\\.", "year": 2009}, {"title": "Lower bounds for reductions", "author": ["M. K\u00e4\u00e4ri\u00e4inen"], "venue": "In Atomic Learning Workshop,", "citeRegEx": "K\u00e4\u00e4ri\u00e4inen,? \\Q2006\\E", "shortCiteRegEx": "K\u00e4\u00e4ri\u00e4inen", "year": 2006}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["Lafferty", "John", "McCallum", "Andrew", "Pereira", "Fernando"], "venue": "In ICML,", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Efficient reductions for imitation learning", "author": ["Ross", "St\u00e9phane", "Bagnell", "Drew"], "venue": "In AISTATS,", "citeRegEx": "Ross et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2010}, {"title": "A reduction of imitation learning and structured prediction to no-regret online learning", "author": ["Ross", "St\u00e9phane", "Gordon", "Geoffery", "Bagnell", "Drew"], "venue": "In AISTATS,", "citeRegEx": "Ross et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2011}, {"title": "A reduction from apprenticeship learning to classification", "author": ["Syed", "Umar", "Schapire", "Rob"], "venue": "In NIPS,", "citeRegEx": "Syed et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Syed et al\\.", "year": 2010}, {"title": "Maxmargin markov networks", "author": ["Taskar", "Benjamin", "Guestrin", "Carlos", "Koller", "Daphne"], "venue": "In NIPS,", "citeRegEx": "Taskar et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Taskar et al\\.", "year": 2003}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["Tsochantaridis", "Ioannis", "Hofmann", "Thomas", "Joachims", "Thorsten", "Altun", "Yasemin"], "venue": "In ICML,", "citeRegEx": "Tsochantaridis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2004}, {"title": "Semantic modeling of natural scenes for content-based image retrieval", "author": ["Vogel", "Julia", "Schiele", "Bernt"], "venue": null, "citeRegEx": "Vogel et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 2007}, {"title": "Structured prediction cascades", "author": ["Weiss", "David", "Taskar", "Ben"], "venue": "In AISTATS,", "citeRegEx": "Weiss et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Weiss et al\\.", "year": 2010}, {"title": "Sidestepping intractable inference with structured ensemble cascades", "author": ["Weiss", "David", "Sapp", "Ben", "Taskar"], "venue": "In NIPS,", "citeRegEx": "Weiss et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Weiss et al\\.", "year": 2010}, {"title": "Samplerank: Training factor graphs with atomic gradients", "author": ["Wick", "Michael L", "Rohanimanesh", "Khashayar", "Bellare", "Kedar", "Culotta", "Aron", "McCallum", "Andrew"], "venue": "In ICML,", "citeRegEx": "Wick et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wick et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 5, "context": "For example, the cost function is often represented as a linear model over template features of both x and y (Lafferty et al., 2001; Taskar et al., 2003; Tsochantaridis et al., 2004).", "startOffset": 109, "endOffset": 182}, {"referenceID": 9, "context": "For example, the cost function is often represented as a linear model over template features of both x and y (Lafferty et al., 2001; Taskar et al., 2003; Tsochantaridis et al., 2004).", "startOffset": 109, "endOffset": 182}, {"referenceID": 10, "context": "For example, the cost function is often represented as a linear model over template features of both x and y (Lafferty et al., 2001; Taskar et al., 2003; Tsochantaridis et al., 2004).", "startOffset": 109, "endOffset": 182}, {"referenceID": 12, "context": "One approach to addressing inference complexity is cascade training (Felzenszwalb & McAllester, 2007; Weiss & Taskar, 2010; Weiss et al., 2010), where efficient", "startOffset": 68, "endOffset": 143}, {"referenceID": 0, "context": "(Dietterich et al., 1995)) have shown good success and there are some positive theoretical guarantees (Syed & Schapire, 2010; Ross & Bagnell,", "startOffset": 0, "endOffset": 25}, {"referenceID": 4, "context": "However, recurrent classifiers can be prone to error propagation (K\u00e4\u00e4ri\u00e4inen, 2006; Ross & Bagnell, 2010).", "startOffset": 65, "endOffset": 105}, {"referenceID": 7, "context": "2009), SMiLe (Ross & Bagnell, 2010), and DAGGER (Ross et al., 2011), attempts to address this issue using more sophisticated training techniques and have shown state-of-the-art structured-prediction results.", "startOffset": 48, "endOffset": 67}, {"referenceID": 14, "context": "The most closely related framework to ours is the SampleRank framework (Wick et al., 2011), which learns a cost function for guiding a type of Monte-Carlo search in the space of complete outputs.", "startOffset": 71, "endOffset": 90}, {"referenceID": 2, "context": "The following theorem can be proved by adapting the proof of (Fern et al., 2006) with minor changes, e.", "startOffset": 61, "endOffset": 80}, {"referenceID": 9, "context": "This dataset contains roughly 6600 examples divided into 10 folds (Taskar et al., 2003).", "startOffset": 66, "endOffset": 87}, {"referenceID": 5, "context": "We compare our results with other structured prediction algorithms including CRFs (Lafferty et al., 2001), SVM-Struct (Tsochantaridis et al.", "startOffset": 82, "endOffset": 105}, {"referenceID": 10, "context": ", 2001), SVM-Struct (Tsochantaridis et al., 2004), SEARN (Hal Daum\u00e9 III et al.", "startOffset": 20, "endOffset": 49}], "year": 2012, "abstractText": "We consider a framework for structured prediction based on search in the space of complete structured outputs. Given a structured input, an output is produced by running a time-bounded search procedure guided by a learned cost function, and then returning the least cost output uncovered during the search. This framework can be instantiated for a wide range of search spaces and search procedures, and easily incorporates arbitrary structured-prediction loss functions. In this paper, we make two main technical contributions. First, we define the limited-discrepancy search space over structured outputs, which is able to leverage powerful classification learning algorithms to improve the search space quality. Second, we give a generic cost function learning approach, where the key idea is to learn a cost function that attempts to mimic the behavior of conducting searches guided by the true loss function. Our experiments on six benchmark domains demonstrate that using our framework with only a small amount of search is sufficient for significantly improving on state-of-the-art structuredprediction performance.", "creator": "gnuplot 4.4 patchlevel 0"}}}