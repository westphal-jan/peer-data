{"id": "1206.6469", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "Inferring Latent Structure From Mixed Real and Categorical Relational Data", "abstract": "We consider analysis of relational data (a matrix), in which the rows correspond to subjects (e.g., people) and the columns correspond to attributes. The elements of the matrix may be a mix of real and categorical. Each subject and attribute is characterized by a latent binary feature vector, and an inferred matrix maps each row-column pair of binary feature vectors to an observed matrix element. The latent binary features of the rows are modeled via a multivariate Gaussian distribution with low-rank covariance matrix, and the Gaussian random variables are mapped to latent binary features via a probit link. The same type construction is applied jointly to the columns. The model infers latent, low-dimensional binary features associated with each row and each column, as well correlation structure between all rows and between all columns.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (1047kb)", "http://arxiv.org/abs/1206.6469v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["esther salazar", "lawrence carin"], "accepted": true, "id": "1206.6469"}, "pdf": {"name": "1206.6469.pdf", "metadata": {"source": "META", "title": "Inferring Latent Structure From Mixed Real and Categorical Relational Data", "authors": ["Esther Salazar", "Matthew S. Cain", "Elise F. Darling", "Stephen R. Mitroff", "Lawrence Carin"], "emails": ["esther.salazar@duke.edu", "matthew.s.cain@duke.edu", "ed75@duke.edu", "mitroff@duke.edu", "lcarin@duke.edu"], "sections": [{"heading": "1. Introduction", "text": "This year, it has reached the stage where it will be able to take the lead, in the same way as it has done in the past."}, {"heading": "2. Basic Model Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Problem statement", "text": "There are categorical M1 entries and real M2 entries. The categorical data are represented as matrix X, and the real entries are represented by the matrix Y; we would like to analyze X and Y entries jointly. The transposition of the column vector xi represents the ith series of X, and the transposition of the column vector yi the ith series of Y. The vector xi = (xi1,.., xiM1) T contains categorical observations where xij entries {0,..., qj \u2212 1} and qj entries correspond to the number of categories associated with the jth component."}, {"heading": "2.2. Factor analysis", "text": "A qj-dimensional probit regression model is used for xij. Specifically, it is assumed that there is a characteristic vector vi-RKx associated with subject i (as discussed below, the need to set Kx disappears in the final form of the model. The observed multinomial variable xij is expressed in terms of a latent variable \u03b2ij-Rqj -1 such variable \u03b2ij + ij, ij-N (0-J) xij = {0 if max1 \u2264 l \u2264 qj \u2212 1 \u03b2 (l) ij < 0p if max1 \u2264 qj \u2212 1) ij (p) ij > 0wo p = 1,."}, {"heading": "2.3. Binary row and column feature vectors", "text": "Similarly, d (p) j {0, 1} K represents the latent binary character vector associated with s (p) j, with cj (0, 1} K, which is defined for bj (for notational simplicity) in such a way that we consider all binary vectors to be equal-dimensional K, but in practice the model reveals the number of binary components required to represent each of these vectors. We assume that (p) j = C (X) j and bj = C (Y) all binary vectors are equal-dimensional K, but in practice the model shows the number of binary components necessary to represent each of these vectors."}, {"heading": "2.4. Low-rank regression matrices", "text": "We model M (X) and M (Y) as low-level matrices: M > (X) = K \u2211 l = 1 \u03bb (X) l (X) l (X) l (X) l (X) l) T, (7) M (Y) = K \u2211 l = 1 \u03bb (Y) l b (Y) l (Y) l (Y) l (V) l (Y) l) T, (8) l (X) l (X) l, N0, v (X) l (Y) l, corresponding to a shortened normal distribution, about (0) l (Y) l (Y) l (Y) l (V) l (Y) l (Y) l is similarly defined. Thevectors u (X) l, v (X) l, v (Y) l and v (Y) l (X) l) l (X) l) l are similarly defined, and we discuss one in detail for concentration."}, {"heading": "3. Correlated Binary Feature Vectors", "text": "We describe in detail the proposed modeling of ri, with a similar construction applied to {d (p) j} and {cj}. A frugal multivariate probit model is imposed: \u03b7k \u0445 N (0, \u03a3), with rik | \u03b7ik = 1, and rik | \u03b7ik = 0, otherwise; k = 1,.., K, with \u03b7k the underlying correlation structure of \u03b7k, and rik is the kth. Component of ri. Marginal, rik \"Ber (\u03c0ik), where \u03c0ik = Pr (\u03b7ik > 0). The covariance matrix, which is an underlying correlation structure between (r1k,., rNk), for all binary characteristics k.We must now put a previous one on the coance matrix approach. A large class of models forces thrift on the reverse (i.e., the precedence matrix precedent) approach."}, {"heading": "4. Posterior Computation", "text": "Approaching the full back row of model parameters is based on a Gibbs sampler (with Metropolis-Hastings updates for a subset of parameters). We will now briefly describe how to determine some of the most interesting parameters based on their complete conditional back distributions. \u2022 Sample u (X) l as (X) l as (X) l as (X) l as (X) l, V (X) l as (IK) l as (E) i as (E) i) T as (E) l as (E) l as (I) \u2212 1, m (X) l as V (X) l as (E) l as (I)."}, {"heading": "5. Applications", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Analysis of the animals dataset", "text": "We first test the performance of the proposed model on the animal dataset (Kok & Domingos, 2007; Sutskever et al., 2009), which consists of 50 animal classes and 85 binary attributes (without missing data).Note that in this experiment we only have a categorical (binary) observation matrix X (0, 1) 50 x 85.The model is equipped with the proposed MCMC schema. We performed the algorithm taking into account 20,000 iterations with a burn-in of 5,000 pulls, and we collect every third sample giving us a total of 5,000 stored specimens.The analysis was performed with K = 20, c = d = 1, and \u03c32\u03bb = 1 (many similar settings yielded similar results).For the sparse probit factor model (discussed in Section 3) we consider six factors; larger models are possible and have been taken into account, as always in our experiments we noticed that fewer than six factors are sufficient to grasp the basic correlation structure."}, {"heading": "5.2. Senate voting data", "text": "We first examine a binary voting matrix from the United States Senate during the 110th Congress, from January 3, 2007 to January 3, 2009. The binary matrix, X, has the dimension 102 x 657, with each line corresponding to a senator and each column corresponding to a piece of legislation; X is manifested by mapping all \"yes\" votes to one and \"no\" votes (or abstentions) to zero. The percentage of missing values is about 7.1%. We perform the analysis of voting data taking into account K = 50. We use the same priors and MCMC setup taken into account in the previous application. We conclude that there are about 10 binary characteristics for the senators, 13 for the legislature, and M (X) had a rank of Kx \u2248 4, with a dominant factor, with dominant corresponding procedures (X) l (consistent with the relaterist search indicating a dominant factor for such data (Wang et al, 2010)."}, {"heading": "5.3. Behavioral dataset", "text": "The behavioral data set comes from a survey conducted by the Duke Visual Cognition Lab in 2010 and 2011. < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "5.4. Computations", "text": "The code for these experiments was written in Matlab, and the calculations were performed on a computer with a 2.53GHz processor and 4GB of memory. To give a sense of the computing times, about 11 seconds per MCMC sample were needed for the behavior dataset considered above."}, {"heading": "6. Summary", "text": "A new model was developed to represent real, categorical and mixed real-categorical relationship data. A multivariate probit model was used to jointly establish a correlation between the subjects and between the attributes. These covariances were used in the experiments to derive hierarchical structures between the subjects and between the attributes. Encouraging results were shown on three real data sets, the last of which is new and features mixed real-categorical survey data for several interesting psychological conditions."}, {"heading": "Acknowledgements", "text": "The research reported here was supported by ARO, ONR and DARPA (under the MSEE programme)."}], "references": [{"title": "The marginal likelihood for decomposable and non-decomposable graphical Gaussian models", "author": ["A. Atay-Kayis", "H. Massam"], "venue": null, "citeRegEx": "Atay.Kayis and Massam,? \\Q2005\\E", "shortCiteRegEx": "Atay.Kayis and Massam", "year": 2005}, {"title": "Latent Dirichlet allocation", "author": ["D.M. Blei", "A.Y. Ng", "M.I. Jordan"], "venue": "J. Machine Learning Res.,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "High-dimensional sparse factor modelling: Applications in gene expression genomics", "author": ["C. Carvalho", "J. Chang", "J. Lucas", "J.R. Nevins", "Q. Wang", "M. West"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Carvalho et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2008}, {"title": "Revised NEO Personality Inventory and NEO Five-Factor Inventory manual", "author": ["P.T. Costa", "R.R. McCrae"], "venue": "Odessa, FL: Psychological Assessment Resources,", "citeRegEx": "Costa and McCrae,? \\Q1992\\E", "shortCiteRegEx": "Costa and McCrae", "year": 1992}, {"title": "Bayesian inference for general Gaussian graphical models with application to multivariate lattice data", "author": ["A. Dobra", "A. Lenkoski", "A. Rodriguez"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Dobra et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dobra et al\\.", "year": 2011}, {"title": "Cluster analysis and display of genome-wide expression patterns", "author": ["M. Eisen", "P. Spellman", "P. Brown", "D. Botstein"], "venue": "In Proc. National Academy of Sciences,", "citeRegEx": "Eisen et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Eisen et al\\.", "year": 1998}, {"title": "Infinite latent feature models and the Indian buffet process", "author": ["T.L. Griffiths", "Z. Ghahramani"], "venue": "In Proc. NIPS", "citeRegEx": "Griffiths and Ghahramani,? \\Q2005\\E", "shortCiteRegEx": "Griffiths and Ghahramani", "year": 2005}, {"title": "A sparse factor-analytic probit model for congressional voting patterns", "author": ["P.R. Hahn", "C.M. Carvalho", "J.G. Scott"], "venue": "Journal of the Royal Statistical Society, Series C,", "citeRegEx": "Hahn et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hahn et al\\.", "year": 2012}, {"title": "Finding Groups in Data. An Introduction to Cluster Analysis", "author": ["L. Kaufman", "P.J. Rousseeuw"], "venue": null, "citeRegEx": "Kaufman and Rousseeuw,? \\Q1990\\E", "shortCiteRegEx": "Kaufman and Rousseeuw", "year": 1990}, {"title": "Statistical predicate invention", "author": ["S. Kok", "P. Domingos"], "venue": "In Proc. ICML", "citeRegEx": "Kok and Domingos,? \\Q2007\\E", "shortCiteRegEx": "Kok and Domingos", "year": 2007}, {"title": "Non-linear matrix factorization with Gaussian processes", "author": ["N. Lawrence", "R. Urtasun"], "venue": "In Proc. ICML", "citeRegEx": "Lawrence and Urtasun,? \\Q2009\\E", "shortCiteRegEx": "Lawrence and Urtasun", "year": 2009}, {"title": "An introduction to the five-factor model and its applications", "author": ["R.R. McCrae", "O.P. John"], "venue": "Journal of Personality,", "citeRegEx": "McCrae and John,? \\Q1992\\E", "shortCiteRegEx": "McCrae and John", "year": 1992}, {"title": "Modeling dyadic data with binary latent factors", "author": ["E. Meeds", "Z. Ghahramani", "R. Neal", "S. Roweis"], "venue": "In Proc. NIPS", "citeRegEx": "Meeds et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Meeds et al\\.", "year": 2007}, {"title": "Flexible covariance estimation in graphical Gaussian models", "author": ["B. Rajaratman", "H. Hassam", "C.M. Carvalho"], "venue": "The Annals of Statistics,", "citeRegEx": "Rajaratman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rajaratman et al\\.", "year": 2008}, {"title": "Bayesian probabilistic matrix factorization with MCMC", "author": ["R. Salakhutdinov", "A. Mnih"], "venue": "In Proc. NIPS", "citeRegEx": "Salakhutdinov and Mnih,? \\Q2008\\E", "shortCiteRegEx": "Salakhutdinov and Mnih", "year": 2008}, {"title": "Objective priors for the multivariate normal model", "author": ["D. Sun", "J.O. Berger"], "venue": "In Proc. 8th Valencia World Meeting on Bayesian Statistics", "citeRegEx": "Sun and Berger,? \\Q2006\\E", "shortCiteRegEx": "Sun and Berger", "year": 2006}, {"title": "Modelling relational data using Bayesian clustered tensor factorization", "author": ["I. Sutskever", "R. Salakhutdinov", "J. Tenenbaum"], "venue": "In Proc. NIPS", "citeRegEx": "Sutskever et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2009}, {"title": "Hierarchical beta processes and the Indian buffet process", "author": ["R.J. Thibaux", "M.I. Jordan"], "venue": "In Proc. AISTATS", "citeRegEx": "Thibaux and Jordan,? \\Q2007\\E", "shortCiteRegEx": "Thibaux and Jordan", "year": 2007}, {"title": "Joint analysis of time-evolving binary matrices and associated documents", "author": ["E. Wang", "D. Liu", "J. Silva", "D. Dunson", "L. Carin"], "venue": "In Proc. NIPS", "citeRegEx": "Wang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2010}, {"title": "Nonparametric Bayesian co-clustering ensembles", "author": ["P. Wang", "K.B. Laskey", "C. Domeniconi", "M.I. Jordan"], "venue": "In SIAM SDM", "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "The history of the cluster heat map", "author": ["L. Wilkinson", "M. Friendly"], "venue": "The American Statistician,", "citeRegEx": "Wilkinson and Friendly,? \\Q2009\\E", "shortCiteRegEx": "Wilkinson and Friendly", "year": 2009}, {"title": "Estimation of a covariance matrix using the reference prior", "author": ["R. Yang", "J.O. Berger"], "venue": "The Annals of Statistics,", "citeRegEx": "Yang and Berger,? \\Q1994\\E", "shortCiteRegEx": "Yang and Berger", "year": 1994}, {"title": "Large-scale collaborative prediction using a nonparametric random effects model", "author": ["K. Yu", "J. Lafferty", "S. Zhu", "Y. Gong"], "venue": "In Proc. ICML", "citeRegEx": "Yu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2009}, {"title": "Bayesian analysis of multivariate nominal measures using multivariate multinomial probit models", "author": ["X. Zhang", "W.J. Boscardin", "T.R. Belin"], "venue": "Computational Statistics and Data Analysis,", "citeRegEx": "Zhang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 22, "context": "For example, there has been a significant focus on exploiting low-rank and related structure in many types of matrices, primarily for matrix completion (Lawrence & Urtasun, 2009; Yu et al., 2009; Salakhutdinov & Mnih, 2008).", "startOffset": 152, "endOffset": 223}, {"referenceID": 19, "context": "For that problem, coclustering has received significant attention (Dhillon et al., 2003; Wang et al., 2011).", "startOffset": 66, "endOffset": 107}, {"referenceID": 12, "context": "For instance, in (Meeds et al., 2007) the authors develop a model in which each row and column has an associated binary feature vector, representing each in terms of the presence/absence of particular latent features.", "startOffset": 17, "endOffset": 37}, {"referenceID": 12, "context": "In (Meeds et al., 2007) the latent binary features are mapped to observed matrix elements via an intervening regression matrix, which is also inferred.", "startOffset": 3, "endOffset": 23}, {"referenceID": 18, "context": "Rather than using binary features to represent the rows and columns, one may also use a sparse real feature vector for each row and column (Salakhutdinov & Mnih, 2008; Wang et al., 2010), as is effectively done in factor analysis (Carvalho et al.", "startOffset": 139, "endOffset": 186}, {"referenceID": 2, "context": ", 2010), as is effectively done in factor analysis (Carvalho et al., 2008).", "startOffset": 51, "endOffset": 74}, {"referenceID": 12, "context": "As noted in (Meeds et al., 2007), and discussed further below, the use of binary feature vectors aids model interpretation, and may also enhance data sharing.", "startOffset": 12, "endOffset": 32}, {"referenceID": 12, "context": "The Indian buffet process (IBP) (Griffiths & Ghahramani, 2005) is a natural tool for modeling latent binary feature vectors, and that approach was taken in (Meeds et al., 2007).", "startOffset": 156, "endOffset": 176}, {"referenceID": 12, "context": "To address these limitations of existing approaches, we propose a new model, in which the rows/columns are each characterized by latent binary feature vectors, as in (Meeds et al., 2007).", "startOffset": 166, "endOffset": 186}, {"referenceID": 2, "context": "This is implemented by imposing a low-rank covariance matrix model, via factor analysis with sparse factor loadings (Carvalho et al., 2008).", "startOffset": 116, "endOffset": 139}, {"referenceID": 23, "context": "Note that \u03a3j is a (qj \u2212 1) \u00d7 (qj \u2212 1) covariance matrix, and the first element of \u03a3j is fixed to 1 in order to avoid identifiability problems (Chib & Greenberg, 1998; Zhang et al., 2008).", "startOffset": 142, "endOffset": 186}, {"referenceID": 12, "context": "This imposes significant structure and sharing on the learning of {vi}, {s j }, {ai} and {bi}, as considered in (Meeds et al., 2007).", "startOffset": 112, "endOffset": 132}, {"referenceID": 12, "context": "This paper differs from (Meeds et al., 2007) in three ways: (i) we jointly consider real and categorical data jointly, (ii) we impose low-rank structure on M (X) and M (Y ) (discussed next), and (ii) a new framework is developed for modeling the binary vectors {ri}, {d j } and {cj} (discussed in Section 3).", "startOffset": 24, "endOffset": 44}, {"referenceID": 18, "context": "Note that for the probit link function this construction implies that we do not require random-effect terms for the subjects and attributes (as is typically done when using real feature vectors (Wang et al., 2010)), since the sum of terms in (9) automatically allow randomeffect terms, if needed (such will correspond to one of the terms in the sum).", "startOffset": 194, "endOffset": 213}, {"referenceID": 4, "context": "tive and many approaches have been proposed (AtayKayis & Massam, 2005; Dobra et al., 2011).", "startOffset": 44, "endOffset": 90}, {"referenceID": 7, "context": "In fact, given that N (dimensionality of the covariance matrix) is typically larger than K, standard estimators are liable to be unstable (Sun & Berger, 2006; Hahn et al., 2012).", "startOffset": 138, "endOffset": 177}, {"referenceID": 7, "context": "Hence, we impose a factor structure on a covariance matrix, in a similar fashion to (Hahn et al., 2012).", "startOffset": 84, "endOffset": 103}, {"referenceID": 13, "context": "Such regularization is crucial when the number of variables is large relative to the sample size, and also when the covariance corresponds to an unobservable latent variable (Rajaratman et al., 2008).", "startOffset": 174, "endOffset": 199}, {"referenceID": 23, "context": "\u2022 The parameter-extended Metropolis-Hastings algorithm is employed to sample \u03a3j given the restriction {\u03a3j}11 = 1 (Zhang et al., 2008) only when qj > 2, otherwise \u03a3j is fixed to one.", "startOffset": 113, "endOffset": 133}, {"referenceID": 16, "context": "We first test the performance of the proposed model on the animals dataset (Kok & Domingos, 2007; Sutskever et al., 2009).", "startOffset": 75, "endOffset": 121}, {"referenceID": 18, "context": "We inferred that there are approximately 10 binary features for the senators, 13 for the legislation, and M (X) had a rank of Kx \u2248 4, with one dominant factor, with dominant corresponding \u03bb (X) l (consistent with related research that indicates one dominant factor for such data (Wang et al., 2010)).", "startOffset": 279, "endOffset": 298}, {"referenceID": 1, "context": "We performed LDA (Blei et al., 2003) topic modeling on the text documents (separate analysis), to infer structure in the legislation, and help interpret the inferred relationships; three types of legislation so in-", "startOffset": 17, "endOffset": 36}, {"referenceID": 1, "context": "Three types of legislation are inferred (rectangles at right), based upon topic modeling (Blei et al., 2003) applied separately to the text legislation.", "startOffset": 89, "endOffset": 108}, {"referenceID": 12, "context": "The first follows the proposed construction, except that the latent binary vectors are modeled via an IBP; the second is the logistic binary matrix factorization (BMF) model (Meeds et al., 2007); the main difference between the first and second alternatives is that the former imposes the low-rank model of Section 2.", "startOffset": 174, "endOffset": 194}], "year": 2012, "abstractText": "We consider analysis of relational data (a matrix), in which the rows correspond to subjects (e.g., people) and the columns correspond to attributes. The elements of the matrix may be a mix of real and categorical. Each subject and attribute is characterized by a latent binary feature vector, and an inferred matrix maps each row-column pair of binary feature vectors to an observed matrix element. The latent binary features of the rows are modeled via a multivariate Gaussian distribution with low-rank covariance matrix, and the Gaussian random variables are mapped to latent binary features via a probit link. The same type construction is applied jointly to the columns. The model infers latent, low-dimensional binary features associated with each row and each column, as well correlation structure between all rows and between all columns.", "creator": "LaTeX with hyperref package"}}}