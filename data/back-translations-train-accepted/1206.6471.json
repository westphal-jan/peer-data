{"id": "1206.6471", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "On causal and anticausal learning", "abstract": "We consider the problem of function estimation in the case where an underlying causal model can be inferred. This has implications for popular scenarios such as covariate shift, concept drift, transfer learning and semi-supervised learning. We argue that causal knowledge may facilitate some approaches for a given problem, and rule out others. In particular, we formulate a hypothesis for when semi-supervised learning can help, and corroborate it with empirical results.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (476kb)", "http://arxiv.org/abs/1206.6471v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012). arXiv admin note: substantial text overlap witharXiv:1112.2738"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012). arXiv admin note: substantial text overlap witharXiv:1112.2738", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["bernhard sch\u00f6lkopf", "dominik janzing", "jonas peters", "eleni sgouritsa", "kun zhang", "joris m mooij"], "accepted": true, "id": "1206.6471"}, "pdf": {"name": "1206.6471.pdf", "metadata": {"source": "META", "title": "On Causal and Anticausal Learning", "authors": ["Bernhard Sch\u00f6lkopf", "Dominik Janzing", "Jonas Peters", "Eleni Sgouritsa", "Kun Zhang", "Joris Mooij"], "emails": ["FIRST.LAST@TUE.MPG.DE", "J.MOOIJ@CS.RU.NL"], "sections": [{"heading": "1. Introduction", "text": "Much of the research is aimed at establishing statistical linkages or dependencies between variables that affect particular variables, especially in situations where we have large amounts of knowledge, but no detailed models of the underlying data that can trigger a process. It has been argued that statistical linkages always exist only in relation to underlying causal structures, which raises the question of the extent to which machine learning can benefit from knowledge of these structures. The current study deals with the simplest possible constellation, in which the causal structure consists only of cause and effect. We argue that, under certain conditions, there is a detailed consideration that leads to asymmetries in common distributions that have implications for statistical learning."}, {"heading": "2. Predicting Effect from Cause", "text": "Consider the case in which we try to estimate a function f: X \u2192 Y or a conditional distribution P (Y | X) in the causal direction, i.e. that X is the cause and Y is the effect. Intuitively, this situation of causal prediction should be the \"simple\" case, since there is a functional mechanism that f should try to imitate. We are interested in how robust the estimate is in terms of changes in the noise variables of the underlying model."}, {"heading": "2.1. Additional information about the input", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1.1. ROBUSTNESS W.R.T. INPUT CHANGES", "text": "Given that training points from P (X, Y) and an additional set of input factors from P (X) have been sampled with P (X) 6 = P (X), there is no reason to believe that the observed change in P (X) (i.e. in P (NX))) will result in a change in P (Y | X), and we therefore conclude that P \u2032 (Y | X) = P (Y | X). This scenario is called covariate shift (Sugiyama & Kawanabe, 2012). However, the equation P \u2032 (Y | X) = P (Y | X) should not be confused with the statement that the rule for predicting Y from X does not need to be adjusted to the new input distribution P (X), because predicting finite data can favor simple functions that fit well with the data in the region where P (X) has a high probability, but not where P (X) is high."}, {"heading": "2.1.2. SEMI-SUPERVISED LEARNING (SSL)", "text": "Objective: Estimate P (Y | X). Note: Due to the independence of the mechanism, P (X) does not contain information about P (Y | X). Therefore, a more accurate estimate of P (X), as possible by adding the test inputs P (X), does not affect an estimate of P (Y | X), and SSL is meaningless for the scenario in Figure 2."}, {"heading": "2.2. Additional information about the output", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.2.1. ROBUSTNESS W.R.T. OUTPUT CHANGES", "text": "Given: Training points from P (X, Y) and an additional set of results from P (Y), where P (Y) is 6 = P (Y). Objective: Estimation P (Y | X). Assumption: no clear solution: First we have to decide whether P (X) or P (Y | X) has changed, because some rough ideas can be found in Changing the localization distribution (Section 4). If P (X) has changed, we proceed as in Section 2.1.1. If P (Y | X) has changed, we can estimate P (Y | X) via the estimate of causal conditions (Section 4)."}, {"heading": "2.2.2. ADDITIONAL OUTPUTS", "text": "Objective: Estimation of P (Y | X).Assumption: P (X, Y) has an additive sound model from X to Y and P (Y) has a unique decomposition as a fusion of two distributions, say P (Y) = Q * R. This is fulfilled, for example, if noise Gaussian and P (\u03c6 (C)) is uncomposable (i.e., it cannot be written as a non-trivial fusion of two distributions).Solution: The additional output helps because the decomposition tells us that either P (NY) = Q or P (NY) = R. The additive sound model learned from the x, y pair will probably tell us which of the alternatives is true."}, {"heading": "2.3. Additional information about input and output", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.3.1. TRANSFER LEARNING (ONLY NOISE CHANGES)", "text": "Given: Training points from P (X, Y) and an additional set of points from P (X, Y), with P (X, Y) 6 = P (X, Y). Aim: P (Y | X) estimate. Assumption: additive noise, where \u03c6 is invariant but sounds can change.Solution: Run conditional ANM to output a single function, only to enforce the independence of residuals separately for the two datasets (Section 4). There is also an SSL variant of this scenario: In the face of a training set plus two unpaired sets from the two original margins, the additional sets help to better estimate P (X, Y) because we have argued in Section 2.2.2 that additional Y values from P (Y) are already helpful. The fact that causal directions are important for transferring knowledge from one dataset to another has already been pointed out by Storkey (2009)."}, {"heading": "2.3.2. CONCEPT DRIFT (ONLY FUNCTION CHANGES)", "text": "Given: Training points from P (X, Y) and an additional set of points from P (X, Y) with P (X, Y) 6 = P (X, Y).Objective: Estimation P (Y | X).Assumption: ANM with NX, NY invariant, but \u03c6 has changed.Solution: Apply ANM to points from P (X, Y) to get \u03c6. Then P \u2032 (Y | X) is given by P \u2032 (Y | X) = PNY (Y \u2212 \u03c6 (X), where the NY index indicates the variable to which this distribution refers."}, {"heading": "3. Predicting Cause from Effect", "text": "Turning now to the opposite direction, where we consider the effect as input and try to predict the value of the causation variables leading to it. This situation, which we call anti-causal prediction, may seem unnatural, but it is indeed omnipresent in machine learning. Consider, for example, the task of predicting the class name of a handwritten digit from its image. Causal structure is as follows: A person intends to write the digit 7, and this intention causes a motor pattern that creates an image of the digit 7 - in this sense, the class designation Y causes the image X.P (X | Y) represents the causal mechanism that generates X from Y, and it is independent of the distribution of the cause P (Y). On the other hand, P (Y | X) is sensitive to changing the distribution of P (Y)."}, {"heading": "3.1. Additional information about the input", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1.1. ROBUSTNESS W.R.T. INPUT CHANGES", "text": "Suppose: additive Gaussian noise with invertable function \u03c6 and uncomposed P (\u03c6 (Y)) is sufficient. Other assumptions are also possible, but the invertibility of causal conditioned P (X | Y) is necessary in any case. 3A related scenario is that we do not have any additional data from P (X), but we still want to use our knowledge of causal direction to learn a model that is reasonably robust when changes in P (X) occur due to changes in P (Y) or P (X | Y). Solution: We apply Localizing distribution change (Section 4) to determine whether P (Y) or P (X | Y) has changed causally. In the first case, we can estimate P (Y) via inverting (X | Y)."}, {"heading": "3.1.2. SEMI-SUPERVISED LEARNING", "text": "The assumption: different options, see note below: P (X) and P (Y | X) are not independent of each other and therefore contain information about each other. Therefore, the additional inputs may allow a more accurate estimate of P (X). Known assumptions for SSL, as discussed by Chapelle et al. (2006), can in fact be seen as linking properties of P (X) with properties of P (Y | X): For example, the cluster assumption states that points located in the same P (X) cluster have the same Y; and the assumption of low density separation implies that the decision limit of a classifier (i.e. the point at which P (Y | X) crosses in a region where P (X) is small; the semi-obsolete flatness assumption implies that the X function (which we can consider as a unit of the P distribution) from which the X function (the unit) can be calculated."}, {"heading": "3.2. Additional information about the output", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1. ROBUSTNESS W.R.T. OUTPUT CHANGES", "text": "Given: training points sampled from P (X, Y) and an additional set of P (Y) sampled outputs, where P (Y) is 6 = P (Y). This scenario is also referred to as a previous probability shift (Storkey, 2009). Objective: Estimation P (Y | X). Solution: Independence of the mechanism implies P (X | Y) = P (X | Y), i.e. P (X, Y) = P (X | Y) P \u2032 (Y). From this we calculate P \u2032 (Y | X) = P \u2032 (X | Y) P \u2032 (Y) and P \u2032 (X, Y) dY."}, {"heading": "3.3. Additional information about input and output", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.3.1. ROBUSTNESS W.R.T. CHANGES OF INPUT AND OUTPUT NOISE (TRANSFER LEARNING)", "text": "Given: training points sampled from P (X, Y) and an additional set of P (X, Y) sampled points, where P (X, Y) is 6 = P (X, Y). Aim: P (Y | X) estimate. Assumption: additive noise where \u03c6 is invariant, but sounds may change. Solution: analogous to Section 2.3.1, but use the model backwards at the end."}, {"heading": "3.3.2. CONCEPT DRIFT (CHANGE OF FUNCTION)", "text": "Given: Training points from P (X, Y) and an additional set of points from P (X, Y) with P (X, Y) 6 = P (X, Y).Aim: Estimation P (Y | X).Assumption: NX, NY invariant, but \u03c6 has changed to \u03c6. Solution: We can learn from P (X, Y)? and then estimate the total distribution P \u2032 (X, Y) based on the estimates of P (NX) and P (NY) obtained from observing the x, y pairs sampled from P (X, Y)."}, {"heading": "4. Modules", "text": "In some cases, we lose no information through this mechanism: Definition 1 (injective conditions) a conditional distribution P (Y | X) is referred to as injective if there are no two distributions. (Example 1 (complete ranking) P (X) 6 = P (X) such that P (\u2032 x) P (x) dx = x) P (x) dx. Example 1 (complete ranking) P (X, Y, havefinite range. Then P (Y | X) is given by a stochastic matrix M and is injective if and only if M has the full rank. Note that this is only possible if we decide. Example 2 (non-linear model) Let X, Y are revalued and let Y = projected."}, {"heading": "5. Empirical Results", "text": "This year it has come to the point where it will be able to eren.n"}, {"heading": "6. Conclusion", "text": "We give an overview of the effects of prediction in causal and anticausal arrangements, in particular the formulation of the hypothesis that, assuming causal mechanisms and input, semi-supervised learning works better than in causal problems. Our preliminary meta-analysis of the literature seems to support this assertion. We thank Ulf Brefeld and Stefan Wrobel for sharing their detailed experimental results so that they allow our meta-analysis. We thank Bob Williamson, Vladimir Vapnik and Jakob Zscheischler for their helpful discourse. http: / pl.is.tue.mpg.de / p / causal-anticausal.Brefeld, U., Ga \u00bc rtner, T., Scheffer, and Wrobel, S."}], "references": [], "referenceMentions": [], "year": 2012, "abstractText": "We consider the problem of function estimation in the case where an underlying causal model can be inferred. This has implications for popular scenarios such as covariate shift, concept drift, transfer learning and semi-supervised learning. We argue that causal knowledge may facilitate some approaches for a given problem, and rule out others. In particular, we formulate a hypothesis for when semi-supervised learning can help, and corroborate it with empirical results.", "creator": "LaTeX with hyperref package"}}}