{"id": "1206.6475", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Jun-2012", "title": "A Split-Merge Framework for Comparing Clusterings", "abstract": "Clustering evaluation measures are frequently used to evaluate the performance of algorithms. However, most measures are not properly normalized and ignore some information in the inherent structure of clusterings. We model the relation between two clusterings as a bipartite graph and propose a general component-based decomposition formula based on the components of the graph. Most existing measures are examples of this formula. In order to satisfy consistency in the component, we further propose a split-merge framework for comparing clusterings of different data sets. Our framework gives measures that are conditionally normalized, and it can make use of data point information, such as feature vectors and pairwise distances. We use an entropy-based instance of the framework and a coreference resolution data set to demonstrate empirically the utility of our framework over other measures.", "histories": [["v1", "Wed, 27 Jun 2012 19:59:59 GMT  (280kb)", "http://arxiv.org/abs/1206.6475v1", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"], ["v2", "Tue, 4 Sep 2012 17:42:41 GMT  (280kb)", "http://arxiv.org/abs/1206.6475v2", "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)"]], "COMMENTS": "Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["qiaoliang xiang", "qi mao", "kian ming adam chai", "hai leong chieu", "ivor w tsang", "zhendong zhao"], "accepted": true, "id": "1206.6475"}, "pdf": {"name": "1206.6475.pdf", "metadata": {"source": "META", "title": "A Split-Merge Framework for Comparing Clusterings ", "authors": ["Qiaoliang Xiang", "Qi Mao", "Kian Ming A. Chai", "Hai Leong Chieu", "Wai-Hung Tsang", "Zhendong Zhao"], "emails": ["QIAOLIANGXIANG@GMAIL.COM", "QMAO1@NTU.EDU.SG", "CKIANMIN@DSO.ORG.SG", "CHAILEON@DSO.ORG.SG", "IVORTSANG@NTU.EDU.SG", "ZHENDONG.ZHAO@MQ.EDU.AU"], "sections": [{"heading": "1. Introduction", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, a country and a country, in which it is a country, a country and a country, in which it is a country, a country, a region and a country, in which it is a country, a country, a country and a country, a country and a country, a country and a country, a country and a country, a country and a country, a country, a country, a country, a country, a country, a country, a country and a country, a country and a country, a country and a country, a country, a country and a country, a country and a country, a country and a country, a country, a country and a country, a country, a country, a country and a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country, a country"}, {"heading": "2. Preliminaries", "text": "Let D = {1, 2,.., n} be a group of n data points, and let fi denote the attribute vector of the i-point. Clustering is a group of clusters, and a cluster is a group of points. Let's specify the set of all clustering, L \u00b2 being the true cluster formation and C \u00b2 being the predicted cluster formation. The term (n \u00b2) = n (n \u2212 1) / 2is the number of pairwise connections between n points. The entropy of clustering L is H (L) = \u2212 x L | n log | L | n log | L | n log | n log | n n n, while the common entropy between two clusters L and C \u2212 \u2212 x L."}, {"heading": "3. Related Work", "text": "In this paper, we focus on the study of symmetrical measures of similarity. At a distance measure, we examine the corresponding measure of similarity by subtracting it from one. Meila \u0442 (2007); Wagner & Wagner (2007); Vinh et al. (2010) have summarized and compared a large number of measures proposed in the literature, and some representative measures are discussed as follows."}, {"heading": "3.1. Pair Counting Measures", "text": "Rand Index A link is positive if the two points are within the same cluster, otherwise it is negative. P (L, C) = \u2211 L-L \u2211 C-C (| L-C | 2) positive links and (n 2) \u2212 P (L, L) \u2212 P (C, C) + P (L, C) + P (L, C) negative links that are two clusters in common. Rand Index is the fraction R (L, C) = (n 2) \u2212 P (L, L) \u2212 P (C, C) + 2P (L, C)) / (n 2) of links that are two clusters in common (Rand, 1971). It is large if there are many clusters (Wagner & Wagner, 2007)."}, {"heading": "3.2. Set Matching Measures", "text": "Van Dongen criterion To transform L to C, 2n \u2212 \u2211 L, maxC, maxC, L, C, maxL, L, C, moves of points are required (Dongen, 2000).This parameter can be limited by division by 2n (Meila, 2007) to a right-open interval [0, 1).The counterpart of similarity is N (L, C) = 1 2 \u2211 L, L, maxC, C | L, C | n + 1 2 \u2211 C, maxL, C, maxL, L, C | n. It is not normalized because its lower limit is invalid. Classification Accuracy By treating clusters as a classification task, classification accuracy calculates the fraction of the points correctly classified (Meila, L, 2001).Determining the best allocation between two clusters is equivalent to solving a maximum weighted two-part matching problem (Meila, 2005)."}, {"heading": "3.3. Information Theoretic Measures", "text": "Normalized mutual information Vinh et al. (2010) advocated NMI (L, C) = I (L, C) / max {H (L), H (C)} after comparing several normalized variants of mutual information. The problem with NMI (L, C) is that I (L, C) indicates the degree of statistical dependence between two clusters and this is not always consistent with their similarity. For example, I (>, C) = 0 means that there is no dependence between > and any C, but the actual similarity depends on the proximity of C to >.Normalized information variation The variation of information VI (L, C) = H (C | L) + H (L | C) is the change in the amount of information when converting L to C (Meila, 2007). Although VI (L, C) has certain desired properties, it is unnormalized, which can be realized by dividing the upper amount of information when converting L to C (Meila, 2007) into the unit (L)."}, {"heading": "4. The Split-Merge Framework", "text": "In Section 4.1, we model the relationship between two clusters as a two-sided graph that can be broken down into contiguous components. In Section 4.2, a component is further divided and merged into sub-components, and the sub-components split and merged can be combined to form a derivative graph D that turns L into C. In Section 4.3, we capture the essence of D by pairing split sub-components with merging sub-components, and the similarity of each pair, referred to as a sub-component pair, is discussed in Section 4.4."}, {"heading": "4.1. Connected Components of a Bipartite Graph", "text": "AJ J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J J"}, {"heading": "4.2. Split and Merge Subcomponents", "text": "One component focuses on the cluster-clustering relationship. It may be difficult to assign a score to such a relationship. < J > J > (J). Therefore, we break a component into sub-components, focusing on cluster clustering relationships. < J > (J). The split chart < L, C > is the full split chart. < L > is the full split chart. < L > is the full split chart. < L > is the full split chart. < L, C > is the full directed split chart from the induced clustering chart to {C}. Conceptually, a split chart represents one or more clusters of C that overlap with L, while a merge chart represents one or more clusters of L that overlap with C. For one component GJ, there may be one or more graphics."}, {"heading": "4.3. Subcomponent Pairs", "text": "Within a component GJ is a splitting (or merging) of the subcomponent into MJ > J > J pair = J > J pair = J pair in the derivative chart D. < < LJ, CJ) would be a direct combination of the similarities to the subcomponents of GJ > J pair = J > J pair. < L, CJ >, C >) such that L-LJ, C-CJ and L-C subcomponents. This definition takes advantage of the fact that a splitting and a merging of the subcomponent are not separated into D, only if a splitting of the subcomponent and a source of the subcomponent in the merger."}, {"heading": "4.4. Similarity on Subcomponent Pairs", "text": "We will now discuss the choice of the measure of equality \u03c3 on a subcomponent pair. Given to a pair (< L, C >, < L, C >), the general idea is to make \u03c3 be a function of the measures of similarity s (C | L) and s (L | C) of the subcomponents. We will discuss two functions: the product and the arithmetic mean. Our preference is the product because it satisfies the consistency of the subcomponents (property 4.4), while the mean does not matter. (4) where s (C | L) and s (L | C) are the meteor-weighted equilibrium component. (L), where s (L | C) and s (L) are the subcomponent L."}, {"heading": "4.5. Examples", "text": "The split-merge framework (4) is flexible because the sub-component similarity measures can be application-specific. We give two examples. (Entropy-based SH) This example uses a normalized entropy of clustering. Replacing it in (4) results in a measure of similarity in the split-merge framework, and we call this measure SH: SH (L, C) = [L]. L-Large measures in Section 6.Mean-squared error measures in Section 6.Mean-squared error measures in Section 6.Mean-squared error measures in Section 6.Mean-squared error measures The split-merge cluster framework (4) can use the feature vectors of points or the substances between these points."}, {"heading": "5. Comparisons with Existing Measures", "text": "We are examining some properties of our split-merge similarity framework S \u0445 given by (4) compared to other measures. There are other properties that we are examining in section 3 of the supplementary material."}, {"heading": "5.1. Conditional Normalization", "text": "In order to facilitate the interpretation and comparison between the different scales, which typically depend on three different scales, the traditional normalization property is focused on the common space of the two clusters and requires that the range of similarity measurement be disregarded at a closed interval (0, 1] (Wagner & Wagner, 2007; Vinh et al., 2010), where the lower limit of zero should be reached, that a cluster is typically the true cluster measurement. Since a fundamental goal of similarity measurement is against true similarity, the similarities in relation to true cluster formation should also be standardized (Luo et al, 2009): In the face of true cluster measurement L, a similarity measurement between zero and one with both extremes should be preservable. Luo et al (2009) has found that some information theoretical measurements do not meet this property, and they have proposed a normalization method that depends on the original measurement sizes, typically depending on two different scales."}, {"heading": "5.2. Join-weighted Decomposition and Consistency", "text": "We examine whether some existing measures of similarity fulfil the properties 4.1 and 4.4.sentence 5.2. Only N, A, K and S * are joint-weighted decomposable. A and S * are subcomponent components. Proof. Table 1 shows that only N, A, K and S * are composible. The dimensions N and K are instances of S \u00b2 in (5), so they are not subcomponent consistent. S * ({L}, CL) is subcomponent consistent, as shown in Section 4.4. For A we have A ({L}, CL) = maxC * CL | / | L | = a (C | L) and A (LC, {C}) = a (L | C), where a is the relevant subcomponent dimension."}, {"heading": "6. Experiments", "text": "We compare conditional normalization and monotonously decreasing properties of different measurements using the core resolution task, which is to group noun phrases (data points) that relate to the same real unit (cluster) (Ng & Cardie, 2002).For a measurement in our split-merge framework, we use the entropy-based SH in Section 4.5. Our experiments use a randomly selected document in the ACE-2005 dataset (Rahman & Ng, 2011).We construct a series of clusters from the best to the worst in relation to a given cluster formation. This series serves to evaluate similarity measurements in relation to the following Desideratum cluster form: a reasonable similarity scale should strictly decrease from one to zero when the cluster scale \"merges\" from the best to a particular cluster scale. This series is used to evaluate similarity measurements in relation to the following unit, but is not a true unit:"}, {"heading": "7. Conclusion", "text": "By modelling the intrinsic relationship between two clusters as a bipartite graph, we have proposed a split-merge framework that can be used to obtain similarity yardsticks for comparing clusters on different datasets. Unlike a representative selection of existing similarity yardsticks, any measurement obtained through the framework is conditionally normalized, composible, and subcomponent consistent. Conditional normalization is especially important because it allows comparing different clusters of different datasets. In addition, our framework can also use feature vectors of data points or distances between datasets."}, {"heading": "Acknowledgments", "text": "This work is supported by the DSO funding DSOCL10021."}], "references": [{"title": "Comparing clusterings in space", "author": ["Coen", "Michael H", "Ansari", "M. Hidayath", "Fillmore", "Nathanael"], "venue": "In ICML, pp", "citeRegEx": "Coen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Coen et al\\.", "year": 2010}, {"title": "Performance criteria for graph clustering and Markov cluster experiments", "author": ["Dongen", "Stijn"], "venue": "Technical report, National Research Institute for Mathematics and Computer Science,", "citeRegEx": "Dongen and Stijn.,? \\Q2000\\E", "shortCiteRegEx": "Dongen and Stijn.", "year": 2000}, {"title": "Lattice Theory: Foundation", "author": ["Gr\u00e4tzer", "George"], "venue": "Springer, 1st edition,", "citeRegEx": "Gr\u00e4tzer and George.,? \\Q2011\\E", "shortCiteRegEx": "Gr\u00e4tzer and George.", "year": 2011}, {"title": "Clustering: Science or art", "author": ["Guyon", "Isabelle", "Luxburg", "Ulrike Von", "Williamson", "Robert C"], "venue": "In NIPS Workshop on Clustering Theory,", "citeRegEx": "Guyon et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Guyon et al\\.", "year": 2009}, {"title": "Comparing partitions", "author": ["Hubert", "Lawrence", "Arabie", "Phipps"], "venue": "Journal of Classification,", "citeRegEx": "Hubert et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Hubert et al\\.", "year": 1985}, {"title": "Understanding of internal clustering validation measures", "author": ["Liu", "Yanchi", "Li", "Zhongmou", "Xiong", "Hui", "Gao", "Xuedong", "Wu", "Junjie"], "venue": "In ICDM,", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Information-theoretic distance measures for clustering validation: Generalization and normalization", "author": ["Luo", "Ping", "Xiong", "Hui", "Zhan", "Guoxing", "Wu", "Junjie", "Shi", "Zhongzhi"], "venue": "IEEE TKDE,", "citeRegEx": "Luo et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Luo et al\\.", "year": 2009}, {"title": "On coreference resolution performance metrics", "author": ["Luo", "Xiaoqiang"], "venue": "In HLT, pp", "citeRegEx": "Luo and Xiaoqiang.,? \\Q2005\\E", "shortCiteRegEx": "Luo and Xiaoqiang.", "year": 2005}, {"title": "Comparing clusterings: an axiomatic view", "author": ["Meil\u0103", "Marina"], "venue": "In ICML, pp", "citeRegEx": "Meil\u0103 and Marina.,? \\Q2005\\E", "shortCiteRegEx": "Meil\u0103 and Marina.", "year": 2005}, {"title": "Comparing clusterings \u2014 an information based distance", "author": ["Meil\u0103", "Marina"], "venue": "J. Multivar. Anal.,", "citeRegEx": "Meil\u0103 and Marina.,? \\Q2007\\E", "shortCiteRegEx": "Meil\u0103 and Marina.", "year": 2007}, {"title": "An experimental comparison of model-based clustering", "author": ["Meil\u0103", "Marina", "Heckerman", "David"], "venue": "methods. ML,", "citeRegEx": "Meil\u0103 et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Meil\u0103 et al\\.", "year": 2001}, {"title": "Improving machine learning approaches to coreference resolution", "author": ["Ng", "Vincent", "Cardie", "Claire"], "venue": "In ACL,", "citeRegEx": "Ng et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Ng et al\\.", "year": 2002}, {"title": "Efficiently clustering documents with committees", "author": ["Pantel", "Patrick", "Lin", "Dekang"], "venue": "In PRICAI, pp", "citeRegEx": "Pantel et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Pantel et al\\.", "year": 2002}, {"title": "Narrowing the modeling gap: a cluster-ranking approach to coreference", "author": ["Rahman", "Altaf", "Ng", "Vincent"], "venue": "resolution. JAIR,", "citeRegEx": "Rahman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rahman et al\\.", "year": 2011}, {"title": "Objective criteria for the evaluation of clustering methods", "author": ["Rand", "William M"], "venue": "JASA, 66(336):846\u2013850,", "citeRegEx": "Rand and M.,? \\Q1971\\E", "shortCiteRegEx": "Rand and M.", "year": 1971}, {"title": "V-measure: A conditional entropy-based external cluster evaluation measure", "author": ["Rosenberg", "Andrew", "Hirschberg", "Julia"], "venue": "In EMNLP-CoNLL, pp", "citeRegEx": "Rosenberg et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Rosenberg et al\\.", "year": 2007}, {"title": "Cluster ensembles \u2014 a knowledge reuse framework for combining multiple partitions", "author": ["Strehl", "Alexander", "Ghosh", "Joydeep"], "venue": "JMLR, 3:583\u2013617,", "citeRegEx": "Strehl et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Strehl et al\\.", "year": 2003}, {"title": "Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance", "author": ["Vinh", "Nguyen Xuan", "Epps", "Julien", "Bailey", "James"], "venue": null, "citeRegEx": "Vinh et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Vinh et al\\.", "year": 2010}, {"title": "Comparing clusterings \u2014 an overview", "author": ["Wagner", "Silke", "Dorothea"], "venue": null, "citeRegEx": "Wagner et al\\.,? \\Q1907\\E", "shortCiteRegEx": "Wagner et al\\.", "year": 1907}], "referenceMentions": [{"referenceID": 17, "context": "Unnormalized and asymmetric measures are inappropriate for comparing clusterings across data sets (Vinh et al., 2010; Wagner & Wagner, 2007).", "startOffset": 98, "endOffset": 140}, {"referenceID": 6, "context": "When a measure is used for comparing all possible clusterings with the true clustering, it is preferable that the similarity scores should be in the closed interval [0, 1] (Luo et al., 2009).", "startOffset": 172, "endOffset": 190}, {"referenceID": 17, "context": "They have been analyzed extensively and systematically in recent years (Meil\u0103, 2007; Vinh et al., 2010).", "startOffset": 71, "endOffset": 103}, {"referenceID": 17, "context": "Some measures tend to give high scores in practice, so adjusted measures, such as adjusted Rand index (Hubert & Arabie, 1985) and adjusted mutual information (Vinh et al., 2010) are proposed to address this issue, but they are not normalized because they may be negative (Meil\u0103, 2007).", "startOffset": 158, "endOffset": 177}, {"referenceID": 3, "context": "In this paper, instead of focusing on designing a new clustering measure, we propose a split-merge framework that can be tailored to different applications (Guyon et al., 2009).", "startOffset": 156, "endOffset": 176}, {"referenceID": 17, "context": "Meil\u0103 (2007); Wagner & Wagner (2007); Vinh et al. (2010) summarized and compared a large number of measures that have been proposed in the literature, and a few representative measures are discussed as follows.", "startOffset": 38, "endOffset": 57}, {"referenceID": 17, "context": "Normalized Mutual Information Vinh et al. (2010) advocated NMI(L,C) = I(L,C)/max{H(L), H(C)} after comparing several normalized variants of the mutual information.", "startOffset": 30, "endOffset": 49}, {"referenceID": 0, "context": "In contrast, previous external measures ignore such information (Coen et al., 2010).", "startOffset": 64, "endOffset": 83}, {"referenceID": 5, "context": "Many internal compactness and separation measures can be used as subcomponent measures (Liu et al., 2010).", "startOffset": 87, "endOffset": 105}, {"referenceID": 0, "context": "In contrast, the hybrid measure proposed by Coen et al. (2010) requires O(n) time in the average case and O(n log n) time in the worst case.", "startOffset": 44, "endOffset": 63}, {"referenceID": 17, "context": ", different data sets), the traditional normalization property focuses on the joint space of the two clusterings and requires that the range of a similarity measure should be normalized to a closed interval [0, 1] (Wagner & Wagner, 2007; Vinh et al., 2010), where the lower bound zero should be achievable.", "startOffset": 214, "endOffset": 256}, {"referenceID": 6, "context": "Since one fundamental goal of a similarity measure is to rank clusterings against a true clustering, the similarities with respect to the true clustering should also be normalized (Luo et al., 2009): given a true clustering L, a similarity measure should be between zero and one with both extremes attainable.", "startOffset": 180, "endOffset": 198}, {"referenceID": 6, "context": "Since one fundamental goal of a similarity measure is to rank clusterings against a true clustering, the similarities with respect to the true clustering should also be normalized (Luo et al., 2009): given a true clustering L, a similarity measure should be between zero and one with both extremes attainable. Luo et al. (2009) have found that some information theoretic measures did not satisfy this property, and they have proposed a normalization procedure using the extreme values attained by the original measures, which typically depends on L or n.", "startOffset": 181, "endOffset": 328}, {"referenceID": 6, "context": "by the procedure of (Luo et al., 2009) in two ways.", "startOffset": 20, "endOffset": 38}], "year": 2012, "abstractText": "Clustering evaluation measures are frequently used to evaluate the performance of algorithms. However, most measures are not properly normalized and ignore some information in the inherent structure of clusterings. We model the relation between two clusterings as a bipartite graph and propose a general component-based decomposition formula based on the components of the graph. Most existing measures are examples of this formula. In order to satisfy consistency in the component, we further propose a split-merge framework for comparing clusterings of different data sets. Our framework gives measures that are conditionally normalized, and it can make use of data point information, such as feature vectors and pairwise distances. We use an entropy-based instance of the framework and a coreference resolution data set to demonstrate empirically the utility of our framework over other measures.", "creator": "LaTeX with hyperref package"}}}