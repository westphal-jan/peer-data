{"id": "1207.0166", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2012", "title": "On Multilabel Classification and Ranking with Partial Feedback", "abstract": "We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-confidence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T^{1/2} log T) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-confidence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance.", "histories": [["v1", "Sat, 30 Jun 2012 23:07:03 GMT  (127kb,D)", "https://arxiv.org/abs/1207.0166v1", null], ["v2", "Tue, 20 Nov 2012 16:48:22 GMT  (128kb,D)", "http://arxiv.org/abs/1207.0166v2", null], ["v3", "Wed, 16 Jan 2013 19:19:34 GMT  (133kb,D)", "http://arxiv.org/abs/1207.0166v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["claudio gentile", "francesco orabona"], "accepted": true, "id": "1207.0166"}, "pdf": {"name": "1207.0166.pdf", "metadata": {"source": "CRF", "title": "On Multilabel Classification and Ranking with Partial Feedback, Ver. 3", "authors": ["Claudio Gentile"], "emails": ["claudio.gentile@uninsubria.it", "francesco@orabona.com"], "sections": [{"heading": "1 Introduction", "text": "Consider a book recommendation system that recommends a few possible books to the user, which he then buys or prefers in a different order. It cannot observe what the user has done when other books are recommended to him, or when the same book ads are placed in a different order within the web page. Such problems are collectively referred to as learning with partial feedback. In contrast, the system (learning algorithm) can know the result of every possible reaction (e.g. the user's action for each and every possible book recommendation placed in the largest banner advertisement)."}, {"heading": "1.1 Related work", "text": "This year, more than ever before in the history of the city, in which it is so far that it is a place where it is a country, in which it is a country, in which it is a country, in which it is a city, in a city, in a country, in a city, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a city, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a country, in a"}, {"heading": "1.2 Our results", "text": "We examine the multi-label and learning-to-rank problems in a partial feedback scenario with contextual information, in which we assume a probabilistic linear model of the labels, although the contexts can be chosen by an adaptive opponent. We consider two families of loss functions, one is a cost-sensitive multi-label loss that generalizes the standard hamming loss in several respects, the other is a kind of (unstandardized) ranking loss. In both cases, the learning algorithm proves a (generalized) linear predictor of the probability that a particular label occurs, the ranking that is produced by the upper trust corrected estimated probabilities. In such constellations, it proves that T 1 / 2 has cumulative remorse limits that are essentially optimal (up to log factors). A distinctive feature of our user feedback model is that, unlike previous papers (e.g., 37, the algorithm), we do not consider structured."}, {"heading": "1.3 Structure of the paper", "text": "The paper is structured as follows: In Section 2, we present our learning model, our initial loss function, the label generation model, and some preliminary results and notations used for the rest of the paper. In Section 3, we describe our partial feedback algorithm, which operates under the loss function introduced in Section 2, together with the associated regret analysis. In Section 4, we show that a very similar machine applies to the partial feedback ranking, where the loss function is a kind of paired ranking loss (with partial feedback). Similar limits of regret are then presented that function under additional modeling constraints. In Section 5, we present our experimental proof by comparing our method with its immediate counterpart with complete information. Section 6 provides evidence ideas and technical details."}, {"heading": "2 Model and preliminaries", "text": "It is not the way in which the loss of the algorithm can be taken into account in the sum of the costs suffered by the algorithm: the distance between Yt and Y (both considered as sets), as well as the cost of the game Y (Y). The cost c (Y) associated with Y could not be taken into account by the sum of the costs listed on each class i (Y). (Y) The cost c (Y) associated with Y could be taken into account by the sum of the costs listed on each class i (Y). (Y) The sum of the costs listed on each class i (Y) may be the order in which Y (as ordered list of terms Y) occurs. (Y) The cost c (0, 1) and the cost c (i, s), i)."}, {"heading": "3 Algorithm and regret bounds", "text": "In Figure 1, our bandit algorithm is for (ordered) multiple denominations. The algorithm is based on replacing the unknown model vectors u1,.., uK with prototype vectors w \"1, t,\"., w \"K,\" with the time-t approach to ui. \"4 Notice that this depends on the actual size of the Ui vectors, so we cannot resolve this problem in K classes if the costs c (i, s) are constant, regardless of i and s.\" 4 Notice that this depends on the actual size of the Ui vectors, so we cannot divide these problems into independent classes. Decomposition takes place if the costs c (i, s) are constant, regardless of i and s, \"the criteria for inclusion will be pi, t.\""}, {"heading": "4 On ranking with partial feedback", "text": "As Lemma 1 points out that the cost values c (i, s) in the loss function \"a, c are strictly decreasing i.e. (1, s) > c (2, s) > c (s, s), for all s [K], then the optimal order Y (1, s) in the order of the order of the order of the order of the order Y (1, s) as the only decreasing order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the sequence of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the order of the"}, {"heading": "5 Experiments", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "6 Technical details", "text": "This section contains all the evidence missing from the main text, along with supplementary results and comments. \"The algorithm in Figure 1 works by updating the flows (1).\" (1) \"The algorithm in Figure 1 works by updating the flows (1).\" (1) \"The algorithm in Figure 1 works by updating the flows (1).\" (2) \"The algorithm in Figure 1.\" (2) \"The algorithm in Figure 1.\" (2) \"The algorithm in Figure 1.\" (2) \"The algorithm in Figure 1.\" (2). \"(2)\" The algorithm in Figure 1. \"(2).\" (2) \"The algorithm in Figure 1.\" (2). \"(1).\" (2). \"The algorithm in Figure 1.\" (2). \"(2).\" The algorithm in Figure 1. \"(2).\" The algorithm in Figure 1. \"(2).\" The algorithm in Figure 1. \"(2).\" The algorithm in Figure 1. \"(2).\" The algorithm in Figure 1. \"(2).\" (2). \"The algorithm in Figure 1.\" (2. \"(2).\" The algorithm in Figure 1. \"(2).\" The algorithm in Figure 1. \"(2.\" (2). \"(2).\""}, {"heading": "7 Conclusions", "text": "We have used generalized linear models to formalize the trade-off between exploration and exploitation in a multi-label / ranking setting with partial feedback that provides T 1 / 2-like limits of remorse under semi-adversarial settings. Our analysis decouples the existing multi-label / ranking loss from the label generation model. Thanks to the use of calibrated score values p, i, t, our algorithm is able to automatically determine where the ranking should be divided between relevant and non-relevant classes [17], the split being clearly induced by the loss parameters in'a, c. We also plan to use more general label models that explicitly capture label correlations that can be applied to other loss functions (e.g. F measure, 0 / 1, average precision, etc.). We also plan to conduct a more thorough experimental comparison, especially on our multi-label classification framework, which we are currently working on (finally)."}], "references": [{"title": "Improved algorithms for linear stochastic bandits", "author": ["Y. Abbasi-Yadkori", "D. Pal", "C. Szepesv\u00e1ri"], "venue": "In Proc. of the 25th NIPS,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Graphical models for bandit problems", "author": ["K. Amin", "M. Kearns", "U. Syed"], "venue": "In Proc. of UAI,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Using confidence bounds for exploitation-exploration", "author": ["P. Auer"], "venue": "trade-offs. JMLR,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Relative loss bounds for online density estimation with the exponential family of distributions", "author": ["K.S. Azoury", "M.K. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2001}, {"title": "Partial monitoring with side information", "author": ["G. Bart\u00f3k", "C. Szepesv\u00e1ri"], "venue": "In Proc. 23rd Alt,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Multi-label classification on tree- and dag-structured hierarchies", "author": ["W. Bi", "J. Kwok"], "venue": "In Proc. 28th ICML,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Learning noisy linear classifiers via adaptive and selective sampling", "author": ["G. Cavallanti", "N. Cesa-Bianchi", "C. Gentile"], "venue": "Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "A second-order perceptron algorithm", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "In Proc. of the 15th Annual Conference on Computational Learning Theory (COLT", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Incremental algorithms for hierarchical classification", "author": ["N. Cesa-Bianchi", "C. Gentile", "L. Zaniboni"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2006}, {"title": "Robust bounds for classification via selective sampling", "author": ["N. Cesa-Bianchi", "C. Gentile", "F. Orabona"], "venue": "In Proc. of the 26th International Conference on Machine Learning", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Multiclass classification with bandit feedback using adaptive regularization", "author": ["K. Crammer", "C. Gentile"], "venue": "In Proc. of the 29th International Conference on Machine Learning", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Stochastic linear optimization under bandit feedback", "author": ["V. Dani", "T. Hayes", "S. Kakade"], "venue": "In Proc. of the 21th annual conference on Learning Theory (COLT", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "Selective sampling and active learning from single and multiple teachers", "author": ["O. Dekel", "C. Gentile", "K. Sridharan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "On label dependence and loss minimization in multi-label classification", "author": ["K. Dembczynski", "W. Waegeman", "W. Cheng", "E. Hullermeier"], "venue": "Machine Learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Parametric bandits: The generalized linear case", "author": ["S. Filippi", "O. Capp\u00e9", "A. Garivier", "C. Szepesv\u00e1ri"], "venue": "In Proc. NIPS,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "An efficient boosting algorithm for combining preferences", "author": ["Y. Freund", "R.D. Iyer", "R.E. Schapire", "Y. Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "Multilabel classification via calibrated label ranking", "author": ["J. Furnkranz", "E. Hullermeier", "E. Loza Menca", "K. Brinker"], "venue": "Machine Learning,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "On multilabel classification and ranking with partial feedback", "author": ["C. Gentile", "F. Orabona"], "venue": "In Proc. NIPS 2012,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Online submodular minimization", "author": ["E. Hazan", "S. Kale"], "venue": "In Proc. NIPS 22,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Newtron: an efficient bandit algorithm for online multiclass prediction", "author": ["E. Hazan", "S. Kale"], "venue": "In NIPS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["E. Hazan", "A. Agarwal", "S. Kale"], "venue": "Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Large margin rank boundaries for ordinal regression", "author": ["R. Herbrich", "T. Graepel", "K. Obermayer"], "venue": "In Advances in Large Margin Classifiers,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2000}, {"title": "Multi-label prediction via compressed sensing", "author": ["D. Hsu", "S. Kakade", "J. Langford", "T. Zhang"], "venue": "In Proc. 23rd NIPS,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "On the generalization ability of online strongly convex programming", "author": ["S. Kakade", "A. Tewari"], "venue": "In Nips,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Efficient bandit algorithms for online multiclass prediction", "author": ["S. Kakade", "S. Shalev-Shwartz", "A. Tewari"], "venue": "In Proc. 25th ICML,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "Non-stochastic bandit slate problems", "author": ["S. Kale", "L. Reyzin", "R. Schapire"], "venue": "In 24th NIPS,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Contextual gaussian process bandit optimization", "author": ["A. Krause", "C.S. Ong"], "venue": "In 25th NIPS,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Asymptotically efficient adaptive allocation rules", "author": ["T.H. Lai", "H. Robbins"], "venue": "Adv. Appl. Math.,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1985}, {"title": "The epoch-greedy algorithm for contextual multi-armed bandits", "author": ["J. Langford", "T. Zhang"], "venue": "Nips", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}, {"title": "Generalized linear models", "author": ["P. McCullagh", "J.A. Nelder"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 1989}, {"title": "Improving multilabel analysis of music titles: A large-scale validation of the correction approach", "author": ["F. Pachet", "P. Roy"], "venue": "IEEE Trans. on Audio, Speech, and Lang. Proc.,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "Elicitation of personal probabilities and expectations", "author": ["L.J. Savage"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1973}, {"title": "Online structured prediction via coactive learning", "author": ["P. Shivaswamy", "T. Joachims"], "venue": "In Proc. 29th ICML,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Fonctions de rpartition n dimensions et leurs marges", "author": ["A. Sklar"], "venue": "Publ. Inst. Statist. Univ. Paris,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 1959}, {"title": "Learning optimally diverse rankings over large document collections", "author": ["A. Slivkins", "F. Radlinski", "S. Gollapudi"], "venue": "In Proc. of the 27th ICML,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2010}, {"title": "The challenge problem for automated detection of 101 semantic concepts in multimedia", "author": ["C.G.M. Snoek", "M. Worring", "J.C. van Gemert", "J.-M. Geusebroek", "A.W.M. Smeulders"], "venue": "In Proc. of the 14th ACM international conference on Multimedia,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2006}, {"title": "Online learning of assignments", "author": ["M. Streeter", "D. Golovin", "A. Krause"], "venue": "In Proc. of the 23rd NIPS,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2009}, {"title": "Random k-labelsets for multilabel classification", "author": ["G. Tsoumakas", "I. Katakis", "I. Vlahavas"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2011}, {"title": "Generalization bounds for online learning algorithms with pairwise loss functions", "author": ["Y. Wang", "R. Khardon", "D. Pechyony", "R. Jones"], "venue": "In Proc. of the 25th Conference on Learning Theory (COLT),", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2012}], "referenceMentions": [{"referenceID": 27, "context": "This technique has been introduced by [28], and can by now be considered a standard tool.", "startOffset": 38, "endOffset": 42}, {"referenceID": 2, "context": ", [3, 12, 15, 11, 27], and references therein) an online algorithm receives at each time step a context (typically, in the form of a feature vector x) and is compelled to select an action (e.", "startOffset": 2, "endOffset": 21}, {"referenceID": 11, "context": ", [3, 12, 15, 11, 27], and references therein) an online algorithm receives at each time step a context (typically, in the form of a feature vector x) and is compelled to select an action (e.", "startOffset": 2, "endOffset": 21}, {"referenceID": 14, "context": ", [3, 12, 15, 11, 27], and references therein) an online algorithm receives at each time step a context (typically, in the form of a feature vector x) and is compelled to select an action (e.", "startOffset": 2, "endOffset": 21}, {"referenceID": 10, "context": ", [3, 12, 15, 11, 27], and references therein) an online algorithm receives at each time step a context (typically, in the form of a feature vector x) and is compelled to select an action (e.", "startOffset": 2, "endOffset": 21}, {"referenceID": 26, "context": ", [3, 12, 15, 11, 27], and references therein) an online algorithm receives at each time step a context (typically, in the form of a feature vector x) and is compelled to select an action (e.", "startOffset": 2, "endOffset": 21}, {"referenceID": 2, "context": "For instance, [3, 12, 15, 1] work in a finite action space where the mappings context-to-loss for each action are linear (or generalized linear, as [15]\u2019s) functions of the features.", "startOffset": 14, "endOffset": 28}, {"referenceID": 11, "context": "For instance, [3, 12, 15, 1] work in a finite action space where the mappings context-to-loss for each action are linear (or generalized linear, as [15]\u2019s) functions of the features.", "startOffset": 14, "endOffset": 28}, {"referenceID": 14, "context": "For instance, [3, 12, 15, 1] work in a finite action space where the mappings context-to-loss for each action are linear (or generalized linear, as [15]\u2019s) functions of the features.", "startOffset": 14, "endOffset": 28}, {"referenceID": 0, "context": "For instance, [3, 12, 15, 1] work in a finite action space where the mappings context-to-loss for each action are linear (or generalized linear, as [15]\u2019s) functions of the features.", "startOffset": 14, "endOffset": 28}, {"referenceID": 14, "context": "For instance, [3, 12, 15, 1] work in a finite action space where the mappings context-to-loss for each action are linear (or generalized linear, as [15]\u2019s) functions of the features.", "startOffset": 148, "endOffset": 152}, {"referenceID": 26, "context": "This is extended by [27], where the loss function is modeled as a sample from a Gaussian process over the joint context-action space.", "startOffset": 20, "endOffset": 24}, {"referenceID": 28, "context": "An earlier (but somehow more general) setting that models such mappings by VC-classes is considered by [29], where a T 2/3 regret bound has been proven under i.", "startOffset": 103, "endOffset": 107}, {"referenceID": 24, "context": ", [25, 11, 20], where either T 2/3 or T 1/2 or even logarithmic regret bounds are proven, depending on the noise model and the underlying loss functions.", "startOffset": 2, "endOffset": 14}, {"referenceID": 10, "context": ", [25, 11, 20], where either T 2/3 or T 1/2 or even logarithmic regret bounds are proven, depending on the noise model and the underlying loss functions.", "startOffset": 2, "endOffset": 14}, {"referenceID": 19, "context": ", [25, 11, 20], where either T 2/3 or T 1/2 or even logarithmic regret bounds are proven, depending on the noise model and the underlying loss functions.", "startOffset": 2, "endOffset": 14}, {"referenceID": 18, "context": "Along these lines are [19, 37, 26, 35, 33, 2].", "startOffset": 22, "endOffset": 45}, {"referenceID": 36, "context": "Along these lines are [19, 37, 26, 35, 33, 2].", "startOffset": 22, "endOffset": 45}, {"referenceID": 25, "context": "Along these lines are [19, 37, 26, 35, 33, 2].", "startOffset": 22, "endOffset": 45}, {"referenceID": 34, "context": "Along these lines are [19, 37, 26, 35, 33, 2].", "startOffset": 22, "endOffset": 45}, {"referenceID": 32, "context": "Along these lines are [19, 37, 26, 35, 33, 2].", "startOffset": 22, "endOffset": 45}, {"referenceID": 1, "context": "Along these lines are [19, 37, 26, 35, 33, 2].", "startOffset": 22, "endOffset": 45}, {"referenceID": 18, "context": "The general problem of online minimization of a submodular loss function under both full and bandit information without covariates is considered by [19], achieving a regret T 2/3 in the bandit case.", "startOffset": 148, "endOffset": 152}, {"referenceID": 36, "context": "[37] consider the problem of online learning of assignments, where at each round an algorithm is requested to assign positions (e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "Another paper with similar goals but a different mathematical model is by [26], where the aim is to learn a suitable ordering (an \u201cordered slate\u201d) of the available actions.", "startOffset": 74, "endOffset": 78}, {"referenceID": 34, "context": "[35] motivate the ability of selecting sets of actions by a problem of diverse retrieval in large document collections which are meant to live in a general metric space.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] use a simple linear model for the hidden utility function of users interacting with a web system and providing partial feedback in any form that allows the system to make significant progress in learning this function (this is called an \u03b1-informative feedback by the authors).", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "The recent paper [2] investigates classes of graphical models for contextual bandit settings that afford richer interaction between contexts and actions leading again to a T 2/3 regret bound.", "startOffset": 17, "endOffset": 20}, {"referenceID": 17, "context": "Finally, a very interesting recent work that came to our attention at the time of writing this extended version of our conference paper [18] is [5].", "startOffset": 136, "endOffset": 140}, {"referenceID": 4, "context": "Finally, a very interesting recent work that came to our attention at the time of writing this extended version of our conference paper [18] is [5].", "startOffset": 144, "endOffset": 147}, {"referenceID": 4, "context": "The results presented by [5] do not seem to conveniently extend to the structured action space setting we are interested in (or, if they do, we do not see it in the current version of their paper).", "startOffset": 25, "endOffset": 28}, {"referenceID": 37, "context": "Relevant references include [38, 17, 14], along with references therein.", "startOffset": 28, "endOffset": 40}, {"referenceID": 16, "context": "Relevant references include [38, 17, 14], along with references therein.", "startOffset": 28, "endOffset": 40}, {"referenceID": 13, "context": "Relevant references include [38, 17, 14], along with references therein.", "startOffset": 28, "endOffset": 40}, {"referenceID": 13, "context": "In contrast to that, the specific setting we are considering here need not face such a modeling [14].", "startOffset": 96, "endOffset": 100}, {"referenceID": 38, "context": "recent work [39] reduces any online algorithm working on pairwise loss functions (like a ranking loss) to a batch algorithm with generalization bound guarantees.", "startOffset": 12, "endOffset": 16}, {"referenceID": 21, "context": "Other related references are [22, 16], where learning is by pairs of examples.", "startOffset": 29, "endOffset": 37}, {"referenceID": 15, "context": "Other related references are [22, 16], where learning is by pairs of examples.", "startOffset": 29, "endOffset": 37}, {"referenceID": 2, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 85, "endOffset": 114}, {"referenceID": 11, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 85, "endOffset": 114}, {"referenceID": 12, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 85, "endOffset": 114}, {"referenceID": 10, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 85, "endOffset": 114}, {"referenceID": 14, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 85, "endOffset": 114}, {"referenceID": 0, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 85, "endOffset": 114}, {"referenceID": 26, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 85, "endOffset": 114}, {"referenceID": 4, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 85, "endOffset": 114}, {"referenceID": 36, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 173, "endOffset": 185}, {"referenceID": 25, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 173, "endOffset": 185}, {"referenceID": 32, "context": "To summarize, whereas we are technically closer to the linear modeling approaches by [3, 12, 13, 11, 15, 1, 27, 5], from a motivational standpoint we are perhaps closest to [37, 26, 33].", "startOffset": 173, "endOffset": 185}, {"referenceID": 18, "context": ", [19, 37, 1, 27]), we are not assuming the algorithm is observing a noisy version of the risk function on the currently selected action.", "startOffset": 2, "endOffset": 17}, {"referenceID": 36, "context": ", [19, 37, 1, 27]), we are not assuming the algorithm is observing a noisy version of the risk function on the currently selected action.", "startOffset": 2, "endOffset": 17}, {"referenceID": 0, "context": ", [19, 37, 1, 27]), we are not assuming the algorithm is observing a noisy version of the risk function on the currently selected action.", "startOffset": 2, "endOffset": 17}, {"referenceID": 26, "context": ", [19, 37, 1, 27]), we are not assuming the algorithm is observing a noisy version of the risk function on the currently selected action.", "startOffset": 2, "endOffset": 17}, {"referenceID": 10, "context": "In this sense, we are more similar to the multiclass bandit algorithm by [11].", "startOffset": 73, "endOffset": 77}, {"referenceID": 10, "context": "Yet, our work is a substantial departure from [11]\u2019s in that we lift their machinery to nontrivial structured action spaces, and we do so by means of generalized linear models.", "startOffset": 46, "endOffset": 50}, {"referenceID": 0, "context": "Specifically, given constant a \u2208 [0, 1] and costs c = {c(i, s), i = 1, .", "startOffset": 33, "endOffset": 39}, {"referenceID": 16, "context": "In this sense, the above problem can be seen as a partial information version of the multilabel ranking problem (see [17], 1 An ordered subset is like a list with no repeated items.", "startOffset": 117, "endOffset": 121}, {"referenceID": 0, "context": "2Notice that a is not redundant here, since the costs c(i, s) have been normalized to [0,1].", "startOffset": 86, "endOffset": 91}, {"referenceID": 29, "context": "3 The reader familiar with generalized linear models will recognize the derivative of the function p(\u2206) = g(\u2212\u2206) g(\u2206)+g(\u2212\u2206) as the (inverse) link function of the associated canonical exponential family of distributions [30].", "startOffset": 218, "endOffset": 222}, {"referenceID": 33, "context": "A classical result in the theory of copulas [34] makes one derive all allowed joint distributions starting from the corresponding one-dimensional marginals.", "startOffset": 44, "endOffset": 48}, {"referenceID": 10, "context": "We use a similar but largely more general analysis than [11]\u2019s to devise an online second-order descent algorithm whose updating rule makes the comparison vector U = (u1, .", "startOffset": 56, "endOffset": 60}, {"referenceID": 0, "context": "Parameters: loss parameters a \u2208 [0, 1], cost values c(i, s), interval D = [\u2212R,R], function g : D \u2192 R, confidence level \u03b4 \u2208 [0, 1].", "startOffset": 32, "endOffset": 38}, {"referenceID": 0, "context": "Parameters: loss parameters a \u2208 [0, 1], cost values c(i, s), interval D = [\u2212R,R], function g : D \u2192 R, confidence level \u03b4 \u2208 [0, 1].", "startOffset": 123, "endOffset": 129}, {"referenceID": 20, "context": ", [21].", "startOffset": 2, "endOffset": 6}, {"referenceID": 20, "context": "This feature tells this algorithm slightly apart from the Online Newton step algorithm [21], which is the starting point of our analysis.", "startOffset": 87, "endOffset": 91}, {"referenceID": 10, "context": ", by [11]), one can use a version of the algorithm which maintains diagonal matrices Ai,t instead of full ones.", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": ", [14]), one can view any multilabel assignment Y = (y1, .", "startOffset": 2, "endOffset": 6}, {"referenceID": 13, "context": "As pointed out by [14], the ranking function f(xt) = (p1,t, .", "startOffset": 18, "endOffset": 22}, {"referenceID": 16, "context": ", f \u2217 K(xt)), 8 This is called the zero point by [17].", "startOffset": 49, "endOffset": 53}, {"referenceID": 13, "context": "This is in striking contrast to the full information setting, where the Bayes optimal ranking only depends on the marginal distribution values pi,t [14].", "startOffset": 148, "endOffset": 152}, {"referenceID": 22, "context": ", [23] and references therein) and/or the specific structure of the set of labels (e.", "startOffset": 2, "endOffset": 6}, {"referenceID": 8, "context": ", [9, 6], and references therein).", "startOffset": 2, "endOffset": 8}, {"referenceID": 5, "context": ", [9, 6], and references therein).", "startOffset": 2, "endOffset": 8}, {"referenceID": 35, "context": "The first one, called Mediamill, was introduced in a video annotation challenge [36].", "startOffset": 80, "endOffset": 84}, {"referenceID": 30, "context": "The second dataset is Sony CSL Paris [31], made up of 16,452 train samples and 16,519 test samples, each sample being described by d = 98 features.", "startOffset": 37, "endOffset": 41}, {"referenceID": 31, "context": ", [32]).", "startOffset": 2, "endOffset": 6}, {"referenceID": 13, "context": "A simple adaptation of [14] (proof of Theorem 1 therein) shows that for a generic sequence \u00e2 =", "startOffset": 23, "endOffset": 27}, {"referenceID": 20, "context": "Proof: For any given class i, the time-t update rule wi,t \u2192 wi,t+1 \u2192 wi,t+1 in Figure 1 allows us to start off from [21] (proof of Theorem 2 therein), from which one can extract the following inequality di,t\u22121(ui,w \u2032 i,t) \u2264 U + 1 (c\u2032\u2032 L) 2 t\u22121 \u2211", "startOffset": 116, "endOffset": 120}, {"referenceID": 12, "context": "We now borrow a proof technique from [13] (see also [11, 1] and references therein).", "startOffset": 37, "endOffset": 41}, {"referenceID": 10, "context": "We now borrow a proof technique from [13] (see also [11, 1] and references therein).", "startOffset": 52, "endOffset": 59}, {"referenceID": 0, "context": "We now borrow a proof technique from [13] (see also [11, 1] and references therein).", "startOffset": 52, "endOffset": 59}, {"referenceID": 23, "context": "For instance, setting for brevity B = B(t, \u03b4) = 3 ln K(t+4) \u03b4 , a result contained in [24] allows us derive the inequality", "startOffset": 86, "endOffset": 90}, {"referenceID": 3, "context": "Applying known inequalities [4, 8, 10, 7, 21, 13], and using the fact that\u2207i,k = L(si,k xkwi,k) si,kxk we have12 t\u22121 \u2211", "startOffset": 28, "endOffset": 49}, {"referenceID": 7, "context": "Applying known inequalities [4, 8, 10, 7, 21, 13], and using the fact that\u2207i,k = L(si,k xkwi,k) si,kxk we have12 t\u22121 \u2211", "startOffset": 28, "endOffset": 49}, {"referenceID": 9, "context": "Applying known inequalities [4, 8, 10, 7, 21, 13], and using the fact that\u2207i,k = L(si,k xkwi,k) si,kxk we have12 t\u22121 \u2211", "startOffset": 28, "endOffset": 49}, {"referenceID": 6, "context": "Applying known inequalities [4, 8, 10, 7, 21, 13], and using the fact that\u2207i,k = L(si,k xkwi,k) si,kxk we have12 t\u22121 \u2211", "startOffset": 28, "endOffset": 49}, {"referenceID": 20, "context": "Applying known inequalities [4, 8, 10, 7, 21, 13], and using the fact that\u2207i,k = L(si,k xkwi,k) si,kxk we have12 t\u22121 \u2211", "startOffset": 28, "endOffset": 49}, {"referenceID": 12, "context": "Applying known inequalities [4, 8, 10, 7, 21, 13], and using the fact that\u2207i,k = L(si,k xkwi,k) si,kxk we have12 t\u22121 \u2211", "startOffset": 28, "endOffset": 49}, {"referenceID": 20, "context": "Notice that using the latter (as in the worst-case analysis by [21]), does not guarantee a significant progress in the positive definiteness of Ai,t.", "startOffset": 63, "endOffset": 67}, {"referenceID": 16, "context": "Thanks to the usage of calibrated score values p\u0302i,t, our algorithm is capable of automatically inferring where to split the ranking between relevant and nonrelevant classes [17], the split being clearly induced by the loss parameters in `a,c.", "startOffset": 174, "endOffset": 178}], "year": 2013, "abstractText": "We present a novel multilabel/ranking algorithm working in partial information settings. The algorithm is based on 2nd-order descent methods, and relies on upper-confidence bounds to trade-off exploration and exploitation. We analyze this algorithm in a partial adversarial setting, where covariates can be adversarial, but multilabel probabilities are ruled by (generalized) linear models. We show O(T 1/2 log T ) regret bounds, which improve in several ways on the existing results. We test the effectiveness of our upper-confidence scheme by contrasting against full-information baselines on real-world multilabel datasets, often obtaining comparable performance.", "creator": "LaTeX with hyperref package"}}}