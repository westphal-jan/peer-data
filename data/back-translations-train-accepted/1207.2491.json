{"id": "1207.2491", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jul-2012", "title": "A Spectral Learning Approach to Range-Only SLAM", "abstract": "We present a novel spectral learning algorithm for simultaneous localization and mapping (SLAM) from range data with known correspondences. This algorithm is an instance of a general spectral system identification framework, from which it inherits several desirable properties, including statistical consistency and no local optima. Compared with popular batch optimization or multiple-hypothesis tracking (MHT) methods for range-only SLAM, our spectral approach offers guaranteed low computational requirements and good tracking performance. Compared with popular extended Kalman filter (EKF) or extended information filter (EIF) approaches, and many MHT ones, our approach does not need to linearize a transition or measurement model; such linearizations can cause severe errors in EKFs and EIFs, and to a lesser extent MHT, particularly for the highly non-Gaussian posteriors encountered in range-only SLAM. We provide a theoretical analysis of our method, including finite-sample error bounds. Finally, we demonstrate on a real-world robotic SLAM problem that our algorithm is not only theoretically justified, but works well in practice: in a comparison of multiple methods, the lowest errors come from a combination of our algorithm with batch optimization, but our method alone produces nearly as good a result at far lower computational cost.", "histories": [["v1", "Tue, 10 Jul 2012 21:19:33 GMT  (2216kb,D)", "http://arxiv.org/abs/1207.2491v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.RO stat.ML", "authors": ["byron boots", "geoffrey j gordon"], "accepted": true, "id": "1207.2491"}, "pdf": {"name": "1207.2491.pdf", "metadata": {"source": "CRF", "title": "A Spectral Learning Approach to Range-Only SLAM", "authors": ["Byron Boots", "Geoffrey J. Gordon"], "emails": ["beb@cs.cmu.edu", "ggordon@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it has come to the point where it will be able to enlighten the aforementioned brain-consecrated brain-consecrated brain-consecrated brain-consecrated brain-consecrated brain-consecrated brain-consecrated brain-tecsrteeSe."}, {"heading": "2 Background", "text": "There are four important pieces of background information: firstly, the known solutions for SLAM, which cover only domains and use variations of the advanced Kalman filter and batch optimization; secondly, recently discovered spectral approaches to identify parameters of nonlinear dynamic systems; thirdly, matrix factorization to determine structures from motion in video; and fourthly, dimensionality reduction methods for localization and mapping. In the following, we will discuss the links between these domains and show how they can be unified within a spectral learning framework."}, {"heading": "2.1 Likelihood-based Range-only SLAM", "text": "The standard probability models for pure localization (Kantor & Singh, 2002; Kurth et al., 2003) represent the robot state by a vector st = [xt, yt, \u03b8t] T; the robot (nonlinear) motion and observation problems are therefore most + 1 = [xt + vt cos (outraged) yt + vt sin (outraged) outraged that it is not able to extend the range (mn, x \u2212 xt) 2 + (mn, y \u2212 yt) 2 + \u03b7t (1) Here the distance has traveled, spectrum is the change of orientation, dt, n is the estimation of the range of the ninth landmark location (mn, mn, y) to the current position of the robot (xt, yt), and it is noise. (During this paper, we assume that known correspondences, since range-sensitive systems such as radio signals have become unique to LAM measurement)."}, {"heading": "2.2 Spectral State Space Discovery and System Identification", "text": "System identification algorithms attempt to learn dynamic system parameters such as a state space, a dynamic model (motion model), and an observation model (measurement model) directly from samples of observations and actions. In recent years, spectral system identification algorithms have become popular; these algorithms learn a state space through a spectral decomposition of a carefully designed matrix of observable features, then find transition and observational models through linear regressions that incorporate the states learned. Originally, sub-space identification algorithms were used almost exclusively for linear system identification (Van Overschee & De Moor, 1996), but more recently, similar spectral algorithms have been used to learn models of partially observable non-linear dynamic systems such as HMMs (Hsu et al., 2009; Siddiqi et al., 2010) and PSRs (Rosencrantz et al., 2004; Boots al.)."}, {"heading": "2.3 Orthographic Structure From Motion", "text": "In a way, the orthographic structure of motion (SfM) is similar to the SLAM problem (Tomasi & Kanade, 1992): the goal is to recreate scene geometry and camera rotations from a sequence of images (compare with the geometry of landmarks and robot positions from a sequence of distance observations), and indeed, a popular solution for SfM is very similar to the step of detecting the state of P points tracked by F-frames. If the images are the result of an orthographic camera projection, then it is possible to show that an image sequence can be represented as a 2F \u00d7 P measurement matrix W, which contains the horizontal and vertical coordinates of P points tracked by F-frames. If the images are the result of an orthographic camera projection, then it is possible that rank (W) = 3. Consequently, the measurement matrix containing the W points, the W points tracked by the P-coordinates, and the P-coordinates are versed by the P-frames."}, {"heading": "2.4 Dimensionality-reduction-based Methods for Mapping", "text": "In particular, the problem of finding a good map can be seen as a search for a (possibly non-linear) embedding of sensor data using methods such as multidimensional scaling (MDS) and multiple learning techniques. For example, MDS was used to determine a Euclidean map of sensor locations where there is no distinction between boundary locations and robot positions (Shang et al., 2003): instead, measurements of all ranges are assumed for a number of landmarks. If some paired measurements are not available, these measurements can be made by an interpolation method, e.g. geodetic distance between landmarks (Tenenbaum et al., 2000; Shang et al., 2003). Our problem differs from this previous work: Unlike MDS, we do not have landmark-to-landmark measurements."}, {"heading": "3 State Space Discovery and Spectral SLAM", "text": "We start with SLAM from domain data without odometry. For the time being, we assume no noise, no missing data and batch processing. In the following, we will generalize: Section 3.2 discusses how to restore robot orientation, Section 3.3 discusses noise, and Section 3.4 discusses missing data and online SLAM. In the appendix (Section 6.3), we will discuss learning motion and measurement models."}, {"heading": "3.1 Range-only SLAM as Matrix Factorization", "text": "Let us look at the matrix Y, x + m 2 n, y) / 2, mn, mn, y] and yyt = 1 x y. let us look at the matrix Y, x RN \u00b7 T of the squared ranges, with N \u2265 4 landmarks and T \u2265 4 time steps: Y = 12 d211 d 2 12. \u2212 d 2 1T d221 d 2 22. \u2212 d 2 2T......... d2N1 d 2 NT (3), where dn, t is the measured distance from the robot to the landmark n in time step. The most basic version of our spectral SLAM method is based on the knowledge that Y factors are determined by robot position (xt, yt) and landmark position (mn, mn, y). To see why noted2n n n, t = (m 2 n, m 2 n, y) \u2212 2mn, x \u00b7 xt \u2212 2mn, y, y \u00b7 yt + (x2t + yt) (4) (we write [C4], mn = [x] n."}, {"heading": "3.2 SLAM with Headings", "text": "In addition to the position of the robot, we want the global path of the robot (7) before processing our learned positions, but in practice we can reduce the variance by adding more features to our measurement matrix: differences between successive pairs of square distances, scaled according to velocity (which we can estimate from odometry).Since we need pairs of time steps, we now have Y values \u2212 1: Y = 12 d211 d 2.... d 2 1T \u2212 1....... d2N1 d 2 d 2 NT \u2212 2. D 2 NT \u2212 1d212 \u2212 d 2 11v1d213 \u2212 d 2 12v2. d21T \u2212 d 2 1T \u2212 1vT \u2212 1... d2N2 \u2212 d 2... d2N2 \u2212 d 2 NV 2 N3v2."}, {"heading": "3.3 A Spectral SLAM Algorithm", "text": "The matrix factorizations of sectors 3.1 and 3.2 indicate a simple SLAM algorithm, Alg. 1: Build an empirical estimate Y of Y by sampling observations as the robot traverses its environment, and then apply a thin SVD value of rank 7, discarding the remaining singular values to suppress noise. < U value and the weighted singular vectors Y value (Y value, 7) (11) Following Section 3.2, the left singular vectors U value are an estimate of our transformed measurement matrix CS-1, and the weighted right singular vectors representing the value of our transformed robot state SX value are an estimate of S via regression or metric upgradation. Let us leave M models that represent the true observation variance M value for a random robotic position."}, {"heading": "3.4 Extensions: Missing Data, Online SLAM, and System ID", "text": "In practice, this assumption is rarely fulfilled: we can measure ranges asynchronously, some range measurements can be completely missing, and it is often the case that the probability calculation is faster than the range measurements, where the missing entries are marked by an EM algorithm, and matrix completion (Cande & Plan, 2009) is replaced by standard approaches for factorization with missing data."}, {"heading": "4 Experimental Results", "text": "We will conduct several SLAM and robot navigation experiments to illustrate and test the ideas proposed in this thesis. First, we will demonstrate how our methods work in theory with synthetic experiments, where complete observations are available at all times and usually noise is sampled from a multivariate Gaussian distribution. Next, we will demonstrate our algorithm using data collected from a real robotic system with significant amounts of missing data. Experiments were conducted in Matlab on a 2.66 GHz Intel Core i7 computer with 8 GB RAM. Unlike non-linear optimization approaches for SLAM, the spectral learning methods described in this thesis are very fast and typically take less than a second."}, {"heading": "4.1 Synthetic Experiments", "text": "Our simulator randomly places 6 boundary stones in a 2-D environment. A simulated robot then randomly moves through the environment for 500 time steps, obtaining a range measurement for each of the boundary stones at each time step. The range measurements are disturbed by sounds taken from a Gaussian distribution with a variance of 1% of the range. In light of this data, we apply the algorithm from Section 3.3 to solve the SLAM problem. We also used the coordinates of 4 boundary stones to learn the linear transformation S and restore the true state space, as shown in Figure 2A. The results indicate that we can accurately restore both the boundary stones and the robot path. We also examined the empirical convergence rate of our observation model (and thus the map) as the number of range measurements increased. To do this, we generated 1,000 different random pairs of surroundings and robotic algorithms, and we repeated the estimated distances for each pair of robots."}, {"heading": "4.2 Robotic Experiments", "text": "We used two freely available environmental zone SLAM data sets collected by an autonomous lawnmower robot (Djugash, 2010), shown in Figure. 3A.1 These \"plaza\" data sets were collected via radio nodes from multi-spectral solutions that use the time of flight of ultra-wide signals to distinguish between the nodes. (Further details of the test series are found in the vicinity) This system produces a time span between the mobile robots and stationary nodes (landmarks) in the vicinity. Landmark radio nodes are placed about 138 cm above the ground, and a node was placed in the middle of the robot frame (also 138 cm above the ground)."}, {"heading": "5 Conclusion", "text": "The core of this new approach is to formulate SLAM as a factorization problem that enables us to derive a locally minimal free spectral learning method that is closely related to SfM and spectral approaches to system identification. We offer theoretical guarantees for our algorithm, discuss how to derive an online algorithm, and show how to generalize a complete algorithm for identifying robotic systems. Finally, we show that our spectral approach to SLAM beats other state-of-the-art SLAM approaches to real SLAM problems."}, {"heading": "Acknowledgements", "text": "Byron Boots and Geoffrey Gordon were supported by ONR MURI grant number N00014-09-11052. Byron Boots was supported by NSF grant number EEEC-0540865."}, {"heading": "6 Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Metric Upgrade for Learned Map", "text": "We assume that the global position estimates of at least four landmarks are known. If these landmarks are known, we can restore all estimated landmarks and robot locations. However, in many cases, no global positions are known; the best we can do is to obtain landmarks and robot positions up to an orthogonal transformation (translation, rotation and reflection). It turns out that the matrix C2, with the same number of rows as C, but 10 columns, whose ith series elements ci, jci, k for 1 \u2264 k \u2264 k \u2264 4 (in any fixed order) we are correct. Note that the rank of C2 can be most 9: of Eq. 5, we know that c2i, 2 + c 2, 3 \u2212 3 \u2212 3 are the function of C2 (in any fixed order) we are."}, {"heading": "6.2 Sample Complexity for the Measurement Model (Robot Map)", "text": "Here we provide the details of what our estimation error scale looks like with the number T of training examples - that is, the scaling of the difference between the estimated measurement model U \u00b2, which represents the position of landmarks and their population partners. Our limit has two parts. First, we use a standard concentration limit (the Azuma-Hoeffding inequality) to show that each element of our estimated covariance M \u00b2 = Y \u00b2 Y \u00b2 > approximates its population value. We start by adding up the empirical covariance matrix as a vector across multiple samples: vec (M \u00b2) = 1T \u00b2 T \u00b2 t \u00b2 t = 1:, twhere the matrix = (Y \u00b2 Y \u00b2 Y \u00b2 Y \u00b2) > is the column-wise Kronecker products of the observations Y \u00b2. We assume that each element of its expectation i \u00b2 is limited by a constant c; we can derive c \u00b2 from the expected errors in the distance measurements and odomricity measurements."}, {"heading": "6.3 The Robot as a Nonlinear Dynamical System", "text": "Once we have learned an interpretable state space via the algorithm of Section 3.3, we can simply write down the nominal robot dynamics in that space, and the accuracy of the resulting model will depend on how well our sensors and actuators follow the nominal dynamics, as well as how well we have learned the transformation S into the interpretable version of the state space. In detail, we model the robot as a controlled nonlinear dynamic system. \u2212 Evolution is governed by the following state space equations, which (1) generalize: st + 1 = f (st, at) + t (17) ot = h (st) \u2212 whet (18) Here, st \u2212 Rk stands for the hidden state \u2212 whet for the control signal, ot Rm for observation, t Rk for state noise, and Rm for observation noise, and imt Rm for observation noise. \u2212 For our pure system following the decomposition of Section 3, we have vvt + vt = 21vt (vt = 21vt)."}, {"heading": "6.3.1 Robot System Identification", "text": "To apply the model of section 6.3, it is important that we maintain the states in the physical coordinate system = q = most of the terms of the special S class (and not just the linearly transformed coordinate frame - i.e., C and not U class = C class). To use this model, we must learn S either by regression or by metric appreciation. However, it is possible to use the system identification instead to derive some deviations from the nominal model of section 6.3. To derive our system identification algorithm, we can explicitly rewrite f (st, at) as a non-linear feature expansion map followed by a linear projection. Our algorithm will then use only linear regression to learn the linear part of the f class."}, {"heading": "6.3.2 Filtering with the Extended Kalman Filter", "text": "Whether we learn the dynamics by system identification or simply enter them into the interpretable version of our state space (>), we will end up with a transition model of the form (22) and an observational model of the form (20). \u2212 In view of these models, it is easy to note an EKF that tracks the robot state. \u2212 The measurement update is merely a standard update of the Kalman filter (see e.g. (Thrun et al., 2005), since the observation model is linear. \u2212 For the motion update, we need a Taylor approximation of the expected state at the time t + 1 around the current MAP state s, given the current action at: st + 1 \u2212 st \u00b2 N (s \u00b2 t, at) + d \u00b2 s \u00b2 s (st \u2212 s \u00b2 t, t \u00b2 t \u2212 t) (26) d\u03c6 of the expected state at the time t + 1 around the current MAP state s \u00b2 t \u00b2, given the current action at: st + 1 \u2212 st \u00b2 s \u00b2 n (t \u00b2 t)."}], "references": [{"title": "Action respecting embedding", "author": ["M. Biggs", "A. Ghodsi", "D. Wilkinson", "M. Bowling"], "venue": "In Proceedings of the Twenty-Second International Conference on Machine Learning (pp. 65\u201372)", "citeRegEx": "Biggs et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Biggs et al\\.", "year": 2005}, {"title": "Predictive state temporal difference learning", "author": ["B. Boots", "G. Gordon"], "venue": "Advances in neural information processing systems", "citeRegEx": "Boots and Gordon,? \\Q2010\\E", "shortCiteRegEx": "Boots and Gordon", "year": 2010}, {"title": "An online spectral learning algorithm for partially observable nonlinear dynamical systems", "author": ["B. Boots", "S. Siddiqi", "G. Gordon"], "venue": "Proceedings of the 25th National Conference on Artificial Intelligence (AAAI-2011)", "citeRegEx": "Boots et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boots et al\\.", "year": 2011}, {"title": "Closing the learning-planning loop with predictive state representations", "author": ["B. Boots", "S.M. Siddiqi", "G.J. Gordon"], "venue": "Proceedings of Robotics: Science and Systems VI", "citeRegEx": "Boots et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Boots et al\\.", "year": 2010}, {"title": "Fast low-rank modifications of the thin singular value decomposition", "author": ["M. Brand"], "venue": "Linear Algebra and its Applications,", "citeRegEx": "Brand,? \\Q2006\\E", "shortCiteRegEx": "Brand", "year": 2006}, {"title": "Matrix completion with noise. CoRR, abs/0903.3131", "author": ["E.J. Cand\u00e8s", "Y. Plan"], "venue": null, "citeRegEx": "Cand\u00e8s and Plan,? \\Q2009\\E", "shortCiteRegEx": "Cand\u00e8s and Plan", "year": 2009}, {"title": "Geolocation with range: Robustness, efficiency and scalabilityPhD", "author": ["J. Djugash"], "venue": null, "citeRegEx": "Djugash,? \\Q2010\\E", "shortCiteRegEx": "Djugash", "year": 2010}, {"title": "A robust method of localization and mapping using only range", "author": ["J. Djugash", "S. Singh"], "venue": "International Symposium on Experimental Robotics", "citeRegEx": "Djugash and Singh,? \\Q2008\\E", "shortCiteRegEx": "Djugash and Singh", "year": 2008}, {"title": "Further results with localization and mapping using range from radio", "author": ["J. Djugash", "S. Singh", "P.I. Corke"], "venue": "International Conference on Field and Service Robotics", "citeRegEx": "Djugash et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Djugash et al\\.", "year": 2005}, {"title": "WiFi-SLAM using Gaussian process latent variable models", "author": ["B. Ferris", "D. Fox", "N. Lawrence"], "venue": "Proceedings of the 20th international joint conference on Artifical intelligence (pp", "citeRegEx": "Ferris et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ferris et al\\.", "year": 2007}, {"title": "A spectral algorithm for learning hidden Markov models. COLT", "author": ["D. Hsu", "S. Kakade", "T. Zhang"], "venue": null, "citeRegEx": "Hsu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2009}, {"title": "Factorization methods for structure from motion", "author": ["T. Kanade", "D. Morris"], "venue": "Philosophical Transactions of the Royal Society of London. Series A: Mathematical, Physical and Engineering", "citeRegEx": "Kanade and Morris,? \\Q1998\\E", "shortCiteRegEx": "Kanade and Morris", "year": 1998}, {"title": "Preliminary results in range-only localization and mapping", "author": ["G.A. Kantor", "S. Singh"], "venue": "Proceedings of the IEEE Conference on Robotics and Automation (ICRA", "citeRegEx": "Kantor and Singh,? \\Q2002\\E", "shortCiteRegEx": "Kantor and Singh", "year": 2002}, {"title": "Range-only SLAM with interpolated range data (Technical Report CMU-RI-TR-06-26)", "author": ["A. Kehagias", "J. Djugash", "S. Singh"], "venue": "Robotics Institute", "citeRegEx": "Kehagias et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kehagias et al\\.", "year": 2006}, {"title": "Experimental results in range-only localization with radio", "author": ["D. Kurth", "G.A. Kantor", "S. Singh"], "venue": "IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS \u201903) (pp", "citeRegEx": "Kurth et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kurth et al\\.", "year": 2003}, {"title": "FastSLAM: A factored solution to the simultaneous localization and mapping problem", "author": ["M. Montemerlo", "S. Thrun", "D. Koller", "B. Wegbreit"], "venue": "In Proceedings of the AAAI National Conference on Artificial Intelligence (pp. 593\u2013598)", "citeRegEx": "Montemerlo et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Montemerlo et al\\.", "year": 2002}, {"title": "Learning low dimensional predictive representations", "author": ["M. Rosencrantz", "G.J. Gordon", "S. Thrun"], "venue": null, "citeRegEx": "Rosencrantz et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Rosencrantz et al\\.", "year": 2004}, {"title": "Localization from mere connectivity", "author": ["Y. Shang", "W. Ruml", "Y. Zhang", "M.P.J. Fromherz"], "venue": "Proceedings of the 4th ACM international symposium on Mobile ad hoc networking & computing (pp. 201\u2013212)", "citeRegEx": "Shang et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Shang et al\\.", "year": 2003}, {"title": "Reduced-rank hidden Markov models", "author": ["S. Siddiqi", "B. Boots", "G.J. Gordon"], "venue": "Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics", "citeRegEx": "Siddiqi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Siddiqi et al\\.", "year": 2010}, {"title": "Matrix perturbation theory", "author": ["G.W. Stewart", "Sun", "J.-G"], "venue": null, "citeRegEx": "Stewart et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Stewart et al\\.", "year": 1990}, {"title": "A global geometric framework for nonlinear dimensionality reduction", "author": ["J.B. Tenenbaum", "V.D. Silva", "J. Langford"], "venue": null, "citeRegEx": "Tenenbaum et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Tenenbaum et al\\.", "year": 2000}, {"title": "Probabilistic robotics (intelligent robotics and autonomous agents)", "author": ["S. Thrun", "W. Burgard", "D. Fox"], "venue": null, "citeRegEx": "Thrun et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Thrun et al\\.", "year": 2005}, {"title": "Probabilistic principal component analysis", "author": ["M.E. Tipping", "C.M. Bishop"], "venue": "Journal of the Royal Statistical Society, Series B,", "citeRegEx": "Tipping and Bishop,? \\Q1999\\E", "shortCiteRegEx": "Tipping and Bishop", "year": 1999}, {"title": "Shape and motion from image streams under orthography: a factorization method", "author": ["C. Tomasi", "T. Kanade"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Tomasi and Kanade,? \\Q1992\\E", "shortCiteRegEx": "Tomasi and Kanade", "year": 1992}, {"title": "Factorization methods for projective structure and motion", "author": ["B. Triggs"], "venue": "Computer Vision and Pattern Recognition,", "citeRegEx": "Triggs,? \\Q1996\\E", "shortCiteRegEx": "Triggs", "year": 1996}, {"title": "Subspace identification for linear systems: Theory, implementation, applications", "author": ["P. Van Overschee", "B. De Moor"], "venue": null, "citeRegEx": "Overschee and Moor,? \\Q1996\\E", "shortCiteRegEx": "Overschee and Moor", "year": 1996}, {"title": "Map building without localization by dimensionality reduction techniques", "author": ["T. Yairi"], "venue": "Proceedings of the 24th international conference on Machine learning (pp. 1071\u20131078)", "citeRegEx": "Yairi,? \\Q2007\\E", "shortCiteRegEx": "Yairi", "year": 2007}], "referenceMentions": [{"referenceID": 14, "context": "Popular approaches to range-only SLAM include EKFs and EIFs (Kantor & Singh, 2002; Kurth et al., 2003; Djugash & Singh, 2008; Djugash, 2010; Thrun et al., 2005), multiple-hypothesis trackers (including particle filters and multiple EKFs/EIFs) (Djugash et al.", "startOffset": 60, "endOffset": 160}, {"referenceID": 6, "context": "Popular approaches to range-only SLAM include EKFs and EIFs (Kantor & Singh, 2002; Kurth et al., 2003; Djugash & Singh, 2008; Djugash, 2010; Thrun et al., 2005), multiple-hypothesis trackers (including particle filters and multiple EKFs/EIFs) (Djugash et al.", "startOffset": 60, "endOffset": 160}, {"referenceID": 21, "context": "Popular approaches to range-only SLAM include EKFs and EIFs (Kantor & Singh, 2002; Kurth et al., 2003; Djugash & Singh, 2008; Djugash, 2010; Thrun et al., 2005), multiple-hypothesis trackers (including particle filters and multiple EKFs/EIFs) (Djugash et al.", "startOffset": 60, "endOffset": 160}, {"referenceID": 8, "context": ", 2005), multiple-hypothesis trackers (including particle filters and multiple EKFs/EIFs) (Djugash et al., 2005; Thrun et al., 2005), and batch optimization of a likelihood function (Kehagias et al.", "startOffset": 90, "endOffset": 132}, {"referenceID": 21, "context": ", 2005), multiple-hypothesis trackers (including particle filters and multiple EKFs/EIFs) (Djugash et al., 2005; Thrun et al., 2005), and batch optimization of a likelihood function (Kehagias et al.", "startOffset": 90, "endOffset": 132}, {"referenceID": 13, "context": ", 2005), and batch optimization of a likelihood function (Kehagias et al., 2006).", "startOffset": 57, "endOffset": 80}, {"referenceID": 6, "context": ", by changing the hypothesis representation (Djugash, 2010) or by keeping multiple hypotheses (Djugash et al.", "startOffset": 44, "endOffset": 59}, {"referenceID": 8, "context": ", by changing the hypothesis representation (Djugash, 2010) or by keeping multiple hypotheses (Djugash et al., 2005; Djugash, 2010; Thrun et al., 2005).", "startOffset": 94, "endOffset": 151}, {"referenceID": 6, "context": ", by changing the hypothesis representation (Djugash, 2010) or by keeping multiple hypotheses (Djugash et al., 2005; Djugash, 2010; Thrun et al., 2005).", "startOffset": 94, "endOffset": 151}, {"referenceID": 21, "context": ", by changing the hypothesis representation (Djugash, 2010) or by keeping multiple hypotheses (Djugash et al., 2005; Djugash, 2010; Thrun et al., 2005).", "startOffset": 94, "endOffset": 151}, {"referenceID": 3, "context": "As we will discuss in Section 2, our approach to SLAM has much in common with spectral algorithms for subspace identification (Van Overschee & De Moor, 1996; Boots et al., 2010); unlike these methods, our focus on SLAM makes it easy to interpret our state space.", "startOffset": 126, "endOffset": 177}, {"referenceID": 24, "context": "Our approach is also related to factorization-based structure from motion (Tomasi & Kanade, 1992; Triggs, 1996; Kanade & Morris, 1998), as well as to recent dimensionality-reduction-based methods for localization and mapping (Shang et al.", "startOffset": 74, "endOffset": 134}, {"referenceID": 17, "context": "Our approach is also related to factorization-based structure from motion (Tomasi & Kanade, 1992; Triggs, 1996; Kanade & Morris, 1998), as well as to recent dimensionality-reduction-based methods for localization and mapping (Shang et al., 2003; Biggs et al., 2005; Ferris et al., 2007; Yairi, 2007).", "startOffset": 225, "endOffset": 299}, {"referenceID": 0, "context": "Our approach is also related to factorization-based structure from motion (Tomasi & Kanade, 1992; Triggs, 1996; Kanade & Morris, 1998), as well as to recent dimensionality-reduction-based methods for localization and mapping (Shang et al., 2003; Biggs et al., 2005; Ferris et al., 2007; Yairi, 2007).", "startOffset": 225, "endOffset": 299}, {"referenceID": 9, "context": "Our approach is also related to factorization-based structure from motion (Tomasi & Kanade, 1992; Triggs, 1996; Kanade & Morris, 1998), as well as to recent dimensionality-reduction-based methods for localization and mapping (Shang et al., 2003; Biggs et al., 2005; Ferris et al., 2007; Yairi, 2007).", "startOffset": 225, "endOffset": 299}, {"referenceID": 26, "context": "Our approach is also related to factorization-based structure from motion (Tomasi & Kanade, 1992; Triggs, 1996; Kanade & Morris, 1998), as well as to recent dimensionality-reduction-based methods for localization and mapping (Shang et al., 2003; Biggs et al., 2005; Ferris et al., 2007; Yairi, 2007).", "startOffset": 225, "endOffset": 299}, {"referenceID": 14, "context": "The standard probabilistic model for range-only localization (Kantor & Singh, 2002; Kurth et al., 2003) represents robot state by a vector st = [xt, yt, \u03b8t]; the robot\u2019s (nonlinear) motion and observation models are", "startOffset": 61, "endOffset": 103}, {"referenceID": 6, "context": "The resulting approach is called the ROP-EKF, and is shown to outperform the ordinary (Cartesian) EKF in several real-world problems, especially in combination with multiple-hypothesis tracking (Djugash & Singh, 2008; Djugash, 2010).", "startOffset": 194, "endOffset": 232}, {"referenceID": 21, "context": "But, the inverse covariance is often approximately sparse, leading to much more efficient approximate computation (Thrun et al., 2005).", "startOffset": 114, "endOffset": 134}, {"referenceID": 10, "context": "Originally, subspace identification algorithms were almost exclusively used for linear system identification (Van Overschee & De Moor, 1996), but recently, similar spectral algorithms have been used to learn models of partially observable nonlinear dynamical systems such as HMMs (Hsu et al., 2009; Siddiqi et al., 2010) and PSRs (Rosencrantz et al.", "startOffset": 280, "endOffset": 320}, {"referenceID": 18, "context": "Originally, subspace identification algorithms were almost exclusively used for linear system identification (Van Overschee & De Moor, 1996), but recently, similar spectral algorithms have been used to learn models of partially observable nonlinear dynamical systems such as HMMs (Hsu et al., 2009; Siddiqi et al., 2010) and PSRs (Rosencrantz et al.", "startOffset": 280, "endOffset": 320}, {"referenceID": 16, "context": ", 2010) and PSRs (Rosencrantz et al., 2004; Boots et al., 2010; Boots & Gordon, 2010; Boots et al., 2011).", "startOffset": 17, "endOffset": 105}, {"referenceID": 3, "context": ", 2010) and PSRs (Rosencrantz et al., 2004; Boots et al., 2010; Boots & Gordon, 2010; Boots et al., 2011).", "startOffset": 17, "endOffset": 105}, {"referenceID": 2, "context": ", 2010) and PSRs (Rosencrantz et al., 2004; Boots et al., 2010; Boots & Gordon, 2010; Boots et al., 2011).", "startOffset": 17, "endOffset": 105}, {"referenceID": 17, "context": "For example, MDS has been used to determine a Euclidean map of sensor locations where there is no distinction between landmark positions and robot positions (Shang et al., 2003): instead all-toall range measurements are assumed for a set of landmarks.", "startOffset": 157, "endOffset": 177}, {"referenceID": 20, "context": "the geodesic distance between the landmarks (Tenenbaum et al., 2000; Shang et al., 2003).", "startOffset": 44, "endOffset": 88}, {"referenceID": 17, "context": "the geodesic distance between the landmarks (Tenenbaum et al., 2000; Shang et al., 2003).", "startOffset": 44, "endOffset": 88}, {"referenceID": 0, "context": "Such nonlinear dimensionality reduction has been used to learn maps of wi-fi networks and landmark locations when sensory data is thought to be nonlinearly related to the underlying Eucidean space in which the landmarks lie (Biggs et al., 2005; Ferris et al., 2007; Yairi, 2007).", "startOffset": 224, "endOffset": 278}, {"referenceID": 9, "context": "Such nonlinear dimensionality reduction has been used to learn maps of wi-fi networks and landmark locations when sensory data is thought to be nonlinearly related to the underlying Eucidean space in which the landmarks lie (Biggs et al., 2005; Ferris et al., 2007; Yairi, 2007).", "startOffset": 224, "endOffset": 278}, {"referenceID": 26, "context": "Such nonlinear dimensionality reduction has been used to learn maps of wi-fi networks and landmark locations when sensory data is thought to be nonlinearly related to the underlying Eucidean space in which the landmarks lie (Biggs et al., 2005; Ferris et al., 2007; Yairi, 2007).", "startOffset": 224, "endOffset": 278}, {"referenceID": 26, "context": "(In particular, (Yairi, 2007) suggests solving range-only mapping using nonlinear dimensionality reduction.", "startOffset": 16, "endOffset": 29}, {"referenceID": 4, "context": "The extension to online SLAM is straightforward: instead of first estimating \u0176 and then performing a SVD, we sequentially estimate our factors \u3008\u00db , \u039b\u0302, V\u0302 >\u3009 via online SVD (Brand, 2006; Boots et al., 2011).", "startOffset": 173, "endOffset": 206}, {"referenceID": 2, "context": "The extension to online SLAM is straightforward: instead of first estimating \u0176 and then performing a SVD, we sequentially estimate our factors \u3008\u00db , \u039b\u0302, V\u0302 >\u3009 via online SVD (Brand, 2006; Boots et al., 2011).", "startOffset": 173, "endOffset": 206}, {"referenceID": 6, "context": "We used two freely available range-only SLAM data sets collected from an autonomous lawn mowing robot (Djugash, 2010), shown in Fig.", "startOffset": 102, "endOffset": 117}, {"referenceID": 6, "context": "(Additional details on the experimental setup can be found in (Djugash, 2010).", "startOffset": 62, "endOffset": 77}, {"referenceID": 6, "context": "The ground truth paths have 2cm accuracy according to (Djugash, 2010).", "startOffset": 54, "endOffset": 69}, {"referenceID": 6, "context": "Next are several standard online range-only SLAM algorithms, summarized in (Djugash, 2010).", "startOffset": 75, "endOffset": 90}, {"referenceID": 15, "context": "These algorithms included the Cartesian EKF, FastSLAM (Montemerlo et al., 2002) with 5,000 particles, and the ROP-EKF (Djugash & Singh, 2008).", "startOffset": 54, "endOffset": 79}, {"referenceID": 13, "context": "We also compared to batch nonlinear optimization, via Gauss-Newton as implemented in Matlab\u2019s fminunc (see (Kehagias et al., 2006) for details).", "startOffset": 107, "endOffset": 130}, {"referenceID": 13, "context": "We followed the suggestions of (Kehagias et al., 2006) and initialized with the dead-reckoning estimate of the robot\u2019s path.", "startOffset": 31, "endOffset": 54}], "year": 2012, "abstractText": "We present a novel spectral learning algorithm for simultaneous localization and mapping (SLAM) from range data with known correspondences. This algorithm is an instance of a general spectral system identification framework, from which it inherits several desirable properties, including statistical consistency and no local optima. Compared with popular batch optimization or multiple-hypothesis tracking (MHT) methods for range-only SLAM, our spectral approach offers guaranteed low computational requirements and good tracking performance. Compared with popular extended Kalman filter (EKF) or extended information filter (EIF) approaches, and many MHT ones, our approach does not need to linearize a transition or measurement model; such linearizations can cause severe errors in EKFs and EIFs, and to a lesser extent MHT, particularly for the highly non-Gaussian posteriors encountered in range-only SLAM. We provide a theoretical analysis of our method, including finite-sample error bounds. Finally, we demonstrate on a real-world robotic SLAM problem that our algorithm is not only theoretically justified, but works well in practice: in a comparison of multiple methods, the lowest errors come from a combination of our algorithm with batch optimization, but our method alone produces nearly as good a result at far lower computational cost.", "creator": "LaTeX with hyperref package"}}}