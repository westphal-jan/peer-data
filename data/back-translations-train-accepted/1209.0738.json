{"id": "1209.0738", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2012", "title": "Sparse coding for multitask and transfer learning", "abstract": "We present an extension of sparse coding to the problems of multitask and transfer learning. The central assumption of the method is that the tasks parameters are well approximated by sparse linear combinations of the atoms of a dictionary on a high or infinite dimensional space. This assumption, together with the large quantity of available data in the multitask and transfer learning settings, allows a principled choice of the dictionary. We provide bounds on the generalization error of this approach, for both settings. Preliminary experiments indicate the advantage of the sparse multitask coding method over single task learning and a previous method based on orthogonal and dense representation of the tasks.", "histories": [["v1", "Tue, 4 Sep 2012 19:06:51 GMT  (54kb)", "https://arxiv.org/abs/1209.0738v1", "25 pages, 5 figures"], ["v2", "Sat, 23 Mar 2013 19:35:27 GMT  (66kb)", "http://arxiv.org/abs/1209.0738v2", null], ["v3", "Mon, 16 Jun 2014 15:06:48 GMT  (55kb)", "http://arxiv.org/abs/1209.0738v3", "International Conference on Machine Learning 2013"]], "COMMENTS": "25 pages, 5 figures", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["andreas maurer", "massimiliano pontil", "bernardino romera-paredes"], "accepted": true, "id": "1209.0738"}, "pdf": {"name": "1209.0738.pdf", "metadata": {"source": "META", "title": "Sparse coding for multitask and transfer learning", "authors": ["Andreas Maurer"], "emails": ["AM@ANDREAS-MAURER.EU", "M.PONTIL@CS.UCL.AC.UK", "BERNARDINO.PAREDES.09@UCL.AC.UK"], "sections": [{"heading": null, "text": "ar Xiv: 120 9.07 38v3 [cs.LG] 1 6"}, {"heading": "1. Introduction", "text": "In fact, it is so that we are able to assert ourselves in the world, that we are able to assert ourselves in the world, that we are able to assert ourselves in the world, and that we are able to assert ourselves in the world, that we are able to assert ourselves in the world, that we are in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world and in the world, in the world, in the world and in the world, in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the, in the world and in the world, in the world in the world, in the, in"}, {"heading": "2. Method", "text": "In this section we will turn to a technical description of the proposed method by introducing some necessary notations along the way. Let H have a finite or infinite dimensional Hilbert space with internal product < \u00b7 \u00b7 \u00b7 \u00b7, \u00b7, \u00b7, norm \u00b7, and fix an integer K. We will examine the problem in D-dimensional dictionaries (or simply dictionaries), which means that each D-DK is a linear map. D: RK \u2192 H, so that each of the canonical basic vectors ek of the RK. The number K can be considered as one of the regulation parameters of our method. \u2022 C\u03b1 is the set of code vectors that are satisfactory in RK."}, {"heading": "3. Learning bounds", "text": "In this section, we present learning limits for Method (1), both in the field of multitask learning and in the field of learning in learning situations, and discuss the specific case of sparse coding."}, {"heading": "3.1. Multitask learning", "text": "Let us compare this task resource risk with the minimal risk that we can take any risks. (< D) We interpret the probability of observing the input / output pair (x, y) in the context of the task. For each of these tasks, an i.i.d. training sample zt = (xti, yti): 1 \u2264 i \u2264 m) is pulled out (\u00b5t) m and the ensemble Z \u0445 Tt = 1 \u00b5mt is fed into the algorithm (1). After the return of a minimizing D (Z) and 1 (Z),.,., T (Z) we will use the prediorD (Z) on the task. The average over all tasks incurred by these predictors is is1TT (x, y)."}, {"heading": "3.2. Learning to learn", "text": "There is no absolute way to judge the quality of a learning algorithm. Algorithms can work well on one type of task, but badly on another kind. It is important that an algorithm works well on those tasks to which it is likely to be applied. To formalize this, Baxter (2000) introduces the probability of finding the concept of an environment that represents a probability mea-sure E on the set of tasks. Given is the transfer risk (or simply the risk) of a learning algorithm A defined as follows: We draw a task from environment E, and it is the probability of finding the pair (x, y) in the context of the task. Given is the transfer risk (or simply the risk) of a learning algorithm A, which is defined as follows. We draw a task from the environment that fixes a corresponding distribution mR. Then we draw a training sample and use the algorithm to calculate the predictor A (z)."}, {"heading": "3.3. Connection to sparse coding", "text": "We discuss a special case of Theorem 2 in the boundary m \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2."}, {"heading": "4. Experiments", "text": "In this section, we present experiments with one synthetic data set and two real data sets. The aim of the experiments is to examine the statistical performance of the proposed method from the point of view of both multitask learning and learning to learn. We compare our method, which is called Sparse Coding Multi Task Learning (SC-MTL), with Independent Gratregression (RR) as baseline and multitask feature learning (MTFL) (Argyriou, Evgeniou, Pontil, 2008) and GO-MTL (Kumar & Daume \u0301 III, 2012)."}, {"heading": "4.1. Optimization algorithm", "text": "We solve problem (1) by alternately minimizing the dictionary matrix D and the code vectors \u03b3. The techniques we use are very similar to the standard methods for sparse coding and dictionary learning, see e.g. (Jenatton et al., 2011) and references to them for more information. In short, assuming that the loss function is convex and has a continuous Lipschitz gradient, either the minimization problem is convex and can be efficiently solved by proximal gradient methods, see e.g. (Beck & Teboulle, 2009; Combettes & Wajs, 2006). The key ingredient in each step is the calculation of the proximity operator, which has a closed form expression in both problems."}, {"heading": "4.2. Toy experiment", "text": "We created a synthetic environment of the tasks as follows: < K = K matrix D by sampling their columns independently of the uniform distribution on the sphere of the unit in Rd. Once D is created, a generic problem is given in the environment by w = D\u03b3, where \u03b3 is an s-sparse vector determined as follows. First, we create a series of J {1,.., K} of cardinality tasks whose elements (indices) are uniformly without substitution from the set {1,.,., K}. We then use the vector j = 0 when J and other random tasks (0, 0.1). Finally, we normalize the tasks so that they are equal to any prescribed value. With the above method, we create T tasks wt = D.t, t = 1., T = Next, for each task we create a training environment zt = (xti, yti)."}, {"heading": "4.3. Learning to learn optical character recognition", "text": "We conducted experiments with real data to study the performance of our method in a learning / transfer situation. To this end, we used the NIST dataset 1, which consists of a set of 14 x 14 pixel images of handwritten characters (numbers and lowercase and uppercase letters, for a total of 52 characters). We looked at the following experimental protocol. First, a set of 20 characters is randomly selected, as well as n instances for each character. These are used to learn all the possibilities of 1-vs-1 move tasks, which is T = 190.1The NIST dataset is available at http: / / www.nist.gov / srd / nistsd19.cfmeach, of which m = 2n have instances. The knowledge learned at this stage is used to learn another set of objectives. In our approach, the assumption is that some of the components in the dictionary will be learned to represent the objectives."}, {"heading": "4.4. Sparse coding of images with missing pixels", "text": "In the last experiment, we look at a sparse coding problem (Olshausen & Field, 1996) of images with optical characters and missing pixels. In the following experiment, we use only the digits. We consider each image as a task, so the input space is the set of 320 possible pixel indexes, while the output space is the real interval [0, 1] representing the gray value. We sample T = 100, 130, 160, 190, 220, 250 images, evenly divided among the 10 possible digits. For each of these digits, a random set of m = 160 pixel values is sampled (so that the set of sample pixels varies2is available at http: / / www.cs.nyu.edu / roweis / data.html.from one image to another)."}, {"heading": "5. Summary", "text": "In this paper, we have examined an application of sparse encoding that is widespread in the field of unsupervised learning and signal processing. Our learning boundaries provide a justification for this method and provide insights into its advantage over independent learning and the dense representation of tasks through learning. The boundaries that exist in a Hilbert space depend on data-dependent variables that measure the intrinsic dimensionality of the data. Numerical simulations presented here suggest that sparse encoding is a promising approach to multitask learning and can lead to significant improvements over competing methods. In the future, it would be valuable to examine extensions of our analysis to more general classes of code vectors."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the EPSRC Grant EP / H027203 / 1 and the Royal Society International Joint Project Grant 2012 / R2."}, {"heading": "A. Notation and tools", "text": "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "B. Proofs", "text": "It is a direct consequence of Hoeffding's difference K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-K-"}, {"heading": "1\u2212 \u03b4 in the multisample Z \u223c \u03c1TE", "text": "& # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & # 160; p & 160; p & 160; p & 160; p & 160; p & 160; p & 160; p; p; p; p; p; 160; p; p & # 160; p; p; p & # 160; p; p; p & # 160; p; p & # 160; p; p & # 160; p; p & # 160; p & # 160; p; p & # 160; p; p; p; p & # 160; p; p; p; p; p; p; p; p; p; p; p; p & # 160; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; & # 160; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; 160; p; p; p; p; p; p; p; p; p; p; p; p; p; 160 & # 160; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; 160; p; p; p; p; p; p;"}], "references": [{"title": "A framework for learning predictive structures from multiple tasks and unlabeled data", "author": ["R.K. Ando", "T. Zhang"], "venue": "J. of Machine Learning Research,", "citeRegEx": "Ando and Zhang,? \\Q2005\\E", "shortCiteRegEx": "Ando and Zhang", "year": 2005}, {"title": "Convex multitask feature learning", "author": ["A. Argyriou", "T. Evgeniou", "M. Pontil"], "venue": "Machine Learning,", "citeRegEx": "Argyriou et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2008}, {"title": "An algorithm for transfer learning in a heterogeneous environment", "author": ["A. Argyriou", "A. Maurer", "M. Pontil"], "venue": "Proc. European Conf. Machine Learning,", "citeRegEx": "Argyriou et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2008}, {"title": "A model for inductive bias learning", "author": ["J. Baxter"], "venue": "J. of Artificial Intelligence Research,", "citeRegEx": "Baxter,? \\Q2000\\E", "shortCiteRegEx": "Baxter", "year": 2000}, {"title": "A fast iterative shrinkagethresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal of Imaging Sciences,", "citeRegEx": "Beck and Teboulle,? \\Q2009\\E", "shortCiteRegEx": "Beck and Teboulle", "year": 2009}, {"title": "Exploiting task relatedness for multiple task learning", "author": ["S. Ben-David", "R. Schuller"], "venue": "Proceedings of Computational Learning Theory (COLT),", "citeRegEx": "Ben.David and Schuller,? \\Q2003\\E", "shortCiteRegEx": "Ben.David and Schuller", "year": 2003}, {"title": "Statistics for HighDimensional Data: Methods, Theory and Applications", "author": ["P. B\u00fchlmann", "S. van de Geer"], "venue": null, "citeRegEx": "B\u00fchlmann and Geer,? \\Q2011\\E", "shortCiteRegEx": "B\u00fchlmann and Geer", "year": 2011}, {"title": "Multi-task learning", "author": ["R. Caruana"], "venue": "Machine Learning,", "citeRegEx": "Caruana,? \\Q1997\\E", "shortCiteRegEx": "Caruana", "year": 1997}, {"title": "Signal recovery by proximal forward-backward splitting", "author": ["P.L. Combettes", "V.R. Wajs"], "venue": "Multiscale Modeling and Simulation,", "citeRegEx": "Combettes and Wajs,? \\Q2006\\E", "shortCiteRegEx": "Combettes and Wajs", "year": 2006}, {"title": "Learning multiple tasks with kernel methods", "author": ["T. Evgeniou", "C.A. Micchelli", "M. Pontil"], "venue": "J. of Machine Learning Research,", "citeRegEx": "Evgeniou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Evgeniou et al\\.", "year": 2005}, {"title": "Proximal methods for hierarchical sparse coding", "author": ["R. Jenatton", "J. Mairal", "G. Obozinski", "F. Bach"], "venue": "J. of Machine Learning Research,", "citeRegEx": "Jenatton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jenatton et al\\.", "year": 2011}, {"title": "Empirical margin distributions and bounding the generalization error of combined classifiers", "author": ["V. Koltchinskii", "D. Panchenko"], "venue": "Annals of Statistics,", "citeRegEx": "Koltchinskii and Panchenko,? \\Q2002\\E", "shortCiteRegEx": "Koltchinskii and Panchenko", "year": 2002}, {"title": "Learning task grouping and overlap in multitask learning", "author": ["A. Kumar", "H. Daum\u00e9 III"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "Kumar and III,? \\Q2012\\E", "shortCiteRegEx": "Kumar and III", "year": 2012}, {"title": "Oracle inequalities and optimal inference under group sparsity", "author": ["K. Lounici", "M. Pontil", "A.B. Tsybakov", "S. van de Geer"], "venue": "Annals of Statistics,", "citeRegEx": "Lounici et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lounici et al\\.", "year": 2011}, {"title": "Concentration inequalities for functions of independent variables", "author": ["A. Maurer"], "venue": "Random Structures and Algorithms,", "citeRegEx": "Maurer,? \\Q2006\\E", "shortCiteRegEx": "Maurer", "year": 2006}, {"title": "Transfer bounds for linear feature learning", "author": ["A. Maurer"], "venue": "Machine Learning,", "citeRegEx": "Maurer,? \\Q2009\\E", "shortCiteRegEx": "Maurer", "year": 2009}, {"title": "K-dimensional coding schemes in Hilbert spaces", "author": ["A. Maurer", "M. Pontil"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Maurer and Pontil,? \\Q2010\\E", "shortCiteRegEx": "Maurer and Pontil", "year": 2010}, {"title": "Probabilistic Methods of Algorithmic Discrete Mathematics", "author": ["C. McDiarmid"], "venue": null, "citeRegEx": "McDiarmid,? \\Q1998\\E", "shortCiteRegEx": "McDiarmid", "year": 1998}, {"title": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images", "author": ["B.A. Olshausen", "D.J. Field"], "venue": null, "citeRegEx": "Olshausen and Field,? \\Q1996\\E", "shortCiteRegEx": "Olshausen and Field", "year": 1996}, {"title": "The one-sided barrier problem for gaussian noise", "author": ["D. Slepian"], "venue": "Bell System Tech. J.,", "citeRegEx": "Slepian,? \\Q1962\\E", "shortCiteRegEx": "Slepian", "year": 1962}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "J. R. Statist. Soc. B,", "citeRegEx": "Tibshirani,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani", "year": 1996}], "referenceMentions": [{"referenceID": 20, "context": "A central development in this respect is the Lasso (Tibshirani, 1996), which estimates a linear predictor in a high dimensional space under a regularizing l1-penalty.", "startOffset": 51, "endOffset": 69}, {"referenceID": 7, "context": "Our work combines ideas from sparse coding (Olshausen & Field, 1996), multitask learning (Ando & Zhang, 2005; Argyriou, Evgeniou, Pontil, 2008; Argyriou, Maurer, Pontil, 2008; Ben-David & Schuller, 2003; Caruana, 1997; Evgeniou, Micchelli, Pontil, 2005; Maurer, 2009) and learning to learn (Baxter, 2000; Thrun & Pratt, 1998).", "startOffset": 89, "endOffset": 267}, {"referenceID": 15, "context": "Our work combines ideas from sparse coding (Olshausen & Field, 1996), multitask learning (Ando & Zhang, 2005; Argyriou, Evgeniou, Pontil, 2008; Argyriou, Maurer, Pontil, 2008; Ben-David & Schuller, 2003; Caruana, 1997; Evgeniou, Micchelli, Pontil, 2005; Maurer, 2009) and learning to learn (Baxter, 2000; Thrun & Pratt, 1998).", "startOffset": 89, "endOffset": 267}, {"referenceID": 3, "context": "Our work combines ideas from sparse coding (Olshausen & Field, 1996), multitask learning (Ando & Zhang, 2005; Argyriou, Evgeniou, Pontil, 2008; Argyriou, Maurer, Pontil, 2008; Ben-David & Schuller, 2003; Caruana, 1997; Evgeniou, Micchelli, Pontil, 2005; Maurer, 2009) and learning to learn (Baxter, 2000; Thrun & Pratt, 1998).", "startOffset": 290, "endOffset": 325}, {"referenceID": 15, "context": "The precursors of the analysis presented here are (Maurer & Pontil, 2010) and (Maurer, 2009).", "startOffset": 78, "endOffset": 92}, {"referenceID": 3, "context": "Our work combines ideas from sparse coding (Olshausen & Field, 1996), multitask learning (Ando & Zhang, 2005; Argyriou, Evgeniou, Pontil, 2008; Argyriou, Maurer, Pontil, 2008; Ben-David & Schuller, 2003; Caruana, 1997; Evgeniou, Micchelli, Pontil, 2005; Maurer, 2009) and learning to learn (Baxter, 2000; Thrun & Pratt, 1998). There is a vast literature on these subjects and the list of papers provided here is necessarily incomplete. Learning to learn (also called inductive bias learning or transfer learning) has been proposed by Baxter (2000) and an error analysis is provided therein, showing that a common representation which performs well on the training tasks will also generalize to new tasks obtained from the same \u201cenvironment\u201d.", "startOffset": 291, "endOffset": 548}, {"referenceID": 3, "context": "To formalize this, Baxter (2000) introduced the notion of an environment, which is a probability mea-", "startOffset": 19, "endOffset": 33}, {"referenceID": 15, "context": "2 of the supplementary appendix and follows the method outlined in (Maurer, 2009): one first bounds the estimation error for the expected empirical risk on future tasks, and then combines this with a bound of the expected true risk by said expected empirical risk.", "startOffset": 67, "endOffset": 81}, {"referenceID": 10, "context": "(Jenatton et al., 2011) and references therein for more information.", "startOffset": 0, "endOffset": 23}, {"referenceID": 10, "context": "(Jenatton et al., 2011; Lounici et al., 2011) or other families of regularizers.", "startOffset": 0, "endOffset": 45}, {"referenceID": 13, "context": "(Jenatton et al., 2011; Lounici et al., 2011) or other families of regularizers.", "startOffset": 0, "endOffset": 45}, {"referenceID": 17, "context": "The concentration inequality in part (i) of the following theorem, known as the bounded difference inequality is given in (McDiarmid, 1998).", "startOffset": 122, "endOffset": 139}, {"referenceID": 14, "context": "A proof of inequality (ii) is given in (Maurer, 2006).", "startOffset": 39, "endOffset": 53}, {"referenceID": 19, "context": "The next result is known as Slepian\u2019s lemma ((Slepian, 1962), (Ledoux & Talagrand, 1991)).", "startOffset": 45, "endOffset": 60}], "year": 2014, "abstractText": "We investigate the use of sparse coding and dictionary learning in the context of multitask and transfer learning. The central assumption of our learning method is that the tasks parameters are well approximated by sparse linear combinations of the atoms of a dictionary on a high or infinite dimensional space. This assumption, together with the large quantity of available data in the multitask and transfer learning settings, allows a principled choice of the dictionary. We provide bounds on the generalization error of this approach, for both settings. Numerical experiments on one synthetic and two real datasets show the advantage of our method over single task learning, a previous method based on orthogonal and dense representation of the tasks and a related method learning task grouping.", "creator": "LaTeX with hyperref package"}}}