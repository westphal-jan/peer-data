{"id": "1209.2434", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Sep-2012", "title": "Query Complexity of Derivative-Free Optimization", "abstract": "This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same.", "histories": [["v1", "Tue, 11 Sep 2012 20:37:02 GMT  (21kb)", "http://arxiv.org/abs/1209.2434v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["kevin g jamieson", "robert d nowak", "benjamin recht"], "accepted": true, "id": "1209.2434"}, "pdf": {"name": "1209.2434.pdf", "metadata": {"source": "CRF", "title": "Query Complexity of Derivative-Free Optimization", "authors": ["Kevin G. Jamieson"], "emails": ["kgjamieson@wisc.edu", "nowak@engr.wisc.edu", "brecht@cs.wisc.edu"], "sections": [{"heading": null, "text": "ar Xiv: 120 9.24 34v1 [st at.M L] 11 September 20This paper shows a fundamental and inevitable gap between the performance of algorithms with access to gradients and those with access to pure function evaluations. However, there are situations where DFO is inevitable, and for such situations we propose a new DFO algorithm that proves to be nearly optimal for the class of strongly convex lens functions. A characteristic feature of the algorithm is that it uses only Boolean function comparisons instead of function evaluations, which makes the algorithm useful for an even wider range of applications, such as optimizations based on pair comparisons with human subjects. We also show that regardless of whether DFO is based on low-noise function evaluations or Boolean function comparisons, the convergence rate is the same."}, {"heading": "1 Introduction", "text": "Optimizing large complex systems often requires the matching of many parameters. Moreover, training data or simulations can be used to estimate the relative value or loss of different parameter settings, but it may be unclear how each parameter affects the overall objective function. In such cases, derivatives of the objective function are not available with respect to the parameters. Thus, we have seen a resurgence of interest in derivative free optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8]. When function evaluations are noiseless, DFO methods can achieve the same convergence rates as noiseless gradient methods up to a small factor that depends on a lower value. This leads to the question of whether the same equivalence can be extended to the case where function evaluations and gradients noisy.Sadly, this paper proves the opposite."}, {"heading": "2 Problem formulation and background", "text": "(1) A function f is strongly convex with constant procedures (1). (2) A function f is strongly convex with constant procedures (2). (2) A constant f (1). (2). (2). (3). (3). (3). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (4). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5). (5. (5). (5). (5). (5). (5). (5. (5). (5). (5). (5.). (5.). (5.)."}, {"heading": "3 Main results", "text": "The following results are presented with simplifying constants that include many factors that are helpful in exposure. Explicit constants are given in the evidence in sections 4 and 5. Everywhere we refer to the minimizer of f as x \u0445 f. Expectations within the limits relate to noise in oracle queries and (possible) random optimization of the algorithm."}, {"heading": "3.1 Query complexity of the function comparison oracle", "text": "Theorem 1: For each f-F-1, L, B we let Cf be a function comparison oracle with parameters, then for n \u2265 8 and sufficiently large tinf x-T-1, L, BE [f (x-T) \u2212 f (x-T) \u2212 f (x-f)] \u2265 c1 exp {\u2212 c2 Tn} if \u0432 = 1c3 (n T) 1 2 (\u0445 -1) if \u0432 > 1where the infimum is above the collection of all possible estimators of x-f, where at most T queries for a function comparison oracle are used and the supremum is taken with parameters in relation to all problems in F, L, B and function comparison oracle. The constants c1, c2, c3 depend on the oracle and the function class parameters, as well as the geometry of B, but are independent of T and n.For the upper limits we propose a specific algorithm based on a function based on a coordination of T that follows x."}, {"heading": "3.2 Query complexity of the function evaluation oracle", "text": "F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & # 160; F & 160; F & # 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F & 160; F &"}, {"heading": "4 Lower Bounds", "text": "The lower limit in theorems 1 and 3 is demonstrated by a general minimax limit (20, Thm. 2.5). Our results relate most to the approach developed in [21] for active learning, which, like optimization, involves a \"simpler\" one than the original one. In this case, the lower limit is set by considering a simple case study of the optimization problem in which the global minimum is required for a limited number of queries. The following theory is used to prove the terms of the theorems, f is a function that can be minimized, and Pf is the probability model that associates noise when f assumes the true function. Theorem 4. [20, Thm. 2.5] Consider a class of functions and a related family of probabilities."}, {"heading": "4.1 Proof of Theorem 1", "text": "First, we will reach the limit in case there is satisfaction. (...) Let's leave the comparative oracle (Cfi (x, y) = character {fi (y) \u2212 fi (y)} = 12 + min {fi (y) \u2212 fi (x). In words, Cfi (x, y) is likely to be as large as the right side from above and is monotonously increasing in fi (y) \u2212 fi (x). Let's leave the sequence {xk, yk} Tk = 1 sequence of T pairs in B and let {Cfi (xk, yk)} Tk = 1 sequence of noisy comparisons. Let's allow the sequence {xk} Tk = 1 to be generated in any way that is subject to the Markovian assumption that Cfi (xk, yk) is given (xk, yk)."}, {"heading": "4.2 Proof of Theorem 1 for \u03ba = 1", "text": "s be a positive integer and let M = economin. Let Mi = 1 be a series of uniform spatial points in B, which we define as a unit cube in Rn, so that we have f (fi, fj) for all i 6 = j. Define fi (x): = \u03c4 2 | | x \u2212 \u0448i | | 2, i = 1,.., Let s: = 12so that d (fi, fj): = | x \u0445 i \u2212 x \u0445 j | | | 2s. Because we have p (Cfi (x, y) = character {fi (y) \u2212 fi (x)},. Let s: = 12\u00ba, so that d (fi, fj): = 12\u00ba, all i (fi, fj): = 1,."}, {"heading": "4.3 Proof of Theorem 3", "text": "Remember that the evaluation oracle is defined as Ef (x): = f (x) + w, where w is a random variable (independent of all other eligible random variables), where E [w] = 0 and E [w2] = \u03c32 > 0. Let Pi, the common probability distribution of {xk, Efi (xk)} Tk = 1 indicate the corresponding order of the loud evaluations of f [w2] F (....) T, Pi, the common probability distribution of {xk, Efi (xk)} k = 1, let Qi, the conditional distribution of Efi (xk) indicate the conditional distribution of Efi (xk)."}, {"heading": "5 Upper bounds", "text": "The algorithm that reaches the upper limit by a pair-wise comparison oracle is a combination of standard techniques and methods from convex optimization and statistical learning literature. The algorithm is explained in detail in Appendix B and summarized as follows: For each iteration, the algorithm randomly selects a uniform coordinate from the n possible dimensions and then performs an approximate line search. By taking advantage of the fact that the function is strongly convex with Lipschitz gradients, standard arguments guarantee that the approximate line search will produce a sufficient decrease in the objective function value in expectation [23, Ch.9.3]. If the pair-wise comparison oracle has not made any errors, then the approximate line search will be achieved by a binary-search-like scheme, essentially a gold-cross-section line search algorithm [24]. However, if the answers from the oracle are only correct, we can make the same-line search safe by repeating the same literature until 25."}, {"heading": "5.1 Coordinate descent", "text": "Given a candidate solution xk by k \u2265 0 iterations, the algorithm defines a search direction dk = ei where i is uniformly selected from the possible n dimensions and ei is a vector of all zeros, except one in the ith coordinate. We note that while we only analyze the case where the search direction dk is a coordinate direction, an analysis with the same result can be uniformly selected from the unity sphere with dk. Given dk, a line search is then performed to find such a case that f (xk) \u2212 f (xk) \u2212 f (xk) is sufficiently small where xk + 1 = xk \u2212 kdk. In fact, as we will see in the next section, the line search for some input parameters of p > 0 guarantees that we will find an answer to such a solution where k (xk) \u2212 f (xk) -f (xk), we will find an optimal solution with xf (k)."}, {"heading": "5.2 Line search", "text": "This section is about keeping a function f (xk + \u03b1kdk) to a minimum. First, let's assume that the oracle does not make any mistakes for the function comparison; the line search works in such a way that we maintain a pair of boundary points where we have the boundary points \u03b1 +, \u03b1 \u2212 in a certain order. An initial series of boundary points \u03b1 + > 0 and \u03b1 \u2212 < 0 are then found in the next order. So, regardless of how far away or close it is, we can guarantee that \u03b1 is still contained within the boundary points, but | \u03b1 + \u2212 \u03b1 12 | \u03b1 + \u2212 \u03b1 \u2212 |. An initial series of boundary points \u03b1 + > 0 and \u03b1 \u2212 < 0 are found by simple binary search. Regardless of how far or close it is, we converge exponentially quickly to it."}, {"heading": "5.3 Making the line search robust to errors", "text": "Now, we assume that the answers of the paired comparison oracle are only likely to be correct in accordance with the model presented above. Essentially, the robust procedure boils down to the line search, as if the oracle had not made any mistakes, except that each time a comparison is required, the oracle is repeatedly questioned until we can be sure of the true direction of the comparison. This strategy applied to active learning is well known for its simplicity and ability to adapt to unknown noise conditions. [25] However, we mention that when this sampling method is used in this way, it is known that it is suboptimal, so that in practice a more efficient approach such as that of [21] is sought to be implemented."}, {"heading": "6 Conclusion", "text": "This paper presented lower limits on the performance of derivative-free optimization for (i) an oracle that provides noisy function evaluations, and (ii) an oracle that probably provides correct Boolean comparisons between function evaluations. Our results were proven for the class of strongly convex functions, but since this class is a subset of all, possibly non-convex functions, our lower limits also apply to much larger classes. In both oracle models, we showed that the expected error decays as in both oracle models (n / T) 1 / 2. Furthermore, for the class of strongly convex functions with Lipschitz gradients, we proposed an algorithm that reaches a rate of O (n / T) 1 / 2, showing that the lower limits are narrow in terms of dependence on the number of iterations T and no more than a factor of n off in dimension.A number of open questions remain particularly when the comparison between the lower limits and the unfeasible conditions."}, {"heading": "A Bounds on (\u03ba, \u00b5, \u03b40) for some distributions", "text": "In this section, we refer the function determination oracle to the function comparison oracle for some common distributions. That is, if Ef (x) = f (x) + f (x) + w stands for a random variable w, we lower the probability \u03b7 (y, x): = P (sign {Ef (y) \u2212 Ef (x) = sign {f (y) \u2212 f (x)} in relation to the parameterization of (1).Lemma 3. Let us use a Gaussian random variable with an average zero and variance \u03c32. Then we perceive (y) true, (x) true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true."}, {"heading": "B Upper Bounds - Extended", "text": "The algorithm that reaches the top limit by using a pair-by-pair comparison oracle is a combination of a few standard techniques and methods derived from convex optimization and statistical learning literature. (The algorithms can be summarized as follows:) At each iteration, the algorithm selects a uniform coordinate from the n possible dimensions and then performs an approximate line search. (The approximate line search makes a sufficient decrease in the objective function in expectation [23, Ch.9.3]. If the pair-by-pair comparison does not make any errors, then the approximate line search is performed by a binary search scheme known in literature as the golden line search.) However, if the answers from the oracle are only likely correct, we do the line search by repeating the same query until we can be sure that the true comparison in the corrupt line search works."}], "references": [{"title": "Efficient optimization of support vector machine learning parameters for unbalanced datasets", "author": ["T. Eitrich", "B. Lang"], "venue": "Journal of computational and applied mathematics, 196(2):425\u2013436,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "A new derivative-free algorithm for the medical image registration problem", "author": ["R. Oeuvray", "M. Bierlaire"], "venue": "International Journal of Modelling and Simulation, 27(2):115\u2013124,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Introduction to derivative-free optimization, volume 8", "author": ["A.R. Conn", "K. Scheinberg", "L.N. Vicente"], "venue": "Society for Industrial Mathematics,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "Optimal Learning", "author": ["Warren B. Powell", "Ilya O. Ryzhov"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Random gradient-free minimization of convex functions", "author": ["Y. Nesterov"], "venue": "CORE Discussion Papers,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S.M. Kakade", "M. Seeger"], "venue": "Arxiv preprint arXiv:0912.3995,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2009}, {"title": "Differential evolution\u2013a simple and efficient heuristic for global optimization over continuous spaces", "author": ["R. Storn", "K. Price"], "venue": "Journal of global optimization, 11(4):341\u2013359,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1997}, {"title": "Stochastic convex optimization with bandit feedback", "author": ["A. Agarwal", "D.P. Foster", "D. Hsu", "S.M. Kakade", "A. Rakhlin"], "venue": "Arxiv preprint arXiv:1107.1744,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2011}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"], "venue": "SIAM Journal on Optimization, 19(4):1574,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2009}, {"title": "Algorithms for approximate calculation of the minimum of a convex function from its values", "author": ["V. Protasov"], "venue": "Mathematical Notes, 59:69\u201374,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1996}, {"title": "Information-based complexity, feedback, and dynamics in convex programming", "author": ["M. Raginsky", "A. Rakhlin"], "venue": "Information Theory, IEEE Transactions on, (99):1\u20131,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "A law of comparative judgment", "author": ["L.L. Thurstone"], "venue": "Psychological Review; Psychological Review, 34(4):273,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1927}, {"title": "The k-armed dueling bandits problem", "author": ["Y. Yue", "J. Broder", "R. Kleinberg", "T. Joachims"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Active ranking using pairwise comparisons", "author": ["K.G. Jamieson", "R.D. Nowak"], "venue": "Arxiv preprint arXiv:1109.3701,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Problem complexity and method efficiency in optimization", "author": ["A.S. Nemirovsky", "D.B. Yudin"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1983}, {"title": "Stochastic convex optimization with bandit feedback", "author": ["A. Agarwal", "D.P. Foster", "D. Hsu", "S.M. Kakade", "A. Rakhlin"], "venue": "Arxiv preprint arXiv:1107.1744,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Information-theoretic lower bounds on the oracle complexity of stochastic convex optimization", "author": ["A. Agarwal", "P.L. Bartlett", "P. Ravikumar", "M.J. Wainwright"], "venue": "Information Theory, IEEE Transactions on, (99):1\u20131,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2010}, {"title": "Optimal algorithms for online convex optimization with multi-point bandit feedback", "author": ["A. Agarwal", "O. Dekel", "L. Xiao"], "venue": "Conference on Learning Theory (COLT),", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Stochastic first-and zeroth-order methods for nonconvex stochastic programming", "author": ["S. Ghadimi", "G. Lan"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Introduction to nonparametric estimation", "author": ["A.B. Tsybakov"], "venue": "Springer Verlag,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2009}, {"title": "Minimax bounds for active learning", "author": ["R.M. Castro", "R.D. Nowak"], "venue": "Information Theory, IEEE Transactions on, 54(5):2339\u20132353,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Convex optimization", "author": ["S.P. Boyd", "L. Vandenberghe"], "venue": "Cambridge Univ Pr,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Algorithms for minimization without derivatives", "author": ["R.P. Brent"], "venue": "Dover Pubns,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2002}, {"title": "Active learning in the non-realizable case", "author": ["M. K\u00e4\u00e4ri\u00e4inen"], "venue": "Algorithmic Learning Theory, pages 63\u201377. Springer,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 1, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 2, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 3, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 4, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 5, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 6, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 7, "context": "Thus, we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1, 2, 3, 4, 5, 6, 7, 8].", "startOffset": 82, "endOffset": 106}, {"referenceID": 8, "context": "When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension [9, 5, 10].", "startOffset": 199, "endOffset": 209}, {"referenceID": 4, "context": "When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension [9, 5, 10].", "startOffset": 199, "endOffset": 209}, {"referenceID": 9, "context": "When function evaluations are noiseless, DFO methods can achieve the same rates of convergence as noiseless gradient methods up to a small factor depending on a low-order polynomial of the dimension [9, 5, 10].", "startOffset": 199, "endOffset": 209}, {"referenceID": 8, "context": "In contrast, noisy gradient methods exhibit \u0398(1/T ) error scaling for strongly convex functions [9, 11].", "startOffset": 96, "endOffset": 103}, {"referenceID": 10, "context": "In contrast, noisy gradient methods exhibit \u0398(1/T ) error scaling for strongly convex functions [9, 11].", "startOffset": 96, "endOffset": 103}, {"referenceID": 11, "context": "In fact, this choice of w corresponds to Thurston\u2019s law of comparative judgment which is a popular model for outcomes of pairwise comparisons from human subjects [12].", "startOffset": 162, "endOffset": 166}, {"referenceID": 6, "context": "[7]) and by optimization problems involving human subjects making paired comparisons (for instance, getting fitted for prescription lenses or a hearing aid where unknown parameters specific to each person are tuned with the familiar queries \u201cbetter or worse?\u201d).", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "Pairwise comparisons have also been suggested as a novel way to tune web-search algorithms [13].", "startOffset": 91, "endOffset": 95}, {"referenceID": 12, "context": "Pairwise comparison strategies have previously been analyzed in the finite setting where the task is to identify the best alternative among a finite set of alternatives (sometimes referred to as the dueling-bandit problem) [13, 14].", "startOffset": 223, "endOffset": 231}, {"referenceID": 13, "context": "Pairwise comparison strategies have previously been analyzed in the finite setting where the task is to identify the best alternative among a finite set of alternatives (sometimes referred to as the dueling-bandit problem) [13, 14].", "startOffset": 223, "endOffset": 231}, {"referenceID": 14, "context": "While there are known theoretical results for DFO in the noiseless setting [15, 5, 10], to the best of our knowledge we are the first to characterize lower bounds for DFO in the stochastic setting.", "startOffset": 75, "endOffset": 86}, {"referenceID": 4, "context": "While there are known theoretical results for DFO in the noiseless setting [15, 5, 10], to the best of our knowledge we are the first to characterize lower bounds for DFO in the stochastic setting.", "startOffset": 75, "endOffset": 86}, {"referenceID": 9, "context": "While there are known theoretical results for DFO in the noiseless setting [15, 5, 10], to the best of our knowledge we are the first to characterize lower bounds for DFO in the stochastic setting.", "startOffset": 75, "endOffset": 86}, {"referenceID": 14, "context": "However, there are algorithms with upper bounds on the rates of convergence for stochastic DFO with the function evaluation oracle [15, 16].", "startOffset": 131, "endOffset": 139}, {"referenceID": 15, "context": "However, there are algorithms with upper bounds on the rates of convergence for stochastic DFO with the function evaluation oracle [15, 16].", "startOffset": 131, "endOffset": 139}, {"referenceID": 14, "context": "While there remains many open problems in stochastic DFO (see Section 6), rates of convergence with a stochastic gradient oracle are well known and were first lower bounded by Nemirovski and Yudin [15].", "startOffset": 197, "endOffset": 201}, {"referenceID": 16, "context": "These classic results were recently tightened to show a dependence on the dimension of the problem [17].", "startOffset": 99, "endOffset": 103}, {"referenceID": 10, "context": "And then tightened again to show a better dependence on the noise [11] which matches the upper bound achieved by stochastic gradient descent [9].", "startOffset": 66, "endOffset": 70}, {"referenceID": 8, "context": "And then tightened again to show a better dependence on the noise [11] which matches the upper bound achieved by stochastic gradient descent [9].", "startOffset": 141, "endOffset": 144}, {"referenceID": 10, "context": "Our bounds are based on simple techniques borrowed from the statistical learning literature that use natural functions and oracles in the same spirit of [11].", "startOffset": 153, "endOffset": 157}, {"referenceID": 14, "context": "Alternatively, under a less restrictive setting, Nemirovski and Yudin proposed two algorithms for the class of convex, Lipschitz functions that obtain rates of n/T 1/4 and p(n)/T , respectively, where p(n) was left as an unspecified polynomial of n [15].", "startOffset": 249, "endOffset": 253}, {"referenceID": 14, "context": "built on the ideas developed in [15] to obtain a result that they point out implies a convergence rate of n/T 1/2 in the optimization setting considered here [16].", "startOffset": 32, "endOffset": 36}, {"referenceID": 15, "context": "built on the ideas developed in [15] to obtain a result that they point out implies a convergence rate of n/T 1/2 in the optimization setting considered here [16].", "startOffset": 158, "endOffset": 162}, {"referenceID": 17, "context": "A related but fundamentally different problem that is somewhat related with the setting considered in this paper is described as online (or stochastic) convex optimization with multi-point feedback [18, 5, 19].", "startOffset": 198, "endOffset": 209}, {"referenceID": 4, "context": "A related but fundamentally different problem that is somewhat related with the setting considered in this paper is described as online (or stochastic) convex optimization with multi-point feedback [18, 5, 19].", "startOffset": 198, "endOffset": 209}, {"referenceID": 18, "context": "A related but fundamentally different problem that is somewhat related with the setting considered in this paper is described as online (or stochastic) convex optimization with multi-point feedback [18, 5, 19].", "startOffset": 198, "endOffset": 209}, {"referenceID": 20, "context": "Our proofs are most related to the approach developed in [21] for active learning, which like optimization involves a Markovian sampling process.", "startOffset": 57, "endOffset": 61}, {"referenceID": 22, "context": "If the pairwise comparison oracle made no errors then the approximate line search is accomplished by a binary-search-like scheme, essentially a golden section line-search algorithm [24].", "startOffset": 181, "endOffset": 185}, {"referenceID": 23, "context": "However, when responses from the oracle are only probably correct we make the line-search robust to errors by repeating the same query until we can be confident about the true, uncorrupted direction of the pairwise comparison using a standard procedure from the active learning literature [25] (a similar technique was also implemented for the bandit setting of derivate-free optimization [8]).", "startOffset": 289, "endOffset": 293}, {"referenceID": 7, "context": "However, when responses from the oracle are only probably correct we make the line-search robust to errors by repeating the same query until we can be confident about the true, uncorrupted direction of the pairwise comparison using a standard procedure from the active learning literature [25] (a similar technique was also implemented for the bandit setting of derivate-free optimization [8]).", "startOffset": 389, "endOffset": 392}, {"referenceID": 23, "context": "This strategy applied to active learning is well known because of its simplicity and its ability to adapt to unknown noise conditions [25].", "startOffset": 134, "endOffset": 138}, {"referenceID": 20, "context": "However, we mention that when used in this way, this sampling procedure is known to be sub-optimal so in practice, one may want to implement a more efficient approach like that of [21].", "startOffset": 180, "endOffset": 184}, {"referenceID": 23, "context": "[25] For any x, y \u2208 B with P (Cf (x, y) = sign{f(y)\u2212 f(x)}) = p, with probability at least 1 \u2212 \u03b4 the coin-tossing algorithm of [25] correctly identifies the sign of E [Cf (x, y)] and requests no more than log(2/\u03b4) 4|1/2\u2212p|2 log2 ( log(2/\u03b4) 4|1/2\u2212p|2 ) pairwise comparisons.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[25] For any x, y \u2208 B with P (Cf (x, y) = sign{f(y)\u2212 f(x)}) = p, with probability at least 1 \u2212 \u03b4 the coin-tossing algorithm of [25] correctly identifies the sign of E [Cf (x, y)] and requests no more than log(2/\u03b4) 4|1/2\u2212p|2 log2 ( log(2/\u03b4) 4|1/2\u2212p|2 ) pairwise comparisons.", "startOffset": 127, "endOffset": 131}], "year": 2012, "abstractText": "This paper provides lower bounds on the convergence rate of Derivative Free Optimization (DFO) with noisy function evaluations, exposing a fundamental and unavoidable gap between the performance of algorithms with access to gradients and those with access to only function evaluations. However, there are situations in which DFO is unavoidable, and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions. A distinctive feature of the algorithm is that it uses only Boolean-valued function comparisons, rather than function evaluations. This makes the algorithm useful in an even wider range of applications, such as optimization based on paired comparisons from human subjects, for example. We also show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons, the convergence rate is the same.", "creator": "LaTeX with hyperref package"}}}