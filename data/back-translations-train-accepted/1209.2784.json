{"id": "1209.2784", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Sep-2012", "title": "Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL", "abstract": "Since its inception, the modus operandi of multi-task learning (MTL) has been to minimize the task-wise mean of the empirical risks. We introduce a generalized loss-compositional paradigm for MTL that includes a spectrum of formulations as a subfamily. One endpoint of this spectrum is minimax MTL: a new MTL formulation that minimizes the maximum of the tasks' empirical risks. Via a certain relaxation of minimax MTL, we obtain a continuum of MTL formulations spanning minimax MTL and classical MTL. The full paradigm itself is loss-compositional, operating on the vector of empirical risks. It incorporates minimax MTL, its relaxations, and many new MTL formulations as special cases. We show theoretically that minimax MTL tends to avoid worst case outcomes on newly drawn test tasks in the learning to learn (LTL) test setting. The results of several MTL formulations on synthetic and real problems in the MTL and LTL test settings are encouraging.", "histories": [["v1", "Thu, 13 Sep 2012 06:14:31 GMT  (53kb,D)", "http://arxiv.org/abs/1209.2784v1", "appearing at NIPS 2012"]], "COMMENTS": "appearing at NIPS 2012", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["nishant a mehta", "dongryeol lee", "alexander g gray"], "accepted": true, "id": "1209.2784"}, "pdf": {"name": "1209.2784.pdf", "metadata": {"source": "CRF", "title": "Minimax Multi-Task Learning and a Generalized Loss-Compositional Paradigm for MTL", "authors": ["Nishant A. Mehta", "Dongryeol Lee", "Alexander G. Gray"], "emails": ["niche@cc.gatech.edu,", "drselee@gmail.com,", "agray@cc.gatech.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "2 Minimax multi-task learning", "text": "We start with a walk through the basic MTL and LTL setups, with an effort to stick to the notation introduced by Baxter [4]. While the rest of the paper will live each labeled example (x, y) in X \u00b7 Y for the input instance x and label y. Typical decisions of X include Rn or a compact subset thereof, while Y is typically a compact subset of R or the binary distribution. In addition, a loss function is defined: R \u00d7 Y \u2192 R +. For simplicity, this work considers \"2 loss (y \u2032, y) 2 for regression and add loss\" (y \u2032)."}, {"heading": "2.1 Minimax MTL", "text": "A natural generalization of the classical MTL results from the introduction of a prior distribution \u03c0 over the index set of tasks [T]. In view of the (idealized) goal of this generalized MTL, the (idealized) goal is only the training data {(xt, 1, yt, 1),.., (xt, m, yt, m). The classical MTL goal (2) corresponds to (3), assuming that the results before [T] are uniform. We argue that in many cases that are most relevant to minimization, the expected error is not among a uniform distribution of tasks or even some predetermined distribution of tasks, but rather the expected error for the worst tasks (3). We propose to minimize the maximum error over the tasks that is most relevant to minimization, not the expected error under a uniform distribution of tasks, or even just any predetermined error, but the expected error for the worst tasks (3)."}, {"heading": "2.2 A learning to learn bound for the maximum risk", "text": "In this subsection, we use the following notation. Let P (1),., P (T) be true risk measures iid from Q, and for t [T] let z (t) be an m-sample (a sample of m points) from P (t) with corresponding empirical measure P (t) m. Even if P's as a probability measure then P'amp # 160; h (y, h (x))); similarly, if Pm'p is an empirical measure, then Pm'p: = 1m m i = 1 '(yi, h (xi)).Our focus is on learning to learn attitude with a minimax lens: If you learn a representation of H from multiple training tasks and observe maximum empirical risk, we would like to guarantee the true risks of thatH's on a newly drawn test task."}, {"heading": "3 A generalized loss-compositional paradigm for MTL", "text": "The paradigma may benefit from a bit of notation (H, h), where (H, h) a number of T-questions (H, h) can be posed. (H, h) A number of risk factors (H, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h,"}, {"heading": "4 Empirical evaluation", "text": "We look at four learning problems; the first three include regression (MTL model in brackets): \u2022 A synthetic data set consisting of two types of tasks (EP model), \u2022 The school records of the Inner London Education Authority (EP model), \u2022 The conjoint analysis Personal Computer Rating Dataset 2 [11] (AEP model). The fourth problem is the multi-class classification of tasks from the MNIST digits dataset [10] with a reduction to multi-task learning using a pair of (binary) classifiers. We use the AEP model. Given the data, each problem concerned a selection of MTL formulations (e.g. minimax MTL digits dataset), model (EP or AEP), and choice of regulated versus restricted solutions. All problems were solved with just a few lines of code using CVX [9, 8]."}, {"heading": "5 Discussion", "text": "Between these extremes lies a continuum of relaxed Minimax MTL formulations. More broadly, we introduced a losscompositional paradigm based on the vector of empirical risk that induces the additional \"p-MTL paradigm.\" Empirical evaluations suggest that \u03b1-minimax-MTL often exceeds \"1 MTL\" in terms of the maximum test risk target and sometimes even the mean test risk target when learning with a model that is very complex relative to the available data. Although efficient algorithms can make the various new MTL learning formulations practical for major problems, an appropriate effort to develop fast algorithms in this setting, beyond the main focus of this general study, would result in MTL learning algorithms being more effective for future miniformats."}], "references": [{"title": "Convex multi-task feature learning", "author": ["A. Argyriou", "T. Evgeniou", "M. Pontil"], "venue": "Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Task clustering and gating for bayesian multitask learning", "author": ["B. Bakker", "T. Heskes"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Rademacher and Gaussian complexities: Risk bounds and structural results", "author": ["Peter L. Bartlett", "Shahar Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "A model of inductive bias learning", "author": ["J. Baxter"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2000}, {"title": "Regularized multi\u2013task learning", "author": ["T. Evgeniou", "M. Pontil"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "A convex optimization approach to modeling consumer heterogeneity in conjoint estimation", "author": ["T. Evgeniou", "M. Pontil", "O. Toubia"], "venue": "Marketing Science,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Multilevel modelling of survey data", "author": ["H. Goldstein"], "venue": "Journal of the Royal Statistical Society. Series D (The Statistician),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1991}, {"title": "Graph implementations for nonsmooth convex programs", "author": ["M. Grant", "S. Boyd"], "venue": "Recent Advances in Learning and Control, Lecture Notes in Control and Information Sciences,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "CVX: Matlab software for disciplined convex programming, version 1.21", "author": ["M. Grant", "S. Boyd"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "Hierarchical bayes conjoint analysis: Recovery of partworth heterogeneity from reduced experimental designs", "author": ["P.J. Lenk", "W.S. DeSarbo", "P.E. Green", "M.R. Young"], "venue": "Marketing Science,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1996}, {"title": "Transfer bounds for linear feature learning", "author": ["A. Maurer"], "venue": "Machine learning,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Statistical analysis of learning dynamics", "author": ["N. Murata", "S. Amari"], "venue": "Signal Processing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1999}, {"title": "Topmoumoute online natural gradient algorithm", "author": ["Nicolas Le Roux", "Pierre-Antoine Manzagol", "Yoshua Bengio"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2008}, {"title": "Large-scale collaborative prediction using a nonparametric random effects model", "author": ["K. Yu", "J. Lafferty", "S. Zhu", "Y. Gong"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Generalizing matrix factorization through flexible regression priors", "author": ["L. Zhang", "D. Agarwal", "B.C. Chen"], "venue": "In Proceedings of the fifth ACM conference on Recommender systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}], "referenceMentions": [{"referenceID": 14, "context": "MTL is incredibly pervasive in machine learning: it has natural connections to random effects models [15]; user preference prediction (including collaborative filtering) can be framed as MTL [16]; multi-class classification admits the popular one-vs-all and all-pairs MTL reductions; and MTL admits provably good learning in settings where single-task learning is hopeless [4, 12].", "startOffset": 101, "endOffset": 105}, {"referenceID": 15, "context": "MTL is incredibly pervasive in machine learning: it has natural connections to random effects models [15]; user preference prediction (including collaborative filtering) can be framed as MTL [16]; multi-class classification admits the popular one-vs-all and all-pairs MTL reductions; and MTL admits provably good learning in settings where single-task learning is hopeless [4, 12].", "startOffset": 191, "endOffset": 195}, {"referenceID": 3, "context": "MTL is incredibly pervasive in machine learning: it has natural connections to random effects models [15]; user preference prediction (including collaborative filtering) can be framed as MTL [16]; multi-class classification admits the popular one-vs-all and all-pairs MTL reductions; and MTL admits provably good learning in settings where single-task learning is hopeless [4, 12].", "startOffset": 373, "endOffset": 380}, {"referenceID": 11, "context": "MTL is incredibly pervasive in machine learning: it has natural connections to random effects models [15]; user preference prediction (including collaborative filtering) can be framed as MTL [16]; multi-class classification admits the popular one-vs-all and all-pairs MTL reductions; and MTL admits provably good learning in settings where single-task learning is hopeless [4, 12].", "startOffset": 373, "endOffset": 380}, {"referenceID": 3, "context": "We begin with a promenade through the basic MTL and LTL setups, with an effort to abide by the notation introduced by Baxter [4].", "startOffset": 125, "endOffset": 128}, {"referenceID": 2, "context": "[3]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "Then, from by now standard learning theory results of Bartlett and Mendelson [3]: Lemma 2.", "startOffset": 77, "endOffset": 80}, {"referenceID": 13, "context": "The contour of the `1-norm of the empirical risks evenly trades off empirical risks between different tasks; however, it has been observed that overfitting often happens near the end of learning, rather than the beginning [14].", "startOffset": 222, "endOffset": 226}, {"referenceID": 4, "context": "We consider two convex multi-task learning formulations: Evgeniou and Pontil\u2019s regularized multi-task learning (the EP model) [5] and Argyriou, Evgeniou, and Pontil\u2019s convex multi-task feature learning (the AEP model) [1].", "startOffset": 126, "endOffset": 129}, {"referenceID": 0, "context": "We consider two convex multi-task learning formulations: Evgeniou and Pontil\u2019s regularized multi-task learning (the EP model) [5] and Argyriou, Evgeniou, and Pontil\u2019s convex multi-task feature learning (the AEP model) [1].", "startOffset": 218, "endOffset": 221}, {"referenceID": 10, "context": "We consider four learning problems; the first three involve regression (MTL model in parentheses): \u2022 A synthetic dataset composed from two modes of tasks (EP model), \u2022 The school dataset from the Inner London Education Authority (EP model), \u2022 The conjoint analysis personal computer ratings dataset 2 [11] (AEP model).", "startOffset": 301, "endOffset": 305}, {"referenceID": 9, "context": "The fourth problem is multi-class classification from the MNIST digits dataset [10] with a reduction to multi-task learning using a tournament of pairwise (binary) classifiers.", "startOffset": 79, "endOffset": 83}, {"referenceID": 8, "context": "All the problems were solved using just a few lines of code using CVX [9, 8].", "startOffset": 70, "endOffset": 76}, {"referenceID": 7, "context": "All the problems were solved using just a few lines of code using CVX [9, 8].", "startOffset": 70, "endOffset": 76}, {"referenceID": 6, "context": "The school dataset has appeared in many previous works [7, 2, 6].", "startOffset": 55, "endOffset": 64}, {"referenceID": 1, "context": "The school dataset has appeared in many previous works [7, 2, 6].", "startOffset": 55, "endOffset": 64}, {"referenceID": 5, "context": "The school dataset has appeared in many previous works [7, 2, 6].", "startOffset": 55, "endOffset": 64}, {"referenceID": 12, "context": "[13]).", "startOffset": 0, "endOffset": 4}], "year": 2012, "abstractText": "Since its inception, the modus operandi of multi-task learning (MTL) has been to minimize the task-wise mean of the empirical risks. We introduce a generalized loss-compositional paradigm for MTL that includes a spectrum of formulations as a subfamily. One endpoint of this spectrum is minimax MTL: a new MTL formulation that minimizes the maximum of the tasks\u2019 empirical risks. Via a certain relaxation of minimax MTL, we obtain a continuum of MTL formulations spanning minimax MTL and classical MTL. The full paradigm itself is loss-compositional, operating on the vector of empirical risks. It incorporates minimax MTL, its relaxations, and many new MTL formulations as special cases. We show theoretically that minimax MTL tends to avoid worst case outcomes on newly drawn test tasks in the learning to learn (LTL) test setting. The results of several MTL formulations on synthetic and real problems in the MTL and LTL test settings are encouraging.", "creator": "LaTeX with hyperref package"}}}