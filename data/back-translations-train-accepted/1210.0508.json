{"id": "1210.0508", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Oct-2012", "title": "Inference algorithms for pattern-based CRFs on sequence data", "abstract": "We consider Conditional Random Fields (CRFs) with pattern-based potentials defined on a chain. In this model the energy of a string (labeling) $x_1 ... x_n$ is the sum of terms over intervals $[i,j]$ where each term is non-zero only if the substring $x_i ... x_j$ equals a prespecified pattern $\\alpha$. Such CRFs were used in computer vision, and can be naturally applied to many sequence tagging problems.", "histories": [["v1", "Mon, 1 Oct 2012 19:13:59 GMT  (63kb,DS)", "https://arxiv.org/abs/1210.0508v1", null], ["v2", "Tue, 23 Oct 2012 16:16:58 GMT  (64kb,DS)", "http://arxiv.org/abs/1210.0508v2", "improved complexity for one of the cases"], ["v3", "Thu, 8 Nov 2012 00:11:30 GMT  (65kb,DS)", "http://arxiv.org/abs/1210.0508v3", null], ["v4", "Sat, 29 Dec 2012 22:13:01 GMT  (72kb,DS)", "http://arxiv.org/abs/1210.0508v4", null], ["v5", "Fri, 20 Jan 2017 08:00:44 GMT  (60kb,D)", "http://arxiv.org/abs/1210.0508v5", "Algorithmica accepted version"]], "reviews": [], "SUBJECTS": "cs.LG cs.DS", "authors": ["rustem takhanov", "vladimir kolmogorov"], "accepted": true, "id": "1210.0508"}, "pdf": {"name": "1210.0508.pdf", "metadata": {"source": "CRF", "title": "Inference algorithms for pattern-based CRFs on sequence data", "authors": ["Rustem Takhanov", "Vladimir Kolmogorov"], "emails": ["takhanov@mail.ru", "vnk@ist.ac.at"], "sections": [{"heading": null, "text": "We present efficient algorithms for the three standard conclusions in a CRF problem, namely the calculation of (i) the partition function, (ii) the marginals, and (iii) the calculation of the MAP patterns. Their complexity is O (nL), O (nL'max), and O (nLmin) respectively. This improves the previous algorithms of [Ye et al.] NIPS 2009, whose complexity is O (nL | D), O (L2 '2max), and O (nL | D |), with the number of input patterns being i."}, {"heading": "1 Notation and preliminaries", "text": "First, we introduce a few definitions. \u2022 A pattern is a pair \u03b1 = ([i, j], \u03b2 x), where [i, j] is an interval in [1, n] and x = xi. \u2022 xj is a sequence via the alphabet D indexed by integers in [i, j] (j) (jp), (jp), (jp), (jp), (jp), (jp), (jp), (jp), (jp), (jp), (jp), (jp), (jp), (jp), (jp). The exact meaning will always be clear from the context. \"+\" stands for an arbitrary, non-empty word or pattern. \u2022 The concatenation of patterns = (i, j), x) and \u03b2 = (k), y) is the pattern."}, {"heading": "2 Computing partition function", "text": "In this section, we specify an algorithm for calculating the quantity (5), which assumes that (R, \u03b2,.eu) is a ring (\u03b2,.eu), which can be used in particular to calculate the partition function. We assume that we can add D whenever necessary. 2Note that we still claim complexity O (nP) when P is the number of different, non-empty prefixes of words in the original group. In fact, we can assume that every letter in Ms in D occurs in at least one word. (If not, then we can \"merge\" non-occurring letters into a single letter and add that letter to the numbers; clearly, any instance above the original pair (D, eMs) can be formulated as an instance above the new pair equivalently. The transformation increases P only by 1). The assumption implies that x x: The addition of the individual letters to D does not increase P by maximum O and P by maximum P."}, {"heading": "2.1 Proof of Theorem 2", "text": "Equation (13b) corresponds to Equation (12b); let us show that Equation (13a) applies to all cases of equality. (Note, applies to all cases of equality (II). (Note, for cases of equality (II) step 2 is correct: Assumption D (x) implies that Ds: s (II) and therefore Xs (II) = \u2205, Ms (II) = O). (Note, for a partial designation x (II): s defines the \"reduced partial cost\" asf \u2212 (x) =. (15) Let us look at this side of equality (II) + c\u03b1 (14). We will show that for all cases of equality Xs (II) there are no returns. (Note) Ws \u2212 1 (Note) Ws \u2212 f \u2212 (Note) f \u2212 (Note) f \u2212 (15)."}, {"heading": "3 Sampling", "text": "In this section, we will consider the semiring (R, \u03b2,) = (R, +, \u00b7) from Example 1. We assume that all costs are absolutely positive. We will introduce an algorithm for sampling patterns, which will follow the probability distribution p (x) = f (x) / Z. As in the previous section, we assume that sampling patterns after pattern after pattern (eq. (10)). For a node, we will leave Ts (x) the sequence of nodes in the subtree of G [4], which will follow the sequence of patterns after pattern (eq. (10). For a pattern of this sampling, we will leave Ts (\u03b1) the sequence of nodes rooted in the subtree of G [4], where the tax sequence is the sequence of the sequence of the sequence of the sequence of taxes."}, {"heading": "3.1 Proof of Theorem 3", "text": "Suppose that the step s (1, n) of the algorithm is valid; this means that patterns \u03b1t are well defined for t (s, n). For t (s, n), we then define the set of patterns At = \u2206 t (\u03b1 + 1) t (if t = \u03b1 then we define At = \u03b1 instead). We also define sentences of markingYt (\u03b1) = {yxt + 1: n | y = Xt (\u03b1 + 1). Let us leave Yn + 1 = D1: n.Lemma 5. Let us assume that step s is valid. (a) Ys + 1 is a resolution of sentences Ys (\u03b1) over Xs. (b) For each Y Ys, Ys is valid. (a) Ys is valid. (a) Ys + 1 is a resolution of sentences Ys (\u03b1) over Xs."}, {"heading": "4 Computing marginals", "text": "In this section we again consider the semiring probabilities of a pattern-based CRF, then we can calculate the pattern-based CRF values (pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-pattern-based pattern-based pattern-based pattern-pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-pattern-based pattern-based pattern-based pattern-based pattern-pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern-based pattern"}, {"heading": "4.1 Proof of theorem 6", "text": "View the names of x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "5.1 Proof of Theorem 9", "text": "x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "6.1 Proof of Theorem 11(a)", "text": "The statement is equivalent to the correctness of (38). First, let us divide the sum above (\u03b2) \u03b2 (\u03b2) \u03b2 (38) into two parts: nodes \u03b2, which belong to (\u03b2), and those which do not: (\u03b2). \u2212 It is easy to see that the second sum can be written as \"true.\" (\u03b2) The second sum can be written as \"true.\" (\u03b2) The third number (n) is equal. (\u03b2) The third number (n) is equal. (b) The third number (n) is equal. (b) The third number (b) is equal. (b) The third number (b) is equal. (b) The third number (b) is equal. (b) The third number (b) is equal. (b) The third number (b) is equal."}, {"heading": "6.2 Proof of Theorem 11(b)", "text": "s look at the process of a broad search in the tree starting from the root. At each step, we will maintain a certain number of nodes in the tree (which we call active nodes), and the transition to the next step is made by selecting one of the active nodes and replacing it with its children. The process stops when the number of active nodes becomes equal to the number of leaves in the tree. At each step of the process, we correspond to a partition of the set. The partition is defined by the following rule: If there are active nodes, then the partition is called active nodes."}, {"heading": "6.3 Proof of Theorem 11(c)", "text": "In this section we describe a pre-processing that will allow computational values Vt (\u03b1, \u03b2). In each (\u03b1, \u03b2) computational value there is a computational value Vt (\u03b1, \u03b2). In this section the procedure is based on the following observation; it follows trivially from the definition (37b). Lemma 13. For each (\u03b1, \u03b2) computational value J there is a computational value Vt (\u03b1, \u03b2). There is no computational time."}, {"heading": "6.4 Proof of Theorem 11(d)", "text": "We shall consider the general case of a commutative semimiring and the case if (R, I) = (R, min, +); the latter case is referred to as the MAP case. We shall consider the number of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children of children."}, {"heading": "7 MAP for non-positive costs", "text": "In this section, we assume that (R,) = (R, min, +) and (S) = (S) = (S) = (S) = (S) = (S) = (S) = (S) and (S) = (S) = (S) = (S). We will present a change that only allows O (n) (I) (S) and (S) comparisons. The number of additions in general will still be O (nP), but we will show that in certain scenarios it can be reduced using a Fast Fourier Transform (FFT). We will assume that \"S\" contains at least one word (S). \"(It can always be added if necessary). As usual, we will first select a set of patterns (S) that are 0 = [S); this step will be described later."}, {"heading": "7.1 Computing f(\u03b1) using FFT", "text": "It is easy to see that f (\u03b1s) = fic (\u03b1 | \u03b2) f (\u03b1 | \u03b2) f (\u03b1 | \u03b2) f (\u03b1 | \u03b2) in O (n log n) time.Proof. We assume that the claim is trivial. Let us leave p = | \u03b1 | \u03b2 | 1, and define sequences a) Rn \u2212 (n log n) time.Proof. We assume that | \u03b1 | \u03b2 | otherwise the claim is trivial."}, {"heading": "7.2 Proof of Theorem 14 (correctness)", "text": "First: Let us prove that for all patterns, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, pattern, number, number, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers, numbers."}, {"heading": "Acknowledgements", "text": "We thank Herbert Edelsbrunner for the helpful discussions."}], "references": [{"title": "Recursive star-tree parallel data structure", "author": ["Omer Berkman", "Uzi Vishkin"], "venue": "SIAM Journal on Computing,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "Beyond pairwise energies: Efficient optimization for higher-order MRFs", "author": ["N. Komodakis", "N. Paragios"], "venue": "In CVPR,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. Lafferty", "A. McCallum", "F Pereira"], "venue": "In ICML,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2001}, {"title": "Semi-Markov conditional random field with high-order features", "author": ["Viet Cuong Nguyen", "Nan Ye", "Wee Sun Lee", "Hai Leong Chieu"], "venue": "In ICML 2011 Structured Sparsity: Learning and Inference Workshop,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Sparse higher order conditional random fields for improved sequence labeling", "author": ["Xian Qian", "Xiaoqian Jiang", "Qi Zhang", "Xuanjing Huang", "Lide Wu"], "venue": "In ICML,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Minimizing sparse higher order energy functions of discrete variables", "author": ["C. Rother", "P. Kohli", "W. Feng", "J. Jia"], "venue": "In CVPR,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Semi-Markov conditional random fields for information extraction", "author": ["S. Sarawagi", "W. Cohen"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Inference algorithms for pattern-based CRFs on sequence data", "author": ["R. Takhanov", "V. Kolmogorov"], "venue": "In ICML,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "A linear algorithm for generating random numbers with a given distribution", "author": ["M.D. Vose"], "venue": "IEEE Transactions on software engineering,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1991}, {"title": "Conditional random fields with high-order features for sequence labeling", "author": ["Nan Ye", "Wee Sun Lee", "Hai Leong Chieu", "Dan Wu"], "venue": "In NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}], "referenceMentions": [{"referenceID": 2, "context": "A popular generalization is the Conditional Random Field model [3] that allows all terms to depend on the full observation z: E(x|z) = \u2211", "startOffset": 63, "endOffset": 66}, {"referenceID": 7, "context": "A preliminary version of this paper appeared in Proceedings of the 30th International Conference on Machine Learning (ICML), 2013 [8].", "startOffset": 130, "endOffset": 133}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Its complexity is either (i) O(nL) per sample, or (ii) O(n) per sample with an O(nL|D|) preprocessing (assuming that we have an oracle that produces independent samples from the uniform distribution on [0, 1] in O(1) time).", "startOffset": 202, "endOffset": 208}, {"referenceID": 1, "context": "Komodakis and Paragios [2] gave an O(nL) technique for minimizing energy (3) in this case.", "startOffset": 23, "endOffset": 26}, {"referenceID": 1, "context": "We present a modification that has the same worst-case complexity but can beat the algorithm in [2] in the best case.", "startOffset": 96, "endOffset": 99}, {"referenceID": 9, "context": "Related work The works of [10] and [2] are probably the most related to our paper.", "startOffset": 26, "endOffset": 30}, {"referenceID": 1, "context": "Related work The works of [10] and [2] are probably the most related to our paper.", "startOffset": 35, "endOffset": 38}, {"referenceID": 1, "context": "The latter considered a pattern-based CRF on a grid for a computer vision application; the MAP inference problem in [2] was converted to sequence labeling problems by decomposing the grid into thin \u201cstripes\u201d.", "startOffset": 116, "endOffset": 119}, {"referenceID": 4, "context": "[5] considered a more general formulation in which a single pattern is characterized by a set of strings rather than a single string \u03b1.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "Their inference procedure reduces the problem to the MAP estimation in a pairwise CRF with cycles, which Some of the bounds stated in [10] are actually weaker.", "startOffset": 134, "endOffset": 138}, {"referenceID": 3, "context": "[4] extended algorithms in [10] to the Semi-Markov model [7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[4] extended algorithms in [10] to the Semi-Markov model [7].", "startOffset": 27, "endOffset": 31}, {"referenceID": 6, "context": "[4] extended algorithms in [10] to the Semi-Markov model [7].", "startOffset": 57, "endOffset": 60}, {"referenceID": 3, "context": "We conjecture that our algorithms can be extended to this case as well, and can yield a better complexity compared to [4].", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "In [8] we applied the pattern-based CRF model to the problem of the protein dihedral angles prediction.", "startOffset": 3, "endOffset": 6}, {"referenceID": 9, "context": "5: \u0398(nP \u2032|D|) algorithm for a general commutative semiring, which is equivalent to the algorithm in [10].", "startOffset": 100, "endOffset": 104}, {"referenceID": 0, "context": "Complexity Assume that we have an oracle that produces independent samples from the uniform distribution on [0, 1] in O(1) time.", "startOffset": 108, "endOffset": 114}, {"referenceID": 8, "context": "With a \u0398(N) preprocessing, a sample can also be produced in O(1) time by the so-called \u201calias method\u201d [9].", "startOffset": 102, "endOffset": 105}, {"referenceID": 8, "context": "After that, for each \u03b1 \u2208 \u03a0s+1 we need to run the linear time procedure of [9] for distributions p(\u03b2) \u221d Ms(\u03b2), \u03b2 \u2208 \u2206s(\u03b1s+1).", "startOffset": 74, "endOffset": 77}, {"referenceID": 9, "context": "Remark 1 An alternative method for computing marginals with complexity O ( n|\u0393|L`max ) was given in [10].", "startOffset": 100, "endOffset": 104}, {"referenceID": 9, "context": "The algorithm closely resembles the method in [10]; it is based on the same idea and has the same complexity.", "startOffset": 46, "endOffset": 50}, {"referenceID": 9, "context": "Remark 2 As we already mentioned, Algorithm 4 resembles the algorithm in [10].", "startOffset": 73, "endOffset": 77}, {"referenceID": 0, "context": "If (R,\u2295,\u2297) = (R,min,+) then this can be reduced to O(nP log(`max + 1)) using the algorithm for Range Minimum Queries by [1].", "startOffset": 120, "endOffset": 123}, {"referenceID": 0, "context": "It is known [1] that with an O(N) preprocessing each query for can be answered in O(1) time per interval.", "startOffset": 12, "endOffset": 15}, {"referenceID": 0, "context": "In the MAP case we simply run the preprocessing of [1] for the sequence Wt(\u03b21), .", "startOffset": 51, "endOffset": 54}, {"referenceID": 1, "context": "[2] gave an algorithm that makes \u0398(nP ) comparisons and \u0398(nP ) additions.", "startOffset": 0, "endOffset": 3}], "year": 2017, "abstractText": "We consider Conditional Random Fields (CRFs) with pattern-based potentials defined on a chain. In this model the energy of a string (labeling) x1 . . . xn is the sum of terms over intervals [i, j] where each term is non-zero only if the substring xi . . . xj equals a prespecified pattern \u03b1. Such CRFs can be naturally applied to many sequence tagging problems. We present efficient algorithms for the three standard inference tasks in a CRF, namely computing (i) the partition function, (ii) marginals, and (iii) computing the MAP. Their complexities are respectively O(nL), O(nL`max) and O(nLmin{|D|, log(`max+1)}) where L is the combined length of input patterns, `max is the maximum length of a pattern, and D is the input alphabet. This improves on the previous algorithms of [Ye et al. NIPS 2009] whose complexities are respectively O(nL|D|), O ( n|\u0393|L`max ) and O(nL|D|), where |\u0393| is the number of input patterns. In addition, we give an efficient algorithm for sampling, and revisit the case of MAP with non-positive weights. This paper addresses the sequence labeling (or the sequence tagging) problem: given an observation z (which is usually a sequence of n values), infer labeling x = x1 . . . xn where each variable xi takes values in some finite domain D. Such problem appears in many domains such as text and speech analysis, signal analysis, and bioinformatics. One of the most successful approaches for tackling the problem is the Hidden Markov Model (HMM). The kth order HMM is given by the probability distribution p(x|z) = 1 Z exp{\u2212E(x|z)} with the energy function E(x|z) = \u2211 i\u2208[1,n] \u03c8i(xi, zi) + \u2211 (i,j)\u2208Ek \u03c8ij(xi:j) (1) where Ek = {(i, i+ k) | i \u2208 [1, n\u2212 k]} and xi:j = xi . . . xj is the substring of x from i to j. A popular generalization is the Conditional Random Field model [3] that allows all terms to depend on the full observation z: E(x|z) = \u2211 i\u2208[1,n] \u03c8i(xi, z) + \u2211 (i,j)\u2208Ek \u03c8ij(xi:j , z) (2) A preliminary version of this paper appeared in Proceedings of the 30th International Conference on Machine Learning (ICML), 2013 [8]. This work was partially supported by the European Research Council under the European Unions Seventh Framework Programme (FP7/2007-2013)/ERC grant agreement no 616160. 1 ar X iv :1 21 0. 05 08 v5 [ cs .L G ] 2 0 Ja n 20 17 We study a particular variant of this model called a pattern-based CRF. It is defined via", "creator": "LaTeX with hyperref package"}}}