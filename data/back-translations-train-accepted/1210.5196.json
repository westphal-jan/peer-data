{"id": "1210.5196", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Oct-2012", "title": "Matrix reconstruction with the local max norm", "abstract": "We introduce a new family of matrix norms, the \"local max\" norms, generalizing existing methods such as the max norm, the trace norm (nuclear norm), and the weighted or smoothed weighted trace norms, which have been extensively used in the literature as regularizers for matrix reconstruction problems. We show that this new family can be used to interpolate between the (weighted or unweighted) trace norm and the more conservative max norm. We test this interpolation on simulated data and on the large-scale Netflix and MovieLens ratings data, and find improved accuracy relative to the existing matrix norms. We also provide theoretical results showing learning guarantees for some of the new norms.", "histories": [["v1", "Thu, 18 Oct 2012 17:30:43 GMT  (27kb,D)", "http://arxiv.org/abs/1210.5196v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["rina foygel", "nathan srebro", "ruslan salakhutdinov"], "accepted": true, "id": "1210.5196"}, "pdf": {"name": "1210.5196.pdf", "metadata": {"source": "CRF", "title": "Matrix reconstruction with the local max norm", "authors": ["Rina Foygel", "Nathan Srebro"], "emails": ["rinafb@stanford.edu", "nati@ttic.edu", "rsalakhu@utstat.toronto.edu"], "sections": [{"heading": "1 Introduction", "text": "In the matrix reconstruction problem, we get a matrix Y-Rn-m, whose entries are only partially observed, and we want to reconstruct the unobserved entries as accurately as possible. Matrix reconstruction results in many modern applications, including the areas of cooperative filtering (e.g. Netflix price), image and video data, and others. This problem has often been addressed by regulating with matrix norms that promote low-level or near-level solutions, including the trace norm (also known as the core norm) and the maximum norm, as well as several adjustments to the trace norm described below. In this essay, we introduce a unifying family of norms that generalize these existing matrix norms, and that can be used to interpolate between the track and the maximum norms. We show that this family includes new norms that lie strictly between the track and the maximum norm."}, {"heading": "1.1 Trace norm and max norm", "text": "It is not as if it is a reactionary process, but a reactionary process, a process that involves blurring the lines between the two parties."}, {"heading": "1.2 The weighted trace norm", "text": "In order to solve the problem, we need to address the question of how we are able to minimize the risks that we pose, \"he said.\" We need to be able to minimize the risks, \"he said.\" We need to be able to minimize the risks. \"He added,\" We need to be able to minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize the risks, minimize, minimize the risks. \""}, {"heading": "2 The local max norm", "text": "We look at a generalization of these standards that lies \"between\" the track standard and the maximum standard. We define for everyone the (R, C) standard of X: EX standard (R, C) = sup r-R, c-C-X standard (r, c). This results in a standard for matrices, except in the trivial case where for some i or some j ri = 0 for all r-R or cj = 0 for all c-C. We now show some existing and new standards that can be achieved by local maximum standards."}, {"heading": "2.1 Trace norm and max norm", "text": "We can get the maximum standard by taking the maximum R and C possible, i.e. we can get the maximum (r, c) -weighted track standard by taking the singlet sets R = {r} and C = {c}. As discussed above, this includes the standard track standard (if r and c are uniform) as well as the weighted, empirically weighted and smoothed weighted track standard."}, {"heading": "2.2 Arbitrary smoothing", "text": "When we use the smoothed weighted maximum standard, we must select the degree of smoothing applicable to the marginal areas, that is, we must choose the smoothed row and column weights as specified in (3) \u0439 in our definition of the smoothed row and column weights. Alternatively, we could regulate all possible smoothing quantities simultaneously by looking at the local maximum standard with R = {(1 \u2212 \u0432) \u00b7 prow + \u0443 \u00b7 1 / n: arbitrarily long, and the same for C. That is, R and C are line segments in the simplex - they are larger than any single point as for the uniform or weighted conductor standard (or smoothed weighted conductor standard for a fixed quantity smoothing), but smaller than the entire simplex as for the maximum standard."}, {"heading": "2.3 Connection to (\u03b2, \u03c4)-decomposability", "text": "[8] we present a class of matrices defined by a property of (\u03b2) and (\u03b2). (\u03b2) decomposition: a matrix X fulfills this property if there is factorization X = A > (where A and B can have an arbitrary number of columns). (\u03b2) This matrix X fulfills this property. (\u03b2) This matrix X fulfills this property. (\u03b2) Decomposition fulfills this property. (\u03b2) This matrix X fulfills this property. (\u03b2) This matrix fulfills this property. (max i). (maxj) Note B (j)."}, {"heading": "2.4 Interpolating between trace norm and max norm", "text": "Next, we turn to an interpolation based on an upper limit, rather than a lower limit, on weights. Consider R = (r). (n) Consider the (r). (n) The (r) standard then corresponds to the (rescaled) trace standard when we opt for 1 / n and 1 / m, and corresponds to the maximum standard when we opt for 1 / m. Allowing and taking intermediate values results in a smooth interpolation between these two familiar norms and can be useful in situations where we want more flexibility in the way we regulate. We can generalize this to an interpolation between the maximum standard and a smoothed weighted trace standard, which we use in our experimental results."}, {"heading": "3 Optimization with the local max norm", "text": "A call for both the Trace-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-SDP-S"}, {"heading": "4 An approximate convex hull and a learning guarantee", "text": "In this section, we look for theoretical error limits for the problem of estimating unobserved entries in a matrix Y that has approximately a low rank. Our results apply to either a uniform or an uneven sample of entries from the matrix. We start with a result that compares the ball of the (R, C) standard unit with a convex shell of rank 1 matrices, which will be useful to prove our learning guarantee."}, {"heading": "4.1 Convex hull", "text": "To gain a better theoretical understanding of the (R, C) standard, we must first define the corresponding vector norms for Rn and Rm. (For each u, Rn) we can imagine this standard as a way to interpolate between the \"2 and\" 2 vector norms. For example, if we select R = R as defined in (5), then \"u\" R is equal to the root-mean square of the \u2212 1 largest entries of u whenever \u2212 1 is an integer. If we define \"V\" C analogous to v \"Rm, we can now refer these vector norms to the (R, C) norm to the (R) norm."}, {"heading": "4.2 Learning guarantee", "text": "We now give our main matrix reconstruction results, which show error limits for a family of norms that are drawn between the maximum norm and the smooth weighted trace norm. Theorem 3: Let us give a distribution to [n]: t = 1,. Let us suppose that a random example of places in the matrix is drawn i.i.d. by p, where these two sentences are defined in (6). Let us suppose that a random sample of places in the matrix is drawn i.i.d. by p, where s \u00b2 s \u00b2 s \u00b2 n, in anticipation of the sample S, in anticipation of ijpij \u00b2 s \u00b2 s, the Yij \u2212 X \u00b2 s class inf. (R, C), which we are drawn in the matrix \u00b2 class."}, {"heading": "5 Experiments", "text": "We test the local maximum standard on simulated and real matrix reconstruction tasks and compare its performance with the maximum standard, the uniform and empirically weighted track standards and the smoothed empirically weighted track standard."}, {"heading": "5.1 Simulations", "text": "We simulate n \u00b7 n noise matrices for n = 30, 60, 120, 240, where the underlying signal is rank k = 2 or k = 4, and we observe s = 3kn entries (uniformly and substituted). We have 50 attempts for each of the 8 combinations of (n, k).Data For each study, we randomly draw a matrix U-Rn \u00b7 k by drawing each row evenly from the unit sphere into Rn. We generate V-Rm \u00b7 k similarly. We set Y = UV > + pie diagonal \u00b7 Z, where the noise matrix has standard standard entries i.i.d. standard entries and \u03c3 = 0.3 is a moderate noise level. We also divide the n2 entries of the matrix into sets S0 tS1 tS2, which consist of s = 3kn training settings."}, {"heading": "5.2 Movie ratings data", "text": "Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters Filters"}, {"heading": "6 Summary", "text": "In this paper, we present a unifying family of matrix standards, the so-called \"local max\" standards, which generalize existing methods of matrix reconstruction, such as the max standard and the trace standard. We examine some interesting subfamilies of local max standards and consider several different options for interpolation between the trace (or smoothed weighted trace) and max standards. We find standards that lie exactly between the trace standard and the max standard and offer improved accuracy in matrix reconstruction for both simulated data and real film evaluations. We show that regulation with a local max standard is relatively easy to optimize, and provide a theoretical result that suggests improved matrix reconstruction using new standards in this family."}, {"heading": "A Proof of Theorem 1", "text": "Special case: Elementary upper limits First, we assume that the total result is true, i.e. that 2% X (R, C) = inf. AB > = X sup."}, {"heading": "R = {r \u2208 \u2206[n] : ri \u2264 Ri \u2200i} and C = {c \u2208 \u2206[m] : cj \u2264 Cj \u2200j} .", "text": "With strong dualism for linear programs, we havesup r = \"X\" R = \"X\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R.\" R \"R\" R \"R\" R \"R\" R \"R\" R. R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R. R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R \"R. R\" R \"R. R\" R \"R\" R \"R\" R \"R. R\" R \"R\" R \"R\" R. R \"R\" R \"R\" R \"R\" R \"R. R\" R \"R\" R \"R\" R \"R. R\" R \"R\" R \"R. R\" R \"R\" R \"R\" R. R \"R\" R \"R\" R. R \"R\" R \"R\" R \"R\" R \"R\" R \"R\" R. R \"R\" R \"R\" R. R \"R\" R. \"R\" R \"R\" R \"R\" R \"R\" R. \"R\" R \"R\" R \"R. R\" R. R \"R\" R \"R\" R \"R. R."}, {"heading": "B Proof of Theorem 2", "text": "We follow similar techniques to those used by Srebro and Shraibman."}, {"heading": "C Proof of Theorem 3", "text": "Following the strategy of Srebro & Shraibman (2005), we will use the wheel maker complexity to limit this excess risk. According to Theorem 8 of Bartlett & Mendelson (2002) 5, we know that there is no solution. (R, C). (1), where the expected wheel maker complexity is defined. (R, C). (2), where the expected wheel maker complexity is defined. (R, C). (S). (R, C). (1). (2), where the expected wheel maker complexity is defined. (R). (R, X). (X). (R). (R). (S). (R). (R). (R). (R). (R). (R). (R). (R). (R). (R). (R). (R). (R). (R). (R)."}, {"heading": "D Proof of Proposition 1", "text": "Let us leave L0 = loss (X) and C (t) = 1 (m). Then, by definition, it is sufficient to show that for some t (0, 1), X (1), X (1), X (n), X (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n), D (n (n), D (n), D (n), D (n), D (n (n), D (n), D (n), D (n (n), D (n (n), D (n), D (n (n), D (n (n), D (n), D (n (n), D (n (n), D (n), D (n), D (n (n), D (n), D (n (n), D (n (n), D (n), D (n, D (n), D (n, D (n, D (n), D (n, D (n, D (n), D (n), D (n, D (n), D (n, D (n, D (n), D (n, D (n), D (n, D, D, D, D (n), D (n, D,"}, {"heading": "E Computing the local max norm with an SDP", "text": "Lemma 2. Suppose R and C are convex and are defined by SDP representable constraints. Then, the (R, C) norm can be defined with the semi-defined program, \"X\" (R, C) = 12 inf supr, \"R\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"j\" j \"j\" j \"i\" i. In the general case, based on Theorem 1 in the main work, we just have to show that \"R\" i \"i\" i \"i\" i."}, {"heading": "2 \u2016X\u2016(R,C) = inf", "text": "In this case, we will again use Lemma 3 to see that this is equivalent to SDPinf {a + R > torif {b + C > b1 = (AA >) ii and vice versa (BB >) jj. In this case, we will again use Lemma 3 to see that this is equivalent to SDPinf {a + R > b > b1 = (AA > b1: a1i) ii and a + a1i (BB >) jj j, (A X > B). Let f: Rn \u00b7 Rm \u2192 R be any function that does not decrease."}], "references": [], "referenceMentions": [], "year": 2012, "abstractText": "We introduce a new family of matrix norms, the \u201clocal max\u201d norms, generalizing<lb>existing methods such as the max norm, the trace norm (nuclear norm), and the<lb>weighted or smoothed weighted trace norms, which have been extensively used in<lb>the literature as regularizers for matrix reconstruction problems. We show that this<lb>new family can be used to interpolate between the (weighted or unweighted) trace<lb>norm and the more conservative max norm. We test this interpolation on simulated<lb>data and on the large-scale Netflix and MovieLens ratings data, and find improved<lb>accuracy relative to the existing matrix norms. We also provide theoretical results<lb>showing learning guarantees for some of the new norms.", "creator": "LaTeX with hyperref package"}}}