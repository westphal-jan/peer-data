{"id": "1211.2476", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2012", "title": "Random Utility Theory for Social Choice", "abstract": "Random utility theory models an agent's preferences on alternatives by drawing a real-valued score on each alternative (typically independently) from a parameterized distribution, and then ranking the alternatives according to scores. A special case that has received significant attention is the Plackett-Luce model, for which fast inference methods for maximum likelihood estimators are available. This paper develops conditions on general random utility models that enable fast inference within a Bayesian framework through MC-EM, providing concave loglikelihood functions and bounded sets of global maxima solutions. Results on both real-world and simulated data provide support for the scalability of the approach and capability for model selection among general random utility models including Plackett-Luce.", "histories": [["v1", "Sun, 11 Nov 2012 23:09:02 GMT  (2140kb,D)", "http://arxiv.org/abs/1211.2476v1", null]], "reviews": [], "SUBJECTS": "cs.MA cs.LG stat.ML", "authors": ["hossein azari soufiani", "david c parkes", "lirong xia"], "accepted": true, "id": "1211.2476"}, "pdf": {"name": "1211.2476.pdf", "metadata": {"source": "CRF", "title": "Random Utility Theory for Social Choice", "authors": ["Hossein Azari Soufiani", "David C. Parkes", "Lirong Xia"], "emails": ["azari@fas.harvard.edu", "parkes@eecs.harvard.edu", "lxia@seas.harvard.edu"], "sections": [{"heading": null, "text": "Random Usage Theory models an agent's preferences for alternatives by determining a real value for each alternative (typically independently) and classifying the alternatives based on results. A particular case that has attracted a lot of attention is the Plackett-Luce model, for which rapid inference methods are available for maximum probability estimators. In this paper, conditions for general random usage models are developed that allow quick inferences within a Bayesian framework through MC-EM, with concave logarithmic functions and limited sets of global maximum solutions available. Results both in the real world and in simulated data support the scalability of the approach and the ability to choose models between general random usage models, including Plackett-Luce."}, {"heading": "1 Introduction", "text": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of ranking in social choice [7, 8, 23, 25, 29, 30] have become more important in recent years. Partly this is due to the explosion of socio-economic platforms where users \"opinions must be aggregated in order to be representative of the reports. Since Condorcet [6] is an approach to this problem, social decisions are formulated as the problem of estimating a true underlying world state (e.g. a true quality ranking of alternatives) in which the individual reports are regarded as noisy data in relation to the true state."}, {"heading": "1.1 Our Contributions", "text": "In this paper, we focus on RUMs, in which the random utilities are generated independently in relation to distributions in the exponential family (EF). [20] This expands the P-L model, since the Gumbel distribution is limited by fixed form parameters belonging to the EF. Our main theoretical contributions are Theorem 1 and Theorem 2, which suggest conditions such as the log-likelihood function is concave and the set of global maxima solutions is limited for the location family, the RUMs, in which the shape of each distribution is fixed and the only latent variables are the locations, i.e. the means of the UFiction function is concave and the set of global maxima solutions is limited for the location family, the RUMs, in which the shape of the individual distributions is specified, and the only latent variables are the locations, i.e. the means of the UFiction functions are concave, the existing UFicity cases are those we use, such as the Lapycles, the Lapycles, the R\u00b5laces, and many other models we use, the RU\u00b5laces."}, {"heading": "2 RUMs and Exponential Families", "text": "In social selection, each agent i \u00b2 \u00b2 =., n} has a strict preference order for alternatives. This provides the data for an inferential approach to social selection. Let's leave L \u2212 \u2212 \u2212 r is a figure that assigns a series of rankings to each preference profile, r: L (C) n 7 \u2192 (2L (C)\\ \u2205 L (C), so that D \u2212 l (C) n. A voting rule r is a figure that assigns a series of rankings to each preference profile, r: L (C) n 7 \u2192 (2L (C)\\ \u2205). Especially in the case of equilibrium, the order of precedence may include x more than one singleton ranking. In the maximum probability (MLE) for social choice, the preference profile is considered data, D = {\u03c01,."}, {"heading": "3 Global Optimality and Log-Concavity", "text": "In this section, we provide a condition on distributions that ensures that the probability function (2) is logically concave in parameters (1). We also provide a condition under which the set of MLE solutions is limited if any latent parameter is fixed, and the only parameters are the means of our MC-EM approach to a global mode with a sufficiently precise E-step. We focus on the location family, which is a subset of RUMs in which the shapes of all RUMs are fixed, and the only parameters are the means of the distributions. For the location family, we can be writeXj = applicable enough, where Xj is a subset of RUMs in which is a random variable whose mean 0 and models are a subjective noise. The random variables are not necessary to be distributed equally."}, {"heading": "4 Monte Carlo EM for Parameter Estimation", "text": "In this section, we propose an MC-EM algorithm for the MLE conclusion for RUMs where each \u00b5j becomes the EF.22Our algorithm can, of course, be extended to calculate a maximum a posteriori probability (MAP) if we have a previous one above the parameters ~ \u03b8. Nevertheless, it seems difficult to motivate the imposition of a previous one above parameters in many social selection ranges. The EM algorithm determines the MLE parameters ~ \u03b8 iteratively and proceeds as follows: In each iteration t + 1, given parameters ~ \u03b8t from the previous iteration, the algorithm consists of an E-step and an M-step. For the E-step, we calculate for each given ~ \u03b8 = (\u03b81,., \u03b8m) the conditional expectation of the complete data log probability (latent variables ~ x and data D), whereby the latent variables ~ ~ ~ ~ ~ are distributed according to the data, the Iteration of the last step of the Iteration and the Iteration of the Iteration."}, {"heading": "4.1 Monte Carlo E-step by Gibbs sampler", "text": "The E-step can be simplified with the help of (3) as follows: E ~ X {log n \u00b2 i = 1 Pr (~ xi, \u03c0i | ~ \u03b8) | D, ~ \u03b8t} = E ~ X {log n \u00b2 i = 1 Pr (~ xi | ~ \u03b8) Pr (\u03c0i | ~ xi) | D, ~ \u03b8t} = n \u2211 i = 1 m \u2211 i = 1 EXij {log\u00b5j (x i \u00b7 \u03b8j) | \u03c0i, ~ \u03b8t} = n \u2211 i = 1 m \u2211 j = 1 (\u03b7 (\u03b8j) EXij {T (x i j) | \u03c0i, ~ \u03b8t} \u2212 A (\u03b8j) + W, where W = EXij {B (x i j) | \u03c0i, ~ \u03b8t} only from ~ successt and D (not on ~ certainj) EXij), which means that it can be treated as a constant in the M-step. Hence, in the E-step we only have to calculate an approximate distribution."}, {"heading": "4.2 M-step", "text": "In the E-step we have calculated (approximate) Si, t + 1j. In the M-step we calculate ~ \u03b8 t + 1 to maximize \u2211 n i = 1 \u2211 m j = 1 (\u03b7 (\u03b8j) EXij {T (x i j) | \u03c0i, ~ \u03b8t} \u2212 A (\u03b8j) + EXij {B (x i j) | \u03c0i, ~ \u03b8t}). Equivalently we calculate phenomena + 1j for each j \u2264 m separately to maximize phenomena n i = 1 {\u03b7 (\u03b8j) EXij {T (x i j) | \u03c0i, ~ \u03b8t} \u2212 A (\u03b8j)} = \u03b7 (\u03b8j) \u0445 n i = 1 S i, t + 1 j \u2212 nA (successj).For the case of normal distribution with fixed variance, where phenomena (\u03b8j) = 2\u03b8j and A (successj) = (\u03b8j) 2, we have shown phenomena + 1j = 1 j + i in the figure + j = 1 algorithm."}, {"heading": "4.3 Convergence", "text": "In the last section, we have shown that if the RUM meets the premise in theorem 1 and theorem 2, the data meet condition 1, then the log probability function is concave, and the set of global maximum solutions is limited, which guarantees the convergence of MC-EM for an exact E-step. In general, MC-EM methods do not have the uniform convergence property of EM methods. To control the approximation error in the MC-E step, we can increase the number of samples with the iterations [28]. In our application, however, we do not care about the exact estimation of ~ \u03b8, as we are only interested in their order in relation to each other. As long as the approximation error remains relatively small, so that the differences in the approximation errors are much greater than the error, we are sure that we stop.A known problem with Gibbs sampling is that it can introduce a correlation between samples."}, {"heading": "5 Experimental Results", "text": "We evaluate the proposed MC-EM algorithm using synthetic data and two real datasets, an election dataset and a dataset representing preferential orders on sushi. For simulated data, we use the Kendall correlation [11] between two hierarchies (typically between the true order and the result of the method) as a measure of performance."}, {"heading": "5.1 Experiments for Synthetic Data", "text": "The results show that a limited number of iterations in the EM algorithm (maximum 3) and samples MN = 4000 (M = 5, N = 800) are sufficient to derive the sequence in most cases. Kendall correlation performance improves for a larger number of agents, corresponding to more data. See Figure 4, which shows the asymptotic behavior of the maximum probability estimator in restoring the true parameters. Figure 4 shows that the larger the size of the data set, the better the performance of the method. In addition, for large deviations in data generation due to increasing noise in the data, the speed at which the performance improves is slower than for smaller deviations located on the left and middle axis."}, {"heading": "5.2 Experiments for Model Robustness", "text": "We apply our methodology to a public election data set collected by Nicolaus Tideman [27], where voters have provided partial dispositions of the candidates. A partial order includes comparisons between a subset of alternatives, and the unmentioned alternatives in the partial order are classified as lower than the lowest alternative among the aforementioned alternatives. The total number of votes is n = 280 and the number of alternatives m = 15. For the purposes of our experiments, we assume the order of the alternatives we obtain by varying the amount of available data. We evaluate the performance of subsamples consisting of 10, 20,... since no fundamental truth is given as part of the data. After finding the basic truth by applying all 280 votes (and a normal model), we compare the performance of our approach as we vary the amount of available data. We evaluate the performance of subsamples consisting of 10, 20,... 280 samples randomly selected from the complete data set."}, {"heading": "5.3 Experiments for Model Fitness", "text": "In addition to a public election dataset, we tested our algorithm using a sushi dataset in which 5000 users gave rankings of 10 different types of sushi [15]. For each experiment, we randomly selected the rankings of L. The deviations were set to 1 and therefore we had the theoretical guarantees for convergence to global optimal solutions through Theorem 1 and Theorem 2. If we let the deviations be part of the parameterization, we lose the theoretical guarantees. However, the EM algorithm can still be applied to 1, and since the deviations are now parameters (instead of being fixed to 1), the model fits better in relation to the log probability of L. For this reason, we adopt rankings with normal distributions where the deviation from AIM is a normal probability of L."}, {"heading": "5.4 Implementation and Run Time", "text": "The runtime of our MC-EM algorithm scales linearly with the number of agents on real data (election data) with a slope of 13.3 seconds per agent on an Intel i5 2.70GHz PC. This is true for 100 iterations of the EM algorithm, with the number of Gibbs scans increasing with iterations in 2000 + 300 \u0445 iteration steps."}, {"heading": "Acknowledgments", "text": "Lirong Xia is supported by the NSF under grant number 1136996 to the Computing Research Association for the CIFellows Project. We thank Craig Boutilier, Jonathan Huang, Tyler Lu, Nicolaus Tideman, Paolo Viappiani and anonymous NIPS-12 reviewers for helpful comments and suggestions or help with the datasets."}], "references": [{"title": "Automobile prices in market", "author": ["Steven Berry", "James Levinsohn", "Ariel Pakes"], "venue": "equilibrium. Econometrica,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1995}, {"title": "Random orderings and stochastic theories of responses", "author": ["Henry David Block", "Jacob Marschak"], "venue": "In Contributions to Probability and Statistics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1960}, {"title": "Maximizing Generalized Linear Mixed Model Likelihoods with an Automated Monte Carlo EM Algorithm", "author": ["James G. Booth", "James P. Hobert"], "venue": "JRSS. Series B,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Handbook of Markov Chain Monte Carlo", "author": ["Steve Brooks", "Andrew Gelman", "Galin Jones", "Xiao-Li Meng", "editors"], "venue": "Chapman and Hall/CRC,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Efficient Bayesian Inference for Generalized Bradley-Terry Models", "author": ["Francois Caron", "Arnaud Doucet"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Preference functions that score rankings and maximum likelihood estimation", "author": ["Vincent Conitzer", "Matthew Rognlie", "Lirong Xia"], "venue": "In Proc. IJCAI,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Common voting rules as maximum likelihood estimators", "author": ["Vincent Conitzer", "Tuomas Sandholm"], "venue": "In Proc. UAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "Solution of a ranking problem from binary comparisons", "author": ["Lester R. Ford", "Jr."], "venue": "The American Mathematical Monthly,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1957}, {"title": "A grade of membership model for rank data", "author": ["Isobel Claire Gormley", "Thomas Brendan Murphy"], "venue": "Bayesian Analysis,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Kendall\u2019s correlation coefficient for vague preferences", "author": ["Przemyslaw Grzegorzewski"], "venue": "Soft Computing,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Bayesian inference for Plackett-Luce ranking models", "author": ["John Guiver", "Edward Snelson"], "venue": "In Proc. ICML,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "The complexity of Kemeny elections", "author": ["Edith Hemaspaandra", "Holger Spakowski", "J\u00f6rg Vogel"], "venue": "Theoretical Computer Science,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "MM algorithms for generalized Bradley-Terry models", "author": ["David R. Hunter"], "venue": "In The Annals of Statistics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2004}, {"title": "Nantonac collaborative filtering: Recommendation based on order responses", "author": ["Toshihiro Kamishima"], "venue": "In Proc. KDD,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Learning to Rank for Information", "author": ["Tie-Yan Liu"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Learning mallows models with pairwise preferences", "author": ["Tyler Lu", "Craig Boutilier"], "venue": "In Proc. ICML,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Individual Choice Behavior: A Theoretical Analysis", "author": ["R. Duncan Luce"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1959}, {"title": "Conditional logit analysis of qualitative choice behavior", "author": ["Daniel McFadden"], "venue": "In Frontiers of Econometrics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1974}, {"title": "Natural Exponential Families with Quadratic Variance Functions", "author": ["Carl N. Morris"], "venue": "Annals of Statistics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1982}, {"title": "The analysis of permutations", "author": ["R.L. Plackett"], "venue": "JRSS. Series C,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1975}, {"title": "Logarithmic concave measures and related topics. In Stochastic Programming, pages 63\u201382", "author": ["Andr\u015b Pr\u00e9kopa"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1980}, {"title": "A maximum likelihood approach for selecting sets of alternatives", "author": ["Ariel D. Procaccia", "Sashank J. Reddi", "Nisarg Shah"], "venue": "In Proc. UAI,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Chapter 29. log-concavity property of probability measures. FSU techinical report", "author": ["Frank Proschan", "Yung L. Tong"], "venue": "Number M-805,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1989}, {"title": "How to calibrate the scores of biased reviewers by quadratic programming", "author": ["Magnus Roos", "J\u00f6rg Rothe", "Bj\u00f6rn Scheuermann"], "venue": "In Proc. AAAI,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Thurstone. A law of comparative judgement", "author": ["Louis Leon"], "venue": "Psychological Review,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1927}, {"title": "Collective Decisions and Voting: The Potential for Public Choice", "author": ["Nicolaus Tideman"], "venue": "Ashgate Publishing,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "A Monte Carlo Implementation of the EM Algorithm and the Poor Man\u2019s Data", "author": ["Greg C.G. Wei", "Martin A. Tanner"], "venue": "Augmentation Algorithms. JASA,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1990}, {"title": "A maximum likelihood approach towards aggregating partial orders", "author": ["Lirong Xia", "Vincent Conitzer"], "venue": "In Proc. IJCAI,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2011}, {"title": "Aggregating preferences in multi-issue domains by using maximum likelihood estimators", "author": ["Lirong Xia", "Vincent Conitzer", "J\u00e9r\u00f4me Lang"], "venue": "In Proc. AAMAS,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2010}, {"title": "The relationship between Luce\u2019s Choice Axiom, Thurstone\u2019s Theory of Comparative Judgment, and the double exponential distribution", "author": ["John I. Jr. Yellott"], "venue": "J. of Mathematical Psychology,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 1977}, {"title": "Optimal voting rules", "author": ["H. Peyton Young"], "venue": "Journal of Economic Perspectives,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 1995}], "referenceMentions": [{"referenceID": 14, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 51, "endOffset": 55}, {"referenceID": 5, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 6, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 21, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 23, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 27, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 28, "context": "Problems of learning with rank-based error metrics [16] and the adoption of learning for the purpose of rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.", "startOffset": 138, "endOffset": 160}, {"referenceID": 30, "context": "Later, Kemeny\u2019s rule was shown to provide the maximum likelihood estimator (MLE) for this model [32].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": "In addition, computing the winner through the Kemeny rule is \u03982 -complete [13].", "startOffset": 74, "endOffset": 78}, {"referenceID": 24, "context": "To overcome the first criticism, a more recent literature adopts the random utility model (RUM) from economics [26].", "startOffset": 111, "endOffset": 115}, {"referenceID": 16, "context": "A popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31].", "startOffset": 37, "endOffset": 45}, {"referenceID": 19, "context": "A popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31].", "startOffset": 37, "endOffset": 45}, {"referenceID": 1, "context": "A popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31].", "startOffset": 153, "endOffset": 159}, {"referenceID": 29, "context": "A popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated according to Gumbel distributions with fixed shape parameter [2,31].", "startOffset": 153, "endOffset": 159}, {"referenceID": 0, "context": "P-L has been extensively applied in econometrics [1, 19], and more recently in machine learning and information retrieval (see [16] for an overview).", "startOffset": 49, "endOffset": 56}, {"referenceID": 17, "context": "P-L has been extensively applied in econometrics [1, 19], and more recently in machine learning and information retrieval (see [16] for an overview).", "startOffset": 49, "endOffset": 56}, {"referenceID": 14, "context": "P-L has been extensively applied in econometrics [1, 19], and more recently in machine learning and information retrieval (see [16] for an overview).", "startOffset": 127, "endOffset": 131}, {"referenceID": 4, "context": "Efficient methods of EM inference [5, 14], and more recently expectation propagation [12], have been developed for P-L and its variants.", "startOffset": 34, "endOffset": 41}, {"referenceID": 12, "context": "Efficient methods of EM inference [5, 14], and more recently expectation propagation [12], have been developed for P-L and its variants.", "startOffset": 34, "endOffset": 41}, {"referenceID": 10, "context": "Efficient methods of EM inference [5, 14], and more recently expectation propagation [12], have been developed for P-L and its variants.", "startOffset": 85, "endOffset": 89}, {"referenceID": 8, "context": "In application to social choice, the P-L model has been used to analyze political elections [10].", "startOffset": 92, "endOffset": 96}, {"referenceID": 15, "context": "EM algorithm has also been used to learn the Mallows model, which is closely related to the Condorcet\u2019s probabilistic model [17].", "startOffset": 124, "endOffset": 128}, {"referenceID": 24, "context": "Specifically, we are not aware of either an analytical solution or an efficient algorithm for MLE inference for one of the most natural models proposed by Thurstone [26], where each Xj is normally distributed.", "startOffset": 165, "endOffset": 169}, {"referenceID": 18, "context": "1 Our Contributions In this paper we focus on RUMs in which the random utilities are independently generated with respect to distributions in the exponential family (EF) [20].", "startOffset": 170, "endOffset": 174}, {"referenceID": 1, "context": "Example 1 (Plackett-Luce as an RUM [2]) In the RUM, let \u03bcj\u2019s be Gumbel distributions.", "startOffset": 35, "endOffset": 38}, {"referenceID": 20, "context": "Proof sketch: The theorem is proved by applying the following lemma, which is Theorem 9 in [22].", "startOffset": 91, "endOffset": 95}, {"referenceID": 7, "context": "The concavity of log-likelihood of P-L has been proved [9] using a different technique.", "startOffset": 55, "endOffset": 58}, {"referenceID": 22, "context": "in [24], the set of global maxima solutions to the likelihood function, denoted by SD, is convex since the likelihood function is log-concave.", "startOffset": 3, "endOffset": 7}, {"referenceID": 7, "context": "[9] proposed the following necessary and sufficient condition for the set of global maxima solutions to be bounded (more precisely, unique) when \u2211m j=1 e \u03b8j = 1.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Rao-Blackwellized: To further improve the Gibbs sampler, we use Rao-Blackwellized [4] estimation using E{T (x j ) | x i,k \u2212j , \u03c0 , ~ \u03b8} instead of the sample x j , where x i,k \u2212j is all of ~x except for x j .", "startOffset": 82, "endOffset": 85}, {"referenceID": 26, "context": "In order to control the error of approximation in the MC-E step we can increase the number of samples with the iterations [28].", "startOffset": 122, "endOffset": 126}, {"referenceID": 2, "context": "With an approach similar to [3], we can derive a relationship between the variance of error in ~ \u03b8 and the Monte-Carlo error in the E-step approximation:", "startOffset": 28, "endOffset": 31}, {"referenceID": 9, "context": "we use the Kendall correlation [11] between two rank orders (typically between the true order and the method\u2019s result) as a measure of performance.", "startOffset": 31, "endOffset": 35}, {"referenceID": 25, "context": "We apply our method to a public election dataset collected by Nicolaus Tideman [27], where the voters provided partial orders on candidates.", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "In addition to a public election dataset, we have tested our algorithm on a sushi dataset, where 5000 users give rankings over 10 different kinds of sushi [15].", "startOffset": 155, "endOffset": 159}], "year": 2012, "abstractText": "Random utility theory models an agent\u2019s preferences on alternatives by drawing a real-valued score on each alternative (typically independently) from a parameterized distribution, and then ranking the alternatives according to scores. A special case that has received significant attention is the Plackett-Luce model, for which fast inference methods for maximum likelihood estimators are available. This paper develops conditions on general random utility models that enable fast inference within a Bayesian framework through MC-EM, providing concave loglikelihood functions and bounded sets of global maxima solutions. Results on both real-world and simulated data provide support for the scalability of the approach and capability for model selection among general random utility models including Plackett-Luce.", "creator": "LaTeX with hyperref package"}}}