{"id": "1211.3212", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Nov-2012", "title": "Distributed Non-Stochastic Experts", "abstract": "We consider the online distributed non-stochastic experts problem, where the distributed system consists of one coordinator node that is connected to $k$ sites, and the sites are required to communicate with each other via the coordinator. At each time-step $t$, one of the $k$ site nodes has to pick an expert from the set ${1, ..., n}$, and the same site receives information about payoffs of all experts for that round. The goal of the distributed system is to minimize regret at time horizon $T$, while simultaneously keeping communication to a minimum.", "histories": [["v1", "Wed, 14 Nov 2012 06:45:38 GMT  (1706kb,D)", "http://arxiv.org/abs/1211.3212v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["varun kanade", "zhenming liu", "bozidar radunovic"], "accepted": true, "id": "1211.3212"}, "pdf": {"name": "1211.3212.pdf", "metadata": {"source": "CRF", "title": "Distributed Non-Stochastic Experts", "authors": ["Varun Kanade", "Zhenming Liu"], "emails": ["vkanade@eecs.berkeley.edu", "zhenming@cs.princeton.edu", "bozidar@microsoft.com"], "sections": [{"heading": null, "text": "\u221a log (n) T) Regret tied to the cost of T communication. (ii) No communication: Each side operates an independent copy - the regret is O (\u221a log (n) kT) and the communication is 0. This paper shows the difficulty of simultaneously achieving repentance asymptotically better than \u221a kT and communication better than T. We specify a novel algorithm that achieves a non-trivial trade-off for an ignorant adversary: Regret O (\u221a k5 (1 +) / 6T) and communication O (T / k), for each value of B (0, 1 / 5). We also consider a variant of the model in which the coordinator selects the expert. In this model we show that the label-efficient forecaster of Cesa-Bianchi et al. (2005) already gives us a strategy that is near optimal in terms of regret and communication."}, {"heading": "1 Introduction", "text": "In this paper, we look at the well-studied non-stochastic expert problem in a distributed environment. In the standard (non-distributed) setting, there are a total of n experts available to advise the decision-maker, and in each round t = 1,..., T, she must decide to follow the advice of one of the experts, say at the point [n] = {1,.., n}. At the end of the round, she observes a payout vector pt. [0, 1] n, where pt [a] denotes the payout that would have been received by following the advice of an expert. The payout that the decision-maker receives is pt [at]., the non-stochastic setting, an opponent decides the payout vectors at any point in time. At the end of the T rounds, the regret of the decision-makers is the difference in the payout she would have received that she would have received."}, {"heading": "2 Models and Summary of Results", "text": "This year, the time has come for us to be able to try to find a solution that we are able to find, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution, that we are able to find a solution. \""}, {"heading": "3 Site-prediction model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Upper Bounds", "text": "We start by making two assumptions that simplify exposure. First, we assume that there are only 2 experts. Generalizing 2 experts to n is simple, as discussed in Remark 1 at the end of this section. Second, we assume that there is a global query counter that is available to all pages and the coordinator that keeps track of the total number of queries received on the k pages. We discuss this assumption in Remark 2 at the end of this section. As is often the case in online algorithms, we assume that the time horizon T is known. Otherwise, the default doubling trick is defined in this section in Table 1. Algorithm Description: Our DFPL algorithm is described in Figure 1 (a)."}, {"heading": "3.2 Lower Bounds", "text": "In this section, we specify a lower limit for distributed counter algorithms in the site prediction model. Distributed counter totals allow strict approximation guarantees, i.e. for factor \u03b2 additive approximation, the required communication is only O (T log (T) \u221a k / \u03b2) [11]. We observe that the noise used by FPL is quite large, O (\u221a T), so it is tempting to find a suitable \u03b2 and operate FPL using approximately summed payouts. (ii) Each site uses only the (approximate) cumulative payouts and any local information it may have, an (approximate) cumulative payout amount for each expert on additive accuracy \u03b2. Furthermore, any communication is used only to maintain such a counter. (ii) Each site then uses only the (approximate) cumulative payouts and any local information it may have in order to select an expert when it is queried."}, {"heading": "4 Coordinator-prediction model", "text": "In the coordinator prediction model, as already mentioned, it is possible to use the label-efficient prediction mechanism LEF (chap. 6 [2, 13]). Let C be an upper limit on the total amount of communication we are allowed to use. The label-efficient prediction mechanism translates into the following simple protocol: Whenever a page receives a payout vector, it forwards that particular payout mechanism to the coordinator with the probability p \u2248 C / T. The coordinator will always execute the exponentially weighted prediction mechanism over the collected subset of payouts to make new decisions. Here, the expected regret is O (T \u221a log (n) / C). In other words, if our regret must be O (\u221a T), the communication must be linear in T. We observe that there is in principle a way to use better algorithms in this setting for two main reasons: (i) if the payout cumulative sites can send them to the coordinator."}, {"heading": "5 Simulations", "text": "In this section, we describe some simulation results by comparing the effectiveness of our DFPL algorithm with some other techniques. While we compare DFPL with simple algorithms - complete communication and no communication, and with two other algorithms we call mini-batch and HYZ. In the mini-batch algorithm, the coordinator randomly requests, with a certain probability p at any given time, all cumulative sequence vectors at all locations. He then sends the sum (across all locations) back to the sites so that all sites have the latest cumulative sequence vector. Whenever such communication occurs, the cost is 2k sequence vectors. We refer to sequence vectors because they are similar in spirit to the minibatch algorithms used in the stochastic optimization problems. In the HYZ algorithm, we first use the distributed counting technique from Huang et al. [11] to obtain the (approximate) expiry time for each expert."}, {"heading": "A Adaptive Adversary", "text": "This section contains a proof for Theorem 3. The proof makes use of Khinchine's inequality = unequally distributed (see Appendix A.1.14 in [2]).Khinchine's inequality. Let \u03c31,. \u2212 \u2212 p = then be Rademacher's random variables, i.e. Pr [\u03c3i = 1] = Pr [\u03c3i = \u2212 1] = 1 / 2. Then consider a1,. \u2212 \u2212 \u2212 p = 1 random variables, i.e. Pr [\u03c3i = 1] = 1 + 1 = 1 momentum (p = 1). Then for any real number a1,. \u2212 p [\u2212 p]. The adaptive adversary divides the total T-time steps into T / k time blocks, each consisting of k-time steps. During each block of k-time steps, each of the k-digits receives exactly 1 query."}, {"heading": "B Follow the Perturbed Leader", "text": "The evidence for lemmas 1. We first note that the regret guarantee of FPL (\u03b7) (see Figure 1 (b) isE [R] \u2264 B \u03b7 T \u2211 t = 1 | pt | 1 + \u03b7Die above appears in the analysis of Kalai and Vempala [6]. Note that, although | pt | 1 = pt [1] + pt [2] (pt [a] \u2265 0 in our setting), we can apply the following trick. We first note that FPL [2] pt [2] = 0 (ii) pt [1] pt [2] pt [2] pt [1] pt [2] pt [1] pt [1] pt [1] pt [1] pt [1] pt [1] pt [1] pt [1] pt [1] pt [1] pt [1] pt [1] pt [1] pt [2] pt [1] pt p p p p p p p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p 8 p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] pt [1] p [1] p [1] pt [1] p [1] pt [1] p [1] pt [1] p [1] p [1] pt [1] p [1] pt [1] p [1] pt [1] p [1] pt [1] p [1] pt [1] p [1] pt [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p [1] p ["}, {"heading": "C Site Prediction : Missing Proofs", "text": "In this section, we generalize our DFPL algorithm for two experts to deal with n experts. Lemma 2 showed that DFPL algorithm, in the hiring of two experts, guarantees that the expected regret is at most c0 \u221a '5 / 6T, where c0 is a universal constant. Our generalization follows a recursive approach. Suppose that any algorithm A can achieve an expected regret, c0 log (n) 5 / 6T with n experts, we show that we can construct algorithm A \"so that we achieve expected regret, c0 (n) + 1) with 2n experts as follows: We perform 2 independent copies of A (say A1 and A2) so that A1 only with the first n experts a1, a2, and A2 with the rest of the experts at + 1, a2n."}, {"heading": "D Proof of Theorem 5", "text": "To prove Theorem 5, we construct a series of reward sequences pt0, p t 1,..., and show that any FPL-like algorithm (as described in Section 4) will ultimately regret that at least one of these sequences depends on the reward sequence, unless the communication is essentially linear in T. Before starting the actual analysis, we must introduce another notation. First, we must remember that C is an upper limit on the amount of communication allowed in the protocol. We will focus on reward sequences where exactly one of the experts receives reward sequences and the other expert receives reward 0, i.e. pt."}], "references": [], "referenceMentions": [], "year": 2012, "abstractText": "We consider the online distributed non-stochastic experts problem, where the distributed<lb>system consists of one coordinator node that is connected to k sites, and the sites are required<lb>to communicate with each other via the coordinator. At each time-step t, one of the k site<lb>nodes has to pick an expert from the set {1, . . . , n}, and the same site receives information<lb>about payoffs of all experts for that round. The goal of the distributed system is to minimize<lb>regret at time horizon T , while simultaneously keeping communication to a minimum. The<lb>two extreme solutions to this problem are: (i) Full communication: This essentially simulates<lb>the non-distributed setting to obtain the optimal O(<lb>\u221a<lb>log(n)T ) regret bound at the cost of<lb>T communication. (ii) No communication: Each site runs an independent copy \u2013 the regret<lb>is O(<lb>\u221a<lb>log(n)kT ) and the communication is 0. This paper shows the difficulty of simultane-<lb>ously achieving regret asymptotically better than<lb>\u221a<lb>kT and communication better than T . We<lb>give a novel algorithm that for an oblivious adversary achieves a non-trivial trade-off: regret<lb>O(<lb>\u221a<lb>k5(1+ )/6T ) and communication O(T/k ), for any value of \u2208 (0, 1/5). We also consider<lb>a variant of the model, where the coordinator picks the expert. In this model, we show that<lb>the label-efficient forecaster of Cesa-Bianchi et al. (2005) already gives us strategy that is near<lb>optimal in regret vs communication trade-off.", "creator": "LaTeX with hyperref package"}}}