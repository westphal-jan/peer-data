{"id": "1302.6009", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Feb-2013", "title": "On learning parametric-output HMMs", "abstract": "We present a novel approach for learning an HMM whose outputs are distributed according to a parametric family. This is done by {\\em decoupling} the learning task into two steps: first estimating the output parameters, and then estimating the hidden states transition probabilities. The first step is accomplished by fitting a mixture model to the output stationary distribution. Given the parameters of this mixture model, the second step is formulated as the solution of an easily solvable convex quadratic program. We provide an error analysis for the estimated transition probabilities and show they are robust to small perturbations in the estimates of the mixture parameters. Finally, we support our analysis with some encouraging empirical results.", "histories": [["v1", "Mon, 25 Feb 2013 07:20:19 GMT  (649kb)", "http://arxiv.org/abs/1302.6009v1", null]], "reviews": [], "SUBJECTS": "cs.LG math.ST stat.ML stat.TH", "authors": ["aryeh kontorovich", "boaz nadler", "roi weiss"], "accepted": true, "id": "1302.6009"}, "pdf": {"name": "1302.6009.pdf", "metadata": {"source": "CRF", "title": "On learning parametric-output HMMs", "authors": ["Aryeh Kontorovich"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 130 2,60 09"}, {"heading": "1 Introduction", "text": "It is a standard tool in the modeling and analysis of time series with a variety of applications. If the number of hidden states is known, the standard method for estimating the HMM parameters from given observed data is the Tree-Welch algorithm [Baum et al., 1970]. The latter is known to suffer from two serious disadvantages: convergence (i) very slow and (ii) only to a local maximum. In fact, the problem of restoring the parameters of a general HMM is demonstrably hard, in several different senses and senses [Abe and Warmuth, 1992, Lyngs\u00f6 and Pedersen, 2001, Terwijn, 2002]. In this paper we consider learning parametric-output HMMs with a limited and known number of hidden states, where the output from each hidden state follows a particular family."}, {"heading": "2 Problem Setup", "text": "The notation: If X-X and Y-Y take values in a separate group, we abbreviate P (x) for Pr (X = x) and P (y | x) for Pr (Y = y | X = x). If Y-Y is continuously evaluated, we use P (y | x) to denote the probability density function of Y.Because x, w-Rn, diag (x) stands for the n \u2212 n diagonal matrix with the entries xi on its diagonal, x / w is the vector with the entries xi / wi, and vice versa x-2w = x-iwix 2 i is a w-weighted number sequence (for wi > 0)."}, {"heading": "3 Learning Parametric-Output HMMs", "text": "The standard approach to learning the parameters of an HMM is to maximize the probability \u2211 x [n] T P0 (x0) P (y0 | x0) T \u2212 1 \u0441t = 1axe, xt \u2212 1P (yt | xt).As discussed in the introduction, this problem is generally mathematically difficult. In practice, the small effects of the initial distribution P0 (x0) on the probability A and F\u03b8n are usually estimated via the tree-welch algorithm, which is computationally slow and only guaranteed to converge to a local maximum."}, {"heading": "3.1 A Decoupling Approach", "text": "In the following, we show that if the output distributions are parametric, we can decouple the HMM learning task in two steps: learning the output parameter Phenomenon 1, followed by learning the transition probabilities of HMM. Under some mild structural assumptions about HMM, this decoupling implies that the difficulty of learning a parametric output parameter HMM can be reduced to learning a parametric mixing model. In fact, we propose an efficient, unique, statistically consistent algorithm for estimating the transition matrix. As an example, we consider learning a Gaussian HMM with univariable output quantities. While the Tree-Welch approach collectively estimates n2 + 2n parameters (the matrix 1 and the parameters 1, 2i), our decoupling approach is initially adjusted to a mixing model with only 3n parameters."}, {"heading": "3.2 Learning the output parameters.", "text": "Assumptions (1a, 1b) imply that the Markov chain is mixed over the hidden states, and so, after only a few time steps, the distribution of Xt is very close to stationary. Assuming that X0 is already sampled from the stationary distribution, or alternatively the first few results are neglected, this implies that any observable Yt is a random realization from the following parametric mixing model. (2) It follows that, given the output sequence (Yt) T \u2212 1 t = 0, one can estimate the output parameters \u03b8i and the stationary distribution \u03c0i by adapting a mixing model of form (2) to the observations, which is usually done via the EM algorithm. Like its more sophisticated cousin Baum-Welch, we assume that the mixing learning algorithm MV also suffers from local maxims."}, {"heading": "3.3 Learning the transition matrix A", "text": "Next, we describe how to restore the matrix A, which has either exact or approximate knowledge of the HMM output probabilities. (To ensure clarity and completeness, we must first specify an estimation method for the stationary distribution.) In this case, we can replace the number of output states with a m \u00b7 n column stochastic matrix B, so that the probability of observing an output is k, since the Markov chain is in the hidden state i. In what follows, we assume that the number of output states is greater or equal to the number of hidden states, and that the m \u00b7 n matrix B has the full order n. The latter is the discrete analogy of the assumption (1c) that since matrix A has a stationary distribution, and the process Yt also has a stationary distribution."}, {"heading": "4 Error analysis", "text": "First, we study the statistical properties of our estimators under the premise that the initial parameters, (2), (3), (3), (4), (4), (4), (4), (4), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5, (5), (5), (5, (5), (5), (5, (5), (5, (5), (5), (5), (5, (5), (5), (5), (5, (5), (5, (5), (5), (5), (5, (5), (5), (5, (5), (5), (5"}, {"heading": "5 Simulation Results", "text": "We look at a toy example with n = 4 hidden states, the results of which are univariate Gaussians, N (\u00b5i, \u03c32i), N (\u2212 4, 4) f2 = N (0, 1) f3 = N (2, 36) f4 = N (4, 1) f4 = N (4, 1) p = (0.3529, 0.2941, 0.2353, 0.1176).Figure 1 shows the mixture and its four components. (3Available at http: / / www.cs.ubc.ubc.ca / ~ murphyk and http: / www.mathworks.com /."}, {"heading": "6 Appendix", "text": "We will now give a detailed description of the theorems mentioned in section 4."}, {"heading": "6.1 Preliminaries I", "text": "In what follows, we use the following notation: For a n \u00b7 n matrix A, vec (A) \u0432Rn2 is the result of stacking its columns vertically to a single long vector. Therefore, the Frobenius matrix norm is for a single long vector. It should also be remembered that the assumption (2b) states that the distributions in F\u03b8n are limited by L, which is by: max i \u00b2 [n] sup y \u00b2 Rf\u03b8i (y) \u2264 L <. The following concentration results from Kontorovich and Weiss [2012, Theorem 1] is our main instrument for detecting the error boundaries in F\u03b8n defined by L."}, {"heading": "6.2 Accuracy of \u03c1\u0302, \u03c3\u0302, \u03be\u0302 and \u03b7\u0302", "text": "The following results show that geometric ergodicity is sufficient to ensure its rapid convergence to true values. Let's (yt) T = be an observed sequence of a discrete result HMM, whose initial state X0 follows the stationary distribution. Let's (3) and (4) follow the stationary distribution with their empirical estimates, which are given in (5). ThenE [n) T [n] - a sequence of a discrete result HMM (33) E [n]. Let's (3) and (4) follow the stationary distribution with their empirical estimates given in (5). ThenE [n] - a sequence of (2)."}, {"heading": "6.3 Proof of theorem 1 - Strong consistency", "text": "We now prove the strong consistency of our estimators set forth in Theorem 1.Evidence. For the individual case, the expectations of Lemon 3 converge with the conclusion that the expectation of E [1 / x) and B) converge. The same argument also applies to the expectation of B (x) and B (x) - 11 is continuously converging to Rm +. Furthermore, f (x) = \u03c0 since the optimization problem (7) has a unique minimizer x for all cases, which is given in particular by x (x) = (x) when the consistency of B (1 / x) \u2212 11 is continuous. Since the argument above shows that the consistency of Rm (7) is almost certain, we have a unique minimizer x for all cases, which is given in particular by x (x) when the consistency of B (1 / x) -11 is given."}, {"heading": "6.4 Proof of Theorem 2: Bounding the error for \u03c0\u0302 in the discrete observations case", "text": "Evidence: Lemma 3 and the fact that we can't agree on a solution means we can't agree on a solution. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "6.5 Preliminaries II", "text": "The remaining estimators (\u03c0 for the case of continuous observations and A \u00b2 for the case of discrete and continuous observations) are obtained as solutions for quadratic programs. Take, for example, the QP for the calculation of p \u00b2 with continuous observations HMM, given in (23). Note that if the solution of the QP were equal to its true values, the solution of the above-mentioned QP is simply subject to the true p \u00b2 = argmin x1 x \u00b2 K \u00b2 -x \u00b2 K \u00b2. In reality, we only have the estimate. To analyze the error, we must consider how the solutions of such a quadratic program are affected by errors related to quadratic programs. More generally, we are dealing with two QPsminQ (x) = min 12 x \u00b2 MX \u00b2 h, (47) min \u00b2 -Q \u00b2 -x \u00b2 value."}, {"heading": "6.6 Proof of Theorem 3: Bounding the error for \u03c0\u0302 in the continuous observations case", "text": "Proof: Note that in the notation given in Theorem 7, we have h = VP and h = VP K. Since we have assumed that the output density parameters are exactly known, we have no error in M = K K. From Lemma 4, we immediately have min (K'K) = V '21 (K), and vice versa, that the output density parameters are exactly known, and from Theorem 7, that we have no errors in M = K'K. Since Lemma 4, we have no more errors in K' 21 (K) and K '21 (K). As a side note, we note that the form of (24) is somewhat counterproductive, as it suggests a worse behavior for larger L'K'K' (1 + 2). Since the assertion follows, the assertion results in the following consequence.As a side note, we point out that the form of (24) behaves somewhat counterintuitively, as it implies a worse behavior for larger L."}, {"heading": "6.7 Proof of Theorem 4: Bounding the error of A\u0302 in the discrete observations case", "text": "It should be remembered that the above-mentioned QP terms could be written in exactly the same way as the above-mentioned QP terms. In reality, as we only have estimates, the optimization problem is called into question. \u2212 vec (A) h (49), where M = C C vec and h = C vec (2), where M vec and h = C vec (2), where M vec and h = C vec (2), exactly the transition probability matrix A. In reality, as we only have estimates, the optimization problem is called into question. \u2212 vec (A), where M vec and h = C vec vec (A), vec vec vec (A), vec vec vec (A) \u2212 vec (A)."}, {"heading": "6.8 Proof of Theorem 5: Bounding the error of A\u0302 in the continuous observations case", "text": "s solve min Aij (0), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p), p (2), p), p), p), p (2), p), p), p), p), p), p), p (2), p), p (2), p), p), p), p), p), p), p), p), p), p), p), p), p), p (2), p), p), p), p), p)."}, {"heading": "6.9 Proof of Theorem 6: Perturbations in the output parameters", "text": "We cite here the proof for the disturbance in the matrix F. The proof for disturbances in the matrix K is similar. Proof. Using the definitions of C and C, up to the first order in the matrix F, and b, ij = k, k, kk, kk, kk, kk, kk, kk, kk, kk, kk, kk, kk, kk, kk, kk, kk, kk, k, kk, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k, k"}], "references": [{"title": "On the computational complexity of approximating distributions by probabilistic automata", "author": ["N. Abe", "M.K. Warmuth"], "venue": "Machine Learning,", "citeRegEx": "Abe and Warmuth.,? \\Q1992\\E", "shortCiteRegEx": "Abe and Warmuth.", "year": 1992}, {"title": "A method of moments for mixture models and hidden markov models", "author": ["A. Anandkumar", "D. Hsu", "S.M. Kakade"], "venue": "In COLT,", "citeRegEx": "Anandkumar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Anandkumar et al\\.", "year": 2012}, {"title": "A maximization technique occurring in the statistical analysis of probabilistic functions of Markov chains", "author": ["L.E. Baum", "T. Petrie", "G. Soules", "N. Weiss"], "venue": "Ann. Math. Stat.,", "citeRegEx": "Baum et al\\.,? \\Q1970\\E", "shortCiteRegEx": "Baum et al\\.", "year": 1970}, {"title": "Polynomial learning of distribution families", "author": ["M. Belkin", "K. Sinha"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "Belkin and Sinha.,? \\Q2010\\E", "shortCiteRegEx": "Belkin and Sinha.", "year": 2010}, {"title": "Inference in hidden Markov models", "author": ["O. Capp\u00e9", "E. Moulines", "T. Ryd\u00e9n"], "venue": null, "citeRegEx": "Capp\u00e9 et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Capp\u00e9 et al\\.", "year": 2005}, {"title": "Full reconstruction of Markov models on evolutionary trees: identifiability and consistency", "author": ["J.T. Chang"], "venue": "Math. Biosci.,", "citeRegEx": "Chang.,? \\Q1996\\E", "shortCiteRegEx": "Chang.", "year": 1996}, {"title": "Learning hidden Markov models using nonnegative matrix factorization", "author": ["G. Cybenko", "V. Crespi"], "venue": "IEEE Trans. Information Theory,", "citeRegEx": "Cybenko and Crespi.,? \\Q2011\\E", "shortCiteRegEx": "Cybenko and Crespi.", "year": 2011}, {"title": "Stability of the solution of definite quadratic programs", "author": ["J.W. Daniel"], "venue": "Mathematical Programming,", "citeRegEx": "Daniel.,? \\Q1973\\E", "shortCiteRegEx": "Daniel.", "year": 1973}, {"title": "On the continuity of the minimum sets of a continuous function", "author": ["G.B. Dantzig", "J. Folkman", "N. Shapiro"], "venue": "J. Math. Anal. Appl.,", "citeRegEx": "Dantzig et al\\.,? \\Q1967\\E", "shortCiteRegEx": "Dantzig et al\\.", "year": 1967}, {"title": "Interior point approach to linear, quadratic and convex programming, volume 277 of Mathematics and its Applications", "author": ["D. den Hertog"], "venue": null, "citeRegEx": "Hertog.,? \\Q1994\\E", "shortCiteRegEx": "Hertog.", "year": 1994}, {"title": "Asymptotics of the maximum likelihood estimator for general hidden Markov models", "author": ["R. Douc", "C. Matias"], "venue": "Bernoulli, 7(3):pp", "citeRegEx": "Douc and Matias.,? \\Q2001\\E", "shortCiteRegEx": "Douc and Matias.", "year": 2001}, {"title": "An algorithm to find the global optimum of left-to-right hidden Markov model parameters", "author": ["A. Farag\u00f3", "G. Lugosi"], "venue": "Problems Control Inform. Theory/Problemy Upravlen. Teor. Inform.,", "citeRegEx": "Farag\u00f3 and Lugosi.,? \\Q1989\\E", "shortCiteRegEx": "Farag\u00f3 and Lugosi.", "year": 1989}, {"title": "A spectral algorithm for learning hidden markov models", "author": ["D. Hsu", "S.M. Kakade", "T. Zhang"], "venue": "In COLT,", "citeRegEx": "Hsu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2009}, {"title": "Uniform Chernoff and Dvoretzky-KieferWolfowitz-type inequalities for Markov chains and related processes, arxiv:1207.4678", "author": ["A. Kontorovich", "R. Weiss"], "venue": null, "citeRegEx": "Kontorovich and Weiss.,? \\Q2012\\E", "shortCiteRegEx": "Kontorovich and Weiss.", "year": 2012}, {"title": "Non-negative matrix factorization for parameter estimation in hidden markov models", "author": ["B. Lakshminarayanan", "R. Raich"], "venue": "In Machine Learning for Signal Processing (MLSP), pages", "citeRegEx": "Lakshminarayanan and Raich.,? \\Q2010\\E", "shortCiteRegEx": "Lakshminarayanan and Raich.", "year": 2010}, {"title": "Complexity of comparing hidden markov models", "author": ["R.B. Lyngs\u00f8", "C.N. Pedersen"], "venue": "In Proceedings of the 12th International Symposium on Algorithms and Computation,", "citeRegEx": "Lyngs\u00f8 and Pedersen.,? \\Q2001\\E", "shortCiteRegEx": "Lyngs\u00f8 and Pedersen.", "year": 2001}, {"title": "Stability bounds for stationary \u03c6-mixing and \u03b2-mixing processes", "author": ["M. Mohri", "A. Rostamizadeh"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Mohri and Rostamizadeh.,? \\Q2010\\E", "shortCiteRegEx": "Mohri and Rostamizadeh.", "year": 2010}, {"title": "Settling the polynomial learnability of mixtures of gaussians", "author": ["Ankur Moitra", "Gregory Valiant"], "venue": "IEEE 51st Annual Symposium on Foundations of Computer Science,", "citeRegEx": "Moitra and Valiant.,? \\Q2010\\E", "shortCiteRegEx": "Moitra and Valiant.", "year": 2010}, {"title": "Learning nonsingular phylogenies and hidden Markov models", "author": ["E. Mossel", "S. Roch"], "venue": "Ann. Appl. Probab.,", "citeRegEx": "Mossel and Roch.,? \\Q2006\\E", "shortCiteRegEx": "Mossel and Roch.", "year": 2006}, {"title": "Interior-point polynomial algorithms in convex programming", "author": ["Y. Nesterov", "A. Nemirovskii"], "venue": null, "citeRegEx": "Nesterov and Nemirovskii.,? \\Q1994\\E", "shortCiteRegEx": "Nesterov and Nemirovskii.", "year": 1994}, {"title": "Readings in speech recognition. chapter A tutorial on hidden Markov models and selected applications in speech recognition, pages", "author": ["L.R. Rabiner"], "venue": null, "citeRegEx": "Rabiner.,? \\Q1990\\E", "shortCiteRegEx": "Rabiner.", "year": 1990}, {"title": "A unifying review of linear gaussian models", "author": ["S. Roweis", "Z. Ghahramani"], "venue": "Neural Comput.,", "citeRegEx": "Roweis and Ghahramani.,? \\Q1999\\E", "shortCiteRegEx": "Roweis and Ghahramani.", "year": 1999}, {"title": "Reduced-rank Hidden Markov Models", "author": ["S.M. Siddiqi", "B. Boots", "G.J. Gordon"], "venue": "In AISTAT,", "citeRegEx": "Siddiqi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Siddiqi et al\\.", "year": 2010}, {"title": "On the learnability of Hidden Markov Models", "author": ["S. Terwijn"], "venue": "In Proceedings of the 6th International Colloquium on Grammatical Inference: Algorithms and Applications,", "citeRegEx": "Terwijn.,? \\Q2002\\E", "shortCiteRegEx": "Terwijn.", "year": 2002}, {"title": "The following concentration result from Kontorovich and Weiss [2012, Theorem 1] is our main tool in proving the error bounds given here", "author": ["\u2264 L"], "venue": "Let Y = Y0,", "citeRegEx": "\u221e.,? \\Q2012\\E", "shortCiteRegEx": "\u221e.", "year": 2012}], "referenceMentions": [{"referenceID": 2, "context": "When the number of hidden states is known, the standard method for estimating the HMM parameters from given observed data is the Baum-Welch algorithm [Baum et al., 1970].", "startOffset": 150, "endOffset": 169}, {"referenceID": 8, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein.", "startOffset": 0, "endOffset": 26}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein.", "startOffset": 27, "endOffset": 51}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999].", "startOffset": 27, "endOffset": 216}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999].", "startOffset": 27, "endOffset": 232}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al.", "startOffset": 27, "endOffset": 262}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001].", "startOffset": 27, "endOffset": 486}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001].", "startOffset": 27, "endOffset": 500}, {"referenceID": 2, "context": "Moitra and Valiant [2010], Belkin and Sinha [2010] and references therein. Related work. The problem of estimating HMM parameters from observations has been actively studied since the 1970\u2019s, see Capp\u00e9 et al. [2005], Rabiner [1990], Roweis and Ghahramani [1999]. While computing the maximumlikelihood estimator for an HMM is in general computationally intractable, under mild conditions, such an estimator is asymptotically consistent and normally distributed, see Bickel et al. [1998], Chang [1996], Douc and Matias [2001]. In recent years, there has been a renewed interest in learning HMMs, in particular under various assumptions that render the learning problem tractable [Farag\u00f3 and Lugosi, 1989, Hsu et al.", "startOffset": 27, "endOffset": 524}, {"referenceID": 1, "context": ", 2010, Anandkumar et al., 2012]. Also, Cybenko and Crespi [2011], Lakshminarayanan and Raich [2010] recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs.", "startOffset": 8, "endOffset": 66}, {"referenceID": 1, "context": ", 2010, Anandkumar et al., 2012]. Also, Cybenko and Crespi [2011], Lakshminarayanan and Raich [2010] recently suggested Non-negative Matrix Factorization (NNMF) approaches for learning HMMs.", "startOffset": 8, "endOffset": 101}, {"referenceID": 16, "context": "However, if these are algorithmically stable \u2014 as such methods typically are \u2014 the iid assumption can be replaced by strong mixing [Mohri and Rostamizadeh, 2010].", "startOffset": 131, "endOffset": 161}, {"referenceID": 3, "context": "Belkin and Sinha [2010]).", "startOffset": 0, "endOffset": 24}, {"referenceID": 19, "context": "(6) Since \u2212 log(x) is convex, (Bx)k is a linear combination of the unknown variables xj , and the constraints are all linear, the above is nothing but a convex program, easily solved via standard optimization methods [Nesterov and Nemirovskii, 1994].", "startOffset": 217, "endOffset": 249}], "year": 2013, "abstractText": "We present a novel approach to learning an HMM whose outputs are distributed according to a parametric family. This is done by decoupling the learning task into two steps: first estimating the output parameters, and then estimating the hidden states transition probabilities. The first step is accomplished by fitting a mixture model to the output stationary distribution. Given the parameters of this mixture model, the second step is formulated as the solution of an easily solvable convex quadratic program. We provide an error analysis for the estimated transition probabilities and show they are robust to small perturbations in the estimates of the mixture parameters. Finally, we support our analysis with some encouraging empirical results.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}