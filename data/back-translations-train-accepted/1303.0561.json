{"id": "1303.0561", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2013", "title": "Top-down particle filtering for Bayesian decision trees", "abstract": "Decision tree learning is a popular approach for classification and regression in machine learning and statistics, and Bayesian formulations---which introduce a prior distribution over decision trees, and formulate learning as posterior inference given data---have been shown to produce competitive performance. Unlike classic decision tree learning algorithms like ID3, C4.5 and CART, which work in a top-down manner, existing Bayesian algorithms produce an approximation to the posterior distribution by evolving a complete tree (or collection thereof) iteratively via local Monte Carlo modifications to the structure of the tree, e.g., using Markov chain Monte Carlo (MCMC). We present a sequential Monte Carlo (SMC) algorithm that instead works in a top-down manner, mimicking the behavior and speed of classic algorithms. We demonstrate empirically that our approach delivers accuracy comparable to the most popular MCMC method, but operates more than an order of magnitude faster, and thus represents a better computation-accuracy tradeoff.", "histories": [["v1", "Sun, 3 Mar 2013 20:36:44 GMT  (6100kb,D)", "https://arxiv.org/abs/1303.0561v1", null], ["v2", "Thu, 22 Aug 2013 23:10:00 GMT  (6099kb,D)", "http://arxiv.org/abs/1303.0561v2", "ICML 2013"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["balaji lakshminarayanan", "daniel m roy", "yee whye teh"], "accepted": true, "id": "1303.0561"}, "pdf": {"name": "1303.0561.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["DANIEL M. ROY"], "emails": [], "sections": [{"heading": null, "text": "Unlike classic decision tree learning algorithms such as ID3, C4.5, and CART, which work from top to bottom, existing Bayesian algorithms generate an approximation of the posterior distribution by iteratively developing a complete tree (or its capture) using local Monte Carlo modifications to the structure of the tree, for example, using the Markov Monte Carlo chain (MCMC). We present a Monte Carlo sequential algorithm (SMC) that works from top to bottom instead, mimicking the behavior and speed of classical algorithms. We demonstrate empirically that our approach delivers accuracy comparable to the most popular MCMC method, but working faster than an order of magnitude, and thus represents a better compromise between compression and accuracy."}, {"heading": "1. Introduction", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a city and in which it is a country."}, {"heading": "2. Model and notation", "text": "In this section, we present the decision tree model for the distribution of the labels Y = {yn} Nn = 1 corresponding to input vectors X = {xn} Nn = 1. Assuming that the probable allocation of input vectors to their labels is mediated by a latent decision tree T, which serves to divide the input space into a single root. Each block is then associated with a parameter that determines the distribution of the input vectors that fall into this block. A rooted, strictly binary tree T is a finite tree with a single root denoted by the empty string, with each internal node p having exactly two children, called the left child p0 and the right child p1. Denote the leaves of T (these nodes without children) are associated by the individual nodes of the tree p.T."}, {"heading": "3. Sequential Monte Carlo (SMC) for Bayesian decision trees", "text": "In this section we describe an SMC algorithm to approximate the posterior distribution to the decision tree (T, \u0440, \u03c4) in view of the designated training data (X, Y). (We refer the reader to (Cap) and al., 2007) for an excellent overview of the SMC techniques.) The approach we choose is to perform particle filtering according to the sequential description of the previous process. (Especially in phase i, where the particles approximate a modified posterior distribution, in which the previous distribution of (T, N) is replaced by the distribution of (Ti, i, \u03c4i), i.e., the process is initiated in phase i. Let me denote the amount of unstopped leaves in stage i, all of which are eligible for expansion. An important freedom we have in our SMC algorithm is the choice of which candidates we choose (or set Ci egg of the candidates) to consider an extension in 2006 (Del et), a high morality."}, {"heading": "4. Experiments", "text": "In this section we evaluate experimentally the design decisions of the SMC algorithm (1998), using the approach of the number of particles and \"islands\" on real datasets, comparing the performance of the SMC with the most popular strategies of the MCMC method for selecting decision-making techniques (Chipman et al., 1998), as well as CART, a popular (non-Bayesian) expansion algorithm. We evaluate all algorithms on the following datasets from the UCI ML repository (Asuncion et al., 2007): \u2022 MAGIC gamma telescope data 2004 (magic-04): N = 19020, K = 2. Pen-based recognition of handwritten numerals (pen digits): N = 10992, D = 16, K = 10.Previous work has mainly on small datasets (e.g., the Wisconsin breast cancer database used by Chipet al)."}, {"heading": "5. Discussion and Future work", "text": "The algorithms mimic classic top-down algorithms for learning decision trees, but use \"local\" probabilities along with resampling steps to control tree growth. We have also shown good computational and statistical performance, especially compared to a state-of-the-art MCMC inference algorithm. Our algorithms are easier to implement than their MCMC counterparts, whose efficient implementations require sophisticated accounting. We have also examined various design options that lead to different SMC algorithms. We found that expanding too many nodes simultaneously yielded degraded performance and more complex methods for selecting nodes. While the one-step optimal proposal often requires fewer particles to achieve a certain accuracy, it was significantly more compact than the previous proposal, resulting in a less efficient algorithm overall on records with few irrelevant inputs."}, {"heading": "Acknowledgments", "text": "We would like to thank Charles Blundell, Arnaud Doucet, David Duvenaud, Jan Gasthaus, Hong Ge, Zoubin Ghahramani and James Robert Lloyd for helpful discussions and feedback on designs. DMR is supported by a Newton International Fellowship and Emmanuel College. BL and YWT gratefully accept generous funds from the Gatsby Charitable Foundation."}, {"heading": "Appendix A. SMC algorithm", "text": "algorithm 1 SMC for Bayesian decision tree learningInputs: training data (X, Y) Number of particles M initialized: T (m) 0 = E (m) 0 = {} \u03c4 (m) 0 = E (m) 0 = E (m) 0 = E (m) 0 = F (Y | T (m) 0) W0 = E (m) 0for i = 1: MAX-STAGES do for m = 1: M doSample T (m) i from Qi (\u00b7 | T (m) i \u2212 1) where T (m) i: = (T (m) i (m) i (m) i, E (m) i \u2212 m) actualization weights: (Here P, Qi denote their density.) w (m) i = P (m) i (T (m) i (m) i (T (m) i (m) m (m), m (m), m (m), m (m (m), m (m), m (m), m (m, m (m), m (m), m (m), m (m), m (T), T (m), T (m), T (m (m), T), T (m (m), T (m (m), T), T (m (m (m), T), T (m (m), T (m (m), T (m), T (m (m), T (m (m), T), T (m (m (m), m (m (m), m (m), m, m (m (m, m, m, m, m, m, m (m, m, m, m), m, m (m, m, m, m), m (m (m, m, m), m (m, m), m (m, m, m (m, m), m (m (m, m), m (m, m (m, m, m), m (m, m (m, m), m (m, m, m, m, m), m (m (m, m), m (m (m,"}, {"heading": "Appendix B. Effect of SMC proposal and expansion strategy on test", "text": "Accuracy The results are shown in Figure 6.Appendix C. Effect of the number of islands: magic-04 dataset The results are shown in Figure 7."}, {"heading": "Appendix D. Marginal likelihood", "text": "The log marginal probability of training data for different suggestions is shown in Figure 8. As the number of particles increases, the log marginal probability for previous and optimal suggestions (as expected) approaches the same value."}, {"heading": "Appendix E. Sensitivity of results to choice of hyperparameters", "text": "In this experiment, we evaluate the sensitivity of the predictive comparison between SMC (previous and optimal proposal), MCMC and CART with respect to the selection of hyperparameters \u03b1 (Dirichlet concentration parameters) and \u03b1s, \u03b2s (tree priors). We consider only nodal expansion, since it consistently exceeded the layered expansion in our previous experiments. In the first variant, we fix \u03b1 = 5.0 (since we do not expect it to affect temporal results) and vary the hyperparameters from \u03b1s = 0.95, \u03b2s = 0.5 to \u03b1s = 0.8, \u03b2s = 0.2 (bold reflection of changes) and also consider the intermediate configurations \u03b1s = 0.95, \u03b2s = 0.2 and \u03b1s = 0.8, \u03b2s = 0.5. In the second variant, we fix the results of the prediction test as being better than those of the prediction test (prediction test). Figures 9, 12, 11 and 4.p are the bottom time (the old ones)."}], "references": [{"title": "BART: Bayesian additive regression trees", "author": ["H.A. Chipman", "E.I. George", "R.E. McCulloch"], "venue": "Ann. Appl. Stat.,", "citeRegEx": "Chipman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chipman et al\\.", "year": 2010}, {"title": "Sequential Monte Carlo samplers", "author": ["P. Del Moral", "A. Doucet", "A. Jasra"], "venue": "J. R. Stat. Soc. Ser. B Stat. Methodol.,", "citeRegEx": "Moral et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Moral et al\\.", "year": 2006}, {"title": "Comparison of resampling schemes for particle filtering", "author": ["R. Douc", "O. Capp\u00e9", "E. Moulines"], "venue": "In Image Sig. Proc. Anal.,", "citeRegEx": "Douc et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Douc et al\\.", "year": 2005}, {"title": "Greedy function approximation: a gradient boosting machine", "author": ["J.H. Friedman"], "venue": "Ann. Statist,", "citeRegEx": "Friedman.,? \\Q2001\\E", "shortCiteRegEx": "Friedman.", "year": 2001}, {"title": "Novel approach to nonlinear/nonGaussian Bayesian state estimation", "author": ["N.J. Gordon", "D.J. Salmond", "A.F.M. Smith"], "venue": "Radar Sig. Proc., IEE Proc. F,", "citeRegEx": "Gordon et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Gordon et al\\.", "year": 1993}, {"title": "Bayesian model averaging is not model combination", "author": ["T.P. Minka"], "venue": "MIT Media Lab note. http://research.microsoft.com/en-us/um/people/minka/ papers/bma.html,", "citeRegEx": "Minka.,? \\Q2000\\E", "shortCiteRegEx": "Minka.", "year": 2000}, {"title": "Induction of decision trees", "author": ["J.R. Quinlan"], "venue": "Machine Learning,", "citeRegEx": "Quinlan.,? \\Q1986\\E", "shortCiteRegEx": "Quinlan.", "year": 1986}, {"title": "C4.5: programs for machine learning", "author": ["J.R. Quinlan"], "venue": null, "citeRegEx": "Quinlan.,? \\Q1993\\E", "shortCiteRegEx": "Quinlan.", "year": 1993}, {"title": "The Mondrian process", "author": ["D.M. Roy", "Y.W. Teh"], "venue": "In Adv. Neural Information Proc. Systems,", "citeRegEx": "Roy and Teh.,? \\Q2009\\E", "shortCiteRegEx": "Roy and Teh.", "year": 2009}, {"title": "Dynamic trees for learning and design", "author": ["M.A. Taddy", "R.B. Gramacy", "N.G. Polson"], "venue": "J. Am. Stat. Assoc.,", "citeRegEx": "Taddy et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Taddy et al\\.", "year": 2011}, {"title": "Bayesian agglomerative clustering with coalescents", "author": ["Y.W. Teh", "H. Daum\u00e9 III", "D.M. Roy"], "venue": "In Adv. Neural Information Proc. Systems,", "citeRegEx": "Teh et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Teh et al\\.", "year": 2008}, {"title": "Bayesian CART: Prior specification and posterior simulation", "author": ["Y. Wu", "H. Tjelmeland", "M. West"], "venue": "J. Comput. Graph. Stat.,", "citeRegEx": "Wu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 6, "context": "Examples of classical approaches that learn single trees include ID3 (Quinlan, 1986), C4.", "startOffset": 69, "endOffset": 84}, {"referenceID": 7, "context": "5 (Quinlan, 1993) and CART (Breiman et al.", "startOffset": 2, "endOffset": 17}, {"referenceID": 3, "context": ", 1984), while methods that learn combinations of decisions trees include boosted decision trees (Friedman, 2001), Random Forests (Breiman, 2001), and many others.", "startOffset": 97, "endOffset": 113}, {"referenceID": 2, "context": ", 1984), while methods that learn combinations of decisions trees include boosted decision trees (Friedman, 2001), Random Forests (Breiman, 2001), and many others. Bayesian decision tree methods, like those first proposed by Buntine (1992), Chipman et al.", "startOffset": 98, "endOffset": 240}, {"referenceID": 0, "context": "Bayesian decision tree methods, like those first proposed by Buntine (1992), Chipman et al. (1998), Denison et al.", "startOffset": 77, "endOffset": 99}, {"referenceID": 0, "context": "Bayesian decision tree methods, like those first proposed by Buntine (1992), Chipman et al. (1998), Denison et al. (1998), and Chipman and McCulloch (2000), and more recently revisited by Wu et al.", "startOffset": 77, "endOffset": 122}, {"referenceID": 0, "context": "Bayesian decision tree methods, like those first proposed by Buntine (1992), Chipman et al. (1998), Denison et al. (1998), and Chipman and McCulloch (2000), and more recently revisited by Wu et al.", "startOffset": 77, "endOffset": 156}, {"referenceID": 0, "context": "Bayesian decision tree methods, like those first proposed by Buntine (1992), Chipman et al. (1998), Denison et al. (1998), and Chipman and McCulloch (2000), and more recently revisited by Wu et al. (2007), Taddy et al.", "startOffset": 77, "endOffset": 205}, {"referenceID": 0, "context": "Bayesian decision tree methods, like those first proposed by Buntine (1992), Chipman et al. (1998), Denison et al. (1998), and Chipman and McCulloch (2000), and more recently revisited by Wu et al. (2007), Taddy et al. (2011) and Anagnostopoulos and Gramacy (2012), cast the problem of decision tree learning into the framework of Bayesian inference.", "startOffset": 77, "endOffset": 226}, {"referenceID": 0, "context": "Bayesian decision tree methods, like those first proposed by Buntine (1992), Chipman et al. (1998), Denison et al. (1998), and Chipman and McCulloch (2000), and more recently revisited by Wu et al. (2007), Taddy et al. (2011) and Anagnostopoulos and Gramacy (2012), cast the problem of decision tree learning into the framework of Bayesian inference.", "startOffset": 77, "endOffset": 265}, {"referenceID": 0, "context": "In order to make straightforward comparisons with existing algorithms, we adopt the model proposed by Chipman et al. (1998). In this model, the prior distribution of the latent tree is defined conditionally on the given input vectors X (see Section 5 for a discussion of this dependence on X and its effect on the exchangeability of", "startOffset": 102, "endOffset": 124}, {"referenceID": 0, "context": "When defining the prior over decision trees given by Chipman et al. (1998), it will be necessary to refer to the \u201cextent\u201d of the data in a block.", "startOffset": 53, "endOffset": 75}, {"referenceID": 8, "context": "A similar approach was employed by Taddy et al. (2011) in the setting of online Bayesian decision trees.", "startOffset": 35, "endOffset": 55}, {"referenceID": 8, "context": "A similar approach was employed by Taddy et al. (2011) in the setting of online Bayesian decision trees. There are similarities also with the bottom-up SMC algorithms by Teh et al. (2008) and Bouchard-C\u00f4t\u00e9 et al.", "startOffset": 35, "endOffset": 188}, {"referenceID": 8, "context": "A similar approach was employed by Taddy et al. (2011) in the setting of online Bayesian decision trees. There are similarities also with the bottom-up SMC algorithms by Teh et al. (2008) and Bouchard-C\u00f4t\u00e9 et al. (2012). We next describe the rule for stopping or growing nodes, and the distribution of cuts.", "startOffset": 35, "endOffset": 220}, {"referenceID": 4, "context": "Informally, this choice would lead us to propose extensions to trees at each stage of the algorithm by sampling from the prior, so we will refer to this as the prior proposal kernel (aka the Bayesian bootstrap filter (Gordon et al., 1993)).", "startOffset": 217, "endOffset": 238}, {"referenceID": 0, "context": "In addition, we compare the performance of SMC to the most popular MCMC method for Bayesian decision tree learning (Chipman et al., 1998), as well as CART, a popular (non-Bayesian) tree induction algorithm. We evaluate all the algorithms on the following datasets from the UCI ML repository (Asuncion and Newman, 2007): \u2022 MAGIC gamma telescope data 2004 (magic-04 ): N = 19020, D = 10, K = 2. \u2022 Pen-based recognition of handwritten digits (pen-digits): N = 10992, D = 16, K = 10. Previous work has focused mainly on small datasets (e.g., the Wisconsin breast cancer database used by Chipman et al. (1998) has 683 data points).", "startOffset": 116, "endOffset": 605}, {"referenceID": 2, "context": "We also evaluated systematic resampling (Douc et al., 2005) but found that the performance was not significantly different.", "startOffset": 40, "endOffset": 59}, {"referenceID": 5, "context": "We believe that the deteriorating performance is due to model misspecification (axisaligned decision trees are hardly the \u2018right\u2019 model for handwritten digits) rather than the inference algorithm itself: \u2018better\u2019 Bayesian inference in a misspecified model might lead to a poorer solution (see (Minka, 2000) for a related discussion).", "startOffset": 293, "endOffset": 306}, {"referenceID": 0, "context": "In this experiment, we compare the SMC algorithms to the MCMC algorithm proposed by Chipman et al. (1998), which employs four types of Metropolis-Hastings proposals: grow (split a leaf node into child nodes), prune (prune a pair of leaf nodes belonging to the same parent), change (change the decision rule at a node) and swap (swap the decision rule of a parent with the decision rule of the child).", "startOffset": 84, "endOffset": 106}, {"referenceID": 9, "context": ", Taddy et al. (2011) demonstrated that their tree structured models yield similar performance as Gaussian processes and random forests.", "startOffset": 2, "endOffset": 22}, {"referenceID": 0, "context": "Bayesian additive regression trees (BART) (Chipman et al., 2010) are such a model class.", "startOffset": 42, "endOffset": 64}, {"referenceID": 0, "context": "Prior work has considered MCMC techniques for posterior inference (Chipman et al., 2010).", "startOffset": 66, "endOffset": 88}, {"referenceID": 8, "context": ", based on the Mondrian process (Roy and Teh, 2009), whose projectivity would re-establish exchangeability while allowing for efficient posterior computations that depend on data.", "startOffset": 32, "endOffset": 51}], "year": 2013, "abstractText": "Decision tree learning is a popular approach for classification and regression in machine learning and statistics, and Bayesian formulations\u2014 which introduce a prior distribution over decision trees, and formulate learning as posterior inference given data\u2014have been shown to produce competitive performance. Unlike classic decision tree learning algorithms like ID3, C4.5 and CART, which work in a top-down manner, existing Bayesian algorithms produce an approximation to the posterior distribution by evolving a complete tree (or collection thereof) iteratively via local Monte Carlo modifications to the structure of the tree, e.g., using Markov chain Monte Carlo (MCMC). We present a sequential Monte Carlo (SMC) algorithm that instead works in a top-down manner, mimicking the behavior and speed of classic algorithms. We demonstrate empirically that our approach delivers accuracy comparable to the most popular MCMC method, but operates more than an order of magnitude faster, and thus represents a better computation-accuracy tradeoff.", "creator": "LaTeX with hyperref package"}}}