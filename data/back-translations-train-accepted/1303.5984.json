{"id": "1303.5984", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Mar-2013", "title": "Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems", "abstract": "We study the problem of adaptive control of a high dimensional linear quadratic (LQ) system. Previous work established the asymptotic convergence to an optimal controller for various adaptive control schemes. More recently, for the average cost LQ problem, a regret bound of ${O}(\\sqrt{T})$ was shown, apart form logarithmic factors. However, this bound scales exponentially with $p$, the dimension of the state space. In this work we consider the case where the matrices describing the dynamic of the LQ system are sparse and their dimensions are large. We present an adaptive control scheme that achieves a regret bound of ${O}(p \\sqrt{T})$, apart from logarithmic factors. In particular, our algorithm has an average cost of $(1+\\eps)$ times the optimum cost after $T = \\polylog(p) O(1/\\eps^2)$. This is in comparison to previous work on the dense dynamics where the algorithm requires time that scales exponentially with dimension in order to achieve regret of $\\eps$ times the optimal cost.", "histories": [["v1", "Sun, 24 Mar 2013 19:56:49 GMT  (26kb)", "http://arxiv.org/abs/1303.5984v1", "16 pages"]], "COMMENTS": "16 pages", "reviews": [], "SUBJECTS": "stat.ML cs.LG math.OC", "authors": ["morteza ibrahimi", "adel javanmard", "benjamin van roy"], "accepted": true, "id": "1303.5984"}, "pdf": {"name": "1303.5984.pdf", "metadata": {"source": "CRF", "title": "Efficient Reinforcement Learning for High Dimensional Linear Quadratic Systems", "authors": ["Morteza Ibrahimi"], "emails": ["ibrahimi@stanford.edu", "adelj@stanford.edu", "bvr@stanford.edu"], "sections": [{"heading": null, "text": "In this paper, we look at the case where the matrices describing the dynamics of the QL system are sparse and their dimensions are large. We present an adaptive control scheme that, apart from logarithmic factors, reaches a regret limit of O (p \u221a T). Specifically, our algorithm has an average cost of (1 + 1) times the optimal cost according to T = polylog (p) O (1 / 2), compared to previous work on dense dynamics, where the algorithm takes time to scale exponentially with dimensions to achieve four times the optimal cost. We believe that our result has prominent applications in the emerging field of computerized advertising, particularly in the area of targeted online advertising and advertising on social networks."}, {"heading": "1 Introduction", "text": "In this thesis we address the problem of adaptive control of a high-dimensional linear system (QL)."}, {"heading": "2 Algorithm", "text": "At the beginning of episode i, the algorithm constructs a confidence set for episode i and applies the optimal control for the estimated parameter during episode i.The confidence set is constructed based on observations from the last episode, but the length of the episodes is chosen to allow geometrically more accurate estimates and shrinkage of the confidence factor in each episode. Follow the details of each step and the pseudo-code for the algorithm. Construction of trust is constructed only based on observations from the last episode, with the length of the episodes allowing increase geometrically. Let L (i) be the controllers selected for episode i."}, {"heading": "3 Main Results", "text": "In this section, we provide performance guarantees in terms of cumulative regret and learning accuracy for the presented algorithms. (To present the theorems, we must first present some assumptions about the system. Given that there is a solution for the following Lyapunov equation, we must find a solution for the following Lyapunov equation. (10) If the closed circuit system (A0 \u2212 B0L) is stable, then the solution for the above equation exists and the state vector x (t) has a normal stationary distribution with covariance. (10) We proceed by introducing an identifiable regulator. (Definition 3.1) For a low-cost matrix, it is 0 = [A0, B0]."}, {"heading": "4 Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Proof of Theorem 3.2", "text": "To prove this, we must first show a set of sufficient conditions for solving the problem. < < p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (1), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (0), p (1), p, p, p, p, p, p, p, p, p, p (1), p, p, p, p, p, p, p, p, p, p, p (1), p, p, p, p, p, p (1), p, p, p, p, p, p, p (1), p, p, p, p, p, p, p (1), p, p, p, p, p (1), p, p, p, p, p, p, p (1), p, p, p, p, p, p, p, p, p (1), p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p (0, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p (0, p, p, p), p, p, p, p, p, p, p (0, p, p, p, p, p, p, p, p, p"}, {"heading": "4.2 Proof of Theorem 3.3", "text": "The high-level idea of proof is similar to the proof of the main theorem in [1]. First, we give a decomposition for the gap between the costs obtained by the algorithm and the optimal costs. Then, we delimit each term of decomposition separately."}, {"heading": "4.2.1 Cost Decomposition", "text": "t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t) t (t) t (t) t (t) t) t (t) t (t) t (t) t (t) t) t (t) t (t) t (t) t) t (t) t (t) t (t) t (t) t) t (t) t (t) t (t) t) t (t (t) t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t) t (t (t) t) t (t) t) t (t) t (t (t) t) t (t) t) t (t (t) t (t) t) t (t) t (t (t) t (t) t (t) t) t (t) t) t (t) t (t) t (t (t) t (t (t) t) t (t) t) t (t) t (t) t (t (t) t) t (t (t) t (t) t (t) t (t) t) t (t) t (t) t (t (t) t) t (t (t)"}, {"heading": "4.2.2 Good events", "text": "We proceed by defining the following two events in the probability space, under which we can bind the terms C1, C2, C3. Then we provide a lower limit for the probability of these events. E1 = {\u04390-0-0-0-1 (i), for i-1}, E2 = {\u0435w (t), for 2 \u221a p log (T / \u03b4), for 1 \u2264 t \u2264 T + 1}."}, {"heading": "4.2.3 Technical lemmas", "text": "The following lemmas set upper limits for C1, C2, C3. Lemma 4.5. (29) Lemma 4.6. (29) Lemma 4.6. Below event E1, E2, the following values hold with probability at least 1 \u2212 \u03b4.C1, \u2264 128C (1 \u2212 \u03c1) 2 p log (T) logT. (30) Lemma 4.7. (29) Lemma 4.6. Below event E1, \u2012 E2, holds with probability at least 1 \u2212 \u03b4. (C3, \u2264 800 (C 1 \u2212 \u03c1) 5 2 k (1 \u2212 \u03c1) 2) \u00b7 1 + C Cmin \u00b7 log (pT)."}, {"heading": "Acknowledgments", "text": "The authors thank the anonymous reviewers for their insightful comments. A.J. is supported by a Caroline and Fabian Pease Stanford Graduate Fellowship."}, {"heading": "A Proof of technical lemmas", "text": "(1) The proof for Lemma 4.2As before is the proof for Lemma 4.2As before is the proof for Lemma 4.2How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (2) (1) How can we provide the proof? (1) How can we provide the proof? (1) How can we provide the proof? (2) How can we provide the proof."}, {"heading": "B Proof of Lemma 4.6", "text": "If the trust set is not updated at a time t + 1, i.e. if it is not + 1, then the number of updates (number of times ALGORITHM changes the guidelines) is at most log4 T up to a time T. If we use the bound K number, we have C2 = \u2212 T number = 0E [x (t + 1) T (K) \u2212 K (t + 1)) x (t + 1) | Ft] \u2264 i number of T2C numbers 2 \u2264 8C (1 \u2212 2) 2 p numbers (T) log4 T, (45) where we used Proposition A.3 in the last step."}, {"heading": "C Proof of Lemma 4.7", "text": "Let yt = [xTt, u T] T + 0T + 0T + 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T (T = 0T = 0T = 0T = 0T) 2T (T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T = 0T."}, {"heading": "D Proof of Lemma 4.8", "text": "We show first that P (E1) \u2264 1 \u2212 \u2264 p =. According to Theorem 3.2, the sample complexity scales with (1 / 2) log (q / \u03b4). Due to the choice of episode lengths in the algorithm, namely \u2206 \u03c4i = 4i (1 + i / log (q / \u03b4)) n1, with a probability of at least 1 \u2212 \u03b4 / 2i, we have d (0 \u2212 \u03b4 (i))) \u2264 2 \u2212 i2 \u2212 i2 and thus 0% (i).Let us now leave w (t).Rp is the noise vector at the time t with i.i.d standard entries. (P (E1) \u2265 1 \u2212 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 (l).For each t \u00b2 1 and each p \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 (l \u00b2)."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "<lb>We study the problem of adaptive control of a high dimensional linear quadratic<lb>(LQ) system. Previous work established the asymptotic convergence to an optimal<lb>controller for various adaptive control schemes. More recently, for the average<lb>cost LQ problem, a regret bound of O(<lb>\u221a<lb>T ) was shown, apart form logarithmic<lb>factors. However, this bound scales exponentially with p, the dimension of the<lb>state space. In this work we consider the case where the matrices describing the<lb>dynamic of the LQ system are sparse and their dimensions are large. We present<lb>an adaptive control scheme that achieves a regret bound of O(p<lb>\u221a<lb>T ), apart from<lb>logarithmic factors. In particular, our algorithm has an average cost of (1 + \u01eb)<lb>times the optimum cost after T = polylog(p)O(1/\u01eb). This is in comparison to<lb>previous work on the dense dynamics where the algorithm requires time that scales<lb>exponentially with dimension in order to achieve regret of \u01eb times the optimal cost.<lb>We believe that our result has prominent applications in the emerging area of<lb>computational advertising, in particular targeted online advertising and advertising<lb>in social networks.", "creator": "LaTeX with hyperref package"}}}