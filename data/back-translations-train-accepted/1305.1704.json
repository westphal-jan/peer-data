{"id": "1305.1704", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2013", "title": "The Extended Parameter Filter", "abstract": "The parameters of temporal models, such as dynamic Bayesian networks, may be modelled in a Bayesian context as static or atemporal variables that influence transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik's filter and a Kalman filter in parameter space and establish more general conditions under which Storvik's filter works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik's method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods.", "histories": [["v1", "Wed, 8 May 2013 03:21:31 GMT  (4611kb,D)", "http://arxiv.org/abs/1305.1704v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.AI", "authors": ["yusuf erol", "lei li", "bharath ramsundar", "stuart j russell"], "accepted": true, "id": "1305.1704"}, "pdf": {"name": "1305.1704.pdf", "metadata": {"source": "META", "title": "The Extended Parameter Filter", "authors": ["Yusuf B. Erol", "Lei Li", "Bharath Ramsundar", "Stuart Russell"], "emails": ["yberol@eecs.berkeley.edu", "leili@cs.berkeley.edu", "rbharath@stanford.edu", "russell@cs.berkeley.edu"], "sections": [{"heading": null, "text": "Yusuf B. Erol \u2020 yberol @ eecs.berkeley.edu Lei Li \u2020 leili @ cs.berkeley.edu Bharath Ramsundar rbharath @ stanford.eduComputer Science Department, Stanford University Stuart Russell \u2020 russell @ cs.berkeley.edu \u2020 EECS Department, University of California, BerkeleyAbstractThe parameters of temporal models, such as Bayesian dynamic networks, can be modeled in a Bayesian context as static or atemporal variables that affect the probabilities of transition at any time step. Particle filters fail in models that include such variables, while methods in which Gibbs uses the sample of parameter variables can cause cost per sample to grow linearly with the length of the observation sequence. Storvik (2002) developed a method for gradually calculating exact, sufficient in some cases, the cost per sample to be reduced to a constant. In this essay, we show a general linking between the filter and the storage conditions, as well as the filter conditions under the calcium conditions."}, {"heading": "1. Introduction", "text": "It is about the question to what extent people are able to get a grip on themselves and on others. (...) It is about the question to what extent they are able to survive themselves. (...) It is about the question to what extent they are able to survive themselves. (...) It is about the question to what extent they are able to survive themselves. (...) It is about the question to what extent they are able to survive themselves. (...) It is about the question to what extent they are able to survive themselves. (...) It is about the question to what extent they are able to survive themselves. (...) It is about the question to what extent is the question to be asked, to what is the question to what extent is the question to be asked, to what is the question to which is to what extent are they themselves and how are they themselves questioned. (...)"}, {"heading": "2. Background", "text": "In this section we discuss dynamic models for the state of the room and the basic framework of approximate filter algorithms."}, {"heading": "2.1. State-space model and filtering", "text": "Let us find a parameter space for a partially observable Markov process: {Xt} t \u2265 0, {Yt} t \u2265 0 as shown in Figure 1 and defined as follows: X0 \u0445 p (x0 | \u03b8) (1) Xt | xt \u2212 1 \u0445 p (xt | xt \u2212 1, \u03b8) (2) Yt | xt \u0445 p (yt | xt, \u03b8) (3) Here, the state variables Xt are not observed and the observations Yt are conditionally assumed independently of other observations that Xt has specified. In this section, we assume that the states Xt, observations Yt and the parameters \u03b8 are real vectors in d, m and p dimensions. Here, both the transition and sensor models are parameterized by \u03b8. To make it easier, in the following sections, we assume that only the transition model is parameterized (observations Yt, and parameters \u03b8); the results in this paper may, however, be covered by a model parameter to cover sensor parameters."}, {"heading": "2.2. Particle filtering", "text": "With known parameters, particle filters can approximate the posterior distribution over the hidden state Xt through a series of samples, the canonical example being the sequential meaning sampling resampling algorithm (SIR) (algorithm 1).The SIR filter has several appealing characteristics, it is modular, efficient, and easy to imple.The filter requires constant time per update, regardless of the time T, and since the number of particles is N \u2192 \u221e, the empirical filter density approaches the true limit density under appropriate assumptions. Particle filters can absorb unknown parameters by inserting parameter variables into the state vector using an \"identity function transition model.\" As mentioned in section 1, this approach leads to degeneration problems - especially with high-dimensional parameters Algorithm 1: Sequential Importance Sampling (SIR)."}, {"heading": "2.3. Storvik\u2019s algorithm", "text": "To avoid the degeneration problem, Storvik (2002) modifies the SIR algorithm by adding a Gibbs sampling step for \u03b8 conditioned on the state path in each particle (see algorithm 2).The algorithm is developed within the SIS framework and therefore inherits the theoretical guarantees of the SIS. Storvik considers unknown parameters in the state development model and assumes a perfectly known sensor model. \u2212 Its analysis can be generalized to unknown sensor models. Storvik's approach becomes efficient in an online setting when a fixed-dimensional sufficient statistical St for the statistical parameters exists (i.e. if p (\u03b8 | x0: t) = p (St)).The important property of this algorithm is that the parameter value simulated in due time does not depend on the previously simulated values. This property prevents the impoverishment of the parameter values in the particles."}, {"heading": "2.4. Separability", "text": "In this section, we define a condition under which there are efficient updates of the parameters. Here, too, we focus on the state space model as described in Figure 1 and Equation (3). The model in Equation (3) can also asxt = f\u03b8 (xt \u2212 1) + vtyt = g (xt) + wt (7) for some suitable f\u03b8, g, vt and wt.Definition 1. A system is separable if the transition function f\u03b8 (xt \u2212 1) can be written as f\u03b8 (xt \u2212 1) = l (xt \u2212 1) Th (\u03b8) for some l (\u00b7) and h (\u00b7) and if the stochastic i.d. noise vt has a log-polynomic density. Theorem 1. For a separable system, there are fixed dimensional sufficient statistics for the Gibbs density, p (\u03b8 | x0: T).The proof is either by the factorization theory of Fisher-Neyman and complementary details in the systems supplementary to the T."}, {"heading": "3. The extended parameter filter", "text": "It is evident that this transition model is not divisible if we align the transition function with a Taylor series near Zerofapolis (xt \u2212 1). We assume that we consider the transition model f\u03b8 (xt \u2212 1) to be inseparable. (xt \u2212 1) It is evident that this transition model is inseparable. (9) It is evident that this transition model is inseparable. (10) If we align the transition function with a Taylor series near Zerofummen (xt \u2212 1). (xt \u2212 1) It is evident that the transition period is inseparable. (9) and it becomes divisible."}, {"heading": "4. Approximating the conditional distribution of parameters", "text": "In this section, we construct approximately sufficient statistics for arbitrary one-dimensional state-space models. We do this by evaluating log-polynomial approximations to arbitrary probability densities. We prove that such approximations can be made with arbitrary precision. Afterwards, we analyze the error resulting from log-polynomial approximation to the arbitrary one-dimensional model."}, {"heading": "4.1. Taylor approximation to an arbitrary density", "text": "Let us assume a distribution p (known only up to a normalization constant) expressed in the form p (x) \u0445 exp (S (x)), where S (x) is an analytical function to support the distribution. Generally, we need a Monte Carlo method to take samples from this arbitrary density. In this section, we describe an alternative, simpler sampling method. We suggest that with a polynomial approximation P (x) (Taylor, Chebyshev, etc.) we can derive sufficient order to the function S (x) samples from a distribution p-Exp (P (x)) with a simpler (i.e. log-polynomial) structure. We show that the distance between distributions p and p decreases to 0 in the order of the approximation increases. The following theorem is based on Taylor approximations (P (x)); however, the theorem may have a generalized polyximation to any approximation."}, {"heading": "4.2. Online approximation of the Gibbs density of the parameter", "text": "In our analysis we proceed from the following model: xt = f\u03b8 (xt \u2212 1) + J = error, vt \u0445 N (0, \u03c32) yt = g (xt) + wt, wt \u0445 N (0, \u03c32o) The subsequent distribution for the static parameter isp (\u03b8 | x0: T), p (xt \u2212 1, \u03b8). The product concept requiring a linear time is the bottleneck for this calculation. A polynomial approximation to the transition function f\u03b8 (\u00b7 T) (the Taylor approximation to the transition function f\u03b8 (\u00b7 T), p (xt \u2212 1) = h (xt \u2212 1)."}, {"heading": "5. Experiments", "text": "The algorithm is implemented for three specific cases: Note that the models discussed do not meet the Gaussian process model assumption of Storvik (2002)."}, {"heading": "5.1. Single parameter nonlinear model", "text": "Consider the following model with the dynamics of the sinusoid transition (SIN): xt = sin (\u03b8xt \u2212 1) + vt, vt \u0445 N (0, \u03c32) yt = xt \u2212 wt, wt \u0445 N (0, \u03c32obs) (13), where \u03c3 = 1, \u03c3obs = 0.1 and the Gauss precedes the parameter \u03b8 N (0, 0.22). The observation sequence is shown by scanning SIN with the true parameter value \u03b8 = 0.7. Figure 3 shows how the Gibbs density p (\u03b8 | x0: t) shrinks in relation to time, verifying the identifiability of the particles for this model. Note that the densities at T are concentrated around the true parameter value. A Taylor approximation of \u03b8 = 0 was applied to the transition function sin (successxt). Figure 4 (a) shows the approximate density of the particles for different orders of polynominations."}, {"heading": "5.2. Cauchy dynamical system", "text": "We consider the following model.xt = axt \u2212 1 + Cauchy (0, \u03b3) (14) yt = xt + N (0, \u03c3obs) (15) Here Cauchy is the Cauchy distribution centered on 0 and with the form parameter \u03b3 = 1. We use a = 0.7, \u03c3obs = 10, with the previous one for the AR (1) parameter being N (0, 0.22) This model represents an auto-regressive time evolution with strong noise. Such strongly tailed sounds are observed in network traffic data and click stream data. We use the default Cauchy distribution isfv (v; 0, 1) = 1\u03c0 (1 + v2) = exp (\u2212 log (1 + v2) -log (1 + v2). We approach the Log (1 + v2) filter with v2 \u2212 v4 / 2 + v6 / 3 \u2212 v8 / 4 +."}, {"heading": "5.3. Smooth Transition AR model", "text": "The smooth transition AR (STAR) model is a smooth generalization of the self-agitating threshold autoregressive (SETAR) step = SETAR convergence of values (van Dijk et al., 2002). It is generally expressed as follows: xt = (a1xt \u2212 1 + a2xt \u2212 2 + \u00b7 + apxt \u2212 p) [G (xt \u2212 d; c)] + twhere t is i.i.d. Gaussian with mean zero and variance \u03c32 and G (\u00b7 \u00b7 b2xt \u2212 2 + bpxt \u2212 p) [G (xt \u2212 d; c)] + twhere t is i.i.d.d. Gaussian with mean zero and variance \u03c32 and G (\u00b7) is a non-linear function of xt \u2212 d, where d > 0 is mixed \u2212 p. We will use the logistic functionG (yt \u2212 d; g; c) = 11 + exp (xt) = exp (xt \u2212 HAR \u2212 d) \u2212 p \u2212 p \u2212 p \u2212 p."}, {"heading": "6. Conclusion", "text": "We have proposed the Advanced Parameter Filter (EPF), a novel approximate inference algorithm that combines Gibb's sampling of parameters with the calculation of approximately sufficient statistics. EPF refresh time is independent of the length of the observation sequence. In addition, the algorithm has detectable error limits and handles a variety of models. Our experiments confirm these properties and illustrate difficult cases in which EPF works well. One limitation of our algorithm is the complexity of the Taylor approach for high-dimensional parameter vectors. We found that in some cases the process can be broken down into low-dimensional partial problems."}, {"heading": "A. Storvik\u2019s filter as a Kalman filter", "text": "Consider the following model: xt = axe \u2212 1 + vt, vt \u0445 N (0, Q) yt = Hxt + wt, wt \u0445 N (0, R) (17) We will refer to the MMSE calman filter estimate as xt | t = E [xt | y0: t] and the variance Pt | t = cov (xt | y0: t). Then the conditional mean estimate is updated as follows: xt | t = axe \u2212 1 | t \u2212 1 + Pt | t \u2212 1H T (HPt | t \u2212 1H T + R) \u2212 1 Kt (yt \u2212 HAxe \u2212 1 | t \u2212 1), with respect to the estimate covariance Pt | t \u2212 1 = APt \u2212 1 | t \u2212 1A T + QPt | t = (I \u2212 KtH) Pt | t \u2212 1 (18) the adjustment of the above conditions to the updates in Equation 6 results in a model where the deviation Q = the deviation is the deviation, Q = the difference is the difference Q = the difference, Q = the difference is the difference."}, {"heading": "B. Proof of theorem 1", "text": "Suppose that x-Rd, \u03b8-Rp and f\u03b8 (\u00b7): Rd-Rd is a vector-weighted function parameterized by \u03b8. Furthermore, based on the assumption of separability f\u03b8 (xt \u2212 1) = l (xt \u2212 1) Th (\u03b8), assuming that l (\u00b7): Rd-Rm-d and h (\u00b7): Rp-Rm and m is an arbitrary constant, the stochastic error will have the logpolynomic density p (vt) and exp (vTt-2vt +.). Let's analyze the case of p (vt) and exp (vTt-2vt), for mathematical simplicity. Proof.log p (\u03b8 | x0: T) and exp (vTt-2vt)."}, {"heading": "C. Proof of theorem 2", "text": "Proposition 1: Let S (x) be an M + 1 times differentiable function and P (x) its order M (x) + R (x). Let I = (x \u2212 a, x + a) be an open interval by x. Let R (x) be the residual function, so that S (x) = P (x) + R (x). Suppose there is a constant U, so that there is (k + 1) (y) f (k + 1) (y) f (m + 1) f (x) x (m + 1)! Let us define the following terms = U aM + 1 (M + 1)! Z = I (S (x)) dxZ = I (P (x))) dx."}, {"heading": "D. Proof of theorem 3", "text": "Proof. log = 0 x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x."}, {"heading": "E. Proof of theorem 4", "text": "The proof. Suppose function f has limited derivatives and limited support, then the maximum error fulfils the following formula: (xk \u2212 1) - (xk \u2212 1) - (xk \u2212 1) - (xk \u2212 1) k. Then the KL divergence between the real rear and the approximated rear part fulfils the following formula: DKL (pT | | p \u00b2) - (19) - (1) - (xk \u2212 f \u00b2) - (xk \u2212 f \u00b2) - (xk \u2212 1) k. Then the KL divergence between the real rear and the approximated rear part fulfils the following formula: DKL (pT | p \u00b2 T) - (19) - (xk \u2212 f \u00b2) - (xk \u2212 f \u00b2) - (pT (xk \u2212 1) - (x0) - (x0) - (x0: T) - (x0: T) - (x0: T) - (x0: T) - (x0: T) - (- (T - -) - (pT - - - -) T (T - - - - -) (T (T - -) (T - - -) (T (T - -) (T - - - - - k - k - k - k - k - k - k - \u00b2 - (T) 1T (T) 1T (T - -) (T) (T - (T) (pT - - -)."}], "references": [{"title": "On-line parameter estimation in general state-space models", "author": ["C. Andrieu", "A. Doucet", "V. Tadic"], "venue": "In Proceedings of the 44th Conference on Decision and Control,", "citeRegEx": "Andrieu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2005}, {"title": "Particle Markov chain Monte Carlo methods", "author": ["Christophe Andrieu", "Arnaud Doucet", "Roman Holenstein"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Andrieu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2010}, {"title": "A tutorial on particle filters for on-line non-linear/non-Gaussian Bayesian tracking", "author": ["Sanjeev Arulampalam", "Simon Maskell", "Neil Gordon", "Tim Clapp"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Arulampalam et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Arulampalam et al\\.", "year": 2002}, {"title": "Particle Learning and Smoothing", "author": ["Carlos M. Carvalho", "Michael S. Johannes", "Hedibert F. Lopes", "Nicholas G. Polson"], "venue": "Statistical Science,", "citeRegEx": "Carvalho et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2010}, {"title": "A tutorial on particle filtering and smoothing: fifteen years later", "author": ["Arnaud Doucet", "Adam M. Johansen"], "venue": "The Oxford Handbook of Nonlinear Filtering,", "citeRegEx": "Doucet and Johansen.,? \\Q2011\\E", "shortCiteRegEx": "Doucet and Johansen.", "year": 2011}, {"title": "The extended parameter filter", "author": ["Yusuf Erol", "Lei Li", "Bharath Ramsundar", "Stuart J. Russell"], "venue": "Technical Report UCB/EECS-2013-48, EECS Department,", "citeRegEx": "Erol et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Erol et al\\.", "year": 2013}, {"title": "Following a moving target \u2013 Monte Carlo inference for dynamic bayesian models", "author": ["Walter R. Gilks", "Carlo Berzuini"], "venue": "Journal of the Royal Statistical Society. Series B (Statistical Methodology),", "citeRegEx": "Gilks and Berzuini.,? \\Q2001\\E", "shortCiteRegEx": "Gilks and Berzuini.", "year": 2001}, {"title": "A new approach to linear filtering and prediction problems", "author": ["Rudolf E. Kalman"], "venue": "Transactions of the ASME \u2013 Journal of Basic Engineering,", "citeRegEx": "Kalman.,? \\Q1960\\E", "shortCiteRegEx": "Kalman.", "year": 1960}, {"title": "Combined parameter and state estimation in simulation-based filtering", "author": ["Jane Liu", "Mike West"], "venue": "In Sequential Monte Carlo Methods in Practice", "citeRegEx": "Liu and West.,? \\Q2001\\E", "shortCiteRegEx": "Liu and West.", "year": 2001}, {"title": "Practical filtering with sequential parameter learning", "author": ["Nicholas G. Polson", "Jonathan R. Stroud", "Peter M\u00fcller"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Polson et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Polson et al\\.", "year": 2008}, {"title": "Monte Carlo Statistical Methods", "author": ["Christian P. Robert", "George Casella"], "venue": null, "citeRegEx": "Robert and Casella.,? \\Q2005\\E", "shortCiteRegEx": "Robert and Casella.", "year": 2005}, {"title": "Particle filters for state-space models with the presence of unknown static paramaters", "author": ["Geir Storvik"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Storvik.,? \\Q2002\\E", "shortCiteRegEx": "Storvik.", "year": 2002}, {"title": "Smooth transition autoregressive models \u2013 a survey of recent developments", "author": ["Dick van Dijk", "Timo Tersvirta", "Philip Hans Franses"], "venue": "Econometric Reviews,", "citeRegEx": "Dijk et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Dijk et al\\.", "year": 2002}, {"title": "An introduction to the Kalman filter", "author": ["Greg Welch", "Gary Bishop"], "venue": null, "citeRegEx": "Welch and Bishop.,? \\Q1995\\E", "shortCiteRegEx": "Welch and Bishop.", "year": 1995}], "referenceMentions": [{"referenceID": 10, "context": "Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant.", "startOffset": 0, "endOffset": 15}, {"referenceID": 10, "context": "Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant.", "startOffset": 0, "endOffset": 15}, {"referenceID": 2, "context": "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008).", "startOffset": 72, "endOffset": 125}, {"referenceID": 8, "context": "For example, the \u201cartificial dynamics\u201d approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of parameter space, but this may result in biased estimates.", "startOffset": 48, "endOffset": 68}, {"referenceID": 0, "context": "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution.", "startOffset": 21, "endOffset": 43}, {"referenceID": 0, "context": "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al.", "startOffset": 73, "endOffset": 1028}, {"referenceID": 0, "context": "quential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2008). In the machine learning context, model parameters may be represented by static parameter variables that define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) converges to a delta function at the true value in the limit of infinitely many observations. Unfortunately, particle filters fail for such models: the algorithm samples parameter values for each particle at time t= 0, but these remain fixed; over time, the particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009); Carvalho et al. (2010) describe several algorithms that have been proposed to solve this degeneracy problem, but the issue remains open because known algorithms either suffer from bias or computational inefficiency.", "startOffset": 73, "endOffset": 1052}, {"referenceID": 2, "context": "Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011).", "startOffset": 233, "endOffset": 286}, {"referenceID": 4, "context": "Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011).", "startOffset": 233, "endOffset": 286}, {"referenceID": 2, "context": "Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011). In the machine learning context, model parameters may be represented by static parameter variables tha define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) conv rges to a delta function at the true value in the li it of infinitely many observations. Unfortunately, particle filters fail for such models: the algorith samples p rameter values for each particle at time t= 0, but these remain fixed; over time, th particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009) and Carvalho et al.", "startOffset": 234, "endOffset": 1186}, {"referenceID": 2, "context": "Exact filtering is intractable except f r certain special c ses (linear\u2013Gaussian models and discrete HMMs), but appr ximate filterin using th p ticl filter (a sequential Monte Carlo method) is feasible in many realworld applications (Arulampalam et al., 2002; Doucet and Johansen, 2011). In the machine learning context, model parameters may be represented by static parameter variables tha define the transition and sensor model probabilities of the Markov process, but do not themselves change over time (Figure 1). The posterior parameter distribution (usually) conv rges to a delta function at the true value in the li it of infinitely many observations. Unfortunately, particle filters fail for such models: the algorith samples p rameter values for each particle at time t= 0, but these remain fixed; over time, th particle resampling process removes all but one set of values; and these are highly unlikely to be correct. The degeneracy problem is especially severe in high-dimensional parameter spaces, whether discrete or continuous. Hence, although learning requires inference, the most successful inference algorithm for temporal models is inapplicable. Kantas et al. (2009) and Carvalho et al. (2010) describe several algorithms that have been proposed to ar X iv :1 30 5.", "startOffset": 234, "endOffset": 1213}, {"referenceID": 8, "context": "For example, the \u201cartificial dynamics\u201d approach (Liu and West, 2001) introduces a stochastic transition model for the parameter variables, allowing exploration of the parameter space, but this may result in biased estimates.", "startOffset": 48, "endOffset": 68}, {"referenceID": 0, "context": "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution.", "startOffset": 21, "endOffset": 43}, {"referenceID": 1, "context": "The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence.", "startOffset": 28, "endOffset": 50}, {"referenceID": 6, "context": "The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables\u2014that is, in Figure 1, P (\u03b8 | X1, .", "startOffset": 28, "endOffset": 54}, {"referenceID": 0, "context": "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence. The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables\u2014that is, in Figure 1, P (\u03b8 | X1, . . . , XT ). This method requires O(T ) computation per sample, leading Gilks and Berzuini to propose a sampling rate proportional to 1/T to preserve constant-time updates. Storvik (2002) and Polson et al.", "startOffset": 22, "endOffset": 673}, {"referenceID": 0, "context": "Online EM algorithms (Andrieu et al., 2005) provide only point estimates of static parameters, may converge to local optima, and are biased unless used with the full smoothing distribution. The particle MCMC algorithm (Andrieu et al., 2010) converges to the true posterior, but requires computation growing with T , the length of the data sequence. The resample-move algorithm (Gilks and Berzuini, 2001) includes Gibbs sampling of parameter variables\u2014that is, in Figure 1, P (\u03b8 | X1, . . . , XT ). This method requires O(T ) computation per sample, leading Gilks and Berzuini to propose a sampling rate proportional to 1/T to preserve constant-time updates. Storvik (2002) and Polson et al. (2008) observe that a fixed-dimensional sufficient statistic (if one exists) for \u03b8 can be updated in constant time.", "startOffset": 22, "endOffset": 698}, {"referenceID": 5, "context": "All details of proofs are given in the appendix of the full version (Erol et al., 2013).", "startOffset": 68, "endOffset": 87}, {"referenceID": 11, "context": "To avoid the degeneracy problem, Storvik (2002) modifies the SIR algorithm by adding a Gibbs sampling step for \u03b8 conditioned on the state trajectory in each particle (see Algorithm 2).", "startOffset": 33, "endOffset": 48}, {"referenceID": 7, "context": "Matching terms with the standard KF update equations (Kalman, 1960), we find that the transition matrix for the KF is the identity matrix, the transition noise covariance matrix is the zero matrix, the observation matrix for the KF is Ft, and the observation noise covariance matrix is Q.", "startOffset": 53, "endOffset": 67}, {"referenceID": 5, "context": "See the supplementary material (Erol et al., 2013) for the derivation.", "startOffset": 31, "endOffset": 50}, {"referenceID": 5, "context": "The proof is straightforward by the Fisher\u2013Neyman factorization theorem; more details are given in the supplementary material of the full version (Erol et al., 2013).", "startOffset": 146, "endOffset": 165}, {"referenceID": 13, "context": "EKF linearizes nonlinear transitions around the current estimates of the mean and covariance and uses Kalman filter updates for state estimation (Welch and Bishop, 1995).", "startOffset": 145, "endOffset": 169}, {"referenceID": 10, "context": "We suggest slice sampling (Neal, 2003) or the MetropolisHastings algorithm (Robert and Casella, 2005) for this purpose.", "startOffset": 75, "endOffset": 101}, {"referenceID": 5, "context": "The proof is given in (Erol et al., 2013).", "startOffset": 22, "endOffset": 41}, {"referenceID": 5, "context": "The proof is given in the supplementary material (Erol et al., 2013).", "startOffset": 49, "endOffset": 68}, {"referenceID": 11, "context": "Note that the models discussed do not satisfy the Gaussian process model assumption of Storvik (2002). 0 0.", "startOffset": 87, "endOffset": 102}], "year": 2013, "abstractText": "The parameters of temporal models, such as dynamic Bayesian networks, may be modelled in a Bayesian context as static or atemporal variables that influence transition probabilities at every time step. Particle filters fail for models that include such variables, while methods that use Gibbs sampling of parameter variables may incur a per-sample cost that grows linearly with the length of the observation sequence. Storvik (2002) devised a method for incremental computation of exact sufficient statistics that, for some cases, reduces the per-sample cost to a constant. In this paper, we demonstrate a connection between Storvik\u2019s filter and a Kalman filter in parameter space and establish more general conditions under which Storvik\u2019s filter works. Drawing on an analogy to the extended Kalman filter, we develop and analyze, both theoretically and experimentally, a Taylor approximation to the parameter posterior that allows Storvik\u2019s method to be applied to a broader class of models. Our experiments on both synthetic examples and real applications show improvement over existing methods.", "creator": "LaTeX with hyperref package"}}}