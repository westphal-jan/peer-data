{"id": "1305.2505", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2013", "title": "On the Generalization Ability of Online Learning Algorithms for Pairwise Loss Functions", "abstract": "In this paper, we study the generalization properties of online learning based stochastic methods for supervised learning problems where the loss function is dependent on more than one training sample (e.g., metric learning, ranking). We present a generic decoupling technique that enables us to provide Rademacher complexity-based generalization error bounds. Our bounds are in general tighter than those obtained by Wang et al (COLT 2012) for the same problem. Using our decoupling technique, we are further able to obtain fast convergence rates for strongly convex pairwise loss functions. We are also able to analyze a class of memory efficient online learning algorithms for pairwise learning problems that use only a bounded subset of past training samples to update the hypothesis at each step. Finally, in order to complement our generalization bounds, we propose a novel memory efficient online learning algorithm for higher order learning problems with bounded regret guarantees.", "histories": [["v1", "Sat, 11 May 2013 13:52:37 GMT  (94kb,D)", "http://arxiv.org/abs/1305.2505v1", "To appear in proceedings of the 30th International Conference on Machine Learning (ICML 2013)"]], "COMMENTS": "To appear in proceedings of the 30th International Conference on Machine Learning (ICML 2013)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["purushottam kar", "bharath k sriperumbudur", "prateek jain 0002", "harish karnick"], "accepted": true, "id": "1305.2505"}, "pdf": {"name": "1305.2505.pdf", "metadata": {"source": "META", "title": "On the Generalization Ability of Online Learning Algorithms for Pairwise Loss Functions", "authors": ["Purushottam Kar", "Bharath K Sriperumbudur"], "emails": ["purushot@cse.iitk.ac.in", "bs493@statslab.cam.ac.uk", "prajain@microsoft.com", "hk@cse.iitk.ac.in"], "sections": [{"heading": "1. Introduction", "text": "Several monitored learning problems include working with paired or higher job loss functions, i.e., loss functions that depend on more than one training session (2001). However, the results of the 30th International Conference on Machine Learning, Atlanta, Georgia, USA, 2013. JMLR: W & CP technique that relies on more than one training session can be used by the author (s).ple. Take, for example, the metric learning problem (Jin et al., 2009), where the goal is to learn a metric M that brings together points from a similar label while separating heavily labeled dots. In this case, however, the loss function is a paired loss function \"(M, x, y), (x, y))), which applies learning skills where the goal is to merge a metric M (x) that merges points from a similar label while distinguishing differently labeled dots. In general, a paired loss function is a pair-wise loss function.\""}, {"heading": "2. Problem Setup", "text": "To facilitate exposure, we present an online learning model for higher-level learning problems in this section. (...) We assume that concrete learning instances such as AUC maximization and metric learning are given in Section 6. (...) For the sake of simplicity, we limit ourselves to pair problems in this work. (...) Our techniques can easily be extended to higher-order problems, as well. (...) For pair learning problems, our goal is to learn a1n (see Section 5). (...) Our goal is to extend the bivariate function h: X \u00b7 X \u2192 Y, where h-value H, with a loss function ': H \u00b7 Z \u00b7 Z \u2192 R +, where Z = X \u00b7 Y.The online learning algorithm will provide sequential access to a stream of elements z1, z2, zn."}, {"heading": "3. Online to Batch Conversion Bounds for Bounded Loss Functions", "text": "We present our generalization limits for algorithms that show regrettable limits in relation to all-pair loss functions (see Eq. (1)) Our results set tighter limits and have a much better dependence on input dimensions than those of Wang et al. (2012) See Section 3.1 for a detailed comparison. (Kakade & Tewari, 2008) The reason for this is that the terms Vt = L \u2212 1) do not follow from existing techniques for first-order problems (such as Cesa-Bianchi et al., 2001; Kakade & Tewari, 2008). The reason for this is that the terms Vt = L \u2212 1) are not formed by the intersection of training samples in Vt and VT. (Our technique, which aims to use the functionalities of the functional classes to get another challenge of symmetry."}, {"heading": "3.1. Discussion on the nature of our bounds", "text": "As mentioned above, our evidence enables us to use Rademacher complexities, which are typically easier to analyze and have narrower boundaries (Kakade et al., 2008). In particular, as shown in Section 6, the Rademacher complexities for L2-regulated learning formulas are dimensionally independent, i.e. Cd = 1. Consequently, unlike the boundaries of (Wang et al., 2012), which have a linear dependence on d, our boundaries are independent of the dimension of the input space. In the case of sparse learning formulas with L1 or the regulation of track standards, we have Cd = \u221a log d, which gives us a slight dependence on the input dimensionality. Our boundaries are also narrower than those of (Wang et al., 2012) in general. While we offer a confidence bond with respect to L1 or track standards regulation, we show that Exp (\u2212 n 2 + log n) is slightly dependent on the input dimensionality, our boundaries are narrower than those of (Wang et al)."}, {"heading": "4. Fast Convergence Rates for Strongly Convex Loss Functions", "text": "In this section, we extend the results of the previous section to ensure a rapid convergence for online learning algorithms that use strongly konvexe loss functions of the following form: \"(h, z, z\") = g (< h, z \") + r (h), where g is a konvexe function and r (h) is a konvexe regulation (see section 6 for examples) i.e. (h2), h2), h2 (0, 1), we haver (1) h2) h2), (h2), (h2), (h2), (h2), (h2), (h2), (h2), (h2), (h2), (h2), (h2), (2), (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (,), (, (,), (, (,), (, (,), (, (,), (,), (, (,), (, (,), (,), (, (,), (, (, (,), (,), (, (,), (, (,), (, (, (,), (, (,), (,), (, (,), (,), (, (, (, (, (,), (,), (, (, (, (,), (, (,), (, (, (, (,), (,), (, (,), (, (, (, (,), (, (,), (, (,), (, (, (, (,), (, (, (, (,), (, (,), (, (, (,), (, (,), (, (, (,), (, (,"}, {"heading": "5. Analyzing Online Learning Algorithms that use Finite Buffers", "text": "In this section we introduce our online rule of actualization to decide on the inclusion of a certain point on the basis of only two examples that we apply. \"(\" We. \"). (\" We. \"). (\" We. \"). (\" We. \"). (\" We. \"). (\" We. \"(\" We. \"). (\" We. \"). (\" We. \"). (\" We. \"). (\" We. \"). (\" We. \"). (\" We. \"(\" We. \"). (\" We. \"). (\" We. \"(\" We. \"). (\" We. \"). (\" We. \"(\" We. \").\" (\"We.\"). (\"We.\" (\"We.\"). (\"We.\" We. \"(.\" We. \"(.\" We. \"). (\" We. \"We.\" (. \"We.\"). (\"We.\" We. \"). (\" We. \"We. (.\" We. \"). (\" We. \"We.\"). (\"We. (.\" We. \"). (\" We. \"We.\"). (\"We. (.\" We. \"). (\" We. (. \"). (\" We. \"We.\"). (. (\"We.\"). (\"We. (\" We. \"). (. (\" We. \"). (\" We. \"We. (\"). (\"We. (\" We. \"). (.\"). (\"We. (\" We. \"We.\"). (. \"). (\"). (\"We. (. (\" We. \"). (\" We. (. \"We.\"). (\"We.\"). (\"We. (. (\" We. \"). (\" We. \"). (\" We. \"). (\" We. (. (\"). (.). (\" We. (. (\"We.). (\" We.). (. (\"We.). (\" We. (.). \"We. (. (.). (. ("}, {"heading": "6. Applications", "text": "In this section we clarify that our definition of the Rademacher complexity for a pair functional class of \"H\" (z, z, z) 7 \"(h, z) 7\" (h, z) 7 \"(h, z) 7\" (h, z) 7 \"(h, z) 7\" (h, z) 7 \"(h, z) 7\" (h, z \"), h\" H \"(h), where there are some Lipschitz loss functions. (h, z) Y (y), y\" (y \"), y\"), y \"(y\"), y \"(y\" y \") and y (y\" y \")."}, {"heading": "7. OLP : Online Learning with Pairwise Loss Functions", "text": "In this section, we present an online learning algorithm for learning with paired losses in a finite buffer setting = 3. The key examples in this section are: \"We.\" (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\" (\"We.\"). (\"We.\" (. \"We.\"). (\"We.\" (. \"We.\"). \"We. (.\" We. \".\" We. \". (.\"). \"We. (.\" We. \"). (.\" We. (. \"We.\"). (. \"We. (.\"). (\"We. (.\" We. \"). (\" We. (. \"). (\" We. (. \"We.\"). (. (\"We.\" We. \"). (. (.\" We. (. \"). (\" We. \"). (\" We. (\"We.\"). (. \"We. (.\" We. (.). \"We. (.). (. (.).\" We. (. \"We.\"). (. \"We. (.\" We. \"). (. (.\"). (. \"). (\" We. (. (. (\"We.). (. (.). (\" We. \"). (\" We. (. (. \"). (. (\" We. (.). (.). (\"We. (. (.). (\" We.). (. (. (.). (\"We.\" We. (.). (.). (\"We."}, {"heading": "8. Experimental Evaluation", "text": "In this section, we present experimental evaluation of our proposed OLP algorithm. We emphasize that the goal of this evaluation is to show that our algorithm, which has high confidence limits, is also competitive in practice with respect to the OAMgra algorithm proposed by Zhao et al. (2011), since our results in Section 5 show that OAMgra enjoys good generalization guarantees despite the absence of an allpairs remorse limit. In our experiments, we adapted the OLP algorithm to the AUC maximization problem and compared it with OAMgra on 18 different benchmark datasets. We used 60% of the available data up to a maximum of 20,000 points to train both algorithms. We refer the reader to Appendix J for a discussion on the implementation of the RS-x algorithm. Figure 1 shows the results of our experiments on 4 datasets over 5 random test / split."}, {"heading": "9. Conclusion", "text": "In this paper, we examined the generalization possibilities of online learning algorithms for paired loss functions from different perspectives. Our results for bound and strongly convex loss functions closely correspond to those of their first-order counterparts. Finally, we expanded our analysis to include algorithms that are only able to provide finite regret limits, in addition to good empirical performance, which could explain the good empirical performance of some existing algorithms. Finally, we presented a new memory-efficient online learning algorithm that is able to provide all-pair regret limits in addition to good empirical performance. For future work, several interesting directions can be pursued, in particular the development of online learning algorithms that can guarantee sublinear regret at constant buffer sizes, or otherwise less regret at finite buffer algorithms. Second, the idea of current-aware buffer updating is a policy that would be interesting both from an empirical point of view and in terms of novel functions."}, {"heading": "Acknowledgment", "text": "The authors thank the anonymous speakers for comments that improved the presentation of the work. PK is supported by Microsoft Corporation and Microsoft Research India as part of a Microsoft Research India Ph.D. Fellowship Award."}, {"heading": "A. Proof of Lemma 1", "text": "Lemma 9 (Lemma 1): Let us build h1,.., hn \u2212 1) a set of hypotheses generated by an online learning algorithm that works with a limited loss function. \u2212 Z \u2212 Z \u2212 Z \u00b7 [0, B]. Then we have for each problem with a probability of at least 1 \u2212 Kong, 1n \u2212 1 n \u00b2 t = 2 L (ht \u2212 1). \u2212 Z \u2212 Z \u2212 T (ht \u2212 1). \u2212 Z \u2212 T (ht \u2212 1). \u2212 Z \u2212 T (ht \u2212 1). T = 2 Rt \u2212 1 (. H) + 3B \u00b7 N (h). N \u2212 Z \u2212 Z \u2212 Z \u2212 T (h). As a first step, we break down the excess risk in a similar way to (Wang et al., 2012). For each h H letL t (h): = E ztr L t (h)."}, {"heading": "B. Proof of Theorem 4", "text": "Theorem 10 (Theorem 4) is the complexity of class F on the implication effectiveness. We start with the function of Prof. (f, x) For the function of Prof. (f, x) we have a closed and convex series of functions about X. Let us assume (f, x) = p (< f, \u03c6 (x) >) + r (f) for a convex function a loss function with P and P as associated population and empirical risk control and f \u00b2 as population risk minimizer. Suppose that P (f) \u2212 P is L-Lipschitz and vice versa (x). Then we have a loss function with P and P \u00b2 -X. Then we have a loss function for all f \u00b2 F, P (f) \u2212 P (f) \u2212 P (f) \u2212 P (f) \u2212 P (f) -Lipschitz and p (x)."}, {"heading": "C. Proof of Theorem 5", "text": "Theorem 14 (Theorem 5) is presented in this case as a side effect of the progression process. (hh) This is a group of hypotheses generated by an online learning algorithm. (h) This is a group of hypotheses generated by an online learning algorithm. (h) This is a group of hypotheses generated by an online learning algorithm. (h) This is a group of hypotheses generated by an online learning algorithm. (h) This is a group in which we have a probability of at least 1 \u2212 1 \u2212 1 n (h) n (h) n. (h) This is a group in which we have a probability of at least 1 \u2212 1 \u2212 1 \u2212 1 (h) n (h)."}, {"heading": "D. Generalization Bounds for Finite Buffer Algorithms", "text": "In this area, we are able to go in search of new paths that lead us astray. (...) In this area, we are able to go in search of new paths. (...) In this area, we are able to go in search of new paths. (...) In this area, we have to go in search of new paths. (...) In this area, we have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths. (...) We have to go in search of new paths."}, {"heading": "E. Proof of Theorem 7", "text": "g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g, g,"}, {"heading": "F. Applications", "text": "In this section we will deduce Rademacher's complexity for hypotheses classes. (...) We will deduce the following results for our derivatives: (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...).). (...). (...).). (...).). (...).). (...).). (...).). (...).). (...).). (...). (...).).). (...). (...).). (...).).). (...). (...).). (...). (...).). (...). (...).). (...).).). (...).). (...). (...). (...).). (...).). (...). (...). (...). (...).).). (...). (...).).). (...).). (...). (...). (...).).). (...).).). (...).). (...)"}, {"heading": "G. Regret Bounds for Reservoir Sampling Algorithms", "text": "The Reservoir Sampling Algorithm (Vitter, 1985) performs sampling essentially without substitution, which means that the samples in the buffer are not samples from the previous stream. Therefore, it becomes somewhat more difficult to test limits of regret using unified convergence arguments. However, there has been a lot of work on analyzing learning algorithms that learn from non-ergodic data, such as data generated by ergodic processes. Of particular interest is a result of Serfling 2, which provides Hoeffding style limits for data generated from a limited population without substitution. Although Serfling's result provides a way to analyze the RS algorithm, this would directly require the use of arguments that cover boundaries that are dimensional and not narrow. It would be interesting to see if equivalents of the inequality of the McDiarmid and Rademacher averages for samples can be formulated to obtain more accurate results."}, {"heading": "H. Analysis of the RS-x Algorithm", "text": "In this section, we analyze the RS-x substream sampling algorithm and prove its statistical properties. We remember that the RS-x algorithm simply allows a point into the buffer if there is room. It performs a repopulation step in the first instance of abundance, which involves filling the buffer by sampling with substitutes from all previously seen points (including the one that caused the abundance). In the following steps, a normal update step would be performed. The following theorem formalizes the properties of the sampling algorithmTheorem 23. Suppose we have a stream of elements z1,... zn is sampled into a buffer B of size s using2R. J. Serfling, probability inqualities for the sum in sampling without substitution. The Annals of Statistics, 2 (1): 39-48, 1974.the RS-x algorithm. Then at any time, each element is explicitly + 2, each element is fixed."}, {"heading": "I. Proof of Theorem 8", "text": "s \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D.D\".D.D \".D\".D \".D.D\".D \".D\".D \".D\".D \".D\".D.D \".D\".D.D \".D\".D \".D\".D.D.D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D\".D \".D"}, {"heading": "K. Additional Experimental Results", "text": "Here we present experimental results on 14 different benchmark datasets (see Figure 3), which compare the OLP algorithm using the RS-x2 buffer policy with the OAMgra algorithm using the RS buffer policy. We continue to observe the trend that OLP is competitive compared to OAMgra, while in most cases we enjoy a slight advantage in small buffer situations."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "In this paper, we study the generalization properties of online learning based stochastic methods for supervised learning problems where the loss function is dependent on more than one training sample (e.g., metric learning, ranking). We present a generic decoupling technique that enables us to provide Rademacher complexity-based generalization error bounds. Our bounds are in general tighter than those obtained by Wang et al. (2012) for the same problem. Using our decoupling technique, we are further able to obtain fast convergence rates for strongly convex pairwise loss functions. We are also able to analyze a class of memory efficient online learning algorithms for pairwise learning problems that use only a bounded subset of past training samples to update the hypothesis at each step. Finally, in order to complement our generalization bounds, we propose a novel memory efficient online learning algorithm for higher order learning problems with bounded regret guarantees.", "creator": "LaTeX with hyperref package"}}}