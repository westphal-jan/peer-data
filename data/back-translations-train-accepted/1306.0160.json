{"id": "1306.0160", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2013", "title": "Phase Retrieval using Alternating Minimization", "abstract": "Phase retrieval problems involve solving linear equations, but with missing sign (or phase, for complex numbers) information. Over the last two decades, a popular generic empirical approach to the many variants of this problem has been one of alternating minimization; i.e. alternating between estimating the missing phase information, and the candidate solution. In this paper, we show that a simple alternating minimization algorithm geometrically converges to the solution of one such problem -- finding a vector $x$ from $y,A$, where $y = |A^T x|$ and $|z|$ denotes a vector of element-wise magnitudes of $z$ -- under the assumption that $A$ is Gaussian.", "histories": [["v1", "Sun, 2 Jun 2013 00:45:12 GMT  (167kb,D)", "http://arxiv.org/abs/1306.0160v1", null], ["v2", "Fri, 12 Jun 2015 11:45:50 GMT  (402kb,D)", "http://arxiv.org/abs/1306.0160v2", "Accepted for publication in IEEE Transactions on Signal Processing"]], "reviews": [], "SUBJECTS": "stat.ML cs.IT cs.LG math.IT", "authors": ["praneeth netrapalli", "prateek jain 0002", "sujay sanghavi"], "accepted": true, "id": "1306.0160"}, "pdf": {"name": "1306.0160.pdf", "metadata": {"source": "CRF", "title": "Phase Retrieval using Alternating Minimization", "authors": ["Praneeth Netrapalli", "Prateek Jain", "Sujay Sanghavi"], "emails": ["praneethn@utexas.edu", "prajain@microsoft.com", "sanghavi@mail.utexas.edu"], "sections": [{"heading": null, "text": "Empirically, our algorithm behaves much like the recently proposed convex techniques for this variant (which are based on \"lifting\" to a convex matrix problem) in terms of sample complexity and robustness to noise. However, our algorithm is much more efficient and can be scaled to major problems. Analytically, we show a geometric convergence to the solution and sample complexity separated by log factors from obvious lower limits. We also establish a near-optimal scaling for when the unknown vector is sparse. Our work represents the only known theoretical guarantee of alternating minimization for each variant of phase recovery problems in the non-convex environment."}, {"heading": "1 Introduction", "text": "In this paper, we are interested in reconstructing a complex vector x-Cn from the orders of magnitude of its linear measurements (i.e., we have the task of reconstructing the measured quantities and reconstructing the measured quantities.) This problem, known as phase retrieval, is encountered in several fields of application in crystallography, optics, spectroscopy and tomography. Furthermore, the problem is comprehensively investigated in the following two settings: 1Our results also cover the real case, i.e. where all quantities are real.ar Xiv: 130 6.01 60v1 [st] J 2un."}, {"heading": "1.1 Related Work", "text": "In fact, it is not as if it were a way in which it has developed in recent years. (...) It is not as if it were a way in which it has developed in recent years. (...) It is not as if it were a way in which it has done so in the past. (...) It is as if it were a way in which it has done so. (...) It is as if it were a way in which it has done so. (...) It is as if it were a way in which it does so. (...) It is not as if it were a way in which it is a way in which it is a way in which it is a way in which it is a way in which it is itself. (...) It is as if it is a way in which it is not itself. (...)"}, {"heading": "2 Notation", "text": "We use bold uppercase letters (A, B, etc.) for matrices, bold lowercase letters (x, y, etc.) for vectors, and non-bold letters (\u03b1, U, etc.) for scalars. For each complex vector w-Cn, | w-Rn denotes its elementary size vector. wT and AT denote the hermitic transposition of vector w and matrix A. e1, e2, etc., denote the canonical base vectors in Cn. z denotes the complex conjugate of the complex number. In this essay, we use the hermitic (or normal) distribution over Cn. a should be distributed according to this distribution if a = a1 + ia2, where a1 and a2 are independent and distributed according to N (0, I). We also define Ph (z) def = z-C and dist (w1 + ia2), with a2 for the high loss and w2 for the high probability and w2 for the high loss."}, {"heading": "3 Algorithm", "text": "In this section, we present our alternating minimization effectiveness for solving the phase retrieval problem: \"We have only one problem that we do not know.\" \"We have a problem that we do not know.\" \"We have a problem that we do not know.\" \"We have a problem that we cannot solve.\" \"We have a problem that we do not want to solve.\" \"We have a problem that we do not want to solve.\" \"We have a problem that we do not want to solve.\" \"Of course, we do not know what we want to do.\" \"We do not know what we want to do.\" \"We have a problem that we do not want to solve.\" \"We have a problem that we do not want to solve.\" \"We have a problem that we do not want to solve.\" \"We do not have a problem that we do not want to solve.\""}, {"heading": "4 Main Results: Analysis", "text": "In this section, we describe the main contributions of this paper: \"We are then large enough to recognize the success of alternate minimization in solving the problem of phase recovery.\" (\"We want all existing guarantees for phase recovery to also be converted into two key results.\" (\"We want all existing guarantees to be converted into two key results.\") \"We first show that if m\" Cn log3 n, then whp the initialization of algorithm 2 compared to PhaseLift and PhaseCut. Our proof of the constant of alternative minimization can be converted into two key results. \"(\" We show that we can then whp the initialization of algorithm x0, which is located at most constant distances of x. \")\" In addition, this constant can be controlled by using more examples (see Theorem 4.1).We then show that it is a fixed Vector. \""}, {"heading": "5 Sparse Phase Retrieval", "text": "In this section we will consider the case in which the umpteenth phase is represented in algorithm 3. A natural and practical question that needs to be asked here is: Can the sample and computational complexity of the recovery algorithm be improved if the umpteenth complexity of this algorithm is still O (n3 / 2)? In this section we provide a simple extension of our AltMinPhase algorithms, which we call SparseAltMinPhase, in the case of the thrifty x-th. The main idea behind our algorithm is to gain the support of the x-th. Then the problem is reduced to phase retrieval of a k-dimensional signal. We then solve the reduced problem with the help of algorithm 2. The pseudo code for SparseAltMinPhase is presented in algorithm 3."}, {"heading": "6 Experiments", "text": "In this section, we present experimental evaluation of the AltMinPhase (algorithm 1) and compare its performance with the SDP-based methods PhaseLift [7] and PhaseCut [43]. We also demonstrate empirically the advantage of our initialization method over the random initialization (referred to by AltMin (random init))) previously considered in the literature (17, 15, 43, 5]. AltMin (random init) is the same as AltMinPhase 1. Step 1 of algorithm 1 is replaced with: x0 \"Uniformly random vector from the unit sphere.In the noisless setting, a study will be successful if the output x -x-x-x-x-x-x-x-x-x-x-x-x satisfies the results of AltMinPhase 2. < 10 \u2212 2. For a given dimension, we do a linear search for smallest m (number of samples) so that empirical success rate over 20 runs is at least 0.8."}, {"heading": "A Proofs for Section 4", "text": "(1) Evidence of Initialization Step of Theorem 4.1. (2) Use: (1) Evidence of Theorem 4.1. (2) Use: (1) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) Use: (2) (2) Use: (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2)) (2) (2) (2) (2) (2)) (2) (2) (2) (2) (2)) (2) (2) (2)) (2) (2) (2) ()) (2) ()) (2) (2) ()) (2) ()) (2) ()) () ()) ()) ()) () ()) ()) () ()) () (())) () () () () () () () () () () () () () () () () () () () () (() () () () (() () (() () (() (() () () () () () () () () ((() () () ((((() () ((() (((() ((() (((() ((() ((((((() ((((((()"}, {"heading": "B Proofs for Section 5", "text": "The proof for Lemma 5.1. for each j [n] and i [m] is the random variable Zij def = | aijyi |. We have the following: \u2022 if j \u00b2 S, thenE [Zij] = 2\u03c0 (\u221a 1 \u2212 (x \u00b2 j) 2 + x * j arcsinx * j) \u2265 2 \u03c0 (1 \u2212 56 (x \u00b2 j) 2 \u2212 16 (x \u00b2 j) 4 + x \u00b2 j (x \u00b2 j + 16 (x \u00b2 j) 3)))) \u2265 2 \u03c0 + 1 6 (x \u00b2 min) 2, with the first step from Korollarium following 3.1 in [27] and the second step from the Taylor series extensions of \u221a 1 \u2212 x2 and arcsin (x), \u2022 if j / \u00b2 S, then E [Zij] = E [aij] = 6 (x \u00b2 min) 2 (| yi |] = 2\u03c0 and finally \u2022 for each j \u2212 p \u2212 Zij \u2212 n \u2212 Zij is a sub-exponential with any product greater than the 1 \u00b2 for each hypothesis."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Phase retrieval problems involve solving linear equations, but with missing sign (or phase, for<lb>complex numbers) information. Over the last two decades, a popular generic empirical approach<lb>to the many variants of this problem has been one of alternating minimization; i.e. alternating<lb>between estimating the missing phase information, and the candidate solution. In this paper, we<lb>show that a simple alternating minimization algorithm geometrically converges to the solution<lb>of one such problem \u2013 finding a vector x from y,A, where y = |Ax| and |z| denotes a vector<lb>of element-wise magnitudes of z \u2013 under the assumption that A is Gaussian.<lb>Empirically, our algorithm performs similar to recently proposed convex techniques for this<lb>variant (which are based on \u201clifting\u201d to a convex matrix problem) in sample complexity and<lb>robustness to noise. However, our algorithm is much more efficient and can scale to large<lb>problems. Analytically, we show geometric convergence to the solution, and sample complexity<lb>that is off by log factors from obvious lower bounds. We also establish close to optimal scaling<lb>for the case when the unknown vector is sparse. Our work represents the only known theoretical<lb>guarantee for alternating minimization for any variant of phase retrieval problems in the non-<lb>convex setting.", "creator": "LaTeX with hyperref package"}}}