{"id": "1306.0751", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jun-2013", "title": "First-order Decomposition Trees", "abstract": "Lifting attempts to speed up probabilistic inference by exploiting symmetries in the model. Exact lifted inference methods, like their propositional counterparts, work by recursively decomposing the model and the problem. In the propositional case, there exist formal structures, such as decomposition trees (dtrees), that represent such a decomposition and allow us to determine the complexity of inference a priori. However, there is currently no equivalent structure nor analogous complexity results for lifted inference. In this paper, we introduce FO-dtrees, which upgrade propositional dtrees to the first-order level. We show how these trees can characterize a lifted inference solution for a probabilistic logical model (in terms of a sequence of lifted operations), and make a theoretical analysis of the complexity of lifted inference in terms of the novel notion of lifted width for the tree.", "histories": [["v1", "Tue, 4 Jun 2013 12:43:07 GMT  (1195kb,D)", "http://arxiv.org/abs/1306.0751v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["nima taghipour", "jesse davis", "hendrik blockeel"], "accepted": true, "id": "1306.0751"}, "pdf": {"name": "1306.0751.pdf", "metadata": {"source": "CRF", "title": "First-Order Decomposition Trees", "authors": ["Nima Taghipour", "Jesse Davis", "Hendrik Blockeel"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to orient themselves in a direction in which they are able to."}, {"heading": "2 Background", "text": "We use logvar for logical variables and randvar for random variables. We write variables in uppercase letters and their values in lowercase letters. If we replace a structure S with the corresponding ti, every occurrence of si in S is replaced by the corresponding ti."}, {"heading": "2.1 Propositional and first-order graphical models", "text": "Probabilistic graphical models such as Bayean networks, Markov networks and factor graphs compactly represent a common distribution over a series of edge vars V = {V1,..., Vn} by factorizing the distribution into a series of local distributions. For example, factor graphs represent the distribution as a product of factors: Pr (V1,.., Vn) = 1Z \u00b2 i (Vi), where inspi is a potential function that maps any configuration of Vi V to a real number and Z is a normalization constant. Probabilistic logical models use first-order logic concepts to provide a high-grade modeling language for the representation of propositional graphical models. While many such languages exist (see [5] for an overview), we focus on parametric factors (parameters) that x-generalize factor graphs. Parameters use parametrized edge vars (PRVs) to represent whole sets of randomness."}, {"heading": "2.2 Inference", "text": "A typical conclusion is to calculate the marginal probability of some variables by summing up the remaining variables, which are called: Pr (V) = \u2211 V (Vi).This is an instance of the general sum product problem [1]. Using notations, we represent this sum of products as V / V (V).Inference to the reproductive decomposition of trees. The following algorithms use the factorization of the model to recursively decompose the original problem into smaller, independent subproblems. This is achieved by decomposing the sum product, according to a simple decomposition rule.Definition 1 (The decomposition rule) Should P be a sum product computation P: (V), and leave M = {M1 (V1), and leave M = {Mk (Vk)} a partition (division) of M (V)."}, {"heading": "3 Lifted inference: Exploiting symmetries", "text": "The conclusion of Section 2.2 ignores the symmetries imposed on us by a PLM. Increased conclusions aim to exploit symmetries among the isomorphic parts of a model. Two constructs are isomorphic if there is a structure that maintains bijection problems between its components. Since PLMs make claims about entire groups of objects, they contain many isomorphisms defined by a bijection at the level of objects. Building on these, symmetries arise between constructs at different levels [11], such as between edge vars, value assignments to edge vars, factors, models, or even product problems. Any exact upscale inference methods use two main tools for exploiting symmetries, i.e. dividing the problem into isomorphic subproblems, solving an instance, and aggregating 2. Counting the number of possible configurations for a configurable."}, {"heading": "4 First-Order decomposition trees", "text": "In this section we propose the structure of the FO trees, which compactly represent a recursive decomposition for a PLM and the symmetries therein."}, {"heading": "4.1 Structure", "text": "A FO-dtree provides a compact representation of a propositional dtree = 1. Like a PLM, a compact representation of a propositional model is done by explicitly capturing isomorphic decomposition that corresponds to a node with isomorphic children in a dtree. Using a new node type called \"decomposition into subbases\" (DPG) means that a FO-dtree represents the entire set of trees (P (xn))).PG (PG)).PG trees."}, {"heading": "4.2 Properties", "text": "Darwiche [2] showed that important properties of recursive decomposition are captured in the properties of dtree nodes. In this section, we define these properties for FO-dtrees. Customizing the definitions of dtree properties such as cutset, context and cluster for FO-dtrees requires taking into account the semantics of a FO-dtree that uses DPG nodes and representative objects. Specifically, this requires the following two modifications (i) for a DPG node TX = (X, X), instead of Child (T), to take into account the semantics of an FO node, and (ii) a function that finds the intersection of two representative edge variars. First, for a DPG node TX = (X, x, C), we can define: ChildTB (TX), its interinstitutional properties (TX), TX nodes of the X nodes."}, {"heading": "5 Liftable FO-dtrees", "text": "In fact, the fact is that most of them are not purely a problem, but a problem that has indeed occurred in recent years."}, {"heading": "6 Lifted inference based on FO-dtrees", "text": "In this section, we show how a liftable FO-dtree can prescribe an LVE solution for the model, providing the first formal method for symbolic operation selection in upscale inferences. In VE, each inference procedure can be characterized by its elimination order. Darwiche [2] shows how we can assign a (partial) elimination order from a dtree to each node (by assigning the elimination of each edge variar to a tree node). We build on this result to read an LVE solution from an (uncounted) FO dtree by assigning each node a series of upscale operations, including upscale elimination of PRVs (by multiplication and summing) Y operations."}, {"heading": "7 Complexity of lifted inference", "text": "This year it is more than ever before."}, {"heading": "8 Conclusion", "text": "An FO-dtree explicitly shows the symmetry between its isomorphic parts and can thus show a form of decomposition that has lifted the applied inference methods. We showed how to decide whether an FO-dtree is capable of lifting (with a corresponding elevated solution), and how to derive the sequence of elevated operations and the complexity of the LVE on the basis of such a tree. While we focused on LVE, our analysis is also applicable to elevated search-based methods, such as elevated recursive conditioning [13], weighted firm order model counting [21], and probabilistic theories that prove [6]. This allows us to derive a sequence of operations and complexity results for these methods when they are operated on an elevated FO-dtree. Furthermore, we can show the close connection between LVE and searched-based methods by analyzing their performance on the O."}, {"heading": "A Proof of Theorem 1", "text": "To prove that each of these problems is solvable (we do not require that we ground the PRVs and deal directly with all their random variants), we need to show that the entire group of random variants in each cluster can be divided into groups of interchangeable k-tuples of random variants. We prove this by citing the properties of counting random variants in PLMs and the accuracy of counting random variants in XVE [10, 16]. For simplicity, we assume that there are no random variants in the cluster (which include generalization of random variants), and then the model can be written as a 1-logvar parameter as follows."}, {"heading": "B Proof of Theorem 2", "text": "The Evidence. We prove the theorem by limiting the complexity of each elevated operation performed on each of the nT nodes of the tree. First, let's consider an elevated elimination performed on any node. The complexity of this operation is proportional to | range (cluster (T \u2032)) |, since it has to do with a parfactor that includes the (counting) marginal vars in the cluster. Each cluster is a group A = {A1, A2,. \u00b7 Aw \u2032 g, (T \u2032 2,..) of the Randvars Ai = # Xi [Pi1 (Xi),.., Pik (Xi)], where w \u2032 # \u2264 w #, and w \u2032 g \u2264 wg. Thus, the range (A) | = (range (Ai \u2032 i \u2032 #} #) and the counting of the marginal vars (Ai) |) \u00b7 p (Pi1 (Xi) # p),"}, {"heading": "C Finding corresponding FO-dtrees", "text": "In this section, we provide a simple algorithm that constructs a model G to find a corresponding tree. (DPGs allow us to let our method go from top to bottom to allow a recursive decomposition of G.) We also briefly discuss possible extensions of this simple algorithm that can turn it into a greedy algorithm selection. (Initially, we have a single node T with a model G. According to a decomposition of G into {Gi} i, we add the children Ti to the tree, and then recursively build each tree Ti for Gi. Among DPG nodes, we represent only one instance of the children. (DPGs allow us to partially decompose the model, and recursively apply this tool in a soil model.) This allows us to reduce the problem of finding a tree. (DPG nodes, we represent only one instance of the children who allow us to partially decompose the model, and recursively apply this tool model in a soil model."}], "references": [{"title": "Solving #-SAT and Bayesian inference with backtracking search", "author": ["F. Bacchus", "S. Dalmao", "T. Pitassi"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Recursive conditioning", "author": ["Adnan Darwiche"], "venue": "Artif. Intell.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Lifted first-order probabilistic inference", "author": ["Rodrigo de Salvo Braz", "Eyal Amir", "Dan Roth"], "venue": "In Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2005}, {"title": "Bucket elimination: A unifying framework for reasoning", "author": ["Rina Dechter"], "venue": "Artif. Intell.,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "An Introduction to Statistical Relational Learning", "author": ["Lise Getoor", "Ben Taskar", "editors"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Probabilistic theorem proving", "author": ["Vibhav Gogate", "Pedro Domingos"], "venue": "In Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Liftability of probabilistic inference: Upper and lower bounds", "author": ["Manfred Jaeger", "Guy Van den Broeck"], "venue": "In Proceedings of the 2nd International Workshop on Statistical Relational AI (StaRAI),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Lifted inference seen from the other side : The tractable features", "author": ["Abhay Jha", "Vibhav Gogate", "Alexandra Meliou", "Dan Suciu"], "venue": "In Proceedings of the 23rd Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Counting belief propagation", "author": ["Kristian Kersting", "Babak Ahmadi", "Sriraam Natarajan"], "venue": "In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Lifted probabilistic inference with counting formulas", "author": ["Brian Milch", "Luke S. Zettlemoyer", "Kristian Kersting", "Michael Haimes", "Leslie Pack Kaelbling"], "venue": "In Proceedings of the 23rd AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Markov chains on orbits of permutation groups", "author": ["Mathias Niepert"], "venue": "In Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "First-order probabilistic inference", "author": ["David Poole"], "venue": "In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Towards completely lifted search-based probabilistic inference", "author": ["David Poole", "Fahiem Bacchus", "Jacek Kisynski"], "venue": "CoRR, abs/1107.4035,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Exploiting contextual independence in probabilistic inference", "author": ["David Poole", "Nevin Lianwen Zhang"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Lifted first-order belief propagation", "author": ["Parag Singla", "Pedro Domingos"], "venue": "In Proceedings of the 23rd AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Generalized counting for lifted variable elimination", "author": ["Nima Taghipour", "Jesse Davis"], "venue": "In Proceedings of the 2nd International Workshop on Statistical Relational AI (StaRAI),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Lifted variable elimination with arbitrary constraints", "author": ["Nima Taghipour", "Daan Fierens", "Jesse Davis", "Hendrik Blockeel"], "venue": "In Proceedings of the 15th International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Completeness results for lifted variable elimination", "author": ["Nima Taghipour", "Daan Fierens", "Guy Van den Broeck", "Jesse Davis", "Hendrik Blockeel"], "venue": "In Proceedings of the 16th International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "On the completeness of first-order knowledge compilation for lifted probabilistic inference", "author": ["Guy Van den Broeck"], "venue": "In Proceedings of the 24th Annual Conference on Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Lifted relax, compensate and then recover: From approximate to exact lifted probabilistic inference", "author": ["Guy Van den Broeck", "Arthur Choi", "Adnan Darwiche"], "venue": "In Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}, {"title": "Lifted probabilistic inference by first-order knowledge compilation", "author": ["Guy Van den Broeck", "Nima Taghipour", "Wannes Meert", "Jesse Davis", "Luc De Raedt"], "venue": "In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "On lifting the gibbs sampling algorithm", "author": ["Deepak Venugopal", "Vibhav Gogate"], "venue": "In Proceedings of the 26th Annual Conference on Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "Probabilistic logical modes (PLMs) combine elements of first-order logic with graphical models to succinctly model complex, uncertain, structured domains [5].", "startOffset": 154, "endOffset": 157}, {"referenceID": 11, "context": "To address this, Poole [12] introduced the concept of lifted probabilistic inference, i.", "startOffset": 23, "endOffset": 27}, {"referenceID": 2, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 5, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 7, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 8, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 9, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 12, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 14, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 16, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 17, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 18, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 20, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 21, "context": "Various lifted algorithms have been proposed, mainly by lifting propositional inference algorithms [3, 6, 8, 9, 10, 13, 15, 17, 18, 19, 21, 22].", "startOffset": 99, "endOffset": 143}, {"referenceID": 3, "context": "The performance of propositional inference, such as variable elimination [4, 14] or recursive conditioning [2], is characterized in terms of a corresponding tree decomposition of the model, and their complexity is measured based on properties of the decomposition, mainly its width.", "startOffset": 73, "endOffset": 80}, {"referenceID": 13, "context": "The performance of propositional inference, such as variable elimination [4, 14] or recursive conditioning [2], is characterized in terms of a corresponding tree decomposition of the model, and their complexity is measured based on properties of the decomposition, mainly its width.", "startOffset": 73, "endOffset": 80}, {"referenceID": 1, "context": "The performance of propositional inference, such as variable elimination [4, 14] or recursive conditioning [2], is characterized in terms of a corresponding tree decomposition of the model, and their complexity is measured based on properties of the decomposition, mainly its width.", "startOffset": 107, "endOffset": 110}, {"referenceID": 1, "context": "It is known that standard (propositional) inference has complexity exponential in the treewidth [2, 4].", "startOffset": 96, "endOffset": 102}, {"referenceID": 3, "context": "It is known that standard (propositional) inference has complexity exponential in the treewidth [2, 4].", "startOffset": 96, "endOffset": 102}, {"referenceID": 1, "context": "Such analysis is typically done using a secondary structure for representing the decomposition of graphical models, such as decomposition trees (dtrees) [2].", "startOffset": 153, "endOffset": 156}, {"referenceID": 4, "context": "While many such languages exist (see [5] for an overview), we focus on parametric factors (parfactors) [12] that generalize factor graphs.", "startOffset": 37, "endOffset": 40}, {"referenceID": 11, "context": "While many such languages exist (see [5] for an overview), we focus on parametric factors (parfactors) [12] that generalize factor graphs.", "startOffset": 103, "endOffset": 107}, {"referenceID": 12, "context": "Every model can be written into this form in poly time [13].", "startOffset": 55, "endOffset": 59}, {"referenceID": 0, "context": "This is an instance of the general sum-product problem [1].", "startOffset": 55, "endOffset": 58}, {"referenceID": 1, "context": "Then, the decomposiSimilarly to existing studies on propositional inference [2, 4], our analysis only considers the model\u2019s global structure, and makes no assumptions about its local structure.", "startOffset": 76, "endOffset": 82}, {"referenceID": 3, "context": "Then, the decomposiSimilarly to existing studies on propositional inference [2, 4], our analysis only considers the model\u2019s global structure, and makes no assumptions about its local structure.", "startOffset": 76, "endOffset": 82}, {"referenceID": 0, "context": "Most exact inference algorithms recursively apply this rule and compute the final result using topdown or bottom-up dynamic programming [1, 2, 4].", "startOffset": 136, "endOffset": 145}, {"referenceID": 1, "context": "Most exact inference algorithms recursively apply this rule and compute the final result using topdown or bottom-up dynamic programming [1, 2, 4].", "startOffset": 136, "endOffset": 145}, {"referenceID": 3, "context": "Most exact inference algorithms recursively apply this rule and compute the final result using topdown or bottom-up dynamic programming [1, 2, 4].", "startOffset": 136, "endOffset": 145}, {"referenceID": 1, "context": "A decomposition tree (dtree) is a structure that represents the decomposition used by a specific solution and allows us to determine its complexity [2].", "startOffset": 148, "endOffset": 151}, {"referenceID": 10, "context": "Building on this, symmetries arise between constructs at different levels [11], such as between: randvars, value assignments to randvars, factors, models, or even sum-product problems.", "startOffset": 74, "endOffset": 78}, {"referenceID": 2, "context": "Below, we show how these tools are used by lifted variable elimination (LVE) [3, 10, 12, 17, 18].", "startOffset": 77, "endOffset": 96}, {"referenceID": 9, "context": "Below, we show how these tools are used by lifted variable elimination (LVE) [3, 10, 12, 17, 18].", "startOffset": 77, "endOffset": 96}, {"referenceID": 11, "context": "Below, we show how these tools are used by lifted variable elimination (LVE) [3, 10, 12, 17, 18].", "startOffset": 77, "endOffset": 96}, {"referenceID": 16, "context": "Below, we show how these tools are used by lifted variable elimination (LVE) [3, 10, 12, 17, 18].", "startOffset": 77, "endOffset": 96}, {"referenceID": 17, "context": "Below, we show how these tools are used by lifted variable elimination (LVE) [3, 10, 12, 17, 18].", "startOffset": 77, "endOffset": 96}, {"referenceID": 1, "context": "Darwiche [2] showed that important properties of a recursive decomposition are captured in the properties of dtree nodes.", "startOffset": 9, "endOffset": 12}, {"referenceID": 18, "context": "Formally, this is called a domain-lifted inference solution [19].", "startOffset": 60, "endOffset": 64}, {"referenceID": 7, "context": "We can show that cutset(TX) excludes from rv(TX) \\ acutset(TX) only those PRVs for which X is a binding class of logvars [8, 19].", "startOffset": 121, "endOffset": 128}, {"referenceID": 18, "context": "We can show that cutset(TX) excludes from rv(TX) \\ acutset(TX) only those PRVs for which X is a binding class of logvars [8, 19].", "startOffset": 121, "endOffset": 128}, {"referenceID": 6, "context": "all models are liftable [7], though each model has at least one FO-dtree.", "startOffset": 24, "endOffset": 27}, {"referenceID": 9, "context": "Such a tree has a corresponding LVE solution: (i) each sub-problem that we need to solve in such a tree can be formulated as a (sum-out) problem on a model consisting of a parfactor with 1-logvar PRVs, and (ii) we can count-convert all the logvars in a parfactor with 1-logvar PRVs [10, 16], to rewrite all the PRVs into a (bounded) number of counting randvars.", "startOffset": 282, "endOffset": 290}, {"referenceID": 15, "context": "Such a tree has a corresponding LVE solution: (i) each sub-problem that we need to solve in such a tree can be formulated as a (sum-out) problem on a model consisting of a parfactor with 1-logvar PRVs, and (ii) we can count-convert all the logvars in a parfactor with 1-logvar PRVs [10, 16], to rewrite all the PRVs into a (bounded) number of counting randvars.", "startOffset": 282, "endOffset": 290}, {"referenceID": 1, "context": "A dtree can prescribe the operations performed by propositional inference, such as VE [2].", "startOffset": 86, "endOffset": 89}, {"referenceID": 1, "context": "Darwiche [2] shows how we can read a (partial) elimination order from a dtree (by assigning elimination of each randvar to some tree node).", "startOffset": 9, "endOffset": 12}, {"referenceID": 12, "context": "While we focused on LVE, our analysis is also applicable to lifted search-based methods, such as lifted recursive conditioning [13], weighted firstorder model counting [21], and probabilistic theorem proving [6].", "startOffset": 127, "endOffset": 131}, {"referenceID": 20, "context": "While we focused on LVE, our analysis is also applicable to lifted search-based methods, such as lifted recursive conditioning [13], weighted firstorder model counting [21], and probabilistic theorem proving [6].", "startOffset": 168, "endOffset": 172}, {"referenceID": 5, "context": "While we focused on LVE, our analysis is also applicable to lifted search-based methods, such as lifted recursive conditioning [13], weighted firstorder model counting [21], and probabilistic theorem proving [6].", "startOffset": 208, "endOffset": 211}, {"referenceID": 21, "context": "FO-dtrees are also useful to approximate lifted inference algorithms, such as lifted blocked Gibbs sampling [22] and RCR [20], that attempt to improve their inference accuracy by identifying liftable subproblems and handling them by exact inference.", "startOffset": 108, "endOffset": 112}, {"referenceID": 19, "context": "FO-dtrees are also useful to approximate lifted inference algorithms, such as lifted blocked Gibbs sampling [22] and RCR [20], that attempt to improve their inference accuracy by identifying liftable subproblems and handling them by exact inference.", "startOffset": 121, "endOffset": 125}, {"referenceID": 9, "context": "We prove this relying on the properties of counting randvars in PLMs, and the correctness of counting conversion in LVE [10, 16].", "startOffset": 120, "endOffset": 128}, {"referenceID": 15, "context": "We prove this relying on the properties of counting randvars in PLMs, and the correctness of counting conversion in LVE [10, 16].", "startOffset": 120, "endOffset": 128}], "year": 2013, "abstractText": "Lifting attempts to speedup probabilistic inference by exploiting symmetries in the model. Exact lifted inference methods, like their propositional counterparts, work by recursively decomposing the model and the problem. In the propositional case, there exist formal structures, such as decomposition trees (dtrees), that represent such a decomposition and allow us to determine the complexity of inference a priori. However, there is currently no equivalent structure nor analogous complexity results for lifted inference. In this paper, we introduce FO-dtrees, which upgrade propositional dtrees to the first-order level. We show how these trees can characterize a lifted inference solution for a probabilistic logical model (in terms of a sequence of lifted operations), and make a theoretical analysis of the complexity of lifted inference in terms of the novel notion of lifted width for the tree.", "creator": "LaTeX with hyperref package"}}}