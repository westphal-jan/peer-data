{"id": "1306.1185", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2013", "title": "Multiclass Total Variation Clustering", "abstract": "Ideas from the image processing literature have recently motivated a new set of clustering algorithms that rely on the concept of total variation. While these algorithms perform well for bi-partitioning tasks, their recursive extensions yield unimpressive results for multiclass clustering tasks. This paper presents a general framework for multiclass total variation clustering that does not rely on recursion. The results greatly outperform previous total variation algorithms and compare well with state-of-the-art NMF approaches.", "histories": [["v1", "Wed, 5 Jun 2013 17:42:57 GMT  (47kb,D)", "http://arxiv.org/abs/1306.1185v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG math.OC", "authors": ["xavier bresson", "thomas laurent 0001", "david uminsky", "james h von brecht"], "accepted": true, "id": "1306.1185"}, "pdf": {"name": "1306.1185.pdf", "metadata": {"source": "CRF", "title": "Multiclass Total Variation Clustering", "authors": ["Xavier Bresson", "Thomas Laurent", "David Uminsky", "James H. von Brecht"], "emails": ["(xbresson@cityu.edu.hk).", "(laurent@math.ucr.edu)", "(duminsky@usfca.edu)", "(jub@math.ucla.edu)"], "sections": [{"heading": "1 Introduction", "text": "Many clustering models are based on minimizing energy over possible partitions of the dataset, until these discrete optimizations usually pose NP-hard problems, however. A natural solution to this problem involves loosening the discrete minimization space into a continuous one to obtain a simpler minimization method. Many current algorithms, such as spectral clustering methods or non-negative matrix factorization (NMF) methods, follow this relaxation approach. However, a fundamental problem arises when using this approach, generally the solution of the relaxed continuous problem and the discrete NP-hard problem, can vary considerably. In other words, relaxation is too loose. Tight relaxation, on the other hand, has a solution that closely coincides with the solution of the original discrete NP-hard problem. Ideas from the imaging literature have recently motivated a new set of algorithms [17, 18, 11, 12, 12, 12, 13, 10] which can achieve narrower than the one used."}, {"heading": "2 The Multiclass Balanced-Cut Model", "text": "Considering a weighted diagram G = (V, W), we leave V = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) | (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) = (A) (A) = (A) (A) = (A) (A) (A) (|) (A) (A) (|) (A) (A) (|) (A) (A) (A) (|) (A) (A) (A) (|) (A) (A) (A) (A) (|) (A) (A) (A) (A) (|) (A) (A) (A) (A) (A) (|) (A) (A) (A) (A) (A) (A) (|) (A) (A) (A) (A) (A) (= A) (A) (A) (A) (A) () (A) (A) (A) (| (A) (A) (A) (A) (A) (= A) (A) (= A) (A) (= A) (A) (= A) (= A) (A) (A) (A) (= A) (= A) (A) (= A) (= A) (= A = A (= A) (= A (= A) (= A) (= A = A) (= A = A (= A) (= A (= A) (= A) (= A) (= A = A = A) (= A = A (= A) (= A = A = A) (= A = A = A = A = A = A = A = A) (= A = A = A = A = A = A = A = A = A = A = A = A = A = A = A ="}, {"heading": "3 Total Variation and a Tight Continuous Relaxation", "text": "We derive our continuous optimisation by changing the adjusted energy (P) to the continuous energy generation (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F. (F). (F). (F). (F. (F).).).). (F. (F.). (F. (F.). (F.). (F. (F.).). (F.). (F.). (F. (F.). (F.). (F.). (F. (F.). (F.). (F. (F.).). (F.). (F. (F.).).)."}, {"heading": "3.1 The Role of Total Variation in the Formation of Quasi-Indicator Functions", "text": "To show the exact role that total variation itself plays in the formation of quasiindicators, it is useful to consider a version of (P-rlx) that uses a spectral relaxation in place of total variation. + fR = 1V (P-rlx2) Here, there are two different approaches. + fR = 1V (P-rlx2) Here, there are two different approaches. + fR = 1A (P-rlx2) Here, there are two different approaches. + fR = 1 (P-rlx2) -1 (F) -2 denotes the spectral relaxation of Cut (A, Ac). It corresponds < f > if L shows the unnormalized graphs of the Laplacian matrix. (Prlx2) refers to spectral clustering (and thus NMF [9]) with a positivity that exists only between the differences."}, {"heading": "3.2 Transductive Framework", "text": "From a modeling point, the presence of transductive labels is not an additional difficulty. In addition to the simplex constraint required for unattended clustering, we also impose the set of labels as a hard constraint. If L1,... LR denotes the R vertex subsets that represent the designated points, so that xi-Lr means xi belongs to class r, then we can force these labels by restricting F to being in the subsetF: = {F-MN-R ([0, 1]): (f1 (xi),... fR (xi)) = er-xi-Lr. \"(8) Here, it denotes the row vector that contains a one in the r location and elsewhere."}, {"heading": "4 Proximal Splitting Algorithm", "text": "This section describes our proximal splitting algorithm for determining local minimizers of a sum of ratios of convex functions subject to a convex constraint. We begin by showing in the first subsection that the functions T (f): = \u043a\u0430f-TV and B (f): = \u0418f-med\u03bb (f) 1-1, \u03bb (9) involved in (P-rlx) or (P-trans) are actually convex. We also give an explicit formula for a subdifferential of B, as our proximal splitting algorithm requires this in explicit form. Afterwards, we summarize some properties of proximal operators before introducing the algorithm."}, {"heading": "4.1 Convexity, Subgradients and Proximal Operators", "text": "Remember that we can consider any function f: V \u2192 R as a vector in RN with f (xi) as the ith component of the vector. We can then consider T and B as functions of RN after R. The next theorem states that both B and T define convex functions in RN and return an element v (f). Functions B and T are convex. Furthermore, f: RN is the vector v (xi) = convective, if f (xi) > med\u03bb (f) + n0, if f (xi) + n0, if f) the convectors B (f) \u2212 1, if f (xi) < med\u03bb (f), if the convectors V (xi) = projected."}, {"heading": "4.2 The Algorithm", "text": "We can solve the problem (P-rlx) or (P-trans) asMinimize C (F) + R (F) + R (F). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D)."}, {"heading": "5 Numerical Experiments", "text": "We are dealing here with a very complex system in which people who are not able to move freely are able to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely, to move freely and to move freely."}, {"heading": "6 Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Proofs of Theorems", "text": "Theorem 4: If f = 1A \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 A subset of A = A = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "6.2 Primal-Dual Formulation", "text": "Consider the minimization F k + 1: = proxT k + \u03b4C (G k) = regardless of which unit (G k). We can call this the saddle point problem u-RNR max p-RMR < p, Ku > + G (u) \u2212 F-K (p). Here, the vector u = (f1,.., fR) t is a \"vectorized\" version of F and the matrix K stands for the block diagonal matrixK: = blkdiag (kBk1 K,..), where K is the gradient matrix of the graph. We define the convex function G (u) asG (u): = 12 R-R = 1 | fr \u2212 gkr | | 2 + inejus C (u), where B is the barrier function of the convex shape."}], "references": [{"title": "Clustering by left-stochastic matrix factorization", "author": ["Raman Arora", "M Gupta", "Amol Kapila", "Maryam Fazel"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Diffuse Interface Models on Graphs for Classification of High Dimensional Data", "author": ["A. Bertozzi", "A. Flenner"], "venue": "Multiscale Modeling and Simulation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Convergence and energy landscape for cheeger cut clustering", "author": ["X. Bresson", "T. Laurent", "D. Uminsky", "J. von Brecht"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Multi-Class Transductive Learning based on ` Relaxations of Cheeger Cut and Mumford-Shah-Potts Model", "author": ["X. Bresson", "X.-C. Tai", "T.F. Chan", "A. Szlam"], "venue": "UCLA CAM Report,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Spectral Clustering Based on the Graph p-Laplacian", "author": ["T. B\u00fchler", "M. Hein"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "A First-Order Primal-Dual Algorithm for Convex Problems with Applications to Imaging", "author": ["A. Chambolle", "T. Pock"], "venue": "Journal of Mathematical Imaging and Vision,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "A Lower Bound for the Smallest Eigenvalue of the Laplacian", "author": ["J. Cheeger"], "venue": "Problems in Analysis,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1970}, {"title": "Spectral Graph Theory, volume 92 of CBMS Regional Conference Series in Mathematics", "author": ["F.R.K. Chung"], "venue": "Published for the Conference Board of the Mathematical Sciences,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "On the equivalence of nonnegative matrix factorization and spectral clustering", "author": ["Chris Ding", "Xiaofeng He", "Horst D Simon"], "venue": "In Proc. SIAM Data Mining Conf,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Fast multiclass segmentation using diffuse interface methods on", "author": ["C. Garcia-Cardona", "E. Merkurjev", "A.L. Bertozzi", "A. Flenner", "A.G. Percus"], "venue": "graphs. Submitted,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "An Inverse Power Method for Nonlinear Eigenproblems with Applications in 1-Spectral Clustering and Sparse PCA", "author": ["M. Hein", "T. B\u00fchler"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Beyond Spectral Clustering - Tight Relaxations of Balanced Graph Cuts", "author": ["M. Hein", "S. Setzer"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "An mbo scheme on graphs for segmentation and image processing", "author": ["E. Merkurjev", "T. Kostic", "A. Bertozzi"], "venue": "UCLA CAM Report 12-46,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "A Finite Algorithm for Finding the Projection of a Point onto the Canonical Simplex of Rn", "author": ["C. Michelot"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1986}, {"title": "Constrained 1-Spectral Clustering", "author": ["S. Rangapuram", "M. Hein"], "venue": "In International conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Normalized Cuts and Image Segmentation", "author": ["J. Shi", "J. Malik"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2000}, {"title": "A total variation-based graph clustering algorithm for cheeger ratio cuts", "author": ["A. Szlam", "X. Bresson"], "venue": "UCLA CAM Report 09-68,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2009}, {"title": "Total variation and cheeger cuts", "author": ["A. Szlam", "X. Bresson"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "Clustering by nonnegative matrix factorization using graph random walk", "author": ["Zhirong Yang", "Tele Hao", "Onur Dikmen", "Xi Chen", "Erkki Oja"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Clustering by low-rank doubly stochastic matrix decomposition", "author": ["Zhirong Yang", "Erkki Oja"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2012}], "referenceMentions": [{"referenceID": 16, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 17, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 10, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 11, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 3, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 14, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 2, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 1, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 12, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 9, "context": "Ideas from the image processing literature have recently motivated a new set of algorithms [17, 18, 11, 12, 4, 15, 3, 2, 13, 10] that can obtain tighter relaxations than those used by NMF and spectral clustering.", "startOffset": 91, "endOffset": 128}, {"referenceID": 17, "context": "Previous total variation algorithms obtain excellent results for two class partitioning problems [18, 11, 12, 3] .", "startOffset": 97, "endOffset": 112}, {"referenceID": 10, "context": "Previous total variation algorithms obtain excellent results for two class partitioning problems [18, 11, 12, 3] .", "startOffset": 97, "endOffset": 112}, {"referenceID": 11, "context": "Previous total variation algorithms obtain excellent results for two class partitioning problems [18, 11, 12, 3] .", "startOffset": 97, "endOffset": 112}, {"referenceID": 2, "context": "Previous total variation algorithms obtain excellent results for two class partitioning problems [18, 11, 12, 3] .", "startOffset": 97, "endOffset": 112}, {"referenceID": 18, "context": "The results significantly outperform previous total variation algorithms and compare well against state-of-the-art approaches [19, 20, 1].", "startOffset": 126, "endOffset": 137}, {"referenceID": 19, "context": "The results significantly outperform previous total variation algorithms and compare well against state-of-the-art approaches [19, 20, 1].", "startOffset": 126, "endOffset": 137}, {"referenceID": 0, "context": "The results significantly outperform previous total variation algorithms and compare well against state-of-the-art approaches [19, 20, 1].", "startOffset": 126, "endOffset": 137}, {"referenceID": 6, "context": "The classical balanced-cut (or, Cheeger cut) [7, 8] asks for a partition of V = A \u222a A into two disjoint sets that minimizes the set energy", "startOffset": 45, "endOffset": 51}, {"referenceID": 7, "context": "The classical balanced-cut (or, Cheeger cut) [7, 8] asks for a partition of V = A \u222a A into two disjoint sets that minimizes the set energy", "startOffset": 45, "endOffset": 51}, {"referenceID": 3, "context": "Previous work [4] has used \u03bb = 1 to obtain a multiclass energy by a straightforward sum of the twoclass balanced-cut terms (1).", "startOffset": 14, "endOffset": 17}, {"referenceID": 0, "context": ", fR] \u2208 MN\u00d7R([0, 1]) denotes the N \u00d7 R matrix that contains in its columns the relaxed optimization variables associated to the R clusters.", "startOffset": 13, "endOffset": 19}, {"referenceID": 0, "context": "We obtain the relaxed version (P-rlx) of (P\u2019) in the usual manner by allowing fr \u2208 [0, 1] to have a continuous range.", "startOffset": 83, "endOffset": 89}, {"referenceID": 0, "context": ", fR : V \u2192 [0, 1] such that f1 + .", "startOffset": 11, "endOffset": 17}, {"referenceID": 0, "context": "Since these quasi-indicator functions essentially take values in the discrete set {0, 1} rather than the continuous interval [0, 1], solving (P-rlx) is almost equivalent to solving either (P) or (P\u2019).", "startOffset": 125, "endOffset": 131}, {"referenceID": 0, "context": ", fR : V \u2192 [0, 1] such that f1 + .", "startOffset": 11, "endOffset": 17}, {"referenceID": 8, "context": "Thus problem (Prlx2) relates to spectral clustering (and therefore NMF [9]) with a positivity constraint.", "startOffset": 71, "endOffset": 74}, {"referenceID": 7, "context": "Several previous works have proven that the relaxation is exact in the two-class case; that is, the total variation solution coincides with the solution of the original NP-hard problem [8, 18, 3, 5].", "startOffset": 185, "endOffset": 198}, {"referenceID": 17, "context": "Several previous works have proven that the relaxation is exact in the two-class case; that is, the total variation solution coincides with the solution of the original NP-hard problem [8, 18, 3, 5].", "startOffset": 185, "endOffset": 198}, {"referenceID": 2, "context": "Several previous works have proven that the relaxation is exact in the two-class case; that is, the total variation solution coincides with the solution of the original NP-hard problem [8, 18, 3, 5].", "startOffset": 185, "endOffset": 198}, {"referenceID": 4, "context": "Several previous works have proven that the relaxation is exact in the two-class case; that is, the total variation solution coincides with the solution of the original NP-hard problem [8, 18, 3, 5].", "startOffset": 185, "endOffset": 198}, {"referenceID": 0, "context": "Figure 2(a) shows the quasi-indicator function f4 obtained by our MTV algorithm while 2(b) shows the function f4 obtained from the NMF algorithm of [1].", "startOffset": 148, "endOffset": 151}, {"referenceID": 0, "context": "Right: Solution f4 from LSD [1] plotted over the fours and nines.", "startOffset": 28, "endOffset": 31}, {"referenceID": 0, "context": "F \u2208 \u03a3 := { F \u2208MN\u00d7R([0, 1]) : fr(xi) \u2265 0, R \u2211", "startOffset": 19, "endOffset": 25}, {"referenceID": 0, "context": ", LR denote the R vertex subsets representing the labeled points, so that xi \u2208 Lr means xi belongs to class r, then we may enforce these labels by restricting F to lie in the subset F \u2208 \u039b := {F \u2208MN\u00d7R([0, 1]) : \u2200r, (f1(xi), .", "startOffset": 200, "endOffset": 206}, {"referenceID": 10, "context": "The formula for the subdifferential generalizes a related result for the symmetric case [11] to the asymmetric setting.", "startOffset": 88, "endOffset": 92}, {"referenceID": 5, "context": "In this work we use the primal-dual algorithm of [6] with acceleration.", "startOffset": 49, "endOffset": 52}, {"referenceID": 13, "context": "When C = \u03a3 the algorithm [14] performs the required projection in at most R steps.", "startOffset": 25, "endOffset": 29}, {"referenceID": 3, "context": "We obtained the first data set (4MOONS) and its similarity matrix from [4] and the remaining five data sets and matrices (WEBKB4, OPTDIGITS, PENDIGITS, 20NEWS, MNIST) from [19].", "startOffset": 71, "endOffset": 74}, {"referenceID": 18, "context": "We obtained the first data set (4MOONS) and its similarity matrix from [4] and the remaining five data sets and matrices (WEBKB4, OPTDIGITS, PENDIGITS, 20NEWS, MNIST) from [19].", "startOffset": 172, "endOffset": 176}, {"referenceID": 10, "context": "We compare against two previous total variation algorithms [11, 3], which rely on recursive bi-partitioning, and two top NMF algorithms [1, 19].", "startOffset": 59, "endOffset": 66}, {"referenceID": 2, "context": "We compare against two previous total variation algorithms [11, 3], which rely on recursive bi-partitioning, and two top NMF algorithms [1, 19].", "startOffset": 59, "endOffset": 66}, {"referenceID": 0, "context": "We compare against two previous total variation algorithms [11, 3], which rely on recursive bi-partitioning, and two top NMF algorithms [1, 19].", "startOffset": 136, "endOffset": 143}, {"referenceID": 18, "context": "We compare against two previous total variation algorithms [11, 3], which rely on recursive bi-partitioning, and two top NMF algorithms [1, 19].", "startOffset": 136, "endOffset": 143}, {"referenceID": 10, "context": "We use the normalized Cheeger cut versions of [11] and [3] with default parameters.", "startOffset": 46, "endOffset": 50}, {"referenceID": 2, "context": "We use the normalized Cheeger cut versions of [11] and [3] with default parameters.", "startOffset": 55, "endOffset": 58}, {"referenceID": 18, "context": "from [19] to test each NMF algorithm.", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": "All non-recursive algorithms (LSD [1], NMFR [19], MTV) received two types of initial data: (a) the deterministic data used in [19]; (b) a random procedure leveraging normalized-cut [16].", "startOffset": 34, "endOffset": 37}, {"referenceID": 18, "context": "All non-recursive algorithms (LSD [1], NMFR [19], MTV) received two types of initial data: (a) the deterministic data used in [19]; (b) a random procedure leveraging normalized-cut [16].", "startOffset": 44, "endOffset": 48}, {"referenceID": 18, "context": "All non-recursive algorithms (LSD [1], NMFR [19], MTV) received two types of initial data: (a) the deterministic data used in [19]; (b) a random procedure leveraging normalized-cut [16].", "startOffset": 126, "endOffset": 130}, {"referenceID": 15, "context": "All non-recursive algorithms (LSD [1], NMFR [19], MTV) received two types of initial data: (a) the deterministic data used in [19]; (b) a random procedure leveraging normalized-cut [16].", "startOffset": 181, "endOffset": 185}, {"referenceID": 2, "context": "Alg/Data 4MOONS WEBKB4 OPTDIGITS PENDIGITS 20NEWS MNIST NCC-TV [3] 88.", "startOffset": 63, "endOffset": 66}, {"referenceID": 10, "context": "80 1SPEC [11] 73.", "startOffset": 9, "endOffset": 13}, {"referenceID": 0, "context": "17 LSD [1] 99.", "startOffset": 7, "endOffset": 10}, {"referenceID": 18, "context": "67 NMFR [19] 77.", "startOffset": 8, "endOffset": 12}, {"referenceID": 5, "context": "We may therefore apply algorithm 2 of [6] with \u03b3 = 1 with to solve the saddle-point problem.", "startOffset": 38, "endOffset": 41}], "year": 2013, "abstractText": "Ideas from the image processing literature have recently motivated a new set of clustering algorithms that rely on the concept of total variation. While these algorithms perform well for bi-partitioning tasks, their recursive extensions yield unimpressive results for multiclass clustering tasks. This paper presents a general framework for multiclass total variation clustering that does not rely on recursion. The results greatly outperform previous total variation algorithms and compare well with state-of-the-art NMF approaches.", "creator": "LaTeX with hyperref package"}}}