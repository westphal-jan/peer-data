{"id": "1306.4650", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jun-2013", "title": "Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization", "abstract": "Majorization-minimization algorithms consist of iteratively minimizing a majorizing surrogate of an objective function. Because of its simplicity and its wide applicability, this principle has been very popular in statistics and in signal processing. In this paper, we intend to make this principle scalable. We introduce and study a stochastic majorization-minimization scheme, which is able to deal with large-scale or possibly infinite data sets. When applied to convex optimization problems under suitable assumptions, we show that it achieves an expected convergence rate of O(1/\\sqrt{n}) after n iterations, and O(1/n) for strongly convex functions. Equally important, our scheme almost surely converges to stationary points for a large class of non-convex problems. We derive from our framework several efficient algorithms. First, we propose a new stochastic proximal gradient method, which experimentally matches state-of-the-art solvers for large-scale l1-logistic regression. Second, we develop an online DC programming algorithm for non-convex sparse estimation. Finally, we demonstrate the effectiveness of our technique for solving large-scale structured matrix factorization problems.", "histories": [["v1", "Wed, 19 Jun 2013 19:21:48 GMT  (292kb)", "https://arxiv.org/abs/1306.4650v1", null], ["v2", "Tue, 10 Sep 2013 12:29:41 GMT  (299kb)", "http://arxiv.org/abs/1306.4650v2", "accepted for publication for Neural Information Processing Systems (NIPS) 2013. This is the 9-pages version followed by 16 pages of appendices. The title has changed compared to the first technical report"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG math.OC", "authors": ["julien mairal"], "accepted": true, "id": "1306.4650"}, "pdf": {"name": "1306.4650.pdf", "metadata": {"source": "CRF", "title": "Stochastic Majorization-Minimization Algorithms for Large-Scale Optimization", "authors": ["Julien Mairal"], "emails": ["julien.mairal@inria.fr"], "sections": [{"heading": null, "text": "ar Xiv: 130 6.46 50v2 [st at.M L] 10 Se \u221a n) after n iterations and from O (1 / n) after strongly convex functions.Equally important, our scheme almost certainly converges to stationary points for a large class of non-convex problems. We develop several efficient algorithms based on our framework. First, we propose a new stochastic proximal gradient method that is experimentally comparable to state-of-the-art solutions for large-scale logistic regression. Second, we develop an online DC programming algorithm for non-convex sparse estimation. Finally, we demonstrate the effectiveness of our approach to solving large-scale structured matrix factoring problems."}, {"heading": "1 Introduction", "text": "This idea can indeed be found in many existing procedures, such as the Expectation Maximization (EM) algorithm (see [5]), which builds a surrogate for a probability model by using Jensen's inequality. Other approaches can also be interpreted from the point of view of majority minimization, such as DC programming [8], which recognizes the difference between convex functions, variational Bayes techniques, and proximal algorithms. In this paper, we present a stochastic majorization minimization algorithm that is suitable for solving large-scale problems."}, {"heading": "2 Optimization with First-Order Surrogate Functions", "text": "The success of such a scheme depends on how well the surrogates f: In this paper we will consider a certain class of surrogate functions introduced in [18] and defined as follows: Definition 2.1 (Strongly Convex First-Order Functions) In this paper, let us consider a certain class of surrogate functions introduced in [18] and defined as follows: Definition 2.1 (Strongly Convex First-Order Functions). Let us consider the meaning of surrogate functions in relation to SL (f) the group of surrogate functions introduced in relation to the surrogate functions in relation to the desired and desired functions in relation to the desired functions introduced in relation to the desired functions in relation to the desired functions in relation to the desired functions, the desired functions in relation to the desired functions in relation to the desired functions, the desired functions in relation to the desired functions in relation to the desired functions are introduced."}, {"heading": "3 Stochastic Optimization", "text": "As stated in [4], one is normally not interested in minimizing an empirical cost estimate for a finite training, but in minimizing expected costs. Therefore, from now on, we assume that f has the form of an anticipated loss function. As often happens in the literature, we assume that expectations are well defined and finally evaluated; we also assume that f from a predetermined X is a data point drawn according to an unknown distribution, and that it is an ongoing loss function. As often done in the literature, we assume that expectations are well defined and finally evaluated; we also assume that f is limited by a predetermined X. We present our approach to coping (2) in algorithm 1. We draw a training point xn, assuming that these points are i.i.d. samples from the data distribution i.i.d. in practice, since it is often difficult to obtain true i.i.e samples, points are calculated randomly on a school."}, {"heading": "3.1 Convergence Analysis - Convex Case", "text": "First, we examine the case of the convex functions fn: \u03b8 7 \u2192 (\u03b8, xn) and assume that (A) the functions fn are constant R-Lipschitz continuous. Note that this is equivalent for convex functions with the statement that the subgradients of fn are uniformly limited by R. Assumption (A) classically in the stochastic optimization literature [22]. Our first result shows that with the average scheme corresponding to \"Option 2\" in Alg. 1, we obtain an expected convergence rate that explicates the role of the weight sequence. (wn) n Proposition 3.1 (convergence rate). If the functions fn are convex, assuming (A), and if we have a convergence rate of \"Option 2\" in Alg. 1, we obtain an expected convergence rate that makes the role of the weight sequence explicit Proposition (3.n) (conversion rate)."}, {"heading": "3.2 Convergence Analysis - Strongly Convex Case", "text": "In this section we present an additional assumption: (B) the functions fn are \u00b5-strongly convex. We show that our method achieves a rate O (1 / n), which is optimal up to a multiplication constant for strongly convex functions (see [14, 22]). Suggestion 3.2 (convergence rate). Under assumptions (A) and (B), with B = L + \u00b5. Define \u03b2, mq and wn, 1 + \u03b2 1 + \u03b2n. Then E [f (\u03b8 n \u2212 1) \u2212 f] + \u03c12 E [\u0441\u0432."}, {"heading": "3.3 Convergence Analysis - Non-Convex Case", "text": "In such a context, convergence to a global (or local) minimum is unattainable, and the support X of the data is compact; (D) The functions fn are uniformly limited by some constant M; (E) The weights wn are not increasing, w1 = 1, [n] the weights w1 = 1, [n] the weights w1 = 1, [n] the weights w1 = 1, [n] the weights are not increasing, [n] the weights are not increasing, [n] the weights w1 = 1, [n] the weights are not increasing, [n] and [n] the weights are not increasing. \"(F) The directional derivatives are fn (n), (n) the\" we. \""}, {"heading": "4 Applications and Experimental Validation", "text": "In this section we present various applications and offer numerical experiments. A C + + / Matlab implementation is available in the SPAMS [19] software package.2 All experiments were performed on a single core of a 2GHz Intel CPU with 64 GB of RAM.2http: / / spams-develop.gforge.inria.fr /."}, {"heading": "4.1 Stochastic Proximal Gradient Descent Algorithm", "text": "Our first application is a stochastic gradient method, which we call SMM (Stochastic Majorisation Minimization), to solve the problems of the form. (4) We can therefore use the proximal gradient questioning in Section 2. Assuming that a weight sequence (wn) n \"s is chosen.\" (4) We believe that a weight sequence (n) n \"s sequence (wn) n\" s sequence (n) n \"s sequence (n) n\" s sequence (n) n \"s sequence (n) n\" s sequence (n) n \"s sequence (n) n\" s sequence (n) n \"s sequence (n) n\" s sequence (n) n \"s sequence (n) n\" s sequence (n) n \"sequence (n) n (n) n (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n) (n)"}, {"heading": "4.2 Online DC Programming for Non-Convex Sparse Estimation", "text": "We are now looking at the same experimental setting as in the previous section, but with a non-convex regularization mechanism. A classic method for minimizing regulated empirical costs is DC programming. It consists in solving a sequence of reweighted problems [8]. A current estimate is updated as a solution to minimized empirical costs."}, {"heading": "4.3 Online Structured Sparse Coding", "text": "In this case, we will be able to see the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforementioned rf for the aforf for the aforementioned rf for the aforf for the aforf for the aforf-g for the aforf-g for the aforf-g for the aforf-d for the aforf-d for the aforf-d for the af-d for the af-d for the af-d for the af-d for the af-d for the aforf-d for the af-d for the af-d for the aforf-d for the aforf-d for the aforf-d for the af-d for the af-d for the af-d for the af for the af-d for the af for the af for the af-d for the af-d for the af for the af for the aforf for the af for the af for the af-d for the af for the af for the aforf for the af for the af for the aforf for the af for the af for the af for the af for the af for the af for the af for the af for the af for the af for the af for the af for the af for the af for the af for the af for the"}, {"heading": "5 Conclusion", "text": "In this work, we have introduced a stochastic majorization minimization algorithm that gracefully scales to millions of training samples. We have shown that it has strong theoretical properties and some practical value associated with machine learning. We have derived several new algorithms from our framework that are state-of-the-art in solving large-scale convex problems or surpassing them, opening up new possibilities for non-convex problems. In the future, we would like to investigate replacement functions that can exploit the curvature of objective function, which we believe is crucial for dealing with poorly conditioned data sets."}, {"heading": "Acknowledgments", "text": "This work was supported by the Gargantua project (Mastodon Programme - CNRS)."}, {"heading": "A Mathematical Background and Useful Results", "text": "The definition of subgradients and directional derivatives can be found in the classic textbooks, which have a similar notation to ours.In this section we present several classic optimization and probability tools that we use in our paper. The first problem is a classic square generic term for differentiable functions with a Lipschitz gradient. Let's f: Rp \u2192 R-Lipschitz gradients. [18].Lemma A.1 (Convex Surrogate for Functions with Lipschitz)."}, {"heading": "Lemma A.5. Deterministic Lemma on Non-negative Converging Series.", "text": "Let us now proceed with the contradiction and assume that we necessarily have a lim infn, that is, a lim infn, a lim infn, a bn = 0. Otherwise, it would be easy to disagree with the assumption that n \u2265 1 anbn < + \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square square"}, {"heading": "Lemma A.6. Stochastic Lemma on Non-negative Converging Series.", "text": "Let (Xn) n \u2265 1 be a sequence of non-negative measurable random variables on a probability range. Let's suppose bn were two non-negative sequences, so \u2211 n \u2265 1 an = + \u221e and \u0445 n \u2265 1 anbn < + \u221e. Let's suppose that there is a constant C, so that for all n \u2265 1, E [Xn] \u2264 bn and | Xn + 1 \u2212 Xn | Can almost certainly. Then Xn almost certainly converges to zero. The following series is Convergent E \u0445 n \u2265 1 anXn = \u2211 n \u2265 1 E [anXn] \u2264 1 anbn < + \u221e, taking advantage of the fact that the random variables are not negative to exchange the sum and the expectation. So we have that the probability 1 anXn \u2265 1 anXn converges with probability one. Then let's call a \u2032 n = an and b \u2032 n = Xn; the conditions of A.5 are safe for one and one \u00b2 with probability n \u00b2 and almost n."}, {"heading": "B Auxiliary Lemmas", "text": "In this section we present auxiliary lemmas for our convex and non-convex analyses, starting with the presentation of a problem that is useful for both and actually represents a core component for all the results presented in [18]. The proof for this problem is simple and available in [18].Lemma B.1 (basic characteristics of first-class surrogacy functions). Leave g to be in SL (f) for some time. Define the approximation error function h-f and let it be a minimizer of. Then, for all other countries of the world, \u2022 (B) = 0; (H) = 22; (T) \u2264 (T) f (T) f (T) (T) + (T) 22 \u00b7 2 \u0441\u0442\u0440\u043e\u0441\u0441\u0441\u0441\u043e\u0441\u043e\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0441\u0441\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0441\u0441\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0441\u0438\u0441\u0441\u0441\u0441\u0438\u0441\u0438"}, {"heading": "B.1 Convex Analysis", "text": "We imagine, for all the n + 0, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n + 1, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity, the quantity n, the quantity n, the quantity n, the quantity n, the quantity, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n, the quantity n,"}, {"heading": "B.2 Non-convex Analysis", "text": "When the functions fn \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 (s \u00b2), convergence analysis plays a greater role. A key tool we use is a uniform convergence result when the function class (x 7) is derived from empirical processes [27], which gives us the following Lemma.Lemma B.6 (Uniform Convergence). Under the assumptions (A), (C) and (D) we have the following uniform law of large numbers: E [sup] n \u00b2 n \u00b2 n \u00b2 n \u00b2 n \u00b2 i = 1fi \u00b2 \u2212 f (Uniform Convergence) \u2264 C \u00b2 n \u00b2 n \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s (s)."}, {"heading": "First part of the lemma:", "text": "Fix n > 0. It is easy to show that f \u2212 n can be written as f \u2212 n = 1 = 1 = 1 = 1 = 1 (unfortunately) with w n = wn for some non-negative weights. We also define the empirical costs Fi, 1 n \u2212 i + 1 \u00b2 n = i fj. According to (9) we have E [sup\u03b8] \u2212 f (270) \u2212 f (270). This relationship can be demonstrated by simple calculation. We get the first part by using the triangular inequality and the fact that the gain wi \u2212 1n = 1 (win \u2212 wi \u2212 1n) (n \u2212 i + 1) (fi \u2212 f) (fi \u2212 f), where we have defined w0n \u2212 n, 0."}, {"heading": "Second part of the lemma:", "text": "We call this: \"Xn\" (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\" (\"Xn\") (\"Xn\") (\"Xn\") (\"Xn\") (\") (\" (\") (\") (\"(\") (\") (\") (\"(\") (\") (\" (\") (\") (\") (\") (\"(\") (\") (\") (\"(\") (\") (\") (\") (\" (\")\" (\") (\") (\"(\") (\") (\") (\"(\") \"(\") (\"(\") \"(\") \"(\") \"(\" (\")\" (\")\" (\")\" (\"(\") \"(\") \"(\") \"(\") \"(\" (\") (\") \"(\") \"(\" (\")\" (\")\" (\"(\") \"(\") \"(\" (\")\" (\"(\") \"(\" (\")\" (\")\" (\")\" (\"(\") \"(\" (\")\" (\"(\") \"(\" (\")\") \"(\" (\")\" (\"(\" (\")\" (\")\" (\"(\") \"(\" (\")\" (\"(\") \"(\" (\")\") \"(\") \"(\" (\")\" (\"(\" (\"(\") \"(\") \"(\") \"(\") \"(\" (\"()\" (\"()\" (\"(\") \"(\") \"(\" (\"()\" () \"(\" (\")\" ("}, {"heading": "C Proofs of the Main Lemmas and Propositions", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C.1 Proof of Proposition 3.1", "text": "Proof. According to Lemma B.4 we have for all n \u2265 1, wnBn \u2212 1 \u2264 wnf + LwnAn \u2212 1 \u2212 LwnAn \u2212 1 + wnCn \u2212 1. By using the relations (7), this corresponds to Bn \u2212 1 \u2212 Bn + wnE [f (\u03b8n \u2212 1)] \u2264 wnf + L (An \u2212 1 \u2212 An) + Cn \u2212 1 \u2212 Cn + (Rwn) 22L. If we add these inequalities between 1 and n, we get B0 \u2212 Bn + n k = 1wkE [f (\u041ak \u2212 1)] \u2264 (n \u041ak = 1wk) f + LA0 \u2212 Lan \u2212 Cn + k = 1 (Rwk) 22L. Note that we also get Bn \u2264 f + LAn + Cn = LAn + B0 \u2212 LA0 + Lbr0.Therefore, by combining the two previous inequalities, n \u2012 k = 1wk = E k = 1wf k k = 1 k = k (k)."}, {"heading": "C.2 Proof of Corollary 3.1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof.", "text": "We choose the weights of the form wn, \u03b3 \u221a n. Then we have chosen \u0445 k = 1w2k \u2264 \u03b32 (1 + logn), using the fact that \u0445 n k = 1 1 k \u2264 1 + log (n). We also have for n \u2265 2, n \u0445 k = 1wk \u2265 2\u03b3 (\u221a n + 1 \u2212 1) \u2265 \u03b3 n, using the fact that \u0441n k = 1 1 1 \u221a k \u2265 2 (\u221a n + 1 \u2212 1), and the fact that 2 (\u221a n + 1 \u2212 1) \u2264 n forall n \u2265 2. If we put this inequality in (3), the desired result is obtained."}, {"heading": "C.3 Proof of Proposition 3.2", "text": "We proceed in several steps and prove the convergence rates of several interest rates. Convergence rate of Cn: Let us now show by induction that we have Cn \u2264 R 2 \u03c1 wn for all n \u2265 1. This obviously applies to n = 1 according to definitions of w1 = 1 and C1 = R 2 2\u03c1. Let us now assume that it applies to n \u2212 1. We have Cn = (1 \u2212 wn) Cn \u2212 1 + R22\u03c1 w2n \u2264 R 2\u03c1 wn ((((1 \u2212 wn) wn \u2212 1) wn (n \u2212 1) \u2264 R 2\u03c1 (\u03b2 (n \u2212 1) \u03b2n + 1) + 1 \u03b2 (n \u2212 -1) \u2264 R 2\u03c1 wn (n \u2212 1) \u03b2 (n \u2212 1) \u03b2 (n \u2212 1) \u03b2 (n \u2212 1) \u03b2 (n \u2212 1), we come to the conclusion that we have the quality of this \u03b2 (n \u2212 \u03b2) for 10. We have this \u03b2 (n \u2212 \u03b2), we have 1 \u03b2 for 10 \u2212 \u03b2, we have 1 \u03b2 for 1 \u03b2, \u2212 \u03b2 n."}, {"heading": "An \u2264 \u03b4wn for all n \u2265 1.", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Convergence rate of E[f(\u03b8\u0302n)\u2212 f\u22c6] + \u03c1\u03ben:", "text": "We reuse Lemma B.4: Bn \u2212 f + 1 \u2264 LAn + Cn, and we consider two possible cases \u2022 If we simply use the convergence rates of A and Cn that were calculated before. \u2022 If we instead use R2 \u03c1\u00b5 < 0 (1 + L\u00b5) wn = R2\u00b5 wn \u2264 2R 2\u00b5 (\u03b2n + 1) wn \u2264 0wn \u2264 2\u03c1\u044b\u03b2n + 1. It is then easy to prove that E [f (\u03b8) \u2212 f] \u2264 Bn is by using Jensen's inequality that allows us to draw conclusions."}, {"heading": "C.4 Proof of Proposition 3.3", "text": "Proof. We generalize the convergence proof for the online matrix factorization of [19]. The proof uses theorem A.1 on the convergence of quasi-martyrids [33], similar to [3] for the proof of the convergence of the stochastic gradient descendant algorithm for non-convex functions."}, {"heading": "Almost sure convergence of (g\u0304n(\u03b8n))n\u22651:", "text": "The first step consists in the application of a convergence theorem for the sequence (g \u00b2 n (n \u00b2 n (n \u00b2 n)) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n (n \u00b2) n (n (n \u00b2) n (n \u00b2) n (n (n \u00b2) n (n \u00b2) n (n (n \u00b2) n (n \u00b2) n (n (n \u00b2) n (n \u00b2) n (n \u00b2) n (n (n \u00b2) n (n) n (n \u00b2) n (n) n (n (n \u00b2) n (n) n (n) n (n) n (n \u00b2 n) n (n (n) n (n) n (n) n (n \u00b2 n) n (n) n (n) n (n (n) n (n \u00b2 n) n (n (n \u00b2 n) n (n \u00b2 n) n (n \u00b2 n) n (n (n) n \u00b2 n (n) n (n) n (n (n) n (n) n \u00b2 n (n) n (n (n) n (n \u00b2 n) n (n (n) n (n) n (n \u00b2 n (n) n (n (n) n (n) n (n \u00b2 n (n) n (n) n (n) n (n (n (n) n) n (n ("}, {"heading": "Almost sure convergence of (f\u0304n(\u03b8n))n\u22651:", "text": "We will show by using Lemma A.5 that the non-positive term f \u2212 n \u2212 n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n (n) n n (n) n (n) n (n) n (n) n (n) n (n (n) n (n) n (n) n (n) n (n) n n (n) n (n) n n n (n) n n (n) n n n n n (n) n n n (n) n n n (n) n) n n (n) n n n n n (n) n) n n (n) n) n n (n) n) n n (n) n n n n (n) n) n (n) n) n n (n) n) n n (n) n) n n n n n) n n (n) n) n (n) n) n n (n) n) n (n) n) n n n) n n (n) n n n n n (n) n) n n (n) n) n n (n) n) n (n) n) n n (n) n n (n) n) n (n n) n) n (n) n) n n (n) n) n n) n (n) n n) n (n) n n) n (n) n (n) n) n (n) n (n) n) n) n (n) n) n (n) n) n) n (n) n) n (n) n (n) n) n) n (n) n (n) n) n) n (n) n"}, {"heading": "Almost sure convergence of (f(\u03b8n))n\u22651:", "text": "Since (f) n (\u03b8n) n \u2265 1 almost certainly converges, we simply use lemmas A.6, which tells us that f) n converges uniformly to f. Then converges (f (\u03b8n) n \u2265 1 almost certainly to g)."}, {"heading": "Asymptotic Stationary Point Condition:", "text": "Let us call h-n, g-n \u2212 f-n, which can be differentiated by the definition of a L-Lipschitz gradient. Since \"n\" is the minimizer of \"g-n,\" we have \"g-n\" (\"n,\" \"n\") = \"g-n\" (\"n,\" \"n\"). Since \"h-n\" is differentiable and its gradient is \"L-Lipschitz,\" we can apply Lemma A.1 to \"n\" (\"n\") and \"n\" (\"n\") \u2212 1L-h-n \"(\" n \"), which results in\" h-n \"(\" n \"),\" h-n \"(\" n \"),\" n-n \"(\" n \") and\" n-n \"(\" n \")."}, {"heading": "C.5 Proof of Proposition 3.4", "text": "The proof. Since convergence is compact after the assumption (C), we can also find in this convergent sequence a sequence (nk) k \"that converges so that it converges to a point (which is compact). For the sake of simplicity and without loss of generality, we can remove the indices k and k\" from the notation and assume that they converge to a point while converging to a point. It is then easy to see that the functions g \"n\" converge uniformly to g, \"since the assumptions made in the proposition are new. The definition h, g\" g \"- f\" - f \"- f,\" we have convergence for all: the convergence \"- f\" - f \"n.\""}, {"heading": "C.6 Proof of Proposition 3.5", "text": "In the second stage of this proof, we need the functions hn in order to be uniform Lipschitz and uniform. It is easy to check whether it is still the case that we made the assumptions we made in Proposition 3.5.The last step on the asymptotic point state is more problematic where we can no longer show that we made the assumptions we made in Proposition 3.5.The last step on the asymptotic point state is that we are not able to be uniform Lipschitz and uniform. It is easy to check that it is the case that we are in Proposition 3.5.However, the last step on the asymptotic point state is more problematic where we can no longer show that we are in Proposition 3.5.0."}, {"heading": "D Additional Experimental Results", "text": "We present some additional experimental comparisons in Figures 4 and 5, which complement the figures in Section 4.1. Figures 6 and 7 show additional figures from the experiment in Section 4.2. Finally, we present three dictionaries corresponding to the experiment in Section 4.3 in Figures 8, 9 and 10."}, {"heading": "Supplementary References", "text": "[31] D.P. Bertsekas. Nonlinear Programming. Athena Scientific Belmont, 1999. 2nd edition. [32] S. P. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004. [33] D. L. Fisk. Quasi-martingales. T. Am. Math. Soc., 120 (3): 359-388, 1965. [34] M. Me'tivier. Semi-martingales. Walter de Gruyter, 1983. [35] Y. Nesterov. Introductory Lectures on Convex Optimization. Kluwer Academic Publishers, 2004. [36] Y. Nesterov and J.-P. Vial. Confidence Level Solutions for stochastic Programming. Automatica, 44 (6): 1559-1568, 2008. [37] J. Nocedal and S. J. Wright. Numerical Optimization. Springer Verlag, 2006. 2nd edition."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "Majorization-minimization algorithms consist of iteratively minimizing a majorizing surrogate of an objective function. Because of its simplicity and its wide applicability, this principle has been very popular in statistics and in signal processing. In this paper, we intend to make this principle scalable. We introduce a stochastic majorization-minimization scheme which is able to deal with largescale or possibly infinite data sets. When applied to convex optimization problems under suitable assumptions, we show that it achieves an expected convergence rate of O(1/ \u221a n) after n iterations, and of O(1/n) for strongly convex functions. Equally important, our scheme almost surely converges to stationary points for a large class of non-convex problems. We develop several efficient algorithms based on our framework. First, we propose a new stochastic proximal gradient method, which experimentally matches state-of-the-art solvers for large-scale l1logistic regression. Second, we develop an online DC programming algorithm for non-convex sparse estimation. Finally, we demonstrate the effectiveness of our approach for solving large-scale structured matrix factorization problems.", "creator": "LaTeX with hyperref package"}}}