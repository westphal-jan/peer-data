{"id": "1307.0060", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jun-2013", "title": "Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs", "abstract": "The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance, but it has proved difficult to directly implement. Instead, most vision tasks are approached via complex bottom-up processing pipelines. Here we show that it is possible to write short, simple probabilistic graphics programs that define flexible generative models and to automatically invert them to interpret real-world images. Generative probabilistic graphics programs consist of a stochastic scene generator, a renderer based on graphics software, a stochastic likelihood model linking the renderer's output and the data, and latent variables that adjust the fidelity of the renderer and the tolerance of the likelihood model. Representations and algorithms from computer graphics, originally designed to produce high-quality images, are instead used as the deterministic backbone for highly approximate and stochastic generative models. This formulation combines probabilistic programming, computer graphics, and approximate Bayesian computation, and depends only on general-purpose, automatic inference techniques. We describe two applications: reading sequences of degraded and adversarially obscured alphanumeric characters, and inferring 3D road models from vehicle-mounted camera images. Each of the probabilistic graphics programs we present relies on under 20 lines of probabilistic code, and supports accurate, approximately Bayesian inferences about ambiguous real-world images.", "histories": [["v1", "Sat, 29 Jun 2013 02:36:45 GMT  (16122kb,D)", "http://arxiv.org/abs/1307.0060v1", "The first two authors contributed equally to this work"]], "COMMENTS": "The first two authors contributed equally to this work", "reviews": [], "SUBJECTS": "cs.AI cs.CV stat.ML", "authors": ["vikash k mansinghka", "tejas d kulkarni", "yura n perov", "joshua b tenenbaum"], "accepted": true, "id": "1307.0060"}, "pdf": {"name": "1307.0060.pdf", "metadata": {"source": "CRF", "title": "Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs", "authors": ["Vikash K. Mansinghka", "Tejas D. Kulkarni", "Yura N. Perov", "Joshua B. Tenenbaum"], "emails": ["jbt)@mit.edu"], "sections": [{"heading": "1 Introduction", "text": "This year, it is at an all-time high in the history of the European Union."}, {"heading": "2 Generative Probabilistic Graphics Programs and Approximate Bayesian Inference.", "text": "Generative probabilistic graphics programs define generative models for images by combining four components: the first is a stochastic scene generator written as probabilistic code that makes random decisions for the location and configuration of the main elements in the scene; the second is a rough renderer based on existing graphics programs that map a scene S and control variables X to an image IR = f (S, X); the third is a stochastic probability model for the image data ID that enables the scoring of rendered scenes taking into account the control variables; the fourth is a set of latent variables X that control the fidelity of the renderer and / or tolerance in the stochastic probability model. These components are schematically shown in Figure 1. We formulate image interpretation tasks related to sampling (approximately) from posterior distribution over images: P (S | ID), P (X), (IR), X), We execute a single probability execution via single i."}, {"heading": "Stochastic Scene Generator", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Approximate Renderer", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Stochastic", "text": "We also allow X = {Xj} to split the control variable X into parts Xj with the predecessors P (Xj), such as the bandwidths of the pro-glyphs Gaussian spatial blur cores, the variance of a Gaussian image threshold, and so on. Our proposals modify individual elements of the scenery and control variables at one time as follows: P (S) = \"i\" P (Si) qi (S \"i, Si) = P (S\" i) P (X) = \"j\" P (Xj) qj, \"Xj) = P (X\" j \"j\" j \"j\"). Now let K = \"i\" i \"|\" i \"be the total number of random variables in each execution. To simplify, we describe the case in which this number can be limited above, i.e. the total number of scene complexity is limited."}, {"heading": "3 Generative Probabilistic Graphics in 2D for Reading Degraded Text.", "text": "We developed a probabilistic graphics program for reading short texts of degraded texts consisting of arbitrary numbers and letters. See Figure 2 for representative inputs and outputs. In this program, the latent scene S = {Si} contains a bank of variables for each glyph, including whether or not a potential letter is present in the scene, what its spatial coordinates and size are, what its identity is, and how it rotates: P (S x i = x) = {1 / w 0 \u2264 x \u2264 w 0 otherwise P (Syi = y) = {1 / h 0 \u2264 x \u2264 h \u2264 0 otherwiseP (Sglyph idi = g)."}, {"heading": "4 Generative Probabilistic Graphics in 3D: Road Finding.", "text": "This is an important problem in autonomous driving. Just as there are many perception problems in the robotic world, there are also clear scene structures that we use for this problem, but also considerable uncertainties regarding the scenery, as well as considerable image-to-image variability that has to be selected from the ground level to detect the width and gauge of the road, and the 3D displacement of the street corner from the (arbitrary) camera position that we use for this problem. Previous encodes are small in relation to the road, and that the road most likely has two lanes (but cannot be centered)."}, {"heading": "5 Discussion", "text": "We have shown that it is possible to write short probabilistic graphics programs that use simple 2D and 3D computer graphics techniques as the backbone of highly approximate generative models. Approximate Bayesian conclusions about the execution history of these probabilistic graphics programs - automatically implemented by generic, one-dimensional transitions using existing rendering libraries and simple liquids - then implement a new variation of analysis by synthesis [20]. We have also shown that this approach can lead to more precise, unified interpretations of real images, and can report coherent uncertainties about latent scenes when appropriate. Our core contributions are the introduction of this conceptual framework and two initial demonstrations of its effectiveness."}, {"heading": "Acknowledgments", "text": "We are grateful to Keith Bonawitz and Eric Jonas for their preparatory work investigating the feasibility of CAPTCHA Breaking in Church and to Seth Teller, Bill Freeman, Ted Adelson, Michael James and Max Siegel for helpful discussions."}], "references": [{"title": "Real time detection of lane markers in urban streets", "author": ["Mohamed Aly"], "venue": "Intelligent Vehicles Symposium,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "An optimal approximation algorithm for Bayesian inference", "author": ["Paul Dagum", "Michael Luby"], "venue": "Artificial Intelligence", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "Bayesian geometric modeling of indoor scenes", "author": ["L Del Pero"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Are we ready for autonomous driving? The KITTI vision benchmark suite", "author": ["Andreas Geiger", "Philip Lenz", "Raquel Urtasun"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Church: A language for generative models", "author": ["Noah Goodman", "Vikash Mansinghka", "Daniel Roy", "Keith Bonawitz", "Joshua Tenenbaum"], "venue": "UAI", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Generative models for discovering sparse distributed representations", "author": ["Geoffrey E Hinton", "Zoubin Ghahramani"], "venue": "Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1997}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Geoffrey E Hinton", "Simon Osindero", "Yee-Whye Teh"], "venue": "Neural computation", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Putting objects in perspective", "author": ["Derek Hoiem", "Alexei A Efros", "Martial Hebert"], "venue": "Computer Vision and Pattern Recognition,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Markov chain Monte Carlo without likelihoods", "author": ["Paul Marjoram", "John Molitor", "Vincent Plagnol", "Simon Tavar\u00e9"], "venue": "Proceedings of the National Academy of Sciences", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2003}, {"title": "Recognizing objects in adversarial clutter: Breaking a visual CAPTCHA", "author": ["Greg Mori", "Jitendra Malik"], "venue": "Computer Vision and Pattern Recognition,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "author": ["Aude Oliva", "Antonio Torralba"], "venue": "In: International journal of computer vision", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "A parametric texture model based on joint statistics of complex wavelet coefficients", "author": ["Javier Portilla", "Eero P Simoncelli"], "venue": "In: International Journal of Computer Vision", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2000}, {"title": "Model criticism based on likelihood-free inference, with an application to protein network evolution", "author": ["Oliver Ratmann", "Christophe Andrieu", "Carsten Wiuf", "Sylvia Richardson"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "An overview of the Tesseract OCR engine", "author": ["Ray Smith"], "venue": "Ninth International Conference on Document Analysis and Recognition", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2007}, {"title": "Image parsing: Unifying segmentation, detection, and recognition", "author": ["Zhuowen Tu", "Xiangrong Chen", "Alan L Yuille", "Song-Chun Zhu"], "venue": "In: International Journal of Computer Vision", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "Image Segmentation by Data-Driven Markov Chain Monte Carlo", "author": ["Zhuowen Tu", "Song-Chun Zhu"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2002}, {"title": "Approximate Bayesian computation (ABC) gives exact results under the assumption of model error", "author": ["Richard D Wilkinson"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Nonstandard interpretations of probabilistic programs for efficient inference", "author": ["David Wingate", "Noah D Goodman", "A Stuhlmueller", "J Siskind"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Vision as Bayesian inference: analysis by synthesis?", "author": ["Alan Yuille", "Daniel Kersten"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Image Parsing via Stochastic Scene Grammar", "author": ["Yibiao Zhao", "Song-Chun Zhu"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}], "referenceMentions": [{"referenceID": 6, "context": "Many pattern recognition and learning techniques can then be used to build classifiers for individual scene elements, and sometimes to learn the features themselves [7, 6].", "startOffset": 165, "endOffset": 171}, {"referenceID": 5, "context": "Many pattern recognition and learning techniques can then be used to build classifiers for individual scene elements, and sometimes to learn the features themselves [7, 6].", "startOffset": 165, "endOffset": 171}, {"referenceID": 13, "context": "For example, the Tesseract system [15] for optical character recognition is over 10, 000 lines of C++.", "startOffset": 34, "endOffset": 38}, {"referenceID": 14, "context": "Generative models for a range of image parsing tasks are also being explored [16, 3, 17, 21, 19].", "startOffset": 77, "endOffset": 96}, {"referenceID": 2, "context": "Generative models for a range of image parsing tasks are also being explored [16, 3, 17, 21, 19].", "startOffset": 77, "endOffset": 96}, {"referenceID": 15, "context": "Generative models for a range of image parsing tasks are also being explored [16, 3, 17, 21, 19].", "startOffset": 77, "endOffset": 96}, {"referenceID": 19, "context": "Generative models for a range of image parsing tasks are also being explored [16, 3, 17, 21, 19].", "startOffset": 77, "endOffset": 96}, {"referenceID": 17, "context": "Generative models for a range of image parsing tasks are also being explored [16, 3, 17, 21, 19].", "startOffset": 77, "endOffset": 96}, {"referenceID": 15, "context": "But like traditional bottom-up pipelines for vision, these approaches have relied on considerable problem-specific engineering, chiefly to design and/or learn custom inference strategies, such as MCMC proposals [17, 21] that incorporate bottom-up cues.", "startOffset": 211, "endOffset": 219}, {"referenceID": 19, "context": "But like traditional bottom-up pipelines for vision, these approaches have relied on considerable problem-specific engineering, chiefly to design and/or learn custom inference strategies, such as MCMC proposals [17, 21] that incorporate bottom-up cues.", "startOffset": 211, "endOffset": 219}, {"referenceID": 7, "context": "For example, [8] has shown that global, 3D geometric information can significantly improve the performance of bottom-up object detectors.", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "Our probabilistic graphics programs are written in a variant of the Church probabilistic programming language [5].", "startOffset": 110, "endOffset": 113}, {"referenceID": 16, "context": "The approximations and stochasticity in our renderer, scene generator and likelihood models serve to implement a variant of approximate Bayesian computation [18, 10].", "startOffset": 157, "endOffset": 165}, {"referenceID": 8, "context": "The approximations and stochasticity in our renderer, scene generator and likelihood models serve to implement a variant of approximate Bayesian computation [18, 10].", "startOffset": 157, "endOffset": 165}, {"referenceID": 8, "context": "Subsequently, combinations of ABC and MCMC were proposed [10], including variants with inference over the threshold value [14].", "startOffset": 57, "endOffset": 61}, {"referenceID": 12, "context": "Subsequently, combinations of ABC and MCMC were proposed [10], including variants with inference over the threshold value [14].", "startOffset": 122, "endOffset": 126}, {"referenceID": 16, "context": "Most recently, extensions have been introduced where the hard cutoff is replaced with a stochastic likelihood model [18].", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "These CAPTCHAs all involve arbitrary digits and letters, and as a result lack cues from word identity that the best published CAPTCHA breaking systems depend on [11].", "startOffset": 161, "endOffset": 165}, {"referenceID": 13, "context": "To calibrate the difficulty of our corpus, we also ran the Tesseract optical character recognition engine [15] on our corpus; its character detection rate was 37.", "startOffset": 106, "endOffset": 110}, {"referenceID": 3, "context": "(b) Representative test frames from the KITTI dataset [4].", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "(d) Results from [1].", "startOffset": 17, "endOffset": 20}, {"referenceID": 0, "context": "For reference, we include the performance of a sophisticated bottom-up baseline system from [1].", "startOffset": 92, "endOffset": 95}, {"referenceID": 0, "context": "Aly et al [1] 68.", "startOffset": 10, "endOffset": 13}, {"referenceID": 3, "context": "Table 1: Quantitative results for lane detection accuracy on one of the road datasets in the KITTI Vision Benchmark Suite [4].", "startOffset": 122, "endOffset": 125}, {"referenceID": 18, "context": "Approximate Bayesian inference over the execution histories of these probabilistic graphics programs \u2014 automatically implemented via generic, single-variable Metropolis-Hastings transitions, using existing rendering libraries and simple likelihoods \u2014 then implements a new variation on analysis by synthesis [20].", "startOffset": 308, "endOffset": 312}, {"referenceID": 11, "context": "Appearance models derived from modern image features and texture descriptors [13, 12] \u2014 going beyond the simple quantizations we currently use \u2014 could also reduce the burden on inference and improve the generalizability of individual programs.", "startOffset": 77, "endOffset": 85}, {"referenceID": 10, "context": "Appearance models derived from modern image features and texture descriptors [13, 12] \u2014 going beyond the simple quantizations we currently use \u2014 could also reduce the burden on inference and improve the generalizability of individual programs.", "startOffset": 77, "endOffset": 85}, {"referenceID": 1, "context": "on factors other than dimensionality [2].", "startOffset": 37, "endOffset": 40}], "year": 2013, "abstractText": "The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance, but it has proved difficult to directly implement. Instead, most vision tasks are approached via complex bottom-up processing pipelines. Here we show that it is possible to write short, simple probabilistic graphics programs that define flexible generative models and to automatically invert them to interpret real-world images. Generative probabilistic graphics programs consist of a stochastic scene generator, a renderer based on graphics software, a stochastic likelihood model linking the renderer\u2019s output and the data, and latent variables that adjust the fidelity of the renderer and the tolerance of the likelihood model. Representations and algorithms from computer graphics, originally designed to produce high-quality images, are instead used as the deterministic backbone for highly approximate and stochastic generative models. This formulation combines probabilistic programming, computer graphics, and approximate Bayesian computation, and depends only on general-purpose, automatic inference techniques. We describe two applications: reading sequences of degraded and adversarially obscured alphanumeric characters, and inferring 3D road models from vehicle-mounted camera images. Each of the probabilistic graphics programs we present relies on under 20 lines of probabilistic code, and supports accurate, approximately Bayesian inferences about ambiguous real-world images.", "creator": "LaTeX with hyperref package"}}}