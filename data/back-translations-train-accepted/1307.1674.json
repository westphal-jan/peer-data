{"id": "1307.1674", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jul-2013", "title": "Stochastic Optimization of PCA with Capped MSG", "abstract": "We study PCA as a stochastic optimization problem and propose a novel stochastic approximation algorithm which we refer to as \"Matrix Stochastic Gradient\" (MSG), as well as a practical variant, Capped MSG. We study the method both theoretically and empirically.", "histories": [["v1", "Fri, 5 Jul 2013 17:39:40 GMT  (88kb,D)", "http://arxiv.org/abs/1307.1674v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["raman arora", "andrew cotter", "nati srebro"], "accepted": true, "id": "1307.1674"}, "pdf": {"name": "1307.1674.pdf", "metadata": {"source": "CRF", "title": "Stochastic Optimization of PCA with Capped MSG", "authors": ["Raman Arora", "Andrew Cotter"], "emails": ["arora@ttic.edu,", "cotter@ttic.edu,", "nati@ttic.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that most of them are able to survive themselves if they do not follow the rules that they have imposed on themselves. (...) It is not the case that they are able to survive themselves. (...) It is not the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) It is the case that they are able to survive themselves. (...) (...) () () (...) () () () () () (...) () () () () () () () () () () () ()) (())) (() ()) (())) (()) () () () ()) () () () () () () ()) () () () () () () () () () ()) () () () () ()) () () () () ()) () () () ()) () () () () () () () ()) () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () () (() (() () () (() () () (() () () (() () () () () () (() ((() (() () () (() () () (() () (() (((() () () () (()"}, {"heading": "2 Problem Setup", "text": "We see PCA as the problem of determining the maximum (unfocused) variance of k-dimensional subspaces in relation to an (unknown) distribution D over x-x-Rd. Without loss of generality, we proceed from a scale as collected in the columns of a matrix U. With this parameterization, PCA is defined as the following stochastic optimization problem, maximized: Ex-D [xTUUTx] (2,1) is subject to: U-Rd-k, UTU = I. In a stochastic optimization setting, we do not have direct knowledge of the distribution and have access to it only through i.i.d. samples - these can be considered \"training examples.\" As with other studies of stoistic approximation methods, we are less concerned with empiricising the required number of samples than with the total number of time required (T = 1 x)."}, {"heading": "3 MSG and MEG", "text": "A natural stochastic approximation (SA) approach to PCA is to carry out projected stochastic gradient lineage (SGD) on problem 2.1, with respect to variable U 3. This leads to the stochastic power method with each iteration given asU (t + 1) = porth (U (t) + \u03b7xtx T t), where xtx T t of the gradient of the PCA object w.r.t. U, \u03b7 is a step size, and porth (\u00b7) projects its reasoning onto the set of orthogonal matrices. Unfortunately, although SGD is well understood for convex problems, problem 2.1 is not convex. Consequently, obtaining a theoretical understanding of the stochastic power method, or how the step size should be determined, has proved elusive. Under some conditions convergence to the optimal solution can be ensured, but no rates are known [Karja and Sanhunen, 1985]."}, {"heading": "3.1 Matrix Stochastic Gradient", "text": "Carrying out SGD on the convex problem 3.2 (w.r.t.) and the resulting solution on the convex problem 3.2 (w.r.t.) results in the following iterations (1983): M (t + 1) = P (Kong) + throuxtx T t), (3.3), where the projection is now based on the (convex) limitations of (3.2). The Matrix Stochastic Gradient (MSG) algorithm includes: 1. Selected step size, iteration number T, and starting point M (0). 2. Iterate the updates (3.3) T times, each using an independent sample xt x x D.3. Average of the iterate as M-size T t = 1M (t = 1M).Algorithm 1 Matrix stochastic gradient (MSG) Update: Calculation of an intrinsic decomposition of M \u00b2 x."}, {"heading": "3.2 Efficient Implementation and Projection", "text": "In this section we show how to perform this update efficiently by maintaining an updated, up-to-date iteration profile of M (t) s, in which the ranks (m (t)) and U (round) can be efficiently updated by inserting 1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-2-1-2-1-1-1-2-1-1-2-1-1-1-1-2-1-1-1-1-1-1-2-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-2-2-1-1-2-1-1-2-1-1-1-2-1-1-1-1-2-1-1-1-1-1-1-2-1-1-1-1-1-1-1-1-2-1-1-1-1-1-1-1-1-1-1-1-1-2-1-1-1-1-1-1-1-1-1-1-1-1-2-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-2-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1"}, {"heading": "3.3 Matrix Exponentiated Gradient", "text": "Since M is constrained by its track and not by its Frobenius standard, it is tempting to consider mirror descent (MD) [Beck and Teboulle, 2003] rather than SGD updates to solve problem 3.2. Remember that mirror descent updates depend on a choice of \"potential function\" (\u00b7) to be selected according to the geometry of the achievable set and gradations [Srebro et al., 2011]. Using the square Frobenius standard as a potential function, i.e., B (M) = N (M) = N) 2F, results in SGD, i.e. the MSG updates (3.3). The track-standard constraint suggests using the von Neumann entropy of the spectrum as a potential function, i.e., h (M) = N (M) = i (M) log (M) (M) (M), where M (x) are the eigenvalues of M."}, {"heading": "4 MSG runtime and the rank of the iterates", "text": "As we have seen, MSG requires O (k / 2) iterations to obtain a -suboptimal solution and any iteration of the MSG cost O (k2t d) operations where kt is the rank ofiterate M (t). This results in a total runtime of the iterate being as long as d, MSG achieves a runtime that is cubic in dimensionality. On the other hand, if the ranking of the iterate is critically dependent on the ranking of the iterate, the runtime of the iterate is as long as d, MSG achieves a proper runtime that is cubic in dimensionality. On the other hand, if the ranking of the iterate O (k), the runtime is linear in dimensionality. Fortunately, in practice, the ranks are typically much lower than the dimensionality. The reason for this is that MSG performs a ranking 1 update followed by a projection on the limitation of M'T (greater dimensionality)."}, {"heading": "5 Capped MSG", "text": "For this reason, we recommend in practice to add a hard constraint K to the rank of the iterates: maximize: Ex-D [xTMx] (5.1) subject to: M-Rd \u00b7 d, 0-M-ItrM = k, rankM \u2264 KWe refer to MSG, where the projection is replaced by a projection to the constraints of (5.1) (i.e., where the iterations are iterated to (5.1), as \"capped MSG.\" For similar reasons as previously discussed, as long as K-K-k, problem 5.1 and problem 3.2 have the same optimum, and it is achieved with a rank-k matrix, and the additional rank constraint of 5.1 is inactive if the constraint of rank-k is identical."}, {"heading": "5.1 Implementing the projection", "text": "The implementation of capped MSG is similar to the implementation of MSG (algorithm 1), except for the projection step. The reasoning as in the proof of Lemma 3.2 shows that if M (t + 1) = P (M \u2032) with M \u2032 = M (t) + \u03b7xtxTt, then M (t) and M \u2032 can be diagonalized simultaneously, and we can therefore only look at how the projection affects the eigenvalues. Thus, if we allow \u03c3 to be the vector of the eigenvalues of M \u2032, and assume that there are more than K of such eigenvalues, then there is a subset of sizeK to the extent that the application of Algorithm 2 to this sentence yields the projected eigenvalues. Since we only perform a ranking 1 update for each iteration, we must verify most K possibilities at the total cost of O (K2 logK) operations, without affecting the asymptotic runtime, since algorithm 1 requires KO (KO) -2d operations."}, {"heading": "5.2 Relationship to the incremental PCA method", "text": "The covered MSG updates with K = k are comparable to the incremental algorithm of Arora et al. [2012] The incremental algorithm maintains an incremental approach to the covariance matrix, which is described by M (t + 1) in the same way as in Section 3.2, with the self-decomposition of iterations limited to the incremental algorithm group. In contrast, incremental updates have not been capped at the number of steps. Updates can be carried out efficiently in Section 3.2 by maintaining the self-decomposition of the iteration. The incremental algorithm has been found to work extremely well in practice, indeed, among the comparative algorithms."}, {"heading": "6 Experiments", "text": "We compared the algorithms on the real MNIST dataset, which consists of 70,000 binary images of handwritten digits of size 28 \u00b7 28, resulting in a dimensionality of 784. We pre-normalized the data by averaging feature vector centering and scaling each feature by the product of its standard deviation and data dimension, so that each feature vector is zero mean and unit of measurement in expectation. In addition to MSG, the incremental algorithm and Warmuth and Kuzmin's algorithm, we also compare with a Grassmannian SGD algorithm by Balzano et al. [2010] all algorithms except the incremental algorithm have a step size parameter. In these experiments, we compared each algorithm with decreasing step size of Warmuth and Kuzmin."}, {"heading": "7 Conclusions", "text": "In this paper, we have presented a careful development and analysis of MSG, a stochastic PCA approximation algorithm that provides good theoretical guarantees and provides a mathematically efficient variant, capped MSG. We show that capped MSG is theoretically well motivated and does not stick to a suboptimal solution. Capped MSG has also proven to be an excellent empirical performance and is therefore a much better alternative to the recently proposed incremental PCA algorithm by Arora et al. [2012]. In addition, we provided a cleaner interpretation of the PCA updates of Warmuth and Kuzmin [2008] in terms of Matrix Exponentiated Gradient (MEG) updates and showed that both MSG and MEG can be interpreted as mirror descending algorithms on the same relaxation of the PCA optimization problem but with different distance generation functions."}, {"heading": "A Proof of Lemma 3.2", "text": "Lemma 3.2. Let M. \"Rd \u00b7 d be a symmetrical matrix, with eigenvalues \u03c3 \u2032 1,.., \u03c3 \u2032 d and associated eigenvectors v\" 1,., v \"d. If M = P (M.\") M \"is projected onto the realizable region of the problem 3.2 in relation to the Frobenius norm, then M will be the unique realizable matrix having the same set of eigenvectors as M.,\" with the associated eigenvalues \u03c31,., \u03c3i = max (0, min (1, \u03c3 \"i + S)), whereby S\".R \"is chosen so that d.\" i \u2212 k. Proof. The problem, M \"can be written in the form of a convex optimization problem \u03c3i,\" and \"we.\" i \"must minimize the conditioners: M \u2212 M.\" 2F \"are subject to 0 M I, trM.\" Because the goal is convex, the constraints are. \"i.\""}], "references": [{"title": "Stochastic optimization for pca and pls", "author": ["Raman Arora", "Andrew Cotter", "Karen Livescu", "Nathan Srebro"], "venue": "In 50th Annual Allerton Conference on Communication, Control, and Computing,", "citeRegEx": "Arora et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2012}, {"title": "Online identification and tracking of subspaces from highly incomplete information", "author": ["Laura Balzano", "Robert Nowak", "Benjamin Recht"], "venue": "CoRR, abs/1006.4046,", "citeRegEx": "Balzano et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Balzano et al\\.", "year": 2010}, {"title": "Mirror descent and nonlinear projected subgradient methods for convex optimization", "author": ["A. Beck", "M. Teboulle"], "venue": "Operations Research Letters,", "citeRegEx": "Beck and Teboulle.,? \\Q2003\\E", "shortCiteRegEx": "Beck and Teboulle.", "year": 2003}, {"title": "The tradeoffs of large scale learning", "author": ["Leon Bottou", "Olivier Bousquet"], "venue": "In NIPS\u201907,", "citeRegEx": "Bottou and Bousquet.,? \\Q2007\\E", "shortCiteRegEx": "Bottou and Bousquet.", "year": 2007}, {"title": "Convex Optimization", "author": ["Stephen Boyd", "Lieven Vandenberghe"], "venue": null, "citeRegEx": "Boyd and Vandenberghe.,? \\Q2004\\E", "shortCiteRegEx": "Boyd and Vandenberghe.", "year": 2004}, {"title": "Incremental singular value decomposition of uncertain data with missing values", "author": ["Matthew Brand"], "venue": "In ECCV,", "citeRegEx": "Brand.,? \\Q2002\\E", "shortCiteRegEx": "Brand.", "year": 2002}, {"title": "Exponentiated gradient algorithms for conditional random fields and max-margin markov networks", "author": ["Michael Collins", "Amir Globerson", "Terry Koo", "Xavier Carreras", "Peter L. Bartlett"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Collins et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Collins et al\\.", "year": 2008}, {"title": "Efficient projections onto the l1-ball for learning in high dimensions", "author": ["John Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Tushar Chandra"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Duchi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2008}, {"title": "Streaming, memory-limited pca", "author": ["Ioannis Mitliagkas", "Constantine Caramanis", "Prateek Jain"], "venue": "URL http://users.ece.utexas.edu/~cmcaram/ pubs/Streaming-PCA.pdf. UT-Austin", "citeRegEx": "Mitliagkas et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mitliagkas et al\\.", "year": 2013}, {"title": "Problem complexity and method efficiency in optimization", "author": ["Arkadi Nemirovski", "David Yudin"], "venue": null, "citeRegEx": "Nemirovski and Yudin.,? \\Q1983\\E", "shortCiteRegEx": "Nemirovski and Yudin.", "year": 1983}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["Arkadi Nemirovski", "Anatoli Juditsky", "Guanghui Lan", "Alexander Shapiro"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nemirovski et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nemirovski et al\\.", "year": 2009}, {"title": "On stochastic approximation of the eigenvectors and eigenvalues of the expectation of a random matrix", "author": ["Erkki Oja", "Juha Karhunen"], "venue": "Journal of Mathematical Analysis and Applications,", "citeRegEx": "Oja and Karhunen.,? \\Q1985\\E", "shortCiteRegEx": "Oja and Karhunen.", "year": 1985}, {"title": "Optimal unsupervised learning in a single-layer linear feedforward neural network", "author": ["Terence D. Sanger"], "venue": "Neural Networks,", "citeRegEx": "Sanger.,? \\Q1989\\E", "shortCiteRegEx": "Sanger.", "year": 1989}, {"title": "SVM optimization: Inverse dependence on training set size", "author": ["Shai Shalev-Shwartz", "Nathan Srebro"], "venue": "In ICML\u201908,", "citeRegEx": "Shalev.Shwartz and Srebro.,? \\Q2008\\E", "shortCiteRegEx": "Shalev.Shwartz and Srebro.", "year": 2008}, {"title": "Stochastic methods for l1 regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Ambuj Tewari"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Shalev.Shwartz and Tewari.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz and Tewari.", "year": 2009}, {"title": "Pegasos: Primal Estimated sub-GrAdient SOlver for SVM", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro"], "venue": "In ICML\u201907,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2007}, {"title": "On the universality of online mirror descent", "author": ["N. Srebro", "K. Sridharan", "A. Tewari"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Srebro et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2011}, {"title": "Randomized online PCA algorithms with regret bounds that are logarithmic in the dimension", "author": ["Manfred K. Warmuth", "Dima Kuzmin"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Warmuth and Kuzmin.,? \\Q2008\\E", "shortCiteRegEx": "Warmuth and Kuzmin.", "year": 2008}, {"title": "Because the objective is strongly convex, and the constraints are convex, this problem must have a unique solution", "author": ["M I", "trM = k"], "venue": "Letting \u03c31,", "citeRegEx": "I and k.,? \\Q2004\\E", "shortCiteRegEx": "I and k.", "year": 2004}], "referenceMentions": [{"referenceID": 0, "context": "In an empirical study of stochastic approximation methods for PCA, a heuristic \u201cincremental\u201d method showed very good empirical performance [Arora et al., 2012].", "startOffset": 139, "endOffset": 159}, {"referenceID": 2, "context": "\u201cbatch\u201d methods) [Bottou and Bousquet, 2007, Shalev-Shwartz and Srebro, 2008]. A similar argument was also made in the context of stochastic optimization, where Nemirovski et al. [2009] argues for stochastic approximation (SA) approaches over ERM.", "startOffset": 18, "endOffset": 186}, {"referenceID": 0, "context": "In an empirical study of stochastic approximation methods for PCA, a heuristic \u201cincremental\u201d method showed very good empirical performance [Arora et al., 2012]. However, no theoretical guarantees or justification were given for incremental PCA. In fact, it was shown that for some distributions it can converge to a suboptimal solution with high probability (see Section 5.2 for more about this \u201cincremental\u201d algorithm). Also relevant is careful theoretical work on online PCA by Warmuth and Kuzmin [2008], in which an online regret guarantee was established.", "startOffset": 140, "endOffset": 506}, {"referenceID": 17, "context": "This follows from the following result of Warmuth and Kuzmin [2008].", "startOffset": 42, "endOffset": 68}, {"referenceID": 17, "context": "1 (Rounding [Warmuth and Kuzmin, 2008]).", "startOffset": 12, "endOffset": 38}, {"referenceID": 17, "context": "1 of Warmuth and Kuzmin [2008] shows how to efficiently find such a convex combination.", "startOffset": 5, "endOffset": 31}, {"referenceID": 9, "context": "Analyzing MSG is straightforward using the standard SGD analysis [Nemirovski and Yudin, 1983]:", "startOffset": 65, "endOffset": 93}, {"referenceID": 9, "context": "Standard SGD analysis of Nemirovski and Yudin [1983] yields that", "startOffset": 25, "endOffset": 53}, {"referenceID": 7, "context": "1Note that our projection problem onto the capped simplex, even when seen in the vector setting, is substantially different from Duchi et al. [2008]. We project onto the set {0 \u2264 \u03c3 \u2264 1, \u2016\u03c3\u20161 = k} in (3.", "startOffset": 129, "endOffset": 149}, {"referenceID": 7, "context": "1Note that our projection problem onto the capped simplex, even when seen in the vector setting, is substantially different from Duchi et al. [2008]. We project onto the set {0 \u2264 \u03c3 \u2264 1, \u2016\u03c3\u20161 = k} in (3.2) and {0 \u2264 \u03c3 \u2264 1, \u2016\u03c3\u20161 = k, \u2016\u03c3\u20160 \u2264 K} in (5.1) whereas Duchi et al. [2008] project onto {0 \u2264 \u03c3, \u2016\u03c3\u20161 = k}.", "startOffset": 129, "endOffset": 278}, {"referenceID": 2, "context": "Since M is constrained by its trace, and not by its Frobenius norm, it is tempting to consider mirror descent (MD) [Beck and Teboulle, 2003] instead of SGD updates for solving Problem 3.", "startOffset": 115, "endOffset": 140}, {"referenceID": 16, "context": "Recall that the Mirror Descent updates depend on a choice of \u201cpotential function\u201d \u03a8(\u00b7) which should be chosen according to the geometry of the feasible set and the subgradients [Srebro et al., 2011].", "startOffset": 177, "endOffset": 198}, {"referenceID": 17, "context": "This leads to multiplicative updates which we refer to as Matrix Exponentiated Gradient (MEG) update similar to those presented by [Warmuth and Kuzmin, 2008].", "startOffset": 131, "endOffset": 157}, {"referenceID": 0, "context": "The capped MSG updates with K = k are similar to the incremental algorithm of Arora et al. [2012]. The incremental algorithm maintains a rank-k approximation of the covariance matrix with updates given by", "startOffset": 78, "endOffset": 98}, {"referenceID": 0, "context": "The incremental algorithm was found to perform extremely well in practice\u2013 it was the best, in fact, among the compared algorithms [Arora et al., 2012].", "startOffset": 131, "endOffset": 151}, {"referenceID": 1, "context": "In addition to MSG, capped MSG, the incremental algorithm and Warmuth and Kuzmin\u2019s algorithm, we also compare to a Grassmannian SGD algorithm of Balzano et al. [2010]. All algorithms except the incremental algorithm have a step-size parameter.", "startOffset": 145, "endOffset": 167}, {"referenceID": 0, "context": "Capped MSG is also shown to have excellent empirical performance and it therefore is a much better alternative to the recently proposed incremental PCA algorithm of Arora et al. [2012]. Furthermore, we provided a cleaner interpretation of PCA updates of Warmuth and Kuzmin [2008] in terms of Matrix Exponentiated Gradient (MEG) updates and showed that both MSG and MEG can be interpreted as mirror descent algorithms on the same relaxation of the PCA optimization problem but with different distance generating functions.", "startOffset": 165, "endOffset": 185}, {"referenceID": 0, "context": "Capped MSG is also shown to have excellent empirical performance and it therefore is a much better alternative to the recently proposed incremental PCA algorithm of Arora et al. [2012]. Furthermore, we provided a cleaner interpretation of PCA updates of Warmuth and Kuzmin [2008] in terms of Matrix Exponentiated Gradient (MEG) updates and showed that both MSG and MEG can be interpreted as mirror descent algorithms on the same relaxation of the PCA optimization problem but with different distance generating functions.", "startOffset": 165, "endOffset": 280}], "year": 2013, "abstractText": "We study PCA as a stochastic optimization problem and propose a novel stochastic approximation algorithm which we refer to as \u201cMatrix Stochastic Gradient\u201d (MSG), as well as a practical variant, Capped MSG. We study the method both theoretically and empirically.", "creator": "LaTeX with hyperref package"}}}