{"id": "1307.4564", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jul-2013", "title": "From Bandits to Experts: A Tale of Domination and Independence", "abstract": "We consider the partial observability model for multi-armed bandits, introduced by Mannor and Shamir. Our main result is a characterization of regret in the directed observability model in terms of the dominating and independence numbers of the observability graph. We also show that in the undirected case, the learner can achieve optimal regret without even accessing the observability graph before selecting an action. Both results are shown using variants of the Exp3 algorithm operating on the observability graph in a time-efficient manner.", "histories": [["v1", "Wed, 17 Jul 2013 10:24:00 GMT  (24kb)", "http://arxiv.org/abs/1307.4564v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["noga alon", "nicol\u00f2 cesa-bianchi", "claudio gentile", "yishay mansour"], "accepted": true, "id": "1307.4564"}, "pdf": {"name": "1307.4564.pdf", "metadata": {"source": "CRF", "title": "From Bandits to Experts: A Tale of Domination and Independence", "authors": ["Noga Alon"], "emails": ["nogaa@tau.ac.il", "nicolo.cesa-bianchi@unimi.it", "claudio.gentile@uninsubria.it", "mansour@tau.ac.il"], "sections": [{"heading": null, "text": "ar Xiv: 130 7,45 64v1 [cs.LG]"}, {"heading": "1 Introduction", "text": "This is a general abstract framework for studying sequential prediction problems, formulated as repeated games between a player and an opponent. A well-researched example of prediction game is this: In each round, the opponent privately assigns a loss value to each action in a set group. Then, the player selects an action (possibly using a random chart) and suffers the corresponding loss. The goal of the player is to control the regret, which is defined as the excessive loss the player suffers over a sequence of rounds compared to the best fixed action. Two important variants of this game have been studied in the past: the expert setting, where at the end of each round the player observes the loss assigned to each action for that round, and the bandit setting, in which the player observes only the loss of the chosen action but not the other actions. Let K be the number of actions available, and T the number of prediction rounds. The best regret for the expert setting is reached."}, {"heading": "2 Learning protocol, notation, and preliminaries", "text": "In fact, as the author says, he is able to be in a position in which he is able, in which he is able to move, and in which he is able, in which he is able to move, in which he is able, in which he is able, in which he is able, in which he is able, in which he is able to move, in which he is able, in which he is able to be in a position, in which he is able to move."}, {"heading": "3 Algorithms without Explicit Exploration: The Uninformed Set-", "text": "In this section, we show that a simple variant of the Exp3 algorithm [3] achieves optimal regret (within logarithmic factors) in two variants of the uninformed environment. (1) We then show that even the more difficult adversarial and directed setting undergoes analysis, although with a weaker regrettability limit. (2) This probability is simply the sum of all pj that is not mixed with the uniform distribution. (2) Exp3-SET uses loss estimates. (The sum includes pi, t, t that we regret the Exp3-SET in relation to the key quantityQpi, t, t, t, t. (the sum includes pi, t, t) we have the regret of the Exp3-SET in relation to the quantityQpi, t, t."}, {"heading": "In the above, the expectations E[\u00b7] are w.r.t. both the algorithm\u2019s randomization and the random", "text": "Generational switch from Gt to Gt to Gt to Gt to Gt to Gt to Gt to Gt to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp to Gp."}, {"heading": "4 Algorithms with Explicit Exploration: The Informed Setting", "text": "We begin by showing a simple example in which our analysis of Exp3-SET inherently fails, due to the fact that when the graph is induced by the observation system, the key quantity Qt in (1) is defined, the key quantity Qt in (1) cannot be defined freely from the choice of probabilities. Therefore, Exp3DOM requires a new algorithm that controls the probabilities pi by adding an exploration term to the distribution pt. This exploration term is supported on a dominant set of the current graph Gt. Exp3DOM requires prior access to a dominant set Rt at each time step, which in turn requires prior knowledge of the entire observation system."}, {"heading": "5 Conclusions and work in progress", "text": "We have studied online prediction problems in partial information systems that interpolate between the classical bandit and expert settings. We have shown a number of results that characterize prediction performance in terms of: the structure of the observation system, the amount of information available prior to prediction, the nature (counterproductive or entirely random) of the process that produced the observation system. Our results are significant improvements over the work [11] that gave rise to this interesting line of research. Our improvements are manifold, ranging from taking into account both informed and uninformed settings to providing more sophisticated graph characterizations, from providing more efficient algorithmic solutions to applying simpler (and often more general) analytical tools. Some of the research we are currently pursuing are the following."}, {"heading": "Acknowledgments", "text": "The first author was partially supported by an ERC Advanced Grant, a US-Israeli BSF grant and the Israeli I-CORE program, the second author partially supported by MIUR (ARS TechnoMedia project, PRIN 2010-2011, scholarship no. 2010N5K7EB 003), the fourth author partially supported by a scholarship from the Israel Science Foundation, a scholarship from the United StatesIsrael Binational Science Foundation (BSF), a scholarship from the Israeli Ministry of Science and Technology, and the Israeli Centers of Research Excellence (I-CORE) program (Center No. 4 / 11)."}, {"heading": "A Technical lemmas and proofs", "text": "This section contains the proofs of all technical results that occur in the main text, together with the clues we all use. (+ 1) + 1) + 1 (+ 1) + 1 (+ 1) + 2 (+ 1) + 2 (+ 1) + 2 (+ 2) + 2 (+ 1) + 2 (+ 1) + 2 (+ 2) + 2 (+ 2) + 2 (+ 2) + 2 (+ 2) + 3 (+ 2) + 3 (+ 3) + 2 + 2 (+ 3) + 4 (+ 3) + 3) + 2 (+ 3) + 4 (+ 3) + 3 (+ 2) + 2 (+ 2) + 2 (+ 2) + 3 (+ 3), + 4 (+ 3) + 4 (+ 3) + 3) + 4 (+ 3) + 3) + 3 (+ 3), + 4 (+ 3) + 3), + 4 (+ 3), + 4 (+ 2) + 4 (+ 2) + 2) + 2 (2), 4 (5), 5, 5 (5), 5 (5), 5 (5, 5, 5, (5), 5, (5, 5, 5, (5), (5), 5, (5, 5, 5, (5), 5, (5), 5, 5, 5 (5), 5 (, 5, 5, (5)."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "<lb>We consider the partial observability model for multi-armed bandits, introduced by Mannor<lb>and Shamir [11]. Our main result is a characterization of regret in the directed observability<lb>model in terms of the dominating and independence numbers of the observability graph. We also<lb>show that in the undirected case, the learner can achieve optimal regret without even accessing<lb>the observability graph before selecting an action. Both results are shown using variants of the<lb>Exp3 algorithm operating on the observability graph in a time-efficient manner.", "creator": "LaTeX with hyperref package"}}}