{"id": "1307.6515", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jul-2013", "title": "Cluster Trees on Manifolds", "abstract": "In this paper we investigate the problem of estimating the cluster tree for a density $f$ supported on or near a smooth $d$-dimensional manifold $M$ isometrically embedded in $\\mathbb{R}^D$. We analyze a modified version of a $k$-nearest neighbor based algorithm recently proposed by Chaudhuri and Dasgupta. The main results of this paper show that under mild assumptions on $f$ and $M$, we obtain rates of convergence that depend on $d$ only but not on the ambient dimension $D$. We also show that similar (albeit non-algorithmic) results can be obtained for kernel density estimators. We sketch a construction of a sample complexity lower bound instance for a natural class of manifold oblivious clustering algorithms. We further briefly consider the known manifold case and show that in this case a spatially adaptive algorithm achieves better rates.", "histories": [["v1", "Wed, 24 Jul 2013 18:17:53 GMT  (80kb)", "http://arxiv.org/abs/1307.6515v1", "28 pages, 3 figures"]], "COMMENTS": "28 pages, 3 figures", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["sivaraman balakrishnan", "srivatsan narayanan", "alessandro rinaldo", "aarti singh", "larry a wasserman"], "accepted": true, "id": "1307.6515"}, "pdf": {"name": "1307.6515.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 130 7,65 15v1 [st at.M L] 24 Jul 2 013"}, {"heading": "CLUSTER TREES ON MANIFOLDS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "By Sivaraman Balakrishnan, Srivatsan Narayanan, Alessandro Rinaldo, Aarti", "text": "The main findings of this paper show that under mild assumptions on f and M we obtain rates of convergence that depend only on d but not on the surrounding dimension D. We also show that similar (though not algorithmic) results can be obtained for kernel density estimators. We outline a construction of an example of lower instance complexity for a natural class of diverse Oblivian algorithms. We briefly consider the known multiple case and show that in this case a better adaptation of the algorithms can be achieved."}], "references": [{"title": "Rates of convergence for the cluster", "author": ["Kamalika Chaudhuri", "Sanjoy Dasgupta"], "venue": "tree. NIPS,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Consistency of single linkage for high-density clusters", "author": ["J.A. Hartigan"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1981}, {"title": "Mode analysis: a generalization of nearest neighbor which reduces chaining", "author": ["D. Wishart"], "venue": "In Proceedings of the Colloquium on Numerical Taxonomy held in the University of St. Andrews,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1969}, {"title": "A generalized single linkage method for estimating the cluster tree of a density", "author": ["W. Stuetzle", "Nugent. R"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Estimating the cluster tree of a density by analyzing the minimal spanning tree of a sample", "author": ["Werner Stuetzle"], "venue": "J. Classification,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2003}, {"title": "Measuring mass concentrations and estimating density contour clusters: an excess mass approach", "author": ["W. Polonik"], "venue": "Annals of Statistics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1995}, {"title": "On nonparametric estimation of density level", "author": ["A B Tsybakov"], "venue": "sets. Ann. Statist.,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1997}, {"title": "Granulometric smoothing", "author": ["G. Walther"], "venue": "Annals of Statistics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1997}, {"title": "A plug-in approach to support estimation", "author": ["Antonio Cuevas", "Ricardo Fraiman"], "venue": "Annals of Statistics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1997}, {"title": "Rod\u0155\u0131guez-Casal. Plug-in estimation of general level", "author": ["Antonio Cuevas", "Wenceslao Gonz\u00e1lez-Manteiga", "Alberto"], "venue": "sets. Aust. N. Z. J. Stat.,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Fast rates for plug-in estimators of density level", "author": ["P. Rigollet", "R. Vert"], "venue": "sets. Bernoulli,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2009}, {"title": "Optimal construction of k-nearest-neighbor graphs for identifying noisy clusters", "author": ["Markus Maier", "Matthias Hein", "Ulrike von Luxburg"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Adaptive {H}ausdorff estimation of density level", "author": ["Aarti Singh", "Clayton Scott", "Robert Nowak"], "venue": "sets. Ann. Statist.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Generalized density clustering", "author": ["Alessandro Rinaldo", "Larry Wasserman"], "venue": "The Annals of Statistics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Stability of density-based clustering", "author": ["Alessandro Rinaldo", "Aarti Singh", "Rebecca Nugent", "Larry Wasserman"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Pruning nearest neighbor cluster trees", "author": ["Samory Kpotufe", "Ulrike von Luxburg"], "venue": "In ICML,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Adaptive density level set clustering", "author": ["Ingo Steinwart"], "venue": "Journal of Machine Learning Research - Proceedings Track,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Consistency and rates for clustering with dbscan", "author": ["Bharath K. Sriperumbudur", "Ingo Steinwart"], "venue": "Journal of Machine Learning Research - Proceedings Track,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Finding the homology of submanifolds with high confidence from random", "author": ["P Niyogi", "S Smale", "S Weinberger"], "venue": "Discrete and Computational Geometry,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Random projection trees and low dimensional manifolds", "author": ["Sanjoy Dasgupta", "Yoav Freund"], "venue": "In STOC,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "A tree-based regressor that adapts to intrinsic dimension", "author": ["Samory Kpotufe", "Sanjoy Dasgupta"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Local polynomial regression on unknown manifolds", "author": ["Peter Bickel", "Bo Li"], "venue": "In Technical report, Department of Statistics, UC Berkeley,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "An upper bound for the volume of geodesic balls in submanifolds of euclidean spaces", "author": ["Frederic Chazal"], "venue": "Personal Communication, available at http://geometrica.saclay.inria.fr/team/Fred.Chazal/BallVolumeJan2013.pdf,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Rates of strong uniform consistency for multivariate kernel density estimators", "author": ["Evarist Gin\u00e9", "Armelle Guillou"], "venue": "In Annales de l\u2019Institut Henri Poincare (B) Probability and Statistics,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2002}, {"title": "Minimax manifold estimation", "author": ["Christopher R. Genovese", "Marco Perone-Pacifico", "Isabella Verdinelli", "Larry Wasserman"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Minimax rates for homology inference", "author": ["Sivaraman Balakrishnan", "Alessandro Rinaldo", "Don Sheehy", "Aarti Singh", "Larry Wasserman"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Empirical geometry of multivariate data: a deconvolution approach", "author": ["V.I. Koltchinskii"], "venue": "Ann. Statist.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2000}], "referenceMentions": [{"referenceID": 0, "context": "We analyze a modified version of a k-nearest neighbor based algorithm recently proposed by Chaudhuri and Dasgupta [1].", "startOffset": 114, "endOffset": 117}, {"referenceID": 1, "context": "Hartigan [2] showed that the popular single-linkage algorithm is not consistent for a sample from R D, with D > 1.", "startOffset": 9, "endOffset": 12}, {"referenceID": 0, "context": "Recently, Chaudhuri and Dasgupta [1] analyzed an algorithm which is both simple and consistent.", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "We show that the simple algorithm studied in [1] is consistent and has fast rates of convergence for data on or near a low dimensional manifold M .", "startOffset": 45, "endOffset": 48}, {"referenceID": 0, "context": "We show that in the known manifold case a modified spatially adaptive algorithm achieves better rates, similar to the near minimax-optimal rates of [1].", "startOffset": 148, "endOffset": 151}, {"referenceID": 2, "context": "The idea of using probability density functions for clustering dates back to Wishart [3].", "startOffset": 85, "endOffset": 88}, {"referenceID": 1, "context": "[2] expanded on this idea and formalized the notions of high-density clustering, of the cluster tree and of consistency and fractional consistency of clustering algorithms.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "In particular, [2] showed that single linkage clustering is consistent when D = 1 but is only fractionally consistent when D > 1.", "startOffset": 15, "endOffset": 18}, {"referenceID": 3, "context": "[4] and [5] have also proposed procedures for recovering the cluster tree.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[4] and [5] have also proposed procedures for recovering the cluster tree.", "startOffset": 8, "endOffset": 11}, {"referenceID": 0, "context": "None of these procedures however, come with the theoretical guarantees given by [1], which demonstrated that a generalization of Wishart\u2019s algorithm allows one to estimate parts of the cluster tree for distributions with full-dimensional support near-optimally under rather mild assumptions.", "startOffset": 80, "endOffset": 83}, {"referenceID": 5, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 6, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 7, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 8, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 9, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 10, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 11, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 12, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 13, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 14, "context": ", [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], and references therein.", "startOffset": 2, "endOffset": 38}, {"referenceID": 15, "context": "Estimating the cluster tree has more recently been considered in [16] which also gives a simple pruning procedure for removing spurious clusters.", "startOffset": 65, "endOffset": 69}, {"referenceID": 16, "context": "[17, 18] propose procedures for determining recursively the lowest split in the cluster tree and give conditions for asymptotic consistency with minimal assumptions on the density.", "startOffset": 0, "endOffset": 8}, {"referenceID": 17, "context": "[17, 18] propose procedures for determining recursively the lowest split in the cluster tree and give conditions for asymptotic consistency with minimal assumptions on the density.", "startOffset": 0, "endOffset": 8}, {"referenceID": 18, "context": "The condition number controls the curvature of M and prevents it from being too close to being self-intersecting (see [19] for a detailed treatment).", "startOffset": 118, "endOffset": 122}, {"referenceID": 0, "context": "To give finite sample results, following [1], we define the notion of salient clusters.", "startOffset": 41, "endOffset": 44}, {"referenceID": 0, "context": "Our definitions are slight modifications of those in [1] to take into account the manifold assumption.", "startOffset": 53, "endOffset": 56}, {"referenceID": 0, "context": "Chaudhuri and Dasgupta [1] analyze a robust single linkage (RSL) algorithm (in Figure 1).", "startOffset": 23, "endOffset": 26}, {"referenceID": 0, "context": "[1] prove the following theorem, establishing finite sample bounds for a particular RSL algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "Ignoring constants that depend on d the main difference between this result and the result of [1] (Theorem 5) is that our results only depend on the manifold dimension d and not the ambient dimension D (typically D \u226b d).", "startOffset": 94, "endOffset": 97}, {"referenceID": 0, "context": "Another aspect is that our choice of the connection radius R depends on the (typically) unknown \u03c1, while for comparison, the connection radius in [1] is chosen to be \u221a 2r.", "startOffset": 146, "endOffset": 149}, {"referenceID": 0, "context": "It is easy to see that this theorem also establishes consistency for recovering the entire cluster tree by selecting an appropriate schedule on \u03c3n, \u01ebn and kn that ensures that all clusters are distinguished for n large enough (see [1] for a formal proof).", "startOffset": 231, "endOffset": 234}, {"referenceID": 0, "context": "Our proofs structurally mirror those in [1].", "startOffset": 40, "endOffset": 43}, {"referenceID": 19, "context": "Similar manifold adaptivity results have been shown in classification [20] and in non-parametric regression [21, 22].", "startOffset": 70, "endOffset": 74}, {"referenceID": 20, "context": "Similar manifold adaptivity results have been shown in classification [20] and in non-parametric regression [21, 22].", "startOffset": 108, "endOffset": 116}, {"referenceID": 21, "context": "Similar manifold adaptivity results have been shown in classification [20] and in non-parametric regression [21, 22].", "startOffset": 108, "endOffset": 116}, {"referenceID": 0, "context": "In the full dimensional setting of [1], this follows from standard VC inequalities.", "startOffset": 35, "endOffset": 38}, {"referenceID": 18, "context": "3 of [19] while the upper bound is based on a modification of the main result of [23].", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "3 of [19] while the upper bound is based on a modification of the main result of [23].", "startOffset": 81, "endOffset": 85}, {"referenceID": 0, "context": "The proof is analogous to the separation proof of [1] with several modifications.", "startOffset": 50, "endOffset": 53}, {"referenceID": 18, "context": "3 in [19] who show that if \u2016p\u2212 q\u2016 = R \u2264 \u03c4/2, then the geodesic distance dM (p, q) \u2264 \u03c4 \u2212 \u03c4 \u221a 1\u2212 2R \u03c4 .", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": ", a continuous map P : [0, 1] \u2192 A such that P (0) = y and P (1) = y\u2032.", "startOffset": 23, "endOffset": 29}, {"referenceID": 0, "context": "For full dimensional densities, [1] showed the information theoretic lower bound n = \u03a9 ( 1 \u03bb\u01ebvD\u03c3 log 1 \u03bb\u01ebvD\u03c3 ) .", "startOffset": 32, "endOffset": 35}, {"referenceID": 24, "context": "This can be fixed without affecting the essence of the construction by smoothing this intersection by rolling a ball of radius \u03c4 around it (a similar construction is made rigorous in Theorem 6 of [25]).", "startOffset": 196, "endOffset": 200}, {"referenceID": 0, "context": "In particular, \u03c1 no longer depends on \u01eb\u03c4 and for the case of \u03c4 fixed (ignoring constants depending on d) the algorithm achieves the near minimax optimal rates of [1], in the manifold setting with d replacing D.", "startOffset": 162, "endOffset": 165}, {"referenceID": 25, "context": "Following the literature on manifold estimation ([26, 25]) we consider two main noise models.", "startOffset": 49, "endOffset": 57}, {"referenceID": 24, "context": "Following the literature on manifold estimation ([26, 25]) we consider two main noise models.", "startOffset": 49, "endOffset": 57}, {"referenceID": 26, "context": "It is also possible to recover the cluster tree in the presence of general additive noise distributions via deconvolution [27, 26] but we do not pursue this approach here.", "startOffset": 122, "endOffset": 130}, {"referenceID": 25, "context": "It is also possible to recover the cluster tree in the presence of general additive noise distributions via deconvolution [27, 26] but we do not pursue this approach here.", "startOffset": 122, "endOffset": 130}, {"referenceID": 23, "context": "Following [24], we will further assume that the class of functions", "startOffset": 10, "endOffset": 14}, {"referenceID": 13, "context": "The first Lemma appears in a similar form in [14] (Proposition 9) and is a modification of a result of [24] (Corollary 2.", "startOffset": 45, "endOffset": 49}, {"referenceID": 23, "context": "The first Lemma appears in a similar form in [14] (Proposition 9) and is a modification of a result of [24] (Corollary 2.", "startOffset": 103, "endOffset": 107}, {"referenceID": 13, "context": "The proof follows along the lines of those in [14, 24].", "startOffset": 46, "endOffset": 54}, {"referenceID": 23, "context": "The proof follows along the lines of those in [14, 24].", "startOffset": 46, "endOffset": 54}, {"referenceID": 23, "context": "To apply Talagrand\u2019s inequality in the proof of [24] we need to bound", "startOffset": 48, "endOffset": 52}, {"referenceID": 23, "context": "Replacing this bound on the variance in the proof of [24] we obtain the desired result.", "startOffset": 53, "endOffset": 57}, {"referenceID": 0, "context": "Our first result mirrors the main result of [1].", "startOffset": 44, "endOffset": 47}, {"referenceID": 0, "context": "Also notice unlike the result of [1] this result requires the density to be uniformly upper bounded.", "startOffset": 33, "endOffset": 36}, {"referenceID": 0, "context": "Notice, that for a fixed \u01eb and n the probability of success decays rapidly with increasing d and that for a fixed d and n the probability of success grows with \u01eb, in agreement with our 1/\u01eb\u03a9(d) prediction and in contrast to the 1/\u01eb2 scaling predicted by [1] for recovering a full-dimensional cluster tree.", "startOffset": 253, "endOffset": 256}, {"referenceID": 18, "context": "The lower bound follows from [19] (Lemma 5.", "startOffset": 29, "endOffset": 33}, {"referenceID": 22, "context": "The upper bound follows from [23] who shows that", "startOffset": 29, "endOffset": 33}, {"referenceID": 18, "context": "See [19] (p.", "startOffset": 4, "endOffset": 8}, {"referenceID": 0, "context": "The lemma now follows using simple manipulations of these inequalities (see [1] for details).", "startOffset": 76, "endOffset": 79}], "year": 2013, "abstractText": "In this paper we investigate the problem of estimating the cluster tree for a density f supported on or near a smooth d-dimensional manifold M isometrically embedded in R. We analyze a modified version of a k-nearest neighbor based algorithm recently proposed by Chaudhuri and Dasgupta [1]. The main results of this paper show that under mild assumptions on f and M , we obtain rates of convergence that depend on d only but not on the ambient dimension D. We also show that similar (albeit non-algorithmic) results can be obtained for kernel density estimators. We sketch a construction of a sample complexity lower bound instance for a natural class of manifold oblivious clustering algorithms. We further briefly consider the known manifold case and show that in this case a spatially adaptive algorithm achieves better rates.", "creator": "LaTeX with hyperref package"}}}