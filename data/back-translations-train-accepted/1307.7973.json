{"id": "1307.7973", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jul-2013", "title": "Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction", "abstract": "This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on two scoring functions that operate by learning low-dimensional embeddings of words and of entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over existing methods that rely on text features alone.", "histories": [["v1", "Tue, 30 Jul 2013 13:37:09 GMT  (78kb)", "http://arxiv.org/abs/1307.7973v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["jason weston", "antoine bordes", "oksana yakhnenko", "nicolas usunier"], "accepted": true, "id": "1307.7973"}, "pdf": {"name": "1307.7973.pdf", "metadata": {"source": "CRF", "title": "Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction", "authors": ["Jason Weston", "Oksana Yakhnenko", "Nicolas Usunier"], "emails": ["jweston@google.com", "bordesan@utc.fr", "oksana@google.com", "usuniern@utc.fr"], "sections": [{"heading": null, "text": "ar Xiv: 130 7,79 73v1 [cs.CL] 3 0Ju l 2"}, {"heading": "1 Introduction", "text": "In fact, most of them are able to survive on their own, without being able to survive on their own."}, {"heading": "2 Embedding-based Framework", "text": "Our work refers to energy-based methods used to learn low-dimensional vector representations (embedding) of atomic symbols (words, entities, relationships, etc.). In this context, we learn two models: one to predict relationships in which relationships are mentioned, and one to encode the interactions between entities and relationships from the KB. The joint action of both models in prediction allows us to use the link between the KB and the text to perform relationship extraction. One could also divide parameters between models (by joint embedding), but this is not implemented in this work. This approach is inspired by previous work that aimed at linking words and orders (Bordes et al., 2012). Both submodels end with learning vector embedding symbols, either for entities or relationships in the KB, or for each word / characteristic of the vocabulary (V.) The set of tites and the entities in the KB and in each case are referred to by the E and nots, respectively by the R and E, and nots."}, {"heading": "2.1 Connecting text and relationships", "text": "The first part of the framework concerns learning a function Sm2r (m, r), based on embedding, which is designed to evaluate the similarity of a relationship between m and a relationship r. Our approach is inspired by previous work on combining word labels and images (Weston et al., 2010), which we adapted by replacing images with mentions and word labels with relationships. Intuitively, it consists of first projecting windows of words into the embedding space and then creating a similarity measurement (the dot product in this paper) between that projection and a relationship. Then, the scoring function is: Sm2r (m, r) = f (m) rwith a function that calculates a window of words in R k, f (m) = W (m); W is the matrix of Rnv \u00d7 k that contains all embedding words."}, {"heading": "2.2 Encoding structured data of KBs", "text": "In order to link these relationship data to our model, we propose to encode their information in entities and relationship embedding (e.g. in (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012): In this paper, we have chosen to use the approach of (Bordes et al., 2013), which is simple, flexible and very promising results on Freebase data.In view of a training set S = (hi, ri, ti), i = 1, | S |} of the relationships extracted from the KB, this model learns the vector embedding of the entities and the relationships using the idea that the functional relationship between scentiles and scentiles induced by the labeling of scales should be transferred to the labeling method b. (b) To link these relationship data with our model, we propose to encode their information in entity and relationship embedding."}, {"heading": "2.3 Implementation for relation extraction", "text": "Our framework can be used for relation extraction in the following ways: First, for each pair of entities (h, t) that occur in the test record, all corresponding mentions Mh, t are collected and a prediction is made with: r-h, t = argmax r-m-Mh, tSm2r (m, r).The predicted relationship can be either a valid relationship or NA - a marker that means there is no relationship between h and t (NA is added to R during training and treated like other relationships).If r-h, t is a relationship, a composite value is defined: Sm2r + kb (h, r-h, t) = \u2211 m-Mh, tSm2r (m, r-h, t) + S-kb (h, r-h, t, t) Therefore, the composite model favors predictions that match both the mentions and the KB."}, {"heading": "3 Experiments", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to move, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "4 Conclusion", "text": "In this paper, we have described a framework for using extensive knowledge bases to improve relationship extraction by not only training pairs (mentioning, relationship), but also using all other KB triples. Our modeling approach is general and should be applied to other settings, such as the task of linking units."}], "references": [{"title": "Open information extraction from the web", "author": ["Banko et al.2007] Michele Banko", "Michael J Cafarella", "Stephen Soderland", "Matthew Broadhead", "Oren Etzioni"], "venue": "In IJCAI,", "citeRegEx": "Banko et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2007}, {"title": "Label ranking under ambiguous supervision for learning semantic correspondences", "author": ["Nicolas Usunier", "Jason Weston"], "venue": "In Proceedings of the 27th International Conference on Machine Learning", "citeRegEx": "Bordes et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2010}, {"title": "Learning structured embeddings of knowledge bases", "author": ["Jason Weston", "Ronan Collobert", "Yoshua Bengio"], "venue": "In Proc. of the 25th Conf. on Artif. Intel. (AAAI)", "citeRegEx": "Bordes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2011}, {"title": "Joint learning of words and meaning representations for open-text semantic parsing", "author": ["Xavier Glorot", "Jason Weston", "Yoshua Bengio"], "venue": "In Proc. of the 15th Intern. Conf. on Artif. Intel. and Stat.,", "citeRegEx": "Bordes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2012}, {"title": "Irreflexive and hierarchical relations as translations", "author": ["Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko"], "venue": "arXiv preprint arXiv:1304.7158", "citeRegEx": "Bordes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "Toward an architecture for never-ending language learning", "author": ["Justin Betteridge", "Bryan Kisiel", "Burr Settles", "Estevam R Hruschka Jr.", "Tom M Mitchell"], "venue": null, "citeRegEx": "Carlson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["Craven et al.1999] Mark Craven", "Johan Kumlien"], "venue": "In ISMB,", "citeRegEx": "Craven and Kumlien,? \\Q1999\\E", "shortCiteRegEx": "Craven and Kumlien", "year": 1999}, {"title": "Incorporating nonlocal information into information extraction systems by gibbs sampling", "author": ["Trond Grenager", "Christopher Manning"], "venue": "In Proceedings of the 43rd Annual Meeting on Association for Computational Linguis-", "citeRegEx": "Finkel et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Finkel et al\\.", "year": 2005}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S Weld"], "venue": "In Proceedings of the 49th Annual Meeting", "citeRegEx": "Hoffmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "Learning language semantics from ambiguous supervision", "author": ["Kate", "Mooney2007] Rohit J Kate", "Raymond J Mooney"], "venue": "In AAAI,", "citeRegEx": "Kate et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kate et al\\.", "year": 2007}, {"title": "Learning semantic correspondences with less supervision", "author": ["Liang et al.2009] Percy Liang", "Michael I Jordan", "Dan Klein"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Lan-", "citeRegEx": "Liang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liang et al\\.", "year": 2009}, {"title": "A joint model of language and perception for grounded attribute learning", "author": ["Nicholas FitzGerald", "Luke Zettlemoyer", "Liefeng Bo", "Dieter Fox"], "venue": "In Proceedings of the International Conference on Machine Learning", "citeRegEx": "Matuszek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Matuszek et al\\.", "year": 2012}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009] Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "A three-way model for collective learning on multi-relational data", "author": ["Volker Tresp", "Hans-Peter Kriegel"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Nickel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2011}, {"title": "Modeling relations and their mentions without labeled text", "author": ["Limin Yao", "Andrew McCallum"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Riedel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Relation extraction with matrix factorization and universal schemas", "author": ["Limin Yao", "Andrew McCallum", "Benjamin M Marlin"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Riedel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2013}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["Julie Tibshirani", "Ramesh Nallapati", "Christopher D Manning"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Process-", "citeRegEx": "Surdeanu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "Large scale image annotation: learning to rank with joint word-image embeddings", "author": ["Weston et al.2010] Jason Weston", "Samy Bengio", "Nicolas Usunier"], "venue": "Machine learning,", "citeRegEx": "Weston et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2010}, {"title": "Autonomously semantifying wikipedia", "author": ["Wu", "Weld2007] Fei Wu", "Daniel S Weld"], "venue": null, "citeRegEx": "Wu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2007}, {"title": "Open information extraction using wikipedia", "author": ["Wu", "Weld2010] Fei Wu", "Daniel S Weld"], "venue": null, "citeRegEx": "Wu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 10, "context": "Previous work Learning under weak supervision is common in Natural language processing, especially for tasks where the annotations costs are important such as semantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012).", "startOffset": 176, "endOffset": 263}, {"referenceID": 1, "context": "Previous work Learning under weak supervision is common in Natural language processing, especially for tasks where the annotations costs are important such as semantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012).", "startOffset": 176, "endOffset": 263}, {"referenceID": 11, "context": "Previous work Learning under weak supervision is common in Natural language processing, especially for tasks where the annotations costs are important such as semantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012).", "startOffset": 176, "endOffset": 263}, {"referenceID": 0, "context": "Large-scale open IE projects (Banko et al., 2007; Carlson et al., 2010) also rely on weak supervision, since they learn models from a seed KB in order to extend it.", "startOffset": 29, "endOffset": 71}, {"referenceID": 5, "context": "Large-scale open IE projects (Banko et al., 2007; Carlson et al., 2010) also rely on weak supervision, since they learn models from a seed KB in order to extend it.", "startOffset": 29, "endOffset": 71}, {"referenceID": 14, "context": "(2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multiinstance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 149, "endOffset": 216}, {"referenceID": 8, "context": "(2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multiinstance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 149, "endOffset": 216}, {"referenceID": 16, "context": "(2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multiinstance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 149, "endOffset": 216}, {"referenceID": 0, "context": "Large-scale open IE projects (Banko et al., 2007; Carlson et al., 2010) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multiinstance learning frameworks (Riedel et al.", "startOffset": 30, "endOffset": 235}, {"referenceID": 0, "context": "Large-scale open IE projects (Banko et al., 2007; Carlson et al., 2010) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multiinstance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Recently, Riedel et al. (2013) proposed an approach to model jointly KB data and text by relying on collaborative filtering.", "startOffset": 30, "endOffset": 545}, {"referenceID": 3, "context": "This approach is inspired by previous work designed to connect words and Wordnet (Bordes et al., 2012).", "startOffset": 81, "endOffset": 102}, {"referenceID": 17, "context": "Our approach is inspired by previous work for connecting word labels and images (Weston et al., 2010), which we adapted, replacing images by mentions and word labels by relationships.", "startOffset": 80, "endOffset": 101}, {"referenceID": 1, "context": "Since this learning problem is weakly supervised, Bordes et al. (2010) showed that a convenient way to train it is by using a ranking loss.", "startOffset": 50, "endOffset": 71}, {"referenceID": 14, "context": "as in (Riedel et al., 2010).", "startOffset": 6, "endOffset": 27}, {"referenceID": 17, "context": "See (Weston et al., 2010; Bordes et al., 2013) for details.", "startOffset": 4, "endOffset": 46}, {"referenceID": 4, "context": "See (Weston et al., 2010; Bordes et al., 2013) for details.", "startOffset": 4, "endOffset": 46}, {"referenceID": 13, "context": "in (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012)): we chose in this work to use the approach of (Bordes et al.", "startOffset": 3, "endOffset": 66}, {"referenceID": 2, "context": "in (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012)): we chose in this work to use the approach of (Bordes et al.", "startOffset": 3, "endOffset": 66}, {"referenceID": 3, "context": "in (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012)): we chose in this work to use the approach of (Bordes et al.", "startOffset": 3, "endOffset": 66}, {"referenceID": 4, "context": ", 2012)): we chose in this work to use the approach of (Bordes et al., 2013), which is simple, flexible and has shown very promising results on Freebase data.", "startOffset": 55, "endOffset": 76}, {"referenceID": 4, "context": "\u2200h,r ,t , ||h||2 \u2264 1, ||r ||2 \u2264 1, ||t||2 \u2264 1, and training is performed using SGD, as in (Bordes et al., 2013).", "startOffset": 90, "endOffset": 111}, {"referenceID": 14, "context": "We use the training and test data, evaluation framework and baselines from (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 75, "endOffset": 142}, {"referenceID": 8, "context": "We use the training and test data, evaluation framework and baselines from (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 75, "endOffset": 142}, {"referenceID": 16, "context": "We use the training and test data, evaluation framework and baselines from (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 75, "endOffset": 142}, {"referenceID": 14, "context": "NYT+FB This dataset, developed by (Riedel et al., 2010), aligns Freebase relations with the New York Times corpus.", "startOffset": 34, "endOffset": 55}, {"referenceID": 7, "context": "Entities were found using the Stanford named entity tagger (Finkel et al., 2005), and were matched to their name in Freebase.", "startOffset": 59, "endOffset": 80}, {"referenceID": 4, "context": "Modeling Following (Bordes et al., 2013) we set the embedding dimension k to 50.", "startOffset": 19, "endOffset": 40}, {"referenceID": 8, "context": "Results Figure 1 displays the aggregate precision / recall curves of our approach WSABIEM2R+FB which uses the combination of Sm2r+Skb, as well as WSABIEM2R , which only uses Sm2r , and state-ofthe-art: HOFFMANN (Hoffmann et al., 2011)2,", "startOffset": 211, "endOffset": 234}, {"referenceID": 16, "context": "MIMLRE (Surdeanu et al., 2012).", "startOffset": 7, "endOffset": 30}, {"referenceID": 14, "context": "RIEDEL (Riedel et al., 2010) and MINTZ (Mintz et al.", "startOffset": 7, "endOffset": 28}, {"referenceID": 12, "context": ", 2010) and MINTZ (Mintz et al., 2009).", "startOffset": 18, "endOffset": 38}, {"referenceID": 8, "context": "There is an error in the plot from (Hoffmann et al., 2011), which we have corrected.", "startOffset": 35, "endOffset": 58}], "year": 2013, "abstractText": "This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on two scoring functions that operate by learning low-dimensional embeddings of words and of entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over existing methods that rely on text features alone.", "creator": "LaTeX with hyperref package"}}}