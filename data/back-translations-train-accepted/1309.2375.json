{"id": "1309.2375", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Sep-2013", "title": "Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization", "abstract": "We introduce a proximal version of the stochastic dual coordinate ascent method and show how to accelerate the method using an inner-outer iteration procedure. We analyze the runtime of the framework and obtain rates that improve state-of-the-art results for various key machine learning optimization problems including SVM, logistic regression, ridge regression, Lasso, and multiclass SVM. Experiments validate our theoretical findings.", "histories": [["v1", "Tue, 10 Sep 2013 05:39:25 GMT  (38kb,D)", "https://arxiv.org/abs/1309.2375v1", null], ["v2", "Tue, 8 Oct 2013 06:06:09 GMT  (38kb,D)", "http://arxiv.org/abs/1309.2375v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG cs.NA stat.CO", "authors": ["shai shalev-shwartz", "tong zhang 0001"], "accepted": true, "id": "1309.2375"}, "pdf": {"name": "1309.2375.pdf", "metadata": {"source": "CRF", "title": "Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization", "authors": ["Shai Shalev-Shwartz", "Tong Zhang"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "We will consider the following generic optimization problem, which is associated with regularized loss minimization, as something we do not know. (.) We will consider the following generic optimization problem, which is associated with regularized loss minimization (.) We will consider the following generic optimization problem, which is associated with linear predictors (.) We will consider it as something that we have defined as a sequence of vector functions. (.) Our goal is to solve: min w. \".\" \"\".. \"\".. \"\".. \"\" \"..\" \"\".. \"\" \"..\" \"\" \"..\" \".\" \"\".. \"\".. \".\" \"\" \"..\" \".\" \"\" \"\".. \"\" \"\" \"..\" \".\" \"\" \".\" \"\" \"\" \"..\" \"\" \".\" \"\" \".\" \"\" \"..\" \"\" \"\". \"\". \"\" \".\" \"\". \"\" \".\" \".\" \"\". \"\". \"\" \".\" \".\" \"\". \"\". \"\". \"\". \"\" \".\" \".\" \".\" \".\" \".\" \".\" \".\" \"\". \"\". \"\" \".\". \"\". \"\". \"\". \".\" \".\". \"\". \"\". \".\". \"\". \"\". \"\". \".\". \"\". \"\". \".\". \"\". \".\" \".\". \".\" \"\". \".\". \"\". \".\". \".\". \".\". \"\" \"\". \".\". \".\". \".\" \".\". \"\" \"\". \".\" \"\". \"\". \"\" \".\" \"\" \".\". \".\" \".\". \"\" \"\". \"\". \"\". \"\". \"\" \".\" \".\" \".\" \"\". \"\". \".\" \"\" \".\". \"\" \"\". \".\" \"\". \".\". \".\" \".\". \"\". \"\". \"\" \".\". \"\" \".\" \".\". \".\""}, {"heading": "2 Preliminaries", "text": "All the functions we look at in this essay are proper convex functions over a Euclidean space. We use R to denote the set of real numbers and simplify our notation when we use R to denote the range of a function f. \u2212 When we use f, we actually output the double norm by issuing the double norm in relation to the double norm. \u00b7 D, where we use the double norm in relation to the upper norm D = sup x: x x x x x: x x x x x x x x: x x x x: p = 1y > x. We also use the double norm in relation to the upper norm P = x > x. We also use the double norm in relation to the double norm i: xi | xi | sup x: the operator norm of a matrix norm X in relation to the norm."}, {"heading": "3 Main Results", "text": "In this section, we describe our algorithms and their analysis. We start in Section 3.1 with a description of our proximal stochastic dual coordinate ascent method (Prox-SDCA) and then show in Section 3.2 how we can speed up the method by invoking Prox-SDCA in a succession of highly regularized problems. In the first two sections, we assume that the loss functions are smooth. Finally, we discuss the case of the Lipschitz loss functions in Section 3.3. The proofs of the main acceleration theorem (Theorem 3) are in Section 4. The rest of the proofs are included in the appendix."}, {"heading": "3.1 Proximal Stochastic Dual Coordinate Ascent", "text": "Our results in this subsection refer to a 1-strong convex function in relation to any standard (1 / 3) and any other goal in relation to any other standard (2) -smooth function in relation to any other standard (2) -smooth function in relation to any other standard (2) -smooth function. At each iteration of dual ascent, we only allow one change in the i'th column of the i'th column of the i'th column, while the rest of the dual vectors are kept intact. We focus on a randomized version of dual ascent in which we select in each round which dual vector to update. In step t, let v \u2212 1) = (1) -1 (2) -3 (1) -4 (1) -4 (1) -4 (1) -4 (1) -4 (1) -4 (4) -4."}, {"heading": "3.2 Acceleration", "text": "The Prox SDCA method described in the previous subsection has the iteration limit of O \u03b2 (n + R 2\u03bb\u03b3). This is an almost linear runtime if the condition number is, R2 / (\u03bb\u03b3), O (n). In this section we show how the dependence on the acceleration number can be improved by an acceleration method. In particular, during this section we assume that 10n < R 2\u03bb \u2212 Log in this subsection also assumes that the regulator, g, 1 is strongly convex in relation to the Euclidean standard, i.e. that the acceleration number (s) works. \u2212 This also implies that the acceleration method for strongly convex regulators in relation to the general standard, i.e. the main idea of the acceleration method is that we perform the Prox SDCA method iteratively, where we call Prox SDCA with the Iteration."}, {"heading": "3.3 Non-smooth, Lipschitz, loss functions", "text": "So far, we have assumed that for each i-set point and set point, a (1 / 3) -smooth function (1 / 3) -smooth function (2) is provided for. We now consider the case in which it is a non-smooth and even non-differentiable function, but it is L-Lipschitz. Following Nesterov [17], we apply a \"smooth\" technique. First, we observe that if the L-Lipschitz function is the double standard, the domain of the L-Lipschitz function in the radius L. Lemschitz is a L-Lipschitz function w.r.t. is a norm, and let us admit that the double norm is."}, {"heading": "4 Proof of Theorem 3", "text": "The first assertion of the theorem is that when the procedure ceases, we P (t), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (t), P (w), P (w), P (w), P (w), P (w), P (w), P (z), P (w), P (w), P (w), P (w), P (z), P (t), P (z), P (z), P (z), P (z), P (z), P (z), P (z), P (z), P (z), P (z), P (w), P (z), P (z), P (w), P (z), P (z), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w), P (w, P (w), P (w), P (w, w, w), P (w, w, P (w), P (w), P (w, P (w), P (w, w), P (w), P (w, P (w, w, w), P (w), P, P (w, P (w, w, w), P (w, P (w), P (w), P (w, P (w), P (w), P (w, P (w), P (w), P (w, P (w), P (w), P (w), P (w, P (w), P (w), P (w, P (w), P (w, P (w), P (w), P (w), P (w, P ("}, {"heading": "5 Applications", "text": "In this section, we specify our algorithmic framework for several popular machine learning applications. In Section 5.1, we begin by describing several loss functions and deriving their conjugate. In Section 5.2, we describe several regularization functions. Finally, in the remaining subsections, we specify our algorithm for Ridge Regression, SVM, Lasso, Logistic Regression, and Multiclass Prediction."}, {"heading": "5.1 Loss functions", "text": "The conjugate function is (b) = max a) max a) max a (a) max a) max a) max a) max a) max a) max a) max b) max a) max a) max a) max a) max a) max a) max a) max a) max a) max b) max a) max a) max a) max a) max a) max b) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a) max a (a) max a) max (a) max a)."}, {"heading": "5.2 Regularizers", "text": "L2 regularization: The simplest regularization is the squared L2 regularization and the subsequent regularization is the squared L2 regularization (w) = squared L2 regularization (w) = squared L2 regularization (w). For our acceleration method, we also use the L2 regularization plus a linear term, namely g (w) = 12 characters (w) = 12 characters (w > z, for any vector e.g. The conjugation of this function is vi (v) = max w > (v > z) \u2212 12 characters (w) plus a linear term, namely g (w) = 12 characters (w > z, for any vector e.g.). The conjugation of this function is vi (v) = max w > (v)."}, {"heading": "5.3 Ridge Regression", "text": "In the ridge regression, we minimize the squared loss with L2 regularization. That is, g (w) = 12% w = 2% and for each i we have this xi (p) -round and \u03c6i (a) = 12 (a \u2212 yi) 2 for some yi \u00b2 R. The primary problem is therefore P (w) = 12n n \u00b2 i = 1 (x > i \u2212 yi) 2 + 2% w \u00b2. In the following, we specify that the maximization problem is with ridge regression. We use option I as it is possible to use a closed form for maximizing the dual taking into account the digit i (\u2212 b) = \u2212 12b2 + yib \u2212 t = \u2212 i \u2212 t = maximization problem."}, {"heading": "5.4 Logistic Regression", "text": "In logistic regression we minimize the logistic loss with the L2 regression = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 2 = 2 and for each i we have this xi-round and \u03c6i (a) = log (1 + ea). The primary problem is as follows: 3P (w) = 1n n x x x (1 + x > i) log (1 + x > i) + 2 x x. The dual problem is D (\u03b1) = 1n x x x x = 1 (x) log (1 + \u03b1i) log (1 + \u03b1i) log (1 = 1 x) log (1 x) log (1 x), and the dual constraints are \u03b1 [\u2212 1, 0] n. In the following we specify Prox-SDCA for logistic regression with option IIIII.Prox-SDCA (((((xi) ni = 1 x), \u03b1 (0), z) for logistic regression Gomize: xw = 1 (P)."}, {"heading": "5.5 Lasso", "text": "In the lasso problem, the loss function is the squared loss, but the regulation problem is the squared solution, which means that we have to solve the problem: min w [12n n] i = 1 (x > i) i = 1 (x > i) i (x > i) i (x > i) i (x > i) i (x = 2) i (x > i) i (x > i) i (x > i) i (x > i) i (x > i) i (x) i (x) i) i (x) i i) i (x) i) i (x) i) i (x) i) i (x) i (x) i) i (x) i) i (x) i) i (x) i) i) i (x) i) i) i \"i) i\" i) i \"i\" i) i \"i\" i) i \"i) i\" i) i."}, {"heading": "5.6 Linear SVM", "text": "Support for Vector Machines (SVM) is an algorithm for learning a linear classification. Linear SVM (i.e., SVM with linear cores) is a minimization of the objective P (w) = 1n n n \u00b2. This can be considered as the target given in (1) by considering the regulation g (w) = 12% w) + \u03bb 2% w \u00b2, where [a] + = max {0 \u2212 a}, and for each i, xi \u2212 Rd \u00b2, as the target given in (1), by applying the regulation g (w) = 12% w \u00b2 2 \u00b2 2, and for each i-note i (a) = [1 \u2212 a] +, is the hinge loss.Let R = maxi xi xi xi xi xi \u00b2 2% 2%. SGD enjoys the rate of O (1). Many software packages apply SDCA and observe the rate O (n + 1\u043c). We now show how our accelerated DCA + 2 enjoys the rate (n)."}, {"heading": "5.7 Multiclass SVM", "text": "Next, we look at the construction described in Crammer and Singer. Each example consists of an instance vector xi-Rd and a label yi-2,. \u2212 k) The goal is to learn a matrix W-Rd, k-so that W-xi is a k-th dimensional vector of the results for the different classes. \u2212 k) The prediction is the coordinate of W-xi of the maximum value. The loss function ismax j 6 = yi (1 + (W > xi) j \u2212 j \u2212 (W > xi) yi (W > xi) yi)."}, {"heading": "6 Experiments", "text": "111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111"}, {"heading": "7 Discussion and Open Problems", "text": "The total running time of the resulting process improves the state of the art in many interesting cases. There are two major open problems that we will leave to future research. Open problem 1. If 1\u03bb\u03b3 is greater than n, the running time of our process becomes O-shaped (d-shaped n-shaped). Is it possible to derive a method whose running time is O-shaped (d-shaped + \u221a 1-shaped)? Open problem 2. Our Prox-SDCA method and its analysis works for regulators that are strongly convex in relation to an arbitrary standard. However, our acceleration method is designed for regulators that are strongly convex in relation to the Euclidean standard. Is it possible to extend the acceleration method to more general regulators?"}, {"heading": "Acknowledgements", "text": "Shai Shalev-Shwartz is supported by Intel Collaborative Research Institute for Computational Intelligence (ICRI-CI) and ISF 598-10. Tong Zhang is supported by NSF IIS-1016061, NSF DMS-1007527 and NSF IIS-1250985."}, {"heading": "A Proofs of Iteration Bounds for Prox-SDCA", "text": "Evidence technology follows the arguments of Shalev-Shwartz and Zhang. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212"}], "references": [{"title": "Estimate sequence methods: extensions and approximations", "author": ["Michel Baes"], "venue": "Institute for Operations Research, ETH, Zu\u0308rich, Switzerland,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["A. Beck", "M. Teboulle"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Exponentiated gradient algorithms for conditional random fields and max-margin markov networks", "author": ["M. Collins", "A. Globerson", "T. Koo", "X. Carreras", "P. Bartlett"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2008}, {"title": "Better mini-batch algorithms via accelerated gradient methods", "author": ["Andrew Cotter", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "arXiv preprint arXiv:1106.4574,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "On the algorithmic implementation of multiclass kernel-based vector machines", "author": ["K. Crammer", "Y. Singer"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2001}, {"title": "Smooth optimization with approximate gradient", "author": ["Alexandre d\u2019Aspremont"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "First-order methods of smooth convex optimization with inexact oracle", "author": ["Olivier Devolder", "Francois Glineur", "Yu. Nesterov"], "venue": "Technical Report 2011/2,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Efficient online and batch learning using forward backward splitting", "author": ["J. Duchi", "Y. Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Efficient projections onto the l 1-ball for learning in high dimensions", "author": ["John Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Tushar Chandra"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Composite objective mirror descent", "author": ["John Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Ambuj Tewari"], "venue": "In Proceedings of the 23rd Annual Conference on Learning Theory,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework", "author": ["Saeed Ghadimi", "Guanghui Lan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Accelerated gradient methods for stochastic optimization and online learning", "author": ["Chonghai Hu", "Weike Pan", "James T Kwok"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Stochastic block-coordinate frank-wolfe optimization for structural svms", "author": ["S. Lacoste-Julien", "M. Jaggi", "M. Schmidt", "P. Pletscher"], "venue": "arXiv preprint arXiv:1207.4747,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Sparse online learning via truncated gradient", "author": ["J. Langford", "L. Li", "T. Zhang"], "venue": "In NIPS,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "A Stochastic Gradient Method with an Exponential Convergence Rate for Strongly-Convex Optimization with Finite Training Sets", "author": ["Nicolas Le Roux", "Mark Schmidt", "Francis Bach"], "venue": "arXiv preprint arXiv:1202.6258,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Efficiency of coordinate descent methods on huge-scale optimization problems", "author": ["Y. Nesterov"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Smooth minimization of non-smooth functions", "author": ["Yurii Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2005}, {"title": "Gradient methods for minimizing composite objective function", "author": ["Yurii Nesterov"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function", "author": ["Peter Richt\u00e1rik", "Martin Tak\u00e1\u010d"], "venue": "Mathematical Programming,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Convergence rates of inexact proximal-gradient methods for convex optimization", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "Technical Report arXiv:1109.2415,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2011}, {"title": "Stochastic methods for l 1-regularized loss minimization", "author": ["S. Shalev-Shwartz", "A. Tewari"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Pegasos: Primal Estimated sub-GrAdient SOlver for SVM", "author": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro"], "venue": "In ICML,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Stochastic methods for l1 regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Ambuj Tewari"], "venue": "In ICML,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2009}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "arXiv preprint arXiv:1209.1873,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2013}, {"title": "Trading accuracy for sparsity in optimization problems with sparsity constraints", "author": ["Shai Shalev-Shwartz", "Nathan Srebro", "Tong Zhang"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Dual averaging method for regularized stochastic learning and online optimization", "author": ["Lin Xiao"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "On the dual formulation of regularized linear systems", "author": ["Tong Zhang"], "venue": "Machine Learning,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2002}], "referenceMentions": [{"referenceID": 24, "context": "This matches the recent result of Shalev-Shwartz and Zhang [25], Le Roux et al.", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "[15], but our setting is significantly more general.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "This significantly improves over the result of [25, 15].", "startOffset": 47, "endOffset": 55}, {"referenceID": 14, "context": "This significantly improves over the result of [25, 15].", "startOffset": 47, "endOffset": 55}, {"referenceID": 17, "context": "It also significantly improves over the runtime of accelerated gradient descent due to Nesterov [18], which is \u00d5(dn \u221a 1 \u03bb \u03b3 ).", "startOffset": 96, "endOffset": 100}, {"referenceID": 21, "context": "[22]), when 1 \u03bb n.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "SVM SGD [22] d \u03bb AGD [17] dn \u221a 1 \u03bb", "startOffset": 8, "endOffset": 12}, {"referenceID": 16, "context": "SVM SGD [22] d \u03bb AGD [17] dn \u221a 1 \u03bb", "startOffset": 21, "endOffset": 25}, {"referenceID": 27, "context": "[28, 27, 21]) d 2", "startOffset": 0, "endOffset": 12}, {"referenceID": 26, "context": "[28, 27, 21]) d 2", "startOffset": 0, "endOffset": 12}, {"referenceID": 20, "context": "[28, 27, 21]) d 2", "startOffset": 0, "endOffset": 12}, {"referenceID": 22, "context": "Stochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1", "startOffset": 30, "endOffset": 38}, {"referenceID": 15, "context": "Stochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1", "startOffset": 30, "endOffset": 38}, {"referenceID": 17, "context": "Stochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1", "startOffset": 48, "endOffset": 55}, {"referenceID": 1, "context": "Stochastic Coordinate Descent [23, 16] dn FISTA [18, 2] dn \u221a 1", "startOffset": 48, "endOffset": 55}, {"referenceID": 14, "context": "Ridge Regression Exact d2n+ d3 SGD [15], SDCA [25] d ( n+ 1 \u03bb )", "startOffset": 35, "endOffset": 39}, {"referenceID": 24, "context": "Ridge Regression Exact d2n+ d3 SGD [15], SDCA [25] d ( n+ 1 \u03bb )", "startOffset": 46, "endOffset": 50}, {"referenceID": 17, "context": "AGD [18] dn \u221a 1 \u03bb", "startOffset": 4, "endOffset": 8}, {"referenceID": 24, "context": "1 In particular, we generalize the recent analysis of [25] in two directions.", "startOffset": 54, "endOffset": 58}, {"referenceID": 24, "context": "As in [25], the runtime of this procedure is \u00d5 ( d ( n+ 1 \u03bb\u03b3 )) .", "startOffset": 6, "endOffset": 10}, {"referenceID": 24, "context": "Additional related work: As mentioned before, our first contribution is a proximal version of the stochastic dual coordinate ascent method and extension of the analysis given in Shalev-Shwartz and Zhang [25].", "startOffset": 203, "endOffset": 207}, {"referenceID": 2, "context": "[3] but in more restricted settings than the general problem considered in this paper.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "One can also apply the analysis of stochastic coordinate descent methods given in Richt\u00e1rik and Tak\u00e1\u010d [19] on the dual problem.", "startOffset": 102, "endOffset": 106}, {"referenceID": 12, "context": "Recently, [13] derived a stochastic coordinate ascent for structural SVM based on the Frank-Wolfe algorithm.", "startOffset": 10, "endOffset": 14}, {"referenceID": 6, "context": "[7], Schmidt et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 19, "context": "[20], to allow approximate and stochastic proximal mapping.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "See also [1, 6].", "startOffset": 9, "endOffset": 15}, {"referenceID": 5, "context": "See also [1, 6].", "startOffset": 9, "endOffset": 15}, {"referenceID": 19, "context": "In particular, it relies on similar ideas as in Proposition 4 of [20].", "startOffset": 65, "endOffset": 69}, {"referenceID": 19, "context": "However, our specific requirement is different, and the proof presented here is different and significantly simpler than that of [20].", "startOffset": 129, "endOffset": 133}, {"referenceID": 11, "context": "See for example [12, 11, 4] and the references therein.", "startOffset": 16, "endOffset": 27}, {"referenceID": 10, "context": "See for example [12, 11, 4] and the references therein.", "startOffset": 16, "endOffset": 27}, {"referenceID": 3, "context": "See for example [12, 11, 4] and the references therein.", "startOffset": 16, "endOffset": 27}, {"referenceID": 14, "context": "As in [15, 25], we avoid the polynomial dependence on 1/ by allowing more than a single pass over the data.", "startOffset": 6, "endOffset": 14}, {"referenceID": 24, "context": "As in [15, 25], we avoid the polynomial dependence on 1/ by allowing more than a single pass over the data.", "startOffset": 6, "endOffset": 14}, {"referenceID": 26, "context": "Note that this particular update is rather similar to the update step of proximal-gradient dual-averaging method (see for example Xiao [27]).", "startOffset": 135, "endOffset": 139}, {"referenceID": 0, "context": "Let s = argmax s\u2208[0,1] [ \u2212\u03c6i (\u2212(\u03b1 (t\u22121) i + sq))\u2212 sw (t\u22121)>Xiq \u2212 s2 2\u03bbn \u2016Xiq\u20162D\u2032 ]", "startOffset": 17, "endOffset": 22}, {"referenceID": 16, "context": "Following Nesterov [17], we apply a \u201csmoothing\u201d technique.", "startOffset": 19, "endOffset": 23}, {"referenceID": 25, "context": "5 in [26].", "startOffset": 5, "endOffset": 9}, {"referenceID": 16, "context": "See Nesterov [17] for discussion.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "The conjugate function is \u03c6\u2217(b) = max a ab\u2212 log(1 + e) = { b log(b) + (1\u2212 b) log(1\u2212 b) if b \u2208 [0, 1] \u221e otherwise", "startOffset": 94, "endOffset": 100}, {"referenceID": 8, "context": "While we do not have a closed form solution for the minimization problem over b in the definition of \u03c6\u0303\u03b3 above, this is a problem of projecting onto the intersection of the L1 ball and the positive orthant, and can be solved efficiently using the following procedure, adapted from [9].", "startOffset": 281, "endOffset": 284}, {"referenceID": 14, "context": "This matches the recent results of [15, 25].", "startOffset": 35, "endOffset": 43}, {"referenceID": 24, "context": "This matches the recent results of [15, 25].", "startOffset": 35, "endOffset": 43}, {"referenceID": 13, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 20, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 26, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 7, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 9, "context": "[14, 21, 27, 8, 10]).", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "Another relevant approach is the FISTA algorithm of [2].", "startOffset": 52, "endOffset": 55}, {"referenceID": 20, "context": "[21] showed that the runtime of this approach is", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Similar results can also be found in [16].", "startOffset": 37, "endOffset": 41}, {"referenceID": 20, "context": "If R2 = O(1) then the runtime of our method is much better than that of [21].", "startOffset": 72, "endOffset": 76}, {"referenceID": 20, "context": "This is the same or better than [21] whenever d = O(n).", "startOffset": 32, "endOffset": 36}, {"referenceID": 4, "context": "7 Multiclass SVM Next we consider Multiclass SVM using the construction described in Crammer and Singer [5].", "startOffset": 104, "endOffset": 107}, {"referenceID": 4, "context": "Such ideas were explored in [5] for the non-smooth max-of-hinge loss.", "startOffset": 28, "endOffset": 31}, {"referenceID": 8, "context": "By the properties of projection onto the simplex (see [9]), for every z \u2208 (zj , zj+1) we have that the projection of \u03bc onto the set {b \u2208 R+ : \u2016b\u20161 = z} is of the form ar = max{0, \u03bcr \u2212 \u03b8/j} where \u03b8 = (\u2212z + \u03bc\u0304j)/j.", "startOffset": 54, "endOffset": 57}, {"referenceID": 1, "context": "In this section we compare Prox-SDCA, its accelerated version Accelerated-Prox-SDCA, and the FISTA algorithm of [2], on L1 \u2212 L2 regularized loss minimization problems.", "startOffset": 112, "endOffset": 115}, {"referenceID": 23, "context": "The experiments were performed on three large datasets with very different feature counts and sparsity, which were kindly provided by Thorsten Joachims (the datasets were also used in [24]).", "startOffset": 184, "endOffset": 188}, {"referenceID": 23, "context": "We multiplied each xi by yi and following [24], we employed the smooth hinge loss, \u03c6\u0303\u03b3 , as in (9), with \u03b3 = 1.", "startOffset": 42, "endOffset": 46}, {"referenceID": 24, "context": "The proof technique follows that of Shalev-Shwartz and Zhang [25], but with the required generality for handling general strongly convex regularizers and smoothness/Lipschitzness with respect to general norms.", "startOffset": 61, "endOffset": 65}, {"referenceID": 0, "context": "Then, for any iteration t and any s \u2208 [0, 1] we have Et[D(\u03b1)\u2212D(\u03b1)] \u2265 s n [P (w(t\u22121))\u2212D(\u03b1(t\u22121))]\u2212 ( s n )2 G(t) 2\u03bb ,", "startOffset": 38, "endOffset": 44}, {"referenceID": 0, "context": "By the definition of the update we have for all s \u2208 [0, 1] that", "startOffset": 52, "endOffset": 58}, {"referenceID": 0, "context": "We will apply Lemma 6 with s = n n+R2/(\u03bb\u03b3) = \u03bbn\u03b3 R2 + \u03bbn\u03b3 \u2208 [0, 1] .", "startOffset": 60, "endOffset": 66}], "year": 2013, "abstractText": "We introduce a proximal version of the stochastic dual coordinate ascent method and show how to accelerate the method using an inner-outer iteration procedure. We analyze the runtime of the framework and obtain rates that improve state-of-the-art results for various key machine learning optimization problems including SVM, logistic regression, ridge regression, Lasso, and multiclass SVM. Experiments validate our theoretical findings.", "creator": "LaTeX with hyperref package"}}}