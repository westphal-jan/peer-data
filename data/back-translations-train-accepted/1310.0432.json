{"id": "1310.0432", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Oct-2013", "title": "Online Learning of Dynamic Parameters in Social Networks", "abstract": "This paper addresses the problem of online learning in a dynamic setting. We consider a social network in which each individual observes a private signal about the underlying state of the world and communicates with her neighbors at each time period. Unlike many existing approaches, the underlying state is dynamic, and evolves according to a geometric random walk. We view the scenario as an optimization problem where agents aim to learn the true state while suffering the smallest possible loss. Based on the decomposition of the global loss function, we introduce two update mechanisms, each of which generates an estimate of the true state. We establish a tight bound on the rate of change of the underlying state, under which individuals can track the parameter with a bounded variance. Then, we characterize explicit expressions for the steady state mean-square deviation(MSD) of the estimates from the truth, per individual. We observe that only one of the estimators recovers the optimal MSD, which underscores the impact of the objective function decomposition on the learning quality. Finally, we provide an upper bound on the regret of the proposed methods, measured as an average of errors in estimating the parameter in a finite time.", "histories": [["v1", "Tue, 1 Oct 2013 19:08:04 GMT  (18kb)", "http://arxiv.org/abs/1310.0432v1", "12 pages, To appear in Neural Information Processing Systems (NIPS) 2013"]], "COMMENTS": "12 pages, To appear in Neural Information Processing Systems (NIPS) 2013", "reviews": [], "SUBJECTS": "math.OC cs.LG cs.SI stat.ML", "authors": ["shahin shahrampour", "alexander rakhlin", "ali jadbabaie"], "accepted": true, "id": "1310.0432"}, "pdf": {"name": "1310.0432.pdf", "metadata": {"source": "CRF", "title": "Online Learning of Dynamic Parameters in Social Networks", "authors": ["Shahin Shahrampour", "Alexander Rakhlin", "Ali Jadbabaie"], "emails": ["1shahin@seas.upenn.edu", "jadbabai@seas.upenn.edu", "rakhlin@wharton.upenn.edu"], "sections": [{"heading": null, "text": "ar Xiv: 131 0.04 32v1 [m. ath. OC] 1 O"}, {"heading": "1 Introduction", "text": "This year, it is only a matter of time before the US will be able to do it again, to be able to change the world again."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 State and Observation Model", "text": "We look at a network consisting of a finite number of agents V = {1, 2,..., N}. Agents indexed by i-V search for the underlying state of the world, xt-R, which varies over time and develops after toxt + 1 = axt + rt, (1) where rt is a zero-mean innovation, independent over time with finite variance E [r2t] = \u03c3 2 r, and a-R is the expected rate of change of the state of the world, which is assumed to be available to all agents and could potentially be greater than a unit. We assume that the initial state x0 is a finite random variable drawn independently of nature. In the time period t, each actor receives a private signal yi, t-R, which is a loud version of xt and can be described by the linear equation t = xt + wi, t."}, {"heading": "2.2 Communication Structure", "text": "Agents communicate with each other to update their beliefs about the underlying state of the world. Interaction between agents is captured by an undirected diagram G = (V, E), where V is the set of agents, and if there is a connection between agent i and agent j, then {i, j}. We allow N-i = {j-V: {i, j-E} to be the set of neighbors of agent i and Ni = N-i-i-i-i-i-i-i. Each agent i can only communicate with his neighbors and assigns a weight pij > 0 for each j-N-i. We also allow pii-0 to denote the autonomy of the agent i. Assumption 1. The communication matrix P = [pij] is symmetrical and double stochastical, i.e., it fulfills pij > 0, pij = pji, and vice versa."}, {"heading": "2.3 Estimate Updates", "text": "From an optimization perspective, this can be seen as a search for an online minimization of the divisible, global, time-varying cost functionmin x-x-Rft (x-Rft (x-Rft) = 1NN x-J = 1 (f-i, t (x-i))), 1-E (yi, t-x) 2) = 1NN x-i = 1 (f-i), N-j = 1pij f-j (x-j)), (3) at any time period. One approach to addressing the stochastic learning problem formulated above is to use distributed dual mean problems regulated by a square proximal function [13]. To this end, when the agent i uses the f-i-i, t as the local loss function, it updates its belief asx-i, t + 1 = one (n-j-nipij x-j-j)."}, {"heading": "2.4 Error Process", "text": "The definition of local error processes in the vectors \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" \"t,\" t, \"\" t, \"t,\" \"t,\" t, \"t,\" t, \"t,\" \"t,\" t, \"\" t, \"t,\" \"t,\" t, \"\" t, \"t,\" \"t,\" t, \"t,\" t, \"\" t, \"t,\" t, \"\" t, \"t,\" \"t,\" t, \"t,\" t, \"\" t, \"t,\" t, \"\" t, \"t,\" t, \"\" t, \"t,\" t, \"t,\" t, \"t,\" \"t,\" t, \"t,\" t, \"t,\" t, \"\" t, \"t,\" t, \"t,\" \"t,\" t, \"t,\" t, \"\" t, \"t,\" t, \"t,\" t, \"\" t, \"t,\" t, \"t,\" t, \"\" t, \"t,\" t, \"t,\" t, \"t,\" \"t,\" t, \"t,\" t, \"t,\" t, \"t,\" t, \"t,\" t, \"t,\" t, \"t,\" t, \"t,\" t, \"t,\" \"\" t, \"t,\" t, \"t,\" \"t,\" t, \"t,\" t, \"t,\" \"t,\" t, \"\" t, \"t,\" t, \"t,\" \"t,\" t, \"\" t, \"\" t, \"t,\" t, \"\" t, \"t,\" \"t,\" t, \"t,\" t, \"t,\" t, \"t,"}, {"heading": "3 Social Learning: Convergence of Beliefs and Regret Analysis", "text": "In this section, we examine the behavior of estimators (4) and (5) in the middle and middle square sense of the net (4), and we provide the repentance analysis. In the following statement, we establish a narrow limit for a under which agents can achieve asymptotically unbiased estimates using the correct signal weight. In other words, if we change less than the rate indicated in the statement, individuals can always pursue a bounded variance by selecting an appropriate signal weight."}, {"heading": "4 The Impact of New Friendships on Social Learning", "text": "In this section we limit our attention to estimators (5) and characterize the intuitive idea that establishing (losing) friendships improves the quality of learning in the sense of decreasing (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) the balance (increasing) (increasing) the equilibrium (increasing) (increasing) the equilibrium) (increasing) (increasing) the equilibrium (increasing) (increasing) the equilibrium) to (removing) the i-th vector in the standard basis of RN, we use the negative half definition, edge function matrix P (i, j), (increasing) the equilibrium (increasing) P (increasing) the equilibrium (increasing) (increasing) the equilibrium (increasing)."}, {"heading": "5 Conclusion", "text": "We investigated a distributed online learning problem via a social network. The objective of the agents is to estimate the underlying state of the world, which follows a geometric random course. Each person receives a noisy signal about the underlying state at any time, so that they communicate with their neighbors to restore the true state. We looked at the problem with an optimization lens, where agents want to minimize a global loss function in a collaborative way. To estimate the underlying state, we proposed two methods that derive from a different decomposition of the global target. Given the structure of the network, we set a tight upper limit for the rate of change of the parameter, which allows the agents to follow the state with a limited variance. In addition, we calculated the averaged stable state, the mean square deviation of the estimates from the true state. The most important observation was the optimality of one of the estimators, which mitigated the dependence of the learning quality on the learning composition we assigned to the average T during the learning process."}, {"heading": "Acknowledgments", "text": "We are grateful for the support of AFOSR MURI CHASE, ONR BRC Program on Decentralized, Online Optimization, NSF within the funding programs CAREER DMS-0954737 and CCF-1116928 as well as the Dean's Research Fund."}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "<lb>This paper addresses the problem of online learning in a dynamic setting. We<lb>consider a social network in which each individual observes a private signal about<lb>the underlying state of the world and communicates with her neighbors at each<lb>time period. Unlike many existing approaches, the underlying state is dynamic,<lb>and evolves according to a geometric random walk. We view the scenario as an<lb>optimization problem where agents aim to learn the true state while suffering the<lb>smallest possible loss. Based on the decomposition of the global loss function, we<lb>introduce two update mechanisms, each of which generates an estimate of the true<lb>state. We establish a tight bound on the rate of change of the underlying state, un-<lb>der which individuals can track the parameter with a bounded variance. Then, we<lb>characterize explicit expressions for the steady state mean-square deviation(MSD)<lb>of the estimates from the truth, per individual. We observe that only one of the<lb>estimators recovers the optimal MSD, which underscores the impact of the objec-<lb>tive function decomposition on the learning quality. Finally, we provide an upper<lb>bound on the regret of the proposed methods, measured as an average of errors in<lb>estimating the parameter in a finite time.", "creator": "LaTeX with hyperref package"}}}