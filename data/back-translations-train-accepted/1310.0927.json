{"id": "1310.0927", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Oct-2013", "title": "Learning Chordal Markov Networks by Constraint Satisfaction", "abstract": "We investigate the problem of learning the structure of a Markov network from data. It is shown that the structure of such networks can be described in terms of constraints which enables the use of existing solver technology with optimization capabilities to compute optimal networks starting from initial scores computed from the data. To achieve efficient encodings, we develop a novel characterization of Markov network structure using a balancing condition on the separators between cliques forming the network. The resulting translations into propositional satisfiability and its extensions such as maximum satisfiability, satisfiability modulo theories, and answer set programming, enable us to prove optimal certain network structures which have been previously found by stochastic search.", "histories": [["v1", "Thu, 3 Oct 2013 09:01:39 GMT  (19kb)", "http://arxiv.org/abs/1310.0927v1", null]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["jukka corander", "tomi janhunen", "jussi rintanen", "henrik j nyman", "johan pensar"], "accepted": true, "id": "1310.0927"}, "pdf": {"name": "1310.0927.pdf", "metadata": {"source": "CRF", "title": "Learning Chordal Markov Networks by Constraint Satisfaction", "authors": ["Jukka Corander", "Tomi Janhunen", "Jussi Rintanen", "Henrik Nyman"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 131 0.09 27v1 [cs.AI] 3"}, {"heading": "1 Introduction", "text": "In fact, in the last ten years, the development of statistical theory has been very different in most countries of the world: in the USA, in Europe, in the USA, in Europe, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA,"}, {"heading": "2 Structure Learning for Markov Networks", "text": "An undirected graph G = (N, E) consists of a series of nodes that represent a series of random variables and a series of undirected edges. (D) A path in a graph is a sequence of nodes so that all two consecutive nodes are connected by an edge. (D) Two sets of nodes A and B are separated by a third set of nodes. (D) A path between a node in A and a node in B contains at least one node in D. An undirected graph is chordal if for all paths v0,. vn with n 4 and v0 there are two nodes vi, vj in the path that is connected by an edge, so that j \u00b1 1 clique in a graph is a series of nodes c, so that all two nodes in it are connected by an edge."}, {"heading": "3 Fundamental Properties and Characterization Results", "text": "In this section, we will point out some properties of chord graphs and cliquengraphs that can be used to encode the learning problem. In particular, we will develop a characterization of the maximum tree weight with respect to a balance state on dividers. The dividers needed to determine the score (1) of a Markov network are defined as follows: Considering the cliquengraph, we can form the cliquengraph in which the nodes are the cliquengraphs and there is an edge between two nodes if the corresponding cliquengraphs have a non-empty section. We label each of the edges with this cut and consider the cardinality of the label as its weight. The dividers are the edge markers of a tree maximum weight spanning the tree of the cliquengraph. The maximum weight of trees of arbitrary graphs can be found in the polynomial time by reducing the problem to the determination of a minimum weight that consists of 20 pairs, and then using all of the cliquengraphs precisely."}, {"heading": "3.1 Characterization of Maximum Weight Spanning Trees", "text": "In fact, it is the case that most people are able to abide by the rules that they have imposed on themselves. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they do not abide by the rules. (...) It is the case that they do not abide by the rules. (...) \"\" It is the case that they abide by the rules. (...) \"(...)\" (...) \"(...)\" (...) \"(...)\" (... \")\" ((...) \"(...\") \"(...\") \"((...)\" (() \"() ((...)\" () (() \"() (()\" () (() () () (() () () () ())) (()) ()) (()) () ()) (()) () () () ()) () () () ()) () () () ()) () () () () ()) () () () () ()) () ()) () () () () () ()) () () ()) () () () () ()) () () () ()) () () () ()) ()) () () ()) () () () () () ()) () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () () () () () () () () (() () () () () () () () () () () () () () (() () () () () () () () (() () () (() () () () ()"}, {"heading": "4 Constraints and Their Translations into MAXSAT, SMT, and ASP", "text": "The objectives of this section are twofold: Firstly, we show how the structural learning problem of the Markov networks is transformed into an abstract constraint satisfaction problem. Secondly, we partially formalize the constraints contained in the language of the statement logic. This is the language directly supported by SMT solvers and which can simply be transformed into a conjunctive normal form used by SAT and MAXSAT solvers. However, in ASP, slightly different rule-based formulations are used, but we leave the corresponding ASP rules for spatial rations.The learning problem is formalized as follows: The goal is to find a balanced sequence tree extending sequences sequences sequences sequences (cf. definition 1) for a series of sequences forming a Markov network sequences \"sequences\" sequences \"sequences\" sequences \"sequences\" sequences \"sequences\" sequences \"sequences\" sequences \"(cf. definition 1) for a series of clicks forming a Markov network, and the sentence S of separators induced by the tree structure. Furthermore, C and S are considered optimal in the sense of (1) sequences, i.e. Total sequences C points (points C) sequences (points of C) sequences (points of S)."}, {"heading": "4.1 Graph Properties", "text": "We assume that clique candidates, which are the non-empty subsets of V, are indexed from 1 to 2. To encrypt the search space for Markov networks, we introduce a meaningful variable for each selected clique candidate c, which c denotes as part of the learned network. For each node n, we have the restriction that c \u00b7 xcm (2), where c1,..., cm are all selected cliques c with n. This clause formalizes point 1 of definition 7. For point 2 (a) and each pair of clique candidates c and c \u00b2, so that c \u00b2, we need such cliques as c \u00b2, (3) for the mutual exclusion of c and c \u00b2 in the network."}, {"heading": "4.2 Chordality", "text": "The idea is to create constraints that correspond to each k \u2265 4 element subset S = {n1,.., nk} of N. Consider all the cycles that these nodes could form in the graph < N, E > of item 3 in definition 7. A cycle begins from a given node, passes through all other nodes in any order, with (undirected) edges between two consecutive nodes, and ends in the start node. The number of required constraints can be reduced by two observations. First, the same cycle could be generated by different start nodes, e.g. cycles n1, n2, n3, n4, n2, n1, n2, n2 are the same."}, {"heading": "4.3 Separators", "text": "Separators for pairs c and c \u00b2 of clique candidates can be formalized as statement variables sc, c \u00b2, meaning that c \u00b2 is a separator and there is an edge in the enclosing tree between c and c \u00b2 labeled by c \u00b2. The corresponding constraint issc, c \u00b2 xc \u00b2 xc \u2032. (7) The absence of the reverse implication formalizes the choice of the compensating tree, i.e. sc, c \u00b2 may be wrong even if xc and xc \u00b2 are applicable. The remaining constraints on separators fall into two cases. First, we have cardinality constraints that encode the compensating condition (see Section 3.1): Each variable occurs more in the selected cliques than it occurs in the separators that label the surrounding tree."}, {"heading": "5 Experimental Evaluation", "text": "In this context, it should be noted that this project is a project, which is a project that is primarily a project, which is a project that is primarily a project."}, {"heading": "6 Conclusions", "text": "In this article, we have presented a generic approach in which the learning problem is expressed in the form of constraints on variables that determine the structure of the learned network. Consequently, the related problem of structural learning of Bajesian networks was addressed by universal combinatorial search methods, including MAXSAT [29] and a constraint programming solver with a linear programming solver as a partial method [30, 31]. We introduced explicit translations of generic constrains into MAXSAT, SMT and ASP and demonstrated their use with existing solver technologies. Thus, our method opens up a novel research location for the further development and optimization of the use of this technology for network learning. There are also many possibilities for the use of these methods in combination with stochastic or heuristic search."}], "references": [{"title": "Markov fields and log-linear interaction models for contingency tables", "author": ["J.N. Darroch", "Steffen L. Lauritzen", "T.P. Speed"], "venue": "The Annals of Statistics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1980}, {"title": "Graphical models for associations between variables, some of which are qualitative and some quantitative", "author": ["Steffen L. Lauritzen", "Nanny Wermuth"], "venue": "The Annals of Statistics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1989}, {"title": "Bayesian graphical model determination using decision theory", "author": ["Jukka Corander"], "venue": "Journal of Multivariate Analysis,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Parallel interacting MCMC for learning of topologies of graphical models", "author": ["Jukka Corander", "Magnus Ekdahl", "Timo Koski"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Markov chain Monte Carlo model determination for hierarchical and graphical log-linear models", "author": ["Petros Dellaportas", "Jonathan J. Forster"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1999}, {"title": "Improving Markov chain Monte Carlo model search for data mining", "author": ["Paolo Giudici", "Robert Castello"], "venue": "Machine Learning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Decomposable graphical Gaussian model determination", "author": ["Paolo Giudici", "Peter J. Green"], "venue": "Biometrika, 86:785\u2013801,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1999}, {"title": "Exact Bayesian structure discovery in Bayesian networks", "author": ["Mikko Koivisto", "Kismat Sood"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2004}, {"title": "Model selection and accounting for model uncertainty in graphical models using Occam\u2019s window", "author": ["David Madigan", "Adrian E. Raftery"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1994}, {"title": "Inducing features of random fields", "author": ["Stephen Della Pietra", "Vincent Della Pietra", "John Lafferty"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1997}, {"title": "Efficient structure learning of Markov networks using L1-regularization", "author": ["Su-In Lee", "Varun Ganapathi", "Daphne Koller"], "venue": "In Advances in Neural Information Processing Systems 19, Proceedings of the Twentieth Annual Conference on Neural Information Processing Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Learning graphical model structure using L1-regularization paths", "author": ["M. Schmidt", "A. Niculescu-Mizil", "K. Murphy"], "venue": "In Proceedings of the National Conference on Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Estimation of sparse binary pairwise Markov networks using pseudo-likelihoods", "author": ["Holger H\u00f6fling", "Robert Tibshirani"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Handbook of Satisfiability, volume 185 of Frontiers in Artificial Intelligence and Applications", "author": ["Armin Biere", "Marijn J.H. Heule", "Hans van Maaren", "Toby Walsh", "editors"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "MaxSAT, Hard and Soft Constraints, chapter 19, pages 613\u2013631", "author": ["Chu Min Li", "Felip Many\u00e0"], "venue": "Volume 185 of Biere et al", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Satisfiability Modulo Theories, chapter 26, pages 825\u2013885", "author": ["Clark Barrett", "Roberto Sebastiani", "Sanjit A. Seshia", "Cesare Tinelli"], "venue": "Volume 185 of Biere et al", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Answer set programming at a glance", "author": ["G. Brewka", "T. Eiter", "M. Truszczy\u0144ski"], "venue": "Communications of the ACM,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Graphical models in applied multivariate statistics", "author": ["Joe Whittaker"], "venue": "Wiley Publishing,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1990}, {"title": "Algorithmic Graph Theory and Perfect Graphs", "author": ["Martin C. Golumbic"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1980}, {"title": "On the history of the minimum spanning tree problem", "author": ["Ronald L Graham", "Pavol Hell"], "venue": "Annals of the History of Computing,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1985}, {"title": "On the tree representation of chordal graphs", "author": ["Yukio Shibata"], "venue": "Journal of Graph Theory,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1988}, {"title": "Optimal junction trees", "author": ["Finn V. Jensen", "Frank Jensen"], "venue": "In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1994}, {"title": "Towards an optimal CNF encoding of Boolean cardinality constraints. In Principles and Practice of Constraint Programming \u2013 CP 2005, number 3709 in Lecture", "author": ["Carsten Sinz"], "venue": "Notes in Computer Science,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "The Sat4j library, release 2.2 system description", "author": ["Daniel Le Berre", "Anne Parrain"], "venue": "Journal on Satisfiability, Boolean Modeling and Computation,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Parallel search for maximum satisfiability", "author": ["Ruben Martins", "Vasco Manquinho", "In\u00eas Lynce"], "venue": "AI Communications,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Optimization in SMT with LA(Q) cost functions", "author": ["Roberto Sebastiani", "Silvia Tomasi"], "venue": "Automated Reasoning,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Conflict-driven answer set solving: From theory to practice", "author": ["Martin Gebser", "Benjamin Kaufmann", "Torsten Schaub"], "venue": "Artif. Intell.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Compact translations of non-disjunctive answer set programs to propositional clauses", "author": ["Tomi Janhunen", "Ilkka Niemel\u00e4"], "venue": "In Gelfond Festschrift,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2011}, {"title": "Bayesian network learning by compiling to weighted MAX-SAT", "author": ["James Cussens"], "venue": "In Proceedings of the Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "Bayesian network learning with cutting planes", "author": ["James Cussens"], "venue": "In Proceedings of the Twenty- Seventh Conference Annual Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2011}, {"title": "Advances in Bayesian network learning using integer programming", "author": ["Mark Bartlett", "James Cussens"], "venue": "In Proceedings of the 29th Conference on Uncertainty in Artificial Intelligence (UAI", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "[1] and Lauritzen and Wermuth [2].", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[1] and Lauritzen and Wermuth [2].", "startOffset": 30, "endOffset": 33}, {"referenceID": 2, "context": "Bayesian learning of undirected GMs, also known as Markov random fields, from databases has attained a considerable interest, both in the statistical and computer science literature [3, 4, 5, 6, 7, 8, 9].", "startOffset": 182, "endOffset": 203}, {"referenceID": 3, "context": "Bayesian learning of undirected GMs, also known as Markov random fields, from databases has attained a considerable interest, both in the statistical and computer science literature [3, 4, 5, 6, 7, 8, 9].", "startOffset": 182, "endOffset": 203}, {"referenceID": 4, "context": "Bayesian learning of undirected GMs, also known as Markov random fields, from databases has attained a considerable interest, both in the statistical and computer science literature [3, 4, 5, 6, 7, 8, 9].", "startOffset": 182, "endOffset": 203}, {"referenceID": 5, "context": "Bayesian learning of undirected GMs, also known as Markov random fields, from databases has attained a considerable interest, both in the statistical and computer science literature [3, 4, 5, 6, 7, 8, 9].", "startOffset": 182, "endOffset": 203}, {"referenceID": 6, "context": "Bayesian learning of undirected GMs, also known as Markov random fields, from databases has attained a considerable interest, both in the statistical and computer science literature [3, 4, 5, 6, 7, 8, 9].", "startOffset": 182, "endOffset": 203}, {"referenceID": 7, "context": "Bayesian learning of undirected GMs, also known as Markov random fields, from databases has attained a considerable interest, both in the statistical and computer science literature [3, 4, 5, 6, 7, 8, 9].", "startOffset": 182, "endOffset": 203}, {"referenceID": 8, "context": "Bayesian learning of undirected GMs, also known as Markov random fields, from databases has attained a considerable interest, both in the statistical and computer science literature [3, 4, 5, 6, 7, 8, 9].", "startOffset": 182, "endOffset": 203}, {"referenceID": 9, "context": "[10] present a greedy local search algorithm Markov network learning and apply it to discovering word", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] reduce the learning problem to a convex optimization problem that is solved by gradient descent.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Related methods have been investigated later [12, 13].", "startOffset": 45, "endOffset": 53}, {"referenceID": 12, "context": "Related methods have been investigated later [12, 13].", "startOffset": 45, "endOffset": 53}, {"referenceID": 3, "context": "Certain types of stochastic search methods, such as Markov Chain Monte Carlo (MCMC) or simulated annealing can be proven to be consistent with respect to the identification of a structure maximizing posterior probability [4, 5, 6, 7].", "startOffset": 221, "endOffset": 233}, {"referenceID": 4, "context": "Certain types of stochastic search methods, such as Markov Chain Monte Carlo (MCMC) or simulated annealing can be proven to be consistent with respect to the identification of a structure maximizing posterior probability [4, 5, 6, 7].", "startOffset": 221, "endOffset": 233}, {"referenceID": 5, "context": "Certain types of stochastic search methods, such as Markov Chain Monte Carlo (MCMC) or simulated annealing can be proven to be consistent with respect to the identification of a structure maximizing posterior probability [4, 5, 6, 7].", "startOffset": 221, "endOffset": 233}, {"referenceID": 6, "context": "Certain types of stochastic search methods, such as Markov Chain Monte Carlo (MCMC) or simulated annealing can be proven to be consistent with respect to the identification of a structure maximizing posterior probability [4, 5, 6, 7].", "startOffset": 221, "endOffset": 233}, {"referenceID": 3, "context": "However, convergence of such methods towards the areas associated with high posterior probabilities may still be slow when the number of nodes increases [4, 6].", "startOffset": 153, "endOffset": 159}, {"referenceID": 5, "context": "However, convergence of such methods towards the areas associated with high posterior probabilities may still be slow when the number of nodes increases [4, 6].", "startOffset": 153, "endOffset": 159}, {"referenceID": 13, "context": "This enables the development of reductions from the structure learning problem to propositional satisfiability (SAT) [14] and its generalizations such as maximum satisfiability (MAXSAT) [15], and satisfiability modulo theories (SMT) [16], as well as answer-set programming (ASP) [17]; and the deployment of respective solver technology for computations.", "startOffset": 117, "endOffset": 121}, {"referenceID": 14, "context": "This enables the development of reductions from the structure learning problem to propositional satisfiability (SAT) [14] and its generalizations such as maximum satisfiability (MAXSAT) [15], and satisfiability modulo theories (SMT) [16], as well as answer-set programming (ASP) [17]; and the deployment of respective solver technology for computations.", "startOffset": 186, "endOffset": 190}, {"referenceID": 15, "context": "This enables the development of reductions from the structure learning problem to propositional satisfiability (SAT) [14] and its generalizations such as maximum satisfiability (MAXSAT) [15], and satisfiability modulo theories (SMT) [16], as well as answer-set programming (ASP) [17]; and the deployment of respective solver technology for computations.", "startOffset": 233, "endOffset": 237}, {"referenceID": 16, "context": "This enables the development of reductions from the structure learning problem to propositional satisfiability (SAT) [14] and its generalizations such as maximum satisfiability (MAXSAT) [15], and satisfiability modulo theories (SMT) [16], as well as answer-set programming (ASP) [17]; and the deployment of respective solver technology for computations.", "startOffset": 279, "endOffset": 283}, {"referenceID": 17, "context": "We have implemented these translations and conducted experiments to study the performance of existing solver technology on structure learning problems in Section 5 using two widely used datasets [18].", "startOffset": 195, "endOffset": 199}, {"referenceID": 18, "context": "Given the set of cliques C in a chordal graph, the set of separators S can be obtained through intersections of the cliques ordered in terms of a junction tree [19], this operation is considered thoroughly in Section 3.", "startOffset": 160, "endOffset": 164}, {"referenceID": 19, "context": "This reduction consists of negating all the edge weights and then using any of the polynomial time algorithms for the latter problem [20].", "startOffset": 133, "endOffset": 137}, {"referenceID": 18, "context": "To restrict the search space we can observe that a chordal graph with n nodes has at most n maximal cliques [19].", "startOffset": 108, "endOffset": 112}, {"referenceID": 20, "context": "Lemma 3 ([21, 22]) Any maximum weight spanning tree of the clique graph is a junction tree, and hence satisfies the running intersection property: for every pair of nodes c and c, (c \u2229 c) \u2286 c for all nodes c on the unique path between c and c.", "startOffset": 9, "endOffset": 17}, {"referenceID": 21, "context": "Lemma 3 ([21, 22]) Any maximum weight spanning tree of the clique graph is a junction tree, and hence satisfies the running intersection property: for every pair of nodes c and c, (c \u2229 c) \u2286 c for all nodes c on the unique path between c and c.", "startOffset": 9, "endOffset": 17}, {"referenceID": 22, "context": "As stated above, cardinality constraints are natively supported by some constraint languages or, alternatively, they can be efficiently reduced to disjunctive Boolean constraints [23].", "startOffset": 179, "endOffset": 183}, {"referenceID": 23, "context": "2) [24] and PWBO (version 2.", "startOffset": 3, "endOffset": 7}, {"referenceID": 24, "context": "2) [25].", "startOffset": 3, "endOffset": 7}, {"referenceID": 25, "context": "For SMT, we used the OPTIMATHSAT solver (version 5) [26].", "startOffset": 52, "endOffset": 56}, {"referenceID": 26, "context": "3) [27] and HCLASP3 (also v.", "startOffset": 3, "endOffset": 7}, {"referenceID": 27, "context": "We also tried the LP2NORMAL tool that reduces cardinality constraints to more basic constraints [28].", "startOffset": 96, "endOffset": 100}, {"referenceID": 17, "context": "To illustrate the potential residing in solver technology, we consider two datasets, one containing risk factors in heart diseases and the other variables related to economical behavior [18], to be abbreviated by heart and econ in the sequel.", "startOffset": 186, "endOffset": 190}, {"referenceID": 3, "context": "For econ, however, exhaustive enumeration is impractical due to the extremely large search space, and consequently the optimality of the Markov network found by stochastic search in [4] had been open until now.", "startOffset": 182, "endOffset": 185}, {"referenceID": 28, "context": "The related problem of structure learning of Bayesian networks has been addressed by general-purpose combinatorial search methods, including MAXSAT [29] and a constraint-programming solver with a linear-programming solver as a subprocedure [30, 31].", "startOffset": 148, "endOffset": 152}, {"referenceID": 29, "context": "The related problem of structure learning of Bayesian networks has been addressed by general-purpose combinatorial search methods, including MAXSAT [29] and a constraint-programming solver with a linear-programming solver as a subprocedure [30, 31].", "startOffset": 240, "endOffset": 248}, {"referenceID": 30, "context": "The related problem of structure learning of Bayesian networks has been addressed by general-purpose combinatorial search methods, including MAXSAT [29] and a constraint-programming solver with a linear-programming solver as a subprocedure [30, 31].", "startOffset": 240, "endOffset": 248}], "year": 2013, "abstractText": "We investigate the problem of learning the structure of a Markov network from data. It is shown that the structure of such networks can be described in terms of constraints which enables the use of existing solver technology with optimization capabilities to compute optimal networks starting from initial scores computed from the data. To achieve efficient encodings, we develop a novel characterization of Markov network structure using a balancing condition on the separators between cliques forming the network. The resulting translations into propositional satisfiability and its extensions such as maximum satisfiability, satisfiability modulo theories, and answer set programming, enable us to prove optimal certain network structures which have been previously found by stochastic search.1", "creator": "LaTeX with hyperref package"}}}