{"id": "1310.5665", "review": {"conference": "icml", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Oct-2013", "title": "Learning Theory and Algorithms for Revenue Optimization in Second-Price Auctions with Reserve", "abstract": "Second-price auctions with reserve play a critical role for modern search engine and popular online sites since the revenue of these companies often directly de- pends on the outcome of such auctions. The choice of the reserve price is the main mechanism through which the auction revenue can be influenced in these electronic markets. We cast the problem of selecting the reserve price to optimize revenue as a learning problem and present a full theoretical analysis dealing with the complex properties of the corresponding loss function. We further give novel algorithms for solving this problem and report the results of several experiments demonstrating their effectiveness.", "histories": [["v1", "Mon, 21 Oct 2013 18:27:25 GMT  (188kb,D)", "http://arxiv.org/abs/1310.5665v1", "Under revision for ICML 2014"], ["v2", "Mon, 13 Jan 2014 18:31:04 GMT  (182kb,D)", "http://arxiv.org/abs/1310.5665v2", "Accepted at ICML 2014"], ["v3", "Tue, 2 Dec 2014 20:42:17 GMT  (172kb,D)", "http://arxiv.org/abs/1310.5665v3", "Accepted at ICML 2014"]], "COMMENTS": "Under revision for ICML 2014", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mehryar mohri", "andres mu\\~noz medina"], "accepted": true, "id": "1310.5665"}, "pdf": {"name": "1310.5665.pdf", "metadata": {"source": "CRF", "title": "Learning Theory and Algorithms for Revenue Optimization in Second-Price Auctions with Reserve", "authors": ["Mehryar Mohri"], "emails": ["mohri@cims.nyu.edu", "munoz@cims.nyu.edu"], "sections": [{"heading": null, "text": "The choice of the minimum price is the most important mechanism by which the auction revenues in these electronic markets can be influenced. We raise the problem of the selection of the minimum price to optimize the proceeds as a learning problem and present a comprehensive theoretical analysis that deals with the complex properties of the corresponding loss function. Furthermore, we present novel algorithms to solve this problem and report on the results of several experiments that prove their effectiveness."}, {"heading": "1 Introduction", "text": "In fact, it is the case that we will be able to go in search of a solution that is capable, that we are able to find a solution that is capable of finding a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution."}, {"heading": "2 Reserve price selection problem", "text": "As already discussed, the choice of the minimum price r is the main mechanism by which a seller can influence the auction proceeds. To determine the results of a second price auction, we need only the vector of the first and second highest bids, which we call b = (b1, b2), B-R2. (1) The simplest constellation is one in which there are no features associated with the auction. (2) The aim of an auction is to select r in order to optimize the expected revenue: E b [revenue (r, b)] = previous sections P [b2 > t] dt + r P [b1 \u2265 r]. (2) The derivation of this equality can be achieved with the help of parts and can be found in the next sequence L x. In fact, this expression is exactly the one optimized by the authors."}, {"heading": "3 Learning guarantees", "text": "Let us leave the sentence of the feature vectors and the function r 7 (1) b) b b) b b) c) c) c) c) c) c) c) c) c) c) c (1) c) c (1) c) c (1) c (1) c) c (1) c) c (1) c) c (1) c) c (1) e (1) c e (1) e (1) c) e (1) c) e (1) e (1) e (1) e (e) e (1) c) e (e) e (e) e (1) e e e e e e (e) e (e) e (e) e (e) e (e) e (e) e (e) e (e) e (e) e (e) e) e (e) e (e) e) e (e) e) e (e) e (e) e) e (e) e (e) e (1) e (e) e) e (e) e (e) e) e (e) e (e) e) e (e) e (e) e) e (e) e (e) e) e (e) e (e) (e) (e) 1) e 1) e (e) e (e) e (e) e) e (e) e (e) e) e (e) e (e) e (e) e (e) e) e (e) e (e) e (e) (e 1) e 1) e (e) e (e) e 1 (e) e 1) e (e) e (e 1 (e) e) e (e) e) e (e (e) e) e (e) e) e (e (e) e (e 1 (e) e) e (e) e (e) e 1 (e) e 1 (e 1 (e) e 1 (e) e) e 1 (e) e) e 1 (e) e (e) e (e) e) e (e) e (e (e) e) e (e 1 (e 1 (e) e 1 (e) e 1 (e e) e) e e) e"}, {"heading": "3.1 Surrogate loss", "text": "As already mentioned, the loss function L in our case does not allow some common useful properties: for all fixed b, L (\u00b7, b), however, this function is indistinguishable at two points, is not convex, and is not Lipschitz, in fact it is discontinuous. For all fixed b, L (\u00b7, b) is quasi-convex, a property that is often desirable since there are several solutions to quasi-convex optimization problems. Unfortunately, a sum of quasi-convex functions, such as the sum that appears in the definition of empirical loss, is not quasi-convex and a fortiori is not convex1. In general, such a sum can add exponentially many local minima. This leads us to a surrogate loss function with more favorable optimization possibilities. A standard method in machine learning is to replace the loss function with a convex upper limit."}, {"heading": "4 Algorithms", "text": "In this section we present algorithms for solving the optimization problem in the selection of the minimum price. We start with a case without attributes and then deal with the general case."}, {"heading": "4.1 No feature case", "text": "We present a general algorithm to optimize sums of functions similar to the problem, or L in onedimensional case.Definition 9. We will say that the function V: R + \u00b7 B \u2192 R is a v function if it allows the following form: V (r, b) = \u2212 a11r \u2264 b2 \u2212 a2r1b2 < r = a3r \u2212 a4) 1b1 < r < (1 +) b1 > 0 constants and a1, a2, a4 defined by a1 = a3b2, a2 = a3, and a4 = a3 (1 +) b1.Figure 4 (a) illustrates this family of loss functions. A v function is a generalization of L.In fact, each v function fulfills V (r, b) \u2264 0 and reaches its minimum at b1."}, {"heading": "4.2 General case", "text": "We consider first the case of a hypothesis, the H of the linear functions x 7 \u2192 w \u00b7 x with limited DC (DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC = 1 DC 1 DC = 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC = 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1 DC 1"}, {"heading": "5 Experiments", "text": "This shows the potential for the scalability of our algorithm. Our algorithm solves the problem with the 20,000 points required only using secondary data. All of our experiments are conducted on the basis of synthetic data, which we do despite the fact that experiments with data from online auctions exist in literature, while this data is not available to the public for confidentiality reasons. To make the most of our knowledge of non-publicly available data sets, no such approach is available for online auctions. The first test we perform evaluates the speed of our algorithm in the simple non-feature case. Figure 6 shows the time it takes for our sorting algorithms to find the optimal solution compared to the online auctions. The first one that evaluates the loss at each point. 2.6 GHz AMD processor with 7GB of RAM. The time it takes our algorithm to solve the problem with 2000 points, whereas the nazi-ve approach takes more than 10 minutes to find the solution."}, {"heading": "100 10\u22121 10\u22122 10\u22123 10\u22124 10\u22125", "text": "Size 6400\u03c3 0.1.2.3.4.5where z +: = max (z, 0), \u0445 N (0, 1) is a Gaussian random variable and \u03c3 takes values in quantity {0,.1,..,.5}.. We have measured the performance of our learning algorithm according to the noise added to the characteristics. Our algorithm was trained on a sample of size 8,000 points and tested on a sample of 8,000 points. Table 1 shows the mean revenue for various algorithms. The first line corresponds to the case where no reserve price is set. The second line represents the revenue obtained by using our simple sorting algorithm, which ignores the feature vectors. Series three shows the performance of our algorithm and the last line shows the maximum possible mean, i.e. the mean value of the highest bids. The results of Table 1 show that our algorithm achieves a perfect performance in the separable case, as expected."}, {"heading": "6 Conclusion", "text": "The specific characteristics of the loss function for this problem required a new analysis and new learning guarantees. The algorithmic solutions we presented are practically applicable to revenue optimization problems for this type of auction in the most realistic environments. Our experimental results also show their effectiveness. Much of the analysis, especially our calibration study, and the presented algorithms may also be of interest in other areas of learning."}, {"heading": "Acknowledgments", "text": "We thank Afshin Rostamizadeh and Umar Syed for the numerous discussions on the topic of this work. This work was partly financed by the NSF Prize IIS-1117591."}, {"heading": "A Proofs for learning guarantees", "text": ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"}, {"heading": "B Combinatorial algorithm", "text": "B.1 Solution PropertyWe will show that problem (19) is a solution r () = b1i (for some i). We will need the following definition. Definition 14. For a value of r \u2212 \u2212 \u2212 \u2212 \u2212 we will see the following subset of R:. If > 0 for all i is such that [\u2212 r; b1i + \u2264 b1i) then F (r +) < F (r +) < F (r +) < F (r +) < F (r +) < F (r +) < F (r \u2212) \u2264 F (r \u2212). The condition that r 6 = b1i for all i implies that there is small enough that there is a solution (r).Proof. Let us leave vi = Vi (r, bi) and vi () vi () = Vi (r +, bi)."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Second-price auctions with reserve play a critical role for modern search engine<lb>and popular online sites since the revenue of these companies often directly de-<lb>pends on the outcome of such auctions. The choice of the reserve price is the<lb>main mechanism through which the auction revenue can be influenced in these<lb>electronic markets. We cast the problem of selecting the reserve price to optimize<lb>revenue as a learning problem and present a full theoretical analysis dealing with<lb>the complex properties of the corresponding loss function. We further give novel<lb>algorithms for solving this problem and report the results of several experiments<lb>demonstrating their effectiveness.", "creator": "LaTeX with hyperref package"}}}