{"id": "1311.1869", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2013", "title": "Optimization, Learning, and Games with Predictable Sequences", "abstract": "We provide several applications of Optimistic Mirror Descent, an online learning algorithm based on the idea of predictable sequences. First, we recover the Mirror Prox algorithm for offline optimization, prove an extension to Holder-smooth functions, and apply the results to saddle-point type problems. Next, we prove that a version of Optimistic Mirror Descent (which has a close relation to the Exponential Weights algorithm) can be used by two strongly-uncoupled players in a finite zero-sum matrix game to converge to the minimax equilibrium at the rate of O((log T)/T). This addresses a question of Daskalakis et al 2011. Further, we consider a partial information version of the problem. We then apply the results to convex programming and exhibit a simple algorithm for the approximate Max Flow problem.", "histories": [["v1", "Fri, 8 Nov 2013 02:47:40 GMT  (22kb)", "http://arxiv.org/abs/1311.1869v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.GT", "authors": ["alexander rakhlin", "karthik sridharan"], "accepted": true, "id": "1311.1869"}, "pdf": {"name": "1311.1869.pdf", "metadata": {"source": "CRF", "title": "Optimization, Learning, and Games with Predictable Sequences", "authors": ["Alexander Rakhlin", "Karthik Sridharan"], "emails": [], "sections": [{"heading": null, "text": "The question of the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why, the why, the why and the why, the why and the why, the why and the why, the why and the why, the why and the why and the why?"}], "references": [], "referenceMentions": [], "year": 2013, "abstractText": "We provide several applications of Optimistic Mirror Descent, an online learning algorithm based on the idea<lb>of predictable sequences. First, we recover theMirror Prox algorithm for offline optimization, prove an extension<lb>to H\u00f6lder-smooth functions, and apply the results to saddle-point type problems. Next, we prove that a version<lb>of Optimistic Mirror Descent (which has a close relation to the Exponential Weights algorithm) can be used by<lb>two strongly-uncoupled players in a finite zero-summatrix game to converge to the minimax equilibrium at the<lb>rate ofO((logT )/T ). This addresses a question of Daskalakis et al [6]. Further, we consider a partial information<lb>version of the problem. We then apply the results to convex programming and exhibit a simple algorithm for the<lb>approximateMax Flow problem.", "creator": "LaTeX with hyperref package"}}}