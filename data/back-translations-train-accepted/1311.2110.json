{"id": "1311.2110", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Nov-2013", "title": "Curvature and Optimal Algorithms for Learning and Minimizing Submodular Functions", "abstract": "We investigate three related and important problems connected to machine learning: approximating a submodular function everywhere, learning a submodular function (in a PAC-like setting [53]), and constrained minimization of submodular functions. We show that the complexity of all three problems depends on the 'curvature' of the submodular function, and provide lower and upper bounds that refine and improve previous results [3, 16, 18, 52]. Our proof techniques are fairly generic. We either use a black-box transformation of the function (for approximation and learning), or a transformation of algorithms to use an appropriate surrogate function (for minimization). Curiously, curvature has been known to influence approximations for submodular maximization [7, 55], but its effect on minimization, approximation and learning has hitherto been open. We complete this picture, and also support our theoretical claims by empirical results.", "histories": [["v1", "Fri, 8 Nov 2013 23:42:34 GMT  (58kb,D)", "http://arxiv.org/abs/1311.2110v1", "21 pages. A shorter version appeared in Advances of NIPS-2013"]], "COMMENTS": "21 pages. A shorter version appeared in Advances of NIPS-2013", "reviews": [], "SUBJECTS": "cs.DS cs.DM cs.LG", "authors": ["rishabh k iyer", "stefanie jegelka", "jeff a bilmes"], "accepted": true, "id": "1311.2110"}, "pdf": {"name": "1311.2110.pdf", "metadata": {"source": "CRF", "title": "Curvature and Optimal Algorithms for Learning and Minimizing Submodular Functions", "authors": ["Rishabh Iyer", "Stefanie Jegelka", "Jeff Bilmes"], "emails": ["rkiyer@uw.edu,", "stefje@eecs.berkeley.edu,", "bilmes@uw.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "2 Problem statements, definitions and background", "text": "Before presenting our main results, we provide some necessary definitions and introduce a new concept that shows the general version of a submodular function (32). (During this work, we assume that the submodular function f is defined on a basis of n elements, that it is not negative and f (\u2205) = 0. We also deal with the following three problems: Problem 1. (or additive) functions, the submodular function f in the form of a value oracle, find an approximation f (within polynomial time and representable within polynomial space), so that it applies to all X (X)."}, {"heading": "2.1 Curvature of a Submodular function", "text": "A central concept in this work is the total curvature of a submodular function f and the curvature f (S) in relation to a series of S (S), defined as [7, 55], [7], [7], [8], [8], [8], [8], [8], [8], [8], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], [11], \"[11],\" [11], \"[11],\" [11], \"[11],\" [11], \"[11],\" [13, \"13,\" 13, \"13,\" 13, \"13,\" 13, \"13,\" 13, \"),\" 13, \"13,\" 13, \"),\" 13, \"13,\" 13, \"13,\"), \"13,\" 13, \"),\" 13, \"),\" 13, \"13,\"), \"13,\"), [13, [13, \"13,\"), 13, \"),\" 13, \"), 13,\" 13, \"),\" 13, \"),\" 13, \"(13,\"), \"),\" 13, \"), [13,\"), [13, [13, \"), [13, [13), [13, [13, [13), [13, [13, [13), [13), [13, [13), [13), [13, [13], [13), [13, [13, [13], [13, [13], [13], [13], [13],"}, {"heading": "2.2 The Curve-normalized Polymatroid function", "text": "To analyze problems 1 - 3, we introduce the concept of a curve normalized function. (...) In addition, we can define any function (...) (...). (...) Specifically, we define the coupling function (...) is a monotonous, increasing, not negative, submodular function f (...) = 0, If we define f = 0, then we define f... 0. We call the curvature normalized version of f (...) because its curvature is a monotonous, increasing, submodular function f (...) = 0,0. Function f allows us to decompile a submodular function f (...) into a \"difficult\" polymatroid function and a \"simple\" modular part as f (...) = difficult (...) + measured function (...)."}, {"heading": "2.3 A framework for curvature-dependent lower bounds.", "text": "Previous information theory lower limits for problems 1-3 [16, 18, 25, 52] are independent of curvature and use functions with \u03baf = 1. These curvature-independent limits are proven by constructing two essentially indistinguishable matroid rank functions h and fR, one of which depends on a random set of R V. It is then argued that any algorithm would have to produce a superpolynomial number of queries about the functions in order to be able to distinguish h and fR with a high probability. The lower limit will be the ratio maxX-C h (X) / fR (X). We extend this proof method to functions with a fixed predetermined curvature. To this end, we define the functions fRUK (X) = kruff R (X) + (1 \u2212 zeptf)."}, {"heading": "3 Approximating submodular functions everywhere", "text": "We start with a theorem that shows how such an approach can be used to obtain a curvature-specific, improved approach. Note that the curvature of a monotonous submodular function can be obtained within 2n + 1 queries to f. The key idea of Theorem 3.1 is to approximate the curved part of f and keep the modular part more exactly f. Theorem 3.1 Given a polymatroid function f < 1, let f approximate f f approximate f, and let f approximate f approximate."}, {"heading": "4 Learning Submodular functions", "text": "Next, we address the problem of submodular functions in a PMAC environment [3]. The PMAC (probably predominantly correct) structure is an extension of the PAC framework [53] to allow multiplicative errors in the function values of a fixed but unknown distribution D over 2V. We obtain training samples {(Xi, f (Xi)} mi = 1 drawn i.i.d. by D. The algorithm may take time to calculate a (polynomically representable) function f, which has a good approximation to f in relation to D. Formally, f must satisfy the thatPrX1, X2 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 Xm \u00b7 D [PrX] (X)."}, {"heading": "5 Constrained submodular minimization", "text": "Next, we apply our results to minimizing submodular functions under certain conditions. (Most restricted minimization algorithms use one of two strategies: they apply a convex relaxation [25, 35], or they optimize a surrogate function f that we refer to the optimal solution as X, 18, 35]. We follow the second strategy and propose a new, widely applicable curve-dependent solution for surrogate functions. A suitable selection of f, as it will theoretically ensure optimal results. (In this section, we refer to the optimal solution as X, argminX, C f, X, 5.1.) Given a submodular function f, we leave f, f, f, f, f, f, f, f, f, X, X, X,. (X)."}, {"heading": "5.1 Experiments", "text": "We conclude this section by empirically showing the performance of MUB and EA and their exact dependence on empirical factors related to curvature. We focus on cardinality lower constraints, C = {X V: | X | \u2265 \u03b1} and the \"worst-case\" class of functions used in this paper to prove lower limits, fR (X) = min {| X-R = \u03b2, | X |, \u03b1}, (40), where R = V\\ R and R V are more random, so that | = \u03b1. We adjust \u03b1 = n1 / 2 + and \u03b2 = n2 using a parameter. The smaller the problem is, the harder the problem. Function (40) has a curvature limit of f = 1. To obtain a function with specific curvature widths, we define empirical factors that are closely related to curvature (X) + (X) and empirical results that we do not exactly adjust to curvature."}, {"heading": "6 Conclusion and Discussion", "text": "In this paper, we examine the effects of curvature on the problems of approximation, learning and minimizing submodular functions under constraints. In addition, in [28] we also consider the role of curvature in submodular optimization problems over a class of submodular constraints. Given that the functional form and effect of the submodularity ratio proposed in [7, 55] is similar to that of Intel, an interesting addition is the question of whether there is a uniform quantity for both terms. Another open question is whether a quantity similar to curvature can be defined for subadditive functions, thereby refining the results in [2, 1] for learning subadditive functions. Finally, it seems that the techniques in this paper could be applied to improve curvature-dependent limits for the limited online use of Bethana functions and thus a refinement of the results in [2, 1] for additive functions."}], "references": [{"title": "Sketching valuation functions", "author": ["A. Badanidiyuru", "S. Dobzinski", "H. Fu", "R. Kleinberg", "N. Nisan", "T. Roughgarden"], "venue": "In SODA,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Learning valuation functions", "author": ["M.F. Balcan", "F. Constantin", "S. Iwata", "L. Wang"], "venue": "COLT,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Submodular functions: Learnability, structure, and optimization", "author": ["N. Balcan", "N. Harvey"], "venue": "In Arxiv preprint,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "A tight (1/2) linear-time approximation to unconstrained submodular maximization", "author": ["N. Buchbinder", "M. Feldman", "J. Naor", "R. Schwartz"], "venue": "In FOCS,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Maximizing a monotone submodular function under a matroid constraint", "author": ["G. Calinescu", "C. Chekuri", "M. Pal", "J. Vondr\u00e1k"], "venue": "IPCO,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Submodular function maximization via the multilinear relaxation and contention resolution schemes", "author": ["C. Chekuri", "J. Vondr\u00e1k", "R. Zenklusen"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Submodular set functions, matroids and the greedy algorithm: tight worstcase bounds and some generalizations of the Rado-Edmonds theorem", "author": ["M. Conforti", "G. Cornuejols"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1984}, {"title": "Decomposition of submodular functions", "author": ["W.H. Cunningham"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1983}, {"title": "Submodular meets spectral: Greedy algorithms for subset selection, sparse approximation and dictionary selection", "author": ["A. Das", "D. Kempe"], "venue": "In ICML,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "Minimizing sparse high-order energies by submodular vertex-cover", "author": ["A. Delong", "O. Veksler", "A. Osokin", "Y. Boykov"], "venue": "In NIPS,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "On the approximation of submodular functions", "author": ["N.R. Devanur", "S. Dughmi", "R. Schwartz", "A. Sharma", "M. Singh"], "venue": "arXiv preprint arXiv:1304.4948,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Maximizing non-monotone submodular functions", "author": ["U. Feige", "V. Mirrokni", "J. Vondr\u00e1k"], "venue": "SIAM J. COMPUT.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "A unified continuous greedy algorithm for submodular maximization", "author": ["M. Feldman", "J. Naor", "R. Schwartz"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "A push-relabel framework for submodular function minimization and applications to parametric optimization", "author": ["L. Fleischer", "S. Iwata"], "venue": "Discrete Applied Mathematics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2003}, {"title": "Submodular functions and optimization, volume 58", "author": ["S. Fujishige"], "venue": "Elsevier Science,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2005}, {"title": "Approximability of combinatorial problems with multi-agent submodular cost functions", "author": ["G. Goel", "C. Karande", "P. Tripathi", "L. Wang"], "venue": "In FOCS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Combinatorial problems with discounted price functions in multi-agent systems", "author": ["G. Goel", "P. Tripathi", "L. Wang"], "venue": "In FSTTCS,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Approximating submodular functions everywhere", "author": ["M. Goemans", "N. Harvey", "S. Iwata", "V. Mirrokni"], "venue": "In SODA,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "The ellipsoid method and its consequences in combinatorial optimization", "author": ["M. Gr\u00f6tschel", "L. Lov\u00e1sz", "A. Schrijver"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1981}, {"title": "Geometric methods in combinatorial optimization", "author": ["M. Grotschel", "L. Lov\u00e1sz", "A. Schrijver"], "venue": "In Silver Jubilee Conf. on Combinatorics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1984}, {"title": "Approximation algorithms and hardness results for labeled connectivity problems", "author": ["R. Hassin", "J. Monnot", "D. Segev"], "venue": "J Combinatorial Optimization,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "A fully combinatorial algorithm for submodular function minimization", "author": ["S. Iwata"], "venue": "In Proceedings of the thirteenth annual ACM-SIAM symposium on Discrete algorithms,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2002}, {"title": "A faster scaling algorithm for minimizing submodular functions", "author": ["S. Iwata"], "venue": "SIAM Journal on Computing,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2003}, {"title": "Submodular function minimization", "author": ["S. Iwata"], "venue": "Mathematical Programming,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2008}, {"title": "Submodular function minimization under covering constraints", "author": ["S. Iwata", "K. Nagano"], "venue": "In In FOCS,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "A simple combinatorial algorithm for submodular function minimization", "author": ["S. Iwata", "J. Orlin"], "venue": "In Proceedings of the twentieth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "A combinatorial strongly polynomial algorithm for minimizing submodular functions", "author": ["S. Iwata", "L. Fleischer", "S. Fujishige"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2001}, {"title": "Submodular optimization with submodular cover and submodular knapsack constraints", "author": ["R. Iyer", "J. Bilmes"], "venue": "In NIPS,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "The submodular Bregman and Lov\u00e1sz-Bregman divergences with applications", "author": ["R. Iyer", "J. Bilmes"], "venue": "In NIPS,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Algorithms for approximate minimization of the difference between submodular functions, with applications", "author": ["R. Iyer", "J. Bilmes"], "venue": "In UAI,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Mirror descent like algorithms for submodular optimization", "author": ["R. Iyer", "S. Jegelka", "J. Bilmes"], "venue": "NIPS Workshop on Discrete Optimization in Machine Learning (DISCML),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Fast semidifferential based submodular function optimization", "author": ["R. Iyer", "S. Jegelka", "J. Bilmes"], "venue": "In ICML,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "Combinatorial Problems with submodular coupling in machine learning and computer vision", "author": ["S. Jegelka"], "venue": "PhD thesis, ETH Zurich,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2012}, {"title": "Online submodular minimization for combinatorial structures", "author": ["S. Jegelka", "J. Bilmes"], "venue": null, "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Approximation bounds for inference using cooperative cuts", "author": ["S. Jegelka", "J.A. Bilmes"], "venue": "In ICML,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2011}, {"title": "Submodularity beyond submodular energies: coupling edges in graph cuts", "author": ["S. Jegelka", "J.A. Bilmes"], "venue": "In CVPR,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2011}, {"title": "A principled deep random field for image segmentation", "author": ["P. Kohli", "A. Osokin", "S. Jegelka"], "venue": "In CVPR,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2013}, {"title": "Near-optimal nonmyopic value of information in graphical models", "author": ["A. Krause", "C. Guestrin"], "venue": "In Proceedings of Uncertainity in Artificial Intelligence. UAI,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2005}, {"title": "Near-optimal sensor placements: Maximizing information while minimizing communication cost", "author": ["A. Krause", "C. Guestrin", "A. Gupta", "J. Kleinberg"], "venue": "In IPSN,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2006}, {"title": "Computing maximal \u201cpolymatroidal\u201d network flows", "author": ["E. Lawler", "C. Martel"], "venue": "Mathematics of Operations Research,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1982}, {"title": "Non-monotone submodular maximization under matroid and knapsack constraints", "author": ["J. Lee", "V. Mirrokni", "V. Nagarajan", "M. Sviridenko"], "venue": "In STOC,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2009}, {"title": "Submodular maximization over multiple matroids via generalized exchange properties", "author": ["J. Lee", "M. Sviridenko", "J. Vondr\u00e1k"], "venue": "In APPROX,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2009}, {"title": "Optimal selection of limited vocabulary speech corpora", "author": ["H. Lin", "J. Bilmes"], "venue": "In Interspeech,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2011}, {"title": "A class of submodular functions for document summarization", "author": ["H. Lin", "J. Bilmes"], "venue": "In The 49th Meeting of the Assoc. for Comp. Ling. Human Lang. Technologies", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2011}, {"title": "Learning mixtures of submodular shells with application to document summarization", "author": ["H. Lin", "J. Bilmes"], "venue": "In UAI,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2012}, {"title": "An analysis of approximations for maximizing submodular set functions\u2014i", "author": ["G. Nemhauser", "L. Wolsey", "M. Fisher"], "venue": "Mathematical Programming,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1978}, {"title": "Approximation algorithms for offline risk-averse combinatorial optimization", "author": ["E. Nikolova"], "venue": null, "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2010}, {"title": "A faster strongly polynomial time algorithm for submodular function minimization", "author": ["J. Orlin"], "venue": "Mathematical Programming,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2009}, {"title": "Symmetric submodular function minimization under hereditary family constraints", "author": ["J. Soto", "M. Goemans"], "venue": null, "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2010}, {"title": "Learning fourier sparse set functions", "author": ["P. Stobbe", "A. Krause"], "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2012}, {"title": "A note on maximizing a submodular set function subject to a knapsack constraint", "author": ["M. Sviridenko"], "venue": "Operations Research Letters,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2004}, {"title": "Submodular approximation: Sampling-based algorithms and lower bounds", "author": ["Z. Svitkina", "L. Fleischer"], "venue": "In FOCS,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2008}, {"title": "A theory of the learnable", "author": ["L.G. Valiant"], "venue": "Communications of the ACM,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 1984}, {"title": "Graph cut based image segmentation with connectivity priors", "author": ["S. Vicente", "V. Kolmogorov", "C. Rother"], "venue": "In Proc. CVPR,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2008}, {"title": "Submodularity and curvature: the optimal algorithm", "author": ["J. Vondr\u00e1k"], "venue": "RIMS Kokyuroku Bessatsu,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2010}, {"title": "Minimum-energy broadcasting in static ad hoc wireless networks", "author": ["P.-J. Wan", "G. Calinescu", "X.-Y. Li", "O. Frieder"], "venue": "Wireless Networks,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2002}, {"title": "Approximation and hardness results for label cut and related problems", "author": ["P. Zhang", "J.-Y. Cai", "L.-Q. Tang", "W.-B. Zhao"], "venue": "Journal of Combinatorial Optimization,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2011}], "referenceMentions": [{"referenceID": 52, "context": "Abstract We investigate three related and important problems connected to machine learning: approximating a submodular function everywhere, learning a submodular function (in a PAC-like setting [53]), and constrained minimization of submodular functions.", "startOffset": 194, "endOffset": 198}, {"referenceID": 2, "context": "We show that the complexity of all three problems depends on the \u201ccurvature\u201d of the submodular function, and provide lower and upper bounds that refine and improve previous results [3, 16, 18, 52].", "startOffset": 181, "endOffset": 196}, {"referenceID": 15, "context": "We show that the complexity of all three problems depends on the \u201ccurvature\u201d of the submodular function, and provide lower and upper bounds that refine and improve previous results [3, 16, 18, 52].", "startOffset": 181, "endOffset": 196}, {"referenceID": 17, "context": "We show that the complexity of all three problems depends on the \u201ccurvature\u201d of the submodular function, and provide lower and upper bounds that refine and improve previous results [3, 16, 18, 52].", "startOffset": 181, "endOffset": 196}, {"referenceID": 51, "context": "We show that the complexity of all three problems depends on the \u201ccurvature\u201d of the submodular function, and provide lower and upper bounds that refine and improve previous results [3, 16, 18, 52].", "startOffset": 181, "endOffset": 196}, {"referenceID": 6, "context": "Curiously, curvature has been known to influence approximations for submodular maximization [7, 55], but its effect on minimization, approximation and learning has hitherto been open.", "startOffset": 92, "endOffset": 99}, {"referenceID": 54, "context": "Curiously, curvature has been known to influence approximations for submodular maximization [7, 55], but its effect on minimization, approximation and learning has hitherto been open.", "startOffset": 92, "endOffset": 99}, {"referenceID": 14, "context": "The search for optimal algorithms for submodular optimization has seen substantial progress [15, 24, 4] in recent years, but is still an ongoing endeavor.", "startOffset": 92, "endOffset": 103}, {"referenceID": 23, "context": "The search for optimal algorithms for submodular optimization has seen substantial progress [15, 24, 4] in recent years, but is still an ongoing endeavor.", "startOffset": 92, "endOffset": 103}, {"referenceID": 3, "context": "The search for optimal algorithms for submodular optimization has seen substantial progress [15, 24, 4] in recent years, but is still an ongoing endeavor.", "startOffset": 92, "endOffset": 103}, {"referenceID": 18, "context": "The first polynomial-time algorithm used the ellipsoid method [19, 20], and several combinatorial algorithms followed [27, 22, 14, 23, 26, 48].", "startOffset": 62, "endOffset": 70}, {"referenceID": 19, "context": "The first polynomial-time algorithm used the ellipsoid method [19, 20], and several combinatorial algorithms followed [27, 22, 14, 23, 26, 48].", "startOffset": 62, "endOffset": 70}, {"referenceID": 26, "context": "The first polynomial-time algorithm used the ellipsoid method [19, 20], and several combinatorial algorithms followed [27, 22, 14, 23, 26, 48].", "startOffset": 118, "endOffset": 142}, {"referenceID": 21, "context": "The first polynomial-time algorithm used the ellipsoid method [19, 20], and several combinatorial algorithms followed [27, 22, 14, 23, 26, 48].", "startOffset": 118, "endOffset": 142}, {"referenceID": 13, "context": "The first polynomial-time algorithm used the ellipsoid method [19, 20], and several combinatorial algorithms followed [27, 22, 14, 23, 26, 48].", "startOffset": 118, "endOffset": 142}, {"referenceID": 22, "context": "The first polynomial-time algorithm used the ellipsoid method [19, 20], and several combinatorial algorithms followed [27, 22, 14, 23, 26, 48].", "startOffset": 118, "endOffset": 142}, {"referenceID": 25, "context": "The first polynomial-time algorithm used the ellipsoid method [19, 20], and several combinatorial algorithms followed [27, 22, 14, 23, 26, 48].", "startOffset": 118, "endOffset": 142}, {"referenceID": 47, "context": "The first polynomial-time algorithm used the ellipsoid method [19, 20], and several combinatorial algorithms followed [27, 22, 14, 23, 26, 48].", "startOffset": 118, "endOffset": 142}, {"referenceID": 23, "context": "For a detailed summary, see [24].", "startOffset": 28, "endOffset": 32}, {"referenceID": 45, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 68, "endOffset": 83}, {"referenceID": 50, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 68, "endOffset": 83}, {"referenceID": 11, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 68, "endOffset": 83}, {"referenceID": 3, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 68, "endOffset": 83}, {"referenceID": 50, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 120, "endOffset": 142}, {"referenceID": 40, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 120, "endOffset": 142}, {"referenceID": 41, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 120, "endOffset": 142}, {"referenceID": 5, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 120, "endOffset": 142}, {"referenceID": 12, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 120, "endOffset": 142}, {"referenceID": 4, "context": "However, maximization problems admit constant-factor approximations [46, 51, 12, 4], often even in the constrained case [51, 41, 42, 6, 13, 5].", "startOffset": 120, "endOffset": 142}, {"referenceID": 2, "context": "While submodularity, like convexity, occurs naturally in a wide variety of problems, recent studies have shown that in the general case, many submodular problems of interest are very hard: the problems of learning a submodular function or of submodular minimization under constraints do not even admit constant or logarithmic approximation factors in polynomial time [3, 17, 18, 25, 52].", "startOffset": 367, "endOffset": 386}, {"referenceID": 16, "context": "While submodularity, like convexity, occurs naturally in a wide variety of problems, recent studies have shown that in the general case, many submodular problems of interest are very hard: the problems of learning a submodular function or of submodular minimization under constraints do not even admit constant or logarithmic approximation factors in polynomial time [3, 17, 18, 25, 52].", "startOffset": 367, "endOffset": 386}, {"referenceID": 17, "context": "While submodularity, like convexity, occurs naturally in a wide variety of problems, recent studies have shown that in the general case, many submodular problems of interest are very hard: the problems of learning a submodular function or of submodular minimization under constraints do not even admit constant or logarithmic approximation factors in polynomial time [3, 17, 18, 25, 52].", "startOffset": 367, "endOffset": 386}, {"referenceID": 24, "context": "While submodularity, like convexity, occurs naturally in a wide variety of problems, recent studies have shown that in the general case, many submodular problems of interest are very hard: the problems of learning a submodular function or of submodular minimization under constraints do not even admit constant or logarithmic approximation factors in polynomial time [3, 17, 18, 25, 52].", "startOffset": 367, "endOffset": 386}, {"referenceID": 51, "context": "While submodularity, like convexity, occurs naturally in a wide variety of problems, recent studies have shown that in the general case, many submodular problems of interest are very hard: the problems of learning a submodular function or of submodular minimization under constraints do not even admit constant or logarithmic approximation factors in polynomial time [3, 17, 18, 25, 52].", "startOffset": 367, "endOffset": 386}, {"referenceID": 2, "context": "Indeed, limited prior work has shown improved results for constrained minimization and learning of sub-classes of submodular functions, including symmetric functions [3, 49], concave functions [17, 37, 47], label cost or covering functions [21, 57].", "startOffset": 166, "endOffset": 173}, {"referenceID": 48, "context": "Indeed, limited prior work has shown improved results for constrained minimization and learning of sub-classes of submodular functions, including symmetric functions [3, 49], concave functions [17, 37, 47], label cost or covering functions [21, 57].", "startOffset": 166, "endOffset": 173}, {"referenceID": 16, "context": "Indeed, limited prior work has shown improved results for constrained minimization and learning of sub-classes of submodular functions, including symmetric functions [3, 49], concave functions [17, 37, 47], label cost or covering functions [21, 57].", "startOffset": 193, "endOffset": 205}, {"referenceID": 36, "context": "Indeed, limited prior work has shown improved results for constrained minimization and learning of sub-classes of submodular functions, including symmetric functions [3, 49], concave functions [17, 37, 47], label cost or covering functions [21, 57].", "startOffset": 193, "endOffset": 205}, {"referenceID": 46, "context": "Indeed, limited prior work has shown improved results for constrained minimization and learning of sub-classes of submodular functions, including symmetric functions [3, 49], concave functions [17, 37, 47], label cost or covering functions [21, 57].", "startOffset": 193, "endOffset": 205}, {"referenceID": 20, "context": "Indeed, limited prior work has shown improved results for constrained minimization and learning of sub-classes of submodular functions, including symmetric functions [3, 49], concave functions [17, 37, 47], label cost or covering functions [21, 57].", "startOffset": 240, "endOffset": 248}, {"referenceID": 56, "context": "Indeed, limited prior work has shown improved results for constrained minimization and learning of sub-classes of submodular functions, including symmetric functions [3, 49], concave functions [17, 37, 47], label cost or covering functions [21, 57].", "startOffset": 240, "endOffset": 248}, {"referenceID": 17, "context": "In particular, our quantification tightens the generic, function-independent bounds in [18, 3, 52, 17, 25] for many practically relevant functions.", "startOffset": 87, "endOffset": 106}, {"referenceID": 2, "context": "In particular, our quantification tightens the generic, function-independent bounds in [18, 3, 52, 17, 25] for many practically relevant functions.", "startOffset": 87, "endOffset": 106}, {"referenceID": 51, "context": "In particular, our quantification tightens the generic, function-independent bounds in [18, 3, 52, 17, 25] for many practically relevant functions.", "startOffset": 87, "endOffset": 106}, {"referenceID": 16, "context": "In particular, our quantification tightens the generic, function-independent bounds in [18, 3, 52, 17, 25] for many practically relevant functions.", "startOffset": 87, "endOffset": 106}, {"referenceID": 24, "context": "In particular, our quantification tightens the generic, function-independent bounds in [18, 3, 52, 17, 25] for many practically relevant functions.", "startOffset": 87, "endOffset": 106}, {"referenceID": 6, "context": "Previously, the concept of curvature has been used to tighten bounds for submodular maximization problems [7, 55].", "startOffset": 106, "endOffset": 113}, {"referenceID": 54, "context": "Previously, the concept of curvature has been used to tighten bounds for submodular maximization problems [7, 55].", "startOffset": 106, "endOffset": 113}, {"referenceID": 17, "context": "By quantifying the influence of curvature on other problems, we improve previous bounds in [18, 3, 52, 17, 25] for many functions used in applications.", "startOffset": 91, "endOffset": 110}, {"referenceID": 2, "context": "By quantifying the influence of curvature on other problems, we improve previous bounds in [18, 3, 52, 17, 25] for many functions used in applications.", "startOffset": 91, "endOffset": 110}, {"referenceID": 51, "context": "By quantifying the influence of curvature on other problems, we improve previous bounds in [18, 3, 52, 17, 25] for many functions used in applications.", "startOffset": 91, "endOffset": 110}, {"referenceID": 16, "context": "By quantifying the influence of curvature on other problems, we improve previous bounds in [18, 3, 52, 17, 25] for many functions used in applications.", "startOffset": 91, "endOffset": 110}, {"referenceID": 24, "context": "By quantifying the influence of curvature on other problems, we improve previous bounds in [18, 3, 52, 17, 25] for many functions used in applications.", "startOffset": 91, "endOffset": 110}, {"referenceID": 17, "context": "(Approximation [18]) Given a submodular function f in form of a value oracle, find an approximation f\u0302 (within polynomial time and representable within polynomial space), such that for all X \u2286 V , it holds that f\u0302(X) \u2264 f(X) \u2264 \u03b11(n)f\u0302(X) for a polynomial \u03b11(n).", "startOffset": 15, "endOffset": 19}, {"referenceID": 2, "context": "(PMAC-Learning [3]) Given i.", "startOffset": 15, "endOffset": 18}, {"referenceID": 51, "context": "(Constrained optimization [52, 17, 25, 35]) Minimize a submodular function f over a family C of feasible sets, i.", "startOffset": 26, "endOffset": 42}, {"referenceID": 16, "context": "(Constrained optimization [52, 17, 25, 35]) Minimize a submodular function f over a family C of feasible sets, i.", "startOffset": 26, "endOffset": 42}, {"referenceID": 24, "context": "(Constrained optimization [52, 17, 25, 35]) Minimize a submodular function f over a family C of feasible sets, i.", "startOffset": 26, "endOffset": 42}, {"referenceID": 34, "context": "(Constrained optimization [52, 17, 25, 35]) Minimize a submodular function f over a family C of feasible sets, i.", "startOffset": 26, "endOffset": 42}, {"referenceID": 17, "context": "[18], who approximate any monotone submodular function to within a factor of O( \u221a n log n), with a lower bound of \u03b11(n) = \u03a9( \u221a n/ log n).", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "Building on this result, Balcan and Harvey [3] show how to PMAC-learn a monotone submodular function within a factor of \u03b12(n) = O( \u221a n), and prove a lower bound of \u03a9(n) for the learning problem.", "startOffset": 43, "endOffset": 46}, {"referenceID": 1, "context": "Subsequent work extends these results to sub-additive and fractionally sub-additive functions [2, 1].", "startOffset": 94, "endOffset": 100}, {"referenceID": 0, "context": "Subsequent work extends these results to sub-additive and fractionally sub-additive functions [2, 1].", "startOffset": 94, "endOffset": 100}, {"referenceID": 44, "context": "Better learning results are possible for the subclass of submodular shells [45] and Fourier sparse set functions [50].", "startOffset": 75, "endOffset": 79}, {"referenceID": 49, "context": "Better learning results are possible for the subclass of submodular shells [45] and Fourier sparse set functions [50].", "startOffset": 113, "endOffset": 117}, {"referenceID": 10, "context": "Very recently Devanur et al [11] investigated a related problem of approximating one class of submodular functions with another and they show how many non-monotone submodular functions can be approximated with simple directed graph cuts within a factor of n/4 which is tight.", "startOffset": 28, "endOffset": 32}, {"referenceID": 2, "context": "Both Problems 1 and 2 have numerous applications in algorithmic game theory and economics [3, 18] as well as machine learning [3, 44, 45, 50, 34].", "startOffset": 90, "endOffset": 97}, {"referenceID": 17, "context": "Both Problems 1 and 2 have numerous applications in algorithmic game theory and economics [3, 18] as well as machine learning [3, 44, 45, 50, 34].", "startOffset": 90, "endOffset": 97}, {"referenceID": 2, "context": "Both Problems 1 and 2 have numerous applications in algorithmic game theory and economics [3, 18] as well as machine learning [3, 44, 45, 50, 34].", "startOffset": 126, "endOffset": 145}, {"referenceID": 43, "context": "Both Problems 1 and 2 have numerous applications in algorithmic game theory and economics [3, 18] as well as machine learning [3, 44, 45, 50, 34].", "startOffset": 126, "endOffset": 145}, {"referenceID": 44, "context": "Both Problems 1 and 2 have numerous applications in algorithmic game theory and economics [3, 18] as well as machine learning [3, 44, 45, 50, 34].", "startOffset": 126, "endOffset": 145}, {"referenceID": 49, "context": "Both Problems 1 and 2 have numerous applications in algorithmic game theory and economics [3, 18] as well as machine learning [3, 44, 45, 50, 34].", "startOffset": 126, "endOffset": 145}, {"referenceID": 33, "context": "Both Problems 1 and 2 have numerous applications in algorithmic game theory and economics [3, 18] as well as machine learning [3, 44, 45, 50, 34].", "startOffset": 126, "endOffset": 145}, {"referenceID": 2, "context": "often have diminishing returns and a natural problem is to estimate these functions [3].", "startOffset": 84, "endOffset": 87}, {"referenceID": 43, "context": "Similarly in machine learning, a number of problems involving sensor placement, summarization and others [44, 30] can be modeled through submodular functions.", "startOffset": 105, "endOffset": 113}, {"referenceID": 29, "context": "Similarly in machine learning, a number of problems involving sensor placement, summarization and others [44, 30] can be modeled through submodular functions.", "startOffset": 105, "endOffset": 113}, {"referenceID": 43, "context": "Since this function is submodular [44], a natural application is to learn these functions for summarization tasks.", "startOffset": 34, "endOffset": 38}, {"referenceID": 37, "context": "Constrained submodular minimization arises in applications such as power assignment or transportation problems [38, 39, 56, 32] .", "startOffset": 111, "endOffset": 127}, {"referenceID": 38, "context": "Constrained submodular minimization arises in applications such as power assignment or transportation problems [38, 39, 56, 32] .", "startOffset": 111, "endOffset": 127}, {"referenceID": 55, "context": "Constrained submodular minimization arises in applications such as power assignment or transportation problems [38, 39, 56, 32] .", "startOffset": 111, "endOffset": 127}, {"referenceID": 31, "context": "Constrained submodular minimization arises in applications such as power assignment or transportation problems [38, 39, 56, 32] .", "startOffset": 111, "endOffset": 127}, {"referenceID": 9, "context": "In machine learning, it occurs, for instance, in the form of MAP inference in high-order graphical models [10, 54, 36] or in size-constrained corpus extraction [43].", "startOffset": 106, "endOffset": 118}, {"referenceID": 53, "context": "In machine learning, it occurs, for instance, in the form of MAP inference in high-order graphical models [10, 54, 36] or in size-constrained corpus extraction [43].", "startOffset": 106, "endOffset": 118}, {"referenceID": 35, "context": "In machine learning, it occurs, for instance, in the form of MAP inference in high-order graphical models [10, 54, 36] or in size-constrained corpus extraction [43].", "startOffset": 106, "endOffset": 118}, {"referenceID": 42, "context": "In machine learning, it occurs, for instance, in the form of MAP inference in high-order graphical models [10, 54, 36] or in size-constrained corpus extraction [43].", "startOffset": 160, "endOffset": 164}, {"referenceID": 51, "context": "Recent results show that almost all constraints make it hard to solve the minimization even within a constant factor [52, 16, 35].", "startOffset": 117, "endOffset": 129}, {"referenceID": 15, "context": "Recent results show that almost all constraints make it hard to solve the minimization even within a constant factor [52, 16, 35].", "startOffset": 117, "endOffset": 129}, {"referenceID": 34, "context": "Recent results show that almost all constraints make it hard to solve the minimization even within a constant factor [52, 16, 35].", "startOffset": 117, "endOffset": 129}, {"referenceID": 6, "context": "1 Curvature of a Submodular function A central concept in this work is the total curvature \u03baf of a submodular function f and the curvature \u03baf (S) with respect to a set S \u2286 V , defined as [7, 55] \u03baf = 1\u2212min j\u2208V f(j | V \\ j) f(j) , \u03baf (S) = 1\u2212min j\u2208S f(j|S\\j) f(j) .", "startOffset": 187, "endOffset": 194}, {"referenceID": 54, "context": "1 Curvature of a Submodular function A central concept in this work is the total curvature \u03baf of a submodular function f and the curvature \u03baf (S) with respect to a set S \u2286 V , defined as [7, 55] \u03baf = 1\u2212min j\u2208V f(j | V \\ j) f(j) , \u03baf (S) = 1\u2212min j\u2208S f(j|S\\j) f(j) .", "startOffset": 187, "endOffset": 194}, {"referenceID": 8, "context": "Conceptually, curvature is distinct from the recently proposed submodularity ratio [9] that measures how far a function is from being submodular.", "startOffset": 83, "endOffset": 86}, {"referenceID": 6, "context": ", from (1\u2212 1/e) to 1 \u03baf (1\u2212 e \u2212\u03baf ) for monotone submodular maximization subject to a cardinality constraint [7] or matroid constraints [55], and these results are tight.", "startOffset": 109, "endOffset": 112}, {"referenceID": 54, "context": ", from (1\u2212 1/e) to 1 \u03baf (1\u2212 e \u2212\u03baf ) for monotone submodular maximization subject to a cardinality constraint [7] or matroid constraints [55], and these results are tight.", "startOffset": 136, "endOffset": 140}, {"referenceID": 54, "context": "In fact, [55] showed that this result for submodular maximization holds for the tighter version of curvature \u03ba\u0303f (S \u2217), where S\u2217 is the optimal solution.", "startOffset": 9, "endOffset": 13}, {"referenceID": 54, "context": "In other words, the bound for the greedy algorithm of [55] can be tightened to 1 \u03ba\u0303f (S\u2217) (1\u2212 e \u2212\u03ba\u0303f (S)).", "startOffset": 54, "endOffset": 58}, {"referenceID": 31, "context": "For submodular minimization, learning, and approximation, however, the role of curvature has not yet been addressed (an exception are the upper bounds in [32] for minimization).", "startOffset": 154, "endOffset": 158}, {"referenceID": 31, "context": "By contrast, many practically interesting functions have smaller curvature, and our analysis will provide an explanation for the good empirical results observed with such functions [32, 44, 33].", "startOffset": 181, "endOffset": 193}, {"referenceID": 43, "context": "By contrast, many practically interesting functions have smaller curvature, and our analysis will provide an explanation for the good empirical results observed with such functions [32, 44, 33].", "startOffset": 181, "endOffset": 193}, {"referenceID": 32, "context": "By contrast, many practically interesting functions have smaller curvature, and our analysis will provide an explanation for the good empirical results observed with such functions [32, 44, 33].", "startOffset": 181, "endOffset": 193}, {"referenceID": 43, "context": "An example for functions with \u03baf < 1 is the class of concave over modular functions that have been used in speech processing [44] and computer vision [36].", "startOffset": 125, "endOffset": 129}, {"referenceID": 35, "context": "An example for functions with \u03baf < 1 is the class of concave over modular functions that have been used in speech processing [44] and computer vision [36].", "startOffset": 150, "endOffset": 154}, {"referenceID": 0, "context": "This class comprises, for instance, functions of the form f(X) = \u2211k i=1(wi(X)) , for some a \u2208 [0, 1] and a nonnegative weight vectors wi.", "startOffset": 94, "endOffset": 100}, {"referenceID": 43, "context": "Such functions may be defined over clusters Ci \u2286 V , in which case the weights wi(j) are nonzero only if j \u2208 Ci [44, 36, 30].", "startOffset": 112, "endOffset": 124}, {"referenceID": 35, "context": "Such functions may be defined over clusters Ci \u2286 V , in which case the weights wi(j) are nonzero only if j \u2208 Ci [44, 36, 30].", "startOffset": 112, "endOffset": 124}, {"referenceID": 29, "context": "Such functions may be defined over clusters Ci \u2286 V , in which case the weights wi(j) are nonzero only if j \u2208 Ci [44, 36, 30].", "startOffset": 112, "endOffset": 124}, {"referenceID": 8, "context": "A related quantity distinct from curvature that has been introduced in the machine learning community is the submodularity ratio [9]:", "startOffset": 129, "endOffset": 132}, {"referenceID": 7, "context": "Our curvature-based decomposition is different from decompositions such as that into a totally normalized function and a modular function [8].", "startOffset": 138, "endOffset": 141}, {"referenceID": 15, "context": "Previous informationtheoretic lower bounds for Problems 1\u20133 [16, 18, 25, 52] are independent of curvature and use functions with \u03baf = 1.", "startOffset": 60, "endOffset": 76}, {"referenceID": 17, "context": "Previous informationtheoretic lower bounds for Problems 1\u20133 [16, 18, 25, 52] are independent of curvature and use functions with \u03baf = 1.", "startOffset": 60, "endOffset": 76}, {"referenceID": 24, "context": "Previous informationtheoretic lower bounds for Problems 1\u20133 [16, 18, 25, 52] are independent of curvature and use functions with \u03baf = 1.", "startOffset": 60, "endOffset": 76}, {"referenceID": 51, "context": "Previous informationtheoretic lower bounds for Problems 1\u20133 [16, 18, 25, 52] are independent of curvature and use functions with \u03baf = 1.", "startOffset": 60, "endOffset": 76}, {"referenceID": 17, "context": "The following are some of our main results: for approximating submodular functions (Problem 1), we replace the known bound of \u03b11(n) = O( \u221a n log n) [18] by an improved curvature-dependent O( \u221a n logn 1+( \u221a n logn\u22121)(1\u2212\u03baf ) ).", "startOffset": 148, "endOffset": 152}, {"referenceID": 2, "context": "For learning submodular functions (Problem 2), we refine the known bound of \u03b12(n) = O( \u221a n) [3] in the PMAC setting to a curvature dependent bound of O( \u221a n 1+( \u221a n\u22121)(1\u2212\u03baf ) ), with a lower bound of \u03a9\u0303( n 1/3 1+(n\u22121)(1\u2212\u03baf ) ).", "startOffset": 92, "endOffset": 95}, {"referenceID": 15, "context": "These bounds refine many of the results in [16, 52, 25, 35].", "startOffset": 43, "endOffset": 59}, {"referenceID": 51, "context": "These bounds refine many of the results in [16, 52, 25, 35].", "startOffset": 43, "endOffset": 59}, {"referenceID": 24, "context": "These bounds refine many of the results in [16, 52, 25, 35].", "startOffset": 43, "endOffset": 59}, {"referenceID": 34, "context": "These bounds refine many of the results in [16, 52, 25, 35].", "startOffset": 43, "endOffset": 59}, {"referenceID": 17, "context": "Previous work established \u03b1-approximations g to a submodular function f satisfying g(S) \u2264 f(S) \u2264 \u03b1g(S) for all S \u2286 V [18].", "startOffset": 117, "endOffset": 121}, {"referenceID": 17, "context": "[18] computes an approximation to a polymatroid function f in polynomial time by approximating the submodular polyhedron via an ellipsoid.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "2 ([18]).", "startOffset": 3, "endOffset": 7}, {"referenceID": 17, "context": "The weights w are computed via an ellipsoidal approximation of the submodular polyhedron [18].", "startOffset": 89, "endOffset": 93}, {"referenceID": 17, "context": "To compute f, construct the function f as in Equation (6), and apply the algorithm in [18] to construct the approximation \u221a wf(X) such that \u221a wf(X) \u2264 f(X) \u2264 O( \u221a n log n) \u221a wf(X).", "startOffset": 86, "endOffset": 90}, {"referenceID": 17, "context": "It refines the lower bound in [18] to include \u03baf .", "startOffset": 30, "endOffset": 34}, {"referenceID": 17, "context": "The information-theoretic proof uses a construction and argumentation similar to that in [18, 52], but perturbs the functions to have the desired curvature.", "startOffset": 89, "endOffset": 97}, {"referenceID": 51, "context": "The information-theoretic proof uses a construction and argumentation similar to that in [18, 52], but perturbs the functions to have the desired curvature.", "startOffset": 89, "endOffset": 97}, {"referenceID": 51, "context": "Using a Chernoff bound, one can then show that any algorithm that uses a polynomial number of queries can distinguish h and f \u03ba with probability only n \u2212\u03c9(1), and therefore cannot reliably distinguish the functions with a polynomial number of queries [52].", "startOffset": 251, "endOffset": 255}, {"referenceID": 43, "context": "The improved curvature dependent bounds immediately imply better bounds for the class of concave over modular functions used in [44, 36, 30].", "startOffset": 128, "endOffset": 140}, {"referenceID": 35, "context": "The improved curvature dependent bounds immediately imply better bounds for the class of concave over modular functions used in [44, 36, 30].", "startOffset": 128, "endOffset": 140}, {"referenceID": 29, "context": "The improved curvature dependent bounds immediately imply better bounds for the class of concave over modular functions used in [44, 36, 30].", "startOffset": 128, "endOffset": 140}, {"referenceID": 2, "context": "We next address the problem of learning submodular functions in a PMAC setting [3].", "startOffset": 79, "endOffset": 82}, {"referenceID": 52, "context": "The PMAC (Probably Mostly Approximately Correct) framework is an extension of the PAC framework [53] to allow multiplicative errors in the function values from a fixed but unknown distribution D over 2 .", "startOffset": 96, "endOffset": 100}, {"referenceID": 2, "context": "Balcan and Harvey [3] propose an algorithm that PMAC-learns any monotone, nonnegative submodular function within a factor \u03b1(n) = \u221a n+ 1 by reducing the problem to that of learning a binary classifier.", "startOffset": 18, "endOffset": 21}, {"referenceID": 2, "context": "1 uses the reduction of Balcan and Harvey [3] to learn the \u03baf -curve-normalized version f of f .", "startOffset": 42, "endOffset": 45}, {"referenceID": 2, "context": "The proof of this theorem directly follows from the results in [3] and those from section 3.", "startOffset": 63, "endOffset": 66}, {"referenceID": 2, "context": "The idea is that, we use the PMAC setting and algorithm from [3].", "startOffset": 61, "endOffset": 64}, {"referenceID": 2, "context": "Let f\u0302\u03ba(X) be the function learn from f using the algorithm from [3].", "startOffset": 65, "endOffset": 68}, {"referenceID": 2, "context": "The case for product distributions also follows from very similar lines and the results from [3].", "startOffset": 93, "endOffset": 96}, {"referenceID": 2, "context": "Again, we use the same matroid functions used in [3].", "startOffset": 49, "endOffset": 52}, {"referenceID": 2, "context": "Notice that the construction of [3], provides a family of matroids and a collection of sets B, with |A| = n, such that f(A) = |A|, A \u2208 B and f(A) = \u03b2 = \u03c9(log n), A / \u2208 B.", "startOffset": 32, "endOffset": 35}, {"referenceID": 2, "context": "Again set \u03b2 = n \u2032 , and using a analysis and construction similar to the hardness proof of section 3 and Theorem 9 from [3] conveys that the lower bound for this problem is \u03a9\u0303( n 1/3 1+(n\u22121)(1\u2212\u03baf ) )", "startOffset": 120, "endOffset": 123}, {"referenceID": 2, "context": "To prove this result, we adapt Algorithm 2 in [3] to curvature and modular approximations.", "startOffset": 46, "endOffset": 49}, {"referenceID": 2, "context": "We detail the parts where our proof deviates from [3].", "startOffset": 50, "endOffset": 53}, {"referenceID": 2, "context": "These samples differ slightly from those in [3].", "startOffset": 44, "endOffset": 47}, {"referenceID": 2, "context": "This follows from Claim 5 in [3].", "startOffset": 29, "endOffset": 32}, {"referenceID": 24, "context": "Most algorithms for constrained minimization use one of two strategies: they apply a convex relaxation [25, 35], or they optimize a surrogate function f\u0302 that should approximate f well [16, 18, 35].", "startOffset": 103, "endOffset": 111}, {"referenceID": 34, "context": "Most algorithms for constrained minimization use one of two strategies: they apply a convex relaxation [25, 35], or they optimize a surrogate function f\u0302 that should approximate f well [16, 18, 35].", "startOffset": 103, "endOffset": 111}, {"referenceID": 15, "context": "Most algorithms for constrained minimization use one of two strategies: they apply a convex relaxation [25, 35], or they optimize a surrogate function f\u0302 that should approximate f well [16, 18, 35].", "startOffset": 185, "endOffset": 197}, {"referenceID": 17, "context": "Most algorithms for constrained minimization use one of two strategies: they apply a convex relaxation [25, 35], or they optimize a surrogate function f\u0302 that should approximate f well [16, 18, 35].", "startOffset": 185, "endOffset": 197}, {"referenceID": 34, "context": "Most algorithms for constrained minimization use one of two strategies: they apply a convex relaxation [25, 35], or they optimize a surrogate function f\u0302 that should approximate f well [16, 18, 35].", "startOffset": 185, "endOffset": 197}, {"referenceID": 31, "context": "1 has also been shown in [32].", "startOffset": 25, "endOffset": 29}, {"referenceID": 31, "context": "Similar to the algorithms in [32, 29, 31], MUB can be extended to an iterative algorithm yielding performance gains in practice.", "startOffset": 29, "endOffset": 41}, {"referenceID": 28, "context": "Similar to the algorithms in [32, 29, 31], MUB can be extended to an iterative algorithm yielding performance gains in practice.", "startOffset": 29, "endOffset": 41}, {"referenceID": 30, "context": "Similar to the algorithms in [32, 29, 31], MUB can be extended to an iterative algorithm yielding performance gains in practice.", "startOffset": 29, "endOffset": 41}, {"referenceID": 35, "context": "1 implies improved approximation bounds for practically relevant concave over modular functions, such as those used in [36].", "startOffset": 119, "endOffset": 123}, {"referenceID": 17, "context": "[18], as in Corollary 3.", "startOffset": 0, "endOffset": 4}, {"referenceID": 46, "context": "Minimizing such a function over constraints C is harder than minimizing a merely modular function, but with the algorithm in [47] we obtain an FPTAS for minimizing f\u0302 over C whenever we can minimize a nonnegative linear function over C.", "startOffset": 125, "endOffset": 129}, {"referenceID": 46, "context": "We use the important result from [47] where they show that any function of the form \u03bb1 \u221a m1(X) + \u03bb2m2(X) where \u03bb1 \u2265 0, \u03bb2 \u2265 0 and m1 and m2 are positive modular functions, has a FPTAS, provided a modular function can easily be optimized over C.", "startOffset": 33, "endOffset": 37}, {"referenceID": 51, "context": "Svitkina and Fleischer [52] prove that for monotone submodular functions of arbitrary curvature, it is impossible to find a polynomial-time algorithm with an approximation factor better than \u221a n/ log n.", "startOffset": 23, "endOffset": 27}, {"referenceID": 51, "context": "These bounds are improvements over the results of [52] whenever \u03baf < 1.", "startOffset": 50, "endOffset": 54}, {"referenceID": 15, "context": "[16] show a O(n)-approximation with matching curvature-independent lower bound \u03a9(n).", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "The proof of this follows in very similar lines to the earlier lower bounds using our construction and the matroid constructions in [16].", "startOffset": 132, "endOffset": 136}, {"referenceID": 34, "context": "Minimum submodular s-t cut (SSC): This problem, also known as the cooperative cut problem [35, 36], asks to minimize a monotone submodular function f such that the solution X \u2286 E is a set of edges whose removal disconnects s from t in G.", "startOffset": 90, "endOffset": 98}, {"referenceID": 35, "context": "Minimum submodular s-t cut (SSC): This problem, also known as the cooperative cut problem [35, 36], asks to minimize a monotone submodular function f such that the solution X \u2286 E is a set of edges whose removal disconnects s from t in G.", "startOffset": 90, "endOffset": 98}, {"referenceID": 34, "context": "Using curvature refines the lower bound in [35]:", "startOffset": 43, "endOffset": 47}, {"referenceID": 34, "context": "It uses the construction from [35].", "startOffset": 30, "endOffset": 34}, {"referenceID": 34, "context": "Jegelka and Bilmes [35] demonstrate how this approximation may be optimized via a generalized maximum flow algorithm that maximizes a polymatroidal network flow [40].", "startOffset": 19, "endOffset": 23}, {"referenceID": 39, "context": "Jegelka and Bilmes [35] demonstrate how this approximation may be optimized via a generalized maximum flow algorithm that maximizes a polymatroidal network flow [40].", "startOffset": 161, "endOffset": 165}, {"referenceID": 34, "context": "We use the polymatroidal network flow construction from [35], where the approximation f\u0302 is defined via a partition of the ground set, and is separable over groups of edges.", "startOffset": 56, "endOffset": 60}, {"referenceID": 33, "context": "This approximation can be solved efficiently via generalized flows in polynomial time [34, 35].", "startOffset": 86, "endOffset": 94}, {"referenceID": 34, "context": "This approximation can be solved efficiently via generalized flows in polynomial time [34, 35].", "startOffset": 86, "endOffset": 94}, {"referenceID": 34, "context": "Then let X\u0302 be the minimizer of f\u0302(X) over C (using the generalized flows [35]).", "startOffset": 74, "endOffset": 78}, {"referenceID": 55, "context": "Such constraints occur for example in power assignment problems [56].", "startOffset": 64, "endOffset": 68}, {"referenceID": 15, "context": "[16] show a curvature-independent optimal approximation factor of O(n) for this problem.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "In this case, we use the construction of [16], and define f \u03ba (X) = \u03baf min{|X\u2229R\u0304|+min{|X\u2229R|, \u03b2}, \u03b1}+ (1\u2212 \u03baf )|X|, and gf (X) = \u03bafmin{|X|, \u03b1}+ (1\u2212 \u03baf )|X|, where \u03b1 = n , \u03b2 = n (1 + \u03b4) and |R| = \u03b1.", "startOffset": 41, "endOffset": 45}, {"referenceID": 15, "context": "For the formal graph construction, see [16].", "startOffset": 39, "endOffset": 43}, {"referenceID": 15, "context": "Then with high probability R is connected in the graph [16].", "startOffset": 55, "endOffset": 59}, {"referenceID": 15, "context": "Ana analogous analysis applies to combinatorial constraints like Steiner trees [16].", "startOffset": 79, "endOffset": 83}, {"referenceID": 15, "context": "We use the same submodular functions as the spanning tree case, and it can be shown [16] that with high probability the set R contains a perfect matching and the two functions are indistinguishable.", "startOffset": 84, "endOffset": 88}, {"referenceID": 24, "context": "This problem has been investigated in [25], and they show that this problem is O(n) hard.", "startOffset": 38, "endOffset": 42}, {"referenceID": 24, "context": "We can use the construction of [25] to show this.", "startOffset": 31, "endOffset": 35}, {"referenceID": 6, "context": "These results complement known results for submodular maximization [7, 55].", "startOffset": 67, "endOffset": 74}, {"referenceID": 54, "context": "These results complement known results for submodular maximization [7, 55].", "startOffset": 67, "endOffset": 74}, {"referenceID": 27, "context": "Moreover, in [28], we also consider the role of curvature in submodular optimization problems over a class of submodular constraints.", "startOffset": 13, "endOffset": 17}, {"referenceID": 8, "context": "Given that the functional form and effect of the submodularity ratio proposed in [9] is similar to that of curvature, an interesting extension is the question of whether there is a single unifying quantity for both of these terms.", "startOffset": 81, "endOffset": 84}, {"referenceID": 1, "context": "Another open question is whether a quantity similar to curvature can be defined for subadditive functions, thus refining the results in [2, 1] for learning subadditive functions.", "startOffset": 136, "endOffset": 142}, {"referenceID": 0, "context": "Another open question is whether a quantity similar to curvature can be defined for subadditive functions, thus refining the results in [2, 1] for learning subadditive functions.", "startOffset": 136, "endOffset": 142}, {"referenceID": 33, "context": "Finally it also seems that the techniques in this paper could be used to provide improved curvature-dependent regret bounds for constrained online submodular minimization [34].", "startOffset": 171, "endOffset": 175}], "year": 2013, "abstractText": "We investigate three related and important problems connected to machine learning: approximating a submodular function everywhere, learning a submodular function (in a PAC-like setting [53]), and constrained minimization of submodular functions. We show that the complexity of all three problems depends on the \u201ccurvature\u201d of the submodular function, and provide lower and upper bounds that refine and improve previous results [3, 16, 18, 52]. Our proof techniques are fairly generic. We either use a black-box transformation of the function (for approximation and learning), or a transformation of algorithms to use an appropriate surrogate function (for minimization). Curiously, curvature has been known to influence approximations for submodular maximization [7, 55], but its effect on minimization, approximation and learning has hitherto been open. We complete this picture, and also support our theoretical claims by empirical results.", "creator": "LaTeX with hyperref package"}}}