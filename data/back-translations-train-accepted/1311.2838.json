{"id": "1311.2838", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Nov-2013", "title": "A PAC-Bayesian bound for Lifelong Learning", "abstract": "Lifelong learning focuses on the idea of retaining and reusing the knowledge learned from observed tasks for solving a new but related task. In this work we present a PAC-Bayesian bound on the generalization error in the lifelong learning framework. Our result gives a theoretical justification of how exploring the data from several related tasks makes it possible to automatically learn prior knowledge and how a prior that performs well on sufficiently many tasks guarantees good learning performance on new tasks from the same environment with high probability.", "histories": [["v1", "Tue, 12 Nov 2013 17:05:04 GMT  (10kb)", "https://arxiv.org/abs/1311.2838v1", null], ["v2", "Sat, 10 May 2014 10:45:51 GMT  (448kb,D)", "http://arxiv.org/abs/1311.2838v2", "to appear at ICML 2014"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["anastasia pentina", "christoph h lampert"], "accepted": true, "id": "1311.2838"}, "pdf": {"name": "1311.2838.pdf", "metadata": {"source": "CRF", "title": "A PAC-Bayesian Bound for Lifelong Learning", "authors": ["Anastasia Pentina", "Christoph H. Lampert"], "emails": ["APENTINA@IST.AC.AT", "CHL@IST.AC.AT"], "sections": [{"heading": null, "text": "In this paper, we examine lifelong learning from a theoretical perspective. Our main result is a PAC-Bayesian generalization boundary that provides a unified view of existing paradigms of transfer learning, such as the transfer of parameters or the transfer of low-dimensional representations. We also use this boundary to derive two principle-based algorithms of lifelong learning, and we show that these results are comparable to existing methods."}, {"heading": "1. Introduction", "text": "Most people are able to learn new concepts from only a few examples. Presumably, this difference stems from the fact that most machine learning systems are trained from the ground up for each task, whereas people use the context and knowledge they have previously acquired to solve other tasks. This observation motivates research on transfer learning: How can information from previously learned tasks be used to solve new tasks? Several scenarios for formalizing this question have been identified. Here, we discuss some related to Super-Proceedings of the 31 st International Conference on Machine Learning, China, 2014. JMLR: Copyright 2014 by the author (s).vised Learning assumes that one or more learning tasks have been observed."}, {"heading": "2. PAC-Bayesian Lifelong Learning", "text": "In order to develop a PAC-Bayesian theory of lifelong learning, we adopt the concept of a task environment from Baxter (2000). We assume that a number of possible tasks T, all of which have set the same entrance room X, output room Y, hypothesis, is unpredictable. \"However, the lifelong learning system (which we will call an agent) requires a general task distribution t1,., tn, which is executed by T according to some unknown distributions of tasks. For each task ti, the agent observes a training set Si = {1, yi1),., (ximi, yimi)}, which means that the distribution of the task is unknown. To solve individual tasks, the agent uses an arbitrary but fixed learning algorithm, i.e. a deterministic process that outputs a form of training S and a form of prior knowledge."}, {"heading": "2.1. Parameter Transfer", "text": "Let X-Rd and H be a series of linear predictors: h (x) = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q"}, {"heading": "2.2. Representation Transfer", "text": "A second assumption, usually made in multitask or lifelong learning, is that the weight vectors for all tasks are in the low-dimensional subspace (> Q = > Q = > Q). Theorem 1 also allows us to learn such a subspace in a principal.Again, we assume that X-Rd and H are a series of linear predictors. We represent k-dimensional subspaces of Rd by d \u00b7 k matrices with orthogonal columns, i.e. elements of Boot's manifold Vd, k. As hyperprior, we want all subspaces to be equally probable, so we place P on the uniform distribution over Vd, k (Downs, 1972) pP (B) -M = 1C0 for all B manifold Vd, k (18) where C0 = 0F1 (12d, 0).As hyperposterior, Q, we want to select a distribution that concentrates its probability mass around a specific M., We call a special case pvin-1Q (LD)."}, {"heading": "3. Experiments", "text": "In this section we show how learning priority distributions can improve prediction performance in real prediction tasks by minimizing the boundaries (16), (17) and (21). To position our results in relation to previous work on parameter and representation transfer, we compare adaptive comb regression (ARR), i.e. equation (10) of the previous wpr series to the average of weight vectors from the observed tasks and to the ELLA algorithm (Ruvolo & Eaton, 2013), which learns subspace representation by means of structured thriftiness constraints, even with squared losses. We also report on the results of ordinary comb regression without knowledge transfer. We conduct experiments on three public datasets: Land Mine Detection (Xue et al., 2007) This dataset consists of 14820 asaton data points. For each data point there are 9 features extracted from radar images and classes."}, {"heading": "3.1. Parameter Transfer", "text": "For the classification tasks (landmines and animals), we optimize the limit (16) using the method of conjugation gradient to determine the minimum. In the case of regression tasks (schools), we first divide the labels (exam results) by their maximum value, which allows us to assume that the square loss is no more than 1. We optimize (17), and due to the square loss, the problem has a closed solution: wQ = (D + \u221a nm) + 1\u0445n: m = Id (22) + 1\u0445m: i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i i > i > i i > i i > i i i > i i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i > i"}, {"heading": "3.2. Representation Transfer", "text": "In a second experiment, we implement the idea of representation transfer from Section 2.2 by invoking the algorithm Prior Learning with Langevin hyperprior (PL-L). As in the case of parameter transfer, we use 0 / 1 loss to measure the quality of classification tasks. For the regression task, we apply the same scaling method as in Section 3.1 and use abbreviated square losses. Both loss functions can be limited by the standardized loss upwards, which we do to obtain comprehensible expressions for the right side of the inequality (21). To numerically optimize the expression (21), we approximate it by replacing all expectations about Q with their values in its mode M. In addition, we replace the error of any Gibbs predictor with the error of the deterministic predictor defined by the mode of posterior distribution wi (M). The result is a quadractive optimization problem over the boot mantle (we solve with the help of 2013)."}, {"heading": "3.3. Evaluation procedure", "text": "In order to obtain reliable estimates of the transmission risk, we repeat the following experimental procedure 100 times for each dataset, calculating the mean prediction errors and standard errors of the intermediate time.In each experiment, we leave a subset of tasks unnoticed (9 in landmines, 39 in schools, 9 in animals), which are not used in any part of the training, but only to evaluate the methods for \"future\" tasks. Of the remaining tasks, we use different fractions to measure the effect of a different number of observed tasks. The algorithms described in sections 3.1 and 3.2 and ARR have a free parameter, the regulatory strength C (10 \u2212 3,.., 103).We select this by means of triple cross-validation in the following way. We divide the data of each task into three parts: We use the first third of all tasks jointly to learn a prediction. To evaluate this beforehand, we then train individual predictors on the second part of the data and test their quality on the third part of the ELLA algorithms based on the 3."}, {"heading": "3.4. Results", "text": "The results of the experiments on all three datasets are shown in Figure 1. Since the classes in the landmine dataset are unbalanced, we give the value of the area under the ROC curve (AUC, greater value means better prediction) for this problem. The tasks in the Animals dataset are balanced, so we report the standard mean of 0 / 1 error for them. As the dataset was too large for the subspace methods, we report only the results for the parameter transmission techniques. For the experiment on the Schools dataset, we report the mean square error (MSE, smaller values mean better prediction).As the first observation, Figure 1 confirms the results of previous work that a better prediction can be achieved by transferring information from related tasks. Overall, it shows that PL-G and PL-L are comparable with the existing manually designed techniques."}, {"heading": "4. Conclusion", "text": "In this paper, we examined lifelong learning from a theoretical perspective. Our main result is a generalization that is bound within a PAC-Bayesian framework (Theorem 1). On the one hand, the boundary is very general and allows us to restore two existing principles of transfer-long learning as special cases: the transfer of classification parameters and the transfer of sub-spaces / representations. On the other hand, the boundary consists only of observable quantities, so that principle-based algorithms for lifelong learning can be derived from it that produce results that are comparable to existing manually designed methods.Another use of the boundary we see is to examine the implicit assumptions of possible learning methods.For example, a method that is achieved by means of an unimmodal hyperposterior requires that all tasks are related to each other. In future work, we plan to examine the potential of integrating more realistic assumptions, such as hierarchical or multimodal beneriors, to loosen the second direction.3."}, {"heading": "A. Proof of Lemma 2", "text": "In proof we will use Hoeffding's Lemma: Lemma 3 (Hoeffding, 1963). Let X be a real random variable, so that Pr (X). (A). (A). (D). (D). (F). (E). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (K). (K). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F). (F. (F). (F). (F). (F). (F). (F). (F.). (F. (F). (F. (F). (F. (F). (F).). (F.). (F. (F.).). (F. (F.). (F.). (F. (F.). (F.).). (F. (F.). (F. (F.). (F. (F.). (F.).). (F. (F.). (F.).). (F"}], "references": [{"title": "Convex multi-task feature learning", "author": ["Argyriou", "Andreas", "Evgeniou", "Theodoros", "Pontil", "Massimiliano"], "venue": "Machine Learning,", "citeRegEx": "Argyriou et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Argyriou et al\\.", "year": 2008}, {"title": "Tabula rasa: Model transfer for object category detection", "author": ["Aytar", "Yusuf", "Zisserman", "Andrew"], "venue": "In International Conference on Computer Vision (ICCV),", "citeRegEx": "Aytar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Aytar et al\\.", "year": 2011}, {"title": "A model of inductive bias learning", "author": ["Baxter", "Jonathan"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Baxter and Jonathan.,? \\Q2000\\E", "shortCiteRegEx": "Baxter and Jonathan.", "year": 2000}, {"title": "Curriculum learning", "author": ["Bengio", "Yoshua", "Louradour", "J\u00e9r\u00f4me", "Collobert", "Ronan", "Weston", "Jason"], "venue": "In International Conference on Machine Learing (ICML),", "citeRegEx": "Bengio et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2009}, {"title": "RecNorm: Simultaneous normalisation and classification applied to speech recognition", "author": ["Bridle", "John S", "Cox", "Stephen J"], "venue": "In Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Bridle et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Bridle et al\\.", "year": 1990}, {"title": "Multitask learning", "author": ["Caruana", "Rich"], "venue": "Machine Learning,", "citeRegEx": "Caruana and Rich.,? \\Q1997\\E", "shortCiteRegEx": "Caruana and Rich.", "year": 1997}, {"title": "PAC-Bayesian Supervised Classification (The Thermodynamics of Statistical Learning)", "author": ["Catoni", "Olivier"], "venue": "Monograph Series of the Institute of Mathematical Statistics. IMS,", "citeRegEx": "Catoni and Olivier.,? \\Q2007\\E", "shortCiteRegEx": "Catoni and Olivier.", "year": 2007}, {"title": "Regularized multi\u2013task learning", "author": ["Evgeniou", "Theodoros", "Pontil", "Massimiliano"], "venue": "In International Conference on Knowledge Discovery and Data Mining (SIGKDD),", "citeRegEx": "Evgeniou et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Evgeniou et al\\.", "year": 2004}, {"title": "PAC-Bayesian learning of linear classifiers", "author": ["Germain", "Pascal", "Lacasse", "Alexandre", "Laviolette", "Fran\u00e7ois", "Marchand", "Mario"], "venue": "In International Conference on Machine Learing (ICML),", "citeRegEx": "Germain et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Germain et al\\.", "year": 2009}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["Hoeffding", "Wassily"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Hoeffding and Wassily.,? \\Q1963\\E", "shortCiteRegEx": "Hoeffding and Wassily.", "year": 1963}, {"title": "Learning task grouping and overlap in multi-task learning", "author": ["Kumar", "Abhishek", "Daum\u00e9 III", "Hal"], "venue": "In International Conference on Machine Learing (ICML),", "citeRegEx": "Kumar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2012}, {"title": "Attribute-based classification for zero-shot visual object categorization", "author": ["Lampert", "Christoph H", "Nickisch", "Hannes", "Harmeling", "Stefan"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI),", "citeRegEx": "Lampert et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lampert et al\\.", "year": 2013}, {"title": "Tutorial on practical prediction theory for classification", "author": ["Langford", "John"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Langford and John.,? \\Q2005\\E", "shortCiteRegEx": "Langford and John.", "year": 2005}, {"title": "PAC-Bayes and margins", "author": ["Langford", "John", "Shawe-Taylor"], "venue": "In Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "Langford et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Langford et al\\.", "year": 2002}, {"title": "PAC-Bayes risk bounds for stochastic averages and majority votes of sample-compressed classifiers", "author": ["Laviolette", "Fran\u00e7ois", "Marchand", "Mario"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Laviolette et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Laviolette et al\\.", "year": 2007}, {"title": "Transfer bounds for linear feature learning", "author": ["Maurer", "Andreas"], "venue": "Machine Learning,", "citeRegEx": "Maurer and Andreas.,? \\Q2009\\E", "shortCiteRegEx": "Maurer and Andreas.", "year": 2009}, {"title": "Sparse coding for multitask and transfer learning", "author": ["Maurer", "Andreas", "Pontil", "Massimiliano", "RomeraParedes", "Bernardino"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Maurer et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Maurer et al\\.", "year": 2013}, {"title": "PAC-Bayesian model averaging", "author": ["McAllester", "David"], "venue": "In Workshop on Computational Learning Theory (COLT),", "citeRegEx": "McAllester and David.,? \\Q1999\\E", "shortCiteRegEx": "McAllester and David.", "year": 1999}, {"title": "Simplified PAC-Bayesian margin bounds", "author": ["McAllester", "David"], "venue": "In Learning Theory and Kernel Machines,", "citeRegEx": "McAllester and David.,? \\Q2003\\E", "shortCiteRegEx": "McAllester and David.", "year": 2003}, {"title": "PAC-Bayes bounds with data dependent priors", "author": ["Parrado-Hern\u00e1ndez", "Emilio", "Ambroladze", "Amiran", "ShaweTaylor", "John", "Sun", "Shiliang"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Parrado.Hern\u00e1ndez et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Parrado.Hern\u00e1ndez et al\\.", "year": 2012}, {"title": "ELLA: An efficient lifelong learning algorithm", "author": ["Ruvolo", "Paul", "Eaton", "Eric"], "venue": "In International Conference on Machine Learing (ICML),", "citeRegEx": "Ruvolo et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ruvolo et al\\.", "year": 2013}, {"title": "Bayesian Gaussian Process Models: PAC-Bayesian Generalization Error Bounds and Sparse Approximations", "author": ["Seeger", "Matthias W"], "venue": "PhD thesis, University of Edinburgh,", "citeRegEx": "Seeger and W.,? \\Q2003\\E", "shortCiteRegEx": "Seeger and W.", "year": 2003}, {"title": "Lifelong robot learning", "author": ["Thrun", "Sebastian", "Mitchell", "Tom M"], "venue": "Robotics and autonomous systems,", "citeRegEx": "Thrun et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Thrun et al\\.", "year": 1995}, {"title": "A feasible method for optimization with orthogonality constraints", "author": ["Wen", "Zaiwen", "Yin", "Wotao"], "venue": "Mathematical Programming,", "citeRegEx": "Wen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2013}, {"title": "Multi-task learning for classification with Dirichlet process priors", "author": ["Xue", "Ya", "Liao", "Xuejun", "Carin", "Lawrence", "Krishnapuram", "Balaji"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Xue et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2007}, {"title": "Cross-domain video concept detection using adaptive SVMs", "author": ["Yang", "Jun", "Yan", "Rong", "Hauptmann", "Alexander G"], "venue": "In International Conference on Multimedia,", "citeRegEx": "Yang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 16, "context": "However, except for a few exception, such as (Maurer, 2009; Maurer et al., 2013), their theoretical justifications are so far not well understood.", "startOffset": 45, "endOffset": 80}, {"referenceID": 25, "context": "2 we demonstrate this process in two cases: assuming that the solutions to all tasks can be represented by a single parameter vector plus small task-specific perturbation (Evgeniou & Pontil, 2004), we obtain an algorithm that resembles previously proposed methods for regularizing the weight vectors of future tasks using linear combinations of weight vectors of previous tasks, such as (Yang et al., 2007; Aytar & Zisserman, 2011).", "startOffset": 387, "endOffset": 431}, {"referenceID": 0, "context": "(Argyriou et al., 2008; Kumar & Daum\u00e9 III, 2012), which have also successfully been applied in the lifelong learning setting (Ruvolo & Eaton, 2013).", "startOffset": 0, "endOffset": 48}, {"referenceID": 16, "context": "Similar results were obtained in (Maurer et al., 2013) in the case of sparsity constraints.", "startOffset": 33, "endOffset": 54}, {"referenceID": 0, "context": "(Argyriou et al., 2008; Kumar & Daum\u00e9 III, 2012), which have also successfully been applied in the lifelong learning setting (Ruvolo & Eaton, 2013). In a case of linear regression, Maurer (2009) used this assumption to prove a generalization bound in the PAC framework, by using the concept of environment of tasks from Baxter (2000) and Rademacher complexity.", "startOffset": 1, "endOffset": 195}, {"referenceID": 0, "context": "(Argyriou et al., 2008; Kumar & Daum\u00e9 III, 2012), which have also successfully been applied in the lifelong learning setting (Ruvolo & Eaton, 2013). In a case of linear regression, Maurer (2009) used this assumption to prove a generalization bound in the PAC framework, by using the concept of environment of tasks from Baxter (2000) and Rademacher complexity.", "startOffset": 1, "endOffset": 334}, {"referenceID": 19, "context": "Parrado-Hern\u00e1ndez et al. (2012) showed that priors can be learned by splitting the available training data into two parts, one for learning a prior, one for learning the predictor.", "startOffset": 0, "endOffset": 32}, {"referenceID": 25, "context": "It can be captured by regularizing the distance to this vector (Aytar & Zisserman, 2011; Yang et al., 2007):", "startOffset": 63, "endOffset": 107}, {"referenceID": 8, "context": "In this case the expected empirical error of the Gibbs classifier is given by the following expression (Germain et al., 2009; Langford & Shawe-Taylor, 2002)", "startOffset": 103, "endOffset": 156}, {"referenceID": 24, "context": "Land Mine Detection (Xue et al., 2007).", "startOffset": 20, "endOffset": 38}, {"referenceID": 0, "context": "We use the same procedure as in (Argyriou et al., 2008; Kumar & Daum\u00e9 III, 2012; Ruvolo & Eaton, 2013) to encode them in a set of binary features.", "startOffset": 32, "endOffset": 102}, {"referenceID": 11, "context": "Animals with Attributes Dataset (Lampert et al., 2013).", "startOffset": 32, "endOffset": 54}, {"referenceID": 3, "context": "into the direction of learning tasks of continuously improving difficulty (Bengio et al., 2009).", "startOffset": 74, "endOffset": 95}], "year": 2014, "abstractText": "Transfer learning has received a lot of attention in the machine learning community over the last years, and several effective algorithms have been developed. However, relatively little is known about their theoretical properties, especially in the setting of lifelong learning, where the goal is to transfer information to tasks for which no data have been observed so far. In this work we study lifelong learning from a theoretical perspective. Our main result is a PAC-Bayesian generalization bound that offers a unified view on existing paradigms for transfer learning, such as the transfer of parameters or the transfer of low-dimensional representations. We also use the bound to derive two principled lifelong learning algorithms, and we show that these yield results comparable with existing methods.", "creator": "LaTeX with hyperref package"}}}