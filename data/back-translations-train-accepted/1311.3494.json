{"id": "1311.3494", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Nov-2013", "title": "Fundamental Limits of Online and Distributed Algorithms for Statistical Learning and Estimation", "abstract": "Many machine learning approaches are characterized by information constraints on how they interact with the training data. These include memory and sequential access constraints (e.g. fast first-order methods to solve stochastic optimization problems); communication constraints (e.g. distributed learning); partial access to the underlying data (e.g. missing features and multi-armed bandits) and more. However, currently we have little understanding how such information constraints fundamentally affect our performance, independent of the learning problem semantics. For example, are there learning problems where \\emph{any} algorithm which has small memory footprint (or can use any bounded number of bits from each example, or has certain communication constraints) will perform worse than what is possible without such constraints? In this paper, we describe how a single set of results implies positive answers to the above, for a variety of settings.", "histories": [["v1", "Thu, 14 Nov 2013 13:21:15 GMT  (139kb,D)", "http://arxiv.org/abs/1311.3494v1", null], ["v2", "Wed, 5 Feb 2014 14:55:06 GMT  (139kb,D)", "http://arxiv.org/abs/1311.3494v2", null], ["v3", "Thu, 6 Feb 2014 06:23:28 GMT  (139kb,D)", "http://arxiv.org/abs/1311.3494v3", null], ["v4", "Tue, 6 May 2014 10:56:31 GMT  (139kb,D)", "http://arxiv.org/abs/1311.3494v4", "New and improved results compared to previous version"], ["v5", "Wed, 21 May 2014 18:35:13 GMT  (139kb,D)", "http://arxiv.org/abs/1311.3494v5", null], ["v6", "Tue, 28 Oct 2014 13:25:09 GMT  (139kb,D)", "http://arxiv.org/abs/1311.3494v6", "Full version of NIPS 2014 paper"]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["ohad shamir"], "accepted": true, "id": "1311.3494"}, "pdf": {"name": "1311.3494.pdf", "metadata": {"source": "CRF", "title": "Fundamental Limits of Online and Distributed Algorithms for Statistical Learning and Estimation", "authors": ["Ohad Shamir"], "emails": ["ohad.shamir@weizmann.ac.il"], "sections": [{"heading": "1 Introduction", "text": "This year, as never before in the history of a country in which it is a country, in which it is a country, in which it is not a country, but a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which"}, {"heading": "Related Work", "text": "In this context, it should be noted that the case concerns a case involving a person who was born in another country, a person who was born in another country, who was born in another country."}, {"heading": "2 Information-Constrained Protocols", "text": "\"It's as if he's in a position to put himself at the top,\" he says."}, {"heading": "3 Main Results", "text": "All our results are based on a simple \"hide-and-seek\" statistical estimation problem, for which we show a large gap between the achievable performance of (b, n, m) protocols and limitless protocols. However, in the next section we will show how some known learning and statistical estimation tasks can be reduced to these simple problems. We will look at two variants of this problem, with different application areas. We will look at the number of distributions {PrJ (\u00b7)} dJ = 1 over {\u2212 1} d defined as PrJ (x) = 2 \u2212 d + 1 (1 + 2 + 2).Given an i.e. examples of instances (\u00b7) in which J is unknown, PrJ (\u00b7)."}, {"heading": "4 Applications", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Online Learning with Partial Information", "text": "Consider the default setting of multi-armed bandits, defined as a game over T rounds in which each round selects a loss vector 't (0, 1) d, and the learner (without knowing' t) has to select an action jt from a fixed set {1,.., d} after which the learner suffers loss' t (jt). The goal of the learner is to minimize regret afterwards to the best fixed action, \u2211 T = 1 't (jt) \u2212 minj' t (j). Crucially, the learner never gets to see 't (jt), but only' t (jt). The following theorem is a simple sequence of Thm. 1, and we sketch the evidence in Appendix D.1Theorem 4. We provide the protocol (d) for each algorithm that looks at only b bits of each loss vector, there is a distribution over loss vectors."}, {"heading": "4.2 Sparse PCA and Sparse Covariance Estimation", "text": "The sparse PCA problem [45] is defined as follows: We are usually given a sample of the vectors x-J = j = j, and we assume that there is any direction corresponding to any sparse vector v (cardinality at most k), so that the variance E [(v > x) 2] along this direction is greater than in any other direction. Our goal is to find this direction. We will focus here on a simple variant of this problem, where the maximum direction v is assumed to be 2-sparse, i.e. there are only 2 non-zero coordinates vi, vj. In this case, E [(v > x) 2] = v21E [x21] + v22E [x22] + 2v1v2E [xixj]."}, {"heading": "Then the following holds:", "text": "\u2022 Leave (I, J) = arg max (i, j) | x (I, J) for each distribution Pr (I, J) = (I, J) \u2265 1 \u2212 s2 exp (\u2212 c / 3) \u2022 For each estimate (I, J) of (I, J) returned by any bounded memory protocol (b, n, m), there is a distribution such as Pr (I, J) = (I, J) \u2264 1 protocol (s2 \u2212 s) \u2212 1 + O (cb s2).The evidence appears in Appendix D.2. Intuitively, it uses a reduction of the sparse PCA problem to the setting considered in Thm. 3. For a reasonably large constant c, the theorem implies that a simple constraint-free protocol will most likely succeed in detecting (I, J), while any bounce memory (b, m) protocol problem fails with high probability."}, {"heading": "4.3 Stochastic Optimization", "text": "This means that the detection (I, J) allows us to make zero errors for this optimization problem. (I, J) This means that the detection (I, J) allows us to make zero errors for this optimization problem. (I, J) This means that the detection (I, J) allows us to make zero errors for this optimization problem. (I, J) This means that the detection (I, J) allows us to make zero errors for this optimization problem. (I, J) It means that the detection (I, J) allows us to make zero errors for this optimization problem. (I, J) It means that the detection (I, J) allows us to make zero errors for this optimization problem. (I, J) It means that the detection (I, J) allows us to make zero errors for this optimization problem. (I, J) It means that the detection (I, J) allows us to make zero errors for this optimization problem."}, {"heading": "6 Discussion and Open Questions", "text": "In this paper, we examined cases where a generic type of information-based algorithm has strictly inferior statistical performance compared to limitless algorithms. As special cases, we identified such gaps for top-notch online and distributed optimization algorithms (e.g. in the context of sparse PCA and covariance estimates) and deduced regrets for lower limits for online learning with partial information, depending on the number of bits received in each round. We believe these results represent a first step in a broader understanding of how information constraints affect learning ability in a statistical setting. There are several immediate questions that remain open. One question is whether our limits on (b, n, m) protocols in Thm. 1 (and its generalized counterpart in Thm. 6) can be improved. We suspect that this is true, and that the limit may be as good as those for memory-limited protocols in Thm."}, {"heading": "A Proof of Thm. 6", "text": "The proof in this section requires an additional notation: \u2022 Let Xkj denote the vector of the values of the j-th coordinate in Xk (the n instances given to the (b, n, m) protocol in iteration k). \u2022 To simplify the representation, we use the notation and use the same letter to denote both a random variable and its possible values. For example, the notation \u2211 XkJ denotes a sum of total possible instances of XkJ. \u2022 We use E0, H0 and I0 to denote expectations, entropy and mutual information related to the probability measurement Pr0 (\u00b7). Furthermore, the proof requires the use of several standard quantities and results from information theory - see Appendix E for more details."}, {"heading": "A.1 Technical Lemmas", "text": "1. For each common distribution p (w, j) and distribution q (w) applies that Ej \u0445 pDkl (p (w | j) | | p (w)) \u2264 Ej \u0445 pDkl (p (w | j) | | q (w))"}, {"heading": "Proof.", "text": "Ej-pDkl (p) | p (w) | j (w) | q (w) = > Q = > Q (w), j) log p (w), j) q (w) = xi (w, j) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (w) p (p) p (p) p (w) p (p) p (p) p (p) p (w) p (p) p (w) p (p) p (p) p (p) p (p) p (p) p (p) p (p) p (p) p) p (p) p (p) p (p) p) p (p) p (p) p (p) p p (w) p (p) p (p) p (p) p (p) p (p) p (p) p (p) p p (w) p (p) p (p p p (p) p (p) p (p) p (w) p (p p) p (p (p) p (p) p (w) p (p (p) p (p p (w) p (p (p) p p (p p p p) p (w) p (p (p) p) p (w) p p (p (p p p) p (w) p (p p (p) p (p p p p (p) p p p p (w) p p (p) p (p) p p p (p p p (p) p p p (w) p (p) p p p p (p) p (p) p (p) p (p) p p p p (p p p (p) p) p p p (p p p p p p (w) p (p) p (p) p (p p) p p p p p p p p (p p"}, {"heading": "A.2 A Key Lemma", "text": "The following key quandary quantifies how the message W \u2212 p = J = J = J = J = J (Xk1,..., X k \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p"}, {"heading": "A.3 Proof of Thm. 6", "text": "Let us now turn to the theorem itself. - The overall strategy is as follows: We consider a randomized setting in which J (J = J = J = J = J = J = J = J = J = J = J (J = J = J = J = J = J = J = J = J = J = J = J = J = J (J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J = J ="}, {"heading": "B Proof of Thm. 7", "text": "As discussed in the text following the theorem statement, the crucial observation is that each bounded memory protocol (b, n, m) is a bounded memory protocol (b, n, m) for each positive integer value. (b, n, m) The boundary in Thm. 6 will improve with increasing probability, so we will select it as the largest possible value, so that Thm. 6 still applies. (b, m, m, m, m, m, m, m). Note that this choice is actually valid: Assuming 3 in our theorem statement, 3n applies. (b, m, b, m)."}, {"heading": "C Proofs of Main Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C.1 Proof of Thm. 1", "text": "The proof for the lower limit follows by applying Thm. \u2212 6 to the distribution we are looking at. We will use the reference distribution Pr0 (\u00b7) which is uniform over {\u2212 1, + 1}. \u2212 We must check whether all the conditions of Thm. 6 are met. \u2212 Condition 1 is easy to check: \u2022 Calculation \u03b2: Pr0 (\u00b7) is a uniform distribution of the other coordinates under PrJ (\u00b7) and Pr0 (\u00b7). \u2212 Regarding the other conditions we must check what values of \u03b2, \u03b3, \u00b52 they would meet: \u2022 Calculation \u03b2: Pr0 (\u00b7) is a uniform distribution over {\u2212 1, + 1} d, so we must have the ability dJ = 1H 0 (xJ) = H 0 (x) and we can take the calculation of \u03b2 = 0 (x). \u2212 Calculation \u03b3 = 1, because Pr0 (xJ) = 1 / 2 for all xJ."}, {"heading": "C.2 Proof of Thm. 2", "text": "Theorem. Consider the hide-and-seek problem 1. Suppose that for any parameter c (2dmnb) and assumption (2dmnb) \u2264 1 36 loge (2dmn b), 2 \u2264 36 loge (2dmnb) c \u2264 mThen for each estimate J (b, n, m) protocol there is any J (J = J) \u2264 1log (d) + loge (2dmnb) 324cbd. However, if mn samples are the coordinate with the highest empirical average (b, n, m), then there are some J (J = J) \u2264 1 \u2212 2d exp (\u2212 12c).Proof. The proof of the upper limit is identical to that in Thm."}, {"heading": "C.3 Proof of Thm. 3", "text": "First, we will render the theorem in a more precise way, without asymptotic notation. Theorem. Suppose \u03c1 = \u221a cd / mn for some parameters c - \u2212 \u2212 log (2dmn log (2d) b + 2) b + 2) \u2265 2, \u221a cdmn \u2264 136 loge (2dmn log (2d) b + 2 log (2dmn log (2d) b + 2) c \u2264 mThen for each estimate J returned from any limited memory (b, n, m) protocol (2dmn log (2d) b) there are some J like thatPrJ (J)."}, {"heading": "D Proof of Results from Sec. 4", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "D.1 Proof of Thm. 4", "text": "Consider the set of distributions PrJ (\u00b7) over {0, 1} d, where each coordinate is chosen independently and uniformly, with the exception of coordinate J, which with probability is 12 + \u03c1 equal to 0, \u03c1 = \u221a min {1 54, 1 27 loge (2d / b)} = 1). It is clear that the coordinate j, which minimizes E ['t (j), is j = J. More on this: If the learner in turn t chooses some jt 6 = J, then E ['t (jt) \u2212' t (J) = 0 [[t (J)] = 0 [t (J)]. Thus, to E [\u2211 T = 1 't (jt) \u2212 \u2211 T = 1' t (J)] < T (for some smaller ones) requires that the expected number of rounds in which jt 6 = J (J)] is at most T. Due to Markov's inequality, this means that the probability that J is not the most frequently chosen coordinate, at most 2 b."}, {"heading": "D.2 Proof of Thm. 5", "text": "The upper limit results from the concentration of the measurement assumptions on x-ixj, and a composite limit, which implies that Pr (i < j, | x-ixj \u2212 E [xixj] | \u2264 \u03c42) \u2265 1 \u2212 s (s-1) exp (\u2212 c3) \u2265 1 \u2212 s2 exp (\u2212 c3). If this event occurs, then the selection (I, J) of the coordinates with the greatest empirical mean is actually successful in capturing (I, J), since | E [xIxJ] | E [xixJ] | E [xixj] applies to all (i, j) 6 = (I, J).The lower limit is based on a reduction in Thm. 3. Specifically, we leave PrI, J () (for the coordinates I < J) a distribution over which we have."}, {"heading": "E Basic Results in Information Theory", "text": "The detection of Thm. 6 makes extensive use of quantities and basic results from information theory. Here, we briefly review the technical results (= | | | | a more complete introduction can be found in [22]. Following the settings considered in the paper, we will focus only on discrete distributions that take values on a finite level. A random variable X takes values in a domain X and has a distribution function p (\u00b7). Intuitively, this quantity measures uncertainty at the value of X \u2212 \u2212 consequently, we can extend its entropy as Xi (or more) x x p (x) log2 (1 / p (x)) = EX log (1 / p (x)).Intuitively, this quantity measures uncertainty at the value of X. This definition can be extended to the common entropy of two (or more) random variables, e.g. H (X) Y = x, y (x) p."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "<lb>Many machine learning approaches are characterized by information constraints on how<lb>they interact with the training data. These include memory and sequential access constraints<lb>(e.g. fast first-order methods to solve stochastic optimization problems); communication con-<lb>straints (e.g. distributed learning); partial access to the underlying data (e.g. missing features<lb>and multi-armed bandits) and more. However, currently we have little understanding how such<lb>information constraints fundamentally affect our performance, independent of the learning prob-<lb>lem semantics. For example, are there learning problems where any algorithm which has small<lb>memory footprint (or can use any bounded number of bits from each example, or has certain<lb>communication constraints) will perform worse than what is possible without such constraints?<lb>In this paper, we describe how a single set of results implies positive answers to the above, for<lb>a variety of settings.", "creator": "LaTeX with hyperref package"}}}