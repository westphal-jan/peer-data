{"id": "1311.4825", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2013", "title": "Gaussian Process Optimization with Mutual Information", "abstract": "In this paper, we analyze a generic algorithm scheme for sequential global optimization using Gaussian processes. The upper bounds we derive on the cumulative regret for this generic algorithm improve by an exponential factor the previously known bounds for algorithms like GP-UCB. We also introduce the novel Gaussian Process Mutual Information algorithm (GP-MI), which significantly improves further these upper bounds for the cumulative regret. We confirm the efficiency of this algorithm on synthetic and real tasks against the natural competitor, GP-UCB, and also the Expected Improvement heuristic.", "histories": [["v1", "Tue, 19 Nov 2013 18:29:19 GMT  (888kb,D)", "https://arxiv.org/abs/1311.4825v1", null], ["v2", "Tue, 20 May 2014 18:25:19 GMT  (888kb,D)", "http://arxiv.org/abs/1311.4825v2", "Proceedings of The 31st International Conference on Machine Learning (ICML 2014)"], ["v3", "Mon, 8 Jun 2015 13:27:19 GMT  (889kb,D)", "http://arxiv.org/abs/1311.4825v3", "Proceedings of The 31st International Conference on Machine Learning (ICML 2014)"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["emile contal", "vianney perchet", "nicolas vayatis"], "accepted": true, "id": "1311.4825"}, "pdf": {"name": "1311.4825.pdf", "metadata": {"source": "CRF", "title": "Gaussian Process Optimization with Mutual Information", "authors": ["Emile Contal", "Vianney Perchet", "Nicolas Vayatis"], "emails": [], "sections": [{"heading": null, "text": "Preprint for the 31st International Conference on Machine Learning (ICML 2014) ar Xiv: 131 1,48 25v3 [st at.M LErratum] After the publication of our article, we found an error in the proof of Lemma 1, which invalidates the main law. It seems that the information given to the algorithm is not sufficient for the main law to be true. Theoretical guarantees would remain valid in an environment in which the algorithm observes instant regret instead of noisy samples of the unknown function. On this page, we describe the error and its consequences. Let f: X \u2192 R be the unknown function that needs to be optimized, which is a sample from a Gaussian process. Let us fix it x?, x1,. Let us fix it. X and the observations yt = f (xt) + t, where the sound variables are not independent of Gaussian noise N (0, Manfred 2). Let us define the inous regret."}, {"heading": "1 Introduction", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to think, to move, to move, to think, to move, to move, to think, to move, to move, to think, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "2.1 Sequential optimization and cumulative regret", "text": "Let f: X \u2192 R, where X-Rd is a compact and convex set, be the unknown function that models the system we want to optimize. We will consider the problem of finding the maximum of f by: f (x?) = maxx-X-f (x) by successive queries x1, x2,..."}, {"heading": "2.2 The Gaussian process framework", "text": "To control the smoothness of the underlying function, we assume that f is sampled from a Gaussian process, GP (m, k) with an intermediate function m: X \u2192 R and core function k: X \u00b7 X \u2192 R +. Thus, we formalize the previous assumption that high local variations of f have a low probability; the previous intermediate function is considered zero without loss of generality, since the kernel k can fully define GP Rasmussen & Williams [2006]; we consider the standardized and dimensionless framework T introduced by Srinivas et al. [2010], where the variance is assumed to be limited, i.e. k (x, x) \u2212 1 for all x \u2212 X \u2212 Bayesian inference. For the iteration T + 1, given the previously observed sounds YT at locations XT, we use Bayesian inference to calculate the current posterior distribution Rasmussen & Williams [2006], which is a GP of averages of + 1 and YT (a T)."}, {"heading": "2.3 The Gaussian Process Mutual Information algorithm", "text": "A new algorithm. The Gau\u00dfsche process Mutual information algorithm (GP-MI) is presented as algorithm 1. The key statement is the choice of the query, xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"}, {"heading": "3 Main Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Generic Optimization Scheme", "text": "We will first look at the generic optimization scheme defined in Algorithm 2, where we have considered it a generic function (= 1). We will first look at the generic optimization scheme defined in Algorithm 2, where we have considered it a generic function (= 1). We only need a protocol to be measurable with respect to Yt \u2212 1, the observations made in iteration t \u2212 1. Theoretical analysis of Algorithm 2 can then be used as a plug-in theorem for existing algorithms. Example: Generic analysis of Algorithm 2 leads to the following upper limits on cumulative regret with high probability. Theorem 1 (Regret Bounds for the generic algorithm) will then be obtained with iteration t (x) = a\u03b2t\u03c32t (x). Generic analysis of Algorithm 2 will lead to the following upper limits on cumulative regret with high probability. Theorem 1 (Regret Bounds for the generic algorithm) will then be obtained with iteration t (x) = a\u03b2t\u03c32t (x). A generic analysis of Algorithm 2 will lead to the following upper limits on cumulative regret with high probability. Theorem 1 (Regret Bounds for the generic algorithm for the generic algorithm > 0) will be distributed to all of the algorithm > T and it is caused by RT."}, {"heading": "4 Theoretical analysis", "text": "In this section, we provide the evidence for theorem 1 and theorem 2. The approach presented here to examine the cumulative regret generated by Gaussian strategies for process optimization is general and can be further applied to other algorithms."}, {"heading": "4.1 Analysis of the general algorithm", "text": "The theoretical analysis of Theorem 1 uses a similar approach to the Azuma-Hoeffding inequality = > Gaussian processes. Let rt = f (x?) \u2212 f (xt) for all t \u2264 T. We define MT, which is later defined as martyrdom in relation to YT \u2212 1, MT = T \u2211 t = 1 \"rt \u2212 p\u00b5t (x?) \u2212 p (4) for T \u2264 1 and M0 = 0. Let Yt be defined as martyrdom difference in relation to MT, which is the difference between instantaneous repentance and the gap between the posterior mean for the optimum and the one queried point, Yt = Mt \u2212 1 = rt \u2212 p\u00b5t (x?) \u2212 t (x?) \u2212 \u00b5t (xt) q for t 1.Lemma 1. The sequence MT is a martyrdom in relation to YT \u2212 1 and all queried."}, {"heading": "5 Practical considerations and experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Numerical experiments", "text": "We compare the empirical performance of our algorithm against the state of GP optimization, the GP-UCB algorithm Srinivas et al. [2012], and a generally applied heuristics, the Expected Improvement (EI) algorithm, with GP Jones et al. [1998]. The tasks used for the evaluation stem from two real applications and five synthetic problems described here. For all data sets and algorithms, the learners were initialized with a random subset of 10 observations {(xi, yi)} i \u2264 10. If the prior distribution of the underlying function is not known, the Bayesian inference was made using a quared exponential kernel. We first selected half of the data to estimate the hyperparameters of the kernel via cross-validation in this subset. Thus, each algorithm ran with the same prior information."}, {"heading": "5.2 Practical aspects", "text": "The guarantees we demonstrate in Section 4.2 on the cumulative regret for the GP-MI algorithm are likely to apply to at least 1 \u2212 \u03b4. Since \u03b1 increases linearly as it decreases exponentially towards 0, the algorithm for choosing \u03b4 is robust. In Figure 4, we present the low impact of the average regret for four different values selected over a wide range. Numerical complexity. Even if the numerical costs of the GP-MI are in practice insignificant compared to the cost of evaluating f, the complexity of the Bayesian sequential update is Osborne [2010] O (T 2) and could be prohibitive for large T. One can drastically reduce the computing time by building Desautel's variance calculation al. [2012] on the fact that T is used for all approximate MMC egorithms."}, {"heading": "6 Conclusion", "text": "We introduced the GP-MI algorithm for GP optimization and demonstrated that its cumulative repentance, which exponentially improves the state of the art in common environments, has upper limits; the theoretical analysis was presented in a generic framework to extend its impact to other similar algorithms; the experiments we conducted with real and synthetic assessments empirically confirmed the efficiency of our algorithm over both the theoretical state of GP optimization, the GP-UCB algorithm, and the commonly used EI heuristics."}, {"heading": "Acknowledgements", "text": "The authors thank David Buffoni and Raffael Bonaque for fruitful discussions and the anonymous reviewers of the 31st International Conference on Machine Learning for their detailed feedback."}], "references": [{"title": "Bandit view on noisy optimization. In Optimization for Machine Learning, pp. 431\u2013454", "author": ["Audibert", "J-Y", "S. Bubeck", "R. Munos"], "venue": null, "citeRegEx": "Audibert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2011}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "P. Fischer"], "venue": "Machine Learning,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Exponential inequalities for self-normalized martingales with applications", "author": ["B. Bercu", "A. Touati"], "venue": "The Annals of Applied Probability,", "citeRegEx": "Bercu and Touati,? \\Q2008\\E", "shortCiteRegEx": "Bercu and Touati", "year": 2008}, {"title": "Upperconfidence-bound algorithms for active learning in multi-armed bandits", "author": ["A. Carpentier", "A. Lazaric", "M. Ghavamzadeh", "R. Munos", "P. Auer"], "venue": "In Proceedings of the International Conference on Algorithmic Learning Theory,", "citeRegEx": "Carpentier et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Carpentier et al\\.", "year": 2011}, {"title": "Near-optimal batch mode active learning and adaptive submodular optimization", "author": ["Y. Chen", "A. Krause"], "venue": "In Proceedings of the International Conference on Machine Learning. icml.cc / Omnipress,", "citeRegEx": "Chen and Krause,? \\Q2013\\E", "shortCiteRegEx": "Chen and Krause", "year": 2013}, {"title": "Parallel Gaussian process optimization with upper confidence bound and pure exploration", "author": ["E. Contal", "D. Buffoni", "A. Robicquet", "N. Vayatis"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Contal et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Contal et al\\.", "year": 2013}, {"title": "Stochastic linear optimization under bandit feedback", "author": ["V. Dani", "T.P. Hayes", "S.M. Kakade"], "venue": "In Proceedings of the 21st Annual Conference on Learning Theory, pp", "citeRegEx": "Dani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dani et al\\.", "year": 2008}, {"title": "Exponential regret bounds for Gaussian process bandits with deterministic observations", "author": ["N. de Freitas", "A.J. Smola", "M. Zoghi"], "venue": "In Proceedings of the 29th International Conference on Machine Learning. icml.cc / Omnipress,", "citeRegEx": "Freitas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Freitas et al\\.", "year": 2012}, {"title": "Parallelizing exploration-exploitation tradeoffs with Gaussian process bandit optimization", "author": ["T. Desautels", "A. Krause", "J.W. Burdick"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Desautels et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Desautels et al\\.", "year": 2012}, {"title": "The VOLNA code for the numerical modelling of tsunami waves: generation, propagation and inundation", "author": ["D. Dutykh", "R Poncet", "F. Dias"], "venue": "European Journal of Mechanics B/Fluids,", "citeRegEx": "Dutykh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dutykh et al\\.", "year": 2011}, {"title": "Efficient SVM regression training with SMO", "author": ["G.W. Flake", "S. Lawrence"], "venue": "Machine Learning,", "citeRegEx": "Flake and Lawrence,? \\Q2002\\E", "shortCiteRegEx": "Flake and Lawrence", "year": 2002}, {"title": "Optimization in Computational Chemistry and Molecular Biology: Local and Global Approaches", "author": ["C.A. Floudas", "P.M. Pardalos"], "venue": "Nonconvex Optimization and Its Applications. Springer,", "citeRegEx": "Floudas and Pardalos,? \\Q2000\\E", "shortCiteRegEx": "Floudas and Pardalos", "year": 2000}, {"title": "Regret bounds for Gaussian process bandit problems", "author": ["S. Grunewalder", "Audibert", "J-Y", "M. Opper", "J. Shawe-Taylor"], "venue": "In Proceedings of the International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Grunewalder et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Grunewalder et al\\.", "year": 2010}, {"title": "The 2010 Mw 7.8 Mentawai earthquake: Very shallow source of a rare tsunami earthquake determined from tsunami field survey and near-field GPS data", "author": ["E.M. Hill", "J.C. Borrero", "Z. Huang", "Q. Qiu", "P. Banerjee", "D.H. Natawidjaja", "P. Elosegui", "H.M. Fritz", "B.W. Suwargadi", "I.R. Pranantyo", "L. Li", "K.A. Macpherson", "V. Skanavis", "C.E. Synolakis", "K. Sieh"], "venue": "J. Geophys. Res.,", "citeRegEx": "Hill et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2012}, {"title": "Efficient global optimization of expensive black-box functions", "author": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global Optimization,", "citeRegEx": "Jones et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1998}, {"title": "Nearly tight bounds for the continuum-armed bandit problem", "author": ["R. Kleinberg"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Kleinberg,? \\Q2004\\E", "shortCiteRegEx": "Kleinberg", "year": 2004}, {"title": "Contextual Gaussian process bandit optimization", "author": ["A. Krause", "C.S. Ong"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Krause and Ong,? \\Q2011\\E", "shortCiteRegEx": "Krause and Ong", "year": 2011}, {"title": "Approximate inference for robust Gaussian process regression", "author": ["M. Kuss", "T. Pfingsten", "L. Csat\u00f3", "C.E. Rasmussen"], "venue": "Max Planck Inst. Biological Cybern., Tubingen, GermanyTech. Rep,", "citeRegEx": "Kuss et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kuss et al\\.", "year": 2005}, {"title": "Bayesian approach to global optimization. Mathematics and its applications", "author": ["J. Mockus"], "venue": "Kluwer Academic,", "citeRegEx": "Mockus,? \\Q1989\\E", "shortCiteRegEx": "Mockus", "year": 1989}, {"title": "Bayesian Gaussian processes for sequential prediction, optimisation and quadrature", "author": ["Osborne", "Michael"], "venue": "PhD thesis, Oxford University New College,", "citeRegEx": "Osborne and Michael.,? \\Q2010\\E", "shortCiteRegEx": "Osborne and Michael.", "year": 2010}, {"title": "Gaussian Processes for Machine Learning", "author": ["C.E. Rasmussen", "C. Williams"], "venue": null, "citeRegEx": "Rasmussen and Williams,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen and Williams", "year": 2006}, {"title": "Practical bayesian optimization of machine learning algorithms", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "Srinivas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Information-theoretic regret bounds for Gaussian process optimization in the bandit setting", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Srinivas et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2012}, {"title": "Long-wave runup on a plane beach behind a conical island", "author": ["T.S. Stefanakis", "F. Dias", "N. Vayatis", "S. Guillas"], "venue": "In Proceedings of the World Conference on Earthquake Engineering,", "citeRegEx": "Stefanakis et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Stefanakis et al\\.", "year": 2012}, {"title": "Can small islands protect nearby coasts from tsunamis ? An active experimental design approach", "author": ["T.S. Stefanakis", "E. Contal", "N. Vayatis", "F. Dias", "C.E. Synolakis"], "venue": "arXiv preprint arXiv:1305.7385,", "citeRegEx": "Stefanakis et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Stefanakis et al\\.", "year": 2013}, {"title": "Review of metamodeling techniques in support of engineering design optimization", "author": ["G. Wang", "S. Shan"], "venue": "Journal of Mechanical Design,", "citeRegEx": "Wang and Shan,? \\Q2007\\E", "shortCiteRegEx": "Wang and Shan", "year": 2007}, {"title": "Stochastic optimization models in finance", "author": ["W.T. Ziemba", "R.G. Vickson"], "venue": "World Scientific Singapore,", "citeRegEx": "Ziemba and Vickson,? \\Q2006\\E", "shortCiteRegEx": "Ziemba and Vickson", "year": 2006}], "referenceMentions": [{"referenceID": 12, "context": "1 Introduction Stochastic optimization problems are encountered in numerous real world domains including engineering design Wang & Shan [2007], finance Ziemba & Vickson [2006], natural sciences Floudas & Pardalos [2000], or in machine learning for selecting models by tuning the parameters of learning algorithms Snoek et al. [2012]. We aim at finding the input of a given system which optimizes the output (or reward).", "startOffset": 313, "endOffset": 333}, {"referenceID": 0, "context": "Efficient algorithms have been studied to tackle this challenge such as multiarmed bandit Auer et al. [2002], Kleinberg [2004], Bubeck et al.", "startOffset": 90, "endOffset": 109}, {"referenceID": 0, "context": "Efficient algorithms have been studied to tackle this challenge such as multiarmed bandit Auer et al. [2002], Kleinberg [2004], Bubeck et al.", "startOffset": 90, "endOffset": 127}, {"referenceID": 0, "context": "Efficient algorithms have been studied to tackle this challenge such as multiarmed bandit Auer et al. [2002], Kleinberg [2004], Bubeck et al. [2011], Audibert et al.", "startOffset": 90, "endOffset": 149}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al.", "startOffset": 8, "endOffset": 31}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al.", "startOffset": 8, "endOffset": 73}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al.", "startOffset": 8, "endOffset": 95}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al.", "startOffset": 8, "endOffset": 134}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al.", "startOffset": 8, "endOffset": 161}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al.", "startOffset": 8, "endOffset": 185}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f .", "startOffset": 8, "endOffset": 211}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret.", "startOffset": 8, "endOffset": 592}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al.", "startOffset": 8, "endOffset": 871}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al.", "startOffset": 8, "endOffset": 899}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al. [2012], Contal et al.", "startOffset": 8, "endOffset": 924}, {"referenceID": 0, "context": "[2011], Audibert et al. [2011], active learning Carpentier et al. [2011], Chen & Krause [2013] or Bayesian optimization Mockus [1989], Grunewalder et al. [2010], Srinivas et al. [2012], de Freitas et al. [2012]. The theoretical analysis of such optimization procedures requires some prior assumptions on the underlying function f . Modeling f as a function distributed from a Gaussian process (GP) enforces near-by locations to have close associated values, and allows to control the general smoothness of f with high probability according to the kernel of the GP Rasmussen & Williams [2006]. Our main contribution is twofold: we propose a generic algorithm scheme for Gaussian process optimization and we prove sharp upper bounds on its cumulative regret. The theoretical analysis has a direct impact on strategies built with the GP-UCB algorithm Srinivas et al. [2012] such as Krause & Ong [2011], Desautels et al. [2012], Contal et al. [2013]. We suggest an alternative policy which achieves an exponential speed up with respect to the cumulative regret.", "startOffset": 8, "endOffset": 946}, {"referenceID": 22, "context": "We consider the normalized and dimensionless framework introduced by Srinivas et al. [2010] where the variance is assumed to be bounded, that is k(x, x) \u2264 1 for all x \u2208 X .", "startOffset": 69, "endOffset": 92}, {"referenceID": 22, "context": "We consider the normalized and dimensionless framework introduced by Srinivas et al. [2010] where the variance is assumed to be bounded, that is k(x, x) \u2264 1 for all x \u2208 X . Bayesian inference. At iteration T + 1, given the previously observed noisy values YT at locations XT , we use Bayesian inference to compute the current posterior distribution Rasmussen & Williams [2006], which is a GP of mean \u03bcT+1 and variance \u03c3 T+1 given at any x \u2208 X by, \u03bcT+1(x) = kT (x) >C\u22121 T YT (1) and \u03c3 T+1(x) = k(x, x)\u2212 kT (x)>C\u22121 T kT (x) , (2) where kT (x) = [k(xt, x)]xt\u2208XT is the vector of covariances between x and the query points at time T , and CT = KT +\u03c3I with KT = [k(xt, xt\u2032)]xt,xt\u2032\u2208XT the kernel matrix, \u03c3 is the variance of the noise and I stands for the identity matrix.", "startOffset": 69, "endOffset": 377}, {"referenceID": 22, "context": "In the GP-UCB algorithm from Srinivas et al. [2012] the exploration coefficient is aO(log t) and therefore tends to infinity.", "startOffset": 29, "endOffset": 52}, {"referenceID": 22, "context": "4 in Srinivas et al. [2012]):", "startOffset": 5, "endOffset": 28}, {"referenceID": 21, "context": "In this setting, the maximum mutual information \u03b3T satisfies the upper bound \u03b3T = Op(log T )q, where d is the dimension of the input space Srinivas et al. [2012]. Corollary 1.", "startOffset": 139, "endOffset": 162}, {"referenceID": 6, "context": "Hence there is no contradiction with the lower bounds stated for linear bandit like those of Dani et al. [2008]. We refer to Srinivas et al.", "startOffset": 93, "endOffset": 112}, {"referenceID": 6, "context": "Hence there is no contradiction with the lower bounds stated for linear bandit like those of Dani et al. [2008]. We refer to Srinivas et al. [2012] for the analysis of \u03b3T with other kernels widely used in practice.", "startOffset": 93, "endOffset": 148}, {"referenceID": 21, "context": "We compare the empirical performances of our algorithm against the stateof-the-art of GP optimization, the GP-UCB algorithm Srinivas et al. [2012], and a commonly used heuristic, the Expected Improvement (EI) algorithm with GP Jones et al.", "startOffset": 124, "endOffset": 147}, {"referenceID": 14, "context": "[2012], and a commonly used heuristic, the Expected Improvement (EI) algorithm with GP Jones et al. [1998]. The tasks used for assessment come from two real applications and five synthetic problems described here.", "startOffset": 87, "endOffset": 107}, {"referenceID": 21, "context": "This benchmark is one of the two synthetic functions used by Srinivas et al. [2012] to evaluate the empirical performances of the GP-UCB algorithm.", "startOffset": 61, "endOffset": 84}, {"referenceID": 21, "context": "This benchmark is one of the two synthetic functions used by Srinivas et al. [2012] to evaluate the empirical performances of the GP-UCB algorithm. No noise has been added to the original signal in this experimental task. \u2022 Goldstein-Price. The Goldstein & Price function is an other benchmark function for global optimization, with a single global optimum but several local optima in the 2-D square [\u22122, 2]\u00d7 [\u22122, 2]. This is the second synthetic benchmark used by Srinivas et al. [2012]. Like in the previous challenge, no noise has been added to the original signal.", "startOffset": 61, "endOffset": 488}, {"referenceID": 13, "context": "Recent post-tsunami survey data as well as the numerical simulations of Hill et al. [2012] have shown that in some cases the run-up, which is the maximum vertical extent of wave climbing on a beach, in areas which were supposed to be protected by small islands in the vicinity of coast, was significantly higher than in neighboring locations.", "startOffset": 72, "endOffset": 91}, {"referenceID": 13, "context": "Recent post-tsunami survey data as well as the numerical simulations of Hill et al. [2012] have shown that in some cases the run-up, which is the maximum vertical extent of wave climbing on a beach, in areas which were supposed to be protected by small islands in the vicinity of coast, was significantly higher than in neighboring locations. Motivated by these observations Stefanakis et al. [2012] investigated this phenomenon by employing numerical simulations using", "startOffset": 72, "endOffset": 400}, {"referenceID": 9, "context": "the VOLNA code Dutykh et al. [2011] with the simplified geometry of a conical island sitting on a flat surface in front of a sloping beach.", "startOffset": 15, "endOffset": 36}, {"referenceID": 9, "context": "the VOLNA code Dutykh et al. [2011] with the simplified geometry of a conical island sitting on a flat surface in front of a sloping beach. In the study of Stefanakis et al. [2013] the setup was controlled by five physical parameters and the aim was to find with confidence and with the least number of simulations the parameters leading to the maximum run-up amplification.", "startOffset": 15, "endOffset": 181}, {"referenceID": 9, "context": "the VOLNA code Dutykh et al. [2011] with the simplified geometry of a conical island sitting on a flat surface in front of a sloping beach. In the study of Stefanakis et al. [2013] the setup was controlled by five physical parameters and the aim was to find with confidence and with the least number of simulations the parameters leading to the maximum run-up amplification. \u2022 Mackey-Glass function. The Mackey-Glass delay-differential equation is a chaotic system in dimension 6, but without noise. It models real feedback systems and is used in physiological domains such as hematology, cardiology, neurology, and psychiatry. The highly chaotic behavior of this function makes it an exceptionally difficult optimization problem. It has been used as a benchmark for example by Flake & Lawrence [2002].", "startOffset": 15, "endOffset": 802}, {"referenceID": 8, "context": "One can reduce drastically the computational time by means of Lazy Variance Calculation Desautels et al. [2012], built on the fact that \u03c3 T (x) always decreases for increasing T and for all x \u2208 X .", "startOffset": 88, "endOffset": 112}, {"referenceID": 8, "context": "One can reduce drastically the computational time by means of Lazy Variance Calculation Desautels et al. [2012], built on the fact that \u03c3 T (x) always decreases for increasing T and for all x \u2208 X . We further mention that approximated inference algorithms such as the EP approximation and MCMC sampling Kuss et al. [2005] can be used as an alternative if the computational time is a restrictive factor.", "startOffset": 88, "endOffset": 322}], "year": 2015, "abstractText": "In this paper, we analyze a generic algorithm scheme for sequential global optimization using Gaussian processes. The upper bounds we derive on the cumulative regret for this generic algorithm improve by an exponential factor the previously known bounds for algorithms like GP-UCB. We also introduce the novel Gaussian Process Mutual Information algorithm (GP-MI), which significantly improves further these upper bounds for the cumulative regret. We confirm the efficiency of this algorithm on synthetic and real tasks against the natural competitor, GP-UCB, and also the Expected Improvement heuristic. Preprint for the 31st International Conference on Machine Learning (ICML 2014) 1 ar X iv :1 31 1. 48 25 v3 [ st at .M L ] 8 J un 2 01 5 Erratum After the publication of our article, we found an error in the proof of Lemma 1 which invalidates the main theorem. It appears that the information given to the algorithm is not sufficient for the main theorem to hold true. The theoretical guarantees would remain valid in a setting where the algorithm observes the instantaneous regret instead of noisy samples of the unknown function. We describe in this page the mistake and its consequences. Let f : X \u2192 R be the unknown function to be optimized, which is a sample from a Gaussian process. Let\u2019s fix x, x1, . . . , xT \u2208 X and the observations yt = f(xt)+ t where the noise variables t are independent Gaussian noise N (0, \u03c3). We define the instantaneous regret rt = f(x?)\u2212 f(xt) and, MT = T \u2211", "creator": "LaTeX with hyperref package"}}}