{"id": "1311.6591", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Nov-2013", "title": "On the Complexity and Approximation of Binary Evidence in Lifted Inference", "abstract": "Lifted inference algorithms exploit symmetries in probabilistic models to speed up inference. They show impressive performance when calculating unconditional probabilities in relational models, but often resort to non-lifted inference when computing conditional probabilities. The reason is that conditioning on evidence breaks many of the model's symmetries, which can preempt standard lifting techniques. Recent theoretical results show, for example, that conditioning on evidence which corresponds to binary relations is #P-hard, suggesting that no lifting is to be expected in the worst case. In this paper, we balance this negative result by identifying the Boolean rank of the evidence as a key parameter for characterizing the complexity of conditioning in lifted inference. In particular, we show that conditioning on binary evidence with bounded Boolean rank is efficient. This opens up the possibility of approximating evidence by a low-rank Boolean matrix factorization, which we investigate both theoretically and empirically.", "histories": [["v1", "Tue, 26 Nov 2013 08:39:49 GMT  (147kb,D)", "http://arxiv.org/abs/1311.6591v1", "To appear in Advances in Neural Information Processing Systems 26 (NIPS), Lake Tahoe, USA, December 2013"]], "COMMENTS": "To appear in Advances in Neural Information Processing Systems 26 (NIPS), Lake Tahoe, USA, December 2013", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["guy van den broeck", "adnan darwiche"], "accepted": true, "id": "1311.6591"}, "pdf": {"name": "1311.6591.pdf", "metadata": {"source": "CRF", "title": "On the Complexity and Approximation of Binary Evidence in Lifted Inference", "authors": ["Guy Van den Broeck"], "emails": ["guyvdb@cs.ucla.edu", "darwiche@cs.ucla.edu"], "sections": [{"heading": "1 Introduction", "text": "We are able to represent both probable dependencies and a relational structure, which is implicitly called a reduction of functionality. Due to their first-order expressivity, they concisely represent probability distributions across a large number of propositional random variables, which leads to inferences in these models quickly becoming insoluble. Lifted consequential algorithms [3] attempt to overcome this problem by exploiting symmetries found in the relational structure of the model. In the absence of evidence, exact elevated inference algorithms can work well. However, for large classes of statistical relational models [4] they perform evidence collections that are polynomial in the number of objects in the model and are exponentially faster than classical inference algorithms. However, when conditioning is literalized a set of evidence results, these elevated algorithms lose their advantage over classical models."}, {"heading": "2 Encoding Binary Relations in Unary", "text": "Our analysis of conditioning is based on reduction and turns evidence of a binary relationship into evidence of several simple predicates. First, we present some necessary background information."}, {"heading": "2.1 Background", "text": "An atom p (t1,.., tn) consists of a predicate p / n of equality n followed by n arguments which are either (lowercase) constants or (uppercase) logical variables. A literal is an atom a or its negation \u00ac a. A formula combines atoms with logical connectives (e.g., physics, physics). A formula is grounded if it does not contain logical variables. A possible world assigns a truth value to each earth atom. Statistical relational languages define a probability distribution over possible words where earth atoms are individual random variables. Countless languages have been proposed in recent years, and our analysis is applied to many, including MLNs [16], parameters [3] and WFOMC problems [8]. Example 1. The following MLNs model the dependencies between web pages."}, {"heading": "2.2 Vector-Product Binary Evidence", "text": "Certain binary relationships can be represented by a pair of unary predicates. If we add the formula to our statistical relationship model and the conditioning of the q and r relations, we can condition certain types of binary p relations. Assuming that we condition this formula (as hard clauses) on the q and r predicates, the probability distribution over the atoms of the original model does not change. It is only an indirect way of conditioning the p relationship. If we now represent these simple relations by vectors q and r and the binary relationship by the binary matrix P, the above technique allows us to condition any relationship P that can be rfactored in the external vector product P = q. Example 3. Consider the following external vector factorization by the Boolean matrix P = 0 0 0 0 0 0 0 0 0 0 0 \u00b7 b \u00b7 1 \u00b2 factorial relationship (Example 3)."}, {"heading": "2.3 Matrix-Product Binary Evidence", "text": "This idea of encoding a binary relationship in unary relationships can be generalized to n pairs of unary relationships by adding the following formula to our model."}, {"heading": "3 Boolean Matrix Factorization", "text": "Matrix factorization (or decomposition) is a popular linear algebra tool. Some well-known examples are the decomposition of individual values and non-negative matrix factorization (NMF) [17, 18]. NMF factorization becomes a product of non-negative matrices, which are easier to interpret and have therefore attracted a lot of attention for unattended learning and feature extraction. These factorizations all work with real matrices. Instead, we look at Boolean matrices with only 0 / 1 entries."}, {"heading": "3.1 Boolean Rank", "text": "The factorization of a matrix P as a QRin of Boolean algebra is a well-known problem called Boolean matrix factorization (BMF) [19, 20]. BMF factorizes a (k \u00b7 l) matrix P into a (k \u00b7 n) matrix Q and a (l \u00b7 n) matrix R, where potentially n k and n l and we always have this n \u2264 min (k, l). Any Boolean matrix can be factorized in this way, and the smallest number n for which it is possible is called the Boolean rank of the matrix. In contrast to the (textbook) real rank, the calculation of the Boolean rank NP-hard and cannot be nearly achieved, unless P = NP [19]. The Boolean and real rank n are incomparable, and the Boolean rank can be exponentially smaller than the real rank. Example 5. The factorization in 4 is a reale with a BMR = 3 over a reolean F = 1, with a number of reolean 11 over a 1 and a BMR = 1."}, {"heading": "3.2 Approximate Boolean Factorization", "text": "Since most real-world matrices will have an almost complete rank (i.e., almost min (k, l)), BMF applications consider approximate factorizations. The goal is to find a pair of the (small) Boolean matrices Qk \u00b7 n and Rl \u00b7 n, so that Pk \u00b7 l \u2248 (Qk \u00b7 n R l \u00b7 n), or more precisely, to find matrices that optimize any target that replaces approximation error and Boolean rank n. When n and n \u00b7 l, this approximation extracts interesting structures and removes noise from the matrix. This has recently led to the BMF receiving considerable attention in the data mining community as a tool for analyzing high-dimensional data. It is used to find important and interpretable (i.e. Boolean) concepts in a data matrix. Unfortunately, the approximate BMF optimization problem is a difficult problem to master, and invaluable [S-23] that algorithms [S] are well connected to the BMF]."}, {"heading": "4 Complexity of Binary Evidence", "text": "Our goal in this section is to provide a new complexity result for arguing with binary evidence in the context of elevated conclusions. Our result can be considered a parameterized complexity result similar to a formula-1 model based on treewidth. However, in order to present the new result, we must first formally define the arithmetic task. We will also review the key complexity result that is now known about this calculation (i.e., the one that we will improve). Consider a set of proofs that represent binary proofs, which is, for some binary evidence results that contain p (X, Y), proofs that include a literal (positive or negative) grounding of predicates p (X, Y). Here, m represents the number of objects that represent X and Y."}, {"heading": "5 Over-Symmetric Evidence Approximation", "text": "Theorem 2 opens up many new possibilities. Even for evidence with a high Boolean rank it is possible to find a low approximate BMF of evidence, as is usually done for other data mining and machine learning problems. Algorithms already exist for solving this problem (cf. Section 3).Example 6. The evidence matrix in Example 4 has Boolean rank 3. Dropping the third pair of vectors reduces the Boolean rank to two.1 1 0 01 1 0 0 0 1 01 0 0 0 1 \u2248 0101 1001 110 0 @ @ @ @ @ 001 0 0 11 10 0 1 0 1 1 10 0 0 0 1 0 0 0 0 1 This factoring is approximate, since it makes the evidence for atom p (c, c) from true to false (represented by the bold 0)."}, {"heading": "6 Empirical Evaluation", "text": "To supplement the theoretical analysis from the previous sections, we will now report on experiments that examine the following practical questions: Q1 How well can we engage with a real world characterized by a low level of the Boolean matrix? Q2 is a good indicator of the complexity of interpretation suggested by Theorem 2? Q3 is an overarching evidence that allows a realistic approach to an approximate approach from four universities. To answer the question, we have an approximation of the binary relationship of the WebKB data using the ASSO algorithm for BMF [20]. The WebKB data consists of the departments of computer science from four universities. The data have information that appears on the pages, labels of the pages and links between the pages (linkto relation). There are four following pieces of evidence, one for each university."}, {"heading": "7 Conclusions", "text": "We presented two main results: the first is a more precise characterization of the complexity of conditioning binary evidence in terms of its Boolean rank; the second is a technique for approximating binary findings by means of low-level Boolean matrix factorization; this is a first type of hyper-symmetric evidence approach that can accelerate increased inference; we have empirically shown that a low BMF accelerates approximate inference, leading to improved approximations; and for future work, we will evaluate the practical implications of the theory developed for other canceled inference algorithms, such as elevated BP, and look at the performance of hyper-symmetric evidence approach to machine learning tasks such as collective classification; there are still many remaining challenges to find good evidence approximation schemes, including those that are query-specific (see Salvo Braglal et [32], or better approximations to run."}, {"heading": "Acknowledgments", "text": "We would like to thank Pauli Miettinen, Mathias Niepert and Jilles Vreeken for their helpful suggestions. This work was supported by the ONR scholarship no. N00014-12-1-0423, the NSF scholarship no. IIS-1118122, the NSF scholarship no. IIS0916161 and the Research Foundation Flanders (FWO-Vlaanderen)."}], "references": [{"title": "editors", "author": ["L. Getoor", "B. Taskar"], "venue": "An Introduction to Statistical Relational Learning. MIT Press", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Probabilistic inductive logic programming: theory and applications", "author": ["Luc De Raedt", "Paolo Frasconi", "Kristian Kersting", "Stephen Muggleton", "editors"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "First-order probabilistic inference", "author": ["David Poole"], "venue": "In Proceedings of IJCAI, pages 985\u2013991,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Liftability of probabilistic inference: Upper and lower bounds", "author": ["Manfred Jaeger", "Guy Van den Broeck"], "venue": "In Proceedings of the 2nd International Workshop on Statistical Relational AI,,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Lifted first-order probabilistic inference", "author": ["Rodrigo de Salvo Braz", "Eyal Amir", "Dan Roth"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2005}, {"title": "Lifted probabilistic inference with counting formulas", "author": ["B. Milch", "L.S. Zettlemoyer", "K. Kersting", "M. Haimes", "L.P. Kaelbling"], "venue": "Proceedings of the 23rd AAAI Conference on Artificial Intelligence", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Lifted probabilistic inference by first-order knowledge compilation", "author": ["Guy Van den Broeck", "Nima Taghipour", "Wannes Meert", "Jesse Davis", "Luc De Raedt"], "venue": "In Proceedings of IJCAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Lifted variable elimination with arbitrary constraints", "author": ["N. Taghipour", "D. Fierens", "J. Davis", "H. Blockeel"], "venue": "Proceedings of the 15th International Conference on Artificial Intelligence and Statistics", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2012}, {"title": "and R", "author": ["H.H. Bui", "T.N. Huynh"], "venue": "de Salvo Braz. Exact lifted inference with distinct soft evidence on every object. In Proceedings of the 26th AAAI Conference on Artificial Intelligence", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Conditioning in first-order knowledge compilation and lifted probabilistic inference", "author": ["Guy Van den Broeck", "Jesse Davis"], "venue": "In Proceedings of the 26th AAAI Conference on Artificial Intelligence,,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Probabilistic theorem proving", "author": ["Vibhav Gogate", "Pedro Domingos"], "venue": "In Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Lifted inference seen from the other side: The tractable features", "author": ["A. Jha", "V. Gogate", "A. Meliou", "D. Suciu"], "venue": "Proceedings of the 24th Conference on Neural Information Processing Systems (NIPS)", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Lifted generative parameter learning", "author": ["Guy Van den Broeck", "Wannes Meert", "Jesse Davis"], "venue": "In Statistical Relational AI (StaRAI) workshop,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Counting belief propagation", "author": ["K. Kersting", "B. Ahmadi", "S. Natarajan"], "venue": "Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI), pages 277\u2013284", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Markov logic networks", "author": ["M. Richardson", "P. Domingos"], "venue": "Machine learning, 62(1):107\u2013136", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2006}, {"title": "Algorithms for non-negative matrix factorization", "author": ["D. Seung", "L. Lee"], "venue": "Advances in neural information processing systems, 13:556\u2013562", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2001}, {"title": "Algorithms and applications for approximate nonnegative matrix factorization", "author": ["M. Berry", "M. Browne", "A. Langville", "V. Pauca", "R. Plemmons"], "venue": "Computational Statistics and Data Analysis", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "The discrete basis problem", "author": ["Pauli Miettinen", "Taneli Mielik\u00e4inen", "Aristides Gionis", "Gautam Das", "Heikki Mannila"], "venue": "In Knowledge Discovery in Databases,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2006}, {"title": "The discrete basis problem", "author": ["Pauli Miettinen", "Taneli Mielikainen", "Aristides Gionis", "Gautam Das", "Heikki Mannila"], "venue": "IEEE Transactions on Knowledge and Data Engineering,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Sparse Boolean matrix factorizations", "author": ["Pauli Miettinen"], "venue": "In IEEE 10th International Conference on Data Mining (ICDM),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Mathematical classification and clustering, volume 11", "author": ["Boris Mirkin"], "venue": "Kluwer Academic Pub,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1996}, {"title": "Tiling databases", "author": ["Floris Geerts", "Bart Goethals", "Taneli Mielik\u00e4inen"], "venue": "In Discovery science,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2004}, {"title": "Stochastic blockmodels: First steps", "author": ["Paul W Holland", "Kathryn Blackmond Laskey", "Samuel Leinhardt"], "venue": "Social networks,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1983}, {"title": "Matrix decomposition methods for data mining: Computational complexity and algorithms", "author": ["Pauli Miettinen"], "venue": "PhD thesis,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Lifted Inference and Learning in Statistical Relational Models", "author": ["Guy Van den Broeck"], "venue": "PhD thesis,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Treewidth: Algorithmic techniques and results", "author": ["Hans L Bodlaender"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1997}, {"title": "Relational learning with statistical predicate invention: Better models for hypertext", "author": ["M. Craven", "S. Slattery"], "venue": "Machine Learning Journal, 43(1/2):97\u2013119", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2001}, {"title": "Markov chains on orbits of permutation groups", "author": ["Mathias Niepert"], "venue": "In Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Symmetry-aware marginal density estimation", "author": ["Mathias Niepert"], "venue": "In Proceedings of the 27th Conference on Artificial Intelligence (AAAI),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Deep transfer via second-order markov logic", "author": ["Jesse Davis", "Pedro Domingos"], "venue": "In Proceedings of the 26th annual international conference on machine learning,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}, {"title": "Anytime lifted belief propagation", "author": ["R. de Salvo Braz", "S. Natarajan", "H. Bui", "J. Shavlik", "S. Russell"], "venue": "Proceedings of the 6th International Workshop on Statistical Relational Learning,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2009}, {"title": "Informed lifting for message-passing", "author": ["K. Kersting", "Y. El Massaoudi", "B. Ahmadi", "F. Hadiji"], "venue": "Proceedings of the 24th AAAI Conference on Artificial Intelligence,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Statistical relational models are capable of representing both probabilistic dependencies and relational structure [1, 2].", "startOffset": 115, "endOffset": 121}, {"referenceID": 1, "context": "Statistical relational models are capable of representing both probabilistic dependencies and relational structure [1, 2].", "startOffset": 115, "endOffset": 121}, {"referenceID": 2, "context": "Lifted inference algorithms [3] attempt to overcome this problem by exploiting symmetries found in the relational structure of the model.", "startOffset": 28, "endOffset": 31}, {"referenceID": 3, "context": "For large classes of statistical relational models [4], they perform inference that is polynomial in the number of objects in the model [5], and are therein exponentially faster than classical inference algorithms.", "startOffset": 51, "endOffset": 54}, {"referenceID": 2, "context": "Examples include publications on FOVE [3, 6, 7] and WFOMC [8, 5].", "startOffset": 38, "endOffset": 47}, {"referenceID": 4, "context": "Examples include publications on FOVE [3, 6, 7] and WFOMC [8, 5].", "startOffset": 38, "endOffset": 47}, {"referenceID": 5, "context": "Examples include publications on FOVE [3, 6, 7] and WFOMC [8, 5].", "startOffset": 38, "endOffset": 47}, {"referenceID": 6, "context": "Examples include publications on FOVE [3, 6, 7] and WFOMC [8, 5].", "startOffset": 58, "endOffset": 64}, {"referenceID": 7, "context": "There are examples for FOVE [9, 10], WFOMC [11], PTP [12] and CP [13].", "startOffset": 28, "endOffset": 35}, {"referenceID": 8, "context": "There are examples for FOVE [9, 10], WFOMC [11], PTP [12] and CP [13].", "startOffset": 28, "endOffset": 35}, {"referenceID": 9, "context": "There are examples for FOVE [9, 10], WFOMC [11], PTP [12] and CP [13].", "startOffset": 43, "endOffset": 47}, {"referenceID": 10, "context": "There are examples for FOVE [9, 10], WFOMC [11], PTP [12] and CP [13].", "startOffset": 53, "endOffset": 57}, {"referenceID": 11, "context": "There are examples for FOVE [9, 10], WFOMC [11], PTP [12] and CP [13].", "startOffset": 65, "endOffset": 69}, {"referenceID": 8, "context": "[10] and Van den Broeck and Davis [11] showed that conditioning on unary evidence is tractable.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[10] and Van den Broeck and Davis [11] showed that conditioning on unary evidence is tractable.", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "Unfortunately, Van den Broeck and Davis [11] also showed that this tractability does not extend to", "startOffset": 40, "endOffset": 44}, {"referenceID": 12, "context": "For example, in lifted generative learning [14], the most challenging task is to compute partition functions without evidence.", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "[15]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "Numerous languages have been proposed in recent years, and our analysis will apply to many, including MLNs [16], parfactors [3] and WFOMC problems [8].", "startOffset": 107, "endOffset": 111}, {"referenceID": 2, "context": "Numerous languages have been proposed in recent years, and our analysis will apply to many, including MLNs [16], parfactors [3] and WFOMC problems [8].", "startOffset": 124, "endOffset": 127}, {"referenceID": 6, "context": "Numerous languages have been proposed in recent years, and our analysis will apply to many, including MLNs [16], parfactors [3] and WFOMC problems [8].", "startOffset": 147, "endOffset": 150}, {"referenceID": 15, "context": "Some well-known instances are singular value decomposition and non-negative matrix factorization (NMF) [17, 18].", "startOffset": 103, "endOffset": 111}, {"referenceID": 16, "context": "Some well-known instances are singular value decomposition and non-negative matrix factorization (NMF) [17, 18].", "startOffset": 103, "endOffset": 111}, {"referenceID": 17, "context": "Factorizing a matrix P as QR in Boolean algebra is a known problem called Boolean Matrix Factorization (BMF) [19, 20].", "startOffset": 109, "endOffset": 117}, {"referenceID": 18, "context": "Factorizing a matrix P as QR in Boolean algebra is a known problem called Boolean Matrix Factorization (BMF) [19, 20].", "startOffset": 109, "endOffset": 117}, {"referenceID": 17, "context": "Unlike (textbook) real-valued rank, computing the Boolean rank is NP-hard and cannot be approximated unless P=NP [19].", "startOffset": 113, "endOffset": 117}, {"referenceID": 18, "context": "Unfortunately, the approximate BMF optimization problem is NP-hard as well, and inapproximable [20].", "startOffset": 95, "endOffset": 99}, {"referenceID": 18, "context": "Algorithms exist that find good approximations for fixed values of n [20], or when P is sparse [21].", "startOffset": 69, "endOffset": 73}, {"referenceID": 19, "context": "Algorithms exist that find good approximations for fixed values of n [20], or when P is sparse [21].", "startOffset": 95, "endOffset": 99}, {"referenceID": 20, "context": "BMF is related to other data mining tasks, such as biclustering [22] and tiling databases [23], whose algorithms could also be used for approximate BMF.", "startOffset": 64, "endOffset": 68}, {"referenceID": 21, "context": "BMF is related to other data mining tasks, such as biclustering [22] and tiling databases [23], whose algorithms could also be used for approximate BMF.", "startOffset": 90, "endOffset": 94}, {"referenceID": 22, "context": "In the context of social network analysis, BMF is related to stochastic block models [24] and their extensions, such as infinite relational models.", "startOffset": 85, "endOffset": 89}, {"referenceID": 3, "context": "Our analysis will apply to classes of models \u2206 that are domain-liftable [4], which means that the complexity of computing Prm(q) without evidence is polynomial in m.", "startOffset": 72, "endOffset": 75}, {"referenceID": 9, "context": "The following recent result provides a lower bound on the complexity of this computation [11].", "startOffset": 89, "endOffset": 93}, {"referenceID": 23, "context": "Lemma 3 (Miettinen [25]).", "startOffset": 19, "endOffset": 23}, {"referenceID": 9, "context": "Lemma 4 (Van den Broeck and Davis [11], Van den Broeck [26]).", "startOffset": 34, "endOffset": 38}, {"referenceID": 24, "context": "Lemma 4 (Van den Broeck and Davis [11], Van den Broeck [26]).", "startOffset": 55, "endOffset": 59}, {"referenceID": 25, "context": "The (a) steps are both NP-hard, yet are efficient assuming bounded treewidth [27] or bounded Boolean rank (Lemma 3).", "startOffset": 77, "endOffset": 81}, {"referenceID": 18, "context": "To answer Q1, we compute approximations of the linkto binary relation in the WebKB data set using the ASSO algorithm for approximate BMF [20].", "startOffset": 137, "endOffset": 141}, {"referenceID": 26, "context": "The WebKB data set consists of web pages from the computer science departments of four universities [28].", "startOffset": 100, "endOffset": 104}, {"referenceID": 6, "context": "These models are compiled using the WFOMC [8] algorithm into first-order NNF circuits, which allow for exact domain-lifted inference (c.", "startOffset": 42, "endOffset": 45}, {"referenceID": 27, "context": "Therefore, we investigate its influence on the Lifted MCMC algorithm (LMCMC) [29] with Rao-Blackwellized probability estimation [30].", "startOffset": 77, "endOffset": 81}, {"referenceID": 28, "context": "Therefore, we investigate its influence on the Lifted MCMC algorithm (LMCMC) [29] with Rao-Blackwellized probability estimation [30].", "startOffset": 128, "endOffset": 132}, {"referenceID": 29, "context": "We run LMCMC on the WebKB MLN of Davis and Domingos [31], which has 333 first-order formulas and over 1 million random variables.", "startOffset": 52, "endOffset": 56}, {"referenceID": 30, "context": "[32]) or that incrementally run inference to find better approximations (cf.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[33]).", "startOffset": 0, "endOffset": 4}], "year": 2013, "abstractText": "Lifted inference algorithms exploit symmetries in probabilistic models to speed up inference. They show impressive performance when calculating unconditional probabilities in relational models, but often resort to non-lifted inference when computing conditional probabilities. The reason is that conditioning on evidence breaks many of the model\u2019s symmetries, which can preempt standard lifting techniques. Recent theoretical results show, for example, that conditioning on evidence which corresponds to binary relations is #P-hard, suggesting that no lifting is to be expected in the worst case. In this paper, we balance this negative result by identifying the Boolean rank of the evidence as a key parameter for characterizing the complexity of conditioning in lifted inference. In particular, we show that conditioning on binary evidence with bounded Boolean rank is efficient. This opens up the possibility of approximating evidence by a low-rank Boolean matrix factorization, which we investigate both theoretically and empirically.", "creator": "LaTeX with hyperref package"}}}