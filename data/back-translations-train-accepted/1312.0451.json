{"id": "1312.0451", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Dec-2013", "title": "Consistency of weighted majority votes", "abstract": "We revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective. In particular, we examine the consistency (both asymptotic and finitary) of the optimal Nitzan-Paroush weighted majority and related rules. In the case of known expert competence levels, we give precise necessary and sufficient conditions for consistency. When the competence levels are unknown, they must be empirically estimated. We provide frequentist and Bayesian analyses for this situation and discuss open problems presented by both approaches. Some of our proof techniques are non-standard and may be of independent interest. Experimental results are provided.", "histories": [["v1", "Mon, 2 Dec 2013 13:41:44 GMT  (313kb)", "https://arxiv.org/abs/1312.0451v1", null], ["v2", "Thu, 5 Dec 2013 13:02:17 GMT  (312kb)", "http://arxiv.org/abs/1312.0451v2", null], ["v3", "Mon, 9 Dec 2013 17:13:01 GMT  (310kb)", "http://arxiv.org/abs/1312.0451v3", null], ["v4", "Sun, 22 Dec 2013 11:23:48 GMT  (310kb)", "http://arxiv.org/abs/1312.0451v4", null], ["v5", "Tue, 21 Jan 2014 08:24:07 GMT  (310kb)", "http://arxiv.org/abs/1312.0451v5", null]], "reviews": [], "SUBJECTS": "math.PR cs.LG stat.ML", "authors": ["daniel berend", "aryeh kontorovich"], "accepted": true, "id": "1312.0451"}, "pdf": {"name": "1312.0451.pdf", "metadata": {"source": "CRF", "title": "Consistency of weighted majority votes", "authors": ["Daniel Berend", "Aryeh Kontorovich"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 131 2.04 51v5 [m. ath. PR] 21 yes"}, {"heading": "1 Introduction", "text": "The problem of the weighting of several experts arises in many situations and is of considerable theoretical and practical importance. Rigorous investigation of majority decisions has its roots in the work of Condorcet (1785). Through the 1970s, the field of decision theory was actively researched various voting rules (see Nitzan & Paroush (1982) and the references contained therein. A typical attitude is as follows: An agent is entrusted with the prediction of some random variable Y questions based on input Xi. Each expert Xi has a level of competence pi (0, 1), which is the probability of making a correct prediction: P (Xi = Y) = pi. Two simplistic assumptions are generally made: (i) Independence: The random variables {Xi: i] are mutually independent. (ii) Unbiased Truth: P (Y = 1) = 1 / 2. We will discuss these assumptions below."}, {"heading": "2 Background and related work", "text": "Machine learning theory typically combines weighted majorities (Littlestone & Warmuth, 1989, 1994) within the framework of online algorithms; see Cesa-Bianchi & Lugosi (2006) for a more modern approach; because online setting is much more counterproductive than ours, we get very different weighted majority rules and consistency guarantees; the weights in (2) exhibit a striking similarity to the Adaboost updating rule (Freund & Schapire, 1997; Schapire & Freund, 2012), which assumes weak learners with access to labeled examples, while the experts in our setting are \"static.\" Nevertheless, we do not rule out a possible deeper link between the Nitzan-Paroush decision rule and funding; in a more recent work line Lacasse et al. (2006); Laviolette & Marchand Marchand (2007); Roy et al. (2011) have developed a simple Bayesian majority theory for online learning."}, {"heading": "3 Known competences", "text": "In this section, we assume that the expert competences pi are known and analyze the consistency of the optimal decision rule of Nitzan-Paroush (2). Our main result is that the probability of error P (fOPT (X) 6 = Y) is low if and only if the rejection potential is greater. Theorem 1. Let us assume that the experts X = (X1,.., Xn) fulfill the assumptions (i) - (ii) and f: {\u00b1 1} n \u2192 {\u00b1 1} is the optimal decision rule of Nitzan-Paroush. Then (i) P (fOPT (X) 6 = Y) \u2264 exp (\u2212 12\u0445). (ii) P (fOPT (X) 6 = Y) \u2265 3 4 [1 + exp (2\u0445 + 4 \u041a\u0438).Open task."}, {"heading": "3.1 Proof of Theorem 1(i)", "text": "An error fOPT (X) 6 = Y occurs exactly when the sum of the correct expert weights does not exceed half of the total mass: P (fOPT (X) 6 = Y) = P (n). (6) Since we can override the probability in (6) asP (P) 6 = Y), the probability in (6) asP (P) 6 = Y) = P (n). (7) A standard tool for estimating such sum deviations is Hoeffding's inequality. Applied to (7), it yields the boundP (fOPT) 6 = Y (Y)."}, {"heading": "3.2 Proof of Theorem 1(ii)", "text": "Define the {\u00b1 1} -indicator -variables\u03b7i = 21 {Xi = Y} \u2212 1, (12) according to the event that the expert is correct and puts it in order, Qi = 1 \u2212 pi. The abbreviation w \u2212 pi = p \u00b7 si = p \u00b7 si will be convenient. We will need some simple lemmings: Lemma 2.P (fOPT (X) = Y) = p \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 Prop \u00b2 \u00b2 \u00b2 \u00b2 1p \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 i i \u00b2 \u00b2 i i \u00b2 \u00b2 \u00b2 i i \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 Prop \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 = p.p = \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 i \u00b2 i i i i \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 i i \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 i p = i \u00b2 i = i \u00b2 i \u00b2 \u00b2 i \u00b2 \u00b2 i \u00b2 \u00b2 i \u00b2 i \u00b2 i \u00b2 i = i = i Prop = p = i = i = i = i = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p ="}, {"heading": "4 Unknown competences: frequentist approach", "text": "Our goal in this section is to obtain, as far as possible, analogies to Theorem 1 for unknown expert competences. If the pis is unknown, they must be empirically estimated before any useful weighted majority decision can be applied. There are various ways to model partial knowledge of expert competences (Baharad et al., 2011, 2012). Perhaps the simplest scenario for estimating the pis is to assume that the ith expert was independently interviewed mi-mal times from which he gave the correct prediction ki times. By defining the {mi}, one defines the committee profile according to k = (k1,.., kn); this is the totality of the empirical knowledge of the broker about the performance of the experts. An empirical decision rule f: (x, k) 7 \u2192 {\u00b1 1} makes a final decision based on the expert inputs x together with the committee profile. Analogous to (1), the probability of an error is an unsafe (k), which is an additional (K)."}, {"heading": "4.1 Low-confidence regime", "text": "In the low confidence system, the sample sizes mi may be as small as 1, and we define ine2w, (ki) = w, LC i: = p, i - 12, i - [n], (23), which triggers the empirical rule f, LC. However, it remains to analyze the probability of error f, LC. (Remember the definition of \"i\" from (5) and observe that the estimated competences p, i, i, i, i and i can assume values from {0, 1}, in which case log (p, i / q, i) = (pi \u2212 12) pi, (24) 2For min {pi, qi} 1, the estimated competences p, i and i, in which case log (p, i / q, i) = \u00b1. The rule in (23) is essentially a Taylor approximation to w, i, (\u00b7) approximately p, i, da, and i, and i, and i, and i, are independent."}, {"heading": "4.2 High-confidence regime", "text": "To formalize this, we will set the empirical weights in accordance with the \"plug-in\" rule. We give two types of limits to P (f) HC 6 = Y: not adaptive and adaptive. In the non-adaptive analysis we show that we are suitable for mimin {pi, qi} i: 1, 2, 3, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5"}, {"heading": "5 Unknown competences: Bayesian approach", "text": "One shortcoming of theorem 10 is that if condition R is not met, the agent does not have an estimate of the probability of error. An alternative (and in a sense cleaner) approach to handling unknown expert skills is to assume a known prior distribution across skill levels pi. The natural procedure for a Bernoulli parameter is the beta distribution (and in a sense cleaner) beta (+ 1) beta (x, \u03b2i) with densitypical skill levels pi, \u03b2i), \u03b2i > 0, where qi = 1 \u2212 pi and B (x, y) = skills (x). Our complete probability model is as follows: Each of the n expert skills pi is drawn with known parameters pi, \u03b2i-i, \u03b2i-i and i-ki independently of the beta distribution."}, {"heading": "6 Experiments", "text": "Most revealing is to consider the committee size n as small when comparing the various voting rules. Indeed, for a large panel of \"slightly competent\" experts with pi = 1 2 + \u03b3 for some g > 0, even the simple majority rule fMAJ (x) = sign (p = 1 xi) has an error probability declared as exp (\u2212 4n\u03b32), which is easily detectable by Hoeffding's limitations. The more complex voting rules discussed in this paper perform even better in this environment. Therefore, small committees provide the natural touchstone for assessing the ability of a voting rule to use highly competent experts. In our experiments, we set n = 5 and the sample sizes mi were identical for all experts. Results were averaged over 105 studies. Two of our experiments are described below. Low vs. high confidence. The goal of this experiment was to contrast the extreme behavior of f \u00b2 LC against f \u00b2 HC."}, {"heading": "7 Discussion", "text": "The classic and seemingly well-understood problem of the consistency of weighted majority votes continues to reveal untapped depth and suggests difficult unresolved issues. We hope that the results and outstanding issues presented here will inspire future research."}, {"heading": "Appendix: Deferred proofs", "text": "Proof of Lemma 4. Since F is symmetrical about x = 12, it is sufficient to make the claim for 12 \u2264 x < 1. We will show that F is concave by examining its second derivative: F \u2032 (x) = \u2212 2x \u2212 1 \u2212 2x (1 \u2212 x) log (x / (1 \u2212 x)) x (1 \u2212 x) (2x \u2212 1) 3. The denominator is obviously not negative to [12, 1], while the counter shows the Taylor expansion \u221e n = 122 (n + 1) (x \u2212 12) 2n + 1 4n2 \u2212 1 \u2265 0.1 2 \u2264 x < 1 (confirmed by laborious but simple calculation). Since F is concave and symmetrical about 12, its maximum occurs at F (1 2) = 1 2."}], "references": [{"title": "Tuning bandit algorithms in stochastic environments", "author": ["Audibert", "Jean-Yves", "Munos", "R\u00e9mi", "Szepesv\u00e1ri", "Csaba"], "venue": "In ALT, pp", "citeRegEx": "Audibert et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2007}, {"title": "Distilling the wisdom of crowds: weighted aggregation of decisions on multiple issues", "author": ["Baharad", "Eyal", "Goldberger", "Jacob", "Koppel", "Moshe", "Nitzan", "Shmuel"], "venue": "Autonomous Agents and Multi-Agent Systems,", "citeRegEx": "Baharad et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Baharad et al\\.", "year": 2011}, {"title": "A sharp estimate of the binomial mean absolute deviation with applications", "author": ["Berend", "Daniel", "Kontorovich", "Aryeh"], "venue": "Statistics & Probability Letters,", "citeRegEx": "Berend et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berend et al\\.", "year": 2013}, {"title": "On the concentration of the missing mass", "author": ["Berend", "Daniel", "Kontorovich", "Aryeh"], "venue": "Electron. Commun. Probab.,", "citeRegEx": "Berend et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berend et al\\.", "year": 2013}, {"title": "When is Condorcet\u2019s jury theorem valid", "author": ["Berend", "Daniel", "Paroush", "Jacob"], "venue": "Soc. Choice Welfare,", "citeRegEx": "Berend et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Berend et al\\.", "year": 1998}, {"title": "Monotonicity in Condorcet\u2019s jury theorem with dependent voters", "author": ["Berend", "Daniel", "Sapir", "Luba"], "venue": "Social Choice and Welfare,", "citeRegEx": "Berend et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Berend et al\\.", "year": 2007}, {"title": "Modelling dependence in simple and indirect majority systems", "author": ["Boland", "Philip J", "Proschan", "Frank", "Y.L. Tong"], "venue": "J. Appl. Probab.,", "citeRegEx": "Boland et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Boland et al\\.", "year": 1989}, {"title": "Prediction, learning, and games", "author": ["Cesa-Bianchi", "Nicol\u00f2", "Lugosi", "G\u00e1bor"], "venue": null, "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2006}, {"title": "A decision-theoretic generalization of online learning and an application to boosting", "author": ["Freund", "Yoav", "Schapire", "Robert E"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "Freund et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1997}, {"title": "The Elements of Statistical Learning: Data Mining, Inference, and Prediction", "author": ["Hastie", "Trevor", "Tibshirani", "Robert", "Friedman", "Jerome"], "venue": null, "citeRegEx": "Hastie et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hastie et al\\.", "year": 2009}, {"title": "Large deviation methods for approximate probabilistic inference", "author": ["Kearns", "Michael J", "Saul", "Lawrence K"], "venue": "In UAI,", "citeRegEx": "Kearns et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kearns et al\\.", "year": 1998}, {"title": "Obtaining measure concentration from Markov contraction", "author": ["Kontorovich", "Aryeh"], "venue": "Markov Processes and Related Fields,", "citeRegEx": "Kontorovich and Aryeh.,? \\Q2012\\E", "shortCiteRegEx": "Kontorovich and Aryeh.", "year": 2012}, {"title": "PAC-Bayes bounds for the risk of the majority vote and the variance of the gibbs classifier", "author": ["Lacasse", "Alexandre", "Laviolette", "Fran\u00e7ois", "Marchand", "Mario", "Germain", "Pascal", "Usunier", "Nicolas"], "venue": "In NIPS, pp", "citeRegEx": "Lacasse et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lacasse et al\\.", "year": 2006}, {"title": "PAC-Bayes risk bounds for stochastic averages and majority votes of sample-compressed classifiers", "author": ["Laviolette", "Fran\u00e7ois", "Marchand", "Mario"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Laviolette et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Laviolette et al\\.", "year": 2007}, {"title": "The weighted majority algorithm", "author": ["Littlestone", "Nick", "Warmuth", "Manfred K"], "venue": "In FOCS, pp", "citeRegEx": "Littlestone et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Littlestone et al\\.", "year": 1989}, {"title": "The weighted majority algorithm", "author": ["Littlestone", "Nick", "Warmuth", "Manfred K"], "venue": "Inf. Comput.,", "citeRegEx": "Littlestone et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Littlestone et al\\.", "year": 1994}, {"title": "Robust aggregation of experts signals", "author": ["Mansour", "Yishay", "Rubinstein", "Aviad", "Tennenholtz", "Moshe"], "venue": null, "citeRegEx": "Mansour et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mansour et al\\.", "year": 2013}, {"title": "Empirical Bernstein bounds and sample-variance penalization", "author": ["Maurer", "Andreas", "Pontil", "Massimiliano"], "venue": "In COLT,", "citeRegEx": "Maurer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Maurer et al\\.", "year": 2009}, {"title": "Concentration inequalities for the missing mass and for histogram rule error", "author": ["McAllester", "David A", "Ortiz", "Luis E"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "McAllester et al\\.,? \\Q2003\\E", "shortCiteRegEx": "McAllester et al\\.", "year": 2003}, {"title": "Empirical Bernstein stopping", "author": ["Mnih", "Volodymyr", "Szepesv\u00e1ri", "Csaba", "Audibert", "Jean-Yves"], "venue": "In ICML, pp", "citeRegEx": "Mnih et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2008}, {"title": "On the problem of the most efficient tests of statistical hypotheses", "author": ["Neyman", "Jerzy", "Pearson", "Egon S"], "venue": "Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences,", "citeRegEx": "Neyman et al\\.,? \\Q1933\\E", "shortCiteRegEx": "Neyman et al\\.", "year": 1933}, {"title": "Optimal decision rules in uncertain dichotomous choice situations", "author": ["Nitzan", "Shmuel", "Paroush", "Jacob"], "venue": "International Economic Review,", "citeRegEx": "Nitzan et al\\.,? \\Q1982\\E", "shortCiteRegEx": "Nitzan et al\\.", "year": 1982}, {"title": "Concentration of measure inequalities in information theory, communications and coding", "author": ["Raginsky", "Maxim", "Sason", "Igal"], "venue": "Foundations and Trends in Communications and Information Theory,", "citeRegEx": "Raginsky et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Raginsky et al\\.", "year": 2013}, {"title": "From PAC-Bayes bounds to quadratic programs for majority votes", "author": ["Roy", "Jean-Francis", "Laviolette", "Fran\u00e7ois", "Marchand", "Mario"], "venue": "In ICML, pp", "citeRegEx": "Roy et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Roy et al\\.", "year": 2011}, {"title": "Boosting. Foundations and algorithms. Adaptive Computation and Machine Learning", "author": ["Schapire", "Robert E", "Freund", "Yoav"], "venue": null, "citeRegEx": "Schapire et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Schapire et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 9, "context": "(3) Thus, wi is the log-odds of expert i being correct \u2014 and the voting rule in (2), also known as naive Bayes (Hastie et al., 2009), may be seen as a simple consequence of the Neyman-Pearson lemma (Neyman & Pearson, 1933).", "startOffset": 111, "endOffset": 132}, {"referenceID": 16, "context": "Even more recently, experts with adversarial noise have been considered (Mansour et al., 2013).", "startOffset": 72, "endOffset": 94}, {"referenceID": 11, "context": "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al.", "startOffset": 25, "endOffset": 47}, {"referenceID": 11, "context": "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al.", "startOffset": 25, "endOffset": 77}, {"referenceID": 11, "context": "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al. (2011) have developed a PAC-Bayesian theory for the majority vote of simple classifiers.", "startOffset": 25, "endOffset": 96}, {"referenceID": 11, "context": "In a recent line of work Lacasse et al. (2006); Laviolette & Marchand (2007); Roy et al. (2011) have developed a PAC-Bayesian theory for the majority vote of simple classifiers. This approach facilitates data-dependent bounds and is even flexible enough to capture some simple dependencies among the classifiers \u2014 though, again, the latter are learners as opposed to our experts. Even more recently, experts with adversarial noise have been considered (Mansour et al., 2013). More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al.", "startOffset": 25, "endOffset": 560}, {"referenceID": 6, "context": "More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al. (1989); Berend & Sapir (2007) which analyze various models of dependence among the experts.", "startOffset": 154, "endOffset": 175}, {"referenceID": 6, "context": "More directly related to the present work are the papers of Berend & Paroush (1998), which characterizes the consistency of the simple majority rule, and Boland et al. (1989); Berend & Sapir (2007) which analyze various models of dependence among the experts.", "startOffset": 154, "endOffset": 198}, {"referenceID": 0, "context": ", These adaptive bounds are similar in spirit to empirical Bernstein methods, (Audibert et al., 2007; Mnih et al., 2008; Maurer & Pontil, 2009), where the player\u2019s confidence depends on the empirical variance.", "startOffset": 78, "endOffset": 143}, {"referenceID": 19, "context": ", These adaptive bounds are similar in spirit to empirical Bernstein methods, (Audibert et al., 2007; Mnih et al., 2008; Maurer & Pontil, 2009), where the player\u2019s confidence depends on the empirical variance.", "startOffset": 78, "endOffset": 143}], "year": 2014, "abstractText": "We revisit the classical decision-theoretic problem of weighted expert voting from a statistical learning perspective. In particular, we examine the consistency (both asymptotic and finitary) of the optimal NitzanParoush weighted majority and related rules. In the case of known expert competence levels, we give sharp error estimates for the optimal rule. When the competence levels are unknown, they must be empirically estimated. We provide frequentist and Bayesian analyses for this situation. Some of our proof techniques are non-standard and may be of independent interest. The bounds we derive are nearly optimal, and several challenging open problems are posed. Experimental results are provided to illustrate the theory.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}