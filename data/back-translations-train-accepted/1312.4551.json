{"id": "1312.4551", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Dec-2013", "title": "Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs", "abstract": "We present an asymptotic analysis of Viterbi Training (VT) and contrast it with a more conventional Maximum Likelihood (ML) approach to parameter estimation in Hidden Markov Models. While ML estimator works by (locally) maximizing the likelihood of the observed data, VT seeks to maximize the probability of the most likely hidden state sequence. We develop an analytical framework based on a generating function formalism and illustrate it on an exactly solvable model of HMM with one unambiguous symbol. For this particular model the ML objective function is continuously degenerate. VT objective, in contrast, is shown to have only finite degeneracy. Furthermore, VT converges faster and results in sparser (simpler) models, thus realizing an automatic Occam's razor for HMM learning. For more general scenario VT can be worse compared to ML but still capable of correctly recovering most of the parameters.", "histories": [["v1", "Mon, 16 Dec 2013 21:03:28 GMT  (170kb)", "http://arxiv.org/abs/1312.4551v1", "Appeared in Neural Information Processing Systems (NIPS) 2011"]], "COMMENTS": "Appeared in Neural Information Processing Systems (NIPS) 2011", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["armen e allahverdyan", "aram galstyan"], "accepted": true, "id": "1312.4551"}, "pdf": {"name": "1312.4551.pdf", "metadata": {"source": "CRF", "title": "Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs", "authors": ["Armen Allahverdyan"], "emails": ["aarmen@yerphi.am", "galstyan@isi.edu"], "sections": [{"heading": null, "text": "ar Xiv: 131 2.45 51v1 [st at.M L] 16 D"}, {"heading": "1 Introduction", "text": "This year, it is so far that it only takes one year to get there like never before."}, {"heading": "2 Hidden Markov Process", "text": "Let S = {S0, S1, S2,...} be a discrete temporal, stationary Markov process with conditional probability Pr [Sk + l = sk | Sk \u2212 1 + l = sk \u2212 1] = p (sk | sk \u2212 1), (1) where l is an integer. Any realization sk of random variables Sk takes values 1,..., L. We assume that S is a mixture: It has a unique stationary distribution pst (s), \u2211 L r = 1p (s | r) pst (r) = pst (s), which is determined from any initial probability in the long time limit. Let random variables Xi be with realizations xi = 1,.., M, loud observations of Si: the (time variant) conditional probability of observation Xi = xi (r) = pst (s), the realization Si = si of the Markov process is a mixture (xk |)."}, {"heading": "3 Parameter Estimation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Maximum Likelihood Estimation", "text": "The unknown parameters of an HMM are the transition probabilities p (s | s) of the Markov process and the observation probabilities p (s | s); see (2). They must be estimated using the observed sequence x. By default, this is done using the maximum probability approach: one starts with certain values p (s | s), p (x | s) of the parameters and calculates the (log) probability ln P (x), where P (in practice) means the probability (4) calculated using the experimental values of the parameters. Next, one maximizes ln P (x) over p (s | s) and \u03c0 (x | s) for the given observed sequence x (in practice this is done using the tree-what algorithm [20, 9]). The reasoning for this approach is as follows: The maximum P (s) probability is long, and the mixing of the large (s) x (we) x-x-x."}, {"heading": "3.2 Viterbi Training", "text": "An alternative approach to the parameter learning uses the maximum a posteriori (MAP) estimate (\u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2, \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 (\u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2 \u03b2"}, {"heading": "3.3 Local Optimization", "text": "As already mentioned, global maximization is not generally feasible for either objective. Instead, in practice, this maximization is implemented locally by an EM algorithm [20, 9]: for a given observed sequence x and for some initial values of the parameters, the expected value of the objective function is calculated among the experimental parameters (E-step) and the parameters are adjusted to maximize this expectation (M-step). The resulting estimates of the parameters are now used as new experimental parameters and the previous step is repeated. This recursion continues until convergence. For our purposes, this method can be understood as calculating certain statistics of the hidden sequence averaged via the Gibbs distribution. 8. Let us actually introduce f\u03b3 (s), which occurs e\u00df\u03b3 (s), N i = 1\u043c (si + 1, a). \u2212 For our purposes, this method follows the calculation of certain statistics of the hidden sequence, which are mediated via the Gibbs distribution."}, {"heading": "4 Generating Function", "text": "Note of (4) that both P (x) and P (x) are taken together as matrix products (x). (For a large number of multipliers (1), the behavior of such products is governed by the multiplicative law of large numbers. Let's recall its formula of [10]: for N (y)] and x (generated by the X mixing process, there is a probability-one convergence: 1 N ln | T (x) | 1 N \u00b2 y P (y) ln \u03bb [T (y)]], (13), where the matrix standard in the linear space of L \u00b7 L matrices, and [T (x)] is the maximum eigenvalue of T (x). Note: (13) does not depend on the specific norm chosen, because all norms are equivalent in end-dimensional linear space; they differ by a multiplicative factor that disappears for N (10)."}, {"heading": "5 Hidden Markov Model with One Unambiguous Symbol", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Definition", "text": "In view of an L state Markov process S, the observed process X has two states 1 and 2; see Figure 1. (All internal states except one are observed as 2, while the internal state 1 produces 1 and 2 with probabilities 1 \u2212 1 and 2 respectively. For L = 3, we get \u03c0 (1 | 1) = 1 \u2212 \u03c0 (2 | 1) = 1 \u2212 3, \u03c0 (1 | 2) = \u03c0 (1 \u2212 3) = 0, \u03c0 (2 | 2) = \u03c0 (2 | 2) = \u03c0 (2 | 3) = 1. Therefore, 1 is clear: if it is observed, the unobserved process S was certainly in 1; see Figure 1. The simplest example of such an HMM already exists for L = 2; see [12] for analytical features of entropy in this case."}, {"heading": "5.2 Solution of the Model", "text": "Using the method outlined in the supplementary material (see also [1, 3]), we can determine that (z, n) = 1 \u2212 z (t0t, n0 + \u03c40\u03c4, n0) + \u2211. (Note: k = 2 [\u03c4, nk \u2212 2 \u2212 t, nk \u2212 1] zk (23), where \"case\" and \"case\" are the largest eigenvalues of T (2) and \"case\" (2), or \"case.\" < 1 | T (1). \u2212 T (2) k, nk \u2212 1] zk (23), where \"case\" and \"case\" case. \"are the largest eigenvalues of T (2) and\" case \"case\" (2)."}, {"heading": "6 The Simplest Non-Trivial Scenario", "text": "The following example allows full analytical treatment, but is general in that it contains all the key features of the more general situation given above (21). Suppose that L = 3 andq0 = q = 0 = r0 = r = 0, B = 0. (29) Note the following explicit expression st0 = p0, T1 = p1q1 + p2r1, T2 = p1r1q2 + p2q1r2, (30). (30). (30-32) Equations with obvious modifications si \u2192 s-i for each si symbol apply to T-k, T-k, and T-k (31)."}, {"heading": "6.1 Optimization of F1", "text": "Equations (27) and (30-32) imply that we k = 0 (k + 1) tk = \u00b5 1 \u2212 \u03c42, \u00b5 \u2261 1 \u2212 \u03c42 + t2 + (1 \u2212 t0) (1 + \u03c42) > 0, (34) \u2212 \u00b5F1 N = t1 ln 1 + t2 ln 2 + (1 \u2212 \u03c42) t0 ln 0 + (1 \u2212 t0) 2 ln 2. (35) Free energyF1 depends on three independent parameters t 0, t 1, t 2 [recall (33)]. Consequently, by minimizing F1 we get t i = ti (i = 0, 1, 2), but we do not get a definitive solution for the unknown parameters: any four numbers p 1, p 2, q 1, r 1 \u2212 1 p 2, t1 = 1q 1, p 2p 1 r (1 \u2212 1)."}, {"heading": "6.2 Optimization of F\u221e", "text": "In the derivative (35), of the derivative (2), of the derivative (2), of the derivative (2), of the derivative (2), of the derivative (2), of the derivative (2), of the derivative (2), of the (2), of the derivative (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2), of the (2, of the (2), of the (2), of the (2, of the (2), of the (2, of the (2), of the (2, of the (2), of the (2, of the (2), of the (2, of the (2), of the (2, of the (2), of the (2, of the (2), of the (2, of the), of the (2, of the (2, of the), of the (1, of the (1, of the), of the (1, of the (1), of the (1), of the (1, of the), of the (1, of the (1), of the (1), of the (1), of the (1, of the (1), of the (1, of the (1), of the (1), of the (1), of the (1, of the (1, of the (1), of the (1), of the (1), of the (1, of the (1), of the (1, of the (1), of the (1), the (1, of the (1), of the (1,"}, {"heading": "6.3 Viterbi EM", "text": "We remember the description of the VT algorithm given after (12). (Sk + 1 = a, Sk = b) via (11, 12) we modify the transfer matrix element in (15, 17) as T-ab (k) \u2192 T-ab (k) e\u03b3, which is modified by (11, 12) for the transition forecasts of the transition forecast 1 = t1- + t2- (1 \u2212 t2) + t0 (1 \u2212 t2) + t0 (1 \u2212 t2), p-t0 (40) r-1 = t1 \u2212 t0 (39) q-1 (39) q-p) via the transition forecast of the transition forecast 1 = t1- (1 \u2212 t1- t2) via the transition forecast 1 + t1- (39 \u2212 t2) via the transition forecast 1 = t1- (39 \u2212 p)."}, {"heading": "7 Summary", "text": "We presented a method for analyzing two basic techniques for estimating parameters in HMMs and illustrated them in a specific class of HMMs with a unique symbol. The virtue of this class of models is that it is precisely solvable, so the quantities sought can be obtained in a closed form through the creation of functions. This is a rare opportunity, because properties of HMM such as probability or entropy are notoriously difficult to calculate explicitly. An important feature of the example here is that the set of unknown parameters is not fully identifiable in the maximum probability that it is one. This corresponds to the zero value of the property of Hessic for the ML (maximum probability) objective function."}, {"heading": "Acknowledgments", "text": "This research was partially supported by the US ARO-MURI Scholarship No. W911NF0610094 and the US DTRA Scholarship HDTRA1-10-1-0086."}], "references": [{"title": "Entropy of Hidden Markov Processes via Cycle Expansion", "author": ["A.E. Allahverdyan"], "venue": "J. Stat. Phys. 133, 535 ", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2008}, {"title": "On Maximum a Posteriori Estimation of Hidden Markov Processes", "author": ["A.E. Allahverdyan", "A. Galstyan"], "venue": "Proc. of UAI, ", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2009}, {"title": "E", "author": ["R. Artuso"], "venue": "Aurell and P. Cvitanovic, Recycling of strange sets, Nonlinearity 3, 325 ", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1990}, {"title": "Bioinformatics", "author": ["P. Baldi", "S. Brunak"], "venue": "MIT Press, Cambridge, USA ", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2001}, {"title": "Statistical inference for probabilistic functions of finite state Markov chains", "author": ["L.E. Baum", "T. Petrie"], "venue": "Ann. Math. Stat. 37, 1554 ", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1966}, {"title": "Estimation of stochastic context-free grammars and their use as language models", "author": ["J.M. Benedi", "J.A. Sanchez"], "venue": "Comp. Speech and Lang. 19, pp. 249-274 ", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2005}, {"title": "On the identifiability problem for functions of finite Markov chains", "author": ["D. Blackwell", "L. Koopmans"], "venue": "Ann. Math. Statist. 28, 1011 ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1957}, {"title": "Viterbi training for PCFGs: Hardness results and competitiveness of uniform initialization", "author": ["S.B. Cohen", "N.A. Smith"], "venue": "Procs. of ACL ", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Hidden Markov processes", "author": ["Y. Ephraim", "N. Merhav"], "venue": "IEEE Trans. Inf. Th., 48, 1518-1569, ", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2002}, {"title": "Lyapunov indices of a product of random matrices", "author": ["L.Y. Goldsheid", "G.A. Margulis"], "venue": "Russ. Math. Surveys 44, 11 ", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1989}, {"title": "Universally Sloppy Parameter Sensitivities in Systems Biology Models", "author": ["R.N. Gutenkunst"], "venue": "PLoS Computational Biology,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Analyticity of entropy rate of hidden Markov chains", "author": ["G. Han", "B. Marcus"], "venue": "IEEE Trans. Inf. Th., 52, 5251 ", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Matrix Analysis (Cambridge", "author": ["R.A. Horn", "C.R. Johnson"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1985}, {"title": "Identifiability of Hidden Markov Information Sources", "author": ["H. Ito", "S. Amari", "K. Kobayashi"], "venue": "IEEE Trans. Inf. Th., 38, 324 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1992}, {"title": "On causally asymmetric versions of Occam\u2019s Razor and their relation to thermodynamics", "author": ["D. Janzing"], "venue": "arXiv:0708.3411 ", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2007}, {"title": "The segmental k-means algorithm for estimating parameters of hidden Markov models", "author": ["B.H. Juang", "L.R. Rabiner"], "venue": "IEEE Trans. Acoustics, Speech, and Signal Processing, ASSP-38, no.9, pp.1639-1641, ", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1990}, {"title": "Maximum-Likelihood Estimation for Hidden Markov Models", "author": ["B.G. Leroux"], "venue": "Stochastic Processes and Their Applications, 40, 127 ", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1992}, {"title": "Maximum likelihood hidden Markov modeling using a dominant sequence of states", "author": ["N. Merhav", "Y. Ephraim"], "venue": "IEEE Transactions on Signal Processing, vol.39, no.9, pp.2111-2115 ", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1991}, {"title": "Restoration of single-channel currents using the segmental k-means method based on hidden Markov modeling", "author": ["F. Qin"], "venue": "Biophys J 86, 14881501 ", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2004}, {"title": "A tutorial on hidden Markov models and selected applications in speech recognition", "author": ["L.R. Rabiner"], "venue": "Proc. IEEE, 77, 257 ", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1989}, {"title": "Comparative Study of the Baum-Welch and Viterbi Training Algorithms", "author": ["L.J. Rodriguez", "I. Torres"], "venue": "Pattern Recognition and Image Analysis, Lecture Notes in Computer Science, 2652/2003, 847 ", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2003}, {"title": "Statistical Mechanics", "author": ["D. Ruelle"], "venue": "Thermodynamic Formalism, ", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1978}, {"title": "Comparison between the inside-outside algorithm and the Viterbi algorithm for stochastic context-free grammars", "author": ["J. Sanchez", "J. Benedi", "F. Casacuberta"], "venue": "Adv. in Struct. and Synt. Pattern Recognition ", "citeRegEx": "23", "shortCiteRegEx": null, "year": 1996}, {"title": "Viterbi Training Improves Unsupervised Dependency Parsing", "author": ["V.I. Spitkovsky", "H. Alshawi", "D. Jurafsky", "C.D. Manning"], "venue": "Proc. of the 14th Conference on Computational Natural Language Learning ", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2010}], "referenceMentions": [{"referenceID": 19, "context": "The inference problems of HMM naturally divide into two classes [20, 9]: i) recovering the hidden sequence of states given the observed sequence, and ii) estimating the model parameters (transition probabilities of the hidden Markov chain and/or conditional probabilities of observations) from the observed sequence.", "startOffset": 64, "endOffset": 71}, {"referenceID": 8, "context": "The inference problems of HMM naturally divide into two classes [20, 9]: i) recovering the hidden sequence of states given the observed sequence, and ii) estimating the model parameters (transition probabilities of the hidden Markov chain and/or conditional probabilities of observations) from the observed sequence.", "startOffset": 64, "endOffset": 71}, {"referenceID": 19, "context": "The first class of problems is usually solved via the maximum a posteriori (MAP) method and its computational implementation known as Viterbi algorithm [20, 9].", "startOffset": 152, "endOffset": 159}, {"referenceID": 8, "context": "The first class of problems is usually solved via the maximum a posteriori (MAP) method and its computational implementation known as Viterbi algorithm [20, 9].", "startOffset": 152, "endOffset": 159}, {"referenceID": 19, "context": "Since global optimization is generally intractable, in practice it is implemented through an expectation\u2013 maximization (EM) procedure known as Baum\u2013Welch algorithm [20, 9].", "startOffset": 164, "endOffset": 171}, {"referenceID": 8, "context": "Since global optimization is generally intractable, in practice it is implemented through an expectation\u2013 maximization (EM) procedure known as Baum\u2013Welch algorithm [20, 9].", "startOffset": 164, "endOffset": 171}, {"referenceID": 7, "context": "Maximizing VT objective function is hard [8], so in practice it is implemented via an EM-style iterations between calculating the MAP sequence and adjusting the model parameters based on the sequence statistics.", "startOffset": 41, "endOffset": 44}, {"referenceID": 16, "context": "It is known that VT lacks some of the desired features of ML estimation such as consistency [17], and in fact, can produce biased estimates [9].", "startOffset": 92, "endOffset": 96}, {"referenceID": 8, "context": "It is known that VT lacks some of the desired features of ML estimation such as consistency [17], and in fact, can produce biased estimates [9].", "startOffset": 140, "endOffset": 143}, {"referenceID": 15, "context": "However, it has been shown to perform well in practice, which explains its widespread use in applications such as speech recognition [16], unsupervised dependency parsing [24], grammar induction [6], ion channel modeling [19].", "startOffset": 133, "endOffset": 137}, {"referenceID": 23, "context": "However, it has been shown to perform well in practice, which explains its widespread use in applications such as speech recognition [16], unsupervised dependency parsing [24], grammar induction [6], ion channel modeling [19].", "startOffset": 171, "endOffset": 175}, {"referenceID": 5, "context": "However, it has been shown to perform well in practice, which explains its widespread use in applications such as speech recognition [16], unsupervised dependency parsing [24], grammar induction [6], ion channel modeling [19].", "startOffset": 195, "endOffset": 198}, {"referenceID": 18, "context": "However, it has been shown to perform well in practice, which explains its widespread use in applications such as speech recognition [16], unsupervised dependency parsing [24], grammar induction [6], ion channel modeling [19].", "startOffset": 221, "endOffset": 225}, {"referenceID": 23, "context": "It is generally assumed that VT is more robust and faster but usually less accurate, although for certain tasks it outperforms conventional EM [24].", "startOffset": 143, "endOffset": 147}, {"referenceID": 17, "context": "[18] established", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "A similar attempt to compare both approaches on discrete models (for stochastic context free grammars) was presented in [23].", "startOffset": 120, "endOffset": 124}, {"referenceID": 0, "context": "Previously, a similar approach was used for calculating entropy rate of a hidden Markov process [1].", "startOffset": 96, "endOffset": 99}, {"referenceID": 6, "context": ", the model is not identifiable [7, 14, 9].", "startOffset": 32, "endOffset": 42}, {"referenceID": 13, "context": ", the model is not identifiable [7, 14, 9].", "startOffset": 32, "endOffset": 42}, {"referenceID": 8, "context": ", the model is not identifiable [7, 14, 9].", "startOffset": 32, "endOffset": 42}, {"referenceID": 8, "context": "Generally, it is not Markov, but it inherits stationarity and mixing from S [9].", "startOffset": 76, "endOffset": 79}, {"referenceID": 19, "context": "Next, one maximizes ln P\u0302 (x) over p\u0302(s|s\u2032) and \u03c0\u0302(x|s) for the given observed sequence x (in practice this is done via the Baum-Welch algorithm [20, 9]).", "startOffset": 145, "endOffset": 152}, {"referenceID": 8, "context": "Next, one maximizes ln P\u0302 (x) over p\u0302(s|s\u2032) and \u03c0\u0302(x|s) for the given observed sequence x (in practice this is done via the Baum-Welch algorithm [20, 9]).", "startOffset": 145, "endOffset": 152}, {"referenceID": 8, "context": "Provided that the length N of the observed sequence is long, and recaling that X is mixing (due to the analogous feature of S) we get probability-one convergence (law of large numbers) [9]: ln P\u0302 (x) \u2192 \u2211", "startOffset": 185, "endOffset": 188}, {"referenceID": 19, "context": "An alternative approach to the parameter learning employs the maximal a posteriori (MAP) estimation and proceeds as follows: Instead of maximizing the likelihood of observed data (5) one tries to maximize the probability of the most likely sequence [20, 9].", "startOffset": 249, "endOffset": 256}, {"referenceID": 8, "context": "An alternative approach to the parameter learning employs the maximal a posteriori (MAP) estimation and proceeds as follows: Instead of maximizing the likelihood of observed data (5) one tries to maximize the probability of the most likely sequence [20, 9].", "startOffset": 249, "endOffset": 256}, {"referenceID": 1, "context": "[2, 4]), we define an auxiliary (Gibbsian) probability", "startOffset": 0, "endOffset": 6}, {"referenceID": 3, "context": "[2, 4]), we define an auxiliary (Gibbsian) probability", "startOffset": 0, "endOffset": 6}, {"referenceID": 1, "context": "8 and 10 refer to, respectively, the Gibbs distribution and free energy of a physical system with Hamiltonian H = \u2212 lnP (s,x) coupled to a thermal bath at inverse temperature \u03b2 = 1/T [2, 4].", "startOffset": 183, "endOffset": 189}, {"referenceID": 3, "context": "8 and 10 refer to, respectively, the Gibbs distribution and free energy of a physical system with Hamiltonian H = \u2212 lnP (s,x) coupled to a thermal bath at inverse temperature \u03b2 = 1/T [2, 4].", "startOffset": 183, "endOffset": 189}, {"referenceID": 19, "context": "Instead, in practice this maximization is locally implemented via an EM-type algorithm [20, 9]: for a given observed sequence x, and for some initial values of the parameters, one calculates the expected value of the objective function under the trial parameters (E-step), and adjusts the parameters to maximize this expectation (M-step).", "startOffset": 87, "endOffset": 94}, {"referenceID": 8, "context": "Instead, in practice this maximization is locally implemented via an EM-type algorithm [20, 9]: for a given observed sequence x, and for some initial values of the parameters, one calculates the expected value of the objective function under the trial parameters (E-step), and adjusts the parameters to maximize this expectation (M-step).", "startOffset": 87, "endOffset": 94}, {"referenceID": 9, "context": "We now recall its formulation from [10]: for N \u2192 \u221e and x generated by the mixing process X there is a probability-one convergence: 1 N ln ||T(x)|| \u2192 1 N \u2211", "startOffset": 35, "endOffset": 39}, {"referenceID": 9, "context": "Note that (13) does not depend on the specific norm chosen, because all norms in the finite-dimensional linear space are equivalent; they differ by a multiplicative factor that disappears for N \u2192 \u221e [10].", "startOffset": 198, "endOffset": 202}, {"referenceID": 0, "context": "Its reformulation in terms of the maximal eigenvalue needs additional arguments [1].", "startOffset": 80, "endOffset": 83}, {"referenceID": 0, "context": "The behavior of \u039b (n,N) is better understood after expressing it via the zeta-function \u03be(z, n) [1]", "startOffset": 95, "endOffset": 98}, {"referenceID": 11, "context": "The simplest example of such HMM exists already for L = 2; see [12] for analytical features of entropy for this case.", "startOffset": 63, "endOffset": 67}, {"referenceID": 6, "context": "This model plays a special role for the HMM theory, since it was employed in the pioneering study of the non-identifiability problem [7].", "startOffset": 133, "endOffset": 136}, {"referenceID": 0, "context": "Using the method outlined in the supplementary material (see also [1, 3]) we get \u03be(z, n) = 1\u2212 z(t0t\u0302n0 + \u03c40\u03c4\u0302 0 ) + \u2211\u221e", "startOffset": 66, "endOffset": 72}, {"referenceID": 2, "context": "Using the method outlined in the supplementary material (see also [1, 3]) we get \u03be(z, n) = 1\u2212 z(t0t\u0302n0 + \u03c40\u03c4\u0302 0 ) + \u2211\u221e", "startOffset": 66, "endOffset": 72}, {"referenceID": 8, "context": "There is possibly a deeper point in the one-step convergence that can explain why in practice VT converges faster than the Baum-Welch algorithm [9, 21]: recall that, e.", "startOffset": 144, "endOffset": 151}, {"referenceID": 20, "context": "There is possibly a deeper point in the one-step convergence that can explain why in practice VT converges faster than the Baum-Welch algorithm [9, 21]: recall that, e.", "startOffset": 144, "endOffset": 151}, {"referenceID": 0, "context": "This is a rare occasion, because characteristics of HMM such as likelihood or entropy are notoriously difficult to calculate explicitly [1].", "startOffset": 136, "endOffset": 139}, {"referenceID": 6, "context": "An important feature of the example considered here is that the set of unknown parameters is not completely identifiable in the maximum likelihood sense [7, 14].", "startOffset": 153, "endOffset": 160}, {"referenceID": 13, "context": "An important feature of the example considered here is that the set of unknown parameters is not completely identifiable in the maximum likelihood sense [7, 14].", "startOffset": 153, "endOffset": 160}, {"referenceID": 10, "context": "This scenario occurs often in various models of physics and computational biology [11].", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "Hence, it is a drawback that the theory of HMM learning was developed assuming complete identifiably [5].", "startOffset": 101, "endOffset": 104}, {"referenceID": 14, "context": "Other connections of this type are discussed in [15].", "startOffset": 48, "endOffset": 52}], "year": 2013, "abstractText": "We present an asymptotic analysis of Viterbi Training (VT) and contrast it with a more conventional Maximum Likelihood (ML) approach to parameter estimation in Hidden Markov Models. While ML estimator works by (locally) maximizing the likelihood of the observed data, VT seeks to maximize the probability of the most likely hidden state sequence. We develop an analytical framework based on a generating function formalism and illustrate it on an exactly solvable model of HMM with one unambiguous symbol. For this particular model the ML objective function is continuously degenerate. VT objective, in contrast, is shown to have only finite degeneracy. Furthermore, VT converges faster and results in sparser (simpler) models, thus realizing an automatic Occam\u2019s razor for HMM learning. For more general scenario VT can be worse compared to ML but still capable of correctly recovering most of the parameters.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}