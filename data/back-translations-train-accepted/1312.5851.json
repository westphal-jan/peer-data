{"id": "1312.5851", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2013", "title": "Fast Training of Convolutional Networks through FFTs", "abstract": "Convolutional networks are one of the most widely employed architectures in computer vision and machine learning. In order to leverage their ability to learn complex functions, large amounts of data are required for training. Training a large convolutional network to produce state-of-the-art results can take weeks, even when using modern GPUs. Producing labels using a trained network can also be costly when dealing with web-scale datasets. In this work, we present a simple algorithm which accelerates training and inference by a significant factor, and can yield improvements of over an order of magnitude compared to existing state-of-the-art implementations. This is done by computing convolutions as pointwise products in the Fourier domain while reusing the same transformed feature map many times. The algorithm is implemented on a GPU architecture and addresses a number of related challenges.", "histories": [["v1", "Fri, 20 Dec 2013 08:42:21 GMT  (282kb,D)", "http://arxiv.org/abs/1312.5851v1", null], ["v2", "Wed, 22 Jan 2014 00:28:06 GMT  (132kb,D)", "http://arxiv.org/abs/1312.5851v2", null], ["v3", "Tue, 28 Jan 2014 01:33:21 GMT  (133kb,D)", "http://arxiv.org/abs/1312.5851v3", null], ["v4", "Tue, 18 Feb 2014 03:20:51 GMT  (134kb,D)", "http://arxiv.org/abs/1312.5851v4", null], ["v5", "Thu, 6 Mar 2014 23:27:18 GMT  (134kb,D)", "http://arxiv.org/abs/1312.5851v5", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["michael mathieu", "mikael henaff", "yann lecun"], "accepted": true, "id": "1312.5851"}, "pdf": {"name": "1312.5851.pdf", "metadata": {"source": "CRF", "title": "Fast Training of Convolutional Networks through FFTs", "authors": ["Michael Mathieu", "Mikael Henaff"], "emails": ["mathieu@cs.nyu.edu", "mbh305@nyu.edu", "yann@cs.nyu.edu"], "sections": [{"heading": "1 Introduction", "text": "While early benchmark datasets in machine learning contained thousands or tens of thousands of samples [5, 2, 8], current datasets are in the order of millions [4, 1]. This presents new challenges in how networks can be trained in a workable time span. Even using parallel computer environments, training a network on ImageNet can take weeks [6]. Furthermore, although the inference of labels using a trained network is comparatively fast, real-world applications such as producing labels for all images on the Internet can represent significant costs in terms of time and resources. Therefore, there is an important need to develop fast algorithms for training and inferences. In this paper, we present a simple algorithm that accelerates training and inference with evolutionary networks."}, {"heading": "2 Theory", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Backpropagation", "text": "The backward propagation algorithm [7] is the standard method for calculating the gradient in the formation of a revolutionary network. During the training, each layer performs three tasks, which we will now describe. First, we repair some notations: for a given layer, we have a series of input feature maps xf indexed by f, each of which has a 2-D image of the dimensions n \u00b7 n. The output consists of a series of feature maps yf \u2032 indexed by f \u2032, which are also 2-D images, the dimension of which depends on the revolutionary core and its gradient. The transferable parameters of the layer consist of a set of weight maps wf \u2032 f, each of which is a small core of the dimensions k \u00b2 k. In the forward step, each output feature map is calculated as the sum of the input feature maps entangled with the corresponding traceable weight core: yf \u2032 f = f \u00b2 f \u00b2, the sum of the input \u00b2 wf \u00b2 are the sum of the maps (1)."}, {"heading": "2.2 Algorithm", "text": "The well-known convolution theorem states that convolutions in the spatial domain are equivalent to pointwise products in the Fourier domain. If F recognizes the Fourier transformation and F \u2212 1 its inversion, we can calculate the convolutions between functions f and g as follows: f \u0445 g = F \u2212 1 (F (f) \u00b7 F (g)))) Typically, this method is used when the size of the convolution-based kernel is close to that of the input image. Note that convolution of an image of size n \u00b7 n with a kernel of size k \u00b7 k requires operations using the direct method O (n2k2).The complexity of the FFT-based method requires O (6n2 protocol n + n2) operations: Any FFT requiresO (n2 protocol n2) = O (2n2 protocol n), and the pointed product in the frequency domain requires 2."}, {"heading": "2.3 Implementation", "text": "Although conceptually straightforward, a number of challenges related to the GPU implementation had to be addressed. Firstly, current GPU implementations of FFT such as cuFFT are designed to run in parallel with individual transformations, which can be useful for calculating a limited number of transformations on large inputs, but are not suitable for our task as we perform many FFTs via relatively small inputs. Therefore, we developed a custom CUDA implementation of the CooleyTukey FFT algorithm, which allowed us to determine how many threads should be allocated to each FFT while simultaneously paralleling feature maps and minibatches. Two-dimensional transformations were performed by calculating one-dimensional transformations across rows and columns in place to save memory on the GPU. As a further means of saving memory, we used symmetric transformations from FTs to only half of the GPU properties."}, {"heading": "3 Experiments", "text": "To test our analysis, we conducted a series of experiments in which we compared the speed of our method with the GPU implementations of [6] and the Torch 7 machine learning environment [3]. Specifically, we compared how each method performed with different core sizes, input sizes and minibatch sizes; the results are shown in Figure 3. For all experiments, we chose 96 input feature maps and 256 output features, which is a typical configuration of the second layer of a deep network. the functions updateOutput, updateGradInput and accGradParameters correspond to the operations in (1), (2) and (3), respectively. All times are measured in seconds. We see that our method significantly outperforms the other two in almost all cases. The improvement is particularly pronounced for the accGradInput and accGradParameters operation, which is the most expensive in arithmetic terms. This is probably due to the fact that we calculate the sum that we have for each FTnel, in addition to the fact that we have a large FTP in each case."}, {"heading": "4 Discussion", "text": "We have presented a simple and fast algorithm for training and concluding using Convolutionary Networks, which, as demonstrated by numerical experiments, exceeds the known state of the art in terms of speed. In the future, we plan to explore the possibilities of learning nuclei directly in the Fourier domain, thereby eliminating the need to specify core quantities as hyperparameters."}], "references": [{"title": "The million song dataset", "author": ["Thierry Bertin-Mahieux", "Daniel P.W. Ellis", "Brian Whitman", "Paul Lamere"], "venue": "In Proceedings of the 12th International Conference on Music Information Retrieval", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Representing shape with a spatial pyramid kernel", "author": ["A. Bosch", "A. Zisserman", "X. Munoz"], "venue": "In Proceedings of the ACM International Conference on Image and Video Retrieval,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Torch7: A matlab-like environment for machine learning", "author": ["Ronan Collobert", "Koray Kavukcuoglu", "Clement Farabet"], "venue": "In NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Jia Deng", "Wei Dong", "Richard Socher", "Li-Jia Li", "Kai Li", "Li Fei-Fei"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2009}, {"title": "Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object", "author": ["L. Fei-Fei", "R. Fergus", "Pietro Perona"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E. Hinton"], "venue": "In NIPS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2012}, {"title": "Efficient backprop", "author": ["Y. LeCun", "L. Bottou", "G. Orr", "K. Muller"], "venue": "Neural Networks: Tricks of the trade. Springer,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1998}, {"title": "Musical genre classification of audio signals", "author": ["G. Tzanetakis", "P. Cook"], "venue": "IEEE Transactions on Speech and Audio Processing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}], "referenceMentions": [{"referenceID": 4, "context": "While early benchmark datasets in machine learning contained thousands or tens of thousands of samples [5, 2, 8], current datasets are of the order of millions [4, 1].", "startOffset": 103, "endOffset": 112}, {"referenceID": 1, "context": "While early benchmark datasets in machine learning contained thousands or tens of thousands of samples [5, 2, 8], current datasets are of the order of millions [4, 1].", "startOffset": 103, "endOffset": 112}, {"referenceID": 7, "context": "While early benchmark datasets in machine learning contained thousands or tens of thousands of samples [5, 2, 8], current datasets are of the order of millions [4, 1].", "startOffset": 103, "endOffset": 112}, {"referenceID": 3, "context": "While early benchmark datasets in machine learning contained thousands or tens of thousands of samples [5, 2, 8], current datasets are of the order of millions [4, 1].", "startOffset": 160, "endOffset": 166}, {"referenceID": 0, "context": "While early benchmark datasets in machine learning contained thousands or tens of thousands of samples [5, 2, 8], current datasets are of the order of millions [4, 1].", "startOffset": 160, "endOffset": 166}, {"referenceID": 5, "context": "Even using parallel computing environments, training a network on ImageNet can take weeks [6].", "startOffset": 90, "endOffset": 93}, {"referenceID": 6, "context": "1 Backpropagation The backpropagation algorithm [7] is the standard method to compute the gradient when training a convolutional network.", "startOffset": 48, "endOffset": 51}, {"referenceID": 5, "context": "3 Experiments To test our analysis, we ran a series of experiments comparing the speed of our method compared to the GPU implementations of [6] and of the Torch 7 machine learning environment [3].", "startOffset": 140, "endOffset": 143}, {"referenceID": 2, "context": "3 Experiments To test our analysis, we ran a series of experiments comparing the speed of our method compared to the GPU implementations of [6] and of the Torch 7 machine learning environment [3].", "startOffset": 192, "endOffset": 195}], "year": 2016, "abstractText": "Convolutional networks are one of the most widely employed architectures in computer vision and machine learning. In order to leverage their ability to learn complex functions, large amounts of data are required for training. Training a large convolutional network to produce state-of-the-art results can take weeks, even when using modern GPUs. Producing labels using a trained network can also be costly when dealing with web-scale datasets. In this work, we present a simple algorithm which accelerates training and inference by a significant factor, and can yield improvements of over an order of magnitude compared to existing state-of-the-art implementations. This is done by computing convolutions as pointwise products in the Fourier domain while reusing the same transformed feature map many times. The algorithm is implemented on a GPU architecture and addresses a number of related challenges.", "creator": "LaTeX with hyperref package"}}}