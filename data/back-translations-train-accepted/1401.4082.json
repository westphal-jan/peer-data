{"id": "1401.4082", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jan-2014", "title": "Stochastic Backpropagation and Approximate Inference in Deep Generative Models", "abstract": "We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic back-propagation -- rules for back-propagation through stochastic variables -- and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.", "histories": [["v1", "Thu, 16 Jan 2014 16:33:23 GMT  (4873kb,D)", "http://arxiv.org/abs/1401.4082v1", "Under review"], ["v2", "Fri, 9 May 2014 12:53:17 GMT  (33347kb,D)", "http://arxiv.org/abs/1401.4082v2", "Appears in Proceedings of the 31st International Conference on Machine Learning (ICML), Beijing, China, 2014"], ["v3", "Fri, 30 May 2014 10:00:36 GMT  (33346kb,D)", "http://arxiv.org/abs/1401.4082v3", "Appears In Proceedings of the 31st International Conference on Machine Learning (ICML), JMLR: W\\&amp;CP volume 32, 2014"]], "COMMENTS": "Under review", "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG stat.CO stat.ME", "authors": ["danilo jimenez rezende", "shakir mohamed", "daan wierstra"], "accepted": true, "id": "1401.4082"}, "pdf": {"name": "1401.4082.pdf", "metadata": {"source": "META", "title": "Stochastic Back-propagation and Variational Inference in  Deep Latent Gaussian Models", "authors": ["Danilo Jimenez Rezende", "Shakir Mohamed", "Daan Wierstra"], "emails": ["daan}@deepmind.com"], "sections": [{"heading": "1. Introduction", "text": "There is a huge effort in machine learning and statistics to develop precise and scalable models."}, {"heading": "2. Deep Latent Gaussian Models", "text": "The model consists of L-layers of latent variables. To generate a sample from the model, we start at the top layer (L) by starting from the top layer (L) by starting from the top layer of the Gaussian distribution. This process is graphically described in Figure 1. This generative process is described by the following equations: L = N, I), l = 1,., L (1) hL = GL.L, (2) hl = Tl (hl + 1) + Gl.L, l = 1. We are."}, {"heading": "3. Stochastic Back-propagation", "text": "The key tool we are developing to enable efficient inference is the rulebook for calculating gradients in models with random variables. We develop these identities and refer to them as rules for stochastic backflow. Gradient lineage methods in latent variable models typically require calculations of the form in which the distribution q is a K-dimensional Gaussian rule, where unfortunately there are a number of parameters of a distributional quantum. In this setting, gradients can be calculated using Gaussian gradient identities. Of particular interest are cases where the distribution q is a K-dimensional Gaussian rule. N (Gaussian, C) requires a K-dimensional Gaussian rule with parameters."}, {"heading": "1. Using the product rule for integrals.", "text": "For many exponential family distributions, it is possible to use the product rule for integrals to express the gradient in terms of parameters (mean or natural) as an expectation of gradients in relation to the random variables themselves. (10) In this way, we can reduce the problem to finding a suitable transformation function that allows us to calculate the required derivatives directly. This approach can be used to derive rules for many other distributions, such as Gaussian, inverse gamma, logNormal and forest distributions."}, {"heading": "2. Using suitable co-ordinate transformations.", "text": "We can also derive stochastic distribution rules for any distribution that can be written as a smooth, invertible transformation of a canonical base distribution. For example, any Gaussian distribution N (\u00b5, C) can be obtained as a transformation of a spherical Gaussian distribution N (0, I) using the transformation y = \u00b5 + R and C = RR > This coordinate transformation makes it possible to write the gradient of expectation with respect to R in such a way that g is the gradient for f that is evaluated at \u00b5 + R and represents a cheaper alternative to the price theorem (8). In general, the estimator (11) will have a higher variance than the estimators based on (8).A brief analysis of the variance of these estimators will discuss section 5 and in Annex B represent a cheaper alternative to the price theorem (8)."}, {"heading": "4. Scalable Inference in DLGMs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Free Energy Objective", "text": "To make a conclusion in DLGMs, we integrate the effect of the latent variables and demand that we calculate the integrated or marginal probability. Generally, this will be an intractable integration, and instead we optimize a lower limit for the marginal probability. We introduce an approximate posterior distribution q and apply Jensen's inequality (Zemel, 1993; Beal, 2003) to obtain the following values: log p (V) = log p (V) = log p (VE) dB = log q (VE) q (VE) q (VE) p (VE, VE) p (VE) p (VE, VE) p (VE) p (VE) = \u2212 DKL (VE) p (VE) + Eq [log p (VE), p (VE) p (VE).We use the non-variable energy model as our objective function."}, {"heading": "4.2. Parameterising the Recognition Covariance", "text": "There are a number of approaches to parameterizing the covariance matrix of the detection model. Maintaining a full covariance matrix C in Equation (14) would entail an algorithmic complexity O (LK3), where K is the number of latent variables per layer and L is the number of latent layers. The simplest approach is to use a diagonal covariance matrix C = diag (d), where d is a K-dimensional vector. This approach is attractive because it allows linear time calculation and sampling, but only an axis-oriented posterior distribution. We can improve the diagonal approximation by looking at a structured covariance parameterized by two independent vectors d and u. We parameterize the precision matrix C \u2212 1 (Magdon-Ismail & Purnell, 2010): D \u2212 d variance \u2212 d as d, d (15)."}, {"heading": "4.3. Gradients of the Free Energy", "text": "We want to minimize the free energy F (V) (14) using stochastic gradient parentage methods to calculate the difference between the two parameters of the generative model and the recognition model. (18) Gradients in relation to the jth generative parameter \u03b8gj (V) can be calculated by approximation (18) with a small number of samples from q (or even a single sample). (18) To obtain gradients in relation to the recognition parameters \u03b8r, we use the rules for Gaussian reproduction developed in Section 3. To address the complexity of the Hessian model in general rule (9), we use the coordinate transformation for the Gaussians to write the differentiation in relation to the function of the Gaussians."}, {"heading": "4.4. Algorithm Summary and Complexity", "text": "Figure 1 (c) shows the computational flow in the model. Our algorithm assumes that it performs a forward step (black arrows): consisting of a bottom-up phase (detection phase) and a top-down phase (generation phase) that updates the hidden activations of the detection model and the parameters of any Gaussian distributions; and a reverse step (red arrows) in which gradients are calculated using the corresponding reverse propagation rule for deterministic and stochastic layers. We perform a gradient downward step using the following distribution steps: (1). The learning procedure is summarized in Algorithm (1): The computational complexity for generating S samples from the generative model is O (SLK)."}, {"heading": "5. Related Work", "text": "Our model refers directly to non-linear distribution models at higher levels, whose means, however, depend on a non-linear change at higher levels. (SBN) (SBN) (1996) are closely related and are models with Bernoulli variables at each level. Both models are formed by a medium field of variable algorithms. (SBN) (2013) is a newer model that builds a direct graphical model using autoregressive Bernoulli distributions. (Gaussian Process of latent variable models (GPLVM, 2005) is the non-parametric analogy of our model, which uses autoregressive Bernoulli distributions at each level."}, {"heading": "6. Results", "text": "Generative models, such as the deep latent Gaussian model, on which we focus, have a number of applications in the fields of simulation, prediction, data visualization, missing data imputation, and other forms of probabilistic thinking. We describe the testing methodology we use and present results on a number of these tasks."}, {"heading": "6.1. Testing Methodology", "text": "We use training data of various types, including binary and counting-based data sets. In all cases, we train with mini-lots, which requires the introduction of scalable terms in the free energy objective function (14) in order to maintain the correct scaling between the previous value above the parameters and the remaining terms (Ahn et al., 2012; Welling & Teh, 2011). We use the target: F (V) = \u2212 \u03bb; n Eq [log p (vn | h (\u0218n)] + 12\u043c. Equal is the relationship between the data set and the mini-batch size. With each iteration, a random mini-batch of the size 200 observations is chosen.All parameters of the model were calculated using samples from the Gaussian detection and the mini-batch size."}, {"heading": "6.2. Analysing the Approximate Posterior", "text": "The specification of the detection model influences how well we are able to gather the statistics of the data and the accuracy and efficiency of learning. We examine the quality of the approximate posterior distribution learned by the detection model compared to the true posterior distribution by using a deep latent Gaussian model on the MNIST dataset of handwritten images. The images are of the size 28 x 28, and we use the binarized dataset from Larochelle & Murray (2011).We use sampling to evaluate the true posterior distribution for a number of MNIST digits under the diago-nal and the structured covariance parameterization of the detection model described in Section 4.2. We visualize the posterior distribution for a model with two Gaussian latent variables in Figure 2. The true posterior distribution is shown by the gray regions and was calculated by importance sampling."}, {"heading": "6.3. Simulation and prediction", "text": "The model consists of two deterministic layers with 200 hidden units and a stochastic layer with 200 latent variables. We use mini-batches with 200 observations and trained the model using stochastic reverse propagation. Examples from this model are in Figure 3. We also compare the test log probability with a large number of existing approaches in Table 1. We used exactly the data set used in Uria et al. (2013) and quote the protocol probabilities in the lower part of the table from this work. These results show that we are able to compete with some of the best models currently available. The numbers generated also match well with the true data and appear visually as good as some of the best visualizations from these competing approaches. We also analyzed the performance of our model with three high-dimensional real image sets. The NORB object identification datasets consist of 24, 300 images displayed in this competing model 96 x x x x x x x x x x x x x x x x"}, {"heading": "6.4. Missing Data Imputation and Denoising", "text": "Data from http: / / www.cs. nyu.edu / ~ roweis / data.htmlmatics and experimental design. We demonstrate the model's ability to randomly add missing data using the MNIST dataset. We test imputability under two different error types (Little & Rubin, 1987): Missing-at-random (MAR), where we consider 60% and 80% of the pixels missing, and Not Missing-at-random (NMAR), where we consider a square region of the image missing. In both test cases, the model produces very good completions. There is uncertainty in the identity of the image, which is expected and reflected in the errors in these completions as the reampling procedure is performed, and further demonstrates the model's ability to capture the diversity of the underlying data."}, {"heading": "6.5. Data Visualisation", "text": "We project the MNIST dataset onto a 2-dimensional latent space and use this 2-D embedding to visualize the data. A 2-dimensional embedding of the MNIST dataset is shown in Figure 6. The classes are divided into different regions, suggesting that such a tool can be useful for gaining insights into the structure of high-dimensional datasets."}, {"heading": "7. Discussion", "text": "Our algorithm generalizes to a broad class of models with continuous latent variables, including Gaussian, non-negative, or parity-enhancing latent variables. Models with discrete latent variables (e.g. sigmoid belief networks) remain the most common but intelligent design to control gradient variance in high-dimensional environments, typically using a large number of latent variables. In this environment, and under the appropriate conditions, the required expectations for Gaussian integral inferences could be well approximated. Therefore, we believe that our approach is also applicable in high-dimensional discrete environments: We can apply the gradient estimators derived in Section 4 as an approximation in high-dimensional latent variable models, and potentially obtain new learning rules for these models."}, {"heading": "8. Conclusion", "text": "We developed a class of universal and flexible generative models with Gaussian latent variables at each level. Our approach introduces a recognition model that can be considered a stochastic encoding of the data to allow for efficient and traceable conclusions. We derived a lower limit on the boundary probability of the generative model and specified the structure and regulation of the recognition model by taking advantage of recent advances in deep learning. By developing modified rules for replication by stochastic layers, we derived an efficient inference algorithm that allows common optimization of all parameters, i.e. parameters of generative and recognition models. We have demonstrated from several real data sets that the model produces realistic samples, provides accurate implications of missing data, and can be a useful tool for high-dimensional data visualization."}, {"heading": "A. Additional Model Details", "text": "In Equation (6), we showed an alternative form of articular log probability that explicitly states that the generative model works by applying a highly nonlinear transformation to a spherical Gaussian distribution (3) in such a way that the transformed distribution best corresponds to the empirical distribution. From the model description (3), (4), we can interpret the variable hl as a deterministic function of the sound variable (5), which can be formally introduced as a coordinate transformation of probability density in Equation (5): We perform a change in the coordinates hl. The density of the transformed variable can be expressed in terms of density (5), the determinant of the jacobic transformation p (3) = p (h) = p (h))))) | v (h (l) = 1 = L = 1 (l). Since the coordinate transformability (l) is linear, we have a linear turn as an index."}, {"heading": "B. Deriving Stochastic Back-propagation Rules", "text": "In Section 3, we have described two ways in which we can derive the stochastic redistribution rules. We show specific examples and provide some more discussions in this section. Using the product rule for integralsWe can derive rules for the stochastic redistribution rules for many distributions by finding a suitable nonlinear function that allows us to directly express the gradient in relation to the parameters of the distribution as gradients in relation to the random variable.The approach we have described in the main text was: Finding a suitable nonlinear function that allows us to consider the gradient in relation to the distribution as gradients in relation to the random variable."}, {"heading": "C. Univariate variance analysis", "text": "In analyzing the variance properties of many estimators, we showed the general scaling of the probability quotient approaches in Section 5. As an example of the further emphasis on the variance nature of these alternative approaches, we present a brief analysis in the univariate case. Consider a random variable p (B) = N (E) and a simple square function of the form f (E) = c (22). (34) For this function, we immediately obtain the following variancesV ar [B (E) = c2\u03c32 (35) V ar [B (E)] = 0 (36) V ar [B (E)] = 0 (E) V ar (E) x (E) x (B) x (F) = 2c2\u03c32 + \u00b52c2 (37) V ar [B (E) x (F) \u2212 E [F (E)] = 2 c2\u00b52 (38) x (38) equations (36) and (37) V ar [B (E) x), with the variance of the IN38 + (E) equality (E) (2 \u00b5F) (E = 211) x (E)."}, {"heading": "D. Estimating the Marginal Likelihood", "text": "We calculate the marginal probability on the basis of meaning samples by generating S samples from the detection model and using the following estimator: p (v) \u2248 1 S \u0445 s = 1 p (v | h (\u0432 (s))) p (\u0432 (s)) q (\u0424s); \u044b (s) \u0445 q (\u0432 | v) (39)"}, {"heading": "E. Missing Data Imputation", "text": ", (), (), (,), (,), (,), (,), (,), (,), (,), (,), (,), (,), (,), (,), (,), (,), (,), (,), (, (,), (,), (,), (, (,), (,), (, (,), (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (,), (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (,), (, (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (, (,), (, (,), (, (,), (,), (, (, (,), (,), (, (,), (, (,), (, (,), (, (,), (, (,), (, (, (,), (,), (, (,), (,), (, (,), (,), (, (, (,), (, (, (,), (,),), (, (,), (, (, (,)"}, {"heading": "G. Additional Related Work", "text": "The model class described here builds on other widely used models with latent Gaussian distributions and provides an inference mechanism for use within this diverse model class. Recognition of the latent Gaussian structure shows the link to models such as generalized linear regression, Gaussian process regression, factor analysis, probable principal component analysis, stochastic volatility models, and other latent Gaussian graphical models (such as logical-Gaussian Cox processes and covariance selection models). Alternative inference approaches. The most common approach to inferences in deep-set models was variable EM. Alternate minimization often suffers from slow convergence, expensive parameter learning steps, and typically requires the specification of additional local boundaries to allow for efficient compression of required expectations. Alternate sleep optimization models are also based on varying EM."}], "references": [{"title": "Bayesian posterior sampling via stochastic gradient Fisher scoring", "author": ["S. Ahn", "A.K. Balan", "M. Welling"], "venue": "In ICML,", "citeRegEx": "Ahn et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ahn et al\\.", "year": 2012}, {"title": "Latent variable models and factor analysis, volume 7 of Kendall\u2019s library of statistics", "author": ["D.J. Bartholomew", "M. Knott"], "venue": null, "citeRegEx": "Bartholomew and Knott,? \\Q1999\\E", "shortCiteRegEx": "Bartholomew and Knott", "year": 1999}, {"title": "Variational Algorithms for approximate Bayesian inference", "author": ["M.J. Beal"], "venue": "PhD thesis, University of Cambridge,", "citeRegEx": "Beal,? \\Q2003\\E", "shortCiteRegEx": "Beal", "year": 2003}, {"title": "Generalized denoising auto-encoders as generative models", "author": ["Y. Bengio", "L. Yao", "G. Alain", "P. Vincent"], "venue": null, "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Transformations des signaux al\u00e9atoires a travers les syst\u00e8mes non lin\u00e9aires sans m\u00e9moire", "author": ["G. Bonnet"], "venue": "Annales des Te\u0301le\u0301communications,", "citeRegEx": "Bonnet,? \\Q1964\\E", "shortCiteRegEx": "Bonnet", "year": 1964}, {"title": "Helmholtz machines and wake-sleep learning. Handbook of Brain Theory and Neural Network", "author": ["P. Dayan"], "venue": null, "citeRegEx": "Dayan,? \\Q2000\\E", "shortCiteRegEx": "Dayan", "year": 2000}, {"title": "Variational inference for continuous sigmoidal Bayesian networks", "author": ["B.J. Frey"], "venue": "6th International Workshop on Artificial Intelligence and Statistics,", "citeRegEx": "Frey,? \\Q1996\\E", "shortCiteRegEx": "Frey", "year": 1996}, {"title": "Variational learning in nonlinear Gaussian belief networks", "author": ["B.J. Frey", "G.E. Hinton"], "venue": "Neural Computation,", "citeRegEx": "Frey and Hinton,? \\Q1999\\E", "shortCiteRegEx": "Frey and Hinton", "year": 1999}, {"title": "Practical variational inference for neural networks", "author": ["A. Graves"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Graves,? \\Q2011\\E", "shortCiteRegEx": "Graves", "year": 2011}, {"title": "Deep autoregressive networks", "author": ["K. Gregor", "A. Mnih", "D. Wierstra"], "venue": "ArXiv preprint", "citeRegEx": "Gregor et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2013}, {"title": "Stochastic variational inference", "author": ["M. Hoffman", "D.M. Blei", "C. Wang", "J. Paisley"], "venue": "arXiv preprint arXiv:1206.7051,", "citeRegEx": "Hoffman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 2012}, {"title": "Auto-encoding variational Bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling", "year": 2013}, {"title": "The neural autoregressive distribution estimator", "author": ["H. Larochelle", "I. Murray"], "venue": "Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS), JMLR W&CP 15:29\u201337,", "citeRegEx": "Larochelle and Murray,? \\Q2011\\E", "shortCiteRegEx": "Larochelle and Murray", "year": 2011}, {"title": "Probabilistic non-linear principal component analysis with Gaussian process latent variable models", "author": ["N. Lawrence"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Lawrence,? \\Q2005\\E", "shortCiteRegEx": "Lawrence", "year": 2005}, {"title": "Approximating the covariance matrix of GMMs with low-rank perturbations", "author": ["M. Magdon-Ismail", "J.T. Purnell"], "venue": null, "citeRegEx": "Magdon.Ismail and Purnell,? \\Q2010\\E", "shortCiteRegEx": "Magdon.Ismail and Purnell", "year": 2010}, {"title": "A family of algorithms for approximate Bayesian inference", "author": ["T. Minka"], "venue": "PhD thesis,", "citeRegEx": "Minka,? \\Q2001\\E", "shortCiteRegEx": "Minka", "year": 2001}, {"title": "Probabilistic inference using Markov Chain Monte Carlo methods", "author": ["R.M. Neal"], "venue": "Technical Report CRG-TR-93-1, University of Toronto,", "citeRegEx": "Neal,? \\Q1993\\E", "shortCiteRegEx": "Neal", "year": 1993}, {"title": "The variational Gaussian approximation revisited", "author": ["M. Opper", "C. Archambeau"], "venue": "Neural computation,", "citeRegEx": "Opper and Archambeau,? \\Q2009\\E", "shortCiteRegEx": "Opper and Archambeau", "year": 2009}, {"title": "A useful theorem for nonlinear devices having Gaussian inputs", "author": ["R. Price"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Price,? \\Q1958\\E", "shortCiteRegEx": "Price", "year": 1958}, {"title": "Approximate Bayesian inference for latent Gaussian models by using integrated nested Laplace approximations", "author": ["H. Rue", "S. Martino", "N. Chopin"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Rue et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Rue et al\\.", "year": 2009}, {"title": "Mean field theory for sigmoid belief networks", "author": ["L.K. Saul", "T. Jaakkola", "M.I. Jordan"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Saul et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Saul et al\\.", "year": 1996}, {"title": "A deep and tractable density estimator", "author": ["B. Uria", "I. Murray", "H. Larochelle"], "venue": "ArXiv preprint", "citeRegEx": "Uria et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Uria et al\\.", "year": 2013}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["M. Welling", "Y.W. Teh"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Welling and Teh,? \\Q2011\\E", "shortCiteRegEx": "Welling and Teh", "year": 2011}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["R.J. Williams"], "venue": "Machine Learning,", "citeRegEx": "Williams,? \\Q1992\\E", "shortCiteRegEx": "Williams", "year": 1992}, {"title": "A minimum description length framework for unsupervised learning", "author": ["R.S. Zemel"], "venue": null, "citeRegEx": "Zemel,? \\Q1993\\E", "shortCiteRegEx": "Zemel", "year": 1993}], "referenceMentions": [{"referenceID": 6, "context": "ilar latent variable models (Dayan et al., 1995; Frey, 1996; Saul et al., 1996; Bartholomew & Knott, 1999; Uria et al., 2013; Gregor et al., 2013) can be easily sampled from, but in most cases, efficient inference algorithms have remained elusive.", "startOffset": 28, "endOffset": 146}, {"referenceID": 20, "context": "ilar latent variable models (Dayan et al., 1995; Frey, 1996; Saul et al., 1996; Bartholomew & Knott, 1999; Uria et al., 2013; Gregor et al., 2013) can be easily sampled from, but in most cases, efficient inference algorithms have remained elusive.", "startOffset": 28, "endOffset": 146}, {"referenceID": 21, "context": "ilar latent variable models (Dayan et al., 1995; Frey, 1996; Saul et al., 1996; Bartholomew & Knott, 1999; Uria et al., 2013; Gregor et al., 2013) can be easily sampled from, but in most cases, efficient inference algorithms have remained elusive.", "startOffset": 28, "endOffset": 146}, {"referenceID": 9, "context": "ilar latent variable models (Dayan et al., 1995; Frey, 1996; Saul et al., 1996; Bartholomew & Knott, 1999; Uria et al., 2013; Gregor et al., 2013) can be easily sampled from, but in most cases, efficient inference algorithms have remained elusive.", "startOffset": 28, "endOffset": 146}, {"referenceID": 2, "context": "A number of approaches are known and currently used, in particular algorithms based on mean-field variational EM (Beal, 2003), the wake-sleep algorithm (Dayan, 2000), policygradient methods such as REINFORCE (Williams, 1992), or stochastic gradient methods (Hoffman et al.", "startOffset": 113, "endOffset": 125}, {"referenceID": 5, "context": "A number of approaches are known and currently used, in particular algorithms based on mean-field variational EM (Beal, 2003), the wake-sleep algorithm (Dayan, 2000), policygradient methods such as REINFORCE (Williams, 1992), or stochastic gradient methods (Hoffman et al.", "startOffset": 152, "endOffset": 165}, {"referenceID": 23, "context": "A number of approaches are known and currently used, in particular algorithms based on mean-field variational EM (Beal, 2003), the wake-sleep algorithm (Dayan, 2000), policygradient methods such as REINFORCE (Williams, 1992), or stochastic gradient methods (Hoffman et al.", "startOffset": 208, "endOffset": 224}, {"referenceID": 10, "context": "A number of approaches are known and currently used, in particular algorithms based on mean-field variational EM (Beal, 2003), the wake-sleep algorithm (Dayan, 2000), policygradient methods such as REINFORCE (Williams, 1992), or stochastic gradient methods (Hoffman et al., 2012).", "startOffset": 257, "endOffset": 279}, {"referenceID": 4, "context": "which are due to the theorems by Bonnet (1964) and Price (1958), respectively.", "startOffset": 33, "endOffset": 47}, {"referenceID": 4, "context": "which are due to the theorems by Bonnet (1964) and Price (1958), respectively.", "startOffset": 33, "endOffset": 64}, {"referenceID": 24, "context": "We introduce an approximate posterior distribution q and applying Jensen\u2019s inequality, following the variational principle (Zemel, 1993; Beal, 2003) to obtain:", "startOffset": 123, "endOffset": 148}, {"referenceID": 2, "context": "We introduce an approximate posterior distribution q and applying Jensen\u2019s inequality, following the variational principle (Zemel, 1993; Beal, 2003) to obtain:", "startOffset": 123, "endOffset": 148}, {"referenceID": 20, "context": "Sigmoid belief networks (SBN) (Saul et al., 1996) are closely related and are models with Bernoulli variables at every layer.", "startOffset": 30, "endOffset": 49}, {"referenceID": 13, "context": "The Gaussian process latent variable model (GPLVM) (Lawrence, 2005) is the non-parametric analogue of our model, and employs Gaussian process priors over the non-linear functions between each layer.", "startOffset": 51, "endOffset": 67}, {"referenceID": 21, "context": "Some of the best results using directed models are provided by the neural autoregressive density estimator (NADE) (Larochelle & Murray, 2011; Uria et al., 2013), which uses function approximation to model conditional distributions within a directed acyclic graph.", "startOffset": 114, "endOffset": 160}, {"referenceID": 6, "context": "Our model is directly related to non-linear Gaussian belief networks (NLGNBN) (Frey & Hinton, 1999), which also use latent Gaussian distributions throughout a multi-layer hierarchy, but whose means are simple non-linear transformations of higher layers. Sigmoid belief networks (SBN) (Saul et al., 1996) are closely related and are models with Bernoulli variables at every layer. Both these models are trained by a mean-field variational EM algorithm. More recently, Gregor et al. (2013) described Deep Auto-regressive Networks (DARN), which also form a directed graphical model that uses auto-regressive Bernoulli distributions at each layer.", "startOffset": 79, "endOffset": 488}, {"referenceID": 3, "context": "Bengio et al. (2013) show how these models can be used as generative models, but since the generative process underlying the denoising auto-encoder is unknown, simulation from the model requires a slow Markov chain sampling procedure.", "startOffset": 0, "endOffset": 21}, {"referenceID": 3, "context": "Bengio et al. (2013) show how these models can be used as generative models, but since the generative process underlying the denoising auto-encoder is unknown, simulation from the model requires a slow Markov chain sampling procedure. In the model we describe, the recognition distribution q(\u03be|v) can be interpreted as a stochastic encoder in the DAE setting. We can readily see the correspondence between the expression for the free energy (12) and the reconstruction error and regularization terms used in denoising autoencoders (c.f. equation (4) of Bengio et al. (2013)).", "startOffset": 0, "endOffset": 574}, {"referenceID": 23, "context": "The most general approaches are policy-gradient methods such as REINFORCE (Williams, 1992) that are simple to implement and applicable to both discrete and continuous models.", "startOffset": 74, "endOffset": 90}, {"referenceID": 8, "context": "The key theorems for the Gaussian stochastic backpropagation were first exploited by Opper & Archambeau (2009) for variational learning in Gaussian process regression, and subsequently by Graves (2011) for learning the parameters of large neural networks.", "startOffset": 188, "endOffset": 202}, {"referenceID": 5, "context": "(13)) which can produce a one-shot sample from the approximate posterior distribution (similar to the procedure in Dayan et al. (1995); Dayan (2000)).", "startOffset": 115, "endOffset": 135}, {"referenceID": 5, "context": "(13)) which can produce a one-shot sample from the approximate posterior distribution (similar to the procedure in Dayan et al. (1995); Dayan (2000)).", "startOffset": 115, "endOffset": 149}, {"referenceID": 5, "context": "(13)) which can produce a one-shot sample from the approximate posterior distribution (similar to the procedure in Dayan et al. (1995); Dayan (2000)). Using a conditional, parametric recognition model also provides a cheap probabilistic encoding of the dataset and provides a framework for treating generative models and classes of auto-encoders on the same principled ground (as described above). Recently, Kingma & Welling (2013) also make the connection between stochastic back-propagation, generative auto-encoders and variational inference that we describe here.", "startOffset": 115, "endOffset": 432}, {"referenceID": 0, "context": "In all cases, we train using mini-batches, which requires the introduction of scaling terms in the free energy objective function (14) in order to maintain the correct scale between the prior over the parameters and the remaining terms (Ahn et al., 2012; Welling & Teh, 2011).", "startOffset": 236, "endOffset": 275}, {"referenceID": 21, "context": "We used exactly the data set used in Uria et al. (2013) and quote the log-likelihoods in the lower part of the table from this work.", "startOffset": 37, "endOffset": 56}, {"referenceID": 5, "context": "80 Wake-Sleep (Dayan, 2000) 91.", "startOffset": 14, "endOffset": 27}, {"referenceID": 21, "context": "Results below from Uria et al. (2013)", "startOffset": 19, "endOffset": 38}], "year": 2014, "abstractText": "We marry ideas from deep neural networks and approximate Bayesian inference to derive a generalised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent approximate posterior distributions, and that acts as a stochastic encoder of the data. We develop stochastic backpropagation \u2013 rules for back-propagation through stochastic variables \u2013 and use this to develop an algorithm that allows for joint optimisation of the parameters of both the generative and recognition model. We demonstrate on several real-world data sets that the model generates realistic samples, provides accurate imputations of missing data and is a useful tool for high-dimensional data visualisation.", "creator": "LaTeX with hyperref package"}}}