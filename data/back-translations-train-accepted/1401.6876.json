{"id": "1401.6876", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jan-2014", "title": "Improving Statistical Machine Translation for a Resource-Poor Language Using Related Resource-Rich Languages", "abstract": "We propose a novel language-independent approach for improving machine translation for resource-poor languages by exploiting their similarity to resource-rich ones. More precisely, we improve the translation from a resource-poor source language X_1 into a resource-rich language Y given a bi-text containing a limited number of parallel sentences for X_1-Y and a larger bi-text for X_2-Y for some resource-rich language X_2 that is closely related to X_1. This is achieved by taking advantage of the opportunities that vocabulary overlap and similarities between the languages X_1 and X_2 in spelling, word order, and syntax offer: (1) we improve the word alignments for the resource-poor language, (2) we further augment it with additional translation options, and (3) we take care of potential spelling differences through appropriate transliteration. The evaluation for Indonesian- &gt;English using Malay and for Spanish -&gt; English using Portuguese and pretending Spanish is resource-poor shows an absolute gain of up to 1.35 and 3.37 BLEU points, respectively, which is an improvement over the best rivaling approaches, while using much less additional data. Overall, our method cuts the amount of necessary \"real training data by a factor of 2--5.", "histories": [["v1", "Thu, 23 Jan 2014 02:42:12 GMT  (416kb)", "http://arxiv.org/abs/1401.6876v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["preslav ivanov nakov", "hwee tou ng"], "accepted": true, "id": "1401.6876"}, "pdf": {"name": "1401.6876.pdf", "metadata": {"source": "CRF", "title": "Improving Statistical Machine Translation for a Resource-Poor Language Using Related Resource-Rich Languages", "authors": ["Preslav Nakov", "Hwee Tou Ng"], "emails": ["pnakov@qf.org.qa", "nght@comp.nus.edu.sg"], "sections": [{"heading": "1. Introduction", "text": "In practice, this requires a large number of parallel sentences in two languages (bittexts) for this pair of languages with decent translation quality are rare, except for Arabic, Chinese and some official languages of the European Union (EU). Most of the 6,500 + world languages remain resource-poor (SMT).c \u00a9 2012 AI Access Foundation All rights reserved.The number of resource-poor languages will continue to decline."}, {"heading": "2. Related Work", "text": "Our general problem formulation is a specific case of domain adaptation. In addition, there are three basic concepts that are at the heart of our work: (1) similarities between related languages, (2) machine translation between closely related languages, and (3) the switch to statistical machine translation. We will review previous work on these topics below and, where appropriate, also mention some other related work."}, {"heading": "2.1 Domain Adaptation", "text": "The domain adaptation problem (or transfer learning problem) occurs in situations where the training and test data comes from different distributions, thus violating the basic assumption of statistical learning theory. Our problem is an example of the specific case of domain adaptation, where domain data is scarce but there is a lot of out-of-domain data. Many efficient techniques have been developed for domain adaptation in natural language processing; see the work of Daume 'and Marcu (2006), Jiang and Zhai (2007a, 2007b), Chan and Ng (2005, 2006, 2007), and Dahlmeier and Ng (2010) for some examples. Unfortunately, these techniques are not directly applicable to machine translation, which is much more complicated, and leaves much more room for diversity in the proposed solutions. This despite the limited previous work on domain models focusing on the adaptation of domain models for SMT, which focus almost exclusively on the European Parliament's annual news translation adjustment part."}, {"heading": "2.2 Cognates", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "2.3 Machine Translation between Closely Related Languages", "text": "Another relevant line of research is machine translation between closely related languages, which is arguably simpler than general SMS, and thus can be handled using word-for-word translation and manual language-specific rules that handle the necessary morphological and syntactical transformations, which has been attempted for a number of language pairs, including Czech-Slovak (Hajic, Hric, & Kubon, 2000), Turkish-Critical Tatar (Altintas & Cicekli, 2002), and Irish-Scottish Gaelic (Scannell, 2006), among others. More recently, the open source machine translation platform at http: / / www.apertium.org / has evolved to use bilingual dictionaries and manual rules to translate between a number of related languages, including Spanish-Catalan, Spanish-Galician, Catalan-Xalician, and Xalician languages."}, {"heading": "2.4 Pivoting", "text": "Another relevant question is whether and to what extent the U.S. and the EU will be able to assert themselves in the global financial and economic crisis, or whether they will be in the global financial and economic crisis, in the global crisis and in the global crises, in the global crisis and in the global crises, in the global crisis and in the global crises, in the global crisis and in the global crises, in the global crisis and in the global crises, in the global crisis and in the global crisis, in the global crisis and in the global crisis, in the global crisis and in the global crisis, in the global crisis and in the global crisis, in the global crisis and in the global crisis, in the global crisis and in the global crisis, in the global crisis and in the global crisis, in the global crisis and in the global crisis, in the global crisis and in the global crisis, in the global crisis, in the global crisis and in the global in the global and in the global, in the global in the global and in the global in the global and in the global, in the global in the global in the global in the global and in the global in the global and in the global in the global and in the global in the global crisis, in the global in the global in the global in the global crisis, in the global in the global in the global in the global in the global crisis, and in the global in the global in the global in the global in the global crisis, in the global in the global in the global in the global in the global crisis, and in the global in the global in the global in the global in the global crisis, and in the global in the global in the global in the global in the global crisis, and in the global in the global in the global in the global in the global in the global and in the global crisis, and in the global in the global in the global in the global and in the global in the global in the global in the global and in the global in the crisis, and in the global in the global and in the global in the global in the global in the and in the global and in the global in the global and in the global in the global and in the global and in the global in the global and in the global in the global and in the global and in the global in the global crisis, and in the global and in the global in the global in the global in the global in the global"}, {"heading": "3. Motivating Example", "text": "Consider Article 1 of the Universal Declaration of Human Rights: all human beings are born free and equal in dignity and rights, endowed with reason and conscience, and should meet one another in a spirit of fraternity. Let's see how it translates into closely related Malay and Indonesian and unequal Spanish and Portuguese."}, {"heading": "3.1 Malay and Indonesian", "text": "In fact, it is as if most of us are able to abide by the rules that they have imposed on themselves, and that they are able to abide by the rules that they have imposed on themselves. (...) It is also as if they are able to abide by the rules. (...) It is not as if they abide by the rules. (...) It is not as if they abide by the rules. (...) It is not as if they abide by the rules. (...) It is not as if they abide by the rules. \"(...) It is not as if they abide by the rules.\" (...) It is not as if they abide by the rules. \"(...) It is not as if they abide by the rules. (...) It is not as if they abide by the rules."}, {"heading": "3.2 Spanish and Portuguese", "text": "Spanish and Portuguese also have a noticeable degree of mutual comprehensibility, but differ in pronunciation, spelling and vocabulary. Unlike Malay and Indonesian, however, they differ syntactically and have a high degree of spelling differences, as can be seen from the translation of Article 1 of the Universal Declaration of Human Rights: \u2022 Spanish: Todos los seres humanos nacen libres e iguales en dignidad y derechos y, dotados como esta \"n de razo\" n y conciencia, deben comportarse fraternalmente los unos con los otros. \"\u2022 Portuguese: Todos os seros humanos nascem livres e iguais em dignidade e em em em em direitos.\" Dotados de raza \"o\" e de los conscie, devem agir uns para com os outros esp. \""}, {"heading": "4. Method", "text": "The above examples suggest that it may be possible to use bi-texts for a language to improve the SMT for a related language, possibly after appropriate transliteration of the relatives into the additional language to match the target spelling. Therefore, we describe two general strategies for improving the phrase-based SMT from a resource-poor language X1 to a target language Y, using a bi-text X2-Y for a related resource-rich language X2: (a) bi-text concatenation with possible repetitions of the original bi-text for balance, and (b) phrase table combination, using each bi-text to build a separate phrase table, and then combining the two phrase tables. We discuss the pros and cons of these general strategies and propose a hybrid approach that combines their strengths while trying to avoid their limitations."}, {"heading": "4.1 Concatenating Bi-texts", "text": "In fact, it is the case that most people are able to survive themselves by blaming themselves and others. (...) In fact, it is the case that people are able to survive themselves. (...) It is not the case that they take guilt upon themselves. (...) It is not the case that they take guilt upon themselves. (...) It is not the case that they take guilt upon themselves. (...) It is the case that they take guilt upon themselves. (...) It is the case that they take guilt. (...). (...). \"(...).\" (...). \"(...).\" It is the case that they take guilt upon themselves. (...). \"(...).\" (...). \"(...).\" It is the case that they take guilt upon themselves. (...). \"(...).\" It is. (...). \"It is. (....\" It is. (...). (. \"It is. (...).\" It is. (.... \"It is. (...).\" It is. (.... \"It is. (...).\" It is. (.... \"It is. (....\" It is. (...). \"It is.\" It is. (.... \"It is.\" It is. (.... \"It is. (...). (.\" It is. \"It is. (.... (...). (.\" It is. \"It is. (. (.). (. (.).\" It is. \"It is. (. (.\" It is. (.).). (.... (.. (. \"It is.).\" It is. (. (.). \"It is. (. (.. (.). (.. (.). (it is.\" It is. (.). (it is.). (it is. (. (it is.). (it is. (. (..). (it.). (it is.). (it is. (it is. (.). (it is. (.). (it is.). (it is. (it. (it is. (it is. (.)."}, {"heading": "4.2 Combining Phrase Tables", "text": "An alternative way to train an improved sentence-based SMT system for X1 \u2192 Y is to build separate phrase tables of X1-Y and X2-Y, which can then (a) be used together, e.g., as alternative decoding paths, (b) merged, e.g., by using one or more additional properties to display the bi-text of each phrase pair, or (c) interpolated, e.g., by using simple linear interpolation. Building two separate phrase tables offers several advantages. First, the preferred phrase pairs extracted from the bi-text for X1-Y are clearly outweighed by a higher weight in linear interpolation compared to the potentially riskier values from the X2-Y bi-text. Second, the lexical and phrase-based probabilities are combined in a principled way."}, {"heading": "4.3 Proposed Approach", "text": "Taking into account the potential advantages and disadvantages of the two general strategies mentioned above, we propose an approach that tries to get the best out of each of them, namely: (i) improved word alignments for X1-Y by distorting the word alignment process by adding additional sentence pairs from X2-Y, and (ii) increased lexical coverage by using additional word alignment pairs that the X2-Y bittext can provide. This is achieved by adding the word alignment tables for cat \u00d7 k: align and cat \u00d7 1. The process can be described in more detail as follows: 1. Create a balanced bittext break consisting of the X1-Y-Bi text repeating k times followed by a copy of the X2-Y-Bi text. Create word alignments for Brep, then cut them off, and hold word alignments just for a copy of the X1-Y-Bi text that contains k-times, followed by a copy of the X2-Y-Bi text."}, {"heading": "5. Datasets", "text": "We are experimenting with the following bilingual texts and monolingual English data: \u2022 Indonesian-English (in-en): - Train: 28,383 sentence pairs (0.8M, 0.9M words); - dev: 2,000 sentence pairs (56.6K, 63.3K words); - Test: 2,000 sentence pairs (58.2K, 69.0K words); - Monolingual English word pairs (59.7K words); - Test: 2,000 sentence pairs (57.9K, 62.4K words). - Train: 2,000 sentence pairs (59.7K, 64.5K words). - Test: 2,000 sentence pairs (57.9K, 62.4K words). - Monolingual English enml: 27.9M words. \u2022 we: - English-English (es-en): - Train: 1,240,518 sentence pairs (35,718 sentence pairs)."}, {"heading": "6. Transliteration", "text": "As we mentioned above, our approach is based on the existence of a large number of cognates between related languages (context).While linguists define cognates as words derived from a common root (Bickford & Tuggy, 2002), computer linguists typically ignore the origin and define them as words in different languages that are mutually translated and have a similar orthography (Melamed, 1999; Mann & Yarowsky, 2001; Bergsma & Kondrak, 2007).As we have seen in Section 3, translation can be very helpful for languages such as Spanish and Portuguese, which have many regular spelling differences.For example, we are building a system for automatic translation from Portuguese to Spanish, which we apply to a list of automatically extracted pairs of likely cognates. We apply this system to the Portuguese side of pt-en training bi-text.Classically, we look at automatic cognates with similar spelling that appear in a common text (context)."}, {"heading": "7. Experiments and Evaluation", "text": "In the following, we describe our basic system and conduct various experiments to assess the similarity between the original (Indonesian and Spanish) and the auxiliary languages (Malay and Portuguese), and then improve Indonesian \u2192 English and Spanish \u2192 English SMT with Malay and Portuguese as auxiliary languages, respectively. We also study the improvement of Spanish \u2192 English SMT and conduct a series of additional experiments. First, we try to use an additional language more similar to Spanish by replacing Portuguese with Italian. Second, we experiment simultaneously with two auxiliary languages: Portuguese and Italian. Finally, we combine our method with two orthogonal competing approaches: (1) with cognates between the source and target languages (Kondrak et al., 2003) and (2) source-language paraphrasing with a pivot language (Callison-Burch et al., 2006)."}, {"heading": "7.1 Baseline SMT System", "text": "In the baseline, we used the following approach: First, we symbolized and minimized both sides of the training text, then we created separate directional alignments for English \u2192 X and X \u2192 English (X-{ Indonesian, Spanish}) with IBM Model 4 (Brown, Della Pietra, Della Pietra, & Mercer, 1993), combined them with the intersection + Grow heuristic (Koehn et al., 2007), and extracted phrase pairs of maximum length seven. Thus, we obtained a phrase table in which each phrase pair is associated with the five standard parameters: forward and backward translation probabilities, forward and backward lexical translation probabilities and phrase penalties. Then, we trained a log-linear model using standard SMT functions: trigram linguistic probability, word penalty, distance-based distortion probability table 10, distortion costs, and forward phrasing probability from the base text, and translation parameters."}, {"heading": "7.2 Cross-lingual Translation Experiments", "text": "Here we study the similarity between the original and the auxiliary languages. First, we measure the vocabulary overlap between the original and the auxiliary languages. (First, we measure the vocabulary overlap between the original and auxiliary languages.) We compare the vocabulary overlap between the original and auxiliary languages. For Spanish and Portuguese, this was feasible because our training texts pt-en and es-en-bi texts originate from the same time span, which means that 40.40% of the Spanish word types exist on the Portuguese side of the pt-en-en-text and largely overlap. We found 110,053 Portuguese and 121,444 Spanish word types in the pt-en-texts and read-bi-texts on the Portuguese side of the pt-en-text. Unfortunately, we could not directly measure the vocabulary between the Indonesian and Indonesian languages because the English pages of the In-en-text-en-en-text-en-text-ml-set-up do not overlap us in the second language."}, {"heading": "7.3 Improving Indonesian\u2192English SMT using Malay", "text": "First, we are studying the effects of k on cat \u00d7 k. for Indonesian \u2192 English SMT using Malay as an additional language. We have tried to define all values of k so that 1 \u2264 k \u2264 16 with 10000n extra ml pairs of sentences, n * 1,2,4,8,16}. As we can see in Figure 1, the highest BLEU values are usually achieved for (n; k), (1; 2), (2; 2), (4; 4), (8; 7), (16; 16)}, so if we apply this relationship between k and n in our experiments (including for Portuguese and Spanish), we should note that there is a lot of fluctuation in the results in Figure 1, probably due to the small sizes of the training companies. Given this fluctuation, the results should not be overinterpreted, for example, it can only be accidental that there are peaks in the different curves in the respective places. \""}, {"heading": "7.4 Improving Spanish\u2192English SMT using Portuguese", "text": "Next, we are experimenting with the use of Portuguese to improve the Spanish \u2192 English SMT. The results are shown in Tables 5 and 6 above. Overall, they agree with those for Indonesian \u2192 English SMT that use the additional Malay-English bi-text (shown in Tables 3 and 4 above). We can also observe that as the original bi-text becomes larger, the gain in BLEU decreases, which is to be expected. Also, note that transliteration is very important here: it doubles the absolute gain in BLEU that was achieved through our method. Table 7 compares the performance of our technique for 160K vs. 1.23M additional pt-en sentence pairs, with and without transliteration for the formation of bi-text with different numbers of parallel es-en sentence pairs (10K, 20K,.., 320K). The table shows the importance of transliteration, which is responsible for about half of the improvement in bi-text pairs, the improvement of the Bi-text line is doubled by the improvement in Bi-pairs."}, {"heading": "7.5 Improving Spanish\u2192English SMT Using Italian", "text": "Figure 2 shows the results when using Italian and Portuguese as auxiliary languages in our method of transliteration. When using Italian instead of Portuguese, we see a clear consistent decrease in the BLEU score. With 10K-en sentence pairs and 160K additional pt-en / it-en sentence pairs, the absolute decrease of BLEU is about 0.9%: we have a value of 25.73% versus 24.82%. In addition, our method of 160K original es-en sentence pairs is slightly below the baseline (by -0.05) when using it-en, whereas it is with pt-en.However, Figure 2 shows that Italian, which is more similar to Spanish than Portuguese, is useful as an auxiliary language for smaller sizes of the original es-en-training bi-text."}, {"heading": "7.6 Improving Spanish\u2192English SMT Using Both Portuguese and Italian", "text": "After seeing that both Portuguese and Italian are useful as auxiliary languages, we tried to use both together, and the experiments were carried out in the same way as using a single auxiliary language, except that we now had to double the usual number of repetitions k of the original bi-text, so that the auxiliary bi-texts did not dominate it at cat \u00b7 k: align. For example, for 10K original es-en training set pairs and 160K additional pt-en and 160K bit-en set pairs, we have to include 32 copies of the original bi-text instead of 16, as we did before. The results for the combination are in Figure 2. Comparing them with the results only using pt-en data, we can see that there is a small but consistent improvement. For example, for 10K original es-en set pairs, 160K additional pt-en set pairs, and 160K additional aupt points, there is an absolute EU increase of 25.0% to BL0K, and the absolute increase of BL-18% to BL0K."}, {"heading": "7.7 Combining Our Method with the Cognate Extraction Technique of Kondrak et al. (2003)", "text": "Next, we combined our method with the cognate extraction technique of Kondrak et al. (2003), where pairs of likely cognates are extracted from the original training bi-text and then added to this bi-text as additional 1-word-to-1-word sentence pairs. Results for adding these cognates to the training es-en bi-text, i.e. for our reimplementation of their algorithm, are shown in the top rows of Table 8. We can see an absolute improvement of 0.5% BLEU for it-en of size up to 40K, and the improvement is statistically significant. Next, we combined our method with the cognate extraction method as follows: First, we augmented the original es-en-text with cognate pairs, and then we used these augmented bi-text instead of it-en in our method."}, {"heading": "7.8 Combining Our Method with the Phrase Table Pivoting Technique of Callison-Burch et al. (2006)", "text": "Finally, we combined our method with the phrase-threshing technique of Callison-Burch et al. (2006), since it is orthogonal. First, we tried the phrase-threshing experiments of Callison-Burch et al. (2006), which proved complicated (although we used their original code to do the spins) because we used different differences in our experimental setups: (1) we used Moses instead of Pharaoh for the translation; (2) we used IRSTLM for language modeling; (3) we used different tokenization; (4) we used a maximum phrase length of up to seven instead of ten; we created our training / de- / test dataset from Europarl v.3, which is different from the version of the Europarl Corpus group that was available in 2006 (which also implies a different baseline).The results are shown in Table 9."}, {"heading": "8. Analysis and Discussion", "text": "In the following, we will perform a more in-depth analysis of our method and the results obtained."}, {"heading": "8.1 Merging Phrase Tables", "text": "Here we compare the merging of cat \u00d7 k: align insight and cat \u00d7 1 (with 1-3 additional phrases, as described above), to two simpler alternatives: (a) replacing cat \u00d7 1 with ml-en, and (b) merging the phrase tables from the original bi-texts, in-en and ml-en.We implement and evaluate the following alternative to our method: (c) The first table is cat \u00d7 k: align as in our method (built on a copy of in-en), and the second is a similar phrase table of ml-en, then shorten the alignments appropriately and build two separate phrase tables. The first table is cat \u00d7 k: align as in our method (built on a copy of in-en), and the second is a similar phrase table that matches ml-en. Unlike (a) above, the word alignments in this second phrase matching table are influenced by the copies of in-en."}, {"heading": "8.2 Transliteration", "text": "In fact, the number of word types that have changed in the process of transcribing the source code is not surprising, since the differences in spelling between Malays and Indonesians are very limited, as we can see in Section 3.1. In Section 3.1, the transformation of Malays and Indonesians is extended to a very small number of words: 7.61% of the word types and 5.78% of the word types in Indonesia. This should not be surprising, since the differences in spelling between Malays and Indonesians are very limited, as we explained in Section 3.1, that the transformation of Malays and Indonesians is limited to a very small number of words."}, {"heading": "8.3 Relative Improvement", "text": "Finally, we address the important question of how much \"real\" data our method saves. Figure 3 graphically compares the improvements over the baseline with our method of 160K vs. 1.23M pt-en sentence pairs and transliteration for different numbers of original training-es-en sentence pairs. From this figure, we can see that with 10K \"real\" training-es-en sentence pairs with 160K additional pt-en sentence pairs and our method we achieve a BLEU score comparable to 40K \"real\" es-es-en sentence pairs, i.e. we cut the required \"real\" data by a factor of four. We can also see that the use of 1.23M pt-en sentence pairs improves this factor to five. Similarly, our method for 20K \"real\" es-en training pairs achieves a BLEU score that would require 3-3.5 times as much \"real\" training-en data for the baseline system, and Figure 4 times more than we would need for these statistics combined with 5M for 5M."}, {"heading": "9. Conclusion", "text": "We have proposed a novel language-independent method to improve statistical machine translation for low-resource languages, taking advantage of its similarity to related resource-rich languages. We have made significant gains in BLEU, improving on the best competing approaches, while using much less additional data. We have further investigated the impact of using a less closely related language as an auxiliary language (Italian instead of Portuguese to improve the Spanish side of SMT), we have attempted to use both Portuguese and Italian together as auxiliary languages, and we have combined our method with two orthogonal competing approaches: (1) use of cognates between the source and the target language, and (2) source language page paraphrasing with a pivot language. All of these experiments have yielded statistically significant improvements for small data sets. Based on the experimental results, we can draw several interesting conclusions: 1. We have shown that the use of related languages can help improve SMT: we achieved 1.35 and 3.37 for BLT."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for their constructive comments and suggestions, which have helped us to improve the quality of the manuscript, supported by the POD0713875 research grant and the Singapore National Research Foundation through its International Research Centre @ Singapore Funding Initiative, and managed by the IDM Programme Office."}], "references": [{"title": "Statistical machine translation", "author": ["Y. Al-Onaizan", "J. Curin", "M. Jahr", "K. Knight", "J. Lafferty", "D. Melamed", "F.J. Och", "D. Purdy", "N. Smith", "D. Yarowsky"], "venue": null, "citeRegEx": "Al.Onaizan et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Al.Onaizan et al\\.", "year": 1999}, {"title": "A machine translation system between a pair of closely related languages", "author": ["K. Altintas", "I. Cicekli"], "venue": "In Proceedings of the 17th International Symposium on Computer and Information Sciences,", "citeRegEx": "Altintas and Cicekli,? \\Q2002\\E", "shortCiteRegEx": "Altintas and Cicekli", "year": 2002}, {"title": "A hybrid approach for converting written Egyptian colloquial dialect into diacritized Arabic", "author": ["H.A. Bakr", "K. Shaalan", "I. Ziedan"], "venue": "In Proceedings of the 6th International Conference on Informatics and Systems, INFOS \u201908,", "citeRegEx": "Bakr et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bakr et al\\.", "year": 2008}, {"title": "Paraphrasing with bilingual parallel corpora", "author": ["C. Bannard", "C. Callison-Burch"], "venue": "In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Bannard and Callison.Burch,? \\Q2005\\E", "shortCiteRegEx": "Bannard and Callison.Burch", "year": 2005}, {"title": "Alignment-based discriminative string similarity", "author": ["S. Bergsma", "G. Kondrak"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Bergsma and Kondrak,? \\Q2007\\E", "shortCiteRegEx": "Bergsma and Kondrak", "year": 2007}, {"title": "Phrase-based statistical machine translation with pivot languages", "author": ["N. Bertoldi", "M. Barbaiani", "M. Federico", "R. Cattoni"], "venue": "In Proceedings of the International Workshop on Spoken Language Translation, IWSLT", "citeRegEx": "Bertoldi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bertoldi et al\\.", "year": 2008}, {"title": "Electronic glossary of linguistic terms. http://www.sil.org/mexico/ling/glosario/E005ai-Glossary.htm", "author": ["A. Bickford", "D. Tuggy"], "venue": null, "citeRegEx": "Bickford and Tuggy,? \\Q2002\\E", "shortCiteRegEx": "Bickford and Tuggy", "year": 2002}, {"title": "CCG supertags in factored statistical machine translation", "author": ["A. Birch", "M. Osborne", "P. Koehn"], "venue": "In Proceedings of the Second Workshop on Statistical Machine Translation,", "citeRegEx": "Birch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Birch et al\\.", "year": 2007}, {"title": "An improved error model for noisy channel spelling correction", "author": ["E. Brill", "R.C. Moore"], "venue": "In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Brill and Moore,? \\Q2000\\E", "shortCiteRegEx": "Brill and Moore", "year": 2000}, {"title": "But dictionaries are data too", "author": ["P.F. Brown", "S.A. Della Pietra", "V.J. Della Pietra", "M.J. Goldsmith", "J. Haji\u010d", "R.L. Mercer", "S. Mohanty"], "venue": "In Proceedings of the Workshop on Human Language Technology,", "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "The mathematics of statistical machine translation: parameter estimation", "author": ["P.F. Brown", "S.A. Della Pietra", "V.J. Della Pietra", "R.L. Mercer"], "venue": "Computational Linguistics,", "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Syntactic constraints on paraphrases extracted from parallel corpora", "author": ["C. Callison-Burch"], "venue": "In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Callison.Burch,? \\Q2008\\E", "shortCiteRegEx": "Callison.Burch", "year": 2008}, {"title": "How-to guide for extracting syntactically constrained paraphrases", "author": ["C. Callison-Burch"], "venue": "http://www.cs.jhu.edu/\u223cccb/howto-extract-paraphrases.html. Retrieved", "citeRegEx": "Callison.Burch,? \\Q2012\\E", "shortCiteRegEx": "Callison.Burch", "year": 2012}, {"title": "Improved statistical machine translation using paraphrases", "author": ["C. Callison-Burch", "P. Koehn", "M. Osborne"], "venue": "In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Callison.Burch et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Callison.Burch et al\\.", "year": 2006}, {"title": "Word sense disambiguation with distribution estimation", "author": ["Y.S. Chan", "H.T. Ng"], "venue": "In Proceedings of the 19th International Joint Conference on Artificial Intelligence,", "citeRegEx": "Chan and Ng,? \\Q2005\\E", "shortCiteRegEx": "Chan and Ng", "year": 2005}, {"title": "Estimating class priors in domain adaptation for word sense disambiguation", "author": ["Y.S. Chan", "H.T. Ng"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,", "citeRegEx": "Chan and Ng,? \\Q2006\\E", "shortCiteRegEx": "Chan and Ng", "year": 2006}, {"title": "Domain adaptation with active learning for word sense disambiguation", "author": ["Y.S. Chan", "H.T. Ng"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Chan and Ng,? \\Q2007\\E", "shortCiteRegEx": "Chan and Ng", "year": 2007}, {"title": "A hierarchical phrase-based model for statistical machine translation", "author": ["D. Chiang"], "venue": "In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Chiang,? \\Q2005\\E", "shortCiteRegEx": "Chiang", "year": 2005}, {"title": "11,001 new features for statistical machine translation", "author": ["D. Chiang", "K. Knight", "W. Wang"], "venue": "In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Chiang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chiang et al\\.", "year": 2009}, {"title": "Machine translation by triangulation: Making effective use of multi-parallel corpora", "author": ["T. Cohn", "M. Lapata"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Cohn and Lapata,? \\Q2007\\E", "shortCiteRegEx": "Cohn and Lapata", "year": 2007}, {"title": "Clause restructuring for statistical machine translation", "author": ["M. Collins", "P. Koehn", "I. Ku\u010derov\u00e1"], "venue": "In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Collins et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Collins et al\\.", "year": 2005}, {"title": "Local lexical adaptation in machine translation through triangulation: SMT helping SMT", "author": ["J.M. Crego", "A. Max", "F. Yvon"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics,", "citeRegEx": "Crego et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Crego et al\\.", "year": 2010}, {"title": "Domain adaptation for semantic role labeling in the biomedical", "author": ["D. Dahlmeier", "H.T. Ng"], "venue": "domain. Bioinformatics,", "citeRegEx": "Dahlmeier and Ng,? \\Q2010\\E", "shortCiteRegEx": "Dahlmeier and Ng", "year": 2010}, {"title": "Domain adaptation for machine translation by mining unseen words", "author": ["III Daum\u00e9", "J. Jagarlamudi"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Daum\u00e9 et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Daum\u00e9 et al\\.", "year": 2011}, {"title": "Domain adaptation for statistical classifiers", "author": ["III Daum\u00e9", "D. Marcu"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "Daum\u00e9 et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Daum\u00e9 et al\\.", "year": 2006}, {"title": "Catalan-English statistical machine translation without parallel corpus: Bridging through Spanish", "author": ["A. de Gispert", "J. Mario"], "venue": "In Proceedings of the 5th Workshop on Strategies for developing Machine Translation for Minority Languages at LREC,", "citeRegEx": "Gispert and Mario,? \\Q2006\\E", "shortCiteRegEx": "Gispert and Mario", "year": 2006}, {"title": "METEOR-NEXT and the METEOR paraphrase tables: Improved evaluation support for five target languages", "author": ["M. Denkowski", "A. Lavie"], "venue": "In Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR,", "citeRegEx": "Denkowski and Lavie,? \\Q2010\\E", "shortCiteRegEx": "Denkowski and Lavie", "year": 2010}, {"title": "Leveraging multiple languages to improve statistical MT word alignments", "author": ["K. Filali", "J. Bilmes"], "venue": "In Proceedings of the IEEE Automatic Speech Recognition and Understanding Workshop,", "citeRegEx": "Filali and Bilmes,? \\Q2005\\E", "shortCiteRegEx": "Filali and Bilmes", "year": 2005}, {"title": "Phrase-based machine transliteration", "author": ["A. Finch", "E. Sumita"], "venue": "In Proceedings of the Workshop on Technologies and Corpora for Asia-Pacific Speech Translation,", "citeRegEx": "Finch and Sumita,? \\Q2008\\E", "shortCiteRegEx": "Finch and Sumita", "year": 2008}, {"title": "What\u2019s in a translation rule", "author": ["M. Galley", "M. Hopkins", "K. Knight", "D. Marcu"], "venue": "In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Galley et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Galley et al\\.", "year": 2004}, {"title": "Improving translation lexicon induction from monolingual corpora via dependency contexts and part-of-speech equivalences", "author": ["N. Garera", "C. Callison-Burch", "D. Yarowsky"], "venue": "In Proceedings of the Thirteenth Conference on Computational Natural Language Learning,", "citeRegEx": "Garera et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Garera et al\\.", "year": 2009}, {"title": "Learning tractable word alignment models with complex constraints", "author": ["J. Graca", "K. Ganchev", "B. Taskar"], "venue": "Comput. Linguist.,", "citeRegEx": "Graca et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Graca et al\\.", "year": 2010}, {"title": "Improving Arabic-Chinese statistical machine translation using English as pivot language", "author": ["N. Habash", "J. Hu"], "venue": "In Proceedings of the Fourth Workshop on Statistical Machine Translation,", "citeRegEx": "Habash and Hu,? \\Q2009\\E", "shortCiteRegEx": "Habash and Hu", "year": 2009}, {"title": "Learning bilingual lexicons from monolingual corpora", "author": ["A. Haghighi", "P. Liang", "T. Berg-Kirkpatrick", "D. Klein"], "venue": "In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Haghighi et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Haghighi et al\\.", "year": 2008}, {"title": "Machine translation of very close languages", "author": ["J. Haji\u010d", "J. Hric", "V. Kubo\u0148"], "venue": "In Proceedings of the Sixth Conference on Applied Natural Language Processing,", "citeRegEx": "Haji\u010d et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Haji\u010d et al\\.", "year": 2000}, {"title": "Lexical normalisation of short text messages: Makn sens a #twitter", "author": ["B. Han", "T. Baldwin"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Han and Baldwin,? \\Q2011\\E", "shortCiteRegEx": "Han and Baldwin", "year": 2011}, {"title": "Tagging Portuguese with a Spanish tagger using cognates", "author": ["J. Hana", "A. Feldman", "C. Brew", "L. Amaral"], "venue": "In Proceedings of the International Workshop on CrossLanguage Knowledge Induction,", "citeRegEx": "Hana et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hana et al\\.", "year": 2006}, {"title": "Adaptation of the translation model for statistical machine translation based on information retrieval", "author": ["A.S. Hildebrand", "M. Eck", "S. Vogel", "A. Waibel"], "venue": "In Proceedings of the 10th Annual Conference of the European Association for Machine Translation,", "citeRegEx": "Hildebrand et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hildebrand et al\\.", "year": 2005}, {"title": "Tuning as ranking", "author": ["M. Hopkins", "J. May"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Hopkins and May,? \\Q2011\\E", "shortCiteRegEx": "Hopkins and May", "year": 2011}, {"title": "Automatic identification of cognates and false friends in French and English", "author": ["D. Inkpen", "O. Frunza", "G. Kondrak"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing,", "citeRegEx": "Inkpen et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Inkpen et al\\.", "year": 2005}, {"title": "Instance weighting for domain adaptation in NLP", "author": ["J. Jiang", "C. Zhai"], "venue": "In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Jiang and Zhai,? \\Q2007\\E", "shortCiteRegEx": "Jiang and Zhai", "year": 2007}, {"title": "A two-stage approach to domain adaptation for statistical classifiers", "author": ["J. Jiang", "C. Zhai"], "venue": "In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,", "citeRegEx": "Jiang and Zhai,? \\Q2007\\E", "shortCiteRegEx": "Jiang and Zhai", "year": 2007}, {"title": "Named entity transliteration and discovery from multilingual comparable corpora", "author": ["A. Klementiev", "D. Roth"], "venue": "In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Klementiev and Roth,? \\Q2006\\E", "shortCiteRegEx": "Klementiev and Roth", "year": 2006}, {"title": "Europarl: A parallel corpus for evaluation of machine translation", "author": ["P. Koehn"], "venue": "In Proceedings of the Tenth Machine Translation Summit, MT Summit", "citeRegEx": "Koehn,? \\Q2005\\E", "shortCiteRegEx": "Koehn", "year": 2005}, {"title": "Edinburgh system description for the IWSLT speech translation evaluation", "author": ["P. Koehn", "A. Axelrod", "A.B. Mayne", "C. Callison-Burch", "M. Osborne", "D. Talbot"], "venue": "In Proceedings of the International Workshop on Spoken Language", "citeRegEx": "Koehn et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2005}, {"title": "Learning a translation lexicon from monolingual corpora", "author": ["P. Koehn", "K. Knight"], "venue": "In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition,", "citeRegEx": "Koehn and Knight,? \\Q2002\\E", "shortCiteRegEx": "Koehn and Knight", "year": 2002}, {"title": "Statistical phrase-based translation", "author": ["P. Koehn", "F.J. Och", "D. Marcu"], "venue": "In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,", "citeRegEx": "Koehn et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Cognates and word alignment in bitexts", "author": ["G. Kondrak"], "venue": "In Proceedings of the Tenth Machine Translation Summit, MT Summit", "citeRegEx": "Kondrak,? \\Q2005\\E", "shortCiteRegEx": "Kondrak", "year": 2005}, {"title": "Cognates can improve statistical translation models", "author": ["G. Kondrak", "D. Marcu", "K. Knight"], "venue": "In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,", "citeRegEx": "Kondrak et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kondrak et al\\.", "year": 2003}, {"title": "Improving word alignment with bridge languages", "author": ["S. Kumar", "F.J. Och", "W. Macherey"], "venue": "In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,", "citeRegEx": "Kumar et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2007}, {"title": "Multipath translation lexicon induction via bridge languages", "author": ["G.S. Mann", "D. Yarowsky"], "venue": "In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies,", "citeRegEx": "Mann and Yarowsky,? \\Q2001\\E", "shortCiteRegEx": "Mann and Yarowsky", "year": 2001}, {"title": "BP2EP \u2013 Adaptation of Brazilian Portuguese texts to European Portuguese", "author": ["L. Marujo", "N. Grazina", "T. L\u00fa\u0131s", "W. Ling", "L. Coheur", "I. Trancoso"], "venue": "In Proceedings of the 15th Conference of the European Association for Machine Translation,", "citeRegEx": "Marujo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Marujo et al\\.", "year": 2011}, {"title": "Machine transliteration of proper names. Master\u2019s thesis, School of Informatics, University of Edinburgh", "author": ["D. Matthews"], "venue": null, "citeRegEx": "Matthews,? \\Q2007\\E", "shortCiteRegEx": "Matthews", "year": 2007}, {"title": "Automatic evaluation and uniform filter cascades for inducing N-best translation lexicons", "author": ["D. Melamed"], "venue": "In Proceedings of the Third Workshop on Very Large Corpora,", "citeRegEx": "Melamed,? \\Q1995\\E", "shortCiteRegEx": "Melamed", "year": 1995}, {"title": "Bitext maps and alignment via pattern recognition", "author": ["D. Melamed"], "venue": "Computational Linguistics,", "citeRegEx": "Melamed,? \\Q1999\\E", "shortCiteRegEx": "Melamed", "year": 1999}, {"title": "Models of translational equivalence among words", "author": ["D. Melamed"], "venue": "Computational Linguistics,", "citeRegEx": "Melamed,? \\Q2000\\E", "shortCiteRegEx": "Melamed", "year": 2000}, {"title": "Automatic detection of orthographic cues for cognate recognition", "author": ["A. Mulloni", "V. Pekar"], "venue": "In Proceedings of the 5th International Conference on Language Resources and Evaluation,", "citeRegEx": "Mulloni and Pekar,? \\Q2006\\E", "shortCiteRegEx": "Mulloni and Pekar", "year": 2006}, {"title": "Improved statistical machine translation using monolingual paraphrases", "author": ["P. Nakov"], "venue": "In Proceedings of the 18th European Conference on Artificial Intelligence,", "citeRegEx": "Nakov,? \\Q2008\\E", "shortCiteRegEx": "Nakov", "year": 2008}, {"title": "Improved word alignments using the Web as a corpus", "author": ["P. Nakov", "S. Nakov", "E. Paskaleva"], "venue": "In Proceedings of the International Conference on Recent Advances in Natural Language Processing,", "citeRegEx": "Nakov et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2007}, {"title": "Improved statistical machine translation for resource-poor languages using related resource-rich languages", "author": ["P. Nakov", "H.T. Ng"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Nakov and Ng,? \\Q2009\\E", "shortCiteRegEx": "Nakov and Ng", "year": 2009}, {"title": "NUS at WMT09: Domain adaptation experiments for English-Spanish machine translation of news commentary text", "author": ["P. Nakov", "H.T. Ng"], "venue": "In Proceedings of the Fourth Workshop on Statistical Machine Translation,", "citeRegEx": "Nakov and Ng,? \\Q2009\\E", "shortCiteRegEx": "Nakov and Ng", "year": 2009}, {"title": "Minimum error rate training in statistical machine translation", "author": ["F.J. Och"], "venue": "In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Och,? \\Q2003\\E", "shortCiteRegEx": "Och", "year": 2003}, {"title": "Statistical multi-source translation", "author": ["F.J. Och", "H. Ney"], "venue": "In Proceedings of MT Summit VIII. Machine Translation in the Information Age, MT Summit", "citeRegEx": "Och and Ney,? \\Q2001\\E", "shortCiteRegEx": "Och and Ney", "year": 2001}, {"title": "A comparison of different machine transliteration models", "author": ["Oh", "J.-H", "Choi", "K.-S", "H. Isahara"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "Oh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Oh et al\\.", "year": 2006}, {"title": "BLEU: a method for automatic evaluation of machine translation", "author": ["K. Papineni", "S. Roukos", "T. Ward", "Zhu", "W.-J"], "venue": "In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "On the importance of pivot language selection for statistical machine translation", "author": ["M. Paul", "H. Yamamoto", "E. Sumita", "S. Nakamura"], "venue": "In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "Paul et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Paul et al\\.", "year": 2009}, {"title": "Dependency treelet translation: Syntactically informed phrasal SMT", "author": ["C. Quirk", "A. Menezes", "C. Cherry"], "venue": "In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Quirk et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Quirk et al\\.", "year": 2005}, {"title": "Induction of cross-language affix and letter sequence correspondence", "author": ["A. Rappoport", "T. Levent-Levi"], "venue": "In Proceedings of the International Workshop on CrossLanguage Knowledge Induction, CrossLangInduction", "citeRegEx": "Rappoport and Levent.Levi,? \\Q2006\\E", "shortCiteRegEx": "Rappoport and Levent.Levi", "year": 2006}, {"title": "Learning string-edit distance", "author": ["E. Ristad", "P. Yianilos"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Ristad and Yianilos,? \\Q1998\\E", "shortCiteRegEx": "Ristad and Yianilos", "year": 1998}, {"title": "Dialectal to standard Arabic paraphrasing to improve Arabic-English statistical machine translation", "author": ["W. Salloum", "N. Habash"], "venue": "In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,", "citeRegEx": "Salloum and Habash,? \\Q2011\\E", "shortCiteRegEx": "Salloum and Habash", "year": 2011}, {"title": "Arabic dialect handling in hybrid machine translation", "author": ["H. Sawaf"], "venue": "In Proceedings of the 9th Conference of the Association for Machine Translation in the Americas,", "citeRegEx": "Sawaf,? \\Q2010\\E", "shortCiteRegEx": "Sawaf", "year": 2010}, {"title": "Machine translation for closely related language pairs. In Proceedings of the LREC2006 Workshop on Strategies for Developing Machine Translation for Minority Languages, Genoa, Italy", "author": ["K. Scannell"], "venue": null, "citeRegEx": "Scannell,? \\Q2006\\E", "shortCiteRegEx": "Scannell", "year": 2006}, {"title": "Inducing translation lexicons via diverse similarity measures and bridge languages", "author": ["C. Schafer", "D. Yarowsky"], "venue": "In Proceedings of the 6th Conference on Natural Language Learning,", "citeRegEx": "Schafer and Yarowsky,? \\Q2002\\E", "shortCiteRegEx": "Schafer and Yarowsky", "year": 2002}, {"title": "Adaptive string distance measures for bilingual dialect lexicon induction", "author": ["Y. Scherrer"], "venue": "In Proceedings of the 45th Annual Meeting of the ACL: Student Research Workshop,", "citeRegEx": "Scherrer,? \\Q2007\\E", "shortCiteRegEx": "Scherrer", "year": 2007}, {"title": "Word lattices for multi-source translation", "author": ["J. Schroeder", "T. Cohn", "P. Koehn"], "venue": "In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,", "citeRegEx": "Schroeder et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Schroeder et al\\.", "year": 2009}, {"title": "Language and translation model adaptation using comparable corpora", "author": ["M. Snover", "B. Dorr", "R. Schwartz"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Snover et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Snover et al\\.", "year": 2008}, {"title": "The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages", "author": ["R. Steinberger", "B. Pouliquen", "A. Widiger", "C. Ignat", "T. Erjavec", "D. Tufis", "D. Varga"], "venue": "In Proceedings of the 5th International Conference on Language Resources and Evaluation,", "citeRegEx": "Steinberger et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Steinberger et al\\.", "year": 2006}, {"title": "Context-based approach for pivot translation services", "author": ["R. Tanaka", "Y. Murakami", "T. Ishida"], "venue": "In Proceedings of the 21st International Joint Conference on Artifical intelligence,", "citeRegEx": "Tanaka et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Tanaka et al\\.", "year": 2009}, {"title": "Automatic construction of weighted string similarity measures", "author": ["J. Tiedemann"], "venue": "In Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,", "citeRegEx": "Tiedemann,? \\Q1999\\E", "shortCiteRegEx": "Tiedemann", "year": 1999}, {"title": "Character-based PSMT for closely related languages", "author": ["J. Tiedemann"], "venue": "In Proceedings of the 13th Annual Conference of the European Association for Machine Translation,", "citeRegEx": "Tiedemann,? \\Q2009\\E", "shortCiteRegEx": "Tiedemann", "year": 2009}, {"title": "Translating transliterations", "author": ["J. Tiedemann", "P. Nabende"], "venue": "International Journal of Computing and ICT Research,", "citeRegEx": "Tiedemann and Nabende,? \\Q2009\\E", "shortCiteRegEx": "Tiedemann and Nabende", "year": 2009}, {"title": "Semi-supervised model adaptation for statistical machine translation", "author": ["N. Ueffing", "G. Haffari", "A. Sarkar"], "venue": "Machine Translation,", "citeRegEx": "Ueffing et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ueffing et al\\.", "year": 2007}, {"title": "A comparison of pivot methods for phrase-based statistical machine translation. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics", "author": ["M. Utiyama", "H. Isahara"], "venue": "Proceedings of the Main Conference,", "citeRegEx": "Utiyama and Isahara,? \\Q2007\\E", "shortCiteRegEx": "Utiyama and Isahara", "year": 2007}, {"title": "Can we translate letters", "author": ["D. Vilar", "Peter", "J.-T", "H. Ney"], "venue": "In Proceedings of the Second Workshop on Statistical Machine Translation,", "citeRegEx": "Vilar et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Vilar et al\\.", "year": 2007}, {"title": "HMM-based word alignment in statistical translation", "author": ["S. Vogel", "H. Ney", "C. Tillmann"], "venue": "In Proceedings of the 16th conference on Computational linguistics,", "citeRegEx": "Vogel et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 1996}, {"title": "Pivot language approach for phrase-based statistical machine translation", "author": ["H. Wu", "H. Wang"], "venue": "Machine Translation,", "citeRegEx": "Wu and Wang,? \\Q2007\\E", "shortCiteRegEx": "Wu and Wang", "year": 2007}, {"title": "Dialect MT: a case study between Cantonese and Mandarin", "author": ["X. Zhang"], "venue": "In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,", "citeRegEx": "Zhang,? \\Q1998\\E", "shortCiteRegEx": "Zhang", "year": 1998}], "referenceMentions": [{"referenceID": 43, "context": "3M parallel sentences (up to 44M words) per language for 11 languages (Koehn, 2005), and the JRC-Acquis corpus provides a comparable amount of European legislation in 22 languages (Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis, & Varga, 2006).", "startOffset": 70, "endOffset": 83}, {"referenceID": 17, "context": ", hierarchical (Chiang, 2005), treelet (Quirk, Menezes, & Cherry, 2005), and syntactic (Galley, Hopkins, Knight, & Marcu, 2004).", "startOffset": 15, "endOffset": 29}, {"referenceID": 14, "context": "Many efficient techniques have been developed for domain adaptation in natural language processing; see the work of Daum\u00e9 and Marcu (2006), Jiang and Zhai (2007a, 2007b), Chan and Ng (2005, 2006, 2007), and Dahlmeier and Ng (2010) for some examples.", "startOffset": 171, "endOffset": 231}, {"referenceID": 14, "context": "Many efficient techniques have been developed for domain adaptation in natural language processing; see the work of Daum\u00e9 and Marcu (2006), Jiang and Zhai (2007a, 2007b), Chan and Ng (2005, 2006, 2007), and Dahlmeier and Ng (2010) for some examples. Unfortunately, these techniques are not directly applicable to machine translation, which is much more complicated, and leaves a lot more space for variety in the proposed solutions. This is so despite the limited previous work on domain adaptation for SMT, which has focused almost exclusively on adapting European parliament debates to the news domain as part of the annual competition on machine translation evaluation at the WMT workshop. To mention just a few of the proposed approaches, Hildebrand, Eck, Vogel, and Waibel (2005) use information retrieval techniques to choose training samples that are similar to the test set as a way to adapt the translation model, while Ueffing, Haffari, and Sarkar (2007) adapt the translation model in a semi-supervised manner using monolingual data from the source language.", "startOffset": 171, "endOffset": 785}, {"referenceID": 14, "context": "Many efficient techniques have been developed for domain adaptation in natural language processing; see the work of Daum\u00e9 and Marcu (2006), Jiang and Zhai (2007a, 2007b), Chan and Ng (2005, 2006, 2007), and Dahlmeier and Ng (2010) for some examples. Unfortunately, these techniques are not directly applicable to machine translation, which is much more complicated, and leaves a lot more space for variety in the proposed solutions. This is so despite the limited previous work on domain adaptation for SMT, which has focused almost exclusively on adapting European parliament debates to the news domain as part of the annual competition on machine translation evaluation at the WMT workshop. To mention just a few of the proposed approaches, Hildebrand, Eck, Vogel, and Waibel (2005) use information retrieval techniques to choose training samples that are similar to the test set as a way to adapt the translation model, while Ueffing, Haffari, and Sarkar (2007) adapt the translation model in a semi-supervised manner using monolingual data from the source language.", "startOffset": 171, "endOffset": 965}, {"referenceID": 14, "context": "Many efficient techniques have been developed for domain adaptation in natural language processing; see the work of Daum\u00e9 and Marcu (2006), Jiang and Zhai (2007a, 2007b), Chan and Ng (2005, 2006, 2007), and Dahlmeier and Ng (2010) for some examples. Unfortunately, these techniques are not directly applicable to machine translation, which is much more complicated, and leaves a lot more space for variety in the proposed solutions. This is so despite the limited previous work on domain adaptation for SMT, which has focused almost exclusively on adapting European parliament debates to the news domain as part of the annual competition on machine translation evaluation at the WMT workshop. To mention just a few of the proposed approaches, Hildebrand, Eck, Vogel, and Waibel (2005) use information retrieval techniques to choose training samples that are similar to the test set as a way to adapt the translation model, while Ueffing, Haffari, and Sarkar (2007) adapt the translation model in a semi-supervised manner using monolingual data from the source language. Snover, Dorr, and Schwartz (2008) adapt both the translation and the language model, using comparable monolingual data in the target language.", "startOffset": 171, "endOffset": 1104}, {"referenceID": 14, "context": "Many efficient techniques have been developed for domain adaptation in natural language processing; see the work of Daum\u00e9 and Marcu (2006), Jiang and Zhai (2007a, 2007b), Chan and Ng (2005, 2006, 2007), and Dahlmeier and Ng (2010) for some examples. Unfortunately, these techniques are not directly applicable to machine translation, which is much more complicated, and leaves a lot more space for variety in the proposed solutions. This is so despite the limited previous work on domain adaptation for SMT, which has focused almost exclusively on adapting European parliament debates to the news domain as part of the annual competition on machine translation evaluation at the WMT workshop. To mention just a few of the proposed approaches, Hildebrand, Eck, Vogel, and Waibel (2005) use information retrieval techniques to choose training samples that are similar to the test set as a way to adapt the translation model, while Ueffing, Haffari, and Sarkar (2007) adapt the translation model in a semi-supervised manner using monolingual data from the source language. Snover, Dorr, and Schwartz (2008) adapt both the translation and the language model, using comparable monolingual data in the target language. Nakov and Ng (2009b) adapt the translation model for phrase-based SMT by combining phrase tables using extra features indicating the source of each phrase; we will use this combination technique as part of our proposed approach below.", "startOffset": 171, "endOffset": 1234}, {"referenceID": 14, "context": "Many efficient techniques have been developed for domain adaptation in natural language processing; see the work of Daum\u00e9 and Marcu (2006), Jiang and Zhai (2007a, 2007b), Chan and Ng (2005, 2006, 2007), and Dahlmeier and Ng (2010) for some examples. Unfortunately, these techniques are not directly applicable to machine translation, which is much more complicated, and leaves a lot more space for variety in the proposed solutions. This is so despite the limited previous work on domain adaptation for SMT, which has focused almost exclusively on adapting European parliament debates to the news domain as part of the annual competition on machine translation evaluation at the WMT workshop. To mention just a few of the proposed approaches, Hildebrand, Eck, Vogel, and Waibel (2005) use information retrieval techniques to choose training samples that are similar to the test set as a way to adapt the translation model, while Ueffing, Haffari, and Sarkar (2007) adapt the translation model in a semi-supervised manner using monolingual data from the source language. Snover, Dorr, and Schwartz (2008) adapt both the translation and the language model, using comparable monolingual data in the target language. Nakov and Ng (2009b) adapt the translation model for phrase-based SMT by combining phrase tables using extra features indicating the source of each phrase; we will use this combination technique as part of our proposed approach below. Finally, Daum\u00e9 and Jagarlamudi (2011) address the domain shift problem by mining appropriate translations for the unseen words.", "startOffset": 171, "endOffset": 1486}, {"referenceID": 53, "context": "Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, and Yarowsky (1999) extracted such likely cognates for Czech-English, using one of the variations of the longest common subsequence ratio or LCSR (Melamed, 1995) described by Tiedemann (1999) as a similarity measure.", "startOffset": 217, "endOffset": 232}, {"referenceID": 55, "context": "It was further extended by Nakov, Nakov, and Paskaleva (2007), who combined LCSR and sentence-level co-occurrences in a bi-text with competitive linking (Melamed, 2000), language-specific weights, and Web n-gram frequencies.", "startOffset": 153, "endOffset": 168}, {"referenceID": 52, "context": "Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, and Yarowsky (1999) extracted such likely cognates for Czech-English, using one of the variations of the longest common subsequence ratio or LCSR (Melamed, 1995) described by Tiedemann (1999) as a similarity measure.", "startOffset": 43, "endOffset": 91}, {"referenceID": 52, "context": "Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, and Yarowsky (1999) extracted such likely cognates for Czech-English, using one of the variations of the longest common subsequence ratio or LCSR (Melamed, 1995) described by Tiedemann (1999) as a similarity measure.", "startOffset": 43, "endOffset": 263}, {"referenceID": 47, "context": "The last approach performed best and was later used by Kondrak, Marcu, and Knight (2003) who demonstrated improved SMT for nine European languages.", "startOffset": 55, "endOffset": 89}, {"referenceID": 47, "context": "The last approach performed best and was later used by Kondrak, Marcu, and Knight (2003) who demonstrated improved SMT for nine European languages. It was further extended by Nakov, Nakov, and Paskaleva (2007), who combined LCSR and sentence-level co-occurrences in a bi-text with competitive linking (Melamed, 2000), language-specific weights, and Web n-gram frequencies.", "startOffset": 55, "endOffset": 210}, {"referenceID": 52, "context": "Transliteration can be modeled using character-based machine translation techniques (Matthews, 2007; Nakov & Ng, 2009a; Tiedemann & Nabende, 2009), which are related to the character-based SMT model of Vilar, Peter, and Ney (2007), and Tiedemann (2009).", "startOffset": 84, "endOffset": 146}, {"referenceID": 42, "context": "For example, Mann and Yarowsky (2001) induce translation lexicons between a resource-rich language (e.", "startOffset": 13, "endOffset": 38}, {"referenceID": 42, "context": "For example, Mann and Yarowsky (2001) induce translation lexicons between a resource-rich language (e.g., English) and a resourcepoor language (e.g., Portuguese) using a resource-rich bridge language that is closely related to the latter (e.g., Spanish). They use pre-existing translation lexicons for the sourceto-bridge mapping step (e.g., English-Spanish), and string distance measures for finding cognates for the bridge-to-target step (e.g., Spanish-Portuguese). This work was extended by Schafer and Yarowsky (2002), and later by Scherrer (2007), who relies on graphemic similarity for inducing bilingual lexicons between Swiss German and Standard German.", "startOffset": 13, "endOffset": 522}, {"referenceID": 42, "context": "For example, Mann and Yarowsky (2001) induce translation lexicons between a resource-rich language (e.g., English) and a resourcepoor language (e.g., Portuguese) using a resource-rich bridge language that is closely related to the latter (e.g., Spanish). They use pre-existing translation lexicons for the sourceto-bridge mapping step (e.g., English-Spanish), and string distance measures for finding cognates for the bridge-to-target step (e.g., Spanish-Portuguese). This work was extended by Schafer and Yarowsky (2002), and later by Scherrer (2007), who relies on graphemic similarity for inducing bilingual lexicons between Swiss German and Standard German.", "startOffset": 13, "endOffset": 552}, {"referenceID": 38, "context": "Koehn and Knight (2002) describe several techniques for inducing translation lexicons from monolingual corpora.", "startOffset": 0, "endOffset": 24}, {"referenceID": 38, "context": "Koehn and Knight (2002) describe several techniques for inducing translation lexicons from monolingual corpora. Starting with unrelated German and English corpora, they look for (1) identical words, (2) cognates, (3) words with similar frequencies, (4) words with similar meanings, and (5) words with similar contexts. This is a bootstrapping process, where new translation pairs are added to the lexicon at each iteration. More recent work on automatic lexicon induction includes that by Haghighi, Liang, Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009).", "startOffset": 0, "endOffset": 541}, {"referenceID": 9, "context": "More recent work on automatic lexicon induction includes that by Haghighi, Liang, Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009). Finally, there is a lot of research on string similarity that has been applied to cognate identification: Ristad and Yianilos (1998) and Mann and Yarowsky (2001) use the minimum edit distance ratio or MEDR with weights that are learned automatically using a stochastic transducer.", "startOffset": 130, "endOffset": 166}, {"referenceID": 9, "context": "More recent work on automatic lexicon induction includes that by Haghighi, Liang, Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009). Finally, there is a lot of research on string similarity that has been applied to cognate identification: Ristad and Yianilos (1998) and Mann and Yarowsky (2001) use the minimum edit distance ratio or MEDR with weights that are learned automatically using a stochastic transducer.", "startOffset": 130, "endOffset": 300}, {"referenceID": 9, "context": "More recent work on automatic lexicon induction includes that by Haghighi, Liang, Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009). Finally, there is a lot of research on string similarity that has been applied to cognate identification: Ristad and Yianilos (1998) and Mann and Yarowsky (2001) use the minimum edit distance ratio or MEDR with weights that are learned automatically using a stochastic transducer.", "startOffset": 130, "endOffset": 329}, {"referenceID": 9, "context": "More recent work on automatic lexicon induction includes that by Haghighi, Liang, Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009). Finally, there is a lot of research on string similarity that has been applied to cognate identification: Ristad and Yianilos (1998) and Mann and Yarowsky (2001) use the minimum edit distance ratio or MEDR with weights that are learned automatically using a stochastic transducer. Tiedemann (1999) and Mulloni and Pekar (2006) learn automatically the regular spelling changes between two related languages, which they incorporate in similarity measures based on LCSR and on MEDR, respectively.", "startOffset": 130, "endOffset": 465}, {"referenceID": 9, "context": "More recent work on automatic lexicon induction includes that by Haghighi, Liang, Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009). Finally, there is a lot of research on string similarity that has been applied to cognate identification: Ristad and Yianilos (1998) and Mann and Yarowsky (2001) use the minimum edit distance ratio or MEDR with weights that are learned automatically using a stochastic transducer. Tiedemann (1999) and Mulloni and Pekar (2006) learn automatically the regular spelling changes between two related languages, which they incorporate in similarity measures based on LCSR and on MEDR, respectively.", "startOffset": 130, "endOffset": 494}, {"referenceID": 9, "context": "More recent work on automatic lexicon induction includes that by Haghighi, Liang, Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009). Finally, there is a lot of research on string similarity that has been applied to cognate identification: Ristad and Yianilos (1998) and Mann and Yarowsky (2001) use the minimum edit distance ratio or MEDR with weights that are learned automatically using a stochastic transducer. Tiedemann (1999) and Mulloni and Pekar (2006) learn automatically the regular spelling changes between two related languages, which they incorporate in similarity measures based on LCSR and on MEDR, respectively. Kondrak (2005) proposes a formula for measuring string similarity based on LCSR with a correction that addresses its general preference for short words.", "startOffset": 130, "endOffset": 676}, {"referenceID": 9, "context": "More recent work on automatic lexicon induction includes that by Haghighi, Liang, Berg-Kirkpatrick, and Klein (2008), and Garera, Callison-Burch, and Yarowsky (2009). Finally, there is a lot of research on string similarity that has been applied to cognate identification: Ristad and Yianilos (1998) and Mann and Yarowsky (2001) use the minimum edit distance ratio or MEDR with weights that are learned automatically using a stochastic transducer. Tiedemann (1999) and Mulloni and Pekar (2006) learn automatically the regular spelling changes between two related languages, which they incorporate in similarity measures based on LCSR and on MEDR, respectively. Kondrak (2005) proposes a formula for measuring string similarity based on LCSR with a correction that addresses its general preference for short words. Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity.", "startOffset": 130, "endOffset": 841}, {"referenceID": 4, "context": "Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity.", "startOffset": 31, "endOffset": 58}, {"referenceID": 4, "context": "Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity. Rappoport and Levent-Levi (2006) learn substring correspondences for cognates, using the string-level substitutions framework of Brill and Moore (2000).", "startOffset": 31, "endOffset": 158}, {"referenceID": 4, "context": "Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity. Rappoport and Levent-Levi (2006) learn substring correspondences for cognates, using the string-level substitutions framework of Brill and Moore (2000). Finally, Inkpen, Frunza, and Kondrak (2005) compare several orthographic similarity measures for cognate extraction.", "startOffset": 31, "endOffset": 277}, {"referenceID": 4, "context": "Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity. Rappoport and Levent-Levi (2006) learn substring correspondences for cognates, using the string-level substitutions framework of Brill and Moore (2000). Finally, Inkpen, Frunza, and Kondrak (2005) compare several orthographic similarity measures for cognate extraction.", "startOffset": 31, "endOffset": 322}, {"referenceID": 4, "context": "Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity. Rappoport and Levent-Levi (2006) learn substring correspondences for cognates, using the string-level substitutions framework of Brill and Moore (2000). Finally, Inkpen, Frunza, and Kondrak (2005) compare several orthographic similarity measures for cognate extraction. While cognates are typically extracted between related languages, there are words with similar spelling between unrelated languages as well, e.g., Arabic, Chinese, Japanese, and Korean proper names are transliterated to English, which uses a different alphabet. See the work of Oh, Choi, and Isahara (2006) for an overview and a comparison of different transliteration models, as well as the proceedings of the annual NEWS named entities workshop, which features shared tasks on transliteration mining and generation (Li & Kumaran, 2010).", "startOffset": 31, "endOffset": 702}, {"referenceID": 4, "context": "Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity. Rappoport and Levent-Levi (2006) learn substring correspondences for cognates, using the string-level substitutions framework of Brill and Moore (2000). Finally, Inkpen, Frunza, and Kondrak (2005) compare several orthographic similarity measures for cognate extraction. While cognates are typically extracted between related languages, there are words with similar spelling between unrelated languages as well, e.g., Arabic, Chinese, Japanese, and Korean proper names are transliterated to English, which uses a different alphabet. See the work of Oh, Choi, and Isahara (2006) for an overview and a comparison of different transliteration models, as well as the proceedings of the annual NEWS named entities workshop, which features shared tasks on transliteration mining and generation (Li & Kumaran, 2010). Transliteration can be modeled using character-based machine translation techniques (Matthews, 2007; Nakov & Ng, 2009a; Tiedemann & Nabende, 2009), which are related to the character-based SMT model of Vilar, Peter, and Ney (2007), and Tiedemann (2009).", "startOffset": 31, "endOffset": 1165}, {"referenceID": 4, "context": "Klementiev and Roth (2006) and Bergsma and Kondrak (2007) propose discriminative frameworks for measuring string similarity. Rappoport and Levent-Levi (2006) learn substring correspondences for cognates, using the string-level substitutions framework of Brill and Moore (2000). Finally, Inkpen, Frunza, and Kondrak (2005) compare several orthographic similarity measures for cognate extraction. While cognates are typically extracted between related languages, there are words with similar spelling between unrelated languages as well, e.g., Arabic, Chinese, Japanese, and Korean proper names are transliterated to English, which uses a different alphabet. See the work of Oh, Choi, and Isahara (2006) for an overview and a comparison of different transliteration models, as well as the proceedings of the annual NEWS named entities workshop, which features shared tasks on transliteration mining and generation (Li & Kumaran, 2010). Transliteration can be modeled using character-based machine translation techniques (Matthews, 2007; Nakov & Ng, 2009a; Tiedemann & Nabende, 2009), which are related to the character-based SMT model of Vilar, Peter, and Ney (2007), and Tiedemann (2009).", "startOffset": 31, "endOffset": 1187}, {"referenceID": 71, "context": "This has been tried for a number of language pairs including Czech\u2013Slovak (Haji\u010d, Hric, & Kubo\u0148, 2000), Turkish\u2013Crimean Tatar (Altintas & Cicekli, 2002), and Irish\u2013Scottish Gaelic (Scannell, 2006), among others.", "startOffset": 180, "endOffset": 196}, {"referenceID": 86, "context": ", between Cantonese and Mandarin (Zhang, 1998), or between a dialect of a language and a standard version of that language, e.", "startOffset": 33, "endOffset": 46}, {"referenceID": 70, "context": ", Egyptian) and Modern Standard Arabic (Bakr, Shaalan, & Ziedan, 2008; Sawaf, 2010; Salloum & Habash, 2011).", "startOffset": 39, "endOffset": 107}, {"referenceID": 70, "context": ", Egyptian) and Modern Standard Arabic (Bakr, Shaalan, & Ziedan, 2008; Sawaf, 2010; Salloum & Habash, 2011). Here again, manual rules and/or language-specific tools are typically used. In the case of Arabic dialects, a further complication arises by the informal status of the dialects, which are not standardized and not used in formal contexts but rather only in informal online communities6 such as social networks, chats, Twitter and SMS messages. This causes further mismatch in domain and genre. Thus, translating from Arabic dialects to Modern Standard Arabic requires, among other things, normalizing informal text to a formal form. In fact, this is a more general problem, which arises with informal sources like SMS messages and Tweets for any language (Han & Baldwin, 2011). Here the main focus is on coping with spelling errors, abbreviations, and slang, which are typically addressed using string edit distance, while also taking pronunciation into account. This is different from our task, where we try to reuse good, formal text from one language to help improve SMT for another language. A closely related relevant line of research is on language adaptation and normalization, when done specifically for improving SMT into another language. For example, Marujo, Grazina, L\u00fa\u0131s, Ling, Coheur, and Trancoso (2011) described a rule-based system for adapting Brazilian Portuguese (BP) to European Portuguese (EP), which they used to adapt BP\u2013 English bi-texts to EP\u2013English.", "startOffset": 71, "endOffset": 1327}, {"referenceID": 43, "context": "Callison-Burch, Koehn, and Osborne (2006) improved phrase-based SMT from Spanish and French to English using source-language phrase-level paraphrases extracted using the pivoting technique of Bannard and Callison-Burch (2005) and eight additional languages from the Europarl corpus (Koehn, 2005).", "startOffset": 282, "endOffset": 295}, {"referenceID": 10, "context": "Callison-Burch, Koehn, and Osborne (2006) improved phrase-based SMT from Spanish and French to English using source-language phrase-level paraphrases extracted using the pivoting technique of Bannard and Callison-Burch (2005) and eight additional languages from the Europarl corpus (Koehn, 2005).", "startOffset": 0, "endOffset": 42}, {"referenceID": 3, "context": "Callison-Burch, Koehn, and Osborne (2006) improved phrase-based SMT from Spanish and French to English using source-language phrase-level paraphrases extracted using the pivoting technique of Bannard and Callison-Burch (2005) and eight additional languages from the Europarl corpus (Koehn, 2005).", "startOffset": 192, "endOffset": 226}, {"referenceID": 61, "context": "The system was then tuned with minimum error rate training (MERT) (Och, 2003), adding an extra feature penalizing low-probability paraphrases; this yielded huge increase in coverage (from 48% to 90% of the test word types when 10K training sentence pairs were used), and up to 1.", "startOffset": 66, "endOffset": 77}, {"referenceID": 57, "context": ", we run MERT for phrase tables with one, two, and three extra features and we choose the phrase table that has achieved the highest BLEU score on tuning, as suggested in the work of Nakov (2008).", "startOffset": 183, "endOffset": 196}, {"referenceID": 55, "context": "Next, we extracted pairs of sentences from the matched document pairs using competitive linking (Melamed, 2000), and we retained the ones whose similarity was above a pre-specified threshold.", "startOffset": 96, "endOffset": 111}, {"referenceID": 54, "context": "While linguists define cognates as words derived from a common root9 (Bickford & Tuggy, 2002), computational linguists typically ignore origin, defining them as words in different languages that are mutual translations and have a similar orthography (Melamed, 1999; Mann & Yarowsky, 2001; Bergsma & Kondrak, 2007).", "startOffset": 250, "endOffset": 313}, {"referenceID": 48, "context": "Classic approaches to automatic cognate extraction look for non-stopwords with similar spelling that appear in parallel sentences in a bi-text (Kondrak et al., 2003).", "startOffset": 143, "endOffset": 165}, {"referenceID": 47, "context": "While linguists define cognates as words derived from a common root9 (Bickford & Tuggy, 2002), computational linguists typically ignore origin, defining them as words in different languages that are mutual translations and have a similar orthography (Melamed, 1999; Mann & Yarowsky, 2001; Bergsma & Kondrak, 2007). Here we adopt the latter definition. As we have seen in Section 3, transliteration can be very helpful for languages like Spanish and Portuguese, which have many regular spelling differences. Thus, we build a system for automatic transliteration from Portuguese to Spanish, which we train on a list of automatically extracted pairs of likely cognates. We apply this system on the Portuguese side of the pt-en training bi-text. Classic approaches to automatic cognate extraction look for non-stopwords with similar spelling that appear in parallel sentences in a bi-text (Kondrak et al., 2003). In our case, however, we need to extract cognates between Spanish and Portuguese given pt-en and es-en bi-texts only, i.e., without having a pt-es bi-text. Although it is easy to construct a pt-es bi-text from the Europarl corpus, we chose not to do so since, in general, synthesizing a bi-text for X1-X2 would be impossible: e.g., it cannot be done for ml-in given our training datasets for in-en and ml-en since their English sides have no sentences in common. Thus, we extracted the list of likely cognates between Portuguese and Spanish from the training pt-en and es-en bi-texts using English as a pivot as follows: We started with IBM model 4 word alignments, from which we extracted four conditional lexical translation probabilities: Pr(pj |ei) and Pr(ei|pj) for Portuguese-English, and Pr(sk|ei) and Pr(ei|sk) for Spanish-English, where pj , ei, and sk stand for a Portuguese, an English and a Spanish word, respectively. Following Wu and Wang (2007), we then induced conditional lexical translation probabilities Pr(pj |sk) and Pr(sk|pj) for Portuguese-Spanish as follows:", "startOffset": 299, "endOffset": 1869}, {"referenceID": 11, "context": "01 has been previously suggested for filtering phrase pairs obtained using pivoting (Callison-Burch, 2008, 2012; Denkowski & Lavie, 2010; Denkowski, 2012). From the remaining pairs, we extracted likely cognates based on Prod(pj , sk) and on the orthographic similarity between pj and sk. Following Melamed (1995), we measured the orthographic similarity using the longest common subsequence ratio (lcsr), defined as follows:", "startOffset": 85, "endOffset": 313}, {"referenceID": 55, "context": "Finally, we performed competitive linking (Melamed, 2000), assuming that each Portuguese wordform had at most one Spanish best cognate match.", "startOffset": 42, "endOffset": 57}, {"referenceID": 47, "context": "58 or higher; this value was found by Kondrak et al. (2003) to be optimal for a number of language pairs in the Europarl corpus.", "startOffset": 38, "endOffset": 60}, {"referenceID": 28, "context": "We randomly split the resulting list into a training (26,725 pairs) and a development dataset (2,000 pairs), and we trained and tuned a character-level phrase-based monotone SMT system similar to Finch and Sumita (2008) to transliterate a Portuguese wordform into a Spanish wordform.", "startOffset": 196, "endOffset": 220}, {"referenceID": 48, "context": "Finally, we combine our method with two orthogonal rivaling approaches: (1) using cognates between the source and the target language (Kondrak et al., 2003), and (2) source-language side paraphrasing with a pivot language (Callison-Burch et al.", "startOffset": 134, "endOffset": 156}, {"referenceID": 13, "context": ", 2003), and (2) source-language side paraphrasing with a pivot language (Callison-Burch et al., 2006).", "startOffset": 73, "endOffset": 102}, {"referenceID": 43, "context": "Third, the improvements are always statistically significant for our approach, according to Collins, Koehn, and Ku\u010derov\u00e1\u2019s (2005) sign test.", "startOffset": 101, "endOffset": 130}, {"referenceID": 47, "context": "7 Combining Our Method with the Cognate Extraction Technique of Kondrak et al. (2003)", "startOffset": 64, "endOffset": 86}, {"referenceID": 47, "context": "Next, we combined our method with the cognate extraction technique of Kondrak et al. (2003), where pairs of likely cognates are extracted from the original training bi-text and then added to that bi-text as additional 1-word-to-1-word sentence pairs.", "startOffset": 70, "endOffset": 92}, {"referenceID": 47, "context": "Table 8: Spanish\u2192English: combining our method with the cognate extraction technique of Kondrak et al. (2003). Shown are BLEU scores (in %) and absolute improvements (over the baseline and over our method) for training bitexts with different numbers of parallel es-en sentence pairs (10K, 20K, .", "startOffset": 88, "endOffset": 110}, {"referenceID": 47, "context": "As we can see, it is worth combining our method with the cognate extraction technique of Kondrak et al. (2003) for small original es-en datasets, e.", "startOffset": 89, "endOffset": 111}, {"referenceID": 47, "context": "We found it interesting that combining our method with the cognate extraction technique of Kondrak et al. (2003) does not help so much when we used transliteration compared to when we do not use it.", "startOffset": 91, "endOffset": 113}, {"referenceID": 11, "context": "8 Combining Our Method with the Phrase Table Pivoting Technique of Callison-Burch et al. (2006)", "startOffset": 67, "endOffset": 96}, {"referenceID": 11, "context": "Finally, we combined our method with the phrase table pivoting technique of Callison-Burch et al. (2006) since they are orthogonal.", "startOffset": 76, "endOffset": 105}, {"referenceID": 11, "context": "First, we tried to reproduce the phrase table pivoting experiments of Callison-Burch et al. (2006), which turned out to be complicated (even though we used their original code to do the pivoting) because of various differences in our experimental setups: (1) we used Moses instead of Pharaoh for translation; (2) we used IRSTLM instead of SRILM for language modeling; (3) we used different tokenization; (4) we used a maximum phrase length of up to seven instead of ten; (5) we created our training/dev/test dataset out of Europarl v.", "startOffset": 70, "endOffset": 99}, {"referenceID": 11, "context": "The bottom three lines show the results reported by Callison-Burch et al. (2006), while the top three lines report the BLEU scores for our reproduction of their experiments, in which about 1.", "startOffset": 52, "endOffset": 81}, {"referenceID": 11, "context": "The combination was carried in the following way: after we had built the final merged phrase table for our method, we paraphrased its source side through pivoting using the method of Callison-Burch et al. (2006). The middle lines of the table show the BLEU scores (in %) of the combined method and absolute improvements (over the baseline and over our method) for training bi-texts with different numbers of parallel es-en sentence pairs (10K, 20K, .", "startOffset": 183, "endOffset": 212}, {"referenceID": 47, "context": ", 10K or 20K (in which cases, statistically significant improvements occur over using our method only), but only when our method does not use transliteration, as was the case for the cognate extraction technique of Kondrak et al. (2003).", "startOffset": 215, "endOffset": 237}, {"referenceID": 11, "context": "Table 9: Spanish\u2192English: combining our method with the phrase table pivoting technique of Callison-Burch et al. (2006). Shown are BLEU scores (in %) and absolute improvements (over the baseline and over our method) for training bi-texts with different numbers of parallel es-en sentence pairs (10K, 20K, .", "startOffset": 91, "endOffset": 120}, {"referenceID": 11, "context": "Table 9: Spanish\u2192English: combining our method with the phrase table pivoting technique of Callison-Burch et al. (2006). Shown are BLEU scores (in %) and absolute improvements (over the baseline and over our method) for training bi-texts with different numbers of parallel es-en sentence pairs (10K, 20K, . . ., 320K) and fixed amount of additional pt-en pairs: (1) about 1.3M pairs for each of eight additional languages in pivoting, and (2) 160K and 1.23M pairs for one language (Portuguese) for our method (with and without transliteration). The last three lines show the results of the phrase table pivoting experiments reported in Callison-Burch et al. (2006) while the first three lines show our reproduction of these experiments.", "startOffset": 91, "endOffset": 665}], "year": 2012, "abstractText": "We propose a novel language-independent approach for improving machine translation for resource-poor languages by exploiting their similarity to resource-rich ones. More precisely, we improve the translation from a resource-poor source language X1 into a resourcerich language Y given a bi-text containing a limited number of parallel sentences for X1-Y and a larger bi-text for X2-Y for some resource-rich language X2 that is closely related to X1. This is achieved by taking advantage of the opportunities that vocabulary overlap and similarities between the languages X1 and X2 in spelling, word order, and syntax offer: (1) we improve the word alignments for the resource-poor language, (2) we further augment it with additional translation options, and (3) we take care of potential spelling differences through appropriate transliteration. The evaluation for Indonesian\u2192English using Malay and for Spanish\u2192English using Portuguese and pretending Spanish is resource-poor shows an absolute gain of up to 1.35 and 3.37 BLEU points, respectively, which is an improvement over the best rivaling approaches, while using much less additional data. Overall, our method cuts the amount of necessary \u201creal\u201d training data by a factor of 2\u20135.", "creator": "TeX"}}}