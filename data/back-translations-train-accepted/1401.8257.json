{"id": "1401.8257", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jan-2014", "title": "Online Clustering of Bandits", "abstract": "We introduce a novel algorithmic approach to content recommendation based on adaptive clustering of exploration-exploitation (\"bandit\") strategies. We provide a sharp regret analysis of this algorithm in a standard stochastic noise setting, demonstrate its scalability properties, and prove its effectiveness on a number of synthetic and real-world datasets. Our experiments show a significant increase in prediction performance over state-of-the-art methods for bandit problems.", "histories": [["v1", "Fri, 31 Jan 2014 18:49:42 GMT  (7938kb,D)", "https://arxiv.org/abs/1401.8257v1", null], ["v2", "Tue, 13 May 2014 07:13:06 GMT  (4223kb,D)", "http://arxiv.org/abs/1401.8257v2", "20 pages, 7 figures, Cycle II Accepted Paper of ICML 2014, Beijing, China. Submitted by Shuai Li (this https URL)"], ["v3", "Fri, 6 Jun 2014 13:59:04 GMT  (8539kb,D)", "http://arxiv.org/abs/1401.8257v3", "In E. Xing and T. Jebara (Eds.), Proceedings of 31st International Conference on Machine Learning, Journal of Machine Learning Research Workshop and Conference Proceedings, Vol.32 (JMLR W&amp;CP-32), Beijing, China, Jun. 21-26, 2014 (ICML 2014), Submitted by Shuai Li (this https URL)"]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["claudio gentile", "shuai li", "giovanni zappella"], "accepted": true, "id": "1401.8257"}, "pdf": {"name": "1401.8257.pdf", "metadata": {"source": "META", "title": "Online Clustering of Bandits", "authors": ["Claudio Gentile", "Shuai Li", "Giovanni Zappella"], "emails": ["CLAUDIO.GENTILE@UNINSUBRIA.IT", "SHUAILI.SLI@GMAIL.COM", "ZAPPELLA@AMAZON.COM"], "sections": [{"heading": "1. Introduction", "text": "The presentation of personalized content to users is now a critical implication for many online recommendation services. Due to the ever-changing number of options available, these services must exhibit strong adaptability when trying to match users \"preferences. Broadly speaking, the underlying systems repeatedly learn to map available content to users, mapping based on context information (i.e. features that are typically extracted from both users and content); the need to focus on content that increases users\" interest, combined with the need to explore new content in order to improve users \"experience globally, generates a well-known exploration and exploitation dilemma that is commonly formalized as a multi-type bandit problem (e.g. Lai & Robbins, 1985; Audier et al., 2001; Audibert et al., 2009; Caron et al., 2012). Specifically, the contextual 2002 bandit methods (e.g. Zer, 2010)."}, {"heading": "2. Learning Model", "text": "We assume that the similarity of user behavior is recognized as an unknown cluster of users. Specifically, this means that V = {1,., n} represents the number of users (1). Then, due to spatial constraints, V \u2212 \u2212 \u2212 1 may be such that users who are in the same cluster have similar behavior and users who are in other clusters have different behavior. The actual partition of V (including the number of clusters m) and the usual user behavior within each cluster are unknown to the learner and must be put to the sword. Learning proceeds in a sequential manner: In each turn t = 1, 2.,., the learner receives a user index, which it together with a set of context vectors Cit = {xt, 2,.,.,."}, {"heading": "3. The Algorithm", "text": "In this year it is so far that it will be able to retaliate. \"(tmi) D\" ei \"n, eSi\" r \"i\" n, \"i\" i \"t,\" i \",\" i, \"\" i, \"\" i, \"\" i, \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\" \",\" \",\" \",\" \",\" \",\" \",\", \"\", \"\", \"\", \"\", \",\", \",\", \",\", \"\", \",\" \",\" \",\" \",\", \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \"\", \"\", \"\", \"\" \"\", \"\", \"\", \"\" \",\" \"\" \",\", \"\" \"\", \"\", \"\" \",\" \"\" \",\" \"\", \"\" \"\", \"\" \"\", \"\" \"\", \"\" \",\" \"\" \"\", \"\" \"\", \"\" \"\", \"\" \"\" \",\" \"\" \"\", \"\" \"\" \",\" \"\" \"\" \",\" \"\" \"\", \"\" \"\" \"\", \"\" \"\" \",\" \"\", \"\" \"\" \"\", \"\" \"\" \"\", \"\" \"\", \"\" \"\" \"\", \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\", \"\", \"\" \"\" \"\" \"\" \"\", \"\" \"\" \"\", \"\" \"\" \"\" \"\", \"\" \"\" \"\" \",\" \"\" \"\" \"\" \"\", \"\" \"\" \"\" \"\" \""}, {"heading": "3.1. Implementation", "text": "When implementing the algorithm in Figure 1, the reader should bear in mind that we expect n (the number of users) to be relatively large, d (the number of characteristics of each item) to be relatively small, and m (the number of true clusters) to be very small compared to n. In this sense, the algorithm can be implemented by storing at each node i-V an estimate for the smallest squares w-j-t, t-1 for each current cluster j-t-t-1, and an additional data structure capable of achieving decreasing dynamic connectivity. Fast implementations of such data structures are those examined by (Thorup, 1997; Kapron et al., 2013) (see also the research thread referenced therein). It can be shown (see the supplementary material) that we have a general (expected) running time in T rounds if EmeO (T (d2 + 2.5 + End Log | 1) + E2 (Ed1) is."}, {"heading": "3.2. Regret Analysis", "text": "Our analysis is based on the high probability analysis contained in (Abbasi-Yadkori et al., 2011) (theorems 1 and 2 therein).The analysis (theorem 1 below) is performed in the case where the original graph G1 is the complete graph. However, the analysis refers to a version of the algorithm in which the trust-bound functions CBj, t \u2212 1 () and C Bi, t \u2212 1 in Figure 1 are replaced by their \"theoretical\" counterparts TCBj, t \u2212 1 (\u00b7), and T \u2212 1 in the version in which the trust-bound functions CBj, t \u2212 1 (\u00b7) and C Bi, t \u2212 1 in Figure 1 are replaced."}, {"heading": "4. Experiments", "text": "We tested our algorithm on both artificial and freely available real data sets against standard bandit baselines."}, {"heading": "4.1. Datasets", "text": "In fact, it is in such a way that it is a way in which people are able to live in it, to live, to live, to live, to live, to live, to live, to live, to live, to work, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live,"}, {"heading": "4.2. Algorithms", "text": "We compared CLUB with two main competitors: LinUCBONE and LinUCB-IND. Both competitors are members of the LinUCB family of algorithms (Auer, 2002; Chu et al., 2011; Li et al., 2010; Abbasi-Yadkori et al., 2011; Cesa-Bianchi et al., 2013). LinUCB-ONE assigns each user a single instance of LinUCB to all users (making the same prediction for all users), while LinUCBIND (\"LinUCB INDependent\") assigns each user an independent instance of LinUCB, whereby each user makes their predictions in a fully personalized manner. In addition, on the UCB synthetic experiments, we added two idealized baselines: a GOBLIN-like algorithm (Cesa-Bianchi et al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al al., 2013), which is matrixed with a laplactic."}, {"heading": "4.3. Results", "text": "Our results are summarized in 13 Figures 3, 4, and 5. On the synthetic datasets (Figure 3) and the LastFM and Delicious datasets (Figure 4), we measure the ratio of the algorithm's cumulative regret to the random dictator's cumulative regret (so the lower the better). On the synthetic datasets, we did this using combinations of the number of clusters, the payout noise, and the cluster size balance. On the Yahoo datasets (Figure 5), since the only payouts available are those recommended in the protocols, we measure instead the clickthrough rate (CTR), i.e. the fraction of the times we get at = 1 from the number of data sets received so far (so the better)."}, {"heading": "Acknowledgments", "text": "We would like to thank the anonymous reviewers for their helpful and constructive comments. The first and second authors also acknowledge the support of the Amazon AWS Award in Education Machine Learning Research Grant."}, {"heading": "A. Appendix", "text": "This supplementary material contains all the evidence and technical details omitted in the main text, as well as supplementary comments, discussions of related work and additional experimental results."}, {"heading": "A.1. Proof of Theorem 1", "text": "The following sequence of lemmas is of preliminary importance: the first requires additional variance conditions on the process X that generates the context vector. We find it convenient to use the node counterpart to TCBj, t \u2212 1 (x), and the cluster counterpart to T-CBi, t \u2212 1 (max.), n \u2212 1 (max.), and cluster index j (max.), x \u2212 2 (x), we leave TCBi, t \u2212 1 (x) = x > M \u2212 1i, t \u2212 1i, t \u2212 1x (x), Mi, t \u2212 1 (max.), t \u2212 1 (max.), p \u2212 1 (max.), n \u2212 2 (x), x \u2212 2 (max.), x \u2212 2 (max.), n (max.), max. (n.), max. (n.), max. (n.)."}, {"heading": "Then:", "text": "Under the same premises as in Lemma 2, \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 k = \u2212 k = > k = = = 1, \u2212 k = = 1,. \u2212 k = 1, \u2212 k = 1,. \u2212 k, and rounds t = 1, 2,. \u2212 k, and rounds t = 1, 2,. \u2212 k, and rounds t = 1, 2,.. \u2212 t, whose columns are the dimensional vectors x, for all s < t: is Vj ', a', t \u2212 1 is the column vector in which we make all payments as, s < t: is the Vj ', and not the corresponding column vectors of the sound swords, for all s < t, a', t \u2212 1 we are the column vector in which we make all payments as, s < t: is the Vj ', and not the corresponding column vectors of the sound swords."}, {"heading": "A.3. Further Plots", "text": "This section provides a more thorough compilation of comparative diagrams of the synthetic datasets described in the main text. See Figure 6 and Figure 7."}, {"heading": "A.4. Derivation of the Reference Bounds", "text": "We now provide a proof sketch of the reference boundaries mentioned in section 2 of the main text. Let's start with the individual user bound by LINUCB (either ONE or IND) from which one can extract (Abbasi-Yadkori et al., 2011). Let's start with the profile vector of that user. Then, with probability, we have at least 1 \u2212 \u043c T = 1 rt = O (\u221a T (2 d log T + \u03c32 log 1 + | | ui | 2) d log T) = O (\u221a T (2 d + | uj | | 2) d) = O \u0432 (((\u03c3 d + \u221a d) \u221a T) \u221a T), the last line that follows the assumption | uj | | = 1.Then there is an easy way to turn this boundary into a boundary for the CLEARVOYANT algorithm that knows all clusters V1,.."}, {"heading": "A.5. Further Comments", "text": "As we said in note 3, a data-dependent variant of the CLUB algorithm can be designed and analyzed based on data-dependent clustering assumptions made by users with respect to a set of context vectors.These data-dependent assumptions allow us to work in a fixed design setting for the sequence of context vectors xt, k, and remove hypotheses relating to E [XX >].To be more precise, we consider an adversary who generates context vectors (units) in a (possibly adaptive) manner that is generated for all x x thus generated x | u > j x \u2212 u > j \u2032 x | qui, whenever j 6 = j \u2032.In other words, the power of the adversary is limited in that he cannot generate two distinct context vectors x and x \u2032, so that the | u > x \u2212 j \u2032 x | x \u00b2 x > j \u00b2 x \u2032 m \u00b2, a cumulative condition that can form both quantities (1) and two quantities (both of them) yields a quantity (both)."}, {"heading": "A.6. Related Work", "text": "The most closely related papers are (Djolonga et al., 2013; Azar et al., 2013; Brunskill & Li, 2013; Maillard & Mannor, 2014).In (Azar et al., 2013), the authors define a transfer learning problem within a stochastic multi-armed bandit scenario that defines a prior distribution across the set of possible models of tasks. In a spirit similar to our work, the most recent work (Brunskill & Li, 2013) directs our attention to clustering of Markov decision processes based on their model parameter similarity. In this paper, the authors analyze a non-contextual stochastic bandit problem where model parameters can indeed be clustered into some (unknown) types, forcing the algorithm to learn the clusters instead of learning the parameters in isolation."}, {"heading": "A.7. Ongoing Research", "text": "This work could be expanded in several directions. Firstly, we could rely on a softer idea of clusters than the one we have adopted here: a cluster consists of nodes where the \"distance\" between the associated profile vectors is smaller than their \"distance between distances.\" However, this probably requires prior knowledge of the distance threshold or number of underlying clusters, which this paper assumes to be unknown. Secondly, it may be possible to treat partially overlapping clusters. Thirdly, CLUB can clearly be modified so that nodes can be analyzed using cluster techniques outside the helper diagram (minut, spectral clustering, etc.) Clusters over interconnected components have the dual advantage of being faster and relatively easy to analyze computationally. In fact, we do not know how to analyze CLUB in combination with alternative cluster techniques, and we suspect that Theorem 1 already delivers the sharpest results when cluster building is based on coherent components."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "We introduce a novel algorithmic approach to content recommendation based on adaptive clustering of exploration-exploitation (\u201cbandit\u201d) strategies. We provide a sharp regret analysis of this algorithm in a standard stochastic noise setting, demonstrate its scalability properties, and prove its effectiveness on a number of artificial and real-world datasets. Our experiments show a significant increase in prediction performance over state-of-the-art methods for bandit problems.", "creator": "LaTeX with hyperref package"}}}