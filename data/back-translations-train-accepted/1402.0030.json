{"id": "1402.0030", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Jan-2014", "title": "Neural Variational Inference and Learning in Belief Networks", "abstract": "Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator the inference model gradient is too high-variance to be useful, we make it practical by applying several straightforward model-independent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset.", "histories": [["v1", "Fri, 31 Jan 2014 23:33:21 GMT  (130kb,D)", "http://arxiv.org/abs/1402.0030v1", null], ["v2", "Wed, 4 Jun 2014 17:12:03 GMT  (57kb)", "http://arxiv.org/abs/1402.0030v2", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["andriy mnih", "karol gregor"], "accepted": true, "id": "1402.0030"}, "pdf": {"name": "1402.0030.pdf", "metadata": {"source": "CRF", "title": "Neural Variational Inference and Learning in Belief Networks", "authors": ["Andriy Mnih", "Karol Gregor"], "emails": ["ANDRIY@DEEPMIND.COM", "KAROL@DEEPMIND.COM"], "sections": [{"heading": "1. Introduction", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "2. Neural variational inference and learning", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Variational objective", "text": "For the sake of simplicity, we also assume that all the latent variables in the model are discrete, although essentially the same approach is applied when some or all of the variables are continuous. We will train the model by maximizing a lower variable limit on the marginal log probability. Following the standard variable inference approach (Jordan et al., 1999), we will introduce a distribution model x by introducing a distribution model x that will serve as an approximation of its exact posterior distribution (h | x). Variational Q will have a simpler form than the exact posterior x and will therefore be easier to work with. The contribution of x to the log probability may then be limited."}, {"heading": "2.2. Parameter gradients", "text": "The gradient of the limit of variation for a single observation x w.r.t. of the model parameters is easy to derive (1) and has the following form to simplify the notation: The corresponding gradient w.r.t. of the inference network parameters is a little more complicated:........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "2.3. Variance reduction techniques", "text": "Although gradient estimates calculated with Eq.6 are usually too loud to be useful in practice, it is easy to reduce their variance to a manageable level using the following model-independent techniques."}, {"heading": "2.3.1. CENTERING THE LEARNING SIGNAL", "text": "So if we look at the results of inference network control Q\u03c6 (h | x) (h | x) (7) as a learning signal for the inference network parameters, and therefore effectively adapt logQ\u03c6 (h | x) to logPledge (x, h) control, then this may seem surprising, since we want the inference network Q\u03c6 (h | x) the inference control control control control control control control control control control control control control control control control control (x, h) control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control control"}, {"heading": "2.3.2. VARIANCE NORMALIZATION", "text": "Even after centering, the use of l\u03c6 (x, h) as a learning signal is not trivial, as the average size of the learning signal can change dramatically and not necessarily monotonously during training. This variability makes it difficult to train an inference network using a fixed learning rate. We address this problem by dividing the centered learning signal by an ongoing estimate of its standard deviation. This normalization ensures that the signal has approximately one variance per unit and can be considered a simple and efficient method of adjusting the learning rate. To ensure that we stop learning when the size of the signal approaches zero, we apply variance normalization only if the estimate of the standard deviation is greater than 1."}, {"heading": "2.3.3. LOCAL LEARNING SIGNALS", "text": "So far, we have made no assumptions about the structure of the model or the inference network, but by using its conditional independence properties, we can form the inference network with simpler and less loud local learning signals instead of the monolithic global learning signal l\u03c6 (x, h). However, our approach to deriving a local signal for a number of parameters involves removing all terms from the global signal that do not affect the value of the resulting gradient estimator. We will derive the layer-specific learning signals for the common case of both the model and the inference network with n layers of latent variables. Of course, the model and the varying posterior distribution signals will then asPTB (x, h) = PTB (x) = 1i = 1 PTB (hi | 1) PTB (hi + 1) PTB (hn), (10) QTB (h | x) QTB (h | x) = QIP distribution signals (x | hIP)."}, {"heading": "3. Related work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Feedforward approximations to inference", "text": "The idea of training an approximate inference network by optimizing a variable lower limit is not new; it goes back at least to Hinton & Zemel (1994), who derived the variable target from the perspective of the Minimum Description Length (MDL) and used it to train linear autoencoders, their probabilistic encoders and decoders corresponding to our inference network and model, but calculated the gradients analytically, which was possible due to the simplicity of their model, and rejected the sample-based approach as impracticable due to Noise.Recently a method for training nonlinear models with continuous latent latent variables, called Stochastic Gradient Variational Bayes (SGVB), proposed by Kingma & Welling (2013) and Rezende et al. (2014) Like NVIL, it involves using feedback forward models to perform approximate inference models, and training them by optimizing a sampling-based estimation."}, {"heading": "3.2. Sampling-based variational inference", "text": "Like NVIL, Black Box Variational Inference (BBVI, Ranganath et al., 2013) learns the variation parameters of the background by optimizing the variation boundary using sample-based gradient estimates, making it applicable to a wide range of models. However, unlike NVIL, BBVI follows the traditional approach of learning a separate set of variation parameters for each observation and does not use an inference network. Furthermore, BBVI uses a fully factored midfield approach to the hinterland, limiting its performance."}, {"heading": "3.3. The wake-sleep algorithm", "text": "NVIL shares many similarities with the Wake-Sleep algorithm (Hinton et al., 1995a), which has the same scalability and applicability to a wide range of models, which was introduced for the training of Helmholtz machines (Dayan et al., 1995), which are multi-layered faith networks extended by detection networks. These detection networks are used for approximate conclusions and are directly analogous to the NVIL inference networks (Eq. 5). Wake-Sleep alternates between updating the model parameters in the wake phase and the detection parameters in the sleep phase. The model parameter update is based on the samples generated from the detection network on the training data and is identical to the NVIL one (Eq. 5). Unlike NVIL, the detection parameters of the wake-phase detection parameters are well trained in the wake-phase detection pattern and the causes of the sleep pattern in the words."}, {"heading": "3.4. REINFORCE", "text": "The use of the gradient (4) to form the inference network can be seen as an example of the REINFORCE algorithm (Williams, 1992) from reinforcement learning (RL), which adjusts the parameters of a stochastic model to maximize the external reward signal depending on the performance of the model. In the face of a model P\u03b8 (x) and a reward signal r (x), REINFORCE updates the model parameters using the rule \u2206 \u2082 EP [(r (x) \u2212 b) and the learning signal logP\u03b8 (x)]. (14) We can consider NVIL as an application of REINFORCE on the basis of a single training, where the inference network corresponds to the stochastic model, the latent state h of the performance and the learning signal lending (x, h) of the reward."}, {"heading": "4. Experimental results", "text": "We conducted two sets of experiments, the first to evaluate the effectiveness of our variance reduction techniques and to compare the performance of NVIL with that of the wake-sleep algorithm. In the second set of experiments, we demonstrated NVIL's ability to process larger data sets from the real world by using them to train generative models of documents."}, {"heading": "4.1. Experimental protocol", "text": "We trained all models with stochastic gradient ascent using mini-batches of 20 observations randomly taken from the training data; the gradient estimates were calculated from a single sample from the inference network; for each data set, we created a validation set by removing a random subset of 100 observations from the training set; the only form of regulation we applied was an early stop based on the validation limit, which was implemented by tracking the parameter configuration with the best validation value ever seen; we implemented each input-dependent baseline with a neural network with a single hidden layer of 100 tanh units; we used fixed learning rates because we found that they provide better results than the annealing schedules we experimented with; the learning rates we reported were improved based on validation set performance in preliminary experiments with a single hidden layer of 100 tanh units; we used fixed learning rates because we found that they provide better results than the annealing schedules we experimented with; and the learning rates we reported were improved on the validation set performance in smaller experiments with smaller performance models we selected to make the model for the inferencing network (which is always smaller than the one for the inferencing model)."}, {"heading": "4.2. Modelling images of digits", "text": "In fact, it is the case that most of us are in a position to move into another world, in which they are able to live in, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "4.3. Document modelling", "text": "The goal is to build a generative model of documents that is represented as word count vectors, also known as Pockets of Words. We trained two simple models on the 20 newsgroups and Reuters Corpus Volume I (RCV1-v2) datasets that were used to evaluate similar models in (Salakhutdinov & Hinton, 2009b; Larochelle & Lauly, 2012). 20 newsgroups is a fairly small dataset of Usenet newsgroup posts, consisting of about 11K training and 7.5K test documents. RCV1 is a much larger dataset of Reuters newsgroup articles, with about 794.4K test documents."}, {"heading": "5. Discussion and future work", "text": "We developed, NVIL, a new training method for intractable directed latent variable models that is generally and easily applicable to new models. We demonstrated that NVIL consistently outperforms the wake-up sleep algorithm in training sigmoidfaith-network-like models. Finally, we demonstrated the potential of our approach by obtaining state-of-the-art results on a sizeable dataset of documents (Reuters RCV1). Since the focus of this work is on the training method, we applied it to some of the simplest possible model and inference network architectures that were sufficient to achieve promising results. We believe that significant performance gains can be achieved by using more expressive architectures, such as those with non-linear differences between layers of stochastic variables. Applying NVIL to models with continuous latent variables is another promising direction, as binary latables in Qs of the world are logically inadequate to QL modeling, we do not always expect NVIx to be appropriate."}, {"heading": "ACKNOWLEDGEMENTS", "text": "We thank Koray Kavukcuoglu, Volodymyr Mnih and Nicolas Heess for their helpful comments and Ruslan Salakhutdinov for providing the edited document records."}], "references": [{"title": "Differential sparse coding", "author": ["Bradley", "David M", "Bagnell", "J Andrew"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bradley et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bradley et al\\.", "year": 2008}, {"title": "Varieties of helmholtz machine", "author": ["Dayan", "Peter", "Hinton", "Geoffrey E"], "venue": "Neural Networks,", "citeRegEx": "Dayan et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Dayan et al\\.", "year": 1996}, {"title": "The helmholtz machine", "author": ["Dayan", "Peter", "Hinton", "Geoffrey E", "Neal", "Radford M", "Zemel", "Richard S"], "venue": "Neural computation,", "citeRegEx": "Dayan et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Dayan et al\\.", "year": 1995}, {"title": "Variance reduction techniques for gradient estimates in reinforcement learning", "author": ["Greensmith", "Evan", "Bartlett", "Peter L", "Baxter", "Jonathan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Greensmith et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Greensmith et al\\.", "year": 2004}, {"title": "Learning fast approximations of sparse coding", "author": ["Gregor", "Karol", "LeCun", "Yann"], "venue": "In Proc. International Conference on Machine learning (ICML\u201910),", "citeRegEx": "Gregor et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2010}, {"title": "Deep autoregressive networks", "author": ["Gregor", "Karol", "Mnih", "Andriy", "Wierstra", "Daan"], "venue": "arXiv preprint arXiv:1310.8499,", "citeRegEx": "Gregor et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2013}, {"title": "Autoencoders, minimum description length, and Helmholtz free energy", "author": ["Hinton", "Geoffrey E", "Zemel", "Richard S"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hinton et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 1994}, {"title": "The \"wake-sleep\" algorithm for unsupervised neural networks", "author": ["Hinton", "Geoffrey E", "Dayan", "Peter", "Frey", "Brendan J", "Neal", "Radford M"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 1995}, {"title": "The\" wake-sleep\" algorithm for unsupervised neural networks", "author": ["Hinton", "Geoffrey E", "Dayan", "Peter", "Frey", "Brendan J", "Neal", "Radford M"], "venue": "Science, pp. 1158\u20131158,", "citeRegEx": "Hinton et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 1995}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Hinton", "Geoffrey E", "Osindero", "Simon", "Teh", "Yee Whye"], "venue": "Neural Computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "An introduction to variational methods for graphical models", "author": ["Jordan", "Michael I", "Ghahramani", "Zoubin", "Jaakkola", "Tommi S", "Saul", "Lawrence K"], "venue": "Machine Learning,", "citeRegEx": "Jordan et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Jordan et al\\.", "year": 1999}, {"title": "Fast inference in sparse coding algorithms with applications to object recognition", "author": ["Kavukcuoglu", "Koray", "Ranzato", "Marc\u2019Aurelio", "LeCun", "Yann"], "venue": "Technical report, Courant Institute,", "citeRegEx": "Kavukcuoglu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kavukcuoglu et al\\.", "year": 2008}, {"title": "Auto-encoding variational bayes", "author": ["Kingma", "Diederik P", "Welling", "Max"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2013}, {"title": "A neural autoregressive topic model", "author": ["Larochelle", "Hugo", "Lauly", "Stanislas"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Larochelle et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Larochelle et al\\.", "year": 2012}, {"title": "The neural autoregressive distribution estimator", "author": ["Larochelle", "Hugo", "Murray", "Iain"], "venue": "JMLR: W&CP,", "citeRegEx": "Larochelle et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Larochelle et al\\.", "year": 2011}, {"title": "Connectionist learning of belief networks", "author": ["Neal", "Radford M"], "venue": "Artificial intelligence,", "citeRegEx": "Neal and M.,? \\Q1992\\E", "shortCiteRegEx": "Neal and M.", "year": 1992}, {"title": "Variational bayesian inference with stochastic search", "author": ["Paisley", "John William", "Blei", "David M", "Jordan", "Michael I"], "venue": "In ICML,", "citeRegEx": "Paisley et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Paisley et al\\.", "year": 2012}, {"title": "Stochastic back-propagation and variational inference in deep latent gaussian models", "author": ["Rezende", "Danilo Jimenez", "Mohamed", "Shakir", "Wierstra", "Daan"], "venue": "arXiv preprint arXiv:1401.4082,", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Deep boltzmann machines", "author": ["Salakhutdinov", "Ruslan", "Hinton", "Geoffrey E"], "venue": "In International Conference on Artificial Intelligence and Statistics, pp", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2009}, {"title": "Replicated softmax: an undirected topic model", "author": ["Salakhutdinov", "Ruslan", "Hinton", "Geoffrey E"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2009}, {"title": "On the quantitative analysis of Deep Belief Networks", "author": ["Salakhutdinov", "Ruslan", "Murray", "Iain"], "venue": "In Proceedings of the 25th Annual International Conference on Machine Learning", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2008}, {"title": "Mean field theory for sigmoid belief networks", "author": ["Saul", "Lawrence K", "Jaakkola", "Tommi", "Jordan", "Michael I"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Saul et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Saul et al\\.", "year": 1996}, {"title": "Learning stochastic feedforward neural networks", "author": ["Tang", "Yichuan", "Salakhutdinov", "Ruslan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Tang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2013}, {"title": "The optimal reward baseline for gradient-based reinforcement learning", "author": ["Weaver", "Lex", "Tao", "Nigel"], "venue": "Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Weaver et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Weaver et al\\.", "year": 2001}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["Williams", "Ronald J"], "venue": "Machine learning,", "citeRegEx": "Williams and J.,? \\Q1992\\E", "shortCiteRegEx": "Williams and J.", "year": 1992}], "referenceMentions": [{"referenceID": 9, "context": "Compared to powerful globally-normalized latent variable models, such as deep belief networks (Hinton et al., 2006) and deep Boltzmann machines (Salakhutdinov & Hinton, 2009a), which can now be trained on fairly large datasets, their purely directed counterparts have been left behind due to the lack of efficient learning algorithms.", "startOffset": 94, "endOffset": 115}, {"referenceID": 10, "context": "Variational methods (Jordan et al., 1999) provide an optimization-based alternative to the sampling-based Monte Carlo methods, and tend to be more efficient.", "startOffset": 20, "endOffset": 41}, {"referenceID": 10, "context": "Variational methods (Jordan et al., 1999) provide an optimization-based alternative to the sampling-based Monte Carlo methods, and tend to be more efficient. They involve approximating the exact posterior using a distribution from a more tractable family, often a fully factored one, by maximizing a variational lower bound on the loglikelihood w.r.t. the parameters of the distribution. For a small class of models, using such variational posteriors allows the expectations that specify the parameter updates to be computed analytically. However, for highly expressive models such as the ones we are interested in, these expectations are intractable even with the simplest variational posteriors. This difficulty is usually dealt with by lower bounding the intractable expectations with tractable one by introducing more variational parameters, as was done for sigmoid belief nets by Saul et al. (1996). However, this technique increases the gap between the bound being optimized and the log-likelihood, potentially resulting in a poorer fit to the data.", "startOffset": 21, "endOffset": 904}, {"referenceID": 17, "context": "In contrast to other work on scaling up variational inference (Kingma & Welling, 2013; Ranganath et al., 2013; Rezende et al., 2014), NVIL can handle both discrete and continuous latent variables, as well as variational posteriors with complex dependency structures.", "startOffset": 62, "endOffset": 132}, {"referenceID": 16, "context": "Moreover, the variance reduction methods we employ are simple and modelindependent, unlike the more sophisticated model-specific control variates of Paisley et al. (2012).", "startOffset": 149, "endOffset": 171}, {"referenceID": 10, "context": "Following the standard variational inference approach (Jordan et al., 1999), given an observation x, we introduce a distribution Q\u03c6(h|x) with parameters \u03c6, which will serve as an approximation to its exact posterior P\u03b8(h|x).", "startOffset": 54, "endOffset": 75}, {"referenceID": 10, "context": "The contribution of x to the log-likelihood can then be lower-bounded as follows (Jordan et al., 1999):", "startOffset": 81, "endOffset": 102}, {"referenceID": 16, "context": "of Paisley et al. (2012)), baselines do not depend on the form of the model or of the variational distribution and thus are easier to use.", "startOffset": 3, "endOffset": 25}, {"referenceID": 17, "context": "Recently a method for training nonlinear models with continuous latent variables, called Stochastic Gradient Variational Bayes (SGVB), has been proposed by Kingma & Welling (2013) and Rezende et al. (2014). Like NVIL, it involves using feedforward models to perform approximate inference and trains them by optimizing a sampling-based estimate of the variational bound on the log-likelihood.", "startOffset": 184, "endOffset": 206}, {"referenceID": 11, "context": "An inference network for efficient generation of samples from the approximate posterior can also be seen as a probabilistic generalization of the approximate feedforward inference methods developed for sparse coding models in the last few years (Kavukcuoglu et al., 2008; Bradley & Bagnell, 2008; Gregor & LeCun, 2010).", "startOffset": 245, "endOffset": 318}, {"referenceID": 2, "context": "This algorithm was introduced for training Helmholtz machines (Dayan et al., 1995), which are multi-layer belief networks augmented with recognition networks.", "startOffset": 62, "endOffset": 82}, {"referenceID": 5, "context": "Interestingly, single-layer fDARN (Gregor et al., 2013) models, which have autoregressive connections between the latent variables, perform better than any of the SBN models trained using the same algorithm.", "startOffset": 34, "endOffset": 55}, {"referenceID": 5, "context": "The NVIL-trained fDARN models with 200 and 500 latent variables also outperform the fDARN (as well as the more expressive DARN) model with 400 latent variables from (Gregor et al., 2013), which were trained using an MDLbased algorithm.", "startOffset": 165, "endOffset": 186}], "year": 2017, "abstractText": "Highly expressive directed latent variable models, such as sigmoid belief networks, are difficult to train on large datasets because exact inference in them is intractable and none of the approximate inference methods that have been applied to them scale well. We propose a fast non-iterative approximate inference method that uses a feedforward network to implement efficient exact sampling from the variational posterior. The model and this inference network are trained jointly by maximizing a variational lower bound on the log-likelihood. Although the naive estimator the inference model gradient is too high-variance to be useful, we make it practical by applying several straightforward modelindependent variance reduction techniques. Applying our approach to training sigmoid belief networks and deep autoregressive networks, we show that it outperforms the wake-sleep algorithm on MNIST and achieves state-of-the-art results on the Reuters RCV1 document dataset.", "creator": "LaTeX with hyperref package"}}}