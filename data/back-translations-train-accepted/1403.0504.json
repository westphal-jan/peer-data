{"id": "1403.0504", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2014", "title": "A Compilation Target for Probabilistic Programming Languages", "abstract": "Forward inference techniques such as sequential Monte Carlo and particle Markov chain Monte Carlo for probabilistic programming can be implemented in any programming language by creative use of standardized operating system functionality including processes, forking, mutexes, and shared memory. Exploiting this we have defined, developed, and tested a probabilistic programming language intermediate representation language we call probabilistic C, which itself can be compiled to machine code by standard compilers and linked to operating system libraries yielding an efficient, scalable, portable probabilistic programming compilation target. This opens up a new hardware and systems research path for optimizing probabilistic programming systems.", "histories": [["v1", "Mon, 3 Mar 2014 18:08:57 GMT  (1038kb,D)", "http://arxiv.org/abs/1403.0504v1", null], ["v2", "Thu, 10 Jul 2014 17:41:10 GMT  (908kb,D)", "http://arxiv.org/abs/1403.0504v2", "In Proceedings of the 31st International Conference on Machine Learning (ICML), 2014"]], "reviews": [], "SUBJECTS": "cs.AI cs.PL stat.ML", "authors": ["brooks paige", "frank wood"], "accepted": true, "id": "1403.0504"}, "pdf": {"name": "1403.0504.pdf", "metadata": {"source": "META", "title": "A Compilation Target for Probabilistic Programming Languages", "authors": ["Brooks Paige", "Frank Wood"], "emails": ["BROOKS@ROBOTS.OX.AC.UK", "FWOOD@ROBOTS.OX.AC.UK"], "sections": [{"heading": "1. Introduction", "text": "This paper introduces a C language library that enables C language interrepresentation for probabilistic programming languages that can be compiled into executable machine code themselves. We call this intermediate language probabilistic C. Probabilistic C can be compiled normally and uses only macros and positive operating system libraries (Open Group, 2004a) to implement universal, scalable, parallel probabilistic programming successes. Note that in this paper we do not show how to compile existing probabilistic programming languages (i.e. IBAL (Pfeffer, 2001), BLOG (Milch et al., 2007), Church (Goodman et al., 2008), Figaro (Pfeffer, 2009), Venture (Mansinghka et al., 2013) or Anglican (Wood et al., 2014) to illustrate this intermediability."}, {"heading": "1.1. Related work", "text": "The characterization of probabilistic programming success that we are looking at here is the process of sampling from the a posteriori distribution of execution tracks resulting from stochastic programs that are forced to reflect observed data, a view that is espoused by, among others, the Church (Goodman et al., 2008), Venture (Mansinghka et al., 2013) and Anglican (Wood et al., 2014) programming languages in which models of observed data can be described purely in the sense of a forward-looking generative process. The Markov chain Monte Carlo (MCMC) is used by these systems to prick from the rear distribution of program execution tracks. Metropolis Hastings (MH) (Goodman et al., 2008) and the particle MCMC (PMCMC) (Wood et al., 2014) are two such approaches. In the latter, it has been determined that a fork-like operation is a fundamental requirement for forward-based testing methodology that could also be applied to the Wood 4v programming, whereby the 2014 is the forensic system)."}, {"heading": "2. Probabilistic Programming", "text": "Any program that makes a random selection over the course of its execution implicitly defines a prior distribution over its random variables; the execution of the program can be interpreted as pulling a sample from the previous one. Conclusion inar Xiv: 140 3.05 04v1 [cs.AI] 3M ar2 014 # closes \"probabilistic.h\" int main (int argc, char * argv) {double var = 2; double mu = normal _ rng (1, 5); observation (normal _ lnp (9, var)); observation (normal _ lnp (8, var)); p r e d i c t f, \"% f\\ n,\" mu. \"Figure 1: Two data points distributed after a Gaussian with unknown means \u00b5. We place one N (1, 5) on \u00b5 before execution, and observe two data points from N."}, {"heading": "2.1. Operating system primitives", "text": "We define an execution trace as the sequence of memory states (stack frames and allocated memory contents) that occur during the sequential execution of machine instructions. The algorithms we propose for conclusions in probabilistic programs directly form a sequence of memory states (stack frames and allocated memory contents) that occur in POSIX-compliant operating systems such as Linux, BSD, and Mac OS X. The cornerstone of our approach is the POSIX fork (Open Group, 2004b). If a process splits, it clones itself by creating a new process with an identical copy of the execution state of the original process and identical source code; both processes then continue normal program execution regardless of the point at which the fork was invoked. While copying the program execution state sounds like a costly process, this can actually be very efficient: the fork is invoked when a copy is rotten."}, {"heading": "3. Inference", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Probability of a program execution trace", "text": "To record the probability of executing a program, we list all N selections, and the associated observed data points y1,.., yN. During a single program run, a total number of N selections x-1,.., x-N selections is made. While N selections may vary between individual program runs, we need N selections to be constant. That is, valid probability models correspond to probabilistic C programs with the same number of observation directives for each program run. As this is left to the programmer (or potentially the compiler; see Section 5 for a brief discussion of this point), it is quite easy to write models in probabilistic C, which are statistically difficult to substantiate. This is the main reason for proposing probabilistic C as the compilation target."}, {"heading": "3.2. Sequential Monte Carlo", "text": "\"We know that most probable programs of interest are intractable samples (x1: N: N).\" Instead, we point out that we (for n: n) have the recursive identification (x1: n), that we (for n: n) have the recursive identification (x1: n), (x1: n). (2) Most probable programs of interest will be intractable to be directly perceived by p (x1: N: N). (1: 1) We point out that we (for n: 1) have the recursive identification (x1: n). (1: n) We have the recursive identification (x1: n). (1: n) We have the recursive identification (x1: n)."}, {"heading": "3.3. Particle Metropolis-Hastings", "text": "The simplest formulation is the particle-independent MetropolisHastings algorithm. After performing a single particle filter sweep, we calculate an estimate of the limit probability, Z-N (y1: N) \u2248 N-N = 1 [1L L L-N = 1 w'n]. (17) Then we perform another iteration of sequential Monte Carlo samples, which we use as the MH proposal; we estimate the limit probability Z-N of the new proposed particle set and then accept the new particle set with the probability min (1, Z-Z / Z-N) and output a new set of prediction collections that otherwise show the same prediction collections as in the previous iteration. Otherwise, the inner loop of algorithm 2 is essentially similar to SMC."}, {"heading": "3.4. Particle Gibbs", "text": "It's not just the way in which it comes to a new process, but also the way in which it comes to a new process, in which it comes to a new process, which stimulates a new way of exploitation and exploitation. (It's not the way in which it comes to a new process.) (It's the way in which it comes to a new process, in which it comes to a new process. (It's the way in which it comes to a new process.) (It's not the way in which it comes to a new process.) (It's the way in which it comes to a new process.) (It's the way in which it comes to a new process, in which it comes to a new way.)"}, {"heading": "4. Experiments", "text": "We now turn to benchmarking probabilistic C against existing probabilistic programming engines and evaluate the 4 Retain and branch inner loop algorithm Assuming: Input of initial C > 0 children to spawn will be maintained \u2190 true doif C = 0 and not maintained, then this execution track will be discarded, exit else {C \u2265 0} lawn C new children will end if waiting for a signal to be reset is maintained when waiting for a signal to reset C, otherwise this execution track will be discarded, exit ending without the accelerative strengths of the three inference algorithms in Section 3. We find that the compilation improves performance 100 times or more over interpreted versions of the same inference algorithm. We also find evidence that optimizing operating systems to support probable program usage could yield significant performance improvements."}, {"heading": "4.1. Comparative performance of inference engines", "text": "We start with benchmarking against two existing probabilistic programming motors: Anglican, as described in (Wood et al., 2014), which also implements Particle Gibbs but is a Scheme-based interpreted language implemented in Clojure and running on the JVM; and probabilistic-js1, a compiled system that implements the Inference approach in (Wingate et al., 2011) that tracks Metropolis-Hastings over every single random selection in the program execution; the interpreted Particle Filter Gibbs motor is mul-1https: / / github.com / dritchie / probabilistic-jstithreaded, and we run it with 100 particles and 8 simultaneous threads; the Metropolis Hastings motor runs on a single core only. In Figure 4, we compare the inference performance in both existing motors with our Particles Gibbs-end, which run 100 and Parts 1000."}, {"heading": "4.2. Performance characteristics across multiple cores", "text": "Since the probabilistic C inference engine shifts much of the calculation to underlying operating system calls, we characterize the limitations of OS implementation by comparing the time to completion as we vary the number of cores. Tests for the hidden Markov model across the core count (all on EC2, all with identical Intel Xeon E5-2680 v2 processors) are shown in Figure 6."}, {"heading": "5. Discussion", "text": "It is as it is that most people are able to move, to move and to move."}], "references": [{"title": "Particle Markov chain Monte Carlo methods", "author": ["Andrieu", "Christophe", "Doucet", "Arnaud", "Holenstein", "Roman"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Andrieu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2010}, {"title": "SSA is functional programming", "author": ["Appel", "Andrew W"], "venue": "SIGPLAN notices,", "citeRegEx": "Appel and W.,? \\Q1998\\E", "shortCiteRegEx": "Appel and W.", "year": 1998}, {"title": "Sequential Monte Carlo methods in practice", "author": ["Doucet", "Arnaud", "De Freitas", "Nando", "Gordon", "Neil"], "venue": null, "citeRegEx": "Doucet et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Doucet et al\\.", "year": 2001}, {"title": "The theory and practice of first-class prompts", "author": ["Felleisen", "Mattias"], "venue": "In Proceedings of the 15th ACM SIGPLANSIGACT symposium on Principles of programming languages,", "citeRegEx": "Felleisen and Mattias.,? \\Q1988\\E", "shortCiteRegEx": "Felleisen and Mattias.", "year": 1988}, {"title": "A language for generative models", "author": ["Goodman", "Noah D", "Mansinghka", "Vikash K", "Roy", "Daniel M", "Bonawitz", "Keith", "Tenenbaum", "Joshua B. Church"], "venue": "In In UAI, pp", "citeRegEx": "Goodman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Goodman et al\\.", "year": 2008}, {"title": "Monolingual probabilistic programming using generalized coroutines", "author": ["Kiselyov", "Oleg", "Shan", "Chung-chien"], "venue": "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009),", "citeRegEx": "Kiselyov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kiselyov et al\\.", "year": 2009}, {"title": "Venture: an interactive, Turing-complete probabilistic programming", "author": ["Mansinghka", "Vikash", "Selsam", "Daniel", "Perov", "Yura"], "venue": "URL http:// probcomp.csail.mit.edu/venture/", "citeRegEx": "Mansinghka et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mansinghka et al\\.", "year": 2013}, {"title": "BLOG: Probabilistic models with unknown objects", "author": ["Milch", "Brian", "Marthi", "Bhaskara", "Russell", "Stuart", "Sontag", "David", "Ong", "Daniel L", "Kolobov", "Andrey"], "venue": "Statistical relational learning,", "citeRegEx": "Milch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Milch et al\\.", "year": 2007}, {"title": "IBAL: A probabilistic rational programming language", "author": ["Pfeffer", "Avi"], "venue": "In IJCAI, pp", "citeRegEx": "Pfeffer and Avi.,? \\Q2001\\E", "shortCiteRegEx": "Pfeffer and Avi.", "year": 2001}, {"title": "Figaro: An object-oriented probabilistic programming language. Charles River Analytics", "author": ["Pfeffer", "Avi"], "venue": "Technical Report,", "citeRegEx": "Pfeffer and Avi.,? \\Q2009\\E", "shortCiteRegEx": "Pfeffer and Avi.", "year": 2009}, {"title": "Effects of copy-on-write memory management on the response time of UNIX fork operations", "author": ["Smith", "Jonathan M", "Maguire", "Jr.", "Gerald Q"], "venue": "COMPUTING SYSTEMS,", "citeRegEx": "Smith et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Smith et al\\.", "year": 1988}, {"title": "Lightweight implementations of probabilistic programming languages via transformational compilation", "author": ["Wingate", "David", "Stuhlmueller", "Andreas", "Goodman", "Noah D"], "venue": "In Proceedings of the 14th international conference on Artificial Intelligence and Statistics,", "citeRegEx": "Wingate et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wingate et al\\.", "year": 2011}, {"title": "A new approach to probabilistic programming inference", "author": ["Wood", "Frank", "van de Meent", "Jan Willem", "Mansinghka", "Vikash"], "venue": "In Proceedings of the 17th International conference on Artificial Intelligence and Statistics,", "citeRegEx": "Wood et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wood et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 7, "context": "IBAL (Pfeffer, 2001), BLOG (Milch et al., 2007), Church (Goodman et al.", "startOffset": 27, "endOffset": 47}, {"referenceID": 4, "context": ", 2007), Church (Goodman et al., 2008), Figaro (Pfeffer, 2009), Venture (Mansinghka et al.", "startOffset": 16, "endOffset": 38}, {"referenceID": 6, "context": ", 2008), Figaro (Pfeffer, 2009), Venture (Mansinghka et al., 2013), or Anglican (Wood et al.", "startOffset": 41, "endOffset": 66}, {"referenceID": 12, "context": ", 2013), or Anglican (Wood et al., 2014)) to this intermediate representation; instead we leave this to future work noting that there is a wealth of readily available resources on language to language compilation that could be leveraged to do this.", "startOffset": 21, "endOffset": 40}, {"referenceID": 2, "context": "Probabilistic C programs compile to machine executable meta-programs that perform inference over the original program via forward methods such as sequential Monte Carlo (Doucet et al., 2001) and particle MCMC variants (Andrieu et al.", "startOffset": 169, "endOffset": 190}, {"referenceID": 0, "context": ", 2001) and particle MCMC variants (Andrieu et al., 2010).", "startOffset": 35, "endOffset": 57}, {"referenceID": 4, "context": "This is the view taken by the Church (Goodman et al., 2008), Venture (Mansinghka et al.", "startOffset": 37, "endOffset": 59}, {"referenceID": 6, "context": ", 2008), Venture (Mansinghka et al., 2013), and Anglican (Wood et al.", "startOffset": 17, "endOffset": 42}, {"referenceID": 12, "context": ", 2013), and Anglican (Wood et al., 2014) programming languages among others.", "startOffset": 22, "endOffset": 41}, {"referenceID": 4, "context": "Single-site Metropolis Hastings (MH) (Goodman et al., 2008) and particle MCMC (PMCMC) (Wood et al.", "startOffset": 37, "endOffset": 59}, {"referenceID": 12, "context": ", 2008) and particle MCMC (PMCMC) (Wood et al., 2014) are two such approaches.", "startOffset": 34, "endOffset": 53}, {"referenceID": 4, "context": "Single-site Metropolis Hastings (MH) (Goodman et al., 2008) and particle MCMC (PMCMC) (Wood et al., 2014) are two such approaches. In the latter it was noted that a fork-like operation is a fundamental requirement of forward inference methods for probabilistic programming, where fork is the standard posix operating system primitive (Open Group, 2004b). Kiselyov & Shan (2009) also noted that delimited continuations, a user-level generalization of fork could be used for inference, albeit in a restricted family of models.", "startOffset": 38, "endOffset": 378}, {"referenceID": 12, "context": "In many probabilistic programming languages, for instance Anglican (Wood et al., 2014) and Venture (Mansinghka et al.", "startOffset": 67, "endOffset": 86}, {"referenceID": 6, "context": ", 2014) and Venture (Mansinghka et al., 2013), such constraints are explicitly imposed by the language itself.", "startOffset": 20, "endOffset": 45}, {"referenceID": 0, "context": "Particle Markov chain Monte Carlo, introduced in Andrieu et al. (2010), uses sequential Monte Carlo to generate highdimensional proposal distributions for MCMC.", "startOffset": 49, "endOffset": 71}, {"referenceID": 12, "context": "We begin by benchmarking against two existing probabilistic programming engines: Anglican, as described in (Wood et al., 2014), which also implements particle Gibbs, but is an interpreted language based on Scheme, implemented in Clojure, and running on the JVM; and probabilistic-js1, a compiled system implementing the inference approach in (Wingate et al.", "startOffset": 107, "endOffset": 126}, {"referenceID": 11, "context": ", 2014), which also implements particle Gibbs, but is an interpreted language based on Scheme, implemented in Clojure, and running on the JVM; and probabilistic-js1, a compiled system implementing the inference approach in (Wingate et al., 2011), which runs Metropolis-Hastings over each individual random choice in the program execution trace.", "startOffset": 223, "endOffset": 245}], "year": 2017, "abstractText": "Forward inference techniques such as sequential Monte Carlo and particle Markov chain Monte Carlo for probabilistic programming can be implemented in any programming language by creative use of standardized operating system functionality including processes, forking, mutexes, and shared memory. Exploiting this we have defined, developed, and tested a probabilistic programming language intermediate representation language we call probabilistic C, which itself can be compiled to machine code by standard compilers and linked to operating system libraries yielding an efficient, scalable, portable probabilistic programming compilation target. This opens up a new hardware and systems research path for optimizing probabilistic programming systems.", "creator": "LaTeX with hyperref package"}}}