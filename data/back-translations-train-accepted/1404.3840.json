{"id": "1404.3840", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Apr-2014", "title": "Surpassing Human-Level Face Verification Performance on LFW with GaussianFace", "abstract": "Face verification remains a challenging problem in very complex conditions with large variations such as pose, illumination, expression, and occlusions. This problem is exacerbated when we rely unrealistically on a single training data source, which is often insufficient to cover the intrinsically complex face variations. This paper proposes a principled multi-task learning approach based on Discriminative Gaussian Process Latent Variable Model, named GaussianFace, to enrich the diversity of training data. In comparison to existing methods, our model exploits additional data from multiple source-domains to improve the generalization performance of face verification in an unknown target-domain. Importantly, our model can adapt automatically to complex data distributions, and therefore can well capture complex face variations inherent in multiple sources. Extensive experiments demonstrate the effectiveness of the proposed model in learning from diverse data sources and generalize to unseen domain. Specifically, the accuracy of our algorithm achieves an impressive accuracy rate of 98.52% on the well-known and challenging Labeled Faces in the Wild (LFW) benchmark. For the first time, the human-level performance in face verification (97.53%) on LFW is surpassed.", "histories": [["v1", "Tue, 15 Apr 2014 07:51:23 GMT  (3154kb)", "http://arxiv.org/abs/1404.3840v1", null], ["v2", "Mon, 16 Jun 2014 14:37:38 GMT  (630kb,D)", "http://arxiv.org/abs/1404.3840v2", null], ["v3", "Sat, 20 Dec 2014 03:37:36 GMT  (630kb,D)", "http://arxiv.org/abs/1404.3840v3", "Appearing in Proceedings of the 29th AAAI Conference on Artificial Intelligence (AAAI-15), Oral Presentation"]], "reviews": [], "SUBJECTS": "cs.CV cs.LG stat.ML", "authors": ["chaochao lu", "xiaoou tang"], "accepted": true, "id": "1404.3840"}, "pdf": {"name": "1404.3840.pdf", "metadata": {"source": "CRF", "title": "Surpassing Human-Level Face Verification Performance on LFW with GaussianFace", "authors": ["Chaochao Lu", "Xiaoou Tang"], "emails": ["xtang}@ie.cuhk.edu.hk"], "sections": [{"heading": null, "text": "ar Xiv: 140 4.38 40v1 [cs.CV] 1 5A pr2 01Face verification remains a difficult problem under very complex conditions with large variations such as pose, illumination, expression and occlusions. This problem is exacerbated when we unrealistically rely on a single training data source, often insufficient to cover the inherently complex variations of the face. This paper proposes a principled multi-task learning approach based on the discriminatory Gaussian process called Latent Variable Model, to enrich the diversity of training data. Compared to existing methods, our model uses additional data from multiple source ranges to improve the generating performance of facial verification within an unknown target range. Importantly, our model can automatically adapt to complex data distributions and can therefore well capture complex surface variations inherent in multiple sources. Extensive experiments show the effectiveness of the proposed model in learning from the 952% of common areas of data and the 928% of unfamiliar surface variations."}, {"heading": "1. Introduction", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "2. Related Work", "text": "In fact, most of them will be able to feel as if they are able to save themselves, and that they will be able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are not able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are able to save themselves. (...) Most of them are not able to save themselves. (...)"}, {"heading": "3. Preliminary", "text": "In this section, we briefly look at Gaussian processes (GPs) for classification and clustering [26] and the Gaussian process latent variable model (GPLVM) [29]. We use the GPs method mainly for the following three notable advantages: First, as already mentioned, it is a non-parametric method, which means that it flexibly adapts its complexity to the complex data distributions in the real world, without heuristics or manual tuning of parameters. Second, the GPs method can be calculated effectively because of its closed limit probability calculation. Furthermore, its hyperparameters can be learned automatically from data without using methods of model selection such as cross-validation, thereby avoiding high computing costs. Third, the GPs \"conclusion is based on Bayean rules, leading to robustness to overfitting. We recommend Rasmussen and Williams\" excellent monograph for further reading [42]."}, {"heading": "3.1. Gaussian Processes for Binary Classification", "text": "Formally, for classification into two classes, it is assumed that we have a training set of D = N observations, D = (xi, yi) Ni = 1, where the i-th input point xi \u2212 RD and its corresponding output yi is binary, where y = 1i is for one class and yi = \u2212 1 is for the other. Suppose X is the N \u00b7 D matrix, where the row vectors represent all n input points and y is the column vector for all n outputs. We define a latent variable fi for each input point xi and let f = [f1,.., fN]. A sigmoid function p is imposed to determine the performance of the latent function in [0, 1], p (fi) = p (yi = 1 | fi). If we assume the dataset f f = f value, then f-f-f value f-x-x-x is generated, then f-probability-f-x-x-erized."}, {"heading": "3.2. Gaussian Processes for Clustering", "text": "The principle of GP clustering is based on the key observation that the variances of the forecast values are smaller in dense areas and greater in sparse areas. (7) This observation can be explained by the variance function of any prediction data point x-3 (x-3) = K-3-4 (x-4). (7) If x-4 (x-4) is located in a sparse region, K-3 (x-4) becomes small, resulting in a large variance \u03c32 (x-4), and vice versa. Another good property of the equation (7) is that it does not depend on the labels, meaning that it can be applied to the unlabeled data. To perform clustering, the following dynamic system, which can be described with Equation (7) asF (x) = \u2212 4-4 (x) can be used."}, {"heading": "3.3. Gaussian Process Latent Variable Model", "text": "Let Z = [z1,.., zN] denote the matrix whose rows represent corresponding positions of X in latent space, where zi-Rd (d-D). The Gaussian latent variable model (GPLVM) can be interpreted as a Gaussian process mapping from a low-dimensional latent space to a high-dimensional dataset in which the position of the points in latent space is determined by maximizing the Gaussian process probability with respect to Z. Given a covariance function for the Gaussian process denoted by k (\u00b7, \u00b7), the probability of the data specifying latent positions results as follows: p (X | Z, \u03b8) = 1 \u221a (2\u03c0) ND | K | D exp (\u2212 1 2 tr (K \u2212 1XX)), (9), where Ki, j = k (zi, zj). Therefore, the posterior margin can be introduced as a primus (Z | 2001-2001 D extr (X), \u2212 2 K (Xtr) and (Xp) as the constant (Xp)."}, {"heading": "4. GaussianFace", "text": "In order to automatically learn discriminatory features or covariance functions and to use the source data to improve facial verification performance, we develop a basic Gaussian Face model by including the multitask learning constraint in the discriminatory Gaussian process latent variable model (DGPLVM) [57]."}, {"heading": "4.1. DGPLVM Reformulation", "text": "The DGPLVM is an extension of the GPLVM, where the discriminatives precede the latent positions = J = N = 11 and not a simple spherical Gaussian. The DGPLVM uses the discriminatives before the discrimination \u2212 \u2212 \u2212 \u2212 N to promote latent positions of the same class that are close to and far removed from other classes. Since facial verification is a binary classification problem and GPs depend mainly on the kernel function, it is natural to use the Kernel Fisher Discriminant Analysis (KFDA) [27] to model class structures in core spaces. To simplify the following, we introduce another equivalent formula of the KFDA to replace the one in [57]. KFDA is a nucleated version of the linear discrimination method. It finds the direction defined by a feature space on which the projections of positive and negative classes are well distinguished by maximizing the ratio of class variance to class."}, {"heading": "4.2. Multi-task Learning Constraint", "text": "From an asymmetric multi-task learning perspective, the tasks should have common hyperparameters of the covariance function. Furthermore, from the perspective of information theory, the information costs between the target task and multiple source tasks should be minimized. A natural method of quantifying information costs is to use mutual entropy, as it is the measure of the interdependence of two distributions. In multi-task learning, we extend mutual entropy to multiple distributions as follows: M = H (pt) \u2212 1SS: i = 1H (pt | pi), (14) where H (\u00b7) is marginal entropy, H (\u00b7 | \u00b7) is conditional entropy, S is the number of source tasks, {pi} Si = 1, and pt is the probability distribution of source tasks or targets."}, {"heading": "4.3. GaussianFace Model", "text": "In this section we describe our GaussianFace model in detail. Suppose we have S source domain data (X1,.., XS) and target domain data (XT). For each source domain data or target domain data Xi, we write their marginal latent space according to Equation (9). (15) where Zi represents the domain-relevant latent space. For each source domain data and target domain data, their covariance functions K | K | D exp (\u2212 1 2 tr (K \u2212 1XiX i))). (15), where Zi represents the domain-relevant latent space. For each source domain data and target domain data, their covariance functions have the same form because they have the same hyperparameters. In this essay, we use a widely used KernelKi, j = kernel Ki = equation (xi, xj = Exj) (Xj = (Xp = 1 \u2212 p)."}, {"heading": "4.4. Optimization", "text": "For model optimization, we first extend the equation (19) to obtain the following equation (ignoring the constant items): LModel = \u2212 logPT + \u03b2PT logPT logPT \u2212 changi = 1 (PT, i logPT, i), (20) where Pi = p (Zi, \u03b8 | Xi) and Pi, j means that the corresponding covariance function is calculated on both Xi and Xj. We can now optimize the equation (20) with respect to the hyperparameters and the latent positions: Zi according to the scaled conjugate gradient (SCG). As we focus in this work on the covariance matrix, we can only present the derivatives of the hyperparameters. It is easy to obtain the LModel items and the latent positions Zi according to the technique Zi (\u03b2 (logPT + 1) + \u03b2 SPT spective S = 1T, Pi \u2212 qi."}, {"heading": "4.5. Speedup", "text": "In the GaussianFace model Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q2-Q2-Q2-Q2-Q2-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-3-Q3-Q3-Q3-3-Q3-Q3-3-Q3-Q3-Q3-3-Q3-Q3-Q3-Q3-3-Q3-Q3-Q3-Q3-Q3-3-Q3-Q3-3-Q3-Q3-Q3-Q3-Q3-Q3-3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-"}, {"heading": "5. GaussianFace Model for Face Verification", "text": "In this section, we describe two applications of the Gaussian Face Model for facial verification: as a binary classifier and as a feature extractor. First, each facial image is normalized to the size of 150 x 120 by an affine transformation based on five landmarks (two eyes, nose, and two corners of the mouth), and the image is then divided into overlapping spots of 25 x 25 pixels with an increment of 2 pixels. Each spot within the image is mapped by a specific descriptor to a vector, and the vector is considered a feature of the spot, where P = 1 is the number of spots within the face image A. In this essay, the multi-scale LBP feature of each spot is extracted [14]. The difference is that the multi-scale LBP descriptors in the center of each spot are extracted, rather than exact landmarks."}, {"heading": "5.1. GaussianFace Model as a Binary Classifier", "text": "For classification, our model can be considered as an approach to learning a covariance function for GPC, as shown in Figure 1 (a), where for a pair of facial images A and B of the same (or different) person, the similarity vector xi = [s1,..., sp,.., sP] should be the data entry point of the Gaussian Face model, where sp is the similarity of xAp and xBp and its corresponding output yi = 1 (or \u2212 1). Using the learned hyperparameters of the covariance function from the training data, we first calculate the similarity vector x using the above method, and then predict whether the pair is of the same person by equation (6). In this essay, we prescribe the sigmoid function \u03c0 (\u00b7) as a cumulative Gaussian distribution (\u00b7) that can be solved analytically by equation."}, {"heading": "5.2. GaussianFace Model as a Feature Extractor", "text": "As a feature extractor, we can consider our model as an approach to automatically extract facial features represented in Figure 1 (b). Here, for a pair of facial images A and B of the same (or other) person, we consider the common feature vector xi = [(xAi), (xBi) as the input data point of the Gaussian Face model, and its corresponding output is yi = 1 (or \u2212 1). To improve the robustness of our approach, the inverted form of xi is also included; for example xi = [x B i), (xAi), the hyperparameters of the covariance function are learned from the training data, we can use the method in Section 3.2 to group the input data into different face shapes."}, {"heading": "6. Experimental Settings", "text": "In this section, we conduct Face Verification Experiments. We start by comparing the source domain data sets and target domain data sets in all of our experiments (see Figure 2 for examples).Source domain data sets therefore include four different types of data sets as follows: Multi-PIE [19]. This data set contains facial images of 337 subjects under 15 viewpoints and 19 lighting conditions in four recording sessions. These images are collected under controlled conditions.The MORPH database contains 55,000 images of more than 13,000 people over the age range of 16 to 77. There is an average of 4 images per individual.Web Images2 These data sets contain approximately 40,000 facial images of 3,261 subjects; that is, approximately 10 images for each person. The images were collected from the web with significant variations in pose, expression and imaging. Life Photos2 contains approximately 5,000 images from 400 subjects collected online."}, {"heading": "7. Experimental Results", "text": "In this section, we will conduct five experiments to demonstrate the validity of the Gaussian Face model."}, {"heading": "7.1. Comparisons with Other MTGP/GP Methods", "text": "Since our model is based on GP models, it is natural to compare our model with four popular GP models: GPC [42], MTGP prediction [6], GPLVM [29], and DGPLVM [57]. To make fair comparisons, all of these models are trained on multiple source domain data sets and use the same two methods as our Gaussian Face model, which is described in Section 5. After learning the hyperparameters of the covariance function for each model, we can consider each model as a binary classifier or feature extractor like ours. Figure 3 shows that our model significantly outperforms the other four GP models, and the superiority of our model becomes apparent as more source domain data sets increase."}, {"heading": "7.2. Comparisons with Other Binary Classifiers", "text": "Since our model can be considered a binary classifier, we also compared our method with other classical binary classifiers. For this work, we chose three popular representatives: SVM [12], Logistic Regression (LR) [17], and Adaboost [18]. Table 1 shows that the performance of our method GaussianFace-BC is much better than that of the other classifiers. Furthermore, these experimental results show the effectiveness of learning constraints for multiple tasks. For example, our GaussianFace-BC shows an improvement of about 7.5% when all four source domain data sets are used for training, while the best of the other three binary classifiers only shows an improvement of about 4%."}, {"heading": "7.3. Comparisons with Other Feature Extractors", "text": "Our model can also be considered a feature extractor implemented by clustering to generate a code book. Therefore, we evaluate our method by comparing it with three popular cluster methods: K-means [24], Random Projection (RP) tree [15] and Gaussian Mixture Model (GMM) [47]. Since our method can automatically determine the number of clusters, all other methods for fair comparison generate the same number of clusters as ours. As shown in Table 2, our method GaussianFace-FE significantly exceeds all comparative approaches, confirming the effectiveness of our method as a feature extractor. Results have also shown that the multi-tasklearning Constraint is effective. Each time a different type of source domain data set is added to the training, performance can be significantly improved. Our GaussianFace-FE model achieves an improvement of over 8% when the number of SD varies from 0 to 4%, which is much higher than the 3."}, {"heading": "7.4. Comparison with the state-of-art Methods", "text": "Motivated by the appealing performance of GaussianFace-BC and GaussianFace-FE, we combine them further for facial verification. Specifically, after facial recognition, GaussianFace-FE is used with GaussianFaceBC 4 to make the final decision. Figure 4 shows the results of this combination compared to modern methods [9, 5, 14, 47, 13, 59, 1, 20, 16]. The best published result on the LFW benchmark is 96.33% 5 achieved by [9]. Our GaussianFace model can improve accuracy to 98.52%, exceeding human performance for the first time (97.53%, truncated) [28]. Figure 5 shows some sample pairs that have always been misclassified by our model. Obviously, it is also difficult for people to verify some of them."}, {"heading": "7.5. Further Validations: Shuffling the SourceTarget", "text": "To further prove the validity of our model, we consider Multi-PIE and MORPH as target domain datasets and the others as source domain datasets. The target domain dataset is divided into two mutually exclusive parts: One consisting of 20,000 matching pairs and 20,000 mismatching pairs is used for training, the4Here, the GaussianFace BC, is trained with the extracted high-dimensional features using GaussianFace-FE.5. In fact, [51] and [53] have achieved higher accuracies of 97.15% and 97.25% respectively. We do not report their performance in Figure 4 because they have not reported their ROC curves on the LFW website, so we cannot obtain the results to plot their ROC curves."}, {"heading": "8. General Discussion", "text": "There is an implicit belief among many psychologists and computer scientists that the capabilities of human face verification currently lie beyond the existing computer-aided face verification algorithms [39], but this belief is supported by anecdotal impressions rather than scientific evidence. In contrast, there is already a number of papers comparing human and computer-aided face verification performance [2, 54, 40, 41, 38, 8]. It has been shown that the best current face verification algorithms are better than humans under good and moderate conditions, so it is really not that difficult to outperform human performance in some specific scenarios. As shown in [38, 48], humans and computer-aided algorithms have different strategies in facial verification. In contrast to performances with unknown faces, human face verification capabilities for known faces are relatively robust to changes in viewing parameters such as lighting and pose."}, {"heading": "9. Conclusion and Future Work", "text": "This paper presents a principle-driven multi-task learning approach based on the discriminatory Gaussian process latent variable model called Gaussian process approximation and anchor diagrams to accelerate the inference and prediction of our model. Based on the Gaussian Face model, we propose two different approaches to facial verification. Extensive experiments with sophisticated datasets confirm the effectiveness of our model. Finally, the GaussianFace model surpassed the accuracy of facial verification at the human level, using additional data from multiple source domains to improve the generalization performance of facial verification in the target area and automatically adapt to complex facial variations. Although several techniques such as the laplace approach and anchor curve to accelerate the process of intuition and large memory model Gaussilication to balance the performance of our model require a high degree of adaptability and complexity at the same time."}, {"heading": "Acknowledgements", "text": "We would like to thank Deli Zhao and Chen Change Loy for their insightful conversations, which are supported in part by Huawei's CUHK Computer Vision Cooperation Fellowship and the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project No.CUHK 416510 and 416312) and the Guangdong Innovative Research Team Program (No.201001D0104648280)."}, {"heading": "1. Introduction", "text": "In fact, most people will be able to move to another world, in which they will be able to move to another world, in which they will be able to move, in which they will be able to move, in which they will be able to move, in which they will be able to move, in which they will be able to change the world, in which they will be able to change the world, in which they will be able to change the world, in which they will be able to change and change the world."}, {"heading": "2. Related Work", "text": "In fact, the majority of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "3. Preliminary", "text": "In this section, we briefly consider GPs for classification and clustering [?] and Gaussian Process Latent Variable Model (GPLVM) [?]. We use the GPs method mainly for the following three notable advantages. Firstly, as already mentioned, it is a non-parametric method, which means that it flexibly adapts its complexity to the complex data distributions in the real world, without heuristics or manual tuning of parameters. Secondly, the GPs method can be calculated effectively due to its closed shape calculation of the limit probability. Furthermore, its hyperparameters can be learned automatically from data without using methods of model selection such as cross-validation, avoiding the high computing costs. Thirdly, the GPs \"conclusion is based on Bayesian rules, leading to robustness to overmatch. We recommend Rasmussen and Williams\" excellent monograph for further reading [?]."}, {"heading": "3.1. Gaussian Processes for Binary Classification", "text": "Formally, for classification into two classes, it is assumed that we have a training set of D = N observations, D = (xi, yi) Ni = 1, where the i-th input point xi \u2212 RD and its corresponding output yi is binary, where y = 1i is for one class and yi = \u2212 1 is for the other. Let X be the N \u00b7 D matrix, where the row vectors represent all n input points and y is the column vector for all n outputs. We define a latent variable fi for each input point xi and leave f = [f1,.., fN]. A sigmoid function p is imposed to output the latent function in [0, 1], p (fi) = p (yi = 1 | fi). If we assume the data set f = f f f f f-f-f becomes the f-f-f capability, then the f-f capability is imposed."}, {"heading": "3.2. Gaussian Processes for Clustering", "text": "The principle of GP clustering is based on the key observation that variances in predictive values are smaller in dense areas and greater in sparse areas.The variances can be used as a good estimate of support for a probability density function, with each individual support domain being considered a cluster. (7) If the x domain is located in a sparse region, the K-K-1K domain becomes small, resulting in a large variance \u03c32 (x), and vice versa. Another good property of the equation (7) is that it does not depend on labels, meaning that it can be applied to the unlabeled data. To perform clustering, the following dynamic system associated with the equation (7) asF (x) = \u2212 direction (x) can be written as an equation."}, {"heading": "3.3. Gaussian Process Latent Variable Model", "text": "Let Z = [z1,.., zN] denote the matrix whose rows represent corresponding positions of X in latent space, where zi-Rd (d-D). The Gaussian latent variable model (GPLVM) can be interpreted as a Gaussian process mapping from a low-dimensional latent space to a high-dimensional dataset in which the position of the points in latent space is determined by maximizing the Gaussian process probability with respect to Z. Given a covariance function for the Gaussian process denoted by k (\u00b7, \u00b7), the probability of the data specifying latent positions is as follows: p (X | Z, \u03b8) = 1 \u221a (2\u03c0) ND | K | D exp (\u2212 1 2 tr (K \u2212 1XX)), (9) where Ki, j = k (zi, zj). Therefore, the posterior position prip (Z | K | D | 2001, 2001 \u2212 1, 2001, X (1), Xp (and) where the constant is."}, {"heading": "4. GaussianFace", "text": "In order to automatically learn discriminatory features or covariance functions and to use the source data to improve facial verification performance, we develop a principal Gaussian Face model by including the multitask learning constraint in the Discriminative Gauss Process Latent Variable Model (DGPLVM) [?]."}, {"heading": "4.1. DGPLVM Reformulation", "text": "The DGPLVM is an extension of the GPLVM, in which the discriminatives are presented before the latent positions = J = N = 11 and not a simple spherical Gaussian. The DGPLVM uses the discriminatives to promote latent positions of the same class, to be close and to be wide of the different classes. Since facial verification is a binary classification problem and the GPs mainly depend on the kernel function, it is natural to use the Kernel Fisher Discriminant Analysis (KFDA) [?] for model class structures in core spaces. For the simplicity of the conclusions below, we will introduce another equivalent formula of the KFDA to replace the one in [?]. KFDA is a kernel-based version of the linear discrimination analysis method. It finds the direction defined by a feature space on which the projections of positive and negative classes are distinguished well by maximizing the ratio of class variance to class."}, {"heading": "4.2. Multi-task Learning Constraint", "text": "From an asymmetric multi-task learning perspective, the tasks should have common hyperparameters of the covariance function. Furthermore, from the perspective of information theory, the information costs between the target task and multiple source tasks should be minimized. A natural method of quantifying information costs is to use mutual entropy, as it is the measure of the interdependence of two distributions. In multi-task learning, we extend mutual entropy to multiple distributions as follows: M = H (pt) \u2212 1SS: i = 1H (pt | pi), (14) where H (\u00b7) is marginal entropy, H (\u00b7 | \u00b7) is conditional entropy, S is the number of source tasks, {pi} Si = 1, and pt is the probability distribution of source tasks or targets."}, {"heading": "4.3. GaussianFace Model", "text": "In this section we describe our GaussianFace model in detail. Suppose we have S source domain data (X1,.., XS) and target domain data (XT). For each source domain data or target domain data Xi, we write their marginal latent space according to Equation (9). (15) where Zi represents the domain-relevant latent space. For each source domain data and target domain data, their covariance functions K | K | D exp (\u2212 1 2 tr (K \u2212 1XiX i))). (15), where Zi represents the domain-relevant latent space. For each source domain data and target domain data, their covariance functions have the same form because they have the same hyperparameters. In this essay, we use a widely used KernelKi, j = kernel Ki = equation (xi, xj = Exj) (Xj = (Xp = 1 \u2212 p)."}, {"heading": "4.4. Optimization", "text": "For model optimization, we first extend the equation (19) to obtain the following equation (ignoring the constant items): LModel = \u2212 logPT + \u03b2PT logPT logPT \u2212 changi = 1 (PT, i logPT, i), (20) where Pi = p (Zi, \u03b8 | Xi) and Pi, j means that the corresponding covariance function is calculated on both Xi and Xj. We can now optimize the equation (20) with respect to the hyperparameters and the latent positions: Zi according to the scaled conjugate gradient (SCG). As we focus in this work on the covariance matrix, we can only present the derivatives of the hyperparameters. It is easy to obtain the LModel items and the latent positions Zi according to the technique Zi (\u03b2 (logPT + 1) + \u03b2 SPT spective S = 1T, Pi \u2212 qi."}, {"heading": "4.5. Speedup", "text": "In the GaussianFace model Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q2-Q2-Q2-Q2-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q3-Q2-Q2-Q2-Q2-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-1-Q1-Q1-Q1-1-Q1-Q1-Q1-Q1-1-Q1-1-Q1-Q1-1-Q1-Q1-1-Q1-1-Q1-Q1-Q1-1-1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-Q1-1-Q1-Q1-Q1-Q1-Q1-1-Q1-Q1-Q1-Q1-1-Q1-Q1-1-Q1-Q1-1-Q1-Q1-Q1-Q1-1-Q1-Q1-Q1-"}, {"heading": "5. GaussianFace Model for Face Verification", "text": "In this section, we describe two applications of the Gaussian Face model for facial verification: as a binary classifier and as a feature extractor. First, each facial image is normalized to the size of 150 x 120 through an affine transformation based on five landmarks (two eyes, nose and two corners of the mouth), and the image is then divided into overlapping areas of 25 x 25 pixels with an increment of 2 pixels. Each spot within the image is mapped from a specific descriptor to a vector, and the vector is considered a feature of the spot, where P = 1 is the number of spots within the face image A. In this essay, the multi-scale LBP characteristic of each spot is extracted [?]. The difference is that the multi-scale LBP descriptors in the center of each spot are extracted, rather than precise landmarks."}, {"heading": "5.1. GaussianFace Model as a Binary Classifier", "text": "For classification, our model can be considered as an approach to learning a covariance function for GPC, as shown in Figure 1 (a), where for a pair of facial images A and B of the same (or different) person, the similarity vector xi = [s1,..., sp,.., sP] should be the data entry point of the Gaussian Face model, where sp is the similarity of xAp and xBp and its corresponding output yi = 1 (or \u2212 1). Using the learned hyperparameters of the covariance function from the training data, we first calculate the similarity vector x using the above method, and then predict whether the pair is of the same person by equation (6). In this essay, we prescribe the sigmoid function p (\u00b7) as a cumulative Gaussian distribution (\u00b7) that can be solved analytically by equation."}, {"heading": "5.2. GaussianFace Model as a Feature Extractor", "text": "As a feature extractor, we can consider our model as an approach to automatically extract facial features represented in Figure 1 (b). Here, for a pair of facial images A and B of the same (or other) person, we consider the common feature vector xi = [(xAi), (xBi) as the input data point of the Gaussian Face model, and its corresponding output is yi = 1 (or \u2212 1). To improve the robustness of our approach, the inverted form of xi is also included; for example xi = [x B i), (xAi), the hyperparameters of the covariance function are learned from the training data, we can use the method in Section 3.2 to group the input data into different face shapes."}, {"heading": "6. Experimental Settings", "text": "In this section, we conduct Face Verification Experiments. Starting with the introduction of source domain \u03b2 data sets and target domain data sets in all of our experiments (see Figure 2 for examples), Source Domain Data Sets comprise four different types of data sets as follows: Multi-PIE [?]. This data set contains facial images of 337 subjects under 15 viewing points and 19 lighting conditions in four recording sessions. These images are collected under controlled conditions. MORPH Database contains 55,000 images of more than 13,000 people between the ages of 16 to 77. There is an average of 4 images per individual.Web Images2 These data sets contain approximately 40,000 facial images of 3,261 subjects; that is, approximately 10 images for each person. Images were collected from the web with significant variations in pose, expression and lighting conditions. Life Photos2 contains approximately 5,000 images from 400 subjects collected online."}, {"heading": "7. Experimental Results", "text": "In this section, we will conduct five experiments to demonstrate the validity of the Gaussian Face model."}, {"heading": "7.1. Comparisons with Other MTGP/GP Methods", "text": "Since our model is based on GP models, it is natural to compare our model with four popular GP models: GPC [?], MTGP prediction [?], GPLVM [?], and DGPLVM [?]. To make fair comparisons, all of these models are trained on multiple source domain datasets, using the same two methods as our Gaussian Face model described in Section 5. After learning the hyperparameters of the covariance function for each model, we can consider each model as a binary classifier or feature extractor like ours. Figure 3 shows that our model significantly outperforms the other four GP models, and the superiority of our model becomes apparent the more source domain datasets there are."}, {"heading": "7.2. Comparisons with Other Binary Classifiers", "text": "Since our model can be considered a binary classifier, we also compared our method with other classical binary classifiers. For this work, we chose three popular representatives: SVM [?], Logistic Regression (LR) [?], and Adaboost [?]. Table 1 shows that the performance of our GaussianFace-BC method is much better than that of the other classifiers. Furthermore, these experimental results show the effectiveness of learning constraints for multiple tasks. For example, our GaussianFace-BC method shows an improvement of about 7.5% when all four source domain data sets are used for training, while the best of the other three binary classifiers only shows an improvement of about 4%."}, {"heading": "7.3. Comparisons with Other Feature Extractors", "text": "Our model can also be considered a feature extractor implemented by clustering to generate a code book. Therefore, we evaluate our method by comparing it with three popular cluster methods: K-means [?], Random Projection (RP) tree [?], and Gaussian MixtureModel (GMM) [?]. Since our method can automatically determine the number of clusters, all other methods generate the same number of clusters for fair comparison as ours. As shown in Table 2, our method GaussianFace-FE significantly outperforms all comparative approaches, confirming the effectiveness of our method as a feature extractor. Results have also shown that learning constraint is effective for multiple tasks. Each time a different source domain data set is added to the training, performance can be significantly improved. Our GaussianFace-FE model achieves an improvement of over 8% when the number of SD varies from 0 to 4, which is much higher than the other 3% of the methods."}, {"heading": "7.4. Comparison with the state-of-art Methods", "text": "Motivated by the appealing performance of GaussianFace-BC and GaussianFace-FE, we continue to combine them for facial verification. Specifically, GaussianFace-FE is used to make the final decision after facial features have been extracted with GaussianFace-FE. Figure 4 shows the results of this combination compared to modern methods [?,?,?,?,?,?,?,?,?,?]. The best published result on the LFW benchmark is 96.33% 5 achieved by [?]. Our GaussianFace model can improve accuracy to 98.52%, which for the first time exceeds performance on a human level (97.53%, truncated) [?]. Figure 5 shows some sample pairs that have always been misclassified by our model. Obviously, it is also difficult for people to verify some of them."}, {"heading": "7.5. Further Validations: Shuffling the SourceTarget", "text": "To further prove the validity of our model, we consider multi-PIE and MORPH data as target domain data sets and the others as source domain data sets. The target domain data set is divided into two mutually exclusive parts: one of 20,000 matching pairs and 20,000 mismatching pairs is used for training, the other for testing. In the test set, similar to the 4Here protocol, the GaussianFace BC is trained with the extracted high-dimensional features using GaussianFace-FE.5. In fact, [?] and [?] have reached a higher accuracy of 97.15% and 97.25%, respectively. We do not report on their performance in Figure 4 because they have not reported their ROC curves on the LFW website, so we cannot obtain the results to plot their ROC curves."}, {"heading": "8. General Discussion", "text": "There is an implicit belief among many psychologists and computer scientists that the capabilities of human face verification currently lie beyond the existing computer-aided face verification algorithms [?], but this belief is supported by anecdotal impressions rather than scientific evidence. In contrast, there are already a number of papers comparing human and computer-aided face verification performance. It has been shown that the best current face verification algorithms are better than humans under good and moderate conditions, so it is really not that difficult to outperform human performance in some specific scenarios. As shown in [?,?] people and computer-aided algorithms have different strategies in facial verification. In contrast to performance with unknown faces, human face verification capabilities for familiar faces are relatively robust to changes in viewing parameters such as lighting parameters and pose. For example, Bruce [?] found human recognition stores for unknown faces when there have been significant decreases in the changes in the viewing parameters."}, {"heading": "9. Conclusion and Future Work", "text": "This paper presents a principle-driven multi-task learning approach based on the discriminatory Gaussian process latent variable model called Gaussian Face for facial verification by incorporating a more computationally efficient equivalent form of KFDA and the multi-task learning constraint of the DGPLVM model. We use Gaussian process approximation and anchor graphics to accelerate the inference and prediction of our model. Based on the Gaussian Face model, we propose two different approaches to facial verification. Extensive experiments with sophisticated datasets confirm the effectiveness of our model. The Gaussian Face model has finally surpassed the accuracy of facial verification at the human level, thanks to the use of additional data from multiple source domains to enhance the generalization performance of facial verification in the target area and to automatically adapt to complex facial verification techniques in order to maximize the amount of time required for the application of large-scale memory variance.Although it is necessary for large-scale approximation, the intuition of large-scale memory models is an intuition."}, {"heading": "Acknowledgements", "text": "We would like to thank Deli Zhao and Chen Change Loy for their insightful conversations, which are supported in part by Huawei's CUHK Computer Vision Cooperation Fellowship and the General Research Fund sponsored by the Research Grants Council of Hong Kong (Project No.CUHK 416510 and 416312) and the Guangdong Innovative Research Team Program (No.201001D0104648280)."}], "references": [{"title": "Comparing human and automatic face recognition performance", "author": ["A. Adler", "M.E. Schuckers"], "venue": "IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 37(5):1248\u20131255,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Face description with local binary patterns: Application to face recognition", "author": ["T. Ahonen", "A. Hadid", "M. Pietikainen"], "venue": "TPAMI, 28(12):2037\u20132041,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "Support vector clustering", "author": ["A. Ben-Hur", "D. Horn", "H.T. Siegelmann", "V. Vapnik"], "venue": "JMLR, 2,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2002}, {"title": "Tom-vs-pete classifiers and identity-preserving alignment for face verification", "author": ["T. Berg", "P.N. Belhumeur"], "venue": "BMVC, volume 1, page 5,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Multi-task gaussian process prediction", "author": ["E. Bonilla", "K.M. Chai", "C. Williams"], "venue": "NIPS,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Changing faces: Visual and non-visual coding processes in face recognition", "author": ["V. Bruce"], "venue": "British Journal of Psychology, 73(1):105\u2013116,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1982}, {"title": "Comparisons between human and computer recognition of faces", "author": ["V. Bruce", "P.J. Hancock", "A.M. Burton"], "venue": "Automatic Face and Gesture Recognition, pages 408\u2013413,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1998}, {"title": "A practical transfer learning algorithm for face verification", "author": ["X. Cao", "D. Wipf", "F. Wen", "G. Duan"], "venue": "ICCV.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Face recognition with learning-based descriptor", "author": ["Z. Cao", "Q. Yin", "X. Tang", "J. Sun"], "venue": "CVPR, pages 2707\u2013 2714,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-task learning with gaussian processes", "author": ["K.M. Chai"], "venue": "The University of Edinburgh,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Libsvm: a library for support vector machines", "author": ["C.-C. Chang", "C.-J. Lin"], "venue": "ACM TIST, 2(3):27,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2011}, {"title": "Bayesian face revisited: A joint formulation", "author": ["D. Chen", "X. Cao", "L. Wang", "F. Wen", "J. Sun"], "venue": "ECCV, pages 566\u2013579.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "Blessing of dimensionality: High-dimensional feature and its efficient compression for face verification", "author": ["D. Chen", "X. Cao", "F. Wen", "J. Sun"], "venue": "CVPR.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Random projection trees for vector quantization", "author": ["S. Dasgupta", "Y. Freund"], "venue": "IEEE Transactions on Information Theory, 55(7):3229\u20133242,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning deep face representation", "author": ["H. Fan", "Z. Cao", "Y. Jiang", "Q. Yin", "C. Doudou"], "venue": "arXiv preprint arXiv:1403.2802,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Liblinear: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "JMLR, 9:1871\u20131874,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2008}, {"title": "A short introduction to boosting", "author": ["Y. Freund", "R. Schapire", "N. Abe"], "venue": "Journal-Japanese Society For Artificial Intelligence, 14(771-780):1612,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1999}, {"title": "Multi-pie", "author": ["R. Gross", "I. Matthews", "J. Cohn", "T. Kanade", "S. Baker"], "venue": "Image and Vision Computing, 28(5):807\u2013813,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Aurora face recognition technical report: Evaluation of algorithm aurora-c-2014-1 on labeled faces in the wild", "author": ["T. Heseltine", "P. Szeptycki", "J. Gomes", "M. Ruiz", "P. Li"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Accuracy and Stability of Numberical Algorithms", "author": ["N.J. Higham"], "venue": "Number 48. Siam,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1996}, {"title": "Learning hierarchical representations for face verification with convolutional deep belief networks", "author": ["G. Huang", "H. Lee", "E. Learned-Miller"], "venue": "CVPR,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "author": ["G.B. Huang", "M. Ramesh", "T. Berg", "E. Learned- Miller"], "venue": "Technical Report 07-49, University of Massachusetts, Amherst,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Face recognition using local quantized patterns", "author": ["S.U. Hussain", "T. Napol\u00e9on", "F. Jurie"], "venue": "In BMVC,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Appearance-based gender classification with gaussian processes", "author": ["H.-C. Kim", "D. Kim", "Z. Ghahramani", "S.Y. Bang"], "venue": "Pattern Recognition Letters, 27(6):618\u2013 626,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2006}, {"title": "Clustering based on gaussian processes", "author": ["H.-C. Kim", "J. Lee"], "venue": "Neural computation, 19(11),", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2007}, {"title": "Optimal kernel selection in kernel fisher discriminant analysis", "author": ["S.-J. Kim", "A. Magnani", "S. Boyd"], "venue": "ICML, pages 465\u2013472,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2006}, {"title": "Attribute and simile classifiers for face verification", "author": ["N. Kumar", "A.C. Berg", "P.N. Belhumeur", "S.K. Nayar"], "venue": "ICCV, pages 365\u2013372,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "Gaussian process latent variable models for visualisation of high dimensional data", "author": ["N.D. Lawrence"], "venue": "NIPS, volume 2, page 5,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2003}, {"title": "Focused multitask learning using gaussian processes", "author": ["G. Leen", "J. Peltonen", "S. Kaski"], "venue": "Machine Learning and Knowledge Discovery in Databases, pages 310\u2013325.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic elastic matching for pose variant face verification", "author": ["H. Li", "G. Hua", "Z. Lin", "J. Brandt", "J. Yang"], "venue": "CVPR.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2013}, {"title": "Nonparametric discriminant analysis for face recognition", "author": ["Z. Li", "D. Lin", "X. Tang"], "venue": "TPAMI, 31(4):755\u2013 761,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "Nonparametric subspace analysis for face recognition", "author": ["Z. Li", "W. Liu", "D. Lin", "X. Tang"], "venue": "CVPR, volume 2, pages 961\u2013966,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2005}, {"title": "Gabor feature based classification using the enhanced fisher linear discriminant model for face recognition", "author": ["C. Liu", "H. Wechsler"], "venue": "TIP,", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2002}, {"title": "Large graph construction for scalable semi-supervised learning", "author": ["W. Liu", "J. He", "S.-F. Chang"], "venue": "ICML, pages 679\u2013686,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2010}, {"title": "Distinctive image features from scaleinvariant keypoints", "author": ["D.G. Lowe"], "venue": "IJCV, 60(2):91\u2013110,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2004}, {"title": "Bayesian face recognition", "author": ["B. Moghaddam", "T. Jebara", "A. Pentland"], "venue": "Pattern Recognition, 33(11):1771\u2013 1782,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2000}, {"title": "Comparing face recognition algorithms to humans on challenging tasks", "author": ["A.J. O\u2019Toole", "X. An", "J. Dunlop", "V. Natu", "P.J. Phillips"], "venue": "ACM Transactions on Applied Perception,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2012}, {"title": "Predicting human performance for face recognition", "author": ["A.J. OToole", "F. Jiang", "D. Roark", "H. Abdi"], "venue": "Face Processing: Advanced Methods and Models. Elsevier, Amsterdam,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2006}, {"title": "Face recognition algorithms surpass humans matching faces over changes", "author": ["A.J. O\u2019Toole", "P.J. Phillips", "F. Jiang", "J. Ayyad", "N. P\u00e9nard", "H. Abdi"], "venue": "in illumination. TPAMI,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2007}, {"title": "Comparison of human and computer performance across face recognition experiments", "author": ["P.J. Phillips", "A.J. O\u2019Toole"], "venue": "Image and Vision Computing,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}, {"title": "Gaussian processes for machine learning", "author": ["C.E. Rasmussen", "C.K.I. Williams"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2006}, {"title": "Morph: A longitudinal image database of normal adult age-progression", "author": ["K. Ricanek", "T. Tesafaye"], "venue": "Automatic Face and Gesture Recognition, pages 341\u2013 345,", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2006}, {"title": "Coupled gaussian process regression for pose-invariant facial expression recognition", "author": ["O. Rudovic", "I. Patras", "M. Pantic"], "venue": "ECCV.", "citeRegEx": "44", "shortCiteRegEx": null, "year": 2010}, {"title": "Using deep belief nets to learn covariance kernels for gaussian processes", "author": ["R. Salakhutdinov", "G.E. Hinton"], "venue": "NIPS,", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2007}, {"title": "Face verification using the lark representation", "author": ["H.J. Seo", "P. Milanfar"], "venue": "TIFS, 6(4):1275\u20131286,", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2011}, {"title": "Fisher vector faces in the wild", "author": ["K. Simonyan", "O.M. Parkhi", "A. Vedaldi", "A. Zisserman"], "venue": "IJCV, 60(2):91\u2013 110,", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2004}, {"title": "Face recognition by humans: 20 results all computer vision researchers should know about", "author": ["P. Sinha", "B. Balas", "Y. Ostrovsky", "R. Russell"], "venue": "Department of Brain and Cognitive Sciences, MIT, Cambridge, MA,", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2005}, {"title": "Bayesian multitask classification with gaussian process priors", "author": ["G. Skolidis", "G. Sanguinetti"], "venue": "IEEE Transactions on Neural Networks, 22(12),", "citeRegEx": "49", "shortCiteRegEx": null, "year": 2011}, {"title": "Hybrid deep learning for face verification", "author": ["Y. Sun", "X. Wang", "X. Tang"], "venue": "ICCV.", "citeRegEx": "50", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep learning face representation from predicting 10,000 classes", "author": ["Y. Sun", "X. Wang", "X. Tang"], "venue": "CVPR,", "citeRegEx": "51", "shortCiteRegEx": null, "year": 2014}, {"title": "Multiple oneshots for utilizing class label information", "author": ["Y. Taigman", "L. Wolf", "T. Hassner"], "venue": "BMVC, pages 1\u201312,", "citeRegEx": "52", "shortCiteRegEx": null, "year": 2009}, {"title": "Deep- Face: Closing the Gap to Human-Level Performance in Face Verification", "author": ["Y. Taigman", "M. Yang", "M. Ranzato", "L. Wolf"], "venue": "CVPR,", "citeRegEx": "53", "shortCiteRegEx": null, "year": 2014}, {"title": "Face sketch recognition", "author": ["X. Tang", "X. Wang"], "venue": "IEEE Transactions on Circuits and Systems for Video Technology, 14(1):50\u201357,", "citeRegEx": "54", "shortCiteRegEx": null, "year": 2004}, {"title": "Unbiased look at dataset bias", "author": ["A. Torralba", "A.A. Efros"], "venue": "CVPR, pages 1521\u20131528,", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2011}, {"title": "Face recognition using eigenfaces", "author": ["M.A. Turk", "A.P. Pentland"], "venue": "CVPR, pages 586\u2013591,", "citeRegEx": "56", "shortCiteRegEx": null, "year": 1991}, {"title": "Discriminative gaussian process latent variable model for classification", "author": ["R. Urtasun", "T. Darrell"], "venue": "ICML, pages 927\u2013934,", "citeRegEx": "57", "shortCiteRegEx": null, "year": 2007}, {"title": "Implicit elastic matching with random projections for pose-variant face recognition", "author": ["J. Wright", "G. Hua"], "venue": "CVPR, pages 1502\u20131509,", "citeRegEx": "58", "shortCiteRegEx": null, "year": 2009}, {"title": "An associate-predict model for face recognition", "author": ["Q. Yin", "X. Tang", "J. Sun"], "venue": "CVPR, pages 497\u2013504,", "citeRegEx": "59", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning gaussian processes from multiple tasks", "author": ["K. Yu", "V. Tresp", "A. Schwaighofer"], "venue": "ICML, pages 1012\u20131019,", "citeRegEx": "60", "shortCiteRegEx": null, "year": 2005}, {"title": "Multi-task warped gaussian process for personalized age estimation", "author": ["Y. Zhang", "D.-Y. Yeung"], "venue": "CVPR, pages 2622\u20132629,", "citeRegEx": "61", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep learning identity preserving face space", "author": ["Z. Zhu", "P. Luo", "X. Wang", "X. Tang"], "venue": "ICCV.", "citeRegEx": "62", "shortCiteRegEx": null, "year": 2013}, {"title": "Recover canonical-view faces in the wild with deep neural networks", "author": ["Z. Zhu", "P. Luo", "X. Wang", "X. Tang"], "venue": "arXiv:1404.3543,", "citeRegEx": "63", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 21, "context": "52% on the well-known and challenging Labeled Faces in the Wild (LFW) benchmark [23].", "startOffset": 80, "endOffset": 84}, {"referenceID": 26, "context": "53%) [28] on LFW is surpassed.", "startOffset": 5, "endOffset": 9}, {"referenceID": 26, "context": "Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades [28, 22, 46, 5, 47, 31, 14, 9].", "startOffset": 173, "endOffset": 203}, {"referenceID": 20, "context": "Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades [28, 22, 46, 5, 47, 31, 14, 9].", "startOffset": 173, "endOffset": 203}, {"referenceID": 44, "context": "Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades [28, 22, 46, 5, 47, 31, 14, 9].", "startOffset": 173, "endOffset": 203}, {"referenceID": 3, "context": "Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades [28, 22, 46, 5, 47, 31, 14, 9].", "startOffset": 173, "endOffset": 203}, {"referenceID": 45, "context": "Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades [28, 22, 46, 5, 47, 31, 14, 9].", "startOffset": 173, "endOffset": 203}, {"referenceID": 29, "context": "Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades [28, 22, 46, 5, 47, 31, 14, 9].", "startOffset": 173, "endOffset": 203}, {"referenceID": 12, "context": "Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades [28, 22, 46, 5, 47, 31, 14, 9].", "startOffset": 173, "endOffset": 203}, {"referenceID": 7, "context": "Face verification, which is the task of determining whether a pair of face images are from the same person, has been an active research topic in computer vision for decades [28, 22, 46, 5, 47, 31, 14, 9].", "startOffset": 173, "endOffset": 203}, {"referenceID": 21, "context": "However, various visual complications deteriorate the performance of face verification, as shown by numerous studies on real-world face images from the wild [23].", "startOffset": 157, "endOffset": 161}, {"referenceID": 21, "context": "Not surprisingly, LFW has proven difficult for automatic face verification methods [23, 28].", "startOffset": 83, "endOffset": 91}, {"referenceID": 26, "context": "Not surprisingly, LFW has proven difficult for automatic face verification methods [23, 28].", "startOffset": 83, "endOffset": 91}, {"referenceID": 20, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 7, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 3, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 12, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 45, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 11, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 57, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 48, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 49, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 51, "context": "Although there has been significant work [22, 9, 5, 14, 47, 13, 59, 50, 51, 53] on LFW and the accuracy rate has been improved from 60.", "startOffset": 41, "endOffset": 79}, {"referenceID": 54, "context": "02% [56] to 97.", "startOffset": 4, "endOffset": 8}, {"referenceID": 51, "context": "25% [53] since LFW is established in 2007, these studies have not closed the gap to human-level performance [28] in face verification.", "startOffset": 4, "endOffset": 8}, {"referenceID": 26, "context": "25% [53] since LFW is established in 2007, these studies have not closed the gap to human-level performance [28] in face verification.", "startOffset": 108, "endOffset": 112}, {"referenceID": 56, "context": "When the distribution changes, these methods may suffer a large performance drop [58].", "startOffset": 81, "endOffset": 85}, {"referenceID": 53, "context": "Learning a model solely on a single source data often leads to overfitting due to dataset bias [55].", "startOffset": 95, "endOffset": 99}, {"referenceID": 34, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 106, "endOffset": 125}, {"referenceID": 1, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 106, "endOffset": 125}, {"referenceID": 32, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 106, "endOffset": 125}, {"referenceID": 8, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 106, "endOffset": 125}, {"referenceID": 22, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 106, "endOffset": 125}, {"referenceID": 60, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 48, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 11, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 35, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 29, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 54, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 3, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 26, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 45, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 31, "context": "2) Modern face verification methods are mainly divided into two categories: extracting low-level features [36, 3, 34, 10, 24], and building classification models [62, 50, 13, 37, 31, 56, 5, 28, 47, 33].", "startOffset": 162, "endOffset": 201}, {"referenceID": 34, "context": "For the methods in the first category, for example, low-level features such as SIFT [36], LBP [3], and Gabor [34] are handcrafted.", "startOffset": 84, "endOffset": 88}, {"referenceID": 1, "context": "For the methods in the first category, for example, low-level features such as SIFT [36], LBP [3], and Gabor [34] are handcrafted.", "startOffset": 94, "endOffset": 97}, {"referenceID": 32, "context": "For the methods in the first category, for example, low-level features such as SIFT [36], LBP [3], and Gabor [34] are handcrafted.", "startOffset": 109, "endOffset": 113}, {"referenceID": 8, "context": "Even for features learned from data [10, 24], the algorithm parameters (such as the depth of random projection tree, or the number of centers in k-means) also need to be specified by users.", "startOffset": 36, "endOffset": 44}, {"referenceID": 22, "context": "Even for features learned from data [10, 24], the algorithm parameters (such as the depth of random projection tree, or the number of centers in k-means) also need to be specified by users.", "startOffset": 36, "endOffset": 44}, {"referenceID": 60, "context": "for the methods in the second category, the architectures of deep networks in [62, 50, 63, 51] (for example, the number of layers, the number of nodes in each layer, etc.", "startOffset": 78, "endOffset": 94}, {"referenceID": 48, "context": "for the methods in the second category, the architectures of deep networks in [62, 50, 63, 51] (for example, the number of layers, the number of nodes in each layer, etc.", "startOffset": 78, "endOffset": 94}, {"referenceID": 61, "context": "for the methods in the second category, the architectures of deep networks in [62, 50, 63, 51] (for example, the number of layers, the number of nodes in each layer, etc.", "startOffset": 78, "endOffset": 94}, {"referenceID": 49, "context": "for the methods in the second category, the architectures of deep networks in [62, 50, 63, 51] (for example, the number of layers, the number of nodes in each layer, etc.", "startOffset": 78, "endOffset": 94}, {"referenceID": 29, "context": "), and the parameters of the models in [31, 5, 28, 47] (for example, the number of Gaussians, the number of classifiers, etc.", "startOffset": 39, "endOffset": 54}, {"referenceID": 3, "context": "), and the parameters of the models in [31, 5, 28, 47] (for example, the number of Gaussians, the number of classifiers, etc.", "startOffset": 39, "endOffset": 54}, {"referenceID": 26, "context": "), and the parameters of the models in [31, 5, 28, 47] (for example, the number of Gaussians, the number of classifiers, etc.", "startOffset": 39, "endOffset": 54}, {"referenceID": 45, "context": "), and the parameters of the models in [31, 5, 28, 47] (for example, the number of Gaussians, the number of classifiers, etc.", "startOffset": 39, "endOffset": 54}, {"referenceID": 55, "context": "To this end, we propose the Multi-Task Learning approach based on Discriminative Gaussian Process Latent Variable Model (DGPLVM) [57], named GaussianFace, for face verification.", "startOffset": 129, "endOffset": 133}, {"referenceID": 20, "context": "Unlike most existing studies [22, 5, 14, 47, 13] that rely on a single training data source, in order to take advantage of more data from multiple source-domains to improve the performance in the target-domain, we introduce the multi-task learning constraint to DGPLVM.", "startOffset": 29, "endOffset": 48}, {"referenceID": 3, "context": "Unlike most existing studies [22, 5, 14, 47, 13] that rely on a single training data source, in order to take advantage of more data from multiple source-domains to improve the performance in the target-domain, we introduce the multi-task learning constraint to DGPLVM.", "startOffset": 29, "endOffset": 48}, {"referenceID": 12, "context": "Unlike most existing studies [22, 5, 14, 47, 13] that rely on a single training data source, in order to take advantage of more data from multiple source-domains to improve the performance in the target-domain, we introduce the multi-task learning constraint to DGPLVM.", "startOffset": 29, "endOffset": 48}, {"referenceID": 45, "context": "Unlike most existing studies [22, 5, 14, 47, 13] that rely on a single training data source, in order to take advantage of more data from multiple source-domains to improve the performance in the target-domain, we introduce the multi-task learning constraint to DGPLVM.", "startOffset": 29, "endOffset": 48}, {"referenceID": 11, "context": "Unlike most existing studies [22, 5, 14, 47, 13] that rely on a single training data source, in order to take advantage of more data from multiple source-domains to improve the performance in the target-domain, we introduce the multi-task learning constraint to DGPLVM.", "startOffset": 29, "endOffset": 48}, {"referenceID": 40, "context": "Moreover, the GaussianFace model is a reformulation based on the Gaussian Processes (GPs) [42], which is a non-parametric Bayesian kernel method.", "startOffset": 90, "endOffset": 94}, {"referenceID": 40, "context": "We make use of GP approximations [42] and anchor graphs [35] to speed up the process of inference and prediction, so as to scale our model to largescale data.", "startOffset": 33, "endOffset": 37}, {"referenceID": 33, "context": "We make use of GP approximations [42] and anchor graphs [35] to speed up the process of inference and prediction, so as to scale our model to largescale data.", "startOffset": 56, "endOffset": 60}, {"referenceID": 21, "context": "\u2022 We achieve superior performance on the challenging LFW benchmark [23], with an accuracy rate of 98.", "startOffset": 67, "endOffset": 71}, {"referenceID": 26, "context": "52%, beyond human-level performance reported in [28].", "startOffset": 48, "endOffset": 52}, {"referenceID": 38, "context": "Human and computer performance on face recognition has been compared extensively [40, 38, 2, 54, 41, 8].", "startOffset": 81, "endOffset": 103}, {"referenceID": 36, "context": "Human and computer performance on face recognition has been compared extensively [40, 38, 2, 54, 41, 8].", "startOffset": 81, "endOffset": 103}, {"referenceID": 0, "context": "Human and computer performance on face recognition has been compared extensively [40, 38, 2, 54, 41, 8].", "startOffset": 81, "endOffset": 103}, {"referenceID": 52, "context": "Human and computer performance on face recognition has been compared extensively [40, 38, 2, 54, 41, 8].", "startOffset": 81, "endOffset": 103}, {"referenceID": 39, "context": "Human and computer performance on face recognition has been compared extensively [40, 38, 2, 54, 41, 8].", "startOffset": 81, "endOffset": 103}, {"referenceID": 6, "context": "Human and computer performance on face recognition has been compared extensively [40, 38, 2, 54, 41, 8].", "startOffset": 81, "endOffset": 103}, {"referenceID": 38, "context": "However, the above conclusion is only verified on face datasets with controlled variations, where only one factor changes at a time [40, 38].", "startOffset": 132, "endOffset": 140}, {"referenceID": 36, "context": "However, the above conclusion is only verified on face datasets with controlled variations, where only one factor changes at a time [40, 38].", "startOffset": 132, "endOffset": 140}, {"referenceID": 45, "context": "applied the Fisher vector to face verification and achieved a good performance [47].", "startOffset": 79, "endOffset": 83}, {"referenceID": 31, "context": "proposed a non-parametric subspace analysis [33, 32], but it is only a linear transformation and cannot cover the complex distributions.", "startOffset": 44, "endOffset": 52}, {"referenceID": 30, "context": "proposed a non-parametric subspace analysis [33, 32], but it is only a linear transformation and cannot cover the complex distributions.", "startOffset": 44, "endOffset": 52}, {"referenceID": 11, "context": "Based on the Joint Bayesian algorithm [13], Cao et al.", "startOffset": 38, "endOffset": 42}, {"referenceID": 7, "context": "proposed a transfer learning approach [9] by merging source-domain data with limited target-domain data.", "startOffset": 38, "endOffset": 41}, {"referenceID": 7, "context": "Moreover, the transfer learning approach in [9] only considered two different domains, restricting its wider applications in largescale data from multiple domains.", "startOffset": 44, "endOffset": 47}, {"referenceID": 61, "context": "[63] learned the transformation from face images under various poses and lighting conditions to a canonical view with a deep convolutional network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 49, "context": "[51] learned face representation with a deep model through face identification, which is a challenging multi-class prediction task.", "startOffset": 0, "endOffset": 4}, {"referenceID": 50, "context": "[52] first utilized explicit 3D face modeling to apply a piecewise affine transformation, and then derived a face representation from a nine-layer deep neural network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 58, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 9, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 23, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 28, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 42, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 47, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 59, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 24, "context": "Actually, MTGP/GPs have been extensively studied in machine learning and computer vision in recent years [6, 60, 11, 25, 30, 44, 49, 61, 26].", "startOffset": 105, "endOffset": 140}, {"referenceID": 58, "context": "However, most of them [60, 11, 6, 44, 25, 49, 61] have only considered the symmetric multi-task learning, which means that all tasks have been assumed to be of equal importance, whereas our purpose is to enhance performance on a target task given all other source tasks.", "startOffset": 22, "endOffset": 49}, {"referenceID": 9, "context": "However, most of them [60, 11, 6, 44, 25, 49, 61] have only considered the symmetric multi-task learning, which means that all tasks have been assumed to be of equal importance, whereas our purpose is to enhance performance on a target task given all other source tasks.", "startOffset": 22, "endOffset": 49}, {"referenceID": 4, "context": "However, most of them [60, 11, 6, 44, 25, 49, 61] have only considered the symmetric multi-task learning, which means that all tasks have been assumed to be of equal importance, whereas our purpose is to enhance performance on a target task given all other source tasks.", "startOffset": 22, "endOffset": 49}, {"referenceID": 42, "context": "However, most of them [60, 11, 6, 44, 25, 49, 61] have only considered the symmetric multi-task learning, which means that all tasks have been assumed to be of equal importance, whereas our purpose is to enhance performance on a target task given all other source tasks.", "startOffset": 22, "endOffset": 49}, {"referenceID": 23, "context": "However, most of them [60, 11, 6, 44, 25, 49, 61] have only considered the symmetric multi-task learning, which means that all tasks have been assumed to be of equal importance, whereas our purpose is to enhance performance on a target task given all other source tasks.", "startOffset": 22, "endOffset": 49}, {"referenceID": 47, "context": "However, most of them [60, 11, 6, 44, 25, 49, 61] have only considered the symmetric multi-task learning, which means that all tasks have been assumed to be of equal importance, whereas our purpose is to enhance performance on a target task given all other source tasks.", "startOffset": 22, "endOffset": 49}, {"referenceID": 59, "context": "However, most of them [60, 11, 6, 44, 25, 49, 61] have only considered the symmetric multi-task learning, which means that all tasks have been assumed to be of equal importance, whereas our purpose is to enhance performance on a target task given all other source tasks.", "startOffset": 22, "endOffset": 49}, {"referenceID": 28, "context": "proposed a MTGP model in the asymmetric setting [30] to focus on improving performance on the target task, and Kim et al.", "startOffset": 48, "endOffset": 52}, {"referenceID": 24, "context": "developed a GP model for clustering [26], but their methods do not take the discriminative information of the covariance function into special account like DGPLVM.", "startOffset": 36, "endOffset": 40}, {"referenceID": 55, "context": "Although the discriminative information is considered in [57], it does not apply multi-task learning to improve its performance.", "startOffset": 57, "endOffset": 61}, {"referenceID": 43, "context": "used a deep belief net to learn a good covariance kernel for GPs [45].", "startOffset": 65, "endOffset": 69}, {"referenceID": 43, "context": "Also, multi-task learning constraint was not considered in [45].", "startOffset": 59, "endOffset": 63}, {"referenceID": 24, "context": "In this section, we briefly review Gaussian Processes (GPs) for classification and clustering [26], and Gaussian Process Latent Variable Model (GPLVM) [29].", "startOffset": 94, "endOffset": 98}, {"referenceID": 27, "context": "In this section, we briefly review Gaussian Processes (GPs) for classification and clustering [26], and Gaussian Process Latent Variable Model (GPLVM) [29].", "startOffset": 151, "endOffset": 155}, {"referenceID": 40, "context": "We recommend Rasmussen and Williams\u2019s excellent monograph for further reading [42].", "startOffset": 78, "endOffset": 82}, {"referenceID": 24, "context": "The theorem in [26] guarantees that almost all the trajectories approach one of the stable equilibrium points detected from Equation (8).", "startOffset": 15, "endOffset": 19}, {"referenceID": 2, "context": "After each data point finds its corresponding stable equilibrium point, we can employ a complete graph [4, 26] to assign cluster labels to data points with the stable equilibrium points.", "startOffset": 103, "endOffset": 110}, {"referenceID": 24, "context": "After each data point finds its corresponding stable equilibrium point, we can employ a complete graph [4, 26] to assign cluster labels to data points with the stable equilibrium points.", "startOffset": 103, "endOffset": 110}, {"referenceID": 55, "context": "where Za is a normalization constant, the uninformative priors over \u03b8, and the simple spherical Gaussian priors over Z are introduced [57].", "startOffset": 134, "endOffset": 138}, {"referenceID": 55, "context": "In order to automatically learn discriminative features or covariance function, and to take advantage of sourcedomain data to improve the performance in face verification, we develop a principled GaussianFace model by including the multi-task learning constraint into Discriminative Gaussian Process Latent Variable Model (DGPLVM) [57].", "startOffset": 331, "endOffset": 335}, {"referenceID": 25, "context": "Since face verification is a binary classification problem and the GPs mainly depend on the kernel function, it is natural to use Kernel Fisher Discriminant Analysis (KFDA) [27] to model class structures in kernel spaces.", "startOffset": 173, "endOffset": 177}, {"referenceID": 55, "context": "For simplicity of inference in the followings, we introduce another equivalent formulation of KFDA to replace the one in [57].", "startOffset": 121, "endOffset": 125}, {"referenceID": 25, "context": "points out [27], i.", "startOffset": 11, "endOffset": 15}, {"referenceID": 33, "context": "In this paper, we use the anchor graphs method [35] to speed up this process.", "startOffset": 47, "endOffset": 51}, {"referenceID": 19, "context": "Using the Woodbury identity [21], computing the n\u00d7 n matrix QQ can be transformed into computing the q \u00d7 q matrix QQ, which is more efficient.", "startOffset": 28, "endOffset": 32}, {"referenceID": 12, "context": "In this paper, the multi-scale LBP feature of each patch is extracted [14].", "startOffset": 70, "endOffset": 74}, {"referenceID": 40, "context": ", where \u03c3(x\u2217) = K\u2217\u2217 \u2212K\u2217K\u0303K\u2217 and f\u0304\u2217(x\u2217) = K\u2217K f\u0302 from Equation (5) [42].", "startOffset": 67, "endOffset": 71}, {"referenceID": 17, "context": "The source-domain datasets include four different types of datasets as follows: Multi-PIE [19].", "startOffset": 90, "endOffset": 94}, {"referenceID": 41, "context": "MORPH [43].", "startOffset": 6, "endOffset": 10}, {"referenceID": 21, "context": "If not otherwise specified, the target-domain dataset is the benchmark of face verification as follows: LFW [23].", "startOffset": 108, "endOffset": 112}, {"referenceID": 7, "context": "Using it also allows us to compare directly with other existing face verification methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 90, "endOffset": 123}, {"referenceID": 3, "context": "Using it also allows us to compare directly with other existing face verification methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 90, "endOffset": 123}, {"referenceID": 12, "context": "Using it also allows us to compare directly with other existing face verification methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 90, "endOffset": 123}, {"referenceID": 45, "context": "Using it also allows us to compare directly with other existing face verification methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 90, "endOffset": 123}, {"referenceID": 11, "context": "Using it also allows us to compare directly with other existing face verification methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 90, "endOffset": 123}, {"referenceID": 57, "context": "Using it also allows us to compare directly with other existing face verification methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 90, "endOffset": 123}, {"referenceID": 18, "context": "Using it also allows us to compare directly with other existing face verification methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 90, "endOffset": 123}, {"referenceID": 14, "context": "Using it also allows us to compare directly with other existing face verification methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 90, "endOffset": 123}, {"referenceID": 21, "context": "Besides, this dataset provides a large set of relatively unconstrained face images with complex variations as described above, and has proven difficult for automatic face verification methods [23, 28].", "startOffset": 192, "endOffset": 200}, {"referenceID": 26, "context": "Besides, this dataset provides a large set of relatively unconstrained face images with complex variations as described above, and has proven difficult for automatic face verification methods [23, 28].", "startOffset": 192, "endOffset": 200}, {"referenceID": 21, "context": "In all the experiments conducted on LFW, we strictly follow the standard unrestricted protocol of LFW [23].", "startOffset": 102, "endOffset": 106}, {"referenceID": 25, "context": "Following the same setting in [27], the regularization parameter \u03bb in (12) is fixed to 10.", "startOffset": 30, "endOffset": 34}, {"referenceID": 40, "context": "Since our model is based on GPs, it is natural to compare our model with four popular GP models: GPC [42], MTGP prediction [6], GPLVM [29], and DGPLVM [57].", "startOffset": 101, "endOffset": 105}, {"referenceID": 4, "context": "Since our model is based on GPs, it is natural to compare our model with four popular GP models: GPC [42], MTGP prediction [6], GPLVM [29], and DGPLVM [57].", "startOffset": 123, "endOffset": 126}, {"referenceID": 27, "context": "Since our model is based on GPs, it is natural to compare our model with four popular GP models: GPC [42], MTGP prediction [6], GPLVM [29], and DGPLVM [57].", "startOffset": 134, "endOffset": 138}, {"referenceID": 55, "context": "Since our model is based on GPs, it is natural to compare our model with four popular GP models: GPC [42], MTGP prediction [6], GPLVM [29], and DGPLVM [57].", "startOffset": 151, "endOffset": 155}, {"referenceID": 10, "context": "For this paper, we chose three popular representatives: SVM [12], logistic regression (LR) [17], and Adaboost [18].", "startOffset": 60, "endOffset": 64}, {"referenceID": 15, "context": "For this paper, we chose three popular representatives: SVM [12], logistic regression (LR) [17], and Adaboost [18].", "startOffset": 91, "endOffset": 95}, {"referenceID": 16, "context": "For this paper, we chose three popular representatives: SVM [12], logistic regression (LR) [17], and Adaboost [18].", "startOffset": 110, "endOffset": 114}, {"referenceID": 22, "context": "Therefore, we evaluate our method by comparing it with three popular clustering methods: K-means [24], Random Projection (RP) tree [15], and Gaussian Mixture Model (GMM) [47].", "startOffset": 97, "endOffset": 101}, {"referenceID": 13, "context": "Therefore, we evaluate our method by comparing it with three popular clustering methods: K-means [24], Random Projection (RP) tree [15], and Gaussian Mixture Model (GMM) [47].", "startOffset": 131, "endOffset": 135}, {"referenceID": 45, "context": "Therefore, we evaluate our method by comparing it with three popular clustering methods: K-means [24], Random Projection (RP) tree [15], and Gaussian Mixture Model (GMM) [47].", "startOffset": 170, "endOffset": 174}, {"referenceID": 10, "context": "SVM [12] 83.", "startOffset": 4, "endOffset": 8}, {"referenceID": 15, "context": "31 LR [17] 81.", "startOffset": 6, "endOffset": 10}, {"referenceID": 16, "context": "75 Adaboost [18] 82.", "startOffset": 12, "endOffset": 16}, {"referenceID": 22, "context": "K-means [24] 84.", "startOffset": 8, "endOffset": 12}, {"referenceID": 13, "context": "68 RP Tree [15] 85.", "startOffset": 11, "endOffset": 15}, {"referenceID": 45, "context": "34 GMM [47] 86.", "startOffset": 7, "endOffset": 11}, {"referenceID": 7, "context": "Figure 4 shows the results of this combination compared with state-of-theart methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 85, "endOffset": 118}, {"referenceID": 3, "context": "Figure 4 shows the results of this combination compared with state-of-theart methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 85, "endOffset": 118}, {"referenceID": 12, "context": "Figure 4 shows the results of this combination compared with state-of-theart methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 85, "endOffset": 118}, {"referenceID": 45, "context": "Figure 4 shows the results of this combination compared with state-of-theart methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 85, "endOffset": 118}, {"referenceID": 11, "context": "Figure 4 shows the results of this combination compared with state-of-theart methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 85, "endOffset": 118}, {"referenceID": 57, "context": "Figure 4 shows the results of this combination compared with state-of-theart methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 85, "endOffset": 118}, {"referenceID": 18, "context": "Figure 4 shows the results of this combination compared with state-of-theart methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 85, "endOffset": 118}, {"referenceID": 14, "context": "Figure 4 shows the results of this combination compared with state-of-theart methods [9, 5, 14, 47, 13, 59, 1, 20, 16].", "startOffset": 85, "endOffset": 118}, {"referenceID": 7, "context": "33% 5, which is achieved by [9].", "startOffset": 28, "endOffset": 31}, {"referenceID": 26, "context": "53%, cropped) [28].", "startOffset": 14, "endOffset": 18}, {"referenceID": 7, "context": "Here, we emphasize that the centers of patches, instead of the accurate and dense facial landmarks like [9], are utilized to extract multi-scale features in our method.", "startOffset": 104, "endOffset": 107}, {"referenceID": 49, "context": "5In fact, [51] and [53] have achieved higher accuracies 97.", "startOffset": 10, "endOffset": 14}, {"referenceID": 51, "context": "5In fact, [51] and [53] have achieved higher accuracies 97.", "startOffset": 19, "endOffset": 23}, {"referenceID": 37, "context": "There is an implicit belief among many psychologists and computer scientists that human face verification abilities are currently beyond existing computer-based face verification algorithms [39].", "startOffset": 190, "endOffset": 194}, {"referenceID": 0, "context": "By contrast, there have already been a number of papers comparing human and computer-based face verification performance [2, 54, 40, 41, 38, 8].", "startOffset": 121, "endOffset": 143}, {"referenceID": 52, "context": "By contrast, there have already been a number of papers comparing human and computer-based face verification performance [2, 54, 40, 41, 38, 8].", "startOffset": 121, "endOffset": 143}, {"referenceID": 38, "context": "By contrast, there have already been a number of papers comparing human and computer-based face verification performance [2, 54, 40, 41, 38, 8].", "startOffset": 121, "endOffset": 143}, {"referenceID": 39, "context": "By contrast, there have already been a number of papers comparing human and computer-based face verification performance [2, 54, 40, 41, 38, 8].", "startOffset": 121, "endOffset": 143}, {"referenceID": 36, "context": "By contrast, there have already been a number of papers comparing human and computer-based face verification performance [2, 54, 40, 41, 38, 8].", "startOffset": 121, "endOffset": 143}, {"referenceID": 6, "context": "By contrast, there have already been a number of papers comparing human and computer-based face verification performance [2, 54, 40, 41, 38, 8].", "startOffset": 121, "endOffset": 143}, {"referenceID": 36, "context": "As pointed out by [38, 48], humans and computer-based algorithms have different strategies in face verification.", "startOffset": 18, "endOffset": 26}, {"referenceID": 46, "context": "As pointed out by [38, 48], humans and computer-based algorithms have different strategies in face verification.", "startOffset": 18, "endOffset": 26}, {"referenceID": 5, "context": "For example, Bruce [7] found human recognition memory for unfamiliar faces dropped substantially when there were changes in viewing parameters.", "startOffset": 19, "endOffset": 22}, {"referenceID": 26, "context": "It has also been examined in [28], where the human performance drops from 99.", "startOffset": 29, "endOffset": 33}], "year": 2014, "abstractText": "Face verification remains a challenging problem in very complex conditions with large variations such as pose, illumination, expression, and occlusions. This problem is exacerbated when we rely unrealistically on a single training data source, which is often insufficient to cover the intrinsically complex face variations. This paper proposes a principled multi-task learning approach based on Discriminative Gaussian Process Latent Variable Model, named GaussianFace, to enrich the diversity of training data. In comparison to existing methods, our model exploits additional data from multiple source-domains to improve the generalization performance of face verification in an unknown target-domain. Importantly, our model can adapt automatically to complex data distributions, and therefore can well capture complex face variations inherent in multiple sources. Extensive experiments demonstrate the effectiveness of the proposed model in learning from diverse data sources and generalize to unseen domain. Specifically, the accuracy of our algorithm achieves an impressive accuracy rate of 98.52% on the well-known and challenging Labeled Faces in the Wild (LFW) benchmark [23]. For the first time, the human-level performance in face verification (97.53%) [28] on LFW is surpassed.", "creator": "LaTeX with hyperref package"}}}