{"id": "1404.4032", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Apr-2014", "title": "Recovery of Coherent Data via Low-Rank Dictionary Pursuit", "abstract": "The recently established RPCA method provides us a convenient way to restore low-rank matrices from grossly corrupted observations. While elegant in theory and powerful in reality, RPCA may be not an ultimate solution to the low-rank matrix recovery problem. Indeed, its performance may not be perfect even when data are strictly low-rank. This is because conventional RPCA ignores the clustering structures of the data which are ubiquitous in modern applications. As the number of cluster grows, the coherence of data keeps increasing, and accordingly, the recovery performance of RPCA degrades. We show that the challenges raised by coherent data (i.e., the data with high coherence) could be alleviated by Low-Rank Representation (LRR), provided that the dictionary in LRR is configured appropriately. More precisely, we mathematically prove that if the dictionary itself is low-rank then LRR is immune to the coherence parameter which increases with the underlying cluster number. This provides an elementary principle for dealing with coherent data. Subsequently, we devise a practical algorithm to obtain proper dictionaries in unsupervised environments. Our extensive experiments on randomly generated matrices verify our claims.", "histories": [["v1", "Tue, 15 Apr 2014 19:35:15 GMT  (329kb)", "https://arxiv.org/abs/1404.4032v1", null], ["v2", "Wed, 16 Jul 2014 17:57:02 GMT  (454kb)", "http://arxiv.org/abs/1404.4032v2", null]], "reviews": [], "SUBJECTS": "stat.ME cs.IT cs.LG math.IT math.ST stat.TH", "authors": ["guangcan liu", "ping li 0001"], "accepted": true, "id": "1404.4032"}, "pdf": {"name": "1404.4032.pdf", "metadata": {"source": "CRF", "title": "Recovery of Coherent Data via Low-Rank Dictionary Pursuit", "authors": ["Guangcan Liu", "Ping Li"], "emails": ["guangcan.liu@rutgers.edu", "pingli@stat.rutgers.edu"], "sections": [{"heading": null, "text": "ar Xiv: 140 4.40 32v2 [st at.M E] 16 Ju"}, {"heading": "1. Introduction", "text": "In the presence of the large errors produced by the large and small countries of the world, it is very important to develop new statistical tools for the analysis and dimensioning of data. A variety of methods have been proposed and researched in the literature over several decades, e.g., (Cande), (Cande), (Cande) and (Law), which deal with new statistical structures of the PCA. (Gnanadesikan and Chain Ring, 1972; Gross, 2011; la Torre and Kanade, 2005; Liu et al, 2013; Gnanadesikan and Chain Ring, 2005; Gnanadesikan and Chain Ring, 1972; Gross, 2011; la Torre et al, 2005."}, {"heading": "2. Summary of Main Notations", "text": "Capital letters such as M are used to represent matrices, and accordingly [M] ij denotes its (i, j) th entry; the letters U, V, and their variants (supplements, subscriptions, etc.) are reserved for left singular vectors, right singular vectors, and support sets; projection onto column space U (resp. V) is slightly used to denote the linear space occupied by columns U (resp. V), i.e. column space (resp. row space); projection onto column space U is used by PU (M) = UUTM, and similarly for row space PV (M) = MV V V V V T, i.e. column space (resp. row space); we also abuse notation to denote the linear space of the matrices supported by the columns."}, {"heading": "3. On the Recovery of Coherent Data", "text": "In this section, we will first examine the physical regime that produces coherent data, and then discuss the problem of recovering coherent data from corrupt observations, and provide some basic principles and an algorithm to solve the problem."}, {"heading": "3.1 Coherence Parameters and Their Properties", "text": "Note that the ranking function cannot fully capture all the characteristics of L0, and therefore it is actually necessary to define some quantities to measure the effects of different extrastructures (beyond minor structures), such as the cluster structure shown in Figure 1. The coherence parameters defined in (Cande und Recht, 2009; Cande et al., 2011) are excellent examples of such quantities."}, {"heading": "3.1.1 \u00b51 and \u00b52", "text": "For a m \u00b7 n matrix L0 with rank r0 and SVD L0 = U0\u04450V T0, some of its important properties can be characterized by two coherence parameters called \u00b51 and \u00b52. The first coherence parameter, 1 \u2264 \u00b51 \u2264 m, which characterizes the slit space identified by U0, is called \u00b51 (L0) = mr0 max 1 \u2264 i \u2264 m \u0445 UT0 ei \u043222, (3,4) 3. In this paper, SVD always refers to thin SVD. For a rank-r matrix M \u0445Rm \u00d7 n, its SVD is in the form UM\u00c4MV T M, with UM \u0394r m \u00d7 r, \u0432M \u0432Rr \u00d7 r and VM \u0432Rn \u00d7 r.where ei denotes the ith standard basis. The second coherence parameter, 1 \u2264 2 \u2264 n, which characterizes the time space identified by V0 \u00b5s, is defined as coherence."}, {"heading": "3.1.2 \u00b52-phenomenon", "text": "In this section we will further show that the widely existing cluster structure regards the coherence parameters of 0 (L0) = n (L0), \u00b52 (L0), \u00b53 (L0)} and cr > 1 (L0) as a numerical constant. Thus, RPCA will be less successful if the coherence parameters are substantially larger: the success condition (3.6) is narrowed when \u00b5 (L0) becomes large. As an extreme example, we will consider the case where the latent matrix L0 is present in only one column and zero everywhere else. Such a matrix produces \u00b52 (L0) = n (n), and thus the success condition (3.6) is ineffective. In this subsection, we will further show that the widely existing cluster structure can increase the coherence parameters and accordingly the gradations of the performance of rooms."}, {"heading": "3.2 Avoiding \u00b52 by LRR", "text": "However, it is usually difficult, if not impossible, to know in advance what kind of additional structures actually exist and what models are appropriate to use. Even if the modalities of the additional structure are known, it is much easier to develop an approach that can avoid the second coherence, e.g. the mixing of several sub-spaces shown in Figure 1, such a strategy still has to overcome some difficult problems, e.g. the estimation of the cluster number. In sharp contrast, it is much easier to develop an approach that can avoid the second coherence. Unfortunately, as explained in (Cande) s and Recht, 2009, it is necessary."}, {"heading": "3.3 An Unsupervised Algorithm for Matrix Recovery", "text": "In order to deal clearly with the data, Theorem 1 proposes that, ideally, the derivatives matrix A in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of data in relation to the collection of"}, {"heading": "4. Proof of Theorem 1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Settings and Some Basic Lemmas", "text": "The same as in RPCA (Cande, s et al., 2011), we assume that the locations of the corrupt entries are selected uniformly at random. In detail, we work with the Bernoulli model. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "4.2 Critical Lemmas", "text": "First of all, we want to prove that the sparse matrix S0 is not in the column space of the dictionary A. < p > p > p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p (1) p) p (1) p) p (1) p) p (1) p (1) p) p (1) p) p (1) p) p (1) p (1) p) p (1) p) p (1) p) p (1) p (1) p) p (1) p (1) p) p (1) p (1) p) p (1) p) p) p (1) p) p (1) p) p) p (1) p) p) p (1) p) p) p) p (1) p) p) p) p (1) p) p) p) p) p) p (1 (1) p) p) p (1) p) p) p) p) p (1 p) p) p) p (1 p) p) p) p) p (1 p) p) p) p (1 p) p) p) p (1 p) p) p) p) p (1 p) p) p) p (1 p) p) p (1 p) p) p) p (1 p) p) p p) p) p (1 p) p) p) p) p (1 p p) p) p p p p p) p (1 p p) p) p) p (1 p) p) p p p) p p p) p p p p (1 p) p (1 p) p) p p) p) p p p) p p p p p) p p (1 p (1 p) p) p) p) p p p) p p p p) p p p p p) p p p p p p p) p p p p p p p p) p p p p p p (1 p) p"}, {"heading": "4.3 Dual Conditions", "text": "It remains to be noted that theorem 1 consists of two steps: 1. Dual Conditions: Determine the sufficient conditions for (Z = A + L0, S = S0) to be the unique optimal solution to the LRR problem (1,3). 2. Dual Certificates: Show that the dual conditions can be met, that is, construct the dual certificates. Then (A + L0, S0) is the unique optimal solution for (1,3) if there is a matrix F that adheres to (a) UV T. (U0) supply PUA (U0) = U0 and UA = {0}. Then (A + L0, S0) is the unique optimal solution for (1,3) if there is a matrix F that obeys (a) UV = sign (S0) + F) + F), (b) PIS (F) = 0, (C) PIS)."}, {"heading": "4.4 Dual Certificates", "text": "To construct a matrix that meets the double conditions listed in Lemma 7, we need the reversal of PUAPAC (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PUAPAC) (PAPUAC) (PAPUA) (PAPUA) (PAPUA) (PAPUAC) (PAPUA) (PAPUAC) (PAPUAC) (PAPUAC) (PAPUA) (PAPUAC) (PAPUA) (PAPUA) (PAPUA) (PAPUAC) (PAPUA) (PAPUA) (PAPUA (PUAC) (PAPUA) (PUAC (PUAC) (PAPUA) (PUAC (PUAC) (PUA) (PUAC (PUAC) (PAPUAC) (PUAC (PUAC) (PUA) (PUAC (PAPUAC) (PUAC) (PUA) (PUAC (PUAC) (PUAC (PUAC) (PUA) (PUAC (PUAC) (PUAC) (PUAC (PUAC) (PUAC (PUAC) (PUAC (PUAC) (PUAC) (PUAC (PUAC) (PUAC) (PUAC (PUAC) (PUAC (PUAC) (PUAC (PUAC) (PUAPAC) (PUAPUAC (PUAC) (PUAC) (PUAC (PUAC) (PUAC) (PUAPAC) (PUAPAC (PUAC (PUAC) (PUAC (PUAC) (PUAC) (PUAPAC) (PUAPAC (PUAC) (PUAPAC ("}, {"heading": "5. Experiments", "text": "Our main finding, Theorem 1, is useful in both supervised and unsupervised environments. To make a fair comparison, we will focus in the experiments of this work on demonstrating the superiority of our unsupervised algorithm 1 over the RPCA."}, {"heading": "5.1 Results on Randomly Generated Matrices", "text": "First, we test the effectiveness of our algorithm 1 using randomly generated matrices. We generate a collection of 200 x 1000 data matrices according to the model of X = P\u0442 (L0) + P\u0442 (S0): \"is a randomly selected support set;\" L0 \"is created by selecting 200 data points from each of 5 randomly generated sub-spaces, and its values are normalized so that\" L0 \"= 1;\" S0 \"consists of random values of Bernoulli \u00b1 1. The dimension of each sub-space varies from 1 to 20 with step size 1, and therefore the rank of\" L0 \"varies between 5 and 1005. This detail also suggests that\" \u03bb = 1 / \u221a n1 \"cannot be the\" best \"choice, e.g. with step size 5. The fraction | (mn) in each sub-space varies from 1 to 20 with step size 1 and 50% with step size 2.5%."}, {"heading": "5.2 Results on Corrupted Motion Sequences", "text": "We are now experimenting with 11 additional sequences attached to the Hopkins155 database (Tron and Vidal, 2007), in which about 10% of the entries in the data matrix of the trajectories are not observed (i.e. missed) due to visual occlusion. We replace each missing entry with a number of Bernoulli \u00b1 1, resulting in a collection of corrupt trajectory matrices to evaluate the effectiveness of matrix recovery algorithms. We are performing subspace cluster procedures on both the corrupted trajectory matrices and the restored versions, using cluster error rates generated by existing subspace cluster methods as valuation metrics. We consider three state-of-the-art subspace cluster methods: Shape Interaction Matrix (SIM) (Costeira and Kanade, 1998), the cluster error rates of existing subspace cluster matrices as corrupt methods."}, {"heading": "6. Conclusion and Future Work", "text": "In this paper, we investigated the problem of the unbundling of low-weighted (L0) and low-weighted (S0) components in a given data matrix. Whenever the low-weighted component has some additional structures, the state-of-the-art RPCA method may fail, even if L0 is strictly low. As a typical example, we consider the case where there is a mixture of several subspaces underlying L0. As the subspace (i.e. cluster) grows large, the second coherence parameter will increase, thus worsening the performance of the RPCA. To overcome the challenges arising from coherent data, one must theoretically grasp the additional structures that produce high coherence. However, such a strategy suffices several practical problems and is therefore impracticable. In sharp contrast, it is much easier to solve the problem by LRRR: If the dictatorial matrix A meets certain conditions, then A is low and UD large."}, {"heading": "Acknowledgement", "text": "Guangcan Liu is a postdoctoral fellow supported by nsf-dms0808864, nsf-ses1131848, nsf-eager1249316, AFOSR-FA9550-13-1-0137 and ONR-N00014-13-1-0764. Ping Li is also partially supported by nsf-iii1360971 and nsf-bigdata1419210."}, {"heading": "Appendix A. List of Notations", "text": "(\u00b7) + Moore-Penrose pseudo-inverse matrix. \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "Appendix B. Why Does \u00b52 Increase with the Cluster Number?", "text": "It is the first and second, which is not sufficient to interpret the phenomenon that the coherence parameters with the cluster number L0. Hence, it is necessary to establish a more precise rule to characterize the coherence parameters. Through extensive experiments, we find that the first and second coherence parameters actually follow the known Zipf law. It is more precise when the datapoints (which form the column vectors of L0) are uniformly sampled."}, {"heading": "Appendix C. Proof of Theorem 2", "text": "The proof that (Z), (Z), (Z), (Z), (Z), (S), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), (Z), ((Z), (Z), (Z), (Z"}, {"heading": "Appendix D. Optimization Procedure", "text": "In this thesis, we use the exact ALM method to solve the optimization problem (1,3). First, we convert (1,3) to the following equivalent problem: min Z, S, J, J, Y and S, s.t. X = AZ + S, Z = J.This problem can be solved by the ALM method, which minimizes the following advanced Lagrange function: female + female + < Y, X \u2212 AZ \u2212 S > + < W, Z \u2212 J > + \u03b82 (female + female).Algorithm 2 \u2212 F) in relation to J, Z and S, each by specifying the other variables and then updating the Lagrange \u2212 S > + < W, Z \u2212 J > + \u03b82 (female).Algorithm 2 summarizes the entire procedure of the optimization process."}], "references": [{"title": "Synthetic aperture radar imaging and motion estimation via robust principle component analysis", "author": ["Liliana Borcea", "Thomas Callaghan", "George Papanicolaou"], "venue": "Arxiv,", "citeRegEx": "Borcea et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Borcea et al\\.", "year": 2012}, {"title": "Matrix completion with noise", "author": ["Emmanuel Cand\u00e8s", "Yaniv Plan"], "venue": "In IEEE Proceeding,", "citeRegEx": "Cand\u00e8s and Plan.,? \\Q2010\\E", "shortCiteRegEx": "Cand\u00e8s and Plan.", "year": 2010}, {"title": "Exact matrix completion via convex optimization", "author": ["Emmanuel Cand\u00e8s", "Benjamin Recht"], "venue": "Foundations of Computational Mathematics,", "citeRegEx": "Cand\u00e8s and Recht.,? \\Q2009\\E", "shortCiteRegEx": "Cand\u00e8s and Recht.", "year": 2009}, {"title": "Robust principal component analysis", "author": ["Emmanuel J. Cand\u00e8s", "Xiaodong Li", "Yi Ma", "John Wright"], "venue": "Journal of the ACM,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2011}, {"title": "A multibody factorization method for independently moving objects", "author": ["Joao Costeira", "Takeo Kanade"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Costeira and Kanade.,? \\Q1998\\E", "shortCiteRegEx": "Costeira and Kanade.", "year": 1998}, {"title": "Sparse subspace clustering", "author": ["E. Elhamifar", "R. Vidal"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Elhamifar and Vidal.,? \\Q2009\\E", "shortCiteRegEx": "Elhamifar and Vidal.", "year": 2009}, {"title": "Matrix rank minimization with applications", "author": ["M. Fazel"], "venue": "PhD thesis,", "citeRegEx": "Fazel.,? \\Q2002\\E", "shortCiteRegEx": "Fazel.", "year": 2002}, {"title": "Random sample consensus: A paradigm for model fitting with applications to image analysis and automated cartography", "author": ["Martin Fischler", "Robert Bolles"], "venue": "Communications of the ACM,", "citeRegEx": "Fischler and Bolles.,? \\Q1981\\E", "shortCiteRegEx": "Fischler and Bolles.", "year": 1981}, {"title": "Robust estimates, residuals, and outlier detection with multiresponse data", "author": ["R. Gnanadesikan", "J.R. Kettenring"], "venue": null, "citeRegEx": "Gnanadesikan and Kettenring.,? \\Q1972\\E", "shortCiteRegEx": "Gnanadesikan and Kettenring.", "year": 1972}, {"title": "Recovering low-rank matrices from few coefficients in any basis", "author": ["D. Gross"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Gross.,? \\Q2011\\E", "shortCiteRegEx": "Gross.", "year": 2011}, {"title": "Robust l1 norm factorization in the presence of outliers and missing data by alternative convex programming", "author": ["Qifa Ke", "Takeo Kanade"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Ke and Kanade.,? \\Q2005\\E", "shortCiteRegEx": "Ke and Kanade.", "year": 2005}, {"title": "A framework for robust subspace learning", "author": ["Fernando De la Torre", "Michael J. Black"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Torre and Black.,? \\Q2003\\E", "shortCiteRegEx": "Torre and Black.", "year": 2003}, {"title": "Unsupervised object segmentation with a hybrid graph model (hgm)", "author": ["Guangcan Liu", "Zhouchen Lin", "Xiaoou Tang", "Yong Yu"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Robust subspace segmentation by low-rank representation", "author": ["Guangcan Liu", "Zhouchen Lin", "Yong Yu"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Exact subspace segmentation and outlier detection by low-rank representation", "author": ["Guangcan Liu", "Huan Xu", "Shuicheng Yan"], "venue": "Journal of Machine Learning Research - Proceedings Track,", "citeRegEx": "Liu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Robust recovery of subspace structures by low-rank representation", "author": ["Guangcan Liu", "Zhouchen Lin", "Shuicheng Yan", "Ju Sun", "Yong Yu", "Yi Ma"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Liu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2013}, {"title": "Spectral regularization algorithms for learning large incomplete matrices", "author": ["Rahul Mazumder", "Trevor Hastie", "Robert Tibshirani"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Mazumder et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mazumder et al\\.", "year": 2010}, {"title": "Low-rank and sparse matrix decomposition for accelerated dynamic mri with separation of background and dynamic components", "author": ["Ricardo Otazo", "Emmanuel Cand\u00e8s", "Daniel K. Sodickson"], "venue": "Arxiv,", "citeRegEx": "Otazo et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Otazo et al\\.", "year": 2012}, {"title": "Rasl: Robust alignment by sparse and low-rank decomposition for linearly correlated images", "author": ["YiGang Peng", "Arvind Ganesh", "John Wright", "Wenli Xu", "Yi Ma"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Peng et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Peng et al\\.", "year": 2012}, {"title": "Convex Analysis", "author": ["R. Rockafellar"], "venue": null, "citeRegEx": "Rockafellar.,? \\Q1970\\E", "shortCiteRegEx": "Rockafellar.", "year": 1970}, {"title": "Random vectors in the isotropic position", "author": ["M. Rudelson"], "venue": "Journal of Functional Analysis,", "citeRegEx": "Rudelson.,? \\Q1999\\E", "shortCiteRegEx": "Rudelson.", "year": 1999}, {"title": "Generalization error bounds for collaborative prediction with low-rank matrices", "author": ["Nathan Srebro", "Tommi Jaakkola"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Srebro and Jaakkola.,? \\Q2005\\E", "shortCiteRegEx": "Srebro and Jaakkola.", "year": 2005}, {"title": "A benchmark for the comparison of 3-d motion segmentation algorithms", "author": ["Roberto Tron", "Rene Vidal"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Tron and Vidal.,? \\Q2007\\E", "shortCiteRegEx": "Tron and Vidal.", "year": 2007}, {"title": "Cofi rank maximum margin matrix factorization for collaborative ranking", "author": ["Markus Weimer", "Alexandros Karatzoglou", "Quoc V. Le", "Alex J. Smola"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Weimer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Weimer et al\\.", "year": 2007}, {"title": "Robust pca via outlier pursuit", "author": ["Huan Xu", "Constantine Caramanis", "Sujay Sanghavi"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Xu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2010}, {"title": "Outlier-robust pca: The highdimensional case", "author": ["Huan Xu", "Constantine Caramanis", "Shie Mannor"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Xu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2013}, {"title": "Tilt: Transform invariant low-rank textures", "author": ["Zhengdong Zhang", "Arvind Ganesh", "Xiao Liang", "Yi Ma"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Zhang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 3, "context": "Abstract The recently established RPCA (Cand\u00e8s et al., 2011) method provides us a convenient way to restore low-rank matrices from grossly corrupted observations.", "startOffset": 39, "endOffset": 60}, {"referenceID": 15, "context": "We show that it is possible for Low-Rank Representation (LRR) (Liu et al., 2013) to overcome the challenges raised by coherent data, as long as the dictionary in LRR is configured appropriately.", "startOffset": 62, "endOffset": 80}, {"referenceID": 1, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 2, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 3, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 7, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 8, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 9, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 10, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 25, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 15, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 16, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 24, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010).", "startOffset": 2, "endOffset": 296}, {"referenceID": 1, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Fischler and Bolles, 1981; Gnanadesikan and Kettenring, 1972; Gross, 2011; Ke and Kanade, 2005; la Torre and Black, 2003; Xu et al., 2013; Liu et al., 2013; Mazumder et al., 2010; Soltanolkotabi et al., 2013; Xu et al., 2010). One of the most exciting methods is probably the so-called RPCA (Robust Principal Component Analysis) method by Cand\u00e8s et al. (2011), built upon the exploration of the following low-rank matrix recovery problem:", "startOffset": 3, "endOffset": 431}, {"referenceID": 6, "context": "where \u2016 \u00b7 \u2016\u2217 is the nuclear norm (Fazel, 2002) of a matrix, \u2016 \u00b7 \u20161 denotes the l1 norm of a matrix seen as a long vector, and \u03bb > 0 is a parameter.", "startOffset": 33, "endOffset": 46}, {"referenceID": 26, "context": ", image processing (Zhang et al., 2012), computer vision (Peng et al.", "startOffset": 19, "endOffset": 39}, {"referenceID": 18, "context": ", 2012), computer vision (Peng et al., 2012), radar imaging (Borcea et al.", "startOffset": 25, "endOffset": 44}, {"referenceID": 0, "context": ", 2012), radar imaging (Borcea et al., 2012), magnetic resonance imaging (Otazo et al.", "startOffset": 23, "endOffset": 44}, {"referenceID": 17, "context": ", 2012), magnetic resonance imaging (Otazo et al., 2012), etc.", "startOffset": 36, "endOffset": 56}, {"referenceID": 4, "context": "Figure 1 demonstrates a typical example of extra structures; that is, the clustering structure which is ubiquitous in modern applications (Costeira and Kanade, 1998; Elhamifar and Vidal, 2009; Soltanolkotabi et al., 2013).", "startOffset": 138, "endOffset": 221}, {"referenceID": 5, "context": "Figure 1 demonstrates a typical example of extra structures; that is, the clustering structure which is ubiquitous in modern applications (Costeira and Kanade, 1998; Elhamifar and Vidal, 2009; Soltanolkotabi et al., 2013).", "startOffset": 138, "endOffset": 221}, {"referenceID": 3, "context": "Nevertheless, as explained in (Cand\u00e8s et al., 2011; Cand\u00e8s and Recht, 2009), the coherence parameters are indeed necessary for matrix recovery (if there is no additional condition available).", "startOffset": 30, "endOffset": 75}, {"referenceID": 2, "context": "Nevertheless, as explained in (Cand\u00e8s et al., 2011; Cand\u00e8s and Recht, 2009), the coherence parameters are indeed necessary for matrix recovery (if there is no additional condition available).", "startOffset": 30, "endOffset": 75}, {"referenceID": 15, "context": "Our study is based on the following convex program termed Low-Rank Representation (LRR) (Liu et al., 2013): min Z,S \u2016Z\u2016\u2217 + \u03bb\u2016S\u20161, s.", "startOffset": 88, "endOffset": 106}, {"referenceID": 1, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Xu et al., 2010; Liu et al., 2012).", "startOffset": 2, "endOffset": 105}, {"referenceID": 2, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Xu et al., 2010; Liu et al., 2012).", "startOffset": 2, "endOffset": 105}, {"referenceID": 3, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Xu et al., 2010; Liu et al., 2012).", "startOffset": 2, "endOffset": 105}, {"referenceID": 24, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Xu et al., 2010; Liu et al., 2012).", "startOffset": 2, "endOffset": 105}, {"referenceID": 14, "context": ", (Cand\u00e8s and Plan, 2010; Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Xu et al., 2010; Liu et al., 2012).", "startOffset": 2, "endOffset": 105}, {"referenceID": 15, "context": "\u22c4 This paper provides insights regarding the LRR model proposed by (Liu et al., 2013).", "startOffset": 67, "endOffset": 85}, {"referenceID": 21, "context": ", (Srebro and Jaakkola, 2005; Weimer et al., 2007).", "startOffset": 2, "endOffset": 50}, {"referenceID": 23, "context": ", (Srebro and Jaakkola, 2005; Weimer et al., 2007).", "startOffset": 2, "endOffset": 50}, {"referenceID": 2, "context": "The coherence parameters defined in (Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011) are excellent exemplars of such quantities.", "startOffset": 36, "endOffset": 81}, {"referenceID": 3, "context": "The coherence parameters defined in (Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011) are excellent exemplars of such quantities.", "startOffset": 36, "endOffset": 81}, {"referenceID": 3, "context": "In (Cand\u00e8s et al., 2011), another coherence parameter, called as the third coherence parameter and denoted as 1 \u2264 \u03bc3 \u2264 mn, is also introduced: \u03bc3(L0) = mn r0 (\u2016U0V T 0 \u2016\u221e) = mn r0 max i,j (|\u3008U 0 ei, V T 0 ej\u3009|).", "startOffset": 3, "endOffset": 24}, {"referenceID": 3, "context": "We include it just for the sake of consistence with (Cand\u00e8s et al., 2011).", "startOffset": 52, "endOffset": 73}, {"referenceID": 3, "context": "The analysis in (Cand\u00e8s et al., 2011) merges the above three parameters into a single one: \u03bc(L0) = max{\u03bc1(L0), \u03bc2(L0), \u03bc3(L0)}.", "startOffset": 16, "endOffset": 37}, {"referenceID": 3, "context": "2 \u03bc2-phenomenon Cand\u00e8s et al. (2011) have proven that the success condition (regarding L0) of RPCA is rank (L0) \u2264 n2 cr\u03bc(L0)(log n1) , (3.", "startOffset": 16, "endOffset": 37}, {"referenceID": 4, "context": ", face, texture and motion (Costeira and Kanade, 1998; Elhamifar and Vidal, 2009; Liu et al., 2010a).", "startOffset": 27, "endOffset": 100}, {"referenceID": 5, "context": ", face, texture and motion (Costeira and Kanade, 1998; Elhamifar and Vidal, 2009; Liu et al., 2010a).", "startOffset": 27, "endOffset": 100}, {"referenceID": 2, "context": "Unfortunately, as explained in (Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Liu et al., 2012), the coherence parameters are necessary for identifying accurately the success conditions of matrix recovery.", "startOffset": 31, "endOffset": 94}, {"referenceID": 3, "context": "Unfortunately, as explained in (Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Liu et al., 2012), the coherence parameters are necessary for identifying accurately the success conditions of matrix recovery.", "startOffset": 31, "endOffset": 94}, {"referenceID": 14, "context": "Unfortunately, as explained in (Cand\u00e8s and Recht, 2009; Cand\u00e8s et al., 2011; Liu et al., 2012), the coherence parameters are necessary for identifying accurately the success conditions of matrix recovery.", "startOffset": 31, "endOffset": 94}, {"referenceID": 15, "context": "The reason is that, as has been explored by (Liu et al., 2013), the complexity of solving the LRR problem (1.", "startOffset": 44, "endOffset": 62}, {"referenceID": 3, "context": "1 Settings and Some Basic Lemmas The same as in RPCA (Cand\u00e8s et al., 2011), we assume that the locations of the corrupted entries are selected uniformly at random.", "startOffset": 53, "endOffset": 74}, {"referenceID": 3, "context": "For general sign matrices, the same as in RPCA (Cand\u00e8s et al., 2011), our Theorem 1 can still be proved by globally placing an elimination theorem and a derandomization scheme.", "startOffset": 47, "endOffset": 68}, {"referenceID": 3, "context": "Provided that A \u2208 R is fairly low-rank, the analysis in (Cand\u00e8s et al., 2011) gives that \u2016PTAP\u03a9\u2016 \u2264 \u221a", "startOffset": 56, "endOffset": 77}, {"referenceID": 3, "context": "Following the techniques in (Cand\u00e8s et al., 2011), we have the following lemma to bound the operator norm of PUAP\u03a9.", "startOffset": 28, "endOffset": 49}, {"referenceID": 20, "context": "Then by using the results in (Rudelson, 1999) and following the proof procedure of (Cand\u00e8s and Recht, 2009), we have that", "startOffset": 29, "endOffset": 45}, {"referenceID": 2, "context": "Then by using the results in (Rudelson, 1999) and following the proof procedure of (Cand\u00e8s and Recht, 2009), we have that", "startOffset": 83, "endOffset": 107}, {"referenceID": 19, "context": "Proof By standard convexity arguments (Rockafellar, 1970), (AL0, S0) is an optimal solution to (1.", "startOffset": 38, "endOffset": 57}, {"referenceID": 15, "context": "1 of (Liu et al., 2013) gives that \u2016AL0 + \u22061\u2016\u2217 > \u2016AL0\u2016\u2217 strictly holds unless \u22061 = 0.", "startOffset": 5, "endOffset": 23}, {"referenceID": 15, "context": "3 of (Liu et al., 2013).", "startOffset": 5, "endOffset": 23}, {"referenceID": 22, "context": "2 Results on Corrupted Motion Sequences We now experiment with 11 additional sequences attached to the Hopkins155 (Tron and Vidal, 2007) database.", "startOffset": 114, "endOffset": 136}, {"referenceID": 4, "context": "We consider three state-of-the-art subspace clustering methods: Shape Interaction Matrix (SIM) (Costeira and Kanade, 1998), Low-Rank Representation with A = X (Liu et al.", "startOffset": 95, "endOffset": 122}, {"referenceID": 5, "context": ", 2010b) (which is referred to as \u201cLRRx\u201d) and Sparse Subspace Clustering (SSC) (Elhamifar and Vidal, 2009).", "startOffset": 79, "endOffset": 106}, {"referenceID": 2, "context": "1 Zipf\u2019s Law When the data points are sampled from a low-rank subspace uniformly at random, it has been proven by (Cand\u00e8s and Recht, 2009) that the first and second coherence parameters are bounded.", "startOffset": 114, "endOffset": 138}, {"referenceID": 2, "context": "11) can also induce the boundedness property proved by (Cand\u00e8s and Recht, 2009).", "startOffset": 55, "endOffset": 79}, {"referenceID": 4, "context": "However, this is unlikely for \u03bc2(L0) to happen, as it is provable that the row projector V0V T 0 , which is also known as Shape Interaction Matrix (SIM) in subspace clustering, measures the subspace membership of the data points (Costeira and Kanade, 1998; Liu et al., 2013).", "startOffset": 229, "endOffset": 274}, {"referenceID": 15, "context": "However, this is unlikely for \u03bc2(L0) to happen, as it is provable that the row projector V0V T 0 , which is also known as Shape Interaction Matrix (SIM) in subspace clustering, measures the subspace membership of the data points (Costeira and Kanade, 1998; Liu et al., 2013).", "startOffset": 229, "endOffset": 274}], "year": 2014, "abstractText": "The recently established RPCA (Cand\u00e8s et al., 2011) method provides us a convenient way to restore low-rank matrices from grossly corrupted observations. While elegant in theory and powerful in reality, RPCA may be not an ultimate solution to the low-rank matrix recovery problem. Indeed, its performance may not be perfect even when the data is strictly low-rank. This is because RPCA prefers incoherent data, which, however, could be inconsistent with some natural structures of data. As a typical example, consider the clustering structure which is ubiquitous in modern applications. As the number of cluster grows, the coherence parameters of data keep increasing, and accordingly, the recovery performance of RPCA degrades. We show that it is possible for Low-Rank Representation (LRR) (Liu et al., 2013) to overcome the challenges raised by coherent data, as long as the dictionary in LRR is configured appropriately. Namely, we mathematically prove that if the dictionary itself is low-rank then LRR can avoid the coherence parameters which have potential to be large. This provides an elementary principle for dealing with coherent data and naturally leads to a practical algorithm for obtaining proper dictionaries in unsupervised environments. Our extensive experiments on randomly generated matrices and real motion sequences show promising results.", "creator": "LaTeX with hyperref package"}}}