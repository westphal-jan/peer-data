{"id": "1404.4960", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Apr-2014", "title": "Agent Behavior Prediction and Its Generalization Analysis", "abstract": "Machine learning algorithms have been applied to predict agent behaviors in real-world dynamic systems, such as advertiser behaviors in sponsored search and worker behaviors in crowdsourcing. The behavior data in these systems are generated by live agents: once the systems change due to the adoption of the prediction models learnt from the behavior data, agents will observe and respond to these changes by changing their own behaviors accordingly. As a result, the behavior data will evolve and will not be identically and independently distributed, posing great challenges to the theoretical analysis on the machine learning algorithms for behavior prediction. To tackle this challenge, in this paper, we propose to use Markov Chain in Random Environments (MCRE) to describe the behavior data, and perform generalization analysis of the machine learning algorithms on its basis. Since the one-step transition probability matrix of MCRE depends on both previous states and the random environment, conventional techniques for generalization analysis cannot be directly applied. To address this issue, we propose a novel technique that transforms the original MCRE into a higher-dimensional time-homogeneous Markov chain. The new Markov chain involves more variables but is more regular, and thus easier to deal with. We prove the convergence of the new Markov chain when time approaches infinity. Then we prove a generalization bound for the machine learning algorithms on the behavior data generated by the new Markov chain, which depends on both the Markovian parameters and the covering number of the function class compounded by the loss function for behavior prediction and the behavior prediction model. To the best of our knowledge, this is the first work that performs the generalization analysis on data generated by complex processes in real-world dynamic systems.", "histories": [["v1", "Sat, 19 Apr 2014 14:57:54 GMT  (25kb)", "http://arxiv.org/abs/1404.4960v1", null], ["v2", "Fri, 11 Jul 2014 06:30:18 GMT  (25kb)", "http://arxiv.org/abs/1404.4960v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["fei tian", "haifang li", "wei chen", "tao qin", "enhong chen", "tie-yan liu"], "accepted": true, "id": "1404.4960"}, "pdf": {"name": "1404.4960.pdf", "metadata": {"source": "CRF", "title": "Agent Behavior Prediction and Its Generalization Analysis", "authors": ["Fei Tian", "Haifang Li", "Wei Chen", "Tao Qin", "Enhong Chen", "Tie-Yan Liu"], "emails": ["tianfei@mail.ustc.edu.cn", "lihaifang@amss.ac.cn", "wche@microsoft.com", "taoqin@microsoft.com", "cheneh@ustc.edu.cn", "tyliu@microsoft.com"], "sections": [{"heading": null, "text": "The result is that behavioural data in these systems are generated by living agents: as soon as systems change due to the adoption of predictive models based on behavioural data, agents will observe these changes and respond by changing their own behaviours accordingly. As a result, behavioural data evolve and are not distributed in an identical and independent manner, posing major challenges for theoretical analysis of machine learning algorithms for predicting behaviour. To address this challenge, we propose to use Markov Chain in Random Environments (MCRE) to describe the behavioural data and perform generalisation analysis of machine learning algorithms for predicting."}, {"heading": "1 Introduction", "text": "In this Internet age, more and more data is generated by self-serving agents in interactive systems. For example, advertisers in sponsored search generate a large volume of bidding log data in their daily contests with each other to induce search users to click their ads; in crowdsourcing, workers generate a lot of behavioral data when competing with other workers when it comes to getting tasks from employers, and when they perform the tasks assigned to them. In many real cases, including the above, there are three types of actors in the systems: platform, users and self-serving actors. Platform is the owner of the system that designs the mechanism of the system and takes care of its execution. Users reach the platform randomly, with their specific needs having to be met. Agents behave strategically to attract the attention of users in order to realize their own utilities. Platform is the owner of the system, which designs the mechanism of the system and takes care of its execution. Agents reach the platform randomly, whereby their specific needs must be met. Agents behave strategically to realize the attention of users in order to realize their own utilities. Taking into account both the needs of the users and the behavior of the platform, the agents \"behavior it is very important for the platform to understand the agents\" feedback to the agents \"behavior (the platform's behavior to the agents\" feedback to the agents)."}, {"heading": "1.1 Examples of ABP", "text": "Here we take sponsored seaerch systems as an example of illustration.In a sponsored search system, platform, users and agents correspond to the search engine, users and advertisers respectively. Advertiser behavior is the offer prices on their ads. When a user submits a query, the user will conduct a GSP auction (Edelman, Ostrovsky, and Schwarz 2005) among all advertisers who are looking for his ads according to the product of the offer price and the predicted click rate, and then the winning advertisers will click on their ads. The search engine will give advertisers feedback on their services (which we usually call key performance indicators, or KPIs for the numbers of impressions and clicks that represent the average advertisers, the average positions and the costs of their advertisers."}, {"heading": "1.2 Generalization Analysis for ABP", "text": "Because of its importance, ABP has been studied in many papers, including (Cary et al. 2007; Pin and Key. 2011; Zhou and Lukose. 2007; Xu et al. 2013; He et al. 2013), some of which (Xu et al. 2013; He et al. 2013) have used machine learning techniques and attempted to learn an agent behavioral model using empirical risk minimization (ERM) on the behavioral protocols. Empirical results have shown that these machine learning techniques can significantly exceed previous non-learning approaches. However, despite the experimental success, the question remains open whether the use of ERM algorithms in behavioral prediction is theoretically sound and whether a certain generalization of such algorithms can be guaranteed. As far as we know, the answers to the above questions are still unclear, mainly due to the complication of the corresponding theoretical analysis. As mentioned above, the behavioral data from self-interested agents is generated and the statistical dependence of both the 1994 and 1994 behavioral factors from the preceding behavioral factors in the general system."}, {"heading": "1.3 Related Work", "text": "There have been extensive game theoretical models for predicting advertisers \"bidding (Cary et al. 2007) (Chakrabarty, Zhou, and Lukose. 2007) (Zhou et al. 2013). These models generally assume that advertisers are perfectly rational and have full access to information, an assumption that goes far beyond reality and has therefore recently been applied to this task using machine learning methods (Cui et al. 2011) (Xu et al. 2013) (He et al. 2013), based on minimizing predictive losses on advertisers\" historical bidding data. For example, in (Xu et al. 2013) the authors propose models that describe different rationalities of advertisers and adjust the model parameters by learning from bidding data, which is most relevant to our work (He et al. 2013), in which a Markov bidding model is introduced and a linear prediction function for maximum likelihood of people learning from emotion is developed."}, {"heading": "1.4 Our Results", "text": "In order to analyze the ERM algorithms for predicting the behavior of agents, we propose a number of new techniques in this paper whose transition matrix varies in time (depending on the random environments), for example, the process of generating behavioral data. After the current auction, the advertiser will consider his / her KPIs, which depend both on the bids of all advertisers and on the random clicks of users. Based on the KPIs, the advertiser will determine how he / she places his / her own bid for the next auction round and for different KPI values, the conditional distribution of his / her bid in the next round will be different. In this sense, the sequence of advertiser bids can be considered as an MCRE.Second, considering that it is difficult to perform a generalization analysis on MCRE."}, {"heading": "2 Agent Behavior Prediction", "text": "In this section, we give a formal description of the Agent Behavior Prediction (ABP) problem. We first show that the process of generating the behavior of self-serving actors can be described by a Markov Chain in Random Environments (MCRE), and then formulate ABP as an optimization problem."}, {"heading": "2.1 Agent Behaviors: Markov Chain in Random Environments", "text": "The dynamic interactive systems mentioned in the introduction share some common characteristics. (1) The behaviors of an agent are essentially dependent on a finite number of his / her historical actions. (2) The behavior of an agent is only dependent on a finite number of his / her historical actions (i.i.d), for example, in sponsor search there are two aspects associated with users: requests from users and users click patterns on ad lists. (2) It is clear that requests can be regarded as i.i.d. random variables. Click patterns are defined in relation to all possible ad lists and they are also independent of agent behavior (which only determine the selected ranking behavior) and can be considered i.d. (3) The behavior change of an agent is mainly influenced by the feedback given by the platform. Since the feedback depends on the users who arrive at behavior changes in the system randomly, the behavior change is not governed by a constant rule, but by some random factors."}, {"heading": "2.2 Learning Agent Behavior Model", "text": "There are some related studies that use empirical risk minimization (ERM) to learn the behavioral model of the agent. Mathematically, given a training set that takes the behavior of the agents and the feedback they received in T rounds {(h1, b1); (h2, b2); (hT, bT)}, the goal is to learn a function f: HN \u00d7 BN that takes the behaviors and feedback in the current round as inputs and predicts the behavior in the next round. To this end, the empirical risk on the training set is minimized: min f: HN \u00d7 Tt = 1 l (f, bt); bt + 1), where l measures the loss between the predicted behavior and the real behavior in the training data. For example, l may be the 0 \u2212 1 loss of classification: l (f: t, ht) the classification function is probable for us."}, {"heading": "3 Generalization Bounds for ABP", "text": "In this section, we perform a generalization analysis of the ERM algorithms for predicting the behavior of agents. Our main result is presented in theorem (3.7). We prove the theorem in three steps: (1) construction of a new Markov chain of higher dimensionality but with more regular properties than the original MCRE; (2) proof of convergence of empirical loss with the expected loss if the data is generated by this new Markov chain; (3) proof of uniform convergence bound by further use of the techniques for covering numbers."}, {"heading": "3.1 Constructing a Higher-Dimensional Markov Chain", "text": "The difficulty of the analysis of the ERM algorithms, when the data are provided by an MCRE, is that it concerns a way in which distributional justice is concerned, which is what it is about, which is distributional justice, which is distributive justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is distributional justice, which is the distribution justice, which is distributional justice, which is distributional justice, which is"}, {"heading": "3.2 Convergence Bound", "text": "In this subsection we show that these results can be used to analyze the convergence rate of empirical risk for a specified prediction model. (hT, bT, bT + 1) = (z1, z2, zT) \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "3.3 Uniform Convergence Bound", "text": "In this section we have a uniform convergence, which is based on the coverage number, as it is in the following theory.Theorem f (1) Uniform Convergence Theorem (1).Let us measure F (1).Let us measure F (1).Let us leave F (1).Let us leave F (2).Let us leave F (2).Let us measure the totality of a functional class. Specifically, the coverage number is N (E).L F, L.F.F.F.F.F.F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\" \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".F\".F \".\".F\".F \".F\".F \".F\".F \".\".F\".F \"."}, {"heading": "4 Conclusion and Future Work", "text": "In this paper, we have examined the generalization capability of ERM algorithms for predicting agent behavior. In particular, we first develop a new technique that transforms MCRE into a higher-dimensional but more regular Markov chain, and then specify a uniform generalization boundary based on the new Markov chain. As for future work, we plan to investigate the common learning problem of the optimal mechanism of the platform and the optimal prediction model of agent behavior. Generalization analyses for these two cases will be even more difficult, and the corresponding results will have deeper implications for the introduction of machine learning into real-world interactive systems."}, {"heading": "5 Acknowledgement", "text": "We thank Di He for his valuable suggestions on the detailed correction method. Thanks to the anonymous reviewers of the AAAI for their comments to make the work more precise and clearer. This work is supported in part by grants from the National Science Foundation for Distinguished Young Scholars of China (Grant No. 61325010)."}], "references": [{"title": "P", "author": ["S. Bendavid", "N. Cesabianchi", "D. Haussler", "Long"], "venue": "M.", "citeRegEx": "Bendavid et al. 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "A", "author": ["M. Cary", "A. Das", "B. Edelman", "I. Giotis", "K. Heimerl", "Karlin"], "venue": "R.; Mathieu, C.; and Schwarz., M.", "citeRegEx": "Cary et al. 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "Budget constrained bidding in keyword auctions and online knapsack problems", "author": ["Chakrabarty", "Zhou", "Lukose"], "venue": "In WWW \u201907 Proceedings of the 16th international conference on World Wide Web. ACM Press", "citeRegEx": "Chakrabarty et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Chakrabarty et al\\.", "year": 2007}, {"title": "Bid landscape forecasting in online ad exchange marketplace", "author": ["Cui"], "venue": "In KDD \u201911 Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM Press", "citeRegEx": "Cui,? \\Q2011\\E", "shortCiteRegEx": "Cui", "year": 2011}, {"title": "Internet advertising and the generalized second price auction: Selling billions of dollars worth of keywords", "author": ["Ostrovsky Edelman", "B. Schwarz 2005] Edelman", "M. Ostrovsky", "M. Schwarz"], "venue": null, "citeRegEx": "Edelman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Edelman et al\\.", "year": 2005}, {"title": "and Ormoneit", "author": ["P.W. Glynn"], "venue": "D.", "citeRegEx": "Glynn and Ormoneit 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "A game-theoretic machine learning approach for revenue maximization in sponsored search", "author": ["He"], "venue": null, "citeRegEx": "He,? \\Q2013\\E", "shortCiteRegEx": "He", "year": 2013}, {"title": "and Rostamizadeh", "author": ["M. Mohri"], "venue": "A.", "citeRegEx": "Mohri and Rostamizadeh 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "B", "author": ["Natarajan"], "venue": "K.", "citeRegEx": "Natarajan 1989", "shortCiteRegEx": null, "year": 1989}, {"title": "Pin and Key", "author": ["F. Pin", "P. Key"], "venue": "In EC \u201911 Proceedings of the 12th ACM conference on Electronic commerce. ACM Press", "citeRegEx": "Pin and Key.,? \\Q2011\\E", "shortCiteRegEx": "Pin and Key.", "year": 2011}, {"title": "V", "author": ["Vapnik"], "venue": "N.", "citeRegEx": "Vapnik 1998", "shortCiteRegEx": null, "year": 1998}, {"title": "Predicting advertiser bidding behaviors in sponsored search by rationality modeling", "author": ["Xu"], "venue": "In Proceedings of the 22nd international conference on World Wide Web, 1433\u20131444", "citeRegEx": "Xu,? \\Q2013\\E", "shortCiteRegEx": "Xu", "year": 2013}, {"title": "Rates of convergence for empirical processes of stationary mixing sequences. The Annals of Probability 94\u2013116", "author": ["B. Yu"], "venue": null, "citeRegEx": "Yu,? \\Q1994\\E", "shortCiteRegEx": "Yu", "year": 1994}, {"title": "and Tao", "author": ["C. Zhang"], "venue": "D.", "citeRegEx": "Zhang and Tao 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "Vindictive bidding in keyword auctions", "author": ["Zhou", "Y. Lukose. 2007] Zhou", "R. Lukose"], "venue": "In ICEC \u201907 Proceedings of the ninth international conference on Electronic commerce. ACM Press", "citeRegEx": "Zhou et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2007}, {"title": "The generalization performance of erm algorithm with strongly mixing observations", "author": ["Li Zou", "B. Xu 2009] Zou", "L. Li", "Z. Xu"], "venue": null, "citeRegEx": "Zou et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2009}], "referenceMentions": [], "year": 2017, "abstractText": "Machine learning algorithms have been applied to predict agent behaviors in real-world dynamic systems, such as advertiser behaviors in sponsored search and worker behaviors in crowdsourcing, and the prediction models have been used for the optimization of these systems. The behavior data in these systems are generated by live agents: once the systems change due to the adoption of the prediction models learnt from the behavior data, agents will observe and respond to these changes by changing their own behaviors accordingly. As a result, the behavior data will evolve and will not be identically and independently distributed, posing great challenges to the theoretical analysis on the machine learning algorithms for behavior prediction. To tackle this challenge, in this paper, we propose to use Markov Chain in Random Environments (MCRE) to describe the behavior data, and perform generalization analysis of the machine learning algorithms on its basis. Since the one-step transition probability matrix of MCRE depends on both previous states and the random environment, conventional techniques for generalization analysis cannot be directly applied. To address this issue, we propose a novel technique that transforms the original MCRE into a higher-dimensional time-homogeneous Markov chain. The new Markov chain involves more variables but is more regular, and thus easier to deal with. We prove the convergence of the new Markov chain when time approaches infinity. Then we prove a generalization bound for the machine learning algorithms on the behavior data generated by the new Markov chain, which depends on both the Markovian parameters and the covering number of the function class compounded by the loss function for behavior prediction and the behavior prediction model. To the best of our knowledge, this is the first work that performs the generalization analysis on data generated by complex processes in real-world dynamic systems. \u2217This work was done when the first two authors were visiting Microsoft Research Asia. Copyright c \u00a9 2014, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.", "creator": "LaTeX with hyperref package"}}}