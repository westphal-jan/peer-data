{"id": "1404.5511", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Apr-2014", "title": "Coactive Learning for Locally Optimal Problem Solving", "abstract": "Coactive learning is an online problem solving setting where the solutions provided by a solver are interactively improved by a domain expert, which in turn drives learning. In this paper we extend the study of coactive learning to problems where obtaining a globally optimal or near-optimal solution may be intractable or where an expert can only be expected to make small, local improvements to a candidate solution. The goal of learning in this new setting is to minimize the cost as measured by the expert effort over time. We first establish theoretical bounds on the average cost of the existing coactive Perceptron algorithm. In addition, we consider new online algorithms that use cost-sensitive and Passive-Aggressive (PA) updates, showing similar or improved theoretical bounds. We provide an empirical evaluation of the learners in various domains, which show that the Perceptron based algorithms are quite effective and that unlike the case for online classification, the PA algorithms do not yield significant performance gains.", "histories": [["v1", "Fri, 18 Apr 2014 21:17:04 GMT  (238kb,D)", "http://arxiv.org/abs/1404.5511v1", "AAAI 2014 paper, including appendices"]], "COMMENTS": "AAAI 2014 paper, including appendices", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["robby goetschalckx", "alan fern", "prasad tadepalli"], "accepted": true, "id": "1404.5511"}, "pdf": {"name": "1404.5511.pdf", "metadata": {"source": "CRF", "title": "Coactive Learning for Locally Optimal Problem Solving", "authors": ["Robby Goetschalckx", "Alan Fern", "Prasad Tadepalli"], "emails": [], "sections": [{"heading": "Introduction", "text": "This work is motivated by situations where a domain expert has to solve a sequence of related problems (for an example of how to reduce the effort of the expert, unfortunately, is an automatic solution approach that can produce initial solutions, which can then, if necessary, be improved from the ground up by the expert with less effort than solving the problem. This requires that the solution approach has a good estimate of the expert's utility function, which is often unknown and needs to be learned through experience. This general idea of online learning of the improved solutions of an in-situ expert is captured in the framework of coactive learning (Shivaswamy et al. 2013), (Raman, Shivaswamy, and, and Joachims \"s,\" which is learned from the improved solutions of an in-situ expert).The current state-of-the-art of coactive learning generally assumes that the solver can either find a globally optimal solution (according to his current estimate of the utility function), or at least be an optimal solution to the one that can be."}, {"heading": "Problem Setup", "text": "Let's look at X as the set of all problems of interest, e.g. a class of TSP diagrams, and Y as the set of all possible problem-solving, e.g. possible tours. < x, y >) < R, which shows the relative value of a given expert solution to a given problem. (< x, y >) For the purposes of learning, we assume that the benefit function by a linear function U (< x, y >) = w??????? (< x, y >) is a real-rated function of problem-solving pairs, and ~ w is a real-rated weight vector. In this work, we assume a limited feature vector length. (\u00b7) We assume that a critical part of our coactive learning framework is the improvement of solutions by the expert."}, {"heading": "Learning Algorithms", "text": "We look at online algorithms that maintain a weight vector that is updated to w0 = 0 and potentially. In iteration, the learner introduces the expert with the solution S (xt) and observes the corresponding improvement sequence with the cost Ct > 0 of our learning algorithms that will adjust the weight vector in the direction of the problem (xt, y). algorithm 1 specifies the scheme used by our learning algorithms for updating the weight vector. In the tradition of Perceptron, this update is passive in the sense that the expert is satisfied with the solution produced, the weight vector is not algorithms for updating the weight vector. Our four algorithms differ only in the decisions they make for the learning rate that controls the size of the weight update."}, {"heading": "Cost Bounds", "text": "In this section, we will present a lower difference between the average cost of all four algorithms presented in the previous section, for our costs, in the realizable learning environment, where the actual benefit function is a linear function of the trait vector, represented by the weight vector. Since the cost is an integer, this effectively represents a limit to the number of examples in which the expert is able to make improvements to the solution. < 2 The most similar previous analysis conducted for coactive learning focuses on the perctron algorithm under the assumptions of global optimism. This analysis provides a limit to the average cost, rather than expert cost, where the benefit difference exists between the globally optimal solution and the learner. Thus, the novelty of our analysis is in directly limiting expert costs, which is probably more relevant, generalizing on setting local optimism, and analyzing a broader group of algorithms (the average cost in 2012)."}, {"heading": "Experiments", "text": "This year it is more than ever before."}, {"heading": "Conclusions", "text": "The main difference to existing work on coactive learning is that the problems are thought to be so difficult that finding the globally optimal solution is incomprehensible and an expert can be expected to make only small, local changes to a solution. We assume that there are locally optimal solutions that can deliver high-quality solutions if he has an accurate estimate of the expert's usefulness. Four algorithms have been presented for this task, with the aim of minimizing the effort required to improve candidate solutions. Two of the algorithms take these costs directly into account in their updating functions. Theoretical limits regarding the average cost of the four algorithms have been shown where the cost-sensitive perceptual algorithm has a much stronger limit. Empirically, most settings confirm that the cost-sensitive versions of the algorithms exceed their cost-insensitive versions."}, {"heading": "Appendix A: Proof of Theorem 1", "text": "The proof is that each limit is derived using a similar strategy, in the tradition of perceptual style analysis. The proof ignores all steps in which no update takes place, as these costs are the same and would only reduce the average cost. First, we show an upper limit on the costs incurred in the square. Using the general breakdown of costs contained in each algorithm, we get a lower upper limit on the costs incurred in relation to the sum of costs incurred in the square."}, {"heading": "Appendix B: Bounds for Noisy Data", "text": "x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "Acknowledgements", "text": "The authors acknowledge the support of the ONR ATL programme N00014-11-1-0105."}], "references": [{"title": "Yahoo! Learning to Rank Challenge Overview", "author": ["Chapelle", "O. Chang 2011] Chapelle", "Y. Chang"], "venue": "Journal of Machine Learning Research", "citeRegEx": "Chapelle et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2011}, {"title": "Online passiveaggressive algorithms. The Journal of Machine Learning Research 7:551\u2013585", "author": ["Crammer"], "venue": null, "citeRegEx": "Crammer,? \\Q2006\\E", "shortCiteRegEx": "Crammer", "year": 2006}, {"title": "Perceptron based learning with example dependent and noisy costs", "author": ["Geibel", "P. Wysotzki 2003] Geibel", "F. Wysotzki"], "venue": "In Proceedings of the 20th International Conference on Machine Learning", "citeRegEx": "Geibel et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Geibel et al\\.", "year": 2003}, {"title": "Learning trajectory preferences for manipulators via iterative improvement", "author": ["Joachims Jain", "A. Saxena 2013] Jain", "T. Joachims", "A. Saxena"], "venue": "In Proceedings of the 30th International Conference on Machine Learning (ICML-13)", "citeRegEx": "Jain et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Jain et al\\.", "year": 2013}, {"title": "Learning socially optimal information systems from egoistic users", "author": ["Raman", "K. Joachims 2013] Raman", "T. Joachims"], "venue": "In ECML/PKDD", "citeRegEx": "Raman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Raman et al\\.", "year": 2013}, {"title": "Stable coactive learning via perturbation", "author": ["Raman"], "venue": "Proceedings of the 30th International Conference on Machine Learning (ICML-13),", "citeRegEx": "Raman,? \\Q2013\\E", "shortCiteRegEx": "Raman", "year": 2013}, {"title": "Online learning to diversify from implicit feedback", "author": ["Shivaswamy Raman", "K. Joachims 2012] Raman", "P. Shivaswamy", "T. Joachims"], "venue": null, "citeRegEx": "Raman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Raman et al\\.", "year": 2012}, {"title": "Online structured prediction via coactive learning", "author": ["Shivaswamy", "P. Joachims 2012] Shivaswamy", "T. Joachims"], "venue": "CoRR abs/1205.4213", "citeRegEx": "Shivaswamy et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Shivaswamy et al\\.", "year": 2012}, {"title": "Learning structured prediction models: A large margin approach", "author": ["Taskar"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Taskar,? \\Q2005\\E", "shortCiteRegEx": "Taskar", "year": 2005}, {"title": "Cost-sensitive learning by costproportionate example weighting", "author": ["Langford Zadrozny", "B. Abe 2003] Zadrozny", "J. Langford", "N. Abe"], "venue": "In Data Mining,", "citeRegEx": "Zadrozny et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zadrozny et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 4, "context": "This general notion of online learning from the improved solutions of an in situ expert is captured by the framework of coactive learning (Shivaswamy and Joachims 2012), (Raman et al. 2013), (Raman, Shivaswamy, and Joachims 2012), (Raman and Joachims 2013).", "startOffset": 170, "endOffset": 189}], "year": 2014, "abstractText": "Coactive learning is an online problem solving setting where the solutions provided by a solver are interactively improved by a domain expert, which in turn drives learning. In this paper we extend the study of coactive learning to problems where obtaining a globally optimal or near-optimal solution may be intractable or where an expert can only be expected to make small, local improvements to a candidate solution. The goal of learning in this new setting is to minimize the cost as measured by the expert effort over time. We first establish theoretical bounds on the average cost of the existing coactive Perceptron algorithm. In addition, we consider new online algorithms that use cost-sensitive and Passive-Aggressive (PA) updates, showing similar or improved theoretical bounds. We provide an empirical evaluation of the learners in various domains, which show that the Perceptron based algorithms are quite effective and that unlike the case for online classification, the PA algorithms do not yield significant performance gains.", "creator": "LaTeX with hyperref package"}}}