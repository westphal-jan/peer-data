{"id": "1405.3162", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2014", "title": "Circulant Binary Embedding", "abstract": "Binary embedding of high-dimensional data requires long codes to preserve the discriminative power of the input space. Traditional binary coding methods often suffer from very high computation and storage costs in such a scenario. To address this problem, we propose Circulant Binary Embedding (CBE) which generates binary codes by projecting the data with a circulant matrix. The circulant structure enables the use of Fast Fourier Transformation to speed up the computation. Compared to methods that use unstructured matrices, the proposed method improves the time complexity from $\\mathcal{O}(d^2)$ to $\\mathcal{O}(d\\log{d})$, and the space complexity from $\\mathcal{O}(d^2)$ to $\\mathcal{O}(d)$ where $d$ is the input dimensionality. We also propose a novel time-frequency alternating optimization to learn data-dependent circulant projections, which alternatively minimizes the objective in original and Fourier domains. We show by extensive experiments that the proposed approach gives much better performance than the state-of-the-art approaches for fixed time, and provides much faster computation with no performance degradation for fixed number of bits.", "histories": [["v1", "Tue, 13 May 2014 14:17:11 GMT  (322kb)", "http://arxiv.org/abs/1405.3162v1", "ICML 2014"]], "COMMENTS": "ICML 2014", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["felix x yu", "sanjiv kumar", "yunchao gong", "shih-fu chang"], "accepted": true, "id": "1405.3162"}, "pdf": {"name": "1405.3162.pdf", "metadata": {"source": "META", "title": "Circulant Binary Embedding", "authors": ["Felix X. Yu", "Yunchao Gong", "Shih-Fu Chang"], "emails": ["YUXINNAN@EE.COLUMBIA.EDU", "SANJIVK@GOOGLE.COM", "YUNCHAO@CS.UNC.EDU", "SFCHANG@EE.COLUMBIA.EDU"], "sections": [{"heading": null, "text": "ar Xiv: 140 5.31 62v1 [st at.M L] 13 M"}, {"heading": "1. Introduction", "text": "In this year it has come to the point where one sees oneself in a position to live in a country in which most people are able to move into another world, in which they are able to integrate themselves, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they, in which they, in which they, in which they, in which"}, {"heading": "2. Circulant Binary Embedding (CBE)", "text": "A circular matrix R: Rd \u00b7 d is a matrix defined by a vector r = (r0, r2, \u00b7 \u00b7, rd \u2212 1) T (Gray, 2006) 4.R = circ (r): = r0 rd \u2212 1. R2 r1 r0 rd \u2212 1 r2... r1 r0.... rd \u2212 2. Rd \u2212 1 rd \u2212 1 rd \u2212 2. R1 r0 r0. (3) Let D be a diagonal matrix with any diagonal entry that is a Bernoulli variable (\u00b1 1 with the probability of 1 / 2). For x-Rd, its d-bit circular Binary Embedding (CBE) is defined by r-Rd: h (x) = character (RDx), (4) where R = circ (r). The k-bit (k < d) CBE is defined as the first k elements of h (x)."}, {"heading": "3. Randomized Circulant Binary Embedding", "text": "A simple method of obtaining CBE (rTx2) is the generation of elements in (3) and (12) in which the distribution ratios (0, 1) are inconsistent. (0, 1) \"We call this method by chance.\" (0, 1) \"We are not able to understand the distribution mechanisms in the world.\" (0, 1) \"We are not able to understand the distribution mechanisms in the world.\" (0, 1) \"We are not able to understand the distribution mechanisms in the world.\" (0, 1) \"We are unable to understand the distribution mechanisms in the world.\" (0, 1) \"(0, 2).\" (0, 2). \"(0)\" We are. \"(0, 1).\" (0, 1). (0, 2). \"(1). (0, 2). (0.). (0, 3. (.). (0.). (0, 3. (.). (.). (0. (.). (.). (0, 3. (.). (. (.). (.). (0, 3. (.). (.). (0, 3. (.). (.). (.). (.). (. (0, 0.). (.). (. (.). (.). (.). (.). (0, 3.). (. (.). (.). (.). (. (.). (.). (0, 3. (.). (.). (. (.).). (. (.). (. (.). (.). (. (.). (0, (.). (.). (. (.). (.). (.). (. (.). (.). (0, (.).). (0, 3. (. (.). (. (.). (.). (. (.). (.). (.). (. (.). (.). (.).). (. (.).). (. (.). (0,"}, {"heading": "4. Learning Circulant Binary Embedding", "text": "We propose data-dependent CBE (CBE-opt) by optimizing the projection matrix with a novel time-frequency alternating optimization. We consider the following objective function when learning the d-bit CBE. The extension of the k < d bits is shown in Section 4.2.argmin B, r | | B \u2212 XRT | | 2F + \u03bb | | RRT \u2212 I | | | 2F (15) s.t. R = circ (r), where X-Rn \u00b7 d contains the data matrix n training points: X = [x0, \u00b7, xn \u2212 1] T, and B-1} n \u00d7 d the corresponding binary code matrix.9In the above optimization, the first term minimizes the distortion due to binarization. The second term tries to make the predictions (rows of R, and thus the corresponding bits) as unrelated as possible."}, {"heading": "4.1. The Time-Frequency Alternating Optimization", "text": "(\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\") (\"Time\" (\"Time\") (\"Time\" (\"Time\") (\"Time) (\" Time \"(\" Time \") (\" Time) (\"Time\") (Time) (\"Time\") (\"Time\" (\"Time\") (\"Time\" (\"Time\") (\"Time) (\" Time) (\"Time) (\" (\"Time) (\" (\"Time) (\" (\"Time) (\") (Time) (\"Time) (\" (\"Time) (\" Time) (\"(\" Time) (\"Time) (\" (\"Time) (\" (\"Time) (\" (\"Time) (\" (\"Time) (\" (\") (\" Time) (\"(\" Time) (\"(\") (\"Time) (\" (\"(\" Time) (\"(\" (\") (\" Time) (\"(\" (\"Time)\" (\"(\" (\"Time)\" (\"(\" (\")\" (\"Time)\" (\"(\" Time) \"(\" (\"(\" (\"Time))\" (\"(\" (\"(\" Time) \"(\" (\"(\" Time) \"(\" (\")\" (\"(\" (\"(\" Time) \"(\" (\"(\" (\"))\" (\"(\")) \"(\" (\"(\" Time) (\"(\" (\"))))) (\" Time) (\"(\" (\"(\" (\"(\" (\"(\" (\")\" (\"(\" (\"(\" Time) \"(\" (\"(\")) \"(\" (\")\" (\"(\" (\"))\" (\"(\")) \"(\" (\"(\" (\"(\" (\")))))"}, {"heading": "4.2. Learning k < d Bits", "text": "In the case of learning k < d bits, we must solve the following optimization problem: argmin B, r | | BPk \u2212 XPTkRT | | 2F + \u03bb | | RPkPTk RT \u2212 I | | 2Fs.t. R = circ (r), (23), in which Pk = [Ik O OOd \u2212 k], Ik is a k \u00b7 k identity matrix and Od \u2212 k is a (d \u2212 k) \u00b7 (d \u2212 k) all-zero matrix. To solve this problem, we propose a simple solution where Bij = 0, i = 0, \u00b7 \u00b7, n \u2212 1, j = k, \u00b7 \u00b7 \u00b7, d \u2212 1 in (15)."}, {"heading": "5. Experiments", "text": "To compare the performance of the proposed circular embedding technology with the current state of the high-dimensional data, we conducted experiments on three real worlds used by the current state-of-the-art method to generate long binary codes (Gong et al., 2013a). The Flickr-25600 dataset contains 100K images sampled from a noisy Internet image collection. Each image is represented by a 25.600 dimensional vector. The third dataset (ImageNet-25600) is another random subset of ImageNet images in 25.600 dimensional space. All vectors are normalized to be normalized by the unit. We compared the performance of the randomized (CBErand) and learned (CBE-opt) versions of our circular embedding techniques with the current state."}, {"heading": "6. Semi-supervised Extension", "text": "In some applications, a few pairs of similar and unequal data points can be accessed. Here, we show how the CBE formula can be extended to integrate such information into learning by adding an additional objective term J (R).argmin B, r | | B \u2212 XRT (2F + \u03bb | | RRT (I | \u2212 J (R) (24) s.t. R = circ (r), J (R) = \u2211 i, j \u2212 Rxi \u2212 Rxi \u2212 | | 22 \u2212 (i, j \u2212 D (Rxi \u2212 Rxj | | 22). (25) Here M \u2212 and D are the sets of \"similar\" and \"unequal\" distances. Intuition serves to maximize the distances between the unequal pairs and minimize the distances between the similar pairs. Such a term is commonly used in semi-monitored binary coding methods (Wang et al., 2010).We use the fixed J method to optimize the distances between the same pairs."}, {"heading": "7. Conclusion", "text": "The proposed method has a time complexity O (d log d) and a space complexity O (d), but does not show any performance deterioration on real data compared to more expensive approaches (O (d2) or O (d1.5). On the contrary, it showed significant gains in accuracy for the specified time. The full potential of the method can be unlocked when applied to ultra-high-dimensional data (say 100 M) for which no other methods are applicable."}], "references": [{"title": "Approximate nearest neighbors and the fast Johnson-Lindenstrauss transform", "author": ["Ailon", "Nir", "Chazelle", "Bernard"], "venue": "In ACM Symposium on Theory of Computing,", "citeRegEx": "Ailon et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ailon et al\\.", "year": 2006}, {"title": "Similarity estimation techniques from rounding algorithms", "author": ["Charikar", "Moses S"], "venue": "In ACM Symposium on Theory of Computing,", "citeRegEx": "Charikar and S.,? \\Q2002\\E", "shortCiteRegEx": "Charikar and S.", "year": 2002}, {"title": "Fast locality-sensitive hashing", "author": ["Dasgupta", "Anirban", "Kumar", "Ravi", "Sarl\u00f3s", "Tam\u00e1s"], "venue": "In ACM SIGKDD Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Dasgupta et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2011}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-Jia", "Kai", "Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Angular quantization-based binary codes for fast similarity search", "author": ["Gong", "Yunchao", "Kumar", "Sanjiv", "Verma", "Vishal", "Lazebnik", "Svetlana"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gong et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gong et al\\.", "year": 2012}, {"title": "Learning binary codes for highdimensional data using bilinear projections", "author": ["Gong", "Yunchao", "Kumar", "Sanjiv", "Rowley", "Henry A", "Lazebnik", "Svetlana"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Gong et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gong et al\\.", "year": 2013}, {"title": "Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval", "author": ["Gong", "Yunchao", "Lazebnik", "Svetlana", "Gordo", "Albert", "Perronnin", "Florent"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Gong et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gong et al\\.", "year": 2013}, {"title": "Asymmetric distances for binary embeddings", "author": ["Gordo", "Albert", "Perronnin", "Florent"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Gordo et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gordo et al\\.", "year": 2011}, {"title": "Toeplitz and circulant matrices: A review", "author": ["Gray", "Robert M"], "venue": "Now Pub,", "citeRegEx": "Gray and M.,? \\Q2006\\E", "shortCiteRegEx": "Gray and M.", "year": 2006}, {"title": "Johnson-Lindenstrauss lemma for circulant matrices", "author": ["Hinrichs", "Aicke", "Vyb\u0131\u0301ral", "Jan"], "venue": "Random Structures & Algorithms,", "citeRegEx": "Hinrichs et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hinrichs et al\\.", "year": 2011}, {"title": "Product quantization for nearest neighbor search", "author": ["Jegou", "Herve", "Douze", "Matthijs", "Schmid", "Cordelia"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Jegou et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jegou et al\\.", "year": 2011}, {"title": "New and improved Johnson-Lindenstrauss embeddings via the restricted isometry property", "author": ["Krahmer", "Felix", "Ward", "Rachel"], "venue": "SIAM Journal on Mathematical Analysis,", "citeRegEx": "Krahmer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Krahmer et al\\.", "year": 2011}, {"title": "Learning to hash with binary reconstructive embeddings", "author": ["Kulis", "Brian", "Darrell", "Trevor"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kulis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kulis et al\\.", "year": 2009}, {"title": "Hashing algorithms for largescale learning", "author": ["Li", "Ping", "Shrivastava", "Anshumali", "Moore", "Joshua", "Konig", "Arnd Christian"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Li et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "Hashing with graphs", "author": ["Liu", "Wei", "Wang", "Jun", "Kumar", "Sanjiv", "Chang", "Shih-Fu"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Liu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2011}, {"title": "Minimal loss hashing for compact binary codes", "author": ["Norouzi", "Mohammad", "Fleet", "David"], "venue": "International Conference on Machine Learning,", "citeRegEx": "Norouzi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Norouzi et al\\.", "year": 2012}, {"title": "Hamming distance metric learning", "author": ["Norouzi", "Mohammad", "Fleet", "David", "Salakhutdinov", "Ruslan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Norouzi et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Norouzi et al\\.", "year": 2012}, {"title": "Localitysensitive binary codes from shift-invariant kernels", "author": ["Raginsky", "Maxim", "Lazebnik", "Svetlana"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Raginsky et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Raginsky et al\\.", "year": 2009}, {"title": "High-dimensional signature compression for large-scale image classification", "author": ["S\u00e1nchez", "Jorge", "Perronnin", "Florent"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "S\u00e1nchez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "S\u00e1nchez et al\\.", "year": 2011}, {"title": "A variant of the Johnson\u2013Lindenstrauss lemma for circulant matrices", "author": ["Vyb\u0131\u0301ral", "Jan"], "venue": "Journal of Functional Analysis,", "citeRegEx": "Vyb\u0131\u0301ral and Jan.,? \\Q2011\\E", "shortCiteRegEx": "Vyb\u0131\u0301ral and Jan.", "year": 2011}, {"title": "Sequential projection learning for hashing with compact codes", "author": ["Wang", "Jun", "Kumar", "Sanjiv", "Chang", "Shih-Fu"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Wang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2010}, {"title": "Spectral hashing", "author": ["Weiss", "Yair", "Torralba", "Antonio", "Fergus", "Rob"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Weiss et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Weiss et al\\.", "year": 2008}, {"title": "New bounds for circulant Johnson-Lindenstrauss embeddings", "author": ["Zhang", "Hui", "Cheng", "Lizhi"], "venue": "arXiv preprint arXiv:1308.6339,", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 13, "context": "Introduction Embedding input data in binary spaces is becoming popular for efficient retrieval and learning on massive data sets (Li et al., 2011; Gong et al., 2013a; Raginsky & Lazebnik, 2009; Gong et al., 2012; Liu et al., 2011).", "startOffset": 129, "endOffset": 230}, {"referenceID": 4, "context": "Introduction Embedding input data in binary spaces is becoming popular for efficient retrieval and learning on massive data sets (Li et al., 2011; Gong et al., 2013a; Raginsky & Lazebnik, 2009; Gong et al., 2012; Liu et al., 2011).", "startOffset": 129, "endOffset": 230}, {"referenceID": 14, "context": "Introduction Embedding input data in binary spaces is becoming popular for efficient retrieval and learning on massive data sets (Li et al., 2011; Gong et al., 2013a; Raginsky & Lazebnik, 2009; Gong et al., 2012; Liu et al., 2011).", "startOffset": 129, "endOffset": 230}, {"referenceID": 13, "context": "In fact, the required number of bits is O(d), where d is the input dimensionality (Li et al., 2011; Gong et al., 2013a; S\u00e1nchez & Perronnin, 2011).", "startOffset": 82, "endOffset": 146}, {"referenceID": 21, "context": "Thus, a number of data-dependent techniques have been proposed with different optimization criteria such as reconstruction error (Kulis & Darrell, 2009), data dissimilarity (Norouzi & Fleet, 2012; Weiss et al., 2008), rankA few methods transform the linear projection via a nonlinear map before taking the sign (Weiss et al.", "startOffset": 173, "endOffset": 216}, {"referenceID": 21, "context": ", 2008), rankA few methods transform the linear projection via a nonlinear map before taking the sign (Weiss et al., 2008; Raginsky & Lazebnik, 2009).", "startOffset": 102, "endOffset": 149}, {"referenceID": 15, "context": "ing loss (Norouzi et al., 2012), quantization error after PCA (Gong et al.", "startOffset": 9, "endOffset": 31}, {"referenceID": 20, "context": ", 2013b), and pairwise misclassification (Wang et al., 2010).", "startOffset": 41, "endOffset": 60}, {"referenceID": 4, "context": ", 2012), quantization error after PCA (Gong et al., 2013b), and pairwise misclassification (Wang et al., 2010). These methods are shown to be effective for learning compact codes for relatively lowdimensional data. However, the O(d2) computational and space costs prohibit them from being applied to learning long codes for high-dimensional data. For instance, to generate O(d)-bit binary codes for data with d \u223c1M, a huge projection matrix will be required needing TBs of memory, which is not practical2. In order to overcome these computational challenges, Gong et al. (2013a) proposed a bilinear projection based coding method for high-dimensional data.", "startOffset": 39, "endOffset": 579}, {"referenceID": 2, "context": "One could in principal use other structured matrices like Hadamard matrix along with a sparse random Gaussian matrix to achieve fast projection as was done in fast Johnson-Lindenstrauss transform(Ailon & Chazelle, 2006; Dasgupta et al., 2011), but it is still slower than circulant projection and needs more space.", "startOffset": 195, "endOffset": 242}, {"referenceID": 20, "context": ", 2013b;a) and (Wang et al., 2010).", "startOffset": 15, "endOffset": 34}, {"referenceID": 3, "context": "The ImageNet-51200 contains 100k images sampled from 100 random classes from ImageNet (Deng et al., 2009), each represented by a 51, 200 dimensional vector.", "startOffset": 86, "endOffset": 105}, {"referenceID": 10, "context": "Bilinear embeddings have been shown to perform similar or better than another promising technique called Product Quantization (Jegou et al., 2011).", "startOffset": 126, "endOffset": 146}, {"referenceID": 21, "context": ", 2013b), SH (Weiss et al., 2008), SKLSH (Raginsky & Lazebnik, 2009), and AQBC (Gong et al.", "startOffset": 13, "endOffset": 33}, {"referenceID": 4, "context": ", 2008), SKLSH (Raginsky & Lazebnik, 2009), and AQBC (Gong et al., 2012).", "startOffset": 53, "endOffset": 72}, {"referenceID": 13, "context": "The advantage is to save on storage allowing even large scale datasets to fit in memory (Li et al., 2011; S\u00e1nchez & Perronnin, 2011).", "startOffset": 88, "endOffset": 132}, {"referenceID": 20, "context": "Such a term is commonly used in semi-supervised binary coding methods (Wang et al., 2010).", "startOffset": 70, "endOffset": 89}], "year": 2014, "abstractText": "Binary embedding of high-dimensional data requires long codes to preserve the discriminative power of the input space. Traditional binary coding methods often suffer from very high computation and storage costs in such a scenario. To address this problem, we propose Circulant Binary Embedding (CBE) which generates binary codes by projecting the data with a circulant matrix. The circulant structure enables the use of Fast Fourier Transformation to speed up the computation. Compared to methods that use unstructured matrices, the proposed method improves the time complexity from O(d2) to O(d log d), and the space complexity from O(d2) to O(d) where d is the input dimensionality. We also propose a novel time-frequency alternating optimization to learn data-dependent circulant projections, which alternatively minimizes the objective in original and Fourier domains. We show by extensive experiments that the proposed approach gives much better performance than the state-of-the-art approaches for fixed time, and provides much faster computation with no performance degradation for fixed number of bits.", "creator": "LaTeX with hyperref package"}}}