{"id": "1406.0189", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2014", "title": "Convex Total Least Squares", "abstract": "We study the total least squares (TLS) problem that generalizes least squares regression by allowing measurement errors in both dependent and independent variables. TLS is widely used in applied fields including computer vision, system identification and econometrics. The special case when all dependent and independent variables have the same level of uncorrelated Gaussian noise, known as ordinary TLS, can be solved by singular value decomposition (SVD). However, SVD cannot solve many important practical TLS problems with realistic noise structure, such as having varying measurement noise, known structure on the errors, or large outliers requiring robust error-norms. To solve such problems, we develop convex relaxation approaches for a general class of structured TLS (STLS). We show both theoretically and experimentally, that while the plain nuclear norm relaxation incurs large approximation errors for STLS, the re-weighted nuclear norm approach is very effective, and achieves better accuracy on challenging STLS problems than popular non-convex solvers. We describe a fast solution based on augmented Lagrangian formulation, and apply our approach to an important class of biological problems that use population average measurements to infer cell-type and physiological-state specific expression levels that are very hard to measure directly.", "histories": [["v1", "Sun, 1 Jun 2014 18:13:08 GMT  (406kb,D)", "http://arxiv.org/abs/1406.0189v1", "9 pages, 4 figures"]], "COMMENTS": "9 pages, 4 figures", "reviews": [], "SUBJECTS": "stat.ML cs.LG q-bio.GN q-bio.QM stat.AP", "authors": ["dmitry malioutov", "nikolai slavov"], "accepted": true, "id": "1406.0189"}, "pdf": {"name": "1406.0189.pdf", "metadata": {"source": "META", "title": "Convex Total Least Squares", "authors": ["Dmitry Malioutov", "Nikolai Slavov"], "emails": ["dmalioutov@us.ibm.com", "nslavov@alum.mit.edu"], "sections": [{"heading": null, "text": "We are investigating the problem of the overall lowest squares (TLS), which generalizes the regression of the lowest squares by allowing measurement errors in both dependent and independent variables. TLS is widely used in applied areas such as computer vision, system identification, and econometrics. The special case, when all dependent and independent variables exhibit the same level of unrelated Gaussian noise known as ordinary TLS, can be solved by Singular Value Decomposition (SVD). However, SVD cannot solve many important practical TLS problems with realistic noise structure, such as different measurement noise, known structure on the errors, or large outliers that require robust error standards. To solve such problems, we are developing convex relaxation approaches for a general class of structured TLS (STLS). We show both theoretically and experimentally that simple nuclear standard relaxation produces large approximation errors for STLS based on very precise, newly applied STLS problems."}, {"heading": "1. Introduction", "text": "In fact, it is the case that most of them are able to move into another world, in which they are able to move, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they are able to move, in which they are able to move, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they"}, {"heading": "1.1. Total Least Squares", "text": "We first check the solution of common TLS problems. We simplify the notation of (1): combining our loud data X and y into a matrix, A, [X \u2212 y] and the errors in E, [Ex \u2212 n] we have an incomplete matrix in which (A-E) [\u03b2 1] = 0. (2) Matrix A is generally full-fledged, and a solution can be achieved by finding an incomplete matrix that is almost known; an approach based on Fourier transformations can handle block-circular errors Ex (Beck & Ben Valley, 2005).to A-D in the sense of the Frobenius standard. This finds the smallest errors Ex and n, so that y + n lies in the range of X \u2212 Ex. The most obvious low-level matrix is achieved simply by calculating the SVD, A-Z = UPS T and setting the smallest singular value to zero."}, {"heading": "2. STLS via a nuclear norm relaxation", "text": "The STLS problem in a general form can be described as follows (Markovsky & Van Huffel, 2007). Using the notation in Section 1.1, we assume that our observed matrix A * * * M \u00b7 N is with complete column order. We aim to find a near-low-ranking matrix A, rank (A) \u2264 N \u2212 1, where the errors E have a certain linear structure: minimum requirement W E * 2F, where rank (A) \u2264 N \u2212 1 A = A + E, and L (E) = b (3) The key components here are the linear qualities that E must meet, L (E) = b. This notation represents a set of linear constraints tr (LTi E) = bi, for i = 1, J. In our application to cell heterogeneity, we accurately match certain entries of A, i.e."}, {"heading": "2.1. Reweighted nuclear norm and the log-determinant heuristic for rank", "text": "A very effective approach to dealing with the nuclear threat situation in the USA (\"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" \"A,\" A, \"\" A, \"A,\" A, \"A,\" A, \"A,\" \"A,\" \"A,\" \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" \"A,\" A, \"A,\" A, \"A,\" \"A,\" A, \"A,\" A, \"A,\" A, \"\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A,\" A, \"A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A, A,"}, {"heading": "3. Fast computation via ALM", "text": "We develop an effective first-order approach for STLS based on the extended Lagrange multiplier (ALM) method (Bertsekas, 1982; Lin et al., 2010). Consider a general, equality-limited optimization problem: min x f (x) in such a way that h (x) = 0. (10) ALM first defines an extended Lagrange function: L (x, \u03bb, \u00b5) = f (x) + KH (x) + KH (x) 22 (11) The advanced Lagrange method alternates optimization via x with updates of \u03bb for an increasing sequence of \u00b5k. The motivation is that either if it is close to the optimal dual solution for (10), or, if it is large enough, the solution adapts to (11) the minimum of the global (10) Q- and convergent (1-K) functions."}, {"heading": "3.1. ALM for nuclear-norm STLS", "text": "We want to solve the problem: min-A-A-A-A-A-E-2F, so that (12) A-A-A-A-A-A-E-E and L-E-B-B-A-A-A-E-B-B-A-A-A-A-A-A-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-A-A-A-A-A-A-A-A-A-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-A-A-A-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-E-A-A-E-E-E-E-E E E-E-E E E E-E-E-E-E-E E E E-E-E E E-E-E E-E-E-E E E E-E-E-E E-E-E E E-E E-E E-E E E E E E-E-E-E E-E E E-E E-E E E-E E-E-E-E E-E E-E E E-E E-E E E-E E-E E E-E E-E-E E E E-E E E E-E-E E-E E-E E E E E-E-E-E E E E-E E E E E-E E-E-E E E E E E-E-"}, {"heading": "3.2. ALM for re-weighted nuclear-norm STLS", "text": "To use the log determinant heuristically, i.e. the reweighted nuclear standards approaches, we have to solve the weighted nuclear standards sub-problems: min. (W1AW2). \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W2AW2 \u2212 W1AW2 \u2212 W1AW2 \u2212 W2AW2 \u2212 W1AW2 and add this definition as an additional linear constraint: min."}, {"heading": "4. Accuracy analysis for STLS", "text": "In the context of matrix completion and robust PCA, the nuclear standard Relaxation has strong theoretical accuracy guarantees (Recht et al., 2010; Chandrasekaranet al., 2011). We are now investigating accuracy \u2212 n approximation guarantees for the STLS problem via the nuclear standard and the reweighted nuclear standards approaches. The analysis is performed in the simple TLS setting, where the optimal solution is available via the SVD \u2212 and it provides valuable insight into the accuracy of our approach to the much harder STLS problem. In particular, we quantify the dramatic benefits of using the reweighting. In this section, we will examine a simplification of our STLS algorithm, where we determine the regulatory parameters once and do not update them by iterations. The full adaptive approach from Section 2.1 is analyzed in the addendum to this paper, where we show that it can restore the exact SVLS solution to the simple TD supply."}, {"heading": "5. Experimental Results", "text": "In fact, it is so that one sees oneself in a position to put oneself at the top of the world, and not only at the top of the world, but also at the top of the world, in which the world is in the world. (...) It is as if the world from the world enters the world of people. (...) It is as if the world enters the world of people. (...) It is as if the world enters the world of people. (...) It is as if the world enters the world of people. (...) It is as if the world enters the world into the world of people. (...) It is as if the world enters the world of people. (...) It is as if it enters the world of the world of people. (...) It is as if it enters the world of the world and the world of the people. (...) It is as if it enters the world into the world of the world and the world of the world of the world. (...) It is as if it enters the world into the world of the world of the world of the world of the world of the people. (...) It is as if it enters the world into the world into the world of the world of the world of the world of the world of the people. (...) It is as if it enters the world into the world into the world of the world of the world of the world of the world of the world of the world of the world and the world of the world of the people. (...) It is as if it enters the world into the world in the world of the world of the world of the world in the world of the world in the world of the world, and the world of the world of the world of the world in the world in the world in the world, and the world in the world in the world of the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world in the world, in the world in the world in the world, in the world in the world in the world in the world in the world, in the world in the world in the world in the world in the world"}, {"heading": "5.1. Quantification of cellular heterogeneity", "text": "In fact, it is such that most of us are able to surpass ourselves, both in terms of the way in which they move and in terms of the way in which they move and in terms of the way in which they move, as well as in terms of the way in which they move, in which they move, in which they move, in which they move, in which they move, in which they move, in which they live, in which they live themselves and in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they, in which they live, in which they live."}, {"heading": "6. Appendix: Error analysis for re-weighted STLS", "text": "To gain insight into the reweighted nuclear standard, we first look at the diagonal case in which A = diag (x). Since both the Frobenius standard and the nuclear standard are uniformly invariant, the analysis extends directly to the non-diagonal case. \u2212 The log heuristic for the threshold of x, so we use vector notation for simplicity. \u2212 The log heuristic for the threshold of x, so we solve the following problem: min 12 x \u2212 y 2 + 1 log (\u03b1 + | xi |), for a very small number > 0. \u2212 This is a separable problem with a closed form solution for each threshold. \u2212 5 If we take the threshold of SVD A = UPS T, we have the UPS-2F = 2 F and the UPS-2Y, we have the threshold of i."}, {"heading": "7. Conclusions", "text": "We considered a convex relaxation for a very rich class of structured TLS problems and provided theoretical guarantees. In addition, we developed an efficient firstorder-extended Lagrange multiplier algorithm for the reweighting of the nuclear standard STLS, which can be applied beyond TLS to matrix completion and robust PCA problems. We applied STLS to the quantification of cellular heterogeneity from population averages. In future work, we will study STLS with sparse and group-sparse solutions and investigate links to robust LS (El Ghaoui & Lebret, 1997)."}], "references": [{"title": "Solution of the matrix equation AX+", "author": ["R.H. Bartels", "G.W. Stewart"], "venue": "XB = C. Communications of the ACM,", "citeRegEx": "Bartels and Stewart,? \\Q1972\\E", "shortCiteRegEx": "Bartels and Stewart", "year": 1972}, {"title": "A global solution for the structured total least squares problem with block circulant matrices", "author": ["A. Beck", "A. Ben-Tal"], "venue": "SIAM Journal on Matrix Analysis and Applic.,", "citeRegEx": "Beck and Ben.Tal,? \\Q2005\\E", "shortCiteRegEx": "Beck and Ben.Tal", "year": 2005}, {"title": "Constrained Optim. and Lagrange Multiplier Methods", "author": ["D.P. Bertsekas"], "venue": null, "citeRegEx": "Bertsekas,? \\Q1982\\E", "shortCiteRegEx": "Bertsekas", "year": 1982}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["S. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Boyd et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2011}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["J. Cai", "E.J. Candes", "Z. Shen"], "venue": "SIAM Journal on Optim.,", "citeRegEx": "Cai et al\\.,? \\Q1956\\E", "shortCiteRegEx": "Cai et al\\.", "year": 1956}, {"title": "Enhancing sparsity by reweighted l1 minimization", "author": ["E.J. Candes", "M.B. Wakin", "S.P. Boyd"], "venue": "J. of Fourier Analysis and Applic.,", "citeRegEx": "Candes et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Candes et al\\.", "year": 2008}, {"title": "Rank-sparsity incoherence for matrix decomposition", "author": ["V. Chandrasekaran", "S. Sanghavi", "P.A. Parrilo", "A.S. Willsky"], "venue": "SIAM Journal on Optim.,", "citeRegEx": "Chandrasekaran et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chandrasekaran et al\\.", "year": 2011}, {"title": "Low-rank structure learning via log-sum heuristic recovery", "author": ["Y. Deng", "Q. Dai", "R. Liu", "Z. Zhang", "S. Hu"], "venue": "arXiv preprint arXiv:1012.1919,", "citeRegEx": "Deng et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2012}, {"title": "Robust solutions to leastsquares problems with uncertain data", "author": ["L. El Ghaoui", "H. Lebret"], "venue": "SIAM J. on Matrix Analysis and Applic.,", "citeRegEx": "Ghaoui and Lebret,? \\Q1997\\E", "shortCiteRegEx": "Ghaoui and Lebret", "year": 1997}, {"title": "A rank minimization heuristic with application to minimum order system approximation", "author": ["M. Fazel", "H. Hindi", "S.P. Boyd"], "venue": "In IEEE American Control Conference,", "citeRegEx": "Fazel et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Fazel et al\\.", "year": 2001}, {"title": "An analysis of the total least squares problem", "author": ["G.H. Golub", "C.F. Van Loan"], "venue": "SIAM Journal on Numerical Analysis,", "citeRegEx": "Golub and Loan,? \\Q1980\\E", "shortCiteRegEx": "Golub and Loan", "year": 1980}, {"title": "Weighted `1 minimization for sparse recovery with prior information", "author": ["A. Khajehnejad", "W. Xu", "S. Avestimehr", "B. Hassibi"], "venue": "In IEEE Int. Symposium on Inf. Theory,", "citeRegEx": "Khajehnejad et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Khajehnejad et al\\.", "year": 2009}, {"title": "The augmented Lagrange multiplier method for exact recovery of corrupted low-rank matrices", "author": ["Z. Lin", "M. Chen", "Y. Ma"], "venue": "arXiv preprint arXiv:1009.5055,", "citeRegEx": "Lin et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2010}, {"title": "Robust recovery of subspace structures by low-rank representation", "author": ["G. Liu", "Z. Lin", "S. Yan", "J. Sun", "Y. Yu", "Y. Ma"], "venue": "arXiv preprint arXiv:1010.2955,", "citeRegEx": "Liu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2010}, {"title": "Software for weighted structured low-rank approximation", "author": ["I. Markovsky", "K. Usevich"], "venue": "J. Comput. Appl. Math.,", "citeRegEx": "Markovsky and Usevich,? \\Q2014\\E", "shortCiteRegEx": "Markovsky and Usevich", "year": 2014}, {"title": "Overview of total least-squares methods", "author": ["I. Markovsky", "S. Van Huffel"], "venue": "Signal processing,", "citeRegEx": "Markovsky and Huffel,? \\Q2007\\E", "shortCiteRegEx": "Markovsky and Huffel", "year": 2007}, {"title": "Application of structured total least squares for system identification and model reduction", "author": ["I. Markovsky", "J.C. Willems", "S. Van Huffel", "B. De Moor", "R. Pintelon"], "venue": "Automatic Control, IEEE Trans. on,", "citeRegEx": "Markovsky et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Markovsky et al\\.", "year": 2005}, {"title": "Reweighted nuclear norm minimization with application to system identification", "author": ["K. Mohan", "M. Fazel"], "venue": "In American Control Conference,", "citeRegEx": "Mohan and Fazel,? \\Q2010\\E", "shortCiteRegEx": "Mohan and Fazel", "year": 2010}, {"title": "Noisy signal recovery via iterative reweighted l1-minimization", "author": ["D. Needell"], "venue": "In Forty-Third Asilomar Conference on Signals, Systems and Computers,", "citeRegEx": "Needell,? \\Q2009\\E", "shortCiteRegEx": "Needell", "year": 2009}, {"title": "Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization", "author": ["B. Recht", "M. Fazel", "P.A. Parrilo"], "venue": "SIAM Review,", "citeRegEx": "Recht et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Recht et al\\.", "year": 2010}, {"title": "Coupling among growth rate response, metabolic cycle, and cell division cycle in yeast", "author": ["N. Slavov", "D. Botstein"], "venue": "Molecular bio. of the cell,", "citeRegEx": "Slavov and Botstein,? \\Q2011\\E", "shortCiteRegEx": "Slavov and Botstein", "year": 2011}, {"title": "Metabolic cycling without cell division cycling in respiring yeast", "author": ["N. Slavov", "J. Macinskas", "A. Caudy", "D. Botstein"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Slavov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Slavov et al\\.", "year": 2011}, {"title": "A conserved cell growth cycle can account for the environmental stress responses of divergent eukaryotes", "author": ["Slavov", "Nikolai", "Airoldi", "Edoardo M", "van Oudenaarden", "Alexander", "Botstein", "David"], "venue": "Molecular Biology of the Cell,", "citeRegEx": "Slavov et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Slavov et al\\.", "year": 1986}, {"title": "Weighted low-rank approximations", "author": ["N. Srebro", "T. Jaakkola"], "venue": "In Int. Conf. Machine Learning (ICML),", "citeRegEx": "Srebro and Jaakkola,? \\Q2003\\E", "shortCiteRegEx": "Srebro and Jaakkola", "year": 2003}, {"title": "SDPT3 \u2013 a Matlab software package for semidefinite programming, version 1.3", "author": ["K.C. Toh", "M.J. Todd", "R.H. T\u00fct\u00fcnc\u00fc"], "venue": "Optim. Method. Softw.,", "citeRegEx": "Toh et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Toh et al\\.", "year": 1999}, {"title": "Weighted and structured sparse total least-squares for perturbed compressive sampling", "author": ["H. Zhu", "G.B. Giannakis", "G. Leus"], "venue": "In IEEE Int. Conf. Acoustics, Speech and Signal Proc.,", "citeRegEx": "Zhu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 16, "context": "block-diagonal, Toeplitz, or Hankel in system identification literature (Markovsky et al., 2005).", "startOffset": 72, "endOffset": 96}, {"referenceID": 25, "context": "by local optimization methods (Markovsky & Usevich, 2014; Zhu et al., 2011; Srebro & Jaakkola, 2003).", "startOffset": 30, "endOffset": 100}, {"referenceID": 9, "context": "Our approach uses the re-weighted nuclear norm relaxation (Fazel et al., 2001) and is highly flexible: it can handle very general linear structure on errors, including arbitrary weights (changing noise for different entries), patterns of observed and unobserved errors, Toeplitz and Hankel structures, and even norms other than the Frobenius norm.", "startOffset": 58, "endOffset": 78}, {"referenceID": 6, "context": "The nuclear norm relaxation has been successfully used for a range of machine learning problems involving rank constraints, including low-rank matrix completion, low-order system approximation, and robust PCA (Cai et al., 2010; Chandrasekaran et al., 2011).", "startOffset": 209, "endOffset": 256}, {"referenceID": 2, "context": "We suggest fast first-order methods based on Augmented Lagrangian multipliers (Bertsekas, 1982) to compute the STLS solution.", "startOffset": 78, "endOffset": 95}, {"referenceID": 9, "context": "A very effective improvement of the nuclear norm comes from re-weighting it (Fazel et al., 2001; Mohan & Fazel, 2010) based on the log-determinant heuristic for rank.", "startOffset": 76, "endOffset": 117}, {"referenceID": 5, "context": "\u2211 i wi|xi| with suitable positive weights wi (Candes et al., 2008) instead of a plain `1-norm.", "startOffset": 45, "endOffset": 66}, {"referenceID": 9, "context": "This iterative approach can be seen as an iterative local linearization of the concave log-penalty for sparsity, \u2211 i log(\u03b4+ |xi|) (Fazel et al., 2001; Candes et al., 2008).", "startOffset": 130, "endOffset": 171}, {"referenceID": 5, "context": "This iterative approach can be seen as an iterative local linearization of the concave log-penalty for sparsity, \u2211 i log(\u03b4+ |xi|) (Fazel et al., 2001; Candes et al., 2008).", "startOffset": 130, "endOffset": 171}, {"referenceID": 18, "context": "In both empirical and emerging theoretical studies(Needell, 2009; Khajehnejad et al., 2009)", "startOffset": 50, "endOffset": 91}, {"referenceID": 11, "context": "In both empirical and emerging theoretical studies(Needell, 2009; Khajehnejad et al., 2009)", "startOffset": 50, "endOffset": 91}, {"referenceID": 9, "context": "has a semi-definite programming (SDP) representation (Fazel et al., 2001).", "startOffset": 53, "endOffset": 73}, {"referenceID": 24, "context": "There are various ways to solve the plain and weighted nuclear norm STLS formulations, including interiorpoint methods (Toh et al., 1999) and iterative thresholding (Cai et al.", "startOffset": 119, "endOffset": 137}, {"referenceID": 2, "context": "In the next section we focus on augmented Lagrangian methods (ALM) (Bertsekas, 1982) which allow fast convergence without using computationally expensive second-order information.", "startOffset": 67, "endOffset": 84}, {"referenceID": 2, "context": "We develop an effective first-order approach for STLS based on the augmented Lagrangian multiplier (ALM) method (Bertsekas, 1982; Lin et al., 2010).", "startOffset": 112, "endOffset": 147}, {"referenceID": 12, "context": "We develop an effective first-order approach for STLS based on the augmented Lagrangian multiplier (ALM) method (Bertsekas, 1982; Lin et al., 2010).", "startOffset": 112, "endOffset": 147}, {"referenceID": 2, "context": "When f and h are both continuously differentiable, if \u03bck is an increasing sequence, the solution converges Q-linearly to the optimal one (Bertsekas, 1982).", "startOffset": 137, "endOffset": 154}, {"referenceID": 12, "context": "The work of (Lin et al., 2010) extended the analysis to allow objective functions involving nuclear-norm terms.", "startOffset": 12, "endOffset": 30}, {"referenceID": 12, "context": "We do not wait for the coordinate descent to converge at each ALM step, but rather update \u039b and \u03bc after a single iteration, following the inexact ALM algorithm in (Lin et al., 2010).", "startOffset": 163, "endOffset": 181}, {"referenceID": 2, "context": "Finally, instead of relaxing the constraint L(E) = b, we keep the constrained form, and follow each step by a projection (Bertsekas, 1982).", "startOffset": 121, "endOffset": 138}, {"referenceID": 13, "context": "There is no known analytic thresholding solution for the weighted nuclear norm, so instead we follow (Liu et al., 2010) to create a new variable D = W1AW2 and add this definition as an additional linear constraint:", "startOffset": 101, "endOffset": 119}, {"referenceID": 3, "context": "3This is closely related to the popular alternating direction of multipliers methods (Boyd et al., 2011).", "startOffset": 85, "endOffset": 104}, {"referenceID": 7, "context": "Note that (Deng et al., 2012) considered a strategy for minimizing re-weighted nuclear norms for matrix completion, but instead of using exact minimization over A, they took a step in the gradient direction.", "startOffset": 10, "endOffset": 29}, {"referenceID": 19, "context": "In context of matrix completion and robust PCA, the nuclear norm relaxation has strong theoretical accuracy guarantees (Recht et al., 2010; Chandrasekaran et al., 2011).", "startOffset": 119, "endOffset": 168}, {"referenceID": 6, "context": "In context of matrix completion and robust PCA, the nuclear norm relaxation has strong theoretical accuracy guarantees (Recht et al., 2010; Chandrasekaran et al., 2011).", "startOffset": 119, "endOffset": 168}, {"referenceID": 21, "context": "We consider a cell culture containing cells in K distinct physiological states, such as phases of cell growth or division cycles (Slavov et al., 2011; 2012).", "startOffset": 129, "endOffset": 156}, {"referenceID": 21, "context": "Our algorithm infers the fraction of cells in HOC and in LOC phase, up to a scalar factor, in close agreement with expectations from physical measurements in synchronized cultures (Slavov et al., 2011; Slavov & Botstein, 2011).", "startOffset": 180, "endOffset": 226}], "year": 2014, "abstractText": "We study the total least squares (TLS) problem that generalizes least squares regression by allowing measurement errors in both dependent and independent variables. TLS is widely used in applied fields including computer vision, system identification and econometrics. The special case when all dependent and independent variables have the same level of uncorrelated Gaussian noise, known as ordinary TLS, can be solved by singular value decomposition (SVD). However, SVD cannot solve many important practical TLS problems with realistic noise structure, such as having varying measurement noise, known structure on the errors, or large outliers requiring robust error-norms. To solve such problems, we develop convex relaxation approaches for a general class of structured TLS (STLS). We show both theoretically and experimentally, that while the plain nuclear norm relaxation incurs large approximation errors for STLS, the re-weighted nuclear norm approach is very effective, and achieves better accuracy on challenging STLS problems than popular non-convex solvers. We describe a fast solution based on augmented Lagrangian formulation, and apply our approach to an important class of biological problems that use population average measurements to infer cell-type and physiological-state specific expression levels that are very hard to measure directly. Proceedings of the 31 st International Conference on Machine Learning, Beijing, China, 2014. JMLR: W&CP volume 32. Copyright 2014 by the author(s).", "creator": "LaTeX with hyperref package"}}}