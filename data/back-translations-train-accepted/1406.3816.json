{"id": "1406.3816", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Jun-2014", "title": "Simultaneous Model Selection and Optimization through Parameter-free Stochastic Learning", "abstract": "Stochastic gradient descent algorithms for training linear and kernel predictors are gaining more and more importance, thanks to their scalability. While various methods have been proposed to speed up their convergence, the model selection phase is often ignored. In fact, in theoretical works most of the time assumptions are made, for example, on the prior knowledge of the norm of the optimal solution, while in the practical world validation methods remain the only viable approach. In this paper, we propose a new kernel-based stochastic gradient descent algorithm that performs model selection while training, with no parameters to tune, nor any form of cross-validation. The algorithm builds on recent advancement in online learning theory for unconstrained settings, to estimate over time the right regularization in a data-dependent way. Optimal rates of convergence are proved under standard smoothness assumptions on the target function, using the range space of the fractional integral operator associated with the kernel.", "histories": [["v1", "Sun, 15 Jun 2014 13:34:27 GMT  (139kb,D)", "http://arxiv.org/abs/1406.3816v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["francesco orabona"], "accepted": true, "id": "1406.3816"}, "pdf": {"name": "1406.3816.pdf", "metadata": {"source": "CRF", "title": "Simultaneous Model Selection and Optimization through Parameter-free Stochastic Learning", "authors": ["Francesco Orabona"], "emails": ["francesco@orabona.com"], "sections": [{"heading": "1 Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2 Problem Setting and Definitions", "text": "Leave X-Rd a compact set and HK the RKHS to a Mercer kernel K: X \u00b7 X \u00b7 R-R = 2 \u00b7 K-R = 2 \u00b7 K-R = 2 \u00b7 K-R = 2 \u00b7 K-R = 2 \u00b7 K-R = 1 (x) > K = 1 (x).L-R: 0 \u00b7 K-L (x).L-L (x): 0 \u00b7 K-L (x), x-L (x), x-L (x), x-L (x), x-L-L (x).L-L (x), x).L-L (x), x).L-L (x), x).L (x), x-L (x), x-L (x)."}, {"heading": "3 A Gentle Start: ASGD, Optimal Step Sizes, and the Perceptron", "text": "We want to investigate the problem of the link between step size and regulation. (3) This result shows the link between step size and degree of regulation: In the case of risk. \"(3)\" We want to investigate the risk of risk. \"(3)\" We want to investigate the problem of risk avoidance. \"(3)\" We want to investigate the problem of risk avoidance. \"(3)\" We want to investigate the problem of risk avoidance. \"(3)\" We want to investigate the problem of risk avoidance. \"(3)\" We want to investigate the problem of risk avoidance. \"(3)\" We want to investigate the problem of risk avoidance. \"(3)\" We want to investigate the problem of risk avoidance. \"(4)\" We want to investigate the problem of risk avoidance. \"(4)\" We want to investigate the risk of risk. \"(4)\" We want to investigate the problem of risk avoidance. \"(4) We want to investigate the problem of risk avoidance."}, {"heading": "4 PiSTOL: Parameter-free STOchastic Learning", "text": "11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11"}, {"heading": "5 Convergence Results for PiSTOL", "text": "(...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...)) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...)) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) ("}, {"heading": "6 Related Work", "text": "In this area, there is a high probability that additional approaches are required to explore previous approaches."}, {"heading": "7 Discussion", "text": "Based on OCO and the tools of statistical learning theory, we have introduced the first parameter-free stochastic learning algorithm that achieves optimal convergence rates, the smoothness of the optimal predictor. Specifically, the algorithm does not require an additional validation method for model selection, but is automatically tuned independently in an online and data-dependent manner. Even if this is mainly a theoretical work, we believe that it could also have great potential in the applied world. Therefore, as proof of the potential of this method, we have also conducted some preliminary experiments to compare the performance of PiSTOL with an SVM that uses 5-fold cross-validation to select the regulation weight parameter. Experiments were repeated with 5 random shuffles, showing the average and standard deviations over three datasets.5 The latest version of LIBSVM was used to train the SVM."}, {"heading": "A Per-coordinate Variant of PiSTOL", "text": "Recently, a number of algorithms have been proposed with different step sizes for each coordinate, e.g. [14, 13]. The motivation is to exploit the sparseness of the characteristics and at the same time have a slower decreasing step size for rare characteristics. However, so far, this adaptation has only taken into account the gradients and not the norm of the competitor. At this point, we are closing this gap. \u2212 As shown in [14], these types of algorithms can be designed and analyzed very simply by executing an independent copy of the algorithm on each coordinate. Therefore, we have the following sequence. \u2212 Suppose that the kernel K is linear. \u2212 Let's also assume that the sequence of xt essentially fulfills the xt and that the losses' t convex and L-Lipschitz 't are."}, {"heading": "B Convergence in L1\u03c1X", "text": "Let us now define the standard assumption about the behavior of the approximation error in L1\u03c1X, see e.g. [34]. Theorem 3. Let us assume that the samples (xt, yt) are Tt = 1 IID of \u03c1 and \"t (x) =\" (ytx). If for some 0 < \u03b2 \u2264 1 and C > 0, then the pair (\u03c1, K) satisfies the averaged solution of PiSTOL: E [E '(f'T)] - E' (f '.T) - (f '.T) - E '(f '.T) - (f '.T) - (f '.T) - (f '.T) - O (T \u2212 \u03b2 + 1)."}, {"heading": "C Details about the Empirical Results", "text": "The loss PiSTOL used in all experiments is a smoothed version of the hinge loss: \"(x) = 0 x \u2265 1 (1 \u2212 x) 2 0 < x < 1 1 \u2212 2x x \u2264 0.For the SVM we used the hinge loss. The parameters of PiSTOL were the same in all experiments: a = 0.25, L = 2, \u03b2 = \u221a 2aLT. The a9a dataset consists of 32561 training samples and 16281 for testing, the dimension of the features is 123. The Gaussian core isK (x, x \u2032) = exp (\u2212 \u03b3 x \u2212 x \u2032 22), where it was set to 0.04 as in [19]. The\" C \"parameter of the SVM was set with cross-validation over the range {2 \u2212 1, 20, 22, 23} problem, whereby the GIT dataset was set to 0.04 as in [19]."}, {"heading": "D Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "D.1 Additional Definitions", "text": "With closed and convex function, the fennel conjugate is defined as HK (< f, g > K \u2212 h (f).D.2 Detection of (3) From [35] it is possible to extract the following inequality: E [E '(f) = supf HK (< f, g > K \u2212 h (f).D.2 Detection of (3) \u2264 inf h HK [E' (h) + 2 K 2\u03b7T] + ((((1 \u2212 2) E '(0).Using the elementary inequalities (1 \u2212 2 \u00b0 C) \u2212 1 \u2264 4\u03b7, \u0438 0 < p > 14, we have E [E' (f \u00b2 T)] \u2264 inf h HKE '(h) + 2 \u00b0 C + 4 \u00b0."}, {"heading": "D.3 Proof of Theorem 1", "text": "The key idea is that we design a time-changing potential function (+ 11). Some of the ideas in the proof are derived from [18, 15]. In the proof of Theorem 1 we also use the following technical lemms.Lemma 2. Let a, b, c, c, c, 0. \u00b7 If b > 0, thenexp (2a b + b22c) \u2264 1 + b2 2c (a + b) 2c (a) 2c + 1) exp (2a b + b22c). \u00b7 If b, then exp (2a b + b22c) \u2264 2 + bc 2c (a2 + b2c) exp (b22c).Proof. Consider the function g (b) = exp (a + b) 22c)."}, {"heading": "D.4 Proof of Corollary 1", "text": "We first give the technical results used in the evidences.Lemma 5. [25, Lemma 2.1] For an H-smooth function ': R \u2192 R +, we have (') 2 \u2264 4Hf (x).Lemma 6. [12, Lemma 7.2] Let c1, c2, \u00b7 \u00b7, cl > 0 and s > q1 > q2 > ql \u2212 1 > 0. Then we get the equation \u2212 c1xq1 \u2212 c2xq2 \u2212 \u00b7 \u00b7 \u00b7 \u2212 cl \u2212 1xql \u2212 1 \u2212 cl \u2212 1 and s > q1 x \u00b2 x \u00b2. In addition, x \u2264 max {(lc1) \u2212 q1 \u2212 q1 s \u2212 q2 \u2212 q2 \u2212 q2 \u2212 c2xq2 \u2212 \u00b7 \u00b7 \u00b7, (lcl \u2212 q2), (lcl \u2212 ql \u2212 c \u00b2) results in the quality."}, {"heading": "D.5 Proof of Lemma 1", "text": "Prove that for each f-L2\u03c1X, define Xf = {x-X: character (f) 6 = fc. It is easy to verify that R (f) \u2212 R (fc) = \u0394Xf | f\u03c1 (x) | d\u03c1X (x) = \u0394Xf | f\u03c1 (x) | 1 (f\u03c1 (x) >) d\u03c1X (x) + \u0394Xf | f\u03c1 (x) | 1 (f\u03c1 (x) \u2264 (x) d\u03c1X (x).Using condition (8) we have R (f) \u2212 R (fc) \u2264 1 (fc) | f\u03c1 (x) \u2212 X (x) + \u0394Xf d\u03c1X (21) \u2264 1 (x) | 2d\u03c1X (x) + c\u03b1 (R (f) \u2212 R (fc) \u2212 R (fc). (22) Using Lemma 10.10 in [12] and proceeding as proof for theorem 10.5 in [f]."}, {"heading": "D.6 Proof of Theorem 2", "text": "We need the following technical results: Lemma 8 + p (q) q + p (q) q + p (c) q (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c) c (c) c (c) c (c) c (c) c (c) c) c (c) c) c (c) c (c) c) c (c) c (c) c) c (c) c (c) c) c (c) c (c) c) c (c) c (c) c) c (c) c (c) c (c) c (c) c (c) c (c) c (c) c) c (c) c) c (c) c) c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c) c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c) c) c) c (c) c) c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c) c \"c (c) c) c) c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c"}, {"heading": "D.7 Proof of Theorem 3", "text": "The evidence for Theorem 2 shows that T-T = \u03b2 \u03b2 \u03b2 (2) T b + \u03c6 (a \u2212 1L) log (1 + T) + b-T (a \u2212 1L) log (1 + T).Divide everything by T, take into account the expectation of the two sides, and Jensen's inequality we use E [E '(f \u2212 T)] \u2264 E [1T t = 1E' (ft) \u2264 inf h-HK E '(h) + 1 h-K T \u2212 1 2 \u00b0 s-T \u00b2 2aL log (2 \u2212 12' (0) T b + E (a \u2212 1L) log (1 + T) + 2) + b-K (a \u2212 2L \u2212 h).Denote by D > L + 2a-T (2 \u2212 1L), L-E (1 \u2212 1L), L-T (a \u2212 1L), L-T (1 \u2212 E), L-T (1 \u2212 E), L-T (1 \u2212 E), L-T (1 \u2212 E), L-T (1 \u2212 T), L-T (a \u2212 T)."}], "references": [], "referenceMentions": [], "year": 2014, "abstractText": "<lb>Stochastic gradient descent algorithms for training linear and kernel predictors are gaining more and<lb>more importance, thanks to their scalability. While various methods have been proposed to speed up their<lb>convergence, the model selection phase is often ignored. In fact, in theoretical works most of the time<lb>assumptions are made, for example, on the prior knowledge of the norm of the optimal solution, while in<lb>the practical world validation methods remain the only viable approach. In this paper, we propose a new<lb>kernel-based stochastic gradient descent algorithm that performs model selection while training, with no<lb>parameters to tune, nor any form of cross-validation. The algorithm builds on recent advancement in<lb>online learning theory for unconstrained settings, to estimate over time the right regularization in a data-<lb>dependent way. Optimal rates of convergence are proved under standard smoothness assumptions on the<lb>target function, using the range space of the fractional integral operator associated with the kernel.", "creator": "TeX"}}}