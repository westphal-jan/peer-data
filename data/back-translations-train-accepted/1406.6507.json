{"id": "1406.6507", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Jun-2014", "title": "Weakly-supervised Discovery of Visual Pattern Configurations", "abstract": "The increasing prominence of weakly labeled data nurtures a growing demand for object detection methods that can cope with minimal supervision. We propose an approach that automatically identifies discriminative configurations of visual patterns that are characteristic of a given object class. We formulate the problem as a constrained submodular optimization problem and demonstrate the benefits of the discovered configurations in remedying mislocalizations and finding informative positive and negative training examples. Together, these lead to state-of-the-art weakly-supervised detection results on the challenging PASCAL VOC dataset.", "histories": [["v1", "Wed, 25 Jun 2014 09:35:40 GMT  (7360kb,D)", "http://arxiv.org/abs/1406.6507v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["hyun oh song", "yong jae lee", "stefanie jegelka", "trevor darrell"], "accepted": true, "id": "1406.6507"}, "pdf": {"name": "1406.6507.pdf", "metadata": {"source": "CRF", "title": "Weakly-supervised Discovery of Visual Pattern Configurations", "authors": ["Hyun Oh Song", "Yong Jae Lee", "Stefanie Jegelka", "Trevor Darrell"], "emails": ["song@eecs.berkeley.edu", "yjlee22@eecs.berkeley.edu", "stefje@eecs.berkeley.edu", "trevor@eecs.berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to live, in which they are able to live, in which they want to live, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they live, in which they are able to live, in which they are able to move, in which they are able"}, {"heading": "1.1 Related work", "text": "In fact, it is such that the greater number of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "2 Approach", "text": "The goal is to find a discriminatory set of parts or patches that occur in many of the positively labeled images in the same configuration. We have approached this goal in two steps. First, we find a set of patches that are discriminatory, i.e., they tend to occur mainly in positive images. Second, we use an efficient approach to find common configurations of such patches. We start with a construction similar to that of Song et al. [27] Let P be the set of positively labeled images. Each image contains candidate boxes {bI, 1, m} found via selective search [28]."}, {"heading": "3 Experiments", "text": "In this section, we analyze (1) the performance of the models associated with the mentioned configurations, and (2) the impact of the hard negatives detected on the detection performance. We advocate a new region where the detection characteristics of each region are pronounced. (3) The results of the study show that the detection characteristics of each region are different."}], "references": [{"title": "On detection of multiple object instances using hough transforms", "author": ["O. Barinova", "V. Lempitsky", "P. Kohli"], "venue": "IEEE TPAMI,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Active detection via adaptive submodularity", "author": ["Y. Chen", "H. Shioi", "C. Fuentes-Montesinos", "L. Koh", "S. Wich", "A. Krause"], "venue": "ICML,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2014}, {"title": "What Makes Paris Look like Paris", "author": ["C. Doersch", "S. Singh", "A. Gupta", "J. Sivic", "A.A. Efros"], "venue": "In SIGGRAPH,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "arXiv e-prints, arXiv:1310.1531 [cs.CV],", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Clustering by Composition Unsupervised Discovery of Image Categories", "author": ["A. Faktor", "M. Irani"], "venue": "ECCV,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2012}, {"title": "Recognition Using Visual Phrases", "author": ["A. Farhadi", "A. Sadeghi"], "venue": "CVPR,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "A Discriminatively Trained, Multiscale, Deformable Part Model", "author": ["P. Felzenszwalb", "D. McAllester", "D. Ramanan"], "venue": "CVPR,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2008}, {"title": "Object Detection with Discriminatively Trained Part Based Models", "author": ["P. Felzenszwalb", "R. Girshick", "D. McAllester", "D. Ramanan"], "venue": "TPAMI, 32(9),", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Object Class Recognition by Unsupervised Scale-Invariant Learning", "author": ["R. Fergus", "P. Perona", "A. Zisserman"], "venue": "CVPR,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2003}, {"title": "An analysis of approximations for maximizing submodular set functions - II", "author": ["M. Fisher", "G. Nemhauser", "L. Wolsey"], "venue": "Math. Prog. Study, 8:73\u201387,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1978}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "arXiv e-prints,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised learning of categories from sets of partially matching image features", "author": ["K. Grauman", "T. Darrell"], "venue": "CVPR,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "The efficacy of the \u201cgreedy\u201d algorithm", "author": ["T. Jenkyns"], "venue": "Proc. of 7th South Eastern Conference on Combinatorics, Graph Theory and Computing, pages 341\u2013350,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1976}, {"title": "Blocks that Shout: Distinctive Parts for Scene Classification", "author": ["M. Juneja", "A. Vedaldi", "C.V. Jawahar", "A. Zisserman"], "venue": "CVPR,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I.S.G. Hinton"], "venue": "NIPS,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2012}, {"title": "Foreground Focus: Unsupervised Learning From Partially Matching Images", "author": ["Y.J. Lee", "K. Grauman"], "venue": "IJCV, 85,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Automatic Discovery of Groups of Objects for Scene Understanding", "author": ["C. Li", "D. Parikh", "T. Chen"], "venue": "CVPR,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "An analysis of approximations for maximizing submodular set functions\u2014I", "author": ["G. Nemhauser", "L. Wolsey", "M. Fisher"], "venue": "Mathematical Programming, 14(1):265\u2013294,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1978}, {"title": "Scene recognition and weakly supervised object localization with deformable part-based models", "author": ["M. Pandey", "S. Lazebnik"], "venue": "ICCV,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2011}, {"title": "From Appearance to Context-Based Recognition: Dense Labeling in Small Images", "author": ["D. Parikh", "C.L. Zitnick", "T. Chen"], "venue": "CVPR,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient Mining of Frequent and Distinctive Feature Configurations", "author": ["T. Quack", "V. Ferrari", "B. Leibe", "L.V. Gool"], "venue": "ICCV,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Unsupervised Discovery of Mid-level Discriminative Patches", "author": ["S. Singh", "A. Gupta", "A.A. Efros"], "venue": "ECCV,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2012}, {"title": "Weakly supervised object detector learning with model drift detection", "author": ["P. Siva", "T. Xiang"], "venue": "ICCV,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}, {"title": "In defence of negative mining for annotating weakly labelled data", "author": ["P. Siva", "C. Russell", "T. Xiang"], "venue": "ECCV,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2012}, {"title": "Video Data Mining Using Configurations of Viewpoint Invariant Regions", "author": ["J. Sivic", "A. Zisserman"], "venue": "CVPR,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2004}, {"title": "Discovering object categories in image collections", "author": ["J. Sivic", "B.Russell", "A.Efros", "A.Zisserman", "W.Freeman"], "venue": "In ICCV,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2005}, {"title": "On learning to localize objects with minimal supervision", "author": ["H.O. Song", "R. Girshick", "S. Jegelka", "J. Mairal", "Z. Harchaoui", "T. Darrell"], "venue": "ICML,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Selective search for object recognition", "author": ["J. Uijlings", "K. van de Sande", "T. Gevers", "A. Smeulders"], "venue": "In IJCV,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "On an estimate of the chromatic class of a p-graph", "author": ["V. Vizing"], "venue": "Diskret. Analiz., 3:25\u201330,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1964}, {"title": "Unsupervised Learning of Models for Recognition", "author": ["M. Weber", "M. Welling", "P. Perona"], "venue": "ECCV,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2000}, {"title": "Efficient Kernels for Identifying Unbounded-order Spatial Features", "author": ["Y. Zhang", "T. Chen"], "venue": "CVPR,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2009}, {"title": "Contrastive learning using spectral methods", "author": ["J. Zou", "D. Hsu", "D. Parkes", "R. Adams"], "venue": "NIPS,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 29, "context": "Early ideas for weakly supervised detection [30, 9] paved the way by successfully learning part-based object models, albeit on simple object-centric datasets (e.", "startOffset": 44, "endOffset": 51}, {"referenceID": 8, "context": "Early ideas for weakly supervised detection [30, 9] paved the way by successfully learning part-based object models, albeit on simple object-centric datasets (e.", "startOffset": 44, "endOffset": 51}, {"referenceID": 18, "context": "Since then, a number of approaches [19, 24, 27] have attempted to learn models on more realistic and challenging data sets that feature large intra-category appearance variations and background clutter.", "startOffset": 35, "endOffset": 47}, {"referenceID": 23, "context": "Since then, a number of approaches [19, 24, 27] have attempted to learn models on more realistic and challenging data sets that feature large intra-category appearance variations and background clutter.", "startOffset": 35, "endOffset": 47}, {"referenceID": 26, "context": "Since then, a number of approaches [19, 24, 27] have attempted to learn models on more realistic and challenging data sets that feature large intra-category appearance variations and background clutter.", "startOffset": 35, "endOffset": 47}, {"referenceID": 26, "context": "To identify such patches, we use a discriminative covering formulation similar to [27].", "startOffset": 82, "endOffset": 86}, {"referenceID": 7, "context": ", [8]).", "startOffset": 2, "endOffset": 5}, {"referenceID": 29, "context": "To reduce laborious bounding box annotation costs, recent weakly-supervised approaches [30, 9, 19, 24, 27] train detectors using binary object-presence labels without any object-location information.", "startOffset": 87, "endOffset": 106}, {"referenceID": 8, "context": "To reduce laborious bounding box annotation costs, recent weakly-supervised approaches [30, 9, 19, 24, 27] train detectors using binary object-presence labels without any object-location information.", "startOffset": 87, "endOffset": 106}, {"referenceID": 18, "context": "To reduce laborious bounding box annotation costs, recent weakly-supervised approaches [30, 9, 19, 24, 27] train detectors using binary object-presence labels without any object-location information.", "startOffset": 87, "endOffset": 106}, {"referenceID": 23, "context": "To reduce laborious bounding box annotation costs, recent weakly-supervised approaches [30, 9, 19, 24, 27] train detectors using binary object-presence labels without any object-location information.", "startOffset": 87, "endOffset": 106}, {"referenceID": 26, "context": "To reduce laborious bounding box annotation costs, recent weakly-supervised approaches [30, 9, 19, 24, 27] train detectors using binary object-presence labels without any object-location information.", "startOffset": 87, "endOffset": 106}, {"referenceID": 29, "context": "Early efforts [30, 9] focused on simple datasets that have a single prominent object in each image (e.", "startOffset": 14, "endOffset": 21}, {"referenceID": 8, "context": "Early efforts [30, 9] focused on simple datasets that have a single prominent object in each image (e.", "startOffset": 14, "endOffset": 21}, {"referenceID": 18, "context": "More recent approaches [19, 24, 27] focus on the more challenging PASCAL dataset, which contains multiple objects in each image and large intra-category appearance variations.", "startOffset": 23, "endOffset": 35}, {"referenceID": 23, "context": "More recent approaches [19, 24, 27] focus on the more challenging PASCAL dataset, which contains multiple objects in each image and large intra-category appearance variations.", "startOffset": 23, "endOffset": 35}, {"referenceID": 26, "context": "More recent approaches [19, 24, 27] focus on the more challenging PASCAL dataset, which contains multiple objects in each image and large intra-category appearance variations.", "startOffset": 23, "endOffset": 35}, {"referenceID": 26, "context": "[27] achieve state-of-the-art results by finding discriminative image patches that occur frequently in the positive images but rarely in the negative images using deep Convolutional Neural Network (CNN) features [15] and a submodular cover formulation.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[27] achieve state-of-the-art results by finding discriminative image patches that occur frequently in the positive images but rarely in the negative images using deep Convolutional Neural Network (CNN) features [15] and a submodular cover formulation.", "startOffset": 212, "endOffset": 216}, {"referenceID": 26, "context": "But, contrary to [27] who assume patches to contain entire objects, we allow patches to contain full objects or merely object parts.", "startOffset": 17, "endOffset": 21}, {"referenceID": 25, "context": "Existing approaches discover high-level object categories [26, 12, 5], mid-level patches [22, 3, 14], or low-level foreground features [16] by grouping similar visual patterns (i.", "startOffset": 58, "endOffset": 69}, {"referenceID": 11, "context": "Existing approaches discover high-level object categories [26, 12, 5], mid-level patches [22, 3, 14], or low-level foreground features [16] by grouping similar visual patterns (i.", "startOffset": 58, "endOffset": 69}, {"referenceID": 4, "context": "Existing approaches discover high-level object categories [26, 12, 5], mid-level patches [22, 3, 14], or low-level foreground features [16] by grouping similar visual patterns (i.", "startOffset": 58, "endOffset": 69}, {"referenceID": 21, "context": "Existing approaches discover high-level object categories [26, 12, 5], mid-level patches [22, 3, 14], or low-level foreground features [16] by grouping similar visual patterns (i.", "startOffset": 89, "endOffset": 100}, {"referenceID": 2, "context": "Existing approaches discover high-level object categories [26, 12, 5], mid-level patches [22, 3, 14], or low-level foreground features [16] by grouping similar visual patterns (i.", "startOffset": 89, "endOffset": 100}, {"referenceID": 13, "context": "Existing approaches discover high-level object categories [26, 12, 5], mid-level patches [22, 3, 14], or low-level foreground features [16] by grouping similar visual patterns (i.", "startOffset": 89, "endOffset": 100}, {"referenceID": 15, "context": "Existing approaches discover high-level object categories [26, 12, 5], mid-level patches [22, 3, 14], or low-level foreground features [16] by grouping similar visual patterns (i.", "startOffset": 135, "endOffset": 139}, {"referenceID": 2, "context": "Recent methods [3, 14] use weakly-supervised labels to discover discriminative visual patterns.", "startOffset": 15, "endOffset": 22}, {"referenceID": 13, "context": "Recent methods [3, 14] use weakly-supervised labels to discover discriminative visual patterns.", "startOffset": 15, "endOffset": 22}, {"referenceID": 0, "context": "Covering formulations have also been used in [1, 2], but after running a trained object detector.", "startOffset": 45, "endOffset": 51}, {"referenceID": 1, "context": "Covering formulations have also been used in [1, 2], but after running a trained object detector.", "startOffset": 45, "endOffset": 51}, {"referenceID": 31, "context": "An alternative discriminative approach, but less scalable than covering, uses spectral methods [32].", "startOffset": 95, "endOffset": 99}, {"referenceID": 29, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 8, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 24, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 20, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 30, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 15, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 7, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 5, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 21, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 16, "context": "Modeling the spatial and geometric relationship between co-occurring visual patterns (objects or object-parts) often improves visual recognition performance [30, 9, 25, 21, 31, 16, 8, 6, 22, 17].", "startOffset": 157, "endOffset": 194}, {"referenceID": 21, "context": "Co-occurring patterns are usually represented as doublets [22], higher-order constellations [30, 9] or star-shaped models [8].", "startOffset": 58, "endOffset": 62}, {"referenceID": 29, "context": "Co-occurring patterns are usually represented as doublets [22], higher-order constellations [30, 9] or star-shaped models [8].", "startOffset": 92, "endOffset": 99}, {"referenceID": 8, "context": "Co-occurring patterns are usually represented as doublets [22], higher-order constellations [30, 9] or star-shaped models [8].", "startOffset": 92, "endOffset": 99}, {"referenceID": 7, "context": "Co-occurring patterns are usually represented as doublets [22], higher-order constellations [30, 9] or star-shaped models [8].", "startOffset": 122, "endOffset": 125}, {"referenceID": 29, "context": "Among these, our work is most inspired by [30, 9], which learns part-based models using only weak-supervision.", "startOffset": 42, "endOffset": 49}, {"referenceID": 8, "context": "Among these, our work is most inspired by [30, 9], which learns part-based models using only weak-supervision.", "startOffset": 42, "endOffset": 49}, {"referenceID": 16, "context": "Our work is also related by [17], which discovers high-level object compositions (\u201cvisual phrases\u201d [6]) using ground-truth bounding box annotations.", "startOffset": 28, "endOffset": 32}, {"referenceID": 5, "context": "Our work is also related by [17], which discovers high-level object compositions (\u201cvisual phrases\u201d [6]) using ground-truth bounding box annotations.", "startOffset": 99, "endOffset": 102}, {"referenceID": 16, "context": "In contrast to [17], we aim to discover part compositions to represent full objects and do so without any bounding box annotations.", "startOffset": 15, "endOffset": 19}, {"referenceID": 26, "context": "[27].", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": ", bI,m} found via selective search [28].", "startOffset": 35, "endOffset": 39}, {"referenceID": 26, "context": "To identify a small, diverse and representative set of such patches, like [27], we construct a bipartite graph G = (U ,V, E), where both U and V contain copies of B(P).", "startOffset": 74, "endOffset": 78}, {"referenceID": 17, "context": "The function F is monotone and submodular, and the C maximizing elements (for a given C) can be selected greedily [18].", "startOffset": 114, "endOffset": 118}, {"referenceID": 26, "context": "Therefore, we take a different approach, differing from [27] whose goal is to identify single patches, and not part-based configurations.", "startOffset": 56, "endOffset": 60}, {"referenceID": 2, "context": "This notion of diversity is reminiscent of NMS and similar to that in [3], but we here phrase and analyze it as a constrained submodular optimization problem.", "startOffset": 70, "endOffset": 73}, {"referenceID": 9, "context": "With this insight, the approximation factor of the greedy algorithm for submodular F follows from [10] and that for non-intersecting \u0393(b) from [13], since in the latter case the problem is that of finding a maximum weight vector in the intersection of \u2206 + 1 matroids.", "startOffset": 98, "endOffset": 102}, {"referenceID": 12, "context": "With this insight, the approximation factor of the greedy algorithm for submodular F follows from [10] and that for non-intersecting \u0393(b) from [13], since in the latter case the problem is that of finding a maximum weight vector in the intersection of \u2206 + 1 matroids.", "startOffset": 143, "endOffset": 147}, {"referenceID": 28, "context": "By Vizing\u2019s theorem [29], we need at most \u2206 + 1 colors.", "startOffset": 20, "endOffset": 24}, {"referenceID": 16, "context": "Our approach is inspired by [17], but does not require any supervision.", "startOffset": 28, "endOffset": 32}, {"referenceID": 7, "context": "In addition, we mine negative examples as in [8].", "startOffset": 45, "endOffset": 48}, {"referenceID": 7, "context": "Our final detector is trained on this augmented training data, and iteratively improved by latent SVM (LSVM) updates (see [8, 27] for details).", "startOffset": 122, "endOffset": 129}, {"referenceID": 26, "context": "Our final detector is trained on this augmented training data, and iteratively improved by latent SVM (LSVM) updates (see [8, 27] for details).", "startOffset": 122, "endOffset": 129}, {"referenceID": 10, "context": "We employ a recent region based detection framework [11, 27] and use the same fc7 features from the CNN model [4] on region proposals [28] throughout the experiment.", "startOffset": 52, "endOffset": 60}, {"referenceID": 26, "context": "We employ a recent region based detection framework [11, 27] and use the same fc7 features from the CNN model [4] on region proposals [28] throughout the experiment.", "startOffset": 52, "endOffset": 60}, {"referenceID": 3, "context": "We employ a recent region based detection framework [11, 27] and use the same fc7 features from the CNN model [4] on region proposals [28] throughout the experiment.", "startOffset": 110, "endOffset": 113}, {"referenceID": 27, "context": "We employ a recent region based detection framework [11, 27] and use the same fc7 features from the CNN model [4] on region proposals [28] throughout the experiment.", "startOffset": 134, "endOffset": 138}, {"referenceID": 19, "context": "More details regarding be transform space binning can be found in [20].", "startOffset": 66, "endOffset": 70}, {"referenceID": 22, "context": "[23] 13.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] 27.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "direct comparison with the state-of-the-art weakly-supervised object detection method [27], we do not use the extra instance level annotations such as pose, difficult, truncated and restrict the supervision to the image level object presence annotations.", "startOffset": 86, "endOffset": 90}, {"referenceID": 22, "context": "Table 1 compares our detection results against two baseline methods [23, 27] which report the result on the full dataset.", "startOffset": 68, "endOffset": 76}, {"referenceID": 26, "context": "Table 1 compares our detection results against two baseline methods [23, 27] which report the result on the full dataset.", "startOffset": 68, "endOffset": 76}, {"referenceID": 26, "context": "Green: our method, Red: [27]", "startOffset": 24, "endOffset": 28}, {"referenceID": 6, "context": "To analyze the effect of our discovered hard negatives, we compare to two baseline cases: (1) not adding any negative examples from positives images (2) adding image regions around the foreground estimate as conventionally implemented in fully supervised object detection algorithms [7, 11].", "startOffset": 283, "endOffset": 290}, {"referenceID": 10, "context": "To analyze the effect of our discovered hard negatives, we compare to two baseline cases: (1) not adding any negative examples from positives images (2) adding image regions around the foreground estimate as conventionally implemented in fully supervised object detection algorithms [7, 11].", "startOffset": 283, "endOffset": 290}, {"referenceID": 10, "context": "We use the criterion from [11], where all image regions in positive images with overlap score (intersection area over union area with respect to foreground regions) less than 0.", "startOffset": 26, "endOffset": 30}], "year": 2014, "abstractText": "The increasing prominence of weakly labeled data nurtures a growing demand for object detection methods that can cope with minimal supervision. We propose an approach that automatically identifies discriminative configurations of visual patterns that are characteristic of a given object class. We formulate the problem as a constrained submodular optimization problem and demonstrate the benefits of the discovered configurations in remedying mislocalizations and finding informative positive and negative training examples. Together, these lead to state-of-the-art weakly-supervised detection results on the challenging PASCAL VOC dataset.", "creator": "LaTeX with hyperref package"}}}