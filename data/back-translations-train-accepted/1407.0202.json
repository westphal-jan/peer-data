{"id": "1407.0202", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jul-2014", "title": "SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives", "abstract": "In this work we introduce a new optimisation method called SAGA in the spirit of SAG, SDCA, MISO and SVRG, a set of recently proposed incremental gradient algorithms with fast linear convergence rates. SAGA improves on the theory behind SAG and SVRG, with better theoretical convergence rates, and has support for composite objectives where a proximal operator is used on the regulariser. Unlike SDCA, SAGA supports non-strongly convex problems directly, and is adaptive to any inherent strong convexity of the problem. We give experimental results showing the effectiveness of our method.", "histories": [["v1", "Tue, 1 Jul 2014 11:47:56 GMT  (715kb,D)", "https://arxiv.org/abs/1407.0202v1", null], ["v2", "Tue, 22 Jul 2014 06:57:50 GMT  (716kb,D)", "http://arxiv.org/abs/1407.0202v2", null], ["v3", "Tue, 16 Dec 2014 08:44:27 GMT  (725kb,D)", "http://arxiv.org/abs/1407.0202v3", "Advances In Neural Information Processing Systems, Nov 2014, Montreal, Canada"]], "reviews": [], "SUBJECTS": "cs.LG math.OC stat.ML", "authors": ["aaron defazio", "francis r bach", "simon lacoste-julien"], "accepted": true, "id": "1407.0202"}, "pdf": {"name": "1407.0202.pdf", "metadata": {"source": "CRF", "title": "SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives", "authors": ["Aaron Defazio"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Remarkably, recent advances [1, 2] have shown that it is possible to minimize strongly convex finite sums demonstrably faster in anticipation than is possible without the finite sum structure. This is significant for machine learning problems as finite sum structure is common in empirical risk minimization. The requirement of strong convexity is also met in typical cases where square regularization is used. In particular, we are interested in minimizing functions of the format (x) = 1 fi (x), in which x, each fi convex is convex and Lipschitz is continuous derivatives with constant L. We will also consider the case in which each fi is strongly convex with constant \u00b5, and the \"composite\" (or proximal) case in which an additional regulation function is added: F (x) + h (x).Rd convex."}, {"heading": "2 SAGA Algorithm", "text": "We start with some known initial vectors x0-Rd and known derivatives f \"i\" i \"i\" j \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"These derivatives are stored in a table with a data structure of length n,\" or alternatively in an n \"d\" matrix. SAGA is inspired by both SAG [1] and SVRG [5] (as we will discuss in Section 3). SAGA uses a step size of \"x\" and makes the following updates, starting with k = 0: SAGA algorithm: Given the value of xk and the individual f \"i\" i \"i\" at the end of the iteration k. \""}, {"heading": "3 Related Work", "text": "We explore the relationship between SAGA and the other fast incremental gradient methods in this section in order to use constant gradient rates. By using SAGA as the centerpoint, we are able to provide a more consistent view than is available in the existing literature. A brief summary of the properties of each method considered in this section is shown in Figure 1. The method from [3] that handles the non-compositional setting is not listed, as its rate is of the slow nature and can be up to n times smaller than that for SAGA or SVRG [5]. SAGA: centerpoint between SAG and SVRG / S2GDIn [5] makes the authors observe that the variance of the standard stochastic gradient (SGD) can only go to zero when decreasing step sizes are used, thus preventing a linear convergence rate as opposed to batch gradient methods. Therefore, you suggest using an update method (see S7 and SD) to use a runtime reduction."}, {"heading": "4 Implementation", "text": "We briefly discuss some implementation concerns: \u2022 For many problems, each f'i derivative is just a simple weighting of the ith data vector. Logistic regression and smallest squares have this property. Instead of storing the full f'i derivative for each i, we only need to store the weighting constants, which reduces the memory requirements in the same way as the SDCA method does in practice. A similar trick can be applied to multi-class classifiers with p classes by storing p \u2212 1 values for each i. \u2022 Our algorithm assumes that initial gradients are known for each fi at source x0. Instead, a heuristic method can be applied in which data points are introduced in a non-randomized order during the first pass, with averages calculated in relation to these data points being processed as widely."}, {"heading": "5 Theory", "text": "In this section, all expectations regarding the choice of j in the iteration k + 1 and conditioned by xk and each f + i (unless otherwise stated) are taken into account. We start with two basic lexicographies that simply specify the properties of the convex functions, followed by Lemma 1, which is specific to our algorithm. Evidence for each of these lexicographies is contained in the supplementary material, leaving f (x) = 1n x (x) = 1n x (x). Each fi is strongly convex and has Lipschitz continuous engravings with constant L. Then for all x and x x x (x): f (x): f (x), f \u2212 p (f (x)]] - f (x) \u2212 f \u2212 f (x) - and Lipschitz (v (v) - and has Lipschitz continuous graditions with constant L. Then for all x and x x x (x): f (x), f \u2212 f \u2212 f (x)."}, {"heading": "6 Experiments", "text": "We tested a binary classifier on MNIST, COVTYPE, IJCNN1, and a minimum square predictor on MILLIONSONG. Details of these data sets can be found in [9]. We used the same code base for each method and only changed the main rule for updates. SVRG was tested with the recalibration pass used for each n iteration, as proposed in [8]. Each method had chosen its step size to give the fastest convergence, we tested with an L2 regulator that all methods support, and with an L1 regulator on a subset of methods. The results are shown in Figure 2. We can see that Finito (perm) yields the best performance on an epoch-equivalent basis, but it may be the most expensive method per SCRG. SVRG is similarly fast on an epoch, but if the number of steps A is considered more like the double-A method, it may be more likely to be the result of the double-A method."}, {"heading": "A The SDCA/Finito Midpoint Algorithm", "text": "Using Lagrange's duality theory, SDCA can be shown at step k as minimizing the following lower limit: Ak (x) = 1n fj (x) + 1n \u2211 i 6 = j [fi (\u03c6 k i) + f \u2032 i (\u03c6 k i), x \u2212 \u03c6ki] + \u00b5 2 x 2. Instead of directly involving the regulator in this limit, we can use the default strong convexity, which is lower for each fi, by removing the \u00b52 x-2 condition and changing the expression in the summation to fi (\u03c6 k i) + f \u2032 i (\u03c6 k i). Transforming it into a strong convexity within the fi functions also results in the following simple modification of the algorithm: Er + 1j = prox-fi = prox-1 is equal."}, {"heading": "B Lemmas", "text": "Lemma 4: \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"f\" - \"-\" f \"-\" f \"-\" - \"f\" - \"f\" - \"-\" f - \"f -\" - \"f -\" f - \"-\" f - \"-\" f - \"-\" f - \"-\" - \"f -\" - \"-\" f - \"-\" - \"f -\" - \"-\" f - \"-\" - \"-\" - \"f -\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-"}, {"heading": "C Non-strongly-convex Problems", "text": "Theorem 2: If every fi is convex then we have x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "D Example Code for Sparse Least Squares & Ridge Regression", "text": "The SAGA method is fairly easy to implement, however, is the implementation for the rare running form = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = long = = long = = long = = long = long = long = = = long = = = long = = = = = long = long = = = = long = = = long = = = = = long = = = = = long = = = long = = = = long = = = = = = = long = = = = = long = = = = = = long = = = = = = = = = = = long = = = = = = long = long = = = = = = = = = long = = = = = = long = = = = = = long = = = = = = = = = = = = long = = = = = = = = = = = = = = = = = = = long = = = = = = = = = = = = = = = = = = = = = = = = = = = = long = = = = = = = = = = = = = = = = = = long = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}], "references": [{"title": "Minimizing finite sums with the stochastic average gradient", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "Technical report, INRIA,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "JMLR, 14:567\u2013599,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Incrementally updated gradient methods for constrained and regularized optimization", "author": ["Paul Tseng", "Sangwoon Yun"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "A proximal stochastic gradient method with progressive variance reduction", "author": ["Lin Xiao", "Tong Zhang"], "venue": "Technical report,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Stochastic dual coordinate ascent with alternating direction method of multipliers", "author": ["Taiji Suzuki"], "venue": "Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Variance reduction techniques for gradient estimates in reinforcement learning", "author": ["Evan Greensmith", "Peter L. Bartlett", "Jonathan Baxter"], "venue": "JMLR, 5:1471\u20131530,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Semi-stochastic gradient descent methods", "author": ["Jakub Kone\u010dn\u00fd", "Peter Richt\u00e1rik"], "venue": "ArXiv e-prints,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Finito: A faster, permutable incremental gradient method for big data problems", "author": ["Aaron Defazio", "Tiberio Caetano", "Justin Domke"], "venue": "Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Incremental majorization-minimization optimization with application to largescale machine learning", "author": ["Julien Mairal"], "venue": "Technical report, INRIA Grenoble Rho\u0302ne-Alpes / LJK Laboratoire Jean Kuntzmann,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Technical report,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Proximal Splitting Methods in Signal Processing. In Fixed-Point Algorithms for Inverse Problems in Science and Engineering", "author": ["Patrick Combettes", "Jean-Christophe Pesquet"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "1 Introduction Remarkably, recent advances [1, 2] have shown that it is possible to minimise strongly convex finite sums provably faster in expectation than is possible without the finite sum structure.", "startOffset": 43, "endOffset": 49}, {"referenceID": 1, "context": "1 Introduction Remarkably, recent advances [1, 2] have shown that it is possible to minimise strongly convex finite sums provably faster in expectation than is possible without the finite sum structure.", "startOffset": 43, "endOffset": 49}, {"referenceID": 2, "context": "We will also consider the case where each fi is strongly convex with constant \u03bc, and the \u201ccomposite\u201d (or proximal) case where an additional regularisation function is added: F (x) = f(x) + h(x), where h : R \u2192 R is convex but potentially non-differentiable, and where the proximal operation of h is easy to compute \u2014 few incremental gradient methods are applicable in this setting [3][4].", "startOffset": 380, "endOffset": 383}, {"referenceID": 3, "context": "We will also consider the case where each fi is strongly convex with constant \u03bc, and the \u201ccomposite\u201d (or proximal) case where an additional regularisation function is added: F (x) = f(x) + h(x), where h : R \u2192 R is convex but potentially non-differentiable, and where the proximal operation of h is easy to compute \u2014 few incremental gradient methods are applicable in this setting [3][4].", "startOffset": 383, "endOffset": 386}, {"referenceID": 0, "context": "In Section 5 we prove theoretical convergence rates for SAGA in the strongly convex case better than those for SAG [1] and SVRG [5], and a factor of 2 from the SDCA [2] convergence rates.", "startOffset": 115, "endOffset": 118}, {"referenceID": 4, "context": "In Section 5 we prove theoretical convergence rates for SAGA in the strongly convex case better than those for SAG [1] and SVRG [5], and a factor of 2 from the SDCA [2] convergence rates.", "startOffset": 128, "endOffset": 131}, {"referenceID": 1, "context": "In Section 5 we prove theoretical convergence rates for SAGA in the strongly convex case better than those for SAG [1] and SVRG [5], and a factor of 2 from the SDCA [2] convergence rates.", "startOffset": 165, "endOffset": 168}, {"referenceID": 0, "context": "SAGA is inspired both from SAG [1] and SVRG [5] (as we will discuss in Section 3).", "startOffset": 31, "endOffset": 34}, {"referenceID": 4, "context": "SAGA is inspired both from SAG [1] and SVRG [5] (as we will discuss in Section 3).", "startOffset": 44, "endOffset": 47}, {"referenceID": 2, "context": "The method from [3], which handles the non-composite setting, is not listed as its rate is of the slow type and can be up to n times smaller than the one for SAGA or SVRG [5].", "startOffset": 16, "endOffset": 19}, {"referenceID": 4, "context": "The method from [3], which handles the non-composite setting, is not listed as its rate is of the slow type and can be up to n times smaller than the one for SAGA or SVRG [5].", "startOffset": 171, "endOffset": 174}, {"referenceID": 5, "context": "3 ? 3[6] 3 7 Non-smooth 7 7 3 7 7 Low Storage Cost 7 7 7 3 7 Simple(-ish) Proof 3 7 3 3 3 Adaptive to SC 3 3 7 ? ? Figure 1: Basic summary of method properties.", "startOffset": 5, "endOffset": 8}, {"referenceID": 4, "context": "In [5], the authors make the observation that the variance of the standard stochastic gradient (SGD) update direction can only go to zero if decreasing step sizes are used, thus preventing a linear convergence rate unlike for batch gradient descent.", "startOffset": 3, "endOffset": 6}, {"referenceID": 6, "context": "They thus propose to use a variance reduction approach (see [7] and references therein for example) on the SGD update in order to be able to use constant step sizes and get a linear convergence rate.", "startOffset": 60, "endOffset": 63}, {"referenceID": 0, "context": "They also mention that SAG (Stochastic Average Gradient) [1] can be interpreted as reducing the variance, though they do not provide the specifics.", "startOffset": 57, "endOffset": 60}, {"referenceID": 0, "context": "One variance reduction approach is to use the following estimator \u03b8\u03b1 as an approximation to EX: \u03b8\u03b1 := \u03b1(X\u2212Y )+EY , for a step size \u03b1 \u2208 [0, 1].", "startOffset": 135, "endOffset": 141}, {"referenceID": 7, "context": "The S2GD method [8] has the same update as SVRG, just differing in how the number of inner loop iterations is chosen.", "startOffset": 16, "endOffset": 19}, {"referenceID": 8, "context": "We now describe how the Finito [9] and MISO\u03bc [10] methods are closely related to SAGA.", "startOffset": 31, "endOffset": 34}, {"referenceID": 9, "context": "We now describe how the Finito [9] and MISO\u03bc [10] methods are closely related to SAGA.", "startOffset": 45, "endOffset": 49}, {"referenceID": 9, "context": "MISO has proven support for proximal operators only in the case where impractically small step sizes are used [10].", "startOffset": 110, "endOffset": 114}, {"referenceID": 1, "context": "SDCA The Stochastic Dual Coordinate Descent (SDCA) [2] method on the surface appears quite different from the other methods considered.", "startOffset": 51, "endOffset": 54}, {"referenceID": 10, "context": "1 Firstly, note that while SDCA was originally described for onedimensional outputs (binary classification or regression), it has been expanded to cover the multiclass predictor case [11] (called Prox-SDCA there).", "startOffset": 183, "endOffset": 187}, {"referenceID": 10, "context": "As noted by Shalev-Shwartz & Zhang [11], the update (9) is actually an instance of the proximal operator of the convex conjugate of fj .", "startOffset": 35, "endOffset": 39}, {"referenceID": 11, "context": "The same trick is commonly used to interpret Dijkstra\u2019s set intersection as a primal algorithm instead of a dual block coordinate descent algorithm [12].", "startOffset": 148, "endOffset": 152}, {"referenceID": 10, "context": "SDCA variants The SDCA theory has been expanded to cover a number of other methods of performing the coordinate step [11].", "startOffset": 117, "endOffset": 121}, {"referenceID": 0, "context": "The variants differ in how \u03b2 \u2208 [0, 1] is chosen.", "startOffset": 31, "endOffset": 37}, {"referenceID": 10, "context": "Variant 5 by Shalev-Shwartz & Zhang [11] does not require operations on the conjugate function, it simply uses \u03b2 = \u03bcn L+\u03bcn .", "startOffset": 36, "endOffset": 40}, {"referenceID": 0, "context": "This procedure has been successfully used with SAG [1].", "startOffset": 51, "endOffset": 54}, {"referenceID": 0, "context": "A just-intime updating of u or x may be performed just as is suggested for SAG [1], which ensures that only sparse updates are done at each iteration.", "startOffset": 79, "endOffset": 82}, {"referenceID": 8, "context": "Details of these datasets can be found in [9].", "startOffset": 42, "endOffset": 45}, {"referenceID": 7, "context": "SVRG was tested with the recalibration pass used every n iterations, as suggested in [8].", "startOffset": 85, "endOffset": 88}], "year": 2014, "abstractText": "In this work we introduce a new optimisation method called SAGA in the spirit of SAG, SDCA, MISO and SVRG, a set of recently proposed incremental gradient algorithms with fast linear convergence rates. SAGA improves on the theory behind SAG and SVRG, with better theoretical convergence rates, and has support for composite objectives where a proximal operator is used on the regulariser. Unlike SDCA, SAGA supports non-strongly convex problems directly, and is adaptive to any inherent strong convexity of the problem. We give experimental results showing the effectiveness of our method.", "creator": "LaTeX with hyperref package"}}}