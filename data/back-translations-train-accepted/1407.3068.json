{"id": "1407.3068", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jul-2014", "title": "Deep Networks with Internal Selective Attention through Feedback Connections", "abstract": "Traditional convolutional neural networks (CNN) are stationary and feedforward. They neither change their parameters during evaluation nor use feedback from higher to lower layers. Real brains, however, do. So does our Deep Attention Selective Network (dasNet) architecture. DasNets feedback structure can dynamically alter its convolutional filter sensitivities during classification. It harnesses the power of sequential processing to improve classification performance, by allowing the network to iteratively focus its internal attention on some of its convolutional filters. Feedback is trained through direct policy search in a huge million-dimensional parameter space, through scalable natural evolution strategies (SNES). On the CIFAR-10 and CIFAR-100 datasets, dasNet outperforms the previous state-of-the-art model.", "histories": [["v1", "Fri, 11 Jul 2014 08:56:54 GMT  (954kb)", "https://arxiv.org/abs/1407.3068v1", "13 pages, 3 figures"], ["v2", "Mon, 28 Jul 2014 08:22:50 GMT  (955kb)", "http://arxiv.org/abs/1407.3068v2", "13 pages, 3 figures"]], "COMMENTS": "13 pages, 3 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["marijn f stollenga", "jonathan masci", "faustino j gomez", "j\u00fcrgen schmidhuber"], "accepted": true, "id": "1407.3068"}, "pdf": {"name": "1407.3068.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["marijn@idsia.ch*,", "jonathan@idsia.ch*,", "tino@idsia.ch", "juergen@idsia.ch"], "sections": [{"heading": null, "text": "ar Xiv: 140 7,30 68v2 [cs.C"}, {"heading": "1 Introduction", "text": "In recent years, it has become clear that the different species we know are not only humans, but also people who are able to identify themselves. (In recent years, it has been shown that the species we know are humans.) This architecture consists of many stacked forward layers that mimic the bottom-up path of the human visual cortex, in which each layer learns increasingly abstract representations of the input data. (In the lower layers, the levels tend to learn biologically plausible features, such as gabor filters [17]. Detectors in higher layers learn to react to specific visual objects or their parts, e.g. [18-21]. Once trained, CNN never changes its weights or filters during evaluation. Evolution has found efficient ways to detect certain objects in the eye of an expert."}, {"heading": "2 Maxout Networks", "text": "In this paper, we use the Maxout networks [10], combined with dropout [27], as the underlying model for theNet. Maxout networks represent the state of the art for object detection in various tasks and have only been exceeded (by a small margin) by averaging several Convolutionary Neural Networks. A similar approach, which does not reduce dimensionality in favor of thrift in representation, was also recently presented [28]. Maxout CNNs consist of a stack of alternating Convolutionary and Maxout layers, with a final classification layer on top: Convolutional Layer. Input into this layer can be an image or output from a previous layer, consisting of c input cards of width m and height n: x-m \u00b7 n The output consists of a series of c output layers on the top layer: Convolutional Layer."}, {"heading": "3 Reinforcement Learning", "text": "The learning agent can be anything that has the ability to act and perceive in a given environment. (In due course, however, the agent receives an observation of the current state of the environment. (However, the agent then enters the state + 1 and receives a reward.) The goal is to find a policy that maximizes the expected future reward, with E, O, and A taking into account the spaces of all possible states, observations, and actions. (The agent then enters the state + 1 and receives a reward rt.) The goal is to find the policies that maximize the expected future reward. (E, O, and A the spaces of all possible states, observations, and actions, respektively.1 The agent then enters the state + 1 and receives a reward rt.) The goal is to find the policies that maximize the expected future reward. (E, O, and A the spaces of all possible states, observations, and actions, are respected) that \"will be sorted in the future.\""}, {"heading": "4 Deep Attention Selective Networks (dasNet)", "text": "The idea behind the Net is to harness the power of sequential processing to improve classification performance."}, {"heading": "5 Related Work", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "6 Experiments on CIFAR-10/100", "text": "Most of them are able to survive themselves, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are not able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own, most of them are able to survive on their own."}, {"heading": "7 Conclusion", "text": "TheNet is a deep neural network with feedback connections learned through reinforcement learning to focus selective internal attention on specific characteristics extracted from images. After a quick initial image classification through a standard stack of feedback filters, feedback can actively change the meaning of certain filters \"in retrospect\" and correct the initial assumption with additional internal \"thoughts.\" DasNet has successfully learned to correct image misclassifications generated by a fully trained feedback maxout network, and its active, selective internal spotlight of attention has enabled state-of-the-art results. Future research will also consider more complex actions that focus (or alter) spatially on portions of the observed images."}, {"heading": "Acknowledgments", "text": "We pay tribute to Matthew Luciw, who has written a short literary review, some of which is included in the Related Work section."}], "references": [{"title": "Neural network model for a mechanism of pattern recognition unaffected by shift in position - Neocognitron", "author": ["K. Fukushima"], "venue": "Trans. IECE, J62-A(10):658\u2013665", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1979}, {"title": "Cresceptron: a self-organizing neural network which grows adaptively", "author": ["Juyang Weng", "Narendra Ahuja", "Thomas S Huang"], "venue": "In International Joint Conference on Neural Networks (IJCNN),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1992}, {"title": "Back-propagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural Computation, 1(4):541\u2013551", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1989}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M.A. Ranzato", "F.J. Huang", "Y.-L. Boureau", "Y. LeCun"], "venue": "Computer Vision and Pattern Recognition, 2007. CVPR \u201907. IEEE Conference on, pages 1\u20138", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2007}, {"title": "Evaluation of pooling operations in convolutional architectures for object recognition", "author": ["D. Scherer", "A. M\u00fcller", "S. Behnke"], "venue": "Proc. International Conference on Artificial Neural Networks (ICANN), pages 92\u2013101", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Flexible", "author": ["D.C. Ciresan", "U. Meier", "J. Masci", "L.M. Gambardella", "J. Schmidhuber"], "venue": "high performance convolutional neural networks for image classification. In Intl. Joint Conference on Artificial Intelligence IJCAI, pages 1237\u20131242", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Multi-column deep neural networks for image classification", "author": ["D.C. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition CVPR 2012", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2012}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "I Sutskever", "G. E Hinton"], "venue": "In Advances in Neural Information Processing Systems (NIPS 2012),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Regularization of neural networks using dropconnect", "author": ["Li Wan", "Matthew Zeiler", "Sixin Zhang", "Yann L Cun", "Rob Fergus"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Mitosis detection in breast cancer histology images with deep neural networks", "author": ["Dan Claudiu Ciresan", "Alessandro Giusti", "Luca Maria Gambardella", "J\u00fcrgen Schmidhuber"], "venue": "In Proc. MICCAI,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Deep neural networks segment neuronal membranes in electron microscopy", "author": ["Dan Claudiu Ciresan", "Alessandro Giusti", "Luca Maria Gambardella", "J\u00fcrgen Schmidhuber"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Learning hierarchical features for scene labeling", "author": ["Cl\u00e9ment Farabet", "Camille Couprie", "Laurent Najman", "Yann LeCun"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1915}, {"title": "Pedestrian detection with unsupervised multi-stage feature learning", "author": ["P. Sermanet", "K. Kavukcuoglu", "S. Chintala", "Y. LeCun"], "venue": "Proc. International Conference on Computer Vision and Pattern Recognition (CVPR\u201913). IEEE", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["Pierre Sermanet", "David Eigen", "Xiang Zhang", "Michael Mathieu", "Rob Fergus", "Yann LeCun"], "venue": "arXiv preprint arXiv:1312.6229,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Technical Report IDSIA- 03-14 / arXiv:1404.7828v1 [cs.NE], The Swiss AI Lab IDSIA", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2014}, {"title": "Theory of communication. Part 1: The analysis of information", "author": ["Dennis Gabor"], "venue": "Electrical Engineers-Part III: Journal of the Institution of Radio and Communication Engineering,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1946}, {"title": "Visualizing and understanding convolutional networks", "author": ["Matthew D. Zeiler", "Rob Fergus"], "venue": "CoRR, abs/1311.2901,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Deep inside convolutional networks: Visualising image classification models and saliency", "author": ["Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Adaptive deconvolutional networks for mid and high level feature learning", "author": ["Matthew D. Zeiler", "Graham W. Taylor", "Rob Fergus"], "venue": "In 2011 International Conference on Computer", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2018}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Quoc Le", "Marc\u2019Aurelio Ranzato", "Rajat Monga", "Matthieu Devin", "Kai Chen", "Greg Corrado", "Jeff Dean", "Andrew Ng"], "venue": "In ICML,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Visual recognition with humans in the loop", "author": ["Steve Branson", "Catherine Wah", "Florian Schroff", "Boris Babenko", "Peter Welinder", "Pietro Perona", "Serge Belongie"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2010}, {"title": "Caltech- UCSD Birds 200", "author": ["P. Welinder", "S. Branson", "T. Mita", "C. Wah", "F. Schroff", "S. Belongie", "P. Perona"], "venue": "Technical Report CNS-TR-2010-001, California Institute of Technology", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2010}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "Technical Report arXiv:1311.2901 [cs.CV], NYU", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "High dimensions and heavy tails for natural evolution strategies", "author": ["Tom Schaul", "Tobias Glasmachers", "J\u00fcrgen Schmidhuber"], "venue": "In Proceedings of the 13th annual conference on Genetic and evolutionary computation,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Master\u2019s thesis, Computer Science Department, University of Toronto", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Geoffrey E Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": "arXiv preprint arXiv:1207.0580,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2012}, {"title": "Compete to compute", "author": ["Rupesh Kumar Srivastava", "Jonathan Masci", "Sohrob Kazerounian", "Faustino Gomez", "J\u00fcrgen Schmidhuber"], "venue": "In NIPS,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Reinforcement learning: a survey", "author": ["Leslie Pack Kaelbling", "Michael L. Littman", "Andrew W. Moore"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1996}, {"title": "Natural evolution strategies", "author": ["D. Wierstra", "T. Schaul", "J. Peters", "J. Schmidhuber"], "venue": "IEEE Congress on Evolutionary Computation, pages 3381\u20133387. IEEE", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2008}, {"title": "Exponential natural evolution strategies", "author": ["T. Glasmachers", "T. Schaul", "S. Yi", "D. Wierstra", "J. Schmidhuber"], "venue": "12th annual conference on Genetic and Evolutionary Computation, pages 393\u2013400. ACM", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2010}, {"title": "Evolutionsstrategie - Optimierung technischer Systeme nach Prinzipien der biologischen Evolution", "author": ["I. Rechenberg"], "venue": "Dissertation", "citeRegEx": "33", "shortCiteRegEx": null, "year": 1971}, {"title": "Numerische Optimierung von Computer-Modellen", "author": ["H.P. Schwefel"], "venue": "Dissertation", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1974}, {"title": "Adaptation in Natural and Artificial Systems", "author": ["J.H. Holland"], "venue": "University of Michigan Press, Ann Arbor", "citeRegEx": "35", "shortCiteRegEx": null, "year": 1975}, {"title": "Distributed hierarchical processing in the primate cerebral cortex", "author": ["Daniel J Felleman", "David C Van Essen"], "venue": "Cerebral cortex,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 1991}, {"title": "Recurrent excitation in neocortical circuits", "author": ["Rodney J Douglas", "Christof Koch", "Misha Mahowald", "KA Martin", "Humbert H Suarez"], "venue": null, "citeRegEx": "37", "shortCiteRegEx": "37", "year": 1995}, {"title": "Hierarchies of cortical areas", "author": ["J. Bullier"], "venue": "J.H. Kaas and C.E. Collins, editors, The Primate Visual System, pages 181\u2013204. CRC Press, New York", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2004}, {"title": "The distinct modes of vision offered by feedforward and recurrent processing", "author": ["Victor AF Lamme", "Pieter R Roelfsema"], "venue": "Trends in neurosciences,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2000}, {"title": "Visual salience", "author": ["L. Itti"], "venue": "2(9):3327", "citeRegEx": "40", "shortCiteRegEx": null, "year": 2007}, {"title": "Perceptual selectivity is task dependent: The pop-out effect poops out", "author": ["Carl M Francolini", "Howard E Egeth"], "venue": "Perception & Psychophysics,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 1979}, {"title": "On second glance: Still no high-level pop-out effect for faces", "author": ["Rufin VanRullen"], "venue": "Vision research,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2006}, {"title": "Brain states: top-down influences in sensory processing", "author": ["Charles D Gilbert", "Mariano Sigman"], "venue": null, "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2007}, {"title": "Cortical feedback improves discrimination between figure and background by v1", "author": ["JM Hupe", "AC James", "BR Payne", "SG Lomber", "P Girard", "J Bullier"], "venue": "v2 and v3 neurons. Nature, 394(6695):784\u2013787", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1998}, {"title": "The role of feedback connections in shaping the responses of visual cortical neurons", "author": ["Jean Bullier", "Jean-Michel Hup\u00e9", "Andrew C James", "Pascal Girard"], "venue": "Progress in brain research,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 2001}, {"title": "Blindsight: the role of feedforward and feedback corticocortical connections", "author": ["Victor AF Lamme"], "venue": "Acta psychologica,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 2001}, {"title": "Top-down facilitation of visual recognition", "author": ["Moshe Bar", "Karim S Kassam", "Avniel Singh Ghuman", "Jasmine Boshyan", "Annette M Schmid", "Anders M Dale", "MS H\u00e4m\u00e4l\u00e4inen", "Ksenija Marinkovic", "DL Schacter", "BR Rosen"], "venue": "Proceedings of the National Academy of Sciences of the United States of America,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2006}, {"title": "The role of competitive inhibition and top-down feedback in binding during object recognition", "author": ["Dean Wyatte", "Seth Herd", "Brian Mingus", "Randall O\u2019Reilly"], "venue": "Frontiers in Psychology,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2012}, {"title": "The limits of feedforward vision: Recurrent processing promotes robust object recognition when objects are degraded", "author": ["Dean Wyatte", "Tim Curran", "Randall O\u2019Reilly"], "venue": "Journal of Cognitive Neuroscience,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2012}, {"title": "Learning to generate artificial fovea trajectories for target detection", "author": ["J. Schmidhuber", "R. Huber"], "venue": "International Journal of Neural Systems, 2(1 & 2):135\u2013141", "citeRegEx": "50", "shortCiteRegEx": null, "year": 1991}, {"title": "Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm", "author": ["Randall C O\u2019Reilly"], "venue": "Neural Computation,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 1996}, {"title": "Restoring partly occluded patterns: A neural network model with backward paths", "author": ["Kunihiko Fukushima"], "venue": "Artificial Neural Networks and Neural Information Processing ICANN/ICONIP 2003,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2003}, {"title": "Learning to combine foveal glimpses with a thirdorder boltzmann machine", "author": ["Hugo Larochelle", "Geoffrey Hinton"], "venue": "Image, 1:x2,", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 2010}, {"title": "Reinforcement learning based visual attention with application to face detection", "author": ["Benjamin Goodrich", "Itamar Arel"], "venue": "In Computer Vision and Pattern Recognition Workshops (CVPRW),", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2012}, {"title": "Using guided autoencoders on face recognition", "author": ["M.F. Stollenga", "M.A. Wiering", "L.R.B. Schomaker"], "venue": "Master\u2019s thesis. University of Groningen", "citeRegEx": "55", "shortCiteRegEx": null, "year": 2011}, {"title": "Recurrent processing during object recognition", "author": ["Randall C OReilly", "Dean Wyatte", "Seth Herd", "Brian Mingus", "David J Jilk"], "venue": "Frontiers in Psychology,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2013}, {"title": "Reinforcement Learning for the adaptive control of perception and action", "author": ["S.D. Whitehead"], "venue": "PhD thesis,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 1992}, {"title": "Learning iterative image reconstruction in the neural abstraction pyramid", "author": ["Sven Behnke"], "venue": "International Journal of Computational Intelligence and Applications,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2001}, {"title": "Face localization and tracking in the neural abstraction pyramid", "author": ["Sven Behnke"], "venue": "Neural Computing & Applications,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2005}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["Matthew D. Zeiler", "Rob Fergus"], "venue": "CoRR, abs/1301.3557,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 42, "endOffset": 45}, {"referenceID": 1, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 70, "endOffset": 73}, {"referenceID": 2, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 94, "endOffset": 99}, {"referenceID": 3, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 94, "endOffset": 99}, {"referenceID": 4, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 94, "endOffset": 99}, {"referenceID": 5, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 108, "endOffset": 111}, {"referenceID": 6, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 167, "endOffset": 173}, {"referenceID": 7, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 167, "endOffset": 173}, {"referenceID": 8, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 167, "endOffset": 173}, {"referenceID": 9, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 198, "endOffset": 206}, {"referenceID": 10, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 198, "endOffset": 206}, {"referenceID": 11, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 226, "endOffset": 233}, {"referenceID": 12, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 226, "endOffset": 233}, {"referenceID": 13, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 226, "endOffset": 233}, {"referenceID": 14, "context": "Deep convolutional neural networks (CNNs) [1] with max-pooling layers [2] trained by backprop [3\u20135] on GPUs [6] have become the state-of-the-art in object recognition [7\u201310], segmentation/detection [11, 12], and scene parsing [13\u201315] (for an extensive review see [16]).", "startOffset": 263, "endOffset": 267}, {"referenceID": 15, "context": "Low-level stages tend to learn biologically plausible feature detectors, such as Gabor filters [17].", "startOffset": 95, "endOffset": 99}, {"referenceID": 16, "context": ", [18\u201321].", "startOffset": 2, "endOffset": 9}, {"referenceID": 17, "context": ", [18\u201321].", "startOffset": 2, "endOffset": 9}, {"referenceID": 18, "context": ", [18\u201321].", "startOffset": 2, "endOffset": 9}, {"referenceID": 19, "context": ", [18\u201321].", "startOffset": 2, "endOffset": 9}, {"referenceID": 20, "context": "However, an expert ornithologist, asked to classify a bird belonging to one of two very similar species, may have to think for more than a few milliseconds before answering [22, 23], implying that several feedforward evaluations are performed, where each evaluation tries to elicit different information from the image.", "startOffset": 173, "endOffset": 181}, {"referenceID": 21, "context": "However, an expert ornithologist, asked to classify a bird belonging to one of two very similar species, may have to think for more than a few milliseconds before answering [22, 23], implying that several feedforward evaluations are performed, where each evaluation tries to elicit different information from the image.", "startOffset": 173, "endOffset": 181}, {"referenceID": 22, "context": "Our aim is to let the system check the usefulness of internal CNN filters automatically, omitting manual inspection [24].", "startOffset": 116, "endOffset": 120}, {"referenceID": 23, "context": "In our current implementation, the attentional policy is evolved using Separable Natural Evolution Strategies (SNES; [25]), instead of a conventional, single agent reinforcement learning method (e.", "startOffset": 117, "endOffset": 121}, {"referenceID": 24, "context": "Experiments on CIFAR-10 and CIFAR100 [26] show that on difficult classification instances, the network corrects itself by emphasizing and de-emphasizing certain filters, outperforming a previous state-ofthe-art CNN.", "startOffset": 37, "endOffset": 41}, {"referenceID": 25, "context": "In this work we use the Maxout networks [10], combined with dropout [27], as the underlying model for dasNet.", "startOffset": 68, "endOffset": 72}, {"referenceID": 26, "context": "A similar approach, which does not reduce dimensionality in favor of sparsity in the representation has also been recently presented [28].", "startOffset": 133, "endOffset": 137}, {"referenceID": 1, "context": "along the height and width [2].", "startOffset": 27, "endOffset": 30}, {"referenceID": 27, "context": "Reinforcement learning (RL) is a general framework for learning to make sequential decisions order to maximize an external reward signal [29, 30].", "startOffset": 137, "endOffset": 145}, {"referenceID": 0, "context": "The objective is to find the policy, \u03c0, that maximizes the expected future discounted reward, E[ \u2211 t \u03b3 rt], where \u03b3 \u2208 [0, 1] discounts the future, modeling the \u201cfarsightedness\u201d of the agent.", "startOffset": 118, "endOffset": 124}, {"referenceID": 28, "context": "Therefore, we instead evolve the policy using a variant for Natural Evolution Strategies (NES; [31, 32]), called Separable NES (SNES; [25]).", "startOffset": 95, "endOffset": 103}, {"referenceID": 29, "context": "Therefore, we instead evolve the policy using a variant for Natural Evolution Strategies (NES; [31, 32]), called Separable NES (SNES; [25]).", "startOffset": 95, "endOffset": 103}, {"referenceID": 23, "context": "Therefore, we instead evolve the policy using a variant for Natural Evolution Strategies (NES; [31, 32]), called Separable NES (SNES; [25]).", "startOffset": 134, "endOffset": 138}, {"referenceID": 30, "context": ", a conventional ES [33\u201335]).", "startOffset": 20, "endOffset": 27}, {"referenceID": 31, "context": ", a conventional ES [33\u201335]).", "startOffset": 20, "endOffset": 27}, {"referenceID": 32, "context": ", a conventional ES [33\u201335]).", "startOffset": 20, "endOffset": 27}, {"referenceID": 33, "context": "Felleman and Van Essen [36] constructed a (now famous) hierarchy diagram of 32 different visual cortical areas in macaque visual cortex.", "startOffset": 23, "endOffset": 27}, {"referenceID": 34, "context": "The top-down connections are more numerous than bottom-up connections, and generally more diffuse [37].", "startOffset": 98, "endOffset": 102}, {"referenceID": 35, "context": "They are thought to play primarily a modulatory role, while feedforward connections serve as directed information carriers [38].", "startOffset": 123, "endOffset": 127}, {"referenceID": 36, "context": "Analysis of response latencies to a newly-presented image lends credence to the theory that there are two stages of visual processing: a fast, pre-attentive phase, due to feedforward processing, followed by an attentional phase, due to the influence of recurrent processing [39].", "startOffset": 274, "endOffset": 278}, {"referenceID": 37, "context": "After the feedforward pass, we can recognize and localize simple salient stimuli, which can \u201cpop-out\u201d [40], and response times do not increase regardless of the number of distractors.", "startOffset": 102, "endOffset": 106}, {"referenceID": 38, "context": "However, this effect has only been conclusively shown for basic features such as color or orientation; for categorical stimuli or faces, whether there is a pop-out effect remains controversial [41, 42].", "startOffset": 193, "endOffset": 201}, {"referenceID": 39, "context": "However, this effect has only been conclusively shown for basic features such as color or orientation; for categorical stimuli or faces, whether there is a pop-out effect remains controversial [41, 42].", "startOffset": 193, "endOffset": 201}, {"referenceID": 40, "context": "Regarding the attentional phase, feedback connections are known to play important roles, such as in feature grouping [43], in differentiating a foreground from its background, (especially", "startOffset": 117, "endOffset": 121}, {"referenceID": 41, "context": "when the foreground is not highly salient [44, 45]), and perceptual filling in [46].", "startOffset": 42, "endOffset": 50}, {"referenceID": 42, "context": "when the foreground is not highly salient [44, 45]), and perceptual filling in [46].", "startOffset": 42, "endOffset": 50}, {"referenceID": 43, "context": "when the foreground is not highly salient [44, 45]), and perceptual filling in [46].", "startOffset": 79, "endOffset": 83}, {"referenceID": 44, "context": "[47] supports the idea that top-down projections from prefrontal cortex play an important role in object recognition by quickly extracting low-level spatial frequency information to provide an initial guess about potential categories, forming a top-down expectation that biases recognition.", "startOffset": 0, "endOffset": 4}, {"referenceID": 45, "context": "Recurrent connections seem to rely heavily on competitive inhibition and other feedback to make object recognition more robust [48, 49].", "startOffset": 127, "endOffset": 135}, {"referenceID": 46, "context": "Recurrent connections seem to rely heavily on competitive inhibition and other feedback to make object recognition more robust [48, 49].", "startOffset": 127, "endOffset": 135}, {"referenceID": 47, "context": "In the context of computer vision, RL has been shown to be able to learn saccades in visual scenes to learn selective attention [50], learn feedback to lower levels [51, 52], and improve face recognition [53\u201355].", "startOffset": 128, "endOffset": 132}, {"referenceID": 48, "context": "In the context of computer vision, RL has been shown to be able to learn saccades in visual scenes to learn selective attention [50], learn feedback to lower levels [51, 52], and improve face recognition [53\u201355].", "startOffset": 165, "endOffset": 173}, {"referenceID": 49, "context": "In the context of computer vision, RL has been shown to be able to learn saccades in visual scenes to learn selective attention [50], learn feedback to lower levels [51, 52], and improve face recognition [53\u201355].", "startOffset": 165, "endOffset": 173}, {"referenceID": 50, "context": "In the context of computer vision, RL has been shown to be able to learn saccades in visual scenes to learn selective attention [50], learn feedback to lower levels [51, 52], and improve face recognition [53\u201355].", "startOffset": 204, "endOffset": 211}, {"referenceID": 51, "context": "In the context of computer vision, RL has been shown to be able to learn saccades in visual scenes to learn selective attention [50], learn feedback to lower levels [51, 52], and improve face recognition [53\u201355].", "startOffset": 204, "endOffset": 211}, {"referenceID": 52, "context": "In the context of computer vision, RL has been shown to be able to learn saccades in visual scenes to learn selective attention [50], learn feedback to lower levels [51, 52], and improve face recognition [53\u201355].", "startOffset": 204, "endOffset": 211}, {"referenceID": 53, "context": "It has been shown to be effective for object recognition [56], and has also been combined with traditional computer vision primitives [57].", "startOffset": 57, "endOffset": 61}, {"referenceID": 54, "context": "It has been shown to be effective for object recognition [56], and has also been combined with traditional computer vision primitives [57].", "startOffset": 134, "endOffset": 138}, {"referenceID": 55, "context": "Iterative processing of images using recurrency has been successfully used for image reconstruction [58] and face-localization [59].", "startOffset": 100, "endOffset": 104}, {"referenceID": 56, "context": "Iterative processing of images using recurrency has been successfully used for image reconstruction [58] and face-localization [59].", "startOffset": 127, "endOffset": 131}, {"referenceID": 24, "context": "The CIFAR-10 dataset [26] is composed of 32\u00d7 32 color images split into 5\u00d7 10 training and 10 testing samples, where each image is assigned to one of 10 classes.", "startOffset": 21, "endOffset": 25}, {"referenceID": 8, "context": "Method CIFAR-10 CIFAR-100 Dropconnect [9] 9.", "startOffset": 38, "endOffset": 41}, {"referenceID": 57, "context": "32% Stochastic Pooling [60] 15.", "startOffset": 23, "endOffset": 27}, {"referenceID": 6, "context": "13% Multi-column CNN [7] 11.", "startOffset": 21, "endOffset": 24}], "year": 2014, "abstractText": "Traditional convolutional neural networks (CNN) are stationary and feedforward. They neither change their parameters during evaluation nor use feedback from higher to lower layers. Real brains, however, do. So does our Deep Attention Selective Network (dasNet) architecture. DasNets feedback structure can dynamically alter its convolutional filter sensitivities during classification. It harnesses the power of sequential processing to improve classification performance, by allowing the network to iteratively focus its internal attention on some of its convolutional filters. Feedback is trained through direct policy search in a huge million-dimensional parameter space, through scalable natural evolution strategies (SNES). On the CIFAR-10 and CIFAR-100 datasets, dasNet outperforms the previous state-of-the-art model.", "creator": "gnuplot 4.6 patchlevel 3"}}}