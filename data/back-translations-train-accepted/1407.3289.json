{"id": "1407.3289", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jul-2014", "title": "Altitude Training: Strong Bounds for Single-Layer Dropout", "abstract": "Dropout training, originally designed for deep neural networks, has been successful on high-dimensional single-layer natural language tasks. This paper proposes a theoretical explanation for this phenomenon: we show that, under a generative Poisson topic model with long documents, dropout training improves the exponent in the generalization bound for empirical risk minimization. Dropout achieves this gain much like a marathon runner who practices at altitude: once a classifier learns to perform reasonably well on training examples that have been artificially corrupted by dropout, it will do very well on the uncorrupted test set. We also show that, under similar conditions, dropout preserves the Bayes decision boundary and should therefore induce minimal bias in high dimensions.", "histories": [["v1", "Fri, 11 Jul 2014 20:32:34 GMT  (99kb,D)", "https://arxiv.org/abs/1407.3289v1", null], ["v2", "Fri, 31 Oct 2014 18:30:18 GMT  (101kb,D)", "http://arxiv.org/abs/1407.3289v2", "Advances in Neural Information Processing Systems (NIPS), 2014"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG math.ST stat.TH", "authors": ["stefan wager", "william fithian", "sida i wang", "percy liang"], "accepted": true, "id": "1407.3289"}, "pdf": {"name": "1407.3289.pdf", "metadata": {"source": "CRF", "title": "Altitude Training: Strong Bounds for Single-Layer Dropout", "authors": ["Stefan Wager", "William Fithian", "Sida Wang"], "emails": ["wfithian}@stanford.edu,", "pliang}@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "The aim of this work is to gain a better theoretical understanding of why dropout regulation works well for natural language tasks. We focus on the task of document classification using linear classification, where data is derived from a generative model. In this setting, random words from a document are effectively deleted during training; this corruption makes the training examples harder, a classification that is able to match the training data to the much simpler incorrect examples."}, {"heading": "2 Dropout Training for Topic Models", "text": "In this section, we present binomial dropout (i)) for (2) some functions (i). We begin with the usual empirical risk minimizers: w) we expect to minimize the risk. (i) we expect to minimize the risk. (i) we expect to minimize the risk. (i) we expect to minimize the risk. (i) we expect to minimize the risk. (i) we expect to minimize the risk. (i) we expect to minimize the risk. (i) we expect to minimize the risk. (i) we expect to minimize the risk. (ii) we expect to minimize the risk."}, {"heading": "3 Altitude Training: Linking the Dropout and Data-Generating Measures", "text": "Our goal is to understand the behavior of a classifier that generalizes in relation to the generalization in relation to the generalization in relation to the generalization (expected risks) of hwhere x is drawn from the underlying data-generating metric: Err (h) def = P [y] 6 = h (x). (4) 1Dropout training is known to work well in practice for multi-class problems [8]. For simplicity, however, we will limit our theoretical analysis to a two-class analysis. (2) In topic modeling, the deepenings of the simplex method are a mixture of topics, whereas we call ourselves a topic. However, since dropout training is based on the corrupt data x (see (3), within the limit of the infinite data that the dropout estimator will convert to minimize the generalization of errors in relation to the generalization in relation to the generalization."}, {"heading": "4 A Generalization Bound for Dropout", "text": "The first assumption is basic: if the classification signal focuses on a few characteristics, then we cannot expect the dropout training to go well; the second and third assumptions, which are more technical, guarantee that a classifying subject can only perform well if it is well suited to each subject; this allows us to apply Theorem 1. A more general analysis that puts assumptions 2 and 3 into perspective can be an interesting avenue for future work. Assumption 1: well-balanced weights First, we must assume that all the signal is not concentrated in a few characteristics."}, {"heading": "5 The Bias of Dropout", "text": "In the previous section, we have shown that we are independent of the topic in which we make the decision that we can accept a substantial reduction in risk. (...) In the previous section, we have shown that the model in the first section is independent. (...) In the second section of the section, we have the possibility that there is a reduction in risk in the second section. (...) In the third section, we have a reduction in risk in the third section. (...) In the third section, we have a reduction in risk in the third section. (...) In the third section, we have a reduction in risk in the third section. (...) In the third section, we have a reduction in risk in the third section. (...) In the third section, we have a reduction in risk in the third section. (...) In the third section, we have a reduction in the third section. (...) In the third section, we have a reduction in risk. (...) In the third section, we have a reduction in the third section."}, {"heading": "6 Experiments and Discussion", "text": "The first of seven independents to vote in the House of Representatives on Tuesday, Sen. John McCain (R-Ariz.) and Sen. John McCain (R-Ariz.) are expected to vote in the House of Representatives on Tuesday, according to a person familiar with the process."}, {"heading": "A Technical Results", "text": "We start with a proof for our most important generalization-related results, namely theorem 1. The proof is based on the following results: Lemma 5. Let Z1,..., Zd are independent Poisson random variables with averages. (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So: (So): (So): (So): (So: (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So): (So: (So): (So): (So): (So): (So): (So: (So): (So): (So)"}], "references": [{"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Geoffrey E Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Adaptive dropout for training deep neural networks", "author": ["Jimmy Ba", "Brendan Frey"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoff Hinton"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Regularization of neural networks using dropconnect", "author": ["Li Wan", "Matthew Zeiler", "Sixin Zhang", "Yann L Cun", "Rob Fergus"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Dropout training as adaptive regularization", "author": ["Stefan Wager", "Sida Wang", "Percy Liang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Fast dropout training", "author": ["Sida I Wang", "Christopher D Manning"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Feature noising for log-linear structured prediction", "author": ["Sida I Wang", "Mengqiu Wang", "Stefan Wager", "Percy Liang", "Christopher D Manning"], "venue": "In Empirical Methods in Natural Language Processing,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Learning with marginalized corrupted features", "author": ["Laurens van der Maaten", "Minmin Chen", "Stephen Tyree", "Kilian Q Weinberger"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "On discriminative vs. generative classifiers: A comparison of logistic regression and naive Bayes", "author": ["Andrew Ng", "Michael Jordan"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "A PAC-Bayesian tutorial with a dropout", "author": ["David McAllester"], "venue": "bound. arXiv:1307.2118,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "The dropout learning algorithm", "author": ["Pierre Baldi", "Peter Sadowski"], "venue": "Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Nightmare at test time: robust learning by feature deletion", "author": ["Amir Globerson", "Sam Roweis"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2006}, {"title": "Convexity, classification, and risk bounds", "author": ["Peter L Bartlett", "Michael I Jordan", "Jon D McAuliffe"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2006}, {"title": "Statistical behavior and consistency of classification methods based on convex risk minimization", "author": ["Tong Zhang"], "venue": "Annals of Statistics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2004}, {"title": "Latent Dirichlet allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2003}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["Bo Pang", "Lillian Lee"], "venue": "In Proceedings of the Association for Computational Linguistics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "Learning word vectors for sentiment analysis", "author": ["Andrew L Maas", "Raymond E Daly", "Peter T Pham", "Dan Huang", "Andrew Y Ng", "Christopher Potts"], "venue": "In Proceedings of the Association for Computational Linguistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Baselines and bigrams: Simple, good sentiment and topic classification", "author": ["Sida Wang", "Christopher D Manning"], "venue": "In Proceedings of the Association for Computational Linguistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Classification with hybrid generative/discriminative models", "author": ["R. Raina", "Y. Shen", "A. Ng", "A. McCallum"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "The trade-off between generative and discriminative classifiers", "author": ["G. Bouchard", "B. Triggs"], "venue": "In International Conference on Computational Statistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2004}, {"title": "Principled hybrids of generative and discriminative models", "author": ["J.A. Lasserre", "C.M. Bishop", "T.P. Minka"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2006}, {"title": "Bias-variance tradeoff in hybrid generative-discriminative models", "author": ["Guillaume Bouchard"], "venue": "In International Conference on Machine Learning and Applications. IEEE,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "Multi-conditional learning: Generative/discriminative training for clustering and classification", "author": ["A. McCallum", "C. Pal", "G. Druck", "X. Wang"], "venue": "In Association for the Advancement of Artificial Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2006}, {"title": "An asymptotic analysis of generative, discriminative, and pseudolikelihood estimators", "author": ["Percy Liang", "Michael I Jordan"], "venue": "In Proceedings of the International Conference on Machine Learning,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "An introduction to probability theory and its applications, volume 2", "author": ["Willliam Feller"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1971}], "referenceMentions": [{"referenceID": 0, "context": "Dropout training [1] is an increasingly popular method for regularizing learning algorithms.", "startOffset": 17, "endOffset": 20}, {"referenceID": 1, "context": "Dropout is most commonly used for regularizing deep neural networks [2, 3, 4, 5], but it has also been found to improve the performance of logistic regression and other single-layer models for natural language tasks such as document classification and named entity recognition [6, 7, 8].", "startOffset": 68, "endOffset": 80}, {"referenceID": 2, "context": "Dropout is most commonly used for regularizing deep neural networks [2, 3, 4, 5], but it has also been found to improve the performance of logistic regression and other single-layer models for natural language tasks such as document classification and named entity recognition [6, 7, 8].", "startOffset": 68, "endOffset": 80}, {"referenceID": 3, "context": "Dropout is most commonly used for regularizing deep neural networks [2, 3, 4, 5], but it has also been found to improve the performance of logistic regression and other single-layer models for natural language tasks such as document classification and named entity recognition [6, 7, 8].", "startOffset": 68, "endOffset": 80}, {"referenceID": 4, "context": "Dropout is most commonly used for regularizing deep neural networks [2, 3, 4, 5], but it has also been found to improve the performance of logistic regression and other single-layer models for natural language tasks such as document classification and named entity recognition [6, 7, 8].", "startOffset": 277, "endOffset": 286}, {"referenceID": 5, "context": "Dropout is most commonly used for regularizing deep neural networks [2, 3, 4, 5], but it has also been found to improve the performance of logistic regression and other single-layer models for natural language tasks such as document classification and named entity recognition [6, 7, 8].", "startOffset": 277, "endOffset": 286}, {"referenceID": 6, "context": "Dropout is most commonly used for regularizing deep neural networks [2, 3, 4, 5], but it has also been found to improve the performance of logistic regression and other single-layer models for natural language tasks such as document classification and named entity recognition [6, 7, 8].", "startOffset": 277, "endOffset": 286}, {"referenceID": 7, "context": "For single-layer linear models, learning with dropout is equivalent to using \u201cblankout noise\u201d [9].", "startOffset": 94, "endOffset": 97}, {"referenceID": 8, "context": "It is instructive to compare our generalization bound to that of Ng and Jordan [10], who showed that the naive Bayes classifier exploits a strong generative assumption\u2014conditional independence of the features given the label\u2014to achieve an excess risk of OP ( \u221a (log d)/n).", "startOffset": 79, "endOffset": 83}, {"referenceID": 9, "context": "McAllester [11] used the PAC-Bayes framework to prove a generalization bound for dropout that decays as 1 \u2212 \u03b4.", "startOffset": 11, "endOffset": 15}, {"referenceID": 4, "context": "Moreover, provided that \u03b4 is not too close to 1, dropout behaves similarly to an adaptive L2 regularizer with parameter \u03b4/(1\u2212\u03b4) [6, 12], and at least in linear regression such L2 regularization improves generalization error by a constant factor.", "startOffset": 128, "endOffset": 135}, {"referenceID": 10, "context": "Moreover, provided that \u03b4 is not too close to 1, dropout behaves similarly to an adaptive L2 regularizer with parameter \u03b4/(1\u2212\u03b4) [6, 12], and at least in linear regression such L2 regularization improves generalization error by a constant factor.", "startOffset": 128, "endOffset": 135}, {"referenceID": 4, "context": "It is also possible to analyze dropout as an adaptive regularizer [6, 9, 13]: in comparison with L2 regularization, dropout favors the use of rare features and encourages confident predictions.", "startOffset": 66, "endOffset": 76}, {"referenceID": 7, "context": "It is also possible to analyze dropout as an adaptive regularizer [6, 9, 13]: in comparison with L2 regularization, dropout favors the use of rare features and encourages confident predictions.", "startOffset": 66, "endOffset": 76}, {"referenceID": 11, "context": "It is also possible to analyze dropout as an adaptive regularizer [6, 9, 13]: in comparison with L2 regularization, dropout favors the use of rare features and encourages confident predictions.", "startOffset": 66, "endOffset": 76}, {"referenceID": 8, "context": ", [10, 14, 15]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 12, "context": ", [10, 14, 15]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 13, "context": ", [10, 14, 15]).", "startOffset": 2, "endOffset": 14}, {"referenceID": 0, "context": "Because we are only interested in the decision boundary, we do not scale down the weight vector obtained by dropout by a factor 1\u2212 \u03b4 as is often done [1].", "startOffset": 150, "endOffset": 153}, {"referenceID": 4, "context": "Binomial dropout differs slightly from the usual definition of (blankout) dropout, which alters the feature vector x by setting random coordinates to 0 [6, 9, 11, 12].", "startOffset": 152, "endOffset": 166}, {"referenceID": 7, "context": "Binomial dropout differs slightly from the usual definition of (blankout) dropout, which alters the feature vector x by setting random coordinates to 0 [6, 9, 11, 12].", "startOffset": 152, "endOffset": 166}, {"referenceID": 9, "context": "Binomial dropout differs slightly from the usual definition of (blankout) dropout, which alters the feature vector x by setting random coordinates to 0 [6, 9, 11, 12].", "startOffset": 152, "endOffset": 166}, {"referenceID": 10, "context": "Binomial dropout differs slightly from the usual definition of (blankout) dropout, which alters the feature vector x by setting random coordinates to 0 [6, 9, 11, 12].", "startOffset": 152, "endOffset": 166}, {"referenceID": 14, "context": "If \u0398 is the (K \u2212 1)-dimensional simplex where \u03bb is a \u03c4 -mixture over K basis vectors, we get the K-topic latent Dirichlet allocation [16].", "startOffset": 133, "endOffset": 137}, {"referenceID": 6, "context": "(4) Dropout training is known to work well in practice for multi-class problems [8].", "startOffset": 80, "endOffset": 83}, {"referenceID": 12, "context": ", [14, 15].", "startOffset": 2, "endOffset": 10}, {"referenceID": 13, "context": ", [14, 15].", "startOffset": 2, "endOffset": 10}, {"referenceID": 15, "context": "0 dataset [17].", "startOffset": 10, "endOffset": 14}, {"referenceID": 16, "context": "(b) IMDB dataset [18].", "startOffset": 17, "endOffset": 21}, {"referenceID": 15, "context": "0 task [17], where the goal is to classify positive versus negative movie reviews on IMDB.", "startOffset": 7, "endOffset": 11}, {"referenceID": 16, "context": "We also ran experiments on a larger IMDB dataset [18] with training and test sets of size 25,000 each and approximately 300,000 features.", "startOffset": 49, "endOffset": 53}, {"referenceID": 17, "context": "Logistic regression with dropout appears to have an intriguing connection to the naive Bayes SVM (NBSVM) [19], which is a way of using naive Bayes generative assumptions to strengthen an SVM.", "startOffset": 105, "endOffset": 109}, {"referenceID": 5, "context": ", [7].", "startOffset": 2, "endOffset": 5}, {"referenceID": 18, "context": "Our analysis presents an interesting contrast to other work that directly combine generative and discriminative modeling by optimizing a hybrid likelihood [20, 21, 22, 23, 24, 25].", "startOffset": 155, "endOffset": 179}, {"referenceID": 19, "context": "Our analysis presents an interesting contrast to other work that directly combine generative and discriminative modeling by optimizing a hybrid likelihood [20, 21, 22, 23, 24, 25].", "startOffset": 155, "endOffset": 179}, {"referenceID": 20, "context": "Our analysis presents an interesting contrast to other work that directly combine generative and discriminative modeling by optimizing a hybrid likelihood [20, 21, 22, 23, 24, 25].", "startOffset": 155, "endOffset": 179}, {"referenceID": 21, "context": "Our analysis presents an interesting contrast to other work that directly combine generative and discriminative modeling by optimizing a hybrid likelihood [20, 21, 22, 23, 24, 25].", "startOffset": 155, "endOffset": 179}, {"referenceID": 22, "context": "Our analysis presents an interesting contrast to other work that directly combine generative and discriminative modeling by optimizing a hybrid likelihood [20, 21, 22, 23, 24, 25].", "startOffset": 155, "endOffset": 179}, {"referenceID": 23, "context": "Our analysis presents an interesting contrast to other work that directly combine generative and discriminative modeling by optimizing a hybrid likelihood [20, 21, 22, 23, 24, 25].", "startOffset": 155, "endOffset": 179}], "year": 2014, "abstractText": "Dropout training, originally designed for deep neural networks, has been successful on high-dimensional single-layer natural language tasks. This paper proposes a theoretical explanation for this phenomenon: we show that, under a generative Poisson topic model with long documents, dropout training improves the exponent in the generalization bound for empirical risk minimization. Dropout achieves this gain much like a marathon runner who practices at altitude: once a classifier learns to perform reasonably well on training examples that have been artificially corrupted by dropout, it will do very well on the uncorrupted test set. We also show that, under similar conditions, dropout preserves the Bayes decision boundary and should therefore induce minimal bias in high dimensions.", "creator": "LaTeX with hyperref package"}}}