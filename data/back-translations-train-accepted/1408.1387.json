{"id": "1408.1387", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Aug-2014", "title": "Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing", "abstract": "Many fields of science and engineering, ranging from predicting protein structures to building machine translation systems, require large amounts of labeled data. These labeling tasks have traditionally been performed by experts; the limited pool of experts would limit the size of the datasets, and make the process slow and expensive. In recent years, there is a rapidly increasing interest in using crowds of semi-skilled workers recruited through the Internet. While this 'crowdsourcing' can cheaply produce large amounts of labeled data in short times, it is typically plagued by the problem of low quality. To address this fundamental challenge in crowdsourcing, we design a novel reward mechanism for acquiring high-quality data, which incentivizes workers to censor their own low-quality data. Our main results are the mathematical proofs showing that surprisingly, under a natural and desirable 'no-free-lunch' requirement, this is the one and only mechanism that is incentive-compatible. The simplicity of the mechanism is an additional attractive property. In preliminary experiments involving over 900 worker-tasks, we observe upto a three-fold drop in the error rates under this unique incentive mechanism.", "histories": [["v1", "Wed, 6 Aug 2014 19:52:28 GMT  (1896kb,D)", "https://arxiv.org/abs/1408.1387v1", null], ["v2", "Tue, 30 Sep 2014 06:29:22 GMT  (2042kb,D)", "http://arxiv.org/abs/1408.1387v2", null], ["v3", "Wed, 16 Dec 2015 19:53:47 GMT  (2732kb,D)", "http://arxiv.org/abs/1408.1387v3", null]], "reviews": [], "SUBJECTS": "cs.GT cs.HC cs.LG", "authors": ["nihar bhadresh shah", "denny zhou"], "accepted": true, "id": "1408.1387"}, "pdf": {"name": "1408.1387.pdf", "metadata": {"source": "CRF", "title": "Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing", "authors": ["Nihar B. Shah", "Dengyong Zhou"], "emails": ["nihar@eecs.berkeley.edu", "dengyong.zhou@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2 Setting and Notation", "text": "The questions are objective, by which we mean each question has just one right answer. Examples of objective questions include multiple choice classification questions such as Figure 1, questions about transcribing text from audio or images, etc. For each possible answer to a question, we define the employee's confidence in an answer as the likelihood that this answer is correct according to their belief. In other words, it can be assumed that the employee has a probability distribution over all possible answers to a question, and the reliance for an answer is the likelihood that this answer is correct. In short, we also define the confidence about an answer that the employee is most confident about that question. We assume that the employee's confidence is independent of other questions. Our goal is that the worker should be incentivized for each question if their confidence for that question is below a certain threshold."}, {"heading": "3 Skip-based Setting", "text": "In this section, we look at the setting in which the worker can decide for each question whether to answer the question or skip it; the worker is not asked for additional information. See Figure 1b for an illustration."}, {"heading": "3.1 Setting", "text": "The aim is to design payment mechanisms that encourage the worker to skip the questions for which his trust is lower than T, and to answer those for which his trust is higher than T. 2 Furthermore, for the questions he tries to answer, he must be incentivised to select the answer he thinks is likely to be right. The value of T is priori selected on the basis of factors such as budget constraints or the desired quality of the labels. The value of T may also depend on the choice of the algorithm that is subsequently applied to aggregate the answers of several workers. In this essay, we assume that the value of the threshold T is already specified for us. We make the following simple and natural requirement: Axiom 1 (No-free-lunch axiom) If all the answers that the worker tries in the gold standard are wrong, the payment is the minimum. Formally, the payment f (x1, xG) = minimum for each evaluation."}, {"heading": "3.2 Payment Mechanism", "text": "We present our proposed payment mechanism in algorithm 1.Algorithm 1: incentive mechanism for skipped setting = 12 cents. We assume that the proposed payment mechanisms in algorithm 1.Algorithm 1: incentive mechanism for skipped setting = 10 cents = 10 cents."}, {"heading": "3.3 Uniqueness of this Mechanism", "text": "In fact, it is such that most of us are able to move into another world, in which they are able, in which they are able, in which they are able, in which they are able, in which they are able, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they"}, {"heading": "3.4 Optimality against Spamming Behavior", "text": "In fact, most of them are able to survive on their own, without being able to survive on their own."}, {"heading": "4 Confidence-based Setting", "text": "\",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \",\" \",\" \",\" \",\" \",\" \",\", \",\" \",\", \"\", \"\", \"\", \"\", \"\" \",\" \",\" \"\", \"\" \",\" \"\", \"\", \"\", \",\" \",\", \",\" \",\" \",\" \",\" \",\", \"\", \"\", \",\" \",\", \"\", \",\", \"\", \",\", \"\", \",\" \",\" \",\", \"\", \",\" \",\", \"\", \",\" \",\", \"\", \",\", \"\", \",\", \"\" \",\", \"\", \",\" \",\" \",\", \"\" \",\" \",\" \",\" \"\", \",\" \",\" \",\", \"\", \",\", \"\", \",\", \"\", \",\", \"\", \",\", \",\", \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\" \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \""}, {"heading": "4.1 Payment Mechanism", "text": "The proposed payment mechanism is described in algorithm 2.Algorithm 2: Incentive mechanism for confidence-based adjustment \u2022 Inputs: I thresholds S1,..., SL and T1,.., TL I budgetary parameters \u00b5max and \u00b5min I ratings (x1,.., xG) \u2022 Inputs: I thresholds S1,..., + L} G of the worker's answers to the G gold standard questions \u2022 Set \u03b1 \u2212 L,.., \u03b1L asI \u03b1L = 1 SL, \u03b1 \u2212 L = 0 I For l,. {L \u2212 1,.,., 1}, \u03b1l = (1 \u2212 Sl) Tl + 1 + (1 \u2212 Sl) (1 \u2212 Tl + 1) \u03b1 \u2212 (l + 1) \u03b1L \u2212 (1 \u2212 Tl + 1), (1 \u2212 L) and (1 \u2212 L) (1 \u2212 Sl,."}, {"heading": "4.2 Uniqueness of this Mechanism", "text": "Theorem 8 The payment mechanism of Algorithm 2 is the only incentive-compatible mechanism that meets the generalized no-free lunch condition. Proof of Theorem 8 is provided in Appendix A.3. Proof is conceptually similar to that of Theorem 8, but involves solving several additional complexities arising from the emergence of multiple confidence levels."}, {"heading": "5 A Stronger No-free-lunch Condition: Impossibility Results", "text": "This year is the highest in the history of the country."}, {"heading": "6 Simulations and Experiments", "text": "In this section, we present synthetic simulations and real-life experiments to evaluate the impact of our setting and mechanism on final label quality."}, {"heading": "6.1 Synthetic Simulations", "text": "We deal with synthetic simulations in order to understand the effects of different distributions of trust and labeling of errors. We consider binary selection questions in this set of simulations. Whenever a worker answers a question, his confidence in the correct answer is drawn from a distribution that is independent of everything else. \u2022 We examine the effects of the following five decisions of distribution P: \u2022 The even distribution on the support [0,5, 1]. \u2022 A triangular distribution with low endpoint 0.2, upper endpoint 1 and a mode of 0.6. \u2022 A beta distribution with parameter values \u03b1 = 5 and \u03b2 = 1. The hammer-spammer distribution [KOS11]: Even distribution with the discrete endpoint {0,5, 1}."}, {"heading": "6.2 Experiments on Amazon Mechanical Turk", "text": "We conducted initial experiments on the commercial crowdsourcing platform Amazon Mechanical Turk (mturk.com) to evaluate our proposed scheme in real-world scenarios. Full data, including the interface presented to the workers in each of the tasks, the results obtained from the workers and the ground truth solutions, are available on the first author's website."}, {"heading": "6.2.1 Goal", "text": "Before going into detail, we first point out certain caveats associated with such an investigation of mechanism design on crowdsourcing platforms. If a worker encounters a mechanism only for a short time (a handful of tasks in typical research experiments) and for a small amount of money (a few dollars at most in typical crowdsourcing tasks), we cannot expect the worker to fully understand the mechanism and act exactly as needed. For example, we would not expect our test results to change significantly even with moderate changes in the amounts promised, and we also expect the results to be loud. Incentive compatibility begins when the worker encounters a mechanism in the longer term, for example when a proposed mechanism is adopted as the standard for a platform, or when higher amounts are involved. In this case, we would expect workers or others (e.g. bloggers or researchers) to develop strategies that can play the mechanism. The theoretical guarantee of incentive compatibility then prevents such gaming in the long term."}, {"heading": "6.2.2 Experimental setup", "text": "We conducted our experiments on the commercial crowdsourcing platform \"Amazon Mechanical Turk\" (mturk.com), on which individuals or companies (so-called \"requests\") can perform tasks, and each individual (so-called \"worker\") can complete the task over the Internet for a pre-determined fee. Payment can consist of two parts: a fixed component that is identical for all workers performing the task, and a \"bonus\" that can be different for different workers and is paid at the requester's discretion. We designed nine experiments (tasks) ranging from image descriptions to text and speech recognition; the individual experiments are described in more detail in Appendix B. All of the experiments included objective questions, and the answers that came out were multiple choice in five of the experiments and free text in the rest. For each experiment, we tested three settings: (i) the conventional basic setting (Figure 1) with a specific worker performing a task."}, {"heading": "6.2.3 Results: Raw data", "text": "Figure 4 shows for the baseline, skipped and trust-based mechanisms for all nine experiments, (i) the fraction of the questions that were incorrectly answered, (ii) the fraction of the questions that were incorrectly answered in the attempted questions, (iii) the average payment to an employee (in cents), and (iv) the breakdown of the answers relative to the fraction of the answers in each trust level. Figure 4 shows that the number of errors among the attempted questions is on average over 100 (random) selections of the gold standard questions, much lower than the trust-based settings prior to the basic setting. Also, note that in the trust-based setting, the answers are expected to be more correct. Overall spending among the attempted questions is much lower in the skip and the trust-based settings prior to the basic setting."}, {"heading": "6.2.4 Results: Aggregated data", "text": "We saw in the previous section that under the skip-based setting, the error rate among the attempted questions was significantly lower than the error rate in the basic setting. However, the skip-based setting was also constructively associated with lower amounts of data due to questions skipped by the workers. To this end, we looked at the five experiments consisting of multiple-choice questions. We had a parameter num-worker values taken in terms of end data quality, i.e. the amount of error data was aggregated. To this end, we looked at the five experiments consisting of multiple-choice questions."}, {"heading": "7 Discussion and Conclusions", "text": "In this concluding section, we will first discuss the modelling assumptions we have made in this paper, followed by a discussion of future work and concluding remarks."}, {"heading": "7.1 Modelling Assumptions", "text": "In forming the model for our problem, as in any other area of theoretical research, we had to make certain assumptions and decisions. Below, we discuss the reasons for the modeling decisions we make. \u2022 Use of gold standard questions. We assume that gold standard questions are in the task, i.e., a subset of questions to which the system developer knows the answers. \u2022 The existence of gold standard is common in crowdsourcing platforms [LEHB10, CMBN11]. \u2022 Workers aiming to maximize their expected payments: We assume that workers want to maximize their expected payments. In many other problems of game theory, people are often assumed to be \"risk averse\" and aim to maximize the expected value of their payments."}, {"heading": "7.2 Open problems", "text": "We will discuss two sets of open problems, one from a practical perspective and another on the theoretical front. First, we assumed in the thesis that the mechanism was provided with the number of total questions N in a task, the number of gold standard questions G, and the threshold T for skipping (or the number and thresholds of different confidence levels). While these parameters can be hand-selected by a system designer based on their own experience, a more principled design of these parameters is an important question. Decisions for these parameters may have to be made on the basis of certain compromises. Thus, for example, a higher value of G reduces the deviation in payments, but uses more resources in relation to gold standard questions. Or, for example, a greater number of threshold levels would increase the amount of information obtained about the convictions of the workers on their own conviction levels. A second open problem is the design of inference algorithms that can take advantage of the levels of the specific structure of skipping levels from Snorm levels from Snorm levels."}, {"heading": "7.3 Conclusions", "text": "Despite remarkable advances in machine learning and artificial intelligence, many problems cannot be solved by humans or machines alone. In recent years, crowdsourcing has emerged as a powerful tool for combining human and machine intelligence. Crowdsourcing is also a standard tool for collecting data for machine learning. However, crowdsourcing is often plagued with the problem of low-quality work results. We have designed a reward mechanism for crowdsourcing to ensure the collection of high-quality data. Under a very natural \"no-free lunch\" axiom, we mathematically prove that our mechanism is surprisingly the only viable reward mechanism. We also show that our \"multiplicative\" mechanism, among all possible incentive-compatible mechanisms, makes the strictly minimum effort for spammers. In preliminary experiments, we observe a significant decrease in error rates among this unique mechanism, indicating that our basic mechanism has the potential to work well."}, {"heading": "Acknowledgements", "text": "The work of Nihar B. Shah was partly funded by a Microsoft Research PhD Fellowship. We thank John C. Platt, Christopher J. C. Burges and Christopher Meek for many inspiring discussions. We also thank John C. Platt and Martin J. Wainwright for their help in proofreading and polishing portions of the manuscript. This work was done when Nihar B. Shah was an intern at Microsoft Research."}, {"heading": "A Proofs", "text": "In this section, we will prove the claimed theoretical results, the proofs of which are not included in the main text of the paper. Incentive compatibility property does not change with any shifting of the mechanism by a constant value or a scaling by a positive constant value. Consequently, for the purposes of these proofs, we can assume that \u00b5min = 0 without loss of universality."}, {"heading": "A.1 Proof of Lemma 4: The Workhorse Lemma", "text": "First we consider the case of G = N. In the sentence {y1.,...), yi \u2212 1, yi + 1,.., yG}, for some (. \u2212 \u2212 \u2212 \u2212 \u2212 1,., G \u2212 1, 2, we assume that there are \u03b7 elements with a value of 1, \u03b3 elements with a value of -1, and (G \u2212 1,.) elements with a value of 0. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 1,. \u2212 1, y1 = 1,., y\u03b7 + 1 = \u2212 1,.,. (.), y\u03b7 + 1 = \u2212 1,. (G \u2212 1,.),."}, {"heading": "A.2 Proof of Theorem 7: Working of Algorithm 2", "text": "We first specify three properties that the constants {\u03b1l} Ll = \u2212 L defined in algorithm 2 = any arbitrary result must fulfill. We will then use these properties in the proof of theorem 7. Lemma 13 for each l-level {0,.., L \u2212 1} Tl + 1\u03b1l + 1 trust (1 \u2212 Tl + 1) \u03b1 \u2212 (l + 1) = Tl + 1\u03b1l + (1 \u2212 Tl + 1) \u03b1 (1 \u2212 L)., (11) andSl + 1\u03b1ji trust + 1 + (1 \u2212 Sl + 1) trust (1 \u2212 Tl + 1). (1). (12) Lemma 14 \u03b1l + (1 > \u03b1ji). L \u2212 1 > \u03b1ji (1 \u2212 L). For each m {1,.,., p > Tm and each z < m and each z < m < m (1) < m (1 \u2212 p)."}, {"heading": "A.2.1 Proof of Lemma 13", "text": "Algorithm 2 states that \u03b1 \u2212 l = 1 \u2212 \u2212 \u2212 \u2212 Sl1 \u2212 > Sl = > Sl for all l > l > l (l).A simple rearrangement of the terms in this expression results in (12).In order to achieve the objective of the test (11), we will first prove an intermediate result: \u03b1l > 1 > \u03b1 \u2212 l \u00b2 {L,.., 1}.The induction hypothesis contains two claims: \u03b1l > 1 > \u03b1 \u2212 l and Tl\u03b1l + (1 \u2212 Tl) \u03b1 \u2212 l > 1. The base case is l = L \u2212 for which we know that \u03b1L = 1SL > 1 > 0 = \u03b1 \u2212 L and Tl\u03b1l + (1 \u2212 Tl) 1. Now let us assume that the induction hypothesis for (l + 1 \u2212 subproduction) is true."}, {"heading": "A.2.2 Proof of Lemma 14", "text": "Next, we will show that \u03b1l + 1 > \u03b1l and \u03b1 \u2212 (l + 1) < \u03b1l \u2212 l > l \u2265 0. Let us first consider l = 0, for which algorithm sets 2 \u03b10 = 1, and we have already proven that \u03b11 > \u03b1l \u2212 1. Let us now consider some l > 0. Let us observe this since Sl\u03b1l + (1 \u2212 Sl) \u03b1 \u2212 l = 1 (Lemma 13), Sl + 1 > Sl and \u03b1l > \u03b1 \u2212 l, it must be that Sl + 1\u03b1l + (1 \u2212 Sl + 1) \u2212 l \u2212 1. (26) From Lemma 13 we also have Sl + 1\u03b1l + 1 (1 \u2212 Sl + 1) (1 \u2212 Sl + 1) \u03b11 (1) = 1. (27) \u2212 \u2212 \u2212 \u2212 \u2212 l \u2212 Sl \u2212 1 (1 \u2212 l) and we also have Sl + 1\u03b1l (1 \u2212 l)."}, {"heading": "A.2.3 Proof of Lemma 15", "text": "Let us first consider the case z = m \u2212 \u2212 1. From term 13 we know that Tm\u03b1m \u2212 1 + (1 \u2212 Tm) \u03b1 \u2212 (m \u2212 1) = Tm\u03b1m + (1 \u2212 Tm) \u03b1 \u2212 m \u21d2 0 = Tm (\u03b1m \u2212 \u03b1m \u2212 1) + Tm (\u03b1 \u2212 (m \u2212 1) \u2212 m) \u2212 (\u03b1 \u2212 (m \u2212 1) \u2212 (34) is a sequence of p > Tm and Lemma 14. A simple rearrangement of the terms into (34) results in (13) + p (\u03b1 \u2212 1) \u2212 m) \u2212 (m \u2212 m). Now, for each z < m, recursively applicable, this result results in getp\u03b1m + (1 \u2212 m)."}, {"heading": "A.3 Proof of Theorem 8: Uniqueness of Algorithm 2", "text": "We will first define an additional piece of notation. Let g: {\u2212 L,., L} N \u2192 R + denote the expected payment based on an assessment of the N-answers, where the expectation is regarding the (uniformly random) choice of G-Gold standard questions. If (x1,.., xN). If (x1,.., xN). If (x1,.., xN). If (x1,.). If (x1,..., xN). (x1,.,.). (x.) N). (1). (x.).,........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"}, {"heading": "A.5 Necessity of Tl > Sl for the Problem to be Well Defined", "text": "We now show that the restriction Tl > Sl was necessary in defining the thresholds in Section 4.Proposition 17 (Incentive Compatibility) Tl > \u2212 \u2212 \u2212 \u2212 l = 63., L}, even if there is no generalized, non-free lunch axiom. First, let's note that the proof for Lemma 16 is not the generalized, non-free lunch axiom (2,. \u2212 \u2212 \u2212 \u2212 l) used to prove the result of Lemma 16. Let's question the employee's confidence for all but for the first question (T1, and that the employee decides to skip all of these questions. Suppose the employee tries the first question. To ensure that the answer he believes most likely to be true."}, {"heading": "A.6 A Stronger No-free-lunch Condition: Impossibility Results", "text": "In this section, we prove the various claims regarding the strict free lunch examined in Section 5."}, {"heading": "A.6.1 Proof of Proposition 9", "text": "If the employee skips all questions, then the expected pay is zero according to the principle of a strong lunch table. Suppose the pay is strictly positive if questions {1,.., z} are answered correctly, questions {z + 1,.., z \u2032} are answered incorrectly and the remaining questions are skipped. If the confidence of the ignorant employee lies in the interval (0, T) for each question, then the attempt to answer questions {1,..., z \u2032} and skip the rest leads to a payment that is strictly positive in expectation. Thus, this ignorant employee is encouraged to answer at least one question."}, {"heading": "A.6.2 Proof of Proposition 10", "text": "(1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1. (1). (1). (1). (1. (1). (1). (1. (1). (1). (1. (1). (1). (1. (1). (1). (1. (1). (1). (1. (1). (1). (1. (1).). (1. (1.). (1.). (1.). (1.). (1. (1.). (1.).). (1. (1.). (1.). (1.).). (1. (1.). (1.). (1. (1. (1.).). (1. (1.). (1.). (1. (1.). (1.). (1.). (1.). (1.). (1. (1. (1.). (1. (1.). (1.).). (1. (1. (1.). (1.). (1.). (1. (1. (1.). (1.).). (1"}, {"heading": "A.6.3 Proof of Proposition 11", "text": "First, we will show that the mechanism works as desired. First, we will consider the case if the employee is unwittingly present and his trust in the form T > p (1) p (2) p (3) p (4) p (G) p (G) p (G) \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "A.6.4 Proof of Proposition 12", "text": "This part of the proof of sentence 11 applies even if L > 1. It follows that for each question the penalty for an incorrect answer is the same for each level of trust in {1,..., L}. Thus, the employee is encouraged to always choose the level of trust for which the payment is the maximum if the answer is correct, regardless of her own confidence in the question. This is contrary to our requirements."}, {"heading": "B Details of Experiments", "text": "The experiments were conducted on the online crowdsourcing platform Amazon Mechanical Turk (mturk.com) between June and October 2013. Figure 6 illustrates the interface shown to the workers for each of the experiments described in Section 6.2, while Figure 7 illustrates the instructions given to the workers. Below, more details on each individual experiment can be found. The description defines the notation \u043a as defined in Algorithm 1 and Algorithm 2, namely \u03b7 = (\u00b5max \u2212 \u00b5min) TG for the jump-based setting and \u0432 = (\u00b5max \u2212 \u00b5min) (1 \u03b1L) G for the trust-based setting."}, {"heading": "B.1 Recognizing the Golden Gate Bridge", "text": "An example of this task is shown in Figure 6a, and the instructions given to the worker under the three mechanisms are shown in Figure 7. The fixed amount offered to the workers for the task was \u00b5min = 3 cents, and the bonus was based on 3 gold standard questions. We compared (a) the basic mechanism with 5 cents for each correct answer in the gold standard, (b) the jump-based mechanism with \u0432 = 5.9 and 1T = 1.5, and (c) the confidence-based mechanism with \u0432 = 5.9 cents, L = 2, \u03b12 = 1.5, \u03b11 = 1.4, \u03b10 = 1, \u03b1 \u2212 1 = 0.5, \u03b1 \u2212 2 = 0. The results of this experiment are shown in Figure 4a."}, {"heading": "B.2 Transcribing Vehicles\u2019 License Plate Numbers from Photographs", "text": "This task provided the workers with 18 photos of cars and asked them to transcribe the number plates of each of them (source of the photos: http: / / www.coolpl8z.com). An example of this task is shown in Figure 6b. The fixed amount offered to the workers for the task was \u00b5min = 4 cents, and the bonus was based on 4 standard gold questions. We compared (a) the basic mechanism with 10 cents for each correct answer in the gold standard, (b) the skip-based mechanism with \u0432 = 0.62 and 1T = 3, and (c) the trust-based mechanism with \u0432 = 3.1 cent, L = 2, \u03b12 = 2, \u03b11 = 1.95, \u03b10 = 1, \u03b1 \u2212 1 = 0.5 \u03b1 \u2212 2 = 0. The results of this experiment are presented in Figure 4b. When evaluating both the answers of the worker and the true solutions, we converted the entire text into uppercase letters and removed all spaces and punctuations."}, {"heading": "B.3 Classifying Breeds of Dogs", "text": "This task required the workers to identify the dog breeds shown in 85 images (image source: [KJYL11, DDS + 09]). For each image, the worker was given ten breeds to choose from. An example of this task is shown in Figure 6c. The fixed amount offered to the workers was \u00b5min = 5 cents for the task, and the bonus was based on 7 gold standard questions. We compared (a) the basic mechanism with 8 cents for each correct answer in the gold standard, (b) the jump-based mechanism with x = 0.78 and 1T = 2, and (c) the trust-based mechanism with x = 0.78 cents, L = 2, \u03b12 = 2, \u03b11 = 1.66, \u03b10 = 1, \u03b1 -1 = 0.67, \u03b1 -2 = 0. The results of this experiment are presented in Figure 4c.B.4, with the identification of the leaders of CountriesNames and 20 personalities given and had to be classified as whether they were ever the President of India or the President."}, {"heading": "B.6 Distinguishing Textures", "text": "This task required the workers to identify the textures represented in 24 grayscale images (image source: [LSP05, dataset 1: Textured surfaces]. For each image, the worker had to choose between 8 different options. Such a task has applications in the field of computer vision, where it helps to detect objects or their surroundings. An example of this task is shown in Figure 6f. The fixed amount offered to the workers for the task was \u00b5min = 3 cents, and the bonus was based on 4 gold standard questions. We compared (a) the basic mechanism with 10 cents for each correct answer in the gold standard, (b) the skip-based mechanism with \u0432 = 3.1 and 1T = 2, and (c) the confidence-based mechanism with \u0432 = 3.1 cent, L = 2, \u03b12 = 2, \u03b11 = 1.66, \u03b10 = 1, \u03b1 \u2212 1 = 0.67, \u03b1 \u2212 2 = 0. The results of this experiment are shown in Figure 4f."}, {"heading": "B.7 Transcribing Text from an Image: Film Certificate", "text": "The task showed an image containing 11 (short) lines of blurred text that the workers had to decipher. We used text from a specific certificate broadcast in India. We slightly modified the text to prevent the workers from searching for part of it online and getting the entire text by searching the first few transcribed lines on the Internet. An example of this task is shown in Figure 6g. The fixed amount offered to the workers was \u00b5min = 5 cents for the task, and the bonus was based on 2 gold standard questions. We compared (a) the basic mechanism with 20 cents for each correct answer in the gold standard, (b) the skip mechanism with area value = 5.5 and 1T = 3, and (c) the trust-based mechanism with area value = 12.5 cents, L = 2, B = 2, B = 1 = 1.95, B = 0, H \u2212 1 = 0.5, H \u2212 2 \u2212 the results of this experiment are shown in Figure 4g."}, {"heading": "B.8 Transcribing Text from an Image: Script of a Play", "text": "The task showed an image containing 12 (short) lines of blurred text that the workers had to decipher. We borrowed a paragraph from Shakespeare's play \"As You Like It.\" We slightly modified the text of the play to prevent the workers from searching for part of it online and obtaining the entire text by searching through the first transcribed lines on the Internet. An example of this task is shown in Figure 6h. The fixed amount offered to the workers was 5 cents for the task, and the bonus was based on 2 gold standard questions. We compared (a) the basic mechanism with \u00b5min = 20 cents for each correct answer in the gold standard, (b) the skip mechanism with \u0432 = 5.5 and 1T = 3, and (c) the confidence-based mechanism with \u0456 = 12.5 cents, L = 2, \u03b12 = 2, \u03b11 = 1.95, \u03b10 = 1 = 0.5, \u03b1 \u2212 2 = 0. The results of this experiment are presented in Figure 4h."}, {"heading": "B.9 Transcribing Text from Audio Clips", "text": "Each audio clip was 3 to 6 seconds long and consisted of a short sentence, such as: \"My favorite topics are sports, politics and movies.\" Each of the clips was recorded with a text-to-speech converter in different accents. An example of this task is shown in Figure 6i. The fixed amount offered to the worker for the task was \u00b5min = 5 cents, and the bonus was based on 2 gold standard questions. We compared (a) the basic mechanism with 20 cents for each correct answer in the gold standard, (b) the skip-based mechanism with \u0432 = 5.5 and 1 T = 3, and (c) the confidence-based mechanism with \u0432 = 12.5 cents, L = 2, \u03b12 = 2, \u03b11 = 1.95, \u03b10 = 1, \u03b1 \u2212 1 = 0.5, \u03b1 \u2212 2 = 0. The results of this experiment are presented in Figure 4i."}, {"heading": "Transcribe*the** license*plate*number*", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C General Utility Functions", "text": "In this section, we will consider a setting in which the worker, instead of maximizing his expected payment, aims to maximize the expected value of any utility function of his pay. Let's consider any function U: R + \u2192 I, where I am any interval on the real number line. We will require the function U to be strictly increased and to have a reversal. Examples of such functions are U (x) = Log (1 + x) with I = R +, U (x) = 1 \u2212 e \u2212 x with I = [0, 1]. For each payment f made to the worker (based on the evaluation of their answers to the gold standard questions), their benefit for this payment is U (f). The worker aims to maximize the expected value of U (f), with the expectation regarding their beliefs about the accuracy of their answers and the uniform random distribution of the G gold standard questions."}], "references": [{"title": "Mechanism design for crowdsourcing: An optimal 1-1/e competitive budget-feasible mechanism for large markets", "author": ["Nima Anari", "Gagan Goel", "Afshin Nikzad"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "Anari et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Anari et al\\.", "year": 2014}, {"title": "Learning from noisy examples", "author": ["Dana Angluin", "Philip Laird"], "venue": "Machine Learning,", "citeRegEx": "Angluin and Laird.,? \\Q1988\\E", "shortCiteRegEx": "Angluin and Laird.", "year": 1988}, {"title": "Boosting algorithms: Regularization, prediction and model fitting", "author": ["Peter B\u00fchlmann", "Torsten Hothorn"], "venue": "Statistical Science,", "citeRegEx": "B\u00fchlmann and Hothorn.,? \\Q2007\\E", "shortCiteRegEx": "B\u00fchlmann and Hothorn.", "year": 2007}, {"title": "Soylent: a word processor with a crowd inside", "author": ["Michael S Bernstein", "Greg Little", "Robert C Miller", "Bj\u00f6rn Hartmann", "Mark S Ackerman", "David R Karger", "David Crowell", "Katrina Panovich"], "venue": "In ACM symposium on User interface software and technology (UIST),", "citeRegEx": "Bernstein et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bernstein et al\\.", "year": 2010}, {"title": "Social science for pennies", "author": ["John Bohannon"], "venue": "Science, 334(6054):307\u2013307,", "citeRegEx": "Bohannon.,? \\Q2011\\E", "shortCiteRegEx": "Bohannon.", "year": 2011}, {"title": "How well does active learning actually work?: Timebased evaluation of cost-reduction strategies for language documentation", "author": ["Jason Baldridge", "Alexis Palmer"], "venue": "In Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Baldridge and Palmer.,? \\Q2009\\E", "shortCiteRegEx": "Baldridge and Palmer.", "year": 2009}, {"title": "Verification of forecasts expressed in terms of probability", "author": ["Glenn W Brier"], "venue": "Monthly weather review,", "citeRegEx": "Brier.,? \\Q1950\\E", "shortCiteRegEx": "Brier.", "year": 1950}, {"title": "Loss functions for binary class probability estimation and classification: Structure and applications", "author": ["Andreas Buja", "Werner Stuetzle", "Yi Shen"], "venue": "Working draft,", "citeRegEx": "Buja et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Buja et al\\.", "year": 2005}, {"title": "Pairwise ranking aggregation in a crowdsourced setting", "author": ["Xi Chen", "Paul N Bennett", "Kevyn Collins-Thompson", "Eric Horvitz"], "venue": "In ACM international conference on Web search and data mining,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Coupled semi-supervised learning for information extraction", "author": ["Andrew Carlson", "Justin Betteridge", "Richard C Wang", "Estevam R Hruschka Jr.", "Tom M Mitchell"], "venue": "In ACM international conference on Web search and data mining,", "citeRegEx": "Carlson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Learning from noisy information in fasart and fasback neuro-fuzzy systems", "author": ["Izquierdo JM Cano", "Yannis A Dimitriadis", "S\u00e1nchez E G\u00f3mez", "Coronado J L\u00f3pez"], "venue": "Neural networks: the official journal of the International Neural Network Society,", "citeRegEx": "Cano et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Cano et al\\.", "year": 2001}, {"title": "Optimum statistical estimation with strategic data sources", "author": ["Yang Cai", "Constantinos Daskalakis", "Christos H Papadimitriou"], "venue": "In Conference on Learning Theory (COLT),", "citeRegEx": "Cai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2015}, {"title": "Opportunities for crowdsourcing research on amazon mechanical", "author": ["Jenny J Chen", "Natala J Menezes", "Adam D Bradley", "TA North"], "venue": "turk. Interfaces,", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "An adaptive learning approach for noisy data streams", "author": ["Fang Chu", "Yizhou Wang", "Carlo Zaniolo"], "venue": "In IEEE International Conference on Data Mining (ICDM),", "citeRegEx": "Chu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Chu et al\\.", "year": 2004}, {"title": "Imagenet: A largescale hierarchical image database", "author": ["Jia Deng", "Wei Dong", "Richard Socher", "Li-Jia Li", "Kai Li", "Li Fei-Fei"], "venue": "In IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Incentive compatible regression learning", "author": ["Ofer Dekel", "Felix Fischer", "Ariel D Procaccia"], "venue": "In ACM-SIAM symposium on Discrete algorithms,", "citeRegEx": "Dekel et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2008}, {"title": "Maximum likelihood estimation of observer error-rates using the EM algorithm", "author": ["Alexander Philip Dawid", "Allan M Skene"], "venue": "Applied statistics,", "citeRegEx": "Dawid and Skene.,? \\Q1979\\E", "shortCiteRegEx": "Dawid and Skene.", "year": 1979}, {"title": "CrowdDB: answering queries with crowdsourcing", "author": ["Michael J Franklin", "Donald Kossmann", "Tim Kraska", "Sukriti Ramesh", "Reynold Xin"], "venue": "In ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Franklin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Franklin et al\\.", "year": 2011}, {"title": "Putting your money where your mouth is: A betting platform for better prediction", "author": ["Fang Fang", "Maxwell Stinchcombe", "Andrew Whinston"], "venue": "Review of Network Economics,", "citeRegEx": "Fang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Fang et al\\.", "year": 2007}, {"title": "Strictly proper scoring rules, prediction, and estimation", "author": ["Tilmann Gneiting", "Adrian E Raftery"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Gneiting and Raftery.,? \\Q2007\\E", "shortCiteRegEx": "Gneiting and Raftery.", "year": 2007}, {"title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "author": ["Geoffrey Hinton", "Li Deng", "Dong Yu", "George E Dahl", "Abdel-rahman Mohamed", "Navdeep Jaitly", "Andrew Senior", "Vincent Vanhoucke", "Patrick Nguyen", "Tara N Sainath"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Adaptive task assignment for crowdsourced classification", "author": ["Chien-Ju Ho", "Shahin Jabbari", "Jennifer W Vaughan"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Ho et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ho et al\\.", "year": 2013}, {"title": "Negative results for active learning with convex losses", "author": ["Steve Hanneke", "Liu Yang"], "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Hanneke and Yang.,? \\Q2010\\E", "shortCiteRegEx": "Hanneke and Yang.", "year": 2010}, {"title": "Repeated labeling using multiple noisy labelers", "author": ["Panagiotis G Ipeirotis", "Foster Provost", "Victor S Sheng", "Jing Wang"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "Ipeirotis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ipeirotis et al\\.", "year": 2014}, {"title": "Optimal number of questionnaire response categories more may not be better", "author": ["W Paul Jones", "Scott A Loe"], "venue": "SAGE Open,", "citeRegEx": "Jones and Loe.,? \\Q2013\\E", "shortCiteRegEx": "Jones and Loe.", "year": 2013}, {"title": "Reputation-based worker filtering in crowdsourcing", "author": ["Srikanth Jagabathula", "Lakshminarayanan Subramanian", "Ashwin Venkataraman"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Jagabathula et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jagabathula et al\\.", "year": 2014}, {"title": "Crystal structure of a monomeric retroviral protease solved by protein folding game players", "author": ["Firas Khatib", "Frank DiMaio", "Seth Cooper", "Maciej Kazmierczyk", "Miroslaw Gilski", "Szymon Krzywda", "Helena Zabranska", "Iva Pichova", "James Thompson", "Zoran Popovi\u0107", "Mariusz Jaskolski", "David Baker"], "venue": "Nature structural & molecular biology,", "citeRegEx": "Khatib et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Khatib et al\\.", "year": 2011}, {"title": "Combining human and machine intelligence in large-scale crowdsourcing", "author": ["Ece Kamar", "Severin Hacker", "Eric Horvitz"], "venue": "In International Conference on Autonomous Agents and Multiagent Systems,", "citeRegEx": "Kamar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kamar et al\\.", "year": 2012}, {"title": "Novel dataset for fine-grained image categorization", "author": ["Aditya Khosla", "Nityananda Jayadevaprakash", "Bangpeng Yao", "Fei-fei Li. L"], "venue": "In First Workshop on Fine-Grained Visual Categorization,", "citeRegEx": "Khosla et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Khosla et al\\.", "year": 2011}, {"title": "Crowdsourcing for book search evaluation: impact of HIT design on comparative system ranking", "author": ["Gabriella Kazai", "Jaap Kamps", "Marijn Koolen", "Natasa Milic-Frayling"], "venue": "In ACM SIGIR conference on Research and development in Information Retrieval,", "citeRegEx": "Kazai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kazai et al\\.", "year": 2011}, {"title": "Iterative learning for reliable crowdsourcing systems. In Advances in neural information processing systems", "author": ["David R Karger", "Sewoong Oh", "Devavrat Shah"], "venue": null, "citeRegEx": "Karger et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Karger et al\\.", "year": 2011}, {"title": "Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution", "author": ["John Le", "Andy Edmonds", "Vaughn Hester", "Lukas Biewald"], "venue": "In SIGIR 2010 workshop on crowdsourcing for search evaluation,", "citeRegEx": "Le et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Le et al\\.", "year": 2010}, {"title": "A hybrid neural network model for noisy data regression. Systems, Man, and Cybernetics, Part B: Cybernetics", "author": ["Eric WM Lee", "Chee Peng Lim", "Richard KK Yuen", "SM Lo"], "venue": "IEEE Transactions on,", "citeRegEx": "Lee et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2004}, {"title": "Variational inference for crowdsourcing", "author": ["Qiang Liu", "Jian Peng", "Alexander T Ihler"], "venue": "In NIPS,", "citeRegEx": "Liu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Using Amazon Mechanical Turk to transcribe historical handwritten documents", "author": ["ASID Lang", "Joshua Rio-Ross"], "venue": "The Code4Lib Journal,", "citeRegEx": "Lang and Rio.Ross.,? \\Q2011\\E", "shortCiteRegEx": "Lang and Rio.Ross.", "year": 2011}, {"title": "Eliciting truthful answers to multiple-choice questions", "author": ["Nicolas Lambert", "Yoav Shoham"], "venue": "In ACM conference on Electronic commerce,", "citeRegEx": "Lambert and Shoham.,? \\Q2009\\E", "shortCiteRegEx": "Lambert and Shoham.", "year": 2009}, {"title": "Random classification noise defeats all convex potential boosters", "author": ["Philip M Long", "Rocco A Servedio"], "venue": "Machine Learning,", "citeRegEx": "Long and Servedio.,? \\Q2010\\E", "shortCiteRegEx": "Long and Servedio.", "year": 2010}, {"title": "A sparse texture representation using local affine regions", "author": ["Svetlana Lazebnik", "Cordelia Schmid", "Jean Ponce"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Lazebnik et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Lazebnik et al\\.", "year": 2005}, {"title": "The magical number seven, plus or minus two: some limits on our capacity for processing information", "author": ["George A Miller"], "venue": "Psychological review,", "citeRegEx": "Miller.,? \\Q1956\\E", "shortCiteRegEx": "Miller.", "year": 1956}, {"title": "Noise tolerance under risk minimization", "author": ["Naresh Manwani", "PS Sastry"], "venue": "IEEE Transactions on Cybernetics,", "citeRegEx": "Manwani and Sastry.,? \\Q2013\\E", "shortCiteRegEx": "Manwani and Sastry.", "year": 2013}, {"title": "Boosted classification trees and class probability/quantile estimation", "author": ["David Mease", "Abraham J Wyner", "Andreas Buja"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Mease et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Mease et al\\.", "year": 2007}, {"title": "Learning from crowds", "author": ["Vikas C Raykar", "Shipeng Yu", "Linda H Zhao", "Gerardo Hermosillo Valadez", "Charles Florin", "Luca Bogoni", "Linda Moy"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Raykar et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Raykar et al\\.", "year": 2010}, {"title": "Elicitation of personal probabilities and expectations", "author": ["Leonard J Savage"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Savage.,? \\Q1971\\E", "shortCiteRegEx": "Savage.", "year": 1971}, {"title": "Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence", "author": ["Nihar B Shah", "Sivaraman Balakrishnan", "Joseph Bradley", "Abhay Parekh", "Kannan Ramchandran", "Martin J Wainwright"], "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Shah et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shah et al\\.", "year": 2015}, {"title": "Seven plus or minus two: A commentary on capacity limitations", "author": ["Richard M Shiffrin", "Robert M Nosofsky"], "venue": "Psychological Review,", "citeRegEx": "Shiffrin and Nosofsky.,? \\Q1994\\E", "shortCiteRegEx": "Shiffrin and Nosofsky.", "year": 1994}, {"title": "reCAPTCHA: Human-based character recognition via web security", "author": ["Luis Von Ahn", "Benjamin Maurer", "Colin McMillen", "David Abraham", "Manuel Blum"], "venue": "measures. Science,", "citeRegEx": "Ahn et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ahn et al\\.", "year": 2008}, {"title": "How much spam can you take? An analysis of crowdsourcing results to increase accuracy", "author": ["Jeroen Vuurens", "Arjen P de Vries", "Carsten Eickhoff"], "venue": "In ACM SIGIR Workshop on Crowdsourcing for Information Retrieval,", "citeRegEx": "Vuurens et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Vuurens et al\\.", "year": 2011}, {"title": "Reliable crowdsourcing for multiclass labeling using coding theory", "author": ["Aditya Vempaty", "Lav R Varshney", "Pramod K Varshney"], "venue": "IEEE Journal of Selected Topics in Signal Processing,", "citeRegEx": "Vempaty et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Vempaty et al\\.", "year": 2014}, {"title": "Bayesian bias mitigation for crowdsourcing", "author": ["Fabian L Wauthier", "Michael Jordan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Wauthier and Jordan.,? \\Q2011\\E", "shortCiteRegEx": "Wauthier and Jordan.", "year": 2011}, {"title": "Towards building a high-quality workforce with Mechanical Turk", "author": ["Paul Wais", "Shivaram Lingamneni", "Duncan Cook", "Jason Fennell", "Benjamin Goldenberg", "Daniel Lubarov", "David Marin", "Hari Simons"], "venue": "NIPS workshop on computational social science and the wisdom of crowds,", "citeRegEx": "Wais et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wais et al\\.", "year": 2010}, {"title": "Task matching in crowdsourcing", "author": ["Man-Ching Yuen", "Irwin King", "Kwong-Sak Leung"], "venue": "In IEEE International Conference on Cyber, Physical and Social Computing,", "citeRegEx": "Yuen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yuen et al\\.", "year": 2011}, {"title": "Optimal PAC multiple arm identification with applications to crowdsourcing", "author": ["Yuan Zhou", "Xi Chen", "Jian Li"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Zhou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2014}, {"title": "Spectral methods meet EM: A provably optimal algorithm for crowdsourcing", "author": ["Yuchen Zhang", "Xi Chen", "Dengyong Zhou", "Michael I Jordan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Learning from the wisdom of crowds by minimax entropy", "author": ["Dengyong Zhou", "John Platt", "Sumit Basu", "Yi Mao"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Zhou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2012}], "referenceMentions": [], "year": 2015, "abstractText": "Crowdsourcing has gained immense popularity in machine learning applications for obtaining large amounts of labeled data. Crowdsourcing is cheap and fast, but suffers from the problem of low-quality data. To address this fundamental challenge in crowdsourcing, we propose a simple payment mechanism to incentivize workers to answer only the questions that they are sure of and skip the rest. We show that surprisingly, under a mild and natural \u201cno-free-lunch\u201d requirement, this mechanism is the one and only incentive-compatible payment mechanism possible. We also show that among all possible incentivecompatible mechanisms (that may or may not satisfy no-free-lunch), our mechanism makes the smallest possible payment to spammers. We further extend our results to a more general setting in which workers are required to provide a quantized confidence for each question. Interestingly, this unique mechanism takes a \u201cmultiplicative\u201d form. The simplicity of the mechanism is an added benefit. In preliminary experiments involving over 900 worker-task pairs, we observe a significant drop in the error rates under this unique mechanism for the same or lower monetary expenditure.", "creator": "LaTeX with hyperref package"}}}