{"id": "1408.6788", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Aug-2014", "title": "Strongly Incremental Repair Detection", "abstract": "We present STIR (STrongly Incremental Repair detection), a system that detects speech repairs and edit terms on transcripts incrementally with minimal latency. STIR uses information-theoretic measures from n-gram models as its principal decision features in a pipeline of classifiers detecting the the different stages of repairs. Results on the Switchboard disfluency tagged corpus show utterance-final accuracy on a par with state-of-the-art incremental repair detection methods, but with better incremental accuracy, faster time-to-detection and less computational overhead. We evaluate its performance using incremental metrics and propose new repair processing evaluation standards.", "histories": [["v1", "Thu, 28 Aug 2014 17:29:55 GMT  (179kb)", "https://arxiv.org/abs/1408.6788v1", "12 pages, 6 figures, EMNLP conference long paper 2014"], ["v2", "Fri, 29 Aug 2014 08:44:09 GMT  (179kb)", "http://arxiv.org/abs/1408.6788v2", "12 pages, 6 figures, EMNLP conference long paper 2014"]], "COMMENTS": "12 pages, 6 figures, EMNLP conference long paper 2014", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["julian hough", "matthew purver"], "accepted": true, "id": "1408.6788"}, "pdf": {"name": "1408.6788.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Matthew Purver"], "emails": ["julian.hough@uni-bielefeld.de", "m.purver@qmul.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 140 8.67 88v2 [cs.CL] 2 9A ug2 014"}, {"heading": "1 Introduction", "text": "Self-repairs in spontaneous language are commented on using a well-established three-phase structure (Shriberg, 1994) and, as in Meteer et al. (1995) \"s Switchboard corpus annotation handbook: John [likes reparandum + {uh} interregnumloves] reparaturMary (1) From the perspective of dialog systems, the recognition of repairs and their assignment enables the appropriate structure for a robust understanding of the natural language (NLU) in interactive systems. The downgrading of the engagement of Reparandum phases and the assignment of appropriate interregandum and repair phases allows the calculation of the intended meaning of the user. Furthermore, the recent focus on incremental dialogue systems (see e.g. (Rieser and Snakes, 2011) means that repair detection should function without unnecessary incrementality and function efficiently within an incremental framework."}, {"heading": "2 Previous work", "text": "In fact, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "3 Challenges and Approach", "text": "In this section, we summarize the challenges for incremental repair detection: 1.5 computational complexity, repair stability hypothesis, latency of detection, and repair structure identification. In 3.1, we explain how to address these. Computational complexity approaches to repair structure detection often use graph memory (Zwarts et al., 2010; Johnson and Charniak, 2004; Heeman and Allen, 1999), which represents a computational overhead: when all possible boundaries for a repair structure can increase in the number of hypotheses starting with each word, for prefixes of length n."}, {"heading": "3.1 Our approach", "text": "In fact, it is a way in which people are able to determine for themselves what they want and what they want to do."}, {"heading": "4 STIR: Strongly Incremental Repair detection", "text": "Our STIR (Strongly Incremental Repair Detection) system therefore takes a local, incremental approach to detecting repairs and isolated processing terms, assigning words to the structures in (2). We include interregnum detection in the process, as interregnum vocabulary has been included in the editing vocabulary (Ginzburg, 2012; Hough and Purver, 2013), a useful feature for repair detection (Lease et al., 2006; Qian and Liu, 2013). {... [rmstart... rmend + {ed} rpstart... rpend]... {ed}... (2) Instead of recognizing the repair structure in its left-right order as above, STIR works as in Figure 1: first detecting processing terms (possibly interregna) at step T1; then detecting repair rpstart at T2; if you find the search modules backwards, eventually finding the detection of several T3 at the end; and finally, the detection of several T3 at the end."}, {"heading": "4.1 Enriched incremental language models", "text": "We derive the basic information theory characteristics that we need with n-gram language models, because they have a long history of information theory (Shannon, 1948) and provide reproducible results without having to commit ourselves to a particular grammar. (S1 S2T0 \"John\" likes \"edS0\" edS2 S3edT1 \"John\" likes \"John\" likes \"John\" likes \"John.\" (S2 S3edT1 \"likes\" John \"likes\". \"S2 S3edT1\" likes \"uh\" ed \"ed\" rpstartS2. \")"}, {"heading": "4.2 Individual classifiers", "text": "This section describes the characteristics used by the 4 individual classifiers. To examine the usefulness of the characteristics used in each classifier, we obtain values on the default exchange data (PTB III files sw4 [5-9] *: 6.4K expressions, 49K words)."}, {"heading": "4.2.1 Edit term detection", "text": "In the first component, we use the well-known observation that editing terms have a distinctive vocabulary (Ginzburg, 2012), and train a Bigram model on a corpus of editing words annotated in Switchboard's training data. The classifier simply uses the surprising lex of this editing model and the surprising lex of the trigram from Section 4.1 \"s Standard Fluid Model. At the current position wn, one, both or none of the words wn and wn \u2212 1 are classified as edits. We found this simple approach effective and stable, although some delayed decisions occur in cases where Lex and WMLlex are high in both models before the end of editing, e.g.\" I like \"\u2192\" I like.... \"Words that are classified as ed are removed from the incremental editing graph (indicated by the dashed line transition in Figure 1) and the stack updated when repair hypotheses are reversed due to a delayed editing hypothesis \u2212 1."}, {"heading": "4.2.2 Repair start detection", "text": "In fact, the higher the accuracy, the better the input for the downstream components and the less effort it takes to filter false positives. We use the information theory features of section 4.1, WML, H for words and POS, and introduce 5 additional information theory features: \u2206 WML is the difference between the WML values of section \u2212 1 and wn; \u2206 H is the difference in entropy between wn \u2212 1 and wn; InformationGain is the difference between the expected entropy of section \u2212 1 and the observed s for wn, a measure that accounts for the effect of the naturally high entropy contexts; BestEntropy reduction of entropy possible by an early coarse hypothesis of the repair set within 3 words; and BestWMLBoost speculates on the best improvement of the WML position by covering rmstart positions up to 3 words."}, {"heading": "4.2.3 Reparandum start detection", "text": "When recognizing rmstart positions based on a hypothetical rpstart (level T3 in Figure 1), we use the rushing channel intuition that removing the repair (from rmstart to rpstart) increases the fluidity of the utterance expressed here as described above as WMLboost. Using gold standard input, we found that this is the case with the herodout data, with an average WMLboost of 0.223 (sd = 0.267) for repair settings and -0.058 (sd = 0.224) for other words in the 6-word story. The negative thrust for non-reparandum words captures the intuition that retracing from these points would make the utterance less grammatical, and vice versa, the thrust provided by the correct rmstart detection helps to resolve the continuation problem for the listener (and our detector) parallelism in the beginnings of the 000pbit and the fact that Mr3 is also the most useful (000rstart and 0.04rbit)."}, {"heading": "4.2.4 Repair end detection and structure classification", "text": "When recognizing the reparandum endword and the repair endword rpend, using the term parallelism, we assume a divergence effect between \u03b8lex in the reparandum endword rpend: in the case of repeat repairs, the KL divergence will be trivial at 0; in the case of substitutions, it will be higher; in the case of deletions, even higher. Considering our characteristic, this KL measure ranks fifth out of 23 characteristics (merit = 0.258 (+ - 0.002)). We introduce another characteristic that encodes the parallelism of repair umRepairDifference: the probability difference between an expression cleaned by the reparandum and the expression with its repair phase, which replaces the reparandum. Both in the POS (merit = 0.366 (+ - 0.003)) and in the Word (merit = 0.352 (+ - 0.002), this was the most discriminatory characteristic."}, {"heading": "4.3 Classifier pipeline", "text": "STIR creates a pipeline of classifiers such as Figure 3, where the classifier passes only incremented words to the rpstart classification, and the rpend classification of the active repair hypotheses stored in a stack. The rpstart classifier passes positive repair hypotheses to the rmstart classifier, which searches backwards for up to 7 words in the utterance. If an rmstart is classified, the output is passed to the rpend classification at the end of the pipeline, and if not rejected, it is pushed onto the repair stack. Repair hypotheses are unbuttoned if the string exceeds 7 words in the rpstart position."}, {"heading": "5 Experimental set-up", "text": "We train STIR on the switching data described above and test it on the standard switching data (PTB III files 4 [0-1] *). To avoid classifiers migrating to the basic language models, we use a multi-layered training approach: we split the corpus into 10 folds and use incremental models developed in the order of 5-6%. Classifiers are then trained as standard on the resulting strange corpus, resulting in better N-grade benefit and better F-score results for detecting all components in the order of 5-6%."}, {"heading": "5.1 Incremental evaluation metrics", "text": "In fact, most of us are able to play by the rules we had in the past."}, {"heading": "6 Results and Discussion", "text": "We evaluate the results of the mediation of test data; Table 2 shows the best results for each of the metrics described above, along with the achievement of the highest total score (TS), and that the highest TS values are achieved for each stage in the pipeline. Our experiments showed that the various system settings are better than the individual settings in all areas. Our best output designs reach 0.779%, although they do not significantly exceed (Zwarts et al., 2010)."}, {"heading": "7 Conclusion", "text": "We have introduced STIR, an incremental repair detector that can be used to experiment with incremental performance and accuracy compromises. In future work, we plan to include probabilistic and distribution characteristics of an incremental parser from top to bottom, e.g. Roark et al. (2009), and use the distribution characteristics of STIR to classify repair types."}, {"heading": "Acknowledgements", "text": "We thank the three anonymous EMNLP reviewers for their helpful comments. Hough is supported by the DUEL project, financially supported by the Agence Nationale de la Research (grant number ANR-13-FRAL-0001) and the German Research Foundation. Much of the work was carried out with the support of an EPSRC-DTA fellowship at Queen Mary University of London. Purver is partly supported by ConCreTe: The ConCreTe project recognizes the financial support of the Future and Emerging Technologies (FET) program within the Seventh Framework Programme of the European Commission under grant number 611733."}], "references": [{"title": "Evaluation and optimisation of incremental processors", "author": ["Baumann et al.2011] T. Baumann", "O. Bu\u00df", "D. Schlangen"], "venue": "Dialogue & Discourse,", "citeRegEx": "Baumann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Baumann et al\\.", "year": 2011}, {"title": "How listeners compensate for disfluencies in spontaneous speech", "author": ["Brennan", "Schober2001] S.E. Brennan", "M.F. Schober"], "venue": "Journal of Memory and Language,", "citeRegEx": "Brennan et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Brennan et al\\.", "year": 2001}, {"title": "An improved error model for noisy channel spelling correction", "author": ["Brill", "Moore2000] Eric Brill", "Robert C Moore"], "venue": "In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Brill et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Brill et al\\.", "year": 2000}, {"title": "Statistical representation of grammaticality judgements: the limits of ngram models", "author": ["Gianluca Giorgolo", "Shalom Lappin"], "venue": "In Proceedings of the Fourth Annual Workshop on Cognitive Modeling and Computa-", "citeRegEx": "Clark et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2013}, {"title": "Metacost: A general method for making classifiers cost-sensitive", "author": ["Pedro Domingos"], "venue": "In Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Domingos.,? \\Q1999\\E", "shortCiteRegEx": "Domingos.", "year": 1999}, {"title": "Using integer linear programming for detecting speech disfluencies", "author": ["Kallirroi Georgila"], "venue": "In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association", "citeRegEx": "Georgila.,? \\Q2009\\E", "shortCiteRegEx": "Georgila.", "year": 2009}, {"title": "Hybrid multi-step disfluency detection", "author": ["Tilman Becker", "Peter Poller"], "venue": "In Machine Learning for Multimodal Interaction,", "citeRegEx": "Germesin et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Germesin et al\\.", "year": 2008}, {"title": "The Interactive Stance: Meaning for Conversation", "author": ["Jonathan Ginzburg"], "venue": null, "citeRegEx": "Ginzburg.,? \\Q2012\\E", "shortCiteRegEx": "Ginzburg.", "year": 2012}, {"title": "Making a contribution: Processing clarification requests in dialogue", "author": ["Arash Eshghi", "Christine Howes", "Matthew Purver"], "venue": "In Proceedings of the 21st Annual Meeting of the Society for Text and Discourse,", "citeRegEx": "Healey et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Healey et al\\.", "year": 2011}, {"title": "Speech repairs, intonational phrases, and discourse markers: modeling speakers\u2019 utterances in spoken dialogue", "author": ["Heeman", "Allen1999] Peter Heeman", "James Allen"], "venue": null, "citeRegEx": "Heeman et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Heeman et al\\.", "year": 1999}, {"title": "Joint incremental disfluency detection and dependency parsing. Transactions of the Association of Computational Linugistics (TACL), 2:131\u2013142", "author": ["Honnibal", "Johnson2014] Matthew Honnibal", "Mark Johnson"], "venue": null, "citeRegEx": "Honnibal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Honnibal et al\\.", "year": 2014}, {"title": "Modelling expectation in the selfrepair processing of annotat-, um, listeners", "author": ["Hough", "Purver2013] Julian Hough", "Matthew Purver"], "venue": "In Proceedings of the 17th SemDial Workshop on the Semantics and Pragmatics of Dialogue (DialDam),", "citeRegEx": "Hough et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hough et al\\.", "year": 2013}, {"title": "On language utility: Processing complexity and communicative efficiency", "author": ["Jaeger", "Tily2011] T Florian Jaeger", "Harry Tily"], "venue": "Wiley Interdisciplinary Reviews: Cognitive Science,", "citeRegEx": "Jaeger et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jaeger et al\\.", "year": 2011}, {"title": "A TAG-based noisy channel model of speech repairs", "author": ["Johnson", "Charniak2004] Mark Johnson", "Eugene Charniak"], "venue": "In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Johnson et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2004}, {"title": "The entropy rate principle as a predictor of processing effort: An evaluation against eye-tracking data", "author": ["Frank Keller"], "venue": "In EMNLP,", "citeRegEx": "Keller.,? \\Q2004\\E", "shortCiteRegEx": "Keller.", "year": 2004}, {"title": "Improved backing-off for m-gram language modeling", "author": ["Kneser", "Ney1995] Reinhard Kneser", "Hermann Ney"], "venue": "In Acoustics, Speech, and Signal Processing,", "citeRegEx": "Kneser et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Kneser et al\\.", "year": 1995}, {"title": "Recognizing disfluencies in conversational speech. Audio, Speech, and Language Processing", "author": ["Lease et al.2006] Matthew Lease", "Mark Johnson", "Eugene Charniak"], "venue": "IEEE Transactions on,", "citeRegEx": "Lease et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lease et al\\.", "year": 2006}, {"title": "Monitoring and self-repair in speech. Cognition, 14(1):41\u2013104", "author": ["W.J.M. Levelt"], "venue": null, "citeRegEx": "Levelt.,? \\Q1983\\E", "shortCiteRegEx": "Levelt.", "year": 1983}, {"title": "Disfluency annotation stylebook for the switchboard corpus", "author": ["Meteer et al.1995] M. Meteer", "A. Taylor", "R. MacIntyre", "R. Iyer"], "venue": null, "citeRegEx": "Meteer et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Meteer et al\\.", "year": 1995}, {"title": "A syntactic time-series model for parsing fluent and disfluent speech", "author": ["Miller", "Schuler2008] Tim Miller", "William Schuler"], "venue": "In Proceedings of the 22nd International Conference on Computational Linguistics-Volume", "citeRegEx": "Miller et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2008}, {"title": "Axiomatic Grammar, Non-Constituent Coordination and Incremental Interpretation", "author": ["David Milward"], "venue": "Ph.D. thesis,", "citeRegEx": "Milward.,? \\Q1991\\E", "shortCiteRegEx": "Milward.", "year": 1991}, {"title": "Disfluency detection using multi-step stacked learning", "author": ["Qian", "Liu2013] Xian Qian", "Yang Liu"], "venue": "In Proceedings of NAACL-HLT,", "citeRegEx": "Qian et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Qian et al\\.", "year": 2013}, {"title": "Non-monotonic parsing of fluent umm I mean disfluent sentences", "author": ["Rasooli", "Joel Tetreault"], "venue": "EACL", "citeRegEx": "Rasooli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rasooli et al\\.", "year": 2014}, {"title": "Introduction to the special issue on incremental processing in dialogue", "author": ["Rieser", "Schlangen2011] Hannes Rieser", "David Schlangen"], "venue": "Dialogue & Discourse,", "citeRegEx": "Rieser et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Rieser et al\\.", "year": 2011}, {"title": "Deriving lexical and syntactic expectation-based measures for psycholinguistic modeling via incremental top-down parsing", "author": ["Roark et al.2009] Brian Roark", "Asaf Bachrach", "Carlos Cardenas", "Christophe Pallier"], "venue": null, "citeRegEx": "Roark et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Roark et al\\.", "year": 2009}, {"title": "A mathematical theory of communication", "author": ["Claude E. Shannon"], "venue": null, "citeRegEx": "Shannon.,? \\Q1948\\E", "shortCiteRegEx": "Shannon.", "year": 1948}, {"title": "How far do speakers back up in repairs? A quantitative model", "author": ["Shriberg", "Stolcke1998] Elizabeth Shriberg", "Andreas Stolcke"], "venue": "In Proceedings of the International Conference on Spoken Language Processing,", "citeRegEx": "Shriberg et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Shriberg et al\\.", "year": 1998}, {"title": "Preliminaries to a Theory of Speech Disfluencies", "author": ["Elizabeth Shriberg"], "venue": "Ph.D. thesis,", "citeRegEx": "Shriberg.,? \\Q1994\\E", "shortCiteRegEx": "Shriberg.", "year": 1994}, {"title": "The impact of language models and loss functions on repair disfluency detection", "author": ["Zwarts", "Johnson2011] Simon Zwarts", "Mark Johnson"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Zwarts et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zwarts et al\\.", "year": 2011}, {"title": "Detecting speech repairs incrementally using a noisy channel approach", "author": ["Zwarts et al.2010] Simon Zwarts", "Mark Johnson", "Robert Dale"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics,", "citeRegEx": "Zwarts et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zwarts et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 27, "context": "Self-repairs in spontaneous speech are annotated according to a well established three-phase structure from (Shriberg, 1994) onwards, and as described in Meteer et al.", "startOffset": 108, "endOffset": 124}, {"referenceID": 18, "context": "Self-repairs in spontaneous speech are annotated according to a well established three-phase structure from (Shriberg, 1994) onwards, and as described in Meteer et al. (1995)\u2019s Switchboard corpus annotation handbook:", "startOffset": 154, "endOffset": 175}, {"referenceID": 20, "context": "However, such left-to-right operability on its own is not sufficient: in line with the principle of strong incremental interpretation (Milward, 1991), a repair detector should give the best results possible as early as possible.", "startOffset": 134, "endOffset": 149}, {"referenceID": 29, "context": "With one exception (Zwarts et al., 2010), there has been no focus on evaluating or improving the incremental performance of repair detection.", "startOffset": 19, "endOffset": 40}, {"referenceID": 5, "context": "Similarly, Georgila (2009) uses Integer Linear Programming post-processing of a CRF to achieve F-scores over 0.", "startOffset": 11, "endOffset": 27}, {"referenceID": 28, "context": "The model we consider most suitable for incremental dialogue systems so far is Zwarts et al. (2010)\u2019s incremental version of Johnson and Charniak (2004)\u2019s noisy channel repair detector, as it incrementally applies structural repair analyses (rather than just identifying reparanda) and is evaluated for its incremental properties.", "startOffset": 79, "endOffset": 100}, {"referenceID": 28, "context": "The model we consider most suitable for incremental dialogue systems so far is Zwarts et al. (2010)\u2019s incremental version of Johnson and Charniak (2004)\u2019s noisy channel repair detector, as it incrementally applies structural repair analyses (rather than just identifying reparanda) and is evaluated for its incremental properties.", "startOffset": 79, "endOffset": 153}, {"referenceID": 29, "context": "Computational complexity Approaches to detecting repair structures often use chart storage (Zwarts et al., 2010; Johnson and Charniak, 2004; Heeman and Allen, 1999), which poses a computational overhead: if considering all possible boundary points for a repair structure\u2019s 3 phases beginning on any word, for prefixes of length n the number of hypotheses can grow in the order O(n4).", "startOffset": 91, "endOffset": 164}, {"referenceID": 29, "context": "Exploring a subset of this space is necessary for assigning entire repair structures as in (1) above, rather than just detecting reparanda: the (Johnson and Charniak, 2004; Zwarts et al., 2010) noisy-channel detector is the only system that applies such structures but the potential runtime complexity in decoding these with their STAG repair parser is O(n5).", "startOffset": 144, "endOffset": 193}, {"referenceID": 16, "context": "In their approach, complexity is mitigated by imposing a maximum repair length (12 words), and also by using beam search with re-ranking (Lease et al., 2006; Zwarts and Johnson, 2011).", "startOffset": 137, "endOffset": 183}, {"referenceID": 16, "context": "In their approach, complexity is mitigated by imposing a maximum repair length (12 words), and also by using beam search with re-ranking (Lease et al., 2006; Zwarts and Johnson, 2011). If we wish to include full decoding of the repair\u2019s structure (as argued by Hough and Purver (2013) as necessary for full interpretation) whilst taking a strictly incremental and time-critical perspective, reducing this complexity by minimizing the size of this search space is crucial.", "startOffset": 138, "endOffset": 285}, {"referenceID": 27, "context": "Zwarts et al. (2010)\u2019s time-to-detection results show their system is only certain about a detection after processing the entire repair.", "startOffset": 0, "endOffset": 21}, {"referenceID": 27, "context": "1 This is perhaps due to lack of clarity in definition: even for human annotators, verbatim repeats withstanding, agreement is often poor (Hough and Purver, 2013; Shriberg, 1994).", "startOffset": 138, "endOffset": 178}, {"referenceID": 29, "context": "To address the above, we propose an alternative to (Johnson and Charniak, 2004; Zwarts et al., 2010)\u2019s noisy channel model.", "startOffset": 51, "endOffset": 100}, {"referenceID": 6, "context": "Though see (Germesin et al., 2008) for one approach, albeit using idiosyncratic repair categories.", "startOffset": 11, "endOffset": 34}, {"referenceID": 17, "context": "In accordance with psycholinguistic evidence (Brennan and Schober, 2001), we assume characteristics of the repair onset allow hearers to detect it very quickly and solve the continuation problem (Levelt, 1983) of integrating the repair into their linguistic context immediately, before processing or even hearing the end of the repair phase.", "startOffset": 195, "endOffset": 209}, {"referenceID": 14, "context": "Our repair onset detection is therefore driven by departures from fluency, via information-theoretic features derived incrementally from a language model in line with recent psycholinguistic accounts of incremental parsing \u2013 see (Keller, 2004; Jaeger and Tily, 2011).", "startOffset": 229, "endOffset": 266}, {"referenceID": 8, "context": "We acknowledge a purely position-based model for reparandum extent detection under-estimates prepositions, which speakers favour as the retrace start and over-estimates verbs, which speakers tend to avoid retracing back to, preferring to begin the utterance again, as (Healey et al., 2011)\u2019s experiments also demonstrate.", "startOffset": 268, "endOffset": 289}, {"referenceID": 7, "context": "We include interregnum recognition in the process, due to the inclusion of interregnum vocabulary within edit term vocabulary (Ginzburg, 2012; Hough and Purver, 2013), a useful feature for repair detection (Lease et al.", "startOffset": 126, "endOffset": 166}, {"referenceID": 16, "context": "We include interregnum recognition in the process, due to the inclusion of interregnum vocabulary within edit term vocabulary (Ginzburg, 2012; Hough and Purver, 2013), a useful feature for repair detection (Lease et al., 2006; Qian and Liu, 2013).", "startOffset": 206, "endOffset": 246}, {"referenceID": 25, "context": "We derive the basic information-theoretic features required using n-gram language models, as they have a long history of information theoretic analysis (Shannon, 1948) and provide reproducible results without forcing commitment to one particular grammar formalism.", "startOffset": 152, "endOffset": 167}, {"referenceID": 3, "context": "Following recent work on modelling grammaticality judgements (Clark et al., 2013), we implement several modifications to standard language models to develop our basic measures of fluency and uncertainty.", "startOffset": 61, "endOffset": 81}, {"referenceID": 3, "context": "3 We then derive surprisal as our principal default lexical uncertainty measurement s (equation 3) in both models; and, following (Clark et al., 2013), the (unigram) Weighted Mean Log trigram probability (WML, eq.", "startOffset": 130, "endOffset": 150}, {"referenceID": 7, "context": "In the first component, we utilise the well-known observation that edit terms have a distinctive vocabulary (Ginzburg, 2012), training a bigram model on a corpus of all edit words annotated in Switchboard\u2019s training data.", "startOffset": 108, "endOffset": 124}, {"referenceID": 4, "context": "Classifiers Classifiers are implemented using Random Forests (Breiman, 2001) and we use different error functions for each stage using MetaCost (Domingos, 1999).", "startOffset": 144, "endOffset": 160}, {"referenceID": 4, "context": "As (Domingos, 1999) demonstrated, there are only relatively small accuracy gains when using more than this, with training time increasing in the order of the re-sample size.", "startOffset": 3, "endOffset": 19}, {"referenceID": 0, "context": "Following (Baumann et al., 2011) we divide our evaluation metrics into similarity metrics (measures of equality with or similarity to a gold standard), timing metrics (measures of the timing of relevant phenomena detected from the gold standard) and diachronic metrics (evolution of incremental hypotheses over time).", "startOffset": 10, "endOffset": 32}, {"referenceID": 29, "context": "To investigate incremental accuracy we evaluate the delayed accuracy (DA) introduced by (Zwarts et al., 2010), as described in section 2 against the utterance-final gold standard disfluency annotations, and use the mean of the 6 word F-scores.", "startOffset": 88, "endOffset": 109}, {"referenceID": 0, "context": "Diachronic metrics To measure stability of repair hypotheses over time we use (Baumann et al., 2011)\u2019s edit overhead (EO) metric.", "startOffset": 78, "endOffset": 100}, {"referenceID": 0, "context": "While Frm, Fs and DA evaluate against what Baumann et al. (2011) call the current gold standard, the incremental gold standard reflects the repair processing approach we set out in 3.", "startOffset": 43, "endOffset": 65}, {"referenceID": 29, "context": "779, marginally though not significantly exceeding (Zwarts et al., 2010)\u2019s measure and STIR achieves 0.", "startOffset": 51, "endOffset": 72}, {"referenceID": 29, "context": "The setting with the best DA improves on (Zwarts et al., 2010)\u2019s result significantly in terms of mean values (0.", "startOffset": 41, "endOffset": 62}, {"referenceID": 24, "context": "Roark et al. (2009), and use STIR\u2019s distributional features to classify repair type.", "startOffset": 0, "endOffset": 20}], "year": 2014, "abstractText": "We present STIR (STrongly Incremental Repair detection), a system that detects speech repairs and edit terms on transcripts incrementally with minimal latency. STIR uses information-theoretic measures from n-gram models as its principal decision features in a pipeline of classifiers detecting the different stages of repairs. Results on the Switchboard disfluency tagged corpus show utterance-final accuracy on a par with state-of-the-art incremental repair detection methods, but with better incremental accuracy, faster time-to-detection and less computational overhead. We evaluate its performance using incremental metrics and propose new repair processing evaluation standards.", "creator": "LaTeX with hyperref package"}}}