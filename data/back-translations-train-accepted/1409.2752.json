{"id": "1409.2752", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Sep-2014", "title": "Winner-Take-All Autoencoders", "abstract": "We explore combining the benefits of convolutional architectures and autoencoders for learning deep representations in an unsupervised manner. A major challenge is to achieve appropriate sparsity among hidden variables, since neighbouring variables in each feature map tend to be highly correlated and a suppression mechanism is therefore needed. Previously, deconvolutional networks and convolutional predictive sparse decomposition have been used to construct systems that have a recognition pathway and a data generation pathway that are trained so that they agree and so that the hidden representation is sparse. We take a more direct approach and describe a way to train convolutional autoencoders layer by layer, where in each layer sparsity is achieved using a winner-take-all activation function within each feature map. Learning is computationally efficient and we show that our method can be used to train shallow and deep convolutional autoencoders whose representations can be used to achieve classification rates on the MNIST, CIFAR-10 and NORB datasets that are competitive with the state of the art.", "histories": [["v1", "Tue, 9 Sep 2014 14:38:43 GMT  (604kb)", "http://arxiv.org/abs/1409.2752v1", null], ["v2", "Sun, 7 Jun 2015 18:28:22 GMT  (947kb)", "http://arxiv.org/abs/1409.2752v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["alireza makhzani", "brendan j frey"], "accepted": true, "id": "1409.2752"}, "pdf": {"name": "1409.2752.pdf", "metadata": {"source": "CRF", "title": "A Winner-Take-All Method for Training Sparse Convolutional Autoencoders", "authors": ["Alireza Makhzani", "Brendan Frey"], "emails": ["makhzani@psi.toronto.edu", "frey@psi.toronto.edu"], "sections": [{"heading": null, "text": "ar Xiv: 140 9.27 52v1 [cs.LG] 9 Sep 2"}, {"heading": "1 Introduction", "text": "This year, it is only a matter of time before there is an agreement, until there is an agreement."}, {"heading": "2 Description of the Algorithm", "text": "The filters and distortions of the encoder are {Pi, bi} and f is the activation function, e.g. linear, sigmoidal or ReLU. We assume that the boundaries of the input image are padded to zero, so that each feature card has the size of the input. The hidden representation is then mapped linearly to the output using x-i (Wi-Fi-zi + b \u2032 i), where Wi-Fi is the i-th decoder reconstruction filter. Parameters are optimized to minimize the mean square error, as is x-x-22, summed across all training points. Fig.2 (a) shows a diagram of a revolutionary auto encoder for 32 x-32 input images and 128 feature cards. Figure 2 (b) shows the function of isolation and the recognition of these two functions essentially without filters."}, {"heading": "2.1 Sparse convolutional autoencoders", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "2.2 Deep sparse convolutional autoencoders", "text": "The sparse Convolutionary Autocoder can be used as a building block to build a deeper hierarchy. To train the hierarchical model, we first train a sparse Convolutionary Autocoder and then, as explained above, turn off the sparseness regulator and use the ReLU activation function, followed by max pooling to obtain feature cards. We then repair the feature cards and train another sparse Convolutionary Autocoder to obtain the deep feature cards. This procedure is repeated to find multi-level representations. It should be noted that the deep layers in unattended learning algorithms only slightly improve classification performance, while the deeper layers are much more helpful. We also observed the same problem in deep sparse Convolutionary Autocoders. While flat Convolutionary Autocoders can achieve almost the same classification rate as flat models with the same architecture (F1) to improve the order of the deeper layer."}, {"heading": "3 Experiments", "text": "In this section, we evaluate the performance of sparse conventional autoencoders (SCAs) on the flat and deep network MNIST, CIFAR 10, and NORB datasets. (We use the acronym SCA to refer to our space-saving method, although we recognize that there are other ways to train a sparse conventional autoencoder.) Here, we only compare the performance of SCAs with other uncontrolled learning methods. In general, the level of supervised learning is better. While most conventional sparse coding algorithms require complex matrix operations such as matrix inversion or SVD decomposition, SCAs only require the max and Argmax operations in addition to matrix multiplication, which are all efficiently implemented in most GPU libraries. We used the publicly available Gnumpy library [15] and Alex Krizhevskys-Cuducnet [1]."}, {"heading": "3.1 MNIST", "text": "For MNIST, the flat SCA architecture has 128 filters with a filter width of 7 and a step width of 1. After training, we use max pooling with a pooling step size of 3 and a pooling width of 5 to get the final 128 x 10 x 10 representation. Logistic regression is then applied to this representation for classification. In the deep architecture, we train another 2048 feature maps on the pooled feature maps of the first layer. Afterwards, we get the final representation by pooling the 2048 feature maps with a step size of 2 and a width of 3 pooling to achieve the final 128 x 5 x 5-5 representation. Very competitive error rates of 0.64% and 0.48% are achieved by the flat and deep architectures."}, {"heading": "3.2 CIFAR-10", "text": "On the CIFAR-10 dataset, we use global contrast normalization and ZCA whitening to pre-process the dataset as described in [7]. In the flat architecture of our network, we use 512 feature maps, with a filter width of 9 and an increment of 1, followed by overlaps with an increment of 4 and a width of 5 to obtain the final representation of 512 x 8 x 8. In the deep architecture, we train 4096 feature maps on the first layer and then use maximum pooling with an increment of 2 and a width of 3 to obtain the final representation of 4096 x 4 x 4 maps. Figure 4 and Figure 1 (b) show the filters we have learned from the raw and white images. Table 2 compares the performance of SCAs with other unmonitored feature learning methods, and shows that SCAs work in a similar way to Conventional SCAs [18] and Spike Slab encoding."}, {"heading": "3.3 NORB", "text": "We also examined the small standardized standardized NORB dataset, which contains 24,300 training and test examples with two views of 96 x 96 pixels. We take the inner 64 x 64 pixels of each view and resize them to 32 x 32 pixels. This size preserves the details of the image and is also small enough to allow quick training. We use global contrast normalization and ZCA whitening to pre-process the dataset as described in [7] and separate the two views to form a training set of 48, 600 images. We learn a representation using this dataset and then at test time we link the function charts of both views to form the final representation of the binocular image. In the flat SCA architecture, we use 128 function cards with a filter width of 9 and a step of 1, and then use overlapping maximum summary of both views to form the final representation of the binocular image."}, {"heading": "4 Discussion", "text": "In this context, it should be noted that the case concerns a case in which a person was killed who was able to kill himself."}, {"heading": "5 Conclusion", "text": "Unlike similar approaches such as deconvolutionary networks and Convolutionary PSD, our method collectively trains the encoder and decoder paths and does not require iterative optimization techniques during learning. One problem with the winner-take-all approach is that features cannot be reused, but our experimental results show that these concerns must not be too limited. We found that adding more features improves classification, but also that training deeper Convolutionary Architectures achieves better results. We conducted experiments with MNIST, CIFAR-10 and NORB datasets and showed that the classification rates of sparse Convolutionary Automatic Coders compete with the state of the art. Interestingly, the flat Convolutionary Autoencoder achieves the same classification rate as a monitored network architecture that requires deeper results in uncontrolled feature learning."}], "references": [{"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS, vol. 1, p. 4, 2012.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["G.E. Hinton", "N. Srivastava", "A. Krizhevsky", "I. Sutskever", "R.R. Salakhutdinov"], "venue": "arXiv preprint arXiv:1207.0580, 2012.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2012}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "ICML, 2013.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Deep boltzmann machines", "author": ["R. Salakhutdinov", "G.E. Hinton"], "venue": "International Conference on Artificial Intelligence and Statistics, pp. 448\u2013455, 2009.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2009}, {"title": "3d object recognition with deep belief nets", "author": ["V. Nair", "G.E. Hinton"], "venue": "NIPS, pp. 1339\u2013 1347, 2009.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2009}, {"title": "Pedestrian detection with unsupervised multi-stage feature learning", "author": ["P. Sermanet", "K. Kavukcuoglu", "S. Chintala", "Y. LeCun"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on, pp. 3626\u20133633, IEEE, 2013.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["A. Coates", "A.Y. Ng", "H. Lee"], "venue": "International Conference on Artificial Intelligence and Statistics, 2011.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2011}, {"title": "k-sparse autoencoders", "author": ["A. Makhzani", "B. Frey"], "venue": "International Conference on Learning Representations, ICLR, 2014.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning convolutional feature hierarchies for visual recognition", "author": ["K. Kavukcuoglu", "P. Sermanet", "Y.-L. Boureau", "K. Gregor", "M. Mathieu", "Y. LeCun"], "venue": "NIPS, vol. 1, p. 5, 2010.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2010}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning, pp. 609\u2013616, ACM, 2009.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Convolutional deep belief networks on cifar-10", "author": ["A. Krizhevsky"], "venue": "Unpublished, 2010.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "Deconvolutional networks", "author": ["M.D. Zeiler", "D. Krishnan", "G.W. Taylor", "R. Fergus"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pp. 2528\u20132535, IEEE, 2010.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Differentiable pooling for hierarchical feature learning", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "arXiv preprint arXiv:1207.0151, 2012.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2012}, {"title": "K-svd: Design of dictionaries for sparse representation", "author": ["M. Aharon", "M. Elad", "A. Bruckstein"], "venue": "Proceedings of SPARS, vol. 5, pp. 9\u201312, 2005.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "Gnumpy: an easy way to use gpu boards in python", "author": ["T. Tieleman"], "venue": "2010.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "Proceedings of the 26th Annual International Conference on Machine Learning, pp. 609\u2013616, ACM, 2009.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M. Ranzato", "F.J. Huang", "Y.-L. Boureau", "Y. Lecun"], "venue": "Computer Vision and Pattern Recognition, 2007. CVPR\u201907. IEEE Conference on, pp. 1\u20138, IEEE, 2007.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2007}, {"title": "Convolutional deep belief networks on cifar-10", "author": ["A. Krizhevsky"], "venue": "2010.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Spike-and-slab sparse coding for unsupervised feature discovery", "author": ["I.J. Goodfellow", "A. Courville", "Y. Bengio"], "venue": "arXiv preprint arXiv:1201.3382, 2012.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2012}, {"title": "Selecting receptive fields in deep networks", "author": ["A. Coates", "A.Y. Ng"], "venue": "NIPS, 2011.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2011}, {"title": "Factored 3-way restricted boltzmann machines for modeling natural images", "author": ["A. Krizhevsky", "G.E. Hinton"], "venue": "International Conference on Artificial Intelligence and Statistics, pp. 621\u2013628, 2010.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2010}, {"title": "Modeling pixel means and covariances using factorized thirdorder boltzmann machines", "author": ["M. Ranzato", "G.E. Hinton"], "venue": "Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, pp. 2551\u20132558, IEEE, 2010.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Unsupervised models of images by spikeand-slab rbms", "author": ["Y. Bengio", "A.C. Courville", "J.S. Bergstra"], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 1145\u20131152, 2011. 9", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "Convolutional architectures have been used very successfully to advance the state of the art in discriminative classification [1], often by training them using new regularization techniques that have been developed in the deep learning community [2, 3].", "startOffset": 126, "endOffset": 129}, {"referenceID": 1, "context": "Convolutional architectures have been used very successfully to advance the state of the art in discriminative classification [1], often by training them using new regularization techniques that have been developed in the deep learning community [2, 3].", "startOffset": 246, "endOffset": 252}, {"referenceID": 2, "context": "Convolutional architectures have been used very successfully to advance the state of the art in discriminative classification [1], often by training them using new regularization techniques that have been developed in the deep learning community [2, 3].", "startOffset": 246, "endOffset": 252}, {"referenceID": 0, "context": "For example, convolutional networks continue to perform better than nonconvolutional architectures on the CIFAR-10 object classification task [1, 3] and new classification records are regularly achieved using convolutional architectures.", "startOffset": 142, "endOffset": 148}, {"referenceID": 2, "context": "For example, convolutional networks continue to perform better than nonconvolutional architectures on the CIFAR-10 object classification task [1, 3] and new classification records are regularly achieved using convolutional architectures.", "startOffset": 142, "endOffset": 148}, {"referenceID": 3, "context": "In parallel with research on discriminative convolutional architectures, neural networks trained in an unsupervised fashion, such as stacked autoencoders, deep Boltzmann machines [4] and deep belief networks [5], have been developed and used to produce representations that have enabled leaps forward in classification accuracy for several tasks.", "startOffset": 179, "endOffset": 182}, {"referenceID": 4, "context": "In parallel with research on discriminative convolutional architectures, neural networks trained in an unsupervised fashion, such as stacked autoencoders, deep Boltzmann machines [4] and deep belief networks [5], have been developed and used to produce representations that have enabled leaps forward in classification accuracy for several tasks.", "startOffset": 208, "endOffset": 211}, {"referenceID": 5, "context": "While discriminative deep learning methods usually outperform these techniques, it is still widely recognized that unsupervised learning algorithms that can extract useful features are needed for solving problems with limited or weak label information, such as video recognition or pedestrian detection [6].", "startOffset": 303, "endOffset": 306}, {"referenceID": 6, "context": "One way to solve this problem is to extract random image patches from input images and then train an unsupervised feature learning algorithm on these patches in isolation [7].", "startOffset": 171, "endOffset": 174}, {"referenceID": 7, "context": "1(a) shows the filters of a sparse non-convolutional autoencoder [8] with 1000 hidden units that was trained on CIFAR-10 image patches.", "startOffset": 65, "endOffset": 68}, {"referenceID": 6, "context": "As discussed in [7, 9], the main problem with this approach is that if the receptive field is small, this method will not capture relevant features (imagine the extreme of 1 \u00d7 1 patches).", "startOffset": 16, "endOffset": 22}, {"referenceID": 8, "context": "As discussed in [7, 9], the main problem with this approach is that if the receptive field is small, this method will not capture relevant features (imagine the extreme of 1 \u00d7 1 patches).", "startOffset": 16, "endOffset": 22}, {"referenceID": 9, "context": "Unsupervised methods that make use of convolutional architectures can be used to address this problem, including convolutional RBMs [10], convolutional DBNs [11, 10], deconvolutional networks [12] and convolutional predictive sparse decomposition (PSD) [9, 6].", "startOffset": 132, "endOffset": 136}, {"referenceID": 10, "context": "Unsupervised methods that make use of convolutional architectures can be used to address this problem, including convolutional RBMs [10], convolutional DBNs [11, 10], deconvolutional networks [12] and convolutional predictive sparse decomposition (PSD) [9, 6].", "startOffset": 157, "endOffset": 165}, {"referenceID": 9, "context": "Unsupervised methods that make use of convolutional architectures can be used to address this problem, including convolutional RBMs [10], convolutional DBNs [11, 10], deconvolutional networks [12] and convolutional predictive sparse decomposition (PSD) [9, 6].", "startOffset": 157, "endOffset": 165}, {"referenceID": 11, "context": "Unsupervised methods that make use of convolutional architectures can be used to address this problem, including convolutional RBMs [10], convolutional DBNs [11, 10], deconvolutional networks [12] and convolutional predictive sparse decomposition (PSD) [9, 6].", "startOffset": 192, "endOffset": 196}, {"referenceID": 8, "context": "Unsupervised methods that make use of convolutional architectures can be used to address this problem, including convolutional RBMs [10], convolutional DBNs [11, 10], deconvolutional networks [12] and convolutional predictive sparse decomposition (PSD) [9, 6].", "startOffset": 253, "endOffset": 259}, {"referenceID": 5, "context": "Unsupervised methods that make use of convolutional architectures can be used to address this problem, including convolutional RBMs [10], convolutional DBNs [11, 10], deconvolutional networks [12] and convolutional predictive sparse decomposition (PSD) [9, 6].", "startOffset": 253, "endOffset": 259}, {"referenceID": 11, "context": "Our work is similar in spirit to deconvolutional networks [12] and convolutional PSD [9, 6], but whereas the approach in that work is to break apart the recognition pathway and data generation pathway, but learn them so that they are consistent, we describe a technique for directly learning a convolutional autoencoder.", "startOffset": 58, "endOffset": 62}, {"referenceID": 8, "context": "Our work is similar in spirit to deconvolutional networks [12] and convolutional PSD [9, 6], but whereas the approach in that work is to break apart the recognition pathway and data generation pathway, but learn them so that they are consistent, we describe a technique for directly learning a convolutional autoencoder.", "startOffset": 85, "endOffset": 91}, {"referenceID": 5, "context": "Our work is similar in spirit to deconvolutional networks [12] and convolutional PSD [9, 6], but whereas the approach in that work is to break apart the recognition pathway and data generation pathway, but learn them so that they are consistent, we describe a technique for directly learning a convolutional autoencoder.", "startOffset": 85, "endOffset": 91}, {"referenceID": 6, "context": "In this figure, we plot the result of patch-based training using the k-means algorithm on the raw and whitened CIFAR-10 dataset as reported in [7] 1.", "startOffset": 143, "endOffset": 146}, {"referenceID": 6, "context": "Other patch-based approaches such as [7] only reports the cross-validation performance.", "startOffset": 37, "endOffset": 40}, {"referenceID": 11, "context": "We first describe our winner-take-all method and then we compare our technique with other approaches, including deconvolutional networks [12].", "startOffset": 137, "endOffset": 141}, {"referenceID": 6, "context": "Consistent with other representation learning approaches such as triangle kmeans [7] and deconvolutional networks [13], we observed that using a softer sparsity constraint at the test time results in a better classification performance.", "startOffset": 81, "endOffset": 84}, {"referenceID": 12, "context": "Consistent with other representation learning approaches such as triangle kmeans [7] and deconvolutional networks [13], we observed that using a softer sparsity constraint at the test time results in a better classification performance.", "startOffset": 114, "endOffset": 118}, {"referenceID": 13, "context": "A problem that arises in almost all sparse coding algorithms, such as OMP, K-SVD [14] or even in k-means clustering, is the problem of dead atoms or empty clusters when learning the dictionary.", "startOffset": 81, "endOffset": 85}, {"referenceID": 14, "context": "We used the publicly available gnumpy library [15] as well as Alex Krizhevsky\u2019s cuda-convnet library [1].", "startOffset": 46, "endOffset": 50}, {"referenceID": 0, "context": "We used the publicly available gnumpy library [15] as well as Alex Krizhevsky\u2019s cuda-convnet library [1].", "startOffset": 101, "endOffset": 104}, {"referenceID": 12, "context": "Error rate Shallow Deconvolutional Net with Differentiable Gaussian Pooling (16 maps) [13] 1.", "startOffset": 86, "endOffset": 90}, {"referenceID": 12, "context": "38% Deep Deconvolutional Net with Differentiable Gaussian Pooling [13] 0.", "startOffset": 66, "endOffset": 70}, {"referenceID": 15, "context": "84% Deep Convolutional Belief Networks [16] 0.", "startOffset": 39, "endOffset": 43}, {"referenceID": 16, "context": "[17] 0.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "On the CIFAR-10 dataset, we use global contrast normalization and ZCA whitening to preprocess the dataset as described in [7].", "startOffset": 122, "endOffset": 125}, {"referenceID": 17, "context": "Table 2 compares the performance of SCAs with other unsupervised feature learning methods, and shows that SCAs perform similarly to convolutional DBNs [18] and spike-and-slab sparse coding [19].", "startOffset": 151, "endOffset": 155}, {"referenceID": 18, "context": "Table 2 compares the performance of SCAs with other unsupervised feature learning methods, and shows that SCAs perform similarly to convolutional DBNs [18] and spike-and-slab sparse coding [19].", "startOffset": 189, "endOffset": 193}, {"referenceID": 6, "context": "It was shown in [7] that the triangle k-means method can achieve classification rates up to 79.", "startOffset": 16, "endOffset": 19}, {"referenceID": 19, "context": "Also, in our deep network, we used full connectivity between layers, but it was recently shown [20] that for triangle k-means, by learning the connectivity between layers using a similarity metric on the feature maps, a \u223c 3% gain in classification rate is achievable.", "startOffset": 95, "endOffset": 99}, {"referenceID": 20, "context": "Accuracy 3-Way Factored RBM (3 layers) [21] 65.", "startOffset": 39, "endOffset": 43}, {"referenceID": 21, "context": "3% Mean-covariance RBM (3 layers) [22] 71.", "startOffset": 34, "endOffset": 38}, {"referenceID": 22, "context": "0% Spike-and-Slab RBM [23] 76.", "startOffset": 22, "endOffset": 26}, {"referenceID": 18, "context": "7% Spike-and-Slab Sparse Coding [19] 78.", "startOffset": 32, "endOffset": 36}, {"referenceID": 17, "context": "3% Convolutional Deep Belief Net (2 layers) [18] (fine-tuned) 78.", "startOffset": 44, "endOffset": 48}, {"referenceID": 6, "context": "9% Triangle k-means (1600 maps) [7] 77.", "startOffset": 32, "endOffset": 35}, {"referenceID": 6, "context": "We use global contrast normalization and ZCA whitening to preprocess the dataset as described in [7] and separate the two views to form a training set of 48, 600 images.", "startOffset": 97, "endOffset": 100}, {"referenceID": 3, "context": "Error rate Deep Boltzmann Machines [4] 7.", "startOffset": 35, "endOffset": 38}, {"referenceID": 20, "context": "2% Third-order RBM [21] 6.", "startOffset": 19, "endOffset": 23}, {"referenceID": 4, "context": "5% Deep Belief Network [5] 5.", "startOffset": 23, "endOffset": 26}, {"referenceID": 6, "context": "0% Triangle k-means [7] (4000 feature maps) 2.", "startOffset": 20, "endOffset": 23}, {"referenceID": 12, "context": "Deconvolutional networks [13] are top down models for generating images from a set of feature maps under a sparsity constraint.", "startOffset": 25, "endOffset": 29}, {"referenceID": 8, "context": "Convolutional PSD [9] was introduced to address this problem.", "startOffset": 18, "endOffset": 21}, {"referenceID": 2, "context": "When we initially described our approach to colleagues, they confused it with maxout [3], which is an activation function that performs a max operation over a set of linear units and represents the maximum of these units as the final activation.", "startOffset": 85, "endOffset": 88}], "year": 2014, "abstractText": "We explore combining the benefits of convolutional architectures and autoencoders for learning deep representations in an unsupervised manner. A major challenge is to achieve appropriate sparsity among hidden variables, since neighbouring variables in each feature map tend to be highly correlated and a suppression mechanism is therefore needed. Previously, deconvolutional networks and convolutional predictive sparse decomposition have been used to construct systems that have a recognition pathway and a data generation pathway that are trained so that they agree and so that the hidden representation is sparse. We take a more direct approach and describe a way to train convolutional autoencoders layer by layer, where in each layer sparsity is achieved using a winner-take-all activation function within each feature map. Learning is computationally efficient and we show that our method can be used to train shallow and deep convolutional autoencoders whose representations can be used to achieve classification rates on the MNIST, CIFAR-10 and NORB datasets that are competitive with the state of the art.", "creator": "LaTeX with hyperref package"}}}