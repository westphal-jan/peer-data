{"id": "1409.3768", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2014", "title": "Optimization Methods for Sparse Pseudo-Likelihood Graphical Model Selection", "abstract": "Sparse high dimensional graphical model selection is a popular topic in contemporary machine learning. To this end, various useful approaches have been proposed in the context of $\\ell_1$-penalized estimation in the Gaussian framework. Though many of these inverse covariance estimation approaches are demonstrably scalable and have leveraged recent advances in convex optimization, they still depend on the Gaussian functional form. To address this gap, a convex pseudo-likelihood based partial correlation graph estimation method (CONCORD) has been recently proposed. This method uses coordinate-wise minimization of a regression based pseudo-likelihood, and has been shown to have robust model selection properties in comparison with the Gaussian approach. In direct contrast to the parallel work in the Gaussian setting however, this new convex pseudo-likelihood framework has not leveraged the extensive array of methods that have been proposed in the machine learning literature for convex optimization. In this paper, we address this crucial gap by proposing two proximal gradient methods (CONCORD-ISTA and CONCORD-FISTA) for performing $\\ell_1$-regularized inverse covariance matrix estimation in the pseudo-likelihood framework. We present timing comparisons with coordinate-wise minimization and demonstrate that our approach yields tremendous payoffs for $\\ell_1$-penalized partial correlation graph estimation outside the Gaussian setting, thus yielding the fastest and most scalable approach for such problems. We undertake a theoretical analysis of our approach and rigorously demonstrate convergence, and also derive rates thereof.", "histories": [["v1", "Fri, 12 Sep 2014 15:25:07 GMT  (76kb,D)", "http://arxiv.org/abs/1409.3768v1", "NIPS accepted version"]], "COMMENTS": "NIPS accepted version", "reviews": [], "SUBJECTS": "stat.CO cs.LG stat.ML", "authors": ["sang-yun oh", "onkar dalal", "kshitij khare", "bala rajaratnam"], "accepted": true, "id": "1409.3768"}, "pdf": {"name": "1409.3768.pdf", "metadata": {"source": "CRF", "title": "Optimization Methods for Sparse Pseudo-Likelihood Graphical Model Selection", "authors": ["Sang-Yun Oh", "Onkar Dalal", "Kshitij Khare"], "emails": ["syoh@lbl.gov", "onkar@alumni.stanford.edu", "kdkhare@stat.ufl.edu", "brajarat@stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1 Background", "text": "These sparse models, popularly known as graphic models, are used in various fields of application, especially in high-dimensional environments. The most popular inverse covariance estimation system is probably the \"1-dimensional positive definitive matrices,\" and \"1-penalty is imposed on the elements of\" 1, \"\" 1, \"\" 1, \"\" 1, \"\" 1, \"\" 1, \"\" \"1,\" \"\" 1, \"\" \"1,\" and \"1.\" The matrix S denotes Thear Xiv: 140 9.37 68v1 [st at.C O], 1, \"1,\" \"1,\" \"1,\" 1. \""}, {"heading": "1.2 The CONCORD method", "text": "Despite their enormous contributions, one shortcoming of the traditional approaches to \"1-punished probability maximization = 1-punished probability maximization\" is the limitation to Gaussian assumption. To close this gap, a series of \"1-punished pseudo-probability approaches\" has been proposed: SPACE Peng et al. [2009] and SPLICE Rocha et al. [2008], SYMLASSO Friedman et al. [2010]. These approaches are either non-convex, and / or convergence of corresponding maximization algorithms are not established. In this sense, non-Gaussian partial correlation graph estimation methods lag considerably behind, despite the enormous need to exceed the Gaussian framework for obvious practical reasons. In very recent work, a convex pseudo-probability approach with good model selection properties named CONCORD Khare et al al al al al al al al al al al. [2014] has been proposed."}, {"heading": "2 CONCORD using proximal gradient methods", "text": "The punished matrix version of the CONCORD objective function in (1) is taken over by the Qcon method (1). (1) using the diagonal and off-diagonal elements of the ECR (2). (1) We will use the notation A = AD + AX to divide each matrix A into its diagonal and off-diagonal terms. (4) This section proposes a scalable and thorough approach to solving the CONCORD objective function using recent advances in convex optimization and derivation of convergence rates for such algorithms. (1) In particular, we use proximal gradient-based methods to demonstrate the effectiveness of such methods for the non-Gaussian graphical modeling problem. (1) First, we propose CONCORD-ISTA and CONCORD-FISTA in Section 2.1: Methods inspired by itative problem solving."}, {"heading": "2.1 Iterative Soft Thresholding Algorithms: CONCORD-ISTA, CONCORD-FISTA", "text": "The iterative soft threshold algorithms (ISTA) have recently gained popularity following the groundbreaking work of Beck and Teboulle Beck and Teboulle [2009].The ISTA methods are based on the forward backward splitting method of Rockafellar [1976] and Nesterov's accelerated gradient methods Nesterov [1983] using the soft threshold as the proximal operator for the \"1 standard.\" The essence of the proximal gradient algorithms is to divide the objective function into a smooth part and a non-smooth part and then to make a proximal step (w.r.t. the non-smooth part) in the negative gradient direction of the smooth part. Nesterov's accelerated gradient extension Nesterov [1983] uses a combination of gradient and dynamic steps to achieve accelerated convergence rates. In this section of CORD COND, we use this function in the context of Accelerated Gradient COND to have a combination of gradient steps."}, {"heading": "2.2 Choice of step size", "text": "In the absence of a good estimate of the Lipschitz constant L, the step size for each iteration of CONCORD-ISTA and CONCORD-FISTA is chosen using the Trace Line Search. Line search for iteration k starts with an initial step size \u03c4 (k, 0) and reduces the step size by a constant factor c until the new iteration meets the sufficient descend condition: h1 (k + 1)) \u2264 Q (k + 1) (8), where Q (k) = h1 (a) + tr (a) (a) (a) a constant initial step size (= 1), (b) the feasible step size from the previous iteration. \u2212 In Section 4 we have implemented algorithms that select the initial step size in three different ways: (a) a constant initial step size (= 1), (b) the feasible step size from the preceding step size (c) (1)."}, {"heading": "2.3 Computational complexity", "text": "After the one-time calculation of S, the most important calculation for each iteration in the CONCORD-ISTA and CONCORD-FISTA algorithms is the matrix matrix multiplication W = S in the gradient term. If s is the number of non-zeros in B, then W can be calculated with O (sp2) operations if we exhaust the extreme sparseness in B. The second matrix matrix multiplication for the term tr (sp) can be efficiently calculated with tr (p2) operations."}, {"heading": "3 Convergence Analysis", "text": "In this section, we demonstrate the convergence of the CONCORD-ISTA and CONCORD-FISTA methods with their respective convergence rates of O (1 / k) and O (1 / k2). We would like to point out that although the authors in Khare et al. [2014] provide evidence of convergence for their respective convergence criteria, they do not provide convergence criteria for the convergence criteria. We begin by demonstrating the lower and upper limits of the diagonal convergence criteria for the diagonal convergence criteria."}, {"heading": "4 Implementation & Numerical Experiments", "text": "In this section we outline the details of the algorithm implementation and present the results of our comprehensive numerical evaluation. Section 4.1 provides performance comparisons from the use of synthetic multivariate Gaussian datasets, which are generated from a wide range of sample size (s) and dimensionality (p). In addition, the convergence of CONCORDISTA and CONCORD-FISTA is illustrated. Section 4.2 has temporal results from the analysis of a real breast cancer dataset with outliers. Comparisons are made with the coordinate-wise CONCORD implementation in the Gconcord package for R at http: / / cran.r-project.org / web / packages / gconcord /.For the implementation of the proposed algorithms, we can also use the existing linear algebra libraries. Most numerical calculations in the algorithms 1 and 2 are linear algebra CORD operations, as opposed to CORD and more efficient COND algorithms."}, {"heading": "4.1 Synthetic Datasets", "text": "Synthetic datasets were generated from true sparsely positive ratio matrices of three sizes: p = {1000, 3000, 5000}. Examples of random matrices used here consist of 4995, 14985, and 24975 non-zeros corresponding to 1%, 0.33%, and 0.20% edge densities. For each p, three random samples of n = {0.25p, 0.75p, 1.25p} were used as inputs. Initial assumptions that the convergence criteria were aligned with those of the coordinated CONCORD implementation. Highlights of the results are summarized below, and the full set of comparisons are included in Supplementary Materials Section A. For synthetic datasets, our experiments suggest that two variations of the CONCORD-ISTA method show little performance differences."}, {"heading": "4.2 Real Data", "text": "Real datasets originating from different physical and biological sciences are often not multivariate Gaussian and may have outliers. Therefore, the convergence characteristics on such datasets may be different. In this section, the performance of the proposed methods is evaluated using a breast cancer dataset [Chang et al., 2005]. This dataset contains expression levels of 24481 genes in 266 patients with breast cancer. Following the approach in Khare et al. Khare et al. [2014], the number of genes is reduced through the use of clinical information provided together with the microarray expression dataset. In particular, survival analysis using univaried Cox regression with patients \"survival times is used to select a subset of genes closely related to breast cancer. A selection of the p-value < 0.03 yields a reduced dataset with p = 4433 genes is not applied to a quick-to-select algorithm of the palate here."}, {"heading": "5 Conclusion", "text": "The Gaussian estimation of the graphical model or inverse covariance estimation has made tremendous progress in recent years. In this paper, we propose to use proximal gradient methods to solve the general, not Gaussian, sparse inverse covariance estimation problem. Convergence rates have been determined for the CONCORD-ISTA and CONCORDFISTA algorithms. Coordinate-wise minimization has been the standard approach to this problem so far, and we provide numerical results that compare CONCORD-ISTA / FISTA and coordinate-wise minimization. We show that CONCORD-ISTA generally performs better coordinate-wise, and in high-dimensional environments CONCORD-ISTA can exceed coordinate-wise optimization by orders of magnitude. We also test the methodology on real datasets. We perform a comprehensive treatment of the problem by also examining the dual formulation and considering methods in high-dimensional environments that we find the goal to be similar to the Gausal one, but do not include any other Gausal one."}, {"heading": "A Timing comparison", "text": "A.1 Mean Acceleration"}, {"heading": "1000 250 0.6 ( 0.7) 0.4 ( 0.3)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1000 750 3.4 ( 1.8) 1.9 ( 0.9)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1000 1250 23.1 ( 5.7) 12.0 ( 3.5)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3000 750 2.7 ( 2.1) 1.9 ( 1.6)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3000 2250 12.8 ( 1.6) 8.8 ( 2.2)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3000 3750 81.9 ( 6.6) 58.2 ( 8.7)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5000 1250 5.6 ( 3.2) 3.0 ( 1.8)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5000 3750 21.1 ( 2.6) 13.5 ( 2.6)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5000 6250 145.8 ( 6.6) 110.1 (16.4)", "text": "A.2 Comparison between CONCORD-ISTA and CONCORD-FISTA variants A.3 Comparison with CONCORD algorithmsA.4 Running times"}, {"heading": "23 1000 1250 0.163 0.23 9 43.84 13 1.25 23 2.75", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "22 1000 1250 0.103 0.44 9 44.16 15 1.93 24 3.02", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "21 1000 1250 0.077 0.97 9 40.50 15 1.65 24 3.34", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "20 1000 1250 0.066 2.03 9 44.15 14 1.79 24 4.09", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "19 1000 1250 0.061 2.91 9 43.84 16 2.36 24 5.38", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "18 1000 1250 0.059 3.43 9 44.25 16 2.49 24 5.00", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "17 1000 1250 0.058 3.69 9 44.21 15 2.54 24 5.29", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "16 1000 750 0.300 0.04 8 6.96 13 1.13 18 2.20", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "15 1000 750 0.163 0.23 9 8.00 15 1.57 24 2.80", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "14 1000 750 0.103 0.76 9 8.40 15 1.58 24 3.26", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "13 1000 750 0.077 3.09 9 8.37 16 3.53 25 4.84", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "12 1000 750 0.066 5.86 10 10.45 20 4.01 27 6.96", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "11 1000 750 0.061 7.64 10 9.97 20 5.41 28 7.96", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10 1000 750 0.059 8.56 10 9.86 20 5.19 28 9.86", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9 1000 750 0.058 8.99 10 9.96 20 4.56 28 12.44", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8 1000 250 0.300 0.05 9 2.58 15 1.23 23 2.67", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7 1000 250 0.163 0.99 9 2.61 18 1.98 26 3.31", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "71 5000 6250 0.163 0.04 16 14787.78 26 97.33 34 173.66", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "70 5000 6250 0.103 0.08 17 15600.83 26 112.48 33 144.42", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "69 5000 6250 0.077 0.10 17 15671.14 27 101.03 25 123.92", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "68 5000 6250 0.066 0.11 17 16220.33 27 111.75 25 129.70", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "67 5000 6250 0.061 0.11 17 15698.53 27 103.06 25 132.57", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "66 5000 6250 0.059 0.12 17 16221.44 27 115.35 25 130.19", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "65 5000 6250 0.058 0.12 17 15698.02 27 113.65 25 150.95", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "64 5000 3750 0.300 0.01 14 1767.63 24 78.77 30 117.03", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "63 5000 3750 0.163 0.04 16 2021.49 25 82.88 33 133.36", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "62 5000 3750 0.103 0.08 16 1780.97 26 88.29 32 141.14", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "61 5000 3750 0.077 0.10 17 2094.73 29 95.84 33 178.13", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "60 5000 3750 0.066 0.11 17 2183.90 29 98.54 25 121.39", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "59 5000 3750 0.061 0.13 17 1967.39 29 114.72 35 186.34", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "58 5000 3750 0.059 0.13 17 1965.36 29 111.53 35 189.05", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "57 5000 3750 0.058 0.14 17 2324.54 29 99.50 35 165.12", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "56 5000 1250 0.300 0.01 14 626.20 25 69.71 30 105.65", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "55 5000 1250 0.163 0.05 16 719.81 25 71.23 34 147.53", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "54 5000 1250 0.103 0.10 17 667.62 27 81.21 33 163.00", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "53 5000 1250 0.077 0.53 17 674.71 30 121.39 35 265.84", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "52 5000 1250 0.066 1.42 17 832.68 32 193.88 37 379.23", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "51 5000 1250 0.061 2.13 18 892.30 36 272.03 40 604.35", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "50 5000 1250 0.059 2.52 18 903.05 37 393.77 40 681.49", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "49 5000 1250 0.058 2.71 18 757.67 38 408.49 40 547.93", "text": "The problem of the dual use of the matrix form is also challenging, since the KKT conditions with the gradient term S1 + 2 do not have a closed form solution, as in the case of the Gaussian problem in Dalal and Rajaratnam (2014). Therefore, we are looking at a vector form of the CONCORD problem by defining two new variables x1 and x2. (21) We are defining two coefficient matrices A1, A2 asA1 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2 Y2"}], "references": [{"title": "DAspremont. Model Selection Through Sparse Maximum Likelihood Estimation for Multivariate Gaussian or", "author": ["Onureena Banerjee", "Laurent El Ghaoui", "Alexandre"], "venue": "Binary Data. JMLR,", "citeRegEx": "Banerjee et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Banerjee et al\\.", "year": 2008}, {"title": "G-ama: Sparse gaussian graphical model estimation via alternating minimization", "author": ["Onkar Anant Dalal", "Bala Rajaratnam"], "venue": "arXiv preprint arXiv:1405.3034,", "citeRegEx": "Dalal and Rajaratnam.,? \\Q2014\\E", "shortCiteRegEx": "Dalal and Rajaratnam.", "year": 2014}, {"title": "Partial Correlation Estimation by Joint Sparse Regression Models", "author": ["Jie Peng", "Pei Wang", "Nengfeng Zhou", "Ji Zhu"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Peng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Peng et al\\.", "year": 2009}, {"title": "A path following algorithm for Sparse Pseudo-Likelihood Inverse Covariance Estimation (SPLICE)", "author": ["Guilherme V Rocha", "Peng Zhao", "Bin Yu"], "venue": "Technical Report 60628102,", "citeRegEx": "Rocha et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rocha et al\\.", "year": 2008}, {"title": "Applications of the lasso and grouped lasso to the estimation of sparse graphical models", "author": ["Jerome Friedman", "Trevor Hastie", "Robert Tibshirani"], "venue": "Technical report,", "citeRegEx": "Friedman et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Friedman et al\\.", "year": 2010}, {"title": "A convex pseudo-likelihood framework for high dimensional partial correlation estimation with convergence guarantees", "author": ["Kshitij Khare", "Sang-Yun Oh", "Bala Rajaratnam"], "venue": "Journal of the Royal Statistical Society: Series B,", "citeRegEx": "Khare et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Khare et al\\.", "year": 2014}, {"title": "A fast iterative shrinkage-thresholding algorithm for linear inverse problems", "author": ["Amir Beck", "Marc Teboulle"], "venue": "SIAM Journal on Imaging Sciences,", "citeRegEx": "Beck and Teboulle.,? \\Q2009\\E", "shortCiteRegEx": "Beck and Teboulle.", "year": 2009}, {"title": "Monotone operators and the proximal point algorithm", "author": ["R.T. Rockafellar"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "Rockafellar.,? \\Q1976\\E", "shortCiteRegEx": "Rockafellar.", "year": 1976}, {"title": "Two-point step size gradient methods", "author": ["J. Barzilai", "J.M. Borwein"], "venue": "IMA Journal of Numerical Analysis,", "citeRegEx": "Barzilai and Borwein.,? \\Q1988\\E", "shortCiteRegEx": "Barzilai and Borwein.", "year": 1988}, {"title": "Robustness, scalability, and integration of a wound-response gene expression signature in predicting breast cancer survival", "author": ["Howard Y Chang", "Dimitry S A Nuyten", "Julie B Sneddon", "Trevor Hastie", "Robert Tibshirani", "Therese S\u00f8 rlie", "Hongyue Dai", "Yudong D He", "Laura J van\u2019t Veer", "Harry Bartelink", "Matt van de Rijn", "Patrick O Brown", "Marc J van de Vijver"], "venue": "Proceedings of the National Academy of Sciences of the United States of America,", "citeRegEx": "Chang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "The literature on this topic is simply enormous and for the sake of brevity, space constraints and the topic of this paper, we avoid an extensive literature review by referring to the references in the seminal work of Banerjee et al. [2008] and the very recent work of Dalal and Rajaratnam [2014].", "startOffset": 218, "endOffset": 241}, {"referenceID": 0, "context": "The literature on this topic is simply enormous and for the sake of brevity, space constraints and the topic of this paper, we avoid an extensive literature review by referring to the references in the seminal work of Banerjee et al. [2008] and the very recent work of Dalal and Rajaratnam [2014]. These two papers contain references to recent work, including past NIPS conference proceedings.", "startOffset": 218, "endOffset": 297}, {"referenceID": 2, "context": "To address this gap, a number of `1-penalized pseudo-likelihood approaches have been proposed: SPACE Peng et al. [2009] and SPLICE Rocha et al.", "startOffset": 101, "endOffset": 120}, {"referenceID": 2, "context": "To address this gap, a number of `1-penalized pseudo-likelihood approaches have been proposed: SPACE Peng et al. [2009] and SPLICE Rocha et al. [2008], SYMLASSO Friedman et al.", "startOffset": 101, "endOffset": 151}, {"referenceID": 2, "context": "To address this gap, a number of `1-penalized pseudo-likelihood approaches have been proposed: SPACE Peng et al. [2009] and SPLICE Rocha et al. [2008], SYMLASSO Friedman et al. [2010]. These approaches are either not convex, and/or convergence of corresponding maximization algorithms are not established.", "startOffset": 101, "endOffset": 184}, {"referenceID": 2, "context": "To address this gap, a number of `1-penalized pseudo-likelihood approaches have been proposed: SPACE Peng et al. [2009] and SPLICE Rocha et al. [2008], SYMLASSO Friedman et al. [2010]. These approaches are either not convex, and/or convergence of corresponding maximization algorithms are not established. In this sense, non-Gaussian partial correlation graph estimation methods have lagged severely behind, despite the tremendous need to move beyond the Gaussian framework for obvious practical reasons. In very recent work, a convex pseudo-likelihood approach with good model selection properties called CONCORD Khare et al. [2014] was proposed.", "startOffset": 101, "endOffset": 634}, {"referenceID": 5, "context": "(3) This coordinate-wise algorithm is shown to converge to a global minima though no rate is given [Khare et al., 2014].", "startOffset": 99, "endOffset": 119}, {"referenceID": 6, "context": "1: methods which are inspired by the iterative soft-thresholding algorithms in Beck and Teboulle [2009]. We undertake a comprehensive treatment of the CONCORD optimization problem by also investigating the dual of the CONCORD problem.", "startOffset": 79, "endOffset": 104}, {"referenceID": 6, "context": "The iterative soft-thresholding algorithms (ISTA) have recently gained popularity after the seminal paper by Beck and Teboulle Beck and Teboulle [2009]. The ISTA methods are based on the Forward-Backward Splitting method from Rockafellar [1976] and Nesterov\u2019s accelerated gradient methods Nesterov [1983] using soft-thresholding as the proximal operator for the `1-norm.", "startOffset": 109, "endOffset": 152}, {"referenceID": 6, "context": "The iterative soft-thresholding algorithms (ISTA) have recently gained popularity after the seminal paper by Beck and Teboulle Beck and Teboulle [2009]. The ISTA methods are based on the Forward-Backward Splitting method from Rockafellar [1976] and Nesterov\u2019s accelerated gradient methods Nesterov [1983] using soft-thresholding as the proximal operator for the `1-norm.", "startOffset": 109, "endOffset": 245}, {"referenceID": 6, "context": "The iterative soft-thresholding algorithms (ISTA) have recently gained popularity after the seminal paper by Beck and Teboulle Beck and Teboulle [2009]. The ISTA methods are based on the Forward-Backward Splitting method from Rockafellar [1976] and Nesterov\u2019s accelerated gradient methods Nesterov [1983] using soft-thresholding as the proximal operator for the `1-norm.", "startOffset": 109, "endOffset": 305}, {"referenceID": 6, "context": "The iterative soft-thresholding algorithms (ISTA) have recently gained popularity after the seminal paper by Beck and Teboulle Beck and Teboulle [2009]. The ISTA methods are based on the Forward-Backward Splitting method from Rockafellar [1976] and Nesterov\u2019s accelerated gradient methods Nesterov [1983] using soft-thresholding as the proximal operator for the `1-norm. The essence of the proximal gradient algorithms is to divide the objective function into a smooth part and a non-smooth part, then take a proximal step (w.r.t. the non-smooth part) in the negative gradient direction of the smooth part. Nesterov\u2019s accelerated gradient extension Nesterov [1983] uses a combination of gradient and momentum steps to achieve accelerated rates of convergence.", "startOffset": 109, "endOffset": 665}, {"referenceID": 8, "context": "This is an approximation of the secant equation which works as a proxy for second order information using successive gradients (see Barzilai and Borwein [1988] for details).", "startOffset": 132, "endOffset": 160}, {"referenceID": 5, "context": "The coordinatewise method for optimizing CONCORD in Khare et al. [2014] also requires cycling through the p entries of \u03a9 in specified order and thus does not allow parallelization.", "startOffset": 52, "endOffset": 72}, {"referenceID": 5, "context": "We would like to point out that, although the authors in Khare et al. [2014] provide a proof of convergence for their coordinate-wise minimization algorithm for CONCORD, they do not provide any rates of convergence.", "startOffset": 57, "endOffset": 77}, {"referenceID": 5, "context": "We would like to point out that, although the authors in Khare et al. [2014] provide a proof of convergence for their coordinate-wise minimization algorithm for CONCORD, they do not provide any rates of convergence. The arguments for convergence leverage the results in Beck and Teboulle [2009] but require some essential ingredients.", "startOffset": 57, "endOffset": 295}, {"referenceID": 6, "context": "The remaining argument for convergence follows from the theorems in Beck and Teboulle [2009].", "startOffset": 68, "endOffset": 93}, {"referenceID": 5, "context": "This can be attributed to min(O(np),O(p)) computational complexity of coordinate-wise CONCORD [Khare et al., 2014], and the sparse linear algebra routines used in CONCORD-ISTA and CONCORD-FISTA implementations slowing down as the number of non-zero elements in \u03a9 increases.", "startOffset": 94, "endOffset": 114}, {"referenceID": 9, "context": "In this section, the performance of proposed methods are assessed on a breast cancer dataset [Chang et al., 2005].", "startOffset": 93, "endOffset": 113}, {"referenceID": 5, "context": "Following the approach in Khare et al. Khare et al. [2014], the number of genes are reduced by utilizing clinical information that is provided together with the microarray expression dataset.", "startOffset": 26, "endOffset": 59}], "year": 2014, "abstractText": "Sparse high dimensional graphical model selection is a popular topic in contemporary machine learning. To this end, various useful approaches have been proposed in the context of `1-penalized estimation in the Gaussian framework. Though many of these inverse covariance estimation approaches are demonstrably scalable and have leveraged recent advances in convex optimization, they still depend on the Gaussian functional form. To address this gap, a convex pseudo-likelihood based partial correlation graph estimation method (CONCORD) has been recently proposed. This method uses coordinate-wise minimization of a regression based pseudo-likelihood, and has been shown to have robust model selection properties in comparison with the Gaussian approach. In direct contrast to the parallel work in the Gaussian setting however, this new convex pseudo-likelihood framework has not leveraged the extensive array of methods that have been proposed in the machine learning literature for convex optimization. In this paper, we address this crucial gap by proposing two proximal gradient methods (CONCORD-ISTA and CONCORD-FISTA) for performing `1-regularized inverse covariance matrix estimation in the pseudo-likelihood framework. We present timing comparisons with coordinate-wise minimization and demonstrate that our approach yields tremendous payoffs for `1-penalized partial correlation graph estimation outside the Gaussian setting, thus yielding the fastest and most scalable approach for such problems. We undertake a theoretical analysis of our approach and rigorously demonstrate convergence, and also derive rates thereof.", "creator": "LaTeX with hyperref package"}}}