{"id": "1409.7495", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Sep-2014", "title": "Unsupervised Domain Adaptation by Backpropagation", "abstract": "Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary).", "histories": [["v1", "Fri, 26 Sep 2014 08:22:21 GMT  (5856kb,D)", "http://arxiv.org/abs/1409.7495v1", null], ["v2", "Fri, 27 Feb 2015 14:54:37 GMT  (6158kb,D)", "http://arxiv.org/abs/1409.7495v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG cs.NE", "authors": ["yaroslav ganin", "victor s lempitsky"], "accepted": true, "id": "1409.7495"}, "pdf": {"name": "1409.7495.pdf", "metadata": {"source": "CRF", "title": "Unsupervised Domain Adaptation by Backpropagation", "authors": ["Yaroslav Ganin", "Victor Lempitsky"], "emails": ["ganin@skoltech.ru", "lempitsky@skoltech.ru"], "sections": [{"heading": null, "text": "Over the course of the training, the approach promotes the emergence of \"deep\" characteristics that are (i) discriminatory for the primary learning task in the source domain and (ii) invariant in terms of displacement between domains. We show that this adaptation behavior can be achieved in almost any feed-forward model by extending it with a few standard layers and a simple new gradient reverse layer. The resulting advanced architecture can be trained using standard back propagation. Overall, the entire approach can be implemented with a low effort using one of the deep learning packages."}, {"heading": "1. Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2. Related work", "text": "A large number of domain matching methods have been proposed in recent years, and here we are focusing on most related species. Several methods lead to unattended domain matching by aligning the attribute distributions in the source and target areas. An important aspect of the distribution approach is the way in which the (dis-) similarity between distributions is measured. Here, an explicit feature transformation is sought that maps the source distributions in the target areas. [16, 10, 2] An important aspect of the distribution approach is the way in which the (dis-) similarity between distributions is measured."}, {"heading": "3. Deep Domain Adaptation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. The model", "text": "We assume that the model works with the input examples of X-X, where X labels (e.g. images of a certain size) and certain labels (output) from the label space Y. We further assume that there are two distribution problems in which Y is a finite quantity (Y = {1, 2,.), but our approach is generic and can handle any output label space that other design models can handle. We further assume that there are two distributions S (x, y) on X-Y that are referred to as source distribution and target distribution (or the target domain and target domain), both distributions are assumed to be complex and unknown, and beyond that we are similar (in other words, S is \"shifted\" by some domain shifts).Our ultimate goal is to predict the labels y label for target distribution."}, {"heading": "3.2. Optimization with backpropagation", "text": "A saddle point (2) - (3) cannot be found as the stationary point of the following stochastic updates (2) - some of which are desirable (2)."}, {"heading": "4. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Datasets", "text": "In this report, we confirm our approach within a series of digital image classification experiments. In each case, we train on the source data set and test on another target data set, with significant shifts between domains (see Figure 2). In total, we have six data sets involved in the experiments described below. The first four data sets are the well-known MNIST dataset [12] and its modifications. Modifications include: \u2022 MNIST (D): Binary dilation with a 3 \u00d7 3 all-one structuring element. This operation makes the strokes thicker and can fill small holes, creating an additional challenge for the classification task. \u2022 MNIST (max, BG): The mixing of white digits over the randomly extracted patches (BSDS500) is a difference between the significant pixels as they are, this modification adds strong background confusion."}, {"heading": "Baselines", "text": "In each experiment, we compare the results of our approach with the two natural baselines, i.e. training in the source domain without adaptation (a lower limit for any reasonable DA method) and training in the target domain while using the target domain names at the same time (an upper limit for DA methods, provided that target data is abundant and the shift between domains is considerable). Furthermore, we compare our approach with the recently proposed unattended DA method based on subspace alignment (SA) [5]. We detail the protocol for using SA below. The SA algorithm has an important free parameter, namely the number of main components. In each of the experiments, we give this baseline an advantage by selecting this value from the range {2,.,.,, 60} so that performance in the target domain is maximized."}, {"heading": "CNN architectures.", "text": "In our experiments, two different architectures were used (Figure 3): we use the smaller one if the source domain is MNIST, and the larger one otherwise. The architectures chosen for these sets are fairly standard in terms of trait extractor and label predictor parts: the \"MNIST\" design is inspired by the classic LeNet-5 [12], while the second CNN is adopted by [19]. In both cases, the domain classification branch is somewhat arbitrary - the effects of changing its design have yet to be analyzed. In terms of loss functions, we rely on logistic regression costs or binomic cross entropy."}, {"heading": "Training procedure.", "text": "The model is trained on 128 elements with 32 x 32 color fields (we replicate channels for the original MNIST), no pre-processing is performed except for the entire mean subtraction, one half of each batch is colonized by samples from the source domain (with known labels), the rest consists of the target domain (with unknown labels), we use stochastic gradient decrease with 0.9 pulses and the learning rate described by the following formula: \u00b5p = \u00b50 (1 + \u03b1 \u00b7 p) \u03b2, (10), where p is the training progress that changes linearly from 0 to 1, \u00b50 = 0.01, \u03b1 = 10, and \u03b2 = 0.75 (the schedule has been optimized to promote convergence and minor errors in the source domain).To suppress the loud signal from the domain classification, we must instead switch the final steps of the training process to the fit factor by gradually changing it from 0 to 1."}, {"heading": "Visualizations.", "text": "We use t-SNE [22] projection to visualize attribute distributions at different points in the network while color-coding the domains (Figure 4). Overall, we observe a fairly strong correlation between the success of the fit in terms of classification accuracy for the target domain and the extent of the discrepancy between domain distributions in our visualizations."}, {"heading": "4.1. Results.", "text": "We are testing our approach and baselines for six different domain pairs. The results obtained by the composition of the feature extractor and the label predictor for the three baseline methods and our approach are summarized in Table 1 and are discussed below."}, {"heading": "MNIST\u2192 its variations", "text": "In the first three experiments, we deal with the MNIST dataset: A classifier is trained on the basis of the original dataset while being adjusted to perform well on a particular modification of the source domain; the three target domains can be ranked on the basis of similarity to the source domain (which is assessed on the basis of the performance of the classifier trained on the source domain and can be applied to the target domain); the domain matching is expected to be easiest for the target domain closest to the source domain (MNIST (D)); and our method is able to cover three-quarters of the performance gap between the source-trained and target-trained classifiers (i.e., lower and upper limits); the adjustment task is more difficult in the case of digits mixed over the color background. Although samples from these domains show considerable clutter, our approach managed to mix the characteristics (Figure 4, which results in very successful adjustment)."}, {"heading": "Synthetic numbers\u2192 SVHN", "text": "To address a common scenario of training on synthetic images and testing on challenging real images, we use SVHN as the target domain and synthetic digits as the source. The proposed back-propagation-based technique works well, covering two-thirds of the gap between training on source data and training on target domain data with known target markers. In contrast, [5] does not significantly improve classification accuracy, making the adjustment task even more difficult than in the case of MNIST experiments."}, {"heading": "MNIST\u2194 SVHN", "text": "Finally, we test our approach to the two most distinguishable domains, MNIST and SVHN. Training to SVHN even without adaptation is challenging - the classification error remains high for the first 150 epochs. Therefore, to avoid getting into a bad local minimum, we do not use an annealing of the learning rate here. Obviously, the two directions (MNIST-to-SVHN and SVHN-to-MNIST) are not equally difficult. As SVHN is more diverse, it is expected that a model trained on SVHN is more general and performs reasonably on the MNIST dataset. In fact, this proves to be the case, and is supported by the appearance of feature distributions. We observe a fairly strong separation between domains when we feed it into the CNN-trained MNIST, while for the SVHN-trained network the characteristics are much more mixed with each other and are supported by the occurrence of feature distributions."}, {"heading": "5. Discussion", "text": "We have proposed a new approach to unattended domain customization of deep feed forward architectures, which enables large-scale training based on a large amount of commented data in the source domain and a large amount of uncommented data in the target domain. Similar to many previous flat and deep DA techniques, the customization is done by aligning the distributions of traits in the two domains, but unlike previous approaches, the customization is done by standard back-propagation training, so the approach is more scalable and can be implemented with any deep learning package. In experiments with digital image classification, the approach showed its efficiency and clearly exceeded a state-of-the-art, unattended DA method. Another evaluation for larger tasks is the immediate future work. It is also interesting to see whether the approach can benefit from a good initialization of the Extrac-MNIST (max, BG) feature."}, {"heading": "Appendix: An alternative optimization approach", "text": "There is an alternative construction (inspired by [9]) that leads to the same updates (4) - (6). Instead of using the gradient inverse layer, the construction introduces two different loss functions for the domain classifier. However, minimizing the first domain loss (Ld +) should lead to better domain discrimination, while the second domain loss (Ld -) is minimized if the domains are different. Stochastic actualizations for Affect f and Affect d are then defined as: \u03b8f \u2190 \u2212 Affect f \u2212 \u00b5 (Impact) (12) Affect-Lid-Affect-Affect-Lid-Affect-Lid-Affect-Lid-Affect-Lid, (13). In this context, the gradient inverse layer represents a special case that corresponds to the pair of domain losses (Ld, \u2212 Expect-Ld) Affect-Affect-Affect-Affect-Affect-Lid-Affect-Lid-Lid-Lid Quer Quer Quer-Quer Quer Quer-Quer Quer Quer-Quer Quer Quer Quer-Quer Quer Quer Quer-Quer Quer-Quer Quer Quer-Quer Quer-Quer Quer-Quer-Quer Quer-Lid."}], "references": [{"title": "Neural codes for image retrieval", "author": ["A. Babenko", "A. Slesarev", "A. Chigorin", "V.S. Lempitsky"], "venue": "ECCV, pp. 584\u2013599", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised domain adaptation by domain invariant projection", "author": ["M. Baktashmotlagh", "M.T. Harandi", "B.C. Lovell", "M. Salzmann"], "venue": "ICCV, pp. 769\u2013776", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Integrating structured biological data by kernel maximum mean discrepancy", "author": ["K.M. Borgwardt", "A. Gretton", "M.J. Rasch", "H. Kriegel", "B. Sch\u00f6lkopf", "A.J. Smola"], "venue": "ISMB, pp. 49\u201357", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2006}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["R.-E. Fan", "K.-W. Chang", "C.-J. Hsieh", "X.-R. Wang", "C.-J. Lin"], "venue": "Journal of Machine Learning Research, 9:1871\u20131874", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Unsupervised visual domain adaptation using subspace alignment", "author": ["B. Fernando", "A. Habrard", "M. Sebban", "T. Tuytelaars"], "venue": "ICCV", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "ICML, pp. 513\u2013520", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Connecting the dots with landmarks: Discriminatively learning domaininvariant features for unsupervised domain adaptation", "author": ["B. Gong", "K. Grauman", "F. Sha"], "venue": "ICML, pp. 222\u2013230", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2013}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "CVPR, pp. 2066\u20132073", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Generative adversarial networks", "author": ["I.J. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A.C. Courville", "Y. Bengio"], "venue": "CoRR, abs/1406.2661", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "ICCV, pp. 999\u20131006", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Correcting sample selection bias by unlabeled data", "author": ["J. Huang", "A.J. Smola", "A. Gretton", "K.M. Borgwardt", "B. Sch\u00f6lkopf"], "venue": "NIPS, pp. 601\u2013608", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2006}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1998}, {"title": "Multi-view object class detection with a 3d geometric model", "author": ["J. Liebelt", "C. Schmid"], "venue": "CVPR", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2010}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Y. Netzer", "T. Wang", "A. Coates", "A. Bissacco", "B. Wu", "A.Y. Ng"], "venue": "NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": "CVPR", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Domain adaptation via transfer component analysis", "author": ["S.J. Pan", "I.W. Tsang", "J.T. Kwok", "Q. Yang"], "venue": "IEEE Transactions on Neural Networks, 22(2):199\u2013 210", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Dlid: Deep learning for domain adaptation by interpolating between domains", "author": ["S.B.S. Chopra", "R. Gopalan"], "venue": "ICML Workshop on Challenges in Representation Learning", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2013}, {"title": "Improving predictive inference under covariate shift by weighting the log-likelihood function", "author": ["H. Shimodaira"], "venue": "Journal of Statistical Planning and Inference, 90(2):227\u2013244", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2000}, {"title": "Improving neural networks with dropout", "author": ["N. Srivastava"], "venue": "PhD thesis, University of Toronto", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2013}, {"title": "Back to the future: Learning shape models from 3d CAD data", "author": ["M. Stark", "M. Goesele", "B. Schiele"], "venue": "BMVC, pp. 1\u201311", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "From virtual to reality: Fast adaptation of virtual object detectors to real domains", "author": ["B. Sun", "K. Saenko"], "venue": "BMVC", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "J", "author": ["D. V\u00e1zquez", "A.M. L\u00f3pez"], "venue": "Mar\u0131\u0301n, D. Ponsa, and D. G. Gomez. Virtual and real world adaptationfor pedestrian detection. IEEE Trans. Pattern Anal. Mach. Intell., 36(4):797\u2013809", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "CoRR, abs/1311.2901", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 12, "context": "One particularly important example is synthetic or semi-synthetic imagery, which may come in abundance and fully labeled, but which inevitably look different from real data [13, 20, 23, 21].", "startOffset": 173, "endOffset": 189}, {"referenceID": 19, "context": "One particularly important example is synthetic or semi-synthetic imagery, which may come in abundance and fully labeled, but which inevitably look different from real data [13, 20, 23, 21].", "startOffset": 173, "endOffset": 189}, {"referenceID": 21, "context": "One particularly important example is synthetic or semi-synthetic imagery, which may come in abundance and fully labeled, but which inevitably look different from real data [13, 20, 23, 21].", "startOffset": 173, "endOffset": 189}, {"referenceID": 20, "context": "One particularly important example is synthetic or semi-synthetic imagery, which may come in abundance and fully labeled, but which inevitably look different from real data [13, 20, 23, 21].", "startOffset": 173, "endOffset": 189}, {"referenceID": 11, "context": "Below, we detail the proposed approach to domain adaptation in deep architectures, and present prelimenary results on traditional deep learning datasets (such as MNIST [12] and SVHN [14]) that clearly demonstrate the unsupervised domain adaptation ability of the proposed method.", "startOffset": 168, "endOffset": 172}, {"referenceID": 13, "context": "Below, we detail the proposed approach to domain adaptation in deep architectures, and present prelimenary results on traditional deep learning datasets (such as MNIST [12] and SVHN [14]) that clearly demonstrate the unsupervised domain adaptation ability of the proposed method.", "startOffset": 182, "endOffset": 186}, {"referenceID": 2, "context": "Some approaches perform this by reweighing or selecting samples from the source domain [3, 11, 7], while others seek an explicit feature space transformation that would map source distribution into the target ones [16, 10, 2].", "startOffset": 87, "endOffset": 97}, {"referenceID": 10, "context": "Some approaches perform this by reweighing or selecting samples from the source domain [3, 11, 7], while others seek an explicit feature space transformation that would map source distribution into the target ones [16, 10, 2].", "startOffset": 87, "endOffset": 97}, {"referenceID": 6, "context": "Some approaches perform this by reweighing or selecting samples from the source domain [3, 11, 7], while others seek an explicit feature space transformation that would map source distribution into the target ones [16, 10, 2].", "startOffset": 87, "endOffset": 97}, {"referenceID": 15, "context": "Some approaches perform this by reweighing or selecting samples from the source domain [3, 11, 7], while others seek an explicit feature space transformation that would map source distribution into the target ones [16, 10, 2].", "startOffset": 214, "endOffset": 225}, {"referenceID": 9, "context": "Some approaches perform this by reweighing or selecting samples from the source domain [3, 11, 7], while others seek an explicit feature space transformation that would map source distribution into the target ones [16, 10, 2].", "startOffset": 214, "endOffset": 225}, {"referenceID": 1, "context": "Some approaches perform this by reweighing or selecting samples from the source domain [3, 11, 7], while others seek an explicit feature space transformation that would map source distribution into the target ones [16, 10, 2].", "startOffset": 214, "endOffset": 225}, {"referenceID": 2, "context": "Here, one popular choice is matching the distribution means in the kernel-reproducing Hilbert space [3, 11], whereas [8, 5] map the principal axes associated with each of the distributions.", "startOffset": 100, "endOffset": 107}, {"referenceID": 10, "context": "Here, one popular choice is matching the distribution means in the kernel-reproducing Hilbert space [3, 11], whereas [8, 5] map the principal axes associated with each of the distributions.", "startOffset": 100, "endOffset": 107}, {"referenceID": 7, "context": "Here, one popular choice is matching the distribution means in the kernel-reproducing Hilbert space [3, 11], whereas [8, 5] map the principal axes associated with each of the distributions.", "startOffset": 117, "endOffset": 123}, {"referenceID": 4, "context": "Here, one popular choice is matching the distribution means in the kernel-reproducing Hilbert space [3, 11], whereas [8, 5] map the principal axes associated with each of the distributions.", "startOffset": 117, "endOffset": 123}, {"referenceID": 9, "context": "Several approaches perform gradual transition from the source to the target domain [10, 8] by a gradual change of the training distribution.", "startOffset": 83, "endOffset": 90}, {"referenceID": 7, "context": "Several approaches perform gradual transition from the source to the target domain [10, 8] by a gradual change of the training distribution.", "startOffset": 83, "endOffset": 90}, {"referenceID": 16, "context": "Among these methods, [17] does this in a \u201cdeep\u201d way by the layerwise training of a sequence of deep autoencoders, while gradually replacing source-domain samples with target-domain samples.", "startOffset": 21, "endOffset": 25}, {"referenceID": 5, "context": "This improves over a similar approach of [6] that simply trains a single deep autoencoder for both domains.", "startOffset": 41, "endOffset": 44}, {"referenceID": 5, "context": "In contrast to [6, 17], our approach performs feature learning, domain adaptation and classifier learning jointly, in a unified architecture, and using a single learning algorithm (backpropagation).", "startOffset": 15, "endOffset": 22}, {"referenceID": 16, "context": "In contrast to [6, 17], our approach performs feature learning, domain adaptation and classifier learning jointly, in a unified architecture, and using a single learning algorithm (backpropagation).", "startOffset": 15, "endOffset": 22}, {"referenceID": 22, "context": "In the context of deep feed-forward architectures, such data can be used to \u201cfine-tune\u201d the network trained on the source domain [24, 15, 1].", "startOffset": 129, "endOffset": 140}, {"referenceID": 14, "context": "In the context of deep feed-forward architectures, such data can be used to \u201cfine-tune\u201d the network trained on the source domain [24, 15, 1].", "startOffset": 129, "endOffset": 140}, {"referenceID": 0, "context": "In the context of deep feed-forward architectures, such data can be used to \u201cfine-tune\u201d the network trained on the source domain [24, 15, 1].", "startOffset": 129, "endOffset": 140}, {"referenceID": 8, "context": "The work that is most related to ours is the recent (and concurrent) technical report [9] on adversarial networks.", "startOffset": 86, "endOffset": 89}, {"referenceID": 17, "context": "Under the covariate shift assumption, this would make the label prediction accuracy on the target domain to be the same as on the source domain [18].", "startOffset": 144, "endOffset": 148}, {"referenceID": 8, "context": "The simple learning procedure outlined above can be rederived/generalized along the lines suggested in [9] (see Appendix).", "startOffset": 103, "endOffset": 106}, {"referenceID": 4, "context": "SA [5] .", "startOffset": 3, "endOffset": 6}, {"referenceID": 4, "context": "For each of the two DA methods (ours and [5]) we show how much of the gap between the lower and the upper bounds was covered (in brackets).", "startOffset": 41, "endOffset": 44}, {"referenceID": 4, "context": "For all five cases, our approach outperforms [5] considerably, and covers a big portion of the gap.", "startOffset": 45, "endOffset": 48}, {"referenceID": 11, "context": "The first four datasets are the well-known MNIST dataset [12] and its modifications.", "startOffset": 57, "endOffset": 61}, {"referenceID": 13, "context": "The last two datasets is the well-known Street View House Number (SVHN) dataset [14] and a new synthetic dataset Syn.", "startOffset": 80, "endOffset": 84}, {"referenceID": 4, "context": "In addition, we compare our approach against the recently proposed unsupervised DA method based on subspace alignment (SA) [5].", "startOffset": 123, "endOffset": 126}, {"referenceID": 11, "context": "The chosen architectures are fairly standard for these datasets in terms of feature extractor and label predictor parts: the \u201cMNIST\u201d design is inspired by the classical LeNet-5 [12], while the second CNN is adopted from [19].", "startOffset": 177, "endOffset": 181}, {"referenceID": 18, "context": "The chosen architectures are fairly standard for these datasets in terms of feature extractor and label predictor parts: the \u201cMNIST\u201d design is inspired by the classical LeNet-5 [12], while the second CNN is adopted from [19].", "startOffset": 220, "endOffset": 224}, {"referenceID": 18, "context": "Following [19] we also use dropout and `2-norm restriction when we train the SVHN architecture.", "startOffset": 10, "endOffset": 14}, {"referenceID": 4, "context": "For the SA baseline, we consider the activations of the last hidden layer in the label predictor (before the final linear classifier) as descriptors/features, and learn the mapping between the source and the target domains [5].", "startOffset": 223, "endOffset": 226}, {"referenceID": 3, "context": "Since the SA baseline requires to train a new classifier after adapting the features, and in order to put all the compared methods on an equal footing, we retrain the last layer of the label predictor using a standard linear SVM [4] for all four compared methods (including ours; the performance on the target domain remains approximately the same after the retraining).", "startOffset": 229, "endOffset": 232}, {"referenceID": 4, "context": "The performance of the unsupervised DA method [5] for all three datasets is much more modest, thus highlighting the difficulty of the adaptation task.", "startOffset": 46, "endOffset": 49}, {"referenceID": 4, "context": "In contrast, [5] does not result in any significant improvement in the classification accuracy, thus highlighting that the adaptation task is even more challenging than in the case of MNIST experiments.", "startOffset": 13, "endOffset": 16}, {"referenceID": 5, "context": "For this, a natural choice would be to use deep autoencoder/deconvolution network trained on both domains (or on the target domain) in a similar vein to [6, 17], effectively using [6, 17] as an initialization to our method.", "startOffset": 153, "endOffset": 160}, {"referenceID": 16, "context": "For this, a natural choice would be to use deep autoencoder/deconvolution network trained on both domains (or on the target domain) in a similar vein to [6, 17], effectively using [6, 17] as an initialization to our method.", "startOffset": 153, "endOffset": 160}, {"referenceID": 5, "context": "For this, a natural choice would be to use deep autoencoder/deconvolution network trained on both domains (or on the target domain) in a similar vein to [6, 17], effectively using [6, 17] as an initialization to our method.", "startOffset": 180, "endOffset": 187}, {"referenceID": 16, "context": "For this, a natural choice would be to use deep autoencoder/deconvolution network trained on both domains (or on the target domain) in a similar vein to [6, 17], effectively using [6, 17] as an initialization to our method.", "startOffset": 180, "endOffset": 187}], "year": 2014, "abstractText": "Top-performing deep architectures are trained on massive amounts of labeled data. In the absence of labeled data for a certain task, domain adaptation often provides an attractive option given that labeled data of similar nature but from a different domain (e.g. synthetic images) are available. Here, we propose a new approach to domain adaptation in deep architectures that can be trained on large amount of labeled data from the source domain and large amount of unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of \u201cdeep\u201d features that are (i) discriminative for the main learning task on the source domain and (ii) invariant with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a simple new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation. Overall the whole approach can be implemented with little effort using any of the deep-learning packages.", "creator": "LaTeX with hyperref package"}}}