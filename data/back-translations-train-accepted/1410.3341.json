{"id": "1410.3341", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Oct-2014", "title": "Generalization Analysis for Game-Theoretic Machine Learning", "abstract": "For Internet applications like sponsored search, cautions need to be taken when using machine learning to optimize their mechanisms (e.g., auction) since self-interested agents in these applications may change their behaviors (and thus the data distribution) in response to the mechanisms. To tackle this problem, a framework called game-theoretic machine learning (GTML) was recently proposed, which first learns a Markov behavior model to characterize agents' behaviors, and then learns the optimal mechanism by simulating agents' behavior changes in response to the mechanism. While GTML has demonstrated practical success, its generalization analysis is challenging because the behavior data are non-i.i.d. and dependent on the mechanism. To address this challenge, first, we decompose the generalization error for GTML into the behavior learning error and the mechanism learning error; second, for the behavior learning error, we obtain novel non-asymptotic error bounds for both parametric and non-parametric behavior learning methods; third, for the mechanism learning error, we derive a uniform convergence bound based on a new concept called nested covering number of the mechanism space and the generalization analysis techniques developed for mixing sequences. To the best of our knowledge, this is the first work on the generalization analysis of GTML, and we believe it has general implications to the theoretical analysis of other complicated machine learning problems.", "histories": [["v1", "Thu, 9 Oct 2014 03:51:19 GMT  (23kb)", "http://arxiv.org/abs/1410.3341v1", null]], "reviews": [], "SUBJECTS": "cs.LG cs.GT", "authors": ["haifang li", "fei tian", "wei chen", "tao qin", "zhiming ma", "tie-yan liu"], "accepted": true, "id": "1410.3341"}, "pdf": {"name": "1410.3341.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 141 0.33 41v1 [cs.LG] 9 Oct 201 4"}, {"heading": "1 Introduction", "text": "In fact, most people who are able to survive themselves are able to survive themselves by going in search of themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "2 GTML Framework", "text": "In this section we briefly introduce the Game Theory Framework for Machine Learning (GTML) and summarize the related notations in Table 1."}, {"heading": "2.1 Mechanisms in Internet Applications", "text": "Internet applications such as sponsored search and crowdsourcing can be viewed as dynamic systems that include interactions between multiple parties, such as users, agents and platforms. In sponsored search, for example, the search engine (platform) ranks and displays ads to users and charges advertisers (agents) when their ads are clicked by users, based on the relevance of the ads and the offer prices reported by advertisers. Similar multi-party relationships can also be found in crowdsourcing, where the platform corresponds with mechanisms that correspond to employers. While we can assume that the behavior of users is generally not the behavior of agents, this is because agents generally have clear usage mechanisms in mind, and they can change their behavior to maximize their usefulness, as the understandings are based on the mechanism that the platform uses."}, {"heading": "2.2 Markov Agent Behavior Model", "text": "To describe how agents change their behaviour, the authors of (He et al. 2013) and (Tian et al. 2014) have proposed a Markov behavioural model. To facilitate the discussion and without losing too much generality, the main assumption of the Markov model is that each actor has limited memory and his behaviour change depends only on his previous behaviour and his signals over a limited number of time periods. Formally, the distribution of the next behavioural profile of the agent in the light of the signal ht can be described as follows: P (bat + 1 | b a t,..., b a 1; ut,..., u1) = P (bat + 1 | b... h1) = P (bat + 1 | b a t, ht): = Mht (b a t, b a t + 1), where Mh is the transitional probability matrix of the behavioural profile."}, {"heading": "2.3 Bi-Level Empirical Risk Minimization", "text": "In (He et al. 2014) both parametric and non-parametric approaches to the behaviour were adopted."}, {"heading": "3 Generalization Analysis for GTML", "text": "In this section, we first give a formal definition of the generalization error of the two-step ERM algorithm for GTML, and then discuss how we can derive a reasonable upper limit for this generalization error. \u2212 Finally, we apply our generalization analysis of GTML to the sponsored search and show that GTML has good generalization capabilities in this scenario. \u2212 According to (Tian et al. 2014), the process (bat, ut) for a generalization model M (such as the true Markov behavioral model M * and the model M * T1 obtained by the behavioral algorithm) is irreducible and aperiotic under some mild conditions. \u2212 The process (bat, ut) is a universally ergodic Markov model for arbitrary mechanisms. \u2212 Then there is a mechanism and a behavioral model M, there is a stationary distribution for (bat, ut), which we call a stationary distribution model."}, {"heading": "3.1 Error Bound for Behavior Learning", "text": "In this subsection, we derive error limits for both parametric and non-parametric behaviors to measure the behavior of certain behaviors. As the behavioral space and signal space are both finite, it is shown in (Tian et al. 2014) that the elements in the N0 step transition probability matrix of [bt] 1, bt} are all positive. To illustrate this, we point to the minimal element in this matrix as 0. Since the mechanism a0 is fixed in the process of behavioral learning, we omit all superscripts a0 in b a0 t unless we are confused. Please note that in (Tian et al. 2014), although authors examined the generalization analysis of behavioral learning errors, their definition cannot be applied in the analysis of GTL, the behavior with which we learn."}, {"heading": "3.2 Error Bound for Mechanism Learning", "text": "In this section, we tie the mechanism learning error by using a new concept called the nested coverage number for the mechanical space. (We first give its definition and then prove a uniform convergence for the mechanical space induced by the mechanisms.) The two-layer coverage contains two coverage layers: the coverage of the first layer is defined for the entire mechanical space, based on the distance between the mechanisms projected onto the finite common data. (First, we construct the coverage of the first layer for the mechanical space.) In mechanical learning, the learned Markov behavioral model M is used to generate the behavioral data for various mechanisms. For simplification, we refer to the stationary distribution of the generated data (a, M, T1) (or the set of stationary distributions for A)."}, {"heading": "3.3 The Total Error Bound", "text": "By combining theorem 3.1, theorem 3.3, theorem 3.2 and theorem 3.5, we obtain the total error limit for GTML, as shown in the following theorem. Theorem 3.6. Using the same assumptions in theorem 3.5, for the two-stage ERM algorithm in GTML, we have for all cases > 0 the following generalization errors bound 3: P (R (a, T2, M) \u2212 R (a, M).) \u2264 O (e \u2212 T1) + O (NdA (B, A) (N1 (B, L, A, T2) e \u2212 Ts 1 + s 2 + T s \u2212 1 + s2)), where s (0, \u03b3) and \u03b4 (0, E / K\u03b1). 3Please refer to theorem C.3 for the total error limit without the assumption of the mixing rate. From the above theorem we have the following observations."}, {"heading": "3.4 Application to Sponsored Search Auctions", "text": "In this section, we apply our GTML generalization analysis to sponsored search auctions. > In Sponsored Search, q = q auctions with a query-dependent reserve price are generally used (Edelman, Ostrovsky and Schwarz 2005; Easley and Kleinberg 2010; Medina and Mohri 2014).When a reserve price r (R +) is used, the GSP auction proceeds in the following manner. (First, the search engine ranks the ads according to their bid prices (here we follow common practice of including the click rate of an ad in its reserve price to facilitate notations), and shows users those ads whose bid prices are higher than the reserve price. If the ad is clicked on the i-th position (referred to as adi), the search engine charges the corresponding advertiser by the maximum of the bid price adi + 1 and the reserve price r."}, {"heading": "4 Conclusion and Future Work", "text": "In this paper, we have presented a formal generalization analysis on game theory machine learning (GTML), which includes a two-step ERM learning process (i.e. mechanism of learning and behavior).The challenges of generalization analysis for GTML lie in the dependence between the behavioral data and the mechanism.To address the challenge, we first tied the error of behavioral learning by using the Hoeffding inequality for Markov chains, and then introduced a new conception, called a nested coverage number, which limits the errors of mechanical learning based on it. Our theoretical analysis not only enriches our understanding of machine learning in complicated dynamic systems with multi-party interactions, but also provides practical algorithmic guidance for mechanism design for these systems. As for future work, we also want to expand the idea of sample sharing and apply it to improve mechanisms in other real-world applications, such as mobile apps and social networks."}], "references": [{"title": "P", "author": ["M. Anthony", "Bartlett"], "venue": "L.", "citeRegEx": "Anthony and Bartlett 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "and Kleinberg", "author": ["D. Easley"], "venue": "J.", "citeRegEx": "Easley and Kleinberg 2010", "shortCiteRegEx": null, "year": 2010}, {"title": "Internet advertising and the generalized second price auction: Selling billions of dollars worth of keywords", "author": ["Ostrovsky Edelman", "B. Schwarz 2005] Edelman", "M. Ostrovsky", "M. Schwarz"], "venue": null, "citeRegEx": "Edelman et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Edelman et al\\.", "year": 2005}, {"title": "and Ormoneit", "author": ["P.W. Glynn"], "venue": "D.", "citeRegEx": "Glynn and Ormoneit 2002", "shortCiteRegEx": null, "year": 2002}, {"title": "A game-theoretic machine learning approach for revenue maximization in sponsored search", "author": ["He"], "venue": "In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence", "citeRegEx": "He,? \\Q2013\\E", "shortCiteRegEx": "He", "year": 2013}, {"title": "A game-theoretic machine learning approach for revenue maximization in sponsored search. CoRR abs/1406.0728", "author": ["He"], "venue": null, "citeRegEx": "He,? \\Q2014\\E", "shortCiteRegEx": "He", "year": 2014}, {"title": "D", "author": ["S. Lahaie", "Pennock"], "venue": "M.", "citeRegEx": "Lahaie and Pennock 2007", "shortCiteRegEx": null, "year": 2007}, {"title": "and Mohri", "author": ["A.M. Medina"], "venue": "M.", "citeRegEx": "Medina and Mohri 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "A", "author": ["Mitrophanov"], "venue": "Y.", "citeRegEx": "Mitrophanov 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "Optimizing relevance and revenue in ad search: a query substitution approach", "author": ["Radlinski"], "venue": "In Proceedings of the 31st annual international ACM SIGIR conference on Research and development", "citeRegEx": "Radlinski,? \\Q2008\\E", "shortCiteRegEx": "Radlinski", "year": 2008}, {"title": "Agent behavior prediction and its generalization analysis", "author": ["Tian"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence", "citeRegEx": "Tian,? \\Q2014\\E", "shortCiteRegEx": "Tian", "year": 2014}, {"title": "Rates of convergence for empirical processes of stationary mixing sequences. The Annals of Probability 94\u2013116", "author": ["B. Yu"], "venue": null, "citeRegEx": "Yu,? \\Q1994\\E", "shortCiteRegEx": "Yu", "year": 1994}, {"title": "Revenue optimization with relevance constraint in sponsored search", "author": ["Zhu"], "venue": "In Proceedings of the Third International Workshop on Data Mining and Audience Intelligence for Advertising,", "citeRegEx": "Zhu,? \\Q2009\\E", "shortCiteRegEx": "Zhu", "year": 2009}, {"title": "Optimizing search engine revenue in sponsored search", "author": ["Zhu"], "venue": "In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Zhu,? \\Q2009\\E", "shortCiteRegEx": "Zhu", "year": 2009}], "referenceMentions": [], "year": 2014, "abstractText": "For Internet applications like sponsored search, cautions need to be taken when using machine learning to optimize their mechanisms (e.g., auction) since selfinterested agents in these applications may change their behaviors (and thus the data distribution) in response to the mechanisms. To tackle this problem, a framework called game-theoretic machine learning (GTML) was recently proposed, which first learns a Markov behavior model to characterize agents behaviors, and then learns the optimal mechanism by simulating agents\u2019 behavior changes in response to the mechanism. While GTML has demonstrated practical success, its generalization analysis is challenging because the behavior data are non-i.i.d. and dependent on the mechanism. To address this challenge, first, we decompose the generalization error for GTML into the behavior learning error and the mechanism learning error; second, for the behavior learning error, we obtain novel non-asymptotic error bounds for both parametric and non-parametric behavior learning methods; third, for the mechanism learning error, we derive a uniform convergence bound based on a new concept called nested covering number of the mechanism space and the generalization analysis techniques developed for mixing sequences. To the best of our knowledge, this is the first work on the generalization analysis of GTML, and we believe it has general implications to the theoretical analysis of other complicated machine learning problems.", "creator": "LaTeX with hyperref package"}}}