{"id": "1410.5518", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Oct-2014", "title": "On Symmetric and Asymmetric LSHs for Inner Product Search", "abstract": "In a recent manuscript (\"Asymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS)\", available on arXiv and to be presented in the upcoming NIPS), Shrivastava and Li argue that there is no symmetric LSH for the problem of Maximum Inner Product Search and propose an asymmetric LSH based on different mappings for query and database points. We show a simple LSH for the problem, using a simple symmetric mapping, with better performance, both theoretically and empirically.", "histories": [["v1", "Tue, 21 Oct 2014 02:00:34 GMT  (129kb)", "http://arxiv.org/abs/1410.5518v1", "9 pages"], ["v2", "Fri, 24 Oct 2014 21:31:06 GMT  (161kb)", "http://arxiv.org/abs/1410.5518v2", "14 pages"], ["v3", "Mon, 8 Jun 2015 19:30:35 GMT  (169kb)", "http://arxiv.org/abs/1410.5518v3", "11 pages, 3 figures, In Proceedings of The 32nd International Conference on Machine Learning (ICML)"]], "COMMENTS": "9 pages", "reviews": [], "SUBJECTS": "stat.ML cs.DS cs.IR cs.LG", "authors": ["behnam neyshabur", "nathan srebro"], "accepted": true, "id": "1410.5518"}, "pdf": {"name": "1410.5518.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Behnam Neyshabur"], "emails": ["bneyshabur@ttic.edu", "nati@ttic.edu"], "sections": [{"heading": null, "text": "ar Xiv: 141 0.55 18v1 [st at.M L] 21 Oct 201 4"}, {"heading": "1 Introduction", "text": "Locality Sensitive Hashing [6] is a popular tool for approximate searching for the closest neighbors and is also widely used in various settings [1, 3, 4]. LSH is based on a random mapping of objects to a small, possibly binary alphabet, which in turn can be used to generate short hash words so that the distances between hash words correspond to similarities between objects. Recent studies have also examined the power of asymmetry in LSH and binary hashing, where two different mappings are used to approximate similarities [7, 8]. Shrivastava and Li [9] consider the problem of Maximum Inner Product Search (MIPS), where similarity between vectors is given by the unnormalized inner product between them. They show that there is no symmetrical LSH for this similarity measurement, LSH for this equality, LSH for the equality, LSH for the equality, LSH for the equality, LH for the equality, SH for the equality, and SH for the equality of the two, and SH for the equality."}, {"heading": "2 Problem Formulation and Background", "text": "It is a \"database\" of vectors that we would like to find without modifying the argmax.We would like a good \"site sensitive hash\" for MIPS."}, {"heading": "3 Symmetric LSH for MIPS", "text": "The assertion that there is no hash that meets the definition 1 for a symmetrical LSH for internal product similarity over X = Rd is indeed true. However, since the queries are normalized and the database objects could be limited and scaled without loss of generality, we are only interested in how the hash applies to x-X = [x-x-x] x-2 \u2264 1} and q-Y = [q | q-2 = 1}. In fact, the main result that Shrivastava and Li determine the existence of an ALSH is applicable only to this pair of database and query spaces - mips-alsh is not an ALSH over the entire Rd space (i.e. if queries are unnormalized and the database is unlimited)."}, {"heading": "3.1 The Standard LSH", "text": "We first point out that after scaling the database by a sufficiently small U, no further asymmetric q-mapping is required, and the standard L2 hash given by (2) is already an LSH for internal product similarity: Theorem 1. For each 0 < S < 1, 0 < c < 1 and U \u2264 2S (1 \u2212 c), there is p1 > p2 so that the hash is hL2a, b under (2) SU one (S0, cS0, p1, p2) -LSH for internal product similarity above X = {x | x \u00b2 2 \u2264 U} and Y = {q \u2212 q \u00b2 2 = 1} (under definitions 2), where S0 = US.The hash proposed here is exactly mips-alsh, but with m = 0, i.e. without the asymmetric P (\u00b7), Q (\u00b7) of (1).cashing."}, {"heading": "3.2 SIMPLE-LSH", "text": "Although we argue in the previous section that even the standard Euclidean LSH is a q for internal product similarity, its hash parameter may be quite large for many thresholds S (see section 4). Furthermore, ensuring the standard Euclidean LSH requires a q q character to scale by a sufficiently small U, and the resulting hash depends on two parameters, namely U and r. Instead, we propose a simpler, parameter-free, fully symmetrical LSH that does not require special pre-scaling and which we call simply-lsh. For x-ha hash parameters Rd, x-ha-2 \u2264 1, we define P (x): x-cos Rd + 1 as follows: P (x) = [x; x-cos x-x-x-22] (6) Clearly, with this definition for x-x-ha, we have such a product (x-ha)."}, {"heading": "4 Theoretical Comparison", "text": "Previously we discussed that an LSH with the smallest possible hashing ratio \u03c1 is desirable. However, for mips-alsh, for each desired threshold S and ratio c can be optimized using the three parameters m, U and r to find the hash with the best \u03c1. However, this optimal guarantee is provided by [9] 3: \u043c mips-alsh (S, c) = min U, r, mlogFr (\u221a 1 + m / 4 \u2212 2SU + U2m + 1) logFr (\u221a 1 + 4 \u2212 2cSU + (cSU) 2m + 1) (9) s.t. U2 m \u2264 2S (1 \u2212 c) m \u2265 1, 0 < r, 0 < U. This is a non-convex optimization problem, and Shrivastava and Li [9] solve it by a grid search using U, r and m ltv.U."}, {"heading": "5 Empirical Evaluation", "text": "We followed the exact same protocol as Shrivastava and Li [9] by comparing mips-alsh with simple-lsh and L2-lsh to two collaborative filter datasets, Netflix and Movielens 10M. For a given user item matrix Z, we followed the pureSVD method proposed in [2]: We first subtracted the average total rating of each individual rating and created the matrix Z with these average subtracted ratings for observed entries and zeros for unobserved entries. We then take a rank-f approximation (top f singular components, f = 150 for Movielens and f = 300 for Netflix) Z \u2248 WATR = Y and define L = W\u0442 so that Y = LR. We can imagine each set of L as a vector presentation of a user and each set of R as a presentation for an item."}, {"heading": "6 Conclusion", "text": "Contrary to what is proposed in [9], we showed that an inherently symmetrical LSH can be used for MIPS. Our proposed Simple Lsh is arguably simpler, symmetrical, parameter-free, uses only a binary alphabet and performs better theoretically and empirically than Mips-Alsh."}], "references": [{"title": "Similarity estimation techniques from rounding algorithms", "author": ["M.S. Charikar"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "Performance of recommender algorithms on top-n recommendation tasks", "author": ["P. Cremonesi", "Y. Koren", "R. Turrin"], "venue": "In Proceedings of the fourth ACM conference on Recommender systems, ACM p", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Locality-sensitive hashing scheme based on p-stable distributions", "author": ["M. Datar", "N. Immorlica", "P. Indyk", "S.V. Mirrokni"], "venue": "In Proc. 20th SoCG pp", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2004}, {"title": "Similarity search in high dimensions via hashing", "author": ["A. Gionis", "P. Indyk", "R. Motwani"], "venue": "VLDB 99,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1999}, {"title": "Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming", "author": ["M.X. Goemans", "D.P. Williamson"], "venue": "Journal of the ACM (JACM) 42.6,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1995}, {"title": "Approximate nearest neighbors: towards removing the curse of dimensionality", "author": ["P. Indyk", "R. Motwani"], "venue": "STOC pp", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "Clustering, hamming embedding, generalized lsh and the max norm", "author": ["B. Neyshabur", "Y. Makarychev", "N. Srebro"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "The power of asymmetry in binary hashing", "author": ["B. Neyshabur", "P. Yadollahpour", "Y. Makarychev", "R. Salakhutdinov", "N. Srebro"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Asymmetric lsh (alsh) for sublinear time maximum inner product search (mips)", "author": ["A. Shrivastava", "P. Li"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}], "referenceMentions": [{"referenceID": 5, "context": "1 Introduction Locality Sensitive Hashing [6] is a popular tool for approximate nearest neighbor search and is also widely used in different settings [1, 3, 4].", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "1 Introduction Locality Sensitive Hashing [6] is a popular tool for approximate nearest neighbor search and is also widely used in different settings [1, 3, 4].", "startOffset": 150, "endOffset": 159}, {"referenceID": 2, "context": "1 Introduction Locality Sensitive Hashing [6] is a popular tool for approximate nearest neighbor search and is also widely used in different settings [1, 3, 4].", "startOffset": 150, "endOffset": 159}, {"referenceID": 3, "context": "1 Introduction Locality Sensitive Hashing [6] is a popular tool for approximate nearest neighbor search and is also widely used in different settings [1, 3, 4].", "startOffset": 150, "endOffset": 159}, {"referenceID": 6, "context": "Recent studies have also explored the power of asymmetry in LSH and binary hashing, where two different mappings are used to approximate similarity [7, 8].", "startOffset": 148, "endOffset": 154}, {"referenceID": 7, "context": "Recent studies have also explored the power of asymmetry in LSH and binary hashing, where two different mappings are used to approximate similarity [7, 8].", "startOffset": 148, "endOffset": 154}, {"referenceID": 8, "context": "Shrivastava and Li [9] consider the problem of Maximum Inner Product Search (MIPS) where similarity between vectors is given by the unnormalized inner product between them.", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "2 Problem Formulation and Background In Maximum Inner Product Search (MIPS), we are given a \u201cdatabase\u201d of vectors S \u2282 R and a query point q \u2208 R and the goal is to find a point p \u2208 S that maximizes the inner product q\u22a4p: p = argmax x\u2208S q\u22a4x As in Shrivastava and Li [9], we assume the following without loss of generality: \u2013 The query q is normalized: Since given a vector q, the norm \u2016q\u20162 does not affect the argmax, we can assume \u2016q\u20162 = 1 always.", "startOffset": 264, "endOffset": 267}, {"referenceID": 5, "context": "; 1/2], (1) 1 This is a formalization of the definition given by Shrivastava and Li, which in turn is a modification of the definition of LSH for distance functions [6].", "startOffset": 165, "endOffset": 168}, {"referenceID": 2, "context": "We know that for any x, y \u2208 R, the collision probability of the hash h2 a,b can be written as [3]:", "startOffset": 94, "endOffset": 97}, {"referenceID": 4, "context": "For any x \u2208 X and q \u2208 Y we have [5]: P[ha(P (q)) = ha(P (x))] = 1\u2212 \u03b8(P (q), P (x)) \u03c0 = 1\u2212 cos \u22121(q\u22a4x) \u03c0 Therefore: \u2013 if q\u22a4x \u2265 S, then P [", "startOffset": 32, "endOffset": 35}, {"referenceID": 8, "context": "This optimal \u03c1 guarantee is given by [9]: \u03c1mips-alsh(S, c) = min U,r,m logFr ( \u221a 1 +m/4\u2212 2SU + U2m+1 )", "startOffset": 37, "endOffset": 40}, {"referenceID": 8, "context": "This is a non-convex optimization problem, and Shrivastava and Li [9] solve it through a grid search over U, r and m and report \u03c1mips-alsh for several choices of S and c.", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "We followed the exact same protocol as Shrivastava and Li [9] comparing mips-alsh to simple-lsh and L2-lsh on two collaborative filtering datasets, Netflix and Movielens 10M.", "startOffset": 58, "endOffset": 61}, {"referenceID": 1, "context": "For a given user-item matrix Z, we followed the pureSVD procedure suggested in [2]: we first subtracted the overall average rating from each individual rating and created the matrix Z with these average-subtracted ratings for observed entries and zeros for unobserved entries.", "startOffset": 79, "endOffset": 82}, {"referenceID": 8, "context": "5 as suggested by [9] and for L2-lsh, we fix U = 0.", "startOffset": 18, "endOffset": 21}, {"referenceID": 8, "context": "6 Conclusion Contrary to what is suggested by [9], we showed that an inherently symmetric LSH can be used for MIPS.", "startOffset": 46, "endOffset": 49}, {"referenceID": 8, "context": "5 as suggested by [9] and for L2-lsh, we fix U = 0.", "startOffset": 18, "endOffset": 21}], "year": 2017, "abstractText": "In a recent manuscript (\u201cAsymmetric LSH (ALSH) for Sublinear Time Maximum Inner Product Search (MIPS)\u201d, available on arXiv and to be presented in the upcoming NIPS), Shrivastava and Li argue that there is no symmetric LSH for the problem of Maximum Inner Product Search and propose an asymmetric LSH based on different mappings for query and database points. We show a simple LSH for the problem, using a simple symmetric mapping, with better performance, both theoretically and empirically.", "creator": "LaTeX with hyperref package"}}}