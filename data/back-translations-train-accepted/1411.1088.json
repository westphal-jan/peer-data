{"id": "1411.1088", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Nov-2014", "title": "Expectation-Maximization for Learning Determinantal Point Processes", "abstract": "A determinantal point process (DPP) is a probabilistic model of set diversity compactly parameterized by a positive semi-definite kernel matrix. To fit a DPP to a given task, we would like to learn the entries of its kernel matrix by maximizing the log-likelihood of the available data. However, log-likelihood is non-convex in the entries of the kernel matrix, and this learning problem is conjectured to be NP-hard. Thus, previous work has instead focused on more restricted convex learning settings: learning only a single weight for each row of the kernel matrix, or learning weights for a linear combination of DPPs with fixed kernel matrices. In this work we propose a novel algorithm for learning the full kernel matrix. By changing the kernel parameterization from matrix entries to eigenvalues and eigenvectors, and then lower-bounding the likelihood in the manner of expectation-maximization algorithms, we obtain an effective optimization procedure. We test our method on a real-world product recommendation task, and achieve relative gains of up to 16.5% in test log-likelihood compared to the naive approach of maximizing likelihood by projected gradient ascent on the entries of the kernel matrix.", "histories": [["v1", "Tue, 4 Nov 2014 21:23:35 GMT  (1413kb,D)", "http://arxiv.org/abs/1411.1088v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["jennifer gillenwater", "alex kulesza", "emily b fox", "benjamin taskar"], "accepted": true, "id": "1411.1088"}, "pdf": {"name": "1411.1088.pdf", "metadata": {"source": "CRF", "title": "Expectation-Maximization for Learning Determinantal Point Processes", "authors": ["Jennifer Gillenwater", "Alex Kulesza"], "emails": ["jengi@cis.upenn.edu", "kulesza@umich.edu", "ebfox@stat.washington.edu", "taskar@cs.washington.edu"], "sections": [{"heading": "1 Introduction", "text": "In this context, it should be noted that this project is a project, which is primarily a project."}, {"heading": "2 Background", "text": "Formally speaking, a DPP P on a basic set of items Y = {1,. >, N} is a probability quantity to 2Y, the set of all subsets of Y. For each Y'Y, we have P (Y) ced det (LY), where L is a positive semi-definitive (PSD) matrix. The LY \u2261 [Lij] i, j'Y subscript denotes the restriction of L to the entries indexed by elements of Y, and we have (L) \u2261 1. Note that the restriction to PSD matrices ensures that all major minors of L are not negative, so det (LY) \u2265 0 is required as for an orderly probability distribution. The normalization constant for the distribution can be calculated explicitly from the fact that Y det (LY) = self-defined (L + I), where I is the N \u00b7 N identity matrix."}, {"heading": "3 Learning algorithms", "text": "In our learning environment, the input consists of n sample subsets, {Y1,.., Yn}, with Yi {1,.., N} for all i. Our goal is to maximize the probability of these sample sets. First, in Section 3.1, we describe a naive optimization procedure: projected gradient ascent on the entries of the boundary matrix K, which will serve as the starting point for our experiments. Then, we develop an EM method: Section 3.2 modifies variables from core entries to eigenvalues and eigenvectors (introduction of a hidden variable in the process), Section 3.3 applies Jensen's inequality to the lower boundary of the object, and Sections 3.4 and 3.5 outline a coordinated ascent procedure on this lower boundary."}, {"heading": "3.1 Projected gradient ascent", "text": "The log probability maximization problem, based on Equation (3), is: max K n \u2211 i = 1 log (| det (K \u2212 IY i) |) s.t. K 0, I \u2212 K 0 (4), where the first constraint ensures that K is PSD and the second sets an upper limit of 1 on its eigenvalues. Let L (K) represent this log probability target. Its partial derivative with respect to K is easy to calculate by using a standard matrix derivative rule [22, equation 57]: \u2202 L (K) \u2202 K = n \u0445 i = 1 (K \u2212 IY i) \u2212 1. (5) Therefore, the projected gradient ascent [23] is a practicable, simple optimization technique. Algorithm 1 outlines this method, which we call K-Ascent (KA), that the initial K is supplied as input to the algorithm."}, {"heading": "3.2 Eigendecomposing", "text": "Self-decomposition is the key to many core DPP algorithms such as sampling and marginalization. This is because self-decomposition offers an alternative view of DPP as a generative process that often leads to more efficient algorithms. Specifically, the sampling of a set of Y values can be split into a two-step process, the first process involving the generation of a hidden variable J value. < N values encoding for a specific group of K eigenvectors. We review this process to develop an EM optimization schema.SupposeK = V > is a self-decomposition of K values. Let V J denote the submatrix of V values that only correspond to the indices in a set of J values."}, {"heading": "3.3 Lower bounding the objective", "text": "We now introduce an auxiliary distribution q (J | Yi) and use it with Jensen's equation q (J | J) to define the probability target. This is a standard technique for developing EM schemes for dealing with hidden variables [25]. Starting from this direction: L (V, q) = n q = 1 log (\u2211 J q (J | Yi) pK (J, Yi) q (J | Yi))). (10) The function F (q, V, K) can be expressed in one of the two following forms: F (q, V) = n q (J, Yi) q (J | Yi) q (J | Yi) q (J | Yi) q (J | Yi)))."}, {"heading": "3.4 E-step", "text": "The E-step is easy to solve by setting q (J | Yi) = pK (J | Yi), which minimizes KL divergence. Interestingly, we can show that this distribution is itself a conditional DPP and can therefore be compactly described by an N \u00b7 N kernel matrix. To complete the E-step, we simply have to construct this kernel. Lemma 1 (see Appendix A for proof) gives an explicit formula. Note that Q's probability mass is limited to sentences of a certain size k, and therefore we call it k-DPP. A k-DPP is a variant of DPP that can also be efficiently sampled and marginalized by modifications of the standard DPP algorithms. (See Appendix A and [3] for more on k-DPPs.) Lemma 1. At the end of the E-step, q (J | Yi) with Yi | k-J-Yag (Yag - YRP - YP - YP - YP) and not (YPs)."}, {"heading": "3.5 M-step", "text": "The M step update for eigenvalues is a closed form expression with no need for projection (19). Deriving the equation (13) in relation to equation (13) allows it to be set to zero, and solving the question of the value (11) is simply unnecessary. (18) The exponential sum here is impractical, but we can eliminate it by using the sum of eigenvectors of QYi (j) with the kernel QYi (J).Thus, we can use the k-DPP marginalization algorithms to efficiently calculate the sum over J. Specifically, we leave the eigenvectors of QYi (j) with the reference to the jth element of the rth eigenvector. Then we are the marginals: j (J) q."}, {"heading": "4 Experiments", "text": "We test the proposed EM learning method (algorithm 2) by comparing it to K-Asscent (KA, algorithm 1) 1. Both methods require an initial core K (5) and (20), with neither EM nor KA able to handle starting from a kernel with too many zeros. Thus, the two initialization options we are examining do not have trivial off-diagonals. The first of these options is relatively naive, while the other takes statistics from the data. For the first type of initialization, we use a wishart distribution with N degrees of freedom and an identity covariance matrix to draw L-WN (N, I). Wishart distribution is relatively inconspicuous: in terms of eigenvectors, it distributes its mass uniformly across all uniform matrices."}, {"heading": "4.1 Baby registry tests", "text": "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii"}, {"heading": "5 Conclusion", "text": "We have explored the learning of DPPs in an environment where the core K has no fixed values or a restrictive parametric form. By exploiting K's self-decomposition, we have been able to develop a novel EM learning algorithm. In a product recommendation task, we have shown that EM is faster and more robust than the naive approach of maximizing probability through projected gradients. In other applications where modelling negative interactions between items is important, we expect EM to similarly have a significant advantage."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the ONR grant N00014-10-1-0746."}, {"heading": "A Proof of Lemma 1", "text": "Before providing the proof, let us briefly point out that q = > J (J) is slightly different from the typical DPPs that we have seen so far in their conditional nature. More precisely, for a certain Yi of size k, q qualifies as k-DPP, a DPP bound to sets of size k. Formally, a k-DPP with (non-marginal) kernel L can scan and marginalize the probability for | Y | = k, and the probability zero for | Y | 6 = k. As for regular DPPs, a k-DPP can be efficiently sampled and marginalized by a (non-marginal) K-DPP, by modifying the standard DPP algorithms. For example, the normalization constant for a k-DPP is given by the identity Y: | Y | = k det (LY) YJ = e N-DPP (L), where e N-DPP (L) represents the elementary symmetric polyminomics."}, {"heading": "B M-Step eigenvalue updates", "text": "We can use the standard k-DPP marginalization formulas for efficient calculation of eigenvalue updates for Qi-Qi-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i"}, {"heading": "C M-Step eigenvector gradient", "text": "Remember that the M-step goal is: F (V) = n (J) = J (J) = J (J) = J (J) q (J) q (J) q (J) = J (J) q (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J (J) = J = J = J) = J (J) = J = J = J = J (J) = J) = J (J) = J = J (J) = J) = J (J) = J = J (J) = J) = J (J) = J = J (J) = J) = J (J) = J (J) = J = J = J (J) = J) = J (J) = J (J) = J = J (J) = J = J = J = J (J) = J = J = J (J) = J) = J (J) = J (J) = J = J = J (J) = J = J = J = J = J = J (J) = J = J = J (J) = J = J = J = J = J = J (J) = J (J) = J = J = J = J (J) = J = J = J = J (J) = J = J = J = J (J) = J) = J = J = J (J) = J = J = J (J) = J = J = J = J (J) = J = J = J = J (J) = J = J = J = J (J) = J = J = J) = J (J) = J = J (J) = J = J = J = J = J (J) = J = J = J = J = J = J = J = J (J) = J) = J = J = J = J = J = J = J = J = J (J = J = J"}, {"heading": "D Baby registry details", "text": "Figure 3a and Figure 3b contain details referred to in the main part of the essay on the baby register record and the learning methods applied to it."}], "references": [{"title": "Learning with Determinantal Point Processes", "author": ["A. Kulesza"], "venue": "PhD thesis, University of Pennsylvania,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Learning Determinantal Point Processes", "author": ["A. Kulesza", "B. Taskar"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "k-DPPs: Fixed-Size Determinantal Point Processes", "author": ["A. Kulesza", "B. Taskar"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Learning Mixtures of Submodular Shells with Application to Document Summarization", "author": ["H. Lin", "J. Bilmes"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Determinantal Point Processes for Machine Learning", "author": ["A. Kulesza", "B. Taskar"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2012}, {"title": "Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms, and Empirical Studies", "author": ["A. Krause", "A. Singh", "C. Guestrin"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2008}, {"title": "Near-Optimal Non-Myopic Value of Information in Graphical Models", "author": ["A. Krause", "C. Guestrin"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2005}, {"title": "Learning the Parameters of Determinantal Point Process Kernels", "author": ["R. Affandi", "E. Fox", "R. Adams", "B. Taskar"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Revenue Submodularity", "author": ["S. Dughmi", "T. Roughgarden", "M. Sundararajan"], "venue": "In Electronic Commerce,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "The Coincidence Approach to Stochastic Point Processes", "author": ["O. Macchi"], "venue": "Advances in Applied Probability,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1975}, {"title": "A Determinantal Point Process Latent Variable Model for Inhibition in Neural Spiking Data", "author": ["J. Snoek", "R. Zemel", "R. Adams"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Fast Determinantal Point Process Sampling with Application to Clustering", "author": ["B. Kang"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Approximate Inference in Continuous Determinantal Point Processes", "author": ["R. Affandi", "E. Fox", "B. Taskar"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Determinantal Clustering Process \u2014 A Nonparametric Bayesian Approach to Kernel Based Semi-Supervised Clustering", "author": ["A. Shah", "Z. Ghahramani"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Nystr\u00f6m Approximation for Large-Scale Determinantal Processes", "author": ["R. Affandi", "A. Kulesza", "E. Fox", "B. Taskar"], "venue": "In Conference on Artificial Intelligence and Statistics (AIStats),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Near-Optimal MAP Inference for Determinantal Point Processes", "author": ["J. Gillenwater", "A. Kulesza", "B. Taskar"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Priors for Diversity in Generative Latent Variable Models", "author": ["J. Zou", "R. Adams"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Markov Determinantal Point Processes", "author": ["R. Affandi", "A. Kulesza", "E. Fox"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Discovering Diverse and Salient Threads in Document Collections", "author": ["J. Gillenwater", "A. Kulesza", "B. Taskar"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Structured Determinantal Point Processes", "author": ["A. Kulesza", "B. Taskar"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Determinantal Processes and Independence", "author": ["J. Hough", "M. Krishnapur", "Y. Peres", "B. Vir\u00e1g"], "venue": "Probability Surveys,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "The Matrix Cookbook", "author": ["K. Petersen", "M. Pedersen"], "venue": "Technical report, University of Denmark,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}, {"title": "Constrained Minimization Methods", "author": ["E. Levitin", "B. Polyak"], "venue": "USSR Computational Mathematics and Mathematical Physics,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1966}, {"title": "Projection Methods for Conic Feasibility Problems", "author": ["D. Henrion", "J. Malick"], "venue": "Optimization Methods and Software,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "A New View of the EM Algorithm that Justies Incremental, Sparse and Other Variants", "author": ["R. Neal", "G. Hinton"], "venue": "Learning in Graphical Models,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "The Geometry of Algorithms with Orthogonality Constraints", "author": ["A. Edelman", "T. Arias", "S. Smith"], "venue": "SIAM Journal on Matrix Analysis and Applications (SIMAX),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1998}, {"title": "Distributions of Matrix Variates and Latent Roots Derived from Normal Samples", "author": ["A. James"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1964}, {"title": "An Analysis of Approximations for Maximizing Submodular Set Functions I", "author": ["G. Nemhauser", "L. Wolsey", "M. Fisher"], "venue": "Mathematical Programming,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1978}, {"title": "Computing Elementary Symmetric Functions and Their Derivatives: A Didactic", "author": ["F. Baker", "M. Harwell"], "venue": "Applied Psychological Measurement,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1996}], "referenceMentions": [{"referenceID": 0, "context": "However, log-likelihood is non-convex in the entries of the kernel matrix, and this learning problem is conjectured to be NP-hard [1].", "startOffset": 130, "endOffset": 133}, {"referenceID": 1, "context": "Thus, previous work has instead focused on more restricted convex learning settings: learning only a single weight for each row of the kernel matrix [2], or learning weights for a linear combination of DPPs with fixed kernel matrices [3].", "startOffset": 149, "endOffset": 152}, {"referenceID": 2, "context": "Thus, previous work has instead focused on more restricted convex learning settings: learning only a single weight for each row of the kernel matrix [2], or learning weights for a linear combination of DPPs with fixed kernel matrices [3].", "startOffset": 234, "endOffset": 237}, {"referenceID": 3, "context": "For example, in product recommendation we typically want to choose a small set of products from a large collection; many other examples of subset selection tasks turn up in domains like document summarization [4, 5], sensor placement [6, 7], image search [3, 8], and auction revenue maximization [9], to name a few.", "startOffset": 209, "endOffset": 215}, {"referenceID": 4, "context": "For example, in product recommendation we typically want to choose a small set of products from a large collection; many other examples of subset selection tasks turn up in domains like document summarization [4, 5], sensor placement [6, 7], image search [3, 8], and auction revenue maximization [9], to name a few.", "startOffset": 209, "endOffset": 215}, {"referenceID": 5, "context": "For example, in product recommendation we typically want to choose a small set of products from a large collection; many other examples of subset selection tasks turn up in domains like document summarization [4, 5], sensor placement [6, 7], image search [3, 8], and auction revenue maximization [9], to name a few.", "startOffset": 234, "endOffset": 240}, {"referenceID": 6, "context": "For example, in product recommendation we typically want to choose a small set of products from a large collection; many other examples of subset selection tasks turn up in domains like document summarization [4, 5], sensor placement [6, 7], image search [3, 8], and auction revenue maximization [9], to name a few.", "startOffset": 234, "endOffset": 240}, {"referenceID": 2, "context": "For example, in product recommendation we typically want to choose a small set of products from a large collection; many other examples of subset selection tasks turn up in domains like document summarization [4, 5], sensor placement [6, 7], image search [3, 8], and auction revenue maximization [9], to name a few.", "startOffset": 255, "endOffset": 261}, {"referenceID": 7, "context": "For example, in product recommendation we typically want to choose a small set of products from a large collection; many other examples of subset selection tasks turn up in domains like document summarization [4, 5], sensor placement [6, 7], image search [3, 8], and auction revenue maximization [9], to name a few.", "startOffset": 255, "endOffset": 261}, {"referenceID": 8, "context": "For example, in product recommendation we typically want to choose a small set of products from a large collection; many other examples of subset selection tasks turn up in domains like document summarization [4, 5], sensor placement [6, 7], image search [3, 8], and auction revenue maximization [9], to name a few.", "startOffset": 296, "endOffset": 299}, {"referenceID": 9, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 44, "endOffset": 48}, {"referenceID": 7, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 10, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 11, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 12, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 13, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 14, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 15, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 16, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 17, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 18, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 1, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 2, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 19, "context": "Originally discovered as models of fermions [10], DPPs have recently been effectively adapted for a variety of machine learning tasks [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2, 3, 20].", "startOffset": 134, "endOffset": 183}, {"referenceID": 20, "context": "They offer attractive computational properties, including exact and efficient normalization, marginalization, conditioning, and sampling [21].", "startOffset": 137, "endOffset": 141}, {"referenceID": 1, "context": "[2] showed that the problem of learning a scalar weight for each row of L is a convex optimization problem.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] explored a different direction, learning weights for a linear combination of DPPs with fixed Ls.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] proposed as an alternative that one first assume L takes on a particular parametric form, and then sample from the posterior distribution over kernel parameters using Bayesian methods.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "This overcomes some of the disadvantages of [3]\u2019s L-ensemble method, but does not allow for learning an unconstrained, non-parametric L.", "startOffset": 44, "endOffset": 47}, {"referenceID": 22, "context": "Thus, projected gradient ascent [23] is a viable, simple optimization technique.", "startOffset": 32, "endOffset": 36}, {"referenceID": 24, "context": "This is a standard technique for developing EM schemes for dealing with hidden variables [25].", "startOffset": 89, "endOffset": 93}, {"referenceID": 2, "context": "(See Appendix A and [3] for more on k-DPPs.", "startOffset": 20, "endOffset": 23}, {"referenceID": 26, "context": "The Wishart distribution is relatively unassuming: in terms of eigenvectors, it spreads its mass uniformly over all unitary matrices [27].", "startOffset": 133, "endOffset": 137}, {"referenceID": 2, "context": "For example, the normalization constant for a k-DPP is given by the identity \u2211 Y :|Y |=k det(LY ) = e N k (L), where e N k (L) represents the kth-order elementary symmetric polynomial on the eigenvalues of L [3].", "startOffset": 208, "endOffset": 211}, {"referenceID": 28, "context": "[29]\u2019s \u201csummation algorithm\u201d computes ek (L) in O(Nk) time.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "As previously noted, elementary symmetric polynomials can be efficiently computed using [29]\u2019s \u201csummation algorithm\u201d.", "startOffset": 88, "endOffset": 92}], "year": 2014, "abstractText": "A determinantal point process (DPP) is a probabilistic model of set diversity compactly parameterized by a positive semi-definite kernel matrix. To fit a DPP to a given task, we would like to learn the entries of its kernel matrix by maximizing the log-likelihood of the available data. However, log-likelihood is non-convex in the entries of the kernel matrix, and this learning problem is conjectured to be NP-hard [1]. Thus, previous work has instead focused on more restricted convex learning settings: learning only a single weight for each row of the kernel matrix [2], or learning weights for a linear combination of DPPs with fixed kernel matrices [3]. In this work we propose a novel algorithm for learning the full kernel matrix. By changing the kernel parameterization from matrix entries to eigenvalues and eigenvectors, and then lower-bounding the likelihood in the manner of expectation-maximization algorithms, we obtain an effective optimization procedure. We test our method on a real-world product recommendation task, and achieve relative gains of up to 16.5% in test log-likelihood compared to the naive approach of maximizing likelihood by projected gradient ascent on the entries of the kernel matrix.", "creator": "LaTeX with hyperref package"}}}