{"id": "1411.1091", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Nov-2014", "title": "Do Convnets Learn Correspondence?", "abstract": "Convolutional neural nets (convnets) trained from massive labeled datasets have substantially improved the state-of-the-art in image classification and object detection. However, visual understanding requires establishing correspondence on a finer level than object category. Given their large pooling regions and training from whole-image labels, it is not clear that convnets derive their success from an accurate correspondence model which could be used for precise localization. In this paper, we study the effectiveness of convnet activation features for tasks requiring correspondence. We present evidence that convnet features localize at a much finer scale than their receptive field sizes, that they can be used to perform intraclass alignment as well as conventional hand-engineered features, and that they outperform conventional features in keypoint prediction on objects from PASCAL VOC 2011.", "histories": [["v1", "Tue, 4 Nov 2014 21:35:55 GMT  (3564kb,D)", "http://arxiv.org/abs/1411.1091v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["jonathan long", "ning zhang", "trevor darrell"], "accepted": true, "id": "1411.1091"}, "pdf": {"name": "1411.1091.pdf", "metadata": {"source": "CRF", "title": "Do Convnets Learn Correspondence?", "authors": ["Jonathan Long", "Ning Zhang", "Trevor Darrell"], "emails": ["trevor}@cs.berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "Despite the magnitude of these results, many [5] doubted that the resulting features had the spatial specificity required for localization; after all, the entire image classification can rely on context references and excessively large pooling regions to complete the task. In rough localizations, such doubts have been alleviated by record-breaking results transferring the same characteristics to PASCAL [3]. Now, the same questions arise on a smaller scale. Are modern convectors, which are distinguished by classification and recognition, also able to find precise matches between object parts? Or do large receptive fields mean that correspondence is effectively bundled away, making this task more suitable for hand-made features? In this paper, we provide evidence that convector network functions work at least as well as conventional, even under the point-to-point correspondence regime, and we show significant improvements in certain categories, including compromises."}, {"heading": "1.1 Related work", "text": "Image Alignment Image alignment is a key step in many computer vision tasks, including face checking, motion analysis, stereo matching, and object recognition. Alignment leads to correspondence between different images by removing class variability and canonization. Alignment methods exist on a surveillance spectrum that ranges from manually labeled industrial dots or landmarks to the requirement of class labeling to require fully unattended common alignment and cluster models. Applied alignment methods are based on an entropy lens. Deep congealing [7] builds on this idea by replacing craft features with unattended features that learn from multiple resolutions. Inspired by optical flow, SIFT Flow [8] matches tightly sampled SIFT functions for correspondence and has been applied to motion prediction. In Section 3, we apply SIFT flow with deep motion prediction and transfer functions."}, {"heading": "1.2 Preliminaries", "text": "We conduct experiments with a network architecture that is almost identical to that of Krizhevsky et al. [2] and that are challenged for classification with the 1.2 million images of ILSVRC 2012. All experiments are realized with caffe, and our network is the publicly available caffe reference model. We use the activation of each layer as a feature that is on convn, pooln, or fcn for the nth convolutional, or fully connected layer. We use the receptive field to refer to the set of input pixels that are in confrontation with a particular entity."}, {"heading": "3 Intraclass alignment", "text": "If true, such characteristics should be useful for a post-hoc alignment in a similar way to conventional characteristics. To test this, we use conventional characteristics for the task of aligning different instances of the same class. We approach this difficult task in the style of the SIFT flow [8]: We retrieve nearby characteristics with a rough similarity measurement, and then compute dense correspondensity on which we impose an MRF smoothness, which eventually makes it possible to distort all images in alignment. Next FT characteristics are calculated using fc7 characteristics. As we specifically test the quality of the alignment, we use the same closest neighbors for conventional characteristics, and we compute both types of characteristics in the same places, the grid of conventional rf centers in response to a single image.Alignment is determined by solving an MRF function."}, {"heading": "4 Keypoint classification", "text": "In this section, we specifically address the ability to understand semantic information on the scale of parts."}, {"heading": "5 Keypoint prediction", "text": "We have seen that despite their large receptive field sizes, convective networks work, as does the handmade function SIFT for alignment and slightly better than SIFT for keypoint classification. Keypoint prediction provides a natural follow-up test Xi. As in Section 3, we use keypoint annotations from PASCAL VOC 2011, and we assume that the basic truth is measured at the boundary between individual objects. [3, 34, 23] However, we have not examined the use of CNNs for keypoint sub-detectors to independently predict keypoint locations. R-CNN [3] and OverFeat [34] have both demonstrated the effectiveness of deep revolutionary networks on the generic object recognition task."}, {"heading": "6 Conclusion", "text": "Through visualization, alignment, and keypoint prediction, we have examined the ability of the intermediate features implicitly learned in a state-of-the-art Convnet classifier to understand specific, local correspondence. Despite their large receiver fields and weak identification training, we have found in all cases that Convnet features are at least as useful (and sometimes much more useful) than traditional features for gathering local visual information. Recognition This work has been partially supported by DARPA's MSEE and SMISC programs, the NSF awards IIS-1427425, IIS-12798, and IIS-1116411, as well as support for Toyota.2But see the keypoint localization work cited in Section 1.1."}], "references": [{"title": "ImageNet: A Large-Scale Hierarchical Image Database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei-Fei"], "venue": "In CVPR,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "In NIPS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "In CVPR,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "The PASCAL Visual Object Classes Challenge 2011", "author": ["M. Everingham", "L. Van Gool", "C.K.I. Williams", "J. Winn", "A. Zisserman"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "Unsupervised joint alignment of complex images", "author": ["G.B. Huang", "V. Jain", "E. Learned-Miller"], "venue": "In ICCV,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Learning to align from scratch", "author": ["G.B. Huang", "M.A. Mattar", "H. Lee", "E. Learned-Miller"], "venue": "In NIPS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Sift flow: Dense correspondence across scenes and its applications", "author": ["C. Liu", "J. Yuen", "A. Torralba"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Bird part localization using exemplar-based models with enforced pose and subcategory consistenty", "author": ["J. Liu", "P.N. Belhumeur"], "venue": "In ICCV,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "POOF: Part-based one-vs.-one features for fine-grained categorization, face verification, and attribute estimation", "author": ["T. Berg", "P.N. Belhumeur"], "venue": "In CVPR,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Localizing parts of faces using a consensus of exemplars", "author": ["P.N. Belhumeur", "D.W. Jacobs", "D.J. Kriegman", "N. Kumar"], "venue": "In CVPR,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Articulated pose estimation using flexible mixtures of parts", "author": ["Y. Yang", "D. Ramanan"], "venue": "In CVPR,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Articulated part-based model for joint object detection and pose estimation", "author": ["M. Sun", "S. Savarese"], "venue": "In ICCV,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Face detection, pose estimation, and landmark localization in the wild", "author": ["X. Zhu", "D. Ramanan"], "venue": "In CVPR,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Poselets: Body part detectors trained using 3d human pose annotations", "author": ["L. Bourdev", "J. Malik"], "venue": "In ICCV,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Using k-poselets for detecting people and localizing their keypoints", "author": ["G. Gkioxari", "B. Hariharan", "R. Girshick", "J. Malik"], "venue": "In CVPR,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Articulated pose estimation using discriminative armlet classifiers", "author": ["G. Gkioxari", "P. Arbelaez", "L. Bourdev", "J. Malik"], "venue": "In CVPR,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Backpropagation applied to hand-written zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural Computation,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1989}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. Lecun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "In Proceedings of the IEEE,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1998}, {"title": "DeCAF: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "In ICML,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Pedestrian detection with unsupervised multistage feature learning", "author": ["P. Sermanet", "K. Kavukcuoglu", "S. Chintala", "Y. LeCun"], "venue": "In CVPR,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2013}, {"title": "DeepPose: Human pose estimation via deep neural networks", "author": ["A. Toshev", "C. Szegedy"], "venue": "In CVPR,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "Learning human pose estimation features with convolutional networks", "author": ["A. Jain", "J. Tompson", "M. Andriluka", "G.W. Taylor", "C. Bregler"], "venue": "In ICLR,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Visualizing and understanding convolutional neural networks", "author": ["M. D Zeiler", "R. Fergus"], "venue": "In ECCV,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Intriguing properties of neural networks", "author": ["C. Szegedy", "W. Zaremba", "I. Sutskever", "J. Bruna", "D. Erhan", "I. Goodfellow", "R. Fergus"], "venue": "In ICLR,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Descriptor Matching with Convolutional Neural Networks: a Comparison to SIFT", "author": ["P. Fischer", "A. Dosovitskiy", "T. Brox"], "venue": "ArXiv e-prints,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "HOGgles: Visualizing Object Detection Features", "author": ["C. Vondrick", "A. Khosla", "T. Malisiewicz", "A. Torralba"], "venue": "In ICCV,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Efficient belief propagation for early vision", "author": ["P. Felzenszwalb", "D.P. Huttenlocher"], "venue": "International journal of computer vision,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2006}, {"title": "Distance transforms of sampled functions", "author": ["P. Felzenszwalb", "D. Huttenlocher"], "venue": "Technical report, Cornell University,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2004}, {"title": "SciPy: Open source scientific tools for Python", "author": ["E. Jones", "T. Oliphant", "P. Peterson"], "venue": null, "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2001}, {"title": "Articulated human detection with flexible mixtures of parts", "author": ["Y. Yang", "D. Ramanan"], "venue": "In PAMI,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}, {"title": "Object recognition from local scale-invariant features", "author": ["D.G. Lowe"], "venue": "In ICCV,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1999}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["P. Sermanet", "D. Eigen", "X. Zhang", "M. Mathieu", "R. Fergus", "Y. LeCun"], "venue": "In ICLR,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Selective search for object recognition", "author": ["J. Uijlings", "K. van de Sande", "T. Gevers", "A. Smeulders"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2013}, {"title": "VLFeat: An open and portable library of computer vision algorithms", "author": ["A. Vedaldi", "B. Fulkerson"], "venue": "http://www.vlfeat.org/,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Convolutional neural nets (convnets) trained from massive labeled datasets [1] have substantially improved the state-of-the-art in image classification [2] and object detection [3].", "startOffset": 75, "endOffset": 78}, {"referenceID": 1, "context": "Convolutional neural nets (convnets) trained from massive labeled datasets [1] have substantially improved the state-of-the-art in image classification [2] and object detection [3].", "startOffset": 152, "endOffset": 155}, {"referenceID": 2, "context": "Convolutional neural nets (convnets) trained from massive labeled datasets [1] have substantially improved the state-of-the-art in image classification [2] and object detection [3].", "startOffset": 177, "endOffset": 180}, {"referenceID": 3, "context": "We present evidence that convnet features localize at a much finer scale than their receptive field sizes, that they can be used to perform intraclass alignment as well as conventional hand-engineered features, and that they outperform conventional features in keypoint prediction on objects from PASCAL VOC 2011 [4].", "startOffset": 313, "endOffset": 316}, {"referenceID": 1, "context": "Recent advances in convolutional neural nets [2] dramatically improved the state-of-the-art in image classification.", "startOffset": 45, "endOffset": 48}, {"referenceID": 2, "context": "For coarse localization, such doubts were alleviated by record breaking results extending the same features to detection on PASCAL [3].", "startOffset": 131, "endOffset": 134}, {"referenceID": 4, "context": "Congealing [6] is an unsupervised joint alignment method based on an entropy objective.", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "Deep congealing [7] builds on this idea by replacing hand-engineered features with unsupervised feature learning from multiple resolutions.", "startOffset": 16, "endOffset": 19}, {"referenceID": 6, "context": "Inspired by optical flow, SIFT flow [8] matches densely sampled SIFT features for correspondence and has been applied to motion prediction and motion transfer.", "startOffset": 36, "endOffset": 39}, {"referenceID": 7, "context": "In particular, fine-grained categorization, the subject of many recent works, depends strongly on part localization [9, 10].", "startOffset": 116, "endOffset": 123}, {"referenceID": 8, "context": "In particular, fine-grained categorization, the subject of many recent works, depends strongly on part localization [9, 10].", "startOffset": 116, "endOffset": 123}, {"referenceID": 9, "context": "Most of the existing works on part localization or keypoint prediction focus on either facial landmark localization [11] or human pose estimation.", "startOffset": 116, "endOffset": 120}, {"referenceID": 10, "context": "Human pose estimation has been approached using tree structured methods to model the spatial relationships between parts [12, 13, 14], and also using poselets [15] as an intermediate step to localize human keypoints [16, 17].", "startOffset": 121, "endOffset": 133}, {"referenceID": 11, "context": "Human pose estimation has been approached using tree structured methods to model the spatial relationships between parts [12, 13, 14], and also using poselets [15] as an intermediate step to localize human keypoints [16, 17].", "startOffset": 121, "endOffset": 133}, {"referenceID": 12, "context": "Human pose estimation has been approached using tree structured methods to model the spatial relationships between parts [12, 13, 14], and also using poselets [15] as an intermediate step to localize human keypoints [16, 17].", "startOffset": 121, "endOffset": 133}, {"referenceID": 13, "context": "Human pose estimation has been approached using tree structured methods to model the spatial relationships between parts [12, 13, 14], and also using poselets [15] as an intermediate step to localize human keypoints [16, 17].", "startOffset": 159, "endOffset": 163}, {"referenceID": 14, "context": "Human pose estimation has been approached using tree structured methods to model the spatial relationships between parts [12, 13, 14], and also using poselets [15] as an intermediate step to localize human keypoints [16, 17].", "startOffset": 216, "endOffset": 224}, {"referenceID": 15, "context": "Human pose estimation has been approached using tree structured methods to model the spatial relationships between parts [12, 13, 14], and also using poselets [15] as an intermediate step to localize human keypoints [16, 17].", "startOffset": 216, "endOffset": 224}, {"referenceID": 1, "context": "Deep learning Convolutional neural networks have gained much recent attention due to their success in image classification [2].", "startOffset": 123, "endOffset": 126}, {"referenceID": 16, "context": "Convnets trained with backpropagation were initially succesful in digit recognition [18] and OCR [19].", "startOffset": 84, "endOffset": 88}, {"referenceID": 17, "context": "Convnets trained with backpropagation were initially succesful in digit recognition [18] and OCR [19].", "startOffset": 97, "endOffset": 101}, {"referenceID": 18, "context": "The feature representations learned from large data sets have been found to generalize well to other image classification tasks [20] and even to object detection [3, 21].", "startOffset": 128, "endOffset": 132}, {"referenceID": 2, "context": "The feature representations learned from large data sets have been found to generalize well to other image classification tasks [20] and even to object detection [3, 21].", "startOffset": 162, "endOffset": 169}, {"referenceID": 19, "context": "The feature representations learned from large data sets have been found to generalize well to other image classification tasks [20] and even to object detection [3, 21].", "startOffset": 162, "endOffset": 169}, {"referenceID": 20, "context": "[22] trained a cascade of regression-based convnets for human pose estimation and Jain et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[23] combine a weak spatial model with deep learning methods.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "Zeiler and Fergus [24] provide several heuristic visualizations suggesting coarse localization ability.", "startOffset": 18, "endOffset": 22}, {"referenceID": 23, "context": "[25] show counterintuitive properties of the convnet representation, and suggest that individual feature channels may not be more semantically meaningful than other bases in feature space.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "A concurrent work [26] compares convnet features with SIFT in a standard descriptor matching task.", "startOffset": 18, "endOffset": 22}, {"referenceID": 1, "context": "[2] and trained for classification using the 1.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "2 million images of the ILSVRC 2012 challenge dataset [1].", "startOffset": 54, "endOffset": 57}, {"referenceID": 25, "context": "All experiments are implemented using caffe [27], and our network is the publicly available caffe reference model.", "startOffset": 44, "endOffset": 48}, {"referenceID": 26, "context": "In Figure 1, we perform a nonparametric reconstruction of images from features in the spirit of HOGgles [28].", "startOffset": 104, "endOffset": 108}, {"referenceID": 6, "context": "We approach this difficult task in the style of SIFT flow [8]: we retrieve near neighbors using a coarse similarity measure, and then compute dense correspondences on which we impose an MRF smoothness prior which finally allows all images to be warped into alignment.", "startOffset": 58, "endOffset": 61}, {"referenceID": 27, "context": "Optimization is performed using belief propagation, with the techniques suggested in [29].", "startOffset": 85, "endOffset": 89}, {"referenceID": 28, "context": "Message passing is performed efficiently using the squared Euclidean distance transform [30].", "startOffset": 88, "endOffset": 92}, {"referenceID": 6, "context": "(Unlike the L1 regularization originally used by SIFT flow [8], this formulation maintains rotational invariance of w.", "startOffset": 59, "endOffset": 62}, {"referenceID": 29, "context": "Given the alignment field w, we warp target to source using bivariate spline interpolation (implemented in SciPy [31]).", "startOffset": 113, "endOffset": 117}, {"referenceID": 30, "context": "We assess correctness using mean PCK [32].", "startOffset": 37, "endOffset": 41}, {"referenceID": 6, "context": "For each target image (left column), we show warped versions of five nearest neighbor images aligned with conv4 flow (first row), and warped versions aligned with SIFT flow [8] (second row).", "startOffset": 173, "endOffset": 176}, {"referenceID": 0, "context": "box width and height, picking some \u03b1 \u2208 [0, 1].", "startOffset": 39, "endOffset": 45}, {"referenceID": 13, "context": "For this task we use keypoint data [15] on the twenty classes of PASCAL VOC 2011 [4].", "startOffset": 35, "endOffset": 39}, {"referenceID": 3, "context": "For this task we use keypoint data [15] on the twenty classes of PASCAL VOC 2011 [4].", "startOffset": 81, "endOffset": 84}, {"referenceID": 31, "context": "We extract features at each keypoint using SIFT [33] and using the column of each convnet layer whose rf center lies closest to the keypoint.", "startOffset": 48, "endOffset": 52}, {"referenceID": 2, "context": "Inspired in part by [3, 34, 23], we train sliding window part detectors to predict keypoint locations independently.", "startOffset": 20, "endOffset": 31}, {"referenceID": 32, "context": "Inspired in part by [3, 34, 23], we train sliding window part detectors to predict keypoint locations independently.", "startOffset": 20, "endOffset": 31}, {"referenceID": 21, "context": "Inspired in part by [3, 34, 23], we train sliding window part detectors to predict keypoint locations independently.", "startOffset": 20, "endOffset": 31}, {"referenceID": 2, "context": "R-CNN [3] and OverFeat [34] have both demonstrated the effectiveness of deep convolutional networks on the generic object detection task.", "startOffset": 6, "endOffset": 9}, {"referenceID": 32, "context": "R-CNN [3] and OverFeat [34] have both demonstrated the effectiveness of deep convolutional networks on the generic object detection task.", "startOffset": 23, "endOffset": 27}, {"referenceID": 33, "context": "2 R-CNN starts from bottom-up region proposal [35], which tends to overlook the signal from small parts.", "startOffset": 46, "endOffset": 50}, {"referenceID": 34, "context": "We compute SIFT on a grid of stride eight and bin size of eight using VLFeat [36].", "startOffset": 77, "endOffset": 81}, {"referenceID": 0, "context": "We combine these to yield a final score f(Xi) = s(Xi) p(Xi) \u03b7 , where \u03b7 \u2208 [0, 1] is a tradeoff parameter.", "startOffset": 74, "endOffset": 80}], "year": 2014, "abstractText": "Convolutional neural nets (convnets) trained from massive labeled datasets [1] have substantially improved the state-of-the-art in image classification [2] and object detection [3]. However, visual understanding requires establishing correspondence on a finer level than object category. Given their large pooling regions and training from whole-image labels, it is not clear that convnets derive their success from an accurate correspondence model which could be used for precise localization. In this paper, we study the effectiveness of convnet activation features for tasks requiring correspondence. We present evidence that convnet features localize at a much finer scale than their receptive field sizes, that they can be used to perform intraclass alignment as well as conventional hand-engineered features, and that they outperform conventional features in keypoint prediction on objects from PASCAL VOC 2011 [4].", "creator": "LaTeX with hyperref package"}}}