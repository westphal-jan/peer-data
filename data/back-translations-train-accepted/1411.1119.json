{"id": "1411.1119", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2014", "title": "Projecting Markov Random Field Parameters for Fast Mixing", "abstract": "Markov chain Monte Carlo (MCMC) algorithms are simple and extremely powerful techniques to sample from almost arbitrary distributions. The flaw in practice is that it can take a large and/or unknown amount of time to converge to the stationary distribution. This paper gives sufficient conditions to guarantee that univariate Gibbs sampling on Markov Random Fields (MRFs) will be fast mixing, in a precise sense. Further, an algorithm is given to project onto this set of fast-mixing parameters in the Euclidean norm. Following recent work, we give an example use of this to project in various divergence measures, comparing univariate marginals obtained by sampling after projection to common variational methods and Gibbs sampling on the original parameters.", "histories": [["v1", "Wed, 5 Nov 2014 00:43:08 GMT  (1957kb,D)", "https://arxiv.org/abs/1411.1119v1", "Neural Information Processing Systems 2014"], ["v2", "Fri, 7 Nov 2014 05:38:17 GMT  (3377kb,D)", "http://arxiv.org/abs/1411.1119v2", "Neural Information Processing Systems 2014"], ["v3", "Wed, 12 Nov 2014 00:05:12 GMT  (3377kb,D)", "http://arxiv.org/abs/1411.1119v3", "Neural Information Processing Systems 2014"]], "COMMENTS": "Neural Information Processing Systems 2014", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["xianghang liu", "justin domke"], "accepted": true, "id": "1411.1119"}, "pdf": {"name": "1411.1119.pdf", "metadata": {"source": "CRF", "title": "Projecting Markov Random Field Parameters for Fast Mixing", "authors": ["Xianghang Liu", "Justin Domke"], "emails": ["xianghang.liu@nicta.com.au", "justin.domke@nicta.com.au"], "sections": [{"heading": "1 Introduction", "text": "There are two main classes of approximate inference algorithms: variation methods and Markov chain Monte Carlo (MCMC) algorithms [13].Among variation methods, however, the medium-field approximations [9] are based on a \"tractable\" family of distribution methods, such as fully factored distributions. Inference finds a distribution in the tractable amount to minimize KL divergence from true distribution. Other methods, such as Loopy belief of distribution (LBP), generalized belief of proliferation [14], and expectation propagation [10] use a less limited family of target distributions, but approximate KL divergence. Variation methods are typically fast and often produce high-quality approximations. However, when variable approximations are bad, estimates can be correspondingly worrying. MCMC strategies, such as Gibbs chain, are basically a distribution chain."}, {"heading": "2 Notation", "text": "We consider discrete pairs of MRFs with n variables, where the i-th variable takes values in {1,..., Li}, E is the set of edges and \u03b8 is the potentials on each edge. Each edge in E is an ordered pair (i, j) with i \u2264 j. The parameters are a series of matrices. The corresponding distribution is p (x; \u03b8) = exp \u2211 (i, j) \u30fb E}. If i > j and (j, i) \u30fb E, let succij denote the transposing of successji. The corresponding distribution is p (x; \u03b8) = exp \u2211 (i, j) \u03c3E \u03b8ij (xi, xj) \u2212 A (\u03b8), (1) where A (\u03b8): = log x exp (i, j)."}, {"heading": "3 Background Theory on Rapid Mixing", "text": "It is not as if the distribution differences between countries were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great, that the distribution differences were so great that the distribution differences were so great."}, {"heading": "4 Dependency for Markov Random Fields", "text": "Theorem 6. The Dependency Matrix for a Margarite Random Field is Limited by Rij (\u03b8) \u2264 max. b1 2. The Dependence Matrix for a Margarite Random Field is restricted by Rij (\u03b8) \u2264 max. 2. The Dependence Matrix for a Margarite Random Field is restricted by Rij (\u03b8) \u2264 max."}, {"heading": "5 Euclidean Projection Operator", "text": "The Euclidean distance between two MRFs, each parameterised by land use planning, is determined by land use planning (land use plan) and land use planning (land use plan), whereas the Euclidean distance between two MRFs, each parameterised by land use planning and land use planning, is land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan = land use plan"}, {"heading": "5.1 Dual Representation", "text": "Theorem 7: Eq. 4 has maximized double representation. (...) This is the double representation maximized. (...) This is the double representation maximized. (...) This is the double representation. (...) This is the double representation. (...) This is the double representation. (...) This is the double representation. (...) This is the double representation. (...) This is the double representation. (...) The double representation. (...) The double representation. (...) This is the double representation. (...) This is the double representation. (...) The double representation. (...) This is the double representation. (...) This is the double representation. (...)"}, {"heading": "5.2 Spectral Norm", "text": "If the spectral norm, i.e. the largest singular value of a matrix, is set, the projection can be performed in Eq.6 by swelling the singular values of A [3]. Theoretically, the use of the spectral norm results in a tighter binding to Z than other norms (Section 3). However, the calculation of a complete singular value decomposition for a graph with a large number of variables can be impractically slow."}, {"heading": "5.3 \u221e-norm", "text": "At this point, we will consider the definition of the 1-point standard, which measures the maximum l1 standard of the series A. This standard has several mathematical advantages. First, to project a matrix onto a 1-point standard sphere, we can simply project each line ai of the matrix onto the 1-point standard sphere. Duchi et al. [4] offer a method that is linear in the number of zeros in a and logarithmic in the length of a. Thus, if Z is an n-point standard, the matrix 6 can be solved for the 1-point standard in time n2 and, for sufficiently sparse matrices, in time n Log n. A second advantage of the 1-point standard is that (in contrast to the spectral standard) the projection in Equation 6 significantly improves the sparseness of the matrix."}, {"heading": "6 Projection in Divergences", "text": "In this section, we will find a distribution p (x; \u03b8) in the fast-mixing family that comes closest to a target distribution p (x; \u0443) in any divergence D. The choice of divergence depends on the convenience of the projection, the approximate family, and the inference task. We will first present a general algorithmic framework based on the projected descent of the gradient (algorithm 1), and then discuss the details of several previously suggested divergences [11, 3]."}, {"heading": "6.1 General algorithm framework for divergence minimization", "text": "The problem of the projection of divergences is formulated in such a way that it is a measure of divergence, with C being the practicable measure set forth in Eq.4. Our general strategy for this is to use the predicted gradient descent to solve the optimization minute (equation, Z). (8) If the common operator uses the solution of Eq.8 to project onto C., as described in Section 5., the only difference in the projection algorithm is in the assessment of the gradient decrease (equation, Z). It is clear that if (inequality, Z) is the solution of Eq.8, then the solution of 7.6.2 divergences of the 5 algorithm 1 Projected gradient descent for divergence projection is initialized (prediction 1, Z1), 1. Repetition of the divergence deviation (prefabrication, ZK) and 1. Convergence deviation (prefabrication, Zk) to this point (ZK)."}, {"heading": "6.2.1 KL-divergence", "text": "The KL divergence is probably the optimal divergence for marginal conclusions, because it strives to obtain the marginals p (x; \u03b8) and p (x; \u043a). However, the projection of the KL divergence is insoluble here, because the evaluation of the gradient of the KL divergence requires the margins of the distribution economy."}, {"heading": "6.2.2 Piecewise KL-divergence", "text": "T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T-T T"}, {"heading": "6.2.3 Reversed KL-divergence", "text": "The \"reverse\" KL divergence KL (\u00da) is minimized by means of medium-field methods. In general, KL (\u03b8) is inferior to marginal inference KL (\u043a \u03b8) because it tends to underestimate the support of distribution [11]. Nevertheless, it often works well in practice. KL divergence can be calculated from samples generated from p (x) [3]. In the implementation, we maintain a \"pool\" of samples, each of which is updated by a single Gibbs step after each iteration of algorithm 1."}, {"heading": "7 Experiments", "text": "The experiments below take two steps: first, the parameters are projected on each distribution (in some deviations) and then we compare the accuracy of the sampling with the resulting marginals. We focus on this second aspect. However, we provide a comparison of the computational time for different projection algorithms in Table 1, and when we compare the accuracy of the sampling with a given amount of time, we provide two curves for the sampling with the original parameters, where a curve has an additional amount of sampling effort to match the time for projection in the reverse KL divergence.7.1 Synthetic MRFsOur first experiment follows the evaluation of the accuracy of the sampling methods in marginal inference. In the experiments, we approach random generated MRF models with rapid mixing distributions using the previously described projection algorithms. Then, the marginals of the fast mixing distributions are estimated by running a chain on each distribution."}, {"heading": "8 Conclusions", "text": "We have derived sufficient conditions for the parameters of an MRF to ensure rapid mixing of univaried Gibbs sampling, together with an algorithm projected onto this set in the Euclidean standard. As an example, we have investigated the accuracy of samples obtained by projection of parameters and subsequent sampling, which competes with both simple variation methods and traditional Gibbs sampling."}, {"heading": "Acknowledgments", "text": "NICTA is funded by the Australian government through the Department of Communications and the Australian Research Council through the ICT Centre of Excellence Program8."}, {"heading": "9 Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9.1 Proof of MRF Dependency Bound", "text": "In this section we find proof of the dependency matrix, which is given in Section 4 above. To begin with, we consider the conditional distribution of a single variable xi when all the others are fixed, which is easy to calculate. The conditional probability of a variable given to all others is (v) = exp (v) / 1T exp (v), and N (i) is the set of indices present in a pair with i.Now, in order to calculate the influence matrix, we must take into account what configuration of all variables other than xi and xj allow a change in xj to induce the largest change in xi (definition 3)."}, {"heading": "9.2 Proof of Dual Representation for Euclidean Projection Operator", "text": "This section provides proof of the main result of section 5.1, as stated below. Theorem 14 (Projection Operator C (Projection, Y): = Argmin (Projection, Y): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection): \u00b7 Argmin (Projection, Z): \u00b7 Argmin (Projection, Z): (\u00b7) (Projection, Z): (\u00b7) (Projection, Z): (\u00b7) (Projection, Z): (Projection, Z): (Argmin, Z): (Argmin, Z): (Argmin, Z): (Argmin, Z): (Argmin, Z): (Argmin, Z): (Argmin, Z): (Argmin, Z): (Argmin, Z): (Argmin: (Argmin, Z): (Argmin, Z): (Argmin, Z): (Argmin, Z: (Argmin, Z): (Argmin, Z): (Argmin, Z: (Argmin, Z): (Argmin, Z): (Argmin, Z: (Argmin, Z): (Argmin, Z, Z): (Argmin, Z: (Argmin, Z, Z): (Argmin, Z: (Argmin, Z, Z): (Argmin, Z, Z): (Argmin, Z: (Argmin, Z): (Argmin, Z, Z): (Argmin, Z: (Argmin, Z): (Argmin, Z: (Argmin, Z, Z, Z): (Argmin, Z, Z, Z): (Argmin, Z: (Argmin, Z"}, {"heading": "9.3 Additional Experimental Results", "text": "The rest of the appendix contains additional experimental results that might not fit into the main paper.1213"}], "references": [{"title": "Nonlinear Programming", "author": ["Dimitri Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2004}, {"title": "A limited memory algorithm for bound constrained optimization", "author": ["Richard H. Byrd", "Peihuang Lu", "Jorge Nocedal", "Ciyou Zhu"], "venue": "SIAM J. Sci. Comput.,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}, {"title": "Projecting Ising model parameters for fast mixing", "author": ["Justin Domke", "Xianghang Liu"], "venue": "In NIPS,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Efficient projections onto the l1-ball for learning in high dimensions", "author": ["John C. Duchi", "Shai Shalev-Shwartz", "Yoram Singer", "Tushar Chandra"], "venue": "In ICML,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Matrix norms and rapid mixing for spin systems", "author": ["Martin E. Dyer", "Leslie Ann Goldberg", "Mark Jerrum"], "venue": "Ann. Appl. Probab.,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2009}, {"title": "Approximate inference using conditional entropy decompositions", "author": ["Amir Globerson", "Tommi Jaakkola"], "venue": "In UAI,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "A simple condition implying rapid mixing of single-site dynamics on spin systems", "author": ["Thomas P. Hayes"], "venue": "In FOCS,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Convergent message-passing algorithms for inference over general graphs with convex free energies", "author": ["Tamir Hazan", "Amnon Shashua"], "venue": "In UAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Expectation propagation for approximate bayesian inference", "author": ["Thomas Minka"], "venue": "In UAI,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2001}, {"title": "Divergence measures and message passing", "author": ["Thomas Minka"], "venue": "Technical report,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "Nonuniversal critical dynamics in monte carlo simulations", "author": ["Robert H. Swendsen", "Jian-Sheng Wang"], "venue": "Phys. Rev. Lett.,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1987}, {"title": "Graphical models, exponential families, and variational inference", "author": ["Martin Wainwright", "Michael Jordan"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Constructing free energy approximations and generalized belief propagation algorithms", "author": ["Jonathan Yedidia", "William Freeman", "Yair Weiss"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}], "referenceMentions": [{"referenceID": 12, "context": "There are two main classes of approximate inference algorithms: variational methods and Markov chain Monte Carlo (MCMC) algorithms [13].", "startOffset": 131, "endOffset": 135}, {"referenceID": 8, "context": "Among variational methods, mean-field approximations [9] are based on a \u201ctractable\u201d family of distributions, such as the fully-factorized distributions.", "startOffset": 53, "endOffset": 56}, {"referenceID": 13, "context": "Other methods, such as loopy belief propagation (LBP), generalized belief propagation [14] and expectation propagation [10] use a less restricted family of target distributions, but approximate the KL-divergence.", "startOffset": 86, "endOffset": 90}, {"referenceID": 9, "context": "Other methods, such as loopy belief propagation (LBP), generalized belief propagation [14] and expectation propagation [10] use a less restricted family of target distributions, but approximate the KL-divergence.", "startOffset": 119, "endOffset": 123}, {"referenceID": 2, "context": "This paper is inspired by a recent hybrid approach for Ising models [3].", "startOffset": 68, "endOffset": 71}, {"referenceID": 2, "context": "Following previous work [3], these ideas are experimentally validated via a projected gradient descent algorithm to minimize other divergences, and looking at the accuracy of the resulting marginals.", "startOffset": 24, "endOffset": 27}, {"referenceID": 4, "context": "[5], generalizing the work of Hayes [7].", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[5], generalizing the work of Hayes [7].", "startOffset": 36, "endOffset": 39}, {"referenceID": 1, "context": "5 can be solved with LBFGS-B [2].", "startOffset": 29, "endOffset": 32}, {"referenceID": 0, "context": "Finally, once h1 and h2 have been solved, the gradient of g is (by Danskin\u2019s theorem [1]) \u2202g \u2202\u2206ij =\u2212Dij\u1e90ij , \u2202g \u2202\u0393ij =\u1e90ji \u2212 \u1e90ij ,", "startOffset": 85, "endOffset": 88}, {"referenceID": 2, "context": "6 can be performed by thresholding the singular values of A [3].", "startOffset": 60, "endOffset": 63}, {"referenceID": 3, "context": "[4] provide a method linear in the number of nonzeros in a and logarithmic in the length of a.", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "We will first present a general algorithmic framework based on projected gradient descent (Algorithm 1), and then discuss the details of several previously proposed divergences [11, 3].", "startOffset": 177, "endOffset": 184}, {"referenceID": 2, "context": "We will first present a general algorithmic framework based on projected gradient descent (Algorithm 1), and then discuss the details of several previously proposed divergences [11, 3].", "startOffset": 177, "endOffset": 184}, {"referenceID": 2, "context": "2 Piecewise KL-divergence One tractable surrogate of KL(\u03c8\u2016\u03b8) is the piecewise KL-divergence [3] defined over some tractable subgraphs.", "startOffset": 92, "endOffset": 95}, {"referenceID": 10, "context": "In general KL(\u03b8\u2016\u03c8) is inferior to KL(\u03c8\u2016\u03b8) for marginal inference since it tends to underestimate the support of the distribution [11].", "startOffset": 129, "endOffset": 133}, {"referenceID": 2, "context": "\u2207\u03b8KL(\u03b8\u2016\u03c8) can computed as \u2207\u03b8KL(\u03b8\u2016\u03c8) = \u2211 x p(x; \u03b8)(\u03b8 \u2212 \u03c8) \u00b7 f(x) ( f(x) \u2212 \u03bc(\u03b8) ) , which can be approximated by samples generated from p(x; \u03b8) [3].", "startOffset": 142, "endOffset": 145}, {"referenceID": 7, "context": "Our first experiment follows that of [8, 3] in evaluating the accuracy of approximation methods in marginal inference.", "startOffset": 37, "endOffset": 43}, {"referenceID": 2, "context": "Our first experiment follows that of [8, 3] in evaluating the accuracy of approximation methods in marginal inference.", "startOffset": 37, "endOffset": 43}, {"referenceID": 5, "context": "Many other methods have been compared against a similar benchmark [6, 8].", "startOffset": 66, "endOffset": 72}, {"referenceID": 7, "context": "Many other methods have been compared against a similar benchmark [6, 8].", "startOffset": 66, "endOffset": 72}, {"referenceID": 0, "context": "25 i , in which ti is sampled uniformly from [0, 1].", "startOffset": 45, "endOffset": 51}, {"referenceID": 11, "context": "On this attractive-only Ising potential, the Swendsen-Wang method [12] mixes rapidly, and so we use the resulting samples to estimate the ground truth.", "startOffset": 66, "endOffset": 70}, {"referenceID": 0, "context": "References [1] Dimitri Bertsekas.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Richard H.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Justin Domke and Xianghang Liu.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] John C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Martin E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Amir Globerson and Tommi Jaakkola.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Thomas P.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Tamir Hazan and Amnon Shashua.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Thomas Minka.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Thomas Minka.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Robert H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Martin Wainwright and Michael Jordan.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Jonathan Yedidia, William Freeman, and Yair Weiss.", "startOffset": 0, "endOffset": 4}], "year": 2014, "abstractText": "Markov chain Monte Carlo (MCMC) algorithms are simple and extremely powerful techniques to sample from almost arbitrary distributions. The flaw in practice is that it can take a large and/or unknown amount of time to converge to the stationary distribution. This paper gives sufficient conditions to guarantee that univariate Gibbs sampling on Markov Random Fields (MRFs) will be fast mixing, in a precise sense. Further, an algorithm is given to project onto this set of fast-mixing parameters in the Euclidean norm. Following recent work, we give an example use of this to project in various divergence measures, comparing univariate marginals obtained by sampling after projection to common variational methods and Gibbs sampling on the original parameters.", "creator": "LaTeX with hyperref package"}}}