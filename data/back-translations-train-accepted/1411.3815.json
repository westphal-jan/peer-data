{"id": "1411.3815", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Nov-2014", "title": "Predictive Encoding of Contextual Relationships for Perceptual Inference, Interpolation and Prediction", "abstract": "We propose a new neurally-inspired model that can learn to encode global relationship context of visual events across time and space and to use the contextual information to modulate the analysis by synthesis process in a predictive coding framework. The model is based on the principle of mutual predictability. It learns latent contextual representations by maximizing the predictability of visual events based on local and global context information. The model can therefore interpolate missing events or predict future events in image sequences. The contextual representations modulate the prediction synthesis process by adaptively rescaling the contribution of each neuron's basis function. In contrast to standard predictive coding models, the prediction error in this model is used to update the context representation but does not alter the feedforward input for the next layer, thus is more consistent with neuro-physiological observations. We establish the computational feasibility of this model by demonstrating its ability to simultaneously infer context, as well as interpolate and predict input image sequences in a unified framework.", "histories": [["v1", "Fri, 14 Nov 2014 07:38:45 GMT  (572kb,D)", "https://arxiv.org/abs/1411.3815v1", null], ["v2", "Sun, 21 Dec 2014 00:08:05 GMT  (934kb,D)", "http://arxiv.org/abs/1411.3815v2", null], ["v3", "Wed, 24 Dec 2014 12:05:56 GMT  (1016kb,D)", "http://arxiv.org/abs/1411.3815v3", null], ["v4", "Mon, 2 Mar 2015 12:50:42 GMT  (2036kb,D)", "http://arxiv.org/abs/1411.3815v4", null], ["v5", "Fri, 10 Apr 2015 17:52:12 GMT  (1146kb,D)", "http://arxiv.org/abs/1411.3815v5", null], ["v6", "Thu, 16 Apr 2015 15:57:36 GMT  (1158kb,D)", "http://arxiv.org/abs/1411.3815v6", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["mingmin zhao", "chengxu zhuang", "yizhou wang", "tai sing lee"], "accepted": true, "id": "1411.3815"}, "pdf": {"name": "1411.3815.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Mingmin Zhao"], "emails": ["zhaomingmin@pku.edu.cn", "zcx11@mails.tsinghua.edu.cn", "Yizhou.Wang@pku.edu.cn", "tai@cnbc.cmu.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, most of them are able to survive on their own if they do not put themselves in a position to survive on their own."}, {"heading": "2 DESCRIPTION OF THE MODEL", "text": "The proposed model seeks to learn relationships between visual events in a spatial or temporal neighborhood in order to provide contextual modulation for image reconstruction, interpolation, and prediction. (Note: The brain continually generates models of the world based on context and memory to predict sensory inputs.) It synthesizes a predicted image and feeds back to adjust the input image represented in the lower sensory areas. The mismatch between the prediction and the input produces a residual signal that can be used to update the predictions to explain the inputs (Mumford, 1992; Rao & Ballard, 1999). Our model expands this \"standard\" predictive coding model by using the residuction signals to actualize the contextual representation, which in turn modifies the functions of the image synthesis process by recalculating the neural properties of the environment."}, {"heading": "3 DESCRIPTION OF THE ALGORITHMS", "text": "In this section, we describe the learning and inference algorithms developed for our model. Bottom-up and top-down estimates play a role in both inference and learning."}, {"heading": "3.1 UNSUPERVISED PARAMETERS LEARNING", "text": "The training data set consists of m image sequences {x (1) 1... N,..., x (m) 1... N} and we assume that each of them is an i.i.d sample from an unknown distribution. The goal is to optimize the following problem: minimize. (z m) i = 1 L (x (i) 1... N, z (i); \u03b8), (5) We use an EM-like algorithm that updates parameters and alternatively adds hidden variables z while the other remains fixed. (Update) We use stochastic gradient descent (SGD) to update the process based on the following updating rule. (k + 1) = imbalances (k) (k)."}, {"heading": "3.2 INFERENCE WITH PARTIAL OBSERVATION", "text": "The conclusion with partial observation refers to the prediction or reconstruction of a missing frame by the trained model, which specifies observed adjacent frames in the sequence. This problem presents itself as an optimization problem, which simultaneously solves the latent variables z for the contextual representation and the missing event / frame xu, 1 \u2264 u \u2264 N: minimize xu, z L (x1... N, z; \u03b8) (9) This optimization problem can be solved efficiently and iteratively by an alternating top-down and bottom-up estimation method. The top-down estimation \"hallucinates\" a missing event based on the adjacent events and the superordinate contextual representation. The bottom-up method uses the prediction weighting error to update the contextual representation. Specifically, the minimization of Eqn. (9) is derived from alternating estimation of xu and itz prevalence in view of Eyu in view of the current Eqn stimation."}, {"heading": "4 EXPERIMENTAL RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 RECEPTIVE FIELD LEARNING", "text": "In the first experiment, we trained our model with films made from natural images. Each film sequence showed either transformation, rotation or transformation. We trained models for each type of transformation film independently of each other, as well as a mixture of the three. We showed the results of the feedback filters with three frames (N = 3). However, the algorithm is not limited to three frames, and we will also show the results of the model with relatively long sequences."}, {"heading": "4.2 UNDERSTANDING THE CONTEXTUAL REPRESENTATION", "text": "To understand the information encoded in the contextual relationship to latent variables z, we used the t-SNE method (Van der Maaten & Hinton, 2008) to see how pattern contents and transformation contents are bundled in a low-dimensional space. We applied the pre-mixed model to a combination of 6,000 synthetic films generated by random translation, rotation, or scaling of image fields, randomly sampled from 3 different datasets (MNIST, natural images, and bouncing spheres), the translation steps were no less than 1 pixel per frame, the rotation angles were no less than 6, and the scaling ratio was sampled using [0.6, 0.9] or [1.1, 1.8] to distinguish the different transformations, visualizing the activities in the z-layer using Hinton's scan algorithm in Figure 3 (a), (3)."}, {"heading": "4.3 PREDICTION AND INTERPOLATION", "text": "This year it is so far that it will be able to erenie.nn the aforementioned lcihsrcnlrVo rf\u00fc eid eerwtlrVo rf\u00fc eid eerwtlrteeae\u00fcgznlrlteeeirsrteeeirsrteeoiKn"}, {"heading": "5 DISCUSSION", "text": "In this context, it should be noted that this project is a project, which is primarily a project."}, {"heading": "6 ACKNOWLEDGMENTS", "text": "This research was supported by research grants 973-2015CB351800, NSFC-61272027 (to YZ Wang) and NSF 1320651 and NIH R01 EY022247 (to TS Lee). Both Wang and Lee's laboratories acknowledge NVIDIA Corporation's support for donating GPUs for this research. Mingmin Zhao and Chengxu Zhuang were supported by scholarships from Peking University and Tsinghua University, respectively, when they visited Carnegie Mellon to conduct this research."}], "references": [{"title": "The proactive brain: using analogies and associations to generate predictions", "author": ["Bar", "Moshe"], "venue": "Trends in cognitive sciences,", "citeRegEx": "Bar and Moshe.,? \\Q2007\\E", "shortCiteRegEx": "Bar and Moshe.", "year": 2007}, {"title": "Theano: a cpu and gpu math expression compiler", "author": ["Bergstra", "James", "Breuleux", "Olivier", "Bastien", "Fr\u00e9d\u00e9ric", "Lamblin", "Pascal", "Pascanu", "Razvan", "Desjardins", "Guillaume", "Turian", "Joseph", "Warde-Farley", "David", "Bengio", "Yoshua"], "venue": "In Proceedings of the Python for scientific computing conference,", "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "The free-energy principle: a unified brain theory", "author": ["Friston", "Karl"], "venue": "Nature Reviews Neuroscience,", "citeRegEx": "Friston and Karl.,? \\Q2010\\E", "shortCiteRegEx": "Friston and Karl.", "year": 2010}, {"title": "Estimating face orientation from robust detection of salient facial structures", "author": ["Gourier", "Nicolas", "Hall", "Daniela", "Crowley", "James L"], "venue": "In FG Net Workshop on Visual Observation of Deictic Gestures. FGnet", "citeRegEx": "Gourier et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Gourier et al\\.", "year": 2000}, {"title": "A practical guide to training restricted boltzmann machines", "author": ["Hinton", "Geoffrey"], "venue": "Momentum,", "citeRegEx": "Hinton and Geoffrey.,? \\Q2010\\E", "shortCiteRegEx": "Hinton and Geoffrey.", "year": 2010}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Hinton", "Geoffrey", "Osindero", "Simon", "Teh", "Yee-Whye"], "venue": "Neural computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Learning methods for generic object recognition with invariance to pose and lighting", "author": ["LeCun", "Yann", "Huang", "Fu Jie", "Bottou", "Leon"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "LeCun et al\\.,? \\Q2004\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2004}, {"title": "Hierarchical bayesian inference in the visual cortex", "author": ["Lee", "Tai Sing", "Mumford", "David"], "venue": "JOSA A,", "citeRegEx": "Lee et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2003}, {"title": "Learning to relate images. Pattern Analysis and Machine Intelligence", "author": ["R. Memisevic"], "venue": "IEEE Transactions on,", "citeRegEx": "Memisevic,? \\Q2013\\E", "shortCiteRegEx": "Memisevic", "year": 2013}, {"title": "Gradient-based learning of higher-order image features", "author": ["Memisevic", "Roland"], "venue": "In ICCV. IEEE,", "citeRegEx": "Memisevic and Roland.,? \\Q2011\\E", "shortCiteRegEx": "Memisevic and Roland.", "year": 2011}, {"title": "Modeling deep temporal dependencies with recurrent \u201cgrammar cells", "author": ["Michalski", "Vincent", "Memisevic", "Roland", "Konda", "Kishore"], "venue": "In NIPS, pp. 1925\u20131933,", "citeRegEx": "Michalski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Michalski et al\\.", "year": 2014}, {"title": "On the computational architecture of the neocortex", "author": ["Mumford", "David"], "venue": "Biological cybernetics,", "citeRegEx": "Mumford and David.,? \\Q1992\\E", "shortCiteRegEx": "Mumford and David.", "year": 1992}, {"title": "On optimization methods for deep learning", "author": ["Ngiam", "Jiquan", "Coates", "Adam", "Lahiri", "Ahbik", "Prochnow", "Bobby", "Le", "Quoc V", "Ng", "Andrew Y"], "venue": "In ICML,", "citeRegEx": "Ngiam et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ngiam et al\\.", "year": 2011}, {"title": "Sparse coding with an overcomplete basis set: A strategy employed by v1", "author": ["Olshausen", "Bruno A", "Field", "David J"], "venue": "Vision research,", "citeRegEx": "Olshausen et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Olshausen et al\\.", "year": 1997}, {"title": "Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects", "author": ["Rao", "Rajesh PN", "Ballard", "Dana H"], "venue": "Nature neuroscience,", "citeRegEx": "Rao et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Rao et al\\.", "year": 1999}, {"title": "Modeling the joint density of two images under a variety of transformations", "author": ["Susskind", "Joshua", "Memisevic", "Roland", "Hinton", "Geoffrey", "Pollefeys", "Marc"], "venue": "In CVPR. IEEE,", "citeRegEx": "Susskind et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Susskind et al\\.", "year": 2011}, {"title": "Prior expectation mediates neural adaptation to repeated sounds in the auditory cortex: an meg study", "author": ["Todorovic", "Ana", "van Ede", "Freek", "Maris", "Eric", "de Lange", "Floris P"], "venue": "The Journal of neuroscience,", "citeRegEx": "Todorovic et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Todorovic et al\\.", "year": 2011}, {"title": "Visualizing data using t-sne", "author": ["Van der Maaten", "Laurens", "Hinton", "Geoffrey"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["Vincent", "Pascal", "Larochelle", "Hugo", "Bengio", "Yoshua", "Manzagol", "Pierre-Antoine"], "venue": "In ICML,", "citeRegEx": "Vincent et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 16, "context": "The predictive coding idea has been generalized to non-visual systems (Bar, 2007; Todorovic et al., 2011), and even a \u201cunified theory\u201d of the brain (Friston, 2010).", "startOffset": 70, "endOffset": 105}, {"referenceID": 8, "context": "This model is inspired and related to Memisevic and Hinton\u2019s (Memisevic, 2013; Susskind et al., 2011; Memisevic, 2011) gated Boltzmann machines (GBM) and gated autoencoder (GAE) which also model spatiotemporal transformations in image sequences.", "startOffset": 61, "endOffset": 118}, {"referenceID": 15, "context": "This model is inspired and related to Memisevic and Hinton\u2019s (Memisevic, 2013; Susskind et al., 2011; Memisevic, 2011) gated Boltzmann machines (GBM) and gated autoencoder (GAE) which also model spatiotemporal transformations in image sequences.", "startOffset": 61, "endOffset": 118}, {"referenceID": 5, "context": "This is a crucial difference from GBM, which, as is the case with most deep learning networks (Hinton et al., 2006), relies on one-pass feedforward computation for inference.", "startOffset": 94, "endOffset": 115}, {"referenceID": 15, "context": "At the abstract graphical model level, our model is very similar to autoencoder, as well as to Memisevic and Hinton\u2019s gated Boltzmann machines (Susskind et al., 2011; Memisevic, 2011).", "startOffset": 143, "endOffset": 183}, {"referenceID": 1, "context": "The algorithm is implemented using Theano (Bergstra et al., 2010) which provides highly optimized symbolic differentiation for efficient and automatic gradient calculation with respect to the objective function.", "startOffset": 42, "endOffset": 65}, {"referenceID": 18, "context": "The idea of denoising (Vincent et al., 2008) is also used to learn more robust filters.", "startOffset": 22, "endOffset": 44}, {"referenceID": 12, "context": "To better exploit the quadratic structure of the objective function, we solve this convex optimization problem using a more efficient quasi-Newton method Limited memory BFGS (L-BFGS) algorithm instead of gradient descent (Ngiam et al., 2011).", "startOffset": 221, "endOffset": 241}, {"referenceID": 6, "context": ", 2004), MNIST handwritten digits and natural images (Olshausen & Field, 1997) and then we evaluated its performance in predicting and interpolating 3D rotation on the NORB dataset (LeCun et al., 2004).", "startOffset": 181, "endOffset": 201}, {"referenceID": 10, "context": "We used a similar parameter setting as that in Michalski et al. (2014). Each chirp sequence contained 160 frames in one second, partitioned into 16 non-overlapping 10-frame intervals, yielding 10dimensional input vectors.", "startOffset": 47, "endOffset": 71}], "year": 2015, "abstractText": "We propose a new neurally-inspired model that can learn to encode the global relationship context of visual events across time and space and to use the contextual information to modulate the analysis by synthesis process in a predictive coding framework. The model learns latent contextual representations by maximizing the predictability of visual events based on local and global contextual information through both top-down and bottom-up processes. In contrast to standard predictive coding models, the prediction error in this model is used to update the contextual representation but does not alter the feedforward input for the next layer, and is thus more consistent with neurophysiological observations. We establish the computational feasibility of this model by demonstrating its ability in several aspects. We show that our model can outperform state-of-art performances of gated Boltzmann machines (GBM) in estimation of contextual information. Our model can also interpolate missing events or predict future events in image sequences while simultaneously estimating contextual information. We show it achieves state-of-art performances in terms of prediction accuracy in a variety of tasks and possesses the ability to interpolate missing frames, a function that is lacking in GBM.", "creator": "LaTeX with hyperref package"}}}