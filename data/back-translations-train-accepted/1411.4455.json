{"id": "1411.4455", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2014", "title": "Errata: Distant Supervision for Relation Extraction with Matrix Completion", "abstract": "The essence of distantly supervised relation extraction is that it is an incomplete multi-label classification problem with sparse and noisy features. To tackle the sparsity and noise challenges, we propose solving the classification problem using matrix completion on factorized matrix of minimized rank. We formulate relation classification as completing the unknown labels of testing items (entity pairs) in a sparse matrix that concatenates training and testing textual features with training labels. Our algorithmic framework is based on the assumption that the rank of item-by-feature and item-by-label joint matrix is low. We apply two optimization models to recover the underlying low-rank matrix leveraging the sparsity of feature-label matrix. The matrix completion problem is then solved by the fixed point continuation (FPC) algorithm, which can find the global optimum. Experiments on two widely used datasets with different dimensions of textual features demonstrate that our low-rank matrix completion approach significantly outperforms the baseline and the state-of-the-art methods.", "histories": [["v1", "Mon, 17 Nov 2014 12:43:30 GMT  (1872kb,D)", "http://arxiv.org/abs/1411.4455v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["miao fan", "deli zhao", "qiang zhou", "zhiyuan liu", "thomas fang zheng", "edward y chang"], "accepted": true, "id": "1411.4455"}, "pdf": {"name": "1411.4455.pdf", "metadata": {"source": "CRF", "title": "Errata: Distant Supervision for Relation Extraction with Matrix Completion", "authors": ["Miao Fan", "Deli Zhao", "Qiang Zhou", "Zhiyuan Liu", "Thomas Fang Zheng", "Edward Y. Chang"], "emails": ["fanmiao.cslt.thu@gmail.com"], "sections": [{"heading": null, "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1 Introduction", "text": "This year it has come to the point that it is a purely reactionary project, in which it is a reactionary project, in which it is a reactionary project."}, {"heading": "2 Related Work", "text": "Snow et al. (2004) used WordNet as a knowledge base to discover more hpyernym / hyponym relationships between entities from news articles. However, either a bioinformatics database or WordNet is maintained by a few experts, so hardly up-to-date. As we enter the big data age, the explosion of unstructured web texts simulates us building more powerful models that can automatically extract relation examples from large online natural language corporations without hand-labeled annotations. Mintz et al. (2009) used Freebase (Bollacker et al., 2008; Bollacker et al.), a large-scale online crowdsourcing knowledge base that contains billions of relationship instances and thousands of relationship names to monitor each other."}, {"heading": "3 Model", "text": "In the field of applied mathematics, we apply a new technique, matrix completion with convex optimization, which was pioneered by Cande and Recht (2009), who proved that most low-rank matrices can be perfectly recovered from an incomplete number of entries, a promising theory that has been successfully applied in many active research areas, such as computer vision (Cabral et al., 2011), referral system (Rennie and Srebro, 2005) and systems controlling (Fazel et al., 2001). Our relationship extraction models are based on the theoretical framework proposed by Goldberg et al. (2010), which formulated multilabel transductive learning as a matrix completion problem. The new framework for classification improves robustness against data noise by penalizing different cost functions for features and labels."}, {"heading": "3.1 Formulation", "text": "Suppose that we have built a training corpus for the relation to n items (entity pairs), that is, we can label the textual characteristics and the labels (relationships) based on the basic alignment assumptions used by Mintz et al. (2009). Let Xtrain (Rn \u00b7 d and Ytrain) label the function matrix and the label matrix for the training (respectively). The linear classification we apply aims to explicitly learn the weight matrix W (1), where 1 is the all-one column vector. b) Then we can predict the label matrix Ytest that we will perform the tests related to the function Matrix Xtest."}, {"heading": "4 Algorithm", "text": "The problem of minimizing the matrix range is NPhard. Therefore, Cande \u0301 s and Recht (2009) proposed to use instead a convex relaxation, the minimization of the nuclear standard. Then, Ma et al. (2011) proposed the fixed-point continuation algorithm (FPC), which is fast and robust. Furthermore, Goldfrab and Ma (2011) proved the convergence of the FPC algorithm to solve the problem of minimizing the nuclear standard. We adopt and modify this algorithm to find the optimum for our noise-tolerant models, i.e. the formulas (3) and (4)."}, {"heading": "4.1 Fixed point continuation for DRMC-b", "text": "Algorithm 1 describes the modified FPC algorithm for solving DRMC-b >, which contains two steps for each iteration, gradient level: In this step, we derive the matrix gradient g (Z) and the bias vector gradient g (b) as follows, g (zij) = 1 | X | xij 1 + exijzij, (i, j), x | Y \u2212 Y \u2212 yi (j \u2212 d) 1 + e yi (j \u2212 d) (zij + bj), (i, j \u2212 d). We use the gradient drop A = Z \u2212 Z (Z)."}, {"heading": "4.2 Fixed point continuation for DRMC-1", "text": "Algorithm 2 is similar to algorithm 1 with two differences: First, there is no bias vector b. Second, a projection step is added to make the first column of the matrix Z to 1. Also, the matrix gradient g (Z) for DRMC-1 isg (zij) = 1 | x (j \u2212 1) x (j \u2212 1) x (i, j \u2212 1) zij, (i, j \u2212 1) x x x (i \u2212 d \u2212 1) zij, (i, j \u2212 d \u2212 1) x y 0, otherwise. Algorithm 2 FPC algorithm for solving DRMC-1 input: Initial matrix Z0; parameter \u00b5, xi; step size \u03c4z \u2212 1).Set Z = Z0. foreach \u00b5 = \u00b51 >... > \u00b5F dowhile relative error > \u03b5 do Gradient: A = z \u2212 g (Output: Z = 1.0, Z (Output: Z = 1.0)."}, {"heading": "5 Experiments", "text": "To perform reliable experiments, we adjust the parameters for our approaches DRMC-b and DRMC-1 and compare them with other four types of landmark methods (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012; Riedel et al., 2013) on two public datasets."}, {"heading": "5.1 Dataset", "text": "The first dataset 12, NYT '10, was developed by Riedel et al. (2010) and also used by Hoffmann et al. (2011) and Surdeanu et al. (2012) Three types of traits, namely lexical, syntactic and named entity-tag traits, were extracted from references to relationships; the second dataset 13, NYT' 13, was also published by Riedel et al. (2013), in which they considered only the lexicalized dependency path between two entities as traits; Table 1 shows that the two datasets differ in some key attributes. More specifically, NYT '10 contains much higher dimensional traits than NYT' 13, while fewer training and testing elements are used."}, {"heading": "5.2 Parameter setting", "text": "In this part we deal with the question of setting parameters: the compromise weights \u00b5 and \u03bb, the step variables \u03c4z and \u03c4b and the decay parameter \u03b7\u00b5.We set \u03bb = 1 to equate the contribution of the cost function conditions for attribute and label matrices in formulas (3) and (4). \u00b5 is assigned by a series of values that obey \u00b5k + 1 = max (\u00b5k\u03b7\u00b5, \u00b5F) 12http: / / iesl.cs.umass.edu / riedel / ecml / 13http: / / iesl.cs.umass.edu / riedel / data-univSchema / We follow the suggestion in (Goldberg et al., 2010) that \u00b5 starts at \u03c31 and \u03c31 is the largest singular value of the Z matrix."}, {"heading": "5.3 Rank estimation", "text": "Although the FPC algorithm converges in an iterative way, the value of \u03b5, which varies with different datasets, is difficult to determine. In practice, we capture the rank of matrix Z in each round of iteration until it converges at a rather small threshold \u03b5 = 10 \u2212 4. This is because we assume that the optimal low-grade representation of matrix Z conveys the really effective information about the underlying semantic correlation between the characteristics and the corresponding labels. We use quintuple cross-validation on the validation set and evaluate performance in each fold with different ranks. At each iteration round, we get a restored matrix and calculate on average the F114 values from the top-5 to the top-all predicted relation cases to measure performance. Figure 3 illustrates the curves of the average F1 values. After including the rank, which differs with the standard F1 score in each range, we calculate the mean for the optimal association and the mean."}, {"heading": "5.4 Method Comparison", "text": "First, we are conducting experiments to compare our approaches with Mintz-09 (Mintz et al., 2009), MultiR-11 (Hoffmann et al., 2011), MIML-12 and MIML-at-least-one-12 (Surdeanu et al., 2012) on the NYT '10 dataset. Surdeanu et al. (2012) published the open source code15 to reproduce the experimental results on these previous methods. Furthermore, their programs can by default use the feature spar-15http: / / nlp.stanford.edu / software / mimlre.shtmlsity degree by filtering a threshold that filters the features that appear less than the usual times. They set the original code to \u03b8 = 5. Therefore, we follow their settings and adopt the same way to filter the features. In this way, we guarantee fair comparison for all methods. Figure 4 (a) shows that our approaches are performing the significant DRS-13 performance enhancements we predicted for DRS-13 and the ASS-13."}, {"heading": "6 Discussion", "text": "We have mentioned that the basic approach of remote monitoring (Mintz et al., 2009) tends to generate noisy (noisy features and incomplete labels) and sparse (sparse labels) data. In this section we will discuss how our approaches address these natural errors. Due to the noisy features and incomplete labels, the underlying data matrix with really effective information tends to be corrupted and the rank of the observed data matrix can be extremely high. Figure 5 shows that the rows of data matrices for the initial optimization of DRMC-b and DRMC-1 are those high values that lead to poor performance. However, as the ranking decreases before approaching optimum, performance gradually improves, meaning that our approaches filter the noise in the data and keep the key information for classifying the recovery of the underlying data-b and DRMC-1 stable."}, {"heading": "7 Conclusion and Future Work", "text": "In this thesis, we contributed two noise-tolerant optimization models 17, DRMC-b and DRMC-1, to remote relationship extraction from a novel perspective. Our models are based on low-criterion matrix completion. Experiments showed that the low representation of the feature-label matrix can exploit the underlying semantic correlated information for relationship classification and is effective in overcoming the difficulties caused by sparse and noisy characteristics and incomplete labels, resulting in significant improvements in performance. Our proposed models also leave open questions for remotely monitored relationship extraction. First, they cannot efficiently process new incoming test elements, as we need to reconstruct the data matrix, which contains not only the test elements, but also all training elements for relationship classification, and recalculate them iteratively. Second, the volume of the DRMC working code used by us is large / can be downloaded from the https / https / large."}, {"heading": "Acknowledgments", "text": "This work is supported by the National Program on Key Basic Research Project (973 Program) under Grant 2013CB329304, the National Science Foundation of China (NSFC) under Grant No.61373075 and HTC Laboratory."}], "references": [{"title": "Freebase: A shared database of structured general human knowledge", "author": ["Robert Cook", "Patrick Tufts"], "venue": "In Proceedings of the national conference on Artificial Intelligence,", "citeRegEx": "Bollacker et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2007}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "In Proceedings of the 2008 ACM SIGMOD international", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Matrix completion for multi-label image classification", "author": ["Fernando Torre", "Jo\u00e3o P Costeira", "Alexandre Bernardino"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Cabral et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cabral et al\\.", "year": 2011}, {"title": "Exact matrix completion via convex optimization", "author": ["Cand\u00e8s", "Recht2009] Emmanuel J Cand\u00e8s", "Benjamin Recht"], "venue": "Foundations of Computational mathematics,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2009}, {"title": "Foundations of Large-Scale Multimedia Information Management and Retrieval", "author": ["Edward Y Chang"], "venue": null, "citeRegEx": "Chang.,? \\Q2011\\E", "shortCiteRegEx": "Chang.", "year": 2011}, {"title": "A generalization of principal components analysis to the exponential family", "author": ["Sanjoy Dasgupta", "Robert E Schapire"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Collins et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Collins et al\\.", "year": 2001}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["Craven", "Kumlien1999] Mark Craven", "Johan Kumlien"], "venue": "In ISMB,", "citeRegEx": "Craven et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Craven et al\\.", "year": 1999}, {"title": "A rank minimization heuristic with application to minimum order system", "author": ["Fazel et al.2001] Maryam Fazel", "Haitham Hindi", "Stephen P Boyd"], "venue": null, "citeRegEx": "Fazel et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Fazel et al\\.", "year": 2001}, {"title": "Transduction with matrix completion: Three birds with one stone", "author": ["Ben Recht", "Junming Xu", "Robert Nowak", "Xiaojin Zhu"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Goldberg et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2010}, {"title": "Convergence of fixed-point continuation algorithms for matrix rank minimization", "author": ["Goldfarb", "Ma2011] Donald Goldfarb", "Shiqian Ma"], "venue": "Foundations of Computational Mathematics,", "citeRegEx": "Goldfarb et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Goldfarb et al\\.", "year": 2011}, {"title": "Calculating the singular values and pseudo-inverse of a matrix", "author": ["Golub", "Kahan1965] Gene Golub", "William Kahan"], "venue": "Journal of the Society for Industrial & Applied Mathematics, Series B: Numerical Analysis,", "citeRegEx": "Golub et al\\.,? \\Q1965\\E", "shortCiteRegEx": "Golub et al\\.", "year": 1965}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S. Weld"], "venue": "In Proceedings of the 49th Annual Meeting", "citeRegEx": "Hoffmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "Why the logistic function? a tutorial discussion on probabilities and neural networks. Computational Cognitive Science Technical Report", "author": ["Michael Jordan"], "venue": null, "citeRegEx": "Jordan.,? \\Q1995\\E", "shortCiteRegEx": "Jordan.", "year": 1995}, {"title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model", "author": ["Yehuda Koren"], "venue": "In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Koren.,? \\Q2008\\E", "shortCiteRegEx": "Koren.", "year": 2008}, {"title": "Fixed point and bregman iterative methods for matrix rank minimization", "author": ["Ma et al.2011] Shiqian Ma", "Donald Goldfarb", "Lifeng Chen"], "venue": "Mathematical Programming,", "citeRegEx": "Ma et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2011}, {"title": "A framework for multiple-instance learning", "author": ["Maron", "Lozano-P\u00e9rez1998] Oded Maron", "Tom\u00e1s Lozano-P\u00e9rez"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Maron et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Maron et al\\.", "year": 1998}, {"title": "Distant supervision for relation extraction with an incomplete knowledge base", "author": ["Min et al.2013] Bonan Min", "Ralph Grishman", "Li Wan", "Chang Wang", "David Gondek"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Asso-", "citeRegEx": "Min et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Min et al\\.", "year": 2013}, {"title": "Fast maximum margin matrix factorization for collaborative prediction", "author": ["Rennie", "Srebro2005] Jasson DM Rennie", "Nathan Srebro"], "venue": "In Proceedings of the 22nd international conference on Machine learning,", "citeRegEx": "Rennie et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Rennie et al\\.", "year": 2005}, {"title": "Modeling relations and their mentions without labeled text", "author": ["Limin Yao", "Andrew McCallum"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "Riedel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Relation extraction with matrix factorization and universal schemas", "author": ["Limin Yao", "Andrew McCallum", "Benjamin M. Marlin"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Asso-", "citeRegEx": "Riedel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2013}, {"title": "Learning syntactic patterns for automatic hypernym discovery", "author": ["Snow et al.2004] Rion Snow", "Daniel Jurafsky", "Andrew Y Ng"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Snow et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Snow et al\\.", "year": 2004}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["Julie Tibshirani", "Ramesh Nallapati", "Christopher D Manning"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Surdeanu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "Reducing wrong labels in distant supervision for relation extraction", "author": ["Issei Sato", "Hiroshi Nakagawa"], "venue": "In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long", "citeRegEx": "Takamatsu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Takamatsu et al\\.", "year": 2012}, {"title": "Filling knowledge base gaps for distant supervision of relation extraction", "author": ["Xu et al.2013] Wei Xu", "Raphael Hoffmann", "Le Zhao", "Ralph Grishman"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Xu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2013}, {"title": "Towards accurate distant supervision for relational facts extraction", "author": ["Zhang et al.2013] Xingxing Zhang", "Jianwen Zhang", "Junyu Zeng", "Jun Yan", "Zheng Chen", "Zhifang Sui"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computa-", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}, {"title": "Exploring various knowledge in relation extraction", "author": ["Zhou et al.2005] Guodong Zhou", "Jian Su", "Jie Zhang", "Min Zhang"], "venue": "In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Zhou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 25, "context": "Traditional supervised methods (Zhou et al., 2005; Bach and Badaskar, 2007) on small hand-labeled corpora, such as MUC1 and ACE2, can achieve high precision and recall.", "startOffset": 31, "endOffset": 75}, {"referenceID": 11, "context": ", 2009) or weak (Hoffmann et al., 2011) supervision paradigm attractive, and we improve the effectiveness of the paradigm in this paper.", "startOffset": 16, "endOffset": 39}, {"referenceID": 14, "context": "We also modify the fixed point continuation (FPC) algorithm (Ma et al., 2011) to find the global optimum.", "startOffset": 60, "endOffset": 77}, {"referenceID": 1, "context": "(2009) adopted Freebase (Bollacker et al., 2008; Bollacker et al., 2007), a large-scale crowdsourcing knowledge base online which contains billions of relation instances and thousands of relation names, to distantly supervise Wikipedia corpus.", "startOffset": 24, "endOffset": 72}, {"referenceID": 0, "context": "(2009) adopted Freebase (Bollacker et al., 2008; Bollacker et al., 2007), a large-scale crowdsourcing knowledge base online which contains billions of relation instances and thousands of relation names, to distantly supervise Wikipedia corpus.", "startOffset": 24, "endOffset": 72}, {"referenceID": 15, "context": "Snow et al. (2004) used WordNet as the knowledge base to discover more hpyernym/hyponym relations between entities from news articles.", "startOffset": 0, "endOffset": 19}, {"referenceID": 15, "context": "Snow et al. (2004) used WordNet as the knowledge base to discover more hpyernym/hyponym relations between entities from news articles. However, either bioinformatic database or WordNet is maintained by a few experts, thus hardly kept up-to-date. As we are stepping into the big data era, the explosion of unstructured Web texts simulates us to build more powerful models that can automatically extract relation instances from large-scale online natural language corpora without handlabeled annotation. Mintz et al. (2009) adopted Freebase (Bollacker et al.", "startOffset": 0, "endOffset": 522}, {"referenceID": 0, "context": "(2009) adopted Freebase (Bollacker et al., 2008; Bollacker et al., 2007), a large-scale crowdsourcing knowledge base online which contains billions of relation instances and thousands of relation names, to distantly supervise Wikipedia corpus. The basic alignment assumption of this work is that if a pair of entities participate in a relation, all sentences that mention these entities are labeled by that relation name. Then we can extract a variety of textual features and learn a multi-class logistic regression classifier. Inspired by multi-instance learning (Maron and Lozano-P\u00e9rez, 1998), Riedel et al. (2010) relaxed the strong assumption and replaced all sentences with at least one sentence.", "startOffset": 25, "endOffset": 617}, {"referenceID": 0, "context": "(2009) adopted Freebase (Bollacker et al., 2008; Bollacker et al., 2007), a large-scale crowdsourcing knowledge base online which contains billions of relation instances and thousands of relation names, to distantly supervise Wikipedia corpus. The basic alignment assumption of this work is that if a pair of entities participate in a relation, all sentences that mention these entities are labeled by that relation name. Then we can extract a variety of textual features and learn a multi-class logistic regression classifier. Inspired by multi-instance learning (Maron and Lozano-P\u00e9rez, 1998), Riedel et al. (2010) relaxed the strong assumption and replaced all sentences with at least one sentence. Hoffmann et al. (2011) pointed out that many entity", "startOffset": 25, "endOffset": 725}, {"referenceID": 18, "context": "They extended the multi-instance learning framework (Riedel et al., 2010) to the multi-label circumstance.", "startOffset": 52, "endOffset": 73}, {"referenceID": 22, "context": "Other literatures (Takamatsu et al., 2012; Min et al., 2013; Zhang et al., 2013; Xu et al., 2013) addressed more specific issues, like how to construct the negative class in learning or how to adopt more information, such as name entity tags, to improve the performance.", "startOffset": 18, "endOffset": 97}, {"referenceID": 16, "context": "Other literatures (Takamatsu et al., 2012; Min et al., 2013; Zhang et al., 2013; Xu et al., 2013) addressed more specific issues, like how to construct the negative class in learning or how to adopt more information, such as name entity tags, to improve the performance.", "startOffset": 18, "endOffset": 97}, {"referenceID": 24, "context": "Other literatures (Takamatsu et al., 2012; Min et al., 2013; Zhang et al., 2013; Xu et al., 2013) addressed more specific issues, like how to construct the negative class in learning or how to adopt more information, such as name entity tags, to improve the performance.", "startOffset": 18, "endOffset": 97}, {"referenceID": 23, "context": "Other literatures (Takamatsu et al., 2012; Min et al., 2013; Zhang et al., 2013; Xu et al., 2013) addressed more specific issues, like how to construct the negative class in learning or how to adopt more information, such as name entity tags, to improve the performance.", "startOffset": 18, "endOffset": 97}, {"referenceID": 17, "context": "They extended the multi-instance learning framework (Riedel et al., 2010) to the multi-label circumstance. Surdeanu et al. (2012) proposed a novel approach to multi-instance multi-label learning for relation extraction, which jointly modeled all the sentences in texts and all labels in knowledge bases for a given entity pair.", "startOffset": 53, "endOffset": 130}, {"referenceID": 5, "context": "Their approach is composed of several models, such as PCA (Collins et al., 2001) and collaborative filtering (Koren, 2008).", "startOffset": 58, "endOffset": 80}, {"referenceID": 13, "context": ", 2001) and collaborative filtering (Koren, 2008).", "startOffset": 36, "endOffset": 49}, {"referenceID": 16, "context": "Our work is more relevant to Riedel et al.\u2019s (2013) which considered the task as a matrix factorization problem.", "startOffset": 29, "endOffset": 52}, {"referenceID": 2, "context": "This promising theory has been successfully applied on many active research areas, such as computer vision (Cabral et al., 2011), recommender system (Rennie and Srebro, 2005) and system controlling (Fazel et al.", "startOffset": 107, "endOffset": 128}, {"referenceID": 7, "context": ", 2011), recommender system (Rennie and Srebro, 2005) and system controlling (Fazel et al., 2001).", "startOffset": 77, "endOffset": 97}, {"referenceID": 2, "context": "This promising theory has been successfully applied on many active research areas, such as computer vision (Cabral et al., 2011), recommender system (Rennie and Srebro, 2005) and system controlling (Fazel et al., 2001). Our models for relation extraction are based on the theoretic framework proposed by Goldberg et al. (2010), which formulated the multi-label transductive learning as a matrix completion problem.", "startOffset": 108, "endOffset": 327}, {"referenceID": 12, "context": "We assume that the actual entry u belonging to the underlying matrix Z\u2217 is randomly generated via a sigmoid function (Jordan, 1995): Pr(u|v) = 1/(1 + e\u2212uv), given the observed binary entry v from the observed sparse matrix Z.", "startOffset": 117, "endOffset": 131}, {"referenceID": 14, "context": "Then, Ma et al. (2011) proposed the fixed point continuation (FPC) algorithm which is fast and robust.", "startOffset": 6, "endOffset": 23}, {"referenceID": 14, "context": "Then, Ma et al. (2011) proposed the fixed point continuation (FPC) algorithm which is fast and robust. Moreover, Goldfrab and Ma (2011) proved the convergence of the FPC algorithm for solving the nuclear norm minimization problem.", "startOffset": 6, "endOffset": 136}, {"referenceID": 11, "context": "In order to conduct reliable experiments, we adjust and estimate the parameters for our approaches, DRMC-b and DRMC-1, and compare them with other four kinds of landmark methods (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012; Riedel et al., 2013) on two public datasets.", "startOffset": 178, "endOffset": 265}, {"referenceID": 21, "context": "In order to conduct reliable experiments, we adjust and estimate the parameters for our approaches, DRMC-b and DRMC-1, and compare them with other four kinds of landmark methods (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012; Riedel et al., 2013) on two public datasets.", "startOffset": 178, "endOffset": 265}, {"referenceID": 19, "context": "In order to conduct reliable experiments, we adjust and estimate the parameters for our approaches, DRMC-b and DRMC-1, and compare them with other four kinds of landmark methods (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012; Riedel et al., 2013) on two public datasets.", "startOffset": 178, "endOffset": 265}, {"referenceID": 17, "context": "The first dataset12, NYT\u201910, was developed by Riedel et al. (2010), and also used by Hoffmann et al.", "startOffset": 46, "endOffset": 67}, {"referenceID": 11, "context": "(2010), and also used by Hoffmann et al. (2011) and Surdeanu et al.", "startOffset": 25, "endOffset": 48}, {"referenceID": 11, "context": "(2010), and also used by Hoffmann et al. (2011) and Surdeanu et al. (2012). Three kinds of features, namely, lexical, syntactic and named entity tag features, were extracted from relation mentions.", "startOffset": 25, "endOffset": 75}, {"referenceID": 11, "context": "(2010), and also used by Hoffmann et al. (2011) and Surdeanu et al. (2012). Three kinds of features, namely, lexical, syntactic and named entity tag features, were extracted from relation mentions. The second dataset13, NYT\u201913, was also released by Riedel et al. (2013), in which they only regarded the lexicalized dependency path between two entities as features.", "startOffset": 25, "endOffset": 270}, {"referenceID": 8, "context": "edu/riedel/data-univSchema/ We follow the suggestion in (Goldberg et al., 2010) that \u03bc starts at \u03c31\u03b7\u03bc, and \u03c31 is the largest singular value of the matrix Z.", "startOffset": 56, "endOffset": 79}, {"referenceID": 8, "context": "edu/riedel/data-univSchema/ We follow the suggestion in (Goldberg et al., 2010) that \u03bc starts at \u03c31\u03b7\u03bc, and \u03c31 is the largest singular value of the matrix Z. We set \u03b7\u03bc = 0.01. The final value of \u03bc, namely \u03bcF , is equal to 0.01. Ma et al. (2011) revealed that as long as the nonnegative step sizes satisfy \u03c4z < min( 4|\u03a9Y | \u03bb , |\u03a9X |) and \u03c4b < 4|\u03a9Y | \u03bb(n+m) , the FPC algorithm will guarantee to converge to a global optimum.", "startOffset": 57, "endOffset": 244}, {"referenceID": 11, "context": ", 2009), MultiR-11 (Hoffmann et al., 2011), MIML-12 and MIML-at-least-one-12 (Surdeanu et al.", "startOffset": 19, "endOffset": 42}, {"referenceID": 21, "context": ", 2011), MIML-12 and MIML-at-least-one-12 (Surdeanu et al., 2012) on NYT\u201910 dataset.", "startOffset": 42, "endOffset": 65}, {"referenceID": 11, "context": ", 2009), MultiR-11 (Hoffmann et al., 2011), MIML-12 and MIML-at-least-one-12 (Surdeanu et al., 2012) on NYT\u201910 dataset. Surdeanu et al. (2012) released the open source code15 to reproduce the experimental results on those previous methods.", "startOffset": 20, "endOffset": 143}, {"referenceID": 19, "context": "We also perform the experiments to compare our approaches with the state-of-the-art NFE-1316 (Riedel et al., 2013) and its sub-methods (N-13, F-13 and NF-13) on NYT\u201913 dataset.", "startOffset": 93, "endOffset": 114}, {"referenceID": 19, "context": "Top-500s for DRMC-1, DRMC-b and the state-ofthe-art method NFE-13 (Riedel et al., 2013).", "startOffset": 66, "endOffset": 87}, {"referenceID": 21, "context": "We relax the feature filtering threshold (\u03b8 = 4, 3, 2) in Surdeanu et al.\u2019s (2012) open source program to generate more sparse features from NYT\u201910 dataset.", "startOffset": 58, "endOffset": 83}, {"referenceID": 4, "context": "For the future work, we plan to improve our models so that they will be capable of incremental learning on large-scale datasets (Chang, 2011).", "startOffset": 128, "endOffset": 141}], "year": 2014, "abstractText": "The essence of distantly supervised relation extraction is that it is an incomplete multi-label classification problem with sparse and noisy features. To tackle the sparsity and noise challenges, we propose solving the classification problem using matrix completion on factorized matrix of minimized rank. We formulate relation classification as completing the unknown labels of testing items (entity pairs) in a sparse matrix that concatenates training and testing textual features with training labels. Our algorithmic framework is based on the assumption that the rank of item-by-feature and item-by-label joint matrix is low. We apply two optimization models to recover the underlying low-rank matrix leveraging the sparsity of featurelabel matrix. The matrix completion problem is then solved by the fixed point continuation (FPC) algorithm, which can find the global optimum. Experiments on two widely used datasets with different dimensions of textual features demonstrate that our low-rank matrix completion approach significantly outperforms the baseline and the state-of-the-art methods.", "creator": "LaTeX with hyperref package"}}}