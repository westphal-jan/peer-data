{"id": "1411.6591", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Oct-2014", "title": "A Latent Source Model for Online Collaborative Filtering", "abstract": "Despite the prevalence of collaborative filtering in recommendation systems, there has been little theoretical development on why and how well it works, especially in the \"online\" setting, where items are recommended to users over time. We address this theoretical gap by introducing a model for online recommendation systems, cast item recommendation under the model as a learning problem, and analyze the performance of a cosine-similarity collaborative filtering method. In our model, each of $n$ users either likes or dislikes each of $m$ items. We assume there to be $k$ types of users, and all the users of a given type share a common string of probabilities determining the chance of liking each item. At each time step, we recommend an item to each user, where a key distinction from related bandit literature is that once a user consumes an item (e.g., watches a movie), then that item cannot be recommended to the same user again. The goal is to maximize the number of likable items recommended to users over time. Our main result establishes that after nearly $\\log(km)$ initial learning time steps, a simple collaborative filtering algorithm achieves essentially optimal performance without knowing $k$. The algorithm has an exploitation step that uses cosine similarity and two types of exploration steps, one to explore the space of items (standard in the literature) and the other to explore similarity between users (novel to this work).", "histories": [["v1", "Fri, 31 Oct 2014 19:59:59 GMT  (554kb,D)", "http://arxiv.org/abs/1411.6591v1", "Advances in Neural Information Processing Systems (NIPS 2014)"]], "COMMENTS": "Advances in Neural Information Processing Systems (NIPS 2014)", "reviews": [], "SUBJECTS": "cs.LG cs.IR stat.ML", "authors": ["guy bresler", "george h chen", "devavrat shah"], "accepted": true, "id": "1411.6591"}, "pdf": {"name": "1411.6591.pdf", "metadata": {"source": "CRF", "title": "A Latent Source Model for Online Collaborative Filtering", "authors": ["Guy Bresler", "George H. Chen", "Devavrat Shah"], "emails": ["gbresler@mit.edu", "georgehc@mit.edu", "devavrat@mit.edu"], "sections": [{"heading": "1 Introduction", "text": "In practice, recommendations are often made through collaborative filtering systems, which amount to recommending an article to a user that other similar or \"close\" users like. Collaborative filtering methods have been widely used for decades, including the messaging system GroupLens. [20] Amazon's article recommendation system boils down to developing an algorithm that emanates from BellKor's Pragmatic Chaos. [16] And a current song recommendation system that wins the Million Dataset Challenge. [17] Most such systems operate in the environment."}, {"heading": "2 A Model and Learning Problem for Online Recommendations", "text": "We consider a system with n users and m-Items (T) as a system with n users and m-Items (T). We consider a system with n users and m-Items (T) as a system with n-Items (T) as a system with n-Items (T). We assume that a user with n-Items (T) -Items (T) -Items (T) -Items (T) -Items (T) -Items (T) -Items (T) -Items (T) -Items (T) -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Items -Ite"}, {"heading": "3 A Collaborative Filtering Algorithm and Its Performance Guarantee", "text": "This section introduces our algorithms, which are recommended to each user by selecting the object with the highest score that is intended for the user. There are two types of articles in which a user is recommended an item that he has not yet consumed, and a common exploration in which all users are asked to provide a rating for the next item in a split, randomly selected sequence of items. Let's fill in the detail. algorithm t, either all users are asked to explore an item or select an item with the highest score for the user."}, {"heading": "4 Proof of Theorem 1", "text": "Remember that Xut is the indicator of good neighbourliness that enables us to argue that after an initial period, there is a high probability of two bad neighbours."}, {"heading": "5 Experimental Results", "text": "We only offer a summary of our experimental results here which is unrepresentative of the actual rating system. We are simulating an online recommendation system based on movie ratings from the Movielens10m and Netflix datasets, each of which provides a sparsely filled user-by-movie rating matrix with ratings of 5 stars. Unfortunately, the existing collaborative filtering of datasets like the two we are looking at cannot provide the interactivity of a real online recommendation system, nor do they allow us to reveal the rating for an item that a user has actually not rated. For the simulation of an online system, the former issue can be addressed by simply looking at revealing entries in the user-by-item rating matrix over time. We address the latter by looking at only a subset of individual datasets. Specifically, we are looking only at the \"top\" users who have rated the most articles, and the \"top\" ones who have received the number of reviews and the most reviews."}, {"heading": "6 Discussion and Related Work", "text": "This paper proposes a model for online recommendation systems under which we can analyze the performance of recommendation algorithms. Theoretically, if a cosmic similarity works well, we justify collaborative filtering method with a key finding of the use of two types of exploration. Barman and Dabeer [4], who investigate the asymptotic consistency of a collaborative filtering method nearby, aim to predict the rating of the next invisible point. Barman and Dabeer [5] investigate the performance of an algorithm called popularity among friends by examining its ability to predict binary ratings in an asymptomatic information system."}, {"heading": "A Appendix", "text": "If it is clear from the context, we omit the argument (t) for indexing time in all our derivatives, i.e. write Yu instead of Yu (t)."}, {"heading": "A.1 Proof of Lemma 1", "text": "We reproduce lemmas 1 below to facilitate the presentation. Allow us the number of users out of the system k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k..k.k..k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k.k..k..k..k..k..k...k..k..k...k..k..k...k...k..k..k...k..k.....k...k...k.....k...k.....k......k.....k......k....k.....k......k.....k.....k.k.....k...........k.....k.k....k.k.....k....k......k..............k.............k.......k....k..............k..............k.......k.......k....................."}, {"heading": "A.1.1 Proof of Lemma 6", "text": "Let's start with a preliminary problem that increases the probability that two users of the same type will not be declared as equivalent.Lemma 8. Let's assume that there are no unique items for all user types. Let's first assume that user u and v have exactly 0 items in common. If < Y and V are not declared as neighbors, let's assume that user u and v have exactly 0 items in common. Let's assume that user u and v have exactly 0 items in common. The two users will not be declared as neighbors if < Y and V are not declared as equivalent. Let's assume that user u and v have exactly 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0 items 0."}, {"heading": "A.1.2 Proof of Lemma 7", "text": "Starting with a preliminary problem, the probability that two users of different types will be declared neighbors is higher than the probability that two users of different types will be declared neighbors. < u > u = > Inconsistent properties will be satisfied for all users (0, 1) If users u and v have different types and assume that they have declared at least 0 items as neighbors declared jointly by joint exploration, we assume that these items (0, 1) are satisfied. As with the evidence of Lemma 8, we will first analyze the case in which users u and v rated exactly 0 items as neighbors. Users u and v will be declared neighbors if < Y items are declared neighbors, Y items are 0, Y items selected by joint exploration."}, {"heading": "A.2 Proof of Lemma 2", "text": "We reproduce Lemma 2 below Lemma 2. For user u at present t, if the good neighborhood holds Egood (u, t) and t \u2264 \u00b5m, thenP (u, t) holds for user u (u, t) holds the good neighborhood Egood (u, t) holds for user u (u, t) holds the good neighborhood Egood (u, t) holds for user u (u, t) holds the good neighborhood Egood (u, t). Lemma 10. For user u at present t, we assume that the good neighborhood holds Egood (u, t). Then for a specific element i, P (item i, t) has the 1 \u2212 10 km rating of good neighbor u) \u2264 exp (\u2212 tn 1 \u2212 40 km).Proof. The number of users u's good neighbors who have rated an element i dominates a Bin (n5k, \u03b5R) t (n) t (m) random variable."}, {"heading": "A.3 Experimental Results", "text": "We demonstrate our algorithm COLLABORATIVE-GREEDY on two sets of data, which unfortunately are filled with two ratings, showing that they have comparable performance and that they both outperform two existing recommendation algorithms. Popularity amongst Friends (PAF) and Deshpande and Montanari's Method (DM). At each step that goes beyond a pre-processing step, PAF considers the next users (\"friends\") for each user and recommends to a user the \"most popular\" element, i.e. the one with the highest number of + 1 ratings, among the user's friends. DM does not collaborate that goes beyond a pre-processing step, which calculates element characteristics vectors via matrix completion. Then, during the online recommendation, DM learns the user characteristics vectors over time using the article characteristics vectors and recommends to each user an element based on the question of whether it works well with the online recommendation system."}], "references": [{"title": "A preliminary study on a recommender system for the million songs dataset challenge", "author": ["Fabio Aiolli"], "venue": "In Proceedings of the Italian Information Retrieval Workshop,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Tensor decompositions for learning latent variable", "author": ["Anima Anandkumar", "Rong Ge", "Daniel Hsu", "Sham M. Kakade", "Matus Telgarsky"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Finite-time analysis of the multiarmed bandit problem", "author": ["Peter Auer", "Nicol\u00f2 Cesa-Bianchi", "Paul Fischer"], "venue": "Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Analysis of a collaborative filter based on popularity amongst neighbors", "author": ["Kishor Barman", "Onkar Dabeer"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Polynomial learning of distribution families", "author": ["Mikhail Belkin", "Kaushik Sinha"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2010}, {"title": "The million song dataset", "author": ["Thierry Bertin-Mahieux", "Daniel P.W. Ellis", "Brian Whitman", "Paul Lamere"], "venue": "In Proceedings of the 12th International Conference on Music Information Retrieval", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Statistical analysis of k-nearest neighbor collaborative recommendation", "author": ["G\u00e9rard Biau", "Beno\u0131\u0302t Cadre", "Laurent Rouvi\u00e8re"], "venue": "The Annals of Statistics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Regret analysis of stochastic and nonstochastic multi-armed bandit problems", "author": ["S\u00e9bastien Bubeck", "Nicol\u00f2 Cesa-Bianchi"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "Learning mixtures of product distributions using correlations and independence", "author": ["Kamalika Chaudhuri", "Satish Rao"], "venue": "In Conference on Learning Theory,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2008}, {"title": "Adaptive collaborating filtering: The low noise regime", "author": ["Onkar Dabeer"], "venue": "In IEEE International Symposium on Information Theory, pages 1197\u20131201,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Linear bandits in high dimension and recommendation", "author": ["Yash Deshpande", "Andrea Montanari"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Exploiting compositionality to explore a large space of model structures", "author": ["Roger B. Grosse", "Ruslan Salakhutdinov", "William T. Freeman", "Joshua B. Tenenbaum"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["Wassily Hoeffding"], "venue": "Journal of the American statistical association,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1963}, {"title": "Regret bounds for sleeping experts and bandits", "author": ["Robert Kleinberg", "Alexandru Niculescu-Mizil", "Yogeshwer Sharma"], "venue": "Machine Learning,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "The BellKor solution to the Netflix grand prize. http://www.netflixprize.com/ assets/GrandPrize2009_BPC_BellKor.pdf", "author": ["Yehuda Koren"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Amazon.com recommendations: item-to-item collaborative filtering", "author": ["Greg Linden", "Brent Smith", "Jeremy York"], "venue": "IEEE Internet Computing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2003}, {"title": "Settling the polynomial learnability of mixtures of gaussians", "author": ["Ankur Moitra", "Gregory Valiant"], "venue": "Proceedings of the 51st Annual IEEE Symposium on Foundations of Computer Science,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2010}, {"title": "The pragmatic theory solution to the netflix grand prize", "author": ["Martin Piotte", "Martin Chabbert"], "venue": "http:// www.netflixprize.com/assets/GrandPrize2009_BPC_PragmaticTheory.pdf,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Grouplens: An open architecture for collaborative filtering of netnews", "author": ["Paul Resnick", "Neophytos Iacovou", "Mitesh Suchak", "Peter Bergstrom", "John Riedl"], "venue": "In Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work, CSCW", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1994}, {"title": "Modelling relational data using bayesian clustered tensor factorization", "author": ["Ilya Sutskever", "Ruslan Salakhutdinov", "Joshua B. Tenenbaum"], "venue": "In NIPS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Reinforcement Learning: An Introduction", "author": ["Richard S. Sutton", "Andrew G. Barto"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1998}, {"title": "On the Likelihood that one Unknown Probability Exceeds", "author": ["William R. Thompson"], "venue": "Another in View of the Evidence of Two Samples. Biometrika,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 1933}], "referenceMentions": [{"referenceID": 18, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 120, "endOffset": 124}, {"referenceID": 15, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 162, "endOffset": 166}, {"referenceID": 14, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 233, "endOffset": 245}, {"referenceID": 17, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 233, "endOffset": 245}, {"referenceID": 0, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 287, "endOffset": 290}, {"referenceID": 5, "context": "Collaborative filtering has been used extensively for decades now including in the GroupLens news recommendation system [20], Amazon\u2019s item recommendation system [17], the Netflix Prize winning algorithm by BellKor\u2019s Pragmatic Chaos [16, 24, 19], and a recent song recommendation system [1] that won the Million Song Dataset Challenge [6].", "startOffset": 335, "endOffset": 338}, {"referenceID": 0, "context": "The ratings are noisy: the latent item preferences for user u are represented by a length-m vector pu \u2208 [0, 1], where user u likes item i with probability pui, independently across items.", "startOffset": 104, "endOffset": 110}, {"referenceID": 19, "context": "We remark that there is evidence suggesting real movie recommendation data to be well modeled by clustering of both users and items [21].", "startOffset": 132, "endOffset": 136}, {"referenceID": 21, "context": "A fundamental difference between our setup and that of the standard stochastic multi-armed bandit problem [23, 8] is that the latter allows each item to be recommended an infinite number of times.", "startOffset": 106, "endOffset": 113}, {"referenceID": 7, "context": "A fundamental difference between our setup and that of the standard stochastic multi-armed bandit problem [23, 8] is that the latter allows each item to be recommended an infinite number of times.", "startOffset": 106, "endOffset": 113}, {"referenceID": 2, "context": "Thus, the solution concept for the stochastic multi-armed bandit problem is to determine the best item (arm) and keep choosing it [3].", "startOffset": 130, "endOffset": 133}, {"referenceID": 13, "context": "On the other hand, sleeping bandits [15] allow for the available items at each time step to vary, but the analysis is worst-case in terms of which items are available over time.", "startOffset": 36, "endOffset": 40}, {"referenceID": 20, "context": "The algorithm is syntactically similar to the \u03b5-greedy algorithm for multiarmed bandits [22], which explores items with probability \u03b5 and otherwise greedily chooses the best item seen so far based on a plurality vote.", "startOffset": 88, "endOffset": 92}, {"referenceID": 0, "context": "Algorithm 1: COLLABORATIVE-GREEDY Input: Parameters \u03b8 \u2208 [0, 1], \u03b1 \u2208 (0, 4/7].", "startOffset": 56, "endOffset": 62}, {"referenceID": 19, "context": "The clustering was found via Bayesian clustered tensor factorization, which was previously shown to model real movie ratings data well [21].", "startOffset": 135, "endOffset": 139}, {"referenceID": 3, "context": "Next, we demonstrate our algorithm COLLABORATIVE-GREEDY on the two simulated online movie recommendation systems, showing that it outperforms two existing recommendation algorithms Popularity Amongst Friends (PAF) [4] and a method by Deshpande and Montanari (DM) [12].", "startOffset": 214, "endOffset": 217}, {"referenceID": 10, "context": "Next, we demonstrate our algorithm COLLABORATIVE-GREEDY on the two simulated online movie recommendation systems, showing that it outperforms two existing recommendation algorithms Popularity Amongst Friends (PAF) [4] and a method by Deshpande and Montanari (DM) [12].", "startOffset": 263, "endOffset": 267}, {"referenceID": 3, "context": "Following the experimental setup of [4], we quantize a rating of 4 stars or more to be +1 (likable), and a rating less than 4 stars to be \u22121 (unlikable).", "startOffset": 36, "endOffset": 39}, {"referenceID": 6, "context": "[7], who study the asymptotic consistency of a cosinesimilarity nearest-neighbor collaborative filtering method.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "Barman and Dabeer [4] study the performance of an algorithm called Popularity Amongst Friends, examining its ability to predict binary ratings in an asymptotic informationtheoretic setting.", "startOffset": 18, "endOffset": 21}, {"referenceID": 9, "context": "Dabeer [11] uses a model similar to ours and studies online collaborative filtering with a moving horizon cost in the limit of small noise using an algorithm that knows the numbers of user types and item types.", "startOffset": 7, "endOffset": 11}, {"referenceID": 10, "context": "Another related work is by Deshpande and Montanari [12], who study online recommendations as a linear bandit problem; their method, however, does not actually use any collaboration beyond a pre-processing step in which offline collaborative filtering (specifically matrix completion) is solved to compute feature vectors for items.", "startOffset": 51, "endOffset": 55}, {"referenceID": 8, "context": ", [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights.", "startOffset": 2, "endOffset": 16}, {"referenceID": 16, "context": ", [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights.", "startOffset": 2, "endOffset": 16}, {"referenceID": 4, "context": ", [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights.", "startOffset": 2, "endOffset": 16}, {"referenceID": 1, "context": ", [10, 18, 5, 2]), where one observes samples from a mixture distribution and the goal is to learn the mixture components and weights.", "startOffset": 2, "endOffset": 16}], "year": 2014, "abstractText": "Despite the prevalence of collaborative filtering in recommendation systems, there has been little theoretical development on why and how well it works, especially in the \u201conline\u201d setting, where items are recommended to users over time. We address this theoretical gap by introducing a model for online recommendation systems, cast item recommendation under the model as a learning problem, and analyze the performance of a cosine-similarity collaborative filtering method. In our model, each of n users either likes or dislikes each of m items. We assume there to be k types of users, and all the users of a given type share a common string of probabilities determining the chance of liking each item. At each time step, we recommend an item to each user, where a key distinction from related bandit literature is that once a user consumes an item (e.g., watches a movie), then that item cannot be recommended to the same user again. The goal is to maximize the number of likable items recommended to users over time. Our main result establishes that after nearly log(km) initial learning time steps, a simple collaborative filtering algorithm achieves essentially optimal performance without knowing k. The algorithm has an exploitation step that uses cosine similarity and two types of exploration steps, one to explore the space of items (standard in the literature) and the other to explore similarity between users (novel to this work).", "creator": "LaTeX with hyperref package"}}}