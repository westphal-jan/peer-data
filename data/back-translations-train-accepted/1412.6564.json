{"id": "1412.6564", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2014", "title": "Move Evaluation in Go Using Deep Convolutional Neural Networks", "abstract": "The game of Go is more challenging than other board games, due to the difficulty of constructing a position or move evaluation function. In this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge. We train a large 12-layer convolutional neural network by supervised learning from a database of human professional games. The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional search program GnuGo in 97% of games, and matched the performance of a state-of-the-art Monte-Carlo tree search that simulates a million positions per move.", "histories": [["v1", "Sat, 20 Dec 2014 00:31:30 GMT  (156kb,D)", "http://arxiv.org/abs/1412.6564v1", null], ["v2", "Fri, 10 Apr 2015 19:03:34 GMT  (419kb,D)", "http://arxiv.org/abs/1412.6564v2", "Minor edits and included captures in Figure 2"]], "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["chris j maddison", "aja huang", "ilya sutskever", "david silver"], "accepted": true, "id": "1412.6564"}, "pdf": {"name": "1412.6564.pdf", "metadata": {"source": "CRF", "title": "MOVE EVALUATION IN GO USING DEEP CONVOLUTIONAL NEURAL NETWORKS", "authors": ["Chris J. Maddison", "Aja Huang", "Ilya Sutskever", "David Silver"], "emails": ["cmaddis@cs.toronto.edu", "ajahuang@google.com", "ilyasu@google.com", "davidsilver@google.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "The most frequently cited reason for the difficulty of Go & Silver, 2011; Enzenberger et al., 2010; Huang et al., 2011 is the difficulty of constructing an evaluation function that can distinguish good traits from bad traits in a particular position. Combining an enormous state space of 10170 positions, combined with sharp tactics that lead to steep nonlinearities in the optimal value function, has led many researchers to conclude that depicting and learning such a function is impossible (Mussler, 2002). In previous years, the most successful methods have actually circumvented this problem with the help of the Monte Carlo Search, which dynamically evaluates a position by random sequences of self-play. Such programs have resulted in strong amateur performance, but a considerable gap remains between top professional gamers and the strongest computer programs. The majority of recent advances is due to increased quantity and quality of previous knowledge, which is used to utilize the search for promising states in both the search tree and during this rollout, Silver et al."}, {"heading": "2 PRIOR WORK", "text": "The resulting program beat a simple, handmade program called Wally. NeuroGo (Enzenberger, 1996) used a more complex architecture to predict final territory, eyes, and connectivity, and again exploited symmetries; and used a connectivity pathfinder to disseminate information about weakly connected groups of stones. Enzenberger's program also used an enhancement of self-play learning. Combined with an alpha beta search, NeuroGo matched the performance of GnuGo on 9 \u00d7 9 Go, reaching about 13 Kyu on 19 \u00d7 19 Go. Sutskever & Nair (2008) applied the conventional network to supervised learning of expert movements."}, {"heading": "3 DATA", "text": "The data set used in this work comes from the KGS server. It consists of sequences of board positions played between people of different rank. Board information includes the position of all tiles on the board of 19x19 and the sequence allows to determine the sequence of moves; one move on it is considered 1 of 361 indicators for each position on the board of 19x191. We learned that Clark & Storkey (2014) adopts a similar approach with a smaller 8-layer CNN encrypted in 86% of the games."}, {"heading": "4 ARCHITECTURE & TRAINING", "text": "In this section we describe the exact network architecture and details of the training procedure. We used a deep convolutionary network with 12 weight matrices for each of them and respected linear non-linearity. The first hidden layers were of size 3 \u00d7 3, with a step from 1 to 2, we also used position-dependent biases (according to Sutskever & Nair), our best models were padded up to 19 \u00d7 19, the number of filters in each layer ranged from 64 to 192, and we used position-dependent biases (according to Sutskever & Nair)."}, {"heading": "5 RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 INVESTIGATION OF WEIGHT SYMMETRIES", "text": "We investigated the effect of weight symmetries on a smaller CNN with 3 or 6 layers. These networks were trained on a reduced functionality, not taking into account rank, freedoms after the pull, catch size, conductor pull and only the history of a train. Results are listed in the following table:% Accuracy 3 layer, 64 filters 43.3 3 3 layer, 64 filters, symmetric 44.3 6 layer, 192 filters 49.6 6 6 layer, 192 filters, symmetric 49.4These results suggest that weight symmetries surprisingly have a strong effect on the prediction of movements for small and flat networks, but the effect seemed to disappear completely in larger and deeper networks."}, {"heading": "5.2 ACCURACY AND PLAYING STRENGTH", "text": "To understand how performance depends on network depth, several networks of different depths were excluded. Each CNN used the same architecture as described above, except that the number of 3 x 3 layers each was 3, 6, 10 and 12. We measured the predictive accuracy on the test set, as well as the strength of the CNN when it was used to directly select moves. This was achieved by entering the current position on the network and selecting the action with maximum probability in the Softmax edition for the current player. Performance was evaluated against the benchmark program GnuGo 3.8 when it was run at its highest level 10. Comparisons are made with the reported values for the 3 dan Monte Carlo search program Aya3; simultaneously published results on a slightly flatter level CNN Clark & Storkey (2014) 4; and also with the predictive accuracy of a 6 dan human (the second author) on randomly selected positions from the test set. All games were evaluated using Chinese Go rules, the Go games were guided by GNugu games."}, {"heading": "6 SEARCH", "text": "To this end, we have tried to integrate our motion prediction network with the Monte Carlo Tree Search (MCTS).Combining MCTS with a large deep neural network is far from trivial, as CNN is slower than the natural speed of the search and it is not possible to evaluate each node with the neural network.The 12-layer network takes 0.15 seconds to create a minibatch size 128.6We address this problem by using asynchronous node evaluation.In asynchronous node evaluation, MCTS builds its search tree and tracks the new nodes that are added to the search tree. If the number of new nodes corresponds to the size of the minibatch, all these new positions are submitted to CNN for evaluation on a GPU. The GPU calculates the motion recommendations while the search continues in parallel. Once the GPU calculation is complete, the previous knowledge in the new search will be significantly updated."}, {"heading": "7 DISCUSSION", "text": "In this work, we have shown that large deep Convolutionary Neural Networks can predict the next step taken by Go experts with an accuracy far superior to previous methods and roughly in line with human performance; in addition, this predictive accuracy results in much stronger pull rating and game. without Clark & Storkey's any5The 8-layer network (2014), 12% of games against Fuego won using time limits equivalent to about 5,000 rollouts per turn. 6The reduction in minibatch size accelerates the end-to-end computation time in our GPU implementation.search, the network is able to outperform traditional search-based programs such as GnuGo and with state-of-the-art MCTS programs such as Pachi and Fuego.In Figure 2, we present an example game played by the 12-layer CNN (without search) versus Fuego (search for 100K rollouts per turn), which was explicitly won by the network player."}], "references": [{"title": "Progressive strategies for Monte-Carlo tree search", "author": ["Chaslot", "Guillaume M. J-B", "Winands", "Mark H. M", "van den Herik", "H. Jaap", "Uiterwijk", "Jos W.H. M", "Bouzy", "Bruno"], "venue": "New Mathematics and Natural Computation,", "citeRegEx": "Chaslot et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chaslot et al\\.", "year": 2008}, {"title": "Teaching deep convolutional neural networks to play Go", "author": ["Clark", "Christopher", "Storkey", "Amos"], "venue": "arXiv preprint arXiv:1412.3409,", "citeRegEx": "Clark et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2014}, {"title": "Efficient selectivity and backup operators in Monte-Carlo tree search", "author": ["Coulom", "R\u00e9mi"], "venue": "In Computers and games,", "citeRegEx": "Coulom and R\u00e9mi.,? \\Q2007\\E", "shortCiteRegEx": "Coulom and R\u00e9mi.", "year": 2007}, {"title": "Large scale distributed deep networks", "author": ["Dean", "Jeffrey", "Corrado", "Greg", "Monga", "Rajat", "Chen", "Kai", "Devin", "Matthieu", "Mao", "Mark", "aurelio Ranzato", "Marc", "Senior", "Andrew", "Tucker", "Paul", "Yang", "Ke", "Le", "Quoc V", "Ng", "Andrew Y"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Dean et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dean et al\\.", "year": 2012}, {"title": "The integration of a priori knowledge into a Go playing neural network", "author": ["Enzenberger", "Markus"], "venue": "URL: http://www. markus-enzenberger. de/neurogo. html,", "citeRegEx": "Enzenberger and Markus.,? \\Q1996\\E", "shortCiteRegEx": "Enzenberger and Markus.", "year": 1996}, {"title": "Fuego - an open-source framework for board games and Go engine based on monte carlo tree search", "author": ["Enzenberger", "Markus", "M\u00fcller", "Martin", "Arneson", "Broderick", "R. Segal"], "venue": "IEEE Trans. Comput. Intellig. and AI in Games,", "citeRegEx": "Enzenberger et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Enzenberger et al\\.", "year": 2010}, {"title": "Combining online and offline learning in UCT", "author": ["S. Gelly", "D. Silver"], "venue": "In 17th International Conference on Machine Learning,", "citeRegEx": "Gelly and Silver,? \\Q2007\\E", "shortCiteRegEx": "Gelly and Silver", "year": 2007}, {"title": "Monte-Carlo tree search and rapid action value estimation in computer Go", "author": ["S. Gelly", "D. Silver"], "venue": "Artificial Intelligence,", "citeRegEx": "Gelly and Silver,? \\Q2011\\E", "shortCiteRegEx": "Gelly and Silver", "year": 2011}, {"title": "Investigating the limits of Monte-Carlo tree search methods in computer Go", "author": ["Huang", "Shih-Chieh", "M\u00fcller", "Martin"], "venue": "In Computers and Games - 8th International Conference,", "citeRegEx": "Huang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2013}, {"title": "Monte-Carlo simulation balancing in practice", "author": ["Huang", "Shih-Chieh", "Coulom", "R\u00e9mi", "Lin", "Shun-Shii"], "venue": "In Proceedings of the 7th International Conference on Computers and Games,", "citeRegEx": "Huang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2011}, {"title": "Bandit based Monte-Carlo planning", "author": ["Kocsis", "Levente", "Szepesv\u00e1ri", "Csaba"], "venue": "In Machine Learning: ECML", "citeRegEx": "Kocsis et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kocsis et al\\.", "year": 2006}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Temporal difference learning of position evaluation in the game of Go", "author": ["Schraudolph", "Nicol N", "Dayan", "Peter", "Sejnowski", "Terrence J"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Schraudolph et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Schraudolph et al\\.", "year": 1994}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Mimicking Go experts with convolutional neural networks", "author": ["Sutskever", "Ilya", "Nair", "Vinod"], "venue": "In Artificial Neural Networks-ICANN", "citeRegEx": "Sutskever et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2008}, {"title": "Going deeper with convolutions", "author": ["Szegedy", "Christian", "Liu", "Wei", "Jia", "Yangqing", "Sermanet", "Pierre", "Reed", "Scott", "Anguelov", "Dragomir", "Erhan", "Dumitru", "Vanhoucke", "Vincent", "Rabinovich", "Andrew"], "venue": "arXiv preprint arXiv:1409.4842,", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 5, "context": "The majority of recent progress has been due to increased quantity and quality of prior knowledge, which is used to bias the search towards more promising states in both the search tree and during rollouts (Coulom, 2007; Gelly & Silver, 2011; Enzenberger et al., 2010; Huang et al., 2011), and it is widely believed that this knowledge is the major bottleneck towards further progress (Huang & M\u00fcller, 2013).", "startOffset": 206, "endOffset": 288}, {"referenceID": 9, "context": "The majority of recent progress has been due to increased quantity and quality of prior knowledge, which is used to bias the search towards more promising states in both the search tree and during rollouts (Coulom, 2007; Gelly & Silver, 2011; Enzenberger et al., 2010; Huang et al., 2011), and it is widely believed that this knowledge is the major bottleneck towards further progress (Huang & M\u00fcller, 2013).", "startOffset": 206, "endOffset": 288}, {"referenceID": 12, "context": "Although CNNs have previously been applied to the game of Go, with modest success (Schraudolph et al., 1994; Enzenberger, 1996; Sutskever & Nair, 2008), previous architectures have typically been limited to one hidden layer of relatively small size, and have not exploited recent advances in computational power.", "startOffset": 82, "endOffset": 151}, {"referenceID": 11, "context": "Schraudolph et al. (1994) trained a simple CNN (exploiting rotational, reflectional, and colour inversion symmetries) to predict final territory, by reinforcement learning from games of self-play.", "startOffset": 0, "endOffset": 26}, {"referenceID": 11, "context": "Schraudolph et al. (1994) trained a simple CNN (exploiting rotational, reflectional, and colour inversion symmetries) to predict final territory, by reinforcement learning from games of self-play. The resulting program beat a simplistic handcrafted program called Wally. NeuroGo (Enzenberger, 1996) used a more sophisticated architecture to predict final territory, eyes, and connectivity, again exploiting symmetries; and used a connectivity pathfinder to propagate information across weakly connected groups of stones. Enzenberger\u2019s program also used reinforcement learning from self-play. When combined with an alpha-beta search, NeuroGo equalled the performance of GnuGo on 9\u00d79 Go, and reached around 13 kyu on 19\u00d7 19 Go. Sutskever & Nair (2008) applied convolutional networks to supervised learning of expert moves, but using a small 1 hidden layer CNN; this matched the state-of-the-art prediction performance, achieving 34.", "startOffset": 0, "endOffset": 750}, {"referenceID": 11, "context": "Krizhevsky et al. (2012) were the first to achieve a very large performance gain with large and deep convolutional neural networks over traditional computer vision systems.", "startOffset": 0, "endOffset": 25}, {"referenceID": 11, "context": "Krizhevsky et al. (2012) were the first to achieve a very large performance gain with large and deep convolutional neural networks over traditional computer vision systems. Improved convolutional neural network architectures (primarily in the form of deeper networks) (Simonyan & Zisserman, 2014) provided another substantial improvement, culminating with Szegedy et al. (2014), who reduced the error rate of Krizhevsky et al.", "startOffset": 0, "endOffset": 378}, {"referenceID": 11, "context": "Krizhevsky et al. (2012) were the first to achieve a very large performance gain with large and deep convolutional neural networks over traditional computer vision systems. Improved convolutional neural network architectures (primarily in the form of deeper networks) (Simonyan & Zisserman, 2014) provided another substantial improvement, culminating with Szegedy et al. (2014), who reduced the error rate of Krizhevsky et al. (2012) from 15.", "startOffset": 0, "endOffset": 434}, {"referenceID": 3, "context": "For training the network, we used asynchronous stochastic gradient descent (Dean et al., 2012) with 50 replicas each on its own GPU.", "startOffset": 75, "endOffset": 94}, {"referenceID": 11, "context": "We also experimented with weight symmetries Schraudolph et al. (1994). Given that the board is symmetric, it makes sense to force the filters and biases to be rotationally and reflectionally symmetric, by aggregating weight updates over the 8-fold symmetry group between connections.", "startOffset": 44, "endOffset": 70}, {"referenceID": 5, "context": "1 (Enzenberger et al., 2010) and Pachi 10.", "startOffset": 2, "endOffset": 28}, {"referenceID": 9, "context": "(2008), and very simple rollouts based solely on 3\u00d7 3 patterns (Huang et al., 2011).", "startOffset": 63, "endOffset": 83}, {"referenceID": 0, "context": "In addition, the MCTS engine utilised standard heuristics for computer Go: RAVE (Gelly & Silver, 2011), a UCT exploration strategy similar to Chaslot et al. (2008), and very simple rollouts based solely on 3\u00d7 3 patterns (Huang et al.", "startOffset": 142, "endOffset": 164}], "year": 2014, "abstractText": "The game of Go is more challenging than other board games, due to the difficulty of constructing a position or move evaluation function. In this paper we investigate whether deep convolutional networks can be used to directly represent and learn this knowledge. We train a large 12-layer convolutional neural network by supervised learning from a database of human professional games. The network correctly predicts the expert move in 55% of positions, equalling the accuracy of a 6 dan human player. When the trained convolutional network was used directly to play games of Go, without any search, it beat the traditional-search program GnuGo in 97% of games, and matched the performance of a state-of-the-art Monte-Carlo tree search that simulates two million positions per move.", "creator": "LaTeX with hyperref package"}}}