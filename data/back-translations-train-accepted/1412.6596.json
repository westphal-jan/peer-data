{"id": "1412.6596", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2014", "title": "Training Deep Neural Networks on Noisy Labels with Bootstrapping", "abstract": "Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On MNIST handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-the- art results, and can also benefit from unlabeled face images with no modification to our method. On the ILSVRC2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.", "histories": [["v1", "Sat, 20 Dec 2014 04:11:33 GMT  (432kb,D)", "https://arxiv.org/abs/1412.6596v1", null], ["v2", "Sat, 7 Feb 2015 22:30:39 GMT  (432kb,D)", "http://arxiv.org/abs/1412.6596v2", null], ["v3", "Wed, 15 Apr 2015 19:48:37 GMT  (432kb,D)", "http://arxiv.org/abs/1412.6596v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["scott reed", "honglak lee", "dragomir anguelov", "christian szegedy", "dumitru erhan", "rew rabinovich"], "accepted": true, "id": "1412.6596"}, "pdf": {"name": "1412.6596.pdf", "metadata": {"source": "CRF", "title": "TRAINING DEEP NEURAL NETWORKS ON NOISY LABELS WITH BOOTSTRAPPING", "authors": ["Scott E. Reed", "Honglak Lee"], "emails": ["reedscot@umich.edu", "honglak@umich.edu", "dragomir@google.com", "szegedy@google.com", "dumitru@google.com", "amrabino@google.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "2 RELATED WORK", "text": "The literature on half-hearted and poorly supervised learning processes is huge (see Zhu, 2005), so in this section we will focus on the key concepts that inspired this work, and on other writings that are only about differentiating, and on a small list of example scenarios that are about identifying and learning oneself. Algorithms will assume that this is an initial classification, and then it will be about naming the unspoken examples, and then it will be about naming the unspoken examples, and then it will be about naming the unspoken example scenarios, and then it will not be about producing the unspoken rules for classification, but about creating a small list of sample scenarios with labels. Algorithms will be driven by building an initial classification, and the algorithms will be driven by building an initial classification."}, {"heading": "3 METHOD", "text": "In this section, we describe two approaches: Section 3.1 uses reconstruction errors as a consistency target and explicitly models noise distribution as matrix mapping model predictions on training labels. A reconstruction loss is added to promote top-down consistency of model predictions with the observations, enabling the model to determine the noise pattern in the data. The method presented in Section 3.2 (Bootstrapping) uses a convex combination of training labels and the predictions of the current model to generate the training targets, thus avoiding direct modelling of the noise distribution. This property is well suited for structured outputs, for which modelling dense interactions between all output units can be neither practical nor meaningful. These two approaches are compared empirically in Section 4.3 on how we can apply our bootstrapping approach to structured outputs by using the proposal, unstructured for each individual case."}, {"heading": "3.1 CONSISTENCY IN MULTI-CLASS PREDICTION VIA RECONSTRUCTION", "text": "Leave x {0, 1} D the data (or deep characteristics calculated from the data) and t = q = q = q (= q = 1) L, \u2211 k tk = 1 (1) the observed multinomial labels. The standard softmax labeling x to t does not take into account noisy or missing labels. In addition to optimizing the conditional log labeling logP (t | x), we add a regularizing term that encourages the class prediction as perspective consistent. We first introduce the \"true\" class name into our model (as opposed to the noisy label observations) as a latent multinomially variable q-labelable q-labeling."}, {"heading": "3.2 CONSISTENCY IN MULTI-CLASS PREDICTION VIA BOOTSTRAPPING", "text": "In this section, we develop a simple consistency object that does not require explicit sound distribution or a reconstruction term. The idea is to dynamically update the objectives of the prediction objective based on the current state of the model. The resulting objectives are a convex combination of (1) the loud training label and (2) the current prediction of the model. Intuitively, as the learner improves over time, his predictions can become more trustworthy. This mitigates the damage caused by erroneous labeling, as erroneous labels are likely to be highly inconsistent with other objectives predicted by the model in order to have the same label.By paying less attention to inconsistent labels, the learner can develop a more coherent model that further improves his ability to evaluate the consistency of loud labels. We refer to this approach as \"bootapping,\" in the sense that we are pulling ourselves up by booting through the Yaroaps (also based on our own work in 1995)."}, {"heading": "3.3 CONSISTENCY WITH STRUCTURED OUTPUT PREDICTION", "text": "In this section, we modify the training goal of the MultiBox (Erhan et al., 2014) object detection network to incorporate an idea of perceptual consistency into the losses. In the MultiBox approach, the bouncing truth bounces are clustered and the resulting centroids are used as \"priors\" for predicting object locations. A deep neural network is trained to make predictions for each basic truth object in an image, a residuality of these basic truth objects in the basic truth object bouncing box bouncing box bouncing boun.In the basic truth object bouncing box bouncing box bouncing bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce are used as the resulting prick prediction of \"the object bouncing bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce bounce.\""}, {"heading": "4 EXPERIMENTS", "text": "We conduct experiments on three image understanding tasks: MNIST detection of handwritten digits, Toroto Faces Database face motion detection, and ILSVRC2014 detection. In all tasks, we omit the term Bounding Box regression for simplicity, see (Erhan et al., 2014) for full details. We train a deep neural network with our proposed consistency target. In our illustrations, \"bootstraprecon\" refers to the training as described in Section 3.1, using reconstruction as the consistency target. \"bootstrap-soft\" and \"bootstrap-hard\" refer to our method described in Section 3.2 and 3.3."}, {"heading": "4.1 MNIST WITH NOISY LABELS", "text": "In this section, we train with our reconstruction target (detailed in Section 3.1) on MNIST handwritten numbers with different noise levels in the labels. In particular, we have used a fixed random permutation of the labels, as shown in Figure 2, and we perform control experiments while exampling the probability of applying the label permutation to each label. All models have been trained with mini-batch SGD, with the same architecture: 784-500-300-10 neural networks with rectified linear units. We used L2 weight drop of 0.0001. We found that \u03b2 = 0.8 worked best for bootstrap-hard, 0.95 for bootstrap-soft and 0.005 for bootstrap-recall. We initialize W (2) on the identity matrix. For the network that is objective with our proposed hard hard, we initialize the network sectors we initialize the Hard network layers."}, {"heading": "4.2 TORONTO FACES DATABASE EMOTION RECOGNITION", "text": "The Toronto Faces Database has 112,234 images, of which 4,178 have emotion labels. In all of the experiments, we first extracted spatial-pyramid emotion labels, as described in (Coates & Ng, 2011), to obtain 3200-dimensional features, and then trained a 3200-1000-500-7 network to predict the 1-of-7 emotion labels for each image. As in the case of our MNIST experiments, we initialize our model from the network that has been pre-trained with predictive only, and fine-tune all layers with our hybrid objectives. Figure 3 summarizes our TFD results. As in the case of MNIST, bootstrap-recon and bootstrap-hard can achieve the best results by significantly exceeding the softmax baseline and presenting bootstrap-soft-labels as a more modest 8th baseline emotion enhance.In this section, we present Emotion-based Emotion 8p 8."}, {"heading": "4.3 ILSVRC 2014 FAST SINGLE-SHOT PERSON DETECTION", "text": "In this section, we apply our method to the detection of people using a MultiBox network based on the inception architecture proposed in (Szegedy et al., 2014). First, we prepared MultiBox for class-specific localization using the full ILSVRC2014 training set, since there are only several thousand images labeled with people in ILSVRC, and then refined only to images of people. An important point for comparison is the Top-K bootstrapping heuristics introduced for MultiBox training in (Szegedy et al., 2014) for person detection in the absence of comments. In this approach, the largest confidence predictions are subtracted from the loss (which we show here in eq. (9)), and the setting used was K = 4. In other words, there is no gradient deriving from the Top-K recognition for the most reliable location predictions. In fact, they may be considered a form of prediction itself that is better than those modified by the top-only predictions, which are the top-only ones in this section."}, {"heading": "4.4 ILSVRC 2014 200-CATEGORY DETECTION", "text": "In this section, we apply our method to the case of object detection on the large-area ImageNet data. Our proposed method is applied in two ways: firstly to the MultiBox network for regional suggestions and secondly to the classification network, which predicts labels for each cropped image region. We follow the approach in (Szegedy et al., 2014) and combine image segments from MultiBox regional suggestions with deep network context characteristics as input to the classifier for each proposed region. We trained the MultiBox network as described in 3.3 and the reclassification network as described in Section 3.2. We found that \"hard\" performed better than the \"soft\" form of bootstrap strapping. MultiBox Postclassifier mAP (%) Recall @ 60p Baseline Baseline 39.8 38.4 Baseline bootstrap-hard 40.0 38.6 bootstrap-hard bootstrap-Googhard-Goog40.1 Goog40.1 Googhard-Goog40.1 Goog40.1 Goog3."}, {"heading": "5 CONCLUSIONS", "text": "In this work, we developed new training methods for weakly supervised deep learning and demonstrated the effectiveness of our approach to multi-class prediction and structured output prediction for multiple datasets. Our method is extremely simple and can be applied with very little technical effort to existing networks trained with a purely supervised goal. The improvements we show even with very simple methods suggest that the step beyond purely supervised deep learning merits further research attention. In addition to achieving better performance with the data we already have, our results suggest that performance gains can be achieved by collecting more data at a lower cost, as the caption does not have to be as exaggerated and flawed as it does not harm performance. In future work, it may be promising to consider a time-dependent policy for tuning \u03b2, the scaling factor between prediction and perception consistency objectives, and to expand our approach to a situated agent."}], "references": [{"title": "Understanding the yarowsky algorithm", "author": ["Abney", "Steven"], "venue": "Computational Linguistics,", "citeRegEx": "Abney and Steven.,? \\Q2004\\E", "shortCiteRegEx": "Abney and Steven.", "year": 2004}, {"title": "Deep generative stochastic networks trainable by backprop", "author": ["Bengio", "Yoshua", "Thibodeau-Laufer", "Eric"], "venue": "arXiv preprint arXiv:1306.1091,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["Blum", "Avrim", "Mitchell", "Tom"], "venue": "In Proceedings of the eleventh annual conference on Computational learning theory,", "citeRegEx": "Blum et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Blum et al\\.", "year": 1998}, {"title": "Identifying mislabeled training data", "author": ["Brodley", "Carla E", "Friedl", "Mark A"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Brodley et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Brodley et al\\.", "year": 1999}, {"title": "Toward an architecture for never-ending language learning", "author": ["Carlson", "Andrew", "Betteridge", "Justin", "Kisiel", "Bryan", "Settles", "Burr", "Hruschka Jr.", "Estevam R", "Mitchell", "Tom M"], "venue": "In AAAI,", "citeRegEx": "Carlson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Carlson et al\\.", "year": 2010}, {"title": "Neil: Extracting visual knowledge from web data", "author": ["Chen", "Xinlei", "Shrivastava", "Abhinav", "Gupta"], "venue": "In Computer Vision (ICCV),", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Enriching visual knowledge bases via object discovery and segmentation", "author": ["Chen", "Xinlei", "Shrivastava", "Abhinav", "Gupta"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "The importance of encoding versus training with sparse coding and vector quantization", "author": ["Coates", "Adam", "Ng", "Andrew Y"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Scalable Object Detection Using Deep Neural Networks", "author": ["Erhan", "Dumitru", "Szegedy", "Christian", "Toshev", "Alexander", "Anguelov", "Dragomir"], "venue": "In CVPR, pp", "citeRegEx": "Erhan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Erhan et al\\.", "year": 2014}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Girshick", "Ross", "Donahue", "Jeff", "Darrell", "Trevor", "Malik", "Jitendra"], "venue": "arXiv preprint arXiv:1311.2524,", "citeRegEx": "Girshick et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Girshick et al\\.", "year": 2013}, {"title": "Multi-prediction deep boltzmann machines", "author": ["Goodfellow", "Ian", "Mirza", "Mehdi", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2013}, {"title": "Semi-supervised learning by entropy minimization", "author": ["Grandvalet", "Yves", "Bengio", "Yoshua"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Grandvalet et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Grandvalet et al\\.", "year": 2005}, {"title": "Analysis of semi-supervised learning with the yarowsky algorithm", "author": ["Haffari", "Gholam Reza", "Sarkar", "Anoop"], "venue": "arXiv preprint arXiv:1206.5240,", "citeRegEx": "Haffari et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Haffari et al\\.", "year": 2012}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["Hinton", "Geoffrey E"], "venue": "Neural computation,", "citeRegEx": "Hinton and E.,? \\Q2002\\E", "shortCiteRegEx": "Hinton and E.", "year": 2002}, {"title": "Restricted boltzmann machine with hidden multinomial output unit", "author": ["Hinton", "Geoffrey E", "Mnih", "Volodymyr"], "venue": "Unpublished work,", "citeRegEx": "Hinton et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2009}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Hinton", "Geoffrey E", "Srivastava", "Nitish", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan R"], "venue": "arXiv preprint arXiv:1207.0580,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Classification using discriminative restricted boltzmann machines", "author": ["Larochelle", "Hugo", "Bengio", "Yoshua"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Larochelle et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Larochelle et al\\.", "year": 2008}, {"title": "The mnist database of handwritten digits", "author": ["LeCun", "Yann", "Cortes", "Corinna"], "venue": null, "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks", "author": ["Lee", "Dong-Hyun"], "venue": "In Workshop on Challenges in Representation Learning,", "citeRegEx": "Lee and Dong.Hyun.,? \\Q2013\\E", "shortCiteRegEx": "Lee and Dong.Hyun.", "year": 2013}, {"title": "Learning to label aerial images from noisy data", "author": ["Mnih", "Volodymyr", "Hinton", "Geoffrey E"], "venue": "In Proceedings of the 29th International Conference on Machine Learning", "citeRegEx": "Mnih et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2012}, {"title": "Analyzing the effectiveness and applicability of co-training", "author": ["Nigam", "Kamal", "Ghani", "Rayid"], "venue": "In Proceedings of the ninth international conference on Information and knowledge management,", "citeRegEx": "Nigam et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Nigam et al\\.", "year": 2000}, {"title": "Text classification from labeled and unlabeled documents using em", "author": ["Nigam", "Kamal", "McCallum", "Andrew Kachites", "Thrun", "Sebastian", "Mitchell", "Tom"], "venue": "Machine learning,", "citeRegEx": "Nigam et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Nigam et al\\.", "year": 2000}, {"title": "Deepid-net: multi-stage and deformable deep convolutional neural networks for object detection", "author": ["Ouyang", "Wanli", "Luo", "Ping", "Zeng", "Xingyu", "Qiu", "Shi", "Tian", "Yonglong", "Li", "Hongsheng", "Yang", "Shuo", "Wang", "Zhe", "Xiong", "Yuanjun", "Qian", "Chen"], "venue": "arXiv preprint arXiv:1409.3505,", "citeRegEx": "Ouyang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ouyang et al\\.", "year": 2014}, {"title": "Learning to disentangle factors of variation with manifold interaction", "author": ["Reed", "Scott", "Sohn", "Kihyuk", "Zhang", "Yuting", "Lee", "Honglak"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "Reed et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reed et al\\.", "year": 2014}, {"title": "Disentangling factors of variation for facial expression recognition", "author": ["Rifai", "Salah", "Bengio", "Yoshua", "Courville", "Aaron", "Vincent", "Pascal", "Mirza", "Mehdi"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "Rifai et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rifai et al\\.", "year": 2012}, {"title": "Semi-supervised self-training of object detection models", "author": ["Rosenberg", "Chuck", "Hebert", "Martial", "Schneiderman", "Henry"], "venue": null, "citeRegEx": "Rosenberg et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Rosenberg et al\\.", "year": 2005}, {"title": "Deep boltzmann machines", "author": ["Salakhutdinov", "Ruslan", "Hinton", "Geoffrey E"], "venue": "In International Conference on Artificial Intelligence and Statistics, pp", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2009}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["Sermanet", "Pierre", "Eigen", "David", "Zhang", "Xiang", "Mathieu", "Micha\u00ebl", "Fergus", "Rob", "LeCun", "Yann"], "venue": "arXiv preprint arXiv:1312.6229,", "citeRegEx": "Sermanet et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sermanet et al\\.", "year": 2013}, {"title": "Information processing in dynamical systems: Foundations of harmony theory", "author": ["Smolensky", "Paul"], "venue": null, "citeRegEx": "Smolensky and Paul.,? \\Q1986\\E", "shortCiteRegEx": "Smolensky and Paul.", "year": 1986}, {"title": "Learning from noisy labels with deep neural networks", "author": ["Sukhbaatar", "Sainbayar", "Fergus", "Rob"], "venue": "arXiv preprint arXiv:1406.2080,", "citeRegEx": "Sukhbaatar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2014}, {"title": "The toronto face database", "author": ["Susskind", "Josh M", "Anderson", "Adam K", "Hinton", "Geoffrey E"], "venue": "Department of Computer Science,", "citeRegEx": "Susskind et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Susskind et al\\.", "year": 2010}, {"title": "Scalable, High-Quality Object Detection", "author": ["C. Szegedy", "S. Reed", "D. Erhan", "D. Anguelov"], "venue": "ArXiv e-prints, December 2014", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Going deeper with convolutions", "author": ["Szegedy", "Christian", "Liu", "Wei", "Jia", "Yangqing", "Sermanet", "Pierre", "Reed", "Scott", "Anguelov", "Dragomir", "Erhan", "Dumitru", "Vanhoucke", "Vincent", "Rabinovich", "Andrew"], "venue": "arXiv preprint arXiv:1409.4842,", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Bootstrapping via graph propagation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pp. 620\u2013628", "author": ["Whitney", "Max", "Sarkar", "Anoop"], "venue": "Association for Computational Linguistics,", "citeRegEx": "Whitney et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Whitney et al\\.", "year": 2012}, {"title": "Unsupervised word sense disambiguation rivaling supervised methods", "author": ["Yarowsky", "David"], "venue": "In Proceedings of the 33rd annual meeting on Association for Computational Linguistics,", "citeRegEx": "Yarowsky and David.,? \\Q1995\\E", "shortCiteRegEx": "Yarowsky and David.", "year": 1995}, {"title": "Visualizing and understanding convolutional neural networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "arXiv preprint arXiv:1311.2901,", "citeRegEx": "Zeiler et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2013}, {"title": "Semi-supervised learning literature survey", "author": ["Zhu", "Xiaojin"], "venue": null, "citeRegEx": "Zhu and Xiaojin.,? \\Q2005\\E", "shortCiteRegEx": "Zhu and Xiaojin.", "year": 2005}], "referenceMentions": [{"referenceID": 16, "context": "Currently the predominant systems for visual object recognition and detection (Krizhevsky et al., 2012; Zeiler & Fergus, 2013; Girshick et al., 2013; Sermanet et al., 2013; Szegedy et al., 2014) use purely supervised training with regularization such as dropout (Hinton et al.", "startOffset": 78, "endOffset": 194}, {"referenceID": 9, "context": "Currently the predominant systems for visual object recognition and detection (Krizhevsky et al., 2012; Zeiler & Fergus, 2013; Girshick et al., 2013; Sermanet et al., 2013; Szegedy et al., 2014) use purely supervised training with regularization such as dropout (Hinton et al.", "startOffset": 78, "endOffset": 194}, {"referenceID": 28, "context": "Currently the predominant systems for visual object recognition and detection (Krizhevsky et al., 2012; Zeiler & Fergus, 2013; Girshick et al., 2013; Sermanet et al., 2013; Szegedy et al., 2014) use purely supervised training with regularization such as dropout (Hinton et al.", "startOffset": 78, "endOffset": 194}, {"referenceID": 32, "context": "Currently the predominant systems for visual object recognition and detection (Krizhevsky et al., 2012; Zeiler & Fergus, 2013; Girshick et al., 2013; Sermanet et al., 2013; Szegedy et al., 2014) use purely supervised training with regularization such as dropout (Hinton et al.", "startOffset": 78, "endOffset": 194}, {"referenceID": 15, "context": ", 2014) use purely supervised training with regularization such as dropout (Hinton et al., 2012) to avoid overfitting.", "startOffset": 75, "endOffset": 96}, {"referenceID": 31, "context": "On the Toronto Face Database (Susskind et al., 2010) we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-the-art results, and can also benefit from unlabeled face images with no modification to our method.", "startOffset": 29, "endOffset": 52}, {"referenceID": 8, "context": ", 2014), we show that our approach improves single-shot person detection using a MultiBox network (Erhan et al., 2014), and also improves performance in full 200-way detection using MultiBox for region proposal and a deep CNN for post-classification.", "startOffset": 98, "endOffset": 118}, {"referenceID": 21, "context": "Co-training (Blum & Mitchell, 1998; Nigam et al., 2000; Nigam & Ghani, 2000) was similarlymotivated but used a pair of classifiers with separate views of the data to iteratively learn and generate additional training labels.", "startOffset": 12, "endOffset": 76}, {"referenceID": 21, "context": "Co-training (Blum & Mitchell, 1998; Nigam et al., 2000; Nigam & Ghani, 2000) was similarlymotivated but used a pair of classifiers with separate views of the data to iteratively learn and generate additional training labels. Whitney & Sarkar (2012) proposed bootstrapping labeled training examples with graph-based label propagation.", "startOffset": 36, "endOffset": 249}, {"referenceID": 21, "context": "Co-training (Blum & Mitchell, 1998; Nigam et al., 2000; Nigam & Ghani, 2000) was similarlymotivated but used a pair of classifiers with separate views of the data to iteratively learn and generate additional training labels. Whitney & Sarkar (2012) proposed bootstrapping labeled training examples with graph-based label propagation. Brodley & Friedl (1999) developed statistical methods for identifying mislabeled training data.", "startOffset": 36, "endOffset": 358}, {"referenceID": 21, "context": "Co-training (Blum & Mitchell, 1998; Nigam et al., 2000; Nigam & Ghani, 2000) was similarlymotivated but used a pair of classifiers with separate views of the data to iteratively learn and generate additional training labels. Whitney & Sarkar (2012) proposed bootstrapping labeled training examples with graph-based label propagation. Brodley & Friedl (1999) developed statistical methods for identifying mislabeled training data. Rosenberg et al. (2005) also trained an object detection system in a weakly-supervised manner using self-training, and demonstrated that their proposed model achieved comparable performance to models trained with a much larger set of labels.", "startOffset": 36, "endOffset": 454}, {"referenceID": 21, "context": "Co-training (Blum & Mitchell, 1998; Nigam et al., 2000; Nigam & Ghani, 2000) was similarlymotivated but used a pair of classifiers with separate views of the data to iteratively learn and generate additional training labels. Whitney & Sarkar (2012) proposed bootstrapping labeled training examples with graph-based label propagation. Brodley & Friedl (1999) developed statistical methods for identifying mislabeled training data. Rosenberg et al. (2005) also trained an object detection system in a weakly-supervised manner using self-training, and demonstrated that their proposed model achieved comparable performance to models trained with a much larger set of labels. However, that approach works as a wrapper around an existing detection system, whereas in this work we integrate a consistency objective for bootstrapping into the training of the deep network itself. Our work shares a similar motivation to these earlier works, but instead of explicitly generating new training labels and adding new examples to the training set in an outer loop, we incorporate our consistency objective directly into the model. In addition, we consider not only the case of learning from unlabeled examples, but also from noisy labels and inexhaustively-annotated examples. Mnih & Hinton (2012) developed deep neural networks for improved labeling of aerial images, with robust loss functions to handle label omission and registration errors.", "startOffset": 36, "endOffset": 1286}, {"referenceID": 4, "context": "Never ending language learning (NELL) (Carlson et al., 2010) and never ending image learning (NEIL) (Chen et al.", "startOffset": 38, "endOffset": 60}, {"referenceID": 5, "context": ", 2010) and never ending image learning (NEIL) (Chen et al., 2013; 2014) are lifelong-learning systems for language and image understanding, respectively.", "startOffset": 47, "endOffset": 72}, {"referenceID": 10, "context": "More recently, multi-prediction DBM training (Goodfellow et al., 2013) and Generative Stochastic Networks (Bengio & Thibodeau-Laufer, 2013) improved the performance and simplified the training of deep generative models, enabling training via backpropagation much like in standard deep supervised networks.", "startOffset": 45, "endOffset": 70}, {"referenceID": 4, "context": "Never ending language learning (NELL) (Carlson et al., 2010) and never ending image learning (NEIL) (Chen et al., 2013; 2014) are lifelong-learning systems for language and image understanding, respectively. They continuously bootstrap themselves using a cycle of data collection, propagation of labels to the newly collected data, and self-improvement by training on the new data. Our work is complementary to these efforts, and focuses on building robustness to noisy and missing labels into the model for weakly-supervised deep learning. Larochelle & Bengio (2008) developed an RBM for classification that uses a hybrid generative and discriminative training objective.", "startOffset": 39, "endOffset": 568}, {"referenceID": 4, "context": "Never ending language learning (NELL) (Carlson et al., 2010) and never ending image learning (NEIL) (Chen et al., 2013; 2014) are lifelong-learning systems for language and image understanding, respectively. They continuously bootstrap themselves using a cycle of data collection, propagation of labels to the newly collected data, and self-improvement by training on the new data. Our work is complementary to these efforts, and focuses on building robustness to noisy and missing labels into the model for weakly-supervised deep learning. Larochelle & Bengio (2008) developed an RBM for classification that uses a hybrid generative and discriminative training objective. Deep Boltmann Machines (Salakhutdinov & Hinton, 2009) can also be trained in a semi-supervised manner with labels connected to the top layer. More recently, multi-prediction DBM training (Goodfellow et al., 2013) and Generative Stochastic Networks (Bengio & Thibodeau-Laufer, 2013) improved the performance and simplified the training of deep generative models, enabling training via backpropagation much like in standard deep supervised networks. However, fully-generative unsupervised training on high-dimensional sensory data, e.g. ImageNet images, is still far behind supervised methods in terms of performance, and so in this work we do not follow the generative approach directly. Instead, this work focuses on a way to benefit from unlabeled and weakly-labeled examples with minimal modification to existing deep supervised networks. We demonstrate increased robustness to label noise and performance improvements from unlabeled data for a minimal engineering effort. More recently, the problem of deep learning from noisy labels has begun to receive attention. Lee (2013) also followed the idea of minimum entropy regularization, and proposed generating \u201cpseudolabels\u201d as training targets for unlabeled data, and showed improved performance on MNIST with few labeled examples.", "startOffset": 39, "endOffset": 1753}, {"referenceID": 4, "context": "Never ending language learning (NELL) (Carlson et al., 2010) and never ending image learning (NEIL) (Chen et al., 2013; 2014) are lifelong-learning systems for language and image understanding, respectively. They continuously bootstrap themselves using a cycle of data collection, propagation of labels to the newly collected data, and self-improvement by training on the new data. Our work is complementary to these efforts, and focuses on building robustness to noisy and missing labels into the model for weakly-supervised deep learning. Larochelle & Bengio (2008) developed an RBM for classification that uses a hybrid generative and discriminative training objective. Deep Boltmann Machines (Salakhutdinov & Hinton, 2009) can also be trained in a semi-supervised manner with labels connected to the top layer. More recently, multi-prediction DBM training (Goodfellow et al., 2013) and Generative Stochastic Networks (Bengio & Thibodeau-Laufer, 2013) improved the performance and simplified the training of deep generative models, enabling training via backpropagation much like in standard deep supervised networks. However, fully-generative unsupervised training on high-dimensional sensory data, e.g. ImageNet images, is still far behind supervised methods in terms of performance, and so in this work we do not follow the generative approach directly. Instead, this work focuses on a way to benefit from unlabeled and weakly-labeled examples with minimal modification to existing deep supervised networks. We demonstrate increased robustness to label noise and performance improvements from unlabeled data for a minimal engineering effort. More recently, the problem of deep learning from noisy labels has begun to receive attention. Lee (2013) also followed the idea of minimum entropy regularization, and proposed generating \u201cpseudolabels\u201d as training targets for unlabeled data, and showed improved performance on MNIST with few labeled examples. Sukhbaatar & Fergus (2014) developed two deep learning techniques for handling noisy labels, learning to model the noise distribution in a top-down and bottom-up fashion.", "startOffset": 39, "endOffset": 1985}, {"referenceID": 8, "context": "3 we show how to apply our bootstrapping approach to structured outputs by using the MultiBox (Erhan et al., 2014) region proposal network to handle the case of inexhaustive structured output labeling for single-shot person detection and for class-agnostic region proposal.", "startOffset": 94, "endOffset": 114}, {"referenceID": 8, "context": "In this section, we modify the training objective of the MultiBox (Erhan et al., 2014) network for object detection to incorporate a notion of perceptual consistency into the loss.", "startOffset": 66, "endOffset": 86}, {"referenceID": 8, "context": "In all tasks, We omit the bounding box regression term for simplicity, see (Erhan et al., 2014) for full details.", "startOffset": 75, "endOffset": 95}, {"referenceID": 24, "context": "(Reed et al., 2014) (Rifai et al.", "startOffset": 0, "endOffset": 19}, {"referenceID": 25, "context": ", 2014) (Rifai et al., 2012)", "startOffset": 8, "endOffset": 28}, {"referenceID": 32, "context": "In this section we apply our method to detecting persons using a MultiBox network built on top of the Inception architecture proposed in (Szegedy et al., 2014).", "startOffset": 137, "endOffset": 159}, {"referenceID": 32, "context": "An important point for comparison is the top-K bootstrapping heuristic introduced for MultiBox training in (Szegedy et al., 2014) for person detection in the presence of missing annotations.", "startOffset": 107, "endOffset": 129}, {"referenceID": 32, "context": "We follow the approach in (Szegedy et al., 2014) and combine image crops from MultiBox region proposals with deep network context features as the input to the classifier for each proposed region.", "startOffset": 26, "endOffset": 48}], "year": 2015, "abstractText": "Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On MNIST handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-theart results, and can also benefit from unlabeled face images with no modification to our method. On the ILSVRC2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.", "creator": "LaTeX with hyperref package"}}}