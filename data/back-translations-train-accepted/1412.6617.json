{"id": "1412.6617", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Dec-2014", "title": "Understanding Minimum Probability Flow for RBMs Under Various Kinds of Dynamics", "abstract": "Energy-based models are popular in machine learning due to the elegance of their formulation and their relationship to statistical physics. Among these, the Restricted Boltzmann Machine (RBM) has been the prototype for some recent advancements in the unsupervised training of deep neural networks. However, the contrastive divergence training algorithm, so often used for such models, has a number of drawbacks and ineligancies both in theory and in practice. Here, we investigate the performance of Minimum Probability Flow learning for training RBMs. This approach reconceptualizes the nature of the dynamics defined over a model, rather than thinking about Gibbs sampling, and derives a simple, tractable, and elegant objective function using a Taylor expansion, allowing one to learn the parameters of any distribution over visible states. In the paper, we expound the Minimum Probability Flow learning algorithm under various dynamics. We empirically analyze its performance on these dynamics and demonstrate that MPF algorithms outperform CD on various RBM configurations.", "histories": [["v1", "Sat, 20 Dec 2014 07:08:37 GMT  (764kb,D)", "http://arxiv.org/abs/1412.6617v1", "Nine pages including the reference page plus one page appendix. Submit to the ICLR2015 conference track for review"], ["v2", "Tue, 6 Jan 2015 16:03:15 GMT  (1207kb,D)", "http://arxiv.org/abs/1412.6617v2", "Nine pages including the reference page plus one page appendix. Submit to the ICLR2015 conference track for review"], ["v3", "Mon, 12 Jan 2015 16:27:21 GMT  (1207kb,D)", "http://arxiv.org/abs/1412.6617v3", "Nine pages including the reference page plus one page appendix. Submit to the ICLR2015 conference track for review"], ["v4", "Sun, 1 Mar 2015 17:37:09 GMT  (1424kb,D)", "http://arxiv.org/abs/1412.6617v4", "Nine pages including the reference page plus one page appendix. Submit to the ICLR2015 conference track for review"], ["v5", "Thu, 2 Apr 2015 20:10:35 GMT  (955kb,D)", "http://arxiv.org/abs/1412.6617v5", "Nine pages including the reference page plus one page appendix. Appeared at ICLR2015 workshop track"], ["v6", "Tue, 7 Apr 2015 20:57:05 GMT  (955kb,D)", "http://arxiv.org/abs/1412.6617v6", "Nine pages including the reference page plus one page appendix. Appeared at ICLR2015 workshop track"]], "COMMENTS": "Nine pages including the reference page plus one page appendix. Submit to the ICLR2015 conference track for review", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["daniel jiwoong im", "ethan buchman", "graham w taylor"], "accepted": true, "id": "1412.6617"}, "pdf": {"name": "1412.6617.pdf", "metadata": {"source": "CRF", "title": "UNDERSTANDING MINIMUM PROBABILITY FLOW FOR RBMS UNDER VARIOUS KINDS OF DYNAMICS", "authors": ["Daniel Jiwoong Im", "Ethan Buchman", "Graham W. Taylor"], "emails": ["imj@uoguelph.ca", "ebuchman@uoguelph.ca", "gwtaylor@uoguelph.ca"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, most people who are able are able to move, to move and to move, to move, to move, to move, to move, to move, to move, to move and to move, to move, to move and to move, to move, to move and to move, to move and to move, to move, to move, to move, to move and to move, to move, to move and to move, to move, to move and to move, to move, to move and to move, to move and to move, to move and to move, to move, to move, to move, to move, to move and to move, to move, to move, to move, to move and to move."}, {"heading": "1.1 RESTRICTED BOLTZMANN MACHINES", "text": "While the learning methods we are discussing are generally applied to undirected probabilistic graphical models, we will use the limited Boltzmann machine (RBM) as a canonical example. An RBM is an undirected bipartite graph with visible (observed) variables v (0, 1) D and hidden (latent) variables h (0, 1) H (Smolensky, 1986). The RBM is an energy-based model in which the power of the state v, h is given by E (v, h). The marginalized probability of visible variables is formulated by the Boltzmann distribution, p; p; p; Wijvihj \u2212 j \u2212 j p (bivi \u2212 j cjhj) p (2), in which the power of the state v, h is given by E (v, c, c). The marginalized probability of visible variables is formulated by the Boltzmann distribution, p. p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p; p"}, {"heading": "2 MINIMUM PROBABILTY FLOW", "text": "The key intuition behind MPF is that NPS can be reformulated in a fixed theoretical context by treating the model distribution as the endpoint of some explicit dynamics and minimizing the probability flow among these dynamics, rather than treating dynamics as a sampling method used to approximate an insoluble function of that distribution. That is, MPF provides a theoretical environment for the formal treatment of Tij that provides a much more general perspective of this operator than CD, while formalizing the notion of minimizing divergence between positive and negative particles."}, {"heading": "2.1 DYNAMICS OF THE MODEL", "text": "The primary mathematical apparatus for MPF is a continuous time-Markov chain known as the master equation. (P-i = \u2211 J-6 = i-ijp (t) j-jip (t) i-i] (7) where j is the data states and i is the non-data states. (P-ij is the probability flow rate from state j to state i. Note that a state is full of vector of variables, and we theoretically list all states. (P-i is the rate of change of probability of state i, i.e. the difference between the probability flowing from any state j to state i, and the probability flowing from state i to another state j in due course. We can reexpress p-i in a simple matrix form asp-i-p (8) by expressing the state ii-ii = \u2212 ii = j-jip (t) i. We find that if the transition form has a unique dividing matrix, then the primary model is a dynamic one."}, {"heading": "2.2 FORM OF THE TRANSITION MATRIX", "text": "MPF does not propose to actually simulate this dynamic. Indeed, there is no need to do so since the formulation of the problem is reduced to a relatively simple optimization problem without an insoluble component. However, we must provide a means of calculating the matrix coefficients. Since our target distribution is the distribution defined by the RBM, we require that it be a function of energy, or more precisely, the parameters of the energy function. (10) The following theorem provides a general form for the transition matrix, so that the equilibrium matrix is the choice to satisfy a detailed equilibrium matrix, namely the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, and the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, and the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix matrix, the equilibrium matrix, the equilibrium matrix matrix, the equilibrium matrix, the equilibrium matrix matrix, the equilibrium matrix matrix, the equilibrium matrix, the equilibrium matrix, and the equilibrium matrix, the equilibrium matrix, the equilibrium matrix matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, and the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the equilibrium matrix, the"}, {"heading": "3 PROBABILITY FLOW RATES \u0393", "text": "At first glance, MPF may seem doomed to failure due to its size, i.e. 2D \u00d7 2D, and the problem of enumerating all states. However, the objective function in Eq.9 adds up to that of the equation, and thus only takes into account the transitions between the data states i (limited by our data set) and the non-data state j (limited by the scarcity of our design).By specifying intractability as sparse, the complexity and size of the data sets dominates it. Conventional methods can train an RBM in two ways, either with sampled negative particles such as CD, PCD or stochastic maximum probability (Hinton, 2002; Tieleman & Hinton, 2009) or via an inductive principle, with fixed sets of \"fantasy cases,\" such as generally score matching, ratio matching or pseudolikelihood (hyrines, 2005; Freitas, 2011; the fixed, and similar ones)."}, {"heading": "3.1 1-BIT FLIP CONNECTIONS", "text": "It can be shown that score matching is a special case of MPF where the connectivity function is set so that all states within a small stroke distance r are connected within the limit of r \u2192 0 (Sohl-Dickstein et al., 2011). Instead, for convenience, we can set the stroke distance to one and take into account that the data states are connected to all other states 1-bit flip-away: gij = {1 if the state i, j differs by a single bit flip-0, otherwise (13) 1-bit flip connectivity provides us with an extremely sparse connection to D2 dissimilar terms instead of 4D and can be regarded as NPS where the only negative particles are those that are 1-bit flip-away from the data states. This was the only connectivity function pursued (Sohl-Dickstein et al., 2011) and is a natural starting point for the approach."}, {"heading": "3.2 FACTORIZED MINIMUM PROBABILITY FLOW", "text": "Before j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j.... j. j.... j. j. j..... j. j. j....... j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j....... j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j.. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j. j."}, {"heading": "3.3 PERSISTENT MINIMUM PROBABILITY FLOW", "text": "There are several ways to sample \"fantasy particles\" from p (v; \u03b8n \u2212 1). Note that the collection of data distribution with respect to \u03b8n \u2212 1 is important. Previously, a Persistent Contrastive Divergence (PCD) was developed to improve CD learning (Tieleman & Hinton, 2009). Similarly, persistence can be applied to the collection of MPF connectivity functions. For each update, we select a new sample based on an MCMC sampler based on previous samples. Subsequently, we update phenomena that J (\u03b8n) \u2264 J (\u03b8n \u2212 1) are saturated (Sohl-Dickstein, 2011). The pseudo-code for persistent MPF is the same as Factored MPF, except for drawing new samples that are in square brackets in algorithm 1.As we will show, the use of persistence is important to achieve a faster MPF formulation while converting \u2212 1."}, {"heading": "4 EXPERIMENTS", "text": "We conducted the first empirical study of MPF under different connectivity types, as in Section 3. We compared our results with CD with a different number of MCMC steps. We analyzed the MPF variants based on the formation of RBMs and evaluated them quantitatively and qualitatively by comparing the protocol probability of the test data and the samples generated from the model. For the experiments, we refer to the 1-bit flip, factored and persistent methods as MPF-1flip, FMPF and PMPF. The goals of these experiments are to1. Let's compare the performance between MPF algorithms under different connectivities; and 2. Let's compare the performance between MPF and CD. In our experiments, we looked at the MNIST and CalTech silhouette data sets. MNIST consists of 60,000 training and 10,000 test images of size 28 x 28 pixels, the handwritten digits from classes 0 to 9."}, {"heading": "4.1 MNIST - EXACT LOG LIKELIHOOD", "text": "In our first experiment, we trained eleven RBMs on the MNIST digits. All RBMs consisted of 20 hidden units and 784 (28 x 28) visible units. Due to the small number of hidden variables, we calculated the exact value of the partition function by explicitly adding all visible configurations. Four RBMs were learned from CD1, CD10, CD15 and CD25. Seven RBMs were learned by 1-bit flip, FMPF and PMPF. This table gives an impression of the performance under different MPF dynamics when the FMPF-k and PMPF-k partition function is similar to CD training, where the number of steps is in k.The average log test probability values of RBMs with 20 hidden units are shown in Table 1."}, {"heading": "4.2 MNIST - ESTIMATING LOG LIKELIHOOD", "text": "In our second set of experiments, we trained RBMs with 200 hidden units. We trained them exactly as described in Section 4.1. These RBMs are capable of generating much higher quality samples from the data distribution, but the partition function can no longer be precisely calculated. To quantify the model, we estimated the test protocol probability using the conservative sample-based likelihood estimator (CSL) (Bengio et al., 2013). Given well-defined conditional probabilities P (v | h) of a model and a set of latent variable samples S collected from a Markov chain, CSL calculated f (v) = log meanh SP (v | h). The advantage of CSL is that scanning latent variables h instead of v has the effect of reducing the variance of the MPL estimator S."}, {"heading": "4.3 CALTECH 101 SILHOUETTES - ESTIMATING LOG LIKELIHOOD", "text": "Compared to MNIST, this dataset contains much more diverse structures with a richer correlation between the pixels, has 10 times more categories, contains less training data per category, and each object covers a larger part of the image. Therefore, we put the number of hidden units at 500. The estimated average log probability of train and test data is presented in Table 3. Results for Caltech 101 silhouettes are consistent with the results on MNIST. In all experiments, we observed a greater distance between PMPF and CD than the number of sampling steps was lower. Furthermore, the single-bit flip technique was not particularly successful, especially as the number of latent variables increased. We speculate that the reason for this might be related to the slow convergence of the dynamic system. In addition, PMPF works better than FMPF for similar reasons. However, persistent learning of the samples as the dynamic steps according to the Dynamic 101 model is most probable, the first steps between the 101 are the most likely ones."}, {"heading": "5 CONCLUSION", "text": "Minimum Probability Flow is an off-the-shelf, unsupervised algorithm that can be applied to all energy-based models. It has a number of beneficial properties but has not seen an application proportional to its potential. In this paper, we first explained MPF and its links to CD training, which allowed us to better understand and perspective on CD. We have demonstrated a general form for the transition matrix so that the equilibrium distribution converges with that of an RBM. This could lead to future enhancements of MPF based on the choice of o (\u00b7) in Equation 11. One of the merits of MPF is that the choice of the design of a dynamic system remains open by defining a connectivity function as long as it meets the fixed point equation. We have thoroughly examined three different connectivity structures and found that connectivity can be designed inductively or by random sampling. Finally, we have shown empirically that MPF, and PF in particular, are better practiced so far by MPF for training models than CDF."}, {"heading": "A MINIMUM PROBABILITY FLOW", "text": "A.1 DYNAMICS OF THE MODELTheorem \u2212 \u2212 \u2212 Fi \u2212 \u2212 \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 fi \u2212 \u2212 fi \u2212"}], "references": [{"title": "Bounding the test log-likelihood of generative models", "author": ["Bengio", "Yoshua", "Yao", "Li", "Cho", "Kyunghyun"], "venue": "In Proceedings of the International Conference of Learning Representations (ICLR),", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Statistical analysis of non-lattice data", "author": ["Besag", "Julian"], "venue": "The Statistician,", "citeRegEx": "Besag and Julian.,? \\Q1975\\E", "shortCiteRegEx": "Besag and Julian.", "year": 1975}, {"title": "Monte carlo sampling methods using markov chains and their applications", "author": ["Hasting", "W. Keith"], "venue": null, "citeRegEx": "Hasting and Keith.,? \\Q1970\\E", "shortCiteRegEx": "Hasting and Keith.", "year": 1970}, {"title": "Training products of experts by minimizing contrastive divergence", "author": ["Hinton", "Geoffrey. E"], "venue": "Neural Computation,", "citeRegEx": "Hinton and E.,? \\Q2002\\E", "shortCiteRegEx": "Hinton and E.", "year": 2002}, {"title": "Estimation of non-normalized statistical models by score matching", "author": ["Hyv\u00e4rinen", "Aapo"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Hyv\u00e4rinen and Aapo.,? \\Q2005\\E", "shortCiteRegEx": "Hyv\u00e4rinen and Aapo.", "year": 2005}, {"title": "Asymptotic efficiency of deterministic estimators for discrete energybased models: Ratio matching and pseudolikelihood", "author": ["Marlin", "Benjamin M", "Freitas", "Nando de"], "venue": "In Proceedings of the Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Marlin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Marlin et al\\.", "year": 2011}, {"title": "On the quantitative analysis of deep belief networks", "author": ["Salakhutdinov", "Ruslan", "Murray", "Iain"], "venue": "In Proceedings of the International Conference of Machine Learning (ICML),", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2008}, {"title": "Information processing in dynamical systems: Foundations of harmony theory. In Parallel Distributed Processing: Volume 1: Foundations, pp. 194\u2013281", "author": ["Smolensky", "Paul"], "venue": null, "citeRegEx": "Smolensky and Paul.,? \\Q1986\\E", "shortCiteRegEx": "Smolensky and Paul.", "year": 1986}, {"title": "Persistent minimum probability flow", "author": ["Sohl-Dickstein", "Jascha"], "venue": "Technical report, Redwood Centre for Theoretical Neuroscience,", "citeRegEx": "Sohl.Dickstein and Jascha.,? \\Q2011\\E", "shortCiteRegEx": "Sohl.Dickstein and Jascha.", "year": 2011}, {"title": "Minimum probability flow learning", "author": ["Sohl-Dickstein", "Jascha", "Battaglino", "Peter", "DeWeese", "Michael R"], "venue": "In Proceedings of the International Conference of Machine Learning (ICML),", "citeRegEx": "Sohl.Dickstein et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sohl.Dickstein et al\\.", "year": 2011}, {"title": "On the convergence properties of contrastive divergence", "author": ["Sutskever", "Ilya", "Tieleman", "Tijmen"], "venue": "In Proceedings of the AI & Statistics (AI STAT),", "citeRegEx": "Sutskever et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2009}, {"title": "Using fast weights to improve persistent contrastive divergence", "author": ["Tieleman", "Tijmen", "Hinton", "Geoffrey E"], "venue": "In Proceedings of the International Conference of Machine Learning (ICML),", "citeRegEx": "Tieleman et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Tieleman et al\\.", "year": 2009}, {"title": "Markov chains for exploring posterior distributions", "author": ["Tierney", "Luke"], "venue": "Annals of Statistics,", "citeRegEx": "Tierney and Luke.,? \\Q1994\\E", "shortCiteRegEx": "Tierney and Luke.", "year": 1994}], "referenceMentions": [{"referenceID": 9, "context": "Here, we take a more general approach to the problem of NPS, in particular, through the lens of the Minimum Probability Flow (MPF) algorithm (Sohl-Dickstein et al., 2011).", "startOffset": 141, "endOffset": 170}, {"referenceID": 9, "context": "Since \u0393ij captures probability flow from state j to state i, this objective function has the quite elegant interpretation of minimizing the probability flow from data states to non-data states (Sohl-Dickstein et al., 2011).", "startOffset": 193, "endOffset": 222}, {"referenceID": 9, "context": "The transition matrix proposed by (Sohl-Dickstein et al., 2011) is thus the simplest case of Theorem 1, found by setting o(\u00b7) = 0 and gij = gji: \u0393ij = gij exp ( 1 2 (Fj(\u03b8)\u2212 Fi(\u03b8)).", "startOffset": 34, "endOffset": 63}, {"referenceID": 9, "context": "1 1-BIT FLIP CONNECTIONS It can be shown that score matching is a special case of MPF, where the connectivity function is set to connect all states within a small hamming distance r in the limit of r \u2192 0 (Sohl-Dickstein et al., 2011).", "startOffset": 204, "endOffset": 233}, {"referenceID": 9, "context": "This was the only connectivity function pursued in (Sohl-Dickstein et al., 2011) and is a natural starting point for the approach.", "startOffset": 51, "endOffset": 80}, {"referenceID": 0, "context": "Likelihood estimates are made with CSL (Bengio et al., 2013).", "startOffset": 39, "endOffset": 60}, {"referenceID": 0, "context": "In order to evaluate the model quantitatively, we estimated the test log-likelihood using the Conservative Samplingbased Likelihood estimator (CSL) (Bengio et al., 2013).", "startOffset": 148, "endOffset": 169}, {"referenceID": 0, "context": "Likelihood estimates are made with CSL (Bengio et al., 2013).", "startOffset": 39, "endOffset": 60}], "year": 2017, "abstractText": "Energy-based models are popular in machine learning due to the elegance of their formulation and their relationship to statistical physics. Among these, the Restricted Boltzmann Machine (RBM) has been the prototype for some recent advancements in the unsupervised training of deep neural networks. However, the contrastive divergence training algorithm, so often used for such models, has a number of drawbacks and ineligancies both in theory and in practice. Here, we investigate the performance of Minimum Probability Flow learning for training RBMs. This approach reconceptualizes the nature of the dynamics defined over a model, rather than thinking about Gibbs sampling, and derives a simple, tractable, and elegant objective function using a Taylor expansion, allowing one to learn the parameters of any distribution over visible states. In the paper, we expound the Minimum Probability Flow learning algorithm under various dynamics. We empirically analyze its performance on these dynamics and demonstrate that MPF algorithms outperform CD on various RBM configurations.", "creator": "LaTeX with hyperref package"}}}