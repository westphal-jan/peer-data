{"id": "1412.6806", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2014", "title": "Striving for Simplicity: The All Convolutional Net", "abstract": "Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the \"deconvolution approach\" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.", "histories": [["v1", "Sun, 21 Dec 2014 16:16:37 GMT  (3566kb,D)", "http://arxiv.org/abs/1412.6806v1", "submitted to ICLR-2015 conference track"], ["v2", "Mon, 2 Mar 2015 21:44:06 GMT  (4448kb,D)", "http://arxiv.org/abs/1412.6806v2", "submitted to ICLR-2015 conference track Version 2: modified according to remarks of the reviewers. Main changes: added Large-All-CNN network, which is all convolutional version of Ben Graham's architecture; added a paragraph on related work; added deconvolutional reconstructions from Caffenet reference network"], ["v3", "Mon, 13 Apr 2015 07:58:17 GMT  (4437kb,D)", "http://arxiv.org/abs/1412.6806v3", "accepted to ICLR-2015 workshop track; no changes other than style"]], "COMMENTS": "submitted to ICLR-2015 conference track", "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["jost tobias springenberg", "alexey dosovitskiy", "thomas brox", "martin riedmiller"], "accepted": true, "id": "1412.6806"}, "pdf": {"name": "1412.6806.pdf", "metadata": {"source": "CRF", "title": "STRIVING FOR SIMPLICITY: THE ALL CONVOLUTIONAL NET", "authors": ["Jost Tobias Springenberg", "Alexey Dosovitskiy", "Thomas Brox", "Martin Riedmiller"], "emails": ["riedmiller}@cs.uni-freiburg.de"], "sections": [{"heading": "1 INTRODUCTION AND RELATED WORK", "text": "The vast majority of modern neo-Nazi networks (CNNs) used to detect objects are endowed with the same principles: they use alternating constellations and layers followed by a small number of fully connected layers (e.g. Jarrett et al.); Ciresan et al.); in each of these layers, the most important activation functions are used; the networks are generally large and regulated; and in recent years, we have focused on improving the performance of this basic pipeline."}, {"heading": "2 MODEL DESCRIPTION - THE ALL CONVOLUTIONAL NETWORK", "text": "The models we use in our experiments differ from standard CNNs in several key aspects. First - and interestingly - we are replacing the pooling layers used in virtually all modern CNNs for object detection. To understand why this method can work, it helps to recall the standard formulation for defining convolution and pooling operations in CNNs. Let's describe the number of channels (in case f is the output of a convolutional layer, N is the number of filters in that layer) as a 3-dimensional array of size W \u00b7 H \u00b7 N, where W \u00b7 N is the width and height and N is the number of channels (in case f is the output of a convolutional layer, N is the number of filters in that layer). Then p-norm subsampling (or pooling) with pooling size k (or half length k / 2) and the array f is an array of 3 (in case f)."}, {"heading": "3 EXPERIMENTS", "text": "In order to quantify the effects of simplifying the model architecture, we conduct experiments on three sets of data: CIFAR-10, CIFAR-100 (Krizhevsky & Hinton, 2009) and ILSVRC-2012 ImageNet (Deng et al., 2009). Specifically, we use CIFAR-10 to conduct an in-depth study of different models, as a large model can be trained on this data set at a moderate computing cost of \u2248 10 hours on a modern GPU. Subsequently, we test the best model found on CIFAR-10 and CIFAR-100 with and without augmentations, and conduct a first preliminary experiment on ILSVRC-2012 ImageNet datasets."}, {"heading": "3.1 EXPERIMENTAL SETUP", "text": "In experiments on CIFAR-10 and CIFAR-100, we use three different base network models, which are designed to reflect current best practices for setting up CNNs for object detection. Architectures of these networks are described in Table 1. Starting from Model A (the simplest model), the depth and number of parameters in the network is gradually increased to Model C. Several things need to be noted here: First, as described in the table, all base networks, which we consider to be 1-by-1 convolution at the top, use to produce 10 outputs, from which we then calculate an average across all positions and a softmax to produce class probabilities (see section 2 for the rationale behind this approach). We have conducted additional experiments with fully connected layers instead of 1-by-1 convolutions, but found these models consistently 0.5% \u2212 1% worse than their fully convolutionary counterparts. This is consistent with similar results from previous work (Lin et, 2014)."}, {"heading": "3.2 CLASSIFICATION RESULTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1 CIFAR-10", "text": "In our first study, we compared all the models of Section 3.1 on the CIFAR-10 Dataset without using augmentations. All the networks were based on the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the other side of the world, in the way they were born on the other side of the world, in the way they were born on the other side of the other side of the other side of the world, in the way they were born on the other side of the other side of the world, in the way they were born on the other side of the other side, in the other side of the other side of the world, in the way they were born on the other side, how they were born on the other side, how they were born on the other side, how they were born on the other side, how they were born on the other side, how they were born on the other side, how they were born on the other side, how they were born on the other side, how they were born on the other side, how they were born on the other side, how they were on the other side, how they were born on the other side, how they were on the other side, how they were born on the other side, how they were born on the other side, how they were on the other side, how they were on the other side, how they were born on the other side, how they were on the other side, how they were on the other side of the other side, how they were born on the other side, how they were on the other side, how they were on the other side,"}, {"heading": "3.2.2 CIFAR-100", "text": "We performed an additional experiment with the CIFAR-100 dataset to confirm the effectiveness of the best model (All-CNN) found for CIFAR-10. As usual, we used the same model as for CIFAR-10 and also recorded all the hyperparameters (learning rate and schedule). Again, this does not necessarily give the best performance. The results of this experiment are shown in Table 4 (right). As you can see, the simple model works with only 3 x 3 rotations and is comparable to the state of the art for this dataset, although most other methods use either more complicated training schemes or network architectures. However, note that the models again differ greatly in their number of traceable parameters, mainly because most models use a fully connected layer to predict class names."}, {"heading": "3.3 CLASSIFICATION OF IMAGENET", "text": "We conducted additional experiments with the ILVRC-2012 subset of the ImageNet dataset, which roughly has an error of 1.2 million SVR24s. Since training a state-of-the-art model on this dataset may require several weeks of computation on a modern GPU, we did not aim for the best performance, but rather conducted a simple \"proof of concept\" experiment. To test whether the architectures that perform best on CIFAR-10 can also be applied to larger datasets, we trained an upscaled version of the All-CNN-B network (which is similar to the architecture proposed by Lin et al. (2014). It has 12 revolutionary layers (Conv1-Conv12) and was designed for 450,000 iterations with stacks of 64 samples each, starting with a learning rate of \u03b3 = 0.01 and dividing it by 10 by 200,000 iterations each. A weight range of approximately 0.005 to 0.0005 is used in all architectures (0.005 to 0.005 is used in all architectures)."}, {"heading": "3.4 DECONVOLUTION", "text": "In order to analyze the network we trained on ImageNet - and to get a first impression of how well the model works without coming to any approximation - we use an approach that evolves in the way it works, in the way it works in a network proposed by Zeiler & Ferry (2014). Following on from this first attempt - and bearing in mind that it does not always work well - we propose a new and efficient method of visualizing the concepts learned from higher layers of the network. The deconvolutional network is able to visualize concepts learned by neurons in higher layers."}, {"heading": "4 DISCUSSION", "text": "Finally, we highlight a few important observations that we have made in our experiments: \u2022 Using modern methods to build Convolutionary Neural Networks, very simple architectures can perform very well: A network that uses nothing more than twists and subsampling matches, or even easily surpasses the state of the art on CIFAR-10 and CIFAR-100. A similar architecture shows competitive results on ImageNet. \u2022 In particular, unlike previous observations, including explicit (max.) pooling operations in a network, CNNs do not always improve performance, which seems to be especially the case when the network is large enough for the dataset on which it is being trained and can learn all necessary inventories only with Convolutionary Layers. \u2022 We propose a new method to visualize the representations learned by higher layers of a Convolutionary Network."}, {"heading": "ACKNOWLEDGMENTS", "text": "We acknowledge the funding provided by the ERC Starting Grant VideoLearn (279401); the work was also partially supported by the Excellence Cluster BrainLinks-BrainTools funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)."}, {"heading": "B ADDITIONAL VISUALIZATIONS", "text": "Additional visualizations of the characteristics learned by the last wave layer 'conven12' and the pre-softmax level 'global pool' are shown in Figure 4 and Figure 5 respectively."}], "references": [{"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-jia", "Kai", "Fei-fei"], "venue": "In CVPR,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Signal recovery from pooling representations", "author": ["Estrach", "Joan B", "Szlam", "Arthur", "Lecun", "Yann"], "venue": "In ICML,", "citeRegEx": "Estrach et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Estrach et al\\.", "year": 2014}, {"title": "Learned-norm pooling for deep feedforward and recurrent neural networks", "author": ["G\u00fcl\u00e7ehre", "\u00c7aglar", "Cho", "KyungHyun", "Pascanu", "Razvan", "Bengio", "Yoshua"], "venue": "In ECML,", "citeRegEx": "G\u00fcl\u00e7ehre et al\\.,? \\Q2014\\E", "shortCiteRegEx": "G\u00fcl\u00e7ehre et al\\.", "year": 2014}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Hinton", "Geoffrey E", "Srivastava", "Nitish", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan R"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "What is the best multi-stage architecture for object recognition", "author": ["Jarrett", "Kevin", "Kavukcuoglu", "Koray", "Ranzato", "Marc\u2019Aurelio", "LeCun", "Yann"], "venue": "In ICCV,", "citeRegEx": "Jarrett et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jarrett et al\\.", "year": 2009}, {"title": "Beyond spatial pyramids: Receptive field learning for pooled image features", "author": ["Jia", "Yangqing", "Huang", "Chang", "Darrell", "Trevor"], "venue": "In CVPR,", "citeRegEx": "Jia et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2012}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G. Hinton"], "venue": null, "citeRegEx": "Krizhevsky and Hinton,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Hinton", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In NIPS, pp", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Deeply supervised nets", "author": ["Lee", "Chen-Yu", "Xie", "Saining", "Gallagher", "Patrick", "Zhang", "Zhengyou", "Tu", "Zhuowen"], "venue": "In Deep Learning and Representation Learning Workshop,", "citeRegEx": "Lee et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2014}, {"title": "Network in network", "author": ["Lin", "Min", "Chen", "Qiang", "Yan", "Shuicheng"], "venue": "In ICLR: Conference Track,", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "In arxiv:cs/arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Deep inside convolutional networks: Visualising image classification models and saliency maps", "author": ["Simonyan", "Karen", "Vedaldi", "Andrea", "Zisserman", "Andrew"], "venue": "In 1312.6034,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Improving deep neural networks with probabilistic maxout units", "author": ["Springenberg", "Jost Tobias", "Riedmiller", "Martin"], "venue": "ICLR: Workshop Track,", "citeRegEx": "Springenberg et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Springenberg et al\\.", "year": 2013}, {"title": "Discriminative transfer learning with tree-based priors", "author": ["Srivastava", "Nitish", "Salakhutdinov", "Ruslan"], "venue": "In NIPS", "citeRegEx": "Srivastava et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2013}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Srivastava", "Nitish", "Hinton", "Geoffrey", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Srivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Compete to compute", "author": ["Srivastava", "Rupesh K", "Masci", "Jonathan", "Kazerounian", "Sohrob", "Gomez", "Faustino", "Schmidhuber", "J\u00fcrgen"], "venue": "In NIPS", "citeRegEx": "Srivastava et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2013}, {"title": "Deep networks with internal selective attention through feedback connections", "author": ["Stollenga", "Marijn F", "Masci", "Jonathan", "Gomez", "Faustino", "Schmidhuber", "J\u00fcrgen"], "venue": "In NIPS,", "citeRegEx": "Stollenga et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Stollenga et al\\.", "year": 2014}, {"title": "Going deeper with convolutions", "author": ["Szegedy", "Christian", "Liu", "Wei", "Jia", "Yangqing", "Sermanet", "Pierre", "Reed", "Scott", "Anguelov", "Dragomir", "Erhan", "Dumitru", "Vanhoucke", "Vincent", "Rabinovich", "Andrew"], "venue": "In arxiv:cs/arXiv:1409.4842,", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Regularization of neural networks using dropconnect", "author": ["Wan", "Li", "Zeiler", "Matthew D", "Zhang", "Sixin", "LeCun", "Yann", "Fergus", "Rob"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Wan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2013}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "In ICLR,", "citeRegEx": "Zeiler et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2013}, {"title": "Visualizing and understanding convolutional networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "In ECCV,", "citeRegEx": "Zeiler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 10, "context": "Among these the most notable directions are work on using more complex activation functions (Goodfellow et al., 2013; Lin et al., 2014; Srivastava et al., 2013) techniques for improving class inference (Stollenga et al.", "startOffset": 92, "endOffset": 160}, {"referenceID": 14, "context": "Among these the most notable directions are work on using more complex activation functions (Goodfellow et al., 2013; Lin et al., 2014; Srivastava et al., 2013) techniques for improving class inference (Stollenga et al.", "startOffset": 92, "endOffset": 160}, {"referenceID": 17, "context": ", 2013) techniques for improving class inference (Stollenga et al., 2014; Srivastava & Salakhutdinov, 2013) as well as procedures for improved regularization (Zeiler & Fergus, 2013; Springenberg & Riedmiller, 2013; Wan et al.", "startOffset": 49, "endOffset": 107}, {"referenceID": 19, "context": ", 2014; Srivastava & Salakhutdinov, 2013) as well as procedures for improved regularization (Zeiler & Fergus, 2013; Springenberg & Riedmiller, 2013; Wan et al., 2013) and layer-wise pre-training using label information (Lee et al.", "startOffset": 92, "endOffset": 166}, {"referenceID": 9, "context": ", 2013) and layer-wise pre-training using label information (Lee et al., 2014).", "startOffset": 60, "endOffset": 78}, {"referenceID": 7, "context": "Second, the success of CNNs for large scale object recognition in the ImageNet challenge (Krizhevsky et al., 2012) has stimulated research towards experimenting with the different architectural choices in CNNs.", "startOffset": 89, "endOffset": 114}, {"referenceID": 18, "context": "Most notably the top entries in the 2014 ImageNet challenge deviated from the standard design principles by either introducing multiple convolutions in between pooling layers (Simonyan & Zisserman, 2014) or by building heterogeneous modules performing convolutions and pooling at multiple scales in each layer (Szegedy et al., 2014).", "startOffset": 310, "endOffset": 332}, {"referenceID": 4, "context": "Jarrett et al. (2009); Krizhevsky et al.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "Jarrett et al. (2009); Krizhevsky et al. (2012); Ciresan et al.", "startOffset": 0, "endOffset": 48}, {"referenceID": 1, "context": "Since dimensionality reduction is performed via strided convolution rather than max-pooling in our architecture it also naturally lends itself to studying questions about the invertibility of neural networks (Estrach et al., 2014).", "startOffset": 208, "endOffset": 230}, {"referenceID": 1, "context": "Since dimensionality reduction is performed via strided convolution rather than max-pooling in our architecture it also naturally lends itself to studying questions about the invertibility of neural networks (Estrach et al., 2014). For a first step in that direction we study properties of our network using a deconvolutional approach similar to Zeiler & Fergus (2014).", "startOffset": 209, "endOffset": 369}, {"referenceID": 8, "context": "It should also be noted that this replacement can also be seen as learning the pooling operation rather than fixing it; which has previously been considered using different parameterizations in the literature 2 (LeCun et al., 1998; G\u00fcl\u00e7ehre et al., 2014; Jia et al., 2012).", "startOffset": 211, "endOffset": 272}, {"referenceID": 2, "context": "It should also be noted that this replacement can also be seen as learning the pooling operation rather than fixing it; which has previously been considered using different parameterizations in the literature 2 (LeCun et al., 1998; G\u00fcl\u00e7ehre et al., 2014; Jia et al., 2012).", "startOffset": 211, "endOffset": 272}, {"referenceID": 5, "context": "It should also be noted that this replacement can also be seen as learning the pooling operation rather than fixing it; which has previously been considered using different parameterizations in the literature 2 (LeCun et al., 1998; G\u00fcl\u00e7ehre et al., 2014; Jia et al., 2012).", "startOffset": 211, "endOffset": 272}, {"referenceID": 18, "context": "The second difference of the network model we consider to standard CNNs is that \u2013 similar to models recently used for achieving state-of-the-art performance in the ILSVRC-2012 competition (Simonyan & Zisserman, 2014; Szegedy et al., 2014) \u2013 we make use of small convolutional layers with k < 5 which can greatly reduce the number of parameters in a network and thus serve as a form of regularization.", "startOffset": 188, "endOffset": 238}, {"referenceID": 2, "context": ", 1998; G\u00fcl\u00e7ehre et al., 2014; Jia et al., 2012). We will evaluate both options in our experiments, ensuring a fair comparison w.r.t. the number of network parameters. The second difference of the network model we consider to standard CNNs is that \u2013 similar to models recently used for achieving state-of-the-art performance in the ILSVRC-2012 competition (Simonyan & Zisserman, 2014; Szegedy et al., 2014) \u2013 we make use of small convolutional layers with k < 5 which can greatly reduce the number of parameters in a network and thus serve as a form of regularization. Additionally, to unify the architecture further, we make use of the fact that if the image area covered by units in the topmost convolutional layer covers a portion of the image large enough to recognize its content (i.e. the object we want to recognize) then fully connected layers can also be replaced by simple 1-by-1 convolutions. This leads to predictions of object classes at different positions which can then simply be averaged over the whole image. This scheme was first described by Lin et al. (2014) and further regularizes the network as the one by one convolution has much less parameters than a fully connected layer.", "startOffset": 8, "endOffset": 1080}, {"referenceID": 0, "context": "In order to quantify the effect of simplifying the model architecture we perform experiments on three datasets: CIFAR-10, CIFAR-100 (Krizhevsky & Hinton, 2009) and ILSVRC-2012 ImageNet (Deng et al., 2009) .", "startOffset": 185, "endOffset": 204}, {"referenceID": 10, "context": "This is in line with similar findings from prior work (Lin et al., 2014).", "startOffset": 54, "endOffset": 72}, {"referenceID": 10, "context": "This is in line with similar findings from prior work (Lin et al., 2014). We hence do not report these numbers here to avoid cluttering the experiments. Second, it can be observed that model B from the table is a variant of the Network in Network architecture proposed by Lin et al. (2014) in which only one 1-by-1 convolution is performed after each \u201cnormal\u201d convolution layer.", "startOffset": 55, "endOffset": 290}, {"referenceID": 10, "context": "This is in line with similar findings from prior work (Lin et al., 2014). We hence do not report these numbers here to avoid cluttering the experiments. Second, it can be observed that model B from the table is a variant of the Network in Network architecture proposed by Lin et al. (2014) in which only one 1-by-1 convolution is performed after each \u201cnormal\u201d convolution layer. Third, model C replaces all 5\u00d7 5 convolutions by simple 3\u00d7 3 convolutions. This serves two purposes: 1) it unifies the architecture to consist only of layers operating on 3 \u00d7 3 spatial neighborhoods of the previous layer feature map (with occasional subsampling); 2) if max-pooling is replaced by a convolutional layer, then 3\u00d7 3 is the minimum filter size to allow overlapping convolution with stride 2. We also highlight that model C resembles the very deep models used by Simonyan & Zisserman (2014) in this years ImageNet competition.", "startOffset": 55, "endOffset": 882}, {"referenceID": 3, "context": "Dropout (Hinton et al., 2012) was used to regularize all networks.", "startOffset": 8, "endOffset": 29}, {"referenceID": 10, "context": "In experiments with data augmentation we perform only the augmentations also used in previous work (Goodfellow et al., 2013; Lin et al., 2014) in order to keep our results comparable.", "startOffset": 99, "endOffset": 142}, {"referenceID": 3, "context": "Dropout (Hinton et al., 2012) was used to regularize all networks. We applied dropout to the input image as well as after each pooling layer (or after the layer replacing the pooling layer respectively). The dropout probabilities were 20% for dropping out inputs and 50% otherwise. We also experimented with additional dropout (i.e. dropout on all layers or only on the 1\u00d7 1 convolution layer) which however did not result in increased accuracy4 . Additionally all models were regularized with weight decay \u03bb = 0.001. In experiments with data augmentation we perform only the augmentations also used in previous work (Goodfellow et al., 2013; Lin et al., 2014) in order to keep our results comparable. These include adding horizontally flipped examples of all images as well as randomly translated versions (with a maximum translation of 5 pixels in each dimension). In all experiments images were whitened and contrast normalized following Goodfellow et al. (2013).", "startOffset": 9, "endOffset": 966}, {"referenceID": 15, "context": "First, confirming previous results from the literature (Srivastava et al., 2014) the simplest model (model A) already performs remarkably well, achieving 12.", "startOffset": 55, "endOffset": 80}, {"referenceID": 10, "context": ", 2013), [2] (Lin et al., 2014), [3] (Lee et al.", "startOffset": 13, "endOffset": 31}, {"referenceID": 9, "context": ", 2014), [3] (Lee et al., 2014), [4] (Stollenga et al.", "startOffset": 13, "endOffset": 31}, {"referenceID": 17, "context": ", 2014), [4] (Stollenga et al., 2014), [5] (Srivastava & Salakhutdinov, 2013).", "startOffset": 13, "endOffset": 37}, {"referenceID": 10, "context": "To test if the architectures performing best on CIFAR-10 also apply to larger datasets, we trained an upscaled version of the All-CNN-B network (which is also similar to the architecture proposed by Lin et al. (2014)).", "startOffset": 199, "endOffset": 217}, {"referenceID": 7, "context": "7% Top-1 error reported by Krizhevsky et al. (2012) \u2013 while having less than 10 million parameters (6 times less than the network of Krizhevsky et al.", "startOffset": 27, "endOffset": 52}, {"referenceID": 7, "context": "7% Top-1 error reported by Krizhevsky et al. (2012) \u2013 while having less than 10 million parameters (6 times less than the network of Krizhevsky et al. (2012)) and taking roughly 4 days to train on a Titan GPU.", "startOffset": 27, "endOffset": 158}, {"referenceID": 11, "context": "The connections between the deconvolution and the backpropagation approach were recently discussed in Simonyan et al. (2014). In short the both methods differ mainly in the way they handle backpropagation through the rectified linear (ReLU) nonlinearity.", "startOffset": 102, "endOffset": 125}], "year": 2017, "abstractText": "Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding \u2013 and building on other recent work for finding simple network structures \u2013 we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the \u201cdeconvolution approach\u201d for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.", "creator": "LaTeX with hyperref package"}}}