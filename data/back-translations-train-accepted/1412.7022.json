{"id": "1412.7022", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2014", "title": "Audio Source Separation with Discriminative Scattering Networks", "abstract": "Inverse problems, such as denoising and source separation, are of great interest in audio and image processing. The classical model-based approach uses problem domain knowledge to define an appropriate objective function requiring in general an iterative inference algorithm. In the case of monoaural speech separation, we require robust signal models that integrate information across long temporal contexts while removing uninformative variability. This is achieved with a pyramid of wavelet scattering operators, which generalizes Constant Q Transforms (CQT) with extra layers of convolution and complex modulus. Learning Non-Negative Matrix Factorizations at different resolutions improves source separation results over fixed-resolution methods.", "histories": [["v1", "Mon, 22 Dec 2014 15:15:44 GMT  (43kb)", "https://arxiv.org/abs/1412.7022v1", null], ["v2", "Fri, 27 Feb 2015 23:54:06 GMT  (41kb)", "http://arxiv.org/abs/1412.7022v2", null], ["v3", "Tue, 28 Apr 2015 02:24:14 GMT  (43kb)", "http://arxiv.org/abs/1412.7022v3", null]], "reviews": [], "SUBJECTS": "cs.SD cs.LG", "authors": ["pablo sprechmann", "joan bruna", "yann lecun"], "accepted": true, "id": "1412.7022"}, "pdf": {"name": "1412.7022.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Pablo Sprechmann", "Joan Bruna", "Yann Lecun"], "emails": ["pablo@cims.nyu.edu", "bruna@cims.nyu.edu", "yann@cims.nyu.edu"], "sections": [{"heading": null, "text": "ar Xiv: 141 2.70 22v3 [cs.SD] 2 8A pr2 015 Accepted as a workshop contribution at ICLR 2015"}, {"heading": "1 INTRODUCTION", "text": "This is a fundamental inverse problem in speech processing (Loizou (2007); Ha \ufffd nsler & Schmidt (2008). Successful algorithms rely on models that capture the regularity of signals while maintaining discrimination between different speakers; the fragmentation of time and frequency representations (Lee & Seung (1999)) has been widely adopted in various audio processing tasks, including source separation in particular, see Smaragdis et al. (2014) for a recent review; there are many works that follow this line in language separation (Schmidt & Olsson (2006); Shashanka et al. (2007) and Enhancement (Duan et al.) (2012)."}, {"heading": "2 SINGLE-CHANNEL SOURCE SEPARATION", "text": "In this paper, we will deal with the families of algorithms that solve source separation on a feature pace. In this section, we will describe various alternatives that fall into this category. We will first introduce the general setting in Section 2.1. In Section 2.2, we will describe the popular NMF framework and the various educational systems associated with it. Finally, in Section 2.3, we will discuss purely discriminatory approaches based on deep networks."}, {"heading": "2.1 PROBLEM FORMULATION", "text": "We look at the setting in which we observe a temporal signal y (t), which is the sum of two sources xi (t), with i = 1, 2, y (t) = x1 (t), (1) and we aim to find estimates x (t). We look at the monitored monoaural source separation problem in which the components xi, i = 1, 2 come from sources for which we have representative training data. In this report, we focus on the case of speech signals, but other alternatives could be considered, such as noise or music.Most newer techniques typically operate with a non-negative time-frequency representation x. Let's look at the transformed version of y (t), which includes m-frequency bins and n-timeframes. This transformation can be considered a non-linear operator and is typically considered the magnitude (or power) of a time-frequency representation such as the short-time fixed."}, {"heading": "2.2 NON-NEGATIVE MATRIX FACTORIZATION", "text": "NMF-based source separation techniques attempt to find the non-negative activations Zi-Rq \u00b7 n, i = 1, 2 best representation of the different language components in two dictionaries Di-Rm \u00b7 q. Ideally, one would want to solve the problem, min x-i, Zi-i = 1, 2, 2, 2, 3, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5"}, {"heading": "2.3 PURELY DISCRIMINATIVE SETTINGS", "text": "Given the mindset of discriminatory learning, one is tempted to simply replace the inference step with a generic neural network architecture with sufficient capacity to perform nonlinear regression, designed to minimize a measure of fitness between the separation of the basic truths and the output as in (5), the most common being the Mean Squared Error (MSE), not that this can be done in attribute space or time domain (when phase recovery is simple). Other alternatives examined in the literature are to predict the masks indicated in (3), as described by Huang et al. (2014a). The most direct choice is to perform the estimation using a DNN on a fixed time scale. The use of a short-time context cannot model long-term time dependencies on the language signals, while the context makes the regression problem solvable."}, {"heading": "3 PYRAMID WAVELET SCATTERING", "text": "In this section, we briefly present the proposed wave scattering pyramid, which is conceptually similar to the standard scattering networks introduced by Mallat (2010), but has different temporal resolutions at each level."}, {"heading": "3.1 WAVELET FILTER BANK", "text": "A wave filter is a bandpass filter with good frequency and spatial localization. We consider a complex wavelet with a quadrature phase whose Fourier transformation fulfills F\u0445 (\u03c9) \u2248 0 for \u03c9 < 0. We assume that the center frequency of F\u0445 1 is and that its bandwidth is in the order of Q \u2212 1. Wave filters centered at frequencies \u03bb = 2j / Q are calculated by widening. The resulting filter bank has a constant number of Q-bands per octave and thus a constant number of Q-bands per octave and J1-octaves. We define it as a low-pass filter with a bandwidth of 2 \u2212 J1."}, {"heading": "3.2 PYRAMID SCATTERING TRANSFORM", "text": "Instead of using a fixed bandwidth smoothing core applied at all levels, we try at critical speed to get the temporal locality as far as possible. We start by removing the complex phase of the wavelength coefficients in Wx with a complex nonlinearity module. Then, we arrange these first layer coefficients as nodes in the first plane of a tree. Each node of this tree is scanned at the critical sampling rate of layer \"1,\" given by the reverse of the largest bandwidth available in the filter bank."}, {"heading": "4 SOURCE SEPARATION ALGORITHMS", "text": "In this section we show some examples of how the proposed pyramid dispersion characteristics could be used to solve the problem of source separation. We present alternatives for both learning paradigms: non-discriminatory and discriminatory."}, {"heading": "4.1 NON-DISCRIMINATIVE TRAINING", "text": "In this context, we try to find models for each loudspeaker that use the characteristics of the wave scattering pyramid. Each layer of transformation produces information with different stability / discriminability compromises. While in typical classification applications one is mainly interested in selecting a single layer that offers the best trade-off given the intrinsic variability of the dataset, we can use signal models at all levels in inverse problems. Suppose that two different sources X1 and X2, and for simplicity's sake consider the characteristics \u03a6j (xi), j = 1, 2, i = 1, 2, xi [Xi], by locating the scattering characteristics of two different resolutions at their respective sampling rates. Therefore, \u03a61 carries more discriminatory and localized information as \u03a61. In non-discriminatory education, we form independent models for each source."}, {"heading": "4.2 DISCRIMINATIVE TRAINING", "text": "The simplest alternative is to form a DNN directly from features that have the same temporal context as features of the second layer. For simplicity, we replace the second layer of complex wavelengths and modules with a simple hair transformation: \u03a62 (x) = {| x * * *. We do not take the absolute value as with standard scattering to allow the DNN the chance to recombine coefficients before the first nonlinearity. We report the results for J2 = 5, which correspond to a temporal context of 130 ms. We refer to this alternative as DNNmulti. As a second example, we consider a multi-resolution Neural Network (CNN), constructed this problem by creating three large contexts with relatively low cost = 2SE."}, {"heading": "5 EXPERIMENTS", "text": "In this section, we present some initial experimental assessments in which we examine the use of multi-resolution signal representation with discriminatory and non-discriminatory training systems, comparing performance against some basic settings, and evaluating the various alternatives in a multilingual environment where we aim to separate male and female language. In each case, we have developed two gender-specific training methods consisting of recordings of a generic group of speakers per gender, none of which was included in the test kit, and the experiments were conducted at the TIMIT level. We have adopted the standard test train split, using all training records (with 462 different speakers) to build the models and a subset of 12 different speakers (6 times and 6 females) for testing, selecting two clips for each speaker and comparing all female-male combinations (144 mixtures)."}, {"heading": "6 DISCUSSION", "text": "We have observed that the performance of source separation algorithms can be improved by using a near-time multi-resolution representation capable of integrating information across longer time contexts, eliminating uninformative variability with a relatively low parameter budget. Consistent with current findings in the literature, we have observed that the inclusion of discriminatory criteria in training leads to significant improvements in source separation. In contrast to standard sparse modeling, where the resulting conclusion can easily be bridged with a neural network, it remains unclear whether phase restoration types can also be efficiently approximated with neural network architectures. We believe that there may still be a gap in performance that can be bridged with suitable discriminatory architectures. While this report shows some promising initial results, several interesting comparisons need to be made and are the subject of current research. We consider an interesting problem to examine the best long-term estimation possibility in the best long-term context."}], "references": [{"title": "Deep scattering spectrum", "author": ["J. And\u00e9n", "S. Mallat"], "venue": "arXiv preprint arXiv:1304.6763,", "citeRegEx": "And\u00e9n and Mallat,? \\Q2013\\E", "shortCiteRegEx": "And\u00e9n and Mallat", "year": 2013}, {"title": "Exploiting long-term temporal dependencies in nmf using recurrent neural networks with application to source separation", "author": ["N. Boulanger-Lewandowski", "G.J. Mysore", "M. Hoffman"], "venue": "In ICASSP,", "citeRegEx": "Boulanger.Lewandowski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Boulanger.Lewandowski et al\\.", "year": 2014}, {"title": "Audio texture synthesis with scattering moments", "author": ["J. Bruna", "S. Mallat"], "venue": "arXiv preprint arXiv:1311.0407,", "citeRegEx": "Bruna and Mallat,? \\Q2013\\E", "shortCiteRegEx": "Bruna and Mallat", "year": 2013}, {"title": "Invariant scattering convolution networks. Pattern Analysis and Machine Intelligence", "author": ["J. Bruna", "S. Mallat"], "venue": "IEEE Transactions on,", "citeRegEx": "Bruna and Mallat,? \\Q2013\\E", "shortCiteRegEx": "Bruna and Mallat", "year": 2013}, {"title": "Source separation with scattering non-negative matrix factorization", "author": ["J. Bruna", "P. Sprechmann", "Lecun", "Yann"], "venue": null, "citeRegEx": "Bruna et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bruna et al\\.", "year": 2014}, {"title": "Learning a deep convolutional network for image super-resolution", "author": ["Dong", "Chao", "Loy", "ChenChange", "He", "Kaiming", "Tang", "Xiaoou"], "venue": "Computer Vision ? ECCV 2014,", "citeRegEx": "Dong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dong et al\\.", "year": 2014}, {"title": "Online plca for real-time semi-supervised source separation", "author": ["Z. Duan", "G.J. Mysore", "P. Smaragdis"], "venue": "In LVA/ICA,", "citeRegEx": "Duan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Duan et al\\.", "year": 2012}, {"title": "Majorization-minimization algorithm for smooth itakura-saito nonnegative matrix factorization", "author": ["C. F\u00e9votte"], "venue": "In ICASSP,", "citeRegEx": "F\u00e9votte,? \\Q2011\\E", "shortCiteRegEx": "F\u00e9votte", "year": 2011}, {"title": "Algorithms for nonnegative matrix factorization with the \u03b2-divergence", "author": ["C. F\u00e9votte", "J. Idier"], "venue": "Neural Computation,", "citeRegEx": "F\u00e9votte and Idier,? \\Q2011\\E", "shortCiteRegEx": "F\u00e9votte and Idier", "year": 2011}, {"title": "Non-negative dynamical system with application to speech and audio", "author": ["C. F\u00e9votte", "Roux", "J. Le", "J.R. Hershey"], "venue": "In ICASSP,", "citeRegEx": "F\u00e9votte et al\\.,? \\Q2013\\E", "shortCiteRegEx": "F\u00e9votte et al\\.", "year": 2013}, {"title": "A practical algorithm for the determination of the phase from image and diffraction plane", "author": ["R.W. Gerchberg", "Saxton", "W. Owen"], "venue": "pictures. Optik,", "citeRegEx": "Gerchberg et al\\.,? \\Q1972\\E", "shortCiteRegEx": "Gerchberg et al\\.", "year": 1972}, {"title": "Learning fast approximations of sparse coding", "author": ["K. Gregor", "Y. LeCun"], "venue": "In ICML, pp", "citeRegEx": "Gregor and LeCun,? \\Q2010\\E", "shortCiteRegEx": "Gregor and LeCun", "year": 2010}, {"title": "Audio imputation using the non-negative hidden markov model", "author": ["J. Han", "G.J. Mysore", "B. Pardo"], "venue": "In LVA/ICA,", "citeRegEx": "Han et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Han et al\\.", "year": 2012}, {"title": "Speech and Audio Processing in Adverse Environments", "author": ["E. H\u00e4nsler", "G. Schmidt"], "venue": null, "citeRegEx": "H\u00e4nsler and Schmidt,? \\Q2008\\E", "shortCiteRegEx": "H\u00e4nsler and Schmidt", "year": 2008}, {"title": "Deep learning for monaural speech separation", "author": ["Huang", "P.-S", "M. Kim", "M. Hasegawa-Johnson", "P. Smaragdis"], "venue": "In ICASSP, pp", "citeRegEx": "Huang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2014}, {"title": "Singing-voice separation from monaural recordings using deep recurrent neural networks", "author": ["Huang", "Po-Sen", "Kim", "Minje", "Hasegawa-Johnson", "Mark", "Smaragdis", "Paris"], "venue": null, "citeRegEx": "Huang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2014}, {"title": "Learning parts of objects by non-negative matrix factorization", "author": ["D.D. Lee", "H.S. Seung"], "venue": null, "citeRegEx": "Lee and Seung,? \\Q1999\\E", "shortCiteRegEx": "Lee and Seung", "year": 1999}, {"title": "Speech Enhancement: Theory and Practice, volume 30", "author": ["P.C. Loizou"], "venue": null, "citeRegEx": "Loizou,? \\Q2007\\E", "shortCiteRegEx": "Loizou", "year": 2007}, {"title": "Task-driven dictionary learning", "author": ["J. Mairal", "F. Bach", "J. Ponce"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Mairal et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mairal et al\\.", "year": 2012}, {"title": "A wavelet tour of signal processing", "author": ["Mallat", "St\u00e9phane"], "venue": "Academic press,", "citeRegEx": "Mallat and St\u00e9phane.,? \\Q1999\\E", "shortCiteRegEx": "Mallat and St\u00e9phane.", "year": 1999}, {"title": "Recursive interferometric representation", "author": ["Mallat", "St\u00e9phane"], "venue": "In Proc. of EUSICO conference,", "citeRegEx": "Mallat and St\u00e9phane.,? \\Q2010\\E", "shortCiteRegEx": "Mallat and St\u00e9phane.", "year": 2010}, {"title": "Understanding how deep belief networks perform acoustic modelling", "author": ["Mohamed", "Abdel-rahman", "Hinton", "Geoffrey", "Penn", "Gerald"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Mohamed et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mohamed et al\\.", "year": 2012}, {"title": "Supervised and unsupervised speech enhancement using nonnegative matrix factorization. Audio, Speech, and Language Processing", "author": ["N. Mohammadiha", "P. Smaragdis", "A. Leijon"], "venue": "IEEE Transactions on,", "citeRegEx": "Mohammadiha et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mohammadiha et al\\.", "year": 2013}, {"title": "A non-negative approach to semi-supervised separation of speech from noise with the use of temporal dynamics", "author": ["G.J. Mysore", "P. Smaragdis"], "venue": "In ICASSP, pp", "citeRegEx": "Mysore and Smaragdis,? \\Q2011\\E", "shortCiteRegEx": "Mysore and Smaragdis", "year": 2011}, {"title": "Single-channel speech separation using sparse non-negative matrix factorization", "author": ["M.N. Schmidt", "R.K. Olsson"], "venue": "In INTERSPEECH,", "citeRegEx": "Schmidt and Olsson,? \\Q2006\\E", "shortCiteRegEx": "Schmidt and Olsson", "year": 2006}, {"title": "Wind noise reduction using non-negative sparse coding", "author": ["M.N. Schmidt", "J. Larsen", "Hsiao", "F.-T"], "venue": "In MLSP,", "citeRegEx": "Schmidt et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2007}, {"title": "Learning to deblur", "author": ["Schuler", "Ch", "M. Hirsch", "S. Harmeling", "B. Scholkopf"], "venue": "arXiv preprint arXiv:1406.7444,", "citeRegEx": "Schuler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Schuler et al\\.", "year": 2014}, {"title": "Sparse Overcomplete Decomposition for Single Channel Speaker Separation", "author": ["M.V.S. Shashanka", "B. Raj", "P. Smaragdis"], "venue": "In ICASSP,", "citeRegEx": "Shashanka et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Shashanka et al\\.", "year": 2007}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Static and dynamic source separation using nonnegative factorizations: A unified view", "author": ["P. Smaragdis", "C. Fevotte", "G Mysore", "N. Mohammadiha", "M. Hoffman"], "venue": "Signal Processing Magazine, IEEE,", "citeRegEx": "Smaragdis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Smaragdis et al\\.", "year": 2014}, {"title": "Learnable low rank sparse models for speech denoising", "author": ["P. Sprechmann", "A. Bronstein", "M. Bronstein", "G. Sapiro"], "venue": "In ICASSP,", "citeRegEx": "Sprechmann et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sprechmann et al\\.", "year": 2013}, {"title": "Supervised non-euclidean sparse NMF via bilevel optimization with applications to speech enhancement", "author": ["P. Sprechmann", "A.M. Bronstein", "G. Sapiro"], "venue": "In HSCMA,", "citeRegEx": "Sprechmann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sprechmann et al\\.", "year": 2014}, {"title": "Performance measurement in blind audio source separation", "author": ["E. Vincent", "R. Gribonval", "C. F\u00e9votte"], "venue": "IEEE Trans. on Audio, Speech, and Lang. Proc.,", "citeRegEx": "Vincent et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2006}, {"title": "Discriminative NMF and its application to single-channel source separation", "author": ["F. Weninger", "J. Le Roux", "Hershey", "J. R", "S. Watanabe"], "venue": "Proc. of ISCA Interspeech,", "citeRegEx": "Weninger et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Weninger et al\\.", "year": 2014}, {"title": "Discriminatively trained recurrent neural networks for single-channel speech separation", "author": ["Weninger", "Felix", "Le Roux", "Jonathan", "Hershey", "John R", "Schuller", "Bj\u00f6rn"], "venue": "In Proc. IEEE GlobalSIP 2014 Symposium on Machine Learning Applications in Speech Processing,", "citeRegEx": "Weninger et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Weninger et al\\.", "year": 2014}, {"title": "Speech denoising using nonnegative matrix factorization with priors", "author": ["K.W. Wilson", "B. Raj", "P. Smaragdis", "A. Divakaran"], "venue": "In ICASSP,", "citeRegEx": "Wilson et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 12, "context": "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); H\u00e4nsler & Schmidt (2008)).", "startOffset": 82, "endOffset": 96}, {"referenceID": 12, "context": "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); H\u00e4nsler & Schmidt (2008)).", "startOffset": 82, "endOffset": 122}, {"referenceID": 12, "context": "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); H\u00e4nsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al.", "startOffset": 82, "endOffset": 506}, {"referenceID": 12, "context": "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); H\u00e4nsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al. (2014) for a recent review.", "startOffset": 82, "endOffset": 639}, {"referenceID": 12, "context": "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); H\u00e4nsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al. (2014) for a recent review. There are many works that follow this line in speech separation (Schmidt & Olsson (2006); Shashanka et al.", "startOffset": 82, "endOffset": 749}, {"referenceID": 12, "context": "Monaural Source Separation is a fundamental inverse problem in speech processing (Loizou (2007); H\u00e4nsler & Schmidt (2008)). Successful algorithms rely on models that capture signal regularity while preserving discrimination between different speakers. The decomposition of time-frequency representations, such as the power or magnitude spectrogram in terms of elementary atoms of a dictionary, has become a popularcitet tool in audio processing. Non-negative matrix factorization (NMF) (Lee & Seung (1999)), have been widely adopted in various audio processing tasks, including in particular source separation, see Smaragdis et al. (2014) for a recent review. There are many works that follow this line in speech separation (Schmidt & Olsson (2006); Shashanka et al. (2007)) and enhancement (Duan et al.", "startOffset": 82, "endOffset": 774}, {"referenceID": 5, "context": "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al.", "startOffset": 25, "endOffset": 44}, {"referenceID": 5, "context": "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)).", "startOffset": 25, "endOffset": 71}, {"referenceID": 5, "context": "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (F\u00e9votte (2011)), including co-occurrence statistics of the basis functions (Wilson et al.", "startOffset": 25, "endOffset": 627}, {"referenceID": 5, "context": "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (F\u00e9votte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al.", "startOffset": 25, "endOffset": 709}, {"referenceID": 5, "context": "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (F\u00e9votte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al.", "startOffset": 25, "endOffset": 805}, {"referenceID": 5, "context": "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (F\u00e9votte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al. (2012); F\u00e9votte et al.", "startOffset": 25, "endOffset": 824}, {"referenceID": 5, "context": "(2007)) and enhancement (Duan et al. (2012); Mohammadiha et al. (2013)). Although NMF applied on spectral features is highly efficient, it fails to model long range geometrical features that characterize speech signals. Increasing the temporal window is not the solution, since it increases significantly the dimensionality of the problem and reduces the discriminative power of the model. In order to overcome this limitation, many works have proposed regularized extensions of NMF to promote learned structure in the codes. Examples of these approaches are, temporal smoothness of the activation coefficients (F\u00e9votte (2011)), including co-occurrence statistics of the basis functions (Wilson et al. (2008)), and learned temporal dynamics with Kalman filtering like techniques(Mysore & Smaragdis (2011); Han et al. (2012); F\u00e9votte et al. (2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al.", "startOffset": 25, "endOffset": 847}, {"referenceID": 1, "context": "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)).", "startOffset": 79, "endOffset": 115}, {"referenceID": 1, "context": "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)). More recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al.", "startOffset": 79, "endOffset": 321}, {"referenceID": 1, "context": "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)). More recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al.", "startOffset": 79, "endOffset": 344}, {"referenceID": 1, "context": "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)). More recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al. (2014); Weninger et al.", "startOffset": 79, "endOffset": 370}, {"referenceID": 1, "context": "(2013)) or integrating Recurrent Neural Networks (RNN) into the NMF framework (Boulanger-Lewandowski et al. (2014)). More recently, several works have observed that the efficiency of these methods can be improved with discriminative training. Discriminatively trained dictionary learning techniques (Mairal et al. (2012); Gregor & LeCun (2010); Sprechmann et al. (2014); Weninger et al. (2014a)) show the importance of adapting the modeling task to become discriminative at the inverse problem at hand.", "startOffset": 79, "endOffset": 395}, {"referenceID": 24, "context": "A number of works completely bypass the modeling aspect and approach inverse problems as non-linear regression problems using Deep Neural Networks(DNN) (Sprechmann et al. (2013); Schuler et al.", "startOffset": 153, "endOffset": 178}, {"referenceID": 21, "context": "(2013); Schuler et al. (2014); Dong et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN.", "startOffset": 8, "endOffset": 27}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al.", "startOffset": 8, "endOffset": 208}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al.", "startOffset": 8, "endOffset": 230}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al.", "startOffset": 8, "endOffset": 272}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)).", "startOffset": 8, "endOffset": 321}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)). The goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al.", "startOffset": 8, "endOffset": 672}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)). The goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al. (2012)).", "startOffset": 8, "endOffset": 719}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)). The goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al. (2012)). This work takes this observation a step further to the multi-resolution setting. We consider a deep representation based on the wavelet scattering pyramid, which produces information at different temporal resolutions and defines a metric which is increasingly contracting. This representation can be thought as a generalization of the CQT. Discriminative features having longer temporal context can be constructed with the scattering transform (Bruna & Mallat (2013b)) and have been sucessfully applied to audio signals by And\u00e9n & Mallat (2013).", "startOffset": 8, "endOffset": 1189}, {"referenceID": 4, "context": "(2014); Dong et al. (2014)) with differet levels of structure ranging from simple frameby-frame regressors to more sophisticated RNN. Applications include source separation in music (Sprechmann et al. (2012); Huang et al. (2014b)), speech separation (Huang et al. (2014a)) and speech enhancement (Weninger et al. (2014b)). The goal of this work is to show that using stable and robust multi-resolution representation of the data can benefit the sources separation algorithms in both discriminative and non-discriminative settings. Previous works have shown that the choice of the input features plays a very important role of on source separation (Weninger et al. (2014b)) and speech recognition (Mohamed et al. (2012)). This work takes this observation a step further to the multi-resolution setting. We consider a deep representation based on the wavelet scattering pyramid, which produces information at different temporal resolutions and defines a metric which is increasingly contracting. This representation can be thought as a generalization of the CQT. Discriminative features having longer temporal context can be constructed with the scattering transform (Bruna & Mallat (2013b)) and have been sucessfully applied to audio signals by And\u00e9n & Mallat (2013). While these features have shown excellent performance in various classification tasks, in the context of source separation we require a representation that not only captures long-range temporal structures, but also preserves as much temporal discriminability as possible.", "startOffset": 8, "endOffset": 1266}, {"referenceID": 4, "context": "While NMF dictionaries at the first level are very selective to temporally localized energy patterns, deeper layers provide additional modeling of the longer temporal dynamics (Bruna et al. (2014)).", "startOffset": 177, "endOffset": 197}, {"referenceID": 14, "context": "Other robust alternatives have also been explored (Huang et al. (2014a);", "startOffset": 51, "endOffset": 72}, {"referenceID": 25, "context": "In this case, the phase recovery problem can be solved very efficiently using soft masks to filter the mixture signal (Schmidt et al. (2007)).", "startOffset": 119, "endOffset": 141}, {"referenceID": 7, "context": "for which there exist standard optimization algorithms, see for example F\u00e9votte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as \u03a6(x\u0302i) = DiZi, and the phase recovery is solved using (2).", "startOffset": 72, "endOffset": 95}, {"referenceID": 7, "context": "for which there exist standard optimization algorithms, see for example F\u00e9votte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as \u03a6(x\u0302i) = DiZi, and the phase recovery is solved using (2). In this supervised setting, the dictionaries are obtained from training data. The classic approach is to build model for each source independently and later use them together at testing time. Many works have observed that sparse coding inference algorithms can be improved in specific tasks by using discriminative training, i.e. by directly optimizing the parameters of the model on the evaluation cost function. Task-aware (or discriminative) sparse modeling is elegantly described by Mairal et al. (2012), observing that one can back-propagate through the Lasso.", "startOffset": 72, "endOffset": 762}, {"referenceID": 7, "context": "for which there exist standard optimization algorithms, see for example F\u00e9votte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as \u03a6(x\u0302i) = DiZi, and the phase recovery is solved using (2). In this supervised setting, the dictionaries are obtained from training data. The classic approach is to build model for each source independently and later use them together at testing time. Many works have observed that sparse coding inference algorithms can be improved in specific tasks by using discriminative training, i.e. by directly optimizing the parameters of the model on the evaluation cost function. Task-aware (or discriminative) sparse modeling is elegantly described by Mairal et al. (2012), observing that one can back-propagate through the Lasso. These ideas have been used in the context of source separation and enhancement (Sprechmann et al. (2014); Weninger et al.", "startOffset": 72, "endOffset": 925}, {"referenceID": 7, "context": "for which there exist standard optimization algorithms, see for example F\u00e9votte & Idier (2011). Once the optimal activations are solved for, the spectral envelopes of the speech are estimated as \u03a6(x\u0302i) = DiZi, and the phase recovery is solved using (2). In this supervised setting, the dictionaries are obtained from training data. The classic approach is to build model for each source independently and later use them together at testing time. Many works have observed that sparse coding inference algorithms can be improved in specific tasks by using discriminative training, i.e. by directly optimizing the parameters of the model on the evaluation cost function. Task-aware (or discriminative) sparse modeling is elegantly described by Mairal et al. (2012), observing that one can back-propagate through the Lasso. These ideas have been used in the context of source separation and enhancement (Sprechmann et al. (2014); Weninger et al. (2014a)).", "startOffset": 72, "endOffset": 950}, {"referenceID": 14, "context": "Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a). The most straight forward choice is to perform the estimation using a DNN on a fixed time scale.", "startOffset": 106, "endOffset": 127}, {"referenceID": 14, "context": "Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a). The most straight forward choice is to perform the estimation using a DNN on a fixed time scale. Using a short temporal context fails to model long range temporal dependencies on the speech signals, while increasing the context renders the regression problem intractable. One could consider to train a DNN on an set of several frames (Weninger et al. (2014b)).", "startOffset": 106, "endOffset": 487}, {"referenceID": 14, "context": "Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a). The most straight forward choice is to perform the estimation using a DNN on a fixed time scale. Using a short temporal context fails to model long range temporal dependencies on the speech signals, while increasing the context renders the regression problem intractable. One could consider to train a DNN on an set of several frames (Weninger et al. (2014b)). Recent works have explored neural network architectures that exploit temporal context such as RNN and Long Short-Term Memory (LSTM) (Huang et al. (2014a); Weninger et al.", "startOffset": 106, "endOffset": 643}, {"referenceID": 14, "context": "Other alternatives studied in the literature consist of predicting the masks given in (3) as described by Huang et al. (2014a). The most straight forward choice is to perform the estimation using a DNN on a fixed time scale. Using a short temporal context fails to model long range temporal dependencies on the speech signals, while increasing the context renders the regression problem intractable. One could consider to train a DNN on an set of several frames (Weninger et al. (2014b)). Recent works have explored neural network architectures that exploit temporal context such as RNN and Long Short-Term Memory (LSTM) (Huang et al. (2014a); Weninger et al. (2014b)).", "startOffset": 106, "endOffset": 668}, {"referenceID": 33, "context": "Similarly as in Weninger et al. (2014b), we simplify the inference by using a stronger version of the linear constraint y = x1 + x2, namely |W y| = |W x1| 2 + |W x2| 2 , and therefore that destructive interferences are negligible.", "startOffset": 16, "endOffset": 40}, {"referenceID": 32, "context": "We used the source-todistortion ratio (SDR), source-to-interference ratio (SIR), and source-to-artifact ratio (SAR) from the BSS-EVAL metrics (Vincent et al. (2006)).", "startOffset": 143, "endOffset": 165}, {"referenceID": 14, "context": "Recent studies have evaluate the use of deep RNN\u2019s for solving the source separation problem Huang et al. (2014a); Weninger et al.", "startOffset": 93, "endOffset": 114}, {"referenceID": 14, "context": "Recent studies have evaluate the use of deep RNN\u2019s for solving the source separation problem Huang et al. (2014a); Weninger et al. (2014b). While Huang et al.", "startOffset": 93, "endOffset": 139}, {"referenceID": 14, "context": "Recent studies have evaluate the use of deep RNN\u2019s for solving the source separation problem Huang et al. (2014a); Weninger et al. (2014b). While Huang et al. (2014a) do not observe significant improvements over", "startOffset": 93, "endOffset": 167}], "year": 2015, "abstractText": "In this report we describe an ongoing line of research for solving single-channel source separation problems. Many monaural signal decomposition techniques proposed in the literature operate on a feature space consisting of a time-frequency representation of the input data. A challenge faced by these approaches is to effectively exploit the temporal dependencies of the signals at scales larger than the duration of a time-frame. In this work we propose to tackle this problem by modeling the signals using a time-frequency representation with multiple temporal resolutions. The proposed representation consists of a pyramid of wavelet scattering operators, which generalizes Constant Q Transforms (CQT) with extra layers of convolution and complex modulus. We first show that learning standard models with this multi-resolution setting improves source separation results over fixed-resolution methods. As study case, we use Non-Negative Matrix Factorizations (NMF) that has been widely considered in many audio application. Then, we investigate the inclusion of the proposed multi-resolution setting into a discriminative training regime. We discuss several alternatives using different deep neural network architectures.", "creator": "LaTeX with hyperref package"}}}