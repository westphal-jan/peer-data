{"id": "1412.7054", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2014", "title": "Attention for Fine-Grained Categorization", "abstract": "This paper presents early experiments extending the work of Ba et al. (2014) on recurrent neural models for attention into less constrained visual environments, beginning with fine-grained categorization on the Stanford Dogs data set. In this work we use an RNN of the same structure but substitute a more powerful visual network and perform large-scale pre-training of the visual network outside of the attention RNN. Most work in attention models to date focuses on tasks with toy or more constrained visual environments. We present results comparing our model to state-of-the-art in fine-grained categorization as well as state-of-the-art deep visual models.", "histories": [["v1", "Mon, 22 Dec 2014 17:06:07 GMT  (1546kb,D)", "http://arxiv.org/abs/1412.7054v1", "ICLR 2015 Workshop submission"], ["v2", "Sat, 28 Feb 2015 00:15:45 GMT  (9774kb,D)", "http://arxiv.org/abs/1412.7054v2", "ICLR 2015 Workshop submission"], ["v3", "Sat, 11 Apr 2015 01:45:56 GMT  (9775kb,D)", "http://arxiv.org/abs/1412.7054v3", "ICLR 2015 Workshop"]], "COMMENTS": "ICLR 2015 Workshop submission", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["pierre sermanet", "rea frome", "esteban real"], "accepted": true, "id": "1412.7054"}, "pdf": {"name": "1412.7054.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["sermanet@google.com", "afrome@google.com", "ereal@google.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "This work represents early experiments that extend the work of Ba et al. (2014) to less restricted visual environments, starting with a fine-grained categorization. Ba et al. (2014) addresses the challenging problem of sequence prediction in simplified visual environments (MNIST and Street View House Numbers) with a recurring model of attention, the Mnih et al. (2014). In addition to this work, we address the easier task of classification, but in a visual environment with significant tangle and pose, and a more difficult class discrimination."}, {"heading": "2 MODEL DESCRIPTION", "text": "In fact, most of us are able to play by the rules we have set ourselves."}, {"heading": "3 EXPERIMENTAL RESULTS", "text": "In fact, it is that we see ourselves as being able to assert ourselves, that we are able to assert ourselves, that we are able to assert ourselves, and that we are able to assert ourselves, that we are able to assert ourselves, that we are able to assert ourselves in the world, \"he said."}], "references": [{"title": "Efficient object detection and segmentation for fine-grained recognition", "author": ["Angelova", "Anelia", "Zhu", "Shenghuo"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Angelova et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Angelova et al\\.", "year": 2013}, {"title": "Multiple Object Recognition with Visual Attention", "author": ["Ba", "Jimmy", "Mnih", "Volodymyr", "Kavukcuoglu", "Koray"], "venue": "CoRR, TBD,", "citeRegEx": "Ba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ba et al\\.", "year": 2014}, {"title": "Learning attentional policies for object tracking and recognition in video with deep networks", "author": ["Bazzani", "Loris", "de Freitas", "Nando", "Larochelle", "Hugo", "Murino", "Vittorio", "Ting", "Jo-Anne"], "venue": "In ICML\u201911: Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "Bazzani et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bazzani et al\\.", "year": 2011}, {"title": "Symbiotic Segmentation and Part Localization for Fine-Grained Categorization", "author": ["Chai", "Yuning", "Lempitsky", "Victor", "Zisserman", "Andrew"], "venue": "In ICCV\u201913: IEEE International Conference on Computer Vision,", "citeRegEx": "Chai et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chai et al\\.", "year": 2013}, {"title": "Learning where to attend with deep architectures for image tracking", "author": ["Denil", "Misha", "Bazzani", "Loris", "Larochelle", "Hugo", "de Freitas", "Nando"], "venue": "Neural Comput.,", "citeRegEx": "Denil et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Denil et al\\.", "year": 2012}, {"title": "Fine-Grained Categorization by Alignments", "author": ["Gavves", "Efstratios", "Fernando", "Basura", "Snoek", "Cees", "Smeulders", "Arnold", "Tuytelaars", "Tinne"], "venue": "In ICCV\u201913: IEEE International Conference on Computer Vision,", "citeRegEx": "Gavves et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gavves et al\\.", "year": 2013}, {"title": "Novel Dataset for Fine-Grained Image Categorization", "author": ["Khosla", "Aditya", "Jayadevaprakash", "Nityananda", "Yao", "Bangpeng", "Fei-Fei", "Li"], "venue": "In First Workshop on Fine-Grained Visual Categorization,", "citeRegEx": "Khosla et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Khosla et al\\.", "year": 2011}, {"title": "Learning to combine foveal glimpses with a third-order boltzmann machine", "author": ["Larochelle", "Hugo", "Hinton", "Geoffrey E"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Larochelle et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Larochelle et al\\.", "year": 2010}, {"title": "Recurrent models of visual attention", "author": ["Mnih", "Volodymyr", "Heess", "Nicolas", "Graves", "Alex", "kavukcuoglu", "koray"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Mnih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2014}, {"title": "The Truth About Cats and Dogs", "author": ["Parkhi", "Omkar M", "Vedaldi", "Andrea", "C.V. Jawahar", "Zisserman", "Andrew"], "venue": "In ICCV\u201911: IEEE International Conference on Computer Vision,", "citeRegEx": "Parkhi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Parkhi et al\\.", "year": 2011}, {"title": "On Learning Where To Look", "author": ["Ranzato", "Marc\u2019Aurelio"], "venue": "CoRR, abs/1405.5488,", "citeRegEx": "Ranzato and Marc.Aurelio.,? \\Q2014\\E", "shortCiteRegEx": "Ranzato and Marc.Aurelio.", "year": 2014}, {"title": "Learning generative models with visual attention", "author": ["Tang", "Yichuan", "Srivastava", "Nitish", "Salakhutdinov", "Ruslan"], "venue": "CoRR, abs/1312.6110,", "citeRegEx": "Tang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2013}, {"title": "The CaltechUCSD Birds-200-2011 Dataset", "author": ["Wah", "Catherine", "Branson", "Steve", "Welinder", "Peter", "Perona", "Pietro", "Belongie", "Serge"], "venue": "Technical Report CNS-TR-2011-001, California Institute of Technology,", "citeRegEx": "Wah et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wah et al\\.", "year": 2011}, {"title": "Unsupervised Template Learning for Fine-Grained Object Recognition", "author": ["Yang", "Shulin", "Bo", "Liefeng", "Wang", "Jue", "Shapiro", "Linda G"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Yang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2012}, {"title": "A Neural Autoregressive Approach to Attention-based Recognition", "author": ["Zheng", "Yin", "Zemel", "RichardS", "Zhang", "Yu-Jin", "Larochelle", "Hugo"], "venue": "IJCV\u201914: International Journal of Computer Vision, pp", "citeRegEx": "Zheng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zheng et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 1, "context": "This paper presents early experiments extending the work of Ba et al. (2014) on recurrent neural models for attention into less constrained visual environments, beginning with fine-grained categorization on the Stanford Dogs data set.", "startOffset": 60, "endOffset": 77}, {"referenceID": 2, "context": "Previous work in learned visual attention models have tackled a number of computer vision problems and demonstrated the benefits of various attention mechanisms, though most of the work focuses on toy or more constrained environments, such as tasks based on MNIST digits (Larochelle & Hinton, 2010; Bazzani et al., 2011; Denil et al., 2012; Ranzato, 2014; Mnih et al., 2014), the vision-control game of \u201ccatch\u201d (Mnih et al.", "startOffset": 271, "endOffset": 374}, {"referenceID": 4, "context": "Previous work in learned visual attention models have tackled a number of computer vision problems and demonstrated the benefits of various attention mechanisms, though most of the work focuses on toy or more constrained environments, such as tasks based on MNIST digits (Larochelle & Hinton, 2010; Bazzani et al., 2011; Denil et al., 2012; Ranzato, 2014; Mnih et al., 2014), the vision-control game of \u201ccatch\u201d (Mnih et al.", "startOffset": 271, "endOffset": 374}, {"referenceID": 8, "context": "Previous work in learned visual attention models have tackled a number of computer vision problems and demonstrated the benefits of various attention mechanisms, though most of the work focuses on toy or more constrained environments, such as tasks based on MNIST digits (Larochelle & Hinton, 2010; Bazzani et al., 2011; Denil et al., 2012; Ranzato, 2014; Mnih et al., 2014), the vision-control game of \u201ccatch\u201d (Mnih et al.", "startOffset": 271, "endOffset": 374}, {"referenceID": 8, "context": ", 2014), the vision-control game of \u201ccatch\u201d (Mnih et al., 2014), expression classification for 100\u00d7100 aligned faces (Larochelle & Hinton, 2010; Zheng et al.", "startOffset": 44, "endOffset": 63}, {"referenceID": 14, "context": ", 2014), expression classification for 100\u00d7100 aligned faces (Larochelle & Hinton, 2010; Zheng et al., 2014), detection of frontal faces (Tang et al.", "startOffset": 61, "endOffset": 108}, {"referenceID": 11, "context": ", 2014), detection of frontal faces (Tang et al., 2013), and tracking of hockey players (Bazzani et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 2, "context": ", 2013), and tracking of hockey players (Bazzani et al., 2011; Denil et al., 2012).", "startOffset": 40, "endOffset": 82}, {"referenceID": 4, "context": ", 2013), and tracking of hockey players (Bazzani et al., 2011; Denil et al., 2012).", "startOffset": 40, "endOffset": 82}, {"referenceID": 1, "context": "This work presents early experiments extending the work of Ba et al. (2014) to less constrained visual environments, beginning with fine-grained categorization.", "startOffset": 59, "endOffset": 76}, {"referenceID": 1, "context": "This work presents early experiments extending the work of Ba et al. (2014) to less constrained visual environments, beginning with fine-grained categorization. Ba et al. (2014) tackles the challenging problem of sequence prediction in simplified visual settings (MNIST and Street View House Numbers) using a recurrent model of attention similar to Mnih et al.", "startOffset": 59, "endOffset": 178}, {"referenceID": 1, "context": "This work presents early experiments extending the work of Ba et al. (2014) to less constrained visual environments, beginning with fine-grained categorization. Ba et al. (2014) tackles the challenging problem of sequence prediction in simplified visual settings (MNIST and Street View House Numbers) using a recurrent model of attention similar to Mnih et al. (2014). Complementary to that work, we are addressing the simpler task of classification but in a visual environment with significant clutter and occlusion, variations in lighting and pose, and a more difficult class discrimination task.", "startOffset": 59, "endOffset": 368}, {"referenceID": 6, "context": "(2014) to the Stanford Dogs fine-grained categorization task (Khosla et al., 2011), choosing to perform the task without using the provided bounding boxes for training or testing.", "startOffset": 61, "endOffset": 82}, {"referenceID": 1, "context": "We apply the visual attention model from Ba et al. (2014) to the Stanford Dogs fine-grained categorization task (Khosla et al.", "startOffset": 41, "endOffset": 58}, {"referenceID": 1, "context": "We apply the visual attention model from Ba et al. (2014) to the Stanford Dogs fine-grained categorization task (Khosla et al., 2011), choosing to perform the task without using the provided bounding boxes for training or testing. This amounts to learning to simultaneously localize and classify objects within scenes despite difficult class boundaries, large variations in pose and lighting, varying and cluttered backgrounds, and occlusion (Figure 1). Fine-grained categorization is a natural proving ground for attention-based models. When performing classification at the sub-category level, e.g. German Shepherd versus Poodle, the background is often uncorrelated with class and acts as a distraction to the primary task. As a result, several hand-crafted vision pipelines use provided bounding boxes to isolate the object of interest or may perform segmentation of the object from the background, e.g. Parkhi et al. (2011); Chai et al.", "startOffset": 41, "endOffset": 929}, {"referenceID": 1, "context": "We apply the visual attention model from Ba et al. (2014) to the Stanford Dogs fine-grained categorization task (Khosla et al., 2011), choosing to perform the task without using the provided bounding boxes for training or testing. This amounts to learning to simultaneously localize and classify objects within scenes despite difficult class boundaries, large variations in pose and lighting, varying and cluttered backgrounds, and occlusion (Figure 1). Fine-grained categorization is a natural proving ground for attention-based models. When performing classification at the sub-category level, e.g. German Shepherd versus Poodle, the background is often uncorrelated with class and acts as a distraction to the primary task. As a result, several hand-crafted vision pipelines use provided bounding boxes to isolate the object of interest or may perform segmentation of the object from the background, e.g. Parkhi et al. (2011); Chai et al. (2013); Angelova & Zhu (2013).", "startOffset": 41, "endOffset": 949}, {"referenceID": 1, "context": "We apply the visual attention model from Ba et al. (2014) to the Stanford Dogs fine-grained categorization task (Khosla et al., 2011), choosing to perform the task without using the provided bounding boxes for training or testing. This amounts to learning to simultaneously localize and classify objects within scenes despite difficult class boundaries, large variations in pose and lighting, varying and cluttered backgrounds, and occlusion (Figure 1). Fine-grained categorization is a natural proving ground for attention-based models. When performing classification at the sub-category level, e.g. German Shepherd versus Poodle, the background is often uncorrelated with class and acts as a distraction to the primary task. As a result, several hand-crafted vision pipelines use provided bounding boxes to isolate the object of interest or may perform segmentation of the object from the background, e.g. Parkhi et al. (2011); Chai et al. (2013); Angelova & Zhu (2013). Attention models could address this challenge by learning to focus processing and discriminatory power on the parts of the image that are relevant for the task.", "startOffset": 41, "endOffset": 972}, {"referenceID": 1, "context": "The structure of our model is the same as that presented in Ba et al. (2014) with only a few differences; we refer the reader to that paper for a complete explanation of the model and discuss the differences is this section.", "startOffset": 60, "endOffset": 77}, {"referenceID": 1, "context": "The structure of our model is the same as that presented in Ba et al. (2014) with only a few differences; we refer the reader to that paper for a complete explanation of the model and discuss the differences is this section. (1) Closer to the classification network described in Mnih et al. (2014), our model chooses actions for N glimpses and then classifies only after the final glimpse, as opposed to the sequence task in Ba et al.", "startOffset": 60, "endOffset": 298}, {"referenceID": 1, "context": "The structure of our model is the same as that presented in Ba et al. (2014) with only a few differences; we refer the reader to that paper for a complete explanation of the model and discuss the differences is this section. (1) Closer to the classification network described in Mnih et al. (2014), our model chooses actions for N glimpses and then classifies only after the final glimpse, as opposed to the sequence task in Ba et al. (2014). The number of glimpses is fixed in each experiment.", "startOffset": 60, "endOffset": 442}, {"referenceID": 6, "context": "We trained and evaluated our model on the Stanford Dogs fine-grained categorization data set (Khosla et al., 2011).", "startOffset": 93, "endOffset": 114}, {"referenceID": 12, "context": "The size of the data set is also more suitable to a deep learning method than most other available fine-grained data sets, though Caltech-UCSD Birds 2011 (Wah et al., 2011) is similar in size with 12,000 training images for 200 categories.", "startOffset": 154, "endOffset": 172}, {"referenceID": 3, "context": "Table 1: Previous state-of-the-art results on Stanford Dogs test set, measured by mean accuracy (mA) as described in Chai et al. (2013).", "startOffset": 117, "endOffset": 136}, {"referenceID": 3, "context": "38 Chai et al. (2013) 0.", "startOffset": 3, "endOffset": 22}, {"referenceID": 3, "context": "38 Chai et al. (2013) 0.46 Gavves et al. (2013) 0.", "startOffset": 3, "endOffset": 48}], "year": 2014, "abstractText": "This paper presents early experiments extending the work of Ba et al. (2014) on recurrent neural models for attention into less constrained visual environments, beginning with fine-grained categorization on the Stanford Dogs data set. In this work we use an RNN of the same structure but substitute a more powerful visual network and perform large-scale pre-training of the visual network outside of the attention RNN. Most work in attention models to date focuses on tasks with toy or more constrained visual environments. We present results comparing our model to state-of-the-art in fine-grained categorization as well as state-of-the-art deep visual models.", "creator": "LaTeX with hyperref package"}}}