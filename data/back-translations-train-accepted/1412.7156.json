{"id": "1412.7156", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2014", "title": "Representation Learning for cold-start recommendation", "abstract": "A standard approach to Collaborative Filtering (CF), i.e. prediction of user ratings on items, relies on Matrix Factorization techniques. Representations for both users and items are computed from the observed ratings and used for prediction. Unfortunatly, these transductive approaches cannot handle the case of new users arriving in the system, with no known rating, a problem known as user cold-start. A common approach in this context is to ask these incoming users for a few initialization ratings. This paper presents a model to tackle this twofold problem of (i) finding good questions to ask, (ii) building efficient representations from this small amount of information. The model can also be used in a more standard (warm) context. Our approach is evaluated on the classical CF problem and on the cold-start problem on four different datasets showing its ability to improve baseline performance in both cases.", "histories": [["v1", "Mon, 22 Dec 2014 21:58:06 GMT  (80kb,D)", "https://arxiv.org/abs/1412.7156v1", null], ["v2", "Fri, 27 Feb 2015 18:56:23 GMT  (392kb,D)", "http://arxiv.org/abs/1412.7156v2", null], ["v3", "Fri, 27 Mar 2015 09:59:25 GMT  (392kb,D)", "http://arxiv.org/abs/1412.7156v3", "Accepted as workshop contribution at ICLR 2015"], ["v4", "Wed, 8 Apr 2015 15:37:19 GMT  (392kb,D)", "http://arxiv.org/abs/1412.7156v4", "Accepted as workshop contribution at ICLR 2015"], ["v5", "Mon, 22 Jun 2015 14:01:33 GMT  (392kb,D)", "http://arxiv.org/abs/1412.7156v5", "Accepted as workshop contribution at ICLR 2015"]], "reviews": [], "SUBJECTS": "cs.IR cs.LG", "authors": ["gabriella contardo", "ludovic denoyer", "thierry artieres"], "accepted": true, "id": "1412.7156"}, "pdf": {"name": "1412.7156.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Gabriella Contardo", "Ludovic Denoyer", "Thierry Arti\u00e8res"], "emails": [], "sections": [{"heading": "1 INTRODUCTION", "text": "Most of the successful machine learning algorithms are based on data representation (age, postcode) or items (type of approach). Most of the successful machine learning algorithms are based on data representation, i.e. a way in which most actors extract most information from the data that supports the model in its objective task. As highlighted by Bengio et al. (2013), the development of models that are able to learn these representations from (raw) data and not learn from manual pre-processing is crucial in order to go further into the areas of Artificial Intelligence and Representation. They aim to propose the most relevant items (e.g. products) for each user to facilitate their experience. In order to recommend such relevant items, systems can rely on different types of data, such as the explicit and implicit feedback of users (e.g. the rating of a movie on a scale of age of a user), or the purchase of an item (e.g. the purchase of an item)."}, {"heading": "2 PROPOSED APPROACH", "text": "We will now rewrite the objective function detailed in Eq.2 in a more general form that will allow us to integrate the Q question (cold start problem) as a representational learning problem. As seen above, we will still consider that each element will have its own learned representation, designating Qi-RN, and will focus on building a user representation. When we are confronted with a new user, our model will first collect a series of evaluations by asking a series of queries during an interview process, which consists of a series of points selected during the training phase. For each element in the interview, the new user will 2The integration of new elements that are less critical in practical applications is not the focus of this paper, but will be discussed in the conclusion. 3The article focuses on a static interview process where the set of items is the same for all future users. A discussion on this point is provided in Section 4, which can provide an opinion, but cannot provide an opinion, even if it does not provide an evaluation."}, {"heading": "2.1 INDUCTIVE ADDITIVE MODEL (IAM)", "text": "The above generic formulation cannot easily be optimized with any representation function. In particular, the use of a transductive model is not trivial in this context, and if we resort to MF-based approaches in this case, we only get very complex solutions with high computational complexity. We therefore need to use a more appropriate representation and learning function, which is described below. (ii) The inductive additive model (IAM) is based on two simple ideas regarding the representation of users that we want to build: (i) First, you need to be able to give good recommendations to any user who does not give any ratings during the interview process. (ii) Second, we want the user representation to be slightly enriched as new ratings are available. This feature makes our approach suitable for the respective cold start setting, but also for the default CF setting. Based on the first idea, IAM considers that each user will be assigned a correlated rating without any answers."}, {"heading": "2.1.1 CONTINUOUS LEARNING PROBLEM", "text": "Let us now describe how the objective function described in Eq.3 can be optimized using the IAM model described in Eq.4. The optimization problem, which consists in minimizing Lcold (q, \u03b1, Q) via q, \u0442, and Q, is a combinatorial problem, since Q is a subset of the items. This combinatorial nature prevents us from using classical optimization methods such as gradient descendant methods, and involves an insoluble number of possible item combinations. We suggest using an L1 relaxation to convert this problem into a continuous one. Let us designate a weight vector, a weight per item, so that if \u03b1i = 0 is not used then items i can be rewritten with items as: Lcold (q, q, \u03b1) = item."}, {"heading": "2.2 IAM AND CLASSICAL COLLABORATIVE FILTERING", "text": "The IAM, which is particularly well suited for the cold start recommendation of the user, can also be used in the classical cooperative filter problem without limiting the number of items. In this case, the objective function can be written as follows: Lwarm (q, \u0441) = \u2211 (u, i) \u0192O (ru, i \u2212 qTi (u, i), as well as O\u0442 ru, i) 2 (8), which can be easily optimized by gradient descent. This model is a simple alternative to matrix factoring-based approaches, which are also evaluated in the experimental part. This model has some nice properties compared to transductive techniques, mainly it can easily update the representation of the user when confronted with new ratings, but this is not the topic of this article."}, {"heading": "3 EXPERIMENTS", "text": "We evaluate our models on four benchmark datasets - Table 1a - of different sizes in terms of the number of users, items or variety of ratings. The datasets are classic datasets used in the literature (Zhou et al. (2011); Golbandi et al. (2010). ML1M corresponds to the MovieLens 1 Million Dataset and Yahoo corresponds to the Yahoo! Music Benchmark. Flixter and Jester areclassical datasets. As our main objective is to evaluate the quality of our approach in the context of new users arriving in the system, we define the following protocol to simulate a realistic interview process for incoming users and evaluate different models. We proceed as follows: (i) We randomly divide each dataset along the users to have a pool of training users composed of 50% of the users of the complete dataset on which we are learning."}, {"heading": "3.1 COLLABORATIVE FILTERING", "text": "First of all, we evaluate the ability of our model to learn relevant representations in a classical CF context. In this case, the IAM model predicts evaluations directly on the basis of the evaluations provided by a user. The results for the four different datasets are presented in Table 1b. We can find that, despite the abundance of information during the learning phase, IAM achieves competitive results, thus confirming the ability of the additive model to generate new users. Specifically, IAM is better than MF for three out of four datasets. Although the Item KNN model delivers slightly better results for two datasets, it should be noted that this method does not rely on or on any representations for users or items and belongs to a different family of procedures. ItemKNN - which is based on a large KNN method - is very tedious and therefore unable to achieve high performance."}, {"heading": "3.2 COLD-START SETTING", "text": "We are now examining the ability of our approach to predict ratings in a realistic cold-start situation. Since MF and ItemKNN were directly selected, we do not offer an opportunity to select a number of items for the interview, we use two benchmark selection methods used in the literature (Rashid et al. (2002). The POP method selects the most popular items - i.e. the items with the highest number of items in training - and the HELF method (Harmonic mean of Entropy and Logarithm of rating Frequency), which selects items both on the basis of their popularity and using an entropy criterion focused on the informativeness of items (e.g. a controversial film may be more informative than a movie that everyone would like). (2008) Our model is learned solely on the basis of the U train. Baselines are compiled on the basis of a data set that is compiled from the original POU rating with the additional ratings in the tests."}, {"heading": "3.3 MIXING COLD-START AND WARM RECOMMENDATION", "text": "Our model can also make it possible to move smoothly from a cold start to a warm context: after answering the interview, the user will interact with the system and submit new evaluations, which can be easily integrated into our inductive translation model, in order to update its representation and thus the resulting recommendations. (i) To this end, we simply change the learning strategy: (i) The model is learned in the warm context described in Equation (8), i.e. we learn the Qi values of each item and the translations of the representations (the Qi parameters). (ii) We select the most relevant items for the interview process by learning the Qi weights using an L1 regulation, as explained in Equation (7). At this stage, we learn only the Qi values, which allow us to select which items to use during the interview, following Equation (6). After the interview, each new user modifies the incoming evaluation, which is explained in a new calculation system, which leads to a representation of the Qi."}, {"heading": "4 RELATED WORK", "text": "The referral problem has been examined under various assumptions: we focus on methods of collaborative filtering (CF) that use only the user and item ratings observed in the past, but other families of approaches exist, as content-based methods that use informative attributes about users and items (Pazzani & Billsus (2007)), and hybrid methods that mix ratings and informative attributes (Basilico & Hofmann (2004). CF techniques can be distinguished into two categories. Memory-based methods, such as Neighborbased CF Resnick et al (1994), calculate weights between items (Sarwar et al. (2001) or users (Herlocker et al. (1999))), based on similarities or correlations between them. Model-based methods, such as latent factor models, tend to have a representative learning approach that uses representation vectors for each user and item."}, {"heading": "5 CONCLUSION AND PERSPECTIVES", "text": "This inductive model (IAM) calculates the representation of a user directly through cumulative translations in the marquee area, with each translation depending on a rating for a particular item. We have also proposed a generic formulation of the user's cold start problem as a representative learning problem, and demonstrated that the IAM method can be instantiated within this framework, so that one can learn both which items to use to create a pre-interview for incoming users, and how to use these ratings for recommendations. Results from four sets of data show the ability of our approach to outperform basic methods. Different research directions are opened up by this work: (i) First, the model can certainly be extended to both incoming users, but also to new items. In this latter case, the interview process would consist of asking ratings for new items on a specific subset of relevant users. (ii) While we have dealt with the problem of creating a static interview based on a new set of personalized interviews currently being created."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This article was supported within the framework of the Labex SMART, which is supported by the French public funds managed by the ANR under the Investissements d'Avenir programme under the reference ANR-11-LABX-65. Part of this work was supported by the DGA-RAPID programme, Project LuxidX."}], "references": [{"title": "Unifying collaborative and content-based filtering", "author": ["Basilico", "Justin", "Hofmann", "Thomas"], "venue": "In Proceedings of the twenty-first international conference on Machine learning,", "citeRegEx": "Basilico et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Basilico et al\\.", "year": 2004}, {"title": "Representation learning: A review and new perspectives", "author": ["Bengio", "Yoshua", "Courville", "Aaron", "Vincent", "Pascal"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Lazy sparse stochastic gradient descent for regularized multinomial logistic regression", "author": ["Carpenter", "Bob"], "venue": "Alias-i, Inc., Tech. Rep, pp", "citeRegEx": "Carpenter and Bob.,? \\Q2008\\E", "shortCiteRegEx": "Carpenter and Bob.", "year": 2008}, {"title": "On bootstrapping recommender systems", "author": ["Golbandi", "Nadav", "Koren", "Yehuda", "Lempel", "Ronny"], "venue": "In Proceedings of the 19th ACM CIKM,", "citeRegEx": "Golbandi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Golbandi et al\\.", "year": 2010}, {"title": "Adaptive bootstrapping of recommender systems using decision trees", "author": ["Golbandi", "Nadav", "Koren", "Yehuda", "Lempel", "Ronny"], "venue": "In Proceedings of the fourth ACM international conference on Web search and data mining,", "citeRegEx": "Golbandi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Golbandi et al\\.", "year": 2011}, {"title": "An algorithmic framework for performing collaborative filtering", "author": ["Herlocker", "Jonathan L", "Konstan", "Joseph A", "Borchers", "Al", "Riedl", "John"], "venue": "In Proceedings of the 22nd annual international ACM SIGIR,", "citeRegEx": "Herlocker et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Herlocker et al\\.", "year": 1999}, {"title": "Factor in the neighbors: Scalable and accurate collaborative filtering", "author": ["Koren", "Yehuda"], "venue": "ACM Transactions on Knowledge Discovery from Data (TKDD),", "citeRegEx": "Koren and Yehuda.,? \\Q2010\\E", "shortCiteRegEx": "Koren and Yehuda.", "year": 2010}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Koren", "Yehuda", "Bell", "Robert", "Volinsky", "Chris"], "venue": null, "citeRegEx": "Koren et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koren et al\\.", "year": 2009}, {"title": "Content-based recommendation systems", "author": ["Pazzani", "Michael J", "Billsus", "Daniel"], "venue": "In The adaptive web,", "citeRegEx": "Pazzani et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pazzani et al\\.", "year": 2007}, {"title": "Getting to know you: learning new user preferences in recommender systems", "author": ["Rashid", "Al Mamunur", "Albert", "Istvan", "Cosley", "Dan", "Lam", "Shyong K", "McNee", "Sean M", "Konstan", "Joseph A", "Riedl", "John"], "venue": "In Proceedings of the 7th IUI,", "citeRegEx": "Rashid et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Rashid et al\\.", "year": 2002}, {"title": "Learning preferences of new users in recommender systems: an information theoretic approach", "author": ["Rashid", "Al Mamunur", "Karypis", "George", "Riedl", "John"], "venue": "ACM SIGKDD Explorations Newsletter,", "citeRegEx": "Rashid et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rashid et al\\.", "year": 2008}, {"title": "Grouplens: an open architecture for collaborative filtering of netnews", "author": ["Resnick", "Paul", "Iacovou", "Neophytos", "Suchak", "Mitesh", "Bergstrom", "Peter", "Riedl", "John"], "venue": "In Proceedings of the 1994 ACM conference on Computer supported cooperative work,", "citeRegEx": "Resnick et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Resnick et al\\.", "year": 1994}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["Sarwar", "Badrul", "Karypis", "George", "Konstan", "Joseph", "Riedl", "John"], "venue": "In Proceedings of WWW,", "citeRegEx": "Sarwar et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Sarwar et al\\.", "year": 2001}, {"title": "Learning multiple-question decision trees for cold-start recommendation", "author": ["Sun", "Mingxuan", "Li", "Fuxin", "Lee", "Joonseok", "Zhou", "Ke", "Lebanon", "Guy", "Zha", "Hongyuan"], "venue": "In Proceedings of the sixth ACM international conference on Web search and data mining,", "citeRegEx": "Sun et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2013}, {"title": "Functional matrix factorizations for cold-start recommendation", "author": ["Zhou", "Ke", "Yang", "Shuang-Hong", "Zha", "Hongyuan"], "venue": "In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,", "citeRegEx": "Zhou et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 1, "context": "As highlighted by Bengio et al. (2013), designing models able to learn these representations from (raw) data instead of manual pre-processing seems crucial to go further in Artificial Intelligence, and representation learning has gain a surge of interest in machine learning.", "startOffset": 18, "endOffset": 39}, {"referenceID": 7, "context": "This loss corresponds to a matrix decomposition in latent factors and different optimization algorithms have been proposed as alternated least squares or stochastic gradient descent (Koren et al. (2009)).", "startOffset": 183, "endOffset": 203}, {"referenceID": 12, "context": "The datasets are classical datasets used in the literature (Zhou et al. (2011); Golbandi et al.", "startOffset": 60, "endOffset": 79}, {"referenceID": 3, "context": "(2011); Golbandi et al. (2010)).", "startOffset": 8, "endOffset": 31}, {"referenceID": 9, "context": "As MF and ItemKNN do not provide a way to select a set of items for the interview, we use two benchmark selection methods used in the literature (Rashid et al. (2002)).", "startOffset": 146, "endOffset": 167}, {"referenceID": 9, "context": "As MF and ItemKNN do not provide a way to select a set of items for the interview, we use two benchmark selection methods used in the literature (Rashid et al. (2002)). The POP method select the most popular items - i.e the items with the highest number of ratings in the training set - and the HELF (Harmonic mean of Entropy and Logarithm of rating Frequency) method which select items based on both their popularity but also using an entropy criterion, which focus on the informativeness of items (e.g a controversial movie can be more informative than a movie liked by everyone) (Rashid et al. (2008)).", "startOffset": 146, "endOffset": 604}, {"referenceID": 5, "context": "Memory-based methods, such as Neighborbased CF Resnick et al. (1994), calculate weights between pairs of items (Sarwar et al.", "startOffset": 47, "endOffset": 69}, {"referenceID": 5, "context": "Memory-based methods, such as Neighborbased CF Resnick et al. (1994), calculate weights between pairs of items (Sarwar et al. (2001)) or users (Herlocker et al.", "startOffset": 47, "endOffset": 133}, {"referenceID": 3, "context": "(2001)) or users (Herlocker et al. (1999)), based on similarities or correlations between them.", "startOffset": 18, "endOffset": 42}, {"referenceID": 3, "context": "(2001)) or users (Herlocker et al. (1999)), based on similarities or correlations between them. Model-based methods, such as Latent Factor Models, have rather a representation learning approach, where representations vectors for each user and item are inferred from the matrix of ratings with matrix factorization techniques (Koren et al. (2009)).", "startOffset": 18, "endOffset": 346}, {"referenceID": 3, "context": "(2001)) or users (Herlocker et al. (1999)), based on similarities or correlations between them. Model-based methods, such as Latent Factor Models, have rather a representation learning approach, where representations vectors for each user and item are inferred from the matrix of ratings with matrix factorization techniques (Koren et al. (2009)). Collaborative filtering models have a major limitation when there is no history for a user or an item. A classical approach in this case is to use an interview process with a few questions asked to the new user as it is done in this paper. Several papers have proposed different methods to choose which questions to select. Static approaches (see Rashid et al. (2002) for a comparative study), construct a static seed set of questions (fixed for all users) following a selection criterion like measures of popularity, entropy or coverage while Golbandi et al.", "startOffset": 18, "endOffset": 716}, {"referenceID": 3, "context": "(2002) for a comparative study), construct a static seed set of questions (fixed for all users) following a selection criterion like measures of popularity, entropy or coverage while Golbandi et al. (2010) also proposed a greedy algorithm that aims to minimize the prediction error performed with the seed set.", "startOffset": 183, "endOffset": 206}, {"referenceID": 3, "context": "(2002) for a comparative study), construct a static seed set of questions (fixed for all users) following a selection criterion like measures of popularity, entropy or coverage while Golbandi et al. (2010) also proposed a greedy algorithm that aims to minimize the prediction error performed with the seed set. Adaptive approaches have also been proposed, where the interview process considers the user\u2019s answers to choose the next question. For example, Rashid et al. (2008) fits a decision tree to find a set of clusters of users, while Golbandi et al.", "startOffset": 183, "endOffset": 476}, {"referenceID": 3, "context": "(2002) for a comparative study), construct a static seed set of questions (fixed for all users) following a selection criterion like measures of popularity, entropy or coverage while Golbandi et al. (2010) also proposed a greedy algorithm that aims to minimize the prediction error performed with the seed set. Adaptive approaches have also been proposed, where the interview process considers the user\u2019s answers to choose the next question. For example, Rashid et al. (2008) fits a decision tree to find a set of clusters of users, while Golbandi et al. (2011) uses a ternary tree where each node is an item and branch corresponds to eventual answers (like,dislike,unknown).", "startOffset": 183, "endOffset": 562}, {"referenceID": 3, "context": "(2002) for a comparative study), construct a static seed set of questions (fixed for all users) following a selection criterion like measures of popularity, entropy or coverage while Golbandi et al. (2010) also proposed a greedy algorithm that aims to minimize the prediction error performed with the seed set. Adaptive approaches have also been proposed, where the interview process considers the user\u2019s answers to choose the next question. For example, Rashid et al. (2008) fits a decision tree to find a set of clusters of users, while Golbandi et al. (2011) uses a ternary tree where each node is an item and branch corresponds to eventual answers (like,dislike,unknown). Zhou et al. (2011) presents functional matrix factorization, a decision tree based method which also associate a latent profile to each nodes of the tree.", "startOffset": 183, "endOffset": 695}, {"referenceID": 3, "context": "(2002) for a comparative study), construct a static seed set of questions (fixed for all users) following a selection criterion like measures of popularity, entropy or coverage while Golbandi et al. (2010) also proposed a greedy algorithm that aims to minimize the prediction error performed with the seed set. Adaptive approaches have also been proposed, where the interview process considers the user\u2019s answers to choose the next question. For example, Rashid et al. (2008) fits a decision tree to find a set of clusters of users, while Golbandi et al. (2011) uses a ternary tree where each node is an item and branch corresponds to eventual answers (like,dislike,unknown). Zhou et al. (2011) presents functional matrix factorization, a decision tree based method which also associate a latent profile to each nodes of the tree. The closest model to our approach is Sun et al. (2013), who learn a ternary tree allowing multiple questions at each node, each node containing a (learned) regressor and translations functions on selected items.", "startOffset": 183, "endOffset": 886}, {"referenceID": 3, "context": "(2002) for a comparative study), construct a static seed set of questions (fixed for all users) following a selection criterion like measures of popularity, entropy or coverage while Golbandi et al. (2010) also proposed a greedy algorithm that aims to minimize the prediction error performed with the seed set. Adaptive approaches have also been proposed, where the interview process considers the user\u2019s answers to choose the next question. For example, Rashid et al. (2008) fits a decision tree to find a set of clusters of users, while Golbandi et al. (2011) uses a ternary tree where each node is an item and branch corresponds to eventual answers (like,dislike,unknown). Zhou et al. (2011) presents functional matrix factorization, a decision tree based method which also associate a latent profile to each nodes of the tree. The closest model to our approach is Sun et al. (2013), who learn a ternary tree allowing multiple questions at each node, each node containing a (learned) regressor and translations functions on selected items. Our model can be seen as one node of their tree. However, their approach does not seem to allow a bridge between cold start and warm context as ours does. It is also interesting to note that while usually more efficient, one drawback of such adaptive approaches is that users usually dislike having to rate item one by one and prefer rating several items in one shot (Golbandi et al. (2011); Rashid et al.", "startOffset": 183, "endOffset": 1434}, {"referenceID": 3, "context": "(2002) for a comparative study), construct a static seed set of questions (fixed for all users) following a selection criterion like measures of popularity, entropy or coverage while Golbandi et al. (2010) also proposed a greedy algorithm that aims to minimize the prediction error performed with the seed set. Adaptive approaches have also been proposed, where the interview process considers the user\u2019s answers to choose the next question. For example, Rashid et al. (2008) fits a decision tree to find a set of clusters of users, while Golbandi et al. (2011) uses a ternary tree where each node is an item and branch corresponds to eventual answers (like,dislike,unknown). Zhou et al. (2011) presents functional matrix factorization, a decision tree based method which also associate a latent profile to each nodes of the tree. The closest model to our approach is Sun et al. (2013), who learn a ternary tree allowing multiple questions at each node, each node containing a (learned) regressor and translations functions on selected items. Our model can be seen as one node of their tree. However, their approach does not seem to allow a bridge between cold start and warm context as ours does. It is also interesting to note that while usually more efficient, one drawback of such adaptive approaches is that users usually dislike having to rate item one by one and prefer rating several items in one shot (Golbandi et al. (2011); Rashid et al. (2002)).", "startOffset": 183, "endOffset": 1456}], "year": 2015, "abstractText": "A standard approach to Collaborative Filtering (CF), i.e. prediction of user ratings on items, relies on Matrix Factorization techniques. Representations for both users and items are computed from the observed ratings and used for prediction. Unfortunatly, these transductive approaches cannot handle the case of new users arriving in the system, with no known rating, a problem known as user cold-start. A common approach in this context is to ask these incoming users for a few initialization ratings. This paper presents a model to tackle this twofold problem of (i) finding good questions to ask, (ii) building efficient representations from this small amount of information. The model can also be used in a more standard (warm) context. Our approach is evaluated on the classical CF problem and on the cold-start problem on four different datasets showing its ability to improve baseline performance in both cases.", "creator": "LaTeX with hyperref package"}}}