{"id": "1412.7525", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Dec-2014", "title": "Difference Target Propagation", "abstract": "Back-propagation has been the workhorse of recent successes of deep learning but it relies on infinitesimal effects (partial derivatives) in order to perform credit assignment. This could become a serious issue as one considers deeper and more non-linear functions, e.g., consider the extreme case of non-linearity where the relation between parameters and cost is actually discrete. Inspired by the biological implausibility of back-propagation, a few approaches have been proposed in the past that could play a similar credit assignment role as back-prop. In this spirit, we explore a novel approach to credit assignment in deep networks that we call target propagation. The main idea is to compute targets rather than gradients, at each layer. Like gradients, they are propagated backwards. In a way that is related but different from previously proposed proxies for back-propagation which rely on a backwards network with symmetric weights, target propagation relies on auto-encoders at each layer. Unlike back-propagation, it can be applied even when units exchange stochastic bits rather than real numbers. We show that a linear correction for the imperfectness of the auto-encoders is very effective to make target propagation actually work, along with adaptive learning rates.", "histories": [["v1", "Tue, 23 Dec 2014 20:57:59 GMT  (327kb,D)", "http://arxiv.org/abs/1412.7525v1", "11 pages, 8 figures, Under review as a conference paper at ICLR 2015"], ["v2", "Tue, 3 Mar 2015 16:54:57 GMT  (313kb,D)", "http://arxiv.org/abs/1412.7525v2", "11 pages, 8 figures, Under review as a conference paper at ICLR 2015"], ["v3", "Sat, 18 Apr 2015 01:01:54 GMT  (418kb,D)", "http://arxiv.org/abs/1412.7525v3", "13 pages, 8 figures, Workshop paper at ICLR 2015"], ["v4", "Sat, 14 Nov 2015 07:05:40 GMT  (418kb,D)", "http://arxiv.org/abs/1412.7525v4", "13 pages, 8 figures, Workshop paper at ICLR 2015"], ["v5", "Wed, 25 Nov 2015 02:30:41 GMT  (413kb,D)", "http://arxiv.org/abs/1412.7525v5", "13 pages, 8 figures, Accepted in ECML/PKDD 2015"]], "COMMENTS": "11 pages, 8 figures, Under review as a conference paper at ICLR 2015", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["dong-hyun lee", "saizheng zhang", "asja fischer", "yoshua bengio"], "accepted": true, "id": "1412.7525"}, "pdf": {"name": "1412.7525.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Dong-Hyun Lee", "Saizheng Zhang", "Antoine Biard", "Yoshua Bengio"], "emails": [], "sections": [{"heading": null, "text": "Re-propagation has been the workhorse of recent successes in deep learning, but it relies on infinitesimal effects (sub-derivatives) to lend, which could become a serious problem considering deeper and more non-linear functions, such as the extreme case of non-linearity, where the relationship between parameters and costs is actually discreet. Inspired by the biological implausibility of re-propagation, some approaches have been proposed in the past that could play a similar role in lending as backprop. In this sense, we are exploring a novel approach to low-level lending, which we call target propagation. The main idea is to calculate targets at each level instead of gradients. Like gradients, they are propagated backwards. In a way that is related, but unlike previously proposed proxies for re-propagation that rely on a symmetrical weight, target propagation rates on codients are effective when they are reliant on reverse-effective units, as opposed to those that are actually automated."}, {"heading": "1 INTRODUCTION", "text": "In fact, we are able to go in search of a solution that is capable of finding a solution that is capable of finding a solution, that is capable of finding a solution, and that is able to find a solution that is capable of finding a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution, that is able to find a solution. \""}, {"heading": "2 PROPOSED TARGET PROPAGATION IMPLEMENTATION", "text": "Although many variants of the general principle of target multiplication can be developed, this paper focuses on a specific approach that is described below and addresses a problem in the formulation presented in an earlier technical report (Bengio, 2014)."}, {"heading": "2.1 FORMULATING TARGETS", "text": "Let us consider an ordinary, deep network learning process. Unknown data distribution is p (x, y), from which the training data is scanned. (W) The network structure is defined ashi = fi (hi \u2212 1) = si (Wihi \u2212 1), i = 1,.., M (1), where hi is the hidden layer, hM is the output of the network, h0 is the input x, si is the nonlinearity (e.g. tanh or sigmoid) and Wi is the weights for layer i, fi is the i-th layer forward mapping. For the simplicity (but an abuse) of notation, the bias term of each layer is contained in Wi. We define j W as the subset of network parameters i, j W = {Wk, k = i + 1., j}."}, {"heading": "2.2 HOW TO ASSIGN A PROPER TARGET TO EACH LAYER", "text": "The problem with lending is this: how should each unit change its performance to increase the probability of reducing the global loss? (1) This error signal is recursively passed from the top level to the bottom level, calculating the gradient of loss in relation to the performance of each level, and we can interpret this gradient as an error signal. (8) In the target prop setting, the signal that gives the direction for the update is the difference between the first and last stage of the equation, and we get: (1) Li \u2212 1 = (h) hi-1 = (h) in the target prop setting is the signal that gives the direction for the update."}, {"heading": "2.3 THE ADVANTAGE OF DIFFERENCE TARGET PROPAGATION", "text": "To stabilize the optimization in the target propagation, hi \u2212 i \u2212 i \u2212 i (hi \u2212 i) i \u2212 i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (hi \u2212 i) i (i) i) i (i) i (i) i) i (i) i (i) (i) (i) i (i) i (i) i (i) i (i) i (i) i (i) i (i) (i) i) (i) (i) (i) (i) i) (i) (i) (i) i) (i) (i) (i) (i) (i) (i) (i) (i) (i) (i) (i) (i) (i) i) (i) (i) (i) (i) (i) (i) (i) (i) (i) (i) (i) (i) (i) i) i (i) i (i) i (i) i (i) i (i) i (i) i (i) i (i) (i) i) i (i) i (i) i (i) i (i) i (i) i (i) i (i) i (i) (i) i (i) (i) (i) (i) i (i) (i) i (i) (i) i (i) (i) (i) (i) i (i) i (i) (i) (i) (i) i (i) (i) (i) i (i) i (i) (i) i (i) (i) i (i) (i) i (i) (i) (i) i (i) (i) (i (i) (i) i (i) (i) (i) (i) i) i (i) i (i) (i) i (i (i) i) i (i) (i"}, {"heading": "3 EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 VERY DEEP NETWORKS", "text": "The network has 7 hidden layers and the number of hidden units is 240. The activation function is the hyperbolic tangent (tanh). We use RMSprop as an adaptive learning rate algorithm because we do not have a global loss for optimization. Instead, we have the local layered target losses that their learning rates might need on different scales (this is what we find when we perform hyper-parameter optimizations on the individual learning rates for each layer). To get this result, we chose the optimal hyper parameters for the best training costs by random search, and the weights are initialized with orthogonal random matrices. To improve the optimization results, layers are updated individually from the bottom layer to the top layer to avoid problems with the current input of each layer that is invalid when we update all layers at a given time."}, {"heading": "3.2 NETWORKS WITH DISCRETIZED TRANSMISSION BETWEEN UNITS", "text": "The network architecture is 784-500-500-10 and only the 1st hidden layer is discredited. Instead of using only the step activation function, we have normal neural layers with tanh, and signals are discredited when transported between layer 1 and layer 2, based on biological considerations and the goal of reducing communication costs between neurons."}, {"heading": "3.3 STOCHASTIC NETWORKS", "text": "Another interesting learning problem that backprop cannot handle well are stochastic networks with separate units. Recently, such networks have attracted attention (Bengio, 2013; Tang and Salakhutdinov, 2013; Bengio et al., 2013) because a stochastic network can learn a multimodal conditional distribution P (Y | X), which is important for structured output predictions. Educational networks of stochastic binary units are also motivated by biology, i.e. they resemble networks of donating neurons. Here, we investigate whether networks of stochastic binary units at MNIST can be trained for classification using target propagation. \u2212 Following Raiko et al al al al al al al al al al al. (2014), the network architecture is 784-200-200-10 and the hidden units are stochastic binary units with the probability that we will activate the specified sigmoid network."}, {"heading": "3.4 BACKPROP-FREE AUTO-ENCODER", "text": "In this context, it should be noted that the training of an auto encoder is also part of what is required for target propagation to train the feedback paths that propagate the targets. (Vincent et al., 2010) and Generative Stochastic Networks (Bengio et al., 2014), we consider the denoizing auto encoder as a stochastic network injected into the input and hidden units to minimize reconstruction loss (Vincent et al., 2010) and Generative Stochastic Networks (Bengio et al., 2014), we consider the denosizing auto encoder as a stochastic network that minimizes reconstruction losses."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank Junyoung Chung for providing the RMS prop code, Caglar Gulcehre for general discussion and feedback, Jyri Kivinen for discussing the backprop-free auto encoder, Mathias Berglund for explaining his stochastic networks, and the developers of Theano (Bergstra et al., 2010; Bastien et al., 2012), a Python library that enabled us to easily develop fast and optimized code for GPU. We also thank the developers of Pylearn2 (Goodfellow et al., 2013), a Python library built on top of Theano that enabled us to easily link the data sets to our Theano code. We are also grateful for the support of NSERC, the Canada Research Chairs, Compute Canada, and CIFAR."}, {"heading": "A PROOF OF PROPOSITION 1", "text": "During an update, the training sample (x, y) is the one where we assume that fi = Z (hi \u2212 1) = Z (hi \u2212 1) = Z (hi \u2212 1), i = Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 \u2212 Z \u2212 \u2212 \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z \u2212 Z"}, {"heading": "B PROOF OF PROPOSITION 2", "text": "(V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (T) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (T) (V) (t) (V) (V) (V) (V) (T) (V) (V) (V) (V) (V) (T) (V) (V) (T) (V) (T) (V) (V) (T) (T) (V) (V) (T) (T) (T) (T) (V) (T) (T) (V) (T) (T) (V) (T) (T) (V) (T) (T) (V) (T) (V) (T) (T) (T) (V (V) (T) (V) (T) (T) (V (T) (T) (T (V) (T) (V) (T (T) (V (V) (T (V) (V) (T) (T (T) (V) (T (T) (T) (T (V) (T (V) (T (V) (T (V) (V) (T (V) (T (T) (T) (T) (T) (T (V) (T (V) (T (V) (T) (T (T (T) (T) (V) (V) (V) (T (V) (T) (T (T (V) (T (T (T) (V) (T) (T) (V) (T (T (T) (T) (V) (T"}], "references": [{"title": "Theano: new features and speed improvements", "author": ["F. Bastien", "P. Lamblin", "R. Pascanu", "J. Bergstra", "I.J. Goodfellow", "A. Bergeron", "N. Bouchard", "Y. Bengio"], "venue": "Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop.", "citeRegEx": "Bastien et al\\.,? 2012", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "Learning deep architectures for AI", "author": ["Y. Bengio"], "venue": "Now Publishers.", "citeRegEx": "Bengio,? 2009", "shortCiteRegEx": "Bengio", "year": 2009}, {"title": "Estimating or propagating gradients through stochastic neurons", "author": ["Y. Bengio"], "venue": "Technical Report arXiv:1305.2982, Universite de Montreal.", "citeRegEx": "Bengio,? 2013", "shortCiteRegEx": "Bengio", "year": 2013}, {"title": "How auto-encoders could provide credit assignment in deep networks via target propagation", "author": ["Y. Bengio"], "venue": "Technical report, arXiv preprint arXiv:1407.7906.", "citeRegEx": "Bengio,? 2014", "shortCiteRegEx": "Bengio", "year": 2014}, {"title": "Estimating or propagating gradients through stochastic neurons for conditional computation", "author": ["Y. Bengio", "N. L\u00e9onard", "A. Courville"], "venue": "arXiv preprint arXiv:1308.3432.", "citeRegEx": "Bengio et al\\.,? 2013", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Deep generative stochastic networks trainable by backprop", "author": ["Y. Bengio", "E. Thibodeau-Laufer", "J. Yosinski"], "venue": "ICML\u20192014.", "citeRegEx": "Bengio et al\\.,? 2014", "shortCiteRegEx": "Bengio et al\\.", "year": 2014}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. WardeFarley", "Y. Bengio"], "venue": "Proceedings of the Python for Scientific Computing Conference (SciPy). Oral Presentation.", "citeRegEx": "Bergstra et al\\.,? 2010", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "Online algorithms and stochastic approximations", "author": ["L. Bottou"], "venue": "Saad, D., editor, Online Learning and Neural Networks. Cambridge University Press, Cambridge, UK. revised, oct 2012.", "citeRegEx": "Bottou,? 1998", "shortCiteRegEx": "Bottou", "year": 1998}, {"title": "Distributed optimization of deeply nested systems", "author": ["M. Carreira-Perpinan", "W. Wang"], "venue": "AISTATS\u20192014, JMLR W&CP, volume 33, pages 10\u201319.", "citeRegEx": "Carreira.Perpinan and Wang,? 2014", "shortCiteRegEx": "Carreira.Perpinan and Wang", "year": 2014}, {"title": "Why does unsupervised pre-training help deep learning? In JMLR W&CP: Proc", "author": ["D. Erhan", "A. Courville", "Y. Bengio", "P. Vincent"], "venue": "AISTATS\u20192010, volume 9, pages 201\u2013208.", "citeRegEx": "Erhan et al\\.,? 2010", "shortCiteRegEx": "Erhan et al\\.", "year": 2010}, {"title": "Pylearn2: a machine learning research library", "author": ["I.J. Goodfellow", "D. Warde-Farley", "P. Lamblin", "V. Dumoulin", "M. Mirza", "R. Pascanu", "J. Bergstra", "F. Bastien", "Y. Bengio"], "venue": "arXiv preprint arXiv:1308.4214.", "citeRegEx": "Goodfellow et al\\.,? 2013", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2013}, {"title": "Deep neural networks for acoustic modeling in speech recognition", "author": ["G. Hinton", "L. Deng", "G.E. Dahl", "A. Mohamed", "N. Jaitly", "A. Senior", "V. Vanhoucke", "P. Nguyen", "T. Sainath", "B. Kingsbury"], "venue": "IEEE Signal Processing Magazine, 29(6):82\u201397.", "citeRegEx": "Hinton et al\\.,? 2012", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G. Hinton"], "venue": "NIPS\u20192012.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Learning processes in an asymmetric threshold network", "author": ["Y. LeCun"], "venue": "Fogelman-Souli\u00e9, F., Bienenstock, E., and Weisbuch, G., editors, Disordered Systems and Biological Organization, pages 233\u2013240. Springer-Verlag, Les Houches, France.", "citeRegEx": "LeCun,? 1986", "shortCiteRegEx": "LeCun", "year": 1986}, {"title": "Mod\u00e8les connexionistes de l\u2019apprentissage", "author": ["Y. LeCun"], "venue": "PhD thesis, Universit\u00e9 de Paris VI.", "citeRegEx": "LeCun,? 1987", "shortCiteRegEx": "LeCun", "year": 1987}, {"title": "Random feedback weights support learningin deep neural networks", "author": ["T.P. Lillicrap", "D. Cownden", "D.B. Tweed", "C.J. Akerman"], "venue": "Technical report, arXiv preprint arXiv:1411.0247.", "citeRegEx": "Lillicrap et al\\.,? 2014", "shortCiteRegEx": "Lillicrap et al\\.", "year": 2014}, {"title": "Techniques for learning binary stochastic feedforward neural networks", "author": ["T. Raiko", "M. Berglund", "G. Alain", "L. Dinh"], "venue": "NIPS Deep Learning Workshop 2014.", "citeRegEx": "Raiko et al\\.,? 2014", "shortCiteRegEx": "Raiko et al\\.", "year": 2014}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Technical report, arXiv preprint arXiv:1409.3215.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "Technical report, arXiv preprint arXiv:1409.4842.", "citeRegEx": "Szegedy et al\\.,? 2014", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "A new learning algorithm for stochastic feedforward neural nets", "author": ["Y. Tang", "R. Salakhutdinov"], "venue": "ICML\u20192013 Workshop on Challenges in Representation Learning.", "citeRegEx": "Tang and Salakhutdinov,? 2013", "shortCiteRegEx": "Tang and Salakhutdinov", "year": 2013}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Tieleman and Hinton,? \\Q2012\\E", "shortCiteRegEx": "Tieleman and Hinton", "year": 2012}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["P. Vincent", "H. Larochelle", "I. Lajoie", "Y. Bengio", "Manzagol", "P.-A."], "venue": "J. Machine Learning Res., 11.", "citeRegEx": "Vincent et al\\.,? 2010", "shortCiteRegEx": "Vincent et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 1, "context": "Recently, deep neural networks have achieved great success in hard AI tasks (Bengio, 2009; Hinton et al., 2012; Krizhevsky et al., 2012; Sutskever et al., 2014), mostly relying on back-propagation as the main way of performing credit assignment over the different sets of parameters associated with each layer of a deep net.", "startOffset": 76, "endOffset": 160}, {"referenceID": 11, "context": "Recently, deep neural networks have achieved great success in hard AI tasks (Bengio, 2009; Hinton et al., 2012; Krizhevsky et al., 2012; Sutskever et al., 2014), mostly relying on back-propagation as the main way of performing credit assignment over the different sets of parameters associated with each layer of a deep net.", "startOffset": 76, "endOffset": 160}, {"referenceID": 12, "context": "Recently, deep neural networks have achieved great success in hard AI tasks (Bengio, 2009; Hinton et al., 2012; Krizhevsky et al., 2012; Sutskever et al., 2014), mostly relying on back-propagation as the main way of performing credit assignment over the different sets of parameters associated with each layer of a deep net.", "startOffset": 76, "endOffset": 160}, {"referenceID": 17, "context": "Recently, deep neural networks have achieved great success in hard AI tasks (Bengio, 2009; Hinton et al., 2012; Krizhevsky et al., 2012; Sutskever et al., 2014), mostly relying on back-propagation as the main way of performing credit assignment over the different sets of parameters associated with each layer of a deep net.", "startOffset": 76, "endOffset": 160}, {"referenceID": 18, "context": ", consider the recent best ImageNet competition entrants (Szegedy et al., 2014) with 19 or 22 layers \u2013 longer-term dependencies, or stronger non-linearities, the composition of many non-linear operations becomes more non-linear.", "startOffset": 57, "endOffset": 79}, {"referenceID": 13, "context": "This link was nicely made in (LeCun, 1986; 1987), which introduced the idea of target propagation and connected it to back-propagation via a Lagrange multipliers formulation (where the constraints require the output of one layer to equal the input of the next layer).", "startOffset": 29, "endOffset": 48}, {"referenceID": 8, "context": "A similar idea was recently proposed where the constraints are relaxed into penalties, yielding a different (iterative) way to optimize deep networks (Carreira-Perpinan and Wang, 2014).", "startOffset": 150, "endOffset": 184}, {"referenceID": 20, "context": "The results show that the proposed form of target propagation is comparable to back-propagation with RMSprop (Tieleman and Hinton, 2012) - a very popular setting to train deep networks nowadays.", "startOffset": 109, "endOffset": 136}, {"referenceID": 3, "context": "Although many variants of the general principle of target propagation can be devised, this paper focuses on a specific approach, described below, which fixes a problem in the formulation introduced in an earlier technical report (Bengio, 2014).", "startOffset": 229, "endOffset": 243}, {"referenceID": 3, "context": "However, in order to avoid the chain of derivatives through many layers, another option, introduced in (Bengio, 2014), is to take advantage of an \u201capproximate inverse\u201d.", "startOffset": 103, "endOffset": 117}, {"referenceID": 3, "context": "This is the vanilla target propagation introduced in (Bengio, 2014): \u0125i\u22121 = gi(\u0125i) (12)", "startOffset": 53, "endOffset": 67}, {"referenceID": 7, "context": "Condition 1, 2, 4 follow the settings of stochastic gradient descent convergence similar to (Bottou, 1998).", "startOffset": 92, "endOffset": 106}, {"referenceID": 15, "context": "Actually, if fi and gi are linear mappings and gi has a random matrix, difference target propagation is equivalent to feedback alignment (Lillicrap et al., 2014) which works well on many datasets.", "startOffset": 137, "endOffset": 161}, {"referenceID": 3, "context": "Moreover, as gi approaches to f \u22121 i , this approaches to vanilla target propagation formula in (Bengio, 2014).", "startOffset": 96, "endOffset": 110}, {"referenceID": 2, "context": "Recently such networks have attracted attention (Bengio, 2013; Tang and Salakhutdinov, 2013; Bengio et al., 2013) because a stochastic network can learn a multi-modal conditional distribution P (Y |X), which is important for structured output predictions.", "startOffset": 48, "endOffset": 113}, {"referenceID": 19, "context": "Recently such networks have attracted attention (Bengio, 2013; Tang and Salakhutdinov, 2013; Bengio et al., 2013) because a stochastic network can learn a multi-modal conditional distribution P (Y |X), which is important for structured output predictions.", "startOffset": 48, "endOffset": 113}, {"referenceID": 4, "context": "Recently such networks have attracted attention (Bengio, 2013; Tang and Salakhutdinov, 2013; Bengio et al., 2013) because a stochastic network can learn a multi-modal conditional distribution P (Y |X), which is important for structured output predictions.", "startOffset": 48, "endOffset": 113}, {"referenceID": 1, "context": "Recently such networks have attracted attention (Bengio, 2013; Tang and Salakhutdinov, 2013; Bengio et al., 2013) because a stochastic network can learn a multi-modal conditional distribution P (Y |X), which is important for structured output predictions. Training networks of stochastic binary units is also motivated from biology, i.e., they resemble networks of spiking neurons. Here, we investigate whether one can train networks of stochastic binary units on MNIST for classification using target propagation. Following Raiko et al. (2014), the network architecture is 784-200-200-10 and the hidden units are stochastic binary units with the probability of turning on given by a sigmoid activation.", "startOffset": 49, "endOffset": 545}, {"referenceID": 1, "context": "Recently such networks have attracted attention (Bengio, 2013; Tang and Salakhutdinov, 2013; Bengio et al., 2013) because a stochastic network can learn a multi-modal conditional distribution P (Y |X), which is important for structured output predictions. Training networks of stochastic binary units is also motivated from biology, i.e., they resemble networks of spiking neurons. Here, we investigate whether one can train networks of stochastic binary units on MNIST for classification using target propagation. Following Raiko et al. (2014), the network architecture is 784-200-200-10 and the hidden units are stochastic binary units with the probability of turning on given by a sigmoid activation. hpi = \u03c3(Wihi\u22121), hi = sample(h p i ) (33) where sample(p) is a binary random variable which is 1 with probability p. As a baseline, we consider a biased gradient estimator in which we do back-propagation as if it were just continuous sigmoid networks. This baseline showed the best performance in Raiko et al. (2014). \u03b4hpi\u22121 = \u03b4h p i \u2202hpi \u2202hpi\u22121 \u223c \u03c3(Wihi\u22121)W i \u03b4h p i (34)", "startOffset": 49, "endOffset": 1021}, {"referenceID": 16, "context": "In the evalution, we averaged the output probabilities of an example over 100 noise samples, and then classify the example accordingly, following Raiko et al. (2014) This suggests that target propagation can directly deal with networks of binary stochastic units.", "startOffset": 146, "endOffset": 166}, {"referenceID": 16, "context": "The second row shows the results from (Raiko et al., 2014).", "startOffset": 38, "endOffset": 58}, {"referenceID": 16, "context": "In our experiment, we used RMS-prop and maximum epochs is 1000 different from (Raiko et al., 2014).", "startOffset": 78, "endOffset": 98}, {"referenceID": 9, "context": "Auto-encoders are interesting building blocks for learning representations, especially deep ones (Erhan et al., 2010).", "startOffset": 97, "endOffset": 117}, {"referenceID": 21, "context": "Like in the work on denoising auto-encoders (Vincent et al., 2010) and Generative Stochastic Networks (Bengio et al.", "startOffset": 44, "endOffset": 66}, {"referenceID": 5, "context": ", 2010) and Generative Stochastic Networks (Bengio et al., 2014), we consider the denoising auto-encoder like a stochastic network with noise injected in input and hidden units, trained to minimize a reconstruction loss.", "startOffset": 43, "endOffset": 64}], "year": 2017, "abstractText": "Back-propagation has been the workhorse of recent successes of deep learning but it relies on infinitesimal effects (partial derivatives) in order to perform credit assignment. This could become a serious issue as one considers deeper and more non-linear functions, e.g., consider the extreme case of non-linearity where the relation between parameters and cost is actually discrete. Inspired by the biological implausibility of back-propagation, a few approaches have been proposed in the past that could play a similar credit assignment role as backprop. In this spirit, we explore a novel approach to credit assignment in deep networks that we call target propagation. The main idea is to compute targets rather than gradients, at each layer. Like gradients, they are propagated backwards. In a way that is related but different from previously proposed proxies for back-propagation which rely on a backwards network with symmetric weights, target propagation relies on auto-encoders at each layer. Unlike back-propagation, it can be applied even when units exchange stochastic bits rather than real numbers. We show that a linear correction for the imperfectness of the auto-encoders is very effective to make target propagation actually work, along with adaptive learning rates.", "creator": "LaTeX with hyperref package"}}}