{"id": "1412.7659", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Dec-2014", "title": "Transformation Properties of Learned Visual Representations", "abstract": "When a three-dimensional object moves through a scene, a corresponding change occurs on the image plane and in the visual representation constructed by a learning algorithm. Starting with the idea that a good representation is one that transforms linearly under scene motions, we use standard results from group representation theory to show that any such representation is equivalent to a combination of particularly simple irreducible representations. We derive a striking relationship between irreducibility and the statistical dependency structure of the representation. Under partial observability, as induced by the perspective projection of a scene onto the image plane, the motion group does not have a linear action on the space of images, so that it becomes necessary to perform inference over a latent representation that does transform linearly. This idea is demonstrated in a model of rotating NORB objects that employs a latent representation of the non-commutative 3D rotation group SO(3).", "histories": [["v1", "Wed, 24 Dec 2014 13:19:20 GMT  (437kb,D)", "https://arxiv.org/abs/1412.7659v1", null], ["v2", "Tue, 3 Mar 2015 04:46:00 GMT  (439kb,D)", "http://arxiv.org/abs/1412.7659v2", null], ["v3", "Tue, 7 Apr 2015 21:20:04 GMT  (439kb,D)", "http://arxiv.org/abs/1412.7659v3", "T.S. Cohen &amp; M. Welling, Transformation Properties of Learned Visual Representations. In International Conference on Learning Representations (ICLR), 2015"]], "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["taco s cohen", "max welling"], "accepted": true, "id": "1412.7659"}, "pdf": {"name": "1412.7659.pdf", "metadata": {"source": "CRF", "title": "TRANSFORMATION PROPERTIES OF LEARNED VISUAL REPRESENTATIONS", "authors": ["Taco S. Cohen"], "emails": ["m.welling}@uva.nl"], "sections": [{"heading": "1 INTRODUCTION", "text": "Much has been written about invariant representations (e.g. Anselmi et al. (2014), and invariance to groups such as translations, rotations, and projected transformations is indeed very important for object recognition. But for a general purpose visual representation - which includes not only recognition tasks, but also understanding of motion and geometric reasoning - we are in a better position to create an integrated system that performs invariant representations as well as relative poses of objects."}, {"heading": "2 SYMMETRIES AND REPRESENTATIONS", "text": "We start from the basic assumption that our learning agent is situated in space, and therefore this space contains a scene. Formally, we present the scene as a function x: R3 \u2192 RK, which describes a list of numbers x (p) at each point in the room, for example, the color, transparency value, material properties, etc. In this and the next section, we proceed further on the assumption of full observability, i.e. that x is thought of as a vector in a Hilbert room S of sufficiently well behaved functions. As we will see, the following analysis does not depend on this particular data representation, but it provides useful intuition and is ultimately realistic. We say that the vector x is a representation of the scene, because the numerical values that one would store in a computer to describe or approximate x depend on \"what is in the scene\" and how it is represented in our preferred frame of reference. \""}, {"heading": "3 IRREDUCIBILITY, INDEPENDENCE AND DECORRELATION", "text": "The simplest examples are PCA and ICA, where the goal is to learn a linear model whose latent variables are all independent (with Gaussian or non-Gaussian boundary distributions); alternatively, one can focus on the properties of transformation and learn a representation that is irreducibly transformed under symmetrical transformations (Cohen & Welling, 2014); from this perspective, irreducible representations (and not independent factors) are the elementary parts from which observation vectors are constructed; in view of these conflicting conceptualizations of representation learning, it is interesting to examine how the transformation properties of a representation relate to its statistical properties; in this section, we show that irreducible representations are decorative or even conditionally independent."}, {"heading": "3.1 IRREDUCIBILITY AND DECORRELATION: AN ELEMENTARY EXAMPLE", "text": "To gain some intuition, we introduce a simple toy model of a fully observable system with symmetry. The states of the system are sufficiently well-behaved functions x: S \u00b2 R on the circle. Observations are generated by looking for an evenly distributed rotation angle and using it to rotate a template. That is, we have observations x: S \u00b2 R on the circle. In this case, the linear transformation F that achieves the reduction into irreducible representations is the standard Fourier transformation, and in fact, we will observe discredited functions with a finite number of coefficients xn = x (n). In this case, the linear transformation F that achieves the reduction into irreducible representations is the standard Fourier transformation, and in fact it will diagram the data (Bruna et al., 2013)."}, {"heading": "3.2 IRREDUCIBILITY AND DECORRELATION: GENERAL CASE", "text": "Theorem 1: Let G be a compact group, V a real vector space, and T: a completely reduced uniform representation of G in V. In addition: Let x = T = T (g) for a fixed template, B = V and G evenly distributed over G. The covariance matrix of the vectors in V is diagonal: Ep (g) [x-lmx-l \u00b2 m \u00b2] = \u03b4ll \u00b2 mm \u00b2 (in this case, class-related covariance should be taken into account) Using the orthogonality of the matrix elements of irreducible representations. See Appendix. The theorem can be easily generalized to more than one template (in this case, class-related covariance should be taken into account), and it is likely that a slightly weaker theorem is detectable for locally compact groups."}, {"heading": "3.3 IRREDUCIBILITY AND CONDITIONAL INDEPENDENCE", "text": "The concept of an irreducible representation can also shed light on time series models based on transformations (Cohen & Welling, 2014; Michalski et al., 2014).We define (xt | xt \u2212 1, g) = N (xt | T (g) xt \u2212 1, \u03c32), (5) where xt and xt \u2212 1 are sometimes observation vectors and T (g) represents a uniform representation of a compact group G. For G, one can construct an exponential family whose sufficient statistics are given by the matrix elements T-lmn (g) of irreducible uniform representations of G. As shown in Cohen & Welling, 2014) for the case of compact commutative groups, the inventory of the l2 standard in the exponent of the Gaussian elements results in a uniform transformation from G to a subordinate p (g | xt, xt \u2212 1) that results in the same exponential manner as the previous configuration (-1)."}, {"heading": "4 PARTIAL OBSERVABILITY", "text": "In reality, we do not observe the complete scene x-S, but only a projected image I-I, which we model as function I: R2 \u2192 R3 (for 3 color channels). Naively, one could try to construct a representation T-shaped: SE (3) \u00b7 I in such a way that the perspective projection \u03c0: S \u2192 I is an equivalent map: T-shaped (g) \u0445 \u03c0 = \u03c0 T (g), but this is not possible, because a 3D movement can bring completely new structures into the image. In classical computer vision, the solution is sought in strong assumptions about scene geometry, such as the assumption that the scene is planar, concealing a representation of the projective group on the image plane. This assumption leads to clean formulas, but real scenes are not flat. A better approach to the problem of partial observability is the modeling of all variabilities that are not caused by the linear action of a low-dimensional group."}, {"heading": "5 A LATENT GROUP REPRESENTATION", "text": "In this section, we define a simple model that shows the idea of a latent group representation. (We) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) center (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we) n (we)"}, {"heading": "5.2 COMPUTATION OF THE REPRESENTATION MATRICES", "text": "We now turn to the calculation of the transformation x \u00b2 T \u00b2 (g) x. Due to the block structure of T \u00b2 (J), this calculation decays into a large number of relatively small matrix elements multiplied. However, the matrix elements T \u00b2 lmn of the irreducible representations of SO (3) are known as Wigner-D. The formulas for these matrix elements by Wigner (1959) contain numerically unstable sums of many elements with large coefficients. Given the importance of these matrices in physical theories and their long history, a relatively new and very fast method leads to the calculation of the representation matrices of T \u2212 l on the basis of real spherical harmonies (Pinchon & Hoggan, 2007). The authors of this paper show that on the basis of real spherical harmonies, a rotation of ZYZ-Euler angles g = (g1, g2, g3) T = J \u00b2 l = three."}, {"heading": "5.3 LEARNING", "text": "We train the model with a stochastic hard EM algorithm, which involves alternating between the following steps: 1. With hard EM, the E-step consists of partial maximization with respect to zn and gn, v (v = 1,..., V) for a single instance n while retaining the parameters \u03b8, \u03c3x. We initialize the latent variables in the state of the last iteration and perform a step of gradient ascent to ln p (Xn, Gn, zn, zn, \u03b8, \u03c3x). 2. The M-step consists of a maximization with respect to the parameters \u03b8, \u03c3x while retaining latent variables. In our stochastic algorithm, we perform a single gradient step with ln p (Xn, Gn, zn, TB, \u03c3x). We use Adagrad for all optimizations (Duchi et al., 2011)."}, {"heading": "6 EXPERIMENTS", "text": "This data set consists of objects in 5 general categories: four-legged animals, human figures, airplanes, trucks and cars. Each category contains 10 examples, of which we used the last 5 for training. Finally, each instance is represented in 9 camera heights (30 to 70 degrees from the horizontal, in 5-degree steps) and 18 azimuths (0 to 340 degrees in 20-degree steps). Finally, there are 6 lighting conditions for each instance, which result in a total of 5 \u00b7 5 \u00b7 6 \u00b7 9 \u00b7 18 = 24300 images. The data were zero mean, contrast normalized and then PCA whitened, maintaining 95% of the variance. We used a neural network equipped with a hidden layer that contains 550 hidden units. The group representation T is determined by a selection of li; i = 1,., L, which we have chosen to be: [0] \u00b7 20 + [1] [4] \u00b7 10 + 4 + 10 + 10 + 10 + 10 + 10 + 10 + 10 figures, each of which consists of four-legged objects, [4]."}, {"heading": "7 RELATED WORK", "text": "Our work refers to the idea of transforming auto-encoders or \"capsules\" by Hinton et al. (2011). A transforming auto-encoder consists of many capsules, each of which learns to recognize a visual entity and predict its pose. Thus, the pose variables g are explicitly represented in the model and act linearly on other pose variables, as is the case in our model. In contrast to our model, a transforming auto-encoder presents the scene content as a set of probabilities, each of which indicates the probability that the preferred visual entity is present. The binary recognition unit used by a capsule for object z corresponds to an orbit O (z) = {T (g) z | g \"G\" in our model. Having a single latent space divided by several visual entities can help in generalization and makes it possible to calculate metric relations between different objects."}, {"heading": "8 CONCLUSION", "text": "As the problem of object recognition in static images steadily approaches \"solved\" status, we should begin to look toward the next frontier. One of the key challenges is to move away from the notion that images typically draw from an underlying distribution (as is only the case in today's benchmark datasets) and begin to model the dynamics of the visual world. Another challenge is to generalize effectively from a few examples that require the use of symmetries in data distribution, both of which require us to take a closer look at the transformation properties of learned visual representations.In this paper, we have theoretically examined the consequences of adopting a linear representation of a symmetry group in the observed or latent representation space. We have also shown that the entire class of such models can be understood mathematically (they are all direct sums of irreducible representations) and have shown how the rotation group specializes in the case theory."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was supported by NWO, grant number NAI.14.108."}, {"heading": "9 APPENDIX", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9.1 PROOF OF THEOREM 1", "text": "m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m-m"}], "references": [{"title": "Unsupervised learning of invariant representations with low sample complexity: the magic of sensory cortex or a new framework for machine learning", "author": ["Anselmi", "Fabio", "Leibo", "Joel Z", "Rosasco", "Lorenzo", "Mutch", "Jim", "Tacchetti", "Andrea", "Poggio", "Tomaso"], "venue": "Technical Report 001, MIT Center for Brains, Minds and Machines,", "citeRegEx": "Anselmi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Anselmi et al\\.", "year": 2014}, {"title": "Representation Learning: A Review and New Perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "A CPU and GPU math compiler in Python", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. WardeFarley", "Bengio", "Y. Theano"], "venue": "In Proceedings of the Python for Scientific Computing Conference (SciPy),", "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "Invariant scattering convolution networks", "author": ["Bruna", "Joan", "Mallat", "St\u00e9phane"], "venue": "IEEE transactions on pattern analysis and machine intelligence,", "citeRegEx": "Bruna et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bruna et al\\.", "year": 2013}, {"title": "Learning Stable Group Invariant Representations with Convolutional Networks", "author": ["Bruna", "Joan", "Szlam", "Arthur", "LeCun", "Yann"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Bruna et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bruna et al\\.", "year": 2013}, {"title": "Learning the Irreducible Representations of Commutative Lie Groups", "author": ["T. Cohen", "M. Welling"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Cohen and Welling,? \\Q2014\\E", "shortCiteRegEx": "Cohen and Welling", "year": 2014}, {"title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "author": ["Duchi", "John", "Hazan", "Elad", "Singer", "Yoram"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Deep Symmetry Networks", "author": ["Gens", "Robert", "Domingos", "Pedro"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Gens et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gens et al\\.", "year": 2014}, {"title": "Fast Training of Pose Detectors in the Fourier Domain", "author": ["Henriques", "Joao F", "Martins", "Pedro", "Caseiro", "Rui", "Batista", "Jorge"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Henriques et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Henriques et al\\.", "year": 2014}, {"title": "Transforming auto-encoders", "author": ["GE Hinton", "A Krizhevsky", "Wang", "SD"], "venue": "ICANN-11: International Conference on Artificial Neural Networks, Helsinki,", "citeRegEx": "Hinton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2011}, {"title": "Group Theoretical Methods in Image Understanding", "author": ["K. Kanatani"], "venue": null, "citeRegEx": "Kanatani,? \\Q1990\\E", "shortCiteRegEx": "Kanatani", "year": 1990}, {"title": "Rotation invariant spherical harmonic representation of 3D shape descriptors", "author": ["Kazhdan", "Michael", "Funkhouser", "Thomas", "Rusinkiewicz", "Szymon"], "venue": "In Eurographics Symposium on Geometry Processing,", "citeRegEx": "Kazhdan et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kazhdan et al\\.", "year": 2003}, {"title": "Learning methods for generic object recognition with invariance to pose and lighting", "author": ["Y. LeCun", "L. Bottou"], "venue": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "LeCun and Bottou,? \\Q2004\\E", "shortCiteRegEx": "LeCun and Bottou", "year": 2004}, {"title": "Group Invariant Scattering", "author": ["Mallat", "Stephane"], "venue": "Communications in Pure and Applied Mathematics,", "citeRegEx": "Mallat and Stephane.,? \\Q2012\\E", "shortCiteRegEx": "Mallat and Stephane.", "year": 2012}, {"title": "On multi-view feature learning", "author": ["R. Memisevic"], "venue": "International Conference on Machine Learning,", "citeRegEx": "Memisevic,? \\Q2012\\E", "shortCiteRegEx": "Memisevic", "year": 2012}, {"title": "Learning the Lie groups of visual invariance", "author": ["X. Miao", "R.P.N. Rao"], "venue": "Neural computation,", "citeRegEx": "Miao and Rao,? \\Q2007\\E", "shortCiteRegEx": "Miao and Rao", "year": 2007}, {"title": "Modeling Deep Temporal Dependencies with Recurrent Grammar Cells", "author": ["Michalski", "Vincent", "Memisevic", "Roland", "K. Konda"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Michalski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Michalski et al\\.", "year": 2014}, {"title": "Rotation matrices for real spherical harmonics: general rotations of atomic orbitals in space-fixed axes", "author": ["Pinchon", "Didier", "Hoggan", "Philip E"], "venue": "Journal of Physics A: Mathematical and Theoretical,", "citeRegEx": "Pinchon et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Pinchon et al\\.", "year": 2007}, {"title": "Learning Lie groups for invariant visual perception", "author": ["R.P.N. Rao", "D.L. Ruderman"], "venue": "Advances in neural information processing systems,", "citeRegEx": "Rao and Ruderman,? \\Q1999\\E", "shortCiteRegEx": "Rao and Ruderman", "year": 1999}, {"title": "Fast computation of 3d spherical fourier harmonic descriptors - a complete orthonormal basis for a rotational invariant representation of threedimensional objects", "author": ["Skibbe", "Henrik", "Wang", "Qing", "Reisert", "Marco"], "venue": "In IEEE International Workshop on 3-D Digital Imaging and Modeling", "citeRegEx": "Skibbe et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Skibbe et al\\.", "year": 2009}, {"title": "Steps Toward a Theory of Visual Information: Active Perception, Signal-to-Symbol Conversion and the Interplay Between Sensing and Control", "author": ["Soatto", "Stefano"], "venue": "CoRR, abs/1110.2,", "citeRegEx": "Soatto and Stefano.,? \\Q2012\\E", "shortCiteRegEx": "Soatto and Stefano.", "year": 2012}, {"title": "An unsupervised algorithm for learning lie group transformations", "author": ["J. Sohl-Dickstein", "J.C. Wang", "B.A. Olshausen"], "venue": "arXiv preprint,", "citeRegEx": "Sohl.Dickstein et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Sohl.Dickstein et al\\.", "year": 2010}, {"title": "Unitary Representations and Harmonic Analysis", "author": ["Sugiura", "Mitsuo"], "venue": null, "citeRegEx": "Sugiura and Mitsuo.,? \\Q1990\\E", "shortCiteRegEx": "Sugiura and Mitsuo.", "year": 1990}, {"title": "Lie Group Transformation Models for Predictive Video Coding", "author": ["CM Wang", "J Shol-Dickstein", "Tosic", "Ivana", "Olshausen", "Bruno A"], "venue": "Data Compression Conference,", "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Group Theory and Its Application to the Quantum Mechanics of Atomic Spectra, 1959", "author": ["E.P. Wigner"], "venue": "ISSN 00029505", "citeRegEx": "Wigner,? \\Q1959\\E", "shortCiteRegEx": "Wigner", "year": 1959}], "referenceMentions": [{"referenceID": 9, "context": "A better approach is to directly impose good transformation properties on a representation space, and then learn the mapping between data and representation space such that these transformation properties are realized (Hinton et al., 2011).", "startOffset": 218, "endOffset": 239}, {"referenceID": 0, "context": "Anselmi et al. (2014)), and invariance to groups such as translations, rotations and projective transformations is indeed very important for object recognition.", "startOffset": 0, "endOffset": 22}, {"referenceID": 21, "context": "Unlike previous work on learning group representations (Rao & Ruderman, 1999; Miao & Rao, 2007; Sohl-Dickstein et al., 2010; Wang et al., 2011; Bruna et al., 2013; Cohen & Welling, 2014), our model does not assume a linear action of the group in the input space, but instead acts linearly on a latent representation of the 3D scene.", "startOffset": 55, "endOffset": 186}, {"referenceID": 23, "context": "Unlike previous work on learning group representations (Rao & Ruderman, 1999; Miao & Rao, 2007; Sohl-Dickstein et al., 2010; Wang et al., 2011; Bruna et al., 2013; Cohen & Welling, 2014), our model does not assume a linear action of the group in the input space, but instead acts linearly on a latent representation of the 3D scene.", "startOffset": 55, "endOffset": 186}, {"referenceID": 3, "context": "Unlike previous work on learning group representations (Rao & Ruderman, 1999; Miao & Rao, 2007; Sohl-Dickstein et al., 2010; Wang et al., 2011; Bruna et al., 2013; Cohen & Welling, 2014), our model does not assume a linear action of the group in the input space, but instead acts linearly on a latent representation of the 3D scene.", "startOffset": 55, "endOffset": 186}, {"referenceID": 10, "context": "The requirement that (T, V ) forms a representation of SE(3) is a sufficient condition for the vectors in V to describe \u201ca thing in space\u201d, because it requires them to transform as space does (Kanatani, 1990).", "startOffset": 192, "endOffset": 208}, {"referenceID": 1, "context": "Irreducibility can also be used to define precisely what a \u201cdisentangled\u201d representation is (Cohen & Welling (2014); see also Bengio et al. (2013)), and as shown in the next section, such a representation will have a simple dependency structure when certain conditions are met.", "startOffset": 126, "endOffset": 147}, {"referenceID": 1, "context": "Irreducibility can also be used to define precisely what a \u201cdisentangled\u201d representation is (Cohen & Welling (2014); see also Bengio et al. (2013)), and as shown in the next section, such a representation will have a simple dependency structure when certain conditions are met. Finally, it is easier to compute a set of generators for the ring of polynomial invariants in an irreducible representation, which can be used to build invariant representations. Kazhdan et al. (2003) use a subset of generators (the power spectrum) to build invariant (but lossy) shape descriptors.", "startOffset": 126, "endOffset": 479}, {"referenceID": 3, "context": "In this case, the linear transformation F that achieves the reduction into irreducible representations is the standard Fourier transform, and indeed it will decorrelate the data (Bruna et al., 2013).", "startOffset": 178, "endOffset": 198}, {"referenceID": 3, "context": "In this case, the linear transformation F that achieves the reduction into irreducible representations is the standard Fourier transform, and indeed it will decorrelate the data (Bruna et al., 2013). To see this, let x\u0302 = Fx, and observe that x\u0302 = FT (\u03b8)\u03c4 = FT (\u03b8)F\u22121\u03c4\u0302 \u2261 T\u0302 (\u03b8)\u03c4\u0302 . (3) Thus T\u0302 = FT (\u03b8)F\u22121 is the representation of the rotation group in the spectral domain. We know from linear algebra that a set of commuting diagonalizable matrices can be simultaneously diagonalized (see Memisevic (2012) and Henriques et al.", "startOffset": 179, "endOffset": 508}, {"referenceID": 3, "context": "In this case, the linear transformation F that achieves the reduction into irreducible representations is the standard Fourier transform, and indeed it will decorrelate the data (Bruna et al., 2013). To see this, let x\u0302 = Fx, and observe that x\u0302 = FT (\u03b8)\u03c4 = FT (\u03b8)F\u22121\u03c4\u0302 \u2261 T\u0302 (\u03b8)\u03c4\u0302 . (3) Thus T\u0302 = FT (\u03b8)F\u22121 is the representation of the rotation group in the spectral domain. We know from linear algebra that a set of commuting diagonalizable matrices can be simultaneously diagonalized (see Memisevic (2012) and Henriques et al. (2014) for a discussion).", "startOffset": 179, "endOffset": 536}, {"referenceID": 16, "context": "3 IRREDUCIBILITY AND CONDITIONAL INDEPENDENCE The concept of an irreducible representation can also shed light on time-series models based on transformations (Cohen & Welling, 2014; Michalski et al., 2014).", "startOffset": 158, "endOffset": 205}, {"referenceID": 3, "context": "A better approach to the problem of partial observability is to model all variability that is not caused by the linear action of a low-dimensional Lie group as being caused by the action of the infinite-dimensional group of diffeomorphisms (Bruna et al., 2013; Soatto, 2012).", "startOffset": 240, "endOffset": 274}, {"referenceID": 3, "context": "A better approach to the problem of partial observability is to model all variability that is not caused by the linear action of a low-dimensional Lie group as being caused by the action of the infinite-dimensional group of diffeomorphisms (Bruna et al., 2013; Soatto, 2012). The scattering representations of Bruna & Mallat (2013) achieve simultaneous insensitivity to translations and diffeomorphisms, and this method achieves very good performance on texture recognition and 2D pattern recognition (e.", "startOffset": 241, "endOffset": 332}, {"referenceID": 10, "context": "By requiring that the latent scene transforms as a representation of a symmetry group, we bias the model towards representing latent properties of the scene as opposed to properties of the image (Kanatani, 1990; Soatto, 2012).", "startOffset": 195, "endOffset": 225}, {"referenceID": 2, "context": "The gradients of which are easily computed using backpropagation (in our own implementation, we compute gradients automatically using Theano (Bergstra et al., 2010)).", "startOffset": 141, "endOffset": 164}, {"referenceID": 19, "context": "Such a function can be decomposed by using multiple copies of each irreducible representation, as was done in Skibbe et al. (2009) in the context of rotation invariant shape descriptors.", "startOffset": 110, "endOffset": 131}, {"referenceID": 24, "context": "The matrix elements T\u0302 l mn of the irreducible representations of SO(3) are known as the Wigner D-functions. The formulae given for these matrix elements by Wigner (1959) involve numerically unstable sums of many elements with large coefficients.", "startOffset": 89, "endOffset": 171}, {"referenceID": 6, "context": "We use adagrad for all optimization (Duchi et al., 2011).", "startOffset": 36, "endOffset": 56}, {"referenceID": 14, "context": "For the case of translational motion of an edge-like structure, this is known as the aperture problem (Memisevic, 2012).", "startOffset": 102, "endOffset": 119}, {"referenceID": 9, "context": "Our work is related to the idea of transforming auto-encoders or \u201ccapsules\u201d by Hinton et al. (2011). A transforming auto-encoder consists of many capsules, each of which learns to recognize a visual entity and predict its pose.", "startOffset": 79, "endOffset": 100}, {"referenceID": 9, "context": "Our work is related to the idea of transforming auto-encoders or \u201ccapsules\u201d by Hinton et al. (2011). A transforming auto-encoder consists of many capsules, each of which learns to recognize a visual entity and predict its pose. The pose variables g are thus explicitly represented in the model, and act linearly on other pose variables, as is the case in our model. Unlike our model, a transforming autoencoder represents the scene content as a set of probabilities, each of which indicates the likelihood of the preferred visual entity being present. The binary recognition unit used by a capsule for object z corresponds to an orbit O(z) = {T\u0302 (g)z | g \u2208 G} in our model. Having a single latent space shared by multiple visual entities may aid in generalization, and makes it possible to compute metric relations between different objects. Our approach should also deal better with (approximately) symmetric objects, for which it is not possible to unambiguously estimate pose and motion (what is the pose of a circle?). For the case of translational motion of an edge-like structure, this is known as the aperture problem (Memisevic, 2012). Instead of trying to estimate the motion anyway, our model would represent the edge as a vector whose orbit has reduced dimensionality compared to non-symmetric objects. That said, the fully connected generative network and hard-EM algorithm used in our current model are not suitable for dealing with large images, and so we consider the current model as only a proof of concept. A more scalable linear representation learning system could be based on a group-invariant convolutional network (e.g. Gens & Domingos (2014); Mallat (2012)) that generates a distributed representation that at each point locally describes the scene content, while transforming in a (locally) covariant manner.", "startOffset": 79, "endOffset": 1666}, {"referenceID": 9, "context": "Our work is related to the idea of transforming auto-encoders or \u201ccapsules\u201d by Hinton et al. (2011). A transforming auto-encoder consists of many capsules, each of which learns to recognize a visual entity and predict its pose. The pose variables g are thus explicitly represented in the model, and act linearly on other pose variables, as is the case in our model. Unlike our model, a transforming autoencoder represents the scene content as a set of probabilities, each of which indicates the likelihood of the preferred visual entity being present. The binary recognition unit used by a capsule for object z corresponds to an orbit O(z) = {T\u0302 (g)z | g \u2208 G} in our model. Having a single latent space shared by multiple visual entities may aid in generalization, and makes it possible to compute metric relations between different objects. Our approach should also deal better with (approximately) symmetric objects, for which it is not possible to unambiguously estimate pose and motion (what is the pose of a circle?). For the case of translational motion of an edge-like structure, this is known as the aperture problem (Memisevic, 2012). Instead of trying to estimate the motion anyway, our model would represent the edge as a vector whose orbit has reduced dimensionality compared to non-symmetric objects. That said, the fully connected generative network and hard-EM algorithm used in our current model are not suitable for dealing with large images, and so we consider the current model as only a proof of concept. A more scalable linear representation learning system could be based on a group-invariant convolutional network (e.g. Gens & Domingos (2014); Mallat (2012)) that generates a distributed representation that at each point locally describes the scene content, while transforming in a (locally) covariant manner.", "startOffset": 79, "endOffset": 1681}], "year": 2015, "abstractText": "When a three-dimensional object moves relative to an observer, a change occurs on the observer\u2019s image plane and in the visual representation computed by a learned model. Starting with the idea that a good visual representation is one that transforms linearly under scene motions, we show, using the theory of group representations, that any such representation is equivalent to a combination of the elementary irreducible representations. We derive a striking relationship between irreducibility and the statistical dependency structure of the representation, by showing that under restricted conditions, irreducible representations are decorrelated. Under partial observability, as induced by the perspective projection of a scene onto the image plane, the motion group does not have a linear action on the space of images, so that it becomes necessary to perform inference over a latent representation that does transform linearly. This idea is demonstrated in a model of rotating NORB objects that employs a latent representation of the noncommutative 3D rotation group SO(3).", "creator": "LaTeX with hyperref package"}}}