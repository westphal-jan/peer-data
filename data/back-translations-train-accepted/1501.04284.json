{"id": "1501.04284", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-Jan-2015", "title": "Pairwise Constraint Propagation on Multi-View Data", "abstract": "This paper presents a graph-based learning approach to pairwise constraint propagation on multi-view data. Although pairwise constraint propagation has been studied extensively, pairwise constraints are usually defined over pairs of data points from a single view, i.e., only intra-view constraint propagation is considered for multi-view tasks. In fact, very little attention has been paid to inter-view constraint propagation, which is more challenging since pairwise constraints are now defined over pairs of data points from different views. In this paper, we propose to decompose the challenging inter-view constraint propagation problem into semi-supervised learning subproblems so that they can be efficiently solved based on graph-based label propagation. To the best of our knowledge, this is the first attempt to give an efficient solution to inter-view constraint propagation from a semi-supervised learning viewpoint. Moreover, since graph-based label propagation has been adopted for basic optimization, we develop two constrained graph construction methods for interview constraint propagation, which only differ in how the intra-view pairwise constraints are exploited. The experimental results in cross-view retrieval have shown the promising performance of our inter-view constraint propagation.", "histories": [["v1", "Sun, 18 Jan 2015 11:52:21 GMT  (834kb)", "http://arxiv.org/abs/1501.04284v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["zhiwu lu", "liwei wang"], "accepted": true, "id": "1501.04284"}, "pdf": {"name": "1501.04284.pdf", "metadata": {"source": "CRF", "title": "Pairwise Constraint Propagation on Multi-View Data", "authors": ["Zhiwu Lu", "Liwei Wang"], "emails": ["zhiwu.lu@gmail.com).", "wanglw@cis.pku.edu.cn)."], "sections": [{"heading": null, "text": "This year, we have reached the point where we feel we are able to live in a country where most people are able to live in a country where they are able, where they are able to move, and where they are able to move."}, {"heading": "A. Problem Formulation", "text": "In view of the fact that the similarity of two data points from different perspectives cannot easily be divided into a series of two-faced partial problems, we focus on interview-related dispersion limitations to two-faced dispersion possibilities to two-faced dispersion possibilities to two-faced dispersion possibilities. Let {X, Y} be a two-view dataset, where X = {x1, xN} and Y = {y1, yM}. It should be noted that we are shown N 6 = M. as an example of a two-faced dataset."}, {"heading": "B. Efficient Algorithm", "text": "Leave Q (FX, FY) the objective function in the equation (2). The alternative optimization technology can be used to solve minFX, FY Q (FX, FY) as follows: 1) Fix FY = F * Y, and find F * X = argminFX Q (FX, F * Y) (2) Fix FX = F * X, and find F * Y * Q (F * X, FY). Pairwise Constraint Propagation over X: When FY is fixed at F * Y, the solution of minFX Q (FX, F * Y) can be found by solving the following linear equation Q (FX * F * X * X * Y * Y, F * Y * Z *) 2 x \u00b2 propagation over X: When FY * Y * Y * (F * Y) is the solution of minFX * Y *, the solution of minFX, F * Y * Y * can be found."}, {"heading": "III. CONSTRAINED GRAPH CONSTRUCTION", "text": "In the last section, we have just developed an efficient interview restriction propagation algorithm based on the graphical propagation technology. However, since the graphical propagation of diagrams has been adopted as the basic optimization technology, there remains a problem with the propagation of interview constraints, i.e. how the paired constraints on graph construction can be exploited within each view. In this section, we will then develop two methods of restricted graph construction for interview constraints that differ only in the way that the pictorial constraints within the view are exploited. To ensure that our interview restriction propagation algorithm is efficient even on large data sets, we will use the traditional k-NN graph construction as the basis of our limited graph construction, i.e. the obtained two constrained graphs can be considered variants of the k-NN graph. In the following, we will only execute {X-X = X graph."}, {"heading": "A. Constrained Weight Adjustment", "text": "The first limited graphics method also limits our interview constraint from a semi-controlled propagation, which we have proposed in Section II. (i.e. Intra-view constraint propagation over X) (i.e. Intra-view constraint propagation: We have just provided a sound solution to the challenge problem of intraview constraint propagation in Section II-B. In this subsection we continue to consider pairwise constraint propagation over a single view, where each pairwise constraint is defined over a pair of data points from the same view from the same view propagation."}, {"heading": "B. Constrained Sparse Representation", "text": "The Second Restricted Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Graph-Gr"}, {"heading": "IV. APPLICATION TO CROSS-VIEW RETRIEVAL", "text": "The fact is that most of us will be able to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to another world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to move to a new world, to a new world to move to a new world, to a new world to move to a new world, to a new world to move to a new world, to a new world to a new world to move to a new world."}, {"heading": "V. EXPERIMENTAL RESULTS", "text": "In this section, our interview constraint propagation (InterCP) algorithm is evaluated in the demanding application of cross-view retrieval. We focus on comparing our inter-CP algorithm with the state-of-the-art approach [15], since both take into account not only correlation analysis (CA), but also semantic abstraction (SA) for text and image views. In addition, we also compare two other closely related approaches that integrate CA + SA for cross-view retrieval similar to [15], but also perform correlation analysis using partial least squares (PLS) [41] and cross-modal factor analysis (CFA) [42] instead of CCA. In the following, these two CA + SA approaches are referred to as CA + SA (PLS) and CA + SA (CFA), while the state-of-the-the-art approach [15] is referred to as CA + SA (CCA) in order to demonstrate the effectiveness of CFA (CFA-K) graphs (using CFA-CA) and CFA-CA-1) graphs."}, {"heading": "A. Experimental Setup", "text": "The first is a Wikipedia benchmark dataset = Inter CSR = 15, which contains a total of 2,866 documents derived from Wikipedia's \"featured articles.\" Each document is in fact a text-image pair commented on with a label from the vocabulary of 10 semantic classes. This benchmark dataset [15] is divided into a set of 2,173 documents and a test set of 693 documents. In addition, the second dataset consists of a total of 8,564 documents cracked from the vocabulary of the photo-sharing website Flickr. Image and text views of each document denote a photo and a set of tags provided by users, respectively. Although such a text presentation does not take a free form, as those for Wikipedia records, it is quite noisy, as many of the tags are incorrectly commented by users. These patch datasets are organized by users in the 11 classes."}, {"heading": "B. Retrieval Results", "text": "The results of the interfractional query of the two sets of data are listed in Tables I and II. The immediate observation is that we can achieve the best results when InterCP + CWA (or Inter-CP + CSR) makes the most effective use of both intra- and inter-view constraints, which means that our Inter-CP with CGC can make the most of the initial supervisory information provided for the interfractional query. Furthermore, the effectiveness of our CGC is enhanced by comparing Inter-CP + CWA vs. InterCP + k-NN (or Inter-CP + CSR + SR) by comparing Inter-CP + CP + CP + CWA + CP-NN (or Inter-CP + CWA + SR) by comparing Inter-CP + CP + CP + CP + CP (or CP-CP) by comparing Inter-CP + CP + CP + CP (or CP + CP)."}, {"heading": "VI. CONCLUSIONS", "text": "In this paper, we have explored the challenging problem of the paired propagation of constraints on multiview data. By splitting the problem of the propagation of constraints between individual views into a series of independent semi-monitored learning sub-problems, we have formulated them uniformly to minimize regulated energy function. More importantly, these semi-monitored learning sub-problems can be efficiently solved by label propagation with k-NN graphs. Subsequently, we develop two methods of restricted graph construction for our constraint between views, and the obtained two graphs can be considered variants of the k-NN graph. Experimental results of query between views have shown that our propagation of constraints between views with restricted graph construction is promising. For future work, our method will be extended to other multi-view tasks."}, {"heading": "ACKNOWLEDGEMENTS", "text": "This work was supported by the National Natural Science Foundation of China under the funding programmes 61202231 and 61222307, the National Key Basic Research Programme (973 Program) of China under the funding programme 2014CB340403, the Beijing Natural Science Foundation of China under the funding programme 4132037, the Basic Research Fund for the Central Universities and the Research Fund of the Renmin University of China under the funding programme 14XNLF04 and a funding programme of Microsoft Research Asia."}], "references": [{"title": "Generalized competitive learning of gaussian mixture models", "author": ["Z. Lu", "H.H.-S. Ip"], "venue": "IEEE Trans. Systems, Man, and Cybernetics, Part B: Cybernetics, vol. 39, no. 4, pp. 901\u2013909, 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "An iterative algorithm for entropy regularized likelihood learning on gaussian mixture with automatic model selection", "author": ["Z. Lu"], "venue": "Neurocomputing, vol. 69, no. 13, pp. 1674\u20131677, 2006.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2006}, {"title": "Image categorization based on a hierarchical spatial markov model", "author": ["L. Wang", "Z. Lu", "H. Ip"], "venue": "CAIP, 2009, pp. 766\u2013773.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2009}, {"title": "From comparing clusterings to combining clusterings", "author": ["Z. Lu", "Y. Peng", "J. Xiao"], "venue": "AAAI, 2008, pp. 665\u2013670.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2008}, {"title": "Constrained spectral clustering through affinity propagation", "author": ["Z. Lu", "M. Carreira-Perpinan"], "venue": "CVPR, 2008, pp. 1\u20138.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2008}, {"title": "Pairwise constraint propagation by semidefinite programming for semi-supervised classification", "author": ["Z. Li", "J. Liu", "X. Tang"], "venue": "ICML, 2008, pp. 576\u2013583.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2008}, {"title": "Segmentation given partial grouping constraints", "author": ["S. Yu", "J. Shi"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 26, no. 2, pp. 173\u2013183, 2004.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2004}, {"title": "Spectral learning", "author": ["S. Kamvar", "D. Klein", "C. Manning"], "venue": "IJCAI, 2003, pp. 561\u2013566.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2003}, {"title": "Learning with local and global consistency", "author": ["D. Zhou", "O. Bousquet", "T. Lal", "J. Weston", "B. Sch\u00f6lkopf"], "venue": "Advances in Neural Information Processing Systems 16, 2004, pp. 321\u2013328.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2004}, {"title": "Semi-supervised learning using Gaussian fields and harmonic functions", "author": ["X. Zhu", "Z. Ghahramani", "J. Lafferty"], "venue": "ICML, 2003, pp. 912\u2013919.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2003}, {"title": "Image categorization by learning with context and consistency", "author": ["Z. Lu", "H. Ip"], "venue": "CVPR, 2009, pp. 2719\u20132726.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Noise-robust semi-supervised learning via fast sparse coding", "author": ["Z. Lu", "L. Wang"], "venue": "Pattern Recognition, vol. 48, no. 2, pp. 605\u2013612, 2015.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2015}, {"title": "Combining latent semantic learning and reduced hypergraph learning for semi-supervised image categorization", "author": ["Z. Lu", "Y. Peng"], "venue": "ACM Multimedia, 2011, pp. 1409\u20131412.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2011}, {"title": "Combining context, consistency, and diversity cues for interactive image categorization", "author": ["Z. Lu", "H. Ip"], "venue": "IEEE Trans. Multimedia, vol. 12, no. 3, pp. 194\u2013203, 2010.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2010}, {"title": "A new approach to cross-modal multimedia retrieval", "author": ["N. Rasiwasia", "J. Costa Pereira", "E. Coviello", "G. Doyle", "G. Lanckriet", "R. Levy", "N. Vasconcelos"], "venue": "ACM Multimedia, 2010, pp. 251\u2013260.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-view clustering with constraint propagation for learning with an incomplete mapping between views", "author": ["E. Eaton", "M. desJardins", "S. Jacob"], "venue": "CIKM, 2010, pp. 389\u2013398.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Multi-modal constraint propagation for heterogeneous image clustering", "author": ["Z. Fu", "H. Ip", "H. Lu", "Z. Lu"], "venue": "ACM Multimedia, 2011, pp. 143\u2013 152.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2011}, {"title": "Multimodal semisupervised learning for image classification", "author": ["M. Guillaumin", "J. Verbeek", "C. Schmid"], "venue": "CVPR, 2010, pp. 902\u2013 909.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Design of multimodal dissimilarity spaces for retrieval of video documents", "author": ["E. Bruno", "N. Moenne-Loccoz", "S. Marchand-Maillet"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 30, no. 9, pp. 1520\u20131533, 2008.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "Constrained spectral clustering via exhaustive and efficient constraint propagation", "author": ["Z. Lu", "H. Ip"], "venue": "ECCV, vol. 6, 2010, pp. 1\u201314.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2010}, {"title": "Symmetric graph regularized constraint propagation", "author": ["Z. Fu", "Z. Lu", "H.H.-S. Ip", "Y. Peng", "H. Lu"], "venue": "AAAI, 2011.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Exhaustive and efficient constraint propagation: A graph-based learning approach and its applications", "author": ["Z. Lu", "Y. Peng"], "venue": "International Journal of Computer Vision, vol. 103, no. 3, pp. 306\u2013325, 2013.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "For most large underdetermined systems of linear equations the minimal l-norm solution is also the sparsest solution", "author": ["D. Donoho"], "venue": "Communications on Pure and Applied Mathematics, vol. 59, no. 7, pp. 797\u2013829, 2004.  9", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "Robust face recognition via sparse representation", "author": ["J. Wright", "A. Yang", "A. Ganesh", "S. Sastry", "Y. Ma"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 31, no. 2, pp. 210\u2013227, 2009.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2009}, {"title": "Latent semantic learning by efficient sparse coding with hypergraph regularization.", "author": ["Z. Lu", "Y. Peng"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Sparsity induced similarity measure for label propagation", "author": ["H. Cheng", "Z. Liu", "J. Yang"], "venue": "ICCV, 2009, pp. 317\u2013324.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning with l-graph for image analysis", "author": ["B. Cheng", "J. Yang", "S. Yan", "T. Huang"], "venue": "IEEE Trans. Image Processing, vol. 19, no. 4, pp. 858\u2013866, Apr. 2010.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Image annotation by semantic sparse recoding of visual content", "author": ["Z. Lu", "Y. Peng"], "venue": "ACM Multimedia, 2012, pp. 499\u2013508.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2012}, {"title": "Latent semantic learning with structured sparse representation for human action recognition", "author": ["\u2014\u2014"], "venue": "Pattern Recognition, vol. 46, no. 7, pp. 1799\u20131809, 2013.", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1809}, {"title": "Semantic sparse recoding of visual content for image applications", "author": ["Z. Lu", "P. Han", "L. Wang", "J.-R. Wen"], "venue": "IEEE Trans. Image Processing, vol. 24, no. 1, 2015.", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2015}, {"title": "Regularization on discrete spaces", "author": ["D. Zhou", "B. Scholk\u00f6pf"], "venue": "DAGM, 2005, pp. 361\u2013368.", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2005}, {"title": "Smoothing proximal gradient method for general structured sparse learning", "author": ["X. Chen", "Q. Lin", "S. Kim", "J.G. Carbonell", "E.P. Xing"], "venue": "UAI, 2011, pp. 105\u2013114.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "Automatic linguistic indexing of pictures by a statistical modeling approach", "author": ["J. Li", "J. Wang"], "venue": "IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 25, no. 9, pp. 1075\u20131088, Sept. 2003.", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2003}, {"title": "Multiple Bernoulli relevance models for image and video annotation", "author": ["S. Feng", "R. Manmatha", "V. Lavrenko"], "venue": "CVPR, vol. 2, 2004, pp. 1002\u20131009.", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2004}, {"title": "Contextual kernel and spectral methods for learning the semantics of images", "author": ["Z. Lu", "H. Ip", "Y. Peng"], "venue": "IEEE Trans. Image Processing, vol. 20, no. 6, pp. 1739\u20131750, 2011.", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2011}, {"title": "Spatial markov kernels for image categorization and annotation", "author": ["Z. Lu", "H. Ip"], "venue": "IEEE Trans. Systems, Man, and Cybernetics, Part B: Cybernetics, vol. 41, no. 4, pp. 976\u2013989, 2011.", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2011}, {"title": "Every picture tells a story: Generating sentences from images", "author": ["A. Farhadi", "M. Hejrati", "M. Sadeghi", "P. Young", "C. Rashtchian", "J. Hockenmaier", "D. Forsyth"], "venue": "ECCV, vol. 4, 2010, pp. 15\u201329.", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2010}, {"title": "Baby talk: Understanding and generating simple image descriptions", "author": ["G. Kulkarni", "V. Premraj", "S. Dhar", "S. Li", "Y. Choi", "A. Berg", "T. Berg"], "venue": "CVPR, 2011, pp. 1601\u20131608.", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2011}, {"title": "Im2Text: Describing images using 1 million captioned photographs", "author": ["V. Ordonez", "G. Kulkarni", "T. Berg"], "venue": "Advances in Neural Information Processing Systems 24, 2012, pp. 1143\u20131151.", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2012}, {"title": "Relations between two sets of variates", "author": ["H. Hotelling"], "venue": "Biometrika, vol. 28, no. 3-4, pp. 321\u2013377, 1936.", "citeRegEx": "40", "shortCiteRegEx": null, "year": 1936}, {"title": "Partial least squares", "author": ["H. Wold"], "venue": "Encyclopedia of Statistical Sciences, S. Kotz and N. Johnson, Eds. New York: Wiley, 1985, pp. 581\u2013591.", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1985}, {"title": "Multimedia content processing through cross-modal association", "author": ["D. Li", "N. Dimitrova", "M. Li", "I.K. Sethi"], "venue": "ACM Multimedia, 2003, pp. 604\u2013611.", "citeRegEx": "42", "shortCiteRegEx": null, "year": 2003}], "referenceMentions": [{"referenceID": 0, "context": "To effectively exploit pairwise constraints for clustering or classification [1]\u2013[4], much attention has been paid to pairwise constraint propagation [5]\u2013[7].", "startOffset": 77, "endOffset": 80}, {"referenceID": 3, "context": "To effectively exploit pairwise constraints for clustering or classification [1]\u2013[4], much attention has been paid to pairwise constraint propagation [5]\u2013[7].", "startOffset": 81, "endOffset": 84}, {"referenceID": 4, "context": "To effectively exploit pairwise constraints for clustering or classification [1]\u2013[4], much attention has been paid to pairwise constraint propagation [5]\u2013[7].", "startOffset": 150, "endOffset": 153}, {"referenceID": 6, "context": "To effectively exploit pairwise constraints for clustering or classification [1]\u2013[4], much attention has been paid to pairwise constraint propagation [5]\u2013[7].", "startOffset": 154, "endOffset": 157}, {"referenceID": 7, "context": "Different from the method [8] which only adjusts the similarities between constrained data points, these approaches can propagate pairwise constraints to other similarities between unconstrained data points and thus achieve better results in most cases.", "startOffset": 26, "endOffset": 29}, {"referenceID": 8, "context": "Since we have to learn the relationships (must-link or cannot-link) between data points, intra-view constraint propagation is more challenging than the traditional label propagation [9]\u2013[14] whose goal is only to predict the labels of unlabeled data points.", "startOffset": 182, "endOffset": 185}, {"referenceID": 13, "context": "Since we have to learn the relationships (must-link or cannot-link) between data points, intra-view constraint propagation is more challenging than the traditional label propagation [9]\u2013[14] whose goal is only to predict the labels of unlabeled data points.", "startOffset": 186, "endOffset": 190}, {"referenceID": 14, "context": "However, besides intra-view pairwise constraints, we may also have easy access to inter-view pairwise constraints in multi-view tasks such as cross-view retrieval [15], where each pairwise constraint is defined over a pair of data points", "startOffset": 163, "endOffset": 167}, {"referenceID": 15, "context": "Although pairwise constraint propagation has been successfully applied to multi-view clustering in [16], [17], only intra-view pairwise constraints are propagated across different views.", "startOffset": 99, "endOffset": 103}, {"referenceID": 16, "context": "Although pairwise constraint propagation has been successfully applied to multi-view clustering in [16], [17], only intra-view pairwise constraints are propagated across different views.", "startOffset": 105, "endOffset": 109}, {"referenceID": 8, "context": "Specifically, we first decompose the inter-view constraint propagation problem into a set of independent semi-supervised learning [9]\u2013[12] subproblems.", "startOffset": 130, "endOffset": 133}, {"referenceID": 11, "context": "Specifically, we first decompose the inter-view constraint propagation problem into a set of independent semi-supervised learning [9]\u2013[12] subproblems.", "startOffset": 134, "endOffset": 138}, {"referenceID": 8, "context": "Through formulating these subproblems uniformly as minimizing a regularized energy functional, we thus develop an efficient algorithm for inter-view constraint propagation based on the traditional graph-based label propagation technique [9].", "startOffset": 237, "endOffset": 240}, {"referenceID": 14, "context": "drawn much attention recently [15].", "startOffset": 30, "endOffset": 34}, {"referenceID": 17, "context": "For cross-view retrieval, it is not feasible to combine multiple views just as previous multi-view retrieval methods [18], [19].", "startOffset": 117, "endOffset": 121}, {"referenceID": 18, "context": "For cross-view retrieval, it is not feasible to combine multiple views just as previous multi-view retrieval methods [18], [19].", "startOffset": 123, "endOffset": 127}, {"referenceID": 15, "context": "More notably, the two closely related methods [16], [17] for multi-view clustering are actually incompetent for cross-view retrieval.", "startOffset": 46, "endOffset": 50}, {"referenceID": 16, "context": "More notably, the two closely related methods [16], [17] for multi-view clustering are actually incompetent for cross-view retrieval.", "startOffset": 52, "endOffset": 56}, {"referenceID": 8, "context": "Furthermore, we develop an efficient algorithm for inter-view constraint propagation based on the label propagation technique [9].", "startOffset": 126, "endOffset": 129}, {"referenceID": 8, "context": "Finally, given two graphs GX = {X ,WX } and GY = {Y,WY} constructed over {X ,Y} with WX (or WY ) being the edge weight matrix defined over the vertex set X (or Y), we utilize the graph-based label propagation method [9] to uniformly solve these semi-supervised learning subproblems:", "startOffset": 216, "endOffset": 219}, {"referenceID": 9, "context": "As for the second and fourth terms, they are known as the energy functional [10] (or smoothness) defined over X and Y .", "startOffset": 76, "endOffset": 80}, {"referenceID": 8, "context": "Fortunately, equation (4) can also be efficiently found using label propagation [9] with k-nearest neighbor (k-NN) graph.", "startOffset": 80, "endOffset": 83}, {"referenceID": 8, "context": "In fact, the linear equation (6) can also be efficiently solved using label propagation [9] with k-NN graph.", "startOffset": 88, "endOffset": 91}, {"referenceID": 8, "context": "According to the convergence analysis in [9], Step (3) converges to F \u2217 X = (1\u2212\u03b1)(I \u2212\u03b1XSX ) ((1\u2212 \u03b2)Z + \u03b2F \u2217 Y), equal to the solution (5) given that \u03b1X = \u03bc\u0302X /(1 + \u03bc\u0302X ) and SX = I \u2212 LX .", "startOffset": 41, "endOffset": 44}, {"referenceID": 19, "context": "These subproblems can be similarly merged to a single optimization problem (similar to [20]\u2013[22]):", "startOffset": 87, "endOffset": 91}, {"referenceID": 21, "context": "These subproblems can be similarly merged to a single optimization problem (similar to [20]\u2013[22]):", "startOffset": 92, "endOffset": 96}, {"referenceID": 9, "context": "The second and fourth terms of the above equation denote the energy functional [10] (or the smoothness measure) defined over X .", "startOffset": 79, "endOffset": 83}, {"referenceID": 19, "context": "0 \u2264 w (x) ij \u2264 1) just as [20]:", "startOffset": 26, "endOffset": 30}, {"referenceID": 22, "context": "The second constrained graph construction method formulates graph construction as sparse representation [23]\u2013[25] and then directly add the intra-view pairwise constraints into sparse representation, which is thus called as constrained sparse representation (CSR).", "startOffset": 104, "endOffset": 108}, {"referenceID": 24, "context": "The second constrained graph construction method formulates graph construction as sparse representation [23]\u2013[25] and then directly add the intra-view pairwise constraints into sparse representation, which is thus called as constrained sparse representation (CSR).", "startOffset": 109, "endOffset": 113}, {"referenceID": 25, "context": ", L1-graph construction [26], [27].", "startOffset": 24, "endOffset": 28}, {"referenceID": 26, "context": ", L1-graph construction [26], [27].", "startOffset": 30, "endOffset": 34}, {"referenceID": 22, "context": "According to [23], if the solution for xi is sparse enough, it can be recovered by:", "startOffset": 13, "endOffset": 17}, {"referenceID": 23, "context": "In practice, due to the noise in the data, we can reconstruct x\u0302i similar to [24]: x\u0302i = Ci\u03b1i+ \u03b6i, where \u03b6i is the noise term.", "startOffset": 77, "endOffset": 81}, {"referenceID": 8, "context": "In fact, this supervisory information can be exploited for L1-graph construction through Laplacian regularization [9], [10].", "startOffset": 114, "endOffset": 117}, {"referenceID": 9, "context": "In fact, this supervisory information can be exploited for L1-graph construction through Laplacian regularization [9], [10].", "startOffset": 119, "endOffset": 123}, {"referenceID": 8, "context": "From this normalized Laplacian matrix Li, we can derive the Laplacian regularization term for the sparse representation problem (12) as \u03b1i Li\u03b1i, the same as the original definition in [9].", "startOffset": 184, "endOffset": 187}, {"referenceID": 11, "context": "Hence, we further formulate an L1norm version of Laplacian regularization [12], [28]\u2013[30]:", "startOffset": 74, "endOffset": 78}, {"referenceID": 27, "context": "Hence, we further formulate an L1norm version of Laplacian regularization [12], [28]\u2013[30]:", "startOffset": 80, "endOffset": 84}, {"referenceID": 29, "context": "Hence, we further formulate an L1norm version of Laplacian regularization [12], [28]\u2013[30]:", "startOffset": 85, "endOffset": 89}, {"referenceID": 8, "context": "However, this is not true for the traditional Laplacian regularization [9], [10], which may introduce extra parameters (hard to tune in practice) into the L1-optimization for sparse representation.", "startOffset": 71, "endOffset": 74}, {"referenceID": 9, "context": "However, this is not true for the traditional Laplacian regularization [9], [10], which may introduce extra parameters (hard to tune in practice) into the L1-optimization for sparse representation.", "startOffset": 76, "endOffset": 80}, {"referenceID": 30, "context": "Moreover, the p-Laplacian regularization [31] can also be regarded as an ordinary L1-generalization of the Laplacian regularization when p = 1.", "startOffset": 41, "endOffset": 45}, {"referenceID": 31, "context": "According to [32], by defining a matrix Cp \u2208", "startOffset": 13, "endOffset": 17}, {"referenceID": 14, "context": "In fact, this is just the goal of cross-view retrieval which has drawn much attention recently [15].", "startOffset": 95, "endOffset": 99}, {"referenceID": 32, "context": "In this case, cross-view retrieval is somewhat similar to automatic image annotation [33]\u2013[36] and image caption generation Three Puerto Ricans were awarded", "startOffset": 85, "endOffset": 89}, {"referenceID": 35, "context": "In this case, cross-view retrieval is somewhat similar to automatic image annotation [33]\u2013[36] and image caption generation Three Puerto Ricans were awarded", "startOffset": 90, "endOffset": 94}, {"referenceID": 14, "context": "Cross-view retrieval examples on the Wikipedia benchmark dataset [15].", "startOffset": 65, "endOffset": 69}, {"referenceID": 36, "context": "[37]\u2013[39], since these three tasks all aim to learn the relations between the text and image views.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "[37]\u2013[39], since these three tasks all aim to learn the relations between the text and image views.", "startOffset": 5, "endOffset": 9}, {"referenceID": 36, "context": "the <object, action, scene> triplets used in [37]), different from", "startOffset": 45, "endOffset": 49}, {"referenceID": 14, "context": "In the context of cross-view retrieval, one notable recent work is [15] which first learns the correlation between the text and image views with canonical correlation analysis (CCA) [40] and then achieves the abstraction by representing text and image at a more general semantic level.", "startOffset": 67, "endOffset": 71}, {"referenceID": 39, "context": "In the context of cross-view retrieval, one notable recent work is [15] which first learns the correlation between the text and image views with canonical correlation analysis (CCA) [40] and then achieves the abstraction by representing text and image at a more general semantic level.", "startOffset": 182, "endOffset": 186}, {"referenceID": 14, "context": "The effectiveness of such integration as compared to CA+SA [15] is preliminarily verified by several cross-view retrieval examples shown in Fig.", "startOffset": 59, "endOffset": 63}, {"referenceID": 14, "context": "We focus on comparing our Inter-CP algorithm with the state-of-the-art approach [15], since they both consider not only correlation analysis (CA) but also semantic abstraction (SA) for text and image views.", "startOffset": 80, "endOffset": 84}, {"referenceID": 14, "context": "Moreover, we also make comparison with another two closely related approaches that integrate CA and SA for cross-view retrieval similar to [15] but perform correlation analysis by partial least squares (PLS) [41] and cross-modal factor analysis (CFA) [42] instead of CCA, respectively.", "startOffset": 139, "endOffset": 143}, {"referenceID": 40, "context": "Moreover, we also make comparison with another two closely related approaches that integrate CA and SA for cross-view retrieval similar to [15] but perform correlation analysis by partial least squares (PLS) [41] and cross-modal factor analysis (CFA) [42] instead of CCA, respectively.", "startOffset": 208, "endOffset": 212}, {"referenceID": 41, "context": "Moreover, we also make comparison with another two closely related approaches that integrate CA and SA for cross-view retrieval similar to [15] but perform correlation analysis by partial least squares (PLS) [41] and cross-modal factor analysis (CFA) [42] instead of CCA, respectively.", "startOffset": 251, "endOffset": 255}, {"referenceID": 14, "context": "In the following, these two CA+SA approaches are denoted as CA+SA (PLS) and CA+SA (CFA), while the state-of-the-art approach [15] is denoted as CA+SA (CCA).", "startOffset": 125, "endOffset": 129}, {"referenceID": 14, "context": "The first one is a Wikipedia benchmark dataset [15], which contains a total of 2,866 documents derived from Wikipedia\u2019s \u201cfeatured articles\u201d.", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "This benchmark dataset [15] is split into a training set of 2,173 documents and a test set of 693 documents.", "startOffset": 23, "endOffset": 27}, {"referenceID": 14, "context": "For the above two datasets, we take the same strategy as [15] to generate both text and image representation.", "startOffset": 57, "endOffset": 61}, {"referenceID": 14, "context": "More concretely, in the Wikipedia dataset, the text representation for each document is derived from a latent Dirichlet allocation model with 10 latent topics, while the image representation is based on a bag-of-words model with 128 visual words learnt from the extracted SIFT descriptors, just as [15].", "startOffset": 298, "endOffset": 302}, {"referenceID": 17, "context": "For each task, the retrieval results are measured with mean average precision (MAP) which has been widely used in the image retrieval literature [18].", "startOffset": 145, "endOffset": 149}], "year": 2015, "abstractText": "This paper presents a graph-based learning approach to pairwise constraint propagation on multi-view data. Although pairwise constraint propagation has been studied extensively, pairwise constraints are usually defined over pairs of data points from a single view, i.e., only intra-view constraint propagation is considered for multi-view tasks. In fact, very little attention has been paid to inter-view constraint propagation, which is more challenging since pairwise constraints are now defined over pairs of data points from different views. In this paper, we propose to decompose the challenging inter-view constraint propagation problem into semi-supervised learning subproblems so that they can be efficiently solved based on graph-based label propagation. To the best of our knowledge, this is the first attempt to give an efficient solution to inter-view constraint propagation from a semi-supervised learning viewpoint. Moreover, since graph-based label propagation has been adopted for basic optimization, we develop two constrained graph construction methods for interview constraint propagation, which only differ in how the intraview pairwise constraints are exploited. The experimental results in cross-view retrieval have shown the promising performance of our inter-view constraint propagation.", "creator": "LaTeX with hyperref package"}}}