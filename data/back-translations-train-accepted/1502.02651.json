{"id": "1502.02651", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2015", "title": "Optimal and Adaptive Algorithms for Online Boosting", "abstract": "We study online boosting, the task of converting any weak online learner into a strong online learner. Based on a novel and natural definition of weak online learnability, we develop two online boosting algorithms. The first algorithm is an online version of boost-by-majority. By proving a matching lower bound, we show that this algorithm is essentially optimal in terms of the number of weak learners and the sample complexity needed to achieve a specified accuracy. This optimal algorithm is not adaptive however. Using tools from online loss minimization, we derive an adaptive online boosting algorithm that is also parameter-free, but not optimal. Both algorithms work with base learners that can handle example importance weights directly, as well as by rejection sampling examples with probability defined by the booster. Results are complemented with an extensive experimental study.", "histories": [["v1", "Mon, 9 Feb 2015 20:58:38 GMT  (19kb)", "http://arxiv.org/abs/1502.02651v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alina beygelzimer", "satyen kale", "haipeng luo"], "accepted": true, "id": "1502.02651"}, "pdf": {"name": "1502.02651.pdf", "metadata": {"source": "CRF", "title": "Optimal and Adaptive Algorithms for Online Boosting", "authors": ["Alina Beygelzimer"], "emails": ["beygel@yahoo-inc.com", "satyen@yahoo-inc.com", "haipengl@cs.princeton.edu"], "sections": [{"heading": null, "text": "ar Xiv: 150 2.02 651v 1 [cs.L G] 9F eb"}, {"heading": "1 Introduction", "text": "s book [2012] for a thorough discussion. They are often much faster, more memory-effective, and apply to situations where the best predictor changes over time are considered new examples. In contrast to the set list, where online learning algorithms typically do not make stochastic assumptions about the data they observe, they are often much faster, more efficient in memory, and apply to situations where the best settings over time are considered new examples. Given the success of the increase in the set list of learning, it is natural to apply the possibility of increasing online learning. In fact, there has already been some work in online boosting [Oza and Russell, 2001, Grabner and Bischof, 2006, Liu, Chen et al.]"}, {"heading": "2 Setup and Assumptions", "text": "We describe the formal structure of the task of online grading by enhancement. (...) We describe the formal structure of the task of online grading by enhancement. (...) We describe the formal prerequisites of online grading by enhancement. (...) We describe the formal prerequisites of online grading by enhancement. (...) Students make a prediction about their label. (...) Students make a prediction about their label. (...) Students have a prediction about their label. (...) Students have a prediction about their label. (...) Students have a prediction about their label. (...) Students have a prediction about their label. (...) Students will have a prediction about their label. (...) Students will have a prediction about their label. (...)"}, {"heading": "2.1 Handling Importance Weights", "text": "Typical online learning algorithms can handle weighted examples: Each example (xt, yt) comes with a weight pt (0, 1), and the loss in this example is scaled by pt, i.e. the loss for predicting y-t is pt1 {y-t = yt}. Consider the following natural extension of the definition of online weak learners, which contains weighted examples: We now require that for each sequence of weighted examples (xt, yt) weighing pt [0, 1] for t = 1, 2,..., T generating online learners predictions y-t that are likely to be at least 1 \u2212 \u043c, T-t = 1pt1 {y-t) weighing pt (0, 1] for t = 1, 2,. (2) Access to such weak learners will make predictions y-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-t-weight pt (0, 1) with weight pt (0, 1] for t = 1, 2,. (2) Access to such weak learners will simply pass the predictions y-t (2) to each weak learning algorithm."}, {"heading": "2.2 Discussion of Weak Online Learning Assumption", "text": "We now justify our definition of weak online learning, vice. Inequality (1). In the standard batch-raising case (1), the corresponding weak learning assumption (see e.g. Schapire and Friend [2012]) is such that there is an algorithm that, given an abundance of examples and an arbitrary distribution, generates a hypothesis that exhibits an error of no more than 12 \u2212 \u03b3 on the training data under the given distribution. This statement can be interpreted to mean that the following two implicit assumptions are made: 1. (Correctness.) In the face of an edge parameter (0, 12), there are a number of hypotheses, H, so that any amount of learning (possibly, a multiset) of examples U, there are some hypotheses that H rules with errors on most 12 \u2212 i.e. we can (x, y) have an optimal learning set of 6 (x)."}, {"heading": "3 An Optimal Algorithm", "text": "In this section, we generalize a family of potential batch boosting algorithms to the online setting. With specific potential, an online version of Boost-by-Majority is being developed that has an optimal number of weak learners and near-optimal sample complexity. Matching lower limits are shown at the end of the section."}, {"heading": "3.1 A Potential Based Family and Boost-By-Majority", "text": "Here we generalize the analysis and propose a potential-based family of online enhancement algorithms. \u2212 So, let's see a sequence of N + 1 non-increasing potential functions. \u2212 Let's see a sequence of N + 1 non-increasing potential functions. (4) Then the algorithm is easy to set: It is 1 and w i = 1 2 (s) 2 (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n (s) n) n (s) n (s) n (s) n) n (s) n (s) n) n (s) n (s) n) n (s) n) n (s) n) n (s) n) n (s) n) n (s) n (s) n) n (s) n (s) n (s) n) n (s) n) n (s (s) n (s) n (s) n (s (s) n) n (s) n (s (s) n (s) n (s) n (s (s) n (s (s) n) n (s (s) n (s (s) n) n (s (s (s) n) n (s (s) n) n (s (s (s) n) n (s (s (s) n (s (s) n) n) n (s (s (s (s) n) n)."}, {"heading": "3.2 Matching Lower Bounds", "text": "We give lower limits on the number of weak learners and the sample complexity in this section, which show that our online BBM algorithm is up to logarithmic factors.Theorem 3: For all weak learning process (0, 14), S \u2265 ln (1), inequality (0, 1) and insufficient learning ability (0, 1), there is a weak online learning algorithm with edge and excess loss S (1) with a probability of at least 1 \u2212 6, so that a failure rate is achieved, an online boosting algorithm must be at least 2 (0, 1), weak learning ability and insufficient complexity of learning processes (S) = 1), with a probability of at least 1 \u2212 6, so that a failure rate of at least 1 \u2212 6, a weak algorithm must be at least 2 (1, 1), weak learning ability and insufficient complexity of learning processes of weak nature (S)."}, {"heading": "4 An Adaptive Algorithm", "text": "Although the online BBM algorithm is optimal, it is unfortunately not adaptive as it requires knowledge of \u03b3 as a parameter unknown before time. As discussed in the introduction, adaptivity is essential for the practical performance of boosting algorithms such as AdaBoost.In this section, therefore, we will examine adaptive online boosting algorithms that use the theory of online loss minimization as the most important tool. It is known that boosting can be seen as an attempt to find a linear combination of weak hypotheses to minimize the overall loss of training examples, usually using functional gradient descendence [see for details Schapire and Freund, 2012, Chap. 7]. AdaBoost, for example, minimizes exponential loss. As already discussed, we intuitively want to avoid that it leads to exponential losses as it could lead to large weights. Instead, we look at logistical losses (s) = ln ()."}, {"heading": "5 Experiments", "text": "While the focus of this work is on a theoretical investigation of online enhancement, we have also conducted experiments to evaluate our algorithms. We expanded the Vowpal Wabbit VW open source learning system to include the algorithms studied in this thesis. We used VW's standard basic learning algorithm as our weak learner and optimized only the learning rate. The boosting algorithms implemented online were Online BBM, AdaBoost.OL, OSBoost (using a uniform weighting of weak learners) and OSBoost.OCP from [Chen et al., 2012], with all major weighted examples used in VW. We also implemented AdaBoost.OL.S, which is the version of AdaBoost.OL, in which examples sampled at VW are weighted instead of.All experiments were conducted on a diversified collection of 13 publicly available data sets."}, {"heading": "A Proof of Lemma 1", "text": "The proof. Fix a weak learner, say WLi. LetU = [t]: (xt, yt) is weak (wi). Since inequality (1) applies even to adaptive opponents, with a high probability, we have [t] = 11 {WLi (xt) 6 = yt] 1 {t \u00b2 inequality (12 \u2212 \u03b3) | U | + S. (16) Now we fix the internal randomness of WLi. Note: Et [t] {t \u00b2 U} = Pit = wi t qualities, where Et [\u00b7] the expectation is tied to the randomness of the booster (and not the) round t. Define \u03c3 = 1 p i. We now show with a high probability that T qualities associated with a high probability, T-II = 11 {WLi (xt) 6 = yt} pit."}, {"heading": "B Proof of Lemma 4", "text": "Let us prove that X \u00b2 B (m, p) is a binomial random variable, with m = N \u2212 i and p = 1 / 2 + \u03b3 / 2. Let us also leave q = 1 \u2212 p and FX the CDF of X. After defining the word, we have a mind \u2264 12 maxk Pr {X = k}. Let us approach X by a Gaussian random variable G \u00b2 N (mp, mpq) with density function f and CDF FG. Note that | Pr {X = k} \u2212 1 f (G) \u2212 1 f (G) dG | = (FX (k) \u2212 1) \u2212 FX (k \u2212 1) \u2212 (FG (k \u2212 1)) \u2212 (Esseen theorem) \u2212 (k \u2212 FG (k \u2212 1))) | \u2264 | FX (k) \u2212 FG (k) \u2212 FG (k) \u2212 FG (k) \u2212 1) | + | FX (k \u2212 qk \u2212 f (1) \u2212 G \u2212 1 \u2212 (G) \u2212 1 \u2212 (G)."}], "references": [{"title": "The uniform hardcore lemma via approximate bregman projections", "author": ["Boaz Barak", "Moritz Hardt", "Satyen Kale"], "venue": "In The twentieth Annual ACM-SIAM Symposium on Discrete Algorithms,", "citeRegEx": "Barak et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Barak et al\\.", "year": 2009}, {"title": "High-probability regret bounds for bandit online linear optimization", "author": ["Peter L. Bartlett", "Varsha Dani", "Thomas Hayes", "Sham Kakade", "Alexander Rakhlin", "Ambuj Tewari"], "venue": "In Proceedings of the 21st Annual Conference on Learning Theory (COLT", "citeRegEx": "Bartlett et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2008}, {"title": "Agnostic Online Learning", "author": ["Shai Ben-David", "D\u00e1vid P\u00e1l", "Shai Shalev-Shwartz"], "venue": "COLT", "citeRegEx": "Ben.David et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2009}, {"title": "FilterBoost: Regression and classification on large datasets", "author": ["Joseph K. Bradley", "Robert E. Schapire"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Bradley and Schapire.,? \\Q2008\\E", "shortCiteRegEx": "Bradley and Schapire.", "year": 2008}, {"title": "On boosting with polynomially bounded distributions", "author": ["Nader H Bshouty", "Dmitry Gavinsky"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Bshouty and Gavinsky.,? \\Q2003\\E", "shortCiteRegEx": "Bshouty and Gavinsky.", "year": 2003}, {"title": "Prediction, Learning, and Games", "author": ["Nicol\u00f2 Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "An Online Boosting Algorithm with Theoretical Justifications", "author": ["Shang-Tse Chen", "Hsuan-Tien Lin", "Chi-Jen Lu"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2012}, {"title": "Boosting with Online Binary Learners for the Multiclass Bandit Problem", "author": ["Shang-Tse Chen", "Hsuan-Tien Lin", "Chi-Jen Lu"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Data Filtering and Distribution Modeling Algorithms for Machine Learning", "author": ["Yoav Freund"], "venue": null, "citeRegEx": "Freund.,? \\Q1992\\E", "shortCiteRegEx": "Freund.", "year": 1992}, {"title": "Boosting: Foundations and Algorithms", "author": ["Robert E. Schapire", "Yoav Freund"], "venue": "Artificial Intelligence and Statistics,", "citeRegEx": "Schapire and Freund.,? \\Q2001\\E", "shortCiteRegEx": "Schapire and Freund.", "year": 2001}, {"title": "2008], for any \u03b4 < 1/e and assuming T \u2265 4, with probability", "author": ["Bartlett"], "venue": null, "citeRegEx": "Bartlett,? \\Q2008\\E", "shortCiteRegEx": "Bartlett", "year": 2008}], "referenceMentions": [{"referenceID": 6, "context": "See the book by Schapire and Freund [2012] for a thorough discussion.", "startOffset": 29, "endOffset": 43}, {"referenceID": 6, "context": ", 2008, Chen et al., 2012, 2014]. From a theoretical viewpoint, recent work by Chen et al. [2012] is perhaps most interesting.", "startOffset": 8, "endOffset": 98}, {"referenceID": 6, "context": "Table 1: Comparisons of our results with those of Chen et al. [2012], assuming, as in their paper, that the weak learner is derived from an online learning algorithm with an O( \u221a T ) regret bound.", "startOffset": 50, "endOffset": 69}, {"referenceID": 6, "context": "OSBoost [Chen et al., 2012] O( 1 \u01eb\u03b3 ) \u00d5( 1 \u01eb\u03b3 ) \u00d7 \u00d7", "startOffset": 8, "endOffset": 27}, {"referenceID": 5, "context": "This algorithm, called Online BBM, improves upon the work of Chen et al. [2012] in several different aspects: 1.", "startOffset": 61, "endOffset": 80}, {"referenceID": 3, "context": "our algorithm doesn\u2019t require weighted online learning, instead using a sampling technique similar to the one used in boosting by filtering in the batch setting [see for example, Freund, 1992, Bradley and Schapire, 2008], and 3. our algorithm is optimal in the sense that no online boosting algorithm can achieve the same error rate with less weak learners or less examples asymptotically (see the lower bounds in Section 3.2). A quantitative comparison of our results with those of Chen et al. [2012] appears in Table 1, where N and T represent the number1 of weak learners and examples needed to achieve error rate \u01eb, and \u03b3 stands for a similar concept of the \u201cedge\u201d of the weak learning oracle as in the batch setting (smaller \u03b3 means more inaccurate weak learners).", "startOffset": 193, "endOffset": 502}, {"referenceID": 3, "context": "our algorithm doesn\u2019t require weighted online learning, instead using a sampling technique similar to the one used in boosting by filtering in the batch setting [see for example, Freund, 1992, Bradley and Schapire, 2008], and 3. our algorithm is optimal in the sense that no online boosting algorithm can achieve the same error rate with less weak learners or less examples asymptotically (see the lower bounds in Section 3.2). A quantitative comparison of our results with those of Chen et al. [2012] appears in Table 1, where N and T represent the number1 of weak learners and examples needed to achieve error rate \u01eb, and \u03b3 stands for a similar concept of the \u201cedge\u201d of the weak learning oracle as in the batch setting (smaller \u03b3 means more inaccurate weak learners). A clear drawback of all the algorithms mentioned above is lack of adaptivity. A simple interpretation of this drawback is that all these algorithms require using \u03b3, an unknown quantity, as a parameter. More importantly, this also means that the algorithm treats each weak learner equally and ignores the fact that some weak learners are actually doing better than the others. The best example of adaptive boosting algorithm is the well-known parameter-free AdaBoost algorithm [Freund and Schapire, 1997], where each weak learner is naturally weighted by how accurate it is. In fact, adaptivity is known to be one of the key features that lead to the practical success of AdaBoost, and therefore should also be essential to the performance of online boosting algorithms. In Section 4, we thus propose AdaBoost.OL, an adaptive and parameter-free online boosting algorithm. As shown in Table 1, AdaBoost.OL is theoretically suboptimal in terms of N and T . However, empirically it generally outperforms OSBoost and sometimes even beats the optimal algorithm Online BBM (see Section 5). Our techniques are also very different from those of Chen et al. [2012], which rely on the smooth boosting algorithm of Servedio [2003].", "startOffset": 193, "endOffset": 1925}, {"referenceID": 3, "context": "our algorithm doesn\u2019t require weighted online learning, instead using a sampling technique similar to the one used in boosting by filtering in the batch setting [see for example, Freund, 1992, Bradley and Schapire, 2008], and 3. our algorithm is optimal in the sense that no online boosting algorithm can achieve the same error rate with less weak learners or less examples asymptotically (see the lower bounds in Section 3.2). A quantitative comparison of our results with those of Chen et al. [2012] appears in Table 1, where N and T represent the number1 of weak learners and examples needed to achieve error rate \u01eb, and \u03b3 stands for a similar concept of the \u201cedge\u201d of the weak learning oracle as in the batch setting (smaller \u03b3 means more inaccurate weak learners). A clear drawback of all the algorithms mentioned above is lack of adaptivity. A simple interpretation of this drawback is that all these algorithms require using \u03b3, an unknown quantity, as a parameter. More importantly, this also means that the algorithm treats each weak learner equally and ignores the fact that some weak learners are actually doing better than the others. The best example of adaptive boosting algorithm is the well-known parameter-free AdaBoost algorithm [Freund and Schapire, 1997], where each weak learner is naturally weighted by how accurate it is. In fact, adaptivity is known to be one of the key features that lead to the practical success of AdaBoost, and therefore should also be essential to the performance of online boosting algorithms. In Section 4, we thus propose AdaBoost.OL, an adaptive and parameter-free online boosting algorithm. As shown in Table 1, AdaBoost.OL is theoretically suboptimal in terms of N and T . However, empirically it generally outperforms OSBoost and sometimes even beats the optimal algorithm Online BBM (see Section 5). Our techniques are also very different from those of Chen et al. [2012], which rely on the smooth boosting algorithm of Servedio [2003]. As far as we know, all other work on smooth boosting In this paper, we use the \u00d5(\u00b7) and \u03a9\u0303(\u00b7) notation to suppress dependence on polylogarithmic factors in the natural parameters.", "startOffset": 193, "endOffset": 1989}, {"referenceID": 8, "context": "In the standard batch boosting case, the corresponding weak learning assumption (see for example Schapire and Freund [2012]) made is that there is an algorithm which, given a training set of examples and an arbitrary distribution on it, generates a hypothesis that has error at most 1 2 \u2212 \u03b3 on the training data under the given distribution.", "startOffset": 110, "endOffset": 124}, {"referenceID": 2, "context": "Ben-David et al. [2009]).", "startOffset": 0, "endOffset": 24}, {"referenceID": 8, "context": "For example, if \u03a6i(s) is the exponential potential that leads to a variant of AdaBoost in the batch setting [see Schapire and Freund, 2012, Chap. 13], then the weight w t could be exponentially large. Fortunately, there is indeed a set of potential functions that produces small weights, which, in the batch setting, corresponds to an algorithm called boost-by-majority (BBM) Freund [1995]. All we need to do is to let Eq.", "startOffset": 126, "endOffset": 390}, {"referenceID": 8, "context": "It is known that boosting can be viewed as trying to find a linear combination of weak hypotheses to minimize the total loss of the training examples, usually using functional gradient descent [see for details Schapire and Freund, 2012, Chap. 7]. AdaBoost, for instance, minimizes the exponential loss. Here, as discussed before, we intuitively want to avoid using exponential loss since it could lead to large weights. Instead, we will consider logistic loss l(s) = ln(1 + exp(\u2212s)), which results in an algorithm called AdaBoost.L in the batch setting [Schapire and Freund, 2012, Chap. 7]. In the online setting, we conceptually define N different \u201cexperts\u201d giving advice on what to predict on the current example xt. In round t, expert i predicts by combining the first i weak learners: \u0177 t = sign( \u2211i j=1 \u03b1 j tWL (xt)). Now as in AdaBoost.L, the weight w i t for WL i is obtained by computing the logistic loss of the prediction of expert i\u2212 1, i.e. l(si\u22121 t ), and then setting w t to be the negative derivative of the loss: w t = \u2212l\u2032(si\u22121 t ) = 1 1 + exp(si\u22121 t ) \u2208 [0, 1]. In terms of the weight of WL, i.e. \u03b1t, ideally we wish to mimic AdaBoost.L and use a fixed \u03b1 i for all t such that the total logistic loss is minimized: \u03b1 = argmin\u03b1 \u2211T t=1 l(s i\u22121 t + \u03b1z i t). Of course this is not possible because \u03b1 depends on the future unknown examples. Nevertheless, it turns out that we can almost achieve that using tools from online learning theory. Indeed, one of the fundamental topics in online learning is exactly how to perform almost as well as the best fixed choice (\u03b1) in the hindsight. Specifically, it turns out that it suffices to restrict \u03b1 to the feasible set [\u22122, 2]. Then consider the following simple one dimensional online learning problem: on each round t, algorithm predicts \u03b1t from a feasible set [\u22122, 2]; the environment then reveals loss function ft(\u03b1) = l(si\u22121 t + \u03b1z t) and the algorithm suffers loss ft(\u03b1 i t). There are many so-called \u201clow-regret\u201d algorithms in the literature (see the survey by Shalev-Shwartz [2011]) for this problem ensuring", "startOffset": 223, "endOffset": 2047}, {"referenceID": 6, "context": "OCP from [Chen et al., 2012], all using importance weighted examples in VW.", "startOffset": 9, "endOffset": 28}], "year": 2015, "abstractText": "We study online boosting, the task of converting any weak online learner into a strong online learner. Based on a novel and natural definition of weak online learnability, we develop two online boosting algorithms. The first algorithm is an online version of boost-by-majority. By proving a matching lower bound, we show that this algorithm is essentially optimal in terms of the number of weak learners and the sample complexity needed to achieve a specified accuracy. This optimal algorithm is not adaptive, however. Using tools from online loss minimization, we derive an adaptive online boosting algorithm that is also parameter-free, but not optimal. Both algorithms work with base learners that can handle example importance weights directly, as well as by rejection sampling examples with probability defined by the booster. Results are complemented with an experimental study.", "creator": "LaTeX with hyperref package"}}}