{"id": "1502.03536", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Feb-2015", "title": "Speeding up Permutation Testing in Neuroimaging", "abstract": "Multiple hypothesis testing is a significant problem in nearly all neuroimaging studies. In order to correct for this phenomena, we require a reliable estimate of the Family-Wise Error Rate (FWER). The well known Bonferroni correction method, while simple to implement, is quite conservative, and can substantially under-power a study because it ignores dependencies between test statistics. Permutation testing, on the other hand, is an exact, non-parametric method of estimating the FWER for a given $\\alpha$-threshold, but for acceptably low thresholds the computational burden can be prohibitive. In this paper, we show that permutation testing in fact amounts to populating the columns of a very large matrix ${\\bf P}$. By analyzing the spectrum of this matrix, under certain conditions, we see that ${\\bf P}$ has a low-rank plus a low-variance residual decomposition which makes it suitable for highly sub--sampled --- on the order of $0.5\\%$ --- matrix completion methods. Based on this observation, we propose a novel permutation testing methodology which offers a large speedup, without sacrificing the fidelity of the estimated FWER. Our evaluations on four different neuroimaging datasets show that a computational speedup factor of roughly $50\\times$ can be achieved while recovering the FWER distribution up to very high accuracy. Further, we show that the estimated $\\alpha$-threshold is also recovered faithfully, and is stable.", "histories": [["v1", "Thu, 12 Feb 2015 04:30:06 GMT  (534kb,D)", "http://arxiv.org/abs/1502.03536v1", "NIPS 13"]], "COMMENTS": "NIPS 13", "reviews": [], "SUBJECTS": "stat.CO cs.AI stat.ML", "authors": ["chris hinrichs", "vamsi k ithapu", "qinyuan sun", "sterling c johnson", "vikas singh"], "accepted": true, "id": "1502.03536"}, "pdf": {"name": "1502.03536.pdf", "metadata": {"source": "CRF", "title": "Speeding up Permutation Testing in Neuroimaging", "authors": ["Chris Hinrichs", "Vamsi K. Ithapu", "Qinyuan Sun", "Sterling C. Johnson", "Vikas Singh"], "emails": ["hinrichs@cs.wisc.edu", "vamsi@cs.wisc.edu", "qsun28@wisc.edu", "scj@medicine.wisc.edu", "vsingh@biostat.wisc.edu"], "sections": [{"heading": "1 Introduction", "text": "Suppose we have completed a placebo-controlled clinical trial on a promising new drug for a neurodegenerative disorder such as Alzheimer's disease (AD) in a small group. It is designed so that, in addition to assessing improvements in standard cognitive outcomes (e.g., MMSE), the alleged treatment effects can also be assessed using neuroimaging data, on the grounds that even if the drug causes variations in cognitive symptoms, the changes in the brain can be seen much earlier in the imaging data, this analysis indicates the statistically significant differences between the brain images of the subjects assigned to the two experimental arms: treatment and placebo. Alternatively, consider a second scenario in which we have completed a neuroimaging research study of a particular controlled factor, such as genotype, and the interest is to evaluate group differences in brain images: to identify which function is affected as belonging to the class."}, {"heading": "2 The Proposed Algorithm", "text": "We will first discuss some of the basic concepts underlying low-rank permutation testing and matrix completion before introducing our algorithm and the associated analysis."}, {"heading": "2.1 Permutation testing", "text": "Remember that although point-by-point test statistics have univariate zero distributions, the sample maximum usually does not have an analytical form due to the strong correlations between the voxels. Permutation is particularly desirable in this context because it is free of any distribution assumption [12]. The basic idea of permutation testing is very simple but extremely powerful. Suppose we have a set of labeled high-dimensional data points and a univariate test statistic that measures interaction between labeled groups for each dimension (or feature). If we randomly permutate the labels and recalculate each test statistic, we get a sample from the global zero distribution that is labeled at most across all of these statistics."}, {"heading": "2.2 Low-rank Matrix completion", "text": "The completion of the low-rank matrix [19] attempts to reconstruct missing entries from a matrix, taking into account only a small fraction of its entries; the problem is not raised, unless we assume that this matrix has a low-rank column space. If so, a much smaller number of observations in the order r log (v), where r occupies the rank of the column space, and v is its ambient dimension [19] is sufficient to restore both an orthogonal basis for the row space and the expansion coefficients for each column, resulting in the recovery. By giving a \"1-standard penalty for the eigenvalues of the obtained matrix over the core standard [20, 21] we can ensure that the solution is as low as possible. Alternatively, we can specify a rank r ahead of time and an orthogonal basis of this rank by specifying a mandient along the 22-nix gradient [17]."}, {"heading": "2.3 Low rank plus a long tail", "text": "Real-world data often have a dominant low component. While the data may not be accurately characterized by a low base, the residual amount will not significantly alter the self-spectrum of covariance of the sample in such cases. Strong correlations are almost synonymous with skewed self-spectrum, because the flatter the self-spectrum, the more sparse will be the resulting covariance matrix (the \"uncertainty principle\" between low and sparse matrices [23]). This low structure prevails for purely linear statistics (such as sample averages). However, non-linearity in the calculation of test statistics, e.g. normalization by pooled variances, will contribute a long tail of eigenvalues, and so we will demand that this long tail either expires quickly or does not overlap with the dominant eigenvalues."}, {"heading": "2.4 Our Method", "text": "Through sub-sampling, we can reconstruct the subset of P via matrix completion, but in order to obtain the desired maximum distribution of the sample, we also need to recover the remainders. Accurate recovery of the residual quantity is essentially impossible; fortunately, we only need its effect on the distribution of the maximum per permutation test. So we estimate its variance, (its mean is zero by assumption), and then random sample from this distribution to restore the unobserved remainder of the matrix. A large component in the runtime of online subspace tracking algorithms is used in updating the base of U; however, once a good estimate for U is found, this becomes superfluous. We divide the entire process into two steps: training and recovery we perform a small number of permutation tests (100 permutations in our experiments)."}, {"heading": "3 Analysis", "text": "We are now discussing two results, which show that as long as the variance of residual values is below a certain level, we can recover the distribution of the sample maximum. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "4 Experimental evaluations", "text": "Our experimental evaluations include four separate neuroimaging datasets of Alzheimer's disease (AD) patients, cognitively healthy age-appropriate controls (CN) and in some cases mild cognitive impairment (MCI) patients. The first is the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, a nationwide multi-site study. ADNI is a groundbreaking study sponsored by the NIH, major pharmaceuticals and others to determine the extent to which multimodal brain imaging can help predict the onset and progression of AD. The others were collected as part of other studies of AD and MCI. We refer to these datasets as Dataset A - D. Their demographic characteristics are as follows: 40 subjects, AD vs. CN, mean age: 76; Dataset B: 50 subjects, AD vs. CN, median age: 68 subjects, CN vs. MI."}, {"heading": "4.2 What is the computational speedup?", "text": "Our experiments indicate that the acceleration is significant. Figures 6 and 2 compare the time needed to perform the complete permutation tests with that of our model. The three graphs in Figure 6 correspond to the data sets used in Figure 5 in this order. Each graph contains 4 curves and represents the time required by our model, the corresponding sampling and the GRASTA divergence (plus training times), and the total time taken to build the entire matrix P (horizontal line). And Figure 2 shows the scatter plot of the computational speedup vs. KL divergence (over 3 repeated test groups for all data sets and sampling rates). Our model achieved at least 30 times shorter computational time in the low sampling regime (< 1%). Approximately 0.5% \u2212 0.6% sub-sampling (where the L acceleration and model acceleration rate < 1% was already achieved in the low sampling regime; < 2)."}, {"heading": "4.3 How stable is the estimated \u03b1-threshold (clinical significance)?", "text": "Our experiments indicate that the threshold is stable. Fig. 4 and Table 1 summarize the clinical significance of our model. Fig. 4 show the error in estimating the true maximum threshold at 1 \u2212 \u03b1 = 0.95 confidence level. The x-axis corresponds to the 20 different sampling rates and the y-axis shows the absolute difference between the thresholds in the log scale. Note that for sampling rates greater than 3% the mean and maximum differences are 0.04 and 0.18. To support this observation, we show the absolute differences in the estimated thresholds of all data sets at 4 different alpha levels in Table 1. The errors for 1 \u2212 \u03b1 = 0.95, 0.99 are at most 0.16. Increasing the error threshold for 1 \u2212 \u03b1 > 0.95 is a slight difference in the estimated thresholds for all data sets at 4 different alpha levels."}, {"heading": "5 Conclusions and future directions", "text": "In this paper, we have proposed a novel method for efficiently approximating the permutation test matrix by first estimating the most important singular vectors, then filling in the missing values using matrix completion, and finally estimating the distribution of residual values. Experiments on four different neuroimaging datasets show that we can restore the distribution of maximum zero statistics to a high degree of accuracy while maintaining a computational acceleration factor of about 50 x. While our focus is on neuroimaging problems, we note that multiple tests and false discovery rate (FDR) corrections are important problems in genomic and RNA analysis, and our contribution could provide an improved impact on existing methods that use permutation testing in these settings [6]. We thank Robert Nowak, Grace Wahba, Moo K. Chung and the anonymous critics for their helpful comments, and Jia Xu for their help in the preliminary implementation of the model."}], "references": [{"title": "Voxel-based morphometry\u2013the methods", "author": ["J. Ashburner", "K.J. Friston"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Why voxel-based morphometry should be used", "author": ["J. Ashburner", "K.J. Friston"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Resampling-based multiple testing: examples and methods for p-value adjustment, volume 279", "author": ["P.H. Westfall", "S.S. Young"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1993}, {"title": "Multiple significance tests: the bonferroni method", "author": ["J.M. Bland", "D.G. Altman"], "venue": "British Medical Journal,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1995}, {"title": "Adjusting multiple testing in multilocus analyses using the eigenvalues of a correlation", "author": ["J. Li", "L. Ji"], "venue": "matrix. Heredity,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Statistical significance for genomewide studies", "author": ["J. Storey", "R. Tibshirani"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2003}, {"title": "Controlling the familywise error rate with plug-in estimator for the proportion of true null hypotheses", "author": ["H. Finner", "V. Gontscharuk"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "A general framework for multiple testing dependence", "author": ["J.T. Leek", "J.D. Storey"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2008}, {"title": "Robustness of multiple testing procedures against dependence", "author": ["S. Clarke", "P. Hall"], "venue": "The Annals of Statistics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis", "author": ["S. Garc\u0131\u0301a", "A. Fern\u00e1ndez", "J. Luengo", "F. Herrera"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Resampling-based multiple testing for microarray data analysis", "author": ["Y. Ge", "S. Dudoit", "T.P. Speed"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2003}, {"title": "Controlling the familywise error rate in functional neuroimaging: a comparative review", "author": ["T. Nichols", "S. Hayasaka"], "venue": "Statistical Methods in Medical Research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2003}, {"title": "Group imaging of task-related changes in cortical synchronisation using nonparametric permutation testing", "author": ["K.D. Singh", "G.R. Barnes", "A. Hillebrand"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "A comparison of random field theory and permutation methods for the statistical analysis of meg data", "author": ["D. Pantazis", "T.E. Nichols", "S. Baillet", "R.M. Leahy"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2005}, {"title": "Analytic estimation of statistical significance maps for support vector machine based multi-variate image analysis and classification", "author": ["B. Gaonkar", "C. Davatzikos"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "A simple correction for multiple comparisons in interval mapping genome", "author": ["J.M. Cheverud"], "venue": "scans. Heredity,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2001}, {"title": "Incremental gradient on the grassmannian for online foreground and background separation in subsampled video", "author": ["J. He", "L. Balzano", "A. Szlam"], "venue": "In CVPR,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Modified randomization tests for nonparametric hypotheses", "author": ["M. Dwass"], "venue": "The Annals of Mathematical Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1957}, {"title": "The power of convex relaxation: Near-optimal matrix completion", "author": ["E.J. Cand\u00e8s", "T. Tao"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Rank minimization and applications in system theory", "author": ["M. Fazel", "H. Hindi", "S. Boyd"], "venue": "In American Control Conference,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization", "author": ["B. Recht", "M. Fazel", "P.A. Parrilo"], "venue": "Arxiv Preprint,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2007}, {"title": "Online identification and tracking of subspaces from highly incomplete information", "author": ["L. Balzano", "R. Nowak", "B. Recht"], "venue": "Arxiv Preprint,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "Rank-sparsity incoherence for matrix decomposition", "author": ["V. Chandrasekaran", "S. Sanghavi", "P.A. Parrilo", "Willsky A. S"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "The eigenvalues and eigenvectors of finite, low rank perturbations of large random matrices", "author": ["F. Benaych-Georges", "R.R. Nadakuditi"], "venue": "Advances in Mathematics,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "[1, 2].", "startOffset": 0, "endOffset": 6}, {"referenceID": 1, "context": "[1, 2].", "startOffset": 0, "endOffset": 6}, {"referenceID": 2, "context": "As one might expect, given the number of hypotheses tests v, multiple testing issues in this setting are quite severe, making it difficult to assess the true FamilyWise Type I Error Rate (FWER) [3].", "startOffset": 194, "endOffset": 197}, {"referenceID": 3, "context": "If we were to address this issue via Bonferroni correction [4], the enormous number of separate tests implies that certain weaker signals will almost certainly never be detected, even if they are real.", "startOffset": 59, "endOffset": 62}, {"referenceID": 4, "context": "Thus, many methods have been developed to more accurately and efficiently estimate or approximate the FWER [5, 6, 7, 8], which is a subject of much interest in statistics [9], machine learning [10], bioinformatics [11], and neuroimaging [12].", "startOffset": 107, "endOffset": 119}, {"referenceID": 5, "context": "Thus, many methods have been developed to more accurately and efficiently estimate or approximate the FWER [5, 6, 7, 8], which is a subject of much interest in statistics [9], machine learning [10], bioinformatics [11], and neuroimaging [12].", "startOffset": 107, "endOffset": 119}, {"referenceID": 6, "context": "Thus, many methods have been developed to more accurately and efficiently estimate or approximate the FWER [5, 6, 7, 8], which is a subject of much interest in statistics [9], machine learning [10], bioinformatics [11], and neuroimaging [12].", "startOffset": 107, "endOffset": 119}, {"referenceID": 7, "context": "Thus, many methods have been developed to more accurately and efficiently estimate or approximate the FWER [5, 6, 7, 8], which is a subject of much interest in statistics [9], machine learning [10], bioinformatics [11], and neuroimaging [12].", "startOffset": 107, "endOffset": 119}, {"referenceID": 8, "context": "Thus, many methods have been developed to more accurately and efficiently estimate or approximate the FWER [5, 6, 7, 8], which is a subject of much interest in statistics [9], machine learning [10], bioinformatics [11], and neuroimaging [12].", "startOffset": 171, "endOffset": 174}, {"referenceID": 9, "context": "Thus, many methods have been developed to more accurately and efficiently estimate or approximate the FWER [5, 6, 7, 8], which is a subject of much interest in statistics [9], machine learning [10], bioinformatics [11], and neuroimaging [12].", "startOffset": 193, "endOffset": 197}, {"referenceID": 10, "context": "Thus, many methods have been developed to more accurately and efficiently estimate or approximate the FWER [5, 6, 7, 8], which is a subject of much interest in statistics [9], machine learning [10], bioinformatics [11], and neuroimaging [12].", "startOffset": 214, "endOffset": 218}, {"referenceID": 11, "context": "Thus, many methods have been developed to more accurately and efficiently estimate or approximate the FWER [5, 6, 7, 8], which is a subject of much interest in statistics [9], machine learning [10], bioinformatics [11], and neuroimaging [12].", "startOffset": 237, "endOffset": 241}, {"referenceID": 11, "context": "A commonly used method of directly and non-parametrically estimating the FWER is Permutation testing [12, 13], which is a method of sampling from the Global (i.", "startOffset": 101, "endOffset": 109}, {"referenceID": 12, "context": "A commonly used method of directly and non-parametrically estimating the FWER is Permutation testing [12, 13], which is a method of sampling from the Global (i.", "startOffset": 101, "endOffset": 109}, {"referenceID": 13, "context": "This step alone can run from a few days up to many weeks and even longer [14, 15].", "startOffset": 73, "endOffset": 81}, {"referenceID": 14, "context": "This step alone can run from a few days up to many weeks and even longer [14, 15].", "startOffset": 73, "endOffset": 81}, {"referenceID": 4, "context": "Note that regardless of their description, strong dependencies of almost any kind will tend to concentrate most of their co-variation into a low-rank subspace, leaving a high-rank, low-variance residual [5].", "startOffset": 203, "endOffset": 206}, {"referenceID": 15, "context": "In fact, for Genome wide Association studies (GWAS), many strategies calculate the \u2018effective number\u2019 (Meff ) of independent tests corresponding to the rank of this subspace [16, 5].", "startOffset": 174, "endOffset": 181}, {"referenceID": 4, "context": "In fact, for Genome wide Association studies (GWAS), many strategies calculate the \u2018effective number\u2019 (Meff ) of independent tests corresponding to the rank of this subspace [16, 5].", "startOffset": 174, "endOffset": 181}, {"referenceID": 16, "context": "Using ideas from online low-rank matrix completion [17] we can sample a few of the Null statistics and reconstruct the remainder as long as we properly account for the residual.", "startOffset": 51, "endOffset": 55}, {"referenceID": 17, "context": "Randomly sampled permutation testing [18] is a methodology for drawing samples under the Global (Family-Wise) Null hypothesis.", "startOffset": 37, "endOffset": 41}, {"referenceID": 11, "context": "Permutation is particularly desirable in this setting because it is free of any distribution assumption whatsoever [12].", "startOffset": 115, "endOffset": 119}, {"referenceID": 18, "context": "Low-rank matrix completion [19] seeks to reconstruct missing entries from a matrix, given only a small fraction of its entries.", "startOffset": 27, "endOffset": 31}, {"referenceID": 18, "context": "If so, then a much smaller number of observations, on the order of r log(v), where r is the column space\u2019s rank, and v is its ambient dimension [19] is sufficient to recover both an orthogonal basis for the row space as well as the expansion coefficients for each column, giving the recovery.", "startOffset": 144, "endOffset": 148}, {"referenceID": 19, "context": "By placing an `1-norm penalty on the eigenvalues of the recovered matrix via the nuclear norm [20, 21] we can ensure that the solution is as low rank as possible.", "startOffset": 94, "endOffset": 102}, {"referenceID": 20, "context": "By placing an `1-norm penalty on the eigenvalues of the recovered matrix via the nuclear norm [20, 21] we can ensure that the solution is as low rank as possible.", "startOffset": 94, "endOffset": 102}, {"referenceID": 21, "context": "Alternatively, we can specify a rank r ahead of time, and estimate an orthogonal basis of that rank by following a gradient along the Grassmannian manifold [22, 17].", "startOffset": 156, "endOffset": 164}, {"referenceID": 16, "context": "Alternatively, we can specify a rank r ahead of time, and estimate an orthogonal basis of that rank by following a gradient along the Grassmannian manifold [22, 17].", "startOffset": 156, "endOffset": 164}, {"referenceID": 21, "context": ", where rows of P arrive one at a time, and both U and W are updated accordingly [22, 17].", "startOffset": 81, "endOffset": 89}, {"referenceID": 16, "context": ", where rows of P arrive one at a time, and both U and W are updated accordingly [22, 17].", "startOffset": 81, "endOffset": 89}, {"referenceID": 22, "context": "skewed eigen-spectrum, because the flatter the eigen-spectrum becomes, the sparser the resulting covariance matrix tends to be (the \u201cuncertainty principle\u201d between low-rank and sparse matrices [23]).", "startOffset": 193, "endOffset": 197}, {"referenceID": 21, "context": "From these permutation tests, we estimate U using sub-sampled matrix completion methods [22, 17], making multiple passes over the training set (with fixed sub-sampling rate), until convergence.", "startOffset": 88, "endOffset": 96}, {"referenceID": 16, "context": "From these permutation tests, we estimate U using sub-sampled matrix completion methods [22, 17], making multiple passes over the training set (with fixed sub-sampling rate), until convergence.", "startOffset": 88, "endOffset": 96}, {"referenceID": 21, "context": "If this low-rank perturbation is sufficient to dominate the eigenvalues of the random matrix, then P can be recovered with high fidelity at a low sampling rate [22, 17].", "startOffset": 160, "endOffset": 168}, {"referenceID": 16, "context": "If this low-rank perturbation is sufficient to dominate the eigenvalues of the random matrix, then P can be recovered with high fidelity at a low sampling rate [22, 17].", "startOffset": 160, "endOffset": 168}, {"referenceID": 23, "context": "Thus, rather than analyzing the singular value spectrum of P directly, we can analyze the eigenvalues of PP using a recent result from [24].", "startOffset": 135, "endOffset": 139}, {"referenceID": 23, "context": "1 from [24].", "startOffset": 7, "endOffset": 11}, {"referenceID": 23, "context": "1 of [24].", "startOffset": 5, "endOffset": 9}, {"referenceID": 23, "context": "The analysis in [24] takes into account the phase transition of extreme eigen values.", "startOffset": 16, "endOffset": 20}, {"referenceID": 16, "context": "Each plot contains 4 curves and represent the time taken by our model, the corresponding sampling and GRASTA [17] recovery (plus training) times and the total time to construct the entire matrix P (horizontal line).", "startOffset": 109, "endOffset": 113}, {"referenceID": 5, "context": "While our focus has been on neuroimaging problems, we note that multiple testing and False Discovery Rate (FDR) correction are important issues in genomic and RNA analyses, and our contribution may offer enhanced leverage to existing methodologies which use permutation testing in these settings[6].", "startOffset": 295, "endOffset": 298}], "year": 2015, "abstractText": "Multiple hypothesis testing is a significant problem in nearly all neuroimaging studies. In order to correct for this phenomena, we require a reliable estimate of the Family-Wise Error Rate (FWER). The well known Bonferroni correction method, while simple to implement, is quite conservative, and can substantially under-power a study because it ignores dependencies between test statistics. Permutation testing, on the other hand, is an exact, non-parametric method of estimating the FWER for a given \u03b1-threshold, but for acceptably low thresholds the computational burden can be prohibitive. In this paper, we show that permutation testing in fact amounts to populating the columns of a very large matrix P. By analyzing the spectrum of this matrix, under certain conditions, we see that P has a low-rank plus a low-variance residual decomposition which makes it suitable for highly sub\u2013sampled \u2014 on the order of 0.5% \u2014 matrix completion methods. Based on this observation, we propose a novel permutation testing methodology which offers a large speedup, without sacrificing the fidelity of the estimated FWER. Our evaluations on four different neuroimaging datasets show that a computational speedup factor of roughly 50\u00d7 can be achieved while recovering the FWER distribution up to very high accuracy. Further, we show that the estimated \u03b1-threshold is also recovered faithfully, and is stable.", "creator": "LaTeX with hyperref package"}}}