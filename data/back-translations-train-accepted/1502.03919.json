{"id": "1502.03919", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2015", "title": "Policy Gradient for Coherent Risk Measures", "abstract": "We provide sampling-based algorithms for optimization under a coherent-risk objective. The class of coherent-risk measures is widely accepted in finance and operations research, among other fields, and encompasses popular risk-measures such as the conditional value at risk (CVaR) and the mean-semi-deviation. Our approach is suitable for problems in which the tunable parameters control the distribution of the cost, such as in reinforcement learning with a parameterized policy; such problems cannot be solved using previous approaches. We consider both static risk measures, and time-consistent dynamic risk measures. For static risk measures, our approach is in the spirit of policy gradient algorithms, while for the dynamic risk measures our approach is actor-critic style.", "histories": [["v1", "Fri, 13 Feb 2015 09:16:24 GMT  (100kb,D)", "https://arxiv.org/abs/1502.03919v1", null], ["v2", "Mon, 8 Jun 2015 06:31:42 GMT  (250kb,D)", "http://arxiv.org/abs/1502.03919v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.LG stat.ML", "authors": ["aviv tamar", "yinlam chow", "mohammad ghavamzadeh", "shie mannor"], "accepted": true, "id": "1502.03919"}, "pdf": {"name": "1502.03919.pdf", "metadata": {"source": "CRF", "title": "Policy Gradient for Coherent Risk Measures", "authors": ["Aviv Tamar", "Yinlam Chow"], "emails": ["avivt@tx.technion.ac.il", "ychow@stanford.edu", "ghavamza@adobe.com", "shie@ee.technion.ac.il"], "sections": [{"heading": "1 Introduction", "text": "In this context, it is worth mentioning that this project is a project, which is primarily a project."}, {"heading": "2 Preliminaries", "text": "If we consider a probability space (\u0432, F, Pzipation) in which \u0432 is the totality of the results (sample space), F is a series of probability distributions representing the set of events in which we are interested, and Pzipzipzipzipzipzipzipzipzip.B is a probability quantity above F parameterized by a limited number of elements. In the following, we suppress the notation of \u03b8 in dependent quantities. To facilitate technical exposure, we limit our attention to limited probability spaces, i.e., we have a limited number of elements. Our results can be extended to the Lp-standardized spaces without loss of generality, but the details are omitted for Brevity.DP. Denote by Z is the space of random variables Z: 0 \u2192 (\u2212 conceived, inst.)."}, {"heading": "2.1 Coherent Risk Measures", "text": "A risk measure is a function: Z \u00b2 R, which is an uncertain result Z in relation to the extended real line R \u00b2 (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A), (A, (A), (A), (A, A, A, (A), (A), (A), (A), (A, (A), (A), (A), (A), (A, (A), (A), (A), (A, (A), (A), (A, (A), (A), (A, (A), (A, (A), (A), (A, (A), (A, (A), (A), (A, (A), (A, (A), (A), (A, (A), (A, (A), (A, (A, A, A, A), (), (A, (), (A), (A, (A, (A, A, A, A, A, (), (), (A, (A, (A), (A, (A, (A), (A), (A, (A, (A, (, A), (A), (A), (A, (A, (A), (A, (A), (A, (A), (A, A, A, (A, A, A, (, A), A, (,"}, {"heading": "2.2 Dynamic Risk Measures", "text": "The risk metrics defined above do not take into account a temporal structure that the random variable might have, e.g. if it is linked to the return of a development in the case of MDPs. In this sense, such risk metrics are called static. Dynamic risk metrics, on the other hand, explicitly take into account the temporal nature of the stochastic result. A primary motivation for considering such measures is the question of time consistency, which is usually defined as follows [30]: If a particular outcome is considered less risky in all countries of the world at level t + 1, then it should also be considered less risky at level t. Example 2.1 in [16] shows the importance of time consistency in assessing risk in a dynamic environment. It shows that optimizing a static metric can lead to \"inconsistent\" behavior over time."}, {"heading": "3 Problem Formulation", "text": "In this paper, we are interested in solving two risk-sensitive optimization problems. In view of a random variable Z and a static coherent risk metric \u03c1, as defined in Section 2, the static risk problem (SRP) is given by min \u03b8 \u03c1 (Z). (4) For example, in an RL environment, Z may correspond to the cumulative discounted cost Z = C (x0) + \u03b3C (x1) + \u00b7 + \u03b3TC (xT) as induced by an MDP with political parameterization by \u03b8. For an MDPM and a dynamic Markov-coherent risk measurement \u03c1T as defined by equation. 3, the dynamic risk problem (DRP) is given by min-dependent cases (M). (5) Except in very limited cases, there is no reason to hope that neither the SRP in (4) nor the DRP in (5) should be a dynamic problem, as the dependence of the risk-based DRP and the full DRP functions are not possible."}, {"heading": "4 Gradient Formula for Static Risk", "text": "In this section, we consider a static, coherent risk measure (Z) and propose sample-based estimates (Z) based on the following assumption generally used in the policy gradient literature. [18] Assumption 4.1. The probability ratio (s) is well defined and limited for all policy gradients logP (n). Furthermore, our approach implicitly assumes that the given gradient formula (s) can be easily calculated, which is also a standard requirement for policy gradient algorithms [18] and is met in various application areas such as queue systems, inventory management and financial engineering (see, for example, the Fu survey [14]. Based on theorem 2.1 and assumption 2.2, we have this requirement (s) for each subject. [Z) is the solution to the convex optimization problem (1)."}, {"heading": "4.1 Example 1: CVaR", "text": "The CVaR at level \u03b1 [0, 1] of a random variable Z, denoted by \u03c1CVaR (Z; \u03b1), is a very popular coherent risk measure [28], defined as \u03c1CVaR (Z; \u03b1). = inf t \u00b2 R {t + \u03b1 \u2212 1E [(Z \u2212 t) +]. If Z is continuous, the CVaR (Z; \u03b1) is well known as the mean of the \u03b1-tail distribution of Z, E [Z | Z > q\u03b1], where q\u03b1 is a (1 \u2212 \u03b1) quantity of Z. Selecting a small \u03b1 therefore makes CVaR particularly vulnerable to rare but very high costs. The risk range for CVaR is known to be [32] U = {s \u00b2 Pledge: Both in qq [0, \u03b1 \u2212 1] and in this case [1 \u2212 1], in which case it can be shown that the presumption with respect to the VaR assumption is explicit [6]."}, {"heading": "4.2 Example 2: Mean-Semideviation", "text": "The semi-deviation of a random variable Z is defined as SD [Z]. = (E [(Z \u2212 E [Z] 2 +]) 1 / 2. The semi-deviation detects the variation of costs only above their mean and is an appealing alternative to the standard deviation, which does not distinguish between the variability of upward and downward deviations. For some \u03b1 [0, 1], the mean-semi-deviation risk is defined as \u03c1MSD (Z; \u03b1). = E [Z] + \u03b1SD [Z] and is a coherent risk measure [32]. We have the following result: Assumption 4.3. Assuming 4.1, we have with the prediction E [Z] = E [s] s [s] s [s] s [s] s [s] s [s] s] s [s] s [s] s] s [s] s [s]."}, {"heading": "4.3 General Gradient Estimation Algorithm", "text": "In the two previous examples, we have obtained a progression formula by analytically calculating the problem of Lagrangian saddle points (6) and inserting it into the formula of Theorem 4.2. We only assume that we know the structure of the risk-envelope curve according to (2). We show that in this case, using an average sample approximation (SAA; [32]) of the formula in Theorem 4.2.Assume that we assume N i.i.d. sample assumptions, i = 1,., and let PTB (Z) be estimated. = 1 N, and let PTB (N) that we assume the average approximation (SAA; [32]) of the formula in Theorem 4.2.Assume that we give the corresponding empirical distributions."}, {"heading": "5 Gradient Formula for Dynamic Risk", "text": "In this section we derive a new formula for the gradient of the Markov Method (34), in which we derive the transition expectancy (9) that we have made. Our approach is based on the combination of the static gradient formula of Theorem 4.2, with a dynamic-programming decomposition of the Markov Method (M). The risk-sensitive value function for an MDP M within the framework of policy is defined if the initial state is x0 x x. It is shown that due to the structure of the Markov Formula the dynamic risk increases (M | x0 = x). The value function is the unique solution of the risk-sensitive Bellman Method (x)."}, {"heading": "6 Numerical Illustration", "text": "In this section, we illustrate our approach using a numerical example. The purpose of this presentation is to emphasize the importance of flexibility in designing risk criteria for selecting an appropriate risk measure - so that both the risk preference of the user and the problem-specific characteristics are taken into account. We consider a trading agent who can invest in one of three assets (see Figure 1 for their distributions).The returns of the first two assets, A1 and A2, are normally distributed: A1, N (1, 1) and A2, N (4, 6).The yield on the third asset A3 has a Pareto distribution: f (z) = \u03b1z\u03b1 + 1, Z > 1, with \u03b1 = 1.5. The mean of the return on A3 is 3 and its deviation is infinite; such strongly waisted distributions are widely used in financial modelling [27]."}, {"heading": "7 Conclusion", "text": "We introduced algorithms to estimate the gradient of both static and dynamic coherent risk metrics, using two new formulae of the political gradient style that combine sampling with convex programming. As a result, our approach expands risk-sensitive RL to the entire class of coherent risk metrics and generalizes several current studies that focus on specific risk metrics. On the technical side, an important future direction is to improve the convergence rate of gradient estimates using methods of the coherent risk metrics. This is particularly important for risk criteria that are sensitive to rare events such as the CVaR [3]. From a conceptual point of view, the coherent risk metrics examined in this paper provide the decision-maker with flexibility in shaping risk metrics. As our numerical example shows, such flexibility is important for selecting the appropriate sense of our risk dynamics, but the uncertainty of the potential of the uncertainty, the uncertainty of the uncertainty of the cost model, the uncertainty that has a lot more potential."}, {"heading": "A Proof of Theorem 4.2", "text": "The first note from Assumption 2.2 that (i) Slater's condition in the primary optimization problem applies (1), (ii) L\u03b8 (2), (3), (3), (3), (4), (4), (4), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5, (5, (5), (5), (5), (5, (5, (5), (5), (5, (5), (5), (5), (5, (5, (5), (5), (5), (5, (5), (5), (5, (5), (5, (5), (5), (5, (5), (5), (5, (5), (5), (5, (5,"}, {"heading": "B Gradient Results for Static Mean-Semideviation", "text": "In this section we look at the mean half deviation risk variable defined as follows: [MSD (Z) = Quoted (Z) = Quoted (Z) = Quoted (Z) + Quoted (Z) + Quoted (Z) + Quoted (Z) + Quoted (Z) + Quoted (Z) + Quoted (Z). \u2212 Quoted (Z). \u2212 Quoted (Z). \u2212 Quoted (Z). \u2212 Quoted (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z). (Z)."}, {"heading": "C Consistency Proof", "text": "Have the probability range of the SAA functions (i.e., randomness due to the sampling) specified, the probability range of the SAA functions (i.e. randomness due to the sampling) specified, the probability range of the SAA functions (i.e. randomness due to the sampling) specified, and the probability range of the SAA functions (i.e. randomness due to the sampling) specified."}, {"heading": "1: Given:", "text": "\u2022 Risk level c \u2022 An i.i.d. sequence z1,..., zN \u0445 P\u03b8.2: SetE [Z] = 1N N \u0445 i = 1 zi.3: SetS \u0445 D (Z) = (1N \u0445 i = 1 (zi \u2212 E [Z]) 2 +) 1 / 2.4: SetS \u0432\u0430\u043d\u0438\u0441E [Z] = 1N \u0445 i = 1 \u0441\u0442\u043e\u043c\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u0438\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0441\u043e\u0435 (zi (zi (zi) zi (zi) zi) zi."}, {"heading": "5: Return:", "text": "The functions of the SN are not empty and limited. (ii) The functions of the SN are not empty and limited. (ii) The SN is not empty and the SN is not empty. (ii) The SN is not empty and the SN is not in order. (i) The SN is not empty. (i) The SN is not empty. (i) The SN are not empty. (i) The SN are not empty. (i) The SN are not empty. (i) The SN are not empty. (i) (i) The SN are not empty. (i) And the SN are not empty. (i) The SN are not empty. (i) The SN are not empty. (i) And the SN are not empty. (i) And the SN are not."}, {"heading": "D Proof of Theorem 5.2", "text": "Similar to the proof of theory 4.2, let us remember the saddle point definition of (1), (2), (2), (2), (3), (3), (3), (4), (4), (4), (4), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5, (5), (5), (5), (5, (5), (5, (5), (5), (5), (5, (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5), (5), (5"}, {"heading": "E Gradient Formula for Dynamic Risk - Full Results", "text": "In this section, we first derive a new formula for the gradient of a general Markov-coherent dynamic risk, which includes the value function of the risk objective (M). (This formula extends the well-known \"political risk theorem\" [34, 17] developed for the expected return to Markov-coherent dynamic risk measures. (See Section E.3), and Actor: Using the value function of the critic, we propose the following actor-critic style algorithm for estimating risk. (M): Critical: For a given policy approach, we calculate the risk-sensitive function of the risk (M). (See Section E.3), and Actor: The value function of the critic is sampled (see Section E.4). The value function we propose for each state is a specific value that encodes the long-term risk based on that state. (See Section E.4) If the state space is large, we calculate the value function by using the dynamic precept function (see Section E.4)."}, {"heading": "F Convergence Analysis of Empirical PRSVI", "text": "Lemma F. 1 (Technical Lemma): Let us consider P (\u00b7 \u00b7) and P (\u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "G Technical Results", "text": "In this section, we simplify the analysis by considering the following empirical, robust optimization problems: max. (1), whereby the solution of the above empirical problem is usually in the x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, x-ten, ten-ten, x-ten, x-ten, ten-ten, x-ten, x-ten, ten-ten, ten-ten, ten-ten-ten, x-ten, ten-ten-ten, x-ten, ten-ten, ten-ten-ten-ten, x-ten, ten-ten-ten-ten, x-ten-ten, x-ten, ten-ten-ten-ten, x-ten, ten-ten-ten-ten-ten-ten, x-ten-ten-ten, x-ten-ten, x-ten-ten-ten, x-ten-ten-ten, x-ten-ten-ten-ten, x-ten-ten-ten, x-ten-ten, x-ten-ten, x-ten-ten, x-ten-ten-ten, x-ten-ten, x-ten-ten-ten-ten, x-ten-ten, x-ten, x-ten-ten, x-ten-ten, x-ten, x-ten-ten, ten-ten-ten, x-ten-ten-ten, x-ten, x-ten, x-ten-ten-ten, x-ten, x-ten-ten, x-ten, x-ten, x-ten, x-ten, x-ten-ten"}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "Several authors have recently developed risk-sensitive policy gradient methods<lb>that augment the standard expected cost minimization problem with a measure of<lb>variability in cost. These studies have focused on specific risk-measures, such as<lb>the variance or conditional value at risk (CVaR). In this work, we extend the pol-<lb>icy gradient method to the whole class of coherent risk measures, which is widely<lb>accepted in finance and operations research, among other fields. We consider<lb>both static and time-consistent dynamic risk measures. For static risk measures,<lb>our approach is in the spirit of policy gradient algorithms and combines a standard<lb>sampling approach with convex programming. For dynamic risk measures, our ap-<lb>proach is actor-critic style and involves explicit approximation of value function.<lb>Most importantly, our contribution presents a unified approach to risk-sensitive<lb>reinforcement learning that generalizes and extends previous results.", "creator": "LaTeX with hyperref package"}}}