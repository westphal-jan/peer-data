{"id": "1502.05556", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Feb-2015", "title": "Just Sort It! A Simple and Effective Approach to Active Preference Learning", "abstract": "From sporting events to sociological surveys, ranking from pairwise comparisons is a tool of choice for many applications. When certain pairs of items are difficult to compare, outcomes can be noisy, and it is necessary to develop robust strategies. In this work, we show how a simple active sampling scheme that uses a standard black box sorting algorithm enables the efficient recovery of the ranking, achieving low error with sparse samples. Both in theory and practice, this active strategy performs systematically better than selecting comparisons at random. As a detour, we show a link between Rank Centrality, a recently proposed algorithm for rank aggregation, and the ML estimator for the Bradley-Terry model. This enables us to develop a new, provably convergent iterative algorithm for computing the ML estimate.", "histories": [["v1", "Thu, 19 Feb 2015 12:50:13 GMT  (68kb,D)", "https://arxiv.org/abs/1502.05556v1", null], ["v2", "Thu, 15 Jun 2017 15:19:38 GMT  (293kb,D)", "http://arxiv.org/abs/1502.05556v2", "Accepted at ICML 2017"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["lucas maystre", "matthias grossglauser"], "accepted": true, "id": "1502.05556"}, "pdf": {"name": "1502.05556.pdf", "metadata": {"source": "CRF", "title": "Just Sort It! A Simple and Effective Approach to Active Preference Learning", "authors": ["Lucas Maystre", "Matthias Grossglauser"], "emails": ["lucas.maystre@epfl.ch", "matthias.grossglauser@epfl.ch"], "sections": [{"heading": "1 Introduction", "text": "The problem of restoring a ranking of n items from noisy results of pairing comparisons has attracted much research interest in the last century, driven by applications in sports [Elo, 1978], social sciences [Thurstone, 1927, Salganik and Levy, 2015] and - more recently - recommendation systems [Houlsby et al., 2012]. While pairing comparison models and related follow-up algorithms have been extensively studied, the question of which pairing comparisons to the sample, also known as active learning, has received considerably less attention. To understand the potential benefits of adaptive selection of samples, we consider the case where comparison models are noiseless, i.e., consistent with a linear order of n items. When itempairs are randomly selected, it is necessary to collect comparisons to restore ranking [n2]."}, {"heading": "1.1 Preliminaries and Notation", "text": "We look at n items represented by consecutive integers [n] = {1,.., n}. Without loss of generality, we assume that the items are ranked by increasing the preference1, i.e., i < j means that j is preferred (in expectation) i. If j is preferred as the result of a paired comparison i, we denote the observation by i \u00b2 j. If i < j, we say that i \u00b2 j is a consistent result and j is an inconsistent (incorrect) result. In most papers, the paired comparison follows a Bradley-Terry model with parameters \u03b8 = [1 \u00b7 \u03b8n], which is the order of sequence in sequence in sequence in sequence in sequence in sequence in sequence in sequence in sequence in sequence of sequence in sequence in sequence in sequence of sequence in sequence."}, {"heading": "2 Related Work", "text": "Recently, there have been a number of results on the complexity of the BT model, based on the assumption that all items are selected before each comparison result. [Negahban et al., 2012, Hajek et al., 2014, Rajkumar and Agarwal, 2014, Vojnovic and Yun, 2016] In general, these results show that the selection of items based on observed results is essentially optimal. Furthermore, they suggest that the ranking generated by the BT model cannot be restored with less than two comparisons. Our work shows that we observe substantial preferences through adaptive selection of pairs based on observed outcomes."}, {"heading": "3 Theoretical Results", "text": "In this section, we begin by examining the behavior and results of Quicksort under inconsistent comparison results (with no assumptions about the origin of a process), then we begin by examining the results generated by the BT model. Most complete evidence results are deferred to Appendix A. Quicksort (lines 4-10), each other element is best described as a recursive procedure. If all comparisons are consistent, it is known that Quicksort is highly likely to be terminated after the O (n log n) sample. What happens if we abandon the consistency of the assumption that these key properties remain valid regardless of what (and how many) comparisons we have?"}, {"heading": "3.1 Displacement in the Poisson Model", "text": "From here, we assume that the comparative results are generated by BT. Clearly, any results about the shift of a rank estimated from samples of a BT model depend on two factors; it is easy to construct a model instance for which it is arbitrarily difficult to restore the ranking by selecting parameters that are sufficiently close to each other. Our approach is as follows: We postulate a family of distributions across two different factors, and we specify limits on the shift that is associated with a high probability. We assume that the comparative results are (in expectation) uniformly noisy across the ranking: i.e., comparing two elements at the bottom is as difficult as comparing two elements at the top or in the middle. This means that the probability distribution over the parameters at the top 1,.,., The results at (random) distances i + k, which depend only on k. Such a distribution occurs when the parameters are drawn at a point of the poison."}, {"heading": "3.2 Independent Uniformly-Distributed Parameters", "text": "Another (perhaps more natural) assumption based on the parameters \u03b8 is to take into account that they are drawn randomly independently and uniformly over a certain period of time, i.e. that the order statistics of the aforementioned variables, i.e. the random variables, are arranged in increasing order. On the basis of some elementary results on the common distribution of the order statistics [see e.g. Arnold et al., 2008] we see that the beta (k, n \u2212 k + 1), i.e. a beta random variable, can be recalculated between 0 and (n + 1) / \u03bb. If fk, n (x) are the probability density of the model, we have for each rigid k and k, fk, n (x).xk \u2212 1 - and essentially a uniform \u2212 k and k distribution."}, {"heading": "4 Experimental Results", "text": "In practice, the comparison budget for estimating a ranking from noisy data might typically be larger than that for a single call of Quicksort, and it might not exactly match the number of comparisons required to perform a certain number of calls to Quicksort to completion. Building on the observations made at the end of Section 3.1, we suggest the following practical active learning strategy: If you have a budget of c-pair comparisons, repeat the sorting process until the budget is exhausted (the last call may need to be shortened), then keep only the set of c comparison pairs and their results, and discard the rankings generated by the sorting process. The final ranking is then derived from the ML estimate of the set of c comparisons. In this section, we demonstrate the effectiveness of this sampling strategy on synthetic and real data. Specifically, we show that it is comparable with existing AL strategies at a fraction of the calculable cost."}, {"heading": "4.1 Competing Sampling Strategies", "text": "To assess the relative advantages of our sorting strategy, we consider three strategies that we believe are representative of the state of the art in active preference learning. Uncertainty Sample. Developed in the context of classification tasks, this popular heuristics of active learning suggests greedily trying the point closest to the decision boundary [Settles, 2012]. In the context of a ranking task, this corresponds to the sample of the item whose relative order is most uncertain. After t observations, when estimating the model parameters \u03b8t, the strategy selects the (t + 1) -st pair uniformly randomly selected items (min i = j | \u03b8ti \u2212 \u03b8tj |.This sentence can be calculated in time O (n log n) by sorting the parameters. The parameters themselves must be estimated, e.g. using (punished) ML conclusions that can be cost-dominating methods in practice."}, {"heading": "4.2 Running Time", "text": "s approximate inference algorithms for the BT model as a Python library5. For5See: http: / / lucas.maystre.ch / choix.ML inference, we note that the fastest runtime is achieved by a truncated Newton algorithm (even for large n). For approximate Bayesian inference, we use a variant of the expectation and propagation algorithm outlined by Chu and Ghahramani. All experiments are performed on a server with a 12-core Xeon X5670 processor running at 2.93 GHz. Numerical calculations use the Intel math kernel library. We illustrate the runtime of AL strategies as follows. For n \u00b2 n {102, 103, 104} we generate results for n comparisons strategies that are randomly selected."}, {"heading": "4.3 Empirical Evaluation", "text": "In fact, most of us are able to surpass ourselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think we will be able to surpass ourselves. \"In other words:\" I don't think we will be able to change the world. \"In other words:\" I don't think we will be able to change the world. \"In other words:\" I don't think we will be able to change the world. \"In other words:\" I don't think we will be able to change the world. \"In other words:\" I don't think we will be able to change the world. \""}, {"heading": "5 Conclusion", "text": "In this paper, we show that active learning can significantly accelerate the task of learning a ranking from loud comparisons, both in theory and in practice. With the advent of large-scale crowdsourcing ranking surveys, as illustrated by the example of GIFGIF and Wiki surveys [Salganik and Levy, 2015], there is a clear need for practical AL strategies. However, existing methods are complex and arithmetically costly to operate even for a reasonable number of items (a few thousand). We show that a deceptively simple idea - the repeated sorting of items - is able to reap all the benefits of active learning, is trivial to implement, and is computationally no more expensive than random sampling. Therefore, we believe that our method can be useful for machine learners interested in ranking problems on the whole. We thank Holly Cogliati-Bauereis, Ksenyelli Konsenyushkova, Korkturkova, and Brunkturkova for providing helpful and anonymous corrections."}, {"heading": "A Proofs", "text": "\"We have a game on n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n"}, {"heading": "B Discriminating the Closest Items", "text": "The distance between the two closest items is dmin = mini | \u03b8i + i \u2212 \u03b8i | = mini xi, i.e. the minimum of n \u2212 1 independent exponential random variables of the rate \u03bb. Let us therefore assume that we compare the two closest items m times and let zi be the random variable for the event \"the result of the i-th comparison is wrong.\" Suppose that dmin \u2264 (\u03bbn) \u2212 1 and \u03bbn \u2265 1 / 2, P [zi = 0] \u2264 1 1 + exp [\u2212 1 / (\u03bbn) \u2264 1 2 \u2212 1 / (\u03bbn) = 1 2 \u2212 1 / (\u03bbn) = 2 \u00b7 (1 + 1 2\u03bbn \u2212 1) \u2264 1 \u2212 2 \u2212 2 \u2212 2 \u2212 3 using the inequality ex-1 +.x."}, {"heading": "C Additional Figures", "text": "In this section, we present a few additional illustrations that supplement the illustrations shown in section 4 of the main text. Figure 5 shows the results of the GIFGIF dataset, including a variant of the uncertainty sample. This variant shows n \u2212 1 comparisons of adjacent pairs in the \u03b8 ranking for each iteration. This strategy performs surprisingly poor.Figure 6 shows results on synthetic datasets with n = 200 and f = 1, 2, 5, 10}. For convenience, we plot each graph on both a linear and a logarithmic scale. Unsurprisingly, the benefits of adaptive sampling are greater when the noise is lower."}], "references": [{"title": "Reconciling Real Scores with Binary Comparisons: A Unified Logistic Model for Ranking", "author": ["N. Ailon"], "venue": "In Advances in Neural Information Processing Systems 21,", "citeRegEx": "Ailon.,? \\Q2008\\E", "shortCiteRegEx": "Ailon.", "year": 2008}, {"title": "An Active Learning Algorithm for Ranking from Pairwise Preferences with an Almost Optimal Query Complexity", "author": ["N. Ailon"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Ailon.,? \\Q2012\\E", "shortCiteRegEx": "Ailon.", "year": 2012}, {"title": "Preference-based learning to rank", "author": ["N. Ailon", "M. Mohri"], "venue": "Machine Learning,", "citeRegEx": "Ailon and Mohri.,? \\Q2010\\E", "shortCiteRegEx": "Ailon and Mohri.", "year": 2010}, {"title": "Aggregating Inconsistent Information: Ranking and Clustering", "author": ["N. Ailon", "M. Charikar", "A. Newman"], "venue": "Journal of the ACM,", "citeRegEx": "Ailon et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ailon et al\\.", "year": 2008}, {"title": "Linear Extensions of a Random Partial Order", "author": ["N. Alon", "B. Bollob\u00e1s", "G. Brightwell", "S. Janson"], "venue": "The Annals of Applied Probability,", "citeRegEx": "Alon et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Alon et al\\.", "year": 1994}, {"title": "Rank Analysis of Incomplete Block Designs: I", "author": ["R.A. Bradley", "M.E. Terry"], "venue": "The Method of Paired Comparisons. Biometrika,", "citeRegEx": "Bradley and Terry.,? \\Q1952\\E", "shortCiteRegEx": "Bradley and Terry.", "year": 1952}, {"title": "Noisy sorting without resampling", "author": ["M. Braverman", "E. Mossel"], "venue": "In Proceedings of SODA\u201908,", "citeRegEx": "Braverman and Mossel.,? \\Q2008\\E", "shortCiteRegEx": "Braverman and Mossel.", "year": 2008}, {"title": "Pairwise Ranking Aggregation in a Crowdsourced Setting", "author": ["X. Chen", "P.N. Bennett", "K. Collins-Thompson", "E. Horvitz"], "venue": "In Proceedings of WSDM\u201913,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Extensions of Gaussian Processes for Ranking: Semisupervised and Active Learning", "author": ["W. Chu", "Z. Ghahramani"], "venue": "In Proceedings of the NIPS 2005 Workshop on Learning", "citeRegEx": "Chu and Ghahramani.,? \\Q2005\\E", "shortCiteRegEx": "Chu and Ghahramani.", "year": 2005}, {"title": "A \u2018reasonable\u2019 social welfare function", "author": ["A.H. Copeland"], "venue": null, "citeRegEx": "Copeland.,? \\Q1951\\E", "shortCiteRegEx": "Copeland.", "year": 1951}, {"title": "Spearman\u2019s Footrule as a Measure of Disarray", "author": ["P. Diaconis", "R.L. Graham"], "venue": "Journal of the Royal Statistical Society, Series B,", "citeRegEx": "Diaconis and Graham.,? \\Q1977\\E", "shortCiteRegEx": "Diaconis and Graham.", "year": 1977}, {"title": "Concentration of Measure for the Analysis of Randomized Algorithms", "author": ["D.P. Dubhashi", "A. Panconesi"], "venue": null, "citeRegEx": "Dubhashi and Panconesi.,? \\Q2009\\E", "shortCiteRegEx": "Dubhashi and Panconesi.", "year": 2009}, {"title": "The Rating Of Chess Players", "author": ["A. Elo"], "venue": "Past & Present. Arco,", "citeRegEx": "Elo.,? \\Q1978\\E", "shortCiteRegEx": "Elo.", "year": 1978}, {"title": "Minimax-optimal Inference from Partial Rankings", "author": ["B. Hajek", "S. Oh", "J. Xu"], "venue": "In Advances in Neural Information Processing Systems 27,", "citeRegEx": "Hajek et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hajek et al\\.", "year": 2014}, {"title": "Active Ranking from Pairwise Comparisons and when Parametric Assumptions Don\u2019t Help", "author": ["R. Heckel", "N.B. Shah", "K. Ramchandran", "M.J. Wainwright"], "venue": null, "citeRegEx": "Heckel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Heckel et al\\.", "year": 2016}, {"title": "Hern\u00e1ndez-lobato. Collaborative Gaussian Processes for Preference Learning", "author": ["N. Houlsby", "F. Husz\u00e1r", "Z. Ghahramani", "J. M"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Houlsby et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Houlsby et al\\.", "year": 2012}, {"title": "Active Ranking using Pairwise Comparisons", "author": ["K. Jamieson", "R. Nowak"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Jamieson and Nowak.,? \\Q2011\\E", "shortCiteRegEx": "Jamieson and Nowak.", "year": 2011}, {"title": "Efficient Clustering for Orders", "author": ["T. Kamishima", "S. Akaho"], "venue": "In Mining Complex Data,", "citeRegEx": "Kamishima and Akaho.,? \\Q2009\\E", "shortCiteRegEx": "Kamishima and Akaho.", "year": 2009}, {"title": "The art of computer programming: sorting and searching, volume 3. AddisonWesley", "author": ["D.E. Knuth"], "venue": "2nd edition,", "citeRegEx": "Knuth.,? \\Q1998\\E", "shortCiteRegEx": "Knuth.", "year": 1998}, {"title": "On Dominance Relations and the Structure of Animal Societies: III The Condition for a Score Structure", "author": ["H.G. Landau"], "venue": "Bulletin of Mathematical Biophysics,", "citeRegEx": "Landau.,? \\Q1953\\E", "shortCiteRegEx": "Landau.", "year": 1953}, {"title": "Bayesian Methods for Adaptive Models", "author": ["D.J.C. MacKay"], "venue": "PhD thesis, California Institute of Technology,", "citeRegEx": "MacKay.,? \\Q1992\\E", "shortCiteRegEx": "MacKay.", "year": 1992}, {"title": "Iterative Ranking from Pair-wise Comparisons", "author": ["S. Negahban", "S. Oh", "D. Shah"], "venue": "In Advances in Neural Information Processing Systems 25,", "citeRegEx": "Negahban et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Negahban et al\\.", "year": 2012}, {"title": "A Statistical Convergence Perspective of Algorithms for Rank Aggregation from Pairwise Data", "author": ["A. Rajkumar", "S. Agarwal"], "venue": "In Proceedings of ICML 2014, Beijing,", "citeRegEx": "Rajkumar and Agarwal.,? \\Q2014\\E", "shortCiteRegEx": "Rajkumar and Agarwal.", "year": 2014}, {"title": "Wiki Surveys: Open and Quantifiable Social Data Collection", "author": ["M.J. Salganik", "K.E.C. Levy"], "venue": "PLOS ONE,", "citeRegEx": "Salganik and Levy.,? \\Q2015\\E", "shortCiteRegEx": "Salganik and Levy.", "year": 2015}, {"title": "Collaborative Learning of Preference Rankings", "author": ["T. Salimans", "U. Paquet", "T. Graepel"], "venue": "In Proceedings of RecSys\u201912,", "citeRegEx": "Salimans et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2012}, {"title": "Active learning for logistic regression: an evaluation", "author": ["A.I. Schein", "L.H. Ungar"], "venue": "Machine Learning,", "citeRegEx": "Schein and Ungar.,? \\Q2007\\E", "shortCiteRegEx": "Schein and Ungar.", "year": 2007}, {"title": "Online Rank Elicitation for Plackett\u2013Luce: A Dueling Bandits Approach", "author": ["B. Sz\u00f6r\u00e9nyi", "R. Busa-Fekete", "A. Paul", "E. H\u00fcllermeier"], "venue": "In Advances in Neural Information Processing Systems 28,", "citeRegEx": "Sz\u00f6r\u00e9nyi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sz\u00f6r\u00e9nyi et al\\.", "year": 2015}, {"title": "A Law of Comparative Judgment", "author": ["L. Thurstone"], "venue": "Psychological Review,", "citeRegEx": "Thurstone.,? \\Q1927\\E", "shortCiteRegEx": "Thurstone.", "year": 1927}, {"title": "Parameter Estimation for Generalized Thurstone Choice Models", "author": ["M. Vojnovic", "S. Yun"], "venue": "In Proceedings of ICML 2016,", "citeRegEx": "Vojnovic and Yun.,? \\Q2016\\E", "shortCiteRegEx": "Vojnovic and Yun.", "year": 2016}, {"title": "Active Collaborative Permutation Learning", "author": ["J. Wang", "N. Srebro", "J. Evans"], "venue": "In Proceedings of KDD\u201914,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "The k-armed dueling bandits problem", "author": ["Y. Yue", "J. Broder", "R. Kleinberg", "T. Joachims"], "venue": "In Proceedings of COLT", "citeRegEx": "Yue et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Yue et al\\.", "year": 2009}, {"title": "Die Berechnung der Turnier-Ergebnisse als ein Maximumproblem der Wahrscheinlichkeitsrechnung", "author": ["E. Zermelo"], "venue": "Mathematische Zeitschrift,", "citeRegEx": "Zermelo.,? \\Q1928\\E", "shortCiteRegEx": "Zermelo.", "year": 1928}], "referenceMentions": [{"referenceID": 12, "context": "The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports [Elo, 1978], social sciences [Thurstone, 1927, Salganik and Levy, 2015] and\u2014more recently\u2014recommender systems [Houlsby et al.", "startOffset": 186, "endOffset": 197}, {"referenceID": 15, "context": "The problem of recovering a ranking over n items from noisy outcomes of pairwise comparisons has attracted, in the last century, much research interest, driven by applications in sports [Elo, 1978], social sciences [Thurstone, 1927, Salganik and Levy, 2015] and\u2014more recently\u2014recommender systems [Houlsby et al., 2012].", "startOffset": 296, "endOffset": 318}, {"referenceID": 4, "context": "If pairs of items are selected at random, it is necessary to collect \u03a9(n) comparisons to recover the ranking [Alon et al., 1994].", "startOffset": 109, "endOffset": 128}, {"referenceID": 25, "context": "However, most strategies are challenging to operate and computationally expensive, thus hindering wider adoption [Schein and Ungar, 2007].", "startOffset": 113, "endOffset": 137}, {"referenceID": 4, "context": "Braverman and Mossel [2008] examine a model where outcomes of pairwise comparisons are flipped with a small, constant probability.", "startOffset": 0, "endOffset": 28}, {"referenceID": 0, "context": "Ailon [2012] considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST).", "startOffset": 0, "endOffset": 13}, {"referenceID": 0, "context": "Ailon [2012] considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST). These theoretical studies imply, in their respective settings, that O(n log n) comparison outcomes are enough to recover a near-optimal ranking. Jamieson and Nowak [2011] propose an efficient active-ranking algorithm that is applicable if items can be embedded in R (e.", "startOffset": 0, "endOffset": 439}, {"referenceID": 0, "context": "Ailon [2012] considers an adversarial setting (comparison outcomes can be arbitrary) and investigates AL in the context of finding a ranking that minimizes the number of inconsistent outcomes, also known as the minimum feedback-arc set problem on tournaments (MFAST). These theoretical studies imply, in their respective settings, that O(n log n) comparison outcomes are enough to recover a near-optimal ranking. Jamieson and Nowak [2011] propose an efficient active-ranking algorithm that is applicable if items can be embedded in R (e.g., using d features) and assuming that admissible rankings satisfy some geometric constraints. Wang et al. [2014] study a collaborative preference-learning problem and show that a variant of uncertainty sampling (a well-known AL strategy) works well for their problem.", "startOffset": 0, "endOffset": 652}, {"referenceID": 20, "context": "From a practical standpoint, Bayesian methods provide an effective way to select informative samples [MacKay, 1992].", "startOffset": 101, "endOffset": 115}, {"referenceID": 10, "context": "Work on Bayesian active preference learning includes Chu 2\u2206(\u03c3)/2 \u2264 K(\u03c3) \u2264 \u2206(\u03c3) [Diaconis and Graham, 1977].", "startOffset": 79, "endOffset": 106}, {"referenceID": 14, "context": "and Ghahramani [2005], Houlsby et al. [2012], Salimans et al.", "startOffset": 23, "endOffset": 45}, {"referenceID": 14, "context": "and Ghahramani [2005], Houlsby et al. [2012], Salimans et al. [2012] and Chen et al.", "startOffset": 23, "endOffset": 69}, {"referenceID": 7, "context": "[2012] and Chen et al. [2013]. We compare our AL strategy to these methods in Section 4.", "startOffset": 11, "endOffset": 30}, {"referenceID": 30, "context": "The dueling bandit problem [Yue et al., 2009] is somewhat related to our work.", "startOffset": 27, "endOffset": 45}, {"referenceID": 25, "context": "The work of Sz\u00f6r\u00e9nyi et al. [2015] is the closest to ours, as it also uses the BT model.", "startOffset": 12, "endOffset": 35}, {"referenceID": 14, "context": "Heckel et al. [2016] investigate a non-parametric model and develop some theoretical guarantees.", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "Quicksort combined with BT comparison outcomes has also been proposed as a probabilistic ranking model [Ailon, 2008].", "startOffset": 103, "endOffset": 116}, {"referenceID": 0, "context": "For example, Ailon et al. [2008] show that Quicksort produces (in expectation) a 3-approximation to the MFAST problem.", "startOffset": 13, "endOffset": 33}, {"referenceID": 0, "context": "Lemma 2 complements Theorem 3 in Ailon and Mohri [2010], which states that Quicksort samples O(n log n) in expectation.", "startOffset": 33, "endOffset": 56}, {"referenceID": 9, "context": "The method assigns, to each item, a score that corresponds to the number of items that it beats in a majority of the rankings, and it then ranks the items by increasing score [Copeland, 1951].", "startOffset": 175, "endOffset": 191}, {"referenceID": 0, "context": "In order to prove (3), we take advantage of a theorem due to Ailon [2008] which states that P [\u03c3(i) < \u03c3(j) | \u03b8] = p(i \u227a j | \u03b8), even if i and j were not directly compared with each other.", "startOffset": 61, "endOffset": 74}, {"referenceID": 0, "context": "In order to prove (3), we take advantage of a theorem due to Ailon [2008] which states that P [\u03c3(i) < \u03c3(j) | \u03b8] = p(i \u227a j | \u03b8), even if i and j were not directly compared with each other. We use a Chernoff bound on dij to show that the relative order between any two items separated by at least O(\u03bb log n) positions is correct with high probability. The second part of the claim follows easily. Note that any method that compares each pair of items at most once results in a ranking estimate \u03c4 with displacement \u2206(\u03c4) = \u03a9(n) with high probability: As there is only a single (possibly inconsistent) comparison outcome between each pair of adjacent items, it is likely that a constant fraction of the items will be ranked incorrectly, resulting in a displacement that grows linearly in n. Hence, our bound on \u2206(\u03c3) shows that Quicksort is order-optimal (in n). In light of Theorem 1, a natural question to ask is as follows. How many comparisons are needed in order to find the correct ranking? Clearly, finding the exact ranking is difficult: in fact, \u03a9(n) comparison outcomes are necessary to discriminate the closest pair of items reliably (see Appendix B). As such, we will focus on finding a ranking that matches the ground truth everywhere, except at a vanishing fraction of the items. Multiple runs of Quicksort likely produce different outputs, because of the noisy comparison outcomes and because the algorithm itself is randomized (the pivot selection is random). By aggregating m independent outputs of Quicksort, is it possible to produce a better ranking estimate? Similarly to Sz\u00f6r\u00e9nyi et al. [2015], we combine the m outputs \u03c31, .", "startOffset": 61, "endOffset": 1610}, {"referenceID": 20, "context": "A principled approach to AL consists of sampling the point that maximizes the expected information gain [MacKay, 1992].", "startOffset": 104, "endOffset": 118}, {"referenceID": 7, "context": "A conceptually similar but slightly different selection strategy is given by Chen et al. [2013]. Letting qij be the marginal distribution of (\u03b8i, \u03b8j), the pair is selected in", "startOffset": 77, "endOffset": 96}, {"referenceID": 18, "context": "In the noiseless setting, Mergesort is known to use on average \u2248 39 % fewer comparisons than Quicksort per run [Knuth, 1998], but it does not benefit from the theoretical guarantees developed in Section 3.", "startOffset": 111, "endOffset": 124}, {"referenceID": 8, "context": "For approximate Bayesian inference, we use a variant of the expectation-propagation algorithm outlined by Chu and Ghahramani [2005]. All experiments are performed on a server with a 12-core Xeon X5670 processor running at 2.", "startOffset": 106, "endOffset": 132}, {"referenceID": 17, "context": "Next, we consider a dataset of Sushi preferences [Kamishima and Akaho, 2009].", "startOffset": 49, "endOffset": 76}, {"referenceID": 23, "context": "With the advent of large-scale crowdsourced ranking surveys, exemplified by GIFGIF and wiki surveys [Salganik and Levy, 2015], there is a clear need for practical AL strategies.", "startOffset": 100, "endOffset": 125}, {"referenceID": 19, "context": "The following proposition is due to Landau [1953].", "startOffset": 36, "endOffset": 50}, {"referenceID": 0, "context": "For the second part, we need a result from Ailon [2008], which characterizes the pairwise marginals of the distribution over rankings induced by Quicksort with comparisons sampled from a BT model.", "startOffset": 43, "endOffset": 56}], "year": 2017, "abstractText": "We address the problem of learning a ranking by using adaptively chosen pairwise comparisons. Our goal is to recover the ranking accurately but to sample the comparisons sparingly. If all comparison outcomes are consistent with the ranking, the optimal solution is to use an efficient sorting algorithm, such as Quicksort. But how do sorting algorithms behave if some comparison outcomes are inconsistent with the ranking? We give favorable guarantees for Quicksort for the popular Bradley\u2013Terry model, under natural assumptions on the parameters. Furthermore, we empirically demonstrate that sorting algorithms lead to a very simple and effective active learning strategy: repeatedly sort the items. This strategy performs as well as state-of-the-art methods (and much better than random sampling) at a minuscule fraction of the computational cost.", "creator": "LaTeX with hyperref package"}}}