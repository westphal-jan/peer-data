{"id": "1502.06464", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2015", "title": "Rectified Factor Networks", "abstract": "We propose rectified factor networks (RFNs) as generative unsupervised models, which learn robust, very sparse, and non-linear codes with many code units. RFN learning is a variational expectation maximization (EM) algorithm with unknown prior which includes (i) rectified posterior means, (ii) normalized signals of hidden units, and (iii) dropout. Like factor analysis, RFNs explain the data variance by their parameters. For pretraining of deep networks on MNIST, rectangle data, convex shapes, NORB, and CIFAR, RFNs were superior to restricted Boltzmann machines (RBMs) and denoising autoencoders. On CIFAR-10 and CIFAR-100, RFN pretraining always improved the results of deep networks for different architectures like AlexNet, deep supervised net (DSN), and a simple \"Network In Network\" architecture. With RFNs success is guaranteed.", "histories": [["v1", "Mon, 23 Feb 2015 15:44:37 GMT  (1237kb,D)", "https://arxiv.org/abs/1502.06464v1", "10 pages + 30 pages supplement"], ["v2", "Thu, 11 Jun 2015 21:27:53 GMT  (3345kb,D)", "http://arxiv.org/abs/1502.06464v2", "9 pages + 49 pages supplement"]], "COMMENTS": "10 pages + 30 pages supplement", "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE stat.ML", "authors": ["djork-arn\u00e9 clevert", "andreas mayr", "thomas unterthiner", "sepp hochreiter"], "accepted": true, "id": "1502.06464"}, "pdf": {"name": "1502.06464.pdf", "metadata": {"source": "CRF", "title": "Rectified Factor Networks", "authors": ["Djork-Arn\u00e9 Clevert", "Andreas Mayr", "Thomas Unterthiner"], "emails": ["okko@bioinf.jku.at", "mayr@bioinf.jku.at", "unterthiner@bioinf.jku.at", "hochreit@bioinf.jku.at"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to survive themselves are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times \":\" I don't think they are able to survive themselves, and that they are able to survive themselves. \""}, {"heading": "2 Rectified Factor Network", "text": "The objective is to construct representations of input factors that (1) are sparse, (2) are not negative, (3) are not linear, (4) are not linear, (3) are not linear, (4), (4), (4), (4), (4), (4), (4), (4), (4), (4), (4), (5), (4), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5, \"(5), (5),\" (5, \"(5),\" (5), \"(5,\" (5), \"(5),\" (5, \"(5),\" (5), \"(5,\" (5), \"(5),\" (5, \"(5),\" (5), \"(5,\" (5), \"(5),\" (5, \"(5),\" (5), \"(5,\" (5), \"(5),\" (5, \"(5),\" (5, \"(5),\" (5), \"(5,\" (5, \"(5), (5,\" (5), \"(5), (5, (5), (5, (5), (5), (5, (5), (5), (5, (5), (5), (5), (5, (5), (5), (5, (5), (5), (5), (5, (5), (5),"}, {"heading": "3 Convergence and Correctness of RFN Learning", "text": "The question that arises is whether this is an error given in detail in the supplement. For convergence, we show that Alg. 1 is a GAM algorithm that converges according to Proposition 5 in [21].Alg. 1 ensures that the M-step objective, which is convex in W-1, is diminished. Updating to 1 leads to the minimum of the objective. Convergence of objective guarantees of a reduction in M-step for 0 < 1 if not in a minimum."}, {"heading": "4 Experiments", "text": "In fact, it is so that most people are able to survive themselves, and that they are able to survive themselves, \"he told the\" World on Sunday \":\" I do not believe that they will be able to save the world. \"(S. S. S. S. S. S. S. S. S.)\" I do not believe that they are able to save the world. \"(S. S. S. S. S. S. S. S. S.)\" (S. S. S. S. S. S. S. S.) \"(S. S. S. S. S. S. S. S. S.)\" I do not believe that the world is in order. \"(S. S. S. S. S. S. S. S. S. S.\" (S. S.) \"(S. S. S.).\" (S. S. S.). \"(S.\" (S. S.). \"(S.). (S.\" (S.). \"(S.). (S.\" (S.). (S.). (S. S.). (S.). (S.). (S. \"(S.). (S.). (S.\" (S.). (S.). (S. \"(S.).\" (S.). (S.). (S.). (S.). (S. \"(S.). (S.). (S.). (S.\" (S.). \"(S.). (S.). (S.\" (S.). \"(S.). (S.\" (S.). \"(S.).\" (S. \"(S.).\" (S.). \"(S.\" (S.). \"(S.\" (S.). \"(S.).\" (S. \"(S.).\" (S. \"(S.).\" (S. \"(S.\" (S.). \"(S.).\" (S. \"(S.\" (S.). \"(S.).\" (S. \"(S.\" (S.). \"(S.\" (S.). \"(S.\" (S.). \"(S.). (S.\" (S.). (S. \"(S.). (S.\" (S. \"(S.). (S.). (S.\" (S.). (S.). (S. \"(S.). (S.\" (S.). (S.). (S.). (S. \"(S.). (S.\" (S.). (S.). (S. \"(S.). (S.). (S."}, {"heading": "5 Conclusion", "text": "The RFN learning algorithm is a posterior regulation method that enforces non-negative and normalized posterior means. We have shown that RFN learning is a generalized method of alternating minimization that has been proven to be convergent and correct. RFNs had the least code, the least reconstruction error, and the least covariance approximation error of all methods that produced sparse representations (SP > 10%). RFNs have shown that they improve performance when used for deep network pretraining. In two pharmaceutical drug discovery studies, RFNs were discovered as small and rare gene modules previously overlooked by other uncontrolled methods. These gene modules were highly relevant and supported decision-making in these deep networks."}, {"heading": "Supplementary Material", "text": "S1 Introduction 5"}, {"heading": "S2 Rectified Factor Network (RFN) Algorithms 5", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S3 Convergence Proof for the RFN Learning Algorithm 9", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S4 Correctness Proofs for the RFN Learning Algorithms 11", "text": "S4.1 Diagonal Noise Covariance Update............................ 12S4.2 Full Noise Covariance Update.............................."}, {"heading": "S5 Maximum Likelihood Factor Analysis 15", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S6 The RFN Objective 18", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S7 Generalized Alternating Minimization 20", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S8 Gradient-based M-step 22", "text": "........................................................................................................................"}, {"heading": "S9 Gradient-based E-Step 26", "text": "S9.1. motivation to correct and normalize constraints....... 27S9.3. E-step for Mean..... Complete E-step constraints.................... 28S9.3.1. E-step minimization problem......... 27S9.3. E-step for Mean......... 28S9.3.2 The projection onto the feasible...................... 29S9.4 E-step for Mean...... Rectifying and normalizing. Constraints. 28S9.3.2."}, {"heading": "S10 Alternative Gaussian Prior 36", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S11 Hyperparameters Selected for Method Assessment 38", "text": "S12 Record I 39"}, {"heading": "S13 Data Set II 43", "text": "S14 RFN Pretraining for Folding Networks 47"}, {"heading": "List of Theorems", "text": "Theorem (Euclidean). Projection). Recorem. 147. Gorem. 246. Convergence. 43. Theorem. 42. Theorem. RFN. 42. Theorem. 43. Theorem. 43. Theorem. 44. Theorem. 44. Theorem. 44. Theorem. 46. Theorem. 46. Theorem. 46. Theorem. 46. Theorem. 46. Theorem. 46. Theorem. 46. Theorem. 46. Theorem. 46. Theorem. 49. Theorem. 49. Theorem. 49. Noise. 49. Noise. 49. Noise. Covariance.). 55. Theorem. Update. Update. 59. Update. 44. Noise. Covariance."}, {"heading": "List of Algorithms", "text": "The first steps in this direction are the complete (complete) analysis. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental) Section. (Supplemental). (Supplemental) Section. (Supplemental). (Supplemental) Section. (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (Supplemental). (..... (..... (..... (..... (..... (...... (..... (.....). (....... (..... (........ (.....). (..... (......... (......... (.....).. (......). (......... (.....). (........ (.....). (..... (..... (........).... (.....).... (............................. (..... (......"}, {"heading": "S2 Rectified Factor Network (RFN) Algorithms", "text": "The RFN algorithm calls algorithm S3 to project the posterior probability pi onto the family of rectified and normalized variational distributions Qi. However, the algorithm S3 guarantees an improvement of the E-step lens O = 1 n \u00b2 n = 1DKL. If all the following Newton-based gradient projection methods fail to reduce the E-step lens, then the projection algorithm S3 reverts to different projection methods. First, the equality constraints are solved and inserted into the target. Then, the contracts are applied to convex and gradient projection methods, an approach known as the \"reduced gradient method\" [17], which is our alternative method preferred."}, {"heading": "Input", "text": "for 1 \u2264 i \u2264 n: vi \u0445 Rm, number of encoding units l hyper parameters \u0432 min, Wmax, \u03b7W, \u03c1, \u03c4, 1 < \u03b7 \u2264 1 initialization \u0432 = \u03c4I, W randomly in [\u2212 \u03c1, \u03c1], C = 1n \u0445 n k = 1 vk v T k, STOP = false Main during STOP = false do - - - E-step 1 - for all 1 \u2264 i \u2264 n do (\u00b5p) i = (I + W TVP \u2212 1W) \u2212 1 W TVP \u2212 1 viend for \u03a3 = (I + W TVP \u2212 1W) \u2212 1 - - - Projecting of (\u00b5p) i to the feasibility specified by algorithm S3 - - E-step 2 - - - U = 1n TA \u2212 n TA \u2212 n i = 1 vi \u00b5 T iS = 1n \u00b2 i = 1n \u00b2 i = 1 \u00b5i \u00b5 - trup - -step - - - STP = -point = E-step 2 - - - Update U = 1 TA \u2212 c = 1 \u2212 K \u2212 \u2212 K = full W \u2212 \u2212 \u2212 K = 1 K \u2212 K \u2212 \u2212 K = 1 \u00b5 = full W \u2212 K \u2212 K \u2212 K \u2212 K \u2212 \u2212 \u2212 \u2212 K \u2212 \u2212 K \u2212 - - - Update - - 1 K \u2212 K \u2212 K \u2212 K \u2212 \u2212 K \u2212 \u2212 \u2212 \u2212 \u2212 K \u2212 \u2212 K \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 K \u2212 K \u2212 1 \u00b5i \u00b5 T = full W \u2212 W \u2212 K \u2212 K \u2212 K \u2212 K \u2212 1 \u2264 i = full W \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 - - - - - - - - - K \u2212 K \u2212 K \u2212 K = full \u2212 K \u2212 K \u2212 K"}, {"heading": "Goal", "text": "Obtaining 0.0newi = 0.0g, which reduce the E-step target, input: 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b = 0.0b b = 0.0b = 0.0b b = 0.0b = 0.0b = 0.0b = 0.0b b = 0.0b = 0.0b = 0.0b = 0.0b b = 0.0b = 0.0b b = 0.0b b = 0.0b = 0.0b = 0.0b b b b = 0.0b b b b b = 0.0b = 0.0b b = 0.0b = 0.0b b b b b b b = 0.0b b = 0.0b b b b b = 0.0b = 0.0b b b b = 0.0b b b b b b = 0.0b"}, {"heading": "Goal", "text": "for 1 \u2264 i \u2264 n: Project (\u00b5p) i to a realizable amount containing the \u00b5i input (\u00b5p) i Mainly for all 1 \u2264 j \u2264 l do \u00b5ij = max {0, [(\u00b5p) i] j} End for algorithm S5 Simple projection: rectification and normalization"}, {"heading": "Goal", "text": "for 1 \u2264 i \u2264 n: project (\u00b5p) i on practicable set giving \u00b5i Input for 1 \u2264 i \u2264 n: (\u00b5p) i Rectifier for all 1 \u2264 i \u2264 n dofor all 1 \u2264 j \u2264 l do \u00b5 \u0432ij = max {0, [(\u00b5p) i] j} end forend for Normalizer for all 1 \u2264 i \u2264 n do if at least one p = ij > 0 thenfor all 1 \u2264 j \u2264 l do \u00b5ij = \u00b5 ij \u221a 1 n = 1 \u00b5 \u00b2 2 sjend for elsefor all 1 \u2264 j \u2264 l do\u00b5ij = {\u221a n for j = arg maxj, 0 otherwise forend for Algorithm S6 Scaled Newton Projection"}, {"heading": "Goal", "text": "Performing a scaled Newton step with subsequent projection Input for 1 \u2264 i \u2264 n: (\u00b5p) i for 1 \u2264 i \u2264 n: \u00b5oldi simple projection P (rectified or corrected & normalized), \u03bb (gradient step variable), \u03b3 (projection difference) Main d = P (\u00b5oldi + \u03bb (((\u00b5p) i \u2212 \u00b5oldi))) \u00b5newi = P (\u00b5oldi + \u03b3 (d \u2212 \u00b5oldi)) algorithm S7 Scaled projection with reduced matrix"}, {"heading": "Goal", "text": "perform a scaled projection step with reduced matrix input for 1 \u2264 i \u2264 n: (\u00b5p) i for 1 \u2264 i \u2264 n: \u00b5oldi simple projection P (rectified or rectified & normalized), \u03bb, \u03b3, H, \u03a3 \u2212 1p Main d = P (\u00b5oldi + \u03bbH \u2212 1 \u03a3 \u2212 1p (((\u00b5p) i \u2212 \u00b5oldi))) \u00b5newi = P (\u00b5oldi + \u03b3 (d \u2212 \u00b5oldi)) algorithm S8 Weight Decay"}, {"heading": "Input", "text": "ParameterW Decay Factors \u03b3G (Gauss) and \u03b3L (Lapland) Gauss W = W \u2212 \u03b3GW Lapland W = Median {\u2212 \u03b3L, W, \u03b3L} W = W \u2212 W \u00b2 Algorithm S9 Failure step"}, {"heading": "Input", "text": "for 1 \u2264 i \u2264 n: \u00b5i failure probability d main thing for all 1 \u2264 i \u2264 n dofor all 1 \u2264 j \u2264 l do Pr (\u03b4 = 0) = d \u00b5ij = \u03b4 \u00b5ijend for end for"}, {"heading": "S3 Convergence Proof for the RFN Learning Algorithm", "text": "The factor analysis of the EM algorithm is modified by Eq. (81) and Eq. (82) in Section S5. M-step is the factor analysis EM algorithm with modified E-step and the M-step. E-step is modified by limiting the variable distribution Q to non-negative means and standardizing its averages across the samples. M-step is modified to a Newton direction gradient step."}, {"heading": "S4 Correctness Proofs for the RFN Learning Algorithms", "text": "The RFN algorithm is correct if it has a small reconstruction error, and explains the covariance matrix of the data by its parameters such as factor analysis. We show in Theorem 5 and Theorem 6 that the RFN algorithm 1. minimizes the reconstruction error due to \u00b5i and \u03a3 (the error is square in \u044b); 2. explains the covariance matrix due to its parameters W and VP plus an estimate of the second moment of the coding units S. Since the minimization of the reconstruction error is based on \u00b5i, the quality of the reconstruction and covariance explanation depends on the correlation between \u00b5i and vi. The greater the correlation between \u00b5i and vi, the lower the reconstruction error and the better the explanation of the data covariance. We ensure maximum information in \u00b5i to vi by the I projection (the minimum KullbackLeibler distance) of the subordinate and normalized Gaussian distributions."}, {"heading": "S4.1 Diagonal Noise Covariance Update", "text": "Theorem 5 (RFN Correctness: Diagonal Noise Covariance Update = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1). (W = 1)."}, {"heading": "S4.2 Full Noise Covariance Update", "text": "Theorem 6 (RFN Correctness: Complete Noise Covariance Update) The fixed point W minimizes the Tr (1) caused by burr regression with Tr (1) = 1n n n (1) n (1) n (1) n (1) n (2) F, (41) using the error = vi \u2212 W (42).The model explains the data covariance matrix with C = 1) + W S W T. (43) The reconstruction error error1n n n (1) n (1) n (1) i (44) is square in (1).The first part results from the previous theorem 5. The fixed point equation for the update results in C \u2212 U W T \u2212 W T \u2212 W T (45) using Eq. (38) leading to C = 1 (38)."}, {"heading": "S5 Maximum Likelihood Factor Analysis", "text": "We get the data {v} = {v1,., vn}, which is assumed to be centered. (51) The model can be done by subtracting the mean p from the data. (51) The model includes the observations v + Rm, the factors h \u2212 Rl, the factor charge matrix W + Rm \u00b7 l, and the noise covariance matrix. (51) Typically, we assume that it is a diagonal matrix to explain the data covariance by signal and not by noise. The variance of the data is explained by a signal part Wh and by a part of the noise. The parameters of the model are W and i. From the model's assumption that if h is given, then only the noise is a random variable and we have."}, {"heading": "S6 The RFN Objective", "text": "In fact, most of them will be able to move to another world, in which they are able to move to another world, in which they are able to move to another world, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in life, in which they live, in which they live, in which they live, in which they live, in which they live, in life, in which they live, in life, in which they live, in which they live, in life, in which they live, in life, in which they live, in life, in which they live, in life, in life, in which they live, in life, in which they live, in life, in which they live, in life, in which they live, in which they live, live, in life, in life, in which they live, in life, in which they live, in life, in which they live, in which they live, in which they live, live, live, in life, in life, in life, in which they live, in life, in which they live, in which they live, in life, in which they live"}, {"heading": "S7 Generalized Alternating Minimization", "text": "Instead of the EM algorithm, we use the Generalized Alternating Minimization (GAM) method [21] to enable a gradient descent in both the M-step and the E-step. Representation of an input by a generative model is the vector of the mean values of the posterior quarter, that is, the most likely hidden variables that produce the observed data. We must modify the E-step to enforce variational distributions that lead to frugal codes above the zero values of the components of its mean vector. Sparse codes, that is, many components of the mean vector are zero, are achieved by the enforcement of non-negative means. This rectification is analogous to reflected linear units that have enabled sparse codes for neural networks. Therefore, the variational distributions are limited to a family with non-negative constraints on the means."}, {"heading": "Then,", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "S8 Gradient-based M-step", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S8.1 Gradient Ascent", "text": "The gradients in the M stage are: VP W E = 12 n n H i = 1 Q = 1 Q = 1 Q = 1 Q = 1 Q = 1 E T (hi) \u2212 1 W EQ (hi h) \u2212 1 W EQ (hi h) \u2212 1 E = 1 E (vi \u2212 Whi) (vi \u2212 Whi) T + 1 E (vi \u2212 Whi). (90) Alternatively, we can estimate the gradients \u2212 1 that lead to the derivatives: VP \u2212 1E = 1 E = 1 E = 1 2 E (vi \u2212 1 E) 2 E (vi \u2212 Whi) 1 EQ (vi \u2212 Whi) T = 1 E). (91) The scaling of the gradients leads to: 2 E \u2212 1 E = 1 E = 1 E = 1 E = 1 E = 1 E = 1 E = 1 E (hi) \u2212 1 E = 1 E = 1 E = 1 E = 1 E = 1 W (h)."}, {"heading": "S8.2 Newton Update", "text": "Instead of the gradient increase, we now consider a Newton update step. The Newton update to search for the roots of \u2202 f \u2202 v is vn + 1 = vn \u2212 \u03b7H \u2212 1 \u0445 vf (vn), (100) where \u03b7 is a small step and H is the Hessian of f in relation to v, which is evaluated in vn. We designate the direction of update with \u0445 v = \u2212 H \u2212 1 \u30fb vf (vn). (101)"}, {"heading": "S8.2.1 Newton Update of the Loading Matrix", "text": "Theorem 8 (Newton Update for Loading Matrix) The M-step target E is square in W, i.e. convex in W. The M-step target is the expected reconstruction error E, which corresponds to Equation (69) E = \u2212 1 n n equation i = 1 x Rl Q (hi) log (p (vi | hi))) dhi = 1 2 (m log (2\u03c0) + log | 3 (103) + Tr (\u044b \u2212 1C) \u2212 2 Tr (\u044b \u2212 1WUT) + Tr (W TVP \u2212 1WS), where Tr has the track of a matrix. This is a quadratic function inW, as explained in the theorem. HessianHW of (2E) as vector is: HW =.104 problem inW = 1 x S (W)."}, {"heading": "S8.2.2 Newton Update of the Noise Covariance", "text": "We define the expected approximation error by E = C \u2212 U W T \u2212 W U + W S W T (108) = 1n n \u2211 i = 1 EQ ((vi \u2212 Whi) (vi \u2212 Whi) T)."}, {"heading": "\u03a8 as parameter.", "text": "Theorem 9 (Newton update for noise covariance): The direction of the Newton update as a parameter in the M step sequence is. (109)"}, {"heading": "An update with \u2206\u03a8 (\u03b7 = 1) leads to the minimum of the M-step objective E .", "text": "Evidence. The M step target is the expected reconstruction error E, which according to Eq. (69) E = \u2212 1 n \u00b2 (1 n \u00b2) i = 1% (1%) Rl Q (hi \u2212) log (p (vi \u2212 hi)) dhi = 1 2 (m log (2\u03c0) + log (110) + Tr (1%) \u2212 2% (1%) + Tr (W \u2212 1WUT) + Tr (W \u2212 1WS)), where Tr is the trace of a matrix. Hessian HUK of (2E) is in terms of its vector: HUK \u2212 1 \u2212 1% (111) is the minimum of E in terms of HUK. Therefore, an update with HUK = E \u2212 2% leads to the minimum. Hessian HUK of (2E) is in terms of its vector: HUK = 1% (1%), HUK = 1% (1%)."}, {"heading": "\u03a8\u22121 as parameter.", "text": "Theorem 10 (Newton Update for Inverse Noise Covariance): The M-step target E is convex in B-1; the Newton update direction for B-1 as parameter in M-step is B-1 = B-1 \u2212 B-1 \u2212 B-1 E-1. (119)"}, {"heading": "A first order approximation of this Newton direction for \u03a8 in the M-step is", "text": "\u0445\u0442 = E \u2212 \u0432. (120)"}, {"heading": "An update with \u2206\u03a8 (\u03b7 = 1) leads to the minimum of the M-step objective E .", "text": "Verse 4 \u2212 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 4 \u2212 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212 verse 4 \u2212"}, {"heading": "S9 Gradient-based E-Step", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S9.1 Motivation for Rectifying and Normalization Constraints", "text": "The representation of the data vector v by the model is the variational mean vector \u00b5q. To obtain sparse encodings, we want to have non-negative \u00b5q. We force non-negative averages by constraints and optimize by projected Newton methods and by gradient projection methods. Non-negative constraints correspond to the correction in the field of the neural mesh. Therefore, we aim to construct sparse encodings analogous to the reflected linear units used for neural networks. We limit the variational distributions to the family of normal distributions with non-negative mean components. Consequently, we introduce non-negative or reflective constraints: \u00b5 \u2265 0, (131) where the inequality holds \"component-wise.\" Generative models with many coding units, however, face a problem. They tend to explain small and rare signals by noise."}, {"heading": "S9.2 The Full E-step Objective", "text": "The E step maximizes F with respect to the variation distribution Q, therefore the E step q q = q q q = q q q = q q = q q (q divergence (KL divergence) [34] DKL (Q (h) p \u2212 p (h) p \u2212 p (h) p \u2212 p (h) p \u2212 p (h) p \u2212 p (h) p \u2212 p (h) p \u2212 p (h) p (133) rectification constraints introduce non-negative constraints. Minimization with respect to Q (hi) results in the constraint minimization problem: min Q (h) 1n \u00b2 p (h) p (h) p (h) p (h) p (h) p (hi) p (vi) s.t."}, {"heading": "S9.3 E-step for Mean with Rectifying Constraints", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S9.3.1 The E-Step Minimization Problem", "text": "The mean vector \u00b5q of Q is the solution of the minimization problem: min \u00b51 2 (\u00b5 \u2212 \u00b5p) T \u03a3 \u2212 1p (\u00b5 \u2212 \u00b5p) (147) s.t. \u00b5 \u2265 0.This is a convex square minimization problem with non-negative constraints (convex practicable proposition).If \u03bb is the Lagrange multiplier for the constraints, then the dual ismin \u03bb1 2 \u03bbT\u0445T\u0445p\u03bb + \u00b5 T p \u03bb (148) s.t. \u03bb 0.The Karush-Kuhn-Tucker conditions require the optimal solution for each component 1 \u2264 j \u2264 l: \u03bbj \u00b5j = 0. (149) Furthermore, the derivative of the lagrange in relation to the \u00b5-peak 1p \u00b5 \u2212 \u03a3 \u2212 1p \u00b5p = 0 (150), which can be written as \u00b5 \u2212 \u00b5p \u2212 bezirp = 0. (151) This minimization problem cannot be directly projected onto the minimization problem."}, {"heading": "S9.3.2 The Projection onto the Feasible Set", "text": "To reduce the target, we perform a gradient projection or a projected Newton step. We base our algorithms on the Euclidean minimum distance projections. If these projections are projected onto convex sets, the distances do not increase. P (Euclidean minimum distance projection) of \u00b5p is then designated by P, that is, the map that records \u00b5p to its next point (in the L2 standard) at the feasible setpoint, resulting from the solution of the convex optimization problem: min \u00b51 2 (\u00b5 \u2212 \u00b5p) T (\u00b5 \u2212 \u00b5p) (152) s.t. The following theorem 11 shows that the update Eq (153) is defined by the optimization problem Eq. (152)."}, {"heading": "S9.4 E-step for Mean with Rectifying and Normalizing Constraints", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S9.4.1 The E-Step Minimization Problem", "text": "The normalization constraints connect the individual optimization problems for each sample vi. for the E-step we obtain the minimization problem: min \u00b5i1n n \u2211 i = 1 (\u00b5i \u2212 (\u00b5p) i) T \u03a3 \u2212 1p (\u00b5i \u2212 (\u00b5p) i) (159) s.t. The solution to this optimization problem are the center vectors \u00b5i of Q (hi). Generalized reduced gradients. The equality constraints can be solved componently. the equality constraints lead to non-convex practicable sets. The solution to this optimization problem are the mean vectors \u00b5i of Q (hi). Generalized reduced gradients. The equality constraints can be solved for a variable that is then inserted into the target. The equality constraint gives an indirect problem for each 1 \u2264 j \u2264 l: \u00b521j = \u2212 n."}, {"heading": "S9.4.2 The Projection onto the Feasible Set", "text": "To reduce the target, we will use a gradient = a projected Newton problem = = a step of the generalized reduced method. We will base our algorithms on Euclidean minimum distance projections. If we project on convex sets, these projections do not increase the distances. Euclidean projection on the realizable set is indicated by P, that is, the map that simultaneously leads {(\u00b5p) i to the next points {\u00b5i} (in the L2 standard) in the realizable set. For the reflection and normalization of constraints, the projection (Euclidean minimum distance) of {(\u00b5p) i} i is set to the non-convex set values."}, {"heading": "S9.5 Gradient and Scaled Gradient Projection and Projected Newton", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S9.5.1 Gradient Projection Algorithm", "text": "The projected gradient descent or gradient projection algorithm [14, 15] first performs a gradient step (\u03b2 = 1 \u00b5k) and then projects the result onto the realizable quantity. P \u2212 \u2212 \u2212 therefore, the map that brings \u00b5 to the next point (in the L2 norm) in the realizable quantity is the projection onto the realizable quantity. The realizable quantity must be convex, but later we will introduce \u2212 gradient projection techniques for the non-convex realizable quantities. (184) The gradient projection method in our case is \u00b5k + 1 = P (\u00b5k \u2212 p \u2212 \u00b5k). The realizable quantity \u2212 p \u2212 gradient projectable methods for the non-convex realizable quantities are also not realizable. [184) The Lipschitz constant for the gradient projection is \u00b5k + 1 = P (\u00b5k \u2212 p \u2212 \u00b5k). The realizable quantity \u2212 p \u2212 gradient projectable methods for the non-convex realizable quantities are also not realizable. [5.5] The Lipschitz constant for the gradient projection ratio is \u2212 5.5. \u2212 5.5 s \u00b2 production \u2212 1p = 1p = 14.5 \u2212 emax = 1p \u2212 4.5 in the proper theorem."}, {"heading": "S9.5.2 Scaled Gradient Projection and Projected Newton Method", "text": "Both the scaled gradient projection algorithm and the projected Newton method have been proposed in [16]. We will follow [15]. The idea is to use a Newton update instead of a gradient update: \u00b5k + 1 = P (\u00b5k + \u03bbH \u2212 1 \u03a3 \u2212 1p (\u00b5p \u2212 \u00b5k)). (190) H \u2212 1 can be any strictly positive definitive matrix. (191) Other \u00b5k + 1 = P ((1 \u2212 \u03bb) \u03bcp, then we have a Newton update of the projected Newton method [16]. The search direction for the unlimited problem can be rotated by H \u2212 1 to be orthogonal to the direction of the decrease in the inactive direction."}, {"heading": "S9.5.3 Combined Method", "text": "After [47, 46] we use the following very general update rule, which includes the Gradient Projection Algorithm (Scaled Gradient Projection Algorithm) and the Projected Newton Method (Scaled Gradient Projection Algorithm). We use the following update for the E-step: dk + 1 = P (\u00b5k + 1 \u2212 K). We have to project twice, because the equality condition produces a multiplicity in the parameter spacing. We iterate this update until we see a decrease of the object in the E-level: DKL \u2212 x \u2212 P (Qk + 1 \u2212 K)."}, {"heading": "S10 Alternative Gaussian Prior", "text": "We assume that h \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W \u2212 W"}, {"heading": "S11 Hyperparameters Selected for Method Assessment", "text": "The performance of rectified factor networks (RFNs) as unsupervised methods of data presentation was compared to: (1) RFN: rectified factor networks, (2) RFNs: RFNs without normalization, (3) PCE: Denociation of autoencoders with rectified linear units, (4) RBM: restricted Boltzmann machines with Gaussian visible units and hidden binary units, (5) FAsp: Factor analysis with Jeffrey's previous (p (z) 1 / z on the hidden units, which is more economical than Laplace before, (6) FAlap: Factor analysis with Laplace in front of the hidden units, (7) ICA: independent component analysis with FastICA [24], (8) SFA: sparse factor analysis with Laplace in front of the hidden units, (9) FAlap: standard factor analysis with Laplace in front of the hidden units, (8) with Alap Laplace in front of the laptop units, (10) with Alap in front of the hidden units, (10) with Alap in front of the PCP:"}, {"heading": "S12 Data Set I", "text": "The number of persons mentioned has risen to 50, 100 or 150.We created nine different records (D1 to D9), in which the number of persons mentioned has risen to 100. (D) D \"i\" i \"s\" i \"s\" s \"i\" s. \"D\" i \"s\" s. \"D\" i \"s.\" s \"s.\" D \"i\" s \"s\" s. \"D\" s \"s\" s. \"s\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s. \"s\" s. \"s\" s. \"s\" s. \"s\" s. \"s\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s.\" s \"s\" s. \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s\" s \"s\" s. \"s\" s \"s.\" s \"s\" s. \"s\" s \"s\" s \"s.\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\""}, {"heading": "S13 Data Set II", "text": "These data sets were generated as described in Section S12, but instead of drawing the remaining components of the comprehensive outer product vectors, they were now drawn by N (0, 0.01). Ta ble S8: Com pari son for 50fa ctor s / h idde nun itsex trac ted by R FN, R FNw ithou tnor mal ion (RFN n n n), d enoi sing auto ender (DA E), rest rict edb B oltz man nm achi nes (RB M), fact oran alys w itha very spar sepr ior (FAsp), fa ctor anal ysis with aL 0 \u00b1 1 p p p n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n in n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n in n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n in n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n n"}, {"heading": "S14 RFN Pretraining for Convolution Nets", "text": "We assess the performance of the RFN first layer pretraining on CIFAR-10 and CIFAR-100 for three deep Convolutionary Network architectures: (i) the AlexNet [32], (ii) Deeply Supervised Networks (DSN) [33], and (iii) our 5 Convolution Network-In-Network (5C-NIN). Both CIFAR Panel datasets contain 60k 32x32 RGB color images divided into 50k train and 10k test sets, divided between 10 (CIFAR10) and 100 (CIFAR100) categories. Both datasets are pre-processed by global contrast normalization and ZCA whitening. Additionally, the datasets were magnified at all limits by adding the images with four zero pixels."}], "references": [{"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R. Salakhutdinov"], "venue": "Science, 313(5786):504\u2013507", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Greedy layer-wise training of deep networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": "B. Sch\u00f6lkopf, J. C. Platt, and T. Hoffman, editors, NIPS, pages 153\u2013160. MIT Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2007}, {"title": "Deep learning in neural networks: An overview", "author": ["J. Schmidhuber"], "venue": "Neural Networks, 61:85\u2013117", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep learning", "author": ["Y. LeCun", "Y. Bengio", "G. Hinton"], "venue": "Nature, 521(7553):436\u2013444", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2015}, {"title": "Rectified linear units improve restricted Boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "ICML, pages 807\u2013814. Omnipress 2010, ISBN 978-1-60558-907-7", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "Deep sparse rectifier neural networks", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "AISTATS, volume 15, pages 315\u2013323", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research, 15:1929\u20131958", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "et al", "author": ["S. Hochreiter", "U. Bodenhofer"], "venue": "FABIA: factor analysis for bicluster acquisition. Bioinformatics, 26(12):1520\u20131527", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "HapFABIA: Identification of very short segments of identity by descent characterized by rare variants in large sequencing data", "author": ["S. Hochreiter"], "venue": "Nucleic Acids Res., 41(22):e202", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "Variational learning in nonlinear Gaussian belief networks", "author": ["B.J. Frey", "G.E. Hinton"], "venue": "Neural Computation, 11(1):193\u2013214", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1999}, {"title": "Variational learning for rectified factor analysis", "author": ["M. Harva", "A. Kaban"], "venue": "Signal Processing, 87(3):509\u2013 527", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2007}, {"title": "Posterior regularization for structured latent variable models", "author": ["K. Ganchev", "J. Graca", "J. Gillenwater", "B. Taskar"], "venue": "Journal of Machine Learning Research, 11:2001\u20132049", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Variational EM algorithms for non-Gaussian latent variable models", "author": ["J. Palmer", "D. Wipf", "K. Kreutz-Delgado", "B. Rao"], "venue": "NIPS, volume 18, pages 1059\u20131066", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2006}, {"title": "On the Goldstein-Levitin-Polyak gradient projection method", "author": ["D.P. Bertsekas"], "venue": "IEEE Trans. Automat. Control, 21:174\u2013184", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1976}, {"title": "Iterative Methods for Optimization", "author": ["C.T. Kelley"], "venue": "Society for Industrial and Applied Mathematics (SIAM), Philadelphia", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1999}, {"title": "Projected Newton methods for optimization problems with simple constraints", "author": ["D.P. Bertsekas"], "venue": "SIAM J. Control Optim., 20:221\u2013246", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1982}, {"title": "Optimization", "author": ["J. Abadie", "J. Carpentier"], "venue": "chapter Generalization of the Wolfe Reduced Gradient Method to the Case of Nonlinear Constraints. Academic Press", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1969}, {"title": "The gradient projection method for nonlinear programming", "author": ["J.B. Rosen"], "venue": "part ii. nonlinear constraints. Journal of the Society for Industrial and Applied Mathematics, 9(4):514\u2013532", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1961}, {"title": "Applied optimal design", "author": ["E.J. Haug", "J.S. Arora"], "venue": "J. Wiley & Sons, New York", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1979}, {"title": "Interior Point Polynomial Time Methods for Linear Programming", "author": ["A. Ben-Tal", "A. Nemirovski"], "venue": "Conic Quadratic Programming, and Semidefinite Programming, chapter 6, pages 377\u2013442. Society for Industrial and Applied Mathematics", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2001}, {"title": "Convergence theorems for generalized alternating minimization procedures", "author": ["A. Gunawardana", "W. Byrne"], "venue": "Journal of Machine Learning Research, 6:2049\u20132073", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2005}, {"title": "Nonlinear Programming: A Unified Approach", "author": ["W.I. Zangwill"], "venue": "Prentice Hall, Englewood Cliffs, N.J.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1969}, {"title": "Learning with Matrix Factorizations", "author": ["N. Srebro"], "venue": "PhD thesis, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2004}, {"title": "A fast fixed-point algorithm for independent component analysis", "author": ["A. Hyv\u00e4rinen", "E. Oja"], "venue": "Neural Comput., 9(7):1483\u20131492", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1999}, {"title": "Learning methods for generic object recognition with invariance to pose and lighting", "author": ["Y. LeCun", "F.-J. Huang", "L. Bottou"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE Press", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2004}, {"title": "et al", "author": ["P. Vincent", "H. Larochelle"], "venue": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. JMLR, 11:3371\u20133408", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2010}, {"title": "et al", "author": ["H. Larochelle", "D. Erhan"], "venue": "An empirical evaluation of deep architectures on problems with many factors of variation. In ICML, pages 473\u2013480", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "Master\u2019s thesis, Deptartment of Computer Science, University of Toronto", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}, {"title": "et al", "author": ["B. Verbist", "G. Klambauer"], "venue": "Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the {QSTAR} project. Drug Discovery Today, 20(5):505 \u2013 513", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2015}, {"title": "A new summarization method for Affymetrix probe level data", "author": ["S. Hochreiter", "D.-A. Clevert", "K. Obermayer"], "venue": "Bioinformatics, 22(8):943\u2013949", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2006}, {"title": "Multi-column deep neural networks for image classification", "author": ["D.C. Ciresan", "U. Meier", "J. Schmidhuber"], "venue": "IEEE Conference on Computer Vision and Pattern Recognition CVPR 2012", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2012}, {"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 25, pages 1097\u20131105. Curran Associates, Inc.", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2012}, {"title": "Deeply-Supervised Nets", "author": ["C.-Y. Lee", "S. Xie", "P. Gallagher", "Z. Zhang", "Z. Tu"], "venue": "ArXiv e-prints", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "On information and sufficiency", "author": ["S. Kullback", "R.A. Leibler"], "venue": "Annals of Mathematical Statistics, 22:79\u2013 86", "citeRegEx": "34", "shortCiteRegEx": null, "year": 1951}, {"title": "Confidence-weighted linear classification", "author": ["M. Dredze", "K. Crammer", "F. Pereira"], "venue": "Proceedings of the 25th international conference on Machine learning (ICML08), volume 25, pages 264\u2013271. ACM New York", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2008}, {"title": "Confidence-weighted linear classification for text categorization", "author": ["M. Dredze", "K. Crammer", "F. Pereira"], "venue": "Journal of Machine Learning Research, 13(1):1891\u20131926", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2012}, {"title": "Trace inequalities involving hermitian matrices", "author": ["R. Patel", "M. Toda"], "venue": "Linear Algebra and its Applications, 23:13\u201320", "citeRegEx": "37", "shortCiteRegEx": null, "year": 1979}, {"title": "A variational bayesian method for rectified factor analysis", "author": ["M. Harva", "A. Kaban"], "venue": "Proc. Int. Joint Conf. on Neural Networks (IJCNN\u201905), pages 185\u2013190", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2005}, {"title": "Posterior vs. parameter sparsity in latent variable models", "author": ["J.V. Graca", "K. Ganchev", "B. Taskar", "F. Pereira"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2009}, {"title": "Expectation maximization and posterior constraints", "author": ["J.V. Graca", "K. Ganchev", "B. Taskar"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2007}, {"title": "A view of the EM algorithm that justifies incremental", "author": ["R. Neal", "G.E. Hinton"], "venue": "sparse, and other variants. In M. I. Jordan, editor, Learning in Graphical Models, pages 355\u2013368. MIT Press, Cambridge, MA", "citeRegEx": "41", "shortCiteRegEx": null, "year": 1998}, {"title": "Statistical Mechanics", "author": ["R.P. Feynman"], "venue": "Benjamin, Reading, MA", "citeRegEx": "42", "shortCiteRegEx": null, "year": 1972}, {"title": "A free energy principle for biological systems", "author": ["K. Friston"], "venue": "Entropy, 14:2100\u20132121", "citeRegEx": "43", "shortCiteRegEx": null, "year": 2012}, {"title": "On the convergence properties of the EM algorithm", "author": ["C.F.J. Wu"], "venue": "Annals of Statistics, 11(1):95\u2013103", "citeRegEx": "44", "shortCiteRegEx": null, "year": 1983}, {"title": "J", "author": ["E.G. Birgin"], "venue": "M. Mart\u0131\u0301nez, and M. Raydan. Nonmonotone spectral projected gradient methods on convex sets. Siam Journal on Optimization, 10(4):1196\u20131211", "citeRegEx": "45", "shortCiteRegEx": null, "year": 2000}, {"title": "Gradient projection methods for quadratic programs and applications in training support vector machines", "author": ["T. Serafini", "G. Zanghirati", "L. Zanni"], "venue": "Optimization Methods and Software, 20(2-3):353\u2013378", "citeRegEx": "46", "shortCiteRegEx": null, "year": 2005}, {"title": "A new projected quasi-Newton approach for the nonnegative least squares problem", "author": ["D. Kim", "S. Sra", "I.S. Dhillon"], "venue": "Technical Report TR-06-54, Department of Computer Sciences, University of Texas at Austin", "citeRegEx": "47", "shortCiteRegEx": null, "year": 2006}, {"title": "Maxout networks", "author": ["I.J. Goodfellow", "D. Warde-Farley", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "ArXiv e-prints", "citeRegEx": "48", "shortCiteRegEx": null, "year": 2013}, {"title": "Fractional max-pooling", "author": ["Benjamin Graham"], "venue": "CoRR, abs/1412.6071,", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "1 Introduction The success of deep learning is to a large part based on advanced and efficient input representations [1, 2, 3, 4].", "startOffset": 117, "endOffset": 129}, {"referenceID": 1, "context": "1 Introduction The success of deep learning is to a large part based on advanced and efficient input representations [1, 2, 3, 4].", "startOffset": 117, "endOffset": 129}, {"referenceID": 2, "context": "1 Introduction The success of deep learning is to a large part based on advanced and efficient input representations [1, 2, 3, 4].", "startOffset": 117, "endOffset": 129}, {"referenceID": 3, "context": "1 Introduction The success of deep learning is to a large part based on advanced and efficient input representations [1, 2, 3, 4].", "startOffset": 117, "endOffset": 129}, {"referenceID": 4, "context": "Sparse representations of the input are in general obtained by rectified linear units (ReLU) [5, 6] and dropout [7].", "startOffset": 93, "endOffset": 99}, {"referenceID": 5, "context": "Sparse representations of the input are in general obtained by rectified linear units (ReLU) [5, 6] and dropout [7].", "startOffset": 93, "endOffset": 99}, {"referenceID": 6, "context": "Sparse representations of the input are in general obtained by rectified linear units (ReLU) [5, 6] and dropout [7].", "startOffset": 112, "endOffset": 115}, {"referenceID": 7, "context": "In bioinformatics sparse codes excelled in biclustering of gene expression data [8] and in finding DNA sharing patterns between humans and Neanderthals [9].", "startOffset": 80, "endOffset": 83}, {"referenceID": 8, "context": "In bioinformatics sparse codes excelled in biclustering of gene expression data [8] and in finding DNA sharing patterns between humans and Neanderthals [9].", "startOffset": 152, "endOffset": 155}, {"referenceID": 9, "context": "For example, generative models with rectified priors, like rectified factor analysis, have zero posterior probability for negative values, therefore their means are positive and not sparse [10, 11].", "startOffset": 189, "endOffset": 197}, {"referenceID": 10, "context": "For example, generative models with rectified priors, like rectified factor analysis, have zero posterior probability for negative values, therefore their means are positive and not sparse [10, 11].", "startOffset": 189, "endOffset": 197}, {"referenceID": 11, "context": "To address the data dependence of the code, we employ the posterior regularization method [12].", "startOffset": 90, "endOffset": 94}, {"referenceID": 12, "context": "For non-Gaussian priors, the computation of the posterior mean of a new input requires either to numerically solve an integral or to iteratively update variational parameters [13].", "startOffset": 175, "endOffset": 179}, {"referenceID": 11, "context": "These E-step and M-step modifications of the posterior regularization method result in a generalized alternating minimization (GAM) algorithm [12].", "startOffset": 142, "endOffset": 146}, {"referenceID": 11, "context": "The constraints on the input representation are enforced by the posterior regularization method [12].", "startOffset": 96, "endOffset": 100}, {"referenceID": 11, "context": ",vn}, the posterior regularization method maximizes the objective F [12]: F = 1 n n \u2211", "startOffset": 68, "endOffset": 72}, {"referenceID": 11, "context": "(1) [12].", "startOffset": 4, "endOffset": 8}, {"referenceID": 13, "context": "Therefore, we perform a step of the gradient projection algorithm [14, 15], which performs first a gradient step and then projects the result to the feasible set.", "startOffset": 66, "endOffset": 74}, {"referenceID": 14, "context": "Therefore, we perform a step of the gradient projection algorithm [14, 15], which performs first a gradient step and then projects the result to the feasible set.", "startOffset": 66, "endOffset": 74}, {"referenceID": 15, "context": "We start by a step of the projected Newton method, then we try the gradient projection algorithm, thereafter the scaled gradient projection algorithm with reduced matrix [16] (see also [15]).", "startOffset": 170, "endOffset": 174}, {"referenceID": 14, "context": "We start by a step of the projected Newton method, then we try the gradient projection algorithm, thereafter the scaled gradient projection algorithm with reduced matrix [16] (see also [15]).", "startOffset": 185, "endOffset": 189}, {"referenceID": 16, "context": "(3), we use the generalized reduced method [17].", "startOffset": 43, "endOffset": 47}, {"referenceID": 17, "context": "Alternatively, we use Rosen\u2019s gradient projection method [18] or its improvement [19].", "startOffset": 57, "endOffset": 61}, {"referenceID": 18, "context": "Alternatively, we use Rosen\u2019s gradient projection method [18] or its improvement [19].", "startOffset": 81, "endOffset": 85}, {"referenceID": 19, "context": "In contrast, a quadratic program solver typically requires for the (nl) variables (the means of the hidden units for all samples) O(nl) steps to find the minimum [20].", "startOffset": 162, "endOffset": 166}, {"referenceID": 20, "context": "The resulting algorithm is a posterior regularization method with a gradient based E- and M-step, leading to a generalized alternating minimization (GAM) algorithm [21].", "startOffset": 164, "endOffset": 168}, {"referenceID": 20, "context": "1 is a GAM algorithm which convergences according to Proposition 5 in [21].", "startOffset": 70, "endOffset": 74}, {"referenceID": 20, "context": "Proposition 5 in [21] is based on Zangwill\u2019s generalized convergence theorem, thus updates of the RFN algorithm are viewed as point-to-set mappings [22].", "startOffset": 17, "endOffset": 21}, {"referenceID": 21, "context": "Proposition 5 in [21] is based on Zangwill\u2019s generalized convergence theorem, thus updates of the RFN algorithm are viewed as point-to-set mappings [22].", "startOffset": 148, "endOffset": 152}, {"referenceID": 22, "context": "The trace norm of a positive semi-definite matrix is its trace and bounds the Frobenius norm [23].", "startOffset": 93, "endOffset": 97}, {"referenceID": 23, "context": "We compare (1) RFN: rectified factor networks, (2) RFNn: RFNs without normalization, (3) DAE: denoising autoencoders with ReLUs, (4) RBM: restricted Boltzmann machines with Gaussian visible units, (5) FAsp: factor analysis with Jeffrey\u2019s prior (p(z) \u221d 1/z) on the hidden units which is sparser than a Laplace prior, (6) FAlap: factor analysis with Laplace prior on the hidden units, (7) ICA: independent component analysis by FastICA [24], (8) SFA: sparse factor analysis with a Laplace prior on the parameters, (9) FA: standard factor analysis, (10) PCA: principal component analysis.", "startOffset": 434, "endOffset": 438}, {"referenceID": 7, "context": "Into these matrices, biclusters are implanted [8].", "startOffset": 46, "endOffset": 49}, {"referenceID": 12, "context": "The variational approximation to the Laplacian is a Gaussian distribution [13].", "startOffset": 74, "endOffset": 78}, {"referenceID": 24, "context": "The benchmark datasets and results are taken from previous publications [25, 26, 27, 28] and contain: (i) MNIST (original MNIST), (ii) basic (a smaller subset of MNIST for training), (iii) bg-rand (MNIST with random noise background), (iv) bg-img (MNIST with random image background), (v) rect (discrimination between tall and wide rectangles), (vi) rect-img (discrimination between tall and wide rectangular images overlayed on random background images), (vii) convex (discrimination between convex and concave shapes), (viii) CIFAR-10 (60k color images in 10 classes), and (ix) NORB (29,160 stereo image pairs of 5 generic categories).", "startOffset": 72, "endOffset": 88}, {"referenceID": 25, "context": "The benchmark datasets and results are taken from previous publications [25, 26, 27, 28] and contain: (i) MNIST (original MNIST), (ii) basic (a smaller subset of MNIST for training), (iii) bg-rand (MNIST with random noise background), (iv) bg-img (MNIST with random image background), (v) rect (discrimination between tall and wide rectangles), (vi) rect-img (discrimination between tall and wide rectangular images overlayed on random background images), (vii) convex (discrimination between convex and concave shapes), (viii) CIFAR-10 (60k color images in 10 classes), and (ix) NORB (29,160 stereo image pairs of 5 generic categories).", "startOffset": 72, "endOffset": 88}, {"referenceID": 26, "context": "The benchmark datasets and results are taken from previous publications [25, 26, 27, 28] and contain: (i) MNIST (original MNIST), (ii) basic (a smaller subset of MNIST for training), (iii) bg-rand (MNIST with random noise background), (iv) bg-img (MNIST with random image background), (v) rect (discrimination between tall and wide rectangles), (vi) rect-img (discrimination between tall and wide rectangular images overlayed on random background images), (vii) convex (discrimination between convex and concave shapes), (viii) CIFAR-10 (60k color images in 10 classes), and (ix) NORB (29,160 stereo image pairs of 5 generic categories).", "startOffset": 72, "endOffset": 88}, {"referenceID": 27, "context": "The benchmark datasets and results are taken from previous publications [25, 26, 27, 28] and contain: (i) MNIST (original MNIST), (ii) basic (a smaller subset of MNIST for training), (iii) bg-rand (MNIST with random noise background), (iv) bg-img (MNIST with random image background), (v) rect (discrimination between tall and wide rectangles), (vi) rect-img (discrimination between tall and wide rectangular images overlayed on random background images), (vii) convex (discrimination between convex and concave shapes), (viii) CIFAR-10 (60k color images in 10 classes), and (ix) NORB (29,160 stereo image pairs of 5 generic categories).", "startOffset": 72, "endOffset": 88}, {"referenceID": 25, "context": "Model selection is based on the validation set performance [26].", "startOffset": 59, "endOffset": 63}, {"referenceID": 24, "context": "001}, Table 2: Results of deep networks pretrained by RFNs and other models (taken from [25, 26, 27, 28]).", "startOffset": 88, "endOffset": 104}, {"referenceID": 25, "context": "001}, Table 2: Results of deep networks pretrained by RFNs and other models (taken from [25, 26, 27, 28]).", "startOffset": 88, "endOffset": 104}, {"referenceID": 26, "context": "001}, Table 2: Results of deep networks pretrained by RFNs and other models (taken from [25, 26, 27, 28]).", "startOffset": 88, "endOffset": 104}, {"referenceID": 27, "context": "001}, Table 2: Results of deep networks pretrained by RFNs and other models (taken from [25, 26, 27, 28]).", "startOffset": 88, "endOffset": 104}, {"referenceID": 25, "context": "Fine-tuning was stopped based on the validation set performance, following [26].", "startOffset": 75, "endOffset": 79}, {"referenceID": 25, "context": "The test error rates together with the 95% confidence interval (computed according to [26]) for deep network pretraining by RFNs and other methods are given in Tab.", "startOffset": 86, "endOffset": 90}, {"referenceID": 28, "context": "Using RFNs we analyzed gene expression datasets of two projects in the lead optimization phase of a big pharmaceutical company [29].", "startOffset": 127, "endOffset": 131}, {"referenceID": 29, "context": "In both projects, the expression data was summarized by FARMS [30] and standardized.", "startOffset": 62, "endOffset": 66}, {"referenceID": 28, "context": "Both findings were not detected by other unsupervised methods, while they were highly relevant and supported decision-making in both projects [29].", "startOffset": 142, "endOffset": 146}, {"referenceID": 0, "context": "References [1] G.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] V.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] X.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] N.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] B.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] E.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] N.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] B.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "5 in [15]) .", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "1 in [15]) .", "startOffset": 5, "endOffset": 9}, {"referenceID": 30, "context": "Finally, Section S14 describes experiments, that we have done to assess the performance of RFN first layer pretraining on CIFAR-10 and CIFAR-100 for three deep convolutional network architectures: (i) the AlexNet [31, 32], (ii) Deeply Supervised Networks (DSN) [33], and (iii) our 5-Convolution-Network-InNetwork (5C-NIN).", "startOffset": 213, "endOffset": 221}, {"referenceID": 31, "context": "Finally, Section S14 describes experiments, that we have done to assess the performance of RFN first layer pretraining on CIFAR-10 and CIFAR-100 for three deep convolutional network architectures: (i) the AlexNet [31, 32], (ii) Deeply Supervised Networks (DSN) [33], and (iii) our 5-Convolution-Network-InNetwork (5C-NIN).", "startOffset": 213, "endOffset": 221}, {"referenceID": 32, "context": "Finally, Section S14 describes experiments, that we have done to assess the performance of RFN first layer pretraining on CIFAR-10 and CIFAR-100 for three deep convolutional network architectures: (i) the AlexNet [31, 32], (ii) Deeply Supervised Networks (DSN) [33], and (iii) our 5-Convolution-Network-InNetwork (5C-NIN).", "startOffset": 261, "endOffset": 265}, {"referenceID": 16, "context": "This approach is called \u201cgeneralized reduced gradient method\u201d [17], which is our preferred alternative method.", "startOffset": 62, "endOffset": 66}, {"referenceID": 17, "context": "If this method fails, then Rosen\u2019s gradient projection method [18] is used.", "startOffset": 62, "endOffset": 66}, {"referenceID": 18, "context": "Finally, the method of Haug and Arora [19] is used.", "startOffset": 38, "endOffset": 42}, {"referenceID": 20, "context": "However, in [21] it is shown how to generalize the GAM convergence proof to mini-batches as it is shown for the incremental EM algorithm.", "startOffset": 12, "endOffset": 16}, {"referenceID": 16, "context": "Algorithm S3 Projection with E-Step Improvement Goal obtain \u03bc i = \u03bci that decrease the E-step objective Input \u03a3 = \u03a3p, \u03a3 = \u03a3 p for 1 \u2264 i \u2264 n: (\u03bcp)i, \u03bc i , pi = N ((\u03bcp)i,\u03a3p) simple projection P (rectified or rectified & normalized), E-step objective: O = 1 n \u2211n i=1DKL(Qi \u2016 pi) \u03b3min, \u03bbmin, \u03c1\u03b3 , \u03c1\u03bb, (for -active set) Main \u2014\u2013Simple Projection\u2014\u2014 perform Newton Projection by Algorithm S5 or Algorithm S4 \u2014\u2013Scaled Projection\u2014\u2014 if 0 \u2264 \u2206O then following loop for: (1) \u03b3, (2) \u03bb, or (3) \u03b3 and \u03bb annealing \u03b3 = \u03bb = 1 while 0 \u2264 \u2206O and \u03bb > \u03bbmin and \u03b3 > \u03b3min do \u03b3 = \u03c1\u03b3 \u03b3 (skipped for \u03bb annealing) \u03bb = \u03c1\u03bb \u03bb (skipped for \u03b3 annealing) perform Scaled Newton Projection by Algorithm S6 end while end if \u2014\u2013Scaled Projection With Reduced Matrix\u2014\u2014 if 0 \u2264 \u2206O then determine -active set as all j with \u03bcj \u2264 setH to \u03a3\u22121 p with -active columns and rows j fixed to ej following loop for: (1) \u03b3, (2) \u03bb, or (3) \u03b3 and \u03bb annealing \u03b3 = \u03bb = 1 while 0 \u2264 \u2206O and \u03bb > \u03bbmin and \u03b3 > \u03b3min do \u03b3 = \u03c1\u03b3 \u03b3 (skipped for \u03bb annealing) \u03bb = \u03c1\u03bb \u03bb (skipped for \u03b3 annealing) perform Scaled Projection With Reduced Matrix by Algorithm S7 end while end if \u2014\u2013General Gradient Projection\u2014\u2014 while 0 \u2264 \u2206O do use generalized reduced gradient [17] OR use Rosen\u2019s gradient projection [18] OR use method of Haug and Arora [19] end while", "startOffset": 1181, "endOffset": 1185}, {"referenceID": 17, "context": "Algorithm S3 Projection with E-Step Improvement Goal obtain \u03bc i = \u03bci that decrease the E-step objective Input \u03a3 = \u03a3p, \u03a3 = \u03a3 p for 1 \u2264 i \u2264 n: (\u03bcp)i, \u03bc i , pi = N ((\u03bcp)i,\u03a3p) simple projection P (rectified or rectified & normalized), E-step objective: O = 1 n \u2211n i=1DKL(Qi \u2016 pi) \u03b3min, \u03bbmin, \u03c1\u03b3 , \u03c1\u03bb, (for -active set) Main \u2014\u2013Simple Projection\u2014\u2014 perform Newton Projection by Algorithm S5 or Algorithm S4 \u2014\u2013Scaled Projection\u2014\u2014 if 0 \u2264 \u2206O then following loop for: (1) \u03b3, (2) \u03bb, or (3) \u03b3 and \u03bb annealing \u03b3 = \u03bb = 1 while 0 \u2264 \u2206O and \u03bb > \u03bbmin and \u03b3 > \u03b3min do \u03b3 = \u03c1\u03b3 \u03b3 (skipped for \u03bb annealing) \u03bb = \u03c1\u03bb \u03bb (skipped for \u03b3 annealing) perform Scaled Newton Projection by Algorithm S6 end while end if \u2014\u2013Scaled Projection With Reduced Matrix\u2014\u2014 if 0 \u2264 \u2206O then determine -active set as all j with \u03bcj \u2264 setH to \u03a3\u22121 p with -active columns and rows j fixed to ej following loop for: (1) \u03b3, (2) \u03bb, or (3) \u03b3 and \u03bb annealing \u03b3 = \u03bb = 1 while 0 \u2264 \u2206O and \u03bb > \u03bbmin and \u03b3 > \u03b3min do \u03b3 = \u03c1\u03b3 \u03b3 (skipped for \u03bb annealing) \u03bb = \u03c1\u03bb \u03bb (skipped for \u03b3 annealing) perform Scaled Projection With Reduced Matrix by Algorithm S7 end while end if \u2014\u2013General Gradient Projection\u2014\u2014 while 0 \u2264 \u2206O do use generalized reduced gradient [17] OR use Rosen\u2019s gradient projection [18] OR use method of Haug and Arora [19] end while", "startOffset": 1221, "endOffset": 1225}, {"referenceID": 18, "context": "Algorithm S3 Projection with E-Step Improvement Goal obtain \u03bc i = \u03bci that decrease the E-step objective Input \u03a3 = \u03a3p, \u03a3 = \u03a3 p for 1 \u2264 i \u2264 n: (\u03bcp)i, \u03bc i , pi = N ((\u03bcp)i,\u03a3p) simple projection P (rectified or rectified & normalized), E-step objective: O = 1 n \u2211n i=1DKL(Qi \u2016 pi) \u03b3min, \u03bbmin, \u03c1\u03b3 , \u03c1\u03bb, (for -active set) Main \u2014\u2013Simple Projection\u2014\u2014 perform Newton Projection by Algorithm S5 or Algorithm S4 \u2014\u2013Scaled Projection\u2014\u2014 if 0 \u2264 \u2206O then following loop for: (1) \u03b3, (2) \u03bb, or (3) \u03b3 and \u03bb annealing \u03b3 = \u03bb = 1 while 0 \u2264 \u2206O and \u03bb > \u03bbmin and \u03b3 > \u03b3min do \u03b3 = \u03c1\u03b3 \u03b3 (skipped for \u03bb annealing) \u03bb = \u03c1\u03bb \u03bb (skipped for \u03b3 annealing) perform Scaled Newton Projection by Algorithm S6 end while end if \u2014\u2013Scaled Projection With Reduced Matrix\u2014\u2014 if 0 \u2264 \u2206O then determine -active set as all j with \u03bcj \u2264 setH to \u03a3\u22121 p with -active columns and rows j fixed to ej following loop for: (1) \u03b3, (2) \u03bb, or (3) \u03b3 and \u03bb annealing \u03b3 = \u03bb = 1 while 0 \u2264 \u2206O and \u03bb > \u03bbmin and \u03b3 > \u03b3min do \u03b3 = \u03c1\u03b3 \u03b3 (skipped for \u03bb annealing) \u03bb = \u03c1\u03bb \u03bb (skipped for \u03b3 annealing) perform Scaled Projection With Reduced Matrix by Algorithm S7 end while end if \u2014\u2013General Gradient Projection\u2014\u2014 while 0 \u2264 \u2206O do use generalized reduced gradient [17] OR use Rosen\u2019s gradient projection [18] OR use method of Haug and Arora [19] end while", "startOffset": 1258, "endOffset": 1262}, {"referenceID": 33, "context": "DKL denotes the Kullback-Leibler (KL) divergence [34], which is larger than or equal to zero.", "startOffset": 49, "endOffset": 53}, {"referenceID": 20, "context": "From the modification of the E-step and the M-step follows that Algorithm S2 is a Generalized Alternating Minimization (GAM) algorithm according to [21].", "startOffset": 148, "endOffset": 152}, {"referenceID": 20, "context": "The most important requirements for the convergence of the GAM algorithm according to Theorem 7 (Proposition 5 in [21]) are the increase of the objective F in both the E-step and the M-step.", "startOffset": 114, "endOffset": 118}, {"referenceID": 16, "context": "To optimize such problems, the generalized reduced gradient method [17] solves each equality constraint for one variable and inserts it into the objective.", "startOffset": 67, "endOffset": 71}, {"referenceID": 17, "context": "For rectifying and normalizing constraints, also Rosen\u2019s [18] and Haug & Arora\u2019s [19] gradient projection method ensures a decrease of the E-step objective since they can be applied to non-convex problems.", "startOffset": 57, "endOffset": 61}, {"referenceID": 18, "context": "For rectifying and normalizing constraints, also Rosen\u2019s [18] and Haug & Arora\u2019s [19] gradient projection method ensures a decrease of the E-step objective since they can be applied to non-convex problems.", "startOffset": 81, "endOffset": 85}, {"referenceID": 20, "context": "We show that the requirements as given in Section S7 for GAM convergence according to Theorem 7 (Proposition 5 in [21]) are fulfilled: 1.", "startOffset": 114, "endOffset": 118}, {"referenceID": 34, "context": "the E-step has a unique maximizer \u2212\u2192 ensured by the convex, continuous, and continuous differentiable function that is minimized [35, 36] together with compact feasible set for the", "startOffset": 129, "endOffset": 137}, {"referenceID": 35, "context": "the E-step has a unique maximizer \u2212\u2192 ensured by the convex, continuous, and continuous differentiable function that is minimized [35, 36] together with compact feasible set for the", "startOffset": 129, "endOffset": 137}, {"referenceID": 20, "context": "Since this Proposition 5 in [21] is based on Zangwill\u2019s generalized convergence theorem, updates of the RFN algorithm are viewed as point-to-set mappings [22].", "startOffset": 28, "endOffset": 32}, {"referenceID": 21, "context": "Since this Proposition 5 in [21] is based on Zangwill\u2019s generalized convergence theorem, updates of the RFN algorithm are viewed as point-to-set mappings [22].", "startOffset": 154, "endOffset": 158}, {"referenceID": 21, "context": "A theorem analog to Theorem 7 but with E-step and M-step conditions exchanged can be derived from Zangwill\u2019s generalized convergence theorem [22].", "startOffset": 141, "endOffset": 145}, {"referenceID": 20, "context": "Therefore the solution of the GAM optimization does not guarantee stationary points in likelihood [21].", "startOffset": 98, "endOffset": 102}, {"referenceID": 36, "context": "(37) The inequality uses the fact that for positive definite matrices A and B inequality Tr(AB) \u2264 Tr(A)Tr(B) holds [37].", "startOffset": 115, "endOffset": 119}, {"referenceID": 22, "context": "The trace norm of a positive semi-definite matrix is its trace and bounds the Frobenius norm [23].", "startOffset": 93, "endOffset": 97}, {"referenceID": 33, "context": "DKL denotes the Kullback-Leibler (KL) divergence [34] which is larger than zero.", "startOffset": 49, "endOffset": 53}, {"referenceID": 9, "context": "However these posteriors do not have sparse means (they must be positive), that is, they do not yield sparse codes [10].", "startOffset": 115, "endOffset": 119}, {"referenceID": 37, "context": "For example, rectified factor analysis, which rectifies Gaussian priors and selects models using a variational Bayesian learning procedure, does not yield posteriors with sparse means [38, 11].", "startOffset": 184, "endOffset": 192}, {"referenceID": 10, "context": "For example, rectified factor analysis, which rectifies Gaussian priors and selects models using a variational Bayesian learning procedure, does not yield posteriors with sparse means [38, 11].", "startOffset": 184, "endOffset": 192}, {"referenceID": 11, "context": "Therefore we use the posterior regularization method (posterior constraint method) [12, 39, 40].", "startOffset": 83, "endOffset": 95}, {"referenceID": 38, "context": "Therefore we use the posterior regularization method (posterior constraint method) [12, 39, 40].", "startOffset": 83, "endOffset": 95}, {"referenceID": 39, "context": "Therefore we use the posterior regularization method (posterior constraint method) [12, 39, 40].", "startOffset": 83, "endOffset": 95}, {"referenceID": 33, "context": "We use the Kullback-Leibler (KL) divergence [34] DKL to measure the distance between these distributions.", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "We obtain the objective F (to be maximized) of the posterior constraint method [12, 39, 40]:", "startOffset": 79, "endOffset": 91}, {"referenceID": 38, "context": "We obtain the objective F (to be maximized) of the posterior constraint method [12, 39, 40]:", "startOffset": 79, "endOffset": 91}, {"referenceID": 39, "context": "We obtain the objective F (to be maximized) of the posterior constraint method [12, 39, 40]:", "startOffset": 79, "endOffset": 91}, {"referenceID": 40, "context": "In the variational framework,Q is the variational distribution andF is called the negative free energy [41].", "startOffset": 103, "endOffset": 107}, {"referenceID": 41, "context": "This physical term is used since variational methods were introduced for quantum physics by Richard Feynman [42].", "startOffset": 108, "endOffset": 112}, {"referenceID": 42, "context": "The hidden variables can be considered as the fictive causes or explanations of environmental fluctuations [43].", "startOffset": 107, "endOffset": 111}, {"referenceID": 20, "context": "Instead of the EM algorithm we use the Generalized Alternating Minimization (GAM) algorithm [21] to allow for gradient descent both in the M-step and the E-step.", "startOffset": 92, "endOffset": 96}, {"referenceID": 11, "context": "To impose constraints on the posterior is known as the posterior constraint method [12, 39, 40].", "startOffset": 83, "endOffset": 95}, {"referenceID": 38, "context": "To impose constraints on the posterior is known as the posterior constraint method [12, 39, 40].", "startOffset": 83, "endOffset": 95}, {"referenceID": 39, "context": "To impose constraints on the posterior is known as the posterior constraint method [12, 39, 40].", "startOffset": 83, "endOffset": 95}, {"referenceID": 20, "context": "Gunawardana and Byrne showed that the GAM converges [21] (see also [44]).", "startOffset": 52, "endOffset": 56}, {"referenceID": 43, "context": "Gunawardana and Byrne showed that the GAM converges [21] (see also [44]).", "startOffset": 67, "endOffset": 71}, {"referenceID": 20, "context": "The following GAM convergence Theorem 7 is Proposition 5 in [21] and proves the convergence of the GAM algorithm to a solution that minimizes \u2212F .", "startOffset": 60, "endOffset": 64}, {"referenceID": 20, "context": "Then, (1) the point-to-set map FB is closed on D\u2032 \u00d7\u0398 (2) FB(D\u2032 \u00d7\u0398) \u2286 D \u00d7\u0398 and FB satisfies the GAM and EQ conditions of the GAM convergence theorem, that is, Theorem 3 in [21].", "startOffset": 171, "endOffset": 175}, {"referenceID": 20, "context": "See Proposition 5 in [21].", "startOffset": 21, "endOffset": 25}, {"referenceID": 34, "context": "The objective for the E-step is strict convex in all its parameters for the variational distributions, simultaneously [35, 36].", "startOffset": 118, "endOffset": 126}, {"referenceID": 35, "context": "The objective for the E-step is strict convex in all its parameters for the variational distributions, simultaneously [35, 36].", "startOffset": 118, "endOffset": 126}, {"referenceID": 20, "context": "Therefore the solution of the GAM optimization does not guarantee stationary points in likelihood [21].", "startOffset": 98, "endOffset": 102}, {"referenceID": 33, "context": "2 The Full E-step Objective The E-step maximizes F with respect to the variational distribution Q, therefore the E-step minimizes the Kullback-Leibler divergence (KL-divergence) [34] DKL(Q(h) \u2016 p(h | v)).", "startOffset": 178, "endOffset": 182}, {"referenceID": 34, "context": "This Kullback-Leibler divergence is convex in the mean vector \u03bcq and the covariance matrix \u03a3q of Q, simultaneously [35, 36].", "startOffset": 115, "endOffset": 123}, {"referenceID": 35, "context": "This Kullback-Leibler divergence is convex in the mean vector \u03bcq and the covariance matrix \u03a3q of Q, simultaneously [35, 36].", "startOffset": 115, "endOffset": 123}, {"referenceID": 16, "context": "To solve the each equality constraints for a variable and insert it into the objective is called generalized reduced gradient method [17].", "startOffset": 133, "endOffset": 137}, {"referenceID": 17, "context": "The gradient projection method has been generalized by Rosen to non-linear constraints [18] and was later improved by [19].", "startOffset": 87, "endOffset": 91}, {"referenceID": 18, "context": "The gradient projection method has been generalized by Rosen to non-linear constraints [18] and was later improved by [19].", "startOffset": 118, "endOffset": 122}, {"referenceID": 13, "context": "1 Gradient Projection Algorithm The projected gradient descent or gradient projection algorithm [14, 15] performs first a gradient step and then projects the result to the feasible set.", "startOffset": 96, "endOffset": 104}, {"referenceID": 14, "context": "1 Gradient Projection Algorithm The projected gradient descent or gradient projection algorithm [14, 15] performs first a gradient step and then projects the result to the feasible set.", "startOffset": 96, "endOffset": 104}, {"referenceID": 14, "context": "5 in [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "5 in [15]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "See [15].", "startOffset": 4, "endOffset": 8}, {"referenceID": 44, "context": "(189) Improved methods for finding an appropriate \u03bb by line search methods have been proposed [45, 46].", "startOffset": 94, "endOffset": 102}, {"referenceID": 45, "context": "(189) Improved methods for finding an appropriate \u03bb by line search methods have been proposed [45, 46].", "startOffset": 94, "endOffset": 102}, {"referenceID": 16, "context": "A special version of the gradient projection method is the generalized reduced method [17].", "startOffset": 86, "endOffset": 90}, {"referenceID": 17, "context": "The gradient projection method has been generalized by Rosen to non-linear constraints [18].", "startOffset": 87, "endOffset": 91}, {"referenceID": 18, "context": "Rosen\u2019s gradient projection method was improved by [19].", "startOffset": 51, "endOffset": 55}, {"referenceID": 15, "context": "2 Scaled Gradient Projection and Projected Newton Method Both the scaled gradient projection algorithm and the projected Newton method were proposed in [16].", "startOffset": 152, "endOffset": 156}, {"referenceID": 14, "context": "We follow [15].", "startOffset": 10, "endOffset": 14}, {"referenceID": 15, "context": "If we setH\u22121 = \u03a3p, then we have a Newton update of the projected Newton method [16].", "startOffset": 79, "endOffset": 83}, {"referenceID": 14, "context": "1 in [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "1 in [15]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "See [15].", "startOffset": 4, "endOffset": 8}, {"referenceID": 15, "context": "The projected Newton method uses \u03bb = 1 to set [16]: = \u2016\u03bck \u2212 P (\u03bcp) \u2016 .", "startOffset": 46, "endOffset": 50}, {"referenceID": 46, "context": "3 Combined Method Following [47, 46] we use the following very general update rule, which includes the gradient projection algorithm, the scaled gradient projection algorithm, and the projected Newton method.", "startOffset": 28, "endOffset": 36}, {"referenceID": 45, "context": "3 Combined Method Following [47, 46] we use the following very general update rule, which includes the gradient projection algorithm, the scaled gradient projection algorithm, and the projected Newton method.", "startOffset": 28, "endOffset": 36}, {"referenceID": 14, "context": "ensures an improvement if only using rectifying constraints according to the theory of projected Newton methods [15].", "startOffset": 112, "endOffset": 116}, {"referenceID": 23, "context": "S11 Hyperparameters Selected for Method Assessment The performance of rectified factor networks (RFNs) as unsupervised methods for data representation was compared with: (1) RFN: rectified factor networks, (2) RFNn: RFNs without normalization, (3) DAE: denoising autoencoders with rectified linear units, (4) RBM: restricted Boltzmann machines with Gaussian visible units and hidden binary units, (5) FAsp: factor analysis with Jeffrey\u2019s prior (p(z) \u221d 1/z) on the hidden units which is sparser than a Laplace prior, (6) FAlap: factor analysis with Laplace prior on the hidden units, (7) ICA: independent component analysis by FastICA [24], (8) SFA: sparse factor analysis with a Laplace prior on the parameters, (9) FA: standard factor analysis, (10) PCA: principal component analysis.", "startOffset": 634, "endOffset": 638}, {"referenceID": 7, "context": "Into these data matrices, structures are implanted as biclusters [8].", "startOffset": 65, "endOffset": 68}, {"referenceID": 31, "context": "S14 RFN Pretraining for Convolution Nets We assess the performance of RFN first layer pretraining on CIFAR-10 and CIFAR-100 for three deep convolutional network architectures: (i) the AlexNet [32], (ii) Deeply Supervised Networks (DSN) [33], and (iii) our 5-Convolution-Network-In-Network (5C-NIN).", "startOffset": 192, "endOffset": 196}, {"referenceID": 32, "context": "S14 RFN Pretraining for Convolution Nets We assess the performance of RFN first layer pretraining on CIFAR-10 and CIFAR-100 for three deep convolutional network architectures: (i) the AlexNet [32], (ii) Deeply Supervised Networks (DSN) [33], and (iii) our 5-Convolution-Network-In-Network (5C-NIN).", "startOffset": 236, "endOffset": 240}, {"referenceID": 47, "context": "Both datasets are preprocessed by global contrast normalization and ZCA whitening [48].", "startOffset": 82, "endOffset": 86}, {"referenceID": 27, "context": "For weight initialization, learning rates, and learning policies we used same strategy as in the AlexNet [28].", "startOffset": 105, "endOffset": 109}, {"referenceID": 47, "context": "For comparison, the lower panel of the table reports the performance of the currently top performing networks: Network In Network (NIN, [49]), Maxout Networks (MN, [48]) and DeepCNiN [50].", "startOffset": 164, "endOffset": 168}, {"referenceID": 48, "context": "For comparison, the lower panel of the table reports the performance of the currently top performing networks: Network In Network (NIN, [49]), Maxout Networks (MN, [48]) and DeepCNiN [50].", "startOffset": 183, "endOffset": 187}], "year": 2015, "abstractText": "We propose rectified factor networks (RFNs) to efficiently construct very sparse, non-linear, high-dimensional representations of the input. RFN models identify rare and small events in the input, have a low interference between code units, have a small reconstruction error, and explain the data covariance structure. RFN learning is a generalized alternating minimization algorithm derived from the posterior regularization method which enforces non-negative and normalized posterior means. We proof convergence and correctness of the RFN learning algorithm. On benchmarks, RFNs are compared to other unsupervised methods like autoencoders, RBMs, factor analysis, ICA, and PCA. In contrast to previous sparse coding methods, RFNs yield sparser codes, capture the data\u2019s covariance structure more precisely, and have a significantly smaller reconstruction error. We test RFNs as pretraining technique for deep networks on different vision datasets, where RFNs were superior to RBMs and autoencoders. On gene expression data from two pharmaceutical drug discovery studies, RFNs detected small and rare gene modules that revealed highly relevant new biological insights which were so far missed by other unsupervised methods.", "creator": "LaTeX with hyperref package"}}}