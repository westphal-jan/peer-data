{"id": "1502.06531", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Feb-2015", "title": "Scalable Variational Inference in Log-supermodular Models", "abstract": "We consider the problem of approximate Bayesian inference in log-supermodular models. These models encompass regular pairwise MRFs with binary variables, but allow to capture high-order interactions, which are intractable for existing approximate inference techniques such as belief propagation, mean field, and variants. We show that a recently proposed variational approach to inference in log-supermodular models -L-FIELD- reduces to the widely-studied minimum norm problem for submodular minimization. This insight allows to leverage powerful existing tools, and hence to solve the variational problem orders of magnitude more efficiently than previously possible. We then provide another natural interpretation of L-FIELD, demonstrating that it exactly minimizes a specific type of R\\'enyi divergence measure. This insight sheds light on the nature of the variational approximations produced by L-FIELD. Furthermore, we show how to perform parallel inference as message passing in a suitable factor graph at a linear convergence rate, without having to sum up over all the configurations of the factor. Finally, we apply our approach to a challenging image segmentation task. Our experiments confirm scalability of our approach, high quality of the marginals, and the benefit of incorporating higher-order potentials.", "histories": [["v1", "Mon, 23 Feb 2015 18:08:07 GMT  (1085kb,D)", "https://arxiv.org/abs/1502.06531v1", null], ["v2", "Tue, 24 Feb 2015 16:43:05 GMT  (1084kb,D)", "http://arxiv.org/abs/1502.06531v2", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["josip djolonga", "andreas krause 0001"], "accepted": true, "id": "1502.06531"}, "pdf": {"name": "1502.06531.pdf", "metadata": {"source": "META", "title": "Scalable Variational Inference in Log-supermodular Models", "authors": ["Josip Djolonga", "Andreas Krause"], "emails": ["JOSIPD@INF.ETHZ.CH", "KRAUSEA@ETHZ.CH"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "2. Background: Submodularity and log-supermodular models", "text": "It is a typical example of a model of this kind that can be used for the introduction. (...) It is as if it were a system, in which it is a system. (...) It is as if it were a system, in which it is a system. (...) It is as if it were a system, in which it is a system. (...) It is as if it were a system, in which it is a system. (...) It is as if it were a system, in which it is a system. (...) It is as if it were a system, in which it is a system. (...) It is as if it were a system, in which it is a system, in which it is a system. (...) It is as if it is a system, in which it is a system, in which it is a system. (...) It is as if it is a system, in which it is a system."}, {"heading": "3. Variational inference with L-FIELD", "text": "The main obstacle to performing inferences in logsupermodular models is the calculation of the normalization factor Z, also known as the partition function in statistical physics. We cannot calculate it directly, because we have to sum up all S-V, so we have to apply approximate techniques. A common approach is to define an optimization problem using some variation parameters q, so that we can calculate the quantity of interest by optimizing this problem. We are now reviewing the variational approximation technology recently introduced by Djolonga & Krause (2014), whose method is based on two main observations: (i) modular functions have analytical log partition functions and (ii) submodular functions can be limited by modular functions. The main idea is the following: If it holds that the A-V: s (A) -V variations (A) V variations will have, then it will be safe."}, {"heading": "4. L-FIELD \u2261Minimum norm point.", "text": "Our first main contribution is the following, perhaps surprising result: Theorem 2. Problems (4) and (3) have the same solution.The proof of this theorem (given in the appendix) depends crucially on the specific characteristics of the base polytop.Similar results have been shown (for other goals) by Nagano & Aihara (2012).This theorem has three immediate, extremely important consequences: First, since the minimum standard point approach is often the method of choice for submodular minimization! Second, in view of this equivalence and theorem 1, we can immediately see that we can reduce the costs of solving many MAP problems to a single minimum standard point problem that leads to significant performance gains - a factor of O (| V |) if we seek the optimal variation solution! Second, in view of this equivalence and theorem 1, we can immediately see that we can actually extract the MAP solution by reversing the marginal solutions to 2.1 / 2.1 dollar point."}, {"heading": "5. The divergence minimization perspective", "text": "The L-FIELD approach directly attacks the partition function. Of course, you can use the factorized distribution Q (Q) Q (Q) Q (Re) Q (Re) Q (Re) Q (Re) Q (Re) Q (Re) Q (Re) Q (Re) Q (Re) Q) Q (Re) Q (Re) Q (Re) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q (Re) Q (Re) Q) Q (Re) Q (Re) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q (Re) Q) Q) Q) Q (Re) Q) Q (Re) Q) Q (Re) Q (Re) Q) Q) Q (Re) Q) Q (Re) Q) Q) Q (Re) Q) Q (Re) Q (Re) Q"}, {"heading": "6. Parallel inference for decomposable models", "text": "In fact, the examples that we have discussed in this form, both in the form, as well as in the way, in which we look at ourselves in the way, how we look at them in the way, how we look at them in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way, how they look in the way they look in the way, how they look in the way they look in the way, how they look in the way they look, how they look in the way they look in the way, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look, how they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look, how they look in the way they look, how they look, how they look in the way they look, how they look in the way they look, how they look, how they look in the way they look in the way they look, how they look, how they look, how they look in the way they look in the way they look, how they look in the way they look, how they look, how they look, how they look in the way they look, how they look in the way they look, how they look in the way they look, how they look in the way they look in the way they look,"}, {"heading": "7. Experiments", "text": "The aim of our experiments is to test the scalability of our approach to major problems and to evaluate the quality of the margins both qualitatively and quantitatively. We used data from Jegelka & Bilmes (2011), which contain a total of 36 images, each with a very detailed (pixel-level precision) down-to-earth truth segmentation. Due to the intractability, we cannot calculate the exact margins against which we would ideally like to compare. As an example of measuring the quality of the approximations, we use the area below the ROC curve (AUC) as a comparison of truth segmentation. We independently classify each pixel as background or background by comparing its approximate marginal values against a threshold that we vary use to obtain the ROC curve."}, {"heading": "8. Conclusion", "text": "Building on Djolonga & Krause's L-FIELD approach (2014), we have established two natural, important interpretations of their method: first, we have shown how L-FIELD can be reduced to solving the well-studied minimum standard point problem, making a plethora of tools from submodular optimization suddenly available for approximate Bayesian conclusions; second, we have shown that the factorized distributions returned by L-FIELD minimize a certain type of information divergence; both theoretical combinations are immediately algorithmically useful; and finally, we have demonstrated our approach to a sophisticated image segmentation task. Using the minimum standard link, we have demonstrated strong convergence rates for a natural parallel approach, with convergence rates depending on the factor graph structure; and finally, we have demonstrated our approach to a sophisticated image segmentation task."}, {"heading": "A. Theory", "text": "(A)..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "B. Proofs for Section 6", "text": "We will first define a dual formulation of the minimization problem for which we have a complete problem. (We will use the set of all valid Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-Vi-V"}, {"heading": "C. Experiments", "text": "We have used the parameter values in the table below. Parameter values \u03b8 0.1, 0.001, 0.0001 \u03b1 1, 0.1, 0.01, 0.001 \u03b2 10, 1, 0.1, 0.01, 0.001 \u03b3 10, 1, 0.1, 0.01, 0.01, 0.001"}], "references": [{"title": "Learning with submodular functions: a con", "author": ["Bach", "Francis"], "venue": null, "citeRegEx": "Bach and Francis.,? \\Q2010\\E", "shortCiteRegEx": "Bach and Francis.", "year": 2010}, {"title": "Modular proximal optimization for multidimensional total-variation regularization", "author": ["Barbero", "\u00c1lvaro", "Sra", "Suvrit"], "venue": null, "citeRegEx": "Barbero et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Barbero et al\\.", "year": 2014}, {"title": "Fast Newton-type methods for total variation regularization", "author": ["Barbero", "lvaro", "Sra", "Suvrit"], "venue": "In ICML, pp", "citeRegEx": "Barbero et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Barbero et al\\.", "year": 2011}, {"title": "Convex Optimization", "author": ["Boyd", "Stephen P", "Vandenberghe", "Lieven"], "venue": null, "citeRegEx": "Boyd et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2004}, {"title": "Greedy dictionary selection for sparse representation", "author": ["Cevher", "Volkan", "Krause", "Andreas"], "venue": "IEEE Journal of Selected Topics in Signal Processing,", "citeRegEx": "Cevher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cevher et al\\.", "year": 2011}, {"title": "Provable submodular minimization using Wolfe\u2019s algorithm", "author": ["Chakrabarty", "Deeparnab", "Jain", "Prateek", "Kothari", "Pravesh"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Chakrabarty et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chakrabarty et al\\.", "year": 2014}, {"title": "Mean shift: A robust approach toward feature space analysis", "author": ["Comaniciu", "Dorin", "Meer", "Peter"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Comaniciu et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Comaniciu et al\\.", "year": 2002}, {"title": "From MAP to marginals: Variational inference in Bayesian submodular models", "author": ["Djolonga", "Josip", "Krause", "Andreas"], "venue": "In Neural Information Processing Systems (NIPS),", "citeRegEx": "Djolonga et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Djolonga et al\\.", "year": 2014}, {"title": "Submodular functions, matroids, and certain polyhedra", "author": ["Edmonds", "Jack"], "venue": "Combinatorial structures and their applications,", "citeRegEx": "Edmonds and Jack.,? \\Q1970\\E", "shortCiteRegEx": "Edmonds and Jack.", "year": 1970}, {"title": "Lexicographically optimal base of a polymatroid with respect to a weight vector", "author": ["Fujishige", "Satoru"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Fujishige and Satoru.,? \\Q1980\\E", "shortCiteRegEx": "Fujishige and Satoru.", "year": 1980}, {"title": "Submodular functions and optimization, volume", "author": ["Fujishige", "Satoru"], "venue": "Annals of Discrete Mathematics", "citeRegEx": "Fujishige and Satoru.,? \\Q2005\\E", "shortCiteRegEx": "Fujishige and Satoru.", "year": 2005}, {"title": "The complexity of ferromagnetic ising with local fields", "author": ["Goldberg", "Leslie Ann", "Jerrum", "Mark"], "venue": "Combinatorics, Probability and Computing,", "citeRegEx": "Goldberg et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2007}, {"title": "Submodularity beyond submodular energies: coupling edges in graph cuts", "author": ["Jegelka", "Stefanie", "Bilmes", "Jeff"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Jegelka et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jegelka et al\\.", "year": 2011}, {"title": "Reflection methods for user-friendly submodular optimization", "author": ["Jegelka", "Stefanie", "Bach", "Francis", "Sra", "Suvrit"], "venue": "In NIPS,", "citeRegEx": "Jegelka et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Jegelka et al\\.", "year": 2013}, {"title": "Polynomial-time approximation algorithms for the ising model", "author": ["Jerrum", "Mark", "Sinclair", "Alistair"], "venue": "SIAM Journal on computing,", "citeRegEx": "Jerrum et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Jerrum et al\\.", "year": 1993}, {"title": "Robust higher order potentials for enforcing label consistency", "author": ["Kohli", "Pushmeet", "Ladick\u00fd", "L\u2019ubor", "Torr", "Philip H.S"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Kohli et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kohli et al\\.", "year": 2009}, {"title": "Near-optimal nonmyopic value of information in graphical models", "author": ["Krause", "Andreas", "Guestrin", "Carlos"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Krause et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2005}, {"title": "Determinantal point processes for machine learning", "author": ["A. Kulesza", "B. Taskar"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Kulesza and Taskar,? \\Q2012\\E", "shortCiteRegEx": "Kulesza and Taskar", "year": 2012}, {"title": "Divergence measures and message passing", "author": ["Minka", "Tom"], "venue": "Technical report, Technical report, Microsoft Research,", "citeRegEx": "Minka and Tom,? \\Q2005\\E", "shortCiteRegEx": "Minka and Tom", "year": 2005}, {"title": "libDAI: A free and open source C++ library for discrete approximate inference in graphical models", "author": ["Mooij", "Joris M"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Mooij and M.,? \\Q2010\\E", "shortCiteRegEx": "Mooij and M.", "year": 2010}, {"title": "Equivalence of convex minimization problems over base polytopes", "author": ["Nagano", "Kiyohito", "Aihara", "Kazuyuki"], "venue": "Japan journal of industrial and applied mathematics,", "citeRegEx": "Nagano et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nagano et al\\.", "year": 2012}, {"title": "On the convergence rate of decomposable submodular function minimization", "author": ["Nishihara", "Robert", "Jegelka", "Stefanie", "Jordan", "Michael I"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Nishihara et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nishihara et al\\.", "year": 2014}, {"title": "A faster strongly polynomial time algorithm for submodular function minimization", "author": ["Orlin", "James B"], "venue": "Mathematical Programming,", "citeRegEx": "Orlin and B.,? \\Q2009\\E", "shortCiteRegEx": "Orlin and B.", "year": 2009}, {"title": "Fusion, propagation, and structuring in belief networks", "author": ["Pearl", "Judea"], "venue": "Artificial intelligence,", "citeRegEx": "Pearl and Judea.,? \\Q1986\\E", "shortCiteRegEx": "Pearl and Judea.", "year": 1986}, {"title": "On measures of entropy and information", "author": ["R\u00e9nyi", "Alfr\u00e9d"], "venue": "In Fourth Berkeley symposium on mathematical statistics and probability,", "citeRegEx": "R\u00e9nyi and Alfr\u00e9d.,? \\Q1961\\E", "shortCiteRegEx": "R\u00e9nyi and Alfr\u00e9d.", "year": 1961}, {"title": "Efficient minimization of decomposable submodular functions", "author": ["Stobbe", "Peter", "Krause", "Andreas"], "venue": "In Proc. Neural Information Processing Systems (NIPS),", "citeRegEx": "Stobbe et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Stobbe et al\\.", "year": 2010}, {"title": "R\u00e9nyi divergence and Kullback-Leibler divergence", "author": ["Van Erven", "Tim", "Harremo\u00ebs", "Peter"], "venue": "arXiv preprint arXiv:1206.2459,", "citeRegEx": "Erven et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Erven et al\\.", "year": 2012}, {"title": "Graphical models, exponential families, and variational inference", "author": ["Wainwright", "Martin J", "Jordan", "Michael I"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "Wainwright et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Wainwright et al\\.", "year": 2008}, {"title": "To compute the Friedrich\u2019s angle we are interested in the singular values of ST (Nishihara et al., 2014)[Lemma", "author": [], "venue": null, "citeRegEx": ".,? \\Q2014\\E", "shortCiteRegEx": ".", "year": 2014}], "referenceMentions": [{"referenceID": 15, "context": "One strategy to generate the regions, used by Kohli et al. (2009) is to generate superpixels, as illustrated on Figure 1.", "startOffset": 46, "endOffset": 66}, {"referenceID": 5, "context": "An algorithm that performs better in practice, but only has a pseudopolynomial running time guarantee (Chakrabarty et al., 2014), is the Fujishige-Wolfe algorithm (Fujishige, 1980).", "startOffset": 102, "endOffset": 128}, {"referenceID": 13, "context": "This problem \u2013 L-FIELD \u2013 can be then solved using the divide-and-conquer algorithm (Bach, 2013; Jegelka et al., 2013) by solving at most O(min{|V |, log 1 }) MAP problems, where is the tolerated error on the marginals.", "startOffset": 83, "endOffset": 117}, {"referenceID": 12, "context": ", by Stobbe & Krause (2010) and Jegelka et al. (2013). The decomposition implies that the corresponding distribution factorizes as follows", "startOffset": 32, "endOffset": 54}, {"referenceID": 12, "context": "An alternative is to apply an approach used by Jegelka et al. (2013), which allows to perform message passing in parallel without losing the convergence guarantees.", "startOffset": 47, "endOffset": 69}, {"referenceID": 12, "context": "An alternative is to apply an approach used by Jegelka et al. (2013), which allows to perform message passing in parallel without losing the convergence guarantees. Jegelka et al. (2013) assume that all factors depend on all variables (i.", "startOffset": 47, "endOffset": 187}, {"referenceID": 19, "context": "Based on recent new results by Nishihara et al. (2014) on block coordinate descent for a similar dual (assuming that all factors depend on all variables, as considered by Jegelka et al.", "startOffset": 31, "endOffset": 55}, {"referenceID": 12, "context": "(2014) on block coordinate descent for a similar dual (assuming that all factors depend on all variables, as considered by Jegelka et al. (2013)), we extend their analysis to obtain a linear convergence rate for our message passing scheme.", "startOffset": 123, "endOffset": 145}, {"referenceID": 12, "context": "(2014) on block coordinate descent for a similar dual (assuming that all factors depend on all variables, as considered by Jegelka et al. (2013)), we extend their analysis to obtain a linear convergence rate for our message passing scheme. Theorem 4 (Extension of Nishihara et al. (2014)).", "startOffset": 123, "endOffset": 288}, {"referenceID": 13, "context": "\u2022 Our approach using only pairwise potentials (\u03b3 = 0), solved using the total variation Douglas-Rachford (DR) code from (Barbero & Sra, 2011; 2014; Jegelka et al., 2013).", "startOffset": 120, "endOffset": 169}], "year": 2015, "abstractText": "We consider the problem of approximate Bayesian inference in log-supermodular models. These models encompass regular pairwise MRFs with binary variables, but allow to capture highorder interactions, which are intractable for existing approximate inference techniques such as belief propagation, mean field, and variants. We show that a recently proposed variational approach to inference in log-supermodular models \u2013L-FIELD\u2013 reduces to the widely-studied minimum norm problem for submodular minimization. This insight allows to leverage powerful existing tools, and hence to solve the variational problem orders of magnitude more efficiently than previously possible. We then provide another natural interpretation of L-FIELD, demonstrating that it exactly minimizes a specific type of R\u00e9nyi divergence measure. This insight sheds light on the nature of the variational approximations produced by L-FIELD. Furthermore, we show how to perform parallel inference as message passing in a suitable factor graph at a linear convergence rate, without having to sum up over all the configurations of the factor. Finally, we apply our approach to a challenging image segmentation task. Our experiments confirm scalability of our approach, high quality of the marginals, and the benefit of incorporating higher-order potentials.", "creator": "LaTeX with hyperref package"}}}