{"id": "1502.07645", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Feb-2015", "title": "Privacy for Free: Posterior Sampling and Stochastic Gradient Monte Carlo", "abstract": "We consider the problem of Bayesian learning on sensitive datasets and present two simple but somewhat surprising results that connect Bayesian learning to \"differential privacy:, a cryptographic approach to protect individual-level privacy while permiting database-level utility. Specifically, we show that that under standard assumptions, getting one single sample from a posterior distribution is differentially private \"for free\". We will see that estimator is statistically consistent, near optimal and computationally tractable whenever the Bayesian model of interest is consistent, optimal and tractable. Similarly but separately, we show that a recent line of works that use stochastic gradient for Hybrid Monte Carlo (HMC) sampling also preserve differentially privacy with minor or no modifications of the algorithmic procedure at all, these observations lead to an \"anytime\" algorithm for Bayesian learning under privacy constraint. We demonstrate that it performs much better than the state-of-the-art differential private methods on synthetic and real datasets.", "histories": [["v1", "Thu, 26 Feb 2015 17:38:47 GMT  (219kb,D)", "https://arxiv.org/abs/1502.07645v1", null], ["v2", "Sun, 12 Apr 2015 02:53:05 GMT  (223kb,D)", "http://arxiv.org/abs/1502.07645v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["yu-xiang wang", "stephen e fienberg", "alexander j smola"], "accepted": true, "id": "1502.07645"}, "pdf": {"name": "1502.07645.pdf", "metadata": {"source": "CRF", "title": "Privacy for Free: Posterior Sampling and Stochastic Gradient Monte Carlo", "authors": ["Yu-Xiang Wang", "Stephen E. Fienberg", "Alex Smola"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 150 2.07 645v 2 [stat.ML] contents"}, {"heading": "1 Introduction 3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2 Notations and Preliminary 4", "text": "2.1 Different privacy..............................................."}, {"heading": "3 Posterior sampling and differential privacy 5", "text": "3.1 Implicit maintenance of differential privacy..........................................................................................................."}, {"heading": "4 Stochastic Gradient MCMC and ( , \u03b4)-Differential privacy 12", "text": "....................................................................................................................................."}, {"heading": "5 Experiments 20", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6 Related work 22", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7 Conclusion and future work 23", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A Stochastic Gradient Fisher Scoring 23", "text": "A.1 Fisher scoring and stochastic gradient Fisher scoring............ 23 A.2 Privacy extension..........................................."}, {"heading": "1 Introduction", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves, \"he said in an interview with the\" New York Times. \"\" I do not think that I see myself in a position to survive myself, \"he said in an interview with the\" New York Times. \"\" I do not believe that I am able to change the world, \"he said in an interview with the\" New York Times, \"\" New York, \"\" New York, \"New York,\" New York, \"New York,\" New York Times, \"\" New York, \"New York Times,\" \"New York,\" New York, \"\" New York, \"New York,\" New York Times, \"\" New York, \"New York,\" New York, \"New York Times,\" New York Times, \"New York Times,\" New York Times, \"New York Times,\" New York, \"New York, New York, New York, New York, New York, New York,\" New York, \"New York,\" New York, \"New York,\" New York, \"New York,\" New York Times, \"New York,\" New York, \"New York Times,\" New York, \"New York,\" New York Times, \"New York,\" New York, \"New York Times,\" New York, \"New York Times,\" New York, \"New York,\" New York Times, \"New York,\" New York Times, \"New York,\" New York Times, \"New York,\" New York Times, \"New York,\" New York Times, \"New York, New York,\" New York Times, \"New York, New York Times,\" New York, New York, \"New York Times,\" New York, New York Times, New York, New York Times, \"New York,\" New York Times, New York, New York, New York Times, New York Times, New York, New York, New York Times, New York, New York Times, New York, New York, New York Times, New York Times, New York, New York, New York Times, New York, New York Times, New York, New York, New York Times, New York Times, New York Times, New York, New York, New York, New York Times, New York Times, New York, New York, New York Times, New York, New"}, {"heading": "2 Notations and Preliminary", "text": "This can be the finite dimensional parameter of a single exponential family model or a collection of these parameters in a graphical model, or a function in a Hilbert space or other infinite dimensional objects if the model is not parametric. If we observe X = {x1,..., xn}, the posterior distribution method (x | 3) and \"(x | 3) show the probability and log probability of observing data point x given model parameters. If we observe X = {x1,..., xn}, the posterior distribution method Gravations (x | 3) shows the probability and log probability of observing data point x (xi | 4)."}, {"heading": "2.1 Differential privacy", "text": "Now we will talk about what we need to know about differential privacy. Leave data space X and data points X, Y and X n. Define d (X, Y) as processing distance or hamming distance between data set X and Y, for example, if X and Y are equal except for one data point, then d (X, Y) = 1. Definition 1. (Differential privacy) We call a randomized algorithm A (, \u03b4) -differentiated private with domain X n, if for all measurable data sets S range (A) and for all X, Y and X-X n such that d (X, Y) \u2264 1, we have P (A (X) and S () \u2264 exp () P (A (Y) and S (S)."}, {"heading": "If \u03b4 = 0, then A is the called -differential private.", "text": "The promise of differential privacy has been interpreted in statistical tests, Byesian inference, and information theory, for which we refer readers to Chapter 1 of (Dwork & Roth, 2013). There are several interesting features of differential privacy that we will exploit here. First, the definition is closed in post-processing. Lemma 2 (Postprocessing Immunity). If A is a (, \u03b4) -DP algorithm, B \u0445 A is also (, \u03b4) -DP algorithm for each B. This is natural, because otherwise the entire point of differential privacy is forfeited. Also, the definition automatically allows cases where sensitive data is accessed more than once. Lemma 3 (Composition Rule). If algorithm A1 (1, \u03b41) -DP and A2 (2) -DP (then A1 + D1) are described as more progressive."}, {"heading": "3 Posterior sampling and differential privacy", "text": "In this section, we make a simple observation that under the condition of the limit value of a log probability, a single sample from the posterior distribution (hereafter referred to as the \"OPS mechanism\") retains a certain degree of differential privacy free of charge. We then quote classical statistical results and show that this sample is a consistent estimator in the most common sense and in many cases nearly optimal."}, {"heading": "3.1 Implicitly Preserving Differential Privacy", "text": "To start with, we show that the sampling method from the rear distribution can be considered intrinsically differentiated (...) Theorem 4: If X is a limited domain (e.g. that it is a limited domain (e.g. that X is a limited domain) and Log p (x) and Log p (x) is an L-Lipschitz function in all previous contexts, then the release of a single sample from the rear distribution (e.g. x) will take place. Proof 4: The rear distribution p (xn) is an L-Lipschitz function in all previous contexts, then the release of a single sample will take place from the rear distribution. Proof 6: Proof 4: The rear distribution p (xn) is an L-Lipschitz function in all previous contexts, then an L-Lipschitz function will take place in all previous contexts."}, {"heading": "3.2 Consistency and Near-Optimality", "text": "In great generality, we will show that the one-to-one estimator is consistent whenever the Bayesian model is consistent, when consistency in Bayesian methods can have different meanings, we will briefly describe two of them according to the nomenclature in Orbanz (2012). Definition 5 (Posterior consistency in Bayesian sense) is consistent if the model is consistent in the Bayesian sense, if the nomenclature in Orbanz (2012), the definition 5 (Posterior consistency in Bayesian sense). Definition 5 (Posterior consistency in Bayesian sense) is weak if the model is consistent in Bayesian sense, if the consistency in Bayesian sense is weak (x1, xn)."}, {"heading": "3.3 (Efficient) sampling from approximate posterior", "text": "The privacy guarantee in Theorem 4 requires scanning from the exact posterior level. In practice, however, exact scanners are rare. As Bayesian models become increasingly complicated, the only viable option is to use Markov Chain Monte Carlo (MCMC) scanners that are almost never accurate. There are exceptions, such as Propp & Wilson (1998), but they only apply to problems with very specific structures. A natural question that needs to be asked is whether we can still say anything meaningful about privacy if the posterior scanning is inaccurate. It turns out that we can do this, and the level of approximation in the privacy is the same as the level of approximation in the scanning in the dissemination. Proposition 10: If a scanning from the distribution preserves PX-different privacy, then any uncompromised scanning of method A that generates a sample of P-X-X is ineffective."}, {"heading": "3.4 Discussions and comparisons", "text": "OPS has a number of advantages over the modern, differentiated private ERM method: objective disturbances (Chaudhuri et al., 2011; Kifer et al., 2012) (from here ObjPert). OPS operates with arbitrarily limited loss functions and priors, while ObjPert requires a number of restrictive assumptions, including double-differentiated loss functions, strongly convex parameters that can be greater than a threshold, etc. These limitations exclude many commonly used loss functions, e.g. '1 loss, hinge loss, huber function, to name a few. Moreover, ObjPert's privacy guarantee only applies to the exact optimal solution, which is often difficult to implement in practice. In contrast, OPS works when the sample is taken from an approximate posterior distribution. From a practical point of view, since OPS stems from the intrinsic protection of the privacy of Bayean learning, it requires very little effort to implement it for practical applications."}, {"heading": "4 Stochastic Gradient MCMC and ( , \u03b4)-Differential privacy", "text": "Given a fixed privacy budget, we see that the single posterior sample produces an optimal score estimate, but what if we want multiple samples? Can we use the privacy budget in a different way that produces many approximate posterior samples? In this section, we will provide an answer by looking at a class of Stochastic Gradient MCMC techniques that have been developed in recent years. We will show that they are also differentiated private if the parameters are appropriately chosen. (2014) The idea is simply to make a private estimate of the gradient (as in Song et al. (2013); Bassily et al. (2014) and the use of the following two celebrated lexicographs in differential privacy in the same way as Bassily et al. (2014) to derive the near-optimal gradient (as in Lemain) -differentiated private SGD. The first problem is the advanced composition that allows us to exchange a small amount of money for privacy."}, {"heading": "4.1 Stochastic Gradient Langevin Dynamics", "text": "The SGLD data will be able to process the SGLD data. < p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p"}, {"heading": "In addition, let , \u03b4, \u03c4, T be chosen such that T \u2265 2N32\u03c4 log(2/\u03b4) . Then Algorithm 2 preserves", "text": "(\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\" (\"We.\"). (\"We.\" (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We.\" (\"We.\"). (\"We.\"). (\"We. (\" We. \"). (\" We. (\"). (\" We. (\"We.). (\"). (\"We. (\"). (\"We. (\"). (\"We. (\"). (\"We. (\" We.). (\"(\" We.). (\"We. (\"). (\"). (\" We.). (\"We.). (\" (\"We. (\" (\"We.).). (\" (\"(\" (\"We.). (\" We.). (\"We.). (\" (. (.). (\"We.). (\" (\"(.). (\" We.). (\"(.). (\" We.). (\"We. (. (\" We.). (. (.). (. (\"(\" We.). (.). (.). (\"We. (\" (\"We.). (.). (. (. (.). (\" We.). (\"We. (.). (. (.)."}, {"heading": "4.2 Hamiltonian Dynamics, Fisher Scoring and Nose-Hoover Thermostat", "text": "One of the practical disadvantages of the SGLD is its random behavior, which slows down the mixing of space and space. (...) In this section, we describe three extensions of the SGLD, which try to solve the problem by selecting the different distribution quantities (Ahn et al., 2012). (...) We point out that in all these methods stochastic gradients are the only form of data access, i.e. similar results to what we have described for SGLD. (...) We briefly describe each method and how to select its different distribution quantities. (...) Stochastic gradients Hamiltonian Monte Carlo after Neal (2011), Langevin Dynamics is a special limiting case of Hamiltonian Dynamics, where one can simply ignore the \"dynamics.\""}, {"heading": "4.3 Discussions and caveats.", "text": "So far, so good."}, {"heading": "5 Experiments", "text": "Figure 1 is a simple illustration of how these stochastic gradient samplers work using a randomly generated linear regression model (note the posterior distribution will be normal, as the contour shows). On the left, it shows how these methods converge like stochastic gradient descent into the pool of convergence. Then, it becomes a posterior sampler. On the right, the figure shows that the stochastic gradient thermostat is able to produce more precise / unbiased results and the effects of differential privacy at the level of = 10 is neglected. To evaluate how our proposed methods work in practice, we chose two binary classification datasets: Abalone and Adult, from the first page of the UCI Machine Learning Repository and conducted Privacy Restricted Logistic Regression on them."}, {"heading": "6 Related work", "text": "In fact, it is the case that most people are able to survive themselves and themselves if they go to another world. (...) It is not as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world. (...) It is as if they go to another world."}, {"heading": "7 Conclusion and future work", "text": "In this paper, we have described two simple but conceptually interesting examples of how Bayesian learning can be differentiated by nature. Specifically, we show that taking a sample from the posterior region is a special case of exponential mechanisms, and that this sample, as an estimator of parametric learning, is nearly optimal. On the other hand, we show that the algorithmic methods of stochastic gradient-Langevin dynamics (and variants) that attempt to experiment from the posterior region also guarantee differential privacy as a by-product. Preliminary experiments suggest that the one-posterior sample mechanism works very well in practice and clearly outperforms the earlier mechanism of privacy in logistical regression."}, {"heading": "A Stochastic Gradient Fisher Scoring", "text": "The Score function S (\u03b8) is the gradient of the Logarized Score function (or a quadratic approximation of the probability calculus) of Taylor Expansion it at the current point \u03b80S (takeover).The Score function is highly non-linear, so we consider the iterative update for the linearized score function (or a quadratic approximation of the probability number) of Taylor Expansion it it it at the current point \u04450S (takeover).The Score function is highly non-linear, so we consider the iterative update for the linearized score function (or a quadratic approximation of the probability number) of Taylor Expansion it it at it at it at it at it at it at it at it at it at it at it at."}], "references": [{"title": "Bayesian posterior sampling via stochastic gradient fisher scoring", "author": ["S. Ahn", "A. Korattikara", "M. Welling"], "venue": "In Proceedings of the 29th International Conference on Machine Learning (ICML-12)", "citeRegEx": "Ahn et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ahn et al\\.", "year": 2012}, {"title": "Mixed membership stochastic blockmodels", "author": ["E.M. Airoldi", "D.M. Blei", "S.E. Fienberg", "E.P. Xing"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Airoldi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Airoldi et al\\.", "year": 2009}, {"title": "Sampling and integration of near log-concave functions", "author": ["D. Applegate", "R. Kannan"], "venue": "In Proceedings of the twenty-third annual ACM symposium on Theory of computing , (pp. 156\u2013163)", "citeRegEx": "Applegate and Kannan,? \\Q1991\\E", "shortCiteRegEx": "Applegate and Kannan", "year": 1991}, {"title": "Private empirical risk minimization, revisited", "author": ["R. Bassily", "A. Smith", "A. Thakurta"], "venue": null, "citeRegEx": "Bassily et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bassily et al\\.", "year": 2014}, {"title": "Bounds on the sample complexity for private learning and private data release", "author": ["A. Beimel", "H. Brenner", "S.P. Kasiviswanathan", "K. Nissim"], "venue": "Machine learning ,", "citeRegEx": "Beimel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Beimel et al\\.", "year": 2014}, {"title": "Predictability, complexity, and learning", "author": ["W. Bialek", "I. Nemenman", "N. Tishby"], "venue": "Neural computation,", "citeRegEx": "Bialek et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Bialek et al\\.", "year": 2001}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Chaudhuri et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2011}, {"title": "Stochastic Gradient Hamiltonian Monte Carlo", "author": ["T. Chen", "E.B. Fox", "C. Guestrin"], "venue": "In Proceeding of 31th International Conference on Machine Learning (ICML\u201914)", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Bayesian asymptotics with misspecified models", "author": ["P. De Blasi", "S.G. Walker"], "venue": "Statistica Sinica,", "citeRegEx": "Blasi and Walker,? \\Q2013\\E", "shortCiteRegEx": "Blasi and Walker", "year": 2013}, {"title": "Robust and private bayesian inference", "author": ["C. Dimitrakakis", "B. Nelson", "A. Mitrokotsa", "B.I. Rubinstein"], "venue": "In Algorithmic Learning Theory ,", "citeRegEx": "Dimitrakakis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dimitrakakis et al\\.", "year": 2014}, {"title": "Bayesian sampling using stochastic gradient thermostats", "author": ["N. Ding", "Y. Fang", "R. Babbush", "C. Chen", "R.D. Skeel", "H. Neven"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Ding et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ding et al\\.", "year": 2014}, {"title": "Differential privacy", "author": ["C. Dwork"], "venue": "Proceedings of the 33rd international conference on Automata, Languages and Programming-Volume Part II , (pp. 1\u201312). Springer-Verlag.", "citeRegEx": "Dwork,? 2006", "shortCiteRegEx": "Dwork", "year": 2006}, {"title": "Preserving statistical validity in adaptive data analysis", "author": ["C. Dwork", "V. Feldman", "M. Hardt", "T. Pitassi", "O. Reingold", "A. Roth"], "venue": null, "citeRegEx": "Dwork et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2014}, {"title": "Differential privacy and robust statistics", "author": ["C. Dwork", "J. Lei"], "venue": "In Proceedings of the forty-first annual ACM symposium on Theory of computing , (pp. 371\u2013380)", "citeRegEx": "Dwork and Lei,? \\Q2009\\E", "shortCiteRegEx": "Dwork and Lei", "year": 2009}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["C. Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "In Theory of cryptography ,", "citeRegEx": "Dwork et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "The algorithmic foundations of differential privacy", "author": ["C. Dwork", "A. Roth"], "venue": "Theoretical Computer Science,", "citeRegEx": "Dwork and Roth,? \\Q2013\\E", "shortCiteRegEx": "Dwork and Roth", "year": 2013}, {"title": "A bayesian hierarchical model for learning natural scene categories", "author": ["L. Fei-Fei", "P. Perona"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Fei.Fei and Perona,? \\Q2005\\E", "shortCiteRegEx": "Fei.Fei and Perona", "year": 2005}, {"title": "Stochastic relaxation, gibbs distributions, and the bayesian restoration of images. Pattern Analysis and Machine Intelligence", "author": ["S. Geman", "D. Geman"], "venue": "IEEE Transactions on,", "citeRegEx": "Geman and Geman,? \\Q1984\\E", "shortCiteRegEx": "Geman and Geman", "year": 1984}, {"title": "The Dirichlet process, related priors and posterior asymptotics, vol", "author": ["S. Ghosal"], "venue": "2. Chapter.", "citeRegEx": "Ghosal,? 2010", "shortCiteRegEx": "Ghosal", "year": 2010}, {"title": "Riemann manifold langevin and hamiltonian monte carlo methods", "author": ["M. Girolami", "B. Calderhead"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Girolami and Calderhead,? \\Q2011\\E", "shortCiteRegEx": "Girolami and Calderhead", "year": 2011}, {"title": "Monte carlo sampling methods using markov chains and their applications", "author": ["W.K. Hastings"], "venue": "Biometrika, 57 (1), 97\u2013109.", "citeRegEx": "Hastings,? 1970", "shortCiteRegEx": "Hastings", "year": 1970}, {"title": "Kernel methods in machine learning", "author": ["T. Hofmann", "B. Sch\u00f6lkopf", "A.J. Smola"], "venue": "The annals of statistics,", "citeRegEx": "Hofmann et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hofmann et al\\.", "year": 2008}, {"title": "On the\u2019semantics\u2019 of differential privacy: A bayesian formulation", "author": ["S.P. Kasiviswanathan", "A. Smith"], "venue": "Journal of Privacy and Confidentiality ,", "citeRegEx": "Kasiviswanathan and Smith,? \\Q2014\\E", "shortCiteRegEx": "Kasiviswanathan and Smith", "year": 2014}, {"title": "Private convex empirical risk minimization and high-dimensional regression", "author": ["D. Kifer", "A. Smith", "A. Thakurta"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Kifer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kifer et al\\.", "year": 2012}, {"title": "The bernstein-von-mises theorem under misspecification", "author": ["B. Kleijn", "A van der Vaart"], "venue": "Electronic Journal of Statistics,", "citeRegEx": "Kleijn and Vaart,? \\Q2012\\E", "shortCiteRegEx": "Kleijn and Vaart", "year": 2012}, {"title": "On the Bernstein-von Mises theorem", "author": ["L.M. Le Cam"], "venue": "Department of Statistics, University of California.", "citeRegEx": "Cam,? 1986", "shortCiteRegEx": "Cam", "year": 1986}, {"title": "Testing statistical hypotheses", "author": ["E.L. Lehmann", "J.P. Romano"], "venue": null, "citeRegEx": "Lehmann and Romano,? \\Q2006\\E", "shortCiteRegEx": "Lehmann and Romano", "year": 2006}, {"title": "Mechanism design via differential privacy", "author": ["F. McSherry", "K. Talwar"], "venue": "In Foundations of Computer Science,", "citeRegEx": "McSherry and Talwar,? \\Q2007\\E", "shortCiteRegEx": "McSherry and Talwar", "year": 2007}, {"title": "Differential privacy: an exploration of the privacy-utility landscape", "author": ["D.J. Mir"], "venue": "Ph.D. thesis, Rutgers University.", "citeRegEx": "Mir,? 2013", "shortCiteRegEx": "Mir", "year": 2013}, {"title": "Mcmc using hamiltonian dynamics", "author": ["R. Neal"], "venue": "Handbook of Markov Chain Monte Carlo, 2 .", "citeRegEx": "Neal,? 2011", "shortCiteRegEx": "Neal", "year": 2011}, {"title": "Lecture notes on bayesian nonparametrics", "author": ["P. Orbanz"], "venue": "Journal of Mathematical Psychology , 56 , 1\u201312.", "citeRegEx": "Orbanz,? 2012", "shortCiteRegEx": "Orbanz", "year": 2012}, {"title": "Statistical parametric mapping: the analysis of functional brain images: the analysis of functional brain", "author": ["W.D. Penny", "K.J. Friston", "J.T. Ashburner", "S.J. Kiebel", "T.E. Nichols"], "venue": null, "citeRegEx": "Penny et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Penny et al\\.", "year": 2011}, {"title": "Coupling from the past: a users guide", "author": ["J. Propp", "D. Wilson"], "venue": "Microsurveys in Discrete Probability ,", "citeRegEx": "Propp and Wilson,? \\Q1998\\E", "shortCiteRegEx": "Propp and Wilson", "year": 1998}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["L. Rabiner"], "venue": "Proceedings of the IEEE , 77 (2), 257\u2013286.", "citeRegEx": "Rabiner,? 1989", "shortCiteRegEx": "Rabiner", "year": 1989}, {"title": "A differentially private stochastic gradient descent algorithm for multiparty classification", "author": ["A. Rajkumar", "S. Agarwal"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Rajkumar and Agarwal,? \\Q2012\\E", "shortCiteRegEx": "Rajkumar and Agarwal", "year": 2012}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "The annals of mathematical statistics,", "citeRegEx": "Robbins and Monro,? \\Q1951\\E", "shortCiteRegEx": "Robbins and Monro", "year": 1951}, {"title": "Minorization conditions and convergence rates for markov chain monte carlo", "author": ["J.S. Rosenthal"], "venue": "Journal of the American Statistical Association, 90 (430), 558\u2013566.", "citeRegEx": "Rosenthal,? 1995", "shortCiteRegEx": "Rosenthal", "year": 1995}, {"title": "Approximation analysis of stochastic gradient langevin dynamics by using fokker-planck equation and ito process", "author": ["I. Sato", "H. Nakagawa"], "venue": "In Proceedings of the 31st International Conference on Machine Learning (ICML-14),", "citeRegEx": "Sato and Nakagawa,? \\Q2014\\E", "shortCiteRegEx": "Sato and Nakagawa", "year": 2014}, {"title": "Efficient, differentially private point estimators", "author": ["A. Smith"], "venue": "arXiv preprint arXiv:0809.4794 .", "citeRegEx": "Smith,? 2008", "shortCiteRegEx": "Smith", "year": 2008}, {"title": "Stochastic gradient descent with differentially private updates", "author": ["S. Song", "K. Chaudhuri", "A.D. Sarwate"], "venue": "In IEEE Global Conference on Signal and Information Processing", "citeRegEx": "Song et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Song et al\\.", "year": 2013}, {"title": "Complexity of inference in latent dirichlet allocation. In Advances in neural information processing", "author": ["D. Sontag", "D. Roy"], "venue": null, "citeRegEx": "Sontag and Roy,? \\Q2011\\E", "shortCiteRegEx": "Sontag and Roy", "year": 2011}, {"title": "Asymptotic statistics, vol", "author": ["A.W. Van der Vaart"], "venue": "3. Cambridge university press.", "citeRegEx": "Vaart,? 2000", "shortCiteRegEx": "Vaart", "year": 2000}, {"title": "non-) asymptotic properties of stochastic gradient langevin dynamics", "author": ["S.J. Vollmer", "Zygalakis", "K. C"], "venue": null, "citeRegEx": "Vollmer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vollmer et al\\.", "year": 2015}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M.J. Wainwright", "M.I. Jordan"], "venue": "Foundations and Trends R", "citeRegEx": "Wainwright and Jordan,? \\Q2008\\E", "shortCiteRegEx": "Wainwright and Jordan", "year": 2008}, {"title": "Bayesian learning via stochastic gradient langevin dynamics", "author": ["M. Welling", "Y.W. Teh"], "venue": "In Proceedings of the 28th International Conference on Machine Learning (ICML-11),", "citeRegEx": "Welling and Teh,? \\Q2011\\E", "shortCiteRegEx": "Welling and Teh", "year": 2011}, {"title": "Probabilistic inference and differential privacy", "author": ["O. Williams", "F. McSherry"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Williams and McSherry,? \\Q2010\\E", "shortCiteRegEx": "Williams and McSherry", "year": 2010}, {"title": "Bayesian inference under differential privacy", "author": ["Y. Xiao", "L. Xiong"], "venue": null, "citeRegEx": "Xiao and Xiong,? \\Q2012\\E", "shortCiteRegEx": "Xiao and Xiong", "year": 2012}], "referenceMentions": [{"referenceID": 33, "context": "In the past few decades, the Bayesian approach has been intensively used in modelling speeches (Rabiner, 1989), text documents (Blei et al.", "startOffset": 95, "endOffset": 110}, {"referenceID": 1, "context": ", 2003), images/videos (Fei-Fei & Perona, 2005), social networks (Airoldi et al., 2009), brain activity (Penny et al.", "startOffset": 65, "endOffset": 87}, {"referenceID": 31, "context": ", 2009), brain activity (Penny et al., 2011), and is often considered gold standard in many of these application domains.", "startOffset": 24, "endOffset": 44}, {"referenceID": 11, "context": "Differential privacy (DP) is a cryptography-inspired notion of privacy (Dwork, 2006; Dwork et al., 2006).", "startOffset": 71, "endOffset": 104}, {"referenceID": 14, "context": "Differential privacy (DP) is a cryptography-inspired notion of privacy (Dwork, 2006; Dwork et al., 2006).", "startOffset": 71, "endOffset": 104}, {"referenceID": 0, "context": "Ahn et al. (2012); Chen et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 0, "context": "Ahn et al. (2012); Chen et al. (2014); Ding et al.", "startOffset": 0, "endOffset": 38}, {"referenceID": 0, "context": "Ahn et al. (2012); Chen et al. (2014); Ding et al. (2014) obey ( , \u03b4)-differentially private with no algorithmic changes when the stepsize is chosen to be small.", "startOffset": 0, "endOffset": 58}, {"referenceID": 27, "context": "We demonstrate empirically that these methods work as well as Similar observations were made in Mir (2013) and Dimitrakakis et al.", "startOffset": 96, "endOffset": 107}, {"referenceID": 9, "context": "We demonstrate empirically that these methods work as well as Similar observations were made in Mir (2013) and Dimitrakakis et al. (2014) under slightly different regimes and assumptions, and we will review them among other related work in Section 6.", "startOffset": 111, "endOffset": 138}, {"referenceID": 6, "context": "or better than the state-of-the-art differential private empirical risk minimization (ERM) solvers using objective perturbation (Chaudhuri et al., 2011; Kifer et al., 2012).", "startOffset": 128, "endOffset": 172}, {"referenceID": 23, "context": "or better than the state-of-the-art differential private empirical risk minimization (ERM) solvers using objective perturbation (Chaudhuri et al., 2011; Kifer et al., 2012).", "startOffset": 128, "endOffset": 172}, {"referenceID": 26, "context": ", McSherry & Talwar (2007); Mir (2013); Bassily et al.", "startOffset": 28, "endOffset": 39}, {"referenceID": 3, "context": ", McSherry & Talwar (2007); Mir (2013); Bassily et al. (2014); Dimitrakakis et al.", "startOffset": 40, "endOffset": 62}, {"referenceID": 3, "context": ", McSherry & Talwar (2007); Mir (2013); Bassily et al. (2014); Dimitrakakis et al. (2014). Proper comparisons with them would require the knowledge of our results, thus we will defer detailed comparisons to Section 6 near the end of the paper.", "startOffset": 40, "endOffset": 90}, {"referenceID": 20, "context": ", Metropolis-Hastings algorithm (Hastings, 1970) to generate samples.", "startOffset": 32, "endOffset": 48}, {"referenceID": 0, "context": "These include Stochastic Gradient Langevin dynamics (SGLD) (Welling & Teh, 2011), Stochstic Gradient Fisher scoring (SGFS) (Ahn et al., 2012), Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) (Chen et al.", "startOffset": 123, "endOffset": 141}, {"referenceID": 7, "context": ", 2012), Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) (Chen et al., 2014) as well as more recent Stochastic Gradient Nos\u00e9-Hoover Thermostat (SGNHT) (Ding et al.", "startOffset": 61, "endOffset": 80}, {"referenceID": 10, "context": ", 2014) as well as more recent Stochastic Gradient Nos\u00e9-Hoover Thermostat (SGNHT) (Ding et al., 2014).", "startOffset": 82, "endOffset": 101}, {"referenceID": 17, "context": ", Metropolis-Hastings algorithm (Hastings, 1970) to generate samples. This is often prohibitively expensive when the data is large. One recent approach to scale up Bayesian learning is to combine stochastic gradient estimation as in Robbins & Monro (1951) and Monte Carlo methods that simulates stochastic differential equations, e.", "startOffset": 13, "endOffset": 256}, {"referenceID": 17, "context": ", Metropolis-Hastings algorithm (Hastings, 1970) to generate samples. This is often prohibitively expensive when the data is large. One recent approach to scale up Bayesian learning is to combine stochastic gradient estimation as in Robbins & Monro (1951) and Monte Carlo methods that simulates stochastic differential equations, e.g. Neal (2011). These include Stochastic Gradient Langevin dynamics (SGLD) (Welling & Teh, 2011), Stochstic Gradient Fisher scoring (SGFS) (Ahn et al.", "startOffset": 13, "endOffset": 347}, {"referenceID": 6, "context": "The boundedness on the loss-function (log-likelihood here) is a standard assumption in many DP works (Chaudhuri et al., 2011; Bassily et al., 2014; Song et al., 2013; Kifer et al., 2012).", "startOffset": 101, "endOffset": 186}, {"referenceID": 3, "context": "The boundedness on the loss-function (log-likelihood here) is a standard assumption in many DP works (Chaudhuri et al., 2011; Bassily et al., 2014; Song et al., 2013; Kifer et al., 2012).", "startOffset": 101, "endOffset": 186}, {"referenceID": 39, "context": "The boundedness on the loss-function (log-likelihood here) is a standard assumption in many DP works (Chaudhuri et al., 2011; Bassily et al., 2014; Song et al., 2013; Kifer et al., 2012).", "startOffset": 101, "endOffset": 186}, {"referenceID": 23, "context": "The boundedness on the loss-function (log-likelihood here) is a standard assumption in many DP works (Chaudhuri et al., 2011; Bassily et al., 2014; Song et al., 2013; Kifer et al., 2012).", "startOffset": 101, "endOffset": 186}, {"referenceID": 3, "context": ", 2011; Bassily et al., 2014; Song et al., 2013; Kifer et al., 2012). Lipschitz constant L is usually small for continuous distributions (at least when the parameter space \u0398 is bounded). This is a bound on log p(x|\u03b8)) so as long as p(x|\u03b8) does not increase or decrease super exponentially fast at any point, L will be a small constant. R can also be made small by a simple preprocessing step that scales down all data points. In the aforementioned papers that assume L, it is typical that they also assume R = 1 for convenience. So we will do the same. In practice, we can algorithmically remove large data points from the data by some predefined threshold or using the \u201cPropose-Test-Release\u201d framework in (Dwork & Lei, 2009) or perform weighted training where we can assign lower weight to data points with large magnitude. Note that this is a desirable step for the robustness to outliers too. Exponential families (in Hilbert space) are an example, see e.g. Bialek et al. (2001); Hofmann et al.", "startOffset": 8, "endOffset": 982}, {"referenceID": 3, "context": ", 2011; Bassily et al., 2014; Song et al., 2013; Kifer et al., 2012). Lipschitz constant L is usually small for continuous distributions (at least when the parameter space \u0398 is bounded). This is a bound on log p(x|\u03b8)) so as long as p(x|\u03b8) does not increase or decrease super exponentially fast at any point, L will be a small constant. R can also be made small by a simple preprocessing step that scales down all data points. In the aforementioned papers that assume L, it is typical that they also assume R = 1 for convenience. So we will do the same. In practice, we can algorithmically remove large data points from the data by some predefined threshold or using the \u201cPropose-Test-Release\u201d framework in (Dwork & Lei, 2009) or perform weighted training where we can assign lower weight to data points with large magnitude. Note that this is a desirable step for the robustness to outliers too. Exponential families (in Hilbert space) are an example, see e.g. Bialek et al. (2001); Hofmann et al. (2008); Wainwright & Jordan (2008).", "startOffset": 8, "endOffset": 1005}, {"referenceID": 3, "context": ", 2011; Bassily et al., 2014; Song et al., 2013; Kifer et al., 2012). Lipschitz constant L is usually small for continuous distributions (at least when the parameter space \u0398 is bounded). This is a bound on log p(x|\u03b8)) so as long as p(x|\u03b8) does not increase or decrease super exponentially fast at any point, L will be a small constant. R can also be made small by a simple preprocessing step that scales down all data points. In the aforementioned papers that assume L, it is typical that they also assume R = 1 for convenience. So we will do the same. In practice, we can algorithmically remove large data points from the data by some predefined threshold or using the \u201cPropose-Test-Release\u201d framework in (Dwork & Lei, 2009) or perform weighted training where we can assign lower weight to data points with large magnitude. Note that this is a desirable step for the robustness to outliers too. Exponential families (in Hilbert space) are an example, see e.g. Bialek et al. (2001); Hofmann et al. (2008); Wainwright & Jordan (2008).", "startOffset": 8, "endOffset": 1033}, {"referenceID": 30, "context": "Since the consistency in Bayesian methods can have different meanings, we briefly describe two of them according to the nomenclature in Orbanz (2012). Definition 5 (Posterior consistency in the Bayesian Sense).", "startOffset": 136, "endOffset": 150}, {"referenceID": 18, "context": "A promising series of results on the consistency for Bayesian nonparametric models can be found in Ghosal (2010)).", "startOffset": 99, "endOffset": 113}, {"referenceID": 18, "context": "Similar statements can also be obtained for some classes of semi-parametric and nonparametric Bayesian models (Ghosal, 2010), which we leave as future work.", "startOffset": 110, "endOffset": 124}, {"referenceID": 36, "context": "We are using L1 distance of the distribution because it is a commonly accepted metric to measure the convergence rate MCMC Rosenthal (1995), and Proposition 10 leaves a clean interface for computational analysis in determining the number of iterations needed to attain a specific level of privacy protection.", "startOffset": 123, "endOffset": 140}, {"referenceID": 3, "context": "The log-concavity of the distributions would imply convexity in the log-likelihood, thus, this essentially confirms the computational efficiency of all convex empirical risk minimization problems under differential privacy constraint (see Bassily et al. (2014)).", "startOffset": 239, "endOffset": 261}, {"referenceID": 6, "context": "OPS has a number of advantages over the state-of-the-art differentially private ERM method: objective perturbation (Chaudhuri et al., 2011; Kifer et al., 2012) (ObjPert from here onwards).", "startOffset": 115, "endOffset": 159}, {"referenceID": 23, "context": "OPS has a number of advantages over the state-of-the-art differentially private ERM method: objective perturbation (Chaudhuri et al., 2011; Kifer et al., 2012) (ObjPert from here onwards).", "startOffset": 115, "endOffset": 159}, {"referenceID": 38, "context": "The idea is to simply privately release an estimate of the gradient (as in Song et al. (2013); Bassily et al.", "startOffset": 75, "endOffset": 94}, {"referenceID": 3, "context": "(2013); Bassily et al. (2014)) and leverage upon the following two celebrated lemmas in differential privacy in the same way as Bassily et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 3, "context": "(2013); Bassily et al. (2014)) and leverage upon the following two celebrated lemmas in differential privacy in the same way as Bassily et al. (2014) does in deriving the near-optimal ( , \u03b4)-differentially private SGD.", "startOffset": 8, "endOffset": 150}, {"referenceID": 4, "context": "In addition, we will also make use of the following lemma due to Beimel et al. (2014). Lemma 13 (Privacy for subsampled data.", "startOffset": 65, "endOffset": 86}, {"referenceID": 4, "context": "In addition, we will also make use of the following lemma due to Beimel et al. (2014). Lemma 13 (Privacy for subsampled data. Lemma 4.4 in Beimel et al. (2014).).", "startOffset": 65, "endOffset": 160}, {"referenceID": 11, "context": "Dwork & Roth (2013)).", "startOffset": 0, "endOffset": 20}, {"referenceID": 42, "context": "Finite sample properties of SGLD is also studied in (Vollmer et al., 2015).", "startOffset": 52, "endOffset": 74}, {"referenceID": 3, "context": "Using the same technique in Bassily et al. (2014), we can further exploit the fact that the subset S that we use to compute the stochastic gradient is chosen uniformly randomly.", "startOffset": 28, "endOffset": 50}, {"referenceID": 42, "context": "This is a suggested heuristic in Welling & Teh (2011) and is inline with the analysis in Sato & Nakagawa (2014) and Vollmer et al. (2015).", "startOffset": 116, "endOffset": 138}, {"referenceID": 3, "context": "Choice of T and \u03c4 By Bassily et al. (2014), it takes at least N data passes to converge in expectation to a point near the minimizer, so taking T = 2N is a good choice.", "startOffset": 21, "endOffset": 43}, {"referenceID": 7, "context": "In this section, we describe three extensions of SGLD that attempts to resolve the issue by either using auxiliary variables to counter the noise in the stochastic gradient(Chen et al., 2014; Ding et al., 2014), or to exploit second order information so as to use Newton-like updates with large stepsize (Ahn et al.", "startOffset": 172, "endOffset": 210}, {"referenceID": 10, "context": "In this section, we describe three extensions of SGLD that attempts to resolve the issue by either using auxiliary variables to counter the noise in the stochastic gradient(Chen et al., 2014; Ding et al., 2014), or to exploit second order information so as to use Newton-like updates with large stepsize (Ahn et al.", "startOffset": 172, "endOffset": 210}, {"referenceID": 0, "context": ", 2014), or to exploit second order information so as to use Newton-like updates with large stepsize (Ahn et al., 2012).", "startOffset": 101, "endOffset": 119}, {"referenceID": 28, "context": "According to Neal (2011), Langevin Dynamics is a special limiting case of Hamiltonian Dynamics, where one can simply ignore the \u201cmomentum\u201d auxiliary variable.", "startOffset": 13, "endOffset": 25}, {"referenceID": 7, "context": "Chen et al. (2014) extends the full \u201cleap-frog\u201d method for HMC in Neal (2011) to work with stochastic gradient and add a \u201cfriction\u201d term in the dynamics to \u201cde-bias\u201d the noise in the stochastic gradient.", "startOffset": 0, "endOffset": 19}, {"referenceID": 7, "context": "Chen et al. (2014) extends the full \u201cleap-frog\u201d method for HMC in Neal (2011) to work with stochastic gradient and add a \u201cfriction\u201d term in the dynamics to \u201cde-bias\u201d the noise in the stochastic gradient.", "startOffset": 0, "endOffset": 78}, {"referenceID": 7, "context": "Chen et al. (2014); Ding et al.", "startOffset": 0, "endOffset": 19}, {"referenceID": 7, "context": "Chen et al. (2014); Ding et al. (2014) both described a reformulation that can be interpret as SGD with momentum.", "startOffset": 0, "endOffset": 39}, {"referenceID": 0, "context": "Stochastic Gradient Fisher Scoring Another extension of SGLD is Stochastic Gradient Fisher Scoring (SGFS), where Ahn et al. (2012) proposes to adaptively interpolate between a preconditioned SGLD (see preconditioning (Girolami & Calderhead, 2011)) and a Markov Chain that samples from a normal approximation of the posterior distribution.", "startOffset": 113, "endOffset": 131}, {"referenceID": 3, "context": "That is the reason why it does not perform as well as other methods despite the theoretically being optimal in scaling (the optimality result is due to SGD (Bassily et al., 2014)).", "startOffset": 156, "endOffset": 178}, {"referenceID": 6, "context": "Specifically, we compared two of our proposed methods, OPS mechanism and hybrid algorithm against the stateof-the-art empirical risk minimization algorithm ObjPert (Chaudhuri et al., 2011; Kifer et al., 2012) under varying level of differential privacy protection.", "startOffset": 164, "endOffset": 208}, {"referenceID": 23, "context": "Specifically, we compared two of our proposed methods, OPS mechanism and hybrid algorithm against the stateof-the-art empirical risk minimization algorithm ObjPert (Chaudhuri et al., 2011; Kifer et al., 2012) under varying level of differential privacy protection.", "startOffset": 164, "endOffset": 208}, {"referenceID": 23, "context": "For fairness, we used the ( , \u03b4)-DP version of the objective perturbation (Kifer et al., 2012) and similarly we used Gaussian mechanism (rather than", "startOffset": 74, "endOffset": 94}, {"referenceID": 26, "context": "For the first part, we become aware recently that Mir (2013) and Dimitrakakis et al.", "startOffset": 50, "endOffset": 61}, {"referenceID": 8, "context": "For the first part, we become aware recently that Mir (2013) and Dimitrakakis et al. (2014) independently developed the idea of using posterior sampling for differential privacy.", "startOffset": 65, "endOffset": 92}, {"referenceID": 8, "context": "For the first part, we become aware recently that Mir (2013) and Dimitrakakis et al. (2014) independently developed the idea of using posterior sampling for differential privacy. Mir (2013, Chapter 5) used a probabilistic bound of the log-likelihood to get ( , \u03b4)\u2212DP but focused mostly on conjugate priors where the posterior distribution is in closed-form. Dimitrakakis et al. (2014) used Lipschitz assumption and bounded data points (implies our boundedness assumption) to obtain a generalized notion of differential privacy.", "startOffset": 65, "endOffset": 385}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS .", "startOffset": 0, "endOffset": 22}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions.", "startOffset": 0, "endOffset": 368}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded.", "startOffset": 0, "endOffset": 612}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.", "startOffset": 0, "endOffset": 828}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.", "startOffset": 0, "endOffset": 938}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known.", "startOffset": 0, "endOffset": 1109}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper.", "startOffset": 0, "endOffset": 1358}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper. For the second part, the idea to privately release stochastic gradient has been well-studied. Song et al. (2013); Bassily et al.", "startOffset": 0, "endOffset": 1607}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper. For the second part, the idea to privately release stochastic gradient has been well-studied. Song et al. (2013); Bassily et al. (2014) explicitly used it for differentially private stochastic gradient descent.", "startOffset": 0, "endOffset": 1630}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper. For the second part, the idea to privately release stochastic gradient has been well-studied. Song et al. (2013); Bassily et al. (2014) explicitly used it for differentially private stochastic gradient descent. And Rajkumar & Agarwal (2012) used it for private multi-party training.", "startOffset": 0, "endOffset": 1735}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper. For the second part, the idea to privately release stochastic gradient has been well-studied. Song et al. (2013); Bassily et al. (2014) explicitly used it for differentially private stochastic gradient descent. And Rajkumar & Agarwal (2012) used it for private multi-party training. Our Theorem 16 is a simple modification of Theorem 2.1 in Bassily et al. (2014). Bassily et al.", "startOffset": 0, "endOffset": 1857}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper. For the second part, the idea to privately release stochastic gradient has been well-studied. Song et al. (2013); Bassily et al. (2014) explicitly used it for differentially private stochastic gradient descent. And Rajkumar & Agarwal (2012) used it for private multi-party training. Our Theorem 16 is a simple modification of Theorem 2.1 in Bassily et al. (2014). Bassily et al. (2014) also showed that the differential private SGD using Gaussian mechanism with \u03c4 = 1 matches the lower bound up to constant and logarithmic, so we are confident that not many algorithms can do significantly better than Algorithm 2.", "startOffset": 0, "endOffset": 1880}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper. For the second part, the idea to privately release stochastic gradient has been well-studied. Song et al. (2013); Bassily et al. (2014) explicitly used it for differentially private stochastic gradient descent. And Rajkumar & Agarwal (2012) used it for private multi-party training. Our Theorem 16 is a simple modification of Theorem 2.1 in Bassily et al. (2014). Bassily et al. (2014) also showed that the differential private SGD using Gaussian mechanism with \u03c4 = 1 matches the lower bound up to constant and logarithmic, so we are confident that not many algorithms can do significantly better than Algorithm 2. Our contribution is to point out the interesting algorithmic structures of SGLD and extensions that preserves differential privacy. The method in Song et al. (2013) requires disjoint minibatches in every data pass, and it requires adding significantly more noise in settings when Lemma 13 applies.", "startOffset": 0, "endOffset": 2274}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper. For the second part, the idea to privately release stochastic gradient has been well-studied. Song et al. (2013); Bassily et al. (2014) explicitly used it for differentially private stochastic gradient descent. And Rajkumar & Agarwal (2012) used it for private multi-party training. Our Theorem 16 is a simple modification of Theorem 2.1 in Bassily et al. (2014). Bassily et al. (2014) also showed that the differential private SGD using Gaussian mechanism with \u03c4 = 1 matches the lower bound up to constant and logarithmic, so we are confident that not many algorithms can do significantly better than Algorithm 2. Our contribution is to point out the interesting algorithmic structures of SGLD and extensions that preserves differential privacy. The method in Song et al. (2013) requires disjoint minibatches in every data pass, and it requires adding significantly more noise in settings when Lemma 13 applies. Song et al. (2013) are however applicable when we are doing only a small number of data passes and for these cases, it gets a much better constant.", "startOffset": 0, "endOffset": 2426}, {"referenceID": 3, "context": "Bassily et al. (2014) used exponential mechanism for empirical risk minimization and the procedure is exactly the same as OPS . Our difference is to connect it to Bayesian learning and to provide results on limiting distribution, statistical efficiency and approximate sampling. We are not aware of a similar asymptotic distribution with the exception of Smith (2008), where a different algorithm (the subsample-and-aggregate scheme) is proven to give an estimator that is asymptotically normal and efficient (therefore, stronger than our result) under a different set of assumptions. Specifically, Smith (2008)\u2019s method requires boundedness of the parameter space while ours method can work with potentially unbounded space so long as the log-likelihood is bounded. Related to the general topic, Kasiviswanathan & Smith (2014) explicitly modeled the \u201csemantics\u201d of differential privacy from a Bayesian point of view, Xiao & Xiong (2012) developed a set of tools for performing Bayesian inference under differential privacy, e.g., conditional probability and credibility intervals. Williams & McSherry (2010) studied a related but completely different problem that uses posterior inference as a meta-postprocessing procedure, which aims at \u201cdenoising\u201d the privately obfuscated data when the private mechanism is known. Integrating Williams & McSherry (2010) with our procedure might lead to some further performance boost, but investigating its effect is beyond the scope of the current paper. For the second part, the idea to privately release stochastic gradient has been well-studied. Song et al. (2013); Bassily et al. (2014) explicitly used it for differentially private stochastic gradient descent. And Rajkumar & Agarwal (2012) used it for private multi-party training. Our Theorem 16 is a simple modification of Theorem 2.1 in Bassily et al. (2014). Bassily et al. (2014) also showed that the differential private SGD using Gaussian mechanism with \u03c4 = 1 matches the lower bound up to constant and logarithmic, so we are confident that not many algorithms can do significantly better than Algorithm 2. Our contribution is to point out the interesting algorithmic structures of SGLD and extensions that preserves differential privacy. The method in Song et al. (2013) requires disjoint minibatches in every data pass, and it requires adding significantly more noise in settings when Lemma 13 applies. Song et al. (2013) are however applicable when we are doing only a small number of data passes and for these cases, it gets a much better constant. Rajkumar & Agarwal (2012)\u2019s setting", "startOffset": 0, "endOffset": 2581}, {"referenceID": 6, "context": "In this way, it replicates objective perturbation (Chaudhuri et al., 2011) (assuming the method actually finds the optimal solution).", "startOffset": 50, "endOffset": 74}, {"referenceID": 6, "context": "Objective perturbation is originally proposed in Chaudhuri et al. (2011) and the ( , \u03b4) version that we refer to first appears in Kifer et al.", "startOffset": 49, "endOffset": 73}, {"referenceID": 6, "context": "Objective perturbation is originally proposed in Chaudhuri et al. (2011) and the ( , \u03b4) version that we refer to first appears in Kifer et al. (2012). Comparing to our two mechanisms that attempts to sample from the posterior, their privacy guarantee requires the solution to be exact while ours does not.", "startOffset": 49, "endOffset": 150}], "year": 2015, "abstractText": "We consider the problem of Bayesian learning on sensitive datasets and present two simple but somewhat surprising results that connect Bayesian learning to \u201cdifferential privacy\u201d, a cryptographic approach to protect individual-level privacy while permiting database-level utility. Specifically, we show that that under standard assumptions, getting one single sample from a posterior distribution is differentially private \u201cfor free\u201d. We will see that estimator is statistically consistent, near optimal and computationally tractable whenever the Bayesian model of interest is consistent, optimal and tractable. Similarly but separately, we show that a recent line of works that use stochastic gradient for Hybrid Monte Carlo (HMC) sampling also preserve differentially privacy with minor or no modifications of the algorithmic procedure at all, these observations lead to an \u201canytime\u201d algorithm for Bayesian learning under privacy constraint. We demonstrate that it performs much better than the state-of-the-art differential private methods on synthetic and real datasets. 1 ar X iv :1 50 2. 07 64 5v 2 [ st at .M L ] 1 2 A pr 2 01 5", "creator": "LaTeX with hyperref package"}}}