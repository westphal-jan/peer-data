{"id": "1502.08053", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2015", "title": "Stochastic Dual Coordinate Ascent with Adaptive Probabilities", "abstract": "This paper introduces AdaSDCA: an adaptive variant of stochastic dual coordinate ascent (SDCA) for solving the regularized empirical risk minimization problems. Our modification consists in allowing the method adaptively change the probability distribution over the dual variables throughout the iterative process. AdaSDCA achieves provably better complexity bound than SDCA with the best fixed probability distribution, known as importance sampling. However, it is of a theoretical character as it is expensive to implement. We also propose AdaSDCA+: a practical variant which in our experiments outperforms existing non-adaptive methods.", "histories": [["v1", "Fri, 27 Feb 2015 20:54:03 GMT  (2315kb)", "http://arxiv.org/abs/1502.08053v1", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG stat.ML", "authors": ["dominik csiba", "zheng qu", "peter richt\u00e1rik"], "accepted": true, "id": "1502.08053"}, "pdf": {"name": "1502.08053.pdf", "metadata": {"source": "META", "title": "Stochastic Dual Coordinate Ascent with Adaptive Probabilities", "authors": ["Dominik Csiba"], "emails": ["CDOMINIK@GMAIL.COM", "ZHENG.QU@ED.AC.UK", "PETER.RICHTARIK@ED.AC.UK"], "sections": [{"heading": null, "text": "ar Xiv: 150 2.08 053v 1 [mat h.O C] 27 Feb 20"}, {"heading": "1. Introduction", "text": "Empirical Loss Minimization (a). In this paper, we look at the regularized risk minimization problem (b). (1) In the context of supervised learning, this is a linear predictive parameter. (2) We try to identify the predictor that minimizes the average (empirical) loss performance. (3) We assume that the loss functions are 1 / 2 smooth. (3) That is, we assume that they are differentiable and have Lipschitz derivatives. (3) We assume that the loss functions are 1 / 3 smooth. (3) We assume that they are differentiable and that they have Lipschitz derivatives. (4)"}, {"heading": "2. Contributions", "text": "Two algorithms with adaptive probabilities. We propose two new stochastic dual ascent algorithms: AdaSDCA (algorithm 1) and AdaSDCA + (algorithm 2) to solve (1) and its dual problem (2). The novelty of our algorithms lies in the adaptive selection of the probability distribution via the dual coordinates. Complexity analysis. We offer a convergence rate analysis for the first method, which shows that AdaSDCA has a better rate than the best known rate for SDCA with a fixed sample (Zhao & Zhang, 2014; Qu et al., 2014). The probabilities are proportional to a certain measure of dual suboptimality associated with each variable.Practical method. AdaSDCA requires the same computational effort per iteration as the Ddax algorithms."}, {"heading": "3. The Algorithm: AdaSDCA", "text": "It is known that the optimum primary coordination (w *, p *) is optimal and that we should fulfil the following optimization conditions: w * (1), (2), (3), (4), (4), (4), (4), (5), (4), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5, (5), (5), (5, (5), (5), (5, (5), (5), (5, (5), (5, (5), (5, (5), (5), (5, (5), (5), (5, (5), (5), (5, (5), (5), (5, (5), (5), (5, (5), (5), (5, (5), (5,"}, {"heading": "4. Convergence results", "text": "In this section we present our theoretical complexity results for AdaSDCA. The main results are formulated in Theorem 7, which covers the general case, and in Theorem 11 in the special case, when {\u03c6i} ni = 1 are all square."}, {"heading": "4.1. General loss functions", "text": "(T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T (T) (T) (T) (T) (T (T) (T) (T) (T) (T) (T (T) (T) (T) (T) (T) (T) (T (T) (T) (T (T) (T) (T) (T) (T) (T) (T) (T (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T) (T (T) (T) (T) (T"}, {"heading": "4.2. Quadratic loss functions", "text": "The main difficulty in solving (11) stems from the inequality constraint, which originates in (9). In this section, we mainly show that the constraint (9) can be solved if all {\u03c6i} i are square. Sentence 10. Let us assume that all {\u03c6i} i are square. Let us suppose t \u2265 0. If Mini-It is pti > 0, then Et [D (\u03b1t + 1) \u2212 D (\u03b1t)] \u2265 \u03b8 (\u0445t, pt) (P (wt) \u2212 D (\u03b1t).Proof. This is a direct consequence of Lemma 5 and the fact that the right side of (8) is equal to 0 if it is equal to 0, if it is equal to (\u0442t, pt).Theorem 11. Let us assume that all {\u03c6i} i are square. Let us consider AdaSDCA. If at each iteration t \u2265 0, Mini-It pti > 0, then (15) then all of us are equal to the rest (if all of the rest is)."}, {"heading": "5. Efficient heuristic variant", "text": "Logical conclusions 9 and 12 indicate how to choose the adaptive sampling probability in AdaSDCA, which yields a theoretical convergence rate at least as good as the IProxSDCA (Zhao & Zhang, 2014). However, there are two main problems with implementing AdaSDCA: 1. Updating the dual residual capacity at each iteration cost O (nnz (A), where nnz (A) is the number of unequal elements of matrix A; 2. We do not know how to calculate the optimal solution of (11). In this section, we propose a heuristic variant of AdaSDCA that avoids the two above problems while remaining close to the \"good\" adaptive sampling distribution."}, {"heading": "5.1. Description of Algorithm", "text": "\"It is very likely that we will be able to create a new system,\" he said. \"We will not do it.\" (\"We will do it.\") \"We will do it.\" (\"We will do it.\") \"We will do it.\" (\"We will do it.\") \"We will do it.\" (\"We will do it.\") \"We will do it.\" (\"We will do it.\") \"We will do it. (\" We will do it. \")\" (\"We will do it.\") \"(\" We will do it. \"(\" We will do it. \")\" We will do it. \"(\" We will do it. \")\" (\"We will do it.\" (\"We will do it.\") \"(\" We will do it. \"(\" We will do it. \")\" (\"We will do it. (\" We will do it. \")\" (\"We will do it. (\" We will do it. \")\" We will do it. (\"We will do it. (\" We will do it. \")\" We will do it. (\"We will do it. (\" We will do it. \"We will do it.\") \"(\" We will do it. (\"We will do it.\" We will do it. (\"We will do it.\") \"We will do it. (\" We will do it. (\"We will do it.\" We will do it. \"). (\" We will do it. (\"We will do it.\" We will do it. \"). (\" We will do it. (\"We will do it.\"). (\"We will do it.\" We will do it. (\"We will do it.\"). (\"We will do it. (\" We will do it. \"). (\" We will do it. (\"We will do it.\"). (\"We will do it. (\" We will do it. \"). (\" We will do it. (\"We will do it.\"). \"We will do it. (\" We will do it. \"). (\" We will do it. (\"We will do it.\"). (\"We will do it."}, {"heading": "5.2. Computational cost", "text": "Sampling and probability update During the algorithm, we derive i [n] from a non-uniform probability distribution pt, which changes with each iteration.This process can be efficiently performed using the random counter algorithm introduced in Section 6.2 of (Nesterov, 2012), which requires O (n log (n) operations to create the probability tree and O (log (n) operations to extract or modify one of the probabilities from the distribution.Total calculation costs We can calculate the calculation cost of an epoch.At the beginning of an epoch, we need O (n) operations to calculate the double remaining sum. We then create a probability tree using O (n log (n) operations. For each iteration, we need O (log (n) operations to sample a coordinate, O (nz / n) operations to compute the update to a point, and another log (n) operation to create a comparison between the probability tree and the result."}, {"heading": "6. Numerical Experiments", "text": "In this section we present the results of numerical experiments."}, {"heading": "6.1. Loss functions", "text": "We test AdaSDCA and AdaSDCA +, SDCA and IProxSDCA for two different types of loss functions {\u03c6i} ni = 1: square loss and smoothed hinge loss. Let's specify y-Rn as a vector of labels. Square loss is given by \u03c6i (x) = 12\u03b3 (x-yi) 2 and the smoothed hinge loss is: inspi (x) = 0 yix \u2265 1 \u2212 yix \u2212 \u03b3 / 2 yix \u2264 1 \u2212 \u03b3 (1 \u2212 yix) 22\u03b3 otherwise we use L2 regulators in both cases, i.e. g (w) = 12 \u0445 W. 2.Square loss functions usually occur in regression problems, and smoothed hinge loss can be found in problems with linear support vectors (SVM) (Shalev-Shwartz & Zhang, 2013a)."}, {"heading": "6.2. Numerical results", "text": "We used 5 different datasets: w8a, Dorothea, mushrooms, cov1 and ijcnn1 (see Table 2). In all our experiments, we used \u03b3 = 1 and \u03bb = 1 / n.AdaSDCA The results of the theory developed in Section 4 can be observed through Figure 1 to Figure 4. AdaSDCA requires the least number of iterations to converge, which confirms the theoretical result.AdaSDCA + V.S. Other We can observe from Figure 15 to 24 that both options of AdaSDCA + exceed SDCA and IProx-SDCA in terms of the number of iterations in terms of square loss functions and smoothed hinge functions. Similar results in terms of time can be observed through Figure 5 to Figure 14. Option I V.S. Option II Despite the fact that Option I is not theoretically supported for smoothed hinge functions and for smoothed hinge functions, it is still supported faster than Option II."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>This paper introduces AdaSDCA: an adap-<lb>tive variant of stochastic dual coordinate as-<lb>cent (SDCA) for solving the regularized empir-<lb>ical risk minimization problems. Our modifica-<lb>tion consists in allowing the method adaptively<lb>change the probability distribution over the dual<lb>variables throughout the iterative process. AdaS-<lb>DCA achieves provably better complexity bound<lb>than SDCA with the best fixed probability dis-<lb>tribution, known as importance sampling. How-<lb>ever, it is of a theoretical character as it is expen-<lb>sive to implement. We also propose AdaSDCA+:<lb>a practical variant which in our experiments out-<lb>performs existing non-adaptive methods.", "creator": "LaTeX with hyperref package"}}}