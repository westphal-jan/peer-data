{"id": "1503.00030", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2015", "title": "Parsing as Reduction", "abstract": "We reduce phrase-representation parsing to dependency parsing. Our reduction is grounded on a new intermediate representation, \"head-ordered dependency trees\", shown to be isomorphic to constituent trees. By encoding order information in the dependency labels, we show that any off-the-shelf, trainable dependency parser can be used to produce constituents. When this parser is non-projective, we can perform discontinuous parsing in a very natural manner. Despite the simplicity of our approach, experiments show that the resulting parsers are on par with strong baselines, such as the Berkeley parser for English and the best single system in the SPMRL-2014 shared task. Results are particularly striking for discontinuous parsing of German, where we surpass the current state of the art by a wide margin.", "histories": [["v1", "Fri, 27 Feb 2015 22:52:37 GMT  (83kb,D)", "http://arxiv.org/abs/1503.00030v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["daniel fern\u00e1ndez-gonz\u00e1lez", "andr\u00e9 f t martins"], "accepted": true, "id": "1503.00030"}, "pdf": {"name": "1503.00030.pdf", "metadata": {"source": "CRF", "title": "Parsing as Reduction", "authors": ["Daniel Fern\u00e1ndez-Gonz\u00e1lez", "Andr\u00e9 F. T. Martins", "D. Afonso Henriques"], "emails": ["danifg@uvigo.es,", "atm@priberam.pt"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that we are able to find a solution that is capable of finding a solution that is also capable of finding a solution."}, {"heading": "2 Background", "text": "Let's start with checking constituent and dependency representations and setting up the notation. After Kong and Smith (2014) we use c / d prefixes for convenience (e.g. we write c-parser for constituent parser and d-tree for dependency tree)."}, {"heading": "2.1 Constituent Trees", "text": "In this context, we focus on the properties of the c-trees rather than the grammars used to generate them. We also assume that the c-trees are an exact strategy with discontinuities, such as those associated with linear context-free paraphrasing systems (LCFRS; Vijay-Shanker et al. (1987))). We also assume that the c-trees are lexicalized.Formally, w1w2. wL is a sentence in which wi names the word in the ith position. A ctree is a rooted tree whose leaves are the words {wi} Li = 1, and whose internal nodes (constituencies) are represented as tuples. < Z, h >, where Z is a non-terminal symbol, h {1, h}."}, {"heading": "2.2 Dependency Trees", "text": "A d tree is a directed tree that spans all the words of the project.1 Each arc in this tree is a tuple < h, m, \">, which has a typical dependency relationship\" between the header wh and the modifier wm.A d tree is projective when for each arc < h, m, \"> 1We assume that dependency trees have a single root between {w1,..., wL}. Therefore, there is no need to consider an additional root symbol, as it is often done in the letter. There is a directed path from h to all words lying between h and m in the surface string (Kahane et al., 1998). Projective d trees can be reached from c trees by reading the lexic heads and dropping the internal nodes."}, {"heading": "3 Head-Ordered Dependency Trees", "text": "Next, we add another layer of structure to d-trees, namely order information. In this context, not all modifiers of a head are \"born equal.\" Instead, their attachment to the head takes place as a sequence of \"events\" reflecting the head's preference to place some modifiers before others. As we will see, this additional structure will undo the ambiguity expressed in Figure 2."}, {"heading": "3.1 Strictly Ordered Dependency Trees", "text": "Let's start with the simpler case, where the attachment order is stricter. For each header h with the modifiers Mh = {m1,..., mK}, we output Mh with a strict command relationship, so that we can organize all modifiers of h like a chain, mi1, hmi2, hmi2, hmi2, hmi2. We consider this chain as a reflection of the order in which the words are appended (i.e., if mi, h mj means that \"mi is appended to h before mj\"). We illustrate this graphically by using d-arcs with clues (# 1, # 2,..) to name the sequence of events, as we call it in Figure 1.A d-tree with a strict sequence for each head. We establish this under a correspondence between d-trees and binary c-trees."}, {"heading": "3.2 Weakly Ordered Dependency Trees", "text": "Next, we will issue strict orders to terminate the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination, the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of the termination of"}, {"heading": "3.3 Continuous and Projective Trees", "text": "In fact, it is as if most people are able to know themselves and understand what they are doing. (...) It is not as if they are able to outwit themselves. (...) \"It is not as if.\" (...) \"It is as if.\" (...) \"It is as if.\" (...) \"It is as if.\" (...) \"It is as if.\" (...) \"It is as if.\" (...) \"It is as if.\" (...) \"It is as if.\" (...) \"It is as if.\" (...) \"It is as if.\" (...) \"It is.\" (...) \"(It is.\" (...). \"(It is.\" (...) \"(It is.\" (...). (It is. (...) \"(It is.\" (...). (It is. (...) \"(It is.\" (...). (It is. (...). (It is. (...) \"(it is. (...). (It is. (...).\" (It is. (It is. (...). \"(It is. (It is.\" (...). (It is. (It is. (...). (It is. (...). (It is. (It is. (...). (It is. (it. (it.). (it. (it. (it is.). (it. (it. (it.). (it. (it.). (it is. (it. (it. (it.). (it.). (it. (it. (it is.). (it. (it. (it.). (it. (it.). (it.). (it. (it is. (it.). (it. (it. (it.). (it is. (it. (it.). (it.). (it is. (it. (it. (it.). (it.). (it.). (it is. (it. (it. (it. (it.). (it.). (it. (it.). (it. (it is. (it is."}, {"heading": "4 Reduction-Based Constituent Parsers", "text": "Next, we will show how to use the equivalence results obtained in the previous section to design cparsers when only a traceable d-parser is available. Faced with a c-treebank provided as input, our approach is outlined as follows: 1. Convert the c-treebank to dependencies (algorithm 1).2. Train a designated d-parser on that treebank. 3. Run the labeled d-parser for each test sentence and convert the predicted d-tree to a c-tree without an unary node (algorithm 2).4. Do post-processing to recover unforeseen things. The next subsections describe each of these steps. Besides, we will illustrate experiments with the English Penn Treebank (Marcus et al., 1993), which we lexicalized using the copyrights of Collins (1999).2"}, {"heading": "4.1 Dependency Encoding", "text": "The first step is the conversion of the c-treebank into head-loaded dependencies, which we initiate with algorithms."}, {"heading": "4.2 Training the Labeled Dependency Parser", "text": "The next step is to train a labeled d-parser on the converted tree base. However, if we do continuous cparsing, we train a projective d-parser; otherwise, we train a non-projective d-parser; 4 In our experiments, we found it advantageous to perform labeled d-parsing in two steps, as is done by McDonald et al. (2006): First, we train an unlabeled d-parser; then we train a dependency label.4 Table 1 compares this approach with a uniform strategy by experimenting with various off-theshelf d-parsers: MaltParser (Nivre et al., 2007), MSTParser (McDonald et al., 2005), ZPar (Zhang3For example, if # 1, # 3, # 4, # 4 and # 2, # 3, # 5 d-parsers are different from each other: MaltParser (Nivre et al., 2007), MSTParser (McDonald et al., 2005, M3, M3, M3, M3, M3, M3, M3, McDonald., 3, 3, 3, 3, 3, 3, 3, 3."}, {"heading": "4.3 Decoding into Unaryless Constituents", "text": "To perform this step, we must first restore the weak order of its modifiers Mh for each head h. We do this by looking at the predicted dependency designations, extracting the event indexes j and using them to form and sort the equivalent classes {M-jh} J = 1. If two modifiers have the same index j, we force them to have consistent designations (by always choosing the label of the modifier closest to the head). For continuous c-parsing, we also reduce the index j of the modifier closer to the head as necessary to ensure that the nesting property holds. In PTB \u00a7 22, these corrections were only necessary for 0.6% of the tokens."}, {"heading": "4.4 Recovery of Unary Nodes", "text": "Finally, the last stage is the restoration of the simple nodes. Faced with an unaryless c-tree as input, we predict unaries by running independent multi-class classifiers on each node in the tree (a simple unstructured task); each class is either NULL (in which case no unary node is appended to the current node) or a concatenation of unary node labels (e.g. S- > ADJP for a node YY); we obtained 64 classes by processing the training sections of the PTB, with the proportion of unary nodes accounting for about 11% of the total number of non-terminal nodes. To reduce complexity, for each node symbol we consider only classes observed for this symbol in the training data. In PTB \u00a7 22 we received an average of 9.9 candidate labels per node containing NVP labels. These classifiers are trained on the original ctreebank and trained to restore these nodes."}, {"heading": "5 Experiments", "text": "We are now comparing our reduction-based parsers with other state-of-the-art c-parsers in a variety of tree banks, both continuous and discontinuous."}, {"heading": "5.1 Results on the English PTB", "text": "Table 2 shows the accuracies and speeds of the English PTB \u00a7 23. We can see that our simple reduction-based c-parser outperforms the three Stanford parsers (Klein and Manning, 2003; Socher et al., 2013 and Stanford Shift-Reduce) and matches the Berkeley parser (Petrov and Klein, 2007), although it is more than 5 times faster. The most closely watched competitor is the newest shift-reduction parser from Zhu et al. (2013), which achieves slightly better accuracy and speed. Our technique has the advantage of being flexible: since the time for d-parsing is the dominant factor (see \u00a7 4.4), plugging a faster d-parser automatically leads to a faster c-parser. Orthogonal techniques, such as semi-supervised training and reranking, can also be applied to our parser to increase its performance."}, {"heading": "5.2 Results on the SPMRL Datasets", "text": "We experimented with data sets for eight morphologically rich languages, based on the SPMRL14 Shared Task (Seddah et al., 2014).5 We used the official training, development and test sets with the predicted POS tags and different lexicography rules for each language. For French and Arabic, we omitted the data set for licensing reasons. For Hebrew and Polish, we used the most left-handed modifier instead. For Swedish, we induced head rules from the provided dependency bank, as described in Versley (2014b). These decisions are based on dev-set experiments. Table 3 shows the results. In all languages except French, our system performs better than the small-scale one (Parkeley or Parkeley) in 2007."}, {"heading": "5.3 Results on the Discontinuous Treebanks", "text": "Finally, we experimented with two widely used discontinuous German tree banks: TIGER (Brants et al., 2002) and NEGRA (Skut et al., 1997); for the former, we used two different splits: TIGERSPMLR, provided in the SPMRL14 shared task; and TIGER-H & N, used by Hall and Nivre (2008); for the NEGRA, we used the standard splits. In these experiments, we skipped the uncommon recovery phase because there are very few simple nodes in the data.7 For the TIGER-SPMRL datasets, we used the predicted \"single-parser.\" We mean a system that does not use ensemble or reranking techniques.7NEGRA has no imponderables; for the TIGER-SPMRL and H & N datasets (NEMRL datasets), the percentage of unweightness of the 1.45% of the assignment is provided in P45%."}, {"heading": "6 Related Work", "text": "Conversions between components and dependencies have been considered by De Marneffe et al. (2006) in the forward direction, and by Collins et al. (1999) and Xia and Palmer (2001) in the backward direction, towards the construction of multi-representative tree banks (Xia et al., 2008). This earlier work aimed at linguistically correct conversions, using gram-specific transformation rules to deal with the kind of ambiguities expressed in Figure 2. Our work differs in that we do not concern ourselves with the linguistic plausibility of our conversions, but only with the formal aspects underlying the two representations. The work that most relates to ours is Hall and Nivre (2008), which convert dependencies into constituents in order to prototype a c-parser for German. Their coding strategy is compared with ours in \u00a7 4.1: they encode the entire vertebral columns into the dependency parameters, which we will use to a large number of parameters, which will be quite similar to the two particles strategy."}, {"heading": "7 Conclusion", "text": "We have proposed a reduction technology that makes it possible to implement a constituent parser when there is only one dependency parser. This technique is applicable to any dependency parser, regardless of its nature or type. This reduction has been achieved by endowing dependency trees with a weak ordering relationship and showing that the resulting class of head-ordered dependency trees is isomorphic for constituent trees. We have shown empirically that the proposed reduction, while simple, leads to highly competitive constituent parsers for English and for eight morphologically rich languages; and that it exceeds the current state of the art in discontinuous parsing German."}, {"heading": "Acknowledgments", "text": "We thank Slav Petrov, Lingpeng Kong and Carlos Go'mez-Rodr\u00edguez for their comments and suggestions. This research was partly funded by the Spanish Ministry of Economy and Competitiveness and FEDER (project TIN201018552-C03-01), the Ministry of Education (FPU funding programme) and Xunta de Galicia (projects R2014 / 029 and R2014 / 034). A. M. was supported by the EU / FEDER programme QREN / POR Lisboa (Portugal) within the Intelligo project (contract 2012 / 24803) and by the FCT funding UID / EEA / 50008 / 2013."}], "references": [{"title": "Jointly learning to extract and compress", "author": ["Taylor Berg-Kirkpatrick", "Dan Gillick", "Dan Klein."], "venue": "Proc. of Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Berg.Kirkpatrick et al\\.,? 2011", "shortCiteRegEx": "Berg.Kirkpatrick et al\\.", "year": 2011}, {"title": "Introducing the ims-wroc\u0142aw-szeged-cis entry at the spmrl 2014 shared task: Reranking and morpho-syntax meet", "author": ["Anders Bj\u00f6rkelund", "\u00d6zlem \u00c7etino\u011flu", "Agnieszka Fale\u0144ska", "Rich\u00e1rd Farkas", "Thomas Mueller", "Wolfgang Seeker", "Zsolt Sz\u00e1nt\u00f3"], "venue": null, "citeRegEx": "Bj\u00f6rkelund et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bj\u00f6rkelund et al\\.", "year": 2014}, {"title": "Development and evaluation of a broad-coverage probabilistic grammar of english-language computer manuals", "author": ["Ezra Black", "John Lafferty", "Salim Roukos."], "venue": "Proc. of Annual Meeting on Association for Computational Linguistics.", "citeRegEx": "Black et al\\.,? 1992", "shortCiteRegEx": "Black et al\\.", "year": 1992}, {"title": "Discontinuity revisited: An improved conversion to context-free representations", "author": ["Adriane Boyd."], "venue": "Proc. of Linguistic Annotation Workshop.", "citeRegEx": "Boyd.,? 2007", "shortCiteRegEx": "Boyd.", "year": 2007}, {"title": "The TIGER treebank", "author": ["Sabine Brants", "Stefanie Dipper", "Silvia Hansen", "Wolfgang Lezius", "George Smith."], "venue": "Proc. of the workshop on treebanks and linguistic theories.", "citeRegEx": "Brants et al\\.,? 2002", "shortCiteRegEx": "Brants et al\\.", "year": 2002}, {"title": "TAG, Dynamic Programming, and the Perceptron for Efficient, Feature-rich Parsing", "author": ["X. Carreras", "M. Collins", "T. Koo."], "venue": "International Conference on Natural Language Learning.", "citeRegEx": "Carreras et al\\.,? 2008", "shortCiteRegEx": "Carreras et al\\.", "year": 2008}, {"title": "Coarseto-fine n-best parsing and maxent discriminative reranking", "author": ["Eugene Charniak", "Mark Johnson."], "venue": "Proc. of ACL.", "citeRegEx": "Charniak and Johnson.,? 2005", "shortCiteRegEx": "Charniak and Johnson.", "year": 2005}, {"title": "Tree-bank grammars", "author": ["E. Charniak."], "venue": "Proc. of the National Conference on Artificial Intelligence.", "citeRegEx": "Charniak.,? 1996", "shortCiteRegEx": "Charniak.", "year": 1996}, {"title": "A maximum-entropyinspired parser", "author": ["Eugene Charniak."], "venue": "Proc. of the North American Chapter of the Association for Computational Linguistics Conference.", "citeRegEx": "Charniak.,? 2000", "shortCiteRegEx": "Charniak.", "year": 2000}, {"title": "A Statistical Parser for Czech", "author": ["Michael Collins", "Lance Ramshaw", "Jan Haji\u010d", "Christoph Tillmann."], "venue": "Proc. of the Annual Meeting of the Association for Computational Linguistics on Computational Linguistics.", "citeRegEx": "Collins et al\\.,? 1999", "shortCiteRegEx": "Collins et al\\.", "year": 1999}, {"title": "Head-driven statistical models for natural language parsing", "author": ["M. Collins."], "venue": "Ph.D. thesis, University of Pennsylvania.", "citeRegEx": "Collins.,? 1999", "shortCiteRegEx": "Collins.", "year": 1999}, {"title": "Multilingual discriminative shift reduce phrase structure parsing for the SPMRL 2014 shared task", "author": ["Benoit Crabb\u00e9", "Djam\u00e9 Seddah."], "venue": "First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis of", "citeRegEx": "Crabb\u00e9 and Seddah.,? 2014", "shortCiteRegEx": "Crabb\u00e9 and Seddah.", "year": 2014}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["Marie-Catherine De Marneffe", "Bill MacCartney", "Christopher D Manning"], "venue": "In Proc. of LREC", "citeRegEx": "Marneffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Extraction automatique de Grammaires d\u2019Arbres Adjoints \u00e0 partir d\u2019un corpus arbor\u00e9 du fran\u00e7ais", "author": ["Ane Dybro-Johansen."], "venue": "Master\u2019s thesis, Universit\u00e9 Paris 7.", "citeRegEx": "Dybro.Johansen.,? 2004", "shortCiteRegEx": "Dybro.Johansen.", "year": 2004}, {"title": "Efficient parsing for bilexical context-free grammars and head automaton grammars", "author": ["J. Eisner", "G. Satta."], "venue": "Proc. of Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Eisner and Satta.,? 1999", "shortCiteRegEx": "Eisner and Satta.", "year": 1999}, {"title": "Three new probabilistic models for dependency parsing: An exploration", "author": ["J.M. Eisner."], "venue": "Proc. of International Conference on Computational Linguistics.", "citeRegEx": "Eisner.,? 1996", "shortCiteRegEx": "Eisner.", "year": 1996}, {"title": "Down-stream effects of tree-to-dependency conversions", "author": ["Jakob Elming", "Anders Johannsen", "Sigrid Klerke", "Emanuele Lapponi", "Hector Martinez Alonso", "Anders S\u00f8gaard."], "venue": "HLT-NAACL.", "citeRegEx": "Elming et al\\.,? 2013", "shortCiteRegEx": "Elming et al\\.", "year": 2013}, {"title": "Dependency systems and phrasestructure systems", "author": ["H. Gaifman."], "venue": "Information and control.", "citeRegEx": "Gaifman.,? 1965", "shortCiteRegEx": "Gaifman.", "year": 1965}, {"title": "Efficient parsing of well-nested linear context-free rewriting systems", "author": ["Carlos G\u00f3mez-Rodr\u0131\u0301guez", "Marco Kuhlmann", "Giorgio Satta"], "venue": "In Proc. of the Annual Conference of the North American Chapter of the Association for Computational Linguistics", "citeRegEx": "G\u00f3mez.Rodr\u0131\u0301guez et al\\.,? \\Q2010\\E", "shortCiteRegEx": "G\u00f3mez.Rodr\u0131\u0301guez et al\\.", "year": 2010}, {"title": "A dependencydriven parser for german dependency and constituency representations", "author": ["Johan Hall", "Joakim Nivre."], "venue": "Proc. of the Workshop on Parsing German.", "citeRegEx": "Hall and Nivre.,? 2008", "shortCiteRegEx": "Hall and Nivre.", "year": 2008}, {"title": "Less grammar, more features", "author": ["David Hall", "Greg Durrett", "Dan Klein."], "venue": "Proc. of the Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Hall et al\\.,? 2014", "shortCiteRegEx": "Hall et al\\.", "year": 2014}, {"title": "Forest reranking: Discriminative parsing with non-local features", "author": ["L. Huang."], "venue": "ACL.", "citeRegEx": "Huang.,? 2008", "shortCiteRegEx": "Huang.", "year": 2008}, {"title": "Dependency-based Semantic Role Labeling of PropBank", "author": ["R. Johansson", "P. Nugues."], "venue": "Empirical Methods for Natural Language Processing.", "citeRegEx": "Johansson and Nugues.,? 2008", "shortCiteRegEx": "Johansson and Nugues.", "year": 2008}, {"title": "PCFG models of linguistic tree representations", "author": ["M. Johnson."], "venue": "Computational Linguistics.", "citeRegEx": "Johnson.,? 1998", "shortCiteRegEx": "Johnson.", "year": 1998}, {"title": "Pseudoprojectivity: a polynomially parsable non-projective dependency grammar", "author": ["S. Kahane", "A. Nasr", "O. Rambow."], "venue": "International Conference on Computational Linguistics.", "citeRegEx": "Kahane et al\\.,? 1998", "shortCiteRegEx": "Kahane et al\\.", "year": 1998}, {"title": "Datadriven parsing using probabilistic linear context-free rewriting systems", "author": ["Laura Kallmeyer", "Wolfgang Maier."], "venue": "Computational Linguistics.", "citeRegEx": "Kallmeyer and Maier.,? 2013", "shortCiteRegEx": "Kallmeyer and Maier.", "year": 2013}, {"title": "Accurate unlexicalized parsing", "author": ["D. Klein", "C.D. Manning."], "venue": "Proc. of Annual Meeting on Association for Computational Linguistics.", "citeRegEx": "Klein and Manning.,? 2003", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "An empirical comparison of parsing methods for stanford dependencies", "author": ["Lingpeng Kong", "Noah A Smith."], "venue": "arXiv preprint arXiv:1404.4314.", "citeRegEx": "Kong and Smith.,? 2014", "shortCiteRegEx": "Kong and Smith.", "year": 2014}, {"title": "Transforming dependencies into phrase structures", "author": ["Lingpeng Kong", "Alexander M. Rush", "Noah A. Smith."], "venue": "Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics.", "citeRegEx": "Kong et al\\.,? 2015", "shortCiteRegEx": "Kong et al\\.", "year": 2015}, {"title": "Efficient third-order dependency parsers", "author": ["T. Koo", "M. Collins."], "venue": "Proc. of ACL.", "citeRegEx": "Koo and Collins.,? 2010", "shortCiteRegEx": "Koo and Collins.", "year": 2010}, {"title": "How to compare treebanks", "author": ["Sandra K\u00fcbler", "Wolfgang Maier", "Ines Rehbein", "Yannick Versley."], "venue": "LREC.", "citeRegEx": "K\u00fcbler et al\\.,? 2008", "shortCiteRegEx": "K\u00fcbler et al\\.", "year": 2008}, {"title": "Mildly non-projective dependency structures", "author": ["Marco Kuhlmann", "Joakim Nivre."], "venue": "Proc. of the COLING/ACL.", "citeRegEx": "Kuhlmann and Nivre.,? 2006", "shortCiteRegEx": "Kuhlmann and Nivre.", "year": 2006}, {"title": "Treebanks and mild context-sensitivity", "author": ["Wolfgang Maier", "Anders S\u00f8gaard."], "venue": "Proc. of Formal Grammar.", "citeRegEx": "Maier and S\u00f8gaard.,? 2008", "shortCiteRegEx": "Maier and S\u00f8gaard.", "year": 2008}, {"title": "Data-driven plcfrs parsing revisited: Restricting the fan-out to two", "author": ["Wolfgang Maier", "Miriam Kaeshammer", "Laura Kallmeyer."], "venue": "Proc. of the Eleventh International Conference on Tree Adjoining Grammars and Related Formalisms.", "citeRegEx": "Maier et al\\.,? 2012", "shortCiteRegEx": "Maier et al\\.", "year": 2012}, {"title": "Building a large annotated corpus of english: The penn treebank", "author": ["Mitchell P. Marcus", "Beatrice Santorini", "Mary Ann Marcinkiewicz."], "venue": "Computational Linguistics.", "citeRegEx": "Marcus et al\\.,? 1993", "shortCiteRegEx": "Marcus et al\\.", "year": 1993}, {"title": "Turning on the turbo: Fast third-order nonprojective turbo parsers", "author": ["A.F.T. Martins", "M.B. Almeida", "N.A. Smith."], "venue": "Proc. of the Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Martins et al\\.,? 2013", "shortCiteRegEx": "Martins et al\\.", "year": 2013}, {"title": "Probabilistic CFG with latent annotations", "author": ["T. Matsuzaki", "Y. Miyao", "J. Tsujii."], "venue": "Proc. of ACL.", "citeRegEx": "Matsuzaki et al\\.,? 2005", "shortCiteRegEx": "Matsuzaki et al\\.", "year": 2005}, {"title": "On the complexity of non-projective data-driven dependency parsing", "author": ["R. McDonald", "G. Satta."], "venue": "Proc. of International Conference on Parsing Technologies.", "citeRegEx": "McDonald and Satta.,? 2007", "shortCiteRegEx": "McDonald and Satta.", "year": 2007}, {"title": "Non-projective dependency parsing using spanning tree algorithms", "author": ["R.T. McDonald", "F. Pereira", "K. Ribarov", "J. Hajic."], "venue": "Proc. of Empirical Methods for Natural Language Processing.", "citeRegEx": "McDonald et al\\.,? 2005", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "Multilingual dependency analysis with a two-stage discriminative parser", "author": ["R. McDonald", "K. Lerman", "F. Pereira."], "venue": "Proc. of International Conference on Natural Language Learning.", "citeRegEx": "McDonald et al\\.,? 2006", "shortCiteRegEx": "McDonald et al\\.", "year": 2006}, {"title": "Labeled pseudo-projective dependency parsing with support vector machines", "author": ["J. Nivre", "J. Hall", "J. Nilsson", "G. Eryi\u01e7it", "S. Marinov."], "venue": "Procs. of International Conference on Natural Language Learning.", "citeRegEx": "Nivre et al\\.,? 2006", "shortCiteRegEx": "Nivre et al\\.", "year": 2006}, {"title": "Maltparser: A language-independent system for data-driven dependency parsing", "author": ["Joakim Nivre", "Johan Hall", "Jens Nilsson", "Atanas Chanev", "Glsen Eryigit", "Sandra K\u00fcbler", "Svetoslav Marinov", "Erwin Marsi."], "venue": "Natural Language Engineering.", "citeRegEx": "Nivre et al\\.,? 2007", "shortCiteRegEx": "Nivre et al\\.", "year": 2007}, {"title": "Improved inference for unlexicalized parsing", "author": ["Slav Petrov", "Dan Klein."], "venue": "Proc. of the North American Chapter of the Association for Computational Linguistics.", "citeRegEx": "Petrov and Klein.,? 2007", "shortCiteRegEx": "Petrov and Klein.", "year": 2007}, {"title": "Treebank-Based Grammar Acquisition for German", "author": ["Ines Rehbein."], "venue": "Ph.D. thesis, School of Computing, Dublin City University.", "citeRegEx": "Rehbein.,? 2009", "shortCiteRegEx": "Rehbein.", "year": 2009}, {"title": "Vine pruning for efficient multi-pass dependency parsing", "author": ["Alexander M Rush", "Slav Petrov."], "venue": "Proc. of the North American Chapter of the Association for Computational Linguistics.", "citeRegEx": "Rush and Petrov.,? 2012", "shortCiteRegEx": "Rush and Petrov.", "year": 2012}, {"title": "On dual decomposition and linear programming relaxations for natural language processing", "author": ["A. Rush", "D. Sontag", "M. Collins", "T. Jaakkola."], "venue": "Proc. of EMNLP.", "citeRegEx": "Rush et al\\.,? 2010", "shortCiteRegEx": "Rush et al\\.", "year": 2010}, {"title": "A classifier-based parser with linear run-time complexity", "author": ["Kenji Sagae", "Alon Lavie."], "venue": "Proceedings of the Ninth International Workshop on Parsing Technology.", "citeRegEx": "Sagae and Lavie.,? 2005", "shortCiteRegEx": "Sagae and Lavie.", "year": 2005}, {"title": "Introducing the spmrl 2014 shared task on parsing morphologically-rich languages", "author": ["Djam\u00e9 Seddah", "Sandra K\u00fcbler", "Reut Tsarfaty."], "venue": "Proc. of the First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic", "citeRegEx": "Seddah et al\\.,? 2014", "shortCiteRegEx": "Seddah et al\\.", "year": 2014}, {"title": "An annotation scheme for free word order languages", "author": ["Wojciech Skut", "Brigitte Krenn", "Thorsten Brants", "Hans Uszkoreit."], "venue": "Proc. of the Fifth Conference on Applied Natural Language Processing ANLP-97.", "citeRegEx": "Skut et al\\.,? 1997", "shortCiteRegEx": "Skut et al\\.", "year": 1997}, {"title": "Parsing with compositional vector grammars", "author": ["Richard Socher", "John Bauer", "Christopher D Manning", "Andrew Y Ng."], "venue": "Proc. of ACL.", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Discontinuous parsing with an efficient and accurate dop model", "author": ["Andreas van Cranenburgh", "Rens Bod."], "venue": "IWPT-2013.", "citeRegEx": "Cranenburgh and Bod.,? 2013", "shortCiteRegEx": "Cranenburgh and Bod.", "year": 2013}, {"title": "Efficient parsing with linear context-free rewriting systems", "author": ["Andreas van Cranenburgh."], "venue": "Proc. of the Conference of the European Chapter of the Association for Computational Linguistics.", "citeRegEx": "Cranenburgh.,? 2012", "shortCiteRegEx": "Cranenburgh.", "year": 2012}, {"title": "Experiments with easy-first nonprojective constituent parsing", "author": ["Yannick Versley."], "venue": "Proc. of the First Joint Workshop on Statistical Parsing of Morphologically Rich Languages and Syntactic Analysis of Non-Canonical Languages.", "citeRegEx": "Versley.,? 2014a", "shortCiteRegEx": "Versley.", "year": 2014}, {"title": "Incorporating semisupervised features into discontinuous easy-first constituent parsing", "author": ["Yannick Versley."], "venue": "CoRR, abs/1409.3813.", "citeRegEx": "Versley.,? 2014b", "shortCiteRegEx": "Versley.", "year": 2014}, {"title": "Phrase dependency parsing for opinion mining", "author": ["Yuanbin Wu", "Qi Zhang", "Xuanjing Huang", "Lide Wu."], "venue": "Proc. of EMNLP.", "citeRegEx": "Wu et al\\.,? 2009", "shortCiteRegEx": "Wu et al\\.", "year": 2009}, {"title": "Converting dependency structures to phrase structures", "author": ["F. Xia", "M. Palmer."], "venue": "Proceedings of the First International Conference on Human Language Technology Research.", "citeRegEx": "Xia and Palmer.,? 2001", "shortCiteRegEx": "Xia and Palmer.", "year": 2001}, {"title": "Towards a multirepresentational treebank", "author": ["Fei Xia", "Owen Rambow", "Rajesh Bhatt", "Martha Palmer", "Dipti Misra Sharma."], "venue": "LOT Occasional Series.", "citeRegEx": "Xia et al\\.,? 2008", "shortCiteRegEx": "Xia et al\\.", "year": 2008}, {"title": "Statistical dependency analysis with support vector machines", "author": ["H. Yamada", "Y. Matsumoto."], "venue": "Proc. of International Conference on Parsing Technologies.", "citeRegEx": "Yamada and Matsumoto.,? 2003", "shortCiteRegEx": "Yamada and Matsumoto.", "year": 2003}, {"title": "Transition-based dependency parsing with rich non-local features", "author": ["Y. Zhang", "J. Nivre."], "venue": "Proc. of the Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Zhang and Nivre.,? 2011", "shortCiteRegEx": "Zhang and Nivre.", "year": 2011}, {"title": "Fast and accurate shiftreduce constituent parsing", "author": ["Muhua Zhu", "Yue Zhang", "Wenliang Chen", "Min Zhang", "Jingbo Zhu."], "venue": "Proc. of ACL.", "citeRegEx": "Zhu et al\\.,? 2013", "shortCiteRegEx": "Zhu et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 7, "context": "Constituent parsing is a central problem in NLP\u2014one at which statistical models trained on treebanks have excelled (Charniak, 1996; Klein and Manning, 2003; Petrov and Klein, 2007).", "startOffset": 115, "endOffset": 180}, {"referenceID": 26, "context": "Constituent parsing is a central problem in NLP\u2014one at which statistical models trained on treebanks have excelled (Charniak, 1996; Klein and Manning, 2003; Petrov and Klein, 2007).", "startOffset": 115, "endOffset": 180}, {"referenceID": 42, "context": "Constituent parsing is a central problem in NLP\u2014one at which statistical models trained on treebanks have excelled (Charniak, 1996; Klein and Manning, 2003; Petrov and Klein, 2007).", "startOffset": 115, "endOffset": 180}, {"referenceID": 22, "context": "Dependency parsers are generally faster, but less informative, since they do not produce constituents, which are often required by downstream applications (Johansson and Nugues, 2008; Wu et al., 2009; Berg-Kirkpatrick et al., 2011; Elming et al., 2013).", "startOffset": 155, "endOffset": 252}, {"referenceID": 54, "context": "Dependency parsers are generally faster, but less informative, since they do not produce constituents, which are often required by downstream applications (Johansson and Nugues, 2008; Wu et al., 2009; Berg-Kirkpatrick et al., 2011; Elming et al., 2013).", "startOffset": 155, "endOffset": 252}, {"referenceID": 0, "context": "Dependency parsers are generally faster, but less informative, since they do not produce constituents, which are often required by downstream applications (Johansson and Nugues, 2008; Wu et al., 2009; Berg-Kirkpatrick et al., 2011; Elming et al., 2013).", "startOffset": 155, "endOffset": 252}, {"referenceID": 16, "context": "Dependency parsers are generally faster, but less informative, since they do not produce constituents, which are often required by downstream applications (Johansson and Nugues, 2008; Wu et al., 2009; Berg-Kirkpatrick et al., 2011; Elming et al., 2013).", "startOffset": 155, "endOffset": 252}, {"referenceID": 6, "context": "Coarse-to-fine decoding (Charniak and Johnson, 2005) and shift-reduce parsing (Sagae and Lavie, 2005; Zhu et al.", "startOffset": 24, "endOffset": 52}, {"referenceID": 46, "context": "Coarse-to-fine decoding (Charniak and Johnson, 2005) and shift-reduce parsing (Sagae and Lavie, 2005; Zhu et al., 2013) were a step for-", "startOffset": 78, "endOffset": 119}, {"referenceID": 59, "context": "Coarse-to-fine decoding (Charniak and Johnson, 2005) and shift-reduce parsing (Sagae and Lavie, 2005; Zhu et al., 2013) were a step for-", "startOffset": 78, "endOffset": 119}, {"referenceID": 41, "context": "While non-projective dependency parsers, which are able to model such phenomena, have been widely developed in the last decade (Nivre et al., 2007; McDonald et al., 2006; Martins et al., 2013), discontinuous constituent parsing is still taking its first steps (Maier and S\u00f8gaard, 2008; Kallmeyer and Maier, 2013).", "startOffset": 127, "endOffset": 192}, {"referenceID": 39, "context": "While non-projective dependency parsers, which are able to model such phenomena, have been widely developed in the last decade (Nivre et al., 2007; McDonald et al., 2006; Martins et al., 2013), discontinuous constituent parsing is still taking its first steps (Maier and S\u00f8gaard, 2008; Kallmeyer and Maier, 2013).", "startOffset": 127, "endOffset": 192}, {"referenceID": 35, "context": "While non-projective dependency parsers, which are able to model such phenomena, have been widely developed in the last decade (Nivre et al., 2007; McDonald et al., 2006; Martins et al., 2013), discontinuous constituent parsing is still taking its first steps (Maier and S\u00f8gaard, 2008; Kallmeyer and Maier, 2013).", "startOffset": 127, "endOffset": 192}, {"referenceID": 32, "context": ", 2013), discontinuous constituent parsing is still taking its first steps (Maier and S\u00f8gaard, 2008; Kallmeyer and Maier, 2013).", "startOffset": 75, "endOffset": 127}, {"referenceID": 25, "context": ", 2013), discontinuous constituent parsing is still taking its first steps (Maier and S\u00f8gaard, 2008; Kallmeyer and Maier, 2013).", "startOffset": 75, "endOffset": 127}, {"referenceID": 19, "context": "Hall and Nivre (2008) attempted a related conversion to parse German, but their complex encoding scheme blows up the number of arc labels, affecting the final parser\u2019s quality.", "startOffset": 0, "endOffset": 22}, {"referenceID": 42, "context": "While simple, our reduction-based parsers are on par with the Berkeley parser for English (Petrov and Klein, 2007), and with the best single system in the recent SPMRL shared task (Seddah et al.", "startOffset": 90, "endOffset": 114}, {"referenceID": 27, "context": "Following Kong and Smith (2014), we use c-/d- prefixes for convenience (e.", "startOffset": 10, "endOffset": 32}, {"referenceID": 10, "context": "This kth node (called the head-child node) is commonly chosen applying an handwritten set of head rules (Collins, 1999; Yamada and Matsumoto, 2003).", "startOffset": 104, "endOffset": 147}, {"referenceID": 57, "context": "This kth node (called the head-child node) is commonly chosen applying an handwritten set of head rules (Collins, 1999; Yamada and Matsumoto, 2003).", "startOffset": 104, "endOffset": 147}, {"referenceID": 7, "context": "There has been a long string of work in statistical c-parsing, shifting from simple models (Charniak, 1996) to more sophisticated ones using structural annotation (Johnson, 1998; Klein and Manning, 2003), latent grammars (Matsuzaki et al.", "startOffset": 91, "endOffset": 107}, {"referenceID": 23, "context": "There has been a long string of work in statistical c-parsing, shifting from simple models (Charniak, 1996) to more sophisticated ones using structural annotation (Johnson, 1998; Klein and Manning, 2003), latent grammars (Matsuzaki et al.", "startOffset": 163, "endOffset": 203}, {"referenceID": 26, "context": "There has been a long string of work in statistical c-parsing, shifting from simple models (Charniak, 1996) to more sophisticated ones using structural annotation (Johnson, 1998; Klein and Manning, 2003), latent grammars (Matsuzaki et al.", "startOffset": 163, "endOffset": 203}, {"referenceID": 36, "context": "There has been a long string of work in statistical c-parsing, shifting from simple models (Charniak, 1996) to more sophisticated ones using structural annotation (Johnson, 1998; Klein and Manning, 2003), latent grammars (Matsuzaki et al., 2005; Petrov and Klein, 2007), and lexicalization (Eisner, 1996; Collins, 1999).", "startOffset": 221, "endOffset": 269}, {"referenceID": 42, "context": "There has been a long string of work in statistical c-parsing, shifting from simple models (Charniak, 1996) to more sophisticated ones using structural annotation (Johnson, 1998; Klein and Manning, 2003), latent grammars (Matsuzaki et al., 2005; Petrov and Klein, 2007), and lexicalization (Eisner, 1996; Collins, 1999).", "startOffset": 221, "endOffset": 269}, {"referenceID": 15, "context": ", 2005; Petrov and Klein, 2007), and lexicalization (Eisner, 1996; Collins, 1999).", "startOffset": 52, "endOffset": 81}, {"referenceID": 10, "context": ", 2005; Petrov and Klein, 2007), and lexicalization (Eisner, 1996; Collins, 1999).", "startOffset": 52, "endOffset": 81}, {"referenceID": 6, "context": "An orthogonal line of work uses ensemble or reranking strategies to further improve accuracy (Charniak and Johnson, 2005; Huang, 2008; Bj\u00f6rkelund et al., 2014).", "startOffset": 93, "endOffset": 159}, {"referenceID": 21, "context": "An orthogonal line of work uses ensemble or reranking strategies to further improve accuracy (Charniak and Johnson, 2005; Huang, 2008; Bj\u00f6rkelund et al., 2014).", "startOffset": 93, "endOffset": 159}, {"referenceID": 1, "context": "An orthogonal line of work uses ensemble or reranking strategies to further improve accuracy (Charniak and Johnson, 2005; Huang, 2008; Bj\u00f6rkelund et al., 2014).", "startOffset": 93, "endOffset": 159}, {"referenceID": 33, "context": "To speed up decoding, prior work has considered restrictons, such as bounding the fan-out (Maier et al., 2012) and requiring well-nestedness (Kuhlmann and Nivre, 2006; G\u00f3mez-Rodr\u0131\u0301guez et al.", "startOffset": 90, "endOffset": 110}, {"referenceID": 31, "context": ", 2012) and requiring well-nestedness (Kuhlmann and Nivre, 2006; G\u00f3mez-Rodr\u0131\u0301guez et al., 2010).", "startOffset": 38, "endOffset": 95}, {"referenceID": 18, "context": ", 2012) and requiring well-nestedness (Kuhlmann and Nivre, 2006; G\u00f3mez-Rodr\u0131\u0301guez et al., 2010).", "startOffset": 38, "endOffset": 95}, {"referenceID": 3, "context": "Other approaches eliminate the discontinuities via tree transformations (Boyd, 2007; K\u00fcbler et al., 2008), sometimes as a pruning step followed by reranking (van Cranenburgh and Bod, 2013).", "startOffset": 72, "endOffset": 105}, {"referenceID": 30, "context": "Other approaches eliminate the discontinuities via tree transformations (Boyd, 2007; K\u00fcbler et al., 2008), sometimes as a pruning step followed by reranking (van Cranenburgh and Bod, 2013).", "startOffset": 72, "endOffset": 105}, {"referenceID": 1, "context": "An orthogonal line of work uses ensemble or reranking strategies to further improve accuracy (Charniak and Johnson, 2005; Huang, 2008; Bj\u00f6rkelund et al., 2014). Discontinuous c-parsing is considered a much harder problem, involving mildly context-sensitive formalisms such as LCFRS or range concatenation grammars, with treebankderived c-parsers exhibiting near-exponential runtime (Kallmeyer and Maier, 2013, Figure 27). To speed up decoding, prior work has considered restrictons, such as bounding the fan-out (Maier et al., 2012) and requiring well-nestedness (Kuhlmann and Nivre, 2006; G\u00f3mez-Rodr\u0131\u0301guez et al., 2010). Other approaches eliminate the discontinuities via tree transformations (Boyd, 2007; K\u00fcbler et al., 2008), sometimes as a pruning step followed by reranking (van Cranenburgh and Bod, 2013). However, reported runtimes are still superior to 10 seconds per sentence, which is not practical. Recently, Versley (2014a) proposed an easyfirst approach that leads to considerable speedups, but is less accurate.", "startOffset": 135, "endOffset": 936}, {"referenceID": 1, "context": "An orthogonal line of work uses ensemble or reranking strategies to further improve accuracy (Charniak and Johnson, 2005; Huang, 2008; Bj\u00f6rkelund et al., 2014). Discontinuous c-parsing is considered a much harder problem, involving mildly context-sensitive formalisms such as LCFRS or range concatenation grammars, with treebankderived c-parsers exhibiting near-exponential runtime (Kallmeyer and Maier, 2013, Figure 27). To speed up decoding, prior work has considered restrictons, such as bounding the fan-out (Maier et al., 2012) and requiring well-nestedness (Kuhlmann and Nivre, 2006; G\u00f3mez-Rodr\u0131\u0301guez et al., 2010). Other approaches eliminate the discontinuities via tree transformations (Boyd, 2007; K\u00fcbler et al., 2008), sometimes as a pruning step followed by reranking (van Cranenburgh and Bod, 2013). However, reported runtimes are still superior to 10 seconds per sentence, which is not practical. Recently, Versley (2014a) proposed an easyfirst approach that leads to considerable speedups, but is less accurate. In this paper, we design fast discontinuous c-parsers that outperform all the ones above by a wide margin, with similar runtimes as Versley (2014a).", "startOffset": 135, "endOffset": 1174}, {"referenceID": 24, "context": "there is a directed path from h to all words that lie between h and m in the surface string (Kahane et al., 1998).", "startOffset": 92, "endOffset": 113}, {"referenceID": 17, "context": "Projective d-trees can be obtained from continuous c-trees by reading off the lexical heads and dropping the internal nodes (Gaifman, 1965).", "startOffset": 124, "endOffset": 139}, {"referenceID": 14, "context": "While projective d-parsers can use dynamic programming (Eisner and Satta, 1999; Koo and Collins, 2010), non-projective d-parsers typically rely on approximate decoders, since the underlying problem is NP-hard beyond arc-factored models (McDonald and Satta, 2007).", "startOffset": 55, "endOffset": 102}, {"referenceID": 29, "context": "While projective d-parsers can use dynamic programming (Eisner and Satta, 1999; Koo and Collins, 2010), non-projective d-parsers typically rely on approximate decoders, since the underlying problem is NP-hard beyond arc-factored models (McDonald and Satta, 2007).", "startOffset": 55, "endOffset": 102}, {"referenceID": 37, "context": "While projective d-parsers can use dynamic programming (Eisner and Satta, 1999; Koo and Collins, 2010), non-projective d-parsers typically rely on approximate decoders, since the underlying problem is NP-hard beyond arc-factored models (McDonald and Satta, 2007).", "startOffset": 236, "endOffset": 262}, {"referenceID": 40, "context": "An alternative are transition-based d-parsers (Nivre et al., 2006; Zhang and Nivre, 2011), which achieve observed linear time.", "startOffset": 46, "endOffset": 89}, {"referenceID": 58, "context": "An alternative are transition-based d-parsers (Nivre et al., 2006; Zhang and Nivre, 2011), which achieve observed linear time.", "startOffset": 46, "endOffset": 89}, {"referenceID": 44, "context": "Since d-parsing algorithms do not have a grammar constant, typical implementations are significantly faster than c-parsers (Rush and Petrov, 2012; Martins et al., 2013).", "startOffset": 123, "endOffset": 168}, {"referenceID": 35, "context": "Since d-parsing algorithms do not have a grammar constant, typical implementations are significantly faster than c-parsers (Rush and Petrov, 2012; Martins et al., 2013).", "startOffset": 123, "endOffset": 168}, {"referenceID": 5, "context": "We may regard a c-tree as a set of L spines, one per word, which attach to each other to form a tree (Carreras et al., 2008).", "startOffset": 101, "endOffset": 124}, {"referenceID": 17, "context": "To see (i), note that the projectiveness of D is ensured by the well-known result of Gaifman (1965) about the projection of continuous trees.", "startOffset": 85, "endOffset": 100}, {"referenceID": 34, "context": "Along the way, we illustrate with experiments using the English Penn Treebank (Marcus et al., 1993), which we lexicalized by applying the head rules of Collins (1999).", "startOffset": 78, "endOffset": 99}, {"referenceID": 10, "context": ", 1993), which we lexicalized by applying the head rules of Collins (1999).2", "startOffset": 60, "endOffset": 75}, {"referenceID": 35, "context": "We predict automatic POS tags with TurboTagger (Martins et al., 2013), with 10-fold jackknifing on the training set.", "startOffset": 47, "endOffset": 69}, {"referenceID": 19, "context": "For comparison, we implemented a third strategy replicating the encoding proposed by Hall and Nivre (2008), which we call H&N-encoding.", "startOffset": 85, "endOffset": 107}, {"referenceID": 41, "context": "4 Table 1 compares this approach against a oneshot strategy, experimenting with various off-theshelf d-parsers: MaltParser (Nivre et al., 2007), MSTParser (McDonald et al.", "startOffset": 123, "endOffset": 143}, {"referenceID": 38, "context": ", 2007), MSTParser (McDonald et al., 2005), ZPar (Zhang", "startOffset": 19, "endOffset": 42}, {"referenceID": 38, "context": "In our experiments, we found it advantageous to perform labeled d-parsing in two stages, as done by McDonald et al. (2006): first, train an unlabeled d-parser; then, train a dependency labeler.", "startOffset": 100, "endOffset": 123}, {"referenceID": 35, "context": "and Nivre, 2011), and TurboParser (Martins et al., 2013), all with the default settings.", "startOffset": 34, "endOffset": 56}, {"referenceID": 42, "context": ", 2013, and Stanford Shift-Reduce), and is on par with the Berkeley parser (Petrov and Klein, 2007), while being more than 5 times faster.", "startOffset": 75, "endOffset": 99}, {"referenceID": 2, "context": "For constituents, we show F1-scores (without punctuation and root nodes), as provided by EVALB (Black et al., 1992).", "startOffset": 95, "endOffset": 115}, {"referenceID": 5, "context": "1 169 Carreras et al. (2008) 90.", "startOffset": 6, "endOffset": 29}, {"referenceID": 5, "context": "1 169 Carreras et al. (2008) 90.7 91.4 91.1 \u2013 Zhu et al. (2013) 90.", "startOffset": 6, "endOffset": 64}, {"referenceID": 5, "context": "1 169 Carreras et al. (2008) 90.7 91.4 91.1 \u2013 Zhu et al. (2013) 90.3 90.6 90.4 1,290 Stanford Shift-Reduce (2014) 89.", "startOffset": 6, "endOffset": 114}, {"referenceID": 5, "context": "1 169 Carreras et al. (2008) 90.7 91.4 91.1 \u2013 Zhu et al. (2013) 90.3 90.6 90.4 1,290 Stanford Shift-Reduce (2014) 89.1 89.1 89.1 655 Hall et al. (2014) 88.", "startOffset": 6, "endOffset": 152}, {"referenceID": 5, "context": "1 169 Carreras et al. (2008) 90.7 91.4 91.1 \u2013 Zhu et al. (2013) 90.3 90.6 90.4 1,290 Stanford Shift-Reduce (2014) 89.1 89.1 89.1 655 Hall et al. (2014) 88.4 88.8 88.6 12 This work 89.9 90.4 90.2 957 Charniak and Johnson (2005)\u2217 91.", "startOffset": 6, "endOffset": 227}, {"referenceID": 5, "context": "1 169 Carreras et al. (2008) 90.7 91.4 91.1 \u2013 Zhu et al. (2013) 90.3 90.6 90.4 1,290 Stanford Shift-Reduce (2014) 89.1 89.1 89.1 655 Hall et al. (2014) 88.4 88.8 88.6 12 This work 89.9 90.4 90.2 957 Charniak and Johnson (2005)\u2217 91.2 91.8 91.5 84 Socher et al. (2013)\u2217 89.", "startOffset": 6, "endOffset": 267}, {"referenceID": 59, "context": "best supervised competitor is the recent shiftreduce parser of Zhu et al. (2013), which achieves slightly better accuracy and speed.", "startOffset": 63, "endOffset": 81}, {"referenceID": 47, "context": "We experimented with datasets for eight morphologically rich languages, from the SPMRL14 shared task (Seddah et al., 2014).", "startOffset": 101, "endOffset": 122}, {"referenceID": 43, "context": "German we used the head rules detailed in DybroJohansen (2004) and Rehbein (2009), respectively.", "startOffset": 67, "endOffset": 82}, {"referenceID": 43, "context": "German we used the head rules detailed in DybroJohansen (2004) and Rehbein (2009), respectively. For Basque, Hungarian and Korean, we always take the rightmost modifier as head-child node. For Hebrew and Polish we use the leftmost modifier instead. For Swedish we induce head rules from the provided dependency treebank, as described in Versley (2014b). These choices were based on dev-set experiments.", "startOffset": 67, "endOffset": 353}, {"referenceID": 42, "context": "For all languages except French, our system outperforms the Berkeley parser (Petrov and Klein, 2007), with or without prescribed POS tags.", "startOffset": 76, "endOffset": 100}, {"referenceID": 11, "context": "Our average F1-scores are superior to the best single parser6 participating in the shared task (Crabb\u00e9 and Seddah, 2014), and to the system of Hall et al.", "startOffset": 95, "endOffset": 120}, {"referenceID": 11, "context": "Our average F1-scores are superior to the best single parser6 participating in the shared task (Crabb\u00e9 and Seddah, 2014), and to the system of Hall et al. (2014), achieving the best results for 4 out of 8 languages.", "startOffset": 96, "endOffset": 162}, {"referenceID": 4, "context": "Finally, we experimented on two widely-used discontinuous German treebanks: TIGER (Brants et al., 2002) and NEGRA (Skut et al.", "startOffset": 82, "endOffset": 103}, {"referenceID": 48, "context": ", 2002) and NEGRA (Skut et al., 1997).", "startOffset": 18, "endOffset": 37}, {"referenceID": 4, "context": "Finally, we experimented on two widely-used discontinuous German treebanks: TIGER (Brants et al., 2002) and NEGRA (Skut et al., 1997). For the former, we used two different splits: TIGERSPMLR, provided in the SPMRL14 shared task; and TIGER-H&N, used by Hall and Nivre (2008). For NEGRA, we used the standard splits.", "startOffset": 83, "endOffset": 275}, {"referenceID": 19, "context": "17 Hall et al. (2014) 83.", "startOffset": 3, "endOffset": 22}, {"referenceID": 11, "context": "72 Crabb\u00e9 and Seddah (2014) 85.", "startOffset": 3, "endOffset": 28}, {"referenceID": 40, "context": "Berkeley Tagged is a version of Petrov and Klein (2007) using the predicted POS tags provided by the organizers.", "startOffset": 32, "endOffset": 56}, {"referenceID": 10, "context": "Crabb\u00e9 and Seddah (2014) is the best nonreranking system in the shared task, and Bj\u00f6rkelund et al.", "startOffset": 0, "endOffset": 25}, {"referenceID": 1, "context": "Crabb\u00e9 and Seddah (2014) is the best nonreranking system in the shared task, and Bj\u00f6rkelund et al. (2014) the ensemble and reranking-based system which won the official task.", "startOffset": 81, "endOffset": 106}, {"referenceID": 43, "context": "The treebanks were lexicalized using the head-rule sets of Rehbein (2009). For comparison to related work, a sentence length cut-off of 30, 40 and 70 was applied during the evaluation.", "startOffset": 59, "endOffset": 74}, {"referenceID": 50, "context": "The best competitor, van Cranenburgh and Bod (2013), is more than 3 points behind, both in TIGER-H&N and in NEGRA.", "startOffset": 25, "endOffset": 52}, {"referenceID": 50, "context": "The best competitor, van Cranenburgh and Bod (2013), is more than 3 points behind, both in TIGER-H&N and in NEGRA. Our reduction-based parsers are also much faster: van Cranenburgh and Bod (2013) report 3 hours to parse NEGRA with L < 40.", "startOffset": 25, "endOffset": 196}, {"referenceID": 50, "context": "The best competitor, van Cranenburgh and Bod (2013), is more than 3 points behind, both in TIGER-H&N and in NEGRA. Our reduction-based parsers are also much faster: van Cranenburgh and Bod (2013) report 3 hours to parse NEGRA with L < 40. Our system parses all NEGRA sentences (regardless of length) in 27.1 seconds, which corresponds to a rate of 618 toks/s. This approaches the speed of the easy-first system of Versley (2014a), who reports runtimes in the range 670\u2013920 toks/s.", "startOffset": 25, "endOffset": 430}, {"referenceID": 56, "context": "(1999) and Xia and Palmer (2001) in the backward direction, toward the construction of multirepresentational treebanks (Xia et al., 2008).", "startOffset": 119, "endOffset": 137}, {"referenceID": 10, "context": "Conversions between constituents and dependencies have been considered by De Marneffe et al. (2006) in the forward direction, and by Collins et al.", "startOffset": 77, "endOffset": 100}, {"referenceID": 9, "context": "(2006) in the forward direction, and by Collins et al. (1999) and Xia and Palmer (2001) in the backward direction, toward the construction of multirepresentational treebanks (Xia et al.", "startOffset": 40, "endOffset": 62}, {"referenceID": 9, "context": "(2006) in the forward direction, and by Collins et al. (1999) and Xia and Palmer (2001) in the backward direction, toward the construction of multirepresentational treebanks (Xia et al.", "startOffset": 40, "endOffset": 88}, {"referenceID": 19, "context": "The work most related to ours is Hall and Nivre (2008), who also convert dependencies to constituents to prototype a c-parser for German.", "startOffset": 33, "endOffset": 55}, {"referenceID": 19, "context": "The work most related to ours is Hall and Nivre (2008), who also convert dependencies to constituents to prototype a c-parser for German. Their encoding strategy is compared to ours in \u00a74.1: they encode the entire spines into the dependency labels, which become rather complex and numerous. A similar strategy has been used by Versley (2014a) for discontinuous c-parsing.", "startOffset": 33, "endOffset": 343}, {"referenceID": 5, "context": "Joint constituent and dependency parsing have been tackled by Carreras et al. (2008) and Rush et al.", "startOffset": 62, "endOffset": 85}, {"referenceID": 5, "context": "Joint constituent and dependency parsing have been tackled by Carreras et al. (2008) and Rush et al. (2010), but the resulting parsers, while accurate, are more expensive than a single c-parser.", "startOffset": 62, "endOffset": 108}, {"referenceID": 5, "context": "Joint constituent and dependency parsing have been tackled by Carreras et al. (2008) and Rush et al. (2010), but the resulting parsers, while accurate, are more expensive than a single c-parser. Very recently, Kong et al. (2015) proposed a much cheaper pipeline in which d-parsing is performed first, followed by a c-parser constrained to be consistent with the predicted d-structure.", "startOffset": 62, "endOffset": 229}, {"referenceID": 25, "context": "10 Kallmeyer and Maier (2013), gold 75.", "startOffset": 3, "endOffset": 30}, {"referenceID": 25, "context": "10 Kallmeyer and Maier (2013), gold 75.75 \u2013 \u2013 \u2013 \u2013 \u2013 van Cranenburgh and Bod (2013), gold \u2013 \u2013 76.", "startOffset": 3, "endOffset": 83}, {"referenceID": 50, "context": "van Cranenburgh and Bod (2013), pred \u2013 \u2013 74.", "startOffset": 4, "endOffset": 31}], "year": 2015, "abstractText": "We reduce phrase-representation parsing to dependency parsing. Our reduction is grounded on a new intermediate representation, \u201chead-ordered dependency trees,\u201d shown to be isomorphic to constituent trees. By encoding order information in the dependency labels, we show that any off-the-shelf, trainable dependency parser can be used to produce constituents. When this parser is non-projective, we can perform discontinuous parsing in a very natural manner. Despite the simplicity of our approach, experiments show that the resulting parsers are on par with strong baselines, such as the Berkeley parser for English and the best single system in the SPMRL-2014 shared task. Results are particularly striking for discontinuous parsing of German, where we surpass the current state of the art by a wide margin.", "creator": "TeX"}}}