{"id": "1503.00332", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2015", "title": "JUMP-Means: Small-Variance Asymptotics for Markov Jump Processes", "abstract": "Markov jump processes (MJPs) are used to model a wide range of phenomena from disease progression to RNA path folding. However, maximum likelihood estimation of parametric models leads to degenerate trajectories and inferential performance is poor in nonparametric models. We take a small-variance asymptotics (SVA) approach to overcome these limitations. We derive the small-variance asymptotics for parametric and nonparametric MJPs for both directly observed and hidden state models. In the parametric case we obtain a novel objective function which leads to non-degenerate trajectories. To derive the nonparametric version we introduce the gamma-gamma process, a novel extension to the gamma-exponential process. We propose algorithms for each of these formulations, which we call \\emph{JUMP-means}. Our experiments demonstrate that JUMP-means is competitive with or outperforms widely used MJP inference approaches in terms of both speed and reconstruction accuracy.", "histories": [["v1", "Sun, 1 Mar 2015 18:59:12 GMT  (3573kb,D)", "https://arxiv.org/abs/1503.00332v1", null], ["v2", "Sun, 31 May 2015 23:26:53 GMT  (3949kb,D)", "http://arxiv.org/abs/1503.00332v2", null], ["v3", "Fri, 5 Jun 2015 16:11:10 GMT  (3949kb,D)", "http://arxiv.org/abs/1503.00332v3", "In Proceedings of the 32nd International Conference on Machine Learning (ICML 2015)"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["jonathan h huggins", "karthik narasimhan", "ardavan saeedi", "vikash k mansinghka"], "accepted": true, "id": "1503.00332"}, "pdf": {"name": "1503.00332.pdf", "metadata": {"source": "META", "title": "JUMP-Means: Small-Variance Asymptotics for  Markov Jump Processes", "authors": ["Jonathan H. Huggins", "Karthik Narasimhan", "Ardavan Saeedi", "Vikash K. Mansinghka"], "emails": ["JHUGGINS@MIT.EDU", "KARTHIKN@CSAIL.MIT.EDU", "ARDAVANS@MIT.EDU", "VKM@MIT.EDU"], "sections": [{"heading": "1. Introduction", "text": "In fact, the majority of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "2. Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Markov Jump Processes", "text": "A Markov jump process (MJP) is defined by (a) a finite (or countable) state space (\u00b7 K), which we use the integers [M], (1,. \u2212 \u2211., \u2212 M]; (b) an initial state probability distribution \u03c0; (c) a (stochastic) state transition matrix P with pss = 0 for all s [M]; and (d) a state with inhabitation time rate vector \u03bb, (... \u00b7 M). The process begins in a state s0 \u0445 \u03c0. When the process enters a state s, it remains there for a residence time exponentially distributed with the parameter p. When the system leaves state s, it passes into state s \u00b2 6 = s with the probability pss \u00b2. An orbit of the MJP is a sequence of states and a residence time of T for each state except for the final state: U, UT, t0, tk, t1, tts1."}, {"heading": "2.2. Previous Approaches to MJP Inference", "text": "There are a number of existing approaches to inferences and learning in MJPs. An algorithm for maximizing expectations (EM) can be derived, but cannot be applied to models with countless infinite states, so it is not suitable for iMJPs (Lange, 2014) (iMJPs are described in detail in Section 4). Furthermore, the maximum probability of discretely observed data with finite entries for the transition matrix obtained from EM may not exist (Bladt & S\u00f8rensen, 2005). The maximum probability amounts to finding maxU ln p (U | \u03c0, P, \u03bb), which can be efficiently performed by dynamic programming (Perkins, 2009). However, the maximum probability solutions for the trajectory are degenerated: Only an infinite amount of time is spent in each state, with the exception of the state visited with the smallest rate parameter (i.e. the longest flight time)."}, {"heading": "2.3. Small-variance Asymptotics", "text": "Consider a Bayesian model p (D | Z, \u03b8, \u03c32) p (Z, \u03b8) in which the probability parameters contain a variance parameter \u03c32. Given some data D, a point estimate for the parameters \u03b8 and latent variables Z of the model can be obtained by maximizing the posterior p (Z, \u03b8 | D, \u03c32) p (D | Z, \u03c3) p (Z, \u03b8), leading to a maximum a posteriori (MAP) estimate. In the SVA approach (Broderick et al., 2013), the MAP optimization is taken into account in the limit, since the probability parameter is taken to zero: \u03c32 \u2192 0. Typically, the small variance limit leads to a much simpler optimization than the MAP optimization with a variance that is not zero. For example, the MAP target for a Gaussian mixing model is simplified to the k mean target."}, {"heading": "3. Parametric MJPs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Directly Observed MJP", "text": "Consider the task of deriving probable states / progression sequences, the O = \u03b2 \u03b2 \u03b2, s \u00b2 i) Ii = 1, the times in which the system was directly observed, and the states of the system at that time. For simplicity, let us assume that t \u00b2 0 = 0 and that all times are in the interval [0, T]. Let s (U, t) is the state of the system that follows the system. (K) The probability of a sequence is \"(U, P,) = 1 [t \u00b7 T] I = 1 [s (U, T) = 1 [s] s (U, i) = s (K, S) \u00b7 i) \u00b7 (K \u00b2 k = 1."}, {"heading": "3.2. Hidden State MJP", "text": "(5) The only difference between the directly observed case and the HMJP is therefore the addition of the observation probability concepts. Since multinomial observations are often used in MJP applications, this is the case. Let us name the number of possible observations and the probability of observation x '= n. The observation probability is scaled in the same way as the transition probabilities, but with \u03b2 = 0.1%. Thus, for the HMJP we get: min U, \u03bb, P, 0.1% = 0.1% (K) + 0.1% (K) + 0.1% (K) + 0.1% (K) + 0.1% (K) + 0.1% (K) + 0.1% (K)."}, {"heading": "3.3. Algorithm", "text": "The optimization of the JUMP mean goals in (A.4) and (6) is not trivial, since we do not know the number of jumps in the MJP, and the combinatorial explosion in the sequences with the number of jump points. The terms that include the continuous variables tk (dwell times) represent additional complexity. We therefore resort to an alternating minimization method to optimize the JUMP mean objective function, similar to that used in Roychowdhury et al. (2013) In each iteration of the optimization process, we first use a modified Viterbi algorithm to obtain the most likely state sequence. Then, we use convex optimization to optimally distribute the jump points in relation to the values from the current state sequence."}, {"heading": "4. Bayesian Nonparametric MJPs", "text": "The iMJP is based on the hierarchical procedure which is based on H and rate parameters. (S0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-0-"}, {"heading": "4.1. Algorithm", "text": "In the iMJP case, we have the additional variables M and Mm = 0 to optimize. Furthermore, the number of variables to optimize depends on the number of states in our model. The most important change to the algorithm from the parametric case is that we have to propose and then accept or reject the addition of new states. (2) For each observation sequence, we apply the Viterbi algorithm and update the times using the new lens function in (14), analogous to steps (3) and (4) in the parametric algorithm. (3) We perform MAP updates for each observation sequence (9) and vice versa, and center the times using the new lens function in (14), analogous to steps (3) and (4) in the parametric algorithm. (3) We perform MAP updates for all states (as in (9) and centric states)."}, {"heading": "5. Experiments", "text": "In this section, we provide a quantitative analysis of the JUMP mean algorithm and compare its performance on synthetic and real data sets with standard inference methods for MJPs. For evaluation, we look at several sequences of discretely observed data and randomly provide a portion of the data. We report reconstruction errors for performance comparison."}, {"heading": "5.1. Parametric Models", "text": "We compared JUMP averages with maximum probability estimation of the MJP parameters we learned from EM (Asger & Ledet, 2005), the MCMC method proposed in Rao & Teh (2013), and a simple baseline in which we ignore the sequential structure of the data. We perform three sets of experiments (2 synthetic, 1 real) for our evaluation. We first generate the lines of the transition probability matrix and transition rates independently of Dir (1) and Gam (1), then we generate 100 different datasets from different MJPs with 10 states. To generate each dataset, we first generate the lines of the transition probability matrix and transition rates independently of Dir (1) and Gam (1), each given the rates and transition probabilities for each dataset, we sample 500 sequences of length 20. We keep 30% of the observations at random reconstruction errors."}, {"heading": "5.2. Nonparametric Model", "text": "We are now looking at a version of the problem of understanding physiological signals discussed in the Introduction. We are using data from the MIMIC database (Goldberger et al., 2000; Moody & Mark, 1996), which contains records of several vital error parameters of ICU patients. Specifically, we are looking at blood pressure measurements of 69 ICU patients collected over a 24-hour period and sub-sample observation sequences of 32 length for each patient, the records of several vital error parameters of ICU patients. We are looking at blood pressure measurements of 69 ICU patients collected over a 24-hour period and sub-sample observation sequences of 32 length for each patient who has fixed the recording of start and end times.2 For the test, we randomly hold 25% of the observations. To initialize the JUMP data, we are selecting uniform matrices for the arrangement of 0 and 2 targets."}, {"heading": "6. Conclusion", "text": "We have derived new objective functions for parametric and Bayesian non-parametric models and proposed efficient algorithms to optimize them. Our experiments show that JUMP means can be used to obtain high-quality, non-degenerated estimates of latent trajectories. JUMP means offer attractive trade-offs between speed and accuracy for both parametric and non-parametric problems and achieve state-of-the-art reconstruction accuracy for non-parametric problems."}, {"heading": "ACKNOWLEDGMENTS", "text": "Thanks to Monir Hajiaghayi, Matthew Johnson and Tejas Kulkarni for helpful comments and discussions. JHH was supported by the US government under FA9550-11C-0028 and awarded by the DoD, Air Force Office of Scientific Research, National Defense Science and Engineering Graduate (NDSEG) Fellowship, 32 CFR 168a."}, {"heading": "A. Parametric MJPs for SVA", "text": "To obtain the SVA target from the parametric MJP model, we begin by scaling the exponential distribution f (t; f) = \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2) \u03b2 (\u03b2)), and the basic measurement is equal to (dt) = 1 (Banerjee et al., 2005). To scale the distribution, we equate the new natural parameter \u03b7 = \u03b2) and the log partitioning function (\u03b7) = \u03b2n (\u03b7). The new basic measurement quantity (dt) is clearly defined by the integral equation (see Banerjee et al al., 2005, theorem 5)."}, {"heading": "B. Bayesian Nonparametric MJPs for SVA", "text": "First of all, we would like to remind you that the Moran gamma process is a distribution over the measured variables. (\u03b2 \u03b2 \u03b2 \u03b2 (\u03b2 \u03b2 \u03b2) is a random measurement that is distributed over the probability range using a Moran gamma method with the basic measurement H. (.),..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "C. Time-accuracy plots for the experiments", "text": "In Fig. C.6, we compare the time accuracy of different methods for different datasets. EM, PMCMC and JUMP means are implemented in Java and MCMC is implemented in Python. To represent the MCMC results, we give a speed boost of 100 times in the results to compensate for Python's slow interpreter. Based on our experience with scientific computer applications, we believe this is a generous adjustment. Furthermore, we note that the EM implementation used in our experiments is not the most optimized in terms of time per iteration, but our goal is to show that JUMP means can achieve comparable performance with a reasonable implementation of MCMC and EM."}, {"heading": "D. Scaling experiments", "text": "For the scaling experiments, we generated 4 data sets consisting of 102 to 105 sequences. All data sets originate from a single hidden state MJP with 5 hidden states and 5 possible observations. For the 20 observations in each sequence, a Gaussian probability is used. Finally, we categorized the observations for the presented results into 5 containers, removed 30% of the data points and predicted their category."}], "references": [{"title": "Particle Markov chain Monte Carlo methods", "author": ["C. Andrieu", "A. Doucet", "R. Holenstein"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Andrieu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Andrieu et al\\.", "year": 2010}, {"title": "Statistical inference in evolutionary models of dna sequences via the em algorithm", "author": ["H. Asger", "J.J. Ledet"], "venue": "Statistical Applications in Genetics and Molecular Biology,", "citeRegEx": "Asger and Ledet,? \\Q2005\\E", "shortCiteRegEx": "Asger and Ledet", "year": 2005}, {"title": "Clustering with bregman divergences", "author": ["A. Banerjee", "S. Merugu", "I.S. Dhillon", "J. Ghosh"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Banerjee et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Banerjee et al\\.", "year": 2005}, {"title": "Statistical inference for discretely observed markov jump processes", "author": ["M. Bladt", "M. S\u00f8rensen"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Bladt and S\u00f8rensen,? \\Q2005\\E", "shortCiteRegEx": "Bladt and S\u00f8rensen", "year": 2005}, {"title": "Efficient estimation of transition rates between credit ratings from observations at discrete time points", "author": ["M. Bladt", "M. S\u00f8rensen"], "venue": "Quantitative Finance,", "citeRegEx": "Bladt and S\u00f8rensen,? \\Q2009\\E", "shortCiteRegEx": "Bladt and S\u00f8rensen", "year": 2009}, {"title": "MAD-Bayes: MAP-based Asymptotic Derivations from Bayes", "author": ["T. Broderick", "B. Kulis", "M.I. Jordan"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Broderick et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Broderick et al\\.", "year": 2013}, {"title": "Efficient Continuous-Time Markov Chain Estimation", "author": ["M. Hajiaghayi", "B. Kirkpatrick", "L. Wang", "A. BouchardC\u00f4t\u00e9"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Hajiaghayi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hajiaghayi et al\\.", "year": 2014}, {"title": "Small-variance asymptotics for exponential family dirichlet process mixture models", "author": ["K. Jiang", "B. Kulis", "M.I. Jordan"], "venue": "In NIPS, pp", "citeRegEx": "Jiang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jiang et al\\.", "year": 2012}, {"title": "Revisiting k-means: New Algorithms via Bayesian Nonparametrics", "author": ["B. Kulis", "M.I. Jordan"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Kulis and Jordan,? \\Q2012\\E", "shortCiteRegEx": "Kulis and Jordan", "year": 2012}, {"title": "Latent Continuous Time Markov Chains for Partially-Observed Multistate Disease Processes", "author": ["J. Lange"], "venue": "PhD thesis,", "citeRegEx": "Lange,? \\Q2014\\E", "shortCiteRegEx": "Lange", "year": 2014}, {"title": "Estimating disease progression using panel", "author": ["M. Mandel"], "venue": "data. Biostatistics,", "citeRegEx": "Mandel,? \\Q2010\\E", "shortCiteRegEx": "Mandel", "year": 2010}, {"title": "A database to support development and evaluation of intelligent intensive care monitoring", "author": ["G. Moody", "R. Mark"], "venue": "In Computers in Cardiology,", "citeRegEx": "Moody and Mark,? \\Q1996\\E", "shortCiteRegEx": "Moody and Mark", "year": 1996}, {"title": "NIST Handbook of Mathematical Functions", "author": ["F.W.J. Olver", "D.W. Lozier", "R.F. Boisvert", "Clark", "C.W. (eds"], "venue": null, "citeRegEx": "Olver et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Olver et al\\.", "year": 2010}, {"title": "Maximum likelihood trajectories for continuous-time markov chains", "author": ["T.J. Perkins"], "venue": "In NIPS,", "citeRegEx": "Perkins,? \\Q2009\\E", "shortCiteRegEx": "Perkins", "year": 2009}, {"title": "Fast MCMC sampling for Markov jump processes and extensions", "author": ["V. Rao", "Y.W. Teh"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Rao and Teh,? \\Q2013\\E", "shortCiteRegEx": "Rao and Teh", "year": 2013}, {"title": "Small-Variance Asymptotics for Hidden Markov Models", "author": ["A. Roychowdhury", "K. Jiang", "B. Kulis"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Roychowdhury et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Roychowdhury et al\\.", "year": 2013}, {"title": "Priors over recurrent continuous time processes", "author": ["A. Saeedi", "A. Bouchard-C\u00f4t\u00e9"], "venue": "In NIPS,", "citeRegEx": "Saeedi and Bouchard.C\u00f4t\u00e9,? \\Q2011\\E", "shortCiteRegEx": "Saeedi and Bouchard.C\u00f4t\u00e9", "year": 2011}, {"title": "Hierarchical Dirichlet Processes", "author": ["Y.W. Teh", "M.I. Jordan", "M.J. Beal", "D.M. Blei"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Teh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Teh et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 10, "context": "gression (Mandel, 2010) and RNA path folding (Hajiaghayi et al.", "startOffset": 9, "endOffset": 23}, {"referenceID": 6, "context": "gression (Mandel, 2010) and RNA path folding (Hajiaghayi et al., 2014), or when the state is only observed indirectly, as in corporate bond rating (Bladt & S\u00f8rensen, 2009).", "startOffset": 45, "endOffset": 70}, {"referenceID": 13, "context": "Furthermore, although MJPs are viewed as more realistic than their discrete-time counterparts in many fields (Rao & Teh, 2013), degenerate solutions for the maximum likelihood (ML) trajectories for both directly and indirectly observed cases (Perkins, 2009), and non-existence of the ML transition matrix (obtained from EM) for some indirectly observed cases (Bladt & S\u00f8rensen, 2009) present inferential challenges.", "startOffset": 242, "endOffset": 257}, {"referenceID": 7, "context": "SVA has been applied to (hierarchical) Dirichlet process mixture models (Kulis & Jordan, 2012; Jiang et al., 2012), Bayesian nonparametric latent feature models (Broderick et al.", "startOffset": 72, "endOffset": 114}, {"referenceID": 5, "context": ", 2012), Bayesian nonparametric latent feature models (Broderick et al., 2013), hidden Markov models (HMMs), and infinite-state HMMs (Roychowdhury et al.", "startOffset": 54, "endOffset": 78}, {"referenceID": 15, "context": ", 2013), hidden Markov models (HMMs), and infinite-state HMMs (Roychowdhury et al., 2013).", "startOffset": 62, "endOffset": 89}, {"referenceID": 9, "context": "An expectation-maximization (EM) algorithm can be derived, but it cannot be applied to models with countably infinite states, so it is not suitable for iMJPs (Lange, 2014) (iMJPs are detailed in Section 4).", "startOffset": 158, "endOffset": 171}, {"referenceID": 13, "context": "Maximum likelihood inference amounts to finding maxU ln p(U |\u03c0, P,\u03bb), which can be carried out efficiently using dynamic programming (Perkins, 2009).", "startOffset": 133, "endOffset": 148}, {"referenceID": 0, "context": "(2014) which is based on particle MCMC (PMCMC) methods (Andrieu et al., 2010).", "startOffset": 55, "endOffset": 77}, {"referenceID": 5, "context": "Recently, a more efficient Monte Carlo method was proposed in Hajiaghayi et al. (2014) which is based on particle MCMC (PMCMC) methods (Andrieu et al.", "startOffset": 62, "endOffset": 87}, {"referenceID": 5, "context": "In the SVA approach (Broderick et al., 2013), the MAP optimization is considered in the limit as the likelihood variance parameter is taken to zero: \u03c3 \u2192 0.", "startOffset": 20, "endOffset": 44}, {"referenceID": 7, "context": "Following (Jiang et al., 2012), we scale the distributions by an inverse variance parameter \u03b2 and then maximize the scaled likelihood and prior in the limit \u03b2 \u2192\u221e (i.", "startOffset": 10, "endOffset": 30}, {"referenceID": 15, "context": "We therefore resort to an alternating minimization procedure to optimize the JUMP-means objective function, similar in spirit to the one used in Roychowdhury et al. (2013). In each iteration of the optimization process, we first use a modified Viterbi algorithm to obtain the most likely state sequence.", "startOffset": 145, "endOffset": 172}, {"referenceID": 7, "context": ", Jiang et al. (2012); Roychowdhury et al.", "startOffset": 2, "endOffset": 22}, {"referenceID": 7, "context": ", Jiang et al. (2012); Roychowdhury et al. (2013)).", "startOffset": 2, "endOffset": 50}, {"referenceID": 10, "context": ", Mandel (2010)).", "startOffset": 2, "endOffset": 16}, {"referenceID": 0, "context": "We compare with particle MCMC (PMCMC) (Andrieu et al., 2010) and EM.", "startOffset": 38, "endOffset": 60}], "year": 2015, "abstractText": "Markov jump processes (MJPs) are used to model a wide range of phenomena from disease progression to RNA path folding. However, maximum likelihood estimation of parametric models leads to degenerate trajectories and inferential performance is poor in nonparametric models. We take a small-variance asymptotics (SVA) approach to overcome these limitations. We derive the small-variance asymptotics for parametric and nonparametric MJPs for both directly observed and hidden state models. In the parametric case we obtain a novel objective function which leads to non-degenerate trajectories. To derive the nonparametric version we introduce the gamma-gamma process, a novel extension to the gamma-exponential process. We propose algorithms for each of these formulations, which we call JUMP-means. Our experiments demonstrate that JUMP-means is competitive with or outperforms widely used MJP inference approaches in terms of both speed and reconstruction accuracy.", "creator": "LaTeX with hyperref package"}}}