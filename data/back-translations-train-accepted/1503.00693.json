{"id": "1503.00693", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2015", "title": "Bayesian Optimization of Text Representations", "abstract": "When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts. These choices can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well. We propose an approach to optimizing over this space of choices, formulating the problem as global optimization. We apply a sequential model-based optimization technique and show that our method makes standard linear models competitive with more sophisticated, expensive state-of-the-art methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems. Our approach is a first step towards black-box NLP systems that work with raw text and do not require manual tuning.", "histories": [["v1", "Mon, 2 Mar 2015 20:23:18 GMT  (215kb,D)", "http://arxiv.org/abs/1503.00693v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG stat.ML", "authors": ["dani yogatama", "lingpeng kong", "noah a smith"], "accepted": true, "id": "1503.00693"}, "pdf": {"name": "1503.00693.pdf", "metadata": {"source": "CRF", "title": "Bayesian Optimization of Text Representations", "authors": ["Dani Yogatama", "Noah A. Smith"], "emails": ["dyogatama@cs.cmu.edu", "nasmith@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "NLP researchers and practitioners spend a considerable amount of time comparing machine-learned text models that differ in relatively uninteresting ways. For example, should bigrams be included in the \"word bag\" when categorizing texts and tf-idf weigh a good idea? These decisions are experimental and often result in large performance differences with low consistency between tasks and datasets in which a combination of decisions works best. Unfortunately, these differences tell us little about language or the problems that machine learners are supposed to solve.We suggest that these decisions can be automated in a similar way to hyperparameter selection (e.g. choosing the strength of a ridge or lasso regulator).Given a particular text dataset and the classification task, we are introducing a technique for optimizing over the space of representative decisions, along with other \"nuances\" that interact with these decisions, such as hyperparameter selection."}, {"heading": "2 Problem Formulation and Notation", "text": "Let the training data consist of a collection of pairs of dtrain = < d.i1, d.o1 >,. < d.in, d.on > >, where each input d.i-I is a text document and each output d.o-O, the output space. The general training goal is to maximize a performance function f (e.g., classification accuracy, log probability, F1 score, etc.) of a machine-learned model, on a held dataset, ddev (I \u00b7 O) n \u2032. Classfication proceeds in three steps: Firstly, RN maps any input to a vector representation. Secondly, a classifier is learned from the inputs (now converted into vectors \"c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c c"}, {"heading": "3 Bayesian Optimization", "text": "Our approach is based on sequential model-based optimization (SMBO; Hutter et al., 2011). It selects iterative representation functions x. In each round, it makes this choice using a non-parametrically estimated probability model of f, then evaluates f - we are talking about a \"study.\" As with any iterative search algorithm, the goal is to balance the exploration of options for x with the utilization of previously explored options, so that a good choice is found in a small number of studies. See algorithm 1. More specifically, xt is selected in the tallest experiment using a capture function A and a \"surrogate\" probability model pt. Second, f is evaluated using xt - a costly operation that requires the selection of parameters w and the evaluation of performance based on the data provided. Third, the probability model is updated using a non-parametric estimator."}, {"heading": "3.1 Acquisition Function", "text": "Good gainful employment provides high values for x, so that either the value f (x) is predicted as high, or because uncertainty about the value f (x) is high; a balance between these is the classic trade-off between exploitation and exploration. We use a criterion called Expected Improvement (EI; Jones, 2001), which is the expectation (according to the current replacement model pt) that the choice will exceed y y y y: A (x; pt, y) = 2,000 \u2212 \u221e max (y \u2212 y, 0) pt (y | x) coloring is selected according to the surrogate model discussed below. (For now, we consider it a powerful \"benchmark\" value of f discovered in previous iterations.) Other options for gainful employment are the maximum probability of improvement (Jones, 2001), the minimum conditional entropy (Villemonteix et al., 2006), the Gauss process is tied to the upper limit of confidence (Srvas et al., work selected most frequently), or a combination of them."}, {"heading": "3.2 Surrogate Model", "text": "As a replacement model, we use a tree-structured parcel estimator (TPE; Bergantasian et al., 2011). This is a non-parametric approach to density estimation. We try to estimate pt (y | x) where y = f (x), the performance function that is expensive, accurately calculate. The TPE approach is as follows: pt (y | x), p (y), p (x | y) pt (x | y) pt (x), p (x) p (x), if y < y (x), if y < y (y), p), p), p \"p\", p \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" p, \"p,\" x, \"x,\" x, \"x, x, x., x, x., x, x, x., x, x., x, x., x., x.,\" x, x., x., \"x, x, x, x.\" x. \"x,\" x, \"x,\" x, x, \"x, x,\" x, x, x., \"x,\" x, \"x,\" x, \"x,\" x, \"x,\" x, x., \"x,\" x, \"x,\" x, \"x,\" x, \"x,\" x, \"x,\" x, \"x.,\" x, \"x,\" x."}, {"heading": "3.3 Implementation Details", "text": "Since SMBO research is active, many implementations are publicly available; we use the HPOlib library (Eggensperger et al., 2013).2 The library takes as input a function L that is treated like a black box - in our case a logistics regression trainer that encloses the LIBLINEAR library (Fan et al., 2008), based on the Trust Region Newton Method (Lin et al., 2008) - and a specification of hyperparameters."}, {"heading": "4 Experiments", "text": "Our experiments consider representative choices and hyperparameters for different text categorization problems."}, {"heading": "4.1 Setup", "text": "We fix our learner L on logistic regression. We optimize the text representation based on the n-gram types used, the type of weighting scheme and the removal of stop words. For n-grams we have two parameters, minimum and maximum lengths (nmin and nmax). (All n-gram lengths between the minimum and maximum, including, are used.) For the weighting scheme we consider Term Frequency, tf-idf and binary schemes. Finally, we also choose whether we should remove stop words before constructing feature vectors for each document. Furthermore, the choice of representation interacts with the regulator and the training convergence criterion (e.g. more n-gram means shorter training time). We consider two regulators, '1 penalty (Tibshirani, 1996) or square' 2 penalty (Hoerl and Kennard, 1970). We also have hyperparameters for regulation strength and tolerance."}, {"heading": "4.2 Datasets", "text": "We rate our method on five text categorization tasks. \u2022 Stanford sentiment treebank (Socher et al., 2013): a sentence-level sentiment analysis dataset for movie reviews from the rottentomatoes.com website. We use the binary classification task, in which the goal is to predict whether a review is positive or negative (no neutral reviews). We have this dataset from http: / / nlp.stanford. edu / sentiment. \u2022 Electronics product reviews from Amazon (McAuley and Leskovec, 2013): This dataset consists of electronic product reviews that are a subset of a large Amazon review dataset."}, {"heading": "4.3 Baselines", "text": "For each set of data, we select monitored, non-ensemble classification methods from the previous literature as baselines. In any case, we value comparisons with the best published linear method (often an SVM with a linear core and representation selected by experts) and the overall best published method. In the following, \"SVM\" always means \"linear SVM.\" All methods were trained and evaluated on the basis of the same training / test data splits; in cases where standard development sets were not available, we randomly used 20% of the training data as a development set."}, {"heading": "4.4 Results", "text": "We summarize the hyperparameters selected by our method and the accuracies achieved (on test data) in Table 3. We discuss comparisons to baselines for each dataset in the Turn.Stanford sentimenttreebank (Table 4).Our logistic regression model exceeds that of Socher et al. (2013), which used only unique specimens but did not specify the weighting scheme for their SVM baselines. Our result is still below the state of the art based on the recursive neural tensor networks (Socher et al., 2013), which only use unique specimens but do not specify the weighting scheme for their SVM baselines. We show that logistic regression is comparable to recursive and matrix-vectorial neural networks (Socher et al., 2011; Socher et al., 2012).Amazonas electronics (Table 5). The best performed methods on this dataset."}, {"heading": "5 Discussion", "text": "This year, it is more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country."}, {"heading": "6 Conclusion", "text": "We used a Bayesian optimization approach to optimize the selection of text representations for various categorization problems. Our sequential model-based optimization technique identifies settings for a standard linear model (logistic regression) that can compete with far more advanced methods of topic classification and sentiment analysis. Each task and data set has its own optimal choices; though relatively uninteresting to researchers and not directly related to domain or language knowledge, these choices have a big impact on performance. We see our approach as a first step toward black box NLP systems that work with raw text and do not require manual coordination."}, {"heading": "Acknowledgements", "text": "This work was supported by grants from the Defense Advanced Research Projects Agency and computing resources provided by Amazon."}], "references": [{"title": "The power of negative thinking: Exploiting label disagreement in the min-cut classification framework", "author": ["Mohit Bansal", "Clair Cardie", "Lillian Lee."], "venue": "Proc. of COLING.", "citeRegEx": "Bansal et al\\.,? 2008", "shortCiteRegEx": "Bansal et al\\.", "year": 2008}, {"title": "Collaborative hyperparameter tuning", "author": ["Remi Bardenet", "Matyas Brendel", "Balazs Kegl", "Michele Sebag."], "venue": "Proc. of ICML.", "citeRegEx": "Bardenet et al\\.,? 2013", "shortCiteRegEx": "Bardenet et al\\.", "year": 2013}, {"title": "Algorithms for hyper-parameter optimization", "author": ["James Bergstra", "Remi Bardenet", "Yoshua Bengio", "Balazs Kegl."], "venue": "Proc. of NIPS.", "citeRegEx": "Bergstra et al\\.,? 2011", "shortCiteRegEx": "Bergstra et al\\.", "year": 2011}, {"title": "Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures", "author": ["James Bergstra", "Daniel Yamins", "David Cox."], "venue": "Proc. of ICML.", "citeRegEx": "Bergstra et al\\.,? 2013", "shortCiteRegEx": "Bergstra et al\\.", "year": 2013}, {"title": "Training restricted boltzmann machines on word observations", "author": ["George E. Dahl", "Ryan P. Adams", "Hugo Larochelle."], "venue": "Proc. of ICML.", "citeRegEx": "Dahl et al\\.,? 2012", "shortCiteRegEx": "Dahl et al\\.", "year": 2012}, {"title": "Parallelizing explorationexploitation tradeoffs with gaussian process bandit optimization", "author": ["Thomas Desautels", "Andreas Krause", "Joel Burdick."], "venue": "Proc. of ICML.", "citeRegEx": "Desautels et al\\.,? 2012", "shortCiteRegEx": "Desautels et al\\.", "year": 2012}, {"title": "Towards an empirical foundation for assessing bayesian optimization of hyperparameters", "author": ["Katharina Eggensperger", "Matthias Feurer", "Frank Hutter", "James Bergstra", "Jasper Snoek", "Holger H. Hoos", "Kevin Leyton-Brown."], "venue": "Proc. of NIPS Workshop on", "citeRegEx": "Eggensperger et al\\.,? 2013", "shortCiteRegEx": "Eggensperger et al\\.", "year": 2013}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "XiangRui Wang", "Chih-Jen Lin."], "venue": "Journal of Machine Learning Research, (9):1871\u20131874.", "citeRegEx": "Fan et al\\.,? 2008", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Ridge regression: Biased estimation for nonorthogonal problems", "author": ["Arthur E. Hoerl", "Robert W. Kennard."], "venue": "Technometrics, 12(1):55\u201367.", "citeRegEx": "Hoerl and Kennard.,? 1970", "shortCiteRegEx": "Hoerl and Kennard.", "year": 1970}, {"title": "Portfolio allocation for bayesian optimization", "author": ["Matthew Hoffman", "Eric Brochu", "Nando de Freitas."], "venue": "Proc. of UAI.", "citeRegEx": "Hoffman et al\\.,? 2011", "shortCiteRegEx": "Hoffman et al\\.", "year": 2011}, {"title": "Sequential model-based optimization for general algorithm configuration", "author": ["Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown."], "venue": "Proc. of LION-5.", "citeRegEx": "Hutter et al\\.,? 2011", "shortCiteRegEx": "Hutter et al\\.", "year": 2011}, {"title": "Parallel algorithm configuration", "author": ["Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown."], "venue": "Proc. of LION.", "citeRegEx": "Hutter et al\\.,? 2012", "shortCiteRegEx": "Hutter et al\\.", "year": 2012}, {"title": "Effective use of word order for text categorization with convolutional neural networks", "author": ["Rie Johnson", "Tong Zhang."], "venue": "arXiv:1412.1058.", "citeRegEx": "Johnson and Zhang.,? 2014", "shortCiteRegEx": "Johnson and Zhang.", "year": 2014}, {"title": "A taxonomy of global optimization methods based on response surfaces", "author": ["Donald R. Jones."], "venue": "Journal of Global Optimization, 21:345\u2013385.", "citeRegEx": "Jones.,? 2001", "shortCiteRegEx": "Jones.", "year": 2001}, {"title": "Newsweeder: Learning to filter netnews", "author": ["Ken Lang."], "venue": "Proc. of ICML.", "citeRegEx": "Lang.,? 1995", "shortCiteRegEx": "Lang.", "year": 1995}, {"title": "Classification using discriminative restricted boltzmann machines", "author": ["Hugo Larochelle", "Yoshua Bengio."], "venue": "Proc. of ICML.", "citeRegEx": "Larochelle and Bengio.,? 2008", "shortCiteRegEx": "Larochelle and Bengio.", "year": 2008}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V. Le", "Tomas Mikolov."], "venue": "Proc. of ICML.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Trust region newton method for large-scale logistic regression", "author": ["Chih-Jen Lin", "Ruby C. Weng", "S. Sathiya Keerthi."], "venue": "Journal of Machine Learning Research, (9):627\u2013650.", "citeRegEx": "Lin et al\\.,? 2008", "shortCiteRegEx": "Lin et al\\.", "year": 2008}, {"title": "Learning word vectors for sentiment analysis", "author": ["Andrew L. Maas", "Raymond E. Daly", "Peter T. Pham", "Dan Huang", "Andrew Y. Ng", "Christopher Potts."], "venue": "Proc. of ACL.", "citeRegEx": "Maas et al\\.,? 2011", "shortCiteRegEx": "Maas et al\\.", "year": 2011}, {"title": "Hidden factors and hidden topics: understanding rating dimensions with review text", "author": ["Julian McAuley", "Jure Leskovec."], "venue": "Proc. of RecSys.", "citeRegEx": "McAuley and Leskovec.,? 2013", "shortCiteRegEx": "McAuley and Leskovec.", "year": 2013}, {"title": "Compressive feature learning", "author": ["Hristo S. Paskov", "Robert West", "John C. Mitchell", "Trevor J. Hastie."], "venue": "Proc of NIPS.", "citeRegEx": "Paskov et al\\.,? 2013", "shortCiteRegEx": "Paskov et al\\.", "year": 2013}, {"title": "Gaussian Processes for Machine Learning", "author": ["Carl Edward Rasmussen", "Christopher K.I. Williams."], "venue": "The MIT Press.", "citeRegEx": "Rasmussen and Williams.,? 2006", "shortCiteRegEx": "Rasmussen and Williams.", "year": 2006}, {"title": "Practical bayesian optimization of machine learning algorithms", "author": ["Jasper Snoek", "Hugo Larrochelle", "Ryan P. Adams."], "venue": "Proc. of NIPS.", "citeRegEx": "Snoek et al\\.,? 2012", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Semi-supervised recursive autoencoders for predicting sentiment distributions", "author": ["Richard Socher", "Jeffrey Pennington", "Eric H. Huang", "Andrew Y. Ng", "Christopher D. Manning."], "venue": "Proc. of EMNLP.", "citeRegEx": "Socher et al\\.,? 2011", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Semantic compositionality through recursive matrix-vector spaces", "author": ["Richard Socher", "Brody Huval", "Christopher D. Manning", "Andrew Y. Ng."], "venue": "Proc. of EMNLP.", "citeRegEx": "Socher et al\\.,? 2012", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Chris Manning", "Andrew Ng", "Chris Potts."], "venue": "Proc. of EMNLP.", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Learning distributed representations for structured output prediction", "author": ["Vivek Srikumar", "Christopher D. Manning."], "venue": "Proc. of NIPS.", "citeRegEx": "Srikumar and Manning.,? 2014", "shortCiteRegEx": "Srikumar and Manning.", "year": 2014}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["Niranjan Srinivas", "Andreas Krause", "Sham Kakade", "Matthias Seeger."], "venue": "Proc. of ICML.", "citeRegEx": "Srinivas et al\\.,? 2010", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Multi-task bayesian optimization", "author": ["Kevin Swersky", "Jasper Snoek", "Ryan P. Adams."], "venue": "Proc. of NIPS.", "citeRegEx": "Swersky et al\\.,? 2013", "shortCiteRegEx": "Swersky et al\\.", "year": 2013}, {"title": "Get out the vote: Determining support or opposition from congressional floor-debate transcripts", "author": ["Matt Thomas", "Bo Pang", "Lilian Lee."], "venue": "Proc. of EMNLP.", "citeRegEx": "Thomas et al\\.,? 2006", "shortCiteRegEx": "Thomas et al\\.", "year": 2006}, {"title": "Regression shrinkage and selection via the lasso", "author": ["Robert Tibshirani."], "venue": "Journal of Royal Statistical Society B, 58(1):267\u2013288.", "citeRegEx": "Tibshirani.,? 1996", "shortCiteRegEx": "Tibshirani.", "year": 1996}, {"title": "An informational approach to the global optimization of expensive-to-evaluate functions", "author": ["Julien Villemonteix", "Emmanuel Vazquez", "Eric Walter."], "venue": "Journal of Global Optimization.", "citeRegEx": "Villemonteix et al\\.,? 2006", "shortCiteRegEx": "Villemonteix et al\\.", "year": 2006}, {"title": "Baselines and bigrams: Simple, good sentiment and topic classification", "author": ["Sida Wang", "Christopher D. Manning."], "venue": "Proc. of ACL.", "citeRegEx": "Wang and Manning.,? 2012", "shortCiteRegEx": "Wang and Manning.", "year": 2012}, {"title": "Multi-level structured models for document sentiment classification", "author": ["Ainur Yessenalina", "Yisong Yue", "Claire Cardie."], "venue": "Proc. of EMNLP.", "citeRegEx": "Yessenalina et al\\.,? 2010", "shortCiteRegEx": "Yessenalina et al\\.", "year": 2010}, {"title": "Efficient transfer learning method for automatic hyperparameter tuning", "author": ["Dani Yogatama", "Gideon Mann."], "venue": "Proc. of AISTATS.", "citeRegEx": "Yogatama and Mann.,? 2014", "shortCiteRegEx": "Yogatama and Mann.", "year": 2014}], "referenceMentions": [{"referenceID": 10, "context": "Our technique instantiates sequential modelbased optimization (SMBO; Hutter et al., 2011).", "startOffset": 62, "endOffset": 89}, {"referenceID": 2, "context": "SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 103, "endOffset": 168}, {"referenceID": 9, "context": "SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 103, "endOffset": 168}, {"referenceID": 22, "context": "SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 103, "endOffset": 168}, {"referenceID": 3, "context": "Though popular in computer vision (Bergstra et al., 2013), these techniques have received little attention in NLP.", "startOffset": 34, "endOffset": 57}, {"referenceID": 10, "context": "Our approach is based on sequential model-based optimization (SMBO; Hutter et al., 2011).", "startOffset": 61, "endOffset": 88}, {"referenceID": 13, "context": "We use a criterion called Expected Improvement (EI; Jones, 2001), which is the expectation (under the current surrogate model pt) that the choice y will exceed y\u2217:", "startOffset": 47, "endOffset": 64}, {"referenceID": 13, "context": ") Other options for the acquisition function include maximum probability of improvement (Jones, 2001), minimum conditional entropy (Villemonteix et al.", "startOffset": 88, "endOffset": 101}, {"referenceID": 31, "context": ") Other options for the acquisition function include maximum probability of improvement (Jones, 2001), minimum conditional entropy (Villemonteix et al., 2006), Gaussian process upper confidence bound (Srinivas et al.", "startOffset": 131, "endOffset": 158}, {"referenceID": 27, "context": ", 2006), Gaussian process upper confidence bound (Srinivas et al., 2010), or a combination of them (Hoffman et al.", "startOffset": 49, "endOffset": 72}, {"referenceID": 9, "context": ", 2010), or a combination of them (Hoffman et al., 2011).", "startOffset": 34, "endOffset": 56}, {"referenceID": 2, "context": "As a surrogate model, we use a tree-structured Parzen estimator (TPE; Bergstra et al., 2011).", "startOffset": 64, "endOffset": 92}, {"referenceID": 2, "context": "As shown by Bergstra et al. (2011), the Expected Improvement in TPE can be written as:", "startOffset": 12, "endOffset": 35}, {"referenceID": 21, "context": "Another common approach to the surrogate is the Gaussian Process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 65, "endOffset": 137}, {"referenceID": 9, "context": "Another common approach to the surrogate is the Gaussian Process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 65, "endOffset": 137}, {"referenceID": 22, "context": "Another common approach to the surrogate is the Gaussian Process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012).", "startOffset": 65, "endOffset": 137}, {"referenceID": 2, "context": "Like Bergstra et al. (2011), our preliminary experiments found the TPE to perform favorably.", "startOffset": 5, "endOffset": 28}, {"referenceID": 6, "context": "Because research on SMBO is active, many implementations are publicly available; we use the HPOlib library (Eggensperger et al., 2013).", "startOffset": 107, "endOffset": 134}, {"referenceID": 17, "context": ", 2008), based on the trust region Newton method (Lin et al., 2008)\u2014and a specification of hyperparameters.", "startOffset": 49, "endOffset": 67}, {"referenceID": 30, "context": "We consider two regularizers, `1 penalty (Tibshirani, 1996) or squared `2 penalty (Hoerl and Kennard, 1970).", "startOffset": 41, "endOffset": 59}, {"referenceID": 8, "context": "We consider two regularizers, `1 penalty (Tibshirani, 1996) or squared `2 penalty (Hoerl and Kennard, 1970).", "startOffset": 82, "endOffset": 107}, {"referenceID": 25, "context": "\u2022 Stanford sentiment treebank (Socher et al., 2013): a sentence-level sentiment analysis dataset for movie reviews from the rottentomatoes.", "startOffset": 30, "endOffset": 51}, {"referenceID": 19, "context": "\u2022 Electronics product reviews from Amazon (McAuley and Leskovec, 2013): this dataset consists of electronic product reviews, which is a subset of a large Amazon review dataset.", "startOffset": 42, "endOffset": 70}, {"referenceID": 18, "context": "\u2022 IMDB movie reviews (Maas et al., 2011): a binary sentiment analysis dataset of highly Dataset Training Dev.", "startOffset": 21, "endOffset": 40}, {"referenceID": 12, "context": "Following the setup of Johnson and Zhang (2014), we only use the text section and ignore the summary section.", "startOffset": 23, "endOffset": 48}, {"referenceID": 29, "context": "\u2022 Congressional vote (Thomas et al., 2006): transcripts from the U.", "startOffset": 21, "endOffset": 42}, {"referenceID": 29, "context": "Similar to previous work (Thomas et al., 2006; Yessenalina et al., 2010), we consider the task to predict the vote (\u201cyea\u201d or \u201cnay\u201d) for the speaker of each speech segment (speaker-based speech-segment classification).", "startOffset": 25, "endOffset": 72}, {"referenceID": 33, "context": "Similar to previous work (Thomas et al., 2006; Yessenalina et al., 2010), we consider the task to predict the vote (\u201cyea\u201d or \u201cnay\u201d) for the speaker of each speech segment (speaker-based speech-segment classification).", "startOffset": 25, "endOffset": 72}, {"referenceID": 14, "context": "\u2022 20 Newsgroups (Lang, 1995): the 20 Newsgroups dataset is a benchmark topic classification dataset, we use the publicly available copy at http://qwone.", "startOffset": 16, "endOffset": 28}, {"referenceID": 25, "context": "While our result is still below the state-of-the-art based on the the recursive neural tensor networks (Socher et al., 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al.", "startOffset": 103, "endOffset": 124}, {"referenceID": 16, "context": ", 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al.", "startOffset": 33, "endOffset": 55}, {"referenceID": 23, "context": ", 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al., 2011; Socher et al., 2012).", "startOffset": 153, "endOffset": 195}, {"referenceID": 24, "context": ", 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al., 2011; Socher et al., 2012).", "startOffset": 153, "endOffset": 195}, {"referenceID": 22, "context": "Our logistic regression model outperforms the baseline SVM reported by Socher et al. (2013), who used only unigrams but did not specify the weighting scheme for their SVM baseline.", "startOffset": 71, "endOffset": 92}, {"referenceID": 12, "context": "The bestperforming methods on this dataset are based on convolutional neural networks (Johnson and Zhang, 2014).", "startOffset": 86, "endOffset": 111}, {"referenceID": 22, "context": "Scores are as reported by Socher et al. (2013) and Le and Mikolov (2014).", "startOffset": 26, "endOffset": 47}, {"referenceID": 16, "context": "(2013) and Le and Mikolov (2014).", "startOffset": 11, "endOffset": 33}, {"referenceID": 12, "context": "Scores are as reported by Johnson and Zhang (2014).", "startOffset": 26, "endOffset": 51}, {"referenceID": 12, "context": "close to convolutional neural networks (Johnson and Zhang, 2014), which are state-of-the-art.", "startOffset": 39, "endOffset": 64}, {"referenceID": 20, "context": "(2012), and compressive feature learning (Paskov et al., 2013).", "startOffset": 41, "endOffset": 62}, {"referenceID": 4, "context": "5 It outperforms SVMs and feed-forward neural networks, the restricted Boltzmann machine approach presented by Dahl et al. (2012), and compressive feature learning (Paskov et al.", "startOffset": 111, "endOffset": 130}, {"referenceID": 29, "context": "SVM results are from Wang and Manning (2012), the RBM (restricted Bolzmann machine) result is from Dahl et al.", "startOffset": 21, "endOffset": 45}, {"referenceID": 4, "context": "SVM results are from Wang and Manning (2012), the RBM (restricted Bolzmann machine) result is from Dahl et al. (2012), NN and CNN results are from Johnson and Zhang (2014), and LR{1, 2, 3, 4, 5}-grams and compressive feature learning results are from Paskov et al.", "startOffset": 99, "endOffset": 118}, {"referenceID": 4, "context": "SVM results are from Wang and Manning (2012), the RBM (restricted Bolzmann machine) result is from Dahl et al. (2012), NN and CNN results are from Johnson and Zhang (2014), and LR{1, 2, 3, 4, 5}-grams and compressive feature learning results are from Paskov et al.", "startOffset": 99, "endOffset": 172}, {"referenceID": 4, "context": "SVM results are from Wang and Manning (2012), the RBM (restricted Bolzmann machine) result is from Dahl et al. (2012), NN and CNN results are from Johnson and Zhang (2014), and LR{1, 2, 3, 4, 5}-grams and compressive feature learning results are from Paskov et al. (2013).", "startOffset": 99, "endOffset": 272}, {"referenceID": 33, "context": "Our method outperforms the best reported results of Yessenalina et al. (2010), which use a multi-level structured model based on a latent-variable SVM.", "startOffset": 52, "endOffset": 78}, {"referenceID": 29, "context": "SVM-link exploits link structures (Thomas et al., 2006); the min-cut result is from Bansal et al.", "startOffset": 34, "endOffset": 55}, {"referenceID": 0, "context": ", 2006); the min-cut result is from Bansal et al. (2008); and SVM-SLE result is reported by Yessenalina et al.", "startOffset": 36, "endOffset": 57}, {"referenceID": 0, "context": ", 2006); the min-cut result is from Bansal et al. (2008); and SVM-SLE result is reported by Yessenalina et al. (2010).", "startOffset": 36, "endOffset": 118}, {"referenceID": 26, "context": "cluding the distributed structured output model (Srikumar and Manning, 2014).", "startOffset": 48, "endOffset": 76}, {"referenceID": 20, "context": "7 The strong logistic regression baseline from Paskov et al. (2013) uses all 5-grams, heuristic normalization, and elastic net regularization; our method found that unigrams and bigrams, with binary weighting and `2 penalty, achieved far better results.", "startOffset": 47, "endOffset": 68}, {"referenceID": 15, "context": "The disriminative RBM result is from Larochelle and Bengio (2008); compressive feature learning and LR-5-grams results are from Paskov et al.", "startOffset": 37, "endOffset": 66}, {"referenceID": 15, "context": "The disriminative RBM result is from Larochelle and Bengio (2008); compressive feature learning and LR-5-grams results are from Paskov et al. (2013), and the distributed structured output result is from Srikumar and Manning (2014).", "startOffset": 37, "endOffset": 149}, {"referenceID": 15, "context": "The disriminative RBM result is from Larochelle and Bengio (2008); compressive feature learning and LR-5-grams results are from Paskov et al. (2013), and the distributed structured output result is from Srikumar and Manning (2014).", "startOffset": 37, "endOffset": 231}, {"referenceID": 32, "context": "x Wang and Manning (2012) report a bigram na\u0131\u0308ve Bayes model achieving 85.", "startOffset": 2, "endOffset": 26}, {"referenceID": 26, "context": "This method was designed for structured prediction, but Srikumar and Manning (2014) also applied it to classification.", "startOffset": 56, "endOffset": 84}, {"referenceID": 22, "context": "There has been work to parallelize Bayesian optimization, making it possible to leverage the power of multicore architectures (Snoek et al., 2012; Desautels et al., 2012; Hutter et al., 2012).", "startOffset": 126, "endOffset": 191}, {"referenceID": 5, "context": "There has been work to parallelize Bayesian optimization, making it possible to leverage the power of multicore architectures (Snoek et al., 2012; Desautels et al., 2012; Hutter et al., 2012).", "startOffset": 126, "endOffset": 191}, {"referenceID": 11, "context": "There has been work to parallelize Bayesian optimization, making it possible to leverage the power of multicore architectures (Snoek et al., 2012; Desautels et al., 2012; Hutter et al., 2012).", "startOffset": 126, "endOffset": 191}, {"referenceID": 1, "context": "See Bardenet et al. (2013), Swersky et al.", "startOffset": 4, "endOffset": 27}, {"referenceID": 1, "context": "See Bardenet et al. (2013), Swersky et al. (2013), and Yogatama and Mann (2014) for how to perform Bayesian optimization in these settings.", "startOffset": 4, "endOffset": 50}, {"referenceID": 1, "context": "See Bardenet et al. (2013), Swersky et al. (2013), and Yogatama and Mann (2014) for how to perform Bayesian optimization in these settings.", "startOffset": 4, "endOffset": 80}, {"referenceID": 34, "context": "Other models, can be considered, of course, as can ensembles (Yogatama and Mann, 2014).", "startOffset": 61, "endOffset": 86}], "year": 2015, "abstractText": "When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts. These choices can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well. We propose an approach to optimizing over this space of choices, formulating the problem as global optimization. We apply a sequential model-based optimization technique and show that our method makes standard linear models competitive with more sophisticated, expensive state-of-theart methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems. Our approach is a first step towards blackbox NLP systems that work with raw text and do not require manual tuning.", "creator": "LaTeX with hyperref package"}}}