{"id": "1503.07508", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2015", "title": "Stable Feature Selection from Brain sMRI", "abstract": "Neuroimage analysis usually involves learning thousands or even millions of variables using only a limited number of samples. In this regard, sparse models, e.g. the lasso, are applied to select the optimal features and achieve high diagnosis accuracy. The lasso, however, usually results in independent unstable features. Stability, a manifest of reproducibility of statistical results subject to reasonable perturbations to data and the model, is an important focus in statistics, especially in the analysis of high dimensional data. In this paper, we explore a nonnegative generalized fused lasso model for stable feature selection in the diagnosis of Alzheimer's disease. In addition to sparsity, our model incorporates two important pathological priors: the spatial cohesion of lesion voxels and the positive correlation between the features and the disease labels. To optimize the model, we propose an efficient algorithm by proving a novel link between total variation and fast network flow algorithms via conic duality. Experiments show that the proposed nonnegative model performs much better in exploring the intrinsic structure of data via selecting stable features compared with other state-of-the-arts.", "histories": [["v1", "Wed, 25 Mar 2015 19:30:14 GMT  (10769kb,D)", "http://arxiv.org/abs/1503.07508v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["bo xin", "lingjing hu", "yizhou wang 0001", "wen gao 0001"], "accepted": true, "id": "1503.07508"}, "pdf": {"name": "1503.07508.pdf", "metadata": {"source": "CRF", "title": "Stable Feature Selection from Brain sMRI", "authors": ["Bo Xin", "Lingjing Hu", "Yizhou Wang", "Wen Gao"], "emails": [], "sections": [{"heading": "Introduction", "text": "It is a matter of time before such a process will occur. (...) It is a matter of time before such a process will occur. (...) It is a matter of time before such a process will occur. (...) It is a matter of time before such a process will occur. (...) It is a matter of time before such a process will occur. (...) It is a matter of time before such a process will occur. (...) It is a matter of time before such a process will occur. \"(...)"}, {"heading": "The Proposed Method", "text": "We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (... We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...) We are not in a position to analyze the results. (...). (...) We are not in a position to analyze the results. (...). (...) We are not in a position to analyze the results."}, {"heading": "Conic Dual to Total Variation", "text": "(3) We apply generalized inequalities and their corresponding problem (2). (4) We first define a set of characteristics required by correct proof. See the supplementary file for proof. We now consider the following problem (we continue to use a minimum of 2wkiL for correct proof of 2wki L in (3): Minimum requirements met by correct proof. (4) We consider the following problem (we continue to use a minimum of 2wkiL in (3): Minimum requirements met by correct proof. (4) We consider the following problem (we continue to use a minimum of 2wkiL in (4): Minimum requirements met by correct proof. (3) We continue to use a minimum of 2wkiL in (3): Minimum requirements, minimum requirements, minimum requirements, minimum requirements, minimum requirements, minimum requirements, minimum requirements."}, {"heading": "Application to the Diagnosis of AD", "text": "In the diagnosis of Alzheimer's Neuroimaging Initiative (ADNI), we are all incorporated into the baseline data that we provide in the areas of \"health,\" \"health,\" \"health,\" \"health,\" \"health,\" \"health,\" \"health,\" \"health,\" \"health,\" \"health,\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\" \",\" \",\" \",\" \",\" \",\" \",\" \",\" \",\", \"\", \",\" \",\", \"\", \"\", \"\", \"\", \"\", \",\" \"\", \",\" \"\", \"\", \",\" \"\", \"\" \",\", \"\" \"\" \"\", \"\", \"\" \",\" \"\" \",\" \",\" \"\" \"\" \",\", \"\" \",\" \"\" \",\" \",\" \"\", \"\" \"\", \"\" \",\" \"\", \"\" \"\", \"\" \",\" \"\", \"\" \"\", \"\" \",\" \"\" \",\" \"\" \",\" \"\" \"\", \"\" \",\" \"\" \""}, {"heading": "Conclusions", "text": "In this paper, we examine the non-negative generalized Fused Lasso model in order to address an important problem of neuroimage analysis, namely the stability of feature selection. Experiments show that our model significantly improves the stabilities4 We note that in (Xin et al. 2014) stability is calculated on the basis of the 50 most positive voxels, as these voxels are considered to be the most stunted. By calculating the stability of all voxels without zero, the mDC of the GFL decreases by about 30%. This clearly shows that the instability is largely caused by the unwanted voxels, which do not correlate with the previous correlation (the scattered blue voxels in the middle row). The feature selection compared to existing methods of brain image analysis. Although n2GFL is applied to the diagnosis of the AD problem, it can be applied to solve more general problems. Furthermore, we believe that the theoretical points mentioned here, e.g. the non-negative FISTA threshold values, provide motivation for the future NSTA and NSTA threshold values."}], "references": [{"title": "A fast diffeomorphic image registration algorithm", "author": ["Ashburner", "J others 2007] Ashburner"], "venue": null, "citeRegEx": "Ashburner and Ashburner,? \\Q2007\\E", "shortCiteRegEx": "Ashburner and Ashburner", "year": 2007}, {"title": "R", "author": ["B.B. Avants", "D.J. Libon", "K. Rascovsky", "A. Boller", "C.T. McMillan", "L. Massimo", "H. Coslett", "A. Chatterjee", "Gross"], "venue": "G.; and Grossman, M.", "citeRegEx": "Avants et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "and Teboulle", "author": ["A. Beck"], "venue": "M.", "citeRegEx": "Beck and Teboulle 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "and Vandenberghe", "author": ["S.P. Boyd"], "venue": "L.", "citeRegEx": "Boyd and Vandenberghe 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "and Darbon", "author": ["A. Chambolle"], "venue": "J.", "citeRegEx": "Chambolle and Darbon 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Discriminative analysis of early alzheimer\u2019s disease using multi-modal imaging and multilevel characterization with multi-classifier (m3)", "author": ["Dai"], "venue": null, "citeRegEx": "Dai,? \\Q2012\\E", "shortCiteRegEx": "Dai", "year": 2012}, {"title": "L", "author": ["Dice"], "venue": "R.", "citeRegEx": "Dice 1945", "shortCiteRegEx": null, "year": 1945}, {"title": "Pathwise coordinate optimization. The Annals of Applied Statistics 1(2):302\u2013332", "author": ["Friedman"], "venue": null, "citeRegEx": "Friedman,? \\Q2007\\E", "shortCiteRegEx": "Friedman", "year": 2007}, {"title": "A fast parametric maximum flow algorithm and applications", "author": ["Grigoriadis Gallo", "G. Tarja 1989] Gallo", "M. Grigoriadis", "R. Tarja"], "venue": "SIAM Journal of Computing", "citeRegEx": "Gallo et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Gallo et al\\.", "year": 1989}, {"title": "Identifying predictive regions from fmri with tv-l1 prior", "author": ["Thirion Gramfort", "A. Varoquaux 2013] Gramfort", "B. Thirion", "G. Varoquaux"], "venue": "In Pattern Recognition in Neuroimaging (PRNI),", "citeRegEx": "Gramfort et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gramfort et al\\.", "year": 2013}, {"title": "and Boyd", "author": ["M. Grant"], "venue": "S.", "citeRegEx": "Grant and Boyd 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "J", "author": ["L. Grosenick", "B. Klingenberg", "K. Katovich", "B. Knutson", "Taylor"], "venue": "E.", "citeRegEx": "Grosenick et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "and Hong", "author": ["D.S. Hochbaum"], "venue": "S.", "citeRegEx": "Hochbaum and Hong 1995", "shortCiteRegEx": null, "year": 1995}, {"title": "Group lasso with overlap and graph lasso", "author": ["Obozinski Jacob", "L. Vert 2009] Jacob", "G. Obozinski", "J.-P. Vert"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Jacob et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jacob et al\\.", "year": 2009}, {"title": "Multiscale mining of fmri data with hierarchical structured sparsity", "author": ["Jenatton"], "venue": "SIAM Journal on Imaging Sciences", "citeRegEx": "Jenatton,? \\Q2012\\E", "shortCiteRegEx": "Jenatton", "year": 2012}, {"title": "H", "author": ["D.D. Lee", "Seung"], "venue": "S.", "citeRegEx": "Lee and Seung 1999", "shortCiteRegEx": null, "year": 1999}, {"title": "Inter-modality relationship constrained multimodality multi-task feature selection for alzheimer\u2019s disease and mild cognitive impairment identification", "author": ["Liu"], "venue": null, "citeRegEx": "Liu,? \\Q2014\\E", "shortCiteRegEx": "Liu", "year": 2014}, {"title": "Ensemble sparse classification of alzheimer\u2019s disease", "author": ["Zhang Liu", "M. Shen 2012] Liu", "D. Zhang", "D. Shen"], "venue": null, "citeRegEx": "Liu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Convex and network flow optimization for structured sparsity", "author": ["Mairal"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "Mairal,? \\Q2011\\E", "shortCiteRegEx": "Mairal", "year": 2011}, {"title": "and Nesterov", "author": ["Y. Nesterov"], "venue": "I.", "citeRegEx": "Nesterov and Nesterov 2004", "shortCiteRegEx": null, "year": 2004}, {"title": "and Abugharbieh", "author": ["B. Ng"], "venue": "R.", "citeRegEx": "Ng and Abugharbieh 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "T", "author": ["N. Rao", "C. Cox", "R. Nowak", "Rogers"], "venue": "T.", "citeRegEx": "Rao et al. 2013", "shortCiteRegEx": null, "year": 2013}, {"title": "Efficient generalized fused lasso and its application to the diagnosis of alzheimers disease", "author": ["Xin"], "venue": "In Twenty-Eighth AAAI Conference on Artificial Intelligence", "citeRegEx": "Xin,? \\Q2014\\E", "shortCiteRegEx": "Xin", "year": 2014}, {"title": "B", "author": ["Yu"], "venue": "2013. Stability. Bernoulli 19(4):1484\u2013", "citeRegEx": "Yu 2013", "shortCiteRegEx": null, "year": 1500}], "referenceMentions": [], "year": 2015, "abstractText": "Neuroimage analysis usually involves learning thousands or even millions of variables using only a limited number of samples. In this regard, sparse models, e.g. the lasso, are applied to select the optimal features and achieve high diagnosis accuracy. The lasso, however, usually results in independent unstable features. Stability, a manifest of reproducibility of statistical results subject to reasonable perturbations to data and the model (Yu 2013), is an important focus in statistics, especially in the analysis of high dimensional data. In this paper, we explore a nonnegative generalized fused lasso model for stable feature selection in the diagnosis of Alzheimer\u2019s disease. In addition to sparsity, our model incorporates two important pathological priors: the spatial cohesion of lesion voxels and the positive correlation between the features and the disease labels. To optimize the model, we propose an efficient algorithm by proving a novel link between total variation and fast network flow algorithms via conic duality. Experiments show that the proposed nonnegative model performs much better in exploring the intrinsic structure of data via selecting stable features compared with other state-of-the-arts. Introduction Neuroimage analysis is challenging due to its high feature dimensionality and data scarcity. Sparse models such as the lasso (Tibshirani 1996) have gained great reputation in statistics and machine learning, and they have been applied to the analysis of such high dimensional data by exploiting the sparsity property in the absence of abundant data. As a major result, automatic selection of relevant variables/features by such sparse formulation achieves promising performance. For example, in (Liu, Zhang, and Shen 2012), the lasso model was applied to the diagnosis of Alzheimer\u2019s disease (AD) and showed better performance than the support vector machine (SVM), which is one of the state-of-the-arts in brain image classification. However, in statistics, it is known that the lasso does not always provide interpretable results because of its instability (Yu 2013). \u201cStability\u201d here means the reproducibility of statistical results subject to reasonable perturbations to data and Copyright c \u00a9 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. the model. (These perturbations include the often used Jacknife, bootstrap and cross-validation.) This unstable behavior of the lasso model is critical in high dimensional data analysis. The resulting irreproducibility of the feature selection are especially undesirable in neuroimage analysis/diagnosis. However, unlike the problems such as registration and classification, the stability issue of feature selection is much less studied in this field. In this paper we propose a model to induce more stable feature selection from high dimensional brain structural Magnetic Resonance Imaging (sMRI) images. Besides sparsity, the proposed model harnesses two important additional pathological priors in brain sMRI: (i) the spatial cohesion of lesion voxels (via inducing fusion terms) and (ii) the positive correlation between the features and the disease labels. The correlation prior is based on the observation that in many brain image analysis problems (such as AD, frontotemporal dementia, corticobasal degeneration, etc), there exist strong correlations between the features and the labels. For example, gray matter of AD is degenerated/atrophied. Therefore, the gray matter values (indicating the volume) are positively correlated with the cognitive scores or disease labels {-1,1}. That is, the less gray matter, the lower the cognitive score. Accordingly, we propose nonnegative constraints on the variables to enforce the prior and name the model as \u201cnon-negative Generalized Fused Lasso\u201d (nGFL). It extends the popular generalized fused lasso and enables it to explore the intrinsic structure of data via selecting stable features. To measure feature stability, we introduce the \u201cEstimation Stability\u201d recently proposed in (Yu 2013) and the (multi-set) Dice coefficient (Dice 1945). Experiments demonstrate that compared with existing models, our model selects much more stable (and pathological-prior consistent) voxels. It is worth mentioning that the non-negativeness per se is a very important prior of many practical problems, e.g. (Lee and Seung 1999). Although nGFL is proposed to solve the diagnosis of AD in this work, the model can be applied to more general problems. Incorporating these priors makes the problem novel w.r.t the lasso or generalized fused lasso from an optimization standpoint. Although off-the-shelf convex solvers such as CVX (Grant and Boyd 2013) can be applied to solve the optimization, it hardly scales to high-dimensional problems in feasible time. In this regard, we propose an efficient algoar X iv :1 50 3. 07 50 8v 1 [ cs .L G ] 2 5 M ar 2 01 5 rithm that solves the nGFL problem exactly. We generalize the proximal gradient methods (such as FISTA) (Beck and Teboulle 2009) to solve our constrained optimization and prove its convergence. We then show that by using an element-wise post-processing, the resulting proximal operator can be reduced to the total variation (TV) problem. It is known that TV can be solved by parametric flow algorithms (Chambolle and Darbon 2009; Xin et al. 2014). In the present study, we provide a novel equivalence via conic duality, which gives us a minimum quadratic cost flow formulation (Hochbaum and Hong 1995). Fast flow algorithms (including parametric flow) are then easily applied. In practice, our algorithm runs hundreds of times faster than CVX at the same precision and can scale to high-dimensional problems. Related work. In addition to sparsity, people leverage underlying data structures and introduce stronger priors such as the structured sparsity (Jacob, Obozinski, and Vert 2009) to increase model stability. However, for voxel-based sMRI data analysis, handcrafted grouping of the voxels or sub-structures may not coincide with various pathological topology priors. Consequently, group lasso (with overlap) (Jacob, Obozinski, and Vert 2009; Jenatton et al. 2012; Rao et al. 2013) is not an ideal model to the problem. In contrast, the graph-based structured sparse models adapt better to such a situation. The most popular one is referred here as LapL1, which adopts l2 norm regularization of neighborhood variable difference (e.g. (Ng and Abugharbieh 2011; Grosenick et al. 2013)). However, as we will show in the experiments, these models select many more features than necessary. Very recently, generalized fused lasso or total variation has been successful applied to brain image analysis problems inducing the l1 difference (Gramfort, Thirion, and Varoquaux 2013; Xin et al. 2014). In the experiments, we show that by including an extra nonnegative constraint, the features selected by our model is much more stable than that of such unconstrained models. A very recent work (Avants et al. 2014) also explored this positive correlation (partially supporting our assumption), but the problem formulation was quite different: neither structural assumption was considered, nor the stability of feature selection was discussed. From the optimization standpoint, the applied framework is similar to that of (Xin et al. 2014) but two key differences exist: (1) the FISTA and soft-thresholding process applied in (Xin et al. 2014) do not generalize to constrained optimization problems, we show important modifications and provide theoretical proof; (2) we propose a novel understanding of TV\u2019s relation with flow problems via conic duality and prove that the minimum norm point problem of (Xin et al. 2014) is a special case of our framework. The Proposed Method Nonnegative Generalized Fused Lasso (n2GFL) Let {(xi, yi)}i=1 be a set of samples, where xi \u2208 R and yi \u2208 R are features and labels, respectively. Also, we denote Although different names are given in e.g. (Ng and Abugharbieh 2011; Grosenick et al. 2013), they are in fact fundamentally applying the graph Laplacian smoothing. by X \u2208 Rd\u00d7N and y \u2208 R the concatenations of xi and yi. Then, we consider the formulation min \u03b2\u2208Rd l(\u03b2;X,y) + \u03bb1 d \u2211", "creator": "LaTeX with hyperref package"}}}