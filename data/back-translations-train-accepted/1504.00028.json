{"id": "1504.00028", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2015", "title": "Real-World Font Recognition Using Deep Network and Domain Adaptation", "abstract": "We address a challenging fine-grain classification problem: recognizing a font style from an image of text. In this task, it is very easy to generate lots of rendered font examples but very hard to obtain real-world labeled images. This real-to-synthetic domain gap caused poor generalization to new real data in previous methods (Chen et al. (2014)). In this paper, we refer to Convolutional Neural Networks, and use an adaptation technique based on a Stacked Convolutional Auto-Encoder that exploits unlabeled real-world images combined with synthetic data. The proposed method achieves an accuracy of higher than 80% (top-5) on a real-world dataset.", "histories": [["v1", "Tue, 31 Mar 2015 20:30:00 GMT  (81kb,D)", "http://arxiv.org/abs/1504.00028v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["zhangyang wang", "jianchao yang", "hailin jin", "eli shechtman", "aseem agarwala", "jonathan brandt", "thomas s huang"], "accepted": true, "id": "1504.00028"}, "pdf": {"name": "1504.00028.pdf", "metadata": {"source": "CRF", "title": "REAL-WORLD FONT RECOGNITION USING DEEP NET-", "authors": ["Zhangyang Wang", "Thomas S. Huang"], "emails": ["t-huang1}@illinois.edu", "jbrandt}@adobe.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "In order to solve this problem with machine learning, we need realistic text images with body text labels. However, such data is scarce and expensive to obtain as it requires a high level of expertise that is unattainable for most people. Therefore, it is not possible to collect a sufficient number of training images from the real world. One way to meet the challenge of training data is to synthesize the training set by displaying text fragments for all necessary fonts. However, we must face the domain discrepancy between synthetic and real text images (Chen et al. (2014)). Characters in real world images are staggered, stretched and distorted in many ways. In (Chen et al. (2014), the authors have tried to overcome this difficulty by adding different degradations to synthetic data. In the end, introducing all possible degradations from the real world into unfeasible school data is enough."}, {"heading": "2 MODEL", "text": "Our basic CNN architecture is similar to the popular ImageNet CNN structure in (Krizhevsky et al. (2012), as shown in Fig. 1. The numbers together with the network pipeline determine the dimensions of the outputs of corresponding layers. If the CNN model is trained entirely on a synthetic data set, it shows a significant drop in performance when testing real data compared to other synthetic validation sets. This also happens with other models such as Chen et al. (2014), which use training and testing sets similar to ours, indicating discrepancies between distributions of synthetic and real validation. Xiv: 150 4.00 028v 1 [cs.C V] 31 MTradition includes pre-processing steps applied at the level of training and / or testing data (Chen)."}, {"heading": "3 EXPERIMENTS", "text": "We implemented and evaluated the local feature embedding-based algorithm (LFE) in (Chen et al. (2014) as a baseline and compared it with our model. A SCAE is first trained on a large collection of synthetic data and blank data from the real world, and then exports the first K = 2 convolutionary layers. The next N \u2212 K layers are trained on labeled synthetic data covering 2,383 classes, making our problem fairly fine-grained. We tested the VFRWild325 dataset used by (Chen et al. (2014) for top-1 and top-5 classification errors. Our model achieved 38.15% in top-1 errors and 20.62% in top-5, which exceeds 6% and 10% over LFE, respectively."}], "references": [{"title": "Large-scale visual font recognition", "author": ["G. Chen", "J. Yang", "H. Jin", "J. Brandt", "E. Shechtman", "A. Agarwala", "T.X. Han"], "venue": "In Proceedings of CVPR,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "In Proceedings of ICML, pp", "citeRegEx": "Glorot et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Proceedings of NIPS, pp", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Stacked convolutional auto-encoders for hierarchical feature extraction", "author": ["J. Masci", "U. Meier", "D. Cire\u015fan", "J. Schmidhuber"], "venue": "In Proceedings of ICANN,", "citeRegEx": "Masci et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Masci et al\\.", "year": 2011}, {"title": "An analysis of unsupervised pre-training in light of recent advances", "author": ["T. Paine", "P. Khorrami", "W. Han", "T.S. Huang"], "venue": "arXiv preprint arXiv:1412.6597,", "citeRegEx": "Paine et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Paine et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "This realto-synthetic domain gap caused poor generalization to new real data in previous methods (Chen et al. (2014)).", "startOffset": 98, "endOffset": 117}, {"referenceID": 0, "context": "However, we must face the domain mismatch between synthetic and real-world text images (Chen et al. (2014)).", "startOffset": 88, "endOffset": 107}, {"referenceID": 0, "context": "However, we must face the domain mismatch between synthetic and real-world text images (Chen et al. (2014)). Characters in real-world images are spaced, stretched and distorted in numerous ways. In (Chen et al. (2014)), the authors tried to overcome this difficulty by adding different degradations to synthetic data.", "startOffset": 88, "endOffset": 218}, {"referenceID": 1, "context": "Our basic CNN architecture is similar to the popular ImageNet CNN structure in (Krizhevsky et al. (2012)), as depicted in Fig.", "startOffset": 80, "endOffset": 105}, {"referenceID": 0, "context": "This also happens with other models such as in Chen et al. (2014), which uses training and testing sets of similar properties to ours.", "startOffset": 47, "endOffset": 66}, {"referenceID": 0, "context": "Tradition approaches to handle this gap include pre-processing steps applied on the training and/or testing data (Chen et al. (2014)).", "startOffset": 114, "endOffset": 133}, {"referenceID": 0, "context": "Tradition approaches to handle this gap include pre-processing steps applied on the training and/or testing data (Chen et al. (2014)). The domain adaptation method in Glorot et al. (2011) extracts lowlevel features that represent both the synthetic and real-world data, based on a stacked auto-encoder (SAE).", "startOffset": 114, "endOffset": 188}, {"referenceID": 0, "context": "Tradition approaches to handle this gap include pre-processing steps applied on the training and/or testing data (Chen et al. (2014)). The domain adaptation method in Glorot et al. (2011) extracts lowlevel features that represent both the synthetic and real-world data, based on a stacked auto-encoder (SAE). We extend the method in Glorot et al. (2011) to decompose the N basic CNN layers into two sub-network parts.", "startOffset": 114, "endOffset": 354}, {"referenceID": 0, "context": "Tradition approaches to handle this gap include pre-processing steps applied on the training and/or testing data (Chen et al. (2014)). The domain adaptation method in Glorot et al. (2011) extracts lowlevel features that represent both the synthetic and real-world data, based on a stacked auto-encoder (SAE). We extend the method in Glorot et al. (2011) to decompose the N basic CNN layers into two sub-network parts. The first K layers accounts for extracting low-level visual features shared by both synthetic and real-world data, and will be learned in a unsupervised way, using unlabeled data from both domains. The remaining N \u2212K layers accounts for learning higher-level discriminative features for classification. It will be trained in a supervised way on top of the first part, using labeled data from the synthetic domain only. To train the first K layers, we exploit a Stacked Convolutional Auto-Encoder (SCAE) (Masci et al. (2011)).", "startOffset": 114, "endOffset": 942}, {"referenceID": 0, "context": "Tradition approaches to handle this gap include pre-processing steps applied on the training and/or testing data (Chen et al. (2014)). The domain adaptation method in Glorot et al. (2011) extracts lowlevel features that represent both the synthetic and real-world data, based on a stacked auto-encoder (SAE). We extend the method in Glorot et al. (2011) to decompose the N basic CNN layers into two sub-network parts. The first K layers accounts for extracting low-level visual features shared by both synthetic and real-world data, and will be learned in a unsupervised way, using unlabeled data from both domains. The remaining N \u2212K layers accounts for learning higher-level discriminative features for classification. It will be trained in a supervised way on top of the first part, using labeled data from the synthetic domain only. To train the first K layers, we exploit a Stacked Convolutional Auto-Encoder (SCAE) (Masci et al. (2011)). Its first two convolutional layers have an identical topology to the first two layers in Fig. 1. Moreover, we set its first and second half to be mirror-symmetrical. The cost function is the mean squared error (MSE) between the input and reconstructed patches. After SCAE is learned, its Conv. Layers 1 and 2 are imported to the CNN in Fig. 1. We adopt the SCAE implementation by Paine et al. (2014). We also find that applying label-preserving data augmentations to synthetic training data helps reduce the domain mismatch.", "startOffset": 114, "endOffset": 1344}, {"referenceID": 0, "context": "Tradition approaches to handle this gap include pre-processing steps applied on the training and/or testing data (Chen et al. (2014)). The domain adaptation method in Glorot et al. (2011) extracts lowlevel features that represent both the synthetic and real-world data, based on a stacked auto-encoder (SAE). We extend the method in Glorot et al. (2011) to decompose the N basic CNN layers into two sub-network parts. The first K layers accounts for extracting low-level visual features shared by both synthetic and real-world data, and will be learned in a unsupervised way, using unlabeled data from both domains. The remaining N \u2212K layers accounts for learning higher-level discriminative features for classification. It will be trained in a supervised way on top of the first part, using labeled data from the synthetic domain only. To train the first K layers, we exploit a Stacked Convolutional Auto-Encoder (SCAE) (Masci et al. (2011)). Its first two convolutional layers have an identical topology to the first two layers in Fig. 1. Moreover, we set its first and second half to be mirror-symmetrical. The cost function is the mean squared error (MSE) between the input and reconstructed patches. After SCAE is learned, its Conv. Layers 1 and 2 are imported to the CNN in Fig. 1. We adopt the SCAE implementation by Paine et al. (2014). We also find that applying label-preserving data augmentations to synthetic training data helps reduce the domain mismatch. Chen et al. (2014) added moderate distortions and corruptions, including noise, blur, rotations and shading effects.", "startOffset": 114, "endOffset": 1488}, {"referenceID": 0, "context": "Tradition approaches to handle this gap include pre-processing steps applied on the training and/or testing data (Chen et al. (2014)). The domain adaptation method in Glorot et al. (2011) extracts lowlevel features that represent both the synthetic and real-world data, based on a stacked auto-encoder (SAE). We extend the method in Glorot et al. (2011) to decompose the N basic CNN layers into two sub-network parts. The first K layers accounts for extracting low-level visual features shared by both synthetic and real-world data, and will be learned in a unsupervised way, using unlabeled data from both domains. The remaining N \u2212K layers accounts for learning higher-level discriminative features for classification. It will be trained in a supervised way on top of the first part, using labeled data from the synthetic domain only. To train the first K layers, we exploit a Stacked Convolutional Auto-Encoder (SCAE) (Masci et al. (2011)). Its first two convolutional layers have an identical topology to the first two layers in Fig. 1. Moreover, we set its first and second half to be mirror-symmetrical. The cost function is the mean squared error (MSE) between the input and reconstructed patches. After SCAE is learned, its Conv. Layers 1 and 2 are imported to the CNN in Fig. 1. We adopt the SCAE implementation by Paine et al. (2014). We also find that applying label-preserving data augmentations to synthetic training data helps reduce the domain mismatch. Chen et al. (2014) added moderate distortions and corruptions, including noise, blur, rotations and shading effects. In addition, we also vary the character spacings and aspect ratios when rendering training data. Note that these steps are not useful for the method in Chen et al. (2014) because it exploits very localized features, but they are very helpful in our case.", "startOffset": 114, "endOffset": 1757}], "year": 2015, "abstractText": "We address a challenging fine-grain classification problem: recognizing a font style from an image of text. In this task, it is very easy to generate lots of rendered font examples but very hard to obtain real-world labeled images. This realto-synthetic domain gap caused poor generalization to new real data in previous methods (Chen et al. (2014)). In this paper, we refer to Convolutional Neural Networks, and use an adaptation technique based on a Stacked Convolutional AutoEncoder that exploits unlabeled real-world images combined with synthetic data. The proposed method achieves an accuracy of higher than 80% (top-5) on a realworld dataset.", "creator": "LaTeX with hyperref package"}}}