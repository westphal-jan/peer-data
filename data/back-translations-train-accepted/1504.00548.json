{"id": "1504.00548", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Apr-2015", "title": "Learning to Understand Phrases by Embedding the Dictionary", "abstract": "Distributional models that learn rich semantic word representations are a success story of recent NLP research. However, developing models that learn useful representations of phrases and sentences has proved far harder. We propose using the definitions found in everyday dictionaries as a means of bridging this gap between lexical and phrasal semantics. We train a recurrent neural network (RNN) to map dictionary definitions (phrases) to (lexical) representations of the words those definitions define. We present two applications of this architecture: a reverse dictionary, for returning the name of a concept given a definition or description, and a general-knowledge (crossword) question answerer. On both tasks, the RNN trained on definitions from a handful of freely-available lexical resources performs comparably or better than existing commercial systems that rely on major task-specific engineering and far greater memory footprints. This strong performance highlights the general effectiveness of both neural language models and definition-based training for training machines to understand phrases and sentences.", "histories": [["v1", "Thu, 2 Apr 2015 13:30:27 GMT  (29kb)", "http://arxiv.org/abs/1504.00548v1", null], ["v2", "Fri, 17 Apr 2015 19:34:07 GMT  (30kb)", "http://arxiv.org/abs/1504.00548v2", null], ["v3", "Sun, 30 Aug 2015 21:34:26 GMT  (32kb)", "http://arxiv.org/abs/1504.00548v3", null], ["v4", "Tue, 22 Mar 2016 16:30:17 GMT  (32kb)", "http://arxiv.org/abs/1504.00548v4", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["felix hill", "kyunghyun cho", "anna korhonen", "yoshua bengio"], "accepted": true, "id": "1504.00548"}, "pdf": {"name": "1504.00548.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Kyunghyun Cho", "Yoshua Bengio"], "emails": ["felix.hill@cl.cam.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 150 4.00 548v 1 [cs.C L] 2A pr2 015"}, {"heading": "1 Introduction", "text": "This task is so difficult in part because there is no obvious gold standard of phrasal representation that can be used in education, evaluation, and in comparison to other systems. The composite meaning of words in a dictionary definition (a large, long-lived, ruminant group of Africans) should correspond to the meaning of the word they define (giraffe). This bridge between lexical and phrasal semantics is useful because high-quality vector representations of individual words can be used as a target when they are able to capture the words in a contiguous world."}, {"heading": "2 Model Architecture", "text": "The architecture that underlines our model is a recursive neural network (RNN). RNNs operate with variable length of input sequences; in our case, with definitions, descriptions or sentences of natural language. RNNs (with LSTMs) have achieved state-of-the-art performance in language modeling (Mikolov et al., 2010), approaching state-of-the-art performance in machine translation (Bahdanau et al., 2015). During the training, the input into the RNN is a word definition (for the reverse dictionary model) or a sentence from an encyclopedia (in the question-answer model).The aim of the model is to map these definitions onto an embedding of the word that defines the definition.The target word embeddings are learned independently of the RNN weighting by projecting the vowels (Word2Vec software)."}, {"heading": "2.1 Long Short Term Memory", "text": "A known obstacle in the formation of RNNs to read language with gradients is that the error signal (gradient) on the training examples either disappears or explodes as the number of time steps (sentence length) increases. Consequently, after reading longer sentences the final internal activation ON usually retains useful information about the last read (sentence end) words, but can neglect important information near the beginning of the input sentence. LSTMs are designed to mitigate this long-term dependence. At any time step t, instead of the single internal layer of units A, the LSTM RNN calculates six internal layers gw, gi, gf, go, go, h and m. The first, gw, represents the core information passed to the LSTM unit to the latest input word. It is calculated as a simple linear projection of the input values WW-W."}, {"heading": "2.2 Implementation Details", "text": "The RNN word embedding in our implementation had a length of 256 and each of the four internal LSTM RNN layers (gating and activation states) had 512 units each. To create the space for target embedding, we trained a continuous sack-of-words model (CBOW) using the Word2Vec software to run about 8 billion words of text.1 The embedding in the target space had the dimension of 500. The model was implemented with Theano (Bergstra et al., 2010) and trained on GPUs with Minibatch-SGD. Batch size was set at 16 and the learning rate was controlled by adadelta (Zeiler, 2012). Training for each model took about 24 hours. We make the entire model code publicly available."}, {"heading": "3 Reverse Dictionaries", "text": "The most immediate application of our trained models is as a reverse dictionary or concept finder. It is easy to look up a definition in a dictionary. 1The Word2Vec embedding models are well known; for more details, see https: / / code.google.com / p / word2vec / The training data for our model has been compiled from various online text sources that return the script demo-train-big-modelv1.sh from the same page.given word, but professional authors often also need suitable words for a particular idea, concept or definition.2 Reverse dictionaries meet this need by returning candidates words with a phrase, description or definition. For example, if the phrase queries an activity that requires strength and determination, the OneLook.com reverse dictionary delivers the concepts exercise and work. Our trained RNN model can perform a similar function by simply inserting the dictionary Reverse into the phrase (a point in the dictionary)."}, {"heading": "3.1 Training", "text": "For each of these words, we extracted dictionary-like definitions from five electronic resources: WordNik, The American Her-2See the testimony from professional writers at http: / / www.onelook.com /? c = awards3Available at http: / / dictionary.reference.com / reverse / itage Dictionary, The Collaborative International Dictionary of English, Wiktionary and Webster's. We chose these five dictionaries because they are freely available through the WordNik API, 4 but theoretically any dictionary could be chosen. Most of the words in our training data had multiple definitions. For each word w with definitions {d1... dn} we included all pairs (w, d1) because they are freely available through the WordNik API, but theoretically any dictionary could be chosen."}, {"heading": "3.2 Comparison and Evaluation", "text": "As a starting point for the RNN approach, we have implemented two unattended methods that use the neural (Word2Vec) word embeddings from the target word space. In the first (add W2V), we compose the embeddings for each word in the input query by senseless addition, and return as candidates the nearest word embeddings to the resulting composite vector. The second baseline, (W2V mult), is identical except that the embeddings are composed by elementary multiplication. Both methods of composition were proposed in a recent study on the structure of phrase representations from word embeddings (Milajevs et al.).None of the models or ratings from previous academic research is publicly available, so direct comparison is not possible."}, {"heading": "3.3 Results", "text": "In fact, most of them will be able to go in search of a solution that originates in the real world."}, {"heading": "3.4 Qualitative Analysis", "text": "Example queries and top five candidates from the models are presented in Table 6. They illustrate characteristics of RNN output that should also be obvious when querying the web demo. The first example shows how the model generalizes beyond its training data. Four of the top five answers could be considered appropriate as they relate to residents of cold countries. However, cold or anything with climate is included in the dictionary definitions of Es-6Our trained model files are about half the size of the six training dictionaries stored as plain text and would therefore be a hundred times smaller than the OneLook database of 1061 dictionaries. Kimo, Scandinavia, Scandinavia, Scandinavia, etc. in the training data. The model has learned that cold is a characteristic of Scandinavia, Siberia and refers to Eskimos through connections with other concepts that are described or defined as cold."}, {"heading": "3.5 Cross-Lingual Reverse Dictionaries", "text": "We show how the RNN architecture can be easily modified to create a bilingual reverse dictionary - a system that gives candidate words in one language that contains a description or definition in another. A bilingual reverse dictionary could have clear applications for translators or transcriptionists. Indeed, the problem of bilingual embedding words in a second language may be more common than in a monolingual context."}, {"heading": "3.6 Discussion", "text": "We have shown that the simple training of the RNN-to-word embedding architecture on six dictionaries results in a reverse dictionary that is comparable to the leading commercial system and offers certain key benefits. Firstly, there is a syntactically and semantically plausible Re-7The approach should work with all bilingual embedding. We thank Stephan Gouws for the training, sponsors as part of a more coherent and homogeneous group of candidates. Secondly, it requires a lot less disk space, which is a significant advantage since language applications and tools generally benefit from portability (e.g. usable on mobile devices). In the next section, we will also show how the architecture can be easily expanded to produce bilingual versions of the same model. Of course, in the analyses carried out so far, we are testing the RNN approach only on tasks for which it has been trained to effectively transfer a task (mapping definitions or descriptions on words)."}, {"heading": "4 General Knowledge (crossword) Question Answering", "text": "Automatically answering questions posed in natural language is a central problem of Artificial Intelligence. Although web search and IR techniques provide a means of finding websites or documents related to language queries, Internet users currently still need to sift through pages to locate the information they want. Systems that attempt to overcome this, via completely open domains or general knowledge that answers questions (open questions), usually require large research teams, modular design, and powerful infrastructure, exemplified by IBM's Watson (Ferrucci et al., 2010). For this reason, much academic research focuses on settings that reduce the scope of the task. This has been achieved by restricting questions to a specific topic or domain (Molla \u0301 and Vicedo, 2007), which allows access to systems with pre-defined text passages from which the answer to the question can be asked (Iyyer et al., 2014 on; Weston, et al.) or centering certain questions or both."}, {"heading": "4.1 Evaluation", "text": "Eddie James is one of the UK's leading crossword compilers and works for several national newspapers. Our long questionnaire consists of the first 150 questions (starting with Riddle # 1) from his Common Knowledge Crossword Puzzles, excluding references to less than four words and those whose answer was not a single word (e.g. Royal Word). To evaluate models using a different type of clue, we have also compiled a series of shorter questions based on the Guardian's Quick Crossword. Guardian Questions still require general factual or linguistic knowledge, but are generally shorter and slightly more cryptic than the longer Eddie James clues. We have again compiled a list of 150 questions, starting January 1, 2015, and exclude questions with multi-word answers. To provide a clear contrast, we have excluded these few questions that are longer than four words."}, {"heading": "4.2 Benchmarks and Comparisons", "text": "We evaluate RNN models that are integrated with and without Wikipedia into the training data. As before, candidates are extracted from the model by entering definitions and returning words that correspond to the narrowest embedding in the target space, but in this case we only consider candidate words whose length matches the length given in the hint. We also compare with the baseline of elementary addition of Word2Vec vectors in the embedding space (we discard the ineffective W2V Mult baseline) and again limit candidates to words of the given length. We also compare with two customized online crossword solver motors. The first, OneAcross (http: / / www.oneacross.com /) is the candidate generation module of the award-winning Proverb crossword system (Littman et al, 2002). Proverb, produced by academic researchers, is featured in national media such as New Scientist and commercial cross-word soldering systems."}, {"heading": "4.3 Results", "text": "The performance of the models on the various questions is shown in Table 6. On the long questions, the RNN models provide the correct answer to more than half of the questions, and in the top 100 candidates almost 80% of the time, which clearly exceeds the baseline and the commercial systems. Their answers are also more consistent (in terms of ranking variance) than the W2V baseline. In evaluating the two commercial systems, One Across and Crossword Maestro, we have access to web interfaces that return up to about 100 candidates for each query, so that membership in the top ten can only be reliably recorded (Accuracy @ 10). On this metric, Crossword Maestro is beaten on the long questions, but the RNN model outperforms both commercial systems. Interestingly, as the questions get shorter, the advantage of the RNN model is reduced."}, {"heading": "4.4 Qualitative Analysis", "text": "The first three examples show that the RNN model, despite the seemingly superficial nature of its training data (definitions and introductory sentences), can answer questions that require factual knowledge of people and places. Another notable feature of the RNN model is the consistent semantic appropriateness of the candidate; in the first case, the top five candidates are all mountains, valleys or places in the Alps; in the second, they are all biblical names; and in the third, four of the five currencies. None of the alternative approaches exhibits this \"smoothness\" or consistency in candidate generation. Despite its simplicity, the W2V add process is sometimes surprisingly effective, as shown by the fact that it returns Joshua to his top candidates for the third query; and the last example in Table 7 highlights a limitation of the RNN approach in its current form. In this particular case, although there is an embedding in the target area, the Nenberger systems are generally not open to the secondary question."}, {"heading": "5 Conclusion", "text": "Dictionaries exist in many languages of the world. We have shown how these lexical resources can be a valuable resource for training the latest neural language models to interpret and render the meaning of phrases and sentences. While people use the phraselike definitions in dictionaries to better understand the meaning of words, machines can use the words to better understand the phrases. We have presented a recurring neural network architecture with a long-term short-term memory to explicitly exploit this idea. On the other hand, the RNN requires comparable to the most well-known commercial applications, although it has access to many fewer definitions. Furthermore, it produces smoother sentences of candidates, uses less memory time and, most importantly, does not require linguistic pre-processing or task-specific technology."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "International Conference on Learning Representations (ICLR).", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Semantic parsing via paraphrasing", "author": ["J. Berant", "P. Liang."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Berant and Liang.,? 2014", "shortCiteRegEx": "Berant and Liang.", "year": 2014}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["James Bergstra", "Olivier Breuleux", "Fr\u00e9d\u00e9ric Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David Warde-Farley", "Yoshua Bengio."], "venue": "Proceedings", "citeRegEx": "Bergstra et al\\.,? 2010", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "Improving dictionary accessibility by maximizing use of available knowledge", "author": ["Slaven Bilac", "Timothy Baldwin", "Hozumi Tanaka."], "venue": "Traitement automatique des langues, 44(2):199\u2013224.", "citeRegEx": "Bilac et al\\.,? 2003", "shortCiteRegEx": "Bilac et al\\.", "year": 2003}, {"title": "Dictionary search based on the target word description", "author": ["Slaven Bilac", "Wataru Watanabe", "Taiichi Hashimoto", "Takenobu Tokunaga", "Hozumi Tanaka."], "venue": "Proc. of the Tenth Annual Meeting of The Association for NLP (NLP2004), pages 556\u2013559.", "citeRegEx": "Bilac et al\\.,? 2004", "shortCiteRegEx": "Bilac et al\\.", "year": 2004}, {"title": "Question answering with subgraph embeddings", "author": ["Antoine Bordes", "Sumit Chopra", "Jason Weston."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Bordes et al\\.,? 2014", "shortCiteRegEx": "Bordes et al\\.", "year": 2014}, {"title": "Building watson: An overview of the deepqa project", "author": ["David Ferrucci", "Eric Brown", "Jennifer Chu-Carroll", "James Fan", "David Gondek", "Aditya A Kalyanpur", "Adam Lally", "J William Murdock", "Eric Nyberg", "John Prager"], "venue": "AI magazine,", "citeRegEx": "Ferrucci et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ferrucci et al\\.", "year": 2010}, {"title": "Dr", "author": ["Matthew L Ginsberg."], "venue": "fill: crosswords and an implemented solver for singly weighted csps. Journal of Artificial Intelligence Research, pages 851\u2013 886.", "citeRegEx": "Ginsberg.,? 2011", "shortCiteRegEx": "Ginsberg.", "year": 2011}, {"title": "Bilbowa: Fast bilingual distributed representations without word alignments", "author": ["Stephan Gouws", "Yoshua Bengio", "Greg Corrado."], "venue": "Proceedings of NIPS Deep Learning Workshop.", "citeRegEx": "Gouws et al\\.,? 2014", "shortCiteRegEx": "Gouws et al\\.", "year": 2014}, {"title": "Neural turing machines", "author": ["Alex Graves", "Greg Wayne", "Ivo Danihelka."], "venue": "arXiv preprint arXiv:1410.5401.", "citeRegEx": "Graves et al\\.,? 2014", "shortCiteRegEx": "Graves et al\\.", "year": 2014}, {"title": "Multilingual distributed representations without word alignment", "author": ["Karl Moritz Hermann", "Phil Blunsom."], "venue": "arXiv preprint arXiv:1312.6173.", "citeRegEx": "Hermann and Blunsom.,? 2013", "shortCiteRegEx": "Hermann and Blunsom.", "year": 2013}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation, 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "A neural network for factoid question answering over paragraphs", "author": ["Mohit Iyyer", "Jordan Boyd-Graber", "Leonardo Claudino", "Richard Socher", "Hal Daum\u00e9 III."], "venue": "Empirical Methods in Natural Language Processing.", "citeRegEx": "Iyyer et al\\.,? 2014", "shortCiteRegEx": "Iyyer et al\\.", "year": 2014}, {"title": "Unifying visual-semantic embeddings with multimodal neural language models", "author": ["Ryan Kiros", "Ruslan Salakhutdinov", "Richard S Zemel."], "venue": "arXiv preprint arXiv:1411.2539.", "citeRegEx": "Kiros et al\\.,? 2014", "shortCiteRegEx": "Kiros et al\\.", "year": 2014}, {"title": "An autoencoder approach to learning bilingual word representations", "author": ["Stanislas Lauly", "Hugo Larochelle", "Mitesh Khapra", "Balaraman Ravindran", "Vikas C Raykar", "Amrita Saha."], "venue": "Advances in Neural Information Processing Systems, pages 1853\u2013", "citeRegEx": "Lauly et al\\.,? 2014", "shortCiteRegEx": "Lauly et al\\.", "year": 2014}, {"title": "Claws4: the tagging of the british national corpus", "author": ["Geoffrey Leech", "Roger Garside", "Michael Bryant."], "venue": "Proceedings of the 15th conference on Computational linguistics-Volume 1, pages 622\u2013 628. Association for Computational Linguistics.", "citeRegEx": "Leech et al\\.,? 1994", "shortCiteRegEx": "Leech et al\\.", "year": 1994}, {"title": "A probabilistic approach to solving crossword puzzles", "author": ["Michael L Littman", "Greg A Keim", "Noam Shazeer."], "venue": "Artificial Intelligence, 134(1):23\u201355.", "citeRegEx": "Littman et al\\.,? 2002", "shortCiteRegEx": "Littman et al\\.", "year": 2002}, {"title": "Recurrent neural network based language model", "author": ["Tomas Mikolov", "Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur."], "venue": "INTERSPEECH 2010, 11th Annual Conference of the International Speech Communication Association,", "citeRegEx": "Mikolov et al\\.,? 2010", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in Neural Information Processing Systems, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Evaluating neural word representations in tensor-based compositional settings", "author": ["Dmitrijs Milajevs", "Dimitri Kartsaklis", "Mehrnoosh Sadrzadeh", "Matthew Purver"], "venue": "Proceedings of EMNLP,", "citeRegEx": "Milajevs et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Milajevs et al\\.", "year": 2014}, {"title": "Question answering in restricted domains: An overview", "author": ["Diego Moll\u00e1", "Jos\u00e9 Luis Vicedo."], "venue": "Computational Linguistics, 33(1):41\u201361.", "citeRegEx": "Moll\u00e1 and Vicedo.,? 2007", "shortCiteRegEx": "Moll\u00e1 and Vicedo.", "year": 2007}, {"title": "A local learning algorithm for dynamic feedforward and recurrent networks", "author": ["Jurgen Schmidhuber."], "venue": "Connection Science, 1(4):403\u2013412.", "citeRegEx": "Schmidhuber.,? 1989", "shortCiteRegEx": "Schmidhuber.", "year": 1989}, {"title": "Building a scalable databasedriven reverse dictionary", "author": ["Ryan Shaw", "Anindya Datta", "Debra VanderMeer", "Kaushik Dutta."], "venue": "Knowledge and Data Engineering, IEEE Transactions on, 25(3):528\u2013540.", "citeRegEx": "Shaw et al\\.,? 2013", "shortCiteRegEx": "Shaw et al\\.", "year": 2013}, {"title": "Towards ai-complete question answering: A set of prerequisite toy tasks", "author": ["Jason Weston", "Antoine Bordes", "Sumit Chopra", "Tomas Mikolov."], "venue": "arXiv preprint arXiv:1502.05698.", "citeRegEx": "Weston et al\\.,? 2015", "shortCiteRegEx": "Weston et al\\.", "year": 2015}, {"title": "Adadelta: an adaptive learning rate method", "author": ["Matthew D Zeiler."], "venue": "arXiv preprint arXiv:1212.5701.", "citeRegEx": "Zeiler.,? 2012", "shortCiteRegEx": "Zeiler.", "year": 2012}, {"title": "Word lookup on the basis of associations: from an idea to a roadmap", "author": ["Michael Zock", "Slaven Bilac."], "venue": "Proceedings of the Workshop on Enhancing and Using Electronic Dictionaries, pages 29\u201335. Association for Computational Linguistics.", "citeRegEx": "Zock and Bilac.,? 2004", "shortCiteRegEx": "Zock and Bilac.", "year": 2004}], "referenceMentions": [{"referenceID": 21, "context": "For this purpose we use a recurrent neural network (RNN) (Schmidhuber, 1989) with long-short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997).", "startOffset": 57, "endOffset": 76}, {"referenceID": 11, "context": "For this purpose we use a recurrent neural network (RNN) (Schmidhuber, 1989) with long-short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997).", "startOffset": 112, "endOffset": 146}, {"referenceID": 18, "context": "Prior to training the RNN, we learn its target lexical representations by training the Word2Vec software (Mikolov et al., 2013) on billions of words of raw text.", "startOffset": 105, "endOffset": 127}, {"referenceID": 25, "context": "tionary or concept finder: a system that returns words based on user descriptions or definitions (Zock and Bilac, 2004).", "startOffset": 97, "endOffset": 119}, {"referenceID": 8, "context": "Moreover, thanks to recent work on multilingual embedding spaces (Gouws et al., 2014), we show that", "startOffset": 65, "endOffset": 85}, {"referenceID": 17, "context": "RNNs (with LSTMs) have achieved state-of-the-art performance in language modelling (Mikolov et al., 2010) image caption generation (Kiros et al.", "startOffset": 83, "endOffset": 105}, {"referenceID": 13, "context": ", 2010) image caption generation (Kiros et al., 2014), approach state-of-the-art performance in machine translation (Bahdanau et al.", "startOffset": 33, "endOffset": 53}, {"referenceID": 0, "context": ", 2014), approach state-of-the-art performance in machine translation (Bahdanau et al., 2015).", "startOffset": 70, "endOffset": 93}, {"referenceID": 18, "context": "The target word embeddings are learned independently of the RNN weights, using the Word2Vec software (Mikolov et al., 2013).", "startOffset": 101, "endOffset": 123}, {"referenceID": 2, "context": "The model was implemented with Theano (Bergstra et al., 2010) and trained with minibatch SGD on GPUs.", "startOffset": 38, "endOffset": 61}, {"referenceID": 24, "context": "The batch size was fixed at 16 and the learning rate was controlled by adadelta (Zeiler, 2012).", "startOffset": 80, "endOffset": 94}, {"referenceID": 3, "context": "These generally rely on common techniques from information retrieval, comparing definitions in their internal database to the input query, and returning the word whose definition is \u2018closest\u2019 to the input query (Bilac et al., 2003; Bilac et al., 2004; Zock and Bilac, 2004).", "startOffset": 211, "endOffset": 273}, {"referenceID": 4, "context": "These generally rely on common techniques from information retrieval, comparing definitions in their internal database to the input query, and returning the word whose definition is \u2018closest\u2019 to the input query (Bilac et al., 2003; Bilac et al., 2004; Zock and Bilac, 2004).", "startOffset": 211, "endOffset": 273}, {"referenceID": 25, "context": "These generally rely on common techniques from information retrieval, comparing definitions in their internal database to the input query, and returning the word whose definition is \u2018closest\u2019 to the input query (Bilac et al., 2003; Bilac et al., 2004; Zock and Bilac, 2004).", "startOffset": 211, "endOffset": 273}, {"referenceID": 3, "context": "These generally rely on common techniques from information retrieval, comparing definitions in their internal database to the input query, and returning the word whose definition is \u2018closest\u2019 to the input query (Bilac et al., 2003; Bilac et al., 2004; Zock and Bilac, 2004). Proximity is quantified differently in each case, but is generally a function of hand-engineered features of the two sentences. For instance, Shaw et al. (2013) propose a method in which the candidates for a given input query are all words in the model\u2019s database whose definitions contain one or more words from the query.", "startOffset": 212, "endOffset": 436}, {"referenceID": 22, "context": "In the only previous academic research on English reverse dictionaries that we are aware of, evaluation was conducted on 300 word-definition pairs written by lexicographers, but which are not publicly available (Shaw et al., 2013).", "startOffset": 211, "endOffset": 230}, {"referenceID": 15, "context": "To do so, we randomly selected 200 adjectives, nouns or verbs from among the top 3000 most frequent tokens in the British National Corpus (Leech et al., 1994) (but outside the top 100).", "startOffset": 138, "endOffset": 158}, {"referenceID": 10, "context": "Bilingual embedding models use bilingual corpora to learn a space of representations of the words in two languages, such that words from either language that have similar meanings are close together (Hermann and Blunsom, 2013; Lauly et al., 2014; Gouws et al., 2014).", "startOffset": 199, "endOffset": 266}, {"referenceID": 14, "context": "Bilingual embedding models use bilingual corpora to learn a space of representations of the words in two languages, such that words from either language that have similar meanings are close together (Hermann and Blunsom, 2013; Lauly et al., 2014; Gouws et al., 2014).", "startOffset": 199, "endOffset": 266}, {"referenceID": 8, "context": "Bilingual embedding models use bilingual corpora to learn a space of representations of the words in two languages, such that words from either language that have similar meanings are close together (Hermann and Blunsom, 2013; Lauly et al., 2014; Gouws et al., 2014).", "startOffset": 199, "endOffset": 266}, {"referenceID": 8, "context": "experiment, we used English-French embeddings learned by the state-of-the-art BilBOWA model (Gouws et al., 2014) from the Wikipedia (monolingual) and Europarl (bilingual) corpora.", "startOffset": 92, "endOffset": 112}, {"referenceID": 6, "context": "teams of researchers, modular design and powerful infrastructure, exemplified by IBM\u2019s Watson (Ferrucci et al., 2010).", "startOffset": 94, "endOffset": 117}, {"referenceID": 20, "context": "This has been achieved by restricting questions to a specific topic or domain (Moll\u00e1 and Vicedo, 2007), allowing systems access to pre-specified passages of text from which the answer can be inferred (Iyyer et al.", "startOffset": 78, "endOffset": 102}, {"referenceID": 12, "context": "This has been achieved by restricting questions to a specific topic or domain (Moll\u00e1 and Vicedo, 2007), allowing systems access to pre-specified passages of text from which the answer can be inferred (Iyyer et al., 2014; Weston et al., 2015), or centering both questions and answers on a particular knowledge base (Berant and Liang, 2014; Bordes et al.", "startOffset": 200, "endOffset": 241}, {"referenceID": 23, "context": "This has been achieved by restricting questions to a specific topic or domain (Moll\u00e1 and Vicedo, 2007), allowing systems access to pre-specified passages of text from which the answer can be inferred (Iyyer et al., 2014; Weston et al., 2015), or centering both questions and answers on a particular knowledge base (Berant and Liang, 2014; Bordes et al.", "startOffset": 200, "endOffset": 241}, {"referenceID": 1, "context": ", 2015), or centering both questions and answers on a particular knowledge base (Berant and Liang, 2014; Bordes et al., 2014).", "startOffset": 80, "endOffset": 125}, {"referenceID": 5, "context": ", 2015), or centering both questions and answers on a particular knowledge base (Berant and Liang, 2014; Bordes et al., 2014).", "startOffset": 80, "endOffset": 125}, {"referenceID": 16, "context": "As our interest is in the language understanding, we do not address the question of fitting answers into a grid, which is the main concern of end-to-end automated crossword solvers (Littman et al., 2002).", "startOffset": 181, "endOffset": 203}, {"referenceID": 16, "context": "com/) is the candidate generation module of the award-winning Proverb crossword system (Littman et al., 2002).", "startOffset": 87, "endOffset": 109}, {"referenceID": 7, "context": "10 We are unable to compare against a third well-known automatic crossword solver, Dr Fill (Ginsberg, 2011), because code for Dr Fill\u2019s candidate-generation module is not readily available.", "startOffset": 91, "endOffset": 107}, {"referenceID": 16, "context": "nents (Littman et al., 2002; Ginsberg, 2011).", "startOffset": 6, "endOffset": 44}, {"referenceID": 7, "context": "nents (Littman et al., 2002; Ginsberg, 2011).", "startOffset": 6, "endOffset": 44}, {"referenceID": 18, "context": "representations are known to encode these sorts of relationships (even after elementwise addition) (Mikolov et al., 2013), and seem particularly powerful in this case as the nearest neighbour search is constrained by a specified word length.", "startOffset": 99, "endOffset": 121}, {"referenceID": 5, "context": "gun to achieve impressive results on certain QA and entailment tasks (Bordes et al., 2014; Graves et al., 2014; Weston et al., 2015).", "startOffset": 69, "endOffset": 132}, {"referenceID": 9, "context": "gun to achieve impressive results on certain QA and entailment tasks (Bordes et al., 2014; Graves et al., 2014; Weston et al., 2015).", "startOffset": 69, "endOffset": 132}, {"referenceID": 23, "context": "gun to achieve impressive results on certain QA and entailment tasks (Bordes et al., 2014; Graves et al., 2014; Weston et al., 2015).", "startOffset": 69, "endOffset": 132}, {"referenceID": 9, "context": "tion of an external memory module, similar to the promising approaches proposed in several recent papers (Graves et al., 2014; Weston et al., 2015).", "startOffset": 105, "endOffset": 147}, {"referenceID": 23, "context": "tion of an external memory module, similar to the promising approaches proposed in several recent papers (Graves et al., 2014; Weston et al., 2015).", "startOffset": 105, "endOffset": 147}], "year": 2015, "abstractText": "Distributional models that learn rich semantic word representations are a success story of recent NLP research. However, developing models that learn useful representations of phrases and sentences has proved far harder. We propose using the definitions found in everyday dictionaries as a means of bridging this gap between lexical and phrasal semantics. We train a recurrent neural network (RNN) to map dictionary definitions (phrases) to (lexical) representations of the words those definitions define. We present two applications of this architecture: a reverse dictionary, for returning the name of a concept given a definition or description, and a general-knowledge (crossword) question answerer. On both tasks, the RNN trained on definitions from a handful of freelyavailable lexical resources performs comparably or better than existing commercial systems that rely on major task-specific engineering and far greater memory footprints. This strong performance highlights the general effectiveness of both neural language models and definitionbased training for training machines to understand phrases and sentences.", "creator": "LaTeX with hyperref package"}}}