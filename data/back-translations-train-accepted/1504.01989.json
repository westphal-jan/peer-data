{"id": "1504.01989", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Apr-2015", "title": "Pixel-wise Deep Learning for Contour Detection", "abstract": "We address the problem of contour detection via per-pixel classifications of edge point. To facilitate the process, the proposed approach leverages with DenseNet, an efficient implementation of multiscale convolutional neural networks (CNNs), to extract an informative feature vector for each pixel and uses an SVM classifier to accomplish contour detection. In the experiment of contour detection, we look into the effectiveness of combining per-pixel features from different CNN layers and verify their performance on BSDS500.", "histories": [["v1", "Wed, 8 Apr 2015 14:44:20 GMT  (13kb)", "http://arxiv.org/abs/1504.01989v1", "2 pages. arXiv admin note: substantial text overlap witharXiv:1412.6857"]], "COMMENTS": "2 pages. arXiv admin note: substantial text overlap witharXiv:1412.6857", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["jyh-jing hwang", "tyng-luh liu"], "accepted": true, "id": "1504.01989"}, "pdf": {"name": "1504.01989.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["jyhjinghwang@iis.sinica.edu.tw", "liutyng@iis.sinica.edu.tw"], "sections": [{"heading": null, "text": "ar Xiv: 150 4.01 989v 1 [cs.C V] 8A pr2 01"}, {"heading": "1 INTRODUCTION", "text": "Since the task is essentially a classification problem, we use deep Convolutionary Neural Networks (CNNs) to establish a discriminatory approach. However, a subtle deviation from typical applications of CNNs should be highlighted. In our method, we intend to use the CNN architecture, e.g. AlexNet (Krizhevsky et al., 2012), to generate characteristics for each image pixel, not just a single characteristic vector for the entire input image. Such a distinction would require a different perspective of parameter fine-tuning, so that a pre-trained CNN on ImageNet (Deng et al., 2009) can be adapted to a new model of classifications per pixel edge. To investigate the property of the characteristics from different revolutionary layers, we are conducting a series of experiments to evaluate their effectiveness in performing contour recognition on the benchmark BSDS segment dataset (Martin 2001)."}, {"heading": "2 PER-PIXEL CNN FEATURES", "text": "It has been shown that most of the existing techniques focus on providing a feature vector for an input image (or image patch), and such a design may not be suitable for vision applications that require the investigation of image characteristics at the pixel level. For contour detection, the key task is to decide whether an underlying pixel is an edge point or not. Therefore, it would be handy that the deep network could provide pro-pixel features. To this end, we extract per pixel CNN features in AlexNet (Krizhevsky et al., 2012) with DenseNet (Iandola et al., 2014) and link them pixel by pixel to feed into a support vector machine (SVM). Our implementation uses DenseNet to extract CNN features due to its efficiency, flexibility and availability. DenseNet is an open source system that condenses and multiscale objectives based on a layer of features."}, {"heading": "3 EXPERIMENTAL RESULTS", "text": "We test our method on the Berkeley Segmentation Dataset and Benchmark (BSDS500) (Martin et al., 2001; Arbelaez et al., 2011). To better assess the effects of the characteristics of different layers, we report on their respective performance in contour detection. The BSDS500 dataset includes 200 training sessions, 100 validations and 200 test images. The limits in each image are labeled and averaged by multiple workers to form the basic truth.The accuracy of contour detection is evaluated by three metrics: the best F measurement on the dataset for a fixed threshold (ODS), the aggregated F measurement on the dataset for the best threshold in each image (OIS) and the average precision (AP) across the memory range (Arbelaez et al., 2011).Before the evaluation, we apply a standard, non-maximum suppression technique on edge maps to obtain thinner contours (Canny), while most of the lower-level characteristics are applied (Canny)."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was partially supported by NSC 102-2221-E-001-021-MY3."}], "references": [{"title": "Contour detection and hierarchical image segmentation", "author": ["Arbelaez", "Pablo", "Maire", "Michael", "Fowlkes", "Charless", "Malik", "Jitendra"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Arbelaez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Arbelaez et al\\.", "year": 2011}, {"title": "A computational approach to edge detection", "author": ["Canny", "John"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Canny and John.,? \\Q1986\\E", "shortCiteRegEx": "Canny and John.", "year": 1986}, {"title": "ImageNet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-Jia", "Kai", "Fei-Fei"], "venue": "In CVPR, pp", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Densenet: Implementing efficient convnet descriptor pyramids", "author": ["Iandola", "Forrest", "Moskewicz", "Matt", "Karayev", "Sergey", "Girshick", "Ross", "Darrell", "Trevor", "Keutzer", "Kurt"], "venue": "arXiv preprint arXiv:1404.1869,", "citeRegEx": "Iandola et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Iandola et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics", "author": ["Martin", "David", "Fowlkes", "Charless", "Tal", "Doron", "Malik", "Jitendra"], "venue": "In Computer Vision,", "citeRegEx": "Martin et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Martin et al\\.", "year": 2001}], "referenceMentions": [{"referenceID": 4, "context": ", AlexNet (Krizhevsky et al., 2012), to generate features for each image pixel, not just a single feature vector for the whole input image.", "startOffset": 10, "endOffset": 35}, {"referenceID": 2, "context": "Such a distinction would call for a different perspective of parameter fine-tuning so that a pre-trained per-image CNN on ImageNet (Deng et al., 2009) can be adapted into a new model for per-pixel edge classifications.", "startOffset": 131, "endOffset": 150}, {"referenceID": 5, "context": "To investigate the property of the features from different convolutional layers, we carry out a number of experiments to evaluate their effectiveness in performing contour detection on the benchmark BSDS Segmentation dataset (Martin et al., 2001).", "startOffset": 225, "endOffset": 246}, {"referenceID": 4, "context": "To this end, we extract per-pixel CNN features in AlexNet (Krizhevsky et al., 2012) using DenseNet (Iandola et al.", "startOffset": 58, "endOffset": 83}, {"referenceID": 3, "context": ", 2012) using DenseNet (Iandola et al., 2014), and pixel-wise concatenate them to feed into a support vector machine (SVM) classifier.", "startOffset": 23, "endOffset": 45}, {"referenceID": 5, "context": "We test our method on the Berkeley Segmentation Dataset and Benchmark (BSDS500) (Martin et al., 2001; Arbelaez et al., 2011).", "startOffset": 80, "endOffset": 124}, {"referenceID": 0, "context": "We test our method on the Berkeley Segmentation Dataset and Benchmark (BSDS500) (Martin et al., 2001; Arbelaez et al., 2011).", "startOffset": 80, "endOffset": 124}, {"referenceID": 0, "context": "The accuracy of contour detection is evaluated by three measures: the best F-measure on the dataset for a fixed threshold (ODS), the aggregate F-measure on the dataset for the best threshold in each image (OIS), and the average precision (AP) on the full recall range (Arbelaez et al., 2011).", "startOffset": 268, "endOffset": 291}], "year": 2015, "abstractText": "We address the problem of contour detection via per-pixel classifications of edge point. To facilitate the process, the proposed approach leverages with DenseNet, an efficient implementation of multiscale convolutional neural networks (CNNs), to extract an informative feature vector for each pixel and uses an SVM classifier to accomplish contour detection. In the experiment of contour detection, we look into the effectiveness of combining per-pixel features from different CNN layers and verify their performance on BSDS500.", "creator": "LaTeX with hyperref package"}}}