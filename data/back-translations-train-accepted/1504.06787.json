{"id": "1504.06787", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Apr-2015", "title": "Max-Margin Deep Generative Models", "abstract": "Deep generative models (DGMs) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability. However, little work has been done on examining whether the representations are discriminative enough to get good prediction performance. In this paper, we present max-margin deep generative models (mmDGMs), which explore the strongly discriminative principle of max-margin learning to improve the discriminative power of DGMs, while retaining the generative capability. We develop an efficient doubly stochastic subgradient algorithm. Empirical results on MNIST and its variant datasets demonstrate that (1) max-margin learning can significantly improve the classification performance of DGMs and meanwhile retain the ability of inferring input data; and (2) mmDGMs are competitive to the state-of-the-art networks that have a similar structure.", "histories": [["v1", "Sun, 26 Apr 2015 06:01:19 GMT  (699kb,D)", "https://arxiv.org/abs/1504.06787v1", null], ["v2", "Fri, 1 May 2015 01:58:31 GMT  (657kb,D)", "http://arxiv.org/abs/1504.06787v2", null], ["v3", "Mon, 15 Jun 2015 08:40:09 GMT  (2139kb,D)", "http://arxiv.org/abs/1504.06787v3", null], ["v4", "Tue, 15 Dec 2015 03:01:06 GMT  (2521kb,D)", "http://arxiv.org/abs/1504.06787v4", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["chongxuan li", "jun zhu", "tianlin shi", "bo zhang"], "accepted": true, "id": "1504.06787"}, "pdf": {"name": "1504.06787.pdf", "metadata": {"source": "CRF", "title": "Max-Margin Deep Generative Models", "authors": ["Chongxuan Li", "Jun Zhu", "Tianlin Shi", "Bo Zhang"], "emails": ["{licx14@mails.,", "dcszj@,", "dcszb@}tsinghua.edu.cn;", "stl501@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who live in the US live where they don't belong."}, {"heading": "2 Basics of Deep Generative Models", "text": "However, a deep generative model (DGM) assumes that each xn-RD model is generated from a vector of latent variables, which itself follows a certain distribution, but the common probability of a DGM is as follows: p (X, Z | \u03b1, \u03b2) = N-RD is generated from a vector of latent variables, (1) where p (zn) is the previous latent variables and p (xn, \u03b2) is the probability model for generative observations. For notation simplicity, we define a system in which we have developed the structure of z, various DGMs, such as the deep faith networks [25, 16], deep sigmoid networks [21], deep latent Gaussian models [24], and deep auto-regressive models [9]."}, {"heading": "3 Max-margin Deep Generative Models", "text": "We look at supervised learning, where the training data is a pair (x, y) with input characteristics q, RD and the basic truth label y. Without loss of generality, we look at the multi-class classification, where y, c = {1,.., M}. A deep generative model with maximum margin (mmDGM) consists of two components: (1) a deep generative model to describe input characteristics; and (2) a classifier with maximum margin to take monitoring into account. For the generative model, we can adopt in theory any DGM that defines a common distribution over (X, Z), as in equation. (1) For the classifier with maximum margin, instead of fitting the input characteristics into a conventional SVM, we define the linear classifier on the latent representations, the learning of which is regulated by the supervision signal, as we will see. Specifically, we define the latent representation of the latent representation when the latency is given by representation."}, {"heading": "3.1 The Learning Problem", "text": "Based on the equivalent variation formula of MLE, we define the common learning problem as a solution approach: min \u03b8, q (\u03b7, Z), \u044b L (\u03b8, q (\u03b7, Z); X) + C N + N + N + N + N + N + N + N (4), y \u00b2 C, s.t.: {Eq [\u03b7 > \u0445 fn (y)] 0 x 0 x 0 x 0 x 0 x 0 x 0 x 0 is the difference of the feature vectors; \u2206 ln (y) is the loss function that measures the cost of predicting y if the true designation is yn; and C is a non-negative regulation parameter that balances the two components."}, {"heading": "3.2 The Doubly Stochastic Subgradient Algorithm", "text": "The variational formula of the problem (5) naturally indicates that we can develop a variational algorithm = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = ="}, {"heading": "4 Experiments", "text": "We now present experimental results on the widely used MNIST [14] and SVHN [22] datasets. Although mmDGMs are applicable to all DGMs that define a common distribution of X and Z, we focus on the Variational Auto-Encoder (VA) [12], which is not monitored. We refer to our mmDGM with VA by MMVA. In our experiments, we consider two types of detection models: Multilayer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs)."}, {"heading": "4.1 Architectures and Settings", "text": "In the case of MLP, we follow the settings in [11] to compare both generative and discriminatory capacities of VA and MVA. In the case of CNN, we use standard Convolutionary Networks [14] with convolution and max pooling operation as a detection model to obtain more competitive classification results. In the generative model, we use unconventional structures as a detection model to roughly reconstruct the input images. Specifically, the generative model has the same structure as the lower detection model, but it replaces the maximum pooling operation [6] and applies unpooling, confusion and rectification in sequence. The total number of parameters in the revolutionary network is comparable to previous work. [8, 17, 15] For simplicity, we are unable to dense mlpconv layers [17, 15] and contrast normalization layers in our detection model."}, {"heading": "4.2 Results on the MNIST dataset", "text": "We present both the predictive performance and the results for generating samples of MMVA and VA + Pegasos using both types of recognition models on the MNIST [14] dataset, which consists of images of 10 different classes (0 to 9) of size 28 \u00d7 28 with 50,000 training samples, 10,000 validation samples and 10,000 test samples. 4.2.1 Predictive Performance Table 1: Error rates (%) on MNIST dataset.MODELL ERROR RATE VA + Pegasos 1.04 VA + Class-conditionVA 0.90 CVA + Pegasos 1.35 CMMMVA 0.45 Stochastic Pooling [33] 0.47 Network in Network [17] 0.47 Maxout Network 0.45 DSN [15] 0.39 In the MLP case, we only use 50,000 training data, and the parameters for classification are optimized."}, {"heading": "4.3 Results on the SVHN (Street View House Numbers) dataset", "text": "SVHN [22] is a large dataset consisting of 32 x 32 color images. The task is to identify center digits in natural scene images, which is much more difficult than classifying handwritten numerals. We follow the work [27, 8] to split the dataset into 598,388 training data, 6000 validation data, and 26,032 test data, and to pre-process the data using Local Contrast Normalization (LCN). We are only looking at the CNN detection model. The network structure is similar to that of MNIST. We have C = 104 for our CMMVA model on SVHN by default. Table 3 shows the predictive performance. On this more difficult problem, we observe a greater improvement by CMMVA compared to CVA + Pegasos, which indicates that DGMs benefit greatly from maximum margin learning in image classification. We compare CMVA lab results with state-of-the-art scenarios."}, {"heading": "4.4 Missing Data Imputation and Classification", "text": "For MNIST, we look at two types of missing values [18]: (1) Border drop: Each pixel is randomly missing with a predetermined probability; and (2) Rect: a rectangle located in the center of the image is missing. In view of the disturbed images, we initialize the missing values uniformly between 0 and 1 and then iteratively perform the following steps: (1) Use the detection model to scan the hidden variables; (2) Predict the missing values to generate images; and (3) Use the refined images as input for the next round. For SVHN, we do the same procedure as in MNIST, but initialize the missing values with Guassianrandom variables as the input distribution changes change. Visualization results on MNIST and SVHN MSR values are displayed in Appendix C and Appendix D."}, {"heading": "5 Conclusions", "text": "We are developing a double stochastic subgradient algorithm to learn all parameters together and consider two types of detection models with MLPs or CNNs. In both cases, we present extensive results to show that mmDGMs can significantly improve the prediction performance of deep generative models while maintaining the strong generative ability to generate input samples and supplementing missing values. In fact, by using CNNs in both detection and generative models, we achieve low error rates for MNIST and SVHN data sets that compete with the state-of-the-art, fully discriminatory networks."}, {"heading": "Acknowledgments", "text": "The work was supported by the National Basic Research Programme (Nos. 2013CB329403, 2012CB316301), the National NSF of China (Nos. 61322308, 61332007), the Tsinghua TNList Lab Big Data Initiative and the Scientific Research Programme of the Tsinghua Initiative (Nos. 20121088071, 20141080934)."}, {"heading": "A Detailed Architectures", "text": "In all our experiments, (C) VA and (C) MMVA use the same structures and settings.A.1 MNISTWe set the dimension of the latent variables to 50 in all experiments to MNIST. In the case of MLP, both the detection and generative models use a two-layer MLP with 500 hidden units in each layer. We illustrate the network architecture of MMVA with hidden variables of Gauss and Bernoulli visible variables in Fig. 3. In the case of CNN, our Convolutionary Network contains 5 folding layers. There are 32 feature maps in the first two folding layers and 64 feature maps in the last three folding layers. We use size 3 filters throughout the network with the exception of size 5 filters in the first layer. Instead of the global average pooling, an MLP with 500 hidden units at the end of the folding layer is used to achieve narrower and better generation layers."}, {"heading": "B T-SNE Visualization Results", "text": "The T-SNE embedding of the results of the features learned from VA and MMVA at the 2D level is shown in Fig. 5 (a) and Fig. 5 (b), respectively, with the same data points randomly sampled from the MNIST dataset. Compared to the VA embedding, MVA separates the images better from different categories, especially for the interchangeable digits such as \"4\" and \"9.\" These results show that MMVA, which benefits from the Max Margin principle, learns more differentiated representations of the digits than VA.C implantation results on MNISTThe implantation results of CVA and CMMVA are shown in Fig. 6. CMVA makes fewer errors and refines the images better, which is consistent with the MSE results, as reported in the main text. We visualize the MMVA implantation results for 20 itations."}, {"heading": "E Classification Results with Missing Values", "text": "CNN directly predicts the incomplete data. CVA and CMMVA first derive missing data for 100 iterations and then make predictions using the refined data. In this scenario, CMMVA outperforms both CVA and CNN, demonstrating the benefits of our mmDGMs, which have both strong discriminatory and generative capabilities."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "Deep generative models (DGMs) are effective on learning multilayered represen-<lb>tations of complex data and performing inference of input data by exploring the<lb>generative ability. However, little work has been done on examining or empower-<lb>ing the discriminative ability of DGMs on making accurate predictions. This pa-<lb>per presents max-margin deep generative models (mmDGMs), which explore the<lb>strongly discriminative principle of max-margin learning to improve the discrim-<lb>inative power of DGMs, while retaining the generative capability. We develop an<lb>efficient doubly stochastic subgradient algorithm for the piecewise linear objec-<lb>tive. Empirical results on MNIST and SVHN datasets demonstrate that (1) max-<lb>margin learning can significantly improve the prediction performance of DGMs<lb>and meanwhile retain the generative ability; and (2) mmDGMs are competitive to<lb>the state-of-the-art fully discriminative networks by employing deep convolutional<lb>neural networks (CNNs) as both recognition and generative models.", "creator": "LaTeX with hyperref package"}}}