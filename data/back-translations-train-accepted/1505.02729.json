{"id": "1505.02729", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2015", "title": "Sample Complexity of Learning Mahalanobis Distance Metrics", "abstract": "Metric learning seeks a transformation of the feature space that enhances prediction quality for the given task at hand. In this work we provide PAC-style sample complexity rates for supervised metric learning. We give matching lower- and upper-bounds showing that the sample complexity scales with the representation dimension when no assumptions are made about the underlying data distribution. However, by leveraging the structure of the data distribution, we show that one can achieve rates that are fine-tuned to a specific notion of intrinsic complexity for a given dataset. Our analysis reveals that augmenting the metric learning optimization criterion with a simple norm-based regularization can help adapt to a dataset's intrinsic complexity, yielding better generalization. Experiments on benchmark datasets validate our analysis and show that regularizing the metric can help discern the signal even when the data contains high amounts of noise.", "histories": [["v1", "Mon, 11 May 2015 18:55:42 GMT  (51kb,D)", "http://arxiv.org/abs/1505.02729v1", "26 pages, 1 figure"]], "COMMENTS": "26 pages, 1 figure", "reviews": [], "SUBJECTS": "cs.LG cs.AI stat.ML", "authors": ["nakul verma", "kristin branson"], "accepted": true, "id": "1505.02729"}, "pdf": {"name": "1505.02729.pdf", "metadata": {"source": "CRF", "title": "Sample Complexity of Learning Mahalanobis Distance Metrics", "authors": ["Nakul Verma", "Kristin Branson"], "emails": ["verman@janelia.hhmi.org;", "bransonk@janelia.hhmi.org"], "sections": [{"heading": "1 Introduction", "text": "Over the past ten years, we have seen a multitude of successful metric learning processes in which the individual dimensions have been related to each other. (...) There is no reason to expect such a development to occur. (...) There is no reason why one should expect such a development to occur. (...) There is no reason why one can go so far. \"(...) There is no reason why one can go so far.\" (...) There is no reason why one can go so far. \"(...)\" There is no reason why one should go so far. \"(...) There is no reason why one can go so far.\" (...) There is no reason why one can go so far. \"(...) There is no reason why one can go so far.\" (...) (...) There is no reason why one can go so far. (...)"}, {"heading": "2 Preliminaries", "text": "Given a representation space X = RD of D real weighted measurements of interest, the goal of metric learning is to learn a metric M (i.e., a D \u00b7 D real weighted weight matrix on X) (i.e., a D \u00b7 D real weighted weight matrix on X; to remove any scaling, we assume that the maximum singular value of M, i.e., \u03c3max (M) = 1) 1, which minimizes the notion of an error based on an unknown underlying distribution D on X \u00b7 {0, 1}. Specifically, we want to find the metricM *: = argminM * M err (M, D), from the class of metricsM taking into account, that is, M \u00b2 RD \u00b7 D = 1}. For verified metric learning, this error is typically defined in several reasonable ways. As already discussed, we explore two intuitive regimes for defining error."}, {"heading": "3 Learning a Metric from Samples", "text": "In any practical environment, we estimate the ideal weighting quantity M * by using the empirical version of the error criterion from a finite sample of D. Let Sm denote a sample of size m, and err (M, Sm) denote the empirical error in the sample Sm (the exact definitions of Sm and the form of the error (M, Sm) will be discussed later). We can then define the empirical risk mitigation quantity from m samples as M \u0445 m: = argminM err (M, Sm). Of course, most practical algorithms provide some approximation to M * m, so it is important to compare the generalization capability of M * m with the theoretically optimal M *. That is, how high (M * m, D) \u2212 err (M *, D) (2) converges when the sample size m grows."}, {"heading": "3.1 Distance-Based Error Analysis", "text": "Considering an i.i.d. sequence of observations z1, z2,. of D, we can combine the observations to form a paired sample Sm = {z1, z2), (z3, z4),., (z2m \u2212 1, z2m) = {z1, z2, i} mi = 1 of size m, and define the sample on the basis of errors caused by a metric M aserri (M, Sm): = 1 m m (m)."}, {"heading": "3.2 Classifier-Based Error Analysis", "text": "In this context, we can obtain an i.i.d. sequence of observations z1, z2,. < from D the sample Sm = {zi} mi = 1 of quantity m directly. To analyze the generalizability of the weighted metrics optimized in relation to an underlying hypothesis class H, we must effectively analyze the classification complexity of H and find an intuitive way to relativize the generalization error to the empirical margin of error (see the work of Anthony & Bartlett (1999) for an excellent discussion. In the context of metric learning in relation to a fixed hypothesis class, we define the empirical error to the empirical margin of error."}, {"heading": "4 Data with Uninformative and Weakly Informative Features", "text": "To provide a solid basis for our study, we are introducing the concept of the metric learning complexity of a given dataset. Our central observation is that a metric that performs well in generalizing should emphasize relevant characteristics while suppressing the contribution of false characteristics. Thus, a good metric reflects the quality of individual characteristic measurements of data and their relative value for the learning task. We can use this and define the metric learning complexity of a given dataset as the intrinsic complexity d of the weighting metric that provides the best generalization performance for that dataset (when multiple metrics perform best, we select the one with a minimum of d). A natural way to characterize the intrinsic complexity of a weighting metric M is the standard for the representation of the matrix that we use as a benchmark for our work."}, {"heading": "4.1 Distance-Based Refinement", "text": "We begin with the following refinement of distance-based metric learning sample complexity for a class of standard Frobenius weighting metrics. Lemma 5 LetM is any class of weighting metrics for character space X = RD. Determine any sample size m and let Sm be an i.i.d. paired sample of size m from an unknown limited distribution D to X \u00d7 {0, 1} (with limit B). For each distance-based loss function, this applies in the first argument, with a probability of at least 1 \u2212 \u043c above the drawing of Sm, sup M \u00b2 M [Errors (M, D) \u2212 Errors (M, Sm)] \u2264 O (\u03bbB2 \u221a d ln (1 / 3) m), where d is a uniform upper limit above the drawing of Sm, sup M \u00b2 M [Errors (M, D) \u2212 Errors (M, Sm)]."}, {"heading": "4.2 Classifier-Based Refinement", "text": "Effective data-dependent analysis of classifier-based metric learning processes requires consideration of potentially complex interactions between any basic hypotheses category and the distortion caused by weighting metrics on the unknown underlying data distribution. In order to make the analysis comprehensible while maintaining our basic hypotheses category H in general, we assume that H is a class of two-layer forward-facing neural networks (Hornik et al., 1989), so this class is flexible enough to integrate the most reasonable target hypotheses. Formally, we define the base hypotheses category of two-layer neural networks with hidden units of asH2-net-static units asH2-net-net-static units asH2-net-net-static units: = {x 7 \u2192 K-net-static cells i = 1-hyprimal cells (x)."}, {"heading": "4.3 Automatically Adapting to Intrinsic Complexity", "text": "Note that, while Lemmas 5 and 6 give a sample complexity limit matched to the metric complexity of a given set of data, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "5 Empirical Evaluation", "text": "We have the opportunity to set out in search of a solution that could put us in a position to put ourselves in a position to put ourselves in a position to put ourselves in a position to put ourselves in a position to put ourselves in a position to put ourselves in a position to put ourselves in a position where we are. \"(ibs)\" We, \"it says in the justification,\" we, \"\" we, \"\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\" we, \"we,\""}, {"heading": "6 Discussion and Conclusion", "text": "Their theoretical work on metric learning focuses almost exclusively on analyzing the generalization errors of variants of optimization criteria for the remote metric learning framework. Jin et al. (2009), for example, analyzes the generalization capability of regulated, convex optimization criteria for paired distances using an algorithmic stability analysis. They derive from this an interesting example of complexity that is sublinear in the U.S. (2012) They discuss that the example complexity can be potentially independent of D, but they do not characterize specific instances or classes of problems where this is possible. Likewise, the recent work of Bellet & Habrard, which uses algorithmic robustness to analyze the generalization capability of pairings and triplexes."}, {"heading": "A Appendix: Various Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Proof of Lemma 1", "text": "Let P be the probability variable caused by the random variable (X, Y), where X: (x, x), Y: (x, x), st: (x, y), p: (X, y:), p: (D, Y:), p: (x, x:), p: (x, x:), p: (x, x:), p: (x, x:), p: (x, x:), p: (X, x:), p: (x), p: (x, x:), p: (x), p: (x), p: (x), p: (x), p: (x), p: (x), p: (x), p: (x), p: (x, p: (x), p: (x), p: (x), p: (x), p: (x), p: (x, y:), p: (X, Y:), p: (x)"}, {"heading": "A.2 Proof of Lemma 2", "text": "We will have a finite class of limited support distributions D, so that ifD will be randomly selected (via the random choice of D). (This implies that for some distributions in D, the probability of failure is at least equal. (This implies that for some distributions in D, the probability of failure is at least equal.) Let us define D: = {x0,., xD} as a set of D + 1 points derived from the distributions of a regular unitsimplex from the underlying space X = RD as below. (For a fixed parameter 0 < 1 (exact value determined later), we define D as a class of all distributions D on X \u00b7 {0, 1} so that the probability is zero. (D assign zero to all records that are not intersectional."}, {"heading": "A.3 Proof of Lemma 3", "text": "& M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M M & M; M & M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M & M; M & M & M & M & M & M & M; M & M & M & M & M & M & M & M & M & M M & M & M & M; M & M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M; M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M & M"}, {"heading": "A.4 Proof of Lemma 4", "text": "For each fixed 0 < \u03b3 < 1 / 8 and the given limited class of distributions with bound B \u2265 1, we consider one (1 / B) -bi-Lipschitz base hypothesis class H, the hypotheses from domain X to [1 / 2 \u2212 4\u03b3, 1 / 2 + 4\u03b3, and define one (1 / 7 \u2192 h (Mx): M \u00b2 -M, h \u00b2 H}.Note that the finding M, which minimizes error, is equivalent to a finding f, which minimizes error to F. Using Lemma \u00b2 s < 1 / 2) -M (F) -X \u00b2 -Z: Fatlt; F \u00b2 -M (F) -M (F) -320, (2), (F) -S (4) -2, see below."}, {"heading": "S \u2282 \u03c04\u03b3(F) of size (1/32\u03b3)D", "text": "2P. (48), \u03c04\u03b3 (H), m), that is one (16), -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -, -,"}, {"heading": "A.5 Proof of Lemma 5", "text": "Let P be the probability measure induced by the random variable (X, Y), where X: = (x, x), Y: = 1 [y = y], st. ((x, y), (x, y)), (D \u00b7 D). Define function classes F: = {fM: X 7 \u2192 E M (x \u2212 x \u00b2), E 2 [x, x \u00b2), E (X \u00b7 X)}. Following the steps of proving Lemma 1, we can conclude that the wheel-maker complexity of F is limited, especially Rm (F) \u2264 4B2 \u221a supM, M, MTM, 2F m. The result follows by pointing out that the first argument and using Lemma 8 is a proxy tip."}, {"heading": "A.6 Proof of Lemma 6", "text": "Consider the function class F: = {fv, M: x 7 \u2192 v \u00b7 Mx \u00b2 v \u00b2 v \u00b2 1 \u2264 1, M \u00b2 M \u00b2, and define the composition of the class F \u00b2: = {x 7 \u00b2 K \u00b2 i = 1 wix \u00b2 (fi (x))), because (let g1,.., gm = independent standard Gaussian variables) Gm (F, D): = Exi \u00b2 complexity of F (in relation to the distributionD) is limited, because (let g1,., gm = independent standard Gaussian variables) Gm (F, D): = Exi \u00b2 complexity of F (supfv, M \u00b2 -F1m m \u00b2 i = 1 gifv, M (xi) = 1 gifv, M (xi)] = 1 Exi \u00b2 -Exi \u00b2 distribution of D (X, i \u00b2), i \u00b2 -Exi (sup M \u00b2, M \u00b2 -M \u00b2 class of M \u00b2 -j \u00b2, M \u00b2 -j -M \u00b2, M \u00b2 -j -M \u00b2."}, {"heading": "A.7 Proof of Corollary 7", "text": "The conclusion of Equation (3) results directly by dividing the specified error probability by the sequence M1, M2, \u00b7 \u00b7 in such a way that the error probability is associated with class Md, then applying Lemma 5 (for distance-based metric learning) or Lemma 6 (for classification-based metric learning) for each class Md separately and finally combining the individual deviations together with a connection boundary. In the second part, for each M-M definition dM and \u0394M definition according to the Lemma definition are applied. In the third part, then with probability at least 1 \u2212 Errors (M-Regulates, D) \u2212 Errors (M-Regulates, Sm) + dM-Regulars (M-Regulars, D) + dM-Regulars (M-Regulates, M-Regulars, M-M-Regulars, M-M-Regulars, M-M-Regulars, M-M-Regulars, M-M-Regulars, M-M-Regulates, M-M-Regulars, M-M-Regulars, M-M-Regulates, M-M-M-Regulates, M-M-Regulates, M-M-Regulates, M-M-M-Regulates, M-M-M-Regulates, M-M-Regulates, M-M-Regulates, M-M-Regulates, M-M-M, M-M-Regulates, M-Regulates, M-M, M-M-M-M and M-M-Regulates, M-M-M-Regulators, M-M-M-Regulates, M-M-M-Regulates, M, M-M-M, M-Regulatory, M-M-M"}], "references": [{"title": "Neural network learning: Theoretical foundations", "author": ["M. Anthony", "P. Bartlett"], "venue": null, "citeRegEx": "Anthony and Bartlett,? \\Q1999\\E", "shortCiteRegEx": "Anthony and Bartlett", "year": 1999}, {"title": "Rademacher and Gaussian complexities: Risk bounds and structural results", "author": ["P. Bartlett", "S. Mendelson"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Bartlett and Mendelson,? \\Q2002\\E", "shortCiteRegEx": "Bartlett and Mendelson", "year": 2002}, {"title": "Robustness and generalization for metric learning", "author": ["A. Bellet", "A. Habrard"], "venue": "CoRR, abs/1209.1086,", "citeRegEx": "Bellet and Habrard,? \\Q2012\\E", "shortCiteRegEx": "Bellet and Habrard", "year": 2012}, {"title": "A survey on metric learning for feature vectors and structured data", "author": ["A. Bellet", "A. Habrard", "M. Sebban"], "venue": "CoRR, abs/1306.6709,", "citeRegEx": "Bellet et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bellet et al\\.", "year": 2014}, {"title": "Learning a distance metric by empirical loss minimization", "author": ["W. Bian", "D. Tao"], "venue": "International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "Bian and Tao,? \\Q2011\\E", "shortCiteRegEx": "Bian and Tao", "year": 2011}, {"title": "Generalization bounds for metric and similarity learning", "author": ["Q. Cao", "Z. Guo", "Y. Ying"], "venue": "CoRR, abs/1207.5437,", "citeRegEx": "Cao et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2013}, {"title": "New generalization bounds for learning kernels", "author": ["C. Cortes", "M. Mohri", "A. Rostamizadeh"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "Cortes et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2010}, {"title": "Information-theoretic metric learning", "author": ["J.V. Davis", "B. Kulis", "P. Jain", "S. Sra", "I.S. Dhillon"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "Davis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Davis et al\\.", "year": 2007}, {"title": "Generalization classification via regularized similarity learning", "author": ["Z. Guo", "Y. Ying"], "venue": "Neural Computation,", "citeRegEx": "Guo and Ying,? \\Q2014\\E", "shortCiteRegEx": "Guo and Ying", "year": 2014}, {"title": "Multilayer feedforward networks are universal approximators", "author": ["K. Hornik", "M. Stinchcombe", "H. White"], "venue": "Neural Networks,", "citeRegEx": "Hornik et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Hornik et al\\.", "year": 1989}, {"title": "Regularized distance metric learning: Theory and algorithm", "author": ["R. Jin", "S. Wang", "Y. Zhou"], "venue": "Neural Information Processing Systems (NIPS),", "citeRegEx": "Jin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jin et al\\.", "year": 2009}, {"title": "Fantope regularization in metric learning", "author": ["M.T. Law", "N. Thome", "M. Cord"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Law et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Law et al\\.", "year": 2014}, {"title": "Robust structural metric learning", "author": ["D.K.H. Lim", "B. McFee", "G.R.G. Lanckriet"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "Lim et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lim et al\\.", "year": 2013}, {"title": "Metric learning to rank", "author": ["B. McFee", "G.R.G. Lanckriet"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "McFee and Lanckriet,? \\Q2010\\E", "shortCiteRegEx": "McFee and Lanckriet", "year": 2010}, {"title": "Learning a distance metric from a network", "author": ["B. Shaw", "B. Huang", "T. Jebara"], "venue": "Neural Information Processing Systems (NIPS),", "citeRegEx": "Shaw et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shaw et al\\.", "year": 2011}, {"title": "Introduction to the non-asymptotic analysis of random matrices", "author": ["R. Vershynin"], "venue": "In Compressed Sensing, Theory and Applications", "citeRegEx": "Vershynin,? \\Q2010\\E", "shortCiteRegEx": "Vershynin", "year": 2010}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["K.Q. Weinberger", "L.K. Saul"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Weinberger and Saul,? \\Q2009\\E", "shortCiteRegEx": "Weinberger and Saul", "year": 2009}, {"title": "Distance metric learning with application to clustering with side-information", "author": ["E.P. Xing", "A.Y. Ng", "M.I. Jordan", "S.J. Russell"], "venue": "Neural Information Processing Systems (NIPS),", "citeRegEx": "Xing et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Xing et al\\.", "year": 2002}, {"title": "Generalization bounds for learning the kernel", "author": ["Y. Ying", "C. Campbell"], "venue": "Conference on Computational Learning Theory (COLT),", "citeRegEx": "Ying and Campbell,? \\Q2009\\E", "shortCiteRegEx": "Ying and Campbell", "year": 2009}], "referenceMentions": [{"referenceID": 7, "context": "A few notable examples include exploiting class labels to find a Mahalanobis distance metric that maximizes the distance between dissimilar observations while minimizing distances between similar ones to improve classification quality (Weinberger & Saul, 2009; Davis et al., 2007), \u2217email: verman@janelia.", "startOffset": 235, "endOffset": 280}, {"referenceID": 15, "context": "Some popular algorithms that optimize for such distance-based objectives include Mahalanobis Metric for Clustering (MMC) by Xing et al. (2002) and Information Theoretic Metric Learning (ITML) by Davis et al.", "startOffset": 124, "endOffset": 143}, {"referenceID": 7, "context": "(2002) and Information Theoretic Metric Learning (ITML) by Davis et al. (2007). Instead of using distance comparisons as a proxy, however, one can also optimize for a specific prediction task directly.", "startOffset": 59, "endOffset": 79}, {"referenceID": 7, "context": "(2002) and Information Theoretic Metric Learning (ITML) by Davis et al. (2007). Instead of using distance comparisons as a proxy, however, one can also optimize for a specific prediction task directly. The second generic framework, the classifier-based metric learning framework, explicitly incorporates the hypothesis associated with the prediction task of interest to learn effective distance metrics. A few interesting examples in this regime include the work by McFee & Lanckriet (2010) that finds metrics that improve ranking quality in information retrieval tasks, and the work by Shaw et al.", "startOffset": 59, "endOffset": 491}, {"referenceID": 7, "context": "(2002) and Information Theoretic Metric Learning (ITML) by Davis et al. (2007). Instead of using distance comparisons as a proxy, however, one can also optimize for a specific prediction task directly. The second generic framework, the classifier-based metric learning framework, explicitly incorporates the hypothesis associated with the prediction task of interest to learn effective distance metrics. A few interesting examples in this regime include the work by McFee & Lanckriet (2010) that finds metrics that improve ranking quality in information retrieval tasks, and the work by Shaw et al. (2011) that learns metrics that help predict connectivity structure in networked data.", "startOffset": 59, "endOffset": 606}, {"referenceID": 16, "context": "Xing et al. (2002) optimize an efficiently computable variant of this criterion, in which they look for a metric that keeps the total pairwise distance amongst the observations from the same class less than a constant while maximizing the total pairwise distance amongst the observations from opposite classes.", "startOffset": 0, "endOffset": 19}, {"referenceID": 7, "context": "The variant proposed by Davis et al. (2007) explicitly includes the upper and lower limits with an added regularization on the learned M to be close to a pre-specified metric of interest M0.", "startOffset": 24, "endOffset": 44}, {"referenceID": 14, "context": "Shaw et al. (2011) also follow this principle and explicitly include network topology constraints to learn a weighting metric that can better predict the connectivity structure in social and web networks.", "startOffset": 0, "endOffset": 19}, {"referenceID": 9, "context": "Recall that for any smooth target function f\u2217, a two layer feed-forward neural network (with appropriate number of hidden units and connection weights) can approximate f\u2217 arbitrarily well (Hornik et al., 1989), so this class is flexible enough to incorporate most reasonable target hypotheses.", "startOffset": 188, "endOffset": 209}, {"referenceID": 12, "context": "This partly explains the observed empirical success of various types of norm-regularized optimization criteria for finding the optimal weighting metric (Lim et al., 2013; Law et al., 2014).", "startOffset": 152, "endOffset": 188}, {"referenceID": 11, "context": "This partly explains the observed empirical success of various types of norm-regularized optimization criteria for finding the optimal weighting metric (Lim et al., 2013; Law et al., 2014).", "startOffset": 152, "endOffset": 188}, {"referenceID": 7, "context": "We select two popular metric learning algorithms, LMNN by Weinberger & Saul (2009) and ITML by Davis et al. (2007), that are designed to find metrics that improve nearest-neighbor classification quality.", "startOffset": 95, "endOffset": 115}, {"referenceID": 9, "context": "Jin et al. (2009), for instance, analyzed the generalization ability of regularized, convex-loss optimization criteria for pairwise distances via an algorithmic stability analysis.", "startOffset": 0, "endOffset": 18}, {"referenceID": 9, "context": "Jin et al. (2009), for instance, analyzed the generalization ability of regularized, convex-loss optimization criteria for pairwise distances via an algorithmic stability analysis. They derive an interesting sample complexity result that is sublinear in \u221a D for datasets of representation dimension D. They discuss that the sample complexity can potentially be independent of D, but do not characterize specific instances or classes of problems where this may be possible. Likewise, recent work by Bellet & Habrard (2012) uses algorithmic robustness to analyze the generalization ability for pairwise- and triplet-based distance metric learning.", "startOffset": 0, "endOffset": 522}, {"referenceID": 9, "context": "Jin et al. (2009), for instance, analyzed the generalization ability of regularized, convex-loss optimization criteria for pairwise distances via an algorithmic stability analysis. They derive an interesting sample complexity result that is sublinear in \u221a D for datasets of representation dimension D. They discuss that the sample complexity can potentially be independent of D, but do not characterize specific instances or classes of problems where this may be possible. Likewise, recent work by Bellet & Habrard (2012) uses algorithmic robustness to analyze the generalization ability for pairwise- and triplet-based distance metric learning. Their analysis relies on the existence of a partition of the input space, such that in each cell of the partition, the training loss and test loss does not deviate much (robustness criteria). Note that their sample complexity bound scales with the partition size, which in general can be exponential in the representation dimension. Perhaps the works most similar to our approach are the sample complexity analyses by Bian & Tao (2011) and Cao et al.", "startOffset": 0, "endOffset": 1082}, {"referenceID": 5, "context": "Perhaps the works most similar to our approach are the sample complexity analyses by Bian & Tao (2011) and Cao et al. (2013). Bian & Tao (2011) analyze the consistency of the ERM criterion for metric learning.", "startOffset": 107, "endOffset": 125}, {"referenceID": 5, "context": "Perhaps the works most similar to our approach are the sample complexity analyses by Bian & Tao (2011) and Cao et al. (2013). Bian & Tao (2011) analyze the consistency of the ERM criterion for metric learning.", "startOffset": 107, "endOffset": 144}, {"referenceID": 5, "context": "Perhaps the works most similar to our approach are the sample complexity analyses by Bian & Tao (2011) and Cao et al. (2013). Bian & Tao (2011) analyze the consistency of the ERM criterion for metric learning. They show a O(m\u22121/2) rate of convergence for the ERM with m samples to the expected risk for thresholds on bounded convex losses for distance-based metric learning. Our upper-bound in Lemma 1 generalizes this result by considering arbitrary (possibly non-convex) distance-based Lipschitz losses and explicitly shows the dependence on the representation dimensionD. Cao et al. (2013) provide an alternate analysis based on norm regularization of the weighting metric for distance-based metric learning.", "startOffset": 107, "endOffset": 593}, {"referenceID": 6, "context": "The typical focus in kernel learning is to analyze the generalization ability of the hypothesis class of linear separators in general Hilbert spaces (Ying & Campbell, 2009; Cortes et al., 2010).", "startOffset": 149, "endOffset": 193}, {"referenceID": 12, "context": "Our empirical results show that such regularization not only helps in designing new metric learning algorithms (Lim et al., 2013; Law et al., 2014), but can even benefit existing metric learning algorithms in high-noise regimes.", "startOffset": 111, "endOffset": 147}, {"referenceID": 11, "context": "Our empirical results show that such regularization not only helps in designing new metric learning algorithms (Lim et al., 2013; Law et al., 2014), but can even benefit existing metric learning algorithms in high-noise regimes.", "startOffset": 111, "endOffset": 147}, {"referenceID": 15, "context": "2 of Vershynin (2010)), we know that |N /D| \u2264 ( 1 + 2D )D .", "startOffset": 5, "endOffset": 22}, {"referenceID": 15, "context": "2 of Vershynin (2010)), we know that |P | \u2265 ( 1 2 )D .", "startOffset": 5, "endOffset": 22}], "year": 2015, "abstractText": "Metric learning seeks a transformation of the feature space that enhances prediction quality for the given task at hand. In this work we provide PAC-style sample complexity rates for supervised metric learning. We give matching lowerand upper-bounds showing that the sample complexity scales with the representation dimension when no assumptions are made about the underlying data distribution. However, by leveraging the structure of the data distribution, we show that one can achieve rates that are fine-tuned to a specific notion of intrinsic complexity for a given dataset. Our analysis reveals that augmenting the metric learning optimization criterion with a simple norm-based regularization can help adapt to a dataset\u2019s intrinsic complexity, yielding better generalization. Experiments on benchmark datasets validate our analysis and show that regularizing the metric can help discern the signal even when the data contains high amounts of noise.", "creator": "LaTeX with hyperref package"}}}