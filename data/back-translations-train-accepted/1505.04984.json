{"id": "1505.04984", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-May-2015", "title": "Risk and Regret of Hierarchical Bayesian Learners", "abstract": "Common statistical practice has shown that the full power of Bayesian methods is not realized until hierarchical priors are used, as these allow for greater \"robustness\" and the ability to \"share statistical strength.\" Yet it is an ongoing challenge to provide a learning-theoretically sound formalism of such notions that: offers practical guidance concerning when and how best to utilize hierarchical models; provides insights into what makes for a good hierarchical prior; and, when the form of the prior has been chosen, can guide the choice of hyperparameter settings. We present a set of analytical tools for understanding hierarchical priors in both the online and batch learning settings. We provide regret bounds under log-loss, which show how certain hierarchical models compare, in retrospect, to the best single model in the model class. We also show how to convert a Bayesian log-loss regret bound into a Bayesian risk bound for any bounded loss, a result which may be of independent interest. Risk and regret bounds for Student's $t$ and hierarchical Gaussian priors allow us to formalize the concepts of \"robustness\" and \"sharing statistical strength.\" Priors for feature selection are investigated as well. Our results suggest that the learning-theoretic benefits of using hierarchical priors can often come at little cost on practical problems.", "histories": [["v1", "Tue, 19 May 2015 13:12:41 GMT  (190kb,D)", "http://arxiv.org/abs/1505.04984v1", "In Proceedings of the 32nd International Conference on Machine Learning (ICML 2015)"]], "COMMENTS": "In Proceedings of the 32nd International Conference on Machine Learning (ICML 2015)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["jonathan h huggins", "joshua b tenenbaum"], "accepted": true, "id": "1505.04984"}, "pdf": {"name": "1505.04984.pdf", "metadata": {"source": "META", "title": "Risk and Regret of Hierarchical Bayesian Learners", "authors": ["Jonathan H. Huggins", "Joshua B. Tenenbaum"], "emails": ["JHUGGINS@MIT.EDU", "JBT@MIT.EDU"], "sections": [{"heading": "1. Introduction", "text": "This year, it has reached the point where it is a reactionary U-turn, capable of retaliating."}, {"heading": "2. Bayesian Online Learning", "text": "In this paper, we assume that the prediction is made on the basis of a generalized linear model (GLM models and prices that we then analyze include a number of models that are used in the real world for scientific applications (Gelman & Hill, 2006; Gelman et al., 2013). GLMs provide significant modeling flexibility, and the class of GLM models and prices that we then analyze include a number of models that are used in the real world for scientific applications (Gelman et al., 2013). GLMs are the logistical regression that applies to Bayxt."}, {"heading": "2.1. Beyond GLMs", "text": "Theorem 2.2 results from a more general result, Theorem 2.4, which enables the probability of the form p (y | x, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no"}, {"heading": "3. Risk Bounds", "text": "It is also desirable to have risk limits in the task, since risk limits do not provide generalization guarantees for unseen data. We are now developing a link between remorse and risk limits via a PAC-Bayesian analysis (McAllester, 2003; Audibert & Bousquet, 2007; Catoni, 2007) such limits also have the advantage that they can be applied to any limited loss (e.g., the 0-1 loss for binary classification), which may be more task-relevant than the log loss. In the batch setting, the data ZT is received all at once by the learners and assumed to be distributed. i.e., depending on the distribution D over X \u00d7 Y: (xt, yt) i.e. D D, t = 1, T. Let \"be a bounded loss function over Y and an element of Y as arguments."}, {"heading": "4. Applications", "text": "We are now using Theorem 2.2 to analyze hierarchical priorities in terms of robustness, shared statistical strength, and feature selection."}, {"heading": "4.1. Hierarchical Priors for Robustness", "text": "In this section, we answer questions Q2-Q4 on how hierarchical priorities for robust conclusions show how, with a correct selection of hyperparameters, a hierarchical approach can lead to increased robustness compared to a flat approach. Specifically, we are analyzing a canonical application of a hierarchical regret - to capture greater uncertainty in the value of a parameter by making a hyperprediction of the variance of the Gaussian approach to this parameter (Berger, 1985; Gelman et al., 2013): \"However, there is greater uncertainty in the value of a parameter by applying a hyperprediction to the variance of the Gaussian approach.\" (Berger, 1985; Gelman et al., 2013): \"However, there is greater uncertainty about the value of such a course of action by applying a hyperprediction to the variance of the Gaussian approach.\""}, {"heading": "4.2. Hierarchical Priors for Sharing Statistical Strength", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1. BACKGROUND", "text": "Next, we look at hierarchical priorities that allow the sharing of statistical strength and provide answers to Q1 and Q2: We set out some conditions under which the sharing of statistical strength can be achieved and others in which non-hierarchical prioritization is preferable.3 In machine learning literature, the goal of \"sharing statistical strength\" through multitask learning (MTL) and \"learning tolearn\" (LTL) has been formalized.3 A series of theoretical studies of MTL and LTL have been conducted, starting with a series of papers by Baxter (cf. Baxter, 1997; 2000).Generally, such MTL and LTL frameworks contain two or more learning problems that are in some way related to each other. Learning characteristics are examined as the number of tasks and / or the number of examples from each task is increased. Baxter (2000) and Ben-David & Schuller (2003) provide example limits on complexity based on classical ideas from evolutionary theory and evolutionary theory."}, {"heading": "4.2.2. SEQUENTIAL OBSERVATIONS FROM MULTIPLE SOURCES", "text": "The sequential observation setting is relevant to the image classification example given in the introduction, in which there are many observations from some data sources and only a small number of observations from numerous other data sources. In order to model this situation, in step t an input xt from the source zt is observed, where the simplicity of the results applies to Gaussian Priors, although the extension of the multivariate t distribution of the Priors is simple. (1,., K). The learner predicts that yt corresponds to the disadvantage of the procedure (zt) Zt \u2212 1. An equivalent formula is that the Bayesian learner xt = (0,., x (k) t,.). (if zt = k) at any time, he receives yt. Instead of the use of independent Gaussian Priors at level (1),...,."}, {"heading": "4.3. Hierarchical Priors for Feature Selection", "text": "One shortcoming of the methods studied so far is the lack of dependence on the property of space that favours the generalisation of generalisation. Thus, for example, the Gaussian Method, developed on the basis of the Gaussian Method, is still unable to apply the Gaussian Method if the Gaussian Method is not able to apply the Gaussian Method. (For example, the Gaussian Method is still of great general interest). (Seeger et al., 2008) However, methods that are applicable to high-dimensional problems but for which n T are nonetheless of great general interest. (For example, the Gaussian Method is dependent on the introduction of the property vector n 5000, whereas most object classes have less than 200 training examples. (In high-dimensional problems, it is desirable to use function selection or economical methods in order to reduce the effective dimension of the problem, with the aim of generalising and increasing it)."}, {"heading": "5. Conclusion", "text": "In Section 4, we first used our main result, Theorem 2.2, to understand and quantify three specific hierarchical predictions that are widely used in practice, especially in combination with a logistical or Gaussian regression probability. In fact, these predictive combinations have often been used with considerable success, even in situations where they are known as rather bad models for the mechanism of generating data. Our analysis provides an explanation for this success. The predictions we analyzed are representative of the variety of ways hierarchical models are used: displaying uncertainty in hyperparameters, linking related observation groups, and creating more complicated distributions from simpler ones. Therefore, our results answer questions Q1-Q4 in some important cases and illustrate a learning theoretical analysis technique that can be applied to other hierarchical models."}, {"heading": "Acknowledgments", "text": "Thanks to Peter Gru \ufffd nwald, Sham Kakade, Peter Krafft and Daniel Roy for helpful discussions and comments. Thanks also to the anonymous reviewers whose constructive comments improved the presentation of the results. JHH was supported by the US government under FA9550-11-C0028 and awarded by the DoD, Air Force Office of Scientific Research, National Defense Science and Engineering Graduate (NDSEG) Fellowship, 32 CFR 168a."}, {"heading": "A. Regret Bounds for Non-GLM Likelihoods", "text": "\u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2"}, {"heading": "A.1. Application to Multi-class Logistic Regression", "text": "For multi-stage logistic regression (MLR) y-value (1,..) K-value is one of the K-classes, the parameters are \"p\" = \"p\" (k) Kk = 1, and the probability is \"p\" (y) = \"exp\" (y) \u00b7 x) \u2211 Kk = 1 \"exp\" (k) \u00b7 x. \"(A.4) To apply Theorem 2.4, we need the following result: sentence A.1. Assumption (A1\") applies to the probability MLR with c = 1 / 2.Proof. First note thatfy (z) = \u2212 zy + ln \u00b2 K = 1 \"zi,\" (A.5) where zi = \"x,\" and thus the Hessian of \"fy\" (z) is independent of y: f \"y\" y \"(z) = 1 (k) = 1\" zi. \""}, {"heading": "B. Proof of Theorem 3.2", "text": "Since pT (\u03b8) = p (Y | X, \u03b8) p0 (\u03b8) p (Y | X), KL (PT | | P0) = EPT [ln pT (\u03b8) p0 (\u03b8)] = EPT [ln p (Y | X, \u03b8) p (Y | X)] = LBayes (ZT) \u2212 LPT (ZT). (B.1) The combination of (2) and (B.1) with Theorem 3.1 implies that with probability 1 \u2212 \u03b4, for all \u03b8, | L (PT) \u2212 L (PT) \u2212 L (PT, ZT)."}, {"heading": "C. KL Divergence Derivations", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C.1. Multivariate Gaussians", "text": "Leave Tue = n (\u00b5i), i = \u2212 \u2212 \u2212 \u2212 \u2212 n, where dim (\u00b5i) = n (n). ThenKL (D1 | | D2) = 12 ED1 (n) = 12 (n). \u2212 n (x \u2212 \u00b51). \u2212 11 (x \u2212 \u00b51). (x \u2212 1). (x \u2212 1). (x \u2212 2). (x (x \u2212 2). (x \u2212 2). (x \u2212 2). (x \u2212 n). (x \u2212 11 (x \u2212 1). (x \u2212 1). (x). (x). (x). (x). (x). (x). (x). (x). (x). (x). (x). (x). (x)."}, {"heading": "C.3. Gaussian and Laplace", "text": "Allow D1 = N (\u00b5, \u03c32) and D2 = Round (\u03b2). ThenKL (D1 | | D2) = ln (2\u03b2) + 1\u03b2 ED1 [| x |] \u2212 1 2 ln (2\u03c0e\u03c32) = ln (2\u03b2) + 12\u03b2 [\u00b5Erf (\u00b5 \u221a 2 \u03c3) + 2 \u221a 2 \u03c3 exp {\u2212 \u00b5 2 2\u03c32}] \u2212 1 2 ln (2\u03c0e\u03c32) \u2264 1 2 ln 2\u03b22 \u03c32 + 1 2\u03b2 [| \u00b5 | \u221a 1 \u2212 exp {\u2212 2\u00b5 2\u03c0\u03c32} + 2 \u221a 2 \u0445 \u03c0 exp {\u2212 \u00b5 22\u03c32}] \u2212 12 ln (\u03c0e)."}, {"heading": "D. Proof of Theorem 4.1", "text": "With P0 = T\u03bd (0, \u03c32I) we have (appendix C.2) KL (Q\u03b8, \u03c6 | | P0) \u2264 ln, n + n 2 ln \u03c32 \u03c62 \u2212 n 2 ln 2e + n (\u03bd + n) 2\u03bd \u03c62 \u03c32 + \u03bd 2 ln (1 + 1\u03bd\u03c32), where n = 2 ln / 2 (\u03bd + n2) n / 2 if n is even (\u03bd + 1) 1 / 2\u03bd (n \u2212 1) / 2 (\u03bd2) 1 / 2 (\u03bd + n2) (n \u2212 1) / 2 (n \u2212 1) / 2 (n \u2212 2) (n \u2212 1) / 2 if it is odd."}, {"heading": "E. More on Hierarchical Priors for Sharing Statistical Strength", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "E.1. Multiple Simultaneous Observations", "text": "The Bayesian learner receives K-input output pairs (x (k) t, y (k) t) t, Kk = 1 in each time step. Each output is predicted with a separate weight vector \u03b8 (k), so that the k-th probability p (y), p (k) \u00b7 x), k = 1,., K. Write Z (k), {(x) t, y (k) t, p (k) t, p (1),., K), k (K), k (k), k (K), place a prediction on the mean of the K-priors. For each dimension j = 1,., n, let\u00b5j | 20, N (0) (E.1), k) j, j (k) j, j."}, {"heading": "E.2. Two-level Prior", "text": "In this section, in the case of sequential observations, we derive the limits for the two-step procedure. Remember that the previous procedure n (0, \u03c320I) (E.6) p (s) p (\u03b2, \u03c321I) s = 1,.., S (E.7) p (k) p (\u00b5 (sk), \u03c322I) k = 1,.., K (E.8) p (s) p (1: S) p (0, \u0445\u00b5), (E.9) p (where) p (p) p) p (2 1I) p (E.10) p (1: S) i and p (1: K) i and p (Chop) p (\u00b5i) p (0, p) p (2) p (2) p (2) p (2) p (2) p (2) p (2) p (p) p (2) p) p (p)."}, {"heading": "E.3. Proof of Theorem E.1", "text": "First take n = 1, which later generalizes to arbitrary n. Select QTB (1: K), \u03c6 = N (2001: K), \u03c32I) and note that | TB (1: K), \u03c6 (2: K) = \u03c32K (2: K) and \u04452 (1: K) = 12K (2: K) + (1: K) > TB (1: K) = 12K (2: K) = 12K (2: K) = 12K (2: K) + K (2: K) 2K (2: K) 2K (2: K), 2K (2: K) 2K (2: K), K (2: K) 2K (2: K), K (2: K) 2K (2: K), 2K (2: K)."}, {"heading": "E.4. Proof of Theorem 4.2", "text": "The proof is similar to that for theorem E.1. However, use separate variances for each source: QTB (1: K), \u03c6 = QTB (k), \u03c6k = K (1: K). The error term used in theorem 2.2 from the Taylor expansion is: K (k) c2, soLBayes (Z) \u2264 K (K) = 1 LD (k) (K) + K (k) c2k 2 + n 2 ln 2 ln 2 ln 2K2 k 2 k \u2212 nK 2n (2 \u2212 20) 2\u03c32\u03b32 k k + 1 2\u03b32 k k = 1 (k)."}, {"heading": "F. More on Feature Selection", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "F.1. The Bayesian Lasso", "text": "For average learners of the Bayesian model, we have: Theorem F. 1 (GLM Bayesian Lasso Regret). If \u03b8i \u0445 round (\u03b8i, \u03b2), i = 1,.., n, thenR (Z, \u03b8) \u2264 1 2\u03b2, i min {\u221a 2 2 \u03c0\u03c62 (\u03b8 \u043a i) 2, | \u03b8 \u043a i |} + n2 ln 2T 2c2\u03b24 (\u221a 2n2 + Tcn\u03b22\u03c0 \u2212 \u221a 2n2) 2. (F.1) In the regime of Tc\u03b22 n becomes (approximately) from (F.1) R (Z, \u03b8) \u2264 1 2\u03b2, i min {\u221a 2 \u03c0\u04322 (\u043a i) 2, |. Therefore, we suspect that up to constant factors, regardless of \u03b2 and c., the limit of regret even for sparsely saturated persons lies in the lowest order of resentment. The inequalities used to prove regret are all quite limited, so that we assume that there is a constant backward factor."}, {"heading": "F.2. Proof of Theorem F.1", "text": "Applicable to theorem 2.2 with Q3 (Q3) KL (Q3) + P0 (P0) \u2264 n2 ln2\u03b22\u03c62 \u2212 n 2 ln (\u03c0e) + 1 2\u03b2 (p) 1 \u2212 exp (p) 1 \u2212 2 (p) 2 sover2} + 2 (p) 2 \u03c6 (p) 2 2\u04452)] \u2264 n 2 ln 2\u03b22 (p) + 2 ln (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) 2 (p) (p) 2) (2) (2) (p) (2) (2) (p) 2) (2) (p)."}, {"heading": "F.3. Proof of Theorem 4.3", "text": "Fix some of the following points: If we have something more than 1 sqm. If we have something more than 1 sqm, then we must have more than 1 sqm. If we have more than 1 sqm, then we must have more than 1 sqm. If we have more than 1 sqm, then we must have more than 1 sqm. If we have more than 1 sqm, then we must have more than 1 sqm. If we have more than 1 sqm, then we must have more than 1 sqm."}], "references": [{"title": "Probabilistic Projections of the Total Fertility Rate for All Countries", "author": ["L. Alkema", "A.E. Raftery", "P. Gerland", "S.J. Clark", "F. Pelletier", "T. Buettner", "G.K. Heilig"], "venue": "Demography,", "citeRegEx": "Alkema et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Alkema et al\\.", "year": 2011}, {"title": "Combining PACBayesian and generic chaining bounds", "author": ["Audibert", "J.-Y", "O. Bousquet"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Audibert et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Audibert et al\\.", "year": 2007}, {"title": "On Bayesian Bounds", "author": ["A. Banerjee"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Banerjee,? \\Q2006\\E", "shortCiteRegEx": "Banerjee", "year": 2006}, {"title": "An Analysis of Logistic Models: Exponential Family Connections and Online Performance", "author": ["A. Banerjee"], "venue": "In International Conference on Data Mining, pp", "citeRegEx": "Banerjee,? \\Q2007\\E", "shortCiteRegEx": "Banerjee", "year": 2007}, {"title": "A Bayesian/information theoretic model of learning to learn via multiple task sampling", "author": ["J. Baxter"], "venue": "Machine learning,", "citeRegEx": "Baxter,? \\Q1997\\E", "shortCiteRegEx": "Baxter", "year": 1997}, {"title": "A Model of Inductive Bias Learning", "author": ["J. Baxter"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Baxter,? \\Q2000\\E", "shortCiteRegEx": "Baxter", "year": 2000}, {"title": "Exploiting task relatedness for multiple task learning", "author": ["S. Ben-David", "R. Schuller"], "venue": "In Conference on Learning Theory,", "citeRegEx": "Ben.David and Schuller,? \\Q2003\\E", "shortCiteRegEx": "Ben.David and Schuller", "year": 2003}, {"title": "Statistical Decision Theory and Bayesian Analysis", "author": ["J.O. Berger"], "venue": null, "citeRegEx": "Berger,? \\Q1985\\E", "shortCiteRegEx": "Berger", "year": 1985}, {"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "Bishop,? \\Q2006\\E", "shortCiteRegEx": "Bishop", "year": 2006}, {"title": "PAC-Bayesian Supervised Classification: The Thermodynamics of Statistical Learning, volume 56 of Lecture Notes ", "author": ["O. Catoni"], "venue": "Monograph Series. Institute of Mathematical Statistics,", "citeRegEx": "Catoni,? \\Q2007\\E", "shortCiteRegEx": "Catoni", "year": 2007}, {"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi", "year": 2006}, {"title": "Data Analysis Using Regression and Multilevel/Hierarchical Models", "author": ["A. Gelman", "J. Hill"], "venue": null, "citeRegEx": "Gelman and Hill,? \\Q2006\\E", "shortCiteRegEx": "Gelman and Hill", "year": 2006}, {"title": "Deep Interactions with MRP: Election Turnout and Voting Patterns Among Small Electoral Subgroups", "author": ["Y. Ghitza", "A. Gelman"], "venue": "American Journal of Political Science,", "citeRegEx": "Ghitza and Gelman,? \\Q2013\\E", "shortCiteRegEx": "Ghitza and Gelman", "year": 2013}, {"title": "The Minimum Description Length Principle", "author": ["P.D. Gr\u00fcnwald"], "venue": null, "citeRegEx": "Gr\u00fcnwald,? \\Q2007\\E", "shortCiteRegEx": "Gr\u00fcnwald", "year": 2007}, {"title": "On universal transfer learning", "author": ["M.M. Hassan Mahmud"], "venue": "Theoretical Computer Science,", "citeRegEx": "Mahmud,? \\Q2009\\E", "shortCiteRegEx": "Mahmud", "year": 2009}, {"title": "Transfer Learning using Kolmogorov Complexity: Basic Theory and Empirical Evaluations", "author": ["M.M. Hassan Mahmud", "S.R. Ray"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mahmud and Ray,? \\Q2007\\E", "shortCiteRegEx": "Mahmud and Ray", "year": 2007}, {"title": "Spike and slab variable selection: Frequentist and Bayesian strategies", "author": ["H. Ishwaran", "J.S. Rao"], "venue": "The Annals of Statistics,", "citeRegEx": "Ishwaran and Rao,? \\Q2005\\E", "shortCiteRegEx": "Ishwaran and Rao", "year": 2005}, {"title": "Estimating Relatedness via Data Compression", "author": ["B. Juba"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Juba,? \\Q2006\\E", "shortCiteRegEx": "Juba", "year": 2006}, {"title": "Online Bounds for Bayesian Algorithms", "author": ["S.M. Kakade", "A.Y. Ng"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kakade and Ng,? \\Q2004\\E", "shortCiteRegEx": "Kakade and Ng", "year": 2004}, {"title": "Worst-case bounds for Gaussian process models", "author": ["S.M. Kakade", "M. Seeger", "D.P. Foster"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kakade et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2005}, {"title": "Simplified PAC-Bayesian Margin Bounds", "author": ["D.A. McAllester"], "venue": "In Conference on Learning Theory,", "citeRegEx": "McAllester,? \\Q2003\\E", "shortCiteRegEx": "McAllester", "year": 2003}, {"title": "Big Bayes Stories\u2014 Foreword", "author": ["K.L. Mengersen", "C.P. Robert"], "venue": "Statistical Science,", "citeRegEx": "Mengersen and Robert,? \\Q2014\\E", "shortCiteRegEx": "Mengersen and Robert", "year": 2014}, {"title": "Bayesian variable selection with shrinking and diffusing priors", "author": ["N.N. Narisetty", "X. He"], "venue": "The Annals of Statistics,", "citeRegEx": "Narisetty and He,? \\Q2014\\E", "shortCiteRegEx": "Narisetty and He", "year": 2014}, {"title": "The Bayesian Lasso", "author": ["T. Park", "G. Casella"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Park and Casella,? \\Q2008\\E", "shortCiteRegEx": "Park and Casella", "year": 2008}, {"title": "A PAC-Bayesian bound for Lifelong Learning", "author": ["A. Pentina", "C.H. Lampert"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Pentina and Lampert,? \\Q2014\\E", "shortCiteRegEx": "Pentina and Lampert", "year": 2014}, {"title": "Bayesian probabilistic population projections for all countries", "author": ["A.E. Raftery", "N. Li", "H. \u0160ev\u010d\u0131\u0301kov\u00e1", "P. Gerland", "G.K. Heilig"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Raftery et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Raftery et al\\.", "year": 2012}, {"title": "Bayesian Probabilistic Projections of Life Expectancy for All Countries", "author": ["A.E. Raftery", "J.L. Chunn", "P. Gerland", "H. \u0160ev\u010d\u0131\u0301kov\u00e1"], "venue": "Demography,", "citeRegEx": "Raftery et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Raftery et al\\.", "year": 2013}, {"title": "Learning to share visual appearance for multiclass object detection", "author": ["R. Salakhutdinov", "A. Torralba", "J.B. Tenenbaum"], "venue": "In Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2011}, {"title": "Perfect sampling for Bayesian variable selection in a linear regression model", "author": ["U. Schneider", "J.N. Corcoran"], "venue": "Journal of Statistical Planning and Inference,", "citeRegEx": "Schneider and Corcoran,? \\Q2004\\E", "shortCiteRegEx": "Schneider and Corcoran", "year": 2004}, {"title": "Information Consistency of Nonparametric Gaussian Process Methods", "author": ["M.W. Seeger", "S.M. Kakade", "D.P. Foster"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Seeger et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Seeger et al\\.", "year": 2008}, {"title": "Regression shrinkage and selection via the lasso", "author": ["R. Tibshirani"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "Tibshirani,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani", "year": 1996}, {"title": "Competitive Online Statistics", "author": ["V. Vovk"], "venue": "International Statistical Review,", "citeRegEx": "Vovk,? \\Q2001\\E", "shortCiteRegEx": "Vovk", "year": 2001}], "referenceMentions": [{"referenceID": 7, "context": "the hyperparameters of the prior distribution (Berger, 1985; Bernardo & Smith, 2000; Gelman et al., 2013).", "startOffset": 46, "endOffset": 105}, {"referenceID": 7, "context": "the hyperparameters of the prior distribution (Berger, 1985; Bernardo & Smith, 2000; Gelman et al., 2013). By explicitly modeling the additional uncertainty, there is greater \u201crobustness\u201d to misspecification and unexpected data. The second is that hierarchical models permit the \u201csharing of statistical strength\u201d between related observations or cohorts (Gelman et al., 2013). For example, take the recent \u201cBig Bayes Stories\u201d special issue of the journal Statistical Science, which was comprised of short articles describing successful applications of Bayesian models to a diverse range of problems, including political science, astronomy, and public health (Mengersen & Robert, 2014). Most of the Bayesian models were hierarchical, and the need for robustness and sharing of statistical strength because of limited data were commonly cited reasons by the practitioners for choosing a hierarchical Bayesian approach. Gelman & Hill (2006) and Gelman et al.", "startOffset": 47, "endOffset": 937}, {"referenceID": 7, "context": "the hyperparameters of the prior distribution (Berger, 1985; Bernardo & Smith, 2000; Gelman et al., 2013). By explicitly modeling the additional uncertainty, there is greater \u201crobustness\u201d to misspecification and unexpected data. The second is that hierarchical models permit the \u201csharing of statistical strength\u201d between related observations or cohorts (Gelman et al., 2013). For example, take the recent \u201cBig Bayes Stories\u201d special issue of the journal Statistical Science, which was comprised of short articles describing successful applications of Bayesian models to a diverse range of problems, including political science, astronomy, and public health (Mengersen & Robert, 2014). Most of the Bayesian models were hierarchical, and the need for robustness and sharing of statistical strength because of limited data were commonly cited reasons by the practitioners for choosing a hierarchical Bayesian approach. Gelman & Hill (2006) and Gelman et al. (2013) both contain further examples of problems in which hierarchical modeling is critical to obtaining high-quality inferences.", "startOffset": 47, "endOffset": 962}, {"referenceID": 7, "context": "the hyperparameters of the prior distribution (Berger, 1985; Bernardo & Smith, 2000; Gelman et al., 2013). By explicitly modeling the additional uncertainty, there is greater \u201crobustness\u201d to misspecification and unexpected data. The second is that hierarchical models permit the \u201csharing of statistical strength\u201d between related observations or cohorts (Gelman et al., 2013). For example, take the recent \u201cBig Bayes Stories\u201d special issue of the journal Statistical Science, which was comprised of short articles describing successful applications of Bayesian models to a diverse range of problems, including political science, astronomy, and public health (Mengersen & Robert, 2014). Most of the Bayesian models were hierarchical, and the need for robustness and sharing of statistical strength because of limited data were commonly cited reasons by the practitioners for choosing a hierarchical Bayesian approach. Gelman & Hill (2006) and Gelman et al. (2013) both contain further examples of problems in which hierarchical modeling is critical to obtaining high-quality inferences. Within the machine learning and vision literature, Salakhutdinov et al. (2011) offers an illustrative case study in the benefits and the pitfalls of employing a hierarchical model.", "startOffset": 47, "endOffset": 1164}, {"referenceID": 7, "context": "the hyperparameters of the prior distribution (Berger, 1985; Bernardo & Smith, 2000; Gelman et al., 2013). By explicitly modeling the additional uncertainty, there is greater \u201crobustness\u201d to misspecification and unexpected data. The second is that hierarchical models permit the \u201csharing of statistical strength\u201d between related observations or cohorts (Gelman et al., 2013). For example, take the recent \u201cBig Bayes Stories\u201d special issue of the journal Statistical Science, which was comprised of short articles describing successful applications of Bayesian models to a diverse range of problems, including political science, astronomy, and public health (Mengersen & Robert, 2014). Most of the Bayesian models were hierarchical, and the need for robustness and sharing of statistical strength because of limited data were commonly cited reasons by the practitioners for choosing a hierarchical Bayesian approach. Gelman & Hill (2006) and Gelman et al. (2013) both contain further examples of problems in which hierarchical modeling is critical to obtaining high-quality inferences. Within the machine learning and vision literature, Salakhutdinov et al. (2011) offers an illustrative case study in the benefits and the pitfalls of employing a hierarchical model. The motivation of Salakhutdinov et al. (2011) was that, for image classification tasks, some categories of objects (e.", "startOffset": 47, "endOffset": 1312}, {"referenceID": 7, "context": "the hyperparameters of the prior distribution (Berger, 1985; Bernardo & Smith, 2000; Gelman et al., 2013). By explicitly modeling the additional uncertainty, there is greater \u201crobustness\u201d to misspecification and unexpected data. The second is that hierarchical models permit the \u201csharing of statistical strength\u201d between related observations or cohorts (Gelman et al., 2013). For example, take the recent \u201cBig Bayes Stories\u201d special issue of the journal Statistical Science, which was comprised of short articles describing successful applications of Bayesian models to a diverse range of problems, including political science, astronomy, and public health (Mengersen & Robert, 2014). Most of the Bayesian models were hierarchical, and the need for robustness and sharing of statistical strength because of limited data were commonly cited reasons by the practitioners for choosing a hierarchical Bayesian approach. Gelman & Hill (2006) and Gelman et al. (2013) both contain further examples of problems in which hierarchical modeling is critical to obtaining high-quality inferences. Within the machine learning and vision literature, Salakhutdinov et al. (2011) offers an illustrative case study in the benefits and the pitfalls of employing a hierarchical model. The motivation of Salakhutdinov et al. (2011) was that, for image classification tasks, some categories of objects (e.g., \u201ccar\u201d or \u201cdog\u201d) have many labeled positive and negative examples while other, visually related, categories (e.g., \u201cbus\u201d or \u201canteater\u201d) have only a few labeled examples. Fig. 1(right, a) shows the distribution of training examples for the 200 object categories used while Fig. 1(right, b) shows the same distribution, but now objects are grouped with those with similar appearances. In both cases, the distributions are fat-tailed: there are a few categories with many training examples and many categories with a few training examples. It was hypothesized that by using a hierarchical Bayesian model, the classes with large amounts of labeled data could be used to construct better classifiers for the classes with small amounts of labeled data. The model used by Salakhutdinov et al. (2011), which ar X iv :1 50 5.", "startOffset": 47, "endOffset": 2180}, {"referenceID": 27, "context": "Why the different performance characteristics for the two hierarchical models? Why do some categories have improved accuracy while others decreased accuracy? In a post-hoc analysis, Salakhutdinov et al. (2011) note that the \u201cobjects with the largest improvement.", "startOffset": 182, "endOffset": 210}, {"referenceID": 27, "context": "Why the different performance characteristics for the two hierarchical models? Why do some categories have improved accuracy while others decreased accuracy? In a post-hoc analysis, Salakhutdinov et al. (2011) note that the \u201cobjects with the largest improvement...borrow visual appearance from other frequent objects\u201d while \u201cobjects with the largest decrease [such as \u2018umbrella\u2019 and \u2018merchandise\u2019] are abstract, and their visual appearance is very different from other object categories.\u201d The results just described lead to numerous theoretical questions of practical consequence: Q1 Can we formalize why for some object classes there was a beneficial sharing of statistical strength, while for other classes the sharing was detrimental? Q2 Can we understand when a flat model should be preferred to a hierarchical one to avoid unfavorable sharing? Q3 More generally, can we obtain guidance on the best type of prior for the problem at hand? Perhaps a different hierarchical prior would have been better suited to learning the image classifiers. For example, could placing hyperpriors on the variance parameters lead to greater \u201crobustness\u201d for object categories such as \u2018umbrella\u2019 and \u2018merchandise,\u2019 whose visual appearance differs from other object categories? Q4 Once the form of the prior has been chosen, how should hyperparameters be set to maximize learning? The settings of the variance hyperparameters was left unspecified by Salakhutdinov et al. (2011), and it is not clear a priori how they should be set, or how much effect their choice will have on learning.", "startOffset": 182, "endOffset": 1463}, {"referenceID": 27, "context": "Reproduced and reconstructed from Salakhutdinov et al. (2011).", "startOffset": 34, "endOffset": 62}, {"referenceID": 26, "context": "For example, one might instead consider the hierarchical models have been used in political science for analyzing polling and census data to predict election outcomes (Ghitza & Gelman, 2013) and in demography for predicting population growth, life expectancy, and fertility rates (Raftery et al., 2013; 2012; Alkema et al., 2011).", "startOffset": 280, "endOffset": 329}, {"referenceID": 0, "context": "For example, one might instead consider the hierarchical models have been used in political science for analyzing polling and census data to predict election outcomes (Ghitza & Gelman, 2013) and in demography for predicting population growth, life expectancy, and fertility rates (Raftery et al., 2013; 2012; Alkema et al., 2011).", "startOffset": 280, "endOffset": 329}, {"referenceID": 31, "context": "Regret bound for a number of Bayesian models have previously been developed (Vovk, 2001; Kakade & Ng, 2004; Kakade et al., 2005; Banerjee, 2006; 2007; Seeger et al., 2008), with a particular focus on regression and simple priors such as independent Gaussian distributions for each regression coefficient.", "startOffset": 76, "endOffset": 171}, {"referenceID": 19, "context": "Regret bound for a number of Bayesian models have previously been developed (Vovk, 2001; Kakade & Ng, 2004; Kakade et al., 2005; Banerjee, 2006; 2007; Seeger et al., 2008), with a particular focus on regression and simple priors such as independent Gaussian distributions for each regression coefficient.", "startOffset": 76, "endOffset": 171}, {"referenceID": 2, "context": "Regret bound for a number of Bayesian models have previously been developed (Vovk, 2001; Kakade & Ng, 2004; Kakade et al., 2005; Banerjee, 2006; 2007; Seeger et al., 2008), with a particular focus on regression and simple priors such as independent Gaussian distributions for each regression coefficient.", "startOffset": 76, "endOffset": 171}, {"referenceID": 29, "context": "Regret bound for a number of Bayesian models have previously been developed (Vovk, 2001; Kakade & Ng, 2004; Kakade et al., 2005; Banerjee, 2006; 2007; Seeger et al., 2008), with a particular focus on regression and simple priors such as independent Gaussian distributions for each regression coefficient.", "startOffset": 76, "endOffset": 171}, {"referenceID": 4, "context": "Our results, which complement existing work on transfer and multitask learning theory (Baxter, 1997; Ben-David & Schuller, 2003; Pentina & Lampert, 2014), show that when the parameters with small regret for a collection of related tasks are either (a) similar or (b) not unexpected under the prior, then the hierarchical model has a smaller regret bound than assuming the tasks are independent.", "startOffset": 86, "endOffset": 153}, {"referenceID": 2, "context": ", 2005; Banerjee, 2006; 2007; Seeger et al., 2008), with a particular focus on regression and simple priors such as independent Gaussian distributions for each regression coefficient. For a discussion of more general (but asymptotic) Bayesian regret bounds for exponential families and other sufficiently \u201cregular\u201d model classes, see Gr\u00fcnwald (2007, Chapter 8). We follow the approach originally taken in Kakade & Ng (2004), and further explored in Kakade et al.", "startOffset": 8, "endOffset": 424}, {"referenceID": 2, "context": ", 2005; Banerjee, 2006; 2007; Seeger et al., 2008), with a particular focus on regression and simple priors such as independent Gaussian distributions for each regression coefficient. For a discussion of more general (but asymptotic) Bayesian regret bounds for exponential families and other sufficiently \u201cregular\u201d model classes, see Gr\u00fcnwald (2007, Chapter 8). We follow the approach originally taken in Kakade & Ng (2004), and further explored in Kakade et al. (2005), Banerjee (2006), and Seeger et al.", "startOffset": 8, "endOffset": 470}, {"referenceID": 2, "context": ", 2005; Banerjee, 2006; 2007; Seeger et al., 2008), with a particular focus on regression and simple priors such as independent Gaussian distributions for each regression coefficient. For a discussion of more general (but asymptotic) Bayesian regret bounds for exponential families and other sufficiently \u201cregular\u201d model classes, see Gr\u00fcnwald (2007, Chapter 8). We follow the approach originally taken in Kakade & Ng (2004), and further explored in Kakade et al. (2005), Banerjee (2006), and Seeger et al.", "startOffset": 8, "endOffset": 487}, {"referenceID": 2, "context": ", 2005; Banerjee, 2006; 2007; Seeger et al., 2008), with a particular focus on regression and simple priors such as independent Gaussian distributions for each regression coefficient. For a discussion of more general (but asymptotic) Bayesian regret bounds for exponential families and other sufficiently \u201cregular\u201d model classes, see Gr\u00fcnwald (2007, Chapter 8). We follow the approach originally taken in Kakade & Ng (2004), and further explored in Kakade et al. (2005), Banerjee (2006), and Seeger et al. (2008), which applies to a large class of Bayesian generalized linear models (GLMs).", "startOffset": 8, "endOffset": 513}, {"referenceID": 19, "context": "Our approach to bounding LBayes(ZT ) follows that of previous work on Bayesian GLM regret bounds with logloss (Kakade & Ng, 2004; Kakade et al., 2005; Seeger et al., 2008), relying on the following well-known result: Proposition 2.", "startOffset": 110, "endOffset": 171}, {"referenceID": 29, "context": "Our approach to bounding LBayes(ZT ) follows that of previous work on Bayesian GLM regret bounds with logloss (Kakade & Ng, 2004; Kakade et al., 2005; Seeger et al., 2008), relying on the following well-known result: Proposition 2.", "startOffset": 110, "endOffset": 171}, {"referenceID": 17, "context": "Our approach to bounding LBayes(ZT ) follows that of previous work on Bayesian GLM regret bounds with logloss (Kakade & Ng, 2004; Kakade et al., 2005; Seeger et al., 2008), relying on the following well-known result: Proposition 2.1 (Kakade & Ng (2004); Banerjee (2006)).", "startOffset": 130, "endOffset": 253}, {"referenceID": 2, "context": "1 (Kakade & Ng (2004); Banerjee (2006)).", "startOffset": 23, "endOffset": 39}, {"referenceID": 20, "context": "We now develop a connection between regret and risk bounds via a PAC-Bayesian analysis (McAllester, 2003; Audibert & Bousquet, 2007; Catoni, 2007).", "startOffset": 87, "endOffset": 146}, {"referenceID": 9, "context": "We now develop a connection between regret and risk bounds via a PAC-Bayesian analysis (McAllester, 2003; Audibert & Bousquet, 2007; Catoni, 2007).", "startOffset": 87, "endOffset": 146}, {"referenceID": 9, "context": "We now develop a connection between regret and risk bounds via a PAC-Bayesian analysis (McAllester, 2003; Audibert & Bousquet, 2007; Catoni, 2007). Such bounds also have the benefit of applying to any bounded loss (e.g., the 0-1 loss for binary classification), which may be more task-relevant than the log-loss. In the batch setting, the data ZT are received all at once by the learner and are assumed to be distributed i.i.d. according to some distribution D over X \u00d7 Y: (xt, yt) i.i.d. \u223c D, t = 1, . . . , T . Let ` be a bounded loss function taking a probability distribution over Y and an element of Y as arguments. Without loss of generality assume ` \u2208 [0, 1]. Writing `\u03b8(x, y) , `(p(\u00b7 |x,\u03b8), y), for any distribution Q over \u0398, let L(Q) , E(x,y)\u223cDE\u03b8\u223cQ[`\u03b8(x, y)] L\u0302(Q,ZT ) , T\u22121 \u2211T t=1 E\u03b8\u223cQ[`\u03b8(xt, yt)] be, respectively, the expected and empirical losses under Q. PAC-Bayesian analyses consider the risk of the Gibbs predictor for the distribution Q (i.e., sample \u03b8 \u223c Q, predict with p(\u00b7 |x,\u03b8)), not the model average over Q (i.e., predict with \u222b p(\u00b7 |x,\u03b8)Q(d\u03b8)). A typical bound (specialized to the Bayesian setting) is the following (here pT (\u03b8) , p(\u03b8 |ZT )): Theorem 3.1 (Audibert & Bousquet (2007)).", "startOffset": 133, "endOffset": 1207}, {"referenceID": 7, "context": "Specifically, we analyze a canonical use of a hierarchical prior \u2014 to capture greater uncertainty in the value of a parameter by placing a hyperprior on the variance of the Gaussian prior on that parameter (Berger, 1985; Bishop, 2006; Gelman et al., 2013): \u03c3 0 |\u03b1, \u03b2 \u223c \u0393\u22121(\u03b1, \u03b2) and \u03b8i |\u03bc0, \u03c3 0 \u223c N(\u03bc0, \u03c3 0), where \u0393\u22121(\u03b1, \u03b2) is the inverse gamma distribution with shape \u03b1 and scale \u03b2.", "startOffset": 206, "endOffset": 255}, {"referenceID": 8, "context": "Specifically, we analyze a canonical use of a hierarchical prior \u2014 to capture greater uncertainty in the value of a parameter by placing a hyperprior on the variance of the Gaussian prior on that parameter (Berger, 1985; Bishop, 2006; Gelman et al., 2013): \u03c3 0 |\u03b1, \u03b2 \u223c \u0393\u22121(\u03b1, \u03b2) and \u03b8i |\u03bc0, \u03c3 0 \u223c N(\u03bc0, \u03c3 0), where \u0393\u22121(\u03b1, \u03b2) is the inverse gamma distribution with shape \u03b1 and scale \u03b2.", "startOffset": 206, "endOffset": 255}, {"referenceID": 4, "context": "A number of theoretical investigations of MTL and LTL haven been carried out, beginning with a series of papers by Baxter (cf. Baxter, 1997; 2000). Generically, such MTL and LTL frameworks involve two or more learning problems that are related to each other in some manner. The learning properties are investigated as the number of tasks and/or the number of examples from each task is increased. Baxter (2000) and Ben-David & Schuller (2003) give sample complexity bounds based on classical ideas from statistical and PAC learning theory.", "startOffset": 115, "endOffset": 411}, {"referenceID": 4, "context": "A number of theoretical investigations of MTL and LTL haven been carried out, beginning with a series of papers by Baxter (cf. Baxter, 1997; 2000). Generically, such MTL and LTL frameworks involve two or more learning problems that are related to each other in some manner. The learning properties are investigated as the number of tasks and/or the number of examples from each task is increased. Baxter (2000) and Ben-David & Schuller (2003) give sample complexity bounds based on classical ideas from statistical and PAC learning theory.", "startOffset": 115, "endOffset": 443}, {"referenceID": 4, "context": "A number of theoretical investigations of MTL and LTL haven been carried out, beginning with a series of papers by Baxter (cf. Baxter, 1997; 2000). Generically, such MTL and LTL frameworks involve two or more learning problems that are related to each other in some manner. The learning properties are investigated as the number of tasks and/or the number of examples from each task is increased. Baxter (2000) and Ben-David & Schuller (2003) give sample complexity bounds based on classical ideas from statistical and PAC learning theory. Baxter (1997) examines the asymptotic learning properties of hierarchical Bayesian models.", "startOffset": 115, "endOffset": 554}, {"referenceID": 4, "context": "A number of theoretical investigations of MTL and LTL haven been carried out, beginning with a series of papers by Baxter (cf. Baxter, 1997; 2000). Generically, such MTL and LTL frameworks involve two or more learning problems that are related to each other in some manner. The learning properties are investigated as the number of tasks and/or the number of examples from each task is increased. Baxter (2000) and Ben-David & Schuller (2003) give sample complexity bounds based on classical ideas from statistical and PAC learning theory. Baxter (1997) examines the asymptotic learning properties of hierarchical Bayesian models. Pentina & Lampert (2014) take a PAC-Bayesian approach while Hassan Mahmud & Ray (2007); Hassan Mahmud (2009), and Juba (2006) develop notions of task-relatedness from an (algorithmic) information-theoretic perspective.", "startOffset": 115, "endOffset": 656}, {"referenceID": 4, "context": "A number of theoretical investigations of MTL and LTL haven been carried out, beginning with a series of papers by Baxter (cf. Baxter, 1997; 2000). Generically, such MTL and LTL frameworks involve two or more learning problems that are related to each other in some manner. The learning properties are investigated as the number of tasks and/or the number of examples from each task is increased. Baxter (2000) and Ben-David & Schuller (2003) give sample complexity bounds based on classical ideas from statistical and PAC learning theory. Baxter (1997) examines the asymptotic learning properties of hierarchical Bayesian models. Pentina & Lampert (2014) take a PAC-Bayesian approach while Hassan Mahmud & Ray (2007); Hassan Mahmud (2009), and Juba (2006) develop notions of task-relatedness from an (algorithmic) information-theoretic perspective.", "startOffset": 115, "endOffset": 718}, {"referenceID": 4, "context": "A number of theoretical investigations of MTL and LTL haven been carried out, beginning with a series of papers by Baxter (cf. Baxter, 1997; 2000). Generically, such MTL and LTL frameworks involve two or more learning problems that are related to each other in some manner. The learning properties are investigated as the number of tasks and/or the number of examples from each task is increased. Baxter (2000) and Ben-David & Schuller (2003) give sample complexity bounds based on classical ideas from statistical and PAC learning theory. Baxter (1997) examines the asymptotic learning properties of hierarchical Bayesian models. Pentina & Lampert (2014) take a PAC-Bayesian approach while Hassan Mahmud & Ray (2007); Hassan Mahmud (2009), and Juba (2006) develop notions of task-relatedness from an (algorithmic) information-theoretic perspective.", "startOffset": 115, "endOffset": 740}, {"referenceID": 4, "context": "A number of theoretical investigations of MTL and LTL haven been carried out, beginning with a series of papers by Baxter (cf. Baxter, 1997; 2000). Generically, such MTL and LTL frameworks involve two or more learning problems that are related to each other in some manner. The learning properties are investigated as the number of tasks and/or the number of examples from each task is increased. Baxter (2000) and Ben-David & Schuller (2003) give sample complexity bounds based on classical ideas from statistical and PAC learning theory. Baxter (1997) examines the asymptotic learning properties of hierarchical Bayesian models. Pentina & Lampert (2014) take a PAC-Bayesian approach while Hassan Mahmud & Ray (2007); Hassan Mahmud (2009), and Juba (2006) develop notions of task-relatedness from an (algorithmic) information-theoretic perspective.", "startOffset": 115, "endOffset": 757}, {"referenceID": 27, "context": "\u03a3 , s\u03c11K + s (1\u2212 \u03c1)I (9) s , \u03c3 0 + \u03c3 , \u03c1 , \u03c3 0/(\u03c3 2 0 + \u03c3 ), (10) This prior corresponds to the one-level prior in Salakhutdinov et al. (2011). Similar results, which will be discussed qualitatively below, can be obtained for the two-level prior at the cost of a significantly more complicated bound.", "startOffset": 115, "endOffset": 143}, {"referenceID": 27, "context": "This setting is exactly that of the image classification problem of Salakhutdinov et al. (2011). For concreteness, consider a \u201clarge data\u201d task with T (1) n cs2 and a \u201csmall data\u201d task T (2) = 2, so that ln ( 4 3n+T cs n+T (1)cs2 ) \u2248 0 and (12) becomes (approximately)", "startOffset": 68, "endOffset": 96}, {"referenceID": 27, "context": "The regret bound for the two-level prior in Salakhutdinov et al. (2011) is quite similar to that for the one-level prior.", "startOffset": 44, "endOffset": 72}, {"referenceID": 27, "context": "The two-level regret bound well-explains the results of Salakhutdinov et al. (2011). The poor performance on image classes with very different visual appearance from the other classes is unsurprising since the parameter vectors that predict these classes well are going to have large ` distance from the parameter vectors of other object classes.", "startOffset": 56, "endOffset": 84}, {"referenceID": 19, "context": "4 In the infinite-dimensional case, Gaussian processes can be used while still obtaining meaningful regret bounds (Kakade et al., 2005; Seeger et al., 2008).", "startOffset": 114, "endOffset": 156}, {"referenceID": 29, "context": "4 In the infinite-dimensional case, Gaussian processes can be used while still obtaining meaningful regret bounds (Kakade et al., 2005; Seeger et al., 2008).", "startOffset": 114, "endOffset": 156}, {"referenceID": 30, "context": "A popular non-Bayesian approach for inducing sparsity is `1 regularization, such as the lasso for linear regression (Tibshirani, 1996).", "startOffset": 116, "endOffset": 134}, {"referenceID": 2, "context": ", Banerjee (2007). In particular, if p , q for some constant 0 < q < 1, then R Bayes(Z,\u03b8 \u2217) is at most \u2016\u03b8\u2217\u20162 2\u03c32 +m ln n 1\u2212 q + ln 1 q + m 2 ln ( 1 + Tc\u03c3 m ) .", "startOffset": 2, "endOffset": 18}], "year": 2015, "abstractText": "Common statistical practice has shown that the full power of Bayesian methods is not realized until hierarchical priors are used, as these allow for greater \u201crobustness\u201d and the ability to \u201cshare statistical strength.\u201d Yet it is an ongoing challenge to provide a learning-theoretically sound formalism of such notions that: offers practical guidance concerning when and how best to utilize hierarchical models; provides insights into what makes for a good hierarchical prior; and, when the form of the prior has been chosen, can guide the choice of hyperparameter settings. We present a set of analytical tools for understanding hierarchical priors in both the online and batch learning settings. We provide regret bounds under log-loss, which show how certain hierarchical models compare, in retrospect, to the best single model in the model class. We also show how to convert a Bayesian log-loss regret bound into a Bayesian risk bound for any bounded loss, a result which may be of independent interest. Risk and regret bounds for Student\u2019s t and hierarchical Gaussian priors allow us to formalize the concepts of \u201crobustness\u201d and \u201csharing statistical strength.\u201d Priors for feature selection are investigated as well. Our results suggest that the learning-theoretic benefits of using hierarchical priors can often come at little cost on practical problems.", "creator": "LaTeX with hyperref package"}}}