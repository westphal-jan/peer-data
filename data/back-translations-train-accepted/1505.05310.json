{"id": "1505.05310", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-May-2015", "title": "Supervised Learning for Dynamical System Learning", "abstract": "Recently there has been substantial interest in predictive state methods for learning dynamical systems: these algorithms are popular since they often offer a good tradeoff between computational speed and statistical efficiency. Despite their desirable properties, though, predictive state methods can sometimes be difficult to use in practice. E.g., in contrast to the rich literature on supervised learning methods, which allows us to choose from an extensive menu of models and algorithms to suit the prior beliefs we have about properties of the function to be learned, predictive state dynamical system learning methods are comparatively inflexible: it is as if we were restricted to use only linear regression instead of being allowed to choose decision trees, nonparametric regression, or the lasso. To address this problem, we propose a new view of predictive state methods in terms of instrumental variable regression. This view allows us to construct a wide variety of dynamical system learners simply by swapping in different supervised learning methods. We demonstrate the effectiveness of our proposed methods by experimenting with non-linear regression to learn a hidden Markov model, showing that the resulting algorithm outperforms the correctness of this algorithm follows directly from our general analysis.", "histories": [["v1", "Wed, 20 May 2015 10:38:44 GMT  (521kb,D)", "http://arxiv.org/abs/1505.05310v1", null], ["v2", "Wed, 4 Nov 2015 16:16:04 GMT  (530kb,D)", "http://arxiv.org/abs/1505.05310v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["ahmed hefny", "carlton downey", "geoffrey j gordon"], "accepted": true, "id": "1505.05310"}, "pdf": {"name": "1505.05310.pdf", "metadata": {"source": "CRF", "title": "A New View of Predictive State Methods for Dynamical System Learning", "authors": ["Ahmed Hefny", "Carlton Downey", "Geoffrey J. Gordon"], "emails": ["ahefny@cs.cmu.edu", "cmdowney@cs.cmu.edu", "ggordon@cs.cmu.edu"], "sections": [{"heading": null, "text": "Learning Dynamic Systems: These algorithms are popular because they often offer a good trade-off between computational speed and statistical efficiency. However, despite their desirable properties, predictive state methods can sometimes be difficult to apply in practice. In contrast to the rich literature on supervised learning methods, which allows us to choose from a wide range of models and algorithms to conform to previous beliefs about the properties of the function to be learned, predictive state dynamic learning methods are comparatively inflexible: it is as if we were limited to using only linear regression rather than choosing decision trees, non-parametric regression or the lasso. To address this problem, we propose a new view of predictive state methods in terms of instrumental variable regression. This view allows us to construct a wide variety of dynamic system learners simply by sharing their learning methods in different monitored learning methods."}, {"heading": "1 Introduction", "text": "The question we ask ourselves is not only a question of reason, but also a question of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of reason, of"}, {"heading": "2 Instrumental Regression for Dynamical Systems", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3 Related Work", "text": "This work covers predictive state learning algorithms for dynamic systems, including spectral algorithms for Kalman filters [2], hidden Markov models [10, 19] and predictive state representations (PSRs) [6, 3], as well as infinite variants such as the embedding of hidden Markov models (HSE-HMM) and predictive state representations (HSE-PSR). A common aspect in all these models is that they exploit the covariance structure between future and past observation sequences to obtain an impartial observable state representation. In fact, many of these algorithms can be reformulated as two-tiered instrumental regression. Boots and Gordon note the link between the HSE-HMM and instrumental variables that are able to solidify."}, {"heading": "4 Theoretical Analysis", "text": "x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "5 Case Study: Learning A Knowledge Tracing Model", "text": "In this section, we will show that we can learn a hidden Markov model by using the two-step regression system. We will also show that we can change regression methods to gain advantages. Specifically, we will consider a limited data scenario in which we have a conflict between the use of many historical features (by choosing a long history window to reduce noise in our predictions, and the rich features of this window to achieve a linear relationship between history and the future) or the use of fewer historical features (by reducing the number of parameters we must learn from limited data). We will show that we can use non-linear S1 regression models to reduce the number of parameters we must learn, resulting in a better empirical prediction accuracy compared to linear models while maintaining consistency. In this experiment, we will try to predict the performance of students who have learned from an interactive computer-assisted tutor, which is a knowledge modeling question that represents a T (The knowledge modeler)."}, {"heading": "5.1 Data Description", "text": "The data set we used to evaluate the model is a publicly available dataset from DataShop [15] called \"Geometry Area (1996-97).\" These data were generated by students learning introductory geometry and contain experiments by 59 students in 12 knowledge components. As is typical for CCT, we consider a student's attempt to answer a question to be correct if the student entered the correct answer on the first attempt without obtaining any clues from the help system."}, {"heading": "Skill", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Skill", "text": "For a student / KC pair, we form a training sequence. We discard sequences with a length of less than 5, resulting in a total of 325 sequences. We pad each observation sequence with dummy observations at the beginning to deal with the case where the history window extends before the start of the sequence. (This procedure allows us to use more data in our regressions, which is important due to our limited sample size.) Therefore, a history observation used as training input for the S1 regression can occur in one of three states: \"right,\" \"wrong,\" or \"before the start of time.\" However, we limit the regression output to binary (\"right\" or \"wrong\")."}, {"heading": "5.2 Model Description", "text": "It is reasonable to choose the predictable state, which leads to the following statistics:"}, {"heading": "5.3 Evaluation Procedure and Results", "text": "We evaluated three variants of HMM learning using two-step regression. They are summarized in Table 1. We evaluated the models using 1000 random splits of the 325 sequences in 200 training sessions and 125 tests. For each split, we trained each model on the basis of the training sequences. Then, for each test sequence, we filtered through the first 3 observations and then predicted the rest of the sequence, giving the mean square error for each split. Results are shown in Figure 4. Results show that Model 3 exceeds Model 2 in terms of accuracy, which in turn exceeds Model 1. In other words, functional enhancement increases predictive accuracy, but even more gain is achieved with non-linear S1 models that require fewer parameters."}, {"heading": "6 Conclusion", "text": "The proposed framework is based on a two-step regression: In the first stage, we use historical characteristics to train regression models that convert future observation windows into state estimates. In the second stage, we use these state estimates to train a linear model that represents system dynamics. This framework encompasses and provides a unified view of some successful dynamic system learning algorithms. We demonstrated the proposed framework in learning a Hidden Markov model, in which we demonstrated that we can use nonlinear regression to include more historical features in identifying the latent state without exponential increase in the number of parameters. As future work, we would like to apply this framework to other scenarios in which we can use additional techniques such as multiple embedding, sparse learning and transfer learning in level 1."}, {"heading": "A Spectral and HSE Dynamical System Learning as", "text": "RegressionIn this section we give examples for mapping some successful algorithms for learning dynamic systems to our framework."}, {"heading": "A.1 HMM", "text": "(1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (3). (3). (2). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3). (3).). (3). (3).). (3). (3). (3). (3).). (3). (3).). (3). (3).). (3). (3). (3). (3). (3).). (3). (3).).). (3). (3). (3). (3). (3). (3).). (3)."}, {"heading": "A.2 Stationary Kalman Filter", "text": "A Kalman filter results from byst = East \u2212 1 + \u03bdtot = Tst + t \u03bdt \u0445 N (0, s) t \u0445 N (0, o) We consider the case of a stationary filter where \u0442t \u0445 E [sts > t] is independent of t. We select our statistics: t \u2212 H: t \u2212 1\u0445 t = ot: t + F \u2212 1\u0121t = ot: t + FIt can be shown [2, 25] that E [st | ht] = s, h\u0442 \u2212 1h, hhtand it follows that E [s] [t | ht] =, hhtand it follows that E [...] [t | ht] = is instrumental, h\u0442 \u2212 1h, hht = W2htwhere is the advanced observer."}, {"heading": "A.3 HSE-PSR", "text": "We define a class of non-parametric two-step regression models. (1) We define a class of non-parametric two-step regression models. (2) We define a class of non-parametric two-step regression models. (2) We define a class of non-parametric two-step regression models. (3) Let us define three reproducing ranges with reproducing kernels kX, kY, and kZ respectively as reproducing ranges. (3) Let us consider the reproducing ranges with reproducing kernels kX, kY, and kZ respectively as reproducing ranges. (3) Let us assume that the reproducing ranges represent the training data. (4) Specifically, we are the sth \"columns\" in E and H accordingly. It is possible to implement S1 with a non-parametric regression method that takes the form of such a regression (4) for a training data."}, {"heading": "B Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1 Proof of Main Theorem", "text": "In this section we provide proof of theorem 2. We will provide finite sample analysis of the effects of S1 regression, covariance estimation and regularization. The asymptotic statement becomes a natural sequence. We will use the amber inequality matrix given below: Lemma B.1 (amber imquality matrix [12]. Let A be a random square symmetric matrix, and r > 0 and k > 0 are such that it is almost certain E [A] [A] max [A] \u2264 r, \u03bbmax [E [A2] \u2264 v, tr (E [A2])). If A1, A2 > 0 and k > 0, then we are independent copies of A > 0, Pr [E] max [1N]."}, {"heading": "The asymptotic statement assumes \u03b7\u03b4,N \u2192 0 as N \u2192\u221e.", "text": "Write: \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"X\" - \"-\" X \"-\" - \"X\" - \"-\" - \"X\" - \"-\" - \"X -\" - \"-\" X - \"-\" - \"X\" - \"-\" X \"-\" - \"X -\" - \"-\" X - \"-\" - \"-\" X - \"-\" - \"-\" X - \"-\" - \"-\" X - \"-\" - \"-\" X - \"-\" - \"-\" - \"X -\" - \"-\" - \"X -\" - \"-\" - \"-\" X - \"-\" - \"-\" - \"X -\" - \"-\" - \"-\" - \"X\" - \"-\" - \"-\" - \"-\" - \"X\" - \"-\" - \"-\" - \"-\" X \"-\" - \"-\" - \"X\" - \"-\" - \"-\" - \"-\" - \"-\" X \"-\" - \"-\" - \"X\" - \"-\" - \"-\" - \"X\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" X \"-\" - \"-\" - \"-\" - \"X\" - \"-\" - \"-\" - \"X\" - \"-\" - \"-\" - \"-\" - \"X -\" - \"-\" - \"-\" X \"-\" - \"-\" X \"-\" - \"X\" - \"-\" X \"-\" - \"-\" - \"-\" - \"X\" - \"-\" X \"-\" - \"-\" X \"-\" - \"-\" X \"-\" - \"-\" X \"-\" - \"X\" - \"-\" - \"X\" - \"-\" - \"-\" - \"-\" - \"X"}, {"heading": "B.2 Proof of Lemma 5", "text": "For t = 1: Let me be an index set over training instances so that Q-test1 = 1 | I | \u2211 i-I-I-I-I-Q-I-Q-I-I-Q-I-I-I-I-I-Q-I-I-Q-I-Qi-I-Qi-X-I, Nfor t > 1: Let A projection operator onR-I-Y-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I-I"}], "references": [{"title": "Directional tuning profiles of motor cortical cells", "author": ["Bagrat Amirikian", "Apostolos P Georgopulos"], "venue": "Neuroscience research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2000}, {"title": "Spectral Approaches to Learning Predictive Representations", "author": ["Byron Boots"], "venue": "PhD thesis,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "An online spectral learning algorithm for partially observable nonlinear dynamical systems", "author": ["Byron Boots", "Geoffrey Gordon"], "venue": "In Proceedings of the 25th National Conference on Artificial Intelligence (AAAI-2011),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Two-manifold problems with applications to nonlinear system identification", "author": ["Byron Boots", "Geoffrey Gordon"], "venue": "In Proc. 29th Intl. Conf. on Machine Learning (ICML),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Hilbert Space Embeddings of Predictive State Representations", "author": ["Byron Boots", "Arthur Gretton", "Geoffrey J. Gordon"], "venue": "In Proc. 29th Intl. Conf. on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Closing the learning planning loop with predictive state representations", "author": ["Byron Boots", "Sajid Siddiqi", "Geoffrey Gordon"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity", "author": ["M Yu Byron", "John P Cunningham", "Gopal Santhanam", "Stephen I Ryu", "Krishna V Shenoy", "Maneesh Sahani"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Knowledge tracing: Modelling the acquisition of procedural knowledge", "author": ["Albert T. Corbett", "John R. Anderson"], "venue": "User Model. User-Adapt. Interact.,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1995}, {"title": "Kernel bayes\u2019 rule: Bayesian inference with positive definite kernels", "author": ["Kenji Fukumizu", "Le Song", "Arthur Gretton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "A spectral algorithm for learning hidden markov models", "author": ["Daniel Hsu", "Sham M. Kakade", "Tong Zhang"], "venue": "In COLT,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2009}, {"title": "Random design analysis of ridge regression", "author": ["Daniel Hsu", "Sham M. Kakade", "Tong Zhang"], "venue": "In COLT 2012 - The 25th Annual Conference on Learning Theory, June", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "Tail inequalities for sums of random matrices that depend on the intrinsic dimension", "author": ["Daniel Hsu", "Sham M Kakade", "Tong Zhang"], "venue": "Electronic Communications in Probability,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "Reduced-rank regression for the multivariate linear model", "author": ["Alan Julian Izenman"], "venue": "Journal of multivariate analysis,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1975}, {"title": "Observable Operator Models for Discrete Stochastic Time Series", "author": ["Herbert Jaeger"], "venue": "Neural Computation,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2000}, {"title": "A data repository for the EDM community: The PSLC DataShop", "author": ["Kenneth R. Koedinger", "R.S.J. Baker", "K. Cunningham", "A. Skogsholm", "B. Leber", "John Stamper"], "venue": "Handbook of Educational Data Mining,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Learning nonlinear dynamic models", "author": ["John Langford", "Ruslan Salakhutdinov", "Tong Zhang"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2009}, {"title": "Time series and system analysis, with applications", "author": ["S.M. Pandit", "S.M. Wu"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1983}, {"title": "Causality: Models, Reasoning, and Inference", "author": ["Judea Pearl"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2000}, {"title": "Reduced-rank hidden Markov models", "author": ["Sajid Siddiqi", "Byron Boots", "Geoffrey J. Gordon"], "venue": "In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS-2010),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Hilbert space embeddings of hidden Markov models", "author": ["L. Song", "B. Boots", "S.M. Siddiqi", "G.J. Gordon", "A.J. Smola"], "venue": "In Proc. 27th Intl. Conf. on Machine Learning (ICML),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Hilbert space embeddings of conditional distributions with applications to dynamical systems", "author": ["Le Song", "Jonathan Huang", "Alexander J. Smola", "Kenji Fukumizu"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2009}, {"title": "Introduction to Econometrics", "author": ["J.H. Stock", "M.W. Watson"], "venue": "Addison- Wesley series in economics. Addison-Wesley,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Direct cortical control of 3d neuroprosthetic devices", "author": ["Dawn M. Taylor", "Stephen I. Helms Tillery", "Andrew B. Schwartz"], "venue": "Science, pages 1829\u20131832,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2002}, {"title": "User-friendly tools for random matrices: An introduction", "author": ["Joel A. Tropp"], "venue": "NIPS Tutorial,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}], "referenceMentions": [{"referenceID": 13, "context": "One of the main tools that algorithm designers use for this purpose is to expand the class of models considered, thereby removing difficult constraints from (1): for example, instead of learning a hidden Markov model (HMM), we can expand the model class to include all observable operator models (OOMs) [14].", "startOffset": 303, "endOffset": 307}, {"referenceID": 17, "context": "Our new view is based on instrumental variable regression [18, 22].", "startOffset": 58, "endOffset": 66}, {"referenceID": 21, "context": "Our new view is based on instrumental variable regression [18, 22].", "startOffset": 58, "endOffset": 66}, {"referenceID": 3, "context": ", in [4].", "startOffset": 5, "endOffset": 8}, {"referenceID": 21, "context": "We propose a generalization of the linear two stage ordinary least squares procedure [22], give error bounds for this generalization, and formulate dynamical systems learning as an instance of this regression technique.", "startOffset": 85, "endOffset": 89}, {"referenceID": 5, "context": ", [6, 3].", "startOffset": 2, "endOffset": 8}, {"referenceID": 2, "context": ", [6, 3].", "startOffset": 2, "endOffset": 8}, {"referenceID": 3, "context": "In fact, it is also known that we can interpret this algorithm as linear instrumental-variable regression [4].", "startOffset": 106, "endOffset": 109}, {"referenceID": 17, "context": "To counteract this bias, we employ instrumental regression [18, 22].", "startOffset": 59, "endOffset": 67}, {"referenceID": 21, "context": "To counteract this bias, we employ instrumental regression [18, 22].", "startOffset": 59, "endOffset": 67}, {"referenceID": 15, "context": "\u03bet must satisfy 2Note that, similar to [16], Pt is a deterministic function of Qt and hence this condition has a unique solution if we observe sufficient examples of Pt and Qt.", "startOffset": 39, "endOffset": 43}, {"referenceID": 1, "context": "This work extends predictive state learning algorithms for dynamical systems, which include spectral algorithms for Kalman filters [2], Hidden Markov Models [10, 19] and Predictive State Representations (PSRs) [6, 3] as well as infinitedimensional variants such as the Hilbert space embedding of hidden Markov models (HSE-HMM) [20] and predictive state representations (HSE-PSR) [5].", "startOffset": 131, "endOffset": 134}, {"referenceID": 9, "context": "This work extends predictive state learning algorithms for dynamical systems, which include spectral algorithms for Kalman filters [2], Hidden Markov Models [10, 19] and Predictive State Representations (PSRs) [6, 3] as well as infinitedimensional variants such as the Hilbert space embedding of hidden Markov models (HSE-HMM) [20] and predictive state representations (HSE-PSR) [5].", "startOffset": 157, "endOffset": 165}, {"referenceID": 18, "context": "This work extends predictive state learning algorithms for dynamical systems, which include spectral algorithms for Kalman filters [2], Hidden Markov Models [10, 19] and Predictive State Representations (PSRs) [6, 3] as well as infinitedimensional variants such as the Hilbert space embedding of hidden Markov models (HSE-HMM) [20] and predictive state representations (HSE-PSR) [5].", "startOffset": 157, "endOffset": 165}, {"referenceID": 5, "context": "This work extends predictive state learning algorithms for dynamical systems, which include spectral algorithms for Kalman filters [2], Hidden Markov Models [10, 19] and Predictive State Representations (PSRs) [6, 3] as well as infinitedimensional variants such as the Hilbert space embedding of hidden Markov models (HSE-HMM) [20] and predictive state representations (HSE-PSR) [5].", "startOffset": 210, "endOffset": 216}, {"referenceID": 2, "context": "This work extends predictive state learning algorithms for dynamical systems, which include spectral algorithms for Kalman filters [2], Hidden Markov Models [10, 19] and Predictive State Representations (PSRs) [6, 3] as well as infinitedimensional variants such as the Hilbert space embedding of hidden Markov models (HSE-HMM) [20] and predictive state representations (HSE-PSR) [5].", "startOffset": 210, "endOffset": 216}, {"referenceID": 19, "context": "This work extends predictive state learning algorithms for dynamical systems, which include spectral algorithms for Kalman filters [2], Hidden Markov Models [10, 19] and Predictive State Representations (PSRs) [6, 3] as well as infinitedimensional variants such as the Hilbert space embedding of hidden Markov models (HSE-HMM) [20] and predictive state representations (HSE-PSR) [5].", "startOffset": 327, "endOffset": 331}, {"referenceID": 4, "context": "This work extends predictive state learning algorithms for dynamical systems, which include spectral algorithms for Kalman filters [2], Hidden Markov Models [10, 19] and Predictive State Representations (PSRs) [6, 3] as well as infinitedimensional variants such as the Hilbert space embedding of hidden Markov models (HSE-HMM) [20] and predictive state representations (HSE-PSR) [5].", "startOffset": 379, "endOffset": 382}, {"referenceID": 3, "context": "Boots and Gordon [4] note the connection between the HSE-HMM and instrumental variables, which is manifested in the use of kernel SVD of a future-past covariance operator to identify the latent state space.", "startOffset": 17, "endOffset": 20}, {"referenceID": 16, "context": "Reducing dynamical systems learning to supervised learning dates back to auto-regressive models [17], where the state of the system is assumed to be fully determined by the previous k observations.", "startOffset": 96, "endOffset": 100}, {"referenceID": 15, "context": "\u2019s sufficient posterior representation (SPR) [16], which encodes the state by the sufficient statistics of the conditional distribution of the next observation and represents system dynamics by three vector-valued functions that are estimated using supervised learning approaches.", "startOffset": 45, "endOffset": 49}, {"referenceID": 15, "context": "Finally, the theoretical analysis of [16] only establishes the consistency of SPR learning assuming that all regression steps are solved perfectly.", "startOffset": 37, "endOffset": 41}, {"referenceID": 19, "context": "The RKHS view is useful when the future statistics are represented in terms of kernels\u2014for example, if they are kernel mean maps of the distribution of future observations, a case that is closely related to the HSE-HMM [20] and HSE-PSR [5] models.", "startOffset": 219, "endOffset": 223}, {"referenceID": 4, "context": "The RKHS view is useful when the future statistics are represented in terms of kernels\u2014for example, if they are kernel mean maps of the distribution of future observations, a case that is closely related to the HSE-HMM [20] and HSE-PSR [5] models.", "startOffset": 236, "endOffset": 239}, {"referenceID": 10, "context": "[11]).", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "Assume that x and y are kernel evaluation functionals, x\u0304 and \u0233 are linear vector functions of z where the linear operator is estimated using conditional mean embedding [21] with regularization parameter \u03bb0 > 0 and that \u2016x\u0304\u2016X , \u2016\u0233\u2016Y < c < \u221e almost surely.", "startOffset": 169, "endOffset": 173}, {"referenceID": 20, "context": "(sketch) This bound is based on [21], which gives a bound on the error in estimating the conditional mean embedding.", "startOffset": 32, "endOffset": 36}, {"referenceID": 7, "context": "We use the Bayesian knowledge tracing (BKT) model [8], which is essentially a 2-state HMM: the state st represents whether a student has learned a knowledge component (KC), and the observation ot represents the success/failure of solving the t question in a sequence of question that cover the said KC.", "startOffset": 50, "endOffset": 53}, {"referenceID": 14, "context": "1 Data Description The data set we used to evaluate the model is a publicly available data set from DataShop [15] called \u201cGeometry Area (1996-97).", "startOffset": 109, "endOffset": 113}, {"referenceID": 9, "context": "In the appendix, we show that if use ht = ot\u22121 and linear regression as S1 regression model, the resulting algorithm is equivalent to spectral HMM method of [10] and thus we use it as a baseline.", "startOffset": 157, "endOffset": 161}], "year": 2017, "abstractText": "Recently there has been substantial interest in predictive state methods for learning dynamical systems: these algorithms are popular since they often offer a good tradeoff between computational speed and statistical efficiency. Despite their desirable properties, though, predictive state methods can sometimes be difficult to use in practice. E.g., in contrast to the rich literature on supervised learning methods, which allows us to choose from an extensive menu of models and algorithms to suit the prior beliefs we have about properties of the function to be learned, predictive state dynamical system learning methods are comparatively inflexible: it is as if we were restricted to use only linear regression instead of being allowed to choose decision trees, nonparametric regression, or the lasso. To address this problem, we propose a new view of predictive state methods in terms of instrumentalvariable regression. This view allows us to construct a wide variety of dynamical system learners simply by swapping in different supervised learning methods. We demonstrate the effectiveness of our proposed methods by experimenting with non-linear regression to learn a hidden Markov model, showing that the resulting algorithm outperforms its linear counterpart; the correctness of this algorithm follows directly from our general analysis.", "creator": "TeX"}}}