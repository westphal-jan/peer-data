{"id": "1506.00379", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2015", "title": "Modeling Relation Paths for Representation Learning of Knowledge Bases", "abstract": "Representation learning of knowledge bases (KBs) aims to embed both entities and relations into a low-dimensional space. Most existing methods only consider direct relations in representation learning. We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model. This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths. (2) We represent relation paths via semantic composition of relation embeddings. Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text.", "histories": [["v1", "Mon, 1 Jun 2015 08:22:49 GMT  (164kb,D)", "https://arxiv.org/abs/1506.00379v1", "10 pages"], ["v2", "Sat, 15 Aug 2015 09:28:49 GMT  (166kb,D)", "http://arxiv.org/abs/1506.00379v2", "10 pages"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yankai lin", "zhiyuan liu", "huan-bo luan", "maosong sun", "siwei rao", "song liu"], "accepted": true, "id": "1506.00379"}, "pdf": {"name": "1506.00379.pdf", "metadata": {"source": "CRF", "title": "Modeling Relation Paths for Representation Learning of Knowledge Bases", "authors": ["Yankai Lin", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun", "Siwei Rao", "Song Liu"], "emails": ["(liuzy@tsinghua.edu.cn)"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is in such a way that most of them are able to move into a different world, in which they are able to live, to live, to live, to live, to live, to work, to live, to live, to work, to live, to work, to work, to live, to live, to work, to live, to live, to work, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live, to live."}, {"heading": "2 Our Model", "text": "In TransE and PTransE, we have entity set E and relation set R and learn to encode both entities and relationships in Rk. Given a KB represented by a series of triples S = {(h, r, t)}, each triple consisting of two entities h, t, E and their relationship r, R, our model is expected to provide a low energy value if the relationship holds, and a high one otherwise."}, {"heading": "2.1 TransE and PTransE", "text": "For each triple function (h, r, t), TransE considers the relationship as a translation vector r between two entity vectors h and t. The energy function is defined as asE (h, r, t) = | | h + r \u2212 t | |, (1), which is expected to get a low value if (h, r, t) is valid, and as highly others.TransE learns only from direct relationships between entities, but ignores multi-step relationship paths, which also contain rich inference patterns between entities.PTransE takes into account relationship paths for learning presentation.Suppose that there are multiple relationship paths P (h, t) = {p1,.., pN} connecting paths between two entities h and t, with relationship path p = (r1,., rl) relation path = (r1 \u2212 \u2192.. rl \u2212 \u2192 t. For each triple function p (h, t), the relationship h, the relationship (h), (1), (h), relationship r, (1)."}, {"heading": "2.2 Relation Path Reliability", "text": "We propose a path-constraint resource allocation (PCRA) algorithm to measure the reliability of a relationship path. Resource allocation over networks was originally proposed for personalized recommendations (Zhou et al., 2007) and has been successfully used to query information measuring belonging between two objects (Lu and Zhou, 2011). We use the amount of resources that ultimately flows to the end unit p to determine the reliability of the path p as a meaningful link between h and t.Formally, we assume that a certain amount of resources is associated with the header unit h and follows the given path p. We use the amount of resources that ultimately flows to the end unit p to calculate the reliability of the path p as a meaningful link between h and t.Formally, for a path triple (h, p, t), we calculate the amount of resources flowing from h to south (south)."}, {"heading": "2.3 Relation Path Representation", "text": "In addition to the relationship path reliability, we must also define the energy functionE (h, p, t) for the path triple (h, p, t) in Equation (2). \u2212 Similar to the energy function of TransE in Equation (1), we will also represent the relationship path p into the embedding space.However, the semantic meaning of a relationship path (h, p) depends to a large extent on the relationships involved. Therefore, formally, it makes sense for us to build path embedding using the semantic composition of relationship embedding. As illustrated in Figure 2, path embedding p consists of the embedding of BorninCity, CityInState and StateInCountry. Formally, p p is a composition operation for a path p = (r1,. rl) and we receive a path embedding as p = r1."}, {"heading": "2.4 Objective Formalization", "text": "We formalize the optimization target of PTransE as L (S) = 1 (h, r, t). (9) The following TransE, L (h, r, t) and L (p, r) are margin-based loss functions in relation to the triple (h, r, t) and the pair (p, r): L (h, r, t) = 1 (h, r, t), 1 (h, r, t), 2 (h, r), 2 (h, r), 3 (h, r, t), 3 (h, r, t), 3 (h, r, t), 4 (h, r, r, t), 4 (h, r, t), 4 (h, r, t), 5 (h), 5 (h), 5 (h), 5 (h), 5 (h)."}, {"heading": "2.5 Optimization and Implementation Details", "text": "For optimization, we use stochastic gradient origin (SGD) to minimize the loss function. We randomly select a valid triple from the training set for learning. During implementation, we also place restrictions on the norms of embeddings h, r, t. That is, we set an amount that significantly affects the performance of presentation learning, which is introduced as a consequence. Reverse relation addition. In some cases, we are interested in the reverse version of a relationship that may not be represented in KBs. For example, there are some implementation details that will significantly affect the performance of presentation learning, which will be introduced as a sequence. Reverse relation addition 3. In some cases, we are interested in the reverse version of a relationship 3 eCategory 2 eCountry e2, which cannot be represented in KBs. In this paper, e3 eCite2 eCountry e2CiteCountry e2 is interested in the e2 eCountry e2 relationship, which cannot be represented in KBs. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 e2Cite2 e2 e2 e2 e2 e2 e2 e2 e2 e3 e2 e3 e2 e3 e2 e3 e2 e2 e3 e2 e3 e2 e3 e3 e2 e3 e2 e2 e2 e3 e2 e2 e2 e3 e2 e2 e2 e2 e3 e2 e2 e2 e2 e3 e2 e2 e2 e2 e2 e2 e2 e2 e2 e3 e2 e2 e2 e2 e2 e2 e2 e2 e2 e3 e2 e2 e2 e2 e2 e2 e2 e2 e2 e2 e2 e2 e2 e2 e2 e2 e3 e2 e2 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3 e3"}, {"heading": "2.6 Complexity Analysis", "text": "We refer to Ne as the number of units, Nr as the number of relationships, and K as the vector dimension. The model parameter size of PTransE is (NeK + NrK), which is the same as TransE. PTransE follows the optimization procedure introduced by (Bordes et al., 2013) to solve Equation (9). We refer to S as the number of triples for learning, P as the expected number of relationship paths between two units, and L as the expected length of relationship paths. For each iteration in optimization, the complexity of TransE is O (SK) and the complexity of PTransE isO (SKPL) for ADD and MUL and O (SK2PL) for RNN."}, {"heading": "3 Experiments and Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Data Sets and Experimental Setting", "text": "In this paper, we use two sets of data extracted from the freebase, i.e. FB15K and FB40K. Statistics of the data sets are listed in Table 1. We evaluate the performance of PTransE and other baselines by predicting whether the triple check is successful. We consider two scenarios: (1) the completion of the knowledge base, which aims to predict the missing entities or relationships in given triples only on the basis of existing KBs. (2) relation extraction from texts, which aim to extract relationships between entities based on information from both plain texts and KBs."}, {"heading": "3.2 Knowledge Base Completion", "text": "The task of completing the knowledge base is to complete the triple (h, r, t) if one of h, t, r is missing. The task was used for evaluation in (Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013). In the test phase, we define for each triple (h, r, t) the following score function for the predictionS (h, r, t) = G (h, r, t) + G (t, r \u2212 1, h), (14) and the score function G (h, r, t) is further defined asG (h, r, t) = | h + r \u2212 t | | + 1Z = p \u00b2 P (h, r \u2212 p), (h, r, t)."}, {"heading": "3.2.1 Entity Prediction", "text": "In the sub-task of the entity prediction, we can filter out all of these values in the ranking before we are called KBs. \"For each triple test with a missing head or tail entity, different methods are used to calculate the results of G (h, r, t) for all candidates and to rate them in descending order. We use two metrics as our evaluation metrics: the mean of the correct entity ranking and the percentage of valid entities listed in the top 10 (hits @ 10). As mentioned in (Bordes et al, 2013), the metrics are desirable but flawed when an invalid triple-up in KBs becomes valid. For example, if the test is triple (Obama, PresidentOf, USA) with the head Entity Lincoln being considered ineffective for prediction, but in fact it is valid in KBs."}, {"heading": "3.2.2 Relation Prediction", "text": "In this subtask, we can use the score function of PTransE to evaluate the candidate relationships, rather than reevaluating them as in the entity prediction. Since our implementation of TransE has achieved the best performance of all baselines for the entity prediction, we are comparing PTransE here only with TransE due to limited space. The evaluation results are shown in Table 4, where we use hits @ 1 instead of hits @ 10 for comparison, since hits @ 10 exceeds 95% for both TransE and PTransE. In this table, we report on the performance of TransE without reversed relationships (TransE), with reversed relationships (+ Rev) and taking into account relation paths for tests such as those in PTransE (+ Rev + Path). We report on the performance of PTransE with only consideration of relation paths (- TransE), only taking into account the part in the equation (path) and taking into account both (Psimilation = 0.001 Translation)."}, {"heading": "3.3 Relation Extraction from Text", "text": "Many papers consider large-scale CBs as remote supervision for commenting sentences as training instances and forming relation classifiers by characteristics extracted from sentences (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) All of these methods establish new facts only on the basis of simple text. TransE was used to enrich a text-based model and achieved a significant improvement (Weston et al., 2013), and the same is true for TransH et al. TransH et al., 2014) and TransR (Lin et al., 2015). We study the effectiveness of PTransE for text relations. We use the New York Times corpus (NYT), which we publish from (Riedel et al., 2010) as training and test data."}, {"heading": "3.4 Case Study of Relation Inference", "text": "We have shown that PTransE can achieve high performance in completing the knowledge base and extracting relationships from text. In this section, we present some examples of relationship conclusions by relation path. According to the learning results of PTransE, we can find new facts from KBs. As shown in Figure 4, two entities Forrest Gump and English are connected by three relation paths, which give us more certainty to predict the relationship between the two entities to LanguageOfFilm."}, {"heading": "4 Related Work", "text": "Much progress has been made in modeling multirelational data such as social networks and CBs in recent years. Many papers deal with relational learning as a multirelational representation problem, encoding both entities and relationships in a low-dimensional latent space, based on Bayesian clusters (Kemp et al., 2006; Miller et al., 2009; Sutskever et al., 2009; Zhu et al., 2012), energy-based models (Bordes et al., 2013; Bordes et al., 2013; Bordes et al., 2014), matrix factorization (Singh and Gordon et al., 2011; Nickel et al., 2012). Among existing representation models, TransE (Bordes et al., 2013) presents a relationship between these entities as a translation between head and tail entities for optimization."}, {"heading": "5 Conclusion and Future Work", "text": "This paper introduces PTransE, a novel method of learning representation for CBs that encodes relation paths to embed both entities and relations in a low-dimensional space. To take advantage of relation paths, we propose a path-constraint resource allocation to measure the reliability of relation paths, and use semantic composition of relationships to represent paths to optimization. We evaluate PTransE based on completion of the knowledge base and extraction of relationships from text. Experimental results show that PTransE provides consistent and significant improvements compared to TransE and other baselines. In the future, we will explore the following research directions: (1) This paper takes into account only the inference patterns between direct relationships and relationship paths between two entities to learn. There are much more complicated patterns between relationships. For example, the Queen (=) Inference (= = =) cannot be obtained by transforming."}, {"heading": "6 Acknowledgments", "text": "Zhiyuan Liu and Maosong Sun are supported by the 973 Program (No. 2014CB340501) and the National Natural Science Foundation of China (NSFC No. 61133012) as well as the Tsinghua-Samsung Joint Lab. Huanbo Luan is supported by the National Natural Science Foundation of China (NSFC No. 61303075). We sincerely thank Yansong Feng for enlightening conversations and all anonymous critics for their constructive comments."}], "references": [{"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "In Proceedings of KDD,", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Learning structured embeddings of knowledge bases", "author": ["Jason Weston", "Ronan Collobert", "Yoshua Bengio"], "venue": "In Proceedings of AAAI,", "citeRegEx": "Bordes et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2011}, {"title": "Joint learning of words and meaning representations for opentext semantic parsing", "author": ["Xavier Glorot", "Jason Weston", "Yoshua Bengio"], "venue": "In Proceedings of AISTATS,", "citeRegEx": "Bordes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2012}, {"title": "Translating embeddings for modeling multi-relational data", "author": ["Nicolas Usunier", "Alberto Garcia-Duran", "Jason Weston", "Oksana Yakhnenko"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Bordes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "A semantic matching energy function for learning with multirelational data", "author": ["Xavier Glorot", "Jason Weston", "Yoshua Bengio"], "venue": "Machine Learning,", "citeRegEx": "Bordes et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2014}, {"title": "Learning new facts from knowledge bases with neural tensor networks and semantic word vectors", "author": ["Chen et al.2013] Danqi Chen", "Richard Socher", "Christopher D Manning", "Andrew Y Ng"], "venue": "Proceedings of ICLR", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Improving learning and inference in a large knowledge-base using latent syntactic cues", "author": ["Gardner et al.2013] Matt Gardner", "Partha Pratim Talukdar", "Bryan Kisiel", "Tom M Mitchell"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Gardner et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gardner et al\\.", "year": 2013}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S Weld"], "venue": "In Proceedings of ACL-HLT,", "citeRegEx": "Hoffmann et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "A latent factor model for highly multirelational data", "author": ["Nicolas L Roux", "Antoine Bordes", "Guillaume R Obozinski"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Jenatton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jenatton et al\\.", "year": 2012}, {"title": "Learning systems of concepts with an infinite relational model", "author": ["Kemp et al.2006] Charles Kemp", "Joshua B Tenenbaum", "Thomas L Griffiths", "Takeshi Yamada", "Naonori Ueda"], "venue": "In Proceedings of AAAI,", "citeRegEx": "Kemp et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kemp et al\\.", "year": 2006}, {"title": "Relational retrieval using a combination of path-constrained random walks", "author": ["Lao", "Cohen2010] Ni Lao", "William W Cohen"], "venue": "Machine learning,", "citeRegEx": "Lao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lao et al\\.", "year": 2010}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["Lao et al.2011] Ni Lao", "Tom Mitchell", "William W Cohen"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Lao et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lao et al\\.", "year": 2011}, {"title": "Reading the web with learned syntactic-semantic inference rules", "author": ["Lao et al.2012] Ni Lao", "Amarnag Subramanya", "Fernando Pereira", "William W Cohen"], "venue": "In Proceedings of EMNLP-CoNLL,", "citeRegEx": "Lao et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lao et al\\.", "year": 2012}, {"title": "Learning entity and relation embeddings for knowledge graph completion", "author": ["Lin et al.2015] Yankai Lin", "Zhiyuan Liu", "Maosong Sun", "Yang Liu", "Xuan Zhu"], "venue": "In Proceedings of AAAI,", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Link prediction in complex networks: A survey", "author": ["L\u00fc", "Zhou2011] Linyuan L\u00fc", "Tao Zhou"], "venue": "Physica A: Statistical Mechanics and its Applications,", "citeRegEx": "L\u00fc et al\\.,? \\Q2011\\E", "shortCiteRegEx": "L\u00fc et al\\.", "year": 2011}, {"title": "Recurrent neural network based language model", "author": ["Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "In Proceedings of Interspeech,", "citeRegEx": "Mikolov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Nonparametric latent feature models for link prediction", "author": ["Miller et al.2009] Kurt Miller", "Michael I Jordan", "Thomas L Griffiths"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Miller et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Miller et al\\.", "year": 2009}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009] Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "In Proceedings of ACL-IJCNLP,", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Vector-based models of semantic composition", "author": ["Mitchell", "Lapata2008] Jeff Mitchell", "Mirella Lapata"], "venue": "In Proceedings of ACL,", "citeRegEx": "Mitchell et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2008}, {"title": "Compositional vector space models for knowledge base inference", "author": ["Benjamin Roth", "Andrew McCallum"], "venue": "In 2015 AAAI Spring Symposium Series", "citeRegEx": "Neelakantan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2015}, {"title": "A three-way model for collective learning on multi-relational data", "author": ["Volker Tresp", "Hans-Peter Kriegel"], "venue": "In Proceedings of ICML,", "citeRegEx": "Nickel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2011}, {"title": "Factorizing yago: scalable machine learning for linked data", "author": ["Volker Tresp", "Hans-Peter Kriegel"], "venue": "In Proceedings of WWW,", "citeRegEx": "Nickel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2012}, {"title": "Modeling relations and their mentions without labeled text", "author": ["Limin Yao", "Andrew McCallum"], "venue": "In Proceedings of ECML-PKDD,", "citeRegEx": "Riedel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Relational learning via collective matrix factorization", "author": ["Singh", "Gordon2008] Ajit P Singh", "Geoffrey J Gordon"], "venue": "In Proceedings of KDD,", "citeRegEx": "Singh et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Singh et al\\.", "year": 2008}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["Danqi Chen", "Christopher D Manning", "Andrew Ng"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["Julie Tibshirani", "Ramesh Nallapati", "Christopher D Manning"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Surdeanu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "Modelling relational data using bayesian clustered tensor factorization", "author": ["Joshua B Tenenbaum", "Ruslan Salakhutdinov"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Sutskever et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2009}, {"title": "Fast random walk with restart and its applications", "author": ["Tong et al.2006] Hanghang Tong", "Christos Faloutsos", "Jia-Yu Pan"], "venue": "In Proceedings of ICDM,", "citeRegEx": "Tong et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Tong et al\\.", "year": 2006}, {"title": "Knowledge graph embedding by translating on hyperplanes", "author": ["Wang et al.2014] Zhen Wang", "Jianwen Zhang", "Jianlin Feng", "Zheng Chen"], "venue": "In Proceedings of AAAI,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Connecting language and knowledge bases with embedding models for relation extraction", "author": ["Weston et al.2013] Jason Weston", "Antoine Bordes", "Oksana Yakhnenko", "Nicolas Usunier"], "venue": "In Proceedings of EMNLP,", "citeRegEx": "Weston et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2013}, {"title": "Bipartite network projection and personal recommendation", "author": ["Zhou et al.2007] Tao Zhou", "Jie Ren", "Mat\u00fa\u0161 Medo", "Yi-Cheng Zhang"], "venue": "Physical Review E,", "citeRegEx": "Zhou et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2007}, {"title": "Max-margin nonparametric latent feature models for link prediction", "author": ["Jun Zhu"], "venue": "In Proceedings of ICML,", "citeRegEx": "Zhu.,? \\Q2012\\E", "shortCiteRegEx": "Zhu.", "year": 2012}], "referenceMentions": [{"referenceID": 3, "context": "TransE (Bordes et al., 2013) is a typical method in the neural-based approach, which learns vectors (i.", "startOffset": 7, "endOffset": 28}, {"referenceID": 28, "context": "Since TransE has issues when modeling 1-to-N, N-to-1 and N-to-N relations, various methods such as TransH (Wang et al., 2014) and TransR (Lin et al.", "startOffset": 106, "endOffset": 125}, {"referenceID": 13, "context": ", 2014) and TransR (Lin et al., 2015) are proposed to assign an entity with different representations when involved in various relations.", "startOffset": 19, "endOffset": 37}, {"referenceID": 30, "context": "Resource allocation over networks was originally proposed for personalized recommendation (Zhou et al., 2007), and has been successfully used in information retrieval for measuring relatedness between two objects (L\u00fc and Zhou, 2011).", "startOffset": 90, "endOffset": 109}, {"referenceID": 15, "context": "RNN is a recent neural-based model for semantic composition (Mikolov et al., 2010).", "startOffset": 60, "endOffset": 82}, {"referenceID": 19, "context": "RNN has also been used for representation learning of relation paths in KBs (Neelakantan et al., 2015).", "startOffset": 76, "endOffset": 102}, {"referenceID": 3, "context": "PTransE follows the optimization procedure introduced by (Bordes et al., 2013) to solve Equation (9).", "startOffset": 57, "endOffset": 78}, {"referenceID": 0, "context": "We evaluate our method on a typical large-scale KB Freebase (Bollacker et al., 2008).", "startOffset": 60, "endOffset": 84}, {"referenceID": 1, "context": "The task has been used for evaluation in (Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013).", "startOffset": 41, "endOffset": 104}, {"referenceID": 2, "context": "The task has been used for evaluation in (Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013).", "startOffset": 41, "endOffset": 104}, {"referenceID": 3, "context": "The task has been used for evaluation in (Bordes et al., 2011; Bordes et al., 2012; Bordes et al., 2013).", "startOffset": 41, "endOffset": 104}, {"referenceID": 3, "context": "In the sub-task of entity prediction, we follow the setting in (Bordes et al., 2013).", "startOffset": 63, "endOffset": 84}, {"referenceID": 3, "context": "As mentioned in (Bordes et al., 2013), the measures are desirable but flawed when an invalid triple ends up being valid in KBs.", "startOffset": 16, "endOffset": 37}, {"referenceID": 3, "context": "For comparison, we select all methods in (Bordes et al., 2013; Wang et al., 2014) as our baselines and use their reported results directly since the evaluation dataset is identical.", "startOffset": 41, "endOffset": 81}, {"referenceID": 28, "context": "For comparison, we select all methods in (Bordes et al., 2013; Wang et al., 2014) as our baselines and use their reported results directly since the evaluation dataset is identical.", "startOffset": 41, "endOffset": 81}, {"referenceID": 20, "context": "The baselines include RESCAL (Nickel et al., 2011), SE (Bordes et al.", "startOffset": 29, "endOffset": 50}, {"referenceID": 1, "context": ", 2011), SE (Bordes et al., 2011), SME (linear) (Bordes et al.", "startOffset": 12, "endOffset": 33}, {"referenceID": 2, "context": ", 2011), SME (linear) (Bordes et al., 2012), SME (bilinear)", "startOffset": 22, "endOffset": 43}, {"referenceID": 2, "context": "(Bordes et al., 2012), LFM (Jenatton et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 8, "context": ", 2012), LFM (Jenatton et al., 2012), TransE (Bordes et al.", "startOffset": 13, "endOffset": 36}, {"referenceID": 3, "context": ", 2012), TransE (Bordes et al., 2013) (original version and our implementation considering reverse relations), TransH (Wang et al.", "startOffset": 16, "endOffset": 37}, {"referenceID": 28, "context": ", 2013) (original version and our implementation considering reverse relations), TransH (Wang et al., 2014), and TransR (Lin et al.", "startOffset": 88, "endOffset": 107}, {"referenceID": 13, "context": ", 2014), and TransR (Lin et al., 2015).", "startOffset": 20, "endOffset": 38}, {"referenceID": 3, "context": "With the same configurations of PTransE, our TransE implementation achieves much better performance than that reported in (Bordes et al., 2013).", "startOffset": 122, "endOffset": 143}, {"referenceID": 3, "context": "As defined in (Bordes et al., 2013), relations in KBs can be divided into various types according to their mapping properties such as 1-to-1, 1-toN, N-to-1 and N-to-N.", "startOffset": 14, "endOffset": 35}, {"referenceID": 17, "context": "Many works regard large-scale KBs as distant supervision to annotate sentences as training instances and build relation classifiers according to features extracted from the sentences (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 183, "endOffset": 270}, {"referenceID": 22, "context": "Many works regard large-scale KBs as distant supervision to annotate sentences as training instances and build relation classifiers according to features extracted from the sentences (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 183, "endOffset": 270}, {"referenceID": 7, "context": "Many works regard large-scale KBs as distant supervision to annotate sentences as training instances and build relation classifiers according to features extracted from the sentences (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 183, "endOffset": 270}, {"referenceID": 25, "context": "Many works regard large-scale KBs as distant supervision to annotate sentences as training instances and build relation classifiers according to features extracted from the sentences (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012).", "startOffset": 183, "endOffset": 270}, {"referenceID": 29, "context": "TransE was used to enrich a text-based model and achieved a significant improvement (Weston et al., 2013), and so do TransH (Wang et al.", "startOffset": 84, "endOffset": 105}, {"referenceID": 28, "context": ", 2013), and so do TransH (Wang et al., 2014) and TransR (Lin et al.", "startOffset": 26, "endOffset": 45}, {"referenceID": 13, "context": ", 2014) and TransR (Lin et al., 2015).", "startOffset": 19, "endOffset": 37}, {"referenceID": 22, "context": "We use New York Times corpus (NYT) released by (Riedel et al., 2010) as training and testing data.", "startOffset": 47, "endOffset": 68}, {"referenceID": 29, "context": "In the experiments, we implemented the textbased model Sm2r presented in (Weston et al., 2013).", "startOffset": 73, "endOffset": 94}, {"referenceID": 25, "context": "We also compare with MIMLRE (Surdeanu et al., 2012) which is the state-of-art method using distant supervision.", "startOffset": 28, "endOffset": 51}, {"referenceID": 9, "context": "Many works cope with relational learning as a multi-relational representation learning problem, encoding both entities and relations in a low-dimensional latent space, based on Bayesian clustering (Kemp et al., 2006; Miller et al., 2009; Sutskever et al., 2009; Zhu, 2012), energy-based models (Bordes et al.", "startOffset": 197, "endOffset": 272}, {"referenceID": 16, "context": "Many works cope with relational learning as a multi-relational representation learning problem, encoding both entities and relations in a low-dimensional latent space, based on Bayesian clustering (Kemp et al., 2006; Miller et al., 2009; Sutskever et al., 2009; Zhu, 2012), energy-based models (Bordes et al.", "startOffset": 197, "endOffset": 272}, {"referenceID": 26, "context": "Many works cope with relational learning as a multi-relational representation learning problem, encoding both entities and relations in a low-dimensional latent space, based on Bayesian clustering (Kemp et al., 2006; Miller et al., 2009; Sutskever et al., 2009; Zhu, 2012), energy-based models (Bordes et al.", "startOffset": 197, "endOffset": 272}, {"referenceID": 31, "context": "Many works cope with relational learning as a multi-relational representation learning problem, encoding both entities and relations in a low-dimensional latent space, based on Bayesian clustering (Kemp et al., 2006; Miller et al., 2009; Sutskever et al., 2009; Zhu, 2012), energy-based models (Bordes et al.", "startOffset": 197, "endOffset": 272}, {"referenceID": 1, "context": ", 2009; Zhu, 2012), energy-based models (Bordes et al., 2011; Chen et al., 2013; Socher et al., 2013; Bordes et al., 2013; Bordes et al., 2014), matrix factorization (Singh and Gordon, 2008; Nickel et al.", "startOffset": 40, "endOffset": 143}, {"referenceID": 5, "context": ", 2009; Zhu, 2012), energy-based models (Bordes et al., 2011; Chen et al., 2013; Socher et al., 2013; Bordes et al., 2013; Bordes et al., 2014), matrix factorization (Singh and Gordon, 2008; Nickel et al.", "startOffset": 40, "endOffset": 143}, {"referenceID": 24, "context": ", 2009; Zhu, 2012), energy-based models (Bordes et al., 2011; Chen et al., 2013; Socher et al., 2013; Bordes et al., 2013; Bordes et al., 2014), matrix factorization (Singh and Gordon, 2008; Nickel et al.", "startOffset": 40, "endOffset": 143}, {"referenceID": 3, "context": ", 2009; Zhu, 2012), energy-based models (Bordes et al., 2011; Chen et al., 2013; Socher et al., 2013; Bordes et al., 2013; Bordes et al., 2014), matrix factorization (Singh and Gordon, 2008; Nickel et al.", "startOffset": 40, "endOffset": 143}, {"referenceID": 4, "context": ", 2009; Zhu, 2012), energy-based models (Bordes et al., 2011; Chen et al., 2013; Socher et al., 2013; Bordes et al., 2013; Bordes et al., 2014), matrix factorization (Singh and Gordon, 2008; Nickel et al.", "startOffset": 40, "endOffset": 143}, {"referenceID": 20, "context": ", 2014), matrix factorization (Singh and Gordon, 2008; Nickel et al., 2011; Nickel et al., 2012) .", "startOffset": 30, "endOffset": 96}, {"referenceID": 21, "context": ", 2014), matrix factorization (Singh and Gordon, 2008; Nickel et al., 2011; Nickel et al., 2012) .", "startOffset": 30, "endOffset": 96}, {"referenceID": 3, "context": "Among existing representation models, TransE (Bordes et al., 2013) regards a relation as translation between head and tail entities for optimization, which achieves a good trade-off between prediction accuracy and computational efficiency.", "startOffset": 45, "endOffset": 66}, {"referenceID": 27, "context": "Most of these works regard each relation and path as discrete symbols, and deal with them using graph-based algorithms, such as random walks with restart (Tong et al., 2006).", "startOffset": 154, "endOffset": 173}, {"referenceID": 12, "context": "Relation paths have also been used for inference on large-scale KBs, such as Path Ranking algorithm (PRA) (Lao and Cohen, 2010), which has been adopted for expert finding (Lao and Cohen, 2010) and information retrieval (Lao et al., 2012).", "startOffset": 219, "endOffset": 237}, {"referenceID": 11, "context": "PRA has also been used for relation extraction based on KB structure (Lao et al., 2011; Gardner et al., 2013).", "startOffset": 69, "endOffset": 109}, {"referenceID": 6, "context": "PRA has also been used for relation extraction based on KB structure (Lao et al., 2011; Gardner et al., 2013).", "startOffset": 69, "endOffset": 109}, {"referenceID": 19, "context": "(Neelakantan et al., 2015) further learns a recurrent neural network (RNN) to represent unseen relation paths according to involved relations.", "startOffset": 0, "endOffset": 26}], "year": 2015, "abstractText": "Representation learning of knowledge bases aims to embed both entities and relations into a low-dimensional space. Most existing methods only consider direct relations in representation learning. We argue that multiple-step relation paths also contain rich inference patterns between entities, and propose a path-based representation learning model. This model considers relation paths as translations between entities for representation learning, and addresses two key challenges: (1) Since not all relation paths are reliable, we design a path-constraint resource allocation algorithm to measure the reliability of relation paths. (2) We represent relation paths via semantic composition of relation embeddings. Experimental results on real-world datasets show that, as compared with baselines, our model achieves significant and consistent improvements on knowledge base completion and relation extraction from text. The source code of this paper can be obtained from https://github.com/mrlyk423/ relation_extraction.", "creator": "LaTeX with hyperref package"}}}