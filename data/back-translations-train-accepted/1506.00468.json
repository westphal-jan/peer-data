{"id": "1506.00468", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Jun-2015", "title": "Classifying Tweet Level Judgements of Rumours in Social Media", "abstract": "Social media is a rich source of rumours and corresponding community reactions. Determining the extent of community belief in a rumour is of value for marketing, politics and journalism. Moreover, collective judgements have been shown to correlate with ground truth. We formulate the problem of estimating the collective judgement of a rumour in social media as a supervised learning using annotated examples. Rumours reflect different characteristics, some shared and some individual. We consider both supervised and unsupervised domain adaptation, in which rumour predictions are made on the basis of other annotated rumours. Evaluation on a set of several thousands tweets on seven rumours shows that we can successfully predict individual and collective judgements.", "histories": [["v1", "Mon, 1 Jun 2015 12:20:21 GMT  (142kb,D)", "https://arxiv.org/abs/1506.00468v1", null], ["v2", "Thu, 10 Sep 2015 18:25:55 GMT  (57kb)", "http://arxiv.org/abs/1506.00468v2", null]], "reviews": [], "SUBJECTS": "cs.SI cs.CL cs.LG", "authors": ["michal lukasik", "trevor cohn", "kalina bontcheva"], "accepted": true, "id": "1506.00468"}, "pdf": {"name": "1506.00468.pdf", "metadata": {"source": "CRF", "title": "Classifying Tweet Level Judgements of Rumours in Social Media", "authors": ["Michal Lukasik", "Trevor Cohn"], "emails": ["m.lukasik@shef.ac.uk", "k.bontcheva@shef.ac.uk", "t.cohn@unimelb.edu.au"], "sections": [{"heading": null, "text": "ar Xiv: 150 6,00 468v 2 [cs.S I] 1 0Se p20 15"}, {"heading": "1 Introduction", "text": "During an earthquake in Chile, for example, rumors circulated on Twitter that a volcano had become active and that there had been a tsunami warning in Valparaiso (Procter et al., 2010); other examples from the riots in England in 2011 were that rioters would attack the children's hospital in Birmingham and that animals had escaped from the zoo (Procter et al., 2013); and social scientists (Procter et al., 2013) manually analyzed a sample of tweets in which different judgments were expressed on rumors and these were manually categorized to support, deny or challenge them, with the goal of automatically classifying rumors at the tweet level to help with (near) real-time rumor monitoring by journalists and authorities (Procter et al., 2013)."}, {"heading": "2 Related work", "text": "In connection with rumors circulating on social media, researchers have examined the differences in information flows between content of varying credibility. For example, Procter et al. (2013) grouped source tests and converted tweets into information flows (Lotan et al., 2011), classifying them by their flow size, as proxies of importance. Information flows were then manually categorized. Along similar veins, Mendoza et al. (2010) found that users handle real and false rumors differently: the former are confirmed more than 90% of the time, while the latter are challenged (questioned or denied) 50% of the time. Friggeri et al. (2014) analyzed rumors from the Snopes.com website, which were matched with public conversations on Facebook. They concluded that false rumors are more likely to receive a comment with a link to the Snopes.com website."}, {"heading": "3 Data", "text": "We evaluate our work on several rumors circulating on Twitter during the 2011 riots in England (see Table 2).The data set was analyzed and manually commented on by a team of social scientists investigating the role of social media during the riots as supportive, questioning or denying (Procter et al., 2013).The original data set also contained commenting tweets, but these were removed from our experiments due to their small number (they accounted for only 5% of the corpus).As can be seen from the dataset overview in Table 2, various rumors exhibit different proportions of supporting, denying and questioning tweets, as has been observed in other studies on rumors (Mendoza et al., 2010; Qazvinian et al., 2011).These variations in the majority classes across rumors underscore the modeling challenge in classifying rumors at the tweet level. In terms of veracity, one rumor was confirmed as true (Miss Selfridge, al.).2011."}, {"heading": "4 Problem formulation", "text": "Let R be a set of rumors, each of which consists of tweets discussing it. Each tweet is classified as supportive, denying, or questioning in relation to its rumor: y (t) 0, 1, 2, where 0 stands for supportive, 1 for denying, and 2 for questioning. First, we consider the setting Leave One Out (LOO), which means that for each rumor R we construct the test set equal to Tr and the training set equal to T\\ Tr. Therefore, this is a very challenging and realistic scenario in which the test set contains a completely invisible rumor from the training set. The second setting is Leave Part Out (LPO). In this formulation, a very small number of initial tweets from the target rumor are inserted into the training set."}, {"heading": "5 Gaussian Processes for Classification", "text": "Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Preotiuc-Pietro et al., 2015). We use Gaussian Processes as this probabilistic kernel-based framework avoids the need for expensive cross-validation for hyperparameter selection.11There exist frequency kernel methods, like SVMs, which additional require extensive heldout parameters do-the central concept of Gaussian Process Classification (GPC, 2005) is a latent function f over inputs x (x)."}, {"heading": "6 Features", "text": "All words have been reduced in size; stopwords removed; all emoticons have been replaced by word2; and stammering has been performed. In addition, several occurrences of a character have been replaced by a double occurrence (Agarwal et al., 2011) to correct spelling errors and extensions, e.g. looool. All punctuation has also been removed, except for.! and?, which we consider important to express emotions. Finally, usernames have been removed because they tend to be odor specific, i.e., very few users comment on more than one rumor. After pre-processing the text data, we either use the resulting bag of words (BOW) or replace all words with their brown cluster IDs (Brown), using 1000 clusters that come from a large Twitter corpus2We dictionary of: http: / / bit.ly / 1rXHdyn or replace all words with their brown cluster IDs (Brown), by using the following dictionary: Op2We: http: / / bit.ly: http: / / bit.ly / 1rXHdyn."}, {"heading": "7 Experiments and Discussion", "text": "Table 3 shows the mean accuracy in the LOO scenario following the GPPooled method, which summarizes all the reference rumors and ignores their task identities. ICM cannot use correlations to target rumors in this case and can therefore not be used. The base of the majority simply assigns Brown the most common class from the training set. We can observe that methods work at a level similar to the majority decisions and only slightly exceed them, showing how difficult the LOO task is when there are no commented target rumor tweets available. Figure 1 shows accuracy for a number of methods as the number of tweets about the target rumor used for training increases. In particular, performance does not increase further, indicating that even 10 commented tweets from the target rumor are available, compared to the results of invisible rumors from Table 3."}, {"heading": "8 Conclusions", "text": "This paper examined the problem of classifying judgments expressed in tweets about rumors. First, we looked at a setting in which there is no training data available from target rumors (LOO). Without access to annotated examples of target rumors, the learning problem becomes very difficult. We demonstrated that in the monitored domain adaptation setting (LPO), even commenting on a small number of tweets contributes to better results. Furthermore, we demonstrated the benefits of a multi-task learning approach and that Brown cluster features are more useful for the task than simple bags of words. Assessment methods are undoubtedly of great value, e.g. for marketing, politics, and journalism, which helps to address widely accepted issues. Although the focus here is on classifying community activities, Castillo et al. (2013) showed that the community response is correlated to the actual veracity of rumors. Consequently, our classification methods could prove useful in the broader task of more demanding and useful facts."}, {"heading": "Acknowledgments", "text": "Partly supported by the European Union under PHEME Funding Agreement No. 611233, which was implemented with the GPy Toolkit (GPy Authors, 2015)."}], "references": [{"title": "Kernels for vector-valued functions: A review", "author": ["Lorenzo Rosasco", "Neil D. Lawrence"], "venue": null, "citeRegEx": "\u00c1lvarez et al\\.,? \\Q2012\\E", "shortCiteRegEx": "\u00c1lvarez et al\\.", "year": 2012}, {"title": "Joint emotion analysis via multitask Gaussian processes", "author": ["Beck et al.2014] Daniel Beck", "Trevor Cohn", "Lucia Specia"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Beck et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Beck et al\\.", "year": 2014}, {"title": "Predicting information credibility in time-sensitive social media", "author": ["Marcelo Mendoza", "Barbara Poblete"], "venue": "Internet Research,", "citeRegEx": "Castillo et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Castillo et al\\.", "year": 2013}, {"title": "Modelling annotator bias with multitask Gaussian processes: An application to machine translation quality estimation", "author": ["Cohn", "Specia2013] Trevor Cohn", "Lucia Specia"], "venue": "In 51st Annual Meeting of the Association", "citeRegEx": "Cohn et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 2013}, {"title": "Rumor cascades", "author": ["Lada Adamic", "Dean Eckles", "Justin Cheng"], "venue": "In International AAAI Conference on Weblogs and Social Media", "citeRegEx": "Friggeri et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Friggeri et al\\.", "year": 2014}, {"title": "Predicting and characterising user impact on twitter", "author": ["Nikolaos Aletras", "Daniel Preotiuc-Pietro", "Trevor Cohn"], "venue": "In Proceedings of the 14th Conference of the European Chapter of the Association", "citeRegEx": "Lampos et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lampos et al\\.", "year": 2014}, {"title": "Re-using an argument corpus to aid in the curation of social media collections", "author": ["Claire Grover", "Jon Oberlander", "Ewan Klein"], "venue": "In Proceedings of the Ninth International Conference on Language Resources", "citeRegEx": "Llewellyn et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Llewellyn et al\\.", "year": 2014}, {"title": "The Arab spring\u2014 the revolutions were tweeted: Information flows during the 2011 Tunisian and Egyptian revolutions", "author": ["Lotan et al.2011] Gilad Lotan", "Erhardt Graeff", "Mike Ananny", "Devin Gaffney", "Ian Pearce", "danah boyd"], "venue": null, "citeRegEx": "Lotan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lotan et al\\.", "year": 2011}, {"title": "Point process modelling of rumour dynamics in social media", "author": ["Trevor Cohn", "Kalina Bontcheva"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International", "citeRegEx": "Lukasik et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lukasik et al\\.", "year": 2015}, {"title": "Twitter under crisis: Can we trust what we RT", "author": ["Barbara Poblete", "Carlos Castillo"], "venue": "In 1st Workshop on Social Media Analytics,", "citeRegEx": "Mendoza et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mendoza et al\\.", "year": 2010}, {"title": "Expectation-propagation for the generative aspect model", "author": ["Minka", "Lafferty2002] Thomas Minka", "John Lafferty"], "venue": "In Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Minka et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Minka et al\\.", "year": 2002}, {"title": "Improved part-of-speech tagging for online conversational text with word clusters", "author": ["Chris Dyer", "Kevin Gimpel", "Nathan Schneider", "Noah A. Smith"], "venue": "In Proceedings of NAACL,", "citeRegEx": "Owoputi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Owoputi et al\\.", "year": 2013}, {"title": "An analysis of the user occupational class through twitter content", "author": ["Vasileios Lampos", "Nikolaos Aletras"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "Preotiuc.Pietro et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Preotiuc.Pietro et al\\.", "year": 2015}, {"title": "Reading the riots: What were the police doing on twitter", "author": ["Procter et al.2013] Rob Procter", "Jeremy Crump", "Susanne Karstedt", "Alex Voss", "Marta Cantijoch"], "venue": "Policing and society,", "citeRegEx": "Procter et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Procter et al\\.", "year": 2013}, {"title": "Rumor has it: Identifying misinformation in microblogs", "author": ["Emily Rosengren", "Dragomir R. Radev", "Qiaozhu Mei"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Qazvinian et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Qazvinian et al\\.", "year": 2011}, {"title": "Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)", "author": ["Rasmussen", "Christopher K.I. Williams"], "venue": null, "citeRegEx": "Rasmussen et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Rasmussen et al\\.", "year": 2005}, {"title": "Detecting and tracking political abuse in social media", "author": ["Michael Conover", "Mark Meiss", "Bruno Gonalves", "Alessandro Flammini", "Filippo Menczer"], "venue": null, "citeRegEx": "Ratkiewicz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ratkiewicz et al\\.", "year": 2011}, {"title": "Early detection of rumors in social media from enquiry posts", "author": ["Zhao et al.2015] Zhe Zhao", "Paul Resnick", "Qiaozhu Mei"], "venue": "In International World Wide Web Conference Committee (IW3C2)", "citeRegEx": "Zhao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 9, "context": "For instance, during an earthquake in Chile rumours spread through Twitter that a volcano had become active and that there was a tsunami warning in Valparaiso (Mendoza et al., 2010).", "startOffset": 159, "endOffset": 181}, {"referenceID": 13, "context": "pital and that animals had escaped from the zoo (Procter et al., 2013).", "startOffset": 48, "endOffset": 70}, {"referenceID": 13, "context": "Social scientists (Procter et al., 2013) analysed manually a sample of tweets expressing different", "startOffset": 18, "endOffset": 40}, {"referenceID": 13, "context": "The goal here is to carry out tweet-level judgement classification automatically, in order to assist in (near) real-time rumour monitoring by journalists and authorities (Procter et al., 2013).", "startOffset": 170, "endOffset": 192}, {"referenceID": 17, "context": "has been used as a first step for early rumour detection by (Zhao et al., 2015).", "startOffset": 60, "endOffset": 79}, {"referenceID": 14, "context": "Previous work on this problem either considered unrealistic settings ignoring temporal ordering and rumour identities (Qazvinian et al., 2011) or proposed regular expressions as a solution (Zhao et al.", "startOffset": 118, "endOffset": 142}, {"referenceID": 17, "context": ", 2011) or proposed regular expressions as a solution (Zhao et al., 2015).", "startOffset": 54, "endOffset": 73}, {"referenceID": 7, "context": "(2013) grouped source tweets and re-tweets into information flows (Lotan et al., 2011), then ranked these by flow size, as a proxy of significance.", "startOffset": 66, "endOffset": 86}, {"referenceID": 10, "context": "For instance, Procter et al. (2013) grouped source tweets and re-tweets into information flows (Lotan et al.", "startOffset": 14, "endOffset": 36}, {"referenceID": 6, "context": "(2013) grouped source tweets and re-tweets into information flows (Lotan et al., 2011), then ranked these by flow size, as a proxy of significance. Information flows were then categorised manually. Along similar vein, Mendoza et al. (2010) found that users deal with true and false rumours differently: the former are affirmed more than 90% of the time, whereas the latter are challenged (questioned or denied) 50% of the time.", "startOffset": 67, "endOffset": 240}, {"referenceID": 4, "context": "Friggeri et al. (2014) analyzed a set rumours from the Snopes.", "startOffset": 0, "endOffset": 23}, {"referenceID": 15, "context": "With respect to automatic methods for detecting misinformation and disinformation in social media, Ratkiewicz et al. (2011) detect political abuse (a kind of disinformation) spread through Twitter.", "startOffset": 99, "endOffset": 124}, {"referenceID": 2, "context": "Castillo et al. (2013) proposed methods for identifying newsworthy information cascades on Twitter and then classifying these cascades as credible and not credible.", "startOffset": 0, "endOffset": 23}, {"referenceID": 17, "context": "Early rumour identification is the focus of Zhao et al. (2015), where regular expressions are", "startOffset": 44, "endOffset": 63}, {"referenceID": 14, "context": "The work most relevant to ours is due to Qazvinian et al. (2011). Their method first carries out rumour retrieval, whereby tweets are clas-", "startOffset": 41, "endOffset": 65}, {"referenceID": 14, "context": "Moreover, unlike Qazvinian et al. (2011), we consider the multi-class classification problem and do not collaps questioning and denying tweets into a single class, since they differ significantly.", "startOffset": 17, "endOffset": 41}, {"referenceID": 13, "context": "The dataset was analysed and annotated manually as supporting, questioning, or denying a rumour, by a team of social scientists studying the role of social media during the riots (Procter et al., 2013).", "startOffset": 179, "endOffset": 201}, {"referenceID": 9, "context": "As can be seen from the dataset overview in Table 2, different rumours exhibit varying proportions of supporting, denying and questioning tweets, which was also observed in other studies of rumours (Mendoza et al., 2010; Qazvinian et al., 2011).", "startOffset": 198, "endOffset": 244}, {"referenceID": 14, "context": "As can be seen from the dataset overview in Table 2, different rumours exhibit varying proportions of supporting, denying and questioning tweets, which was also observed in other studies of rumours (Mendoza et al., 2010; Qazvinian et al., 2011).", "startOffset": 198, "endOffset": 244}, {"referenceID": 17, "context": "rumour detection (Zhao et al., 2015).", "startOffset": 17, "endOffset": 36}, {"referenceID": 5, "context": "to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015).", "startOffset": 87, "endOffset": 180}, {"referenceID": 1, "context": "to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015).", "startOffset": 87, "endOffset": 180}, {"referenceID": 12, "context": "to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015).", "startOffset": 87, "endOffset": 180}, {"referenceID": 12, "context": "cent work on occupational class classification (Preotiuc-Pietro et al., 2015).", "startOffset": 47, "endOffset": 77}, {"referenceID": 0, "context": "To handle this with GPC, we use a multiple output model based on the Intrinsic Coregionalisation Model (ICM; (\u00c1lvarez et al., 2012)).", "startOffset": 109, "endOffset": 131}, {"referenceID": 1, "context": "(Beck et al., 2014) and it can also be applied to classification ones.", "startOffset": 0, "endOffset": 19}, {"referenceID": 11, "context": "(Owoputi et al., 2013).", "startOffset": 0, "endOffset": 22}, {"referenceID": 6, "context": "In all cases, simple retweets are removed from the training set to prevent bias (Llewellyn et al., 2014).", "startOffset": 80, "endOffset": 104}, {"referenceID": 2, "context": "Although the focus here is on classifying community reactions, Castillo et al. (2013) showed that community reaction is correlated with actual rumour veracity.", "startOffset": 63, "endOffset": 86}, {"referenceID": 8, "context": "For example, the rumour diffusion pattern (Lukasik et al., 2015) may be a useful cue for judgement classification.", "startOffset": 42, "endOffset": 64}], "year": 2015, "abstractText": "Social media is a rich source of rumours and corresponding community reactions. Rumours reflect different characteristics, some shared and some individual. We formulate the problem of classifying tweet level judgements of rumours as a supervised learning task. Both supervised and unsupervised domain adaptation are considered, in which tweets from a rumour are classified on the basis of other annotated rumours. We demonstrate how multi-task learning helps achieve good results on rumours from the 2011 England riots.", "creator": "LaTeX with hyperref package"}}}