{"id": "1506.01972", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Jun-2015", "title": "Improved SVRG for Non-Strongly-Convex or Sum-of-Non-Convex Objectives", "abstract": "We revisit an important class of composite stochastic minimization problems that often arises from empirical risk minimization settings, such as Lasso, Ridge Regression, and Logistic Regression.", "histories": [["v1", "Fri, 5 Jun 2015 17:00:43 GMT  (1648kb,D)", "http://arxiv.org/abs/1506.01972v1", null], ["v2", "Fri, 5 Feb 2016 20:55:39 GMT  (879kb,D)", "http://arxiv.org/abs/1506.01972v2", null], ["v3", "Fri, 27 May 2016 19:14:20 GMT  (1411kb,D)", "http://arxiv.org/abs/1506.01972v3", "improved writing and included more experiments in this version"]], "reviews": [], "SUBJECTS": "cs.LG cs.DS math.OC stat.ML", "authors": ["zeyuan allen zhu", "yang yuan"], "accepted": true, "id": "1506.01972"}, "pdf": {"name": "1506.01972.pdf", "metadata": {"source": "CRF", "title": "UniVR: A Universal Variance Reduction Framework for Proximal Stochastic Gradient Method", "authors": ["Zeyuan Allen-Zhu", "Yang Yuan"], "emails": ["zeyuan@csail.mit.edu", "yangyuan@cs.cornell.edu"], "sections": [{"heading": "1 Introduction", "text": "In this paper, we look at the following problems, which we place in this category."}, {"heading": "2 Algorithm Description", "text": "We assume that each fi (\u00b7) is convex, differentiable, and L-smooth (or has a continuous course of L-Lipschitz): that our algorithm for the non-strongly convex case is represented in algorithm 1. In view of an initial vector x\u03c6, our algorithm is divided into S. The s-th epoch consists of ms stochastic gradient steps (see line 8 of UniVR), in which ms is doubled between two consecutive epochs. This \"duplication\" distinguishes our method from all quoted variance reduction methods. In each epoch, similar to SVRG [6, 19], we calculate the complete duplication of the Unix."}, {"heading": "3 Related Work", "text": "If the full gradient is used at each step of the complete gradient, a simple gradient descendant algorithm converges into O (L / \u03b5) steps and therefore has a gradient complexity O (nL / \u03b5) (see, for example, the Nesterov textbook [10]). However, this has been improved to O (n \u00b0 L / \u03b5) and O (n \u00b0 L / \u03b5) using the accelerated gradient method of Nesterov [9]. However, even if the standard and accelerated versions of the two methods gradient complexity O (n \u00b0 L / \u03b5) and O (n \u00b0 L / \u03c3 log descent) and the big data scenario (i.e.) such performances are often unsatisfactory, a growing amount of attention has been paid in the direction of stochastic gradient descent (SGD) over the last two decades."}, {"heading": "4 Analysis for the Non-Strongly Convex Case", "text": "For each outer iteration s [S] and inner iteration t [0, 1,.., ms \u2212 1] of the UniVR, we have assumed the selected random index i [n] and the random course of the course in this column that the initial objective distance to the minima, F (xx) \u2212 F (x) \u2212 F (x) \u2212 x) is a constant for a clean comparation. bFollowing the tradition of machine learning literature, we have assumed in this column that for the initial vector xp \u2212 F (x) \u2212 F (x) \u2212 F (x) \u2212 F (x) \u2212 F (x) \u2212 f (f) \u2212 f) are the constants for a clean comparation. cThis can be reduced to O (d + n) if the total number of iterations is specified."}, {"heading": "5 Experiment", "text": "In this section we confirm our theoretical results with three real datasets: \u2022 (1) the adult dataset (32, 561 examples and 123 features), (2) the covtype dataset (581, 012 examples and 54 features), and (3) the 2nd class of the MNIST dataset (60, 000 examples and 780 features), (2) the covtype dataset (581, 012 examples and 54 features), and (3) the 2nd class of the MNIST dataset (60, 000 examples and 780 features), (1) and (2) the target size of the target sizes of the target sizes, lasso and LR do not admit strongly convex objective, while RR has a strongly convex objective goal."}, {"heading": "A Proof of Lemma 4.2", "text": "f, f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f (f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f), f (f), f (f), f (f), f (f), f (f), f), f (f), f), f (f), f), f), f), f (f), f (f), f), f), f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f f, f f, f, f f, f f, f, f, f, f), f), f (f), f, f), f, f), f, f), f, f), f, f), f), f, f), f, f), f, f, f), f, f), f, f, f), f, f, f, f), f, f), f, f, f), f, f), f, f, f), f, f, f, f, f, f), f, f, f), f, f, f, f, f, f), f, f, f, f, f, f, f, f), f, f, f, f, f, f, f, f, f, f), f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f,"}, {"heading": "B Analysis for the Strongly Convex Case", "text": "In this section we show that if we assume that it is a strongly convex part, we can also modify our algorithm UniVRsc for the strongly convex case so that it has a gradient corresponding to the state of art for the strongly convex case. \u2212 \u2212 \u2212 Our algorithm UniVRsc for the strongly convex case is represented in algorithm 2. \u2212 Our algorithm is again subdivided into S-epochs, in which each epoch has the length m for the same m. Unlike UniVR, we choose a weighted average x s 1: 1 (1 \u2212 2). \u2212 We have an initial vector xp = 1 xst (1 \u2212 2). \u2212 xst (1 \u2212 2) t ratherthan has a uniform average x: m t = 1 x s in each epoch.As in section 4, for each outer iteration."}], "references": [{"title": "SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives", "author": ["Aaron Defazio", "Francis Bach", "Simon Lacoste-Julien"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Finito: A Faster, Permutable Incremental Gradient Method for Big Data Problems", "author": ["Aaron J. Defazio", "Tib\u00e9rio S. Caetano", "Justin Domke"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "LIBSVM Data: Classification, Regression and Multi-label", "author": ["Rong-En Fan", "Chih-Jen Lin"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Elad Hazan", "Amit Agarwal", "Satyen Kale"], "venue": "Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "An Accelerated Proximal Coordinate Gradient Method and its Application to Regularized Empirical Risk Minimization", "author": ["Qihang Lin", "Zhaosong Lu", "Lin Xiao"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Incremental Majorization-Minimization Optimization with Application to Large-Scale Machine Learning", "author": ["Julien Mairal"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "A method of solving a convex programming problem with convergence rate O(1/k)", "author": ["Yurii Nesterov"], "venue": "In Doklady AN SSSR (translated as Soviet Mathematics Doklady),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1983}, {"title": "Introductory Lectures on Convex Programming Volume: A Basic course, volume I", "author": ["Yurii Nesterov"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2004}, {"title": "Feature selection, L1 vs. L2 regularization, and rotational invariance", "author": ["Andrew Y. Ng"], "venue": "In Proceedings of the 21st International Conference on Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Minimizing finite sums with the stochastic average gradient", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "arXiv preprint arXiv:1309.2388,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "SDCA without Duality", "author": ["Shai Shalev-Shwartz"], "venue": "arXiv preprint arXiv:1502.06177,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Logarithmic regret algorithms for strongly convex repeated games", "author": ["Shai Shalev-Shwartz", "Yoram Singer"], "venue": "Technical report,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2007}, {"title": "Proximal Stochastic Dual Coordinate Ascent", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "arXiv preprint arXiv:1211.2717,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "Regression shrinkage and selection via the lasso", "author": ["Robert Tibshirani"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1996}, {"title": "A Proximal Stochastic Gradient Method with Progressive Variance Reduction", "author": ["Lin Xiao", "Tong Zhang"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Solving large scale linear prediction problems using stochastic gradient descent algorithms", "author": ["Tong Zhang"], "venue": "In Proceedings of the 21st International Conference on Machine Learning,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk Minimization", "author": ["Yuchen Zhang", "Lin Xiao"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}], "referenceMentions": [{"referenceID": 18, "context": "Since the computation of \u2207fi(x) is usually n times faster than that of \u2207f(x), SGD has been successfully applied to many large-scale learning problems, see for instance [1, 20].", "startOffset": 168, "endOffset": 175}, {"referenceID": 0, "context": "More recently, the convergence speed of SGD has been improved to a next level [2, 3, 6, 8, 12, 15, 16, 19].", "startOffset": 78, "endOffset": 106}, {"referenceID": 1, "context": "More recently, the convergence speed of SGD has been improved to a next level [2, 3, 6, 8, 12, 15, 16, 19].", "startOffset": 78, "endOffset": 106}, {"referenceID": 4, "context": "More recently, the convergence speed of SGD has been improved to a next level [2, 3, 6, 8, 12, 15, 16, 19].", "startOffset": 78, "endOffset": 106}, {"referenceID": 6, "context": "More recently, the convergence speed of SGD has been improved to a next level [2, 3, 6, 8, 12, 15, 16, 19].", "startOffset": 78, "endOffset": 106}, {"referenceID": 10, "context": "More recently, the convergence speed of SGD has been improved to a next level [2, 3, 6, 8, 12, 15, 16, 19].", "startOffset": 78, "endOffset": 106}, {"referenceID": 13, "context": "More recently, the convergence speed of SGD has been improved to a next level [2, 3, 6, 8, 12, 15, 16, 19].", "startOffset": 78, "endOffset": 106}, {"referenceID": 14, "context": "More recently, the convergence speed of SGD has been improved to a next level [2, 3, 6, 8, 12, 15, 16, 19].", "startOffset": 78, "endOffset": 106}, {"referenceID": 17, "context": "More recently, the convergence speed of SGD has been improved to a next level [2, 3, 6, 8, 12, 15, 16, 19].", "startOffset": 78, "endOffset": 106}, {"referenceID": 4, "context": "One particular way to reduce the variance can be described as follows (see for instance Johnson and Zhang [6]).", "startOffset": 106, "endOffset": 109}, {"referenceID": 1, "context": "1) when the objective function F (x) is strongly convex [3, 6, 15, 16, 19].", "startOffset": 56, "endOffset": 74}, {"referenceID": 4, "context": "1) when the objective function F (x) is strongly convex [3, 6, 15, 16, 19].", "startOffset": 56, "endOffset": 74}, {"referenceID": 13, "context": "1) when the objective function F (x) is strongly convex [3, 6, 15, 16, 19].", "startOffset": 56, "endOffset": 74}, {"referenceID": 14, "context": "1) when the objective function F (x) is strongly convex [3, 6, 15, 16, 19].", "startOffset": 56, "endOffset": 74}, {"referenceID": 17, "context": "1) when the objective function F (x) is strongly convex [3, 6, 15, 16, 19].", "startOffset": 56, "endOffset": 74}, {"referenceID": 16, "context": "This is particularly true for Lasso [18] and `1-Regularized Logistic Regression [11], two cornerstone problems extensively used for feature selections.", "startOffset": 36, "endOffset": 40}, {"referenceID": 9, "context": "This is particularly true for Lasso [18] and `1-Regularized Logistic Regression [11], two cornerstone problems extensively used for feature selections.", "startOffset": 80, "endOffset": 84}, {"referenceID": 0, "context": "Another possible solution is to tackle the non-strongly convex case directly [2, 8, 12], without using any dummy regularizer.", "startOffset": 77, "endOffset": 87}, {"referenceID": 6, "context": "Another possible solution is to tackle the non-strongly convex case directly [2, 8, 12], without using any dummy regularizer.", "startOffset": 77, "endOffset": 87}, {"referenceID": 10, "context": "Another possible solution is to tackle the non-strongly convex case directly [2, 8, 12], without using any dummy regularizer.", "startOffset": 77, "endOffset": 87}, {"referenceID": 4, "context": "Finally, in both cases, UniVR demands a memory storage ofO(d), matching the best known memory requirement of SVRG [6], and is much cheaper thanO(nd) as required by many others (either direct or indirect methods).", "startOffset": 114, "endOffset": 117}, {"referenceID": 4, "context": "Within each epoch, similar to SVRG [6, 19], we compute the full gradient \u03bc\u0303s\u22121 = \u2207f(x\u0303s\u22121) where x\u0303s\u22121 is the average point of the previous epoch.", "startOffset": 35, "endOffset": 42}, {"referenceID": 17, "context": "Within each epoch, similar to SVRG [6, 19], we compute the full gradient \u03bc\u0303s\u22121 = \u2207f(x\u0303s\u22121) where x\u0303s\u22121 is the average point of the previous epoch.", "startOffset": 35, "endOffset": 42}, {"referenceID": 8, "context": "If the full gradient is used at each step of the algorithm, a simple gradient descent algorithm converges in O(L/\u03b5) steps and therefore has a gradient complexity O(nL/\u03b5) (see for instance the textbook of Nesterov [10]).", "startOffset": 213, "endOffset": 217}, {"referenceID": 7, "context": "This has been improved to O(n \u221a L/\u03b5) using Nesterov\u2019s accelerated gradient method [9].", "startOffset": 82, "endOffset": 85}, {"referenceID": 18, "context": "When the use of the full gradient \u2207f(x) is simply replaced with a stochastic gradient \u03bet = \u2207fi(xt), SGD achieves a convergence rate of O(1/\u03b5) [20, 22].", "startOffset": 142, "endOffset": 150}, {"referenceID": 3, "context": "Later, a faster O(1/\u03b5) convergence rate was discovered for functions that are strongly convex [5, 14].", "startOffset": 94, "endOffset": 101}, {"referenceID": 12, "context": "Later, a faster O(1/\u03b5) convergence rate was discovered for functions that are strongly convex [5, 14].", "startOffset": 94, "endOffset": 101}, {"referenceID": 10, "context": "The first published method that reduces the variance and overcomes the previous barrier of SGD methods is due to Schmidt, Le Roux, and Bach [12].", "startOffset": 140, "endOffset": 144}, {"referenceID": 3, "context": ", linear convergence) for strongly convex and smooth objectives, comparing to the O(1/\u03b5) convergence rate of the standard SGD [5, 14], matching that of the full gradient descent [10].", "startOffset": 126, "endOffset": 133}, {"referenceID": 12, "context": ", linear convergence) for strongly convex and smooth objectives, comparing to the O(1/\u03b5) convergence rate of the standard SGD [5, 14], matching that of the full gradient descent [10].", "startOffset": 126, "endOffset": 133}, {"referenceID": 8, "context": ", linear convergence) for strongly convex and smooth objectives, comparing to the O(1/\u03b5) convergence rate of the standard SGD [5, 14], matching that of the full gradient descent [10].", "startOffset": 178, "endOffset": 182}, {"referenceID": 6, "context": "For instance, the authors of MISO [8], Finito [3], and SAGA [2] have defined \u03bet to be of a form slightly different from SAG.", "startOffset": 34, "endOffset": 37}, {"referenceID": 1, "context": "For instance, the authors of MISO [8], Finito [3], and SAGA [2] have defined \u03bet to be of a form slightly different from SAG.", "startOffset": 46, "endOffset": 49}, {"referenceID": 0, "context": "For instance, the authors of MISO [8], Finito [3], and SAGA [2] have defined \u03bet to be of a form slightly different from SAG.", "startOffset": 60, "endOffset": 63}, {"referenceID": 4, "context": "The authors of SVRG [6] (and its follow-up work Prox-SVRG [19]) have adopted the idea of \u201cepochs\u201d and defined \u03bet = \u2207if(xt) \u2212 \u2207if(xt) + \u2207f(x\u0303) like we do in this paper.", "startOffset": 20, "endOffset": 23}, {"referenceID": 17, "context": "The authors of SVRG [6] (and its follow-up work Prox-SVRG [19]) have adopted the idea of \u201cepochs\u201d and defined \u03bet = \u2207if(xt) \u2212 \u2207if(xt) + \u2207f(x\u0303) like we do in this paper.", "startOffset": 58, "endOffset": 62}, {"referenceID": 14, "context": "The algorithm SDCA [16] has also been discovered to be intrinsically performing some \u201cvariance reduction\u201d procedure [2, 6, 13].", "startOffset": 19, "endOffset": 23}, {"referenceID": 0, "context": "The algorithm SDCA [16] has also been discovered to be intrinsically performing some \u201cvariance reduction\u201d procedure [2, 6, 13].", "startOffset": 116, "endOffset": 126}, {"referenceID": 4, "context": "The algorithm SDCA [16] has also been discovered to be intrinsically performing some \u201cvariance reduction\u201d procedure [2, 6, 13].", "startOffset": 116, "endOffset": 126}, {"referenceID": 11, "context": "The algorithm SDCA [16] has also been discovered to be intrinsically performing some \u201cvariance reduction\u201d procedure [2, 6, 13].", "startOffset": 116, "endOffset": 126}, {"referenceID": 15, "context": "In this structured case, the accelerated SDCA method [17], along with subsequent works APCG [7] and SPDC [21], obtains a slightly better gradient complexity O (( n + min { L/\u03b5, \u221a nL/\u03b5 }) log 1\u03b5 ) .", "startOffset": 53, "endOffset": 57}, {"referenceID": 5, "context": "In this structured case, the accelerated SDCA method [17], along with subsequent works APCG [7] and SPDC [21], obtains a slightly better gradient complexity O (( n + min { L/\u03b5, \u221a nL/\u03b5 }) log 1\u03b5 ) .", "startOffset": 92, "endOffset": 95}, {"referenceID": 19, "context": "In this structured case, the accelerated SDCA method [17], along with subsequent works APCG [7] and SPDC [21], obtains a slightly better gradient complexity O (( n + min { L/\u03b5, \u221a nL/\u03b5 }) log 1\u03b5 ) .", "startOffset": 105, "endOffset": 109}, {"referenceID": 4, "context": "SVRG [6] Prox-SVRG [19] yes O(d) O ( (n+ L \u03c3 ) log 1 \u03b5 ) no O ( (n+ L \u03b5 ) log 1 \u03b5 )", "startOffset": 5, "endOffset": 8}, {"referenceID": 17, "context": "SVRG [6] Prox-SVRG [19] yes O(d) O ( (n+ L \u03c3 ) log 1 \u03b5 ) no O ( (n+ L \u03b5 ) log 1 \u03b5 )", "startOffset": 19, "endOffset": 23}, {"referenceID": 1, "context": "Finito [3] no O(nd) O ( n log L/\u03c3 \u03b5 ) (only when n \u2265 L/\u03c3) no -", "startOffset": 7, "endOffset": 10}, {"referenceID": 14, "context": "SDCA [16] Prox-SDCA [15] yes O(Td+ n) c O ( (n+ L \u03c3 ) log L/\u03c3+n \u03b5 ) no O ( (n+ L \u03b5 ) log L+n \u03b5 )", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "SDCA [16] Prox-SDCA [15] yes O(Td+ n) c O ( (n+ L \u03c3 ) log L/\u03c3+n \u03b5 ) no O ( (n+ L \u03b5 ) log L+n \u03b5 )", "startOffset": 20, "endOffset": 24}, {"referenceID": 6, "context": "MISO [8] no O(nd) O ( nL \u03c3 log L/\u03c3 \u03b5 )", "startOffset": 5, "endOffset": 8}, {"referenceID": 10, "context": "SAG [12] no O(nd) O ( (n+ L \u03c3 ) log L/(\u03c3n)+1 \u03b5 ) yes O ( n+L \u03b5 )", "startOffset": 4, "endOffset": 8}, {"referenceID": 0, "context": "SAGA [2] yes O(nd) O ( (n+ L \u03c3 ) log min{L/\u03c3,n} \u03b5 ) yes O ( n+L \u03b5 )", "startOffset": 5, "endOffset": 8}, {"referenceID": 0, "context": "[2, 6, 19]).", "startOffset": 0, "endOffset": 10}, {"referenceID": 4, "context": "[2, 6, 19]).", "startOffset": 0, "endOffset": 10}, {"referenceID": 17, "context": "[2, 6, 19]).", "startOffset": 0, "endOffset": 10}, {"referenceID": 2, "context": "In this section, we confirm our theoretical findings using three real-life datasets: (1) the Adult dataset (32, 561 examples and 123 features), (2) the Covtype dataset (581, 012 examples and 54 features), and (3) the 2nd class of the MNIST dataset (60, 000 examples and 780 features) [4].", "startOffset": 284, "endOffset": 287}, {"referenceID": 15, "context": "Following [17], we have normalized each feature vector to have Euclidean norm 1.", "startOffset": 10, "endOffset": 14}, {"referenceID": 4, "context": "\u2022 SVRG [6, 19] with (their suggested) epoch size m = 2n and step size \u03b7 = 0.", "startOffset": 7, "endOffset": 14}, {"referenceID": 17, "context": "\u2022 SVRG [6, 19] with (their suggested) epoch size m = 2n and step size \u03b7 = 0.", "startOffset": 7, "endOffset": 14}, {"referenceID": 10, "context": "\u2022 SAG [12] and SAGA [2] both with step size 0.", "startOffset": 6, "endOffset": 10}, {"referenceID": 0, "context": "\u2022 SAG [12] and SAGA [2] both with step size 0.", "startOffset": 20, "endOffset": 23}, {"referenceID": 13, "context": "3 \u2022 SDCA [15, 16] with both their Option I (steepest descent) and Option IV (constant step size).", "startOffset": 9, "endOffset": 17}, {"referenceID": 14, "context": "3 \u2022 SDCA [15, 16] with both their Option I (steepest descent) and Option IV (constant step size).", "startOffset": 9, "endOffset": 17}], "year": 2017, "abstractText": "We revisit an important class of composite stochastic minimization problems that often arises from empirical risk minimization settings, such as Lasso, Ridge Regression, and Logistic Regression. We present a new algorithm UniVR based on stochastic gradient descent with variance reduction. Our algorithm supports non-strongly convex objectives directly, and outperforms all of the state-of-the-art algorithms, including both direct algorithms (SAG, MISO, and SAGA) and indirect algorithms (SVRG, ProxSVRG, SDCA, ProxSDCA, and Finito) for such objectives. Our algorithm supports strongly convex objectives as well, and matches the best known linear convergence rate. Experiments support our theory. As a result, UniVR closes an interesting gap in the literature because all the existing direct algorithms for the non-strongly convex case perform much slower than the indirect algorithms. We thus believe that UniVR provides a unification between the strongly and the non-strongly convex stochastic minimization theories.", "creator": "LaTeX with hyperref package"}}}