{"id": "1506.02162", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2015", "title": "Learning from Rational Behavior: Predicting Solutions to Unknown Linear Programs", "abstract": "We define and study the problem of predicting the solution to a linear program, given only partial information about its objective and constraints. This generalizes the problem of learning to predict the purchasing behavior of a rational agent who has an unknown objective function, which has been studied under the name \"Learning from Revealed Preferences\". We give mistake bound learning algorithms in two settings: in the first, the objective of the linear program is known to the learner, but there is an arbitrary, fixed set of constraints which are unknown. Each example given to the learner is defined by an additional, known constraint, and the goal of the learner is to predict the optimal solution of the linear program given the union of the known and unknown constraints. This models, among other things, the problem of predicting the behavior of a rational agent whose goals are known, but whose resources are unknown. In the second setting, the objective of the linear program is unknown, and changing in a controlled way. The constraints of the linear program may also change every day, but are known. An example is given by a set of constraints and partial information about the objective, and the task of the learner is again to predict the optimal solution of the partially known linear program.", "histories": [["v1", "Sat, 6 Jun 2015 15:10:25 GMT  (351kb,D)", "https://arxiv.org/abs/1506.02162v1", null], ["v2", "Sun, 8 May 2016 20:07:43 GMT  (865kb,D)", "http://arxiv.org/abs/1506.02162v2", null], ["v3", "Wed, 26 Oct 2016 16:41:01 GMT  (651kb,D)", "http://arxiv.org/abs/1506.02162v3", "The short version of this paper appears in the proceedings of NIPS-16"]], "reviews": [], "SUBJECTS": "cs.DS cs.GT cs.LG", "authors": ["shahin jabbari", "ryan m rogers", "aaron roth", "steven z wu"], "accepted": true, "id": "1506.02162"}, "pdf": {"name": "1506.02162.pdf", "metadata": {"source": "CRF", "title": "Learning from Rational Behavior: Predicting Solutions to Unknown Linear Programs", "authors": ["Shahin Jabbari", "Ryan Rogers", "Aaron Roth", "Zhiwei Steven Wu"], "emails": ["{jabbari@cis,", "ryrogers@sas,", "aaroth@cis,", "wuzhiwei@cis}.upenn.edu"], "sections": [{"heading": "1 Introduction", "text": "We initiate the systematic study of a general class of multidimensional prediction problems where the learner wants to predict the solution of an unknown linear program (LP), since some partial information is available either about the composition of the constraints or the goal. In the specific case where there is a single objective constraint that changes, and the goal that is unknown and fixed, this problem was investigated under the name Learning of Obvious Preferences [1, 2, 3, 16] and encompasses the following scenario: a buyer with an unknown linear utility function over d goods u: Rd \u2192 R defined as u (x) x faces a purchase decision every day. On the day, she observes a series of prices that Rd-0 and buys the bundle of goods that maximize their unknown utility, subject to a budget: x (t) argmax x x so-called purchase decisions."}, {"heading": "1.1 Our Results", "text": "In this model, the learner encounters an arbitrary sequence of examples online and has to make a prediction for the sequence of examples. If the learner is stronger than (and implies), the goal is to find an upper limit on the sequence of mistakes the learner can make."}, {"heading": "1.2 Related Work", "text": "Beigman and Vohra [3] were the first to investigate preference problems (RPP) as learning problems and correlate them with multidimensional classifications; they derived sample complexity limits for such problems by calculating the fat-shaking dimension of the class of target benefit functions; and they showed that the set of Lipschitz continuous assessment functions had finite fat-shaking dimensions. Zadimoghaddam and Roth [16] provided efficient algorithms with polynomial sample complexity for RPP PAC learning over the class of linear (and piecewise linear) utility functions. Balcan et al. [2] showed a link between RPP and the structured prediction problem of learning d-dimensional linear classes [7, 8, 12] and use an efficient variant of the compression techniques given by Daniely and Shalev-Shwartz."}, {"heading": "2 Model and Preliminaries", "text": "We first define the geometric terms used in this work. A hyperplane and a half space in Rd are the set of points satisfying the linear equation a1x1 +. A adxd = b) and the linear inequality a1x1 +. A adxd \u2264 b for a set of ais respectively, provided that not all ai's are zero at the same time. A set of hyperplanes is linearly independent if the normal vectors to the hyperplanes are linearly independent. A polytopic (referred to by P'Rd) is the bounded intersection of finitely many half spaces, written as P = {x | Ax \u2264 b}. A edge space e of a polytopic P is a one dimensional subspace that is the intersection of d \u2212 1 linearly independent hyperplanes of P, and an edge is the intersection between an edge-space e and the polytope P.We denote the set of edges of polytope by EP."}, {"heading": "3 The Known Objective Problem", "text": "We assume that the number of people living in a country in which they live is very high. (...) We assume that the number of people living in another country is very high. (...) We assume that the number of people living in another country is very high. (...) We assume that the number of people living in another country is very high. (...) We assume that the number of people living in another country is very high. (...) We assume that the number of people living in another country in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live. (...) We assume that the number of people living in another country in which they live, in which they live, in which they live, in which they live, in which they live, in which they live. (...) We assume that the number of people living in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they, in which they, in which they live, in a country, in which they, in which they live, in which they, in which they, in a country, in which they, in which, in which they, in which they, in"}, {"heading": "3.3 Necessity of the Precision Bound", "text": "We show the necessity of assumption 3 by showing that the dependence on the precision parameter N is narrow within our margin of error. We show that under assumption 3 there is a polytopic and a sequence of additional constraints, so that each learning algorithm will make mistakes. This implies that it is impossible to learn with finite errors without a limit of precision. Sentence 8. For each learning algorithm A in the known objective problem and each d \u2265 3 there is a polytopeP and a sequence of additional constraints {N (t)} t, so that the number of errors made by A is at least \u0432 (N)."}, {"heading": "3.4 Stochastic Setting", "text": "The lower boundary implies that we must say goodbye to any point (p, b) that corresponds to half the space N = {x}. We do not make assumptions about the shape of D and require our boundaries to keep our boundaries. We describe each point (p, b) that corresponds to the shape of D = {x}. We do not make assumptions about the shape of D and require our decisions about all decisions of D. We describe each point (p, b) that of D = {x}. We do not make assumptions about the shape of D and require that we be in the worst of all decisions of D. We describe that each point is pursued on the basis of the following high level: LearnHull tracks the convex hull hull C (t \u2212 1) of all observed solutions to the day. LearnHull then behaves as if this convex hull is the entire feasible region."}, {"heading": "4 The Known Constraints Problem", "text": "We consider the known limitations as a problem in which the learner observes the changing limitations of the psyche. (We assume that we observe the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche, the psyche of the psyche of the psyche of the psyche, the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the psyche of the p"}, {"heading": "A Polynomial Mistake Bound with Exponential Running Time", "text": "In this section, we will give a simple randomized algorithm for the unknown constraints, which, in anticipation of a number of errors that are only linear in dimension d, will indicate the number of lines in the unknown delimitation matrix A (denoted by m), and the bit accuracy N, which requires exponential runtime. If the number of lines is large, this may represent an exponential improvement over the LearnEdge margin of error, which is linear in the number of edges on the polytopic P, which we will shortly describe, is a randomized variant of the known halving algorithms [13]. We will leave it as an open problem whether the error achieved by this algorithm is also formed by a computationally efficient algorithm.Let K form the hypothesis class of all polytopes, so that each entry can be written in d dimensions."}, {"heading": "B Missing Proofs from Section 3", "text": "B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B."}, {"heading": "C Circumventing the Lower Bound when d \u2264 2", "text": "In Theorem 8 (in Section 3.3), we have proved the necessity of assuming 3 by showing that the dependence on the precision parameter N is narrow within our margin of error. However, Theorem 8 requires that the dimension d be at least 3.We now show that this condition is actually necessary in the dimension - even without the finite precision assumption (Assumption 3), we can have (mathematically efficient) algorithms with small margin of error if dimension d \u2264 2. In d = 1, a maximum of two constraints are sufficient to determine any constraint matrix A, because the constraint matrix A defines a feasible interval on the real line. Thus, we will guess the value that maximizes the objective subject of the only known constraint. Once we have made a mistake, we must have learned the true optimum of the underlying problem, because our conjecture was impracticable."}, {"heading": "D Missing Proofs from Section 4", "text": "Theorem 20. Let P'Rd be a polytope given as the intersection of linear constraints, the Ellipsoid algorithm outputs a point p \"P\" or outputs P \"empty at most poly (d, N) iterations.We are now ready to bound the number that LearnEllipsoid algorithm outputs a point p\" or outputs P \"its empty at most poly (d, N) iterations.We are ready to bound the number of errors that LearnEllipsoid makes a theorem 13. When LearnEllipsoid algorithm outputs a point p\" P \"or outputs P\" its empty at most poly (d, N) iterations.We are ready to bound the number that LearnEllipsoid of Theorem 13. When LearnEllipsoid algoritheH (t) = W = (w1,."}], "references": [{"title": "Online learning and profit maximization from revealed preferences", "author": ["K. AMIN", "R. CUMMINGS", "L. DWORKIN", "M. KEARNS", "A. ROTH"], "venue": "In Proceedings of the 29th AAAI Conference on Artificial Intelligence", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Learning economic parameters from revealed preferences", "author": ["M. BALCAN", "A. DANIELY", "R. MEHTA", "R. URNER", "V. VAZIRANI"], "venue": "In Proceeding of the 10th International Conference on Web and Internet Economics", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Learning from revealed preference", "author": ["E. BEIGMAN", "R. VOHRA"], "venue": "In Proceedings of the 7th ACM Conference on Electronic Commerce", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Escaping the local minima via simulated annealing: Optimization of approximately convex functions", "author": ["A. BELLONI", "T. LIANG", "H. NARAYANAN", "A. RAKHLIN"], "venue": "In Proceeding of the 28th Conference on Learning Theory", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Achieving target equilibria in network routing games without knowing the latency functions", "author": ["U. BHASKAR", "K. LIGETT", "L. SCHULMAN", "C. SWAMY"], "venue": "In Proceeding of the 55th IEEE Annual Symposium on Foundations of Computer Science", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Learning what\u2019s going on: Reconstructing preferences and priorities from opaque transactions", "author": ["A. BLUM", "Y. MANSOUR", "J. MORGENSTERN"], "venue": "In Proceedings of the 16th ACM Conference on Economics and Computation", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Discriminative reranking for natural language parsing", "author": ["M. COLLINS"], "venue": "In Proceedings of the 17th International Conference on Machine Learning", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2000}, {"title": "Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms", "author": ["M. COLLINS"], "venue": "In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2002}, {"title": "Optimal learners for multiclass problems", "author": ["A. DANIELY", "S. SHALEV-SHWARTZ"], "venue": "In Proceedings of the 27th Conference on Learning Theory", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Geometric Algorithms and Combinatorial Optimization, second corrected ed., vol. 2 of Algorithms and Combinatorics", "author": ["M. GR\u00d6TSCHEL", "L. LOV\u00c1SZ", "A. SCHRIJVER"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1993}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J. LAFFERTY", "A. MCCALLUM", "F. PEREIRA"], "venue": "In Proceedings of the 18th International Conference on Machine Learning", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2001}, {"title": "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm", "author": ["N. LITTLESTONE"], "venue": "Machine Learning 2,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "Watch and learn: Optimizing from revealed preferences feedback", "author": ["A. ROTH", "J. ULLMAN", "WU"], "venue": "In Proceedings of the 48th Annual ACMSymposium on Theory of Computing", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "A theory of the learnable", "author": ["L. VALIANT"], "venue": "Communications of the ACM 27,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1984}], "referenceMentions": [{"referenceID": 0, "context": "In the special case in which there is a single known constraint that is changing and the objective that is unknown and fixed, this problem has been studied under the name learning from revealed preferences [1, 2, 3, 16] and captures the following scenario: a buyer, with an unknown linear utility function over d goods u : R \u2192 R defined as u(x) = c \u00b7 x faces a purchasing decision every day.", "startOffset": 206, "endOffset": 219}, {"referenceID": 1, "context": "In the special case in which there is a single known constraint that is changing and the objective that is unknown and fixed, this problem has been studied under the name learning from revealed preferences [1, 2, 3, 16] and captures the following scenario: a buyer, with an unknown linear utility function over d goods u : R \u2192 R defined as u(x) = c \u00b7 x faces a purchasing decision every day.", "startOffset": 206, "endOffset": 219}, {"referenceID": 2, "context": "In the special case in which there is a single known constraint that is changing and the objective that is unknown and fixed, this problem has been studied under the name learning from revealed preferences [1, 2, 3, 16] and captures the following scenario: a buyer, with an unknown linear utility function over d goods u : R \u2192 R defined as u(x) = c \u00b7 x faces a purchasing decision every day.", "startOffset": 206, "endOffset": 219}, {"referenceID": 0, "context": "Each example at day t is specified by the vector p \u2208 R\u22650 (which fixes the constraint), and the goal is to accurately predict the purchased bundle x \u2208 [0, 1] that is the result of optimizing the unknown linear objective.", "startOffset": 150, "endOffset": 156}, {"referenceID": 5, "context": "This generalizes some of the preference learning problems recently studied by Blum et al [6].", "startOffset": 89, "endOffset": 92}, {"referenceID": 11, "context": "We study both variants of the problem (see below) in the strong mistake bound model of learning [13].", "startOffset": 96, "endOffset": 100}, {"referenceID": 13, "context": "Mistake bound learnability is stronger than (and implies) PAC learnability [15].", "startOffset": 75, "endOffset": 79}, {"referenceID": 2, "context": "Beigman and Vohra [3] were the first to study revealed preference problems (RPP) as a learning problems and to relate them to multi-dimensional classification.", "startOffset": 18, "endOffset": 21}, {"referenceID": 1, "context": "[2] showed a connection between RPP and the structured prediction problem of learning d-dimensional linear classes [7, 8, 12], and use an efficient variant of the compression techniques given by Daniely and Shalev-Shwartz [9] to give efficient PAC algorithms with optimal sample complexity for various classes of economically meaningful utility functions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[2] showed a connection between RPP and the structured prediction problem of learning d-dimensional linear classes [7, 8, 12], and use an efficient variant of the compression techniques given by Daniely and Shalev-Shwartz [9] to give efficient PAC algorithms with optimal sample complexity for various classes of economically meaningful utility functions.", "startOffset": 115, "endOffset": 125}, {"referenceID": 7, "context": "[2] showed a connection between RPP and the structured prediction problem of learning d-dimensional linear classes [7, 8, 12], and use an efficient variant of the compression techniques given by Daniely and Shalev-Shwartz [9] to give efficient PAC algorithms with optimal sample complexity for various classes of economically meaningful utility functions.", "startOffset": 115, "endOffset": 125}, {"referenceID": 10, "context": "[2] showed a connection between RPP and the structured prediction problem of learning d-dimensional linear classes [7, 8, 12], and use an efficient variant of the compression techniques given by Daniely and Shalev-Shwartz [9] to give efficient PAC algorithms with optimal sample complexity for various classes of economically meaningful utility functions.", "startOffset": 115, "endOffset": 125}, {"referenceID": 8, "context": "[2] showed a connection between RPP and the structured prediction problem of learning d-dimensional linear classes [7, 8, 12], and use an efficient variant of the compression techniques given by Daniely and Shalev-Shwartz [9] to give efficient PAC algorithms with optimal sample complexity for various classes of economically meaningful utility functions.", "startOffset": 222, "endOffset": 225}, {"referenceID": 0, "context": "[1] study the RPP for linear valuation functions in the mistake bound model, and in the query model in which the learner gets to set prices and wishes to maximize profit.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "[14] also study the query model of learning and give results for strongly concave objective functions, leveraging an algorithm of Belloni et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "[4] for bandit convex optimization with adversarial noise.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[11] states that if each constraint in P \u2286 R has encoding length at most N then each vertex of P has encoding length at most 4dN .", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5], we use the Ellipsoid algorithm to learn the coefficients {v}i\u2208[n], and show that the mistake bound of the resulting algorithm is bounded by the (polynomial) running time of the Ellipsoid.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "We again point out that this is implied if the halfspaces defining the polytope are described with finite precision [11].", "startOffset": 116, "endOffset": 120}, {"referenceID": 9, "context": "2 [11]).", "startOffset": 2, "endOffset": 6}], "year": 2016, "abstractText": "We define and study the problem of predicting the solution to a linear program (LP) given only partial information about its objective and constraints. This generalizes the problem of learning to predict the purchasing behavior of a rational agent who has an unknown objective function, that has been studied under the name \u201cLearning from Revealed Preferences\". We give mistake bound learning algorithms in two settings: in the first, the objective of the LP is known to the learner but there is an arbitrary, fixed set of constraints which are unknown. Each example is defined by an additional known constraint and the goal of the learner is to predict the optimal solution of the LP given the union of the known and unknown constraints. This models the problem of predicting the behavior of a rational agent whose goals are known, but whose resources are unknown. In the second setting, the objective of the LP is unknown, and changing in a controlled way. The constraints of the LP may also change every day, but are known. An example is given by a set of constraints and partial information about the objective, and the task of the learner is again to predict the optimal solution of the partially known LP.", "creator": "LaTeX with hyperref package"}}}