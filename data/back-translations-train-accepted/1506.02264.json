{"id": "1506.02264", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2015", "title": "Visual Learning of Arithmetic Operations", "abstract": "Many learning tasks combine perceptual and cognitive (e.g. logical, symbolic) sub-tasks. In some cases end-to-end learning of the perceptual and cognitive sub-tasks can be more difficult than learning each sub-task individually. In other cases such end-to-end learning can be very efficient. As end-to-end learning is becoming more prevalent in AI, it is important to understand when this approach can work efficiently.", "histories": [["v1", "Sun, 7 Jun 2015 13:44:15 GMT  (494kb,D)", "https://arxiv.org/abs/1506.02264v1", null], ["v2", "Fri, 27 Nov 2015 12:18:48 GMT  (459kb,D)", "http://arxiv.org/abs/1506.02264v2", "To appear in AAAI 2016"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["yedid hoshen", "shmuel peleg"], "accepted": true, "id": "1506.02264"}, "pdf": {"name": "1506.02264.pdf", "metadata": {"source": "CRF", "title": "Visual Learning of Arithmetic Operations", "authors": ["Yedid Hoshen", "Shmuel Peleg"], "emails": [], "sections": [{"heading": null, "text": "The input consists of two images, each with a 7-digit number; the output, also an image, shows the number that represents the result of an arithmetic operation (e.g. addition or subtraction) on the two input numbers; the concepts of a number or an operator are not explicitly introduced; this indicates that addition is a simple cognitive task that can be learned visually with a very small number of neurons; other operations, e.g. multiplication, could not be learned with this architecture; some tasks could not be learned end-to-end (e.g. addition with Roman numerals), but were easy to learn once they were divided into two separate subtasks: a perception task for character recognition and cognitive subtasks for arithmetic. This indicates that some tasks can be easily learned end-to-end, but others must be divided into subtasks."}, {"heading": "1. Introduction", "text": "It is not only a matter of time before it will be, but also of time until it will be, until it will be, \"he told the German Press Agency.\" I don't think we will be able to get to grips with the problem, \"he said.\" But I don't think we will be able to get to grips with the problem. \"He added,\" I don't think we will be able to get to grips with the problem. \"He added,\" I don't think we will be able to get to grips with the problem. \""}, {"heading": "2. Arithmetic as Neural Frame Prediction", "text": "In this section we describe a visual protocol for learning arithmetic by predicting images. This is done by training an artificial neural network with input and output examples."}, {"heading": "2.1. Learning Arithmetic from Visual Examples", "text": "Our protocol for visual learning arithmetic is based on image prediction. For two input images F1, F2, target image E is the correct prediction. The learner is obliged to predict the output image, and the predicted image is referred to as P. The prediction loss is written by the sum of square differences (SSD) between the pixel intensities of the predicted image P and the target image E. The input numbers are randomly selected in a given range (additionally we use the range of [0,4999999]) and on the input images. The result of the arithmetic operation on the input numbers (e.g. their sum) is written on the target image E. The numbers are written on the images with a standard font and always placed at the same image position. See Figure 1 for examples. Learning consists of training the network with N such input / output examples (we use N = 150 000)."}, {"heading": "2.2. Network Architecture", "text": "In this section, we present a method to test the feasibility of learning arithmetic using the protocol shown in Sec. 2.1. Our simple but powerful learner is a fully networked artificial neural network, as shown in Fig. 2.The network consists of an input layer of dimensions Fx \u00b7 Fy \u00b7 2, where Fx and Fy are the dimensions of the two input images. We used Fx \u00b7 Fy = 15 \u00d7 60, unless otherwise specified. The network has three hidden layers, each with 256 nodes with ReLU activation functions (max (0, x)) and an output layer (of the same height and width as the input images) with sigmoid activation. All nodes between adjacent layers were fully connected."}, {"heading": "3. Experiments", "text": "The aim of this work is to investigate whether arithmetic operations with purely visual information can be learned end-to-end. For this purpose, several experiments were carried out:"}, {"heading": "3.1. Experimental Procedure", "text": "The numbers were randomly generated from a pre-defined range as detailed below. The output images were created similarly and showed the result of the arithmetic operation at the entrance. The following arithmetic operations were investigated: \u2022 Addition: sum of two 7-digit numbers, each in the range [0,4999999]. The first number was selected to be larger or equal to the second number to ensure a positive result. \u2022 Multiplication: product of two numbers, each in the range [0,3160]. \u2022 Addition of two 7-digit numbers in the range [0,9999999]. The first number was selected to be larger or equal to the second number to ensure a positive result. \u2022 Multiplication: product of two numbers, each in the range [0,3160]. \u2022 Addition of two 7-digit numbers: sum of two numbers in the range [0,4999999]. Both input and output were written in Roman numbers (IVXLCDM and other 7 digits we \"invented.\""}, {"heading": "3.2. Results", "text": "The correctness of the test set was measured using an OCR software (Tesseract [16]), which was not applied to the output images. OCR results were compared with the desired performance, and the percentage of erroneous digits was calculated. The effectiveness of the neural network approach was tested on the following operations. Supplement: Three results from the test set are shown in the figure. 1. Input and output numbers were not included in the education table. Examples show qualitatively the effectiveness of the network in complementing with purely visual information. Quantitatively, the network was able to learn the completion with great accuracy, with erroneous digital prediction rate, which is only 1.9%.Subtraction: We used a neural network with identical architecture for completion. Subtraction of a small number of a larger one was found to be of comparable difficulty to completion."}, {"heading": "4. Previous Work", "text": "The theoretical characterization of operations that can be learned through neural networks is an established field of research. A groundbreaking paper presented by [5] uses threshold circuits as a model for the capacity of neural networks. A number of papers (e.g. [8, 15, 3]) have established the feasibility of implementing several arithmetic operations on binary numbers. Recently [4] has dealt with the implementation of universal turing machines that use neural networks. Most theoretical work in the field used binary representation of numbers and addressed arithmetic operations not in decimal form. Noteworthy is a general result (see [14], which shows that operations that can be implemented by rotating machines in time T (n) are implemented through a neural network of O (n) layers and with O (n) nodes."}, {"heading": "5. Discussion", "text": "This year it will be so far that it will be able to name the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc"}, {"heading": "6. Feasibility of a Visual Addition Network", "text": "In this section, we provide a proof of feasibility by constructing a neural network architecture that can learn how to add end-to-end visual data. < p > p > p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p p = p = p = p p = p = p = p"}, {"heading": "7. Conclusions", "text": "Our neural network was able to learn addition and subtraction, and was resilient to heavy image noise; the concept of numbers was not explicitly applied; we showed that the network was not able to learn some other operations such as multiplication and visual addition using Roman numbers; for the latter, we showed that while all subtasks are easy to learn, the end-to-end task is not applicable; in order to better understand the capabilities of the network, a theoretical analysis was presented showing how a network capable of performing visual addition can be constructed; this theoretical framework can help determine whether a new arithmetic operation can be learned using a supplying DNN architecture; we point out that such an analysis is quite restrictive and the hypothesis that an experimental confirmation of end-to-end-to-end learning can lead from complex tasks to a generative solution."}], "references": [{"title": "Multiple object recognition with visual attention", "author": ["J. Ba", "V. Mnih", "K. Kavukcuoglu"], "venue": "arXiv:1412.7755", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural networks for Pattern Recognition", "author": ["C.M. Bishop"], "venue": "Oxford Univ. Press", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1995}, {"title": "Solving arithmetic problems using feed-forward neural networks", "author": ["L. Franco", "S.A. Cannas"], "venue": "Neurocomputing, 18(1):61\u201379", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1998}, {"title": "Neural turing machines", "author": ["A. Graves", "G. Wayne", "I. Danihelka"], "venue": "arXiv:1410.5401", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Threshold circuits of bounded depth", "author": ["A. Hajnal", "W. Maass", "P. Pudl\u00e1k", "M. Szegedy", "G. Turan"], "venue": "Annual Symposium on Foundations of Computer Science, pages 99\u2013110. IEEE", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1987}, {"title": "A", "author": ["A. Hannun", "C. Case", "J. Casper", "B. Catanzaro", "G. Diamos", "E. Elsen", "R. Prenger", "S. Satheesh", "S. Sengupta"], "venue": "Coates, et al. Deepspeech: Scaling up end-to-end speech recognition. arXiv:1412.5567", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, 313(5786):504\u2013507", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2006}, {"title": "Some notes on threshold circuits", "author": ["T. Hofmeister", "W. Hohberg", "S. K\u00f6hling"], "venue": "and multiplication in depth 4. In Int. Conf. Fundamentals of Computation Theory, pages 230\u2013239. Springer", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1991}, {"title": "Deep features for text spotting", "author": ["M. Jaderberg", "A. Vedaldi", "A. Zisserman"], "venue": "ECCV\u201914, pages 512\u2013 528. Springer", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "arXiv:1408.5093", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "Handwritten digit recognition with a back-propagation network", "author": ["Y. LeCun", "B.E. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W.E. Hubbard", "L.D. Jackel"], "venue": "NIPS\u201989", "citeRegEx": "11", "shortCiteRegEx": null, "year": 1990}, {"title": "Vision: A Computational Investigation into the Human Representation and Processing of Visual Information", "author": ["D. Marr"], "venue": "W.H. Freeman & Co", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1982}, {"title": "Modeling ancient and modern arithmetic practices: Addition and multiplication 7  with arabic and roman numerals", "author": ["D. Schlimm", "H. Neth"], "venue": "30th Annual Conference of the Cognitive Science Society, pages 2097\u2013 2102", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2008}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["S. Shalev-Shwartz", "S. Ben-David"], "venue": "Cambridge University Press", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Depth efficient neural networks for division and related problems", "author": ["K.-Y. Siu", "J. Bruck", "T. Kailath", "T. Hofmeister"], "venue": "IEEE Trans. Information Theory, 39(3):946\u2013956", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1993}, {"title": "An overview of the tesseract ocr engine", "author": ["R. Smith"], "venue": "Int. Conf. on Document Analysis and Recognition (ICDAR), pages 629\u2013633", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2007}, {"title": "Show and tell: A neural image caption generator", "author": ["O. Vinyals", "A. Toshev", "S. Bengio", "D. Erhan"], "venue": "arXiv:1411.4555", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Anticipating the future by watching unlabeled video", "author": ["C. Vondrick", "H. Pirsiavash", "A. Torralba"], "venue": "arXiv:1504.08023", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning to discover efficient mathematical identities", "author": ["W. Zaremba", "K. Kurach", "R. Fergus"], "venue": "NIPS\u201914, pages 1278\u20131286", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to execute", "author": ["W. Zaremba", "I. Sutskever"], "venue": "arXiv:1410.4615", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "Systems now exist for end-to-end training of image to sentence generation [17] and speech to sentence generation [6].", "startOffset": 74, "endOffset": 78}, {"referenceID": 5, "context": "Systems now exist for end-to-end training of image to sentence generation [17] and speech to sentence generation [6].", "startOffset": 113, "endOffset": 116}, {"referenceID": 1, "context": "We model the learning process as a feed-forward artificial neural network [2, 7].", "startOffset": 74, "endOffset": 80}, {"referenceID": 6, "context": "We model the learning process as a feed-forward artificial neural network [2, 7].", "startOffset": 74, "endOffset": 80}, {"referenceID": 9, "context": "The network was implemented using the Caffe package [10].", "startOffset": 52, "endOffset": 56}, {"referenceID": 15, "context": "The correctness of the test set was measured using an OCR software (Tesseract [16] ) which was applied to the output pictures.", "startOffset": 78, "endOffset": 82}, {"referenceID": 2, "context": ", [3]) has shown that multiplication of binary numbers may require two more layers than their addition, we experimented with adding more hidden layers.", "startOffset": 2, "endOffset": 5}, {"referenceID": 11, "context": "Addition of Roman numerals: It has been hypothesized by Marr [12] and others (see [13]) that arithmetic using Roman numerals can be more challenging than using Arabic numerals.", "startOffset": 61, "endOffset": 65}, {"referenceID": 12, "context": "Addition of Roman numerals: It has been hypothesized by Marr [12] and others (see [13]) that arithmetic using Roman numerals can be more challenging than using Arabic numerals.", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "A pioneering paper presented by [5] used threshold circuits", "startOffset": 32, "endOffset": 35}, {"referenceID": 7, "context": ", [8, 15, 3]) established the feasibility of the implementation of several arithmetic operations on binary numbers.", "startOffset": 2, "endOffset": 12}, {"referenceID": 14, "context": ", [8, 15, 3]) established the feasibility of the implementation of several arithmetic operations on binary numbers.", "startOffset": 2, "endOffset": 12}, {"referenceID": 2, "context": ", [8, 15, 3]) established the feasibility of the implementation of several arithmetic operations on binary numbers.", "startOffset": 2, "endOffset": 12}, {"referenceID": 3, "context": "Recently [4] has addressed implementing Universal Turing Machines using neural networks.", "startOffset": 9, "endOffset": 12}, {"referenceID": 13, "context": "Notably, a general result (see [14]), shows that operations implementable by Turing machine in time T (n) can be implemented by a neural network of O(T (n)) layers and with O(T (n)) nodes.", "startOffset": 31, "endOffset": 35}, {"referenceID": 11, "context": "Roman representations was made by Marr [12] and others.", "startOffset": 39, "endOffset": 43}, {"referenceID": 12, "context": "see [13] for a review and algorithms for Roman numeral addition and multiplication.", "startOffset": 4, "endOffset": 8}, {"referenceID": 10, "context": "Optical Character Recognition (OCR) [11, 9] is a well studied field.", "startOffset": 36, "endOffset": 43}, {"referenceID": 8, "context": "Optical Character Recognition (OCR) [11, 9] is a well studied field.", "startOffset": 36, "endOffset": 43}, {"referenceID": 19, "context": "Learning to execute Python code (including arithmetic) from textual data has been shown to be possible using LSTMs by Zaremba and Sutskever [20].", "startOffset": 140, "endOffset": 144}, {"referenceID": 0, "context": "[1].", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "In [19], Recurrent Neural Networks (RNNs) were used for algebraic expression simplification.", "startOffset": 3, "endOffset": 7}, {"referenceID": 16, "context": "End-to-end learning of Image-to-Sentence [17] and of Speech-to-Sentence [6] has been described by multiple researchers.", "startOffset": 41, "endOffset": 45}, {"referenceID": 5, "context": "End-to-end learning of Image-to-Sentence [17] and of Speech-to-Sentence [6] has been described by multiple researchers.", "startOffset": 72, "endOffset": 75}, {"referenceID": 17, "context": "[18] successfully learned to predict the objects to appear in a future video frame from several previous frames.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "The greater simplicity of our task allows us to use raw frames rather than an intermediate representation as used in [18].", "startOffset": 117, "endOffset": 121}, {"referenceID": 14, "context": "This is also justified theoretically as (i) Binary multiplication was shown by previous papers [15, 3] to require deeper networks than binary addition.", "startOffset": 95, "endOffset": 102}, {"referenceID": 2, "context": "This is also justified theoretically as (i) Binary multiplication was shown by previous papers [15, 3] to require deeper networks than binary addition.", "startOffset": 95, "endOffset": 102}, {"referenceID": 13, "context": "This means [14] that the operation is realizable only by a deeper (O(n) vs.", "startOffset": 11, "endOffset": 15}], "year": 2015, "abstractText": "A simple Neural Network model is presented for end-to-end visual learning of arithmetic operations from pictures of numbers. The input consists of two pictures, each showing a 7-digit number. The output, also a picture, displays the number showing the result of an arithmetic operation (e.g., addition or subtraction) on the two input numbers. The concepts of a number, or of an operator, are not explicitly introduced. This indicates that addition is a simple cognitive task, which can be learned visually using a very small number of neurons. Other operations, e.g., multiplication, were not learnable using this architecture. Some tasks were not learnable end-to-end (e.g., addition with Roman numerals), but were easily learnable once broken into two separate sub-tasks: a perceptual Character Recognition and cognitive Arithmetic sub-tasks. This indicates that while some tasks may be easily learnable end-to-end, other may need to be broken into sub-tasks.", "creator": "LaTeX with hyperref package"}}}