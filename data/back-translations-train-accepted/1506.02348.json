{"id": "1506.02348", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2015", "title": "Convergence Rates of Active Learning for Maximum Likelihood Estimation", "abstract": "An active learner is given a class of models, a large set of unlabeled examples, and the ability to interactively query labels of a subset of these examples; the goal of the learner is to learn a model in the class that fits the data well.", "histories": [["v1", "Mon, 8 Jun 2015 04:05:43 GMT  (16kb)", "http://arxiv.org/abs/1506.02348v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["kamalika chaudhuri", "sham m kakade", "praneeth netrapalli", "sujay sanghavi"], "accepted": true, "id": "1506.02348"}, "pdf": {"name": "1506.02348.pdf", "metadata": {"source": "CRF", "title": "Convergence Rates of Active Learning for Maximum Likelihood Estimation", "authors": ["Kamalika Chaudhuri", "Sham Kakade", "Praneeth Netrapalli", "Sujay Sanghavi"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 150 6.02 348v 1 [csPrevious theoretical work has strictly characterized the complexity of active learning, but most of this work focuses on the PAC or agnostic PAC model. In this paper, we focus our attention on a more general setting - the maximum probability estimate. Provided that certain conditions adhere to the model class, we provide a two-step active learning algorithm for this problem. The conditions we require are relatively general and cover the widespread class of generalized linear models, which in turn include models for binary and multi-level classification, regression, and conditional random fields. Our analysis shows that, unlike binary classification, in the realizable case, only a single additional round of interaction is sufficient to achieve approximately optimal performance in the maximum probability estimate."}, {"heading": "1 Introduction", "text": "The goal of the learner is to learn a model in the class with small target errors, while interactively querying the labels of as few of the unmarked samples as possible. Most theoretical work on active learning focuses on the PAC or the agnostic PAC model, in which the goal is to learn binary classifiers belonging to a particular hypothesis class [2, 13, 6, 3, 4, 22], and there are only a handful of exceptions [19, 8, 20]. In this paper, we shift our attention to a more general setting - maximum probability estimation belonging to a particular hypothesis class. [2, 9, 3, 4, 22] and there are only a handful of exceptions [19, 8, 20] that draw our attention to a more general setting - maximum probability estimation (MLE), where Pr (Y | X) is described by a model belonging to a model class."}, {"heading": "1.1 Related Work", "text": "However, the two main styles of algorithms for the unrealizable case are incompatible examples of active learning [2, 9, 4], and margin or trust-based active learning [3, 22]. While active learning in the realizable case is supposed to achieve an exponential improvement in label complexity over passive learning [2, 9, 4], the gains are more modest (sometimes a constant factor)."}, {"heading": "2 The Model", "text": "We start with a certain notation. We are given a pool U = {x1,.. ai examples of n unlabeled examples from any instance space X and the ability to interactively query labels belonging to a label space Y of these examples. In addition, we get a family of models M = {p (y | x, \u03b8), which are parameterized by a label space X. We assume that there is an unknown parameter that queries the label name of an xi-U, generates a family of models drawn from the distribution p (y | x, \u03b8). We also abuse a notation and use of U to name the uniform distribution of examples in U. We consider the fixed definition (or transductive) of the setting, where our goal is to minimize the error on the fixed set of points U. For each x x x x, y, y, x, x, we define the negative log function L (y, x)."}, {"heading": "3 Algorithm", "text": "The main idea behind our algorithm is to sample xi on the basis of a well-designed distribution level above U.Suppose the labels of these samples are generated according to the following criteria: yi-p (y-xi, \u03b8).Lemma 1 specifies that the expected logarithmic error of the ML estimate with respect to m samples from this case is essentially Tr (IB) \u2212 1IU (\u03b8)) / m.This suggests that we use a small number m1 of samples as the distribution level, which Tr (IB) \u2212 1IU (\u03b8) minimizes. Unfortunately, we cannot do this because it is not known to us. We solve this problem by means of a two-stage algorithm; in the first stage we use a small number m1 of samples to construct a rough estimation.In steps 1-2) and in the second steps IB-1 (IB-1) and in the third steps we directly form a small distribution level (IB-1 and IB-1)."}, {"heading": "4 Performance Guarantees", "text": "The following regularity conditions are essentially a quantified version of the standard Local Asymptotic Normality (LAN) conditions for studying maximum probability (see [16, 21]). Assumption 1. (Regularity conditions for LAN) 1. Smooth: The first three derivatives of L (y | x, \u03b8) exist in all inner points of Rd. 2. Compactness: There is an internal point of distribution. 3. Strong convexity: IU (both derivatives) is positively defined with smallest singular value. (xi, \u03b8). (1) Compactness is defined with minimum singular value. (Lipschitz) Continuity: There is a neighborhood B of distribution and a constant L3, so that for all x x x U, I (x). (x) L3-Lipschitz is in that neighborhood. (we) L3-Lipschitz is in that neighborhood."}, {"heading": "4.1 Discussions", "text": "Several remarks on Economy 1 are fine. The high probability that is bound in Economy 1 is in relation to the samples taken in S1; provided these samples are representative (which happens with a probability of more than 1 \u2212 \u043c), the output 2 of Algorithm 1 will fulfill (1). Moreover, Theorem 1 assumes that the labels are sampled with substitution; in other words, Economy 1 can query the etiquette of a point xi Economy. The removal of this assumption is a possibility for future work. Secondly, the highest value term is both in (1) and (2) Tr (IBA) \u2212 1IU (BA) / m. The terms that include a point xi Economy are lower than both in Economy \u00b2 and Economy \u00b2 and Economy \u00b2 are o (1). Moreover, if \u00df = Economy (1) and (2) is lower, then the term that \u03b2 is in (1) \u2212 1IU (BA) \u2212 1IU (BA) / m Economy is lower. Take note that Economy, Economy \u00b2, Economy, Economy, Economy, Economy \u00b2 and Economy \u00b2, are lower than both in m2 and Economy \u00b2 and Economy \u00b2, are o (1). Also, Economy, Economy, Economy, Economy, are lower than both in (1), Economy \u00b2, Economy, Economy, are o, and Economy \u00b2, if, Economy, Economy, is lower, Economy, Economy, Economy, Economy, Economy, and \u00b2, is lower, between, Economy and Economy, Economy, Economy, Economy, Economy, Economy, is, Economy, Economy, is, measured, m\u03b2, and Economy, and Economy, and, Economy, and, Economy, Economy, Economy, Economy, Economy, Economy, is lower, (1)."}, {"heading": "4.2 Proof Outline", "text": "Our main result is based on the following three steps:"}, {"heading": "4.2.1 Bounding the Log-likelihood Error", "text": "First, we characterize the log probability error (wrt U) of empirical risk minimization (ERM), which has been determined on the basis of a sample distribution. Specifically, let us be a distribution on U. Let us be the ERM estimate on the basis of the distribution method. Core of our analysis is Lemma 1, which shows a precise estimate of the log probability error E [LU (\u03b8) -LU (\u03b8) -3), in which Xi and Yi fulfill the regularity conditions in assumptions 1 and 2. Let us distribute U and the ERM estimate (3) on the basis of m2-marked examples. Furthermore, let us assume that institutional L fulfills the regularity conditions in assumptions 1 and 2. Let us distribute U and the ERM estimate (3) on the basis of m2-marked examples."}, {"heading": "4.2.2 Approximating \u03b8\u2217", "text": "Lemma 1 motivates sampling from the optimal sample distribution \u04451, which minimizes the number of points (m1) and solves an ML estimation problem in order to obtain a rough estimate, which we do not know. To solve this problem, our algorithm first queries the designations of a small fraction of points (m1) and then solves an ML estimation problem in order to obtain a rough estimate of the phenomenon. II, how close should \u03b81 be to regularity? Our analysis shows that for each x, I (x, \u03b81) is a constant spectral approximation to I (x); the number of samples required to achieve this is assumed in Lemma 2. Lemma 2. Lemma 2. 2. assumes that L fulfills the regularity conditions in assumptions 1 and 2. If the number of samples used in the first stages 1 > O max L2 log2 d, L21 (L23 + 1\u0445min), 2 logameters L is greater than T (max T 23 T, T is greater than T in the regularity conditions."}, {"heading": "4.2.3 Computing \u03931", "text": "Third, we are left with the task of obtaining a distribution \u04321 that minimizes the probability of an error in the log. We now present this optimization problem as SDP. From terms 1 and 2, it is clear that we should aim to obtain a sampling distribution \u04411 = (aim2: i [n]) that minimizes Tr (IC1) \u2212 1 IC1 (IC1). Let us leave IU (IC1) = IC1 IC1 (IC1) \u2212 1 vj, which corresponds to the solution: min a, cd, ICJ, ICJ (IC1), IC1 (IC1), IC1 (IC1) = IC1 IC1 (IC1) \u2212 1 vj, IC1 vj (IC1) \u2212 1 vj."}, {"heading": "5 Illustrative Examples", "text": "Next, we present some examples that illustrate theorem 1. We begin by showing that condition 1 is fulfilled by the popular class of Generalized Linear Models."}, {"heading": "5.1 Derivations for Generalized Linear Models", "text": "A generalized linear model is specified by three parameters - a linear model, a sufficient statistic, and a member of the exponential family. Let's be a linear model: \u03b7 = \u03b8 X. Then, in a generalized linear model (GLM), Y is drawn from an exponential family distribution with the parameter \u03b7. Specifically, the log probability is written as log p (y) \u2212 A (\u03b7), where t (\u00b7) is the sufficient statistic and A (\u00b7) is the log partition function. From the properties of the exponential family, the log probability results as log p (y | \u03b7) = \u03b7 t (y) \u2212 A (\u03b7). If we take the derivative with respect to the log function, we have: \"Log p (y | Celsius, x) \u0445 - x.\""}, {"heading": "5.2 Specific Examples", "text": "Our first example is linear regression. In this case, the negative logarithm function is as follows: L (y, x, x, x) = (y, x, x) = (y, x, x) = (y, x) = (y, x, x) 2, and the corresponding Fisher information matrix I (x, x) is called: I (x, x) = xx (x, x). Note that in this (very special) case, the Fisher information matrix does not depend on the distribution; as a result, we can eliminate the first two steps of the algorithm and move directly to step 3. If we are the covariance matrix of U, then theorem 1, tell us that we need the quantity of the distribution matrix."}, {"heading": "6 Conclusion", "text": "In this paper, we provide an active learning algorithm for maximum probability estimation, which has been shown to achieve the optimal convergence rate (down to lower terms) and use only two rounds of interaction; our algorithm is used in a very general environment that includes generalized linear models; there are several possibilities for future work; our algorithm involves solving a mathematically expensive SDP; an open question is whether there is a more efficient, perhaps greedy algorithm that achieves the same rate; a second open question is whether it is possible to remove the acceptance of the replacement sample; a final question is what happens when IU (\u03b8) has a high conditional number; in this case, our algorithm will require a large number of samples in the first stage; an open question is whether we can use a more sophisticated procedure to reduce the label requirement in the first stage."}, {"heading": "Acknowledgements", "text": "KC thanks the NSF under IIS 1162851 for supporting the research. Part of this work was done during a visit of KC to Microsoft Research New England."}, {"heading": "A Proofs", "text": "To prove Lemma 1, we use the following result, which is a modification of \"Q.\" In particular, the following problem is a generalization of Theorem 5.1 of \"10,\" and its proof (omitted here) arises from the generalization of the evidence that \"Q\" is another function. Lemma 4. Suppose that \"Q\" (decrypted), and \"Rd\" (decrypted), random functions are extracted from a distribution. Let P = E [decrypted] and \"Q: R\" be another function. Let \"L\" (decrypted), and \"O\" (decrypted), and \"O\" (decrypted): 1. (decrypted), that \"L\" O \"(with probability one), 2. (decrypted), 3. (decrypted), 4. (decrypted), 5. (decrypted), 5. (decrypted), 6. (decrypted), 6. (decrypted), 6. (decrypted), 6. (decrypted), 6. (decrypted), 6., 8. (decrypted), 8. (decrypted. (decrypted), 8., 8. (decrypted), 9. (decrypted., 9. (decrypted), 9. (decrypted. (decrypted), 9. (decrypted), 9."}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "An active learner is given a class of models, a large set of unlabeled examples, and the ability<lb>to interactively query labels of a subset of these examples; the goal of the learner is to learn a<lb>model in the class that fits the data well.<lb>Previous theoretical work has rigorously characterized label complexity of active learning,<lb>but most of this work has focused on the PAC or the agnostic PAC model. In this paper,<lb>we shift our attention to a more general setting \u2013 maximum likelihood estimation. Provided<lb>certain conditions hold on the model class, we provide a two-stage active learning algorithm<lb>for this problem. The conditions we require are fairly general, and cover the widely popular<lb>class of Generalized Linear Models, which in turn, include models for binary and multi-class<lb>classification, regression, and conditional random fields.<lb>We provide an upper bound on the label requirement of our algorithm, and a lower bound<lb>that matches it up to lower order terms. Our analysis shows that unlike binary classification in<lb>the realizable case, just a single extra round of interaction is sufficient to achieve near-optimal<lb>performance in maximum likelihood estimation. On the empirical side, the recent work in [11]<lb>and [12] (on active linear and logistic regression) shows the promise of this approach.", "creator": "LaTeX with hyperref package"}}}