{"id": "1506.03039", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jun-2015", "title": "Measuring Sample Quality with Stein's Method", "abstract": "To improve the efficiency of Monte Carlo estimation, practitioners are turning to biased Markov chain Monte Carlo procedures that trade off asymptotic exactness for computational speed. The reasoning is sound: a reduction in variance due to more rapid sampling can outweigh the bias introduced. However, the inexactness creates new challenges for sampler and parameter selection, since standard measures of sample quality like effective sample size do not account for asymptotic bias. To address these challenges, we introduce a new computable quality measure based on Stein's method that bounds the discrepancy between sample and target expectations over a large class of test functions. We use our tool to compare exact, biased, and deterministic sample sequences and illustrate applications to hyperparameter selection, convergence rate assessment, and quantifying bias-variance tradeoffs in posterior inference.", "histories": [["v1", "Tue, 9 Jun 2015 18:48:58 GMT  (285kb,D)", "https://arxiv.org/abs/1506.03039v1", "29 pages, 5 figures"], ["v2", "Fri, 19 Jun 2015 05:15:18 GMT  (354kb,D)", "http://arxiv.org/abs/1506.03039v2", "28 pages, 5 figures"], ["v3", "Sat, 12 Sep 2015 23:31:21 GMT  (293kb,D)", "http://arxiv.org/abs/1506.03039v3", "28 pages, 6 figures"], ["v4", "Mon, 11 Jan 2016 03:47:27 GMT  (1387kb,D)", "http://arxiv.org/abs/1506.03039v4", "17 pages, 6 figures"], ["v5", "Mon, 6 Mar 2017 18:59:16 GMT  (1389kb,D)", "http://arxiv.org/abs/1506.03039v5", "17 pages, 6 figures"]], "COMMENTS": "29 pages, 5 figures", "reviews": [], "SUBJECTS": "stat.ML cs.LG math.PR stat.ME", "authors": ["jackson gorham", "lester w mackey"], "accepted": true, "id": "1506.03039"}, "pdf": {"name": "1506.03039.pdf", "metadata": {"source": "CRF", "title": "Measuring Sample Quality with Stein\u2019s Method", "authors": ["Jackson Gorham"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "When faced with a complex target distribution, we often turn to Markov chain Monte Carlo (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCS) (MCMC S) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC (MCMC) (MCMC) (MCMC (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) (MCMC) ("}, {"heading": "2 Quality Measures for Samples", "text": "(c) (c) (c) (c) (c) (c) (c) ((c) ((c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c) (c (c) (c) (c) (c (c) (c) (c (c) (c) (c (c) (c (c) (c) (c) (c (c (c) (c (c) (c) (c (c) (c) (c (c (c (c) (c) (c (c (c) (c) (c (c (c) (c) (c) (c (c (c) (c) (c (c) (c (c) (c) (c (c (c) (c) (c (c (c) (c (c) (c) (c (c)"}, {"heading": "3 Stein\u2019s Method", "text": "Stein's method [7] to characterize convergence in the distribution typically proceeds in three steps: 1. Identify a real weighted operator T, which acts on the basis of a set G of Rd-evaluated1 functions of X, for the EP [(T g) (Z)] = 0 for all g-G. (2) Together, T and G define the stone discrepancy, S (Q, T, G), sup g-G | EQ [(T g) (X)] | = sup g-G-G-EQ [(T g) (X)] \u2212 EP [(T g) (Z)] | = dT G (Q, P), a quality scale of type IPM without explicit integration under P. 2. Lower limits the stone discrepancy by a familiar convergence-determining IPM dH. This step can be performed once, in advance, for large classes of target distributions, and ensures that we are versed, in a sequence, from (S), to (T), a probability scale (M m m m m m m), and then m (H, a probability scale (1)."}, {"heading": "3.1 Identifying a Stein Operator", "text": "The generator method of Barbour [8] provides a convenient and general method of constructing operators T that generate mean zero functions under P (2). Let (Zt) t (0) represent a Markov process with unique stationary distribution P. Then the infinitesimal generator A of (Zt) t \u2265 0, defined by (Au) (x) = lim t \u2192 0 (E [u (Zt) | Z0 = x] \u2212 u (x) / t for u: Rd \u2192 R, satisfies EP [(Au) (Z)] = 0 under mild conditions on A and u. Hence, a candidate operator T can be constructed from any infinitesimal generator."}, {"heading": "3.2 Lower Bounding the Classical Stein Discrepancy", "text": "In the univariate constellation (d = 1), it is known for a multitude of targets P that the classical stone discrepancy S (\u00b5m, TP, G-A) converges to zero only if the Waterstone distance dW-A (\u00b5m, P) is actually [? 10]. In the multivariate constellation, analogous statements are available for multivariate Gauss targets [11, 12, 13] but few other target distributions have been analyzed. In order to extend the scope of the multivariate literature, we show in Theorem 2 that the classical stone discrepancy also determines the Waterstone convergence for a large class of strongly log-concave densities, including Bayesian logistic regression posterior under Gauss priors. Theorem 2 (Stone discrepancy Lower-T-T-P) shows that the lower limits for strongly log-concave densities (P = log) and A-log-A-strongly conv-P (strongly conv-P) are sufficient."}, {"heading": "3.3 Upper Bounding the Classical Stein Discrepancy", "text": "Next, we set sufficient conditions for the convergence of the classical stone discrepancy to zero. Sentence 3 (stone discrepancy upper limit).IfX \u0445 Q and Z \u0445 P with log p (Z) integral, S (Q, TP, G, E) \u2264 VP-I-E [EX-Z] + E [EY-Log p (X) \u2212 EY-Log p (Z)] + E [EY-Log p (Z)] + EY [EY-Log p (Z) > EY] \u2264 I-E [EX-Z] + E [EY-Log p (X) \u2212 EY-Log p (Z)] + E [EY-Log p (Z)], 2] E [EY-Log p (X-Z).An implication of sentence 3 is that S (Qm, TP, G-Qm) converges to zero whenever Xm-Qm converges to Z-P and EY-Log (Xm)."}, {"heading": "3.4 Extension to Non-uniform Stein Sets", "text": "The analyses and algorithms in this work take into account uneven stone sets of form Gc1: 3, 1: 3, 2: 3, 3: 4, 3: 4, 4: 4, 4: 5, 4: 5, 5: 5, 5: 7, 5: 7, 5: 7, 5: 7, 6: 7, 6: 7, 6: 7, 8: 8, 8: 8, 8: 8, 8: 8, 8: 8, 7: 8, 7: 8, 8: 8, 9: 9, 9: 9, 9: 11, 9: 11, 9: 11, 9: 11, 9: 11, 9: 11, 9: 11, 9: 8: 8, 8: 8, 8: 8, 8: 8, 8: 8, 8: 8, 8: 8, 8: 8, 8: 8, 8: 8, 8, 8: 8, 9: 9, 9: 9: 9, 9: 11, 9: 11, 9: 11: 11, 9: 11: 11, 9: 11, 9: 11, 9: 11, 9: 11: 11, 11: 11, 11: 11, 11: 11, 11: 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11: 11, 11: 11: 11, 11: 11, 11: 11: 11, 11: 11, 11: 11, 11: 11: 11, 11: 11: 11, 11: 11: 11, 11: 11, 11: 11, 11: 11: 11, 11: 11: 11, 11: 11, 11: 11: 11, 11, 11: 11: 11, 11: 11, 11: 11, 11: 11, 11: 11: 11, 11: 11, 11: 11, 11, 11: 11, 11: 11: 11: 11, 11, 11: 11, 11: 11: 11, 11: 11, 11: 11, 11: 11, 11, 11: 11, 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11, 11, 11: 11, 11: 11, 11: 11, 11, 11: 11, 11, 11, 11: 11, 11, 11"}, {"heading": "4 Computing Stein Discrepancies", "text": "In this section we present an efficiently calculable stone discrepancy with convergence properties similar to those of the classical discrepancy. We limit attention to the unrestricted domain X = Rd in sections 4.1-4.3 and introduce extensions for restricted domains in section 4.4."}, {"heading": "4.1 Graph Stein Discrepancies", "text": "The evaluation of a stone discrepancy S (Q, TP, G) for a fixed (Q, P) group is reduced to solving an optimization program using functions g (G). For example, the classic stone discrepancy is optimum S (Q, TP, G) = supg \u00b2 n i = 1 q (xi) (< g (xi), p (xi) > + < p (xi) >) (6) s.t. (x).t. (x).p (x).p (x).p (x).p (x).p (x).p (x).p (x).p (x).p (x).p), p (x).p (x).p), p (x).p (x).p), p (x).p (x).p)."}, {"heading": "4.2 Geometric Spanners", "text": "For a given dilation factor t \u2265 1, a wrench [16, 17] is a diagram G = (V, E) with a weight distribution between each edge (x, y) and a path between each pair x \"6 = y.\" V with a total weight not greater than t. \"X = Rd, Gt = (supp (Q), E) is a wrench and G1 = (supp (Q), {(xi, xl) supp (Q) 2: xi 6 = xl}), thenS (Q, TP), G-S (Q, G1) \u2264 S (Q \u00b7 \u00b7 P, Gt \u00b7 \u00b7, Gt), 2t S (Q), Q \u00b7 P (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (G \u00b7 P), a wrench (Q \u00b7 P), a wrench (G), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P, a wrench (Q \u00b7 P), a wrench (Q \u00b7 \u00b7 P), a wrench (Q \u00b7 P, a wrench (Q \u00b7 P), a wrench (Q \u00b7 P, a wrench (Q \u00b7 P), a wrench (Q \u00b7 P), a wrench (Q \u00b7 P, P, a wrench (Q \u00b7 P), a wrench (Q \u00b7 P, a wrench (Q \u00b7 G, a wrench), a wrench (Q \u00b7 G, a wrench), a wrench (Q \u00b7 G, a wrench (Q \u00b7 G, a wrench), a wrench (Q \u00b7 G, a wrench (Q \u00b7 G), a wrench (Q \u00b7 G (Q \u00b7 G, a wrench)."}, {"heading": "4.3 Decoupled Linear Programs", "text": "We recommend the \"1 standard,\" because the resulting optimization problem decouples into d independent end-dimensional linear programs (LPs) that can be solved in parallel. More precisely, S (Q, TP, G) \u00b7 1, Q, (V, E) = 1 sup-dimensional linear programs (LPs) that can be solved in parallel. More precisely, S (Q, TP, G-1, Q, (V, E) = 1 sup-dimensional linear programs (LPs)."}, {"heading": "4.4 Constrained Domains", "text": "A small modification of the unrestricted formula (7) extends our tractable stone discrepancy calculation to all areas defined by coordinate boundary constraints, that is, to X = (\u03b11, \u03b21) \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 (\u03b1d, \u03b2d) with \u2212 \u2212 \u03b2\u03b2\u03b2q (\u00b2 \u00b2). Specifically, we extend the j-th coordinate program of (7) with the boundary compatibility constraint (\u00b2). \u2212 \u2212 bj \u2212 bj \u2212 bj \u2212 bj \u2212 bj (\u00b2). \u2212 bj \u2212 bj \u2212 bj \u2212 bj (\u00b2) stone, and k 6 = j. (8) These additional constraints ensure that our candidate function and gradient values can be extended to a smooth function that meets the boundary conditions; < b)."}, {"heading": "5 Experiments", "text": "We now turn to an empirical evaluation of our proposed quality standards. We calculate all spanners with the efficient C + + implementation of Bouts et al. [19] and solve all optimization programs with Julia for Mathematical Programming [20] using the standard Gurobi 6.0.4 solver [21]. All reported timings are determined with a single core of an Intel Xeon CPU E5-2650 v2 @ 2.60GHz."}, {"heading": "5.1 A Simple Example", "text": "Let's start with a simple example to illustrate some of the characteristics of stone diagnostics. For the target P = N (0, 1), we create a sequence of sample points i.i.d. from the target and a second sequence i.i.d. from the t-distribution of a scaled student with matching variance and 10 degrees of freedom. The left panel of Figure 1 shows that the complete stone discrepancy applied to the first NGaussian sample points decays to zero at a n \u2212 0.52 rate, while the discrepancy applied to the t sample of the scaled student remains zero. The middle panel shows optimal stone functions g, which the Stein program has restored for different sample sizes. Each g results in a test function h, TP g, which best distinguishes the sample Q from the target P. Remarkably, the t functions of the student have relatively large variations in the carrier."}, {"heading": "5.2 Comparing Discrepancies", "text": "We show in theorem 9 in the appendix that at d = 1 the classical stone discrepancy is the optimum of a convex square-delimited square program with a linear objective, O (n) variables and O (n) constraints, which allows us to directly compare the behavior of the diagram and the classical stone discrepancies. We also compare the Waterstone distance dW, which can be calculated for simple universal target distributions [22] and demonstrably the uneven stone discrepancies (5) with c1: 3 = (0.5, 0.5, 1) for P = Unif (0, 1) and c1: 3 = (1, 4, 2) for P = N (0, 1) [? 23]. At N (0, 1) and Unif (0, 1) targets and several random number generator seeds, we create a sequence of sample points."}, {"heading": "5.3 Selecting Sampler Hyperparameters", "text": "Stochastic Gradient Langevin Dynamics (SGLD) [3] with constant step size is a biased MCMC method for scalable inference. It approaches overdamped Langevin diffusion, but since no Metropolis-Hastings (MH) correction is used, the stationary distribution of SGLD deviates from its target as it grows. However, if it is too small, the SGLD explores the sample space too slowly. Therefore, an appropriate selection for precise posterior inference is crucial. To illustrate the value of stone diagnostics for this task, we use the posterior bimodal Gaussian mixing model (GMM) of [3] as our target. For a number of step sizes, we use SGLD with minibatch size 5 to draw 50 independent length sequences n = 1000, and choose the value of the highest quality sample - maximum median ES3b based on this diagram (a small sample size)."}, {"heading": "5.4 Quantifying a Bias-Variance Trade-off", "text": "The approximate Random Walk MH (ARWMH) sampler [5] is a second, biased MCMC method designed for scalable posterior inference. Its tolerance parameter controls the number of datapoint probability evaluations used to approximate the standard MH correction step. Qualitatively, a greater value implies fewer probability calculations, faster sampling, and a faster reduction in variance. A smaller value results in a closer approximation to the MH correction and less bias in the stationary distribution of the sampler. We will use the Stein discrepancy to explicitly quantify this bias variance."}, {"heading": "5.5 Assessing Convergence Rates", "text": "The stone discrepancy can also be used to assess the quality of deterministic sample sequences. Figure 5 in the appendix shows for P = Unif (0, 1) the complete graph-stone discrepancy of the first n points of an i.i.d. Unif (0, 1) sample, a deterministic sobol sequence [26], and a deterministic kernel herding sequence [27], defined by the norm,,,, H = 1 0 (h \u2032 (x)) 2dx. \"We use the mean of over 50 sequences in the i.i.d. case, and estimate the convergence rate for each sampler based on the slope of the least square affine that matches each log log log diagram. The discrepancy calculation time is 0.08 s for n = 200 points and the recovered rate of n \u2212 0.49 and n \u2212 1 for the i.i.i.i.i.i. sequences and 1 for each of the expected sequences (1 / 1)."}, {"heading": "6 Discussion of Related Work", "text": "The diagnosis of [31, 32] also takes asymptotic bias into account, but loses its distinctiveness by taking into account only a finite collection of functionalities. For example, the score statistic of [32] for an N (0, 1) target does not take into account two samples with the same first and second moment. The maximum mean discrepancy (MMD) on a characteristic Hilbert space [33] takes into account the full distribution distortion, but is only practical if the expected core evaluations can be easily calculated below the target. MSD can be approximated, but this requires access to a separate trustworthy soil truth sample from the target."}, {"heading": "A Proof of Proposition 1", "text": "Our integrability assumption along with the boundary of g and g implies that EP [< p, g (Z) >] and EP [< g (Z), as well as log p (Z) >] exist. Define the radius r, Br = {x, Rd: x, x, p =. Because X is convex, the intersection point X, Br with the Lipschitz boundary is compact and convex (Z). Thus, the divergence theorem (integration by parts) implies that EP [(TP g) (Z)] = EP [< g (Z) > + < g (Z) > + < g (Z), p (Z) > < g (Z) < g (Z) < g (Z) < p (Z) < m (Z) < g (Z) > r (Z) < g (Z) < g (Z) to the boundary (Z)."}, {"heading": "B Proof of Theorem 2: Stein Discrepancy Lower Bound for Strongly Log-concave Densities", "text": "We leave Ck (X) the number of real evaluated functions based on (X), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), (S), S (S), S, S, (S), S, S, (S, S, S, S, S, S (S), S (S), S (S), S (S, S, S (S), S (S), S (S), S (S, S (S), S (S), S (S), S (S (S), S (S), S (S), S (S (S), S (S), S (S (S), S (S), S (S (S), S (S), S (S (S), S (S (S), S (S (S), S (S), S (S (S), S (S (S), S (S (S), S (S, S), S (S (S), S (S (S), S (S, S (S, S), S (S (S, S, S, S, S, S, S (S, S, S (S), S (S, S, S (S), S (S (S), S (S, S, S (S, S), S (S (S, S), S (S (S, S, S (S), S (S, S, S, S (S, S, S), S (S (S), S (S"}, {"heading": "C Proof of Proposition 3: Stein Discrepancy Upper Bound", "text": "The Lipschitz constraints and limits in G and G now result in EQ [(TP g) (X)] = E [(TP g) (X) \u2212 (TP g) (X) \u2212 (TP g) (X) \u2212 (TP g) (X) = E [(TP g) (Z) = E [< g (X), p (Z) > \u2212 < g (Z) \u2212 g (Z), p (Z) > + < g (Z) > + < g (Z) > + E [< g (X) \u2212 g (Z) >] = E [< g (X) \u2212 g (Z) \u2212 Z), p (Z) \u2212 g (Z) >] + E [< g (X) \u2212 g (Z), g (Z) \u2212 M (Z), p (Z) \u2212 Z (Z) \u2212 Z (Z) \u2212 Z (Z) > M) (Z) for the quality) > (Z)."}, {"heading": "D Proof of Proposition 4: Equivalence of Non-uniform Stein Discrepancies", "text": "Attach all c1, c2, c3 > 0, and leave cmax = max (c1, c2, c3) and cmin = min (c1, c2, c3).Since the stone discrepancy target in g is linear, we have for each a > 0 aS (Q, TP, G, GECE) = S (Q, TP, aG, ECE).The result now follows from the observation that cminG, ECE, GC1: 3, ECE, ECE, ECE."}, {"heading": "E Proof of Proposition 5: Equivalence of Classical and Complete Graph Stein Discrepancies", "text": "The first inequality results from the fact that G, TP, G, Q, G1. According to the Whitney Glaeser extension theorem [15, Thm. 1,4] of Glaeser [14], for each function g, G, Q, G1 there is a function g as a function of (Q, P), g as a function of dimension d and the norm. Since the stone discrepancy target in g is linear and depends only on g by the values g (xi) and g (xi), we have S (Q, TP, G, G1) \u2264 S (Q, TP, KdG, KdG) = D S (Q, TP, G)."}, {"heading": "F Proof of Proposition 6: Equivalence of Spanner and Complete Graph Stein Discrepancies", "text": "The first inequality is the result of the fact that G + zl \u2212 zl \u2212 zl = zl \u2212 zl = zl \u2212 l = zl \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212 l \u2212"}, {"heading": "G Finite-dimensional Classical Stein Program", "text": "Theorem 9 (Finite-dimensional Classic Stone Program). If X = (\u03b1, \u03b2) for \u2212 \u221e (VI) < \u03b2 \u2264 (VI) and x (1) < \u00b7 < x (n) actually the sorted values of {x1,.., xn, \u03b1, \u03b2 (R), then the non-uniform stone discrepancy S (Q, TP, Gc1: 3) is the optimal value of the convex program g (n). (xn, \u03b1 (i)) d dx log p (i) g (i) g (i) g (i))) + q (i), g (i) s.t. (1) s.t. (i).,., n). (g). (1)."}, {"heading": "H Equivalence of Constrained Classical and Spanner Stein Discrepancies", "text": "For P with support X = (\u03b11, \u03b21) \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 (\u03b1d, \u03b2d) \u00b7 \u00b7 \u00b7 Q (1) \u00b7 \u00b7 \u00b7 Q (1) \u00b7 \u00b7 \u00b7 \u00b7 Q (1) \u00b7 \u00b7 \u00b7 Q (1) \u00b7 \u00b7 \u00b7 Q (1) \u00b7 \u00b7 \u00b7 \u00b7 Q (1) (1) \u00b7 \u00b7 \u00b7 Q (1) \u00b7 \u00b7 Q (1) \u00b7 \u00b7 Q (1) \u00b7 (1) \u00b7 \u00b7 Q (1) \u00b7 \u00b7 \u00b7 \u00b7 Q (1) \u00b7 \u00b7 \u00b7 b (1). \u2212 b) \u2212 b (1) \u2212 b (1), \u2212 b (2). \u2212 b (2) \u00b7 G (1) \u2212 b), \u00b7 b (2), \u2212 b) \u00b7 b (2), \u2212 b (2), \u2212 b), \u2212 b)."}, {"heading": "Acknowledgments", "text": "The authors thank Madeleine Udell for her generous advice on optimizing Julia, Quirijn Bouts, and Kevin Buchin for their wise advice and greedy key implementations, Francis Bach for sharing his pseudo-sampling code, Andreas Eberle for his Triple Coupling Pointers, and Jessica Hwang for their feedback on various versions of this manuscript. This work was supported by the Frederick E. Terman Fellowship and the National Science Foundation Graduate Research Fellowship under grant number DGE-114747."}], "references": [{"title": "Handbook of Markov chain Monte Carlo", "author": ["S. Brooks", "A. Gelman", "G. Jones", "X.-L. Meng"], "venue": "CRC press", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Markov chain Monte Carlo maximum likelihood", "author": ["C.J. Geyer"], "venue": "Computer Science and Statistics: Proc. 23rd Symp. Interface, pages 156\u2013163", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1991}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["M. Welling", "Y. Teh"], "venue": "ICML", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2011}, {"title": "Bayesian posterior sampling via stochastic gradient Fisher scoring", "author": ["S. Ahn", "A. Korattikara", "M. Welling"], "venue": "Proc. 29th ICML, ICML\u201912", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Austerity in MCMC land: Cutting the Metropolis-Hastings budget", "author": ["A. Korattikara", "Y. Chen", "M. Welling"], "venue": "Proc. of 31st ICML, ICML\u201914", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Integral probability metrics and their generating classes of functions", "author": ["A. M\u00fcller"], "venue": "Ann. Appl. Probab., 29 (2):pp. 429\u2013443", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1997}, {"title": "A bound for the error in the normal approximation to the distribution of a sum of dependent random variables", "author": ["C. Stein"], "venue": "Proc. 6th Berkeley Symposium on Mathematical Statistics and Probability ", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1971}, {"title": "Stein\u2019s method and Poisson process convergence", "author": ["A.D. Barbour"], "venue": "J. Appl. Probab., (Special Vol. 25A): 175\u2013184", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1988}, {"title": "Control functionals for Monte Carlo integration", "author": ["C. Oates", "M. Girolami", "N. Chopin"], "venue": "To appear in JRSS, Series B", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Nonnormal approximation by Stein\u2019s method of exchangeable pairs with application to the Curie-Weiss model", "author": ["S. Chatterjee", "Q. Shao"], "venue": "Ann. Appl. Probab., 21(2):464\u2013483", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Multivariate normal approximation with Stein\u2019s method of exchangeable pairs under a general linearity condition", "author": ["G. Reinert", "A. R\u00f6llin"], "venue": "Ann. Probab., 37(6):2150\u20132173", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Multivariate normal approximation using exchangeable pairs", "author": ["S. Chatterjee", "E. Meckes"], "venue": "ALEA Lat. Am. J. Probab. Math. Stat., 4:257\u2013283", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "On Stein\u2019s method for multivariate normal approximation", "author": ["E. Meckes"], "venue": "High dimensional probability V: the Luminy volume, volume 5 of Inst. Math. Stat. Collect., pages 153\u2013178. Inst. Math. Statist., Beachwood, OH", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "\u00c9tude de quelques alg\u00e8bres tayloriennes", "author": ["G. Glaeser"], "venue": "J. Analyse Math., 6:1\u2013124; erratum, insert to 6 ", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1958}, {"title": "The Whitney extension problem and Lipschitz selections of set-valued mappings in jetspaces", "author": ["P. Shvartsman"], "venue": "Trans. Amer. Math. Soc., 360(10):5529\u20135550", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2008}, {"title": "There is a Planar Graph Almost As Good As the Complete Graph", "author": ["P. Chew"], "venue": "Proc. 2nd SOCG, pages 169\u2013177, New York, NY", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1986}, {"title": "Graph spanners", "author": ["D. Peleg", "A. Sch\u00e4ffer"], "venue": "J. Graph Theory, 13(1):99\u2013116", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1989}, {"title": "Fast construction of nets in low-dimensional metrics and their applications", "author": ["S. Har-Peled", "M. Mendel"], "venue": "SIAM J. Comput., 35(5):1148\u20131184", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2006}, {"title": "A", "author": ["Q.W. Bouts"], "venue": "P. ten Brink, and K. Buchin. A framework for Computing the Greedy Spanner. In Proc. of 30th SOCG, pages 11:11\u201311:19, New York, NY", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Computing in operations research using Julia", "author": ["M. Lubin", "I. Dunning"], "venue": "INFORMS Journal on Computing, 27(2):238\u2013248", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Calculation of the Wasserstein distance between probability distributions on the line", "author": ["S. Vallender"], "venue": "Theory Probab. Appl., 18(4):784\u2013786", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1974}, {"title": "Stein\u2019s method of exchangeable pairs for the Beta distribution and generalizations", "author": ["C. D\u00f6bler"], "venue": "arXiv:1411.4477", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "boot: Bootstrap R (S-Plus) Functions, 2015. R package version 1.3-15", "author": ["A. Canty", "B. Ripley"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Exponential convergence of Langevin distributions and their discrete approximations", "author": ["G. Roberts", "R. Tweedie"], "venue": "Bernoulli, 2(4):341\u2013363", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1996}, {"title": "On the distribution of points in a cube and the approximate evaluation of integrals", "author": ["I. Sobol"], "venue": "USSR Comput. Math. and Math. Phys, (7):86\u2013112", "citeRegEx": "26", "shortCiteRegEx": null, "year": 1967}, {"title": "Super-samples from kernel herding", "author": ["Y. Chen", "M. Welling", "A. Smola"], "venue": "UAI", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2010}, {"title": "Central limit theorems for the Wasserstein distance between the Empirical and the True Distributions", "author": ["E. del Barrio", "E. Gin\u00e9", "C. Matr\u00e1n"], "venue": "Ann. Probab., 27(2):1009\u20131071,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 1999}, {"title": "Low discrepancy sequences in high dimensions: How well are their projections distributed", "author": ["X. Wang", "I. Sloan"], "venue": "J. Comput. Appl. Math.,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "On the equivalence between herding and conditional gradient algorithms", "author": ["F. Bach", "S. Lacoste-Julien", "G. Obozinski"], "venue": "Proc. 29th ICML, ICML\u201912", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2012}, {"title": "Gibbs sampler convergence criteria", "author": ["A. Zellner", "C. Min"], "venue": "JASA, 90(431):921\u2013927", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1995}, {"title": "Output assessment for Monte Carlo simulations via the score statistic", "author": ["Y. Fan", "S.P. Brooks", "A. Gelman"], "venue": "J. Comp. Graph. Stat., 15(1)", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2006}, {"title": "A kernel method for the two-sampleproblem", "author": ["A. Gretton", "K. Borgwardt", "M. Rasch", "B. Sch\u00f6lkopf", "A. Smola"], "venue": "Adv. NIPS 19, pages 513\u2013520", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2006}, {"title": "Multivariate Stein factors for a class of strongly log-concave distributions", "author": ["L. Mackey", "J. Gorham"], "venue": "arXiv:1512.07392", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "1 Introduction When faced with a complex target distribution, one often turns to Markov chain Monte Carlo (MCMC) [1] to approximate intractable expectations EP [h(Z)] = \u222b X p(x)h(x)dx with asymptotically exact sample estimates EQ[h(X)] = \u2211n i=1 q(xi)h(xi).", "startOffset": 113, "endOffset": 116}, {"referenceID": 1, "context": "These complex targets commonly arise as posterior distributions in Bayesian inference and as candidate distributions in maximum likelihood estimation [2].", "startOffset": 150, "endOffset": 153}, {"referenceID": 0, "context": "However, the added flexibility introduces new challenges for sampler and parameter selection, since standard sample quality measures, like effective sample size, asymptotic variance, trace and mean plots, and pooled and within-chain variance diagnostics, presume eventual convergence to the target [1] and hence do not account for asymptotic bias.", "startOffset": 298, "endOffset": 301}, {"referenceID": 5, "context": "In this case, the expression (1) is termed an integral probability metric (IPM) [6].", "startOffset": 80, "endOffset": 83}, {"referenceID": 6, "context": "3 Stein\u2019s Method Stein\u2019s method [7] for characterizing convergence in distribution classically proceeds in three steps: 1.", "startOffset": 32, "endOffset": 35}, {"referenceID": 7, "context": "1 Identifying a Stein Operator The generator method of Barbour [8] provides a convenient and general means of constructing operators T which produce mean-zero functions under P (2) .", "startOffset": 63, "endOffset": 66}, {"referenceID": 10, "context": "In the multivariate setting, analogous statements are available for multivariate Gaussian targets [11, 12, 13], but few other target distributions have been analyzed.", "startOffset": 98, "endOffset": 110}, {"referenceID": 11, "context": "In the multivariate setting, analogous statements are available for multivariate Gaussian targets [11, 12, 13], but few other target distributions have been analyzed.", "startOffset": 98, "endOffset": 110}, {"referenceID": 12, "context": "In the multivariate setting, analogous statements are available for multivariate Gaussian targets [11, 12, 13], but few other target distributions have been analyzed.", "startOffset": 98, "endOffset": 110}, {"referenceID": 8, "context": "The operator TP has also found fruitful application in the design of Monte Carlo control variates [9].", "startOffset": 98, "endOffset": 101}, {"referenceID": 13, "context": "Proposition 5 follows from the Whitney-Glaeser extension theorem for smooth functions [14, 15] and implies that the complete graph Stein discrepancy inherits all of the desirable convergence properties of the classical discrepancy.", "startOffset": 86, "endOffset": 94}, {"referenceID": 14, "context": "Proposition 5 follows from the Whitney-Glaeser extension theorem for smooth functions [14, 15] and implies that the complete graph Stein discrepancy inherits all of the desirable convergence properties of the classical discrepancy.", "startOffset": 86, "endOffset": 94}, {"referenceID": 15, "context": "2 Geometric Spanners For a given dilation factor t \u2265 1, a t-spanner [16, 17] is a graph G = (V,E) with weight \u2016x\u2212 y\u2016 on each edge (x, y) \u2208 E and a path between each pair x\u2032 6= y\u2032 \u2208 V with total weight no larger than t\u2016x\u2032 \u2212 y\u2032\u2016.", "startOffset": 68, "endOffset": 76}, {"referenceID": 16, "context": "2 Geometric Spanners For a given dilation factor t \u2265 1, a t-spanner [16, 17] is a graph G = (V,E) with weight \u2016x\u2212 y\u2016 on each edge (x, y) \u2208 E and a path between each pair x\u2032 6= y\u2032 \u2208 V with total weight no larger than t\u2016x\u2032 \u2212 y\u2032\u2016.", "startOffset": 68, "endOffset": 76}, {"referenceID": 17, "context": "Moreover, for any `p norm, a 2-spanner with O(\u03badn) edges can be computed in O(\u03badn log(n)) expected time for \u03bad a constant depending only on d and \u2016\u00b7\u2016 [18].", "startOffset": 150, "endOffset": 154}, {"referenceID": 18, "context": "[19] and solve all optimization programs using Julia for Mathematical Programming [20] with the default Gurobi 6.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[19] and solve all optimization programs using Julia for Mathematical Programming [20] with the default Gurobi 6.", "startOffset": 82, "endOffset": 86}, {"referenceID": 20, "context": "which is computable for simple univariate target distributions [22] and provably lower bounds the non-uniform Stein discrepancies (5) with c1:3 = (0.", "startOffset": 63, "endOffset": 67}, {"referenceID": 2, "context": "3 Selecting Sampler Hyperparameters Stochastic Gradient Langevin Dynamics (SGLD) [3] with constant step size is a biased MCMC procedure designed for scalable inference.", "startOffset": 81, "endOffset": 84}, {"referenceID": 2, "context": "To illustrate the value of the Stein diagnostic for this task, we adopt the bimodal Gaussian mixture model (GMM) posterior of [3] as our target.", "startOffset": 126, "endOffset": 129}, {"referenceID": 0, "context": "For a range of step sizes , we use SGLD with minibatch size 5 to draw 50 independent sequences of length n = 1000, and we select the value of with the highest median quality \u2013 either the maximum effective sample size (ESS, a standard diagnostic based on autocorrelation [1]) or the minimum spanner Stein discrepancy \u2013 across these sequences.", "startOffset": 270, "endOffset": 273}, {"referenceID": 4, "context": "4 Quantifying a Bias-Variance Trade-off The approximate random walk MH (ARWMH) sampler [5] is a second biased MCMC procedure designed for scalable posterior inference.", "startOffset": 87, "endOffset": 90}, {"referenceID": 22, "context": "We analyze a dataset of 53 prostate cancer patients with six binary predictors and a binary outcome indicating whether cancer has spread to surrounding lymph nodes [24].", "startOffset": 164, "endOffset": 168}, {"referenceID": 0, "context": "Our target is the Bayesian logistic regression posterior [1] under a N (0, I) prior on the parameters.", "startOffset": 57, "endOffset": 60}, {"referenceID": 23, "context": "To corroborate our result, we use a Metropolis-adjusted Langevin chain [25] of length 10 as a surrogateQ\u2217 for the target and compute several error measures for each sampleQ: normalized probability error maxl |E[\u03c3(\u3008X,wl\u3009)\u2212 \u03c3(\u3008Z,wl\u3009)]|/\u2016wl\u2016\u221e, mean error maxj |E[Xj\u2212Zj ]| maxj |EQ\u2217 [Zj ]| , and second moment error maxj,k |E[XjXk\u2212ZjZk]| maxj,k |EQ\u2217 [ZjZk]| for X \u223c Q, Z \u223c Q \u2217, \u03c3(t) , 1 1+e\u2212t , and wl the l-th datapoint covariate vector.", "startOffset": 71, "endOffset": 75}, {"referenceID": 24, "context": "Unif(0, 1) sample, a deterministic Sobol sequence [26], and a deterministic kernel herding sequence [27] defined by the norm \u2016h\u2016H = \u222b 1 0 (h\u2032(x))2dx.", "startOffset": 50, "endOffset": 54}, {"referenceID": 25, "context": "Unif(0, 1) sample, a deterministic Sobol sequence [26], and a deterministic kernel herding sequence [27] defined by the norm \u2016h\u2016H = \u222b 1 0 (h\u2032(x))2dx.", "startOffset": 100, "endOffset": 104}, {"referenceID": 26, "context": "and Sobol sequences accord with expected O(1/ \u221a n) and O(1/n) bounds from the literature [28, 29].", "startOffset": 89, "endOffset": 97}, {"referenceID": 27, "context": "and Sobol sequences accord with expected O(1/ \u221a n) and O(1/n) bounds from the literature [28, 29].", "startOffset": 89, "endOffset": 97}, {"referenceID": 28, "context": "As witnessed also in other metrics [30], the herding rate of n\u22120.", "startOffset": 35, "endOffset": 39}, {"referenceID": 29, "context": "The diagnostics of [31, 32] also account for asymptotic bias but lose discriminating power by considering only a finite collection of functionals.", "startOffset": 19, "endOffset": 27}, {"referenceID": 30, "context": "The diagnostics of [31, 32] also account for asymptotic bias but lose discriminating power by considering only a finite collection of functionals.", "startOffset": 19, "endOffset": 27}, {"referenceID": 30, "context": "For example, for a N (0, 1) target, the score statistic of [32] cannot distinguish two samples with equal first and second moments.", "startOffset": 59, "endOffset": 63}, {"referenceID": 31, "context": "Maximum mean discrepancy (MMD) on a characteristic Hilbert space [33] takes full distributional bias into account but is only viable when the expected kernel evaluations are easily computed under the target.", "startOffset": 65, "endOffset": 69}, {"referenceID": 32, "context": "The following result, proved in the companion paper [34], establishes the existence of explicit constants (Stein factors) c1, c2, c3 > 0, such that, for any test function h \u2208M\u2016\u00b7\u2016, the Stein equation h(x)\u2212 EP [h(Z)] = (TP gh)(x) has a solution gh = 12\u2207uh belonging to the non-uniform Stein set G c1:3 \u2016\u00b7\u2016 .", "startOffset": 52, "endOffset": 56}, {"referenceID": 32, "context": "2 of the companion paper [34] establishes this result for the case \u2016\u00b7\u2016 = \u2016\u00b7\u20162; we omit the proof of the generalization which closely mirrors that of the Euclidean norm case.", "startOffset": 25, "endOffset": 29}, {"referenceID": 13, "context": "4] of Glaeser [14], for every function g \u2208 G\u2016\u00b7\u2016,Q,G1 , there exists a function g\u0303 \u2208 \u03bad G\u2217 \u2016\u00b7\u2016 with g(xi) = g\u0303(xi) and \u2207g(xi) = \u2207g\u0303(xi) for all xi in the support of Q.", "startOffset": 14, "endOffset": 18}, {"referenceID": 0, "context": "For any such (mi,Mi) pair, there exists \u03b6i \u2208 [0, 1] satisfying g(x(i+1))\u2212 g(x(i)) = \u222b x(i+1) x(i) \u03b6imi(t) + (1\u2212 \u03b6i)Mi(t)dt, and hence we will define the extension g\u0303(x) = g(x(i)) + \u222b x x(i) \u03b6imi(t) + (1\u2212 \u03b6i)Mi(t)dt.", "startOffset": 45, "endOffset": 51}], "year": 2017, "abstractText": "To improve the efficiency of Monte Carlo estimation, practitioners are turning to biased Markov chain Monte Carlo procedures that trade off asymptotic exactness for computational speed. The reasoning is sound: a reduction in variance due to more rapid sampling can outweigh the bias introduced. However, the inexactness creates new challenges for sampler and parameter selection, since standard measures of sample quality like effective sample size do not account for asymptotic bias. To address these challenges, we introduce a new computable quality measure based on Stein\u2019s method that quantifies the maximum discrepancy between sample and target expectations over a large class of test functions. We use our tool to compare exact, biased, and deterministic sample sequences and illustrate applications to hyperparameter selection, convergence rate assessment, and quantifying bias-variance tradeoffs in posterior inference.", "creator": "LaTeX with hyperref package"}}}