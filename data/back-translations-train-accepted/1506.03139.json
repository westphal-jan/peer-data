{"id": "1506.03139", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2015", "title": "Robust Subgraph Generation Improves Abstract Meaning Representation Parsing", "abstract": "The Abstract Meaning Representation (AMR) is a representation for open-domain rich semantics, with potential use in fields like event extraction and machine translation. Node generation, typically done using a simple dictionary lookup, is currently an important limiting factor in AMR parsing. We propose a small set of actions that derive AMR subgraphs by transformations on spans of text, which allows for more robust learning of this stage. Our set of construction actions generalize better than the previous approach, and can be learned with a simple classifier. We improve on the previous state-of-the-art result for AMR parsing, boosting end-to-end performance by 3 F$_1$ on both the LDC2013E117 and LDC2014T12 datasets.", "histories": [["v1", "Wed, 10 Jun 2015 00:40:12 GMT  (585kb,D)", "http://arxiv.org/abs/1506.03139v1", "To appear in ACL 2015"]], "COMMENTS": "To appear in ACL 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["keenon werling", "gabor angeli", "christopher d manning"], "accepted": true, "id": "1506.03139"}, "pdf": {"name": "1506.03139.pdf", "metadata": {"source": "CRF", "title": "Robust Subgraph Generation Improves Abstract Meaning Representation Parsing", "authors": ["Keenon Werling", "Gabor Angeli", "Christopher D. Manning"], "emails": ["keenon@stanford.edu", "angeli@stanford.edu", "manning@stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "The second step is the relation of names (AMR) (Banarescu et al., 2013) is a rich, graph-based language that expresses semantics over a wide range. The formalism is supported by a large data collection, and it is promising to enable a new type of natural language application, ranging from semantically conscious MT to rich broad knowledge bases. Figure 1 shows an example of AMR for \"he joyfully ran to his dog rover,\" and we give a brief introduction to AMR in Section 2. This paper focuses on AMR parsing, the task of mapping a natural language sentence into an AMR graph. We follow previous work (Flanigan et al., 2014) in splitting AMR into two steps. The first step is the conceptualization that AMR nodes generate from text, which we call NER + (Section 3.1)."}, {"heading": "2 The AMR Formalism", "text": "AMR is a language that expresses semantics as an ingrained, directed, and potentially cyclic graph, where nodes represent concepts and arcs represent relationships between concepts. AMR is based on neo-Davidson semantics (Davidson, 1967; Parsons, 1990). Nodes (concepts) in an AMR graph do not need to be explicitly grounded in the source set, and while such an alignment is often generated by train AMR parsers, it is not provided in the educational society. Nodes semantics can represent lexical items (e.g. dog), meaning-marked lexical items (e.g. run-01), type markers (e.g. date entity), and a variety of other phenomena. The edges (relationships) in AMR describe a number of semantic relationships between concepts."}, {"heading": "2.1 AMR Subgraphs", "text": "The mapping of symbols in a set on AMR nodes is not one-to-one. A single token or span of symbols can create a subgraph of AMR consisting of multiple nodes. Logically, these subgraphs can be considered an expression of a single concept and are useful to treat as such (e.g., see Section 3.1). Many of these subgraphs with multiple nodes capture structured data such as time expressions, as in Figure 4. In this example, a date entity node is created to indicate that this node is part of a structured subcomponent that represents a date in which the nodes and slurs within the component have specific semantics. This illustrates a more comprehensive recurring pattern in AMR: An artificial node, based on its title, may have expected children with a special semantics. A particularly prominent example of this pattern is the name node (see \"Rover\" in Figure 1), which means that all of the phrases are provided with an outgoing name."}, {"heading": "3 Task Decomposition", "text": "To our knowledge, the JAMR parser is the only end-to-end AMR parser published at the time of publication. An important finding in JAMR is that AMR parsing can be divided into two distinct tasks: (1) NER + + (concept identification): the task of interpreting which units are referred to in the text, accomplished by generating the best AMR subgraphs for a given set of tokens, and (2) SRL + + (relationship identification): the task of determining what relationships exist between units, accomplished by unbundling the subgraphs generated by NER + + and creating a fully connected diagram. We will describe both tasks in more detail below."}, {"heading": "3.1 NER++", "text": "Much of the difficulty in parsing AMR is in generating local subgraphs that represent the meaning of symbol ranges. For example, formalism implicitly requires comprehensive notions of NER, lemmatization, meaning disambiguation, number normalization, and temporal parsing; to illustrate this, Figure 2 requires lemmatization (cheerful \u2192 joy), meaning tagging (run \u2192 run-01), and an open domain NER (i.e. rover). In addition, many of the generated subgraphs (e.g. sailors in Figure 3) have rich semantics that go beyond those of standard NLP systems. Formally, NER + + is the task of generating a disjunct group of subgraphs that represent the meaning of localized word span in the sentence. For NER + +, JAMR uses a simple Viterbi sequence model to generate AMR subgraphs directly from these text fields rather than generalizing a generalized contribution."}, {"heading": "3.2 SRL++", "text": "The second stage of AMR decomposition consists in creating a coherent diagram from the disjoint subgraphs created by NER + +. While NER + + produces subgraphs whose arcs encode domain-specific semantics (e.g., month), the arcs in SRL + + tend to have generally applicable semantics. For example, the many arcs encode conventional semantic roles (e.g., ARG0 and destination in Figure 2) or an idea that resembles syntactic dependencies (e.g., Mod and Poss in Figure 2). For SRL + +, JAMR uses a variation of the maximum cross-linked graph algorithm, augmented by dual decomposition, to impose linguistic constraints on a most likely target."}, {"heading": "4 A Novel NER++ Method", "text": "By way of illustration, 38% of the words in the LDC2014E113 developer set are not visible during training time. By using training sets, these small, memory-based approaches are extremely brittle. We eliminate much of the need to memorize the card pings in NER + + by dividing the AMR subgraph's search space in terms of the actions required to derive a node from its aligned token. At test times, we perform sequence labeling of the input marks with these actions, and then deterministically redirect the AMR subgraphs from span of tokens by applying the transformation mandated by their actions. In Section 4.1, we explain how to manage this partition accurately, and in Section 4.3, how to create training data from existing resources to set up and train an action-type classifier."}, {"heading": "4.1 Derivation actions", "text": "In fact, the action is an action that is not an action, but an action that involves naming the person concerned. In fact, the name of the person concerned does not correspond to the name of the person in question, but is associated with the name of the person in question. In fact, the act does not correspond to the name of the person in question, but is related to the name of the person in question. In fact, the act does not correspond to the name of the person in question, but to the name of the person in question. In fact, the act does not correspond to the name of the person in question, but to the name of the person in question. In fact, the action encompasses the verb sensation of the characteristic of the person in question."}, {"heading": "4.2 Action Reliability", "text": "In many cases, multiple actions could produce the same subgraph when applied to a node. In this section, we therefore present a method for solving this ambiguity, based on comparing the reliability with which actions generate the correct subgraph, and discuss implications. Even with a perfect action classification for a character, certain actions can cause preliminary errors. Some of our actions are completely deterministic in their conversion from the word to the subgraph AMR (e.g. IDENTITY), but others tend to make errors in this conversion (e.g. VERB, DICT). We define the term action reliability as the probability of deriving the correct node from a span of tokens based on the choice of the correct action mode. To provide a concrete example, our DICR Dictionary of Reference Classifiers predicts the correct AMR subgraph 67% of the time."}, {"heading": "4.3 Training the Action Classifier", "text": "Given a set of AMR training data in the form of (graph, set) pairs, we first align the graph nodes with the set (see Section 5). Formally, alignment for each node ni in the AMR graph gives us a token sj (at the jth index in the set), which we believe to be the node ni.Then, for each action type, we can ask whether this action type is able to take token sj and correctly generate ni. Specifically, we imagine that the token sj is running, and the node ni has the title run-01. The two action types we find that can correctly generate this node are DICT and VERB. We select the most reliable action type from these available (see Figure 5) to generate the observed node - in this case VERB.In cases where an AMR subgraph is generated from multiple tokens, we assign the tograph to each one of the actionnodes."}, {"heading": "5 Automatic Alignment of Training Data", "text": "It is quite possible that a subgraph can consist of many individual nodes, in cases where a subgraph should be aligned to several tokens, we generate an alignment from the subgraph to the various tokens. It is empirically very rare for a subgraph to have more nodes than the tokens. There have been two previous attempts to produce automatic AMR alignments, the first being the 1A sequence model was tried and did not show any improvement over a simple problem."}, {"heading": "6 Related Work", "text": "Prior to working in AMR and related formalities, these are Jones et al. (2012), and Flanigan et al. (2014). Jones et al. (2012), motivated by applications in machine translation, has proposed a graphic semantic representation that precedes AMR but is closely related. They propose a hyperedge replacement grammar (HRG) to analyze in and out of this graphic semantic form. Flanigan et al. (2014) forms the basis of this paper's approach. Their system introduces the two-step approach we use: they implement a rules-based alignment to learn a mapping of subgraphs, and train a variant of a maximum tree parser that is adapted to graphics and additional constraints on their relation identifications (SRL + +) component. Wang et al. (2015) uses a transition-based algorithm to transform dependent trees in AMR."}, {"heading": "7 Results", "text": "We present improvements to end-to-end AMR parsing on two sets of data using our NER + + component. Accuracy of the action type classifier on an automatically aligned body and accuracy of alignment on a small hand labeled body are also reported."}, {"heading": "7.1 End-to-end AMR Parsing", "text": "We evaluate our NER + + component in the context of end-to-end AMR analysis on two corpora: the Newswire section of LDC2014T12 and the split specified in Flanigan et al. (2014) of LDC2013E117, both consisting primarily of Newswire. We compare two systems: the JAMR parser (Flanigan et al., 2014), 2 and the JAMR SRL + + component with our NER + + approach. The accuracy of the AMR analysis is measured using a metric called smatch (Cai and Knight, 2013), which stands for \"s (emantic) agreement.\" The metric is the formula 1 of a best match between triples and triples implied by the target graph - that is, the set of (parent, edge, child) triples in the chart. Our results are given in Table 3. We report significantly higher reset numbers for both sets of data in the parsed chart, not the improvement itself (i.e. the improvement in both sets of our predictive value is \u2264)."}, {"heading": "7.2 Component Accuracy", "text": "We evaluate our aligner using a small set of 100 hand-labeled alignments and evaluate our NER + + classifier using automatically generated alignments across the entire corpus. On a hand-annotated dataset of 100 AMR parses from the LDC2014T12 corpus, our aligner reaches an accuracy of 83.2. This is a measurement of the percentage of AMR nodes that are aligned to the correct token in their source set. Note that this is a different metric from the 2Available at https: / / github.com / jflanigan / jamr.3 Our dataset is publicly available at http: / / nlp. stanford.edu / projects / amrprecision / previous work on alignments, and is based on both a different alignment dataset and subtly different alignment annotation schemes."}, {"heading": "8 Conclusion", "text": "We show that a simple classification of actions generated by these subgraphs improves end-to-end memory of AMR analysis with little loss of precision, resulting in an overall gain in Formula 1. A clear direction of future work is to improve the coverage of defined actions. For example, a richer lemmatizer could shift the burden of lemmatizing unknown words into the semantics of the AMR problem and away from the dictionary search component. We hope that our decomposition provides a useful framework to guide future work in the NER + + and AMR areas in general."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for their thoughtful feedback. Stanford University appreciates the support of the Defense Advanced Research Projects Agency (DARPA) Deep Exploration and Filtering of Text (DEFT) Programunder Air Force Research Laboratory (AFRL) Contract Number FA8750-13-2-0040. Any opinions, findings, conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA, AFRL or the U.S. government."}], "references": [{"title": "Abstract meaning representation for sembanking", "author": ["Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider"], "venue": null, "citeRegEx": "Banarescu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Banarescu et al\\.", "year": 2013}, {"title": "An adapted Lesk algorithm for word sense disambiguation using wordnet", "author": ["Banerjee", "Pedersen2002] Satanjeev Banerjee", "Ted Pedersen"], "venue": "In Computational linguistics and intelligent text processing", "citeRegEx": "Banerjee et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Banerjee et al\\.", "year": 2002}, {"title": "Modeling biological processes for reading comprehension", "author": ["Vivek Srikumar", "Pei-Chun Chen", "Brad Huang", "Christopher D Manning", "Abby Vander Linden", "Brittany Harding", "Peter Clark"], "venue": "In Proc. EMNLP", "citeRegEx": "Berant et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2014}, {"title": "CONLL-X shared task on multilingual dependency parsing", "author": ["Buchholz", "Marsi2006] Sabine Buchholz", "Erwin Marsi"], "venue": "In Proceedings of the Tenth Conference on Computational Natural Language Learning,", "citeRegEx": "Buchholz et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Buchholz et al\\.", "year": 2006}, {"title": "Smatch: an evaluation metric for semantic feature structures", "author": ["Cai", "Knight2013] Shu Cai", "Kevin Knight"], "venue": "ACL", "citeRegEx": "Cai et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2013}, {"title": "The KANT perspective: A critique of pure transfer (and pure interlingua, pure statistics,...)", "author": ["Teruko Mitamura", "Eric H Nyberg"], "venue": null, "citeRegEx": "Carbonell et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Carbonell et al\\.", "year": 1999}, {"title": "SUTIME: a library for recognizing and normalizing time expressions", "author": ["Chang", "Manning2012] Angel Chang", "Chris Manning"], "venue": "In Language Resources and Evaluation", "citeRegEx": "Chang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2012}, {"title": "The logical form of action sentences", "author": ["Donald Davidson"], "venue": "The Logic of Decision and Action,", "citeRegEx": "Davidson.,? \\Q1967\\E", "shortCiteRegEx": "Davidson.", "year": 1967}, {"title": "The Stanford typed dependencies representation", "author": ["de Marneffe", "Christopher D. Manning"], "venue": "In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser", "citeRegEx": "Marneffe et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2008}, {"title": "Incorporating non-local information into information extraction systems by Gibbs sampling", "author": ["Trond Grenager", "Christopher Manning"], "venue": null, "citeRegEx": "Finkel et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Finkel et al\\.", "year": 2005}, {"title": "A discriminative graph-based parser for the abstract meaning representation", "author": ["Sam Thomson", "Jaime Carbonell", "Chris Dyer", "Noah A Smith"], "venue": null, "citeRegEx": "Flanigan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Flanigan et al\\.", "year": 2014}, {"title": "Automatic labeling of semantic roles", "author": ["Gildea", "Jurafsky2002] Daniel Gildea", "Daniel Jurafsky"], "venue": "Computational linguistics,", "citeRegEx": "Gildea et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Gildea et al\\.", "year": 2002}, {"title": "Learning to solve arithmetic word problems with verb categorization", "author": ["Hannaneh Hajishirzi", "Oren Etzioni", "Nate Kushman"], "venue": null, "citeRegEx": "Hosseini et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hosseini et al\\.", "year": 2014}, {"title": "Semantics-based machine translation with hyperedge replacement grammars", "author": ["Jones et al.2012] Bevan Jones", "Jacob Andreas", "Daniel Bauer", "Karl Moritz Hermann", "Kevin Knight"], "venue": "In COLING,", "citeRegEx": "Jones et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jones et al\\.", "year": 2012}, {"title": "Learning to transform natural to formal languages", "author": ["Kate et al.2005] Rohit J. Kate", "Yuk Wah Wong", "Raymond J. Mooney"], "venue": null, "citeRegEx": "Kate et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Kate et al\\.", "year": 2005}, {"title": "An interlingua based on domain actions for machine translation of taskoriented dialogues", "author": ["Levin et al.1998] Lori S Levin", "Donna Gates", "Alon Lavie", "Alex Waibel"], "venue": "In ICSLP,", "citeRegEx": "Levin et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Levin et al\\.", "year": 1998}, {"title": "Learning dependency-based compositional semantics", "author": ["Liang et al.2011] P. Liang", "M.I. Jordan", "D. Klein"], "venue": null, "citeRegEx": "Liang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Liang et al\\.", "year": 2011}, {"title": "Online largemargin training of dependency parsers", "author": ["Koby Crammer", "Fernando Pereira"], "venue": null, "citeRegEx": "McDonald et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "An efficient interlingua translation system for multi-lingual document production", "author": ["Eric H Nyberg", "Jaime G Carbonell"], "venue": "Proceedings of Machine Translation Summit III", "citeRegEx": "Mitamura et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Mitamura et al\\.", "year": 1991}, {"title": "A survey of named entity recognition and classification", "author": ["Nadeau", "Sekine2007] David Nadeau", "Satoshi Sekine"], "venue": "Lingvisticae Investigationes,", "citeRegEx": "Nadeau et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Nadeau et al\\.", "year": 2007}, {"title": "The proposition bank: An annotated corpus of semantic roles", "author": ["Palmer et al.2005] Martha Palmer", "Daniel Gildea", "Paul Kingsbury"], "venue": null, "citeRegEx": "Palmer et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Palmer et al\\.", "year": 2005}, {"title": "Events in the Semantics of English: A study in subatomic semantics", "author": ["Terence Parsons"], "venue": null, "citeRegEx": "Parsons.,? \\Q1990\\E", "shortCiteRegEx": "Parsons.", "year": 1990}, {"title": "Aligning english strings with abstract meaning representation graphs", "author": ["Yang Gao", "Ulf Hermjakob", "Kevin Knight"], "venue": null, "citeRegEx": "Pourdamghani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pourdamghani et al\\.", "year": 2014}, {"title": "Semantic role labeling via integer linear programming inference", "author": ["Dan Roth", "Wen-tau Yih", "Dav Zimak"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "Punyakanok et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Punyakanok et al\\.", "year": 2004}, {"title": "The semantics of role labeling", "author": ["Vivek Srikumar"], "venue": "Ph.D. thesis,", "citeRegEx": "Srikumar.,? \\Q2013\\E", "shortCiteRegEx": "Srikumar.", "year": 2013}, {"title": "Heideltime: High quality rule-based extraction and normalization of temporal expressions", "author": ["Str\u00f6tgen", "Gertz2010] Jannik Str\u00f6tgen", "Michael Gertz"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation,", "citeRegEx": "Str\u00f6tgen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Str\u00f6tgen et al\\.", "year": 2010}, {"title": "Semeval-2010 task 13: TempEval-2", "author": ["Roser Sauri", "Tommaso Caselli", "James Pustejovsky"], "venue": "In Proceedings of the 5th International Workshop on Semantic Evaluation,", "citeRegEx": "Verhagen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Verhagen et al\\.", "year": 2010}, {"title": "A transition-based algorithm for amr parsing", "author": ["Wang et al.2015] Chuan Wang", "Nianwen Xue", "Sameer Pradhan"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Unsupervised word sense disambiguation rivaling supervised methods", "author": ["David Yarowsky"], "venue": null, "citeRegEx": "Yarowsky.,? \\Q1995\\E", "shortCiteRegEx": "Yarowsky.", "year": 1995}, {"title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars", "author": ["Zettlemoyer", "Collins2005] Luke S. Zettlemoyer", "Michael Collins"], "venue": null, "citeRegEx": "Zettlemoyer et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zettlemoyer et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 0, "context": "The Abstract Meaning Representation (AMR) (Banarescu et al., 2013) is a rich, graph-based language for expressing semantics over a broad do-", "startOffset": 42, "endOffset": 66}, {"referenceID": 10, "context": "We follow previous work (Flanigan et al., 2014) in dividing AMR parsing into two steps.", "startOffset": 24, "endOffset": 47}, {"referenceID": 10, "context": "For example, when the existing AMR parser JAMR (Flanigan et al., 2014) is given a gold NER++ output, and must only perform SRL++ over given subgraphs it scores 80 F1 \u2013 nearly the inter-annotator agreement of 83 F1, and far higher than its end to end accuracy of 59 F1.", "startOffset": 47, "endOffset": 70}, {"referenceID": 10, "context": "graphs are combined into a coherent AMR parse using the maximum spanning connected subgraph algorithm of Flanigan et al. (2014).", "startOffset": 105, "endOffset": 128}, {"referenceID": 10, "context": "62 smatch (an F1 measure of correct AMR arcs; see Cai and Knight (2013)) when incorporated into the SRL++ parser of Flanigan et al. (2014). When evaluating the performance of our action classifier in isolation, we obtain an action classification ac-", "startOffset": 116, "endOffset": 139}, {"referenceID": 7, "context": "AMR is based on neo-Davidsonian semantics, (Davidson, 1967; Parsons, 1990).", "startOffset": 43, "endOffset": 74}, {"referenceID": 21, "context": "AMR is based on neo-Davidsonian semantics, (Davidson, 1967; Parsons, 1990).", "startOffset": 43, "endOffset": 74}, {"referenceID": 20, "context": "The root node of the graph is labeled run-01, corresponding to the PropBank (Palmer et al., 2005) definition of the verb ran.", "startOffset": 76, "endOffset": 97}, {"referenceID": 24, "context": "The label for destination is taken from a finite set of special arc sense tags similar to the preposition senses found in (Srikumar, 2013).", "startOffset": 122, "endOffset": 138}, {"referenceID": 10, "context": "DICT This class serves as a back-off for the other classes, implementing an approach similar to Flanigan et al. (2014). In particular, we memorize a simple mapping from spans of text (such", "startOffset": 96, "endOffset": 119}, {"referenceID": 10, "context": "The approach taken in Flanigan et al. (2014) can be", "startOffset": 22, "endOffset": 45}, {"referenceID": 22, "context": "Pourdamghani et al. (2014) approached the alignment problem in the framework of the IBM alignment models.", "startOffset": 0, "endOffset": 27}, {"referenceID": 12, "context": "Prior work in AMR and related formalisms include Jones et al. (2012), and Flanigan et al.", "startOffset": 49, "endOffset": 69}, {"referenceID": 13, "context": "Jones et al. (2012), motivated by applications in Machine Translation, proposed a graphical semantic meaning representation that predates AMR, but is intimately related.", "startOffset": 0, "endOffset": 20}, {"referenceID": 10, "context": "Flanigan et al. (2014) forms the basis of the approach of this paper.", "startOffset": 0, "endOffset": 23}, {"referenceID": 10, "context": "Flanigan et al. (2014) forms the basis of the approach of this paper. Their system introduces the two-stage approach we use: they implement a rule-based alignment to learn a mapping from tokens to subgraphs, and train a variant of a maximum spanning tree parser adapted to graphs and with additional constraints for their relation identifications (SRL++) component. Wang et al. (2015) uses a transition based algorithm to transform dependency trees into AMR parses.", "startOffset": 0, "endOffset": 385}, {"referenceID": 9, "context": "These include named entity recognition (Nadeau and Sekine, 2007; Finkel et al., 2005), word sense disambiguation (Yarowsky, 1995; Banerjee and Pedersen, 2002), lemmatization, and a number of more domain specific tasks.", "startOffset": 39, "endOffset": 85}, {"referenceID": 28, "context": ", 2005), word sense disambiguation (Yarowsky, 1995; Banerjee and Pedersen, 2002), lemmatization, and a number of more domain specific tasks.", "startOffset": 35, "endOffset": 80}, {"referenceID": 26, "context": "For example, a full understanding of AMR requires normalizing temporal expressions (Verhagen et al., 2010; Str\u00f6tgen and Gertz, 2010; Chang and Manning, 2012).", "startOffset": 83, "endOffset": 157}, {"referenceID": 23, "context": "In turn, the SRL++ facet of AMR takes many insights from semantic role labeling (Gildea and Jurafsky, 2002; Punyakanok et al., 2004; Srikumar, 2013; Das et al., 2014) to capture the rela-", "startOffset": 80, "endOffset": 166}, {"referenceID": 24, "context": "In turn, the SRL++ facet of AMR takes many insights from semantic role labeling (Gildea and Jurafsky, 2002; Punyakanok et al., 2004; Srikumar, 2013; Das et al., 2014) to capture the rela-", "startOffset": 80, "endOffset": 166}, {"referenceID": 17, "context": "tactic dependency parsing (de Marneffe and Manning, 2008; McDonald et al., 2005; Buchholz and Marsi, 2006).", "startOffset": 26, "endOffset": 106}, {"referenceID": 14, "context": "More generally, parsing to a semantic representation is has been explored in depth for when the representation is a logical form (Kate et al., 2005; Zettlemoyer and Collins, 2005; Liang et al., 2011).", "startOffset": 129, "endOffset": 199}, {"referenceID": 16, "context": "More generally, parsing to a semantic representation is has been explored in depth for when the representation is a logical form (Kate et al., 2005; Zettlemoyer and Collins, 2005; Liang et al., 2011).", "startOffset": 129, "endOffset": 199}, {"referenceID": 2, "context": "For example, work by Berant et al. (2014) parses text into a formal representation of a biological process.", "startOffset": 21, "endOffset": 42}, {"referenceID": 2, "context": "For example, work by Berant et al. (2014) parses text into a formal representation of a biological process. Hosseini et al. (2014) solves algebraic word problems by parsing them into a", "startOffset": 21, "endOffset": 131}, {"referenceID": 18, "context": "Interlingua (Mitamura et al., 1991; Carbonell et al., 1999; Levin et al., 1998) are an important inspiration for decoupling the semantics of the AMR language from the surface form of the text being parsed; although, AMR has a self-admitted English bias.", "startOffset": 12, "endOffset": 79}, {"referenceID": 5, "context": "Interlingua (Mitamura et al., 1991; Carbonell et al., 1999; Levin et al., 1998) are an important inspiration for decoupling the semantics of the AMR language from the surface form of the text being parsed; although, AMR has a self-admitted English bias.", "startOffset": 12, "endOffset": 79}, {"referenceID": 15, "context": "Interlingua (Mitamura et al., 1991; Carbonell et al., 1999; Levin et al., 1998) are an important inspiration for decoupling the semantics of the AMR language from the surface form of the text being parsed; although, AMR has a self-admitted English bias.", "startOffset": 12, "endOffset": 79}, {"referenceID": 10, "context": "We evaluate our NER++ component in the context of end-to-end AMR parsing on two corpora: the newswire section of LDC2014T12 and the split given in Flanigan et al. (2014) of LDC2013E117, both consisting primarily of newswire.", "startOffset": 147, "endOffset": 170}, {"referenceID": 10, "context": "pare two systems: the JAMR parser (Flanigan et al., 2014),2 and the JAMR SRL++ component with our NER++ approach.", "startOffset": 34, "endOffset": 57}, {"referenceID": 10, "context": "We find our informativeness-based alignment objective slightly improves end-to-end performance when compared to the rule-based approach of (Flanigan et al., 2014), improving F1 by roughly 1 point (64/59/61 P/R/F1 to 65/59/62 P/R/F1).", "startOffset": 139, "endOffset": 162}], "year": 2015, "abstractText": "The Abstract Meaning Representation (AMR) is a representation for opendomain rich semantics, with potential use in fields like event extraction and machine translation. Node generation, typically done using a simple dictionary lookup, is currently an important limiting factor in AMR parsing. We propose a small set of actions that derive AMR subgraphs by transformations on spans of text, which allows for more robust learning of this stage. Our set of construction actions generalize better than the previous approach, and can be learned with a simple classifier. We improve on the previous state-of-the-art result for AMR parsing, boosting end-to-end performance by 3 F1 on both the LDC2013E117 and LDC2014T12 datasets.", "creator": "LaTeX with hyperref package"}}}