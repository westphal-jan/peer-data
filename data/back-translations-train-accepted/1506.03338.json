{"id": "1506.03338", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2015", "title": "Neural Adaptive Sequential Monte Carlo", "abstract": "Sequential Monte Carlo (SMC), or particle filtering, is a popular class of methods for sampling from an intractable target distribution using a sequence of simpler intermediate distributions. Like other importance sampling-based methods, performance is critically dependent on the proposal distribution: a bad proposal can lead to arbitrarily inaccurate estimates of the target distribution. This paper presents a new method for automatically adapting the proposal using an approximation of the Kullback-Leibler divergence between the true posterior and the proposal distribution. The method is very flexible, applicable to any parameterised proposal distribution and it supports online and batch variants. We use the new framework to adapt powerful proposal distributions with rich parameterisations based upon neural networks leading to Neural Adaptive Sequential Monte Carlo (NASMC). Experiments indicate that NASMC significantly improves inference in a non-linear state space model outperforming adaptive proposal methods including the Extended Kalman and Unscented Particle Filters. Experiments also indicate that improved inference translates into improved parameter learning when NASMC is used as a subroutine of Particle Marginal Metropolis Hastings. Finally we show that NASMC is able to train a neural network-based deep recurrent generative model achieving results that compete with the state-of-the-art for polymorphic music modelling. NASMC can be seen as bridging the gap between adaptive SMC methods and the recent work in scalable, black-box variational inference.", "histories": [["v1", "Wed, 10 Jun 2015 14:52:09 GMT  (403kb)", "https://arxiv.org/abs/1506.03338v1", null], ["v2", "Thu, 11 Jun 2015 07:11:56 GMT  (403kb)", "http://arxiv.org/abs/1506.03338v2", null], ["v3", "Mon, 16 Nov 2015 21:28:48 GMT  (408kb)", "http://arxiv.org/abs/1506.03338v3", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["shixiang gu", "zoubin ghahramani", "richard e turner"], "accepted": true, "id": "1506.03338"}, "pdf": {"name": "1506.03338.pdf", "metadata": {"source": "CRF", "title": "Neural Adaptive Sequential Monte Carlo", "authors": ["Shixiang Gu Zoubin Ghahramani", "Richard E. Turner"], "emails": ["sg717@cam.ac.uk,", "zoubin@eng.cam.ac.uk,", "ret26@cam.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 150 6.03 338v 3 [cs.L G] 16 Nov 2"}, {"heading": "1 Introduction", "text": "In this context, it should be noted that this is not a purely formal matter, but a purely formal matter, which is a purely formal matter."}, {"heading": "2 Sequential Monte Carlo", "text": "We begin with a brief look at two basic SMC algorithms, sequential meaning sampling (SIS) and sequential meaning resampling (SIR). Consider a probabilistic model that includes (possibly multidimensional) hidden and observed states, the common distribution of which is defined as p (z1: T, x1: T). This general form subsumes general state models, such as Hidden Markov models (HMMs), as well as non-Markovian hidden state models, such as Gaussian processessessessessesses.The aim of the sequential meaning sampler is to approximate posterior distribution over the hidden states."}, {"heading": "2.1 The Critical Role of Proposal Distributions in Sequential Monte Carlo", "text": "The choice of application distribution in SMC is crucial. Even when applying the resampling step, poor application distribution results in trajectories that, when traced backwards, quickly collapse to a single ancestor. Clearly, this represents a poor approximation to the true rear p (z1: T | x1: T). However, these effects can be mitigated by increasing the number of particles and / or applying more complex additional MCMC movements [5, 2], but these strategies increase the computational cost. The conclusion is that the proposal should be selected with care. The optimal choice for an unrestricted proposal that has access to all the observed data at all times is the intracterial distribution q\u03c6 (z1: T | x1: T) = p\u03b8 (z1: T | x1: T). Given the limitations imposed by factoring, this will result in q (z1: 1 \u2212 xt: uncentered = centered \u2212 1), \u2212 centered in the next house."}, {"heading": "3 Adapting Proposals by Descending the Inclusive KL Divergence", "text": "In this work, the quality of the supply distribution will be optimized using the inclusive LL divergence between the actual posterior distribution and the proposal. (Parameters will be made explicit, as we will shortly be interested in adapting the proposal and learning the model.) This goal is chosen for four main reasons: First, this is a direct measure of the quality of the proposal, as opposed to those typically used as an effective sample size. Second, if the true posterior is in the class of distributions that are achievable by the proposal, then the goal has a global optimum at this point. Third, if the true posterior is not within this class, then this LL divergence tends to find proposals that have a higher entropy than the original, which is advantageous for the importance. (The exclusive LL is therefore not suitable)."}, {"heading": "4 Flexible and Trainable Proposal Distributions Using Neural Networks", "text": "The proposed adaptation method can be applied to all parametric application distributions. At this point, we briefly describe how this flexibility can be used to deploy powerful neural network-based parameterization, which has recently demonstrated excellent performance in supervised sequence learning tasks [10, 11]. In general, the application of these techniques to unattended sequence modeling is an active field of research that is still in its infancy [12], and this work opens a new avenue in this broader research effort. In short, the goal is to parameterize q\u03c6 (zt | z1: t \u2212 1, x1: t) - stochastic mapping of the proposal from all previous hidden states z1: t \u2212 1 and all observations (up to and including the current observation) x1: t to the current hidden state, zt - in a flexible, computationally efficient and traceable manner."}, {"heading": "5 Experiments", "text": "The goal of the experiments is threefold: First, to evaluate the performance of the adaptive method of inferring on standard benchmarks used by the SMC community with known soil truth. Second, to evaluate performance when using SMC as the inner loop of a learning algorithm. Again, we use an example with known soil truth. Third, to apply SMC learning to complex models that would normally be challenging for SMC relative to the state of the art in approximate inferencing. Instead, we use a number of other metrics. For experiments where the soil truth z1: T is known, we cannot effectively evaluate the basic mean square error number (RMSE) between the approximate rear mean of the latent variables (z-t) and the true value (MSE log) (z-1)."}, {"heading": "5.1 Inference in a Benchmark Nonlinear State-Space Model", "text": "To assess the effectiveness of our adaptive SMC method, we tested our method on a standard nonlinear state-space model commonly used to name SMC algorithms [2, 3]. The model is given by Eq. 3, where estimates are based on (\u03c3v, \u03c3w). Posterior distribution patterns (z1: T | x1: T) are highly multimodal due to uncertainty about the signs of the latent states. (zt \u2212 1) = N (zt \u2212 1, \u03c32v), p (z1) = N (z1; 0, 5), p (xt | zt) = N (zt \u2212 1), \u03c32w), f (zt \u2212 1, t \u2212 1 / 2 + 25zt \u2212 25zt \u2212 1) we: F cos (1.2t), g (z 2 t / 20 (3)."}, {"heading": "5.2 Inference in the Cart and Pole System", "text": "As a second and physically more sensible system, we considered a cart-pole system consisting of an inverted pendulum resting on a movable base [16], which was driven by an input of white noise. To simulate the system, an ODE solver was used from its motion equations. We considered the problem, the true position of the cart and the orientation of the pendulum (along with its derivatives and input noise) from noisy measurements of the position of the pole tip. Results are presented in Figure 2. The system is much more complicated than the model in Fig. 5.1 and does not allow the use of EKPF or UPF directly. Our suggested model RNN-MD successfully learns good suggestions without direct access to the previous dynamics."}, {"heading": "5.3 Bayesian learning in a Nonlinear SSM", "text": "A prominent example is the Particle-Markov chain in Monte Carlo [3], a class of methods that sample from the common posterior via model parameters \u03b8 and latent state paths, p (\u03b8, z1: T | x1: T). Here we look at the Particle-Marginal Metropolis-Hasting Sample (PMMH). In this context, SMC is used to construct a suggestion distribution for a Metropolis-Hasting (MH) acceptance / rejection step. The proposal is made by sampling a proposed set of parameters, e.g. by interfering with the current parameters using a Gaussian random course, then SMC is used to stab a proposed set of latent state variables, resulting in a common proposal q (subjects). The proposal is formed by sampling the proposed parameters, e.g. by sampling the current parameters using a Gaussian random path, then stitching a proposed set of latent state variables, which leads to a common proposal MC being used to a proposed latent."}, {"heading": "5.4 Polyphonic Music Generation", "text": "Finally, the new method is used to train a latent variable recurrent neural network (LV-RNN) to model four polymorphic music records of varying complexity [17]. These data sets are commonly used to evaluate RNN models due to their high dimensionality and the complex temporal dependencies involved on different timescales [17, 18, 19]. Each data set contains at least 7 hours of polyphonic music with an average polyphony (number of simultaneous notes) of 3.9 out of 88. LVRNN contains a recursive neural network with LSTM layers driven by i.i.e. stochastic latent variables (zt) at any point in time and stochastic outputs (xt) that are fed back into the dynamics (full details in the complementary material). Both LSTM data sets in the generative and suggestion models are set as approximate units."}, {"heading": "6 Comparison of Variational Inference to the NASMC approach", "text": "There are several similarities between NASMC and Variational Free Energy Methods that apply detection models. Variational Free Energy Methods refine an approximation q\u03c6 (z | x) to the posterior distribution p\u03b8 (z | x) by optimizing the exclusive (or variational) KL divergence KL [q\u03c6 (z | x) | p\u03b8 (z | x)]. It is customary to approximate this integral using samples from the approximate posterior [21, 22, 23]. This general approach is similar in the spirit of the way in which the proposal is adapted in NASMC, except that the inclusive KL divergence divergence is EmployedKL (z | x) | q\u03c6 (z | x) and this means that a random sample-based approximation requires a simulation from the true posterior. Critically, NASMC uses the approximate posterior distribution as a reference point to construct a more precise annerior."}, {"heading": "7 Conclusion", "text": "This paper developed a powerful method for adapting application distributions within general SMC algorithms. The method parameterizes application distribution using a recursive neural network to model long-term contextual information, enables flexible distribution forms including mixing density networks, and enables efficient training through stochastic gradient descent. It was found that the method outperforms existing adaptive application mechanisms including EKPF and UPF on a standard SMC benchmark, improves the branding and mixing of the PMMH sampler, and enables effective formation of latently variable recursive neural networks using SMC. We hope that the link between SMC and neural Network Technologies will inspire further research on adaptive SMC methods, in particular the application of the methods developed in this paper to adaptive particle smoothing, high-dimensional latent models, and adaptive PMCMC for probabilistic programming."}, {"heading": "Acknowledgments", "text": "SG is generously supported by the Cambridge-Tu \ufffd bingen Fellowship, the ALTA Institute and Jesus College, Cambridge. RET thanks the EPSRC (grants EP / G050821 / 1 and EP / L000776 / 1), Theano developers for their toolkit, the authors of [5] for publishing the source code, and Roger Frigola, Sumeet Singh, Fredrik Lindsten and Thomas Scho \ufffd n for providing helpful experimental suggestions."}], "references": [{"title": "Novel approach to nonlinear/non-gaussian bayesian state estimation", "author": ["N.J. Gordon", "D.J. Salmond", "A.F. Smith"], "venue": "IEE Proceedings F (Radar and Signal Processing), vol. 140, pp. 107\u2013113, IET, 1993.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1993}, {"title": "Sequential monte carlo methods in practice", "author": ["A. Doucet", "N. De Freitas", "N. Gordon"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2001}, {"title": "Particle markov chain monte carlo methods", "author": ["C. Andrieu", "A. Doucet", "R. Holenstein"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), vol. 72, no. 3, pp. 269\u2013342, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Particle approximations of the score and observed information matrix in state space models with application to parameter estimation", "author": ["G. Poyiadjis", "A. Doucet", "S.S. Singh"], "venue": "Biometrika, vol. 98, no. 1, pp. 65\u2013 80, 2011.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2011}, {"title": "The unscented particle filter", "author": ["R. Van Der Merwe", "A. Doucet", "N. De Freitas", "E. Wan"], "venue": "Advances in Neural Information Processing Systems, pp. 584\u2013590, 2000.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2000}, {"title": "Variational gaussian process state-space models", "author": ["R. Frigola", "Y. Chen", "C. Rasmussen"], "venue": "Advances in Neural Information Processing Systems, pp. 3680\u20133688, 2014.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Information theory, inference, and learning", "author": ["D.J. MacKay"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "Expectation propagation for approximate bayesian inference", "author": ["T.P. Minka"], "venue": "Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence, pp. 362\u2013369, Morgan Kaufmann Publishers Inc., 2001.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2001}, {"title": "Adaptive Sequential Monte Carlo Methods", "author": ["J. Cornebise"], "venue": "PhD thesis,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Supervised sequence labelling with recurrent neural networks, vol. 385", "author": ["A. Graves"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in Neural Information Processing Systems, pp. 3104\u20133112, 2014.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "CoRR, vol. abs/1308.0850, 2013.", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2013}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1997}, {"title": "Mixture density networks", "author": ["C.M. Bishop"], "venue": "1994.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1994}, {"title": "DRAW: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D.J. Rezende", "D. Wierstra"], "venue": "Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015, pp. 1462\u20131471, 2015.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Nonlinear modelling and control using Gaussian processes", "author": ["A. McHutchon"], "venue": "PhD thesis,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Modeling temporal dependencies in highdimensional sequences: Application to polyphonic music generation and transcription", "author": ["N. Boulanger-Lewandowski", "Y. Bengio", "P. Vincent"], "venue": "International Conference on Machine Learning (ICML), 2012.", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Advances in optimizing recurrent networks", "author": ["Y. Bengio", "N. Boulanger-Lewandowski", "R. Pascanu"], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pp. 8624\u2013 8628, IEEE, 2013.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning stochastic recurrent networks", "author": ["J. Bayer", "C. Osendorfer"], "venue": "arXiv preprint arXiv:1411.7610, 2014.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D.P. Kingma", "J. Ba"], "venue": "The International Conference on Learning Representations (ICLR), 2015.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Auto-encoding variational bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "The International Conference on Learning Representations (ICLR), 2014.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "International Conference on Machine Learning (ICML), 2014.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Neural variational inference and learning in belief networks", "author": ["A. Mnih", "K. Gregor"], "venue": "International Conference on Machine Learning (ICML), 2014.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "Two problems with variational expectation maximisation for time-series models", "author": ["R.E. Turner", "M. Sahani"], "venue": "Bayesian Time series models (D. Barber, T. Cemgil, and S. Chiappa, eds.), ch. 5, pp. 109\u2013 130, Cambridge University Press, 2011.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2011}, {"title": "The\u201d wake-sleep\u201d algorithm for unsupervised neural networks", "author": ["G.E. Hinton", "P. Dayan", "B.J. Frey", "R.M. Neal"], "venue": "Science, vol. 268, no. 5214, pp. 1158\u20131161, 1995.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1995}, {"title": "Reweighted wake-sleep", "author": ["J. Bornschein", "Y. Bengio"], "venue": "The International Conference on Learning Representations (ICLR), 2015. 9", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "More specifically, the sequence constructs a proposal for importance sampling (IS) [1, 2].", "startOffset": 83, "endOffset": 89}, {"referenceID": 1, "context": "More specifically, the sequence constructs a proposal for importance sampling (IS) [1, 2].", "startOffset": 83, "endOffset": 89}, {"referenceID": 1, "context": "SMC is particularly well-suited for performing inference in non-linear dynamical models with hidden variables, since filtering naturally decomposes into a sequence, and in many such cases it is the state-of-the-art inference method [2, 3].", "startOffset": 232, "endOffset": 238}, {"referenceID": 2, "context": "SMC is particularly well-suited for performing inference in non-linear dynamical models with hidden variables, since filtering naturally decomposes into a sequence, and in many such cases it is the state-of-the-art inference method [2, 3].", "startOffset": 232, "endOffset": 238}, {"referenceID": 3, "context": "SMC has been used in such a way for both approximate maximum-likelihood parameter learning [4] and in Bayesian approaches such as the recently developed Particle MCMC methods [3].", "startOffset": 91, "endOffset": 94}, {"referenceID": 2, "context": "SMC has been used in such a way for both approximate maximum-likelihood parameter learning [4] and in Bayesian approaches such as the recently developed Particle MCMC methods [3].", "startOffset": 175, "endOffset": 178}, {"referenceID": 0, "context": "If the proposal is not well-matched to the target distribution, then the method can produce samples that have low effective sample size and this leads to Monte Carlo estimates that have pathologically high variance [1].", "startOffset": 215, "endOffset": 218}, {"referenceID": 0, "context": "The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3].", "startOffset": 160, "endOffset": 163}, {"referenceID": 4, "context": "The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3].", "startOffset": 231, "endOffset": 240}, {"referenceID": 1, "context": "The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3].", "startOffset": 231, "endOffset": 240}, {"referenceID": 2, "context": "The SMC community has developed approaches to mitigate these limitations such as resampling to improve particle diversity when the effective sample size is low [1] and applying MCMC transition kernels to improve particle diversity [5, 2, 3].", "startOffset": 231, "endOffset": 240}, {"referenceID": 4, "context": "ter (UPF) [5].", "startOffset": 10, "endOffset": 13}, {"referenceID": 2, "context": "We show that improved performance of the SMC algorithm translates into improved mixing of the Particle Marginal Metropolis-Hasting (PMMH) [3].", "startOffset": 138, "endOffset": 141}, {"referenceID": 0, "context": "To alleviate the problem, the Sequential Importance Resampling (SIR) algorithm [1] adds an additional step that resamples z t at time t from a multinomial distribution given by w\u0303(z (n) 1:t ) and gives the new particles equal weight.", "startOffset": 79, "endOffset": 82}, {"referenceID": 1, "context": "Finally, to lighten notation, we use the shorthand More advanced implementations resample only when the effective sample size falls below a threshold [2].", "startOffset": 150, "endOffset": 153}, {"referenceID": 4, "context": "These effects can be mitigated by increasing the number of particles and/or applying more complex additional MCMC moves [5, 2], but these strategies increase the computational cost.", "startOffset": 120, "endOffset": 126}, {"referenceID": 1, "context": "These effects can be mitigated by increasing the number of particles and/or applying more complex additional MCMC moves [5, 2], but these strategies increase the computational cost.", "startOffset": 120, "endOffset": 126}, {"referenceID": 4, "context": "Examples include the EKPF and UPF [5].", "startOffset": 34, "endOffset": 37}, {"referenceID": 5, "context": "First, the extended and unscented Kalman Filter from which these methods are derived are known to be inaccurate and poorly behaved for many problems outside of the SMC setting [6].", "startOffset": 176, "endOffset": 179}, {"referenceID": 6, "context": "Third, if the true posterior does not lie within this class, then this KL divergence tends to find proposal distributions that have higher entropy than the original which is advantageous for importance sampling (the exclusive KL is unsuitable for this reason [7]).", "startOffset": 259, "endOffset": 262}, {"referenceID": 3, "context": "A similar derivation for maximum likelihood learning is also discussed in [4].", "startOffset": 74, "endOffset": 77}, {"referenceID": 7, "context": "Similarly, although the method bears similarity to the assumed-density filter (ADF) [8] which minimizes a (local) inclusive KL, the new method has the advantage of minimizing a global cost and does not require particle-specific moment matching.", "startOffset": 84, "endOffset": 87}, {"referenceID": 8, "context": "Special cases have been previously treated by [9].", "startOffset": 46, "endOffset": 49}, {"referenceID": 9, "context": "Here we briefly describe how to utilize this flexibility to employ powerful neural network-based parameterizations that have recently shown excellent performance in supervised sequence learning tasks [10, 11].", "startOffset": 200, "endOffset": 208}, {"referenceID": 10, "context": "Here we briefly describe how to utilize this flexibility to employ powerful neural network-based parameterizations that have recently shown excellent performance in supervised sequence learning tasks [10, 11].", "startOffset": 200, "endOffset": 208}, {"referenceID": 11, "context": "Generally speaking, applications of these techniques to unsupervised sequence modeling settings is an active research area that is still in its infancy [12] and this work opens a new avenue in this wider research effort.", "startOffset": 152, "endOffset": 156}, {"referenceID": 12, "context": "Here we use a class of functions called Long Short-Term Memory (LSTM) that define a deterministic mapping from an input sequence to an output sequence using parameter-efficient recurrent dynamics, and alleviate the common vanishing gradient problem in recurrent neural networks [13, 10, 11].", "startOffset": 278, "endOffset": 290}, {"referenceID": 9, "context": "Here we use a class of functions called Long Short-Term Memory (LSTM) that define a deterministic mapping from an input sequence to an output sequence using parameter-efficient recurrent dynamics, and alleviate the common vanishing gradient problem in recurrent neural networks [13, 10, 11].", "startOffset": 278, "endOffset": 290}, {"referenceID": 10, "context": "Here we use a class of functions called Long Short-Term Memory (LSTM) that define a deterministic mapping from an input sequence to an output sequence using parameter-efficient recurrent dynamics, and alleviate the common vanishing gradient problem in recurrent neural networks [13, 10, 11].", "startOffset": 278, "endOffset": 290}, {"referenceID": 13, "context": "The distributions q\u03c6(zt|ht) can be a mixture of Gaussians (a mixture density network (MDN) [14]) in which the mixing proportions, means and covariances are parameterised through another neural network (see the supplementary for details on LSTM, MDN, and neural network architectures).", "startOffset": 91, "endOffset": 95}, {"referenceID": 1, "context": "In order to evaluate the effectiveness of our adaptive SMC method, we tested our method on a standard nonlinear state-space model often used to benchmark SMC algorithms [2, 3].", "startOffset": 169, "endOffset": 175}, {"referenceID": 2, "context": "In order to evaluate the effectiveness of our adaptive SMC method, we tested our method on a standard nonlinear state-space model often used to benchmark SMC algorithms [2, 3].", "startOffset": 169, "endOffset": 175}, {"referenceID": 14, "context": "Can injecting information about the prior dynamics into the proposal improve performance (similar in spirit to [15] for variational methods)? To assess this, we parameterized proposals for vt (process noise) instead of zt (-f-), and let the proposal have access to the prior dynamics f(zt\u22121, t) .", "startOffset": 111, "endOffset": 115}, {"referenceID": 4, "context": "67s RNN-NASMC, where EKPF and UPF implementations are provided by [5].", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "Interestingly, there is no clear cut winner between the EKPF and UPF, although the UPF does return LML estimates that have lower variance [5].", "startOffset": 138, "endOffset": 141}, {"referenceID": 15, "context": "As a second and more physically meaningful system we considered a cart-pole system that consists of an inverted pendulum that rests on a movable base [16].", "startOffset": 150, "endOffset": 154}, {"referenceID": 2, "context": "One prominent example is Particle Markov Chain Monte Carlo [3], a class of methods that sample from the joint posterior over model parameters \u03b8 and latent state trajectories, p(\u03b8, z1:T |x1:T ).", "startOffset": 59, "endOffset": 62}, {"referenceID": 2, "context": "1 following [3].", "startOffset": 12, "endOffset": 15}, {"referenceID": 16, "context": "Finally, the new method is used to train a latent variable recurrent neural network (LV-RNN) for modelling four polymorphic music datasets of varying complexity [17].", "startOffset": 161, "endOffset": 165}, {"referenceID": 16, "context": "These datasets are often used to benchmark RNN models because of their high dimensionality and the complex temporal dependencies involved at different time scales [17, 18, 19].", "startOffset": 163, "endOffset": 175}, {"referenceID": 17, "context": "These datasets are often used to benchmark RNN models because of their high dimensionality and the complex temporal dependencies involved at different time scales [17, 18, 19].", "startOffset": 163, "endOffset": 175}, {"referenceID": 18, "context": "These datasets are often used to benchmark RNN models because of their high dimensionality and the complex temporal dependencies involved at different time scales [17, 18, 19].", "startOffset": 163, "endOffset": 175}, {"referenceID": 19, "context": "Both the LSTM layers in the generative and proposal models are set as 1000 units and Adam [20] is used as the optimizer.", "startOffset": 90, "endOffset": 94}, {"referenceID": 16, "context": "The hyperparameters are tuned using the validation set [17].", "startOffset": 55, "endOffset": 59}, {"referenceID": 17, "context": "The log likelihood on the test set, a standard metric for comparison in generative models [18, 21, 19], is approximated using SMC with 500 particles.", "startOffset": 90, "endOffset": 102}, {"referenceID": 20, "context": "The log likelihood on the test set, a standard metric for comparison in generative models [18, 21, 19], is approximated using SMC with 500 particles.", "startOffset": 90, "endOffset": 102}, {"referenceID": 18, "context": "The log likelihood on the test set, a standard metric for comparison in generative models [18, 21, 19], is approximated using SMC with 500 particles.", "startOffset": 90, "endOffset": 102}, {"referenceID": 18, "context": "\u201cFD-RNN\u201d and \u201cSTORN\u201d are from [19], and \u201csRNN\u201d and \u201cRNN-NADE\u201d are results from [18].", "startOffset": 30, "endOffset": 34}, {"referenceID": 17, "context": "\u201cFD-RNN\u201d and \u201cSTORN\u201d are from [19], and \u201csRNN\u201d and \u201cRNN-NADE\u201d are results from [18].", "startOffset": 79, "endOffset": 83}, {"referenceID": 20, "context": "It is common to approximate this integral using samples from the approximate posterior [21, 22, 23].", "startOffset": 87, "endOffset": 99}, {"referenceID": 21, "context": "It is common to approximate this integral using samples from the approximate posterior [21, 22, 23].", "startOffset": 87, "endOffset": 99}, {"referenceID": 22, "context": "It is common to approximate this integral using samples from the approximate posterior [21, 22, 23].", "startOffset": 87, "endOffset": 99}, {"referenceID": 23, "context": "We believe that this can lead to significant advantages over variational free-energy methods, especially in the time-series setting where variational methods are known to have severe biases [24].", "startOffset": 190, "endOffset": 194}, {"referenceID": 24, "context": "There is a close connection between NASMC and the wake-sleep algorithm [25] .", "startOffset": 71, "endOffset": 75}, {"referenceID": 25, "context": "The wake-sleep algorithm also employs the inclusive KL divergence to refine a posterior approximation and recent generalizations have shown how to incorporate this idea into importance sampling [26].", "startOffset": 194, "endOffset": 198}, {"referenceID": 4, "context": "We thank Theano developers for their toolkit, the authors of [5] for releasing the source code, and Roger Frigola, Sumeet Singh, Fredrik Lindsten, and Thomas Sch\u00f6n for helpful suggestions on experiments.", "startOffset": 61, "endOffset": 64}], "year": 2015, "abstractText": "Sequential Monte Carlo (SMC), or particle filtering, is a popular class of methods for sampling from an intractable target distribution using a sequence of simpler intermediate distributions. Like other importance sampling-based methods, performance is critically dependent on the proposal distribution: a bad proposal can lead to arbitrarily inaccurate estimates of the target distribution. This paper presents a new method for automatically adapting the proposal using an approximation of the Kullback-Leibler divergence between the true posterior and the proposal distribution. The method is very flexible, applicable to any parameterized proposal distribution and it supports online and batch variants. We use the new framework to adapt powerful proposal distributions with rich parameterizations based upon neural networks leading to Neural Adaptive Sequential Monte Carlo (NASMC). Experiments indicate that NASMC significantly improves inference in a non-linear state space model outperforming adaptive proposal methods including the Extended Kalman and Unscented Particle Filters. Experiments also indicate that improved inference translates into improved parameter learning when NASMC is used as a subroutine of Particle Marginal Metropolis Hastings. Finally we show that NASMC is able to train a latent variable recurrent neural network (LV-RNN) achieving results that compete with the state-of-the-art for polymorphic music modelling. NASMC can be seen as bridging the gap between adaptive SMC methods and the recent work in scalable, black-box variational inference.", "creator": "LaTeX with hyperref package"}}}