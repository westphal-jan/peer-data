{"id": "1506.03487", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2015", "title": "From Paraphrase Database to Compositional Paraphrase Model and Back", "abstract": "The Paraphrase Database (PPDB; Ganitkevitch et al., 2013) is an extensive semantic resource, consisting of a list of phrase pairs with (heuristic) confidence estimates. However, it is still unclear how it can best be used, due to the heuristic nature of the confidences and its necessarily incomplete coverage. We propose models to leverage the phrase pairs from the PPDB to build parametric paraphrase models that score paraphrase pairs more accurately than the PPDB's internal scores while simultaneously improving its coverage. They allow for learning phrase embeddings as well as improved word embeddings. Moreover, we introduce two new, manually annotated datasets to evaluate short-phrase paraphrasing models. Using our paraphrase model trained using PPDB, we achieve state-of-the-art results on standard word and bigram similarity tasks and beat strong baselines on our new short phrase paraphrase tasks.", "histories": [["v1", "Wed, 10 Jun 2015 21:29:28 GMT  (35kb)", "https://arxiv.org/abs/1506.03487v1", "2015 TACL paper to Appear. Submitted 1/2015. Accepted 2/2015. Published 6/2015"], ["v2", "Wed, 26 Aug 2015 21:18:00 GMT  (36kb)", "http://arxiv.org/abs/1506.03487v2", "2015 TACL paper updated with an appendix describing new 300 dimensional embeddings. Submitted 1/2015. Accepted 2/2015. Published 6/2015"]], "COMMENTS": "2015 TACL paper to Appear. Submitted 1/2015. Accepted 2/2015. Published 6/2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["john wieting", "mohit bansal", "kevin gimpel", "karen livescu", "dan roth"], "accepted": true, "id": "1506.03487"}, "pdf": {"name": "1506.03487.pdf", "metadata": {"source": "CRF", "title": "From Paraphrase Database to Compositional Paraphrase Model and Back", "authors": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu", "Dan Roth"], "emails": ["wieting2@illinois.edu", "danr@illinois.edu", "mbansal@ttic.edu", "kgimpel@ttic.edu", "klivescu@ttic.edu"], "sections": [{"heading": null, "text": "ar Xiv: 150 6.03 487v 2 [cs.C L] 26 Aug 201 5"}, {"heading": "1 Introduction", "text": "In fact, it is the case that most of the people who have decided to take such a step are able to walk it as well. \"It is not that they have accepted such a step.\" But it is as if \".\" \"It is as if\". \"\" It is as if \".\" \"It is as if\". \"\" It is as if. \"\" It is as if \".\" \"\" It is as if. \"\" \"It is as if.\" \"\" It is as if. \"\" It is as if. \"\" \"It is as if.\" \".\" \"\". \"\". \"\" \".\" \"\". \"\" \".\" \"\" \".\" \"\" \".\" \"\" \".\" \"\" \".\" \"\" \"\". \"\" \"\". \"\" \".\" \"\" \".\" \"\" \"\". \"\" \"\" \".\" \"\". \"\" \"\" \".\" \"\" \".\" \"\". \"\" \".\" \"\" \"\". \"\". \".\" \"\" \".\" \"\" \"\" \".\". \"\" \".\" \".\" \"\" \".\" \"\" \"\" \".\" \".\". \"\". \"\" \"\". \"\". \"\" \".\" \".\" \".\" \"\". \"\". \"\". \"\". \"\" \".\" \"\". \".\" \"\" \".\" \".\". \"\" \"\". \".\". \"\" \"\". \"\". \"\" \".\" \".\" \".\" \"\". \"\" \".\" \"\" \".\" \"\" \".\". \".\" \".\". \"\" \".\" \".\" \"\". \".\" \"\" \".\" \"\" \"\" \".\" \"\" \"\" \".\" \"\" \".\" \"\" \"\". \".\" \"\" \"\" \"\" \".\" \"\". \"\" \"\" \".\" \"\" \"\". \"\" \".\" \".\". \"\" \"\". \"\" \"\" \".\" \"\" \".\". \"\" \"\". \"\" \"\" \"\". \".\" \"\" \"\". \".\" \".\" \"\". \".\" \""}, {"heading": "2 Related Work", "text": "The intuition of most methods of creating these vectors (or embedding) is that similar words have similar contexts (Firth, 1957). Previous models used latent semantic analysis (LSA) (Deerwester et al., 1990), but these embeddings are now being used in new ways because they are tailored to specific downstream tasks (Bansal et al., 2014). Phrase representations can be made from word vectors using composition models. Simple but effective composition models have been studied by Mitchell and Lapata (2010) and Blacoe and Lapata Zoloze (2012), who compared a variety of binary operations on word vectors and found that simple point-wise multiplication is performed by them."}, {"heading": "3 New Paraphrase Datasets", "text": "We created two new datasets: (1) AnnotatedPPDB, a subset of phrases from the PPDB that are commented according to their strength for a paraphrase relationship, and (2) ML Paraphrase, a rewrite of the Mitchell and Lapata Bigram similarity dataset (2010), which is commented on due to the strength of the paraphrase relationship."}, {"heading": "3.1 Annotated-PPDB", "text": "Most existing paraphrase tasks focus on words, such as SimLex-999 (Hill et al., 2014b), or entire sentences, such as Microsoft Research Paraphrase Corpus (Dolan et al., 2004; Quirk et al., 2004). To our knowledge, there are no datasets that focus on the feasibility of short phrases. So we created Annotated-PPPDB so that researchers can focus on local compositional phenomena and directly measure the performance of models - avoiding the need to do so at a sentence level. Models that have strong performance on Annotated-PPDB can be used to provide more accurate reliability values for the PPPDB as well as reduce the need for large paraphrase tables altogether.5We replicated this approach and found time to use paraphrases."}, {"heading": "3.2 ML-Paraphrase", "text": "Our second newly commented dataset, the ML paraphrase, is based on the Bigram similarity task originally introduced by Mitchell and Lapata (2010); we refer to the original annotations as the ML dataset. The ML dataset consists of human similarity ratings for three types of bigrams: adjective-noun (JN), noun-noun (NN), and verb-noun (VN). Through manual verification, we found that the annotations were incompatible with the notion of similarity at the center of paraphrase tasks. For example, television and television were the highest rated phrases in the NN section (based on the average annotation value). Likewise, one of the highest rated JN pairs was an older man and an older woman. This indicates that the annotations reflect a topical similarity and not just functional or definitional similarity."}, {"heading": "4 Paraphrase Models", "text": "Our goal is to embed phrases in a low-dimensional space in such a way that cosine similarity in space corresponds to the strength of the paraphrase relationship between phrases. We use a recursive neural network (RNN) similar to that used by Socher et al. (2014). First, we use a constituent parser to obtain a binarized parser of a phrase. For phrase p, we recursively calculate its vector g (p) = f (W [g (c1); g (c2) + b), if phrase p is the yield of a parent node in a parse tree, and phrases c1 and c2 are the yields of its two child nodes, we define g (p) recursively as follows: g (p) = f (W [g (c1); g (c2) + b), where f has an elemental activation function (tanh); [c2) is the child node (W); (W) is the word (W)."}, {"heading": "4.1 Objective Functions", "text": "We present objective functions for training on pairs extracted from PPDB. Training data consists of (possibly noisy) pairs taken directly from the original PPDB. In the following sections we discuss how to extract training pairs for specific tasks. We assume that our training data consists of a series of phrase pairs. < x1, x2 >, where the objective results are used as parameters. (W, b, x2 > Ww), we minimize our objective function on the data using AdaGrad (Duchi et al., 2011) with mini batches. The objective function follows: min W, b, Ww1 | X (X1, x2 > Xmax)."}, {"heading": "5 Experiments \u2013 Word Paraphrasing", "text": "First, we present experiments for learning lexical paraphrasability. We train pairs of words from the PPDB and evaluate them on the SimLex 999 dataset (Hill et al., 2014b), achieving the best results to date."}, {"heading": "5.1 Training Procedure", "text": "To learn word vectors that reflect colloquial language, we optimized Equation 2. There are many tunable hyperparameters with this goal, so we set the initial learning rates for word embedding to 0.5 and the marginal values to 1. Then we performed a rough grid search over a parameter space for \u03bbWw and the mini-batch size. We took into account \u03bbWw values in {10 \u2212 2, 10 \u2212 3,..., 10 \u2212 7, 0} and minibatch sizes in {100, 250, 500, 1000}. We trained 20 epochs for each set of hyperparameters using AdaGrad (Duchi et al., 2011). For all experiments, we initialized our word vectors with word vectors trained with word2vec (Mikolov et al., 2013a). The vectors were trained in English Wikipedia (tokenized and lowerized, yielding 1.8B tokens).10 We used approximately 27K most frequently in the window."}, {"heading": "5.2 Extracting Training Data", "text": "We used the XL data for all experiments, including phrases. We used XL instead of XXL because XL overall is better quality, but still large enough to be selective in selecting the training pairs. There are 548,085 pairs in total. We removed 174,766 words that contained either numerical digits or words that were not in our vocabulary. We then removed 260,425 redundant pairs, so that we ended up with a set of 112,894 word pairs. 10We used the snapshot from December 2, 2013."}, {"heading": "5.3 Tuning and Evaluation", "text": "The hyperparameters were adjusted with the help of the dataset wordsim-353 (WS353) (Finkelstein et al., 2001), in particular its similarity (WS-S) and kinship (WSR) (Agirre et al., 2009). In particular, we tried to maximize the 2x WS-S correlation minus the WS-R correlation. The idea was to reward vectors with high similarity and relatively low kinship in order to target the paraphrase relationship. After the vote, we evaluated the best hyperparameters on the dataset SimLex-999 (SL999) (Hill et al., 2014b). As the primary test set, we chose SL999, as it most accurately evaluates the paraphrase relationship. Although WS-S represents a close approximation to this relationship, it does not include pairs that are merely associated and low values, the SL999 (the parallel equivalence we use for the cosmic relationship)."}, {"heading": "5.4 Results", "text": "Table 3 shows results on SL999 in improving the original word vectors by training on word pairs from the PPDB, both with and without limitations. The \"PARAGRAM WS\" lines show results in optimizing 2 \u00d7 WS-S-WS-R. We also show results for strong skipping programs and the best results from the literature, including state-of-the-art results from Hill et al. (2014a) and the Interannotator Agreement from Hill et al. (2014b). The table shows that by training on PPDB we can absolutely exceed the previous best correlations on SL999 by 4-6% and achieve the best results reported to date. We also find that we can train low-dimensional word vectors that outperform much larger vectors. This is very useful as the use of large vectors can increase both time and memory consumption in NLP applications."}, {"heading": "5.5 Sentiment Analysis", "text": "As an extrinsic evaluation of our PARAGRAM word vectors, we used them in a Convolutionary Neural Network (CNN) for sentiment analysis. We used the simple Kim CNN (2014) and the binary sentiment analysis task at the sentiment level by Socher et al. (2013). We used the standard data splits, removing examples with a neutral rating. We trained all the components of the training set while using only full sentences from the development and testing, giving us pull / development / test sizes of 67,349 / 872 / 1,821. CNN uses M-gram filters, each of which is a m \u00d7 n vector. CNN calculates the inner product between an m-gram filter and each m-gram ecgram in an example, maintaining the maximum match (so-called \"max-pooling\"). The score of the game is a single dimension in a feature vector that is linked to an example vector for a vector."}, {"heading": "6 Experiments \u2013 Compositional Paraphrasing", "text": "In this section, we describe experiments on a variety of compositional phrase-based paraphrasing tasks. We start with the simplest case of bigrams and then arrive at short phrases. For all tasks, we train the corresponding data from the PPDB again and test different evaluation data sets, including our two novel data sets (Annotated PPDB and ML paraphrase)."}, {"heading": "6.1 Training Procedure", "text": "We trained our models by optimizing Equation 1 using AdaGrad (Duchi et al., 2011). We set the initial learning rates for word embedding to 0.5 and for composition parameters to 0.05 and the margin to 1. Then we performed a rough grid search for a parameter space for \u03bbWw, \u03bbW and mini batch size. For \u03bbWw, our search space again consisted of {10 \u2212 2, 10 \u2212 3,..., 10 \u2212 7, 0}, for HigW it was {10 \u2212 1, 10 \u2212 2, 10 \u2212 3, 0}, and we investigated batch sizes of {100, 250, 500, 1000, 2000}. When initializing with PARAGRAM vectors, the search space for HigWw was shifted upward to be {10 \u2212 1, 10 \u2212 1, 10 \u2212 3,..., 10 \u2212 6} to reflect our increased confidence in the initial vectors."}, {"heading": "6.2 Evaluation and Baselines", "text": "For all experiments, we again used cosinal similarity as a comparative measure and evaluated statistical significance using the method of (Steiger, 1980).A baseline used in all compositional experiments is the vector addition of word vectors with skip gram (or PARAGRAM).In contrast to explicit word vectors, where point-by-point multiplication acts as a conjunction of characteristics and achieves good results in composition tasks (Mitchell and Lapata, 2008), addition with skip gram vectors (Mikolov et al., 2013b) results in better performance than multiplication."}, {"heading": "6.3 Bigram Paraphrasability", "text": "To analyze our ability to paraphrase bigrams, we consider the original Bigram similarity task by Mitchell and Lapata (2010) as well as our newlyannotated version of it: ML-Paraphrase.Extracting Training Data Training data for these tasks was extracted from the XL part of PPDB).The bigram similarity task from Mitchell and Lapata (2010) contains three types of bigrams: adjective-noun (JN), noun-noun (NN), and verb-noun (VN).We aimed to collect pairs of PPDB that mirror these three types of bigramsms. We found parsing to be unreliable on such short segments of text, so we used a POS tagger al (Manning et al., 2014) to tag the tokens in each phrase. We then used the word alignments in PPDB to extract bigramsms for training."}, {"heading": "6.4 Phrase Paraphrasability", "text": "In this section, we show that by building a model based on filtered phrase pairs in PPDB, the first major overlap of the word can actually be distinguished between quality paraphrases and bad paraphrases in PPDB, better than the original heuristic scoring scheme by Ganitkevitch et al. (2013).Extracting Training Data As Before, Training Data As Before, Training Data As Extract Extract Extract Extract From the XL Section of PDB).Similar to the process used to create our AnnotatedPDB Dataset, phrases were filtered so that only those with an overlap of less than 0.5 were kept. We also removed redundant phrases and phrases that contained tokens that were not included in our vocabulary, and the phrases were then selected according to their effective size and 20,000 examples that had effective sizes of 3, 4 and more than 5, creating a training sample of 60,000."}, {"heading": "7 Qualitative Analysis", "text": "We performed a qualitative analysis to identify sources of error and to determine differences between the addition of PARAGRAM vectors and the use of an RNN initiated with them. To do this, we took the output of both systems on annotated PPDB and mapped their cosmic similarities to the interval [1, 5] and then calculated their absolute error compared to the gold rates. This is probably because most positive pairs have high word overlaps and can thus be represented effectively with the size of the gold ratings."}, {"heading": "8 Conclusion", "text": "Since PPDB is automatically created from parallel corpora, our models are also built automatically. Only small amounts of annotated data are used to tune hyperparameters. In addition, we have introduced two new datasets to evaluate compositional models of short paraphrases, closing a gap in the NLP community as no datasets are currently being created for this purpose. Successful models based on these datasets can then be used to extend the coverage of PPDB or provide an alternative. Much work remains to be done in developing new composition models, whether with new network architectures or distance functions. In this work, we base our composition function on constituents of parse trees, but this may not be the best approach - especially for short phrases. Dependency syntax may be a better alternative (Socher et al. 2014). Besides improving composition in a different direction to explore text block specimens in other phrases."}, {"heading": "Appendix A", "text": "Increasing the dimension of word embedding or training these people can have a significant positive impact on many tasks - both word embedding and downstream tasks. We scale our original 25-dimensional PARAGRAM embedding and slightly modify our training process to produce two sets of 300-dimensional PARAGRAM vectors, outperforming our original 25-dimensional PARAGRAM vectors on all tasks and achieving human-level performance on SL999 and WS353. In addition, they are both on par with the RNN models we have designed specifically for each task."}, {"heading": "Acknowledgements", "text": "We thank the editor and the anonymous reviewers, as well as Yuri Ganitkevitch, Weiran Wang, and Kazuma Hashimoto, for their valuable comments and technical support. We also thank Chris Callison-Burch, Dipanjan Das, Kuzman Ganchev, Ellie Pavlick, Slav Petrov, Owen Rambow, David Sontag, Oscar Ta \ufffd ckstro \ufffd m, Kapil Thadani, Lyle Ungar, Benjamin Van Durme, and Mo Yu for helpful conversations. This research was supported by a Google Faculty Research Award to Mohit Bansal, Karen Livescu, and Kevin Gimpel, the Multimodal Information Access & Synthesis Center at UIUC, part of CCICADA, a DHS Science and Technology Center of Excellence, and by DARPA under contract number FA8750-13-2-0008. The views and conclusions contained therein are those of the authors and should not be interpreted to necessarily represent the official guidelines or remarks made at the DPA, when expressed or related to the USA."}], "references": [{"title": "A study on similarity and relatedness using distributional and wordnet-based approaches", "author": ["Eneko Agirre", "Enrique Alfonseca", "Keith Hall", "Jana Kravalova", "Marius Pa\u015fca", "Aitor Soroa."], "venue": "Proceedings of Human Language Technologies: The 2009 Annual Con-", "citeRegEx": "Agirre et al\\.,? 2009", "shortCiteRegEx": "Agirre et al\\.", "year": 2009}, {"title": "A survey of paraphrasing and textual entailment methods", "author": ["Ion Androutsopoulos", "Prodromos Malakasiotis."], "venue": "Journal of Artificial Intelligence Research, pages 135\u2013187.", "citeRegEx": "Androutsopoulos and Malakasiotis.,? 2010", "shortCiteRegEx": "Androutsopoulos and Malakasiotis.", "year": 2010}, {"title": "Paraphrasing with bilingual parallel corpora", "author": ["Colin Bannard", "Chris Callison-Burch."], "venue": "Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 597\u2013604. Association for Computational Linguistics.", "citeRegEx": "Bannard and Callison.Burch.,? 2005", "shortCiteRegEx": "Bannard and Callison.Burch.", "year": 2005}, {"title": "Tailoring continuous word representations for dependency parsing", "author": ["Mohit Bansal", "Kevin Gimpel", "Karen Livescu."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Bansal et al\\.,? 2014", "shortCiteRegEx": "Bansal et al\\.", "year": 2014}, {"title": "Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space", "author": ["Marco Baroni", "Roberto Zamparelli."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages", "citeRegEx": "Baroni and Zamparelli.,? 2010", "shortCiteRegEx": "Baroni and Zamparelli.", "year": 2010}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Janvin."], "venue": "The Journal of Machine Learning Research, 3:1137\u20131155.", "citeRegEx": "Bengio et al\\.,? 2003", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Semantic parsing via paraphrasing", "author": ["Jonathan Berant", "Percy Liang."], "venue": "Proceedings of ACL.", "citeRegEx": "Berant and Liang.,? 2014", "shortCiteRegEx": "Berant and Liang.", "year": 2014}, {"title": "The meaning factory: Formal semantics for recognizing textual entailment and determining semantic similarity", "author": ["Johannes Bjerva", "Johan Bos", "Rob van der Goot", "Malvina Nissim."], "venue": "SemEval 2014, page 642.", "citeRegEx": "Bjerva et al\\.,? 2014", "shortCiteRegEx": "Bjerva et al\\.", "year": 2014}, {"title": "A comparison of vector-based representations for semantic composition", "author": ["William Blacoe", "Mirella Lapata."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learn-", "citeRegEx": "Blacoe and Lapata.,? 2012", "shortCiteRegEx": "Blacoe and Lapata.", "year": 2012}, {"title": "Paraphrase substitution for recognizing textual entailment", "author": ["Wauter Bosma", "Chris Callison-Burch."], "venue": "Proceedings of the 7th International Conference on Cross-Language Evaluation Forum: Evaluation of Multilingual and Multi-modal Information Re-", "citeRegEx": "Bosma and Callison.Burch.,? 2007", "shortCiteRegEx": "Bosma and Callison.Burch.", "year": 2007}, {"title": "Libsvm: a library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin."], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27.", "citeRegEx": "Chang and Lin.,? 2011", "shortCiteRegEx": "Chang and Lin.", "year": 2011}, {"title": "Indexing by latent semantic analysis", "author": ["Scott C. Deerwester", "Susan T Dumais", "Thomas K. Landauer", "George W. Furnas", "Richard A. Harshman."], "venue": "JAsIs, 41(6):391\u2013407.", "citeRegEx": "Deerwester et al\\.,? 1990", "shortCiteRegEx": "Deerwester et al\\.", "year": 1990}, {"title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources", "author": ["Bill Dolan", "Chris Quirk", "Chris Brockett."], "venue": "Proceedings of Coling 2004, pages 350\u2013356, Geneva, Switzerland, Aug 23\u2013Aug 27. COLING.", "citeRegEx": "Dolan et al\\.,? 2004", "shortCiteRegEx": "Dolan et al\\.", "year": 2004}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer."], "venue": "J. Mach. Learn. Res., 12:2121\u20132159, July.", "citeRegEx": "Duchi et al\\.,? 2011", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Paraphrase-driven learning for open question answering", "author": ["Anthony Fader", "Luke Zettlemoyer", "Oren Etzioni."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1608\u20131618, Sofia, Bul-", "citeRegEx": "Fader et al\\.,? 2013", "shortCiteRegEx": "Fader et al\\.", "year": 2013}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Manaal Faruqui", "Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A. Smith."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Lin-", "citeRegEx": "Faruqui et al\\.,? 2015", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "Placing search in context: The concept revisited", "author": ["Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin."], "venue": "Proceedings of the 10th international conference on World Wide Web, pages 406\u2013414. ACM.", "citeRegEx": "Finkelstein et al\\.,? 2001", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2001}, {"title": "A Synopsis of Linguistic Theory, 19301955", "author": ["J.R. Firth"], "venue": null, "citeRegEx": "Firth.,? \\Q1957\\E", "shortCiteRegEx": "Firth.", "year": 1957}, {"title": "Ppdb: The paraphrase database", "author": ["Juri Ganitkevitch", "Benjamin Van Durme", "Chris Callison-Burch."], "venue": "HLT-NAACL, pages 758\u2013764. The Association for Computational Linguistics.", "citeRegEx": "Ganitkevitch et al\\.,? 2013", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "Jointly learning word representations and composition functions using predicate-argument structures", "author": ["Kazuma Hashimoto", "Pontus Stenetorp", "Makoto Miwa", "Yoshimasa Tsuruoka."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural", "citeRegEx": "Hashimoto et al\\.,? 2014", "shortCiteRegEx": "Hashimoto et al\\.", "year": 2014}, {"title": "Simlex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Felix Hill", "Roi Reichart", "Anna Korhonen."], "venue": "CoRR, abs/1408.3456.", "citeRegEx": "Hill et al\\.,? 2014b", "shortCiteRegEx": "Hill et al\\.", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746\u20131751, Doha, Qatar, October. Association for Computational Linguistics.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky."], "venue": "Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics:", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Improved statistical machine translation using monolingually-derived paraphrases", "author": ["Yuval Marton", "Chris Callison-Burch", "Philip Resnik."], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 381\u2013390, Singapore, Au-", "citeRegEx": "Marton et al\\.,? 2009", "shortCiteRegEx": "Marton et al\\.", "year": 2009}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781.", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in Neural Information Processing Systems, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Vector-based models of semantic composition", "author": ["Jeff Mitchell", "Mirella Lapata."], "venue": "ACL, pages 236\u2013 244. Citeseer.", "citeRegEx": "Mitchell and Lapata.,? 2008", "shortCiteRegEx": "Mitchell and Lapata.", "year": 2008}, {"title": "Composition in distributional models of semantics", "author": ["Jeff Mitchell", "Mirella Lapata."], "venue": "Cognitive Science, 34(8):1388\u20131439.", "citeRegEx": "Mitchell and Lapata.,? 2010", "shortCiteRegEx": "Mitchell and Lapata.", "year": 2010}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014), 12.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Monolingual machine translation for paraphrase generation", "author": ["Chris Quirk", "Chris Brockett", "William Dolan."], "venue": "Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 142\u2013149, Barcelona, Spain, July. Association for Computational Linguis-", "citeRegEx": "Quirk et al\\.,? 2004", "shortCiteRegEx": "Quirk et al\\.", "year": 2004}, {"title": "Augmenting FrameNet via PPDB", "author": ["Pushpendre Rastogi", "Benjamin Van Durme."], "venue": "Proceedings of the Second Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 1\u20135, Baltimore, Maryland, USA, June. Association for Compu-", "citeRegEx": "Rastogi and Durme.,? 2014", "shortCiteRegEx": "Rastogi and Durme.", "year": 2014}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Potts."], "venue": "Pro-", "citeRegEx": "Potts.,? 2013", "shortCiteRegEx": "Potts.", "year": 2013}, {"title": "Tests for comparing elements of a correlation matrix", "author": ["James H Steiger."], "venue": "Psychological Bulletin,", "citeRegEx": "Steiger.,? 1980", "shortCiteRegEx": "Steiger.", "year": 1980}, {"title": "Learning composition models for phrase embeddings", "author": ["Mo Yu", "Mark Dredze."], "venue": "Transactions of", "citeRegEx": "Yu and Dredze.,? 2015", "shortCiteRegEx": "Yu and Dredze.", "year": 2015}, {"title": "Estimating linear models for compositional", "author": ["Francesca Fallucchi", "Suresh Manandhar"], "venue": null, "citeRegEx": "Fallucchi and Manandhar.,? \\Q2010\\E", "shortCiteRegEx": "Fallucchi and Manandhar.", "year": 2010}], "referenceMentions": [{"referenceID": 18, "context": "The Paraphrase Database (PPDB; Ganitkevitch et al., 2013) is an extensive semantic resource, consisting of a list of phrase pairs with (heuristic) confidence estimates.", "startOffset": 24, "endOffset": 57}, {"referenceID": 14, "context": "a variety of NLP tasks like question answering (Rinaldi et al., 2003; Fader et al., 2013), semantic parsing (Berant and Liang, 2014), textual entail-", "startOffset": 47, "endOffset": 89}, {"referenceID": 6, "context": ", 2013), semantic parsing (Berant and Liang, 2014), textual entail-", "startOffset": 26, "endOffset": 50}, {"referenceID": 9, "context": "ment (Bosma and Callison-Burch, 2007), and machine translation (Marton et al.", "startOffset": 5, "endOffset": 37}, {"referenceID": 23, "context": "ment (Bosma and Callison-Burch, 2007), and machine translation (Marton et al., 2009).", "startOffset": 63, "endOffset": 84}, {"referenceID": 1, "context": "See Androutsopoulos and Malakasiotis (2010) for a survey on approaches for detecting paraphrases.", "startOffset": 4, "endOffset": 44}, {"referenceID": 18, "context": "The most recent work in this area is the Paraphrase Database (PPDB; Ganitkevitch et al., 2013), a collection of confidence-rated paraphrases created using the pivoting technique of Bannard and Callison-Burch (2005) over large parallel corpora.", "startOffset": 61, "endOffset": 94}, {"referenceID": 7, "context": ", 2013), for predicting sentence similarity (Bjerva et al., 2014), and to improve the coverage of FrameNet (Rastogi and Van Durme, 2014).", "startOffset": 44, "endOffset": 65}, {"referenceID": 2, "context": ", 2013), a collection of confidence-rated paraphrases created using the pivoting technique of Bannard and Callison-Burch (2005) over large parallel corpora.", "startOffset": 94, "endOffset": 128}, {"referenceID": 24, "context": "First we show that initial skip-gram word vectors (Mikolov et al., 2013a) can", "startOffset": 50, "endOffset": 73}, {"referenceID": 18, "context": "We use it to show that the phrase embeddings produced by our methods are significantly more indicative of paraphrasability than the original heuristic scoring used by Ganitkevitch et al. (2013). Thus we use the power of PPDB to improve its contents.", "startOffset": 167, "endOffset": 194}, {"referenceID": 26, "context": "Our second dataset, ML-Paraphrase, is a reannotation of the bigram similarity corpus from Mitchell and Lapata (2010). The task was originally developed to measure semantic similarity of bigrams, but some annotations are not congruent with the functional similarity central to paraphrase relationships.", "startOffset": 90, "endOffset": 117}, {"referenceID": 20, "context": "Provide new PARAGRAM word vectors, learned using PPDB, that achieve state-of-the-art performance on the SimLex-999 lexical similarity task (Hill et al., 2014b) and lead to improved performance in sentiment analysis.", "startOffset": 139, "endOffset": 159}, {"referenceID": 26, "context": "The second is a new annotation of the bigram similarity task in Mitchell and Lapata (2010) that makes it", "startOffset": 64, "endOffset": 91}, {"referenceID": 17, "context": "The intuition of most methods to create these vectors (or embeddings) is that similar words have similar contexts (Firth, 1957).", "startOffset": 114, "endOffset": 127}, {"referenceID": 11, "context": "Earlier models made use of latent semantic analysis (LSA) (Deerwester et al., 1990).", "startOffset": 58, "endOffset": 83}, {"referenceID": 5, "context": "Recently, more sophisticated neural models, work originating with (Bengio et al., 2003), have been gaining popularity (Mikolov et al.", "startOffset": 66, "endOffset": 87}, {"referenceID": 24, "context": ", 2003), have been gaining popularity (Mikolov et al., 2013a; Pennington et al., 2014).", "startOffset": 38, "endOffset": 86}, {"referenceID": 28, "context": ", 2003), have been gaining popularity (Mikolov et al., 2013a; Pennington et al., 2014).", "startOffset": 38, "endOffset": 86}, {"referenceID": 3, "context": "These embeddings are now being used in new ways as they are being tailored to specific downstream tasks (Bansal et al., 2014).", "startOffset": 104, "endOffset": 125}, {"referenceID": 7, "context": "Simple but effective compositional models were studied by Mitchell and Lapata (2008; 2010) and Blacoe and Lapata (2012). They compared a variety of binary operations on word vectors and found that simple point-wise multiplication of explicit vector representations performed very well.", "startOffset": 95, "endOffset": 120}, {"referenceID": 7, "context": "Simple but effective compositional models were studied by Mitchell and Lapata (2008; 2010) and Blacoe and Lapata (2012). They compared a variety of binary operations on word vectors and found that simple point-wise multiplication of explicit vector representations performed very well. Other works like Zanzotto et al. (2010) and Baroni and Zamparelli (2010) also explored composition using models based on operations of vectors and matrices.", "startOffset": 95, "endOffset": 326}, {"referenceID": 4, "context": "(2010) and Baroni and Zamparelli (2010) also explored composition using models based on operations of vectors and matrices.", "startOffset": 11, "endOffset": 40}, {"referenceID": 25, "context": "(2013a) also do well on compositional tasks simply by adding the word vectors (Mikolov et al., 2013b).", "startOffset": 78, "endOffset": 101}, {"referenceID": 23, "context": "More recent work has shown that the extremely efficient neural embeddings of Mikolov et al. (2013a) also do well on compositional tasks simply by adding the word vectors (Mikolov et al.", "startOffset": 77, "endOffset": 100}, {"referenceID": 19, "context": "Hashimoto et al. (2014)", "startOffset": 0, "endOffset": 24}, {"referenceID": 26, "context": "introduced an alternative word embedding and compositional model based on predicate-argument structures that does well on two simple composition tasks, including the one introduced by Mitchell and Lapata (2010).", "startOffset": 184, "endOffset": 211}, {"referenceID": 8, "context": "volving compositionality (Blacoe and Lapata, 2012; Hashimoto et al., 2014).", "startOffset": 25, "endOffset": 74}, {"referenceID": 19, "context": "volving compositionality (Blacoe and Lapata, 2012; Hashimoto et al., 2014).", "startOffset": 25, "endOffset": 74}, {"referenceID": 8, "context": "volving compositionality (Blacoe and Lapata, 2012; Hashimoto et al., 2014).5 However, we found success using RNNs in a supervised setting, similar to Socher et al. (2014), who used RNNs to learn representations for image descriptions.", "startOffset": 26, "endOffset": 171}, {"referenceID": 15, "context": "Lastly, the PPDB has been used along with other resources to learn word embeddings for several tasks, including semantic similarity, language modeling, predicting human judgments, and classification (Yu and Dredze, 2014; Faruqui et al., 2015).", "startOffset": 199, "endOffset": 242}, {"referenceID": 33, "context": "Concurrently with our work, it has also been used to construct paraphrase models for short phrases (Yu and Dredze, 2015).", "startOffset": 99, "endOffset": 120}, {"referenceID": 26, "context": "We created two novel datasets: (1) AnnotatedPPDB, a subset of phrase pairs from PPDB which are annotated according to how strongly they represent a paraphrase relationship, and (2) MLParaphrase, a re-annotation of the bigram similarity dataset from Mitchell and Lapata (2010), again annotated for strength of paraphrase relationship.", "startOffset": 249, "endOffset": 276}, {"referenceID": 20, "context": "Most existing paraphrase tasks focus on words, like SimLex-999 (Hill et al., 2014b), or entire sentences, such as the Microsoft Research Paraphrase Corpus (Dolan et al.", "startOffset": 63, "endOffset": 83}, {"referenceID": 12, "context": ", 2014b), or entire sentences, such as the Microsoft Research Paraphrase Corpus (Dolan et al., 2004; Quirk et al., 2004).", "startOffset": 80, "endOffset": 120}, {"referenceID": 29, "context": ", 2014b), or entire sentences, such as the Microsoft Research Paraphrase Corpus (Dolan et al., 2004; Quirk et al., 2004).", "startOffset": 80, "endOffset": 120}, {"referenceID": 26, "context": "Our second newly-annotated dataset, ML-Paraphrase, is based on the bigram similarity task originally introduced by Mitchell and Lapata (2010); we refer to the original annotations as the ML dataset.", "startOffset": 115, "endOffset": 142}, {"referenceID": 27, "context": "49 (final column) reported by Mitchell and Lapata and also surpassed by pointwise multiplication (Mitchell and Lapata, 2010).", "startOffset": 97, "endOffset": 124}, {"referenceID": 13, "context": "To learn the model parameters (W, b,Ww), we minimize our objective function over the data using AdaGrad (Duchi et al., 2011) with mini-batches.", "startOffset": 104, "endOffset": 124}, {"referenceID": 24, "context": "This gave us an objective that bears some similarity to the skip-gram objective with negative sampling in word2vec (Mikolov et al., 2013a).", "startOffset": 115, "endOffset": 138}, {"referenceID": 20, "context": "We train on word pairs from PPDB and evaluate on the SimLex-999 dataset (Hill et al., 2014b), achieving the best results reported to date.", "startOffset": 72, "endOffset": 92}, {"referenceID": 13, "context": "We trained for 20 epochs for each set of hyperparameters using AdaGrad (Duchi et al., 2011).", "startOffset": 71, "endOffset": 91}, {"referenceID": 24, "context": "For all experiments, we initialized our word vectors with skip-gram vectors trained using word2vec (Mikolov et al., 2013a).", "startOffset": 99, "endOffset": 122}, {"referenceID": 20, "context": "58 Hill et al. (2014b) 200 0.", "startOffset": 3, "endOffset": 23}, {"referenceID": 20, "context": "58 Hill et al. (2014b) 200 0.446 Hill et al. (2014a) - 0.", "startOffset": 3, "endOffset": 53}, {"referenceID": 16, "context": "Hyperparameters were tuned using the wordsim-353 (WS353) dataset (Finkelstein et al., 2001), specifically its similarity (WS-S) and relatedness (WSR) partitions (Agirre et al.", "startOffset": 65, "endOffset": 91}, {"referenceID": 0, "context": ", 2001), specifically its similarity (WS-S) and relatedness (WSR) partitions (Agirre et al., 2009).", "startOffset": 77, "endOffset": 98}, {"referenceID": 20, "context": "After tuning, we evaluated the best hyperparameters on the SimLex-999 (SL999) dataset (Hill et al., 2014b).", "startOffset": 86, "endOffset": 106}, {"referenceID": 32, "context": "the one-tailed method of (Steiger, 1980).", "startOffset": 25, "endOffset": 40}, {"referenceID": 20, "context": "We also show results for strong skip-gram baselines and the best results from the literature, including the state-of-the-art results from Hill et al. (2014a) as well as the interannotator agreement from Hill et al.", "startOffset": 138, "endOffset": 158}, {"referenceID": 20, "context": "We also show results for strong skip-gram baselines and the best results from the literature, including the state-of-the-art results from Hill et al. (2014a) as well as the interannotator agreement from Hill et al. (2014b).11", "startOffset": 138, "endOffset": 223}, {"referenceID": 21, "context": "We used the simple CNN from Kim (2014) and the binary sentence-level sentiment analysis task from Socher et al.", "startOffset": 28, "endOffset": 39}, {"referenceID": 21, "context": "We used the simple CNN from Kim (2014) and the binary sentence-level sentiment analysis task from Socher et al. (2013). We used the standard data splits, removing examples with a neutral rating.", "startOffset": 28, "endOffset": 119}, {"referenceID": 21, "context": "While Kim (2014) used m-gram filters of several lengths, we only used unigram filters.", "startOffset": 6, "endOffset": 17}, {"referenceID": 13, "context": "1 using AdaGrad (Duchi et al., 2011).", "startOffset": 16, "endOffset": 36}, {"referenceID": 32, "context": "For all experiments, we again used cosine similarity as our similarity metric and evaluated the statistical significance using the method of (Steiger, 1980).", "startOffset": 141, "endOffset": 156}, {"referenceID": 26, "context": "Unlike explicit word vectors, where point-wise multiplication acts as a conjunction of features and performs well on composition tasks (Mitchell and Lapata, 2008), using addition with skip-gram vectors (Mikolov et al.", "startOffset": 135, "endOffset": 162}, {"referenceID": 25, "context": "Unlike explicit word vectors, where point-wise multiplication acts as a conjunction of features and performs well on composition tasks (Mitchell and Lapata, 2008), using addition with skip-gram vectors (Mikolov et al., 2013b) gives better performance than multiplication.", "startOffset": 202, "endOffset": 225}, {"referenceID": 26, "context": "To evaluate our ability to paraphrase bigrams, we consider the original bigram similarity task from Mitchell and Lapata (2010) as well as our newlyannotated version of it: ML-Paraphrase.", "startOffset": 100, "endOffset": 127}, {"referenceID": 26, "context": "The bigram similarity task from Mitchell and Lapata (2010) contains three types of bigrams: adjective-noun (JN), noun-noun (NN), and verb-noun (VN).", "startOffset": 32, "endOffset": 59}, {"referenceID": 22, "context": "ger (Manning et al., 2014) to tag the tokens in each phrase.", "startOffset": 4, "endOffset": 26}, {"referenceID": 26, "context": "Model Mitchell and Lapata (2010) Bigrams ML-Paraphrase word vectors n comp.", "startOffset": 6, "endOffset": 33}, {"referenceID": 25, "context": "Table 5: Results on the test section of the bigram similarity task of Mitchell and Lapata (2010) and our newly annotated version (ML-Paraphrase).", "startOffset": 70, "endOffset": 97}, {"referenceID": 19, "context": "05) over the skip-gram model, \u2020 statistically significant over the {PARAGRAM, +} model, and \u2021 statistically significant over Hashimoto et al. (2014).", "startOffset": 125, "endOffset": 149}, {"referenceID": 25, "context": "That is, the JN and NN results from Mitchell and Lapata (2010) use their multiplicative model and the VN results use their dilation model.", "startOffset": 36, "endOffset": 63}, {"referenceID": 19, "context": "From Hashimoto et al. (2014) we used their PAS-CLBLM Addl and PAS-CLBLM Addnl models.", "startOffset": 5, "endOffset": 29}, {"referenceID": 26, "context": "We report results on the test portion of the original Mitchell and Lapata (2010) dataset (ML) as well as the entirety of our newly-annotated dataset (MLParaphrase).", "startOffset": 54, "endOffset": 81}, {"referenceID": 19, "context": "The results obtained here differ from those reported in Hashimoto et al. (2014) as we scored their vectors with a newer Python implementation of Spearman \u03c1 that handles ties (Hashimoto, P.", "startOffset": 56, "endOffset": 80}, {"referenceID": 18, "context": "model based on filtered phrase pairs in PPDB, we can actually distinguish between quality paraphrases and poor paraphrases in PPDB better than the original heuristic scoring scheme from Ganitkevitch et al. (2013).", "startOffset": 186, "endOffset": 213}, {"referenceID": 10, "context": "We also train a support vector regression model (epsilon-SVR) (Chang and Lin, 2011) on the 33 features that are included for each phrase pair in PPDB.", "startOffset": 62, "endOffset": 83}, {"referenceID": 20, "context": "611, which is easily beaten by automatic methods (Hill et al., 2014b).", "startOffset": 49, "endOffset": 69}, {"referenceID": 26, "context": "Model Mitchell and Lapata (2010) Bigrams ML-Paraphrase word vectors n comp.", "startOffset": 6, "endOffset": 33}], "year": 2015, "abstractText": "The Paraphrase Database (PPDB; Ganitkevitch et al., 2013) is an extensive semantic resource, consisting of a list of phrase pairs with (heuristic) confidence estimates. However, it is still unclear how it can best be used, due to the heuristic nature of the confidences and its necessarily incomplete coverage. We propose models to leverage the phrase pairs from the PPDB to build parametric paraphrase models that score paraphrase pairs more accurately than the PPDB\u2019s internal scores while simultaneously improving its coverage. They allow for learning phrase embeddings as well as improved word embeddings. Moreover, we introduce two new, manually annotated datasets to evaluate short-phrase paraphrasing models. Using our paraphrase model trained using PPDB, we achieve state-of-the-art results on standard word and bigram similarity tasks and beat strong baselines on our new short phrase paraphrase tasks.1,2", "creator": "LaTeX with hyperref package"}}}