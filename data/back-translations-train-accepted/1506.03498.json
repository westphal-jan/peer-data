{"id": "1506.03498", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jun-2015", "title": "Matrix Completion from Fewer Entries: Spectral Detectability and Rank Estimation", "abstract": "The completion of low rank matrices from few entries is a task with many practical applications. We consider here two aspects of this problem: detectability, i.e. the ability to estimate the rank $r$ reliably from the fewest possible random entries, and performance in achieving small reconstruction error. We propose a spectral algorithm for these two tasks called MaCBetH (for Matrix Completion with the Bethe Hessian). The rank is estimated as the number of negative eigenvalues of the Bethe Hessian matrix, and the corresponding eigenvectors are used as initial condition for the minimization of the discrepancy between the estimated matrix and the revealed entries. We analyze the performance in a random matrix setting using results from the statistical mechanics of the Hopfield neural network, and show in particular that MaCBetH efficiently detects the rank $r$ of a large $n\\times m$ matrix from $C(r)r\\sqrt{nm}$ entries, where $C(r)$ is a constant close to $1$. We also evaluate the corresponding root-mean-square error empirically and show that MaCBetH compares favorably to other existing approaches.", "histories": [["v1", "Wed, 10 Jun 2015 22:46:02 GMT  (170kb,D)", "https://arxiv.org/abs/1506.03498v1", null], ["v2", "Tue, 30 Jun 2015 17:15:13 GMT  (432kb,D)", "http://arxiv.org/abs/1506.03498v2", null], ["v3", "Thu, 28 Jan 2016 10:16:56 GMT  (432kb,D)", "http://arxiv.org/abs/1506.03498v3", "NIPS Conference 2015"]], "reviews": [], "SUBJECTS": "cond-mat.dis-nn cs.LG stat.ML", "authors": ["alaa saade", "florent krzakala", "lenka zdeborov\u00e1"], "accepted": true, "id": "1506.03498"}, "pdf": {"name": "1506.03498.pdf", "metadata": {"source": "CRF", "title": "Matrix Completion from Fewer Entries: Spectral Detectability and Rank Estimation", "authors": ["A. Saade", "F. Krzakala", "L. Zdeborov\u00e1"], "emails": [], "sections": [{"heading": null, "text": "We look at two aspects of the problem here: the ability to appreciate the ability. We look at two aspects of the ability to recognize the ability to recognize. We have two different assumptions, which are the ability, the ability, the ability to recognize and the ability, the ability, the ability to recognize, to recognize and understand, to recognize. [We have the ability, the way, the way to analyze, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way, the way,"}, {"heading": "II. PROBLEM DEFINITION AND RELATION TO OTHER WORKS", "text": "LetMtrue be a rank-r matrix search thatMtrue = XY \u2020, (1) where X-Rn \u00b7 r and Y-Rm \u00b7 r are two (unknown) high matrices. We observe only a small fraction of the elements of Mtrue, chosen uniformly according to the random principle. We call E the subset of the observed entries, andM the (sparse) matrix based on E, the non-elements of which are the revealed entries of Mtrue. The aim is to give the order r matrixMtrue = XY \u2020 M. An important parameter controlling the difficulty of the problem is = | E | / \u221a nm supporting the proposed matrix, this is the average number of revealed entries per row or column. In our numerical examples and theoretical justifications we will create the low rank matrix Mtrue = XY \u2020 by using large matrices X and Y with iid causal elements, we call this random matrix."}, {"heading": "III. ALGORITHM AND MOTIVATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A. The MacBetH algorithm", "text": "A standard approach to the completion problem (see e.g. [3]) is the minimization of the natural functions (\u03b2 \u03b2), Y (ij), E [Mij \u2212 (XY \u2020) ij] 2 (2) via X-Rn \u00b7 r and Y-Rm \u00b7 r. This function is not convex and the global optimization is difficult. Therefore, one resorts to a local optimization technique with a careful selection of the initial conditions X0, Y0. (3) 3 We refer to the graph, which is thus defined as G., we consider a weighted two-part, undirected diagram with Adjacency Matrix A (n + m) \u00b7 (n + m) A = (0 M MT 0).3 We now define the Bethe Hessian Matrix H (\u03b2), R (n + m)."}, {"heading": "B. Motivation from a Hopfield model", "text": "In view of the observed matrix M from the previous section, we shall consider the following graphic modelP ({s}, {t}) = 1 Z exp \u03b2 \u2211 (i, j) - 1 E Mijsitj, (6) where the {si} 1 \u2264 i \u2264 1 and {tj} 1 \u2264 1 \u2264 1 \u2264 1 \u2264 1 \u2264 1 \u2264 1 \u2264 1 \u2264 0 = 0 = 0 = 0 = 0 = 0 = 1 parameter controlling the intensity of interactions. This model is a (generalized) Hebbian Hopfield Model [10] on a split, sparse diagram. To examine it, we can use the standard approximation Bethe, which is generally assumed to be exactly for such problems on large random graphs [11, 12]. In this approximation, the means E (si), E (tj) and moments E (sitj) of each variable are approximated by the parameters bi, cj and ij which minimize the so-called energy performance."}, {"heading": "IV. ANALYSIS OF PERFORMANCE IN DETECTION", "text": "We will now show how the performance of MaCBetH can be analyzed and the spectral properties of the matrix can be characterized using both tools from statistical mechanics and rigorous arguments."}, {"heading": "A. Analysis of the phase transition", "text": "Let us begin by examining the phase transition, through which our spectral method will determine the correct order of precedence. Let us let xp = (x l) 1 \u2264 l \u2264 r (\u03b2) 1 \u2264 l \u2264 r = random vectors with the same empirical distribution as the rows of X and Y. Using the statistical mechanics correspondence between the negative eigenvalues of the Bethe Hessian and the appearance of the phase transitions in the model (6), we can calculate the values \u03b2R and \u03b2SG, where instabilities occur in the direction of respectively the retrieval states and the trace Glassy states, arise. We have repeated the calculations of the [13-16] phase transitions in the model, using the cavity method, which interests the reader in the technical details of statistical mechanics to the neural networks."}, {"heading": "B. Computation of the spectral density", "text": "In this section we show how the spectral density of the Bethe Hessian can be calculated analytically in relation to the spatial conditions using tree-like graphs such as those generated uniformly by the selection according to the random principle. (1) The spectral density is thus defined as follows: (2) It can be shown [21] that the spectral density (in which potential delta peaks were removed) that the spectral density (in which potential delta peaks are removed) is given by the way. (1) The spectral density (in which potential delta peaks were removed) is given: (2) = lim n, m \u00b2 s 1\u03c0 (n + m) n + m. (1) In the range of cosmic density i (16), where there are complex variables living on the vertices of the graph G given by: (2 + 1 + 1)."}, {"heading": "V. NUMERICAL TESTS", "text": "The aforementioned beginnings in the reconstructed matrix are able to reconstruct the aforementioned beginnings. [26] The aforementioned beginnings in the most reactionary phase of ascent to the most reactionary phase of ascension to the most reactionary phase of ascension to the most reactionary phase of ascension to the second phase of ascension to the second phase of ascension to the third phase of ascension to the third phase of ascension to the fourth phase of ascension to the fourth phase of ascension."}, {"heading": "VI. CONCLUSION", "text": "In this paper, we have introduced MaCBetH, a matrix completion algorithm that is efficient for two distinct complementary tasks: (i) it has the ability to reliably estimate a finite rank r from less random entries than other existing approaches, and (ii) it exhibits fewer root-middle-square reconstruction errors than its competitors. The algorithm is based on the Bethe matrix and takes advantage of recent advances in building efficient spectral methods for clustering sparse networks [5, 8, 9] as well as the OptSpace approach [3] for matrix completion. Demos in Julia and matlab are available for download [26]. The method presented here offers a number of possible future directions, including replacing the minimization of the cost function with a message-forwarding algorithm, using different models of neural networks, or a more theoretical direction that includes the calculation of theoretical transitions to optimum information [9]."}, {"heading": "Acknowledgment", "text": "The research leading to these results was funded by the European Research Council under the 7th Framework Programme of the European Union. [4] 2001 Networks of the European Union (FP / 2007-2013 / ERC Grant Agreement 307087-SPARCS). [1] E. J. Cand\u00e8s and B. Recht, \"Exact matrix complexation via convex optimization,\" Foundations of Computational Mathematics, vol. 9, no. 6, pp. 717-772, 2009. [2] E. J. Cand\u00e8s and T. Tao, \"The power of convex relaxation: Near-optimal matrix completion,\" Foundations of Computational Mathematics, IEEE Transactions on, vol. 56, pp. 2053-2080, 2010. R. H. Keshavan, A. Montanari, and S. Oh. Matrix completion from a few entries,. Information Theory, IEEE Transactions on, vol."}], "references": [{"title": "Exact matrix completion via convex optimization", "author": ["E.J. Cand\u00e8s", "B. Recht"], "venue": "Foundations of Computational mathematics, vol. 9, no. 6, pp. 717\u2013772, 2009.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2009}, {"title": "The power of convex relaxation: Near-optimal matrix completion", "author": ["E.J. Cand\u00e8s", "T. Tao"], "venue": "Information Theory, IEEE Transactions on, vol. 56, no. 5, pp. 2053\u20132080, 2010.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2010}, {"title": "Matrix completion from a few entries", "author": ["R.H. Keshavan", "A. Montanari", "S. Oh"], "venue": "Information Theory, IEEE Transactions on, vol. 56, no. 6, pp. 2980\u20132998, 2010.", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2010}, {"title": "Quantum state tomography via compressed sensing", "author": ["D. Gross", "Y.-K. Liu", "S.T. Flammia", "S. Becker", "J. Eisert"], "venue": "Physical review letters, vol. 105, no. 15, p. 150401, 2010.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2010}, {"title": "Spectral clustering of graphs with the bethe hessian", "author": ["A. Saade", "F. Krzakala", "L. Zdeborov\u00e1"], "venue": "Advances in Neural Information Processing Systems, 2014, pp. 406\u2013414.", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2014}, {"title": "Spectral detection in the censored block model", "author": ["A. Saade", "F. Krzakala", "M. Lelarge", "L. Zdeborov\u00e1"], "venue": "IEEE International Symposium on Information Theory (ISIT2015), to appear, 2015.", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["J.-F. Cai", "E.J. Cand\u00e8s", "Z. Shen"], "venue": "SIAM Journal on Optimization, vol. 20, no. 4, pp. 1956\u20131982, 2010.", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1956}, {"title": "Spectral redemption in clustering sparse networks", "author": ["F. Krzakala", "C. Moore", "E. Mossel", "J. Neeman", "A. Sly", "L. Zdeborov\u00e1", "P. Zhang"], "venue": "Proc. Natl. Acad. Sci., vol. 110, no. 52, pp. 20 935\u201320 940, 2013.", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Non-backtracking spectrum of random graphs: community detection and non-regular ramanujan graphs", "author": ["C. Bordenave", "M. Lelarge", "L. Massouli\u00e9"], "venue": "2015, arXiv:1501.06087.", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural networks and physical systems with emergent collective computational abilities", "author": ["J.J. Hopfield"], "venue": "Proc. Nat. Acad. Sci., vol. 79, no. 8, pp. 2554\u20132558, 1982.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1982}, {"title": "Bethe free energy, kikuchi approximations, and belief propagation algorithms", "author": ["J.S. Yedidia", "W.T. Freeman", "Y. Weiss"], "venue": "Advances in neural information processing systems, vol. 13, 2001.", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2001}, {"title": "Information, Physics, and Computation", "author": ["M. Mezard", "A. Montanari"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Spin-glass models of neural networks", "author": ["D.J. Amit", "H. Gutfreund", "H. Sompolinsky"], "venue": "Physical Review A, vol. 32, no. 2, p. 1007, 1985.", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1985}, {"title": "Finite connectivity attractor neural networks", "author": ["B. Wemmenhove", "A. Coolen"], "venue": "Journal of Physics A: Mathematical and General, vol. 36, no. 37, p. 9617, 2003.", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2003}, {"title": "The little\u2013hopfield model on a sparse random graph", "author": ["I.P. Castillo", "N. Skantzos"], "venue": "Journal of Physics A: Mathematical and General, vol. 37, no. 39, p. 9087, 2004.", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2004}, {"title": "Nonbacktracking operator for the ising model and its applications in systems with multiple states", "author": ["P. Zhang"], "venue": "Physical Review E, vol. 91, no. 4, p. 042120, 2015.", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Validity estimates for loopy belief propagation on binary real-world networks.", "author": ["J.M. Mooij", "H.J. Kappen"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2004}, {"title": "The bethe approximation for solving the inverse ising problem: a comparison with other inference methods", "author": ["F. Ricci-Tersenghi"], "venue": "J. Stat. Mech.: Th. and Exp., p. P08015, 2012.", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Statistical physics of hard optimization problems", "author": ["L. Zdeborov\u00e1"], "venue": "acta physica slovaca, vol. 59, no. 3, pp. 169\u2013303, 2009.", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2009}, {"title": "Phase transitions and sample complexity in bayes-optimal matrix factorization", "author": ["Y. Kabashima", "F. Krzakala", "M. M\u00e9zard", "A. Sakata", "L. Zdeborov\u00e1"], "venue": "2014, arXiv:1402.1298.", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2014}, {"title": "Cavity approach to the spectral density of sparse symmetric random matrices", "author": ["T. Rogers", "I.P. Castillo", "R. K\u00fchn", "K. Takeda"], "venue": "Phys. Rev. E, vol. 78, no. 3, p. 031116, 2008.", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2008}, {"title": "Resolvent of large random graphs", "author": ["C. Bordenave", "M. Lelarge"], "venue": "Random Structures and Algorithms, vol. 37, no. 3, pp. 332\u2013352, 2010.", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2010}, {"title": "Julia: A fresh approach to numerical computing", "author": ["J. Bezanson", "A. Edelman", "S. Karpinski", "V.B. Shah"], "venue": "2014, arXiv:1411.1607.", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2014}, {"title": "The nlopt nonlinear-optimization package", "author": ["S.G. Johnson"], "venue": "2014.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "minfunc: unconstrained differentiable multivariate optimization in matlab", "author": ["M. Schmidt"], "venue": "http://www.cs.ubc.ca/ ~schmidtm/Software/minFunc.html , 2005.", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2005}, {"title": "On the limited memory bfgs method for large scale optimization", "author": ["D.C. Liu", "J. Nocedal"], "venue": "Mathematical programming, vol. 45, no. 1-3, pp. 503\u2013528, 1989.", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1989}, {"title": "Low-rank matrix completion with noisy observations: a quantitative comparison", "author": ["R.H. Keshavan", "A. Montanari", "S. Oh"], "venue": "47th Annual Allerton Conference on Communication, Control, and Computing, 2009, pp. 1216\u20131222.", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 0, "context": "[1\u20133], motivated by many applications such as collaborative filtering [1], quantum tomography [4] in physics, or the analysis of a covariance matrix [1].", "startOffset": 0, "endOffset": 5}, {"referenceID": 1, "context": "[1\u20133], motivated by many applications such as collaborative filtering [1], quantum tomography [4] in physics, or the analysis of a covariance matrix [1].", "startOffset": 0, "endOffset": 5}, {"referenceID": 2, "context": "[1\u20133], motivated by many applications such as collaborative filtering [1], quantum tomography [4] in physics, or the analysis of a covariance matrix [1].", "startOffset": 0, "endOffset": 5}, {"referenceID": 0, "context": "[1\u20133], motivated by many applications such as collaborative filtering [1], quantum tomography [4] in physics, or the analysis of a covariance matrix [1].", "startOffset": 70, "endOffset": 73}, {"referenceID": 3, "context": "[1\u20133], motivated by many applications such as collaborative filtering [1], quantum tomography [4] in physics, or the analysis of a covariance matrix [1].", "startOffset": 94, "endOffset": 97}, {"referenceID": 0, "context": "[1\u20133], motivated by many applications such as collaborative filtering [1], quantum tomography [4] in physics, or the analysis of a covariance matrix [1].", "startOffset": 149, "endOffset": 152}, {"referenceID": 0, "context": "The most widely considered question in this setting is how many entries need to be revealed such that the matrix can be completed exactly in a computationally efficient way [1, 3].", "startOffset": 173, "endOffset": 179}, {"referenceID": 2, "context": "The most widely considered question in this setting is how many entries need to be revealed such that the matrix can be completed exactly in a computationally efficient way [1, 3].", "startOffset": 173, "endOffset": 179}, {"referenceID": 4, "context": "The rank in our algorithm is estimated as the number of negative eigenvalues of an associated Bethe Hessian matrix [5, 6], and the corresponding eigenvectors are used as an initial condition for the local optimization of a cost function commonly considered in matrix completion (see e.", "startOffset": 115, "endOffset": 121}, {"referenceID": 5, "context": "The rank in our algorithm is estimated as the number of negative eigenvalues of an associated Bethe Hessian matrix [5, 6], and the corresponding eigenvectors are used as an initial condition for the local optimization of a cost function commonly considered in matrix completion (see e.", "startOffset": 115, "endOffset": 121}, {"referenceID": 2, "context": "[3]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "The corresponding RMSE is evaluated empirically, and in the regime close to C(r)r \u221a nm, it compares very favorably to existing approaches, in particular to OptSpace [3].", "startOffset": 165, "endOffset": 168}, {"referenceID": 0, "context": "The matrix completion problem was popularized in [1] who proposed nuclear norm minimization as a convex relaxation of the problem.", "startOffset": 49, "endOffset": 52}, {"referenceID": 6, "context": "A low complexity procedure to solve the problem was later proposed by [7] and is based on singular value decomposition (SVD).", "startOffset": 70, "endOffset": 73}, {"referenceID": 2, "context": "A considerable step towards theoretical understanding of matrix completion from few entries was made in [3] who proved that with the use of trimming the performance of SVD-based matrix completion can be improved and a RMSE proportional to \u221a nr/|E| can be achieved.", "startOffset": 104, "endOffset": 107}, {"referenceID": 2, "context": "The algorithm of [3] is referred to as OptSpace, and empirically it achieves state-of-the-art RMSE in the regime of very few revealed entries.", "startOffset": 17, "endOffset": 20}, {"referenceID": 2, "context": "OptSpace proceeds in three steps [3].", "startOffset": 33, "endOffset": 36}, {"referenceID": 4, "context": "Our method leverages on recent progress made in the task of detecting communities in the stochastic block model [5, 8] with spectral methods.", "startOffset": 112, "endOffset": 118}, {"referenceID": 7, "context": "Our method leverages on recent progress made in the task of detecting communities in the stochastic block model [5, 8] with spectral methods.", "startOffset": 112, "endOffset": 118}, {"referenceID": 2, "context": "Both in community detection and matrix completion, traditional spectral methods fail in the very sparse regime due to the existence of spurious large eigenvalues (or singular values) corresponding to localized eigenvectors [3, 8].", "startOffset": 223, "endOffset": 229}, {"referenceID": 7, "context": "Both in community detection and matrix completion, traditional spectral methods fail in the very sparse regime due to the existence of spurious large eigenvalues (or singular values) corresponding to localized eigenvectors [3, 8].", "startOffset": 223, "endOffset": 229}, {"referenceID": 4, "context": "The authors of [5, 8, 9] showed that using the non-backtracking matrix or the closely related Bethe Hessian as a basis for the spectral method in community detection provides reliable rank estimation and better inference performance.", "startOffset": 15, "endOffset": 24}, {"referenceID": 7, "context": "The authors of [5, 8, 9] showed that using the non-backtracking matrix or the closely related Bethe Hessian as a basis for the spectral method in community detection provides reliable rank estimation and better inference performance.", "startOffset": 15, "endOffset": 24}, {"referenceID": 8, "context": "The authors of [5, 8, 9] showed that using the non-backtracking matrix or the closely related Bethe Hessian as a basis for the spectral method in community detection provides reliable rank estimation and better inference performance.", "startOffset": 15, "endOffset": 24}, {"referenceID": 2, "context": "[3]) is to minimize the cost function", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "In step 2 we could also use the non-backtracking matrix weighted by tanh\u03b2Mij , it was shown in [5] that the spectrum of the Bethe Hessian and the non-backtracking matrix are closely related.", "startOffset": 95, "endOffset": 98}, {"referenceID": 9, "context": "This model is a (generalized) Hebbian Hopfield model [10] on a bipartite sparse graph.", "startOffset": 53, "endOffset": 57}, {"referenceID": 10, "context": "To study it, we can use the standard Bethe approximation which is widely believed to be exact for such problems on large random graphs [11, 12].", "startOffset": 135, "endOffset": 143}, {"referenceID": 11, "context": "To study it, we can use the standard Bethe approximation which is widely believed to be exact for such problems on large random graphs [11, 12].", "startOffset": 135, "endOffset": 143}, {"referenceID": 11, "context": "[12\u201316] and references therein) and the phenomenology, that we shall review briefly here, is well known.", "startOffset": 0, "endOffset": 7}, {"referenceID": 12, "context": "[12\u201316] and references therein) and the phenomenology, that we shall review briefly here, is well known.", "startOffset": 0, "endOffset": 7}, {"referenceID": 13, "context": "[12\u201316] and references therein) and the phenomenology, that we shall review briefly here, is well known.", "startOffset": 0, "endOffset": 7}, {"referenceID": 14, "context": "[12\u201316] and references therein) and the phenomenology, that we shall review briefly here, is well known.", "startOffset": 0, "endOffset": 7}, {"referenceID": 15, "context": "[12\u201316] and references therein) and the phenomenology, that we shall review briefly here, is well known.", "startOffset": 0, "endOffset": 7}, {"referenceID": 4, "context": "It would be tempting to continue the Bethe approach and to derive the belief propagation equations, but we shall here instead consider a simpler spectral relaxation of the problem, following the same strategy as used in [5, 6] for graph clustering.", "startOffset": 220, "endOffset": 226}, {"referenceID": 5, "context": "It would be tempting to continue the Bethe approach and to derive the belief propagation equations, but we shall here instead consider a simpler spectral relaxation of the problem, following the same strategy as used in [5, 6] for graph clustering.", "startOffset": 220, "endOffset": 226}, {"referenceID": 16, "context": "First, we use the fact that the paramagnetic state (8) is always a stationary point of the Bethe free energy, for any value of \u03b2 [17, 18].", "startOffset": 129, "endOffset": 137}, {"referenceID": 17, "context": "First, we use the fact that the paramagnetic state (8) is always a stationary point of the Bethe free energy, for any value of \u03b2 [17, 18].", "startOffset": 129, "endOffset": 137}, {"referenceID": 4, "context": "At this point, the elements of the Hessian involving one derivative with respect to \u03beij vanish, while the block involving two such derivatives is a diagonal positive definite matrix [5, 17].", "startOffset": 182, "endOffset": 189}, {"referenceID": 16, "context": "At this point, the elements of the Hessian involving one derivative with respect to \u03beij vanish, while the block involving two such derivatives is a diagonal positive definite matrix [5, 17].", "startOffset": 182, "endOffset": 189}, {"referenceID": 4, "context": "The remaining part is the matrix called Bethe Hessian in [5],", "startOffset": 57, "endOffset": 60}, {"referenceID": 15, "context": "Note that a similar approach was used in [16] to detect the retrieval states of a Hopfield model using the weighted non-backtracking matrix [8], which linearizes the belief propagation equations rather than the Bethe free energy, resulting in a larger, non-symmetric matrix.", "startOffset": 41, "endOffset": 45}, {"referenceID": 7, "context": "Note that a similar approach was used in [16] to detect the retrieval states of a Hopfield model using the weighted non-backtracking matrix [8], which linearizes the belief propagation equations rather than the Bethe free energy, resulting in a larger, non-symmetric matrix.", "startOffset": 140, "endOffset": 143}, {"referenceID": 12, "context": "We have repeated the computations of [13\u201316] in the case of model (6), using the cavity method [12].", "startOffset": 37, "endOffset": 44}, {"referenceID": 13, "context": "We have repeated the computations of [13\u201316] in the case of model (6), using the cavity method [12].", "startOffset": 37, "endOffset": 44}, {"referenceID": 14, "context": "We have repeated the computations of [13\u201316] in the case of model (6), using the cavity method [12].", "startOffset": 37, "endOffset": 44}, {"referenceID": 15, "context": "We have repeated the computations of [13\u201316] in the case of model (6), using the cavity method [12].", "startOffset": 37, "endOffset": 44}, {"referenceID": 11, "context": "We have repeated the computations of [13\u201316] in the case of model (6), using the cavity method [12].", "startOffset": 95, "endOffset": 99}, {"referenceID": 13, "context": "We refer the reader interested in the technical details of the statistical mechanics approach to neural networks to [14\u201316].", "startOffset": 116, "endOffset": 123}, {"referenceID": 14, "context": "We refer the reader interested in the technical details of the statistical mechanics approach to neural networks to [14\u201316].", "startOffset": 116, "endOffset": 123}, {"referenceID": 15, "context": "We refer the reader interested in the technical details of the statistical mechanics approach to neural networks to [14\u201316].", "startOffset": 116, "endOffset": 123}, {"referenceID": 11, "context": "[12, 19]), the stability of the paramagnetic state (8) towards these two phases can be monitored in terms of the two following parameters:", "startOffset": 0, "endOffset": 8}, {"referenceID": 18, "context": "[12, 19]), the stability of the paramagnetic state (8) towards these two phases can be monitored in terms of the two following parameters:", "startOffset": 0, "endOffset": 8}, {"referenceID": 11, "context": "We thus computed c numerically using a population dynamics algorithm [12] and the results for C(r) = c/r are presented on Figure 2.", "startOffset": 69, "endOffset": 73}, {"referenceID": 19, "context": "It is interesting to note that this result was obtained as the detectability threshold in completion of rank r = O(n) matrices from O(n) entries in the Bayes optimal setting in [20].", "startOffset": 177, "endOffset": 181}, {"referenceID": 19, "context": "Notice, however, that exact completion in the setting of [20] is only possible for > r(m+ n)/ \u221a nm: clearly detection and exact completion are different phenomena.", "startOffset": 57, "endOffset": 61}, {"referenceID": 20, "context": "Using again the cavity method, It can be shown [21] that the spectral density (in which potential delta peaks have been removed) is given by", "startOffset": 47, "endOffset": 51}, {"referenceID": 21, "context": "Quite remarkably, it has been shown [22] that this approach leads to an asymptotically exact (and rigorous) description of the spectral density on Erd\u0151s-R\u00e9nyi random graphs, which are locally tree-like in the limit where n,m\u2192\u221e.", "startOffset": 36, "endOffset": 40}, {"referenceID": 4, "context": "The proof follows [5] and begins by noticing that \u2206i\u2192j = cosh(\u03b2Aij) is a fixed point of the recursion (18) for \u03bb = 0.", "startOffset": 18, "endOffset": 21}, {"referenceID": 7, "context": "The linear operator thus defined is a weighted version of the non-backtracking matrix of [8].", "startOffset": 89, "endOffset": 92}, {"referenceID": 4, "context": "In particular, for \u03b2 < \u03b2SG, \u03c1 < 1, so that a straightforward application [5] of the implicit function theorem allows to show that there exists a neighborhood U of 0 such that for any \u03bb \u2208 U , there exists a real, linearly stable fixed point of (18), yielding a spectral density equal to 0.", "startOffset": 73, "endOffset": 76}, {"referenceID": 22, "context": "The algorithm was implemented in Julia [23], using the NLopt optimization package [24] for the minimization of the discrepancy (2).", "startOffset": 39, "endOffset": 43}, {"referenceID": 23, "context": "The algorithm was implemented in Julia [23], using the NLopt optimization package [24] for the minimization of the discrepancy (2).", "startOffset": 82, "endOffset": 86}, {"referenceID": 24, "context": "A matlab demo using the implementation of the limited-memory BFGS algorithm of [25] is also available.", "startOffset": 79, "endOffset": 83}, {"referenceID": 2, "context": "We compare the final RMSE achieved on the reconstructed matrix XY \u2020 with 4 other initializations of the optimization, including the largest singular vectors of the trimmed matrix M [3].", "startOffset": 181, "endOffset": 184}, {"referenceID": 2, "context": "Along the same lines, OptSpace [3] uses a different", "startOffset": 31, "endOffset": 34}, {"referenceID": 25, "context": "All methods optimize the cost function (2) using a limited-memory BFGS algorithm [27] part of NLopt [24], starting from different initial conditions.", "startOffset": 81, "endOffset": 85}, {"referenceID": 23, "context": "All methods optimize the cost function (2) using a limited-memory BFGS algorithm [27] part of NLopt [24], starting from different initial conditions.", "startOffset": 100, "endOffset": 104}, {"referenceID": 2, "context": "The initial conditions compared are MaCBetH with oracle rank (MaCBetH OR) or inferred rank (MaCBetH IR), SVD of the observed matrixM after trimming, with oracle rank (Tr-SVD OR), or inferred rank (Tr-SVD IR, note that this is equivalent to OptSpace [3] in this regime), and random initial conditions with oracle rank (Random OR).", "startOffset": 249, "endOffset": 252}, {"referenceID": 26, "context": "For the Tr-SVD IR method, we inferred the rank from the SVD by looking for an index for which the ratio between two consecutive eigenvalues is minimized, as suggested in [28].", "startOffset": 170, "endOffset": 174}, {"referenceID": 4, "context": "The algorithm is built around the Bethe Hessian matrix and leverages both on recent progresses in the construction of efficient spectral methods for clustering of sparse networks [5, 8, 9], and on the OptSpace approach [3] for matrix completion.", "startOffset": 179, "endOffset": 188}, {"referenceID": 7, "context": "The algorithm is built around the Bethe Hessian matrix and leverages both on recent progresses in the construction of efficient spectral methods for clustering of sparse networks [5, 8, 9], and on the OptSpace approach [3] for matrix completion.", "startOffset": 179, "endOffset": 188}, {"referenceID": 8, "context": "The algorithm is built around the Bethe Hessian matrix and leverages both on recent progresses in the construction of efficient spectral methods for clustering of sparse networks [5, 8, 9], and on the OptSpace approach [3] for matrix completion.", "startOffset": 179, "endOffset": 188}, {"referenceID": 2, "context": "The algorithm is built around the Bethe Hessian matrix and leverages both on recent progresses in the construction of efficient spectral methods for clustering of sparse networks [5, 8, 9], and on the OptSpace approach [3] for matrix completion.", "startOffset": 219, "endOffset": 222}, {"referenceID": 0, "context": "[1] E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] R.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] J.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] F.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] C.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] B.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[27] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[28] R.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "A. Saade, F. Krzakala and L. Zdeborov\u00e1 1 Laboratoire de Physique Statistique, UMR 8550 CNRS, Department of Physics, \u00c9cole Normale Sup\u00e9rieure and PSL Research University, Rue Lhomond, 75005 Paris, France 2 Sorbonne Universit\u00e9s, UPMC Univ Paris 06, UMR 8550, LPS, F-75005, Paris, France 3 ESPCI and CNRS UMR 7083 Gulliver, 10 rue Vauquelin,Paris 75005 4 Institut de Physique Th\u00e9orique, CEA Saclay and URA 2306, CNRS, 91191 Gif-sur-Yvette, France (Dated: January 29, 2016)", "creator": "LaTeX with hyperref package"}}}