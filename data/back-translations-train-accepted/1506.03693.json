{"id": "1506.03693", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jun-2015", "title": "Optimization Monte Carlo: Efficient and Embarrassingly Parallel Likelihood-Free Inference", "abstract": "We describe an embarrassingly parallel, anytime Monte Carlo method for likelihood-free models. The algorithm starts with the view that the stochasticity of the pseudo-samples generated by the simulator can be controlled externally by a vector of random numbers u, in such a way that the outcome, knowing u, is deterministic. For each instantiation of u we run an optimization procedure to minimize the distance between summary statistics of the simulator and the data. After reweighing these samples using the prior and the Jacobian (accounting for the change of volume in transforming from the space of summary statistics to the space of parameters) we show that this weighted ensemble represents a Monte Carlo estimate of the posterior distribution. The procedure can be run embarrassingly parallel (each node handling one sample) and anytime (by allocating resources to the worst performing sample). The procedure is validated on six experiments.", "histories": [["v1", "Thu, 11 Jun 2015 14:45:30 GMT  (1656kb,D)", "https://arxiv.org/abs/1506.03693v1", "NIPS 2015 submission"], ["v2", "Wed, 2 Dec 2015 18:58:09 GMT  (1646kb,D)", "http://arxiv.org/abs/1506.03693v2", "NIPS 2015 camera ready"]], "COMMENTS": "NIPS 2015 submission", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["edward meeds", "max welling"], "accepted": true, "id": "1506.03693"}, "pdf": {"name": "1506.03693.pdf", "metadata": {"source": "CRF", "title": "Optimization Monte Carlo: Efficient and Embarrassingly Parallel Likelihood-Free Inference", "authors": ["Edward Meeds", "Max Welling"], "emails": ["tmeeds@gmail.com", "welling.max@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is so that most of them are able to survive themselves by surviving themselves, and that they are able to survive themselves by surviving themselves. In fact, it is so that they are able to survive themselves. In fact, it is so that they are able to survive themselves. In fact, it is so that they are able to survive themselves. In fact, it is so that they are able to survive themselves and to survive themselves. In fact, it is so that they are able to survive themselves. In fact, it is so that they are able to survive themselves and survive themselves."}, {"heading": "2 ABC Sampling Algorithms", "text": "The primary interest in ABC is the back of the simulation parameters. Rather, we can use the simulator as a generator of pseudo-samples in the same space as y. By treating x as an auxiliary variable, we can proceed with the Bayesian treatment: p (\u03b8 | y) = p (\u03b8) p (y | \u03b8) p (y | x) p (x | x) p (x | x) p (x | x) p (x | x) p (x | p) dx (1) Of particular importance is the choice of kernel qualities that measure the discrepancy between observations y and pseudo-data x. Popular choices for nuclei are the Gaussian nucleus and the uniform tube / ball. The bandwidth parameter (which can be a vector that plays a major role in the relative importance of the respective observations)."}, {"heading": "3 A Parallel and Efficient ABC Sampling Algorithm", "text": "Inherent in our assumptions about the simulator is that there are internal calls to a random number generator that produces the stochasticity of the pseudo-random samples. We assume for the moment that this can be represented by a vector of uniform random numbers u, which, if known, would make the simulator deterministic. This assumption was previously used in ABC, initially in \"coupled ABC\" [16] and also in an application of Hamilton's dynamics to ABC [15]. We do not make further assumptions regarding u or p (u), although some problems may be known about their dimensions and distribution. In these cases, it may be worthwhile using Sobol or other low discrepancy sequences to further improve the accuracy of any Monte Carlo estimates."}, {"heading": "3.1 The case D\u03b8 = Dy", "text": "We will first examine the case when the number of parameters equals the number of sum statistics i. To understand the derivative, it helps to look at Figure 1a, which illustrates the derivative for the one-dimensional case. \u2212 \u2212 \u2212 \u2212 In the following, we will use the following abbreviation: fi (\u03b8) stands for f (\u03b8, ui). The general idea is that we want to write the approach to the rear plane as a mixture of small uniform spheres (or delta pitches in the boundary): p (\u03b8 | y). \u2212 f (ui, \u03b8). \u2212 f (ui) The general idea is that we will derive the rear plane as a mixture of small uniform spheres (5) with some weights that we will shortly derive. Then, if we are small enough, we can replace any average of a sufficiently smooth function h."}, {"heading": "3.2 The case D\u03b8 < Dy", "text": "This is the overdetermined case, and here the situation as shown in Figure 1b is typical: The multiplicity tracked by f (\u03b8, ui) as we vary it forms a low-dimensional surface in the Dy-dimensional envelope space. This multiplicity may or may not overlap with the sphere centered on observation y (or ellipsoid, for the general case instead). Suppose the multiplicity intersects the epsilon sphere, but not y. Since we trust our observation to the distance, we can simply select the closest point between i and y on the multiplicity, which is by,. Suppose that the multiplicity intersects between i and i (y \u2212 fi (\u03b8 o i) J o \u2020 i = (J oT i i) \u2212 1JoTi (13), where Jo \u2020 i is the pseudo-inverse point. We can now define our ellipse around this point by shifting the center of the sphere from fi."}, {"heading": "3.3 The case D\u03b8 > Dy", "text": "This is the underdetermined case in which it is typical that whole multiplicities (e.g. hyperplanes) can be a solution to | | y \u2212 fi (\u03b8 \u043a i) | | = 0. In this case we cannot approach the buttocks with a mixture of point masses, and therefore the procedure is not applicable. However, the case D\u03b8 > Dy is less interesting than the others mentioned above, as we expect to have more summary statistics than parameters for most problems."}, {"heading": "4 Experiments", "text": "The aim of these experiments is to 1) demonstrate the accuracy of OMC and 2) demonstrate the relative efficiency of OMC in relation to two sequential MC algorithms, SMC (aka Population MC [3]) and adaptive weighted SMC [5]. To demonstrate the accuracy, we show histograms of weighted samples along with the true posterior (if known) and, for three experiments, the exact OMC-weighted samples (if the exact jacobic and optimal \u03b8 is known). To demonstrate efficiency, we calculate the mean simulations per sample (SS) - the number of simulations needed to reach a threshold - and the effective sample size (ESS), which is defined as 1 / wTw. Additionally, we can measure ESS / n, the fracture of effective samples in the baseline population. ESS is a good method to determine whether the posterior is dominated by a few particles and how many particles / less discrepancies there are for OMC."}, {"heading": "4.1 Normal with Unknown Mean and Known Variance", "text": "The simplest example is the conclusion of the mean \u03b8 of a univariate normal distribution with known variance \u03c32. The previous distribution \u03c0 (\u03b8) is normal with mean prediction \u03b80 and variance k\u03c32, where k > 0 is a factor that relates the dispersions of \u03b8 and the data yn. The simulator can generate data according to the normal distribution or deterministically if the random effects Rum are known: \u03c0 (xm | \u03b8) = N (xm | \u03b8, \u03c32) = \u21d2 xm = \u03b8 + Rum (14), where Rum = \u03c3 2 is erf \u2212 1 (2um \u2212 1) (using the reverse CDF). A sufficient statistic for this problem is the average s (x) = 1M \u00b2 xm. Therefore, we have f (\u03b8, u) = \u03b8 + R (u), where R (u) = \u2211 Rum / M (the average of random effects) is. In our experiment, we set M = 2 and the input = 0, we can calculate the exact value of this problem for Jacobian (and we can)."}, {"heading": "4.2 Normal Mixture", "text": "An exemplary ABC problem is the conclusion from the mean of a mixture of two normal [19, 3, 5]: p (x | \u03b8) = \u03c1N (\u03b8, \u03c321) + (1 \u2212 \u03c1) N (\u03b8, \u03c322), with \u03c0 (\u03b8) = U (\u03b8a, \u03b8b), with hyperparameters equal to 0. In this problem M = 1 we drop the subscript m. The true neighbour is simply p (zipal | y = 0). The actual neighbour causes N (zipal, \u03c321) + (1 \u2212 \u03c1) N (zipal, \u03c322). In this problem there are two random numbers u1 and u2, one for the selection of the mixing component and the other for the random innovation; furthermore, the statistic is the identity, i.e. (x) x = 10, 10}. In this problem there are two random numbers: u1 and u2, one for the selection of the mixing component and the other for the random innovation."}, {"heading": "4.3 Exponential with Unknown Rate", "text": "In this example, the objective is to derive the rate \u03b8 of an exponential distribution with a gamma prior p (\u03b8) = gamma (\u03b8 | \u03b1, \u03b2), based on M draws from Exp (\u03b8): p (xm | \u03b8) = Exp (xm | \u03b8) = \u03b8 exp (\u2212 \u03b8xm) = \u21d2 xm = \u2212 1\u03b8 ln (1 \u2212 um) = 1 \u03b8 rum (17), where rum = \u2212 ln (1 \u2212 um) (the inverted CDF of the exponent) is. A sufficient statistic for this problem is the average s (x) = \u2211 m xm / M. Again, we have exact expressions for the jacobic and successoi, where f (\u03b8, ui) = R (ui) / \u03b8, Ji = \u2212 R (ui) / depen2 and successoi = R (ui) / s (y) is used."}, {"heading": "4.4 Linked Mean and Variance of Normal", "text": "In this example, we link the mean and variance of the data generation function as follows: p (xm | \u03b8) = N (xm | \u03b8, \u03b82) = \u21d2 xm = \u03b8 + \u03b8 \u221a 2 erf \u2212 1 (2um \u2212 1) = \u03b8rum (18), where rum = 1 + \u221a 2 erf \u2212 1 (2um \u2212 1). We set a positive constraint to \u03b8: p (\u03b8) = U (0, 10). We used 2 statistics, where the mean and variance of M are derived from the simulator: s1 (x) = 1M xm = \u21d2 f1 (\u03b8, u) = \u03b8R (u) \u0445 f1 (zipiert, u)."}, {"heading": "4.5 Lotka-Volterra", "text": "The simplest Lotka-Volterra model explains predator-prey populations over time, controlled by a series of stochastic differential equations: dx1 dt = \u03b81x1 \u2212 \u03b82x1x2 + r1 dx2 dt = \u2212 \u03b82x2 \u2212 \u03b83x1x2 + r2 (21), where x1 and x2 are the prey and predator populations, respectively. Gaussian noise r \u0445 N (0, 102) is therefore added at each full-time step. Lognormal priors are set above \u03b8. The simulator runs in T = 50 time steps with constant initial populations of 100 for both predator and predator. Therefore, there are P = 2T outputs (prey and predator populations linked), which we use as statistics. To perform a deterministic simulation, we plot ui \u00b2 (u), whereby the dimension of u is used for half of the random variables for r1 and the other half for bian-simulations."}, {"heading": "4.6 Bayesian Inference of the M/G/1 Queue Model", "text": "Bayesian conclusion of the M / G / 1 queuing model is a challenge and requires ABC algorithms [4, 8] or sophisticated MCMC-based procedures [18]. Although the output is easy to simulate, it can be jerky. In the M / G / 1 queuing model, a single server processes incoming customers, who are then served within a random time. m currently arrives wm \u0445 Exp (\u03b83) after customer m \u2212 1 and is served in sm \u0445 U (\u03b81, \u03b82) service time. both wm and sm are not observed; only the departure times xm are observed. Following [18] we write the simulation algorithm with respect to arrival times vm. To simplify the updates, we keep the departure times dm. Initially d0 = 0 and v0 = 0, followed by updates for m \u2265 1: vm \u2212 1 + wm xm = sm + 0. (max + 22 + dbian = most \u2212 dm functions are found)."}, {"heading": "5 Conclusion", "text": "We have presented Optimization Monte Carlo, a probability-free algorithm that, by controlling simulator randomness, transforms traditional ABC inference into a series of optimization procedures. By using OMC, scientists can focus their attention on finding a useful optimization procedure for their simulator, and then use OMC in parallel to independently generate samples. We have shown that OMC can also be very efficient, although this depends on the quality of the optimization procedure that is applied to each problem. In our experiments, the simulators were cheap to run and enabled Jacobin calculations using finite differences. We point out that for high-dimensional input spaces and expensive simulators, this may not be feasible, solutions include randomized gradient estimates [22] or automatic differentiation libraries (e.g. [14])."}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for the many useful comments that have improved this manuscript. MW thanks Facebook, Google and Yahoo for their support."}], "references": [{"title": "Large scale distributed Bayesian matrix factorization using stochastic gradient MCMC", "author": ["S. Ahn", "A. Korattikara", "N. Liu", "S. Rajan", "M. Welling"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Distributed stochastic gradient MCMC", "author": ["S. Ahn", "B. Shahbaba", "M. Welling"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Adaptive approximate Bayesian computation", "author": ["M.A. Beaumont", "Cornuet", "J.-M", "Marin", "C.P. Robert"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Non-linear regression models for approximate Bayesian computation", "author": ["M.G. Blum", "O. Fran\u00e7ois"], "venue": "Statistics and Computing,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Sequential Monte Carlo with adaptive weights for approximate Bayesian computation", "author": ["F.V. Bonassi", "M. West"], "venue": "Bayesian Analysis,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Sequential Monte Carlo samplers", "author": ["P. Del Moral", "A. Doucet", "A. Jasra"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Approximate Bayesian computation using indirect inference", "author": ["C.C. Drovandi", "A.N. Pettitt", "M.J. Faddy"], "venue": "Journal of the Royal Statistical Society: Series C (Applied Statistics),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Constructing summary statistics for approximate Bayesian computation: semi-automatic approximate Bayesian computation", "author": ["P. Fearnhead", "D. Prangle"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2012}, {"title": "The ABC of simulation estimation with auxiliary statistics. arXiv preprint arXiv:1501.01265v2", "author": ["Forneron", "J.-J", "S. Ng"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "A likelihood-free reverse sampler of the posterior distribution. arXiv preprint arXiv:1506.04017v1", "author": ["Forneron", "J.-J", "S. Ng"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Bayesian optimization for likelihood-free inference of simulator-based statistical models. Journal of Machine Learning Research, preprint arXiv:1501.03291", "author": ["M.U. Gutmann", "J. Corander"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Efficient global optimization of expensive black-box functions", "author": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global optimization,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "Efficient likelihood-free Bayesian computation for household epidemics", "author": ["P. Neal"], "venue": "Statistical Computing,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Asynchronous anytime Sequential Monte Carlo", "author": ["B. Paige", "F. Wood", "A. Doucet", "Y.W. Teh"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2014}, {"title": "On Bayesian inference for the M/G/1 queue with efficient MCMC sampling", "author": ["A.Y. Shestopaloff", "R.M. Neal"], "venue": "Technical Report, Dept. of Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Sequential Monte Carlo without likelihoods", "author": ["S. Sisson", "Y. Fan", "M.M. Tanaka"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2007}, {"title": "Sequential Monte Carlo without likelihoods: Errata", "author": ["S. Sisson", "Y. Fan", "M.M. Tanaka"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "Practical Bayesian optimization of machine learning algorithms", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Multivariate stochastic approximation using a simultaneous perturbation gradient approximation", "author": ["J.C. Spall"], "venue": "Automatic Control, IEEE Transactions on,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1992}], "referenceMentions": [{"referenceID": 1, "context": "There has been considerable progress in distributed MCMC algorithms aimed at large-scale data problems [2, 1].", "startOffset": 103, "endOffset": 109}, {"referenceID": 0, "context": "There has been considerable progress in distributed MCMC algorithms aimed at large-scale data problems [2, 1].", "startOffset": 103, "endOffset": 109}, {"referenceID": 13, "context": "Recently, a sequential Monte Carlo (SMC) algorithm called \u201cthe particle cascade\u201d was introduced that emits streams of samples asynchronously with minimal memory management and communication [17].", "startOffset": 190, "endOffset": 194}, {"referenceID": 10, "context": "Indeed, optimization as part of a likelihood-free inference procedure has recently been proposed [12]; using a probabilistic model of the mapping from parameters to differences between observations and simulator outputs, they apply \u201cBayesian Optimization\u201d (e.", "startOffset": 97, "endOffset": 101}, {"referenceID": 11, "context": "[13, 21]) to efficiently perform posterior inference.", "startOffset": 0, "endOffset": 8}, {"referenceID": 17, "context": "[13, 21]) to efficiently perform posterior inference.", "startOffset": 0, "endOffset": 8}, {"referenceID": 6, "context": "Connections between ABC and indirect inference have been made previously by [7] as a novel way of creating summary statistics.", "startOffset": 76, "endOffset": 79}, {"referenceID": 8, "context": "An indirect inference perspective led to an independently developed version of OMC called the \u201creverse sampler\u201d [9, 10].", "startOffset": 112, "endOffset": 119}, {"referenceID": 9, "context": "An indirect inference perspective led to an independently developed version of OMC called the \u201creverse sampler\u201d [9, 10].", "startOffset": 112, "endOffset": 119}, {"referenceID": 5, "context": "We focus our attention on population-based ABC samplers, which include rejection sampling, importance sampling (IS), sequential Monte Carlo (SMC) [6, 20] and population Monte Carlo [3].", "startOffset": 146, "endOffset": 153}, {"referenceID": 16, "context": "We focus our attention on population-based ABC samplers, which include rejection sampling, importance sampling (IS), sequential Monte Carlo (SMC) [6, 20] and population Monte Carlo [3].", "startOffset": 146, "endOffset": 153}, {"referenceID": 2, "context": "We focus our attention on population-based ABC samplers, which include rejection sampling, importance sampling (IS), sequential Monte Carlo (SMC) [6, 20] and population Monte Carlo [3].", "startOffset": 181, "endOffset": 184}, {"referenceID": 12, "context": "This assumption has been used previously in ABC, first in \u201ccoupled ABC\u201d [16] and also in an application of Hamiltonian dynamics to ABC [15].", "startOffset": 72, "endOffset": 76}, {"referenceID": 12, "context": "We will first derive a dual representation for the ABC likelihood function p (y|\u03b8) (see also [16]),", "startOffset": 93, "endOffset": 97}, {"referenceID": 2, "context": "The goal of these experiments is to demonstrate 1) the correctness of OMC and 2) the relative efficiency of OMC in relation to two sequential MC algorithms, SMC (aka population MC [3]) and adaptive weighted SMC [5].", "startOffset": 180, "endOffset": 183}, {"referenceID": 4, "context": "The goal of these experiments is to demonstrate 1) the correctness of OMC and 2) the relative efficiency of OMC in relation to two sequential MC algorithms, SMC (aka population MC [3]) and adaptive weighted SMC [5].", "startOffset": 211, "endOffset": 214}, {"referenceID": 15, "context": "2 Normal Mixture A standard illustrative ABC problem is the inference of the mean \u03b8 of a mixture of two normals [19, 3, 5]: p(x|\u03b8) = \u03c1N (\u03b8, \u03c3 1)+ (1\u2212 \u03c1)N (\u03b8, \u03c3 2), with \u03c0(\u03b8) = U(\u03b8a, \u03b8b) where hyperparameters are \u03c1 = 1/2, \u03c3 1 = 1, \u03c3 2 2 = 1/100, \u03b8a = \u221210, \u03b8b = 10, and a single observation scalar y = 0.", "startOffset": 112, "endOffset": 122}, {"referenceID": 2, "context": "2 Normal Mixture A standard illustrative ABC problem is the inference of the mean \u03b8 of a mixture of two normals [19, 3, 5]: p(x|\u03b8) = \u03c1N (\u03b8, \u03c3 1)+ (1\u2212 \u03c1)N (\u03b8, \u03c3 2), with \u03c0(\u03b8) = U(\u03b8a, \u03b8b) where hyperparameters are \u03c1 = 1/2, \u03c3 1 = 1, \u03c3 2 2 = 1/100, \u03b8a = \u221210, \u03b8b = 10, and a single observation scalar y = 0.", "startOffset": 112, "endOffset": 122}, {"referenceID": 4, "context": "2 Normal Mixture A standard illustrative ABC problem is the inference of the mean \u03b8 of a mixture of two normals [19, 3, 5]: p(x|\u03b8) = \u03c1N (\u03b8, \u03c3 1)+ (1\u2212 \u03c1)N (\u03b8, \u03c3 2), with \u03c0(\u03b8) = U(\u03b8a, \u03b8b) where hyperparameters are \u03c1 = 1/2, \u03c3 1 = 1, \u03c3 2 2 = 1/100, \u03b8a = \u221210, \u03b8b = 10, and a single observation scalar y = 0.", "startOffset": 112, "endOffset": 122}, {"referenceID": 15, "context": "This problem is notable for causing performance issues in ABC-MCMC [19] and its difficulty in targeting the tails of the posterior [3]; this is not the case for OMC.", "startOffset": 67, "endOffset": 71}, {"referenceID": 2, "context": "This problem is notable for causing performance issues in ABC-MCMC [19] and its difficulty in targeting the tails of the posterior [3]; this is not the case for OMC.", "startOffset": 131, "endOffset": 134}, {"referenceID": 3, "context": "6 Bayesian Inference of the M/G/1 Queue Model Bayesian inference of the M/G/1 queuing model is challenging, requiring ABC algorithms [4, 8] or sophisticated MCMC-based procedures [18].", "startOffset": 133, "endOffset": 139}, {"referenceID": 7, "context": "6 Bayesian Inference of the M/G/1 Queue Model Bayesian inference of the M/G/1 queuing model is challenging, requiring ABC algorithms [4, 8] or sophisticated MCMC-based procedures [18].", "startOffset": 133, "endOffset": 139}, {"referenceID": 14, "context": "6 Bayesian Inference of the M/G/1 Queue Model Bayesian inference of the M/G/1 queuing model is challenging, requiring ABC algorithms [4, 8] or sophisticated MCMC-based procedures [18].", "startOffset": 179, "endOffset": 183}, {"referenceID": 14, "context": "Following [18], we write the simulation algorithm in terms of arrival times vm.", "startOffset": 10, "endOffset": 14}, {"referenceID": 18, "context": "We note that for high-dimensional input spaces and expensive simulators, this may be infeasible, solutions include randomized gradient estimates [22] or automatic differentiation (AD) libraries (e.", "startOffset": 145, "endOffset": 149}], "year": 2015, "abstractText": "We describe an embarrassingly parallel, anytime Monte Carlo method for likelihood-free models. The algorithm starts with the view that the stochasticity of the pseudo-samples generated by the simulator can be controlled externally by a vector of random numbers u, in such a way that the outcome, knowing u, is deterministic. For each instantiation of u we run an optimization procedure to minimize the distance between summary statistics of the simulator and the data. After reweighing these samples using the prior and the Jacobian (accounting for the change of volume in transforming from the space of summary statistics to the space of parameters) we show that this weighted ensemble represents a Monte Carlo estimate of the posterior distribution. The procedure can be run embarrassingly parallel (each node handling one sample) and anytime (by allocating resources to the worst performing sample). The procedure is validated on six experiments.", "creator": "LaTeX with hyperref package"}}}