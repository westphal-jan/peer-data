{"id": "1506.04132", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2015", "title": "Stochastic Expectation Propagation", "abstract": "Expectation propagation (EP) is a deterministic approximation algorithm that is often used to perform approximate Bayesian parameter learning. EP approximates the full intractable posterior distribution through a set of local-approximations that are iteratively refned for each datapoint. EP can offer analytic and computational advantages over other approximations, such as Variational Inference (VI), and is the method of choice for a number of models. The local nature of EP appears to make it an ideal candidate for performing Bayesian learning on large-scale datasets. However, EP has a crucial limitation in this context: the number approximating factors need to increase with the number of data-points, N, which entails a large computational burden. This paper presents an extension to EP, called stochastic expectation propagation (SEP), that maintains a global posterior approximation (like VI) but updates it in a local way (like EP). Experiments on a number of synthetic and real-world data indicate that SEP performs almost as well as full EP, but reduces the memory consumption by a factor of N.", "histories": [["v1", "Fri, 12 Jun 2015 19:51:06 GMT  (780kb)", "http://arxiv.org/abs/1506.04132v1", null], ["v2", "Wed, 18 Nov 2015 10:52:17 GMT  (1879kb,D)", "http://arxiv.org/abs/1506.04132v2", "Published at NIPS 2015. 18 pages including supplementary"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["yingzhen li", "jos\u00e9 miguel hern\u00e1ndez-lobato", "richard e turner"], "accepted": true, "id": "1506.04132"}, "pdf": {"name": "1506.04132.pdf", "metadata": {"source": "CRF", "title": "Stochastic Expectation Propagation", "authors": ["Yingzhen Li", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"], "emails": ["yl494@cam.ac.uk", "jmh@seas.harvard.edu", "ret26@cam.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 150 6.04 132v 1 [stat.ML] 1 2Ju n"}, {"heading": "1 Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2 Expectation Propagation and Assumed Density Filtering", "text": "We begin with a brief review of the EP and ADF algorithms on which our new method is based."}, {"heading": "3 Stochastic Expectation Propagation", "text": "In this section, we present a new algorithm inspired by EP, called stochastic expectation q q (SEP), which combines the advantages of local approximation (including tractability of updates, distributability and parallelism) with global approximation (reduced memory requirements) q. However, the algorithm can be interpreted as a version of EP in which the approximation factors are bound, or alternatively as a corrected version of ADF that prevents overfitting. The key idea is that in convergence, the approximation factors in the EP can be interpreted as parameterization of a global factor f."}, {"heading": "4 Algorithmic extensions to SEP and theoretical results", "text": "From a practical point of view, SEP was motivated by the limitations inherent in EP and ADF. In this section, we expand SEP in four orthogonal directions and refer to SVI through these extensions. Many of the algorithms described in this section are summarized in Figure 2 and detailed in the supplementary material."}, {"heading": "4.1 Parallel SEP: Relating the EP fixed points to SEP", "text": "The SEP algorithm outlined above approaches a probability at a point in time that can be computationally slow. However, it is easy to parallelise the SEP updates by following the same recipe by which EP is parallelized. First, let's consider a minibatch of M data points (for a complete parallel (batch) update of SEP algorithm 1 EPAlgorithm 2 ADFAlgorithm 3 SEPuse M = N). Unlike EP, they are all identical. Subsequently, the calculation of the M intermediate factors fm (\u03b8) projection is updated by EDFAlgorithm 2 ADFAlgorithm 3 SEPuse M / q \u2212 1 (N). In the EP, these intermediate factors are updated to the new approximation of probability and the approximation to q properties."}, {"heading": "4.2 Stochastic Power EP: Relationships to variational methods", "text": "Can these relationships be made more formal? If the moment-projection step in the EP is replaced by a natural step for adjusting parameters, then the resulting algorithm corresponds to the Variational Message Passing (VMP) algorithm [23] (and see supplementary material). Furthermore, VMP has the same fixed points as the conclusion of variation [13] (since minimizing local variational KL divergences equals minimizing global variation).These results are transferred to the new algorithms with minor modifications. Specifically, VMP can be transformed into SVMP by using the same (global) form of approximation used by SEP. In the supplementary material, we show that this algorithm is an instance of standard SVI and that it therefore has the same fixed points in anticipation as VI. Generally, one of the members of the PEP family of algorithms focused on limiting the weight of EP cases (the EP-EP supplement is the EP case)."}, {"heading": "4.3 Distributed SEP: controlling granularity of the approximation", "text": "The EP uses a fine-grained approximation, which contains a single factor for each probability. On the other hand, the SEP uses a coarse-grained approximation, which contains a global signal factor, to approximate the average effect of all probability concepts. It might be feared that the approximation of the SEP is too strict if the dataset contains records with very different probability contributions (for example, the classification of handwritten digits into odd and even classes).In such cases, it might be more sensible to partition the data set into K sections {Dk = {xn} Nk = Nk \u2212 1} Kk = 1 with N = \u2211 Kk = 1 Nk and to use an approximation factor for each partition. If normal EP updates are used in this situation, we arrive at the distributed EP algorithm [5] [6], but such updates are a challenge, since several probability concepts are included in each update, which require additional approximations (e.g. MC)."}, {"heading": "4.4 SEP with latent variables", "text": "Many applications of EP involve latent variable models. Although this is not the main focus of the paper, we show that SEP is applicable in this case and prevents the memory imprint from being scaled to N. Let us consider a model that contains hidden variables associated with each observation p (xn, hn | \u03b8), which are i.i.d. drawn from a previous p0 (hn). The aim is to determine the actual posterior effect of each intractable term based on a product of approximate factors, p (hn | hn) p0 (hn) \u2248 fn (\u03b8) gn (hn) p (hn) p (hn) p (hn).Typically, EP would determine the effect of each intractable term based on a product of approximate factors, p (hn | hn) p0 (hn) \u2248 fn (\u03b8) gn (hn) gn (hn) p (hn) p (hn) p0 (hn) p (hn) phn) phn (hn) phn (hn) phn) as approximate (0) parameters, or (hn) as approximate (hn) factors."}, {"heading": "5 Experiments", "text": "The aim of the experiments was to evaluate SEP on a number of data sets (synthetic and real world, small and large) and on a number of models (probit regression, mixing of Gaussian and Bayesian neural networks)."}, {"heading": "5.1 Bayesian probit regression", "text": "In fact, it is the case that most of us are able to assert ourselves, and that they are able to assert themselves, \"he said in an interview of the\" Welt am Sonntag \"with regard to the\" Welt am Sonntag. \""}, {"heading": "5.2 Mixture of Gaussians for clustering", "text": "The small-scale experiments on probit regression indicate that SEP performs well for fully observed probability models. Although it is not the focus of the work, we tried to test the flexibility of the method by applying it to a latent variable model, in particular a mixture of Gaussian. A synthetic MoGs dataset with N = 200 data points was constructed containing J = 4 Gaussian. Means were sampled from a Gaussian distribution p (\u00b5j) = N (\u00b5; m, I), cluster identity variables were sampled from a uniform categorical distribution p (hn = j) = 1 / 4, and each mixture component was isotropic p (xn | hn) = N (\u00b5hn, 0.52I). EP, ADF, and SEP were performed to approximate the common posterior distribution p (hn = j) = 1 / 4, and each mixture component was isotropic = N (\u00b5x2p)."}, {"heading": "5.3 Probabilistic back-propagation", "text": "Specifically, we evaluate the methods for probabilistic-backpropagation (PBP) [4], a newer state-of-the-art method for scalable Bayesian learning in neural network models. Previous implementations of PBP perform multiple iterations of ADF over training data. The moment-matching operations required by ADF are themselves insoluble, and they are approximated by the initial spread of uncertainty on synaptic weights by the network in sequential fashion, and then by the calculation of the gradient of marginal probability by back propagation. Previous implementations of PBP are based on ADF to reduce the large storage costs that would be required by EP when the amount of available data is very large. We conducted several experiments to evaluate the accuracy of the various implementations of PBP based on ADF, SEP, and regression-based EP."}, {"heading": "6 Conclusions and future work", "text": "We have linked the new algorithm to a number of existing methods, including assumed density filtering, variational messaging, variational inference, stochastic variation inference, and averaged EP. Experiments with Bayesian logistic regression (both in the synthetic and real world) and the mix of castors showed that the new method had an accuracy that competed with EP. Experiments with the probable reverse propagation of large regression datasets in the real world showed once again that SEP is comparable to EP with a vastly reduced memory requirement. Future experimental work will focus on the development of data partitioning methods to use fine-grained approximations (DESP), which showed promising experimental performance as well as mini-batch updates. Theoretical work will examine the convergence properties of the new algorithms, for which we currently have limited results."}, {"heading": "A Further theoretical results", "text": "We have described the extensions of stochastic expectation propagation (SEP) in the main text (1). We provide further details in this section (1). Analysis of the EP and variable inference (VI) relations requires an introduction of the potency EP (PEP). However, as a preparation, let us consider the alpha divergence first presented in [25] D\u03b1 (MP). \u2212 The two cases of KL divergence also belong to the family of alpha divergence by definition: D1 (p). (1) The two cases of KL divergence belong to the family of alpha divergence by definition: D1 (p)."}, {"heading": "B Algorithmic design details", "text": "B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B. B."}, {"heading": "C Further experimental results", "text": "We also provide the details of memory consumption for experiments using probabilistic backpropagation (PBP) in Table 7 (a). We observe significant memory reductions by running SEP instead of EP, while still achieving similar accuracies. In particular, for Year, a typical large dataset in both the number of observations N and the dimensionality D, SEP achieves savings in double-digit gigabytes. In fact, we have performed the test for EP with a machine with more than 100 GB of RAM, which is the incredibly large memory requirement of full EP. Although it is not a main purpose, we continue to test the performance of SEP using sampling methods for calculating moments 3. We use the settings of probit regression, but change the probit unit to sigmoid function, making the moment projection analytically intractable. We partition the dataset into K = 20 subsets {Dk}, and we also include the SEP subset and the SEP factor in local factors."}], "references": [{"title": "Distributed stochastic gradient mcmc", "author": ["Sungjin Ahn", "Babak Shahbaba", "Max Welling"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Towards scaling up markov chain monte carlo: an adaptive subsampling approach", "author": ["R\u00e9mi Bardenet", "Arnaud Doucet", "Chris Holmes"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Stochastic variational inference", "author": ["Matthew D. Hoffman", "David M. Blei", "Chong Wang", "John William Paisley"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Probabilistic backpropagation for scalable learning of bayesian neural networks", "author": ["J.M. Hern\u00e1ndez-Lobato", "Ryan P. Adams"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2015}, {"title": "Expectation propagation as a way of life", "author": ["Andrew Gelman", "Aki Vehtari", "Pasi Jyl\u00e4nki", "Christian Robert", "Nicolas Chopin", "John P. Cunningham"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Distributed bayesian posterior sampling via moment sharing", "author": ["Minjie Xu", "Balaji Lakshminarayanan", "Yee Whye Teh", "Jun Zhu", "Bo Zhang"], "venue": "In NIPS,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Expectation propagation for approximate Bayesian inference", "author": ["T.P. Minka"], "venue": "Uncertainty in Artificial Intelligence, volume 17, pages 362\u2013369", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2001}, {"title": "Expectation consistent approximate inference", "author": ["Manfred Opper", "Ole Winther"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2005}, {"title": "Assessing approximate inference for binary gaussian process classification", "author": ["Malte Kuss", "Carl Edward Rasmussen"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2005}, {"title": "Expectation propagation for likelihood-free inference", "author": ["Simon Barthelm\u00e9", "Nicolas Chopin"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Gaussian probabilities and expectation propagation", "author": ["John P Cunningham", "Philipp Hennig", "Simon Lacoste-Julien"], "venue": "arXiv preprint arXiv:1111.6832,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Power EP", "author": ["T.P. Minka"], "venue": "Technical Report MSR-TR-2004-149, Microsoft Research, Cambridge", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2004}, {"title": "Variational message passing", "author": ["John M Winn", "Christopher M Bishop"], "venue": "In Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2005}, {"title": "An introduction to variational methods for graphical models", "author": ["Michael I Jordan", "Zoubin Ghahramani", "Tommi S Jaakkola", "Lawrence K Saul"], "venue": "Machine learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1999}, {"title": "Variational algorithms for approximate Bayesian inference", "author": ["Matthew James Beal"], "venue": "PhD thesis, University of London,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2003}, {"title": "Two problems with variational expectation maximisation for time-series models", "author": ["R.E. Turner", "M. Sahani"], "venue": "D. Barber, T. Cemgil, and S. Chiappa, editors, Bayesian Time series models, chapter 5, pages 109\u2013130. Cambridge University Press", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic amplitude and frequency demodulation", "author": ["Richard E. Turner", "Maneesh Sahani"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "TrueskillTM: A bayesian skill rating system", "author": ["Ralf Herbrich", "Tom Minka", "Thore Graepel"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "Stochastic models, estimation and control", "author": ["Peter S. Maybeck"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1982}, {"title": "Sparse-posterior gaussian processes for general likelihoods", "author": ["Yuan Qi", "Ahmed H Abdel-Gawad", "Thomas P Minka"], "venue": "In Uncertainty and Artificial Intelligence (UAI),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Methods of information geometry, volume 191", "author": ["Shun-ichi Amari", "Hiroshi Nagaoka"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "Expectation propagation in the large-data limit", "author": ["Guillaume Dehaene", "Simon Barthelm\u00e9"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Divergence measures and message passing", "author": ["Thomas Minka"], "venue": "Technical Report MSR-TR-2005-173, Microsoft Research,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo", "author": ["Matthew D Hoffman", "Andrew Gelman"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Differential-Geometrical Methods in Statistic", "author": ["Shun-ichi Amari"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1985}, {"title": "Information geometry of \u03b1-projection in mean field approximation", "author": ["Shun-ichi Amari", "Shiro Ikeda", "Hidetoshi Shimokawa"], "venue": "Advanced Mean Field Methods,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2001}], "referenceMentions": [{"referenceID": 0, "context": "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].", "startOffset": 34, "endOffset": 40}, {"referenceID": 1, "context": "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].", "startOffset": 34, "endOffset": 40}, {"referenceID": 2, "context": "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].", "startOffset": 115, "endOffset": 118}, {"referenceID": 3, "context": "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].", "startOffset": 149, "endOffset": 152}, {"referenceID": 4, "context": "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].", "startOffset": 221, "endOffset": 227}, {"referenceID": 5, "context": "Examples include sampling such as [1, 2], distributional approximations including stochastic variational inference [3] and assumed density filtering [4], and approaches that mix distributional and sampling approximations [5, 6].", "startOffset": 221, "endOffset": 227}, {"referenceID": 6, "context": "One family of approximation method has garnered less attention in this regard: Expectation propagation (EP) [7][8].", "startOffset": 108, "endOffset": 111}, {"referenceID": 7, "context": "One family of approximation method has garnered less attention in this regard: Expectation propagation (EP) [7][8].", "startOffset": 111, "endOffset": 114}, {"referenceID": 8, "context": "At first sight, it therefore appears well suited to large-data problems: the locality of computation make the algorithm simple to parallelise and distribute, and good practical performance on a range of small-data applications suggest that it will be accurate [9, 10, 11].", "startOffset": 260, "endOffset": 271}, {"referenceID": 9, "context": "At first sight, it therefore appears well suited to large-data problems: the locality of computation make the algorithm simple to parallelise and distribute, and good practical performance on a range of small-data applications suggest that it will be accurate [9, 10, 11].", "startOffset": 260, "endOffset": 271}, {"referenceID": 10, "context": "At first sight, it therefore appears well suited to large-data problems: the locality of computation make the algorithm simple to parallelise and distribute, and good practical performance on a range of small-data applications suggest that it will be accurate [9, 10, 11].", "startOffset": 260, "endOffset": 271}, {"referenceID": 11, "context": "The same pathology exists for the broader class of power-EP (PEP) algorithms [12] that includes variational message-passing [13].", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "The same pathology exists for the broader class of power-EP (PEP) algorithms [12] that includes variational message-passing [13].", "startOffset": 124, "endOffset": 128}, {"referenceID": 13, "context": "In contrast, variational inference (VI) methods [14, 15] utilise global approximations that are refined directly (rather than through local components) which prevents memory overheads from scaling with N .", "startOffset": 48, "endOffset": 56}, {"referenceID": 14, "context": "In contrast, variational inference (VI) methods [14, 15] utilise global approximations that are refined directly (rather than through local components) which prevents memory overheads from scaling with N .", "startOffset": 48, "endOffset": 56}, {"referenceID": 15, "context": "It is well known that variational free-energy approaches are biased and often severely so [16] and for particular models the variational free-energy objective is pathologically ill-suited [11, 17].", "startOffset": 90, "endOffset": 94}, {"referenceID": 10, "context": "It is well known that variational free-energy approaches are biased and often severely so [16] and for particular models the variational free-energy objective is pathologically ill-suited [11, 17].", "startOffset": 188, "endOffset": 196}, {"referenceID": 16, "context": "It is well known that variational free-energy approaches are biased and often severely so [16] and for particular models the variational free-energy objective is pathologically ill-suited [11, 17].", "startOffset": 188, "endOffset": 196}, {"referenceID": 17, "context": "TrueSkill [18]).", "startOffset": 10, "endOffset": 14}, {"referenceID": 18, "context": "A second approach is to use a simple variant of EP called assumed density filtering (ADF) which only requires a global approximation to be stored [19].", "startOffset": 146, "endOffset": 150}, {"referenceID": 6, "context": "ADF, however, provides poorly calibrated uncertainty estimates [7] which was one of the main motivating reasons for developing EP in the first place.", "startOffset": 63, "endOffset": 66}, {"referenceID": 19, "context": "low rank, [20]).", "startOffset": 10, "endOffset": 14}, {"referenceID": 4, "context": "Another idea uses EP to carve up the dataset [5, 6] using approximating factors for collections of data-points.", "startOffset": 45, "endOffset": 51}, {"referenceID": 5, "context": "Another idea uses EP to carve up the dataset [5, 6] using approximating factors for collections of data-points.", "startOffset": 45, "endOffset": 51}, {"referenceID": 4, "context": "(Indeed, the spirit of [5, 6] is to extend sampling methods to large-datasets, not EP itself.", "startOffset": 23, "endOffset": 29}, {"referenceID": 5, "context": "(Indeed, the spirit of [5, 6] is to extend sampling methods to large-datasets, not EP itself.", "startOffset": 23, "endOffset": 29}, {"referenceID": 2, "context": "Indeed, the generalisation of the algorithm to the PEP setting directly relates to SVI [3].", "startOffset": 87, "endOffset": 90}, {"referenceID": 20, "context": "If the approximating distribution is in the exponential family, as is often the case, then the KL minimisation reduces to a moment-matching step [21] that we denote fn(\u03b8) \u2190 proj[p\u0303n(\u03b8)]/q\u2212n(\u03b8).", "startOffset": 145, "endOffset": 149}, {"referenceID": 21, "context": "For M = N parallel SEP is equivalent to the so-called Averaged EP algorithm proposed in [22] as a theoretical tool to study the convergence properties of normal EP.", "startOffset": 88, "endOffset": 92}, {"referenceID": 21, "context": "Since SEP\u2019s approximating factor f(\u03b8) converges, in expectation, to the geometric average of the intermediate factors f\u0304(\u03b8) \u221d [ \u220fN n=1 fn(\u03b8)] 1 N , SEP converges in expectation to the same fixed points as AEP, and therefore under certain conditions [22], to the same fixed points as EP.", "startOffset": 249, "endOffset": 253}, {"referenceID": 2, "context": "The relationship between variational inference and stochastic variational inference [3] mirrors the relationship between EP and SEP.", "startOffset": 84, "endOffset": 87}, {"referenceID": 22, "context": "Can these relationships be made more formal? If the moment projection step in EP is replaced by a natural parameter matching step then the resulting algorithm is equivalent to the Variational Message Passing (VMP) algorithm [23] (and see supplementary material).", "startOffset": 224, "endOffset": 228}, {"referenceID": 12, "context": "Moreover, VMP has the same fixed points as variational inference [13] (since minimising the local variational KL divergences is equivalent to minimising the global variational KL).", "startOffset": 65, "endOffset": 69}, {"referenceID": 4, "context": "If normal EP updates are used in this situation we arrive at the Distributed EP algorithm [5][6], but such updates are challenging as multiple likelihood terms must be included during each update necessitating additional approximations (e.", "startOffset": 90, "endOffset": 93}, {"referenceID": 5, "context": "If normal EP updates are used in this situation we arrive at the Distributed EP algorithm [5][6], but such updates are challenging as multiple likelihood terms must be included during each update necessitating additional approximations (e.", "startOffset": 93, "endOffset": 96}, {"referenceID": 23, "context": "Performance was measured by computing an approximation of KL(p(\u03b8|D)||q(\u03b8)) where p(\u03b8|D) was replaced by a Gaussian that had the same mean and covariance as samples drawn from the posterior using the No-U-Turn sampler (NUTS) [24].", "startOffset": 224, "endOffset": 228}, {"referenceID": 3, "context": "Specifically we evaluate the methods for probabilistic-backpropagation (PBP) [4], a recent state-of-the-art method for scalable Bayesian learning in neural network models.", "startOffset": 77, "endOffset": 80}, {"referenceID": 3, "context": "We performed several experiments to assess the accuracy of different implementations of PBP based on ADF, SEP and EP on regression datasets following the same experimental protocol as in [4].", "startOffset": 187, "endOffset": 190}, {"referenceID": 3, "context": "We considered neural networks with 100 hidden units and followed the same experimental protocol as described by [4].", "startOffset": 112, "endOffset": 115}], "year": 2015, "abstractText": "Expectation propagation (EP) is a deterministic approximation algorithm that is often used to perform approximate Bayesian parameter learning. EP approximates the full intractable posterior distribution through a set of local-approximations that are iteratively refined for each datapoint. EP can offer analytic and computational advantages over other approximations, such as Variational Inference (VI), and is the method of choice for a number of models. The local nature of EP appears to make it an ideal candidate for performing Bayesian learning on large-scale datasets. However, EP has a crucial limitation in this context: the number approximating factors need to increase with the number of data-points, N , which entails a large computational burden. This paper presents an extension to EP, called stochastic expectation propagation (SEP), that maintains a global posterior approximation (like VI) but updates it in a local way (like EP). Experiments on a number of synthetic and real-world data indicate that SEP performs almost as well as full EP, but reduces the memory consumption by a factor of N .", "creator": "LaTeX with hyperref package"}}}