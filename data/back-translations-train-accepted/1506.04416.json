{"id": "1506.04416", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2015", "title": "Bayesian dark knowledge", "abstract": "We consider the problem of Bayesian parameter estimation for deep neural networks, which is important in problem settings where we may have little data, and/ or where we need accurate posterior predictive densities, e.g., for applications involving bandits or active learning. One simple approach to this is to use online Monte Carlo methods, such as SGLD (stochastic gradient Langevin dynamics). Unfortunately, such a method needs to store many copies of the parameters (which wastes memory), and needs to make predictions using many versions of the model (which wastes time).", "histories": [["v1", "Sun, 14 Jun 2015 16:22:16 GMT  (384kb,D)", "http://arxiv.org/abs/1506.04416v1", null], ["v2", "Tue, 7 Jul 2015 18:38:47 GMT  (383kb,D)", "http://arxiv.org/abs/1506.04416v2", null], ["v3", "Fri, 6 Nov 2015 23:51:30 GMT  (394kb,D)", "http://arxiv.org/abs/1506.04416v3", "final version submitted to NIPS 2015"]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["anoop korattikara balan", "vivek rathod", "kevin p murphy", "max welling"], "accepted": true, "id": "1506.04416"}, "pdf": {"name": "1506.04416.pdf", "metadata": {"source": "CRF", "title": "Bayesian Dark Knowledge", "authors": ["Anoop Korattikara", "Vivek Rathod", "Kevin Murphy"], "emails": ["kpmurphy}@google.com", "m.welling@uva.nl"], "sections": [{"heading": "1 Introduction", "text": "However, there is a principal method to address this problem, where we first calculate the posterior distribution using the model parameters, where D is the number of characteristics that the i'th input method has, and the i'th input method is the i'th output method. Then we calculate the posterior predictive distribution, p'th output, p'th output, p'th output."}, {"heading": "2 Methods", "text": "Our goal is to create a student neuronal network (SNN) in order to approximate the Bayesian prediction distribution of the teacher. \"\" For this network, which is a Monte Carlo ensemble of teachers-neuronal networks (TNN), our objective behavior (w | x) = KL (y | x, w) = \u2212 S (y | x, w) =. S (y | x, w) =..P. (y | x, DN) = \u2212 Ep. (y | x, DN) = \u2212 Ep. (y | x, DN). (y | x, DN) logS (y | x, DN) logS (y | x, w) + const = \u2212 S (y | x, w).S (c).S \".S\".S \".S.\" S. \"S\" S \"S.\" S \"S\" S \"S\" S \"S\" S \"S.\" S \"S\" S \"S\" S. \"S\" S \"S.\" S \"S.\" S \"S\" S \"S.\" S \"S\" S. \"S\" S \"S.\" S \"S.\" S. \".S\".S. \"S\" S. \"S\" S \"S\" S \"S\" S. \"S\" S. \"S\" S \"S.\" S. \"S\" S \"S.\" S \"S.\" S \"S.\" S \"S\" S \"S\" S. \"S\" S. \"S.\" S \"S\" S. \"S\" S \"S.\" S \"S\" S. \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S \"S\" S \"S.\" S \"S\" S. \"S.\" S \"S\" S. \"S\" S \"S\" S. \"S\" S \"S\" S \"S\" S. \"S\" S. \"S\" S \"S.\" S \"S\" S \"S.\" S. \"S\" S. \"S\" S \"S.\" S. \"S\" S. \"S\" S \"S\" S \"S.\" S \"S.\" S. \"S.\" S \"S.\" S \"S\" S"}, {"heading": "2.1 Classification", "text": "For classification problems, each teacher network \u03b8 models the observations using a standard Softmax model, p (y = k | x, \u03b8). We want to approximate this using a student network, which also has an algorithm 1: Distilled SGLD 1. Input: DN = {(xi, yi)} Ni = 1, minibatch size M, number of iterations T, curriculum for teachers, curriculum for students, teacher before stage 2 for t = 1: T do 3 / / / pull teacher (SGLD step) 4 example minibatch indices S [1, N] for the size M 5 example number of pupils N (0, throutI) 6 update event + 1: = advance + advance (advance) p (advance) + NM value (advance) + NM value (SGLD step) + Q. value (advance), Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q. Q."}, {"heading": "2.2 Regression", "text": "In regression, the observations are modeled as follows: p (yi | xi, \u03b8) = N (yi | f (xi | \u03b8), \u03bb \u2212 1n), where f (x \u2212 \u03b8) is the prediction of TNN and \u03bbn is the precision of noise. We will train a student network to determine the parameters of approximate distribution \u00b5 (x, w) and \u03b1 (x, w); note that this is twice the number of results of the teacher network, as we want to capture the (data-dependent) variance. 1 The SNN results \u03b1 (x, w) instead of directly predicting the variance: 2 (x | w) and \u03b1 (x, w) to avoid dealing with positivity limitations during training."}, {"heading": "3 Experimental results", "text": "In this section, we compare SGLD and distilled SGLD with other approximate inference methods, including plugin approximation with SGD, the EP approach of [HLA15], the VB approach of [BCKW15], and Hamiltonian Monte Carlo (HMC) [Nea11], which is considered the \"gold standard\" for MCMC for neural networks. We implemented SGD and SGLD with the Torch library (torch.ch), and for HMC we used Stan (mc-stan.org). We perform this comparison for various classification and regression problems, as summarized in Table 1.1. This is not necessary in the classification case, as the Softmax distribution already covers uncertainties. Ideally, we would apply all methods to all records to allow for proper comparison. Unfortunately, for various reasons, this was not possible, so the open source code for the second approach we could not evaluate the EMC's slow access to the third regression method, so that we could only use the third method for the WMC."}, {"heading": "3.1 Toy 2d classification problem", "text": "We start with a toy 2d binary classification problem to visually illustrate the performance of the various methods. We create a synthetic dataset in 2 dimensions with 2 classes, 10 points per class. We then fit a multi-layer perceptron (MLP) with a hidden layer of 10 ReLu units and 2 softmax outputs (designated 2-10-2) using SGD. The resulting predictions are shown in Figure 1 (a). We see the expected sigmoidal probability ramp orthogonal to the linear decision limit. Unfortunately, this method predicts a labeling of 0 or 1 with very high certainty, even for points that are far away from the training data (e.g. in the upper left and lower right corner). In Figure 1 (b) we show the result of the HMC using 20k samples. This is the \"true\" posterior predictive density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density (density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density density)."}, {"heading": "3.2 MNIST classification", "text": "Now we look at the MNIST number classification problem, which has N = 60k examples, 10 classes, and D = 784 characteristics. The only pre-processing we do is to divide the pixel values by 126 (as in [BCKW15]). We train only on 50K data points and use the remaining 10K for adjusting hyperparameters. This means that our results are not strictly comparable to a lot of published work that uses the entire data set for training, but the difference is likely to be small. Following [BCKW15] we use an MLP with 2 hidden layers with 400 hidden units per shift, ReLU activations, and Softmax outputs; we call this 784-400-10. This model has 500k parameters. We first adjust this model by SGD, using these hyperparameters: fixed learning rate of 4 \u2212 6, previous precision of 5 \u2212 6, precision of 6."}, {"heading": "3.3 Toy 1d regression", "text": "We start with a toy 1d regression problem to visually illustrate the performance of different methods. We use the same data and models as [HLA15]. Specifically, we use N = 20 points in2 We have to be somewhat careful with these conclusions, as they are largely based on a single study. (However, the distilled SGLD results on 400 units are the mean over 10 attempts; the standard error was only 0.01.) D = 1 dimensions sampled from the function y = x3 + n, where n \u00b2 N (0, 9). We adjust these data with an MLP with 10 hidden units and ReLU activations. For SGLD, we use S = 2000 samples. For distillation, the teacher uses the same architecture as the students. The results are shown in Figure 2. We see that SGLD is a better approximation to the \"true\" (HMC) posterior predictive density than the VB approximation and the SD-loss, but we see the SD-loss."}, {"heading": "3.4 Boston housing", "text": "Finally, we consider a larger regression problem, namely the Boston Housing Dataset, which was also used in [HLA15]. This has N = 506 data points (456 training, 50 tests), with D = 13 dimensions. Because this data set is so small, we repeated all experiments 20 times using different tensile / test splitters. Following [HLA15], we use an MLP with 1 layer of 50 hidden units and ReLU activations. First, we use SGD, with these hyperparameters4: minibatch size M = 1, noise precision \u03bbn = 1.25, previous precision \u03bb = 1, number of experiments 20, constant learning rate throut = 1e \u2212 6, number of iterations T = 170K. As shown in Table 5, we get an average log probability of \u2212 2.7639. Next, we adjust the model with SGLD. We use an initial learning rate of 0 = 1.WLA5, we get an Iteration \u2212 Iteration."}, {"heading": "4 Conclusions and future work", "text": "We have demonstrated a very simple method of \"bayan being\" in relation to neural networks (and other types of models) that seems to work better than the recently proposed alternatives based on EP [HLA15] and VB [BCKW15]. We have several things we would like to do in the future: (1) Show the utility of our model in an end-to-end task where predictive uncertainty is useful (as with context-dependent bandits or active learning); (2) Explore more complex SG-MCMC methods, such as distributed SGLD and SG-NHT. (3) Consider ways to reduce the variance of the algorithm by perhaps scanning a running minibatch of parameters uniformly from the rear area, which can be performed online by sampling reservoirs. (4) Explore smarter methods of data generation to train the student [5], ask if our method is superior to the prevalence in 14."}, {"heading": "Acknowledgements", "text": "We thank Jose \"Miguel Herna\" ndez-Lobato for his comments and for distributing the source code for the PBP algorithm, Jonathan Huang, George Papandreou and Sergio Guadaramma for their comments, and Nick Johnston for helping with the Torch library."}], "references": [{"title": "Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring", "author": ["S. Ahn", "A. Korattikara", "M. Welling"], "venue": "ICML", "citeRegEx": "AKW12", "shortCiteRegEx": null, "year": 2012}, {"title": "Distributed stochastic gradient MCMC", "author": ["Sungjin Ahn", "Babak Shahbaba", "Max Welling"], "venue": "ICML,", "citeRegEx": "ASW14", "shortCiteRegEx": null, "year": 2014}, {"title": "Weight uncertainty in neural networks", "author": ["C. Blundell", "J. Cornebise", "K. Kavukcuoglu", "D. Wierstra"], "venue": "ICML", "citeRegEx": "BCKW15", "shortCiteRegEx": null, "year": 2015}, {"title": "Model compression", "author": ["Cristian Bucila", "Rich Caruana", "Alexandru Niculescu-Mizil"], "venue": "KDD,", "citeRegEx": "BCNM06", "shortCiteRegEx": null, "year": 2006}, {"title": "Stochastic Gradient Hamiltonian Monte Carlo", "author": ["Tianqi Chen", "Emily B Fox", "Carlos Guestrin"], "venue": "ICML,", "citeRegEx": "CFG14", "shortCiteRegEx": null, "year": 2014}, {"title": "Bayesian sampling using stochastic gradient thermostats", "author": ["N Ding", "Y Fang", "R Babbush", "C Chen", "R Skeel", "H Neven"], "venue": "NIPS", "citeRegEx": "DFB14", "shortCiteRegEx": null, "year": 2014}, {"title": "Practical variational inference for neural networks", "author": ["Alex Graves"], "venue": "NIPS,", "citeRegEx": "Gra11", "shortCiteRegEx": null, "year": 2011}, {"title": "Probabilistic backpropagation for scalable learning of bayesian neural networks", "author": ["J. Hern\u00e1ndez-Lobato", "R. Adams"], "venue": "ICML", "citeRegEx": "HLA15", "shortCiteRegEx": null, "year": 2015}, {"title": "Distilling the knowledge in a neural network", "author": ["Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean"], "venue": "NIPS Deep Learning Workshop,", "citeRegEx": "HVD14", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic gradient VB and the variational auto-encoder", "author": ["Diederik P Kingma", "Max Welling"], "venue": "ICLR,", "citeRegEx": "KW14", "shortCiteRegEx": null, "year": 2014}, {"title": "In Handbook of Markov chain Monte Carlo", "author": ["Radford Neal. MCMC using hamiltonian dynamics"], "venue": "Chapman and Hall,", "citeRegEx": "Nea11", "shortCiteRegEx": null, "year": 2011}, {"title": "Stochastic gradient riemannian langevin dynamics on the probability simplex", "author": ["Sam Patterson", "Yee Whye Teh"], "venue": "NIPS,", "citeRegEx": "PT13", "shortCiteRegEx": null, "year": 2013}, {"title": "FitNets: Hints for thin deep nets", "author": ["Adriana Romero", "Nicolas Ballas", "Samira Ebrahimi Kahou", "Antoine Chassang", "Carlo Gatta", "Yoshua Bengio"], "venue": "Arxiv, 19", "citeRegEx": "RBK14", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "ICML", "citeRegEx": "RMW14", "shortCiteRegEx": null, "year": 2014}, {"title": "Compact approximations to bayesian predictive distributions", "author": ["Edward Snelson", "Zoubin Ghahramani"], "venue": "ICML,", "citeRegEx": "SG05", "shortCiteRegEx": null, "year": 2005}, {"title": "Intriguing properties of neural networks", "author": ["Christian Szegedy", "Wojciech Zaremba", "Ilya Sutskever", "Joan Bruna", "Dumitru Erhan", "Ian Goodfellow", "Rob Fergus"], "venue": "ICLR,", "citeRegEx": "SZS14", "shortCiteRegEx": null, "year": 2014}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["Max Welling", "Yee W Teh"], "venue": "ICML,", "citeRegEx": "WT11", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 7, "context": "We compare to two very recent approaches to Bayesian neural networks, namely an approach based on expectation propagation [HLA15] and an approach based on variational Bayes [BCKW15].", "startOffset": 122, "endOffset": 129}, {"referenceID": 2, "context": "We compare to two very recent approaches to Bayesian neural networks, namely an approach based on expectation propagation [HLA15] and an approach based on variational Bayes [BCKW15].", "startOffset": 173, "endOffset": 181}, {"referenceID": 7, "context": "Recently, [HLA15] proposed a method called \u201cprobabilistic backpropagation\u201d (PBP) based on an online version of expectation propagation (EP), (i.", "startOffset": 10, "endOffset": 17}, {"referenceID": 2, "context": "[BCKW15] proposed an approach called \u201cBayes by Backprop\u201d (BBB) based on variational Bayes (VB), extending earlier work of [Gra11, KW14, RMW14].", "startOffset": 0, "endOffset": 8}, {"referenceID": 16, "context": "However, recently a method called stochastic gradient Langevin dynamics (SGLD) [WT11] has been devised that can draw samples from the posterior in an online fashion, just as SGD updates a point estimate of the parameters online.", "startOffset": 79, "endOffset": 85}, {"referenceID": 4, "context": "Furthermore, various extensions of SGLD have been proposed, including stochastic gradient hybrid Monte Carlo (SGHMC) [CFG14], stochastic gradient Nos\u00e9-Hoover Thermostat (SGNHT) [DFB14] (which improves upon SGHMC), stochastic gradient Fisher scoring (SGFS) [AKW12] (which uses second order information), stochastic gradient Riemannian Langevin Dynamics (for inferring parameters in the probability simplex) [PT13], distributed SGLD [ASW14], etc.", "startOffset": 117, "endOffset": 124}, {"referenceID": 5, "context": "Furthermore, various extensions of SGLD have been proposed, including stochastic gradient hybrid Monte Carlo (SGHMC) [CFG14], stochastic gradient Nos\u00e9-Hoover Thermostat (SGNHT) [DFB14] (which improves upon SGHMC), stochastic gradient Fisher scoring (SGFS) [AKW12] (which uses second order information), stochastic gradient Riemannian Langevin Dynamics (for inferring parameters in the probability simplex) [PT13], distributed SGLD [ASW14], etc.", "startOffset": 177, "endOffset": 184}, {"referenceID": 0, "context": "Furthermore, various extensions of SGLD have been proposed, including stochastic gradient hybrid Monte Carlo (SGHMC) [CFG14], stochastic gradient Nos\u00e9-Hoover Thermostat (SGNHT) [DFB14] (which improves upon SGHMC), stochastic gradient Fisher scoring (SGFS) [AKW12] (which uses second order information), stochastic gradient Riemannian Langevin Dynamics (for inferring parameters in the probability simplex) [PT13], distributed SGLD [ASW14], etc.", "startOffset": 256, "endOffset": 263}, {"referenceID": 11, "context": "Furthermore, various extensions of SGLD have been proposed, including stochastic gradient hybrid Monte Carlo (SGHMC) [CFG14], stochastic gradient Nos\u00e9-Hoover Thermostat (SGNHT) [DFB14] (which improves upon SGHMC), stochastic gradient Fisher scoring (SGFS) [AKW12] (which uses second order information), stochastic gradient Riemannian Langevin Dynamics (for inferring parameters in the probability simplex) [PT13], distributed SGLD [ASW14], etc.", "startOffset": 406, "endOffset": 412}, {"referenceID": 1, "context": "Furthermore, various extensions of SGLD have been proposed, including stochastic gradient hybrid Monte Carlo (SGHMC) [CFG14], stochastic gradient Nos\u00e9-Hoover Thermostat (SGNHT) [DFB14] (which improves upon SGHMC), stochastic gradient Fisher scoring (SGFS) [AKW12] (which uses second order information), stochastic gradient Riemannian Langevin Dynamics (for inferring parameters in the probability simplex) [PT13], distributed SGLD [ASW14], etc.", "startOffset": 431, "endOffset": 438}, {"referenceID": 16, "context": "However, in this paper, we will just use \u201cvanilla\u201d SGLD [WT11].", "startOffset": 56, "endOffset": 62}, {"referenceID": 8, "context": "Following [HVD14], we call q(y|x) the \u201cteacher\u201d and S(y|x,w) the \u201cstudent\u201d.", "startOffset": 10, "endOffset": 17}, {"referenceID": 14, "context": "In particular, [SG05] also trained a parametric student model to approximate a Monte Carlo teacher.", "startOffset": 15, "endOffset": 21}, {"referenceID": 8, "context": "[HVD14] also trained a student neural network to emulate the predictions of a (larger) teacher network, a process they call \u201cdistillation\u201d.", "startOffset": 0, "endOffset": 7}, {"referenceID": 3, "context": "This extends earlier work of [BCNM06] which approximated an ensemble of classifiers by a single one.", "startOffset": 29, "endOffset": 37}, {"referenceID": 12, "context": "[RBK14] further extend this approach by training a student network that is deeper, but thinner (hence the term \u201cfit nets\u201d), than the teacher, and injecting supervision at multiple levels.", "startOffset": 0, "endOffset": 7}, {"referenceID": 8, "context": "[HVD14] coined the term \u201cdark knowledge\u201d to represent the information which is \u201chidden\u201d inside the teacher network, and which can then be distilled into the student.", "startOffset": 0, "endOffset": 7}, {"referenceID": 8, "context": "This is true for two reasons: first, the teacher is trained to predict a single label per input, whereas the student is trained to predict a distribution, which contains more information (as argued in [HVD14]); second, the teacher makes multiple passes over the same training data, whereas the student sees \u201cfresh\u201d randomly generated data D\u2032 at each step.", "startOffset": 201, "endOffset": 208}, {"referenceID": 7, "context": "In this section, we compare SGLD and distilled SGLD with other approximate inference methods, including the plugin approximation using SGD, the EP approach of [HLA15], the VB approach of [BCKW15], and Hamiltonian Monte Carlo (HMC) [Nea11], which is considered the \u201cgold standard\u201d for MCMC for neural nets.", "startOffset": 159, "endOffset": 166}, {"referenceID": 2, "context": "In this section, we compare SGLD and distilled SGLD with other approximate inference methods, including the plugin approximation using SGD, the EP approach of [HLA15], the VB approach of [BCKW15], and Hamiltonian Monte Carlo (HMC) [Nea11], which is considered the \u201cgold standard\u201d for MCMC for neural nets.", "startOffset": 187, "endOffset": 195}, {"referenceID": 10, "context": "In this section, we compare SGLD and distilled SGLD with other approximate inference methods, including the plugin approximation using SGD, the EP approach of [HLA15], the VB approach of [BCKW15], and Hamiltonian Monte Carlo (HMC) [Nea11], which is considered the \u201cgold standard\u201d for MCMC for neural nets.", "startOffset": 231, "endOffset": 238}, {"referenceID": 2, "context": "Second, we did not get access to the code for the VB approach in time for us to compare to it, so we just quote performance numbers from their paper [BCKW15].", "startOffset": 149, "endOffset": 157}, {"referenceID": 2, "context": "The only preprocessing we do is divide the pixel values by 126 (as in [BCKW15]).", "startOffset": 70, "endOffset": 78}, {"referenceID": 2, "context": "Following [BCKW15], we use an MLP with 2 hidden layers with 400 hidden units per layer, ReLU activations, and softmax outputs; we denote this by 784-400-400-10.", "startOffset": 10, "endOffset": 18}, {"referenceID": 2, "context": "6%, which is a bit lower than the SGD number reported in [BCKW15].", "startOffset": 57, "endOffset": 65}, {"referenceID": 2, "context": "4%, which is better than the SGD, dropout and BBB results from [BCKW15].", "startOffset": 63, "endOffset": 71}, {"referenceID": 7, "context": "We use the same data and model as [HLA15].", "startOffset": 34, "endOffset": 41}, {"referenceID": 2, "context": "SGD [BCKW15] Dropout BBB SGD (our impl.", "startOffset": 4, "endOffset": 12}, {"referenceID": 2, "context": "SGD (first column), Dropout and BBB/ VB numbers are quoted from [BCKW15].", "startOffset": 64, "endOffset": 72}, {"referenceID": 7, "context": "Finally, we consider a larger regression problem, namely the Boston housing dataset, which was also used in [HLA15].", "startOffset": 108, "endOffset": 115}, {"referenceID": 7, "context": "Following [HLA15], we use an MLP with 1 layer of 50 hidden units and ReLU activations.", "startOffset": 10, "endOffset": 17}, {"referenceID": 7, "context": "Furthermore, both SGLD and distilled SGLD are better than the PBP/ EP method of [HLA15] and the BBB/ VB method of [BCKW15].", "startOffset": 80, "endOffset": 87}, {"referenceID": 2, "context": "Furthermore, both SGLD and distilled SGLD are better than the PBP/ EP method of [HLA15] and the BBB/ VB method of [BCKW15].", "startOffset": 114, "endOffset": 122}, {"referenceID": 7, "context": "3 According to a personal communication with the authors of [HLA15] VB numbers are based on the method of [Gra11], but the method of [BCKW15] apparently gives similar results.", "startOffset": 60, "endOffset": 67}, {"referenceID": 6, "context": "3 According to a personal communication with the authors of [HLA15] VB numbers are based on the method of [Gra11], but the method of [BCKW15] apparently gives similar results.", "startOffset": 106, "endOffset": 113}, {"referenceID": 2, "context": "3 According to a personal communication with the authors of [HLA15] VB numbers are based on the method of [Gra11], but the method of [BCKW15] apparently gives similar results.", "startOffset": 133, "endOffset": 141}, {"referenceID": 7, "context": "We choose all hyper-parameters using cross-validation whereas [HLA15] performs posterior inference on the noise and prior precisions, and uses Bayesian optimization to choose the remaining hyper-parameters.", "startOffset": 62, "endOffset": 69}, {"referenceID": 7, "context": "test log likelihood EP/ PBP (as reported in [HLA15]) -2.", "startOffset": 44, "endOffset": 51}, {"referenceID": 7, "context": "089 VB (as reported in [HLA15]) -2.", "startOffset": 23, "endOffset": 30}, {"referenceID": 7, "context": "(Figures a-d kindly provided by the authors of [HLA15].", "startOffset": 47, "endOffset": 54}, {"referenceID": 7, "context": "We have shown a very simple method for \u201cbeing Bayesian\u201d about neural networks (and other kinds of models), that seems to work better than recently proposed alternatives based on EP [HLA15] and VB [BCKW15].", "startOffset": 181, "endOffset": 188}, {"referenceID": 2, "context": "We have shown a very simple method for \u201cbeing Bayesian\u201d about neural networks (and other kinds of models), that seems to work better than recently proposed alternatives based on EP [HLA15] and VB [BCKW15].", "startOffset": 196, "endOffset": 204}, {"referenceID": 15, "context": "(5) Investigating if our method is able to reduce the prevalence of confident false predictions on adversarially generated examples, such as those discussed in [SZS14].", "startOffset": 160, "endOffset": 167}], "year": 2015, "abstractText": "We consider the problem of Bayesian parameter estimation for deep neural networks, which is important in problem settings where we may have little data, and/ or where we need accurate posterior predictive densities p(y|x,D), e.g., for applications involving bandits or active learning. One simple approach to this is to use online Monte Carlo methods, such as SGLD (stochastic gradient Langevin dynamics). Unfortunately, such a method needs to store many copies of the parameters (which wastes memory), and needs to make predictions using many versions of the model (which wastes time). We describe a method for \u201cdistilling\u201d a Monte Carlo approximation to the posterior predictive density into a more compact form, namely a single deep neural network. We compare to two very recent approaches to Bayesian neural networks, namely an approach based on expectation propagation [HLA15] and an approach based on variational Bayes [BCKW15]. Our method performs better than both of these, is much simpler to implement, and uses less computation at test time.", "creator": "LaTeX with hyperref package"}}}