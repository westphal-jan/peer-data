{"id": "1506.05254", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Jun-2015", "title": "Gradient Estimation Using Stochastic Computation Graphs", "abstract": "In a variety of problems originating in supervised, unsupervised, and reinforcement learning, the loss function is defined by an expectation over a collection of random variables, which might be part of a probabilistic model or the external world. Estimating the gradient of this loss function, using samples, lies at the core of gradient-based learning algorithms for these problems. We introduce the formalism of stochastic computation graphs---directed acyclic graphs that include both deterministic functions and conditional probability distributions---and describe how to easily and automatically derive an unbiased estimator of the loss function's gradient. The resulting algorithm for computing the gradient estimator is a simple modification of the standard backpropagation algorithm. The generic scheme we propose unifies estimators derived in variety of prior work, along with variance-reduction techniques therein. It could assist researchers in developing intricate models involving a combination of stochastic and deterministic operations, enabling, for example, attention, memory, and control actions.", "histories": [["v1", "Wed, 17 Jun 2015 09:32:31 GMT  (277kb,D)", "http://arxiv.org/abs/1506.05254v1", null], ["v2", "Fri, 13 Nov 2015 03:19:18 GMT  (277kb,D)", "http://arxiv.org/abs/1506.05254v2", null], ["v3", "Tue, 5 Jan 2016 19:56:22 GMT  (277kb,D)", "http://arxiv.org/abs/1506.05254v3", "Advances in Neural Information Processing Systems 28 (NIPS 2015)"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["john schulman", "nicolas heess", "theophane weber", "pieter abbeel"], "accepted": true, "id": "1506.05254"}, "pdf": {"name": "1506.05254.pdf", "metadata": {"source": "CRF", "title": "Gradient Estimation Using Stochastic Computation Graphs", "authors": ["John Schulman", "Nicolas Heess", "Pieter Abbeel"], "emails": ["joschu@eecs.berkeley.edu", "heess@google.com", "theophane@google.com", "pabbeel@eecs.berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Gradient Estimators for a Single Random Variable", "text": "This section discusses the calculation of the course of an expectation over a single random variable - the estimators described here will be the building blocks for more complex cases with multiple variables. Suppose that x is a random variable, f is a function (say SF), and we are interested in calculating this probability distribution. (PD) There are a few different ways in which the process of generating x could be parameterized, which can lead to different gradient estimators. \u2022 We could get a parameterized probability distribution if, however, the calculation of the probability distribution x \u00b2 p (x) is required. In this case, we can use the Score function (SF) to find an estimator [3]: Systematism Ex [f (x)] = Ex (x) = Ex (x)."}, {"heading": "2.2 Stochastic Computation Graphs", "text": "The results of this article are applied to stochastic computation graphs, which are defined as follows: Definition 1 (Stochastic Computation Graph). A directed, acyclic graph with three types of nodes: 1. Input nodes that are set externally, including the parameters we differentiate with regards to. 2. Deterministic nodes that are functions of their parents.3. Stochastic nodes that are conditionally distributed among their parents.Each parent node v of an unentered node w is connected to it by a directed edge (v, w).In the subsequent diagrams of this article, we will use circles to designate stochastic nodes and squares as shown below. The structure of the graph fully specifies which estimator we will use: SF, PD or a combination thereof. This graphic notation is shown below, along with the individual variable estimators from the Input Node Defect Nodes section."}, {"heading": "2.3 Simple Examples", "text": "Gradient estimators can be described by writing and differentiating expectations as integrals, as with the simpler estimators in Section 2.1. However, they are also implied by the general results we see in Section 3.These simple examples illustrate several important motives where stochastic and deterministic nodes are arranged in series or in parallel. Note, for example, that in (2) the derivative of y does not occur in the estimator, because the path from \u03b8 to f is \"blocked\" by x. Similarly, in (3) p (y | x) no determination appears (this type of behavior is particularly useful when we only have access to a system simulator but do not have access to the actual probability function). On the other hand, (4) a direct path from the determination to f provides a term for the gradient estimator."}, {"heading": "3 Main Results on Stochastic Computation Graphs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Gradient Estimators", "text": "That is, we must derive the cost of an estimated sum of costs in a statistical diagram that favors dependence by different functions. (1) This estimator can be efficiently differentiated by making an appropriate \"surrogate\" of objective functioning.Let us denounce the amount of input nodes. (2) A pathological derivative that identifies dependence by differentiating function.2) We will denounce the amount of input nodes, D the number of input nodes, D the deterministic nodes, and S the amount of stochastic nodes. Further, we will denounce a number of cost nodes. 3) We will denounce the amount of input nodes, D the deterministic nodes, and S the amount of stochastic nodes."}, {"heading": "3.3 Higher-Order Derivatives.", "text": "The gradient estimator for a stochastic calculation graph is itself a stochastic calculation graph. Therefore, it is possible to calculate the gradient again (for each component of the gradient vector) and obtain an estimator of the Hessian. For most interesting problems, it is not efficient to calculate this dense Hesse. On the other hand, one can also differentiate the gradient vector product to obtain a Hessian vector product - this calculation is usually not much more expensive than the gradient calculation itself. With the Hessian vector product, one can implement a quasi-Newton algorithm via the conjugate gradient algorithm. [28] A variant of this technique, called Hessian-free optimization [13], is used to form large neural networks."}, {"heading": "4 Variance Reduction", "text": "Consider the estimation of the score function [f (x) \u2212 b]. Taking the score function estimator, one generally obtains a significant difference reduction - b is often referred to as baseline3 (see [6] for a more in-depth discussion of baselines and their variance reduction properties).We can make a general statement in the case of stochastic calculation graphs - that we can add a baseline3 to each stochastic node (see [6]), which depends on all nodes it does not affect."}, {"heading": "5 Algorithms", "text": "As shown in section 3, the gradient estimator can be determined by differentiating a substitute objective function L. Therefore, this derivation can be calculated by implementing the backpropagation algorithm to L. This is probably the most practical and efficient method and can be facilitated by automatic differentiation software. Algorithm 1 explicitly shows how the gradient estimator is calculated in a backward pass through the stochastic calculation curve. The algorithm recursively calculates gv: = \u2202 \u2202 vE [\u2211 c-C v-cc] at each deterministic and input node v."}, {"heading": "6 Related Work", "text": "In fact, a stochastic calculation pattern is a type of grammar diagram in which the deterministic nodes correspond to degenerated probability distributions.) The subject of gradient estimation is inspired by Bayes networks and influence diagrams [19]. (In fact, a stochastic calculation pattern is a type of Bayes network in which the deterministic nodes correspond to degenerated probability distributions.) The subject of gradient estimation has aroused a significant interest in machine learning. (Gradients for networks with stochastic units were investigated in Bengio et al.) The subject of gradient estimation has aroused a significant interest in machine learning. (Gradients for networks with stochastic units were investigated in Bengio et al.)"}, {"heading": "7 Conclusion", "text": "We have developed a framework to describe a calculation with stochastic and deterministic operations, called a stochastic calculation graph. Considering a stochastic calculation graph, we can automatically obtain a gradient estimator because the graph meets the appropriate conditions for the differentiation of functions at its nodes; the gradient can be efficiently calculated in a reverse motion through the graph: one approach is to apply the standard backpropagation algorithm to one of the replacement loss functions in Section 3; another approach (which is roughly equivalent) is to apply a modified backpropagation method shown in Algorithm 1. We hope that the results we present will be sufficiently general to automatically reproduce a variety of gradient estimators derived from previous work in amplification learning and probability modeling, as we show in Appendix C. We hope that this work will facilitate the advancement of more interesting and powerful models."}, {"heading": "8 Acknowledgements", "text": "We would like to thank Shakir Mohamed, Dave Silver, Yuval Tassa, Andriy Mnih and others from DeepMind for their insightful comments."}, {"heading": "A Proofs", "text": "Theorem 1We consider the case that all random variables are continuously evaluated, so expectations can be written as integrals. The case of discrete random variables is similar. We will differentiate the expectation of a uniform cost concept; summed up by these conditions, equation (6).Ev S, v S, v S, v S, v S, dv S, v S, v S, v S (7).Ev S, v S, v S, v S, v S, v S, v S S, v S S, dv S (DEPSv) dv S, v S S S, v S S S S, v S S S S S, v S S S S S S, v S S S S, v S S S S S, S S S S S S v S S S, S S S S S v S S S, S S S S S v S S S, S S S S S v S S S, S S S S v S S S S, S S S S v S S S S, S S S v S S S S S, S S S v S S S S S v S S S, S S S S v S S S S S, S S v S S S S S v S S S S, S S v S S S S S S v S S S, S S S v S S S S S, S v S S S S S v S S S S, S v S S S S S S v S S S S, S v S S S S S S v S S S S, S v S S S S S v S S S S S, S S v S S S S S, S v S S S S v S S S S S S, S v S S S S v S S S S S S, S v S S S v S S S S S S S, S v S S v S S S S S S S S, S v S S S S S v S S S S S, S v S S S v S S S S S S, S v S S, S v S S S S S v S S S S S S S S S, S v S S S S S, S v S S S v S S S S, S S v S S S S S S S"}, {"heading": "B Surrogate as an Upper Bound, and MM Algorithms", "text": "Under certain conditions, L is an upper limit for the true target (plus a constant). We will apply two constraints to the stochastic calculation curve: (1) Firstly, that all costs c \u00b2 C are negative. (2) The costs are not deterministically affected by the parameters c \u00b2. Firstly, we will use an importance sample to record the expectation of a given cost node when the sample distribution deviates from the distribution we evaluate: for the parameters c \u00b2, p \u00b2, p \u00b2, p \u00b2, c, c, c \u00b2, c \u00b2, c \u00b2, c \u00b2, c \u00b2, c \u00b2, c \u00b2, c \u00b2, c \u00b2, c, c \u00b2, c \u00b2, c \u00b2, c \u00b2, c \u00b2, c, c \u00b2, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c,"}, {"heading": "C Examples", "text": "r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r2 r3 r3 r3 r3 r3 r3 r8 r3 r3 r3 r3 r3 r8 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r2 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r8 r8 r8 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r3 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r8 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7 r7"}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>In a variety of problems originating in supervised, unsupervised, and reinforce-<lb>ment learning, the loss function is defined by an expectation over a collection<lb>of random variables, which might be part of a probabilistic model or the exter-<lb>nal world. Estimating the gradient of this loss function, using samples, lies at<lb>the core of gradient-based learning algorithms for these problems. We introduce<lb>the formalism of stochastic computation graphs\u2014directed acyclic graphs that in-<lb>clude both deterministic functions and conditional probability distributions\u2014and<lb>describe how to easily and automatically derive an unbiased estimator of the loss<lb>function\u2019s gradient. The resulting algorithm for computing the gradient estimator<lb>is a simple modification of the standard backpropagation algorithm. The generic<lb>scheme we propose unifies estimators derived in variety of prior work, along with<lb>variance-reduction techniques therein. It could assist researchers in developing in-<lb>tricate models involving a combination of stochastic and deterministic operations,<lb>enabling, for example, attention, memory, and control actions.", "creator": "LaTeX with hyperref package"}}}