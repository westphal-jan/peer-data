{"id": "1506.06726", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jun-2015", "title": "Skip-Thought Vectors", "abstract": "We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.", "histories": [["v1", "Mon, 22 Jun 2015 19:33:40 GMT  (1199kb,D)", "http://arxiv.org/abs/1506.06726v1", "11 pages"]], "COMMENTS": "11 pages", "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["ryan kiros", "yukun zhu", "ruslan salakhutdinov", "richard s zemel", "raquel urtasun", "antonio torralba 0001", "sanja fidler"], "accepted": true, "id": "1506.06726"}, "pdf": {"name": "1506.06726.pdf", "metadata": {"source": "CRF", "title": "Skip-Thought Vectors", "authors": ["Ryan Kiros", "Yukun Zhu", "Ruslan Salakhutdinov", "Richard S. Zemel", "Antonio Torralba", "Raquel Urtasun", "Sanja Fidler"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "It is indeed the case that we are able to manoeuvre ourselves into a situation where we have to put ourselves at the centre."}, {"heading": "2 Approach", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Inducing skip-thought vectors", "text": "In other words, we have only one sentence in which we behave in a way, how we have behaved in a way, how we have behaved in a way, how we have behaved in a way, how we have behaved in a way, how we have behaved in a way, how we have behaved in a way, how we behave in a way, how we behave in a way, how we behave in a way, how we behave in a way, how we behave in a way, how we behave in a way, how we behave in a way, how we behave in a way, how we behave in a way, how we behave in a way, how we behave in a way. \""}, {"heading": "2.2 Vocabulary expansion", "text": "Suppose we have a model trained to induce word representations such as word2vec. Let Vw2v designate the word as the embedding space of these word representations and let Vrnn designate the RNN word as the embedding space. We assume that the vocabulary of Vw2v is much larger than that of Vrnn. Our goal is to construct a mapping f: Vw2v \u2192 Vrnn parameterized by a matrix W, so that v \u00b2 = Wv for v \u00b2 Vw2v and v \u00b2 Vrnn. Inspired by [15] having learned linear mappings between translation word spaces, we solve an unregulated L2 linear regression loss for matrix W. Thus, each word from Vw2v can now be mapped as a vocabulator for coding sentences. Table 3 shows examples of the nearest problem that do not appear at the introductory level for words that are sufficient."}, {"heading": "3 Experiments", "text": "In our experiments, we evaluate the ability of our encoder as a generic trait extractor after training on the BookCorpus dataset. Our experimental setup for each task is as follows: \u2022 Using the learned encoder as a trait extractor, extracting skip vectors for all records. \u2022 If the task involves calculating scores between pairs of sentences, we calculate component-by-component structures between pairs. This is described in more detail for each experiment. \u2022 Train a linear classifier over the extracted traits, without additional fine-tuning or feedback from the skip thought model. We limit ourselves to linear classifiers for two reasons. The first is to directly evaluate the display quality of the calculated vectors. It is possible that additional performance gains can be achieved during our experiments with non-linear models, but this does not fall within the scope of our goal. In addition, it allows us to better analyze the strengths and weaknesses of the learned vectors."}, {"heading": "3.1 Details of training", "text": "In order to cause the skipped thought vectors, we build two separate models on our book body. One is a unidirectional encoder with 2400 dimensions, which we then call uni-skip. The other is a bidirectional model with forward and backward directed encoders of 1200 dimensions each. This model contains two encoders with different parameters: one encoder receives the sentence in the correct order, while the other receives the sentence in reverse order. The results are then linked to a 2400 dimensional vector. We refer to this model as bi-skip. For training, we initialize all recursive matrices with orthogonal initialization [16]. Non-recursive weights are distributed uniformly in [-0,1,0,1]."}, {"heading": "3.2 Semantic relatedness", "text": "In fact, it is that we are able to assert ourselves, that we are able to put ourselves on top, \"he said.\" We have to put ourselves on top, \"he said.\" We have to put ourselves on top, \"he said.\" We have to put ourselves on top, \"he said.\" We have to put ourselves on top, \"he said.\" We have to put ourselves on top, \"he said.\" We have to put ourselves on top, \"he said.\" We have to put ourselves on top. \""}, {"heading": "3.3 Paraphrase detection", "text": "The next task we are looking at is paraphrase detection on the Microsoft Research Paraphrase Corpus [30]. In this task, two sets are given and you have to predict whether they are paraphrases or not. The training set consists of 4076 pairs of sentences (2753 which are positive) and the test set has 1725 pairs (1147 are positive). We then calculate a vector that represents the sentence pair in the same way as on the SICK dataset, using the component-by-component product u \u00b7 v and its absolute difference | u \u2212 v |, which are then concatenated together. We then train the logistic regression above to predict whether the sentences are paraphrases. Cross-validation is used to match the L2 penalty.As with the semantic relational task, paraphrase detection has been largely dominated by extensive feature engineering (or a combination of feature engineering and set settings) using two sets of results: one in two sets and one in two."}, {"heading": "3.4 Image-sentence ranking", "text": "For this experiment, we use the Microsoft COCO dataset [34], which is the largest publicly available dataset of images with high-quality set descriptions. Each image is annotated with 5 captions, each of which comes from different commentators. After previous work, we consider two tasks: image description and image search. For image descriptions, one image is presented and sentences are rated on the basis of how well they describe the query image. The image search task is reversed: with a caption, we obtain images that match the query well. The training set includes over 80,000 images with 5 captions each. For development and testing, we use the same splits as [31]. The development and test kits each contain 1000 images and 5000 captions. The evaluation is performed with Recall @ K, i.e. the mean number of images for which the correct caption is ranked within the top K results (and vice versa)."}, {"heading": "3.5 Classification benchmarks", "text": "For our final quantitative experiments, we report on several classification benchmarks commonly used to evaluate sentence representation methods. We use 5 data sets: Film Evaluation Mood (MR) [36], Customer Evaluation (CR) [37], Subjectivity / Objectivity Classification (SUBJ) [38], Opinion Polarity (MPQA) [39] and Question Type Classification (TREC) [40]. For all data sets, we simply extract thought vectors and form a logistic regression classifier above. 10-fold cross validation is used to evaluate the first 4 data sets, while TREC has a predefined pull / test split. We match the L2 punishability with the cross validation (and therefore use a nested cross validation for the first 4 data sets NB-94.4).Method MR CR SUBJ MPQA TRECNB-SV41 [873.873.874]."}, {"heading": "3.6 Visualizing skip-thoughts and generating stories", "text": "As a final experiment, we used t-SNE [42] to skip thought vectors extracted from TREC, SUBJ, and SICK datasets, and the visualizations are shown in Figure 2. For SICK visualization, each point represents a sentence pair, which is calculated by concatenating component-by-component and absolute differences in characteristics. It is noteworthy that sentence pairs that are similar to each other are embedded side each other. Even without the use of relation labels, skipped vectors can learn to grasp these characteristics precisely. 3We use the at https: / / github.com / mesnilgr / nbsvmSince our decoder is a neural language model, we can also generate a generation from it by conditioning a sentence by creating a new sentence that binds and continues the generated example to the previous text."}, {"heading": "4 Conclusion", "text": "We evaluated the effectiveness of Skip Thought Vectors as a standard sentence representation with linear classifiers over 8 tasks. Many of the methods we compare with have been evaluated on only one task. The fact that Skip Thought Vectors work well on all the tasks considered underscores the robustness of our representations. We believe that our model for learning Skip Thought Vectors only scratches the surface of possible targets. Many variations have yet to be explored, including (a) deep encoders and decoders, (b) larger context windows, (c) encoding and decrypting paragraphs, (d) other encoders such as convectors. Probably, further exploration of this space will lead to even higher quality representations."}, {"heading": "Acknowledgments", "text": "We thank Geoffrey Hinton for proposing the name skip-thoughts and Felix Hill, Kelvin Xu, Kyunghyun Cho and Ilya Sutskever for valuable comments and discussions. This work was supported by NSERC, Samsung, CIFAR, Google and ONR Grant N00014-14-1-0232."}], "references": [{"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts"], "venue": "In EMNLP,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1997}, {"title": "A convolutional neural network for modelling sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["Kyunghyun Cho", "Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio"], "venue": null, "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Self-adaptive hierarchical sentence model", "author": ["Han Zhao", "Zhengdong Lu", "Pascal Poupart"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V Le", "Tomas Mikolov"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books", "author": ["Yukun Zhu", "Ryan Kiros", "Richard S. Zemel", "Ruslan Salakhutdinov", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler"], "venue": "In Arxiv,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Recurrent continuous translation models", "author": ["Nal Kalchbrenner", "Phil Blunsom"], "venue": "In EMNLP,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc VV Le"], "venue": "In NIPS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "ICLR,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio"], "venue": "NIPS Deep Learning Workshop,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Tomas Mikolov", "Quoc V Le", "Ilya Sutskever"], "venue": "arXiv preprint arXiv:1309.4168,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2013}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["Andrew M Saxe", "James L McClelland", "Surya Ganguli"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "ICLR,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Illinois-lh: A denotational and distributional approach to semantics", "author": ["Alice Lai", "Julia Hockenmaier"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Unal-nlp: Combining soft cardinality features for semantic textual similarity, relatedness and entailment", "author": ["Sergio Jimenez", "George Duenas", "Julia Baquero", "Alexander Gelbukh", "Av Juan Dios B\u00e1tiz", "Av Mendiz\u00e1bal"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "The meaning factory: Formal semantics for recognizing textual entailment and determining semantic similarity", "author": ["Johannes Bjerva", "Johan Bos", "Rob van der Goot", "Malvina Nissim"], "venue": "SemEval", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Ecnu: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment", "author": ["Jiang Zhao", "Tian Tian Zhu", "Man Lan"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Improved semantic representations from tree-structured long short-term memory", "author": ["Kai Sheng Tai", "Richard Socher", "Christopher D Manning"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Grounded compositional semantics for finding and describing images with sentences", "author": ["Richard Socher", "Andrej Karpathy", "Quoc V Le", "Christopher D Manning", "Andrew Y Ng"], "venue": "TACL,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection", "author": ["Richard Socher", "Eric H Huang", "Jeffrey Pennin", "Christopher D Manning", "Andrew Y Ng"], "venue": "In NIPS,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Using machine translation evaluation techniques to determine sentence-level semantic equivalence", "author": ["Andrew Finch", "Young-Sook Hwang", "Eiichiro Sumita"], "venue": "In IWP,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Paraphrase identification as probabilistic quasi-synchronous recognition", "author": ["Dipanjan Das", "Noah A Smith"], "venue": "In ACL,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2009}, {"title": "Using dependency-based features to take the \u00e2\u0102IJpara-farce\u00e2\u0102\u0130 out of paraphrase", "author": ["Stephen Wan", "Mark Dras", "Robert Dale", "C\u00e9cile Paris"], "venue": "In Proceedings of the Australasian Language Technology Workshop,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2006}, {"title": "Re-examining machine translation metrics for paraphrase identification", "author": ["Nitin Madnani", "Joel Tetreault", "Martin Chodorow"], "venue": "In NAACL,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2012}, {"title": "Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment", "author": ["Marco Marelli", "Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources", "author": ["Bill Dolan", "Chris Quirk", "Chris Brockett"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2004}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["A. Karpathy", "L. Fei-Fei"], "venue": "In CVPR,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2015}, {"title": "Associating neural word embeddings with deep image representations using fisher vectors", "author": ["Benjamin Klein", "Guy Lev", "Gil Sadeh", "Lior Wolf"], "venue": "In CVPR,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2015}, {"title": "Deep captioning with multimodal recurrent neural networks (m-rnn)", "author": ["Junhua Mao", "Wei Xu", "Yi Yang", "Jiang Wang", "Alan Yuille"], "venue": null, "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2015}, {"title": "Microsoft coco: Common objects in context", "author": ["Tsung-Yi Lin", "Michael Maire", "Serge Belongie", "James Hays", "Pietro Perona", "Deva Ramanan", "Piotr Doll\u00e1r", "C Lawrence Zitnick"], "venue": "In ECCV,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": "ICLR,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2015}, {"title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales", "author": ["Bo Pang", "Lillian Lee"], "venue": "In ACL,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2005}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2004}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["Bo Pang", "Lillian Lee"], "venue": "In ACL,", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2004}, {"title": "Annotating expressions of opinions and emotions in language", "author": ["Janyce Wiebe", "Theresa Wilson", "Claire Cardie"], "venue": "Language resources and evaluation,", "citeRegEx": "39", "shortCiteRegEx": "39", "year": 2005}, {"title": "Learning question classifiers", "author": ["Xin Li", "Dan Roth"], "venue": "In Proceedings of the 19th international conference on Computational linguistics,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 2002}, {"title": "Baselines and bigrams: Simple, good sentiment and topic classification", "author": ["Sida Wang", "Christopher D Manning"], "venue": "In ACL,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2012}, {"title": "Visualizing data using t-sne", "author": ["Laurens Van der Maaten", "Geoffrey Hinton"], "venue": null, "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "In recent years, several approaches have been developed for learning composition operators that map word vectors to sentence vectors including recursive networks [1], recurrent networks [2], convolutional networks [3, 4] and recursive-convolutional methods [5, 6] among others.", "startOffset": 162, "endOffset": 165}, {"referenceID": 1, "context": "In recent years, several approaches have been developed for learning composition operators that map word vectors to sentence vectors including recursive networks [1], recurrent networks [2], convolutional networks [3, 4] and recursive-convolutional methods [5, 6] among others.", "startOffset": 186, "endOffset": 189}, {"referenceID": 2, "context": "In recent years, several approaches have been developed for learning composition operators that map word vectors to sentence vectors including recursive networks [1], recurrent networks [2], convolutional networks [3, 4] and recursive-convolutional methods [5, 6] among others.", "startOffset": 214, "endOffset": 220}, {"referenceID": 3, "context": "In recent years, several approaches have been developed for learning composition operators that map word vectors to sentence vectors including recursive networks [1], recurrent networks [2], convolutional networks [3, 4] and recursive-convolutional methods [5, 6] among others.", "startOffset": 214, "endOffset": 220}, {"referenceID": 4, "context": "In recent years, several approaches have been developed for learning composition operators that map word vectors to sentence vectors including recursive networks [1], recurrent networks [2], convolutional networks [3, 4] and recursive-convolutional methods [5, 6] among others.", "startOffset": 257, "endOffset": 263}, {"referenceID": 5, "context": "In recent years, several approaches have been developed for learning composition operators that map word vectors to sentence vectors including recursive networks [1], recurrent networks [2], convolutional networks [3, 4] and recursive-convolutional methods [5, 6] among others.", "startOffset": 257, "endOffset": 263}, {"referenceID": 6, "context": "The paragraph vector of [7] is an alternative to the above models in that it can learn unsupervised sentence representations by introducing a distributed sentence indicator as part of a neural language model.", "startOffset": 24, "endOffset": 27}, {"referenceID": 7, "context": "Using word vector learning as inspiration, we propose an objective function that abstracts the skip-gram model of [8] to the sentence level.", "startOffset": 114, "endOffset": 117}, {"referenceID": 8, "context": "We chose to use a large collection of novels, namely the BookCorpus dataset [9] for training our models.", "startOffset": 76, "endOffset": 79}, {"referenceID": 8, "context": "Table 1: Summary statistics of the BookCorpus dataset [9].", "startOffset": 54, "endOffset": 57}, {"referenceID": 7, "context": "Using pretrained word2vec representations learned with a continuous bag-of-words model [8], we learn a linear mapping from a word in word2vec space to a word in the encoder\u2019s vocabulary space.", "startOffset": 87, "endOffset": 90}, {"referenceID": 9, "context": "Several choices of encoder-decoder pairs have been explored, including ConvNet-RNN [10], RNN-RNN [11] and LSTM-LSTM [12].", "startOffset": 83, "endOffset": 87}, {"referenceID": 10, "context": "Several choices of encoder-decoder pairs have been explored, including ConvNet-RNN [10], RNN-RNN [11] and LSTM-LSTM [12].", "startOffset": 97, "endOffset": 101}, {"referenceID": 11, "context": "Several choices of encoder-decoder pairs have been explored, including ConvNet-RNN [10], RNN-RNN [11] and LSTM-LSTM [12].", "startOffset": 116, "endOffset": 120}, {"referenceID": 12, "context": "The source sentence representation can also dynamically change through the use of an attention mechanism [13] to take into account only the relevant words for translation at any given time.", "startOffset": 105, "endOffset": 109}, {"referenceID": 13, "context": "In our model, we use an RNN encoder with GRU [14] activations and an RNN decoder with a conditional GRU.", "startOffset": 45, "endOffset": 49}, {"referenceID": 10, "context": "This model combination is nearly identical to the RNN encoder-decoder of [11] used in neural machine translation.", "startOffset": 73, "endOffset": 77}, {"referenceID": 1, "context": "GRU has been shown to perform as well as LSTM [2] on sequence modelling tasks [14] while being conceptually simpler.", "startOffset": 46, "endOffset": 49}, {"referenceID": 13, "context": "GRU has been shown to perform as well as LSTM [2] on sequence modelling tasks [14] while being conceptually simpler.", "startOffset": 78, "endOffset": 82}, {"referenceID": 8, "context": "A preliminary version of our model was developed in the context of a computer vision application [9].", "startOffset": 97, "endOffset": 100}, {"referenceID": 14, "context": "Inspired by [15], which learned linear mappings between translation word spaces, we solve an un-regularized L2 linear regression loss for the matrix W.", "startOffset": 12, "endOffset": 16}, {"referenceID": 15, "context": "For training, we initialize all recurrent matricies with orthogonal initialization [16].", "startOffset": 83, "endOffset": 87}, {"referenceID": 17, "context": "Illinois-LH [18] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 18, "context": "3692 UNAL-NLP [19] 0.", "startOffset": 14, "endOffset": 18}, {"referenceID": 19, "context": "3550 Meaning Factory [20] 0.", "startOffset": 21, "endOffset": 25}, {"referenceID": 20, "context": "3224 ECNU [21] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 21, "context": "Mean vectors [22] 0.", "startOffset": 13, "endOffset": 17}, {"referenceID": 22, "context": "4557 DT-RNN [23] 0.", "startOffset": 12, "endOffset": 16}, {"referenceID": 22, "context": "3822 SDT-RNN [23] 0.", "startOffset": 13, "endOffset": 17}, {"referenceID": 21, "context": "3848 LSTM [22] 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 21, "context": "2831 Bidirectional LSTM [22] 0.", "startOffset": 24, "endOffset": 28}, {"referenceID": 21, "context": "2736 Dependency Tree-LSTM [22] 0.", "startOffset": 26, "endOffset": 30}, {"referenceID": 23, "context": "feats [24] 73.", "startOffset": 6, "endOffset": 10}, {"referenceID": 23, "context": "2 RAE+DP [24] 72.", "startOffset": 9, "endOffset": 13}, {"referenceID": 23, "context": "6 RAE+feats [24] 74.", "startOffset": 12, "endOffset": 16}, {"referenceID": 23, "context": "2 RAE+DP+feats [24] 76.", "startOffset": 15, "endOffset": 19}, {"referenceID": 24, "context": "FHS [25] 75.", "startOffset": 4, "endOffset": 8}, {"referenceID": 25, "context": "7 PE [26] 76.", "startOffset": 5, "endOffset": 9}, {"referenceID": 26, "context": "7 WDDP [27] 75.", "startOffset": 7, "endOffset": 11}, {"referenceID": 27, "context": "0 MTMETRICS [28] 77.", "startOffset": 12, "endOffset": 16}, {"referenceID": 21, "context": "The first group of results are SemEval 2014 submissions, while the second group are results reported by [22].", "startOffset": 104, "endOffset": 108}, {"referenceID": 16, "context": "We used the Adam algorithm [17] for optimization.", "startOffset": 27, "endOffset": 31}, {"referenceID": 28, "context": "Our first experiment is on the SemEval 2014 Task 1: semantic relatedness SICK dataset [29].", "startOffset": 86, "endOffset": 90}, {"referenceID": 21, "context": "Recently, [22] showed that learning representations with LSTM or Tree-LSTM for the task at hand is able to outperform these existing systems.", "startOffset": 10, "endOffset": 14}, {"referenceID": 21, "context": "These two features were also used by [22].", "startOffset": 37, "endOffset": 41}, {"referenceID": 21, "context": "To predict a score, we use the same setup as [22].", "startOffset": 45, "endOffset": 49}, {"referenceID": 21, "context": "Only the dependency tree-LSTM of [22] performs better than our results.", "startOffset": 33, "endOffset": 37}, {"referenceID": 29, "context": "The next task we consider is paraphrase detection on the Microsoft Research Paraphrase Corpus [30].", "startOffset": 94, "endOffset": 98}, {"referenceID": 23, "context": "We report experiments in two settings: one using the features as above and the other incorporating basic statistics between sentence pairs, the same features used by [24].", "startOffset": 166, "endOffset": 170}, {"referenceID": 23, "context": "We isolate the results and baselines used in [24] as well as the top published results on this task.", "startOffset": 45, "endOffset": 49}, {"referenceID": 30, "context": "0 500 DVSA [31] 38.", "startOffset": 11, "endOffset": 15}, {"referenceID": 31, "context": "8 3 GMM+HGLMM [32] 39.", "startOffset": 14, "endOffset": 18}, {"referenceID": 32, "context": "6 4 m-RNN [33] 41.", "startOffset": 10, "endOffset": 14}, {"referenceID": 33, "context": "For this experiment, we use the Microsoft COCO dataset [34] which is the largest publicly available dataset of images with high-quality sentence descriptions.", "startOffset": 55, "endOffset": 59}, {"referenceID": 30, "context": "For development and testing we use the same splits as [31].", "startOffset": 54, "endOffset": 58}, {"referenceID": 31, "context": "Recently, [32] showed that by using Fisher vectors for representing sentences, linear CCA can be applied to obtain performance that is as strong as using RNNs for this task.", "startOffset": 10, "endOffset": 14}, {"referenceID": 31, "context": "Thus the method of [32] is a strong baseline to compare our sentence representations with.", "startOffset": 19, "endOffset": 23}, {"referenceID": 34, "context": "For our experiments, we represent images using 4096-dimensional OxfordNet features from their 19-layer model [35].", "startOffset": 109, "endOffset": 113}, {"referenceID": 30, "context": "Using skip-thought vectors for sentences, we get performance that is on par with both [31] and [32] except for R@1 on image annotation, where other methods perform much better.", "startOffset": 86, "endOffset": 90}, {"referenceID": 31, "context": "Using skip-thought vectors for sentences, we get performance that is on par with both [31] and [32] except for R@1 on image annotation, where other methods perform much better.", "startOffset": 95, "endOffset": 99}, {"referenceID": 31, "context": "Combined with the results of [32], it also highlights that simple, scalable embedding techniques perform very well provided that high-quality image and sentence vectors are available.", "startOffset": 29, "endOffset": 33}, {"referenceID": 35, "context": "We use 5 datasets: movie review sentiment (MR) [36], customer product reviews (CR) [37], subjectivity/objectivity classification (SUBJ) [38], opinion polarity (MPQA) [39] and question-type classification (TREC) [40].", "startOffset": 47, "endOffset": 51}, {"referenceID": 36, "context": "We use 5 datasets: movie review sentiment (MR) [36], customer product reviews (CR) [37], subjectivity/objectivity classification (SUBJ) [38], opinion polarity (MPQA) [39] and question-type classification (TREC) [40].", "startOffset": 83, "endOffset": 87}, {"referenceID": 37, "context": "We use 5 datasets: movie review sentiment (MR) [36], customer product reviews (CR) [37], subjectivity/objectivity classification (SUBJ) [38], opinion polarity (MPQA) [39] and question-type classification (TREC) [40].", "startOffset": 136, "endOffset": 140}, {"referenceID": 38, "context": "We use 5 datasets: movie review sentiment (MR) [36], customer product reviews (CR) [37], subjectivity/objectivity classification (SUBJ) [38], opinion polarity (MPQA) [39] and question-type classification (TREC) [40].", "startOffset": 166, "endOffset": 170}, {"referenceID": 39, "context": "We use 5 datasets: movie review sentiment (MR) [36], customer product reviews (CR) [37], subjectivity/objectivity classification (SUBJ) [38], opinion polarity (MPQA) [39] and question-type classification (TREC) [40].", "startOffset": 211, "endOffset": 215}, {"referenceID": 40, "context": "NB-SVM [41] 79.", "startOffset": 7, "endOffset": 11}, {"referenceID": 40, "context": "3 MNB [41] 79.", "startOffset": 6, "endOffset": 10}, {"referenceID": 5, "context": "3 cBoW [6] 77.", "startOffset": 7, "endOffset": 10}, {"referenceID": 5, "context": "GrConv [6] 76.", "startOffset": 7, "endOffset": 10}, {"referenceID": 5, "context": "4 RNN [6] 77.", "startOffset": 6, "endOffset": 9}, {"referenceID": 5, "context": "2 BRNN [6] 82.", "startOffset": 7, "endOffset": 10}, {"referenceID": 3, "context": "0 CNN [4] 81.", "startOffset": 6, "endOffset": 9}, {"referenceID": 5, "context": "6 AdaSent [6] 83.", "startOffset": 10, "endOffset": 13}, {"referenceID": 6, "context": "Paragraph-vector [7] 74.", "startOffset": 17, "endOffset": 20}, {"referenceID": 40, "context": "In particular, the NB-SVM of [41] is a fast and robust performer on these tasks.", "startOffset": 29, "endOffset": 33}, {"referenceID": 41, "context": "As a final experiment, we applied t-SNE [42] to skip-thought vectors extracted from TREC, SUBJ and SICK datasets and the visualizations are shown in Figure 2.", "startOffset": 40, "endOffset": 44}], "year": 2015, "abstractText": "We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoderdecoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.", "creator": "LaTeX with hyperref package"}}}