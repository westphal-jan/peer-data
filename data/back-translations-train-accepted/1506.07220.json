{"id": "1506.07220", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2015", "title": "Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks", "abstract": "Financial news contains useful information on public companies and the market. In this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market. Experimental results have shown that our proposed methods are simple but very effective, which can significantly improve the stock prediction accuracy on a standard financial database over the baseline system using only the historical price information.", "histories": [["v1", "Wed, 24 Jun 2015 01:43:11 GMT  (155kb,D)", "http://arxiv.org/abs/1506.07220v1", "5 pages, 2 figures, technical report"]], "COMMENTS": "5 pages, 2 figures, technical report", "reviews": [], "SUBJECTS": "cs.CE cs.AI cs.CL", "authors": ["yangtuo peng", "hui jiang"], "accepted": true, "id": "1506.07220"}, "pdf": {"name": "1506.07220.pdf", "metadata": {"source": "CRF", "title": "Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks", "authors": ["Yangtuo Peng", "Hui Jiang"], "emails": ["tim@cse.yorku.ca,", "hj@cse.yorku.ca,"], "sections": [{"heading": "1 Introduction", "text": "In recent years, deep neural networks (DNNs) have achieved tremendous success in many data models and predictive tasks ranging from speech recognition, computer vision to processing natural language. In this paper, we are interested in applying the powerful deep learning methods to financial data models to predict stock prices. Traditionally, neural networks have been used to model stock prices as time series for predictive purposes, as in (Kaastra and Boyd, 1991; Adya and Collopy, 1991; Chan et al., 2000; Skabar and Cloete, 2002; Zhu et al., 2008). In this earlier work, due to the limited training data and computing power available at the time, flat neural networks were typically used to model various types of features extracted from stock price records, such as historical prices, trading volumes, etc., to predict future stock returns and market returns."}, {"heading": "2 Our Approach", "text": "In this paper, we use deep neural networks (DNNs) as a predictive model that takes the characteristics extracted from both historical price information and online financial news as input to predict future stock movements (up or down)."}, {"heading": "2.1 Deep Neural Networks", "text": "The structure of the DNNs used in this essay is a conventional multi-layer perceptron with many hidden layers. An L-layer DNN consisting of hidden nonlinear layers and an output layer. The output layer is used to model the posterior probability of each output target. In this essay, we use the rectified linear activation function, i.e. f (x) = max (0, x), to calculate from activations to outputs in each hidden layer, which in turn are fed to the Thear Xiv: 150 6.07 220v 1 [cs.C E] June 24, 2015next layer as input. For the output layer, we use the Softmax function to calculate rear probabilities between two nodes that stand for replenishment and deposition."}, {"heading": "2.2 Features from historical price data", "text": "In this thesis, for each target value on a target date, we select the closing prices of the previous five days and link them to an input feature vector for DNNs: P = (pt \u2212 5, pt \u2212 4, pt \u2212 3, pt \u2212 2, pt \u2212 1), where t denotes the target date and pm denotes the closing price on the day m. Then, we normalize all prices based on the mean and variance calculated from all the closing prices of this share in the training set. In addition, we also calculate differences of the first and second order between the closing prices of the five days, which are appended as additional feature vectors. For example, we calculate the difference of the first order as follows: \u2206 P = (pt \u2212 4, pt \u2212 3, pt \u2212 2, pt \u2212 1) \u2212 (pt \u2212 5, pt \u2212 4, pt \u2212 3, pn \u2212 2). Similarly, we calculate the difference of the second order by calculating the difference between two adjacent values in each point Finally, we take function for each target value on a specific P-vector."}, {"heading": "2.3 Financial news features", "text": "In fact, the fact is that most of us are able to go in search of a solution that is capable, in that they are able to find a solution that is capable of finding a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution, that they are able to find a solution."}, {"heading": "2.4 Predicting Unseen Stocks via Correlation Graph", "text": "There are a large number of shares that are traded on the market. However, we can usually find only a fraction of them mentioned in the daily financial news. Therefore, for each date, we can predict the above method only the shares mentioned in the news. In this section, we propose a new method to predict more shares that are not mentioned directly in the financial news. Here, we propose to use a stock correlation curve shown in Figure 1 to predict these unseen shares. The stock correlation curve is an undirected graph in which each node represents a share and the arc between two nodes represents the correlation between these two shares. For example, if some shares are mentioned in the graph in the news on a given day, we first use the above method to predict these mentioned shares. Afterwards, the predictions are propagated along the arcs in the graph to generate predictions for these unseen shares (we construct the top 5.000 shares)."}, {"heading": "3 Dataset", "text": "The financial news data we used in this article is from Ding et al., 2014, which includes 106,521 articles from Reuters and 447,145 from Bloomberg. The news articles were published from October 2006 to December 2013. Historical securities data are from the database of the Centre for Research in Security Prices (CRSP) (as of 2012). We use the securities data only between 2006 and 2013 to compare the period of financial news. Based on the publication data of the samples, we have divided the data set into three groups: a training set (all samples between 2006-10-01 and 2012-12-31), a validation set (2013-01-01 and 2013-06-15) and a test set (2013-06-16 to 2013-12-31). The training set contains 65,646 samples, the validation set 10,941 samples and the test set 9,911 samples."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Stock Prediction using DNNs", "text": "In the first experiment, we used DNNs to predict the stock's price performance based on a variety of features, namely a polar prediction of next-day price movements (either a rise or a fall).Here, we trained a series of DNNs based on various combinations of feature vectors and found that the DNN structure of 4 hidden layers (with 1024 hidden nodes in each layer) yields the best performance in the validation group. We used the historical price feature alone to create the baseline, and added various features derived from financial news to top it. We measured final performance by calculating the error rate on the test set. As shown in Table 1, the features derived from financial news can significantly improve prediction accuracy, and we achieved the best performance (a 43.13% error rate) by using all the features described in Sections 2.2 and 2.3."}, {"heading": "4.2 Predict Unseen Stocks via Correlation", "text": "Here we group all results from DNNs based on the data of all samples of the test set. For each date, we create a vector x based on the DNN prediction results for all observed shares and zeros for all invisible shares, as described in Section 2.4. Subsequently, the vector is propagated through the correlation chart to generate another set of predictions about the stock movements. We can apply a threshold to the propagated vector to circumvent all predictions with low confidence. The remaining predictions can be used to predict some shares invisible on the test set. The prediction of all invisible shares is compared with the actual stock movements on the next day. Experimental results are shown in Figure 2, where the left Y axis denotes the prediction opposite accuracy and the right Y axis denotes the percentage of predictions of all 5000 shares per day under each cut threshold. For example, we can predict 110 per large share per use, with an additional threshold of 2.9% (with an accuracy of 354)."}, {"heading": "5 Conclusion", "text": "In this paper, we have proposed a simple way to use financial news to predict stock movements, based on the popular Word embedding and deep learning techniques. Our experiments have shown that financial news is very useful for stock forecasting, and the proposed methods can significantly improve the predictive accuracy of a standard financial dataset."}, {"heading": "Acknowledgments", "text": "This work was partially supported by an NSERC Engage grant from the Canadian federal government."}], "references": [{"title": "How effective are neural networks at forecasting and prediction? a review and evaluation", "author": ["Adya", "Collopy1991] Monica Adya", "Fred Collopy"], "venue": "Journal of Forecasting,", "citeRegEx": "Adya et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Adya et al\\.", "year": 1991}, {"title": "Identifying and following expert investors in stock microblogs", "author": ["Elad Dinur", "Ronen Feldman", "Moshe Fresko", "Guy Goldstein"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language", "citeRegEx": "Bar.Haim et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bar.Haim et al\\.", "year": 2011}, {"title": "Financial time series forecasting by neural network using conjugate gradient learning algorithm and multiple linear regression weight initialization", "author": ["Chan et al.2000] Man-Chung Chan", "Chi-Cheong Wong", "Chi-Chung Lam"], "venue": null, "citeRegEx": "Chan et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Chan et al\\.", "year": 2000}, {"title": "Using structured events to predict stock price movement: An empirical investigation", "author": ["Ding et al.2014] Xiao Ding", "Yue Zhang", "Ting Liu", "Junwen Duan"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Ding et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ding et al\\.", "year": 2014}, {"title": "Designing a neural network for forecasting financial and economic time series", "author": ["Kaastra", "Boyd1991] Iebeling Kaastra", "Milton Boyd"], "venue": null, "citeRegEx": "Kaastra et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Kaastra et al\\.", "year": 1991}, {"title": "Generating typed dependency parses from phrase structure parses", "author": ["Bill MacCartney", "Christopher D. Manning"], "venue": "In Proceedings LREC", "citeRegEx": "Marneffe et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Marneffe et al\\.", "year": 2006}, {"title": "Efficient estimation of word representations in vector space", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": "In Proceedings of Workshop at ICLR", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Exploiting topic based twitter sentiment for stock prediction", "author": ["Si et al.2013] Jianfeng Si", "Arjun Mukherjee", "Bing Liu", "Qing Li", "Huayi Li", "Xiaotie Deng"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Si et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Si et al\\.", "year": 2013}, {"title": "Exploiting social relations and sentiment for stock prediction", "author": ["Si et al.2014] Jianfeng Si", "Arjun Mukherjee", "Bing Liu", "Sinno Jialin Pan", "Qing Li", "Huayi Li"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Si et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Si et al\\.", "year": 2014}, {"title": "Neural networks, financial trading and the efficient markets hypothesis", "author": ["Skabar", "Cloete2002] Andrew Skabar", "Ian Cloete"], "venue": "In Proc. the Twenty-Fifth Australasian Computer Science Conference (ACSC2002),", "citeRegEx": "Skabar et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Skabar et al\\.", "year": 2002}, {"title": "Measuring praise and criticism: Inference of semantic orientation from association", "author": ["Turney", "Littman2003] Peter D. Turney", "Michael L. Littman"], "venue": "ACM Trans. Inf. Syst.,", "citeRegEx": "Turney et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2003}, {"title": "From frequency to meaning: Vector space models of semantics", "author": ["Turney", "Pantel2010] Peter D. Turney", "Patrick Pantel"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "Turney et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turney et al\\.", "year": 2010}, {"title": "Semantic frames to predict stock price movement", "author": ["Xie et al.2013] Boyi Xie", "Rebecca J. Passonneau", "Leon Wu", "Germ\u00e1n G. Creamer"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Xie et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Xie et al\\.", "year": 2013}, {"title": "Predicting stock index increments by neural networks: The role of trading volume under different horizons", "author": ["Zhu et al.2008] Xiaotian Zhu", "Hong Wang", "Li Xu", "Huaizu Li"], "venue": "Expert Systems with Applications,", "citeRegEx": "Zhu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "Traditionally neural networks have been used to model stock prices as time series for the forecasting purpose, such as in (Kaastra and Boyd, 1991; Adya and Collopy, 1991; Chan et al., 2000; Skabar and Cloete, 2002; Zhu et al., 2008).", "startOffset": 122, "endOffset": 232}, {"referenceID": 14, "context": "Traditionally neural networks have been used to model stock prices as time series for the forecasting purpose, such as in (Kaastra and Boyd, 1991; Adya and Collopy, 1991; Chan et al., 2000; Skabar and Cloete, 2002; Zhu et al., 2008).", "startOffset": 122, "endOffset": 232}, {"referenceID": 13, "context": "More recently, in the community of natural language processing, many methods have been proposed to explore additional information (mainly online text data) for stock forecasting, such as financial news (Xie et al., 2013; Ding et al., 2014), twitters sentiments (Si et al.", "startOffset": 202, "endOffset": 239}, {"referenceID": 3, "context": "More recently, in the community of natural language processing, many methods have been proposed to explore additional information (mainly online text data) for stock forecasting, such as financial news (Xie et al., 2013; Ding et al., 2014), twitters sentiments (Si et al.", "startOffset": 202, "endOffset": 239}, {"referenceID": 8, "context": ", 2014), twitters sentiments (Si et al., 2013; Si et al., 2014), microblogs (Bar-Haim et al.", "startOffset": 29, "endOffset": 63}, {"referenceID": 9, "context": ", 2014), twitters sentiments (Si et al., 2013; Si et al., 2014), microblogs (Bar-Haim et al.", "startOffset": 29, "endOffset": 63}, {"referenceID": 1, "context": ", 2014), microblogs (Bar-Haim et al., 2011).", "startOffset": 20, "endOffset": 43}, {"referenceID": 13, "context": "For example, (Xie et al., 2013) propose to use semantic frame parsers to generalize from sentences to scenarios to detect the (positive or negative) roles of specific companies, where support", "startOffset": 13, "endOffset": 31}, {"referenceID": 3, "context": "On the other hand, (Ding et al., 2014) propose to use various lexical and syntactic constraints to extract event features for stock forecasting, where they have investigate both lin-", "startOffset": 19, "endOffset": 38}, {"referenceID": 5, "context": "To do this, we use the Stanford parser (Marneffe et al., 2006) to detect whether the target stock is a subject of the keyword or not.", "startOffset": 39, "endOffset": 62}, {"referenceID": 3, "context": "The financial news data we used in this paper are provided by (Ding et al., 2014) which contains 106,521 articles from Reuters and 447,145 from Bloomberg.", "startOffset": 62, "endOffset": 81}], "year": 2015, "abstractText": "Financial news contains useful information on public companies and the market. In this paper we apply the popular word embedding methods and deep neural networks to leverage financial news to predict stock price movements in the market. Experimental results have shown that our proposed methods are simple but very effective, which can significantly improve the stock prediction accuracy on a standard financial database over the baseline system using only the historical price information.", "creator": "LaTeX with hyperref package"}}}