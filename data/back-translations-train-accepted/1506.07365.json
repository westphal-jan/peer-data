{"id": "1506.07365", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2015", "title": "Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images", "abstract": "We introduce Embed to Control (E2C), a method for model learning and control of non-linear dynamical systems from raw pixel images. E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear. Our model is derived directly from an optimal control formulation in latent space, supports long-term prediction of image sequences and exhibits strong performance on a variety of complex control problems.", "histories": [["v1", "Wed, 24 Jun 2015 13:48:51 GMT  (4350kb,D)", "https://arxiv.org/abs/1506.07365v1", null], ["v2", "Thu, 25 Jun 2015 21:08:02 GMT  (4351kb,D)", "http://arxiv.org/abs/1506.07365v2", null], ["v3", "Fri, 20 Nov 2015 14:49:18 GMT  (4346kb,D)", "http://arxiv.org/abs/1506.07365v3", "Final NIPS version"]], "reviews": [], "SUBJECTS": "cs.LG cs.CV stat.ML", "authors": ["manuel watter", "jost tobias springenberg", "joschka boedecker", "martin a riedmiller"], "accepted": true, "id": "1506.07365"}, "pdf": {"name": "1506.07365.pdf", "metadata": {"source": "CRF", "title": "Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images", "authors": ["Manuel Watter", "Jost Tobias Springenberg", "Joschka Boedecker", "Martin Riedmiller"], "emails": ["watterm@cs.uni-freiburg.de", "springj@cs.uni-freiburg.de", "jboedeck@cs.uni-freiburg.de", "riedmiller@google.com"], "sections": [{"heading": "1 Introduction", "text": "Control of nonlinear dynamic systems with continuous states and spaces of action is one of the key problems in robotics and, more broadly, in learning autonomous actors. A prominent class of algorithms aimed at solving this problem are model-based (stochastic) control algorithms such as the iLQG control [1, 2], which approach the general nonlinear control problem through local linearization. Combined with retrograde horizontal control [3], and machine learning methods, such algorithms are powerful tools for solving complex control problems [3, 4, 5] but they either rely on a known system model or require the design of real states to succeed, we need algorithms to learn algorithms capable of developing complex control mechanisms."}, {"heading": "2 The Embed to Control (E2C) model", "text": "We briefly discuss the problem of SOC for dynamic systems, introduce an approximately locally optimal control in the latent space and conclude with the derivation of our model."}, {"heading": "2.1 Problem Formulation", "text": "We consider the control of unknown dynamic systems of the form st + 1 = f (st, ut) + \u0442, \u0445 N (0, ut), (1), where t denotes the time steps, st-Rns denotes the system state, ut-Rnu denotes the applied control, ut-Rnu denotes the system noise. The function f (st, ut) is an arbitrary, smooth system dynamics. We refer to equation (1) with the notation P (st + 1 | st, ut), which we assume to be a multivariate normal distribution N (f (st, ut). We also assume that we only have access to visual representations xt-Rnx of the state st. This limitation requires the solution of a common state and control problem. For simplicity, we assume that xt is a fully observed representation of st (st, ut), but loosen this assumption later. Our goal is then to include a low-dimensional state problem that can be introduced into the optimum state model."}, {"heading": "2.2 Stochastic locally optimal control in latent spaces", "text": "Let zt. Rnz is the derived latent state from image xt of state st and f lat (zt, ut) the transition dynamics in latent space, i.e., zt + 1 = f lat (zt, ut). Thus f lat models the changes that occur in zt when the control ut is applied to the underlying system as latent space analogous to f (st, ut). Suppose f lat is known, optimal control for a path of length T in the dynamic system can be derived by minimizing the function J (z1: T, u1: T), which yields the expected future costs if the following (z1: T, u1: T): J (z1: T) = Ez [cT, uT) + T \u2212 1: nnamizing t0 c (zt, ut)], (3) where c (zt, ut) are instantaneous costs."}, {"heading": "2.3 A locally linear latent state space model for dynamical systems", "text": "Starting with the SOC formulation, we now turn to the problem of learning an appropriate latent representation, which we then combine directly with the SOC. (iii) There must be sufficient information about the next latent state, which must be locally linearizable, to enable an accurate prediction of the next latent state. (ii) It must be possible to accurately predict the next latent state. (iii) There must be a certain representation of the properties (ii) and (iii) in particular a detection of possibly highly non-linear changes in latent representation due to the transformations of the observed scene caused by control commands. (Crucially, these are particularly difficult to model and subsequently linearize."}, {"heading": "2.4 Learning via stochastic gradient variational Bayes", "text": "For the training of the model we use a dataset D = {(x1, u1, x2),.., (xT \u2212 1, uT \u2212 1, xT), which contains observation stuples with corresponding controls obtained from interactions with the dynamic system. From this dataset we learn the parameters of inference, transition and generative model by minimizing a limit of variation on the true data, negative log probability \u2212 logP (xt, ut, xt + 1) plus an additional limitation of latent representation. The complete loss function 2 becomes asL (D) = [xt, ut, xt + 1)."}, {"heading": "3 Experimental Results", "text": "We evaluate our model based on four visual tasks: an agent in a plane with obstacles, a visual version of the classic pendulum swing, balancing a cart pole system and controlling a three-bar arm with larger images. These are described in detail below."}, {"heading": "3.1 Experimental Setup", "text": "We look at two different network types for our model: standard fully connected neural networks with up to three levels that we all have at our disposal. (That is, we work well at controlling images in terms of the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the way they're related to the same the way they're related to the way they're related to the way they're related to the way they're related to the same"}, {"heading": "3.2 Control in a planar system", "text": "The agent in the planar system can move in a limited two-dimensional plane by selecting a continuous offset in x- and y-direction.The high-dimensional representation of a state is a 40 x 40 black-and-white image. Blocked by six circular obstacles, the task is to move to the bottom right of the image, starting from a random x-position at the top of the image. The encodings of obstacles are determined prior to planning, and an additional square cost concept disadvantages proximity to them. A representation of the observations on which the control is carried out - along with their corresponding state values and embedding in the latent space - is shown in Figure 2. The figure also clearly shows a fundamental advantage that the E2C model has over its competitors: While the separately trained car encoders provide aesthetically pleasing images, the models show that the underlying structure of the state space is not detected, which makes the dynamics-based estimation of the space and the costs said in the space more difficult."}, {"heading": "3.3 Learning swing-up for an inverted pendulum", "text": "Next, we turn to the task of controlling the classical inverted pendulum system [15] using images. We create representations of the state by reproducing a fixed longitudinal line from the center of the image at an angle corresponding to the pendulum position. The aim of this task is to swing and balance an uncontrolled pendulum from a resting position (pendulum hanging down). Exemplary observations and reconstructions for this system are given in Figure 3 (d). In the visual inverted pendulum task, our algorithm faces two additional difficulties: The observed space is not Markov, as the angular velocity cannot be derived from a single image, and secondly, discretization errors due to the representation of pendulum angles as small 48 x 48 pixel images make exact control difficult. In order to restore the Markov property, we stack two images (as input channels) and thus consider a single-stage model. Figure 3 shows the topology of the single latency of this system, as well as the dynamics of our single system, in one case."}, {"heading": "3.4 Balancing a cart-pole and controlling a simulated robot arm", "text": "Finally, we consider the control of two more complex dynamic systems of images with a six-layer convolutionary inference system and a six-layer generative network curved upwards, resulting in a 12-layer, deep path from input to reconstruction. Specifically, we control a visual version of the classic cartpole system [16] consisting of a history of two 80 x 80 pixel images and a three-layer, planar robotic arm based on a history of two 128 x 128 pixel images. Latent space should be eight-dimensional in both experiments. As in previous experiments, the real dimensionality of the cart pole is four and is controlled by action, while for the arm the real state can be described in six dimensions (hinged angles and velocities) and controlled using a three-dimensional action vector corresponding to motor torques. As in previous experiments, the E2C model seems to have no problem finding a linear insertion system that can only be performed locally by means of the 7th images, which can only be performed in the 4th ones)."}, {"heading": "4 Comparison to recent work", "text": "In the context of representative control learning (cf. Bo \ufffd hmer et al. [17] for an overview), deep auto encoders (without taking into account state transitions) have already been used previously, e.g. by Lange and Riedmiller [18]. A more direct path to control based on image flows is increasing in recent work on (model-free) deep end-to-end Q learning for Atari games by Mnih et al. [19], as well as nuclear-based [20] and deep political learning for robot control [21]. Close to our approach is a recent essay by Wahlstro et al. [22], in which auto encoders are used to extract latent representation for control from images learning a non-linear model of forward dynamics. Their model is jointly trained and thus resembles the non-linear E2C variant of It. In contrast to our general model, its formulation does not require long-term PCs and does not anticipate that they are in the long term."}, {"heading": "5 Conclusion", "text": "We introduced Embed to Control (E2C), a system for stochastic optimal control of high-dimensional image streams. Key to this approach is the extraction of a latent dynamic model, which must necessarily be locally linear in its state transitions. An evaluation of four demanding benchmarks showed that E2C can find embedding on which the control can be carried out with ease and achieves a performance close to that achieved by optimal control of the real system model."}, {"heading": "Acknowledgments", "text": "We would like to thank A. Radford, L. Metz and T. DeWolf for the exchange of code and A. Dosovitskiy for useful discussions. This work was partly funded by a DFG grant within the Priority Programme \"Autonomous Learning\" (SPP1597) and the Excellence Cluster BrainLinks-BrainTools (grant number EXC 1086). M. Watter is supported by the Baden-W\u00fcrttemberg State Graduate Funding Programme."}, {"heading": "A Supplementary to the E2C description", "text": "Thus, it is not possible to use such a matrix to calculate the KL divergence penalty of Equation (11) (which makes it difficult to reverse the results). We started our experiments with a complete matrix (and only the approximation of all KL divergence concepts), but quickly found that a precedence order pertubation of the identity matrix could instead be used without loss of power in any of our benchmarks. To achieve the opposite, the resulting networks have fewer parameters and are therefore easier to train. Here, we give the derivation of this process and how the KL divergence of Equation (11) can be calculated."}, {"heading": "B Supplementary to the experimental setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1 Up-convolution", "text": "While these networks help us overcome the problem of large input dimensions (i.e. 2 x 128 x 128 pixel images in the three-link arm task), we still need to generate images in full resolution with the decoder network. To generate high-dimensional images, fully connected neural networks are simply not an option. We have therefore decided to use up-revolutionary networks, which have recently proven to be powerful models for image generation [8, 9, 33]. To build these models, we essentially \"mirror\" the revolutionary architecture used for the encoder. More specifically, for each 5 x 5 convolution followed by 2 x 2 max pooling steps in the encoder network, we perform a 2 x 2 x 2 up-sampling and 5 x 5 convolution steps in the decoder network. The full network architecture is vlateness, followed by a 2 x 2 maxpooling steps in the encoder network, introduced."}, {"heading": "B.3 Evaluation criteria", "text": "For comparing the performance of all variants of E2C and baselines, the following criteria are important: \u2022 Autoencoding. The ability to reconstruct the given observations is the basic necessity for a functioning model. The reconstruction costs drive a model to identify individual states from its observations. \u2022 Decoding the next state. In order for planning to be possible at all, the decoder must be able to generate the correct images from transitions performed by the dynamic model. If this is not the case, we know that the latent states of the coding and the transition model do not correspond, which prevents any planning. \u2022 Optimisation of latent traction costs. The action sequences to achieve a specified target are entirely determined by locally linearized dynamics in latent space. Therefore, minimising the traction costs in latent space x is a necessity for successful control. \u2022 Optimisation of real traction costs."}, {"heading": "B.4 The three-link robot arm", "text": "The robotic arm we used in the last experiment in the main work was simulated using dynamics packaged in Python by MapleSim http: / / www.maplesoft.com / products / maplesim / simulator and visualized for the production of E2C using PyGame. We simulated a fairly standard robotic arm with three linkages, the length of the linkages was set to 2, 1.2 and 0.7 (units were set to meters), and the masses of the corresponding linkages were all set at 10kg. B.5 Evaluation of the True System Model.5 To compare the effectiveness of different models in combination with optimal control algorithms, we always gave the costs in latent space (as used by the optimal control algorithm) as well as the \"real\" traction costs. To calculate these real costs, we evaluated the same cost functions as in latent space (square costs based on the deviation from a specific control algorithm) and the \"real\" cost \"of using the system during the matrix implementation, but the cost was calculated for each of a different system and for the application."}, {"heading": "B.6 Neural Network training", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.6.1 Experimental Setup", "text": "All data sets were created in advance as D = {(x1, u1, x2),.., (xT \u2212 1, uT \u2212 1, xT) for training, validation, and test division. While the E2C models were trained on D, those that do not contain transition information (i.e. AE, UAE), on imagesDimages = {x1,.., xT}, and our E2C models were trained on the full D. to learn dynamics predictions for the picture-only encoders, the slowness of VAE on the pairs of the image subset Dpairs = {(x1, x2),., (xT \u2212 1, xT)}, and our E2C models were trained on the full D. To learn dynamic predictions for the image-only auto encoders, we extracted the latent representations and combined them with the actions of D into the dynamics = (z1, u1, z2)."}, {"heading": "Plane", "text": "\u2022 Input: 402 image dimensions, 2 action dimensions \u2022 Latent spatial dimension: 2 \u2022 Encoder: 150 ReLU - 150 ReLU - 150 ReLU - 4 linear (2 for AE) \u2022 Decoder: 200 ReLU - 200 ReLU - 1600 linear (sigmoid for AE) \u2022 Dynamics: 100 ReLU - 100 ReLU + output layer (except Global E2C) - AE, UAE, VAE with slowness, non-linear E2C: 2 Linear - E2C: 8 linear (2 \u00b7 2 for At, 2 \u00b7 1 for Bt, 2 for ot), \u03bb = 0.25 \u2022 Adam: \u03b1 = 10 \u2212 4, \u03b22 = 0.1 \u2022 Rating costs: Rz = 0.1 \u00b7 I, Ru = I, Ro = I, Ro = LU- LU (IPendulum Reversal: 2 \u00b7 1 for Bt, 2 \u00b7 482 image dimensions, 1 action Udimension U02 \u2022 U800 - Udimension for U800 \u00b7 4800: 1 space dimension: 1 - LE: 1"}, {"heading": "Cart-Pole balancing", "text": "\u2022 Input: 2 \u00b7 802 image dimensions, 1 action dimension \u2022 Latent space dimension: 8 \u2022 Encoder: 32 x 5 x 5 ReLU - 32 x 5 x 5 ReLU - 32 x 5 ReLU - 512 ReLU - 512 ReLU \u2022 Decoder: 512 ReLU - 512 ReLU - 2 x 2 up-sampling - 32 x 5 x 5 ReLU - 2 x 2 up-sampling - 32 x 5 x 5 ReLU - 2 x 2 up-sampling - 32 x 5 x 5 conv. ReLU \u2022 Dynamic range: 200 ReLU - 200 ReLU + 32 Linear (2 \u00b7 8 for At = (I + vtrTt), 8 \u00b7 1 for Bt, 8for bt), \u03bb = 1 \u2022 Adam: \u03b1 = 10 \u2212 4, \u03b22 = 0.1 \u2022 Rating costs: Rz = I, Ru = I"}, {"heading": "Three-link arm", "text": "\u2022 Input: 2 \u00b7 1282 screen dimensions, 3 action dimensions \u2022 Latent space dimensions: 8 \u2022 Encoder: 64 x 5 x 5 conv. ReLU - 2 x 2 max-pooling - 32 x 5 conv. ReLU - 2 x 2max-pooling - 32 x 5 conv. ReLU - 2 x 2 max-pooling - 512 ReLU - 512 ReLU \u2022 Decoder: 512 ReLU - 512 ReLU - 2 x 2 up-sampling - 32 x 5 x 5 ReLU - 2 x 2 up-sampling - 32 x 5 x 5 ReLU - 2 x 2 up-sampling - 64 x 5 x 5 conv. ReLU \u2022 Dynamic range: 200 ReLU - 200 ReLU + 48 linear (2 \u00b7 8 for At = (I + vtrTt, 8for bt), 8 \u00b7 3 for Bt, 8 x 5 x 5 conv."}, {"heading": "C Supplementary evaluations", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C.1 Trajectories for plane and pendulum", "text": "In order to qualitatively measure the predictive accuracy, the initial state of a trajectory is encoded and the actions applied to the latent representation. After each transition, the predicted latent position is decoded and visualized. In this way, multi-stage predictions for the planar system in Figure 5 and for the inverted pendulum in Figure 6 and 7.C.2 Inverted pendulum latent spaceEncoding the pendulum pictures into a 3-dimensional latent space enables a visual comparison in Figure 8."}, {"heading": "C.3 Trajectories for cart-pole and three-link arm", "text": "Finally, similar to the images in Section C.1, Figure 9 shows multi-stage predictions for the cartel pole system. We present important cases: (1) a long-term prediction where the cartel pole stands still (essentially the unstable fixed point of the underlying dynamics); (2) the cart pole moving to the right, changing the direction of the poles, angular velocity (middle column); (3) and the pole moving farthest to the right.The long-term predictions of the E2C model are all of high quality. Note that the predictions for uncontrolled dynamics show a slight presetting of the pole moving to the right (an effect we have consistently seen in trained models for the cartel pole).We attribute this problem to the fact that discretization errors in the image reproduction process of the pole angle make it difficult to accurately predict small speeds in the armature."}, {"heading": "No Control Moving leftMoving right", "text": "C.6 Comparison of cart pole and robotic arm trajectory optimizers In order to compare how well AICO handles the covariance matrices estimated in latent space, we performed an additional experiment at the cart pole and the three-part robotic arm task and compared them with iLQR. We performed model predictive control with the locally linear E2C model, starting with 10 different start states each. The remaining settings are as described in Section C.5. As described in Table 3, both methods performed roughly the same for these tasks, suggesting that the covariance matrices estimated by our model do not \"violate\" planning, but their consideration does not improve performance either."}], "references": [{"title": "Differential dynamic programming", "author": ["D. Jacobson", "D. Mayne"], "venue": "American Elsevier,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1970}, {"title": "A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems", "author": ["E. Todorov", "W. Li"], "venue": "ACC. IEEE,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2005}, {"title": "Receding horizon differential dynamic programming", "author": ["Y. Tassa", "T. Erez", "W.D. Smart"], "venue": "Proc. of NIPS,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Probabilistic differential dynamic programming", "author": ["Y. Pan", "E. Theodorou"], "venue": "Proc. of NIPS,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Variational policy search via trajectory optimization", "author": ["S. Levine", "V. Koltun"], "venue": "Proc. of NIPS,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2013}, {"title": "Auto-encoding variational bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "Proc. of ICLR,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "Proc. of ICML,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Deconvolutional networks", "author": ["M.D. Zeiler", "D. Krishnan", "G.W. Taylor", "R. Fergus"], "venue": "CVPR,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning to generate chairs with convolutional neural networks", "author": ["A. Dosovitskiy", "J.T. Springenberg", "T. Brox"], "venue": "Proc. of CVPR,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Optimal Control and Estimation", "author": ["R.F. Stengel"], "venue": "Dover Publications,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 1994}, {"title": "Iterative Linear Quadratic Regulator Design for Nonlinear Biological Movement Systems", "author": ["W. Li", "E. Todorov"], "venue": "Proc. of ICINCO,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2004}, {"title": "Robot Trajectory Optimization using Approximate Inference", "author": ["M. Toussaint"], "venue": "Proc. of ICML,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "An introduction to variational methods for graphical models", "author": ["M.I. Jordan", "Z. Ghahramani", "T.S. Jaakkola", "L.K. Saul"], "venue": "Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1999}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "Proc. of ICLR,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "An approach to fuzzy control of nonlinear systems; stability and design issues", "author": ["H. Wang", "K. Tanaka", "M. Griffin"], "venue": "IEEE Trans. on Fuzzy Systems, 4(1),", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1996}, {"title": "Introduction to Reinforcement Learning", "author": ["R.S. Sutton", "A.G. Barto"], "venue": "MIT Press, Cambridge, MA, USA, 1st edition,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1998}, {"title": "Autonomous learning of state representations for control", "author": ["W. B\u00f6hmer", "J.T. Springenberg", "J. Boedecker", "M. Riedmiller", "K. Obermayer"], "venue": "KI - K\u00fcnstliche Intelligenz,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep auto-encoder neural networks in reinforcement learning", "author": ["S. Lange", "M. Riedmiller"], "venue": "Proc. of IJCNN,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2010}, {"title": "Human-level control through deep reinforcement learning", "author": ["V. Mnih", "K. Kavukcuoglu", "D. Silver", "A.A. Rusu", "J. Veness", "M.G. Bellemare", "A. Graves", "M. Riedmiller", "A.K. Fidjeland", "G. Ostrovski", "S. Petersen", "C. Beattie", "A. Sadik", "I. Antonoglou", "H. King", "D. Kumaran", "D. Wierstra", "S. Legg", "D. Hassabis"], "venue": "Nature, 518(7540), 02", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning of non-parametric control policies with highdimensional state features", "author": ["H. van Hoof", "J. Peters", "G. Neumann"], "venue": "In Proc. of AISTATS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "End-to-end training of deep visuomotor policies", "author": ["S. Levine", "C. Finn", "T. Darrell", "P. Abbeel"], "venue": "CoRR, abs/1504.00702,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "From pixels to torques: Policy learning with deep dynamical models", "author": ["N. Wahlstr\u00f6m", "T.B. Sch\u00f6n", "M.P. Deisenroth"], "venue": "CoRR, abs/1502.02251,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2015}, {"title": "DRAW: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D. Rezende", "D. Wierstra"], "venue": "Proc. of ICML,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning stochastic recurrent networks", "author": ["J. Bayer", "C. Osendorfer"], "venue": "NIPS 2014 Workshop on Advances in Variational Inference,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Transforming auto-encoders", "author": ["G. Hinton", "A. Krizhevsky", "S. Wang"], "venue": "Proc. of ICANN,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "Nice: Non-linear independent components estimation", "author": ["L. Dinh", "D. Krueger", "Y. Bengio"], "venue": "CoRR, abs/1410.8516,", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2015}, {"title": "Transformation properties of learned visual representations", "author": ["T. Cohen", "M. Welling"], "venue": "ICLR,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Dynamical binary latent variable models for 3d human pose tracking", "author": ["G.W. Taylor", "L. Sigal", "D.J. Fleet", "G.E. Hinton"], "venue": "Proc. of CVPR,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning to relate images", "author": ["R. Memisevic"], "venue": "IEEE Trans. on PAMI, 35(8):1829\u20131846,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning nonlinear dynamic models", "author": ["J. Langford", "R. Salakhutdinov", "T. Zhang"], "venue": "ICML,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2009}, {"title": "Bayesian Forecasting and Dynamic Models (Springer Series in Statistics)", "author": ["M. West", "J. Harrison"], "venue": "Springer-Verlag, February", "citeRegEx": "31", "shortCiteRegEx": null, "year": 1997}, {"title": "Latent Kullback Leibler control for continuous-state systems using probabilistic graphical models", "author": ["T. Matsubara", "V. G\u00f3mez", "H.J. Kappen"], "venue": "UAI,", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep convolutional inverse graphics network", "author": ["T.D. Kulkarni", "W. Whitney", "P. Kohli", "J.B. Tenenbaum"], "venue": "CoRR, abs/1503.03167,", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2015}, {"title": "Image super-resolution with fast approximate convolutional sparse coding", "author": ["C. Osendorfer", "H. Soyer", "P. van der Smagt"], "venue": "In Proc. of ICONIP, Lecture Notes in Computer Science. Springer International Publishing,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2014}, {"title": "State representation learning in robotics: Using prior knowledge about physical interaction", "author": ["R. Jonschkowski", "O. Brock"], "venue": "Proc. of RSS,", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2014}, {"title": "Reinforcement learning on slow features of high-dimensional input streams", "author": ["R. Legenstein", "N. Wilbert", "L. Wiskott"], "venue": "PLoS Computational Biology,", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2010}, {"title": "Unsupervised learning of visual invariance with temporal coherence", "author": ["W. Zou", "A. Ng", "K. Yu"], "venue": "NIPS*2011 Workshop on Deep Learning and Unsupervised Feature Learning,", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2011}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["A.M. Saxe", "J.L. McClelland", "S. Ganguli"], "venue": "Proc. of ICLR,", "citeRegEx": "38", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep sparse rectifier neural networks", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "AISTATS. Journal of Machine Learning Research - Workshop and Conference Proceedings,", "citeRegEx": "39", "shortCiteRegEx": null, "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "A prominent class of algorithms that aim to solve this problem are model-based locally optimal (stochastic) control algorithms such as iLQG control [1, 2], which approximate the general nonlinear control problem via local linearization.", "startOffset": 148, "endOffset": 154}, {"referenceID": 1, "context": "A prominent class of algorithms that aim to solve this problem are model-based locally optimal (stochastic) control algorithms such as iLQG control [1, 2], which approximate the general nonlinear control problem via local linearization.", "startOffset": 148, "endOffset": 154}, {"referenceID": 2, "context": "When combined with receding horizon control [3], and machine learning methods for learning approximate system models, such algorithms are powerful tools for solving complicated control problems [3, 4, 5]; however, they either rely on a known system model or require the design of relatively low-dimensional state representations.", "startOffset": 44, "endOffset": 47}, {"referenceID": 2, "context": "When combined with receding horizon control [3], and machine learning methods for learning approximate system models, such algorithms are powerful tools for solving complicated control problems [3, 4, 5]; however, they either rely on a known system model or require the design of relatively low-dimensional state representations.", "startOffset": 194, "endOffset": 203}, {"referenceID": 3, "context": "When combined with receding horizon control [3], and machine learning methods for learning approximate system models, such algorithms are powerful tools for solving complicated control problems [3, 4, 5]; however, they either rely on a known system model or require the design of relatively low-dimensional state representations.", "startOffset": 194, "endOffset": 203}, {"referenceID": 4, "context": "When combined with receding horizon control [3], and machine learning methods for learning approximate system models, such algorithms are powerful tools for solving complicated control problems [3, 4, 5]; however, they either rely on a known system model or require the design of relatively low-dimensional state representations.", "startOffset": 194, "endOffset": 203}, {"referenceID": 5, "context": "To learn such a latent space we propose a new deep generative model belonging to the class of variational autoencoders [6, 7] that is derived from an iLQG formulation in latent space.", "startOffset": 119, "endOffset": 125}, {"referenceID": 6, "context": "To learn such a latent space we propose a new deep generative model belonging to the class of variational autoencoders [6, 7] that is derived from an iLQG formulation in latent space.", "startOffset": 119, "endOffset": 125}, {"referenceID": 7, "context": "As an aside, we also validate that deep up-convolutional networks [8, 9] are powerful generative models for large images.", "startOffset": 66, "endOffset": 72}, {"referenceID": 8, "context": "As an aside, we also validate that deep up-convolutional networks [8, 9] are powerful generative models for large images.", "startOffset": 66, "endOffset": 72}, {"referenceID": 9, "context": ", st can be inferred from zt alone, and f lat is differentiable, the cost-minimizing controls can be computed from J(z1:T ,u1:T ) via SOC algorithms [10].", "startOffset": 149, "endOffset": 153}, {"referenceID": 10, "context": "In combination with Equation (4) this gives us a local linear-quadratic-Gaussian formulation at each time step t which can be solved by SOC algorithms such as iterative linear-quadratic regulation (iLQR) [11] or approximate inference control (AICO) [12].", "startOffset": 204, "endOffset": 208}, {"referenceID": 11, "context": "In combination with Equation (4) this gives us a local linear-quadratic-Gaussian formulation at each time step t which can be solved by SOC algorithms such as iterative linear-quadratic regulation (iLQR) [11] or approximate inference control (AICO) [12].", "startOffset": 249, "endOffset": 253}, {"referenceID": 12, "context": "[13] for an overview) we resort to sampling zt from an approximate posterior distribution Q\u03c6(Z|X) with parameters \u03c6.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "It additionally comes with the benefit that we can use the reparameterization trick [6, 7] to backpropagate gradients of a loss function based on samples through the latent distribution.", "startOffset": 84, "endOffset": 90}, {"referenceID": 6, "context": "It additionally comes with the benefit that we can use the reparameterization trick [6, 7] to backpropagate gradients of a loss function based on samples through the latent distribution.", "startOffset": 84, "endOffset": 90}, {"referenceID": 7, "context": "We consider two different network types for our model: Standard fully connected neural networks with up to three layers, which work well for moderately sized images, are used for the planar and swing-up experiments; A deep convolutional network for the encoder in combination with an up-convolutional network as the decoder which, in accordance with recent findings from the literature [8, 9], we found to be an adequate model for larger images.", "startOffset": 386, "endOffset": 392}, {"referenceID": 8, "context": "We consider two different network types for our model: Standard fully connected neural networks with up to three layers, which work well for moderately sized images, are used for the planar and swing-up experiments; A deep convolutional network for the encoder in combination with an up-convolutional network as the decoder which, in accordance with recent findings from the literature [8, 9], we found to be an adequate model for larger images.", "startOffset": 386, "endOffset": 392}, {"referenceID": 13, "context": "Training was performed using Adam [14] throughout all experiments.", "startOffset": 34, "endOffset": 38}, {"referenceID": 10, "context": "To perform optimal control in the latent space of different models, we employ two trajectory optimization algorithms: iterative linear quadratic regulation (iLQR) [11] (for the plane and inverted pendulum) and approximate inference control (AICO) [12] (all other experiments).", "startOffset": 163, "endOffset": 167}, {"referenceID": 11, "context": "To perform optimal control in the latent space of different models, we employ two trajectory optimization algorithms: iterative linear quadratic regulation (iLQR) [11] (for the plane and inverted pendulum) and approximate inference control (AICO) [12] (all other experiments).", "startOffset": 247, "endOffset": 251}, {"referenceID": 2, "context": "Except for the experiments on the planar system, control was performed in a model predictive control fashion using the receding horizon scheme introduced in [3].", "startOffset": 157, "endOffset": 160}, {"referenceID": 14, "context": "We next turn to the task of controlling the classical inverted pendulum system [15] from images.", "startOffset": 79, "endOffset": 83}, {"referenceID": 15, "context": "Specifically, we control a visual version of the classical cartpole system [16] from a history of two 80\u00d7 80 pixel images as well as a three-link planar robot arm based on a history of two 128 \u00d7 128 pixel images.", "startOffset": 75, "endOffset": 79}, {"referenceID": 16, "context": "[17] for a review), deep autoencoders (ignoring state transitions) similar to our baseline models have been applied previously, e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "by Lange and Riedmiller [18].", "startOffset": 24, "endOffset": 28}, {"referenceID": 18, "context": "[19], as well as kernel based [20] and deep policy learning for robot control [21].", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[19], as well as kernel based [20] and deep policy learning for robot control [21].", "startOffset": 30, "endOffset": 34}, {"referenceID": 20, "context": "[19], as well as kernel based [20] and deep policy learning for robot control [21].", "startOffset": 78, "endOffset": 82}, {"referenceID": 21, "context": "[22], where autoencoders are used to extract a latent representation for control from images, on which a non-linear model of the forward dynamics is learned.", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "As stated above, our system belongs to the family of VAEs and is generally similar to recent work such as Kingma and Welling [6], Rezende et al.", "startOffset": 125, "endOffset": 128}, {"referenceID": 6, "context": "[7], Gregor et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 22, "context": "[23], Bayer and Osendorfer [24].", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[23], Bayer and Osendorfer [24].", "startOffset": 27, "endOffset": 31}, {"referenceID": 24, "context": "This includes the development of transforming auto-encoders [25] and recent probabilistic models for images [26, 27].", "startOffset": 60, "endOffset": 64}, {"referenceID": 25, "context": "This includes the development of transforming auto-encoders [25] and recent probabilistic models for images [26, 27].", "startOffset": 108, "endOffset": 116}, {"referenceID": 26, "context": "This includes the development of transforming auto-encoders [25] and recent probabilistic models for images [26, 27].", "startOffset": 108, "endOffset": 116}, {"referenceID": 27, "context": "Second, learning relations between pairs of images \u2013 although without control \u2013 has received considerable attention from the community during the last years [28, 29].", "startOffset": 157, "endOffset": 165}, {"referenceID": 28, "context": "Second, learning relations between pairs of images \u2013 although without control \u2013 has received considerable attention from the community during the last years [28, 29].", "startOffset": 157, "endOffset": 165}, {"referenceID": 29, "context": "[30] for a discussion) through, e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": ", hidden Markov models and Kalman filters [31, 32].", "startOffset": 42, "endOffset": 50}, {"referenceID": 31, "context": ", hidden Markov models and Kalman filters [31, 32].", "startOffset": 42, "endOffset": 50}, {"referenceID": 0, "context": "References [1] D.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] E.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] A.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] V.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] N.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] K.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] L.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] G.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[30] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[31] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 31, "context": "[32] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 33, "context": "[34] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "[35] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 35, "context": "[36] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "[37] W.", "startOffset": 0, "endOffset": 4}, {"referenceID": 37, "context": "[38] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 38, "context": "[39] X.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "We thus decided to use up-convolutional networks, which were recently show to be powerful models for image generation [8, 9, 33].", "startOffset": 118, "endOffset": 128}, {"referenceID": 8, "context": "We thus decided to use up-convolutional networks, which were recently show to be powerful models for image generation [8, 9, 33].", "startOffset": 118, "endOffset": 128}, {"referenceID": 32, "context": "We thus decided to use up-convolutional networks, which were recently show to be powerful models for image generation [8, 9, 33].", "startOffset": 118, "endOffset": 128}, {"referenceID": 8, "context": "[9].", "startOffset": 0, "endOffset": 3}, {"referenceID": 33, "context": "The upsampling strategy we use is simple \u201cperforated\u201d upsampling as described in [34].", "startOffset": 81, "endOffset": 85}, {"referenceID": 34, "context": "Enforcing temporal slowness during learning has previously been found to be a good proxy for learning representations in reinforcement learning [35, 36] and representation learning from videos [37].", "startOffset": 144, "endOffset": 152}, {"referenceID": 35, "context": "Enforcing temporal slowness during learning has previously been found to be a good proxy for learning representations in reinforcement learning [35, 36] and representation learning from videos [37].", "startOffset": 144, "endOffset": 152}, {"referenceID": 36, "context": "Enforcing temporal slowness during learning has previously been found to be a good proxy for learning representations in reinforcement learning [35, 36] and representation learning from videos [37].", "startOffset": 193, "endOffset": 197}, {"referenceID": 37, "context": "2 Implementation details We used orthogonal weight initialization for every layer [38].", "startOffset": 82, "endOffset": 86}, {"referenceID": 13, "context": "As described in the main paper, Adam [14] was used as the learning rule for all networks.", "startOffset": 37, "endOffset": 41}, {"referenceID": 38, "context": "The architectures used for our experiments were as follows (where ReLU stands for rectified linear units [39] and conv.", "startOffset": 105, "endOffset": 109}], "year": 2015, "abstractText": "We introduce Embed to Control (E2C), a method for model learning and control of non-linear dynamical systems from raw pixel images. E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear. Our model is derived directly from an optimal control formulation in latent space, supports long-term prediction of image sequences and exhibits strong performance on a variety of complex control problems.", "creator": "LaTeX with hyperref package"}}}