{"id": "1506.07452", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2015", "title": "Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation", "abstract": "Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3D videos to segment them. They have a fixed input size and typically perceive only small local contexts of the pixels to be classified as foreground or background. In contrast, Multi-Dimensional Recurrent NNs (MD-RNNs) can perceive the entire spatio-temporal context of each pixel in a few sweeps through all pixels, especially when the RNN is a Long Short-Term Memory (LSTM). Despite these theoretical advantages, however, unlike CNNs, previous MD-LSTM variants were hard to parallelize on GPUs. Here we re-arrange the traditional cuboid order of computations in MD-LSTM in pyramidal fashion. The resulting PyraMiD-LSTM is easy to parallelize, especially for 3D data such as stacks of brain slice images. PyraMiD-LSTM achieved best known pixel-wise brain image segmentation results on MRBrainS13 (and competitive results on EM-ISBI12).", "histories": [["v1", "Wed, 24 Jun 2015 16:26:51 GMT  (640kb,D)", "http://arxiv.org/abs/1506.07452v1", "Marijn F. Stollenga and Wonmin Byeon are the shared first authors, both authors contributed equally to this work"]], "COMMENTS": "Marijn F. Stollenga and Wonmin Byeon are the shared first authors, both authors contributed equally to this work", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["marijn f stollenga", "wonmin byeon", "marcus liwicki", "j\u00fcrgen schmidhuber"], "accepted": true, "id": "1506.07452"}, "pdf": {"name": "1506.07452.pdf", "metadata": {"source": "CRF", "title": "Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation", "authors": ["Marijn F. Stollenga", "Wonmin Byeon", "Marcus Liwicki", "Juergen Schmidhuber"], "emails": ["marijn@idsia.ch,", "wonmin.byeon@dfki.de"], "sections": [{"heading": "1 Introduction", "text": "Long-term short-term memory (LSTM) networks [1, 2] are recursive neural networks (RNNs) originally designed for sequence processing, achieving state-of-the-art results in difficult tasks such as handwriting recognition [3], large speech recognition [4, 5] and machine translation [6]. Their architecture includes gates to store and read information from linear units called fault carousels that store information about long time intervals, which is difficult for traditional RNs.ar Xiv: 150 6.07 452v 1Multi-dimensional LSTM networks (MD-LSTM [7]) connect hidden LSTM units in network-like mode1. Two-dimensional MD-LSTM is applicable for image segmentation [7, 8, 9] where each pixel is assigned to a class such as background or foreground."}, {"heading": "2 Method", "text": "The original LSTM unit consists of an entrance gate (i), forget-me-not gate (f), exit gate (o) and memory cell (c), which control what should be remembered or forgotten about potentially long periods of time. All gates and activations are real vectors: x, i, f, c, c, h, RT, where T is the length of input. The gates and activations at discrete time t (t = 1,2,...) are calculated as follows: they are real activation vectors: x, i, f, c, c, o, h, RT, where T is the length of input. The gates and activations at discrete time t (t = 1,2,...) are calculated as follows: they are real (xt \u00b7 successxi + ht-1 \u00b7 occurrence ibias), (1) ft = occurrence ibias), (xt \u00b7 gate (xt \u00b7 occurrence) and occurrence ibias)."}, {"heading": "2.1 Pyramidal Connection Topology", "text": "In MD-LSTM, the connections with the grid axes are filled in. In 2D, these directions are up, down, left and right. A 2D-LSTM adds the pixel-by-pixel output of 4 LSTMs, one scans the image pixel by pixel from northwest to southeast, one from northeast to southwest, one from southwest to northwest. This facilitates parallelism since all elements of an entire network series are calculated independently, which does not work for MD-LSTM, up or down (left in the case of Figure 1-B)."}, {"heading": "2.2 PyraMiD-LSTM", "text": "Here we explain the PyraMiD-LSTM network architecture for 3D volumes (see Figure 3). It consists of six LSTM with RNN-specific convolutions (C-LSTM), one for each direction to generate the full context of each pixel. Note that each of these C-LSTMs is a complete LSTM RNN that processes the entire volume in one direction. Directions D are defined via the three axes (x, \u00b7, \u00b7 1), (\u00b7, \u00b7 1, \u00b7), (\u00b7, \u00b7 1, \u00b7), (1, \u00b7), (\u2212), (\u2212), (\u2212), (\u2212), (\u2212 1, \u00b7, \u00b7). Each C-LSTM performs compilations in a plane that moves in the defined direction. The symbol (\u00b7) in one dimension means that the plane runs parallel to that axis, and \u2212 1 implies that the compilation moves along the positive or negative axis."}, {"heading": "3 Experiments", "text": "We are the only ones who are in a position to put ourselves in the world, who are able to get lost in the world, who are able to get lost in the world, who are able to look into the world, who are able to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to understand, to look into the world, to understand, to look into the world, to understand, to understand, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look into the world, to look, to look into the world, to look into the world, to look into the world, to look, to look into the world, to look into the world, to look, to look into the world, to look into the world, to look, to look into the world, to look, to look into the world, to look into the world, to look, to look into the world, to look, to look into the world, to look, to look into the world, to look, to look, to see, to look into the world, to look, to look into the world, to look, to understand, to see, to understand, to understand, to look into the world, to look into the world, to understand, to look into the world, to understand, to look into the world, to understand, to look into the world, to look, to look into the world, to see, to understand, to understand, to look into the world, to understand, to look into the world, to understand, to understand, to understand"}, {"heading": "3.1 Neuronal Membrane Segmentation", "text": "The IDSIA and DIVE teams, like our method, provide probability maps for each pixel. These maps are customized by the post-processing techniques of the SCI teams [24], which directly optimize marginal error (DIVE-SCI (top-1) and IDSIA-SCI (top-2)); this is especially important in this particular segmentation task. Without post-processing, PyraMiD LSTM networks outperform other methods in marginal error and are competitive in wrapping and pixel error. Of course, performance could be further improved by applying post-processing techniques. Figure 4 shows an example of a segmentation result."}, {"heading": "3.2 MR Brain Segmentation", "text": "The results are compared on the basis of the following three metrics: \u2022 The DICE overlap (DC) [25]: Spatial overlap between segmented volume and ground truth \u2022 The modified Hausdorff distance (MD) [26]: 95th percentile Hausdorff distance between segmented volume and ground truth \u2022 The absolute volume difference (AVD) [27]: the absolute difference between segmented and ground truth volume, normalized across the entire volume. The results of the MR image segmentation are evaluated by the organizers of ISBI NEATBrain15 [14], who have provided the extensive comparison to other approaches on http: / / mrbrains13.isi.uu.nl / results.php. Table 2 compares our results with those of the five best teams. The organizers calculate a total of nine measures and rank all teams individually for each of them. These ranks are then summarized per team, with the final rankings broken down by the metropolises."}, {"heading": "4 Conclusion", "text": "Since 2011, GPU-trained Max Pooling CNNs have dominated classification contests [30, 31, 32] and segmentation contests [12], but MD-LSTM could pose a serious challenge to such CNNs, at least in terms of segmentation tasks. However, unlike CNNs, MD-LSTM has an elegant recursive method of taking into account the entire spatial and temporal context of each pixel in both images and videos. However, previous MD-LSTM implementations have failed to exploit the parallelism of modern GPU hardware, which has been changed by our work presented here. Although our novel high-parallel PyraMiD-LSTM has already led to demanding benchmarks, we feel we have only scratched the surface of what will be possible with such PyraMiDLSTM and other MD-RNNNNs."}, {"heading": "5 Acknowledgements", "text": "We thank Klaus Greff and Alessandro Giusti for their valuable discussions and Jan Koutnik and Dan Ciresan for their useful feedback. We also thank the organizers of ISBI NEATBrain15 [14] and the organizers of ISBI 2012, especially Adrie \u00a8 nne Mendrik and Ignacio Arganda-Carreras. Finally, we thank NVIDIA for generously providing hardware to carry out our research. This research was funded by the EU project NASCENCE (EU / FP7-ICT-317662)."}], "references": [{"title": "Long Short-Term Memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1997}, {"title": "Learning to Forget: Continual Prediction with LSTM", "author": ["F.A. Gers", "J. Schmidhuber", "F. Cummins"], "venue": "Proc. ICANN\u201999, Int. Conf. on Artificial Neural Networks. Edinburgh, Scotland: IEE,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "A Novel Connectionist System for Improved Unconstrained Handwriting Recognition", "author": ["A. Graves", "M. Liwicki", "S. Fernandez", "R. Bertolami", "H. Bunke", "J. Schmidhuber"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2009}, {"title": "Sequence Discriminative Distributed Training of Long Short-Term Memory Recurrent Neural Networks", "author": ["H. Sak", "O. Vinyals", "G. Heigold", "A. Senior", "E. McDermott", "R. Monga", "M. Mao"], "venue": "Proc. Interspeech", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling", "author": ["H. Sak", "A. Senior", "F. Beaufays"], "venue": "Proc. Interspeech", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Sequence to Sequence Learning with Neural Networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Tech. rep. arXiv:1409.3215 [cs.CL]. NIPS\u20192014. Google,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Multi-dimensional Recurrent Neural Networks", "author": ["A. Graves", "S. Fern\u00e1ndez", "J. Schmidhuber"], "venue": "ICANN", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks", "author": ["A. Graves", "J. Schmidhuber"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2009}, {"title": "Scene Labeling With LSTM Recurrent Neural Networks", "author": ["W. Byeon", "T.M. Breuel", "F. Raue", "M. Liwicki"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Snakes: Active contour models", "author": ["M. Kass", "A. Witkin", "D. Terzopoulos"], "venue": "English. In: International Journal of Computer Vision", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1988}, {"title": "LINKS: Learning-based multi-source IntegratioN frameworK for Segmentation of infant brain images", "author": ["L. Wang", "Y. Gao", "F. Shi", "G. Li", "J.H. Gilmore", "W. Lin", "D. Shen"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Deep Neural Networks Segment Neuronal Membranes in Electron Microscopy Images", "author": ["D.C. Ciresan", "A. Giusti", "L.M. Gambardella", "J. Schmidhuber"], "venue": "Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2012}, {"title": "An integrated micro-and macroarchitectural analysis of the Drosophila brain by computer-assisted serial section electron microscopy", "author": ["A. Cardona", "S. Saalfeld", "S. Preibisch", "B. Schmid", "A. Cheng", "J. Pulokas", "P. Tomancak", "V. Hartenstein"], "venue": "PLoS biology", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2010}, {"title": "MRBrainS Challenge: Online Evaluation Framework for Brain Image Segmentation in 3T MRI Scans, http://mrbrains13.isi.uu.nl", "author": ["A.M. Mendrik", "K.L. Vincken", "H.J. Kuijf", "G.J. Biessels", "M.A. Viergever (organizers"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Parallel algorithms for approximation of distance maps on parametric surfaces", "author": ["O. Weber", "Y.S. Devir", "A.M. Bronstein", "M.M. Bronstein", "R. Kimmel"], "venue": "ACM Transactions on Graphics (TOG)", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Adaptive Histogram Equalization and Its Variations", "author": ["S.M. Pizer", "E.P. Amburn", "J.D. Austin", "R. Cromartie", "A. Geselowitz", "T. Greer", "B.T.H. Romeny", "J.B. Zimmerman"], "venue": "In: Comput. Vision Graph. Image Process", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1987}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["T. Tieleman", "G. Hinton"], "venue": "In: COURSERA: Neural Networks for Machine Learning", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "RMSProp and equilibrated adaptive learning rates for non-convex optimization", "author": ["Y.N. Dauphin", "H. de Vries", "J. Chung", "Y. Bengio"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Untersuchungen zu dynamischen neuronalen Netzen", "author": ["S. Hochreiter"], "venue": "Diploma thesis, Institut fu\u0308r Informatik, Lehrstuhl Prof. Brauer, Technische Universita\u0308t Mu\u0308nchen. Advisor: J. Schmidhuber", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1991}, {"title": "cuDNN: Efficient Primitives for Deep Learning", "author": ["S. Chetlur", "C. Woolley", "P. Vandermersch", "J. Cohen", "J. Tran", "B. Catanzaro", "E. Shelhamer"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Objective Criteria for the Evaluation of Clustering Methods", "author": ["W.M. Rand"], "venue": "Journal of the American Statistical Association", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1971}, {"title": "Boundary Learning 12  by Optimization with Topological Constraints", "author": ["V. Jain", "B. Bollmann", "M. Richardson", "D. Berger", "M. Helmstaedter", "K. Briggman", "W. Denk", "J. Bowden", "J. Mendenhall", "W. Abraham", "K. Harris", "N. Kasthuri", "K. Hayworth", "R. Schalek", "J. Tapia", "J. Lichtman", "H. Seung"], "venue": "Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "A modular hierarchical approach to 3D electron microscopy image segmentation", "author": ["T. Liu", "C. Jones", "M. Seyedhosseini", "T. Tasdizen"], "venue": "Journal of Neuroscience Methods", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Measures of the Amount of Ecologic Association Between Species", "author": ["L.R. Dice"], "venue": "English. In: Ecology", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1945}, {"title": "Comparing images using the Hausdorff distance", "author": ["D. Huttenlocher", "G. Klanderman", "W. Rucklidge"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on 15.9", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1993}, {"title": "An evaluation of four automatic methods of segmenting the subcortical structures in the brain", "author": ["K.O. Babalola", "B. Patenaude", "P. Aljabar", "J. Schnabel", "D. Kennedy", "W. Crum", "S. Smith", "T. Cootes", "M. Jenkinson", "D. Rueckert"], "venue": null, "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "Journal of Machine Learning Research", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Recurrent Neural Network Regularization", "author": ["W. Zaremba", "I. Sutskever", "O. Vinyals"], "venue": null, "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2014}, {"title": "A Committee of Neural Networks for Traffic Sign Classification", "author": ["D.C. Ciresan", "U. Meier", "J. Masci", "J. Schmidhuber"], "venue": "In: International Joint Conference on Neural Networks (IJCNN)", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2011}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I Sutskever", "G. E Hinton"], "venue": "In: NIPS", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Visualizing and Understanding Convolutional Networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "Tech. rep. arXiv:1311.2901 [cs.CV]. NYU,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Long Short-Term Memory (LSTM) networks [1, 2] are recurrent neural networks (RNNs) initially designed for sequence processing.", "startOffset": 39, "endOffset": 45}, {"referenceID": 1, "context": "Long Short-Term Memory (LSTM) networks [1, 2] are recurrent neural networks (RNNs) initially designed for sequence processing.", "startOffset": 39, "endOffset": 45}, {"referenceID": 2, "context": "They achieved state-of-the-art results on challenging tasks such as handwriting recognition [3], large vocabulary speech recognition [4, 5] and machine translation [6].", "startOffset": 92, "endOffset": 95}, {"referenceID": 3, "context": "They achieved state-of-the-art results on challenging tasks such as handwriting recognition [3], large vocabulary speech recognition [4, 5] and machine translation [6].", "startOffset": 133, "endOffset": 139}, {"referenceID": 4, "context": "They achieved state-of-the-art results on challenging tasks such as handwriting recognition [3], large vocabulary speech recognition [4, 5] and machine translation [6].", "startOffset": 133, "endOffset": 139}, {"referenceID": 5, "context": "They achieved state-of-the-art results on challenging tasks such as handwriting recognition [3], large vocabulary speech recognition [4, 5] and machine translation [6].", "startOffset": 164, "endOffset": 167}, {"referenceID": 6, "context": "Multi-Dimensional LSTM networks (MD-LSTM [7]) connect hidden LSTM units in grid-like fashion1.", "startOffset": 41, "endOffset": 44}, {"referenceID": 6, "context": "Two dimensional MD-LSTM is applicable to image segmentation [7, 8, 9] where each pixel is assigned to a class such as background or foreground.", "startOffset": 60, "endOffset": 69}, {"referenceID": 7, "context": "Two dimensional MD-LSTM is applicable to image segmentation [7, 8, 9] where each pixel is assigned to a class such as background or foreground.", "startOffset": 60, "endOffset": 69}, {"referenceID": 8, "context": "Two dimensional MD-LSTM is applicable to image segmentation [7, 8, 9] where each pixel is assigned to a class such as background or foreground.", "startOffset": 60, "endOffset": 69}, {"referenceID": 9, "context": "Most previous approaches process each 2D slice separately, using image segmentation algorithms such as snakes [10], random forests [11] and Convolutional Neural Networks [12].", "startOffset": 110, "endOffset": 114}, {"referenceID": 10, "context": "Most previous approaches process each 2D slice separately, using image segmentation algorithms such as snakes [10], random forests [11] and Convolutional Neural Networks [12].", "startOffset": 131, "endOffset": 135}, {"referenceID": 11, "context": "Most previous approaches process each 2D slice separately, using image segmentation algorithms such as snakes [10], random forests [11] and Convolutional Neural Networks [12].", "startOffset": 170, "endOffset": 174}, {"referenceID": 12, "context": "Competitive results are achieved on EM-ISBI12 [13]; best known results are achieved on MRBrainS13 [14].", "startOffset": 46, "endOffset": 50}, {"referenceID": 13, "context": "Competitive results are achieved on EM-ISBI12 [13]; best known results are achieved on MRBrainS13 [14].", "startOffset": 98, "endOffset": 102}, {"referenceID": 1, "context": "We will first describe standard one-dimensional LSTM [2] and MD-LSTM.", "startOffset": 53, "endOffset": 56}, {"referenceID": 14, "context": "A similar connection strategy has been previously used to speed up non-euclidian distance computations on surfaces [15].", "startOffset": 115, "endOffset": 119}, {"referenceID": 12, "context": "EM dataset The EM dataset [13] is provided by the ISBI 2012 workshop on Segmentation of Neuronal Structures in EM Stacks [16].", "startOffset": 26, "endOffset": 30}, {"referenceID": 13, "context": "MR Brain dataset The MR Brain images are provided by the ISBI 2015 workshop on Neonatal and Adult MR Brain Image Segmentation (ISBI NEATBrainS15) [14].", "startOffset": 146, "endOffset": 150}, {"referenceID": 10, "context": "We do not apply the complex pre-processing common in biomedical image segmentation [11].", "startOffset": 83, "endOffset": 87}, {"referenceID": 15, "context": "0), then a Contrast-Limited Adaptive Histogram Equalization (CLAHE) [17] is applied to enhance the local contrast (tile size: 16\u00d716, contrast limit: 2.", "startOffset": 68, "endOffset": 72}, {"referenceID": 16, "context": "Training We apply RMS-prop [18, 19] with momentum.", "startOffset": 27, "endOffset": 35}, {"referenceID": 17, "context": "Training We apply RMS-prop [18, 19] with momentum.", "startOffset": 27, "endOffset": 35}, {"referenceID": 18, "context": "This also helps to deal with vanishing gradients [20].", "startOffset": 49, "endOffset": 53}, {"referenceID": 19, "context": "For GPU implementation, the NVIDIA CUDA Deep Neural Network library (cuDNN) [21] is used.", "startOffset": 76, "endOffset": 80}, {"referenceID": 11, "context": "IDSIA [12] 0.", "startOffset": 6, "endOffset": 10}, {"referenceID": 20, "context": "\u2022 Rand error [22]: 1 - F-score of rand index, which measures similarity between two segmentations on the foreground.", "startOffset": 13, "endOffset": 17}, {"referenceID": 21, "context": "\u2022 Warping error [23]: topological disagreements (object splits and mergers)", "startOffset": 16, "endOffset": 20}, {"referenceID": 22, "context": "These maps are adapted by the post-processing technique of the teams SCI [24], which directly optimizes the rand error (DIVE-SCI (top-1) and IDSIA-SCI (top-2)); this is most important in this particular segmentation task.", "startOffset": 73, "endOffset": 77}, {"referenceID": 23, "context": "\u2022 The DICE overlap (DC) [25]: spatial overlap between the segmented volume and ground truth", "startOffset": 24, "endOffset": 28}, {"referenceID": 24, "context": "\u2022 The modified Hausdorff distance (MD) [26]: 95th-percentile Hausdorff distance between the segmented volume and ground truth", "startOffset": 39, "endOffset": 43}, {"referenceID": 25, "context": "\u2022 The absolute volume difference (AVD) [27]: the absolute difference between segmented and ground truth volume, normalized over the whole volume.", "startOffset": 39, "endOffset": 43}, {"referenceID": 13, "context": "Results MR brain image segmentation results are evaluated by the ISBI NEATBrain15 organizers [14] who provided the extensive comparison to other approaches on http: //mrbrains13.", "startOffset": 93, "endOffset": 97}, {"referenceID": 26, "context": "We also tried regularization through dropout [28].", "startOffset": 45, "endOffset": 49}, {"referenceID": 27, "context": "Following earlier work [29], the dropout operator is applied only to non-recurrent connections (50% dropout on fully connected layers and/or 20% on input layer).", "startOffset": 23, "endOffset": 27}, {"referenceID": 28, "context": "Since 2011, GPU-trained max-pooling CNNs have dominated classification contests [30, 31, 32] and segmentation contests [12].", "startOffset": 80, "endOffset": 92}, {"referenceID": 29, "context": "Since 2011, GPU-trained max-pooling CNNs have dominated classification contests [30, 31, 32] and segmentation contests [12].", "startOffset": 80, "endOffset": 92}, {"referenceID": 30, "context": "Since 2011, GPU-trained max-pooling CNNs have dominated classification contests [30, 31, 32] and segmentation contests [12].", "startOffset": 80, "endOffset": 92}, {"referenceID": 11, "context": "Since 2011, GPU-trained max-pooling CNNs have dominated classification contests [30, 31, 32] and segmentation contests [12].", "startOffset": 119, "endOffset": 123}, {"referenceID": 13, "context": "We also thank the ISBI NEATBrain15 organizers [14] and the ISBI 2012 organisers, in particular Adri\u00ebnne Mendrik and Ignacio Arganda-Carreras.", "startOffset": 46, "endOffset": 50}], "year": 2015, "abstractText": "Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3D videos to segment them. They have a fixed input size and typically perceive only small local contexts of the pixels to be classified as foreground or background. In contrast, Multi-Dimensional Recurrent NNs (MD-RNNs) can perceive the entire spatio-temporal context of each pixel in a few sweeps through all pixels, especially when the RNN is a Long Short-Term Memory (LSTM). Despite these theoretical advantages, however, unlike CNNs, previous MD-LSTM variants were hard to parallelize on GPUs. Here we re-arrange the traditional cuboid order of computations in MD-LSTM in pyramidal fashion. The resulting PyraMiD-LSTM is easy to parallelize, especially for 3D data such as stacks of brain slice images. PyraMiD-LSTM achieved best known pixel-wise brain image segmentation results on MRBrainS13 (and competitive results on EM-ISBI12).", "creator": "LaTeX with hyperref package"}}}