{"id": "1506.08669", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Jun-2015", "title": "Efficient and Parsimonious Agnostic Active Learning", "abstract": "We develop a new active learning algorithm for the streaming setting satisfying three important properties: 1) It provably works for any classifier representation and classification problem including those with severe noise. 2) It is efficiently implementable with an ERM oracle. 3) It is more aggressive than all previous approaches satisfying 1 and 2. To do this we create an algorithm based on a newly defined optimization problem and analyze it. We also conduct the first experimental analysis of all efficient agnostic active learning algorithms, discovering that this one is typically better across a wide variety of datasets and label complexities.", "histories": [["v1", "Mon, 29 Jun 2015 15:02:55 GMT  (149kb,D)", "http://arxiv.org/abs/1506.08669v1", null], ["v2", "Wed, 6 Jan 2016 02:49:21 GMT  (441kb,D)", "http://arxiv.org/abs/1506.08669v2", null], ["v3", "Thu, 7 Jan 2016 18:27:33 GMT  (477kb,D)", "http://arxiv.org/abs/1506.08669v3", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["tzu-kuo huang", "alekh agarwal", "daniel j hsu", "john langford", "robert e schapire"], "accepted": true, "id": "1506.08669"}, "pdf": {"name": "1506.08669.pdf", "metadata": {"source": "CRF", "title": "Efficient and Parsimonious Agnostic Active Learning", "authors": ["Tzu-Kuo Huang", "Alekh Agarwal", "Daniel J. Hsu", "John Langford", "Robert E. Schapire"], "emails": ["tkhuang@microsoft.com", "alekha@microsoft.com", "djhsu@cs.columbia.edu", "jcl@microsoft.com", "schapire@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "This year it has come to the point that it will only be a matter of time before it will happen, until it does."}, {"heading": "2 Preliminaries", "text": "Leave H & # 8222; H & # 8222; H & # 8222; H & # 8220;. & # 8222; H & # 8220;. & # 8222; H & # 8220;. & # 8222; H & # 8220;. & # 8222; H & # 8220;. & # 8222; H & # 8222; H & # 8220;. & # 8222; H & # 8222;. & # 8222; H & # 8220;. & # 8222; H & # 8220;. & # 8222; H & # 8220;. & # 8222; H & # 8222;. & # 8222; H & # 8222;. & # 8222; H & # 8220;. & # 8222; H & # 8220;. & # 8222; H & # 8220;. & # 8222; H & # 8222; H & # 8222; H & # 8222; H & # 8222; H & # 8222."}, {"heading": "3 Algorithm", "text": "The algorithm recognizes each epoch as long as the epoch lengths are as long as the epoch lengths are as long as possible. (For technical reasons, we will always query the first 3 labels to set the algorithms in motion.) At the beginning of the epoch, we will calculate a quantity function whose sole purpose is to maintain the correct number of recorded possibilities. (h, S).4See Footnote 3. Adding an example of importance without updating the other states of the algorithms. (h, S)"}, {"heading": "4 Generalization and Label Complexity", "text": "We now present guarantees for the generalization error and the complexity of the labeling of algorithm 1 under the assumption of a solution for (OP), which we offer in the next section."}, {"heading": "4.1 Generalization guarantees", "text": "The first theory offers a generalization of error. Defineerrm (h): = 1: 1, 2: 1, 2: 1, 2: 1, 3: 1, 3: 1, 3: 1, 4: 1, 4: 1, 5: 1, 5: 1, 5: 1, 6: 1, 6: 1, 6: 1, 6: 1, 6: 1, 8: 1, 8: 1, 8: 1, 8: 2, 8: 2, 8: 1, 8: 2, 8: 2, 8: 2, 8: 1, 8: 1, 8: 9: 9, 11: 11, 11: 11, 11, 11: 11, 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11, 11: 11: 11, 11: 11, 11: 11, 11: 11: 11, 11: 11, 11: 1, 7: 1, 7: 1, 7: 1, 7: 1, 7: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 2, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1, 8: 1,"}, {"heading": "4.2 Label complexity", "text": "Generalization alone does not convey the overall quality of an active learning algorithm, since a trivial algorithm always queries with probability 1, corresponding to the generalization guarantees of passive learning. In this section, we show that our algorithm can achieve the generalization guarantees mentioned above, although it is low in complexity in favorable situations. We start with a worst-case result in an agnostic environment and then describe a specific example that shows some key differences of our approach from its predecessors."}, {"heading": "4.2.1 Disagreement-based label complexity bounds", "text": "In order to quantify the extent of achievements in passive learning, we measure the severity of our problem using the discrepancy coefficient [Hanneke, 2014] defined in our statement on the state of noise (10), which in fact corresponds to 1 / 3 of the results of Castro and Nowak [2008]. (11) We have a set of classifiers that includes a set of classifiers H and a data distribution P, an active learning problem is simple if good classifiers do not agree on a small fraction of the examples, so that the active learning algorithm can increasingly limit attention in this way. (With this definition, we have the following result for the etiquette of complexity of algorithms 1. Theorem 2.) We have the probability that the ability of active learning can be limited to only a small fraction of the examples."}, {"heading": "4.2.2 Improved label complexity for a hard problem instance", "text": "We present an example where the complexity of algorithm 1 is significantly lower than both IWAL and Oracular CAL due to the rare query in the discrepancy region. The example considers a distribution and a6Expectation in relation to the coins thrown by the algorithm. In the first case, little advantage is gained from a label because it provides evidence against only one classifier. ACTIVE COVER queries about the discrepancy region with a probability close to Pmin 1 in case (ii), while other queries with probability (1) everywhere imply that O (n) times more queries. Specifically, we consider the following binary classification problem."}, {"heading": "5 Efficient implementation", "text": "In algorithm 1, the calculation of hm is an ERM operation that can be performed efficiently if an efficient passive learner is available. However, several other hurdles remain. \u2212 Testing for x-Dm in the algorithm, as well as algorithm 2 Coordinate ascension algorithm to solve (OP) precision parameters. \u2212 Testing for x-Dm in the algorithm. \u2212 Testing for x-Dm. \u2212 Testing for s = arg maxs. \u2212 Testing h = arg max h-H-EX (X). \u2212 Testing. \u2212 Testing. \u2212 Testing. \u2212 Testing. \u2212 Testing. \u2212 Testing. \u2212 Testing. \u2212 Testing. \u2212 Testing. \u2212 Testing. \u2212 Testing."}, {"heading": "5.1 Solving (OP) with the true expectation", "text": "The main challenge is that the optimization variable P (x) is of infinite dimension (X), where the difficulty with the Lagrange duality (which leads to a dual representation of P (x) in relation to a series of classifiers found by successive calls to an ERM oracle) is reduced to an acceptable level. We begin by eliminating the bound constraints using barrier functions. The objective EX [1 \u2212 P (x)] is already a barrier at P (x) = 1. To force the lower limit (6), we modify the objective toEX [11 \u2212 P]."}, {"heading": "5.2 Solving (OP) with expectation over samples", "text": "A simple and natural replacement for PX is an i.i.d. sample that we have drawn from it. Let us show that solving a correctly defined sample of (OP) results in a solution of the original (OP) with guarantees similar to those in Theorem 3. Specifically, we define the following sample of (OP). Let S have a large sample that i.i.d. will be roughly the same from (OP) as (OP) except with all population expectations being replaced by empirical expectations that will be identical with respect to S. Now for any other variant of (OPS,) except that the limitations of variance (5) are loosened by an additive inconsistency of principles. Each time ACTIVE COVER must be solved (OP)."}, {"heading": "6 Experiments with Agnostic Active Learning", "text": "As Theorem 3 suggests, the query probability function (13) may require as many asO (\u03c42i) classifiers, further increasing memory requirements. In Section 6.1, we discuss a scalable online approach to ACTIVE COVER, ONLINE ACTIVE COVER (OAC), which we have empirically implemented and tested with the setup in Section 6.2. Experimental results and discussions can be found in Section 6.3."}, {"heading": "6.1 Online Active Cover (OAC)", "text": "To illustrate the dependence of a query probability function on both a weight vector and the current epoch, we write it as subscriptions: q\u03bb, i (x): 1 (2Pmin, i) 2 + 2 (h) 6 = hi (x) P\u03bb, i (x): 1 (x) Di) q\u03bb, i (x) 1 + q\u03bb, i (x). We use 1h for a binary vector with 1 in the entry corresponding to the classifier h and 0 elsewhere. To explain the connections between algorithms 1 (AC) and 3 (OAC), we start by updating the ERM classifiers and thresholds."}, {"heading": "6.2 Setup", "text": "We perform an empirical comparison of OAC with the following active learning algorithms. \u2022 IWAL: A minor modification of algorithm 1 by Beygelzimer et al. [2010], which performs a weighted sample of labels and maintains an unbiased estimate of the classification error. (In the calculation of the query probability (instead of using a conservative, problem-free threshold as in Beygelzimer et al. [2010], we use the following error-dependent quantity: C0 log kk \u2212 1 ek \u2212 1 log kk \u2212 1, (22), where ek \u2212 1 is the weighted error estimate according to algorithm processes k \u2212 1 example. C0 is the only active learning probability. The query probability is set to 1 if the error difference Gk, defined in step 2 by algorithm 1 by Beygelzimer et al. [2010], is lower than the threshold (22) and an algorithm is taken from the other function."}, {"heading": "6.3 Results and Discussions", "text": "In fact, it is the case that most people are able to comply with the rules that they have imposed on themselves. (...) In fact, it is not the case that they are able to comply with the rules. (...) In fact, it is the case that they are able to comply with the rules. (...) In fact, it is the case that they are able to comply with the rules of the market. (...) \"It is the case that they are able to comply with the rules of the market.\" (...) In fact, it is the case that they comply with the rules of the market. \"(...) The rules of the market.\" (...) The rules of the market. \"(...) The rules of the market. (...) The rules of the market. (...) The rules of the market. (...) The rules of the market. (...) The rules of the market. (...) The rules of the market. (...) The rules of the market. (...) The rules of the market."}, {"heading": "7 Analysis of generalization ability", "text": "In this section, we present the main framework and analysis of the results based on the generalization properties of the ACTIVE COVER algorithm. Our analysis is divided into several steps. First, we create an additional notation for the evidence. Our analysis is based on two thresholds of deviation for the empirical regret and the empirical error of the ERM classifier, which are achieved by appropriate application of Freedman-style concentration limits for martyrdom. Both limits depend on the variance and scope of our error and regret estimates for all classifiers h-H, and these sizes are controlled by the limitations (5) and (6) in defining the optimization problem (OP). Since our data consists of examples from different eras using different query truths Pm, the above steps with appropriate manipulations result in limits for the epoch m, with respect to different quantities affecting the previous eras, the appropriate sequences are then determined by the following theorem and its intuitive consequences."}, {"heading": "7.1 Framework for generalization analysis", "text": "(...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...)) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (... (...) (...) (...) (... (...) (...) (...) (... (...) (...) (...) (... (...) (...) (...) (... (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (... (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (..."}, {"heading": "7.2 Proofs of main results", "text": "Theorem 5. For all epochs m = 1, 2,.., M and all h \u00b2 H we have with probability at least 1 \u2212 \u03b4 | reg (h, h \u00b2, Z \u00b2 m) \u2212 r \u00b2 egm (h, h \u00b2) \u2212 r \u00b2 egm (h, h \u00b2) | \u2264 12 r \u00b2 egm (h, h \u00b2) + \u03b74 \u0445 m, (31) reg (h \u00b2, hm + 1, Z \u00b2 m). (33) The theorem is proven inductively. We first give the proof sketch for this theorem and then show how theorem 1 and its consequences follow."}, {"heading": "7.2.1 Proof of Theorem 5", "text": "The question is whether the solution to the problem is a solution or not. (...) The question is whether there is a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution. (...) The question is whether there will be a solution."}, {"heading": "7.2.2 Proof of Theorem 1", "text": "We only prove the first part of the theorem. The second part is simply a reformulation of the inequality (32) in theorem 5. The first part is essentially a reformulation of (31) in theorem 5, except the bound part uses \"m\" instead of \"m.\" To prove the theorem, select any epoch m \"m\" and h \"m.\" Since h \"m,\" 1 \"m\" and 1 \"m,\" we have 1 \"reg\" (h) \"m\" by lemma. It is then sufficient to tie r \"egm\" (h, h \"). By the limit of deviation (31) we have\" egm \"(h, h\") \u2264 reg \"(h\" m \") \u2264 reg\" (h \"m\") \u2264, \"h\" m. \"+ 1\" egm \"(h\" m \") \u2264 m.\""}, {"heading": "8 Conclusion", "text": "In this paper, we propose a new algorithm for agnostic active learning in a streaming setting. It has strong theoretical guarantees, maintaining good generalization properties while achieving low label complexity in favorable environments. Specifically, we show that the algorithm performs optimally in a non-consensual analysis of label complexity, even in special cases such as realizable problems and under Tsybakov's low-noise conditions. In addition, we present an interesting example that highlights the structural difference between our algorithm and some predecessors in terms of label complexity. In fact, a key improvement to our algorithm is that we do not always have to question the overall discrepancy region-limiting of most computationally efficient predecessors. This is achieved by carefully constructing an optimization problem that defines good quantum probability functions based on the use of refined error-estimated data."}, {"heading": "Acknowledgements", "text": "The authors thank Kamalika Chaudhuri for helpful first conversations."}, {"heading": "A Deviation bound", "text": "Let X1, X2,.., Xn be a martyrdom difference sequence adapted to filtration. Suppose there is a function bn of X1,.., Xn that is 1 \u2264 i \u2264 n, | Xi | \u2264 bn, 1 \u2264 bn \u2264 bmax, where bmax is a non-random quantity that can depend on n. DefineSn: = n b = 1 Xi, Vn: = n = 1 E [X2i | Fi \u2212 1].Select any 0 < 1 / e2 and n \u2265 3. We have Pr (Sn \u00b2) + 3bn log (1 / 3 bn) + 3bn log (1 / 5%) (1 / 5%). (2 + log2 bmax) log n.Proof."}, {"heading": "B Auxiliary results for Theorem 1", "text": "The threshold defined in (2) and the minimum probability Pmin, m defined in (7) meet the following values for all m + 1, m \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 2 \u2212 1 \u2212 1 \u2212 1 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 log (log) 32 (log (log (log) 32 (log (H | / 6)) 32 (log (log (H | / 6))) \u2212 1 \u2212 1 \u2212 2 \u2212 2 \u2212 2 \u2212 1 \u2212 2 \u2212 1 \u2212 32 (log (h1 \u2212 1 \u2212 1 \u2212 1)) 32 (log (H | / 6))) + 1 \u2212 1 \u2212 1 \u2212 log (H | / 6)) + 1 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 1 \u2212 1 \u2212 32 (log (log (log (log (log)) \u2212 1 \u2212 m) 32 (log (log (H | / 6))) \u2212 2 \u2212 2 \u2212 32 (log (log (h2 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 32)) + 1 \u2212 2 \u2212 2 \u2212 2 \u2212 32 (log (log (h1 \u2212))) 32 (log (log (log (H | / 6)))) 32 (log (log (h1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1))))) 32 (log (log (h1 \u2212 2 \u2212 2 \u2212 2 \u2212 32)) + 1 \u2212 32 (h2 \u2212 32 (h2 \u2212 32))) 32 (log (h1 \u2212 2 \u2212 32 (h2 \u2212 32)) 32 (log (h2 \u2212 32) 32) 32 (log (h2 \u2212 32) 32) 32 (log (log (h1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1) 32) 32) 32 (h1 \u2212 1 \u2212 1 \u2212 2 \u2212 2 \u2212 2 \u2212 2 \u2212 32) 32 (h2 \u2212 32) 32 (h2 \u2212 32) 32) 32 (h2 \u2212 32) 32 (h2 \u2212 32) 32 (log (h2 \u2212 32) 32 h2 \u2212 32) 32) 32) 32 (log ("}, {"heading": "C Proofs omitted from Section 7.2", "text": "We begin with the proofs of Lemmas 1 and 2. Proofs of Lemmas 1 and 2. Proofs of Lemmas 1 and 2. Proofs of Lemmas 1 and 2. Proofs of Lemmas 2 and 1. Proof that the definitions of reg \u00b2 m (h, h, h, h, h) and reg (h, h, h, h) and reg (h, h, h, h) and reg (h, h, h, h) and reg (h, h, h, h, h) and reg (h, h, h) and reg (h, h) and reg (h, h, h, h) and reg (h, h, h, h) and reg (h, h, h) and reg (h, h) and reg (h, h)."}, {"heading": "D Label Complexity", "text": "(1: 1) (1: 1) (1: 1) (1: 1) (1: 1) (1: 1) (1: 1) (1: 1) (1: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2: 1) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (2) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1) (1) (1) (1 (1) (1) (1) (1 (1) (1) (1 (1) (1) (1) (1 (1) (1 (1) (1) (1) (1) (1 (1) (1 (1) (1 (1) (1) (1) (1 (1) (1) (1) (1 (1) (1 (1) (1 (1) (1 (1) (1) (1) (1 (1 (1) (1 (1) (1 (1) (1) (1 (1) (1) (1) (1 (1) (1) (1 (1 (1) (1) (1) (1 (1) (1 (1) (1) (1 (1) (1"}, {"heading": "E Proofs for Tsybakov\u2019s low-noise condition", "text": "We begin with a dilemma that captures the behavior of the individual terms and assume that the probability of a region of discrepancy below the Tsybakov noise state (10) continues to increase. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 The results of corollariums 2 and 4 are directly under the conditions of theorem 1, and we assume that the low noise state (10) will continue. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 The results of corollariums 2 and 4 are directly under the conditions of theorem 1, and error (h). \u2212 \u2212 The results of the two epochs m = 1, 2,. \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 \u2212 We will explain the results in detail below. \u2212 \u2212 m The constants c > 0 (depending on the distribution parameters) that we capture. \u2212 u The constants (depending on the distribution parameters) that we capture for all epochs (53)."}, {"heading": "F Analysis of the Optimization Algorithm", "text": "We start by showing how to find the most violated constraint (step 3) by invoking a double (weighted) ERM oracle (1), then we prove theorem 3, followed by the framework and the proof for theorem 4.F.1 \u2212 \u2212 \u2212 The most violated constraint We remember our earlier notation Imh (x) = 1 (h (h) 6 = hm (x) 6 (x) x (x) x (h). Consider the solution (OP) using an unmarked sample S of size and note that step 3 is equivalent to a minh (h) -minh (h) -H bm (h) \u2212 E [Imh (X) -X) -X) -X (56) = arg minh (H) 2 (Xi \u2212 1)."}, {"heading": "G Experimental Details", "text": "Here we provide more details about the experiments. G.1 Datasets Table 1 gives details about the 23 binary classification datasets used in our experiments (where n is the number of examples, d is the number of characters, s is the average number of non-zero characters per example, and r is the ratio of the minority class). G.2 Hyper-Parameter Settings We start with the actual hyper parameters used by OAC."}], "references": [{"title": "Active and passive learning of linear separators under log-concave distributions", "author": ["Maria-Florina Balcan", "Phil Long"], "venue": "In Conference on Learning Theory,", "citeRegEx": "Balcan and Long.,? \\Q2013\\E", "shortCiteRegEx": "Balcan and Long.", "year": 2013}, {"title": "Agnostic active learning", "author": ["Maria-Florina Balcan", "Alina Beygelzimer", "John Langford"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "Balcan et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2006}, {"title": "Margin based active learning", "author": ["Maria-Florina Balcan", "Andrei Broder", "Tong Zhang"], "venue": "In Proceedings of the 20th annual conference on Learning theory,", "citeRegEx": "Balcan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2007}, {"title": "Gaussian and Rademacher complexities: Risk bounds and structural results", "author": ["P. Bartlett", "S. Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bartlett and Mendelson.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett and Mendelson.", "year": 2002}, {"title": "Importance weighted active learning", "author": ["A. Beygelzimer", "S. Dasgupta", "J. Langford"], "venue": "In ICML,", "citeRegEx": "Beygelzimer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2009}, {"title": "Agnostic active learning without constraints", "author": ["A. Beygelzimer", "D. Hsu", "J. Langford", "T. Zhang"], "venue": "In NIPS,", "citeRegEx": "Beygelzimer et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2010}, {"title": "Minimax bounds for active learning", "author": ["R.M. Castro", "R.D. Nowak"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Castro and Nowak.,? \\Q2008\\E", "shortCiteRegEx": "Castro and Nowak.", "year": 2008}, {"title": "Improving generalization with active learning", "author": ["D. Cohn", "L. Atlas", "R. Ladner"], "venue": "Machine Learning,", "citeRegEx": "Cohn et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 1994}, {"title": "Coarse sample complexity bounds for active learning", "author": ["S. Dasgupta"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Dasgupta.,? \\Q2005\\E", "shortCiteRegEx": "Dasgupta.", "year": 2005}, {"title": "A general agnostic active learning algorithm", "author": ["S. Dasgupta", "D. Hsu", "C. Monteleoni"], "venue": "In NIPS,", "citeRegEx": "Dasgupta et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2007}, {"title": "On tail probabilities for martingales", "author": ["D.A. Freedman"], "venue": "The Annals of Probability,", "citeRegEx": "Freedman.,? \\Q1975\\E", "shortCiteRegEx": "Freedman.", "year": 1975}, {"title": "Theoretical Foundations of Active Learning", "author": ["S. Hanneke"], "venue": "PhD thesis,", "citeRegEx": "Hanneke.,? \\Q2009\\E", "shortCiteRegEx": "Hanneke.", "year": 2009}, {"title": "Theory of disagreement-based active learning", "author": ["Steve Hanneke"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Hanneke.,? \\Q2014\\E", "shortCiteRegEx": "Hanneke.", "year": 2014}, {"title": "A generalization of sampling without replacement from a finite universe", "author": ["D.G. Horvitz", "D.J. Thompson"], "venue": "J. Amer. Statist. Assoc.,", "citeRegEx": "Horvitz and Thompson.,? \\Q1952\\E", "shortCiteRegEx": "Horvitz and Thompson.", "year": 1952}, {"title": "Algorithms for Active Learning", "author": ["Daniel J. Hsu"], "venue": "PhD thesis, University of California at San Diego,", "citeRegEx": "Hsu.,? \\Q2010\\E", "shortCiteRegEx": "Hsu.", "year": 2010}, {"title": "On the generalization ability of online strongly convex programming algorithms", "author": ["S.M. Kakade", "A. Tewari"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Kakade and Tewari.,? \\Q2009\\E", "shortCiteRegEx": "Kakade and Tewari.", "year": 2009}, {"title": "On the complexity of linear prediction: Risk bounds, margin bounds, and regularization", "author": ["Sham M Kakade", "Karthik Sridharan", "Ambuj Tewari"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Kakade et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2009}, {"title": "Online importance weight aware updates", "author": ["Nikos Karampatziakis", "John Langford"], "venue": "UAI", "citeRegEx": "Karampatziakis and Langford.,? \\Q2011\\E", "shortCiteRegEx": "Karampatziakis and Langford.", "year": 2011}, {"title": "Rademacher complexities and bounding the excess risk in active learning", "author": ["Vladimir Koltchinskii"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Koltchinskii.,? \\Q2010\\E", "shortCiteRegEx": "Koltchinskii.", "year": 2010}, {"title": "Optimal aggregation of classifiers in statistical learning", "author": ["A.B. Tsybakov"], "venue": "Ann. Statist.,", "citeRegEx": "Tsybakov.,? \\Q2004\\E", "shortCiteRegEx": "Tsybakov.", "year": 2004}, {"title": "Beyond disagreement-based agnostic active learning", "author": ["Chicheng Zhang", "Kamalika Chaudhuri"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Zhang and Chaudhuri.,? \\Q2014\\E", "shortCiteRegEx": "Zhang and Chaudhuri.", "year": 2014}, {"title": "By a simple variant of the argument by Bartlett and", "author": [], "venue": "\u039b\u03b5}", "citeRegEx": "F,? \\Q2002\\E", "shortCiteRegEx": "F", "year": 2002}], "referenceMentions": [{"referenceID": 7, "context": "1 Introduction How can you best learn a classifier given a label budget? Active learning approaches are known to yield exponential improvements over supervised learning under strong assumptions [Cohn et al., 1994].", "startOffset": 194, "endOffset": 213}, {"referenceID": 6, "context": "This results in a poor label complexity, well short of information-theoretic limits [Castro and Nowak, 2008] even for general robust solutions [Zhang and Chaudhuri, 2014].", "startOffset": 84, "endOffset": 108}, {"referenceID": 20, "context": "This results in a poor label complexity, well short of information-theoretic limits [Castro and Nowak, 2008] even for general robust solutions [Zhang and Chaudhuri, 2014].", "startOffset": 143, "endOffset": 170}, {"referenceID": 11, "context": "The label complexity bound depends on the disagreement coefficient [Hanneke, 2009], which does not completely capture the advantage of the algorithm.", "startOffset": 67, "endOffset": 82}, {"referenceID": 0, "context": "Under much weaker assumptions, streaming-based agnostic active learning [Balcan et al., 2006, Beygelzimer et al., 2009, 2010, Dasgupta et al., 2007, Zhang and Chaudhuri, 2014] is particularly appealing since it is known to work for any classifier representation and any label noise distribution with an i.i.d. data source.1 Here, a learning algorithm decides for each unlabeled example in sequence whether or not to request a label, never revisiting this decision. Restated then: What is the best possible active learning algorithm which works for any classifier representation, any label noise distribution, and is computationally tractable? Computational tractability is a critical concern, because most known algorithms for this setting [e.g., Balcan et al., 2006, Koltchinskii, 2010, Zhang and Chaudhuri, 2014] require explicit enumeration of classifiers, implying exponentially-worse computational complexity compared to typical supervised learning algorithms. Active learning algorithms based on empirical risk minimization (ERM) oracles [Beygelzimer et al., 2009, 2010, Hsu, 2010] can overcome this intractability by using passive classification algorithms as the oracle to achieve a computationally acceptable solution. Achieving generality, robustness, and acceptable computation has a cost. For the above methods [Beygelzimer et al., 2009, 2010, Hsu, 2010], a label is requested on nearly every unlabeled example where two empirically good classifiers disagree. This results in a poor label complexity, well short of information-theoretic limits [Castro and Nowak, 2008] even for general robust solutions [Zhang and Chaudhuri, 2014]. Until now. In Section 3, we design a new algorithm ACTIVE COVER (AC) for constructing query probability functions that minimize the probability of querying inside the disagreement region\u2014the set of points where good classifiers disagree\u2014and never query otherwise. This requires a new algorithm that maintains a parsimonious cover of the set of empirically good classifiers. The cover is a result of solving an optimization problem (in Section 5) specifying the properties of a desirable query probability function. The cover size provides a practical knob between computation and label complexity, as demonstrated by the complexity analysis we present in Section 5. In Section 4, we provider our main results which demonstrate that AC effectively maintains a set of good classifiers, achieves good generalization error, and has a label complexity bound tighter than previous approaches. The label complexity bound depends on the disagreement coefficient [Hanneke, 2009], which does not completely capture the advantage of the algorithm. In Appendix 4.2.2, we provide an example of a hard active learning problem where AC is 1See the monograph of Hanneke [2014] for an overview of the existing literature, including alternative settings where additional assumptions are placed on the data source (e.", "startOffset": 73, "endOffset": 2805}, {"referenceID": 4, "context": "In the IWAL framework [Beygelzimer et al., 2009], a decision whether or not to query a label is made randomly: the learner picks a probability p \u2208 [0, 1], and queries the label with that probability.", "startOffset": 22, "endOffset": 48}, {"referenceID": 13, "context": "Whenever p > 0, an unbiased error estimate can be produced using inverse probability weighting [Horvitz and Thompson, 1952].", "startOffset": 95, "endOffset": 123}, {"referenceID": 14, "context": "This is most easily seen for Oracular CAL [Hsu, 2010] which queries with probability 1 if X \u2208 Dm and 0 otherwise.", "startOffset": 42, "endOffset": 53}, {"referenceID": 5, "context": "A similar argument can also be made for the IWAL method [Beygelzimer et al., 2010], which also queries in the disagreement region with probability 1, and hence suffers from the same suboptimality compared to our choice.", "startOffset": 56, "endOffset": 82}, {"referenceID": 19, "context": "One intuitive condition that controls the errors within the disagreement region is the low-noise condition of Tsybakov [2004], which asserts that there exist constants \u03b6 > 0 and 0 < \u03c9 \u2264 1 such that Pr(h(X) 6= h\u2217(X)) \u2264 \u03b6 \u00b7 (err(h)\u2212 err(h\u2217))\u03c9, \u2200h \u2208 H such that err(h)\u2212 err(h\u2217) \u2264 \u03b50.", "startOffset": 110, "endOffset": 126}, {"referenceID": 6, "context": "It is worth noting that the rates obtained here are known to be unimprovable for even passive learning under the Tsybakov noise condition Castro and Nowak [2008].5 Consequently, there is no loss of statistical efficiency in using our active learning approach.", "startOffset": 138, "endOffset": 162}, {"referenceID": 12, "context": "1 Disagreement-based label complexity bounds In order to quantify the extent of gains over passive learning, we measure the hardness of our problem using the disagreement coefficient [Hanneke, 2014], which is defined as 5\u03c9 in our statement of the low-noise condition (10) corresponds to 1/\u03ba in the results of Castro and Nowak [2008].", "startOffset": 183, "endOffset": 198}, {"referenceID": 6, "context": "1 Disagreement-based label complexity bounds In order to quantify the extent of gains over passive learning, we measure the hardness of our problem using the disagreement coefficient [Hanneke, 2014], which is defined as 5\u03c9 in our statement of the low-noise condition (10) corresponds to 1/\u03ba in the results of Castro and Nowak [2008].", "startOffset": 309, "endOffset": 333}, {"referenceID": 5, "context": "We contrast this with the label complexity of IWAL [Beygelzimer et al., 2010], which grows as \u03b8 \u221a n independent of err(h\u2217).", "startOffset": 51, "endOffset": 77}, {"referenceID": 14, "context": "A much closer comparison is with respect to the Oracular CAL algorithm [Hsu, 2010], which does have a dependence on \u221a nerr(h\u2217) in the second term, but has a worse dependence on \u03b8.", "startOffset": 71, "endOffset": 82}, {"referenceID": 14, "context": "Indeed the proofs of these results are entirely based on the fact that we do not query outside the disagreement region, a property shared by the previous Oracular CAL algorithm [Hsu, 2010].", "startOffset": 177, "endOffset": 188}, {"referenceID": 6, "context": "The label complexity obtained above is indeed optimal in terms of the dependence on n, the number of unlabeled examples, matching known information-theoretic rates of Castro and Nowak [2008]. This can be seen since the regret from Corollary 2 falls as a function of the number of queries at a rate of \u00d5(q \u2212 1 2(1\u2212\u03c9) m log(|H|/\u03b4)) after m epochs, where qm is the number of label queries.", "startOffset": 167, "endOffset": 191}, {"referenceID": 6, "context": "The label complexity obtained above is indeed optimal in terms of the dependence on n, the number of unlabeled examples, matching known information-theoretic rates of Castro and Nowak [2008]. This can be seen since the regret from Corollary 2 falls as a function of the number of queries at a rate of \u00d5(q \u2212 1 2(1\u2212\u03c9) m log(|H|/\u03b4)) after m epochs, where qm is the number of label queries. This is indeed optimal according to the lower bounds of Castro and Nowak [2008], after recalling that \u03c9 = 1/\u03ba in their results.", "startOffset": 167, "endOffset": 467}, {"referenceID": 8, "context": "Starting with the first issue, we follow Dasgupta et al. [2007] who cleverly observed that x \u2208 Dm can be efficiently determined using a single call to an ERM oracle.", "startOffset": 41, "endOffset": 64}, {"referenceID": 17, "context": "See Appendix F of [Karampatziakis and Langford, 2011] for details.", "startOffset": 18, "endOffset": 53}, {"referenceID": 17, "context": "The specific importance weighted oracle we use is a reduction to online importance-weighted logistic regression [Karampatziakis and Langford, 2011] implemented in Vowpal Wabbit (VW).", "startOffset": 112, "endOffset": 147}, {"referenceID": 17, "context": "The specific importance weighted oracle we use is a reduction to online importance-weighted logistic regression [Karampatziakis and Langford, 2011] implemented in Vowpal Wabbit (VW). Instead of computing the query probability function by solving a batch optimization problem as in Step 5 of AC, OAC maintains a fixed number l of classifiers that are intended to be a cover of the set of good classifiers. On every new example, this cover undergoes a sequence of online, importance weighted updates (Steps 7 to 13 of OAC), which are meant to approximate the coordinate ascent steps in Algorithm 2. The importance structure (16) is derived from (57), accounting for the fact that the algorithm simply uses the incoming stream of examples to estimate EX [\u00b7] rather than a separate unlabeled sample. The same approximation is also present in the updates (17) and (18), which are online estimates of the numerator and the denominator of the additive coordinate update in Step 7 of Algorithm 2. Because (17) is an online estimate, we need to explicitly enforce non-negativity. Finally, Steps 9 to 14 of AC and Steps 14 to 26 of OAC perform the querying of labels. As pointed out in Section 5, the test in Step 16 of OAC is done via an online technique detailed in Appendix F of Karampatziakis and Langford [2011].", "startOffset": 113, "endOffset": 1307}, {"referenceID": 4, "context": "\u2022 IWAL: A slight modification of Algorithm 1 of Beygelzimer et al. [2010], which performs importance-weighted sampling of labels and maintains an unbiased estimate of classification error.", "startOffset": 48, "endOffset": 74}, {"referenceID": 4, "context": "\u2022 IWAL: A slight modification of Algorithm 1 of Beygelzimer et al. [2010], which performs importance-weighted sampling of labels and maintains an unbiased estimate of classification error. In computing the query probability, rather than using a conservative, problem-independent threshold as in Beygelzimer et al. [2010], we use the following error-dependent quantity: \u221a C0 log k k \u2212 1 ek\u22121 + C0 log k k \u2212 1 , (22) where ek\u22121 is the importance-weighted error estimate after the algorithm processes k \u2212 1 examples.", "startOffset": 48, "endOffset": 321}, {"referenceID": 4, "context": "\u2022 IWAL: A slight modification of Algorithm 1 of Beygelzimer et al. [2010], which performs importance-weighted sampling of labels and maintains an unbiased estimate of classification error. In computing the query probability, rather than using a conservative, problem-independent threshold as in Beygelzimer et al. [2010], we use the following error-dependent quantity: \u221a C0 log k k \u2212 1 ek\u22121 + C0 log k k \u2212 1 , (22) where ek\u22121 is the importance-weighted error estimate after the algorithm processes k \u2212 1 examples. C0 is the only active learning hyper-parameter. The query probability is set to 1 if the error difference Gk, defined in Step 2 of Algorithm 1 of Beygelzimer et al. [2010], is smaller than the threshold (22), and otherwise a decreasing function of Gk.", "startOffset": 48, "endOffset": 686}, {"referenceID": 14, "context": "\u2022 ORA-I: An Oracular-CAL [Hsu, 2010] style variant of Algorithm 3.", "startOffset": 25, "endOffset": 36}, {"referenceID": 14, "context": "\u2022 ORA-II: An Oracular-CAL [Hsu, 2010] style variant of IWAL, where the query probability is set to 1 if the error difference Gk, defined in Step 2 of Algorithm 1 of Beygelzimer et al.", "startOffset": 26, "endOffset": 37}, {"referenceID": 4, "context": "\u2022 ORA-II: An Oracular-CAL [Hsu, 2010] style variant of IWAL, where the query probability is set to 1 if the error difference Gk, defined in Step 2 of Algorithm 1 of Beygelzimer et al. [2010], is smaller than the threshold \u221a C0 log k k \u2212 1 ek\u22121 + C0 log k k \u2212 1 .", "startOffset": 165, "endOffset": 191}], "year": 2017, "abstractText": "We develop a new active learning algorithm for the streaming setting satisfying three important properties: 1) It provably works for any classifier representation and classification problem including those with severe noise. 2) It is efficiently implementable with an ERM oracle. 3) It is more aggressive than all previous approaches satisfying 1 and 2. To do this we create an algorithm based on a newly defined optimization problem and analyze it. We also conduct the first experimental analysis of all efficient agnostic active learning algorithms, discovering that this one is typically better across a wide variety of datasets and label complexities.", "creator": "LaTeX with hyperref package"}}}