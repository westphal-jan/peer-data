{"id": "1506.08928", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Jun-2015", "title": "Fast ADMM Algorithm for Distributed Optimization with Adaptive Penalty", "abstract": "We propose new methods to speed up convergence of the Alternating Direction Method of Multipliers (ADMM), a common optimization tool in the context of large scale and distributed learning. The proposed method accelerates the speed of convergence by automatically deciding the constraint penalty needed for parameter consensus in each iteration. In addition, we also propose an extension of the method that adaptively determines the maximum number of iterations to update the penalty. We show that this approach effectively leads to an adaptive, dynamic network topology underlying the distributed optimization. The utility of the new penalty update schemes is demonstrated on both synthetic and real data, including a computer vision application of distributed structure from motion.", "histories": [["v1", "Tue, 30 Jun 2015 03:37:07 GMT  (1009kb,D)", "http://arxiv.org/abs/1506.08928v1", "8 pages manuscript, 2 pages appendix, 5 figures"]], "COMMENTS": "8 pages manuscript, 2 pages appendix, 5 figures", "reviews": [], "SUBJECTS": "cs.LG cs.CV math.OC", "authors": ["changkyu song", "sejong yoon", "vladimir pavlovic"], "accepted": true, "id": "1506.08928"}, "pdf": {"name": "1506.08928.pdf", "metadata": {"source": "CRF", "title": "Fast ADMM Algorithm for Distributed Optimization with Adaptive Penalty", "authors": ["Changkyu Song", "Sejong Yoon", "Vladimir Pavlovic"], "emails": ["vladimir}@cs.rutgers.edu"], "sections": [{"heading": "1 Introduction", "text": "The need for algorithms and methods that can handle large data in a distributed environment has increased significantly in recent years. Specifically, such settings can occur in two prototypical scenarios: (a) induced distributed data: distribute and parallelise arithmetically sophisticated optimization tasks in conjunction with a distributed model; and (b) intrinsically distributed data: data is collected in a connected network of sensors (e.g. mobile devices, camera networks), where some or all of the computer nodes can be performed without the need for centralized data to be merged. Several distributed learning approaches have been proposed to meet these needs (e.g. the alternative directional method of the multiplier (ADMM)."}, {"heading": "2 Problem Description and Related Works", "text": "The problem we are looking at in this paper can be formulated as a consensus-based optimization problem [11]. A general consensus-based optimization problem can be written [11]. A general consensus-based optimization problem can be written [11]. [14] This problem is typically a reformulation of a centralized optimization problem that has a number of optimal parameters. [14] The sum of the convex objective functions is minimized. [14] The sum of objective functions is typically a reformulation of the centralized optimization problem. [14] The objective results are presented in a decomposable objective f (8). [16] Given the consensus formulation, the original problem can be solved by decomposing the problem into J subproblems so that J processors can work together to solve the overall problem by changing the equality constraint to a globally divided parameter."}, {"heading": "2.1 Convergence Speed of ADMM", "text": "The currently known convergence rate of ADMM is O (1 / T), where T is the number of iterations (15). Although O (1 / T) is the best known limit, it has been empirically observed that ADMM converges faster in many applications. Furthermore, the computation time per iteration can dominate the entire runtime of the algorithm. Therefore, many acceleration techniques have been proposed for ADMM that are application-specific. Another way is to find a predictor-corrector step for the coordinate lineage [16], using some available acceleration methods such as [17]. It guarantees square convergence for strongly convex fi (\u00b7). Another way is to replace the gradient downward optimization with a stochastic one [18, 19]. This approach has recently gained attention as it significantly reduces the computation per iteration. However, these methods usually do not require the coordination center node without further ado."}, {"heading": "3 Proposed Methods", "text": "We present our proposed ADMM fine update systems in three steps. First, we extend the above-mentioned update scheme from (4) to be applicable to fully decentralized environments. Next, we propose the novel strategy for accelerating ADMM parameters that does not require manual adjustment of \u03c4 t. Finally, we extend the strategy so that we can automatically select the maximum number of penalty update steps."}, {"heading": "3.1 ADMM with Varying Penalty (ADMM-VP)", "text": "To expand (4) for a fully distributed environment, we first introduce throuti, the penalty for the i-th node for the t-th iteration. Next, however, we must calculate the local primary and dual residuals for each i-node. In the fully distributed learning framework of [13, 14], the dual auxiliary variable disappears from the derivative. However, to calculate the residuals, we must track the dual variable, which is essentially the average of local estimates, explicitly via iterations. The squared residual norms for the i-th node are defined after the derivative. However, to calculate the residual values, we must track the dual variables, which are essentially the mean of local estimates, explicitly via iterations. The squared residual norms for the i-th node are defined as such."}, {"heading": "3.2 ADMM with Adaptive Penalty (ADMM-AP)", "text": "We expand \u03b7i by introducing a bidirectional graph with a penalty frame parameter \u03b7ij specific to directed edge eij from node i to j. The modified extended Lagrangian Li is similar to (3) except that we replace a penalty frame with a penalty frame. Furthermore, the penalty frame controls the amount that each restriction contributes to the local minimization problem. The penalty frame parameter \u03b7ij is determined by evaluating the maximum number of iterations of node j with the objective function fi (\u00b7) of the node i ashion i + 1ij = (1 + result tij) if t < tmax\u03b70, otherwise (6), where tmax is the maximum number of iterations for updating as proposed in [10] and that we will not achieve the objective objective objective objective."}, {"heading": "3.3 ADMM with Network Adaptive Penalty (ADMM-NAP)", "text": "In order to extend the proposed method for automatically determining the maximum number of penalty updates, the penalty update for the ADMM is slowly being extended. (9) Figure 1c shows how the proposed model has structures other than centralized and traditional distributed models, and how nodes can change their parameters over network.In addition to the adaptive penalty update, the inequality condition in the summation of \u03c4uij, u = 1.. t must encode the issued budget so that the edge eij can change its upper limit. All nodes have their upper limit T tij, and each time it makes a change to the edge, it must pay exactly the amount it has changed. If the edge has changed too much, the updating strategy will prevent the edge from changing the edge."}, {"heading": "3.4 Combined Update Strategies (ADMM-VP + AP, ADMM-VP + NAP)", "text": "Based on (4) and the proposed update programs (6) and (9), we can easily develop a combined update strategy by replacing (4) with (4). Based on preliminary experiments, we have determined that this replacement is of little use. Instead, we propose another punitive update strategy combining ADMM-VP and ADMM-AP as\u03b7t + 1ij = \u03b7tij \u00b7 (1 + 5 tij) \u00b7 2 if we combine (1 + 2 tij) \u00b7 (1 + 5 tij) \u00b7 (1 / 2) if we combine (12) what we call ADMM-VP + AP. To combine ADMM-VP and ADMM-NAP, we consider the summary state of (9). We call this strategy ADMM-VP + NAP."}, {"heading": "4 Distributed Maximum Likelihood Learning", "text": "In this section, we will show how our method can be applied to an existing distributed learning system in the context of distributed probabilistic principal component analysis (D-PPCA). D-PPCA can be seen as a basic approach to a general matrix factorization task for potentially missing data, with many applications taking place in machine learning."}, {"heading": "4.1 Probabilistic Principal Component Analysis", "text": "The probabilistic PCA (PPCA) [21] has many applications for visual problems, including the structure of movement, dictionary learning, image painting, etc. We limit our attention here to the linear PPCA without loss of generalization. The centralized PPCA is formulated as the task of projecting the source data x according to x = Wz + \u00b5 +, where x-RD is the observation slit vector, z-RM is the latent variable according to z-N (0, I), W-RD \u00b7 M restores the projection matrix that maps x to z, \u00b5-RD allows a non-zero mean value, and the Gaussian observation noise \u2212 X N (0, a-1I) with the noise precision a. If a \u2212 1 = 0, PPCA restores the standard PCA. The posterior estimation of the latent variable z \u2212 expander \u2212 \u2212 taking into account the observation x isp (x | x) or (M, >, W, W, W, W, W, W \u2212 W, W, W \u2212 W, W \u2212 W, W \u2212 W \u2212 W, W \u2212 W \u2212 W, W \u2212 W \u2212 W \u2212, W \u2212 W, W \u2212 W \u2212 W \u2212, W \u2212 W \u2212 W \u2212, W \u2212 W, W \u2212 W \u2212 W, W \u2212 W \u2212 W, W \u2212 W \u2212 W \u2212, W \u2212 W \u2212 W \u2212, W, W \u2212 W, W \u2212 W \u2212 W, W \u2212 W, W \u2212 W, W \u2212 W, W \u2212 W, W \u2212, W \u2212 W, W, W, W \u2212 W-RD, W-RD, W-RD, W-RD-RD, W-RD-RD-RD-RD-RD-RD-RD-RD-X-RD-RD-RD-RD-RD-RD-RD-RD-RD-RD is the observation slit vector with the z-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N-N"}, {"heading": "4.2 Distributed PPCA", "text": "The distributed extension of the PPCA (D-PPCA) [14] can be derived by applying ADMM to the above-mentioned centralized PPCA model. Each node learns its local copy of the PPCA parameters with its set of local observations Xi = {xin | n = 1.. Ni}, where xin denotes the n-th observation in the i-th node and Ni is the number of observations available in the node. Subsequently, they exchange the parameters with the help of the Lagrange multipliers and impose consensus constraints on the parameters. Globally limited optimization is the compilation of local parameters and vice versa."}, {"heading": "4.3 D-PPCA with Network Adpative Penalty", "text": "The advanced Lagrange application of the proposed ADMM with Network Adpative Penalty is similar [14], except that \u03b5ij. with \u03bbi, \u03b3i, \u03b2i Lagrange multipliers for the PPCA parameters for the node i. The adaptive Penalty Constraint \u03b7tij dynamically controls the speed of parameter propagation, so that the general optimization converges empirically faster than [14]. Since the update formulas for the three parameters are similar, we present the \u00b5i update as an example. First, \u00b5i can be updated as a centralized counterpart [21]. The M step is similar to [14], unless we use separate \u03b7ij for each edge. Since the update formulas for the three parameters are similar, we can present the \u00b5i update as an example."}, {"heading": "5 Experiments", "text": "First, we analyze and compare the proposed methods (ADMM-VP, ADMM-AP, ADMM-NAP, ADMM-VP + AP, ADMM-VP + NAP) with the basic method using synthetic data. Next, we apply our method to a distributed structure of motion problems using two real benchmark datasets. For the baseline, we compare with the standard ADMM-based D-PPCA [14], which is referred to as ADMM."}, {"heading": "5.1 Synthetic Data", "text": "We generated 500 samples of 20-dimensional observations from a 5-dim subspace according to N (0, I), with Gaussian measurement noise following N (0, 0.2 \u00b7 I. For the distributed settings, the samples are uniformly assigned to each node. All experiments are performed with 20 independent random initializations. We investigated the effects of different graph topologies and different graph sizes. We tested three network topologies: complete, ring, and cluster (a connected graph consists of two complete graphs associated with an edge). For graph size, we tested 12, 16, and 20 node settings. The three best graphs in Fig. 2 show the results over the different number of nodes, while graph topology is specified as a complete graph."}, {"heading": "5.2 Distributed Affine Structure from Motion", "text": "The aim is to evaluate the 3D structure of the objects as well as the camera movement, defining the input matrix as 2 \u00b0 C. For the detailed experimental settings, we refer to the number of points. The use of PCs in the camera is inevitable."}, {"heading": "6 Conclusion", "text": "Unlike previous approaches, our adaptive penalty update methods ADMM-AP and ADMM-NAP are not dependent on the parameters that require manual adjustment, and using both synthetic and real data experiments, we demonstrated the empirical effectiveness of the methods across the baseline. In addition, we found that the performance of ADMM-VP decreases with poorly connected charts, and in these cases, ADMM-AP and ADMM-NAP can be useful. The proposed methods leave some room for improvement. For the problems where the standard ADMM can converge fast enough, the proposed methods show less than significant gains. A better convergence criterion could help to stop the proposed algorithms in earlier iterations (e.g. a criterion to stop algorithms that can remove long tails in Fig. 2b or Fig. 2c)."}, {"heading": "A D-PPCA with Network Adaptive Penalty", "text": "Here we summarize the distributed probable principal component analysis (D-PPCA) [14] algorithm that has been modified to use the proposed Adaptive Penalty Update Scheme (ADMM-NAP). We follow the notations from the previous sections. D-PPCA with Network Adaptive Penalty Algorithm is summarized in Algorithm 1.Algorithm 1 D-PPCA with Network Adpative PenaltyRequire: For each node I randomly initialize W0i, \u00b50i, a0i and set \u03bb0i = 0, \u03b30i = 0, \u03b7ij = \u03b7 for j-Bi1: for t = 0, 1, 2, \u00b7 \u00b7 \u00b7 up to Broadcast 2: for all i-V do 3: Compute E [zin] and E [zinz > in] 4: Compute Wt + 1i, \u00b5 (t + 1) i, a (t + 1) i 5: end for all i-V do: > 1 and E [zin], \u00b5 in [zt] and 1 for all [zin]."}, {"heading": "B Results on Caltech Turntable Dataset", "text": "We compare the proposed methods ADMM with Varying Penalty (ADMM-VP), ADMM with Adaptive Penalty (ADMM-AP) and ADMM with Network Adaptive Penalty (ADMM-NAP) and their combination (ADMM-VP + AP, ADMM-VP + NAP) with the standard ADMM-based D-PPCA [14] using the same experimental setting. Fig. 4 shows a sample box, features extracted from the box and the centralized SVD-based reconstructed structure that we used as the ground truth. In the thesis we show the results of Standing.Fig. 5 summarizes the results of the remaining four objects. The results and analyses explained in the main paper on the Standing object also apply to these four remaining objects. First, we compare the upper and middle rows."}], "references": [{"title": "Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers", "author": ["Stephen Boyd", "Neal Parikh", "Eric Chu", "Borja Peleato", "Jonathan Eckstein"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2010}, {"title": "Fixed-rank representation for unsupervised visual learning", "author": ["Risheng Liu", "Zhouchen Lin", "Fernando De la Torre", "Zhixun Su"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Non-negative low rank and sparse graph for semi-supervised learning", "author": ["Liansheng Zhuang", "Haoyuan Gao", "Zhouchen Lin", "Yi Ma", "Xin Zhang", "Nenghai Yu"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "A Convex Optimization Framework for Active Learning", "author": ["Ehsan Elhamifar", "Guillermo Sapiro", "Allen Y. Yang", "S. Shankar Sastry"], "venue": "In IEEE International Conference on Computer Vision,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "Learning by associating ambiguously labeled images", "author": ["Zinan Zeng", "Shijie Xiao", "Kui Jia", "Tsung-Han Chan", "Shenghua Gao", "Dong Xu", "Yi Ma"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Robust estimation of 3d human poses from a single image", "author": ["Chunyu Wang", "Yizhou Wang", "Zhouchen Lin", "Alan L. Yuille", "Wen Gao"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Recognizing complex events in videos by learning key static-dynamic evidences", "author": ["Kuan-Ting Lai", "Dong Liu", "Ming-Syan Chen", "Shih-Fu Chang"], "venue": "In Proceedings of the European Conference on Computer Vision (ECCV),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Fast and Exact: ADMM-Based Discriminative Shape Segmentation with Loopy Part Models", "author": ["H. Boussaid", "I. Kokkinos"], "venue": "In Computer Vision and Pattern Recognition (CVPR), IEEE Conference on,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Distributed Non-Convex ADMMinference in Large-scale Random Fields", "author": ["Ondrej Miksik", "Vibhav Vineet", "Patrick P\u00e9rez", "Philip H.S. Torr"], "venue": "In British Machine Vision Conference (BMVC),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Alternating Direction Method with Self-Adaptive Penalty Parameters for Monotone Variational Inequalities", "author": ["B.S. He", "H. Yang", "S.L. Wang"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2000}, {"title": "Parallel and Distributed Computation: Numerical Methods", "author": ["D.P. Bertsekas", "J.N. Tsitsiklis"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1989}, {"title": "Pattern Recognition and Machine Learning", "author": ["Christopher Bishop"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Distributed Clustering Using Wireless Sensor Networks", "author": ["Pedro A. Forero", "Alfonso Cano", "Georgios B. Giannakis"], "venue": "IEEE Journal of Selected Topics in Signal Processing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2011}, {"title": "Distributed probabilistic learning for camera networks with missing data", "author": ["Sejong Yoon", "Vladimir Pavlovic"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "On the O(1/n) Convergence Rate of the Douglas-Rachford Alternating Direction Method", "author": ["Bingsheng He", "Xiaoming Yuan"], "venue": "SIAM Journal of Numerical Analysis,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Fast Alternating Direction Optimization Methods", "author": ["Tom Goldstein", "Brendan O\u2019Donoghue", "Simon Setzer", "Richard Baraniuk"], "venue": "SIAM Journal of Imaging Science,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "A method of solving a convex programming problem with convergence rate o(1/k)", "author": ["Yurii Nesterov"], "venue": "Soviet Math. Dokl.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1983}, {"title": "Stochastic alternating direction method of multipliers", "author": ["H. Ouyang", "N. He", "L. Tran", "A. Gray"], "venue": "Proceedings of the 30th International Conference on Machine Learning (ICML),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Dual averaging and proximal gradient descent for online alternating direction multiplier method", "author": ["T. Suzuki"], "venue": "In Proceedings of the 30th International Conference on Machine Learning (ICML),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Monotone operators and the proximal point algorithm", "author": ["R.T. Rockafellar"], "venue": "SIAM Journal on Control and Optimization,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1976}, {"title": "Probabilistic Principal Component Analysis", "author": ["Michael E. Tipping", "Chris M. Bishop"], "venue": "Journal of the Royal Statistical Society, Series B,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1999}, {"title": "Evaluation of Features Detectors and Descriptors based on 3D Objects", "author": ["Pierre Moreels", "Pietro Perona"], "venue": "International Journal of Computer Vision,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2007}, {"title": "A Benchmark for the Comparison of 3-D Motion Segmentation Algorithms", "author": ["Roberto Tron", "Rene Vidal"], "venue": "In IEEE International Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2007}, {"title": "Distributed Computer Vision Algorithms Through Distributed Averaging", "author": ["Roberto Tron", "Rene Vidal"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}], "referenceMentions": [{"referenceID": 0, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 69, "endOffset": 72}, {"referenceID": 1, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 253, "endOffset": 277}, {"referenceID": 2, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 253, "endOffset": 277}, {"referenceID": 3, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 253, "endOffset": 277}, {"referenceID": 4, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 253, "endOffset": 277}, {"referenceID": 5, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 253, "endOffset": 277}, {"referenceID": 6, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 253, "endOffset": 277}, {"referenceID": 7, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 253, "endOffset": 277}, {"referenceID": 8, "context": "In particular, the alternating direction method of multiplier (ADMM) [1] is an optimization technique that has been very often used in computer vision and machine learning to handle model estimation and learning in either of the two large data settings [2, 3, 4, 5, 6, 7, 8, 9].", "startOffset": 253, "endOffset": 277}, {"referenceID": 9, "context": "Our method extends an acceleration approach for ADMM [10] by an efficient variable penalty parameter update strategy.", "startOffset": 53, "endOffset": 57}, {"referenceID": 10, "context": "2 Problem Description and Related Works The problem we consider in this paper can be formulated as a consensus-based optimization problem [11].", "startOffset": 138, "endOffset": 142}, {"referenceID": 0, "context": "The optimization can be approached efficiently by exploiting the alternating direction method of multiplier (ADMM) [1].", "startOffset": 115, "endOffset": 118}, {"referenceID": 8, "context": "Edges in this graph depict functional (in)dependencies among variables, commonly found in representations such as Markov Random Fields [9] or Factor Graphs [12].", "startOffset": 135, "endOffset": 138}, {"referenceID": 11, "context": "Edges in this graph depict functional (in)dependencies among variables, commonly found in representations such as Markov Random Fields [9] or Factor Graphs [12].", "startOffset": 156, "endOffset": 160}, {"referenceID": 12, "context": "In this context, to fully decompose f(\u00b7) and eliminate the need for a processing center completely, one can introduce auxiliary variables \u03c1ij on every edge to break the dependency between \u03b8i and \u03b8j [13, 14] as shown in Fig.", "startOffset": 198, "endOffset": 206}, {"referenceID": 13, "context": "In this context, to fully decompose f(\u00b7) and eliminate the need for a processing center completely, one can introduce auxiliary variables \u03c1ij on every edge to break the dependency between \u03b8i and \u03b8j [13, 14] as shown in Fig.", "startOffset": 198, "endOffset": 206}, {"referenceID": 14, "context": "1 Convergence Speed of ADMM The currently known convergence rate of ADMM is O(1/T ) where T is the number of iterations [15].", "startOffset": 120, "endOffset": 124}, {"referenceID": 15, "context": "One way is to come up with a predictor-corrector step for the coordinate descent [16] using some available acceleration method such as [17].", "startOffset": 81, "endOffset": 85}, {"referenceID": 16, "context": "One way is to come up with a predictor-corrector step for the coordinate descent [16] using some available acceleration method such as [17].", "startOffset": 135, "endOffset": 139}, {"referenceID": 17, "context": "Another way is to replace the gradient descent optimization with a stochastic one [18, 19].", "startOffset": 82, "endOffset": 90}, {"referenceID": 18, "context": "Another way is to replace the gradient descent optimization with a stochastic one [18, 19].", "startOffset": 82, "endOffset": 90}, {"referenceID": 9, "context": "For example, [10] proposed ADMM with self-adaptive penalty, and it improved the convergence speed as well as made its performance less dependent on initial penalty values.", "startOffset": 13, "endOffset": 17}, {"referenceID": 9, "context": "The idea of [10] is to change the constraint penalty taking account of the relative magnitudes of primal and dual residuals of ADMM as follows", "startOffset": 12, "endOffset": 16}, {"referenceID": 0, "context": "The strength of this approach is that conservative changes in the penalty are guaranteed to converge [1, 20].", "startOffset": 101, "endOffset": 108}, {"referenceID": 19, "context": "The strength of this approach is that conservative changes in the penalty are guaranteed to converge [1, 20].", "startOffset": 101, "endOffset": 108}, {"referenceID": 0, "context": "Please refer [1], page 18 and 51 for their definitions.", "startOffset": 13, "endOffset": 16}, {"referenceID": 12, "context": "In the fully distributed learning framework of [13, 14], the dual auxiliary variable vanishes from derivation.", "startOffset": 47, "endOffset": 55}, {"referenceID": 13, "context": "In the fully distributed learning framework of [13, 14], the dual auxiliary variable vanishes from derivation.", "startOffset": 47, "endOffset": 55}, {"referenceID": 0, "context": "Note the difference from the standard residual definitions for consensus ADMM [1], used in (4), where the dual variable is considered as a single, globally accessible variable, \u03b8\u0304 instead of local \u03b8\u0304 i .", "startOffset": 78, "endOffset": 81}, {"referenceID": 9, "context": "Lastly, [10] stopped changing \u03b7 after t > 50.", "startOffset": 8, "endOffset": 12}, {"referenceID": 9, "context": "where t is the maximum number of iterations for the update as proposed in [10] and \u03c4 t ij = \u03bai(\u03b8 t i) \u03bai(\u03b8 t j) \u2212 1 , \u03bai(\u03b8) = ( f t i (\u03b8)\u2212 f i fmax i \u2212 fmin i + 1 ) , (7) f i = max{f t i (\u03b8 i), f t i (\u03b8 j) : j \u2208 Bi} , f i = min{f t i (\u03b8 i), f t i (\u03b8 j) : j \u2208 Bi} .", "startOffset": 74, "endOffset": 78}, {"referenceID": 9, "context": "On the other hand, the convergence property of [10] still holds for the proposed algorithm.", "startOffset": 47, "endOffset": 51}, {"referenceID": 9, "context": "2 of [10], the requirement for the convergence is to satisfy the update ratio to be fixed after", "startOffset": 5, "endOffset": 9}, {"referenceID": 0, "context": "5, 2], which matches with the increase and decrease amount suggested in [1, 10].", "startOffset": 72, "endOffset": 79}, {"referenceID": 9, "context": "5, 2], which matches with the increase and decrease amount suggested in [1, 10].", "startOffset": 72, "endOffset": 79}, {"referenceID": 9, "context": "One may use t = 50 as in [10].", "startOffset": 25, "endOffset": 29}, {"referenceID": 20, "context": "1 Probabilistic Principal Component Analysis The Probabilistic PCA (PPCA) [21] has many applications in vision problems, including structure from motion, dictionary learning, image inpainting, etc.", "startOffset": 74, "endOffset": 78}, {"referenceID": 13, "context": "2 Distributed PPCA The distributed extension of PPCA (D-PPCA) [14] can be derived by applying ADMM to the centralized PPCA model above.", "startOffset": 62, "endOffset": 66}, {"referenceID": 13, "context": "For the details regarding how the decentralized model is optimized, see [14].", "startOffset": 72, "endOffset": 76}, {"referenceID": 13, "context": "3 D-PPCA with Network Adpative Penalty The augmented Lagrangian applying the proposed ADMM with Network Adpative Penalty is similar to [14] except that \u03b7 becomes \u03b7ij .", "startOffset": 135, "endOffset": 139}, {"referenceID": 13, "context": "The adaptive penalty constraint \u03b7 ij controls the speed of parameter propagation dynamically so that the overall optimization empirically converges faster than [14].", "startOffset": 160, "endOffset": 164}, {"referenceID": 12, "context": "One can solve this optimization using the distributed EM approach [13].", "startOffset": 66, "endOffset": 70}, {"referenceID": 20, "context": "The E-step of the D-PPCA is the same as centralized counterpart [21].", "startOffset": 64, "endOffset": 68}, {"referenceID": 13, "context": "The M-step is similar to [14] except we use separate \u03b7ij for each edge.", "startOffset": 25, "endOffset": 29}, {"referenceID": 13, "context": "For the baseline, we compare with the standard ADMM-based D-PPCA [14] denoted as ADMM.", "startOffset": 65, "endOffset": 69}, {"referenceID": 13, "context": "To assess convergence, we compare the relative change of (14) to a fixed threshold (10\u22123 in this case) for the D-PPCA experiments as in [14].", "startOffset": 136, "endOffset": 140}, {"referenceID": 21, "context": "2 Distributed Affine Structure from Motion We tested the performance of our method on five objects of Caltech Turntable [22] and Hopkins 155 [23] dataset as in [14].", "startOffset": 120, "endOffset": 124}, {"referenceID": 22, "context": "2 Distributed Affine Structure from Motion We tested the performance of our method on five objects of Caltech Turntable [22] and Hopkins 155 [23] dataset as in [14].", "startOffset": 141, "endOffset": 145}, {"referenceID": 13, "context": "2 Distributed Affine Structure from Motion We tested the performance of our method on five objects of Caltech Turntable [22] and Hopkins 155 [23] dataset as in [14].", "startOffset": 160, "endOffset": 164}, {"referenceID": 13, "context": "For the detailed experimental setting, refer to [14, 24].", "startOffset": 48, "endOffset": 56}, {"referenceID": 23, "context": "For the detailed experimental setting, refer to [14, 24].", "startOffset": 48, "endOffset": 56}, {"referenceID": 13, "context": "For the Hopkins 155 dataset, we compared methods on 135 objects using the same approach as [14].", "startOffset": 91, "endOffset": 95}, {"referenceID": 13, "context": "A D-PPCA with Network Adaptive Penalty Here we summarize the distributed probabilistic principal component analysis (D-PPCA) [14] algorithm modified to use the proposed network adaptive penalty update scheme (ADMM-NAP).", "startOffset": 125, "endOffset": 129}, {"referenceID": 21, "context": "B Results on Caltech Turntable Dataset We present example image frames from the Caltech Turntable [22] dataset used in [14].", "startOffset": 98, "endOffset": 102}, {"referenceID": 13, "context": "B Results on Caltech Turntable Dataset We present example image frames from the Caltech Turntable [22] dataset used in [14].", "startOffset": 119, "endOffset": 123}, {"referenceID": 13, "context": "We compare the proposed methods, ADMM with Varying Penalty (ADMM-VP), ADMM with Adaptive Penalty (ADMM-AP) and ADMM with Network Adaptive Penalty (ADMM-NAP) and their combination (ADMM-VP + AP, ADMM-VP + NAP) with the standard ADMM based D-PPCA [14] using the same experimental setting.", "startOffset": 245, "endOffset": 249}, {"referenceID": 13, "context": "(e) StorageBin (102 points) Figure 4: The Caltech Turntable dataset objects used in [14] and the centralized SVD-based affine structure from motion result.", "startOffset": 84, "endOffset": 88}], "year": 2015, "abstractText": "We propose new methods to speed up convergence of the Alternating Direction Method of Multipliers (ADMM), a common optimization tool in the context of large scale and distributed learning. The proposed method accelerates the speed of convergence by automatically deciding the constraint penalty needed for parameter consensus in each iteration. In addition, we also propose an extension of the method that adaptively determines the maximum number of iterations to update the penalty. We show that this approach effectively leads to an adaptive, dynamic network topology underlying the distributed optimization. The utility of the new penalty update schemes is demonstrated on both synthetic and real data, including a computer vision application of distributed structure from motion.", "creator": "LaTeX with hyperref package"}}}