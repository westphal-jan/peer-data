{"id": "1507.02528", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Jul-2015", "title": "Faster Convex Optimization: Simulated Annealing with an Efficient Universal Barrier", "abstract": "Interior point methods and random walk approaches have been long considered disparate approaches for convex optimization. We show how simulated annealing, one of the most common random walk algorithms, is equivalent, in a certain sense, to the central path interior point algorithm applied to the entropic universal barrier function. Using this observation we improve the state of the art in polynomial time convex optimization. We give a randomized algorithm for optimization over a convex set, defined by a membership oracle, which improves the state of the art by at most square root of the dimension. This result is based on a new temperature schedule for simulated annealing, inspired by the relationship to the central path following interior point algorithm with the entropic universal barrier function.", "histories": [["v1", "Thu, 9 Jul 2015 14:32:55 GMT  (19kb)", "https://arxiv.org/abs/1507.02528v1", null], ["v2", "Thu, 5 Nov 2015 16:50:41 GMT  (96kb,D)", "http://arxiv.org/abs/1507.02528v2", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG", "authors": ["jacob d abernethy", "elad hazan"], "accepted": true, "id": "1507.02528"}, "pdf": {"name": "1507.02528.pdf", "metadata": {"source": "CRF", "title": "Faster Convex Optimization: Simulated Annealing with an Efficient Universal Barrier", "authors": ["Jacob Abernethy"], "emails": ["jabernet@umich.edu", "ehazan@princeton.edu"], "sections": [{"heading": null, "text": "ar Xiv: 150 7.02 528v 2 [mat h.O C] 5"}, {"heading": "1 Introduction", "text": "We must acknowledge the underlying limitations that require an efficient barrier, namely in practice. These methods are known to perform well in practice and to come with rigorous theoretical guarantees of polynomial term, but with a significant catch we must admit an efficient computable barrier function. Barrier functions are defined as satisfactory different conditions, the Scheme-Scheme-Schema-Scheme-Scheme-Scheme-Scheme-Scheme-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers-Barriers"}, {"heading": "1.1 Preliminaries", "text": "In this paper, terms from probability theory and convex analysis are summarized, with most definitions moved to where they are first used. We try to follow the conventions of internal point iteration, as in the excellent text by Nemirovski [15], and the simulated annealing and random walk notation of [7]. For a certain constant C, we say that a distribution P is C-isotropic if for a vector v-isotropic in relation to P-if1 C-X-X-P [(v > X) 2] \u2264 C-v-v-2.Let P, P \"be two distributions on Rn with means \u00b5, \u00b5.\" We say P is C-isotropic in relation to P-if1 C-X-X-X-X-X-X-X-X [v > X) 2] \u2264 E-X-X-X-X-X-X-X-X-X-X-X-X-X-X-X-X-X [>-X-X-X]."}, {"heading": "1.2 Structure of this paper", "text": "We begin with an overview of random walk methods for optimisation in the next section and introduce the concept of the heat path for simulated annealing. In the following section, the important terms from the methods of the inner point for optimisation and the entropic barrier function are summarised. In Section 4, we formally link the two approaches by proving that the heat path and the central path for the entropic barrier are identical. We start with a new temperature scheme for simulated annealing and the proof of its convergence properties. In the appendix, we describe the KalaiVempala method for analysing the simulated annealing and its main components for completeness."}, {"heading": "2 An Overview of Simulated Annealing", "text": "Consider the following distribution via the set parameters of the entropic barrier, as we will define them in the next section. (3) Consider the following distribution via the set parameters for any input-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector"}, {"heading": "2.1 The heat path for simulated annealing", "text": "Our main result comes from the observation that the method of the inner points following the path has an analogue in the world of the random principle. Simulated annealing involves a carefully selected temperature plan to achieve its goal from an almost uniform distribution. We can imagine all temperature plans to carry out a random process, the alternating mean of which is a single, well-defined curve. For a given convex quantity of K'Rd and objective imbalance, we define the heat path as the following set of points parameterized by temperature t [0, \u221e] as follows: Heat path (t) = E x \u0445 path [x] We can now define the heat path = area content (t). At this point, it is not even clear why this number of points is even a continuous curve in space, let alone an analogous conception in the inner point world. We will return to this equivalence in section 4."}, {"heading": "3 An Overview of Interior Point Methods for Optimization", "text": "Let us now examine the enormous convergence rate (IPMs) to optimize the additional functionality, and in particular the use of the iterative Newton step technique. The first instance of polynomial time algorithms for convex optimization using internal point machinery was the linear programming algorithms of Karmarkar [8]. The groundbreaking book by Nesterov and Nemirovskii [16] is the same to solve the linear optimization problem in equation (1). The intuition behind IPMs is that iterative updating schemes such as the gradient descent to solution (1) may fail because the boundary of K is difficult to manage and \"will move toward descent.\""}, {"heading": "4 The Equivalence of IterativeNewton and SimulatedAnnealing", "text": "We now show that the two previous techniques, the Iterative Newton Method and the Simulated Annealing Method, are in a sense two sides of the same coin. Specifically, if the barrier function is selected appropriately, the task of unifying the sequence of Newton iterations x-1, x-2,... can be regarded exactly as an estimate of the averages for each of the distributions P\u03b81, P\u03b82,... This match helps to unify two very popular optimization methods, but also provides three additional new results: 1. We show that the heat path for simulated annealing is equivalent to the central path with the entropic barrier. 2As said, algorithm 3 requires the determination of the minimizer of the K (\u00b7), but this is not strictly necessary. The convergence rate can be determined as long as a \"reasonable\" starting point x-0 can be equated with the entropic barrier."}, {"heading": "4.1 The Duality of Optimization and Sampling", "text": "We start by paraphrasing our Boltzmann distribution for the exponential family form, where P\u03b8 (x): = exp (\u2212 \u03b8 > x \u2212 A), where A (\u03b8): = log-K exp (\u2212 \u03b8 > x \"), dx.\" (15) Function A (\u00b7), however, is known as the log partition function of the exponential family, and it has several very natural properties in terms of the mean and variance of Pledge: \"A,\" \"E,\" \"E,\" \"E,\" \"E,\" \"E,\" \"E,\" \"E,\" \"\" E, \"\" \"E,\" \"\" E, \".\" (17) We can also appeal to the convex (fennel) duality to obtain the conjugateA, \"\" X \": = sup.P,\" \"E.\" (18) It is easy to state that A, \"the domain of A,\" is exactly the space of A. \""}, {"heading": "4.2 Equivalence of the heat path and central path", "text": "The most appealing observation about the equivalence between random run optimization and the internal point method is the following geometric equivalence of curves. Define the heat path for a given convex quantity of K'Rd and objective \u03b8 as follows: Heat path = 0.0 {heat path (t)} = 0.0 {E x \u00b2 P + t [x]} To see that this heat path is a continuous curve in space, consider the central path function. It is generally known that the central path is a continuous curve in space for each self-conforming barrier function."}, {"heading": "4.3 IPM techniques for sampling and the new schedule", "text": "We prove our main theorems, formally expressed as: Theorem 4th place of the temperature table (> DA = > DA, where R = diam (K) and \u03b8k: = (1 \u2212 1). \u2212 DA (2 \u2212 1). \u2212 DA (2 \u2212 2). \u2212 DA (2 \u2212 2). (DA (6). (6). (6) the theorem 1. algorithm 2. with this plan provides a -approximate solution in time. \u2212 DA (6). (6) is formally proven in the following dilemma, in which decisively the method of the inner point is used, namely Lemma 3.Lemma 5. Consider distributions. \u2212 P (1 + 2). \u2212 PD (1 + 3). (16). Then we have the following limit on the '2 distance between distributions. (2). (2)."}, {"heading": "4.4 Some history on the entropic barrier and the universal barrier for cones", "text": "We note that a cone K is very rare, but a noteworthy example is the PD cone (matrices with all positive eigenvalues). Considering any point x-K, we can define a separate region of K in which the properties of K are set as they were set."}, {"heading": "A An Explanation of Newton\u2019s Method via Reweighting", "text": "With this stochastic approach, however, it is not immediately clear why Newton's method is an appropriate iterative update scheme for optimization. We now provide some evidence along these lines. - Assuming that we have already calculated (an approximation of) x (\u03b8) and that our distribution parameter has been updated to a \"close\" compromise, our goal now is to calculate the new mean x (\u03b8). \u2212 x (\u03b8) = \"K x dPTB\" = \"K x dPTB\" (x) dPTB \"(x) dPTB\" E \"X\" X \"X\" X \"X\" X \"- A\" PTB. \"Consider the last term as a reweighting factor. Now we will redefine the reweighting factor:\" A \"KTB\" \u2212 KTB \u2212 KTB \u2212 \"PTB\" X. \"\u2212 PTB\" X \"PTB\" - > PTB \"-\" PTB. \"Let's think of the last term as the reweighting factor."}, {"heading": "B Proof structure of the Kalai-Vempala theorem", "text": "That is, it is necessary for each of us (n3) steps to ensure that the mixing ratios are incorporated into the stationary distribution of the P2 proof sketch. Proof is based on the iteratively applied theorem from 2012: Theorem 5. Let us be a density proportional to e \u2212 a T x via a convex K-proof sketch. (a) The level of probability 1 / 64 contains a ball of radius s [b].Ef"}], "references": [], "referenceMentions": [], "year": 2015, "abstractText": "<lb>This paper explores a surprising equivalence between two seemingly-distinct convex opti-<lb>mization methods. We show that simulated annealing, a well-studied random walk algorithms,<lb>is directly equivalent, in a certain sense, to the central path interior point algorithm for the the<lb>entropic universal barrier function. This connection exhibits several benefits. First, we are able<lb>improve the state of the art time complexity for convex optimization under the membership<lb>oracle model. We improve the analysis of the randomized algorithm of Kalai and Vempala [7]<lb>by utilizing tools developed by Nesterov and Nemirovskii [16] that underly the central path fol-<lb>lowing interior point algorithm. We are able to tighten the temperature schedule for simulated<lb>annealing which gives an improved running time, reducing by square root of the dimension<lb>in certain instances. Second, we get an efficient randomized interior point method with an<lb>efficiently computable universal barrier for any convex set described by a membership oracle.<lb>Previously, efficiently computable barriers were known only for particular convex sets. 1<lb>ar<lb>X<lb>iv<lb>:1<lb>50<lb>7.<lb>02<lb>52<lb>8v<lb>2<lb>[<lb>m<lb>at<lb>h.<lb>O<lb>C<lb>]<lb>5<lb>N<lb>ov<lb>2<lb>01<lb>5", "creator": "LaTeX with hyperref package"}}}