{"id": "1507.04457", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Jul-2015", "title": "Preference Completion: Large-scale Collaborative Ranking from Pairwise Comparisons", "abstract": "In this paper we consider the collaborative ranking setting: a pool of users each provides a small number of pairwise preferences between $d$ possible items; from these we need to predict preferences of the users for items they have not yet seen. We do so by fitting a rank $r$ score matrix to the pairwise data, and provide two main contributions: (a) we show that an algorithm based on convex optimization provides good generalization guarantees once each user provides as few as $O(r\\log^2 d)$ pairwise comparisons -- essentially matching the sample complexity required in the related matrix completion setting (which uses actual numerical as opposed to pairwise information), and (b) we develop a large-scale non-convex implementation, which we call AltSVM, that trains a factored form of the matrix via alternating minimization (which we show reduces to alternating SVM problems), and scales and parallelizes very well to large problem settings. It also outperforms common baselines on many moderately large popular collaborative filtering datasets in both NDCG and in other measures of ranking performance.", "histories": [["v1", "Thu, 16 Jul 2015 06:00:51 GMT  (122kb,D)", "http://arxiv.org/abs/1507.04457v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["dohyung park", "joe neeman", "jin zhang", "sujay sanghavi", "inderjit s dhillon"], "accepted": true, "id": "1507.04457"}, "pdf": {"name": "1507.04457.pdf", "metadata": {"source": "CRF", "title": "Preference Completion: Large-scale Collaborative Ranking from Pairwise Comparisons", "authors": ["Dohyung Park", "Sujay Sanghavi"], "emails": ["dhpark@utexas.edu", "joeneeman@gmail.com", "zj@utexas.edu", "sanghavi@mail.utexas.edu", "inderjit@cs.utexas.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, the fact is that most of them are able to move, to move, and that they are able to move, to travel the world, to travel the world."}, {"heading": "1.1 Related Work", "text": "There are many different settings for this problem, which we discuss below. However, the main problem in this community is to estimate a ranking function based on predefined feature vectors and relevance values. However, depending on its application, a feature vector may take into account our user item analysis or a single element. We refer the reader to the survey [15]. A ranking with pair comparisons In a single-user model, we are asked to learn a single ranking with pair comparisons. Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless answers; Jamieson Nowak [11] provide an algorithm for accurately restoring the true ranking under an approximate approximate approximate approximate assumptions."}, {"heading": "2 Empirical Risk Minimization (ERM)", "text": "First, let's formulate the problem mathematically: the task is to estimate the ranking of multiple users based on multiple items. We specify the number of users according to d1 and the number of items according to d2. The observed comparison is then derived from {Yijk, 1, \u2212 1}: (i, j, k), where Yijk, if user i prefers items j and k items, and Yijk, = \u2212 1 otherwise. Let's specify the observed comparison according to {Yijk, k): (i, j, k), where Yijk = 1 stands if user i prefers items k, and Yijk = \u2212 1 otherwise. Let's specify i = {(j, k): (i, j, k), the set of items that user i has compared. We predict rankings for multiple users by estimating a ranking for multiple users (Yint by using a Score Matrix, Xidj > Id2 means that Xidik > Id1 means that."}, {"heading": "3 Convex Relaxation", "text": "Our first method is the convex relaxation of (1), which contains a constraint of the core norm. Minimize X (i, j, k), (Yijk (Xij \u2212 Xik)), (2) are subject to the constraint of the core norm for each matrix X. The only parameter of this algorithm is \u03bb, which regulates the trade-off between better optimization of the probability of the observed data and rigor in imposing an approximate low-ranking structure. Since we have motivated our algorithm by the assumption that X has a low rank, we should point out how the parameter of our algorithm compares with rank: Note that if X is a d1 x d2 rank-r matrix, the largest absolute entry of which X has a low rank, and that it is then equal to both the size of X and that of other elements of the proportion."}, {"heading": "3.1 Analytic results", "text": "We analyze (2) by starting from a standard model for pairs comparisons, then we offer a statistical guarantee for the method under the model.We recall the classic Bradley-Terry-Luce model (3, 17] for pairs of preferences of an individual user, who assumes that the probability that item j is preferred over k is given by logistics of the difference in the underlying preference values of the two items. (1) We assume that each user has a true score item X. (Yijk = 1) = exp (X) = exp (X + exp) 1 (X + exp)."}, {"heading": "3.1.1 Maximum likelihood estimation of X\u2217", "text": "By specializing in the loss function L, Theorem 3.1 has a simple sequence for the most likely estimation of the X probability. Remember that if \u00b5 and \u03bd are two probability distributions on a finite set S, the Kullback-Leibler divergence between them isD (\u00b5) = \u2211 s-S \u00b5 (s) log \u00b5 (s) \u03bd (s), according to the convention that 0 log 0 = 0. Let us remember that although D (\u00b7) is not a metric, it is always not negative and that D (\u00b5) = 0 implies \u00b5 = \u03bd.Correction 3.3. Let us distribute Y and \u0438 as PX for some d1 \u00d7 d2 matrix. Let us define the loss function L by L (z) = log (1 + exp (z) = 0 implies \u00b5 = \u03bd.Correction 3.3. Let us distribute Y and Y for some d1 \u00d7 d2 matrix X (L). Let us define the loss function L by L (1 + exp) = L."}, {"heading": "4 Large-scale Non-convex Implementation", "text": "It is not the first time that we have had a problem with the poor quality of the data, and it is also not the first time that we have had such a problem in the form X = UV > and better empirical performance compared to several existing empirical principles. (This leads to a non-convex optimization problem in U-Rd1 \u00b7 r and V-Rd2 \u00b7 r, where it explicitly fixes the ranking parameters in the form X = UV > and replaces the regulators accordingly.) This leads to a non-convex optimization problem in U-Rd1 \u00b7 r and V-Rd2 \u00b7 r, where we solve the non-convex problem by fixing it between updated U, and vice versa. With the associated loss (which we have found), each of these problems becomes an SVM problem - hh.2. We solve the non-convex problem by fixing it between updated U, and vice versa."}, {"heading": "4.1 Parallelization", "text": "For each partial problem, we parallelise the stochastic dual-coordinate-descendancy algorithm asynchronously without locking. In view of the T-processors, each processor randomly tries a triple (i, j, k) and updates the corresponding dual variable and the user or item vectors. We note that this update is for a sparse subset of parameters. In the user part, a coordinate-descendancy step for a sample updates only r from the rd1 variables. In the item part, a coordinate-descendancy step for a sample update is only 2r from the rd2 variables. This motivates us not to lock the variables when they are updated, so that we ignore the conflicts. This non-lock parallelism proves effective in [19] for stochastic gradient descendancy (SGD) on the sum of the sparse functions. Furthermore, in [8], the stochastic descendancy coordinates work well without locking."}, {"heading": "4.2 Remark on the implementation", "text": "We have observed empirically that this sequence leads to a better convergence of practical datasets. We also find that each partial problem reuses the dual variables in the previous outer iteration. If the characteristics (V for the solution of U and U for the solution of V) are nearly converged, they do not change too much. By reusing the dual variables in the previous iteration, we can start with a workable solution that comes close to the optimum."}, {"heading": "5 Experimental results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Pairwise data", "text": "We used the MovieLens 100k dataset, which contains 100,000 ratings given by 943 users in 1682 movies. Ratings are given as integers from one to five, but we converted them into preference data, explaining that a user prefers one movie to another if he gives it a higher rating (if two movies get the same rating, we treat it as if the user had no preference), then we had 20% of the data available as a test set. \u2022 We compared our algorithm with the following two: \u2022 Bayesian Personalized Ranking (BPR) [20]: This algorithm is based on a similar model to ours, but a different optimization method (essentially a variant of stochastic gradient descent). \u2022 Matrix completion from pair differences: A standard matrix completion algorithm that - for different triples (i, j, k) - determines the difference between the ratings of the articles j and kj."}, {"heading": "5.2 Large-scale experiments on rating data", "text": "Now we show that our algorithm also performs a collaborative ranking method based on rating data. We used the datasets given in Table 1. Given a set of ratings for each user, our algorithm is only used to use non-binding pairs of comparisons from the set, while other competing algorithms use the ratings themselves. Therefore, they have more information than ours. The competing algorithms are those provided with publicly available codes by the authors. \u2022 CofiRank [28] 1 This algorithm uses alternating minimizations to directly optimize ratings. 1http: / www.cofirank.org, The dimension and regulation parameters are set as proposed in the papers. \u2022 Local Collaborative Ranking (LCR) [13] 2: The main idea is to predict preferences from the weighted sum of multiple low-graded models."}, {"heading": "5.3 Computational speed and Scalability", "text": "Figures 2a and 2b show NDCG @ 10 over time of our algorithms with 1, 4 and 16 threads, compared to CofiRank. Figure 2c shows the accuracy @ 10 over time of our algorithm with C = 5000. We note that our algorithm converges faster, while the sample size for our algorithm is greater than the number of training evaluations used in the competing algorithms. Table 4 shows the scalability of AltSVM. We measured the time to achieve a tolerance of 10 \u2212 5 on the MovieLens1m binary dataset. As shown in the table, we were able to achieve significant accelerations."}, {"heading": "6 Conclusion", "text": "We have shown that convex loosening provides good generalization guarantees for empirical risk minimization. We also proposed a non-convex algorithm for the large practical environments, which alternately solves two SVM problems. We found that our algorithm outperforms the existing ones and parallelizes well."}, {"heading": "A Proof of Theorem 3.1", "text": "We write L (X) for the function that is optimized; i.e., L (X) = K (I, j, k) = K (I, j) = K (I, j) = K (I, j) = K (I, j) = K (I, j) (I, j) = K (I, j) (I, j) (I, j) = K (I, j) = K (X) (X): X (X): X (X) \u00b7 d2), K (X) (X), K) = K (X) = K (K) (X) (K) (X) = K (X) = K (X): X (X): X (X): X (X): X (X) \u00b7 d2), K (X): X (K), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X), K (X, K (X), K (X), K (X), K (X), K (X), K (X, K (X), K (X), K (X), K (X, K (X), K (X), K (X, K (X), K (X), K (X, K (X), K (X), K (X, K (X), K (X), K (X, K (X), K (X), K (X, K (X), K (X, K (X), K (X), K (X, K (X), K (X), X (X, K (X), K (X, K (X), K (X), K (X, K (X), K (X), X (X (X), K (X), X (X, K (X), K (X, K (X, X, X), K (X), X,"}, {"heading": "B Proof of Lemma A.1", "text": "We will split M into two parts, M = M (1) \u2212 M (2), M (1), M (1), M (1), M (1), M (1), M (2), M (2), M (1), M (1), M (1), M (1), M (2), M (1), M (2), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1, 1, 1, M (1), M (1, 1, 1, M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1), M (1, M (1), M (1), M (1), M (1, M (1), M (1), M (1), M (1), M (1, M (1), M (1), M (1), M (1, M (1), M (1), M (1, M (1), M (1), M (1, M (1), M (1), M (1, M (1), M (1), M (1, M (1), M (1), M (1, M (1), M (1), M (1, M (1, M (1), M (1), M (1, M (1), M (1), M (1, M (1, M (1), M (1), M (1, M (1), M (1), M (1), M (1, M (1), M (1, M (1), M (1, M (1), M (1), M ("}, {"heading": "C Proof of Theorem 3.2", "text": "We construct matrices X1,..,.,.,.,.,.,.,.,..,..,....,.....,..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "D Comparison to Stochastic Gradient Descent", "text": "Another handy algorithm for optimization (3) is the Stochastic Gradient Descent (SGD). We experimented with SGD on the same datasets in Table 1. We performed the algorithm with the same regulation parameters and different step sizes. SGD statistical results were observed to be no better than AltSVM, and therefore we did not present them in the main paper. First, we describe the SGD procedure. At each step, we select a triple (i, j, k) step uniformly and perform an SGD step that can be written as u + i."}], "references": [{"title": "Active learning ranking from pairwise preferences with almost optimal query complexity", "author": ["Ailon", "Nir"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2011}, {"title": "Collaborative ranking", "author": ["Balakrishnan", "Suhrid", "Chopra", "Sumit"], "venue": "In ACM International Conference on Web Search and Data Mining (WSDM),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Rank analysis of incomplete block designs: I. the method of paired comparisons", "author": ["Bradley", "Ralph Allan", "Terry", "Milton E"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1952}, {"title": "1-bit matrix completion", "author": ["Davenport", "Mark A", "Plan", "Yaniv", "Berg", "Ewout van den", "Wootters", "Mary"], "venue": "Information and Inference,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Minimax-optimal inference from partial rankings", "author": ["Hajek", "Bruce", "Oh", "Sewoong", "Xu", "Jiaming"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Large Margin Rank Boundaries for Ordinal Regression, chapter 7, pp. 115\u2013132", "author": ["Herbrich", "Ralf", "Graepel", "Thore", "Obermayer", "Klaus"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2000}, {"title": "A dual coordinate descent method for large-scale linear SVM", "author": ["Hsieh", "Cho-Jui", "Chang", "Kai-Wei", "Lin", "Chih-Jen", "Keerthi", "S. Sathiya", "S. Sundararajan"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2008}, {"title": "PASSCoDe: Parallel asynchronous stochastic dual co-ordinate descent", "author": ["Hsieh", "Cho-Jui", "Yu", "Hsiang-Fu", "Dhillon", "Inderjit S"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Collaborative filtering for implicit feedback datasets", "author": ["Hu", "Yifan", "Koren", "Yehuda", "Volinsky", "Chris"], "venue": "In IEEE International Conference on Data Mining (ICDM),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Active ranking using pairwise comparisons", "author": ["K.G. Jamieson", "R. Nowak"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Active ranking using pairwise comparisons", "author": ["Jamieson", "Kevin G", "Nowak", "Robert D"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2011}, {"title": "Optimizing search engines using clickthrough data", "author": ["Joachims", "Thorsten"], "venue": "In SIGKDD,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2002}, {"title": "Local collaborative ranking", "author": ["Lee", "Joonseok", "Bengio", "Samy", "Kim", "Seungyeon", "Lebanon", "Guy", "Singer", "Yoram"], "venue": "In International World Wide Web Conference (WWW),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Probabilistic latent preference analysis for collaborative filtering", "author": ["Liu", "Nathan N", "Zhao", "Min", "Yang", "Qiang"], "venue": "In Proceedings of the 18th ACM conference on Information and knowledge management,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Learning to Rank for Information Retrieval", "author": ["Liu", "Tie-Yan"], "venue": "Now Publishers Inc.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2009}, {"title": "Individualized rank aggregation using nuclear norm regularization", "author": ["Lu", "Yu", "Negahban", "Sahand"], "venue": "ArXiv e-prints:", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Iterative ranking from pair-wise comparisons", "author": ["Negahban", "Sahand", "Oh", "Sewoong", "Shah", "Devavrat"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Hogwild: A lock-free approach to parallelizing stochastic gradient descent", "author": ["Niu", "Feng", "Recht", "Benjamin", "R\u00e9", "Christopher", "Wright", "Stephen"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Bpr: Bayesian personalized ranking from implicit feedback", "author": ["Rendle", "Steffen", "Freudenthaler", "Christoph", "Gantner", "Zeno", "Schmidt-Thieme", "Lars"], "venue": "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2009}, {"title": "The expected norm of random matrices", "author": ["Seginer", "Yoav"], "venue": "Combinatorics Probability and Computing,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2000}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shalev-Shwartz", "Shai", "Zhang", "Tong"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Climf: collaborative less-is-more filtering", "author": ["Shi", "Yue", "Karatzoglou", "Alexandros", "Baltrunas", "Linas", "Larson", "Martha", "Oliver", "Nuria", "Hanjalic", "Alan"], "venue": "In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Maximum margin matrix factorization", "author": ["Srebro", "Nathan", "Rennie", "Jason", "Jaakkola", "Tommi"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2004}, {"title": "Compressed sensing: theory and applications, chapter Introduction to the non-asymptotic analysis of random matrices", "author": ["Vershynin", "Roman"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Collaborative ranking with 17 parameters", "author": ["Volkovs", "Maksims N", "Zemel", "Richard S"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2012}, {"title": "Efficient ranking from pairwise comparisons", "author": ["Wauthier", "Fabian L", "Jordan", "Michael I", "Jojic", "Nebojsa"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2013}, {"title": "Cofirank: maximum margin matrix factorization for collaborative ranking", "author": ["Weimer", "Markus", "Karatzoglou", "Alexandros", "Le", "Quoc V", "Smola", "Alex"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2007}, {"title": "Latent collaborative retrieval", "author": ["Weston", "Jason", "Want", "Chong", "Weiss", "Ron", "Berenzeig", "Adam"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2012}, {"title": "Jointly clustering rows and columns of binary matrices: Algorithms and trade-offs", "author": ["Xu", "Jiaming", "Wu", "Rui", "Zhu", "Kai", "Hajek", "Bruce", "R Srikant", "Ying", "Lei"], "venue": "In ACM Sigmetrics,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2013}, {"title": "Inferring users preferences from crowdsourced pairwise comparisons: A matrix completion approach", "author": ["Yi", "Jinfeng", "Jin", "Rong", "Jain", "Shaili", "Anil"], "venue": "In First AAAI Conference on Human Computation and Crowdsourcing,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2013}, {"title": "Ranking via robust binary classification and parallel parameter estimation in large-scale data", "author": ["Yun", "Hyokun", "Raman", "Parameswaran", "S.V.N. Vishwanathan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2014}], "referenceMentions": [{"referenceID": 6, "context": "We apply a stochastic version of dual coordinate descent [7, 22] with lockfree parallelization.", "startOffset": 57, "endOffset": 64}, {"referenceID": 20, "context": "We apply a stochastic version of dual coordinate descent [7, 22] with lockfree parallelization.", "startOffset": 57, "endOffset": 64}, {"referenceID": 5, "context": "While there have been algorithms that use pairwise comparisons [6, 12] of the training samples, our setting is different in that our data consists only of pairwise comparisons.", "startOffset": 63, "endOffset": 70}, {"referenceID": 11, "context": "While there have been algorithms that use pairwise comparisons [6, 12] of the training samples, our setting is different in that our data consists only of pairwise comparisons.", "startOffset": 63, "endOffset": 70}, {"referenceID": 14, "context": "We refer the reader to the survey [15].", "startOffset": 34, "endOffset": 38}, {"referenceID": 9, "context": "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.", "startOffset": 17, "endOffset": 21}, {"referenceID": 0, "context": "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.", "startOffset": 32, "endOffset": 35}, {"referenceID": 10, "context": "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.", "startOffset": 110, "endOffset": 114}, {"referenceID": 0, "context": "Jamieson & Nowak [10] and Ailon [1] consider an active query model with noiseless responses; Jamieson & Nowak [11] give an algorithm for exactly recovering the true ranking under a low-rank assumption similar to ours, while Ailon [1] approximately recovers the true ranking without such an assumption.", "startOffset": 230, "endOffset": 233}, {"referenceID": 25, "context": "[27] and Negahban et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] learn a ranking from noisy pairwise comparisions; Negahban et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] consider a Bradley-Terry-Luce model similar to ours and attempt to learn an underlying score vector, while Wauthier et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[27] get by without structure assumptions, but only attempt to learn the ranking itself.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] considered a problem to learn a single ranking given a more generalized partial rankings from the Plackett-Luce model and provided a minimax-optimal algorithm.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20] and Liu et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] were the first to take this approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 29, "context": "[31] took a purely optimization-based approach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "[9] and Shi et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 21, "context": "[23] consider the problem of learning from latent feedback.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "Recently, Lu & Negahban [16] analyzed an algorithm which is very similar to ours for the Bradley-Terry-Luce model independently from our work.", "startOffset": 24, "endOffset": 28}, {"referenceID": 3, "context": "[4] is most closely related to ours, in that they assume an underlying lowrank structure and give an algorithm based on convex optimization.", "startOffset": 0, "endOffset": 3}, {"referenceID": 28, "context": "[30] consider a slightly different goal: rather than attempting to recover the preferences of each user, they try to cluster similar users and similar items together.", "startOffset": 0, "endOffset": 4}, {"referenceID": 30, "context": "[32] proposed an optimization problem motivated from robust binary classification and used stochastic gradient descent to solve the problem in a large-scale setting.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[28] attempted to directly optimize Normalized Discounted Cumulative Gain (NDCG), a widely used performance measure for ranking problems.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "Balakrishnan & Chopra [2], and Volkovs & Zemel [26] converted this problem into a learning-to-rank problem and solved it using the existing algorithms.", "startOffset": 22, "endOffset": 25}, {"referenceID": 24, "context": "Balakrishnan & Chopra [2], and Volkovs & Zemel [26] converted this problem into a learning-to-rank problem and solved it using the existing algorithms.", "startOffset": 47, "endOffset": 51}, {"referenceID": 27, "context": "[29] and Lee et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[29] proposed a tensor model to rank items for different queries and users, and [13] proposed a weighted sum of low-rank matrix models.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[29] proposed a tensor model to rank items for different queries and users, and [13] proposed a weighted sum of low-rank matrix models.", "startOffset": 80, "endOffset": 84}, {"referenceID": 2, "context": "Recall the classical Bradley-Terry-Luce model [3, 17] for pairwise preferences of a single user, which assumes that the probability of item j being preferred over k is given by a logistic of the difference of the underlying preference scores of the two items.", "startOffset": 46, "endOffset": 53}, {"referenceID": 11, "context": "For the U update, each user vector naturally decouples and can be done in parallel (and in fact just reduces to the case of rankSVM [12]).", "startOffset": 132, "endOffset": 136}, {"referenceID": 22, "context": "where we replace the nuclear norm regularizer using the property \u2016X\u2016\u2217 = minX=UV > 12(\u2016U\u2016 2 F + \u2016V \u2016F ) [24].", "startOffset": 103, "endOffset": 107}, {"referenceID": 6, "context": "This motivates us to apply the stochastic dual coordinate descent algorithm [7, 22], which not only converges fast but also takes advantages of feature sparsity in linear SVMs.", "startOffset": 76, "endOffset": 83}, {"referenceID": 20, "context": "This motivates us to apply the stochastic dual coordinate descent algorithm [7, 22], which not only converges fast but also takes advantages of feature sparsity in linear SVMs.", "startOffset": 76, "endOffset": 83}, {"referenceID": 20, "context": "Each coordinate descent step takes O(r) computation, and iterations over |\u03a9| coordinates provide linear convergence [22].", "startOffset": 116, "endOffset": 120}, {"referenceID": 17, "context": "This lock-free parallelism is shown to be effective in [19] for stochastic gradient descent (SGD) on the sum of sparse functions.", "startOffset": 55, "endOffset": 59}, {"referenceID": 7, "context": "Moreover, in [8], it is also shown that the stochastic dual coordinate descent scales well without locking.", "startOffset": 13, "endOffset": 16}, {"referenceID": 18, "context": "We compared our algorithm to the following two: \u2022 Bayesian Personalized Ranking (BPR) [20]: This algorithm is based on a similar model to ours, but a different optimization procedure (essentially, a variant of stochastic gradient descent).", "startOffset": 86, "endOffset": 90}, {"referenceID": 3, "context": "A similar phenomenon was also observed in [4].", "startOffset": 42, "endOffset": 45}, {"referenceID": 18, "context": "[20], and if the data were fully observed then it would measure Kendall\u2019s distance between each user\u2019s true preferences and the learned ones.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "\u2022 CofiRank [28]1 This algorithm uses alternating minimization to directly optimize NDCG.", "startOffset": 11, "endOffset": 15}, {"referenceID": 12, "context": "\u2022 Local Collaborative Ranking (LCR) [13]2 : The main idea is to predict preferences from the weighted sum of multiple low-rank matrices model.", "startOffset": 36, "endOffset": 40}, {"referenceID": 30, "context": "\u2022 RobiRank [32]3 : This algorithm uses stochastic gradient descent to optimize the loss function motivated from robust binary classification.", "startOffset": 11, "endOffset": 15}, {"referenceID": 26, "context": "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].", "startOffset": 85, "endOffset": 100}, {"referenceID": 1, "context": "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].", "startOffset": 85, "endOffset": 100}, {"referenceID": 24, "context": "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].", "startOffset": 85, "endOffset": 100}, {"referenceID": 12, "context": "We follow the standard setting that are used in the collaborative ranking literature [28, 2, 26, 13].", "startOffset": 85, "endOffset": 100}, {"referenceID": 30, "context": "We compare our algorithm against RobiRank [32], which is a recently proposed algorithm for collaborative ranking with binary ratings.", "startOffset": 42, "endOffset": 46}], "year": 2015, "abstractText": "In this paper we consider the collaborative ranking setting: a pool of users each provides a small number of pairwise preferences between d possible items; from these we need to predict each users preferences for items they have not yet seen. We do so by fitting a rank r score matrix to the pairwise data, and provide two main contributions: (a) we show that an algorithm based on convex optimization provides good generalization guarantees once each user provides as few as O(r log d) pairwise comparisons \u2013 essentially matching the sample complexity required in the related matrix completion setting (which uses actual numerical as opposed to pairwise information), and (b) we develop a large-scale non-convex implementation, which we call AltSVM, that trains a factored form of the matrix via alternating minimization (which we show reduces to alternating SVM problems), and scales and parallelizes very well to large problem settings. It also outperforms common baselines on many moderately large popular collaborative filtering datasets in both NDCG and in other measures of ranking performance.", "creator": "LaTeX with hyperref package"}}}