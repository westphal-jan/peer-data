{"id": "1508.00305", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Aug-2015", "title": "Compositional Semantic Parsing on Semi-Structured Tables", "abstract": "Two important aspects of semantic parsing for question answering are the breadth of the knowledge source and the depth of logical compositionality. While existing work trades off one aspect for another, this paper simultaneously makes progress on both fronts through a new task: answering complex questions on semi-structured tables using question-answer pairs as supervision. The central challenge arises from two compounding factors: the broader domain results in an open-ended set of relations, and the deeper compositionality results in a combinatorial explosion in the space of logical forms. We propose a logical-form driven parsing algorithm guided by strong typing constraints and show that it obtains significant improvements over natural baselines. For evaluation, we created a new dataset of 22,033 complex questions on Wikipedia tables, which is made publicly available.", "histories": [["v1", "Mon, 3 Aug 2015 02:53:01 GMT  (271kb,D)", "http://arxiv.org/abs/1508.00305v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["panupong pasupat", "percy liang"], "accepted": true, "id": "1508.00305"}, "pdf": {"name": "1508.00305.pdf", "metadata": {"source": "CRF", "title": "Compositional Semantic Parsing on Semi-Structured Tables", "authors": ["Panupong Pasupat", "Percy Liang"], "emails": ["ppasupat@cs.stanford.edu", "pliang@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "In the semantic parody of answering questions, questions of natural language are transformed into logical forms that can be executed on a knowledge source in order to obtain answers to questions. Early semantic parsifum systems were trained to answer highly compositional questions, but knowledge sources were limited to small closed databases (Zelle and Mooney, 2007; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2011)."}, {"heading": "2 Task", "text": "Our task is as follows: given a table t and a question x above the table, output a list of values y that answers the question according to the table. Examples of inputs and outputs are shown in Figure 1. The system has access to a training set D = {(xi, ti, yi)} Ni = 1 of questions, tables and answers, but the tables in the test data do not appear during the training. The only limitation of question x is that a person must be able to answer it with only table t. Otherwise, the question can be of any type, from a simple table lookup question to a more complicated one that involves various logical operations. We have created a new data set, WIKITABLEQUESTIONS, of question-answer pairs on HTML tables as follows. We have merged randomly selected data tables from Wikipedia with at least 8 rows and 5 columns."}, {"heading": "3 Approach", "text": "We now describe our semantic parsing framework for answering a given question and training the model with question-answer pairs. Prediction. Given a table t and a question x, we predict an answer y using the framework shown in Figure 2. First, we convert table t into a knowledge diagram w (\"world\") encoding various relationships in the table (Section 4). Next, we generate a series of logical forms for candidates Zx by analyzing the question x using the information from w (Section 6.2). Each generated logical form z-Zx is a graph query that can be executed on the knowledge diagram w to obtain a denotation JzKw. We extract a characteristic vector \u03c6 (x, w, z) for each z-Zx (Section 6.2) and define a logline distribution across the candidates: pTB (z | x, w), exp (x), w, exp (w), w, w (x)."}, {"heading": "4 Knowledge graph", "text": "Inspired by the graph representation of knowledge bases, we process the table t by deterministically converting it into a knowledge graph w, as in Figure 3. In the simplest form, table rows form row nodes, strings in table cells become entity nodes, 1and table columns become directed edges from row nodes to entity1Two occurrences of the same string form a node in this column. The column headers are used as edge labels for these row-entity relations. The representation of the knowledge graph is convenient for three reasons: First, we can encode different forms of entity normalization in the graph. Some entity strings (e.g. \"1900\") can be interpreted as edge labels, a date or an intrinsic label depending on the context, while some other lines (e.g. \"200 km\") form a multiple form of the entity. Instead of binding to a normalization scheme, we introduce a channel scheme accordingly."}, {"heading": "5 Logical forms", "text": "As our language for logical forms, we use lambda dependency-based compositional semantics (Liang, 2013) or lambda-DCS, which we briefly describe here. Each lambda-DCS logical form is either simple (to denote a value list) or binary (to denote a list of pairs), the most basic unit forms are singletons (e.g. China represents an entity node and 30 a single number), while the most basic binary forms are relationships (e.g. City maps rows on city titles, Next maps rows on rows, and > = maps numbers on numbers). Logical forms can be combined into larger ones using various operations listed in Table 1."}, {"heading": "6 Parsing and ranking", "text": "Considering the knowledge diagram w, we now describe how to parse the expression x into a series of logical forms of candidate Zx."}, {"heading": "6.1 Parsing algorithm", "text": "The first rule is a lexical rule, which agrees with a standard diagram parseur. Both parsers build recursive derivatives and corresponding logical forms on by repeatedly applying derivative rules, which but have a logical form, which is independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way, as they are independent of the way and independent of the way, as they are independent of the way they are independent of the way."}, {"heading": "6.2 Features", "text": "We define characteristics \u03c6 (x, w, z) for our log-linear model to determine the relationship between question x and the candidate e.g. Table 4 shows some sample characteristics from each characteristic type. Most characteristics are of the form (f (x), g (z) or (f (x), h (y), where y = JzKw is the denotation, and f, g, and h extract some information (e.g. identity, POS tags) from x, z or y, respectively. Phrase predicate: Conjunctions between ngrams f (x) from x and predicates g (z) from e.g. We use both lexicalized characteristics where all possible pairs (f (x), g (z)) form different characteristics, and binary unexicalized characteristics that indicate whether f (x) and g (z) have a string match.missing predicate: Indicators about whether there are entities or the relations between the Jotype, but the Xxy or the Y are not mentioned in question e.g. the Xxy or the Xxy are mentioned in the question)."}, {"heading": "6.3 Generation and pruning", "text": "Due to their recursive nature, the rules allow us to generate highly compositional logical forms. However, compositivity goes hand in hand with the generation of exponentially more logical forms, most of which are redundant (e.g. logical forms with an Argmax operation on a set of size 1). We use several methods to deal with this combinatorial explosion: beam search. We calculate the model probability of each partial logical form based on available characteristics (i.e. characteristics that do not depend on the final denotation) and keep only the K = 200 highest-value logical forms in each cell. Print. We trim partial logical forms that result in invalid or redundant final logical forms. For example, we eliminate any logical form that does not perform typing checks (e.g. Beijing and Greece), execute an empty list (e.g. Year.number.24), contain an aggregate or superlative on a single sentence (e.g. Beijing, 2012 or Year.two)."}, {"heading": "7 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1 Main evaluation", "text": "We evaluate the system on the basis of the development sets (three random 80: 20 splits of training data) and the test data. In both settings, the tables on which we test do not appear during the training. Evaluation metrics. Our most important measurement is the accuracy, i.e. the number of examples (x, t, y) on which the system returns the correct answer y. We also report on the oracle value, which counts the number of examples in which at least one generated candidate z-Zx is executed on y.Baseline. We compare the system to two baselines. The first baseline (IR), which simulates the retrieval of information, selects a response y from among the units in the table using a logical-linear model of units (table cells) and non-logical forms. The characteristics are conjunctions between phrases in x and properties of answers y, which cover all characteristics in our main system that do not contain the logical form. As the upper limit of this baseline, 9.1% of the development examples receive a logical answer."}, {"heading": "7.2 Dataset statistics", "text": "In this section, we analyze the breadth and depth of the WIKITABLEQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUITUQUQUQUQUQUQUQUUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUQUUQUQUQUUQUQUQUQUQUQUQUQUUUQUQUUQUQUQUQUUUUQUQUQUUQUQUUUUQUQUUQUQUUUUUQUUUUUUUUUUUUQUQUUUQUQU"}, {"heading": "7.3 Features", "text": "The most influential features are lexicalized phrase predicate characteristics that capture the relationship between phrases and logical operations (e.g., the relationship \"last\" to argmax) and between phrases and relationships (e.g., the relationship \"before\" to < or further, and the relationship \"who\" to the relationship name). Anchoring with trigger words. In our analysis algorithm, relationships and logical operations are not anchored to the utterance. We consider an alternative approach in which logical operations are attached to \"triggering\" phrases that are hand-coded based on coding statistics (e.g., we solve a counting logic with how many and total). Table 6 (c) shows that the trigger words do not significantly affect accuracy, indicating that the original system is already able to learn the relationship between phrases and operations even without a manual lexicon."}, {"heading": "7.4 Semantically correct logical forms", "text": "In our environment, we are faced with a new challenge arising from learning with designations: with deeper compositivity, a greater number of nonsensical logical forms can be executed on the correct designation. For example, if the target answer is a small number (say 2), it is possible to count the number of lines with some random properties and arrive at the correct answer. However, as the system encounters more examples, it can potentially learn to disadvantage them by recognizing the characteristics of semantically correct logical forms. Instead, the system can only learn the characteristics of semantically correct logical forms if it can generate them at all. To see how well the system can generate correct logical forms, it is not enough to look at the oracle value, as bad logical forms can perform the correct designations. Instead, we randomly selected 200 examples and commented them manually with logical forms to see if a trained system can generate the commented logical form as an appendix."}, {"heading": "7.5 Error analysis", "text": "Errors in the development data can be divided into four groups: the first two groups are unprocessed question types (21%) and failure to anchor entities (25%) as described in Section 7.4; the third group are normalization and type errors (29%): Although we deal with some forms of entity normalization, we observe many unprocessed string formats such as times (e.g. 3: 45.79) and urban-rural pairs (e.g. Beijing, China); and complex calculations such as calculation periods (e.g. 12: 00-1: 00 \u2192 1 hour); and finally, we have errors (25%) that mostly occur when the phrase of the utterance and the relationship are oblique to each other (e.g. \"airplane\" and model)."}, {"heading": "8 Discussion", "text": "Our work simultaneously increases the breadth of the source of knowledge and the depth of compositivity in semantic states. \"This section examines the links in both aspects to related areas of work. Different semantic parsing systems are designed to bypass different sets of logical operations and gradations of compositivity. For example, form-filling systems (Wang et al., 2011) usually require a smaller scope of operations and compositionality, while early statistical semantic parsers are used to answer questions (Wong and Mooney, 2007) and high-precision natural language interfaces for databases (Androutsopoulos et al., 1995; Population Table and al., 2003) target more compositional expressions with a wide range of logical operations. This work aims to further increase the logical range of coverage. For example, compared with the Geoquery dataset, the WIKITABLESTIONS dataset."}], "references": [{"title": "Natural language interfaces to databases \u2013 an introduction", "author": ["G.D. Ritchie", "P. Thanisch"], "venue": "Journal of Natural Language Engineering,", "citeRegEx": "Androutsopoulos et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Androutsopoulos et al\\.", "year": 1995}, {"title": "Semantic parsing via paraphrasing. In Association for Computational Linguistics (ACL)", "author": ["Berant", "Liang2014] J. Berant", "P. Liang"], "venue": null, "citeRegEx": "Berant et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2014}, {"title": "Semantic parsing on Freebase from question-answer pairs. In Empirical Methods in Natural Language Processing (EMNLP)", "author": ["Berant et al.2013] J. Berant", "A. Chou", "R. Frostig", "P. Liang"], "venue": null, "citeRegEx": "Berant et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "WebTables: exploring the power of tables on the web", "author": ["A. Halevy", "D.Z. Wang", "E. Wu", "Y. Zhang"], "venue": "In Very Large Data Bases (VLDB),", "citeRegEx": "Cafarella et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cafarella et al\\.", "year": 2008}, {"title": "Largescale semantic parsing via schema matching and lexicon extension. In Association for Computational Linguistics (ACL)", "author": ["Cai", "Yates2013] Q. Cai", "A. Yates"], "venue": null, "citeRegEx": "Cai et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2013}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi et al.2010] J. Duchi", "E. Hazan", "Y. Singer"], "venue": "In Conference on Learning Theory (COLT)", "citeRegEx": "Duchi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2010}, {"title": "Paraphrase-driven learning for open question answering. In Association for Computational Linguistics (ACL)", "author": ["Fader et al.2013] A. Fader", "L. Zettlemoyer", "O. Etzioni"], "venue": null, "citeRegEx": "Fader et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Fader et al\\.", "year": 2013}, {"title": "Open question answering over curated and extracted knowledge bases", "author": ["Fader et al.2014] A. Fader", "L. Zettlemoyer", "O. Etzioni"], "venue": "In International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "Fader et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fader et al\\.", "year": 2014}, {"title": "Answering table augmentation queries from unstructured lists on the web", "author": ["Gupta", "Sarawagi2009] R. Gupta", "S. Sarawagi"], "venue": "In Very Large Data Bases (VLDB),", "citeRegEx": "Gupta et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2009}, {"title": "Knowledge base population: Successful approaches and challenges", "author": ["Ji", "Grishman2011] H. Ji", "R. Grishman"], "venue": "In Association for Computational Linguistics (ACL),", "citeRegEx": "Ji et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2011}, {"title": "Jointly learning to parse and perceive: Connecting natural language to the physical world. Transactions of the Association for Computational Linguistics (TACL), 1:193\u2013206", "author": ["Krishnamurthy", "Kollar2013] J. Krishnamurthy", "T. Kollar"], "venue": null, "citeRegEx": "Krishnamurthy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Krishnamurthy et al\\.", "year": 2013}, {"title": "Lexical generalization in CCG grammar induction for semantic parsing", "author": ["L. Zettlemoyer", "S. Goldwater", "M. Steedman"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Kwiatkowski et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2011}, {"title": "Scaling semantic parsers with on-the-fly ontology matching", "author": ["E. Choi", "Y. Artzi", "L. Zettlemoyer"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Kwiatkowski et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2013}, {"title": "Lambda dependencybased compositional semantics", "author": ["P. Liang"], "venue": "Technical report,", "citeRegEx": "Liang.,? \\Q2013\\E", "shortCiteRegEx": "Liang.", "year": 2013}, {"title": "Annotating and searching web tables using entities, types and relationships", "author": ["Limaye et al.2010] G. Limaye", "S. Sarawagi", "S. Chakrabarti"], "venue": "In Very Large Data Bases (VLDB),", "citeRegEx": "Limaye et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Limaye et al\\.", "year": 2010}, {"title": "Open language learning for information extraction", "author": ["Masaum et al.2012] Masaum", "M. Schmitz", "R. Bart", "S. Soderland", "O. Etzioni"], "venue": "In Empirical Methods in Natural Language Processing and Computational Natural Language Learning", "citeRegEx": "Masaum et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Masaum et al\\.", "year": 2012}, {"title": "Zero-shot entity extraction from web pages. In Association for Computational Linguistics (ACL)", "author": ["Pasupat", "Liang2014] P. Pasupat", "P. Liang"], "venue": null, "citeRegEx": "Pasupat et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pasupat et al\\.", "year": 2014}, {"title": "Answering table queries on the web using column keywords", "author": ["Pimplikar", "Sarawagi2012] R. Pimplikar", "S. Sarawagi"], "venue": "In Very Large Data Bases (VLDB),", "citeRegEx": "Pimplikar et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Pimplikar et al\\.", "year": 2012}, {"title": "Towards a theory of natural language interfaces to databases", "author": ["Popescu et al.2003] A. Popescu", "O. Etzioni", "H. Kautz"], "venue": "In International Conference on Intelligent User Interfaces (IUI),", "citeRegEx": "Popescu et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Popescu et al\\.", "year": 2003}, {"title": "Evaluation of spoken language systems: The ATIS domain", "author": ["P. Price"], "venue": "In Proceedings of the Third DARPA Speech and Natural Language Workshop,", "citeRegEx": "Price.,? \\Q1990\\E", "shortCiteRegEx": "Price.", "year": 1990}, {"title": "Large-scale semantic parsing without question-answer pairs. Transactions of the Association for Computational Linguistics (TACL), 2(10):377\u2013392", "author": ["S. Reddy", "M. Lapata", "M. Steedman"], "venue": null, "citeRegEx": "Reddy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reddy et al\\.", "year": 2014}, {"title": "Exploiting a web of semantic data for interpreting tables", "author": ["Syed et al.2010] Z. Syed", "T. Finin", "V. Mulwad", "A. Joshi"], "venue": "In Proceedings of the Second Web Science Conference", "citeRegEx": "Syed et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Syed et al\\.", "year": 2010}, {"title": "Pythia: compositional meaning construction for ontology-based question answering on the semantic web", "author": ["Unger", "Cimiano2011] C. Unger", "P. Cimiano"], "venue": "In Proceedings of the 16th international conference on Natural language processing", "citeRegEx": "Unger et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Unger et al\\.", "year": 2011}, {"title": "Template-based question answering over RDF data", "author": ["Unger et al.2012] C. Unger", "L. B\u00fchmann", "J. Lehmann", "A. Ngonga", "D. Gerber", "P. Cimiano"], "venue": "In World Wide Web (WWW),", "citeRegEx": "Unger et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Unger et al\\.", "year": 2012}, {"title": "Recovering semantics of tables on the web", "author": ["Venetis et al.2011] P. Venetis", "A. Halevy", "J. Madhavan", "M. Pa\u015fca", "W. Shen", "F. Wu", "G. Miao", "C. Wu"], "venue": "In Very Large Data Bases (VLDB),", "citeRegEx": "Venetis et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Venetis et al\\.", "year": 2011}, {"title": "Semantic frame-based spoken language understanding. Spoken Language Understanding: Systems for Extracting Semantic Information from Speech, pages 41\u201391", "author": ["Y. Wang", "L. Deng", "A. Acero"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Learning synchronous grammars for semantic parsing with lambda calculus", "author": ["Wong", "Mooney2007] Y.W. Wong", "R.J. Mooney"], "venue": "In Association for Computational Linguistics (ACL),", "citeRegEx": "Wong et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wong et al\\.", "year": 2007}, {"title": "Scalable attribute-value extraction from semi-structured text", "author": ["Y.W. Wong", "D. Widdows", "T. Lokovic", "K. Nigam"], "venue": "In IEEE International Conference on Data Mining Workshops,", "citeRegEx": "Wong et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wong et al\\.", "year": 2009}, {"title": "Open information extraction using Wikipedia", "author": ["Wu", "Weld2010] F. Wu", "D.S. Weld"], "venue": "In Association for Computational Linguistics (ACL),", "citeRegEx": "Wu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2010}, {"title": "Learning to parse database queries using inductive logic programming", "author": ["Zelle", "Mooney1996] M. Zelle", "R.J. Mooney"], "venue": "In Association for the Advancement of Artificial Intelligence (AAAI),", "citeRegEx": "Zelle et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Zelle et al\\.", "year": 1996}, {"title": "Online learning of relaxed CCG grammars for parsing to logical form", "author": ["Zettlemoyer", "Collins2007] L.S. Zettlemoyer", "M. Collins"], "venue": "In Empirical Methods in Natural Language Processing and Computational Natural Language Learning", "citeRegEx": "Zettlemoyer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zettlemoyer et al\\.", "year": 2007}, {"title": "Automatic extraction of top-k lists from the web", "author": ["Z. Zhang", "K.Q. Zhu", "H. Wang", "H. Li"], "venue": "In International Conference on Data Engineering", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 11, "context": "Early semantic parsing systems were trained to answer highly compositional questions, but the knowledge sources were limited to small closed-domain databases (Zelle and Mooney, 1996; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2011).", "startOffset": 158, "endOffset": 262}, {"referenceID": 2, "context": "More recent work sacrifices compositionality in favor of using more open-ended knowledge bases such as Freebase (Cai and Yates, 2013; Berant et al., 2013; Fader et al., 2014; Reddy et al., 2014).", "startOffset": 112, "endOffset": 194}, {"referenceID": 7, "context": "More recent work sacrifices compositionality in favor of using more open-ended knowledge bases such as Freebase (Cai and Yates, 2013; Berant et al., 2013; Fader et al., 2014; Reddy et al., 2014).", "startOffset": 112, "endOffset": 194}, {"referenceID": 20, "context": "More recent work sacrifices compositionality in favor of using more open-ended knowledge bases such as Freebase (Cai and Yates, 2013; Berant et al., 2013; Fader et al., 2014; Reddy et al., 2014).", "startOffset": 112, "endOffset": 194}, {"referenceID": 5, "context": "We optimize \u03b8 using AdaGrad (Duchi et al., 2010), running 3 passes over the data.", "startOffset": 28, "endOffset": 48}, {"referenceID": 13, "context": "As our language for logical forms, we use lambda dependency-based compositional semantics (Liang, 2013), or lambda DCS, which we briefly describe here.", "startOffset": 90, "endOffset": 103}, {"referenceID": 2, "context": "This rule subset has the same logical coverage as Berant and Liang (2014), which is designed to handle the WEBQUESTIONS (Berant et al., 2013) and FREE917 (Cai and Yates, 2013) datasets.", "startOffset": 120, "endOffset": 141}, {"referenceID": 11, "context": "This rule subset has the same logical coverage as Berant and Liang (2014), which is designed to handle the WEBQUESTIONS (Berant et al.", "startOffset": 61, "endOffset": 74}, {"referenceID": 19, "context": "the tables in the WIKITABLEQUESTIONS dataset contain many more relations than closed-domain datasets such as Geoquery (Zelle and Mooney, 1996) and ATIS (Price, 1990).", "startOffset": 152, "endOffset": 165}, {"referenceID": 25, "context": "For example, form-filling systems (Wang et al., 2011) usually cover a smaller scope of operations and compositionality, while early statistical semantic parsers for question answering (Wong and Mooney, 2007; Zettlemoyer and Collins, 2007) and high-accuracy natural language interfaces for databases (Androutsopoulos et al.", "startOffset": 34, "endOffset": 53}, {"referenceID": 0, "context": ", 2011) usually cover a smaller scope of operations and compositionality, while early statistical semantic parsers for question answering (Wong and Mooney, 2007; Zettlemoyer and Collins, 2007) and high-accuracy natural language interfaces for databases (Androutsopoulos et al., 1995; Popescu et al., 2003) target more compositional utterances with a wide range of logical operations.", "startOffset": 253, "endOffset": 305}, {"referenceID": 18, "context": ", 2011) usually cover a smaller scope of operations and compositionality, while early statistical semantic parsers for question answering (Wong and Mooney, 2007; Zettlemoyer and Collins, 2007) and high-accuracy natural language interfaces for databases (Androutsopoulos et al., 1995; Popescu et al., 2003) target more compositional utterances with a wide range of logical operations.", "startOffset": 253, "endOffset": 305}, {"referenceID": 23, "context": "A lexicon can be automatically generated (Unger and Cimiano, 2011; Unger et al., 2012), learned from data (Zettlemoyer and Collins, 2007; Kwiatkowski et al.", "startOffset": 41, "endOffset": 86}, {"referenceID": 11, "context": ", 2012), learned from data (Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2011), or extracted from external sources (Cai and Yates, 2013; Berant et al.", "startOffset": 27, "endOffset": 84}, {"referenceID": 2, "context": ", 2011), or extracted from external sources (Cai and Yates, 2013; Berant et al., 2013), but requires some techniques to generalize to unseen data.", "startOffset": 44, "endOffset": 86}, {"referenceID": 1, "context": ", 2011), or extracted from external sources (Cai and Yates, 2013; Berant et al., 2013), but requires some techniques to generalize to unseen data. Our work takes a different approach similar to the logical form growing algorithm in Berant and Liang (2014) by not anchoring relations and operations to the utterance.", "startOffset": 66, "endOffset": 256}, {"referenceID": 2, "context": "In particular, large-scale knowledge bases have gained popularity in the semantic parsing community (Cai and Yates, 2013; Berant et al., 2013; Fader et al., 2014).", "startOffset": 100, "endOffset": 162}, {"referenceID": 7, "context": "In particular, large-scale knowledge bases have gained popularity in the semantic parsing community (Cai and Yates, 2013; Berant et al., 2013; Fader et al., 2014).", "startOffset": 100, "endOffset": 162}, {"referenceID": 12, "context": "The increasing number of relations and entities motivates new resources and techniques for improving the accuracy, including the use of ontology matching models (Kwiatkowski et al., 2013), paraphrase models (Fader et al.", "startOffset": 161, "endOffset": 187}, {"referenceID": 6, "context": ", 2013), paraphrase models (Fader et al., 2013; Berant and Liang, 2014), and unlabeled sentences (Krishnamurthy and Kollar, 2013; Reddy et al.", "startOffset": 27, "endOffset": 71}, {"referenceID": 20, "context": ", 2013; Berant and Liang, 2014), and unlabeled sentences (Krishnamurthy and Kollar, 2013; Reddy et al., 2014).", "startOffset": 57, "endOffset": 109}, {"referenceID": 3, "context": "There have been several studies on analyzing or inferring the table schemas (Cafarella et al., 2008; Venetis et al., 2011; Syed et al., 2010; Limaye et al., 2010) and answering search queries by joining tables on similar columns (Cafarella et al.", "startOffset": 76, "endOffset": 162}, {"referenceID": 24, "context": "There have been several studies on analyzing or inferring the table schemas (Cafarella et al., 2008; Venetis et al., 2011; Syed et al., 2010; Limaye et al., 2010) and answering search queries by joining tables on similar columns (Cafarella et al.", "startOffset": 76, "endOffset": 162}, {"referenceID": 21, "context": "There have been several studies on analyzing or inferring the table schemas (Cafarella et al., 2008; Venetis et al., 2011; Syed et al., 2010; Limaye et al., 2010) and answering search queries by joining tables on similar columns (Cafarella et al.", "startOffset": 76, "endOffset": 162}, {"referenceID": 14, "context": "There have been several studies on analyzing or inferring the table schemas (Cafarella et al., 2008; Venetis et al., 2011; Syed et al., 2010; Limaye et al., 2010) and answering search queries by joining tables on similar columns (Cafarella et al.", "startOffset": 76, "endOffset": 162}, {"referenceID": 3, "context": ", 2010) and answering search queries by joining tables on similar columns (Cafarella et al., 2008; Gonzalez et al., 2010; Pimplikar and Sarawagi, 2012).", "startOffset": 74, "endOffset": 151}, {"referenceID": 15, "context": "In parallel, open information extraction (Wu and Weld, 2010; Masaum et al., 2012) and knowledge base population (Ji and Grishman, 2011) extract information from web pages and compile them into structured data.", "startOffset": 41, "endOffset": 81}, {"referenceID": 27, "context": "In future work, we wish to draw information from other semi-structured formats such as colon-delimited pairs (Wong et al., 2009), bulleted lists (Gupta and Sarawagi, 2009), and top-k lists (Zhang et al.", "startOffset": 109, "endOffset": 128}, {"referenceID": 31, "context": ", 2009), bulleted lists (Gupta and Sarawagi, 2009), and top-k lists (Zhang et al., 2013).", "startOffset": 68, "endOffset": 88}, {"referenceID": 13, "context": "Pasupat and Liang (2014) used a framework similar to ours to extract entities from web pages, where the \u201clogical forms\u201d were XPath expressions.", "startOffset": 12, "endOffset": 25}], "year": 2015, "abstractText": "Two important aspects of semantic parsing for question answering are the breadth of the knowledge source and the depth of logical compositionality. While existing work trades off one aspect for another, this paper simultaneously makes progress on both fronts through a new task: answering complex questions on semi-structured tables using question-answer pairs as supervision. The central challenge arises from two compounding factors: the broader domain results in an open-ended set of relations, and the deeper compositionality results in a combinatorial explosion in the space of logical forms. We propose a logical-form driven parsing algorithm guided by strong typing constraints and show that it obtains significant improvements over natural baselines. For evaluation, we created a new dataset of 22,033 complex questions on Wikipedia tables, which is made publicly available.", "creator": "LaTeX with hyperref package"}}}