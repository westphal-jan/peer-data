{"id": "1508.04032", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Aug-2015", "title": "Variable Elimination in the Fourier Domain", "abstract": "Probabilistic inference is a key computational challenge in statistical machine learning and artificial intelligence. The ability to represent complex high dimensional probability distributions in a compact form is the most important insight in the field of graphical models.", "histories": [["v1", "Mon, 17 Aug 2015 14:04:07 GMT  (167kb,D)", "http://arxiv.org/abs/1508.04032v1", null], ["v2", "Wed, 22 Jun 2016 03:18:10 GMT  (4104kb,D)", "http://arxiv.org/abs/1508.04032v2", "Proceedings of the 33rd International Conference on Machine Learning (ICML), 2016"]], "reviews": [], "SUBJECTS": "cs.AI", "authors": ["yexiang xue", "stefano ermon", "ronan le bras", "carla p gomes", "bart selman"], "accepted": true, "id": "1508.04032"}, "pdf": {"name": "1508.04032.pdf", "metadata": {"source": "CRF", "title": "Variable Elimination in Fourier Domain", "authors": ["Yexiang Xue", "Stefano Ermon", "Ronan Lebras", "Carla P. Gomes", "Bart Selman"], "emails": ["yexiang@cs.cornell.edu", "ermon@cs.stanford.edu", "selman}@cs.cornell.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it is so far that it will only be a matter of time before an agreement is reached."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Inference In Graphical Models", "text": "We consider a Boolean graphical model of N = | V | Boolean variables, where V = {xi | i \u0394V} represents the remaining factors. We use bold variables to represent a vector of variables. For example, the vector of all Boolean variables x is shown as x = (x1, x2,..., xN) T. In addition, we use xS to represent the image of the vector x projected onto a subset of variables: xS = (xi1, xi2,., xik) T, where xi1,.,., xik. Aprobabilistic graphical model is defined as: Pr (x) = 1Z f (x) = 1Z K-i (xSi). Each of these operations i: {\u2212 1, 1} | Si + is referred to as a dynamic key, and is a function that depends on a subset of variables."}, {"heading": "2.2 Hadmard-Fourier Transformation", "text": "The Hadmard-Fourier transformation has recently attracted a lot of attention in PAC learning theory. Table 1 provides an example in which a function \u03c6 (x, y) is transformed into its Fourier representation; the transformation works by writing a function defined on a Boolean hypercube using interpolation, and then rearranging the terms to obtain a canonical term; the example can be generalized, and it can be shown that any function defined on a Boolean hypercube can be represented equally in Fourier space: Definition 1. (Hadmard-Fourier transformation) Each f: {\u2212 1, 1} n \u2192 R can be expressed uniquely as multilinear polynomia, f (x) = [n] cS-i-S xi.where each cS-Fourier follows a standard notation, we will write f-Fourier (S) to rename the coefficient courier-Fourier and a Fourier-Fourier."}, {"heading": "3 Low Degree Concentration of Fourier Coefficients", "text": "The question that arises in this context is whether this is a way in which people in a country where most people are able to move to another world go to another world. (...) The question is whether it is a country in which people live in another world. (...) The question is whether it is a country in which people live in another world. (...) The question is whether it is a country in which people live in another world. (...) The question is whether people live in another world, in which people live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live. \"(...)"}, {"heading": "4 Variable Elimination in Fourier Domain", "text": "The classic VE algorithm consists of two basic steps - the multiplication step and the elimination step. The multiplication step picks up f & g, and the elimination step returns f & g, while the elimination step includes a variable of f & t. The naive approach is to transform the representation back into the value domain by doing the two steps there, then transform it back into the Fourier domain. While this strategy eliminates all the advantages of Fourier representation, we can advance the elimination in the Fourier domain. A naive approach is to transform the representation back into the value domain, perform the two steps back into the Fourier domain."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Weight Concentration on Low Degree Coefficients", "text": "First, we validate our theoretical results on the basis of the sparse Fourier representations and the weight concentration on low-grade coefficients. The weighted 3-SAT instances are specified by a CNF and a weight \u03b7. Each factor corresponds to a clause in the CNF. When the clause is met, the corresponding factor evaluates to 1, otherwise to \u03b7. For each setting, we randomly generate 100 instances. For each instance, we calculate the square sum weight at each degree: Wk [f] = \u2211 S [n], | S | = k f (S) 2. Figure 2 shows the mean value of the square sum weight over 100 instances. As shown in the figure, the weights focus on low-grade coefficients, regardless of dependence."}, {"heading": "5.2 The Performance When Applying to Variable Elimination", "text": "We integrate the Fourier representation into the variable elimination algorithm and rate its performance as an approximate probable conclusion to estimate the partitioning function of undirected graphical models. Our main comparison is against the advanced heurigen factors. The versions we have obtained for Maximum Estimation (MAP) are the way in which the partitioning function is calculated by replacing the maximizing operators with the advanced heurigen factors. The versions we have received are for Maximum Estimation (MAP)."}, {"heading": "6 Conclusion", "text": "Our approach is based on discrete Fourier representation of weighted Boolean functions and complements the classical method of exploiting conditional independence between variables. We show that a large class of weighted probabilistic graphical models has a compact Fourier representation. This theoretical result opens up a completely new way of approaching a probability distribution. We demonstrate the importance of this approach by applying it to the variable elimination algorithm and comparing the results with the bucket representation and other approximate inference algorithms, achieving very encouraging results."}, {"heading": "7 Supplementary Materials", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1 Proof of Lemma 1", "text": "Allow Rln to impose restrictions on n Boolean variables x1,..,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,..,...,..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................."}, {"heading": "7.2 Proof of Theorem 2", "text": "For any term in the Fourier expansion whose degree is less than or equal to d, we can treat this term as a weighted function that contains less than or equal to d variables. Therefore, it can be represented by a decision tree in which each path of the tree does not contain more than d variables (hence the tree is at most at the depth of d). Since f is represented as a sum over a series of Fourier terms up to degree d, it can also be represented as the sum of the corresponding decision trees."}, {"heading": "7.3 Proof of Theorem 5", "text": "Let the Fourier expansion be f: f (x) = 1 (x\\ x0, x0 = + 1) + f (x\\ x0, x0 = -1) (10) = 1 (x0) S: x0 (S) \u00b7 1 + 1 S: x0 (x\\ x0) \u00b7 1 + 2 S: x0 (S) \u00b7 1 + 2 S: x0 (S) \u00b7 1 (\u2212 1) (11) + 2 S: x0 6 (S) \u00b7 1 + 2 S: x0 (x\\ x0) + 2 S: x0 (x\\ x0) + 2 S: x0 6 (S) \u00b7 2 S: x0 (x\\ x0) (12) = 2 S: x0 6 (S) \u00b7 2 \u00b7 f: 0 (S) \u00b7 2 (S: 0 (x\\ x0) (13)."}], "references": [{"title": "On Learning Monotone Boolean Functions", "author": ["Avirim Blum", "Carl Burch", "John Langford"], "venue": "In FOCS,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "On sparse, spectral and other parameterizations of binary probabilistic models", "author": ["David Buchman", "Mark W. Schmidt", "Shakir Mohamed", "David Poole", "Nando de Freitas"], "venue": "In AISTATS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "A knowledge compilation", "author": ["Adnan Darwiche", "Pierre Marquis"], "venue": "map. J. Artif. Int. Res.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Mini-buckets: A general scheme for generating approximations in automated reasoning", "author": ["Rina Dechter"], "venue": "In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1997}, {"title": "Mini-bucket elimination with moment matching", "author": ["Natalia Flerova", "Er Ihler", "Rina Dechter", "Lars Otten"], "venue": "NIPS Workshop DISCML,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Recursive decomposition for nonconvex optimization", "author": ["Abram L. Friesen", "Pedro Domingos"], "venue": "In Proceedings of the 24th International Joint Conference on Artificial Intelligence,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "A complete anytime algorithm for treewidth", "author": ["Vibhav Gogate", "Rina Dechter"], "venue": "In Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2004}, {"title": "Structured message passing", "author": ["Vibhav Gogate", "Pedro M. Domingos"], "venue": "In UAI,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Computational Limitations of Small-depth Circuits", "author": ["Johan H\u00e5stad"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1987}, {"title": "On the partition function and random maximum aposteriori perturbations", "author": ["Tamir Hazan", "Tommi S. Jaakkola"], "venue": "In ICML,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Join-graph based costshifting schemes", "author": ["Alexander T. Ihler", "Natalia Flerova", "Rina Dechter", "Lars Otten"], "venue": "In UAI,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2012}, {"title": "An introduction to variational methods for graphical models", "author": ["Michael I. Jordan", "Zoubin Ghahramani", "Tommi S. Jaakkola", "Lawrence K. Saul"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1999}, {"title": "Amazon.com recommendations: Item-to-item collaborative filtering", "author": ["Greg Linden", "Brent Smith", "Jeremy York"], "venue": "IEEE Internet Computing,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Constant depth circuits, fourier transform, and learnability", "author": ["Nathan Linial", "Yishay Mansour", "Noam Nisan"], "venue": "J. ACM,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1993}, {"title": "Learning Boolean functions via the Fourier transform. advances in neural computation and learning, 0:1\u201328", "author": ["Yishay Mansour"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 1994}, {"title": "Join-graph propagation algorithms", "author": ["Robert Mateescu", "Kalev Kask", "Vibhav Gogate", "Rina Dechter"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "libDAI: A free and open source C++ library for discrete approximate inference in graphical models", "author": ["Joris M. Mooij"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Some topics in analysis of boolean functions", "author": ["Ryan O\u2019Donnell"], "venue": "Proceedings of the fourtieth annual ACM symposium on Theory of computing - STOC", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}, {"title": "Estimation of interaction potentials of spatial point patterns through the maximum likelihood procedure", "author": ["Yosihiko Ogata", "Masaharu Tanemura"], "venue": "Annals of the Institute of Statistical Mathematics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1981}, {"title": "Bounded arithmetic and lower bounds in boolean complexity", "author": ["Alexander A. Razborov"], "venue": "In Feasible Mathematics II, Progress in Computer Science and Applied Logic", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1995}, {"title": "Tightening lp relaxations for map using message passing", "author": ["David Sontag", "Talya Meltzer", "Amir Globerson", "Tommi Jaakkola", "Yair Weiss"], "venue": "In UAI,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2008}], "referenceMentions": [{"referenceID": 3, "context": "Similar ideas have been considered in the analysis of Boolean functions and logical forms [4], as well as in physics with low rank tensor decompositions and matrix product states representations [6, 12, 13, 22].", "startOffset": 90, "endOffset": 93}, {"referenceID": 5, "context": "Similar ideas have been considered in the analysis of Boolean functions and logical forms [4], as well as in physics with low rank tensor decompositions and matrix product states representations [6, 12, 13, 22].", "startOffset": 195, "endOffset": 210}, {"referenceID": 11, "context": "Similar ideas have been considered in the analysis of Boolean functions and logical forms [4], as well as in physics with low rank tensor decompositions and matrix product states representations [6, 12, 13, 22].", "startOffset": 195, "endOffset": 210}, {"referenceID": 12, "context": "Similar ideas have been considered in the analysis of Boolean functions and logical forms [4], as well as in physics with low rank tensor decompositions and matrix product states representations [6, 12, 13, 22].", "startOffset": 195, "endOffset": 210}, {"referenceID": 20, "context": "Similar ideas have been considered in the analysis of Boolean functions and logical forms [4], as well as in physics with low rank tensor decompositions and matrix product states representations [6, 12, 13, 22].", "startOffset": 195, "endOffset": 210}, {"referenceID": 3, "context": "Numerous approximate and exact inference algorithms are based on this idea [4, 5, 16, 8, 23, 3, 11, 10].", "startOffset": 75, "endOffset": 103}, {"referenceID": 4, "context": "Numerous approximate and exact inference algorithms are based on this idea [4, 5, 16, 8, 23, 3, 11, 10].", "startOffset": 75, "endOffset": 103}, {"referenceID": 15, "context": "Numerous approximate and exact inference algorithms are based on this idea [4, 5, 16, 8, 23, 3, 11, 10].", "startOffset": 75, "endOffset": 103}, {"referenceID": 7, "context": "Numerous approximate and exact inference algorithms are based on this idea [4, 5, 16, 8, 23, 3, 11, 10].", "startOffset": 75, "endOffset": 103}, {"referenceID": 2, "context": "Numerous approximate and exact inference algorithms are based on this idea [4, 5, 16, 8, 23, 3, 11, 10].", "startOffset": 75, "endOffset": 103}, {"referenceID": 10, "context": "Numerous approximate and exact inference algorithms are based on this idea [4, 5, 16, 8, 23, 3, 11, 10].", "startOffset": 75, "endOffset": 103}, {"referenceID": 9, "context": "Numerous approximate and exact inference algorithms are based on this idea [4, 5, 16, 8, 23, 3, 11, 10].", "startOffset": 75, "endOffset": 103}, {"referenceID": 17, "context": "The Fourier representation has found numerous recent applications in PAC learning [18, 15, 1, 2], but these ideas have not been fully exploited in the fields of probabilistic inference and graphical models.", "startOffset": 82, "endOffset": 96}, {"referenceID": 14, "context": "The Fourier representation has found numerous recent applications in PAC learning [18, 15, 1, 2], but these ideas have not been fully exploited in the fields of probabilistic inference and graphical models.", "startOffset": 82, "endOffset": 96}, {"referenceID": 0, "context": "The Fourier representation has found numerous recent applications in PAC learning [18, 15, 1, 2], but these ideas have not been fully exploited in the fields of probabilistic inference and graphical models.", "startOffset": 82, "endOffset": 96}, {"referenceID": 1, "context": "The Fourier representation has found numerous recent applications in PAC learning [18, 15, 1, 2], but these ideas have not been fully exploited in the fields of probabilistic inference and graphical models.", "startOffset": 82, "endOffset": 96}, {"referenceID": 13, "context": "However, a rather surprising fact which was first discovered by Linial [14] is that factors corresponding to fairly general classes of logical forms admit a compact Fourier representation.", "startOffset": 71, "endOffset": 75}, {"referenceID": 8, "context": "The proof extends the famous Hastad\u2019s Switching Lemma[9] to the weighted case.", "startOffset": 53, "endOffset": 56}, {"referenceID": 6, "context": "The complexity of the VE algorithm depends on the size of largest factors generated during the elimination process, and is known to be exponential in the tree-width [7].", "startOffset": 165, "endOffset": 168}, {"referenceID": 3, "context": "Detcher proposed the Mini-bucket Elimination Algorithm [4], which dynamically decomposes and approximates factors (when the domain of a product exceeds a threshold) with the product of smaller factors during the elimination process.", "startOffset": 55, "endOffset": 58}, {"referenceID": 17, "context": "One classical result [18] states that if a function can be captured by a decision tree with depth d, then it can be represented with Fourier coefficients up to degree d: Theorem 1.", "startOffset": 21, "endOffset": 25}, {"referenceID": 13, "context": "Linial [14] proved the following key result: Theorem 3 (Linial).", "startOffset": 7, "endOffset": 11}, {"referenceID": 0, "context": "For a graphical model, we can always rescale each factor properly to ensure its range is within [0, 1] and the largest element is 1.", "startOffset": 96, "endOffset": 102}, {"referenceID": 8, "context": "The proof of theorem 4 relies on the notion of random restriction and our extension to the Hastad\u2019s Switching Lemma[9] to the class of weighted functions defined above.", "startOffset": 115, "endOffset": 118}, {"referenceID": 19, "context": "The formal proof of Lemma 1 is based on a clever generalization of the proof by Razborov for the unweighted case [20], and is deferred to the supplementary materials.", "startOffset": 113, "endOffset": 117}, {"referenceID": 18, "context": "We implemented the classical Ogata-Tanemura scheme [19] to estimate the partition function in MCMC.", "startOffset": 51, "endOffset": 55}, {"referenceID": 16, "context": "We use the implementation in LibDAI [17] for belief propagation.", "startOffset": 36, "endOffset": 40}, {"referenceID": 2, "context": "We first compare on small instances for which we can compute ground truth using Ace [3].", "startOffset": 84, "endOffset": 87}], "year": 2017, "abstractText": "Probabilistic inference is a key computational challenge in statistical machine learning and artificial intelligence. The ability to represent complex high dimensional probability distributions in a compact form is the most important insight in the field of graphical models. In this paper, we explore a novel way to exploit compact representations of highdimensional probability distributions in approximate probabilistic inference algorithms. Our approach is based on discrete Fourier Representation of weighted Boolean Functions, complementing the classical method to exploit conditional independence between the variables. We show that a large class of probabilistic graphical models have a compact Fourier representation. This theoretical result opens up an entirely new way of approximating a probability distribution. We demonstrate the significance of this approach by applying it to the variable elimination algorithm and comparing the results with the bucket representation and other approximate inference algorithms, obtaining very encouraging results.", "creator": "LaTeX with hyperref package"}}}