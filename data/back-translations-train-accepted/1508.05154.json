{"id": "1508.05154", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Aug-2015", "title": "Posterior calibration and exploratory analysis for natural language processing models", "abstract": "Many models in natural language processing define probabilistic distributions over linguistic structures. We argue that (1) the quality of a model' s posterior distribution can and should be directly evaluated, as to whether probabilities correspond to empirical frequencies, and (2) NLP uncertainty can be projected not only to pipeline components, but also to exploratory data analysis, telling a user when to trust and not trust the NLP analysis. We present a method to analyze calibration, and apply it to compare the miscalibration of several commonly used models. We also contribute a coreference sampling algorithm that can create confidence intervals for a political event extraction task.", "histories": [["v1", "Fri, 21 Aug 2015 00:25:51 GMT  (126kb,D)", "https://arxiv.org/abs/1508.05154v1", "12 pages (including supplementary information) in EMNLP 2015"], ["v2", "Wed, 2 Sep 2015 17:26:24 GMT  (126kb,D)", "http://arxiv.org/abs/1508.05154v2", "15 pages (including supplementary information), proceedings of EMNLP 2015"]], "COMMENTS": "12 pages (including supplementary information) in EMNLP 2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["khanh nguyen", "brendan o'connor"], "accepted": true, "id": "1508.05154"}, "pdf": {"name": "1508.05154.pdf", "metadata": {"source": "CRF", "title": "Posterior calibration and exploratory analysis for natural language processing models", "authors": ["Khanh Nguyen", "Brendan O\u2019Connor"], "emails": ["kxnguyen@cs.umd.edu", "brenocon@cs.umass.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "2 Definition of calibration", "text": "Consider a binary probability log, which consists of a binary label and probable prediction results. (Each instance has a down-to-earth label that is used for evaluation.) The prediction problem is to generate a predicted probability or predictive power q (0, 1). (Typically, we use some form of probable model to accomplish this task. (qN, yN) The predictive pairs of the model are produced by the model. Many metrics evaluate the overall quality of how well the predicted probabilities match the data, e.g. the known average log probability), L '(~ y, ~ q) = 1N."}, {"heading": "3 Empirical calibration analysis", "text": "From a test set of labeled data, we can analyze the model calibration both in terms of calibration error and visualize the calibration curve of label frequency versus predicted strength. However, the calculation of label frequencies P (y = 1 | q) requires an unlimited amount of data, so approximation methods are required to perform calibration analyses."}, {"heading": "3.1 Adaptive binning procedure", "text": "Previous studies evaluating calibration in supervised machine learning models (Niculescu-Mizil and Caruana, 2005; Bennett, 2000) calculate the frequency of labels by dividing the prediction space into deciles or other uniform distances - e.g. q [0, 0.1), q [0.1, 0.2), etc. - and then calculate the empirical label frequency in each garbage can. This method can be seen as using a form of non-parametric regression (in particular a regressogram; Tukey 1961) to calculate the function f (q) = P (y = 1 | q) from observed data points. But models in natural language processing give very scaled distributions of confidence values q (many are close to 0 or 1), so this method does not work well as there are much more variable estimates near algorithm 2."}, {"heading": "3.2 Confidence interval estimation", "text": "Since the estimation of confidence bands for non-parametric regression is an unsolved problem (Wasserman, 2006), we resort to a simple method based on binning. We construct a binomial normal approximation for the label frequency estimation in each container and simulate from it; each simulation across all containers is used to construct a calibration error; these simulated calibration errors are collected to construct a normal approximation for estimating the calibration error. Since we use container sizes of at least \u03b2 \u2265 200 in our experiments, the central limit theorem justifies these approximations. We report all calibration errors along with their 95% confidence intervals calculated according to Algorithm 2.7."}, {"heading": "3.3 Visualizing calibration", "text": "To better understand the calibration properties of a model, we plot the pairs (p-1, q-1), (p-2, q-2), \u00b7 \u00b7 \u00b7, (p-T, q-T) obtained through adaptive binning to visualize the calibration curve of the model - this visualization is known as a calibration or reliability graph. It provides finer-grained insights into the calibration behavior in various prediction ranges. A perfectly calibrated curve would agree with the y = x diagonal line. If the curve is above the diagrams, the model is uncertain (q < pq); and if it is below the diagrams, the model is overconfident (q > pq). One advantage of drawing a curve estimated from solid tanks is that the distribution of points indicates the refinement aspect of the model's performance. If the positions tend to cluster, the upper and lower edges tend to the left corners."}, {"heading": "4 Calibration for classification and tagging models", "text": "Using the method described in \u00a7 3, we assess the quality of subsequent predictions of several classification and tagging models. In all of our exper-7A models, the big unsolved problem is how to choose the container size fairly. If it is too large, the curve is smoothed over and the calibration looks better than it should be; if it is too small, the calibration looks worse than it should be. Bandwidth selection and cross validation techniques could better solve this problem in future work. Meanwhile, visualizations of the calibration curves help the reader to learn the resolution of a particular analysis - if the containers are far apart, the data is sparse and the specific details of the curve in these regions are not known."}, {"heading": "4.1 Naive Bayes and logistic regression", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1 Introduction", "text": "Previous work on Naive Bayes has found that the likelihood of calibration problems is higher, partly due to its flawed conditional assumptions of independence (Niculescu-Mizil and Caruana, 2005; Bennett, 2000; Domingos and Pazzani, 1997). Since logistical regression has the same loglinear representation capacity (Ng and Jordan, 2002) but does not suffer from the assumptions of independence, we select them for comparison and possibly hypothesize them better. We analyze a binary classification task of Twitter mood analysis from emoticons. We collect a data set consisting of tweets identified as English by the Twitter API, collected from 2014 to 2015, using the \"Emoticon Trick\" (Read, 2005; Lin and Kolcz, 2012) to identify tweets that contain at least one occurrence of smiley emoticons."}, {"heading": "4.1.2 Results", "text": "Naive Bayes achieves a slightly higher F-1 value (NB 73.8% vs. LR 72.9%), but logistic regression has a much lower calibration error: less than half as much RMSE (NB 0.105 vs. LR 0.041; Figure 2). Both models tend to be uncertain in the lower prediction range and overconfident in the higher range, but the tendency is more pronounced in Naive Bayes."}, {"heading": "4.2 Hidden Markov models and conditional random fields", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1 Introduction", "text": "Hidden Markov Models (HMM) and Linear Chain Random Fields (CRF) are another commonly used pair of analog generative and discriminatory models. Both define a posterior via tag sequences P (y | x), which we use on part-of-speech tagging. We can analyze these models within the scope of binary calibration (\u00a7 2-3) by looking at the marginal distribution of binary-rated results of parts of the predicted structures. To prepare a POS tagging dataset, we extract the calibration of the predicted probabilities of single token tags (\u00a7 4.2.2) and the pairs of consecutive tags (\u00a7 4.2.3), which are calculated using the forward-looking algorithm. To prepare a POS tagging dataset, we extract Wall Street Journal articles from the CoNLL-2011 Coreference Shared Task of Dataset Pradhan."}, {"heading": "4.2.2 Predicting single-word tags", "text": "In this experiment, we measure the miscalibration of the two models by predicting the tags of individual words. First, we generate a set of 33,306 prediction label pairs (for each token) for each tag type, and then link them together via the tags for calibration analysis. Figure 3 shows that the two models have different calibration patterns. HMM tends to be very uncertain, while the CRF is overconfident and the CRF as a whole has a smaller (better) calibration error. We also examine the calibration errors of the individual POS tags (Figure 4 (a). We find that CRF is calibrated much better than HMM in most, but not all categories (39 of 47). For example, they are calibrated roughly equally when predicting the NN tag."}, {"heading": "4.2.3 Predicting two-consecutive-word tags", "text": "There is no reason to limit ourselves to modelling predictions of single words; these models define marginal distributions over larger units of text. Next, we examine the calibration of subsequent predictions of tag pairs on two consecutive words in the test sentence. The same analysis may be relevant, for example, for phrase extraction or other chunking / parsing tasks: 00.0000.0250.0500.075NN IN NN P DT JJ Ave rage (5) Ave rage (all) LabelC alib ErrHMM CRF (a) We report the results for the five and 100 most common tag pairs (Figure 4 (b)). We observe a pattern similar to that seen in the individual tag experiment: The CRF is generally calibrated better than the HMM, but the HMM achieves better calibration errors in 29 out of 100 categories. These tagging experiments show that different models may have different calibration levels depending on the application."}, {"heading": "5 Coreference resolution", "text": "We are examining a third model, a probabilistic model for the co-ference of nouns within a document, which has an efficient sample-based inference method. In this section we present it and analyze its calibration, in preparation for the next section in which we will use it for exploratory data analysis."}, {"heading": "5.1 Antecedent selection model", "text": "We use the Berkeley Coreference Resolution System (Durrett and Klein, 2013), originally presented as CRF; we give it the equivalent of a set of independent logistic regressions (see Appendix for details).The primary component of this model is a locally normalized log-linear distribution across clusters of noun phrases, with each cluster denoting an entity.The model takes a fixed input of N mentions (noun phrases), indexed by i in their position order in the document. It postulates that each mention i has a latent antecedent selection decision, ai {1,..., i \u2212 1, NEW}, denotingwhich previous mention it assumes, or NEW appended when it starts a new entity that has not yet been seen at a previous position in the text. Such mention i-mention attachment of the entity is an entity entity entity entity entity."}, {"heading": "5.2 Sampling-based inference", "text": "This distribution is a complex mathematical object; an attractive approach to analyzing it is to take samples from this distribution and then analyze the samples.This precursor model allows a very simple method of taking independent e-samples by going through Def. 2: Independent Sample of each ai and then computing the related components of the resulting precursor diagram. Constructively, there are samples from the common distribution of e in this method (although we never calculate the probability of a single cluster forming e).Unlike approximate sample approaches, such as the Markov chain Monte Carlo methods used in other Korean ferencing work on Sample e (Haghighi and Klein, 2007), there are no questions about branding or autocorrelation (Kass et al., 1998).Each sample is independent and very fast to calculate - only slightly slower than the calculation of MAP assignment (due to exposure and normalization for each of these algorithms)."}, {"heading": "5.3 Calibration analysis", "text": "We consider the following inference query: for a randomly selected pair of mentions, are they koreferent? Even if the accuracy of the model is comparatively low, it may be the case that it is correctly calibrated - if it thinks that there should be great variability in entity clusters, it may be uncertain whether a pair of mentions should go together. Let \"ij be 1 if the mentions i and j are predicted as koreferent, and 0 otherwise. Annotated data define a gold standard\" (g) ij value for each pair i, j. Any probability distribution over e defines a marginal Bernoulli distribution for each sentence \"ij, marginalized e: P (\" ij = 1 | x) = 1 {(i, j) qqe} P (e | x) (2), where (i, j) ib) iff is true iff there is an entity that can say both as a character and a correlation with a traditional calibration."}, {"heading": "6 Uncertainty in Entity-based Exploratory Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Entity-syntactic event aggregation", "text": "rE \"s tis rf\u00fc ide rf\u00fc ide f\u00fc die f \u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc die f\u00fc"}, {"heading": "6.2 Results", "text": "In fact, most of them are able to outdo themselves, and they are able to outdo themselves, \"he said in an interview with The New York Times,\" I don't think they are able to change the world. \""}, {"heading": "7 Conclusion", "text": "In this paper, we argue that the calibration of posterior predictions is a desirable property of probabilistic NLP models and that it can be directly evaluated. We also show a use case of calibrated uncertainty: its propagation into downstream exploratory analyses.Our downstream simulation approach to exploratory and error analysis refers to Smith's downstream predictive verification (Gelman et al., 2013), which analyzes a downstream analysis of model assumptions; Mimno and Lead (2011) apply it to a thematic model.One possibility for future work is to investigate more effective non-parametric regression methods to better estimate and visualize calibration errors, such as Gaussian processes or bootstrapped nuclear density estimates. Another important question is: What types of conclusions are facilitated by correct calibration? Intuitively, we think that excessive confidence will lead to overly high confidence intervals, but all expectations are helpful."}, {"heading": "Acknowledgments", "text": "Thanks to Erik Learned-Miller, Benjamin Marlin, Craig Greenberg, Phan-Minh Nguyen, Caitlin Cellier and the CMU ARK Lab for discussions and comments, and to the anonymous reviewers (especially R3) for helpful suggestions."}, {"heading": "1 Sampling a deterministic function of a random variable", "text": "At several points in this thesis, we define probability distributions by deterministic functions of a random variable (1) (uncertain) x (uncertain). This should be constructively valid, but we provide the following argument for further justification. X is a random variable and g (x) is a deterministic function that takes a value of X as input. Since g depends on a random variable, g (X) is also a random variable. The distribution for g (X), or aspects thereof (such as a PMF or independent samples thereof) can be calculated by marginalizing X as input."}, {"heading": "2 Normalization in the coreference model", "text": "Durrett and Klein (2013) present their model as globally normalized but fully factorized CRF: P (a | x) = 1 Z-i exp (wTf (i, ai, x)) Since the factor function for each random variable ai decays independently of each other, their probabilities are actually independent and can be rewritten with local normalization, P (a | x) = 1 Zi exp (wTf (i, ai, x)). This interpretation justifies the use of independent samples to take posterior joint samples."}, {"heading": "3 Event analysis: Corpus selection, country affiliation, and parsing", "text": "In the New York Times Annotated Corpus, each article is labeled with a large number of labels. We contain articles that contain a category whose label begins with the string Top / News / World and excludes articles with a category that matches theregex / (Sports | Opinion), and whose body contains at least one country name.Country names are taken from the igos.txt dictionary, which is based on previous work (http: / / brenocon.com / irevents /). Country name matching is case-sensitive: When trying to compare a word with the lexicon, if a match is not found, it retreats to remove the last two characters. (This is usually unnecessary because the dictionary contains modification forms.) POS, NER and components and dependency savings are created with Stanford CoreNLP 3.5.2 with default settings, except for a change to reduce their shifting within the given parameters to reduce the speed of synchronization. \""}, {"heading": "4 Event time series graphs", "text": "The following pages contain downstream time series diagrams for 20 countries, as described in the section on Korean-based event aggregation, in order of decreasing overall event frequency. As in the main paper, the blue line indicates the rear mean, and the grey region indicates 95% subordinate credibility intervals, aggregating the count on a monthly basis. Titles are ISO3 country codes. 1990 1995 2000 2000 20050 20050 20050 1020 30USA0 1020 301990 1995 2000 20050 1020 3040IRQ0 1020 30401990 1995 2000 2000 20050 510 20SRB0 510 20090 1995 20050 20050 20050 24 681990 1995 1995 2000 20050 24 681990 1995 1995 20050 24 681990 1995 1995 1995 1995 KIGN0 AF681990 1995 1995 1995 1995 20050 24 68FRA0 681990 2002000 2000 2000 2000 2000 2000 2002000 2002000 20050 20050 20050"}], "references": [{"title": "Learning latent personas of film characters", "author": ["David Bamman", "Brendan O\u2019Connor", "Noah A. Smith"], "venue": "In Proceedings of ACL,", "citeRegEx": "Bamman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bamman et al\\.", "year": 2013}, {"title": "Assessing the calibration of naive Bayes\u2019 posterior estimates", "author": ["Paul N. Bennett"], "venue": "Technical report,", "citeRegEx": "Bennett.,? \\Q2000\\E", "shortCiteRegEx": "Bennett.", "year": 2000}, {"title": "Distance dependent Chinese restaurant processes", "author": ["David M. Blei", "Peter I. Frazier"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Blei and Frazier.,? \\Q2011\\E", "shortCiteRegEx": "Blei and Frazier.", "year": 2011}, {"title": "Automatic extraction of events from open source text for predictive forecasting", "author": ["Elizabeth Boschee", "Premkumar Natarajan", "Ralph Weischedel"], "venue": "Handbook of Computational Approaches to Counterterrorism,", "citeRegEx": "Boschee et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Boschee et al\\.", "year": 2013}, {"title": "Verification of forecasts expressed in terms of probability", "author": ["Glenn W. Brier"], "venue": "Monthly weather review,", "citeRegEx": "Brier.,? \\Q1950\\E", "shortCiteRegEx": "Brier.", "year": 1950}, {"title": "Reliability, sufficiency, and the decomposition of proper scores", "author": ["Jochen Br\u00f6cker"], "venue": "Quarterly Journal of the Royal Meteorological Society,", "citeRegEx": "Br\u00f6cker.,? \\Q2009\\E", "shortCiteRegEx": "Br\u00f6cker.", "year": 2009}, {"title": "Likelihood-ratio calibration using priorweighted proper scoring rules", "author": ["Niko Br\u00fcmmer", "George Doddington"], "venue": "arXiv preprint arXiv:1307.7981,", "citeRegEx": "Br\u00fcmmer and Doddington.,? \\Q2013\\E", "shortCiteRegEx": "Br\u00fcmmer and Doddington.", "year": 2013}, {"title": "The comparison and evaluation of forecasters", "author": ["Morris H. DeGroot", "Stephen E. Fienberg"], "venue": "The statistician,", "citeRegEx": "DeGroot and Fienberg.,? \\Q1983\\E", "shortCiteRegEx": "DeGroot and Fienberg.", "year": 1983}, {"title": "On the optimality of the simple Bayesian classifier under zero-one loss", "author": ["Pedro Domingos", "Michael Pazzani"], "venue": "Machine learning,", "citeRegEx": "Domingos and Pazzani.,? \\Q1997\\E", "shortCiteRegEx": "Domingos and Pazzani.", "year": 1997}, {"title": "Easy victories and uphill battles in coreference resolution", "author": ["Greg Durrett", "Dan Klein"], "venue": "In EMNLP, pages 1971\u20131982,", "citeRegEx": "Durrett and Klein.,? \\Q2013\\E", "shortCiteRegEx": "Durrett and Klein.", "year": 2013}, {"title": "A joint model for entity analysis: Coreference", "author": ["Greg Durrett", "Dan Klein"], "venue": "typing, and linking. Transactions of the Association for Computational Linguistics,", "citeRegEx": "Durrett and Klein.,? \\Q2014\\E", "shortCiteRegEx": "Durrett and Klein.", "year": 2014}, {"title": "Solving the problem of cascading errors: Approximate Bayesian inference for linguistic annotation pipelines", "author": ["Jenny Rose Finkel", "Christopher D. Manning", "Andrew Y. Ng"], "venue": "In Proceedings of the 2006 Conference on Empirical Methods", "citeRegEx": "Finkel et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Finkel et al\\.", "year": 2006}, {"title": "Bayesian data analysis", "author": ["Andrew Gelman", "John B. Carlin", "Hal S. Stern", "David B. Dunson", "Aki Vehtari", "Donald B. Rubin"], "venue": "Chapman and Hall/CRC,", "citeRegEx": "Gelman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gelman et al\\.", "year": 2013}, {"title": "Rich sourceside context for statistical machine translation", "author": ["Kevin Gimpel", "Noah A. Smith"], "venue": "In Proceedings of the Third Workshop on Statistical Machine Translation,", "citeRegEx": "Gimpel and Smith.,? \\Q2008\\E", "shortCiteRegEx": "Gimpel and Smith.", "year": 2008}, {"title": "Softmaxmargin CRFs: Training log-linear models with cost functions", "author": ["Kevin Gimpel", "Noah A. Smith"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association", "citeRegEx": "Gimpel and Smith.,? \\Q2010\\E", "shortCiteRegEx": "Gimpel and Smith.", "year": 2010}, {"title": "A systematic exploration of diversity in machine translation", "author": ["Kevin Gimpel", "Dhruv Batra", "Chris Dyer", "Gregory Shakhnarovich"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Gimpel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gimpel et al\\.", "year": 2013}, {"title": "Strictly proper scoring rules, prediction, and estimation", "author": ["Tilmann Gneiting", "Adrian E. Raftery"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Gneiting and Raftery.,? \\Q2007\\E", "shortCiteRegEx": "Gneiting and Raftery.", "year": 2007}, {"title": "Parsing algorithms and metrics", "author": ["Joshua Goodman"], "venue": "Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Goodman.,? \\Q1996\\E", "shortCiteRegEx": "Goodman.", "year": 1996}, {"title": "Markov chain Monte Carlo in practice: a roundtable discussion", "author": ["Robert E. Kass", "Bradley P. Carlin", "Andrew Gelman", "Radford M. Neal"], "venue": "The American Statistician,", "citeRegEx": "Kass et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Kass et al\\.", "year": 1998}, {"title": "Minimum Bayes-risk decoding for statistical machine translation", "author": ["Shankar Kumar", "William Byrne"], "venue": "HLT-NAACL 2004: Main Proceedings,", "citeRegEx": "Kumar and Byrne.,? \\Q2004\\E", "shortCiteRegEx": "Kumar and Byrne.", "year": 2004}, {"title": "GDELT: Global data on events, location, and tone", "author": ["Kalev Leetaru", "Philip A. Schrodt"], "venue": "In ISA Annual Convention,", "citeRegEx": "Leetaru and Schrodt.,? \\Q1979\\E", "shortCiteRegEx": "Leetaru and Schrodt.", "year": 1979}, {"title": "Large-scale machine learning at Twitter", "author": ["Jimmy Lin", "Alek Kolcz"], "venue": "In Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,", "citeRegEx": "Lin and Kolcz.,? \\Q2012\\E", "shortCiteRegEx": "Lin and Kolcz.", "year": 2012}, {"title": "Deep parsing in Watson", "author": ["Michael C. McCord", "J. William Murdock", "Branimir K. Boguraev"], "venue": "IBM Journal of Research and Development,", "citeRegEx": "McCord et al\\.,? \\Q2012\\E", "shortCiteRegEx": "McCord et al\\.", "year": 2012}, {"title": "Bayesian checking for topic models", "author": ["David Mimno", "David Blei"], "venue": "In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Mimno and Blei.,? \\Q2011\\E", "shortCiteRegEx": "Mimno and Blei.", "year": 2011}, {"title": "A general framework for forecast verification", "author": ["Allan H. Murphy", "Robert L. Winkler"], "venue": "Monthly Weather Review,", "citeRegEx": "Murphy and Winkler.,? \\Q1987\\E", "shortCiteRegEx": "Murphy and Winkler.", "year": 1987}, {"title": "Predicting good probabilities with supervised learning", "author": ["Alexandru Niculescu-Mizil", "Rich Caruana"], "venue": "In Proceedings of the 22nd International Conference on Machine Learning,", "citeRegEx": "Niculescu.Mizil and Caruana.,? \\Q2005\\E", "shortCiteRegEx": "Niculescu.Mizil and Caruana.", "year": 2005}, {"title": "Learning to extract international relations from political context", "author": ["Brendan O\u2019Connor", "Brandon Stewart", "Noah A. Smith"], "venue": "In Proceedings of ACL,", "citeRegEx": "O.Connor et al\\.,? \\Q2013\\E", "shortCiteRegEx": "O.Connor et al\\.", "year": 2013}, {"title": "Crfsuite: a fast implementation of conditional random fields (CRFs)", "author": ["Naoaki Okazaki"], "venue": null, "citeRegEx": "Okazaki.,? \\Q2007\\E", "shortCiteRegEx": "Okazaki.", "year": 2007}, {"title": "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In Advances in large margin classifiers", "author": ["John Platt"], "venue": null, "citeRegEx": "Platt.,? \\Q2000\\E", "shortCiteRegEx": "Platt.", "year": 2000}, {"title": "CoNLL-2011 shared task: Modeling unrestricted coreference in Ontonotes", "author": ["Sameer Pradhan", "Lance Ramshaw", "Mitchell Marcus", "Martha Palmer", "Ralph Weischedel", "Nianwen Xue"], "venue": "In Proceedings of the Fifteenth Conference", "citeRegEx": "Pradhan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2011}, {"title": "Using emoticons to reduce dependency in machine learning techniques for sentiment classification", "author": ["Jonathon Read"], "venue": "In Proceedings of the ACL Student Research Workshop,", "citeRegEx": "Read.,? \\Q2005\\E", "shortCiteRegEx": "Read.", "year": 2005}, {"title": "The New York Times Annotated Corpus", "author": ["Evan Sandhaus"], "venue": "Linguistic Data Consortium,", "citeRegEx": "Sandhaus.,? \\Q2008\\E", "shortCiteRegEx": "Sandhaus.", "year": 2008}, {"title": "Precedents, progress, and prospects in political event data", "author": ["Philip A. Schrodt"], "venue": "International Interactions,", "citeRegEx": "Schrodt.,? \\Q2012\\E", "shortCiteRegEx": "Schrodt.", "year": 2012}, {"title": "Joint inference of entities, relations, and coreference", "author": ["Sameer Singh", "Sebastian Riedel", "Brian Martin", "Jiaping Zheng", "Andrew McCallum"], "venue": "In Proceedings of the 2013 Workshop on Automated Knowledge Base Construction,", "citeRegEx": "Singh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Singh et al\\.", "year": 2013}, {"title": "Minimum risk annealing for training log-linear models", "author": ["David A. Smith", "Jason Eisner"], "venue": "In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,", "citeRegEx": "Smith and Eisner.,? \\Q2006\\E", "shortCiteRegEx": "Smith and Eisner.", "year": 2006}, {"title": "A global joint model for semantic role labeling", "author": ["Kristina Toutanova", "Aria Haghighi", "Christopher D. Manning"], "venue": "Computational Linguistics,", "citeRegEx": "Toutanova et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2008}, {"title": "Wider pipelines: Nbest alignments and parses in MT training", "author": ["Ashish Venugopal", "Andreas Zollmann", "Noah A. Smith", "Stephan Vogel"], "venue": "In Proceedings of AMTA,", "citeRegEx": "Venugopal et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Venugopal et al\\.", "year": 2008}, {"title": "All of nonparametric statistics", "author": ["Larry Wasserman"], "venue": "Springer Science & Business Media,", "citeRegEx": "Wasserman.,? \\Q2006\\E", "shortCiteRegEx": "Wasserman.", "year": 2006}, {"title": "Transforming classifier scores into accurate multiclass probability estimates", "author": ["Bianca Zadrozny", "Charles Elkan"], "venue": "In Proceedings of KDD,", "citeRegEx": "Zadrozny and Elkan.,? \\Q2002\\E", "shortCiteRegEx": "Zadrozny and Elkan.", "year": 2002}], "referenceMentions": [{"referenceID": 22, "context": "But these systems are accurate enough so that their outputs can be used as soft, if noisy, indicators of language meaning for use in downstream analysis, such as systems that perform question answering, machine translation, event extraction, and narrative analysis (McCord et al., 2012; Gimpel and Smith, 2008; Miwa et al., 2010; Bamman et al., 2013).", "startOffset": 265, "endOffset": 350}, {"referenceID": 13, "context": "But these systems are accurate enough so that their outputs can be used as soft, if noisy, indicators of language meaning for use in downstream analysis, such as systems that perform question answering, machine translation, event extraction, and narrative analysis (McCord et al., 2012; Gimpel and Smith, 2008; Miwa et al., 2010; Bamman et al., 2013).", "startOffset": 265, "endOffset": 350}, {"referenceID": 0, "context": "But these systems are accurate enough so that their outputs can be used as soft, if noisy, indicators of language meaning for use in downstream analysis, such as systems that perform question answering, machine translation, event extraction, and narrative analysis (McCord et al., 2012; Gimpel and Smith, 2008; Miwa et al., 2010; Bamman et al., 2013).", "startOffset": 265, "endOffset": 350}, {"referenceID": 11, "context": "com/nlpcalib/ But a probabilistic model gives a probability distribution over many other output structures that have smaller predicted probabilities; a line of work has sought to control cascading pipeline errors by passing on multiple structures from earlier stages of analysis, by propagating prediction uncertainty through multiple samples (Finkel et al., 2006), K-best lists (Venugopal et al.", "startOffset": 343, "endOffset": 364}, {"referenceID": 36, "context": ", 2006), K-best lists (Venugopal et al., 2008; Toutanova et al., 2008), or explicitly diverse lists (Gimpel et al.", "startOffset": 22, "endOffset": 70}, {"referenceID": 35, "context": ", 2006), K-best lists (Venugopal et al., 2008; Toutanova et al., 2008), or explicitly diverse lists (Gimpel et al.", "startOffset": 22, "endOffset": 70}, {"referenceID": 15, "context": ", 2008), or explicitly diverse lists (Gimpel et al., 2013); often the goal is to marginalize over structures to calculate and minimize an expected loss function, as in minimum Bayes risk decoding (Goodman, 1996; Kumar and Byrne, 2004), or to perform joint inference between early and later stages of NLP analysis (e.", "startOffset": 37, "endOffset": 58}, {"referenceID": 17, "context": ", 2013); often the goal is to marginalize over structures to calculate and minimize an expected loss function, as in minimum Bayes risk decoding (Goodman, 1996; Kumar and Byrne, 2004), or to perform joint inference between early and later stages of NLP analysis (e.", "startOffset": 145, "endOffset": 183}, {"referenceID": 19, "context": ", 2013); often the goal is to marginalize over structures to calculate and minimize an expected loss function, as in minimum Bayes risk decoding (Goodman, 1996; Kumar and Byrne, 2004), or to perform joint inference between early and later stages of NLP analysis (e.", "startOffset": 145, "endOffset": 183}, {"referenceID": 10, "context": ", 2013); often the goal is to marginalize over structures to calculate and minimize an expected loss function, as in minimum Bayes risk decoding (Goodman, 1996; Kumar and Byrne, 2004), or to perform joint inference between early and later stages of NLP analysis (e.g. Singh et al., 2013; Durrett and Klein, 2014).", "startOffset": 262, "endOffset": 312}, {"referenceID": 4, "context": "or mean squared error, also known as the Brier score when y is binary (Brier, 1950),", "startOffset": 70, "endOffset": 83}, {"referenceID": 24, "context": "where P(y | q) denotes the label empirical frequency, conditional on a prediction strength (Murphy and Winkler, 1987).", "startOffset": 91, "endOffset": 117}, {"referenceID": 7, "context": "5 Applying this factorization to the Brier score leads to the calibrationrefinement decomposition (DeGroot and Fienberg, 1983), in terms of expectations with respect to the prediction strength distribution P(q):", "startOffset": 98, "endOffset": 126}, {"referenceID": 16, "context": "These two loss functions are instances of proper scoring rules (Gneiting and Raftery, 2007; Br\u00f6cker, 2009).", "startOffset": 63, "endOffset": 106}, {"referenceID": 5, "context": "These two loss functions are instances of proper scoring rules (Gneiting and Raftery, 2007; Br\u00f6cker, 2009).", "startOffset": 63, "endOffset": 106}, {"referenceID": 5, "context": "They all include a notion of calibration corresponding to a Bregman divergence (Br\u00f6cker, 2009); for example, crossentropy can be broken down such that KL divergence is the measure of miscalibration.", "startOffset": 79, "endOffset": 94}, {"referenceID": 25, "context": "Previous studies that assess calibration in supervised machine learning models (Niculescu-Mizil and Caruana, 2005; Bennett, 2000) calculate label frequencies by dividing the prediction space into deciles or other evenly spaced bins\u2014e.", "startOffset": 79, "endOffset": 129}, {"referenceID": 1, "context": "Previous studies that assess calibration in supervised machine learning models (Niculescu-Mizil and Caruana, 2005; Bennett, 2000) calculate label frequencies by dividing the prediction space into deciles or other evenly spaced bins\u2014e.", "startOffset": 79, "endOffset": 129}, {"referenceID": 37, "context": "Since how to estimate confidence bands for nonparametric regression is an unsolved problem (Wasserman, 2006), we resort to a simple method based on the binning.", "startOffset": 91, "endOffset": 108}, {"referenceID": 25, "context": "Previous work on Naive Bayes has found its probabilities to have calibration issues, in part due to its incorrect conditional independence assumptions (Niculescu-Mizil and Caruana, 2005; Bennett, 2000; Domingos and Pazzani, 1997).", "startOffset": 151, "endOffset": 229}, {"referenceID": 1, "context": "Previous work on Naive Bayes has found its probabilities to have calibration issues, in part due to its incorrect conditional independence assumptions (Niculescu-Mizil and Caruana, 2005; Bennett, 2000; Domingos and Pazzani, 1997).", "startOffset": 151, "endOffset": 229}, {"referenceID": 8, "context": "Previous work on Naive Bayes has found its probabilities to have calibration issues, in part due to its incorrect conditional independence assumptions (Niculescu-Mizil and Caruana, 2005; Bennett, 2000; Domingos and Pazzani, 1997).", "startOffset": 151, "endOffset": 229}, {"referenceID": 30, "context": "We collect a dataset consisting of tweets identified by the Twitter API as English, collected from 2014 to 2015, with the \u201cemoticon trick\u201d (Read, 2005; Lin and Kolcz, 2012) to label tweets that contain at least one occurrence of the smiley emoticon \u201c:)\u201d as \u201chappy\u201d (y = 1) and others as y = 0.", "startOffset": 139, "endOffset": 172}, {"referenceID": 21, "context": "We collect a dataset consisting of tweets identified by the Twitter API as English, collected from 2014 to 2015, with the \u201cemoticon trick\u201d (Read, 2005; Lin and Kolcz, 2012) to label tweets that contain at least one occurrence of the smiley emoticon \u201c:)\u201d as \u201chappy\u201d (y = 1) and others as y = 0.", "startOffset": 139, "endOffset": 172}, {"referenceID": 29, "context": "To prepare a POS tagging dataset, we extract Wall Street Journal articles from the English CoNLL-2011 coreference shared task dataset from Ontonotes (Pradhan et al., 2011), using the CoNLL-2011 splits for training, development and testing.", "startOffset": 149, "endOffset": 171}, {"referenceID": 27, "context": "CRFsuite (Okazaki, 2007).", "startOffset": 9, "endOffset": 24}, {"referenceID": 9, "context": "We use the Berkeley coreference resolution system (Durrett and Klein, 2013), which was originally presented as a CRF; we give it an equivalent a series of independent logistic regressions (see appendix for details).", "startOffset": 50, "endOffset": 75}, {"referenceID": 2, "context": "In a manner similar to a distance-dependent Chinese restaurant process (Blei and Frazier, 2011), it is non-parametric in the sense that the number of clusters M is not fixed in advance.", "startOffset": 71, "endOffset": 95}, {"referenceID": 18, "context": "Unlike approximate sampling approaches, such as Markov chain Monte Carlo methods used in other coreference work to sample e (Haghighi and Klein, 2007), here there are no questions about burn-in or autocorrelation (Kass et al., 1998).", "startOffset": 213, "endOffset": 232}, {"referenceID": 32, "context": "We illustrate with an event analysis application to count the number of \u201ccountry attack events\u201d: for a particular country of the world, how many news articles describe an entity affiliated with that country as the agent of an attack, and how does this number change over time? This is a simplified version of a problem where such systems have been built and used for political science analysis (Schrodt et al., 1994; Schrodt, 2012; Leetaru and Schrodt, 2013; Boschee et al., 2013; O\u2019Connor et al., 2013).", "startOffset": 394, "endOffset": 503}, {"referenceID": 3, "context": "We illustrate with an event analysis application to count the number of \u201ccountry attack events\u201d: for a particular country of the world, how many news articles describe an entity affiliated with that country as the agent of an attack, and how does this number change over time? This is a simplified version of a problem where such systems have been built and used for political science analysis (Schrodt et al., 1994; Schrodt, 2012; Leetaru and Schrodt, 2013; Boschee et al., 2013; O\u2019Connor et al., 2013).", "startOffset": 394, "endOffset": 503}, {"referenceID": 26, "context": "We illustrate with an event analysis application to count the number of \u201ccountry attack events\u201d: for a particular country of the world, how many news articles describe an entity affiliated with that country as the agent of an attack, and how does this number change over time? This is a simplified version of a problem where such systems have been built and used for political science analysis (Schrodt et al., 1994; Schrodt, 2012; Leetaru and Schrodt, 2013; Boschee et al., 2013; O\u2019Connor et al., 2013).", "startOffset": 394, "endOffset": 503}, {"referenceID": 31, "context": "We tag and parse a 193,403 article subset of the Annotated New York Times LDC corpus (Sandhaus, 2008), which includes articles about world", "startOffset": 85, "endOffset": 101}, {"referenceID": 11, "context": "This highlights an alternative use of Finkel et al. (2006)\u2019s approach of sampling multiple NLP pipeline components, which in that work was used to perform joint inference.", "startOffset": 38, "endOffset": 59}, {"referenceID": 12, "context": "Our posterior simulation approach for exploratory and error analysis relates to posterior predictive checking (Gelman et al., 2013), which analyzes a posterior to test model assumptions; Mimno and Blei (2011) apply it to a topic model.", "startOffset": 110, "endOffset": 131}, {"referenceID": 12, "context": "Our posterior simulation approach for exploratory and error analysis relates to posterior predictive checking (Gelman et al., 2013), which analyzes a posterior to test model assumptions; Mimno and Blei (2011) apply it to a topic model.", "startOffset": 111, "endOffset": 209}, {"referenceID": 25, "context": "Finally, it may be interesting to pursue recalibration methods, which readjust a non-calibrated model\u2019s predictions to be calibrated; recalibration methods have been developed for binary (Platt, 1999; Niculescu-Mizil and Caruana, 2005) and multiclass (Zadrozny and Elkan, 2002) classification settings, but we are unaware of methods appropriate for the highly structured outputs typical in linguistic analysis.", "startOffset": 187, "endOffset": 235}, {"referenceID": 38, "context": "Finally, it may be interesting to pursue recalibration methods, which readjust a non-calibrated model\u2019s predictions to be calibrated; recalibration methods have been developed for binary (Platt, 1999; Niculescu-Mizil and Caruana, 2005) and multiclass (Zadrozny and Elkan, 2002) classification settings, but we are unaware of methods appropriate for the highly structured outputs typical in linguistic analysis.", "startOffset": 251, "endOffset": 277}, {"referenceID": 34, "context": "Another approach might be to directly constrain CalibErr = 0 during training, or try to reduce it as a training-time risk minimization or cost objective (Smith and Eisner, 2006; Gimpel and Smith, 2010; Stoyanov et al., 2011; Br\u00fcmmer and Doddington, 2013).", "startOffset": 153, "endOffset": 254}, {"referenceID": 14, "context": "Another approach might be to directly constrain CalibErr = 0 during training, or try to reduce it as a training-time risk minimization or cost objective (Smith and Eisner, 2006; Gimpel and Smith, 2010; Stoyanov et al., 2011; Br\u00fcmmer and Doddington, 2013).", "startOffset": 153, "endOffset": 254}, {"referenceID": 6, "context": "Another approach might be to directly constrain CalibErr = 0 during training, or try to reduce it as a training-time risk minimization or cost objective (Smith and Eisner, 2006; Gimpel and Smith, 2010; Stoyanov et al., 2011; Br\u00fcmmer and Doddington, 2013).", "startOffset": 153, "endOffset": 254}], "year": 2015, "abstractText": "Many models in natural language processing define probabilistic distributions over linguistic structures. We argue that (1) the quality of a model\u2019s posterior distribution can and should be directly evaluated, as to whether probabilities correspond to empirical frequencies; and (2) NLP uncertainty can be projected not only to pipeline components, but also to exploratory data analysis, telling a user when to trust and not trust the NLP analysis. We present a method to analyze calibration, and apply it to compare the miscalibration of several commonly used models. We also contribute a coreference sampling algorithm that can create confidence intervals for a political event extraction task.1", "creator": "LaTeX with hyperref package"}}}