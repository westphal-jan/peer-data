{"id": "1508.05170", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Aug-2015", "title": "Adaptive Online Learning", "abstract": "We propose a general framework for studying adaptive regret bounds in the online learning framework, including model selection bounds and data-dependent bounds. Given a data- or model-dependent bound we ask, \"Does there exist some algorithm achieving this bound?\" We show that modifications to recently introduced sequential complexity measures can be used to answer this question by providing sufficient conditions under which adaptive rates can be achieved. In particular each adaptive rate induces a set of so-called offset complexity measures, and obtaining small upper bounds on these quantities is sufficient to demonstrate achievability. A cornerstone of our analysis technique is the use of one-sided tail inequalities to bound suprema of offset random processes.", "histories": [["v1", "Fri, 21 Aug 2015 03:44:43 GMT  (32kb,D)", "http://arxiv.org/abs/1508.05170v1", "27 pages"]], "COMMENTS": "27 pages", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["dylan j foster", "alexander rakhlin", "karthik sridharan"], "accepted": true, "id": "1508.05170"}, "pdf": {"name": "1508.05170.pdf", "metadata": {"source": "CRF", "title": "Adaptive Online Learning", "authors": ["Dylan J. Foster", "Alexander Rakhlin", "Karthik Sridharan"], "emails": [], "sections": [{"heading": null, "text": "Our framework gains and improves a variety of adaptive boundaries, including quantile boundaries, second-order data-dependent boundaries, and small loss boundaries. In addition, we derive a new type of adaptive boundary for linear online optimization based on the spectral standard, as well as a new online PAC Bayes theorem that applies to countless infinite quantities."}, {"heading": "1 Introduction", "text": "In fact, \"he said,\" it's not like we're going to solve the problem, \"he said.\" But it's not like we're going to solve the problem. \"\" It's not like we're going to solve the problem, \"he said.\" But it's not like we're going to solve the problem. \"\" It's not like we're going to do it. \""}, {"heading": "1.1 Framework", "text": "Let X be the set of observations, D the space of decisions, and Y the set of results. Let (S) denote the set of distributions on a set S. Let \": D \u00b7 Y \u2192 R be a loss function. The online learning framework is defined by the following process: For t = 1,.., n, nature provides input instance xt X; learner selects prediction distribution qt (D); nature provides marking yt-Y, while the learner draws predictions and suffers losses\" (y-t, yt). Two specific scenarios of interest are monitored (Y R, D R) and online linear (or convex) optimization (X = 0} is the singleton set, Y and D are standard balls in dual band spaces and \"(y-yf)."}, {"heading": "1.2 Related Work", "text": "The case where Bn (f; x1: n, y1: n) = Bn (x1: n, y1: n) does not depend on f, has received the most attention in the literature, focusing on limits that may be narrower for \"beautiful sequences,\" but the current work was motivated in part by the work of [14], which presents an algorithm that competes with all experts at the same time, but with varying regrets in relation to each of them, depending on the quantity of the expert, and [13] in the expert setting. The present paper is a limit of type Bn (f) (depending on f, f denotes the quantity that refers to the quantity)."}, {"heading": "2 Adaptive Rates and Achievability: General Setup", "text": "The first step in building a general theory of adaptive online learning is to determine what adaptive remorse limits are possible (= 1). Remember that an adaptive remorse limit of Bn: F \u00b7 Xn \u00b7 Yn \u2192 R is achievable if there is an online learning algorithm that produces predictions / decisions in such a way that (2).In the rest of the work we can formalize the notation of Bn \u00b2 n to define the interleaved application of operators within the brackets, repeated over t = 1., n rounds (see [21]). Achievability of an adaptive rate can be quantified by the following minimax. Definition of Bn we define the offset minimax value: An (F, Bn)."}, {"heading": "3 Probabilistic Tools", "text": "As mentioned in the introduction, our technique is based on certain one-sided probable inequalities. We now specify the first building block: a fairly simple maximum inequality."}, {"heading": "4 Achievable Bounds", "text": "In this section, we will use Lemma 1 together with the probabilistic tools from the previous section to obtain a set of achievable adaptive limits for various online learning problems. We will divide the section into a subsection for each category of adaptive limits described in Section 1.1."}, {"heading": "4.1 Adapting to Data", "text": "Consider here the fit rates of the form Bn (x1: n, y1: n) or Bn (y1: n), uniform over f \u00b2 F. We show the performance of the developed tools using the following example. Example 4.1 (Online linear optimization in Rd). Consider the problem of linear online optimization, where F = {f \u00b2 f \u00b2 2 \u2264 1}, Y = {y = 2 \u2264 1}, X = {0}, and '(y \u00b2, y) = y \u00b2, y \u00b2. The following fit rate is achievable: Bn (y1: n) = 16 \u221a d log (n) XXXXXXXXXXX (n \u00b2 t = 1 yty t) 1 / 2XXXXXXXXXXXXXXXL + 16 \u2012 d log (n), at which the spectral standard is."}, {"heading": "4.2 Model Adaptation", "text": "D (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). ("}, {"heading": "4.3 Adapting to Data and Model Simultaneously", "text": "We can imagine the predictable sequence Mt as a previous hypothesis that we would compare with the hypothesis. Of particular interest is the example of the online optimistic PAC-Bayesian group, which - in contrast to previous results - does not depend on the number of experts and is therefore responsible for numerically infinite sets of experts. At the same time, the bound experts can adapt to the loss of the mix of experts. Example 4.3 (Generalized Predictable Sequences (Supervised Learning)) and provides an exact analogy to the PAC Bayesian theorem of statistical learning. Further quantitative expert limits can easily be recovered from the result. Example 4.3 (Generalized Sequences). (Supervised Learning). Consider an exact analogy with a convex 1-Lipschitz loss. Let (Mt) t. 1 be any predictable sequence that the learner can calculate based on information."}, {"heading": "5 Relaxations for Adaptive Learning", "text": "(1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (1) \"We must adjust.\" (2) \"We must adjust.\" (2) \"(2)\" We must adjust. \"(2)\" (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2). (2. (2). (2). (2.). (2.). (2.). (2.). (2. (2.). (2.). (2.). (2.). (2.). (2.). (2.). (2.).). (3.). (3.).). (3. (3.). (3.). (3.). (3.). (3.). (3.). (3.). (3.). (3.).). (3.).). (3. (3.). (3.). (3.).). (3.). (3.). (3.). (3.). (3.). (3.). (3.). (3.). (3.).). (3.). (3.). (3.). (3.).). (3.). (3.).). (3. (3.). (3.).). (3."}, {"heading": "A Appendix", "text": "We start from the definition of An (F) by starting with the nth term and then working backwards by repeating the Minimax theory. (For this purpose we start with the innermost term as, sup xn). (For this purpose, in lines similar to those in [24, 7, 21], we start with the innermost term as, sup xn. \"(F). (F). (F). (n). (F). (F). (F). (F). (n). (F). (F). (n). (F). (F). (n). (F). (F). (n). (F). (F). (F). (F). (F). (F). (F). (n). (F). (n). (F). (n). (f). (f). (f)."}, {"heading": "B Relaxations and Algorithms", "text": "The proof of admissibility for Example 5.1.Lemma 12. The following limit is attainable in the situation given in Example 5.1: Bn (f) = 3 \u221a 2nmax {KL (f) \u2212 n (1) + 1). (17) Following the analysis of Corollary 8, we directly consider an upper limit based on KL (f). Specifically: We move from (17) to the upper limit (i) = 3 \u00b0 nRi + 4 \u00b0 nRi = 2i \u2212 1 \u00b0 n. To keep the analysis as tidy as possible, we will examine the attainability of Bn (i) = D \u00b2 n, setting of D \u00b2 n \u00b2 s and including additional constants only when we reach a point in the analysis where it becomes necessary."}], "references": [{"title": "Minimum contrast estimators on sieves: exponential bounds and rates of convergence", "author": ["Lucien Birg\u00e9", "Pascal Massart"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1998}, {"title": "Adaptive model selection using empirical complexities", "author": ["G\u00e1bor Lugosi", "Andrew B Nobel"], "venue": "Annals of Statistics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1999}, {"title": "Model selection and error estimation", "author": ["Peter L. Bartlett", "St\u00e9phane Boucheron", "G\u00e1bor Lugosi"], "venue": "Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Concentration inequalities and model selection, volume", "author": ["Pascal Massart"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2007}, {"title": "Learning without Concentration", "author": ["Shahar Mendelson"], "venue": "In Conference on Learning Theory,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Learning with square loss: Localization through offset rademacher complexity", "author": ["Tengyuan Liang", "Alexander Rakhlin", "Karthik Sridharan"], "venue": "Proceedings of The 28th Conference on Learning Theory,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Online nonparametric regression", "author": ["Alexander Rakhlin", "Karthik Sridharan"], "venue": "Proceedings of The 27th Conference on Learning Theory,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Online learning: Random averages, combinatorial parameters, and learnability", "author": ["Alexander Rakhlin", "Karthik Sridharan", "Ambuj Tewari"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2010}, {"title": "Extracting certainty from uncertainty: Regret bounded by variation in costs", "author": ["Elad Hazan", "Satyen Kale"], "venue": "Machine learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2010}, {"title": "Online optimization with gradual variations", "author": ["Chao-Kai Chiang", "Tianbao Yang", "Chia-Jung Lee", "Mehrdad Mahdavi", "Chi-Jen Lu", "Rong Jin", "Shenghuo Zhu"], "venue": "In COLT,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Online learning with predictable sequences", "author": ["Alexander Rakhlin", "Karthik Sridharan"], "venue": "In Proceedings of the 26th Annual Conference on Learning Theory (COLT),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Improved second-order bounds for prediction with expert advice", "author": ["Nicolo Cesa-Bianchi", "Yishay Mansour", "Gilles Stoltz"], "venue": "Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2007}, {"title": "A parameter-free hedging algorithm", "author": ["Kamalika Chaudhuri", "Yoav Freund", "Daniel J Hsu"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Unconstrained online linear learning in hilbert spaces: Minimax algorithms and normal approximations", "author": ["H. Brendan McMahan", "Francesco Orabona"], "venue": "Proceedings of The 27th Conference on Learning Theory,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Prediction, Learning, and Games", "author": ["Nicolo Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "Smoothness, low noise and fast rates", "author": ["Nathan Srebro", "Karthik Sridharan", "Ambuj Tewari"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Achieving all with no parameters: Adaptive normalhedge", "author": ["Haipeng Luo", "Robert E. Schapire"], "venue": "CoRR, abs/1502.05934,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Second-order quantile methods for experts and combinatorial games", "author": ["Wouter M. Koolen", "Tim van Erven"], "venue": "In Proceedings of the 28th Annual Conference on Learning Theory (COLT),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2015}, {"title": "Behavior of sequential predictors of binary sequences. In in Trans. 4th Prague Conference on Information Theory, Statistical Decision Functions, Random Processes, pages 263\u2013272", "author": ["Thomas M. Cover"], "venue": "Publishing House of the Czechoslovak Academy of Sciences,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1967}, {"title": "Statistical learning theory and sequential prediction", "author": ["Alexander Rakhlin", "Karthik Sridharan"], "venue": null, "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Optimum bounds for the distributions of martingales in banach spaces", "author": ["Iosif Pinelis"], "venue": "The Annals of Probability, 22(4):1679\u20131706,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1994}, {"title": "Online learning: Beyond regret", "author": ["Alexander Rakhlin", "Karthik Sridharan", "Ambuj Tewari"], "venue": "arXiv preprint arXiv:1011.3168,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2010}, {"title": "Sequential complexities and uniform martingale laws of large numbers", "author": ["Alexander Rakhlin", "Karthik Sridharan", "Ambuj Tewari"], "venue": "Probability Theory and Related Fields,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Regret to the best vs. regret to the average", "author": ["Eyal Even-Dar", "Michael Kearns", "Yishay Mansour", "Jennifer Wortman"], "venue": "Machine Learning,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "Oracle inequalities and model selection have been topics of intense research in statistics in the last two decades [1, 2, 3].", "startOffset": 115, "endOffset": 124}, {"referenceID": 1, "context": "Oracle inequalities and model selection have been topics of intense research in statistics in the last two decades [1, 2, 3].", "startOffset": 115, "endOffset": 124}, {"referenceID": 2, "context": "Oracle inequalities and model selection have been topics of intense research in statistics in the last two decades [1, 2, 3].", "startOffset": 115, "endOffset": 124}, {"referenceID": 3, "context": "In order to select a good model in a data-driven manner, one first establishes non-asymptotic data-dependent bounds on the fluctuations of an empirical process indexed by elements in each model (see the monograph [4]).", "startOffset": 213, "endOffset": 216}, {"referenceID": 4, "context": "This realization is motivated by the recent work of [5, 6, 7].", "startOffset": 52, "endOffset": 61}, {"referenceID": 5, "context": "This realization is motivated by the recent work of [5, 6, 7].", "startOffset": 52, "endOffset": 61}, {"referenceID": 6, "context": "This realization is motivated by the recent work of [5, 6, 7].", "startOffset": 52, "endOffset": 61}, {"referenceID": 6, "context": "At the high level, our approach will be to develop one-sided inequalities for the suprema of certain offset processes [7], with an offset that is chosen to be \u201cslightly larger\u201d than the complexity of the corresponding model.", "startOffset": 118, "endOffset": 121}, {"referenceID": 7, "context": "For example, sequential Rademacher complexity of F is one of the tightest achievable uniform rates for a variety of loss functions [8, 7].", "startOffset": 131, "endOffset": 137}, {"referenceID": 6, "context": "For example, sequential Rademacher complexity of F is one of the tightest achievable uniform rates for a variety of loss functions [8, 7].", "startOffset": 131, "endOffset": 137}, {"referenceID": 8, "context": "An incomplete list of prior work includes [9, 10, 11, 12], couched in the setting of online linear/convex optimization, and [13] in the experts setting.", "startOffset": 42, "endOffset": 57}, {"referenceID": 9, "context": "An incomplete list of prior work includes [9, 10, 11, 12], couched in the setting of online linear/convex optimization, and [13] in the experts setting.", "startOffset": 42, "endOffset": 57}, {"referenceID": 10, "context": "An incomplete list of prior work includes [9, 10, 11, 12], couched in the setting of online linear/convex optimization, and [13] in the experts setting.", "startOffset": 42, "endOffset": 57}, {"referenceID": 11, "context": "An incomplete list of prior work includes [9, 10, 11, 12], couched in the setting of online linear/convex optimization, and [13] in the experts setting.", "startOffset": 42, "endOffset": 57}, {"referenceID": 12, "context": "An incomplete list of prior work includes [9, 10, 11, 12], couched in the setting of online linear/convex optimization, and [13] in the experts setting.", "startOffset": 124, "endOffset": 128}, {"referenceID": 13, "context": "The present paper was partly motivated by the work of [14] who presented an algorithm that competes with all experts simultaneously, but with varied regret with respect to each of them, depending on the quantile of the expert.", "startOffset": 54, "endOffset": 58}, {"referenceID": 14, "context": "The work of [15] considers online linear optimization with an unbounded set and provides oracle inequalities with an appropriately chosen function Bn(f).", "startOffset": 12, "endOffset": 16}, {"referenceID": 16, "context": "4], [17, 13]) fall in this category trivially, since one may overbound the loss of the best function by the performance of f .", "startOffset": 4, "endOffset": 12}, {"referenceID": 12, "context": "4], [17, 13]) fall in this category trivially, since one may overbound the loss of the best function by the performance of f .", "startOffset": 4, "endOffset": 12}, {"referenceID": 17, "context": "We would like to draw attention to the recent result of [18] who show an adaptive bound in terms of both the loss of comparator and the KL divergence between the comparator and some pre-fixed prior distribution over experts.", "startOffset": 56, "endOffset": 60}, {"referenceID": 18, "context": "An MDL-style bound in terms of the variance of the loss of the comparator (under the distribution induced by the algorithm) was recently given in [19].", "startOffset": 146, "endOffset": 150}, {"referenceID": 19, "context": "Our study was also partly inspired by Cover [20] who characterized necessary and sufficient conditions for achievable bounds in prediction of binary sequences.", "startOffset": 44, "endOffset": 48}, {"referenceID": 19, "context": "The methods in [20], however, rely on the structure of the binary prediction problem and do not readily generalize to other settings.", "startOffset": 15, "endOffset": 19}, {"referenceID": 6, "context": "It should be noted that while existing literature on adaptive online learning has focused on simple hypothesis classes such as finite experts and finite-dimensional p-norm balls, our results extend to general hypothesis classes, including large nonparametric ones discussed in [7].", "startOffset": 277, "endOffset": 280}, {"referenceID": 20, "context": ", n rounds (see [21]).", "startOffset": 16, "endOffset": 20}, {"referenceID": 7, "context": ", Bn(f ;x1\u2236n, y1\u2236n) = Bn, achievability reduces to the minimax analysis explored in [8].", "startOffset": 84, "endOffset": 87}, {"referenceID": 7, "context": "We first show that the minimax value is bounded by an offset version of the sequential Rademacher complexity studied in [8].", "startOffset": 120, "endOffset": 123}, {"referenceID": 21, "context": "A simple yet powerful example for the control of the supremum of a stochastic process is an inequality due to Pinelis [22] for the norm (which can be written as a supremum over the dual ball) of a martingale in a 2-smooth Banach space.", "startOffset": 118, "endOffset": 122}, {"referenceID": 23, "context": "Instead, we make use of the following result from [24] that extends Lemma 3 at a price of a poly-logarithmic factor.", "startOffset": 50, "endOffset": 54}, {"referenceID": 23, "context": "Before stating the lemma, we briefly define the relevant complexity measures (see [24] for more details).", "startOffset": 82, "endOffset": 86}, {"referenceID": 23, "context": "Lemma 4 ([24]).", "startOffset": 9, "endOffset": 13}, {"referenceID": 6, "context": "The behavior of this offset process was shown to govern the optimal rates of convergence for online nonparametric regression [7].", "startOffset": 125, "endOffset": 128}, {"referenceID": 21, "context": "To prove it, we use the concentration bound from [22] (Lemma 3) within the proof of the above corollary to remove the extra logarithmic factors.", "startOffset": 49, "endOffset": 53}, {"referenceID": 14, "context": "For the case of a Hilbert space, the above bound was achieved by [15].", "startOffset": 65, "endOffset": 69}, {"referenceID": 17, "context": "This example subsumes and improves upon the recent results from [18, 14] and provides an exact analogue to the PAC Bayesian theorem from statistical learning.", "startOffset": 64, "endOffset": 72}, {"referenceID": 13, "context": "This example subsumes and improves upon the recent results from [18, 14] and provides an exact analogue to the PAC Bayesian theorem from statistical learning.", "startOffset": 64, "endOffset": 72}, {"referenceID": 24, "context": "This extends the study of [25] to supervised learning and a general class of experts F .", "startOffset": 26, "endOffset": 30}, {"referenceID": 17, "context": "This is an improvement over the bound in [18] in that the bound is independent of number of experts, and thus holds even for countably infinite sets of experts.", "startOffset": 41, "endOffset": 45}, {"referenceID": 18, "context": "The KL term in our bound may be compared to the MDL-style term in the bound of [19].", "startOffset": 79, "endOffset": 83}, {"referenceID": 13, "context": "If we have a large (but finite) number of experts and take the uniform distribution \u03c0, the above bound provides an improvement over both [14] and [18] for quantile bounds for experts.", "startOffset": 137, "endOffset": 141}, {"referenceID": 17, "context": "If we have a large (but finite) number of experts and take the uniform distribution \u03c0, the above bound provides an improvement over both [14] and [18] for quantile bounds for experts.", "startOffset": 146, "endOffset": 150}, {"referenceID": 12, "context": "Evaluating the above bound with a distribution f that places all its weight on any one expert appears to address the open question posed by [13] of obtaining algorithm-independent oracle-type variance bounds for experts.", "startOffset": 140, "endOffset": 144}, {"referenceID": 0, "context": "[1] Lucien Birg\u00e9, Pascal Massart, et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] G\u00e1bor Lugosi and Andrew B Nobel.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Peter L.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Pascal Massart.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Shahar Mendelson.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Tengyuan Liang, Alexander Rakhlin, and Karthik Sridharan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Alexander Rakhlin and Karthik Sridharan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Elad Hazan and Satyen Kale.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Chao-Kai Chiang, Tianbao Yang, Chia-Jung Lee, Mehrdad Mahdavi, Chi-Jen Lu, Rong Jin, and Shenghuo Zhu.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Alexander Rakhlin and Karthik Sridharan.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] John Duchi, Elad Hazan, and Yoram Singer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Nicolo Cesa-Bianchi, Yishay Mansour, and Gilles Stoltz.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Kamalika Chaudhuri, Yoav Freund, and Daniel J Hsu.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] Nicolo Cesa-Bianchi and G\u00e1bor Lugosi.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] Nathan Srebro, Karthik Sridharan, and Ambuj Tewari.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] Haipeng Luo and Robert E.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] Wouter M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] Thomas M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] Alexander Rakhlin and Karthik Sridharan.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] Iosif Pinelis.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Alexander Rakhlin, Karthik Sridharan, and Ambuj Tewari.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] Eyal Even-Dar, Michael Kearns, Yishay Mansour, and Jennifer Wortman.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "To this end on similar lines as in [24, 7, 21], we start with the inner most term as,", "startOffset": 35, "endOffset": 46}, {"referenceID": 6, "context": "To this end on similar lines as in [24, 7, 21], we start with the inner most term as,", "startOffset": 35, "endOffset": 46}, {"referenceID": 20, "context": "To this end on similar lines as in [24, 7, 21], we start with the inner most term as,", "startOffset": 35, "endOffset": 46}, {"referenceID": 23, "context": "Compactness of the sets and lower semi-continuity of the losses and Bn are sufficient, but see [24, 21] for milder conditions.", "startOffset": 95, "endOffset": 103}, {"referenceID": 20, "context": "Compactness of the sets and lower semi-continuity of the losses and Bn are sufficient, but see [24, 21] for milder conditions.", "startOffset": 95, "endOffset": 103}, {"referenceID": 20, "context": "See [21] for more details of the steps involved in obtaining the above equality.", "startOffset": 4, "endOffset": 8}, {"referenceID": 6, "context": "To prove the bound in Equation 3, note that, Bn(f ;x1\u2236n, y1\u2236n) = Bn(y1\u2236n) and so, (this proof is similar in spirit to the one in [7])", "startOffset": 129, "endOffset": 132}, {"referenceID": 23, "context": "because 1 n \u2211 n t=1 w k t ( ) \u2264 3\u03b2 k for any by triangle inequality (see [24]).", "startOffset": 73, "endOffset": 77}], "year": 2015, "abstractText": "We propose a general framework for studying adaptive regret bounds in the online learning framework, including model selection bounds and data-dependent bounds. Given a dataor model-dependent bound we ask, \u201cDoes there exist some algorithm achieving this bound?\u201d We show that modifications to recently introduced sequential complexity measures can be used to answer this question by providing sufficient conditions under which adaptive rates can be achieved. In particular each adaptive rate induces a set of so-called offset complexity measures, and obtaining small upper bounds on these quantities is sufficient to demonstrate achievability. A cornerstone of our analysis technique is the use of one-sided tail inequalities to bound suprema of offset random processes. Our framework recovers and improves a wide variety of adaptive bounds including quantile bounds, second-order data-dependent bounds, and small loss bounds. In addition we derive a new type of adaptive bound for online linear optimization based on the spectral norm, as well as a new online PAC-Bayes theorem that holds for countably infinite sets.", "creator": "LaTeX with hyperref package"}}}