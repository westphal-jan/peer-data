{"id": "1508.06034", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2015", "title": "Better Summarization Evaluation with Word Embeddings for ROUGE", "abstract": "ROUGE is a widely adopted, automatic evaluation measure for text summarization. While it has been shown to correlate well with human judgements, it is biased towards surface lexical similarities. This makes it unsuitable for the evaluation of abstractive summarization, or summaries with substantial paraphrasing. We study the effectiveness of word embeddings to overcome this disadvantage of ROUGE. Specifically, instead of measuring lexical overlaps, word embeddings are used to compute the semantic similarity of the words used in summaries instead. Our experimental results show that our proposal is able to achieve better correlations with human judgements when measured with the Spearman and Kendall rank coefficients.", "histories": [["v1", "Tue, 25 Aug 2015 05:04:53 GMT  (21kb)", "http://arxiv.org/abs/1508.06034v1", "Pre-print - To appear in proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)"]], "COMMENTS": "Pre-print - To appear in proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["jun-ping ng", "viktoria abrecht"], "accepted": true, "id": "1508.06034"}, "pdf": {"name": "1508.06034.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["jng324@bloomberg.net", "vkanchakousk@bloomberg.net"], "sections": [{"heading": null, "text": "ar Xiv: 150 8.06 034v 1 [cs.C L] 25 Aug 201 5"}, {"heading": "1 Introduction", "text": "In fact, most of them are able to judge the quality of their work."}, {"heading": "2 Related Work", "text": "While ROUGE is widely used, as we noted earlier, there is a significant body of work that examines the evaluation of automatic text aggregation systems. A good overview of many of these measures was written by Steinberger and Jez ek (2012). Therefore, we will not try to go through every measure, but rather highlight the more significant efforts in this area. In addition to ROUGE, basic elements (BE) (Hovy et al., 2005) were also used in the joint task assessments of DUC / TAC. It is an automatic method that evaluates the completeness of the content of a generated summary by dividing sentences into smaller, granular information units (referred to as \"base elements\"). The pyramid method originally proposed by Passonneau et al. (2005) is another staple in DUC / TAC. However, it is a semi-automated method where significant human intervention is required to identify information units, called Units."}, {"heading": "3 Methodology", "text": "We want the world that we live in to remain the way it is in the future. (We want the world that we live in to be no more than that it is.) We want the world that we live in to be no more than that it is. (We want the world that we live in to be no more than that it is. (We want it to be as if it is.) We want the world that we are no more than that it is. (We want it to be as if it is.) We want it to be the world that it is, that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that it is that"}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Dataset and Metrics", "text": "For our experiments, we use the data set used in AESOP (Owczarzak and Dang, 2011) and the corresponding correlation yardsticks. To provide clarity, we first describe the data set used in the main task of summarizing the TAC. The main data set for the summary consists of 44 topics, each of which is associated with a set of 10 documents. There are also four human-curated model summaries for each of these topics. Each of the 51 participating systems generated a summary for each of these topics. These automatically-generated summaries, together with the human-curated summaries from 4https: / / drive.google.com / file / d / 0B7XkCwpI5KDYNlNUTTlSS21pQmM / edit? etc = sharingmodel summaries, then form the basis of the data collection for AESOP. To assess how effective an automated evaluation system is, each of these judges are asked to create a human summary for each of 51."}, {"heading": "4.2 Results", "text": "We evaluate three different variants of our proposal, ROUGE-WE-1, ROUGE-WE-2, and ROUGE-WE-SU4, against their corresponding variants of ROUGE (i.e., ROUGE-1, ROUGE-WE-2, ROUGE-SU4). However, it is worth noting that in AESOP in 2011, ROUGE-SU4, the correlation between the results of each variant of ROUGE-WE was shown to correlate very well with human judgments, especially for pyramid and responsiveness, and most of the participating systems.Tables 1, 2, and 3 show the correlation of the results of each variant of ROUGE-WE with human judgments, responsiveness, and readability. The tables also show the correlations achieved by ROUGE-1, ROUGE-2, and ROUGE-SU4. The best result for each column was considered for readability."}, {"heading": "5 Conclusion", "text": "We have proposed an improvement in the popular ROUGE metric in this paper, ROUGE-WE. This improvement allows us to go beyond lexicographic matches and instead capture the semantic similarities between words used in a generated summary and a human-made model summary. If we experiment with the TAC-AESOP datasets, we show that this proposal has very good correlations with human evaluations as measured by the Spearman and Kendall Rank coefficients. In particular, ROUGE-WE-1 outperforms the leading state-of-the-art systems. In the perspective, we want to build on this work. One area that needs to be improved is the use of more comprehensive evaluation datasets. The AESOP summaries that we have used in our experiments are drawn from systems involved in the AC-Li task, a strong summary."}], "references": [{"title": "Overview of the TAC 2009 Summarization Track", "author": ["Dang", "Owczarzak2009] Hoa Trang Dang", "Karolina Owczarzak"], "venue": "In Proceedings of the Text Analysis Conference (TAC)", "citeRegEx": "Dang et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Dang et al\\.", "year": 2009}, {"title": "CatolicaSC at TAC", "author": [], "venue": "In Proceedings of the Text Analysis Conference (TAC)", "citeRegEx": "Oliveira.,? \\Q2011\\E", "shortCiteRegEx": "Oliveira.", "year": 2011}, {"title": "AutoSummENG and MeMoG in Evaluating Guided Summaries", "author": ["Giannakopoulos", "Vangelis Karkaletsis"], "venue": "In Proceedings of the Text Analysis Conference (TAC)", "citeRegEx": "Giannakopoulos et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Giannakopoulos et al\\.", "year": 2009}, {"title": "Evaluating DUC 2005 using Basic Elements", "author": ["Hovy et al.2005] Eduard Hovy", "Chin-Yew Lin", "Liang Zhou"], "venue": "In Proceedings of the Document Understanding Conference (DUC)", "citeRegEx": "Hovy et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Hovy et al\\.", "year": 2005}, {"title": "Using Unsupervised System with Least Linguistic Features for TACAESOP Task", "author": ["Kumar et al.2011] Niraj Kumar", "Kannan Srinathan", "Vasudeva Varma"], "venue": "In Proceedings of the Text Analysis Conference (TAC)", "citeRegEx": "Kumar et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2011}, {"title": "Document Summarization via Guided Sentence Compression", "author": ["Chen Li", "Fei Liu", "Fuliang Weng", "Yang Liu"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Looking for a Few Good Metrics: ROUGE and its Evaluation", "author": ["Chin-Yew Lin"], "venue": "In Working Notes of the 4th NTCIR Workshop Meeting", "citeRegEx": "Lin.,? \\Q2004\\E", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "ROUGE: A Package for Automatic Evaluation of Summaries", "author": ["Chin-Yew Lin"], "venue": "In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop", "citeRegEx": "Lin.,? \\Q2004\\E", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Toward Abstractive Summarization Using Semantic Representations", "author": ["Liu et al.2015] Fei Liu", "Jeffrey Flanigan", "Sam Thomson", "Norman Sadeh", "Noah A. Smith"], "venue": "In Proceedings of the Conference of the North American Chapter of the Association", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Linguistic Regularities in Continuous Space Word Representations", "author": ["Wen-tau Yih", "Geoffrey Zweig"], "venue": "In Proceedings of the Conference of the North American Chapter of the Association for Computational Lin-", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Vector-based Models of Semantic Composition", "author": ["Mitchell", "Lapata2008] Jeff Mitchell", "Mirella Lapata"], "venue": "In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL),", "citeRegEx": "Mitchell et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2008}, {"title": "Exploiting Timelines to Enhance Multi-document Summarization", "author": ["Ng et al.2014] Jun-Ping Ng", "Yan Chen", "Min-Yen Kan", "Zhoujun Li"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association", "citeRegEx": "Ng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ng et al\\.", "year": 2014}, {"title": "An Introduction to DUC", "author": ["Over", "Yen2004] Paul Over", "James Yen"], "venue": "In Proceedings of the Document Understanding Conference (DUC)", "citeRegEx": "Over et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Over et al\\.", "year": 2004}, {"title": "Overview of the TAC 2011 Summarization Track: Guided Task and AESOP Task", "author": ["Owczarzak", "Dang2011] Karolina Owczarzak", "Hoa Trang Dang"], "venue": "In Proceedings of the Text Analysis Conference (TAC)", "citeRegEx": "Owczarzak et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Owczarzak et al\\.", "year": 2011}, {"title": "Overview of the TAC 2010 Summarization Track", "author": ["Karolina Owczarzak"], "venue": "In Proceedings of the Text Analysis Conference (TAC)", "citeRegEx": "Owczarzak.,? \\Q2010\\E", "shortCiteRegEx": "Owczarzak.", "year": 2010}, {"title": "Applying the Pyramid Method", "author": ["Ani Nenkova", "Kathleen McKeown", "Sergey Sigelman"], "venue": "DUC", "citeRegEx": "Passonneau et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Passonneau et al\\.", "year": 2005}, {"title": "Automated Pyramid Scoring of Summaries using Distributional Semantics", "author": ["Emily Chen", "Weiwei Guo", "Dolores Perin"], "venue": "In Proceedings of the 51st Annual Meeting of the Association", "citeRegEx": "Passonneau et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Passonneau et al\\.", "year": 2013}, {"title": "Evaluation Measures for Text Summarization", "author": ["Steinberger", "Je\u017eek2012] Josef Steinberger", "Karel Je\u017eek"], "venue": "Computing and Informatics,", "citeRegEx": "Steinberger et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Steinberger et al\\.", "year": 2012}, {"title": "An Exploration of Embeddings for Generalized Phrases", "author": ["Yin", "Sch\u00fctze2014] Wenpeng Yin", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of the ACL 2014 Student Research Workshop,", "citeRegEx": "Yin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2014}, {"title": "Factor-based Compositional Embedding Models", "author": ["Yu et al.2014] Mo Yu", "Matthew Gormley", "Mark Dredze"], "venue": "In Proceedings of the NIPS 2014 Deep Learning and Representation Learning Workshop", "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 14, "context": "There has been on-going efforts to improve on automatic summarization evaluation measures, such as the Automatically Evaluating Summaries of Peers (AESOP) task in TAC (Dang and Owczarzak, 2009; Owczarzak, 2010; Owczarzak and Dang, 2011).", "startOffset": 167, "endOffset": 236}, {"referenceID": 3, "context": "Besides ROUGE, Basic Elements (BE) (Hovy et al., 2005) has also been used in the DUC/TAC shared task evaluations.", "startOffset": 35, "endOffset": 54}, {"referenceID": 15, "context": "The pyramid method originally proposed by Passonneau et al. (2005) is another staple in", "startOffset": 42, "endOffset": 67}, {"referenceID": 16, "context": "posed (Passonneau et al., 2013).", "startOffset": 6, "endOffset": 31}, {"referenceID": 14, "context": "ported in Owczarzak and Dang (2011), AutoSummENG (Giannakopoulos and Karkaletsis, 2009), is a graph-based system which scores summaries based on the similarity between the graph structures of the generated summaries and model summaries.", "startOffset": 10, "endOffset": 36}, {"referenceID": 9, "context": "Mikolov et al. (2013) describe one such variant, called word2vec, which gives us this desired property2.", "startOffset": 0, "endOffset": 22}, {"referenceID": 15, "context": "As reviewed in Section 2, this is a semi-automated measure described in Passonneau et al. (2005).", "startOffset": 72, "endOffset": 97}, {"referenceID": 4, "context": "C S IIITH3 (Kumar et al., 2011) is a graphbased system which assess summaries based on differences in word co-locations between generated summaries and model summaries.", "startOffset": 11, "endOffset": 31}, {"referenceID": 3, "context": "BE-HM (baseline by the organizers of the AESOP task) is the BE system (Hovy et al., 2005), where basic elements are identified using a head-modifier criterion on parse results from Minipar.", "startOffset": 70, "endOffset": 89}, {"referenceID": 5, "context": "It will be helpful to enlarge this set of summaries to include output from summarizers which carry out substantial paraphrasing (Li et al., 2013; Ng et al., 2014; Liu et al., 2015).", "startOffset": 128, "endOffset": 180}, {"referenceID": 11, "context": "It will be helpful to enlarge this set of summaries to include output from summarizers which carry out substantial paraphrasing (Li et al., 2013; Ng et al., 2014; Liu et al., 2015).", "startOffset": 128, "endOffset": 180}, {"referenceID": 8, "context": "It will be helpful to enlarge this set of summaries to include output from summarizers which carry out substantial paraphrasing (Li et al., 2013; Ng et al., 2014; Liu et al., 2015).", "startOffset": 128, "endOffset": 180}, {"referenceID": 19, "context": "generalization of unigram word embeddings into bigrams (or phrases), is still an open problem (Yin and Sch\u00fctze, 2014; Yu et al., 2014).", "startOffset": 94, "endOffset": 134}], "year": 2015, "abstractText": "ROUGE is a widely adopted, automatic evaluation measure for text summarization. While it has been shown to correlate well with human judgements, it is biased towards surface lexical similarities. This makes it unsuitable for the evaluation of abstractive summarization, or summaries with substantial paraphrasing. We study the effectiveness of word embeddings to overcome this disadvantage of ROUGE. Specifically, instead of measuring lexical overlaps, word embeddings are used to compute the semantic similarity of the words used in summaries instead. Our experimental results show that our proposal is able to achieve better correlations with human judgements when measured with the Spearman and Kendall rank coefficients.", "creator": "LaTeX with hyperref package"}}}