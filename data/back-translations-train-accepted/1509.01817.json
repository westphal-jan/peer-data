{"id": "1509.01817", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Sep-2015", "title": "On collapsed representation of hierarchical Completely Random Measures", "abstract": "The main aim of this paper is to establish the applicability of a broad class of random measures, that includes the gamma process, for mixed membership modelling. We use completely random measures~(CRM) and hierarchical CRM to define a prior for Poisson processes. We derive the marginal distribution of the resultant point process, when the underlying CRM is marginalized out. Using well known properties unique to Poisson processes, we were able to derive an exact approach for instantiating a Poisson process with a hierarchical CRM prior. Furthermore, we derive Gibbs sampling strategies for hierarchical CRM models based on Chinese restaurant franchise sampling scheme. As an example, we present the sum of generalized gamma process (SGGP), and show its application in topic-modelling. We show that one can determine the power-law behaviour of the topics and words in a Bayesian fashion, by defining a prior on the parameters of SGGP.", "histories": [["v1", "Sun, 6 Sep 2015 14:44:38 GMT  (58kb,D)", "https://arxiv.org/abs/1509.01817v1", "14 pages, 1 figure"], ["v2", "Thu, 2 Jun 2016 06:46:28 GMT  (69kb,D)", "http://arxiv.org/abs/1509.01817v2", "11 pages, 1 figure"]], "COMMENTS": "14 pages, 1 figure", "reviews": [], "SUBJECTS": "math.ST cs.LG stat.TH", "authors": ["gaurav pandey", "ambedkar dukkipati"], "accepted": true, "id": "1509.01817"}, "pdf": {"name": "1509.01817.pdf", "metadata": {"source": "META", "title": "On collapsed representation of hierarchical Completely Random Measures", "authors": ["Gaurav Pandey", "Ambedkar Dukkipati"], "emails": ["GP88@CSA.IISC.ERNET.IN", "AD@CSA.IISC.ERNET.IN"], "sections": [{"heading": "1. Introduction", "text": "Depending on the problem, a single latent attribute can be allowed that can be shown as an object without there being a topic, with each topic appearing in the document with variable multiplicity; the corresponding problem of assigning the words of a document to topics is called topic modeling; while parametric solutions to mixed membership models of the 33rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W & CP volume 48, which is modeling as a topic, have been available in the literature for more than a decade (Landauer & Dumais, 1997; Hofmann, 1999; Blei et al., 2001), the first non-parametric approximation that allowed the number of latent classes to arise."}, {"heading": "2. Preliminaries and background", "text": "In this section, we correct the notation and recall some well-known results from the theory of point processes."}, {"heading": "2.1. Poisson process", "text": "Let (S, S) be a measurable space and let (S) be a randomly countable collection of points on S. Letters N (A) = > Letters A |, for each measurable quantity A. N is also known as the counting process of the number. If N (A) is independent of N (B), then we refer both to the random collection and to its counting processesN as a Poisson process. Let (T, T) be another measurable space and f: S \u2192 T be a measurable function. If the forward measurement of the number is above f \u2212 1, that is, f \u2212 1 is not atomic, then f (E) = {f (x): x (T) is another measurable space and f: S \u2192 T is a measurable function."}, {"heading": "2.2. Completely random measures", "text": "Let's (B) set the space of all finite metrics to (S, S), which is provided with a suitable \u03c3 algebra. A completely random metric (CRM) is a measurable mapping of (S, S), i = 1, 2,.. are independent, and (B, S, S, S) is independent, and (B, S, S, S) is independent, and (B, S, S, S, S, S) is independent, and (B, S, S, S, S, S, S) is independent. (B, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S, S"}, {"heading": "3. The proposed model", "text": "We assume that each sample Xi is generated as follows: \u2022 The basic measurement \u03a6 is CRM (\u03c1, \u00b5), where \u03c1 and \u00b5 are random and finite (non-atomic) measurements to (S, S) respectively. \u2022 The latent measurement Ni for each object Xi is a Poisson process with medium measurement. \u2022 The visible measurements Xi are made from Ni.Note: For the Xi theme modeling, S corresponds to the space of all probability measurements on the words in the dictionary, also known as Topics. If we take samples, we stitch a subset of topics, along with the weights for these topics."}, {"heading": "3.1. Marginalizing out the object specific measure", "text": "It is easy to see that if it is a finite measurement, only 1 object is sampled from its object-specific random measurement, we will present the results in case n objects, N1,.., Nn are sampled from the object-specific random measurement. This extended result is needed in the next section when measuring the marginalization of the base. There are several ways to instantiate the random measurement. For example, one can take advantage of the fact that the underlying measurement is purely atomic, the support of CRM is limited to measures whose support is a subordinate measurement."}, {"heading": "3.2. Marginalizing out the base measure", "text": "The previous section derives the marginal distribution of the Poisson processes for a defined realization of the base process. In this section we also want to marginalize the marginalization of CRM processes. \u2212 \u2212 \u2212 The marginalization of the process eliminates the independence between the latent characteristics of Nis, so we need the common distribution of N1,., Nn.The model taking into account the CRM criteria (1), whose overall picture we derive from the above description. \u2212 The Ni processes can be achieved equally by sampling a Poisson process. (1) The Poisson process (1), whose overall picture we use. \u2212 Proposition 3.4 to Marginalize from the above description. \u2212 The Ni processes can be achieved equally by sampling a Poisson process with the mean metric (dx)."}, {"heading": "4. Implementation via Gibbs sampling", "text": "In this section, however, it is not clear how the above derivatives can be used for determining the latent characteristics from their previous distribution, the P (N1,., Nn) for the objects X1,., Xn, which is the goal of this work. In this section, it is simply necessary to multiply the equations in this section by the probability of the latent characteristics in order to be able to perform MCMC sampling in hierarchical CRM models."}, {"heading": "5. Experimental results", "text": "We use hierarchical CRM Poisson models to learn topics from the NIPS corpus 1.1, which can be downloaded from http: / / psiexp.ss.uci.edu / research / programs _ data / toolbox.htm."}, {"heading": "5.1. Evaluation", "text": "To evaluate the different models, we divide each document into a training section and a test section, independently selecting a Boolean random variable for each word at random. The probability of sending the word to the training section varies from 0.3 to 0.7. We perform 2000 iterations of the Gibbs sampling, the first 500 iterations are discarded, and each sample in all 5 iterations thereafter is used to update the document-specific distribution on topics and the topic-specific distribution on words. Specifically, let us specify the number of words, K the number of topics, (\u03b2dk) 1 \u2264 k the document-specific distribution on topics for document d and (\u03c4kw) 1 \u2264 w \u2264 W the topic-specific distribution on words for the most topical topic. Then, the probability of observing a word w in document d is given by \u0445K = 1 \u03b2dkKKKKKKKKKs. For the test, the evaluation metric, the mean geometry of all words is simple."}, {"heading": "5.2. Varying the Common CRM", "text": "In our experiments, we fix the object-specific random measurement, which in (8) is called q q = q = q = q = q Results (31). For the object-specific random measurements, we consider two specific decisions of random measurements. \u2022 Generalized gamma process (GGP): The Poisson intensity of the measurements of precision is given by equally high (dz, dx) = equally high (dx) values, with the object-specific gamma values (1 \u2212 d) and \u2212 zz \u2212 d \u2212 1 dz, 0 \u2264 d < 1, \u03b8 > 0 and \u00b5 (S) = 1. The corresponding Laplace exponent is given by the object-specific capabilities ((1 + t) d \u2212 d \u2212 d \u2212 d values of the generalized gamma processes (SGGP) and \u2212 zz \u2212 d values: The Poisson intensity of precision is given by the precision equal to high (dz) values."}, {"heading": "6. Conclusion", "text": "For years, hierarchical dirichlet processes have been the standard tool for non-parametric topic modeling, as collapsed inferences in the HDP can be performed with the Chinese restaurant franchise scheme. In this paper, we wanted to show that collapsed Gibbs samples can be extended to a much larger number of hierarchical randomized measures by using the same Chinese restaurant franchise scheme, opening doors for further research into the effectiveness of different hierarchical priorities. We hope this will foster a better understanding of the applicability of different hierarchical CRM priorities. In addition, the results of the paper can be used to prove results for hierarchical CRMs in other contexts, such as non-parametric hidden Markov models."}, {"heading": "Acknowledgement", "text": "Gaurav Pandey is supported by the IBM PhD Fellowship for the academic year 2015-2016."}, {"heading": "Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of proposition 3.1", "text": "Proof. Let's say N = number of processes n = 1Ni. Since, due to land use, N1,.., Nn is an independent Poisson process with an average measurement, N is a Poisson process due to land use with an average measurement n. Since E [et1N (A) + t2N (B) | land use plan] = E [et1N (A) | land use plan (A) | land use plan (B)], and land use plan (A) and land use plan (B) are independent, N (A) and N (B) are also independent and therefore N is a CRM. Consequently N (dx) = land use R + sN (dx), for a Poisson process N (dx), for a Poisson process N (A)."}, {"heading": "Proof of proposition 3.2", "text": "+ + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + = + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +"}, {"heading": "Proof of Corollary 3.3", "text": "Proof. Sentence 3.1 shows that the different points in the point processes Ni, 1 \u2264 i \u2264 n, form a Poisson process with the mean measurement quantity \u00b5 (dx) \u00b5 (S) \u0445 (n). Thus, the total number of individual points k is distributed as Poisson (\u043d (n)."}, {"heading": "Proof of Proposition 3.4", "text": "Proof. Let N = \u2211 n = 1Ni. From the arguments of sentence 3.1 it is clear that N is a CRM and can therefore be written as N (dx) + zN (dz, dx) for some Poisson processes. Let us define the random collection of points that match N (dx). Now, define a map f: R + \u00b7 S \u2192 S as a projection map on S, i.e. f (x, y) = y and M = f (x, y) = {f (x, y): (x, y), with the double brackets indicating that M is a multiset. The rest of the arguments remain the same as in sentence 3.1 and statement 3.2."}, {"heading": "Proof of Lemma 4.1", "text": "On the basis of proposal 3.4 on the marginalization of \"i\" from \"i\" from \"i\" from \"i\" from \"i\" from \"i\" from \"i\" from \"i\" from \"8 we get that [mij] 1\" i \"=\" i \"(S) =\" exp \"(S) =\" i \"(S) =\" i \"(S) + (1\" e \")\" i \"(dz)))) (\" i \"j\" = 1mij)! \u00b7 ri \"j\" j \"= 1\" z \"(S) +\" z \"(35) Lass\" i \"= i\" i \"(S) = 1mij.\" If we take the expectation with respect to \"i\" (S), we get the marginal distribution of \"i\" j \"1\" j \"ri\" \u00b7 i, \"where\" i \"z\" (S) is also random. P \"[mij] 1\" i \"(S) = 1\" z \"(S) = 1.\""}], "references": [{"title": "Latent Dirichlet Allocation", "author": ["Blei", "David M", "Ng", "Andrew Y", "Jordan", "Michael I"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Blei et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2001}, {"title": "Combinatorial Clustering and the Beta Negative Binomial Process", "author": ["Broderick", "Tamara", "Mackey", "Lester", "Paisley", "John", "Jordan", "Michael I"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Broderick et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Broderick et al\\.", "year": 2015}, {"title": "The combinatorial structure of beta negative binomial processes", "author": ["Heaukulani", "Creighton", "Roy", "Daniel M"], "venue": "arXiv preprint arXiv:1401.0062,", "citeRegEx": "Heaukulani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Heaukulani et al\\.", "year": 2013}, {"title": "Probabilistic latent semantic analysis", "author": ["Hofmann", "Thomas"], "venue": "In Proceedings of the Fifteenth conference on Uncertainty in Artificial Intelligence,", "citeRegEx": "Hofmann and Thomas.,? \\Q1999\\E", "shortCiteRegEx": "Hofmann and Thomas.", "year": 1999}, {"title": "Bayesian Poisson process Partition Calculus with an application to Bayesian L\u00e9vy Moving Averages", "author": ["James", "Lancelot F"], "venue": "Annals of Statistics,", "citeRegEx": "James and F.,? \\Q2005\\E", "shortCiteRegEx": "James and F.", "year": 2005}, {"title": "Completely Random Measures", "author": ["Kingman", "John"], "venue": "Pacific Journal of Mathematics,", "citeRegEx": "Kingman and John.,? \\Q1967\\E", "shortCiteRegEx": "Kingman and John.", "year": 1967}, {"title": "A solution to Plato\u2019s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge", "author": ["Landauer", "Thomas K", "Dumais", "Susan T"], "venue": "Psychological review,", "citeRegEx": "Landauer et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Landauer et al\\.", "year": 1997}, {"title": "Markov Chain Sampling Methods for Dirichlet Process Mixture Models", "author": ["Neal", "Radford M"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "Neal and M.,? \\Q2000\\E", "shortCiteRegEx": "Neal and M.", "year": 2000}, {"title": "The continuum-of-urns scheme, generalized beta and indian buffet processes, and hierarchies thereof", "author": ["Roy", "Daniel M"], "venue": "arXiv preprint arXiv:1501.00208,", "citeRegEx": "Roy and M.,? \\Q2014\\E", "shortCiteRegEx": "Roy and M.", "year": 2014}, {"title": "Hierarchical Dirichlet Processes", "author": ["Teh", "Yee Whye", "Jordan", "Michael I", "Beal", "Matthew J", "Blei", "David M"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Teh et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Teh et al\\.", "year": 2006}, {"title": "The Infinite Gamma-Poisson Feature Model", "author": ["Titsias", "Michalis K"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Titsias and K.,? \\Q2008\\E", "shortCiteRegEx": "Titsias and K.", "year": 2008}, {"title": "Beta-negative binomial process and exchangeable random partitions for mixed-membership modeling", "author": ["Zhou", "Mingyuan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Zhou and Mingyuan.,? \\Q2014\\E", "shortCiteRegEx": "Zhou and Mingyuan.", "year": 2014}, {"title": "Negative Binomial Process Count and Mixture Modelling", "author": ["Zhou", "Mingyuan", "Carin", "Lawrence"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}, {"title": "Beta-Negative Binomial Process and Poisson Factor Analysis", "author": ["Zhou", "Mingyuan", "Hannah", "Lauren A", "Dunson", "David B", "Carin", "Lawrence"], "venue": "In AISTATS,", "citeRegEx": "Zhou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2012}, {"title": "Priors for random count matrices derived from a family of negative binomial processes", "author": ["Zhou", "Mingyuan", "Padilla", "Oscar Hernan Madrid", "Scott", "James G"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "elling have been available in literature since more than a decade (Landauer & Dumais, 1997; Hofmann, 1999; Blei et al., 2001), the first non-parametric approach, that allowed the number of latent classes to be determined as well, was the hierarchical Dirichlet process (HDP) (Teh et al.", "startOffset": 66, "endOffset": 125}, {"referenceID": 9, "context": ", 2001), the first non-parametric approach, that allowed the number of latent classes to be determined as well, was the hierarchical Dirichlet process (HDP) (Teh et al., 2006).", "startOffset": 157, "endOffset": 175}, {"referenceID": 13, "context": "On the other hand, recent approaches such as hierarchical beta-negative binomial process (Zhou et al., 2012; Broderick et al., 2015) and hierarchical gamma-Poisson process (Titsias, 2008; Zhou & Carin, 2015) model the object as a point process, sampled from an object specific random measure, which is itself sampled from a common random measure.", "startOffset": 89, "endOffset": 132}, {"referenceID": 1, "context": "On the other hand, recent approaches such as hierarchical beta-negative binomial process (Zhou et al., 2012; Broderick et al., 2015) and hierarchical gamma-Poisson process (Titsias, 2008; Zhou & Carin, 2015) model the object as a point process, sampled from an object specific random measure, which is itself sampled from a common random measure.", "startOffset": 89, "endOffset": 132}, {"referenceID": 9, "context": "Alternatively, for the HDP, a Chinese restaurant franchise scheme (Teh et al., 2006) can be used for collapsed inference in the model (that is, without explicitly instantiating the atoms).", "startOffset": 66, "endOffset": 84}, {"referenceID": 12, "context": "Fully collapsed inference scheme has also been proposed for beta-negative binomial process (BNBP) (Heaukulani & Roy, 2013; Zhou, 2014) and Gamma-Gamma-Poisson process (Zhou et al., 2015).", "startOffset": 167, "endOffset": 186}, {"referenceID": 0, "context": "elling have been available in literature since more than a decade (Landauer & Dumais, 1997; Hofmann, 1999; Blei et al., 2001), the first non-parametric approach, that allowed the number of latent classes to be determined as well, was the hierarchical Dirichlet process (HDP) (Teh et al., 2006). Both the approaches model the object as a set of repeated draws from an object-specific distribution, whereby the object specific distribution is itself sampled from a common distribution. On the other hand, recent approaches such as hierarchical beta-negative binomial process (Zhou et al., 2012; Broderick et al., 2015) and hierarchical gamma-Poisson process (Titsias, 2008; Zhou & Carin, 2015) model the object as a point process, sampled from an object specific random measure, which is itself sampled from a common random measure. In some sense, these approaches are more natural for mixed membership modelling, since they model the object as a single entity rather than as a sequence of draws from a distribution. A straightforward implementation of any of the above nonparametric models would require sampling the atoms in the non-parametric distribution for the base as well as objectspecific measure. However, since the number of atoms in these distributions are often infinite, a truncation step is required to ensure tractability. Alternatively, for the HDP, a Chinese restaurant franchise scheme (Teh et al., 2006) can be used for collapsed inference in the model (that is, without explicitly instantiating the atoms). Fully collapsed inference scheme has also been proposed for beta-negative binomial process (BNBP) (Heaukulani & Roy, 2013; Zhou, 2014) and Gamma-Gamma-Poisson process (Zhou et al., 2015). Of particular relevance is the work by Roy (2014), whereby a Chinese restaurant fanchise scheme has been proposed for hierarchies of beta proceses (and its generalizations), when coupled with Bernoulli process.", "startOffset": 107, "endOffset": 1764}, {"referenceID": 0, "context": "elling have been available in literature since more than a decade (Landauer & Dumais, 1997; Hofmann, 1999; Blei et al., 2001), the first non-parametric approach, that allowed the number of latent classes to be determined as well, was the hierarchical Dirichlet process (HDP) (Teh et al., 2006). Both the approaches model the object as a set of repeated draws from an object-specific distribution, whereby the object specific distribution is itself sampled from a common distribution. On the other hand, recent approaches such as hierarchical beta-negative binomial process (Zhou et al., 2012; Broderick et al., 2015) and hierarchical gamma-Poisson process (Titsias, 2008; Zhou & Carin, 2015) model the object as a point process, sampled from an object specific random measure, which is itself sampled from a common random measure. In some sense, these approaches are more natural for mixed membership modelling, since they model the object as a single entity rather than as a sequence of draws from a distribution. A straightforward implementation of any of the above nonparametric models would require sampling the atoms in the non-parametric distribution for the base as well as objectspecific measure. However, since the number of atoms in these distributions are often infinite, a truncation step is required to ensure tractability. Alternatively, for the HDP, a Chinese restaurant franchise scheme (Teh et al., 2006) can be used for collapsed inference in the model (that is, without explicitly instantiating the atoms). Fully collapsed inference scheme has also been proposed for beta-negative binomial process (BNBP) (Heaukulani & Roy, 2013; Zhou, 2014) and Gamma-Gamma-Poisson process (Zhou et al., 2015). Of particular relevance is the work by Roy (2014), whereby a Chinese restaurant fanchise scheme has been proposed for hierarchies of beta proceses (and its generalizations), when coupled with Bernoulli process. In this paper, it is our aim to extend fully collapsed sampling so as to allow any completely random measure (CRM) for the choice of base and object-specific measure. As proposed in Roy (2014) for hierarchies of generalized beta processes, we propose Chinese restaurant franchise schemes for hierarchies of CRMs, when coupled with Poisar X iv :1 50 9.", "startOffset": 107, "endOffset": 2118}, {"referenceID": 9, "context": "In an analny with the Chinese restaurant franchise model (Teh et al., 2006), one can think of Til", "startOffset": 57, "endOffset": 75}], "year": 2016, "abstractText": "The aim of the paper is to provide an exact approach for generating a Poisson process sampled from a hierarchical CRM, without having to instantiate the infinitely many atoms of the random measures. We use completely random measures (CRM) and hierarchical CRM to define a prior for Poisson processes. We derive the marginal distribution of the resultant point process, when the underlying CRM is marginalized out. Using well known properties unique to Poisson processes, we were able to derive an exact approach for instantiating a Poisson process with a hierarchical CRM prior. Furthermore, we derive Gibbs sampling strategies for hierarchical CRM models based on Chinese restaurant franchise sampling scheme. As an example, we present the sum of generalized gamma process (SGGP), and show its application in topicmodelling. We show that one can determine the power-law behaviour of the topics and words in a Bayesian fashion, by defining a prior on the parameters of SGGP.", "creator": "LaTeX with hyperref package"}}}