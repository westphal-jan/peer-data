{"id": "1509.06812", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Sep-2015", "title": "Learning Wake-Sleep Recurrent Attention Models", "abstract": "Despite their success, convolutional neural networks are computationally expensive because they must examine all image locations. Stochastic attention-based models have been shown to improve computational efficiency at test time, but they remain difficult to train because of intractable posterior inference and high variance in the stochastic gradient estimates. Borrowing techniques from the literature on training deep generative models, we present the Wake-Sleep Recurrent Attention Model, a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients. We show that our method can greatly speed up the training time for stochastic attention networks in the domains of image classification and caption generation.", "histories": [["v1", "Tue, 22 Sep 2015 23:52:30 GMT  (490kb,D)", "http://arxiv.org/abs/1509.06812v1", "To appear in NIPS 2015"]], "COMMENTS": "To appear in NIPS 2015", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["jimmy ba", "ruslan salakhutdinov", "roger b grosse", "brendan j frey"], "accepted": true, "id": "1509.06812"}, "pdf": {"name": "1509.06812.pdf", "metadata": {"source": "CRF", "title": "Learning Wake-Sleep Recurrent Attention Models", "authors": ["Jimmy Ba", "Roger Grosse"], "emails": ["jimmy@psi.toronto.edu", "rgrosse@cs.toronto.edu", "rsalskhu@cs.toronto.edu", "frey@psi.toronto.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "2 Related work", "text": "In recent years, the number of people who are able to work has multiplied; the number of people who are unable to work is on the increase; the number of people who are unable to work is on the increase; the number of people who are unable to work is on the increase; the number of people who are unable to work is on the increase; the number of people who are unable to work is on the increase; and the number of people who are unable to work is on the increase."}, {"heading": "3 Wake-Sleep Recurrent Attention Model", "text": "We now describe our Recursive Attention Model (WS-RAM). Faced with an image I, the network first selects a sequence of views a = (a1,.., aN) and after each fleeting glance receives an observation xn, which is calculated by mapping g (an, I. This mapping could, for example, extract an image patch at a certain scale. The first fleeting glance is based on a low-resolution version of the input, while subsequent glances are selected based on information obtained from previous glances. Views are stochastically selected according to a distribution (an | a1: n \u2212 1, I,), with the first fleeting glance pointing to the parameters of the network, as opposed to soft attention models that distribute deterministically attention across all image locations. After the last fleeting glance, the network predicts a distribution p (y | a, I, cellular) over the target resolution (for example, the header or image category)."}, {"heading": "4 Learning", "text": "In this thesis, we assume that we have a dataset with labels y for the monitored prediction task (e.g. object category). Unlike the monitored highlighting task (e.g. [20, 21]), there are no labels for which task to participate. Instead, we learn an attention policy based on the idea that the best places that make the model most robust in predicting the right category are the ones. In particular, we strive to maximize the probability of the class name (or accordingly minimize cross entropy) by marginalizing the actions at every glance: \"= log p (y | I, \u03b8) = log \u0445 a (a | I, Tennessee) p (y | a, I)."}, {"heading": "4.1 Variational lower bound", "text": "We first outline the approach of [2], which has trained the model to maximize a variable lower limit: \"Let q (a | y, I) be an approximate distribution, and the lower limit to\" is then given by: \"= log \u2211 a p (a | I, \u03b8) p (y | a, I, \u03b8) \u2265 \u2211 a q (a | y, I) log p (y, a | I, \u03b8) + H [q] = F. (2) In the case where q (a | y, I) = p (a | I, \u03b8) is the previous one, the number of p (a | I, \u03b8) log p (y | a, I, \u03b8) decreases. (3) The learning rules can be derived by deriving Eqn. 3 in relation to the model parameters."}, {"heading": "4.2 An improved lower bound on the log-likelihood", "text": "The variation method described above has some counterproductive properties early in training. First, because it maps the log probability of actions, it greatly increases the differences in the probabilities associated with the true category, even if they can be equally bad in practice, since they both missed the relevant information. Second, curious behavior is that all logbook sequences are equally weighted in the logbook probability. It would be better if the training method focused its efforts on the use of those glances that contain relevant information. Both of these effects contribute to noise in the early stages of training, especially in the early stages of training. Instead, we adopt an approach based on the Wake-p stage of reweighted wake-sleep [9], where we attempt to maximize the marginal log probability directly."}, {"heading": "4.3 Training an inference network", "text": "Late in training, once the attention model has learned an effective policy, the previous distribution p (a | I, \u03b8) q is a reasonable choice for the proposal distribution q (a | y, I), as it relies significant probability mass on good actions. However, early in training, the model may have only a low probability of selecting a good group of insights, and the previous one may have little overlap with the subsequent one. To deal with this, we train an inference network to predict, in light of the observations and class designation, where the network should look like it correctly predicts that the class (see Figure 1).With this additional information, the inference network can act as a \"teacher\" for attention policy.The inference network predicts a sequence of insights: q (a | y, I, \u03b7) = N \u00b2 n = qy (an, I, a1: n \u2212 1).This distribution is analogous to the previous one, except that each decision also recognizes the label."}, {"heading": "4.4 Control variates", "text": "The speed of the convergence of the gradient ascent with the gradients defined in Eqns = 0 = 15 expectations is very similar. The results of the convergence of the gradient ascent with the gradient q = 14 defined in Eqns suffer from a high variance of the stochastic gradient estimation. The selection of effective control variants for the stochastic gradient estimators results in the finding of a function that is strongly correlated with the gradient vectors and whose expectation is known or comprehensible in order to calculate the variance [17, 10, 3, 11, 2]. Unfortunately, a good choice of the control variant is strongly dependent on the model. We first note that: Eq (a | y, I, \u03b7) q (a | I, I, \u03b7) a protocol p (a) q (a | I, IV), I, IV, I, IV, IV, IV, IV, I, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, I, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV, IV,"}, {"heading": "4.5 Encouraging exploration", "text": "Similar to other methods based on reinforcement learning, stochastic attention networks face the problem of encouraging the method to explore different actions. Since the gradient in Eq.8 only rewards or punishes the short-term sequences actually performed, any part of the room that is never visited does not receive a reward signal. [2] introduced several heuristics to promote exploration, including: (1) increasing the temperature of the supply distribution, (2) regulating the attention policy to promote the viewing of all image locations, and (3) adding a regularization term to promote high entropy in the action distribution. We implemented all three heuristics for the WS-RAM and for the baselins. Although these hayristics are important for good baseline performance, we found that they made little difference to the WS-RAM because the basic method was already sufficiently studied."}, {"heading": "5 Experimental results", "text": "In order to measure the effectiveness of the proposed WS-RAM method, we first investigated a toy classification task involving a variant of the MNIST handwritten digit dataset [25], in which transformations were applied to the images. Then, we evaluated the proposed method on a much more difficult task of generating captions using the Flickr8k dataset [26]."}, {"heading": "5.1 Translated scaled MNIST", "text": "We created a dataset of randomly transferred and scaled handwritten digits from the MNIST dataset. [25] Each digit was placed in a 100x100 black background image at a random location and scale. The task was to identify the numerical class. Attention models were allowed four glances before making a classification prediction. The aim of this experiment was to evaluate the effectiveness of our proposed WS-RAM model in comparison with the varying approach of [2]. For both the WS-RAM and the baseline, the architecture was a stochastic attention model that used ReLU units in all recursive layers. Actions included both continuous and discrete latent variables corresponding to the angle scale and the location. Distribution across the actions was represented as a Gaussian random variable for the site and an independent multinomical learning scale was trained to achieve the highest possible variable for all networks [whereby all were trained to achieve the highest]."}, {"heading": "5.2 Generating captions using multi-scale attention", "text": "We also used the WS-RAM method to learn a stochastic attention model similar to the [5] method for generating captions. We reported on the results of the widely used Flickr8k dataset. The distribution of training / validity / test followed the same protocol as in previous work [28]. The aim of this experiment was to investigate the improvement of WS-RAM over the variation method for learning with realistic inputs. Similar to [5], we first performed a Convolutionary Network, and the Attention Network then determined which part of the Convolutionary Net Representation should be taken into account. The Attention Network predicted both the layer to be looked after and a location within the layer, as opposed to [5] where the scale was held tight. As a Convolutionary Network shrinks the representation by max pooling, the choice of a layer of the selection of a scale corresponds to the choice of a WS. At each glance, the inferential network is immediately preceded by the WS in our target model."}, {"heading": "6 Conclusions", "text": "In this paper, we introduced the Wake-Sleep Recurrent Attention Model (WS-RAM), an efficient method for training stochastic attention models. This method improves on previous work by using the reweighted wake-sleep algorithm [9] to approximate expectations from the posterior view of gazes. Furthermore, we introduced control variants to reduce the variability of stochastic gradients. Our method reduces variance in gradient estimates and accelerates the training of attention networks for invariant handwritten recognition of digits as well as for the generation of captions."}, {"heading": "Acknowledgments", "text": "This work was supported by the Fields Institute, Samsung, ONR Grant N00014-14-1-0232 and the hardware donation from NVIDIA Corporation."}], "references": [{"title": "ImageNet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2012}, {"title": "Multiple object recognition with visual attention", "author": ["J. Ba", "V. Mnih", "K. Kavukcuoglu"], "venue": "International Conference on Learning Representations,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Recurrent models of visual attention", "author": ["V. Mnih", "N. Heess", "A. Graves", "K. Kavukcuoglu"], "venue": "Neural Information Processing Systems,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning generative models with visual attention", "author": ["Y. Tang", "N. Srivastava", "R. Salakhutdinov"], "venue": "Neural Information Processing Systems,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Show, attend, and tell: neural image caption generation with visual attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A. Courville", "R. Salakhutdinov", "R.S. Zemel", "Y. Bengio"], "venue": "International Conference on Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "International Conference on Learning Representations,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2015}, {"title": "Reinforcement learning neural Turing machines", "author": ["W. Zaremba", "I. Sutskever"], "venue": "arXiv:1505.00521,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2015}, {"title": "The Helmholtz machine", "author": ["P. Dayan", "G.E. Hinton", "R.M. Neal", "R.S. Zemel"], "venue": "Neural Computation, 7:889\u2013904,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 1995}, {"title": "Reweighted wake-sleep", "author": ["J. Bornschein", "Y. Bengio"], "venue": "arXiv:1406.2751,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Variational Bayesian inference with stochastic search", "author": ["J. Paisley", "D.M. Blei", "M.I. Jordan"], "venue": "International Conference on Machine Learning,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Neural variational inference and learning in belief networks", "author": ["A. Mnih", "K. Gregor"], "venue": "International Conference on Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning to combine foveal glimpses with a third-order Boltzmann machine", "author": ["H. Larochelle", "G.E. Hinton"], "venue": "Neural Information Processing Systems,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2010}, {"title": "Learning where to attend with deep architectures for image tracking", "author": ["M. Denil", "L. Bazzani", "H. Larochelle", "N. de Freitas"], "venue": "Neural Computation,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "arXiv:1308.0850,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "DRAW: a recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D. Wierstra"], "venue": "arXiv:1502.04623,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2015}, {"title": "Connectionist learning of belief networks", "author": ["Radford M. Neal"], "venue": "Artificial Intelligence,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1992}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["R.J. Williams"], "venue": "Machine Learning, 8:229\u2013256,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1992}, {"title": "Auto-encoding variational Bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "International Conference on Learning Representations,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2014}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "International Conference on Machine Learning,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "A model of saliency-based visual attention for rapid scene analysis", "author": ["L. Itti", "C. Koch", "E. Niebur"], "venue": "IEEE Transactions of Pattern Analysis and Machine Intelligence, 20(11):1254\u201359, November", "citeRegEx": "20", "shortCiteRegEx": null, "year": 1998}, {"title": "Learning to predict where humans look", "author": ["T. Judd", "K. Ehinger", "F. Durand", "A. Torralba"], "venue": "International Conference on Computer Vision,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning stochastic feedforward neural networks", "author": ["Y. Tang", "R. Salakhutdinov"], "venue": "Neural Information Processing Systems,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2013}, {"title": "Importance weighted autoencoders", "author": ["Y. Burda", "R. Grosse", "R. Salakhutdinov"], "venue": "arXiv:1509.00519,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "The optimal reward baseline for gradient-based reinforcement learning", "author": ["Lex Weaver", "Nigel Tao"], "venue": "In Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2001}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE, 86(11):2278\u20132324,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1998}, {"title": "Framing image description as a ranking task: Data, models and evaluation metrics", "author": ["Micah Hodosh", "Peter Young", "Julia Hockenmaier"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Adam: a method for stochastic optimization", "author": ["D. Kingma", "J.L. Ba"], "venue": "arXiv:1412.6980,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2014}, {"title": "Deep visual-semantic alignments for generating image descriptions", "author": ["Andrej Karpathy", "Li Fei-Fei"], "venue": "arXiv preprint arXiv:1412.2306,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "[1])).", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "This has motivated recent work on visual attention-based models [2, 3, 4], which reduce the number of parameters and computational operations by selecting informative regions of an image to focus on.", "startOffset": 64, "endOffset": 73}, {"referenceID": 2, "context": "This has motivated recent work on visual attention-based models [2, 3, 4], which reduce the number of parameters and computational operations by selecting informative regions of an image to focus on.", "startOffset": 64, "endOffset": 73}, {"referenceID": 3, "context": "This has motivated recent work on visual attention-based models [2, 3, 4], which reduce the number of parameters and computational operations by selecting informative regions of an image to focus on.", "startOffset": 64, "endOffset": 73}, {"referenceID": 4, "context": "One such approach was recently used by [5] to automatically generate image captions and highlight which image region was relevant to each word in the caption.", "startOffset": 39, "endOffset": 42}, {"referenceID": 4, "context": "[5]) obtain features from a weighted average of all image locations, where locations are weighted based on a model\u2019s saliency map.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2, 3]) chooses, typically stochastically, a series of discrete glimpse locations.", "startOffset": 0, "endOffset": 6}, {"referenceID": 2, "context": "[2, 3]) chooses, typically stochastically, a series of discrete glimpse locations.", "startOffset": 0, "endOffset": 6}, {"referenceID": 5, "context": "Unfortunately, this comes at a cost: while soft attention models can be trained with standard backpropagation [6, 5], this does not work for hard attention models, whose glimpse selections are typically discrete.", "startOffset": 110, "endOffset": 116}, {"referenceID": 4, "context": "Unfortunately, this comes at a cost: while soft attention models can be trained with standard backpropagation [6, 5], this does not work for hard attention models, whose glimpse selections are typically discrete.", "startOffset": 110, "endOffset": 116}, {"referenceID": 6, "context": "(The latter problem was also observed by [7] in the context of memory networks.", "startOffset": 41, "endOffset": 44}, {"referenceID": 7, "context": "inference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11].", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "inference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11].", "startOffset": 60, "endOffset": 63}, {"referenceID": 9, "context": "inference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11].", "startOffset": 86, "endOffset": 94}, {"referenceID": 10, "context": "inference networks [8], the reweighted wake-sleep algorithm [9], and control variates [10, 11].", "startOffset": 86, "endOffset": 94}, {"referenceID": 1, "context": "First, we present a new learning algorithm for stochastic attention models and compare it with a training method based on variational inference [2].", "startOffset": 144, "endOffset": 147}, {"referenceID": 1, "context": "Our model achieves similar performance to the variational method [2], but with much faster training times.", "startOffset": 65, "endOffset": 68}, {"referenceID": 11, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 67, "endOffset": 80}, {"referenceID": 3, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 67, "endOffset": 80}, {"referenceID": 2, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 67, "endOffset": 80}, {"referenceID": 1, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 67, "endOffset": 80}, {"referenceID": 12, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 98, "endOffset": 105}, {"referenceID": 2, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 98, "endOffset": 105}, {"referenceID": 5, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 127, "endOffset": 130}, {"referenceID": 4, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 151, "endOffset": 154}, {"referenceID": 13, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 177, "endOffset": 185}, {"referenceID": 14, "context": "Such models have been applied successfully in image classification [12, 4, 3, 2], object tracking [13, 3], machine translation [6], caption generation [5], and image generation [14, 15].", "startOffset": 177, "endOffset": 185}, {"referenceID": 1, "context": "Attention has been shown both to improve computational efficiency [2] and to yield insight into the network\u2019s behavior [5].", "startOffset": 66, "endOffset": 69}, {"referenceID": 4, "context": "Attention has been shown both to improve computational efficiency [2] and to yield insight into the network\u2019s behavior [5].", "startOffset": 119, "endOffset": 122}, {"referenceID": 1, "context": "[2]).", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "This difficulty is closely related to the problem of posterior inference in training deep generative models such as sigmoid belief networks [16].", "startOffset": 140, "endOffset": 144}, {"referenceID": 7, "context": "A classic example was the Helmholtz machine [8], where the inference network predicts a mean field approximation to the posterior.", "startOffset": 44, "endOffset": 47}, {"referenceID": 10, "context": "Neural variational inference and learning (NVIL) [11] trains both networks to maximize a variational lower bound on the log-likelihood.", "startOffset": 49, "endOffset": 53}, {"referenceID": 16, "context": "In particular, one uses an algortihm from reinforcement learning called REINFORCE [17], which attempts to infer a reward baseline for each instance.", "startOffset": 82, "endOffset": 86}, {"referenceID": 2, "context": "The choice of baseline is crucial to good performance; NVIL uses a separate neural network to compute the baseline, an approach also used by [3] in the context of attention networks.", "startOffset": 141, "endOffset": 144}, {"referenceID": 8, "context": "The reweighted wake-sleep approach [9] is similar to traditional wake-sleep, but uses importance sampling in place of mean field inference to approximate the posterior.", "startOffset": 35, "endOffset": 38}, {"referenceID": 17, "context": "Another method based on inference networks is variational autoencoders [18, 19], which exploit a clever reparameterization of the probabilistic model in order to improve the signal in the stochastic gradients.", "startOffset": 71, "endOffset": 79}, {"referenceID": 18, "context": "Another method based on inference networks is variational autoencoders [18, 19], which exploit a clever reparameterization of the probabilistic model in order to improve the signal in the stochastic gradients.", "startOffset": 71, "endOffset": 79}, {"referenceID": 19, "context": "[20, 21]), there are no labels for where to attend.", "startOffset": 0, "endOffset": 8}, {"referenceID": 20, "context": "[20, 21]), there are no labels for where to attend.", "startOffset": 0, "endOffset": 8}, {"referenceID": 1, "context": "We first outline the approach of [2], who trained the model to maximize a variational lower bound on `.", "startOffset": 33, "endOffset": 36}, {"referenceID": 1, "context": "In the case where q(a | y, I) = p(a | I,\u03b8) is the prior, as considered by [2], this reduces to F = \u2211", "startOffset": 74, "endOffset": 77}, {"referenceID": 1, "context": "As observed by [2], one must carefully use control variates in order to make this technique practical; we defer discussion of control variates to Section 4.", "startOffset": 15, "endOffset": 18}, {"referenceID": 8, "context": "Instead, we adopt an approach based on the wake-p step of reweighted wake-sleep [9], where we attempt to maximize the marginal log-probability ` directly.", "startOffset": 80, "endOffset": 83}, {"referenceID": 21, "context": "When q is chosen to be the prior, this approach is equivalent to the method of [22] for learning generative feed-forward networks.", "startOffset": 79, "endOffset": 83}, {"referenceID": 22, "context": "[23] further analyzed a closely related importance sampling based estimator in the context of generative models, bounding the mean absolute deviation and showing that the bias decreases monotonically with the number of samples.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Our training procedure for the inference network parallels the wake-q step of reweighted wakesleep [9].", "startOffset": 99, "endOffset": 102}, {"referenceID": 16, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 9, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 2, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 10, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 1, "context": "Past work using similar gradient updates has found significant benefit from the use of control variates, or reward baselines, to reduce the variance [17, 10, 3, 11, 2].", "startOffset": 149, "endOffset": 167}, {"referenceID": 9, "context": "Choosing effective control variates for the stochastic gradient estimators amounts to finding a function that is highly correlated with the gradient vectors, and whose expectation is known or tractable to compute [10, 24].", "startOffset": 213, "endOffset": 221}, {"referenceID": 23, "context": "Choosing effective control variates for the stochastic gradient estimators amounts to finding a function that is highly correlated with the gradient vectors, and whose expectation is known or tractable to compute [10, 24].", "startOffset": 213, "endOffset": 221}, {"referenceID": 10, "context": "Following the analogy with reinforcement learning highlighted by [11], these control variates can also be viewed as reward baselines:", "startOffset": 65, "endOffset": 69}, {"referenceID": 1, "context": "[2] introduced several heuristics to encourage exploration, including: (1) raising the temperature of the proposal distribution, (2) regularizing the attention policy to encourage viewing all image locations, and (3) adding a regularization term to encourage high entropy in the action distribution.", "startOffset": 0, "endOffset": 3}, {"referenceID": 24, "context": "To measure the effectiveness of the proposed WS-RAM method, we first investigated a toy classification task involving a variant of the MNIST handwritten digits dataset [25] where transformations were applied to the images.", "startOffset": 168, "endOffset": 172}, {"referenceID": 25, "context": "We then evaluated the proposed method on a substantially more difficult image caption generation task using the Flickr8k [26] dataset.", "startOffset": 121, "endOffset": 125}, {"referenceID": 24, "context": "We generated a dataset of randomly translated and scaled handwritten digits from the MNIST dataset [25].", "startOffset": 99, "endOffset": 103}, {"referenceID": 1, "context": "The goal of this experiment was to evaluate the effectiveness of our proposed WS-RAM model compared with the variational approach of [2].", "startOffset": 133, "endOffset": 136}, {"referenceID": 26, "context": "All networks were trained using Adam [27], with the learning rate set to the highest value that allowed the model to successfully converge to a sensible attention policy.", "startOffset": 37, "endOffset": 41}, {"referenceID": 4, "context": "We also applied the WS-RAM method to learn a stochastic attention model similar to [5] for generating image captions.", "startOffset": 83, "endOffset": 86}, {"referenceID": 27, "context": "The training/valid/test split followed the same protocol as used in previous work [28].", "startOffset": 82, "endOffset": 86}, {"referenceID": 4, "context": "Similarly to [5], we first ran a convolutional network, and the attention network then determined which part of the convolutional net representation to attend to.", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "The attention network predicted both which layer to attend to and a location within the layer, in contrast with [5], where the scale was held fixed.", "startOffset": 112, "endOffset": 115}, {"referenceID": 8, "context": "This method improves upon prior work by using the reweighted wake-sleep algorithm [9] to approximate expectations from the posterior over glimpses.", "startOffset": 82, "endOffset": 85}], "year": 2015, "abstractText": "Despite their success, convolutional neural networks are computationally expensive because they must examine all image locations. Stochastic attention-based models have been shown to improve computational efficiency at test time, but they remain difficult to train because of intractable posterior inference and high variance in the stochastic gradient estimates. Borrowing techniques from the literature on training deep generative models, we present the Wake-Sleep Recurrent Attention Model, a method for training stochastic attention networks which improves posterior inference and which reduces the variability in the stochastic gradients. We show that our method can greatly speed up the training time for stochastic attention networks in the domains of image classification and caption generation.", "creator": "LaTeX with hyperref package"}}}