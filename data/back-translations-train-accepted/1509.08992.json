{"id": "1509.08992", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Sep-2015", "title": "Maximum Likelihood Learning With Arbitrary Treewidth via Fast-Mixing Parameter Sets", "abstract": "Inference is typically intractable in high-treewidth undirected graphical models, making maximum likelihood learning a challenge. One way to overcome this is to restrict parameters to a tractable set, most typically the set of tree-structured parameters. This paper explores an alternative notion of a tractable set, namely a set of \"fast-mixing parameters\" where Markov chain Monte Carlo (MCMC) inference can be guaranteed to quickly converge to the stationary distribution. While it is common in practice to approximate the likelihood gradient using samples obtained from MCMC, such procedures lack theoretical guarantees. This paper proves that for any exponential family with bounded sufficient statistics, (not just graphical models) when parameters are constrained to a fast-mixing set, gradient descent with gradients approximated by sampling will approximate the maximum likelihood solution inside the set with high-probability. When unregularized, to find a solution epsilon-accurate in log-likelihood requires a total amount of effort cubic in 1/epsilon, disregarding logarithmic factors. When ridge-regularized, strong convexity allows a solution epsilon-accurate in parameter distance with effort quadratic in 1/epsilon. Both of these provide of a fully-polynomial time randomized approximation scheme.", "histories": [["v1", "Wed, 30 Sep 2015 01:44:41 GMT  (149kb)", "http://arxiv.org/abs/1509.08992v1", "Advances in Neural Information Processing Systems 2015"], ["v2", "Fri, 30 Oct 2015 07:29:08 GMT  (149kb)", "http://arxiv.org/abs/1509.08992v2", "Advances in Neural Information Processing Systems 2015"]], "COMMENTS": "Advances in Neural Information Processing Systems 2015", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["justin domke"], "accepted": true, "id": "1509.08992"}, "pdf": {"name": "1509.08992.pdf", "metadata": {"source": "CRF", "title": "Maximum Likelihood Learning With Arbitrary Treewidth via Fast-Mixing Parameter Sets", "authors": ["Justin Domke"], "emails": ["justin.domke@nicta.com.au"], "sections": [{"heading": null, "text": "ar Xiv: 150 9.08 992v 1 [cs.L G] 30 SE"}, {"heading": "1 Introduction", "text": "It is not only the way in which most people are able to put themselves into the world, but also the way in which they are put into the world. (...) It is also the way in which they are put into the world. (...) It is the way in which they are put into the world. (...) It is the way in which they are put into the world. (...) It is the way in which they are put into the world. (...) It is the way in which they are put into the world. (...) It is the way in which they are put into the world. (...) It is the way in which they are put into the world. (...) It is the way in which they are penetrated into the world. (...) It is the way in which they are penetrated into the world."}, {"heading": "2 Setup", "text": "Although the number of Markov chain transitions is used for each sample, the most important symbols are given here for further reference quantities. (This is a parameter vector that must be learned.) While the approximate distribution is obtained from the iteration chain of the iteration chain of the iteration chain, the approximate distribution from the iteration chain of the iteration chain is k. (v iterations of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of the iteration chain of"}, {"heading": "3 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Mixing times and Fast-Mixing Parameter Sets", "text": "This paper assumes that a sampling algorithm is known, a single iteration of which one can think about an operator that transforms some starting distributions into another. Stationary distribution takes place in another, i.e. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. liv. liv. liv. liv. liv. liv. liv. liv. mv. liv. liv. liv. liv. liv. liv. mv. liv. liv. liv. liv. liv. mv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. mv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. liv. limv. limv. limv. liv liv limv. limv. limv. liv limv. limv. liv limv. limv. limv. liv liv limv. liv limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. liv limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. limv. lim"}, {"heading": "4 Main Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Lipschitz Gradient", "text": "For reasons of lack of space, detailed proofs are moved to the appendix. However, informal proof sketches are provided to give a certain intuition for results with longer proofs. Our first main result is that the regularized protocol probability has a Lipschitz gradient. Theorem 1. The regularized protocol probability gradient is L-Lipschitz with L = 4R22 + \u03bb, i.e., that the probability for the protocol has a Lipschitz gradient. Theorem 1. The regularized protocol probability gradient is L-Lipschitz with L = 4R22 + \u03bb, i.e. that the probability for the protocol-probability-Gradient-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Values-Val"}, {"heading": "4.2 Convex convergence", "text": "KO KO + KCB + KCB + KCB + CB + KCB + CB KO + KO CB KO + KO CB + KCB + KCB + KCB + CB + KCB + KCB + KO CB KO + KO CB KO + KO CB KO + KO CB KO + KO CB + KCO CB + KO CB + KO CB + KO KO CB KO KO KO KO + KO KO KO KCB + KO KO KCB + KCB + KCO KCB + KCO KCO KCO KCB + KO KCO KCB + KCO KCO KCO KCB + KCO KCO KCO KCB + KCO KCB + KCB + KCB + KCB + KCO KCO KCO KCO KCO KCB + KCO KCO KCO KCB + KCO KCO KCO KCB + KCO KCB + KCO KCO KCO KCB + KCO KCO KCO KCB + KCO KCO KCB + KCO KCO KCO KCB + KCO KCO KCO KCB + KCO KCO KCB + KCO KCO KCO KCO KCB + KCO KCO KCO KCO KCO KCB + KCO KCO KCO KCB + KCO KCO KCO KCB + KCB KCO KCO KCO KCO KCO KCO KCB + KCO KCO KCO KCB KCO KCO KCO KCO KCO KCO KCO KCO KCO KCO KCO KCO KCB KCO KCO KCO KCO KCO KCO KCO KCO K"}, {"heading": "4.3 Strongly Convex Convergence", "text": "This section gives the main result for the convergence, which only applies in one particular case, where \u03bb > 0. Again, the main difficulty in this proof shows that the sum of the errors of the estimated gradients is small at each iteration. (This is done by using a concentration imbalance to show that the error of each estimated gradient is small, and then applying a union that is bound to show that the sum of the errors is small. (The main result is as follows.) If the protocol constant of regulation is at least 1 \u2212 \"algorithm 1 will meet expectations.\" (1 \u2212 \"L\") Hop \"2\" (\"L\") Hop. \"(2\" L \") Hop.\" (1 \"L\") Log. \"(2\" R2M. \")"}, {"heading": "5 Discussion", "text": "An important detail in the previous results is that the convex analysis yields convergence in terms of regularized log probability, while the strongly convex analysis yields convergence in terms of parameter distance. If we drop logarithmic factors, the workload required to optimize the log probability using the convex algorithm is in the order of 1 / 3, while the workload for optimization using the strongly convex analysis is in the order of 1 / 2. Although these quantities are not directly comparable, the standard limits for suboptimal convex functions with strongly convex L-Lipschitz gradients are in the order of 1 / 2. Roughly speaking, a regularization for the strongly convex analysis shows that an optimum of log probability can only be achieved linearly in 1 / 4 with a workload."}, {"heading": "6 Example", "text": "While this work does not require a significant practical contribution to practice, it is useful to illustrate an example. Let's take an Ising model p (x) \u0445 exp (\u2211 (i, j) \u0109ijxixj) for xi {\u2212 1, 1} on a 4 \u00d7 4 grid with 5 random vectors as training data. Sufficient statistics are t (x) = {xixj | (i, j) \u0445 pairs} and with 24 pairs. For a fast mixing grid, limitations are required for all pairs. As the maximum degree is 4, the lower value of L = 10 \u2212 4 tanh (.2). Fixed Same applies to 1, vice versa = 2 and vice versa = 0.1. Although the above theory suggests that the Lipschitz constant L = 4R22 + \u03bb = 97, a lower value of L = 10 is used, which converges more quickly in practice."}, {"heading": "7 Conclusions", "text": "This section discusses some of the weaknesses of the above analysis and possible directions for future work. However, the analysis of complexity in terms of the total sampling effort ignores the complexity of the projection itself. As the projection only needs to be performed K times, this time will often be very short compared to the sampling time. (This certainly applies to the above example.) However, this might not be the case if the projection algorithm scales superlinearly in the size of the model. Another problem is how the samples are initialized. As far as the proof is correct, the initial distribution r is arbitrary. In the above example, a simple uniform distribution is used. However, one could use the empirical distribution of training data, which is equivalent to a contrasting divergence [5]. It is reasonable to assume that this tends to reduce the mixing time when the model is close to generalization of the data. \u2212 However, the number of Markov transitions prescribed above is greater than the Diz, and the Diz 1 is not greater than the usual strategy."}, {"heading": "Acknowledgements", "text": "Thanks to Ivona Bez\u00e1kov\u00e1, Aaron Defazio, Nishant Mehta, Aditya Menon, Cheng Soon Ong and Christfried Webers. NICTA is funded by the Australian Government through the Department of Communications and by the Australian Research Council through the ICT Centre of Excellence Program."}, {"heading": "8 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "8.1 Optimization", "text": "The main results in this paper are strongly based on the work of Schmidt et al. [26] on the convergence of proximal gradient methods with errors in estimated gradients. (Special case of [26, Proposition 1]) Suppose a function f is convex with an L-Lipshitz gradient (Meaning of convex functions with errors in estimated gradients. (Special case of [26, Proposition 1]) Suppose a function f is convex with an L-Lipshitz gradient (Meaning of convex functions with errors in estimated gradients.) \u2212 f (Special case of [26, Proposition 1] Suppose a closed convex is set and an iteratesque convex is used."}, {"heading": "8.2 Concentration Results", "text": "Theorem 14. (Bernstein's Inequality) Supposedly Z1,..., ZK are independent with the mean 0, the | Zk | \u2264 c and the \u03c32i = V [Zi]. Then, if we define the following Hoeffding type, which is obliged to control the difference between the expected value of t (X) and the estimated value using M examples. Theorem 15. If X1,..., XM are independent variables with the mean of \u00b5 and vice versa, then the following Hoeffding type is bound to control the difference between the expected value of t (X) and the estimated value using M examples. Theorem 15. If X1,..., XM are independent variables with the mean of \u00b5, and the X \u2212 \u00b5-\u00b5 / 3)."}, {"heading": "9 Preliminary Results", "text": "A result that we will use several times is that for 0 < \u03b1 < 1, \u2212 1log (\u03b1) \u2264 11 \u2212 \u03b1. This limit is narrow in the boundary that lies between two estimated mean vectors. \u2212 The difference between two estimated mean vectors is then by Eq [t (X) \u2212 E q [t) \u2212 Ep [t (X)] 2 \u2264 2R2 \u00b2 q \u2212 p \u00b2 TV.Proof. Let the distribution functions of p and q be P and Q respectively. Then we have that Ep [t (X) \u2212 E q [t) [t) \u00b2 (X) \u00b2 \u00b2 \u00b2 \u00b2 (x) (dP (x) \u00b2 x) \u2212 dQ (x) \u00b2 x \u00b2 \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x \u00b2 x."}, {"heading": "10 Lipschitz Continuity", "text": "This section shows that the crest-regulated empirical protocol probability actually has a continuous course. Theorem 20. The regulated protocol probability function is L-Lipschitz with L = 4R22 + \u03bb, i.e., f-Lipschitz with L-Lipschitz, i.e. f-Lipschitz, f-Lipschitz, 2-Lipschitz, 2-Lipschitz, 2-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-5-5, 5-5-5, 5-5-5, 5-5-5, 5-5-5-schitz, 5-5-5-5, 5-5-schitz, 5-5-5-schitz, 5-5-5-schitz, 5-Lipschitz, 5-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 4-Lipschitz, 5-5-5, 5-5, 5-5-5, 5-5-5, 5-5, 5-5-5, 5-5-5, 5-5-5, 5-5, 5-5-5, 5-5, 5-5-5-5-5, 5-5-5, 5-5-5-5, 5-5-5, 5-5, 5-5-5, 5-5-5, 5-5-5-5, 5-5-5-5, 5-"}, {"heading": "11 Convex Convergence", "text": "This section gives the main result for convergence, which is true both in the regularized case and in the unregulated case where it is an isolated case where the sum of the norms of the estimated gradients is smaller. Theorem 21. Assuming that X1,..., XM are independent and equally distributed, and that the sum of the norms of the estimated gradients is smaller than 1 MM m = 1Xm \u2212 \u00b5 m 2]. Assuming that E [Z2] = V [Z] + E [Z] + E [Z] 2and the fact that the variance is not negative (Or simply Jensen's inequality), we can haveE [MM] m = 1Xm + 1Xm \u2212.m \u00b2 that we have two MM [Z] = 1M [Z] [Z] 2and the fact that the variance is not negative (Or simply Jensen's inequality)."}, {"heading": "12 Strongly Convex Convergence", "text": "This section mentions the main result for the convergence, which only applies in the case where there are no unambiguous results. (...) The main difficulty of this proof is that the sum of the error norms of the estimated gradients is small. (...) This proof is relatively simple, because we simply classify all errors as low with high probability, instead of collectively grasping the sum of errors. (...) If we have the difference of distributions, we can go after the error in the course forecast. (...) Log the course forecast. (...) Log the errors in the course forecast. (...) Log the course forecast. (...) Log the course forecast. (...) Log the course forecast. (...) Log the course forecast. (...)"}], "references": [{"title": "Learning factor graphs in polynomial time and sample complexity", "author": ["P. Abbeel", "D. Koller", "A. Ng"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Learning with blocks composite likelihood and contrastive divergence", "author": ["A. Asuncion", "Q. Liu", "A. Ihler", "P. Smyth"], "venue": "In AISTATS,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Statistical analysis of non-lattice data", "author": ["J. Besag"], "venue": "Journal of the Royal Statistical Society. Series D (The Statistician),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1975}, {"title": "Concentration Inequalities: A Nonasymptotic Theory of Independence", "author": ["S. Boucheron", "G. Lugosi", "P. Massart"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2013}, {"title": "On contrastive divergence learning", "author": ["M.A. Carreira-Peripi\u00f1\u00e1n", "G. Hinton"], "venue": "In AISTATS,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Approximating discrete probability distributions with dependence trees", "author": ["C.I. Chow", "C.N. Liu"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1968}, {"title": "Estimation of markov Random field prior parameters using Markov chain Monte Carlo maximum likelihood", "author": ["X. Descombes", "J.Z. Robin Morris", "M. Berthod"], "venue": "IEEE Transactions on Image Processing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1996}, {"title": "Projecting Ising model parameters for fast mixing", "author": ["J. Domke", "X. Liu"], "venue": "In NIPS,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Matrix norms and rapid mixing for spin systems", "author": ["M.E. Dyer", "L.A. Goldberg", "M. Jerrum"], "venue": "Ann. Appl. Probab.,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2009}, {"title": "Markov chain Monte Carlo maximum likelihood", "author": ["C. Geyer"], "venue": "In Symposium on the Interface,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1991}, {"title": "Maximum likelihood estimation for spatial models by Markov chain Monte Carlo stochastic approximation", "author": ["M.G. Gu", "Zhu", "H.-T"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2001}, {"title": "A simple condition implying rapid mixing of single-site dynamics on spin systems", "author": ["T. Hayes"], "venue": "In FOCS,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2006}, {"title": "Inferning with high girth graphical models", "author": ["U. Heinemann", "A. Globerson"], "venue": "In ICML,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "A practical guide to training restricted boltzmann machines", "author": ["G. Hinton"], "venue": "Technical report, University of Toronto,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Simulation reductions for the ising model", "author": ["M. Huber"], "venue": "Journal of Statistical Theory and Practice,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Estimation of non-normalized statistical models by score matching", "author": ["A. Hyv\u00e4rinen"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2005}, {"title": "Polynomial-time approximation algorithms for the ising model", "author": ["M. Jerrum", "A. Sinclair"], "venue": "SIAM Journal on Computing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1993}, {"title": "Probabilistic Graphical Models: Principles and Techniques", "author": ["D. Koller", "N. Friedman"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2009}, {"title": "Composite likelihood methods", "author": ["B. Lindsay"], "venue": "Contemporary Mathematics,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1988}, {"title": "Projecting Markov random field parameters for fast mixing", "author": ["X. Liu", "J. Domke"], "venue": "In NIPS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2014}, {"title": "Asymptotic efficiency of deterministic estimators for discrete energy-based models: Ratio matching and pseudolikelihood", "author": ["B. Marlin", "N. de Freitas"], "venue": "In UAI,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Linear and parallel learning of markov random fields", "author": ["Y. Mizrahi", "M. Denil", "N. de Freitas"], "venue": "In ICML,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Perturb-and-map random fields: Using discrete optimization to learn and sample from energy models", "author": ["G. Papandreou", "A.L. Yuille"], "venue": "In ICCV,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2011}, {"title": "Learning in Markov random fields using tempered transitions", "author": ["R. Salakhutdinov"], "venue": "In NIPS,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2009}, {"title": "Convergence rates of inexact proximal-gradient methods for convex optimization", "author": ["M. Schmidt", "N.L. Roux", "F. Bach"], "venue": "In NIPS,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "A generative perspective on MRFs in low-level vision", "author": ["U. Schmidt", "Q. Gao", "S. Roth"], "venue": "In CVPR,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2010}, {"title": "Learning fast-mixing models for structured prediction", "author": ["J. Steinhardt", "P. Liang"], "venue": "In ICML,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Training restricted Boltzmann machines using approximations to the likelihood gradient", "author": ["T. Tieleman"], "venue": "In ICML,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2008}, {"title": "An overview of composite likelihood methods", "author": ["C. Varin", "N. Reid", "D. Firth"], "venue": "Statistica Sinica,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2011}, {"title": "Estimating the \"wrong\" graphical model: Benefits in the computation-limited setting", "author": ["M. Wainwright"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2006}, {"title": "Graphical models, exponential families, and variational inference", "author": ["M. Wainwright", "M. Jordan"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2008}, {"title": "Filters, random fields and maximum entropy (FRAME): Towards a unified theory for texture modeling", "author": ["S.C. Zhu", "Y. Wu", "D. Mumford"], "venue": "International Journal of Computer Vision,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1998}], "referenceMentions": [], "year": 2017, "abstractText": "Inference is typically intractable in high-treewidth undirected graphical models, making maximum likelihood learning a challenge. One way to overcome this is to restrict parameters to a tractable set, most typically the set of tree-structured parameters. This paper explores an alternative notion of a tractable set, namely a set of \u201cfast-mixing parameters\u201d where Markov chain Monte Carlo (MCMC) inference can be guaranteed to quickly converge to the stationary distribution. While it is common in practice to approximate the likelihood gradient using samples obtained from MCMC, such procedures lack theoretical guarantees. This paper proves that for any exponential family with bounded sufficient statistics, (not just graphical models) when parameters are constrained to a fast-mixing set, gradient descent with gradients approximated by sampling will approximate the maximum likelihood solution inside the set with high-probability. When unregularized, to find a solution \u01eb-accurate in log-likelihood requires a total amount of effort cubic in 1/\u01eb, disregarding logarithmic factors. When ridge-regularized, strong convexity allows a solution \u01eb-accurate in parameter distance with effort quadratic in 1/\u01eb. Both of these provide of a fully-polynomial time randomized approximation scheme.", "creator": "LaTeX with hyperref package"}}}