{"id": "1510.03519", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Oct-2015", "title": "Bridge Correlational Neural Networks for Multilingual Multimodal Representation Learning", "abstract": "Recently there has been a lot of interest in learning common representations for multiple views of data. These views could belong to different modalities or languages. Typically, such common representations are learned using a parallel corpus between the two views (say, 1M images and their English captions). In this work, we address a real-world scenario where no direct parallel data is available between two views of interest (say, V1 and V2) but parallel data is available between each of these views and a pivot view (V3). We propose a model for learning a common representation for V1, V2 and V3 using only the parallel data available between V1V3 and V2V3. The proposed model is generic and even works when there are n views of interest and only one pivot view which acts as a bridge between them. There are two specific downstream applications that we focus on (i) Transfer learning between languages L1,L2,...,Ln using a pivot language L and (ii) cross modal access between images and a language L1 using a pivot language L2. We evaluate our model using two datasets : (i) publicly available multilingual TED corpus and (ii) a new multilingual multimodal dataset created and released as a part of this work. On both these datasets, our model outperforms state of the art approaches.", "histories": [["v1", "Tue, 13 Oct 2015 03:25:18 GMT  (4707kb,D)", "http://arxiv.org/abs/1510.03519v1", "12 pages"], ["v2", "Sat, 6 Feb 2016 07:44:01 GMT  (4536kb,D)", "http://arxiv.org/abs/1510.03519v2", "12 pages"], ["v3", "Fri, 1 Jul 2016 09:01:19 GMT  (4515kb,D)", "http://arxiv.org/abs/1510.03519v3", "Published at NAACL-HLT 2016"]], "COMMENTS": "12 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["janarthanan rajendran", "mitesh m khapra", "sarath chandar", "balaraman ravindran"], "accepted": true, "id": "1510.03519"}, "pdf": {"name": "1510.03519.pdf", "metadata": {"source": "CRF", "title": "Bridge Correlational Neural Networks for Multilingual Multimodal Representation Learning", "authors": ["Janarthanan Rajendran", "Mitesh M. Khapra", "Sarath Chandar", "Balaraman Ravindran"], "emails": ["rsdjjana@gmail.com", "mikhapra@in.ibm.com", "apsarathchandar@gmail.com", "ravi@cse.iitm.ac.in"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to"}, {"heading": "2 Related Work", "text": "In fact, it is the case that most of them are able to abide by the rules that they have imposed on themselves, and that they are able to abide by the rules that they have imposed on themselves. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they are able to abide by the rules. (...) In fact, it is the case that they are able to determine for themselves what they are doing. (...)"}, {"heading": "3 Bridge Correlational Neural Network", "text": "In this section we describe an extension of the CorrNet model we propose (Chandar et al., 2015), which addresses the problem of common representations between two views when parallel data is available between them. We propose an extension of their model, which simultaneously learns a common representation of individual views when parallel data is available only between one and two views. Let's leave the training data Z = {zi} Ni = 1, where each training instance contains only two views, i.e., zi = (vij, v i M), where j {1,.., M \u2212 1} and M is a pivot view. To be clearer, the training data contain N1, which is available (vi1, v i M)."}, {"heading": "4 Datasets", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Multlingual TED corpus", "text": "Hermann and Blunsom (2014b) provide a massively ymultilingual corpus, based on the TED corpus 1 for the IWSLT 2013 (Cettolo et al., 2012). It contains English transcriptions of several TED conference papers and their translations into multiple languages. We use the parallel data between English and other languages to train Bridge Corrnet (English thus acts as the fulcrum). Hermann and Blunsom (2014b) also propose a multilingual classification task using this corpus. The idea is to use the keywords associated with each paper as class labels and then train a classification to predict these classes. There are one or more such keywords for each paper, but only the 15 most common keywords in all documents are considered class labels. We used the same pre-processed train / test / valid splits 2 as (Hermann and Blunsom, in total, 12.0orpus consists of 12.078 documents)."}, {"heading": "4.2 Multilingual Image Caption dataset", "text": "The MSCOCO dataset 3 contains images and their captions in English. On average, there are 5 captions per image. The standard train / valid / test splits for this dataset are also available online. However, the reference captions for the images in the test split are not provided. As we need such reference captions for evaluations, we create a new train / valid / test of this dataset. Specifically, we take 80K images from the standard train split and 40K images from the standard valid split. We then randomly split the 120K images into train (118K), validation (1K) and test set (1K). We then create a multilingual version of the test data by collecting French and German translations for all 5 captions in the test set. We use crowdsourcing to do this. We use the CrowdFlower4 platform and solidify a French and a German translation of the captions for each of 5000 native language captions."}, {"heading": "5 Experiment 1: Transfer learning using a pivot language", "text": "From the TED corpus described above, we look at English transcriptions and their translations into 11 languages, namely Arabic, German, Spanish, French, Italian, Dutch, Polish, Portuguese (Brazil), Roman, Russian, and Turkish. After setting up Hermann and Blunsom (2014b), we consider the task of foreign language learning between each of the 11C2 non-English language pairs. The task is to classify documents in one language when no labeled training data is available in that language, but training data is available in another language. This includes the following steps: 1. Train classifier: Consider one language as the source language and the remaining 10 languages as the target languages. Train a document classifier using the labeled data of the source language, with each training document displayed using the hidden representation calculated using a trained bridge corrnet model. As in (Hermann and Blunsom, 2014b) we used an average of 10 perceptions for each of our experiments, each of which was trained as an Epoon for an experiment."}, {"heading": "5.1 Training and tuning Bridge Corrnet", "text": "For the above process to work, we must first train Bridge Corrnet so that it can then be used to calculate a common hidden representation for documents in different languages. Similarly, we treat Bridge CorrNet as the rotation language (View) and construct parallel training sets Z1 to Z11. Each instance in Z1 contains the English and Arabic view of the same conversation (Document). Similarly, we use this vocabulary in Z2 to construct the English and German view of the same conversation (Document), etc. For each language, we first construct a vocabulary containing all the words that occur more than 5 times in the corpus (all talks) of that language. We then use this vocabulary to construct a bag representation for each document. The size of the vocabulary (V |) for different languages varied from 31213 to 60326 words. To be clearer, v1 = variable, R | V | Arabic, v2 = man."}, {"heading": "5.2 Results", "text": "Before presenting the results for our Cross Language Classification Experiment, we first want to give a qualitative feel for the representations learned with Bridge CorrNet. To do this, we randomly select a few English words and find their closest neighbors in different languages based on the representations learned with Bridge CorrNet. These English words and their neighbors are shown in Table 4. In almost all cases, the closest neighbors of the English words turn out to be their exact translations or highly semantically related words. In addition, we observed that the representations of the translation pairs in non-English languages (say, French and German) are also transitively close, due to the pivot language. We now present the results of our Cross Language Classification Task in Table 1. Each row corresponds to a source language and each column corresponds to a target language. We report on the average F1 results in all 15 classes. We compare our results with the best results reported in (Hermann and Blunsom, 2014b)."}, {"heading": "6 Experiment 2: Cross modal access using a pivot language", "text": "In this experiment, we are interested in retrieving images using the above data. We expect to use this data with the above data in French (or German) and vice versa. However, for the training, we do not have parallel data containing images and their parallel French (or German) documents. Instead, we use the following datasets: (i) a dataset Z1, which contains images and their English captions, and (ii) a dataset Z2, which contains English and their parallel French (or German) documents. For Z2, we use the English-French (or German) parallel documents from the train split of the TED corpus (see Section 4.2). We use English as the Pivot language and Zug Bridge Corrnet with Z = {Z1, Z2} to learn common representations for images, English text and French (or German) text."}, {"heading": "6.1 Qualitative Analysis", "text": "Although the absolute mean value appears high, as indicated in Table 6, a qualitative analysis of the results indicates that Bridge CorrNet is capable of capturing crossmodal semantics between images and Franco-German descriptions. We illustrate this with a few examples in Table 6 and 7. The first line in Table 6 shows an image and its top 5 closest German captions (based on the Euclidean distance between their common representations). According to our parallel captions test, only the second and fourth captions actually correspond to this image. However, we note that the first and fifth captions are also semantically strongly related to the image. Both captions are about horses, grass or water bodies (ocean), etc. Similarly, the last line in Table 6 shows an image and its top 5 closest French captions. None of these captions actually correspond to the image according to our parallel captions test. However, the first, third and fourth captions are semantically relevant to this baseball, as all of them speak very much between the two of the French captions."}, {"heading": "7 Conclusion", "text": "In this paper, we propose Bridge Correlational Neural Networks that can learn common representations for multiple views, even if parallel data is only available between those views and a pivot view. We evaluate the performance of the representations we have learned using our model for different tasks using two large datasets. In particular, we evaluate performance in cross-language classification, monolingual classification and modal access. In all of these tasks, our method performs better than existing state-of-the-art approaches. We also publish a new multilingual caption dataset that will be helpful in further research in this area. In particular, we plan to use this data to create and evaluate a model for multilingual subtitle generation (as opposed to retrieval)."}], "references": [{"title": "A kernel method for canonical correlation analysis", "author": ["S. Akaho"], "venue": "In Proc. Int\u2019l Meeting on Psychometric Society", "citeRegEx": "Akaho.,? \\Q2001\\E", "shortCiteRegEx": "Akaho.", "year": 2001}, {"title": "Deep canonical correlation analysis", "author": ["Andrew et al.2013] Galen Andrew", "Raman Arora", "Jeff Bilmes", "Karen Livescu"], "venue": null, "citeRegEx": "Andrew et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Andrew et al\\.", "year": 2013}, {"title": "Cross language retrieval via transitive translation", "author": ["L.A. Ballesteros"], "venue": null, "citeRegEx": "Ballesteros.,? \\Q2000\\E", "shortCiteRegEx": "Ballesteros.", "year": 2000}, {"title": "Wit: Web inventory of transcribed and translated talks", "author": ["Christian Girardi", "Marcello Federico"], "venue": "In Proceedings of the 16 Conference of the European Association for Machine Translation (EAMT),", "citeRegEx": "Cettolo et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cettolo et al\\.", "year": 2012}, {"title": "Multilingual deep learning", "author": ["Mitesh M. Khapra", "Balaraman Ravindran", "Vikas C. Raykar", "Amrita Saha"], "venue": "NIPS Deep Learning Workshop", "citeRegEx": "Chandar et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chandar et al\\.", "year": 2013}, {"title": "An autoencoder approach to learning bilingual word representations", "author": ["Stanislas Lauly", "Hugo Larochelle", "Mitesh M. Khapra", "Balaraman Ravindran", "Vikas C. Raykar", "Amrita Saha"], "venue": null, "citeRegEx": "Chandar et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chandar et al\\.", "year": 2014}, {"title": "Machine translation by triangulation: Making effective use of multi-parallel corpora", "author": ["Cohn", "Lapata2007] Trevor Cohn", "Mirella Lapata"], "venue": "In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,", "citeRegEx": "Cohn et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cohn et al\\.", "year": 2007}, {"title": "Fast regularized canonical correlation analysis", "author": ["Cruz-Cano", "Lee2014] Raul Cruz-Cano", "MeiLing Ting Lee"], "venue": "Computational Statistics & Data Analysis,", "citeRegEx": "Cruz.Cano et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cruz.Cano et al\\.", "year": 2014}, {"title": "Bilbowa: Fast bilingual distributed representations without word alignments", "author": ["Gouws et al.2015] Stephan Gouws", "Yoshua Bengio", "Greg Corrado"], "venue": "In Proceedings of the 32nd International Conference", "citeRegEx": "Gouws et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gouws et al\\.", "year": 2015}, {"title": "Multilingual Distributed Representations without Word Alignment", "author": ["Hermann", "Phil Blunsom"], "venue": "In Proceedings of International Conference on Learning Representations (ICLR)", "citeRegEx": "Hermann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2014}, {"title": "Multilingual models for compositional distributed semantics", "author": ["Hermann", "Phil Blunsom"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Hermann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2014}, {"title": "Relations between two sets of variates", "author": ["H. Hotelling"], "venue": null, "citeRegEx": "Hotelling.,? \\Q1936\\E", "shortCiteRegEx": "Hotelling.", "year": 1936}, {"title": "Nonlinear canonical correlation analysis by neural networks", "author": ["W.W. Hsieh"], "venue": "Neural Networks,", "citeRegEx": "Hsieh.,? \\Q2000\\E", "shortCiteRegEx": "Hsieh.", "year": 2000}, {"title": "Everybody loves a rich cousin: An empirical study of transliteration through bridge languages. In Human Language Technologies", "author": ["A. Kumaran", "Pushpak Bhattacharyya"], "venue": null, "citeRegEx": "Khapra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Khapra et al\\.", "year": 2010}, {"title": "2010b. PR + RQ ALMOST EQUAL TO PQ: transliteration mining using bridge language", "author": ["Raghavendra Udupa", "A. Kumaran", "Pushpak Bhattacharyya"], "venue": "In Proceedings of the Twenty-Fourth AAAI Conference on Artificial", "citeRegEx": "Khapra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Khapra et al\\.", "year": 2010}, {"title": "Inducing Crosslingual Distributed Representations of Words", "author": ["Ivan Titov", "Binod Bhattarai"], "venue": "In Proceedings of the International Conference on Computational Linguistics (COLING)", "citeRegEx": "Klementiev et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Klementiev et al\\.", "year": 2012}, {"title": "Compositional machine transliteration", "author": ["Kumaran et al.2010] A. Kumaran", "Mitesh M. Khapra", "Pushpak Bhattacharyya"], "venue": "ACM Trans. Asian Lang. Inf. Process.,", "citeRegEx": "Kumaran et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kumaran et al\\.", "year": 2010}, {"title": "Experiments with transitive dictionary translation and pseudo-relevance feedback using graded relevance assessments", "author": ["Heikki Keskustalo", "Kalervo J\u00e4rvelin"], "venue": "Journal of the American Society", "citeRegEx": "Lehtokangas et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Lehtokangas et al\\.", "year": 2008}, {"title": "Tensor canonical correlation analysis for multi-view dimension reduction", "author": ["Luo et al.2015] Yong Luo", "Dacheng Tao", "Yonggang Wen", "Kotagiri Ramamohanarao", "Chao Xu"], "venue": "In Arxiv", "citeRegEx": "Luo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luo et al\\.", "year": 2015}, {"title": "Exploiting Similarities among Languages for Machine Translation", "author": ["Quoc Le", "Ilya Sutskever"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Improved statistical machine translation for resource-poor languages using related resource-rich languages", "author": ["Nakov", "Ng2009] Preslav Nakov", "Hwee Tou Ng"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Nakov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nakov et al\\.", "year": 2009}, {"title": "Multimodal deep learning", "author": ["Ngiam et al.2011] J. Ngiam", "A. Khosla", "M. Kim", "J. Nam", "H. Lee", "Ng. Andrew"], "venue": null, "citeRegEx": "Ngiam et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ngiam et al\\.", "year": 2011}, {"title": "Canonical ridge analysis with ridge parameter optimization, may", "author": ["L.K. Hansen", "S.C. Strother"], "venue": null, "citeRegEx": "Nielsen et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Nielsen et al\\.", "year": 1998}, {"title": "Grounded compositional semantics for finding and describing images with sentences", "author": ["Andrej Karpathy", "Quoc V. Le", "Christopher D. Manning", "Andrew Y. Ng"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2014}, {"title": "Leveraging monolingual data for crosslingual compositional word representations", "author": ["Soyer et al.2015] Hubert Soyer", "Pontus Stenetorp", "Akiko Aizawa"], "venue": "In Proceedings of the 3rd International Conference on Learning Representations,", "citeRegEx": "Soyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Soyer et al\\.", "year": 2015}, {"title": "Multimodal learning with deep boltzmann machines", "author": ["Srivastava", "Ruslan Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Regularized generalized canonical correlation analysis", "author": ["Tenenhaus", "Tenenhaus2011] Arthur Tenenhaus", "Michel Tenenhaus"], "venue": null, "citeRegEx": "Tenenhaus et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tenenhaus et al\\.", "year": 2011}, {"title": "A comparison of pivot methods for phrase-based statistical machine translation", "author": ["Utiyama", "Isahara2007] Masao Utiyama", "Hitoshi Isahara"], "venue": "In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguis-", "citeRegEx": "Utiyama et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Utiyama et al\\.", "year": 2007}, {"title": "Canonical ridge and econometrics of joint production", "author": ["H.D. Vinod"], "venue": "Journal of Econometrics,", "citeRegEx": "Vinod.,? \\Q1976\\E", "shortCiteRegEx": "Vinod.", "year": 1976}, {"title": "On deep multi-view representation learning", "author": ["Wang et al.2015] Weiran Wang", "Raman Arora", "Karen Livescu", "Jeff Bilmes"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Pivot language approach for phrase-based statistical machine translation", "author": ["Wu", "Wang2007] Hua Wu", "Haifeng Wang"], "venue": "Machine Translation,", "citeRegEx": "Wu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2007}, {"title": "A deep and autoregressive approach for topic modeling of multimodal data. CoRR, abs/1409.3970", "author": ["Zheng et al.2014a] Yin Zheng", "Yu-Jin Zhang", "Hugo Larochelle"], "venue": null, "citeRegEx": "Zheng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zheng et al\\.", "year": 2014}, {"title": "Topic modeling of multimodal data: An autoregressive approach", "author": ["Zheng et al.2014b] Yin Zheng", "Yu-Jin Zhang", "Hugo Larochelle"], "venue": "In 2014 IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Zheng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zheng et al\\.", "year": 2014}, {"title": "Bilingual Word Embeddings for Phrase-Based Machine Translation", "author": ["Zou et al.2013] Will Y. Zou", "Richard Socher", "Daniel Cer", "Christopher D. Manning"], "venue": "In Conference on Empirical Methods in Natural Language Processing (EMNLP", "citeRegEx": "Zou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 21, "context": "Existing approaches to common representation learning (Ngiam et al., 2011; Klementiev et al., 2012; Chandar et al., 2013; Chandar et al., 2014; Andrew et al., 2013; Hermann and Blunsom, 2014b; Wang et al., 2015) typically require parallel data between the two views.", "startOffset": 54, "endOffset": 211}, {"referenceID": 15, "context": "Existing approaches to common representation learning (Ngiam et al., 2011; Klementiev et al., 2012; Chandar et al., 2013; Chandar et al., 2014; Andrew et al., 2013; Hermann and Blunsom, 2014b; Wang et al., 2015) typically require parallel data between the two views.", "startOffset": 54, "endOffset": 211}, {"referenceID": 4, "context": "Existing approaches to common representation learning (Ngiam et al., 2011; Klementiev et al., 2012; Chandar et al., 2013; Chandar et al., 2014; Andrew et al., 2013; Hermann and Blunsom, 2014b; Wang et al., 2015) typically require parallel data between the two views.", "startOffset": 54, "endOffset": 211}, {"referenceID": 5, "context": "Existing approaches to common representation learning (Ngiam et al., 2011; Klementiev et al., 2012; Chandar et al., 2013; Chandar et al., 2014; Andrew et al., 2013; Hermann and Blunsom, 2014b; Wang et al., 2015) typically require parallel data between the two views.", "startOffset": 54, "endOffset": 211}, {"referenceID": 1, "context": "Existing approaches to common representation learning (Ngiam et al., 2011; Klementiev et al., 2012; Chandar et al., 2013; Chandar et al., 2014; Andrew et al., 2013; Hermann and Blunsom, 2014b; Wang et al., 2015) typically require parallel data between the two views.", "startOffset": 54, "endOffset": 211}, {"referenceID": 29, "context": "Existing approaches to common representation learning (Ngiam et al., 2011; Klementiev et al., 2012; Chandar et al., 2013; Chandar et al., 2014; Andrew et al., 2013; Hermann and Blunsom, 2014b; Wang et al., 2015) typically require parallel data between the two views.", "startOffset": 54, "endOffset": 211}, {"referenceID": 11, "context": "Canonical Correlation Analysis (CCA) and its variants (Hotelling, 1936; Vinod, 1976; Nielsen et al., 1998; Cruz-Cano and Lee, 2014; Akaho, 2001)", "startOffset": 54, "endOffset": 144}, {"referenceID": 28, "context": "Canonical Correlation Analysis (CCA) and its variants (Hotelling, 1936; Vinod, 1976; Nielsen et al., 1998; Cruz-Cano and Lee, 2014; Akaho, 2001)", "startOffset": 54, "endOffset": 144}, {"referenceID": 22, "context": "Canonical Correlation Analysis (CCA) and its variants (Hotelling, 1936; Vinod, 1976; Nielsen et al., 1998; Cruz-Cano and Lee, 2014; Akaho, 2001)", "startOffset": 54, "endOffset": 144}, {"referenceID": 0, "context": "Canonical Correlation Analysis (CCA) and its variants (Hotelling, 1936; Vinod, 1976; Nielsen et al., 1998; Cruz-Cano and Lee, 2014; Akaho, 2001)", "startOffset": 54, "endOffset": 144}, {"referenceID": 12, "context": "common representations was proposed in (Hsieh, 2000).", "startOffset": 39, "endOffset": 52}, {"referenceID": 21, "context": "Multimodal Autoencoder (MAE) proposed in (Ngiam et al., 2011) uses", "startOffset": 41, "endOffset": 61}, {"referenceID": 29, "context": "Deep Canonically Correlated Autoencoder (DCCAE) which was proposed in (Wang et al., 2015) uses a combination of Autoencoder (encoding/decoding only inside the", "startOffset": 70, "endOffset": 89}, {"referenceID": 1, "context": "Similarly, Deep CCA (Andrew et al., 2013) uses deep neural networks to encode the views in a common space.", "startOffset": 20, "endOffset": 41}, {"referenceID": 15, "context": "resentation Learning using Neural Networks relied on this word level alignment information (Klementiev et al., 2012; Zou et al., 2013; Mikolov et al., 2013).", "startOffset": 91, "endOffset": 156}, {"referenceID": 33, "context": "resentation Learning using Neural Networks relied on this word level alignment information (Klementiev et al., 2012; Zou et al., 2013; Mikolov et al., 2013).", "startOffset": 91, "endOffset": 156}, {"referenceID": 19, "context": "resentation Learning using Neural Networks relied on this word level alignment information (Klementiev et al., 2012; Zou et al., 2013; Mikolov et al., 2013).", "startOffset": 91, "endOffset": 156}, {"referenceID": 5, "context": "level alignments (Hermann and Blunsom, 2014b; Hermann and Blunsom, 2014a; Chandar et al., 2014; Soyer et al., 2015; Gouws et al., 2015).", "startOffset": 17, "endOffset": 135}, {"referenceID": 24, "context": "level alignments (Hermann and Blunsom, 2014b; Hermann and Blunsom, 2014a; Chandar et al., 2014; Soyer et al., 2015; Gouws et al., 2015).", "startOffset": 17, "endOffset": 135}, {"referenceID": 8, "context": "level alignments (Hermann and Blunsom, 2014b; Hermann and Blunsom, 2014a; Chandar et al., 2014; Soyer et al., 2015; Gouws et al., 2015).", "startOffset": 17, "endOffset": 135}, {"referenceID": 21, "context": "Ngiam et al. (2011) proposed", "startOffset": 0, "endOffset": 20}, {"referenceID": 23, "context": "learning include (Zheng et al., 2014a; Zheng et al., 2014b; Socher et al., 2014).", "startOffset": 17, "endOffset": 80}, {"referenceID": 16, "context": ", 2008), pivot based transliteration and transliteration mining (Khapra et al., 2010a; Kumaran et al., 2010; Khapra et al., 2010b; Zhang et al., 2011).", "startOffset": 64, "endOffset": 150}, {"referenceID": 3, "context": "multilingual corpus based on the TED corpus1 for IWSLT 2013 (Cettolo et al., 2012).", "startOffset": 60, "endOffset": 82}, {"referenceID": 23, "context": "Socher et al. (2014) use a similar experimental setup at a much smaller scale (using a train/valid/test split of 800/100/100 image-caption pairs).", "startOffset": 0, "endOffset": 21}, {"referenceID": 21, "context": "Fr/De-En-Image MAE: The Multimodal Autoencoder (MAE) proposed by (Ngiam et al., 2011) was the only competing model which was easily ex-", "startOffset": 65, "endOffset": 85}, {"referenceID": 23, "context": "numbers reported in Socher et al. (2014) also suggest the same).", "startOffset": 20, "endOffset": 41}, {"referenceID": 13, "context": "The first is the Bridge CCA model proposed by Khapra et al. (2010b)", "startOffset": 46, "endOffset": 68}, {"referenceID": 1, "context": "We then tried using the Deep CCA model proposed by Andrew et al. (2013) as a substitute for CCA and trained it using the same process as outlined in (Khapra et al.", "startOffset": 51, "endOffset": 72}], "year": 2017, "abstractText": "Recently there has been a lot of interest in learning common representations for multiple views of data. These views could belong to different modalities or languages. Typically, such common representations are learned using a parallel corpus between the two views (say, 1M images and their English captions). In this work, we address a real-world scenario where no direct parallel data is available between two views of interest (say, V1 and V2) but parallel data is available between each of these views and a pivot view (V3). We propose a model for learning a common representation for V1, V2 and V3 using only the parallel data available between V1V3 and V2V3. The proposed model is generic and even works when there are n views of interest and only one pivot view which acts as a bridge between them. There are two specific downstream applications that we focus on (i) Transfer learning between languages L1,L2,...,Ln using a pivot language L and (ii) cross modal access between images and a language L1 using a pivot language L2. We evaluate our model using two datasets : (i) publicly available multilingual TED corpus and (ii) a new multilingual multimodal dataset created and released as a part of this work. On both these datasets, our model outperforms state of the art approaches.", "creator": "LaTeX with hyperref package"}}}