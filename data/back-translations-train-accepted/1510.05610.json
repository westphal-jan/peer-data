{"id": "1510.05610", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Oct-2015", "title": "Stochastically Transitive Models for Pairwise Comparisons: Statistical and Computational Issues", "abstract": "There are various parametric models for analyzing pairwise comparison data, including the Bradley-Terry-Luce (BTL) and Thurstone models, but their reliance on strong parametric assumptions is limiting. In this work, we study a flexible model for pairwise comparisons, under which the probabilities of outcomes are required only to satisfy a natural form of stochastic transitivity. This class includes several parametric models including the BTL and Thurstone models as special cases, but is considerably more general. We provide various examples of models in this broader stochastically transitive class for which classical parametric models provide poor fits. Despite this greater flexibility, we show that the matrix of probabilities can be estimated at the same rate as in standard parametric models. On the other hand, unlike in the BTL and Thurstone models, computing the least-squares estimate in the stochastically transitive model is non-trivial, and we explore various computationally tractable alternatives. We show that a simple singular value thresholding algorithm is statistically consistent but does not achieve the minimax rate. We then propose and study algorithms that achieve the minimax rate over interesting sub-classes of the full stochastically transitive class. We complement our theoretical results with thorough numerical simulations.", "histories": [["v1", "Mon, 19 Oct 2015 18:19:16 GMT  (166kb,D)", "http://arxiv.org/abs/1510.05610v1", null], ["v2", "Wed, 21 Oct 2015 17:54:49 GMT  (171kb,D)", "http://arxiv.org/abs/1510.05610v2", null], ["v3", "Wed, 25 May 2016 18:41:40 GMT  (179kb,D)", "http://arxiv.org/abs/1510.05610v3", null], ["v4", "Wed, 28 Sep 2016 02:14:25 GMT  (232kb,D)", "http://arxiv.org/abs/1510.05610v4", null]], "reviews": [], "SUBJECTS": "stat.ML cs.IT cs.LG math.IT", "authors": ["nihar b shah", "sivaraman balakrishnan", "aditya guntuboyina", "martin j wainwright"], "accepted": true, "id": "1510.05610"}, "pdf": {"name": "1510.05610.pdf", "metadata": {"source": "CRF", "title": "Stochastically Transitive Models for Pairwise Comparisons: Statistical and Computational Issues", "authors": ["Nihar B. Shah", "Sivaraman Balakrishnan", "Adityanand Guntuboyina", "Martin J. Wainright"], "emails": ["nihar@eecs.berkeley.edu,", "sbalakri@berkeley.edu,", "aditya@stat.berkeley.edu,", "wainwrig@berkeley.edu."], "sections": [{"heading": "1 Introduction", "text": "This year, it is so far that it will be able to take the lead, \"he told the German Press Agency in an interview.\" It is very important that we are able to establish ourselves in the region, \"he said."}, {"heading": "2 Background and problem formulation", "text": "For an accumulation of n \u2265 2 items, we assume that we have a mechanism for making loud comparisons between any pair of i 6 = j of different items. A complete set of all possible pairwise comparisons can be described by a probability matrix M * [0, 1] n \u00b7 n in which M * ij is the probability that item i is preferred to item j. The upper and lower half of the probability matrix M * are connected by the inclined symmetry condition M * ji = 1 \u2212 M * ij for all i, j * [n].1."}, {"heading": "2.1 Estimation of pairwise comparison probabilities", "text": "Considering any arbitrary matrix M-1-n with M-ij = 1-M-II-II-II-II-II-II for each (i, j), we assume that we observe a random matrix Y-II-II with (upper triangular) independent Bernoulli entries, especially with P [Yij = 1] = M-II-II for each 1 \u2264 i \u2264 j \u2264 n and Yji = 1 \u2212 Yij. Based on observation Y, our goal in this paper is to restore an accurate estimate of the full matrix M-II in the square of Frobenius's Norm. Our focus in this paper will be on the setting in which we observe the result of a single pair comparison for n items. Subsequently, we will also address the more general case when we have partial observations, that is, when each pair comparison is observed with a fixed probability."}, {"heading": "2.2 Strong stochastic transitivity", "text": "In addition to the limitations of the matrix already mentioned, more structured and interesting models are achieved by imposing further constraints on the entries of M *. We now turn to such a condition, known as strong stochastic transitivity (SST), which reflects the natural transitivity of any complete order. Formally, we assume that the complete collection of elements [n] is endowed with a complete order. We use the notation \u03c0 (i) \u03c0 (j) \u03c0 (j) j) to convey that article i is preferred in the complete order j. Let us consider some triples (i, j, k) so that there is a complete order \u03c0 (j). A matrix M * fulfils the SST condition if the inequality M * is that the inequality M \u00b2 condition applies to each such threefold. The mutation underlying this constraint is as follows."}, {"heading": "2.3 Classical parametric models", "text": "Let us now describe a family of classical parametric models, one that includes Bradley Terry-Luce and Thurstone (case V) models [BT52, Luc59, Thu27]. As we will see, they may be the cause of a relatively small subclass of SST matrices CSST. In detail, parametric models are described by a weight vector w * Rn corresponding to the mental qualities of n items. Furthermore, we note that the psychological literature is also known as weak and moderately stochastic transitivity conditions. From a statistical point of view, pairwise comparative probabilities cannot be uniformly estimated in a minimaxim sense under these conditions. We formally append them to C.function F: R 7 \u2192 [0, 1] so that F (t) = 1 \u2212 F (\u2212 t) is valid for all valid F \u2212 R; we refer to each such function F as valid."}, {"heading": "2.4 Inadequacies of parametric models", "text": "As noted in the introduction, much of the work to date (e.g. DM59, ML65, Tve72, BW97) is observable in the United States. (This may be one reason for this phenomenon, but the probability that such a model will cause another depends on the abilities of others. (It may not be that such a model depends on the value of a single latent factor) - for example, that our preference for cars depends only on their fuel efficiency, or that the probability that one hockey team will defeat another depends on the abilities of tornadoes. (This intuition can be based on the value of a single latent factor), which is far removed from any valid parametry as it is summed up: for every n-4, there are existing matrices of tornadoes."}, {"heading": "3 Main results", "text": "So far, we have introduced two classes of models for matrices of pairs of comparative probabilities: Our main results provide characterizations of the estimation error associated with various subsets of these classes, either with optimal estimators (which we assume cannot be calculated with polynomial time) or with more computationally efficient estimators that can be calculated in polynomial time."}, {"heading": "3.1 Characterization of the minimax risk", "text": "We start by providing a result that characterizes the minimax risk square Frobenius standard on the class CSST of the SST matrices. It is a matter of taking an infimum on the set of all possible estimators that are measurable functions Y 7 \u2192 M'n \u00b7 n Given that the data matrix Y [0, 1} n \u00d7 n is taken from the observational model (1). Theorem 1. There are universal constants 0 < K'n like thatK'n \u2264 inf M'sup M \"n, M\" n \"n\" n \"n\" s \"s\" s \"s.\" There are universal constants 0 < K \"n\" < Ku like thatK \"n\" n \"M\" n \"n.\" We prove this theorem in Section 5.1. \"The proof of the lower limit is based on the extraction of a certain subset of CSST.\""}, {"heading": "3.2 Sharp analysis of singular value thresholding (SVT)", "text": "The first polynomial time estimator we are looking at is a simple estimator based on thresholds of the observed matrix Y, and it reconstructs its truncated SVD. In this section, we prove that its error rate as O (n \u2212 1 2) decreases uniformly over CSST again, and furthermore proves that this upper limit is inevitable. Let's start with the description of the estimator. Given the observation matrix Y threshold, we can write its singular decomposition as Y = UDV T, where the matrix D is diagonal, whereas the matrix (n \u00b7 n) matrices U and V are orthonormal."}, {"heading": "3.3 Optimal rates for high SNR subclass", "text": "In this section, we describe a multi-stage polynomial time estimation that shows (up to logarithmic factors) multiple error (up to logarithmic factors) that we can achieve the optimal O (1 / n) rate via an interesting subclass of CSST. This subset corresponds to matrices M that have a relatively high signal-to-noise ratio (SNR), which means that no entries of M fall within a given window of 1 / 2. (12) Formally, we define the number of information contained in each observation, away from zero uniformly in n, as opposed to matrices in which some large subsets of Entrys have values equal to (or arbitrarily close) to 12. In terms of estimation difficulties, this SNR limitation does not make the problem much easier: as the following averages, we show that some large subsets of Entrys have values close to 12."}, {"heading": "3.4 Optimal rates for parametric subclasses", "text": "Let us now return to the class of parametric models CPAR (F), which was introduced earlier in Section 2.3. As already shown in Proposition 1, this class is much smaller than the class CSST, in the sense that there are models in CSST that cannot be approached well by any parametric model. However, these classes differ in terms of minimum estimation rates only by logarithmic factors. An advantage of the parametric class is that it is possible to achieve the minimum estimation by using a simple polynomial time estimator. In particular, the maximum estimation of the concave function F can be achieved by solving a convex program."}, {"heading": "3.5 Extension to partial observations", "text": "Let us consider the extension of our results to the environment in which not all entries of Y are observed. Instead, let us assume that each entry of Y is observed independently of the probability pots. In other words, the number of pairs that are compared is the set of edges of an erdo-re-nyi diagram G (n, pobs) that has the n points as its wells. (a) There are positive universal constants of K'and Ku such that the Minimax risk is not compared, and the application of the previously investigated algorithms to the resulting matrix Y.Theorem 5. In the partial observation described above: (a) There are positive universal constants of K'and Ku such that the Minimax risk is not compared. (1 pobsn, 1 n2)."}, {"heading": "4 Simulations", "text": "In this section, we present the results from simulations to gain a further understanding of the problem, in particular, to understand the rates of estimation under certain generative models. We examine the performance of the soft SVT estimator (Section 3.2) and the maximum probability of an estimator under the Turstone model (Section 2.3).5 However, the output of the SVT estimator does not have to be in the amount we generate in the following five ways: The matrix M is generated by projecting the results of the SVT estimator on this basis, which have a constant factor reduction in error. In our simulations, we generate the truth M in the following five ways: The uniform M is generated by drawing (n 2) values independently and uniformly randomly in [12, 1] and sort them in descending order."}, {"heading": "5 Proofs of main results", "text": "This section is devoted to the proofs of our main results - theorems 1 to 5. During this and other proofs, we use the notation {c, c, c0, C, C \u00b2 and so on to designate positive constants whose values may vary from line to line. Furthermore, we assume that n is undercut by a universal constant to avoid degeneration; for each square matrix, we let {\u03c31 (A),..., \u03c3n (A)} specify their singular values (ordered from the greatest to the smallest), and similarly, for each symmetric matrix, we let M, Rn \u00b7 n, {\u03bb1 (M),., \u03bbn (M)} specify their ordered eigenvalues."}, {"heading": "5.1 Proof of Theorem 1", "text": "This section is devoted to the proof of theorem 1, including the upper and lower limits of minimax risk in the Frobenius quadratic norm."}, {"heading": "5.1.1 Proof of upper bound", "text": "(2) < (2) < (2) < (2) < (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5, (5), (5), (5, (5), (5), (5), (5), (5), (5, (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5),"}, {"heading": "5.1.2 Proof of lower bound", "text": "Let us now turn to the proof of the lower limit in Theorem 1. We can assume that the correct sequence / column order is fixed and is known as 1 2 \u00b7 \u00b7 \u00b7 n. Here we take advantage of the fact that disclosing knowledge of this sequence cannot make the estimation problem more difficult. If we recall the definition (18) of the bivariate isotonic class CBISO, we can use the subclass C \u00b2 SST: = {M \u00b2 CBISO | Mi, j = 1 for j > i + 1 and Mi, j = 1 \u2212 Mj, i for j \u2264 i} Each matrix M is this subclass with the vector q = q (M) - Rn \u2212 1 for elements qi: = Mi, i + 1. The only constraint imposed on q (M) by including M \u00b2 CSST is that Qi [12, 1] is this subclass for all i = 1,."}, {"heading": "5.2 Proof of Theorem 2", "text": "Remember (1) that we can write our observation model as Y = M * + W, where W * Rn \u00b7 n is a zero-mean matrix with entries drawn independently of the interval [\u2212 1, 1] (except for the oblique symmetry condition)."}, {"heading": "5.2.1 Proof of upper bound", "text": "Our proof of the upper limit depends on the following two factors: Lemma 3. If we rely on the upper limit, then we are dependent on the upper limit. (...) If we come to the upper limit, we will come to the upper limit. (...) If we come to the upper limit, we will come to the upper limit. (...) If we come to the upper limit, we will come to the upper limit. (...) If we come to the upper limit, we will come to the upper limit. (...) We will come to the upper limit. (...) We will come to the upper limit. (...) We will come to the upper limit. (...) We will come to the upper limit. (...) We will come to the upper limit. (...) We will come to the upper limit. (...)"}, {"heading": "5.2.2 Proof of lower bound", "text": "We now turn to the proof of the lower limit in theorem 2. We divide our analysis into two cases, depending on the magnitude of the constants. We assume that the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants. - In this case we consider the constants of the constants of the constants of the constants of the constants of the constants, the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants of the constants."}, {"heading": "5.3 Proof of Theorem 3", "text": "We now prove our results on the high SNR subclass of the CSST, in particular by setting a lower limit and then analyzing the two-step estimator described in Section 3.3 to obtain the upper limit."}, {"heading": "5.3.1 Proof of lower bound", "text": "To prove the lower limit, we follow the proof for the lower limit of theorem 1, with the only difference that the vector q \u0435Rn \u2212 1 is limited to lying in the interval [12 + \u03b3, 1] n \u2212 1.7In particular, the laplac of a graph is given by L = D \u2212 A, where A is the graph adaptation matrix and D is the diagonal degree matrix."}, {"heading": "5.3.2 Proof of upper bound", "text": "Remember that the second step of our approach involves a limited regression caused by the difference between the two levels of FAS and the correct identity spermutation. (31) In order to formalize this notion, for each fixed permutation we must take into account the error caused by the noise in our samples, and also some form of approximation error caused by the difference between the two levels of FAS and the correct identity spermutation. (31) In order to formalize this notion, we must consider the limited minimum square estimates, which relate to the minimum square. (31) The first sequence provides an upper limit for the error matrix. (31) The second sequence is that we consider the restricted minimum square, which includes both approximation and estimation errors. (41) There is a universal constant, which is 0 > 0."}, {"heading": "5.4 Proof of Theorem 4", "text": "Let us now turn to our theorem, which sets upper and lower limits when estimating pairs of probability matrices for parametric models, starting with a proof of the claimed lower limit."}, {"heading": "5.4.1 Lower bound", "text": "We prove our lower limit by constructing a series of matrices that are well separated in the Frobenius standard. (Using this sentence, we then use an argument based on Fano's inequality to reduce the minimax risk. (<) The basis of our construction of the matrix collection is a collection of Boolean vectors. (For all two Boolean vectors b, b, 1) n, let dH (b, b, b) j = 1 [bj 6 = b, j] denote their hamming vectors. (Lemma 8. For all fixed vectors b, 1 / 4) there is a collection of Boolean vectors {b1, b,., bT} such as thatH (b, bk), dH (b, 0)} n, which we (b, 0) n, the j."}, {"heading": "5.4.2 Upper bound", "text": "In our previous paper [SBB + 15 \u2212 \u2212 w2, Theorem 2b], we demonstrated that if F is strongly log-concave and doubly differentiable, then there is a universal constant Ku, so that the maximum probability estimator w-ML is a square error in mostsup w-concave. [\u2212 1,1] n, < w-constant, 1 > = 0E [\u2211 w-ML \u2212 w-22] \u2264 Ku. (41) In addition, the MLE is calculable in polynomial time taking into account the log-concave assumption. Let M (w-ML) and M (w-ML) denote the pair-wise comparison matrices induced by the equation (4) by w-ML and w-concavity. It is sufficient to combine the Frobenius standard."}, {"heading": "5.5 Proof of Theorem 5", "text": "We now turn to the proof of theorem 5, which characterizes the behavior of various estimators for the partially observed case."}, {"heading": "5.5.1 Proof of part (a)", "text": "In this section, we prove the lower and upper limit, which in Equation (17a) in part (a).Proof of the lower limit: We begin by proving the lower limit in Equation (17a). - The lower limit in Equation (17a). - The lower limit in Equation (17a). - The lower limit in Equation (17a). - The lower limit in Equation (17a). - The lower limit in Equation (2b). - The lower limit (2b). - The lower limit (2b). - The lower limit (2b). - The lower limit (2b). - The lower limit (2b). - (2b). - The lower limit (2b). (2b). - The lower limit (2b). (b). (b). (b)."}, {"heading": "5.5.2 Proof of part (b)", "text": "To prove the limit (17b), we analyze the SVT estimator T\u03bbn, pobs (Y) with the threshold \u03bbn, pobs = 2.1 \u221a npobs. Of course, our analysis is similar to the complete observation situation from Section 5.2. Let us recall our formulation of the problem with respect to the observation matrix Y together with the sound matrix W \u2032 from equations (43) and (44). Note that Lemma 3 and Lemma 4 continue to apply in the partial observation case, but W in the case of Lemma is replaced by 1 pobs W. The entries of W \u2032 are in [\u2212 1, 1] and are therefore 1-sub-Gaussian, are i.e. on and above the diagonals, are zero-average and fulfill the oblique symmetry. As before, theorem 3.4 of Chatterjee [Cha14] then applies to the probability that we have the result of Lemma (= 1.1) and the result of 1-symmetry."}, {"heading": "5.5.3 Proof of part (c)", "text": "As proof for the fully observed case from Section 5.4.2, we consider the two-step estimator based on the first calculation of the mean square error associated with this estimator. Our observation model can be described in the following way: Let us consider an erdo-s-re-nyi graph on n vertices with each independently drawn edge with a probability of pobs. For each edge in this graph, we obtain an observation of the corner pair at the end points of that edge. Let us consider L as the (random) laplactic matrix of this graph. From Theorem 2 (b) from our work [SBB + 15] on the estimation of parametric models, we obtain an observation of the vertice at the end points of that edge."}, {"heading": "6 Discussion", "text": "In this paper, we analyzed a flexible model for pairwise comparative data, which includes various parametric models, including the BTL and Thurstone models, as special cases. We analyzed various estimates for this broader matrix family, ranging from optimal estimates to various polynomial time estimators, including forms of the singular value threshold, as well as multi-level methods based on a noisy sorting routine. All results in this paper focus on estimating the matrix of paired comparative probabilities in the Frobenius standard. Estimating probabilities in other metrics, such as the KL divergence or \"1 standard,\" may be desirable. We suspect that the results in these metrics will be useful. Determining the best possible rates for polynomial time algorithms across the full class CSST is problematic."}, {"heading": "A Proof of Proposition 1", "text": "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *-* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *"}, {"heading": "B Minimizing feedback arc set over entire SST class", "text": "Our analysis in Theorem 3 shows that the two-step estimator proposed in Section 3.3 works well below the stated limits for the input of M *, i.e. M * CHIGH (\u03b3) for a fixed \u03b3. This two-step estimator is based on the determination of a minimum feedback arc theorem (FAS) in the first step. In this section, we examine the effectiveness of estimators based on a minimum FAS across the entire CSST class. We show that the minimization of FAS is not good via CSST. The intuition is that although the minimization of the feedback arc theorem seems to minimize discrepancies at the global level, it only makes local decisions: If it is known that the i and j positions are in adjacent positions, the order between these two positions is decided solely on the result of the comparison between the i and j positions, and is independent of the result of the comparisons of i and j."}, {"heading": "C Relation to other models", "text": "We put things in perspective on the other models that are considered in literature. We start with two weaker versions of stochastic transitivity, which we have explored in literature on psychology and social science. (...) The other two popular (and weaker) models are the moderate stochastic transitivities, which we consider strong stochastic transitivity in literature on psychology and social science. (...) The two other popular (and weaker) models are those of moderate stochastic transitivity, which asCMST defines: = [0] n \"n\" mik \"n\" n \"n\" n \"n\" n \"n\" n \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. (\"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s."}], "references": [{"title": "Aggregating inconsistent information: ranking and clustering", "author": ["N. Ailon", "M. Charikar", "A. Newman"], "venue": "Journal of the ACM (JACM), 55(5):23", "citeRegEx": "ACN08", "shortCiteRegEx": null, "year": 2008}, {"title": "SIAM Journal on Discrete Mathematics", "author": ["N. Alon. Ranking tournaments"], "venue": "20(1):137\u2013142,", "citeRegEx": "Alo06", "shortCiteRegEx": null, "year": 2006}, {"title": "Spectra of graphs", "author": ["A.E. Brouwer", "W.H. Haemers"], "venue": "Springer", "citeRegEx": "BH11", "shortCiteRegEx": null, "year": 2011}, {"title": "Noisy sorting without resampling", "author": ["M. Braverman", "E. Mossel"], "venue": "Proc. ACMSIAM symposium on Discrete algorithms, pages 268\u2013276", "citeRegEx": "BM08", "shortCiteRegEx": null, "year": 2008}, {"title": "Rank analysis of incomplete block designs: I", "author": ["R.A. Bradley", "M.E. Terry"], "venue": "The method of paired comparisons. Biometrika, pages 324\u2013345", "citeRegEx": "BT52", "shortCiteRegEx": null, "year": 1952}, {"title": "Decisions", "author": ["T.P. Ballinger", "N.T. Wilcox"], "venue": "error and heterogeneity. The Economic Journal, 107(443):1090\u20131105", "citeRegEx": "BW97", "shortCiteRegEx": null, "year": 1997}, {"title": "Models for paired comparison data: A review with emphasis on dependent data", "author": ["M. Cattelan"], "venue": "Statistical Science, 27(3):412\u2013433", "citeRegEx": "Cat12", "shortCiteRegEx": null, "year": 2012}, {"title": "On matrix estimation under monotonicity constraints", "author": ["S. Chatterjee", "A. Guntuboyina", "B. Sen"], "venue": "arXiv:1506.03430", "citeRegEx": "CGS15", "shortCiteRegEx": null, "year": 2015}, {"title": "Matrix estimation by universal singular value thresholding", "author": ["S. Chatterjee"], "venue": "The Annals of Statistics, 43(1):177\u2013214", "citeRegEx": "Cha14", "shortCiteRegEx": null, "year": 2014}, {"title": "On the spectra of general random graphs", "author": ["F. Chung", "M. Radcliffe"], "venue": "The electronic journal of combinatorics, 18(1):P215", "citeRegEx": "CR11", "shortCiteRegEx": null, "year": 2011}, {"title": "A generalization of spectral analysis with application to ranked data", "author": ["P. Diaconis"], "venue": "The Annals of Statistics, 17(3):949\u2013979", "citeRegEx": "Dia89", "shortCiteRegEx": null, "year": 1989}, {"title": "A topic modeling approach to ranking", "author": ["W. Ding", "P. Ishwar", "V. Saligrama"], "venue": "Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics", "citeRegEx": "DIS15", "shortCiteRegEx": null, "year": 2015}, {"title": "Experimental tests of a stochastic decision theory", "author": ["D. Davidson", "J. Marschak"], "venue": "Measurement: Definitions and theories, pages 233\u201369", "citeRegEx": "DM59", "shortCiteRegEx": null, "year": 1959}, {"title": "Binary choice probabilities: on the varieties of stochastic transitivity", "author": ["P.C. Fishburn"], "venue": "Journal of Mathematical psychology, 10(4):327\u2013352", "citeRegEx": "Fis73", "shortCiteRegEx": null, "year": 1973}, {"title": "A nonparametric approach to modeling choice with limited data", "author": ["V.F. Farias", "S. Jagabathula", "D. Shah"], "venue": "Management Science, 59(2):305\u2013322", "citeRegEx": "FJS13", "shortCiteRegEx": null, "year": 2013}, {"title": "Probability models and statistical analyses for ranking data", "author": ["M.A. Fligner", "J.S. Verducci"], "venue": "volume 80. Springer", "citeRegEx": "FV93", "shortCiteRegEx": null, "year": 1993}, {"title": "Donoho", "author": ["M. Gavish", "D. L"], "venue": "The optimal hard threshold for singular values is 4/sqrt(3),", "citeRegEx": "GD13", "shortCiteRegEx": null, "year": 2013}, {"title": "A comparison of signalling alphabets", "author": ["E.N. Gilbert"], "venue": "Bell System Technical Journal, 31(3):504\u2013522", "citeRegEx": "Gil52", "shortCiteRegEx": null, "year": 1952}, {"title": "Entropy estimate for high-dimensional monotonic functions", "author": ["F. Gao", "J.A. Wellner"], "venue": "Journal of Multivariate Analysis, 98(9):1751\u20131764", "citeRegEx": "GW07", "shortCiteRegEx": null, "year": 2007}, {"title": "Minimax-optimal inference from partial rankings", "author": ["B. Hajek", "S. Oh", "J. Xu"], "venue": "Advances in Neural Information Processing Systems, pages 1475\u20131483", "citeRegEx": "HOX14", "shortCiteRegEx": null, "year": 2014}, {"title": "How to rank with few errors", "author": ["C. Kenyon-Mathieu", "W. Schudy"], "venue": "Symposium on Theory of computing (STOC), pages 95\u2013103. ACM", "citeRegEx": "KMS07", "shortCiteRegEx": null, "year": 2007}, {"title": "Algebraic connectivity of Erd\u00f6s-R\u00e9nyi graphs near the connectivity threshold", "author": ["T. Kolokolnikov", "B. Osting", "J. Von Brecht"], "venue": "Available online http://www.mathstat.dal.ca/ tkolokol/papers/braxton-james.pdf", "citeRegEx": "KOVB14", "shortCiteRegEx": null, "year": 2014}, {"title": "The Concentration of Measure Phenomenon", "author": ["M. Ledoux"], "venue": "Mathematical Surveys and Monographs. American Mathematical Society, Providence, RI", "citeRegEx": "Led01", "shortCiteRegEx": null, "year": 2001}, {"title": "Individual choice behavior: A theoretical analysis", "author": ["R.D. Luce"], "venue": "New York: Wiley", "citeRegEx": "Luc59", "shortCiteRegEx": null, "year": 1959}, {"title": "Analyzing and modeling rank data", "author": ["J.I. Marden"], "venue": "CRC Press", "citeRegEx": "Mar96", "shortCiteRegEx": null, "year": 1996}, {"title": "Stochastic transitivity and cancellation of preferences between bitter-sweet solutions", "author": ["D.H. McLaughlin", "R.D. Luce"], "venue": "Psychonomic Science, 2(1-12):89\u201390", "citeRegEx": "ML65", "shortCiteRegEx": null, "year": 1965}, {"title": "Iterative ranking from pair-wise comparisons", "author": ["S. Negahban", "S. Oh", "D. Shah"], "venue": "Advances in Neural Information Processing Systems, pages 2474\u20132482", "citeRegEx": "NOS12", "shortCiteRegEx": null, "year": 2012}, {"title": "Concentration of the adjacency matrix and of the Laplacian in random graphs with independent edges", "author": ["R.I. Oliveira"], "venue": "arXiv preprint:0911.0600", "citeRegEx": "Oli09", "shortCiteRegEx": null, "year": 2009}, {"title": "Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence", "author": ["N.B. Shah", "S. Balakrishnan", "J. Bradley", "A. Parekh", "K. Ramchandran", "M. Wainwright"], "venue": "Conference on Artificial Intelligence and Statistics, pages 856\u2013865", "citeRegEx": "SBB+15", "shortCiteRegEx": null, "year": 2015}, {"title": "Constrained statistical inference: Order", "author": ["M.J. Silvapulle", "P.K. Sen"], "venue": "inequality, and shape constraints, volume 912. John Wiley & Sons", "citeRegEx": "SS11", "shortCiteRegEx": null, "year": 2011}, {"title": "The behavior of eigenvalues and singular values under perturbations of restricted rank", "author": ["R. Thompson"], "venue": "Linear Algebra and its Applications, 13(1):69\u201378", "citeRegEx": "Tho76", "shortCiteRegEx": null, "year": 1976}, {"title": "A law of comparative judgment", "author": ["L.L. Thurstone"], "venue": "Psychological Review, 34(4):273", "citeRegEx": "Thu27", "shortCiteRegEx": null, "year": 1927}, {"title": "Elimination by aspects: A theory of choice", "author": ["A. Tversky"], "venue": "Psychological review, 79(4):281", "citeRegEx": "Tve72", "shortCiteRegEx": null, "year": 1972}, {"title": "Estimate of the number of signals in error correcting codes", "author": ["R. Varshamov"], "venue": "Dokl. Akad. Nauk SSSR", "citeRegEx": "Var57", "shortCiteRegEx": null, "year": 1957}], "referenceMentions": [{"referenceID": 31, "context": "The Bradley-Terry-Luce [BT52, Luc59] and Thurstone [Thu27] models are mainstays in analyzing this type of pairwise comparison data.", "startOffset": 51, "endOffset": 58}, {"referenceID": 13, "context": ", see Fishburn [Fis73] for an overview), where the only coherence assumption made on the pairwise comparison probabilities is that of strong stochastic transitivity, or SST for short.", "startOffset": 15, "endOffset": 22}, {"referenceID": 5, "context": "[BW97] is especially strongly worded:", "startOffset": 0, "endOffset": 6}, {"referenceID": 8, "context": "An estimator based on hard-thresholding was studied previously in this context by Chatterjee [Cha14].", "startOffset": 93, "endOffset": 100}, {"referenceID": 3, "context": "Our third contribution, formalized in Theorems 3 and 4, is to show that for certain interesting subsets of the full SST class, a combination of parametric maximum likelihood [SBB+15] and noisy sorting algorithms [BM08] leads to a tractable two-stage method that achieves the minimax rate.", "startOffset": 212, "endOffset": 218}, {"referenceID": 8, "context": "Our fourth contribution is to supplement our minimax lower bound with lower bounds for various known estimators, including those based on thresholding singular values [Cha14], noisy sorting [BM08], and parametric methods [NOS12, HOX14, SBB+15]) based on parametric models.", "startOffset": 167, "endOffset": 174}, {"referenceID": 3, "context": "Our fourth contribution is to supplement our minimax lower bound with lower bounds for various known estimators, including those based on thresholding singular values [Cha14], noisy sorting [BM08], and parametric methods [NOS12, HOX14, SBB+15]) based on parametric models.", "startOffset": 190, "endOffset": 196}, {"referenceID": 8, "context": "Chatterjee [Cha14] formally introduced the estimation problem considered in this paper, and analyzed an estimator based on singular value thresholding.", "startOffset": 11, "endOffset": 18}, {"referenceID": 3, "context": "Part of our analysis leverages an algorithm from the paper [BM08]; in particular, we extend their analysis in order to provide guarantees for estimating pairwise comparison probabilities as opposed to estimating the underlying order.", "startOffset": 59, "endOffset": 65}, {"referenceID": 29, "context": ", [SS11]), particularly to the problem of bi-variate isotonic regression.", "startOffset": 2, "endOffset": 8}, {"referenceID": 18, "context": "We use Dudley\u2019s entropy integral in order to derive an upper bound that is sharp up to a logarithmic factor; doing so in turn requires deriving upper bounds on the metric entropy of the class CSST for which we leverage the prior work of Gao and Wellner [GW07].", "startOffset": 253, "endOffset": 259}, {"referenceID": 8, "context": "For the full class CSST, Chatterjee [Cha14] analyzed the performance of such an estimator and proved that the squared Frobenius error decays as O(n\u2212 1 4 ) uniformly over CSST.", "startOffset": 36, "endOffset": 43}, {"referenceID": 8, "context": "To be clear, Chatterjee [Cha14] actually analyzed the hard-SVT estimator, which is based on the hard-thresholding operator", "startOffset": 24, "endOffset": 31}, {"referenceID": 3, "context": "In particular, we call upon a polynomial-time algorithm due to Braverman and Mossel [BM08] that, under the model (12), is guaranteed to find the exact solution to the FAS problem with high probability.", "startOffset": 84, "endOffset": 90}, {"referenceID": 3, "context": "We note that we do not have an analogue of the high-SNR result in the partial observations case since having partial observations reduces the SNR; the noisy-sorting algorithm of Braverman and Mossel [BM08] for the high-SNR case requires a computational complexity of e\u03b3 \u22124 and hence is not computable in time polynomial in n when \u03b3 < (log n)\u2212 1 4 , and this disallows most interesting scalings of pobs with n.", "startOffset": 199, "endOffset": 205}, {"referenceID": 3, "context": "In particular, it relies on the algorithm due to Braverman and Mossel [BM08] to compute the feedback arc set minimizer.", "startOffset": 70, "endOffset": 76}, {"referenceID": 3, "context": "\u2022 High SNR: A setting studied previously by Braverman and Mossel [BM08], in which the noise is independent of the items being compared.", "startOffset": 65, "endOffset": 71}, {"referenceID": 18, "context": "of Gao and Wellner [GW07].", "startOffset": 19, "endOffset": 25}, {"referenceID": 8, "context": "4 of Chatterjee [Cha14], which guarantees that", "startOffset": 16, "endOffset": 23}, {"referenceID": 8, "context": "Proof of Lemma 4 In this proof, we make use of a construction due to Chatterjee [Cha14].", "startOffset": 80, "endOffset": 87}, {"referenceID": 2, "context": "Consequently, from standard results in spectral graph theory [BH11], the eigenvalues of \u1ef8 are given by {4 sin2( n )} n\u22121 i=0 .", "startOffset": 61, "endOffset": 67}, {"referenceID": 30, "context": "Standard results in matrix perturbation theory [Tho76] guarantee that a rank-one perturbation can shift the position (in the large-to-small ordering) of any eigenvalue by at most one.", "startOffset": 47, "endOffset": 54}, {"referenceID": 3, "context": ") Braverman and Mossel [BM08] showed that for the class CHIGH(\u03b3), there exists a positive constant c\u2014depending on \u03b3 but independent of n\u2014such that", "startOffset": 23, "endOffset": 29}, {"referenceID": 8, "context": "4 of Chatterjee [Cha14] then implies that", "startOffset": 16, "endOffset": 23}], "year": 2017, "abstractText": "There are various parametric models for analyzing pairwise comparison data, including the Bradley-Terry-Luce (BTL) and Thurstone models, but their reliance on strong parametric assumptions is limiting. In this work, we study a flexible model for pairwise comparisons, under which the probabilities of outcomes are required only to satisfy a natural form of stochastic transitivity. This class includes several parametric models including the BTL and Thurstone models as special cases, but is considerably more general. We provide various examples of models in this broader stochastically transitive class for which classical parametric models provide poor fits. Despite this greater flexibility, we show that the matrix of probabilities can be estimated at the same rate as in standard parametric models. On the other hand, unlike in the BTL and Thurstone models, computing the least-squares estimate in the stochastically transitive model is non-trivial, and we explore various computationally tractable alternatives. We show that a simple singular value thresholding algorithm is statistically consistent but does not achieve the minimax rate. We then propose and study algorithms that achieve the minimax rate over interesting sub-classes of the full stochastically transitive class. We complement our theoretical results with thorough numerical simulations.", "creator": "LaTeX with hyperref package"}}}