{"id": "1510.07609", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Oct-2015", "title": "Efficient Learning by Directed Acyclic Graph For Resource Constrained Prediction", "abstract": "We study the problem of reducing test-time acquisition costs in classification systems. Our goal is to learn decision rules that adaptively select sensors for each example as necessary to make a confident prediction. We model our system as a directed acyclic graph (DAG) where internal nodes correspond to sensor subsets and decision functions at each node choose whether to acquire a new sensor or classify using the available measurements. This problem can be naturally posed as an empirical risk minimization over training data. Rather than jointly optimizing such a highly coupled and non-convex problem over all decision nodes, we propose an efficient algorithm motivated by dynamic programming. We learn node policies in the DAG by reducing the global objective to a series of cost sensitive learning problems. Our approach is computationally efficient and has proven guarantees of convergence to the optimal system for a fixed architecture. In addition, we present an extension to map other budgeted learning problems with large number of sensors to our DAG architecture and demonstrate empirical performance exceeding state-of-the-art algorithms for data composed of both few and many sensors.", "histories": [["v1", "Mon, 26 Oct 2015 19:40:10 GMT  (76kb,D)", "http://arxiv.org/abs/1510.07609v1", "To appear in NIPS 2015"]], "COMMENTS": "To appear in NIPS 2015", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["joseph wang", "kirill trapeznikov", "venkatesh saligrama"], "accepted": true, "id": "1510.07609"}, "pdf": {"name": "1510.07609.pdf", "metadata": {"source": "CRF", "title": "Efficient Learning by Directed Acyclic Graph For Resource Constrained Prediction", "authors": ["Joseph Wang", "Kirill Trapeznikov"], "emails": ["joewang@bu.edu", "kirill.trapeznikov@stresearch.com", "srv@bu.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "2 Adaptive Sensor Acquisition by DAG", "text": "In this section, we present our Adaptive Sensor Acquisition DAG, which decides sequentially during the test period which sensors should be acquired for each new example entered into the system. Before we formally describe the system and our learning approach, we first provide a simple illustration of a DAG with 3 sensors shown in Figure 1. Consider a new example entering the system. First, it has a state of [0, 0, 0] T (like all samples acquired during the test period), since no sensors have been acquired. It is accepted the political function that makes a decision to measure or stop and classify one of the three sensors. Suppose that the function perceive the example is assigned to the state [1, 0, 0, which indicates that the first sensor must be classified after this first one, or the second T is determined."}, {"heading": "2.1 Problem Formulation", "text": "We assume that the state includes all possible metrics. We assume that the state includes all possible metrics. We assume that the state includes all possible metrics. We assume that the state includes all possible metrics. We assume that the metrics of the individual metrics are different. We assume that the metrics of the individual metrics are different. We assume that the metrics of the individual metrics are different from the individual metrics of the individual metrics. We assume that the metrics of the individual metrics of the individual metrics are different. We assume that the metrics of the individual metrics of the individual metrics are different from each other. We assume that the metrics of the individual metrics of the individual metrics are different. We assume that the individual metrics of the individual metrics are different from each other."}, {"heading": "2.2 Learning Policies in a DAG", "text": "Learning the \u03c01,., \u03c0K functions that minimize the problem in (7) is a highly coupled problem. Learning a decision function \u03c0j depends on the other functions in two respects: (a) \u03c0j depends on functions at nodes downstream (nodes for which a path exists), as these determine the cost of each action performed by \u03c0j on a single example (the cost-to-go), and (b) \u03c0j depends on functions upstream at nodes (nodes for which a path exists), as these determine the distribution of examples acting on the basis of a policy. Consider a policy that corresponds to the state sj that all outgoing edges lead from j to page. Also, let us assume that all examples pass through this node (we ignore the effects of the upstream dependency b). This results in the following important problem: Lemma 2.1."}, {"heading": "2.3 Analysis", "text": "Our goal is to show that the expected risk of political functions \u03c01,., \u03c0K learned from Alg. 1 convergence to Bayes risk. We first give our main result: Theorem 2.2. Alg. 1 is universally consistent, that is, it is applied by Eq. 8.Alg. 1 emulates a dynamic program applied in an empirical setting. Political functions are decoupled and trained from the performance of the descending nodes. To optimize the empirical framework, we optimize at each stage over all examples in the training set. The key finding is the fact that universally consistent learners make optimal decisions about the data space that they are locally optimal. To illustrate this point, we consider a standard problem."}, {"heading": "2.4 Generalization to Other Budgeted Learning Problems", "text": "Although we have presented our algorithm in the context of a supervised classification and a uniform linear cost structure for sensor acquisition, the above framework considers a wide range of problems. In particular, any loss-based learning problem can be solved with the proposed DAG approach by generalizing the cost functionC (x, y, sj, sk) = {c (x, y, sj, sk) if sk 6 = sSC D (x, y, sj) otherwise, (10) where c (x, y, sj, sk) is the cost of purchasing sensors in sk\\ sj, e.g. (x, y) given the current state sj and D (x, y, sj) a certain loss associated with the application of sensor subsets sj on example (x, y). This framework allows for much more complex budget-targeted learning problems to be addressed in sk\\ sj."}, {"heading": "3 Adaptive Sensor Acquisition in High-Dimensions", "text": "So far, we look at the case where the DAG system acquires a full set of sensors instead of using them. \"However, this is often not mathematically feasible, since the number of nodes in the diagram increases exponentially with the number of sensors. In practice, these complete systems are feasible only for data generated from a small set of sensors (10 or less). [6, 24, 11] We assume that the number of\" active \"nodes in the exhaustive diagram is small, that is, these nodes are either not visited by examples or by all examples visiting the node acquiring the same next sensor. Equivalently, this can be considered the system that requires only a small number of sensors to classify all examples at low cost."}, {"heading": "4 Experimental Results", "text": "In order to demonstrate the performance of our DAG sensor acquisition system, we provide experimental results on data sets previously used in budgeted learning. We test three data sets previously used for budget cascades [19, 22]. In these data sets, examples are composed of a small number of sensors (less than 4 sensors). To accurately compare performance, we apply the LP approach to learning sensor trees [20] and construct trees that contain all subsets of sensors, as opposed to the previously used fixed-order cascades [19, 22]. Next, we investigate the performance of the DAG system using three higher-dimensional data sets previously used to compare budgeted learning performance [11]. In these cases, the dimensionality of the data (between 50 and 400 characteristics) makes an exhaustive subset of construction computationally impossible."}, {"heading": "4.1 Small Sensor Set Experiments", "text": "We compare the performance of our trained DAG with that of a complete tree trained using an LP replacement tree [20] on the Landsat, Pima and Letter datasets. To construct each sensor DAG, we include all subsets of sensors (including the blank set) and connect any two nodes that differ by a single sensor, with the edge of the smaller sensor subset pointing to the larger sensor subset. By including the blank set, no initial sensor needs to be selected. 3rd order homogeneous polynomes are used for both classification and system functions in the LP and DAG. As can be seen in Figure 3, the systems learned with a DAG exceed the LP tree systems. Furthermore, the performance of both systems is significantly better than the performance previously determined on these datasets for budget cascades [19, 22] resulting from both the higher complexity of the DAG's learning and decision-making functionality in the DAG's comparison with the tree structure."}, {"heading": "4.2 Large Sensor Set Experiments", "text": "Next, we compare the performance of our trained DAG with that of CSTC [24] and ASTC [11] for the MiniBooNE, Forest and CIFAR datasets. We use the validation data to find the homogeneous polynomial that delivers the best classification performance using all characteristics (MiniBooNE: linear, Forest: 2nd order, CIFAR: 3rd order). These polynomial functions are then used for all classification and policy functions. For each dataset, 7 subsets were found, with an 8th subset of all characteristics added. A comprehensive DAG was trained across all unions of these 8 subgroups. Figure 4 shows a performance that compares the average costs to average errors of CSTC, ASTC and our DAG system. Systems learned with a DAG outperform both CSTC and ASTC for MiniBooNE and Forest datasets, with comparable performance with low budgets and superior budgets."}], "references": [{"title": "Convexity, Classification, and Risk Bounds", "author": ["P. Bartlett", "M. Jordan", "J. Mcauliffe"], "venue": "Journal of American Statistical Association,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Multiclass classification with filter trees", "author": ["A. Beygelzimer", "J. Langford", "P. Ravikumar"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "Fast classification using sparse decision dags", "author": ["R. Busa-Fekete", "D. Benbouzid", "B. K\u00e9gl"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2012}, {"title": "Classifier cascade: Tradeoff between accuracy and feature evaluation cost", "author": ["M. Chen", "Z. Xu", "K. Weinberger", "O. Chapelle", "D. Kedem"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2012}, {"title": "Datum-wise classification: a sequential approach to sparsity", "author": ["G. Dulac-Arnold", "L. Denoyer", "P. Preux", "P. Gallinari"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2011}, {"title": "Active classification based on value of classifier", "author": ["T. Gao", "D. Koller"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Imitation learning by coaching", "author": ["H. He", "H. Daume III", "J. Eisner"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "Cost-sensitive feature acquisition and classification", "author": ["S. Ji", "L. Carin"], "venue": "Pattern Recognition,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Prediction-time active feature-value acquisition for cost-effective customer targeting", "author": ["P. Kanani", "P. Melville"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Dynamic feature selection for classification on a budget", "author": ["S. Karayev", "M. Fritz", "T. Darrell"], "venue": "In International Conference on Machine Learning: Workshop on Prediction with Sequential Models,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Feature-cost sensitive learning with submodular trees of classifiers", "author": ["M. Kusner", "W. Chen", "Q. Zhou", "Z. Xu", "K. Weinberger", "Y. Chen"], "venue": "In Twenty-Eighth AAAI Conference on Artificial Intelligence,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Cost-effective outbreak detection in networks", "author": ["J. Leskovec", "A. Krause", "C. Guestrin", "C. Faloutsos", "J. VanBriesen", "N. Glance"], "venue": "In International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Learning with marginalized corrupted features", "author": ["L. Maaten", "M. Chen", "S. Tyree", "K.Q. Weinberger"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Feature-budgeted random forest", "author": ["F. Nan", "J. Wang", "V. Saligrama"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Fast margin-based cost-sensitive classification", "author": ["F. Nan", "J. Wang", "K. Trapeznikov", "V. Saligrama"], "venue": "In International Conference on Acoustics, Speech and Signal Processing,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "An analysis of approximations for maximizing submodular set functionsi", "author": ["G. Nemhauser", "L. Wolsey", "M. Fisher"], "venue": "Mathematical Programming,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1978}, {"title": "Feature value acquisition in testing: A sequential batch test algorithm", "author": ["V.S. Sheng", "C.X. Ling"], "venue": "In Proceedings of the 23rd International Conference on Machine Learning,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2006}, {"title": "Consistency of support vector machines and other regularized kernel classifiers", "author": ["I. Steinwart"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2005}, {"title": "Supervised sequential classification under budget constraints", "author": ["K. Trapeznikov", "V. Saligrama"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}, {"title": "Model selection by linear programming", "author": ["J. Wang", "T.K. Bolukbasi", "Trapeznikov", "V. Saligrama"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Local supervised learning through space partitioning", "author": ["J. Wang", "J. Saligrama"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "An lp for sequential learning under budgets", "author": ["J. Wang", "K. Trapeznikov", "V. Saligrama"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2014}, {"title": "The greedy miser: Learning under test-time budgets", "author": ["Z. Xu", "O. Chapelle", "K. Weinberger"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2012}, {"title": "Cost-sensitive tree of classifiers", "author": ["Z. Xu", "M. Kusner", "M. Chen", "K. Weinberger"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "A Survey of Recent Advances in Face Detection", "author": ["C. Zhang", "Z. Zhang"], "venue": "Technical report, Microsoft Research,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2010}], "referenceMentions": [{"referenceID": 22, "context": "In contrast, non-adaptive methods [23] attempt to identify a common sparse subset of sensors that can work well for all data.", "startOffset": 34, "endOffset": 38}, {"referenceID": 18, "context": "First, we consider the case where the number of sensors available is small (as in [19, 22, 20]), though the dimensionality of data acquired by each sensor may be large (such as an image taken in different modalities).", "startOffset": 82, "endOffset": 94}, {"referenceID": 21, "context": "First, we consider the case where the number of sensors available is small (as in [19, 22, 20]), though the dimensionality of data acquired by each sensor may be large (such as an image taken in different modalities).", "startOffset": 82, "endOffset": 94}, {"referenceID": 19, "context": "First, we consider the case where the number of sensors available is small (as in [19, 22, 20]), though the dimensionality of data acquired by each sensor may be large (such as an image taken in different modalities).", "startOffset": 82, "endOffset": 94}, {"referenceID": 1, "context": "Cost-sensitive learning (CSL) generalizes multi-decision learning by allowing decision costs to be data dependent [2].", "startOffset": 114, "endOffset": 117}, {"referenceID": 23, "context": "Next, we extend our formulation to the case where a large number of sensors exist, but the number of distinct sensor subsets that are necessary for classification is small (as in [24, 11] where the depth of the trees is fixed to 5).", "startOffset": 179, "endOffset": 187}, {"referenceID": 10, "context": "Next, we extend our formulation to the case where a large number of sensors exist, but the number of distinct sensor subsets that are necessary for classification is small (as in [24, 11] where the depth of the trees is fixed to 5).", "startOffset": 179, "endOffset": 187}, {"referenceID": 24, "context": "It arguably originated with detection cascades (see [25, 4] and references therein), a popular method in reducing computation cost in object detection for cases with highly skewed class imbalance and generic features.", "startOffset": 52, "endOffset": 59}, {"referenceID": 3, "context": "It arguably originated with detection cascades (see [25, 4] and references therein), a popular method in reducing computation cost in object detection for cases with highly skewed class imbalance and generic features.", "startOffset": 52, "endOffset": 59}, {"referenceID": 18, "context": "[19] and Wang et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22, 20].", "startOffset": 0, "endOffset": 8}, {"referenceID": 19, "context": "[22, 20].", "startOffset": 0, "endOffset": 8}, {"referenceID": 18, "context": "[19] propose a similar training scheme for the case of cascades, however restrict their training to cascades and simple decision functions which require alternating optimization to learn.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21, 22, 20] attempt to jointly solve the decision learning problem by formulating a linear upper-bounding surrogate, converting the problem into a linear program (LP).", "startOffset": 0, "endOffset": 12}, {"referenceID": 21, "context": "[21, 22, 20] attempt to jointly solve the decision learning problem by formulating a linear upper-bounding surrogate, converting the problem into a linear program (LP).", "startOffset": 0, "endOffset": 12}, {"referenceID": 19, "context": "[21, 22, 20] attempt to jointly solve the decision learning problem by formulating a linear upper-bounding surrogate, converting the problem into a linear program (LP).", "startOffset": 0, "endOffset": 12}, {"referenceID": 23, "context": "[24] and Kusner et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11], who introduce Cost-Sensitive Trees of Classifiers (CSTC) and Approximately Submodular Trees of Classifiers (ASTC), respectively, to reducing test time costs.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] propose Approximately Submodular Trees of Classifiers (ASTC), a variation of CSTC which provides robust performance with significantly reduced training time and greedy approximation, respectively.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] proposed random forests to efficiently learn budgeted systems using greedy approximation over large data sets.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "Generative methods [17, 8, 9, 6] pose the problem as a POMDP, learn conditional probability models, and myopically select features based information gain of unknown features.", "startOffset": 19, "endOffset": 32}, {"referenceID": 7, "context": "Generative methods [17, 8, 9, 6] pose the problem as a POMDP, learn conditional probability models, and myopically select features based information gain of unknown features.", "startOffset": 19, "endOffset": 32}, {"referenceID": 8, "context": "Generative methods [17, 8, 9, 6] pose the problem as a POMDP, learn conditional probability models, and myopically select features based information gain of unknown features.", "startOffset": 19, "endOffset": 32}, {"referenceID": 5, "context": "Generative methods [17, 8, 9, 6] pose the problem as a POMDP, learn conditional probability models, and myopically select features based information gain of unknown features.", "startOffset": 19, "endOffset": 32}, {"referenceID": 4, "context": "MDPbased methods [5, 10, 7, 3] encode current observations as state, unused features as action space, and formulate various reward functions to account for classification error and costs.", "startOffset": 17, "endOffset": 30}, {"referenceID": 9, "context": "MDPbased methods [5, 10, 7, 3] encode current observations as state, unused features as action space, and formulate various reward functions to account for classification error and costs.", "startOffset": 17, "endOffset": 30}, {"referenceID": 6, "context": "MDPbased methods [5, 10, 7, 3] encode current observations as state, unused features as action space, and formulate various reward functions to account for classification error and costs.", "startOffset": 17, "endOffset": 30}, {"referenceID": 2, "context": "MDPbased methods [5, 10, 7, 3] encode current observations as state, unused features as action space, and formulate various reward functions to account for classification error and costs.", "startOffset": 17, "endOffset": 30}, {"referenceID": 6, "context": "[7] apply imitation learning of a greedy policy with a single classification step as actions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] and Karayev et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] apply reinforcement learning to solve this MDP.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[3] propose classifier cascades with an additional skip action within an MDP framework.", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "[15] consider a nearest neighbor approach to feature selection, with classification confidence driven by the classification margin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "Let us assume that the function \u03c00 routes the example to the state [1, 0, 0] , indicating that the first sensor is acquired.", "startOffset": 67, "endOffset": 76}, {"referenceID": 12, "context": "sensor) capable classification system as in [13].", "startOffset": 44, "endOffset": 48}, {"referenceID": 1, "context": "We solve the CSL problem by using a filter-tree scheme [2] for Learn, which constructs a tree of binary classifiers.", "startOffset": 55, "endOffset": 58}, {"referenceID": 1, "context": "[2], where an instance of the problem is defined by a distribution D over X \u00d7 [0, inf), a space of features and associated costs for predicting each of the k labels for each realization of features.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "This can be achieved by training universally consistent CSL algorithms such as filter trees [2] that reduce the problem to binary classification.", "startOffset": 92, "endOffset": 95}, {"referenceID": 0, "context": "By learning consistent binary classifiers [1, 18], the risk of the cost-sensitive function can be shown to converge to the Bayes risk [2].", "startOffset": 42, "endOffset": 49}, {"referenceID": 17, "context": "By learning consistent binary classifiers [1, 18], the risk of the cost-sensitive function can be shown to converge to the Bayes risk [2].", "startOffset": 42, "endOffset": 49}, {"referenceID": 1, "context": "By learning consistent binary classifiers [1, 18], the risk of the cost-sensitive function can be shown to converge to the Bayes risk [2].", "startOffset": 134, "endOffset": 137}, {"referenceID": 23, "context": "In contrast, nearly all previous approaches require solving a non-convex problem and resort to alternating optimization [24, 19] or greedy approximation [11].", "startOffset": 120, "endOffset": 128}, {"referenceID": 18, "context": "In contrast, nearly all previous approaches require solving a non-convex problem and resort to alternating optimization [24, 19] or greedy approximation [11].", "startOffset": 120, "endOffset": 128}, {"referenceID": 10, "context": "In contrast, nearly all previous approaches require solving a non-convex problem and resort to alternating optimization [24, 19] or greedy approximation [11].", "startOffset": 153, "endOffset": 157}, {"referenceID": 21, "context": "Alternatively, convex surrogates proposed for the global problem [22, 20] require solving large convex programs with \u03b8(n) variables, even for simple linear decision functions.", "startOffset": 65, "endOffset": 73}, {"referenceID": 19, "context": "Alternatively, convex surrogates proposed for the global problem [22, 20] require solving large convex programs with \u03b8(n) variables, even for simple linear decision functions.", "startOffset": 65, "endOffset": 73}, {"referenceID": 5, "context": "Motivated by previous methods [6, 24, 11], we assume that the number of \u201cactive\u201d nodes in the exhaustive graph is small, that is these nodes are either not visited by any examples or all examples that visit the node acquire the same next sensor.", "startOffset": 30, "endOffset": 41}, {"referenceID": 23, "context": "Motivated by previous methods [6, 24, 11], we assume that the number of \u201cactive\u201d nodes in the exhaustive graph is small, that is these nodes are either not visited by any examples or all examples that visit the node acquire the same next sensor.", "startOffset": 30, "endOffset": 41}, {"referenceID": 10, "context": "Motivated by previous methods [6, 24, 11], we assume that the number of \u201cactive\u201d nodes in the exhaustive graph is small, that is these nodes are either not visited by any examples or all examples that visit the node acquire the same next sensor.", "startOffset": 30, "endOffset": 41}, {"referenceID": 15, "context": "Applying a greedy strategy therefore yields a 1\u2212 1e approximation of the optimal strategy [16].", "startOffset": 90, "endOffset": 94}, {"referenceID": 11, "context": "Additionally, this result can be extended to the case of non-uniform costs, where a simple extension of the greedy algorithm yields a constant-order approximation [12].", "startOffset": 163, "endOffset": 167}, {"referenceID": 18, "context": "Three data sets previously used for budget cascades [19, 22] are tested.", "startOffset": 52, "endOffset": 60}, {"referenceID": 21, "context": "Three data sets previously used for budget cascades [19, 22] are tested.", "startOffset": 52, "endOffset": 60}, {"referenceID": 19, "context": "To accurately compare performance, we apply the LP approach to learning sensor trees [20] and construct trees containing all subsets of sensors as opposed to the fixed order cascades previously applied [19, 22].", "startOffset": 85, "endOffset": 89}, {"referenceID": 18, "context": "To accurately compare performance, we apply the LP approach to learning sensor trees [20] and construct trees containing all subsets of sensors as opposed to the fixed order cascades previously applied [19, 22].", "startOffset": 202, "endOffset": 210}, {"referenceID": 21, "context": "To accurately compare performance, we apply the LP approach to learning sensor trees [20] and construct trees containing all subsets of sensors as opposed to the fixed order cascades previously applied [19, 22].", "startOffset": 202, "endOffset": 210}, {"referenceID": 10, "context": "Next, we examine performance of the DAG system using 3 higher dimensional sets of data previously used to compare budgeted learning performance [11].", "startOffset": 144, "endOffset": 148}, {"referenceID": 23, "context": "We compare performance with CSTC [24] and ASTC [11].", "startOffset": 33, "endOffset": 37}, {"referenceID": 10, "context": "We compare performance with CSTC [24] and ASTC [11].", "startOffset": 47, "endOffset": 51}, {"referenceID": 1, "context": "For all experiments, we use cost sensitive filter trees [2], where each binary classifier in the tree is learned using logistic regression.", "startOffset": 56, "endOffset": 59}, {"referenceID": 19, "context": "We compare performance of our trained DAG with that of a complete tree trained using an LP surrogate [20] on the landsat, pima, and letter datasets.", "startOffset": 101, "endOffset": 105}, {"referenceID": 18, "context": "Additionally, the performance of both of the systems is significantly better than previously reported performance on these data sets for budget cascades [19, 22].", "startOffset": 153, "endOffset": 161}, {"referenceID": 21, "context": "Additionally, the performance of both of the systems is significantly better than previously reported performance on these data sets for budget cascades [19, 22].", "startOffset": 153, "endOffset": 161}, {"referenceID": 23, "context": "Next, we compare performance of our trained DAG with that of CSTC [24] and ASTC [11] for the MiniBooNE, Forest, and CIFAR datasets.", "startOffset": 66, "endOffset": 70}, {"referenceID": 10, "context": "Next, we compare performance of our trained DAG with that of CSTC [24] and ASTC [11] for the MiniBooNE, Forest, and CIFAR datasets.", "startOffset": 80, "endOffset": 84}], "year": 2015, "abstractText": "We study the problem of reducing test-time acquisition costs in classification systems. Our goal is to learn decision rules that adaptively select sensors for each example as necessary to make a confident prediction. We model our system as a directed acyclic graph (DAG) where internal nodes correspond to sensor subsets and decision functions at each node choose whether to acquire a new sensor or classify using the available measurements. This problem can be naturally posed as an empirical risk minimization over training data. Rather than jointly optimizing such a highly coupled and non-convex problem over all decision nodes, we propose an efficient algorithm motivated by dynamic programming. We learn node policies in the DAG by reducing the global objective to a series of cost sensitive learning problems. Our approach is computationally efficient and has proven guarantees of convergence to the optimal system for a fixed architecture. In addition, we present an extension to map other budgeted learning problems with large number of sensors to our DAG architecture and demonstrate empirical performance exceeding state-of-the-art algorithms for data composed of both few and many sensors.", "creator": "LaTeX with hyperref package"}}}