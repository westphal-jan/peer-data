{"id": "1510.08692", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Oct-2015", "title": "Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling", "abstract": "Monte Carlo sampling for Bayesian posterior inference is a common approach used in machine learning. The Markov Chain Monte Carlo procedures that are used are often discrete-time analogues of associated stochastic differential equations (SDEs). These SDEs are guaranteed to leave invariant the required posterior distribution. An area of current research addresses the computational benefits of stochastic gradient methods in this setting. Existing techniques rely on estimating the variance or covariance of the subsampling error, and typically assume constant variance. In this article, we propose a covariance-controlled adaptive Langevin thermostat that can effectively dissipate parameter-dependent noise while maintaining a desired target distribution. The proposed method achieves a substantial speedup over popular alternative schemes for large-scale machine learning applications.", "histories": [["v1", "Thu, 29 Oct 2015 13:57:11 GMT  (64kb)", "http://arxiv.org/abs/1510.08692v1", "Advances in Neural Information Processing Systems (NIPS), 2015"]], "COMMENTS": "Advances in Neural Information Processing Systems (NIPS), 2015", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["xiaocheng shang", "zhanxing zhu", "benedict j leimkuhler", "amos j storkey"], "accepted": true, "id": "1510.08692"}, "pdf": {"name": "1510.08692.pdf", "metadata": {"source": "CRF", "title": "Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling", "authors": ["Xiaocheng Shang", "Zhanxing Zhu", "Benedict Leimkuhler", "Amos J. Storkey"], "emails": ["(x.shang@ed.ac.uk).", "b.leimkuhler@ed.ac.uk", "(zhanxing.zhu@ed.ac.uk).", "a.storkey@ed.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 151 0.08 692v 1 [stat.ML] 2 9"}, {"heading": "1 Introduction", "text": "For example, the Standard Markov Chain Monte Carlo (MCMC) Methods [16], as well as typical Hybrid Monte Carlo (HMC) Methods [3, 6, 9], which calculate the likelihood of acceptance and create informational suggestions based on the whole dataset. To improve computing efficiency, a number of stochastic gradient methods [4, 5, 21] can be proposed in the setting of Bayesian sampling methods based on random (and much smaller) subsets that approximate the probability of total dataset distribution, thus significantly reducing the cost of computational distribution in practice. Welling and Teh proposed the so-called School of Mathematics and Maxwell Institute for Mathematical Sciences, University of Edinburgh, EH9 3FD, UK (x.shang @ ed.ac.com)."}, {"heading": "2 Bayesian Sampling with Noisy Gradients", "text": "In the typical setting of Bayesian sampling [3, 19] one is interested in drawing states from a posterior distribution, which is defined as such. (However, the whole dataset, and \u03c0 (X) and \u03c0 (\u03b8) are the probability and previous distribution, respectively. We introduce a potential energy function U by defining the whole dataset (\u2212 \u03b2U), where \u03b2 is a positive parameter and can be interpreted as proportional to the reciprocal temperature in an associated physical system, i.e. \u03b2 \u2212 kBT (kB is the Boltzmann constant and T is temperature). In practice, the unit is considered to be notational simplicity."}, {"heading": "3 Covariance-Controlled Adaptive Langevin Thermostat", "text": "As mentioned in the previous section, the SGNHT method (8) can only reduce noise with constant covariance matrix (1). If the covariance matrix becomes a parameter-dependent covariance matrix (2), the system cannot be expected to approach the desired invariant distribution (10), which typically leads to a poor estimate of the functions of interest parameters. In this case, however, it is not clear whether there is an invariant distribution in all.In order to construct a stochastic dynamic distribution that preserves the canonical distribution, we propose to use a suitable damping method for effective dissipation of parameter-dependent noise. To this end, we propose the following covariance matrix-controlled distribution (CCAdaptive)."}, {"heading": "3.1 Covariance Estimation of Noisy Gradients", "text": "Assuming that the noise of the stochastic gradient follows a normal distribution, we apply a similar method (= 2) to estimate the covariance matrix associated with the noisy gradient. If we apply g (\u03b8; x) = equilified log \u03c0 (x) and assume that the size of the subset n is large enough to hold the central boundary theorem, we have the covariance of the gradients at the gradient. Since the noisy (stochastic) gradient is on the current subset of U (\u03b8t; x)]], (16) where it is = Cov [g; x), the covariance of the gradient is at the top of L. Given the fact that the noisy (stochastic) gradient is on the current subset of U (\u03b8t; x) = \u2212 Nn."}, {"heading": "4 Numerical Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Bayesian Inference for Gaussian Distribution", "text": "We first compare the performance of the newly established CCAdL method with SGHMC and SGNHT = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 2 = 1 = 2 = 1 = 1 = 2 = 1 = 1 = 1 = 1 = 0 = 100 samples from the normal standard distribution N (0, 1). We then used the probability function of N (xi | 2 = 1 = 1 = 1 = 2 = 1 = 2 = 2 = 2 = 1 = 1 = 2 = 1 = 1 = 1 = 1 = 0 = 100 samples from the standard distribution N (0, 1). We then used the corresponding background distribution of N (xi | \u00b5, \u03b3 \u2212 1) and ordered the normal gamma distribution as its previous distribution, i.e., we determined N = 100 samples from the standard distribution N (0, 1).Then the corresponding background distribution performed another normal gamma distribution, i.e. (\u00b5, \u03b3 | \u00b5N) a better distribution of the CCCCCCN values \u2212 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 3 = 3 = 3 = 2 = 1 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 2 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 = 5 ="}, {"heading": "4.2 Large-scale Bayesian Logistic Regression", "text": "We then consider a Bayesian logistical regression model based on the benchmark MNIST dataset for the binary classification of digits 7 and 9 with 12, 214 training points and a test set of size 2037. A 100-dimensional random projection of the original characteristics was used. We used the probability function \u03c0 ({xi, yi} Ni = 1 | w). A subset of size n = 500 was used for each time step. As the dimensionality of this problem is not so high, a full covariance estimate for CCAdL was used. We examine the convergence rate of each method by measuring the test log probability of the target values and the target values, comparing the target number of the target number of the target number with the number of passes over the entire dataset."}, {"heading": "4.3 Discriminative Restricted Boltzmann Machine (DRBM)", "text": "DRBM [11] is a self-contained nonlinear classifier, and the gradient of its discriminatory goal can be calculated explicitly. Due to the limited space, we refer readers to [11] for more details. We trained a DRBM on various large-format multi-class data sets from the LIBSVM data collection, including connect-4, letter and SensIT Vehicle acoustic. Detailed information of these data sets is presented in Table 2. http: / / www.csie.ntu.edu.tw / ~ cjlin / libsvmtools / datasets / multiclass.htmlWe chose the number of hidden units using cross-validation to get their best results. Since the dimension of the parameters, Nd, is relatively high, we used only diagonal co-variance matrices / datasets / datasets / multiclass.htmlWe chose the number of hidden units using cross-dimming results to get their best results."}, {"heading": "5 Conclusions and Future Work", "text": "In this article, we have proposed a novel covariance-controlled adaptive Langevin formula (CCAdL) that can effectively derive parameter-dependent noise while maintaining a desirable invariant distribution. CCAdL combines ideas from SGHMC and SGNHT from literature, but achieves significant improvements over any of these methods in practice. The additional error introduced by the covariance estimate is likely to be relatively small, i.e. substantially smaller than the error resulting from the loud gradient. Our results have been verified in large-scale machine learning applications. In particular, we have consistently observed that SGHMC relies on a small step h and large friction A, which significantly reduces its usefulness in practice as discussed. The techniques presented in this article could be useful in the more general environment of large-scale application of the properties of Langesian sampling and optimization that we leave for future work."}, {"heading": "Acknowledgements", "text": "XS and ZZ would like to thank the University of Edinburgh and China Scholarship Council for their financial support."}], "references": [{"title": "Long time accuracy of Lie-Trotter splitting methods for Langevin dynamics", "author": ["A. Abdulle", "G. Vilmart", "K.C. Zygalakis"], "venue": "SIAM Journal on Numerical Analysis,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Bayesian posterior sampling via stochastic gradient Fisher scoring", "author": ["S. Ahn", "A. Korattikara", "M. Welling"], "venue": "In Proceedings of the 29th International Conference on Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2012}, {"title": "Handbook of Markov Chain Monte Carlo", "author": ["S. Brooks", "A. Gelman", "G. Jones", "X.-L. Meng"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2011}, {"title": "Stochastic gradient Hamiltonian Monte Carlo", "author": ["T. Chen", "E.B. Fox", "C. Guestrin"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Bayesian sampling using stochastic gradient thermostats", "author": ["N. Ding", "Y. Fang", "R. Babbush", "C. Chen", "R.D. Skeel", "H. Neven"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Hybrid Monte Carlo", "author": ["S. Duane", "A.D. Kennedy", "B.J. Pendleton", "D. Roweth"], "venue": "Physics Letters B,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1987}, {"title": "Understanding Molecular Simulation: From Algorithms to Applications, Second Edition", "author": ["D. Frenkel", "B. Smit"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2001}, {"title": "Computational Statistical Mechanics, Studies in Modern Thermodynamics", "author": ["W.G. Hoover"], "venue": "Elsevier Science,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1991}, {"title": "A generalized guided Monte Carlo algorithm", "author": ["A.M. Horowitz"], "venue": "Physics Letters B,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1991}, {"title": "Adaptive stochastic methods for sampling driven molecular systems", "author": ["A. Jones", "B. Leimkuhler"], "venue": "The Journal of Chemical Physics,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Classification using discriminative restricted Boltzmann machines", "author": ["H. Larochelle", "Y. Bengio"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2008}, {"title": "Rational construction of stochastic numerical methods for molecular sampling", "author": ["B. Leimkuhler", "C. Matthews"], "venue": "Applied Mathematics Research eXpress,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Molecular Dynamics: With Deterministic and Stochastic Numerical Methods", "author": ["B. Leimkuhler", "C. Matthews"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "The computation of averages from equilibrium and nonequilibrium Langevin molecular dynamics", "author": ["B. Leimkuhler", "C. Matthews", "G. Stoltz"], "venue": "IMA Journal of Numerical Analysis,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Adaptive thermostats for noisy gradient systems", "author": ["B. Leimkuhler", "X. Shang"], "venue": "arXiv preprint arXiv:1505.06889,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Equation of state calculations by fast computing machines", "author": ["N. Metropolis", "A.W. Rosenbluth", "M.N. Rosenbluth", "A.H. Teller", "E. Teller"], "venue": "The Journal of Chemical Physics,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1953}, {"title": "A unified formulation of the constant temperature molecular dynamics methods", "author": ["S. Nos\u00e9"], "venue": "The Journal of Chemical Physics,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1984}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1951}, {"title": "Monte Carlo Statistical Methods, Second Edition", "author": ["C. Robert", "G. Casella"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "Non-) asymptotic properties of stochastic gradient Langevin dynamics", "author": ["S.J. Vollmer", "K.C. Zygalakis", "Y.W. Teh"], "venue": "arXiv preprint arXiv:1501.00438,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["M. Welling", "Y.W. Teh"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}], "referenceMentions": [{"referenceID": 15, "context": "For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.", "startOffset": 63, "endOffset": 67}, {"referenceID": 2, "context": "For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.", "startOffset": 121, "endOffset": 130}, {"referenceID": 5, "context": "For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.", "startOffset": 121, "endOffset": 130}, {"referenceID": 8, "context": "For instance, standard Markov Chain Monte Carlo (MCMC) methods [16], as well as typical Hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance probability and the creation of informed proposals based on the whole dataset.", "startOffset": 121, "endOffset": 130}, {"referenceID": 3, "context": "In order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice.", "startOffset": 86, "endOffset": 100}, {"referenceID": 4, "context": "In order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice.", "startOffset": 86, "endOffset": 100}, {"referenceID": 19, "context": "In order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice.", "startOffset": 86, "endOffset": 100}, {"referenceID": 20, "context": "In order to improve computational efficiency, a number of stochastic gradient methods [4, 5, 20, 21] have been proposed in the setting of Bayesian sampling based on random (and much smaller) subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice.", "startOffset": 86, "endOffset": 100}, {"referenceID": 20, "context": "Stochastic Gradient Langevin Dynamics (SGLD) [21], combining the ideas of stochastic optimization [18] and traditional Brownian dynamics, with a sequence of stepsizes decreasing to zero.", "startOffset": 45, "endOffset": 49}, {"referenceID": 17, "context": "Stochastic Gradient Langevin Dynamics (SGLD) [21], combining the ideas of stochastic optimization [18] and traditional Brownian dynamics, with a sequence of stepsizes decreasing to zero.", "startOffset": 98, "endOffset": 102}, {"referenceID": 19, "context": "[20], where a modified SGLD (mSGLD) was also introduced that was designed to reduce sampling bias.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "SGLD generates samples from first order Brownian dynamics, and thus, with a fixed timestep, one can show that it is unable to dissipate excess noise in gradient approximations while maintaining the desired invariant distribution [4].", "startOffset": 229, "endOffset": 232}, {"referenceID": 3, "context": "[4], which relies on second order Langevin dynamics and incorporates a parameter-dependent diffusion matrix that is intended to effectively offset the stochastic perturbation of the gradient.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "Moreover, as pointed out in [5] poor estimation of it may have a significant adverse influence on the sampling of the target distribution; for example the effective system temperature may be altered.", "startOffset": 28, "endOffset": 31}, {"referenceID": 6, "context": "The \u201cthermostat\u201d idea, which is widely used in molecular dynamics [7, 13], was recently adopted in the Stochastic Gradient Nos\u00e9-Hoover Thermostat (SGNHT) by Ding et al.", "startOffset": 66, "endOffset": 73}, {"referenceID": 12, "context": "The \u201cthermostat\u201d idea, which is widely used in molecular dynamics [7, 13], was recently adopted in the Stochastic Gradient Nos\u00e9-Hoover Thermostat (SGNHT) by Ding et al.", "startOffset": 66, "endOffset": 73}, {"referenceID": 4, "context": "[5] in order to adjust the kinetic energy during simulation in such a way that the canonical ensemble is preserved (i.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "In fact, the SGNHT method is essentially equivalent to the Adaptive Langevin (Ad-Langevin) thermostat proposed earlier by Jones and Leimkuhler [10] in the molecular dynamics setting (see [15] for discussion).", "startOffset": 143, "endOffset": 147}, {"referenceID": 14, "context": "In fact, the SGNHT method is essentially equivalent to the Adaptive Langevin (Ad-Langevin) thermostat proposed earlier by Jones and Leimkuhler [10] in the molecular dynamics setting (see [15] for discussion).", "startOffset": 187, "endOffset": 191}, {"referenceID": 4, "context": "The underlying dynamics of the SGNHT [5] was taken up by Leimkuhler and Shang [15], together with the design of discretization schemes with high effective order of accuracy.", "startOffset": 37, "endOffset": 40}, {"referenceID": 14, "context": "The underlying dynamics of the SGNHT [5] was taken up by Leimkuhler and Shang [15], together with the design of discretization schemes with high effective order of accuracy.", "startOffset": 78, "endOffset": 82}, {"referenceID": 2, "context": "2 Bayesian Sampling with Noisy Gradients In the typical setting of Bayesian sampling [3, 19], one is interested in drawing states from a posterior distribution defined as \u03c0(\u03b8|X) \u221d \u03c0(X|\u03b8)\u03c0(\u03b8) , (1) where \u03b8 \u2208 RNd is the parameter vector of interest, X denotes the entire dataset, and, \u03c0(X|\u03b8) and \u03c0(\u03b8) are the likelihood and prior distributions, respectively.", "startOffset": 85, "endOffset": 92}, {"referenceID": 18, "context": "2 Bayesian Sampling with Noisy Gradients In the typical setting of Bayesian sampling [3, 19], one is interested in drawing states from a posterior distribution defined as \u03c0(\u03b8|X) \u221d \u03c0(X|\u03b8)\u03c0(\u03b8) , (1) where \u03b8 \u2208 RNd is the parameter vector of interest, X denotes the entire dataset, and, \u03c0(X|\u03b8) and \u03c0(\u03b8) are the likelihood and prior distributions, respectively.", "startOffset": 85, "endOffset": 92}, {"referenceID": 3, "context": "As in [4,5], the gradient noise is assumed to be Gaussian with mean zero and unknown variance, in which case one may rewrite the noisy force as F\u0303(\u03b8) = \u2212\u2207U(\u03b8) + \u221a \u03a3(\u03b8)MR , (6) where M typically is a diagonal matrix, \u03a3(\u03b8) represents the covariance matrix of the noise and R is a vector of i.", "startOffset": 6, "endOffset": 11}, {"referenceID": 4, "context": "As in [4,5], the gradient noise is assumed to be Gaussian with mean zero and unknown variance, in which case one may rewrite the noisy force as F\u0303(\u03b8) = \u2212\u2207U(\u03b8) + \u221a \u03a3(\u03b8)MR , (6) where M typically is a diagonal matrix, \u03a3(\u03b8) represents the covariance matrix of the noise and R is a vector of i.", "startOffset": 6, "endOffset": 11}, {"referenceID": 4, "context": "[5], has the following underlying dynamics, written as a standard It\u014d stochastic differential equation (SDE) system [15]: d\u03b8 = Mpdt , dp = \u2212\u2207U(\u03b8)dt+ \u03c3 \u221a hMdW\u2212 \u03bepdt+ \u221a", "startOffset": 0, "endOffset": 3}, {"referenceID": 14, "context": "[5], has the following underlying dynamics, written as a standard It\u014d stochastic differential equation (SDE) system [15]: d\u03b8 = Mpdt , dp = \u2212\u2207U(\u03b8)dt+ \u03c3 \u221a hMdW\u2212 \u03bepdt+ \u221a", "startOffset": 116, "endOffset": 120}, {"referenceID": 3, "context": "where, colloquially, dW and dWA, respectively, represent vectors of independent Wiener increments; and are often informally denoted by N (0,dtI) [4].", "startOffset": 145, "endOffset": 148}, {"referenceID": 7, "context": "The auxiliary variable \u03be \u2208 R is governed by a Nos\u00e9-Hoover device [8,17] via a negative feedback mechanism, i.", "startOffset": 65, "endOffset": 71}, {"referenceID": 16, "context": "The auxiliary variable \u03be \u2208 R is governed by a Nos\u00e9-Hoover device [8,17] via a negative feedback mechanism, i.", "startOffset": 65, "endOffset": 71}, {"referenceID": 9, "context": "Proposition 1: (See Jones and Leimkuhler [10]) The SGNHT method (8) preserves the modified Gibbs (stationary) distribution", "startOffset": 41, "endOffset": 45}, {"referenceID": 4, "context": "[5] claimed that it is reasonable to assume the covariance matrix \u03a3(\u03b8) is constant when the size of the dataset, N , is large, in which case the variance of the posterior of \u03b8 is small.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4], which uses dynamics of the following form: d\u03b8 = Mpdt , dp = \u2212\u2207U(\u03b8)dt+ \u221a h\u03a3(\u03b8)MdW\u2212Apdt+ \u221a 2\u03b2\u22121 (AI\u2212 h\u03a3(\u03b8)/2)MdWA .", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "However, too-large a friction would essentially reduce SGHMC to SGLD, which is not desirable, as pointed out in [4], while extremely small stepsize would significantly impact the computational efficiency.", "startOffset": 112, "endOffset": 115}, {"referenceID": 1, "context": "1 Covariance Estimation of Noisy Gradients Under the assumption that the noise of the stochastic gradient follows a normal distribution, we apply a similar method to that of [2] to estimate the covariance matrix associated with the noisy gradient.", "startOffset": 174, "endOffset": 177}, {"referenceID": 1, "context": "As proved in [2], this estimator has a convergence order of O(1/N).", "startOffset": 13, "endOffset": 16}, {"referenceID": 4, "context": "The procedure of the CCAdL method is summarized in Algorithm 1, where we simply used M = I, \u03b2 = 1, and \u03bc = Nd in order to be consistent with the original implementation of SGNHT [5].", "startOffset": 178, "endOffset": 181}, {"referenceID": 14, "context": "A recent article [15] has introduced higher order of accuracy schemes which can improve accuracy, but our interest here is in the direct comparison of the underlying machinery of SGHMC, SGNHT, and CCAdL, so we avoid further modifications and enhancements related to timestepping at this stage.", "startOffset": 17, "endOffset": 21}, {"referenceID": 4, "context": "We apply the same experimental setting as in [5].", "startOffset": 45, "endOffset": 48}, {"referenceID": 4, "context": "This directly violates the constant noise variance assumption of SGNHT [5], while CCAdL adjusts to the varying noise variance.", "startOffset": 71, "endOffset": 74}, {"referenceID": 10, "context": "3 Discriminative Restricted Boltzmann Machine (DRBM) DRBM [11] is a self-contained non-linear classifier, and the gradient of its discriminative objective can be explicitly computed.", "startOffset": 58, "endOffset": 62}, {"referenceID": 10, "context": "Due to the limited space, we refer the readers to [11] for more details.", "startOffset": 50, "endOffset": 54}, {"referenceID": 0, "context": "However, we point out that optimal design of splitting methods in ergodic SDE systems has been explored recently in the mathematics community [1, 13, 14].", "startOffset": 142, "endOffset": 153}, {"referenceID": 12, "context": "However, we point out that optimal design of splitting methods in ergodic SDE systems has been explored recently in the mathematics community [1, 13, 14].", "startOffset": 142, "endOffset": 153}, {"referenceID": 13, "context": "However, we point out that optimal design of splitting methods in ergodic SDE systems has been explored recently in the mathematics community [1, 13, 14].", "startOffset": 142, "endOffset": 153}, {"referenceID": 14, "context": "Moreover, it has been shown in [15] that a certain type of symmetric splitting method for the AdLangevin/SGNHT method with a clean (full) gradient inherits the superconvergence property (i.", "startOffset": 31, "endOffset": 35}, {"referenceID": 11, "context": "fourth order convergence to the invariant distribution for configurational quantities) recently demonstrated in the setting of Langevin dynamics [12,14].", "startOffset": 145, "endOffset": 152}, {"referenceID": 13, "context": "fourth order convergence to the invariant distribution for configurational quantities) recently demonstrated in the setting of Langevin dynamics [12,14].", "startOffset": 145, "endOffset": 152}], "year": 2015, "abstractText": "Monte Carlo sampling for Bayesian posterior inference is a common approach used in machine learning. The Markov Chain Monte Carlo procedures that are used are often discrete-time analogues of associated stochastic differential equations (SDEs). These SDEs are guaranteed to leave invariant the required posterior distribution. An area of current research addresses the computational benefits of stochastic gradient methods in this setting. Existing techniques rely on estimating the variance or covariance of the subsampling error, and typically assume constant variance. In this article, we propose a covariance-controlled adaptive Langevin thermostat that can effectively dissipate parameter-dependent noise while maintaining a desired target distribution. The proposed method achieves a substantial speedup over popular alternative schemes for large-scale machine learning applications.", "creator": "LaTeX with hyperref package"}}}