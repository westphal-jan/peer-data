{"id": "1511.02163", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Nov-2015", "title": "Submodular Hamming Metrics", "abstract": "We show that there is a largely unexplored class of functions (positive polymatroids) that can define proper discrete metrics over pairs of binary vectors and that are fairly tractable to optimize over. By exploiting submodularity, we are able to give hardness results and approximation algorithms for optimizing over such metrics. Additionally, we demonstrate empirically the effectiveness of these metrics and associated algorithms on both a metric minimization task (a form of clustering) and also a metric maximization task (generating diverse k-best lists).", "histories": [["v1", "Fri, 6 Nov 2015 17:13:32 GMT  (1353kb,D)", "http://arxiv.org/abs/1511.02163v1", "15 pages, 1 figure, a short version of this will appear in the NIPS 2015 conference"]], "COMMENTS": "15 pages, 1 figure, a short version of this will appear in the NIPS 2015 conference", "reviews": [], "SUBJECTS": "cs.DS cs.AI cs.DM", "authors": ["jennifer gillenwater", "rishabh k iyer", "bethany lusch", "rahul kidambi", "jeff a bilmes"], "accepted": true, "id": "1511.02163"}, "pdf": {"name": "1511.02163.pdf", "metadata": {"source": "CRF", "title": "Submodular Hamming Metrics", "authors": ["Jennifer Gillenwater", "Rishabh Iyer", "Bethany Lusch", "Rahul Kidambi", "Jeff Bilmes"], "emails": ["bilmes}@uw.edu"], "sections": [{"heading": "1 Introduction", "text": "A good distance is often the key to an effective mechanical learning algorithm. (B = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 1 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0 = 0: 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0: 0 = 0 = 0: 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 = 0 = 0: 0 = 0 = 0 = 0 ="}, {"heading": "2 Applications", "text": "The question of the way in which the differences between the individual image functions are shown is not only the question of the type of image, but also the question of the way in which the differences between the individual image functions are shown. (The question of the way in which the different image functions between the individual image functions are shown is not the question of the way in which the differences between the individual image functions (e.g. n-grams) and Bi are shown. The question of the way in which the different image functions between the individual image functions are shown is the question of the way in which the differences between the individual image functions (e.g. n-grams) and Bi is the set of characteristics for the document i. Hamming distance has a value 2 if Bi4Bj = {\"submodular,\" \"synapse\" and if Bi4Bj = \"submodular,\" \"submodular.\""}, {"heading": "3 Properties of the submodular Hamming metric", "text": "Next, we show some interesting properties of the submodular Hamming distance (A42.).Proofs for all theorems and lemmas (A = 44. A = 44. A = 44. A = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 5. B = 4. B B = 4. B B = 4. B B B = 4. B B = 4. B = 4. B = 5. B B = 5. B = 4. B = 6. B = 6. B = 4. B = 6. B = 4. B = 4. B = 6. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 6. B = 6. B = 6. B = 4. B = 4. B = 4. B = 4. B = 6. B = 4. B = 4. B = 4. B = 4. B = 4. B = 6. B = 4. B = 4. B = 4. B = 4. B = 4. B = 6. B = 4. B = 4. B = 4. B = 4. B = 4. B = 6. B = 4. B = 4. B = 4. B = 4. B = 6. B = 4. B = 4. B = 4. B = 4. B = 6. B = 6. B = 6. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4. B = 4."}, {"heading": "4 Minimization of the submodular Hamming metric", "text": "In this section, we will focus on SH-min (the centric finding problem). We will consider the four cases in Table 1: the restricted (A-C-2V) and unrestricted (A-C-2V) settings, as well as the homogeneous case (in which all FI have the same function) and the heterogeneous case. Before diving in, we will note that in all cases we not only require natural oracle access to the objective function F (A) = x m i = 1 fi (A4Bi) (i.e. the ability to rate F (A) for all A V), but also knowledge of the Bi (the B sequence). Theorem 4.1 shows that without knowledge of B SH-min is impossible to estimate. In practice, the requirement for knowledge of B is not a significant limitation; for all applications described in Section 2, B is of course known. Theorem 4.1: Let f be a positive polymatroid function."}, {"heading": "4.1 Unconstrained setting", "text": "The question of hardness in the homogeneous case remains open. Theorem 4.2 solves this question for the heterogeneous case by showing that it is NP-hard and that no algorithm can do better than a 4 / 3 approximation guarantee. The question of hardness in the homogeneous case remains open. Theorem 4.2 solves this question for the heterogeneous case and shows that no algorithms can be better than a 4 / 3 approximation guarantee. Theorem 4.2. The unrestricted and heterogeneous version of SH-min is NP-hard."}, {"heading": "4.2 Constrained setting", "text": "In essence, the problem of hardness in the existing work is applied to the limited SH-min problem, so it is also difficult to approach one factor better than another. Theorem 4.5 shows that even a simple SH-min problem requires the same SH problem and identical fi problem (s). Furthermore, no algorithm can achieve an approximation factor that is better than one factor (n \u2212 1). Theorem 4.5. Homogenetic SH-min is NP-hard under cardinality limitations. Moreover, no algorithm can achieve an approximation factor that is better than one (n \u2212 1)."}, {"heading": "5 Maximization of the submodular Hamming metric", "text": "Next, we will characterize the hardness of SH-max (the diversification problem) and describe the approximation algorithms for it. We will first show that all versions of SH-max, even the unrestricted homogeneity, not only the maximum homogeneity of SH-max, but also the maximum homogeneity of SH-max, a non-trivial function such as a monotonous function such as a polymatroid is not NP-hard. But for SH-max, despite the fact that the fi are monotonous in terms of their reasoning A4Bi, they are not monotonous in relation to A itself. This makes SH-max considerably harder. After we have determined that SH-max is a complete NP-hard, we will show that no poly-time algorithms can get an approximation factor better 3 / 4 in the unrestricted setting, and a factor of (1 \u2212 1 / e) in the restricted setting."}, {"heading": "6 Experiments", "text": "In order to demonstrate the effectiveness of the submodular hamming indicators proposed here, we apply them to a metric minimization task (clustering) and a metric maximization task (various k-best)."}, {"heading": "6.1 SH-min application: clustering", "text": "rf\u00fc ide rf\u00fc the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf for the rf"}, {"heading": "7 Conclusion", "text": "In this thesis, we defined a new class of distance functions: submodular hamming metrics. We determined hardness results for the associated SH-min and SH-max problems and provided approximation algorithms. In addition, we demonstrated the practicability of these metrics for several applications. There remain some outstanding theoretical questions (e.g. the density of the hardness results and the NP hardness of SH-min) as well as many possibilities to apply submodular hamming metrics to other problems of machine learning (e.g. the structured predictive application from Section 2)."}], "references": [{"title": "Least Squares Quantization in PCM", "author": ["S. Lloyd"], "venue": "IEEE Transactions on Information Theory, 28(2):129\u2013137,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1982}, {"title": "Learning Efficient Random Maximum A-Posteriori Predictors with Non-Decomposable Loss Functions", "author": ["T. Hazan", "S. Maji", "J. Keshet", "T. Jaakkola"], "venue": "NIPS,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning CRFs Using Graph Cuts", "author": ["M. Szummer", "P. Kohli", "D. Hoiem"], "venue": "ECCV,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2008}, {"title": "Perceptually Inspired Layout-Aware Losses for Image Segmentation", "author": ["A. Osokin", "P. Kohli"], "venue": "ECCV,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Learning Submodular Losses with the Lovasz Hinge", "author": ["J. Yu", "M. Blaschko"], "venue": "ICML,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2015}, {"title": "Diverse M-Best Solutions in Markov Random Fields", "author": ["D. Batra", "P. Yadollahpour", "A. Guzman", "G. Shakhnarovich"], "venue": "ECCV,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning Mixtures of Submodular Functions for Image Collection Summarization", "author": ["S. Tschiatschek", "R. Iyer", "H. Wei", "J. Bilmes"], "venue": "NIPS,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Measure Theory", "author": ["P. Halmos"], "venue": "Springer,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1974}, {"title": "Approximation Bounds for Inference using Cooperative Cuts", "author": ["S. Jegelka", "J. Bilmes"], "venue": "ICML,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2011}, {"title": "Submodular Secretary Problem and Extensions", "author": ["M. Bateni", "M. Hajiaghayi", "M. Zadimoghaddam"], "venue": "Technical report, MIT,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2010}, {"title": "On Submodular Function Minimization", "author": ["W.H. Cunningham"], "venue": "Combinatorica, 3:185 \u2013 192,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1985}, {"title": "An Analysis of Approximations for Maximizing Submodular Set Functions I", "author": ["G. Nemhauser", "L. Wolsey", "M. Fisher"], "venue": "14(1),", "citeRegEx": "13", "shortCiteRegEx": null, "year": 1978}, {"title": "Approximability of combinatorial problems with multi-agent submodular cost functions", "author": ["G. Goel", "C. Karande", "P. Tripathi", "L. Wang"], "venue": "FOCS,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2009}, {"title": "Learning with Submodular Functions: A Convex Optimization Perspective", "author": ["Francis R. Bach"], "venue": "CoRR, abs/1111.6453,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology", "author": ["D. Gusfield"], "venue": "Cambridge University Press,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1997}, {"title": "Curvature and Efficient Approximation Algorithms for Approximation and Minimization of Submodular Functions", "author": ["R. Iyer", "S. Jegelka", "J. Bilmes"], "venue": "NIPS,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Submodularity and Curvature: The Optimal Algorithm", "author": ["J. Vondr\u00e1k"], "venue": "RIMS Kokyuroku Bessatsu, 23,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2010}, {"title": "Submodular Approximation: Sampling-Based Algorithms and Lower Bounds", "author": ["Z. Svitkina", "L. Fleischer"], "venue": "FOCS,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2008}, {"title": "Size-constrained Submodular Minimization through Minimum Norm Base", "author": ["K. Nagano", "Y. Kawahara", "K. Aihara"], "venue": "ICML,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Submodularity Beyond Submodular Energies: Coupling Edges in Graph Cuts", "author": ["S. Jegelka", "J. Bilmes"], "venue": "CVPR,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2011}, {"title": "The Submodular Bregman and Lov\u00e1sz-Bregman Divergences with Applications", "author": ["R. Iyer", "J. Bilmes"], "venue": "NIPS,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Fast Semidifferential-Based Submodular Function Optimization", "author": ["R. Iyer", "S. Jegelka", "J. Bilmes"], "venue": "ICML,", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Maximizing non-monotone submodular functions", "author": ["Uriel Feige", "Vahab S Mirrokni", "Jan Vondrak"], "venue": "SIAM Journal on Computing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "A Threshold of ln n for Approximating Set Cover", "author": ["Uriel Feige"], "venue": "Journal of the ACM,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1998}, {"title": "A Tight Linear Time (1/2)-Approximation for Unconstrained Submodular Maximization", "author": ["N. Buchbinder", "M. Feldman", "J. Naor", "R. Schwartz"], "venue": "FOCS,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2012}, {"title": "Submodular maximization with cardinality constraints", "author": ["N. Buchbinder", "M. Feldman", "J. Naor", "R. Schwartz"], "venue": "SODA,", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2014}, {"title": "k-means++: The Advantages of Careful Seeding", "author": ["D. Arthur", "S. Vassilvitskii"], "venue": "SODA,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2007}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["T. Mikolov", "I. Sutskever", "K. Chen", "G. Corrado", "J. Dean"], "venue": "NIPS,", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "Clustering: Many clustering algorithms, including for example k-means [1], use distance functions in their optimization.", "startOffset": 70, "endOffset": 73}, {"referenceID": 1, "context": "However, both [2] and [3] observe poor performance with Hamming distance and recent work by [4] shows improved performance with richer distances that are supermodular functions of A.", "startOffset": 14, "endOffset": 17}, {"referenceID": 2, "context": "However, both [2] and [3] observe poor performance with Hamming distance and recent work by [4] shows improved performance with richer distances that are supermodular functions of A.", "startOffset": 22, "endOffset": 25}, {"referenceID": 3, "context": "However, both [2] and [3] observe poor performance with Hamming distance and recent work by [4] shows improved performance with richer distances that are supermodular functions of A.", "startOffset": 92, "endOffset": 95}, {"referenceID": 4, "context": ") In fact, [5] observes superior results with this type of loss-augmented inference using a special case of a submodular Hamming metric for the task of multi-label image classification.", "startOffset": 11, "endOffset": 14}, {"referenceID": 5, "context": "For instance, [6] showed that for image segmentation and pose tracking a diverse set of k solutions tended to contain a better predictor than the top k highest-scoring solutions.", "startOffset": 14, "endOffset": 17}, {"referenceID": 6, "context": "Submodular functions are a natural model for several summarization problems [7, 8].", "startOffset": 76, "endOffset": 82}, {"referenceID": 7, "context": "This result is known (see for instance Chapter 8 of [9]), but we provide a proof (in the supplementary material) for completeness.", "startOffset": 52, "endOffset": 55}, {"referenceID": 8, "context": "The simple subadditive function example in the introduction of [10] shows that subadditive minimization is inapproximable, and Theorem 17 of [11] states that no algorithm exists for subadditive maximization that has an approximation factor better than \u00d5( \u221a n).", "startOffset": 63, "endOffset": 67}, {"referenceID": 9, "context": "The simple subadditive function example in the introduction of [10] shows that subadditive minimization is inapproximable, and Theorem 17 of [11] states that no algorithm exists for subadditive maximization that has an approximation factor better than \u00d5( \u221a n).", "startOffset": 141, "endOffset": 145}, {"referenceID": 10, "context": "By contrast, submodular minimization is poly-time in the unconstrained setting [12], and a simple greedy algorithm from [13] gives a 1\u2212 1/eapproximation for maximization of positive polymatroids subject to a cardinality constraint.", "startOffset": 79, "endOffset": 83}, {"referenceID": 11, "context": "By contrast, submodular minimization is poly-time in the unconstrained setting [12], and a simple greedy algorithm from [13] gives a 1\u2212 1/eapproximation for maximization of positive polymatroids subject to a cardinality constraint.", "startOffset": 120, "endOffset": 124}, {"referenceID": 10, "context": "Submodular minimization is poly-time in the unconstrained setting [12].", "startOffset": 66, "endOffset": 70}, {"referenceID": 12, "context": "Borrowing from [14]\u2019s Theorem 3.", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "[14] shows that, knowing G but given only value-oracle access to the f0, no poly-time algorithm can distinguish between f 0 and f b 0 .", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "The ratio of these minimizers is 2\u2212 , which allows [14] to show that no poly-time algorithm can achieve a (2\u2212 )-approximation for the minimum submodular vertex cover problem.", "startOffset": 51, "endOffset": 55}, {"referenceID": 13, "context": "The submodularity of F\u0304 follows from the fact that submodular functions are closed under restriction, complementation, and addition (see [16], page 9).", "startOffset": 137, "endOffset": 141}, {"referenceID": 14, "context": "This result is known [17], as the proof of the guarantee only makes use of metricity and homogeneity (not submodularity), and these properties are common to much other work.", "startOffset": 21, "endOffset": 25}, {"referenceID": 15, "context": "1 of [18] establishes that this problem is NP-hard and has a hardness of \u03a9( \u221a n 1+( \u221a n\u22121)(1\u2212\u03baf ) ).", "startOffset": 5, "endOffset": 9}, {"referenceID": 15, "context": "[18, 14].", "startOffset": 0, "endOffset": 8}, {"referenceID": 12, "context": "[18, 14].", "startOffset": 0, "endOffset": 8}, {"referenceID": 16, "context": "5 depends on a quantity \u03baf , which is also called the curvature of a submodular function [19, 18].", "startOffset": 89, "endOffset": 97}, {"referenceID": 15, "context": "5 depends on a quantity \u03baf , which is also called the curvature of a submodular function [19, 18].", "startOffset": 89, "endOffset": 97}, {"referenceID": 17, "context": "Unfortunately, the UNION-SPLIT algorithm from the previous section requires an efficient algorithm for submodular function minimization, and no such algorithm exists in the constrained setting; submodular minimization is NP-hard even under simple cardinality constraints [20] (although see [21] that shows it is possible to get solutions for a subset of the cardinality constraints).", "startOffset": 271, "endOffset": 275}, {"referenceID": 18, "context": "Unfortunately, the UNION-SPLIT algorithm from the previous section requires an efficient algorithm for submodular function minimization, and no such algorithm exists in the constrained setting; submodular minimization is NP-hard even under simple cardinality constraints [20] (although see [21] that shows it is possible to get solutions for a subset of the cardinality constraints).", "startOffset": 290, "endOffset": 294}, {"referenceID": 19, "context": "F\u0302 consists of superdifferentials [22, 23] of F \u2019s component submodular functions.", "startOffset": 34, "endOffset": 42}, {"referenceID": 20, "context": "F\u0302 consists of superdifferentials [22, 23] of F \u2019s component submodular functions.", "startOffset": 34, "endOffset": 42}, {"referenceID": 21, "context": "We use the superdifferentials defined as \u201cgrow\u201d and \u201cshrink\u201d in [24].", "startOffset": 64, "endOffset": 68}, {"referenceID": 15, "context": "The below bound then holds (from [18]): fi(Y ) \u2264 f\u0302i(Y ) \u2264 |Y | 1 + (|Y | \u2212 1)(1\u2212 \u03bafi(Y )) fi(Y ), \u2200Y \u2286 V.", "startOffset": 33, "endOffset": 37}, {"referenceID": 22, "context": "5 of [25].", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "The construction of [25] suggests that for both these functions, h1(i) = h2(i) = n \u2212 1, and hence the constant \u2211 i\u2208V h(i) = n(n \u2212 1).", "startOffset": 20, "endOffset": 24}, {"referenceID": 22, "context": "Moreover, according to [25], the maximum value of h1(A) is n/4, while that of h2(A) is n/2.", "startOffset": 23, "endOffset": 27}, {"referenceID": 23, "context": "This SH-max instance is exactly the problem of monotone submodular maximization subject to cardinality constraint, which is not only NP-hard but has a hardness of 1\u2212 1/e [26].", "startOffset": 170, "endOffset": 174}, {"referenceID": 26, "context": "We use k-means++ initialization [29] and average over 10 trials.", "startOffset": 32, "endOffset": 36}, {"referenceID": 27, "context": "To get the word clustersW , we first run the WORD2VEC code of [30], which generates a 100-dimensional real-valued vector of features for each word, and then run k-means clustering with Euclidean distance on these vectors to define 100 word clusters.", "startOffset": 62, "endOffset": 66}, {"referenceID": 26, "context": "To initialize, we again use k-means++ [29], with k = 10.", "startOffset": 38, "endOffset": 42}, {"referenceID": 6, "context": "We compute Sij by taking the dot product of the ith and jth feature vectors, which are the same as those used by [8].", "startOffset": 113, "endOffset": 116}, {"referenceID": 11, "context": "For HM we optimize via the standard greedy algorithm [13]; since the facility location function g is monotone submodular, this implies an approximation guarantee of (1 \u2212 1/e).", "startOffset": 53, "endOffset": 57}, {"referenceID": 11, "context": "For SM, we experiment with two algorithms: (1) standard greedy [13], and (2) UNION-SPLIT (Algorithm 1) with standard greedy as the SUBMODULAR-OPT function.", "startOffset": 63, "endOffset": 67}, {"referenceID": 24, "context": "Note that neither of these optimization techniques has a formal approximation guarantee, though the latter would if instead of standard greedy we used the bi-directional greedy algorithm of [27].", "startOffset": 190, "endOffset": 194}, {"referenceID": 6, "context": "We employ the image summarization dataset from [8], which consists of 14 image collections, each of which contains n = 100 images.", "startOffset": 47, "endOffset": 50}, {"referenceID": 6, "context": "For evaluation, we employ the V-ROUGE score developed by [8]; the mean V-ROUGE (mV-ROUGE) of the k summaries provides a quantitative measure of their goodness.", "startOffset": 57, "endOffset": 60}], "year": 2015, "abstractText": "We show that there is a largely unexplored class of functions (positive polymatroids) that can define proper discrete metrics over pairs of binary vectors and that are fairly tractable to optimize over. By exploiting submodularity, we are able to give hardness results and approximation algorithms for optimizing over such metrics. Additionally, we demonstrate empirically the effectiveness of these metrics and associated algorithms on both a metric minimization task (a form of clustering) and also a metric maximization task (generating diverse k-best lists).", "creator": "LaTeX with hyperref package"}}}