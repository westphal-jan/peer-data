{"id": "1511.03719", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2015", "title": "Universum Prescription: Regularization Using Unlabeled Data", "abstract": "This paper shows that simply prescribing \"none of the above\" labels to unlabeled data has a beneficial regularization effect to supervised learning. We call it universum prescription by the fact that the prescribed labels cannot be one of the supervised labels. In spite of its simplicity, universum prescription obtained competitive results in training deep convolutional networks for CIFAR-10, CIFAR-100 and STL-10 datasets. A qualitative justification of these approaches using Rademacher complexity is presented. The effect of a regularization parameter -- probability of sampling from unlabeled data -- is also studied empirically.", "histories": [["v1", "Wed, 11 Nov 2015 22:46:46 GMT  (99kb,D)", "http://arxiv.org/abs/1511.03719v1", null], ["v2", "Wed, 18 Nov 2015 19:54:22 GMT  (100kb,D)", "http://arxiv.org/abs/1511.03719v2", null], ["v3", "Sun, 22 Nov 2015 22:12:09 GMT  (100kb,D)", "http://arxiv.org/abs/1511.03719v3", null], ["v4", "Thu, 21 Jan 2016 06:11:33 GMT  (100kb,D)", "http://arxiv.org/abs/1511.03719v4", null], ["v5", "Mon, 15 Feb 2016 18:52:30 GMT  (100kb,D)", "http://arxiv.org/abs/1511.03719v5", null], ["v6", "Mon, 25 Apr 2016 21:10:32 GMT  (99kb,D)", "http://arxiv.org/abs/1511.03719v6", null], ["v7", "Fri, 18 Nov 2016 01:15:30 GMT  (104kb,D)", "http://arxiv.org/abs/1511.03719v7", "7 pages for article, 3 pages for supplemental material. To appear in AAAI-17"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["xiang zhang", "yann lecun"], "accepted": true, "id": "1511.03719"}, "pdf": {"name": "1511.03719.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Xiang Zhang", "Yann LeCun"], "emails": ["yann}@cs.nyu.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, it is the case that one is able to find a solution that is capable of finding a solution that is capable of finding a solution that is capable of finding a solution and that is able to find a solution that is capable of finding a solution that is capable of finding a solution that is capable of finding a solution that is capable of finding a solution that is capable of finding a solution that is capable of finding a solution, that is able to find a solution that is capable of finding a solution, that is able to find a solution that is capable of finding a solution."}, {"heading": "2 UNIVERSUM PRESCRIPTION", "text": "In this section, we try to formalize the trick by prescribing \"none of the above\" labels. We call it universe prescription because these labels might not belong to a controlled class. Consider the problem of exclusive k-way classification. In the conclusion, we find the most likely class y (1, 2,.., k) given input x. In learning, we hope to find a hypothesis function h, H mapping to Rk, so that the label is determined by y = argmini hi (x). The following assumptions are made.1. (loss assumption) The loss that is used as optimization target is a negative log probability: L (h, x, y) = hy (x) + log [k, i = 1 Exp (\u2212 hi (x))))) and the following assumptions are made.1. (loss assumption) 2. (universe assumption) The percentage of samples that belong to one of k classes is negligible."}, {"heading": "2.1 UNIFORM PRESCRIPTION", "text": "It is known that the negative log probability is merely a reduced form of transverse entropyL (h, x, y) = \u2212 k \u2211 i = 1 Q [Y = i | x] log Pr [Y = i | x, h] (4) in which the target probability Q [Y = y | x] = 1 and Q [Y = i | x] = 0 for i 6 = y. Assuming that we get an blank sample x, we hope to prescribe something Q [Y = y | x] so that each class has an equally minimal probability. Q must also fulfill the probability k = 1Q [Y = i | x] = 1 on the basis of probability axioms, and the only possible choice for Q is then Q [Y | x] = 1 / k. The learning algorithm then uses transverse entropy loss instead of negative log probability. It is worth noting that the uniform output has the maximum entropy among all possible options, such as a consistent parameter is obtained in the case of a hypothesis."}, {"heading": "2.2 DUSTBIN CLASS", "text": "Another way to prescribe an agnostic target is to add a \"trash can\" class to the monitored task, which requires some modifications to the hypotheses function h so that it outputs k + 1 targets. In deep learning models, one can simply expand the last parameterized level. All unlabeled data is prescribed to this additional \"trash can\" class. The learning algorithm remains unchanged. The effect of the trash class is clearly evident in the loss function of an unlabeled sample (x, k + 1) L (h, x, k + 1) = hk + 1 (x) + log [k + 1 \u2211 i = 1 exchange (\u2212 hi (x)]. (5) The second term is a \"soft\" maximum for all dimensions of \u2212 h. If an unlabeled sample is present, the algorithm tries to introduce smoothness by minimizing probability peaks."}, {"heading": "2.3 BACKGROUND CLASS", "text": "We could further simplify the trash class by removing parameters for class k + 1. For some given threshold constants, we could change the probability of a labeled sample as follows: Pr [Y = y | x, h] = exp (\u2212 hy (x)) exp (\u2212 \u03c4) + \u2211 k i = 1 exp (\u2212 hi (x)), (6) and an unlabeled sample Pr [Y = k + 1 | x, h] = exp (\u2212 \u03c4) exp (\u2212 \u03c4) + \u2211 k i = 1 exp (\u2212 hi (x))))). (7) This will result in changes in the loss function of a labeled sample (x, y) asL (h, x, y) = hy (x) + log [exp (\u2212 \u03c4) + k \u00b2 i = 1 exp (\u2212 hi (x))."}, {"heading": "3 THEORETICAL JUSTIFICATION", "text": "In this part, we derive a qualitative justification for universal prescriptions. (PAC) Learning effectiveness (Valiant = 1) Learning effectiveness (Valiant = 1) Learning effectiveness (Valiant = 1) Learning effectiveness (Valiant = 1) Learning effectiveness (VapnikChervonenkis (Vapnik and Chervonenkis (1971))), covering numbers (Dudley (1967) and others. Our theory is based on Rademacher complexity (Bartlett & Mendelson (2003)), similar to the work of Wan et al. (2013), in which both dropouts (Srivastava et al. (Wan et al. (2013)) are justified. Rademacher complexity is usually a lower limit of other numerical or combinatorial complexity."}, {"heading": "4 EXPERIMENTS ON IMAGE CLASSIFICATION", "text": "Two series of data sets - CIFAR-10 / 100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) - are selected based on the availability of unlabeled data. However, the model we are using is a 21-layer Convolutionary Network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998))), inspired by Simonyan & Zisserman (2014), in which the inputs are 32 times 32 images and all the revolutionary layers are 3 times 3 and fully padded. All pooling layers are max-pooling, and ReLUs (Nair & Hinton (2010)) are used as non-linear units according to all the revolutionary and linear layers."}, {"heading": "4.1 CIFAR-10 AND CIFAR-100", "text": "The samples of the CIFAR-10 and CIFAR-100 datasets (Krizhevsky (2009)) are taken from the 80 million tiny image datasets (Torralba et al. (2008)). Each dataset contains 60,000 samples, representing a very small proportion of 80 million. This is an ideal case for our methods in which we can use the entire 80 million images as unlabeled data. CIFAR-10 dataset has 10 classes, and CIFAR100 has 20 (coarse) or 100 (fine-grained) classes. Table 2 contains the results. The generalization gap is estimated by the difference between test and training errors. All universal prescription models use unlabeled data with the probability p = 0,2.Table 3: Comparison of the individual models CIFAR-10 and CIFAR-100 results (IFAR-100 results) in the second and third columns."}, {"heading": "4.2 STL-10", "text": "The STL-10 dataset (Coates et al. (2011)) has a size of 96 by 96 for its images. We have sampled it down to 32 by 32 to use the same model, and the dataset contains a very small number of training samples - 5000 in total. The attached unlabeled dataset is larger at 100,000 samples. There is no guarantee that these additional samples will be outside the supervised training classes. Both the size of the dataset and non-compliance with the universe assumption could be the reason that the universe recipe failed. To verify that the additional data is the problem, we also conducted an experiment with the 80 million tiny images as an unlabeled dataset, as in Table 2. Due to the long training times of our models, we did not perform a 10x training as in the original paper by Coates et al. (2011), so our result is not comparable to that of the literature."}, {"heading": "5 EFFECT OF THE REGULARIZATION PARAMETER", "text": "In this section we show the experiments. In order to prevent an exhaustive search for the regularization parameter from transferring our models to the test data, we use a different model for this section. It is described in Table 4, which has a total of 9 parameterized layers. The design was inspired by Sermanet et et al. (2013). For each p selection, we performed 6 experiments combining universe prescription models and dropouts. The dropouts are added between the fully interconnected layers with failure probability 0.5. Figure 1 shows the results. From Figure 1, we can conclude that an increasing p will reduce the generalization gap. However, we cannot make p too large because after a certain point the dropouts are too large and both the training and testing errors worsen.The comparison between CIFAR-10 / 100 and STL-10, the model variance is made by the combined size of the prescription data and the universality of the test data."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank NVIDIA Corporation for their support with the donation of two Tesla K40 GPUs used for this research. Sainbayar Sukhbaatar provided many useful comments. Aditya Ramesh and Junbo Zhao helped verify the evidence."}, {"heading": "APPENDIX: PROOF OF THEOREM 2", "text": "Let us have a dataset of size m (S1 and S2 are two non-overlapping subsets of S \u2212 \u2212 S1 \u2212 S2 \u2212 S2 \u2212 S2 \u2212 S2 \u2212 S2 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S2 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S1 \u2212 S2 \u2212 S2 \u2212 S2 \u2212 S2 \u2212 S2 \u2212 S2 \u2212 S2 (17) Proof. Let (xj, yj) S1 for j = 1, 2,., m \u2212 S1 and (xj, yj) S2 \u2212 S2 for i \u2212 m,., m. Denote N as a discrete universal distribution on {1 \u2212 1, \u2212 1}. Let us use the constellation of the Supremum and the symmetry of NR S1 (F) and S1 S1 (F) S1 \u2212 S1 \u2212 S2."}], "references": [{"title": "Learning from hints in neural networks", "author": ["Abu-Mostafa", "Yaser S"], "venue": "Journal of complexity,", "citeRegEx": "Abu.Mostafa and S.,? \\Q1990\\E", "shortCiteRegEx": "Abu.Mostafa and S.", "year": 1990}, {"title": "Rademacher and gaussian complexities: Risk bounds and structural results", "author": ["Bartlett", "Peter L", "Mendelson", "Shahar"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Bartlett et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2003}, {"title": "Model selection and error estimation", "author": ["Bartlett", "Peter L", "Boucheron", "St\u00e9phane", "Lugosi", "G\u00e1bor"], "venue": "Machine Learning,", "citeRegEx": "Bartlett et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2002}, {"title": "A model of inductive bias learning", "author": ["Baxter", "Jonathan"], "venue": "J. Artif. Int. Res.,", "citeRegEx": "Baxter and Jonathan.,? \\Q2000\\E", "shortCiteRegEx": "Baxter and Jonathan.", "year": 2000}, {"title": "Scaling learning algorithms towards ai", "author": ["Bengio", "Yoshua", "LeCun", "Yann"], "venue": null, "citeRegEx": "Bengio et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2007}, {"title": "Representation learning: A review and new perspectives", "author": ["Bengio", "Yoshua", "Courville", "Aaron", "Vincent", "Pierre"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Multitask learning: A knowledge-based source of inductive bias", "author": ["Caruana", "Richard"], "venue": "In Proceedings of the Tenth International Conference on Machine Learning,", "citeRegEx": "Caruana and Richard.,? \\Q1993\\E", "shortCiteRegEx": "Caruana and Richard.", "year": 1993}, {"title": "A Discussion of Semi-Supervised Learning and Transduction, pp. 473\u2013478", "author": ["O. Chapelle", "B. Schlkopf", "A. Zien"], "venue": null, "citeRegEx": "Chapelle et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2006}, {"title": "Semi-supervised learning. Adaptive computation and machine learning", "author": ["Chapelle", "Olivier", "Schlkopf", "Bernhard", "Zien", "Alexander"], "venue": null, "citeRegEx": "Chapelle et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2006}, {"title": "An analysis of single-layer networks in unsupervised feature learning", "author": ["Coates", "Adam", "Ng", "Andrew Y", "Lee", "Honglak"], "venue": "In International conference on artificial intelligence and statistics,", "citeRegEx": "Coates et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2011}, {"title": "Data dependent regularization", "author": ["Corduneanu", "Adrian", "Jaakkola", "Tommi"], "venue": null, "citeRegEx": "Corduneanu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Corduneanu et al\\.", "year": 2006}, {"title": "The sizes of compact subsets of hilbert space and continuity of gaussian processes", "author": ["Dudley", "Richard M"], "venue": "Journal of Functional Analysis,", "citeRegEx": "Dudley and M.,? \\Q1967\\E", "shortCiteRegEx": "Dudley and M.", "year": 1967}, {"title": "Why does unsupervised pre-training help deep learning", "author": ["Erhan", "Dumitru", "Bengio", "Yoshua", "Courville", "Aaron", "Manzagol", "Pierre-Antoine", "Vincent", "Pascal", "Samy"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Erhan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Erhan et al\\.", "year": 2010}, {"title": "Learning by transduction", "author": ["Gammerman", "Alexander", "Vovk", "Volodya", "Vapnik", "Vladimir"], "venue": "In Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "Gammerman et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Gammerman et al\\.", "year": 1998}, {"title": "Neural networks and the bias/variance dilemma", "author": ["Geman", "Stuart", "Bienenstock", "Elie", "Doursat", "Ren\u00e9"], "venue": "Neural computation,", "citeRegEx": "Geman et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Geman et al\\.", "year": 1992}, {"title": "Spatially-sparse convolutional neural networks", "author": ["Graham", "Benjamin"], "venue": "CoRR, abs/1409.6070,", "citeRegEx": "Graham and Benjamin.,? \\Q2014\\E", "shortCiteRegEx": "Graham and Benjamin.", "year": 2014}, {"title": "Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "arXiv preprint arXiv:1502.01852,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Distilling the knowledge in a neural network", "author": ["Hinton", "Geoffrey", "Vinyals", "Oriol", "Dean", "Jeff"], "venue": "arXiv preprint arXiv:1503.02531,", "citeRegEx": "Hinton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2015}, {"title": "A fast learning algorithm for deep belief nets", "author": ["Hinton", "Geoffrey E", "Osindero", "Simon", "Teh", "Yee-Whye"], "venue": "Neural computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Rademacher penalties and structural risk minimization", "author": ["Koltchinskii", "Vladimir"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Koltchinskii and Vladimir.,? \\Q2001\\E", "shortCiteRegEx": "Koltchinskii and Vladimir.", "year": 2001}, {"title": "Rademacher processes and bounding the risk of function learning. In High dimensional probability II, pp. 443\u2013457", "author": ["Koltchinskii", "Vladimir", "Panchenko", "Dmitriy"], "venue": null, "citeRegEx": "Koltchinskii et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Koltchinskii et al\\.", "year": 2000}, {"title": "Learning multiple layers of features from tiny images", "author": ["Krizhevsky", "Alex"], "venue": null, "citeRegEx": "Krizhevsky and Alex.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Alex.", "year": 2009}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural Computation,", "citeRegEx": "LeCun et al\\.,? \\Q1989\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1989}, {"title": "Gradient-based learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "A tutorial on energybased learning", "author": ["LeCun", "Yann", "Chopra", "Sumit", "Hadsell", "Raia", "Ranzato", "Marc\u2019Aurelio", "Huang", "Fu-Jie"], "venue": null, "citeRegEx": "LeCun et al\\.,? \\Q2006\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2006}, {"title": "Deeply-supervised nets", "author": ["Lee", "Chen-Yu", "Xie", "Saining", "Gallagher", "Patrick", "Zhang", "Zhengyou", "Tu", "Zhuowen"], "venue": "In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Lee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2015}, {"title": "Some applications of concentration inequalities to statistics", "author": ["Massart", "Pascal"], "venue": "In Annales de la Faculte\u0301 des sciences de Toulouse: Mathe\u0301matiques,", "citeRegEx": "Massart and Pascal.,? \\Q2000\\E", "shortCiteRegEx": "Massart and Pascal.", "year": 2000}, {"title": "Skeletonization: A technique for trimming the fat from a network via relevance assessment", "author": ["Mozer", "Michael C", "Smolensky", "Paul"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mozer et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Mozer et al\\.", "year": 1989}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["Nair", "Vinod", "Hinton", "Geoffrey E"], "venue": "In Proceedings of the 27th International Conference on Machine Learning", "citeRegEx": "Nair et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2010}, {"title": "Some methods of speeding up the convergence of iteration methods", "author": ["B.T. Polyak"], "venue": "USSR Computational Mathematics and Mathematical Physics,", "citeRegEx": "Polyak,? \\Q1964\\E", "shortCiteRegEx": "Polyak", "year": 1964}, {"title": "Efficient learning of sparse representations with an energy-based model", "author": ["Ranzato", "Marc\u2019Aurelio", "Poultney", "Christopher", "Chopra", "Sumit", "LeCun", "Yann"], "venue": "In et al., J. Platt (ed.), Advances in Neural Information Processing Systems (NIPS 2006),", "citeRegEx": "Ranzato et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2006}, {"title": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "author": ["Sermanet", "Pierre", "Eigen", "David", "Zhang", "Xiang", "Mathieu", "Micha\u00ebl", "Fergus", "Rob", "LeCun", "Yann"], "venue": "CoRR, abs/1312.6229,", "citeRegEx": "Sermanet et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sermanet et al\\.", "year": 2013}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "CoRR, abs/1409.1556,", "citeRegEx": "Simonyan and Zisserman,? \\Q2014\\E", "shortCiteRegEx": "Simonyan and Zisserman", "year": 2014}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Srivastava", "Nitish", "Hinton", "Geoffrey", "Krizhevsky", "Alex", "Sutskever", "Ilya", "Salakhutdinov", "Ruslan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Symbolic-neural systems and the use of hints for developing complex systems", "author": ["Suddarth", "Steven C", "Holden", "Alistair DC"], "venue": "International Journal of Man-Machine Studies,", "citeRegEx": "Suddarth et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Suddarth et al\\.", "year": 1991}, {"title": "On the importance of initialization and momentum in deep learning", "author": ["Sutskever", "Ilya", "Martens", "James", "Dahl", "George", "Hinton", "Geoffrey"], "venue": "In Proceedings of the 30th international conference on machine learning", "citeRegEx": "Sutskever et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2013}, {"title": "Learning to Learn", "author": ["Thrun", "Sebastian", "Pratt", "Lorien (eds"], "venue": null, "citeRegEx": "Thrun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Thrun et al\\.", "year": 1998}, {"title": "80 million tiny images: A large data set for nonparametric object and scene recognition", "author": ["Torralba", "Antonio", "Fergus", "Rob", "Freeman", "William T"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Torralba et al\\.,? \\Q1958\\E", "shortCiteRegEx": "Torralba et al\\.", "year": 1958}, {"title": "A theory of the learnable", "author": ["Valiant", "Leslie G"], "venue": "Communications of the ACM,", "citeRegEx": "Valiant and G.,? \\Q1984\\E", "shortCiteRegEx": "Valiant and G.", "year": 1984}, {"title": "The Nature of Statistical Learning Theory", "author": ["Vapnik", "Vladimir N"], "venue": null, "citeRegEx": "Vapnik and N.,? \\Q1995\\E", "shortCiteRegEx": "Vapnik and N.", "year": 1995}, {"title": "Estimation of Dependences Based on Empirical Data", "author": ["Vapnik", "Vladimir N"], "venue": null, "citeRegEx": "Vapnik and N.,? \\Q2006\\E", "shortCiteRegEx": "Vapnik and N.", "year": 2006}, {"title": "On the uniform convergence of relative frequencies of events to their probabilities", "author": ["Vapnik", "Vladimir N", "Chervonenkis", "A Ya"], "venue": "Theory of Probability & Its Applications,", "citeRegEx": "Vapnik et al\\.,? \\Q1971\\E", "shortCiteRegEx": "Vapnik et al\\.", "year": 1971}, {"title": "Regularization of neural networks using dropconnect", "author": ["Wan", "Li", "Zeiler", "Matthew", "Zhang", "Sixin", "LeCun", "Yann", "Fergus", "Rob"], "venue": "In Proceedings of the 30th International Conference on Machine Learning", "citeRegEx": "Wan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2013}, {"title": "Inference with the universum", "author": ["Weston", "Jason", "Collobert", "Ronan", "Sinz", "Fabian", "Bottou", "L\u00e9on", "Vapnik", "Vladimir"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "Weston et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2006}, {"title": "Stochastic pooling for regularization of deep convolutional neural networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "CoRR, abs/1301.3557,", "citeRegEx": "Zeiler et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2013}, {"title": "Pac-learning for energy-based models", "author": ["Zhang", "Xiang"], "venue": "Master\u2019s thesis,", "citeRegEx": "Zhang and Xiang.,? \\Q2013\\E", "shortCiteRegEx": "Zhang and Xiang.", "year": 2013}, {"title": "Introduction to semi-supervised learning", "author": ["Zhu", "Xiaojin", "Goldberg", "Andrew B"], "venue": "Synthesis lectures on artificial intelligence and machine learning,", "citeRegEx": "Zhu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2009}], "referenceMentions": [{"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)).", "startOffset": 270, "endOffset": 291}, {"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)).", "startOffset": 270, "endOffset": 388}, {"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)). Our work is a direct extension to learning in the presence of universum (Weston et al. (2006)), originated from Vapnik (1998) and Vapnik (2006).", "startOffset": 270, "endOffset": 484}, {"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)). Our work is a direct extension to learning in the presence of universum (Weston et al. (2006)), originated from Vapnik (1998) and Vapnik (2006).", "startOffset": 270, "endOffset": 516}, {"referenceID": 5, "context": "We study three different ways to prescribe \u201cnone of the above\u201d outputs, dubbed uniform prescription, dustbin class, and background class and show that they improve the test error of convolutional networks trained on CIFAR-10, CIFIAR-100 (Krizhevsky (2009)), and STL-10 (Coates et al. (2011)). The method is justified theoretically using Radamacher complexity (Bartlett & Mendelson (2003)). Our work is a direct extension to learning in the presence of universum (Weston et al. (2006)), originated from Vapnik (1998) and Vapnik (2006). The definition of universum is a set of unlabeled data that are known not to belong to any of the classes but in the same domain of the training data.", "startOffset": 270, "endOffset": 534}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009).", "startOffset": 115, "endOffset": 139}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al.", "startOffset": 115, "endOffset": 165}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al.", "startOffset": 115, "endOffset": 249}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al.", "startOffset": 115, "endOffset": 301}, {"referenceID": 5, "context": "Using unlabeled data to facilitate supervised learning is sometimes called semi-supervised learning as surveyed by Chapelle et al. (2006b) and Zhu & Goldberg (2009). The most related ones are information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al. (1998)).", "startOffset": 115, "endOffset": 327}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work.", "startOffset": 48, "endOffset": 69}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work.", "startOffset": 48, "endOffset": 95}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work.", "startOffset": 48, "endOffset": 140}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al.", "startOffset": 48, "endOffset": 229}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al.", "startOffset": 48, "endOffset": 250}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task.", "startOffset": 48, "endOffset": 272}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2).", "startOffset": 48, "endOffset": 598}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2).", "startOffset": 48, "endOffset": 615}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data.", "startOffset": 48, "endOffset": 776}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data.", "startOffset": 48, "endOffset": 803}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data. Universum prescription is also related to the idea of dark knowledge (Bucilu et al. (2006)) (Hinton et al.", "startOffset": 48, "endOffset": 969}, {"referenceID": 4, "context": "Representation or feature learning (reviewed by Bengio et al. (2013) and Bengio & LeCun (2007)) and transfer learning (Thrun & Pratt (1998)) are also related to our work. They include the idea of pretraining (Erhan et al. (2010) Hinton et al. (2006) Ranzato et al. (2006)), which transfers the features learnt from unlabeled data to some supervised task. Universum prescription incoporates unlabeled data as part of the supervised training process, imposing neither sparsity nor reconstruction. The methods in this article could be thought of as a simple form of multi-task learning (Baxter (2000)) (Caruana (1993)), where an auxiliary task is to control overfitting under the universum assumption (see section 2). It can also be thought of as using hints (Abu-Mostafa (1990)) (Suddarth & Holden (1991)) for training where the hint is functional regularity from unlabeled data. Universum prescription is also related to the idea of dark knowledge (Bucilu et al. (2006)) (Hinton et al. (2015)).", "startOffset": 48, "endOffset": 992}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al.", "startOffset": 36, "endOffset": 61}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance.", "startOffset": 36, "endOffset": 97}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance. As part of the general statistical learning theory (Vapnik (1995), Vapnik (1998)), the justification for regularization is well-developed.", "startOffset": 36, "endOffset": 228}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance. As part of the general statistical learning theory (Vapnik (1995), Vapnik (1998)), the justification for regularization is well-developed.", "startOffset": 36, "endOffset": 243}, {"referenceID": 32, "context": "Some other methods such as dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) cheaply simulate model averaging to control the model variance. As part of the general statistical learning theory (Vapnik (1995), Vapnik (1998)), the justification for regularization is well-developed. There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al.", "startOffset": 36, "endOffset": 400}, {"referenceID": 14, "context": "There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)).", "startOffset": 142, "endOffset": 162}, {"referenceID": 14, "context": "There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)).", "startOffset": 142, "endOffset": 231}, {"referenceID": 14, "context": "There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)). We qualitatively justify the methods using Radamacher complexity (Bartlett & Mendelson (2003)), similar to Wan et al.", "startOffset": 142, "endOffset": 327}, {"referenceID": 14, "context": "There are many formulations, such as probably approximately correct (PAC) learning (Valiant (1984)), the trade-off between bias and variance (Geman et al. (1992)), and the prescription of Baysian a priori (Mozer & Smolensky (1989)). We qualitatively justify the methods using Radamacher complexity (Bartlett & Mendelson (2003)), similar to Wan et al. (2013).", "startOffset": 142, "endOffset": 358}, {"referenceID": 7, "context": "This is opposite to the assumptions of information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al.", "startOffset": 124, "endOffset": 148}, {"referenceID": 7, "context": "This is opposite to the assumptions of information regularization (Corduneanu & Jaakkola (2006)) and transduction learning (Chapelle et al. (2006a)) (Gammerman et al. (1998)).", "startOffset": 124, "endOffset": 174}, {"referenceID": 41, "context": "Our theory is based on Rademacher complexity (Bartlett & Mendelson (2003)), similar to the work by Wan et al. (2013) in which both dropout (Srivastava et al.", "startOffset": 99, "endOffset": 117}, {"referenceID": 33, "context": "(2013) in which both dropout (Srivastava et al. (2014)) and dropconnect (Wan et al.", "startOffset": 30, "endOffset": 55}, {"referenceID": 33, "context": "(2013) in which both dropout (Srivastava et al. (2014)) and dropconnect (Wan et al. (2013)) are justified.", "startOffset": 30, "endOffset": 91}, {"referenceID": 1, "context": "We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000).", "startOffset": 68, "endOffset": 91}, {"referenceID": 1, "context": "We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000).", "startOffset": 68, "endOffset": 120}, {"referenceID": 1, "context": "We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000).", "startOffset": 68, "endOffset": 141}, {"referenceID": 1, "context": "We use the formulation by Zhang (2013), but anterior results are in Bartlett et al. (2002), Bartlett & Mendelson (2003), Koltchinskii (2001) and Koltchinskii & Panchenko (2000). We refer the reader to these publications for proof.", "startOffset": 68, "endOffset": 177}, {"referenceID": 22, "context": "It is similar to the definition of energy used by energy-based learning in LeCun et al. (2006). It could be the error function E(h, x, y) = 1 \u2212 1{y = argmini(hi(x))}, the exponential function E(h, x, y) = exp(hy(x)), the negative probability function E(h, x, y) = 1 \u2212 Pr[Y = y|x, h], or simply the loss E(h, x, y) = L(h, x, y).", "startOffset": 75, "endOffset": 95}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data.", "startOffset": 70, "endOffset": 91}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al.", "startOffset": 70, "endOffset": 233}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded.", "startOffset": 70, "endOffset": 254}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded.", "startOffset": 70, "endOffset": 295}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded. All pooling layers are max-pooling, and ReLUs (Nair & Hinton (2010)) are used as the non-linearity after all convolutional and linear layers.", "startOffset": 70, "endOffset": 462}, {"referenceID": 9, "context": "Two series of datasets \u2013 CIFAR-10/100 (Krizhevsky (2009)) and STL-10 (Coates et al. (2011)) \u2013 are chosen due to the availability of unlabeled data. The model we used is a 21-layer convolutional network (ConvNet) (LeCun et al. (1989), LeCun et al. (1998)) inspired by Simonyan & Zisserman (2014), in which the inputs are 32-by-32 images and all convolutional layers are 3-by-3 and fully padded. All pooling layers are max-pooling, and ReLUs (Nair & Hinton (2010)) are used as the non-linearity after all convolutional and linear layers. Two dropout (Srivastava et al. (2014)) layers of probability 0.", "startOffset": 70, "endOffset": 574}, {"referenceID": 28, "context": "gradient descent with momentum (Polyak (1964), Sutskever et al.", "startOffset": 32, "endOffset": 46}, {"referenceID": 28, "context": "gradient descent with momentum (Polyak (1964), Sutskever et al. (2013)) 0.", "startOffset": 32, "endOffset": 71}, {"referenceID": 16, "context": "The weights are initialized in the same way as He et al. (2015). The initial motivation for choosing such a big network is to make sure it will have enough capacity for overfitting so that the effect of regularization is clearly shown.", "startOffset": 47, "endOffset": 64}, {"referenceID": 37, "context": "1 CIFAR-10 AND CIFAR-100 The samples of CIFAR-10 and CIFAR-100 datasets (Krizhevsky (2009)) are from the 80 million tiny images dataset (Torralba et al. (2008)).", "startOffset": 137, "endOffset": 160}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.", "startOffset": 7, "endOffset": 25}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.", "startOffset": 7, "endOffset": 58}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.81 35.68 YES Goodfellow et al. (2013) 9.", "startOffset": 7, "endOffset": 98}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.81 35.68 YES Goodfellow et al. (2013) 9.38 38.57 YES Wan et al. (2013) 11.", "startOffset": 7, "endOffset": 131}, {"referenceID": 25, "context": "30 YES Lee et al. (2015) 7.97 34.57 YES Lin et al. (2013) 8.81 35.68 YES Goodfellow et al. (2013) 9.38 38.57 YES Wan et al. (2013) 11.10 N/A NO Zeiler & Fergus (2013) 15.", "startOffset": 7, "endOffset": 167}, {"referenceID": 9, "context": "2 STL-10 The STL-10 dataset (Coates et al. (2011)) has size 96-by-96 for its images.", "startOffset": 29, "endOffset": 50}, {"referenceID": 9, "context": "2 STL-10 The STL-10 dataset (Coates et al. (2011)) has size 96-by-96 for its images. We downsampled them to 32by-32 so as to use the same model. The dataset contains a very small number of training samples \u2013 5000 in total. The accompanying unlabeled dataset is larger with 100,000 samples. There is no guarantee that these extra samples are outside of the supervised training classes. Both the dataset size and failure to comply with universum assumption might be the reason why universum prescription failed. To verify that the extra data is the problem, we also performed an experiment using the 80 million tiny images as the unlabeled dataset, as shown in table 2. Due to long training times of our models, we did not perform 10-fold training as in the original paper by Coates et al. (2011), therefore our result is not comparable to those in the literature.", "startOffset": 29, "endOffset": 795}, {"referenceID": 31, "context": "The design is inspired by Sermanet et al. (2013). For each choice of p we conducted 6 experiments combining universum prescription models and dropout.", "startOffset": 26, "endOffset": 49}], "year": 2017, "abstractText": "This paper shows that simply prescribing \u201cnone of the above\u201d labels to unlabeled data has a beneficial regularization effect to supervised learning. We call it universum prescription by the fact that the prescribed labels cannot be one of the supervised labels. In spite of its simplicity, universum prescription obtained competitive results in training deep convolutional networks for CIFAR-10, CIFAR100 and STL-10 datasets. A qualitative justification of these approaches using Rademacher complexity is presented. The effect of a regularization parameter \u2013 probability of sampling from unlabeled data \u2013 is also studied empirically.", "creator": "LaTeX with hyperref package"}}}