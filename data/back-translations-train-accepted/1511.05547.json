{"id": "1511.05547", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Nov-2015", "title": "Return of Frustratingly Easy Domain Adaptation", "abstract": "Unlike human learning, machine learning often fails to handle changes between training (source) and test (target) input distributions. Such domain shifts, common in practical scenarios, severely damage the performance of conventional machine learning methods. Supervised domain adaptation methods have been proposed for the case when the target data have labels, including some that perform very well despite being ``frustratingly easy'' to implement. However, in practice, the target domain is often unlabeled, requiring unsupervised adaptation. We propose a simple, effective, and efficient method for unsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL minimizes domain shift by aligning the second-order statistics of source and target distributions, without requiring any target labels. Even though it is extraordinarily simple--it can be implemented in four lines of Matlab code--CORAL performs remarkably well in extensive evaluations on standard benchmark datasets.", "histories": [["v1", "Tue, 17 Nov 2015 20:53:26 GMT  (611kb,D)", "http://arxiv.org/abs/1511.05547v1", "Accepted by AAAI-16"], ["v2", "Wed, 9 Dec 2015 05:39:43 GMT  (608kb,D)", "http://arxiv.org/abs/1511.05547v2", "Fixed typos. Full paper to appear in AAAI-16. Extended Abstract of the full paper to appear in TASK-CV 2015 workshop"]], "COMMENTS": "Accepted by AAAI-16", "reviews": [], "SUBJECTS": "cs.CV cs.AI cs.LG cs.NE", "authors": ["baochen sun", "jiashi feng", "kate saenko"], "accepted": true, "id": "1511.05547"}, "pdf": {"name": "1511.05547.pdf", "metadata": {"source": "META", "title": "Return of Frustratingly Easy Domain Adaptation", "authors": ["Baochen Sun", "Jiashi Feng", "Kate Saenko"], "emails": ["bsun@cs.uml.edu", "elefjia@nus.edu.sg", "saenko@cs.uml.edu"], "sections": [{"heading": null, "text": "\"Everything should be made as simple as possible, but not easier.\" Albert Einstein"}, {"heading": "1 Introduction", "text": "In fact, most people who are able to learn from very few examples described, and apply the knowledge learned to new examples in novel situations, will only be successful if the large amounts of labelled data given are of the same distribution as the test distribution. Both theoretically (Ben-David et al. 2007) and practically (Saenko et al. 2010; Torralba and Efros 2011), we have shown that the error in the verification of the monitored methods generally increases in relation to the distribution of training courses and test examples."}, {"heading": "2 Related Work", "text": "It is a fundamental problem of machine learning, and it has also attracted a lot of attention in language, natural language, and visual communities; a variety of techniques have been proposed for assisted adaptation; some consider the source domain as an approach that regulates the learning problem in the sparsely designated target domain, e.g., (Yang, Yan, and Hauptmann 2007); others minimize the distance between the target and source domains, either by reweighting the domains or by changing the feature representation according to some explicit distribution methods (Borgwardt et al. 2006); some learn a transformation based on features that exhibit a contrasting loss (Saenko et al. 2010); probably the simplest and most prominent verified approach is the \"frustratingly simple\" feature replication (thumb III 2007); in the face of a feature vector x, it defines the augmented function vector (x = source of data); and in xx, the source of data."}, {"heading": "3 Correlation Alignment for Unsupervised Domain Adaptation", "text": "We present an extremely simple method of domain adaptation - CORrelation ALignment (CORAL) - which aims to coordinate the distributions of source and target attributes in an uncontrolled manner. We propose to coordinate the distributions by aligning the second-order statistics, i.e. covariance."}, {"heading": "3.1 Formulation and Derivation", "text": "We describe our method by taking a multi-level classification problem as a running example. Let's assume we get Source-Domain training examples DS = > x = > x x x = > x x = > case examples DS = > x = > = > case examples DS = > x = > = > case cases DS = > = > = > * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *"}, {"heading": "3.2 Algorithm", "text": "We can intuitively imagine transformation A in this way: the first part US\u03a3 + S 1 2US > whitens the source data, while the second part UT [1: r] \u0441T [1: r] 1 2UT [1: r] > quickly stains it with the target covariance, but this is illustrated in Figure 2 (b) and Figure 2 (c) respectively. Traditional whitening adds a small adjustment parameter \u03bb to the diagonal elements of the covariance matrix to explicitly bring it into full range, and then multiplies the original characteristic by the inverse square root (or square root for the staining) of its properties. Whitening and re-staining here are slightly different from them, as the data may probably lie in a lower dimensional space and the covariance matrices may be low. In practice, for the sake of efficiency and stability, we can do the classic whitening and staining."}, {"heading": "3.3 Relationship to Existing Methods", "text": "It has long been known that the normalization of input functions improves many self-learning methods, e.g. (Ioffe and Szegedy 2015). However, CORAL does not simply lead to the normalization of functions, but aligns two different distributions. Standard characteristics do not normalize to this problem as illustrated in Figure 2 (a). In this example, the characteristics are standardized so that they are the same in every dimension, the differences in the correlations present in the source and target areas cause the distributions to be different. Relations to the manifestation methods are not monitored."}, {"heading": "3.4 Application to Deep Neural Networks", "text": "Suppose the calculation (I) was performed by a multi-layer neural network, then the input of each layer \u03c6k may suffer from covariant shift as well. However, the batch normalization (Ioffe and Szegedy 2015) attempts to compensate for the internal covariate shift by normalizing each minibatch shift as a zero mean and unit. However, as shown in Figure 2, such normalization may not be sufficient. Even if applied with full white drawing, the batch normalization cannot compensate for the external covariate shift: Activation of the layer will be decorative for a source point, but not for a target point. Furthermore, as mentioned in Section 3.2, the brightening of both areas still does not work. Our method can easily be integrated into a deep architecture by treating layers as features (e.g. fc6 or fc7 by AlexNet (Krizhevsky, Sutskever and 2012)."}, {"heading": "4 Experiments", "text": "We evaluate our object recognition method (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li and Chellappa 2011; Kulis, Saenko and Darrell 2011; Saenko et al. 2010) and mood analysis (Blitzer, Dredze and Pereira 2007) with both flat and deep characteristics and use standard benchmarks and protocols. In all experiments, we assume that the target domain is unlabeled. We follow the standard procedure (Fernando et al. 2013; Donahue et al. 2014) and use a linear SVM as the base classifier. The model selection approach (Fernando et al. 2013) is used to cross-validate the C parameter for SVM on the source domain. As there are no other hyperparameters (with the exception of the usual brightening and coloring regulation parameters we discussed in Section 3.2 and Figure 3), the results can be easily reproduced in this paper."}, {"heading": "4.1 Object Recognition", "text": "In this context, it is also worth mentioning the fact that most of them are people who are able to survive themselves, in the form of people who are able to survive themselves, and in the form of people who are able to survive themselves, and in the form of people who are able to survive themselves, and in the form of people who are able to survive themselves, and in the form of people who are able to survive themselves, and in the form of people who are able to survive themselves, and in the form of people who are able to survive themselves, and in the form of people who are able to survive themselves."}, {"heading": "4.2 Sentiment Analysis", "text": "We also evaluate our sentiment analysis method using the standard Amazon review dataset (Blitzer, Dredze and Pereira 2007; Gong, Grauman and Sha 2013).We use the processed data from (Gong, Grauman and Sha 2013) where the dimensionality of the bag characteristics has been reduced to keep the top 400 words without compromising performance.This dataset contains Amazon ratings in 4 areas: kitchen appliances, DVD, books and electronics.For each domain, there are 1000 positive and 1000 negative ratings. We follow the standard protocol of (Gong, Grauman and Sha 2013) and conduct experiments on 20 random training / test columns and report the mean accuracy for each domain.Results In Table 5, we compare our method with five published methods: TCA (Pan et al. 2009), GFS (Gopalan, Li and Chellappa 2011), GFK (Gong et al 2012), SCANG (Sinterfield), Sentitzer (Sentifield), Sentifield, INERG (Sentifield) and Sentifield."}, {"heading": "5 Discussion", "text": "Tables 1-5 show that, while extremely simple, CORAL outperforms all 16 basic methods on all four standard domain customization benchmarks by using both wordbag and wordbag functions.An interesting finding is that the difference between CORAL and other published methods is much greater for deep features (e.g. 64.0 for CORAL-fc6 compared to 49.1 for SA-fc6) than for wordbag functions.This could be because deep features are more correlated than words (e.g. the largest single value of the Amazon-fc6 covariance matrix is 354 compared to 27 for Amazon-SURF).Likewise, the improvement for images (Tables 1-4) is much greater than text (Table 5), possibly because wordbag functions are extremely sparse and less correlated than image functions."}, {"heading": "6 Conclusion", "text": "In this article, we have proposed a simple, efficient, and effective method of domain customization that is \"frustratingly easy\" to implement: the only calculation is to color the white source characteristics with the covariance of the target domain. Extensive experiments with standard benchmarks demonstrate the superiority of our method over many existing state-of-the-art methods. These results confirm that CORAL is applicable to several types of characteristics, including powerful deep characteristics, and to various tasks, including computer vision and natural language processing."}, {"heading": "7 Acknowledgments", "text": "The authors thank Mingsheng Long, Judy Hoffman and Trevor Darrell for helpful discussions and suggestions; the critics for their valuable comments. The Tesla K40 used for this research was donated by NVIDIA Corporation and supported by the NSF Awards IIS-1451244 and IIS-1212928."}], "references": [{"title": "Analysis of representations for domain adaptation", "author": ["S. Ben-David", "J. Blitzer", "K. Crammer", "F. Pereira"], "venue": "NIPS.", "citeRegEx": "Ben.David et al\\.,? 2007", "shortCiteRegEx": "Ben.David et al\\.", "year": 2007}, {"title": "Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification", "author": ["J. Blitzer", "M. Dredze", "F. Pereira"], "venue": "ACL.", "citeRegEx": "Blitzer et al\\.,? 2007", "shortCiteRegEx": "Blitzer et al\\.", "year": 2007}, {"title": "Domain adaptation with structural correspondence learning", "author": ["J. Blitzer", "R. McDonald", "F. Pereira"], "venue": "EMNLP.", "citeRegEx": "Blitzer et al\\.,? 2006", "shortCiteRegEx": "Blitzer et al\\.", "year": 2006}, {"title": "Integrating structured biological data by kernel maximum mean discrepancy", "author": ["K.M. Borgwardt", "A. Gretton", "M.J. Rasch", "H.-P. Kriegel", "B. Sch\u00f6lkopf", "A.J. Smola"], "venue": "Bioinformatics.", "citeRegEx": "Borgwardt et al\\.,? 2006", "shortCiteRegEx": "Borgwardt et al\\.", "year": 2006}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["J.-F. Cai", "E.J. Cand\u00e8s", "Z. Shen"], "venue": "SIAM J. on Optimization 20(4):1956\u20131982.", "citeRegEx": "Cai et al\\.,? 2010", "shortCiteRegEx": "Cai et al\\.", "year": 2010}, {"title": "Beyond the shortest path : Unsupervised domain adaptation by sampling subspaces along the spline flow", "author": ["R. Caseiro", "J.F. Henriques", "P. Martins", "J. Batista"], "venue": "CVPR.", "citeRegEx": "Caseiro et al\\.,? 2015", "shortCiteRegEx": "Caseiro et al\\.", "year": 2015}, {"title": "Dlid: Deep learning for domain adaptation by interpolating between domains", "author": ["S. Chopra", "S. Balakrishnan", "R. Gopalan"], "venue": "ICML Workshop.", "citeRegEx": "Chopra et al\\.,? 2013", "shortCiteRegEx": "Chopra et al\\.", "year": 2013}, {"title": "Frustratingly easy domain adaptation", "author": ["III H. Daume"], "venue": "ACL.", "citeRegEx": "Daume,? 2007", "shortCiteRegEx": "Daume", "year": 2007}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. FeiFei"], "venue": "CVPR.", "citeRegEx": "Deng et al\\.,? 2009", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "ICML.", "citeRegEx": "Donahue et al\\.,? 2014", "shortCiteRegEx": "Donahue et al\\.", "year": 2014}, {"title": "Domain adaptation from multiple sources via auxiliary classifiers", "author": ["L. Duan", "I.W. Tsang", "D. Xu", "T. Chua"], "venue": "ICML.", "citeRegEx": "Duan et al\\.,? 2009", "shortCiteRegEx": "Duan et al\\.", "year": 2009}, {"title": "Domain transfer multiple kernel learning", "author": ["L. Duan", "I.W. Tsang", "D. Xu"], "venue": "TPAMI 34(3):465\u2013479.", "citeRegEx": "Duan et al\\.,? 2012", "shortCiteRegEx": "Duan et al\\.", "year": 2012}, {"title": "Unsupervised visual domain adaptation using subspace alignment", "author": ["B. Fernando", "A. Habrard", "M. Sebban", "T. Tuytelaars"], "venue": "ICCV.", "citeRegEx": "Fernando et al\\.,? 2013", "shortCiteRegEx": "Fernando et al\\.", "year": 2013}, {"title": "Unsupervised domain adaptation by backpropagation", "author": ["Y. Ganin", "V. Lempitsky"], "venue": "ICML.", "citeRegEx": "Ganin and Lempitsky,? 2015", "shortCiteRegEx": "Ganin and Lempitsky", "year": 2015}, {"title": "Domain adaptive neural networks for object recognition", "author": ["M. Ghifary", "W.B. Kleijn", "M. Zhang"], "venue": "PRICAI.", "citeRegEx": "Ghifary et al\\.,? 2014", "shortCiteRegEx": "Ghifary et al\\.", "year": 2014}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "CVPR.", "citeRegEx": "Gong et al\\.,? 2012", "shortCiteRegEx": "Gong et al\\.", "year": 2012}, {"title": "Connecting the dots with landmarks: Discriminatively learning domaininvariant features for unsupervised domain adaptation", "author": ["B. Gong", "K. Grauman", "F. Sha"], "venue": "ICML.", "citeRegEx": "Gong et al\\.,? 2013", "shortCiteRegEx": "Gong et al\\.", "year": 2013}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "ICCV.", "citeRegEx": "Gopalan et al\\.,? 2011", "shortCiteRegEx": "Gopalan et al\\.", "year": 2011}, {"title": "Caltech 256 object category dataset", "author": ["G. Gregory", "H. Alex", "P. Pietro"], "venue": "Tech. Rep. UCB/CSD-04-1366, California Institue of Technology.", "citeRegEx": "Gregory et al\\.,? 2007", "shortCiteRegEx": "Gregory et al\\.", "year": 2007}, {"title": "Learning from multiple outlooks", "author": ["M. Harel", "S. Mannor"], "venue": "ICML.", "citeRegEx": "Harel and Mannor,? 2011", "shortCiteRegEx": "Harel and Mannor", "year": 2011}, {"title": "Discriminative decorrelation for clustering and classification", "author": ["B. Hariharan", "J. Malik", "D. Ramanan"], "venue": "ECCV.", "citeRegEx": "Hariharan et al\\.,? 2012", "shortCiteRegEx": "Hariharan et al\\.", "year": 2012}, {"title": "Coupled dictionary and feature space learning with applications to cross-domain image synthesis and recognition", "author": ["Huang", "D.-A.", "Wang", "Y.-C."], "venue": "ICCV.", "citeRegEx": "Huang et al\\.,? 2013", "shortCiteRegEx": "Huang et al\\.", "year": 2013}, {"title": "Correcting sample selection bias by unlabeled data", "author": ["J. Huang", "A.J. Smola", "A. Gretton", "K.M. Borgwardt", "B. Sch\u00f6lkopf"], "venue": "NIPS.", "citeRegEx": "Huang et al\\.,? 2006", "shortCiteRegEx": "Huang et al\\.", "year": 2006}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "ICML.", "citeRegEx": "Ioffe and Szegedy,? 2015", "shortCiteRegEx": "Ioffe and Szegedy", "year": 2015}, {"title": "Instance Weighting for Domain Adaptation in NLP", "author": ["J. Jiang", "C. Zhai"], "venue": "ACL.", "citeRegEx": "Jiang and Zhai,? 2007", "shortCiteRegEx": "Jiang and Zhai", "year": 2007}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS.", "citeRegEx": "Krizhevsky et al\\.,? 2012", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "What you saw is not what you get: Domain adaptation using asymmetric kernel transforms", "author": ["B. Kulis", "K. Saenko", "T. Darrell"], "venue": "CVPR.", "citeRegEx": "Kulis et al\\.,? 2011", "shortCiteRegEx": "Kulis et al\\.", "year": 2011}, {"title": "Transfer joint matching for unsupervised domain adaptation", "author": ["M. Long", "J. Wang", "G. Ding", "J. Sun", "P. Yu"], "venue": "CVPR.", "citeRegEx": "Long et al\\.,? 2014", "shortCiteRegEx": "Long et al\\.", "year": 2014}, {"title": "Learning transferable features with deep adaptation networks", "author": ["M. Long", "Y. Cao", "J. Wang", "M.I. Jordan"], "venue": "ICML.", "citeRegEx": "Long et al\\.,? 2015", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "Understanding deep image representations by inverting them", "author": ["A. Mahendran", "A. Vedaldi"], "venue": "CVPR.", "citeRegEx": "Mahendran and Vedaldi,? 2015", "shortCiteRegEx": "Mahendran and Vedaldi", "year": 2015}, {"title": "Domain adaptation via transfer component analysis", "author": ["S.J. Pan", "I.W. Tsang", "J.T. Kwok", "Q. Yang"], "venue": "IJCAI.", "citeRegEx": "Pan et al\\.,? 2009", "shortCiteRegEx": "Pan et al\\.", "year": 2009}, {"title": "Adapting visual category models to new domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "ECCV.", "citeRegEx": "Saenko et al\\.,? 2010", "shortCiteRegEx": "Saenko et al\\.", "year": 2010}, {"title": "Generalized domain-adaptive dictionaries", "author": ["S. Shekhar", "V.M. Patel", "H.V. Nguyen", "R. Chellappa"], "venue": "CVPR.", "citeRegEx": "Shekhar et al\\.,? 2013", "shortCiteRegEx": "Shekhar et al\\.", "year": 2013}, {"title": "Frustratingly easy NBNN domain adaptation", "author": ["T. Tommasi", "B. Caputo"], "venue": "ICCV.", "citeRegEx": "Tommasi and Caputo,? 2013", "shortCiteRegEx": "Tommasi and Caputo", "year": 2013}, {"title": "A testbed for crossdataset analysis", "author": ["T. Tommasi", "T. Tuytelaars"], "venue": "ECCV TASK-CV Workshop.", "citeRegEx": "Tommasi and Tuytelaars,? 2014", "shortCiteRegEx": "Tommasi and Tuytelaars", "year": 2014}, {"title": "Unbiased look at dataset bias", "author": ["A. Torralba", "A.A. Efros"], "venue": "CVPR.", "citeRegEx": "Torralba and Efros,? 2011", "shortCiteRegEx": "Torralba and Efros", "year": 2011}, {"title": "Deep domain confusion: Maximizing for domain invariance", "author": ["E. Tzeng", "J. Hoffman", "N. Zhang", "K. Saenko", "T. Darrell"], "venue": "CoRR abs/1412.3474.", "citeRegEx": "Tzeng et al\\.,? 2014", "shortCiteRegEx": "Tzeng et al\\.", "year": 2014}, {"title": "Sun database: Large-scale scene recognition from abbey to zoo", "author": ["J. Xiao", "J. Hays", "K.A. Ehinger", "A. Oliva", "A. Torralba"], "venue": "CVPR.", "citeRegEx": "Xiao et al\\.,? 2010", "shortCiteRegEx": "Xiao et al\\.", "year": 2010}, {"title": "Adapting SVM classifiers to data with shifted distributions", "author": ["J. Yang", "R. Yan", "A. Hauptmann"], "venue": "ICDM Workshop.", "citeRegEx": "Yang et al\\.,? 2007", "shortCiteRegEx": "Yang et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 0, "context": "Both theoretical (Ben-David et al. 2007; Blitzer, Dredze, and Pereira 2007) and practical results (Saenko et al.", "startOffset": 17, "endOffset": 75}, {"referenceID": 31, "context": "2007; Blitzer, Dredze, and Pereira 2007) and practical results (Saenko et al. 2010; Torralba and Efros 2011) have shown that the test error of supervised methods generally increases in proportion to the \u201cdifference\u201d between the distributions of training and test examples.", "startOffset": 63, "endOffset": 108}, {"referenceID": 35, "context": "2007; Blitzer, Dredze, and Pereira 2007) and practical results (Saenko et al. 2010; Torralba and Efros 2011) have shown that the test error of supervised methods generally increases in proportion to the \u201cdifference\u201d between the distributions of training and test examples.", "startOffset": 63, "endOffset": 108}, {"referenceID": 0, "context": "Both theoretical (Ben-David et al. 2007; Blitzer, Dredze, and Pereira 2007) and practical results (Saenko et al. 2010; Torralba and Efros 2011) have shown that the test error of supervised methods generally increases in proportion to the \u201cdifference\u201d between the distributions of training and test examples. For example, Donahue et al. (2014) showed that even state-of-the-art Deep Convolutional Neural Network features learned on a dataset of 1.", "startOffset": 18, "endOffset": 343}, {"referenceID": 7, "context": "Daume III (2007) proposed a supervised domain adaptation approach notable for its extreme simplicity: it merely changes the features by making domainspecific and common copies, then trains a supervised classifier on the new features from both domains.", "startOffset": 0, "endOffset": 17}, {"referenceID": 36, "context": "For object recognition, we demonstrate that it works well with both standard \u201cflat\u201d bag-ofwords features and with state-of-the-art deep CNN features (Krizhevsky, Sutskever, and Hinton 2012), outperforming existing methods, including recent deep CNN adaptation approaches (Tzeng et al. 2014; Ganin and Lempitsky 2015; Long et al. 2015).", "startOffset": 271, "endOffset": 334}, {"referenceID": 13, "context": "For object recognition, we demonstrate that it works well with both standard \u201cflat\u201d bag-ofwords features and with state-of-the-art deep CNN features (Krizhevsky, Sutskever, and Hinton 2012), outperforming existing methods, including recent deep CNN adaptation approaches (Tzeng et al. 2014; Ganin and Lempitsky 2015; Long et al. 2015).", "startOffset": 271, "endOffset": 334}, {"referenceID": 28, "context": "For object recognition, we demonstrate that it works well with both standard \u201cflat\u201d bag-ofwords features and with state-of-the-art deep CNN features (Krizhevsky, Sutskever, and Hinton 2012), outperforming existing methods, including recent deep CNN adaptation approaches (Tzeng et al. 2014; Ganin and Lempitsky 2015; Long et al. 2015).", "startOffset": 271, "endOffset": 334}, {"referenceID": 3, "context": "Others minimize the distance between the target and source domains, either by re-weighting the domains or by changing the feature representation according to some explicit distribution distance metric (Borgwardt et al. 2006).", "startOffset": 201, "endOffset": 224}, {"referenceID": 31, "context": "Some learn a transformation on features using a contrastive loss (Saenko et al. 2010).", "startOffset": 65, "endOffset": 85}, {"referenceID": 24, "context": "Early techniques for unsupervised adaptation consisted of re-weighting the training point losses to more closely reflect those in the test distribution (Jiang and Zhai 2007; Huang et al. 2006).", "startOffset": 152, "endOffset": 192}, {"referenceID": 22, "context": "Early techniques for unsupervised adaptation consisted of re-weighting the training point losses to more closely reflect those in the test distribution (Jiang and Zhai 2007; Huang et al. 2006).", "startOffset": 152, "endOffset": 192}, {"referenceID": 32, "context": "Dictionary learning methods (Shekhar et al. 2013; Huang and Wang 2013) try to learn a dictionary where the difference between the source and target domain is minimized in the new representation.", "startOffset": 28, "endOffset": 70}, {"referenceID": 15, "context": "Recent state-of-the-art unsupervised approaches (Gopalan, Li, and Chellappa 2011; Gong et al. 2012; Long et al. 2014; Caseiro et al. 2015) have pursued adaptation by projecting the source and target distributions into a lower-dimensional manifold, and finding a transformation that brings the subspaces closer together.", "startOffset": 48, "endOffset": 138}, {"referenceID": 27, "context": "Recent state-of-the-art unsupervised approaches (Gopalan, Li, and Chellappa 2011; Gong et al. 2012; Long et al. 2014; Caseiro et al. 2015) have pursued adaptation by projecting the source and target distributions into a lower-dimensional manifold, and finding a transformation that brings the subspaces closer together.", "startOffset": 48, "endOffset": 138}, {"referenceID": 5, "context": "Recent state-of-the-art unsupervised approaches (Gopalan, Li, and Chellappa 2011; Gong et al. 2012; Long et al. 2014; Caseiro et al. 2015) have pursued adaptation by projecting the source and target distributions into a lower-dimensional manifold, and finding a transformation that brings the subspaces closer together.", "startOffset": 48, "endOffset": 138}, {"referenceID": 15, "context": "Geodesic methods find a path along the subspace manifold, and either project source and target onto points along that path (Gopalan, Li, and Chellappa 2011), or find a closedform linear map that projects source points to target (Gong et al. 2012).", "startOffset": 228, "endOffset": 246}, {"referenceID": 19, "context": "Alternatively, the subspaces can be aligned by computing the linear map that minimizes the Frobenius norm of the difference between them (Harel and Mannor 2011; Fernando et al. 2013).", "startOffset": 137, "endOffset": 182}, {"referenceID": 12, "context": "Alternatively, the subspaces can be aligned by computing the linear map that minimizes the Frobenius norm of the difference between them (Harel and Mannor 2011; Fernando et al. 2013).", "startOffset": 137, "endOffset": 182}, {"referenceID": 13, "context": "ReverseGrad (Ganin and Lempitsky 2015), DAN (Long et al.", "startOffset": 12, "endOffset": 38}, {"referenceID": 28, "context": "ReverseGrad (Ganin and Lempitsky 2015), DAN (Long et al. 2015), and DDC (Tzeng et al.", "startOffset": 44, "endOffset": 62}, {"referenceID": 36, "context": "2015), and DDC (Tzeng et al. 2014) directly optimize the deep representation for domain invariance, using additional loss layers designed for this purpose.", "startOffset": 15, "endOffset": 34}, {"referenceID": 19, "context": "However, the data typically lie on a lower dimensional manifold (Harel and Mannor 2011; Gong et al. 2012; Fernando et al. 2013), and so the covariance matrices are likely to be low rank (Hariharan, Malik, and Ramanan 2012).", "startOffset": 64, "endOffset": 127}, {"referenceID": 15, "context": "However, the data typically lie on a lower dimensional manifold (Harel and Mannor 2011; Gong et al. 2012; Fernando et al. 2013), and so the covariance matrices are likely to be low rank (Hariharan, Malik, and Ramanan 2012).", "startOffset": 64, "endOffset": 127}, {"referenceID": 12, "context": "However, the data typically lie on a lower dimensional manifold (Harel and Mannor 2011; Gong et al. 2012; Fernando et al. 2013), and so the covariance matrices are likely to be low rank (Hariharan, Malik, and Ramanan 2012).", "startOffset": 64, "endOffset": 127}, {"referenceID": 19, "context": "However, as demonstrated in (Harel and Mannor 2011; Fernando et al. 2013) and our experiments, transforming data from source to target space gives better performance.", "startOffset": 28, "endOffset": 73}, {"referenceID": 12, "context": "However, as demonstrated in (Harel and Mannor 2011; Fernando et al. 2013) and our experiments, transforming data from source to target space gives better performance.", "startOffset": 28, "endOffset": 73}, {"referenceID": 23, "context": ", (Ioffe and Szegedy 2015).", "startOffset": 2, "endOffset": 26}, {"referenceID": 15, "context": "Relationship to Manifold Methods Recent state-of-theart unsupervised approaches project the source and target distributions into a lower-dimensional manifold and find a transformation that brings the subspaces closer together (Gopalan, Li, and Chellappa 2011; Gong et al. 2012; Fernando et al. 2013; Harel and Mannor 2011).", "startOffset": 226, "endOffset": 322}, {"referenceID": 12, "context": "Relationship to Manifold Methods Recent state-of-theart unsupervised approaches project the source and target distributions into a lower-dimensional manifold and find a transformation that brings the subspaces closer together (Gopalan, Li, and Chellappa 2011; Gong et al. 2012; Fernando et al. 2013; Harel and Mannor 2011).", "startOffset": 226, "endOffset": 322}, {"referenceID": 19, "context": "Relationship to Manifold Methods Recent state-of-theart unsupervised approaches project the source and target distributions into a lower-dimensional manifold and find a transformation that brings the subspaces closer together (Gopalan, Li, and Chellappa 2011; Gong et al. 2012; Fernando et al. 2013; Harel and Mannor 2011).", "startOffset": 226, "endOffset": 322}, {"referenceID": 19, "context": "We note that subspace-mapping approaches (Harel and Mannor 2011; Fernando et al. 2013) only align the top k (subspace dimensionality) eigenvectors of the source and target covariance matrices.", "startOffset": 41, "endOffset": 86}, {"referenceID": 12, "context": "We note that subspace-mapping approaches (Harel and Mannor 2011; Fernando et al. 2013) only align the top k (subspace dimensionality) eigenvectors of the source and target covariance matrices.", "startOffset": 41, "endOffset": 86}, {"referenceID": 30, "context": ", (Pan et al. 2009; Long et al. 2015)) for domain adaptation can be interpreted as \u201cmoment matching\u201d and can express arbitrary statistics of the data.", "startOffset": 2, "endOffset": 37}, {"referenceID": 28, "context": ", (Pan et al. 2009; Long et al. 2015)) for domain adaptation can be interpreted as \u201cmoment matching\u201d and can express arbitrary statistics of the data.", "startOffset": 2, "endOffset": 37}, {"referenceID": 19, "context": "As demonstrated in (Kulis, Saenko, and Darrell 2011; Harel and Mannor 2011; Fernando et al. 2013), asymmetric transformations are more flexible and often yield better performance for domain adaptation tasks.", "startOffset": 19, "endOffset": 97}, {"referenceID": 12, "context": "As demonstrated in (Kulis, Saenko, and Darrell 2011; Harel and Mannor 2011; Fernando et al. 2013), asymmetric transformations are more flexible and often yield better performance for domain adaptation tasks.", "startOffset": 19, "endOffset": 97}, {"referenceID": 23, "context": "Batch Normalization (Ioffe and Szegedy 2015) tries to compensate for internal covariate shift by normalizing each mini-batch to be zero-mean and unitvariance.", "startOffset": 20, "endOffset": 44}, {"referenceID": 15, "context": "We evaluate our method on object recognition (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and sentiment analysis (Blitzer, Dredze, and Pereira 2007) with both shallow and deep features, using standard benchmarks and protocols.", "startOffset": 45, "endOffset": 171}, {"referenceID": 12, "context": "We evaluate our method on object recognition (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and sentiment analysis (Blitzer, Dredze, and Pereira 2007) with both shallow and deep features, using standard benchmarks and protocols.", "startOffset": 45, "endOffset": 171}, {"referenceID": 31, "context": "We evaluate our method on object recognition (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and sentiment analysis (Blitzer, Dredze, and Pereira 2007) with both shallow and deep features, using standard benchmarks and protocols.", "startOffset": 45, "endOffset": 171}, {"referenceID": 12, "context": "We follow the standard procedure (Fernando et al. 2013; Donahue et al. 2014) and use a linear SVM as the base classifier.", "startOffset": 33, "endOffset": 76}, {"referenceID": 9, "context": "We follow the standard procedure (Fernando et al. 2013; Donahue et al. 2014) and use a linear SVM as the base classifier.", "startOffset": 33, "endOffset": 76}, {"referenceID": 12, "context": "The model selection approach of (Fernando et al. 2013) is used to set the C parameter for the SVM by doing cross-validation on the source domain.", "startOffset": 32, "endOffset": 54}, {"referenceID": 31, "context": "Both the standard Office (Saenko et al. 2010) and extended Office-Caltech10 (Gong et al.", "startOffset": 25, "endOffset": 45}, {"referenceID": 15, "context": "2010) and extended Office-Caltech10 (Gong et al. 2012) datasets are used as benchmarks in this paper.", "startOffset": 36, "endOffset": 54}, {"referenceID": 15, "context": "Object Recognition with Shallow Features The OfficeCaltech10 dataset is the standard benchmark (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) for domain adaptation with shallow features (SURF) in object recognition.", "startOffset": 95, "endOffset": 221}, {"referenceID": 12, "context": "Object Recognition with Shallow Features The OfficeCaltech10 dataset is the standard benchmark (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) for domain adaptation with shallow features (SURF) in object recognition.", "startOffset": 95, "endOffset": 221}, {"referenceID": 31, "context": "Object Recognition with Shallow Features The OfficeCaltech10 dataset is the standard benchmark (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) for domain adaptation with shallow features (SURF) in object recognition.", "startOffset": 95, "endOffset": 221}, {"referenceID": 15, "context": "We follow the standard protocol of (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and conduct experiments in 20 randomized trials for each domain shift and average the accuracy over the trials.", "startOffset": 35, "endOffset": 161}, {"referenceID": 12, "context": "We follow the standard protocol of (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and conduct experiments in 20 randomized trials for each domain shift and average the accuracy over the trials.", "startOffset": 35, "endOffset": 161}, {"referenceID": 31, "context": "We follow the standard protocol of (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and conduct experiments in 20 randomized trials for each domain shift and average the accuracy over the trials.", "startOffset": 35, "endOffset": 161}, {"referenceID": 15, "context": "In each trial, we use the standard setting (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and randomly sample the same number (20 for Amazon, Caltech, and Webcam; 8 for DSLR as there are only 8 images per category in the DSLR domain) of labelled images in the source domain as training set, and use all the unlabelled data in the target domain as the test set.", "startOffset": 43, "endOffset": 169}, {"referenceID": 12, "context": "In each trial, we use the standard setting (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and randomly sample the same number (20 for Amazon, Caltech, and Webcam; 8 for DSLR as there are only 8 images per category in the DSLR domain) of labelled images in the source domain as training set, and use all the unlabelled data in the target domain as the test set.", "startOffset": 43, "endOffset": 169}, {"referenceID": 31, "context": "In each trial, we use the standard setting (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010) and randomly sample the same number (20 for Amazon, Caltech, and Webcam; 8 for DSLR as there are only 8 images per category in the DSLR domain) of labelled images in the source domain as training set, and use all the unlabelled data in the target domain as the test set.", "startOffset": 43, "endOffset": 169}, {"referenceID": 10, "context": "Results In Table 1, we compare our method to five recent published methods: SVMA (Duan, Tsang, and Xu 2012), DAM (Duan et al. 2009), GFK (Gong et al.", "startOffset": 113, "endOffset": 131}, {"referenceID": 15, "context": "2009), GFK (Gong et al. 2012), SA (Fernando et al.", "startOffset": 11, "endOffset": 29}, {"referenceID": 12, "context": "2012), SA (Fernando et al. 2013), and TCA (Pan et al.", "startOffset": 10, "endOffset": 32}, {"referenceID": 30, "context": "2013), and TCA (Pan et al. 2009) as well as the no adaptation baseline (NA).", "startOffset": 15, "endOffset": 32}, {"referenceID": 9, "context": "Object Recognition with Deep Features The Office dataset is the standard benchmark (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015) for domain adaptation with deep features in object recognition.", "startOffset": 83, "endOffset": 149}, {"referenceID": 36, "context": "Object Recognition with Deep Features The Office dataset is the standard benchmark (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015) for domain adaptation with deep features in object recognition.", "startOffset": 83, "endOffset": 149}, {"referenceID": 13, "context": "Object Recognition with Deep Features The Office dataset is the standard benchmark (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015) for domain adaptation with deep features in object recognition.", "startOffset": 83, "endOffset": 149}, {"referenceID": 9, "context": "DECAF (Donahue et al. 2014) uses AlexNet (Krizhevsky, Sutskever, and Hinton 2012) pre-trained on ImageNet (Deng et al.", "startOffset": 6, "endOffset": 27}, {"referenceID": 8, "context": "2014) uses AlexNet (Krizhevsky, Sutskever, and Hinton 2012) pre-trained on ImageNet (Deng et al. 2009) and extracts the fc6 or fc7 layers in the source domains as features to train a classifier.", "startOffset": 84, "endOffset": 102}, {"referenceID": 36, "context": "DDC (Tzeng et al. 2014) adds a domain confusion loss to AlexNet (Krizhevsky, Sutskever, and Hinton 2012) and fine-tunes it on both the source and target domain.", "startOffset": 4, "endOffset": 23}, {"referenceID": 28, "context": "DAN (Long et al. 2015) and ReverseGrad (Ganin and Lempitsky 2015) are the two most recent domain adaptation approaches based on deep architectures.", "startOffset": 4, "endOffset": 22}, {"referenceID": 13, "context": "2015) and ReverseGrad (Ganin and Lempitsky 2015) are the two most recent domain adaptation approaches based on deep architectures.", "startOffset": 22, "endOffset": 48}, {"referenceID": 9, "context": "We follow the protocol of (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015) and conduct experiments on 5 random training/test splits and get the mean accuracy for each domain shift.", "startOffset": 26, "endOffset": 92}, {"referenceID": 36, "context": "We follow the protocol of (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015) and conduct experiments on 5 random training/test splits and get the mean accuracy for each domain shift.", "startOffset": 26, "endOffset": 92}, {"referenceID": 13, "context": "We follow the protocol of (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015) and conduct experiments on 5 random training/test splits and get the mean accuracy for each domain shift.", "startOffset": 26, "endOffset": 92}, {"referenceID": 15, "context": "Table 1: Object recognition accuracies of all 12 domain shifts on the Office-Caltech10 dataset (Gong et al. 2012) with SURF features, following the protocol of (Gong et al.", "startOffset": 95, "endOffset": 113}, {"referenceID": 15, "context": "2012) with SURF features, following the protocol of (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010).", "startOffset": 52, "endOffset": 178}, {"referenceID": 12, "context": "2012) with SURF features, following the protocol of (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010).", "startOffset": 52, "endOffset": 178}, {"referenceID": 31, "context": "2012) with SURF features, following the protocol of (Gong et al. 2012; Fernando et al. 2013; Gopalan, Li, and Chellappa 2011; Kulis, Saenko, and Darrell 2011; Saenko et al. 2010).", "startOffset": 52, "endOffset": 178}, {"referenceID": 15, "context": "Table 3: Object recognition accuracies of all 12 domain shifts on the Office-Caltech10 dataset (Gong et al. 2012) with SURF features, using the \u201cfully-transductive\u201d protocol.", "startOffset": 95, "endOffset": 113}, {"referenceID": 31, "context": "Table 2: Object recognition accuracies of all 6 domain shifts on the standard Office dataset (Saenko et al. 2010) with deep features, following the protocol of (Donahue et al.", "startOffset": 93, "endOffset": 113}, {"referenceID": 9, "context": "2010) with deep features, following the protocol of (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015).", "startOffset": 52, "endOffset": 118}, {"referenceID": 36, "context": "2010) with deep features, following the protocol of (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015).", "startOffset": 52, "endOffset": 118}, {"referenceID": 13, "context": "2010) with deep features, following the protocol of (Donahue et al. 2014; Tzeng et al. 2014; Ganin and Lempitsky 2015).", "startOffset": 52, "endOffset": 118}, {"referenceID": 33, "context": "2013), DANN (Ghifary, Kleijn, and Zhang 2014), DANBNN (Tommasi and Caputo 2013), DECAF (Donahue et al.", "startOffset": 54, "endOffset": 79}, {"referenceID": 9, "context": "2013), DANN (Ghifary, Kleijn, and Zhang 2014), DANBNN (Tommasi and Caputo 2013), DECAF (Donahue et al. 2014), DDC (Tzeng et al.", "startOffset": 87, "endOffset": 108}, {"referenceID": 36, "context": "2014), DDC (Tzeng et al. 2014), DAN (Long et al.", "startOffset": 11, "endOffset": 30}, {"referenceID": 28, "context": "2014), DAN (Long et al. 2015) and ReverseGrad (Ganin and Lempitsky 2015) as well as four no adaptation baselines (NA-fc6, NA-fc7, NA-FT6, and NA-FT7).", "startOffset": 11, "endOffset": 29}, {"referenceID": 13, "context": "2015) and ReverseGrad (Ganin and Lempitsky 2015) as well as four no adaptation baselines (NA-fc6, NA-fc7, NA-FT6, and NA-FT7).", "startOffset": 22, "endOffset": 48}, {"referenceID": 34, "context": "Table 4: Object recognition accuracies of all 6 domain shifts on the Testbed Cross-Dataset (Tommasi and Tuytelaars 2014) dataset with DECAF-fc7 features, using the \u201cfully-transductive\u201d protocol.", "startOffset": 91, "endOffset": 120}, {"referenceID": 8, "context": "C: Caltech256 dataset (Gregory, Alex, and Pietro 2007), I: ImageNet dataset (Deng et al. 2009), S: SUN dataset (Xiao et al.", "startOffset": 76, "endOffset": 94}, {"referenceID": 37, "context": "2009), S: SUN dataset (Xiao et al. 2010).", "startOffset": 22, "endOffset": 40}, {"referenceID": 34, "context": "To investigate the effect of the number of classes, we use the Testbed Cross-Dataset (Tommasi and Tuytelaars 2014) dataset and conduct experiments on all the 6 shifts.", "startOffset": 85, "endOffset": 114}, {"referenceID": 30, "context": "Results In Table 5, we compare our method to five published methods: TCA (Pan et al. 2009), GFS (Gopalan, Li, and Chellappa 2011), GFK (Gong et al.", "startOffset": 73, "endOffset": 90}, {"referenceID": 15, "context": "2009), GFS (Gopalan, Li, and Chellappa 2011), GFK (Gong et al. 2012), SCL (Blitzer, McDonald, and Pereira 2006), and KMM (Huang et al.", "startOffset": 50, "endOffset": 68}, {"referenceID": 22, "context": "2012), SCL (Blitzer, McDonald, and Pereira 2006), and KMM (Huang et al. 2006) as well as the no adaptation baseline (NA).", "startOffset": 58, "endOffset": 77}, {"referenceID": 29, "context": "As demonstrated in (Mahendran and Vedaldi 2015), high level deep features are more \u201cparts\u201d or \u201cobjects\u2019.", "startOffset": 19, "endOffset": 47}], "year": 2017, "abstractText": "Unlike human learning, machine learning often fails to handle changes between training (source) and test (target) input distributions. Such domain shifts, common in practical scenarios, severely damage the performance of conventional machine learning methods. Supervised domain adaptation methods have been proposed for the case when the target data have labels, including some that perform very well despite being \u201cfrustratingly easy\u201d to implement. However, in practice, the target domain is often unlabeled, requiring unsupervised adaptation. We propose a simple, effective, and efficient method for unsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL minimizes domain shift by aligning the second-order statistics of source and target distributions, without requiring any target labels. Even though it is extraordinarily simple\u2013it can be implemented in four lines of Matlab code\u2013CORAL performs remarkably well in extensive evaluations on standard benchmark datasets. \u201cEverything should be made as simple as possible, but not simpler.\u201d", "creator": "TeX"}}}