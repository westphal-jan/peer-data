{"id": "1511.06251", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Stochastic Modified Equations and Adaptive Stochastic Gradient Algorithms", "abstract": "Stochastic gradient algorithms (SGA) are increasingly popular in machine learning applications and have become \"the algorithm\" for extremely large scale problems. Although there are some convergence results, little is known about their dynamics. In this paper, We propose the method of stochastic modified equations (SME) to analyze the dynamics of the SGA. Using this technique, we can give precise characterizations for both the initial convergence speed and the eventual oscillations, at least in some special cases. Furthermore, the SME formalism allows us to characterize various speed-up techniques, such as introducing momentum, adjusting the learning rate and the mini-batch sizes. Previously, these techniques relied mostly on heuristics. Besides introducing simple examples to illustrate the SME formalism, we also apply the framework to improve the relaxed randomized Kaczmarz method for solving linear equations. The SME framework is a precise and unifying approach to understanding and improving the SGA, and has the potential to be applied to many more stochastic algorithms.", "histories": [["v1", "Thu, 19 Nov 2015 16:49:33 GMT  (3851kb)", "http://arxiv.org/abs/1511.06251v1", null], ["v2", "Fri, 20 Nov 2015 19:58:15 GMT  (4801kb)", "http://arxiv.org/abs/1511.06251v2", "Changes: 1. Fixed a sign mistake in eq. (74). 2. Factor of d in eq. (98), and thus figure 10's estimate of k^*. 3. Fixed some typos and figure scales"], ["v3", "Tue, 20 Jun 2017 13:56:33 GMT  (1326kb,D)", "http://arxiv.org/abs/1511.06251v3", "Major changes including a proof of the weak approximation, asymptotic expansions and application-oriented adaptive algorithms"]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["qianxiao li", "cheng tai", "weinan e"], "accepted": true, "id": "1511.06251"}, "pdf": {"name": "1511.06251.pdf", "metadata": {"source": "CRF", "title": "Dynamics of Stochastic Gradient Algorithms", "authors": ["Qianxiao Li"], "emails": ["qianxiao@math.princeton.edu", "chengt@math.princeton.edu", "weinan@math.princeton.edu"], "sections": [{"heading": null, "text": "ar Xiv: 151 1.06 251v 1Keywords: stochastic gradient algorithms, stochastically modified equations, dynamics, optimal control"}, {"heading": "1. Introduction", "text": "In fact, most of them will be able to play by the rules that they have shown in recent years, and they will be able to play by the rules that they have shown."}, {"heading": "2. Stochastic modified equations", "text": "In this section, we present the concept of the SME equation, followed by two concrete examples to illustrate the approach. As discussed earlier, the main purpose of this work is to introduce this technique and how we can use it to use some numerical examples to justify the SME approach. The motivation behind the SME is the following: At each step of the SGA iterations, the exact statement is made as to how the SME iterations randomly and uniformly select the original SGA distribution from the n functions. Since the SME approximation is an unbiased estimator of f. HenceExk + 1 = xk (4) This can be regarded as the forward Euler scheme for solving the differential equation."}, {"heading": "2.1 One dimensional example", "text": "Leave f1 (x) = (x \u2212 a) 2 and f2 (x \u2212 b) 2 where x, a, b \u00b2 R is reached. We want mizef (x) = 12 f1 (x) \u2212 \u2212 \u2212 p, (13) and we have xk + 1 \u2212 \u03b1 = (a + b) the point at which the minimum is reached. The GD step to solve this problem is isxk + 1 = xk \u2212 p, (14) i.e. the convergence is linear. On the other hand, the SGA step is isxk + 1 = xp, (15) where it is (xk \u2212 \u03b1). We are i.d random variable that takes value 1 and 2 with probability. Figure 2 (a) shows the GD and SGA problem (xk \u2212 p)."}, {"heading": "2.2 Multi-dimensional example", "text": "Our second example is a multi-dimensional problem. Consider Minimizingf (x) = 12nn \u2211 i = 1 (xi + 1) 2 + \u03bbi (xi \u2212 1) 2), x \u2212 Kong Rd. (23) Minimizing this function is equivalent to solving a particular inconsistent linear system Ax = b in which \u03bbi represents the eigenvalues of ATA. (24) Using the technique introduced previously, we obtain the following SME: dXi (t) = 2\u03bbixin, (t) ij = 4\u03bb2i (t))), dBi (t), i = 1, \u00b7 \u00b7 The exact solution to (25) is complicated."}, {"heading": "3. Acceleration techniques.", "text": "We have seen in the previous section that the SME provides a precise characterization of the dynamics of the SGA when the learning rate is sufficiently low. In this section we will show how the SME can also be useful for analyzing and improving acceleration techniques of the classic SGA. Three of these we will discuss in detail, namely the addition of dynamics, adaptation of learning rates and the introduction of mini-batch."}, {"heading": "3.1 SGA with momentum", "text": "The classical impulse method is a method for accelerating gradient descendence. For quadratic functions, it can be shown that the impulse reduces the number of iterations from O (III) to O (IV) if the impulse is the conditional number of the problem. More recently, the impulse has been used in conjunction with the SME approach. It has been empirically observed that SGA accelerates convergence with the impulse, see, for example, Sutskever et al. (2013). We study the effects of the impulse using the SME approach. The usual SGA with dynamics runs as follows: x0 = x0, v 0 = v0, then iteratethe following two steps: {vk + 1 = \u00b5vk \u2212 v \u00b2 k (xk) xk + 1 = xk + 1, (32) for k = 0, 1, 2, \u00b7 \u00b7 \u00b7 \u00b7 v2."}, {"heading": "3.2 Optimal learning rate", "text": "Remember that when using SGA to minimize a generic function, good performance is often observed at an early stage. However, after a series of iterations, the objective function begins to fluctuate and does not decrease further. We called this point the transition point of the SGA. In practice, a common method of not reaching this point is the gradual decrease in the learning rate. The problem of the optimal learning rate can be formulated as follows: Given a fixed duration, how do you choose a learning schedule to minimize the error at the end of the run?"}, {"heading": "3.2.1 Optimal control setup", "text": "The iteration step for the SGA with adapted learning rates can be written: asxk + 1 = xk \u2212 \u03b7uk - fk (xk), (46), where uk (0, 1) represents the factor by which the learning rate in the current step is reduced. (The corresponding SME is {dX (t) = \u2212 u (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t), f (t, f (t), f (t), f (t), f (t, f (t), f (t), f (t (t), f (t), f (t, f (t), f (t), f (t (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t, f (t), f (t), f (t (t), f (t (t), f (t), f (t, f (t), f (t), f (t ("}, {"heading": "3.2.2 Exact Solution of the HJB", "text": "First, we perform the minimization via u: min u \u0432 [0,1] {F (u >, m) Vm} = \u2212 m2 \u03b7 Vm \u2264 2\u03b7, Vm \u2265 0 \u2212 \u043c, 4 (\u03b7 \u2212 m) Vm > 2\u03b7, Vm \u2265 0 or m \u2264 \u03b7, Vm < 0, 0 m > \u03b7, Vm < 0. (58) The minimization of the control is inverted in (56) results in a Hamilton-Jacobi equation that can easily be solved by the method of characters. isV (m, t) = m\u03b7 + m (T \u2212 t) m \u2264 < the optimal control is learning. (59) The substitution (58) results in an equation that can be solved simply by the method of characteristics."}, {"heading": "3.3 Optimal mini-batch size", "text": "Another approach to optimizing the SGA is the use of mini-batch, in which we use more than one sample of gradient Fk for each iteration. Essentially, this is a method of reducing variance, where a larger batch size leads to less variance. However, increasing the batch size also involves computational effort. We will use the stochastic modified equation to find a balance between the two."}, {"heading": "3.3.1 Optimal control setup", "text": "The SGA iteration with mini-stacking can be written as asxk + 1 = xk \u2212 \u03b7 1 + uk1 + uk \u2211 j = 1 \u0445f\u03b3j (xk), (64), where uk is a non-negative integer and therefore 1 + uk is the stack size in the current iteration. the corresponding stochastic modified equation isdX (t) = \u2212 f (X (t))) dt + 270 (t) \u03c3 (X (t)) dB (t), (65) where u (t) \u2265 0 for all t [0, T]. To perform precise calculations, let us look again at the one-dimensional example (52) for which the modified equation isdX (t) = \u2212 2X (t) dt + 2 x (t) dt + 1 (t) dB (t) \u2265 1 (t) dB (t) (t), (66) and the moment equation is {m = F (u (t), m (t): 4 + (T) (1) (T)."}, {"heading": "3.3.2 Exact Solution of the HJB", "text": "If we do the minimization via u, we cannot get the results. < < < p > p > p > p > p > p > p > p > p > p > p > p > p p > p (p) p (p) p (p) p (p) p (p) p (p) p (p) p (p) p (p) p \u2212 p (p) p \u2212 p) p (p) p (p) p (p) p (p) p) p (p) p (p) p) p (p) p (p) p (p) p (p) p (p) p (p) p (p) p (p) p) p (p) p (p) p) p (p) p (p) p) p (p) p (p) p (p) p (p) p (p) p) p (p) p (p) p) p (p) p (p) p) p (p) p (p) p) p (p) p) p (p) p (p) p) p (p) p) p (p) p (p) p) p (p) p) p (p) p (p) p) p (p) p (p) p) p (p) p) p (p) p (p) p) p (p) p (p) p) p (p) p (p) p) p (p (p) p (p) p (p) p) p) p (p (p) (p) p (p) (p) p (p) (p) p (p) p) p (p) p (p (p) (p) p (p) p (p (p (p) p) p (p (p) p (p (p) p (p) (p) p (p) p) p (p (p (p) p (p) p (p) p) p (p (p (p) p) (p (p) p (p) p) p (p (p) p) p (p (p) p (p) (p) p (p (p) p) p (p) p (p (p (p) p) p (p"}, {"heading": "4. Application to General Linear Equation", "text": "In this section, we translate what we have learned so far into practical procedures and apply it to solving general linear equations, one of the most basic and important test environments for SGA algorithms."}, {"heading": "4.1 Dynamics", "text": "The essential dynamic characteristic is the same as the example in Section 2.2. For general A, 1n, \u2211 i, fi (x), fi (x), fi (x), T = 2n, iai (a T i x \u2212 bi), 2aTi, f (x), f (x), f (x), T = 4 n2AT (Ax \u2212 b) (x), TA (79) The SME is then: {dX = \u2212 2 m AT (AX \u2212 b), f (X), p (x), p (x), i), fi (x), f (x), f (x), f (x), f (x). (80) The drift matrix and the volatility matrix, which generally does not oscillate, hence, we cannot expect them to be diagonalized at the same time. To perform the analysis, we have to make some approximations. We replace the volatility with a constant matrix."}, {"heading": "4.2 Momentum", "text": "Let us now examine the SGA with dynamics applied to the solution of the contradictory equation Ax = b. In particular, we demonstrate the choice of the optimal \u00b5. With the same notation we write X = UY + x *, V = UZ. Then the second moment equations dY 2i = 2 \u03b7 YiZidt dYiZi = (\u2212 2n\u03bbiY 2i + \u00b5 \u2212 1 \u03b7 YiZi) dt dZ2i = (\u2212 4n\u03bbiZi + 2 (\u00b5 \u2212 1) \u03b7 Z2i + \u03b7\u03b2i) dt (85) for i = 1, \u00b7 \u00b7, i.e. if we set the initial quantity to zero, we see that EY 2i = \u03b2i\u03b7n4\u03bbi (\u00b5 \u2212 1) is also an average convergence. FortceE-Xt \u2212 x \u00b2 \u00b2 \u00b2 \u00b2 is the optimal starting time (\u00b5 \u2212 1)."}, {"heading": "4.3 Learning rate schedule", "text": "Here we apply the knowledge gained from the 3.2 section to select the optimum learning rate. We define the total error rate (t): = E-X x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "4.4 Mini-batch schedule", "text": "The current equation for the mini-stack sample is used in addition to the usual stack sample. < n (t) < n (t) n m (t) + m (0) + m (0) = m0. (99) We will only consider the case where \u03b3 is sufficiently small (g) \u2212 106 \u2212 n (T) to make a mini-stack sample desirable. HJB's solution yields the optimal stack sample (t) = {0 \u2264 t < T \u2212 t (t) n (100), with HJB (t) obtaining the optimal stack sample (t). (101) We can estimate \u03b2 as before, but we must also determine the stack sample. To do this, we fix M as the number of stack samples we will use."}, {"heading": "5. Discussion", "text": "In this paper, we have introduced the stochastic modified equation approach for analyzing stochastic gradient techniques, which we should use with respect to the various SME techniques. For simple prototypical examples, we can perform exact calculations that quantify the precise stochastic dynamics of the SGA. However, the most important features can be summarized as follows: \u2022 In small times, SGA iteration is very efficient, because in the appropriate SME methods, drift dominates volatility. \u2022 In this regime, for generic problems, the SGA is expected to be as fast as GD, but the latter includes n times the calculation cost (based on gradient evaluations), where n is the number of functions that make up the objective function f. \u2022 If the error O (\u03b7) is, we enter a regime in which the SGA fails to further reduce the objective function due to variance. The SME reflects this as the volatility that dominates the two regiments that we call the transition time."}], "references": [{"title": "Non-strongly-convex smooth stochastic approximation with convergence rate o (1/n)", "author": ["Francis Bach", "Eric Moulines"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bach and Moulines.,? \\Q2013\\E", "shortCiteRegEx": "Bach and Moulines.", "year": 2013}, {"title": "Practical recommendations for gradient-based training of deep architectures", "author": ["Yoshua Bengio"], "venue": "In Neural Networks: Tricks of the Trade,", "citeRegEx": "Bengio.,? \\Q2012\\E", "shortCiteRegEx": "Bengio.", "year": 2012}, {"title": "The stability properties of a coupled pair of non-linear partial difference equations", "author": ["Bart J Daly"], "venue": "Mathematics of Computation,", "citeRegEx": "Daly.,? \\Q1963\\E", "shortCiteRegEx": "Daly.", "year": 1963}, {"title": "Random perturbations of dynamical systems, volume 260", "author": ["Mark I Freidlin", "Joseph Sz\u00fccs", "Alexander D Wentzell"], "venue": "Springer Science & Business Media,", "citeRegEx": "Freidlin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Freidlin et al\\.", "year": 2012}, {"title": "Heuristic stability theory for finite-difference equations", "author": ["CW Hirt"], "venue": "Journal of Computational Physics,", "citeRegEx": "Hirt.,? \\Q1968\\E", "shortCiteRegEx": "Hirt.", "year": 1968}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Johnson and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Johnson and Zhang.", "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks. Advances in neural information processing", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Yann LeCun", "Bernhard Boser", "John S Denker", "Donnie Henderson", "Richard E Howard", "Wayne Hubbard", "Lawrence D Jackel"], "venue": "Neural computation,", "citeRegEx": "LeCun et al\\.,? \\Q1989\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1989}, {"title": "Non-asymptotic analysis of stochastic approximation algorithms for machine learning", "author": ["Eric Moulines", "Francis R Bach"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Moulines and Bach.,? \\Q2011\\E", "shortCiteRegEx": "Moulines and Bach.", "year": 2011}, {"title": "Stochastic gradient descent, weighted sampling, and the randomized kaczmarz algorithm", "author": ["Deanna Needell", "Rachel Ward", "Nati Srebro"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Needell et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Needell et al\\.", "year": 2014}, {"title": "Difference methods and the equations of hydrodynamics", "author": ["WF Noh", "MH Protter"], "venue": "Technical report,", "citeRegEx": "Noh and Protter.,? \\Q1960\\E", "shortCiteRegEx": "Noh and Protter.", "year": 1960}, {"title": "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Mathematical Programming,", "citeRegEx": "Shalev.Shwartz and Zhang.,? \\Q2014\\E", "shortCiteRegEx": "Shalev.Shwartz and Zhang.", "year": 2014}, {"title": "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes", "author": ["Ohad Shamir", "Tong Zhang"], "venue": "arXiv preprint arXiv:1212.1824,", "citeRegEx": "Shamir and Zhang.,? \\Q2012\\E", "shortCiteRegEx": "Shamir and Zhang.", "year": 2012}, {"title": "A randomized kaczmarz algorithm with exponential convergence", "author": ["Thomas Strohmer", "Roman Vershynin"], "venue": "Journal of Fourier Analysis and Applications,", "citeRegEx": "Strohmer and Vershynin.,? \\Q2009\\E", "shortCiteRegEx": "Strohmer and Vershynin.", "year": 2009}, {"title": "On the importance of initialization and momentum in deep learning", "author": ["Ilya Sutskever", "James Martens", "George Dahl", "Geoffrey Hinton"], "venue": "In Proceedings of the 30th international conference on machine learning", "citeRegEx": "Sutskever et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2013}, {"title": "The modified equation approach to the stability and accuracy analysis of finite-difference methods", "author": ["RF Warming", "BJ Hyett"], "venue": "Journal of computational physics,", "citeRegEx": "Warming and Hyett.,? \\Q1974\\E", "shortCiteRegEx": "Warming and Hyett.", "year": 1974}, {"title": "A proximal stochastic gradient method with progressive variance reduction", "author": ["Lin Xiao", "Tong Zhang"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Xiao and Zhang.,? \\Q2014\\E", "shortCiteRegEx": "Xiao and Zhang.", "year": 2014}], "referenceMentions": [{"referenceID": 12, "context": "Although there have been some convergence results of the SGA algorithms and their variants (Shamir and Zhang, 2012; Moulines and Bach, 2011; Needell et al., 2014; Xiao and Zhang, 2014; Shalev-Shwartz and Zhang, 2014; Bach and Moulines, 2013), less is known about their dynamics.", "startOffset": 91, "endOffset": 241}, {"referenceID": 8, "context": "Although there have been some convergence results of the SGA algorithms and their variants (Shamir and Zhang, 2012; Moulines and Bach, 2011; Needell et al., 2014; Xiao and Zhang, 2014; Shalev-Shwartz and Zhang, 2014; Bach and Moulines, 2013), less is known about their dynamics.", "startOffset": 91, "endOffset": 241}, {"referenceID": 9, "context": "Although there have been some convergence results of the SGA algorithms and their variants (Shamir and Zhang, 2012; Moulines and Bach, 2011; Needell et al., 2014; Xiao and Zhang, 2014; Shalev-Shwartz and Zhang, 2014; Bach and Moulines, 2013), less is known about their dynamics.", "startOffset": 91, "endOffset": 241}, {"referenceID": 16, "context": "Although there have been some convergence results of the SGA algorithms and their variants (Shamir and Zhang, 2012; Moulines and Bach, 2011; Needell et al., 2014; Xiao and Zhang, 2014; Shalev-Shwartz and Zhang, 2014; Bach and Moulines, 2013), less is known about their dynamics.", "startOffset": 91, "endOffset": 241}, {"referenceID": 11, "context": "Although there have been some convergence results of the SGA algorithms and their variants (Shamir and Zhang, 2012; Moulines and Bach, 2011; Needell et al., 2014; Xiao and Zhang, 2014; Shalev-Shwartz and Zhang, 2014; Bach and Moulines, 2013), less is known about their dynamics.", "startOffset": 91, "endOffset": 241}, {"referenceID": 0, "context": "Although there have been some convergence results of the SGA algorithms and their variants (Shamir and Zhang, 2012; Moulines and Bach, 2011; Needell et al., 2014; Xiao and Zhang, 2014; Shalev-Shwartz and Zhang, 2014; Bach and Moulines, 2013), less is known about their dynamics.", "startOffset": 91, "endOffset": 241}, {"referenceID": 3, "context": "Its origin may be attributed to Hirt (1968); Noh and Protter (1960); Daly (1963); Warming and Hyett (1974).", "startOffset": 32, "endOffset": 44}, {"referenceID": 3, "context": "Its origin may be attributed to Hirt (1968); Noh and Protter (1960); Daly (1963); Warming and Hyett (1974).", "startOffset": 32, "endOffset": 68}, {"referenceID": 2, "context": "Its origin may be attributed to Hirt (1968); Noh and Protter (1960); Daly (1963); Warming and Hyett (1974).", "startOffset": 69, "endOffset": 81}, {"referenceID": 2, "context": "Its origin may be attributed to Hirt (1968); Noh and Protter (1960); Daly (1963); Warming and Hyett (1974). The early applications was the analysis of the consistency and stability of numerical methods for partial differential equations, see Hirt (1968); Warming and Hyett (1974).", "startOffset": 69, "endOffset": 107}, {"referenceID": 2, "context": "Its origin may be attributed to Hirt (1968); Noh and Protter (1960); Daly (1963); Warming and Hyett (1974). The early applications was the analysis of the consistency and stability of numerical methods for partial differential equations, see Hirt (1968); Warming and Hyett (1974).", "startOffset": 69, "endOffset": 254}, {"referenceID": 2, "context": "Its origin may be attributed to Hirt (1968); Noh and Protter (1960); Daly (1963); Warming and Hyett (1974). The early applications was the analysis of the consistency and stability of numerical methods for partial differential equations, see Hirt (1968); Warming and Hyett (1974). The method of modified equations consists of creating a differential equation which approximates the given numerical scheme more accurately than the original equation.", "startOffset": 69, "endOffset": 280}, {"referenceID": 12, "context": "Strohmer and Vershynin (2009); Needell et al.", "startOffset": 0, "endOffset": 30}, {"referenceID": 9, "context": "Strohmer and Vershynin (2009); Needell et al. (2014). Introducing the relaxation, the Kaczmarz iteration rule is x = x + \u03b1 b\u03b3k \u2212 \u3008a\u03b3 k , xk\u3009 \u2016a\u03b3\u20162 a \u03b3k .", "startOffset": 31, "endOffset": 53}, {"referenceID": 14, "context": "It has been empirically observed that SGA with momentum accelerates convergence, see for example, Sutskever et al. (2013). We study the effects of momentum using the SME approach.", "startOffset": 98, "endOffset": 122}, {"referenceID": 12, "context": "In the literature, a learning rate schedule of O (1/k) is usually proposed to ensure convergence (Shamir and Zhang, 2012).", "startOffset": 97, "endOffset": 121}, {"referenceID": 5, "context": "In particular, the optimal control result states that instead of using a batch size that is constant in time (as is often applied in practice, see for example, Krizhevsky et al. (2012); LeCun et al.", "startOffset": 160, "endOffset": 185}, {"referenceID": 5, "context": "In particular, the optimal control result states that instead of using a batch size that is constant in time (as is often applied in practice, see for example, Krizhevsky et al. (2012); LeCun et al. (1989); Bengio (2012)), the better strategy is to perform an aggressive minibatching at the end.", "startOffset": 160, "endOffset": 206}, {"referenceID": 1, "context": "(1989); Bengio (2012)), the better strategy is to perform an aggressive minibatching at the end.", "startOffset": 8, "endOffset": 22}], "year": 2017, "abstractText": "Stochastic gradient algorithms (SGA) are increasingly popular in machine learning applications and have become \u201cthe algorithm\u201d for extremely large scale problems. Although there are some convergence results, little is known about their dynamics. In this paper, We propose the method of stochastic modified equations (SME) to analyze the dynamics of the SGA. Using this technique, we can give precise characterizations for both the initial convergence speed and the eventual oscillations, at least in some special cases. Furthermore, the SME formalism allows us to characterize various speed-up techniques, such as introducing momentum, adjusting the learning rate and the mini-batch sizes. Previously, these techniques relied mostly on heuristics. Besides introducing simple examples to illustrate the SME formalism, we also apply the framework to improve the relaxed randomized Kaczmarz method for solving linear equations. The SME framework is a precise and unifying approach to understanding and improving the SGA, and has the potential to be applied to many more stochastic algorithms.", "creator": "LaTeX with hyperref package"}}}