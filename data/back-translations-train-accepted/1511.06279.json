{"id": "1511.06279", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Neural Programmer-Interpreters", "abstract": "We propose the neural programmer-interpreter (NPI): a recurrent and compositional neural network that learns to represent and execute programs. NPI has three learnable components: a task-agnostic recurrent core, a persistent key-value program memory, and domain-specific encoders that enable a single NPI to operate in multiple perceptually diverse environments with distinct affordances. By learning to compose lower-level programs to express higher-level programs, NPI reduces sample complexity and increases generalization ability compared to sequence-to-sequence LSTMs. The program memory allows efficient learning of additional tasks by building on existing programs. NPI can also harness the environment (e.g. a scratch pad with read-write pointers) to cache intermediate results of computation, lessening the long-term memory burden on recurrent hidden units. In this work we train the NPI with fully-supervised execution traces; each program has example sequences of calls to the immediate subprograms conditioned on the input. Rather than training on a huge number of relatively weak labels, NPI learns from a small number of rich examples. We demonstrate the capability of our model to learn several types of compositional programs: addition, sorting, and canonicalizing 3D models. Furthermore, a single NPI learns to execute these programs and all 21 associated subprograms.", "histories": [["v1", "Thu, 19 Nov 2015 17:49:32 GMT  (845kb,D)", "http://arxiv.org/abs/1511.06279v1", "ICLR 2016 conference submission"], ["v2", "Mon, 23 Nov 2015 19:30:01 GMT  (846kb,D)", "http://arxiv.org/abs/1511.06279v2", "ICLR 2016 conference submission"], ["v3", "Tue, 8 Dec 2015 18:11:35 GMT  (845kb,D)", "http://arxiv.org/abs/1511.06279v3", "ICLR 2016 conference submission"], ["v4", "Mon, 29 Feb 2016 11:12:36 GMT  (882kb,D)", "http://arxiv.org/abs/1511.06279v4", "ICLR 2016 conference submission"]], "COMMENTS": "ICLR 2016 conference submission", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["scott reed", "nando de freitas"], "accepted": true, "id": "1511.06279"}, "pdf": {"name": "1511.06279.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["NEURAL PROGRAMMER-INTERPRETERS", "Scott Reed"], "emails": ["scott.ellison.reed@gmail.com", "nandodefreitas@google.com"], "sections": [{"heading": null, "text": "We propose the Neural Programmer-Interpreter (NPI): a recursive and compositional neural network that learns to represent and execute programs. NPI has three learnable components: a task-agnostic recursive core, a persistent key-value program memory, and domain-specific encoders that allow a single NPI to work in multiple perceptibly diverse environments with different affordability. By learning to compose lower-level programs to express higher-level programs, NPI reduces the complexity of samples and increases generalization capability compared to LSTMs with sequence sequence sequence sequence sequence sequences. Program memory allows efficient learning of additional tasks by building on existing programs. NPI can also use the environment (e.g. a scratch pad with write and read pointers) to cache interim results of the calculation, thereby reducing the load of long-term memory on repetitive work by comparatively large numbers of NPI, rather than having the number of repetitive units in each program."}, {"heading": "1 INTRODUCTION", "text": "This year, it has reached the stage where it will be able to take the measures mentioned in order to reactivate them."}, {"heading": "2 RELATED WORK", "text": "Several ideas related to our approach have a long history. For example, the idea of using dynamically programmable networks, in which the activations of a network become weights (the program) of a second network, was mentioned in the Sigma-Pi section of the influential PDP paper (Rumelhart et al., 1986), an idea that appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relationships and in (Donnarumma et al., 2015) as a key concept of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, in which one learns the parameters of a slowly changing network, which in turn induces context-dependent weight changes for a second rapidly changing network. These approaches were shown only in very limited settings. In cognitive science, several theories of brain cells that control other parts of the brain were studied, which in turn induce context-dependent weight changes, were suggested for a second rapidly changing network. These approaches were presented in very limited settings. In cognitive science, several theories of brain cells that control other parts of the brain, in order to perform multiple tasks, were suggested for example, ma ma ma ma ma ma ma ma ma ma ma. In cognitive science, several theories of brain cells that control other parts of the brain have been proposed in 2003, for example, ma ma ma ma ma ma ma ma ma ma ma ma ma (see: ma ma ma ma ma ma ma ma ma ma ma ma ma ma) and ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma ma (for example)."}, {"heading": "3 MODEL", "text": "The NPI core is a long-term short-term memory (LSTM) network (Hochreiter & Schmidhuber, 1997) that acts as a router between programs based on the current state observation and previous hidden state. At each step, the core module can select a different program to be called using content-based addressing; it outputs the likelihood of terminating the current program with a single binary unit. If this probability is exceeded (we used 0.5), the caller is given back control by cracking the hidden units of the caller and uncoupling the program from a program call stack and continuing execution in that context; the NPI can also optionally write arguments (ARG) that are passed to the called subroutines by reference or value; for example, an argument could point to a specific position in the input sequence (after reference), or it could specify a number of programs that consist of a particular sequence in the following state of the observation."}, {"heading": "3.1 INFERENCE", "text": "The only question is how it could come to such a development. (...) The only question is whether it can come to such a development at all. (...) The question is whether it can come to such a development at all. (...) The question is whether it can come to such a development at all. (...) The only question is whether it can come to such a development at all. (...) The only question is whether it can come to such a development at all. (...) The only question is whether it can come to such a development at all. (...) The only question is whether it can come to such a development at all. \"(...) The only question is whether it can come to such a development at all. (...) The only question is how it can come to such a development. (...) The only question is whether it can come to such a development at all. (...)"}, {"heading": "3.2 TRAINING", "text": "In order to explore the execution of programs, we must prolong them. (...) We must directly maximize the probability of execution. (...) We must track the execution of programs according to the length of the input. (...) We must apply the chain rule to model the common probability. (...) We must prolong the argumentation of programs. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them. (...) We must prolong them."}, {"heading": "4 EXPERIMENTS", "text": "This section describes the environment and function of the state encoder for each task and shows exemplary results and accuracy of predictions. For all tasks, the core LSTM had two layers of size 256. We trained the NPI model and all program embedding together with RMSprop at the base learning rate 0.0001, batch size 1 and reduced the learning rate by a factor of 0.95 in 10,000 steps."}, {"heading": "4.1 TASK AND ENVIRONMENT DESCRIPTIONS", "text": "In this section, we provide an overview of the tasks used to evaluate our model."}, {"heading": "4.2 SAMPLE COMPLEXITY AND GENERALIZATION", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "4.3 LEARNING NEW PROGRAMS WITH A FIXED CORE", "text": "One challenge for continuous learning of neural network-based agents is that training on new tasks and experiences can lead to deterioration in performance for old tasks. Learning new tasks may require significant changes in network weights, so care must be taken to avoid catastrophic forgetting (Mccloskey & Cohen, 1989; OReilly et al., 2014).With NPI, one solution is to correct the weights of the core routing module and make sparse updates to program memory. When adding a new program, the routing calculation of the core module is completely unaffected; all learning for a new task takes place in the embedding space of the program. Of course, adding new programs to memory adds a new program selection at each step, and an old program may erroneously call a newly added program. To overcome this, learning a new set of program vectors with a fixed core in practice will not only train on the tracks of the program, but also on the tracks of existing programs."}, {"heading": "4.4 SOLVING MULTIPLE TASKS WITH A SINGLE NETWORK", "text": "In this section, we conduct a controlled experiment to compare the performance of a multi-task NPI with multiple single-task NPI models. Table 1 shows the results for the addition, sorting, and canonization of 3D vehicle models. We trained and evaluated 10-digit numbers for addition, length-5 arrays for sorting, and up to four-stage trajectories for canonization. As shown in Table 1, a single multi-task NPI can learn all three programs (and necessarily the 21 subroutines) with modest performance deterioration compared to an NPI trained on single tasks."}, {"heading": "5 CONCLUSION", "text": "We have shown that the NPI can learn programs in very different environments with different affordability. In the context of sorting, we have shown that the NPI has a very strong generalization compared to sequence-to-sequence LSTMs. We have also shown how a trained, solid-core NPI can continue to learn new programs without forgetting programs that have already been learned."}, {"heading": "ACKNOWLEDGMENTS", "text": "We sincerely thank Arun Nair and Ed Grefenstette for their helpful suggestions."}, {"heading": "6 APPENDIX", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 LISTING OF LEARNED PROGRAMS", "text": "Below we list the programs learned from our model:"}, {"heading": "6.2 GENERATED EXECUTION TRACE OF BUBBLESORT", "text": "Figure 8 shows the sequence of program calls for BUBBLESORT. Pointers 1 and 2 are used to supplement the \"bubble\" operation, which involves comparing and exchanging adjacent array elements. The third pointer (referred to as \"PTR 3\" in the trace) is used to count the number of calls to BUBBLE. After each call to RESET, the swapping pointers are moved to the beginning of the array and the counter pointer is moved forward by 1. Once it reaches the end of the scratch pad, the model learns to stop executing BUBBLESORT."}], "references": [{"title": "Neural reuse: A fundamental organizational principle of the brain", "author": ["Anderson", "Michael L"], "venue": "Behavioral and Brain Sciences, 33:245\u2013266,", "citeRegEx": "Anderson and L.,? \\Q2010\\E", "shortCiteRegEx": "Anderson and L.", "year": 2010}, {"title": "Programmable reinforcement learning agents", "author": ["Andre", "David", "Russell", "Stuart J"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Andre et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Andre et al\\.", "year": 2001}, {"title": "Hierarchical reinforcement learning with the MAXQ value function decomposition", "author": ["Dietterich", "Thomas G"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Dietterich and G.,? \\Q2000\\E", "shortCiteRegEx": "Dietterich and G.", "year": 2000}, {"title": "Programming in the brain: A neural network theoretical framework", "author": ["Donnarumma", "Francesco", "Prevete", "Roberto", "Trautteur", "Giuseppe"], "venue": "Connection Science,", "citeRegEx": "Donnarumma et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Donnarumma et al\\.", "year": 2012}, {"title": "A programmerinterpreter neural network architecture for prefrontal cognitive control", "author": ["Donnarumma", "Francesco", "Prevete", "Roberto", "Chersi", "Fabian", "Pezzulo", "Giovanni"], "venue": "International Journal of Neural Systems,", "citeRegEx": "Donnarumma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Donnarumma et al\\.", "year": 2015}, {"title": "3D object detection and viewpoint estimation with a deformable 3D cuboid model", "author": ["Fidler", "Sanja", "Dickinson", "Sven", "Urtasun", "Raquel"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Fidler et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Fidler et al\\.", "year": 2012}, {"title": "Long short-term memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Hierarchical apprenticeship learning with application to quadruped locomotion", "author": ["Kolter", "Zico", "Abbeel", "Pieter", "Ng", "Andrew Y"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kolter et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kolter et al\\.", "year": 2008}, {"title": "Catastrophic interference in connectionist networks: The sequential learning problem", "author": ["Mccloskey", "Michael", "Cohen", "Neal J"], "venue": "In The psychology of learning and motivation,", "citeRegEx": "Mccloskey et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Mccloskey et al\\.", "year": 1989}, {"title": "Building program vector representations for deep learning", "author": ["Mou", "Lili", "Li", "Ge", "Liu", "Yuxuan", "Peng", "Hao", "Jin", "Zhi", "Xu", "Yan", "Zhang", "Lu"], "venue": "arXiv preprint arXiv:1409.3358,", "citeRegEx": "Mou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mou et al\\.", "year": 2014}, {"title": "Complementary learning systems", "author": ["OReilly", "Randall C", "Bhattacharyya", "Rajan", "Howard", "Michael D", "Ketz", "Nicholas"], "venue": "Cognitive Science,", "citeRegEx": "OReilly et al\\.,? \\Q2014\\E", "shortCiteRegEx": "OReilly et al\\.", "year": 2014}, {"title": "Modular inverse reinforcement learning for visuomotor behavior", "author": ["Rothkopf", "ConstantinA", "Ballard", "DanaH"], "venue": "Biological Cybernetics,", "citeRegEx": "Rothkopf et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rothkopf et al\\.", "year": 2013}, {"title": "Parallel distributed processing: Explorations in the microstructure of cognition, vol. 1. chapter A General Framework for Parallel", "author": ["D.E. Rumelhart", "G.E. Hinton", "J.L. McClelland"], "venue": "Distributed Processing,", "citeRegEx": "Rumelhart et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1986}, {"title": "Universal value function approximators", "author": ["Schaul", "Tom", "Horgan", "Daniel", "Gregor", "Karol", "Silver", "David"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Schaul et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schaul et al\\.", "year": 2015}, {"title": "Learning to control fast-weight memories: An alternative to dynamic recurrent networks", "author": ["Schmidhuber", "J\u00fcrgen"], "venue": "Neural Computation,", "citeRegEx": "Schmidhuber and J\u00fcrgen.,? \\Q1992\\E", "shortCiteRegEx": "Schmidhuber and J\u00fcrgen.", "year": 1992}, {"title": "Controlled and automatic processing: behavior, theory, and biological mechanisms", "author": ["Schneider", "Walter", "Chein", "Jason M"], "venue": "Cognitive Science,", "citeRegEx": "Schneider et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Schneider et al\\.", "year": 2003}, {"title": "Learning options through human interaction", "author": ["Subramanian", "Kaushik", "Isbell", "Charles", "Thomaz", "Andrea"], "venue": "In IJCAI Workshop on Agents Learning Interactively from Human Teachers,", "citeRegEx": "Subramanian et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Subramanian et al\\.", "year": 2011}, {"title": "Using matrices to model symbolic relationship", "author": ["Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Sutskever et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2009}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing", "author": ["Sutskever", "Ilya", "Vinyals", "Oriol", "Le", "Quoc VV"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning", "author": ["Sutton", "Richard S", "Precup", "Doina", "Singh", "Satinder"], "venue": "Artificial Intelligence,", "citeRegEx": "Sutton et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1999}, {"title": "Learning to execute", "author": ["Zaremba", "Wojciech", "Sutskever", "Ilya"], "venue": "arXiv preprint arXiv:1410.4615,", "citeRegEx": "Zaremba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 12, "context": "program) of a second network was mentioned in the Sigma-Pi units section of the influential PDP paper (Rumelhart et al., 1986).", "startOffset": 102, "endOffset": 126}, {"referenceID": 4, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control.", "startOffset": 115, "endOffset": 140}, {"referenceID": 16, "context": "(2008) and Rothkopf & Ballard (2013)) and elicitation of options through human interaction (Subramanian et al., 2011).", "startOffset": 91, "endOffset": 117}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network.", "startOffset": 116, "endOffset": 235}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al.", "startOffset": 116, "endOffset": 684}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al.", "startOffset": 116, "endOffset": 701}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al.", "startOffset": 116, "endOffset": 730}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall.", "startOffset": 116, "endOffset": 762}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al.", "startOffset": 116, "endOffset": 1322}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al.", "startOffset": 116, "endOffset": 1346}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al. (1999) and Schaul et al.", "startOffset": 116, "endOffset": 1368}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al. (1999) and Schaul et al. (2015)), imitation and apprenticeship learning (e.", "startOffset": 116, "endOffset": 1393}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al. (1999) and Schaul et al. (2015)), imitation and apprenticeship learning (e.g., Kolter et al. (2008) and Rothkopf & Ballard (2013)) and elicitation of options through human interaction (Subramanian et al.", "startOffset": 116, "endOffset": 1461}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al. (1999) and Schaul et al. (2015)), imitation and apprenticeship learning (e.g., Kolter et al. (2008) and Rothkopf & Ballard (2013)) and elicitation of options through human interaction (Subramanian et al.", "startOffset": 116, "endOffset": 1491}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al. (1999) and Schaul et al. (2015)), imitation and apprenticeship learning (e.g., Kolter et al. (2008) and Rothkopf & Ballard (2013)) and elicitation of options through human interaction (Subramanian et al., 2011). These ideas have held great promise, but have not enjoyed significant impact. We believe the recurrent compositional neural representations proposed in this paper could help these approaches in the future, and in particular in overcoming feature engineering. This work is also closely related to program induction. Most previous work on program induction, i.e. inducing a program given example input and output pairs, has used genetic programming (Banzhaf et al., 1998) to evolve useful programs from candidate populations. There have been several recent works extending recurrent networks to solve problems not traditionally cast as simple sequence prediction. Zaremba & Sutskever (2014) trained LSTM models to read in the text of simple programs character-by-character and correctly predict the program output.", "startOffset": 116, "endOffset": 2262}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al. (1999) and Schaul et al. (2015)), imitation and apprenticeship learning (e.g., Kolter et al. (2008) and Rothkopf & Ballard (2013)) and elicitation of options through human interaction (Subramanian et al., 2011). These ideas have held great promise, but have not enjoyed significant impact. We believe the recurrent compositional neural representations proposed in this paper could help these approaches in the future, and in particular in overcoming feature engineering. This work is also closely related to program induction. Most previous work on program induction, i.e. inducing a program given example input and output pairs, has used genetic programming (Banzhaf et al., 1998) to evolve useful programs from candidate populations. There have been several recent works extending recurrent networks to solve problems not traditionally cast as simple sequence prediction. Zaremba & Sutskever (2014) trained LSTM models to read in the text of simple programs character-by-character and correctly predict the program output. Though not practical as a real interpreter, it is somewhat astonishing that it works. Mou et al. (2014) process program symbols to learn max-margin program embeddings with the help of parse trees.", "startOffset": 116, "endOffset": 2490}, {"referenceID": 3, "context": "This idea appeared in (Sutskever & Hinton, 2009) in the context of learning higher order symbolic relations and in (Donnarumma et al., 2015) as the key ingredient of an architecture for prefrontal cognitive control. Schmidhuber (1992) proposed a related meta-learning idea, whereby one learns the parameters of a slowly changing network, which in turn generates context dependent weight changes for a second rapidly changing network. These approaches have only been demonstrated in very limited settings. In cognitive science, several theories of brain areas controlling other brain parts so as to carry out multiple tasks have been proposed; see for example Schneider & Chein (2003); Anderson (2010) and Donnarumma et al. (2012). Recently, Graves et al. (2014) advanced a neural Turing machine that is capable of learning and executing simple programs such as repeat copying, simple priority sorting and associative recall. Instead of using input and output pairs, our model is trained on program execution traces at varying levels of abstraction. In exchange for this richer supervision, we get the benefit of learning compositionality of programs, and also data efficient training of complex programs. Related problems have been studied in the literature on hierarchical reinforcement learning (e.g., Dietterich (2000); Andre & Russell (2001); Sutton et al. (1999) and Schaul et al. (2015)), imitation and apprenticeship learning (e.g., Kolter et al. (2008) and Rothkopf & Ballard (2013)) and elicitation of options through human interaction (Subramanian et al., 2011). These ideas have held great promise, but have not enjoyed significant impact. We believe the recurrent compositional neural representations proposed in this paper could help these approaches in the future, and in particular in overcoming feature engineering. This work is also closely related to program induction. Most previous work on program induction, i.e. inducing a program given example input and output pairs, has used genetic programming (Banzhaf et al., 1998) to evolve useful programs from candidate populations. There have been several recent works extending recurrent networks to solve problems not traditionally cast as simple sequence prediction. Zaremba & Sutskever (2014) trained LSTM models to read in the text of simple programs character-by-character and correctly predict the program output. Though not practical as a real interpreter, it is somewhat astonishing that it works. Mou et al. (2014) process program symbols to learn max-margin program embeddings with the help of parse trees. Vinyals et al. (2015) developed Pointer Networks that generalize the notion of encoder attention in order to provide the decoder a variable-sized output space depending on the input sequence length.", "startOffset": 116, "endOffset": 2605}, {"referenceID": 12, "context": "The programs therefore have a more succinct representation than neural programs encoded as the full set of weights in a neural network (Rumelhart et al., 1986; Graves et al., 2014).", "startOffset": 135, "endOffset": 180}, {"referenceID": 18, "context": "The program and state vectors are then propagated forward through an LSTM mapping flstm as in (Sutskever et al., 2014).", "startOffset": 94, "endOffset": 118}, {"referenceID": 18, "context": "To simplify the notation, we have abstracted properties such as layers and cell memory in the sequence-to-sequence LSTM of equation (2); see (Sutskever et al., 2014) for details.", "startOffset": 141, "endOffset": 165}, {"referenceID": 5, "context": "For training data, we used renderings of the 3D car CAD models from (Fidler et al., 2012).", "startOffset": 68, "endOffset": 89}, {"referenceID": 18, "context": "We compare the generalization ability of our model to a flat sequence-to-sequence LSTM (Sutskever et al., 2014), using the same number of layers (2) and hidden units (256).", "startOffset": 87, "endOffset": 111}, {"referenceID": 10, "context": "The learning of new tasks may require that the network weights change substantially, so care must be taken to avoid catastrophic forgetting(Mccloskey & Cohen, 1989; OReilly et al., 2014).", "startOffset": 139, "endOffset": 186}], "year": 2017, "abstractText": "We propose the neural programmer-interpreter (NPI): a recurrent and compositional neural network that learns to represent and execute programs. NPI has three learnable components: a task-agnostic recurrent core, a persistent key-value program memory, and domain-specific encoders that enable a single NPI to operate in multiple perceptually diverse environments with distinct affordances. By learning to compose lower-level programs to express higher-level programs, NPI reduces sample complexity and increases generalization ability compared to sequence-tosequence LSTMs. The program memory allows efficient learning of additional tasks by building on existing programs. NPI can also harness the environment (e.g. a scratch pad with read-write pointers) to cache intermediate results of computation, lessening the long-term memory burden on recurrent hidden units. In this work we train the NPI with fully-supervised execution traces; each program has example sequences of calls to the immediate subprograms conditioned on the input. Rather than training on a huge number of relatively weak labels, NPI learns from a small number of rich examples. We demonstrate the capability of our model to learn several types of compositional programs: addition, sorting, and canonicalizing 3D models. Furthermore, a single NPI learns to execute these programs and all 21 associated subprograms.", "creator": "LaTeX with hyperref package"}}}