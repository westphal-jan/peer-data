{"id": "1511.06394", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Geodesics of learned representations", "abstract": "We develop a new method for visualizing and refining the invariances of learned representations. Given two reference images (typically, differing by some transformation), we synthesize a sequence of images lying on a path between them that is of minimal length in the space of a representation (a \"representational geodesic\"). If the transformation relating the two reference images is an invariant of the representation, this sequence should follow the gradual evolution of this transformation. We use this method to assess the invariances of state-of-the-art image classification networks and find that surprisingly, they do not exhibit invariance to basic parametric transformations of translation, rotation, and dilation. Our method also suggests a remedy for these failures, and following this prescription, we show that the modified representation exhibits a high degree of invariance for a range of geometric image transformations.", "histories": [["v1", "Thu, 19 Nov 2015 21:40:13 GMT  (1059kb,D)", "https://arxiv.org/abs/1511.06394v1", "Submitted to ICLR2016"], ["v2", "Thu, 7 Jan 2016 21:10:58 GMT  (1059kb,D)", "http://arxiv.org/abs/1511.06394v2", "Response to first set of reviews for ICLR2016"], ["v3", "Tue, 19 Jan 2016 21:05:40 GMT  (981kb,D)", "http://arxiv.org/abs/1511.06394v3", "Final response to reviews for ICLR2016"], ["v4", "Mon, 22 Feb 2016 17:42:25 GMT  (981kb,D)", "http://arxiv.org/abs/1511.06394v4", "Published as a conference paper at ICLR 2016"]], "COMMENTS": "Submitted to ICLR2016", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["olivier j h\\'enaff", "eero p simoncelli"], "accepted": true, "id": "1511.06394"}, "pdf": {"name": "1511.06394.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": ["eero}@cns.nyu.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "2 SYNTHESIZING GEODESIC SEQUENCES", "text": "Suppose we have an image representation, y = f (x), where x is the vector of image pixel intensity and f (\u00b7) is a continuous function that maps it to an abstract vector-like representation y (e.g. the reactions of an intermediate stage of a hierarchical neural network). In view of the initial and final images, we would like to synthesize an image sequence that lies along the path of minimum length in the representation space (a representative geodesy). If the mapping is done many to one (which is usually the case), this image sequence is not unique. We solve this ambiguity by selecting the representational geodesy that is also in the image space of minimum length (i.e. a conditional geodesy in the image space)."}, {"heading": "2.1 OBJECTIVE FUNCTION", "text": "In order to produce such a sequence, we optimize an objective function expressing a discrete approach to the problem, directly in the form of images scanned along the path. In view of a desired sequence length N and initial and final images, {x0, xN}, we would like to synthesize a sequence of images, \u03b3 = {xn; n = 0. N}, which is located along a geodesic sequence in the display space. The display path length isL [f (\u03b3)] = N \u2211 n = 1 \u0441f (xn \u2212 1) - f (xn \u2212 1) - 2, which is limited by the representational energy E [f (\u03b3)] = N \u0445 f (xn \u2212 1) - 22 thanks to the Kauchy-Schwartz inequality L [f (\u03b3)] 2 \u2264 NE [f (\u03b3)] - is associated with equality when and only when the representations are connected to each other, which is supported by the minimization of energy."}, {"heading": "2.2 OPTIMIZATION", "text": "We optimize this goal in three steps. First, we initialize the problem with the minimum E [\u03b3], which is simply a sequence of images that are linearly interpolated between the first and last images. Next, we minimize the representational geodesic target E [f)]. Finally, we minimize the image domain geodetic lens due to remaining in the line of representational geodesics.Minimizing the representational geodesic object in the second step requires optimizing an image for its representation via a non-linear function, and thus shares much of the non-conventional excellency found in the formation of deep neural networks. Specifically, the curvature of the energy surface can be variably used over the course of optimization. Therefore, we used the Adam optimization method (Kingma & Ba, 2014), which uses scaled gradients by continuously estimating their variance, which provides robustness to these changes in the energy landscape."}, {"heading": "3 VISUALIZING GEODESIC SEQUENCES", "text": "We used our geodetic framework to study the invariance characteristics of the 16-layer VGG network (Simonyan & Zisserman, 2014), which we selected for its conceptual simplicity and strong object recognition performance. We used the results of the third stage of pooling as a \"representation\" for our tests. Each stage of this continuous nonlinear mapping is constructed as a composition of three elementary operations: linear filtering, half-wave rectification, and maximum pooling (which summarizes a local region with its maximum). We followed the pre-processing steps described in the original paper: images are scaled back to the range [0, 255], color channels are permutated from RGB to BGR, and the mean BGR pixel value [104, 117, 124] is subtracted."}, {"heading": "3.1 GEODESICS AS A DIAGNOSTIC TOOL", "text": "We first investigated whether this representation linearizes basic geometric transformations: translation, rotation, and dilatation, by calculating the geodesic sequence between two images that differ by one of these transformations, and comparing it to the basic truth sequence obtained by incremental application of the same transformation.The extent of the general transformation determines the difficulty of this task: All representations (even trivial ones) will produce geodesics that are close to the truth for very small transformations, while all are likely to fail due to very large transformations. For our discriminatory test, we chose intermediate values: an 8-pixel transformation, a 4-pixel rotation, and a 10-percent dilatation. We found that the VGG network, despite its impressive classification performance, is not in the linearization of this simple geometric deformation, and produced geodesics with distinctive alizing artefacts (Figure 3, middle column column column)."}, {"heading": "3.2 DISAMBIGUATING SPATIAL SCALE AND NONLINEAR COMPLEXITY WITH GEODESICS", "text": "So far, we have found that a deep representation is able to alleviate a number of real-world transformations (Figure 3, right column), while a flat one (e.g., pixel intensities) is not (Figure 1, middle column). However, it is unclear whether the improved invariance of deep representation is due to the spatial extent to which it calculates its responses, or to its nonlinear complexity. In fact, as we advance the hierarchy of a neural network, the effective input region for each unit (the \"receptive field\") is increasing, simply because of cascaded convolution and subsampled pooling. At the same time, the complexity of representation is increasing as a longer sequence of nonlinear operations."}, {"heading": "3.3 LINEARIZING NATURAL IMAGE SEQUENCES", "text": "After testing the ability of the modified VGG network to linearize simple parametric transformations, we asked if it could linearize the compositions of these transformations that arise in natural image sequences. To explore this, we extracted 5 images from the film Melancholia and created a geodesic from the first to the last. We find that these geodesic fluid transitions between the two images capture much of the actual temporal evolution of the video (Figure 5, left and right panels). Relative to the original sequence, the only errors it produces are due to known problems in estimating motion. A large part of the transformation in the video is an unplanned rotation due to camera rotation, resulting in a composition of translations and condensities throughout the image. In a region of the image with periodic structure (e.g. the geodesic texture of the chair), the movement between the two halves is usually known, because the problem is the end of the two."}, {"heading": "4 DISCUSSION", "text": "In fact, most people who are able to feel able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, and to move."}, {"heading": "ACKNOWLEDGMENTS", "text": "This work was supported by the Howard Hughes Medical Institute."}], "references": [{"title": "Untangling invariant object recognition", "author": ["DiCarlo", "James J", "Cox", "David D"], "venue": "Trends in Cognitive Sciences,", "citeRegEx": "DiCarlo et al\\.,? \\Q2007\\E", "shortCiteRegEx": "DiCarlo et al\\.", "year": 2007}, {"title": "Learning invariant features through topographic filter maps", "author": ["Kavukcuoglu", "Koray", "Ranzato", "Marc\u2019Aurelio", "Fergus", "Rob", "LeCun", "Yann"], "venue": null, "citeRegEx": "Kavukcuoglu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kavukcuoglu et al\\.", "year": 2009}, {"title": "Adam: A Method for Stochastic Optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoff"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Group Invariant Scattering", "author": ["Mallat", "St\u00e9phane"], "venue": "arXiv.org, math.FA,", "citeRegEx": "Mallat and St\u00e9phane.,? \\Q2011\\E", "shortCiteRegEx": "Mallat and St\u00e9phane.", "year": 2011}, {"title": "A Parametric Texture Model Based on Joint Statistics of Complex Wavelet Coefficients", "author": ["Portilla", "Javier", "Simoncelli", "Eero P"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Portilla et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Portilla et al\\.", "year": 2000}, {"title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "author": ["Saxe", "Andrew M", "McClelland", "James L", "Ganguli", "Surya"], "venue": null, "citeRegEx": "Saxe et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Saxe et al\\.", "year": 2013}, {"title": "Very Deep Convolutional Networks for Large-Scale Image Recognition. arXiv.org, cs.CV", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": null, "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Intriguing properties of neural networks", "author": ["Szegedy", "Christian", "Zaremba", "Wojciech", "Sutskever", "Ilya", "Bruna", "Joan", "Erhan", "Dumitru", "Goodfellow", "Ian", "Fergus", "Rob"], "venue": null, "citeRegEx": "Szegedy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2013}, {"title": "A convolutional subunit model for neuronal responses in macaque V1", "author": ["B Vintch", "J A Movshon", "Simoncelli", "Eero P"], "venue": "The Journal of Neuroscience,", "citeRegEx": "Vintch et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vintch et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 3, "context": "Recent examples of learned visual representations have proven highly effective for recognition (Krizhevsky et al., 2012), but a precise understanding of exactly what they represent remains elusive.", "startOffset": 95, "endOffset": 120}, {"referenceID": 1, "context": "And although these representations are hypothesized to be invariant to various identity-preserving deformations, apart from a few exceptions, these claims are rarely tested directly (Kavukcuoglu et al., 2009).", "startOffset": 182, "endOffset": 208}, {"referenceID": 8, "context": "When applied to deep recognition networks, synthesis has revealed failures in the form of \u201cadversarial examples\u201d: images that appear entirely different to a human observer, and yet are identified by the network as belonging to the same category (Szegedy et al., 2013).", "startOffset": 245, "endOffset": 267}, {"referenceID": 6, "context": "Recent theoretical work shows that optimizing all layers of a network jointly makes the problem significantly more difficult than optimizing a single layer in isolation (Saxe et al., 2013).", "startOffset": 169, "endOffset": 188}], "year": 2016, "abstractText": "We develop a new method for visualizing and refining the invariances of learned representations. Specifically, we test for a general form of invariance, linearization, in which the action of a transformation is confined to a low-dimensional subspace. Given two reference images (typically, differing by some transformation), we synthesize a sequence of images lying on a path between them that is of minimal length in the space of the representation (a \u201crepresentational geodesic\u201d). If the transformation relating the two reference images is linearized by the representation, this sequence should follow the gradual evolution of this transformation. We use this method to assess the invariance properties of a state-of-the-art image classification network and find that geodesics generated for image pairs differing by translation, rotation, and dilation do not evolve according to their associated transformations. Our method also suggests a remedy for these failures, and following this prescription, we show that the modified representation is able to linearize a variety of geometric image transformations.", "creator": "LaTeX with hyperref package"}}}