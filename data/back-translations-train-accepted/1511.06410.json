{"id": "1511.06410", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Nov-2015", "title": "Better Computer Go Player with Neural Network and Long-term Prediction", "abstract": "Competing with top human players in the ancient game of Go has been a long-term goal of artificial intelligence. Go's high branching factor makes traditional search techniques ineffective, even on leading-edge hardware, and Go's evaluation function could change drastically with one stone change. Recent works [Maddison et al. (2015); Clark &amp; Storkey (2015)] show that search is not strictly necessary for machine Go players. A pure pattern-matching approach, based on a Deep Convolutional Neural Network (DCNN) that predicts the next move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source Go engines such as Pachi [Baudis &amp; Gailly (2012)] if its search budget is limited. We extend this idea in our bot named darkforest, which relies on a DCNN designed for long-term predictions. Darkforest substantially improves the win rate for pattern-matching approaches against MCTS-based approaches, even with looser search budgets. Against human players, darkforest achieves a stable 1d-2d level on KGS Go Server, estimated from free games against human players. This substantially improves the estimated rankings reported in Clark &amp; Storkey (2015), where DCNN-based bots are estimated at 4k-5k level based on performance against other machine players. Adding MCTS to darkforest creates a much stronger player: with only 1000 rollouts, darkforest+MCTS beats pure darkforest 90% of the time; with 5000 rollouts, our best model plus MCTS beats Pachi with 10,000 rollouts 95.5% of the time.", "histories": [["v1", "Thu, 19 Nov 2015 21:59:58 GMT  (1152kb,D)", "http://arxiv.org/abs/1511.06410v1", "10 pages, 9 without references. Submission for ICLR 2016"], ["v2", "Tue, 26 Jan 2016 07:17:06 GMT  (1153kb,D)", "http://arxiv.org/abs/1511.06410v2", "10 pages, 9 without references. Submission for ICLR 2016"], ["v3", "Mon, 29 Feb 2016 15:52:34 GMT  (1153kb,D)", "http://arxiv.org/abs/1511.06410v3", "10 pages, 9 without references. Submission for ICLR 2016"]], "COMMENTS": "10 pages, 9 without references. Submission for ICLR 2016", "reviews": [], "SUBJECTS": "cs.LG cs.AI", "authors": ["yuandong tian", "yan zhu"], "accepted": true, "id": "1511.06410"}, "pdf": {"name": "1511.06410.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Yuandong Tian", "Yan Zhu"], "emails": ["yuandong@fb.com", "yz328@cs.rutgers.edu"], "sections": [{"heading": null, "text": "Recent work [Maddison et al. (2015); Clark & Storkey (2015)] shows that the search for machine Go players is not strictly necessary; a pure pattern matching approach, based on a Deep Convolutional Neural Network (DCNN) predicting the next step, can work just as well as open source go engines like Pachi [Baudis & Gailly (2012)] when the search budget is limited; we are expanding this idea in our Darkforest robot, which is based on a DCNN designed for long-term prediction; Darkforest significantly improves the return rate for pattern matching approaches against MCTS-based approaches, even with looser search budgets; unlike human players, Darkforest, which is based on a DCNN designed for long-term prediction; Darkforest significantly improves the return rate for pattern matching approaches against MCTS-based approaches, even with Darkwood budgets, Darkforest reaches an estimated 4GS-2GS only on 5.5%, which Darkwood budgets are estimated to reach 2GS."}, {"heading": "1 INTRODUCTION", "text": "For a long time, Go has been considered a major challenge in artificial intelligence due to its high predictive factors (typically in the order of a hundred to 19x19 small board situations). Fig. 1 shows a simple representation of the game of Go. Two players, black and white, place stones at intersections, which in turn stand on a 19x19 board (Fig. 1 (a)). A group is actually captured when their freedoms are zero. The goal of the game is to control more territory than the opponent (Fig. 1 (c)). The freedoms of a group is the number of their adjacent empty intersections (Fig. 1) shows that the Go rating system is difficult from kyu level (beginner to decent amateur, 30k-1k) at Dan level (advanced amateur, 1d-7d) and at professional level (1p-9p) [silver (2009)].Go is due to its high branching factors (i.e. steps in the size of a hundred could be completely removed from a small board on the order of 19x19 and 19x19)."}, {"heading": "2 METHOD", "text": "Using Neural Network as a functional approximator and pattern matcher to predict the next step of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)]. Recent progress [Maddison et al. (2015); Clark & Storkey (2015)] uses Deep Convolutional Neural Network (DCNN) to predict train and show significant improvements over flat networks or linear functional approximators based on manually designed features or simple patterns from previous games [Silver (2009)]. In this paper, we train a DCNN to predict the next k movements as input taking into account the current board situation. We treat the 19 x 19 board as a 19 image with multiple channels. Each channel encodes a different aspect of board information, e.g. freedoms (Fig). Compared to Open Source's previous work, we use a more compact set of features and significantly increase it."}, {"heading": "2.1 FEATURE CHANNELS", "text": "Table 1 shows the characteristics extracted from the current board situation. Each characteristic is a binary 19 x 19 map, except for history information and position mask, which are real numbers in [0, 1]. The story is encoded as Exp (\u2212 t * 0.1), where t is the length of the placement of the stone. The exponential time decay is intended to allow the network to focus on the most recent fight. Position marker is defined as Exp (\u2212 12 l2), where l2 is the square distance to the board center. It is used to encode the relative position of each intersection. There are two differences between our characteristics and those in Maddison et al. (2015). First, we use relative encoding (our / opponent) for almost all characteristics. In contrast, the characteristics in Maddison et al. (2015) are mostly player-agnostic. Second, our feature set is simpler and more compact (25 vs. 36 players have entry levels) for almost all the same move as in advance level (2015)."}, {"heading": "2.2 NETWORK ARCHITECTURE", "text": "Fig. 3 shows the architecture of the network for our best model. We use a 12-layer (d = 12) complete wave network. Each wave layer is followed by a ReLU nonlinearity. Except for the first layer, all layers use the same width w = 384. No weight distribution is used. We do not use pooling as it negatively affects performance. Instead of two Softmax outputs [Maddison et al. (2015)] to predict black-and-white movements, we use only one Softmax layer to predict the next move, which reduces the number of parameters."}, {"heading": "2.3 LONG TERM PLANNING", "text": "Each move is a separate Softmax output. The motivation is twofold: first, we want our network to focus on a strategic plan, not on the immediate next move; second, we expect more monitoring on multiple Softmax outputs to train the network. Table 2 calculates the ratio of the average Gradient L2 standard (over the first 9 epochs, first 1000 minibatches removed) between 1 and 3-step predictions on each folding layer. As expected, the gradient orders of magnitude of the top layers (layers closer to Softmax) are higher in the 3-step prediction; however, the gradient orders of magnitude of the lower layers are roughly the same, which shows that the lower gradients are eliminated in the 3-step prediction and probably only the most important gradients remain for training."}, {"heading": "2.4 TRAINING", "text": "In training, we use 16 CPU threads to prepare the minibatch, simulating 300 randomly selected games from the dataset. In each minibatch, we randomly select one game from 300 for each thread, simulate one step according to the game record, and extract features and next k moves as an input / output pair within the batch. When the game is over (or less than k moves remain), we randomly select one (with replacement) from the training set and continue. Batch size is 256. We use data augmentation with rotation at 90-degree intervals and horizontal / vertical flipping. For each board situation, data augmentation could generate up to 8 different scenarios. Before training, we randomly initiate games into different stages, ensuring that each stack contains situations that correspond to different levels of play."}, {"heading": "2.5 MONTE CARLO TREE SEARCH", "text": "From the experiments it is clear that DCNN is tactically weak due to the lack of search. Search is a way to explore the solution space tied to the current board situation, and to build a non-parametric local model for the game. The local model is more flexible than the global model, which has been learned from massive training data and is more adapted to the current situation. The state-of-the-art approach in Computer Go is Monte-Carlo Tree Search (MCTS). Fig. 4 shows its basic principles. Combining DCNN with MCTS does not require trivial technical efforts, as each rollout of MCTS is much faster than the DCNN rating. Therefore, these two need to run in parallel to frequent communications. Our basic implementation of MCTS gives 16k rollouts per second (for 16 threads on a machine running Intel Xeon CPU E5-2680 v2 at 2.80 GHz), whereas it usually takes 0.2s for DCNN to give board ratings from 12P8 to 12P4."}, {"heading": "3 EXPERIMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 SETUP", "text": "We use the public KGS dataset (over 170k games) used in Maddison et al. (2015), we use all games prior to 2012 as a training set and 2013-2015 games as a test set, resulting in 144,748 games for training and 26,814 games for testing, we also use GoGoD dataset 1 (over 80k games), which is also used in Clark & Storkey (2015), 75,172 games for training and 2,592 games for testing. For evaluation, our model competes with GnuGo, Pachi [Baudis & Gailly (2012)] and Fuego [Enzenberger et al. (2010)], we use GnuGo 3.8 Level 10, Pachi 11.99 (Genjo devel) with the sample files and Fuego 1.1 during our experiments."}, {"heading": "3.2 MOVE PREDICTION", "text": "Table 3 shows the performance comparison for train prediction. For models predicting the next k-moves, we only evaluate their prediction accuracy for the next move. With our training frame, we are able to achieve a slightly higher top-1 prediction accuracy (after hundreds of eras) compared to Maddison et al. (2015). Note that the use of standard or advanced features appears to have slight advantages (fig. 5). Therefore, for the other experiments, we use d = 12 and w = 384, as shown in fig. 3.1. We used the summer version GoGoD 2015, which is available at http: / / www.god.co.uk. We omit antique games and only use game records after 1800 AD."}, {"heading": "3.3 WIN RATE", "text": "Amazingly, the win rate does not correlate well with the accuracy of the train predictions. In terms of train prediction accuracy in the test set, all numbers are roughly the same, except for a few percentage differences. However, their win rates are very different from other game engines. Table 6 shows how the win rate increases over time. From the figure, our DCNN with 2 or 3 steps is about 10% -15% (in absolute difference) better than DCNN with 1 step. For more steps, the performance shows decreasing returns. On the other hand, the win rate of the standard feature is comparable to the extended one. Table 4 shows that the win rate of our approach is substantially higher than that of the previous work steps. We also train a smaller model with w = 144, whose number of parameters are comparable to Maddison et al. (2015) Our smaller model reaches 43.3% in 300 games against Pachi 10k, when Pachi's3We test darkfores2 against Fuego."}, {"heading": "3.4 EVALUATION ON KGS GO SERVER", "text": "We put our bots on the KGS Go server and checked their performance over a three-month period. Darkforest was made public on August 31, 2015. Since then, it has played about 2000 games. Recently, we also released the improved version darkfores1 on November 2, 2015. In order to reach the endgame board situations, we have failed 1000 attempts of standard policy to find the dead stones, followed by standard trump Taylor scoring. If all 1000 attempts show that they lose by 10 + points, they resign. In the KGS Go server, their levels are around KGS 1d-2d, while darkfores1 is slightly stronger, in line with its better win rate against open source engines. Table 6 shows the statistics they also played against 4d players and won 3 games out of 9. This is a significant improvement over the AI developed in Clark & Storkey (2015), which holds 4k-5k levels estimated by playing against Go engines."}, {"heading": "3.5 COMBINATION WITH MONTE CARLO TREE SEARCH (MCTS", "text": "We build an MCTS framework and investigate how DCNN + MCTS might affect the win rate. Our MCTS implementation is always fairly standard. Tree Policy: For a list of moves sorted according to the softmax probability of DCNN, we select the moves from the most likely until the accumulated probability exceeds 0.8, and use UCT [Browne et al. (2012)] to select moves for tree expansion. Note that the DCNN trust points of the selected moves are not used in UCT. Default Policy: Following Pachi's implementation [Baudis & Gailly (2012)], we use 3x3 patterns, opponents atari points, detection of nakadepunkte, and avoidance of standard measures. The default policy is played until no player can play a move that is not self-destructive. We test our synchronized MCTS implementation with Darkforest, darkforeskesk1 and daresk2."}, {"heading": "4 CONCLUSION AND FUTURE WORK", "text": "In this paper, we have significantly improved the performance of the DCNN-based Go AI, comprehensively evaluated it against open source engines and strong amateur players, and demonstrated its potential when combined with Monte-Carlo Tree Search (MCTS). Ideally, we want to construct a system that combines pattern matching and search, and can be trained together online. Pattern matching with DCNN is good at reading the global board, but may fail to capture specific local situations. On the other hand, the search is excellent at modeling arbitrary situations, building a local, not parametric model for the current state only when the computation costs are affordable. One paradigm is updating the DCNN weights (i.e., Policy Gradient [Sutton et al. (1999)]), after MCTS has completed and selected a different best move than DCNN's proposal."}], "references": [{"title": "Pachi: State of the art open source go program", "author": ["Baudis", "Petr", "Gailly", "Jean-loup"], "venue": null, "citeRegEx": "Baudis et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Baudis et al\\.", "year": 2012}, {"title": "A survey of monte carlo tree search methods", "author": ["Browne", "Cameron B", "Powley", "Edward", "Whitehouse", "Daniel", "Lucas", "Simon M", "Cowling", "Peter", "Rohlfshagen", "Philipp", "Tavener", "Stephen", "Perez", "Diego", "Samothrakis", "Spyridon", "Colton", "Simon"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on,", "citeRegEx": "Browne et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Browne et al\\.", "year": 2012}, {"title": "Training deep convolutional neural networks to play go", "author": ["Clark", "Christopher", "Storkey", "Amos"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning", "citeRegEx": "Clark et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2015}, {"title": "The integration of a priori knowledge into a go playing neural network", "author": ["Enzenberger", "Markus"], "venue": "URL: http://www. markus-enzenberger. de/neurogo. html,", "citeRegEx": "Enzenberger and Markus.,? \\Q1996\\E", "shortCiteRegEx": "Enzenberger and Markus.", "year": 1996}, {"title": "Fuegoan opensource framework for board games and go engine based on monte carlo tree search", "author": ["Enzenberger", "Markus", "M\u00fcller", "Martin", "Arneson", "Broderick", "Segal", "Richard"], "venue": "Computational Intelligence and AI in Games, IEEE Transactions on,", "citeRegEx": "Enzenberger et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Enzenberger et al\\.", "year": 2010}, {"title": "Bandit based monte-carlo planning", "author": ["Kocsis", "Levente", "Szepesv\u00e1ri", "Csaba"], "venue": "In Machine Learning: ECML", "citeRegEx": "Kocsis et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Kocsis et al\\.", "year": 2006}, {"title": "Move evaluation in go using deep convolutional neural networks", "author": ["Maddison", "Chris J", "Huang", "Aja", "Sutskever", "Ilya", "Silver", "David"], "venue": null, "citeRegEx": "Maddison et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Maddison et al\\.", "year": 2015}, {"title": "Evolving neural networks to play go", "author": ["Richards", "Norman", "Moriarty", "David E", "Miikkulainen", "Risto"], "venue": "Applied Intelligence,", "citeRegEx": "Richards et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Richards et al\\.", "year": 1998}, {"title": "Temporal difference learning of position evaluation in the game of go", "author": ["Schraudolph", "Nicol N", "Dayan", "Peter", "Sejnowski", "Terrence J"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Schraudolph et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Schraudolph et al\\.", "year": 1994}, {"title": "Reinforcement learning and simulation-based search", "author": ["Silver", "David"], "venue": "Doctor of philosophy, University of Alberta,", "citeRegEx": "Silver and David.,? \\Q2009\\E", "shortCiteRegEx": "Silver and David.", "year": 2009}, {"title": "Mimicking go experts with convolutional neural networks", "author": ["Sutskever", "Ilya", "Nair", "Vinod"], "venue": "In Artificial Neural Networks-ICANN", "citeRegEx": "Sutskever et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2008}, {"title": "Policy gradient methods for reinforcement learning with function approximation", "author": ["Sutton", "Richard S", "McAllester", "David A", "Singh", "Satinder P", "Mansour", "Yishay"], "venue": "In NIPS,", "citeRegEx": "Sutton et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1999}], "referenceMentions": [{"referenceID": 6, "context": "Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players.", "startOffset": 14, "endOffset": 37}, {"referenceID": 6, "context": "Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players.", "startOffset": 14, "endOffset": 61}, {"referenceID": 6, "context": "Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players. A pure pattern-matching approach, based on a Deep Convolutional Neural Network (DCNN) that predicts the next move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source Go engines such as Pachi [Baudis & Gailly (2012)] if its search budget is limited.", "startOffset": 14, "endOffset": 365}, {"referenceID": 6, "context": "Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players. A pure pattern-matching approach, based on a Deep Convolutional Neural Network (DCNN) that predicts the next move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source Go engines such as Pachi [Baudis & Gailly (2012)] if its search budget is limited. We extend this idea in our bot named darkforest, which relies on a DCNN designed for long-term predictions. Darkforest substantially improves the win rate for patternmatching approaches against MCTS-based approaches, even with looser search budgets. Against human players, darkforest achieves a stable 1d-2d level on KGS Go Server, estimated from free games against human players. This substantially improves the estimated rankings reported in Clark & Storkey (2015), where DCNN-based bots are estimated at 4k-5k level based on performance against other machine players.", "startOffset": 14, "endOffset": 866}, {"referenceID": 6, "context": "Fortunately, recent works [Maddison et al. (2015); Clark & Storkey (2015)] in Computer Go have shown that the Go board situation could be deciphered with Deep Convolutional Neural Network (DCNN).", "startOffset": 27, "endOffset": 50}, {"referenceID": 6, "context": "Fortunately, recent works [Maddison et al. (2015); Clark & Storkey (2015)] in Computer Go have shown that the Go board situation could be deciphered with Deep Convolutional Neural Network (DCNN).", "startOffset": 27, "endOffset": 74}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones.", "startOffset": 108, "endOffset": 129}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones.", "startOffset": 108, "endOffset": 157}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)].", "startOffset": 108, "endOffset": 789}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines.", "startOffset": 108, "endOffset": 1118}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al.", "startOffset": 108, "endOffset": 1820}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al.", "startOffset": 108, "endOffset": 1844}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)].", "startOffset": 108, "endOffset": 1871}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)].", "startOffset": 108, "endOffset": 1891}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)]. Recent progress [Maddison et al. (2015); Clark & Storkey (2015)] uses Deep Convolutional Neural Network (DCNN) for move prediction, and shows substantial improvement over shallow networks or linear function approximators based on manually designed features or simple patterns extracted from previous games [Silver (2009)].", "startOffset": 108, "endOffset": 1933}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)]. Recent progress [Maddison et al. (2015); Clark & Storkey (2015)] uses Deep Convolutional Neural Network (DCNN) for move prediction, and shows substantial improvement over shallow networks or linear function approximators based on manually designed features or simple patterns extracted from previous games [Silver (2009)].", "startOffset": 108, "endOffset": 1957}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)]. Recent progress [Maddison et al. (2015); Clark & Storkey (2015)] uses Deep Convolutional Neural Network (DCNN) for move prediction, and shows substantial improvement over shallow networks or linear function approximators based on manually designed features or simple patterns extracted from previous games [Silver (2009)].", "startOffset": 108, "endOffset": 2214}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)]. Recent progress [Maddison et al. (2015); Clark & Storkey (2015)] uses Deep Convolutional Neural Network (DCNN) for move prediction, and shows substantial improvement over shallow networks or linear function approximators based on manually designed features or simple patterns extracted from previous games [Silver (2009)]. In this paper, we train a DCNN that predicts the next k moves given the current board situation as an input. We treat the 19\u00d7 19 board as a 19\u00d7 19 image with multiple channels. Each channel encodes a different aspect of board information, e.g., liberties (Fig. 1(b)). Compared to previous works, we use a more compact feature set and predict long-term moves, and show that they lead to a substantial performance boost in terms of win rate against open source engines. 2.1 FEATURE CHANNELS Table 1 shows the features extracted from the current board situation. Each feature is a binary 19\u00d719 map except for history information and position mask, which are real numbers in [0, 1]. History is encoded as exp(\u2212t \u2217 0.1), where t is how long the stone has been placed. The exponential temporal decay is meant to enable the network to focus on the recent battle. Position mark is defined as exp(\u2212 12 l ), where l is the squared L2 distance to the board center. It is used to encode the relative position of each intersection. There are two differences between our features and those in Maddison et al. (2015). First, we use relative coding (our/opponent) for almost all the features.", "startOffset": 108, "endOffset": 3318}, {"referenceID": 1, "context": "player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)]. Recent progress [Maddison et al. (2015); Clark & Storkey (2015)] uses Deep Convolutional Neural Network (DCNN) for move prediction, and shows substantial improvement over shallow networks or linear function approximators based on manually designed features or simple patterns extracted from previous games [Silver (2009)]. In this paper, we train a DCNN that predicts the next k moves given the current board situation as an input. We treat the 19\u00d7 19 board as a 19\u00d7 19 image with multiple channels. Each channel encodes a different aspect of board information, e.g., liberties (Fig. 1(b)). Compared to previous works, we use a more compact feature set and predict long-term moves, and show that they lead to a substantial performance boost in terms of win rate against open source engines. 2.1 FEATURE CHANNELS Table 1 shows the features extracted from the current board situation. Each feature is a binary 19\u00d719 map except for history information and position mask, which are real numbers in [0, 1]. History is encoded as exp(\u2212t \u2217 0.1), where t is how long the stone has been placed. The exponential temporal decay is meant to enable the network to focus on the recent battle. Position mark is defined as exp(\u2212 12 l ), where l is the squared L2 distance to the board center. It is used to encode the relative position of each intersection. There are two differences between our features and those in Maddison et al. (2015). First, we use relative coding (our/opponent) for almost all the features. In contrast, the features in Maddison et al. (2015) are largely player-agnostic.", "startOffset": 108, "endOffset": 3445}, {"referenceID": 6, "context": "In comparison, Maddison et al. (2015) uses such features like liberties after the move, captures after the move, etc.", "startOffset": 15, "endOffset": 38}, {"referenceID": 6, "context": "In comparison, Maddison et al. (2015) uses such features like liberties after the move, captures after the move, etc. We use a similar way to encode rank in 9 planes as in Maddison et al. (2015). That is, all kyu-players have all nine planes zero, 1d players has their first plane all-1, 2d players have their second plane all-1, etc.", "startOffset": 15, "endOffset": 195}, {"referenceID": 6, "context": "In comparison, Maddison et al. (2015) uses such features like liberties after the move, captures after the move, etc. We use a similar way to encode rank in 9 planes as in Maddison et al. (2015). That is, all kyu-players have all nine planes zero, 1d players has their first plane all-1, 2d players have their second plane all-1, etc. For 9d and professional players, all the planes are filled with 1. 2.2 NETWORK ARCHITECTURE Fig. 3 shows the architecture of the network for our best model. We use a 12-layered (d = 12) full convolutional network. Each convolution layer is followed by a ReLU nonlinearity. Except for the first layer, all layers use the same width w = 384. No weight sharing is used. We do not use pooling since they negatively affect the performance. Instead of using two softmax outputs [Maddison et al. (2015)] to predict black and white moves, we only use one softmax layer to predict the next move, reducing the number of parameters.", "startOffset": 15, "endOffset": 831}, {"referenceID": 6, "context": "Unlike Maddison et al. (2015) that uses asynchronous stochastic gradient descent, we just use vanilla SGD on 4 NVidia K40m GPUs in a single machine to train the entire network (for some models we use 3 GPUs with 255 as the batch size).", "startOffset": 7, "endOffset": 30}, {"referenceID": 6, "context": "Unlike Maddison et al. (2015) that uses asynchronous stochastic gradient descent, we just use vanilla SGD on 4 NVidia K40m GPUs in a single machine to train the entire network (for some models we use 3 GPUs with 255 as the batch size). Each epoch lasts about 5 to 6 hours. The learning rate is set to be 0.05. Typically, the model starts to converge within one epoch and shows good performance after 50-60 epochs (around two weeks). Reducing the learning rate after the performance stalls will increase the performance even further. 2.5 MONTE CARLO TREE SEARCH From the experiments, we clearly show that DCNN is tactically weak due to the lack of search. Search is a way to explore the solution space conditioned on the current board situation, and build a non-parametric local model for the game. The local model is more flexible than the global model learned from massive training data and more adapted to the current situation. The state-of-the-art approach in computer Go is Monte-Carlo Tree Search (MCTS). Fig. 4 shows its basic principle. Combining DCNN with MCTS requires nontrivial engineering efforts because each rollout of MCTS is way much faster than DCNN evaluation. Therefore, these two must run in parallel with frequent communications. Our basic implementation of MCTS gives 16k rollouts per second (for 16 threads on a machine with Intel Xeon CPU E5-2680 v2 at 2.80GHz) while it typically takes 0.2s for DCNN to give board evaluations of a batch size of 128 with 4 GPUs. There are two ways to address this problem. In asynchronized implementation used in Maddison et al. (2015), MCTS sends the newly expanded node to DCNN but is not blocked by DCNN evaluation.", "startOffset": 7, "endOffset": 1595}, {"referenceID": 5, "context": "Note that our implementation is not directly comparable to the asynchronized version in Maddison et al. (2015), achieving 86.", "startOffset": 88, "endOffset": 111}, {"referenceID": 5, "context": "Note that our implementation is not directly comparable to the asynchronized version in Maddison et al. (2015), achieving 86.7% with 100k rollouts. 3 EXPERIMENTS 3.1 SETUP We use the public KGS dataset (\u223c170k games), which is used in Maddison et al. (2015). We use all games before 2012 as the training set and 2013-2015 games as the test set.", "startOffset": 88, "endOffset": 257}, {"referenceID": 5, "context": "Note that our implementation is not directly comparable to the asynchronized version in Maddison et al. (2015), achieving 86.7% with 100k rollouts. 3 EXPERIMENTS 3.1 SETUP We use the public KGS dataset (\u223c170k games), which is used in Maddison et al. (2015). We use all games before 2012 as the training set and 2013-2015 games as the test set. This leads to 144,748 games for training and 26,814 games for testing. We also use GoGoD dataset1 (\u223c80k games), which is also used in Clark & Storkey (2015). 75,172 games are used for training and 2,592 for testing.", "startOffset": 88, "endOffset": 501}, {"referenceID": 5, "context": "Note that our implementation is not directly comparable to the asynchronized version in Maddison et al. (2015), achieving 86.7% with 100k rollouts. 3 EXPERIMENTS 3.1 SETUP We use the public KGS dataset (\u223c170k games), which is used in Maddison et al. (2015). We use all games before 2012 as the training set and 2013-2015 games as the test set. This leads to 144,748 games for training and 26,814 games for testing. We also use GoGoD dataset1 (\u223c80k games), which is also used in Clark & Storkey (2015). 75,172 games are used for training and 2,592 for testing. For evaluation, our model competes with GnuGo, Pachi [Baudis & Gailly (2012)] and Fuego [Enzenberger et al.", "startOffset": 88, "endOffset": 637}, {"referenceID": 4, "context": "For evaluation, our model competes with GnuGo, Pachi [Baudis & Gailly (2012)] and Fuego [Enzenberger et al. (2010)].", "startOffset": 89, "endOffset": 115}, {"referenceID": 4, "context": "For evaluation, our model competes with GnuGo, Pachi [Baudis & Gailly (2012)] and Fuego [Enzenberger et al. (2010)]. We use GnuGo 3.8 level 10, Pachi 11.99 (Genjo-devel) with the pattern files, and Fuego 1.1 throughout our experiments. 3.2 MOVE PREDICTION Table 3 shows the performance comparison for move prediction. For models that predict the next k moves, we only evaluate their prediction accuracy for the immediate next move. Maddison et al. (2015) d=12,w=384 d=12,w=512 d=16,w=512 d=17,w=512 55.", "startOffset": 89, "endOffset": 455}, {"referenceID": 4, "context": "For evaluation, our model competes with GnuGo, Pachi [Baudis & Gailly (2012)] and Fuego [Enzenberger et al. (2010)]. We use GnuGo 3.8 level 10, Pachi 11.99 (Genjo-devel) with the pattern files, and Fuego 1.1 throughout our experiments. 3.2 MOVE PREDICTION Table 3 shows the performance comparison for move prediction. For models that predict the next k moves, we only evaluate their prediction accuracy for the immediate next move. Maddison et al. (2015) d=12,w=384 d=12,w=512 d=16,w=512 d=17,w=512 55.2 57.1 57.3 56.6 56.4 Table 3: Comparison of Top-1 accuracies for next move predictions using standard features. d is the depth of the model while w is the number of filters at convolutional layers (except the first layer). With our training framework, we are able to achieve slightly higher Top-1 prediction accuracy (after hundreds of epochs) compared to Maddison et al. (2015). Note that using standard or extended features seem to have marginal gains (Fig.", "startOffset": 89, "endOffset": 882}, {"referenceID": 6, "context": "0 Maddison et al. (2015) 97.", "startOffset": 2, "endOffset": 25}, {"referenceID": 6, "context": "0 Maddison et al. (2015) 97.2 47.4 11.0 23.3 12.5 darkforest 96.7\u00b1 1.7 67.3\u00b1 3.2 23.3\u00b1 3.0 86.6\u00b1 0.5 52.2\u00b1 1.9 darkfores1 99.3\u00b1 0.7 86.7\u00b1 3.1 51.7\u00b1 0.1 94.3\u00b1 0.9 78.9\u00b1 2.6 darkfores2 99.7\u00b1 0.3 94.3\u00b1 1.7 73.7\u00b1 0.9 99.3\u00b1 0.7 91.0\u00b1 4.1 Table 4: Win rate comparison against open source engines between our model and previous works. For each setting, 3 groups of 100 games are played. We report the average win rate and standard deviation computed from group averages. All the game experiments mentioned in this paper use komi 7.5 and Chinese rules. Pondering (keep searching when the opponent is thinking) in Pachi and Fuego are on. Note that in Clark & Storkey (2015), they control the time per move as 10 sec/move on 2x 1.", "startOffset": 2, "endOffset": 665}, {"referenceID": 6, "context": "0 Maddison et al. (2015) 97.2 47.4 11.0 23.3 12.5 darkforest 96.7\u00b1 1.7 67.3\u00b1 3.2 23.3\u00b1 3.0 86.6\u00b1 0.5 52.2\u00b1 1.9 darkfores1 99.3\u00b1 0.7 86.7\u00b1 3.1 51.7\u00b1 0.1 94.3\u00b1 0.9 78.9\u00b1 2.6 darkfores2 99.7\u00b1 0.3 94.3\u00b1 1.7 73.7\u00b1 0.9 99.3\u00b1 0.7 91.0\u00b1 4.1 Table 4: Win rate comparison against open source engines between our model and previous works. For each setting, 3 groups of 100 games are played. We report the average win rate and standard deviation computed from group averages. All the game experiments mentioned in this paper use komi 7.5 and Chinese rules. Pondering (keep searching when the opponent is thinking) in Pachi and Fuego are on. Note that in Clark & Storkey (2015), they control the time per move as 10 sec/move on 2x 1.6 GHz cores, instead of fixing the rollout number.3 We also train a smaller model with w = 144 whose number of parameters are comparable to Maddison et al. (2015). Our smaller model achieves 43.", "startOffset": 2, "endOffset": 883}, {"referenceID": 6, "context": "In contrast, Maddison et al. (2015) reports 47.", "startOffset": 13, "endOffset": 36}, {"referenceID": 6, "context": "In contrast, Maddison et al. (2015) reports 47.4% and does not mention pondering status. Darkforest AI Bots. We build three bots from the trained models. Our first bot darkforest is trained using standard features, 1 step prediction on KGS dataset. The second bot darkfores1 is trained using extended features, 3 step prediction on GoGoD dataset. Both bots are trained with constant learning rate 0.05. Based on darkfores1, we fine-tuned the learning rate to create an even stronger DCNN player, darkfores2. Table 4 shows their strengths against open source engines. It seems that despite the fact that GoGoD is smaller, our model can be trained faster with better performance, presumably because GoGoD contains all professional games, while games from KGS Server are a bit noisy. Win rates between pairs of the three bots (Table 5) are also consistent with their performances against open source engines. We also compare darkforest with a public DCNN model4. Since both models are deterministic, we sample the moves according to the softmax probability. We played two sets of 100 games; the win rate is 100% and 99% respectively. Darkforest always wins if using their strongest moves or sampling from top 5 confident moves. 3.4 EVALUATION ON KGS GO SERVER We also put our bots onto KGS Go server and check their performance over three months period. Darkforest became publicly available on Aug 31, 2015. Since then it has played about 2000 games. Recently we also release the improved version darkfores1 on Nov 2, 2015. To score the endgame board situations, we randomly run 1000 trials of default policy to find the dead stones, followed by standard Tromp-Taylor scoring. If all 1000 trials show losing by 10+ points, they resign. In KGS Go server, their levels are around KGS 1d-2d, while darkfores1 is slightly stronger, consistent with its better win rate against open source engines. Table 6 shows the statistics. In addition, they also played against 4d players and had won 3 games out of 9. This is a major improvement upon the AI developed in Clark & Storkey (2015) that holds 4k-5k level, estimated by playing against Go engines.", "startOffset": 13, "endOffset": 2075}, {"referenceID": 1, "context": "8, and use UCT [Browne et al. (2012)] to select moves for tree expansion.", "startOffset": 16, "endOffset": 37}, {"referenceID": 1, "context": "8, and use UCT [Browne et al. (2012)] to select moves for tree expansion. Note that the DCNN confidences of the selected moves are not used in UCT. Default policy: Following Pachi\u2019s implementation [Baudis & Gailly (2012)], we use 3x3 patterns, opponent atari points, detection of nakade points and avoidance of self-atari for default policy.", "startOffset": 16, "endOffset": 221}, {"referenceID": 6, "context": "In comparison, an asynchronized version is used in Maddison et al. (2015) that achieves 86.", "startOffset": 51, "endOffset": 74}, {"referenceID": 11, "context": ", Policy Gradient [Sutton et al. (1999)]) after MCTS completes and chooses a different best move than DCNN\u2019s proposal.", "startOffset": 19, "endOffset": 40}, {"referenceID": 11, "context": ", Policy Gradient [Sutton et al. (1999)]) after MCTS completes and chooses a different best move than DCNN\u2019s proposal. To increase the signal bandwidth, we could also update weights using all the board situations along the trajectory of the best move. Alternatively, we could update the weights when MCTS is running. Actor-Critics algorithms [Konda & Tsitsiklis (1999)] can also be used to train two models simultaneously, one to predict the next move (actor) and the other to evaluate the current board situation (critic).", "startOffset": 19, "endOffset": 369}], "year": 2015, "abstractText": "Competing with top human players in the ancient game of Go has been a longterm goal of artificial intelligence. Go\u2019s high branching factor makes traditional search techniques ineffective, even on leading-edge hardware, and Go\u2019s evaluation function could change drastically with one stone change. Recent works [Maddison et al. (2015); Clark & Storkey (2015)] show that search is not strictly necessary for machine Go players. A pure pattern-matching approach, based on a Deep Convolutional Neural Network (DCNN) that predicts the next move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source Go engines such as Pachi [Baudis & Gailly (2012)] if its search budget is limited. We extend this idea in our bot named darkforest, which relies on a DCNN designed for long-term predictions. Darkforest substantially improves the win rate for patternmatching approaches against MCTS-based approaches, even with looser search budgets. Against human players, darkforest achieves a stable 1d-2d level on KGS Go Server, estimated from free games against human players. This substantially improves the estimated rankings reported in Clark & Storkey (2015), where DCNN-based bots are estimated at 4k-5k level based on performance against other machine players. Adding MCTS to darkforest creates a much stronger player: with only 1000 rollouts, darkforest+MCTS beats pure darkforest 90% of the time; with 5000 rollouts, our best model plus MCTS beats Pachi with 10,000 rollouts 95.5% of the time. 1 INTRODUCTION For a long time, computer Go is considered to be a grand challenge in artificial intelligence. Fig. 1 shows a simple illustration of the game of Go. Two players, black and white, place stones at intersections in turn on a 19x19 board (Fig. 1(a)). Black plays first on an empty board. A 4-connected component of the same color is called a group. The liberties of a group is the number of its neighboring empty intersections (Fig. 1(b)). A group is captured if its liberties are zero. The goal of the game is to control more territory than the opponent (Fig. 1(c)). Fig. 1(d)) shows the Go rating system, ranging from kyu level (beginner to decent amateur, 30k-1k) to dan level (advanced amateur, 1d-7d) and to professional levels (1p-9p) [Silver (2009)]. Go is difficult due to its high branching factors (typically on the order of hundred on a 19x19 board) and subtle board situations that are sensitive to small changes (adding/removing one stone could alter the life/death situation of a large group of stone and thus completely changes the final score). A combination of the two implies that the only solution is to use massive search that requires a prohibitive amount of resources, which is not attainable with cutting-edge hardware. Fortunately, recent works [Maddison et al. (2015); Clark & Storkey (2015)] in Computer Go have shown that the Go board situation could be deciphered with Deep Convolutional Neural Network (DCNN). They can predict the next move that a human would play 55.2% of the time. However, whether this accuracy leads to a strong Go AI is not yet well understood. It is possible that DCNN correctly predicts most regular plays by looking at the correlation of local patterns, but still fails to predict the critical one or two moves and loses the game. Indeed, a DCNN-based 1 ar X iv :1 51 1. 06 41 0v 1 [ cs .L G ] 1 9 N ov 2 01 5 Under review as a conference paper at ICLR 2016 30k\t\r   1k\t\r   1d\t\r   7d\t\r   1p\t\r   9p (b) (a) (d) B W (c) Figure 1: A simple illustrations on Go rules and rating system. Images are from Internet. player is still behind compared to traditional open-source engines based on Monte-Carlo Tree Search (MCTS) [Browne et al. (2012); Kocsis & Szepesv\u00e1ri (2006)], let alone commercial ones. In this paper, we show that DCNN-based move predictions indeed give a strong Go AI, if properly trained. In particular, we carefully design the training process and choose to predict next k moves rather than the immediate next move to enrich the gradient signal. Despite our prediction giving a mere 2% boost for accuracy of move predictions, the win rate against open-source engines (e.g., Pachi and Fuego) in heavy search scenarios (e.g., 100k rollouts) is more than 6 times higher (Pachi: 11.0% vs 73.7%, Fuego: 12.5% vs 91.0%) than current state-of-the-art DCNN-based player [Maddison et al. (2015)]. In addition, we release our two bots, called darkforest and darkfores1, to public KGS Go server for free games. A collection of more than 2000 games against humans over three months show that the search-less darkforest holds a decent 1d-2d level, much better than the neural network based AI proposed by Clark & Storkey (2015) that holds 4-5 kyu estimated from games against other MCTS-based Go engines. Our bots also share the common weakness of DCNN-based methods in local tactics. We show that, by combining DCNN with MCTS, our bots can address the local tactics weakness and greatly boost the strength. With only 1000 rollouts, our synchronized version of DCNN+MCTS runs 6 seconds per move and achieves an impressive 90% win rate against pure DCNN. Our best model, darkfores2, combined with MCTS of 5000 rollouts, has a 95.5% win rate over Pachi with 10,000 rollouts. 2 METHOD Using Neural Network as a function approximator and pattern matcher to predict the next move of Go is a long-standing idea [Sutskever & Nair (2008); Richards et al. (1998); Schraudolph et al. (1994); Enzenberger (1996)]. Recent progress [Maddison et al. (2015); Clark & Storkey (2015)] uses Deep Convolutional Neural Network (DCNN) for move prediction, and shows substantial improvement over shallow networks or linear function approximators based on manually designed features or simple patterns extracted from previous games [Silver (2009)]. In this paper, we train a DCNN that predicts the next k moves given the current board situation as an input. We treat the 19\u00d7 19 board as a 19\u00d7 19 image with multiple channels. Each channel encodes a different aspect of board information, e.g., liberties (Fig. 1(b)). Compared to previous works, we use a more compact feature set and predict long-term moves, and show that they lead to a substantial performance boost in terms of win rate against open source engines. 2.1 FEATURE CHANNELS Table 1 shows the features extracted from the current board situation. Each feature is a binary 19\u00d719 map except for history information and position mask, which are real numbers in [0, 1]. History is encoded as exp(\u2212t \u2217 0.1), where t is how long the stone has been placed. The exponential temporal decay is meant to enable the network to focus on the recent battle. Position mark is defined as exp(\u2212 12 l ), where l is the squared L2 distance to the board center. It is used to encode the relative position of each intersection. There are two differences between our features and those in Maddison et al. (2015). First, we use relative coding (our/opponent) for almost all the features. In contrast, the features in Maddison et al. (2015) are largely player-agnostic. Second, our feature set is simpler and compact (25 vs. 36 input 2 Under review as a conference paper at ICLR 2016", "creator": "LaTeX with hyperref package"}}}