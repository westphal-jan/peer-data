{"id": "1511.07130", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2015", "title": "Parallel Predictive Entropy Search for Batch Global Optimization of Expensive Objective Functions", "abstract": "We develop parallel predictive entropy search (PPES), a novel algorithm for Bayesian optimization of expensive black-box objective functions. At each iteration, PPES aims to select a batch of points which will maximize the information gain about the global maximizer of the objective. Well known strategies exist for suggesting a single evaluation point based on previous observations, while far fewer are known for selecting batches of points to evaluate in parallel. The few batch selection schemes that have been studied all resort to greedy methods to compute an optimal batch. To the best of our knowledge, PPES is the first non-greedy batch Bayesian optimization strategy. We demonstrate the benefit of this approach in optimization performance on both synthetic and real world applications, including problems in machine learning, rocket science and robotics.", "histories": [["v1", "Mon, 23 Nov 2015 08:21:17 GMT  (311kb,D)", "http://arxiv.org/abs/1511.07130v1", "12 pages in Neural Information Processing Systems 2015"]], "COMMENTS": "12 pages in Neural Information Processing Systems 2015", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["amar shah", "zoubin ghahramani"], "accepted": true, "id": "1511.07130"}, "pdf": {"name": "1511.07130.pdf", "metadata": {"source": "CRF", "title": "Parallel Predictive Entropy Search for Batch Global Optimization of Expensive Objective Functions", "authors": ["Amar Shah", "Zoubin Ghahramani"], "emails": ["as793@cam.ac.uk", "zoubin@eng.cam.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "This year, we will be able to look for a solution that will enable us to find a solution, that will enable us to find a solution that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution, that will enable us to find a solution. \""}, {"heading": "2 Problem Statement and Background", "text": "Our goal is to maximize an objective function f: X \u2192 R, which is not known but can be evaluated very well, in several places in parallel. In this work we assume that X is a compact subset of RD. In each decision we have to select a series of Q points where we assume that t = {xt, 1,..., Q} X, where the objective function would be next evaluated in parallel, leads to a scalar observation yt, q = f (xt, q) + t, where we assume that t, q \u00b2 N (0, 2) i.e. we want to minimize a future regret, rT = [f) \u2212 f, where x-argmaxx (f) is an optimal decision (x)."}, {"heading": "3 Parallel Predictive Entropy Search", "text": "Analogous to [13], PPES aims to select the set of Q points, St = {xq} Qq = 1, which represents the maximizesaPES (St | D) = H [p (x) | D) -E p ({yq} Qq = 1, St) [H [p (x)] -E p (x) -D (x) -D (x) -D = 1, St) [H [p (x) -D) -D [p (x) -D) -D, St) [p (x) -D) -D [p] -D is the differential entropy of its argument and the aforementioned expectation is taken with respect to the subsequent Qyq-1 type."}, {"heading": "3.1 Approximating the Predictive Entropy", "text": "Under the assumption of a stitch sample of x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "3.2 Sampling from the Posterior over the Global Maximizer", "text": "So far we have considered how to approximate H [yq] Qq = 1 | D, St, x \u0445 x], since we have to estimate the expected value of this quantity via the posterior distribution of the global maximizer, p (x) | D). Literally, p (x), p (x), p (x), p (x), p (x), p (x), p (x), p (x), p (x), p (x), p (x), p (x), but it is possible to approximate the desired expectation of Monte Carlo. We will consider two approaches to amplify from the posterior of the global maximizer of f: (i) a maximum posteriori (MAP) method, and (ii) a random feaur approximation of p (x)."}, {"heading": "3.3 Computing and Optimizing the PPES Approximation", "text": "Let's use the set of kernel parameters and the observation of noise variance, \u03c32 q q = q q (Q = q) (Q = q) (K = q) (K = q) (K = q) (K = Q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = Q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = q) (K = q) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K)) (K) (K) (K) (K)) (K) (K) (K)) (K) (K) (K) (K) (K) (K)) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K) (K (K) (K) (K) (K) (K (K) (K) (K) (K (K) (K) (K (K) (K) (K (K) (K) (K (K) (K) (K) (K (K (K) (K) (K) (K (K) (K (K (K) (K) (K) (K) (K (K) (K) (K (K) (K) (K) (K (K) (K (K) (K) (K) (K) (K) (K) (K) (K) (K (K) (K) (K) (K) (K) (K) (K) (K) (K) (K (K) (K) (K) (K"}, {"heading": "4 Empirical Study", "text": "In this section, we will examine the performance of PPES in comparison to the above methods. We will model f as a Gaussian process with constant mean \u03bb and covariance kernel k. Observations of objective function are drawn independently of each other. (We will model f as a Gaussian process with constant mean and covariance kernel k.) In our experiments, we will select a quadratic-exponential core of form k (x, x, x). (We will therefore model the set of model hyperparameters so that it applies a broad Gaussian hyperprior to the other hyperparameters.) It is worth investigating how well a PPES process (7) is able to test aPPES (2). (2) To visualize the approach in a way, we will generate a sample f from another hyperparameter. It is worth investigating how well a PES (7) is able to approach PES (2)."}, {"heading": "5 Conclusions", "text": "Our method is greedy in the sense that it aims to maximize the one-step gain in information about the location of x *, but it is not greedy in the way it selects a set of points to be evaluated next. Previous methods are doubly greedy because they are one step ahead, and also greedily pick a set of points. Compliance methods tend to under-explore, which impairs their performance in multimodal, loud lens functions, as we show in our experiments."}], "references": [{"title": "Review of Metamodeling Techniques in Support of Engineering Design Optimization", "author": ["G. Wang", "S. Shan"], "venue": "Journal of Mechanical Design, 129(4):370\u2013380", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2007}, {"title": "Stochastic Optimization Models in Finance", "author": ["W. Ziemba", "R. Vickson"], "venue": "World Scientific Singapore,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2006}, {"title": "Practical Bayesian Optimization of Machine Learning Algorithms", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": "NIPS", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Bayesian Approach to Global Optimization: Theory and Applications", "author": ["J. Mockus"], "venue": "Kluwer", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1989}, {"title": "Automatic Gait Optimization with Gaussian Process Regression", "author": ["D. Lizotte", "T. Wang", "M. Bowling", "D. Schuurmans"], "venue": "IJCAI, pages 944\u2013949", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "The Knowledge-Gradient Algorithm for Sequencing Experiments in Drug Discovery", "author": ["D.M. Negoescu", "P.I. Frazier", "W.B. Powell"], "venue": "INFORMS Journal on Computing, 23(3):346\u2013 363", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2011}, {"title": "Gaussian Processes for Machine Learning", "author": ["Carl Rasmussen", "Chris Williams"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2006}, {"title": "Student-t Processes as Alternatives to Gaussian Processes", "author": ["A. Shah", "A.G. Wilson", "Z. Ghahramani"], "venue": "AISTATS", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2014}, {"title": "Mr Prabat", "author": ["J. Snoek", "O. Rippel", "K. Swersky", "R. Kiros", "N. Satish", "N. Sundaram", "M. Patwary"], "venue": "and R. P. Adams. Scalable Bayesian Optimization Using Deep Neural Networks. ICML", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "and N", "author": ["E. Brochu", "M. Cora"], "venue": "de Freitas. A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Applications to Active User Modeling and Hierarchical Reinforcement Learning. Technical Report TR-2009-23, University of British Columbia", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2009}, {"title": "Traveling salesman should not be greedy:domination analysis of greedy-type heuristics for the TSP", "author": ["G. Gutin", "A. Yeo", "A. Zverovich"], "venue": "Discrete Applied Mathematics, 117:81\u201386", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2002}, {"title": "Entropy Search for Information-Efficient Global Optimization", "author": ["P. Hennig", "C.J. Schuler"], "venue": "JMLR", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Predictive Entropy Search for Efficient Global Optimization of Black-box Functions", "author": ["J.M. Hern\u00e1ndez-Lobato", "M.W. Hoffman", "Z. Ghahramani"], "venue": "NIPS", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2014}, {"title": "Dealing with Asynchronicity in Parallel Gaussian Process Based Optimization", "author": ["D. Ginsbourger", "J. Janusevskis", "R. Le Riche"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2011}, {"title": "Batch Bayesian Optimization via Simulation Matching", "author": ["J. Azimi", "A. Fern", "X.Z. Fern"], "venue": "NIPS", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2010}, {"title": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "ICML", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2010}, {"title": "Parallelizing Exploration-Exploitation Tradeoffs with Gaussian Process Bandit Optimization", "author": ["T. Desautels", "A. Krause", "J. Burdick"], "venue": "ICML", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Parallel Gaussian Process Optimization with Upper Confidence Bound and Pure Exploration", "author": ["E. Contal", "D. Buffoni", "D. Robicquet", "N. Vayatis"], "venue": "Machine Learning and Knowledge Discovery in Databases, pages 225\u2013240. Springer Berlin Heidelberg", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2013}, {"title": "Information-Based Objective Functions for Active Data Selection", "author": ["D.J. MacKay"], "venue": "Neural Computation, 4(4):590\u2013604", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1992}, {"title": "Collaborative Gaussian Processes for Preference Learning", "author": ["N. Houlsby", "J.M. Hern\u00e1ndez-Lobato", "F. Huszar", "Z. Ghahramani"], "venue": "NIPS", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2012}, {"title": "A Family of Algorithms for Approximate Bayesian Inference", "author": ["T.P. Minka"], "venue": "PhD thesis, Masachusetts Institute of Technology", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2001}, {"title": "Lectures on Fourier Integrals", "author": ["S. Bochner"], "venue": "Princeton University Press", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1959}, {"title": "Random Features for Large-Scale Kernel Machines", "author": ["A. Rahimi", "B. Recht"], "venue": "NIPS", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2007}, {"title": "Bayesian Learning for Neural Networks", "author": ["R.M. Neal"], "venue": "PhD thesis, University of Toronto", "citeRegEx": "24", "shortCiteRegEx": null, "year": 1995}, {"title": "Expectation Propagation for Exponential Families", "author": ["M. Seeger"], "venue": "Technical Report, U.C. Berkeley", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2008}, {"title": "Gaussian Probabilities and Expectation Propagation", "author": ["J.P. Cunningham", "P. Hennig", "S. Lacoste-Julien"], "venue": "arXiv", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "A Nonparametric Estimation of the Entropy for Absolutely Continuous Distributions", "author": ["I. Ahmad", "P.E. Lin"], "venue": "IEEE Trans. on Information Theory, 22(3):372\u2013375", "citeRegEx": "27", "shortCiteRegEx": null, "year": 1976}, {"title": "Practical Bayesian Optimization", "author": ["D. Lizotte"], "venue": "PhD thesis, University of Alberta", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "A Nonparametric Approach to Noisy and Costly Optimization", "author": ["B.S. Anderson", "A.W. Moore", "D. Cohn"], "venue": "ICML", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2000}, {"title": "Test Functions for Multimodal Search Techniques", "author": ["J. Shekel"], "venue": "Information Science and Systems", "citeRegEx": "30", "shortCiteRegEx": null, "year": 1971}, {"title": "Optimization of ph and nitrogen for enhanced hydrogen production by synechocystis sp", "author": ["E.H. Burrows", "W.K. Wong", "X. Fern", "F.W.R. Chaplen", "R.L. Ely"], "venue": "pcc 6803 via statistical and machine learning methods. Biotechnology Progress, 25(4):1009\u20131017", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2009}, {"title": "In Classical Mechanics with MATLAB Applications", "author": ["J.E. Hasbun"], "venue": "Jones & Bartlett Learning", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2008}, {"title": "Feedback Control of Dynamic Bipedal Robot Locomotion", "author": ["E. Westervelt", "J. Grizzle"], "venue": "Control and Automation Series. CRC PressINC", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2007}, {"title": "EP: A Quick Reference", "author": ["T. Minka"], "venue": "Technical Report", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 0, "context": "engineering design [1], finance [2] and algorithm optimization [3].", "startOffset": 19, "endOffset": 22}, {"referenceID": 1, "context": "engineering design [1], finance [2] and algorithm optimization [3].", "startOffset": 32, "endOffset": 35}, {"referenceID": 2, "context": "engineering design [1], finance [2] and algorithm optimization [3].", "startOffset": 63, "endOffset": 66}, {"referenceID": 3, "context": "Bayesian optimization [4] has been successfully applied in a range of difficult, expensive global optimization tasks including optimizing a robot controller to maximize gait speed [5] and discovering a chemical derivative of a particular molecule which best treats a particular disease [6].", "startOffset": 22, "endOffset": 25}, {"referenceID": 4, "context": "Bayesian optimization [4] has been successfully applied in a range of difficult, expensive global optimization tasks including optimizing a robot controller to maximize gait speed [5] and discovering a chemical derivative of a particular molecule which best treats a particular disease [6].", "startOffset": 180, "endOffset": 183}, {"referenceID": 5, "context": "Bayesian optimization [4] has been successfully applied in a range of difficult, expensive global optimization tasks including optimizing a robot controller to maximize gait speed [5] and discovering a chemical derivative of a particular molecule which best treats a particular disease [6].", "startOffset": 286, "endOffset": 289}, {"referenceID": 6, "context": "A common approach for modeling f is to use a Gaussian process prior [7], as it is highly flexible and amenable to analytic calculations.", "startOffset": 68, "endOffset": 71}, {"referenceID": 7, "context": "Student-t process priors [8] and deep neural networks [9].", "startOffset": 25, "endOffset": 28}, {"referenceID": 8, "context": "Student-t process priors [8] and deep neural networks [9].", "startOffset": 54, "endOffset": 57}, {"referenceID": 9, "context": "expected improvement, probability of improvement and upper confidence bound [10], there are few well known strategies for selecting batches of points.", "startOffset": 76, "endOffset": 80}, {"referenceID": 10, "context": "Greedy choice making can be severely detrimental, for example, a greedy approach to the travelling salesman problem could potentially lead to the uniquely worst global solution [11].", "startOffset": 177, "endOffset": 181}, {"referenceID": 11, "context": "The algorithm we develop, parallel predictive entropy search, extends the methods of [12, 13] to multiple point batch selection.", "startOffset": 85, "endOffset": 93}, {"referenceID": 12, "context": "The algorithm we develop, parallel predictive entropy search, extends the methods of [12, 13] to multiple point batch selection.", "startOffset": 85, "endOffset": 93}, {"referenceID": 13, "context": "[14] considered an approach which sequentially used the EI criterion to greedily choose a batch of points to query next, which [3] formalized and utilized by defining aEI\u2212MCMC ( x|D, {xq\u2032}qq\u2032=1 ) = \u222b", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[14] considered an approach which sequentially used the EI criterion to greedily choose a batch of points to query next, which [3] formalized and utilized by defining aEI\u2212MCMC ( x|D, {xq\u2032}qq\u2032=1 ) = \u222b", "startOffset": 127, "endOffset": 130}, {"referenceID": 14, "context": "A similar but different approach called simulated matching (SM) was introduced by [15].", "startOffset": 82, "endOffset": 86}, {"referenceID": 15, "context": "The upper confidence bound (UCB) strategy [16] is another method used by practitioners to decide where to evaluate an objective function next.", "startOffset": 42, "endOffset": 46}, {"referenceID": 16, "context": "In order to extend this approach to the parallel setting, [17] noted that the predictive variance of a Gaussian process depends only on where observations are made, and not the observations themselves.", "startOffset": 58, "endOffset": 62}, {"referenceID": 17, "context": "Finally, a variant of the GP-UCB was proposed by [18].", "startOffset": 49, "endOffset": 53}, {"referenceID": 18, "context": "3 Parallel Predictive Entropy Search Our approach is to maximize information [19] about the location of the global maximizer x\u2217, which we measure in terms of the negative differential entropy of p(x\u2217|D).", "startOffset": 77, "endOffset": 81}, {"referenceID": 12, "context": "Analogous to [13], PPES aims to choose the set of Q points, St = {xq}Qq=1, which maximizes aPPES(St|D) = H [ p(x\u2217|D) ] \u2212 E p ( {yq}Qq=1 \u2223\u2223D,St)[H[p(x\u2217|D \u222a {xq, yq}Qq=1)]], (1) where H[p(x)] = \u2212 \u222b p(x) log p(x)dx is the differential entropy of its argument and the expectation above is taken with respect to the posterior joint predictive distribution of {yq}Qq=1 given the previous evaluations, D, and the set St.", "startOffset": 13, "endOffset": 17}, {"referenceID": 11, "context": "Significant approximations need to be made to (1) before it becomes practically useful [12].", "startOffset": 87, "endOffset": 91}, {"referenceID": 19, "context": "A convenient equivalent formulation of the quantity in (1) can be written as the mutual information between x\u2217 and {yq}Qq=1 given D [20].", "startOffset": 132, "endOffset": 136}, {"referenceID": 20, "context": "The integral in (4) can be approximated using expectation propagation [21].", "startOffset": 70, "endOffset": 74}, {"referenceID": 12, "context": "We propose as in [13], to sample and optimize an analytic approximation to g.", "startOffset": 17, "endOffset": 21}, {"referenceID": 21, "context": "By Bochner\u2019s theorem [22], a stationary kernel function, k, has a Fourier dual s(w), which is equal to the spectral density of k.", "startOffset": 21, "endOffset": 25}, {"referenceID": 22, "context": "Let \u03c6(x) = \u221a 2\u03b1/m cos(Wx+b) denote anm-dimensional feature mapping where W and b consist of m stacked samples from p(w, b), then the kernel k can be approximated by the inner product of these features, k(x,x\u2032) \u2248 \u03c6(x)>\u03c6(x\u2032) [23].", "startOffset": 223, "endOffset": 227}, {"referenceID": 23, "context": "In fact, limm\u2192\u221e g is a true sample from p(f |D) [24].", "startOffset": 48, "endOffset": 52}, {"referenceID": 2, "context": "A similar approach is taken in [3, 13].", "startOffset": 31, "endOffset": 38}, {"referenceID": 12, "context": "A similar approach is taken in [3, 13].", "startOffset": 31, "endOffset": 38}, {"referenceID": 24, "context": "1 of [25], which says that converged site parameters, {Z\u0303q, \u03bc\u0303q, \u03c3\u0303q} q=1 , have 0 derivative with respect to parameters of p(f+|D,St,x).", "startOffset": 5, "endOffset": 9}, {"referenceID": 25, "context": "A similar approach is taken in [26], and discussed in [7].", "startOffset": 31, "endOffset": 35}, {"referenceID": 6, "context": "A similar approach is taken in [26], and discussed in [7].", "startOffset": 54, "endOffset": 57}, {"referenceID": 0, "context": "(a) Synthetic objective function (blue line) defined on [0, 1], with noisy observations (black squares).", "startOffset": 56, "endOffset": 62}, {"referenceID": 0, "context": "(b) Ground truth aPPES defined on [0, 1], obtained by rejection sampling.", "startOffset": 34, "endOffset": 40}, {"referenceID": 0, "context": "In order to test the approximation in a manner amenable to visualization, we generate a sample f from a Gaussian process prior on X = [0, 1], with \u03b3 = 1, \u03c3 = 10\u22124 and l = 0.", "startOffset": 134, "endOffset": 140}, {"referenceID": 0, "context": "A rejection sampling based approach is used to compute the ground truth aPPES, defined on XQ = [0, 1].", "startOffset": 95, "endOffset": 101}, {"referenceID": 0, "context": "We first discretize [0, 1], and sample p(x\u2217|D) in (2) by evaluating samples from p(f |D) on the discrete points and choosing the input with highest function value.", "startOffset": 20, "endOffset": 26}, {"referenceID": 0, "context": "Samples from p(f |D) are evaluted on discrete points in [0, 1] and rejected if the highest function value occurs not at x\u2217.", "startOffset": 56, "endOffset": 62}, {"referenceID": 26, "context": "We add independent Gaussian noise with variance \u03c3 to the non rejected samples from the previous step and approximate H [ p ( y1, y2|D,x1,x2,x\u2217 )] using kernel density estimation [27].", "startOffset": 178, "endOffset": 182}, {"referenceID": 0, "context": "The black squares on the axes of Figures 1(b) and 1(c) represent the locations in X = [0, 1] where f has been noisily sampled, and the darker the shade, the larger the function value.", "startOffset": 86, "endOffset": 92}, {"referenceID": 27, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including BraninHoo [28], a mixture of cosines [29], a Shekel function with 10 modes [30] (each defined on [0, 1]) and the Hartmann-6 function [28] (defined on [0, 1]).", "startOffset": 104, "endOffset": 108}, {"referenceID": 28, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including BraninHoo [28], a mixture of cosines [29], a Shekel function with 10 modes [30] (each defined on [0, 1]) and the Hartmann-6 function [28] (defined on [0, 1]).", "startOffset": 131, "endOffset": 135}, {"referenceID": 29, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including BraninHoo [28], a mixture of cosines [29], a Shekel function with 10 modes [30] (each defined on [0, 1]) and the Hartmann-6 function [28] (defined on [0, 1]).", "startOffset": 169, "endOffset": 173}, {"referenceID": 0, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including BraninHoo [28], a mixture of cosines [29], a Shekel function with 10 modes [30] (each defined on [0, 1]) and the Hartmann-6 function [28] (defined on [0, 1]).", "startOffset": 191, "endOffset": 197}, {"referenceID": 27, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including BraninHoo [28], a mixture of cosines [29], a Shekel function with 10 modes [30] (each defined on [0, 1]) and the Hartmann-6 function [28] (defined on [0, 1]).", "startOffset": 227, "endOffset": 231}, {"referenceID": 0, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including BraninHoo [28], a mixture of cosines [29], a Shekel function with 10 modes [30] (each defined on [0, 1]) and the Hartmann-6 function [28] (defined on [0, 1]).", "startOffset": 244, "endOffset": 250}, {"referenceID": 30, "context": "The next function, hydrogen, returns the amount of hydrogen produced by particular bacteria as a function of pH and nitrogen levels of a growth medium [32].", "startOffset": 151, "endOffset": 155}, {"referenceID": 31, "context": "Thirdly we consider a function, rocket, which runs a simulation of a rocket [33] being launched from the Earth\u2019s surface and returns the time taken for the rocket to land on the Earth\u2019s surface.", "startOffset": 76, "endOffset": 80}, {"referenceID": 32, "context": "Finally we consider a function, robot, which returns the walking speed of a bipedal robot [34].", "startOffset": 90, "endOffset": 94}, {"referenceID": 0, "context": "The function\u2019s input parameters, which live in [0, 1], are the robot\u2019s controller.", "startOffset": 47, "endOffset": 53}, {"referenceID": 16, "context": "The greediness and nonrequirement of MCMC sampling of the SM-UCB, GP-BUCB and GP-UCB-PE algorithms make them amenable to large batch experiments, for example, [17] consider optimization in R with batches of size 10.", "startOffset": 159, "endOffset": 163}, {"referenceID": 0, "context": "Since \u00e2PPES is defined on XQ = [0, 1], this method may miss a global optimum.", "startOffset": 31, "endOffset": 37}, {"referenceID": 0, "context": "Other methods all select their batches greedily, and hence only need to optimize in X = [0, 1].", "startOffset": 88, "endOffset": 94}], "year": 2015, "abstractText": "We develop parallel predictive entropy search (PPES), a novel algorithm for Bayesian optimization of expensive black-box objective functions. At each iteration, PPES aims to select a batch of points which will maximize the information gain about the global maximizer of the objective. Well known strategies exist for suggesting a single evaluation point based on previous observations, while far fewer are known for selecting batches of points to evaluate in parallel. The few batch selection schemes that have been studied all resort to greedy methods to compute an optimal batch. To the best of our knowledge, PPES is the first nongreedy batch Bayesian optimization strategy. We demonstrate the benefit of this approach in optimization performance on both synthetic and real world applications, including problems in machine learning, rocket science and robotics.", "creator": "LaTeX with hyperref package"}}}