{"id": "1511.07211", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Nov-2015", "title": "Noisy Submodular Maximization via Adaptive Sampling with Applications to Crowdsourced Image Collection Summarization", "abstract": "We address the problem of maximizing an unknown submodular function that can only be accessed via noisy evaluations. Our work is motivated by the task of summarizing content, e.g., image collections, by leveraging users' feedback in form of clicks or ratings. For summarization tasks with the goal of maximizing coverage and diversity, submodular set functions are a natural choice. When the underlying submodular function is unknown, users' feedback can provide noisy evaluations of the function that we seek to maximize. We provide a generic algorithm \\submM{} for maximizing an unknown submodular function under cardinality constraints. This algorithm makes use of a novel exploration module -- \\blbox{} -- that proposes good elements based on adaptively sampling noisy function evaluations. \\blbox{} is able to accommodate different kinds of observation models such as value queries and pairwise comparisons. We provide PAC-style guarantees on the quality and sampling cost of the solution obtained by \\submM{}. We demonstrate the effectiveness of our approach in an interactive, crowdsourced image collection summarization application.", "histories": [["v1", "Mon, 23 Nov 2015 13:19:05 GMT  (1633kb,D)", "https://arxiv.org/abs/1511.07211v1", "AAAI'16"], ["v2", "Tue, 1 Dec 2015 09:49:35 GMT  (1736kb,D)", "http://arxiv.org/abs/1511.07211v2", "Extended version of AAAI'16 paper"]], "COMMENTS": "AAAI'16", "reviews": [], "SUBJECTS": "cs.AI cs.LG stat.ML", "authors": ["adish singla", "sebastian tschiatschek", "andreas krause 0001"], "accepted": true, "id": "1511.07211"}, "pdf": {"name": "1511.07211.pdf", "metadata": {"source": "CRF", "title": "Noisy Submodular Maximization via Adaptive Sampling with Applications to Crowdsourced Image Collection Summarization", "authors": ["Adish Singla", "Sebastian Tschiatschek", "Andreas Krause"], "emails": ["adish.singla@inf.ethz.ch", "sebastian.tschiatschek@inf.ethz.ch", "krausea@ethz.ch"], "sections": [{"heading": "Introduction", "text": "This year, the time has come for such a process as never before. \"It has come to the point,\" he says, \"where there is such a process, where there is such a process,\" he says. \"It's like there is such a process,\" he says. \"But it's not like there is such a process.\" \"It's like there is such a process,\" he says, \"but it's not like there is such a process.\""}, {"heading": "Related Work", "text": "The question is whether and in what form people are able to survive themselves and themselves, and the question is to what extent they are able to survive themselves, and to what extent they are able to survive themselves, and to what extent they are able to survive themselves, and to what extent they are able to survive themselves, and to what extent they are able to survive themselves, and to what extent they are able to survive themselves, and to what extent they are able to survive themselves, and to what extent they are able to survive themselves."}, {"heading": "Problem Statement", "text": "We assume that a utility function f: 2V \u2192 R over subsets of V. \"Given a series of items, the utility efficiency of this set f (S) is a bigger problem than f (S). Furthermore, we assume that f: 0, monotone and submodular items are not negative, monoton and submodular. It notes that f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 1, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f: 0, f"}, {"heading": "Submodular Maximization Under Noise", "text": "The simplest adaptive strategy that TOPX could implement is to estimate the confidence needed to decide on the next element. (However, the best difference between the individual elements is under noise.) Intuitively, it aims to imitate the greedy algorithms in noise-free environments and ensure that they select a good element in each iteration. (Since we cannot accurately evaluate the marginal benefits, we have to experiment with various items and use statistical inferences to select items of high value. (These experiments, the core part of our algorithm, will use a novel exploration module called TOPX.The EXPGREEDY, cf., algorithm 1, iteratively builds up a set of S V by making use of TOPX, \"k.\") to select the next item at each iteration. TOPX returns to items that could potentially be included in S to maximize its utility."}, {"heading": "Exploration Module TOPX", "text": "In this section we describe the design of our exploration module TOPX, which is used by EXPGREEDY."}, {"heading": "TOPX with Value Queries", "text": "We begin with the observation that for defining an optimal approach to the subdivision functions. (...) We begin with the observation that for defining an optimal approach to the subdivision functions. (...) We begin with the observation that for defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach. (...) We begin with defining an optimal approach."}, {"heading": "TOPX with Preference Queries", "text": "We now show how noisy preference queries can be used. As previously introduced, we assume that there is an underlying preference model (unknown to the algorithm) that results in the probabilities Pi > j | S for position i being preferred over position j based on the values f (i | S) and f (j | S). In this thesis, we focus on determining the Borda winner, i.e., position i maximizes the Borda score P (i | S), which is formally stated as point 1 (N \u2212 1). The Borda score measures the probability that position i is preferred over another point randomly selected. Furthermore, our model assumes that an increasing gap in the utilities leads to a monotonous increase in the induced probabilities, stating that the uppermost l-values in terms of marginal gains are the Borda scores for the uppermost l-scores."}, {"heading": "Experimental Evaluation", "text": "We are now reporting on the results of our synthetic experiments."}, {"heading": "Experimental Setup", "text": "In the synthetic experiments, we assume that there is an underlying submodular utility function f that we want to maximize. TOPX, the exploration module, performs value or preference queries and receives noisy responses based on model parameters and the marginal benefits of items for this function. For our experiments, we constructed a realistic probabilistic utility function that follows the ideas of El-Arini et al. (2009) on a principle of N = 60 items. Details of this construction are not important for the results given below and can be found in Appendix E of the extended version of this paper (Singla, Tschiatschek and Krause 2016). We compare several variants of our algorithm that we refer to in EXPGREEDY, which approach refers to the parameters used to call TOPX."}, {"heading": "Results", "text": "Sample Complexity. In Figure 3 (a) we look at value queries and compare the number of queries performed by different algorithms \u03b2 = number of available noise levels until the convergence of the solution with the desired guarantees. For deviation \u03c32, we generate the query responses by sampling samples uniformly from the interval [\u00b5 \u2212 \u03c32, \u00b5 + \u03c32], where \u00b5 is the expected value of this query. As a reference, the query costs of GREEDY are marked with access to the unknown function f (which corresponds to N \u00b7 k). Sample complexity differs by orders of magnitude, i.e. the number of queries performed by EXPGREEDY grows much more slowly than those performed by EXPGREEDYG and EXPGREEDYO. Sample complexity of UNIFORM is worse than that of other orders of magnitude compared to other variants of our algorithms."}, {"heading": "Image Collection Summarization", "text": "We are now presenting the results of a crowdsourcing application to summarize images carried out on Amazon's Mechanical Turk platform. As part of our V image set, we retrieved 60 images that are in any way related to the city of Venice, see Figure 1 (a). In total, over 100 different workers participated in a summary. Detailed instructions can be found in Appendix F of the extended version of this paper (Singla, Chiatschek and Krause 2016). We conducted three instances of the algorithm for three different summary tasks covering the topics (i) Venice, (ii) Venice and (iii) Venice."}, {"heading": "Conclusions", "text": "We have proposed algorithms based on novel adaptive sampling strategies to achieve high-quality solutions with low sample complexity. Our theoretical analyses and experimental evaluations provide insights into the trade-offs between solution quality and sample complexity. Furthermore, we have demonstrated the practical applicability of our approach to crowdsourcing image collections. We thank Besmira Nushi for helpful discussions. This research is supported in part by the SNF grant 200021 137971 and the Nano-Tera.ch program within the framework of the Opensense II project."}, {"heading": "Utility function f", "text": "We have retrieved 350 images from Flickr along with their associated metadata (asosciated tags, the total number of tags and the view count) that are in some way related to the city of Venice. [0, 1] Following El-Arini et al. (2009), we constructed f (S) = 20 j = 1 wj fj (S), each fj (S) being a probable coverage function with reach [0, 1] that quantifies how well a topic j is covered, and where wj is a weight that quantifies the importance of topic j. Specifically, we have done this as follows: For each of the 350 images from Flickr we get the asosciated tags of Ti, the total number of tags, and the view count."}, {"heading": "Set of items V", "text": "In order to construct our basic set V, we have downloaded another set of 60 test images (together with the associated metadata), which formed our test collection, which we want to summarize 3. These test images are shown in Figure 1 (a). Our goal is to summarize this test collection in simulations for Venice using the function constructed above. To this end, we define the coverage of a series of images S for subject j as fj (S) = 1 \u2212 s \"S (1 \u2212 f \u2032 j (s))),\" i.e. as a kind of probability reporting (El-Arini et al. 2009), in which f \u2032 j (s), \"log (vs) 1 [j-Ts] is normalized to [0, 1] across all j and s. Of course, more advanced models could be used for evaluating image collections, e.g. V-ROUGE, a scoring function tailored to the task of summarizing images (Chischek 2014)."}], "references": [{"title": "N", "author": ["M. Balcan", "Harvey"], "venue": "J. A.", "citeRegEx": "Balcan and Harvey 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "M", "author": ["R.A. Bradley", "Terry"], "venue": "E.", "citeRegEx": "Bradley and Terry 1952", "shortCiteRegEx": null, "year": 1952}, {"title": "Pure exploration in multi-armed bandits problems", "author": ["Munos Bubeck", "S. Stoltz 2009] Bubeck", "R. Munos", "G. Stoltz"], "venue": "In ALT,", "citeRegEx": "Bubeck et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bubeck et al\\.", "year": 2009}, {"title": "Submodular maximization with cardinality constraints", "author": ["Buchbinder"], "venue": null, "citeRegEx": "Buchbinder,? \\Q2014\\E", "shortCiteRegEx": "Buchbinder", "year": 2014}, {"title": "and H\u00fcllermeier", "author": ["R. Busa-Fekete"], "venue": "E.", "citeRegEx": "Busa.Fekete and H\u00fcllermeier 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "M", "author": ["S. Chen", "T. Lin", "I. King", "Lyu"], "venue": "R.; and Chen, W.", "citeRegEx": "Chen et al. 2014", "shortCiteRegEx": null, "year": 2014}, {"title": "Turning down the noise in the blogosphere", "author": ["El-Arini"], "venue": null, "citeRegEx": "El.Arini,? \\Q2009\\E", "shortCiteRegEx": "El.Arini", "year": 2009}, {"title": "Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems", "author": ["Mannor Even-Dar", "E. Mansour 2006] Even-Dar", "S. Mannor", "Y. Mansour"], "venue": null, "citeRegEx": "Even.Dar et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Even.Dar et al\\.", "year": 2006}, {"title": "and Singer", "author": ["A. Hassidim"], "venue": "Y.", "citeRegEx": "Hassidim and Singer 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "R", "author": ["K.G. Jamieson", "S. Katariya", "A. Deshpande", "Nowak"], "venue": "D.", "citeRegEx": "Jamieson et al. 2015", "shortCiteRegEx": null, "year": 2015}, {"title": "Maximizing the spread of influence through a social network", "author": ["Kleinberg Kempe", "D. Tardos 2003] Kempe", "J. Kleinberg", "\u00c9. Tardos"], "venue": null, "citeRegEx": "Kempe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kempe et al\\.", "year": 2003}, {"title": "and Golovin", "author": ["A. Krause"], "venue": "D.", "citeRegEx": "Krause and Golovin 2012", "shortCiteRegEx": null, "year": 2012}, {"title": "and Guestrin", "author": ["A. Krause"], "venue": "C.", "citeRegEx": "Krause and Guestrin 2005", "shortCiteRegEx": null, "year": 2005}, {"title": "and Guestrin", "author": ["A. Krause"], "venue": "C.", "citeRegEx": "Krause and Guestrin 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "and Guestrin", "author": ["A. Krause"], "venue": "C.", "citeRegEx": "Krause and Guestrin 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Near-optimal sensor placements: Maximizing information while minimizing communication cost", "author": ["Krause"], "venue": null, "citeRegEx": "Krause,? \\Q2006\\E", "shortCiteRegEx": "Krause", "year": 2006}, {"title": "R", "author": ["Luce"], "venue": "D.", "citeRegEx": "Luce 1959", "shortCiteRegEx": null, "year": 1959}, {"title": "Distributed submodular maximization: Identifying representative elements in massive data", "author": ["Mirzasoleiman"], "venue": null, "citeRegEx": "Mirzasoleiman,? \\Q2013\\E", "shortCiteRegEx": "Mirzasoleiman", "year": 2013}, {"title": "An analysis of the approximations for maximizing submodular set functions", "author": ["Wolsey Nemhauser", "G. Fisher 1978] Nemhauser", "L. Wolsey", "M. Fisher"], "venue": "Math. Prog", "citeRegEx": "Nemhauser et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Nemhauser et al\\.", "year": 1978}, {"title": "W", "author": ["A. Singh", "A. Krause", "Kaiser"], "venue": "J.", "citeRegEx": "Singh. Krause. and Kaiser 2009", "shortCiteRegEx": null, "year": 2009}, {"title": "Noisy submodular maximization via adaptive sampling with applications to crowdsourced image collection summarization (extended version). http://arxiv.org/abs/1511.07211", "author": ["Tschiatschek Singla", "A. Krause 2016] Singla", "S. Tschiatschek", "A. Krause"], "venue": null, "citeRegEx": "Singla et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Singla et al\\.", "year": 2016}, {"title": "and Golovin", "author": ["M. Streeter"], "venue": "D.", "citeRegEx": "Streeter and Golovin 2008", "shortCiteRegEx": null, "year": 2008}, {"title": "Learning mixtures of submodular functions for image collection summarization", "author": ["Tschiatschek"], "venue": null, "citeRegEx": "Tschiatschek,? \\Q2014\\E", "shortCiteRegEx": "Tschiatschek", "year": 2014}, {"title": "and Guestrin", "author": ["Y. Yue"], "venue": "C.", "citeRegEx": "Yue and Guestrin 2011", "shortCiteRegEx": null, "year": 2011}, {"title": "Optimal PAC multiple arm identification with applications to crowdsourcing", "author": ["Chen Zhou", "Y. Li 2014] Zhou", "X. Chen", "J. Li"], "venue": null, "citeRegEx": "Zhou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2014}, {"title": "Proof of Theorem 1 In the following, we provide the proof of Theorem 1. Proof. This proof adopts the proof of (Buchbinder et al", "author": ["A. Appendix"], "venue": null, "citeRegEx": "Appendix,? \\Q2014\\E", "shortCiteRegEx": "Appendix", "year": 2014}, {"title": "Proof Sketch of Theorem 3 For proving Theorem 3, consider a simpler variant of Algorithm 2. Assume that we solve the top identification problems for l \u2208", "author": ["C. Appendix"], "venue": null, "citeRegEx": "Appendix,? \\Q2014\\E", "shortCiteRegEx": "Appendix", "year": 2014}], "referenceMentions": [], "year": 2015, "abstractText": "We address the problem of maximizing an unknown submodular function that can only be accessed via noisy evaluations. Our work is motivated by the task of summarizing content, e.g., image collections, by leveraging users\u2019 feedback in form of clicks or ratings. For summarization tasks with the goal of maximizing coverage and diversity, submodular set functions are a natural choice. When the underlying submodular function is unknown, users\u2019 feedback can provide noisy evaluations of the function that we seek to maximize. We provide a generic algorithm \u2013 EXPGREEDY \u2013 for maximizing an unknown submodular function under cardinality constraints. This algorithm makes use of a novel exploration module \u2013 TOPX \u2013 that proposes good elements based on adaptively sampling noisy function evaluations. TOPX is able to accommodate different kinds of observation models such as value queries and pairwise comparisons. We provide PAC-style guarantees on the quality and sampling cost of the solution obtained by EXPGREEDY. We demonstrate the effectiveness of our approach in an interactive, crowdsourced image collection summarization application.", "creator": "LaTeX with hyperref package"}}}