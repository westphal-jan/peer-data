{"id": "1511.07543", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Nov-2015", "title": "Convergent Learning: Do different neural networks learn the same representations?", "abstract": "Recent success in training deep neural networks have prompted active investigation into the features learned on their intermediate layers. Such research is difficult because it requires making sense of non-linear computations performed by millions of learned parameters, but valuable because it increases our ability to understand current models and training algorithms and thus create improved versions of them. In this paper we investigate the extent to which neural networks exhibit what we call convergent learning, which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar low-dimensional spaces. We propose a specific method of probing representations: training multiple networks and then comparing and contrasting their individual, learned representations at the level of neurons or groups of neurons. We begin research into this question using three techniques to approximately align different neural networks on a feature level: a bipartite matching approach that makes one-to-one assignments between neurons, a sparse prediction approach that finds one-to-many mappings, and a spectral clustering approach that finds many-to-many mappings. This initial investigation reveals a few previously unknown properties of neural networks, and we argue that future research into the question of convergent learning will yield many more. The insights described here include (1) that some features are learned reliably in multiple networks, yet other features are not consistently learned; (2) that units learn to span low-dimensional subspaces and, while these subspaces are common to multiple networks, the specific basis vectors learned are not; (3) that the representation codes are a mix between a local code and slightly, but not fully, distributed codes across multiple units.", "histories": [["v1", "Tue, 24 Nov 2015 02:31:46 GMT  (9071kb,D)", "http://arxiv.org/abs/1511.07543v1", "A preliminary version of this work will be presented at the NIPS 2015 Feature Extraction workshop"], ["v2", "Fri, 8 Jan 2016 02:33:05 GMT  (9072kb,D)", "http://arxiv.org/abs/1511.07543v2", "A preliminary version of this work was presented at the NIPS 2015 Feature Extraction workshop"], ["v3", "Sun, 28 Feb 2016 22:04:54 GMT  (9072kb,D)", "http://arxiv.org/abs/1511.07543v3", "Published as a conference paper at ICLR 2016"]], "COMMENTS": "A preliminary version of this work will be presented at the NIPS 2015 Feature Extraction workshop", "reviews": [], "SUBJECTS": "cs.LG cs.NE", "authors": ["yixuan li", "jason yosinski", "jeff clune", "hod lipson", "john hopcroft"], "accepted": true, "id": "1511.07543"}, "pdf": {"name": "1511.07543.pdf", "metadata": {"source": "CRF", "title": "CONVERGENT LEARNING: DO DIFFERENT NEURAL NETWORKS LEARN THE SAME REPRESENTATIONS?", "authors": ["Yixuan Li", "Jason Yosinski", "Jeff Clune", "Hod Lipson", "John Hopcroft"], "emails": ["yli@cs.cornell.edu", "yosinski@cs.cornell.edu", "jeh@cs.cornell.edu", "jeffclune@uwyo.edu,", "hod.lipson@columbia.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, it is so that most of them are able to determine for themselves what they want and what they want. (...) It is not so that they are able to decide whether they want it or not. (...) It is not so that they want it. (...) It is not so that they want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...). \"(.).\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (.). \"(.).\" (. \"(.).\" (.). \"(.).\" (. \"(.).\" (.). \"(.\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.\" (.). \"(.).\" (. \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.\" (.). \"(.).\" (.).). \"(.\" (.). \"(.).\" (. \"(.).\" (.).). \"(.\" (.). \"(.).).\" (.). \"(.\" (.). \"(.).).\" (.). \"(.\" (.). \"(.).).).\" (. \"(.).\" ("}, {"heading": "2 EXPERIMENTAL SETUP", "text": "All networks in this study follow the basic architecture established by Krizhevsky et al. (2012), with parameters learned in five revolutionary layers (Conv1 - Conv5) followed by three fully connected layers (fc6 - fc8). The structure is slightly modified in two ways. First, Krizhevsky et al. (2012) uses limited connectivity between certain layer pairs to split the model across two GPUs.4 Here, we remove this artificial group structure and allow all channels on each layer to connect to all channels on the previous layer, as we only want to examine the group structure, which is of course not generated by architectural decisions. Second, we expose the local response-normalization layers after the failures that are released with the Caffe framework, which does not significantly affect performance (Jia et al, 2014). Networks are trained using Caffe Challenge on the Large Image Recgnition Scale."}, {"heading": "3 IS THERE A ONE-TO-ONE ALIGNMENT BETWEEN FEATURES LEARNED", "text": "We would like to investigate the similarities and differences between several training runs of the same network architecture. Due to the symmetries in the architecture and the weight initialization procedures, many equivalent solutions could be created for each parameter vector found simply by permutating the orders of units within one layer (and permutating the outgoing weights accordingly). Therefore, as a first step in analyzing the similarities and differences between different networks, we ask the following question: If we allow ourselves to permutate the units of a network, to what extent can we reconcile it with another? To do this, we need to find units of equivalent or approximately equivalent value across the network, and for this task we use the size-independent measurements of correlation and mutual information. We give the results primarily with the simpler, computationally faster correlation measure (Section 3.1), but then confirm the mutual measure of information qualitatively similar results (Section 3.2)."}, {"heading": "3.1 ALIGNMENT VIA CORRELATION", "text": "As discussed in section 2, we calculate correlations within the network and between the network units. Figure 1 shows the correlation values measured within the network, which are calculated between units on a network and other units on the same network (Figures a, b), as well as the inter-net correlations between two different networks (Figure c). We find matching units between a pair of networks - here Net1 and Net2 - in two ways. In the first approach, for each unit in Net1, we find the unit in Net2 with maximum correlation to it, which is approximately the maximum unit along each line of Figure 1c. This type of mapping is known as bipartite semi-matching in graph theory (Lawler, 1976), and we adopt the same nomenclature. This method can lead to multiples of Net1 paired with the same unit in Net2. Figure 2 shows the eight highest correlation characteristics and eight lowest matching characteristics, which coincide with the matching semanclature."}, {"heading": "3.2 ALIGNMENT VIA MUTUAL INFORMATION", "text": "Since correlation is a relatively simple mathematical measure that could overlook some forms of statistical dependence, we also performed one-to-one alignments of neurons by measuring the mutual information between them. Mutual information measures how much knowledge is gained about one variable by knowing the value of another. Formally, the mutual information of the two random variables X (n) l, i and X (m) l, j, which defines the activation of the i-th neuron in Netn and the j-th neuron in Netn as: I (X (n) l, i; X (m) l, j: I (n) l, i \u00b2 b \u00b2 X (m) l, j p (a, b) log (p (a) p (b))), where p (a, b) is the common probability distribution of X (n) l, i and X (m) l, i \u00b2 b) l, and p (a) b (matt) (a) log (b) (b) (p) (p) (p) (p) (p), where p (p) is common."}, {"heading": "4 RELAXING THE ONE-TO-ONE CONSTRAINT TO FIND SPARSE, FEW-TO-ONE MAPPINGS", "text": "The previous section showed that while some neurons have a one-on-one match in another network, for other neurons there is no one-on-one match (with correlation above a modest threshold). For example, 17% of neurons in Net1 have no match in Net2 with a correlation above 0.5 (Figure 3); this figure rises to 37% for convection 2.63% for convection 3 and 92% for convection 4 before falling to 75% for convection 5 (see Figure 10).These numbers suggest that, especially for intermediate layers, a simple one-on-one mapping is not a sufficient model to predict the activations of some neurons in a network (even with the same task).The result could be either because the representations are unique (i.e. not convergent), or because the best possible one-on-one mapping is insufficient to tell the full story of a representation."}, {"heading": "5 CONCLUSIONS", "text": "We have demonstrated a method of quantifying trait similarity between different, independently trained deep neural networks. We show how insights can be gained by stringing different neural networks together on a trait or subspace level by mixing three approaches: bipartite matching that makes one-to-one mappings between neurons, a sparse prediction, and a cluster approach that finds one-to-one mappings. Our key findings are: 1. Some traits are reliably learned in multiple networks, but other traits are not consistently learned; 2. Learn units to span low-dimensional subspaces, and while these subspaces are distributed across multiple networks that are learned specific base vectors."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors thank NASA Space Technology Research Fellowship (JY) for funding, Wendy Shang for talks and initial ideas, Yoshua Bengio for modeling suggestions, and Anh Nguyen and Kilian Weinberger for helpful comments and editing. This work was partially supported by the US Army Research Office W911NF-14-1-0477, NSF Grant 1527232. Jeff Clune was awarded an NSF CAREER Award (CAREER: 1453549)."}, {"heading": "S.1 ACTIVATION VALUES: HIGH CORRELATION VS. LOW CORRELATION", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "S.2 ADDITIONAL MATCHING RESULTS", "text": "Figure 10 shows additional results of comparing tasks generated by semi-matching and matching methods in conven2 - conven5. For each unit, both semi-matching and matching are found, then the units are sorted in the order of decreasing semi-matching values and both correlation values are plotted."}, {"heading": "S.3 DOES RELAXING THE ONE-TO-ONE CONSTRAINT TO FIND MANY-TO-MANY GROUPINGS REVEAL MORE SIMILARITIES BETWEEN WHAT DIFFERENT NETWORKS LEARN?", "text": "Since the previous sections have shown that neurons do not necessarily correspond via a globally consistent one-to-one synchronization between networks, we are now trying to find many-to-many synchronizations between networks using a spectral cluster approach."}, {"heading": "S.3.1 NEURON SIMILARITY GRAPHS", "text": "We define three types of similarity diagrams based on the correlation matrices obtained above. Single-mesh neuron similarity diagrams. Each vertex vp in this diagram represents a unit p in layer l. Two vertexes are connected by an edge of weight cpq if the correlation value cpq in the self-correlation matrix corr (Xl, Xl) between unit p and unit q is greater than a certain threshold. For a pair of fully formed DNNsX and Y, the correlation value cpq in the self-correlation matrix corr (Xl, Xl) between unit q can be constructed in a similar manner. Note that GXY, l is a two-part graph and contains twice as many vertices as the one in GX."}, {"heading": "S.3.2 SPECTRAL CLUSTERING AND METRICS FOR NEURON CLUSTERS", "text": "We define three types of similarity diagrams based on the correlation matrices obtained above (see section p. 3.1 for definition). Let us define Wl-R2Sl-2Sl as combined correlation matrices between two DNNs, X and Y in layer l, where wjk is the entry in the jth line and in the box column of this matrix. Sl is the number of channels (units) in layer L. Wl is defined as Wl = [korr (Xl, Xl) korr (Xl, Yl) korr (Xl, Yl) > korr (Yl, Yl)].The unnormalized laplazian matrix is defined as Ll = Dl \u2212 Wl, where the degree matrix Dl is the diagonal matrix with degrees dj = \u0445 2Sl k = 1 wjk."}, {"heading": "S.3.3 SPECTRAL CLUSTERING RESULTS", "text": "Figure 12 shows the permutated combined correlation matrix after applying the spectral cluster algorithm for Conv1 - Conv5. Figure 13 shows 12 neuron clusters with high similarities between the networks in Conv1 layer, and Figure 14 shows the top 8 neuron clusters with the highest similarity measurement between Conv2 layer. The matching results indicate that there are multiple matches of the feature cards between two fully formed networks with different random initializations, and the number of neurons learning the same feature may vary between networks. In practice, for example, the four units of {89, 90, 134, 226} in Net1 and three units of {2, 39, 83} in Net2 can learn the features about green objects."}, {"heading": "S.3.4 HIERARCHICAL SPECTRAL CLUSTERING RESULTS", "text": "Due to the stochastic effects of random initialization of centroids in k-middle clusters, some of the initial clusters contain more neurons than others. To obtain a finer-grained cluster structure, we repeatedly apply k-middle clustering to any cluster of size > 2\u03b1 \u00b7 Sl, \u03b1 being a tunable parameter to adjust the maximum size of the leaf clusters. Figure 15 shows the partial hierarchical structure of neuron cluster partnerships in the convex layer. The cluster at the root of the tree is a first-level cluster containing many similar units from both DNNs. Here, we assume \u03b1 = 0.025 for the convex layer, resulting in a hierarchical neuron cluster tree structure with leaf clusters containing fewer than 6 neurons from each network.The fat box of each subcluster contains neurons from Net1 and the remaining neurons from Net2, for example, Net62, has similar units, namely # 137, which have characteristics from Submag2, # 33."}, {"heading": "S.3.5 METRICS FOR NEURON CLUSTERS", "text": "Here we present two quantifiers for quantifying the similarity between neurons, which are grouped by application of the cluster algorithm described above. Similarities between the networks: SimXl \u2192 Yl = (Sl \u2211 p = 1 Sl \u2211 q = 1 corr (Xl, Yl) pq) / S2lSimilarities within the network: SimXl, Yl = (SimXl \u2192 Xl + SimYl \u2192 Yl) / 2We conducted further experiments to quantify the similarity between merged neurons. Figure 16 shows the measurement of the similarity between the network and within the network for Conv1 - Conv5. The value of k for the initial cluster formation is fixed at 40 for Conv1 layer and 100 for all other layers. In our experiments, the number of final clusters, which are reached after further hierarchical branching, is {43, 113, 130, 155, 131}. The tail in these neurons with the zero value is due to the similarity between the contexts only 3."}, {"heading": "S.4 COMPARING AVERAGE NEURAL ACTIVATIONS WITHIN AND BETWEEN NETWORKS", "text": "The first layer of networks trained on natural images (here the conv1 layer) tends to learn channels that correspond to similar patterns as gabor filters (oriented edge filters) and color spots. As shown in Figure 18, there are certain systematic distortions in the relative orders of magnitude of activations of the various channels of the first layer. Responses of low frequency filters are much larger than those of high frequency filters. This phenomenon is probably a consequence of the 1 / f power spectrum of activation of natural images, in which on average low spatial frequencies tend to contain a higher energy (because they are more common) than high spatial frequencies. In Figure 17, we show the mean activations for each unit of four networks, plotted in sorted order from the highest to the lowest. Firstly, and most clearly, we see a pattern of strongly varying mean activation values across units, with a gap between the most active and least active units."}], "references": [{"title": "Provable bounds for learning some deep representations", "author": ["Arora", "Sanjeev", "Bhaskara", "Aditya", "Ge", "Rong", "Ma", "Tengyu"], "venue": "In ICML, pp", "citeRegEx": "Arora et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Arora et al\\.", "year": 2014}, {"title": "Identifying and attacking the saddle point problem in high-dimensional non-convex optimization", "author": ["Dauphin", "Yann", "Pascanu", "Razvan", "G\u00fcl\u00e7ehre", "\u00c7aglar", "Cho", "Kyunghyun", "Ganguli", "Surya", "Bengio", "Yoshua"], "venue": "CoRR, abs/1406.2572,", "citeRegEx": "Dauphin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dauphin et al\\.", "year": 2014}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-Jia", "Kai", "Fei-Fei"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Understanding deep architectures using a recursive convolutional network", "author": ["Eigen", "David", "Rolfe", "Jason", "Fergus", "Rob", "LeCun", "Yann"], "venue": "arXiv preprint arXiv:1312.1847,", "citeRegEx": "Eigen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Eigen et al\\.", "year": 2013}, {"title": "Explaining and Harnessing Adversarial Examples", "author": ["Goodfellow", "Ian J", "Shlens", "Jonathon", "Szegedy", "Christian"], "venue": "ArXiv e-prints,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "An n\u02c65/2 algorithm for maximum matchings in bipartite graphs", "author": ["Hopcroft", "John E", "Karp", "Richard M"], "venue": "SIAM Journal on computing,", "citeRegEx": "Hopcroft et al\\.,? \\Q1973\\E", "shortCiteRegEx": "Hopcroft et al\\.", "year": 1973}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Jia", "Yangqing", "Shelhamer", "Evan", "Donahue", "Jeff", "Karayev", "Sergey", "Long", "Jonathan", "Girshick", "Ross", "Guadarrama", "Sergio", "Darrell", "Trevor"], "venue": "arXiv preprint arXiv:1408.5093,", "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoff"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Combinatorial optimization: networks and matroids", "author": ["Lawler", "Eugene L"], "venue": "Courier Corporation,", "citeRegEx": "Lawler and L.,? \\Q1976\\E", "shortCiteRegEx": "Lawler and L.", "year": 1976}, {"title": "Understanding image representations by measuring their equivariance and equivalence", "author": ["Lenc", "Karel", "Vedaldi", "Andrea"], "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Lenc et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lenc et al\\.", "year": 2015}, {"title": "Understanding deep image representations by inverting them", "author": ["Mahendran", "Aravindh", "Vedaldi", "Andrea"], "venue": "arXiv preprint arXiv:1412.0035,", "citeRegEx": "Mahendran et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mahendran et al\\.", "year": 2014}, {"title": "Kernel analysis of deep networks", "author": ["Montavon", "Gr\u00e9goire", "Braun", "Mikio L", "M\u00fcller", "Klaus-Robert"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Montavon et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Montavon et al\\.", "year": 2011}, {"title": "Sparse matrix factorization", "author": ["Neyshabur", "Behnam", "Panigrahy", "Rina"], "venue": "arXiv preprint arXiv:1311.3315,", "citeRegEx": "Neyshabur et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Neyshabur et al\\.", "year": 2013}, {"title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images", "author": ["Nguyen", "Anh", "Yosinski", "Jason", "Clune", "Jeff"], "venue": "arXiv preprint arXiv:1412.1897,", "citeRegEx": "Nguyen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2014}, {"title": "Why does deep learning work?-a perspective from group theory", "author": ["Paul", "Arnab", "Venkatasubramanian", "Suresh"], "venue": "arXiv preprint arXiv:1412.6621,", "citeRegEx": "Paul et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Paul et al\\.", "year": 2014}, {"title": "Deep inside convolutional networks: Visualising image classification models and saliency maps", "author": ["Simonyan", "Karen", "Vedaldi", "Andrea", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1312.6034,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Intriguing properties of neural networks", "author": ["Szegedy", "Christian", "Zaremba", "Wojciech", "Sutskever", "Ilya", "Bruna", "Joan", "Erhan", "Dumitru", "Goodfellow", "Ian J", "Fergus", "Rob"], "venue": "CoRR, abs/1312.6199,", "citeRegEx": "Szegedy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2013}, {"title": "Regression shrinkage and selection via the lasso", "author": ["Tibshirani", "Robert"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pp", "citeRegEx": "Tibshirani and Robert.,? \\Q1996\\E", "shortCiteRegEx": "Tibshirani and Robert.", "year": 1996}, {"title": "How transferable are features in deep neural networks", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Yosinski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yosinski et al\\.", "year": 2014}, {"title": "Understanding neural networks through deep visualization", "author": ["Yosinski", "Jason", "Clune", "Jeff", "Nguyen", "Anh", "Fuchs", "Thomas", "Lipson", "Hod"], "venue": "In Deep Learning Workshop, International Conference on Machine Learning (ICML),", "citeRegEx": "Yosinski et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yosinski et al\\.", "year": 2015}, {"title": "Visualizing and understanding convolutional networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "In ECCV, pp", "citeRegEx": "Zeiler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 0, "context": "Many recent studies have focused on understanding deep neural networks from both a theoretical perspective (Arora et al., 2014; Neyshabur & Panigrahy, 2013; Montavon et al., 2011; Paul & Venkatasubramanian, 2014; Goodfellow et al., 2014) and from an empirical perspective (Eigen et al.", "startOffset": 107, "endOffset": 237}, {"referenceID": 11, "context": "Many recent studies have focused on understanding deep neural networks from both a theoretical perspective (Arora et al., 2014; Neyshabur & Panigrahy, 2013; Montavon et al., 2011; Paul & Venkatasubramanian, 2014; Goodfellow et al., 2014) and from an empirical perspective (Eigen et al.", "startOffset": 107, "endOffset": 237}, {"referenceID": 4, "context": "Many recent studies have focused on understanding deep neural networks from both a theoretical perspective (Arora et al., 2014; Neyshabur & Panigrahy, 2013; Montavon et al., 2011; Paul & Venkatasubramanian, 2014; Goodfellow et al., 2014) and from an empirical perspective (Eigen et al.", "startOffset": 107, "endOffset": 237}, {"referenceID": 3, "context": ", 2014) and from an empirical perspective (Eigen et al., 2013; Szegedy et al., 2013; Simonyan et al., 2013; Zeiler & Fergus, 2014; Nguyen et al., 2014; Yosinski et al., 2014; Mahendran & Vedaldi, 2014; Yosinski et al., 2015).", "startOffset": 42, "endOffset": 224}, {"referenceID": 16, "context": ", 2014) and from an empirical perspective (Eigen et al., 2013; Szegedy et al., 2013; Simonyan et al., 2013; Zeiler & Fergus, 2014; Nguyen et al., 2014; Yosinski et al., 2014; Mahendran & Vedaldi, 2014; Yosinski et al., 2015).", "startOffset": 42, "endOffset": 224}, {"referenceID": 13, "context": ", 2014) and from an empirical perspective (Eigen et al., 2013; Szegedy et al., 2013; Simonyan et al., 2013; Zeiler & Fergus, 2014; Nguyen et al., 2014; Yosinski et al., 2014; Mahendran & Vedaldi, 2014; Yosinski et al., 2015).", "startOffset": 42, "endOffset": 224}, {"referenceID": 18, "context": ", 2014) and from an empirical perspective (Eigen et al., 2013; Szegedy et al., 2013; Simonyan et al., 2013; Zeiler & Fergus, 2014; Nguyen et al., 2014; Yosinski et al., 2014; Mahendran & Vedaldi, 2014; Yosinski et al., 2015).", "startOffset": 42, "endOffset": 224}, {"referenceID": 19, "context": ", 2014) and from an empirical perspective (Eigen et al., 2013; Szegedy et al., 2013; Simonyan et al., 2013; Zeiler & Fergus, 2014; Nguyen et al., 2014; Yosinski et al., 2014; Mahendran & Vedaldi, 2014; Yosinski et al., 2015).", "startOffset": 42, "endOffset": 224}, {"referenceID": 0, "context": "Many recent studies have focused on understanding deep neural networks from both a theoretical perspective (Arora et al., 2014; Neyshabur & Panigrahy, 2013; Montavon et al., 2011; Paul & Venkatasubramanian, 2014; Goodfellow et al., 2014) and from an empirical perspective (Eigen et al., 2013; Szegedy et al., 2013; Simonyan et al., 2013; Zeiler & Fergus, 2014; Nguyen et al., 2014; Yosinski et al., 2014; Mahendran & Vedaldi, 2014; Yosinski et al., 2015). In this paper we continue this trajectory toward attaining a deeper understanding of neural net training by proposing a new approach. We begin by noting that modern deep neural networks (DNNs) exhibit an interesting phenomenon: networks trained starting at different random initializations frequently converge to solutions with similar performance (see Dauphin et al. (2014) and Section 2 below).", "startOffset": 108, "endOffset": 831}, {"referenceID": 7, "context": "We employ an architecture derived from AlexNet (Krizhevsky et al., 2012) and train multiple networks on the ImageNet dataset (Deng et al.", "startOffset": 47, "endOffset": 72}, {"referenceID": 2, "context": ", 2012) and train multiple networks on the ImageNet dataset (Deng et al., 2009) (details in Section 2).", "startOffset": 60, "endOffset": 79}, {"referenceID": 6, "context": "Second, we place the local response normalization layers after the pooling layers following the defaults released with the Caffe framework, which does not significantly impact performance (Jia et al., 2014).", "startOffset": 188, "endOffset": 206}, {"referenceID": 2, "context": "Networks are trained using Caffe on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012 dataset (Deng et al., 2009).", "startOffset": 112, "endOffset": 131}, {"referenceID": 7, "context": "3% reported in the original study (Krizhevsky et al., 2012).", "startOffset": 34, "endOffset": 59}, {"referenceID": 5, "context": "2 EXPERIMENTAL SETUP All networks in this study follow the basic architecture laid out by Krizhevsky et al. (2012), with parameters learned in five convolutional layers (conv1 \u2013 conv5) followed by three fully connected layers (fc6 \u2013 fc8).", "startOffset": 90, "endOffset": 115}, {"referenceID": 5, "context": "2 EXPERIMENTAL SETUP All networks in this study follow the basic architecture laid out by Krizhevsky et al. (2012), with parameters learned in five convolutional layers (conv1 \u2013 conv5) followed by three fully connected layers (fc6 \u2013 fc8). The structure is modified slightly in two ways. First, Krizhevsky et al. (2012) employed limited connectivity between certain pairs of layers to enable splitting the model across two GPUs.", "startOffset": 90, "endOffset": 319}, {"referenceID": 2, "context": "Networks are trained using Caffe on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012 dataset (Deng et al., 2009). We trained four networks in the above manner using four different random initializations. We refer to these as Net1, Net2, Net3, and Net4. The four networks perform very similarly on the validation set, achieving top-1 accuracies of 58.65%, 58.73%, 58.79%, and 58.84%, which are similar to the top-1 performance of 59.3% reported in the original study (Krizhevsky et al., 2012). Note that we use the words \u201cfilters\u201d, \u201cchannels\u201d, \u201cneurons\u201d, and \u201cunits\u201d interchangeably to mean channels for a convolutional layer or individual units in a fully connected layer. Or, more generally, a space that is an affine transformation of the first network\u2019s representation space. In Krizhevsky et al. (2012) the conv2, conv4, and conv5 layers were only connected to half of the preceding layer\u2019s channels.", "startOffset": 113, "endOffset": 826}, {"referenceID": 18, "context": "This result may be related to previously observed greater complexity in the intermediate layers as measured through the lens of optimization difficulty (Yosinski et al., 2014).", "startOffset": 152, "endOffset": 175}, {"referenceID": 19, "context": ", deconv (Zeiler & Fergus, 2014), DeepVis (Yosinski et al., 2015), have revealed neurons with multiple functions (e.", "startOffset": 42, "endOffset": 65}], "year": 2017, "abstractText": "Recent successes in training large, deep neural networks have prompted active investigation into the representations learned on their intermediate layers. Such research is difficult because it requires making sense of non-linear computations performed by millions of learned parameters, but valuable because it increases our ability to understand current models and training algorithms and thus create improved versions of them. In this paper we investigate the extent to which neural networks exhibit what we call convergent learning, which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar lowdimensional spaces. We propose a specific method of probing representations: training multiple networks and then comparing and contrasting their individual, learned representations at the level of neurons or groups of neurons. We begin research into this question by introducing three techniques to approximately align different neural networks on a feature or subspace level: a bipartite matching approach that makes one-to-one assignments between neurons, a sparse prediction and clustering approach that finds one-to-many mappings, and a spectral clustering approach that finds many-to-many mappings. This initial investigation reveals a few interesting, previously unknown properties of neural networks, and we argue that future research into the question of convergent learning will yield many more. The insights described here include (1) that some features are learned reliably in multiple networks, yet other features are not consistently learned; (2) that units learn to span low-dimensional subspaces and, while these subspaces are common to multiple networks, the specific basis vectors learned are not; (3) that the representation codes are a mix between a local (single unit) code and slightly, but not fully, distributed codes across multiple units; (4) that the average activation values of neurons vary considerably within a network, yet the mean activation values across different networks converge to an almost identical distribution. 1", "creator": "LaTeX with hyperref package"}}}