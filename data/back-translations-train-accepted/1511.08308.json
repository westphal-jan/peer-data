{"id": "1511.08308", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Nov-2015", "title": "Named Entity Recognition with Bidirectional LSTM-CNNs", "abstract": "Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance. In this paper, we present a novel neural network architecture that automatically detects word- and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering. We also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing exact match approaches. Extensive evaluation shows that, given only tokenized text, publicly available word vectors, and an automatically constructed lexicon from open sources, our system is able to surpass the reported state-of-the-art on the OntoNotes 5.0 dataset by 2.35 F1 points and achieves competitive results on the CoNLL 2003 dataset, rivaling systems that employ heavy feature engineering, proprietary lexicons, and rich entity linking information.", "histories": [["v1", "Thu, 26 Nov 2015 07:40:33 GMT  (72kb,D)", "http://arxiv.org/abs/1511.08308v1", null], ["v2", "Fri, 25 Mar 2016 09:23:52 GMT  (93kb,D)", "http://arxiv.org/abs/1511.08308v2", null], ["v3", "Tue, 29 Mar 2016 06:25:57 GMT  (93kb,D)", "http://arxiv.org/abs/1511.08308v3", null], ["v4", "Thu, 16 Jun 2016 06:15:49 GMT  (94kb,D)", "http://arxiv.org/abs/1511.08308v4", "To appear in Transactions of the Association for Computational Linguistics"], ["v5", "Tue, 19 Jul 2016 05:02:51 GMT  (94kb,D)", "http://arxiv.org/abs/1511.08308v5", "To appear in Transactions of the Association for Computational Linguistics"]], "reviews": [], "SUBJECTS": "cs.CL cs.LG cs.NE", "authors": ["jason p c chiu", "eric nichols"], "accepted": true, "id": "1511.08308"}, "pdf": {"name": "1511.08308.pdf", "metadata": {"source": "CRF", "title": "Named Entity Recognition with Bidirectional LSTM-CNNs", "authors": ["Jason P.C. Chiu", "Eric Nichols"], "emails": ["jsonchiu@gmail.com", "e.nichols@jp.honda-ri.com"], "sections": [{"heading": "1 Introduction", "text": "Named entity recognition is an important task in NLP. High-performance approaches have been dominated by using statistical models such as CRF, SVM, or perceptron models to craft functions (Ratinov and Roth, 2009; Passos et al., 2014; Luo et al., 2015). But Collobert et al. (2011b) has proposed an effective neural network model that requires little feature engineering and instead learns important features from word embeddings trained on large amounts of unlabeled text - an approach that is based on a variety of data due to recent advances in unmonitored learning of word embeddings (Collobert and Weston, 2008). Mikolov et al., 2013) and neural network algorithms that allow for deep architectures (Rumelhart et al., 1986). Unfortunately, there are many limitations to the model proposed by Collobert et al. (2011b)."}, {"heading": "2 Model", "text": "Our neural network is inspired by the work of Collobert et al. (2011b), where feature vectors are calculated by lookup tables, linked together, and then fed into a multi-layered network. Instead of a feed-forward network, we use the more powerful recurrent neural network; in particular, we choose the bi-directional short-term memory (LSTM), which is successfully used in other sequence marking tasks such as speech recognition (Graves et al., 2013). In addition, we use the idea of a Convolutionary Neural Network for inducing character-level characteristics, which has been successfully applied in Spanish and Portuguese NERS (dos Santos et al., 2015) and German POStagging (Labeau et al., 2015)."}, {"heading": "2.1 Word-level Features", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1.1 Word Embeddings", "text": "Our best model uses the publicly available 50-dimensional word embeddings published by Collobert et al. (2011b) 1, which were trained on Wikipedia and Reuters RCV-1 corporation. We also experimented with two other groups of published embeddings, namely Stanford's GloVe embeddings2 with 6 billion words from Wikipedia and Web text (Pennington et al., 2014) and Google's word2vec embeddings3 with 100 billion words from Google News (Mikolov et al., 2013). Furthermore, assuming that word embeddings trained on in-domain text might work better, we also used the publicly available GloVe program (Pennington et al., 2014) and an internal re-implementation 4 of the word2vec program (Mikolov et al., 2013) to convert word embeddings on Wikipedia and Reuters RCV1 datasets to be pre-embedded in their respective table."}, {"heading": "2.1.2 Capitalization Feature", "text": "Since capitalization information is deleted when looking up word embedding, we evaluate Collobert's method of using a separate lookup table to add a capitalization function with the following options: allCaps, uppercase, lowercase, mixedCaps, noinfo (Collobert et al., 2011b) This method is compared with the character type features we introduce in Section 2.2.1 Part of SENNA: http: / / ml.nec-labs.com / senna / 2Available at http: / / nlp.stanford.edu / projects / glove / 3Available at https: / / code.google.com / p / word2vec / 4We used our in-house rhyming implementation to train word vectors because it uses distributed processing to train much faster than the publicly published implementation of word2vec and its performance in the word analogy task reported by Micoloet in 2013."}, {"heading": "2.1.3 Lexicons", "text": "Almost all state-of-the-art systems use lexicographs as a form of external knowledge (Ratinov and Roth, 2009; Passos et al., 2014; Durrett and Klein, 2014; Luo et al., 2015).For each of the four categories (person, organization, location, miscellaneous) defined by the CoNLL in 2003, we have compiled a list of known named entities from DBpedia (Auer et al., 2007) by assigning all descendants of the DBpedia types that have been assigned to the CoNLL category.7 We have not created separate lexicographs for the OntoNotes tagsets, because correspondence between the DBpedia categories and their tags cannot be found."}, {"heading": "2.2 Character-level Features", "text": "Figure 2 shows CNN extracting a feature vector of fixed length from the characters of a single word. For each character of a word, features are encoded and concatenated using lookup tables, then passed through convolution and max layers. The resulting vector is associated with other feature vectors at word level described above."}, {"heading": "2.2.1 Character Embeddings", "text": "To create a character embedding of 25 dimensions, we randomly initialized a lookup table with values from a uniform distribution in the range [\u2212 0.5, 0.5]. The character set contains all the unique characters in the CoNLL 2003 dataset (including uppercase and lowercase letters, numbers, and punctuation marks) plus the special characters PADDING and UNWNOWN. The PADDING token is used for CNN, and the UNWNOWN token is used for all other characters (occurring in OntoNotes). For all experiments, the same set of random embedding was used."}, {"heading": "2.2.2 Character Type Feature", "text": "A lookup table was used to output a four-dimensional vector representing the character type (uppercase, lowercase, punctuation, etc.).Padding P o Padding CharEmbeddingTypei c a s sConvolutionMax over timeChar characteristuresFigure 2: The Convolutionary Neural Network extracts character characteristics from each word. Character embedding and character type feature vector are calculated by lookup tables, and are then concatenated and passed to CNN."}, {"heading": "2.2.3 Extracting Features Using a Convolutional Neural Network", "text": "For each word, we use a convolution and a maximum plane to extract a new feature vector from the character-specific feature vectors described above. Words are padded on both sides with a number of special PADDING characters, including the window size and output vector size, depending on the window size of CNN's CNN.Hyper parameters."}, {"heading": "2.3 Sequence-labelling with Bidirectional LSTM", "text": "Following the speech recognition framework outlined by Graves et al. (2013), we used a stacked 10 bi-directional recursive neural network10 For each direction (forward and backward), the input is fed into several layers of LSTM units connected successively to long-term short-term memory (LSTM) to transform the extracted word characteristics into a distribution of named entity tag values. This network configuration is referred to for the rest of the paper as BLSTM. Figure 3 and Figure 4 illustrate the network in detail. The extracted features of each word are fed into a forward-facing LSTM network and a backward-facing LSTM network. Output of each recursive network is fed at each step by a linear layer and a logsoftmax layer to decode the log probabilities for each tag category, and those vectors are then simply added to the smaller variants to try out the best one."}, {"heading": "2.4 Training and Inference", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.4.1 Implementation", "text": "We implement the neural network using the torch7 library (Collobert et al., 2011a). Training and deduction are performed at the sentence level. The initial states of the LSTM are zero vectors. Except for character and word embedding, the initialization of which has already been described, all reference tables are randomly initialized and assigned values from the normal standard distribution."}, {"heading": "2.4.2 Objective Function and Inference", "text": "First, we define a tag transition matrix A, where Ai, j represents the score of jumping from day i to day j in consecutive words, and A0, i as the score for (i.e. LSTM units in the second layer are captured in the output of the first layer, and so on); the number of layers is a concerted hyperparameter. Figure 3 shows only one unit for simplicity. We saw paintings by Picasso WordEmbeddingCapitalizationLexicon Features (one per category) Char FeaturesLSTM LSTM LSTM LSTM LSTM LSTM LSTM Lgorithm, which find images by Picasso WordEmbeddingCapitalizationLexicon Features (one per category) (one per category)."}, {"heading": "2.4.3 Learning Algorithm", "text": "As shown in Table 8 and Table 9, applying dropouts to the input and output nodes of each LSTM layer (Pham et al., 2014) was very effective in reducing overpass. We investigated other, more complex optimization algorithms such as Pulse (Nesterov, 1983), AdaDelta (Zeiler, 2012) and RMSProp (Hinton et al., 2012), and in preliminary experiments they did not significantly improve the pure SGD."}, {"heading": "2.4.4 Tagging Scheme", "text": "The output tags are provided with BIOES (which stand for Begin, Inside, Outside, End, Single), as this scheme outperforms others such as BIO (Ratinov and Roth, 2009)."}, {"heading": "3 Evaluation", "text": "The evaluation was based on the established but less studied dataset CoNLL-2003 NER shared task (Tjong Kim Sang and De Meulder, 2003) and the much larger but less studied dataset OntoNotes 5.0 (Hovy et al., 2006). Table 2 provides an overview of these two different datasets. We have conducted each experiment several times and report on the average and standard deviation of at least 7 successful studies. As the model sometimes does not converge for unknown reasons, we exclude studies in all experiments where the final F1 value of a subset of training data falls below a certain threshold."}, {"heading": "3.1 Dataset Preprocessing", "text": "For all records, we have performed the following pre-processing: \u2022 All sequences of the digits 0-9 are replaced by a single \"0.\" \u2022 Before the training begins, records are grouped by record length and divided into minibatches, which are then mixed. In addition, tokens are split before and after each digit for the OntoNotes record to manage the date, time, money, percentage, quantity, ordinary and cardinal name entity tags."}, {"heading": "3.2 CoNLL 2003 Dataset", "text": "Table 3 shows the selected hyperparameters for all experiments in which the CoNLL-2003 dataset was involved. We adjusted the hyperparameters to the development determined by random search, and then trained the model for both the training and development groups. We excluded all studies in which the final F1 value on the development set was below 95. There was no ambiguity in the selection of the threshold, as each study scored either above 99 or below 90 points. We trained the models for a large number of epochs, because when we adjusted to the development set, we found that the model appears plateau for some initializations about 20-30 epochs, but nevertheless improves slowly from epoch 50 and beyond."}, {"heading": "3.3 OntoNotes 5.0 Dataset", "text": "Following Durrett and Klein (2014), we applied our model to the part of the CoNLL-2012 Shared Task Data Set (Pradhan et al., 2012) with notes on the gold standard; the New Testament part was excluded due to the lack of notes on the gold standard. Hyperparameters were not able to perform a new random search across the entire parameter range due to time constraints. Therefore, we simply used the best setting from the CoNLL 2003 experiments and adjusted the number of epochs and the learning rate based on the performance of the development set. Table 3 shows the last hyperparameters for all experiments relating to this data set. We excluded all studies where the final F1 value of the last 5,000 sets of the training set was below 80; each study scored either above 80 or below 50."}, {"heading": "4 Results and Discussion", "text": "Table 4 shows the results for all datasets. Our best model competes with other state-of-the-art systems on the CoNLL 2003 dataset and for the OntoNotes dataset to the best of our knowledge with the results of we11OntoNotes (Durrett and Klein, 2014) 12It was unclear whether or not they rated their system on the CoNLL 2012 breakdown of the OntoNotes dataset. 13 numbers from the original paper (Luo et al., 2015). Although precision, recall, and F1 values are clearly inconsistent, it is unclear how they are erroneous. have surpassed the previous highest reported results in terms of precision, recall, and F1 score. Specifically, word embeddings and character properties (produced by CNN) contributed most to the performance, suggesting that the neural network, when sufficient data is available, is able to automatically learn the relevant features for NER without feature engineering."}, {"heading": "4.1 Character-level CNNs vs. Character Type and Capitalization Features", "text": "Comparing Table 5 and Table 6 shows that BLSTM CNN models perform significantly better on CoNLL-2003 than BLSTM models when they have the same functionality; this effect is much lower and remarkably 14Wilcoxon Ranking Test, p < 0.05 when the four BLSTM models are compared with the corresponding BLSTM CNN models that use the same functionality; the Wilcoxon Ranking Test was selected for its robustness over small sample sizes when distribution is unknown; statistically significant on OntoNotes when capitalization features are added; and it is noteworthy that neither the character type nor capitalization features at the character level offer CNN improvements; these results suggest that CNN can replace handmade character class features."}, {"heading": "4.2 Word Embeddings", "text": "Table 4 and Table 7 show that we achieve a large, significant 15 improvement when using trained word embeddings, as opposed to random embeddings, regardless of the additional features used. This is15Wilcoxon rank sum test, p < 0.001 in line with results previously obtained by Collobert et. al. (2011b).Table 7 compares the performance of the various word embeddings in our best model in Table 4 (BLSTM-CNN + emb + lex).For CoNLL-2003, publicly available word embeddings are about one point behind Collobert's embeddings. For OntoNotes, GloVe embeddings perform near Collobert embeddings, while Google embeddings are again one point behind. In addition, 300 dimensional word embeddings do not represent a significant improvement over 50-dimensional embeddings - a result previously obtained by Turial et al al as a better-available word embeddings (2010)."}, {"heading": "4.3 Effect of Dropout", "text": "Table 8 and Table 9 compare the result with and without dropout for each dataset. All other hyperparameters and features remain the same as our best model Table 4. In both datasets, dropout is indispensable to the state of the art, and the improvement is statistically meaningful18; without dropout, training data performance improves while test results suffer."}, {"heading": "4.4 Lexicon Features", "text": "Table 5 and Table 6 show that on the CoNLL 2003 dataset, the addition of lexicon characteristics per-16Wilcoxon rank sum test, p < 0.01 17Wilcoxon rank sum test, p < 0.01 for CoNLL-2003 and OntoNotes.vide represents a small improvement 19 in all models. Unfortunately, such an improvement does not occur in OntoNotes, most likely because our lexicon is unpopulated for many of the tags in the OntoNotes tagset due to the lack of appropriate DBpedia categories. Another interpretation of these results is that our CNN model at character level learns much from the same knowledge encoded in the NE lexicon. For lexicon matching, we have also tried the method outlined by Collobert et al. (2011b), where exact matches are performed for each category and \"switched\" to \"the corresponding lexicon attribute if an overmatch is not found at an easy level."}, {"heading": "5 Related Research", "text": "Named Entity Recognition is a task with a long history in the NLP. In this section, we summarize the work that is most relevant to our research, namely those with which we make direct comparisons and from which our approach was inspired."}, {"heading": "5.1 Named Entity Recognition", "text": "Most recent approaches to the NER model have been characterized by the use of CRF models or other models such as SVMs and averaged perceptron models, where performance is strongly dependent on feature engineering. Ratinov and Roth (2009) used nonlocal features, Wikipedia gazetteers and Brown cluster-like word representations, and achieved an F1 score of 90.80 on CoNLL-2003.19Not statistically significant 20This should come as no great surprise given the amount of information about the correct status of nouns conveyed by capitalization in the English language. Lin and Wu (2009) surpassed them without using a gazetteer, instead using phrase features obtained by performing k-means clusters through a private database of search engine queries. Passos et al. (2014) achieved nearly the same performance by using only public data, using the lexicographs \"used in their model."}, {"heading": "5.2 NER with Neural Networks", "text": "While many approaches involve CRF models, there has also been a long history of research applying neural networks to NER. Early experiments were hampered by a lack of computing power, scalable learning algorithms, and high-quality word embedded.Petasis et al. (2000) used an advanced neural network with a hidden layer on NER and obtained CNSTM results on the MUC6 dataset. Their approach used uniform encodings for POS tags and gazetteer tags for each word, without word embedded.Hammerton (2003) tried a CNSTM network and a combination of 64-dimensional word vectors trained using self-organizing maps, as well as context vectors obtained using principle-component analysis. However, while our method optimized log probability and used softmax, they used a different output encoding and optimized objective function."}, {"heading": "6 Conclusion", "text": "We have shown that our neural network model, which includes a bi-directional LSTM and a CNN at the character level, and benefits from robust training through dropout, achieves state-of-the-art results in detecting designated entities with low feature engineering. Our model improves on earlier, best-reported results from the large OntoNotes dataset, suggesting that the model is capable of learning complex relationships from large amounts of 21 character-level encoded RNNNs that, despite promising results in language model applications (Karpathy et al., 2015), did not perform as well as CNNs, and that our CNN models at the character level learn much from the smaller CoNLL 2003 datasets encoded in lexicon. A preliminary assessment of our partially matching lexicon algorithm suggests that performance could be further improved by more flexible use of existing lexicon, but that our drawing-level CNN models are coding a large portion of the information in lexicon."}, {"heading": "Acknowledgments", "text": "This research was supported by Honda Research Institute Japan, Co.Ltd. The authors thank Collobert et al. (2011b) for publishing the SENNA source code and word vectors, the contributors of the torch7 framework and Andrey Karpathy for the reference implementation of the LSTM."}], "references": [{"title": "DBpedia: A nucleus for a web of open data", "author": ["S\u00f6ren Auer", "Christian Bizer", "Georgi Kobilarov", "Jens Lehmann", "Richard Cyganiak", "Zachary Ives."], "venue": "Springer.", "citeRegEx": "Auer et al\\.,? 2007", "shortCiteRegEx": "Auer et al\\.", "year": 2007}, {"title": "A convolutional neural network for modelling sentences", "author": ["Phil Blunsom", "Edward Grefenstette", "Nal Kalchbrenner"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Proceedings of the 52nd Annual Meeting", "citeRegEx": "Blunsom et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Blunsom et al\\.", "year": 2014}, {"title": "On the properties of neural machine translation: Encoder-decoder approaches", "author": ["Kyunghyun Cho", "Bart van Merri\u00ebnboer", "Dzmitry Bahdanau", "Yoshua Bengio."], "venue": "Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A unified architecture for natural language processing: Deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston."], "venue": "Proceedings of the 25th international conference on Machine learning, pages 160\u2013167. ACM.", "citeRegEx": "Collobert and Weston.,? 2008", "shortCiteRegEx": "Collobert and Weston.", "year": 2008}, {"title": "Torch7: A matlab-like environment for machine learning", "author": ["Ronan Collobert", "Koray Kavukcuoglu", "Cl\u00e9ment Farabet."], "venue": "BigLearn, NIPS Workshop, number EPFL-CONF-192376.", "citeRegEx": "Collobert et al\\.,? 2011a", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "The Journal of Machine Learning Research, 12:2493\u2013 2537.", "citeRegEx": "Collobert et al\\.,? 2011b", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Boosting named entity recognition with neural character embeddings", "author": ["C\u0131cero dos Santos", "Victor Guimaraes", "RJ Niter\u00f3i", "Rio de Janeiro."], "venue": "Proceedings of NEWS 2015 The Fifth Named Entities Workshop, page 25.", "citeRegEx": "Santos et al\\.,? 2015", "shortCiteRegEx": "Santos et al\\.", "year": 2015}, {"title": "A joint model for entity analysis: Coreference, typing, and linking", "author": ["Greg Durrett", "Dan Klein."], "venue": "Transactions of the Association for Computational Linguistics, 2:477\u2013490.", "citeRegEx": "Durrett and Klein.,? 2014", "shortCiteRegEx": "Durrett and Klein.", "year": 2014}, {"title": "Learning to forget: Continual prediction with LSTM", "author": ["Felix A Gers", "J\u00fcrgen Schmidhuber", "Fred Cummins."], "venue": "Neural computation, 12(10):2451\u20132471.", "citeRegEx": "Gers et al\\.,? 2000", "shortCiteRegEx": "Gers et al\\.", "year": 2000}, {"title": "Learning task-dependent distributed representations by backpropagation through structure", "author": ["Christoph Goller", "Andreas Kuchler."], "venue": "Neural Networks, 1996., IEEE International Conference on, volume 1, pages 347\u2013352. IEEE.", "citeRegEx": "Goller and Kuchler.,? 1996", "shortCiteRegEx": "Goller and Kuchler.", "year": 1996}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["Alan Graves", "Abdel-rahman Mohamed", "Geoffrey Hinton."], "venue": "Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on, pages 6645\u20136649. IEEE.", "citeRegEx": "Graves et al\\.,? 2013", "shortCiteRegEx": "Graves et al\\.", "year": 2013}, {"title": "Named entity recognition with long short-term memory", "author": ["James Hammerton."], "venue": "Proceedings of the seventh conference on Natural language learning at HLTNAACL 2003-Volume 4, pages 172\u2013175. Association for Computational Linguistics.", "citeRegEx": "Hammerton.,? 2003", "shortCiteRegEx": "Hammerton.", "year": 2003}, {"title": "Lecture 6e: rmsprop: divide the gradient by a running average of its recent magnitude", "author": ["Geoffrey Hinton", "Nitish Srivastava", "Kevin Swersky."], "venue": "Neural Networks for Machine Learning. http: //www.cs.toronto.edu/ \u0303tijmen/csc321/", "citeRegEx": "Hinton et al\\.,? 2012", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "OntoNotes: the 90% solution", "author": ["Eduard Hovy", "Mitchell Marcus", "Martha Palmer", "Lance Ramshaw", "Ralph Weischedel."], "venue": "Proceedings of the human language technology conference of the NAACL, Companion Volume: Short Papers, pages 57\u201360. Association", "citeRegEx": "Hovy et al\\.,? 2006", "shortCiteRegEx": "Hovy et al\\.", "year": 2006}, {"title": "Bidirectional LSTM-CRF models for sequence tagging", "author": ["Zhiheng Huang", "Wei Xu", "Kai Yu."], "venue": "CoRR, abs/1508.01991.", "citeRegEx": "Huang et al\\.,? 2015", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "Visualizing and understanding recurrent networks", "author": ["Andrej Karpathy", "Justin Johnson", "Fei-Fei Li."], "venue": "CoRR, abs/1506.02078.", "citeRegEx": "Karpathy et al\\.,? 2015", "shortCiteRegEx": "Karpathy et al\\.", "year": 2015}, {"title": "Non-lexical neural architecture for fine-grained pos tagging", "author": ["Matthieu Labeau", "Kevin L\u00f6ser", "Alexandre Allauzen."], "venue": "Proceedings of the 2015 Conference", "citeRegEx": "Labeau et al\\.,? 2015", "shortCiteRegEx": "Labeau et al\\.", "year": 2015}, {"title": "Phrase clustering for discriminative learning", "author": ["Dekang Lin", "Xiaoyun Wu."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2,", "citeRegEx": "Lin and Wu.,? 2009", "shortCiteRegEx": "Lin and Wu.", "year": 2009}, {"title": "Joint entity recognition and disambiguation", "author": ["Gang Luo", "Xiaojiang Huang", "Chin-Yew Lin", "Zaiqing Nie."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 879\u2013888, Lisbon, Portugal, September. Associ-", "citeRegEx": "Luo et al\\.,? 2015", "shortCiteRegEx": "Luo et al\\.", "year": 2015}, {"title": "Rnnlm-recurrent neural network language modeling toolkit", "author": ["Tomas Mikolov", "Stefan Kombrink", "Anoop Deoras", "Lukar Burget", "Jan Cernocky."], "venue": "Proc. of the 2011 ASRU Workshop, pages 196\u2013201.", "citeRegEx": "Mikolov et al\\.,? 2011", "shortCiteRegEx": "Mikolov et al\\.", "year": 2011}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A method of solving a convex programming problem with convergence rate O(1/k)", "author": ["Yurii Nesterov."], "venue": "Soviet Mathematics Doklady, 27(2):372\u2013376.", "citeRegEx": "Nesterov.,? 1983", "shortCiteRegEx": "Nesterov.", "year": 1983}, {"title": "Lexicon infused phrase embeddings for named entity resolution", "author": ["Alexandre Passos", "Vineet Kumar", "Andrew McCallum."], "venue": "Proceedings of CoNLL-2014, page 78.", "citeRegEx": "Passos et al\\.,? 2014", "shortCiteRegEx": "Passos et al\\.", "year": 2014}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014), 12:1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Symbolic and neural learning for named-entity recognition", "author": ["G Petasis", "S Petridis", "G Paliouras", "V Karkaletsis", "SJ Perantonis", "CD Spyropoulos."], "venue": "Symposium on Computational Intelligence and Learning, Chios, Greece, pages 58\u201366. Citeseer.", "citeRegEx": "Petasis et al\\.,? 2000", "shortCiteRegEx": "Petasis et al\\.", "year": 2000}, {"title": "Dropout improves recurrent neural networks for handwriting recognition", "author": ["Vu Pham", "Th\u00e9odore Bluche", "Christopher Kermorvant", "J\u00e9r\u00f4me Louradour."], "venue": "Frontiers in Handwriting Recognition (ICFHR), 2014 14th International Conference on, pages 285\u2013", "citeRegEx": "Pham et al\\.,? 2014", "shortCiteRegEx": "Pham et al\\.", "year": 2014}, {"title": "Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes", "author": ["Sameer Pradhan", "Alessandro Moschitti", "Nianwen Xue", "Olga Uryupina", "Yuchen Zhang."], "venue": "Joint Conference on EMNLP and CoNLL-Shared Task, pages 1\u201340. Association for", "citeRegEx": "Pradhan et al\\.,? 2012", "shortCiteRegEx": "Pradhan et al\\.", "year": 2012}, {"title": "Design challenges and misconceptions in named entity recognition", "author": ["Lev Ratinov", "Dan Roth."], "venue": "Proceedings of the Thirteenth Conference on Computational Natural Language Learning, pages 147\u2013155. Association for Computational Linguistics.", "citeRegEx": "Ratinov and Roth.,? 2009", "shortCiteRegEx": "Ratinov and Roth.", "year": 2009}, {"title": "Learning representations by back-propagating errors", "author": ["David Rumelhart", "Geoffrey Hinton", "Ronald Williams."], "venue": "Nature, pages 323\u2013533.", "citeRegEx": "Rumelhart et al\\.,? 1986", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1986}, {"title": "Introduction to the conll-2003 shared task: Languageindependent named entity recognition", "author": ["Erik F Tjong Kim Sang", "Fien De Meulder."], "venue": "Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4, pages 142\u2013147.", "citeRegEx": "Sang and Meulder.,? 2003", "shortCiteRegEx": "Sang and Meulder.", "year": 2003}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["Joseph Turian", "Lev Ratinov", "Yoshua Bengio."], "venue": "Proceedings of the 48th annual meeting of the association for computational linguistics, pages 384\u2013394. Association for Computa-", "citeRegEx": "Turian et al\\.,? 2010", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "ADADELTA: an adaptive learning rate method", "author": ["Matthew D. Zeiler."], "venue": "CoRR, abs/1212.5701.", "citeRegEx": "Zeiler.,? 2012", "shortCiteRegEx": "Zeiler.", "year": 2012}], "referenceMentions": [{"referenceID": 27, "context": "High performance approaches have been dominated by applying statistical models such as CRF, SVM, or perceptron models to hand-crafted features (Ratinov and Roth, 2009; Passos et al., 2014; Luo et al., 2015).", "startOffset": 143, "endOffset": 206}, {"referenceID": 22, "context": "High performance approaches have been dominated by applying statistical models such as CRF, SVM, or perceptron models to hand-crafted features (Ratinov and Roth, 2009; Passos et al., 2014; Luo et al., 2015).", "startOffset": 143, "endOffset": 206}, {"referenceID": 18, "context": "High performance approaches have been dominated by applying statistical models such as CRF, SVM, or perceptron models to hand-crafted features (Ratinov and Roth, 2009; Passos et al., 2014; Luo et al., 2015).", "startOffset": 143, "endOffset": 206}, {"referenceID": 3, "context": "(2011b) proposed an effective neural network model that requires little feature engineering and instead learns important features from word embeddings trained on large quantities of unlabelled text \u2013 an approach made possible by recent advancements in unsupervised learning of word embeddings on massive amount of data (Collobert and Weston, 2008; Mikolov et al., 2013) and neural network training algorithms permitting deep architectures (Rumelhart et al.", "startOffset": 319, "endOffset": 369}, {"referenceID": 20, "context": "(2011b) proposed an effective neural network model that requires little feature engineering and instead learns important features from word embeddings trained on large quantities of unlabelled text \u2013 an approach made possible by recent advancements in unsupervised learning of word embeddings on massive amount of data (Collobert and Weston, 2008; Mikolov et al., 2013) and neural network training algorithms permitting deep architectures (Rumelhart et al.", "startOffset": 319, "endOffset": 369}, {"referenceID": 28, "context": ", 2013) and neural network training algorithms permitting deep architectures (Rumelhart et al., 1986).", "startOffset": 77, "endOffset": 101}, {"referenceID": 3, "context": "However, Collobert et al. (2011b) proposed an effective neural network model that requires little feature engineering and instead learns important features from word embeddings trained on large quantities of unlabelled text \u2013 an approach made possible by recent advancements in unsupervised learning of word embeddings on massive amount of data (Collobert and Weston, 2008; Mikolov et al.", "startOffset": 9, "endOffset": 34}, {"referenceID": 4, "context": "Unfortunately there are many limitations to the model proposed by Collobert et al. (2011b). First, it uses a simple feed-forward neural network, which restricts the use of context to a fixed sized window around each word \u2013 an approach that discards useful long-distance relations between words.", "startOffset": 66, "endOffset": 91}, {"referenceID": 9, "context": "A well-studied solution for a neural network to process variable length input and have long term memory is the recurrent neural network (RNN) (Goller and Kuchler, 1996).", "startOffset": 142, "endOffset": 168}, {"referenceID": 10, "context": "Recently, RNNs have shown great success in diverse NLP tasks such as speech recognition (Graves et al., 2013), machine translation (Cho et al.", "startOffset": 88, "endOffset": 109}, {"referenceID": 2, "context": ", 2013), machine translation (Cho et al., 2014), and language modeling (Mikolov et al.", "startOffset": 29, "endOffset": 47}, {"referenceID": 19, "context": ", 2014), and language modeling (Mikolov et al., 2011).", "startOffset": 31, "endOffset": 53}, {"referenceID": 8, "context": "The long-short term memory (LSTM) unit with the forget gate allows highly non-trivial long-distance dependencies to be easily learned (Gers et al., 2000).", "startOffset": 134, "endOffset": 153}, {"referenceID": 10, "context": "For sequential labelling tasks such as NER and speech recognition, a bi-directional LSTM model can take into account an effectively infinite amount of context on both sides of a word and eliminates the problem of limited context that applies to any feed-forward model (Graves et al., 2013).", "startOffset": 268, "endOffset": 289}, {"referenceID": 2, "context": ", 2013), machine translation (Cho et al., 2014), and language modeling (Mikolov et al., 2011). The long-short term memory (LSTM) unit with the forget gate allows highly non-trivial long-distance dependencies to be easily learned (Gers et al., 2000). For sequential labelling tasks such as NER and speech recognition, a bi-directional LSTM model can take into account an effectively infinite amount of context on both sides of a word and eliminates the problem of limited context that applies to any feed-forward model (Graves et al., 2013). While LSTMs have been studied in the past for the NER task by Hammerton (2003), the lack of computational power (which led to the use of very small models) and quality word embeddings ar X iv :1 51 1.", "startOffset": 30, "endOffset": 620}, {"referenceID": 1, "context": "(2011b) also applied CNNs to semantic role labeling, and variants of the architecture have been applied to parsing and other tasks requiring tree structures (Blunsom et al., 2014).", "startOffset": 157, "endOffset": 179}, {"referenceID": 3, "context": "Collobert et al. (2011b) also applied CNNs to semantic role labeling, and variants of the architecture have been applied to parsing and other tasks requiring tree structures (Blunsom et al.", "startOffset": 0, "endOffset": 25}, {"referenceID": 4, "context": "Furthermore, as lexicons are crucial to NER performance, we propose a new lexicon encoding scheme and matching algorithm that can make use of partial matches, and we compare it to the exact match only approach of Collobert et al. (2011b). Extensive evaluation shows that our proposed method performs competitively on the CoNLL-2003 NER shared task and outperforms all known state-of the-art systems on the OntoNotes 5.", "startOffset": 213, "endOffset": 238}, {"referenceID": 10, "context": "Instead of a feed-forward network, we use the more powerful recurrent neural network; in particular, we choose the bidirectional long-short term memory (LSTM) network, which has been used successfully in other sequence labelling tasks such as speech recognition (Graves et al., 2013).", "startOffset": 262, "endOffset": 283}, {"referenceID": 16, "context": ", 2015) and German POStagging (Labeau et al., 2015).", "startOffset": 30, "endOffset": 51}, {"referenceID": 4, "context": "Our neural network is inspired by the work of Collobert et al. (2011b), where feature vectors are computed by lookup tables and concatenated together, and then fed into a multi-layer network.", "startOffset": 46, "endOffset": 71}, {"referenceID": 4, "context": "Our best model uses the publicly available 50dimensional word embeddings released by Collobert et al. (2011b)1, which were trained on Wikipedia and Reuters RCV-1 corpus.", "startOffset": 85, "endOffset": 110}, {"referenceID": 23, "context": "We also experimented with two other sets of published embeddings, namely Stanford\u2019s GloVe embeddings2 trained on 6 billion words from Wikipedia and web text (Pennington et al., 2014) and Google\u2019s word2vec embeddings3 trained on 100 billion words from Google News (Mikolov et al.", "startOffset": 157, "endOffset": 182}, {"referenceID": 20, "context": ", 2014) and Google\u2019s word2vec embeddings3 trained on 100 billion words from Google News (Mikolov et al., 2013).", "startOffset": 88, "endOffset": 110}, {"referenceID": 23, "context": "In addition, as we hypothesized that word embeddings trained on in-domain text may perform better, we also used the publicly available GloVe (Pennington et al., 2014) program and an in-house re-implementation4 of the word2vec (Mikolov et al.", "startOffset": 141, "endOffset": 166}, {"referenceID": 20, "context": ", 2014) program and an in-house re-implementation4 of the word2vec (Mikolov et al., 2013) program to train word embeddings on Wikipedia and Reuters RCV1 dataset as well.", "startOffset": 67, "endOffset": 89}, {"referenceID": 4, "context": "Following Collobert et al. (2011b), all words are lower-cased before passing through the lookup table to convert to their corresponding embeddings.", "startOffset": 10, "endOffset": 35}, {"referenceID": 5, "context": "As capitalization information is erased during lookup of the word embedding, we evaluate Collobert\u2019s method of using a separate lookup table to add a capitalization feature with the following options: allCaps, upperInitial, lowercase, mixedCaps, noinfo (Collobert et al., 2011b).", "startOffset": 253, "endOffset": 278}, {"referenceID": 17, "context": "word2vec/ We used our in-house reimplementation to train word vectors because it uses distributed processing to train much quicker than the publicly-released implementation of word2vec and its performance on the word analogy task was higher than reported by Mikolov et al. (2013). While Collobert et al.", "startOffset": 258, "endOffset": 280}, {"referenceID": 4, "context": "While Collobert et al. (2011b) used Wikipedia text from 2007, we used Wikipedia text from 2011.", "startOffset": 6, "endOffset": 31}, {"referenceID": 27, "context": "Almost all state of the art NER systems make use of lexicons as a form of external knowledge (Ratinov and Roth, 2009; Passos et al., 2014; Durrett and Klein, 2014; Luo et al., 2015).", "startOffset": 93, "endOffset": 181}, {"referenceID": 22, "context": "Almost all state of the art NER systems make use of lexicons as a form of external knowledge (Ratinov and Roth, 2009; Passos et al., 2014; Durrett and Klein, 2014; Luo et al., 2015).", "startOffset": 93, "endOffset": 181}, {"referenceID": 7, "context": "Almost all state of the art NER systems make use of lexicons as a form of external knowledge (Ratinov and Roth, 2009; Passos et al., 2014; Durrett and Klein, 2014; Luo et al., 2015).", "startOffset": 93, "endOffset": 181}, {"referenceID": 18, "context": "Almost all state of the art NER systems make use of lexicons as a form of external knowledge (Ratinov and Roth, 2009; Passos et al., 2014; Durrett and Klein, 2014; Luo et al., 2015).", "startOffset": 93, "endOffset": 181}, {"referenceID": 0, "context": "For each of the four categories (Person, Organization, Location, Miscellaneous) defined by the CoNLL 2003 NER shared task, we compiled a list of known named entities from DBpedia (Auer et al., 2007), by extracting all descendants of DBpedia types corresponding to the CoNLL categories7.", "startOffset": 179, "endOffset": 198}, {"referenceID": 4, "context": "As shown in Table 10, we found that this more sophisticated method outperforms the method presented by Collobert et al. (2011b), which simply uses exact matching and marks tokens with on/off instead of BIOES annotation.", "startOffset": 103, "endOffset": 128}, {"referenceID": 10, "context": "Following the speech-recognition framework outlined by Graves et al. (2013), we employed a stacked10 bi-directional recurrent neural network", "startOffset": 55, "endOffset": 76}, {"referenceID": 4, "context": "We implement the neural network using the torch7 library (Collobert et al., 2011a).", "startOffset": 57, "endOffset": 82}, {"referenceID": 4, "context": "We train our network to maximize the sentencelevel log-likelihood as presented by Collobert et al. (2011b).", "startOffset": 82, "endOffset": 107}, {"referenceID": 5, "context": "This objective function and its gradients can be efficiently computed by dynamic programming (Collobert et al., 2011b).", "startOffset": 93, "endOffset": 118}, {"referenceID": 25, "context": "As shown in Table 8 and Table 9, we found that applying dropout to the input and output nodes of each LSTM layer (Pham et al., 2014) was quite effective in reducing overfitting.", "startOffset": 113, "endOffset": 132}, {"referenceID": 21, "context": "We explored other more sophisticated optimization algorithms such as momentum (Nesterov, 1983), AdaDelta (Zeiler, 2012), and RMSProp (Hinton et al.", "startOffset": 78, "endOffset": 94}, {"referenceID": 31, "context": "We explored other more sophisticated optimization algorithms such as momentum (Nesterov, 1983), AdaDelta (Zeiler, 2012), and RMSProp (Hinton et al.", "startOffset": 105, "endOffset": 119}, {"referenceID": 12, "context": "We explored other more sophisticated optimization algorithms such as momentum (Nesterov, 1983), AdaDelta (Zeiler, 2012), and RMSProp (Hinton et al., 2012), and in preliminary experiments they did not meaningfully improve upon plain SGD.", "startOffset": 133, "endOffset": 154}, {"referenceID": 27, "context": "The output tags are annotated with BIOES (which stand for Begin, Inside, Outside, End, Single) as this scheme has been reported to outperform others such as BIO (Ratinov and Roth, 2009).", "startOffset": 161, "endOffset": 185}, {"referenceID": 13, "context": "0 dataset (Hovy et al., 2006).", "startOffset": 10, "endOffset": 29}, {"referenceID": 26, "context": "Following Durrett and Klein (2014), we applied our model to the portion of the CoNLL-2012 shared task dataset (Pradhan et al., 2012) with gold-standard named entity annotations; the New Testaments portion was excluded for lacking gold-standard annotations.", "startOffset": 110, "endOffset": 132}, {"referenceID": 7, "context": "Following Durrett and Klein (2014), we applied our model to the portion of the CoNLL-2012 shared task dataset (Pradhan et al.", "startOffset": 10, "endOffset": 35}, {"referenceID": 7, "context": "OntoNotes results taken from (Durrett and Klein, 2014) It was unclear whether or not they evaluated their system on the CoNLL-2012 split of the OntoNotes dataset.", "startOffset": 29, "endOffset": 54}, {"referenceID": 18, "context": "Numbers taken from the original paper (Luo et al., 2015).", "startOffset": 38, "endOffset": 56}, {"referenceID": 4, "context": "19) Collobert et al. (2011b) - 88.", "startOffset": 4, "endOffset": 29}, {"referenceID": 4, "context": "19) Collobert et al. (2011b) - 88.67 - Collobert et al. (2011b) + lexicon - 89.", "startOffset": 4, "endOffset": 64}, {"referenceID": 4, "context": "19) Collobert et al. (2011b) - 88.67 - Collobert et al. (2011b) + lexicon - 89.59 - Huang et al. (2015) - 90.", "startOffset": 4, "endOffset": 104}, {"referenceID": 4, "context": "19) Collobert et al. (2011b) - 88.67 - Collobert et al. (2011b) + lexicon - 89.59 - Huang et al. (2015) - 90.10 - Ratinov and Roth (2009)11 91.", "startOffset": 4, "endOffset": 138}, {"referenceID": 4, "context": "19) Collobert et al. (2011b) - 88.67 - Collobert et al. (2011b) + lexicon - 89.59 - Huang et al. (2015) - 90.10 - Ratinov and Roth (2009)11 91.20 90.50 90.80 82.00 84.95 83.45 Lin and Wu (2009) - 90.", "startOffset": 4, "endOffset": 194}, {"referenceID": 4, "context": "19) Collobert et al. (2011b) - 88.67 - Collobert et al. (2011b) + lexicon - 89.59 - Huang et al. (2015) - 90.10 - Ratinov and Roth (2009)11 91.20 90.50 90.80 82.00 84.95 83.45 Lin and Wu (2009) - 90.90 - Passos et al. (2014)12 - 90.", "startOffset": 4, "endOffset": 225}, {"referenceID": 4, "context": "19) Collobert et al. (2011b) - 88.67 - Collobert et al. (2011b) + lexicon - 89.59 - Huang et al. (2015) - 90.10 - Ratinov and Roth (2009)11 91.20 90.50 90.80 82.00 84.95 83.45 Lin and Wu (2009) - 90.90 - Passos et al. (2014)12 - 90.90 - 82.24 Durrett and Klein (2014) - 85.", "startOffset": 4, "endOffset": 268}, {"referenceID": 4, "context": "19) Collobert et al. (2011b) - 88.67 - Collobert et al. (2011b) + lexicon - 89.59 - Huang et al. (2015) - 90.10 - Ratinov and Roth (2009)11 91.20 90.50 90.80 82.00 84.95 83.45 Lin and Wu (2009) - 90.90 - Passos et al. (2014)12 - 90.90 - 82.24 Durrett and Klein (2014) - 85.22 82.89 84.04 Luo et al. (2015)13 91.", "startOffset": 4, "endOffset": 306}, {"referenceID": 30, "context": "In addition, 300 dimensional embeddings present no significant improvement over 50 dimensional embeddings \u2013 a result previously reported by Turian et al. (2010).", "startOffset": 140, "endOffset": 161}, {"referenceID": 23, "context": "As word embedding quality depends on hyper-parameter choice during their training (Pennington et al., 2014), and also, in our NER neural network, hyper-parameter choice is likely sensitive to the type of word embeddings used, optimizing them all will likely produce better results and provide a fairer comparison of word embedding quality.", "startOffset": 82, "endOffset": 107}, {"referenceID": 4, "context": "For lexicon matching, we also tried the method outlined by Collobert et al. (2011b), which involves performing exact matching for each category and turning \u201con\u201d the corresponding lexicon feature when a match is found.", "startOffset": 59, "endOffset": 84}, {"referenceID": 27, "context": "Ratinov and Roth (2009) used nonlocal features, gazetteer extracted from Wikipedia, and Brown-cluster-like word representations, and achieved an F1 score of 90.", "startOffset": 0, "endOffset": 24}, {"referenceID": 17, "context": "Lin and Wu (2009) surpassed them without using a gazetteer, by instead using phrase features obtained by performing k-means clustering over a private database of search engine query logs.", "startOffset": 0, "endOffset": 18}, {"referenceID": 17, "context": "Lin and Wu (2009) surpassed them without using a gazetteer, by instead using phrase features obtained by performing k-means clustering over a private database of search engine query logs. Passos et al. (2014) obtained nearly the same performance using only public data by training phrase vectors in their lexicon-infused SkipGram model.", "startOffset": 0, "endOffset": 209}, {"referenceID": 7, "context": "Durrett and Klein (2014) combined coreference resolution, entity linking, and NER into a single CRF model and added cross-task interaction factors.", "startOffset": 0, "endOffset": 25}, {"referenceID": 7, "context": "Durrett and Klein (2014) combined coreference resolution, entity linking, and NER into a single CRF model and added cross-task interaction factors. Their system achieved state of the art results on the OntoNotes dataset, but they did not evaluate on the CoNLL-2003 dataset due to lack of coreference annotations. Luo et al. (2015) achieved the current state of the art results on CoNLL-2003 by training a joint model over the NER and entity linking tasks, the pair of tasks whose inter-dependencies contributed the most to the work of Durrett and Klein (2014).", "startOffset": 0, "endOffset": 331}, {"referenceID": 7, "context": "Durrett and Klein (2014) combined coreference resolution, entity linking, and NER into a single CRF model and added cross-task interaction factors. Their system achieved state of the art results on the OntoNotes dataset, but they did not evaluate on the CoNLL-2003 dataset due to lack of coreference annotations. Luo et al. (2015) achieved the current state of the art results on CoNLL-2003 by training a joint model over the NER and entity linking tasks, the pair of tasks whose inter-dependencies contributed the most to the work of Durrett and Klein (2014).", "startOffset": 0, "endOffset": 560}, {"referenceID": 4, "context": "Much later, with the advent of neural word embeddings, Collobert et al. (2011b) presented SENNA, which employs a feed-forward deep neu-", "startOffset": 55, "endOffset": 80}, {"referenceID": 4, "context": "Recently, dos Santos et al. (2015) presented their CharWNN network, which augments the neural network of Collobert et al.", "startOffset": 14, "endOffset": 35}, {"referenceID": 4, "context": "(2015) presented their CharWNN network, which augments the neural network of Collobert et al. (2011b) with character level CNNs, and they reported improved performance on Spanish and Portuguese NER.", "startOffset": 77, "endOffset": 102}, {"referenceID": 14, "context": "Our method is most similar to the recent BiLSTM-CRF model for POS-tagging, chunking, and NER presented by Huang et al. (2015) and the BiRNN model for POS-tagging presented by Labeau et al.", "startOffset": 106, "endOffset": 126}, {"referenceID": 14, "context": "Our method is most similar to the recent BiLSTM-CRF model for POS-tagging, chunking, and NER presented by Huang et al. (2015) and the BiRNN model for POS-tagging presented by Labeau et al. (2015). Both of them employed the same objective function and similar bidirectional networks, with the former using a Bi-directional LSTM without CNNs and the latter using character-level CNNs with standard RNNs.", "startOffset": 106, "endOffset": 196}, {"referenceID": 14, "context": "Our method is most similar to the recent BiLSTM-CRF model for POS-tagging, chunking, and NER presented by Huang et al. (2015) and the BiRNN model for POS-tagging presented by Labeau et al. (2015). Both of them employed the same objective function and similar bidirectional networks, with the former using a Bi-directional LSTM without CNNs and the latter using character-level CNNs with standard RNNs. Our method differs from Huang et al. (2015) in that we employ very little feature engineering and instead take advantage of character level CNNs to automatically extract features from a word.", "startOffset": 106, "endOffset": 446}, {"referenceID": 14, "context": "Our method is most similar to the recent BiLSTM-CRF model for POS-tagging, chunking, and NER presented by Huang et al. (2015) and the BiRNN model for POS-tagging presented by Labeau et al. (2015). Both of them employed the same objective function and similar bidirectional networks, with the former using a Bi-directional LSTM without CNNs and the latter using character-level CNNs with standard RNNs. Our method differs from Huang et al. (2015) in that we employ very little feature engineering and instead take advantage of character level CNNs to automatically extract features from a word. Unlike Labeau et al. (2015), we employed the more powerful LSTM, which we found to outperform standard RNNs in preliminary experimentation as well as being easier to train.", "startOffset": 106, "endOffset": 622}, {"referenceID": 14, "context": "Our method is most similar to the recent BiLSTM-CRF model for POS-tagging, chunking, and NER presented by Huang et al. (2015) and the BiRNN model for POS-tagging presented by Labeau et al. (2015). Both of them employed the same objective function and similar bidirectional networks, with the former using a Bi-directional LSTM without CNNs and the latter using character-level CNNs with standard RNNs. Our method differs from Huang et al. (2015) in that we employ very little feature engineering and instead take advantage of character level CNNs to automatically extract features from a word. Unlike Labeau et al. (2015), we employed the more powerful LSTM, which we found to outperform standard RNNs in preliminary experimentation as well as being easier to train. In addition, while Labeau et al. (2015) reported near stateof-the-art performance in German POS tagging with no word embeddings at all, we found that even with character-level CNNs, word embeddings are crucial to NER performance.", "startOffset": 106, "endOffset": 807}, {"referenceID": 15, "context": "Attempts at character-level RNNs did not perform as well as CNNs despite promising results in language model applications (Karpathy et al., 2015).", "startOffset": 122, "endOffset": 145}, {"referenceID": 4, "context": "The authors would like to thank Collobert et al. (2011b) for releasing the SENNA source code and word vectors, the torch7 framework contributors, and Andrey Karpathy for the reference LSTM implementation.", "startOffset": 32, "endOffset": 57}], "year": 2015, "abstractText": "Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance. In this paper, we present a novel neural network architecture that automatically detects wordand character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering. We also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing exact match approaches. Extensive evaluation shows that, given only tokenized text, publicly available word vectors, and an automatically constructed lexicon from open sources, our system is able to surpass the reported state-ofthe-art on the OntoNotes 5.0 dataset by 2.35 F1 points and achieves competitive results on the CoNLL 2003 dataset, rivaling systems that employ heavy feature engineering, proprietary lexicons, and rich entity linking information.", "creator": "LaTeX with hyperref package"}}}