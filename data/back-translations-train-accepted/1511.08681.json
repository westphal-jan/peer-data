{"id": "1511.08681", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Nov-2015", "title": "Algorithms for Differentially Private Multi-Armed Bandits", "abstract": "We present differentially private algorithms for the stochastic Multi-Armed Bandit (MAB) problem. This is a problem for applications such as adaptive clinical trials, experiment design, and user-targeted advertising where private information is connected to individual rewards. Our major contribution is to show that there exist $(\\epsilon, \\delta)$ differentially private variants of Upper Confidence Bound algorithms which have optimal regret, $O(\\epsilon^{-1} + \\log T)$. This is a significant improvement over previous results, which only achieve poly-log regret $O(\\epsilon^{-2} \\log^{2} T)$, because of our use of a novel interval-based mechanism. We also substantially improve the bounds of previous family of algorithms which use a continual release mechanism. Experiments clearly validate our theoretical bounds.", "histories": [["v1", "Fri, 27 Nov 2015 14:16:00 GMT  (73kb)", "http://arxiv.org/abs/1511.08681v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.CR cs.LG", "authors": ["aristide c y tossou", "christos dimitrakakis"], "accepted": true, "id": "1511.08681"}, "pdf": {"name": "1511.08681.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Christos Dimitrakakis"], "emails": ["chrdimi}@chalmers.se"], "sections": [{"heading": null, "text": "ar Xiv: 151 1.08 681v 1 [stat.ML] 2 7N ov2 01"}, {"heading": "1 Introduction", "text": "The well-known stochastic K-armed bandit problem (Thompson 1933; Robbins and others 1952) involves an agent sequentially selecting between a set of weapons A = {1,.., K}, and obtaining a sequence of scalar rewards {rt}, so that if the agent's action at the time is t = i, then he receives reward rt from any distribution Pi with expectation \u00b5i, E (rt | at = i).The goal of the decision maker is to draw arms to maximize the overall reward, T t = 1 rt obtained. This problem is a model for many applications in which there is a need for trading-off exploration and exploitation. This is because we see only the reward of the arm we draw. An example are clinical trials in which arms correspond to various treatments or tests, and the goal may be to maximize the number of cured patients over time."}, {"heading": "1.1 Related Work", "text": "While DP initially focused on static databases, interest in its relation to online learning problems has increased lately. In the full information environment, a differentiated private algorithm for the opposing case was presented (Jain, Kothari and Thakurta 2012), while (Zhao et al. 2014) an application for smart networks in this constellation was presented. (Thakurta and Smith 2013) provided a differentiated private algorithm for the problem of interdependence, while (Zhao et al.) an application for smart networks in this constellation was presented. (Mishra and Thakurta 2015) provided a differentiated private algorithm for the stochastic bandit problem. Their algorithms are based on two non-private stochastic bandit algorithms that are not based on the top of the constellation. (UCB, Cesa-Bianchi and Fischer 2002)"}, {"heading": "1.2 Our Contributions", "text": "\u2022 We present a novel differentiated private algorithm (DP-UCB-INT) in the stochastic bandit setting, which is near-optimal and adds only an additive constant term to the optimal non-private version (depending on the privacy parameter). Previous algorithms had the optimum in large multiplicative factors. \u2022 We also offer an incremental but important improvement in regretting the existing differentiated private algorithm in the stochastic bandit, which uses the same family of algorithms previously presented in the literature, by using a simpler trust retention and a more sophisticated method of proof. These limits are reached by DP-UCB-BOUND and DP-UCB algorithms. \u2022 We present the first set of differentiated private algorithms in the bandit setting, which are unlimited and do not require knowledge of horizon T. In addition, our regret analysis keeps pace for any time."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Multi-Armed Bandit", "text": "The well-known stochastic K-armed bandit problem (Thompson 1933; Lai and Robbins 1985; Auer, Cesa-Bianchi and Fischer 2002) involves an agent selecting one after the other between a series of K-weapons A = {1,..., K}. At each step t, the player selects an action at = i, A and receives a reward rt [0, 1]. The reward rt is drawn from a fixed but unknown distribution of Pi, so that E (rt | at) = \u00b5i. The goal of the decision maker is to draw the arms to maximize the total reward obtained after T-interactions. (2.1) An equivalent idea is to minimize total regret against an agent who knew the arm with the maximum expectation before the start of the game and always plays it. This is defined by: R, T\u00b5, T-1, T-T-T = 1rt. (2.1), where \u00b5, maxa-A \u00b5a is the mediate reward for the 1-1, optimal reward for the 1-1 and 1-1."}, {"heading": "2.2 Differential Privacy", "text": "A differentiated privacy was originally proposed by (Dwork 2006) to formalize the amount of information about the input of an algorithm that is leaked to an opponent who observes its results, regardless of what the lateral information of the opponent is. In the context of our setup, the input of the algorithm is the sequence of rewards and its output is the actions. Consequently, we use the following definition of differentiated private bandit algorithms. Definition 2.1 ((() -differentiated private bandit algorithm is privacy.) A bandit algorithm is () -differentiated private, if for all sequences r1: t \u2212 1 and r1: t \u2212 1, which differ in at most one single step, we have for all S A: \u03c0 (at) privacy."}, {"heading": "2.3 Hybrid Mechanism", "text": "The hybrid mechanism is an online algorithm that is used to continuously release the sum of some statistics while maintaining differential privacy. Formally, there is a stream \u03c3t = r1, r2.. rt of statistics with ri in [0, 1]. At each step t a new statistical rt is given. The aim is to find the subtotal (yt = \u2211 t = 1 ri) of statistics from time step 1 to t without affecting the privacy of the statistics. In other words, we would like to find a randomized mechanism M (yt | \u03c3t, y1: t \u2212 1), that is, differential privacy. The hybrid mechanism solves this problem by combining the logarithm and the binary noisy sum mechanism. Whenever t = 2k is used for any holistic k, it uses the logarithm mechanism to release a noisy sum by adding Laplace noise effect (1)."}, {"heading": "3 Private Stochastic Multi-Armed Bandits", "text": "Our algorithms are based on the non-private UCB algorithm by (Auer, Cesa-Bianchi and Fischer 2002). At each step, UCB based its actions on an optimistic estimate of the expected reward for each arm. This estimate is the sum of the empirical mean and an upward-bound trust of \u221a 2 log t na, t, where t is the time step and na, t is the number of arms played to date. We can observe that the only quantity that uses the value of the reward is the empirical mean. In order to achieve a differentiated privacy, it is sufficient for the player to base his action on differentiated private empirical means for each arm. This is so, because once the mean of each arm is calculated, the action that is played is a deterministic function of the mean. Specifically, we can see the differential mechanism as a black box, which allows UCB to choose the empirical mean of each non-empirical arm to maintain the other mean for another private arm."}, {"heading": "3.1 The DP-UCB-BOUND Algorithm", "text": "In a statement, the company said it was \"deeply saddened\" by the news of the deaths of the two men and their families, and that it was \"deeply saddened\" to learn of the loss of their loved ones... and that the loss of their loved ones will be felt all over the world. \""}, {"heading": "3.2 The DP-UCB Algorithm", "text": "The most important observation used in algorithm 2 is that if we insert a reward for all hybrid mechanisms at each step, the magnitude of the noise will be the same. This means that there is no longer a need to compensate for an additional limit. Specifically, every time we play an arm at = a and get the reward rt, we not only add it to the hybrid mechanism corresponding to the arm a, but we also add a reward of 0 to the hybrid mechanism of all other arms. Since these calculate a sum, it does not affect subsequent calculations. Theorem 3.3 shows the validity of this approach by showing a regret that is only linked to the optimal non-private regret with an additional factor of O (2 log2 log t). Algorithm 2 DP-UCBRun algorithm 1 sets a value to 0, when arm is played at = a, we put 0 to all hybrid mechanisms connected to an additional log factor of 2 (O)."}, {"heading": "3.3 The DP-UCB-INT Algorithm", "text": "Both algorithms 1 and 2 enjoy a logarithmic regret with only a small additional factor in the time we use only for the optimal non-privacy. (However, this also means that we can get a differentiated privacy with only one additional factor for the optimal privacy.) (This means that we should have a differentiated privacy with only one additional factor for the optimal privacy. (This means that we will get a multiplicative constant for the optimal privacy.) In other words, to eliminate this factor, noise should not depend on novel tricks to achieve differentiated privacy. (Looking at the analysis of algorithms 1 and 2, we observe that by adding noise proportional to the optimum, a multiplicative constant for the optimal privacy should be obtained.) But how can we get such privacy in this case? Note that if we use the means at any time and use the algorithms to use them."}, {"heading": "4 Experiments", "text": "We conduct experiments with weapons whose rewards come from the independent UCB distribution, but the plot on a logarithmic scale shows the regret of the algorithms in over 100,000 time steps with an average of over 100 runs. We have targeted two different levels of privacy: 0.1 and 1. For DP-UCB-INT, we select the entered privacy in such a way that the general privacy is compared with the algorithm defined in episode 3.2 and presented in episode 10 (Private-UCB) with a failure probability chosen to t \u2212 4. We run two scenarios: First, we have used two weapons: one with expectation 0.9 and one with expectation 0.6. The second scenario is a more challenging one with 10 UCB runs with an expectation of 0.1, except two with 0.55 runs, which are not significantly better."}, {"heading": "5 Conclusion and Future Work", "text": "The first two, (DP-UCB and DP-UCBBOUND) are variants of an existing private UCB algorithm (Mishra and Thakurta 2015), while the third uses an interval-based mechanism; the first two algorithms are only within a factor of O (1 log t) and O (2 log2 log t) to the non-private algorithm; the last algorithm, DP-UCB-INT, deals efficiently with the privacy level and regret, and is able to achieve the same regret as the non-private algorithm up to an additional additive constant. This has been achieved by applying two key tricks: updating the mean of each arm with a frequency proportional to privacy."}, {"heading": "A Collected proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Proof of Theorem 3.2", "text": "a is used to indicate the index of an arm. c) is the differential privacy parameter = = reference point for the time.From Lemma (B.2) we know that the error between empirical and private mean is always limited as systemic. It is defined as: hn = 1hn with probability of at least 1 \u2212 hn, X is the empirical mean returned by the private mechanism, Y is the true empirical mean, hn is the error due to the differential private mechanism. It is defined as: hn = 1hn (logn) \u00b7 ln 4n, X is the empirical mean returned by the private mechanic. c) We can rewrite this value in equations A.1 and A.2.Pr (X)."}, {"heading": "A.2 Proof for Theorem 3.3", "text": "The proof of this theorem is similar to that for theorem 3.5 with hn = 1\u0432 \u00b7 \u221a 8 (log n) \u00b7 ln 4\u03b3 \u00b7 1n + 1\u0445 \u00b7 \u221a 8 \u00b7 ln 4\u03b3 \u00b7 1n. We make the same choice of \u03bb and \u03b3. However, the minimum number n compatible with these decisions leads to transcendental equations in the same form as those in the proof of theorem 3.2.B proofs for UCB interval algorithm Fact B.1. Differential privacy of the Laplace mechanism (see Theorem 4 in (Dwork and Roth 2013)). For each real function g of the data is a mechanism that adds Laplace noise to the scale parameter \u03b2, \u0445 g / \u03b2-differential is private, where \u0432g is the L1 sensitivity of g."}, {"heading": "B.1 Proof of Lemma 3.1", "text": "Proof. In fact, for each arm we add a Laplace noise of mean 0 and scale nv / 2 \u2212 1a, t, where na, t is the number of times that arm has been played. Since the sensitivity of the mean is 1na, t, we use the differential privacy of the Laplace mechanism (fact B.1) to provide the proof."}, {"heading": "B.2 Proof of Theorem 3.4", "text": "Similar to the proof of theory 3.1, the general privacy of algorithm 3 is the same as the general privacy of the mechanism that calculates the mean of the rewards received from an individual arm. \u2212 A new Laplace mechanism is used to calculate the mean of each arm. \u2212 n However, a new mean is released only t / f times (all f-time steps) after t-times steps in which f is used the interval. \u2212 n According to the k-times adaptive composition set (III-3 in (Dwork, Rothblum and Vadhan 2010), algorithm 3 is released individually for each arbitrary series. \u2212 n The k-times adaptive composition set (III-3 in (Dwork, Rothblum and Vadhan 2010). \u2212 n The algorithm 3 is released individually."}, {"heading": "B.3 Proof of Corollary 3.1", "text": "From Theorem 3.4 we know that algorithm 3 for all types of communications (0, 1), 1 < v \u2264 1.5 with the exception of min {C, D} C = t = 1e 1 \u00b0 nvD = 1 \u00b0 nvD = 1 \u00b0 nv \u2212 1 \u00b0 nv \u2212 1 \u00b0 nv + 2 \u00b0 n = 12 \u00b0 nvIt is easy to obtain an upper limit for C by applying holistic test inequality: C \u2264 t = 1 \u2212 v / 2 \u2212 v / 2 1 \u2212 v / 2We now simplify D using a standard approximation for exponential functions. D = 1 \u00b0 n = 1e 1 \u00b0 nv \u2212 1 \u00b0 nv + 1 \u00b0 nv + 1 \u00b0 n = 12 \u00b0 nv \u00b2 nv (B.7)."}, {"heading": "B.4 Proof of Corollary 3.2", "text": "The proof is directly derived from episode 3.1. It is provided by inversion of the term using the Riemann-Zeta function in episode 3.1."}, {"heading": "B.5 Proof of Theorem 3.5", "text": "Fact B.2 (Fact 3.7 in (Dwork and Roth 2013) = 3.5 (b) thenPr (| Y | \u2265 b ln 1) = 4 (B). (B.11) Let us first ignore the effects of calculating the averages per interval and assume that we will omit them in each step after playing each arm f0 x in which f0 \u2264 1 \u00b2 is the first value of the row f defined (B.1). Since the proof is very similar to that of Theorem 3.2, we will omit some steps.Similarly to the proof of Theorem 3.2, we will take a bad arm if one of the following 3 events happens: X. (B.12) Xa, na, na, na, na (B.13)."}], "references": [{"title": "Finite time analysis of the multiarmed bandit problem. Machine Learning 47(2/3):235\u2013256", "author": ["Cesa-Bianchi Auer", "P. Fischer 2002] Auer", "N. CesaBianchi", "P. Fischer"], "venue": null, "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Analytical approximations for real values of the lambert w-function", "author": ["Barry"], "venue": "Mathematics and Computers in Simulation", "citeRegEx": "Barry,? \\Q2000\\E", "shortCiteRegEx": "Barry", "year": 2000}, {"title": "Optimal adaptive policies for sequential allocation problems", "author": ["Burnetas", "A.N. Katehakis 1996] Burnetas", "M.N. Katehakis"], "venue": "Advances in Applied Mathematics", "citeRegEx": "Burnetas et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Burnetas et al\\.", "year": 1996}, {"title": "you might also like: \u201d privacy risks of collaborative filtering", "author": ["Calandrino"], "venue": "IEEE Symposium on Security and Privacy,", "citeRegEx": "Calandrino,? \\Q2011\\E", "shortCiteRegEx": "Calandrino", "year": 2011}, {"title": "Private and continual release of statistics", "author": ["Shi Chan", "T.H. Song 2010] Chan", "E. Shi", "D. Song"], "venue": "In Automata, Languages and Programming", "citeRegEx": "Chan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chan et al\\.", "year": 2010}, {"title": "Asymptotic behavior of minimal-exploration allocation policies: Almost sure, arbitrarily slow growing regret", "author": ["Cowan", "W. Katehakis 2015] Cowan", "M.N. Katehakis"], "venue": "arXiv preprint arXiv:1505.02865", "citeRegEx": "Cowan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cowan et al\\.", "year": 2015}, {"title": "Robust and private Bayesian inference", "author": ["Dimitrakakis"], "venue": "In Algorithmic Learning Theory", "citeRegEx": "Dimitrakakis,? \\Q2014\\E", "shortCiteRegEx": "Dimitrakakis", "year": 2014}, {"title": "The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical Computer Science 9(34):211\u2013407", "author": ["Dwork", "C. Roth 2013] Dwork", "A. Roth"], "venue": null, "citeRegEx": "Dwork et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2013}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["Dwork"], "venue": "In Proceedings of the Third Conference on Theory of Cryptography,", "citeRegEx": "Dwork,? \\Q2006\\E", "shortCiteRegEx": "Dwork", "year": 2006}, {"title": "Boosting and differential privacy", "author": ["Rothblum Dwork", "C. Vadhan 2010] Dwork", "G.N. Rothblum", "S. Vadhan"], "venue": "In Proceedings of the 2010 IEEE 51st Annual Symposium on Foundations of Computer Science,", "citeRegEx": "Dwork et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dwork et al\\.", "year": 2010}, {"title": "Differentially private online learning", "author": ["Kothari Jain", "P. Thakurta 2012] Jain", "P. Kothari", "A. Thakurta"], "venue": "COLT 2012 - The 25th Annual Conference on Learning Theory,", "citeRegEx": "Jain et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jain et al\\.", "year": 2012}, {"title": "Asymptotically efficient adaptive allocation rules. Advances in applied mathematics 6(1):4\u201322", "author": ["Lai", "T.L. Robbins 1985] Lai", "H. Robbins"], "venue": null, "citeRegEx": "Lai et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Lai et al\\.", "year": 1985}, {"title": "nearly) optimal differentially private stochastic multi-arm bandits", "author": ["Mishra", "N. Thakurta 2015] Mishra", "A. Thakurta"], "venue": "Proceedings of the 31th International Conference on Conference on Uncertainty in Artificial Intelligence (UAI-2015)", "citeRegEx": "Mishra et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mishra et al\\.", "year": 2015}, {"title": "Handling advertisements of unknown quality in search advertising", "author": ["Pandey", "S. Olston 2006] Pandey", "C. Olston"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Pandey et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Pandey et al\\.", "year": 2006}, {"title": "Some aspects of the sequential design of experiments. Bulletin of the American Mathematical Society 58(5):527\u2013535", "author": ["H Robbins"], "venue": null, "citeRegEx": "Robbins,? \\Q1952\\E", "shortCiteRegEx": "Robbins", "year": 1952}, {"title": "nearly) optimal algorithms for private online learning in full-information and bandit settings", "author": ["Thakurta", "A.G. Smith 2013] Thakurta", "A.D. Smith"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Thakurta et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Thakurta et al\\.", "year": 2013}, {"title": "Supplementary Materials for Algorithms for Differentially Private Multi-Armed Bandits", "author": ["Tossou", "A. Dimitrakakis 2016] Tossou", "C. Dimitrakakis"], "venue": null, "citeRegEx": "Tossou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tossou et al\\.", "year": 2016}, {"title": "Achieving differential privacy of data disclosure in the smart grid", "author": ["Zhao"], "venue": "IEEE Conference on Computer Communications,", "citeRegEx": "Zhao,? \\Q2014\\E", "shortCiteRegEx": "Zhao", "year": 2014}, {"title": "bound). For any \u03b3 \u2264 n\u2212b, where b > 0, Chan\u2019s hybrid mechanism is \u01eb-differential private and has an error bounded with probability at least", "author": ["Improved (Chan", "Shi", "Song"], "venue": null, "citeRegEx": ".Chan et al\\.,? \\Q2010\\E", "shortCiteRegEx": ".Chan et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 8, "context": "Differential privacy (DP) (Dwork 2006) provides an answer to this privacy issue by making the output of an algorithm almost insensitive to any single user information.", "startOffset": 26, "endOffset": 38}, {"referenceID": 8, "context": "2 Differential Privacy Differential privacy was originally proposed by (Dwork 2006), as a way to formalise the amount of information about the input of an algorithm, that is leaked to an adversary observing its output, no matter what the adversary\u2019s side information is.", "startOffset": 71, "endOffset": 83}, {"referenceID": 8, "context": "[Dwork 2006] Dwork, C.", "startOffset": 0, "endOffset": 12}], "year": 2015, "abstractText": "We present differentially private algorithms for the stochastic Multi-Armed Bandit (MAB) problem. This is a problem for applications such as adaptive clinical trials, experiment design, and user-targeted advertising where private information is connected to individual rewards. Our major contribution is to show that there exist (\u01eb, \u03b4) differentially private variants of Upper Confidence Bound algorithms which have optimal regret, O(\u01eb + log T ). This is a significant improvement over previous results, which only achieve poly-log regret O(\u01eb log T ), because of our use of a novel intervalbased mechanism. We also substantially improve the bounds of previous family of algorithms which use a continual release mechanism. Experiments clearly validate our theoretical bounds.", "creator": "LaTeX with hyperref package"}}}