{"id": "1512.00077", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Nov-2015", "title": "Decoding Hidden Markov Models Faster Than Viterbi Via Online Matrix-Vector (max, +)-Multiplication", "abstract": "In this paper, we present a novel algorithm for the maximum a posteriori decoding (MAPD) of time-homogeneous Hidden Markov Models (HMM), improving the worst-case running time of the classical Viterbi algorithm by a logarithmic factor. In our approach, we interpret the Viterbi algorithm as a repeated computation of matrix-vector $(\\max, +)$-multiplications. On time-homogeneous HMMs, this computation is online: a matrix, known in advance, has to be multiplied with several vectors revealed one at a time. Our main contribution is an algorithm solving this version of matrix-vector $(\\max,+)$-multiplication in subquadratic time, by performing a polynomial preprocessing of the matrix. Employing this fast multiplication algorithm, we solve the MAPD problem in $O(mn^2/ \\log n)$ time for any time-homogeneous HMM of size $n$ and observation sequence of length $m$, with an extra polynomial preprocessing cost negligible for $m &gt; n$. To the best of our knowledge, this is the first algorithm for the MAPD problem requiring subquadratic time per observation, under the assumption -- usually verified in practice -- that the transition probability matrix does not change with time.", "histories": [["v1", "Mon, 30 Nov 2015 22:38:07 GMT  (1618kb,D)", "https://arxiv.org/abs/1512.00077v1", "AAAI 2016, to appear"], ["v2", "Fri, 11 Dec 2015 10:40:51 GMT  (1618kb,D)", "http://arxiv.org/abs/1512.00077v2", "AAAI 2016, to appear"]], "COMMENTS": "AAAI 2016, to appear", "reviews": [], "SUBJECTS": "cs.LG cs.DS cs.IT math.IT", "authors": ["massimo cairo", "gabriele farina", "romeo rizzi"], "accepted": true, "id": "1512.00077"}, "pdf": {"name": "1512.00077.pdf", "metadata": {"source": "CRF", "title": "Decoding Hidden Markov Models Faster Than Viterbi Via Online Matrix-Vector (max,+)-Multiplication", "authors": ["Massimo Cairo", "Gabriele Farina", "Romeo Rizzi"], "emails": ["massimo.cairo@unitn.it", "gabriele2.farina@mail.polimi.it", "romeo.rizzi@univr.it"], "sections": [{"heading": "Introduction", "text": "It is not like it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way, in which it is about a way and a way in which it is about a way, in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way in which it is about a way and a way in which it is about a way and a way it is about a way in which it is about a way and a way in which it is about a way and a way it is about a way and a way it is about a way and a way and a way it is about a way and a way it is about a way and a way it is about a way and a way it is about a way and a way and a way it is about a way and a way it is about a way and a way and a way and a way it is about a way it is about a way and a way it is about a way and a way it is about a way and a way and a way and a way it is about a way it is a way and a way it is a way and a way it is a way and a way and a way it is a way and a way it is a way it is a way and a way it is"}, {"heading": "Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Notation", "text": "The i-th component of a vector v is denoted by v [i]; similarly, M [i, j] denotes the entry of row i and column j in the matrix M. Indexes are always considered as starting from 1. In the face of two vectors a and b of dimension n, so that a [i] \u2264 b [i] for each coordinate index i = 1,..., n, we type a b and say that b a or, equivalent, that (a, b) is a dominant pairing. In the face of a matrix or vector M with non-negative entries, we write logM in such a way that the matrix or vector resulting from M is meant by applying the logarithm to each component. We will almost always use the extended set R \u0445 = R, so that we can write log 0 = \u2212 \u00b2. We assume that \u2212 \u221e + x = x + (\u2212 \u221e) = \u2212 \u221e and x > for all x \u00b2"}, {"heading": "Hidden Markov Models (HMMs)", "text": "We formally present the concept of time-homogeneous HMM with natural numbers. Definition 1. A time-homogeneous HMM is a tuple M = (S, A, A, T, E) consisting of: \u2022 a set S = {s1,., sn} of n hidden states; n is formally referred to as the size of the model; \u2022 an output path is multiplied (S, A, A, E) consisting of: \u2022 a set S = {s1,., 2) of n hidden states; a matrix T = {ts (s, S, S, S, S, S, S) of transition probabilities between states; a matrix E = {s, A, S, emission probabilities. The matrix T and E are stochastical, i.e. the entries of each line add up to 1.For notational convenience, we relativize the states of a HMM with natural numbers,.e."}, {"heading": "Experimental evaluation", "text": "Methodology. All algorithms are implemented in the C + + 11 language, compiled with the Clang compiler, and run on the OSX 10.10.3 operating system. The main memory is an 8GB 1600MHz DDR3 RAM, and the processor is an Intel Core i7-4850HQ CPU, with 6MB of shared L3 cache. All the matrices and vectors used for the experiments have entries sampled from a uniform distribution over (0, 1) R. Results. How does our proposed ORMV (max, +) MUL algorithm for tight matrices compare with the trivial? We analyze the throughput of algorithm 1, based on the geometric subroutines exposed in the Lemma 4 evidence, and compare it with the trivial multiplication approach of matrices. For each pair (s, t) we run 25 tests, each of which consists of a matrix \u00d7 n."}, {"heading": "Conclusion and future works", "text": "In this paper, we specify the first algorithm for the maximum a posteriori decoding (MAPD) of time-homogeneous hidden markov models that require asymptotically less than O (mn2) operations in the worst case scenario. To this end, we first introduce an online problem of geometric dominance and propose a simple divide-and-conquer solution that generalizes the classic result by (Chan 2008). Finally, we apply the first algorithm that solves the online matrix vector (max, +) multiplication problem over the R problem in subquadratic time after polynomic pre-processing of the matrix. Finally, we apply the faster multiplication to the MAPD problem. In addition, we think that our proposal paves the way to several unexplored questions that we intend to examine in future work: \u2022 intersect major polylogarithmic factors by dividing the equation in a different way to the 2015 and other year decoding (another way to the 2015)."}, {"heading": "Acknowledgements", "text": "Massimo Cairo was supported by the Faculty of Computer Science of the University of Verona within the framework of the doctoral fellowship \"Computational Mathematics and Biology.\" We would like to thank Marco Elver, Nicola Gatti, Zu Kim and Luigi Laura for their valuable suggestions."}, {"heading": "Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Missing proofs", "text": "We prove theorem 1 and theorem 4. Theorem 1. Problem 2 can be solved in O (d log | B | p) | time per query, according to an O (B | d + 1) time and space preprocessing. Proof. For each coordinate k = 1,.., d, define the sequence bk1,.., b k | B | log all vectors in B according to their k-th coordinate. Namely: bk1 [k] \u2264 bk2, \u00b7 bk | B | k | B | [k]. Faced with an input vector p, let rk [0,.] be the last position in which p can be inserted into the sequence bk1.,., b k k | B |, maintaining its order according to the k-th coordinate. This is the only index that fulfills: bk1, k [k], b, k, k, k, k, k, k, k, k, k, k, k."}, {"heading": "Experimental evaluation", "text": "It is not the first time that the EU Commission has taken such a step."}], "references": [{"title": "Hidden markov model based optical character recognition in the presence of deterministic transformations", "author": ["O.E. Agazzi", "Kuo", "S.-s."], "venue": "Pattern recognition 26(12):1813\u2013 1826.", "citeRegEx": "Agazzi et al\\.,? 1993", "shortCiteRegEx": "Agazzi et al\\.", "year": 1993}, {"title": "Necklaces, convolutions, and x+ y", "author": ["D. Bremner", "T.M. Chan", "E.D. Demaine", "J. Erickson", "F. Hurtado", "J. Iacono", "S. Langerman", "P. Taslakian"], "venue": "Algorithms\u2013 ESA 2006. Springer. 160\u2013171.", "citeRegEx": "Bremner et al\\.,? 2006", "shortCiteRegEx": "Bremner et al\\.", "year": 2006}, {"title": "All-pairs shortest paths with real weights in o (n 3/log n) time", "author": ["T.M. Chan"], "venue": "Algorithmica 50(2):236\u2013243.", "citeRegEx": "Chan,? 2008", "shortCiteRegEx": "Chan", "year": 2008}, {"title": "Speeding up the four russians algorithm by about one more logarithmic factor", "author": ["T.M. Chan"], "venue": "Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, 212\u2013217. SIAM.", "citeRegEx": "Chan,? 2015", "shortCiteRegEx": "Chan", "year": 2015}, {"title": "Implementing em and viterbi algorithms for hidden markov model in linear memory", "author": ["A. Churbanov", "S. Winters-Hilt"], "venue": "BMC bioinformatics 9(1):224.", "citeRegEx": "Churbanov and Winters.Hilt,? 2008", "shortCiteRegEx": "Churbanov and Winters.Hilt", "year": 2008}, {"title": "A more efficient algorithm for the min-plus multiplication", "author": ["W. Dobosiewicz"], "venue": "International journal of computer mathematics 32(1-2):49\u201360.", "citeRegEx": "Dobosiewicz,? 1990", "shortCiteRegEx": "Dobosiewicz", "year": 1990}, {"title": "Carpediem: Optimizing the viterbi algorithm and applications to supervised sequential learning", "author": ["R. Esposito", "D.P. Radicioni"], "venue": "The Journal of Machine Learning Research 10:1851\u20131880.", "citeRegEx": "Esposito and Radicioni,? 2009", "shortCiteRegEx": "Esposito and Radicioni", "year": 2009}, {"title": "Fast algorithms for large-state-space hmms with applications to web usage analysis", "author": ["P.F. Felzenszwalb", "D.P. Huttenlocher", "J.M. Kleinberg"], "venue": "Advances in NIPS 16:409\u2013416.", "citeRegEx": "Felzenszwalb et al\\.,? 2004", "shortCiteRegEx": "Felzenszwalb et al\\.", "year": 2004}, {"title": "Maximum likelihood linear transformations for hmm-based speech recognition", "author": ["M.J. Gales"], "venue": "Computer speech & language 12(2):75\u201398.", "citeRegEx": "Gales,? 1998", "shortCiteRegEx": "Gales", "year": 1998}, {"title": "Reduced space sequence alignment", "author": ["J. Grice", "R. Hughey", "D. Speck"], "venue": "Computer applications in the biosciences : CABIOS 13(1):45\u201353.", "citeRegEx": "Grice et al\\.,? 1997", "shortCiteRegEx": "Grice et al\\.", "year": 1997}, {"title": "A generalized hidden markov model for the recognition of human genes in dna", "author": ["D.K.D. Haussler", "Eeckman", "M.G.R.F.H."], "venue": "Proc. Int. Conf. on Intelligent Systems for Molecular Biology, St. Louis, 134\u2013142.", "citeRegEx": "Haussler et al\\.,? 1996", "shortCiteRegEx": "Haussler et al\\.", "year": 1996}, {"title": "Unifying and strengthening hardness for dynamic problems via the online matrix-vector multiplication conjecture", "author": ["M. Henzinger", "S. Krinninger", "D. Nanongkai", "T. Saranurak"], "venue": "Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, STOC \u201915,", "citeRegEx": "Henzinger et al\\.,? 2015", "shortCiteRegEx": "Henzinger et al\\.", "year": 2015}, {"title": "Hidden Markov models for speech recognition, volume 2004", "author": ["X.D. Huang", "Y. Ariki", "M.A. Jack"], "venue": "Edinburgh university press Edinburgh.", "citeRegEx": "Huang et al\\.,? 1990", "shortCiteRegEx": "Huang et al\\.", "year": 1990}, {"title": "Efficient staggered decoding for sequence labeling", "author": ["N. Kaji", "Y. Fujiwara", "N. Yoshinaga", "M. Kitsuregawa"], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, 485\u2013494. Association for Computational Linguistics.", "citeRegEx": "Kaji et al\\.,? 2010", "shortCiteRegEx": "Kaji et al\\.", "year": 2010}, {"title": "Robust part-of-speech tagging using a hidden markov model", "author": ["J. Kupiec"], "venue": "Computer Speech & Language 6(3):225\u2013242.", "citeRegEx": "Kupiec,? 1992", "shortCiteRegEx": "Kupiec", "year": 1992}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["J.D. Lafferty", "A. McCallum", "F.C.N. Pereira"], "venue": "Proceedings of the Eighteenth International Conference on Machine Learning, ICML \u201901, 282\u2013289. San Francisco, CA, USA: Morgan", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "The mailman algorithm: A note on matrix\u2013vector multiplication", "author": ["E. Liberty", "S.W. Zucker"], "venue": "Information Processing Letters 109(3):179\u2013182.", "citeRegEx": "Liberty and Zucker,? 2009", "shortCiteRegEx": "Liberty and Zucker", "year": 2009}, {"title": "Speeding up hmm decoding and training by exploiting sequence repetitions", "author": ["Y. Lifshits", "S. Mozes", "O. Weimann", "M. Ziv-Ukelson"], "venue": "Algorithmica 54(3):379\u2013399.", "citeRegEx": "Lifshits et al\\.,? 2009", "shortCiteRegEx": "Lifshits et al\\.", "year": 2009}, {"title": "Genome-Scale Algorithm Design", "author": ["V. M\u00e4kinen", "D. Belazzougui", "F. Cunial", "A.I. Tomescu"], "venue": "Cambridge University Press.", "citeRegEx": "M\u00e4kinen et al\\.,? 2015", "shortCiteRegEx": "M\u00e4kinen et al\\.", "year": 2015}, {"title": "The on-line viterbi algorithm", "author": ["R. \u0160r\u00e1mek"], "venue": "KAI FMFI UK, Bratislava, m\u00e1j.", "citeRegEx": "\u0160r\u00e1mek,? 2007", "shortCiteRegEx": "\u0160r\u00e1mek", "year": 2007}, {"title": "Real-time american sign language recognition using desk and wearable computer based video", "author": ["T. Starner", "J. Weaver", "A. Pentland"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on 20(12):1371\u20131375.", "citeRegEx": "Starner et al\\.,? 1998", "shortCiteRegEx": "Starner et al\\.", "year": 1998}, {"title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm", "author": ["A.J. Viterbi"], "venue": "Information Theory, IEEE Transactions on 13(2):260\u2013269.", "citeRegEx": "Viterbi,? 1967", "shortCiteRegEx": "Viterbi", "year": 1967}, {"title": "Matrix-vector multiplication in subquadratic time:(some preprocessing required)", "author": ["R. Williams"], "venue": "SODA, volume 7, 995\u20131001.", "citeRegEx": "Williams,? 2007", "shortCiteRegEx": "Williams", "year": 2007}, {"title": "Hidden markov models and their applications in biological sequence analysis", "author": ["Yoon", "B.-J."], "venue": "Current genomics 10(6):402.", "citeRegEx": "Yoon and B..J.,? 2009", "shortCiteRegEx": "Yoon and B..J.", "year": 2009}], "referenceMentions": [{"referenceID": 21, "context": "Hidden Markov Models (HMMs) are simple probabilistic models originally introduced (Viterbi 1967) to decode convolutional codes.", "startOffset": 82, "endOffset": 96}, {"referenceID": 8, "context": "Due to their universal and fundamental nature, these models have successfully been applied in several fields, with many important applications, such as gene prediction (Haussler and Eeckman 1996), speech, gesture and optical character recognition (Gales 1998; Huang, Ariki, and Jack 1990; Starner, Weaver, and Pentland 1998; Agazzi and Kuo 1993), and part-of-speech tagging (Kupiec 1992).", "startOffset": 247, "endOffset": 345}, {"referenceID": 14, "context": "Due to their universal and fundamental nature, these models have successfully been applied in several fields, with many important applications, such as gene prediction (Haussler and Eeckman 1996), speech, gesture and optical character recognition (Gales 1998; Huang, Ariki, and Jack 1990; Starner, Weaver, and Pentland 1998; Agazzi and Kuo 1993), and part-of-speech tagging (Kupiec 1992).", "startOffset": 374, "endOffset": 387}, {"referenceID": 18, "context": "rently they hold a recognized place in that field (Yoon 2009; M\u00e4kinen et al. 2015).", "startOffset": 50, "endOffset": 82}, {"referenceID": 21, "context": "Traditionally, the MAPD problem is solved by the Viterbi algorithm (Viterbi 1967), inO(mn2) time and O(mn) memory for any model of size n and observation sequence of length m.", "startOffset": 67, "endOffset": 81}, {"referenceID": 19, "context": "oped (\u0160r\u00e1mek 2007; Churbanov and Winters-Hilt 2008; Felzenszwalb, Huttenlocher, and Kleinberg 2004; Esposito and Radicioni 2009; Kaji et al. 2010).", "startOffset": 5, "endOffset": 146}, {"referenceID": 4, "context": "oped (\u0160r\u00e1mek 2007; Churbanov and Winters-Hilt 2008; Felzenszwalb, Huttenlocher, and Kleinberg 2004; Esposito and Radicioni 2009; Kaji et al. 2010).", "startOffset": 5, "endOffset": 146}, {"referenceID": 6, "context": "oped (\u0160r\u00e1mek 2007; Churbanov and Winters-Hilt 2008; Felzenszwalb, Huttenlocher, and Kleinberg 2004; Esposito and Radicioni 2009; Kaji et al. 2010).", "startOffset": 5, "endOffset": 146}, {"referenceID": 13, "context": "oped (\u0160r\u00e1mek 2007; Churbanov and Winters-Hilt 2008; Felzenszwalb, Huttenlocher, and Kleinberg 2004; Esposito and Radicioni 2009; Kaji et al. 2010).", "startOffset": 5, "endOffset": 146}, {"referenceID": 17, "context": "In (Lifshits et al. 2009), the authors show a method to speed up the decoding of HMMs by aO(logm) factor, by precomputing all possible observation sequences of length logm, in a fashion similar to the Four Russians method.", "startOffset": 3, "endOffset": 25}, {"referenceID": 22, "context": "Algorithms faster than the trivial quadratic one are known for the OMV MUL problem over finite semirings (Williams 2007), as well as over real numbers with standard (+, \u00b7)-multiplication, if the matrix has only a constant number of distinct values (Liberty and Zucker 2009).", "startOffset": 105, "endOffset": 120}, {"referenceID": 16, "context": "Algorithms faster than the trivial quadratic one are known for the OMV MUL problem over finite semirings (Williams 2007), as well as over real numbers with standard (+, \u00b7)-multiplication, if the matrix has only a constant number of distinct values (Liberty and Zucker 2009).", "startOffset": 248, "endOffset": 273}, {"referenceID": 5, "context": "In the specific case of real (max,+)-multiplication, subcubic algorithms have been known for years (Dobosiewicz 1990; Chan 2008; 2015) for the matrix-matrix multiplication problem, with important applications to graph theory and boolean matrix multiplication, among others.", "startOffset": 99, "endOffset": 134}, {"referenceID": 2, "context": "In the specific case of real (max,+)-multiplication, subcubic algorithms have been known for years (Dobosiewicz 1990; Chan 2008; 2015) for the matrix-matrix multiplication problem, with important applications to graph theory and boolean matrix multiplication, among others.", "startOffset": 99, "endOffset": 134}, {"referenceID": 11, "context": "Note that the ORMV (max,+)-MUL can be used to compute the OMV MUL over the Boolean semiring: for this problem, it has been conjectured (Henzinger et al. 2015) that no \u201ctruly polynomially subquadratic\u201d algorithm1 exists for the ORMV (max,+)-MUL problem.", "startOffset": 135, "endOffset": 158}, {"referenceID": 1, "context": "We reduce the ORMV (max,+)-MUL problem to a multi-dimensional geometric dominance problem, following an approach similar to that of (Bremner et al. 2006; Chan 2008).", "startOffset": 132, "endOffset": 164}, {"referenceID": 2, "context": "We reduce the ORMV (max,+)-MUL problem to a multi-dimensional geometric dominance problem, following an approach similar to that of (Bremner et al. 2006; Chan 2008).", "startOffset": 132, "endOffset": 164}, {"referenceID": 2, "context": "divide-and-conquer algorithm, which can be regarded as a transposition of the algorithm of (Chan 2008) to the online setting.", "startOffset": 91, "endOffset": 102}, {"referenceID": 2, "context": "Our key contributions are as follows: (i) we extend the geometric dominance reporting problem introduced in (Chan 2008) to the online setting; (ii) we solve the ORMV (max,+)-MUL problem in O(n2/ log n) time after a polynomial preprocessing of the n \u00d7 n matrix; (iii) we show an algorithm solving the MAPD problem on timehomogeneous HMMs in O(mn2/ log n) time in the worstcase, after a polynomial preprocessing of the model.", "startOffset": 108, "endOffset": 119}, {"referenceID": 19, "context": "for it, including the memory saving ones (\u0160r\u00e1mek 2007; Churbanov and Winters-Hilt 2008), are still applicable once the first part has been carried out based on our approach.", "startOffset": 41, "endOffset": 87}, {"referenceID": 4, "context": "for it, including the memory saving ones (\u0160r\u00e1mek 2007; Churbanov and Winters-Hilt 2008), are still applicable once the first part has been carried out based on our approach.", "startOffset": 41, "endOffset": 87}, {"referenceID": 2, "context": "Theorem 2 ((Chan 2008), Lemma 2.", "startOffset": 11, "endOffset": 22}, {"referenceID": 2, "context": "To this end, we first introduce an online geometric dominance reporting problem, and propose a simple divide-and-conquer solution, generalizing the classical result by (Chan 2008).", "startOffset": 168, "endOffset": 179}, {"referenceID": 3, "context": "Furthermore, we think that our proposal paves the way to several unexplored questions which we intend to explore in future works: \u2022 cut larger polylogarithmic factors, by splitting cases in Equation 4 in a different manner, as in (Chan 2015); \u2022 study and implement a more succinct version of the deci-", "startOffset": 230, "endOffset": 241}, {"referenceID": 6, "context": "sion tree, in order to mitigate the memory footprint; \u2022 analyze the relationship of our work with other existing heuristics, such as CarpeDiem (Esposito and Radicioni 2009); \u2022 combine our speed-up to the one delivered by the approach in (Lifshits et al.", "startOffset": 143, "endOffset": 172}, {"referenceID": 17, "context": "sion tree, in order to mitigate the memory footprint; \u2022 analyze the relationship of our work with other existing heuristics, such as CarpeDiem (Esposito and Radicioni 2009); \u2022 combine our speed-up to the one delivered by the approach in (Lifshits et al. 2009).", "startOffset": 237, "endOffset": 259}], "year": 2015, "abstractText": "In this paper, we present a novel algorithm for the maximum a posteriori decoding (MAPD) of timehomogeneous Hidden Markov Models (HMM), improving the worst-case running time of the classical Viterbi algorithm by a logarithmic factor. In our approach, we interpret the Viterbi algorithm as a repeated computation of matrix-vector (max,+)multiplications. On time-homogeneous HMMs, this computation is online: a matrix, known in advance, has to be multiplied with several vectors revealed one at a time. Our main contribution is an algorithm solving this version of matrix-vector (max,+)-multiplication in subquadratic time, by performing a polynomial preprocessing of the matrix. Employing this fast multiplication algorithm, we solve the MAPD problem in O(mn/ logn) time for any time-homogeneous HMM of size n and observation sequence of length m, with an extra polynomial preprocessing cost negligible for m > n. To the best of our knowledge, this is the first algorithm for the MAPD problem requiring subquadratic time per observation, under the only assumption \u2013 usually verified in practice \u2013 that the transition probability matrix does not change with time.", "creator": "TeX"}}}