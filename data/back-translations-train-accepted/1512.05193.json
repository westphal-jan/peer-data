{"id": "1512.05193", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Dec-2015", "title": "ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs", "abstract": "How to model a pair of sentences is a critical issue in many natural language processing (NLP) tasks such as answer selection (AS), paraphrase identification (PI) and textual entailment (TE). Most prior work (i) deals with one individual task by fine-tuning a specific system; (ii) models each sentence separately, without considering the impact of the other sentence; or (iii) relies fully on manually designed, task-specific linguistic features. This work presents a general Attention Based Convolutional Neural Network (ABCNN) for modeling a pair of sentences. We make three contributions. (i) ABCNN can be applied to a wide variety of tasks that require modeling of sentence pairs. (ii) We propose three attention schemes that integrate mutual influence between sentences into CNN; thus, the representation of each sentence takes into consideration its counterpart. These interdependent sentence pair representations are more powerful than isolated sentence representations. (iii) ABCNN achieves state-of-the-art performance on AS, PI and TE tasks.", "histories": [["v1", "Wed, 16 Dec 2015 14:55:17 GMT  (281kb,D)", "http://arxiv.org/abs/1512.05193v1", "11 pages, 2 figures"], ["v2", "Tue, 29 Dec 2015 10:39:53 GMT  (328kb,D)", "http://arxiv.org/abs/1512.05193v2", "12 pages, 3 figures"], ["v3", "Sat, 9 Apr 2016 11:59:39 GMT  (312kb,D)", "http://arxiv.org/abs/1512.05193v3", "Accepted by TACL, to appear"]], "COMMENTS": "11 pages, 2 figures", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["wenpeng yin", "hinrich sch\\\"utze", "bing xiang", "bowen zhou"], "accepted": true, "id": "1512.05193"}, "pdf": {"name": "1512.05193.pdf", "metadata": {"source": "CRF", "title": "ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs", "authors": ["Wenpeng Yin", "Hinrich Sch\u00fctze", "Bing Xiang", "Bowen Zhou"], "emails": ["wenpeng@cis.lmu.de", "bingxia@us.ibm.com", "zhou@us.ibm.com"], "sections": [{"heading": "1 Introduction", "text": "How to model a sentence pair is a critical issue in many NLP tasks such as response selection (AS) (Yu et al., 2014; Feng et al., 2015), paraphrasing identification (PI) (Madnani et al., 2012; Yin and protections, 2015a), textual entanglement (TE) (Marelli et al., 2014a; Bowman et al., 2015a), and machine translation (Bahdanau et al., 2015). Most previous work models differ in terms of the effects of the other being. This neglects the reciprocal influence of the two sentences in the context of the task. It also contradicts what humans do when comparing two sentences. We usually focus on key parts of the first sentence by extracting parts from the second sentence that are related by identity, synomymy, antonymy, and other relationships."}, {"heading": "2 Related Work", "text": "For AS, Yu et al. (2014) present a bigram CNN to model question and answer candidates. Yang et al. (2015) extend this method and get a state-of-the-art performance on the WikiQA dataset (Section 5.2). Feng et al. (2015) test different arrangements of a bi-CNN architecture on an insurance area QA dataset. Tan et al. (2015) explore bidirectional long-term short-term memory (LSTM, Hochreiter and Schmidhuber (1997) in the same insurance-based dataset. Our approach is different because we do not model the sentences by two independent neural networks in parallel, but as an interdependent sentence pair by using attention.For PI, Blacoe and Lapata (2012) form the sentence representation by summarizing word embedding."}, {"heading": "3 BCNN: Basic Bi-CNN", "text": "In fact, most of them are able to follow the rules that they have imposed on themselves. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are not able to follow the rules. (...) Most of them are able to follow the rules. (...) Most of them are able to follow the rules themselves. (...) Most of them are not able to determine themselves. (...) Most of them are not able to determine themselves. (...) Most of them are able to determine themselves what they are doing. (...)"}, {"heading": "4 ABCNN: Attention-Based BCNN", "text": "We introduce three different attention mechanisms for modeling sentence pairs in BCNN; see Figure 3."}, {"heading": "4.1 ABCNN-1", "text": "In fact, it is a kind of conspiracy that is able to hide, and that is able to hide, \"he said in an interview with the\" New York Times. \"(afu)\" It is as it is. \"(afu)\" It is as it is. \"(afu)\" It is as it is. \"(afu)\" It is as it is. \"(afu)\" It is as it is. \"(afu)\" It is as it is. \"(afu)"}, {"heading": "4.2 ABCNN-2", "text": "ABCNN-1 calculates the attention weights directly from the representation with the aim of improving the characteristics calculated by folding. ABCNN-2 instead calculates the attention weights on the output of the folding with the aim of reweighting this folding. In the example shown in Figure 3 (b), the characteristic values are output by folding for s0 and s1; each column is the representation of a unit. The attention matrix A compares all units in s0 with all units of s1. We sum up all attention values for one unit to derive a uniform attention weight for that unit. This corresponds to the summation of all values in a row of A for s0 (resulting in the shown column vector of size 7) and summarizes all values in a column for s1 (resulting in the line vector of size 9 shown).More formally, the attention of A-Rs \u00d7 will be the attention matrix."}, {"heading": "4.3 ABCNN-3", "text": "ABCNN-3 combines ABCNN-1 and ABCNN-2 by stacking. See Figure 3 (c). ABCNN-3 combines the strengths of ABCNN-1 and ABCNN-2 by allowing the attention mechanism to work (i) both on folding and bundling parts of a folding plus pooling block and (ii) on both the input granularity and the more abstract output granularity."}, {"heading": "5 Experiments", "text": "We test the proposed architectures based on three tasks: response selection, paraphrase identification, and text embedding."}, {"heading": "5.1 Common Training Setup", "text": "For all tasks, words are initialized by 300-dimensional word2vec embeddings and not changed during training. A single randomly initialized embedding3 is created for all unknown words by uniform sampling of [-.01,.01]. We employ Adagrad (Duchi et al., 2011) and regularize L2. Network configuration. Each network in the experiments below consists of (i) an initialization block b1, which initializes words by word2vec embeddings, (ii) a stack of convolution pooling blocks b2,. bk, computing increasingly abstract features, and (ii) a final LR layer (logistic regression layer), as shown in Figure 2.We Input to the LR layer consists of kn functions - each block provides n similarity scores (such as cosmic similarity)."}, {"heading": "5.2 Answer Selection", "text": "We use WikiQA, 5, an open domain question and answer dataset. We use the sub-task, which assumes that there is at least one correct answer to a question. The corresponding dataset consists of 20,360 pairs of question candidates on the train, 1,130 pairs in development, and 2,352 pairs in the test, using the standard structure to consider only questions that have correct answers for evaluation. Following Yang et al. (2015), we shorten the answers to 40 marks. The task is to evaluate the candidates \"answers based on their affiliation with the question. Rating measures are medium average precision (MAP) and medium reciprocity (MRR)."}, {"heading": "5.2.1 Baseline Systems", "text": "We compare with the seven systems considered by Yang et al. (2015): (i) WordCnt: Counting the number of nonstop words in the question that also occur in the answer; (ii) WgtWordCnt: Reweighting the counts based on the IDF values of the question words; (iii) LCLR (Yih et al., 2013) uses rich lexical semantic features, including word / Lemma matching, WordNet (Miller, 1995) and distribution models; (iv) PV: Paragraph Vector (Le and Mikolov, 2014); (v) CNN: bigram convolutional neural network (Yu et al., 2014); (vi) PV-Cnt: combine PV with (i) and (ii); (vii) CNN-Cnt: combine CNN with (i) and (ii)."}, {"heading": "5.2.2 Task-Specific Setup", "text": "For this task we use cosine similarity as similarity value. Additionally we use sentence lengths, WordCnt and WgtWordCnt. Thus, the final input into the LR plane has the size k + 4: one cosine for each of the k blocks and the four additional characteristics."}, {"heading": "5.2.3 Results", "text": "Table 3 shows the performance of baselines, BCNN and the three ABCNN architectures. For 5http: / / aka.ms / WikiQA (Yang et al., 2015) CNNs, we test one (one-conv) and two (two-conv) convolution pooling blocks. The non-attention network BCNN already performs better than baselines. If we add attention mechanisms, performance improves by several points. If we compare ABCNN-2 with ABCNN-1, we find that ABCNN-2 is slightly better, although ABCNN-2 is the simpler architecture. If we combine ABCNN-1 and ABCNN-2 to ABCNN-3, we get further improvements. 6This can be explained by ABCNN-3's ability to take into account finer granularity, although ABCNN-2 is the simpler architecture."}, {"heading": "5.3 Paraphrase Identification", "text": "We use Microsoft Research Paraphrase (MSRP) corpus (Dolan et al., 2004). The training set contains 2753 true / 1323 false and the test set 1147 true / 578 false paraphrase pairs. We randomly select 400 pairs from the train and use them as a developer pair, but we still report results for the entire training. For each triple (label, s0, s1) on the train we add additional (label, s1, s0) to make the most of the training data."}, {"heading": "5.3.1 Baseline Systems", "text": "We compare our system with high-performance neural network systems (NN) and non-NN systems. (i) RAE (Socher et al., 2011) Recursive autoencoder that learns how to display phrases when parsing trees, then passes phrase-phrase similarity values to classifiers. (ii) Bi CNN-MI (Yin and Protectors, 2015a). A bi-CNN architecture that recognizes multilingual phrases, models that match between phrase-phrase pairs and applies pre-training. (iii) MPSSM-CNN (He et al., 2015) Like Bi CNNMI, MPSSM-CNN stacks CNNs to extract sentence features at multiple granularity levels and uses multiple types of pooling, then compares two sets with multiple similarity metrics. (This is the state-of-the-art NN system (iv) Madani nal."}, {"heading": "5.3.2 Task-Specific Setup", "text": "In this task, we add the 15 MT characteristics of (Madnani et al., 2012) and the length of the two sentences. In addition, we calculate ROUGE-1, ROUGE-2 and ROUGE-SU4.8, which measure the similarity between the two sentences on (i) unirams, (ii) bigrams and (iii) unigrams or jump bigrams (maximum jump distance of four). In this task, we found that converting the Euclidean distance into similarity values is 1 / (1 + | x \u2212 y |) better than cosmic similarity. In addition, we use dynamic pooling (yin and protectors, 2015a) of the attention matrix and forward summarized values of all blocks to the LR level. This gives us a slightly better performance than just formatting adaptation characteristics at the typesetting level."}, {"heading": "5.3.3 Results", "text": "Table 4 shows that BCNN is slightly worse than the state of the art, whereas ABCNN-1 roughly matches the state of the art. ABCNN-2 is slightly higher than the state of the art. ABCNN-3 significantly exceeds the state of the art in terms of accuracy and F1.9 Two folding layers bring only slight improvements compared to one.8http: / / www.isi.edu / licensed-sw / see / rouge (Lin, 2004) 9If we run ABCNN-3 (two convectors) without the 15 + 3 \"linguistic\" features (i.e. MT and ROUGE), the performance is 75.1 / 82.7."}, {"heading": "5.4 Textual Entailment", "text": "SemEval 2014 Task 1 (Marelli et al., 2014a) evaluates system predictions of text relationships on sentence pairs from the SICK dataset (Marelli et al., 2014b). The three classes are division, contradiction, and neutrality. The sizes of the SICK train, developer, and test sets are 4439, 495, and 4906 pairs, respectively. We call this dataset ORIG.We also create NONOVER, a copy of ORIG, in which the words that occur in both sentences are removed. A sentence in NONOVER is designated by the special token < empty > when all words are removed. Table 5 shows three pairs of ORIG and their transformation into NONOVER. We note that the concentration on the non-overlapping parts provides clearer clues for TE than ORIG. In this task, we perform two copies of each network, one for ORIG, one for NforONOVER; these two networks have a common move (hock) and one (hock)."}, {"heading": "5.4.1 Task-Specific Setup", "text": "We have found that two similarity values from each block (instead of just one) are helpful for this task. We use cosmic similarity and Euclidean distance. As for paraphrase identification, we add the 15 MT characteristics for each pair of sentences based on the observation that sentences are more likely to be paraphrased than contradictory sentences. We use the following linguistic characteristics. Denial. Obviously, denial is an important feature for detecting contradictions. Characteristic NEG is set to 1 when each sentence is \"no,\" \"not,\" \"nobody\" is \"and to 0 otherwise.Nyms. Following Lai and Hockenmaier (2014), we use WordNet to detect synonyms, hypernyms and antonyms in pairs, but we do this on NONOVER (not on ORIG) to focus on what is critical for TE."}, {"heading": "5.4.2 Results", "text": "Table 6 shows that our CNNs outperform SemEval's top 3 systems, demonstrating the promising use of deep learning for TE. Comparing ABCNN to BCNN, the attention mechanism consistently improves performance. ABCNN-1 performs roughly as well as ABCNN-2, while ABCNN-3 performs better: an increase of 1.6 points.10"}, {"heading": "5.5 Summary", "text": "Our experimental results on the tasks of AS, PI and TE show that attention-based CNNs without attention mechanisms perform better than CNNs without attention mechanisms. ABCNN-2 generally outperforms ABCNN-1 and ABCNN-3. In all tasks, we have not seen much improvement for two-convectors over Oneconv. This is probably due to the limited size of training data. We expect deeper ABCNNs to show their effectiveness when larger training sets are available. Previous work on attention mechanisms in neural networks relies predominantly on (bi-directional) LSTM. LSTM learns sentence representation with a focus on a local word. This type of sentence representation is used for attention-based systems because they are mainly intended to denote the local word, while we memorize the entire context in the mean-10. If we can get ABCNN-3 (two convectors) with no linguistic framework, we may also show that this attention-based performance is very contextual, in 84.63, which is very good."}, {"heading": "6 Conclusion", "text": "In this paper, we presented three mechanisms for integrating attention into a revolutionary neural network for general sentence pair modeling tasks. Experiments in AS, PI, and TE tasks all demonstrated the effectiveness of attention-based CNNs."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": "In Proceedings of the 3rd International Conference on Learning Representations", "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "A comparison of vector-based representations for semantic composition", "author": ["Blacoe", "Lapata2012] William Blacoe", "Mirella Lapata"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural", "citeRegEx": "Blacoe et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Blacoe et al\\.", "year": 2012}, {"title": "2015a. A large annotated corpus for learning natural language inference", "author": ["Gabor Angeli", "Christopher Potts", "Christopher D Manning"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Process-", "citeRegEx": "Bowman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Recursive neural networks can learn logical semantics", "author": ["Christopher Potts", "Christopher D Manning"], "venue": "In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality (CVSC),", "citeRegEx": "Bowman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources", "author": ["Dolan et al.2004] Bill Dolan", "Chris Quirk", "Chris Brockett"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "Dolan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dolan et al\\.", "year": 2004}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi et al.2011] John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Applying deep learning to answer selection: A study and an open task. arXiv preprint arXiv:1508.01585", "author": ["Feng et al.2015] Minwei Feng", "Bing Xiang", "Michael R Glass", "Lidan Wang", "Bowen Zhou"], "venue": null, "citeRegEx": "Feng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2015}, {"title": "Multi-perspective sentence similarity modeling with convolutional neural networks", "author": ["He et al.2015] Hua He", "Kevin Gimpel", "Jimmy Lin"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["Hu et al.2014] Baotian Hu", "Zhengdong Lu", "Hang Li", "Qingcai Chen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2014}, {"title": "Discriminative improvements to distributional sentence similarity", "author": ["Ji", "Eisenstein2013] Yangfeng Ji", "Jacob Eisenstein"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Ji et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2013}, {"title": "Illinois-lh: A denotational and distributional approach to semantics", "author": ["Lai", "Hockenmaier2014] Alice Lai", "Julia Hockenmaier"], "venue": "SemEval", "citeRegEx": "Lai et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lai et al\\.", "year": 2014}, {"title": "Distributed representations of sentences and documents", "author": ["Le", "Mikolov2014] Quoc V Le", "Tomas Mikolov"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Le et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Le et al\\.", "year": 2014}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Chin-Yew Lin"], "venue": "In Text summarization branches out: Proceedings of the ACL-04 workshop,", "citeRegEx": "Lin.,? \\Q2004\\E", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Re-examining machine translation metrics for paraphrase identification", "author": ["Joel Tetreault", "Martin Chodorow"], "venue": "In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Madnani et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Madnani et al\\.", "year": 2012}, {"title": "Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness", "author": ["Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli"], "venue": null, "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "A sick cure for the evaluation of compositional distributional semantic models", "author": ["Stefano Menini", "Marco Baroni", "Luisa Bentivogli", "Raffaella Bernardi", "Roberto Zamparelli"], "venue": "In Proceedings of LREC,", "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Wordnet: a lexical database for english", "author": ["George A Miller"], "venue": "Communications of the ACM,", "citeRegEx": "Miller.,? \\Q1995\\E", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Reasoning about entailment with neural attention", "author": ["Edward Grefenstette", "Karl Moritz Hermann", "Tom\u00e1\u0161 Ko\u010disk\u1ef3", "Phil Blunsom"], "venue": "arXiv preprint arXiv:1509.06664", "citeRegEx": "Rockt\u00e4schel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rockt\u00e4schel et al\\.", "year": 2015}, {"title": "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection", "author": ["Eric H Huang", "Jeffrey Pennin", "Christopher D Manning", "Andrew Y Ng"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Lstm-based deep learning models for non-factoid answer selection. arXiv preprint arXiv:1511.04108", "author": ["Tan et al.2015] Ming Tan", "Bing Xiang", "Bowen Zhou"], "venue": null, "citeRegEx": "Tan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tan et al\\.", "year": 2015}, {"title": "A deep architecture for semantic matching with multiple positional sentence representations. arXiv preprint arXiv:1511.08277", "author": ["Wan et al.2015] Shengxian Wan", "Yanyan Lan", "Jiafeng Guo", "Jun Xu", "Liang Pang", "Xueqi Cheng"], "venue": null, "citeRegEx": "Wan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wan et al\\.", "year": 2015}, {"title": "Wikiqa: A challenge dataset for opendomain question answering", "author": ["Yang et al.2015] Yi Yang", "Wen-tau Yih", "Christopher Meek"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "Question answering using enhanced lexical semantic models", "author": ["Yih et al.2013] Wen-tau Yih", "Ming-Wei Chang", "Christopher Meek", "Andrzej Pastusiak"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Yih et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yih et al\\.", "year": 2013}, {"title": "Convolutional neural network for paraphrase identification", "author": ["Yin", "Sch\u00fctze2015a] Wenpeng Yin", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association", "citeRegEx": "Yin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2015}, {"title": "2015b. Multigrancnn: An architecture for general matching of text chunks on multiple levels of granularity", "author": ["Yin", "Sch\u00fctze2015b] Wenpeng Yin", "Hinrich Sch\u00fctze"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Yin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2015}, {"title": "Deep learning for answer sentence selection. arXiv preprint arXiv:1412.1632", "author": ["Yu et al.2014] Lei Yu", "Karl Moritz Hermann", "Phil Blunsom", "Stephen Pulman"], "venue": null, "citeRegEx": "Yu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2014}, {"title": "Ecnu: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment", "author": ["Zhao et al.2014] Jiang Zhao", "Tian Tian Zhu", "Man Lan"], "venue": "SemEval", "citeRegEx": "Zhao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 27, "context": "How to model a pair of sentences is a critical issue in many NLP tasks such as answer selection (AS) (Yu et al., 2014; Feng et al., 2015), paraphrase identification (PI) (Madnani et al.", "startOffset": 101, "endOffset": 137}, {"referenceID": 6, "context": "How to model a pair of sentences is a critical issue in many NLP tasks such as answer selection (AS) (Yu et al., 2014; Feng et al., 2015), paraphrase identification (PI) (Madnani et al.", "startOffset": 101, "endOffset": 137}, {"referenceID": 14, "context": ", 2015), paraphrase identification (PI) (Madnani et al., 2012; Yin and Sch\u00fctze, 2015a), textual entailment (TE) (Marelli et al.", "startOffset": 40, "endOffset": 86}, {"referenceID": 0, "context": ", 2015a) and machine translation (Bahdanau et al., 2015).", "startOffset": 33, "endOffset": 56}, {"referenceID": 24, "context": ", Yih et al. (2013) employ word alignment to match related parts of the two sentences.", "startOffset": 2, "endOffset": 20}, {"referenceID": 27, "context": "For AS, Yu et al. (2014) present a bigram CNN to model", "startOffset": 8, "endOffset": 25}, {"referenceID": 21, "context": "Yang et al. (2015) extend this method and get state-of-the-art performance on the the WikiQA dataset (Section 5.", "startOffset": 0, "endOffset": 19}, {"referenceID": 6, "context": "Feng et al. (2015) test various setups of a bi-CNN architecture on an insurance domain QA dataset.", "startOffset": 0, "endOffset": 19}, {"referenceID": 6, "context": "Feng et al. (2015) test various setups of a bi-CNN architecture on an insurance domain QA dataset. Tan et al. (2015) explored bidirectional long shortterm memory (LSTM, Hochreiter and Schmidhuber (1997)) in the same insurance-based dataset.", "startOffset": 0, "endOffset": 117}, {"referenceID": 6, "context": "Feng et al. (2015) test various setups of a bi-CNN architecture on an insurance domain QA dataset. Tan et al. (2015) explored bidirectional long shortterm memory (LSTM, Hochreiter and Schmidhuber (1997)) in the same insurance-based dataset.", "startOffset": 0, "endOffset": 203}, {"referenceID": 20, "context": "Socher et al. (2011) use recursive autoencoder (RAE) to model representations of local phrases in sentences, then pool similarity values of phrases from the two sentences as features for binary classification.", "startOffset": 0, "endOffset": 21}, {"referenceID": 20, "context": "Socher et al. (2011) use recursive autoencoder (RAE) to model representations of local phrases in sentences, then pool similarity values of phrases from the two sentences as features for binary classification. Yin and Sch\u00fctze (2015a) present a similar model in which RAE is replaced by CNN.", "startOffset": 0, "endOffset": 234}, {"referenceID": 2, "context": "For TE, Bowman et al. (2015b) employ recursive neural networks to encode entailment on SICK (Marelli et al.", "startOffset": 8, "endOffset": 30}, {"referenceID": 2, "context": "For TE, Bowman et al. (2015b) employ recursive neural networks to encode entailment on SICK (Marelli et al., 2014b). Rockt\u00e4schel et al. (2015) present an attention-based LSTM for the Stanford Natural Language Inference corpus (Bowman et al.", "startOffset": 8, "endOffset": 143}, {"referenceID": 9, "context": "Hu et al. (2014) present two CNN architectures, ARC-I and ARC-II, for sentence", "startOffset": 0, "endOffset": 17}, {"referenceID": 22, "context": "Wan et al. (2015) try to match two sentences in AS and SC by multi-", "startOffset": 0, "endOffset": 18}, {"referenceID": 17, "context": "Each word is represented as a d0-dimensional precomputed word2vec (Mikolov et al., 2013) embedding,1 d0 = 300.", "startOffset": 66, "endOffset": 88}, {"referenceID": 5, "context": "We employ Adagrad (Duchi et al., 2011) and L2 regularization.", "startOffset": 18, "endOffset": 38}, {"referenceID": 23, "context": "Following Yang et al. (2015), we", "startOffset": 10, "endOffset": 29}, {"referenceID": 23, "context": "We compare with the seven systems considered by Yang et al. (2015): (i) WordCnt: count the number of non-stopwords in the question that also oc-", "startOffset": 48, "endOffset": 67}, {"referenceID": 24, "context": "cur in the answer; (ii) WgtWordCnt: reweight the counts by the IDF values of the question words; (iii) LCLR (Yih et al., 2013) makes use of rich lexical semantic features, including word/lemma matching, WordNet (Miller, 1995) and distributional models;", "startOffset": 108, "endOffset": 126}, {"referenceID": 18, "context": ", 2013) makes use of rich lexical semantic features, including word/lemma matching, WordNet (Miller, 1995) and distributional models;", "startOffset": 92, "endOffset": 106}, {"referenceID": 27, "context": "(iv) PV: Paragraph Vector (Le and Mikolov, 2014); (v) CNN: bigram convolutional neural network (Yu et al., 2014); (vi) PV-Cnt: combine PV with (i) and (ii); (vii) CNN-Cnt: combine CNN with (i) and (ii).", "startOffset": 95, "endOffset": 112}, {"referenceID": 23, "context": "ms/WikiQA (Yang et al., 2015) method MAP MRR", "startOffset": 10, "endOffset": 29}, {"referenceID": 4, "context": "We use Microsoft Research Paraphrase (MSRP) corpus (Dolan et al., 2004).", "startOffset": 51, "endOffset": 71}, {"referenceID": 20, "context": "RAE (Socher et al., 2011).", "startOffset": 4, "endOffset": 25}, {"referenceID": 7, "context": "(iii) MPSSM-CNN (He et al., 2015).", "startOffset": 16, "endOffset": 33}, {"referenceID": 14, "context": "(iv) MT (Madnani et al., 2012).", "startOffset": 8, "endOffset": 30}, {"referenceID": 14, "context": "For better comparability of approaches in our experiments, we use a simple SVM classifier, which performs slightly worse than Madnani et al. (2012)\u2019s more complex meta-classifier.", "startOffset": 126, "endOffset": 148}, {"referenceID": 14, "context": "(Madnani et al., 2012) and the lengths of the two sentences.", "startOffset": 0, "endOffset": 22}, {"referenceID": 13, "context": "edu/licensed-sw/see/rouge (Lin, 2004) If we run ABCNN-3 (two conv) without the 15+3 \u201clinguistic\u201d features (i.", "startOffset": 26, "endOffset": 37}, {"referenceID": 28, "context": "6 (Zhao et al., 2014) Illinois-LH run1 84.", "startOffset": 2, "endOffset": 21}], "year": 2015, "abstractText": "How to model a pair of sentences is a critical issue in many natural language processing (NLP) tasks such as answer selection (AS), paraphrase identification (PI) and textual entailment (TE). Most prior work (i) deals with one individual task by fine-tuning a specific system; (ii) models each sentence separately, without considering the impact of the other sentence; or (iii) relies fully on manually designed, task-specific linguistic features. This work presents a general Attention Based Convolutional Neural Network (ABCNN) for modeling a pair of sentences. We make three contributions. (i) ABCNN can be applied to a wide variety of tasks that require modeling of sentence pairs. (ii) We propose three attention schemes that integrate mutual influence between sentences into CNN; thus, the representation of each sentence takes into consideration its counterpart. These interdependent sentence pair representations are more powerful than isolated sentence representations. (iii) ABCNN achieves state-of-the-art performance on AS, PI and TE tasks.", "creator": "LaTeX with hyperref package"}}}