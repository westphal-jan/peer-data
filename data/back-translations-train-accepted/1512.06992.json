{"id": "1512.06992", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Dec-2015", "title": "On the Differential Privacy of Bayesian Inference", "abstract": "We study how to communicate findings of Bayesian inference to third parties, while preserving the strong guarantee of differential privacy. Our main contributions are four different algorithms for private Bayesian inference on proba-bilistic graphical models. These include two mechanisms for adding noise to the Bayesian updates, either directly to the posterior parameters, or to their Fourier transform so as to preserve update consistency. We also utilise a recently introduced posterior sampling mechanism, for which we prove bounds for the specific but general case of discrete Bayesian networks; and we introduce a maximum-a-posteriori private mechanism. Our analysis includes utility and privacy bounds, with a novel focus on the influence of graph structure on privacy. Worked examples and experiments with Bayesian na{\\\"i}ve Bayes and Bayesian linear regression illustrate the application of our mechanisms.", "histories": [["v1", "Tue, 22 Dec 2015 09:22:39 GMT  (35kb,D)", "http://arxiv.org/abs/1512.06992v1", "AAAI 2016, Feb 2016, Phoenix, Arizona, United States"]], "COMMENTS": "AAAI 2016, Feb 2016, Phoenix, Arizona, United States", "reviews": [], "SUBJECTS": "cs.AI cs.CR cs.LG math.ST stat.ML stat.TH", "authors": ["zuhe zhang", "benjamin i p rubinstein", "christos dimitrakakis"], "accepted": true, "id": "1512.06992"}, "pdf": {"name": "1512.06992.pdf", "metadata": {"source": "CRF", "title": null, "authors": [], "emails": [], "sections": [{"heading": null, "text": "Our main contributions are four different algorithms for private Bayesian inferences to probabilistic graphical models, including two mechanisms for adding noise to Bayesian updates, either directly to the posterior parameters or to their Fourier transformation, to maintain update consistency. We also use a recently introduced posterior scanning mechanism for which we demonstrate limitations on the specific but general case of discrete Bayesian networks, and we introduce a maximum a posterior private mechanism. Our analysis covers utility and privacy limits, with a novel emphasis on the impact of graph structure on privacy. Applied examples and experiments with naive Bayesian Bayes and Bayesian linear regression illustrate the application of our mechanisms."}, {"heading": "1 Introduction", "text": "We look at the problem that a statistical system is facing, as something that surrounds the world and as something that spans the world. It's a case that's about people's privacy. It's a case that's about protecting people's privacy. It's a case that's about people's privacy. It's a case that's about people's privacy. It's a case that's about people's privacy. It's a case that's about people's privacy. It's a case that's about people's privacy. It's a case that's about people's privacy. It's a case that's about people's privacy. It's a case that's about people's privacy. It's a case that's about people's privacy."}, {"heading": "2 Problem Setting", "text": "Consider a Bayesian statistician B, who estimates the parameters of some distribution families, with observations referred to as xi-Xi, where Xi is the sample space of Xi. B has a previous distribution1, which reflects their previous belief, and which updates them to an observation x to obtain subsequent results (B | x) = \"B-p\u03b8 (x),\" B-p\u0432 \"(x),\" B-p\u0430 \"(x),\" B-brush \"(x),\" X-brush (x). \"Subsequent updates are made using an i.i.d. data set D = (i Xi) n to\" (\u00b7 | D) n. \"B's goal is to communicate their subsequent distribution to a third party, while limiting the information disclosed about the original data. However, from the vendor's point of view before the data is published, B is carefully assumed to have the information A and B confidentially controlled."}, {"heading": "2.1 Probabilistic Graphical Models", "text": "Our main results focus on PGMs where conditional assumptions of independence with common factoring positions (x) = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" = \"i\" in a Bajian network - a directed acyclic graph with \"s as an example 1. Specifically, we illustrate some of our mechanisms on systems Bernoulli r.v.\" s Xi \"=\" 0, 1. \"In this case, we represent the conditional distribution of Xi as\" Bernoulli \"with the parameters\" i, \"\" j \"[0, 1]: (Xi | X\u03c0i = j)\" Bernoulli \"(\" i, j). 1Strictly speaking, it is a measurement of probability on a beti = \"ali.\""}, {"heading": "2.2 Differential Privacy", "text": "B communicates with A by publishing information on posterior distribution via a randomized mechanism M that matches the D-D data set to a response in sentence Y. Dwork et al. (2006) characterize when such a mechanism is private: Definition 1 (Differential Privacy). A randomized mechanism is (, \u03b4) -DP when for neighboring D, D-D and measurable B-Y: P [M (D), B] \u2264 e P [M (D), B] + \u03b4, where D = (xi) ni = 1, D = (x-i) ni = 1 are adjacent if x i = x-i for at most one i. This definition requires adjacent data sets to produce similar response distributions. Consequently, it is impossible for A to identify the true dataset from limited mechanisms query responses."}, {"heading": "3 Privacy by Posterior Perturbation", "text": "One approach to differential privacy is the use of Laplace additive noise (Dwork et al., 2006). Previous work focused on adding noise directly to the outputs of a non-private mechanism. We are the first to apply Laplace noise to the rear parameter updates."}, {"heading": "3.1 Laplace Mechanism on Posterior Updates", "text": "In the setting of example 1, we can add Laplace noise to the rear parameters. Algorithm 1 publishes disturbed parameter updates for the rear areas, which are calculated simply by counting. It then adds zero-mean noise to the updates. Algorithm 1 publishes disturbed parameter updates for the rear areas. This is the final dependence on D. Finally, the disturbed updates are reduced to zero to exclude the invalid beta parameters and are top dividing lines on n. This results in an upper limit for the raw updates and facilitates the application of the McDiarmid differences in application analysis. Lemma A.1 points out that this truncation only improves utility (relative to pre-truncation utility) and not privacy. Algorithm 1 Laplace mechanism on posterior updates 1: input data D; I do not stop the utility."}, {"heading": "3.2 Laplace Mechanism in the Fourier Domain", "text": "\"We are not in a position to protect our privacy,\" he said. (2007) \"It is probably inconsistent with another (e.g.).\" This section represents a particularly natural application to Bayesian posterior updates. Denote of h. \"R\".0,1 \"I | the contingency table over r.v. s I.\" (D: i.e.), for any combination of variables j. \"(D: i.e.), for any combination of variables j.\" (D: i.e.), for any combination of variables j. \"(D: i.e.), for any combination of variables j.\" (D: i.e.), for any combination of variables j. \"(D: i.e.), for any combination of variables j.\" (D: i.e.), for any combination of variables j. \"(i.e.), for any combination of variables.\" (i.e.)."}, {"heading": "4 Privacy by Posterior Sampling", "text": "For general Bayesian networks, B can release samples from the posterior Dimitrakakis et al. (2014) instead of taking disturbed samples from the posterior parameterization. We are now developing a calculation of the structure of (stochastic) Lipschitz properties of r.v. systems that are local (stochastic) Lipschitz. Given the smoothness of the entire network, different privacy and usefulness of posterior sampling follow."}, {"heading": "4.1 (Stochastic) Lipschitz Smoothness of Networks", "text": "The following problem shows that the individual continuity of the conditional continuity of the continuity of the continuity of the continuity of the \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "4.2 MAP by the Exponential Mechanism", "text": "As an application of the posterior sampler, we now turn to the publication of MAP point estimates via the exponential mechanism McSherry and Talwar (2007), which selects answers from a probability exponential in a score function. By selecting a service function maximized by a non-private target mechanism, the exponential mechanism can be used to approach this target privately with high benefit. It is then natural to select as our utility u the posterior probability. (\u00b7 D) This mechanism is maximized by the MAP estimate. (Algorithm 3: Mechanism for MAP Point Estimates 1: Input data D; previous procedure D; appropriate smoothness parameters c, L > 0; Param-Eters distance r > 0, Privacy > 0 2: Calculation of posterior data (2001)."}, {"heading": "5 Experiments", "text": "After proposing a number of mechanisms for approximating exact Bayesian conclusions in the general framework of probabilistic graphical models, we now demonstrate our approaches using two simple, well-known PGMs: the (generative) naive Bayes classifier and the (discriminatory) linear regression. This section of derivatives in the appendix illustrates how our approaches are applied and supports our extensive theoretical findings through experimental observation. We focus on the trade-off between privacy and benefit (accuracy or MSE), which involves the (private) posterior via a predictive posterior distribution in both case studies. 4In particular, the baseline measure ensures that we have a proper density function: If u (D, Tennessee) is limited by M, then we have a normalization of constant Exp (D, TB))."}, {"heading": "5.1 Bayesian Discrete Na\u00efve Bayes", "text": "An illustrative example of our mechanisms is a Bayesian naive Bayes model based on Bernoulli class Y and attribute variables Xi, with full conjugated beta priors. This PGM specializes directly in the ongoing example 1. We synthesized data generated from a naive Bayes model, with 16 features and 1000 examples, from which we trained our mechanisms on only 50 examples, with uniform beta priors. We formed predictive laggards for Y | X, from which we make predictions for the remaining, invisible test data to evaluate classification accuracy. Results are reported in Figure 1, where the average performance is taken over 100 repetitions to account for randomness in traction / test distribution, and randomized mechanisms. The small size of these data poses a challenge in our environment, as privacy is harder to maintain than the smaller samples."}, {"heading": "5.2 Bayesian Linear Regression", "text": "Next, we examine a system of continuous r.v. \"s in Bayesian linear regression for which our posterior sampler is most suitable. We model the Y marking as i.i.d. Gaussian with known variance and mean a linear function of the characteristics and the linear weights equipped with multivariate Gaussian covariance before it with zero mean and spherical covariance. To fulfill assumption 1, we conservatively shorten the Gaussian predictions (see Appendix) and the sample from the resulting posterioral abbreviations; form a predictive posterior; then calculate the square error. To evaluate our approach, we used the U.S. Census data set from the Integrated Public Use Microdata Series Minnesota Population Center (2009) with 370k data sets and 14 demographic characteristics. To predict the year slump, we train 10% data with the rest of the less concise variance for the annex of the O showing more condense predisities."}, {"heading": "6 Conclusions", "text": "We have presented a number of mechanisms for differentiated-private conclusions in graphical models, within a Bayesian framework. The first two rear interference parameters to achieve privacy can be achieved either by interference in the original parameter domain or in the frequency domain by a Fourier transformation. Our third mechanism is based on the choice of a previous one, in combination with posterior scanning. We supplement our mechanisms for releasing the rear, with private MAP point counters. Everywhere we have demonstrated usefulness and privacy limits for our mechanisms, which in most cases depend on the graph structure of the Bayesian network: Of course conditional independence influences privacy. We support our new mechanisms and analyses with applications based on two concrete models, with experiments examining the trade in private utilities. This work was partially supported by the Swiss National Foundation SICRI2-154458."}, {"heading": "A Proofs for Laplace Mechanism on Posterior Updates", "text": "The probability of an event that none of the 2,000 is usually + \u03b2\u03b2i.d. Noise is added to each number z > 0 in absolute value: 1 \u2212 P [2mk = 1 {Ak}] 1 \u2212 2m k = 1 \u2212 2m exp (\u2212 z / 2 | I |). To ensure that this probability is not lower than 1 \u2212 p (2mk = 1 {Ak} 1 \u2212 ln (2mk = 1 P [Ai] = 1 \u2212 2m exp (\u2212 z / 2 | I |). To ensure that this probability is not lower than 1 \u2212 p (2mk = 1), we need z (2mk = 2 | I | ln) 0 \u2212 p (2m).A.2 Proof Theorem 1 \u00b7 Lemma A.1. (McDiarmid's inequality) Suppose, the random variableZ1, \u00b7 Zm \u00b7 Z are independent, f is an assignment of Z1, f \u00b2, f \u00b2, n\u00b2."}, {"heading": "B Posterior Sampling", "text": "B. 1 proof for Lemma 2d (x), pta (y), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), ta (i), ta (i), ta (i), ta (i), ta (i), ta (i), ta (i), ta (i), ta (i), ta (i), ta (i), ta (i), ta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i), pta (i, pta (i), pta (i), pta (i), pta (i, pta (i), pta (i), pta (i, pta (i), pta (i), pta (i, pta (i, i), pta (i (i), pta (i, pta (i), pta (i, i (i, i), i (i), i (i (i, i), pta (i, pta (i, i), pta (i (i), i, i (i), pta (i, i (i, i), pta (i, i (i, i), pta (i), pta (i, pta (i), pta (i, i, i (i), i (i (i, i), pta (i), pta (i, pta (i, pta"}, {"heading": "C Bayesian Na\u00efve Bayes", "text": "We check the derivation of the naive Bayes prediction for two cases applied in our experiments. C.1 Closed form Beta-Bernoulli If the r.v.'s are all Bernoulli's with beta conjugate predictions: P (Y = y | X = x). The closed form Beta-Bernoulli's are all Bernoulli's with beta predictions."}, {"heading": "D Bayesian Linear Regression", "text": "Let's make a series of observations D = (x1, y1), (xn, yn), (xn, yn) where xi = (1) i,., x (d) i, i) i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i"}], "references": [{"title": "Privacy, accuracy, and consistency too: A holistic solution to contingency table release", "author": ["B. Barak", "K. Chaudhuri", "C. Dwork", "S. Kale", "F. McSherry", "K. Talwar"], "venue": "PODS \u201907, 273\u2013282.", "citeRegEx": "Barak et al\\.,? 2007", "shortCiteRegEx": "Barak et al\\.", "year": 2007}, {"title": "Convergence rates for differentially private statistical estimation", "author": ["K. Chaudhuri", "D. Hsu"], "venue": "ICML\u201912.", "citeRegEx": "Chaudhuri and Hsu,? 2012", "shortCiteRegEx": "Chaudhuri and Hsu", "year": 2012}, {"title": "Privacy-preserving logistic regression", "author": ["K. Chaudhuri", "C. Monteleoni"], "venue": "NIPS\u201908, 289\u2013296.", "citeRegEx": "Chaudhuri and Monteleoni,? 2008", "shortCiteRegEx": "Chaudhuri and Monteleoni", "year": 2008}, {"title": "Differentially private empirical risk minimization", "author": ["K. Chaudhuri", "C. Monteleoni", "A.D. Sarwate"], "venue": "Journal of Machine Learning Research 12(Mar):1069\u20131109.", "citeRegEx": "Chaudhuri et al\\.,? 2011", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2011}, {"title": "Near-optimal differentially private principal components", "author": ["K. Chaudhuri", "A. Sarwate", "K. Sinha"], "venue": "NIPS\u201912, 989\u2013997.", "citeRegEx": "Chaudhuri et al\\.,? 2012", "shortCiteRegEx": "Chaudhuri et al\\.", "year": 2012}, {"title": "Robust and private Bayesian inference", "author": ["C. Dimitrakakis", "B. Nelson", "A. Mitrokotsa", "B. Rubinstein"], "venue": "ALT\u201914.", "citeRegEx": "Dimitrakakis et al\\.,? 2014", "shortCiteRegEx": "Dimitrakakis et al\\.", "year": 2014}, {"title": "Differential privacy in a Bayesian setting through posterior sampling", "author": ["C. Dimitrakakis", "B. Nelson", "Z. Zhang", "A. Mitrokotsa", "B. Rubinstein"], "venue": "Technical Report 1306.1066, arXiv.", "citeRegEx": "Dimitrakakis et al\\.,? 2015", "shortCiteRegEx": "Dimitrakakis et al\\.", "year": 2015}, {"title": "Local privacy and statistical minimax rates", "author": ["J.C. Duchi", "M.I. Jordan", "M.J. Wainwright"], "venue": "Technical Report 1302.3203, arXiv.", "citeRegEx": "Duchi et al\\.,? 2013", "shortCiteRegEx": "Duchi et al\\.", "year": 2013}, {"title": "Differential privacy for statistics: What we know and what we want to learn", "author": ["C. Dwork", "A. Smith"], "venue": "Journal of Privacy and Confidentiality 1(2):135\u2013154.", "citeRegEx": "Dwork and Smith,? 2009", "shortCiteRegEx": "Dwork and Smith", "year": 2009}, {"title": "Calibrating noise to sensitivity in private data analysis", "author": ["C. Dwork", "F. McSherry", "K. Nissim", "A. Smith"], "venue": "TCC\u201906, 265\u2013284.", "citeRegEx": "Dwork et al\\.,? 2006", "shortCiteRegEx": "Dwork et al\\.", "year": 2006}, {"title": "A practical differentially private random decision tree classifier", "author": ["G. Jagannathan", "K. Pillaipakkamnatt", "R. Wright"], "venue": "ICDM\u201909, 114\u2013121.", "citeRegEx": "Jagannathan et al\\.,? 2009", "shortCiteRegEx": "Jagannathan et al\\.", "year": 2009}, {"title": "La cryptographie militaire", "author": ["A. Kerckhoffs"], "venue": "Journal des sciences militaires IX:5\u2013 83 January; 161\u2013191, February.", "citeRegEx": "Kerckhoffs,? 1883", "shortCiteRegEx": "Kerckhoffs", "year": 1883}, {"title": "Mechanism design via differential privacy", "author": ["F. McSherry", "K. Talwar"], "venue": "FOCS\u201907, 94\u2013103.", "citeRegEx": "McSherry and Talwar,? 2007", "shortCiteRegEx": "McSherry and Talwar", "year": 2007}, {"title": "Differentially-private learning and information theory", "author": ["D. Mir"], "venue": "Proceedings of the 2012 Joint EDBT/ICDT Workshops, 206\u2013210. ACM.", "citeRegEx": "Mir,? 2012", "shortCiteRegEx": "Mir", "year": 2012}, {"title": "On the leakage of information in biometric authentication", "author": ["E. Pagnin", "C. Dimitrakakis", "A. Abidin", "A. Mitrokotsa"], "venue": "Indocrypt 2014.", "citeRegEx": "Pagnin et al\\.,? 2014", "shortCiteRegEx": "Pagnin et al\\.", "year": 2014}, {"title": "Learning in a large function space: Privacy-preserving mechanisms for SVM learning", "author": ["B.I.P. Rubinstein", "P.L. Bartlett", "L. Huang", "N. Taft"], "venue": "Journal of Privacy and Confidentiality", "citeRegEx": "Rubinstein et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rubinstein et al\\.", "year": 2012}, {"title": "Privacy for free: Posterior sampling and stochastic gradient monte carlo", "author": ["Y.-X. Wang", "S. Fienberg", "A. Smola"], "venue": "Blei, D., and Bach, F., eds., ICML\u201915, 2493\u2013 2502.", "citeRegEx": "Wang et al\\.,? 2015", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Probabilistic inference and differential privacy", "author": ["O. Williams", "F. McSherry"], "venue": "NIPS\u201910, 2451\u20132459.", "citeRegEx": "Williams and McSherry,? 2010", "shortCiteRegEx": "Williams and McSherry", "year": 2010}, {"title": "Bayesian inference under differential privacy", "author": ["Y. Xiao", "L. Xiong"], "venue": "arXiv preprint arXiv:1203.0617.", "citeRegEx": "Xiao and Xiong,? 2012", "shortCiteRegEx": "Xiao and Xiong", "year": 2012}, {"title": "Functional mechanism: regression analysis under differential privacy", "author": ["J. Zhang", "Z. Zhang", "X. Xiao", "Y. Yang", "M. Winslett"], "venue": "Proc. VLDB Endowment 5(11):1364\u20131375.", "citeRegEx": "Zhang et al\\.,? 2012", "shortCiteRegEx": "Zhang et al\\.", "year": 2012}, {"title": "Privbayes: Private data release via bayesian networks", "author": ["J. Zhang", "G. Cormode", "C.M. Procopiuc", "D. Srivastava", "X. Xiao"], "venue": "SIGMOD\u201914, 1423\u20131434.", "citeRegEx": "Zhang et al\\.,? 2014", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "The differential privacy of Bayesian inference", "author": ["S. Zheng"], "venue": "Bachelor\u2019s thesis, Harvard College.", "citeRegEx": "Zheng,? 2015", "shortCiteRegEx": "Zheng", "year": 2015}], "referenceMentions": [{"referenceID": 0, "context": "Such requirements of privacy are of growing interest in the learning Chaudhuri and Hsu (2012); Duchi, Jordan, and Wainwright (2013), theoretical computer science Dwork and Smith (2009); McSherry and Talwar (2007) and databases communities Barak et al.", "startOffset": 69, "endOffset": 94}, {"referenceID": 0, "context": "Such requirements of privacy are of growing interest in the learning Chaudhuri and Hsu (2012); Duchi, Jordan, and Wainwright (2013), theoretical computer science Dwork and Smith (2009); McSherry and Talwar (2007) and databases communities Barak et al.", "startOffset": 69, "endOffset": 132}, {"referenceID": 0, "context": "Such requirements of privacy are of growing interest in the learning Chaudhuri and Hsu (2012); Duchi, Jordan, and Wainwright (2013), theoretical computer science Dwork and Smith (2009); McSherry and Talwar (2007) and databases communities Barak et al.", "startOffset": 69, "endOffset": 185}, {"referenceID": 0, "context": "Such requirements of privacy are of growing interest in the learning Chaudhuri and Hsu (2012); Duchi, Jordan, and Wainwright (2013), theoretical computer science Dwork and Smith (2009); McSherry and Talwar (2007) and databases communities Barak et al.", "startOffset": 69, "endOffset": 213}, {"referenceID": 0, "context": "Such requirements of privacy are of growing interest in the learning Chaudhuri and Hsu (2012); Duchi, Jordan, and Wainwright (2013), theoretical computer science Dwork and Smith (2009); McSherry and Talwar (2007) and databases communities Barak et al. (2007); Zhang et al.", "startOffset": 239, "endOffset": 259}, {"referenceID": 0, "context": "Such requirements of privacy are of growing interest in the learning Chaudhuri and Hsu (2012); Duchi, Jordan, and Wainwright (2013), theoretical computer science Dwork and Smith (2009); McSherry and Talwar (2007) and databases communities Barak et al. (2007); Zhang et al. (2014) due to the impact on individual privacy by real-world data analytics.", "startOffset": 239, "endOffset": 280}, {"referenceID": 7, "context": "priors, that add Laplace noise Dwork et al. (2006) to posterior parameters (or their Fourier coefficients) to preserve privacy.", "startOffset": 31, "endOffset": 51}, {"referenceID": 5, "context": "In this case, we explore a mechanism Dimitrakakis et al. (2014) which samples from the posterior to answer queries\u2014no additional noise is injected.", "startOffset": 37, "endOffset": 64}, {"referenceID": 5, "context": "In this case, we explore a mechanism Dimitrakakis et al. (2014) which samples from the posterior to answer queries\u2014no additional noise is injected. We complement our study with a maximum a posteriori estimator that leverages the exponential mechanism McSherry and Talwar (2007). Our utility and privacy bounds connect privacy and graph/dependency structure, and are complemented by illustrative experiments with Bayesian na\u00efve Bayes and linear regression.", "startOffset": 37, "endOffset": 278}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al.", "startOffset": 130, "endOffset": 162}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al.", "startOffset": 130, "endOffset": 196}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al.", "startOffset": 130, "endOffset": 239}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al.", "startOffset": 130, "endOffset": 281}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009).", "startOffset": 130, "endOffset": 327}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy.", "startOffset": 130, "endOffset": 386}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy.", "startOffset": 130, "endOffset": 474}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy.", "startOffset": 130, "endOffset": 595}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy. Xiao and Xiong (2012) similarly used Bayesian credible intervals to increase the utility of query responses.", "startOffset": 130, "endOffset": 708}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy. Xiao and Xiong (2012) similarly used Bayesian credible intervals to increase the utility of query responses. Little attention has been paid to private inference in the Bayesian setting. We seek to adapt Bayesian inference to preserve differential privacy when releasing posteriors. Dimitrakakis et al. (2014; 2015) introduce a differentially-private mechanism for Bayesian inference based on posterior sampling\u2014a mechanism on which we build\u2014 while Zheng (2015) considers further refinements.", "startOffset": 130, "endOffset": 1147}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy. Xiao and Xiong (2012) similarly used Bayesian credible intervals to increase the utility of query responses. Little attention has been paid to private inference in the Bayesian setting. We seek to adapt Bayesian inference to preserve differential privacy when releasing posteriors. Dimitrakakis et al. (2014; 2015) introduce a differentially-private mechanism for Bayesian inference based on posterior sampling\u2014a mechanism on which we build\u2014 while Zheng (2015) considers further refinements. Wang, Fienberg, and Smola (2015) explore Monte Carlo approaches to Bayesian inference using the same mechanism, while Mir (2012) was the first to establish differential privacy of the Gibbs estimator McSherry and Talwar (2007) by minimising risk bounds.", "startOffset": 130, "endOffset": 1211}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy. Xiao and Xiong (2012) similarly used Bayesian credible intervals to increase the utility of query responses. Little attention has been paid to private inference in the Bayesian setting. We seek to adapt Bayesian inference to preserve differential privacy when releasing posteriors. Dimitrakakis et al. (2014; 2015) introduce a differentially-private mechanism for Bayesian inference based on posterior sampling\u2014a mechanism on which we build\u2014 while Zheng (2015) considers further refinements. Wang, Fienberg, and Smola (2015) explore Monte Carlo approaches to Bayesian inference using the same mechanism, while Mir (2012) was the first to establish differential privacy of the Gibbs estimator McSherry and Talwar (2007) by minimising risk bounds.", "startOffset": 130, "endOffset": 1307}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy. Xiao and Xiong (2012) similarly used Bayesian credible intervals to increase the utility of query responses. Little attention has been paid to private inference in the Bayesian setting. We seek to adapt Bayesian inference to preserve differential privacy when releasing posteriors. Dimitrakakis et al. (2014; 2015) introduce a differentially-private mechanism for Bayesian inference based on posterior sampling\u2014a mechanism on which we build\u2014 while Zheng (2015) considers further refinements. Wang, Fienberg, and Smola (2015) explore Monte Carlo approaches to Bayesian inference using the same mechanism, while Mir (2012) was the first to establish differential privacy of the Gibbs estimator McSherry and Talwar (2007) by minimising risk bounds.", "startOffset": 130, "endOffset": 1405}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy. Xiao and Xiong (2012) similarly used Bayesian credible intervals to increase the utility of query responses. Little attention has been paid to private inference in the Bayesian setting. We seek to adapt Bayesian inference to preserve differential privacy when releasing posteriors. Dimitrakakis et al. (2014; 2015) introduce a differentially-private mechanism for Bayesian inference based on posterior sampling\u2014a mechanism on which we build\u2014 while Zheng (2015) considers further refinements. Wang, Fienberg, and Smola (2015) explore Monte Carlo approaches to Bayesian inference using the same mechanism, while Mir (2012) was the first to establish differential privacy of the Gibbs estimator McSherry and Talwar (2007) by minimising risk bounds. This paper is the first to develop mechanisms for differential privacy under the general framework of Bayesian inference on multiple, dependent r.v.\u2019s. Our mechanisms consider graph structure and include a purely Bayesian approach that only places conditions on the prior. We show how the (stochastic) Lipschitz assumptions of Dimitrakakis et al. (2014) lift to graphs of r.", "startOffset": 130, "endOffset": 1786}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy. Xiao and Xiong (2012) similarly used Bayesian credible intervals to increase the utility of query responses. Little attention has been paid to private inference in the Bayesian setting. We seek to adapt Bayesian inference to preserve differential privacy when releasing posteriors. Dimitrakakis et al. (2014; 2015) introduce a differentially-private mechanism for Bayesian inference based on posterior sampling\u2014a mechanism on which we build\u2014 while Zheng (2015) considers further refinements. Wang, Fienberg, and Smola (2015) explore Monte Carlo approaches to Bayesian inference using the same mechanism, while Mir (2012) was the first to establish differential privacy of the Gibbs estimator McSherry and Talwar (2007) by minimising risk bounds. This paper is the first to develop mechanisms for differential privacy under the general framework of Bayesian inference on multiple, dependent r.v.\u2019s. Our mechanisms consider graph structure and include a purely Bayesian approach that only places conditions on the prior. We show how the (stochastic) Lipschitz assumptions of Dimitrakakis et al. (2014) lift to graphs of r.v.\u2019s, and bound KL-divergence when releasing an empirical posterior based on a modified prior. While Chaudhuri, Monteleoni, and Sarwate (2011) achieve privacy in regularised Empirical Risk Minimisation through objective randomisation, we do so through conditions on priors.", "startOffset": 130, "endOffset": 1949}, {"referenceID": 1, "context": "Many individual learning algorithms have been adapted to maintain differential privacy, including regularised logistic regression Chaudhuri and Monteleoni (2008), the SVM Rubinstein et al. (2012); Chaudhuri, Monteleoni, and Sarwate (2011), PCA Chaudhuri, Sarwate, and Sinha (2012), the functional mechanism Zhang et al. (2012) and trees Jagannathan, Pillaipakkamnatt, and Wright (2009). Probabilistic graphical models have been used to preserve privacy. Zhang et al. (2014) learned a graphical model from data, in order to generate surrogate data for release; while Williams and McSherry (2010) fit a model to the response of private mechanisms to clean up output and improve accuracy. Xiao and Xiong (2012) similarly used Bayesian credible intervals to increase the utility of query responses. Little attention has been paid to private inference in the Bayesian setting. We seek to adapt Bayesian inference to preserve differential privacy when releasing posteriors. Dimitrakakis et al. (2014; 2015) introduce a differentially-private mechanism for Bayesian inference based on posterior sampling\u2014a mechanism on which we build\u2014 while Zheng (2015) considers further refinements. Wang, Fienberg, and Smola (2015) explore Monte Carlo approaches to Bayesian inference using the same mechanism, while Mir (2012) was the first to establish differential privacy of the Gibbs estimator McSherry and Talwar (2007) by minimising risk bounds. This paper is the first to develop mechanisms for differential privacy under the general framework of Bayesian inference on multiple, dependent r.v.\u2019s. Our mechanisms consider graph structure and include a purely Bayesian approach that only places conditions on the prior. We show how the (stochastic) Lipschitz assumptions of Dimitrakakis et al. (2014) lift to graphs of r.v.\u2019s, and bound KL-divergence when releasing an empirical posterior based on a modified prior. While Chaudhuri, Monteleoni, and Sarwate (2011) achieve privacy in regularised Empirical Risk Minimisation through objective randomisation, we do so through conditions on priors. We develop an alternate approach that uses the additive-noise mechanism of Dwork et al. (2006) to perturb posterior parameterisations; and we apply techniques due to Barak et al.", "startOffset": 130, "endOffset": 2175}, {"referenceID": 0, "context": "(2006) to perturb posterior parameterisations; and we apply techniques due to Barak et al. (2007), who released marginal tables that maintain consistency in addition to privacy, by adding Laplace noise in the Fourier domain.", "startOffset": 78, "endOffset": 98}, {"referenceID": 5, "context": "Sampler 7 (2L, 0) if Lipschitz; or (0, \u221a M/2) stochastic Lipschitz expected utility functional wrt posterior O ( \u03b7 + \u221a ln(1/\u03b4)/N ) Dimitrakakis et al. (2015)", "startOffset": 131, "endOffset": 158}, {"referenceID": 14, "context": ", Pagnin et al. (2014).", "startOffset": 2, "endOffset": 23}, {"referenceID": 9, "context": "Dwork et al. (2006) characterise when such a mechanism is private: Definition 1 (Differential Privacy).", "startOffset": 0, "endOffset": 20}, {"referenceID": 9, "context": "One approach to differential privacy is to use additive Laplace noise (Dwork et al., 2006).", "startOffset": 70, "endOffset": 90}, {"referenceID": 9, "context": "To establish differential privacy of our mechanism, we must calculate a Lipschitz condition for the vector \u2206\u03c9 called global sensitivity Dwork et al. (2006). Lemma 1.", "startOffset": 136, "endOffset": 156}, {"referenceID": 9, "context": "To establish differential privacy of our mechanism, we must calculate a Lipschitz condition for the vector \u2206\u03c9 called global sensitivity Dwork et al. (2006). Lemma 1. For any neighbouring datasets D, D\u0303, the corresponding updates \u2206\u03c9,\u2206\u03c9\u0303 satisfy \u2016\u2206\u03c9 \u2212\u2206\u03c9\u0303\u20161 \u2264 2|I|. Proof. By changing the observations of one datum, at most two counts associated with each Xi can change by 1. Corollary 1. Algorithm 1 preserves -differential privacy. Proof. Based on Lemma 1, the intermediate \u2206\u03c9\u2032 preserve -differential privacy Dwork et al. (2006). Since truncation depends only on \u2206\u03c9\u2032, theZ preserves the same privacy.", "startOffset": 136, "endOffset": 528}, {"referenceID": 10, "context": "2 Laplace Mechanism in the Fourier Domain Algorithm 1 follows Kerckhoffs\u2019s Principle Kerckhoffs (1883) of \u201cno security through obscurity\u201d: differential privacy defends against a mechanism-aware attacker.", "startOffset": 62, "endOffset": 103}, {"referenceID": 0, "context": "To achieve differential privacy and stealth, we turn to Barak et al. (2007)\u2019s study of consistent marginal contingency table release.", "startOffset": 56, "endOffset": 76}, {"referenceID": 0, "context": "Due to this basis structure and linearity of the projection operator, any marginal contingency table must lie in the span of few projections of Fourier basis vectors Barak et al. (2007): Theorem 2.", "startOffset": 166, "endOffset": 186}, {"referenceID": 0, "context": "What is gained by passing to the Fourier domain, is that the perturbed marginal tables of Corollary 2 are consistent: anything in the span of projected Fourier basis vectors corresponds to some valid contingency table on I with (possibly negative) real-valued cells Barak et al. (2007).", "startOffset": 266, "endOffset": 286}, {"referenceID": 0, "context": "We adapt an idea of Barak et al. (2007) to increase the coefficient of Fourier basis vector f, affecting a small increment to each cell of the contingency table.", "startOffset": 20, "endOffset": 40}, {"referenceID": 5, "context": "For general Bayesian networks, B can release samples from the posterior Dimitrakakis et al. (2014) instead of perturbed samples of the posterior\u2019s parametrisation.", "startOffset": 72, "endOffset": 99}, {"referenceID": 12, "context": "2 MAP by the Exponential Mechanism As an application of the posterior sampler, we now turn to releasing MAP point estimates via the exponential mechanism McSherry and Talwar (2007), which samples responses from a likelihood exponential in some score function.", "startOffset": 154, "endOffset": 181}, {"referenceID": 10, "context": "Providing the base measure is non-trivial in general, but for discrete finite outcome spaces can be uniform McSherry and Talwar (2007). For our mechanism to be broadly applicable, we can safely take \u03bc(\u03b8) as \u03be (\u03b8).", "startOffset": 108, "endOffset": 135}, {"referenceID": 5, "context": "The sensitivity of the posterior score function corresponds to the computed \u2206 (Dimitrakakis et al., 2015, Theorem 6) under either Lipschitz assumptions. The result then follows from (McSherry and Talwar, 2007, Theorem 6). Utility for Algorithm 3 follows from McSherry and Talwar (2007), and states that the posterior likelihood of responses is likely to be close to that of the MAP.", "startOffset": 79, "endOffset": 286}, {"referenceID": 9, "context": "The small size of this data represents a challenge in our setting, since privacy is more difficult to preserve under smaller samples Dwork et al. (2006). As expected, privacy incurs a sacrifice to accuracy for all private mechanisms.", "startOffset": 133, "endOffset": 153}], "year": 2015, "abstractText": "We study how to communicate findings of Bayesian inference to third parties, while preserving the strong guarantee of differential privacy. Our main contributions are four different algorithms for private Bayesian inference on probabilistic graphical models. These include two mechanisms for adding noise to the Bayesian updates, either directly to the posterior parameters, or to their Fourier transform so as to preserve update consistency. We also utilise a recently introduced posterior sampling mechanism, for which we prove bounds for the specific but general case of discrete Bayesian networks; and we introduce a maximum-a-posteriori private mechanism. Our analysis includes utility and privacy bounds, with a novel focus on the influence of graph structure on privacy. Worked examples and experiments with Bayesian na\u00efve Bayes and Bayesian linear regression illustrate the application of our mechanisms.", "creator": "LaTeX with hyperref package"}}}