{"id": "1512.07422", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Dec-2015", "title": "Adaptive Algorithms for Online Convex Optimization with Long-term Constraints", "abstract": "We present an adaptive online gradient descent algorithm to solve online convex optimization problems with long-term constraints , which are constraints that need to be satisfied when accumulated over a finite number of rounds T , but can be violated in intermediate rounds. For some user-defined trade-off parameter $\\beta$ $\\in$ (0, 1), the proposed algorithm achieves cumulative regret bounds of O(T^max{$\\beta$,1--$\\beta$}) and O(T^(1--$\\beta$/2)) for the loss and the constraint violations respectively. Our results hold for convex losses and can handle arbitrary convex constraints without requiring knowledge of the number of rounds in advance. Our contributions improve over the best known cumulative regret bounds by Mahdavi, et al. (2012) that are respectively O(T^1/2) and O(T^3/4) for general convex domains, and respectively O(T^2/3) and O(T^2/3) when further restricting to polyhedral domains. We supplement the analysis with experiments validating the performance of our algorithm in practice.", "histories": [["v1", "Wed, 23 Dec 2015 10:32:09 GMT  (126kb,D)", "http://arxiv.org/abs/1512.07422v1", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG math.OC", "authors": ["rodolphe jenatton", "jim c huang", "c\u00e9dric archambeau"], "accepted": true, "id": "1512.07422"}, "pdf": {"name": "1512.07422.pdf", "metadata": {"source": "CRF", "title": "Adaptive Algorithms for Online Convex Optimization with Long-term Constraints", "authors": ["Rodolphe Jenatton", "Jim Huang", "C\u00e9dric Archambeau"], "emails": ["jenatton@amazon.com", "huangjim@amazon.com", "cedrica@amazon.com"], "sections": [{"heading": null, "text": "We present an adaptive online gradient descend algorithm to solve convex optimization problems with long-term limitations that must be met if they are accumulated over a limited number of rounds T but can be violated in intermediate rounds. In some user-defined target parameters \u03b2 (0, 1), the proposed algorithm achieves cumulative remorse limits of O (Tmax {\u03b2, 1 \u2212 \u03b2}) and O (T 1 \u2212 \u03b2 / 2) for loss or constraint violations, respectively. Our results apply to convex losses and can handle any convex limitations without having to know the number of rounds in advance. Our contributions improve on the most well-known cumulative remorse limits of Mahdavi et al. (2012), which are O (T 1 / 2) and O (T 3 / 4) for general convex domains and O (T 2 / 3) for further limiting the performance of our polydramas experiments."}, {"heading": "1 Introduction", "text": "In fact, most of us are able to play by the rules we have set ourselves in order to fulfil them."}, {"heading": "2 Online Convex Optimization with Long-term Constraints", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Preliminaries", "text": "Consider m convex functions gj: Rd 7 \u2192 R, which produce a convex constraint setX, {x-Rd: max j \u00b2 {1, \u00b7 \u00b7, m} gj (x) \u2264 0}. We assume that the quantity X is so limited that it is included in any Euclidean sphere B with a radius R > 0 (discussed further in Section 5): X B, {x-Rd: x-Rd \u00b2 2 \u2264 R). Together with the functions gj, we consider a sequence of convex functions ft: Rd 7 \u2192 R + such thatmax t \u00b2 {1, \u00b7, T} max x, x-Rd (x) \u2212 ft (x \u00b2 F for some F > 0.As is typically assumed in online learning [6], the functions gj and ft are to be considered as a continuous Lipschitz \u00b2. Generally, we do not assume that gj and ft differ."}, {"heading": "2.2 Problem Statement", "text": "Let {xt} Tt = 1 be the sequence of vectors played by the learner and {ft (xt)} Tt = 1 be the corresponding sequence of losses incurred. Our goal is to efficiently solve the following optimization problem online: min xT-B {fT (xT) +.. + min x2-B {f2 (x2) + minx1-B f1 (x1)} \u2212 minx-X-T \u2211 t = 1 ft (x) subject to the following long-term restriction: max j-T = 1 gj (xt) \u2264 0."}, {"heading": "3 Adaptive Online Algorithms based on a Saddle-point Formulation", "text": "Following [15], we will consider a saddle-point formulation of the optimization problem. For each \u03bb-R +, x-B, we define the following function: Lt (x, \u03bb), ft (x) + \u03bbg (x) \u2212 \u03b8t 2 \u03bb2where g (x), maxj \u0432 {1, \u00b7 \u00b7, m} gj (x) and {\u03b8t} Tt = 1 is a sequence of positive numbers to be specified later. The role of g is to combine the m constraints into a single function. Otherwise, it retains the same properties as the individual gj's (sub-differentiability, limited (sub-) gradients and limits. See sentence 6 in [15] or section 2.3 in [5] for a proof. In the saddle-point formulation (2), we will alternately see the properties of each gj's (sub-differentiability, limited (sub-) Tt distances and limits; see sentence 6 or 2.3 for a proof [2]."}, {"heading": "3.1 Main Results", "text": "We begin with the list of three sufficient conditions for the achievement of sublinear term limits for the proposed algorithm \u03b2 = \u03b2 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 = = = = = = = = = = = ="}, {"heading": "3.2 Analysis and Proofs", "text": "In order to analyze the above algorithm, we first present a series of lemmas, analogous to the one developed in [15], which we provide below for self-limitation, starting with the upper limit of variations of Lt in relation to their two arguments. This observation is at the origin of our improved regrets. Lemma 1 (upper limit of Lt (xt) \u2212 Lt (xt, \u03bb) \u2212 t is not only concave, as seen in [15], but strongly concave with parameters. This observation is at the origin of our improved regrets. Lemma 1 (upper limit of Lt (xt) \u2212 Lt (xt, \u03bb) \u2212 t))))) For Lt (x, \u03bb \u2212 t) is defined as a definition from above and not negatively."}, {"heading": "3.3 Towards No Violation of Constraints", "text": "Next, we show that our extension is also applicable to the more specific constellation developed in Section 3.2 of [\u03b2], where additional assumptions about the course of g \u03b2 cannot lead to any limitation. For the sake of self-limitation, let us briefly remember this. Suppose \u03b3 0 and r > 0 exist, so that the variations of g have lower limits than min x. (See Theorem 7 in [15]: The constellation of g = 0 x. (3) Denote X\u03b3, {x: Rd (x) + 0. It can then be shown that (see Theorem 7 in [15]): The constellation of T = 1 ft (x). \u2212 The constellation of Tt = 1 ft (x)."}, {"heading": "4 Experiments", "text": "We conducted two experiments to confirm the limits of regret obtained for our adaptive algorithms for OCO with long-term limitations and to compare them with the algorithms proposed in [15]. First, we examine the online estimation of double stochastic matrices where the convex domain of interest X is polyhedrical, but whose projection operator is difficult to calculate [12, 10]. Second, we consider the sparse online classification of binary matrices based on the elastic net penalty [27]. We refer to our adaptive online gradient descent (A-OGD) for convex (i.e. convex = 0) as convex A-OGD and for strongly convex ft (i.e. > 0) as strongly convex A-OGD, which enjoy the same regrets guarantees for O (T 2 / 3) for loss and restraint."}, {"heading": "4.1 Doubly-Stochastic Matrices", "text": "The double stochastic matrices appear in many machine learning and optimization problems, such as clustering applications [25] or learning permutations [12, 10]. In short, for a sequence of matrices {Yt} Tt = 1 in Rp \u00b7 p, we solve the following optimization problem online: min X-Rp \u00b7 p T = 1 2-Yt \u2212 X-2F (5), subject to the (linear) convex constraints X \u2265 0, X1 = 1 and X > 1 = 1. This problem can easily be mapped to the OCO setting by assuming that the sequence {Y} Tt = 1 is generated by random permutation matrices, which are known to represent the extreme points of the set of doublystochastic matrices x \u2265 0, x, x = 1 and X > 1. [4] We have d = pang (X), x x, x, x, x, x, x, x, x, x, x, x, x x x, x x x x x, x x, x x x, x x, x x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x x, x, x, x, x, x, x, x x, x, x, x x, x, x, x, x x, x, x, x x x x, x, x, x, x, x, x x, x, x, x, x, x, x, x, x, x, x, x, x"}, {"heading": "4.2 Sparse Online Binary Classification", "text": "Next, we will examine the application of the sparse online binary classification. Our goal is to minimize the log loss. (1) D's \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s"}, {"heading": "5 Discussion", "text": "In this section, we will discuss several generalizations. Broader families of step sizes. We have assumed that the updates of the primary variable x are driven by a projected gradient step controlled by a single step size \u03b7t. Following the ideas developed in [19, 9], we could analyze the repentance guarantees of our algorithm if there is a vector of step sizes \u03b7t given by a diagonal matrix diag. \u2212 For this purpose, we could, for example, introduce a smooth, 1-strongly convex functional solution with domain characteristics. In the light of (2), it is seductive to ask whether we can find a tightening function that will lead to lower cumulative repentance guarantees. \u2212 To this end, we could introduce a smooth, 1-strongly convex functional solution with domain characteristics. The saddle formulation of the storm is then given by another (x) to a punishment."}], "references": [{"title": "Fast algorithms for online stochastic convex programming", "author": ["Shipra Agrawal", "Nikhil R. Devanur"], "venue": "In SODA 2015 (ACM-SIAM Symposium on Discrete Algorithms). SIAM-Society for Industrial and Applied Mathematics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Online linear optimization and adaptive routing", "author": ["Baruch Awerbuch", "Robert Kleinberg"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2008}, {"title": "Parallel and Distributed Computation: Numerical Methods", "author": ["Dimitri P. Bertsekas", "John N. Tsitsiklis"], "venue": "Prentice-Hall, Inc.,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1989}, {"title": "Tres observaciones sobre el algebra lineal", "author": ["Garrett Birkhoff"], "venue": "Univ. Nac. Tucuma\u0301n Rev. Ser. A,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1946}, {"title": "Convex Analysis and Nonlinear Optimization: Theory and Examples", "author": ["J.M. Borwein", "A.S. Lewis"], "venue": "Springer", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2006}, {"title": "Prediction, learning, and games", "author": ["Nicolo Cesa-Bianchi", "G\u00e1bor Lugosi"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2006}, {"title": "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives", "author": ["Aaron Defazio", "Francis Bach", "Simon Lacoste- Julien"], "venue": "Technical report, preprint arXiv:1407.0202,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "CVXPY: A Python-embedded modeling language for convex optimization, version 0.2", "author": ["Steven Diamond", "Eric Chu", "Stephen Boyd"], "venue": "http://cvxpy.org/,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "Journal of Machine Learning Research, 12:2121\u20132159", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "d\u2019Aspremont. Convex relaxations for permutation problems", "author": ["Fajwel Fogel", "Rodolphe Jenatton", "Francis Bach", "Alexandre"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2013}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Elad Hazan", "Amit Agarwal", "Satyen Kale"], "venue": "Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "Learning permutations with exponential weights", "author": ["D.P. Helmbold", "M.K. Warmuth"], "venue": "Journal of Machine Learning Research, 10:1705\u20131736", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "A saddle point algorithm for networked online convex optimization", "author": ["Alec Koppel", "Felicia Y Jakubiec", "Alejandro Ribeiro"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Practical aspects of the moreau\u2013yosida regularization: Theoretical preliminaries", "author": ["Claude Lemar\u00e9chal", "Claudia Sagastiz\u00e1bal"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1997}, {"title": "Trading regret for efficiency: online convex optimization with long term constraints", "author": ["Mehrdad Mahdavi", "Rong Jin", "Tianbao Yang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Efficient constrained regret minimization", "author": ["Mehrdad Mahdavi", "Tianbao Yang", "Rong Jin"], "venue": "Technical report, preprint arXiv:1205.2265,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Stochastic gradient descent with only one projection", "author": ["Mehrdad Mahdavi", "Tianbao Yang", "Rong Jin", "Shenghuo Zhu", "Jinfeng Yi"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Online learning with constraints. In Learning Theory, pages 529\u2013543", "author": ["Shie Mannor", "John N Tsitsiklis"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2006}, {"title": "Adaptive bound optimization for online convex optimization", "author": ["H Brendan McMahan", "Matthew Streeter"], "venue": "In Proceedings of the annual conference on Computational Learning Theory (COLT),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Prox-method with rate of convergence o (1/t) for variational inequalities with lipschitz continuous monotone operators and smooth convex-concave saddle point problems", "author": ["Arkadi Nemirovski"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Numerical Optimization", "author": ["J. Nocedal", "S.J. Wright"], "venue": "Springer", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2006}, {"title": "Mind the duality gap: Logarithmic regret algorithms for online optimization", "author": ["Shai Shalev-Shwartz", "Sham M Kakade"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2009}, {"title": "Online alternating direction method", "author": ["Huahua Wang", "Arindam Banerjee"], "venue": "Technical report, preprint arXiv:1306.3721,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "The greedy miser: Learning under test-time budgets", "author": ["Zhixiang Xu", "Kilian Weinberger", "Olivier Chapelle"], "venue": "Technical report, preprint arXiv:1206.6451,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "Doubly stochastic normalization for spectral clustering", "author": ["Ron Zass", "Amnon Shashua"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2006}, {"title": "Online convex programming and generalized infinitesimal gradient ascent", "author": ["Martin Zinkevich"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2003}, {"title": "Regularization and variable selection via the elastic net", "author": ["H. Zou", "T. Hastie"], "venue": "Journal of the Royal Statistical Society. Series B, 67(2):301\u2013320", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2005}], "referenceMentions": [{"referenceID": 1, "context": "Online convex optimization (OCO) plays a key role in machine learning applications, such as adaptive routing in networks [2] and online display advertising [1].", "startOffset": 121, "endOffset": 124}, {"referenceID": 0, "context": "Online convex optimization (OCO) plays a key role in machine learning applications, such as adaptive routing in networks [2] and online display advertising [1].", "startOffset": 156, "endOffset": 159}, {"referenceID": 25, "context": "The problem was formalized in the seminal work of [26], which presents an online algorithm based on projected gradient descent [3] that guarantees a cumulative regret of O(T ) when the set X is convex and the loss functions are Lipschitz-continuous over X .", "startOffset": 50, "endOffset": 54}, {"referenceID": 2, "context": "The problem was formalized in the seminal work of [26], which presents an online algorithm based on projected gradient descent [3] that guarantees a cumulative regret of O(T ) when the set X is convex and the loss functions are Lipschitz-continuous over X .", "startOffset": 127, "endOffset": 130}, {"referenceID": 10, "context": "In [11] and [22], algorithms with logarithmic regret bounds were proposed for strongly convex loss functions.", "startOffset": 3, "endOffset": 7}, {"referenceID": 21, "context": "In [11] and [22], algorithms with logarithmic regret bounds were proposed for strongly convex loss functions.", "startOffset": 12, "endOffset": 16}, {"referenceID": 17, "context": "Another example is from wireless communications [18], where xt is a vector of power allocations across multiple devices, and the learner must satisfy average power consumption constraints per device.", "startOffset": 48, "endOffset": 52}, {"referenceID": 14, "context": "This class of problems was studied previously in [15, 16].", "startOffset": 49, "endOffset": 57}, {"referenceID": 15, "context": "This class of problems was studied previously in [15, 16].", "startOffset": 49, "endOffset": 57}, {"referenceID": 15, "context": "In particular, [16] considered online exponentially-weighted average in the case where the loss and constraints are linear, while [15] presented online algorithms based on projected subgradients and the mirror prox method [20].", "startOffset": 15, "endOffset": 19}, {"referenceID": 14, "context": "In particular, [16] considered online exponentially-weighted average in the case where the loss and constraints are linear, while [15] presented online algorithms based on projected subgradients and the mirror prox method [20].", "startOffset": 130, "endOffset": 134}, {"referenceID": 19, "context": "In particular, [16] considered online exponentially-weighted average in the case where the loss and constraints are linear, while [15] presented online algorithms based on projected subgradients and the mirror prox method [20].", "startOffset": 222, "endOffset": 226}, {"referenceID": 14, "context": "The analysis of [15] assumes the number of rounds is known ahead of time, which enables the authors to set the various constants in the algorithm that lead to the desired regret bounds.", "startOffset": 16, "endOffset": 20}, {"referenceID": 16, "context": "This is closely related to recent work in stochastic optimization that aims to minimize the number of expensive projection steps [17].", "startOffset": 129, "endOffset": 133}, {"referenceID": 22, "context": "The guarantees sought in our analysis have also similarities with the results obtained in the context of the online alternating direction method [23], where regret bounds are provided for the violation of equality constraints.", "startOffset": 145, "endOffset": 149}, {"referenceID": 14, "context": "Contributions: Building on the work of [15], we propose an algorithm based on a saddle-point formulation of the OCO problem with long-term constraints, which is adaptive (i.", "startOffset": 39, "endOffset": 43}, {"referenceID": 14, "context": "Also, the algorithm we derive allows us to interpolate between the regret bounds of O(T ) and O(T ) from [15] and the above bound of O(T ), depending on how we wish to trade off between the cumulative regret associated to the loss and the long-term constraints.", "startOffset": 105, "endOffset": 109}, {"referenceID": 14, "context": "In addition to our analysis of regret bounds, we empirically validate our algorithm by comparing it to the methods of [15] on a) the online estimation of doubly stochastic matrices and b) the online learning of sparse logistic regression based on the elastic net penalty [27].", "startOffset": 118, "endOffset": 122}, {"referenceID": 26, "context": "In addition to our analysis of regret bounds, we empirically validate our algorithm by comparing it to the methods of [15] on a) the online estimation of doubly stochastic matrices and b) the online learning of sparse logistic regression based on the elastic net penalty [27].", "startOffset": 271, "endOffset": 275}, {"referenceID": 5, "context": "As is typically assumed in online learning [6], the functions gj and ft shall be taken to be Lipschitz continuous.", "startOffset": 43, "endOffset": 46}, {"referenceID": 14, "context": "Finally, we note that the set of assumptions enumerated in this section are equivalent to the ones in [15].", "startOffset": 102, "endOffset": 106}, {"referenceID": 14, "context": "Following [15], we consider a saddle-point formulation of the optimization problem.", "startOffset": 10, "endOffset": 14}, {"referenceID": 14, "context": "It otherwise preserves the same properties as those of individual gj \u2019s (sub-differentiability, bounded (sub-)gradients and bounded values; see Proposition 6 in [15] or Section 2.", "startOffset": 161, "endOffset": 165}, {"referenceID": 4, "context": "3 in [5] for a proof).", "startOffset": 5, "endOffset": 8}, {"referenceID": 20, "context": "1 in [21]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "We note at this point that in contrast to our method, [15] make use of a single \u03b8 that is constant in all rounds.", "startOffset": 54, "endOffset": 58}, {"referenceID": 14, "context": "\u2022 Initialize x1 = 0 and \u03bb1 = 0 More precisely, in [15], \u03b8 is equal to the product of a constant step size times a constant scaling factor.", "startOffset": 50, "endOffset": 54}, {"referenceID": 14, "context": "The algorithm is in the same vein as the ones proposed in [15, 13], but it is adaptive.", "startOffset": 58, "endOffset": 66}, {"referenceID": 12, "context": "The algorithm is in the same vein as the ones proposed in [15, 13], but it is adaptive.", "startOffset": 58, "endOffset": 66}, {"referenceID": 14, "context": "which matches the mirror prox guarantees of [15] while being valid for general convex constraint sets X as opposed to just polyhedral constraint sets.", "startOffset": 44, "endOffset": 48}, {"referenceID": 14, "context": "1 in [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "The analysis is analogous to that developed in [15], which we provide below for selfcontainedness.", "startOffset": 47, "endOffset": 51}, {"referenceID": 14, "context": "In particular, the following lemma takes advantage of the fact that the partial function \u03bb 7\u2192 Lt(xt, \u03bb) is not only concave as considered in [15], but strongly concave with parameter \u03b8t.", "startOffset": 141, "endOffset": 145}, {"referenceID": 14, "context": "2 from [15], where additional assumptions on the gradient of g can translate into no constraint violations.", "startOffset": 7, "endOffset": 11}, {"referenceID": 14, "context": "It can then be shown that (see Theorem 7 in [15]): \u2223\u2223\u2223\u2211Tt=1 ft(x?)\u2212\u2211Tt=1 ft(x\u03b3)\u2223\u2223\u2223 \u2264 Gr T\u03b3, (4)", "startOffset": 44, "endOffset": 48}, {"referenceID": 16, "context": "Examples where (3) holds include the positive semi-definite cone, as described in Section 4 of [17].", "startOffset": 95, "endOffset": 99}, {"referenceID": 14, "context": "This result extends Theorem 8 and Corollary 13 from [15] in that it holds for general convex domains X (as opposed to only polyhedral ones).", "startOffset": 52, "endOffset": 56}, {"referenceID": 14, "context": "We ran two sets of experiments to validate the regret bounds obtained for our adaptive algorithms for OCO with long-term constraints and compare to the algorithms proposed in [15].", "startOffset": 175, "endOffset": 179}, {"referenceID": 11, "context": "First, we examine the online estimation of doubly-stochastic matrices where the convex domain of interest X is polyhedral but whose projection operator is difficult to compute [12, 10].", "startOffset": 176, "endOffset": 184}, {"referenceID": 9, "context": "First, we examine the online estimation of doubly-stochastic matrices where the convex domain of interest X is polyhedral but whose projection operator is difficult to compute [12, 10].", "startOffset": 176, "endOffset": 184}, {"referenceID": 26, "context": "Second, we consider sparse online binary classification based on the elastic net penalty [27].", "startOffset": 89, "endOffset": 93}, {"referenceID": 14, "context": "The method of [15] that handles general convex domains X will be referred to as Convex OGD, while the mirror prox method analyzed in [15], which is only applicable to polyhedral domains, will be denoted by Convex mirror prox.", "startOffset": 14, "endOffset": 18}, {"referenceID": 14, "context": "The method of [15] that handles general convex domains X will be referred to as Convex OGD, while the mirror prox method analyzed in [15], which is only applicable to polyhedral domains, will be denoted by Convex mirror prox.", "startOffset": 133, "endOffset": 137}, {"referenceID": 14, "context": "The parameters of Convex OGD and Convex mirror prox are instantiated according to [15].", "startOffset": 82, "endOffset": 86}, {"referenceID": 24, "context": "1 Doubly-Stochastic Matrices Doubly-stochastic matrices appear in many machine learning and optimization problems, such as clustering applications [25] or learning permutations [12, 10].", "startOffset": 147, "endOffset": 151}, {"referenceID": 11, "context": "1 Doubly-Stochastic Matrices Doubly-stochastic matrices appear in many machine learning and optimization problems, such as clustering applications [25] or learning permutations [12, 10].", "startOffset": 177, "endOffset": 185}, {"referenceID": 9, "context": "1 Doubly-Stochastic Matrices Doubly-stochastic matrices appear in many machine learning and optimization problems, such as clustering applications [25] or learning permutations [12, 10].", "startOffset": 177, "endOffset": 185}, {"referenceID": 3, "context": "This problem can easily be mapped to OCO setting by assuming that the sequence {Y}t=1 is generated by random permutation matrices which are known to constitute the extreme points of the set of doublystochastic matrices [4].", "startOffset": 219, "endOffset": 222}, {"referenceID": 7, "context": "The offline solutions of (5) required for various t \u2208 {1, \u00b7 \u00b7 \u00b7 , T} to compute the regret are obtained using CVXPY [8].", "startOffset": 116, "endOffset": 119}, {"referenceID": 14, "context": "We surmise that this may be due to the fact that the guarantees of Convex mirror prox proved in [15] only hold for very large T .", "startOffset": 96, "endOffset": 100}, {"referenceID": 14, "context": "Theorem 12 from [15] requires T \u2265 164(m+1), which translates into T > 10 in our setting.", "startOffset": 16, "endOffset": 20}, {"referenceID": 23, "context": ", in the context of learning predictors with low-latency [24].", "startOffset": 57, "endOffset": 61}, {"referenceID": 6, "context": "Moreover, and in order to best display cumulative regret, we compute offline solutions of (6) for various t \u2208 {1, \u00b7 \u00b7 \u00b7 , T} thanks to an implementation of [7].", "startOffset": 156, "endOffset": 159}, {"referenceID": 18, "context": "Following the ideas developed in [19, 9], we could analyze the regret guarantees of our algorithm when there is a vector of step sizes \u03b7t that is given by a diagonal matrix Diag(\u03b7t) \u2208 Rd\u00d7d, updating adaptively and separately each coordinate of x.", "startOffset": 33, "endOffset": 40}, {"referenceID": 8, "context": "Following the ideas developed in [19, 9], we could analyze the regret guarantees of our algorithm when there is a vector of step sizes \u03b7t that is given by a diagonal matrix Diag(\u03b7t) \u2208 Rd\u00d7d, updating adaptively and separately each coordinate of x.", "startOffset": 33, "endOffset": 40}, {"referenceID": 13, "context": "Moreover, the maximization with respect to \u03bb in the last step of Lemma 4 introduces the Moreau envelope [14] of the Fenchel conjugate of \u03c6, namely", "startOffset": 104, "endOffset": 108}], "year": 2015, "abstractText": "We present an adaptive online gradient descent algorithm to solve online convex optimization problems with long-term constraints, which are constraints that need to be satisfied when accumulated over a finite number of rounds T , but can be violated in intermediate rounds. For some user-defined trade-off parameter \u03b2 \u2208 (0, 1), the proposed algorithm achieves cumulative regret bounds ofO(Tmax{\u03b2,1\u2212\u03b2}) andO(T 1\u2212\u03b2/2) for the loss and the constraint violations respectively. Our results hold for convex losses and can handle arbitrary convex constraints without requiring knowledge of the number of rounds in advance. Our contributions improve over the best known cumulative regret bounds by Mahdavi, et al. (2012) that are respectively O(T ) and O(T ) for general convex domains, and respectively O(T ) andO(T ) when further restricting to polyhedral domains. We supplement the analysis with experiments validating the performance of our algorithm in practice.", "creator": "LaTeX with hyperref package"}}}