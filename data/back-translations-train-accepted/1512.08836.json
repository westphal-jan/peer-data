{"id": "1512.08836", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Dec-2015", "title": "Learning to Filter with Predictive State Inference Machines", "abstract": "Latent state space models are one of the most fundamental and widely used tools for modeling dynamical systems. Traditional Maximum Likelihood Estimation (MLE) based approaches aim to maximize the likelihood objective, which is non-convex due to latent states. While non-convex optimization methods like EM can learn models that locally optimize the likelihood objective, using the locally optimal model for an inference task such as Bayesian filtering usually does not have performance guarantees. In this work, we propose a method that considers the inference procedure on the dynamical system as a composition of predictors. Instead of optimizing a given parametrization of latent states, we learn predictors for inference in predictive belief space, where we can use sufficient features of observations for supervision of our learning algorithm. We further show that our algorithm, the Predictive State Inference Machine, has theoretical performance guarantees on the inference task. Empirical verification across several of dynamical system benchmarks ranging from a simulated helicopter to recorded telemetry traces from a robot showcase the abilities of training Inference Machines.", "histories": [["v1", "Wed, 30 Dec 2015 03:17:00 GMT  (412kb,D)", "https://arxiv.org/abs/1512.08836v1", null], ["v2", "Mon, 30 May 2016 17:20:32 GMT  (1065kb,D)", "http://arxiv.org/abs/1512.08836v2", "ICML 2016"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["wen sun", "arun venkatraman", "byron boots", "j andrew bagnell"], "accepted": true, "id": "1512.08836"}, "pdf": {"name": "1512.08836.pdf", "metadata": {"source": "META", "title": "Learning to Filter with Predictive State Inference Machines", "authors": ["Wen Sun", "Arun Venkatraman", "Byron Boots", "J. Andrew Bagnell"], "emails": ["WENSUN@CS.CMU.EDU", "ARUNVENK@CS.CMU.EDU", "BBOOTS@CC.GATECH.EDU", "DBAGNELL@RI.CMU.EDU"], "sections": [{"heading": "1. Introduction", "text": "This year, as never before in the history of a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which it is a country, in which is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which is a country, in which is a country, in which is a country"}, {"heading": "2. Related Work", "text": "In addition to the MLE-based approaches and the spectral learning approaches mentioned in Section 1, there are several monitored learning approaches related to our work. Data as Demonstrator (DaD) (Venkatraman et al., 2015) applies the idea of the Inference Machine to fully observable Markov chains and directly optimizes predictive accuracy in open loops. In contrast, we aim to design an unattended learning algorithm for latent state models (e.g. HMMs and LDSs) to improve the accuracy of predictive and Bayean filtering. It is unclear how to apply DaD to learning a Bayean filter. Author-regressive models (Wei, 1994) to fully observable Markov chains (AR-k) use the most recent k observations to predict the next observation. The AR model is not suitable for latent state models, as beliefs are more conditional on the entire history."}, {"heading": "3. Preliminaries", "text": "We consider uncontrolled discrete time-invariant dynamic systems. At any time, the latent state of the dynamic system, st-Rm, stochastically generates an observation, xt-Rn, from an observation model P (xt-st). The stochastic transition model P (st + 1 | st) calculates the predictive distribution of states at t + 1 taking into account the state at the time. We define the belief in a latent state st + 1 as the distribution of st + 1 taking into account all previous observations up to the time step t: {x1,..., xt}, which we call ht."}, {"heading": "3.1. Belief Propagation in Latent State Space Models", "text": "Let us define bt as faith P (st | ht \u2212 1). If the transition model P (st + 1 | st) and the observation model P (st | st) are known, faith bt can be calculated by a special case of message transmission called forward faith propagation: bt + 1 = 1P (st | ht \u2212 1) st btP (st + 1 | st) P (xt | st) dst. (1) The above equation essentially represents faith and the present observation xt is based on the next faith. (1) Consider the following linear dynamic system: st + 1 = branch + s, s (0, Q), xt = Cst + x, x N (0, R), (2) where A Rm \u00d7 m is the transition matrix, C Rn \u00d7 m is the observation matrix, and the observation matrix is the observation matrix, and Q Rm \u00d7 m \u00b7 n are noise variants."}, {"heading": "3.2. Predictive State Representations", "text": "Recently, we assume that predictable state representations and observable operator models have been used to filter, predict, and simulate time series data (Jaeger, 2000; Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Hefny et al., 2015) These models provide a compact and complete description of a dynamic system that is easier to learn than latent variable models by presenting the state as a set of observable variables like future observations. In this paper, we follow a predictive state representation (PSR) and define the state as the distribution of ft = [x T t, x T + k \u2212 1]."}, {"heading": "4. Predictive State Inference Machines", "text": "The original framework of the Inference Machine reduces the problem of learning graphical models to solving a series of classification or regression problems where the learned classifiers mimic procedures that generate boundary distributions for the nodes of the model (Langford et al., 2009; Ross et al., 2011b; Bagnell et al., 2010). However, inference machines cannot be applied to learning latent state space models (unattended learning) because we do not have access to hidden state information.We solve this problem with predictive states. By using an observable representation of the state, observations can be used in the training data for monitoring in the inference machine. More formally, instead of tracking the hidden state st, we focus on the corresponding prediction state E [\u03c6 (ft) | ht \u2212 1]. Assuming that the given prediction state E [ceptive state (state) is calculated (F) | state, we can show the probability \u2212 1 (P) that the prediction state E (F) can be calculated."}, {"heading": "4.1. Predictive State Propagation", "text": "We now describe the corresponding propagations of faith to update the predictive state from E [\u03c6 (ft) | ht \u2212 1] to E [\u03c6 (ft + 1) | ht]. Since we assume that the mapping of P (st | ht \u2212 1) to P (ft | ht \u2212 1) and the mapping of P (ft | ht \u2212 1) to E [\u03c6 | ht \u2212 1) are both bijective, there must be a bijective map q and its inverse q \u2212 1 so that q (P | ht \u2212 1) and the mapping of P (t \u2212 1) = E [\u03c6) \u2212 ht \u2212 1) and q \u2212 1 (E)."}, {"heading": "4.2. Learning Non-stationary Filters with Predictive States", "text": "It is not as if there is a loss, as in an example Bregman divergence causes there to be other optimizations that are optimized by the conditional expectation (Banerjee et al., 2005). We can d (mt, ft) s (mt, ft) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t (t) t (t) t (t) t (t (t) t (t) t (t) t (t) t (t (t) t (t) t (t) t (t) t (t) t (t (t) t (t (t) t) t (t) t (t (t) t (t) t) t (t (t) t (t) t (t) t (t (t) t) t (t (t (t) t (t) t) t (t (t) t (t (t) t (t) t (t) t (t) t (t (t) t (t) t) t (t (t (t) t (t (t) t) t (t (t) t (t) t (t (t (t) t (t) t) t (t (t) t) t (t (t (t) t (t"}, {"heading": "4.3. Learning Stationary Filters with Predictive States", "text": "The optimization framework for the search for a good localized filter F is defined as: min F & # 252; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222; f & # 8222;."}, {"heading": "5. Experiments", "text": "We evaluate the PSIM based on a variety of dynamic system benchmarks. We use two feature functions: \u03c61 (ft) = [xt,..., xt + k \u2212 1], which stack the k-future observations with each other (therefore, message m can be considered a prediction of future k-observations (x-t,.., x-t + k \u2212 1), and \u03c62 (ft) = [xt,..., xt + k \u2212 1, xt2,..., x2t + k \u2212 1], which includes second moments (hence m represents a Gaussian distribution approximating the true distribution of future observations). To measure how good the compressed predictive states are, we extract x-i from m-t and evaluate the square distance between the predicted observation x-i and the corresponding true observation xi. We implement PSIM with DAgger using two underlying regression methods: composite quadression (PSIM-IR regression) and regression (PSIM-IAR observation)."}, {"heading": "5.1. Synthetic Linear Dynamical System", "text": "First, we tested our algorithms on a synthetic linear dynamic system (eq. 2) using a 2-dimensional observation method x. We designed the system to be exactly 2-observable.Since the observation sequences are collected from the LDS linear stationary Kalman filter (Boots, 2012; Hefny et al., 2015), we set k = 2 and use \u03c61 (ft) = [xt, xt + 1]. Note that the 4-dimensional prediction state E [\u03c61 (ft) | ht] represents the exact conditional distribution of the observations (xt, xt + 1) and therefore corresponds to P (st | ht \u2212 1) (see the detailed case study for LDS in the appendix).With the linear ridge regression, we test PSIM with the prediction training, PSIM with DAgger."}, {"heading": "5.2. Real Dynamical Systems", "text": "In fact, it is such that the greater part of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to move, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to"}, {"heading": "6. Conclusion", "text": "We have introduced PREDICTIVE STATE INFERENCE MACHINES, a novel approach to learn directly to filter with latent state room models. PSIM leverages ideas from PSRs and reduces the unattended learning of latent state room models to a supervised learning environment, guaranteeing filtering performance for general nonlinear models in both realisable and agnostic environments."}, {"heading": "Acknowledgements", "text": "This material is based on work partially supported by: DARPA ALIAS Contract No HR0011-15-C-0027 and National Science Foundation Graduate Research Fellowship No DGE-1252522. Authors also thank Geoff Gordon for valuable discussions."}, {"heading": "A. Proof of Theorem. 4.1", "text": "Let us assume that in the time step t all calculation steps m \u00b2 1 are exactly the same as m \u00b2 1, that is, there are no observations, conditioning on nothing. Let us now assume that minimizing the empirical risk via Dt is equivalent to minimizing the true risk. [d (F (m\u03c4t, x\u03c4t), f\u03c4t + 1). Since we use sufficient characteristics for the distribution P (ft | ht \u2212 1) and we assume that the system is k-observable, there is an underlying deterministic map, which we call F \u00b2 t here, that the maps are not represented as F \u00b2 t, but as F \u00b2 t."}, {"heading": "B. Proof of Theorem. 4.2", "text": "Assuming an infinite number of training paths, we can represent the target as follows: E\u03c4 \u0445 D 1T T \u2211 t = 1 d (Ft (m, p, p, p, p) = 1 T \u2211 t = 1 E (z, f) \u03c9t [d (Ft (z), f)]] (16) Note that each Ft is trained by minimizing risk: Ft = arg min F \u0445 FE (z, f) \u03c9t [d (F (z), f)]]. (17) Since we define t = minF \u0445 F E (z, f) \u03c9t [d (F (z), f)], we have: E\u03c4 \u0445 D 1T \u0445 t = 1 d (Ft (m, x, p) t (f, p, t + 1 T) = 1 T t (fining) = 1 T (z, f)."}, {"heading": "C. Proof of Theorem. 4.3", "text": "To derive a generalisation from this, we have to assume that in relation to the first Term F (z) -2 and the second Term F (z) -2 we distance ourselves further from M (s) -2 in T-2-2-3-3-3-3-3-3-3-3-3-3-3-3-3-3-3-3-3-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-4-Term F-4-4-4-4-4-4-4-4-4-4-4-4-Term F-4-4-4-4-4-4-4-Term F-4-4-4-4-Term F-4-4-Term F-4-Term F-4-Term F-4-Term F-4-Term F-4-Term F-4-Term F-Term F-Term F-Term F-Term F-Term F-"}, {"heading": "D. Case Study: Stationary Kalman Filter", "text": "To illustrate it better, we must consider a special dynamic system in this range. (D) We must concentrate on the filters (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n n (D) n n (D) n n n n (D) n n n n n (D) n n n n n n n (D) n n n n (D) n n n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n (D) n n (D) n n n n (D) n n n n (D) n n n n n n n n (D) n n n n (D) n n n) n (D) n (D) n (D) n (D) n) n (D) n (D) n) n (D) n (D) n (D) n (D) n (D) n (D) n) n n (D) n) n (D) n) n (D) n (D) n (D) n n (D) n (D) n n (D) n n n n n n (D) n (D) n n n n n (D (D) n n n n n n n (D) n n n n (D (D n n n n n (D) n n n (D) n n n n n) n n n (D) n n n (D) n n n n) n n n n (D) n n n n (D) n n n n (D) n (D) n n (D) n) n n n n) n n n n n) n (D) n (D) n) n n) n n n n n n n n) n (D) n) n"}, {"heading": "E. Additional Experiments", "text": "iSe rf\u00fc ide rf\u00fc ide rtef\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rteeei the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the"}], "references": [{"title": "Learning deep inference machines", "author": ["Bagnell", "J Andrew", "Grubb", "Alex", "Munoz", "Daniel", "Ross", "Stephane"], "venue": "The Learning Workshop,", "citeRegEx": "Bagnell et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bagnell et al\\.", "year": 2010}, {"title": "On the optimality of conditional expectation as a bregman predictor", "author": ["Banerjee", "Arindam", "Guo", "Xin", "Wang", "Hui"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Banerjee et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Banerjee et al\\.", "year": 2005}, {"title": "Theano: new features and speed improvements", "author": ["Bastien", "Fr\u00e9d\u00e9ric", "Lamblin", "Pascal", "Pascanu", "Razvan", "Bergstra", "James", "Goodfellow", "Ian J", "Bergeron", "Arnaud", "Bouchard", "Nicolas", "Bengio", "Yoshua"], "venue": "Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop,", "citeRegEx": "Bastien et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bastien et al\\.", "year": 2012}, {"title": "Spectral Approaches to Learning Predictive Representations", "author": ["Boots", "Byron"], "venue": "PhD thesis,", "citeRegEx": "Boots and Byron.,? \\Q2012\\E", "shortCiteRegEx": "Boots and Byron.", "year": 2012}, {"title": "Predictive state temporal difference learning", "author": ["Boots", "Byron", "Gordon", "Geoffrey J"], "venue": "In NIPS,", "citeRegEx": "Boots et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boots et al\\.", "year": 2011}, {"title": "Closing the learning-planning loop with predictive state representations", "author": ["Boots", "Byron", "Siddiqi", "Sajid M", "Gordon", "Geoffrey J"], "venue": "The International Journal of Robotics Research,", "citeRegEx": "Boots et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Boots et al\\.", "year": 2011}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["Cesa-Bianchi", "Nicolo", "Conconi", "Alex", "Gentile", "Claudio"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2004}, {"title": "Learning for control from multiple demonstrations", "author": ["Coates", "Adam", "Abbeel", "Pieter", "Ng", "Andrew Y"], "venue": "In ICML,", "citeRegEx": "Coates et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Coates et al\\.", "year": 2008}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi", "John", "Hazan", "Elad", "Singer", "Yoram"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["Hazan", "Elad", "Agarwal", "Amit", "Kale", "Satyen"], "venue": "Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2007}, {"title": "Supervised learning for dynamical system learning", "author": ["Hefny", "Ahmed", "Downey", "Carlton", "Gordon", "Geoffrey J"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Hefny et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hefny et al\\.", "year": 2015}, {"title": "A spectral algorithm for learning hidden markov models", "author": ["Hsu", "Daniel", "M. Kakade", "Sham", "Zhang", "Tong"], "venue": "In COLT,", "citeRegEx": "Hsu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hsu et al\\.", "year": 2009}, {"title": "Observable operator models for discrete stochastic time series", "author": ["Jaeger", "Herbert"], "venue": "Neural Computation,", "citeRegEx": "Jaeger and Herbert.,? \\Q2000\\E", "shortCiteRegEx": "Jaeger and Herbert.", "year": 2000}, {"title": "Low-rank spectral learning", "author": ["Kulesza", "Alex", "Rao", "N Raj", "Singh", "Satinder"], "venue": "In Proceedings of the 17th Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Kulesza et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kulesza et al\\.", "year": 2014}, {"title": "Learning nonlinear dynamic models", "author": ["Langford", "John", "Salakhutdinov", "Ruslan", "Zhang", "Tong"], "venue": "In Proceedings of the 26th International Conference on Machine Learning", "citeRegEx": "Langford et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Langford et al\\.", "year": 2009}, {"title": "Deeply learning the messages in message passing inference", "author": ["Lin", "Guosheng", "Shen", "Chunhua", "Reid", "Ian", "van den Hengel", "Anton"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Predictive representations of state", "author": ["Littman", "Michael L", "Sutton", "Richard S", "Singh", "Satinder"], "venue": "In NIPS,", "citeRegEx": "Littman et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Littman et al\\.", "year": 2001}, {"title": "Foundations of machine learning", "author": ["Mohri", "Mehryar", "Rostamizadeh", "Afshin", "Talwalkar", "Ameet"], "venue": "MIT press,", "citeRegEx": "Mohri et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mohri et al\\.", "year": 2012}, {"title": "Random features for largescale kernel machines", "author": ["Rahimi", "Ali", "Recht", "Benjamin"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Rahimi et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Rahimi et al\\.", "year": 2007}, {"title": "Pose machines: Articulated pose estimation via inference machines", "author": ["Ramakrishna", "Varun", "Munoz", "Daniel", "Hebert", "Martial", "Bagnell", "James Andrew", "Sheikh", "Yaser"], "venue": "In Computer Vision\u2013 ECCV", "citeRegEx": "Ramakrishna et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ramakrishna et al\\.", "year": 2014}, {"title": "Efficient reductions for imitation learning", "author": ["Ross", "St\u00e9phane", "Bagnell", "J. Andrew"], "venue": "In AISTATS, pp", "citeRegEx": "Ross et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2010}, {"title": "A reduction of imitation learning and structured prediction to noregret online learning", "author": ["Ross", "St\u00e9phane", "Gordon", "Geoffrey J", "Bagnell", "J.Andrew"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Ross et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2011}, {"title": "Learning message-passing inference machines for structured prediction", "author": ["Ross", "Stephane", "Munoz", "Daniel", "Hebert", "Martial", "Bagnell", "J Andrew"], "venue": "In CVPR,", "citeRegEx": "Ross et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ross et al\\.", "year": 2011}, {"title": "A unifying review of linear gaussian models", "author": ["Roweis", "Sam", "Ghahramani", "Zoubin"], "venue": "Neural computation,", "citeRegEx": "Roweis et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Roweis et al\\.", "year": 1999}, {"title": "Mind the duality gap: Logarithmic regret algorithms for online optimization", "author": ["Shalev-Shwartz", "Shai", "Kakade", "Sham M"], "venue": "In NIPS, pp", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2009}, {"title": "Predictive state representations: A new theory for modeling dynamical systems", "author": ["Singh", "Satinder", "James", "Michael R", "Rudary", "Matthew R"], "venue": "In UAI,", "citeRegEx": "Singh et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Singh et al\\.", "year": 2004}, {"title": "Optimistic rates for learning with a smooth loss", "author": ["Srebro", "Nathan", "Sridharan", "Karthik", "Tewari", "Ambuj"], "venue": "arXiv preprint arXiv:1009.3896,", "citeRegEx": "Srebro et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2010}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["Tieleman", "Tijmen", "Hinton", "Geoffrey"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Tieleman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Tieleman et al\\.", "year": 2012}, {"title": "Subspace identification for linear systems: TheoryImplementationApplications", "author": ["Van Overschee", "Peter", "De Moor", "BL"], "venue": "Springer Science & Business Media,", "citeRegEx": "Overschee et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Overschee et al\\.", "year": 2012}, {"title": "Improving multi-step prediction of learned time series models", "author": ["Venkatraman", "Arun", "Hebert", "Martial", "Bagnell", "J Andrew"], "venue": null, "citeRegEx": "Venkatraman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Venkatraman et al\\.", "year": 2015}, {"title": "Time series analysis", "author": ["Wei", "William Wu-Shyong"], "venue": "Addison-Wesley publication,", "citeRegEx": "Wei and Wu.Shyong.,? \\Q1994\\E", "shortCiteRegEx": "Wei and Wu.Shyong.", "year": 1994}, {"title": "Adadelta: an adaptive learning rate method", "author": ["Zeiler", "Matthew D"], "venue": "arXiv preprint arXiv:1212.5701,", "citeRegEx": "Zeiler and D.,? \\Q2012\\E", "shortCiteRegEx": "Zeiler and D.", "year": 2012}, {"title": "F}, which is determined by F and d. Without loss of generality, we assume l(z", "author": [], "venue": "{lF : (z,", "citeRegEx": "\u2208,? \\Q2012\\E", "shortCiteRegEx": "\u2208", "year": 2012}], "referenceMentions": [{"referenceID": 4, "context": "Spectral Learning methods are a popular alternative to MLE for learning models of dynamical systems (Boots, 2012; Boots et al., 2011; Hsu et al., 2009; Hefny et al., 2015).", "startOffset": 100, "endOffset": 171}, {"referenceID": 11, "context": "Spectral Learning methods are a popular alternative to MLE for learning models of dynamical systems (Boots, 2012; Boots et al., 2011; Hsu et al., 2009; Hefny et al., 2015).", "startOffset": 100, "endOffset": 171}, {"referenceID": 10, "context": "Spectral Learning methods are a popular alternative to MLE for learning models of dynamical systems (Boots, 2012; Boots et al., 2011; Hsu et al., 2009; Hefny et al., 2015).", "startOffset": 100, "endOffset": 171}, {"referenceID": 4, "context": "Spectral Learning methods are a popular alternative to MLE for learning models of dynamical systems (Boots, 2012; Boots et al., 2011; Hsu et al., 2009; Hefny et al., 2015). This family of algorithms provides theoretical guarantees on discovering the global optimum for the model parameters under the assumptions of infinite training data and realizability. However, in the non-realizable setting \u2014 i.e. model mismatch (e.g., using learned parameters of a Linear Dynamical System (LDS) model for a non-linear dynamical system) \u2014 these algorithms lose any performance guarantees on using the learned model for filtering or other inference tasks. For example, Kulesza et al. (2014) shows when the model rank is lower than the rank of the underlying dynamical system, the inference performance of the learned model may be arbitrarily bad.", "startOffset": 114, "endOffset": 679}, {"referenceID": 18, "context": "of Ross et al. (2011b); Ramakrishna et al.", "startOffset": 3, "endOffset": 23}, {"referenceID": 18, "context": "(2011b); Ramakrishna et al. (2014); Lin et al.", "startOffset": 9, "endOffset": 35}, {"referenceID": 15, "context": "(2014); Lin et al. (2015). Inference machines do not parametrize the graphical model (e.", "startOffset": 8, "endOffset": 26}, {"referenceID": 16, "context": "To generalize Inference Machines to dynamical systems with latent states, we leverage ideas from Predictive State Representations (PSRs) (Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Hefny et al., 2015).", "startOffset": 137, "endOffset": 219}, {"referenceID": 25, "context": "To generalize Inference Machines to dynamical systems with latent states, we leverage ideas from Predictive State Representations (PSRs) (Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Hefny et al., 2015).", "startOffset": 137, "endOffset": 219}, {"referenceID": 4, "context": "To generalize Inference Machines to dynamical systems with latent states, we leverage ideas from Predictive State Representations (PSRs) (Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Hefny et al., 2015).", "startOffset": 137, "endOffset": 219}, {"referenceID": 10, "context": "To generalize Inference Machines to dynamical systems with latent states, we leverage ideas from Predictive State Representations (PSRs) (Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Hefny et al., 2015).", "startOffset": 137, "endOffset": 219}, {"referenceID": 29, "context": "Data as Demonstrator (DaD) (Venkatraman et al., 2015) applies the Inference Machine idea to fully observable Markov chains, and directly optimizes the open-loop forward prediction accuracy.", "startOffset": 27, "endOffset": 53}, {"referenceID": 13, "context": "Though spectral algorithms can promise global optimality in certain cases, this desirable property does not hold under model mismatch (Kulesza et al., 2014).", "startOffset": 134, "endOffset": 156}, {"referenceID": 16, "context": "Recently, predictive state representations and observable operator models have been used to learn from, filter on, predict, and simulate time series data (Jaeger, 2000; Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Boots & Gordon, 2011; Hefny et al., 2015).", "startOffset": 154, "endOffset": 272}, {"referenceID": 25, "context": "Recently, predictive state representations and observable operator models have been used to learn from, filter on, predict, and simulate time series data (Jaeger, 2000; Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Boots & Gordon, 2011; Hefny et al., 2015).", "startOffset": 154, "endOffset": 272}, {"referenceID": 4, "context": "Recently, predictive state representations and observable operator models have been used to learn from, filter on, predict, and simulate time series data (Jaeger, 2000; Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Boots & Gordon, 2011; Hefny et al., 2015).", "startOffset": 154, "endOffset": 272}, {"referenceID": 10, "context": "Recently, predictive state representations and observable operator models have been used to learn from, filter on, predict, and simulate time series data (Jaeger, 2000; Littman et al., 2001; Singh et al., 2004; Boots et al., 2011; Boots & Gordon, 2011; Hefny et al., 2015).", "startOffset": 154, "endOffset": 272}, {"referenceID": 10, "context": ", xt+k\u22121} (Hefny et al., 2015).", "startOffset": 10, "endOffset": 30}, {"referenceID": 25, "context": ", the distribution of ft), then we also know everything there is to know about the state of a dynamical system at time step t (Singh et al., 2004).", "startOffset": 126, "endOffset": 146}, {"referenceID": 10, "context": "PSRs explicitly assume there exists a linear relationship between E[\u03c6(ft)|ht\u22121] and E[\u03b6(ft, xt+k)|ht\u22121], which can be learned by Instrumental Variable Regression (IVR) (Hefny et al., 2015).", "startOffset": 168, "endOffset": 188}, {"referenceID": 10, "context": "Following Hefny et al. (2015), we define the predictive state at time step t as E[\u03c6(ft)|ht\u22121] where \u03c6 is some feature function that is sufficient for the distribution P (ft|ht\u22121).", "startOffset": 10, "endOffset": 30}, {"referenceID": 11, "context": "This assumption allows us to avoid the cryptographic hardness of the general problem (Hsu et al., 2009).", "startOffset": 85, "endOffset": 103}, {"referenceID": 14, "context": "The original Inference Machine framework reduces the problem of learning graphical models to solving a set of classification or regression problems, where the learned classifiers mimic message passing procedures that output marginal distributions for the nodes in the model (Langford et al., 2009; Ross et al., 2011b; Bagnell et al., 2010).", "startOffset": 274, "endOffset": 339}, {"referenceID": 0, "context": "The original Inference Machine framework reduces the problem of learning graphical models to solving a set of classification or regression problems, where the learned classifiers mimic message passing procedures that output marginal distributions for the nodes in the model (Langford et al., 2009; Ross et al., 2011b; Bagnell et al., 2010).", "startOffset": 274, "endOffset": 339}, {"referenceID": 4, "context": "PSIM is different from PSRs in the following respects: (1) PSIM collapses the two steps of PSRs (predict the extended state and then condition on the latest observation) into one step\u2014as an Inference Machine\u2014for closed-loop update of predictive states; (2) PSIM directly targets the filtering task and has theoretical guarantees on the filtering performance; (3) unlike PSRs where one usually needs to utilize linear PSRs for learning purposes (Boots et al., 2011), PSIM can generalize to non-linear dynamics by leveraging non-linear regression or classification models.", "startOffset": 444, "endOffset": 464}, {"referenceID": 1, "context": "Squared loss in an example Bregman divergence of which there are others that are optimized by the conditional expectation (Banerjee et al., 2005).", "startOffset": 122, "endOffset": 145}, {"referenceID": 14, "context": "To analyze the consistency of our algorithm, we assume every learning problem can be solved perfectly (risk minimizer finds the Bayes optimal) (Langford et al., 2009).", "startOffset": 143, "endOffset": 166}, {"referenceID": 6, "context": "2 can be regarded as running the Follow the Leader (FTL) (Cesa-Bianchi et al., 2004; Shalev-Shwartz & Kakade, 2009; Hazan et al., 2007) on the sequence of loss functions {Ln(F )}n=1.", "startOffset": 57, "endOffset": 135}, {"referenceID": 9, "context": "2 can be regarded as running the Follow the Leader (FTL) (Cesa-Bianchi et al., 2004; Shalev-Shwartz & Kakade, 2009; Hazan et al., 2007) on the sequence of loss functions {Ln(F )}n=1.", "startOffset": 57, "endOffset": 135}, {"referenceID": 10, "context": "We compare our approaches to several baselines: Autoregressive models (AR), Subspace State Space System Identification (N4SID) (Van Overschee & De Moor, 2012), and PSRs implemented with IVR (Hefny et al., 2015).", "startOffset": 190, "endOffset": 210}, {"referenceID": 10, "context": "The sequences of observations are collected from the linear stationary Kalman filter of the LDS (Boots, 2012; Hefny et al., 2015).", "startOffset": 96, "endOffset": 129}], "year": 2016, "abstractText": "Latent state space models are a fundamental and widely used tool for modeling dynamical systems. However, they are difficult to learn from data and learned models often lack performance guarantees on inference tasks such as filtering and prediction. In this work, we present the PREDICTIVE STATE INFERENCE MACHINE (PSIM), a data-driven method that considers the inference procedure on a dynamical system as a composition of predictors. The key idea is that rather than first learning a latent state space model, and then using the learned model for inference, PSIM directly learns predictors for inference in predictive state space. We provide theoretical guarantees for inference, in both realizable and agnostic settings, and showcase practical performance on a variety of simulated and real world robotics benchmarks.", "creator": "LaTeX with hyperref package"}}}