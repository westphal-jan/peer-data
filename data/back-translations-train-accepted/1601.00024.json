{"id": "1601.00024", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Dec-2015", "title": "Selecting Near-Optimal Learners via Incremental Data Allocation", "abstract": "We study a novel machine learning (ML) problem setting of sequentially allocating small subsets of training data amongst a large set of classifiers. The goal is to select a classifier that will give near-optimal accuracy when trained on all data, while also minimizing the cost of misallocated samples. This is motivated by large modern datasets and ML toolkits with many combinations of learning algorithms and hyper-parameters. Inspired by the principle of \"optimism under uncertainty,\" we propose an innovative strategy, Data Allocation using Upper Bounds (DAUB), which robustly achieves these objectives across a variety of real-world datasets.", "histories": [["v1", "Thu, 31 Dec 2015 22:19:09 GMT  (399kb,D)", "http://arxiv.org/abs/1601.00024v1", "AAAI-2016: The Thirtieth AAAI Conference on Artificial Intelligence"]], "COMMENTS": "AAAI-2016: The Thirtieth AAAI Conference on Artificial Intelligence", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["ashish sabharwal", "horst samulowitz", "gerald tesauro"], "accepted": true, "id": "1601.00024"}, "pdf": {"name": "1601.00024.pdf", "metadata": {"source": "CRF", "title": "Selecting Near-Optimal Learners via Incremental Data Allocation", "authors": ["Ashish Sabharwal", "Horst Samulowitz", "Gerald Tesauro"], "emails": ["AshishS@allenai.org", "samulowitz@us.ibm.com", "gtesauro@us.ibm.com"], "sections": [{"heading": null, "text": "In an idealized environment where the expected accuracy of a classifier trained on n samples can be well known, we develop considerable theoretical support for DAUB. Under these conditions, we establish a strict sublinear limit on regretting the approach (in terms of misallocated data) and a strict limit on the sub-optimality of the selected classifier. Our accuracy estimates using real data sets involve only slight violations of the theoretical scenario, suggesting that the practical behavior of DAUB is likely to approximate the idealized behavior."}, {"heading": "1 Introduction", "text": "In fact, it is in such a way that we are able to enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into which we enter into another world, in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we, in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we, in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we, in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we, in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we into which we enter into which we enter into which we enter into which we into which we into which we enter into which we enter into which we enter into which we"}, {"heading": "2 Cost-Sensitive Training Data Allocation", "text": "We start with the formal definition of the problem of cost-sensitive training data. (...) We use the learners to expand their knowledge and skills. (...) We have the opportunity to expand their knowledge and knowledge. (...) We have the opportunity to expand their knowledge and knowledge. (...) We have the opportunity to expand their knowledge and knowledge. (...) We have the opportunity to expand their knowledge and knowledge. (...) We have the same knowledge and knowledge. (...) We have the same knowledge and knowledge. (...) We have the same knowledge and knowledge. (...) We have the same knowledge. (...) We have the same knowledge. (...) We have the same knowledge. (...) We have the same knowledge. (...) We have the same. (...) We have the same knowledge. (...) We have the same. (...) We have the same. (...) We have the same. (... We have the same knowledge. (...) We have the same. (...) We have the same."}, {"heading": "3 The DAUB Algorithm", "text": "The basic idea is to design an optimistic model for a complete training (N) of learners (N). (N) The learners with the highest upper limit are then able to obtain additional estimates. (N) The implementation of DAUB leads to a monotonous regression to determine a strict upper limit of fi (n). (N) The learners have a strict upper limit of fi (n).Like a bootstrapping step, DAUB first allocations b, br, and br2 examples for each training. (n) Senden ni of the most recent values of fi (n) provides a strict upper limit of fi (n). (n) As a bootstrapping step, DAUB first allocations b, and br2 examples for each training. (n) She trains them, and takes their validation in arrays f T i and f V i, Input: Learners C = (C1)."}, {"heading": "3.1 Theoretical Support for DAUB", "text": "To understand the behavior of DAUB, we consider an idealized variant, DAUB *, which functions exactly like DAUB, but has access to the actual expected accuracy and cost functions if it does not only take into account its observed assessments. As learning variance decreases (via random gradations of size n), the observations of fi (n) and ci (n) are aligned to these ideal values, and the behavior of DAUB is therefore essentially determined by DAUB *.Let f = maxi [M] fi (N) be the (unknown) target accuracy and Ci \u0445 be the corresponding (unknown) optimal learner. For each Ci, let ui: [N] \u2192 an arbitrarily projected upper estimate that DAUB * will be used for fi (N) if there are n < N training examples of Ci. We assume that it does not rise to the points where it is evaluated by DAUB."}, {"heading": "3.1.1 Obtaining Valid Projected Upper Bounds", "text": "If fi for i [M] were arbitrary functions, it would clearly be impossible to project fi (N) upwards by looking only at estimates of fi (n) to n < N. Fortunately, each fi is the expected accuracy of a learner and is therefore expected to behave in some way. To limit the regret of DAUB *, we assume two assumptions about the behavior of fi. Firstly, fi is not decreasing, i.e., more training data does not harm validation accuracy. Secondly, fi has a decreasing yield, namely, if n grows, the additional validation accuracy advantage diminishes by including more training examples. Formally: definition 6. f: N \u2192 [0, 1] is well behaved if it is not decreasing and its discrete derivative, f: \u2032, is not derivative, f \u2032, (Ufi) downwards (UAC).These assumptions are well supported by the expected accuracy of the PORP perspective."}, {"heading": "3.1.2 Bounding Regret", "text": "We fix ubi as the projected upper boundary function and explore how (N,) -J (J) -J (J) -J (J) -J (J) -J (J) -J (J) -J (J) -J (J) -J (N) -J (J) -J (N) -J (N) -N (N) -N (N) -N (N) -N (N) -N -N (N) -N (N) -N (N) -N (N) -N (N) -N) -N (N) -N (N) -N (N) -N (N) -J) -J (N) -J (N) -J) -J (N) -J) -N (N) -J (N) -J) -J (N) -J (N) -J (J) (J) (J) (J) (J) (J) -J (J) -J) -J (N) -J (J) -J) -N (N) -J (N) -J) -N (N) -N (N) -N (N) -N (N) -N (N) -N (N) -J) -J (N) -J (N) -J (N) -J (N) -J (N) -J) -J (N (N) -J (N) -J (N) -J (N) -J (N (N) -J) -J (N (N) -J (N (N) -J) -J (N (N) -J (N) -J (N (N) -J) -J (N (N (N) -J) -J (N (N) -J (N (N) -J) -J (N (N) -J (N (N) -J) -J (N (N (N) -J) -J (N (N (N) -J) -J (N (J) -J (N (N) -J) -J (N (J) -J (N (J) -J) -J (N (J) -J (N (N (J) -J) -J (N (J"}, {"heading": "3.1.3 Tightness of Bounds", "text": "The cost limit for incorrectly allocated data in Theorem 2 with respect to n \u0445 i is actually tight at worst (up to a constant factor), unless further assumptions are made about the accuracy functions. In particular, any algorithm that guarantees (N, \u0445) optimality without further assumptions must, at worst, incur costs in the order of cj (n \u0445 j) for each suboptimal Cj-C (see Theorem 5 appendix for a formal statement): Theorem 4 (Lower Bound, informal statement). Let it be an algorithm for allocating training data that always produces an (N, \u0445) -optimal learner. Then there is a (N, \u0445) -suboptimal learner Cj that would force A to accept incorrectly allocated training costs greater than cj (n \u0445 j) / 2."}, {"heading": "4 Experiments", "text": "In fact, most of us are able to keep ourselves to the limits of our capabilities, \"he told\" Welt am Sonntag \":\" This is not the first time that we have been able to move to another world, to move to another world. \""}, {"heading": "5 Conclusion", "text": "We reiterate the potential practical implications of our original, cost-sensitive data allocation scenario, combined with a new real-world support approach and our proposed DAUB algorithm to address this issue. In our experience, DAUB is fairly easy to use, easy to code and optimize, making it ideal for practitioners without knowledge of learning algorithms or data characteristics. In addition, all interim results can be used to interactively engage the practitioner in relevant information such as progress (e.g. updated learning curves) and decisions (e.g. assigned data). Such a tool was developed by Biem et al. [9] and a snapshot of it is shown in Figure 3.Our theoretical work on the idealized DAUB * also reveals new insights into real-world behavior."}, {"heading": "A Appendix: Proof Details", "text": "Let r > 1 and b + n. \"Let r > 1 and b + n.\" Let r > 1 and b + n. \"Let r > 1 and b + n.\" Let r \"Let\" n. \"Let\" n. \"Let\" n. \"Let\" s. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let.\" Let. \"Let...................................................."}, {"heading": "B Classifier Parameterizations", "text": "The exact configurations of each classifier in the WEKA package used in the classification experiments are as follows: 1. weka.classifiers.trees.SimpleCart2. weka.classifiers.rules.classiers.sr.wekakaka.-klassiers.bayers-bayers.NaiveBayesUpdateable4. weka.classifiers.functions.SMO -K \"weka.classifiers.functioners.sr.sr.wees.-C 250007 -G 0.01\" 5. weka.i.i.i.i.i.i.i.i.i.i.i.i.i.r.r.r.. r.. r............... i...... r.i.i.i.i.....................i.i.i.i.i.i............................i........i.i.i.i................i....i.i.i.i................i.i.i.i....................i....i.i.i.i....i.i....i.i.i....i.i.i............i.i.i....i.i.i.i....i.i............i.i.i.i............................i....i....i....i.i.i.i.i....i.i.i.i....i.i.i....i.i....i.i.i....i.i....i.i.i....i.i.i....i.i.i....i.i....i.i....i.i.i.i....i.i.i....i.i.i........i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i.i....i"}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "We study a novel machine learning (ML) problem setting of sequentially allocating small<lb>subsets of training data amongst a large set of classifiers. The goal is to select a classifier<lb>that will give near-optimal accuracy when trained on all data, while also minimizing the cost<lb>of misallocated samples. This is motivated by large modern datasets and ML toolkits with<lb>many combinations of learning algorithms and hyper-parameters. Inspired by the principle of<lb>\u201coptimism under uncertainty,\u201d we propose an innovative strategy, Data Allocation using Upper<lb>Bounds (DAUB), which robustly achieves these objectives across a variety of real-world datasets.<lb>We further develop substantial theoretical support for DAUB in an idealized setting where<lb>the expected accuracy of a classifier trained on n samples can be known exactly. Under these<lb>conditions we establish a rigorous sub-linear bound on the regret of the approach (in terms<lb>of misallocated data), as well as a rigorous bound on suboptimality of the selected classifier.<lb>Our accuracy estimates using real-world datasets only entail mild violations of the theoretical<lb>scenario, suggesting that the practical behavior of DAUB is likely to approach the idealized<lb>behavior.", "creator": "LaTeX with hyperref package"}}}