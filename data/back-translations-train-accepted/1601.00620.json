{"id": "1601.00620", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jan-2016", "title": "Distant IE by Bootstrapping Using Lists and Document Structure", "abstract": "Distant labeling for information extraction (IE) suffers from noisy training data. We describe a way of reducing the noise associated with distant IE by identifying coupling constraints between potential instance labels. As one example of coupling, items in a list are likely to have the same label. A second example of coupling comes from analysis of document structure: in some corpora, sections can be identified such that items in the same section are likely to have the same label. Such sections do not exist in all corpora, but we show that augmenting a large corpus with coupling constraints from even a small, well-structured corpus can improve performance substantially, doubling F1 on one task.", "histories": [["v1", "Mon, 4 Jan 2016 19:46:00 GMT  (151kb,D)", "http://arxiv.org/abs/1601.00620v1", "7 pages, to appear at AAAI 2016"]], "COMMENTS": "7 pages, to appear at AAAI 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lidong bing", "mingyang ling", "richard c wang", "william w cohen"], "accepted": true, "id": "1601.00620"}, "pdf": {"name": "1601.00620.pdf", "metadata": {"source": "CRF", "title": "Distant IE by Bootstrapping Using Lists and Document Structure", "authors": ["Lidong Bing", "Mingyang Ling", "Richard C. Wang", "William W. Cohen"], "emails": ["{lbing@cs,", "mingyanl@andrew,", "wcohen@cs}.cmu.edu", "richardwang@baidu.com"], "sections": [{"heading": "Introduction", "text": "This year, the time has come for you to be able to get to know a new country where people are able to find a new home."}, {"heading": "Knowledge Base and Corpora", "text": "Even large, curated CBs are often incomplete: for example, a recent paper shows that more than 57% of the nine most commonly used attribute / relation values for the 100 most common PERSON drugs are missing in Freebase (West et al. 2014). We look at the expansion of Freebase coverage in the medical field, which is currently relatively limited: for example, an April 2014 freebase snapshot (after filtering noise with simple rules such as length of more than 60 characters and commas) contains only 4,605 cases of \"disease or medical condition\" and 4,383 cases of \"drug,\" whereas dailymed.nlm.nih.gov contains data on over 74k drugs, and malacards.org lists nearly 10k diseases."}, {"heading": "Propagation Graph", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to integrate themselves, in which they are able to live, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they are able to change the world, in which they live, in which they live, in which they live, in which they live in which they live, in which they live in which they live in which they live, in which they live in which they are able to integrate themselves, and in which they are able to live, in which they are able to change the world, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in"}, {"heading": "Label Propagation", "text": "Given the nature of these added edges, it seems plausible to use label propagation on the above chart to propagate relation types of seed NP (disease NP) pairs with known metamorphosis types, such as those that correspond to triples in KB, to more pairs and lists throughout the chart. This can be considered semi-supervised learning (SSL) of pairs that are used to treat a relationship (e.g., \"to treat\" or \"side effects.\" We are adopting an existing multi-class labeling method, namely MRRankWalk (MRW) (Lin and Cohen 2010), to accomplish our task, which is a graph-based SSL in connection with personalized PageRank (PPR) (Haveliwala et al. 2003) (aka random walk with restart (Tong, Faloutsos, and Pan 2006) Sector I. Given a chart that matrix is represented by an apparent class, the probability class S is sensed over Kong, Faloutsos, and Pan equilibrium class."}, {"heading": "Classification", "text": "One could imagine using the output of MRW to directly expand a KB. However, the process described above cannot be conveniently used to label new documents as they appear. As this is also often a goal, we use the MRW output to train a classifier, which can then be used to classify the mentions of entities (singlet lists) and coordinate lists in each new document, as well as those that are not reached in the graph above. We use the same attribute generator for both mentions and lists. Shallow attributes include: tokens in the NPs and character prefixes / suffixes of these tokens; tokens from the sentence that contains the NP; and tokens and bigrams from a window around the NPs. From the dependency analysis, we also find the verb that is the next precursor of the head of the NP, and all modifiers of this verb / suffix are computed from this list; the token and the sentence that contains the tob; the token and the set."}, {"heading": "Parameter Tuning", "text": "Two important parameters in DIEBOLDS are the number of seeds for MRW label propagation and the uppermost N number for generating training examples for SVM. Here we describe our method of coordination. The evaluation data is generated using a number of validating facts. Specifically, these facts are used as MRW seed and the top 200 lists (singleton and coordinate lists) of each relationship as evaluated by MRW are collected. We consider these lists to be pseudo-label-like examples to test the performance of trained classifiers in DIEBOLDS. Their trait vectors are generated in the same way as above. We refer to total available seeds for DIEBOLDS as a development set, no overlap with the validation set set set here. The effect of the uppermost N number in the use of 100% development seeds is stated in Figure 4. As we expect, too few examples or too many examples of training for a precise classifier are insufficient to indicate that the few examples are insufficient."}, {"heading": "Evaluation Datasets 1", "text": "For the first set of data, we manually labeled 10 pages from the WikiDisease corpus and 10 pages from the DailyMed corpus. The annotated text fragments are the NPs that are the object values of these 8 relationships, with the drug or disease described as the subject of the relationship by the corresponding document. In total, we collected 436 Triple Facts for the disease area and 320 Triple Facts for the drug area. The task of a pipeline is to extract the objects of the relationships in a given document.For the second set, we use questions in the training data set of BioASQ3-Task B 2 to investigate the ability of the DIEBOLDS edition to answer these questions.This data set contains four types of questions: Yes / No Questions, Factoid Questions, List Questions, and Summary Questions (Tsatsaronis et al. 2015). We focus on factoid and list questions because these questions require a specific entity name (e.g. a list of diseases, a medicine or a summary of them)."}, {"heading": "Baselines", "text": "The first two baselines are based on remote monitoring. A DS baseline attempts to classify each NP in its input corpus into one of the interested metamorphosis types, or \"others\" with the training corpus as remote monitoring. Each sentence in the corpus is processed using the same preprocessing pipeline to detect NPs. Subsequently, these NPs are labeled with the training corpus. Characteristics are defined and extracted in the same way as we did for DIEBOLDS, and binary classifiers are trained using the same methodology. The first DS baseline only generates labeled examples from the target corpus, and it is called DS1. While the second DS baseline uses both target corpus and structured corpus, and it is called DS2. The third baseline applies the list structure to DS1, and the first preforms the propagation with MRW on the two-sided diagram of the target corpus. Then, DS classifiers are evaluated in the same way with the top lists, the MRW."}, {"heading": "Variants of DIEBOLDS", "text": "We also examine different variants of DIEBOLDS: The first variant removes S-edges and N-edges from the DIEBOLDS diagram when multiplying labels, and it is called DIEBOLDS-SN. By removing S-edges and N-edges respectively, we have two more variants called DIEBOLDSS and DIEBOLDS-N. We use the same way to adjust the parameters for these variants and also the base line DS + L. Specifically, all baselines and variants use 100% of the training seed, and the uppermost N-values are determined as those which have achieved the best performance from the tuning examples."}, {"heading": "Experimental Settings", "text": "We extracted three times these 8 target relationships from the free base. In particular, if the subject of a triple matches a drug or disease name in our target corpus and its object value also appears in this document, it will be extracted as seed. In the disease field, we receive 1,524, 1,976, 593, 674 and 99 triples for treatments, symptoms, risk factors, causes or prevention factors. In the pharmaceutical field, we receive 2,973, 229 and 243 triples for treatment, conditions it can prevent, or side effects. These triples are divided into development kits and validated at a ratio of 9: 1. The development kit is used as MRW seed, and the validation kit is used to validate various parameters. Note that we do not use seeds that match only the structured corpus, as we aim to evaluate the effect of using structured corpus on the extraction of each pre-corpus, and to evaluate the performance of each of the pre-corpus we take, and to evaluate the specific corpus and the validation of such corpus."}, {"heading": "Results on Labeled Pages", "text": "In fact, it is in such a way that we are in a position to enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into another world, in which we enter into which we enter into which we enter into another world, in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we in which we enter into which we enter into which we enter into which we enter into which we enter into which we in which we enter into which we enter into which we enter into which we enter into which we enter into which we in which we enter into which we enter into which we enter into which we in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we, in which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we enter into which we into which we enter into which we enter into which we enter into which we enter into which we into which we enter into which we enter into which we into which we enter into which we into which we enter into which we enter into which we enter into which we enter into which we into which we enter into which we enter into which we into which we enter into which we into which we into which we into which we enter into which we enter into which we"}, {"heading": "Results on BioASQ Questions", "text": "In fact, most of them are able to go to another world, to go to another world, to go to another world, to go to another world, to go to another world, to go to another world, to not find themselves, to not find themselves, to not find themselves, to not find themselves, to not find themselves, to not find themselves, to not find themselves, to not find themselves, to not find oneself, to not find oneself, to not find oneself, to not find oneself, to not find oneself, to not find oneself."}, {"heading": "Acknowledgments", "text": "This work was funded by a scholarship from Baidu USA and NSF under the research grant IIS-1250956."}], "references": [{"title": "Snowball: Extracting relations from large plain-text collections", "author": ["E. Agichtein", "L. Gravano"], "venue": "Proceedings of the Fifth ACM International Conference on Digital Libraries, 85\u201394.", "citeRegEx": "Agichtein and Gravano,? 2000", "shortCiteRegEx": "Agichtein and Gravano", "year": 2000}, {"title": "Improving distant supervision for information extraction using label propagation through lists", "author": ["L. Bing", "S. Chaudhari", "R. Wang C", "W.W. Cohen"], "venue": "EMNLP, 524\u2013 529.", "citeRegEx": "Bing et al\\.,? 2015", "shortCiteRegEx": "Bing et al\\.", "year": 2015}, {"title": "Learning to extract relations from the web using minimal supervision", "author": ["R.C. Bunescu", "R.J. Mooney"], "venue": "ACL.", "citeRegEx": "Bunescu and Mooney,? 2007", "shortCiteRegEx": "Bunescu and Mooney", "year": 2007}, {"title": "LIBSVM: a library for support vector machines", "author": ["Chang", "C.-C.", "Lin", "C.-J."], "venue": "Software available at http://www.csie.ntu.edu.tw/ \u0303cjlin/libsvm.", "citeRegEx": "Chang et al\\.,? 2001", "shortCiteRegEx": "Chang et al\\.", "year": 2001}, {"title": "A comparison of string distance metrics for name-matching tasks", "author": ["W.W. Cohen", "P. Ravikumar", "S.E. Fienberg"], "venue": "IIWeb-03.", "citeRegEx": "Cohen et al\\.,? 2003", "shortCiteRegEx": "Cohen et al\\.", "year": 2003}, {"title": "Constructing biological knowledge bases by extracting information from text sources", "author": ["M. Craven", "J. Kumlien"], "venue": "ISMB-99, 77\u201386.", "citeRegEx": "Craven and Kumlien,? 1999", "shortCiteRegEx": "Craven and Kumlien", "year": 1999}, {"title": "An analytical comparison of approaches to personalizing pagerank", "author": ["T. Haveliwala", "S. Kamvar", "A. Kamvar", "G. Jeh"], "venue": "Technical report, Stanford University.", "citeRegEx": "Haveliwala et al\\.,? 2003", "shortCiteRegEx": "Haveliwala et al\\.", "year": 2003}, {"title": "Knowledge-based weak supervision for information extraction of overlapping relations", "author": ["R. Hoffmann", "C. Zhang", "X. Ling", "L. Zettlemoyer", "D.S. Weld"], "venue": "ACL, 541\u2013550.", "citeRegEx": "Hoffmann et al\\.,? 2011", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "Semi-supervised classification of network data using very few labels", "author": ["F. Lin", "W.W. Cohen"], "venue": "ASONAM, 192\u2013199.", "citeRegEx": "Lin and Cohen,? 2010", "shortCiteRegEx": "Lin and Cohen", "year": 2010}, {"title": "Introduction to information retrieval, volume 1", "author": ["C.D. Manning", "P. Raghavan", "H. Sch\u00fctze"], "venue": "Cambridge university press.", "citeRegEx": "Manning et al\\.,? 2008", "shortCiteRegEx": "Manning et al\\.", "year": 2008}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["M. Mintz", "S. Bills", "R. Snow", "D. Jurafsky"], "venue": "ACL, 1003\u20131011.", "citeRegEx": "Mintz et al\\.,? 2009", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Populating the semantic web by macroreading internet text", "author": ["T.M. Mitchell", "J. Betteridge", "A. Carlson", "E. Hruschka", "R. Wang"], "venue": "ISWC, 998\u20131002.", "citeRegEx": "Mitchell et al\\.,? 2009", "shortCiteRegEx": "Mitchell et al\\.", "year": 2009}, {"title": "Bootstrapping biomedical ontologies for scientific text using nell", "author": ["D. Movshovitz-Attias", "W.W. Cohen"], "venue": "BioNLP, 11\u201319.", "citeRegEx": "Movshovitz.Attias and Cohen,? 2012", "shortCiteRegEx": "Movshovitz.Attias and Cohen", "year": 2012}, {"title": "Modeling relations and their mentions without labeled text", "author": ["S. Riedel", "L. Yao", "A. McCallum"], "venue": "ECML PKDD. 148\u2013163.", "citeRegEx": "Riedel et al\\.,? 2010", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Learning Dictionaries for Information Extraction by Multi-level Boot-strapping", "author": ["E. Riloff", "R. Jones"], "venue": "AAAI/IAAI, 1044\u20131049.", "citeRegEx": "Riloff and Jones,? 1999", "shortCiteRegEx": "Riloff and Jones", "year": 1999}, {"title": "Dependency parsing and domain adaptation with lr models and parser ensembles", "author": ["K. Sagae", "J. Tsujii"], "venue": "EMNLP-CoNLL, 1044\u20131050.", "citeRegEx": "Sagae and Tsujii,? 2007", "shortCiteRegEx": "Sagae and Tsujii", "year": 2007}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["M. Surdeanu", "J. Tibshirani", "R. Nallapati", "C.D. Manning"], "venue": "EMNLP-CoNLL, 455\u2013465.", "citeRegEx": "Surdeanu et al\\.,? 2012", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "Fast random walk with restart and its applications", "author": ["H. Tong", "C. Faloutsos", "J.-Y. Pan"], "venue": "ICDM, 613\u2013622.", "citeRegEx": "Tong et al\\.,? 2006", "shortCiteRegEx": "Tong et al\\.", "year": 2006}, {"title": "An overview of the bioasq large-scale biomedical semantic indexing and question answering competition", "author": ["M. Schroeder", "I. Androutsopoulos", "G. Paliouras"], "venue": "BMC Bioinformatics 16(1).", "citeRegEx": "Schroeder et al\\.,? 2015", "shortCiteRegEx": "Schroeder et al\\.", "year": 2015}, {"title": "Programming with personalized pagerank: a locally groundable first-order probabilistic logic", "author": ["W.Y. Wang", "K. Mazaitis", "W.W. Cohen"], "venue": "CIKM, 2129\u20132138.", "citeRegEx": "Wang et al\\.,? 2013", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "Knowledge base completion via searchbased question answering", "author": ["R. West", "E. Gabrilovich", "K. Murphy", "S. Sun", "R. Gupta", "D. Lin"], "venue": "WWW, 515\u2013526.", "citeRegEx": "West et al\\.,? 2014", "shortCiteRegEx": "West et al\\.", "year": 2014}, {"title": "Autonomously semantifying wikipedia", "author": ["F. Wu", "D.S. Weld"], "venue": "CIKM, 41\u201350.", "citeRegEx": "Wu and Weld,? 2007", "shortCiteRegEx": "Wu and Weld", "year": 2007}, {"title": "Open information extraction using wikipedia", "author": ["F. Wu", "D.S. Weld"], "venue": "ACL, 118\u2013127.", "citeRegEx": "Wu and Weld,? 2010", "shortCiteRegEx": "Wu and Weld", "year": 2010}, {"title": "Semisupervised learning using Gaussian fields and harmonic functions", "author": ["X. Zhu", "Z. Ghahramani", "J. Lafferty"], "venue": "ICML-03.", "citeRegEx": "Zhu et al\\.,? 2003", "shortCiteRegEx": "Zhu et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 7, "context": ", (Hoffmann et al. 2011; Riedel, Yao, and McCallum 2010; Surdeanu et al. 2012)); by carefully selecting the entity mentions from contexts likely to include specific KB facts (Wu and Weld 2010); or by careful filtering of the KB strings used as seeds (Movshovitz-Attias and Cohen 2012).", "startOffset": 2, "endOffset": 78}, {"referenceID": 16, "context": ", (Hoffmann et al. 2011; Riedel, Yao, and McCallum 2010; Surdeanu et al. 2012)); by carefully selecting the entity mentions from contexts likely to include specific KB facts (Wu and Weld 2010); or by careful filtering of the KB strings used as seeds (Movshovitz-Attias and Cohen 2012).", "startOffset": 2, "endOffset": 78}, {"referenceID": 22, "context": "2012)); by carefully selecting the entity mentions from contexts likely to include specific KB facts (Wu and Weld 2010); or by careful filtering of the KB strings used as seeds (Movshovitz-Attias and Cohen 2012).", "startOffset": 101, "endOffset": 119}, {"referenceID": 12, "context": "2012)); by carefully selecting the entity mentions from contexts likely to include specific KB facts (Wu and Weld 2010); or by careful filtering of the KB strings used as seeds (Movshovitz-Attias and Cohen 2012).", "startOffset": 177, "endOffset": 211}, {"referenceID": 1, "context": "a fact used in prior work (Bing et al. 2015) to propagate NP categories from unambiguous NPs (such as chest pain in passage 2) to ambiguous ones (e.", "startOffset": 26, "endOffset": 44}, {"referenceID": 8, "context": "used propagation methods (Zhu, Ghahramani, and Lafferty 2003; Lin and Cohen 2010) to exploit this intuition, by propagating the low-confidence labels associated with distance supervision matches through an appropriate graph.", "startOffset": 25, "endOffset": 81}, {"referenceID": 20, "context": ", a recent work showed that more than 57% of the nine commonly used attribute/relation values are missing for the top 100k most frequent PERSON entities in Freebase (West et al. 2014).", "startOffset": 165, "endOffset": 183}, {"referenceID": 15, "context": "List Extraction and Graph with List Edges We use the GDep parser (Sagae and Tsujii 2007), a dependency parser trained on the GENIA Treebank, to parse the corpora.", "startOffset": 65, "endOffset": 88}, {"referenceID": 8, "context": "We adopt an existing multi-class label propagation method, namely, MultiRankWalk (MRW) (Lin and Cohen 2010), to handle our task, which is a graph-based SSL related to personalized PageRank (PPR) (Haveliwala et al.", "startOffset": 87, "endOffset": 107}, {"referenceID": 6, "context": "We adopt an existing multi-class label propagation method, namely, MultiRankWalk (MRW) (Lin and Cohen 2010), to handle our task, which is a graph-based SSL related to personalized PageRank (PPR) (Haveliwala et al. 2003) (aka random walk with restart (Tong, Faloutsos, and Pan 2006)).", "startOffset": 195, "endOffset": 219}, {"referenceID": 5, "context": "Distant supervision was initially employed by Craven and Kumlien (1999) in the biomedical domain under a different terminology, i.", "startOffset": 46, "endOffset": 72}, {"referenceID": 5, "context": "Distant supervision was initially employed by Craven and Kumlien (1999) in the biomedical domain under a different terminology, i.e. weakly labeled data. Then, it attracted attentions from the IE community. Mintz et al. (2009) employed Freebase to label sentences containing a pair of entities that participate in a known Freebase relation, and aggregated the features from different sentences for this relation.", "startOffset": 46, "endOffset": 227}, {"referenceID": 7, "context": "MultiR (Hoffmann et al. 2011) and Multi-Instance Multi-Label Learning (MIML) (Surdeanu et al.", "startOffset": 7, "endOffset": 29}, {"referenceID": 16, "context": "2011) and Multi-Instance Multi-Label Learning (MIML) (Surdeanu et al. 2012) further improve it to support multiple relations expressed by different sentences in a bag.", "startOffset": 53, "endOffset": 75}, {"referenceID": 14, "context": "In the classic bootstrapping learning (Riloff and Jones 1999; Agichtein and Gravano 2000; Bunescu and Mooney 2007), small number of seed instances are used to extract, from a large corpus, new patterns, which are used to extract more instances.", "startOffset": 38, "endOffset": 114}, {"referenceID": 0, "context": "In the classic bootstrapping learning (Riloff and Jones 1999; Agichtein and Gravano 2000; Bunescu and Mooney 2007), small number of seed instances are used to extract, from a large corpus, new patterns, which are used to extract more instances.", "startOffset": 38, "endOffset": 114}, {"referenceID": 2, "context": "In the classic bootstrapping learning (Riloff and Jones 1999; Agichtein and Gravano 2000; Bunescu and Mooney 2007), small number of seed instances are used to extract, from a large corpus, new patterns, which are used to extract more instances.", "startOffset": 38, "endOffset": 114}, {"referenceID": 11, "context": "This approach aggregates different mention occurrences of the same NP, falling in the macroreading paradigm (Mitchell et al. 2009), and it might also be a good direction to explore.", "startOffset": 108, "endOffset": 130}], "year": 2016, "abstractText": "Distant labeling for information extraction (IE) suffers from noisy training data. We describe a way of reducing the noise associated with distant IE by identifying coupling constraints between potential instance labels. As one example of coupling, items in a list are likely to have the same label. A second example of coupling comes from analysis of document structure: in some corpora, sections can be identified such that items in the same section are likely to have the same label. Such sections do not exist in all corpora, but we show that augmenting a large corpus with coupling constraints from even a small, well-structured corpus can improve performance substantially, doubling F1 on one task.", "creator": "TeX"}}}