{"id": "1602.00991", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Feb-2016", "title": "Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks", "abstract": "This paper presents to the best of our knowledge the first end-to-end object tracking approach which directly maps from raw sensor input to object tracks in sensor space without requiring any feature engineering or system identification in the form of plant or sensor models. Specifically, our system accepts a stream of raw sensor data at one end and, in real-time, produces an estimate of the entire environment state at the output including even occluded objects. We achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks. In particular, we propose a learning method based on a form of input dropout which allows learning in an unsupervised manner, only based on raw, occluded sensor data without access to ground-truth annotations. We demonstrate our approach using a synthetic dataset designed to mimic the task of tracking objects in 2D laser data -- as commonly encountered in robotics applications -- and show that it learns to track many dynamic objects despite occlusions and the presence of sensor noise.", "histories": [["v1", "Tue, 2 Feb 2016 16:10:16 GMT  (379kb,D)", "http://arxiv.org/abs/1602.00991v1", "Published in The Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16) Video:this https URLCode:this http URL"], ["v2", "Tue, 8 Mar 2016 22:09:05 GMT  (379kb,D)", "http://arxiv.org/abs/1602.00991v2", "Published in The Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16), Video:this https URL, Code:this http URL"]], "COMMENTS": "Published in The Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16) Video:this https URLCode:this http URL", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV cs.NE cs.RO", "authors": ["peter ondruska", "ingmar posner"], "accepted": true, "id": "1602.00991"}, "pdf": {"name": "1602.00991.pdf", "metadata": {"source": "CRF", "title": "Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks", "authors": ["Peter Ondr\u00fa\u0161ka", "Ingmar Posner"], "emails": ["ingmar}@robots.ox.ac.uk"], "sections": [{"heading": "Introduction", "text": "In fact, the fact is that most of us are able to abide by the rules that they apply in practice, and that they are able to abide by the rules that they apply in practice, and that they abide by the rules that they apply in practice, and that they abide by the rules that they apply in practice, and that they abide by the rules that they apply in practice."}, {"heading": "Deep Tracking", "text": "Formally, our goal is to predict the current, non-occluded scene around the robot, since the sequence of sensor observations, i.e. P (yt | x1: t) modeling, which is a discrete stochastic process with unknown dynamics, models the scene around the robot that contains other static and dynamic objects, and xt yt the sensor measurements are directly visible parts of the scene. We use the encoding xt = {vt, rt}, where {vit, zit} = {1, yit} when the i-th element of yt is observed and {0, 0} otherwise. In addition, when changing the scene, the robot can observe different parts of the scene at different times. Generally, this problem cannot be effectively solved if the process is purely random and unpredictable, as in this case there is no way to determine the unobserved elements of yt. In practice, however, the sequences yt and structural and temporal regularities that can be used to evaluate these patterns can be effective."}, {"heading": "The Model", "text": "Like many approaches to object tracking, our model can only be obtained by subsequent measurements."}, {"heading": "Filtering Using Recurrent Neural Network", "text": "The calculation of P (yt | x1: t) is easily performed by iteratively updating the current belief BtBt = F (Bt \u2212 1, xt) (5), which is defined by equations 2,3 and simultaneously predicting P (yt | x1: t) = P (yt | Bt) (6) defined by equation 4. In addition, instead of yt, the same method can be used to predict any state in the future P (yt + n | x1: t) by modeling the generative process by blank observations of the form x (t + 1): (t + n) = \u2205. For realistic applications, however, this approach is limited by the need for the appropriate representation of faith as well as the explicit knowledge of the distributions in Equation 1. The key idea of our solution is to avoid the need to specify this knowledge and instead use a highly expressive neural network governed by the weights WF and WP to assume both F (unmodelled, Bxt \u2212 1) and a modeled."}, {"heading": "Training", "text": "The network can be trained both in a supervised mode, i.e. with both known y1: N, x1: N, and in an unattended mode, in which only x1: N is known. A common method of supervised training is to minimize the negative log probability of the true scene state in view of the sensor input L = \u2212 N \u2211 t = 1 logP (yt | x1: t) (7) This target can be achieved by gradient descending with partial derivatives given by time background propagation (Rumelhart, Hinton and Williams 1985), which requires L \u0445 Bt = 4 (Bt, xt + 1)."}, {"heading": "Unsupervised Training", "text": "The goal of the unattended training is to train F (Bt \u2212 1, xt) and P (yt | Bt) using only x1: t. This may seem impossible without knowledge of yt, as there is no way to correct the network predictions. However, some values of yt are known as xt yt in the directly observed sensor measurements. A naive approach would be to train the network to predict the known values of yt from Equation 7 and not spread them backwards from the not observed ones. However, such an approach would fail, as the network would only learn to copy the observed elements of xt into the output and never predict objects in secret. Instead, and crucially, we propose not to train the network to predict the current state P (yt | x1: t), but a state in the future P (yt + n | x1: t). For the network to correctly predict the visible part of the object, the network must learn."}, {"heading": "Experimental Results", "text": "In this section, we demonstrate the effectiveness of our approach in estimating the complete scene state in a simulated scenario depicting a robot equipped with a 2D laser scanner surrounded by many dynamic objects. Our inspiration is the situation of a robot in the middle of a busy street surrounded by a crowd. Objects are modeled as circles that move independently of each other at constant speed in a random direction, but never collide with each other or with the robot. Over time, the number of objects present in the scene fluctuates between two and 12, as randomly new objects appear and later disappear at a distance from the robot. Sensor Input At each step, we simulated the sensor input as it is usually provided by a plane laser scanner. We divided the scene around the robot with a 2D grid of 50 x 50 pixels, with the robot positioned toward the lowest center. To model sensor inputs, we use a {xelweight} to represent the presence of each object, and the number of each pixel is followed by an observer."}, {"heading": "Neural Network", "text": "For the common model F (Bt \u2212 1, xt) and P (yt | Bt) we used a small, recursive network, as shown in Figure 4. This architecture has four layers and uses convolutionary operations, followed by a sigmoid nonlinearity as a basic information processing step at each level. The network has a total of 11k parameters and its hyperparameters such as the number of channels in each layer and size of the nuclei were determined by cross-validation. The belief state Bt is represented by the third layer of size 50 \u00d7 16, which is held between the time steps. Figure F (Bt \u2212 1, xt) is composed of the stage of input pre-processing (the encoder) followed by a stage of hidden decor Decor Decor Decor Decor Decor Decor Decor Decor 5 Decor. The objective of the encoder is to analyze the sensor measurements to detect objects that are directly responsible for the 2 7x7 Decor Decor Decor Decor Decor Decor Decor Decor Decor Decor"}, {"heading": "Training", "text": "We created 10,000 sequences with a length of 200 time steps and trained the network for a total of 50,000 iterations using stochastic gradient descendence with a learning rate of 0.9. Initial belief Bt was modeled as a free parameter optimized in conjunction with network weights WF, WP. Both supervised (i.e. when the basic truth of yt is known) and unsupervised were attempted with nearly identical results. Figure 5 illustrates the unattended training progress. First, the network produces random results, then it gradually learns to predict the correct shape of the visible objects, and finally it learns to track its position itself through complete occlusion. As illustrated in the accompanying video, the fully trained network is able to immediately track an object after seeing only a portion of it, and is then able to confidently track its correct shape by showing its position itself over long periods of network activations exemplified by 6 parts."}, {"heading": "Related Works", "text": "It is about the modeling of partially observable stochastic processes with a particular focus on application3See the accompanying video.of tracking objects. This problem is commonly solved by Bavarian filtering, which has led to tracking methods for a variety of domains (Yilmaz, Javed, and Shah 2006).Frequently, in these approaches, state representation is designed by hand and prediction and correction operations are made under a series of assumptions about model distributions or sampling-based methods.The Kalman filter (Kalman 1960), for example, assumes a multicultural normal distribution to represent the belief in the latent state that leads to the known prediction / actualization equations, but limits its expressive power. In contrast, the particle filter (Thrun, Burgard, and Fox 2005) dispenses with all assumptions about faith distributions and deals with an exemplary approach."}, {"heading": "Conclusions", "text": "In this paper, we introduced Deep Tracking, an end-to-end approach that uses recurrent neural networks to map directly from raw sensor data into an interpretable but hidden sensor space and predict the hidden state of the entire scene in a simulated 2D sensor application. It avoids any manual production of plant or sensor models and instead learns the corresponding models directly from raw, hidden sensor data. The approach was demonstrated using a synthetic dataset, where it enabled a highly accurate reconstruction of the underlying world model. As a future work, our goal is to evaluate Deep Tracking using real data collected by robots in a variety of situations such as pedestrian zones or in the context of autonomous driving in the presence of other road users. In both situations, knowledge of the likely unhidden scene is a key prerequisite for robust robot decisions."}], "references": [{"title": "Bayesian filtering: From kalman filters to particle filters, and beyond", "author": ["Z. Chen"], "venue": null, "citeRegEx": "Chen,? \\Q2003\\E", "shortCiteRegEx": "Chen", "year": 2003}, {"title": "Human tracking using convolutional neural networks", "author": ["Fan"], "venue": "Neural Networks, IEEE Transactions on 21(10):1610\u20131623", "citeRegEx": "Fan,? \\Q2010\\E", "shortCiteRegEx": "Fan", "year": 2010}, {"title": "Recurrent network models for human dynamics", "author": ["Fragkiadaki"], "venue": null, "citeRegEx": "Fragkiadaki,? \\Q2015\\E", "shortCiteRegEx": "Fragkiadaki", "year": 2015}, {"title": "Long short-term memory. Neural computation 9(8):1735\u20131780", "author": ["Hochreiter", "S. Schmidhuber 1997] Hochreiter", "J. Schmidhuber"], "venue": null, "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Multi-object tracking using feed-forward neural networks", "author": ["J\u00e4nen"], "venue": "In Soft Computing and Pattern Recognition (SoCPaR),", "citeRegEx": "J\u00e4nen,? \\Q2010\\E", "shortCiteRegEx": "J\u00e4nen", "year": 2010}, {"title": "A new approach to linear filtering and prediction problems", "author": ["R.E. Kalman"], "venue": "Journal of Fluids Engineering", "citeRegEx": "Kalman,? \\Q1960\\E", "shortCiteRegEx": "Kalman", "year": 1960}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, 1097\u20131105", "author": ["Sutskever Krizhevsky", "A. Hinton 2012] Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["McCallum Lafferty", "J. Pereira 2001] Lafferty", "A. McCallum", "F.C. Pereira"], "venue": null, "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Recurrent neural networks. Design and Applications", "author": ["Medsker", "L. Jain 2001] Medsker", "L. Jain"], "venue": null, "citeRegEx": "Medsker et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Medsker et al\\.", "year": 2001}, {"title": "Structured recurrent temporal restricted boltzmann machines", "author": ["Mittelman"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "Mittelman,? \\Q2014\\E", "shortCiteRegEx": "Mittelman", "year": 2014}, {"title": "A tutorial on hidden markov models and selected applications in speech recognition", "author": ["L.R. Rabiner 1989] Rabiner"], "venue": "Proceedings of the IEEE 77(2):257\u2013286", "citeRegEx": "Rabiner,? \\Q1989\\E", "shortCiteRegEx": "Rabiner", "year": 1989}, {"title": "Learning internal representations by error propagation", "author": ["Hinton Rumelhart", "D.E. Williams 1985] Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": null, "citeRegEx": "Rumelhart et al\\.,? \\Q1985\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1985}, {"title": "Learning representations by back-propagating errors. Cognitive modeling 5:3", "author": ["Hinton Rumelhart", "D.E. Williams 1988] Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": null, "citeRegEx": "Rumelhart et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1988}, {"title": "Convolutional lstm network: A machine learning approach for precipitation nowcasting", "author": ["Shi"], "venue": "arXiv preprint arXiv:1506.04214", "citeRegEx": "Shi,? \\Q2015\\E", "shortCiteRegEx": "Shi", "year": 2015}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Srivastava"], "venue": "The Journal of Machine Learning Research", "citeRegEx": "Srivastava,? \\Q2014\\E", "shortCiteRegEx": "Srivastava", "year": 2014}, {"title": "Learning multilevel distributed representations for high-dimensional sequences", "author": ["Sutskever", "I. Hinton 2007] Sutskever", "G.E. Hinton"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Sutskever et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2007}, {"title": "The recurrent temporal restricted boltzmann machine", "author": ["Hinton Sutskever", "I. Taylor 2009] Sutskever", "G.E. Hinton", "G.W. Taylor"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Sutskever et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2009}, {"title": "Deep neural networks for object detection", "author": ["Toshev Szegedy", "C. Erhan 2013] Szegedy", "A. Toshev", "D. Erhan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Szegedy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2013}, {"title": "Object tracking: A survey. Acm computing surveys (CSUR) 38(4):13", "author": ["Javed Yilmaz", "A. Shah 2006] Yilmaz", "O. Javed", "M. Shah"], "venue": null, "citeRegEx": "Yilmaz et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Yilmaz et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 0, "context": "Like many approaches to object tracking, our model is inspired by Bayesian filtering (Chen 2003).", "startOffset": 85, "endOffset": 96}, {"referenceID": 10, "context": "The methods such as the Hidden Markov Model (Rabiner 1989) are therefore not directly applicable.", "startOffset": 44, "endOffset": 58}, {"referenceID": 5, "context": "The Kalman filter (Kalman 1960), for example, assumes a multivariate normal distribution to represent the belief over the latent state leading to the well-known prediction/update equations but limiting its expressive power.", "startOffset": 18, "endOffset": 31}], "year": 2016, "abstractText": "This paper presents to the best of our knowledge the first end-to-end object tracking approach which directly maps from raw sensor input to object tracks in sensor space without requiring any feature engineering or system identification in the form of plant or sensor models. Specifically, our system accepts a stream of raw sensor data at one end and, in real-time, produces an estimate of the entire environment state at the output including even occluded objects. We achieve this by framing the problem as a deep learning task and exploit sequence models in the form of recurrent neural networks to learn a mapping from sensor measurements to object tracks. In particular, we propose a learning method based on a form of input dropout which allows learning in an unsupervised manner, only based on raw, occluded sensor data without access to ground-truth annotations. We demonstrate our approach using a synthetic dataset designed to mimic the task of tracking objects in 2D laser data \u2013 as commonly encountered in robotics applications \u2013 and show that it learns to track many dynamic objects despite occlusions and the presence of sensor noise.", "creator": "LaTeX with hyperref package"}}}