{"id": "1602.01064", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Feb-2016", "title": "Minimum Regret Search for Single- and Multi-Task Optimization", "abstract": "We propose minimum regret search (MRS), a novel acquisition function for Bayesian optimization. MRS bears similarities with information-theoretic approaches such as entropy search (ES). However, while ES aims in each query at maximizing the information gain with respect to the global maximum, MRS aims at minimizing the expected immediate regret of its ultimate recommendation for the optimum. While empirically ES and MRS perform similar in most of the cases, MRS produces fewer outliers with high regret than ES. We provide empirical results both for a synthetic single-task optimization problem as well as for a simulated multi-task robotic control problem.", "histories": [["v1", "Tue, 2 Feb 2016 19:58:11 GMT  (1177kb,D)", "https://arxiv.org/abs/1602.01064v1", null], ["v2", "Tue, 9 Feb 2016 18:58:45 GMT  (1171kb,D)", "http://arxiv.org/abs/1602.01064v2", "Revising Section 3.1"], ["v3", "Tue, 24 May 2016 06:57:30 GMT  (1542kb,D)", "http://arxiv.org/abs/1602.01064v3", "Final version for ICML 2016"]], "reviews": [], "SUBJECTS": "stat.ML cs.IT cs.LG cs.RO math.IT", "authors": ["jan hendrik metzen"], "accepted": true, "id": "1602.01064"}, "pdf": {"name": "1602.01064.pdf", "metadata": {"source": "META", "title": "Minimum Regret Search for Single- and Multi-Task Optimization", "authors": ["Jan Hendrik Metzen"], "emails": ["JANMETZEN@MAILBOX.ORG"], "sections": [{"heading": "1. INTRODUCTION", "text": "Bayesian Optimization (BO, Shahriari et al., 2016) refers to a sequential, model-based, global approach to optimizing black box functions. It is particularly well suited for problems that are non-convex, do not necessarily provide derivatives, are more expensive to evaluate (either mathematically, economically, or morally), and can potentially be noisy. Under these conditions, there is typically no guarantee of finding the true optimum of the function with a finite number of function evaluations. Instead, the goal is often to find a solution that has a small simple regret (MRbeck et al., 2009) with respect to true optimum, where simple regret denotes the difference between the true optimal functional value and the functional value of the \"solution\" after a finite number of function evaluations. BO aims to find such a solution of small simple regret while minimizing the number of evaluations of the expensive target function."}, {"heading": "2. BACKGROUND", "text": "In this section, we provide a brief overview of Bayesian Optimization (BO). We refer to Shahriari et al. (2016) for a more up-to-date, comprehensive review of BO. BO can be applied to black box optimization problems, which typically optimize an objective function f: X \u2192 R to a limited amount of X-RD. Unlike most other black box optimization methods, BO is a global method that uses all previous evaluations of f (x), rather than using only a subset of history to approximate a local gradient or essian. To do this, BO maintains a probabilistic model for f (x), typically a Gaussian process (GP, Rasmussen & Williams, 2006), and uses this model to decide on which xn + 1 the function f is evaluated. Assume we have already queried n datapoints and monitored their (noisy) function values."}, {"heading": "3. MINIMUM REGRET SEARCH", "text": "Information-based strategies for Bayesian optimization such as ES and PES have performed well empirically, but as we discuss in Section 3.3, their internal goal of minimizing uncertainty in the location of the optimizer x?, i.e. minimizing the differential entropy of p?, is actually (albeit related) different from the common external goal of minimizing the simple regret of x-N, the recommendation of BO for x-N after N attempts. We define the simple regret of x-N as Rf (x-N) = f (x-N) = maxx f (x-N) \u2212 f (x-N). Clearly x? has zero and thus minimal simple regret, but a query that leads to a maximum reduction of H (x-N) is not necessarily the one that also leads to the maximum reduction of the expected simple regret. In this section, we suggest the search for minimum regret (MRS) that explicitly aims to explicitly express the expected regret."}, {"heading": "3.1. Formulation", "text": "It is about the question to what extent it is actually about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question, to what extent it is about the question,"}, {"heading": "3.2. Approximation", "text": "Since several quantities in the MRS cannot be calculated in a closed form, we resort to similar discretizations and approximations as suggested by Hennig & Schuler (2012) for entropy search; we focus here on sampling-based approximations; for an alternative way of approximating Ep (f) based on expectation propagation, we refer to Hennig & Schuler (2012); first, we approach Ep (f) by taking five Monte Carlo samples from p (f), which is easy in the case of GPs; second, we approach Ey | p (f), xq by taking ny Monte Carlo samples from p (f) from the predictive distribution xq; and third, we discredit p? to a finite number of no-representation points selected from a non-uniform measurement, which turns Ex-p? n into a weighted sum in the definition of MRS (xq)."}, {"heading": "3.3. Illustration", "text": "Figure 1 shows an illustration of different acquisition functions on a simple one-dimensional target function = 1.5 due to the low acquisition functions = 1. The left figure shows a hypothetical GP posterior (illustrated by its mean and default deviation) for the length scale l = 0.75 and the resulting probability that x is the optimum of f = 0.07. Furthermore, the expected simple repentance of the selection of x designated by ER (x) is shown. The minimum of ER (x) and the maximum of p? are both at x = 1.5. However, the expected repentance of x is approximately ER (x) = 0.07. We record E [max (f (x) \u2212 f (x), 0) in order to shed additional light on situations where x = 1.5 would generate a significant repentance: This quantity shows that most of the expected repentance of x effects comes from situations where the \"true\" optimum \"range of 3.5 can be explained broadly by the optimum of this GP observation at the same time."}, {"heading": "4. MULTI-TASK MINIMUM REGRET SEARCH", "text": "Several enhancements to Bayesian optimization for multi-task learning have been proposed, both for discrete tasks (Krause & Ong, 2011) and for continuous tasks (Metzen, 2015); multi-task BO has been shown to efficiently learn about a number of discrete tasks at the same time (Krause & Ong, 2011); to enable the transfer of knowledge about cheaper tasks to more expensive tasks (Swersky et al., 2013); and to achieve performance on low-dimensional contextual political search problems (Metzen et al., 2015), especially in combination with active learning (Metzen, 2015); in this section we focus on multi-task BO for a continuous set of tasks; a similar enhancement for discrete multi-task learning would be straightforward; a continuous set of tasks is encountered, for example, when applying BO to contextual political search (see section 2)."}, {"heading": "5. EXPERMENTS", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1. Synthetic Single-Task Benchmark", "text": "In the first phase of the experiment, we perform a similar analysis to Hennig & Schuler (2012, Section 3.1): We compare different algorithms on a number of individual functions evaluated by a generative model, namely the same GPbased model used by the optimization internally as a surrogate. (This excludes model shifts and undesirable biases that can be introduced by resorting to common handmade test functions.) Specifically, we select the parameter space to match the two-dimensional unit X = [0, 1] 2 and generate test functions by sampling 250 function values shared by a GP with an isotropic RBF kernel of the length scale l = 0.1 and unit signal variance. A GP is adjusted to these function values and the resulting posterior mean is used as a test function. In addition, Gaussian Noise with standard deviations (10 \u2212 3) is added to each observation."}, {"heading": "5.2. Multi-Task Robotic Behavior Learning", "text": "We present the results of the simulated robot control task used by Metzen (2015), in which the robot arm COMPI (Bargsten & de Gea, 2015) is used to throw a ball at a target on the ground encoded in a two-dimensional context vector, the target area is S = [1, 2,5] m \u00b7 [-1, 1] m and the robot arm is mounted at the origin (0, 0) of this coordinate system \u2212 contexts are randomly uniformly encoded by S. The low-level policy is a common space of dynamic motion primitives (DMP, Ijspeert et al., 2013) with pre-selected starting and target angles for each joint and all DMP weights set to 0. These DMP results when throwing a ball so that it hits the ground near the center of the target area. Adaptation to different target positions is achieved by modifying the parameters: The first component, the learning area, the DMP, the execution time of the DMP is determined."}, {"heading": "6. DISCUSSION AND CONCLUSION", "text": "We have empirically compared MRS with other acquisition capabilities based on a synthetic optimization problem with only one task and a simulated robot control problem with multiple tasks. Results suggest that MRS performs well compared to the other approaches and less likely to elicit a high simple regret than ES, since its goal is explicitly aimed at minimizing regret. However, an empirical comparison with PES remains future work. As PES has the same goal as ES (minimizing H (x?))), it is likely to have the same deficit in ignoring areas that have a low probability of p? but could still cause a large potential regret. Unlike ES and MRS, PES allows formal treatment of GP hyperparameters, which may make it more sample efficient. Possible future research approaches to GP hyperparameter treatment and more efficient approaches to MRS-12S would therefore be worthwhile to look for a more interesting basis for MRS-12S."}, {"heading": "A. Synthetic Single-Task Benchmark with Model Mismatch", "text": "We present results for an identical constellation as reported in Section 5.1, with the only difference that the test functions were scanned by a GP with a rational quadratic constellation with length scale l = 0.1 and scale mix \u03b1 = 1.0. The kernel used in the GP replacement model is not modified, i.e. an RBF kernel with length scale l = 0.1 is used. Thus, since a different type of kernel test functions and replacement model rule, we have a model deviation that would be common in real-world problems. Figure 5 summarizes the results of the experiment. Interestingly, in contrast to the experiment without model deviation for this constellation, there are also significant differences in the mean simple regret between MRS and ES: While ES initially performs slightly better, it is exceeded by MRS for N > 60. We suspect that this is due to the fact that ES tends to examine more locally than S."}], "references": [{"title": "COMPI: Development of a 6-DOF compliant robot arm for human-robot cooperation", "author": ["Bargsten", "Vinzenz", "de Gea", "Jose"], "venue": "In Proceedings of the 8th International Workshop on Human-Friendly Robotics (HFR-2015)", "citeRegEx": "Bargsten et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bargsten et al\\.", "year": 2015}, {"title": "Algorithms for Hyper-Parameter Optimization", "author": ["Bergstra", "James", "Bardenet", "Remi", "Bengio", "Yoshua", "Kegl", "Balazs"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Bergstra et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2011}, {"title": "Pure Exploration in Multi-armed Bandits Problems", "author": ["Bubeck", "S\u00e9bastien", "Munos", "R\u00e9mi", "Stoltz", "Gilles"], "venue": null, "citeRegEx": "Bubeck et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bubeck et al\\.", "year": 2009}, {"title": "A Limited-Memory Algorithm for Bound Constrained Optimization", "author": ["Byrd", "Richard H", "Lu", "Peihuang", "Nocedal", "Jorge", "Zhu", "Ciyou"], "venue": "SIAM Journal on Scientific Computing,", "citeRegEx": "Byrd et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Byrd et al\\.", "year": 1995}, {"title": "Bayesian Optimization for Learning Gaits under Uncertainty", "author": ["Calandra", "Roberto", "Seyfarth", "Andr", "Peters", "Jan", "Deisenroth", "Marc P"], "venue": "Annals of Mathematics and Artificial Intelligence (AMAI),", "citeRegEx": "Calandra et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Calandra et al\\.", "year": 2015}, {"title": "A Survey on Policy Search for Robotics", "author": ["Deisenroth", "Marc Peter", "Neumann", "Gerhard", "Peters", "Jan"], "venue": "Foundations and Trends in Robotics,", "citeRegEx": "Deisenroth et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Deisenroth et al\\.", "year": 2013}, {"title": "The Knowledge-Gradient Policy for Correlated Normal Beliefs", "author": ["Frazier", "Peter", "Powell", "Warren", "Dayanik", "Savas"], "venue": "INFORMS Journal on Computing,", "citeRegEx": "Frazier et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Frazier et al\\.", "year": 2009}, {"title": "Entropy Search for Information-Efficient", "author": ["Hennig", "Philipp", "Schuler", "Christian J"], "venue": "Global Optimization. JMLR,", "citeRegEx": "Hennig et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hennig et al\\.", "year": 2012}, {"title": "Predictive Entropy Search for Efficient Global Optimization of Black-box Functions", "author": ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", "Hoffman", "Matthew W", "Ghahramani", "Zoubin"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Hern\u00e1ndez.Lobato et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hern\u00e1ndez.Lobato et al\\.", "year": 2014}, {"title": "Dynamical Movement Primitives: Learning Attractor Models for Motor Behaviors", "author": ["Ijspeert", "Auke Jan", "Nakanishi", "Jun", "Hoffmann", "Heiko", "Pastor", "Peter", "Schaal", "Stefan"], "venue": "Neural Computation,", "citeRegEx": "Ijspeert et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ijspeert et al\\.", "year": 2013}, {"title": "Lipschitzian optimization without the Lipschitz constant", "author": ["D.R. Jones", "C.D. Perttunen", "B.E. Stuckman"], "venue": "Journal of Optimization Theory and Applications,", "citeRegEx": "Jones et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1993}, {"title": "A Taxonomy of Global Optimization Methods Based on Response Surfaces", "author": ["Jones", "Donald R"], "venue": "Journal of Global Optimization,", "citeRegEx": "Jones and R.,? \\Q2001\\E", "shortCiteRegEx": "Jones and R.", "year": 2001}, {"title": "Methods of Reducing Sample Size in Monte Carlo Computations", "author": ["H. Kahn", "A.W. Marshall"], "venue": "Journal of the Operations Research Society of America,", "citeRegEx": "Kahn and Marshall,? \\Q1953\\E", "shortCiteRegEx": "Kahn and Marshall", "year": 1953}, {"title": "Contextual Gaussian Process Bandit Optimization", "author": ["Krause", "Andreas", "Ong", "Cheng S"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Krause et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2011}, {"title": "Combining active learning and reactive control for robot grasping", "author": ["Kroemer", "O. B", "R. Detry", "J. Piater", "J. Peters"], "venue": "Robot. Auton. Syst.,", "citeRegEx": "Kroemer et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kroemer et al\\.", "year": 2010}, {"title": "A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the Presence of Noise", "author": ["H.J. Kushner"], "venue": "Journal of Fluids Engineering,", "citeRegEx": "Kushner,? \\Q1964\\E", "shortCiteRegEx": "Kushner", "year": 1964}, {"title": "Automatic gait optimization with gaussian process regression", "author": ["Lizotte", "Daniel", "Wang", "Tao", "Bowling", "Michael", "Schuurmans", "Dale"], "venue": null, "citeRegEx": "Lizotte et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Lizotte et al\\.", "year": 2007}, {"title": "Bayesian optimisation for intelligent environmental monitoring", "author": ["R. Marchant", "F. Ramos"], "venue": "In Intelligent Robots and Systems (IROS),", "citeRegEx": "Marchant and Ramos,? \\Q2012\\E", "shortCiteRegEx": "Marchant and Ramos", "year": 2012}, {"title": "Active Contextual Entropy Search", "author": ["Metzen", "Jan Hendrik"], "venue": "In Proceedings of NIPS Workshop on Bayesian Optimization,", "citeRegEx": "Metzen and Hendrik.,? \\Q2015\\E", "shortCiteRegEx": "Metzen and Hendrik.", "year": 2015}, {"title": "Bayesian Optimization for Contextual Policy Search", "author": ["Metzen", "Jan Hendrik", "Fabisch", "Alexander", "Hansen", "Jonas"], "venue": "In Proceedings of the Second Machine Learning in Planning and Control of Robot Motion Workshop.,", "citeRegEx": "Metzen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Metzen et al\\.", "year": 2015}, {"title": "The application of Bayesian methods for seeking the extremum", "author": ["J. Mockus", "V. Tiesis", "A. Zilinskas"], "venue": "Toward Global Optimization,", "citeRegEx": "Mockus et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Mockus et al\\.", "year": 1978}, {"title": "Gaussian Processes for Machine Learning", "author": ["Rasmussen", "Carl", "Williams", "Christopher"], "venue": null, "citeRegEx": "Rasmussen et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Rasmussen et al\\.", "year": 2006}, {"title": "Taking the Human Out of the Loop: A Review of Bayesian Optimization", "author": ["B. Shahriari", "K. Swersky", "Z. Wang", "R.P. Adams", "N. de Freitas"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Shahriari et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shahriari et al\\.", "year": 2016}, {"title": "An Entropy Search Portfolio for Bayesian Optimization", "author": ["Shahriari", "Bobak", "Wang", "Ziyu", "Hoffman", "Matthew W", "Bouchard-C\u00f4t\u00e9", "Alexandre", "de Freitas", "Nando"], "venue": "In NIPS workshop on Bayesian optimization,", "citeRegEx": "Shahriari et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shahriari et al\\.", "year": 2014}, {"title": "Practical Bayesian Optimization of Machine Learning Algorithms", "author": ["Snoek", "Jasper", "Larochelle", "Hugo", "Adams", "Ryan P"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["Srinivas", "Niranjan", "Krause", "Andreas", "Seeger", "Matthias"], "venue": "In Proceedings of the 27th International Conference on Machine Learning,", "citeRegEx": "Srinivas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "MultiTask Bayesian Optimization", "author": ["Swersky", "Kevin", "Snoek", "Jasper", "Adams", "Ryan P"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Swersky et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Swersky et al\\.", "year": 2013}, {"title": "An informational approach to the global optimization of expensive-to-evaluate functions", "author": ["Villemonteix", "Julien", "Vazquez", "Emmanuel", "Walter", "Eric"], "venue": "Journal of Global Optimization,", "citeRegEx": "Villemonteix et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Villemonteix et al\\.", "year": 2008}], "referenceMentions": [{"referenceID": 2, "context": "Instead, one often aims at finding a solution which has small simple regret (Bubeck et al., 2009) with regard to the true optimum, where simple regret denotes the difference of the true optimal function value and the function value of the \u201csolution\u201d selected", "startOffset": 76, "endOffset": 97}, {"referenceID": 1, "context": "BO has been applied to a diverse set of problems, ranging from hyperparameter optimization of machine learning models (Bergstra et al., 2011; Snoek et al., 2012) over robotics (Calandra et al.", "startOffset": 118, "endOffset": 161}, {"referenceID": 24, "context": "BO has been applied to a diverse set of problems, ranging from hyperparameter optimization of machine learning models (Bergstra et al., 2011; Snoek et al., 2012) over robotics (Calandra et al.", "startOffset": 118, "endOffset": 161}, {"referenceID": 4, "context": ", 2012) over robotics (Calandra et al., 2015; Lizotte et al., 2007; Kroemer et al., 2010; Marco et al., 2015) to sensor networks (Srinivas et al.", "startOffset": 22, "endOffset": 109}, {"referenceID": 16, "context": ", 2012) over robotics (Calandra et al., 2015; Lizotte et al., 2007; Kroemer et al., 2010; Marco et al., 2015) to sensor networks (Srinivas et al.", "startOffset": 22, "endOffset": 109}, {"referenceID": 14, "context": ", 2012) over robotics (Calandra et al., 2015; Lizotte et al., 2007; Kroemer et al., 2010; Marco et al., 2015) to sensor networks (Srinivas et al.", "startOffset": 22, "endOffset": 109}, {"referenceID": 25, "context": ", 2015) to sensor networks (Srinivas et al., 2010) and environmental monitoring (Marchant & Ramos, 2012).", "startOffset": 27, "endOffset": 50}, {"referenceID": 1, "context": "BO has been applied to a diverse set of problems, ranging from hyperparameter optimization of machine learning models (Bergstra et al., 2011; Snoek et al., 2012) over robotics (Calandra et al., 2015; Lizotte et al., 2007; Kroemer et al., 2010; Marco et al., 2015) to sensor networks (Srinivas et al., 2010) and environmental monitoring (Marchant & Ramos, 2012). For a more comprehensive overview of application areas, we refer to Shahriari et al. (2016).", "startOffset": 119, "endOffset": 454}, {"referenceID": 27, "context": "In the latter class, the group of entropy search-based approaches (Villemonteix et al., 2008; Hennig & Schuler, 2012; Hern\u00e1ndez-Lobato et al., 2014), which aims at maximizing the information gain regarding the true optimum, has achieved state-of-the-art performance on a number of synthetic and real-world problems.", "startOffset": 66, "endOffset": 148}, {"referenceID": 8, "context": "In the latter class, the group of entropy search-based approaches (Villemonteix et al., 2008; Hennig & Schuler, 2012; Hern\u00e1ndez-Lobato et al., 2014), which aims at maximizing the information gain regarding the true optimum, has achieved state-of-the-art performance on a number of synthetic and real-world problems.", "startOffset": 66, "endOffset": 148}, {"referenceID": 22, "context": "We refer to Shahriari et al. (2016) for a recent more extensive review of BO.", "startOffset": 12, "endOffset": 36}, {"referenceID": 10, "context": "A common strategy is to use DIRECT (Jones et al., 1993) to find the approximate global maximum, followed by L-BFGS (Byrd et al.", "startOffset": 35, "endOffset": 55}, {"referenceID": 3, "context": ", 1993) to find the approximate global maximum, followed by L-BFGS (Byrd et al., 1995) to refine it.", "startOffset": 67, "endOffset": 86}, {"referenceID": 25, "context": "Srinivas et al. (2010) proposed GP-UCB, which entails a specific schedule for \u03ban that yields provable cumulative regret bounds.", "startOffset": 0, "endOffset": 23}, {"referenceID": 6, "context": "A generalization of EI is the knowledge gradient factor (Frazier et al., 2009), which can better handle noisy observations, which impede the estimation of the incumbent.", "startOffset": 56, "endOffset": 78}, {"referenceID": 8, "context": "The third class of acquisition functions are informationbased policies, which entail Thompson sampling and entropy search (ES, Villemonteix et al., 2008; Hennig & Schuler, 2012; Hern\u00e1ndez-Lobato et al., 2014).", "startOffset": 122, "endOffset": 208}, {"referenceID": 27, "context": "Computing aES directly is intractable for continuous spaces X ; prior work has discretized X and used either Monte Carlo sampling (Villemonteix et al., 2008) or expectation propagation (Hennig & Schuler, 2012).", "startOffset": 130, "endOffset": 157}, {"referenceID": 5, "context": "We refer to Deisenroth et al. (2013) for a recent overview of (contextual) policy search approaches in robotics.", "startOffset": 12, "endOffset": 37}, {"referenceID": 26, "context": "Multi-task BO has been demonstrated to learn efficiently about a set of discrete tasks concurrently (Krause & Ong, 2011), to allow transferring knowledge learned on cheaper tasks to more expensive tasks (Swersky et al., 2013), and to yield state-of-the-art performance on low-dimensional contextual policy search problems (Metzen et al.", "startOffset": 203, "endOffset": 225}, {"referenceID": 19, "context": ", 2013), and to yield state-of-the-art performance on low-dimensional contextual policy search problems (Metzen et al., 2015), in particular when combined with active learning (Metzen, 2015).", "startOffset": 104, "endOffset": 125}, {"referenceID": 19, "context": "We follow the formulation of BO-CPS (Metzen et al., 2015) and adapt it for MRS were required.", "startOffset": 36, "endOffset": 57}, {"referenceID": 25, "context": "In contrast, the acquisition functions GP-UCB (Srinivas et al., 2010) and ES (Metzen et al.", "startOffset": 46, "endOffset": 69}, {"referenceID": 19, "context": ", 2010) and ES (Metzen et al., 2015) have been extended straightforwardly and the same approach applies also to MRS.", "startOffset": 15, "endOffset": 36}, {"referenceID": 8, "context": "These results are roughly in correspondence with prior results (Hennig & Schuler, 2012; Hern\u00e1ndez-Lobato et al., 2014) on the same task; note, however, that Hern\u00e1ndez-Lobato et al.", "startOffset": 63, "endOffset": 118}, {"referenceID": 8, "context": "These results are roughly in correspondence with prior results (Hennig & Schuler, 2012; Hern\u00e1ndez-Lobato et al., 2014) on the same task; note, however, that Hern\u00e1ndez-Lobato et al. (2014) used a lower noise level and thus, absolute values are not comparable.", "startOffset": 88, "endOffset": 188}, {"referenceID": 8, "context": "Thus, predictive entropy search (Hern\u00e1ndez-Lobato et al., 2014) would likely be affected by the same deficiency.", "startOffset": 32, "endOffset": 63}, {"referenceID": 19, "context": "This is because the execution time and first joint allow already adapting the throw to different contexts (Metzen et al., 2015); controlling more joints mostly adds additional search dimensions.", "startOffset": 106, "endOffset": 127}, {"referenceID": 23, "context": "Moreover, we consider MRS to be a valuable addition to the set of base strategies in a portfolio-based BO approach (Shahriari et al., 2014).", "startOffset": 115, "endOffset": 139}], "year": 2016, "abstractText": "We propose minimum regret search (MRS), a novel acquisition function for Bayesian optimization. MRS bears similarities with information-theoretic approaches such as entropy search (ES). However, while ES aims in each query at maximizing the information gain with respect to the global maximum, MRS aims at minimizing the expected simple regret of its ultimate recommendation for the optimum. While empirically ES and MRS perform similar in most of the cases, MRS produces fewer outliers with high simple regret than ES. We provide empirical results both for a synthetic single-task optimization problem as well as for a simulated multi-task robotic control problem.", "creator": "LaTeX with hyperref package"}}}