{"id": "1602.02196", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2016", "title": "BISTRO: An Efficient Relaxation-Based Method for Contextual Bandits", "abstract": "We present efficient algorithms for the problem of contextual bandits with i.i.d. covariates, an arbitrary sequence of rewards, and an arbitrary class of policies. Our algorithm BISTRO requires d calls to the empirical risk minimization (ERM) oracle per round, where d is the number of actions. The method uses unlabeled data to make the problem computationally simple. When the ERM problem itself is computationally hard, we extend the approach by employing multiplicative approximation algorithms for the ERM. The integrality gap of the relaxation only enters in the regret bound rather than the benchmark. Finally, we show that the adversarial version of the contextual bandit problem is learnable (and efficient) whenever the full-information supervised online learning problem has a non-trivial regret guarantee (and efficient).", "histories": [["v1", "Sat, 6 Feb 2016 00:34:59 GMT  (22kb)", "http://arxiv.org/abs/1602.02196v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["alexander rakhlin", "karthik sridharan"], "accepted": true, "id": "1602.02196"}, "pdf": {"name": "1602.02196.pdf", "metadata": {"source": "CRF", "title": "BISTRO: An Efficient Relaxation-Based Method for Contextual Bandits", "authors": ["Alexander Rakhlin", "Karthik Sridharan"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 160 2.02 196v 1 [cs.L G] 6F eb"}, {"heading": "1 Introduction", "text": "In fact, we are able to move, to be able to be able to be able to be able to be able to be."}, {"heading": "2 Notation", "text": "We denote [d] {1,.., d} and a1: t {a1,.., at}. Let us take the probability simplex over d-coordinates. The vector of ones is denoted by 1 and an indicator of event A by I {A}. For a matrix M we use Mt to refer to its t-th column."}, {"heading": "3 Setup", "text": "Let us remember the online protocol. At each round t [n] we observe lateral information xt [X], forecast y [t] qt [c] qt [d] and observe feedback ct (y) for some ct [0,1].Given x1: n, it is convenient to work with a matrix representation of class F projected onto this data. (2) Let M [x1: n] = {Mf: f [xn]) which we collect as matrix Mf, defined as Mf (j, t) = I {f (xt) = j}. (2) Let M [x1: n] = {Mf: f \u00b2 F} denote the collection of matrices. (The hat on M] reminds us of the dependence of this set on matrix1: n, even if it is not explicitly mentioned."}, {"heading": "4 Relaxations for Partial Information", "text": "Let us note the information obtained in round t as a tuple of It (xt, qt, y-t, ct) = (xt, qt, y-t, ct (y-t)), bearing in mind that xt is revealed before choosing qt. In full information problems, it contains the vector ct, but not so in our bandit case. For partial information problems, it is crucial to include qt in the definition of It, in addition to the value ct (y-t). A partial information recovery Rel () is a function that maps (I1,.., It) to a real value, for each t-x. We say that partial information recovery Relaxation Rel (I1,.) is permissible if it applies to all t-Q1,."}, {"heading": "5 The BISTRO Algorithm", "text": "For each t (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e (n) e) e (n) e (n) e (n) e (n) e) e (n) e (n) e (n) e (e) e (n) e) e (n) e (n) e (n) e (n) e (n) e (n) e) e (e) e (e) e) e (e) e (e) e) e (e) e (n) e (e) e (e) e (e) e) e (e) e (n) e (e) e) e (e) e (e) e (n) e (e) e (n) e) e (e) e (e) e (n) e) e (e) e (e) e (n) e) e (e) e (e) e) e (n) e (e) e) e (e) e (e) e) e (e) e) e (n (e) e) e (e) e) e (e) e) e (e) e (e) e) e (e) e) e (e) e) e (e (e) e) e (e) e) e (e (e) e) e (e) e) e (e) e) e (e) e (e) e (e) e (e) e) e (e) e) e (e (e) e) e) e (e (e (e) e) e (e) e) e (e) e) e (e (e) e) e (e (e) e) e (e) e (e) e) e (e (e) e) e (e) e) e (e (e (e) e (e) e) e) e (e (n (e) e) e (e) e) e ("}, {"heading": "6 Extensions", "text": "In this section, we will outline several enhancements to BISTRO. In particular, we will show how to include additional data-based constraints and how to use further optimization-based relaxations (such as LP or SDP) to obtain polynomial time methods for the ERM solution (or regularized ERM solution). We will show that one reaches a limit of regret that is only worsened by a factor related to the integrity gap in the integral program voltage. In terms of both computational and predictive performance, these techniques extend the applicability of BISTRO."}, {"heading": "6.1 Data-dependent policy classes", "text": "A verification of the evidence shows that all steps are passed through when one defines remorse in (1) with respect to a data-dependent class F [x1: n]. (10) In this case, we associate Mf as defined in (2) with each f-F [x1: n] and take M-F = {Mf: f-F [x1: n]. The BISTRO algorithm is then identical, while the upper limit of regret in Theorem 2 now replaces ER (F; x1: n) with ER (F [x1: n]; x1: n). The ability to change the set of guidelines according to the actual data allows an additional degree of flexibility. This flexibility can be realized by additional global constraints with respect to x1: n, as we show in the next sections."}, {"heading": "6.2 Data-based constraints", "text": "In fact, most of them are able to move to another world, in which they are able, in which they are able to move, and in which they are able to move."}, {"heading": "6.3 Regularized relaxation", "text": "Let FK [x1: n] = {f = F: C (f; x1: n) \u2264 K} be the limited set for a certain value K and a limited function C, as in the previous section. Let us write C (M; x1: n) for the matrix representation the corresponding f = F. The following form of relaxation might be more suitable for approach algorithms than the one in which the constraint is strictly enforced. Lemma 4. For any other way, K > 0, the partial information relaxationE (x) t + 1: n sup M: n sup M (n) the constraint Y (M; x1: n) the alternative solution Y + (n \u2212 t) is permissible, where M (13) is the way the matrix representation of the original (unlimited) set of policy."}, {"heading": "6.4 Optimization-based relaxations", "text": "In order to solve the problem, we have to ask ourselves whether there is a problem in which we choose such a solution at all. (...) The idea is that we choose such a solution. (...) The question that we choose such a solution is that we choose such a solution. (...) The question that we choose to choose such a solution is whether we choose to choose such a solution. (...) The question that we choose to choose such a solution is not whether we choose to choose such a solution. (...) The question that we choose to choose such a solution is not. (...) The question that we choose to choose such a solution is not. (...) The question that we choose to choose such a solution is not. (...) The question that we choose to choose such a solution is not. (...) The question that we choose to choose such a solution is not. (...) The question that we choose to choose such a solution is not. (...)"}, {"heading": "6.5 Adversarial contexts", "text": "Suppose we do not make assumptions about the evolution of the problem, which can now be treated as a worst-case problem. (This problem is the complete information we want), and therefore one cannot hope that the problem of complete information can be solved, if there is complete information relaxation, then one can use it to solve the problem of contextual contextualization. (In addition, it is based on the work of [RSS12, FRS15], all known online learning methods based on relativization. (Hence, we essentially prove that a problem is learnable online), then it is learnable in the adversarial contextual setting, then it is learnable."}, {"heading": "7 Open Problems and Future Directions", "text": "In the case of inequality (22), we decouple the distribution q \u2032 t from qt, and this seems to be the source of the lots, at least in the analysis. A more detailed analysis in this step could solve the problem. It is unclear what kind of structure of F can be used to improve the calculation and / or guarantees for BISTROs. Under structural assumptions about F, one can generate sufficient statistics for the information I1: t and thus avoid retaining all estimates c-t. Of course, this is the case for non-context bandits where the sum between c-t is sufficient (at least as evidenced by existing near-optimal bandit methods). An interesting method of investigation is to examine the more general case when x-s are drawn from a stochastic process with a parameterized form. Then, one can try to estimate the parameters of the process on-the-go and use the future data for random evaluations."}, {"heading": "8 Proofs", "text": "The proof for Lemma 1. In the proof we use the abbreviation. nt = 1 denotes the repeated use of the operators within the brackets from t = 1 to n. As an example, the order of the operators E x1 max c1 E x2 max c2 [G (x1, c1, x2, c2)] acting on the function G is abbreviated as Ext maxct 2t = 1 [G (x1, c1, x2, c2)]. Leave q1,., qn is a valid strategy. The expected regret of this strategy can be expressed by E [Reg] \u2264 sup c1: n E [Reg] \u2264 sup ct n ct n ct n ct n t = 1 qTt ct qTt ct qTt ct \u2212 inf f f y suct t = 1 f (xt) Tct t as the inequality of Jensen."}, {"heading": "A Proof of Theorem 2", "text": "It is not possible for there to be an agreement. (...) It is not possible for there to be an agreement. (...) It is not possible. (...) It is not possible. (...) It is not possible. (...) It is not possible. (...) It is not possible. (...) It is not possible. (...) It is not possible. (...) It is not possible. (...) It is not possible. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...).). (...). (...). (...).). (...).). (...).). (...). (...).). (...).). (...).). (...).). (...).).). (...). (...).). (...).). (...).). (...).). (...). (...).). (...).). (...).). (...). (...). (...).). (...).). (...). (...). (...).). (...). (...). (...).).).). (...). (...). (...). (...).). (...).). (...). (...). (...).).).). (...). (...). (...).).). (...).).). (...). ("}], "references": [{"title": "The nonstochastic multiarmed bandit problem", "author": ["P. Auer", "N. Cesa-Bianchi", "Y. Freund", "R.E. Schapire"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Auer et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2002}, {"title": "Taming the monster: A fast and simple algorithm for contextual bandits", "author": ["A. Agarwal", "D. Hsu", "S. Kale", "J. Langford", "L. Li", "R.E. Schapire"], "venue": "arXiv preprint arXiv:1402.0555,", "citeRegEx": "Agarwal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2014}, {"title": "Contextual bandit algorithms with supervised learning guarantees", "author": ["A. Beygelzimer", "J. Langford", "L. Li", "L. Reyzin", "R.E. Schapire"], "venue": "In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics", "citeRegEx": "Beygelzimer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Beygelzimer et al\\.", "year": 2011}, {"title": "A linear programming formulation and approximation algorithms for the metric labeling problem", "author": ["C. Chekuri", "S. Khanna", "J. Naor", "L. Zosin"], "venue": "SIAM Journal on Discrete Mathematics,", "citeRegEx": "Chekuri et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Chekuri et al\\.", "year": 2004}, {"title": "Efficient optimal learning for contextual bandits", "author": ["M. Dudik", "D. Hsu", "S. Kale", "N. Karampatziakis", "J. Langford", "L. Reyzin", "T. Zhang"], "venue": "arXiv preprint arXiv:1106.2369,", "citeRegEx": "Dudik et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dudik et al\\.", "year": 2011}, {"title": "Adaptive online learning", "author": ["D. Foster", "A. Rakhlin", "K. Sridharan"], "venue": "In NIPS,", "citeRegEx": "Foster et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Foster et al\\.", "year": 2015}, {"title": "Newtron: an efficient bandit algorithm for online multiclass prediction", "author": ["E. Hazan", "S. Kale"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hazan and Kale.,? \\Q2011\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2011}, {"title": "Efficient bandit algorithms for online multiclass prediction", "author": ["S.M. Kakade", "S. Shalev-Shwartz", "A. Tewari"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Kakade et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2008}, {"title": "Approximation algorithms for classification problems with pairwise relationships: Metric labeling and markov random fields", "author": ["J. Kleinberg", "E. Tardos"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "Kleinberg and Tardos.,? \\Q2002\\E", "shortCiteRegEx": "Kleinberg and Tardos.", "year": 2002}, {"title": "Global optimization with polynomials and the problem of moments", "author": ["J. B Lasserre"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Lasserre.,? \\Q2001\\E", "shortCiteRegEx": "Lasserre.", "year": 2001}, {"title": "Hybrid stochastic-adversarial on-line learning", "author": ["A. Lazaric", "R. Munos"], "venue": "In Conference on Learning Theory,", "citeRegEx": "Lazaric and Munos.,? \\Q2009\\E", "shortCiteRegEx": "Lazaric and Munos.", "year": 2009}, {"title": "Asymptotically efficient adaptive allocation rules", "author": ["T.L. Lai", "H. Robbins"], "venue": "Advances in Applied Mathematics,", "citeRegEx": "Lai and Robbins.,? \\Q1985\\E", "shortCiteRegEx": "Lai and Robbins.", "year": 1985}, {"title": "The epoch-greedy algorithm for multi-armed bandits with side information", "author": ["J. Langford", "T. Zhang"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Langford and Zhang.,? \\Q2008\\E", "shortCiteRegEx": "Langford and Zhang.", "year": 2008}, {"title": "Tighter bounds for multi-armed bandits with expert advice", "author": ["H. B McMahan", "M. J Streeter"], "venue": "In COLT,", "citeRegEx": "McMahan and Streeter.,? \\Q2009\\E", "shortCiteRegEx": "McMahan and Streeter.", "year": 2009}, {"title": "Semidefinite programming relaxations for semialgebraic problems", "author": ["P.A. Parrilo"], "venue": "Mathematical programming,", "citeRegEx": "Parrilo.,? \\Q2003\\E", "shortCiteRegEx": "Parrilo.", "year": 2003}, {"title": "Hierarchies of relaxations for online prediction problems with evolving constraints", "author": ["A. Rakhlin", "K. Sridharan"], "venue": "In COLT,", "citeRegEx": "Rakhlin and Sridharan.,? \\Q2015\\E", "shortCiteRegEx": "Rakhlin and Sridharan.", "year": 2015}, {"title": "Relax and randomize: From value to algorithms", "author": ["A. Rakhlin", "O. Shamir", "K. Sridharan"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Rakhlin et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Rakhlin et al\\.", "year": 2012}], "referenceMentions": [], "year": 2016, "abstractText": "We present efficient algorithms for the problem of contextual bandits with i.i.d. covariates, an arbitrary sequence of rewards, and an arbitrary class of policies. Our algorithm BISTRO requires d calls to the empirical risk minimization (ERM) oracle per round, where d is the number of actions. The method uses unlabeled data to make the problem computationally simple. When the ERM problem itself is computationally hard, we extend the approach by employing multiplicative approximation algorithms for the ERM. The integrality gap of the relaxation only enters in the regret bound rather than the benchmark. Finally, we show that the adversarial version of the contextual bandit problem is learnable (and efficient) whenever the full-information supervised online learning problem has a non-trivial regret guarantee (and efficient).", "creator": "LaTeX with hyperref package"}}}