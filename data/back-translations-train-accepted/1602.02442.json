{"id": "1602.02442", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Feb-2016", "title": "A Simple Practical Accelerated Method for Finite Sums", "abstract": "We describe a novel optimization method for finite sums (such as empirical risk minimization problems) building on the recently introduced SAGA method. Our method achieves an accelerated convergence rate on strongly convex smooth problems, matching the conjectured optimal rate. Our method has only one parameter (a step size), and is radically simpler than other accelerated methods for finite sums.", "histories": [["v1", "Mon, 8 Feb 2016 00:24:01 GMT  (2996kb,D)", "https://arxiv.org/abs/1602.02442v1", "Draft"], ["v2", "Thu, 27 Oct 2016 23:18:05 GMT  (3000kb,D)", "http://arxiv.org/abs/1602.02442v2", null]], "COMMENTS": "Draft", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["aaron defazio"], "accepted": true, "id": "1602.02442"}, "pdf": {"name": "1602.02442.pdf", "metadata": {"source": "CRF", "title": "A Simple Practical Accelerated Method for Finite Sums", "authors": ["Aaron Defazio"], "emails": [], "sections": [{"heading": null, "text": "We describe a novel finite sum optimization method (such as empirical risk mitigation problems) that builds on the recently introduced SAGA method. Our method achieves an accelerated convergence rate for strongly convex smooth problems. Our method has only one parameter (one step variable) and is radically simpler than other accelerated finite sum methods. Furthermore, it can be applied when the terms are not smooth, resulting in a method that is applicable in many areas where operator splitting methods would traditionally be used. However, a large part of recent developments in optimization has focused on minimizing convex finite sums of the form: f (x) = 1n, which is a very general class of problems including empirical risk mitigation (ERM) as a special case. Any function h can be written in this form by specifying f1 (x) and fi = 0 for i 6 = 1."}, {"heading": "1 Algorithm", "text": "For convenience, we use the following compact notation: prox\u03b3i (x) = argminy {\u03b3fi (y) + 12 \u0445 x \u2212 y 2}. However, in many cases, this proximal operator can be calculated efficiently or in a closed form, see section 4 for details. Like SAGA, we can also select a table of gradients gi, one for each function fi. We designate the state of gi at the end of the step of gki. The iterate (our guess at the solution) at the end of the step is called xk. Startup x0 can be chosen at will be arbitrarily. The complete algorithm 1. The sum of gradients 1n i = 1g k i can be cached and efficiently updated at each step, and in most cases a complete vector for each step is stored."}, {"heading": "2 Relation to other approaches", "text": "Our method is most closely related to the SAGA method. To clarify the relationship, we can write the most important step of our method: xk + 1 = xk \u2212 \u03b3 [f \u2032 j (x k + 1) \u2212 gkj + 1n \u2211 i = 1 gki], whereas SAGA has a step of the form: xk + 1 = xk \u2212 \u03b3 [f \u2032 j (x k) \u2212 gkj + 1n \u2211 i = 1 gki]. The difference is the point at which the gradient of fj is evaluated. The proximal operator has the effect of evaluating the gradient at xk + 1 instead of xk. While there is a small difference on the surface, this change has profound effects. It allows the method to be applied directly to non-smooth problems with fixed increments, a property not shared by SAGA or other primary FIG methods. Furthermore, it allows for much larger increments to be used, which is why the method is likely."}, {"heading": "3 Theory", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Proximal operator bounds", "text": "In this section, let us define some simple limits from the theory of the proximal operator that we will use in this thesis. Let us define the short-hand proof p\u03b3f (x) = prox\u03b3f (x) and leave g\u03b3f (x) = 1 \u03b3 (x \u2212 p\u03b3f (x), so that p\u03b3f (x) = x \u2212 \u03b3g\u03b3f (x). Note that g\u03b3f (x) is a subgradient of f at point p\u03b3f (x). This relationship is known as the optimum condition of the proximal operator. Note that the evidence for the following two statements is in the supplementary material.Proposal 1. (Consolidation of solid non-expansivity under strong convexity) For each x, y Rd and each convex function f: Rd \u2192 R with strong convexity constant \u00b5 \u2265 0, < x \u2212 y, p\u03b3f (x) \u2212 p\u03b3f (y) district > (1 \u00b5pf)."}, {"heading": "In operator theory this property is known as (1 + \u00b5\u03b3)-cocoerciveness of p\u03b3f .", "text": "Proposition 2 (Moreau decompression) For each x-rd and each convexe function f: Rd \u2192 R with fennel conjugat f: p\u03b3f (x) = x-\u03b3p 1 \u03b3 f: p (x / \u03b3). (1) Let's also call our definition of g\u03b3f: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p: p:"}, {"heading": "3.2 Notation", "text": "In addition to the notation used in the description of the algorithm, we also specify a series of subgradients g \u0445 j, one for each component j at x *, which is chosen so that it is p = 1 g * j = 0. We also define vj = x * + g * j. Note that in solving x * we want to apply an approximate step for component j of the form: x * = prox\u03b3j (x * + g * j) = prox\u03b3j (vj).Lemma 4. (Technical problem required by the main proof) Under algorithm 1, taking into account the expectation of random selection of j, conditioning on xk and each Gki, we can bind the following internal product at step k: E \u00b2 [gkj \u2212 1n \u00b2 i = 1 gki] \u2212 g \u00b2 j, (xk \u2212 x \u00b2) + gkj \u2212 n \u00b2 g \u00b2 g \u00b2 g = 1 g \u00b2 g \u00b2."}, {"heading": "3.3 Main result", "text": "Theorem 5 (single step Lyapunov descent) We define the Lyapunov function T k of our algorithm (Point-SAGA) in step k as follows: T k = cn \u00b2 -2 + 4nL2 + 4nL2 + 4n 2L, the expectation of Tk + 1, via the random choice of j, conditioning on xk and each gki, is: E [T k + 1] \u2264 (1 \u2212 j) T k = 1 \u2212 1n 2L, the expectation of Tk + 1, via the random choice of j, conditioning on xk and each gki, is: E [T k + 1] \u2264 (1 \u2212 j), T k = 1 \u2212 2L, if each fi: Rd \u2192 R is L-smooth and strongly convex and 0 < p < L This is the same Lyapunov function as used by Hofmann and al. [2015].Proof."}, {"heading": "4 Implementation", "text": "A quick cython implementation is available on the author's website. Proximal operators Implementation of the proximal operator is straightforward for the most common binary classification and regression methods. We include details for calculating the proximal operators for the hinge, square and logistics losses in the supplementary material. Logistic loss does not have a proximal operator in closed form, but in practice can be calculated very efficiently using Newton's method based on a 1D sub-problem. If problems of a non-trivial dimensionality occur, the cost of the dot products is much higher in the main step than the cost of the proximal operator evaluation. We also detail how to handle a quadratic regulator within each semester within the prox operator that has a closed form in relation to the unregulated prox operator. Initialization Instead of specifying the gi = f effect prior to the start of the dual operator is usable."}, {"heading": "5 Experiments", "text": "We tested our algorithm, which we call Point-SAGA against SAGA [Defazio et al., 2014a], SDCA [Shalev-Shwartz and Zhang, 2013a], Pegasos / SGD [Shalev-Shwartz et al., 2011], and the Catalyst Acceleration Scheme [Lin et al., 2015]. SDCA was chosen as the internal algorithm for the Catalyst Scheme because it does not require a step size, making it the most practical of the variants. Catalysts applied to SDCA are essentially the same algorithms proposed in Shalev-Shwartz and Zhang. A single inner epoch was used for each SDCA invocation. Accelerated MISO and the primary-dual FIG method [Lan and Zhou, 2015] were excluded when we wanted to test the frugal problems, and they are not designed for that."}, {"heading": "A Proximal operators", "text": "For the most common binary classification and regression methods, the implementation of the proximal operator is straightforward. In this section, yj is the label or target for regression, and Xj is the data instance vector. In binary classification, we assume that yj, 1, 1,. Hinge loss: fj (z) = l (z; yj, Xj) = max {0, 1 \u2212 yj < z, Xj >}. The proximal operator has a closed form expression: prox.fj (z) = z \u2212 j.fj (z; yj, Xj) \u2212 j.fj (z) = fine fine fine fine (z; jj, Xj) = fine fine fine (z) = fine fine (z)."}, {"heading": "L2 regularization", "text": "The inclusion of a regulator within each FI, i.e. Fi (x) = fi (x) + \u00b52 \u0445 x \u0445 2, can be done with the help of the proximal operator of fi. Define the scale factor: \u03c1 = 1 \u2212 \u00b5\u03b3 1 + \u00b5\u03b3. Then prox\u03b3Fi (z) = prox\u03c1\u03b3fi (\u03c1z)."}, {"heading": "B Proofs", "text": "Stage fright is not only a problem, but also a problem that we have to solve. (...) We start by splitting on the right side of the inner product. (...) We start by splitting on the right side of the inner product. (...) We start by splitting on the right side of the inner product. (...) We start by splitting on the right side of the inner product. (...) We start by splitting on the right side of the inner product. (...) We start by splitting on the left side of the inner product. (...) We start by splitting on the right side of the inner product. (...) We start by splitting on the right side of the inner product. (...) We start by splitting on the right side of the inner product. (...) We start by splitting on the left side of the inner product. (...) We start by splitting on the right side of the inner product. (...)"}, {"heading": "C Proximal operator bounds with proofs", "text": "In this section, let us demonstrate some simple limits of proximal operator theory that we will use in this work. (Define the short-term p\u03b3f (x) = prox\u03b3f (x), and let g\u03b3f (x) \u2212 \u03b3f (x). This relationship is known as the optimum condition of the proximal operator. We will also use a few standard convectivity limits without proof. Let f: Rd \u2192 R be a convex function with a strong convective constant p (x)."}], "references": [{"title": "Libsvm : a library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Chang and Lin.,? \\Q2011\\E", "shortCiteRegEx": "Chang and Lin.", "year": 2011}, {"title": "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives", "author": ["Aaron Defazio", "Francis Bach", "Simon Lacoste-Julien"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Defazio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Defazio et al\\.", "year": 2014}, {"title": "Finito: A faster, permutable incremental gradient method for big data problems", "author": ["Aaron Defazio", "Tiberio Caetano", "Justin Domke"], "venue": "Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "Defazio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Defazio et al\\.", "year": 2014}, {"title": "Variance reduced stochastic gradient descent with neighbors", "author": ["Thomas Hofmann", "Aurelien Lucchi", "Simon Lacoste-Julien", "Brian McWilliams"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Hofmann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hofmann et al\\.", "year": 2015}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": null, "citeRegEx": "Johnson and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Johnson and Zhang.", "year": 2013}, {"title": "Semi-Stochastic Gradient Descent Methods", "author": ["Jakub Kone\u010dn\u00fd", "Peter Richt\u00e1rik"], "venue": "ArXiv e-prints,", "citeRegEx": "Kone\u010dn\u00fd and Richt\u00e1rik.,? \\Q2013\\E", "shortCiteRegEx": "Kone\u010dn\u00fd and Richt\u00e1rik.", "year": 2013}, {"title": "An optimal randomized incremental gradient method", "author": ["G. Lan", "Y. Zhou"], "venue": "ArXiv e-prints,", "citeRegEx": "Lan and Zhou.,? \\Q2015\\E", "shortCiteRegEx": "Lan and Zhou.", "year": 2015}, {"title": "A universal catalyst for first-order optimization", "author": ["Hongzhou Lin", "Julien Mairal", "Zaid Harchaoui"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Incremental majorization-minimization optimization with application to large-scale machine learning", "author": ["Julien Mairal"], "venue": "Technical report, INRIA Grenoble Rho\u0302ne-Alpes / LJK Laboratoire Jean Kuntzmann,", "citeRegEx": "Mairal.,? \\Q2014\\E", "shortCiteRegEx": "Mairal.", "year": 2014}, {"title": "Stochastic proximal gradient descent with acceleration techniques", "author": ["Atsushi Nitanda"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Nitanda.,? \\Q2014\\E", "shortCiteRegEx": "Nitanda.", "year": 2014}, {"title": "Monotone operators and the proximal point algorithm", "author": ["R Tyrrell Rockafellar"], "venue": "SIAM journal on control and optimization,", "citeRegEx": "Rockafellar.,? \\Q1976\\E", "shortCiteRegEx": "Rockafellar.", "year": 1976}, {"title": "Minimizing finite sums with the stochastic average gradient", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "Technical report,", "citeRegEx": "Schmidt et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2013}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": null, "citeRegEx": "Shalev.Shwartz and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Shalev.Shwartz and Zhang.", "year": 2013}, {"title": "Accelerated mini-batch stochastic dual coordinate ascent", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Shalev.Shwartz and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Shalev.Shwartz and Zhang.", "year": 2013}, {"title": "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Technical report,", "citeRegEx": "Shalev.Shwartz and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Shalev.Shwartz and Zhang.", "year": 2013}, {"title": "Pegasos: Primal estimated sub-gradient solver for svm", "author": ["Shai Shalev-Shwartz", "Yoram Singer", "Nathan Srebro", "Andrew Cotter"], "venue": "Mathematical programming,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 11, "context": "In most cases recently developed methods such as SAG [Schmidt et al., 2013] can find an -minimum faster than either stochastic gradient descent or accelerated black-box approaches, both in theory and in practice.", "startOffset": 53, "endOffset": 75}, {"referenceID": 6, "context": "This rate matches the lower bound known for this problem [Lan and Zhou, 2015] under the gradient oracle.", "startOffset": 57, "endOffset": 77}, {"referenceID": 10, "context": "SAGA degenerates into regular gradient descent, whereas our method becomes the proximal-point method [Rockafellar, 1976]: x = prox\u03b3f (x ).", "startOffset": 101, "endOffset": 120}, {"referenceID": 6, "context": "The general approach of applying the proximal-point method as the outer-loop of a doubleloop scheme has been dubbed the Catalyst algorithm Lin et al. [2015]. It can be applied to accelerate any FIG method.", "startOffset": 139, "endOffset": 157}, {"referenceID": 6, "context": "Recently a very interesting primal-dual approach has been proposed by Lan and Zhou [2015]. All of the prior accelerated methods are significantly more complex than the approach we propose, and have more complex proofs.", "startOffset": 70, "endOffset": 90}, {"referenceID": 3, "context": "This is the same Lyapunov function as used by Hofmann et al. [2015]. Proof.", "startOffset": 46, "endOffset": 68}, {"referenceID": 15, "context": ", 2014a], SDCA [Shalev-Shwartz and Zhang, 2013a], Pegasos/SGD [Shalev-Shwartz et al., 2011] and the catalyst acceleration scheme [Lin et al.", "startOffset": 62, "endOffset": 91}, {"referenceID": 7, "context": ", 2011] and the catalyst acceleration scheme [Lin et al., 2015].", "startOffset": 45, "endOffset": 63}, {"referenceID": 6, "context": "Accelerated MISO as well as the primal-dual FIG method [Lan and Zhou, 2015] were excluded as we wanted to test on sparse problems and they are not designed to take advantage of sparsity.", "startOffset": 55, "endOffset": 75}, {"referenceID": 0, "context": "We selected a set of commonly used datasets from the LIBSVM repository [Chang and Lin, 2011].", "startOffset": 71, "endOffset": 92}, {"referenceID": 0, "context": "5 Experiments We tested our algorithm which we call Point-SAGA against SAGA [Defazio et al., 2014a], SDCA [Shalev-Shwartz and Zhang, 2013a], Pegasos/SGD [Shalev-Shwartz et al., 2011] and the catalyst acceleration scheme [Lin et al., 2015]. SDCA was chosen as the inner algorithm for the catalyst scheme as it doesn\u2019t require a step-size, making it the most practical of the variants. Catalyst applied to SDCA is essentially the same algorithm as proposed in Shalev-Shwartz and Zhang [2013c]. A single inner epoch was used for each SDCA invocation.", "startOffset": 77, "endOffset": 491}], "year": 2016, "abstractText": "We describe a novel optimization method for finite sums (such as empirical risk minimization problems) building on the recently introduced SAGA method. Our method achieves an accelerated convergence rate on strongly convex smooth problems. Our method has only one parameter (a step size), and is radically simpler than other accelerated methods for finite sums. Additionally it can be applied when the terms are non-smooth, yielding a method applicable in many areas where operator splitting methods would traditionally be applied.", "creator": "LaTeX with hyperref package"}}}