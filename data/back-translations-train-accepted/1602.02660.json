{"id": "1602.02660", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Feb-2016", "title": "Exploiting Cyclic Symmetry in Convolutional Neural Networks", "abstract": "Many classes of images exhibit rotational symmetry. Convolutional neural networks are sometimes trained using data augmentation to exploit this, but they are still required to learn the rotation equivariance properties from the data. Encoding these properties into the network architecture, as we are already used to doing for translation equivariance by using convolutional layers, could result in a more efficient use of the parameter budget by relieving the model from learning them. We introduce four operations which can be inserted into neural network models as layers, and which can be combined to make these models partially equivariant to rotations. They also enable parameter sharing across different orientations. We evaluate the effect of these architectural modifications on three datasets which exhibit rotational symmetry and demonstrate improved performance with smaller models.", "histories": [["v1", "Mon, 8 Feb 2016 17:37:16 GMT  (624kb,D)", "http://arxiv.org/abs/1602.02660v1", "10 pages, 6 figures, submitted to ICML 2016"], ["v2", "Thu, 26 May 2016 11:47:18 GMT  (624kb,D)", "http://arxiv.org/abs/1602.02660v2", "10 pages, 6 figures, accepted for publication at ICML 2016"]], "COMMENTS": "10 pages, 6 figures, submitted to ICML 2016", "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.NE", "authors": ["sander dieleman", "jeffrey de fauw", "koray kavukcuoglu"], "accepted": true, "id": "1602.02660"}, "pdf": {"name": "1602.02660.pdf", "metadata": {"source": "META", "title": "Exploiting Cyclic Symmetry in Convolutional Neural Networks", "authors": ["Sander Dieleman", "Jeffrey De Fauw", "Koray Kavukcuoglu"], "emails": ["SEDIELEM@GOOGLE.COM", "DEFAUW@GOOGLE.COM", "KORAYK@GOOGLE.COM"], "sections": [{"heading": "1. Introduction", "text": "For many applications of machine learning with sensory data (e.g. computer vision, speech recognition), neural networks have largely displaced traditional approaches based on handcrafted characteristics, which require considerable technical effort and prior knowledge to design. Neural networks, however, are able to automatically extract much of this knowledge from data previously used in models with the help of feature engineering.However, this evolution has not stopped machine learning practitioners from learning about their datasets and problem domains: foreknowledge is now encoded in the architecture of neural networks, but the most prominent example of this is the standard representation of Convolutionary Neural Networks (CNNs), which typically consist of shifting revolutionary layers and layers."}, {"heading": "2. Cyclic symmetry", "text": "These patterns often occur in different alignments: for example, edges in images can be arbitrarily aligned. As a result, CNNs will often learn multiple copies of the same filter in different alignments, which is especially obvious when the input data has rotational symmetry. Therefore, it may be useful to encode a form of rotational symmetry in the architecture of a neural network, as well as the parameters resulting from the folding operation translational symmetry. This could reduce the redundancy of learning to recognize the same patterns in different alignments, and it may allow us to reduce the number of model parameters and reduce the risk of overlaying."}, {"heading": "3. Equivariance and invariance", "text": "Many classes of images have partial or complete rotation symmetry, especially in biology, astronomy, medicine, and aerial photography.Some types of data have specific surface symmetry, such as board configurations in Go game.The tasks we want to perform with such data using neural networks usually require an equivariance of rotations: When the input is rotated, the learned representations should change in a predictable manner (Lenc & Vedaldi, 2014).Formally speaking, a function f is equivalent to a class of transformations T if for all transformations T and for all transformations T and T and T for all transformations input x a corresponding transformation T of the input f (x) can be found, so that f (Tx) = T (x) is equal for all x (Schmidt & Roth, 2012).Frequently, the representations should not change at all when the input is rotated, i.e. they should be invariant. From this, it follows that an ariant is also invasive for all of us, but not necessarily for all of us (T)."}, {"heading": "4. Encoding equivariance in neural nets", "text": "The easiest way to achieve an (approximate) invariance to a class of input transformations is to train a neural network with data augmentation (Simard et al., 2003): During the training, examples are randomly disrupted by transformations from this class to encourage the network to produce the right result, regardless of how the input is transformed. Provided the network has sufficient capacity, it should be able to learn such invariances from data in many cases (Lenc & Vedaldi, 2014), but even if it learns the invariance perfectly on the training set, there is no guarantee that this will be generalized. To obtain such a guarantee, we could encode the desired invariance display properties within the network architecture and allow it to use the additional released learning capacity to learn other concepts."}, {"heading": "4.1. Framework", "text": "We will present four operations that can be cast as layers in a neural network and that form a framework with which we can easily build networks that correspond to cyclic rotations and share parameters across different orientations. An overview can be found in Table 1 and a visualization in Figure 1. Each of the operations changes either the size of the minibatch (slicing, pooling) or the number of feature cards (rolling) or both (stacking), and these operations do not affect the behavior of the surrounding layers in any way, so in principle they are compatible with newer architectural innovations such as Inception (Szegedy et al., 2014) and Remaining Learning Processes (He et al., 2015)."}, {"heading": "4.2. Cyclic slicing and pooling", "text": "In fact, most of them are able to play by the rules that they play by the rules."}, {"heading": "4.3. Cyclic rolling", "text": "Next, we will introduce the cyclic rolling process. We observe that each mini-batch of intermediate cycles = 2x apply this process = Half-cyclic activations in a network with cyclic slicing and pooling contains four sets of feature cards for each example. These are not just rotation cards from each other as they correspond to different relative orientations of filters and inputs (indicated by different colors in Figure 3). By re-aligning and stacking them along the feature dimension \u2212 we can increase the number of feature cards within each path fourfold with a simple copy operation, which means that the next evolution layer gets a richer representation than its input. Therefore, we can reduce the number of filters in the Convolutionary Layers \u2212 while maintaining a rich representation \u2212. In practice, this amounts to 4-way parameter sharing: each filter produces not one, but four feature cards that will be described from different operational orientations."}, {"heading": "4.4. Cyclic stacking", "text": "We may also want to achieve a parameter division by rolling in networks that need not be fully equivalent: As mentioned in Section 1, even networks trained in nature images often have a lot of redundancy in the first two layers. To accommodate this use case, we can simply stack (i.e. merge) feature cards that we have obtained from the various orientations along the feature dimension instead of bundling them as usual, which is the same as the stacking operation T we introduced previously."}, {"heading": "4.5. Rotate feature maps or filters?", "text": "As mentioned in Section 2, we can rotate either the filters or the function boards on which they operate equally to achieve a 4-way parameter distribution, because only their relative orientation influences the result of folding. This means that there are two possible practical implementations, with both their own advantages and disadvantages. Rotating the function boards may not be the most natural choice, but it is easiest to implement in many modern, deep learning software frameworks, because the role operation can be isolated and viewed as a separate layer in a neural network model. By stacking the function boards that correspond to different orientations in the stack dimension, it becomes easier to exploit the data parallelism (the effective stack size for most of the computer-consuming operations is larger). The function boards must necessarily be square, otherwise it would not be possible to stack the different orientations into a single stack."}, {"heading": "4.6. Dihedral symmetry", "text": "The previous discussion willingly generalizes to the case of surface formation by modifying the crop operation so that in addition to the rotated copies of the input (a total of 8 copies) it is also tilted, and by adapting all other operations accordingly. One complication is that the equivariant display properties of the surface section are less simple: the resulting permutation along the stack dimension is no longer cyclic. It is also important to take into account that flipping and rotating do not oscillate."}, {"heading": "5. Related Work", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "6. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. Datasets", "text": "Plankton The plankton datasets (Cowen et al., 2015) consist of 30,336 grayscale images of different sizes, unevenly divided into 121 classes corresponding to different types of plankton. We have switched them to 95 \u00d7 95 based on the length of their longest page. We split these datasets into separate validation and training sets of 3037 and 27,299 images, respectively. These datasets were used for the National Data Science Bowl3, a data science Competition3https: / www.kaggle.com / c / datasciencebowlhosted on the Kaggle platform. Although 130,400 images were provided for testing, their labels were never published. These images were used to evaluate the competition results. We were able to obtain test results by submitting predictions to Kaggle."}, {"heading": "6.2. Experimental setup", "text": "For the plankton and galaxy datasets, the architectures are inspired by the VGG architectures (Simonyan & Zisserman, 2014) using 3 x 3 \"equal\" coils (which keep the spatial dimensions of the characteristic maps constant by padding the input by zero).For the Massachusetts dataset, we use a stack of 5 x 5 \"valid\" coil layers (which do not decrease the input and spacing of the spatial dimensions) without pooling, followed by 1 x 1 coils to ensure that enough contextual information is available for each pixel. They are shown in Figure 6.We use the Adam optimization method (Kingma & Ba, 2014) for all experiments."}, {"heading": "6.3. Pooling functions", "text": "First, we modified the plankton base architecture by adding a cyclic slicing layer on the input side and a cyclic pooling layer just before the output layer. We reduced the batch size used for training by a factor of 4. We compared three different pooling functions: the mean, the maximum (max) and the root-mean square (RMS). We also investigated whether or not we should apply ReLU nonlinearity to the features before pooling, resulting in a total of six configurations listed in Table 2, along with their approximate number of parameters and results. Mean pooling without nonlinearity delivers the best results in terms of cross-entropy. We will report on results that use only this pooling function for further experiments, noting that the choice of function typically depends on the dataset and size of the model."}, {"heading": "6.4. Networks with rolling layers", "text": "Next, we investigated the effect of inserting one or more rolling layers into the networks, in addition to the less occurring and contracting layers. We looked at two approaches: In one case, we insert rolling layers after all the revolutionary layers, and after the first dense layer (roll all), and reduce the number of units in these layers; in another case, we insert rolling layers only after the first dense layer (roll dense); we can keep the number of characteristic maps after which rolling operations are inserted constant by reducing the number of filters by a factor of 4; the layers then have 4 times fewer parameters; if we halve the number of filters instead, the number of characteristic maps will double compared to the original model; this implies a reduction in the parameters for the layer before rolling operation, but an increase in the next layer."}, {"heading": "7. Conclusion and future work", "text": "We have introduced a framework for building rotation-equivalent neural networks using four new layers that can be easily inserted into existing network architectures, and no further modifications are required beyond adjusting the minibatch size. We demonstrated improved performance of the resulting equivalent networks on datasets that have full rotation symmetry while reducing the number of parameters. Rapid GPU implementation of rolling operation for Theano (using CUDA cores) can be found at https: / / github.com / benanne / kaggle-ndsb.In future work, we would like to apply our approach to even more data types that have rotation symmetry, especially in areas where data shortage is often a problem (e.g. medical imaging), and where additional parameter release would be valuable to reduce the overhaul."}, {"heading": "Acknowledgements", "text": "The authors thank Jeroen Burms, Pieter Buteneers, Taco Cohen, Jonas Degrave, Lasse Espeholt, Max Jaderberg, Ira Korshunova, Volodymyr Mnih, Lionel Pigou, Laurent Sifre, Karen Simonyan and Aa \ufffd ron van den Oord for their insights and contributions."}], "references": [{"title": "Training deep convolutional neural networks to play go", "author": ["Clark", "Christopher", "Storkey", "Amos"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning", "citeRegEx": "Clark et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2015}, {"title": "Learning the irreducible representations of commutative lie groups", "author": ["Cohen", "Taco", "Welling", "Max"], "venue": "arXiv preprint arXiv:1402.4437,", "citeRegEx": "Cohen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cohen et al\\.", "year": 2014}, {"title": "Planktonset 1.0: Plankton imagery data collected from f.g. walton smith in straits of florida from 2014-06-03 to 2014-06-06 and used in the 2015 national data science", "author": ["Cowen", "Robert K", "S. Sponaugle", "K.L. Robinson", "J. Luo"], "venue": null, "citeRegEx": "Cowen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Cowen et al\\.", "year": 2015}, {"title": "Rotation-invariant convolutional neural networks for galaxy morphology prediction", "author": ["Dieleman", "Sander", "Willett", "Kyle W", "Dambre", "Joni"], "venue": "Monthly Notices of the Royal Astronomical Society,", "citeRegEx": "Dieleman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dieleman et al\\.", "year": 2015}, {"title": "Rotation-invariant neoperceptron", "author": ["Fasel", "Beat", "Gatica-Perez", "Daniel"], "venue": "In Pattern Recognition,", "citeRegEx": "Fasel et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Fasel et al\\.", "year": 2006}, {"title": "Deep symmetry networks", "author": ["Gens", "Robert", "Domingos", "Pedro M"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Gens et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gens et al\\.", "year": 2014}, {"title": "Measuring invariances in deep networks. In Advances in neural information processing", "author": ["Goodfellow", "Ian", "Lee", "Honglak", "Le", "Quoc V", "Saxe", "Andrew", "Ng", "Andrew Y"], "venue": null, "citeRegEx": "Goodfellow et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2009}, {"title": "Deep residual learning for image recognition", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "arXiv preprint arXiv:1512.03385,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Transforming auto-encoders", "author": ["Hinton", "Geoffrey E", "Krizhevsky", "Alex", "Wang", "Sida D"], "venue": "In Artificial Neural Networks and Machine Learning\u2013ICANN", "citeRegEx": "Hinton et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2011}, {"title": "Spatial transformer networks", "author": ["Jaderberg", "Max", "Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "In Advances in Neural Information Processing Systems, pp. 2008\u20132016,", "citeRegEx": "Jaderberg et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jaderberg et al\\.", "year": 2015}, {"title": "Learning invariant features through topographic filter maps", "author": ["Kavukcuoglu", "Koray", "Ranzato", "Marc Aurelio", "Fergus", "Rob", "Le-Cun", "Yann"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Kavukcuoglu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kavukcuoglu et al\\.", "year": 2009}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Transformation equivariant boltzmann machines", "author": ["Kivinen", "Jyri J", "Williams", "Christopher KI"], "venue": "In Artificial Neural Networks and Machine Learning\u2013ICANN", "citeRegEx": "Kivinen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kivinen et al\\.", "year": 2011}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Understanding image representations by measuring their equivariance and equivalence", "author": ["Lenc", "Karel", "Vedaldi", "Andrea"], "venue": "arXiv preprint arXiv:1411.5908,", "citeRegEx": "Lenc et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lenc et al\\.", "year": 2014}, {"title": "Learning invariant representations and applications to face verification", "author": ["Liao", "Qianli", "Leibo", "Joel Z", "Poggio", "Tomaso"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Liao et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liao et al\\.", "year": 2013}, {"title": "Machine Learning for Aerial Image Labeling", "author": ["Mnih", "Volodymyr"], "venue": "PhD thesis, University of Toronto,", "citeRegEx": "Mnih and Volodymyr.,? \\Q2013\\E", "shortCiteRegEx": "Mnih and Volodymyr.", "year": 2013}, {"title": "Tiled convolutional neural networks", "author": ["Ngiam", "Jiquan", "Chen", "Zhenghao", "Chia", "Daniel", "Koh", "Pang W", "Le", "Quoc V", "Ng", "Andrew Y"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Ngiam et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ngiam et al\\.", "year": 2010}, {"title": "Rotation invariant neural network-based face detection", "author": ["Rowley", "Henry A", "Baluja", "Shumeet", "Kanade", "Takeo"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "Rowley et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Rowley et al\\.", "year": 1998}, {"title": "Learning rotation-aware features: From invariant priors to equivariant descriptors", "author": ["Schmidt", "Uwe", "Roth", "Stefan"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Schmidt et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2012}, {"title": "Rotation, scaling and deformation invariant scattering for texture discrimination", "author": ["Sifre", "Laurent", "Mallat", "St\u00e9phane"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Sifre et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sifre et al\\.", "year": 2013}, {"title": "Best practices for convolutional neural networks applied to visual document analysis", "author": ["Simard", "Patrice Y", "Steinkraus", "Dave", "Platt", "John C"], "venue": "In null,", "citeRegEx": "Simard et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Simard et al\\.", "year": 2003}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Learning invariant representations with local transformations", "author": ["Sohn", "Kihyuk", "Lee", "Honglak"], "venue": "arXiv preprint arXiv:1206.6418,", "citeRegEx": "Sohn et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sohn et al\\.", "year": 2012}, {"title": "Going deeper with convolutions", "author": ["Szegedy", "Christian", "Liu", "Wei", "Jia", "Yangqing", "Sermanet", "Pierre", "Reed", "Scott", "Anguelov", "Dragomir", "Erhan", "Dumitru", "Vanhoucke", "Vincent", "Rabinovich", "Andrew"], "venue": "arXiv preprint arXiv:1409.4842,", "citeRegEx": "Szegedy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2014}, {"title": "Learning to extract motion from videos in convolutional neural networks", "author": ["Teney", "Damien", "Hebert", "Martial"], "venue": "arXiv preprint arXiv:1601.07532,", "citeRegEx": "Teney et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Teney et al\\.", "year": 2016}, {"title": "Flip-rotatepooling convolution and split dropout on convolution neural networks for image classification", "author": ["Wu", "Fa", "Hu", "Peijun", "Kong", "Dexing"], "venue": "arXiv preprint arXiv:1507.08754,", "citeRegEx": "Wu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 21, "context": "The simplest way to achieve (approximate) invariance to a class of transformations of the input, is to train a neural network with data augmentation (Simard et al., 2003): during training, examples are randomly perturbed with transformations from this class, to encourage the network to produce the correct result regardless of how the input is transformed.", "startOffset": 149, "endOffset": 170}, {"referenceID": 24, "context": "Beyond this, these operations do not affect the behaviour of the surrounding layers in any way, so in principle they are compatible with recent architectural innovations such as Inception (Szegedy et al., 2014) and residual learning (He et al.", "startOffset": 188, "endOffset": 210}, {"referenceID": 7, "context": ", 2014) and residual learning (He et al., 2015).", "startOffset": 30, "endOffset": 47}, {"referenceID": 3, "context": "Dieleman et al. (2015) also create multiple rotated and flipped versions of images and feed them to the same stack of convolutional layers.", "startOffset": 0, "endOffset": 23}, {"referenceID": 3, "context": "Dieleman et al. (2015) also create multiple rotated and flipped versions of images and feed them to the same stack of convolutional layers. The resulting representations are then concatenated and fed to a stack of dense layers. While this does not yield invariant predictions, it does enable parameter sharing across orientations. In our framework, this approach can be reproduced using a slicing layer at the input, and a stacking layer between the convolutional and dense parts of the network. A similar approach is investigated by Teney & Hebert (2016), where filters of individual convolutional layers are constrained to be rotations of each other.", "startOffset": 0, "endOffset": 556}, {"referenceID": 17, "context": "Tiled CNNs (Ngiam et al., 2010), in which weight sharing is reduced, are able to approximate more complex local invariances than regular CNNs.", "startOffset": 11, "endOffset": 31}, {"referenceID": 10, "context": "The model of Kavukcuoglu et al. (2009) is able to learn local invariance to arbitrary transformations by grouping its filters into overlapping neighbourhoods whose activations are pooled together.", "startOffset": 13, "endOffset": 39}, {"referenceID": 10, "context": "The model of Kavukcuoglu et al. (2009) is able to learn local invariance to arbitrary transformations by grouping its filters into overlapping neighbourhoods whose activations are pooled together. Liao et al. (2013) describe a template-based approach that successfully learns representations invariant to both affine and nonaffine transformations (e.", "startOffset": 13, "endOffset": 216}, {"referenceID": 10, "context": "The model of Kavukcuoglu et al. (2009) is able to learn local invariance to arbitrary transformations by grouping its filters into overlapping neighbourhoods whose activations are pooled together. Liao et al. (2013) describe a template-based approach that successfully learns representations invariant to both affine and nonaffine transformations (e.g. out-of-plane rotation). Cohen & Welling (2014) propose a probabilistic framework to directly model the transformation group to which a given dataset exhibits equivariance.", "startOffset": 13, "endOffset": 400}, {"referenceID": 8, "context": "A third alternative to encoding or learning equivariance properties involves explicitly estimating the transformation applied to the input separately for each example, as is done by transforming auto-encoders (Hinton et al., 2011) and spatial transformer networks (Jaderberg et al.", "startOffset": 209, "endOffset": 230}, {"referenceID": 9, "context": ", 2011) and spatial transformer networks (Jaderberg et al., 2015).", "startOffset": 41, "endOffset": 65}, {"referenceID": 8, "context": "A third alternative to encoding or learning equivariance properties involves explicitly estimating the transformation applied to the input separately for each example, as is done by transforming auto-encoders (Hinton et al., 2011) and spatial transformer networks (Jaderberg et al., 2015). This approach was also investigated for face detection by Rowley et al. (1998).", "startOffset": 210, "endOffset": 369}, {"referenceID": 6, "context": "Both Goodfellow et al. (2009) and Lenc & Vedaldi (2014) discuss how the equivariance properties of representations can be measured.", "startOffset": 5, "endOffset": 30}, {"referenceID": 6, "context": "Both Goodfellow et al. (2009) and Lenc & Vedaldi (2014) discuss how the equivariance properties of representations can be measured.", "startOffset": 5, "endOffset": 56}, {"referenceID": 2, "context": "Plankton The Plankton dataset (Cowen et al., 2015) consists of 30,336 grayscale training images of varying size, divided unevenly into 121 classes which correspond to different species of plankton.", "startOffset": 30, "endOffset": 50}, {"referenceID": 13, "context": "We use discrete learning rate schedules with tenfold decreases near the end of training, following Krizhevsky et al. (2012). For the plankton dataset we also use weight decay for additional regularisation.", "startOffset": 99, "endOffset": 124}], "year": 2016, "abstractText": "Many classes of images exhibit rotational symmetry. Convolutional neural networks are sometimes trained using data augmentation to exploit this, but they are still required to learn the rotation equivariance properties from the data. Encoding these properties into the network architecture, as we are already used to doing for translation equivariance by using convolutional layers, could result in a more efficient use of the parameter budget by relieving the model from learning them. We introduce four operations which can be inserted into neural network models as layers, and which can be combined to make these models partially equivariant to rotations. They also enable parameter sharing across different orientations. We evaluate the effect of these architectural modifications on three datasets which exhibit rotational symmetry and demonstrate improved performance with smaller models.", "creator": "LaTeX with hyperref package"}}}