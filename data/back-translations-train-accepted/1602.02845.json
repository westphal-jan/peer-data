{"id": "1602.02845", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "9-Feb-2016", "title": "Online Active Linear Regression via Thresholding", "abstract": "We consider the problem of online active learning to collect data for regression modeling. Specifically, we consider a decision maker that faces a limited experimentation budget but must efficiently learn an underlying linear population model. Our goal is to develop algorithms that provide substantial gains over passive random sampling of observations. To that end, our main contribution is a novel threshold-based algorithm for selection of observations; we characterize its performance and related lower bounds. We also apply our approach successfully to regularized regression. Simulations suggest the algorithm is remarkably robust: it provides significant benefits over passive random sampling even in several real-world datasets that exhibit high nonlinearity and high dimensionality --- significantly reducing the mean and variance of the squared error.", "histories": [["v1", "Tue, 9 Feb 2016 02:51:12 GMT  (3761kb,D)", "https://arxiv.org/abs/1602.02845v1", null], ["v2", "Wed, 10 Feb 2016 17:53:33 GMT  (3761kb,D)", "http://arxiv.org/abs/1602.02845v2", null], ["v3", "Thu, 23 Jun 2016 18:36:58 GMT  (7567kb,D)", "http://arxiv.org/abs/1602.02845v3", null], ["v4", "Wed, 21 Dec 2016 13:36:50 GMT  (7532kb,D)", "http://arxiv.org/abs/1602.02845v4", "Published in AAAI 2017"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["carlos riquelme", "ramesh johari", "baosen zhang"], "accepted": true, "id": "1602.02845"}, "pdf": {"name": "1602.02845.pdf", "metadata": {"source": "CRF", "title": "Online Active Linear Regression via Thresholding", "authors": ["Carlos Riquelme", "Ramesh Johari", "Baosen Zhang"], "emails": ["rikel@stanford.edu", "rjohari@stanford.edu", "zhangbao@uw.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is in such a way that we will be able to go into another world, in which we go into another world, in which we are in another world, in which we are in another world, in which we are in another world, in which we live in another world, in which we live in another world, in which we live in another world, in which we live in another world, in which we are in another world, in which we in which we live in another world, in which we in which we live in another world, in which we live in another world, in which we live in a world, in which we live in which we in which we live in another world, in which we in which we live in which we in which we in which we in which we in which we in which we in which we in which we in which we live in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we live in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which we in which"}, {"heading": "2 Problem Definition", "text": "The online active learning problem for regression is defined as follows: We observe n covariant vectors in a d-dimensional space Xi \u03b2 Rd, the i.i.d.d. When confronted with the i-th observation, we must choose whether we want to label it or not, i.e., we choose to observe the result. If we decide to label the observation, we get Y i-R. Otherwise, we do not see its label, and the result remains unknown. Furthermore, we assume that Y at most emerges k from the n observations. We assume that covariates are distributed according to a known distribution D, with zero mean EX = 0, and covariance matrix = EXXT. Furthermore, we assume that Y follows a linear model: Y = XT\u03b2-X +, where \u03b2-Rd and \u0445 N-Rd are the miniature distribution."}, {"heading": "3 Algorithm and Main Results", "text": "In this section, we motivate the algorithm to quantify the main result that quantifies its performance for general distributions (X) (X). Finally, we show how to generalize the results to a sparse linear regression. In Appendix E, we derive a CLT approach with guarantees useful in complex or unknown distribution settings. Without losing generality, we assume that every observation is white, that is, E [XXT] is the identity matrix. For correlated observations X, we \"apply X,\" which is useful in complex or unknown distribution settings. Without losing generality, we assume that every observation is white, that is, E [XXT] is the identity matrix. For correlated observations X. \""}, {"heading": "3.1 Thresholding Algorithm", "text": "For each incoming observation Xi, we calculate its weighted norm. (possibly after a brightening if necessary) (If the norm is above the threshold, then we select the observation, otherwise we ignore it. (4) Algorithm 1: Thresholding algorithm is tantamount to determining the largest observations based on our budget, so we need the satisfaction of the largest observations (3) and (4). (4) Algorithm 1: Thresholding algorithm 1: Algorithm 1: Sentence 1: Rd + 1 satisfaction (3) and (4). (2: Set S = \u2205 3: for observation 1 \u2264 i: Observe Xi. 5: Compute Xi = D \u2212 1 / 2UTXi: Observate Xi. (6: if the observation Xi."}, {"heading": "3.2 Main Theorem", "text": "Theorem 3.1 states that D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D-D"}, {"heading": "3.3 Sparsity and Regularization", "text": "The profit, which is achieved by active learning in our environment, works as follows: First, we focus on actual support, since it decreases very quickly if d's increases, and section 4 shows that the profit cannot generally be improved. (In Annex J, we also provide the results for the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of the consideration of"}, {"heading": "3.4 Proof of Theorem 3.1", "text": "The full proof of Theorem 3.1 is in Appendix B. We provide here only a sketch. The proof is a direct application of spectral results in [26], which are derived by a congruence argument using a discrete net N on the Euclidean sphere Sd \u2212 1, along with a concentration imbalance of the amber type, which controls deviations of [26] for each element w \u00b2 N in the mesh. Finally, a composite boundary is taken over the mesh. This fact can be quite useful in practice if F is unknown. We can consider some initial budget imbalances X1,.., XT to restore F, and then (10) ED \u00b2 X2j implies in the denominator of the RHS, instead. This fact may well be useful in practice if F is unknown. We can consider some initial budget imbalances X1,."}, {"heading": "4 Lower Bound", "text": "In this section, we derive a lower limit for the k > d setting. Suppose all the data is given. Again, let's choose the k observations with the largest standards, referred to as X \u00b2. To minimize the prediction error, the best possible X \u00b2 is TX \u00b2 diagonally, with identical entries, and let's track the sum of the norms. No selection algorithm, online or offline, can do this better. Algorithm 1 accomplishes this by selecting observations with large norms and unrelated entries (if necessary). Theorem 4.1 captures this intuition. Theorem 4.1 Let A be an algorithm for the problem we have described in Section 2."}, {"heading": "5 Simulations", "text": "We performed experiments in various settings: regulated estimators in high dimensions, and the basic threshold approaches in the real world to explore their performance in strongly nonlinear environments. We compare the performance in high-dimensional settings of random sampling and algorithm 1 - both with an appropriately adapted lasso estimator - against algorithm 2, which takes into account the structure of the problem (s d). For completeness, we also show the performance of algorithm 2, if all the observations are included in the final OLS estimate, and that of random sampling (RS) and algorithm 2, which takes into account the structure of the problem (Thr), if the true support S is known in advance, and the OLS calculation on S. In Figure 1 (a) we see that algorithm 2 dramatically reduces the observations of the MSE, while in Figure 1 (b) we zoom-in order to see that we perform all observations in a remarkable way, all the final observations for the algorithm 2."}, {"heading": "6 Conclusion", "text": "Our work provides a comprehensive analysis of threshold algorithms for active online learning of linear regression models, which prove to be good both theoretically and empirically. There are several natural open directions. Additional robustness could be guaranteed in other environments by combining our algorithm as a \"black box\" with other approaches: For example, a random sample or stratified sample could be used to determine whether significant nonlinearity is present and to determine the fraction of observations collected via thresholds."}, {"heading": "7 Acknowledgments", "text": "The authors thank Sven Schmit for his excellent comments and suggestions, Mohammad Ghavamzadeh for fruitful discussions and the anonymous reviewers for their valuable feedback. We appreciate the support of the National Science Foundation under the grants CMMI-1234955, CNS-1343253 and CNS-1544548."}, {"heading": "A Whitening", "text": "Before determining the norm of incoming observations, it is useful to correlate and standardize their components, i.e. to lighten the data. Then, we apply the algorithm to uncorrelated covariates with zero and unit variance (not necessarily independent). The covariance matrix can be decomposed as \u03a3 = UDUT, where U is orthogonal and D diagonal with dii = \u03bbi (\u03a3). We blur any observation to X = D \u2212 1 / 2UTX-Rd \u00b7 1 (while for X-Rk \u00b7 d, X-Rk = XUD \u2212 1 / 2), so that EX-X-T = Id. We denote whitened observations with X-X and X-X-X in the appendix. After a certain algebra, we see that d-Max- (X-T-X-1) \u2264 Tr (X-X-1) \u2212 d \u00b2 -large values with X-X-X-X (highest X-X-X) and X-X-X-X even maxister."}, {"heading": "B Proof of Theorem 3.1", "text": "Theorem B.1 Let n > d."}, {"heading": "C Proof of Tr(X\u22121) \u2265 Tr(Diag(X)\u22121)", "text": "To justify that we want S = XTX to be as close to the diagonal as possible, we show the following problem: Under our assumptions, S is symmetrically positively defined with the probability of 1, Lemma C.1 Let X be a n \u00b7 n symmetrically positive definitive matrix. In other words, we show the diagonal matrix (matrix with all diagonals 0) after the reverse operation.We show this by induction. Let us consider a 2 \u00d7 2 matrix X = [a b b b b c] (24) and Tr (X \u2212 1) Tr (b) = 1ac \u2212 b2 (a + c) \u2212 b2 > 0 (X is positive, where the expression k = 1 x is."}, {"heading": "D Proof of Corollary 3.2", "text": "Corollary x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "E CLT Approximation", "text": "As we explain in the main text, it is sometimes difficult to calculate the distribution of individual components. (...) Fortunately, the sum of random variables is the sum of random variables, and in high-dimensional spaces, a CLT approach can help us choose a good threshold. (...) In this section, we derive some theoretical guarantees. (...) CLT is a good idea for random variables (since the square is still limited and therefore subgaussian), but if the underlying components are Xj unbounded subgaussian, we will at least be subexponential - since the square of a random variable is subexponential, [26] - and a higher threshold - like the one coming from chi-squared - is more appropriate. (...) Moreover, in the context of severe effects, catastrophic effects are expected, as P (maxj Xj > j) dominates the individual components."}, {"heading": "F Proof of Theorem 4.1", "text": "Theorem F. 1 Let A be an algorithm for the problem we described in Section 2. Then EA is Tr (V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V V = V = V = V V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V V = V = V = V = V = V = V = V = V V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V = V"}, {"heading": "G Proof of Corollary 4.2", "text": "We assume that we can start the expected maximum number of random variables with d degree of Freedom.Let us start with 51 percent of the distribution. We can assume that we have the maximum distribution of variables with d degree of Freedom.Let us (51). We assume that we have the maximum distribution of variables with d degree of Freedom.Let us (51). We assume that we have the maximum distribution of variables with d degree of Freedom.Let us (51). We assume that we have the maximum distribution of variables with d degree of Freedom.Let us (51). We assume that we have the maximum distribution of variables with the identity covariance matrix. In other words, we have the maximum distribution of variables with d degree of Freedom.Let us (51) we have the maximum distribution of variables with d degree of Freedom.We are the variable of the Identity Covariance Matrix."}, {"heading": "H Proof of Theorem 3.3", "text": "We point out the following theorems (1). (1) Suppose we run the sparse threshold algorithm with k1 = C \u00b2 s observations to obtain support for \u03b2, for an appropriate C \u00b2 constant. (2) Execute X2 k2 = k \u2212 k1 observations on the thresholds to S (1). It follows that t = a \u00b2 s observations exist for the support of \u03b2, for an appropriate C \u00b2 constant c1, and c, which depend on the subgaussian standard of D (1). (2) Thus, t = a \u00b2 s observations exist for the support of \u03b2-2 \u2212 k2 \u2212 C \u00b2 s. (2) universal constants c2, and c, which depend on the subgaussian standard of D (1). (2), so that with the probability of least1 \u2212 2e \u2212 k."}, {"heading": "I Proof of CLT Lower Bound", "text": "Conclusion I.1 Suppose the norm of white observations is distributed according to ZB = N (d, \u03b32) and then we have this for any algorithm AEA Tr (\u03a3 (X TX) \u2212 1) \u2265 d (1 + \u03b3d \u221a 2 log n) k. (82) Proof by theorem F.1, we have to calculate E [maxi] | Xi | | | 2] Assuming \"Xi\" 2 \u0445 N (d, \u03b32) for each i what E [max i] | Xi | | | 2] = E [d + max i [n] \u03b3 | Xi | | 2 \u2212 d \u03b3] (83) \u2264 d + \u03b3 E [max i [n] N (0, 1)] (84) \u2264 d + \u04212 log n, (85) and the result follows."}, {"heading": "J Ridge Regression", "text": "Regulated linear estimators also benefit from large and well-balanced observations. We show that under the mild assumptions, the performance of the comb regression is directly correlated with the performance of the previous sections. Thereby, the comb estimator is so large that the optimal penalty parameter is unknown until the end of the data acquisition process. We assume that it is uniformly random in a small interval. Theorem J.1 Let R > 0. Assume the penalty parameters for the comb regression are uniformly selected."}, {"heading": "K Simulations", "text": "In particular, we present experiments for linear models, synthetic linear models, synthetic nonlinear data and additional regularized and real datasets.K.1 Linear modelsWe first show empirically the results demonstrated in Theorem B.1. For a sequence of values of n, we select k = n observations in Rd, with fixed d = 10. The observations are generated according to N (0, Id), and y follows a linear model with \u03b2i models that are executed (\u2212 5, 5).For each tuple (n, k), we repeat the experiment 200 times and calculate the quadrilateral error (\u03b2).The results in Figure 3 (a) show the average MSE of algorithm 1 significantly better than those of random sampling."}], "references": [{"title": "Agnostic active learning", "author": ["M.-F. Balcan", "A. Beygelzimer", "J. Langford"], "venue": "In Proceedings of the 23rd international conference on Machine learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Margin based active learning", "author": ["M.-F. Balcan", "A. Broder", "T. Zhang"], "venue": "In Learning Theory,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "The true sample complexity of active learning", "author": ["M.-F. Balcan", "S. Hanneke", "J.W. Vaughan"], "venue": "Machine learning,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2010}, {"title": "Maximizing expected model change for active learning in regression", "author": ["W. Cai", "Y. Zhang", "J. Zhou"], "venue": "In Data Mining (ICDM),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "Minimax bounds for active learning", "author": ["R.M. Castro", "R.D. Nowak"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Improving generalization with active learning", "author": ["D. Cohn", "L. Atlas", "R. Ladner"], "venue": "Machine learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 1994}, {"title": "Active learning with statistical models", "author": ["D.A. Cohn", "Z. Ghahramani", "M.I. Jordan"], "venue": "Journal of artificial intelligence research,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "Hierarchical sampling for active learning", "author": ["S. Dasgupta", "D. Hsu"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "A general agnostic active learning algorithm", "author": ["S. Dasgupta", "C. Monteleoni", "D.J. Hsu"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2007}, {"title": "Modelling extremal events, volume 33", "author": ["P. Embrechts", "C. Kl\u00fcppelberg", "T. Mikosch"], "venue": "Springer Science & Business Media,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1997}, {"title": "Event labeling combining ensemble detectors and background knowledge", "author": ["H. Fanaee-T", "J. Gama"], "venue": "Progress in Artificial Intelligence,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Ridge regression: Biased estimation for nonorthogonal problems", "author": ["A.E. Hoerl", "R.W. Kennard"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1970}, {"title": "Heavy-tailed regression with a generalized median-of-means", "author": ["D. Hsu", "S. Sabato"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Inequalities for quantiles of the chi-square distribution", "author": ["T. Inglot"], "venue": "Probability and Mathematical Statistics,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Variable selection in high-dimension with random designs and orthogonal matching pursuit", "author": ["A. Joseph"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Rademacher complexities and bounding the excess risk in active learning", "author": ["V. Koltchinskii"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2010}, {"title": "Nonmyopic active learning of gaussian processes: an explorationexploitation approach", "author": ["A. Krause", "C. Guestrin"], "venue": "In Proceedings of the 24th international conference on Machine learning,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2007}, {"title": "Adaptive estimation of a quadratic functional by model selection", "author": ["B. Laurent", "P. Massart"], "venue": "Annals of Statistics,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2000}, {"title": "Optimal design of experiments, volume", "author": ["F. Pukelsheim"], "venue": "siam,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1993}, {"title": "Active regression by stratification", "author": ["S. Sabato", "R. Munos"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Pool-based active learning in approximate linear regression", "author": ["M. Sugiyama", "S. Nakajima"], "venue": "Machine Learning,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2009}, {"title": "Signal recovery from partial information via orthogonal matching pursuit", "author": ["J. Tropp", "A.C. Gilbert"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2005}, {"title": "Introduction to the non-asymptotic analysis of random matrices", "author": ["R. Vershynin"], "venue": "arXiv preprint arXiv:1011.3027,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2010}, {"title": "Sharp thresholds for high-dimensional and noisy sparsity recovery usingconstrained quadratic programming (lasso)", "author": ["M.J. Wainwright"], "venue": "Information Theory, IEEE Transactions on,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2009}, {"title": "Noise-adaptive margin-based active learning and lower bounds under tsybakov noise condition", "author": ["Y. Wang", "A. Singh"], "venue": "arXiv preprint arXiv:1406.5383,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}], "referenceMentions": [{"referenceID": 2, "context": ", [3, 6, 7, 8, 17].", "startOffset": 2, "endOffset": 18}, {"referenceID": 4, "context": ", [3, 6, 7, 8, 17].", "startOffset": 2, "endOffset": 18}, {"referenceID": 5, "context": ", [3, 6, 7, 8, 17].", "startOffset": 2, "endOffset": 18}, {"referenceID": 6, "context": ", [3, 6, 7, 8, 17].", "startOffset": 2, "endOffset": 18}, {"referenceID": 15, "context": ", [3, 6, 7, 8, 17].", "startOffset": 2, "endOffset": 18}, {"referenceID": 0, "context": ", [1, 2, 9, 10, 28].", "startOffset": 2, "endOffset": 19}, {"referenceID": 1, "context": ", [1, 2, 9, 10, 28].", "startOffset": 2, "endOffset": 19}, {"referenceID": 7, "context": ", [1, 2, 9, 10, 28].", "startOffset": 2, "endOffset": 19}, {"referenceID": 8, "context": ", [1, 2, 9, 10, 28].", "startOffset": 2, "endOffset": 19}, {"referenceID": 24, "context": ", [1, 2, 9, 10, 28].", "startOffset": 2, "endOffset": 19}, {"referenceID": 3, "context": ", [5, 18, 24] and the references within.", "startOffset": 2, "endOffset": 13}, {"referenceID": 16, "context": ", [5, 18, 24] and the references within.", "startOffset": 2, "endOffset": 13}, {"referenceID": 20, "context": ", [5, 18, 24] and the references within.", "startOffset": 2, "endOffset": 13}, {"referenceID": 19, "context": "A closely related work to our setting is [23]: they study online or stream-based active learning for linear regression, with random design.", "startOffset": 41, "endOffset": 45}, {"referenceID": 12, "context": "They propose a theoretical algorithm that partitions the space by stratification based on Monte-Carlo methods, where a recently proposed algorithm for linear regression [14] is used as a black box.", "startOffset": 169, "endOffset": 173}, {"referenceID": 19, "context": "While [23] does not tackle high-dimensional settings, we overcome the exponential data requirements via l1-regularization.", "startOffset": 6, "endOffset": 10}, {"referenceID": 18, "context": "This is related to the A-optimality criterion, [22].", "startOffset": 47, "endOffset": 51}, {"referenceID": 11, "context": "observations, \u03b2\u0302k := \u03b2\u0302 OLS k has sampling distribution \u03b2\u0302k | X \u223c N (\u03b2\u2217, \u03c32(XTX)\u22121), [13].", "startOffset": 85, "endOffset": 89}, {"referenceID": 22, "context": "Note that O(d) observations are required for accurate recovery when D is subgaussian, and O(d log d) if subexponential, [26].", "startOffset": 120, "endOffset": 124}, {"referenceID": 11, "context": "Since the variance of the MSE for fixed X depends on \u2211 j 1/\u03bbj(X X) [13], it is also minimized by selecting observations that lead to large eigenvalues of XX.", "startOffset": 67, "endOffset": 71}, {"referenceID": 21, "context": "Based, for example, on the results of [25] and Theorem 1 in [16], we could extend our results to subgaussian data via the Orthogonal Matching Pursuit algorithm for recovery.", "startOffset": 38, "endOffset": 42}, {"referenceID": 14, "context": "Based, for example, on the results of [25] and Theorem 1 in [16], we could extend our results to subgaussian data via the Orthogonal Matching Pursuit algorithm for recovery.", "startOffset": 60, "endOffset": 64}, {"referenceID": 23, "context": "3 summarizes the performance of Algorithm 2; it requires the standard assumptions on \u03a3, \u03bb and mini |\u03b2i| for support recovery (see Theorem 3 in [27]).", "startOffset": 143, "endOffset": 147}, {"referenceID": 23, "context": "Assume \u03a3, \u03bb and mini |\u03b2i| satisfy the standard conditions given in Theorem 3 of [27].", "startOffset": 80, "endOffset": 84}, {"referenceID": 22, "context": "The proof is a direct application of spectral results in [26], which are derived via a covering argument using a discrete net N on the unit Euclidean sphere Sd\u22121, together with a Bernstein-type concentration inequality that controls deviations of \u2016Xw\u20162 for each element w \u2208 N in the net.", "startOffset": 57, "endOffset": 61}, {"referenceID": 19, "context": "More generally, our probabilistic bounds are strongest when k \u2265 Cd log d for some constant C \u2265 0, a common situation in active learning [23], where super-linear requirements in d seem unavoidable in noisy settings.", "startOffset": 136, "endOffset": 140}, {"referenceID": 10, "context": "In the Bike Sharing dataset [12] we predict the number of hourly users of the service, given weather conditions, including temperature, wind speed, humidity, and temporal covariates.", "startOffset": 28, "endOffset": 32}, {"referenceID": 0, "context": "References [1] M.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] M.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[5] W.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[6] R.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[7] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[8] D.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[9] S.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[10] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "[11] P.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[12] H.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[13] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[14] D.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[15] T.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] V.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] A.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] B.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[22] F.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[23] S.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[24] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[25] J.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[26] R.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[27] M.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[28] Y.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "39 in [26] which guarantees that, for \u03b1 > 0 such that t = \u03b1 \u221a k \u2212 C \u221a d > 0, with probability at least 1\u2212 2 exp(\u2212ct) we have", "startOffset": 6, "endOffset": 10}, {"referenceID": 17, "context": "By [19], we have that P(Z\u03be \u2212 d \u2265 2 \u221a dx+ 2x) \u2264 exp(\u2212x).", "startOffset": 3, "endOffset": 7}, {"referenceID": 13, "context": "1 of [15].", "startOffset": 5, "endOffset": 9}, {"referenceID": 13, "context": "1 of [15]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "The CLT is a good idea for bounded variables (as the square is still bounded, and therefore subgaussian), but if the underlying components Xj are unbounded subgaussian, Z\u03be will be at least subexponential\u2014as the square of a subgaussian random variable is subexponential, [26]\u2014, and a higher threshold \u2014like that coming from chi-squared\u2014 is more appropriate.", "startOffset": 270, "endOffset": 274}, {"referenceID": 13, "context": "1 of [15], we have that for small k/n \u221a 2 log(n/k)\u2212 log(4 log(n/k)) + 2 2 \u221a 2 log(n/k) \u2264 \u03a6\u22121 ( 1\u2212 k n ) (43)", "startOffset": 5, "endOffset": 9}, {"referenceID": 9, "context": "Further, the normalizing constants are known (see Chapter 3 of [11]).", "startOffset": 63, "endOffset": 67}, {"referenceID": 0, "context": "Fix \u03b1 \u2208 [0, 1].", "startOffset": 8, "endOffset": 14}, {"referenceID": 23, "context": "Assume \u03a3, \u03bb and mini |\u03b2i| satisfy the standard conditions given in Theorem 3 of [27].", "startOffset": 80, "endOffset": 84}, {"referenceID": 23, "context": "For support recovery, we use Theorem 3 from [27]: Theorem H.", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "The covariance matrix of \u03b2\u0302\u03bb is Cov(\u03b2\u0302\u03bb) = \u03c3 WXXW, while its bias is given by \u2212\u03bbW\u03b2\u2217 (see [13]).", "startOffset": 89, "endOffset": 93}], "year": 2016, "abstractText": "We consider the problem of online active learning to collect data for regression modeling. Specifically, we consider a decision maker with a limited experimentation budget who must efficiently learn an underlying linear population model. Our main contribution is a novel threshold-based algorithm for selection of most informative observations; we characterize its performance and fundamental lower bounds. We extend the algorithm and its guarantees to sparse linear regression in high-dimensional settings. Simulations suggest the algorithm is remarkably robust: it provides significant benefits over passive random sampling in real-world datasets that exhibit high nonlinearity and high dimensionality \u2014 significantly reducing both the mean and variance of the squared error.", "creator": "LaTeX with hyperref package"}}}