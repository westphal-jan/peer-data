{"id": "1602.03481", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2016", "title": "Achieving budget-optimality with adaptive schemes in crowdsourcing", "abstract": "Crowdsourcing systems provide scalable and cost-effective human-powered solutions at marginal cost, for classification tasks where humans are significantly better than the machines. Although traditional approaches in aggregating crowdsourced labels have relied on the Dawid-Skene model, this fails to capture how some tasks are inherently more difficult than the others. Several generalizations have been proposed, but inference becomes intractable and typical solutions resort to heuristics. To bridge this gap, we study a recently proposed generalize Dawid-Skene model, and propose a linear-time algorithm based on spectral methods. We show near-optimality of the proposed approach, by providing an upper bound on the error and comparing it to a fundamental limit. We provide numerical experiments on synthetic data matching our analyses, and also on real datasets demonstrating that the spectral method significantly improves over simple majority voting and is comparable to other methods.", "histories": [["v1", "Wed, 10 Feb 2016 18:46:30 GMT  (212kb)", "http://arxiv.org/abs/1602.03481v1", "15 pages, 4 figures"], ["v2", "Tue, 29 Nov 2016 04:31:25 GMT  (118kb,D)", "http://arxiv.org/abs/1602.03481v2", "22 pages, 4 figures"], ["v3", "Fri, 25 Aug 2017 16:35:55 GMT  (134kb,D)", "http://arxiv.org/abs/1602.03481v3", "32 pages, 4 figures"]], "COMMENTS": "15 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.LG cs.HC cs.SI stat.ML", "authors": ["ashish khetan", "sewoong oh"], "accepted": true, "id": "1602.03481"}, "pdf": {"name": "1602.03481.pdf", "metadata": {"source": "CRF", "title": "Reliable Crowdsourcing under the Generalized Dawid-Skene Model", "authors": ["Ashish Khetan", "Sewoong Oh"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 160 2.03 481v 1 [cs.L G] 10 Feb 2016"}, {"heading": "1 Introduction", "text": "This results in savings in the budget for crowdsourcing applicants. However, algorithmic and theoretical advances have focused on the Dawid Skene model to describe how workers respond to tasks that do not capture, as some tasks are inherently more difficult than the others. In fact, tailored to real-world crowdsourcing tasks to capture the inherent difficulty of tasks, we achieve significantly better performance. We bridge this gap by studying a generalized Dawid Skene model and examining the basic boundary of what the best algorithms can achieve and a suitable linear age algorithm. Setup. We consider a crowdsourcing system with m tasks to be classified and n-workers. We model workers \"responses with a current generalization of the Dawid Skene model (2015), which was introduced in Zhou et al."}, {"heading": "2 Main Results", "text": "We present an iterative algorithm based on a spectral method and provide an upper limit for the error rate achieved by this algorithm in Theorem 2.2. Comparing it to a basic lower limit in Lemma 2.3, we find the near-optimality of our approach."}, {"heading": "2.1 Algorithm", "text": "We propose to use a state-of-the-art spectral method based on non-traceable operators first presented in Karger et al. (2011). A similar approach was later applied to other consequence problems, e.g. the method of automatic traceability (2013); Bordenave et al. (2015) We compare the proposed iterative algorithm with other standard methods in Section 4, and show that typical approaches such as EM or faith propagation are mathematically intractable. The proposed algorithm is a message delivery algorithm that operates on two types of messages: the task messages {xi \u2192 j} (i, j) and the task is probably a positive task and the work messages {yj \u2192 i} (i, j)."}, {"heading": "2.2 Performance Guarantee", "text": "We determine when the proposed spectral method works and prove a sharp limit on the error rate that can be reached. To simplify the notation, we let the number of error messages increase based on the central limit theory. By tracking how the mean and variance evolve, we can accurately describe the probability of errors that are achieved by the proposed iterative algorithm. Theorem 2.1. Support for the results of other (n) and Logm logm logm (n) tasks are assigned to random graphs based on (n) regular graphs. Then, for each t > 0, the estimate t (n) is reached according to k iterations of Algorithm 1."}, {"heading": "2.3 Fundamental Limit", "text": "From Theorem 2.2 it follows that it is sufficient to assign an error smaller than \u03b5 for a task i among a wide range of parameters. In the following theorem we show that this scaling is also necessary. Therefore, our iterative algorithm is nearly optimal in terms of the average number of workers assigned to each task, in a Minimax scenario in which we consider the best task assignment scheme with the best inference algorithm, and nature selects the worst distribution of workers PJ among the distributions with the same \u03b2. We provide proof of the problem in Section B in the supplementary material. Lemma 2.3. There is a positive constant C \u2032 s.t. if (2qi \u2212 1) < 1 if the number of workers assigned to task i by a non-adaptive task assignment scheme is less than (C \u2032 / (\u03b2 (2qi \u2212 2 \u2212 1), then an error can be less than 1 / 2), and no condition for a task less than 1)."}, {"heading": "3 Experimental Results", "text": "In Figure 4, we compare our algorithm with alternating minimization and majority matching of simulated data and real data. The first plot is created under the same settings as the first plot in Figure 3, except that we use n = m = 300 and \u03b2 = 0.2 here. It shows that our algorithm and alternating minimization are almost identical after the phase transition, while alternating minimization before the phase transition is better. In the second plot, we compare all three algorithms with real data collected by Amazon Mechanical Turk. We developed an experiment like this: We created color comparison tasks; we showed three colors for each task and asked the worker to specify \"whether the first color is more similar to the second color or the third color.\" We created 50 such color comparison tasks and recruited 28 workers to answer all the tasks. We take the basic truth that the color is closer to the first color in paired spacing in the color space. The second of the algorithms shows the probability of the number of errors when the three answers are asked."}, {"heading": "4 Comparisons to other algorithms", "text": "If the number of people is of different quality in order to optimally estimate tasks, we must first estimate the skills of workers (usually a maximum number of people) (usually a maximum number of people).If the number of people (usually a maximum number of people) is different, this is usually solved using an EM algorithm that treats them as latent variables. However, as Qis are continuous in our environment, the reduction of the lower limit of P [q] p0, A] is logged."}, {"heading": "5 Proof of Theorems 2.1 and 2.2", "text": "We will prove the main results for a randomly selected node I (m), and all analyses are, of course, for a specific i if they are done on the basis of Qi. Let t (k) i estimate the resulting task i after executing the iterative inference algorithms for k iterations. Let us calculate the conditional error probability of a task I randomly selected, i.e., P [tI 6 = t) I assume that qI (1 / 2), i.e. the true label is ti = 1. The analysis for qI \u2264 (1 / 2) is similar and leads to the same result in our algorithm, we perform task assignment on a random bipartite graph G (m). [n], E) constructed according to the configuration model."}, {"heading": "6 Discussion", "text": "We are examining a generalized Dawid-Skene model that captures the difficulties of the tasks. We propose a spectral approach that is linear in time in the problem parameters. We show that this approach achieves near-optimal performance by setting a sharp limit on the error rate and comparing it to a basic lower limit. One of the most interesting findings is that for heterogeneous tasks, a uniform assignment of the same number of workers to each task is bad. Overall, the average error rate is dominated by the most difficult tasks. It is consistent with our intuition that those tasks that are inherently more difficult should be assigned more workers."}, {"heading": "A Proof of Theorems 2.1 and 2.2 continued", "text": "By the definition of x (k) q (23), E (e) q (k) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (1) q (2) q (1) q) q (2) q (1) q) p (1) q) q (2), p (2), p) q (2), p), p (2), p (2), p (2), p (p), p (p), p), p (2), p (p), p), p (p), p), p (2), p (p)."}, {"heading": "B Proof of lower bound lemma 2.3", "text": "Let F be a distribution to the worker quality pj = 1 / 2 with probability 1 / 1. Let F\u03b2 be a collection of all distributions F so that: F\u03b2 = {F | EF [(2pj \u2212 1) 2] = \u03b2 \u00b2. Define the Minimax rate to the error probability of a task i, due to its difficulty level qi, asmin."}], "references": [{"title": "The probabilistic method", "author": ["Alon", "Noga", "Spencer", "Joel H"], "venue": null, "citeRegEx": "Alon et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Alon et al\\.", "year": 2004}, {"title": "Non-backtracking spectrum of random graphs: community detection and non-regular ramanujan graphs", "author": ["Bordenave", "Charles", "Lelarge", "Marc", "Massouli\u00e9", "Laurent"], "venue": "In Foundations of Computer Science (FOCS),", "citeRegEx": "Bordenave et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bordenave et al\\.", "year": 2015}, {"title": "Aggregating crowdsourced binary ratings", "author": ["N. Dalvi", "A. Dasgupta", "R. Kumar", "V. Rastogi"], "venue": "In Proceedings of the 22nd international conference on World Wide Web,", "citeRegEx": "Dalvi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dalvi et al\\.", "year": 2013}, {"title": "Maximum likelihood estimation of observer error-rates using the em algorithm", "author": ["A.P. Dawid", "A.M. Skene"], "venue": "Applied statistics,", "citeRegEx": "Dawid and Skene,? \\Q1979\\E", "shortCiteRegEx": "Dawid and Skene", "year": 1979}, {"title": "Minimax optimal convergence rates for estimating ground truth from crowdsourced labels", "author": ["C. Gao", "D. Zhou"], "venue": "arXiv preprint arXiv:1310.5764,", "citeRegEx": "Gao and Zhou,? \\Q2013\\E", "shortCiteRegEx": "Gao and Zhou", "year": 2013}, {"title": "Who moderates the moderators?: crowdsourcing abuse detection in user-generated content", "author": ["Ghosh", "Arpita", "Kale", "Satyen", "McAfee", "Preston"], "venue": "In Proceedings of the 12th ACM conference on Electronic commerce,", "citeRegEx": "Ghosh et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ghosh et al\\.", "year": 2011}, {"title": "Learning with multiple labels", "author": ["R. Jin", "Z. Ghahramani"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Jin and Ghahramani,? \\Q2003\\E", "shortCiteRegEx": "Jin and Ghahramani", "year": 2003}, {"title": "Iterative learning for reliable crowdsourcing systems. In Advances in neural information processing", "author": ["D.R. Karger", "S. Oh", "D. Shah"], "venue": null, "citeRegEx": "Karger et al\\.,? \\Q1953\\E", "shortCiteRegEx": "Karger et al\\.", "year": 1953}, {"title": "Efficient crowdsourcing for multi-class labeling", "author": ["D.R. Karger", "S. Oh", "D. Shah"], "venue": "In Proceedings of the ACM SIGMETRICS/international conference on Measurement and modeling of computer systems,", "citeRegEx": "Karger et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Karger et al\\.", "year": 2013}, {"title": "Budget-optimal task allocation for reliable crowdsourcing systems", "author": ["D.R. Karger", "S. Oh", "D. Shah"], "venue": "Operations Research,", "citeRegEx": "Karger et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Karger et al\\.", "year": 2014}, {"title": "Budget-optimal task allocation for reliable crowdsourcing systems", "author": ["Karger", "David R", "Oh", "Sewoong", "Shah", "Devavrat"], "venue": "Operations Research,", "citeRegEx": "Karger et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Karger et al\\.", "year": 2014}, {"title": "Matrix completion from a few entries", "author": ["Keshavan", "Raghunandan H", "Oh", "Sewoong", "Montanari", "Andrea"], "venue": "In Information Theory,", "citeRegEx": "Keshavan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Keshavan et al\\.", "year": 2009}, {"title": "Spectral redemption in clustering sparse networks", "author": ["Krzakala", "Florent", "Moore", "Cristopher", "Mossel", "Elchanan", "Neeman", "Joe", "Sly", "Allan", "Zdeborov\u00e1", "Lenka", "Zhang", "Pan"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Krzakala et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Krzakala et al\\.", "year": 2013}, {"title": "Error rate bounds and iterative weighted majority voting for crowdsourcing", "author": ["H. Li", "B. Yu"], "venue": "arXiv preprint arXiv:1411.4086,", "citeRegEx": "Li and Yu,? \\Q2014\\E", "shortCiteRegEx": "Li and Yu", "year": 2014}, {"title": "Error rate analysis of labeling by crowdsourcing", "author": ["H. Li", "B. Yu", "D. Zhou"], "venue": "In Proc. Machine Learning meets Crowdsourcing, Workshop at the Int?l Conference on Machine Learning (ICML-2013),", "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Variational inference for crowdsourcing", "author": ["Liu", "Qiang", "Peng", "Jian", "Ihler", "Alex T"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Liu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Information, physics, and computation", "author": ["Mezard", "Marc", "Montanari", "Andrea"], "venue": null, "citeRegEx": "Mezard et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mezard et al\\.", "year": 2009}, {"title": "Get another label? improving data quality and data mining using multiple, noisy labelers", "author": ["Sheng", "Victor S", "Provost", "Foster", "Ipeirotis", "Panagiotis G"], "venue": "In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Sheng et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Sheng et al\\.", "year": 2008}, {"title": "Inferring ground truth from subjective labelling of venus images", "author": ["P. Smyth", "U. Fayyad", "M. Burl", "P. Perona", "P. Baldi"], "venue": "In NIPS,", "citeRegEx": "Smyth et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Smyth et al\\.", "year": 1995}, {"title": "The multidimensional wisdom of crowds", "author": ["P. Welinder", "S. Branson", "S. Belongie", "P. Perona"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Welinder et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Welinder et al\\.", "year": 2010}, {"title": "Whose vote should count more: Optimal integration of labels from labelers of unknown expertise", "author": ["J. Whitehill", "P. Ruvolo", "T. Wu", "J. Bergsma", "J. Movellan"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Whitehill et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Whitehill et al\\.", "year": 2009}, {"title": "Spectral methods meet em: A provably optimal algorithm for crowdsourcing", "author": ["Y. Zhang", "X. Chen", "D. Zhou", "M.I. Jordan"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Learning from the wisdom of crowds by minimax entropy", "author": ["D. Zhou", "J. Platt", "S. Basu", "Y. Mao"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Zhou et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2012}, {"title": "Regularized minimax conditional entropy for crowdsourcing", "author": ["D. Zhou", "Q. Liu", "J.C. Platt", "C. Meek", "N.B. Shah"], "venue": "arXiv preprint arXiv:1503.07240,", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 22, "context": "We model the worker responses using a recent generalization of the Dawid-Skene model introduced in Zhou et al. (2015), that models how different tasks can have different difficulties.", "startOffset": 99, "endOffset": 118}, {"referenceID": 4, "context": "The original Dawid-Skene model introduced in Dawid & Skene (1979) and analyzed in Karger et al. (2014a) is a special case, when all tasks are equally easy, i.", "startOffset": 82, "endOffset": 104}, {"referenceID": 2, "context": "This idea was first introduced by Dawid and Skene (Dawid & Skene, 1979) who proposed an Expectation Maximization (EM) approach. Following this work, several approaches have been proposed to solve the inference problem under the Dawid-Skene model Smyth et al. (1995); Sheng et al.", "startOffset": 34, "endOffset": 266}, {"referenceID": 2, "context": "This idea was first introduced by Dawid and Skene (Dawid & Skene, 1979) who proposed an Expectation Maximization (EM) approach. Following this work, several approaches have been proposed to solve the inference problem under the Dawid-Skene model Smyth et al. (1995); Sheng et al. (2008); Karger et al.", "startOffset": 34, "endOffset": 287}, {"referenceID": 2, "context": "This idea was first introduced by Dawid and Skene (Dawid & Skene, 1979) who proposed an Expectation Maximization (EM) approach. Following this work, several approaches have been proposed to solve the inference problem under the Dawid-Skene model Smyth et al. (1995); Sheng et al. (2008); Karger et al. (2011); Liu et al.", "startOffset": 34, "endOffset": 309}, {"referenceID": 2, "context": "This idea was first introduced by Dawid and Skene (Dawid & Skene, 1979) who proposed an Expectation Maximization (EM) approach. Following this work, several approaches have been proposed to solve the inference problem under the Dawid-Skene model Smyth et al. (1995); Sheng et al. (2008); Karger et al. (2011); Liu et al. (2012a); Zhou et al.", "startOffset": 34, "endOffset": 329}, {"referenceID": 2, "context": "This idea was first introduced by Dawid and Skene (Dawid & Skene, 1979) who proposed an Expectation Maximization (EM) approach. Following this work, several approaches have been proposed to solve the inference problem under the Dawid-Skene model Smyth et al. (1995); Sheng et al. (2008); Karger et al. (2011); Liu et al. (2012a); Zhou et al. (2012); Li & Yu (2014); Zhang et al.", "startOffset": 34, "endOffset": 349}, {"referenceID": 2, "context": "This idea was first introduced by Dawid and Skene (Dawid & Skene, 1979) who proposed an Expectation Maximization (EM) approach. Following this work, several approaches have been proposed to solve the inference problem under the Dawid-Skene model Smyth et al. (1995); Sheng et al. (2008); Karger et al. (2011); Liu et al. (2012a); Zhou et al. (2012); Li & Yu (2014); Zhang et al.", "startOffset": 34, "endOffset": 365}, {"referenceID": 2, "context": "This idea was first introduced by Dawid and Skene (Dawid & Skene, 1979) who proposed an Expectation Maximization (EM) approach. Following this work, several approaches have been proposed to solve the inference problem under the Dawid-Skene model Smyth et al. (1995); Sheng et al. (2008); Karger et al. (2011); Liu et al. (2012a); Zhou et al. (2012); Li & Yu (2014); Zhang et al. (2014); Dalvi et al.", "startOffset": 34, "endOffset": 386}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks.", "startOffset": 8, "endOffset": 28}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al.", "startOffset": 8, "endOffset": 195}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance.", "startOffset": 8, "endOffset": 283}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem.", "startOffset": 8, "endOffset": 340}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem. However, in this dense regime, all tasks are assigned a growing number of workers as the problem size increases and eventually all tasks are labelled correctly with high probability. In this paper, we are interested in a more challenging setting where each task is assigned only a small number of workers. A spectral algorithm has been analyzed under the original Dawid-Skene model in Dalvi et al. (2013), and tighter analysis showed that the spectral approach is near-optimal in Karger et al.", "startOffset": 8, "endOffset": 866}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem. However, in this dense regime, all tasks are assigned a growing number of workers as the problem size increases and eventually all tasks are labelled correctly with high probability. In this paper, we are interested in a more challenging setting where each task is assigned only a small number of workers. A spectral algorithm has been analyzed under the original Dawid-Skene model in Dalvi et al. (2013), and tighter analysis showed that the spectral approach is near-optimal in Karger et al. (2011). A weighted majority voting algorithm has been analyzed in Li et al.", "startOffset": 8, "endOffset": 962}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem. However, in this dense regime, all tasks are assigned a growing number of workers as the problem size increases and eventually all tasks are labelled correctly with high probability. In this paper, we are interested in a more challenging setting where each task is assigned only a small number of workers. A spectral algorithm has been analyzed under the original Dawid-Skene model in Dalvi et al. (2013), and tighter analysis showed that the spectral approach is near-optimal in Karger et al. (2011). A weighted majority voting algorithm has been analyzed in Li et al. (2013), showing the dependence on the choice of the weights.", "startOffset": 8, "endOffset": 1038}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem. However, in this dense regime, all tasks are assigned a growing number of workers as the problem size increases and eventually all tasks are labelled correctly with high probability. In this paper, we are interested in a more challenging setting where each task is assigned only a small number of workers. A spectral algorithm has been analyzed under the original Dawid-Skene model in Dalvi et al. (2013), and tighter analysis showed that the spectral approach is near-optimal in Karger et al. (2011). A weighted majority voting algorithm has been analyzed in Li et al. (2013), showing the dependence on the choice of the weights. The original Dawid-Skene model, when all qi\u2019s are either one or zero, several practical inference algorithms have been developed with strong performance guarantees. However, one of the main weakness of the model is that it does not capture how some tasks are more difficult than the others. To overcome this challenge, several practical models have been proposed recently Jin & Ghahramani (2003); Whitehill et al.", "startOffset": 8, "endOffset": 1488}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem. However, in this dense regime, all tasks are assigned a growing number of workers as the problem size increases and eventually all tasks are labelled correctly with high probability. In this paper, we are interested in a more challenging setting where each task is assigned only a small number of workers. A spectral algorithm has been analyzed under the original Dawid-Skene model in Dalvi et al. (2013), and tighter analysis showed that the spectral approach is near-optimal in Karger et al. (2011). A weighted majority voting algorithm has been analyzed in Li et al. (2013), showing the dependence on the choice of the weights. The original Dawid-Skene model, when all qi\u2019s are either one or zero, several practical inference algorithms have been developed with strong performance guarantees. However, one of the main weakness of the model is that it does not capture how some tasks are more difficult than the others. To overcome this challenge, several practical models have been proposed recently Jin & Ghahramani (2003); Whitehill et al. (2009); Welinder et al.", "startOffset": 8, "endOffset": 1513}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem. However, in this dense regime, all tasks are assigned a growing number of workers as the problem size increases and eventually all tasks are labelled correctly with high probability. In this paper, we are interested in a more challenging setting where each task is assigned only a small number of workers. A spectral algorithm has been analyzed under the original Dawid-Skene model in Dalvi et al. (2013), and tighter analysis showed that the spectral approach is near-optimal in Karger et al. (2011). A weighted majority voting algorithm has been analyzed in Li et al. (2013), showing the dependence on the choice of the weights. The original Dawid-Skene model, when all qi\u2019s are either one or zero, several practical inference algorithms have been developed with strong performance guarantees. However, one of the main weakness of the model is that it does not capture how some tasks are more difficult than the others. To overcome this challenge, several practical models have been proposed recently Jin & Ghahramani (2003); Whitehill et al. (2009); Welinder et al. (2010); Zhou et al.", "startOffset": 8, "endOffset": 1537}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem. However, in this dense regime, all tasks are assigned a growing number of workers as the problem size increases and eventually all tasks are labelled correctly with high probability. In this paper, we are interested in a more challenging setting where each task is assigned only a small number of workers. A spectral algorithm has been analyzed under the original Dawid-Skene model in Dalvi et al. (2013), and tighter analysis showed that the spectral approach is near-optimal in Karger et al. (2011). A weighted majority voting algorithm has been analyzed in Li et al. (2013), showing the dependence on the choice of the weights. The original Dawid-Skene model, when all qi\u2019s are either one or zero, several practical inference algorithms have been developed with strong performance guarantees. However, one of the main weakness of the model is that it does not capture how some tasks are more difficult than the others. To overcome this challenge, several practical models have been proposed recently Jin & Ghahramani (2003); Whitehill et al. (2009); Welinder et al. (2010); Zhou et al. (2015). Although inference algorithms based on these more complex models significantly improve over those based on Dawid-Skene model on real-world datasets, there is no analysis on their performance.", "startOffset": 8, "endOffset": 1557}, {"referenceID": 2, "context": "(2014); Dalvi et al. (2013). In the theoretical side, the dense regime has been studied first, where all workers are assigned all tasks. Spectral method was first analyzed in Ghosh et al. (2011) and an EM approach followed by spectral initial step is analyzed in Zhang et al. (2014) to achieve a near-optimal performance. Gao & Zhou (2013) analyzed the MAP estimator, which is computationally intractable, and identified the minimax error rate of this problem. However, in this dense regime, all tasks are assigned a growing number of workers as the problem size increases and eventually all tasks are labelled correctly with high probability. In this paper, we are interested in a more challenging setting where each task is assigned only a small number of workers. A spectral algorithm has been analyzed under the original Dawid-Skene model in Dalvi et al. (2013), and tighter analysis showed that the spectral approach is near-optimal in Karger et al. (2011). A weighted majority voting algorithm has been analyzed in Li et al. (2013), showing the dependence on the choice of the weights. The original Dawid-Skene model, when all qi\u2019s are either one or zero, several practical inference algorithms have been developed with strong performance guarantees. However, one of the main weakness of the model is that it does not capture how some tasks are more difficult than the others. To overcome this challenge, several practical models have been proposed recently Jin & Ghahramani (2003); Whitehill et al. (2009); Welinder et al. (2010); Zhou et al. (2015). Although inference algorithms based on these more complex models significantly improve over those based on Dawid-Skene model on real-world datasets, there is no analysis on their performance. Contributions. We bridge this gap between simple models with strong guarantees and complex models that represent real-world data. To the best of our knowledge, we provide the first analysis on a crowdsourcing model that captures the difficulties of the tasks, namely the generalized Dawid-Skene model introduced in Zhou et al. (2015). We propose an efficient iterative algorithm based on spectral methods, which does not require any hyper-parameters, only takes the crowdsourced data as input, and runs in time linear in the number of received answers up to a logarithmic factor.", "startOffset": 8, "endOffset": 2084}, {"referenceID": 6, "context": "1 Algorithm We propose using a state-of-the-art spectral method based on non-backtracking operators, first introduced for inference in Karger et al. (2011). A similar approach has been later applied to other inference problems, e.", "startOffset": 135, "endOffset": 156}, {"referenceID": 6, "context": "1 Algorithm We propose using a state-of-the-art spectral method based on non-backtracking operators, first introduced for inference in Karger et al. (2011). A similar approach has been later applied to other inference problems, e.g. Krzakala et al. (2013); Bordenave et al.", "startOffset": 135, "endOffset": 256}, {"referenceID": 1, "context": "(2013); Bordenave et al. (2015). We compare the proposed iterative algorithm with other standard methods in Section 4, and show that typical approaches such as the EM or the belief propagation are computationally intractable.", "startOffset": 8, "endOffset": 32}, {"referenceID": 7, "context": "Also, typical random matrix analyses, such as those in Keshavan et al. (2009); Karger et al.", "startOffset": 55, "endOffset": 78}, {"referenceID": 7, "context": "(2009); Karger et al. (2013), shows that the spectral norm of the noise (A \u2212 E[A]) is bounded by C((l \u2212 1)(r \u2212 1)) with some constant C.", "startOffset": 8, "endOffset": 29}, {"referenceID": 7, "context": "We run synthetic experiments with m = n = 1000 and the crowds are generated from the spammer-hammer model where pj = 1 with probability \u03b2 and 1/2 otherwise Karger et al. (2014b). We fix \u03b2 = 0.", "startOffset": 156, "endOffset": 178}, {"referenceID": 15, "context": "Only when pj\u2019s are continuous and qi\u2019s are discrete Liu et al. (2012b) propose algorithms to compute the marginals using modified belief propagation and mean field method both.", "startOffset": 52, "endOffset": 71}, {"referenceID": 7, "context": "We use a result from Karger et al. (2014b) to show that the local neighborhood of a randomly chosen task node I is a tree with high probability.", "startOffset": 21, "endOffset": 43}, {"referenceID": 7, "context": "(15) The next lemma from Karger et al. (2014b) shows that the local subgraph is a tree with high probability as m grows.", "startOffset": 25, "endOffset": 47}, {"referenceID": 7, "context": "1 (Lemma 5 from Karger et al. (2014b)).", "startOffset": 16, "endOffset": 38}, {"referenceID": 7, "context": "The proof technique is similar to the one introduced in Karger et al. (2014b). Precisely, we show,", "startOffset": 56, "endOffset": 78}], "year": 2016, "abstractText": "Crowdsourcing systems provide scalable and cost-effective human-powered solutions at marginal cost, for classification tasks where humans are significantly better than the machines. Although traditional approaches in aggregating crowdsourced labels have relied on the Dawid-Skene model, this fails to capture how some tasks are inherently more difficult than the others. Several generalizations have been proposed, but inference becomes intractable and typical solutions resort to heuristics. To bridge this gap, we study a recently proposed generalize Dawid-Skene model, and propose a linear-time algorithm based on spectral methods. We show near-optimality of the proposed approach, by providing an upper bound on the error and comparing it to a fundamental limit. We provide numerical experiments on synthetic data matching our analyses, and also on real datasets demonstrating that the spectral method significantly improves over simple majority voting and is comparable to other methods.", "creator": "gnuplot 5.0 patchlevel 1"}}}