{"id": "1602.03483", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2016", "title": "Learning Distributed Representations of Sentences from Unlabelled Data", "abstract": "Unsupervised methods for learning distributed representations of words are ubiquitous in today's NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-linear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance.", "histories": [["v1", "Wed, 10 Feb 2016 18:49:58 GMT  (32kb)", "http://arxiv.org/abs/1602.03483v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.LG", "authors": ["felix hill", "kyunghyun cho", "anna korhonen"], "accepted": true, "id": "1602.03483"}, "pdf": {"name": "1602.03483.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Kyunghyun Cho", "Anna Korhonen"], "emails": ["felix.hill@cl.cam.ac.uk", "kyunghyun.cho@nyu.edu", "alk23@cam.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 160 2.03 483v 1 [cs.C L] 10 FeUnsupervised methods for learning distributed representations of words are ubiquitous in today's NLP research, but far less is known about the best way to learn distributed phrase or sentence representations from unlabeled data. This paper is a systematic comparison of models learning such representations. We find that the optimal approach depends crucially on the intended application. Deeper, more complex models are preferable when they are to be used in monitored systems, but flat log-linear models are best suited for constructing representation spaces that can be deciphered with simple spatial distance measurements. We also propose two new, unattended targets that aim to optimize the trade-off between training time, domain portability and performance."}, {"heading": "1 Introduction", "text": "Distributed representations - densely packed vectors that encrypt the semantics of linguistic units - are ubiquitous in today's NLP research; for single words or word-like entities, there are established ways to obtain such representations from naturally occurring (unlabeled) training data based on comparatively task-agnostic objectives (such as predicting adjacent words), understood empirically (Baroni et al., 2014b) and theoretically (Levy and Goldberg, 2014); the best word representation spaces reflect aspects of human conceptual organization (Hill et al., 2015b) and can be added as attributes that improve the performance of numerous language processing systems (Collobert et al., 2011); in contrast, there is comparatively little consensus on distributed representations of phrases or sentences."}, {"heading": "2 Distributed Sentence Representations", "text": "To limit the analysis, we compare neural language models that compute sentence representations from unlabeled, naturally occurring data, as with the prevailing methods for word representation. [2] Nor do we focus on \"bottom-up\" models, where phrases or sentences are constructed from fixed mathematical operations on word vectors (although we consider a canonical case - see CBOW below); these have already been compared by Milajevs et al. (2014). Most of the space is devoted to our novel approaches, and we refer the reader to the original papers for more details on existing models. [2] This excludes innovative monitored sentenzel architectures, including (Socher et al., 2011; Kalchbrenner et al., 2014) and many others."}, {"heading": "2.1 Existing Models Trained on Text", "text": "The cost of a training example is the sum of the individual correct words in the targets, the Si \u2212 1, Si + 1 in any document, the SkipThought model (Kiros et al., 2015) is trained to predict target sentences Si \u2212 1 and Si + 1 given source sentence Si. As with all sequence-to-sequence models, the source sentence is \"encoded\" by a recursive neural network (RNN) (using gated recurrent uUnits (Cho et al., 2014) and then \"decrypted\" into the two target sentences. Importantly, RNNs use a single set of update weights in each time step, both the encoder and the decoder decoder decoder."}, {"heading": "2.2 Models Trained on Structured Resources", "text": "The following models are based on (freely available) data that have more structure than raw text. DictRep Hill et al. (2015a) trained neural language models to map dictionary definitions to pre-trained word embeddings of the words defined by these definitions. They experimented with BOW and RNN (with LSTM) encoding architectures and variants in which the input word embeddings were either learned or pre-trained (+ embs.) to match the target word embeddings. We implement their models using the available code and training data.6CaptionRep With the same overall architecture, we trained (BOW and RNN) models to assign captions in the COCO dataset (Chen et al., 2015) to pre-trained vector representations of images. The images were encoded by a deep revolutionary network (Szegedy et al. 2014) we did not pre-code the 2014 object task based on the SVC."}, {"heading": "2.3 Novel Text-Based Models", "text": "We present two new approaches to address certain limitations with the existing models."}, {"heading": "2.4 Training and Model Selection", "text": "Unless mentioned above, all models have been trained at the Toronto Books Corpus, which has the interpretative coherence required for SkipThought and FastSent. The corpus consists of 70 million ordered sets of over 7,000 books. Model specifications are in Table 1. Log-linear models (SkipGram, CBOW, ParagraphVec, and FastSent) have been trained for an epoch on a CPU core. Display dimension d for these models was found after tuning d = 100, 200, 300, 400, 500} on the validation kit. 10 All other models have been trained on a GPU. S (D) AE models have been trained for an epoch (about 8 days). SkipThought model was trained for two weeks and spanned just under one epoch. 11 CaptionRep and DictRep monitored performance on pre-set training data and the training was stopped after 24 hours of a Plateau NT cost of 72 hours."}, {"heading": "3 Evaluating Sentence Representations", "text": "In previous work, distributed language representations were evaluated either by measuring the effect of adding representations as features in 9http: / / www.cs.toronto.edu / \u02dc mbweb / 10For ParagraphVec only d '100, 200} due to the high memory footprint. 11Downloaded from https: / / github.com / ryankiros / skip-thoughtssome classification task - monitored evaluation (Collobert et al., 2011; Mikolov et al., 2013a; Kiros et al., 2015) - or by comparing them with human kinship judgments - reckless evaluation (Hill et al., 2015a; Baroni et al., 2014b; Levy et al., 2015)."}, {"heading": "3.1 Supervised Evaluations", "text": "Presentations are applied to 6 sentence classification tasks: Paraphrase Identification (MSRP) (Dolan et al., 2004), Film Opinion (MR) (Pang et al., 2005), Product Assessment (CR) (Hu and Liu, 2004), Subjectivity Classification (SUBJ) (Pang and Lee, 2004), Opinion Polarity (MPQA) (Wiebe et al., 2005) and Question Type Classification (TREC) (Voorhees, 2002). We follow the procedure (and code) of Kiros et al. (2015): A logistic regression classifier is trained on sentence representations, using 10-fold cross-validation when a train-test split is not predefined."}, {"heading": "3.2 Unsupervised Evaluations", "text": "The SICK dataset (Marelli et al., 2014) consists of 10,000 sentence pairs and reference ratings. The STS dataset 2014 (Agirre et al., 2014) consists of 3,750 pairs and ratings from six linguistic domains. Example ratings are in Table 2. All available pairs are used for testing, except for the 500 SICK \"trial\" pairs reserved for matching hyperparameters (representation size of log-linear models and noise parameters in SDAE), and the optimal settings for this task are then applied to both monitored and unattended evaluations."}, {"heading": "4 Results", "text": "Overall, SkipThought vectors perform best in three of the six ratings, with the BOW DictRep model, with pre-embedded words, scoring best in two and the SDAE in one. SDAE also performs significantly better in the paraphrasing task, exceeding SkipThought by three percentage points and approaching the performance of models designed specifically for this task (Ji and Eisenstein, 2013). SDAE is also consistently better than SAE, which is consistent with other results, according to which adding noise leads to richer representations (Vincent et al., 2008). Results of the non-verified ratings are shown in Table 4. The same DictRep model scores best in four of the six STS categories (and overall)."}, {"heading": "5 Discussion", "text": "It may be that the different learning methods used in the individual countries are handled differently by the individual countries. (...) It may be that the individual countries behave differently. (...) It may not be the case that the individual countries agree on a common denominator. (...) It may not be the case that the individual countries agree on a common denominator. (...) It may not be the case that the individual countries agree on a common denominator. (...) It may not be the case that the individual countries agree on a common denominator. (...) It may be the case that the countries agree on a common denominator. (...) It may not be the case that the countries agree on a common denominator. (...) It may be that the countries agree on a common denominator. (...) It may be that the countries agree on a common denominator. (...) It may not be the case that the countries agree on a common denominator."}, {"heading": "6 Conclusion", "text": "Advances in deep learning algorithms, software and hardware mean that many architectures and objectives for learning distributed sentence representations from unlabeled data are now available to NLP researchers. We have presented the first (to our knowledge) systematic comparison of these methods. We showed remarkable differences in the performance of approaches across a range of assessments. Among other things, we found that the optimal approach depends crucially on whether representations are used in monitored or unmonitored environments - in the latter case, fast, flat BOW models can still achieve the best performance. In addition, we proposed two new goals, FastSent and Sequential Denoising Autoencoders, which perform particularly well in certain tasks (MSRP or SICK sentence-related).13 However, if the application is unknown, the best all-round choice could be DictRep: learning a pre-formed word emplacement from the word phrase signal in dictionary definitions."}, {"heading": "Acknowledgments", "text": "This work was supported by a Google Faculty Award to AK and FH and a Google European Doctoral Fellowship to FH. Thanks also to Marek Rei, Tamara Polajnar, Laural Rimell, Jamie Ryan Kiros and Piotr Bojanowski for helpful discussions and comments."}], "references": [{"title": "Semeval-2014 task 10: Multilingual semantic textual similarity", "author": ["Agirre et al.2014] Eneko Agirre", "Carmen Banea", "Claire Cardie", "Daniel Cer", "Mona Diab", "Aitor GonzalezAgirre", "Weiwei Guo", "Rada Mihalcea", "German Rigau", "Janyce Wiebe"], "venue": null, "citeRegEx": "Agirre et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2014}, {"title": "Learning distributed representations from reviews for collaborative filtering", "author": ["Kyle Kastner", "Kyunghyun Cho", "Aaron Courville"], "venue": "In Proceedings of the 9th ACM Conference on Recommender Systems,", "citeRegEx": "Almahairi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Almahairi et al\\.", "year": 2015}, {"title": "Frege in space: A program of compositional distributional semantics", "author": ["Baroni et al.2014a] Marco Baroni", "Raffaela Bernardi", "Roberto Zamparelli"], "venue": "Linguistic Issues in Language Technology,", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Don\u2019t count, predict! a systematic comparison of context-counting vs. context-predicting semantic vectors", "author": ["Baroni et al.2014b] Marco Baroni", "Georgiana Dinu", "Germ\u00e1n Kruszewski"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association", "citeRegEx": "Baroni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Baroni et al\\.", "year": 2014}, {"title": "Multimodal distributional semantics", "author": ["Bruni et al.2014] Elia Bruni", "Nam-Khanh Tran", "Marco Baroni"], "venue": "J. Artif. Intell. Res. (JAIR),", "citeRegEx": "Bruni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bruni et al\\.", "year": 2014}, {"title": "Microsoft coco captions: Data collection and evaluation", "author": ["Chen et al.2015] Xinlei Chen", "Hao Fang", "Tsung-Yi Lin", "Ramakrishna Vedantam", "Saurabh Gupta", "Piotr Dollar", "C Lawrence Zitnick"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Holger Schwenk", "Yoshua Bengio."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Schwenk and Bengio.,? 2014", "shortCiteRegEx": "Schwenk and Bengio.", "year": 2014}, {"title": "Combining symbolic and distributional models of meaning", "author": ["Clark", "Pulman2007] Stephen Clark", "Stephen Pulman"], "venue": "In AAAI Spring Symposium: Quantum Interaction,", "citeRegEx": "Clark et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2007}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Semi-supervised sequence learning", "author": ["Dai", "Le2015] Andrew M Dai", "Quoc V Le"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Dai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dai et al\\.", "year": 2015}, {"title": "Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources", "author": ["Dolan et al.2004] Bill Dolan", "Chris Quirk", "Chris Brockett"], "venue": "In Proceedings of the 20th international conference on Computational Linguistics,", "citeRegEx": "Dolan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dolan et al\\.", "year": 2004}, {"title": "Learning to understand phrases by embedding the dictionary. Transactions of the Association for Computational Linguistics", "author": ["Hill et al.2015a] Felix Hill", "Kyunghyun Cho", "Anna Korhonen", "Yoshua Bengio"], "venue": null, "citeRegEx": "Hill et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "2015b. Simlex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Hill et al.2015b] Felix Hill", "Roi Reichart", "Anna Korhonen"], "venue": null, "citeRegEx": "Hill et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Mining and summarizing customer reviews", "author": ["Hu", "Liu2004] Minqing Hu", "Bing Liu"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Hu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2004}, {"title": "Deep unordered composition rivals syntactic methods for text classification", "author": ["Iyyer et al.2015] Mohit Iyyer", "Varun Manjunatha", "Jordan Boyd-Graber", "Hal Daum\u00e9 III"], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Iyyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Iyyer et al\\.", "year": 2015}, {"title": "Discriminative improvements to distributional sentence similarity", "author": ["Ji", "Eisenstein2013] Yangfeng Ji", "Jacob Eisenstein"], "venue": "In EMNLP,", "citeRegEx": "Ji et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2013}, {"title": "A convolutional neural network for modelling sentences", "author": ["Edward Grefenstette", "Phil Blunsom"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Distributed representations of sentences and documents", "author": ["Le", "Mikolov2014] Quoc V Le", "Tomas Mikolov"], "venue": "In Proceedings of ICML", "citeRegEx": "Le et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Le et al\\.", "year": 2014}, {"title": "Neural word embedding as implicit matrix factorization", "author": ["Levy", "Goldberg2014] Omer Levy", "Yoav Goldberg"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Levy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2014}, {"title": "Improving distributional similarity with lessons learned from word embeddings. Transactions of the Association for Computational Linguistics, 3:211\u2013225", "author": ["Levy et al.2015] Omer Levy", "Yoav Goldberg", "Ido Dagan"], "venue": null, "citeRegEx": "Levy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "Deep captioning with multimodal recurrent neural networks (m-rnn)", "author": ["Mao et al.2015] Junhua Mao", "Wei Xu", "Yi Yang", "Jiang Wang", "Alan Yulle"], "venue": "In Proceedings of ICLR", "citeRegEx": "Mao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mao et al\\.", "year": 2015}, {"title": "A sick cure for the evaluation of compositional distributional semantic models", "author": ["Stefano Menini", "Marco Baroni", "Luisa Bentivogli", "Raffaella Bernardi", "Roberto Zamparelli"], "venue": "In Proceedings of LREC,", "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Evaluating neural word representations in tensor-based compositional settings", "author": ["Dimitri Kartsaklis", "Mehrnoosh Sadrzadeh", "Matthew Purver"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Milajevs et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Milajevs et al\\.", "year": 2014}, {"title": "Vector-based models of semantic composition", "author": ["Mitchell", "Lapata2008] Jeff Mitchell", "Mirella Lapata"], "venue": "In ACL,", "citeRegEx": "Mitchell et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2008}, {"title": "Composition in distributional models of semantics", "author": ["Mitchell", "Lapata2010] Jeff Mitchell", "Mirella Lapata"], "venue": "Cognitive science,", "citeRegEx": "Mitchell et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2010}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["Pang", "Lee2004] Bo Pang", "Lillian Lee"], "venue": "In Proceedings of the 42nd annual meeting on Association for Computational Linguistics,", "citeRegEx": "Pang et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2004}, {"title": "Seeing stars: Exploiting class relationships for sentiment", "author": ["Pang", "Lee2005] Bo Pang", "Lillian Lee"], "venue": null, "citeRegEx": "Pang et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2005}, {"title": "Jointly optimizing word representations for lexical and sentential tasks with the c-phrase model", "author": ["Pham et al.2015] Nghia The Pham", "Germ\u00e1n Kruszewski", "Angeliki Lazaridou", "Marco Baroni"], "venue": "Proceedings of ALC", "citeRegEx": "Pham et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pham et al\\.", "year": 2015}, {"title": "An exploration of discoursebased sentence spaces for compositional distributional semantics. In Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (LSDSem)", "author": ["Laura Rimell", "Stephen Clark"], "venue": null, "citeRegEx": "Polajnar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Polajnar et al\\.", "year": 2015}, {"title": "Imagenet large scale visual recognition challenge", "author": ["Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein"], "venue": null, "citeRegEx": "Russakovsky et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Russakovsky et al\\.", "year": 2014}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models. arXiv preprint arXiv:1507.04808", "author": ["Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau"], "venue": null, "citeRegEx": "Serban et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Semi-supervised recursive autoencoders for predicting sentiment distributions", "author": ["Jeffrey Pennington", "Eric H Huang", "Andrew Y Ng", "Christopher D Manning"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural", "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Generating text with recurrent neural networks", "author": ["James Martens", "Geoffrey E Hinton"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Sutskever et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2011}, {"title": "Sequence to sequence learning with neural networks. In Advances in neural information processing systems, pages 3104\u20133112", "author": ["Oriol Vinyals", "Quoc VV Le"], "venue": null, "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["Hugo Larochelle", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Vincent et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2008}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["Hugo Larochelle", "Isabelle Lajoie", "Yoshua Bengio", "Pierre-Antoine Manzagol"], "venue": "The Journal of Machine", "citeRegEx": "Vincent et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2010}, {"title": "Overview of the trec 2001 question answering track", "author": ["Ellen M Voorhees"], "venue": "NIST special publication,", "citeRegEx": "Voorhees.,? \\Q2002\\E", "shortCiteRegEx": "Voorhees.", "year": 2002}, {"title": "Annotating expressions of opinions and emotions in language. Language resources and evaluation, 39(2-3):165\u2013210", "author": ["Wiebe et al.2005] Janyce Wiebe", "Theresa Wilson", "Claire Cardie"], "venue": null, "citeRegEx": "Wiebe et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wiebe et al\\.", "year": 2005}], "referenceMentions": [{"referenceID": 8, "context": ", 2015b), and can be added as features to improve the performance of numerous language processing systems (Collobert et al., 2011).", "startOffset": 106, "endOffset": 130}, {"referenceID": 35, "context": "Examples include machine translation (Sutskever et al., 2014), image captioning (Mao et al.", "startOffset": 37, "endOffset": 61}, {"referenceID": 20, "context": ", 2014), image captioning (Mao et al., 2015) and dialogue systems (Serban et al.", "startOffset": 26, "endOffset": 44}, {"referenceID": 32, "context": ", 2015) and dialogue systems (Serban et al., 2015).", "startOffset": 29, "endOffset": 50}, {"referenceID": 24, "context": "See the contrasting conclusions in (Mitchell and Lapata, 2008; Clark and Pulman, 2007; Baroni et al., 2014a; Milajevs et al., 2014) among others.", "startOffset": 35, "endOffset": 131}, {"referenceID": 24, "context": "2 Likewise, we do not focus on \u2018bottom up\u2019 models where phrase or sentence representations are built from fixed mathematical operations on word vectors (although we do consider a canonical case see CBOW below); these were already compared by Milajevs et al. (2014). Most space is devoted to our novel approaches, and we refer the reader to the original papers for more details of existing models.", "startOffset": 242, "endOffset": 265}, {"referenceID": 33, "context": "This excludes innovative supervised sentencelevel architectures including (Socher et al., 2011; Kalchbrenner et al., 2014) and many others.", "startOffset": 74, "endOffset": 122}, {"referenceID": 16, "context": "This excludes innovative supervised sentencelevel architectures including (Socher et al., 2011; Kalchbrenner et al., 2014) and many others.", "startOffset": 74, "endOffset": 122}, {"referenceID": 29, "context": "We also compare to CPHRASE (Pham et al., 2015), an approach that exploits a (supervised) parser to infer distributed semantic representations based on a syntactic parse of sentences.", "startOffset": 27, "endOffset": 46}, {"referenceID": 11, "context": "DictRep Hill et al. (2015a) trained neural language models to map dictionary definitions to pre-trained word embeddings of the words defined by those definitions.", "startOffset": 8, "endOffset": 28}, {"referenceID": 5, "context": "CaptionRep Using the same overall architecture, we trained (BOW and RNN) models to map captions in the COCO dataset (Chen et al., 2015) to pre-trained vector representations of images.", "startOffset": 116, "endOffset": 135}, {"referenceID": 31, "context": ", 2014) trained on the ILSVRC 2014 object recognition task (Russakovsky et al., 2014).", "startOffset": 59, "endOffset": 85}, {"referenceID": 36, "context": "As a result of this process, DAEs learn to represent the data in terms of features that explain its important factors of variation (Vincent et al., 2008).", "startOffset": 131, "endOffset": 153}, {"referenceID": 37, "context": "Transforming data into DAE representations (as a \u2018pre-training\u2019 or initialisation step) gives more robust (supervised) classification performance in deep feedforward networks (Vincent et al., 2010).", "startOffset": 175, "endOffset": 197}, {"referenceID": 14, "context": "The \u2018word dropout\u2019 effect when po \u2265 0 has also been used as a regulariser for deep nets in supervised language tasks (Iyyer et al., 2015), and for large px the objective is similar to word-level \u2018debagging\u2019 (Sutskever et al.", "startOffset": 117, "endOffset": 137}, {"referenceID": 34, "context": ", 2015), and for large px the objective is similar to word-level \u2018debagging\u2019 (Sutskever et al., 2011).", "startOffset": 77, "endOffset": 101}, {"referenceID": 30, "context": "The model could be said to exploit a type of sentence-level Distributional Hypothesis (Harris, 1954; Polajnar et al., 2015).", "startOffset": 86, "endOffset": 123}, {"referenceID": 8, "context": "some classification task - supervised evaluation (Collobert et al., 2011; Mikolov et al., 2013a; Kiros et al., 2015) - or by comparing with human relatedness judgements - unspervised evaluation (Hill et al.", "startOffset": 49, "endOffset": 116}, {"referenceID": 19, "context": ", 2015) - or by comparing with human relatedness judgements - unspervised evaluation (Hill et al., 2015a; Baroni et al., 2014b; Levy et al., 2015).", "startOffset": 85, "endOffset": 146}, {"referenceID": 10, "context": "Representations are applied to 6 sentence classification tasks: paraphrase identification (MSRP) (Dolan et al., 2004), movie review sentiment (MR) (Pang and Lee, 2005), product reviews (CR) (Hu and Liu, 2004), subjectivity classification (SUBJ) (Pang and Lee, 2004), opinion polarity (MPQA) (Wiebe et al.", "startOffset": 97, "endOffset": 117}, {"referenceID": 39, "context": ", 2004), movie review sentiment (MR) (Pang and Lee, 2005), product reviews (CR) (Hu and Liu, 2004), subjectivity classification (SUBJ) (Pang and Lee, 2004), opinion polarity (MPQA) (Wiebe et al., 2005) and question type classification (TREC) (Voorhees, 2002).", "startOffset": 181, "endOffset": 201}, {"referenceID": 38, "context": ", 2005) and question type classification (TREC) (Voorhees, 2002).", "startOffset": 48, "endOffset": 64}, {"referenceID": 10, "context": "Representations are applied to 6 sentence classification tasks: paraphrase identification (MSRP) (Dolan et al., 2004), movie review sentiment (MR) (Pang and Lee, 2005), product reviews (CR) (Hu and Liu, 2004), subjectivity classification (SUBJ) (Pang and Lee, 2004), opinion polarity (MPQA) (Wiebe et al., 2005) and question type classification (TREC) (Voorhees, 2002). We follow the procedure (and code) of Kiros et al. (2015): a logistic regression classifier is trained on top of sentence representations, with 10-fold cross-validation used when a train-test split is not pre-defined.", "startOffset": 98, "endOffset": 428}, {"referenceID": 21, "context": "The SICK dataset (Marelli et al., 2014) consists of 10,000 pairs of sentences and relatedness judgements.", "startOffset": 17, "endOffset": 39}, {"referenceID": 0, "context": "The STS 2014 dataset (Agirre et al., 2014) consists of 3,750 pairs and ratings from six linguistic domains.", "startOffset": 21, "endOffset": 42}, {"referenceID": 36, "context": "SDAE is also consistently better than SAE, which aligns with other findings that adding noise to AEs produces richer representations (Vincent et al., 2008).", "startOffset": 133, "endOffset": 155}, {"referenceID": 29, "context": "The best performing raw text model on SICK is FastSent, which achieves almost identical performance to CPHRASE\u2019s state-of-the-art performance for a distributed model (Pham et al., 2015).", "startOffset": 166, "endOffset": 185}, {"referenceID": 38, "context": "the answer) (Voorhees, 2002).", "startOffset": 12, "endOffset": 28}, {"referenceID": 4, "context": "For instance, the (multimodal) representations produced by the CaptionRep model do not perform particularly well apart from on the Image category of STS where they beat all other models, demonstrating a clear effect of the well-studied modality differences in representation learning (Bruni et al., 2014).", "startOffset": 284, "endOffset": 304}, {"referenceID": 1, "context": "In the SkipThought, S(D)AE and NMT models, the cost is computed based on a non-linear decoding of the internal sentence representations, so, as also observed by (Almahairi et al., 2015), the informative geometry of the representation space may not be reflected in a simple cosine distance.", "startOffset": 161, "endOffset": 185}, {"referenceID": 39, "context": "72 (Wiebe et al., 2005)), and for MR, SUBJ and TREC, each item is only rated by one or two annotators to maximise coverage.", "startOffset": 3, "endOffset": 23}], "year": 2016, "abstractText": "Unsupervised methods for learning distributed representations of words are ubiquitous in today\u2019s NLP research, but far less is known about the best ways to learn distributed phrase or sentence representations from unlabelled data. This paper is a systematic comparison of models that learn such representations. We find that the optimal approach depends critically on the intended application. Deeper, more complex models are preferable for representations to be used in supervised systems, but shallow log-linear models work best for building representation spaces that can be decoded with simple spatial distance metrics. We also propose two new unsupervised representation-learning objectives designed to optimise the trade-off between training time, domain portability and performance.", "creator": "LaTeX with hyperref package"}}}