{"id": "1602.04375", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Feb-2016", "title": "Science Question Answering using Instructional Materials", "abstract": "We provide a solution for elementary science test using instructional materials. We posit that there is a hidden structure that explains the correctness of an answer given the question and instructional materials and present a unified max-margin framework that learns to find these hidden structures (given a corpus of question-answer pairs and instructional materials), and uses what it learns to answer novel elementary science questions. Our evaluation shows that our framework outperforms several strong baselines.", "histories": [["v1", "Sat, 13 Feb 2016 20:13:48 GMT  (2363kb,D)", "https://arxiv.org/abs/1602.04375v1", null], ["v2", "Tue, 5 Apr 2016 01:17:56 GMT  (547kb,D)", "http://arxiv.org/abs/1602.04375v2", "Corrected that the science QA dataset is NOT freely available"]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.IR cs.LG", "authors": ["mrinmaya sachan", "kumar avinava dubey", "eric p xing"], "accepted": true, "id": "1602.04375"}, "pdf": {"name": "1602.04375.pdf", "metadata": {"source": "CRF", "title": "Science Question Answering using Instructional Materials", "authors": ["Mrinmaya Sachan", "Avinava Dubey", "Eric P. Xing"], "emails": ["epxing}@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "We propose an approach to answering multiplechoice elementary science tests (Clark, 2015) by using the student's scientific curriculum and other domain-specific knowledge resources. Our approach learns latent response structures that align question-answers with corresponding snippets in the curriculum. The curriculum usually includes a series of textbooks. Each textbook in turn includes a series of chapters, each chapter is further divided into sections - each discussing a specific scientific concept. Therefore, the response-remunerated structure consists of selecting a particular textbook from the curriculum, selecting a chapter in the textbook, selecting a few sentences in the section, and then using words / multiword expressions (mwe's) in the hypothesis (formed by combining the question and an answer candidate)."}, {"heading": "2 Method", "text": "We assume that we have the right hypothesis for the right answer. (...) We assume that we select the right hypothesis. (...) We assume that we select the right hypothesis. (...) We assume that we select the correct hypothesis. (...) We assume that we select the correct hypothesis. (...) We assume that we select the correct hypothesis. (...) We assume that we select the correct hypothesis. (...) We assume that we select the correct hypothesis. (...) We assume that we select the correct hypothesis. (...) We assume that we select the correct hypothesis. (...) We assume that we select the correct hypothesis. (...) We assume that the correct hypothesis is the hypothesis. (...)"}, {"heading": "3 Experiments", "text": "The question we have asked ourselves is whether we are able to change the world, and whether we are able to change it. (...) The question we have asked ourselves is not new. (...) The question we have asked ourselves is not new. (...) The question we have asked ourselves is not new. (...) The question we have asked ourselves is not new. (...) The question we have asked ourselves is not new. (...) The question we have asked ourselves is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new. (...) The question is not new."}, {"heading": "4 Conclusion", "text": "We solved the problem of answering science questions in 8th grade using textbooks, domain-specific dictionaries and semi-structured tables. We presented the task as an extension of text entanglement and proposed a solution that learns latent structures that match pairs of questions with corresponding snippets in the textbooks. We further refined the structures using domain-specific dictionaries and semi-structured tables. The task required dealing with a variety of question types, so we extended our technique to multiple tasks. Our technique showed improvements across a number of baselines. Finally, we also used a number of related review questions that were used to make further improvements."}], "references": [{"title": "Semantic parsing on freebase from question-answer pairs", "author": ["Andrew Chou", "Roy Frostig", "Percy Liang"], "venue": "In Proceedings of Empirical Methods in Natural Language Processing,", "citeRegEx": "Berant et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "Discriminative word alignment with conditional random fields", "author": ["Blunsom", "Cohn2006] Phil Blunsom", "Trevor Cohn"], "venue": "In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Asso-", "citeRegEx": "Blunsom et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Blunsom et al\\.", "year": 2006}, {"title": "Combining retrieval, statistics, and inference to answer elementary science questions", "author": ["Clark et al.2016] Peter Clark", "Oren Etzioni", "Daniel Khashabi", "Tushar Khot", "Ashish Sabharwal", "Oyvind Tafjord", "Peter Turney"], "venue": "Proceedings of AAAI", "citeRegEx": "Clark et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2016}, {"title": "Elementary School Science and Math Tests as a Driver for AI:Take the Aristo Challenge", "author": ["Peter Clark"], "venue": "In Proceedings of IAAI", "citeRegEx": "Clark.,? \\Q2015\\E", "shortCiteRegEx": "Clark.", "year": 2015}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Regularized multi\u2013task learning", "author": ["Evgeniou", "Pontil2004] Theodoros Evgeniou", "Massimiliano Pontil"], "venue": "In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Evgeniou et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Evgeniou et al\\.", "year": 2004}, {"title": "A linear-time bottom-up discourse parser with constraints and post-editing", "author": ["Feng", "Hirst2014] Vanessa Wei Feng", "Graeme Hirst"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Feng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Feng et al\\.", "year": 2014}, {"title": "Introduction to \u201cthis is watson", "author": ["David A Ferrucci"], "venue": "IBM Journal of Research and Development,", "citeRegEx": "Ferrucci.,? \\Q2012\\E", "shortCiteRegEx": "Ferrucci.", "year": 2012}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "A neural network for factoid question answering over paragraphs", "author": ["Iyyer et al.2014] Mohit Iyyer", "Jordan Boyd-Graber", "Leonardo Claudino", "Richard Socher", "Hal Daum\u00e9 III"], "venue": "In Proceedings of Empirical Methods in Natural Language Process-", "citeRegEx": "Iyyer et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Iyyer et al\\.", "year": 2014}, {"title": "Discourse complements lexical semantics for non-factoid answer reranking", "author": ["Jansen et al.2014] Peter Jansen", "Mihai Surdeanu", "Peter Clark"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Jansen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jansen et al\\.", "year": 2014}, {"title": "jmwe: A java toolkit for detecting multi-word expressions", "author": ["Kulkarni", "Finlayson2011] Nidhi Kulkarni", "Mark Alan Finlayson"], "venue": "In Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,", "citeRegEx": "Kulkarni et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2011}, {"title": "A phrasebased alignment model for natural language inference", "author": ["Michel Galley", "Christopher D Manning"], "venue": "In Proceedings of the conference on empirical methods in natural language processing,", "citeRegEx": "MacCartney et al\\.,? \\Q2008\\E", "shortCiteRegEx": "MacCartney et al\\.", "year": 2008}, {"title": "Rhetorical Structure Theory: Toward a functional theory of text organisation", "author": ["Mann", "Thompson1988] William C Mann", "Sandra A Thompson"], "venue": null, "citeRegEx": "Mann et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Mann et al\\.", "year": 1988}, {"title": "Vector-based models of semantic composition", "author": ["Mitchell", "Lapata2008] Jeff Mitchell", "Mirella Lapata"], "venue": "ACL", "citeRegEx": "Mitchell et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2008}, {"title": "Mctest: A challenge dataset for the open-domain machine comprehension of text", "author": ["Christopher JC Burges", "Erin Renshaw"], "venue": "In Proceedings of Empirical Methods in Natural Language Processing", "citeRegEx": "Richardson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 2013}, {"title": "Learning answer-entailing structures for machine comprehension", "author": ["Avinava Dubey", "Eric P Xing", "Matthew Richardson"], "venue": "In Proceedings of the Annual Meeting of the Association", "citeRegEx": "Sachan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sachan et al\\.", "year": 2015}, {"title": "Relation alignment for textual entailment recognition", "author": ["Sammons et al.2009] M. Sammons", "V. Vydiswaran", "T. Vieira", "N. Johri", "M. Chang", "D. Goldwasser", "V. Srikumar", "G. Kundu", "Y. Tu", "K. Small", "J. Rule", "Q. Do", "D. Roth"], "venue": "In TAC", "citeRegEx": "Sammons et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Sammons et al\\.", "year": 2009}, {"title": "A walk-based semantically enriched tree kernel over distributed word representations", "author": ["Srivastava", "Hovy2013] Shashank Srivastava", "Dirk Hovy"], "venue": "In Proceedings of Empirical Methods in Natural Language Processing,", "citeRegEx": "Srivastava et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2013}, {"title": "Biutee: A modular open-source system for recognizing textual entailment", "author": ["Stern", "Dagan2012] Asher Stern", "Ido Dagan"], "venue": "In Proceedings of the ACL 2012 System Demonstrations,", "citeRegEx": "Stern et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Stern et al\\.", "year": 2012}, {"title": "Back to basics for monolingual alignment: Exploiting word similarity and contextual evidence", "author": ["Steven Bethard", "Tamara Sumner"], "venue": "Transactions of the Association of Computational Linguistics", "citeRegEx": "Sultan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sultan et al\\.", "year": 2014}, {"title": "Information extraction over structured data: Question answering with freebase", "author": ["Yao", "Van Durme2014] Xuchen Yao", "Benjamin Van Durme"], "venue": "In Proceedings of the 52nd Annual Meeting of the Association", "citeRegEx": "Yao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2014}, {"title": "A lightweight and high performance monolingual word aligner", "author": ["Yao et al.2013] Xuchen Yao", "Benjamin Van Durme", "Chris Callison-Burch", "Peter Clark"], "venue": "ACL", "citeRegEx": "Yao et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2013}, {"title": "Question answering using enhanced lexical semantic models", "author": ["Yih et al.2013] Wentau Yih", "Ming-Wei Chang", "Christopher Meek", "Andrzej Pastusiak"], "venue": "In Proceedings of the 51st Annual Meeting of the Association", "citeRegEx": "Yih et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yih et al\\.", "year": 2013}, {"title": "The concave-convex procedure", "author": ["Yuille", "Rangarajan2003] A.L. Yuille", "Anand Rangarajan"], "venue": "Neural Comput", "citeRegEx": "Yuille et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Yuille et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 3, "context": "choice elementary science tests (Clark, 2015) using the science curriculum of the student and other domain specific knowledge resources.", "startOffset": 32, "endOffset": 45}, {"referenceID": 2, "context": "These domainspecific knowledge resources can be very useful forms of knowledge representation as shown in previous works (Clark et al., 2016).", "startOffset": 121, "endOffset": 141}, {"referenceID": 17, "context": "applications such as MT (Blunsom and Cohn, 2006), RTE (Sammons et al., 2009; MacCartney et al., 2008; Yao et al., 2013; Sultan et al., 2014), QA (Berant et al.", "startOffset": 54, "endOffset": 140}, {"referenceID": 12, "context": "applications such as MT (Blunsom and Cohn, 2006), RTE (Sammons et al., 2009; MacCartney et al., 2008; Yao et al., 2013; Sultan et al., 2014), QA (Berant et al.", "startOffset": 54, "endOffset": 140}, {"referenceID": 22, "context": "applications such as MT (Blunsom and Cohn, 2006), RTE (Sammons et al., 2009; MacCartney et al., 2008; Yao et al., 2013; Sultan et al., 2014), QA (Berant et al.", "startOffset": 54, "endOffset": 140}, {"referenceID": 20, "context": "applications such as MT (Blunsom and Cohn, 2006), RTE (Sammons et al., 2009; MacCartney et al., 2008; Yao et al., 2013; Sultan et al., 2014), QA (Berant et al.", "startOffset": 54, "endOffset": 140}, {"referenceID": 0, "context": ", 2014), QA (Berant et al., 2013; Yih et al., 2013; Yao and Van Durme, 2014; Sachan et al., 2015), etc.", "startOffset": 12, "endOffset": 97}, {"referenceID": 23, "context": ", 2014), QA (Berant et al., 2013; Yih et al., 2013; Yao and Van Durme, 2014; Sachan et al., 2015), etc.", "startOffset": 12, "endOffset": 97}, {"referenceID": 16, "context": ", 2014), QA (Berant et al., 2013; Yih et al., 2013; Yao and Van Durme, 2014; Sachan et al., 2015), etc.", "startOffset": 12, "endOffset": 97}, {"referenceID": 7, "context": "Retrieval and answer selection are usually designed as isolated or loosely connected components in QA systems (Ferrucci, 2012) leading to loss in performance \u2013 our approach mit-", "startOffset": 110, "endOffset": 126}, {"referenceID": 16, "context": "Pontil (2004) which was also used in a reading comprehension setting by Sachan et al. (2015). In a nutshell, the approach redefines the LSSVM feature map and shows that the MTLSSVM objective takes the same form as equation 1 with", "startOffset": 72, "endOffset": 93}, {"referenceID": 10, "context": "RST tells us that sentences with discourse relations are related to each other and can help us answer certain kinds of questions (Jansen et al., 2014).", "startOffset": 129, "endOffset": 150}, {"referenceID": 4, "context": "Semantic word match (cosine similarity using SENNA word vectors (Collobert et al., 2011) and \u201cAntonymy\u201d \u2018Class-Inclusion\u2019 or \u2018Is-A\u2019 relations using Wordnet).", "startOffset": 64, "endOffset": 88}, {"referenceID": 2, "context": "The first two baselines (Lucene and PMI) are taken from Clark et al. (2016). The Lucene baseline scores each answer candidate ai by searching for the combination of the ques-", "startOffset": 56, "endOffset": 76}, {"referenceID": 15, "context": "The next three baselines, inspired from Richardson et al. (2013), retrieve the top two CK12 sections querying q+ai in Lucene and score the answer candidates using these documents.", "startOffset": 40, "endOffset": 65}, {"referenceID": 22, "context": "(2016), Jacana aligner (Yao et al., 2013) and two neural network approaches, LSTM (Hochreiter and Schmidhuber,", "startOffset": 23, "endOffset": 41}, {"referenceID": 2, "context": "Then we also tried other approaches such as the RNN approach described in Clark et al. (2016), Jacana aligner (Yao et al.", "startOffset": 74, "endOffset": 94}, {"referenceID": 9, "context": "1997) and QANTA (Iyyer et al., 2014) They form our next four baselines.", "startOffset": 16, "endOffset": 36}], "year": 2016, "abstractText": "We provide a solution for elementary science tests using instructional materials. We posit that there is a hidden structure that explains the correctness of an answer given the question and instructional materials and present a unified max-margin framework that learns to find these hidden structures (given a corpus of questionanswer pairs and instructional materials), and uses what it learns to answer novel elementary science questions. Our evaluation shows that our framework outperforms several strong baselines.", "creator": "TeX"}}}