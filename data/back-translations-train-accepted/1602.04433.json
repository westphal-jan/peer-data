{"id": "1602.04433", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Feb-2016", "title": "Unsupervised Domain Adaptation with Residual Transfer Networks", "abstract": "The recent success of deep neural networks relies on massive amounts of labeled data. For a target task where labeled data is unavailable, domain adaptation can transfer a learner from a different source domain. In this paper, we propose a new approach to domain adaptation in deep networks that can simultaneously learn adaptive classifiers and transferable features from labeled data in the source domain and unlabeled data in the target domain. We relax a shared-classifier assumption made by previous methods and assume that the source classifier and target classifier differ by a residual function. We enable classifier adaptation by plugging several layers into the deep network to explicitly learn the residual function with reference to the target classifier. We embed features of multiple layers into reproducing kernel Hilbert spaces (RKHSs) and match feature distributions for feature adaptation. The adaptation behaviors can be achieved in most feed-forward models by extending them with new residual layers and loss functions, which can be trained efficiently using standard back-propagation. Empirical evidence exhibits that the approach outperforms state of art methods on standard domain adaptation datasets.", "histories": [["v1", "Sun, 14 Feb 2016 09:47:30 GMT  (242kb)", "http://arxiv.org/abs/1602.04433v1", null], ["v2", "Thu, 16 Feb 2017 07:56:49 GMT  (339kb,D)", "http://arxiv.org/abs/1602.04433v2", "30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mingsheng long", "han zhu", "jianmin wang 0001", "michael i jordan"], "accepted": true, "id": "1602.04433"}, "pdf": {"name": "1602.04433.pdf", "metadata": {"source": "META", "title": "Unsupervised Domain Adaptation with Residual Transfer Networks", "authors": ["Mingsheng Long", "Jianmin Wang", "Michael I. Jordan"], "emails": ["MINGSHENG@TSINGHUA.EDU.CN", "JIMWANG@TSINGHUA.EDU.CN", "JORDAN@BERKELEY.EDU"], "sections": [{"heading": null, "text": "ar Xiv: 160 2.04 433v 1 [cs.L G] 14 Feb 20"}, {"heading": "1. Introduction", "text": "This year it is more than ever before."}, {"heading": "2. Related Work", "text": "In fact, most of them will be able to move to another world, where they will be able to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "3. Residual Transfer Networks", "text": "The source domain and target domain are scanned using the probability distributions p and q or grade p 6 = q. The goal of this paper is to create a deep neural network that allows learning the transfer classifiers y = fs (x) and y = ft (x) to bridge the discrepancy between source and target domains, so that the target risk Rt (ft) = Pr (x, y) q [ft (x) 6 = y] is minimized supervisionarily by using the source domain. The challenge of uncontrolled domain adjustment arises from the fact that the target domain has no marked data, while the source classifier fs, which has been trained on source domain Ds, cannot be applied directly to the target domain Dt."}, {"heading": "3.1. Convolutional Neural Network", "text": "We will extend from the ground-breaking AlexNet architecture (Krizhevsky et al., 2012), which comprises five Convolutionary Layers (Conv1-Conv5) and three Completely Linked Layers (Fc6-Fc8), with Conv1-Fc7 being feature layers and Fc8 being the classification layer. Specifically, each Completely Linked Layer will learn a nonlinear mapping function, where hi is the hidden representation of example xi, wound is the hidden representation of the Excel layer, the weight and bias parameters of the third layer, and ais the activation function of the fourth layer, which is taken as rectifier units (ReLU) a (x) = max (0, x) for the feature layers or soft units ai (x)."}, {"heading": "3.2. Classifier Adaptation", "text": "Although the classifier and the target classifier are different, fs (x) 6 = ft (x) may have a complex dual functionality (dual functionality) to ensure the feasibility of domain adaptation. Therefore, it is reasonable to assume that fs (x) and ft (x) may differ only by a small malfunction. Previous work (Yang et al., 2007; Duan et al., 2012b) assumes that ft (x) = fs (x) + f (x), where the malfunction f (x) is a function of the input function x. Unfortunately, these methods require target data to learn the perturbation function, which cannot be applied to unattended domain adaptation. We argue that the difficulty arises because no limitation is imposed on the perturbation function f (x), so it is independent of the source data and source classifiers (x), so that target data must be learned from it."}, {"heading": "3.3. Feature Adaptation", "text": "The literature has shown that the deep features learned from CNNs can unravel the explanatory factors of the variations underlying the data distributions and facilitate knowledge transfer (Oquab et al., 2013; Bengio et al., 2013), but deep features can only reduce, not eliminate, the discrepancy between cross-domain distributions (Yosinski et al., 2014; Tzeng et al., 2014), thus motivating the state of the art methods for comprehensive adaptation of traits (Long et al., 2015; Ganin & Lempitsky et al., 2015; Tzeng et al al al al al., 2015; Tzeng et al., 2014; Tzeng et al., 2014), with the deep adaptation network (Long et al., 2015) being very well addressed for fine-tuning the feature distributions of the source and the target."}, {"heading": "3.4. Residual Transfer Network", "text": "Based on the above-mentioned analysis to enable effective unattended domain adaptation, we propose that the Residual Transfer Network (RTN) integrates Deep Feature Learning (1), Classifier Adaptation (2) - (3) and Feature Adaptation (4) into an end-to-end deep learning framework asmin fS = fT + 0 (fT) 1nsns \u2211 i = 1L (fs (s s s s s i), y s i) + 0 (t i) + 1 (t i) + 1).The proposed RTN model (6) is capable of learning both adaptive classifiers and transferable features, as well as the compromise parameters for the entropy penalty (3) and multi-layer MMMD penalty (4).The proposed RTN model (6) is capable of learning both adaptive classifiers and transferable features."}, {"heading": "4. Experiments", "text": "We evaluate the proposed residual transfer network against benchmarks for unattended domain adjustments with respect to state-of-the-art transfer learning and deep learning methods. Data sets, codes and configurations are made publicly available."}, {"heading": "4.1. Setup", "text": "In fact, it is a purely reactionary project, which is a reactionary project, which is a reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary, reactionary."}, {"heading": "4.2. Results and Discussion", "text": "This year it is more than ever before."}, {"heading": "4.3. Empirical Analysis", "text": "Prediction visualization: We illustrate the adaptivity of classifiers by visualizing in Figures 3 (a) -3 (d) the t-SNE embedding (Donahue et al., 2014) of the predictions made by the DAN and RTN classifiers for transmission task A \u2192 W. We can make the following observations. (1) DAN's predictions in Figure 3 (a) -3 (b) show that the target categories are not well distinguished by the source classifier, which means that target data is not compatible with the source classifier. Therefore, the source and target classifiers should not be assumed to be identical, which, whatever, are a common assumption of all previous deep domain adaptation classes (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempsky, 2015; Tzeng et al al, 2015)."}, {"heading": "5. Conclusion", "text": "This paper presented a novel approach to unattended deep network domain adaptation that enables the simultaneous learning of adaptive classifiers and transferable traits. Similar to many previous domain adaptation techniques, the adaptation of traits occurs by matching the distribution of traits across domains. However, unlike all previous techniques, the proposed approach also supports classification adaptation, which is achieved through a new residual transfer module to bridge the source classifier and target classifier. This new ingredient makes the approach a good complement to existing techniques, and the approach can be trained through standard back propagation that is scalable and can be implemented through any in-depth learning package."}], "references": [{"title": "Analysis of representations for domain adaptation", "author": ["S. Ben-David", "J. Blitzer", "K. Crammer", "F. Pereira"], "venue": "In NIPS,", "citeRegEx": "Ben.David et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2007}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": null, "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Multi-task recurrent neural network for immediacy prediction", "author": ["X. Chu", "W. Ouyang", "W. Yang", "X. Wang"], "venue": "In ICCV, pp", "citeRegEx": "Chu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chu et al\\.", "year": 2015}, {"title": "Domain transfer multiple kernel learning", "author": ["L. Duan", "I.W. Tsang", "D. Xu"], "venue": "TPAMI, 34(3):465\u2013479,", "citeRegEx": "Duan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Duan et al\\.", "year": 2012}, {"title": "Visual event recognition in videos by learning from web data", "author": ["L. Duan", "D. Xu", "I.W. Tsang", "J. Luo"], "venue": null, "citeRegEx": "Duan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Duan et al\\.", "year": 2012}, {"title": "Unsupervised domain adaptation by backpropagation", "author": ["Y. Ganin", "V. Lempitsky"], "venue": "In ICML,", "citeRegEx": "Ganin and Lempitsky,? \\Q2015\\E", "shortCiteRegEx": "Ganin and Lempitsky", "year": 2015}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["X. Glorot", "A. Bordes", "Y. Bengio"], "venue": "In ICML,", "citeRegEx": "Glorot et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "Geodesic flow kernel for unsupervised domain adaptation", "author": ["B. Gong", "Y. Shi", "F. Sha", "K. Grauman"], "venue": "In CVPR,", "citeRegEx": "Gong et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gong et al\\.", "year": 2012}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In NIPS,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Domain adaptation for object recognition: An unsupervised approach", "author": ["R. Gopalan", "R. Li", "R. Chellappa"], "venue": "In ICCV. IEEE,", "citeRegEx": "Gopalan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gopalan et al\\.", "year": 2011}, {"title": "Semi-supervised learning by entropy minimization", "author": ["Y. Grandvalet", "Y. Bengio"], "venue": "In NIPS, pp", "citeRegEx": "Grandvalet and Bengio,? \\Q2004\\E", "shortCiteRegEx": "Grandvalet and Bengio", "year": 2004}, {"title": "A kernel two-sample test", "author": ["A. Gretton", "K. Borgwardt", "M. Rasch", "B. Sch\u00f6lkopf", "A. Smola"], "venue": "JMLR, 13:723\u2013773,", "citeRegEx": "Gretton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gretton et al\\.", "year": 2012}, {"title": "Optimal kernel choice for large-scale two-sample tests", "author": ["A. Gretton", "B. Sriperumbudur", "D. Sejdinovic", "H. Strathmann", "S. Balakrishnan", "M. Pontil", "K. Fukumizu"], "venue": "In NIPS,", "citeRegEx": "Gretton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gretton et al\\.", "year": 2012}, {"title": "Caltech-256 object category dataset", "author": ["G. Griffin", "A. Holub", "P. Perona"], "venue": "Technical report, California Institute of Technology,", "citeRegEx": "Griffin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Griffin et al\\.", "year": 2007}, {"title": "Cross modal distillation for supervision transfer", "author": ["S. Gupta", "J. Hoffman", "J. Malik"], "venue": "arXiv preprint arXiv:1507.00448,", "citeRegEx": "Gupta et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gupta et al\\.", "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "arXiv preprint arXiv:1512.03385,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "LSDA: Large scale detection through adaptation", "author": ["J. Hoffman", "S. Guadarrama", "E. Tzeng", "R. Hu", "J. Donahue", "R. Girshick", "T. Darrell", "K. Saenko"], "venue": "In NIPS,", "citeRegEx": "Hoffman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 2014}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": "In MM,", "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In NIPS,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Learning with augmented features for supervised and semi-supervised heterogeneous domain adaptation", "author": ["W. Li", "L. Duan", "D. Xu", "I.W. Tsang"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Transfer feature learning with joint distribution adaptation", "author": ["M. Long", "J. Wang", "G. Ding", "J. Sun", "P.S. Yu"], "venue": "In ICCV,", "citeRegEx": "Long et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Long et al\\.", "year": 2013}, {"title": "Learning transferable features with deep adaptation networks", "author": ["M. Long", "Y. Cao", "J. Wang", "M.I. Jordan"], "venue": "In ICML,", "citeRegEx": "Long et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "Domain adaptation: Learning bounds and algorithms", "author": ["Y. Mansour", "M. Mohri", "A. Rostamizadeh"], "venue": "In COLT,", "citeRegEx": "Mansour et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mansour et al\\.", "year": 2009}, {"title": "Multimodal deep learning", "author": ["J. Ngiam", "A. Khosla", "M. Kim", "J. Nam", "H. Lee", "A.Y. Ng"], "venue": "In ICML,", "citeRegEx": "Ngiam et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ngiam et al\\.", "year": 2011}, {"title": "Learning and transferring mid-level image representations using convolutional neural networks", "author": ["M. Oquab", "L. Bottou", "I. Laptev", "J. Sivic"], "venue": null, "citeRegEx": "Oquab et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Oquab et al\\.", "year": 2013}, {"title": "Domain adaptation via transfer component analysis", "author": ["S.J. Pan", "I.W. Tsang", "J.T. Kwok", "Q. Yang"], "venue": "TNNLS,", "citeRegEx": "Pan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pan et al\\.", "year": 2011}, {"title": "Adapting visual category models to new domains", "author": ["K. Saenko", "B. Kulis", "M. Fritz", "T. Darrell"], "venue": "In ECCV,", "citeRegEx": "Saenko et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Saenko et al\\.", "year": 2010}, {"title": "Return of frustratingly easy domain adaptation", "author": ["B. Sun", "J. Feng", "K. Saenko"], "venue": "In AAAI,", "citeRegEx": "Sun et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2016}, {"title": "Unbiased look at dataset bias", "author": ["A. Torralba", "A.A. Efros"], "venue": "In CVPR,", "citeRegEx": "Torralba and Efros,? \\Q2011\\E", "shortCiteRegEx": "Torralba and Efros", "year": 2011}, {"title": "Deep domain confusion: Maximizing for domain invariance", "author": ["E. Tzeng", "J. Hoffman", "N. Zhang", "K. Saenko", "T. Darrell"], "venue": null, "citeRegEx": "Tzeng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Tzeng et al\\.", "year": 2014}, {"title": "Simultaneous deep transfer across domains and tasks", "author": ["E. Tzeng", "J. Hoffman", "N. Zhang", "K. Saenko", "T. Darrell"], "venue": "In ICCV,", "citeRegEx": "Tzeng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tzeng et al\\.", "year": 2015}, {"title": "Flexible transfer learning under support and model shift", "author": ["X. Wang", "J. Schneider"], "venue": "In NIPS,", "citeRegEx": "Wang and Schneider,? \\Q2014\\E", "shortCiteRegEx": "Wang and Schneider", "year": 2014}, {"title": "Cross-domain video concept detection using adaptive svms", "author": ["J. Yang", "R. Yan", "A.G. Hauptmann"], "venue": "In MM,", "citeRegEx": "Yang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2007}, {"title": "How transferable are features in deep neural networks", "author": ["J. Yosinski", "J. Clune", "Y. Bengio", "H. Lipson"], "venue": "In NIPS,", "citeRegEx": "Yosinski et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yosinski et al\\.", "year": 2014}, {"title": "Domain adaptation under target and conditional shift", "author": ["K. Zhang", "B. Sch\u00f6lkopf", "K. Muandet", "Z. Wang"], "venue": "In ICML,", "citeRegEx": "Zhang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 33, "context": "In particular, recent studies have shown that deep neural networks can learn more transferable features for domain adaptation (Donahue et al., 2014; Yosinski et al., 2014), by disentangling explanatory factors of variations underlying data samples, and grouping deep features hierarchically in accordance with their relatedness to invariant factors.", "startOffset": 126, "endOffset": 171}, {"referenceID": 29, "context": "The latest advances have been achieved by embedding domain adaptation in the pipeline of deep feature learning to extract domain-invariant representations (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 155, "endOffset": 239}, {"referenceID": 21, "context": "The latest advances have been achieved by embedding domain adaptation in the pipeline of deep feature learning to extract domain-invariant representations (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 155, "endOffset": 239}, {"referenceID": 30, "context": "The latest advances have been achieved by embedding domain adaptation in the pipeline of deep feature learning to extract domain-invariant representations (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 155, "endOffset": 239}, {"referenceID": 15, "context": "This work is primarily motivated by He et al. (2015), the winner of the ImageNet ILSVRC 2015 challenge.", "startOffset": 36, "endOffset": 53}, {"referenceID": 25, "context": "Transfer learning is to mitigate the burden of manual labeling for machine learning (Pan et al., 2011; Duan et al., 2012a; Zhang et al., 2013; Li et al., 2014; Wang & Schneider, 2014), computer vision (Saenko et al.", "startOffset": 84, "endOffset": 183}, {"referenceID": 34, "context": "Transfer learning is to mitigate the burden of manual labeling for machine learning (Pan et al., 2011; Duan et al., 2012a; Zhang et al., 2013; Li et al., 2014; Wang & Schneider, 2014), computer vision (Saenko et al.", "startOffset": 84, "endOffset": 183}, {"referenceID": 19, "context": "Transfer learning is to mitigate the burden of manual labeling for machine learning (Pan et al., 2011; Duan et al., 2012a; Zhang et al., 2013; Li et al., 2014; Wang & Schneider, 2014), computer vision (Saenko et al.", "startOffset": 84, "endOffset": 183}, {"referenceID": 26, "context": ", 2014; Wang & Schneider, 2014), computer vision (Saenko et al., 2010; Gopalan et al., 2011; Gong et al., 2012; Duan et al., 2012b; Hoffman et al., 2014) and natural language processing (Collobert et al.", "startOffset": 49, "endOffset": 153}, {"referenceID": 9, "context": ", 2014; Wang & Schneider, 2014), computer vision (Saenko et al., 2010; Gopalan et al., 2011; Gong et al., 2012; Duan et al., 2012b; Hoffman et al., 2014) and natural language processing (Collobert et al.", "startOffset": 49, "endOffset": 153}, {"referenceID": 7, "context": ", 2014; Wang & Schneider, 2014), computer vision (Saenko et al., 2010; Gopalan et al., 2011; Gong et al., 2012; Duan et al., 2012b; Hoffman et al., 2014) and natural language processing (Collobert et al.", "startOffset": 49, "endOffset": 153}, {"referenceID": 16, "context": ", 2014; Wang & Schneider, 2014), computer vision (Saenko et al., 2010; Gopalan et al., 2011; Gong et al., 2012; Duan et al., 2012b; Hoffman et al., 2014) and natural language processing (Collobert et al.", "startOffset": 49, "endOffset": 153}, {"referenceID": 1, "context": "Deep neural networks can learn abstract representations that disentangle different explanatory factors of variations behind data samples (Bengio et al., 2013) and manifest invariant factors underlying different populations that transfer well from original tasks to similar novel tasks (Yosinski et al.", "startOffset": 137, "endOffset": 158}, {"referenceID": 33, "context": ", 2013) and manifest invariant factors underlying different populations that transfer well from original tasks to similar novel tasks (Yosinski et al., 2014).", "startOffset": 134, "endOffset": 157}, {"referenceID": 6, "context": "Thus deep neural networks have been explored for domain adaptation (Glorot et al., 2011; Oquab et al., 2013; Hoffman et al., 2014), multimodal and multi-task learning (Collobert et al.", "startOffset": 67, "endOffset": 130}, {"referenceID": 24, "context": "Thus deep neural networks have been explored for domain adaptation (Glorot et al., 2011; Oquab et al., 2013; Hoffman et al., 2014), multimodal and multi-task learning (Collobert et al.", "startOffset": 67, "endOffset": 130}, {"referenceID": 16, "context": "Thus deep neural networks have been explored for domain adaptation (Glorot et al., 2011; Oquab et al., 2013; Hoffman et al., 2014), multimodal and multi-task learning (Collobert et al.", "startOffset": 67, "endOffset": 130}, {"referenceID": 23, "context": ", 2014), multimodal and multi-task learning (Collobert et al., 2011; Ngiam et al., 2011; Gupta et al., 2015), where significant performance gains have been witnessed relative to prior shallow transfer learning methods.", "startOffset": 44, "endOffset": 108}, {"referenceID": 14, "context": ", 2014), multimodal and multi-task learning (Collobert et al., 2011; Ngiam et al., 2011; Gupta et al., 2015), where significant performance gains have been witnessed relative to prior shallow transfer learning methods.", "startOffset": 44, "endOffset": 108}, {"referenceID": 6, "context": "However, recent advances show that deep neural networks can learn abstract feature representations that can only reduce, but not remove, the cross-domain discrepancy (Glorot et al., 2011; Tzeng et al., 2014).", "startOffset": 166, "endOffset": 207}, {"referenceID": 29, "context": "However, recent advances show that deep neural networks can learn abstract feature representations that can only reduce, but not remove, the cross-domain discrepancy (Glorot et al., 2011; Tzeng et al., 2014).", "startOffset": 166, "endOffset": 207}, {"referenceID": 0, "context": "Dataset shift has posed a bottleneck to the transferability of deep features, resulting in statistically unbounded risk for target tasks (Ben-David et al., 2007; Mansour et al., 2009; Ben-David et al., 2010).", "startOffset": 137, "endOffset": 207}, {"referenceID": 22, "context": "Dataset shift has posed a bottleneck to the transferability of deep features, resulting in statistically unbounded risk for target tasks (Ben-David et al., 2007; Mansour et al., 2009; Ben-David et al., 2010).", "startOffset": 137, "endOffset": 207}, {"referenceID": 29, "context": "Some recent work addresses the aforementioned problem by deep domain adaptation, which bridges the two worlds of deep learning and domain adaptation (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 149, "endOffset": 233}, {"referenceID": 21, "context": "Some recent work addresses the aforementioned problem by deep domain adaptation, which bridges the two worlds of deep learning and domain adaptation (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 149, "endOffset": 233}, {"referenceID": 30, "context": "Some recent work addresses the aforementioned problem by deep domain adaptation, which bridges the two worlds of deep learning and domain adaptation (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 149, "endOffset": 233}, {"referenceID": 29, "context": "They extend deep convolutional networks (CNNs) to domain adaptation either by adding one or multiple adaptation layers through which the mean embeddings of distributions are matched (Tzeng et al., 2014; Long et al., 2015), or by adding a fully connected subnetwork as a domain discriminator whilst the deep features are learned to confuse the domain discriminator in a domain-adversarial training paradigm (Ganin & Lempitsky, 2015; Tzeng et al.", "startOffset": 182, "endOffset": 221}, {"referenceID": 21, "context": "They extend deep convolutional networks (CNNs) to domain adaptation either by adding one or multiple adaptation layers through which the mean embeddings of distributions are matched (Tzeng et al., 2014; Long et al., 2015), or by adding a fully connected subnetwork as a domain discriminator whilst the deep features are learned to confuse the domain discriminator in a domain-adversarial training paradigm (Ganin & Lempitsky, 2015; Tzeng et al.", "startOffset": 182, "endOffset": 221}, {"referenceID": 30, "context": ", 2015), or by adding a fully connected subnetwork as a domain discriminator whilst the deep features are learned to confuse the domain discriminator in a domain-adversarial training paradigm (Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 192, "endOffset": 237}, {"referenceID": 15, "context": "This work is primarily motivated by He et al. (2015), the winner of the ImageNet ILSVRC 2015 challenge.", "startOffset": 36, "endOffset": 53}, {"referenceID": 32, "context": "Note that the idea of adapting source classifier to target domain by adding a perturbation function has been studied by (Yang et al., 2007; Duan et al., 2012b).", "startOffset": 120, "endOffset": 159}, {"referenceID": 21, "context": "Note that current state of the art deep feature adaptation methods (Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015) generally assume shared classifier on their adaptive deep features.", "startOffset": 67, "endOffset": 131}, {"referenceID": 30, "context": "Note that current state of the art deep feature adaptation methods (Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015) generally assume shared classifier on their adaptive deep features.", "startOffset": 67, "endOffset": 131}, {"referenceID": 18, "context": "We will extend from the breakthrough AlexNet architecture (Krizhevsky et al., 2012) that comprises five convolutional layers (conv1\u2013conv5) and three fully connected layers (fc6\u2013fc8), where conv1\u2013fc7 are feature layers and fc8 is the classifier layer.", "startOffset": 58, "endOffset": 83}, {"referenceID": 33, "context": "Based on the quantification study of feature transferability (Yosinski et al., 2014), the convolutional layers conv1\u2013conv5 can learn generic features transferable across domains (Yosinski et al.", "startOffset": 61, "endOffset": 84}, {"referenceID": 33, "context": ", 2014), the convolutional layers conv1\u2013conv5 can learn generic features transferable across domains (Yosinski et al., 2014).", "startOffset": 101, "endOffset": 124}, {"referenceID": 32, "context": "Previous works (Yang et al., 2007; Duan et al., 2012b) assume that ft(x) = fs(x) + \u2206f(x), where the perturbation \u2206f(x) is a function of input feature x.", "startOffset": 15, "endOffset": 54}, {"referenceID": 15, "context": "We are motivated by the deep residual learning framework presented by He et al. (2015) to win the ImageNet ILSVRC", "startOffset": 70, "endOffset": 87}, {"referenceID": 21, "context": "structures, hence they are not safely transferable and should be adapted with MK-MMD minimization (Long et al., 2015); (2) supervised", "startOffset": 98, "endOffset": 117}, {"referenceID": 15, "context": "A building block for residual learning (He et al., 2015).", "startOffset": 39, "endOffset": 56}, {"referenceID": 15, "context": "The residual learning is the key contributor to the successful training of very deep networks (He et al., 2015).", "startOffset": 94, "endOffset": 111}, {"referenceID": 15, "context": "The deep residual learning (He et al., 2015) ensures to output valid classifiers |\u2206f (fT (x))| \u226a |fT (x)| \u2248 |fS (x)|.", "startOffset": 27, "endOffset": 44}, {"referenceID": 24, "context": "The literature has revealed that the deep features learned by CNNs can disentangle the explanatory factors of variations underlying data distributions and facilitate knowledge transfer (Oquab et al., 2013; Bengio et al., 2013).", "startOffset": 185, "endOffset": 226}, {"referenceID": 1, "context": "The literature has revealed that the deep features learned by CNNs can disentangle the explanatory factors of variations underlying data distributions and facilitate knowledge transfer (Oquab et al., 2013; Bengio et al., 2013).", "startOffset": 185, "endOffset": 226}, {"referenceID": 33, "context": "But deep features can only reduce, but not remove, the cross-domain distribution discrepancy (Yosinski et al., 2014; Tzeng et al., 2014), which thus motivates the state of the art deep feature adaptation methods (Long et al.", "startOffset": 93, "endOffset": 136}, {"referenceID": 29, "context": "But deep features can only reduce, but not remove, the cross-domain distribution discrepancy (Yosinski et al., 2014; Tzeng et al., 2014), which thus motivates the state of the art deep feature adaptation methods (Long et al.", "startOffset": 93, "endOffset": 136}, {"referenceID": 21, "context": ", 2014), which thus motivates the state of the art deep feature adaptation methods (Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 83, "endOffset": 147}, {"referenceID": 30, "context": ", 2014), which thus motivates the state of the art deep feature adaptation methods (Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 83, "endOffset": 147}, {"referenceID": 21, "context": "As feature adaptation has been addressed quite well, we adopt the deep adaptation network (DAN) (Long et al., 2015) to fine-tune CNN on labeled examples and require the feature distributions of the source and target to become similar under feature representations of fully connected layers L = {fc6, fc7, fc8}, which is realized by minimizing a multi-layer MK-MMD penalty as", "startOffset": 96, "endOffset": 115}, {"referenceID": 21, "context": "Characteristic kernel k (x,x) = \u3008\u03c6 (x) , \u03c6 (x)\u3009 is defined as the convex combination of m PSD kernels {ku}, K , {k = \u2211m u=1 \u03b2uku : \u2211m u=1 \u03b2u = 1, \u03b2u > 0, \u2200u} where the kernel coefficients {\u03b2u} can be simply set to 1/m or can be learned by multiple kernel learning (Long et al., 2015).", "startOffset": 264, "endOffset": 283}, {"referenceID": 21, "context": "As classifier adaptation proposed in this paper and feature adaptation studied in (Long et al., 2015; Ganin & Lempitsky, 2015) are tailored to adapt different layers of the deep networks, they are well complementing to each other to establish better performance and can be combined wherever necessary.", "startOffset": 82, "endOffset": 126}, {"referenceID": 21, "context": "As training deep CNNs requires a large amount of labeled data that is prohibitive for many domain adaptation applications, we start with the AlexNet model pre-trained on ImageNet 2012 data and fine-tune it as (Long et al., 2015).", "startOffset": 209, "endOffset": 228}, {"referenceID": 15, "context": "The training of RTN mainly follows standard backpropagation, including the residual layers for classifier adaptation (He et al., 2015).", "startOffset": 117, "endOffset": 134}, {"referenceID": 21, "context": "But the optimization of MKMMD penalty (4) requires carefully-designed algorithm as detailed in (Long et al., 2015) for linear-time training with back-propagation.", "startOffset": 95, "endOffset": 114}, {"referenceID": 19, "context": "In heterogeneous domain adaptation where the feature representations are different across domains (Li et al., 2014), the residual transfer can be applied to the feature layers (e.", "startOffset": 98, "endOffset": 115}, {"referenceID": 2, "context": "(2) In multi-task learning (Chu et al., 2015) that solves multiple potentially correlated tasks together to improve performance of all these tasks by sharing statistic strength, the residual transfer can also be extended to bridge the gap between specific task and the shared task.", "startOffset": 27, "endOffset": 45}, {"referenceID": 26, "context": "Office-31 (Saenko et al., 2010) is a standard benchmark for domain adaptation, comprising 4,652 images distributed in 31 classes collected from three distinct domains: Amazon (A), which contains images downloaded from amazon.", "startOffset": 10, "endOffset": 31}, {"referenceID": 29, "context": "We evaluate all methods across three transfer tasks A \u2192 W, D \u2192 W and W \u2192 D, which are commonly adopted by previous deep transfer learning methods (Donahue et al., 2014; Tzeng et al., 2014; Ganin & Lempitsky, 2015), and across another three transfer tasks A \u2192 D, D \u2192 A and W \u2192 A as presented in (Long et al.", "startOffset": 146, "endOffset": 213}, {"referenceID": 21, "context": ", 2014; Ganin & Lempitsky, 2015), and across another three transfer tasks A \u2192 D, D \u2192 A and W \u2192 A as presented in (Long et al., 2015; Tzeng et al., 2015).", "startOffset": 113, "endOffset": 152}, {"referenceID": 30, "context": ", 2014; Ganin & Lempitsky, 2015), and across another three transfer tasks A \u2192 D, D \u2192 A and W \u2192 A as presented in (Long et al., 2015; Tzeng et al., 2015).", "startOffset": 113, "endOffset": 152}, {"referenceID": 7, "context": "Office-Caltech (Gong et al., 2012) is built by selecting the 10 common categories shared by the Office-31 and Caltech256 (C) (Griffin et al.", "startOffset": 15, "endOffset": 34}, {"referenceID": 13, "context": ", 2012) is built by selecting the 10 common categories shared by the Office-31 and Caltech256 (C) (Griffin et al., 2007) datasets, and is widely used by previous methods (Long et al.", "startOffset": 98, "endOffset": 120}, {"referenceID": 20, "context": ", 2007) datasets, and is widely used by previous methods (Long et al., 2013; Sun et al., 2016).", "startOffset": 57, "endOffset": 94}, {"referenceID": 27, "context": ", 2007) datasets, and is widely used by previous methods (Long et al., 2013; Sun et al., 2016).", "startOffset": 57, "endOffset": 94}, {"referenceID": 25, "context": "We compare with state of the art transfer and deep learning methods: Transfer Component Analysis (TCA) (Pan et al., 2011), Geodesic Flow Kernel (GFK) (Gong et al.", "startOffset": 103, "endOffset": 121}, {"referenceID": 7, "context": ", 2011), Geodesic Flow Kernel (GFK) (Gong et al., 2012), Deep Domain Confusion (DDC) (Tzeng et al.", "startOffset": 36, "endOffset": 55}, {"referenceID": 29, "context": ", 2012), Deep Domain Confusion (DDC) (Tzeng et al., 2014), Deep Adaptation Network (DAN) (Long et al.", "startOffset": 37, "endOffset": 57}, {"referenceID": 21, "context": ", 2014), Deep Adaptation Network (DAN) (Long et al., 2015), and Reverse Gradient (RevGrad) (Ganin & Lempitsky, 2015).", "startOffset": 39, "endOffset": 58}, {"referenceID": 8, "context": "RevGrad boosts domain adaptation by making source and target indistinguishable for a discriminative domain classifier through adversarial training (Goodfellow et al., 2014).", "startOffset": 147, "endOffset": 172}, {"referenceID": 26, "context": "We follow standard evaluation protocols for unsupervised domain adaptation (Saenko et al., 2010; Long et al., 2015).", "startOffset": 75, "endOffset": 115}, {"referenceID": 21, "context": "We follow standard evaluation protocols for unsupervised domain adaptation (Saenko et al., 2010; Long et al., 2015).", "startOffset": 75, "endOffset": 115}, {"referenceID": 26, "context": "For the Office-31 dataset, we adopt the sampling protocol (Saenko et al., 2010) that randomly samples the source domain with 20 labeled examples per category for Amazon (A) and 8 labeled examples per category for Webcam (W) and DSLR (D).", "startOffset": 58, "endOffset": 79}, {"referenceID": 21, "context": "For the Office-Caltech dataset, we adopt the full-sampling protocol (Long et al., 2015) that uses all labeled source examples and all unlabeled target examples.", "startOffset": 68, "endOffset": 87}, {"referenceID": 21, "context": "We follow (Long et al., 2015) and use multi-kernel MMD for DAN and RTN, and a family of m Gaussian kernels by varying bandwidth bu \u2208 [2b, 2b] with a multiplicative step-size of 2.", "startOffset": 10, "endOffset": 29}, {"referenceID": 21, "context": "We conduct cross-validation on labeled source data to select parameters of RTN (Long et al., 2015).", "startOffset": 79, "endOffset": 98}, {"referenceID": 17, "context": "We implement all deep methods based on the Caffe (Jia et al., 2014) deep-learning framework, and fine-tune from Caffe-trained models of AlexNet (Krizhevsky et al.", "startOffset": 49, "endOffset": 67}, {"referenceID": 18, "context": ", 2014) deep-learning framework, and fine-tune from Caffe-trained models of AlexNet (Krizhevsky et al., 2012) pre-trained on ImageNet (Russakovsky et al.", "startOffset": 84, "endOffset": 109}, {"referenceID": 26, "context": "Accuracy on Office-31 dataset under sampling protocol (Saenko et al., 2010) for unsupervised adaptation.", "startOffset": 54, "endOffset": 75}, {"referenceID": 25, "context": "Method A \u2192 W D \u2192 W W \u2192 D A \u2192 D D \u2192 A W \u2192 A Avg TCA (Pan et al., 2011) 59.", "startOffset": 51, "endOffset": 69}, {"referenceID": 7, "context": "8 GFK (Gong et al., 2012) 58.", "startOffset": 6, "endOffset": 25}, {"referenceID": 18, "context": "7 AlexNet (Krizhevsky et al., 2012) 60.", "startOffset": 10, "endOffset": 35}, {"referenceID": 29, "context": "7 DDC (Tzeng et al., 2014) 62.", "startOffset": 6, "endOffset": 26}, {"referenceID": 21, "context": "3 DAN (Long et al., 2015) 66.", "startOffset": 6, "endOffset": 25}, {"referenceID": 21, "context": "Accuracy on Office-Caltech dataset under full protocol (Long et al., 2015) for unsupervised adaptation.", "startOffset": 55, "endOffset": 74}, {"referenceID": 25, "context": "Method A\u2192W D\u2192W W\u2192D A\u2192D D\u2192A W\u2192A A\u2192C W\u2192C D\u2192C C\u2192A C\u2192W C\u2192D Avg TCA (Pan et al., 2011) 84.", "startOffset": 63, "endOffset": 81}, {"referenceID": 7, "context": "0 GFK (Gong et al., 2012) 89.", "startOffset": 6, "endOffset": 25}, {"referenceID": 18, "context": "5 AlexNet (Krizhevsky et al., 2012) 83.", "startOffset": 10, "endOffset": 35}, {"referenceID": 29, "context": "3 DDC (Tzeng et al., 2014) 86.", "startOffset": 6, "endOffset": 26}, {"referenceID": 21, "context": "2 DAN (Long et al., 2015) 93.", "startOffset": 6, "endOffset": 25}, {"referenceID": 26, "context": "Note that the results of RevGrad under the sampling protocol (Saenko et al., 2010) are directly reported from (Sun et al.", "startOffset": 61, "endOffset": 82}, {"referenceID": 27, "context": ", 2010) are directly reported from (Sun et al., 2016), as the original paper only provided results under the full-sampling protocol (Ganin & Lempitsky, 2015).", "startOffset": 35, "endOffset": 53}, {"referenceID": 26, "context": "A \u2192 W and A \u2192 D, where the source and target are substantially different, and achieves comparable classification accuracy on easy transfer tasks, D \u2192 W and W \u2192 D, where source and target are similar (Saenko et al., 2010).", "startOffset": 199, "endOffset": 220}, {"referenceID": 24, "context": "This result confirms the current practice that supervised fine-tuning is important for transferring source classifier to target domain (Oquab et al., 2013), and sustains the recent discovery that deep neural networks learn abstract feature representation, which can only reduce, but not remove, the cross-domain discrepancy (Yosinski et al.", "startOffset": 135, "endOffset": 155}, {"referenceID": 33, "context": ", 2013), and sustains the recent discovery that deep neural networks learn abstract feature representation, which can only reduce, but not remove, the cross-domain discrepancy (Yosinski et al., 2014).", "startOffset": 176, "endOffset": 199}, {"referenceID": 15, "context": "Otherwise, the residual function may tend to learn a useless zero mapping such that the source and target classifiers are nearly identical (He et al., 2015).", "startOffset": 139, "endOffset": 156}, {"referenceID": 21, "context": "This evidence suggests the residual transfer of classifiers devised in this paper is as effective as the MMD adaptation of features (Long et al., 2015).", "startOffset": 132, "endOffset": 151}, {"referenceID": 29, "context": "Hence the source and target classifiers should not be assumed to be identical, which, whatsoever, has been a common assumption made by all prior deep domain adaptation methods (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 176, "endOffset": 260}, {"referenceID": 21, "context": "Hence the source and target classifiers should not be assumed to be identical, which, whatsoever, has been a common assumption made by all prior deep domain adaptation methods (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 176, "endOffset": 260}, {"referenceID": 30, "context": "Hence the source and target classifiers should not be assumed to be identical, which, whatsoever, has been a common assumption made by all prior deep domain adaptation methods (Tzeng et al., 2014; Long et al., 2015; Ganin & Lempitsky, 2015; Tzeng et al., 2015).", "startOffset": 176, "endOffset": 260}, {"referenceID": 15, "context": "Analysis of Layer Responses: We illustrate in Figure 4(a) the average magnitudes and standard deviations of the layer responses (He et al., 2015), which are the outputs of fT (x) (fc8 layer), \u2206f(fT (x)) (fc10 layer), and fS(x) (sum operator) before other nonlinearity (ReLU/addition/softmax), respectively.", "startOffset": 128, "endOffset": 145}, {"referenceID": 15, "context": "The small residual function can be learned more effectively through the residual learning framework (He et al., 2015).", "startOffset": 100, "endOffset": 117}, {"referenceID": 21, "context": "Parameter Sensitivity: Besides the MMD penalty parameter \u03bb as DAN (Long et al., 2015), the RTN model involves another entropy penalty parameter \u03b3.", "startOffset": 66, "endOffset": 85}], "year": 2016, "abstractText": "The recent success of deep neural networks relies on massive amounts of labeled data. For a target task where labeled data is unavailable, domain adaptation can transfer a learner from a different source domain. In this paper, we propose a new approach to domain adaptation in deep networks that can simultaneously learn adaptive classifiers and transferable features from labeled data in the source domain and unlabeled data in the target domain. We relax a shared-classifier assumption made by previous methods and assume that the source classifier and target classifier differ by a residual function. We enable classifier adaptation by plugging several layers into the deep network to explicitly learn the residual function with reference to the target classifier. We embed features of multiple layers into reproducing kernel Hilbert spaces (RKHSs) and match feature distributions for feature adaptation. The adaptation behaviors can be achieved in most feed-forward models by extending them with new residual layers and loss functions, which can be trained efficiently using standard back-propagation. Empirical evidence exhibits that the approach outperforms state of art methods on standard domain adaptation datasets.", "creator": "LaTeX with hyperref package"}}}