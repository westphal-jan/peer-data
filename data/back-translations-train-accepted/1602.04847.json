{"id": "1602.04847", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Feb-2016", "title": "Black-box Optimization with a Politician", "abstract": "We propose a new framework for black-box convex optimization which is well-suited for situations where gradient computations are expensive. We derive a new method for this framework which leverages several concepts from convex optimization, from standard first-order methods (e.g. gradient descent or quasi-Newton methods) to analytical centers (i.e. minimizers of self-concordant barriers). We demonstrate empirically that our new technique compares favorably with state of the art algorithms (such as BFGS).", "histories": [["v1", "Mon, 15 Feb 2016 21:35:58 GMT  (247kb,D)", "http://arxiv.org/abs/1602.04847v1", "19 pages"]], "COMMENTS": "19 pages", "reviews": [], "SUBJECTS": "math.OC cs.DS cs.LG cs.NA", "authors": ["s\u00e9bastien bubeck", "yin tat lee"], "accepted": true, "id": "1602.04847"}, "pdf": {"name": "1602.04847.pdf", "metadata": {"source": "CRF", "title": "Black-box optimization with a politician", "authors": ["S\u00e9bastien Bubeck", "Yin Tat Lee"], "emails": ["sebubeck@microsoft.com", "yintat@mit.edu"], "sections": [{"heading": "1 Introduction", "text": "In this paper, we propose to replace the oracle with a politician. Instead of answering the original question we asked the politician, we present the following definition (for reasons of simplicity), which is guaranteed to be better than the original query x in the sense that f (y) \u2264 f (x). The newly selected query also depends on the history of the questions asked to the politician. Formally, we present the following definition (for reasons of simplicity), which we use for either a gradient or a subgradient of f (x).Definition 1 Let X-Rn and f-R-Rn is a politician."}, {"heading": "2 Affine invariant politician", "text": "As mentioned above, we assume that the complexity of calculating the map x 7 \u2192 f (x) Q (x) is a superlinear (Q). This means that we can afford to have a politician in such a way that the complexity of calculating the map (x, h) 7 \u2192 \u03a6 (x, h) O (n) poly (k)) (we consider the number of iterations k to be typically much smaller than the dimension n. We show in this section that this condition is (essentially) met automatically as long as the politician is unpredictable in this sense (we use a slight misuse of language and refer to a map f \u2192 f where f) is a politician for f, as a politician."}, {"heading": "3 Geometric politician", "text": "In this section we describe the geometric politician, which is based on ideas presented in Bubeck et al. (2015) A key observation in the latter work is that if f has a very strong convex function, the x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-"}, {"heading": "4 Volumetric center", "text": "The volumetric barrier for a polytope was introduced in Vaidya [1996] = > FR = > FR = > R = > FR = > R = > R = > R = > R = > R = > R = > R = > R (Section 2.3, Bubeck [2015] for more details and Lee et al. [2015] forrecent advances on this construction (x) = 1 log (bi \u2212 a > i x), defining the volumetric barrier vP (x) = logdet vP byvP (x) = logdet (x), then the volumetric middle c (P) is defined as a minimizer of the vP."}, {"heading": "5 Experiments", "text": "In this section we compare the geometric politician with two libraries for methods of the first order, minFunc Schmidt [2012] and TFOCS Becker et al. [2011], both popular MATLAB libraries for minimizing the general smooth convex functions. Since the focus of this paper is on how to find a good step direction by means of a politician, we use the exact line search (up to the precision of the machine) whenever possible. This eliminates the effect of different line searches and reduces the number of algorithms we have to test. TFOCS is the only algorithm we use that does not use line search because it does not offer such an option. To compensate for the injustice to TFOCS, we point out that the algorithm uses TFOCS accelerated gradient descent and therefore we implement the accelerated gradient descent of Gonz\u00e1le."}, {"heading": "5.1 Details of Implementations", "text": "The first algorithm we implement is the \u2205 + algorithm, which we simply repeatedly call a politician. As we will see, this algorithm is excellent for non-smooth problems, but not competitive for smooth problems. The second algorithm we implement is the accelerated gradient descent proposed by Gonzaga and Karas Gonzaga and Karas Gonzaga and Karas [2013]. This algorithm uses the line search to learn the smoothing parameter and the strong convexity parameter, see algorithm 3. We disable the line (*) in the algorithm if it is a politician, rather than an oracle, because it does not apply to the strong convexity parameter if it is not an oracle. The third algorithm we implement is the Broyden Fletcher Gold Color algorithm. (This algorithm does not work for the strong convexity parameter if it is not a gold parameter)."}, {"heading": "5.2 Quadratic function", "text": "We look at the function f (x) = (x \u2212 c) > D (x \u2212 c), (2) where D is a diagonal matrix with uniformly sampled entries and c is a random vector with uniformly sampled entries from the normal distribution N (0, 1). As it is a square function, CG, BFGS and BFGS + are equivalent and optimal, namely they give the minimum point in the span of all previous gradients. Algorithm 3: Gonzaga-Karas \"variant of accelerated gradient input: x1. \u03b3 = 2\u03b1, v0 = x0 and y0 = x0. for k \u2190 1, 2, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 doyk \u2012 f (yk \u2212 1). xk + 1 = line search (yk) (yk, \u2212 f \u2212 x0) and we then use a first order."}, {"heading": "5.3 Variant of Nesterov\u2019s Worst Function", "text": "Nesterov [2004] introduced the function f (x) = (1 \u2212 x > [1]). To distinguish the performance between CG, BFGS and BFGS +, we consider the following non-square variant f (x) = g (1 \u2212 x [1]) + n \u2212 1 x (x [k] \u2212 x (3) for a function to be defined g (x) = | x | then all methods of the first order take at least n iterations to minimize f exactly. On the other hand, with g (x) = max (| \u2212 0,1, 0) one of the minimizers of f (1, 910, \u00b7 \u00b7 \u00b7, 1 \u00b7 \u00b7 \u00b7, 0."}, {"heading": "5.4 Binary regression with smoothed hinge loss", "text": "We consider the binary classification problem on the data sets of Chang and Lin [2011]. However, the problem is to minimize the regulated empirical risks: ft (x) = 1n \u2211 i = 1 t (bia T i x) + 0, if ai-Rd, bi-R are given by the data sets, \u03bb is the regulation coefficient, t is the smoothed hinge loss defined by t (z) = 0, if z \u2264 \u2212 t 2, if z \u2265 \u2212 1 2t (z + 1) 2 otherwiseand is the smoothness parameter, t is the smoothed hinge loss defined by t (z). The latter case is to test how well the algorithms work when the function is not smooth."}, {"heading": "5.5 Summary", "text": "The experiments show that BFGS + and BFGS perform best among all methods for smooth test problems, while BFGS + and GK + perform best for smooth test problems. The first phenomenon is based on the optimality of this algorithm for quadratic problems. We leave the explanation for the second phenomenon as an open problem. At least the experiments show that this is not due to the geometric oracle itself, since \u2205 + is much slower, and this is not due to the original algorithm, since GK + performs much worse than GK + on these problems. Overall, these experiments are very promising for the geometric oracle as a replacement for quadratic problems and as an all-purpose solution due to its robustness."}, {"heading": "6 Discussion", "text": "We have shown that the cost per step of an affine, invariant politician (k) is negligible compared to the gradient calculation (which, in fact, has a lot of possibilities: instead of a basic addition or scalar multiplication, one can imagine that the calculation of a linear program or even the search for an exponential space (in fact, say: k < 30 and n > 1010, then 2k < n) demonstrates the effectiveness of this strategy. On the other hand, from a theoretical standpoint of view, a lot remains to be done. For example, one can prove the results of the following flavor: Theorem 1 Lass f so that I (x) \u03b2I."}], "references": [{"title": "The volumetric barrier for convex quadratic constraints", "author": ["M.K. Anstreicher"], "venue": "Mathematical Programming,", "citeRegEx": "Anstreicher.,? \\Q2004\\E", "shortCiteRegEx": "Anstreicher.", "year": 2004}, {"title": "A cutting plane algorithm for convex programming that uses analytic centers", "author": ["David S Atkinson", "Pravin M Vaidya"], "venue": "Mathematical Programming,", "citeRegEx": "Atkinson and Vaidya.,? \\Q1995\\E", "shortCiteRegEx": "Atkinson and Vaidya.", "year": 1995}, {"title": "A cutting plane method from analytic centers for stochastic programming", "author": ["Olivier Bahn", "O Du Merle", "J-L Goffin", "J-P Vial"], "venue": "Mathematical Programming,", "citeRegEx": "Bahn et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Bahn et al\\.", "year": 1995}, {"title": "Templates for convex cone problems with applications to sparse signal recovery", "author": ["Stephen R Becker", "Emmanuel J Cand\u00e8s", "Michael C Grant"], "venue": "Mathematical programming computation,", "citeRegEx": "Becker et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Becker et al\\.", "year": 2011}, {"title": "Convex optimization: Algorithms and complexity", "author": ["S. Bubeck"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Bubeck.,? \\Q2015\\E", "shortCiteRegEx": "Bubeck.", "year": 2015}, {"title": "A geometric alternative to nesterov\u2019s accelerated gradient descent", "author": ["S. Bubeck", "Y.-T. Lee", "M. Singh"], "venue": "Arxiv preprint arXiv:1506.08187,", "citeRegEx": "Bubeck et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bubeck et al\\.", "year": 2015}, {"title": "Libsvm: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST).,", "citeRegEx": "Chang and Lin.,? \\Q2011\\E", "shortCiteRegEx": "Chang and Lin.", "year": 2011}, {"title": "Shallow, deep and very deep cuts in the analytic center cutting plane method", "author": ["Jean-Louis Goffin", "Jean-Philippe Vial"], "venue": "Mathematical Programming,", "citeRegEx": "Goffin and Vial.,? \\Q1999\\E", "shortCiteRegEx": "Goffin and Vial.", "year": 1999}, {"title": "Fine tuning nesterovs steepest descent algorithm for differentiable convex programming", "author": ["Cl\u00f3vis C Gonzaga", "Elizabeth W Karas"], "venue": "Mathematical Programming,", "citeRegEx": "Gonzaga and Karas.,? \\Q2013\\E", "shortCiteRegEx": "Gonzaga and Karas.", "year": 2013}, {"title": "Partitions of mass-distributions and of convex bodies by hyperplanes", "author": ["B. Gr\u00fcnbaum"], "venue": "Pacific J. Math,", "citeRegEx": "Gr\u00fcnbaum.,? \\Q1960\\E", "shortCiteRegEx": "Gr\u00fcnbaum.", "year": 1960}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["R. Johnson", "T. Zhang"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Johnson and Zhang.,? \\Q2013\\E", "shortCiteRegEx": "Johnson and Zhang.", "year": 2013}, {"title": "A stochastic gradient method with an exponential convergence rate for strongly-convex optimization with finite training sets", "author": ["N. Le Roux", "M. Schmidt", "F. Bach"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Roux et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Roux et al\\.", "year": 2012}, {"title": "A faster cutting plane method and its implications for combinatorial and convex optimization", "author": ["Y.-T. Lee", "A. Sidford", "S.C.-W Wong"], "venue": "Arxiv preprint arXiv:1508.04874,", "citeRegEx": "Lee et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2015}, {"title": "Problem Complexity and Method Efficiency in Optimization", "author": ["A. Nemirovski", "D. Yudin"], "venue": "Wiley Interscience,", "citeRegEx": "Nemirovski and Yudin.,? \\Q1983\\E", "shortCiteRegEx": "Nemirovski and Yudin.", "year": 1983}, {"title": "Introductory lectures on convex optimization: A basic course", "author": ["Y. Nesterov"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "Nesterov.,? \\Q2004\\E", "shortCiteRegEx": "Nesterov.", "year": 2004}, {"title": "minfunc: unconstrained differentiable multivariate optimization in matlab", "author": ["M Schmidt"], "venue": "URL http://www. di. ens. fr/mschmidt/Software/minFunc. html,", "citeRegEx": "Schmidt.,? \\Q2012\\E", "shortCiteRegEx": "Schmidt.", "year": 2012}, {"title": "A new algorithm for minimizing convex functions over convex sets", "author": ["P.M. Vaidya"], "venue": "Mathematical programming,", "citeRegEx": "Vaidya.,? \\Q1996\\E", "shortCiteRegEx": "Vaidya.", "year": 1996}], "referenceMentions": [{"referenceID": 12, "context": "In standard black-box convex optimization Nemirovski and Yudin [1983], Nesterov [2004], Bubeck [2015] first-order methods interact with an oracle: given a query point x, the oracle reports the value and gradient of the underlying objective function f at x.", "startOffset": 42, "endOffset": 70}, {"referenceID": 12, "context": "In standard black-box convex optimization Nemirovski and Yudin [1983], Nesterov [2004], Bubeck [2015] first-order methods interact with an oracle: given a query point x, the oracle reports the value and gradient of the underlying objective function f at x.", "startOffset": 42, "endOffset": 87}, {"referenceID": 4, "context": "In standard black-box convex optimization Nemirovski and Yudin [1983], Nesterov [2004], Bubeck [2015] first-order methods interact with an oracle: given a query point x, the oracle reports the value and gradient of the underlying objective function f at x.", "startOffset": 88, "endOffset": 102}, {"referenceID": 4, "context": "We do so by introducing the geometric politician (Section 3), which is based on a combination of the recent ideas of Bubeck et al. [2015] with standard cutting plane/interior point methods machinery (through the notion of a \u201ccenter\u201d of a set, see Section 4).", "startOffset": 117, "endOffset": 138}, {"referenceID": 4, "context": "We describe in this section the geometric politician which is based on ideas developed in Bubeck et al. [2015]. A key observation in the latter paper is that if f is a \u03b1-strongly convex function minimized at x\u2217 then one has for any x, \u2225\u2225\u2225\u2225x\u2217 \u2212 x\u2212 1 \u03b1 \u2225\u2225\u2225\u22252 \u2264 \u2016\u2207f(x)\u2016 \u03b12 \u2212 2 \u03b1 (f(x)\u2212 f(x\u2217)) .", "startOffset": 90, "endOffset": 111}, {"referenceID": 9, "context": "In particular if the next query point yk+1 is the center of gravity of Rk then we have that the volume of Rk+1 is at most 1 \u2212 1/e times the volume of Rk (see Gr\u00fcnbaum [1960]), thus leading to an exponential convergence rate.", "startOffset": 158, "endOffset": 174}, {"referenceID": 14, "context": "The volumetric barrier for a polytope was introduced in Vaidya [1996] to construct an algorithm with both the oracle complexity of the center of gravity method and the computational complexity of the ellipsoid method (see [Section 2.", "startOffset": 56, "endOffset": 70}, {"referenceID": 4, "context": "3, Bubeck [2015]] for more details and Lee et al.", "startOffset": 3, "endOffset": 17}, {"referenceID": 4, "context": "3, Bubeck [2015]] for more details and Lee et al. [2015] for", "startOffset": 3, "endOffset": 57}, {"referenceID": 0, "context": "It is shown in Anstreicher [2004] that vR is a self-concordant barrier which means that the center can be updated (when a new ball is added to R) via few iterations of Newton\u2019s method.", "startOffset": 15, "endOffset": 34}, {"referenceID": 0, "context": "It is shown in Anstreicher [2004] that vR is a self-concordant barrier which means that the center can be updated (when a new ball is added to R) via few iterations of Newton\u2019s method. Often in practice, it takes less than 5 iterations to update the minimizer of a self-concordant barrier Goffin and Vial [1999], Bahn et al.", "startOffset": 15, "endOffset": 312}, {"referenceID": 0, "context": "It is shown in Anstreicher [2004] that vR is a self-concordant barrier which means that the center can be updated (when a new ball is added to R) via few iterations of Newton\u2019s method. Often in practice, it takes less than 5 iterations to update the minimizer of a self-concordant barrier Goffin and Vial [1999], Bahn et al. [1995] when we add a new constraint.", "startOffset": 15, "endOffset": 332}, {"referenceID": 15, "context": "Although the analytic center is a more popular choice for \u201cgeometrical\u201d algorithms, we choose volumetric center here because it gives a better convergence rate Vaidya [1996], Atkinson and Vaidya [1995] and the extra cost \u03c8(k) is negligible to the cost of updating QR decomposition nk.", "startOffset": 160, "endOffset": 174}, {"referenceID": 1, "context": "Although the analytic center is a more popular choice for \u201cgeometrical\u201d algorithms, we choose volumetric center here because it gives a better convergence rate Vaidya [1996], Atkinson and Vaidya [1995] and the extra cost \u03c8(k) is negligible to the cost of updating QR decomposition nk.", "startOffset": 175, "endOffset": 202}, {"referenceID": 10, "context": "In this section, we compare the geometric politician against two libraries for first order methods, minFunc Schmidt [2012] and TFOCS Becker et al.", "startOffset": 108, "endOffset": 123}, {"referenceID": 3, "context": "In this section, we compare the geometric politician against two libraries for first order methods, minFunc Schmidt [2012] and TFOCS Becker et al. [2011]. Both are popular MATLAB libraries for minimizing general smooth convex functions.", "startOffset": 133, "endOffset": 154}, {"referenceID": 3, "context": "In this section, we compare the geometric politician against two libraries for first order methods, minFunc Schmidt [2012] and TFOCS Becker et al. [2011]. Both are popular MATLAB libraries for minimizing general smooth convex functions. Since the focus of this paper is all about how to find a good step direction using a politician, we use the exact line search (up to machine accuracy) whenever possible. This eliminates the effect of different line searches and reduces the number of algorithms we need to test. TFOCS is the only algorithm we use which does not use line search because they do not provide such option. To compensate on the unfairness to TFOCS, we note that the algorithm TFOCS uses is accelerated gradient descent and hence we implement the GonzagaKaras\u2019s accelerated gradient descent Gonzaga and Karas [2013], which is specifically designed to be used with exact line search.", "startOffset": 133, "endOffset": 830}, {"referenceID": 3, "context": "In this section, we compare the geometric politician against two libraries for first order methods, minFunc Schmidt [2012] and TFOCS Becker et al. [2011]. Both are popular MATLAB libraries for minimizing general smooth convex functions. Since the focus of this paper is all about how to find a good step direction using a politician, we use the exact line search (up to machine accuracy) whenever possible. This eliminates the effect of different line searches and reduces the number of algorithms we need to test. TFOCS is the only algorithm we use which does not use line search because they do not provide such option. To compensate on the unfairness to TFOCS, we note that the algorithm TFOCS uses is accelerated gradient descent and hence we implement the GonzagaKaras\u2019s accelerated gradient descent Gonzaga and Karas [2013], which is specifically designed to be used with exact line search. Another reason we pick this variant of accelerated gradient descent is because we found it to be the fastest variant of accelerated gradient descent (excluding the geometric descent of Bubeck et al. [2015]) for our tested data (Gonzaga and Karas also observed that on their own dataset).", "startOffset": 133, "endOffset": 1103}, {"referenceID": 3, "context": "In this section, we compare the geometric politician against two libraries for first order methods, minFunc Schmidt [2012] and TFOCS Becker et al. [2011]. Both are popular MATLAB libraries for minimizing general smooth convex functions. Since the focus of this paper is all about how to find a good step direction using a politician, we use the exact line search (up to machine accuracy) whenever possible. This eliminates the effect of different line searches and reduces the number of algorithms we need to test. TFOCS is the only algorithm we use which does not use line search because they do not provide such option. To compensate on the unfairness to TFOCS, we note that the algorithm TFOCS uses is accelerated gradient descent and hence we implement the GonzagaKaras\u2019s accelerated gradient descent Gonzaga and Karas [2013], which is specifically designed to be used with exact line search. Another reason we pick this variant of accelerated gradient descent is because we found it to be the fastest variant of accelerated gradient descent (excluding the geometric descent of Bubeck et al. [2015]) for our tested data (Gonzaga and Karas also observed that on their own dataset). The algorithms to be tested are the following: \u2022 [SD] Steepest descent algorithm in minFunc. \u2022 [Nes] Accelerated gradient descent, General Scheme 2.2.6 in Nesterov [2004]. \u2022 [TFOCS] Accelerated gradient descent in TFOCS.", "startOffset": 133, "endOffset": 1356}, {"referenceID": 3, "context": "In this section, we compare the geometric politician against two libraries for first order methods, minFunc Schmidt [2012] and TFOCS Becker et al. [2011]. Both are popular MATLAB libraries for minimizing general smooth convex functions. Since the focus of this paper is all about how to find a good step direction using a politician, we use the exact line search (up to machine accuracy) whenever possible. This eliminates the effect of different line searches and reduces the number of algorithms we need to test. TFOCS is the only algorithm we use which does not use line search because they do not provide such option. To compensate on the unfairness to TFOCS, we note that the algorithm TFOCS uses is accelerated gradient descent and hence we implement the GonzagaKaras\u2019s accelerated gradient descent Gonzaga and Karas [2013], which is specifically designed to be used with exact line search. Another reason we pick this variant of accelerated gradient descent is because we found it to be the fastest variant of accelerated gradient descent (excluding the geometric descent of Bubeck et al. [2015]) for our tested data (Gonzaga and Karas also observed that on their own dataset). The algorithms to be tested are the following: \u2022 [SD] Steepest descent algorithm in minFunc. \u2022 [Nes] Accelerated gradient descent, General Scheme 2.2.6 in Nesterov [2004]. \u2022 [TFOCS] Accelerated gradient descent in TFOCS. \u2022 [GK] Gonzaga-Karas\u2019s of Accelerated Gradient Descent (Sec 5.1). \u2022 [Geo] Geometric Descent Bubeck et al. [2015]. \u2022 [CG] Non-Linear Conjugate Gradient in minFunc.", "startOffset": 133, "endOffset": 1519}, {"referenceID": 8, "context": "The second algorithm we implement is the accelerated gradient descent proposed by Gonzaga and Karas Gonzaga and Karas [2013]. This algorithm uses line search to learn the the smoothness parameter and strong convexity parameter, see Algorithm 3.", "startOffset": 82, "endOffset": 125}, {"referenceID": 14, "context": "3 Variant of Nesterov\u2019s Worst Function Nesterov [2004] introduced the function", "startOffset": 13, "endOffset": 55}, {"referenceID": 6, "context": "4 Binary regression with smoothed hinge loss We consider the binary classification problem on the datasets from Chang and Lin [2011]. The problem is to minimize the regularized empirical risk:", "startOffset": 112, "endOffset": 133}, {"referenceID": 10, "context": "We note that for this problem it would be natural to compare ourselves with SGD (stochastic gradient descent) or more refined stochastic algorithms such as SAG Le Roux et al. [2012] or SVRG Johnson and Zhang [2013].", "startOffset": 163, "endOffset": 182}, {"referenceID": 10, "context": "[2012] or SVRG Johnson and Zhang [2013]. However since the focus of this paper is on general black-box optimization we stick to comparing only to general methods.", "startOffset": 15, "endOffset": 40}, {"referenceID": 11, "context": "Note however that it is well-known that the volumetric center is usually more difficult to analyze, Vaidya [1996], Atkinson and Vaidya [1995].", "startOffset": 100, "endOffset": 114}, {"referenceID": 1, "context": "Note however that it is well-known that the volumetric center is usually more difficult to analyze, Vaidya [1996], Atkinson and Vaidya [1995]. \u2022 The extraneous log(\u03ba) comes from the number of potential restart when we decrease \u03b1.", "startOffset": 115, "endOffset": 142}, {"referenceID": 1, "context": "Note however that it is well-known that the volumetric center is usually more difficult to analyze, Vaidya [1996], Atkinson and Vaidya [1995]. \u2022 The extraneous log(\u03ba) comes from the number of potential restart when we decrease \u03b1. Is there a better way to learn \u03b1 that would not incur this additional logarithmic term? \u2022 Bubeck et al. [2015] shows essentially that one can combine the ellipsoid method with gradient descent to achieve the optimal 1\u2212 \u221a 1/\u03ba rate.", "startOffset": 115, "endOffset": 341}, {"referenceID": 1, "context": "Note however that it is well-known that the volumetric center is usually more difficult to analyze, Vaidya [1996], Atkinson and Vaidya [1995]. \u2022 The extraneous log(\u03ba) comes from the number of potential restart when we decrease \u03b1. Is there a better way to learn \u03b1 that would not incur this additional logarithmic term? \u2022 Bubeck et al. [2015] shows essentially that one can combine the ellipsoid method with gradient descent to achieve the optimal 1\u2212 \u221a 1/\u03ba rate. Can we prove such a result for SD+? The geometric politician could be refined in many ways. Here are two simple questions that we leave for future work: \u2022 One can think that gradient descent stores 1 gradient information, accelerated gradient descent stores 2 gradient information, and our method stores all past gradient information. We believe that neither 1, 2 nor all is the correct answer. Instead, the algorithm should dynamically decide the number of gradients to store based on the size of its memory, the cost of computing gradients, and the information each gradient reveals. \u2022 Is there a stochastic version of our algorithm? How well would such a method compare with state of the art stochastic algorithms such as SAG Le Roux et al. [2012] and SVRG Johnson and Zhang [2013]?", "startOffset": 115, "endOffset": 1212}, {"referenceID": 1, "context": "Note however that it is well-known that the volumetric center is usually more difficult to analyze, Vaidya [1996], Atkinson and Vaidya [1995]. \u2022 The extraneous log(\u03ba) comes from the number of potential restart when we decrease \u03b1. Is there a better way to learn \u03b1 that would not incur this additional logarithmic term? \u2022 Bubeck et al. [2015] shows essentially that one can combine the ellipsoid method with gradient descent to achieve the optimal 1\u2212 \u221a 1/\u03ba rate. Can we prove such a result for SD+? The geometric politician could be refined in many ways. Here are two simple questions that we leave for future work: \u2022 One can think that gradient descent stores 1 gradient information, accelerated gradient descent stores 2 gradient information, and our method stores all past gradient information. We believe that neither 1, 2 nor all is the correct answer. Instead, the algorithm should dynamically decide the number of gradients to store based on the size of its memory, the cost of computing gradients, and the information each gradient reveals. \u2022 Is there a stochastic version of our algorithm? How well would such a method compare with state of the art stochastic algorithms such as SAG Le Roux et al. [2012] and SVRG Johnson and Zhang [2013]?", "startOffset": 115, "endOffset": 1246}, {"referenceID": 14, "context": "6 in Nesterov [2004] shows that", "startOffset": 5, "endOffset": 21}], "year": 2016, "abstractText": "We propose a new framework for black-box convex optimization which is well-suited for situations where gradient computations are expensive. We derive a new method for this framework which leverages several concepts from convex optimization, from standard first-order methods (e.g. gradient descent or quasi-Newton methods) to analytical centers (i.e. minimizers of self-concordant barriers). We demonstrate empirically that our new technique compares favorably with state of the art algorithms (such as BFGS).", "creator": "LaTeX with hyperref package"}}}