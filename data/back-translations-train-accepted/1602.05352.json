{"id": "1602.05352", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Feb-2016", "title": "Recommendations as Treatments: Debiasing Learning and Evaluation", "abstract": "Most data for evaluating and training recommender systems is subject to selection biases, either through self-selection by the users or through the actions of the recommendation system itself. In this paper, we provide a principled approach to handling selection biases, adapting models and estimation techniques from causal inference. The approach leads to unbiased performance estimators despite biased data, and to a matrix factorization method that provides substantially improved prediction performance on real-world data. We theoretically and empirically characterize the robustness of the approach, finding that it is highly practical and scalable.", "histories": [["v1", "Wed, 17 Feb 2016 09:58:25 GMT  (1111kb,D)", "http://arxiv.org/abs/1602.05352v1", "10 pages"], ["v2", "Fri, 27 May 2016 03:18:59 GMT  (1178kb,D)", "http://arxiv.org/abs/1602.05352v2", "10 pages in ICML 2016"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.IR", "authors": ["tobias schnabel", "adith swaminathan", "ashudeep singh", "navin chandak", "thorsten joachims"], "accepted": true, "id": "1602.05352"}, "pdf": {"name": "1602.05352.pdf", "metadata": {"source": "META", "title": "Recommendations as Treatments: Debiasing Learning and Evaluation ", "authors": ["Tobias Schnabel", "Adith Swaminathan", "Ashudeep Singh {TBS", "Navin Chandak", "Thorsten Joachims"], "emails": ["AS3354}@CORNELL.EDU", "NAVINCHANDAK92@GMAIL.COM", "TJ@CS.CORNELL.EDU"], "sections": [{"heading": "1. Introduction", "text": "In a movie recommendation system, for example, users typically see and rate the movies they like and rarely rate movies they dislike (Pradel et al., 2012). Likewise, when an ad placement system recommends ads, it shows ads that it deems interesting to the user but less frequently displays other ads, creating a widely recognized challenge for the training and evaluation of recommendation systems (Marlin & Zemel, 2009; De Myttenaere et al, 2014). In this paper, we develop an approach to evaluating and preparing the work of the International Conference on Machine Learning (ICML)."}, {"heading": "2. Related Work", "text": "Previous work that explicitly addressed the MNAR nature of recommendation data approached the problem as a miscalculation of data based on the common probability of the missing data model and the rating model (Marlin et al., 2007; Marlin & Zemel, 2009; Herna \u0301 ndez-Lobato et al., 2014), resulting in complex and highly complex methodologies. We take a fundamentally different approach that treats both models separately, making our approach modular and scalable. Furthermore, our approach is robust against misspecification of the rating model, and we characterize how the general learning process gradually deteriorates under a misspecified missing data model. We compare empirically with the state-of-the-the-art Joint Likelihood Model (Herna \u0301 ndez-Lobato et al., 2014) in this paper. Related, but unlike the problem we are looking at, only the recommendation from positive feedback (2016 Hu Hal, 2008 Blei; Dawen)."}, {"heading": "3. Unbiased Performance Estimation for Recommendation", "text": "Consider the following toy example, adapted from Steck (2010) to illustrate the catastrophic effects that selection distortions can have on conventional ratings by using a test set of hero ratings. Use u {1,..., U} to denote users and i {1,..., I} to denote items. Figure 1 shows the matrix of true ratings Y < U \u00d7 I for our toy example, in which a subset of users are \"horror lovers,\" rating all horror movies 5 and all love movies 1. Similarly, there is a subset of \"love lovers\" rating the other way around. However, both groups rate dramas as 3. The binary matrix O 0, 1} U \u00d7 I in Figure 1 shows for which movies users submitted their ratings to the system, [Ou, i = 1]. Our toy example shows a strong correlation between the sympathy of a movie and the matrix, u = P, and the matrix = P, which describes the matrix = P, and the matrix = P."}, {"heading": "3.1. Task 1: Estimating Rating Prediction Accuracy", "text": "For the first task, we would like to evaluate how well a predicted rating matrix Y reflects the true ratings in Y. Standard rating measures such as Mean Absolute Error (MAE) or Mean Squared Error (MSE) can be written as follows: R (Y) = U (U) = 1 I (I), i (Y), i (Y), (1) for an appropriately selected task, i (Y, Y).MAE: \u03b4u, i (Y, Y) = | Yu, i \u2212 Y (U), i | / (U \u00b7 I), (2) MSE: \u0441u, i (Y, Y) = (Yu, i \u2212 Y), i), (U \u00b7 I), (3) Accuracy: \u00e7u, i (Y, Y), i (Y), i (Y), i (Y), i (I), i (I)."}, {"heading": "3.2. Task 2: Estimating Recommendation Quality", "text": "Instead of evaluating the accuracy of the predicted ratings, we should evaluate the quality of a particular recommendation more directly (naively). To this end, we should redefine Y recommendations to encode recommendations as a binary matrix, analogous to O, where [Y-u, i = 1] recommendations (i is recommended for u], limited to a budget of k recommendations per user. An example is Y-3 in Figure 1. A reasonable method to measure the quality of a recommendation is the cumulative gain (CG) that the user derives from the recommended movies, which we define as the average star rating of the recommended movies in our toy example1. CG, in turn, can be written in the form of equation (1) with CG: i (Y, Y) = Y-u, i \u00b7 Yu, i \u00b7 Yu, i \u00b7 Yu, i / (k \u00b7 U) observations of the recommended movies. (7) Unless users have seen all movies directly in Y, we cannot pilibrate all of them via Y (G)."}, {"heading": "3.3. Propensity-Scored Performance Estimators", "text": "In this context, we distinguish between the following two settings: Users are part of the allocation mechanism, the O. An example is an online streaming service for movies, where users choose the movies they watch and rate themselves. In this paper, we assume that the allocation mechanisms are more likely, which means that the allocation mechanisms Pu, i = 1) of the observation mechanisms Pu, i = 1) of the observation mechanisms Pu."}, {"heading": "3.4. Empirical Illustration of Estimators", "text": "To illustrate the effectiveness of the proposed estimators in comparison to the na\u00efve estimator, we performed an experiment with the semisynthetic ML100K dataset, which is described in more detail in Section 6.2. Y is fully known for this dataset, so that we can calculate the true performance using Equation (1). The probability Pu, i of observing a rating Yu, i was chosen to imitate the observed margins in ML100K (see Section 6.2) in such a way that 1% of the O matrix was not zero. Table 1 shows the results for estimating the accuracy of the rating using MAE and the recommendation quality using DCG @ 50 for the following five prediction matrices Y-i. Let us be the number of r-star ratings in Y. REC ONES: The prediction matrix Y Y Y Y Y is identical to the rating SOS-II except that | Y = 5 | randomly selected true ratings are extrapolated from 1 to 5."}, {"heading": "4. Propensity-Scored Recommendation Learning", "text": "The previous section derived effective performance estimators to evaluate a prediction Y. In the following, we will use these estimators as part of an empirical risk mitigation (ERM) framework for learning, demonstrate generalization error margins for this ERM framework, and derive a matrix factorization method for rating prediction."}, {"heading": "4.1. Empirical Risk Minimization for Recommendation with Propensities", "text": "Empirical risk mitigation underlies many successful learning algorithms such as SVMs (Cortes & Vapnik, 1995), Boosting (Schapire, 1990) and Deep Networks (Bengio, 2009), and weighted ERM approaches have been effective for cost-sensitive classification, domain adaptation and covariant shift (Zadrozny et al., 2003; Bickel et al., 2009; Sugiyama & Kawanabe, 2012). We adapt the ERM to our setting by recognizing that equation (1) corresponds to an expected loss (i.e. risk) over the data generation process P (O | P). Given a sample from P (O | P), we can consider the IPS estimate from Equation (11) to be the empirical risk R (Y) that estimates R (Y) for any Y change."}, {"heading": "4.2. Propensity-Scored Matrix Factorization", "text": "Suppose a standardized, d-restricted and L2-regulated matrix factorization model Y-u, i = uTu vi + au + bi + cwith user, item, and global offsets as our hypothesis space H. Within the framework of this model, the tendentiously evaluated ERM leads to the following training target: argmin U, V, A [\u2211 Ou, i = 1 \u03b4u, i (Y, U TV + A) Pu, i + \u03bb (| U | 2F + | | 2F)] (17), where A encodes the offset conditions and Y-ERM = UTV + A. Except for the inclinations Pu, i, which act as weights for each loss date, the training target is identical to the incomplete matrix factorization target (Koren, 2008; Steck, 2010; Hu et, this problem means that we can draw this year (MAYs 2) with the existing principle."}, {"heading": "5. Propensity Estimation for Observational Data", "text": "We now turn to the observational setting, in which the inclinations must be appreciated, as users make self-directed decisions, the results of which come to light. One might worry that one must perfectly reconstruct all inclinations. However, as we will show, we only need estimated inclinations that are \"better\" than the naive assumption that observations are uniformly revealed, i.e., Pu, i = | Ou, i = 1 | / (U \u00b7 I) for all users and items. Below, we will describe what \"better\" inclinations are both in terms of the bias they evoke and in terms of their impact on the variability of the learning process."}, {"heading": "5.1. Propensity Estimation via Naive Bayes", "text": "For our assignment model, we need to estimate a collection of Bernoulli random variables Ou, i, where the parameters Pu, i correspond to the slopes we are aiming for. In principle, the distribution of P (O | X, Xhid, Y) (20) may depend on some observable characteristics X (e.g. the predicted rating displayed to the user), non-observable characteristics Xhid (e.g. whether the film was recommended by a friend), and the ratings Y. It is reasonable to assume that Ou, i is independent of the new predictions Y (and therefore independent of \u03b4u, i (Y, Y))) once the observable characteristics are taken into account. Below, two prediction methods are outlined, but there is a wide range of other available techniques (e.g. McCaffrey et al., 2004). In our first approach to estimating P (O | X, Xhid, Y), we can assume that dependencies on profiles we observe only X and Yu-values (we only add X and Yu-values to the Xi)."}, {"heading": "5.2. Propensity Estimation via Logistic Regression", "text": "The second approach to estimating inclination, which we examine in our experiments, is based on logistic regression, as it is often used in statistics (Rosenbaum, 2002). It also assumes (20), but aims to find model parameters \u03c6, so that O becomes independent of unobserved Xhid and Y, i.e. P (O | X, Xhid, Y) = P (O | X, \u03c6). The main assumption for modelling is that there is a \u03c6 = (w, \u03b2, \u03b3), so that Pu, i = \u03c3 (wTXu, i + \u03b2i + \u03b3u)."}, {"heading": "6. Empirical Evaluation", "text": "We conduct extensive experiments to evaluate the empirical performance and robustness of the proposed methods in both experimental and observational environments. Furthermore, we compare the current joint likelihood method for MNAR data (Herna \u0301 ndezLobato et al., 2014) with real data sets."}, {"heading": "6.1. Experiment Setup", "text": "In all experiments, we perform the model selection for the regularization parameter \u03bb and / or the rank of factorization d by cross-validation as follows: We randomly divide the observed MNAR evaluations into four folds, training three and evaluating the remaining ones using the IPS estimator. Note that this additional allocation of inclinations requires scaling the inclinations in the training folds by k \u2212 1 k and the inclinations in the validation fold by 1 k. Parameters with the best average validation target performance are used to retrain all MNAR data. We report on the test performance on the MCAR test samples that accompany the real data sets, and on Equation (1) for our semi-synthetic data."}, {"heading": "6.2. How is evaluation affected by sampling bias severity?", "text": "In this experiment, we evaluate how different observation distributions affect the accuracy of the performance estimators. We compare the naive estimators for MSE (5), MAE (5), and DCG (10) with their inclination-weighted analogies, IPS (11), and SNIPS (14). Since this experiment requires experimental control of the sampling bias, we have a semi-synthetic dataset and observation model.ML100K Dataset2 provides 100K MNAR ratings for 1683 films from 944 users. To enable an assessment of the truth based on a fully known assessment matrix, we complete these partial evaluations using a standard matrix factorization of d = 100. However, the completed matrix gives unrealistically high ratings for almost all films, so we adjust ratings for the final Y distribution to achieve a more realistic distribution of ratings."}, {"heading": "6.3. How is learning affected by sampling bias severity?", "text": "The following experiment examines whether these increases in the accuracy of risk assessment translate into improved learning about the ERM, also in the Experimental Setting. Both methods use the same semi-synthetic ML100K dataset and the same observational model as above, and compare our MFIPS matrix factorization with the traditional unweighted MF-naive matrix factorization. Both methods use the same factorization model with separate \u03bb that is cross-validated and d = 20. The results are shown in Figure 3 (left), where shaded regions show 95% confidence intervals over 40 studies. Tender-weighted matrix factorization MF-IPS exceeds conventional matrix factorization by an order of magnitude relative to MSE. We also conducted experiments for MAE, and the results are similar. Slightly surprisingly, learning appears to be even less influenced by a selection bias (i.e., a small point) than the assessment. We suspect that this is due to the relatively stable distribution of the Y-rating."}, {"heading": "6.4. How robust is evaluation and learning to inaccurately learned propensities?", "text": "To investigate the robustness of inclination estimates of varying accuracy, we use the ML100K data and the observation model with \u03b1 = 0.25. To generate increasingly poor inclination estimates, we use the Naive Bayes model from Section 5.1, but vary the size of the uniform sample available for the evaluation of the limit valuations P (Yu, i = r) via the Laplace estimator. For zero samples, we specify that P (Yu, i = r) = 1 / 5 for all R. Figure 4 shows how the quality of the inclination estimates affects the evaluation using the same setup as in Section 6.2. Under no circumstances do the IPS and SNIPS estimators perform worse than Naive. Interestingly, IPS-NB with estimated inclination estimates performs even better than IPS-KNOWN with known inclinations."}, {"heading": "6.5. Performance on Real-World Data", "text": "Our latest experiments concern the performance of customers shopping in an online store. We use the following two sets of data, both of which have a separate test set in which users were asked to rate a uniformly drawn sample of Items.Yahoo! R3 HL Dataset. This Dataset3 (Marlin & Zemel, 2009) contains ratings of user songs selected by 15,400 users. The test set contains ratings from a subset of 5,400 users who were asked to rate 10 randomly selected songs. For this data, we estimate the bias via Naive Bayes. As a unified sample for determining the marginal rating distribution, we set aside 5% of the uniformly drawn sample and report only on the remaining 95% of the testset.3http: / / webscope.sandbox.yahoo.com / Coat Shopping Dataset. We collected new Dataset4 in which customers purchase a coat in an online store."}, {"heading": "7. Conclusions", "text": "The paper suggested an effective and robust approach to managing selection distortions in the assessment and learning of recommendation systems based on inclination assessment, and the modularity of the approach - separating the estimation of the allocation model from the rating model - also makes it very practical. In particular, any conditional probability assessment method can be used as an inclination estimator, and we suspect that many existing rating models can be retrofitted with inclination weighting without sacrificing scalability."}], "references": [{"title": "A statistical method for system evaluation using incomplete judgments", "author": ["Aslam", "Javed A", "Pavlu", "Virgil", "Yilmaz", "Emine"], "venue": "In SIGIR,", "citeRegEx": "Aslam et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Aslam et al\\.", "year": 2006}, {"title": "Chasing $1,000,000. how we won the netflix progress prize", "author": ["R. Bell", "Y. Koren", "C. Volinsky"], "venue": "Statistical Computing and Graphics,", "citeRegEx": "Bell et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bell et al\\.", "year": 2007}, {"title": "Learning deep architectures for ai", "author": ["Bengio", "Yoshua"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Bengio and Yoshua.,? \\Q2009\\E", "shortCiteRegEx": "Bengio and Yoshua.", "year": 2009}, {"title": "Discriminative learning under covariate shift", "author": ["Bickel", "Steffen", "Br\u00fcckner", "Michael", "Scheffer", "Tobias"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bickel et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bickel et al\\.", "year": 2009}, {"title": "A limited memory algorithm for bound constrained optimization", "author": ["Byrd", "Richard H", "Lu", "Peihuang", "Nocedal", "Jorge", "Zhu", "Ciyou"], "venue": "SIAM Journal on Scientific Computing,", "citeRegEx": "Byrd et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Byrd et al\\.", "year": 1995}, {"title": "Gradient descent optimization of smoothed information retrieval metrics", "author": ["Chapelle", "Olivier", "Wu", "Mingrui"], "venue": "Information retrieval,", "citeRegEx": "Chapelle et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2010}, {"title": "Sample selection bias correction theory", "author": ["Cortes", "Corinna", "Mohri", "Mehryar", "Riley", "Michael", "Rostamizadeh", "Afshin"], "venue": "In International Conference on Algorithmic Learning Theory,", "citeRegEx": "Cortes et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2008}, {"title": "Learning bounds for importance weighting", "author": ["Cortes", "Corinna", "Mansour", "Yishay", "Mohri", "Mehryar"], "venue": "In NIPS, pp", "citeRegEx": "Cortes et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2010}, {"title": "Modeling user exposure in recommendation", "author": ["Dawen Liang", "Laurent Charlin", "James McInerney", "Blei", "David"], "venue": "In WWW,", "citeRegEx": "Liang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Liang et al\\.", "year": 2016}, {"title": "Reducing offline evaluation bias in recommendation systems", "author": ["De Myttenaere", "Arnaud", "Le Grand", "B\u00e9n\u00e9dicte", "Golden", "Boris", "Rossi", "Fabrice"], "venue": "In Benelearn,", "citeRegEx": "Myttenaere et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Myttenaere et al\\.", "year": 2014}, {"title": "Doubly robust policy evaluation and learning", "author": ["Dud\u0131\u0301k", "Miroslav", "Langford", "John", "Li", "Lihong"], "venue": "In ICML, pp", "citeRegEx": "Dud\u0131\u0301k et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dud\u0131\u0301k et al\\.", "year": 2011}, {"title": "Large-scale matrix factorization with distributed stochastic gradient descent", "author": ["Gemulla", "Rainer", "Nijkamp", "Erik", "Haas", "Peter J", "Sismanis", "Yannis"], "venue": "In KDD, pp", "citeRegEx": "Gemulla et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gemulla et al\\.", "year": 2011}, {"title": "Probabilistic matrix factorization with non-random missing data", "author": ["Hern\u00e1ndez-Lobato", "Jose M", "Houlsby", "Neil", "Ghahramani", "Zoubin"], "venue": "In ICML, pp", "citeRegEx": "Hern\u00e1ndez.Lobato et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hern\u00e1ndez.Lobato et al\\.", "year": 2014}, {"title": "Weighted average importance sampling and defensive mixture distributions", "author": ["Hesterberg", "Tim"], "venue": null, "citeRegEx": "Hesterberg and Tim.,? \\Q1995\\E", "shortCiteRegEx": "Hesterberg and Tim.", "year": 1995}, {"title": "Efficient estimation of average treatment effects using the estimated propensity", "author": ["K. Hirano", "G. Imbens", "G. Ridder"], "venue": "score. Econometrica,", "citeRegEx": "Hirano et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hirano et al\\.", "year": 2003}, {"title": "Collaborative filtering for implicit feedback datasets", "author": ["Hu", "Yifan", "Koren", "Yehuda", "Volinsky", "Chris"], "venue": "In ICDM, pp", "citeRegEx": "Hu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2008}, {"title": "Correcting sample selection bias by unlabeled data", "author": ["Huang", "Jiayuan", "Smola", "Alexander J", "Gretton", "Arthur", "Borgwardt", "Karsten M", "Sch\u00f6lkopf", "Bernhard"], "venue": "In NIPS, pp", "citeRegEx": "Huang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2006}, {"title": "Causal Inference for Statistics, Social, and Biomedical Sciences", "author": ["G. Imbens", "D. Rubin"], "venue": null, "citeRegEx": "Imbens and Rubin,? \\Q2015\\E", "shortCiteRegEx": "Imbens and Rubin", "year": 2015}, {"title": "A support vector method for multivariate performance measures", "author": ["T. Joachims"], "venue": "In ICML, pp", "citeRegEx": "Joachims,? \\Q2005\\E", "shortCiteRegEx": "Joachims", "year": 2005}, {"title": "Factorization meets the neighborhood: A multifaceted collaborative filtering model", "author": ["Koren", "Yehuda"], "venue": "In KDD, pp", "citeRegEx": "Koren and Yehuda.,? \\Q2008\\E", "shortCiteRegEx": "Koren and Yehuda.", "year": 2008}, {"title": "Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms", "author": ["Li", "Lihong", "Chu", "Wei", "Langford", "John", "Wang", "Xuanhui"], "venue": "In WSDM,", "citeRegEx": "Li et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "Topn recommendation with missing implicit feedback", "author": ["Lim", "Daryl", "McAuley", "Julian", "Lanckriet", "Gert"], "venue": "In RecSys, pp", "citeRegEx": "Lim et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lim et al\\.", "year": 2015}, {"title": "Projected gradient methods for nonnegative matrix factorization", "author": ["Lin", "Chih-Jen"], "venue": "Neural computation,", "citeRegEx": "Lin and Chih.Jen.,? \\Q2007\\E", "shortCiteRegEx": "Lin and Chih.Jen.", "year": 2007}, {"title": "Statistical Analysis with Missing Data", "author": ["R.J.A. Little", "D.B. Rubin"], "venue": "John Wiley,", "citeRegEx": "Little and Rubin,? \\Q2002\\E", "shortCiteRegEx": "Little and Rubin", "year": 2002}, {"title": "Collaborative prediction and ranking with non-random missing data", "author": ["Marlin", "Benjamin M", "Zemel", "Richard S"], "venue": "In RecSys, pp", "citeRegEx": "Marlin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Marlin et al\\.", "year": 2009}, {"title": "Collaborative filtering and the missing at random assumption", "author": ["Marlin", "Benjamin M", "Zemel", "Richard S", "Roweis", "Sam", "Slaney", "Malcolm"], "venue": "In UAI,", "citeRegEx": "Marlin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Marlin et al\\.", "year": 2007}, {"title": "Propensity score estimation with boosted regression for evaluating causal effects in observational studies", "author": ["McCaffrey", "Daniel F", "Ridgeway", "Greg", "Morral", "Andrew R"], "venue": "Psychological Methods,", "citeRegEx": "McCaffrey et al\\.,? \\Q2004\\E", "shortCiteRegEx": "McCaffrey et al\\.", "year": 2004}, {"title": "Ranking with non-random missing ratings: influence of popularity and positivity on evaluation metrics", "author": ["Pradel", "Bruno", "Usunier", "Nicolas", "Gallinari", "Patrick"], "venue": "In RecSys, pp", "citeRegEx": "Pradel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Pradel et al\\.", "year": 2012}, {"title": "Observational Studies", "author": ["Rosenbaum", "Paul R"], "venue": null, "citeRegEx": "Rosenbaum and R.,? \\Q2002\\E", "shortCiteRegEx": "Rosenbaum and R.", "year": 2002}, {"title": "Alternatives to bpref", "author": ["Sakai", "Tetsuya"], "venue": "In SIGIR, pp. 71\u201378", "citeRegEx": "Sakai and Tetsuya.,? \\Q2007\\E", "shortCiteRegEx": "Sakai and Tetsuya.", "year": 2007}, {"title": "The strength of weak learnability", "author": ["Schapire", "Robert E"], "venue": "Machine Learning,", "citeRegEx": "Schapire and E.,? \\Q1990\\E", "shortCiteRegEx": "Schapire and E.", "year": 1990}, {"title": "Review of inverse probability weighting for dealing with missing data", "author": ["Seaman", "Shaun R", "White", "Ian R"], "venue": "Statistical methods in medical research,", "citeRegEx": "Seaman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Seaman et al\\.", "year": 2013}, {"title": "Training and testing of recommender systems on data missing not at random", "author": ["Steck", "Harald"], "venue": "In KDD,", "citeRegEx": "Steck and Harald.,? \\Q2010\\E", "shortCiteRegEx": "Steck and Harald.", "year": 2010}, {"title": "Learning from logged implicit exploration data", "author": ["Strehl", "Alexander L", "Langford", "John", "Li", "Lihong", "Kakade", "Sham"], "venue": "In NIPS, pp", "citeRegEx": "Strehl et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Strehl et al\\.", "year": 2010}, {"title": "Machine Learning in Non-Stationary Environments - Introduction to Covariate Shift Adaptation", "author": ["Sugiyama", "Masashi", "Kawanabe", "Motoaki"], "venue": null, "citeRegEx": "Sugiyama et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sugiyama et al\\.", "year": 2012}, {"title": "The self-normalized estimator for counterfactual learning", "author": ["A. Swaminathan", "T. Joachims"], "venue": "In NIPS,", "citeRegEx": "Swaminathan and Joachims,? \\Q2015\\E", "shortCiteRegEx": "Swaminathan and Joachims", "year": 2015}, {"title": "Conditional monte carlo for normal samples", "author": ["H.F. Trotter", "J.W. Tukey"], "venue": "In Symposium on Monte Carlo Methods,", "citeRegEx": "Trotter and Tukey,? \\Q1956\\E", "shortCiteRegEx": "Trotter and Tukey", "year": 1956}, {"title": "Maximum margin matrix factorization for collaborative ranking", "author": ["Weimer", "Markus", "Karatzoglou", "Alexandros", "Le", "Quoc Viet", "Smola", "Alex"], "venue": null, "citeRegEx": "Weimer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Weimer et al\\.", "year": 2007}, {"title": "Inverse probability weighted estimation for general missing data problems", "author": ["J. Wooldridge"], "venue": "Journal of Econometrics,", "citeRegEx": "Wooldridge,? \\Q2007\\E", "shortCiteRegEx": "Wooldridge", "year": 2007}, {"title": "A simple and efficient sampling method for estimating AP and NDCG", "author": ["Yilmaz", "Emine", "Kanoulas", "Evangelos", "Aslam", "Javed A"], "venue": "In SIGIR,", "citeRegEx": "Yilmaz et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Yilmaz et al\\.", "year": 2008}, {"title": "Scalable coordinate descent approaches to parallel matrix factorization for recommender systems", "author": ["Yu", "Hsiang-Fu", "Hsieh", "Cho-Jui", "I Dhillon"], "venue": "In ICDM,", "citeRegEx": "Yu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2012}, {"title": "Costsensitive learning by cost-proportionate example weighting", "author": ["Zadrozny", "Bianca", "Langford", "John", "Abe", "Naoki"], "venue": "In ICDM, pp", "citeRegEx": "Zadrozny et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Zadrozny et al\\.", "year": 2003}], "referenceMentions": [{"referenceID": 27, "context": "In a movie recommendation system, for example, users typically watch and rate those movies that they like, and rarely rate movies that they do not like (Pradel et al., 2012).", "startOffset": 152, "endOffset": 173}, {"referenceID": 6, "context": "First, we show how estimating the quality of a recommendation system can be approached with propensity-weighting techniques commonly used in causal inference (Imbens & Rubin, 2015), complete-cases analysis (Little & Rubin, 2002), and other problems (Cortes et al., 2008; Bickel et al., 2009; Sugiyama & Kawanabe, 2012).", "startOffset": 249, "endOffset": 318}, {"referenceID": 3, "context": "First, we show how estimating the quality of a recommendation system can be approached with propensity-weighting techniques commonly used in causal inference (Imbens & Rubin, 2015), complete-cases analysis (Little & Rubin, 2002), and other problems (Cortes et al., 2008; Bickel et al., 2009; Sugiyama & Kawanabe, 2012).", "startOffset": 249, "endOffset": 318}, {"referenceID": 1, "context": "standard estimators commonly used in the past (Bell et al., 2007).", "startOffset": 46, "endOffset": 65}, {"referenceID": 12, "context": "For the task of learning recommender systems, we show that our new matrix factorization method substantially outperforms methods that ignore selection bias, as well as existing state-of-the-art methods that perform jointlikelihood inference under MNAR data (Hern\u00e1ndez-Lobato et al., 2014).", "startOffset": 257, "endOffset": 288}, {"referenceID": 25, "context": "Past work that explicitly dealt with the MNAR nature of recommendation data approached the problem as missingdata imputation based on the joint likelihood of the missing data model and the rating model (Marlin et al., 2007; Marlin & Zemel, 2009; Hern\u00e1ndez-Lobato et al., 2014).", "startOffset": 202, "endOffset": 276}, {"referenceID": 12, "context": "Past work that explicitly dealt with the MNAR nature of recommendation data approached the problem as missingdata imputation based on the joint likelihood of the missing data model and the rating model (Marlin et al., 2007; Marlin & Zemel, 2009; Hern\u00e1ndez-Lobato et al., 2014).", "startOffset": 202, "endOffset": 276}, {"referenceID": 12, "context": "We empirically compare against the state-of-the-art joint likelihood model (Hern\u00e1ndez-Lobato et al., 2014) in this paper.", "startOffset": 75, "endOffset": 106}, {"referenceID": 15, "context": "Related but different from the problem we consider is recommendation from positive feedback alone (Hu et al., 2008; Dawen Liang & Blei, 2016).", "startOffset": 98, "endOffset": 141}, {"referenceID": 21, "context": "Alternative approaches to learning with MNAR data (Steck, 2010; Lim et al., 2015) aim to avoid the problem by considering performance measures less affected by selection bias.", "startOffset": 50, "endOffset": 81}, {"referenceID": 3, "context": "Weighting approaches are also widely used in domain adaptation and covariate shift, where data from one source is used to train for a different problem (e.g., Huang et al., 2006; Bickel et al., 2009; Sugiyama & Kawanabe, 2012).", "startOffset": 152, "endOffset": 226}, {"referenceID": 6, "context": "We will draw upon this work, especially the learning theory related to weighting approaches in (Cortes et al., 2008; 2010).", "startOffset": 95, "endOffset": 122}, {"referenceID": 0, "context": "Hence, we are faced with the following counterfactual question: how well would our users have enjoyed themselves (in terms of CG), if they had followed our recommendations \u0176 instead of watching the movies indicated in O? Note that rankings of recommendations are similar to the set-based recommendation described above, and measures like Discounted Cumulative Gain (DCG), DCG@k, Precision at k (PREC@k), and others (Aslam et al., 2006; Yilmaz et al., 2008) also fit in this setting.", "startOffset": 415, "endOffset": 456}, {"referenceID": 39, "context": "Hence, we are faced with the following counterfactual question: how well would our users have enjoyed themselves (in terms of CG), if they had followed our recommendations \u0176 instead of watching the movies indicated in O? Note that rankings of recommendations are similar to the set-based recommendation described above, and measures like Discounted Cumulative Gain (DCG), DCG@k, Precision at k (PREC@k), and others (Aslam et al., 2006; Yilmaz et al., 2008) also fit in this setting.", "startOffset": 415, "endOffset": 456}, {"referenceID": 20, "context": "The key to getting unbiased counterfactual estimates of recommendation quality despite missing observations lies in the following connection to estimating average treatment effects of a given policy in causal inference, already explored in the contextual bandit setting (Li et al., 2011; Dud\u0131\u0301k et al., 2011).", "startOffset": 270, "endOffset": 308}, {"referenceID": 10, "context": "The key to getting unbiased counterfactual estimates of recommendation quality despite missing observations lies in the following connection to estimating average treatment effects of a given policy in causal inference, already explored in the contextual bandit setting (Li et al., 2011; Dud\u0131\u0301k et al., 2011).", "startOffset": 270, "endOffset": 308}, {"referenceID": 41, "context": "Empirical Risk Minimization underlies many successful learning algorithms like SVMs (Cortes & Vapnik, 1995), Boosting (Schapire, 1990), and Deep Networks (Bengio, 2009), and weighted ERM approaches have been effective for cost-sensitive classification, domain adaptation and covariate shift (Zadrozny et al., 2003; Bickel et al., 2009; Sugiyama & Kawanabe, 2012).", "startOffset": 291, "endOffset": 362}, {"referenceID": 3, "context": "Empirical Risk Minimization underlies many successful learning algorithms like SVMs (Cortes & Vapnik, 1995), Boosting (Schapire, 1990), and Deep Networks (Bengio, 2009), and weighted ERM approaches have been effective for cost-sensitive classification, domain adaptation and covariate shift (Zadrozny et al., 2003; Bickel et al., 2009; Sugiyama & Kawanabe, 2012).", "startOffset": 291, "endOffset": 362}, {"referenceID": 6, "context": "To illustrate the validity of the propensity-scored ERM approach, we state the following generalization error bound (proof in appendix) similar to Cortes et al. (2010). We consider only finiteH for the sake of conciseness.", "startOffset": 147, "endOffset": 168}, {"referenceID": 15, "context": "Except for the propensities Pu,i that act like weights for each loss term, the training objective is identical to the standard incomplete matrix factorization objective (Koren, 2008; Steck, 2010; Hu et al., 2008) with MSE (3) or MAE (2).", "startOffset": 169, "endOffset": 212}, {"referenceID": 40, "context": "This means that we can readily draw upon the existing arsenal of optimization algorithms (i.e., Gemulla et al., 2011; Yu et al., 2012), making the training problem highly scalable.", "startOffset": 89, "endOffset": 134}, {"referenceID": 4, "context": "For the experiments reported in this paper, we use Limited-memory BFGS (Byrd et al., 1995).", "startOffset": 71, "endOffset": 90}, {"referenceID": 18, "context": "Solving this training objective for other \u03b4u,i(Y, \u0176 ) that are non-differentiable is more challenging, but possible avenues exist (Joachims, 2005; Chapelle & Wu, 2010).", "startOffset": 130, "endOffset": 167}, {"referenceID": 26, "context": ", McCaffrey et al., 2004) In our first approach to estimating P (O|X,Xhid, Y ), we assume that dependencies from covariates X and X and other ratings are negligible, reducing the model to P (Ou,i|Yu,i) similar to Marlin & Zemel (2009). Note that we can treat Yu,i as observed, since we only need to know the propensity for observed entries to compute IPS and SNIPS.", "startOffset": 2, "endOffset": 235}, {"referenceID": 14, "context": "This effect is known, partly because the estimated propensities can provide an effect akin to stratification (Hirano et al., 2003; Wooldridge, 2007).", "startOffset": 109, "endOffset": 148}, {"referenceID": 38, "context": "This effect is known, partly because the estimated propensities can provide an effect akin to stratification (Hirano et al., 2003; Wooldridge, 2007).", "startOffset": 109, "endOffset": 148}, {"referenceID": 12, "context": "Table 2 shows that our propensity-scored matrix factorization MF-IPS with learnt propensities substantially and significantly outperforms the conventional matrix factorization approach, as well as the Bayesian imputation models from (Hern\u00e1ndez-Lobato et al., 2014), abbreviated as HL-MNAR and HL-MAR (paired t-test, p < 0.", "startOffset": 233, "endOffset": 264}, {"referenceID": 12, "context": "Note that our performance numbers for HL on Yahoo closely match the values reported in (Hern\u00e1ndez-Lobato et al., 2014).", "startOffset": 87, "endOffset": 118}, {"referenceID": 12, "context": "Table 2 shows that our propensity-scored matrix factorization MF-IPS with learnt propensities substantially and significantly outperforms the conventional matrix factorization approach, as well as the Bayesian imputation models from (Hern\u00e1ndez-Lobato et al., 2014), abbreviated as HL-MNAR and HL-MAR (paired t-test, p < 0.001 for all). This holds for both MAE and MSE. Furthermore, the performance of MF-IPS beats the best published results for Yahoo in terms of MSE (1.115) and is close in terms of MAE (0.770) (the CTP-v model of (Marlin & Zemel, 2009) as reported in the supplementary material of Hern\u00e1ndezLobato et al. (2014)).", "startOffset": 234, "endOffset": 630}, {"referenceID": 33, "context": "Furthermore, note that there are several promising directions for further improving performance, like propensity clipping (Strehl et al., 2010), doubly-robust estimation (Dud\u0131\u0301k et al.", "startOffset": 122, "endOffset": 143}, {"referenceID": 10, "context": ", 2010), doubly-robust estimation (Dud\u0131\u0301k et al., 2011), and the use of improved methods for propensity estimation (McCaffrey et al.", "startOffset": 34, "endOffset": 55}, {"referenceID": 26, "context": ", 2011), and the use of improved methods for propensity estimation (McCaffrey et al., 2004).", "startOffset": 67, "endOffset": 91}], "year": 2017, "abstractText": "Most data for evaluating and training recommender systems is subject to selection biases, either through self-selection by the users or through the actions of the recommendation system itself. In this paper, we provide a principled approach to handling selection biases, adapting models and estimation techniques from causal inference. The approach leads to unbiased performance estimators despite biased data, and to a matrix factorization method that provides substantially improved prediction performance on real-world data. We theoretically and empirically characterize the robustness of the approach, finding that it is highly practical and scalable.", "creator": "LaTeX with hyperref package"}}}