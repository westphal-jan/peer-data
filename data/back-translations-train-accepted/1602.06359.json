{"id": "1602.06359", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Feb-2016", "title": "Text Matching as Image Recognition", "abstract": "Matching two texts is a fundamental problem in many natural language processing tasks. An effective way is to extract meaningful matching patterns from words, phrases, and sentences to produce the matching score. Inspired by the success of convolutional neural network in image recognition, where neurons can capture many complicated patterns based on the extracted elementary visual patterns such as oriented edges and corners, we propose to model text matching as the problem of image recognition. Firstly, a matching matrix whose entries represent the similarities between words is constructed and viewed as an image. Then a convolutional neural network is utilized to capture rich matching patterns in a layer-by-layer way. We show that by resembling the compositional hierarchies of patterns in image recognition, our model can successfully identify salient signals such as n-gram and n-term matchings. Experimental results demonstrate its superiority against the baselines.", "histories": [["v1", "Sat, 20 Feb 2016 02:55:11 GMT  (595kb,D)", "http://arxiv.org/abs/1602.06359v1", "Accepted by AAAI-2016"]], "COMMENTS": "Accepted by AAAI-2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["liang pang", "yanyan lan", "jiafeng guo", "jun xu", "shengxian wan", "xueqi cheng"], "accepted": true, "id": "1602.06359"}, "pdf": {"name": "1602.06359.pdf", "metadata": {"source": "CRF", "title": "Text Matching as Image Recognition", "authors": ["Liang Pang", "Yanyan Lan", "Jiafeng Guo", "Jun Xu", "Shengxian Wan", "Xueqi Cheng"], "emails": ["pangliang@software.ict.ac.cn,", "wanshengxian@software.ict.ac.cn,", "lanyanyan@ict.ac.cn", "guojiafeng@ict.ac.cn", "junxu@ict.ac.cn", "cxq@ict.ac.cn"], "sections": [{"heading": "Introduction", "text": "Agreement between two texts is central to many applications of natural language, such as machine translation (Brown et al. 1993), question and answer (Xue, Jeon, and Croft 2008), paraphrase identification (Socher et al. 2011), and document recovery (Li and Xu 2014). For two texts, T1 = (w1, w2,.., wm) and T2 = (v1, v2,.., vn), the degree of agreement is typically measured as a score generated by a scoring function on the representation of each text: Match (T1, T2) = F (\u03a6 (T1), \u03a6 (T2), (1), where wi and vj denote the i-th word in T1 and T2, respectively. \u2022 is a function for assigning each text to a vector, and F is the scoring function for modelling the interactions between them."}, {"heading": "T1 : Down the ages noodles and dumplings were famous", "text": "Copyright c \u00a9 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved."}, {"heading": "T2 : Down the ages dumplings and noodles were popular in", "text": "We see that the interaction structures are of different levels, from words, phrases to sentences. First, there are many word-level matching signals, including the identical word matching between \"bottom\" in T1 and \"bottom\" in T2, and a similar word matching between \"famous\" in T1 and \"popular\" in T2. These signals compose the level matching between \"bottom\" in T1 and \"bottom\" in T2, the disordered n-term matching between \"noodles and dumplings and noodles\" in T2, and semantic n-term matching between \"famous Chinese foods\" in T2 and \"were popular in T2.\" They form sentence matching signals that are crucial for determining the appropriate degree of T1 and T2."}, {"heading": "Motivation", "text": "It has been widely recognized that a good matching decision requires taking into account the rich interaction structures in the text matching process, from word interactions to different matching patterns in phrases and whole sentences. Taking the above two sentences as an example, the interaction structures of different levels, as shown in Figure 1. Word Level Matching Signals point to matches between words in the two texts, including not only identical word comparisons such as \"down-down,\" \"age-ages,\" \"noodles-noodles,\" \"and-and-and,\" \"noplings-dumplings,\" and \"were,\" but also similar word comparisons such as \"chinese-china-china.\" Phrase matching matching signals refer to matching signals between phrase signals that refer to the phrase matching level of phrase signals (including term-gram and n)."}, {"heading": "MatchPyramid", "text": "In this section, we introduce a new, in-depth architecture for text comparisons, MatchPyramid. The basic idea is to model text comparisons as image recognition by taking the matching matrix as an image, as shown in Figure 3."}, {"heading": "Matching Matrix: Bridging the Gap between Text Matching and Image Recognition", "text": "As discussed above, a difficult problem lies in the modeling of text matches as image recognition in the different representations of text and image: the former are two 1D (onedimensional) word sequences, while the latter is typically a 2D pixel grid. To solve this problem, we represent the input of text matches as a matrix M, where each element Mij represents the basic interaction, i.e. similarity between word wi and vj (see Equation. 2). In this way, we can consider the matrix M as an image, where each entry (i.e. the similarity between two words) represents the i-th and j-th words in two texts, and represents a general operator for achieving similarity."}, {"heading": "Hierarchical Convolution: A Way to Capture Rich Matching Patterns", "text": "For the first level of CNN, the k-th kernel scans w (1, k) across the entire matrix z (0) = M to generate a function board z (1, k): z (1, k) i, j = \u03c3 (rk \u2212 1 s = 0 rk \u2212 1 x t = 0 w (1, k) s, t \u00b7 z (0) i + s, j + t + b (1, k))), (6), where rk denotes the size of the k-th kernel. In this paper, we use square kernels and ReLU (Dahl, Sainath and Hinton 2013) is assumed to be an active function. Dynamic recognition strategy (Socher et al. 2011) is used to deal with the variability of the text length."}, {"heading": "Matching Score and Training", "text": "We use a MLP (Multi-Layer Perception) to generate the final matching score. If we take, for example, the binary classification and the two-layer perceptron, we obtain a two-dimensional matching score vector: (s0, s1) > = W2\u03c3 (W1z + b1) + b2, (10) where s0 and s1 are the matching scores of the corresponding class, z is the output of the hierarchical convolution, Wi is the weight of the i-th MLP layer and \u03c3 denotes the activation function. The Softmax function is used to output the probability of belonging to each class, and cross-entropy is used as an objective function for training. Therefore, we take the matrix with indicator function as an example, similar observations can be obtained for other matrix with cosine similarity and dot product."}, {"heading": "Experiments", "text": "In this section, we conduct experiments on two tasks, namely paraphrase identification and paper quotation matching, to demonstrate the superiority of MatchPyramid over baselines."}, {"heading": "Competitor Methods and Experimental Settings", "text": "In fact, most people are able to survive on their own without having to move to another world."}, {"heading": "T1 : this article describes pulsed thermal time of flight ttof", "text": "Flow sensor system as two subsystems pulsed wire system and heat flow system, the entire flow sensor is theoretically considered linear."}, {"heading": "T2 : the authors report on novel linear time invariant lti", "text": "We can see that the matching should take into account both lexical and semantic information here. Collected from a commercial academic website, the data set contains a total of 838,908 instances (pairs of text), where there are 279,636 positive (matched) instances and 559 272 negative (incongruence) instances. Negative instances are randomly sampled papers that have no citation relationships. We divide the entire data set into three parts, 599 196 instances for training, 119 829 for validation and 119 883 for testing. The results in Table 2 show that TF-IDF is also a strong baseline on this data set, which is even better than some deep models such as DSSM and CDSSM. This can be achieved by the large difference between the test data (paper citation data) and the training data (clicks through DSM-SARC results)."}, {"heading": "Related Work", "text": "Most previous work on text matching attempts to find good representations for a single text, and generally uses a simple scoring function to get the appropriate results. Examples include Partly Least Square (Wu, Li, and Xu 2013), Canonical Correlation Analysis (Hardoon and Shawe-Taylor 2003), and some deep models such as DSSM (Huang et al. 2013), CDSSM (Gao et al. 2014; Shen et al. 2014) and ARC-I (Hu et al. 2014). Recently, a brand new approach to modeling the interaction between two sets has been proposed and received much attention, examples being DEEPMATCH (Lu and Li 2013), URAE et al. 2011) and ARC-II (Hu et al. 2014). Our model falls into this category, so we give some detailed discussions about the differences of our model against these methods."}, {"heading": "Conclusion", "text": "In this paper, we consider text comparison as image recognition and propose a new deep architecture, MatchPyramid. Our model can automatically capture important matching patterns such as unicam, n-gram, and n-term at various levels. Experimental results show that our model can surpass baselines, including some recently proposed deep matching algorithms."}, {"heading": "Acknowledgments", "text": "This work was funded by the 973 Program of China under grant numbers 2014CB340401 and 2012CB316303, the 863 Program of China under grant numbers 2014AA015204, the National Natural Science Foundation of China (NSFC) under grant numbers 61472401, 61433014, 61425016, 61425016 and 61203298, the Key Research Program of the Chinese Academy of Sciences under grant numbers KGZD-EW-T03-2 and the Youth Innovation Promotion Association CAS under grant numbers 20144310."}], "references": [{"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Brown"], "venue": null, "citeRegEx": "Brown,? \\Q1993\\E", "shortCiteRegEx": "Brown", "year": 1993}, {"title": "Improving deep neural networks for lvcsr using rectified linear units and dropout", "author": ["Sainath Dahl", "G.E. Hinton 2013] Dahl", "T.N. Sainath", "G.E. Hinton"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Dahl et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dahl et al\\.", "year": 2013}, {"title": "Automatically constructing a corpus of sentential paraphrases", "author": ["Dolan", "W.B. Brockett 2005] Dolan", "C. Brockett"], "venue": "In Proc. of IWP", "citeRegEx": "Dolan et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Dolan et al\\.", "year": 2005}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Hazan Duchi", "J. Singer 2011] Duchi", "E. Hazan", "Y. Singer"], "venue": "The Journal of Machine Learning Research 12:2121\u20132159", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Modeling interestingness with deep neural networks", "author": ["Gao"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Gao,? \\Q2014\\E", "shortCiteRegEx": "Gao", "year": 2014}, {"title": "Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping", "author": ["L.R.C.S. L"], "venue": "[Giles", "citeRegEx": "L.,? \\Q2001\\E", "shortCiteRegEx": "L.", "year": 2001}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Girshick"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Girshick,? \\Q2014\\E", "shortCiteRegEx": "Girshick", "year": 2014}, {"title": "Kcca for different level precision in content-based image retrieval", "author": ["Hardoon", "D.R. Shawe-Taylor 2003] Hardoon", "J. Shawe-Taylor"], "venue": "In Proceedings of Third International Workshop on Content-Based Multimedia Indexing,", "citeRegEx": "Hardoon et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Hardoon et al\\.", "year": 2003}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Hinton"], "venue": "CoRR abs/1207.0580", "citeRegEx": "Hinton,? \\Q2012\\E", "shortCiteRegEx": "Hinton", "year": 2012}, {"title": "Convolutional neural network architectures for matching natural language sentences", "author": ["Hu"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hu,? \\Q2014\\E", "shortCiteRegEx": "Hu", "year": 2014}, {"title": "Learning deep structured semantic models for web search using clickthrough data", "author": ["Huang"], "venue": "In Proceedings of the 22nd ACM international conference on Conference on Information and Knowledge Management,", "citeRegEx": "Huang,? \\Q2013\\E", "shortCiteRegEx": "Huang", "year": 2013}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Jia"], "venue": "arXiv preprint arXiv:1408.5093", "citeRegEx": "Jia,? \\Q2014\\E", "shortCiteRegEx": "Jia", "year": 2014}, {"title": "A convolutional neural network for modelling sentences", "author": ["Grefenstette Kalchbrenner", "N. Blunsom 2014] Kalchbrenner", "E. Grefenstette", "P. Blunsom"], "venue": "CoRR abs/1404.2188", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Gradient-based learning applied to document recognition", "author": ["LeCun"], "venue": "Proceedings of the IEEE", "citeRegEx": "LeCun,? \\Q1998\\E", "shortCiteRegEx": "LeCun", "year": 1998}, {"title": "Semantic matching in search. Foundations and Trends in Information Retrieval 7(5):343\u2013469", "author": ["Li", "H. Xu 2014] Li", "J. Xu"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "A deep architecture for matching short texts", "author": ["Lu", "Z. Li 2013] Lu", "H. Li"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Lu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2013}, {"title": "Efficient estimation of word representations in vector space. CoRR abs/1301.3781", "author": ["Mikolov"], "venue": null, "citeRegEx": "Mikolov,? \\Q2013\\E", "shortCiteRegEx": "Mikolov", "year": 2013}, {"title": "Extended boolean information retrieval. Communications of the ACM 26(11):1022\u20131036", "author": ["Fox Salton", "G. Wu 1983] Salton", "E.A. Fox", "H. Wu"], "venue": null, "citeRegEx": "Salton et al\\.,? \\Q1983\\E", "shortCiteRegEx": "Salton et al\\.", "year": 1983}, {"title": "A latent semantic model with convolutionalpooling structure for information retrieval", "author": ["Shen"], "venue": "In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,", "citeRegEx": "Shen,? \\Q2014\\E", "shortCiteRegEx": "Shen", "year": 2014}, {"title": "Best practices for convolutional neural networks applied to visual document analysis", "author": ["Steinkraus Simard", "P.Y. Platt 2003] Simard", "D. Steinkraus", "J.C. Platt"], "venue": "In 2013 12th International Conference on Document Analysis and Recognition,", "citeRegEx": "Simard et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Simard et al\\.", "year": 2003}, {"title": "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection", "author": ["Socher"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Socher,? \\Q2011\\E", "shortCiteRegEx": "Socher", "year": 2011}, {"title": "Learning representations by backpropagating errors", "author": ["Williams", "Hinton 1986] Williams", "D.R.G.H. R", "G. Hinton"], "venue": "Nature", "citeRegEx": "Williams et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Williams et al\\.", "year": 1986}, {"title": "Learning query and document similarities from click-through bipartite graph with metadata", "author": ["Li Wu", "W. Xu 2013] Wu", "H. Li", "J. Xu"], "venue": "In Proceedings of the sixth ACM international conference on WSDM,", "citeRegEx": "Wu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2013}, {"title": "Retrieval models for question and answer archives", "author": ["Jeon Xue", "X. Croft 2008] Xue", "J. Jeon", "W.B. Croft"], "venue": "In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Xue et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2008}, {"title": "Visualizing and understanding convolutional networks", "author": ["Zeiler", "M.D. Fergus 2014] Zeiler", "R. Fergus"], "venue": "In Computer Vision\u2013ECCV", "citeRegEx": "Zeiler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2014}], "referenceMentions": [], "year": 2016, "abstractText": "Matching two texts is a fundamental problem in many natural language processing tasks. An effective way is to extract meaningful matching patterns from words, phrases, and sentences to produce the matching score. Inspired by the success of convolutional neural network in image recognition, where neurons can capture many complicated patterns based on the extracted elementary visual patterns such as oriented edges and corners, we propose to model text matching as the problem of image recognition. Firstly, a matching matrix whose entries represent the similarities between words is constructed and viewed as an image. Then a convolutional neural network is utilized to capture rich matching patterns in a layer-by-layer way. We show that by resembling the compositional hierarchies of patterns in image recognition, our model can successfully identify salient signals such as n-gram and n-term matchings. Experimental results demonstrate its superiority against the baselines.", "creator": "LaTeX with hyperref package"}}}