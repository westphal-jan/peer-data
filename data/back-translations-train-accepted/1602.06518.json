{"id": "1602.06518", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Feb-2016", "title": "Multi-task Learning with Labeled and Unlabeled Tasks", "abstract": "In this paper we consider the problem of multi-task learning, in which a learner is given a collection of prediction tasks that need to be solved. In contrast to previous work, we give up on the assumption that labeled training data is available for all tasks. Instead, we propose an active task selection framework, where based only on the unlabeled data, the learner can choose a, typically small, subset of tasks for which he gets some labeled examples. For the remaining tasks, which have no available annotation, solutions are found by transferring information from the selected tasks. We analyze two transfer strategies and develop generalization bounds for each of them. Based on this theoretical analysis we propose two algorithms for making the choice of labeled tasks in a principled way and show their effectiveness on synthetic and real data.", "histories": [["v1", "Sun, 21 Feb 2016 11:18:10 GMT  (73kb,D)", "http://arxiv.org/abs/1602.06518v1", null], ["v2", "Wed, 30 Mar 2016 09:30:21 GMT  (73kb,D)", "http://arxiv.org/abs/1602.06518v2", null], ["v3", "Wed, 1 Mar 2017 12:22:56 GMT  (1705kb,D)", "http://arxiv.org/abs/1602.06518v3", null], ["v4", "Thu, 8 Jun 2017 09:14:03 GMT  (1706kb,D)", "http://arxiv.org/abs/1602.06518v4", null]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["anastasia pentina", "christoph h lampert"], "accepted": true, "id": "1602.06518"}, "pdf": {"name": "1602.06518.pdf", "metadata": {"source": "CRF", "title": "Active Task Selection for Multi-Task Learning", "authors": ["Anastasia Pentina", "Christoph H. Lampert"], "emails": ["apentina@ist.ac.at", "chl@ist.ac.at"], "sections": [{"heading": "1 Introduction", "text": "rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "2 Related Work", "text": "Most existing multi-task learning methods operate in a fully monitored environment and are therefore based on the idea of improving the overall prediction quality by exchanging information between tasks, either assuming that the predictors for all tasks are similar to each other in some standard, and exploiting this fact by specific regulators [9], or assuming that the predictors for all tasks share a common low-dimensional representation that can be learned from the data [8, 1]. Subsequent work expands and generalizes these concepts, e.g. learning the relationships of tasks [25, 12] or dividing only between subgroups of tasks [30, 13, 3]. However, all of the above methods require labeled data for each task, because they correlate tasks with their predictions. Active learning has not yet found widespread use in the multi-task environment. Two works along these lines are [21, 24] but do not include active learning at the training level."}, {"heading": "3 Preliminaries", "text": "Before going into the details of our paper, we will introduce some notations and reintroduce some key definitions and results from the multi-domain and domain matching literature."}, {"heading": "3.1 Formal setting", "text": "Formally, we assume that there are a number of T tasks {< D1, f1 >,.., < DT, fT >} in which each task t is defined by a boundary distribution Dt over the entrance space X and a deterministic labeling function ft: X \u2192 Y. The goal of the learner is to find T predictors h1,.., hT in a hypothesis that would minimize the average expected risk: he (h1,., hT) = 1T T T-HT = 1 ert (ht), (1) where ert (ht) = E x-Dt '(ht (x), ft (x). In this work, we focus on the case of binary tasks, Y = {\u2212 1}, and 0 / 1 loss,. \""}, {"heading": "3.2 Background on domain adaptation", "text": "The success of such a method depends on how similar the source is to the object. The discrepancy between distributions D1 and D2 over X in relation to a hypothesis that we consider in this paper to be a reasonable measure of similarity results from the concept of discrepancy: Definition 1 (definition 4 in [14]). The discrepancy between distributions D1 and D2 over X in relation to a hypothesis H is defined as: disk (D1, D2) = max h, h \"disk (h, h) \u2212 erD2 (h, h\") | 2), where erDi (h, h \") = Ex\" Di \"(h), h\" disk (x), h \"disk (x). This measure has two advantages: 1. The discrepancy allows to relate the performance of a hypothesis to a problem."}, {"heading": "4 Transfer from a single task", "text": "Probably the simplest method that can be applied in unattended areas is the number of tasks based on the examples of the source task described. (In this section, we will examine what would be the optimal choice of the described tasks if this transfer method is used to learn the remaining tasks (Figure 1). We assume that based on the blank data, the learner selects k tasks and assigns each of the remaining blank tasks to one of them. (Figure 1) We encode such a task with a vector C = (c1,., cT) that corresponds to most of the different components of the selected described tasks and specifies which of them will be used as the source of information for the t-th task."}, {"heading": "5 Transfer from multiple tasks", "text": "In the previous section, we assumed that the learner would use only one of the selected tasks as the source of information for each task. (However, this is not the only solution, as only one of them can be used for the selected tasks according to the labels.) In addition, it might be advantageous to transfer information from the other named task as source code. To take advantage of this possibility, we consider an extension of the method described in the previous section in the case of multiple sources. Instead of training a classifier for the target domain, this method minimizes a combination of training errors in multiple source domains. For a series of tasks I = {i1,."}, {"heading": "6 Experiments", "text": "In both cases, we are dealing with a series of excesses that are proving to be insufficient, both in terms of the way in which we select the individual tasks, and in terms of the way in which we select the individual tasks, and in terms of the way in which we select the individual tasks. (...) The other points we choose are in the way in which we select them, in the way in which we select them. (...) We have the same selection results, in the way in which we select them, in the way in which we perform them. (...) We have the same and in the way in which we choose them. \""}, {"heading": "7 Conclusion", "text": "In this paper, we have introduced and examined the framework for active task selection: a modification of multi-task learning inspired by the active learning paradigm. While at first all tasks are represented only by unmarked training samples, the learner decides on a budget which tasks are of interest to query labels and solves the remaining tasks only on the basis of their unmarked data and information transferred from the selected tasks. We analysed this framework for two domain adaptation methods and established generalisation limits that can be used to make the selection of the labelled tasks in principle. We also provided an empirical evaluation showing the advantages of the proposed methods. In future work, we plan to further exploit the idea of active learning in application to the multi-task environment. In particular, we are interested in seeing if the learner is allowed to decide which tasks to mark iteratively rather than forcing him to choose all tasks at the same time, to obtain better learning methods and to guarantee more effective learning."}, {"heading": "Acknowledgments", "text": "The authors thank Marius Kloft for the helpful discussions. This work was partly funded by the European Research Council under the Seventh Framework Programme of the European Union (FP7 / 2007-2013) / ERC Funding Agreement No. 308036. A Tesla K40 card used for this research was donated by NVIDIA Corporation."}, {"heading": "A Technical Lemmas", "text": "Using a union argument, we generalize statement 2 for all T (T \u2212 1) / 2 discrepancies occurring in pairs at the same time: Korollary 1. Leave d the VC dimension of the hypothesis class H, D1,.., DT simultaneously for all i, j = 1,.., T: Disc (Di, Dj) \u2264 f Disc (Si, Sj) + 2 x sequence (2n) + 2 protocol (T) + protocol (2 / 3) simultaneously for all i, j = 1,.,., T: Disc (Di, Dj) \u2264 f Disc (Si, Sj) + 2 x sequence (2n) + protocol (2 / 3) Lemma 1 (Lemma 1 (Corollary 3.4 in [17]). Let d set the VC dimension of the hypothesis H and S a random sample."}, {"heading": "B Proof of Theorem 1", "text": "Firstly, we note that for each I = {i1,.., ik}, each c = (c1,.., cT) and each (hi) i-I the following sequence of sentence 1 applies: 1T \u2211 t = 1 ert (hct) \u2264 1 T \u2211 t = 1 erct (hct) + 1 T \u2211 t = 1 disk (Dt, Dct) + 1 T \u2211 t = 1 \u03bbtct. (24) Next, we have bound the expected error terms on the right side by their empirical equivalents. To do this, we apply a union-related argument to Lemma 1 and get it with probability at the same time for all i = 1,.., T and all hi-H terms the following inequality applies: eri (hi) \u2264 e-ri (hi) \u2264 d-findings (em / d) + \u00b2 d-findings (m / d) m + ampling (T) + log (2 / g) 2m, (25) to tie the discrepancy, discretion, discretion, discretion, discretion (hi) \u2264 e-ri (hi), discretion (2), hi () (hi), (2), (c1) and (hi)."}, {"heading": "C Proof of Theorem 2", "text": "As proof of Theorem 1, we have the multiple task error due to errors in the source tasks and the transition to empirical quantities while maintaining the effect of random sampling control. However, the steps are more involved, as we now require that the boundaries be uniform in the (continuous) weight classes, so that we cannot rely on simple unit boundaries. For the first step, we note the following result (inspired by Theorem 4 in [4]): Lemma 6. Let < D1, t1 >,. < DT > be T > be T tasks and I = {i1,., ik}. Then applies to each t = 1,.,."}], "references": [{"title": "Convex multi-task feature learning", "author": ["Andreas Argyriou", "Theodoros Evgeniou", "Massimiliano Pontil"], "venue": "Machine Learning (ML),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2008}, {"title": "Greedy sparsity-constrained optimization", "author": ["Sohail Bahmani", "Bhiksha Raj", "Petros T. Boufounos"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Convex multi-task learning by clustering", "author": ["Aviad Barzilai", "Koby Crammer"], "venue": "In Conference on Uncertainty in Artificial Intelligence (AISTATS),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "A theory of learning from different domains", "author": ["Shai Ben-David", "John Blitzer", "Koby Crammer", "Alex Kulesza", "Fernando Pereira", "Jennifer Wortman Vaughan"], "venue": "Machine Learning (ML),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Analysis of representations for domain adaptation", "author": ["Shai Ben-David", "John Blitzer", "Koby Crammer", "Fernando Pereira"], "venue": "In Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Regularity properties of certain families of chance variables", "author": ["Joseph L Doob"], "venue": "Transactions of the American Mathematical Society,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1940}, {"title": "Transductive Rademacher complexity and its applications", "author": ["Ran El-Yaniv", "Dmitry Pechyony"], "venue": "In Workshop on Computational Learning Theory (COLT),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2007}, {"title": "Multi-task feature learning", "author": ["A Evgeniou", "Massimiliano Pontil"], "venue": "In Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2007}, {"title": "Regularized multi-task learning", "author": ["Theodoros Evgeniou", "Massimiliano Pontil"], "venue": "In International Conference on Knowledge Discovery and Data Mining (SIGKDD),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2004}, {"title": "Domain adaptation for large-scale sentiment classification: A deep learning approach", "author": ["Xavier Glorot", "Antoine Bordes", "Yoshua Bengio"], "venue": "In International Conference on Machine Learing (ICML),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Probability inequalities for sums of bounded random variables", "author": ["Wassily Hoeffding"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1963}, {"title": "Learning with whom to share in multi-task feature learning", "author": ["Zhuoliang Kang", "Kristen Grauman", "Fei Sha"], "venue": "In International Conference on Machine Learing (ICML),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2011}, {"title": "Learning task grouping and overlap in multi-task learning", "author": ["Abhishek Kumar", "Hal Daum\u00e9 III"], "venue": "In International Conference on Machine Learing (ICML),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Domain adaptation: Learning bounds and algorithms", "author": ["Yishay Mansour", "Mehryar Mohri", "Afshin Rostamizadeh"], "venue": "In Workshop on Computational Learning Theory (COLT),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Concentration inequalities for functions of independent variables", "author": ["Andreas Maurer"], "venue": "Random Structures and Algorithms,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "On the method of bounded differences", "author": ["C. McDiarmid"], "venue": "In Surveys in Combinatorics", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1989}, {"title": "Foundations of Machine Learning", "author": ["Mehryar Mohri", "Afshin Rostamizadeh", "Ameet Talwalkar"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2012}, {"title": "Domain adaptation via transfer component analysis", "author": ["Sinno Jialin Pan", "Ivor W Tsang", "James T Kwok", "Qiang Yang"], "venue": "IEEE Transactions on Neural Networks (T-NN),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "A simple and fast algorithm for k-medoids clustering", "author": ["Hae-Sang Park", "Chi-Hyuck Jun"], "venue": "Expert Systems with Applications,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2009}, {"title": "Curriculum learning of multiple tasks", "author": ["Anastasia Pentina", "Viktoriia Sharmanska", "Christoph H Lampert"], "venue": "In Conference on Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2015}, {"title": "Multi-task active learning for linguistic annotations", "author": ["Roi Reichart", "Katrin Tomanek", "Udo Hahn", "Ari Rappoport"], "venue": "In Conference of the Association for Computational Linguistics (ACL),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "ImageNet large scale visual recognition challenge", "author": ["Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein", "Alexander C. Berg", "Li Fei-Fei"], "venue": "International Journal of Computer Vision (IJCV),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "Active task selection for lifelong machine learning", "author": ["Paul Ruvolo", "Eric Eaton"], "venue": "In Conference on Artificial Intelligence (AAAI),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Active online multitask learning", "author": ["Avishek Saha", "Piyush Rai", "Hal Daum\u00e9 III", "Suresh Venkatasubramanian"], "venue": "In ICML Workshop on Budget Learning,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Online learning of multiple tasks and their relationships", "author": ["Avishek Saha", "Piyush Rai", "Hal Daum\u00e9 III", "Suresh Venkatasubramanian"], "venue": "In Conference on Uncertainty in Artificial Intelligence (AISTATS),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Improving predictive inference under covariate shift by weighting the log-likelihood function", "author": ["Hidetoshi Shimodaira"], "venue": "Journal of Statistical Planning and Inference,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2000}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}, {"title": "Localized complexities for transductive learning", "author": ["I. Tolstikhin", "G. Blanchard", "M. Kloft"], "venue": "In Workshop on Computational Learning Theory (COLT),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2014}, {"title": "Bridged refinement for transfer learning", "author": ["Dikan Xing", "Wenyuan Dai", "Gui-Rong Xue", "Yong Yu"], "venue": "In Knowledge Discovery in Databases (PKDD),", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2007}], "referenceMentions": [{"referenceID": 13, "context": "In this paper we concentrate on two transfer methods that use the discrepancy distance [14] to quantify the similarity between unlabeled tasks.", "startOffset": 87, "endOffset": 91}, {"referenceID": 8, "context": "For this, they either assume that the predictors for all tasks are similar to each other in some norm and exploit this fact through specific regularizers [9], or they assume that the predictors for all tasks share a common low-dimensional representation that can be learned from the data [8, 1].", "startOffset": 154, "endOffset": 157}, {"referenceID": 7, "context": "For this, they either assume that the predictors for all tasks are similar to each other in some norm and exploit this fact through specific regularizers [9], or they assume that the predictors for all tasks share a common low-dimensional representation that can be learned from the data [8, 1].", "startOffset": 288, "endOffset": 294}, {"referenceID": 0, "context": "For this, they either assume that the predictors for all tasks are similar to each other in some norm and exploit this fact through specific regularizers [9], or they assume that the predictors for all tasks share a common low-dimensional representation that can be learned from the data [8, 1].", "startOffset": 288, "endOffset": 294}, {"referenceID": 24, "context": "learning the relatedness of tasks [25, 12] or sharing only between subgroups of tasks [30, 13, 3].", "startOffset": 34, "endOffset": 42}, {"referenceID": 11, "context": "learning the relatedness of tasks [25, 12] or sharing only between subgroups of tasks [30, 13, 3].", "startOffset": 34, "endOffset": 42}, {"referenceID": 12, "context": "learning the relatedness of tasks [25, 12] or sharing only between subgroups of tasks [30, 13, 3].", "startOffset": 86, "endOffset": 97}, {"referenceID": 2, "context": "learning the relatedness of tasks [25, 12] or sharing only between subgroups of tasks [30, 13, 3].", "startOffset": 86, "endOffset": 97}, {"referenceID": 20, "context": "Two works in this direction are [21, 24], which, however, use active learning on the level of training examples, not tasks.", "startOffset": 32, "endOffset": 40}, {"referenceID": 23, "context": "Two works in this direction are [21, 24], which, however, use active learning on the level of training examples, not tasks.", "startOffset": 32, "endOffset": 40}, {"referenceID": 22, "context": "The idea of choosing tasks was used in active curriculum selection [23, 20], where the learner can influence the order in which tasks are processed.", "startOffset": 67, "endOffset": 75}, {"referenceID": 19, "context": "The idea of choosing tasks was used in active curriculum selection [23, 20], where the learner can influence the order in which tasks are processed.", "startOffset": 67, "endOffset": 75}, {"referenceID": 4, "context": "To transfer information between tasks, our work builds on existing results for single-source and multi-source domain adaptation [5, 14].", "startOffset": 128, "endOffset": 135}, {"referenceID": 13, "context": "To transfer information between tasks, our work builds on existing results for single-source and multi-source domain adaptation [5, 14].", "startOffset": 128, "endOffset": 135}, {"referenceID": 25, "context": "We suspect, however, that also other domain adaptation techniques could be exploited for the active task selection scenario, in particular those based on source reweighting [26], representation learning [18, 10], or semi-supervised transfer [29].", "startOffset": 173, "endOffset": 177}, {"referenceID": 17, "context": "We suspect, however, that also other domain adaptation techniques could be exploited for the active task selection scenario, in particular those based on source reweighting [26], representation learning [18, 10], or semi-supervised transfer [29].", "startOffset": 203, "endOffset": 211}, {"referenceID": 9, "context": "We suspect, however, that also other domain adaptation techniques could be exploited for the active task selection scenario, in particular those based on source reweighting [26], representation learning [18, 10], or semi-supervised transfer [29].", "startOffset": 203, "endOffset": 211}, {"referenceID": 28, "context": "We suspect, however, that also other domain adaptation techniques could be exploited for the active task selection scenario, in particular those based on source reweighting [26], representation learning [18, 10], or semi-supervised transfer [29].", "startOffset": 241, "endOffset": 245}, {"referenceID": 13, "context": "For both methods that we consider in this work a sensible measure of similarity is provided by the notion of discrepancy: Definition 1 (Definition 4 in [14]).", "startOffset": 152, "endOffset": 156}, {"referenceID": 3, "context": "The discrepancy allows relating the performance of a hypothesis on one task to its performance on a different task: Proposition 1 (Theorem 2 in [4]).", "startOffset": 144, "endOffset": 147}, {"referenceID": 3, "context": "The discrepancy can be estimated from unlabeled samples: Proposition 2 (Lemma 1 in [4]).", "startOffset": 83, "endOffset": 86}, {"referenceID": 0, "context": ", T} define: \u039b = { \u03b1 \u2208 [0, 1] : T \u2211", "startOffset": 23, "endOffset": 29}, {"referenceID": 6, "context": "Therefore we utilize techniques from the literature on transductive learning [7] instead.", "startOffset": 77, "endOffset": 80}, {"referenceID": 15, "context": "We first apply Doob\u2019s construction to \u03a6 in order to obtain a martingale sequence and then use McDiarmid\u2019s inequality for martingales [16].", "startOffset": 133, "endOffset": 137}, {"referenceID": 27, "context": "Using results from [28] and [11] we observe that: E S1,.", "startOffset": 19, "endOffset": 23}, {"referenceID": 10, "context": "Using results from [28] and [11] we observe that: E S1,.", "startOffset": 28, "endOffset": 32}, {"referenceID": 14, "context": "The main instrument that we used here is a refined version of McDiarmid\u2019s inequality, which is due to [15].", "startOffset": 102, "endOffset": 106}, {"referenceID": 21, "context": "We use the train part of the ImageNet ILSVRC2010 dataset [22], which consists of approximately 1.", "startOffset": 57, "endOffset": 61}, {"referenceID": 26, "context": "We extract features using a deep convolutional neural network [27] that was pretrained on a different dataset (ILSVRC2012), reduce their dimension to 5 using PCA and augment them with a constant feature, resulting in d = 6.", "startOffset": 62, "endOffset": 66}, {"referenceID": 3, "context": "We estimate the empirical discrepancies between pairs of tasks (step 1 in Algorithms 1 and 2) by finding a hypothesis in H that minimizes the squared loss for the binary classification problem of separating the two sets of instances, as in [4].", "startOffset": 240, "endOffset": 243}, {"referenceID": 18, "context": "To minimize the k-medoid risk (step 2 in Algorithm 1) we perform a local search as in [19].", "startOffset": 86, "endOffset": 90}, {"referenceID": 1, "context": "For the corresponding minimization of (16) in Algorithm 2 we use the GraSP algorithm [2].", "startOffset": 85, "endOffset": 88}, {"referenceID": 0, "context": "References [1] Andreas Argyriou, Theodoros Evgeniou, and Massimiliano Pontil.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Sohail Bahmani, Bhiksha Raj, and Petros T.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Aviad Barzilai and Koby Crammer.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman Vaughan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Joseph L Doob.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Ran El-Yaniv and Dmitry Pechyony.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] A Evgeniou and Massimiliano Pontil.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Theodoros Evgeniou and Massimiliano Pontil.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Xavier Glorot, Antoine Bordes, and Yoshua Bengio.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Wassily Hoeffding.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Zhuoliang Kang, Kristen Grauman, and Fei Sha.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Abhishek Kumar and Hal Daum\u00e9 III.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] Andreas Maurer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang Yang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] Hae-Sang Park and Chi-Hyuck Jun.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] Anastasia Pentina, Viktoriia Sharmanska, and Christoph H Lampert.", "startOffset": 0, "endOffset": 4}, {"referenceID": 20, "context": "[21] Roi Reichart, Katrin Tomanek, Udo Hahn, and Ari Rappoport.", "startOffset": 0, "endOffset": 4}, {"referenceID": 21, "context": "[22] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[23] Paul Ruvolo and Eric Eaton.", "startOffset": 0, "endOffset": 4}, {"referenceID": 23, "context": "[24] Avishek Saha, Piyush Rai, Hal Daum\u00e9 III, and Suresh Venkatasubramanian.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[25] Avishek Saha, Piyush Rai, Hal Daum\u00e9 III, and Suresh Venkatasubramanian.", "startOffset": 0, "endOffset": 4}, {"referenceID": 25, "context": "[26] Hidetoshi Shimodaira.", "startOffset": 0, "endOffset": 4}, {"referenceID": 26, "context": "[27] Karen Simonyan and Andrew Zisserman.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "[28] I.", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "[29] Dikan Xing, Wenyuan Dai, Gui-Rong Xue, and Yong Yu.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "4 in [17]).", "startOffset": 5, "endOffset": 9}, {"referenceID": 15, "context": "10 in [16]).", "startOffset": 6, "endOffset": 10}, {"referenceID": 27, "context": "Lemma 3 (Part of Lemma 19 in [28]).", "startOffset": 29, "endOffset": 33}, {"referenceID": 10, "context": "Lemma 4 (Originally [11]; in this form Theorem 18 in [28]).", "startOffset": 20, "endOffset": 24}, {"referenceID": 27, "context": "Lemma 4 (Originally [11]; in this form Theorem 18 in [28]).", "startOffset": 53, "endOffset": 57}, {"referenceID": 14, "context": "Lemma 5 (Theorem 1 in [15]).", "startOffset": 22, "endOffset": 26}, {"referenceID": 3, "context": "For the first step, we establish the following result (inspired by Theorem 4 in [4]): Lemma 6.", "startOffset": 80, "endOffset": 83}, {"referenceID": 5, "context": "We now create a martingale sequence using Doob\u2019s construction [6]: Wij = E Z {\u03a6(Z)| z 11 }.", "startOffset": 62, "endOffset": 65}, {"referenceID": 6, "context": "(38) Following the path of the proof of Lemma 2 in [7] we would like to apply Lemma 2.", "startOffset": 51, "endOffset": 54}, {"referenceID": 0, "context": "(49) where for the first inequality we used that supF\u2212supG \u2264 sup(F\u2212G) for any F,G, and for the second inequality we used that ` is bounded by [0, 1].", "startOffset": 142, "endOffset": 148}, {"referenceID": 16, "context": "3 in [17]): |A| \u2264 ( ekm d )d .", "startOffset": 5, "endOffset": 9}, {"referenceID": 16, "context": "3 in [17]):", "startOffset": 5, "endOffset": 9}, {"referenceID": 14, "context": "The main ingredient is a refined version of McDiarmid\u2019s inequality, due to Maurer [15] (Lemma 5, page 12), which allows us to make use of the internal structure of the weights, \u03b1, while deriving a large deviation bound.", "startOffset": 82, "endOffset": 86}, {"referenceID": 0, "context": "where for the last inequality we use that ` is bounded in [0, 1].", "startOffset": 58, "endOffset": 64}], "year": 2017, "abstractText": "In this paper we consider the problem of multi-task learning, in which a learner is given a collection of prediction tasks that need to be solved. In contrast to previous work, we give up on the assumption that labeled training data is available for all tasks. Instead, we propose an active task selection framework, where based only on the unlabeled data, the learner can choose a, typically small, subset of tasks for which he gets some labeled examples. For the remaining tasks, which have no available annotation, solutions are found by transferring information from the selected tasks. We analyze two transfer strategies and develop generalization bounds for each of them. Based on this theoretical analysis we propose two algorithms for making the choice of labeled tasks in a principled way and show their effectiveness on synthetic and real data.", "creator": "LaTeX with hyperref package"}}}