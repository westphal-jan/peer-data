{"id": "1603.01333", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Mar-2016", "title": "Joint Learning Templates and Slots for Event Schema Induction", "abstract": "Automatic event schema induction (AESI) means to extract meta-event from raw text, in other words, to find out what types (templates) of event may exist in the raw text and what roles (slots) may exist in each event type. In this paper, we propose a joint entity-driven model to learn templates and slots simultaneously based on the constraints of templates and slots in the same sentence. In addition, the entities' semantic information is also considered for the inner connectivity of the entities. We borrow the normalized cut criteria in image segmentation to divide the entities into more accurate template clusters and slot clusters. The experiment shows that our model gains a relatively higher result than previous work.", "histories": [["v1", "Fri, 4 Mar 2016 02:15:11 GMT  (742kb)", "http://arxiv.org/abs/1603.01333v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lei sha", "sujian li", "baobao chang", "zhifang sui"], "accepted": true, "id": "1603.01333"}, "pdf": {"name": "1603.01333.pdf", "metadata": {"source": "CRF", "title": "Joint Learning Templates and Slots for Event Schema Induction", "authors": ["Lei Sha", "Sujian Li", "Baobao Chang", "Zhifang Sui"], "emails": ["szf@pku.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 160 3.01 333v 1 [cs.C L] 4M arAutomatic event schema induction (AESI) means extracting meta-event from raw text, in other words, figuring out what types (templates) of event can exist in the raw text and what roles (slots) can exist in each event type. In this paper, we propose a common, holistic model for learning templates and slots simultaneously, based on the limitations of templates and slots in the same sentence. In addition, the semantic information of the entities is also considered for the inner connectivity of the entities."}, {"heading": "1 Introduction", "text": "The event schema is a high-level representation of a series of similar events. It is very useful for traditional information extraction (IE) (Sagayam et al., 2012). An example of the event schema is in Table 1. Given the bomb schema, we just need to find the right words to fill the slots in obtaining a bomb event. There are two main approaches to the AESI task. Both use the idea of bundling the potential event arguments to find the event schema, one of which is the probable graphical model (Chambers, 2013; Cheung, 2013). By including templates and slots as latent topics, probable graphical models learn these templates and slots Bombing Template Perpetrator: person Victim: person Target: public Instrument: bomb topics"}, {"heading": "2 Task Definition", "text": "Our model is an entity model. This model represents a document d as a set of entities Ed = [ei | i = 1, 2, \u00b7 \u00b7}. Each entity is a quadruple e = (h, p, d, f). In this case, h represents the header of an entity, p represents its predicate, and d represents the dependency path between predicate and header, f contains the entity attributes (such as the direct hypernyms of the header), the sentence identifier where e occurred, and the document identifier where e occurred. A simple example is Figure 1. Our ultimate goal is to assign two identifiers to each entity, a slot variable s and a template variable. After that, we can summarize them all to obtain event schemes."}, {"heading": "3 Automatic Event Schema Induction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Inner Connectivity Between Entities", "text": "We focus on two types of internal connectivity: (1) the probability that two entities belong to the same template; (2) the probability that two entities belong to the same slot;"}, {"heading": "3.1.1 Template Level Connectivity", "text": "Therefore (Chambers and Jurafsky, 2011) PMI uses to measure the correlation of two words in the same document, but it cannot combine two words from different documents. In the Bayesian model of (Chambers, 2013) p (predicate) is the key factor to determine the template, but it ignores the fact that nearby units should belong to the same template. In this paper, we are trying to combine two scales. That is, if two units have occurred in the vicinity, they can belong to the same template; if they have a similar meaning, they can also belong to the same template. We use PMI to measure the distance similarity and use word vector (Mikolov et al., 2013) to calculate the semantic similarity. A word vector can represent the meaning of a word well."}, {"heading": "3.1.2 Slot Level Connectivity", "text": "If two entities can play a similar role in an event, they probably fill the same slot. We know that if two entities can play a similar role, their headers can have the same hypernyms. We are only looking at the direct hypernyms here. Besides, their predicates can have a similar meaning and the entities have the same dependency path to their predicate. Therefore, we give the factors equal weights and add them together to achieve the similarity of the slit plane. WS (i, j) = cosp (i, j) + \u03b4 (dependi = dependj) + \u03b4 (hypernymi or hypernymj 6 = \u03c6) (2) Here, \u03b4 (\u00b7) has a value 1 if the inner expression is true and 0 otherwise. The \"hypernym\" derives from Wordings (Miller, 1995), so it is a series of direct hypernymi entities. If the headers of two entities have at least one cosmic entity in common, then they belong to the same cosmos again."}, {"heading": "3.2 Template and Slot Clustering Using Normalized Cut", "text": "Normalized section aims to maximize similarity within the class while minimizing similarity between classes, which handles the connectivity between entities well; the edge weight between two points is their similarity at the template / slot level; the greater the similarity value, the more likely it is that the two entities (dot) belong to the same template / slot, which is also our intuition; for simplicity, we call the unit E = {e1, \u00b7 \u00b7, e | E |} and the template T. We use the XT | E | partition matrix XT to represent the template cluster result; let's leave XT = [XT1, \u00b7 \u00b7 \u00b7, XT | T |], where XTl is a binary indicator for the XTl (Tl).XT (i, l)."}, {"heading": "3.3 Joint Model With Sentence Constraints", "text": "For event schema induction, we find an important property and call it \"set constraint\" = GT = GT relationship. (Theentities in a set often belong to a template, but different slots. The set constraint contains two types of constraints, \"template constraint\" and \"slot constraint.\" (1) Template constraint: entities in the same set are usually in different slots. (Therefore, we should make the slots in the same set as many as possible.) Based on these considerations, we can add an additional element to the optimization object. Let set be the number of sets. Define set \u00d7 | E | Matrix J as set constraint Xmax, the entities of J is as follows: J (i, j) = {1 ei-sentcej 0 otherwise (7) Easy to represent the GTT relationship between the GT and GT."}, {"heading": "4 Experiment", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Dataset", "text": "In this work, we use MUC-4 (Sundheim, 1991) as a data set consistent with previous work (Chambers and Jurafsky, 2011; Chambers, 2013).The MUC-4 corpus contains 1300 documents in the training set, 200 in the development set (TS1, TS2) and 200 in the test set (TS3, TS4) on Latin American terrorist news. We have gone through the 1500 documents (training / development set) several times and select the best ones. The MUC-4 corpus contains six template types: attack, kidnapping, bombing, arson, and forced labor, and for each template there are 25 slots."}, {"heading": "4.2 Performance", "text": "The five words in each slot are the five randomly selected units from the mapped slots. The collectively learned templates and slots appear reasonable. We compare our results with four papers (Chambers and Jurafsky, 2011; Cheung, 2013; Chambers, 2013; Nguyen et al., 2015), as shown in Table 2. Our model has surpassed all previous methods.The improvement in recall is due to the normalized editing criteria that can better utilize the internal networking between the units. Punitive limitation improves the result one step further. BombingPerpetrator Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim Victim The guerillas The smuggling mafia Drug traffickerThe smuggling mafia The Atlacatl battalionThe police leaderThe Peruvian EmbassionThe diplomats Victim protectorsThe embassy leaderThe police machinesThe personal vehicle guidelineThe child militant bombings"}, {"heading": "5 Related Works", "text": "There are also some state-of-the-art works using a probabilistic graphic model (Chambers, 2013; Cheung, 2013; Nguyen et al., 2015)."}, {"heading": "6 Conclusion", "text": "This model uses word embedding as well as PMI to measure the inner connection of entities, and uses normalized section for more accurate clustering. Finally, our model uses sentence constraints to extract templates and slots simultaneously, and the experiment has proven the effectiveness of our model."}, {"heading": "Acknowledgments", "text": "This research is supported by the National Key Basic Research Program of China (No.2014CB340504) and the National Natural Science Foundation of China (No.61375074,61273318). The contact authors of this work are Sujian Li and Baobao Chang."}, {"heading": "1 The Model", "text": "Cluster optimization is shown in Eq 1.max \u03b51 (XT) = 1 | J (J) sentence (T | | T | \u2211 l = 1XTTlWTl XTTlDTls.t. (1) Cluster optimization is shown in Eq 2.max \u03b52 (XS) = 1 | S | 1 | E | (1) (1) (Generator XTSlWSXSl XSls.t. (XS). (1) Cluster optimization is shown in Eq 2.max \u03b52 (XS) = 1 | S | 2 | S \u00b2 l = 1XTSlWSXSl XTDSXSls.t. (XTSlWSl XSls.t. (1) XSlot 2.max \u03b52 (XS) = 1 slot set, XS is the slot XSint, XS is the slot cluster result with XS1, \u00b7 JT3, XTXS3 | S |], where XSl is the maximiator for XSl."}, {"heading": "2 Solving Method: Alternating Maximization", "text": "In this case, the detailed solution of the complex model in Eq 6 (Sq 6) -S (Sq 6) -S (Sq 6) -S (SR) -S (SR) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S -S -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S) -S (S (S) -S (S) -S (S) -S (S (S) -S (S) -S (S (S) -S (S) -S (S (S) -S (S (S) -S (S (S) -S (S) -S (S (S) -S (S) -S (S (S) -S (S) -S (S (S) -S (S (S) -S) -S (S (S) -S (S) -S (S) -S (S (S) S (S) S) S (S (S) S (S (S) S (S) S) S (S) S (S (S) S (S) S (S) S (S) S (S) S) S (S) S (S -S) S (S) S -S (S) S -S -S (S (S) S (S) S)"}, {"heading": "3 Experiment Setting", "text": "The cluster size in Eq 13 and Eq 11 can be considered a precursor to the cluster size and the slot cluster size. We use most of the time before that all clusters are the same size."}], "references": [{"title": "The elements of statistical learning", "author": ["Trevor Hastie", "Robert Tibshirani", "Jerome Friedman", "T Hastie", "J Friedman", "R Tibshirani"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2009}, {"title": "Alternating maximization procedure for finding the global maximum of directed information", "author": ["Iddo Naiss", "Haim H Permuter"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Multiclass spectral clustering", "author": ["Stella X Yu", "Jianbo Shi"], "venue": "In Computer Vision,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}], "referenceMentions": [], "year": 2016, "abstractText": "Automatic event schema induction (AESI) means to extract meta-event from raw text, in other words, to find out what types (templates) of event may exist in the raw text and what roles (slots) may exist in each event type. In this paper, we propose a joint entity-driven model to learn templates and slots simultaneously based on the constraints of templates and slots in the same sentence. In addition, the entities\u2019 semantic information is also considered for the inner connectivity of the entities. We borrow the normalized cut criteria in image segmentation to divide the entities into more accurate template clusters and slot clusters. The experiment shows that our model gains a relatively higher result than previous work.", "creator": "LaTeX with hyperref package"}}}