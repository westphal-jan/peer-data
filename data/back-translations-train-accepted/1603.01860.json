{"id": "1603.01860", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Mar-2016", "title": "Generalization error bounds for learning to rank: Does the length of document lists matter?", "abstract": "We consider the generalization ability of algorithms for learning to rank at a query level, a problem also called subset ranking. Existing generalization error bounds necessarily degrade as the size of the document list associated with a query increases. We show that such a degradation is not intrinsic to the problem. For several loss functions, including the cross-entropy loss used in the well known ListNet method, there is \\emph{no} degradation in generalization ability as document lists become longer. We also provide novel generalization error bounds under $\\ell_1$ regularization and faster convergence rates if the loss function is smooth.", "histories": [["v1", "Sun, 6 Mar 2016 19:01:53 GMT  (34kb)", "http://arxiv.org/abs/1603.01860v1", "Appeared in ICML 2015. arXiv admin note: substantial text overlap witharXiv:1405.0586"]], "COMMENTS": "Appeared in ICML 2015. arXiv admin note: substantial text overlap witharXiv:1405.0586", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ambuj tewari", "sougata chaudhuri"], "accepted": true, "id": "1603.01860"}, "pdf": {"name": "1603.01860.pdf", "metadata": {"source": "META", "title": "Generalization error bounds for learning to rank:  Does the length of document lists matter?", "authors": ["Ambuj Tewari"], "emails": ["TEWARIA@UMICH.EDU", "SOUGATA@UMICH.EDU"], "sections": [{"heading": null, "text": "ar Xiv: 160 3.01 860v 1 [cs.L G] 6M ar"}, {"heading": "1. Introduction", "text": "This year it is more than ever before."}, {"heading": "2. Preliminaries", "text": "In the area of learning to rank (also referred to as subset ranking) it is distinguished from other related problems, e.g. the two-tier ranking (two-tier ranking), an example is the form (q, d1, dm). Here it is a search query and d1,.., dm are documents with varying degrees of relevance to the query., in which the relevance tag in the entries in y contains the relevance tag for the m individual documents. Typically, y has integer entries in the range [0,., Ymax], where Ymax often the relevance tag is less than 5. For our theoretical analysis, we will get rid of some of these details by assuming that there is a query document pair (q, d) to Rd. As a result, the training example (q, d1, y), y."}, {"heading": "3. Application to Specific Losses", "text": "In order to whet the reader's appetite for the following technical presentation, we will consider two loss functions, one convex and one non-convex, in order to illustrate the concrete improvements that our new generalization limits offer. A generalization limit is the form: L\u03c6 (w) \u2264 L\u03c6 (w) + \"complexity concept.\" It should be noted that the learning algorithm w * does not have access to knowledge of the underlying distribution of the data. Chapelle & Wu's complexity concept (2010) is O (GCW\u03c6 W2RX \u221a m / n). The constant GCW\u03c6 is the Lipschitz constant of the surrogate (considered as a function of the score vector s) w.r.t. Our limits will instead have the form O (GZW2RX \u04321 / n), where the GZW value is the Lipschitz constant of the ZWT / Norm."}, {"heading": "3.1. Application to ListNet", "text": "The ListNet ranking method (Cao et al., 2007) uses a convex surrogate method, which is defined in the following way.1 Define m maps from Rm to R as: Pj (v) = exp (vj) / \u2211 m i = 1 exp (vi) for j [m].A simple calculation shows that the Lipschitz (as well as the smoothness) constant of \u03c6LN m is independent. 1The ListNet paper actually defines a loss family based on probability models for top-k documents. We use k = 1 in our definition, as this is the version implemented in its experimental results.Proposition 1: The Lipschitz (or smoothness) constant of ListLN w.r.1"}, {"heading": "3.2. Application to Smoothed DCG@1", "text": "This example comes from the work of Chapelle & Wu (2010).The smoothed DCG @ 1, a non-convex surrogate, is defined as: \u03c6SD (s, y) = D (1) m \u2211 i = 1G (yi) exp (si / \u03c3) \u2211 j exp (sj / \u03c3), where D (i) = 1 / log2 (1 + i) is the \"discounting function\" and G (i) = 2i \u2212 1 is the \"winning function.\" The degree of smoothing is controlled by the parameter \u03c3 > 0 and the smoothed version approaches DCG @ 1 as \u03c3 \u2192 0 (DCG stands for Discounted Cumulative Gain (Ja \ufffd rvelin & Keka \ufffd la \ufffd inen, 2002).The Lipschitz constant of throughSD w.r.d."}, {"heading": "3.3. Application to RankSVM", "text": "A number of studies have shown that ListNet performs better empirically than RankSVM. One possible reason for the better performance of ListNet compared to RankSVM is that the Lipschitz constant of the RankSVM replacement scale performs better empirically than RankSVM. Due to the lack of space, we provide the details in the supplement."}, {"heading": "4. Does The Length of Document Lists Matter?", "text": "Our work is directly motivated by a very interesting generalization, which is obliged to learn the order of precedence on the basis of Chapelle & Wu (2010, Theorem 1). They considered a Lipschitz continuous loss \u03c6 with Lipschitz's constant GCW\u03c6 w.r.t. as the norm for the second group. They show that the predominant term on the right is O (GCW\u03c6 W2RX \u221a (w) + 3GCW\u03c6 W2RX \u221a mn + 270 log (1 / 3) n. The predominant term on the right is O (GCW\u03c6 W2RX \u221a m / n). In the next three sections we will derive improved limits of the form O (G\u0441W2RX \u221a 1 / n), whereby G\u03c6 \u2264 GCW\u0445 \u0432\u0438\u043d\u0438\u043cm, but may be much smaller. Before doing so, we want to investigate the dimensionality reduction of the linear scanning function caused by a natural invariant mutation."}, {"heading": "4.1. Permutation invariance removes m dependence in dimensionality of linear scoring functions", "text": "As explained in section 2, a ranking is achieved by sorting a score vector achieved via a linear scoring function. Consider the space of the linear scoring function, which consists of all linear cards for this card Rm \u00b7 d to Rm: Ffull: = {X 7 \u2192 [< X, W1 >,.. < X, Wm >]: These linear cards are fully parameterized by matrices W1,..., a complete parameterization of the linear scoring function depends on the dimension m2d. Note that the commonly used class of linear scoring functions Flin Eq. 1 is actually a low d-dimensional subspace of the complete m2d-dimensional space of all linear cards. It is important to note that the dimension of Flin Flin is independent of m in learning theory, which affects the generalization errors."}, {"heading": "5. Online to Batch Conversion", "text": "In this section, we build some intuition about why it is natural that we are in the definition of the Lipschitz constant of loss. \"To achieve this, we consider the following well-known online gradient lineage (OGD). Remember that OGD refers to the simple online algorithm that makes the update\" wi + 1 \"+\" wi \"+\" wifi \"(wi). If we run\" OGD \"to generate\" wi \"s, we have for all other areas\" W2: n \"i = 1fi (wi) \u2212 n\" i = 1fi \"(w),\" W 22 + \"G2n,\" where G has a limit for the maximum yield of 2-norm gradients \"wifi\" (wi) and \"fi\" s must be convex. \"If we (1), y\" i \"i\" i, \"we can.\""}, {"heading": "6. Stochastic Convex Optimization", "text": "First, we define the regulated empirical risk mixer: w = Argmin-Value-Value-Value-Value-Value-Value-Value-Value-Index-Value-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index-Index."}, {"heading": "7. Bounds for Non-convex Losses", "text": "The above discussion suggests that we have a way of defining a narrower, possibly m-independent, generalizing margin of error by assuming that this number does not exceed 1 percent of the total. (...) The standard method in the binary classification is to adhere to the Ledoux-Talagrand contraction principles in order to establish the wheel-maker complexity. (...) The Lipschitz constant is defined for only one standard, i.e. the absolute value standard is not immediately clear how such an approach would work if the loss is tied to the wheel-maker complexity. (...) Since the loss function takes over the scalar argument, the Lipschitz constant is defined for only one standard. (...) The absolute value standard is not immediately clear how such an approach would work if the vector-weighted arguments and Lipschitz w.r.dout. (Talrand) We are not aware that an extension of the Leagx principle becomes an appropriate one."}, {"heading": "8. Extensions", "text": "We extend the above generalization limits to two settings: a) high-dimensional characteristics and b) smooth losses."}, {"heading": "8.1. High-dimensional features", "text": "If we learn to evaluate situations with high dimensional characteristics, it may not be appropriate to use the class F2 of the limited predictors. Instead, we would like to consider the class F1 of the limited predictors. In this case, the uniform limit of loss follows slightly under the (very reasonable) assumption that the size of the input matrix X in relation to a bound R-X standard of each line. The following analogy of proposition 7 can be shown. The following analogy of position 7 follows the (very reasonable) assumption that the size of the input matrix X in relation to a bound R-X standard of each line. The following analogy of position 7 can be shown."}, {"heading": "8.2. Smooth losses", "text": "We will again use online remorse limits to explain why we should expect \"optimistic\" rates for smooth losses before delivering more general results for smooth but possibly non-convex losses."}, {"heading": "8.3. Online regret bounds under smoothness", "text": "Let's go back to the OGD Guarantee, this time in a slightly refined version. If we run OGD with a learning rate of 42.1 percent, then (for all others) it is necessary (for all others), (for all others), (for all others), (for others), (for others), (for others), (for others), (for others), (for others), (for others), (for others), (for others), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for us), (for, (for us), (for us), (for, (for us), (for us), (for, (for us), (for us), (for, (for us), (for us), (for us), (for, (for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for), for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for, for"}, {"heading": "8.4. Generalization error bounds under smoothness", "text": "To prove a general result for possibly non-convex smooth losses, we will apply an approach based on numbers. To start with, we need a useful problem from Srebro et al. (2010, Lemma A.1 in Supplementary Material). Note that we do not need to talk about the standard when it comes to functions about real evaluations when it comes to smoothness, since essentially the only available norm is the absolute value. Lemma 13. For each h-smooth non-negative function f: R + and each t, r-R we have (f (t) \u2212 f (r) 2 \u2264 6h (f) + f (r))) (t \u2212 r) 2.We first offer an extension of this problem to the vector falle.Lemma 14. If Rm \u2192 R + is a non-negative function with a smooth constant, then the HDP-2 is a non-negative function with a smooth constant."}, {"heading": "9. Conclusion", "text": "We have shown that there is no need for the margin of error for query-level learning to deteriorate as the length of document lists associated with queries increases, and the key idea behind our improved limits was to define Lipschitz constants rather than the \"standard\" standard. As a result, we have been able to derive much tighter guarantees for popular loss functions such as ListNet and Smoothed DCG @ 1 than are currently available.Our generalized analysis of learning to rank algorithms paves the way for further interesting work. One possibility is to use these limits to design active learning algorithms for learning ranking with formal complexity guarantees for labels. Another interesting option is to consider other problems, such as multi-label learning, where functions with vector-rated outputs are learned by optimizing a common function of these outputs."}, {"heading": "Acknowledgement", "text": "We gratefully acknowledge the support of NSF within the framework of the funding IIS-1319810. Thanks to Prateek Jain for the discussions that led us to Theorem 3."}, {"heading": "A. Proof of Proposition 1", "text": "We have the following standard vektors: 1 exp (sj) ejp (s, y) = 1 exp (sj) ejp (s, y) = 1 exp (sj) ejp (s, y) = 1 exp (sj) ejp = 1 exp (sj) ejp (s, y) [s, y] j, k = \u2212 exp (sj) 1 + 1 exp (sj) (sj) 1 exp (sj) 1 = 1 exp (sj) 1 exp (sj) 2 + exp (sj) (sj) (sj) 1 exp (sj) (sj) 1 sj (sj) sj (1) sj (1) sj (1) sj (1) sj (1) sp (1) sj (1) sj (1) sj (1) sp (1) (1 sj) sj (1) sp (1) (1 sj) (1 sp (1)."}, {"heading": "B. Proof of Proposition 2", "text": "Proof: Let us designate 1 (condition) as indicator variable. We have [sj (s, y)] j = D (1) (m, i = 1G (ri) [1\u03c3 exp (si, c))] [sj (s, y)] 1 (i = j) \u2212 1 \u03c3 exp (((((si + sj) / \u03c3)) (\u2211 j \"exp (sj\" / \u03c3))) 2]) Therefore we have [s\u03c6SD (s, y) 1 D (1) G (Ymax) \u2264 m \"j = 1 (m, i = 1 [12000 exp (si / \u03c3) \u0445 j\" exp (sj \"/ \u03c3) 1 (i = j) + 1% exp ((si + sj) + 1% exp (si + sj) (sj\" exp (sj) \u00b2 (sj) 2]) = 1\u03c3 (sj \"exp (sj, c)."}, {"heading": "C. RankSVM", "text": "The RankSVM surrogate is defined as: \u03c6RS (s, y) = m \u2211 i = 1m \u2211 j = 1max (0, 1 (yi > yj) (1 + sj \u2212 si)) It is easy to see that the RS (s, y) = \u2211 mi = 1 \u2211 m j = 1 max (0, 1 (yi > yj) (1 + sj \u2212 si)) (ej \u2212 ei)."}, {"heading": "D. Proof of Theorem 3", "text": "Evidence. It is easy to verify that F'lin is present in both Ffull and Fperminv. < p > m Permutation Matrix corresponds to a permutation matrix, so let's look at the complete linear class Ffull. < p \u00b2 Invariant display property means that for each x, X, P\u03c0 [< X, W1 >,.. < X, Wm >] we look at the complete linear class Ffull. < p \u00b2 Invariant display property means that for each x, X, P\u03c0 [< X, W1 >, we look at the complete linear class Ffull."}, {"heading": "E. Proof of Lemma 4", "text": "Proof: The first equality is true because \"X\" 1 \"p\" p \"sup\" v \"6\" 0 \"X\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" v \"1\" p \"p\" p \"p\" p \"p\" v \"1\" p \"p\" p \"v\" 6 \"= 0\" p \"p\" p \"p\" p \"v\" 1 \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" 1 \"p\" p \"1\" p \"p\" p \"p\" p \"1\" p \"p\" p \"p\" v \"1\" p \"p\" p \"v\" 1 \"u\" q \"q\" p \"u6\" u \"p\" p \"q\" u \"p\" p \"p\" u \"p\" u \"p\" p \"u\" p \"p\" u \"p\" p \"p\" u \"p\" p \"p\" g \"g\" g \"g\" g \"g\" g \"g\" g \"g\" g."}, {"heading": "F. Proof of Theorem 6", "text": "Our theory is developed from the \"expectation version\" of Theorem 6 by Shalev-Shwartz et al. (2009), which was originally given in probable form. (2009) The expected version is as follows: Let Z be a space equipped with a probability distribution, the Z1,.., Zn. Let W Rd and f: W \u00b7 Z \u2192 R. (W) W1nn. (W, Zi). We define F (w, Z) = E [f, Z) and let W Rd = argminw \u00b2 W F (w), w = argmin w \u00b2 W1nn. (W, Zi). Then E [F, w) \u2212 F (w) \u2212 F (W, Z)."}, {"heading": "G. Proof of Theorem 12", "text": "Evidence. If we follow exactly the same line of argument (reduction of a sample of size n, where each prediction is evaluated in Rm, to a sample of size mn, where each prediction is a real value) as at the beginning of the proof of proposition 7, we have the following limit based on Zhang (2002, Corollary 5): log2 N + (1) (1) (1) (G1, G1, mn) \u2264 288G2A 2 1 R 2 X (2 + ln d) 2 x log2 (2) (2) 8G W1R, X / mn + 1) in (11) or the result. 4Remember that a function is called an upper convex (2 + ln d): upper convex (2 + ln d) 2 x log2 (2) x log2 (2) iff f \u2212 zip.H. Calculations preceding the derivation of HL (8) to HL (4) 4W 4b + (4b) (4b) at the beginning of size 4b, each log2 + (4b 4b 4b 4b 4b 4b 4b 4b 4b 4b 4b 4b 4b 4b 4b: N."}, {"heading": "I. Calculation of smoothness constant", "text": "(X (i))"}, {"heading": "J. Proof of Lemma 14", "text": "Consider the function f (t) = \u03c6 ((1 \u2212 t) s1 + ts2). It is clearly not negative. Moreover, it is clearly not negative."}, {"heading": "K. Proof of Proposition 15", "text": "The proof: Let's w, w & # 246; fen, 2 (r).Mit Lemma 14 n & # 160; i = 11n (& # 160; X (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) w & # 160; i (i) + f & # 160; i (i) w & # 160; i (i) w & # 160; i (i)."}, {"heading": "L. Proof of Corollary 16", "text": "Proof. We include the estimation of Proposition 15 in (5): R-n (F\u03c6, 2 (r)) \u2264 inf \u03b1 > 0 4\u03b1 + 10 (B-B) \u00b7 12H-W 22 R 2 X-R-2 Log2 (2mn + 1) n dB-inf \u03b1 > 0 (4\u03b1 + 20) 3W2RX - rH\u03c6 log2 (3mn) n-Br\u03b11 Log2 (dB). Now we select \u03b1 = C-r, where C = 5 \"3W2RX\" H\u03c6 log2 (3mn) n gives us the upper limit R-n (F\u03c6, 2 (r) \u2264 4 \"rC (1 + Log) \u2264 4\" rC log 3 \"BC."}, {"heading": "M. Proof of Theorem 17", "text": "Proof: We refer to Theorem 6.1 of Bousquet (2002) that there is an upper limit (F2, \u03c6 (r)). The upper limit in Corollary 16 above meets these conditions, and therefore we use a non-negative, non-decreasing, non-zero functional principle so that we know that the upper limit in Corollary 16 above meets these conditions, and therefore we use a non-negative, non-decreasing, non-zero functional principle with C defined in Corollary 16. From Bousquet's result, we know that the upper limit in Corollary 16 meets these conditions with a probability of at least 1 \u2212 44 that the upper limit is in Corollary 16."}], "references": [{"title": "Rademacher and Gaussian complexities: Risk bounds and structural results", "author": ["Bartlett", "Peter L", "Mendelson", "Shahar"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Bartlett et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2003}, {"title": "Concentration inequalities and empirical processes theory applied to the analysis of learning algorithms", "author": ["Bousquet", "Olivier"], "venue": "PhD thesis, Ecole Polytechnique,", "citeRegEx": "Bousquet and Olivier.,? \\Q2002\\E", "shortCiteRegEx": "Bousquet and Olivier.", "year": 2002}, {"title": "Learning to rank: from pairwise approach to listwise approach", "author": ["Cao", "Zhe", "Qin", "Tao", "Liu", "Tie-Yan", "Tsai", "Ming-Feng", "Li", "Hang"], "venue": "In Proceedings of the 24th International Conference on Machine Learning,", "citeRegEx": "Cao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Cao et al\\.", "year": 2007}, {"title": "Gradient descent optimization of smoothed information retrieval metrics", "author": ["Chapelle", "Olivier", "Wu", "Mingrui"], "venue": "Information retrieval,", "citeRegEx": "Chapelle et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2010}, {"title": "Expected reciprocal rank for graded relevance", "author": ["Chapelle", "Olivier", "Metlzer", "Donald", "Zhang", "Ya", "Grinspan", "Pierre"], "venue": "In Proceedings of the 18th ACM Conference on Information and Knowledge Management,", "citeRegEx": "Chapelle et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2009}, {"title": "Future directions in learning to rank", "author": ["Chapelle", "Olivier", "Chang", "Yi", "Liu", "Tie-Yan"], "venue": "In Proceedings of the Yahoo! Learning to Rank Challenge June", "citeRegEx": "Chapelle et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chapelle et al\\.", "year": 2010}, {"title": "Cumulated gainbased evaluation of IR techniques", "author": ["J\u00e4rvelin", "Kalervo", "Kek\u00e4l\u00e4inen", "Jaana"], "venue": "ACM Transactions on Information Systems,", "citeRegEx": "J\u00e4rvelin et al\\.,? \\Q2002\\E", "shortCiteRegEx": "J\u00e4rvelin et al\\.", "year": 2002}, {"title": "Optimizing search engines using clickthrough data", "author": ["Joachims", "Thorsten"], "venue": "In Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Joachims and Thorsten.,? \\Q2002\\E", "shortCiteRegEx": "Joachims and Thorsten.", "year": 2002}, {"title": "Query-level stability and generalization in learning to rank", "author": ["Lan", "Yanyan", "Liu", "Tie-Yan", "Qin", "Tao", "Ma", "Zhiming", "Li", "Hang"], "venue": "In Proceedings of the 25th International Conference on Machine Learning,", "citeRegEx": "Lan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Lan et al\\.", "year": 2008}, {"title": "Generalization analysis of listwise learning-to-rank algorithms", "author": ["Lan", "Yanyan", "Liu", "Tie-Yan", "Ma", "Zhiming", "Li", "Hang"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,", "citeRegEx": "Lan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lan et al\\.", "year": 2009}, {"title": "LETOR: Benchmark dataset for research on learning to rank for information retrieval", "author": ["Liu", "Tie-yan", "Xu", "Jun", "Qin", "Tao", "Xiong", "Wenying", "Li", "Hang"], "venue": "In Proceedings of SIGIR 2007 Workshop on Learning to Rank for Information Retrieval,", "citeRegEx": "Liu et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2007}, {"title": "Rademacher averages and phase transitions in Glivenko-Cantelli classes", "author": ["Mendelson", "Shahar"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Mendelson and Shahar.,? \\Q2002\\E", "shortCiteRegEx": "Mendelson and Shahar.", "year": 2002}, {"title": "Some extensions of an inequality of Vapnik and Chervonenkis", "author": ["Panchenko", "Dmitriy"], "venue": "Electronic Communications in Probability,", "citeRegEx": "Panchenko and Dmitriy.,? \\Q2002\\E", "shortCiteRegEx": "Panchenko and Dmitriy.", "year": 2002}, {"title": "Stochastic convex optimization", "author": ["Shalev-Shwartz", "Shai", "Shamir", "Ohad", "Srebro", "Nathan", "Sridharan", "Karthik"], "venue": "In Proceedings of the 22nd Annual Conference on Learning Theory,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2009}, {"title": "Smoothness, low noise, and fast rates", "author": ["Srebro", "Nathan", "Sridharan", "Karthik", "Tewari", "Ambuj"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Srebro et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srebro et al\\.", "year": 2010}, {"title": "Covering number bounds of certain regularized linear function classes", "author": ["Zhang", "Tong"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Zhang and Tong.,? \\Q2002\\E", "shortCiteRegEx": "Zhang and Tong.", "year": 2002}, {"title": "Proof of Theorem 6 Our theorem is developed from the \u201cexpectation version\u201d of Theorem 6 of Shalev-Shwartz et al. (2009) that was originally given in probabilistic form. The expected version is as follows. Let Z be a space endowed with a probability distribution generating iid draws Z1", "author": ["F. \u2016Xj\u2016p"], "venue": null, "citeRegEx": ".Xj.p.,? \\Q2009\\E", "shortCiteRegEx": ".Xj.p.", "year": 2009}], "referenceMentions": [{"referenceID": 4, "context": "The performance of ranking functions on test sets is evaluated using a variety of performance measures such as NDCG (J\u00e4rvelin & Kek\u00e4l\u00e4inen, 2002), ERR (Chapelle et al., 2009) or Average Precision (Yue et al.", "startOffset": 151, "endOffset": 174}, {"referenceID": 3, "context": "However, as soon as one optimizes a surrogate loss, one has to deal with two questions (Chapelle et al., 2011). First, does minimizing the surrogate on finite training data imply small expected surrogate loss on infinite unseen data? Second, does small expected surrogate loss on infinite unseen data imply small target loss on infinite unseen data? The first issue is one of generalization error bounds for empirical risk minimization (ERM) algorithms that minimize surrogate loss on training data. The second issue is one of calibration: does consistency in the surrogate loss imply consistency in the target loss? This paper deals with the former issue, viz. that of generalization error bounds for surrogate loss minimization. In pioneering works, Lan et al. (2008; 2009) gave generalization error bounds for learning to rank algorithms. However, while the former paper was restricted to analysis of pairwise approach to learning to rank, the later paper was limited to results on just three surrogates: ListMLE, ListNet and RankCosine. To the best of our knowledge, the most generally applicable bound on the generalization error of query-level learning to rank algorithms has been obtained by Chapelle & Wu (2010). The bound of Chapelle & Wu (2010), while generally applicable, does have an explicit dependence on the length of the document list associated with a query.", "startOffset": 88, "endOffset": 1220}, {"referenceID": 3, "context": "However, as soon as one optimizes a surrogate loss, one has to deal with two questions (Chapelle et al., 2011). First, does minimizing the surrogate on finite training data imply small expected surrogate loss on infinite unseen data? Second, does small expected surrogate loss on infinite unseen data imply small target loss on infinite unseen data? The first issue is one of generalization error bounds for empirical risk minimization (ERM) algorithms that minimize surrogate loss on training data. The second issue is one of calibration: does consistency in the surrogate loss imply consistency in the target loss? This paper deals with the former issue, viz. that of generalization error bounds for surrogate loss minimization. In pioneering works, Lan et al. (2008; 2009) gave generalization error bounds for learning to rank algorithms. However, while the former paper was restricted to analysis of pairwise approach to learning to rank, the later paper was limited to results on just three surrogates: ListMLE, ListNet and RankCosine. To the best of our knowledge, the most generally applicable bound on the generalization error of query-level learning to rank algorithms has been obtained by Chapelle & Wu (2010). The bound of Chapelle & Wu (2010), while generally applicable, does have an explicit dependence on the length of the document list associated with a query.", "startOffset": 88, "endOffset": 1255}, {"referenceID": 10, "context": "In benchmark datasets (Liu et al., 2007), m can easily be in the 100-1000 range.", "startOffset": 22, "endOffset": 40}, {"referenceID": 2, "context": "Application to ListNet The ListNet ranking method (Cao et al., 2007) uses a convex surrogate, that is defined in the following way1.", "startOffset": 50, "endOffset": 68}, {"referenceID": 8, "context": "In particular, the results of Lan et al. (2009) have an m! dependence since they consider the top-m version of ListNet.", "startOffset": 30, "endOffset": 48}, {"referenceID": 8, "context": "In particular, the results of Lan et al. (2009) have an m! dependence since they consider the top-m version of ListNet. However, even if the top-1 variant above is considered, their proof technique will result in at least a linear dependence on m and does not result in as tight a bound as we get from our general results. It is also easy to see that the Lipschitz constant G \u03c6LN of ListNet loss w.r.t. l2 norm is also 2 and hence the bound of Chapelle & Wu (2010) necessarily has a \u221a m dependence in it.", "startOffset": 30, "endOffset": 465}, {"referenceID": 14, "context": "1 of Srebro et al. (2010) tells us that any non-negative, smooth function f(w) enjoy an important self-bounding property for the gradient:", "startOffset": 5, "endOffset": 26}], "year": 2016, "abstractText": "We consider the generalization ability of algorithms for learning to rank at a query level, a problem also called subset ranking. Existing generalization error bounds necessarily degrade as the size of the document list associated with a query increases. We show that such a degradation is not intrinsic to the problem. For several loss functions, including the cross-entropy loss used in the well known ListNet method, there is no degradation in generalization ability as document lists become longer. We also provide novel generalization error bounds under l1 regularization and faster convergence rates if the loss function is smooth.", "creator": "LaTeX with hyperref package"}}}