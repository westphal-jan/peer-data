{"id": "1603.02618", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Mar-2016", "title": "The red one!: On learning to refer to things based on their discriminative properties", "abstract": "As a first step towards agents learning to communicate about their visual environment, we propose a system that, given visual representations of a referent (cat) and a context (sofa), identifies their discriminative attributes, i.e., properties that distinguish them (has_tail). Moreover, despite the lack of direct supervision at the attribute level, the model learns to assign plausible attributes to objects (sofa-has_cushion). Finally, we present a preliminary experiment confirming the referential success of the predicted discriminative attributes.", "histories": [["v1", "Tue, 8 Mar 2016 18:39:46 GMT  (1896kb,D)", "http://arxiv.org/abs/1603.02618v1", null], ["v2", "Mon, 23 May 2016 17:04:15 GMT  (2006kb,D)", "http://arxiv.org/abs/1603.02618v2", "Accepted as an ACL-short sumbmission"]], "reviews": [], "SUBJECTS": "cs.CL cs.CV", "authors": ["angeliki lazaridou", "nghia the pham", "marco baroni"], "accepted": true, "id": "1603.02618"}, "pdf": {"name": "1603.02618.pdf", "metadata": {"source": "CRF", "title": "\u201cThe red one!\u201d: On learning to refer to things based on their discriminative properties", "authors": ["Angeliki Lazaridou", "Marco Baroni"], "emails": ["angeliki.lazaridou@unitn.it", "thenghia.pham@unitn.it", "marco.baroni@unitn.it"], "sections": [{"heading": "1 Introduction", "text": "From this perspective, it is important to think about an appropriate general framework for communicating language to machines. Since we primarily use language for communication, a reasonable approach is to develop systems within a true communicative setup (Steels, 2003; Mikolov et al., 2015). In this perspective, our long-term goal is to develop communities of computer agents who learn how to use language efficiently to achieve communicative success (Vogel et al., 2013; Foerster et al., 2016). Within this general picture, a fundamental aspect of meaning in which communication is actually crucial is the act of reference (Searle, 1969; Abbott, 2010), the ability to successfully talk to others about things in the external world (Vogel et al., 2013; Foerster et al., 2016)."}, {"heading": "2 Discriminative Attribute Dataset", "text": "In recent years, it has become clear that the values we have mentioned are not only the values we have mentioned, but also the values we have mentioned, but also the values we have mentioned."}, {"heading": "3 Discriminative Attribute Network", "text": "The proposed Discriminative Attribute Network (DAN) learns to predict the discriminatory attributes of the referent object cr and context cc without direct monitoring at the attribute level, but relies only on discrimination information (e.g., for the objects in Figure 2, the gold vector would contain 1 for has _ tail, but 0 for both is _ green and has _ legs).However, the model is implicitly encouraged to embed objects in an attribute space in order to generalize the discrimination vectors of different training pairs, so it also effectively learns to annotate objects with visual attributes. Figure 2 presents a schematic view of the DAN that focuses on a single attribute; the model is presented with two concepts (< CAT, SOFA >) and random samples of a visual instance each."}, {"heading": "4 Predicting Discriminativeness", "text": "We evaluate the model's ability to predict attributes that differentiate the intended speaker from the context. In fact, we ask the model to return all discriminatory attributes for a pair, regardless of whether they are positive for the speaker or positive for the context (given images of a cat and a building, both + is _ furry and \u2212 made _ of _ bricks are discriminatory for the cat) Test stimuli We derive our test stimuli from the VisA test split (see Section 2), which contains 2000 pairs. Unlike in the training, where the model was presented with specific visual instances (i.e. single images), we use visual concepts (CAT, BED) to evaluate, which we derive by averaging the vectors of all images associated with an object (i.e., the derivation of CAT from all images of cats), due to the lack of gold information about per image attributes. Results We compare DAN with a random presupposition probability that is estimated on the basis of discrimination."}, {"heading": "5 Predicting Attributes", "text": "Attribute learning is typically studied in supervised setups (Ferrari and Zisserman, 2007; Farhadi et al., 2009; Russakovsky and Fei-Fei, 2010) Our model learns to embed visual objects in an attribute space by indirectly monitoring attribute discrimination for specific < speakers, contexts > pairs. Conceptual attributes are never explicitly observed during the training; the question arises whether discrimination causes the model to learn plausible conceptual attributes. Note that the idea that the semantics of attributes arise from their distinctive function within a communication system is entirely consistent with the classical structuralist view of linguistic meaning (Geeraerts, 2009). To test our hypothesis, we feed the same test stimuli (visual concept vectors) as in the previous experiment, but now we consider activations in the attribute layer to be unfeasible."}, {"heading": "6 Evaluating Referential Success", "text": "Finally, we conducted a pilot study to test whether Dan's ability to predict discriminatory attributes at the concept level is not overlapping. < RE, bounding box > pair, whose RE does not overlap with our attribute and marks the remaining attributes with the overlapping attribute. < RE, bounding box, attribute >, bounding box > pair, we sample as context another < RE, bounding box > pair such that (i) the context RE does not contain the referent attribute, derivative data of the form < RE, bounding box, attribute > attributes of this type, we sample as context another < RE, bounding box > pair such that (i) the context RE does not contain the referent attribute, so that the latter is a likely discriminative feature; (ii) referent and context come from different images, so that their boards do not accidentally overlap (i)."}, {"heading": "7 Conclusion", "text": "We introduced DAN, a model that learns from a speaker and context to predict its discriminatory characteristics while deriving visual attributes from concepts as a by-product of its educational regime. While the predicted discriminatory attributes can lead to referential success, DAN currently lacks all other referential attributes (emphasis, linguistic and pragmatic bliss, etc.).We are currently working on adding communication (thus simulating a speaker-listener scenario (Golland et al., 2010) and natural language to the image."}], "references": [{"title": "Content determination in the generation of referring expressions", "author": ["Dale", "Haddock1991] Robert Dale", "Nicholas Haddock"], "venue": "Computational Intelligence,", "citeRegEx": "Dale et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Dale et al\\.", "year": 1991}, {"title": "Computational interpretations of the gricean maxims in the generation of referring expressions", "author": ["Dale", "Reiter1995] Robert Dale", "Ehud Reiter"], "venue": "Cognitive science,", "citeRegEx": "Dale et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Dale et al\\.", "year": 1995}, {"title": "Imagenet: A largescale hierarchical image database", "author": ["Deng et al.2009] Jia Deng", "Wei Dong", "Richard Socher", "Lia-Ji Li", "Li Fei-Fei"], "venue": "In Proceedings of CVPR,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Describing objects by their attributes", "author": ["Farhadi et al.2009] Ali Farhadi", "Ian Endres", "Derek Hoiem", "David Forsyth"], "venue": "In Proceedings of CVPR,", "citeRegEx": "Farhadi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Farhadi et al\\.", "year": 2009}, {"title": "Learning visual attributes", "author": ["Ferrari", "Zisserman2007] Vittorio Ferrari", "Andrew Zisserman"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Ferrari et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ferrari et al\\.", "year": 2007}, {"title": "Learning to communicate to solve riddles with deep distributed recurrent q-networks", "author": ["Yannis M. Assael", "Nando de Freitas", "Shimon Whiteson"], "venue": "Technical Report arXiv:1602.02672", "citeRegEx": "Foerster et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Foerster et al\\.", "year": 2016}, {"title": "Theories of lexical semantics", "author": ["Dirk Geeraerts"], "venue": null, "citeRegEx": "Geeraerts.,? \\Q2009\\E", "shortCiteRegEx": "Geeraerts.", "year": 2009}, {"title": "A game-theoretic approach to generating spatial descriptions", "author": ["Golland et al.2010] Dave Golland", "Percy Liang", "Dan Klein"], "venue": "In Proceedings of the 2010 conference on empirical methods in natural language processing,", "citeRegEx": "Golland et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Golland et al\\.", "year": 2010}, {"title": "Teaching machines to read and comprehend", "author": ["Tom\u00e1\u0161 Ko\u010disk\u00fd", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Hermann et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "The Goldilocks principle: Reading children\u2019s books with explicit memory representations. http://arxiv.org/ abs/1511.02301", "author": ["Hill et al.2015] Felix Hill", "Antoine Bordes", "Sumit Chopra", "Jason Weston"], "venue": null, "citeRegEx": "Hill et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Referitgame: Referring to objects in photographs of natural scenes", "author": ["Vicente Ordonez", "Mark Matten", "Tamara L Berg"], "venue": "In EMNLP,", "citeRegEx": "Kazemzadeh et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kazemzadeh et al\\.", "year": 2014}, {"title": "Computational generation of referring expressions: A survey", "author": ["Krahmer", "Van Deemter2012] Emiel Krahmer", "Kees Van Deemter"], "venue": "Computational Linguistics,", "citeRegEx": "Krahmer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krahmer et al\\.", "year": 2012}, {"title": "A roadmap towards machine intelligence", "author": ["Armand Joulin", "Marco Baroni"], "venue": "arXiv preprint arXiv:1511.08130", "citeRegEx": "Mikolov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2015}, {"title": "Natural reference to objects in a visual domain", "author": ["Kees van Deemter", "Ehud Reiter"], "venue": "In Proceedings of the 6th international natural language generation conference,", "citeRegEx": "Mitchell et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2010}, {"title": "Attribute learning in large-scale datasets", "author": ["Russakovsky", "Fei-Fei2010] Olga Russakovsky", "Li Fei-Fei"], "venue": "In Proceedings of ECCV,", "citeRegEx": "Russakovsky et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Russakovsky et al\\.", "year": 2010}, {"title": "Speech Acts: An Essay in the Philosophy of Language", "author": ["John R. Searle"], "venue": null, "citeRegEx": "Searle.,? \\Q1969\\E", "shortCiteRegEx": "Searle.", "year": 1969}, {"title": "Models of semantic representation with visual attributes", "author": ["Vittorio Ferrari", "Mirella Lapata"], "venue": "In Proceedings of ACL,", "citeRegEx": "Silberer et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Silberer et al\\.", "year": 2013}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Zisserman2014] Karen Simonyan", "Andrew Zisserman"], "venue": "arXiv preprint arXiv:1409.1556", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Social language learning", "author": ["Luc Steels"], "venue": "The Future of Learning,", "citeRegEx": "Steels.,? \\Q2003\\E", "shortCiteRegEx": "Steels.", "year": 2003}, {"title": "MatConvNet \u2013 Convolutional Neural Networks for MATLAB", "author": ["Vedaldi", "Lenc2015] Andrea Vedaldi", "Karel Lenc"], "venue": "Proceeding of the ACM Int. Conf. on Multimedia", "citeRegEx": "Vedaldi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vedaldi et al\\.", "year": 2015}, {"title": "Emergence of gricean maxims from multi-agent decision theory", "author": ["Vogel et al.2013] Adam Vogel", "Max Bodoia", "Christopher Potts", "Daniel Jurafsky"], "venue": "In HLT-NAACL,", "citeRegEx": "Vogel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 8, "context": "Recent advances in end-to-end-trained neural network architectures have renewed interest in developing systems capable of genuine language understanding (Hermann et al., 2015; Hill et al., 2015).", "startOffset": 153, "endOffset": 194}, {"referenceID": 9, "context": "Recent advances in end-to-end-trained neural network architectures have renewed interest in developing systems capable of genuine language understanding (Hermann et al., 2015; Hill et al., 2015).", "startOffset": 153, "endOffset": 194}, {"referenceID": 18, "context": "setup (Steels, 2003; Mikolov et al., 2015).", "startOffset": 6, "endOffset": 42}, {"referenceID": 12, "context": "setup (Steels, 2003; Mikolov et al., 2015).", "startOffset": 6, "endOffset": 42}, {"referenceID": 15, "context": "Within this general picture, one fundamental aspect of meaning where communication is indeed crucial is the act of reference (Searle, 1969; Abbott, 2010), the ability to successfully talk to others about things in the external world.", "startOffset": 125, "endOffset": 153}, {"referenceID": 16, "context": "Our starting point is the Visual Attributes for Concepts Dataset (ViSA) (Silberer et al., 2013), which contains per-concept (as opposed to perimage) attributes for 500 concrete concepts (CAT, ar X iv :1 60 3.", "startOffset": 72, "endOffset": 95}, {"referenceID": 2, "context": "We extracted on average 100 images annotated with each of these concepts from ImageNet (Deng et al., 2009).", "startOffset": 87, "endOffset": 106}, {"referenceID": 3, "context": "pervised setups (Ferrari and Zisserman, 2007; Farhadi et al., 2009; Russakovsky and Fei-Fei, 2010).", "startOffset": 16, "endOffset": 98}, {"referenceID": 6, "context": "tics of attributes arises from their distinctive function within a communication system is fully in line with the classic structuralist view of linguistic meaning (Geeraerts, 2009).", "startOffset": 163, "endOffset": 180}, {"referenceID": 16, "context": "We report moreover the best F1 score of Silberer et al. (2013), who learn a SVM for each", "startOffset": 40, "endOffset": 63}, {"referenceID": 10, "context": "Test stimuli Our starting point is the ReferIt dataset (Kazemzadeh et al., 2014), consisting of REs denoting objects (delimited by bounding boxes) in natural images.", "startOffset": 55, "endOffset": 80}, {"referenceID": 7, "context": "We are currently working towards adding communication (thus simulating a speaker-listener scenario (Golland et al., 2010)) and natural language to the picture.", "startOffset": 99, "endOffset": 121}], "year": 2017, "abstractText": "As a first step towards agents learning to communicate about their visual environment, we propose a system that, given visual representations of a referent (cat) and a context (sofa), identifies their discriminative attributes, i.e., properties that distinguish them (has_tail). Moreover, despite the lack of direct supervision at the attribute level, the model learns to assign plausible attributes to objects (sofa-has_cushion). Finally, we present a preliminary experiment confirming the referential success of the predicted discriminative attributes.", "creator": "LaTeX with hyperref package"}}}