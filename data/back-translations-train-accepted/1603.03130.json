{"id": "1603.03130", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Mar-2016", "title": "Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning", "abstract": "In PU learning, a binary classifier is trained only from positive (P) and unlabeled (U) data without negative (N) data. Although N data is missing, it sometimes outperforms PN learning (i.e., supervised learning) in experiments. In this paper, we theoretically compare PU (and the opposite NU) learning against PN learning, and prove that, one of PU and NU learning given infinite U data will almost always improve on PN learning. Our theoretical finding is also validated experimentally.", "histories": [["v1", "Thu, 10 Mar 2016 02:53:52 GMT  (47kb)", "https://arxiv.org/abs/1603.03130v1", null], ["v2", "Mon, 23 May 2016 04:35:47 GMT  (169kb,D)", "http://arxiv.org/abs/1603.03130v2", null], ["v3", "Fri, 28 Oct 2016 13:37:46 GMT  (169kb,D)", "http://arxiv.org/abs/1603.03130v3", "NIPS 2016 camera-ready version"]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["gang niu", "marthinus christoffel du plessis", "tomoya sakai", "yao ma", "masashi sugiyama"], "accepted": true, "id": "1603.03130"}, "pdf": {"name": "1603.03130.pdf", "metadata": {"source": "CRF", "title": "Theoretical Comparisons of Positive-Unlabeled Learning against Positive-Negative Learning", "authors": ["Gang Niu", "Marthinus C. du Plessis", "Tomoya Sakai", "Yao Ma", "Masashi Sugiyama"], "emails": ["gang@ms.,", "christo@ms.,", "sakai@ms.,", "yao@ms.,"], "sections": [{"heading": "1 Introduction", "text": "It is not as if PU learning is an open problem, that it is sometimes even better than PN learning (i.e. that proper, supervised learning in practice may be associated with prior class changes [12]), yet there is neither theoretical nor experimental analysis of this phenomenon, and it is likely that PU learning outperforms PN learning. We clarify this question on this issue. Problem Settings For PU learning, there are two problem settings based on one sample (OS) and two samples (TS) of data."}, {"heading": "2 Unbiased estimators to the risk", "text": "For convenience, specify p + (x) = p (x | Y = + 1) and p \u2212 (x) = p (x | Y = \u2212 1) partial marginal densities. Note that instead of data queried from p (x, y), three sets of data X +, X \u2212 and Xu (consisting of three marginal densities p + (x), p \u2212 g (x) and p (x) are considered independently of each other. Let g: Rd \u2192 R are a real-rated binary classification decision and \": R \u00b7 {\u00b1 1} \u2192 R are a lip-tip continuous loss function. Denote byR + (g) = E + ['(g), R \u2212 g) = E \u2212 (g) = (g) (X), partial risks, where E \u00b1 1), where E \u00b1 [\u00b7] = EX \u00b1 p \u00b1."}, {"heading": "3 Theoretical comparisons based on risk bounds", "text": "When it comes to learning, we assume that we are given a function class G, and let g * = arg m \u00b2 (G) be the optimal decision function in G, g \u00b2 pn = arg m \u00b2 pn (g), g \u00b2 pu = arg m \u00b2 pu (g), and g \u00b2 nu = arg m \u00b2 pu (g). < pn (g) are any global minimizers for three risk estimators. In this section, we guide and compare risk limits of three risk evaluators g \u00b2 pn, g \u00b2 pu, and g \u00b2 nu (g) to the Bayes risks w.r.t. 'and' 01, where the infimum of g exceeds all measurable functions. \u2212 n In this section, we refer and compare risk limits of three risk evaluators g \u00b2 pn, g \u00b2 pu, and g \u00b2 nu (g) under the following mild assumptions of G, p (x), p + (x), and p \u2212 p (x): there is a constant G \u00b2 of such risk > nn."}, {"heading": "3.1 Risk bounds", "text": "Let us see the Lipschitz constant of \"in its first parameter\" so that the probability that it is at least 1 / 2 percent is low. (We establish the learning guarantee of g + 4 (the proof can be found in Appendix A). (Theorem 2 \u2212 \u2212 \u2212 G) For any other solution > 0, with a probability of at least 1 \u2212 3, 2R (g) n. (G) n. (G) n. (G) n. (G) n. (G) n. (G) n. (G) + 2p. (G) n. (4 / 3) n. (G) n. (4 / 4) n. (G) n. (4 / 4) n. (G) n. (4 / 4) n. (n.) n. (G) n. (4) n. (n.) n. (4) n. (4) n. (n. (G) n. (4) n. (4) n. (n.) n. (4) n. (n. (G) n. (4) n. (n.) n. (4) n. (n. (G) n. (4) n."}, {"heading": "3.2 Finite-sample comparisons", "text": "Note that three risk minimizers g'pn, g'pu, and g'nu work on similar issues and their limits are assigned exactly the same detection method in Corollary 5. Then, the boundary differences reflect the intrinsic differences between risk minimizers. Let's compare these boundaries."}, {"heading": "3.3 Asymptotic comparisons", "text": "In practice, we can find that g-pu is worse than g-pn and p-pu, pn > 1 given X +, X \u2212 and Xu. This is probably the consequence, especially if nu is not sufficiently larger than n + and n \u2212. Should we then try to collect much more U data or simply forgo PU learning? Furthermore, if we are able to have as much U data as possible, is there a solution that is demonstrably better than PN learning? We answer these questions by asymptotic comparisons. Notice that each pair of (n +, nu) has a value of RHS of (12), each (n \u2212) yields a value of RHS of (11), and consequently each triple of (n +, n \u2212, nu) determines a value of RPU properties of (n)."}, {"heading": "3.4 Remarks", "text": "Theorem 2 is based on a fundamental problem of uniform deviation from the risk estimator R-pu (g) to the risk R-pu (g): Lemma 8. For each \u03b4 > 0, with a probability of at least 1 \u2212 \u03b4, supg-G | R-pu (g) \u2212 R (g) | \u2264 4\u03c0L'Rn +, p + (G) + 2L'Rnu, p (G) + 2\u03c0 ln (4 / \u03b4) 2n + \u221a ln (4 / \u03b4) 2nu.In Lemma 8, R (g) w.r.t. p (x, y), although R-pu (g) w.r.t. p + (x) and p (x).t. complex. Rademaker complexities are also w.r.t. p + (x) and p (x), and they can easily be implied for theorems 6 and 7. Theorems 6 and 7 rely on (5).Thanks to it, we can simplify theorems Y and the fact that the majority does not (G)."}, {"heading": "4 Experiments", "text": "In this area, we are able to validate our theoretical knowledge on three levels. (...) In this area, we are able to analyze our theoretical knowledge on three levels. (...) In this area, we are able to analyze the data on three levels. (...) In this area, we are able to analyze the data on three levels. (...) In this area, we are able to analyze the data on three levels. (...) In this area, we are able to analyze the data on three levels. (...) In this area, we are able to analyze the data on three levels. (...) In this area, we are able to analyze the data on three levels. (...) The model contains one million data that are drawn from p (...). (...) The model g (...) is the normal distribution with the mean and the covariance. (...)"}, {"heading": "5 Conclusions", "text": "In this paper, we investigated a fundamental problem in PU learning, namely when PU learning is likely to outperform PN learning. Risk minimizer error limits were established in PN, PU and NU learning. We found that the PU (or NU) limit is narrower than the PN limit if \u03b1pu, pn in (14) (or \u03b1nu, pn in (15)) is smaller than one (see Theorem 6); either the limit of \u03b1pu, pn or \u03b1nu, pn will be smaller than one if the size of the U data increases faster than the size of the P and N data (see Theorem 7). We experimentally validated our theoretical results using an artificial dataset and nine benchmark data."}, {"heading": "Acknowledgments", "text": "GN was supported by the JST CREST program and Microsoft Research Asia. MCdP, YM and MS were supported by the JST CREST program. TS was supported by JSPS KAKENHI 15J09111."}, {"heading": "A Proofs", "text": "In this appendix, we occupy theorem 1 in section 2, and Lemma 8, theorem 2, and corollary 5 in section 3. The proofs of theorems 3 and 4 are omitted because they are essentially similar to theorem 2, which are based on slightly different uniform deviation boundaries. A.1 Proof theorem 1The proof is simple. Denote for theorem (g) + (x) = p (Y = + 1 | X = x), \u03c0 \u2212 (x) = p (Y = 1 | X = x), then the conditional risk is EY ['sr (X), Y) | X = x = x (x) \u2212 s probability (x)."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "In PU learning, a binary classifier is trained from positive (P) and unlabeled (U) data<lb>without negative (N) data. Although N data is missing, it sometimes outperforms<lb>PN learning (i.e., ordinary supervised learning). Hitherto, neither theoretical nor<lb>experimental analysis has been given to explain this phenomenon. In this paper,<lb>we theoretically compare PU (and NU) learning against PN learning based on the<lb>upper bounds on estimation errors. We find simple conditions when PU and NU<lb>learning are likely to outperform PN learning, and we prove that, in terms of the<lb>upper bounds, either PU or NU learning (depending on the class-prior probability<lb>and the sizes of P and N data) given infinite U data will improve on PN learning.<lb>Our theoretical findings well agree with the experimental results on artificial and<lb>benchmark data even when the experimental setup does not match the theoretical<lb>assumptions exactly.", "creator": "LaTeX with hyperref package"}}}