{"id": "1603.03515", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Mar-2016", "title": "Near-Optimal Active Learning of Halfspaces via Query Synthesis in the Noisy Setting", "abstract": "In this paper, we consider the problem of actively learning a linear classifier through query synthesis where the learner can construct artificial queries in order to estimate the true decision boundaries. This problem has recently gained a lot of interest in automated science and adversarial reverse engineering for which only heuristic algorithms are known. In such applications, queries can be constructed de novo to elicit information (e.g., automated science) or to evade detection with minimal cost (e.g., adversarial reverse engineering).", "histories": [["v1", "Fri, 11 Mar 2016 04:18:48 GMT  (7790kb)", "http://arxiv.org/abs/1603.03515v1", null], ["v2", "Sat, 12 Nov 2016 17:39:47 GMT  (6921kb)", "http://arxiv.org/abs/1603.03515v2", "Accepted by AAAI 2017"]], "reviews": [], "SUBJECTS": "cs.AI cs.IT cs.LG math.IT", "authors": ["lin chen 0003", "seyed hamed hassani", "amin karbasi"], "accepted": true, "id": "1603.03515"}, "pdf": {"name": "1603.03515.pdf", "metadata": {"source": "CRF", "title": "Dimension Coupling: Optimal Active Learning of Halfspaces via Query Synthesis", "authors": ["Lin Chen", "Hamed Hassani", "Amin Karbasi"], "emails": [], "sections": [{"heading": null, "text": "ar Xiv: 160 3.03 515v 1 [cs.A I] We are developing a general framework, the so-called Dimensional Coupling (DC), which 1) reduces a d-dimensional learning problem to d-1 low-dimensional sub-problems, 2) efficiently solves each sub-problem, and 3) aggregates the results appropriately and produces a linear classifier. We are looking at the three most common scenarios in literature: idealized noise-free, independent noise adjustments and agnostic settings. We are showing that the DC framework avoids the curse of dimensionality: its computational complexity scales linearly with the dimension in all three cases. Furthermore, in the noiseless and noisy cases, we are showing that the quantum complexity of DC is nearly optimal (within a constant factor of the optimal algorithm). We are also developing an agnostic variant of DC, for which we offer strong theoretical guarantees. To further support our theoretical analysis, we are comparing the performance of DC with the three common concepts we often run faster in all three terms."}, {"heading": "Introduction", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to integrate themselves, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they, in which they live, in which they live, in which they are able to move, in which they are able to integrate themselves, and in which they are able to put themselves in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they"}, {"heading": "Problem Formulation", "text": "Our goal is to estimate an unknown half-space H * = {x-Rd: \u0445 h *, x-R > Y \u00b2, with as few queries as possible. < p-R-R is the standard inner product of Euclidean space (hence it also denotes the Euclidean norm), h-R is any (hidden) unit vector we want to estimate, and a generic query is the form symbol. p-R-R-R is the form symbol. p-R-R-R is the only thing we get from a query, the sign of the inner product, not the value. E.g. the query of the form symbol. x-R-R-R-R is the ith standard base vector, where ei-R-R reveals only the sign of the ith component of the h symbol (and nothing more about its value)."}, {"heading": "Dimension Coupling Based Framework", "text": "& & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & # 160; & & # 160; & # 160; & # 160; & # 160;"}, {"heading": "Empirical Results", "text": "Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Samply-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Samply-Sampling-Sampling-Sampling-Sampling-Sampling-Sampling-Samply-Sampling-Sampling-Sampling-Sampling-Sampling-Samply-Sampling-Sampling-Samp"}, {"heading": "Appendix A: Proof of Theorem 2", "text": "It is therefore not difficult to confirm that DC (1) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2 (2) -2) (2) -2 (2) -2 (2) -2) (2) -2) (2) -2) (2) -2 (2) -2 (2) -2)."}, {"heading": "Appendix B: Proof of Theorem 4", "text": "The two parts are: (i) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: (i) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: (i) Preferred part: all h) Preferred part: all h) Preferred part: all h (i) Preferred part: (i) Preferred part: all h) Preferred part: all h) Preferred part: all h (i) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: all h) Preferred part: all h (i) Preferred part: (i) Preferred part: (i) Preferred part: (i) Preferred part: (i) Preferred part (i)."}, {"heading": "Appendix C: Proof of Theorem 5", "text": "First we consider Pr [R (h) > min {R (h1), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (2), R (2), R (2), R (2), R (2), R (2), R (2, 2, R, 2, 2, R (2), R (2, 2), R (2), R (2, 2), R (2, 2), R (2, 2), R (2), R (2, 2), R (2), R (2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R, R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h2), R (h"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "<lb>In this paper, we consider the problem of actively learning a linear classifier<lb>through query synthesis where the learner can construct artificial queries in order<lb>to estimate the true decision boundaries. This problem has recently gained a lot of<lb>interest in automated science and adversarial reverse engineering for which only<lb>heuristic algorithms are known. In such applications, queries can be constructed<lb>de novo to elicit information (e.g., automated science) or to evade detection with<lb>minimal cost (e.g., adversarial reverse engineering).<lb>We develop a general framework, called dimension coupling (DC), that 1) re-<lb>duces a d-dimensional learning problem to d \u2212 1 low-dimensional sub-problems,<lb>2) solves each sub-problem efficiently, and 3) appropriately aggregates the results<lb>and outputs a linear classifier. We consider the three most common scenarios in<lb>the literature: idealized noise-free, independent noise realizations, and agnostic<lb>settings. We show that the DC framework avoids the curse of dimensionality: its<lb>computational complexity in all three cases scales linearly with the dimension.<lb>Moreover, in the noiseless and noisy cases, we show that the query complexity of<lb>DC is near optimal (within a constant factor of the optimum algorithm). We also<lb>develop an agnostic variant of DC for which we provide strong theoretical guaran-<lb>tees. To further support our theoretical analysis, we compare the performance of<lb>DC with the existing work in all three settings. We observe that DC consistently<lb>outperforms the prior arts in terms of query complexity while often running orders<lb>of magnitude faster.", "creator": "LaTeX with hyperref package"}}}