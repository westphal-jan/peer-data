{"id": "1603.05157", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2016", "title": "Comparing Convolutional Neural Networks to Traditional Models for Slot Filling", "abstract": "We address relation classification in the context of slot filling, the task of finding and evaluating fillers like \"Steve Jobs\" for the slot X in \"X founded Apple\". We propose a convolutional neural network which splits the input sentence into three parts according to the relation arguments and compare it to state-of-the-art and traditional approaches of relation classification. Finally, we combine different methods and show that the combination is better than individual approaches. We also analyze the effect of genre differences on performance.", "histories": [["v1", "Wed, 16 Mar 2016 16:02:03 GMT  (80kb,D)", "http://arxiv.org/abs/1603.05157v1", "NAACL 2016"], ["v2", "Mon, 4 Apr 2016 14:54:28 GMT  (80kb,D)", "http://arxiv.org/abs/1603.05157v2", "NAACL 2016"]], "COMMENTS": "NAACL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["heike adel", "benjamin roth", "hinrich sch\u00fctze"], "accepted": true, "id": "1603.05157"}, "pdf": {"name": "1603.05157.pdf", "metadata": {"source": "CRF", "title": "Comparing Convolutional Neural Networks to Traditional Models for Slot Filling", "authors": ["Heike Adel"], "emails": ["heike@cis.lmu.de"], "sections": [{"heading": "1 Introduction", "text": "The only question is how it came to be that these two are people who have settled in another country. (...) The only question is whether they are people who live in a different country than in another country. (...) The only question is whether they are people who live in another country. (...) The only question is whether they are people who live in another country. (...) The only question is whether they are people who live in another country. (...) The only question is whether they are people who live in another country. (...) The only question is whether they are people who live in another country. (...) The only question is whether they are people who live in another country. (...) The only question is whether they are people \"who live in another country.\" (...) The only question is whether they are people \"who live in another country.\" (...) The only question is \"(...) The only question is about people.\" (...) The only question is about people. (...) The only question is about people. (...) The only question is about people. (...) The only about people. (...) The only question is about people. (... It is about people. (...) The only about people. (It is about.) The only about people. (It is about people. (...) The only about. (It is about.) The only about people. (It is about people. (It is about.) The only about people. (It is about people. (It is about...) The question. (It is about people. (It is about.) The only about people. (It is about.) The question. (It is about people."}, {"heading": "2 Related work", "text": "Participants in the SF Shared Task (Surdeanu, 2013) are classified with a large body of text. For evaluation, they receive a collection of queries and must provide fillers for predefined relationships and an offset of a context that can serve as justification. Most participants use pipeline-based systems. Rosa et al. (2014) analyzed sources of recalls in these pipelines. Results of the systems show the difficulty of the task: In the 2014 evaluation, the top-rated system had a formula of.37 (Angeli et al., 2014a). To train their models, most groups use remote supervision (Mintz et al., 2009). The top-ranked systems use machine learning rather than manually developed patterns or models (Surdeanu and Ji, 2014). Methods for extracting and scoring candidates range from patterns (Gonza, lez et al., 2012; Liu and Zhao, 2012; al; Li)."}, {"heading": "3 Challenges of slot filling", "text": "Faced with a large body of evaluation, systems must first find documents relevant to the entity of the query, including challenges such as alternative names for the same entity, spelling errors of names and ambiguous names (different entities with the same name), and then extract sentences mentioning the entity for each relevant document, as well as possible fillers for the given entity. In most cases, these tasks use co-ordinate resolution and entity recognition tools. Finally, systems must decide which filler candidate should be issued as the solution for the given entity, a step that can be reduced to the classification of relations. It is one of the most important parts of the entire pipeline as it directly affects the quality of the entity. Finally, the most important challenges for classifying the relationship to the entity's entity's entity's entity's entity's entity's entity entification are little or loud (widely monitored) training data, data from different domains, and test sets that have been extracted from a pipeline of different NLP components."}, {"heading": "4 Models for relation classification", "text": "The first approach we evaluate is pattern matching. For a particular set, pattern matching is not considered correct if one of the patterns matches; otherwise, the candidate is rejected. Specifically, we apply two different pattern sets: the first set consists of patterns learned by remote control (PATdist), which are used in the SF challenge (Riedel et al., 2013); the second set contains patterns of universal schema relationships for the SF task (PATuschema); and universal schema relationships are extracted based on matrix factorization (Riedel et al, 2013). In this thesis, we apply the universal schema patterns extracted by Roth et al. (2014).Support vector machines (SVMs). We evaluate two different feature sets: bag-of-word features features (SVMbow) and skip n-gram features."}, {"heading": "5 Experiments and results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Training data", "text": "We have created a series of (subject, relationship, object) tuples by querying Freebase (Bollacker et al., 2008) for relationships that correspond to one of the tuples: (i) the TAC source corpus (TAC, 2014), (ii) a snapshot of Wikipedia (May 2014), (iii) the freebase description fields, (iv) a subset of Clueweb2, (v) a New York Times corpus (LDC2008T19). The resulting sentences are positive training examples. Based on the tuples set, we have selected negative examples by searching the company for judgments that contain (i) a mention of a name that occurs in a tuple, (ii) do not contain the correct training example."}, {"heading": "5.2 Evaluation data", "text": "One of the most important challenges in building and evaluating classification models for SF is the lack of training and evaluation data. Each group has its own data sets and comparisons for groups that are difficult. Therefore, we have developed a script that creates a clean data set based on manually annotated system evaluations. In the future, it can be used by all participants to evaluate components for their slot filling systems."}, {"heading": "5.3 Experiments", "text": "In fact, we are able to put ourselves at the top of the group in the way that we have put ourselves at the top of the group we are in."}, {"heading": "6 Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Contribution of each model", "text": "To see how much each model contributes to the CMB, we count how often each weight between 0.0 and 1.0 is selected for linear interpolation, and the results are plotted as histograms (Figure 2). A weight of 0.0 means that the corresponding model does not contribute to the CMB. We see that all three models contribute to the CMB for most of the slots. CNN, for example, is included in the combination for 14 of the 24 slots, improving performance on these slots."}, {"heading": "6.2 Comparison of CNN to traditional models", "text": "To study this effect, we select for each CNN the five best cores whose activation correlates most strongly with the end result of the positive class. Then, we calculate which n-grams of these cores are selected in the maximum pooling step. This corresponds to those n-grams recognized by the kernel as the most meaningful for the given slot. Figure 3 shows the result for an example sentence expressing the slot relation: Parents. The height of a bar is the number of times the 3-gram around the corresponding word has been selected by k-max pooling; for example, the bar above \"newest\" corresponds to the tri-gram \"of its newest subsidiary.\" The figure shows that the revolutionary filters are able to learn sentences that trigger a relationship."}, {"heading": "6.3 Correlation with end-to-end results", "text": "In this section, we show that the use of the dataset we provide with this work enables us to tune classification models for the end-to-end SF task. For each model and any combination of models, we calculate averages on our assessment set and final F1 values when operating the entire slot fill pipeline with our internal system. The best results of our slot fill system are an F1 of.290 for the 2013 queries and.250 for the 2014 queries. We calculate Pearson's correlation coefficients to evaluate the correlation between relation classification and end-to-end performance for the n different system configurations (i.e. model combinations).The correlation of the results on our evaluation dataset with the SF results in 2013 queries is.89, which correlates with the SF results in 2014 queries. 82. This confirms that good results on the dataset we propose lead to good results in the task-to-end."}, {"heading": "6.4 Effect of genre and time", "text": "The distribution of these different genres in the extracted rating data is as follows: 2012 / 3 2014 News 87.5% 73.4% Web + Forums 12.5% 26.6% The share of non-news has more than doubled from 12.5% to 26.6%. So when we use 2012 / 2013 as development and 2014 as testing, we face a domain adaptation problem. In this section, we detail the impact of domain differences on our models. For our genre analysis, we retrain our models to use genre-specific training kits WEB and NEWS 6 and use cross-genre ratings to show that performance differences due to different training kits are avoided."}, {"heading": "7 Conclusion", "text": "In this paper, we presented different approaches to classifying slot fill ratios: patterns, support vector machines, and Convolutionary Neural Networks. We examined their complementary strengths and weaknesses, and demonstrated that their combination can better deal with a variety of problems posed by slot filling than any single approach. We proposed a context-sensitive CNN that surpasses the current state of the art piecemeal. In addition, we analyzed the impact of the genre on slot filling and showed that it needs to be thoroughly investigated in slot filling research. Finally, we provided a benchmark for classifying slot fill relationships that will facilitate direct comparisons of approaches in the future."}, {"heading": "8 Additional Resources", "text": "We publish the scripts we have developed to extract the annotated evaluation data and our splits by genre and year, as well as the dev / evaluation splits. In addition, we provide a detailed distribution of positive and negative examples in the evaluation data."}, {"heading": "Acknowledgments", "text": "Heike Adel is a scholarship holder of the Google European Doctoral Fellowship in Natural Language Processing and this research is supported by this Fellowship. We thank Gabor Angeli for his active support with the Mintz + + and MIMLRE models."}], "references": [{"title": "Combining distant and partial supervision for relation extraction", "author": ["Angeli et al.2014b] Gabor Angeli", "Julie Tibshirani", "Jean Y. Wu", "Christopher D. Manning"], "venue": null, "citeRegEx": "Angeli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Angeli et al\\.", "year": 2014}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor"], "venue": "In ACM SIGMOD", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Natural language processing (almost) from scratch. JMLR", "author": ["Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": null, "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Classifying relations by ranking with convolutional neural networks", "author": ["Bing Xiang", "Bowen Zhou"], "venue": null, "citeRegEx": "Santos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Santos et al\\.", "year": 2015}, {"title": "LIBLINEAR: A library for large linear classification", "author": ["Fan et al.2008] Rong-En Fan", "Kai-Wei Chang", "Cho-Jui Hsieh", "Xiang-Rui Wang", "Chih-Jen Lin"], "venue": null, "citeRegEx": "Fan et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Fan et al\\.", "year": 2008}, {"title": "Mixture-model adaptation for SMT", "author": ["Foster", "Kuhn2007] George Foster", "Roland Kuhn"], "venue": "In Workshop on SMT", "citeRegEx": "Foster et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Foster et al\\.", "year": 2007}, {"title": "Domain adaptation for largescale sentiment classification: A deep learning approach", "author": ["Glorot et al.2011] Xavier Glorot", "Antoine Bordes", "Yoshua Bengio"], "venue": null, "citeRegEx": "Glorot et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "The TALP participation at TAC-KBP", "author": ["E. Sapena", "M. Vila", "M.A. Mart\u0131"], "venue": "In TAC", "citeRegEx": "Sapena et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sapena et al\\.", "year": 2012}, {"title": "Semeval-2010 task 8: Multi-way classification of semantic relations", "author": ["Su Nam Kim", "Zornitsa Kozareva", "Preslav Nakov", "Diarmuid \u00d3 S\u00e9aghdha", "Sebastian Pad\u00f3", "Marco Pennacchiotti", "Lorenza Romano", "Stan Szpakowicz"], "venue": null, "citeRegEx": "Hendrickx et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Hendrickx et al\\.", "year": 2010}, {"title": "A convolutional neural network for modelling sentences", "author": ["Edward Grefenstette", "Phil Blunsom"], "venue": null, "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Sweat2012: Pattern based English slot filling system for knowledge base population at TAC", "author": ["Liu", "Zhao2012] Fang Liu", "Jun Zhao"], "venue": "In TAC", "citeRegEx": "Liu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Slot-filling by substring extraction at tac kbp 2012 (team papelo)", "author": ["Bing Bai", "Kazi Saidul Hasan"], "venue": "In TAC", "citeRegEx": "Malon et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Malon et al\\.", "year": 2012}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Efficient estimation of word representations in vector space. In Workshop at ICLR", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "New york university 2012 system for KBP slot filling", "author": ["Min et al.2012] Bonan Min", "Xiang Li", "Ralph Grishman", "Ang Sun"], "venue": "In TAC", "citeRegEx": "Min et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Min et al\\.", "year": 2012}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mintz et al.2009] Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky"], "venue": "ACL/IJCNLP", "citeRegEx": "Mintz et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Overview of the 2012 shared task on parsing the web", "author": ["Petrov", "McDonald2012] Slav Petrov", "Ryan McDonald"], "venue": "SANCL", "citeRegEx": "Petrov et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Petrov et al\\.", "year": 2012}, {"title": "Analysing recall loss in named entity slot filling", "author": ["Pink et al.2014] Glen Pink", "Joel Nothman", "James R Curran"], "venue": null, "citeRegEx": "Pink et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pink et al\\.", "year": 2014}, {"title": "GDUFS at slot filling TAC-KBP", "author": ["Qiu et al.2012] Xin Ying Qiu", "Xiaoting Li", "Weijian Mo", "Manli Zheng", "Zhuhe Zheng"], "venue": "In TAC", "citeRegEx": "Qiu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Qiu et al\\.", "year": 2012}, {"title": "Relation extraction with matrix factorization and universal schemas", "author": ["Limin Yao", "Andrew McCallum", "Benjamin M Marlin"], "venue": "In HLT-NAACL", "citeRegEx": "Riedel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2013}, {"title": "Effective slot filling based on shallow distant supervision methods", "author": ["Roth et al.2013] Benjamin Roth", "Tassilo Barth", "Michael Wiegand", "Mittul Singh", "Dietrich Klakow"], "venue": "In TAC", "citeRegEx": "Roth et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2013}, {"title": "Universal schema for slotfilling, cold-start kbp and event argument extraction: UMAss IESL at TAC KBP", "author": ["Roth et al.2014] Benjamin Roth", "Emma Strubell", "John Sullivan", "Lakshmi Vikraman", "Kate Silverstein", "Andrew McCallum"], "venue": "In TAC", "citeRegEx": "Roth et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Roth et al\\.", "year": 2014}, {"title": "Overview of the English slot filling track at the TAC 2014 knowledge base population evaluation", "author": ["Surdeanu", "Ji2014] Mihai Surdeanu", "Heng Ji"], "venue": "In TAC", "citeRegEx": "Surdeanu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2014}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["Julie Tibshirani", "Ramesh Nallapati", "Christopher D Manning"], "venue": "In Joint Conference on EMNLP and CoNLL", "citeRegEx": "Surdeanu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "Overview of the tac2013 knowledge base population evaluation: English slot filling and temporal slot filling", "author": ["Mihai Surdeanu"], "venue": "In TAC", "citeRegEx": "Surdeanu.,? \\Q2013\\E", "shortCiteRegEx": "Surdeanu.", "year": 2013}, {"title": "Stacked ensembles of information extractors for knowledge-base population", "author": ["Viswanathan", "Nazneen Fatema Rajani", "Yinon Bentor", "Raymond Mooney."], "venue": "ACL.", "citeRegEx": "Viswanathan et al\\.,? 2015", "shortCiteRegEx": "Viswanathan et al\\.", "year": 2015}, {"title": "Relation classification via convolutional deep neural network. In COLING", "author": ["Zeng et al.2014] Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao"], "venue": null, "citeRegEx": "Zeng et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2014}, {"title": "Distant supervision for relation extraction via piecewise convolutional neural networks", "author": ["Zeng et al.2015] Daojian Zeng", "Kang Liu", "Yubo Chen", "Jun Zhao"], "venue": null, "citeRegEx": "Zeng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zeng et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 13, "context": "Furthermore, they make use of word embeddings that directly reflect word similarity (Mikolov et al., 2013).", "startOffset": 84, "endOffset": 106}, {"referenceID": 27, "context": "In this work, we train different variants of CNNs: As a baseline, we re-implement the recently developed piecewise CNN (Zeng et al., 2015).", "startOffset": 119, "endOffset": 138}, {"referenceID": 18, "context": "Riedel et al. (2013), Hendrickx et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 8, "context": "(2013), Hendrickx et al. (2010)) since data and relations can be quite different.", "startOffset": 8, "endOffset": 32}, {"referenceID": 17, "context": "The official SF Shared Task evaluations only assess whole systems (with potential subsequent faults in their pipelines (Pink et al., 2014)).", "startOffset": 119, "endOffset": 138}, {"referenceID": 24, "context": "The participants of the SF Shared Task (Surdeanu, 2013) are provided with a large text corpus.", "startOffset": 39, "endOffset": 55}, {"referenceID": 15, "context": "To train their models, most groups use distant supervision (Mintz et al., 2009).", "startOffset": 59, "endOffset": 79}, {"referenceID": 18, "context": "The methods for extracting and scoring candidates range from pattern based approaches (Gonz\u00e0lez et al., 2012; Liu and Zhao, 2012; Li et al., 2012; Qiu et al., 2012; Roth et al., 2014) over rule based systems (Varma et al.", "startOffset": 86, "endOffset": 183}, {"referenceID": 21, "context": "The methods for extracting and scoring candidates range from pattern based approaches (Gonz\u00e0lez et al., 2012; Liu and Zhao, 2012; Li et al., 2012; Qiu et al., 2012; Roth et al., 2014) over rule based systems (Varma et al.", "startOffset": 86, "endOffset": 183}, {"referenceID": 11, "context": ", 2012) to classifiers (Malon et al., 2012; Roth et al., 2013).", "startOffset": 23, "endOffset": 62}, {"referenceID": 20, "context": ", 2012) to classifiers (Malon et al., 2012; Roth et al., 2013).", "startOffset": 23, "endOffset": 62}, {"referenceID": 14, "context": "Pink et al. (2014) analyzed sources of recall losses in these pipelines.", "startOffset": 0, "endOffset": 19}, {"referenceID": 20, "context": "dates (Roth et al., 2013); their results suggest that n-gram based features are sufficient to build reliable classifiers for the relation classification module.", "startOffset": 6, "endOffset": 25}, {"referenceID": 19, "context": "dates (Roth et al., 2013); their results suggest that n-gram based features are sufficient to build reliable classifiers for the relation classification module. They also show that SVMs outperform patterns. CNNs and baseline models for relation classification. Zeng et al. (2014) and Dos Santos et al.", "startOffset": 7, "endOffset": 280}, {"referenceID": 3, "context": "(2014) and Dos Santos et al. (2015) applied CNNs to the relation classification SemEval Shared Task data from 2010 and showed", "startOffset": 15, "endOffset": 36}, {"referenceID": 11, "context": "Malon et al. (2012) described a CNN for slot filling that is based on the output of a parser.", "startOffset": 0, "endOffset": 20}, {"referenceID": 15, "context": "Mintz++ (Mintz et al., 2009; Surdeanu et al., 2012) and MIMLRE (Surdeanu et al.", "startOffset": 8, "endOffset": 51}, {"referenceID": 23, "context": "Mintz++ (Mintz et al., 2009; Surdeanu et al., 2012) and MIMLRE (Surdeanu et al.", "startOffset": 8, "endOffset": 51}, {"referenceID": 23, "context": ", 2012) and MIMLRE (Surdeanu et al., 2012).", "startOffset": 19, "endOffset": 42}, {"referenceID": 15, "context": "Mintz++ (Mintz et al., 2009; Surdeanu et al., 2012) and MIMLRE (Surdeanu et al., 2012). Mintz++ is a model based on the Mintz features (lexical and syntactic features for relation extraction). It was developed by Surdeanu et al. (2012) and used as a base-", "startOffset": 9, "endOffset": 236}, {"referenceID": 27, "context": "Another baseline model which we use in this work is a piecewise convolutional neural network (Zeng et al., 2015).", "startOffset": 93, "endOffset": 112}, {"referenceID": 6, "context": "ied (Glorot et al., 2011; Foster and Kuhn, 2007).", "startOffset": 4, "endOffset": 48}, {"referenceID": 20, "context": "They have been used in the SF challenge by the topranked system in the 2013 Shared Task (Roth et al., 2013).", "startOffset": 88, "endOffset": 107}, {"referenceID": 19, "context": "Universal schema relations are extracted based on matrix factorization (Riedel et al., 2013).", "startOffset": 71, "endOffset": 92}, {"referenceID": 20, "context": "work, we apply the universal schema patterns extracted for slot filling by Roth et al. (2014). Support vector machines (SVMs).", "startOffset": 75, "endOffset": 94}, {"referenceID": 20, "context": "work, we apply the universal schema patterns extracted for slot filling by Roth et al. (2014). Support vector machines (SVMs). Our second approach is support vector machines. We evaluate two different feature sets: bag-of-word features (SVMbow) and skip n-gram features (SVMskip). Based on the results of Roth et al. (2013), we", "startOffset": 75, "endOffset": 324}, {"referenceID": 20, "context": "(Roth et al., 2013)).", "startOffset": 0, "endOffset": 19}, {"referenceID": 4, "context": "We train one linear SVM (Fan et al., 2008) for each relation and feature set and tune parameter C on dev.", "startOffset": 24, "endOffset": 42}, {"referenceID": 2, "context": "CNNs are increasingly applied in NLP (Collobert et al., 2011; Kalchbrenner et al., 2014).", "startOffset": 37, "endOffset": 88}, {"referenceID": 9, "context": "CNNs are increasingly applied in NLP (Collobert et al., 2011; Kalchbrenner et al., 2014).", "startOffset": 37, "endOffset": 88}, {"referenceID": 2, "context": "Max pooling (Collobert et al., 2011) detects the globally most relevant features obtained by local convolution.", "startOffset": 12, "endOffset": 36}, {"referenceID": 26, "context": "Our baseline CNN is the model developed by Zeng et al. (2015). It represents the", "startOffset": 43, "endOffset": 62}, {"referenceID": 9, "context": "1 The results of convolution are pooled using k-max pooling (Kalchbrenner et al., 2014): only the k = 3 maximum values of each filter application are kept.", "startOffset": 60, "endOffset": 87}, {"referenceID": 25, "context": "For a comparison of different combination possibilities, see, for example, (Viswanathan et al., 2015).", "startOffset": 75, "endOffset": 101}, {"referenceID": 1, "context": "We created a set of (subject, relation, object) tuples by querying Freebase (Bollacker et al., 2008) for relations that correspond to one of the", "startOffset": 76, "endOffset": 100}, {"referenceID": 12, "context": "for sentences that (i) contain a mention of a name occurring in a tuple, (ii) do not contain the correct filler, (iii) contain a mention different from the correct filler, but with the same named entity type (based on CoreNLP NER (Manning et al., 2014)).", "startOffset": 230, "endOffset": 252}, {"referenceID": 0, "context": "In order to reduce incorrect labels, we applied a self-training procedure: We trained SVMs on the SF dataset created by Angeli et al. (2014b). With the resulting SVMs, we predicted labels for our training set.", "startOffset": 120, "endOffset": 142}, {"referenceID": 14, "context": "label did not match the distant supervised label, we deleted the corresponding training example (Min et al., 2012).", "startOffset": 96, "endOffset": 114}, {"referenceID": 0, "context": "org/clueweb12 We do not use the SF dataset directly because (i) it provides few examples per slot (min: 1, max: 4960) and (ii) it consists of examples for which the classifiers of Angeli et al. (2014b) were indecisive, i.", "startOffset": 180, "endOffset": 202}, {"referenceID": 27, "context": "While the baseline network CNNpiece (Zeng et al., 2015) achieves F1 of .", "startOffset": 36, "endOffset": 55}], "year": 2017, "abstractText": "We address relation classification in the context of slot filling, the task of finding and evaluating fillers like \u201cSteve Jobs\u201d for the slot X in \u201cX founded Apple\u201d. We propose a convolutional neural network which splits the input sentence into three parts according to the relation arguments and compare it to state-ofthe-art and traditional approaches of relation classification. Finally, we combine different methods and show that the combination is better than individual approaches. We also analyze the effect of genre differences on performance.", "creator": "LaTeX with hyperref package"}}}