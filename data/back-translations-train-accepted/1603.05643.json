{"id": "1603.05643", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Mar-2016", "title": "Variance Reduction for Faster Non-Convex Optimization", "abstract": "We consider the fundamental problem in non-convex optimization of efficiently reaching a stationary point. In contrast to the convex case, in the long history of this basic problem, the only known theoretical results on first-order non-convex optimization remain to be full gradient descent that converges in $O(1/\\varepsilon)$ iterations for smooth objectives, and stochastic gradient descent that converges in $O(1/\\varepsilon^2)$ iterations for objectives that are sum of smooth functions.", "histories": [["v1", "Thu, 17 Mar 2016 19:55:12 GMT  (4239kb,D)", "https://arxiv.org/abs/1603.05643v1", null], ["v2", "Thu, 25 Aug 2016 02:34:00 GMT  (4254kb,D)", "http://arxiv.org/abs/1603.05643v2", "polished writing"]], "reviews": [], "SUBJECTS": "math.OC cs.DS cs.LG cs.NE stat.ML", "authors": ["zeyuan allen zhu", "elad hazan"], "accepted": true, "id": "1603.05643"}, "pdf": {"name": "1603.05643.pdf", "metadata": {"source": "CRF", "title": "Variance Reduction for Faster Non-Convex Optimization", "authors": ["Zeyuan Allen-Zhu", "Elad Hazan"], "emails": ["zeyuan@csail.mit.edu", "ehazan@cs.princeton.edu"], "sections": [{"heading": null, "text": "We offer the first improvement in this area of research. Our result is based on the recently introduced trick for reducing variance in convex optimization and on a brand new analysis of variance reduction that is suitable for nonconvex optimization. For targets that represent the sum of smooth functions, our first-order stochastic minibatch method converges at an O (1 / \u03b5) rate and is faster than complete gradient reduction by 1 (n1 / 3).We demonstrate the effectiveness of our methods for empirical risk minimization with nonconvex loss functions and for forming neural networks."}, {"heading": "1 Introduction", "text": "Numerous machine learning problems are, of course, formulated as non-convex optimization problems, as are many others. Examples include conclusions in graphical models, unattended learning models such as theme models, dictionaries, and perhaps most noteworthy is the formation of deep neural networks. Indeed, non-convex optimization can be used for machine learning as one of the most important fronts of research. As the global minimization of non-convex functions is NP-hard, various alternative approaches are used. For some models, probable and other assumptions about the input factors, specially designed polynomial algorithms can be used [5, 6, 15]. However, the multitude and variety of machine learning applications requires a robust, generic optimization method that can be applied as a tool, rather than reinventing each specific model. One approach is the design of global non-convex heuristics such as simulated annealic or bayesian optimization."}, {"heading": "1.1 Our Result", "text": "The question of the way in which the individual countries engage with the individual countries is the question of the way in which they engage with the individual countries. (...) The question of the way in which they engage with the individual countries is not only the question of the way in which they engage with the individual countries, but also the question of the way in which they engage with the individual countries. (...) The question of the way in which they engage with the individual countries, the way in which they engage with the individual countries, the way in which they engage with the individual countries, the way in which they engage themselves, the way in which they engage themselves, the way in which they engage themselves, the way in which they engage themselves, the way in which they do not want to engage themselves. (...)"}, {"heading": "1.2 Extensions", "text": "Our result in this thesis extends trivially to the minibatch setting: if we select fi (\u00b7) for more than one random index i in each iteration, then we can define according to the gradient estimator and the result of this work remains the same. Note, however, that the speed we achieve in this case compared to the gradient descent is O ((n / b) 1 / 3, where b is the minibatch size. Therefore, the smaller b is the better sequential runtime we expect to see (which is also observed in our experiments), and other uniformity assumptions. Our result generalizes to the setting when each fi (\u00b7) enjoys a different smoothing parameter. In this setting, one must select a random index i [n] with an uneven distribution in order to obtain a faster runtime. Our result generalizes to the upper and lower veance n."}, {"heading": "1.3 Other Related Works", "text": "For convex goals, finding stationary points (or equivalent to the global minimum) for a problem (1,1) has received much attention in the machine learning and optimization communities in recent years; many first-order methods [8, 16, 23, 26] and their accelerations [1, 3, 18, 27, 28] have been proposed in recent years. Even if f (\u00b7) is convex, but each fi (\u00b7) is not convex, the problem (1,1) can be easily solved [4, 11, 24]. Algorithm 1 simplified SVRG method in the non-convex constellation Input: x\u03c6 is an initial vector, the number of epochs, m number of iterations per epoch, the step length. 1: x10 x 2: do for s 1 to s 3: 4 x 4: for fast convergence."}, {"heading": "2 Notations and Algorithm", "text": "\"We have the possibility that we will be able to see the differences between our evidence and the known results.\" \"We,\" he says, \"we.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" We. \"\" \"We.\" \".\" \".\" \"\" We. \"\" \".\" \"\" \".\" \"\" \".\" \"\" \"\". \"\" \"\". \"\" \"\" \".\" \"\" \"\". \"\" \".\" \"\" \".\" \"\" \".\"., \".,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,..,.,.,.,.,.,..,.,.,..,..,.,.,..,.,.,..,.,.,.,..,..,..,..,.,.,.,...,.,..,.,.,.,..,..,.,.,.,.,.,.,...,.,..,..,.,.,.,.,.,.,..,.,.,.,.,..,.,..,.,.,.,.,.,..,.,.,.,.,.,.,...,.,.,.,.,.,.,.,.,.,.,.,.,..,.,.,..,.,.,.,.,.,.,.,.,.,.,.,.,..,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,.,..,.,.,.,.,.,.,.,.,.,.,.,"}, {"heading": "3 Two Useful Lemmas", "text": "The first describes the expected objective decrease between two consecutive iterations. (This is a standard step used in the analysis of gradient lineage for smooth functions, and we additionally take into account the variance of gradient estimation. (This is a standard step used in the analysis of gradient lineage for some gradient estimators.) If the stride length of 1L, we havef (xk + 1) \u2212 E [f (xk + 1)] [f (xk + 1) [f)) [f (xk + 1)) [f (xk + 1)) [f) [f) [f (xk + 1)] [f (xk + 1)] [f) [f (xk + 1)] [f (f) [f) [f [f [f), xk) [f)."}, {"heading": "4 Upper Bounding the Variance", "text": "The key concepts behind all variance-reduction literatures (such as SVRG [16], SAGA [8], and SAG [23]) are to prove that variance E [3] [4], the objective distance to the minimum, is the only exception to working on the sum of non-convexic but strongly convexic objectives [4, 24], where the authors have objective-convexic objective objectives [4, 24], where the authors have objective-convexic objective objectives [4, 24] where the authors have objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-objective-convex [4"}, {"heading": "5 Final Theorem", "text": "We obtain that (x0) - E [f (xm)] - E [f (xm) - E [f (xm) - E [f (xm) - E [f (xm)] - 2 E [H20: m \u2212 1] \u2212 6 mL3d \u00b7 E [f (x0) \u2212 f (xm) - 2m0 H20: m \u2212 1]. (5,1) In other words, as long as 6throu2 m0mL 3d \u2264 12, we arrive at atf (x0) \u2212 E [f (xm) - f (xm) - 2m0 H20: m \u2212 1). (5,2) Note that (5,2) - xxmL \u2212 d \u2212 12, we arrive at atf (xm) - E [f (xm) - 6 E [f (xm) - 1 E [H20: m \u2212 1)."}, {"heading": "In other words, to obtain a point x satisfying \u2016\u2207f(x)\u20162 \u2264 \u03b5, the total number of iterations needed", "text": "for algorithm 1 is Sn = O (n2 / 3L (f (x\u03c6) \u2212 minx f (x) \u03b5). The amortized complexity per iteration of SVRG is at most twice as high as that of SGD. Therefore, this is a factor that is faster in the solution (1.1) than the method of complete gradient descent."}, {"heading": "6 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Empirical Risk Minimization with Non-Convex Loss", "text": "We look at the binary classification on four standard datasets that can be found on the website of LibSVM (10): \"We look at the binary classification on four standard datasets that can also be found on the website of LibSVM.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \"\" \"We.\" \"We.\" \"\" We. \"\" \"We.\" \"\" We. \"\" \"We.\" \"\" \"We.\" \"\" We. \"\" \"We.\" \"We.\" \"\" We. \"\" We. \"\" We. \"\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\" We. \"We.\""}, {"heading": "6.2 Neural Network", "text": "It is time for a reorientation of the Presidency of the Council of the EU, so that the Presidency of the Council of the EU will enter into force shortly in order to strengthen the Presidency of the Council of the EU."}, {"heading": "Acknowledgements", "text": "E. Hazan thanks for the support of the National Science Foundation scholarship IIS-1523815 and a Google research award. Z. Allen-Zhu thanks for the support of a Microsoft research award, no. 0518584.Appendix"}, {"heading": "A Detailed Proof", "text": "In the detailed evidence, we focus again on the analysis of a single epoch. As before, we opt for a parameter m0 that separates us."}, {"heading": "In other words, to obtain a point x satisfying \u2016\u2207f(x)\u20162 \u2264 \u03b5, the total number of iterations needed", "text": "For algorithm 1 isSn = O (n2 / 3L (f (x\u03c6) \u2212 minx f (x) \u03b5).13As with SGD, one can easily apply a Markov inequality to come to the conclusion that we probably have at least 2 / 3 the same asymptotic upper limit for deterministic magnitude."}], "references": [{"title": "Katyusha: The First Direct Acceleration of Stochastic Gradient Methods", "author": ["Zeyuan Allen-Zhu"], "venue": "ArXiv e-prints,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "Linear coupling: An ultimate unification of gradient and mirror descent", "author": ["Zeyuan Allen-Zhu", "Lorenzo Orecchia"], "venue": "ArXiv e-prints,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Even Faster Accelerated Coordinate Descent Using Non-Uniform Sampling", "author": ["Zeyuan Allen-Zhu", "Peter Richt\u00e1rik", "Zheng Qu", "Yang Yuan"], "venue": "In ICML,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Improved SVRG for Non-Strongly-Convex or Sum-of-Non- Convex Objectives", "author": ["Zeyuan Allen-Zhu", "Yang Yuan"], "venue": "In ICML,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "A practical algorithm for topic modeling with provable guarantees", "author": ["Sanjeev Arora", "Rong Ge", "Yonatan Halpern", "David M. Mimno", "Ankur Moitra", "David Sontag", "Yichen Wu", "Michael Zhu"], "venue": "In ICML,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2013}, {"title": "New algorithms for learning incoherent and overcomplete dictionaries", "author": ["Sanjeev Arora", "Rong Ge", "Ankur Moitra"], "venue": "In COLT,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Lectures on Modern Convex Optimization", "author": ["Aharon Ben-Tal", "Arkadi Nemirovski"], "venue": "Society for Industrial and Applied Mathematics,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives", "author": ["Aaron Defazio", "Francis Bach", "Simon Lacoste-Julien"], "venue": "In NIPS,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2011}, {"title": "LIBSVM Data: Classification, Regression and Multi-label", "author": ["Rong-En Fan", "Chih-Jen Lin"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Fast and simple PCA via convex optimization", "author": ["Dan Garber", "Elad Hazan"], "venue": "ArXiv e-prints,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "Escaping from saddle points\u2014online stochastic gradient for tensor decomposition", "author": ["Rong Ge", "Furong Huang", "Chi Jin", "Yang Yuan"], "venue": "In COLT,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2015}, {"title": "Accelerated gradient methods for nonconvex nonlinear and stochastic programming", "author": ["Saeed Ghadimi", "Guanghui Lan"], "venue": "Mathematical Programming,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "DRAFT: Introduction to online convex optimimization", "author": ["Elad Hazan"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "A spectral algorithm for learning hidden markov models", "author": ["Daniel Hsu", "Sham M. Kakade", "Tong Zhang"], "venue": "J. Comput. Syst. Sci.,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In NIPS,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Accelerated Proximal Gradient Methods for Nonconvex Programming", "author": ["Huan Li", "Zhouchen Lin"], "venue": "In NIPS,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "An Accelerated Proximal Coordinate Gradient Method and its Application to Regularized Empirical Risk Minimization", "author": ["Qihang Lin", "Zhaosong Lu", "Lin Xiao"], "venue": "In NIPS,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Adaptive Bound Optimization for Online Convex Optimization", "author": ["H. Brendan McMahan", "Matthew Streeter"], "venue": "In Proceedings of the 23rd Annual Conference on Learning Theory - COLT", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2010}, {"title": "Introductory Lectures on Convex Programming Volume: A Basic course, volume I", "author": ["Yurii Nesterov"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2004}, {"title": "Stochastic variance reduction for nonconvex optimization", "author": ["Sashank J. Reddi", "Ahmed Hefny", "Suvrit Sra", "Barnabas Poczos", "Alex Smola"], "venue": "ArXiv e-prints,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Fast incremental method for nonconvex optimization", "author": ["Sashank J. Reddi", "Suvrit Sra", "Barnabas Poczos", "Alex Smola"], "venue": "ArXiv e-prints,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "Minimizing finite sums with the stochastic average gradient", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "arXiv preprint arXiv:1309.2388,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "SDCA without Duality", "author": ["Shai Shalev-Shwartz"], "venue": "arXiv preprint arXiv:1502.06177,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Learning kernel-based halfspaces with the 0-1 loss", "author": ["Shai Shalev-Shwartz", "Ohad Shamir", "Karthik Sridharan"], "venue": "SIAM Journal on Computing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2011}, {"title": "Stochastic dual coordinate ascent methods for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2013}, {"title": "Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized Loss Minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "In ICML,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2014}, {"title": "Stochastic Primal-Dual Coordinate Method for Regularized Empirical Risk Minimization", "author": ["Yuchen Zhang", "Lin Xiao"], "venue": "In ICML,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "For some models, probabilistic and other assumptions on the input can be used to give specially designed polynomial-time algorithms [5, 6, 15].", "startOffset": 132, "endOffset": 142}, {"referenceID": 5, "context": "For some models, probabilistic and other assumptions on the input can be used to give specially designed polynomial-time algorithms [5, 6, 15].", "startOffset": 132, "endOffset": 142}, {"referenceID": 14, "context": "For some models, probabilistic and other assumptions on the input can be used to give specially designed polynomial-time algorithms [5, 6, 15].", "startOffset": 132, "endOffset": 142}, {"referenceID": 12, "context": "Following the classical benchmark for non-convex optimization (see for instance [13]), we focus on algorithms that can efficiently find an approximate stationary point x satisfying \u2016\u2207f(x)\u20162 \u2264 \u03b5.", "startOffset": 80, "endOffset": 84}, {"referenceID": 11, "context": "[12] also demonstrated that a simple noise-addition scheme is sufficient for stochastic gradient descent to escape from saddle points.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "This is a folklore result in optimization and included for instance in [13].", "startOffset": 71, "endOffset": 75}, {"referenceID": 12, "context": "This result is perhaps first formalized by Ghadimi and Lan [13].", "startOffset": 59, "endOffset": 63}, {"referenceID": 15, "context": "1 Our Result We prove that variance reduction techniques, based on the SVRG method [16], produce an \u03b5stationary point in only O (n2/3L(f(x0)\u2212f(x\u2217)) \u03b5 ) iterations.", "startOffset": 83, "endOffset": 87}, {"referenceID": 13, "context": "3 of [14] usually turn each fi(x) into a smooth function without sacrificing too much accuracy.", "startOffset": 5, "endOffset": 9}, {"referenceID": 15, "context": "Our proposed algorithm is very analogous to SVRG of [16].", "startOffset": 52, "endOffset": 56}, {"referenceID": 24, "context": "For instance, for binary classification problems, the sigmoid function \u2014or more broadly, any natural smoothed variant of the 0-1 loss function\u2014 is not only a more natural choice than artificial ones such as hinge loss, logistic loss, squared loss, but also generalize better in terms of testing accuracy especially when there are outliers [25].", "startOffset": 339, "endOffset": 343}, {"referenceID": 24, "context": "Shalev-Shwartz, Shamir and Sridharan [25] showed that this minimization problem is still solvable in the improper learning sense, with the help from kernel methods and gradient descent.", "startOffset": 37, "endOffset": 41}, {"referenceID": 3, "context": "Instead of requiring each fi(\u00b7) to be L-smooth, one can assume it is L-upper smooth and l-lower smooth, a notation introduced by [4]; in such a case, faster results can also be obtained using our same proof techniques.", "startOffset": 129, "endOffset": 132}, {"referenceID": 3, "context": "This is faster than the previous running time on SVRG which is \u00d5(n+L2/\u03c32), however, it is not faster than using SVRG+Catalyst which gives \u00d5(n + n3/4 \u221a L/ \u221a \u03c3), see discussion in [4].", "startOffset": 178, "endOffset": 181}, {"referenceID": 7, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 114, "endOffset": 129}, {"referenceID": 15, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 114, "endOffset": 129}, {"referenceID": 22, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 114, "endOffset": 129}, {"referenceID": 25, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 114, "endOffset": 129}, {"referenceID": 0, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 161, "endOffset": 179}, {"referenceID": 2, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 161, "endOffset": 179}, {"referenceID": 17, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 161, "endOffset": 179}, {"referenceID": 26, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 161, "endOffset": 179}, {"referenceID": 27, "context": "1) has received lots of attentions across machine learning and optimization communities; many first-order methods [8, 16, 23, 26] as well as their accelerations [1, 3, 18, 27, 28] have been proposed in the past a few years.", "startOffset": 161, "endOffset": 179}, {"referenceID": 3, "context": "1) can be solved easily [4, 11, 24].", "startOffset": 24, "endOffset": 35}, {"referenceID": 10, "context": "1) can be solved easily [4, 11, 24].", "startOffset": 24, "endOffset": 35}, {"referenceID": 23, "context": "1) can be solved easily [4, 11, 24].", "startOffset": 24, "endOffset": 35}, {"referenceID": 16, "context": "The results of Li and Lin [17] and Ghadimi and Lan [13] unify the theory of non-convex and convex optimization in the following sense.", "startOffset": 26, "endOffset": 30}, {"referenceID": 12, "context": "The results of Li and Lin [17] and Ghadimi and Lan [13] unify the theory of non-convex and convex optimization in the following sense.", "startOffset": 51, "endOffset": 55}, {"referenceID": 19, "context": "They provide general first-order schemes such that, if the parameters are tuned properly, the schemes can converge (1) as fast as gradient descent in terms of finding an approximate stationary point; and (2) as fast as accelerated gradient descent [20] in terms of minimizing the objective if the function is convex.", "startOffset": 248, "endOffset": 252}, {"referenceID": 20, "context": "A few days after the first version of this paper appeared on arXiv, we became aware of another group of authors that have independently obtained essentially the same result [21, 22].", "startOffset": 173, "endOffset": 181}, {"referenceID": 21, "context": "A few days after the first version of this paper appeared on arXiv, we became aware of another group of authors that have independently obtained essentially the same result [21, 22].", "startOffset": 173, "endOffset": 181}, {"referenceID": 6, "context": "Mirror descent is a terminology mostly used in optimization literature, see for instance the textbook [7].", "startOffset": 102, "endOffset": 105}, {"referenceID": 1, "context": "In our SVRG method, the descent step xk+1 \u2190 xk \u2212 \u03b7\u2207\u0303k can be interpreted as a mirror descent step in the Euclidean space (see for instance [2]), and therefore mirror-descent analysis applies.", "startOffset": 139, "endOffset": 142}, {"referenceID": 1, "context": "Our main theorem is motivated by the linear-coupling framework [2].", "startOffset": 63, "endOffset": 66}, {"referenceID": 15, "context": "The key idea behind all variance-reduction literatures (such as SVRG [16], SAGA [8], and SAG [23]) is to prove that the variance E[(\u03c3s k)] decreases as s or k increases.", "startOffset": 69, "endOffset": 73}, {"referenceID": 7, "context": "The key idea behind all variance-reduction literatures (such as SVRG [16], SAGA [8], and SAG [23]) is to prove that the variance E[(\u03c3s k)] decreases as s or k increases.", "startOffset": 80, "endOffset": 83}, {"referenceID": 22, "context": "The key idea behind all variance-reduction literatures (such as SVRG [16], SAGA [8], and SAG [23]) is to prove that the variance E[(\u03c3s k)] decreases as s or k increases.", "startOffset": 93, "endOffset": 97}, {"referenceID": 3, "context": "Perhaps the only exception is the work on sum-of-non-convex but strongly-convex objectives [4, 24], where the authors upper bound E[(\u03c3s k)] by O ( \u2016xk \u2212 x\u2217\u20162 ) , the squared vector distance to the minimum.", "startOffset": 91, "endOffset": 98}, {"referenceID": 23, "context": "Perhaps the only exception is the work on sum-of-non-convex but strongly-convex objectives [4, 24], where the authors upper bound E[(\u03c3s k)] by O ( \u2016xk \u2212 x\u2217\u20162 ) , the squared vector distance to the minimum.", "startOffset": 91, "endOffset": 98}, {"referenceID": 0, "context": "Now we can telescope This new technique has also been applied to convex settings recently [1].", "startOffset": 90, "endOffset": 93}, {"referenceID": 9, "context": "1 Empirical Risk Minimization with Non-Convex Loss We consider binary classification on four standard datasets that can be found on the LibSVM website [10]: \u2022 the adult (a9a) dataset (32, 561 training samples, 16, 281 testing samples, and 123 features).", "startOffset": 151, "endOffset": 155}, {"referenceID": 15, "context": "For each of the two datasets, we consider both training the unregularized version, as well as the `2 regularized version with weight 10 \u22123 for CIFAR-10 and 10\u22124 for MNIST, two parameters suggested by [16].", "startOffset": 200, "endOffset": 204}, {"referenceID": 8, "context": "We implement two classical algorithms: stochastic gradient descent (SGD) with the best tuned polynomial learning rate and adaptive subGradient method (AdaGrad) of [9, 19] which is essentially SGD but with an adaptive learning rate.", "startOffset": 163, "endOffset": 170}, {"referenceID": 18, "context": "We implement two classical algorithms: stochastic gradient descent (SGD) with the best tuned polynomial learning rate and adaptive subGradient method (AdaGrad) of [9, 19] which is essentially SGD but with an adaptive learning rate.", "startOffset": 163, "endOffset": 170}], "year": 2016, "abstractText": "We consider the fundamental problem in non-convex optimization of efficiently reaching a stationary point. In contrast to the convex case, in the long history of this basic problem, the only known theoretical results on first-order non-convex optimization remain to be full gradient descent that converges in O(1/\u03b5) iterations for smooth objectives, and stochastic gradient descent that converges in O(1/\u03b5) iterations for objectives that are sum of smooth functions. We provide the first improvement in this line of research. Our result is based on the variance reduction trick recently introduced to convex optimization, as well as a brand new analysis of variance reduction that is suitable for non-convex optimization. For objectives that are sum of smooth functions, our first-order minibatch stochastic method converges with an O(1/\u03b5) rate, and is faster than full gradient descent by \u03a9(n). We demonstrate the effectiveness of our methods on empirical risk minimizations with nonconvex loss functions and training neural nets.", "creator": "LaTeX with hyperref package"}}}