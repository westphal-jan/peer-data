{"id": "1603.06160", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Mar-2016", "title": "Stochastic Variance Reduction for Nonconvex Optimization", "abstract": "We study nonconvex finite-sum problems and analyze stochastic variance reduced gradient (SVRG) methods for them. SVRG and related methods have recently surged into prominence for convex optimization given their edge over stochastic gradient descent (SGD); but their theoretical analysis almost exclusively assumes convexity. In contrast, we prove non-asymptotic rates of convergence (to stationary points) of SVRG for nonconvex optimization, and show that it is provably faster than SGD and gradient descent. We also analyze a subclass of nonconvex problems on which SVRG attains linear convergence to the global optimum. We extend our analysis to mini-batch variants of SVRG, showing (theoretical) linear speedup due to mini-batching in parallel settings.", "histories": [["v1", "Sat, 19 Mar 2016 23:37:38 GMT  (130kb,D)", "http://arxiv.org/abs/1603.06160v1", null], ["v2", "Mon, 4 Apr 2016 23:08:20 GMT  (130kb,D)", "http://arxiv.org/abs/1603.06160v2", "Minor feedback changes"]], "reviews": [], "SUBJECTS": "math.OC cs.LG cs.NE stat.ML", "authors": ["sashank j reddi", "ahmed hefny", "suvrit sra", "barnab\u00e1s p\u00f3czos", "alexander j smola"], "accepted": true, "id": "1603.06160"}, "pdf": {"name": "1603.06160.pdf", "metadata": {"source": "CRF", "title": "Stochastic Variance Reduction for Nonconvex Optimization", "authors": ["Sashank J. Reddi", "Ahmed Hefny"], "emails": ["sjakkamr@cs.cmu.edu", "ahefny@cs.cmu.edu", "suvrit@mit.edu", "bapoczos@cs.cmu.edu", "alex@smola.org"], "sections": [{"heading": "1 Introduction", "text": "This year, it has come to the point where there is only one person who is able to take care of another person who is able to take care of another person."}, {"heading": "1.1 Related Work", "text": "An important reference for stochastic convex optimization (for minEz [F (x, z)]) is (Nemirovski et al., 2009). Faster convergence rates are achieved for problems in Fn by VR methods, see e.g.: (Defazio et al., 2014a; Johnson & Zhang, 2013; Schmidt et al., 2013; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b). Asynchronous VR frameworks developed in Reddi et al., 2015; Mania et al., 2015; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b). Asynchronous VR frameworks are developed in Reddi et al., 2015; Robushein et al., 2015). Agarwal & Bottou (2014) study lower bounds for convex finite-sum problems."}, {"heading": "2 Background & Problem Setup", "text": "We say that f is smooth if there is a constant L analysis in which the functions fi in (1) are smooth, so that the functions fi in (x) \u2212 fi (y), fi (y), fi (y), fi (n), fi (n), fi (n), fi (n), fi (n), fi (y), fi (y), fi (n), fi (n), fi (n), fi (n), fi (n), fi (n), fi (n), fi (n), fi (n), fi (n), fi (n), fi (n), fi (n), f (n), f (f), f (c), f (c), f (c), f (c), f (c), c, c, c, c, c, c, c, c, c, c, c, c, c, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, c, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f, f"}, {"heading": "2.1 Nonconvex SGD: Convergence Rate", "text": "The stochastic gradient descent (Sgd) is one of the simplest algorithms to solve (1); algorithm 1 lists its pseudo-code. By using a uniformly randomly selected (with substitution) index, it is randomly converted from [n], SgdAlgorithm 1 SGDInput: x0, increment order: {\u03b7t > 0} T \u2212 1t = 0 for t = 0 to T \u2212 1 uniform {1,.., n} xt + 1 = xt \u2212 approximation fit (x) end forms an unbiased estimate of the gradient for each iteration. Under appropriate conditions, Ghadimi & Lan (2013) determine the convergence rate of Sgd to a stationary point of f. Their results include the following theorem.Theorem f has an unbiased gradient (x)."}, {"heading": "3 Nonconvex SVRG", "text": "We are turning our focus to reduced variance methods. We are using Svrg (Johnson & Zhang, 2013), an algorithm that has recently been shown to be very effective in reducing variance in convex problems. As a result, he has gained a considerable interest in machine learning and optimization. We are trying to understand its advantages for nonconvex optimization. For reference, Algorithm 2, Svrg introduces pseudocode.Observe that Algorithm 2 operates in epochs s. At the end of the epoch, a complete gradient is calculated at the point x that requires n calls to the IFO. Within its inner loop, Svrg m performs stochastic updates. Therefore, the total number of IFO calls is (m + n). For m = 1, the algorithm is reduced to the classical gradient."}, {"heading": "3.1 Gradient Dominated Functions", "text": "Before concluding our discussion of the convergence of nonconvex Svrg, we note that a linear convergence rate for the class of profile functions (1) is dominated (2). To simplify the exposure, we assume that profile functions (1 / 3, a property corresponding to the \"High Condition Number Regime\" for strongly convex functions in machine learning (2). Note that gradient-dominated functions cannot be convective (3)."}, {"heading": "4 Convex Case", "text": "It is a natural question whether this rate can be improved if we assume that we can give an affirmative answer, if we obtain an affirmative rate for the simplicity of the comparison, our analysis also provides rates with respect to the optimality gap [f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (x) - f (f (f) - f (f) f (f (x) - f - f - - - - f (x) - f (x) - f (f (f (x) - f (f) - f (f) - f (f - f) - f (f) - f (f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f - f (f - f) (f (f) (f (f) f (f (f) f (f (x) - f) - f (f (f) f (f (x) - f) - f (f (f (x) - f) - f (f (x) - f (f) - f (f (x) - f (f) - f (x) - f (f (x) - f (f) - f (f (x) - f (x) - f (f (f) f (f (x) - f (f (x) - f) - f (x) - f (x) - f (f (x) - f (f (x) - f (f (x) - f (f) f (f (f (x) f (x) - f (x) - f (f (x) - f (x) - f (f (x) f (x) f (f (x) - f (f (x)"}, {"heading": "5 Mini-batch Nonconvex SVRG", "text": "In this section we will examine the mini-batch version of algorithm 2. Mini-batch is a popular strategy, especially in multicore and distributed settings, as it greatly contributes to exploiting parallelism and reducing communication costs. However, the pseudo-code for mini-batches is provided in the supplement because of lack of space. The key difference between the mini-batches Svrg and algorithm 2 lies in lines 6 to 8. To use the mini-batches, we replace line 6 with sampling (with replacement) a mini-batch There is a difference in size b; lines 7 to 8 are replaced by the following updates: us + 1t = 1."}, {"heading": "6 Comparison of the convergence rates", "text": "In this section, we will give a comprehensive comparison of the results obtained in this thesis. In particular, we will compare the most important aspects of convergence rates for Sgd, GradientDescent, and Svrg. The comparison is based on IFO complexity to achieve a -accurate solution.Dependency on n: The number of IFO calls of Svrg and GradientDescent, however, is explicitly dependent on n. The number of IFO calls in GradientDescent is proportional to n. But for Svrg this dependency is reduced to n1 / 2 for convex (Corollary 7) and n2 for nonconvex (Corollary 3) problems. Whether this difference in dependence on n is due to non-convergence."}, {"heading": "7 Best of two worlds", "text": "In this case, the IFO complexity of Svrg is lower than that of Sgd and GradientDescent. This variant of Svrg (Msvrg) selects a step size based on the total number of iterations T (or alternatively). For our discussion below, we assume that T > n. Theorem 8. Let us have f \u00b2 Fn gradients that adhere to limits. Let it come to gradients = max {c / \u221a T, \u00b51 / (Ln2 / 3)} (\u00b51 is the universal constant of Korollar 3), m = bn / (3\u00b51) c, and c = 270 x."}, {"heading": "8 Experiments", "text": "We present our empirical results in this section. For our experiments, we examine the problem of multilateral classification with neural networks. (This is a typical problem that has occurred in the machine learning environment.) We use the CIFAR-102, MNIST3, and STL-104 datasets for our experiments. These datasets are standard in the neural networks. (The \"2 regularization is 1e-3 for CIFAR-10 and MNIST3 for our experiments.) The\" 2 regularization is 1e-3 for CIFAR-10 and MNE-10 for use. \"The features in the datasets are standardized to the intervals of datasets [0, 1]. All datasets come with a predefined division into training and test datasets.We compare Sgd (the de facto algorithms for education) against the non-conventional networks."}, {"heading": "9 Discussion", "text": "In this paper, we examined a VR scheme for non-convex optimization. We showed that using VR in stochastic methods can provide better performance than both Sgd and GradientDescent in the context of non-convex optimization. If the f in (1) function is dominated by gradients, we proposed a variant of Svrg that exhibits linear convergence to the global minimum. Our analysis shows that Svrg, unlike Sgd, has a number of interesting properties, including fixed-step convergence, descent property after each epoch; a property that does not have to apply to Sgd. We also showed that Svrg, unlike Sgd, enjoys an efficient mini-stacking, achieving acceleration linear in the size of minibatches in parallel settings. Our analysis also shows that the starting point and use of mini-stacks are important for Sgd."}, {"heading": "Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A Nonconvex SGD: Convergence Rate", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Theorem 1", "text": "Let us assume that f has a predefined gradient; let us leave \"t\" = \"p\" = \"c / p\" T, whereby \"c\" (f (x0) - \"f (x)\") - \"p\" (2) - \"p\" (1) - \"p\" (1) - \"p\" (2) - \"p\" (2) - \"p\" (2) - \"p\" - \"p\" (2) - \"p\" (2) - \"p\" (1) - \"p\" (2) - \"p\" (2) - \"p\" (2) - \"p\" (2) - \"p\" (2) - \"p\" - \"-\" p \"-\". \"-\" - \"-\" p \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\". \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \".\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\". \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\". \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" -. \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-.\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-.\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-.\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-\" - \"-"}, {"heading": "B Nonconvex SVRG", "text": "s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s"}, {"heading": "Proof of Theorem 2", "text": "Theorem: Let's leave f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 252; f & # 246; f & # 252; f & # 252; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f & # 160; f (f & # 160; f & # 160; f & # 160)."}, {"heading": "Proof of Theorem 3", "text": "Theorem. Suppose f \u00b2 Fn. Let us leave \u03b7 = \u00b50 / (Ln\u03b1) (0 < \u00b50 < 1 and 0 < \u03b1 \u2264 1), \u03b2 = L / n\u03b1 / 2, m = bn3\u03b1 / 2 / (3\u00b50) c and T is a multiple of m. Then there are universal constants (f (x0) \u2212 0 so that we have the following solution to the problem in (1) and xa is the output of Algorithm 2.Proof. For our analysis we will demand an upper limit for c0. We observe that c0 = \u00b520L n2\u03b1 (1 +) and we 3\u00b5L n2\u03b1 (1 +) m \u2212 1 \u00b2 equality."}, {"heading": "Proof of Corollary 2", "text": "Suppose the IFO complexity of algorithm 2 (with parameters from Theorem 3) is: IFO calls = {O (n + (n1 \u2212 \u03b1 2 /)), if \u03b1 < 2 / 3, O (n + (n\u03b1 /), if \u03b1 \u2265 2 / 3. Proof. This result is obtained from Theorem 3 and the fact that m = bn3\u03b1 / 2 / (3\u00b50) c. Suppose \u03b1 < 2 / 3, then m = o (n). However, n IFO calls are invested in calculating the average gradient at the end of each epoch. That is, n IFO calls are required for m-iterations of the algorithm. On the basis of this relationship, we get O (n + (n1 \u2212 \u03b1 2 /)) in this case. On the other hand, the total number of IFO calls made by algorithm is reduced by 2 / m (n) (b)."}, {"heading": "C GD-SVRG", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Theorem 4", "text": "Theorem. Suppose f is dominated by inequality where \u03c4 > n1 / 3. Then follow the iterations of algorithm 3 with T = d2L\u03c4n2 / 3 / \u03bd1e, m = bn / (3\u00b51) c, \u03b7t = \u00b51 / (Ln2 / 3) for all 0 \u2264 t \u2264 m \u2212 1 and pm = 1 and pi = 0 for all 0 \u2264 i < m satisfyE [2] \u2264 2 \u2212 k [3]. Here are the constants used in sequence 3. Conclusion 3 shows that the iterates of algorithm 3 satisfy E [3] \u2264 2 \u2212 k [f (xk) \u04322 / 3E [f (xk \u2212 1) \u2212 f (x \u04321) \u2212 f [3] replace the specified value of T in the above inequality, we haveE [4]."}, {"heading": "Proof of Theorem 5", "text": "Theorem. If f is the case that -gradient is dominated (\u03c4 > n1 / 3), then with T = d2L\u03c4n2 / 3 / \u03bd1e, m = bn / (3\u00b51) c, \u03b7t = \u00b51 / (Ln2 / 3) for 0 \u2264 t \u2264 m \u2212 1 and pm = 1 and pi = 0 for all 0 \u2264 i < m, then the iterations of algorithm 3 are satisfactory E [f (xk) \u2212 f (x)] \u2264 2 \u2212 k [f (x0) \u2212 f (x)]. Here are the iterations of algorithm 1, \u03bd1 as in episode 3; x \u0445 is an optimal solution.Evidence. The proof imitates that of theorem 4; now we have the following condition for the iterate of algorithm 3: E [f (xk) \u2212 f (xk) \u2212 2] \u2264 E [f (x \u2212 1) \u2212 f (x)."}, {"heading": "D Convex SVRG: Convergence Rate", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Theorem 6", "text": "If fi is convex for all i [n] [n], pi = 1 / m for 0 \u2264 i m \u2212 1, and pm = 0, then for Algorithm 2, we haveE [n] [n]. [n]. [n]. (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f. (f). (f). (f. (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (). (f). (f). (f). (f). (f). (f). (f). (). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (f). (. (f). (. (f). (f). (f). (f). (. (f). (. (f). (f). (. (. (f). (. (f). (. (. (. (f). (f). (. (f). (. (. (. (f). (. (f). (f). (f). (. (. (. (. (f). (. (f). (f). (. (f). (. (. (f). (f). (. ("}, {"heading": "E Minibatch Nonconvex SVRG", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Theorem 7", "text": "The proofs essentially follow the lines of Lemma 1, Theorem 2 and Theorem 3 with the additional complexity of mini-batch. We first prove some intermediate results before we come to the proof of Theorem 7 Lemma 2. (Suppose we have s + 1t: = E [f (x s + 1 t) + ct + 1t \u2212 x \u00b2 s \u00b2 s \u00b2 2], ct = \u2212 ct + 1 (1 + 2 x). (Suppose we have s + 1t: = E (x s + 1 t) + ct \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s (ct + 1 x). (Suppose) 2tL 3b, for 0 \u2264 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2). (Suppose). (Suppose). (Suppose we have s + 1 and 0 \u2264 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s)."}, {"heading": "F MSVRG: Convergence Rate", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Theorem 8", "text": "& & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; & # 10; &"}, {"heading": "G Key Lemmatta", "text": "s calculate + 1t from the mini-batch version of algorithm 2, i.e., algorithm 4 with mini-batch size b. Then we present E [P + 1t] 2E [P + 1t] 2E [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 1T [P] 1T 1T 1T [P] 1T [P] 1T [P] 1T] 1T [P] 1T [P] 1T] 1T [T] 1T [T] 1T [P) 1T 1T 1T 1T 1T 1T 1T [P) 1T 1T 1T 1T 1T 1T 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P] 1T [P [P] 1T [P] 1T [P] 1T [P] 1T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P] 2T [P]"}, {"heading": "H Experiments", "text": "Figure 2 shows the remaining diagrams for MNIST and STL-10 datasets. As shown in the diagrams, there is no significant difference in the test error of Svrg and Sgd for these datasets."}, {"heading": "I Other Lemmas", "text": "We need Lemma 5 for our results in the convex case. - Lemma 5 (Johnson & Zhang (2013). - Let g: Rd \u2192 R convex with a continuous course of L-Lipschitz. - Let g: (x) \u2212 g: (y) \u2212 g (y) \u2212 g: (y) \u2212 g (y), x \u2212 y >, for all x, y \u2212 Rd.Proof. Consider h: (x) \u2212 g (y) \u2212 g (y) \u2212 g (y) \u2212 g: (y), x \u2212 y > for any y \u2212 Rd. - Note that h: is also L-Lipschitz continuous. - Note that h: (x) 0 (since h: y) \u2212 g (y: y) \u2212 g (y), or alternatively, da h: f: f (f), x x: f (f)."}], "references": [{"title": "A lower bound for the optimization of finite sums", "author": ["Agarwal", "Alekh", "Bottou", "Leon"], "venue": null, "citeRegEx": "Agarwal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2014}, {"title": "Incremental gradient, subgradient, and proximal methods for convex optimization: A survey", "author": ["Bertsekas", "Dimitri P"], "venue": null, "citeRegEx": "Bertsekas and P.,? \\Q2011\\E", "shortCiteRegEx": "Bertsekas and P.", "year": 2011}, {"title": "Stochastic gradient learning in neural networks", "author": ["Bottou", "L\u00e9on"], "venue": "Proceedings of Neuro-N\u0131mes,", "citeRegEx": "Bottou and L\u00e9on.,? \\Q1991\\E", "shortCiteRegEx": "Bottou and L\u00e9on.", "year": 1991}, {"title": "SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives", "author": ["Defazio", "Aaron", "Bach", "Francis", "Lacoste-Julien", "Simon"], "venue": "In NIPS", "citeRegEx": "Defazio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Defazio et al\\.", "year": 2014}, {"title": "Finito: A faster, permutable incremental gradient method for big data problems", "author": ["Defazio", "Aaron J", "Caetano", "Tib\u00e9rio S", "Domke", "Justin"], "venue": null, "citeRegEx": "Defazio et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Defazio et al\\.", "year": 2014}, {"title": "Optimal distributed online prediction using mini-batches", "author": ["Dekel", "Ofer", "Gilad-Bachrach", "Ran", "Shamir", "Ohad", "Xiao", "Lin"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Dekel et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dekel et al\\.", "year": 2012}, {"title": "Escaping from saddle points - online stochastic gradient for tensor decomposition", "author": ["Ge", "Rong", "Huang", "Furong", "Jin", "Chi", "Yuan", "Yang"], "venue": "In Proceedings of The 28th Conference on Learning Theory,", "citeRegEx": "Ge et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ge et al\\.", "year": 2015}, {"title": "Stochastic first- and zeroth-order methods for nonconvex stochastic programming", "author": ["Ghadimi", "Saeed", "Lan", "Guanghui"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Ghadimi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ghadimi et al\\.", "year": 2013}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Glorot", "Xavier", "Bengio", "Yoshua"], "venue": "Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS10),", "citeRegEx": "Glorot et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2010}, {"title": "Beyond convexity: Stochastic quasi-convex optimization", "author": ["Hazan", "Elad", "Levy", "Kfir", "Shalev-Shwartz", "Shai"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Hazan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2015}, {"title": "A distributed, asynchronous and incremental algorithm for nonconvex optimization: An admm based approach", "author": ["Hong", "Mingyi"], "venue": "arXiv preprint arXiv:1412.6058,", "citeRegEx": "Hong and Mingyi.,? \\Q2014\\E", "shortCiteRegEx": "Hong and Mingyi.", "year": 2014}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Johnson", "Rie", "Zhang", "Tong"], "venue": "In NIPS", "citeRegEx": "Johnson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2013}, {"title": "Semi-Stochastic Gradient Descent Methods", "author": ["Kone\u010dn\u00fd", "Jakub", "Richt\u00e1rik", "Peter"], "venue": null, "citeRegEx": "Kone\u010dn\u00fd et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kone\u010dn\u00fd et al\\.", "year": 2013}, {"title": "Mini-Batch Semi-Stochastic Gradient Descent in the Proximal Setting", "author": ["Kone\u010dn\u00fd", "Jakub", "Liu", "Jie", "Richt\u00e1rik", "Peter", "Tak\u00e1\u010d", "Martin"], "venue": null, "citeRegEx": "Kone\u010dn\u00fd et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kone\u010dn\u00fd et al\\.", "year": 2015}, {"title": "Stochastic approximation methods for constrained and unconstrained systems, volume 26", "author": ["Kushner", "Harold Joseph", "Clark", "Dean S"], "venue": "Springer Science & Business Media,", "citeRegEx": "Kushner et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kushner et al\\.", "year": 2012}, {"title": "Efficient mini-batch training for stochastic optimization", "author": ["Li", "Mu", "Zhang", "Tong", "Chen", "Yuqiang", "Smola", "Alexander J"], "venue": "In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD", "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Asynchronous Parallel Stochastic Gradient for Nonconvex Optimization", "author": ["Lian", "Xiangru", "Huang", "Yijun", "Li", "Yuncheng", "Liu", "Ji"], "venue": "In NIPS,", "citeRegEx": "Lian et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lian et al\\.", "year": 2015}, {"title": "Analysis of recursive stochastic algorithms", "author": ["Ljung", "Lennart"], "venue": "Automatic Control, IEEE Transactions on,", "citeRegEx": "Ljung and Lennart.,? \\Q1977\\E", "shortCiteRegEx": "Ljung and Lennart.", "year": 1977}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Nemirovski et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Nemirovski et al\\.", "year": 2009}, {"title": "Problem Complexity and Method Efficiency in Optimization", "author": ["Nemirovski", "Arkadi", "D. Yudin"], "venue": null, "citeRegEx": "Nemirovski et al\\.,? \\Q1983\\E", "shortCiteRegEx": "Nemirovski et al\\.", "year": 1983}, {"title": "Introductory Lectures On Convex Optimization: A Basic Course", "author": ["Nesterov", "Yurii"], "venue": null, "citeRegEx": "Nesterov and Yurii.,? \\Q2003\\E", "shortCiteRegEx": "Nesterov and Yurii.", "year": 2003}, {"title": "Cubic regularization of newton method and its global performance", "author": ["Nesterov", "Yurii", "Polyak", "Boris T"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nesterov et al\\.", "year": 2006}, {"title": "Pseudogradient adaptation and training algorithms", "author": ["BT Poljak", "Tsypkin", "Ya Z"], "venue": "Automation and Remote Control,", "citeRegEx": "Poljak et al\\.,? \\Q1973\\E", "shortCiteRegEx": "Poljak et al\\.", "year": 1973}, {"title": "Gradient methods for the minimisation of functionals", "author": ["B.T. Polyak"], "venue": "USSR Computational Mathematics and Mathematical Physics,", "citeRegEx": "Polyak,? \\Q1963\\E", "shortCiteRegEx": "Polyak", "year": 1963}, {"title": "On variance reduction in stochastic gradient descent and its asynchronous variants", "author": ["Reddi", "Sashank", "Hefny", "Ahmed", "Sra", "Suvrit", "Poczos", "Barnabas", "Smola", "Alex J"], "venue": "In NIPS", "citeRegEx": "Reddi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Reddi et al\\.", "year": 2015}, {"title": "A stochastic approximation method", "author": ["H. Robbins", "S. Monro"], "venue": "Annals of Mathematical Statistics,", "citeRegEx": "Robbins and Monro,? \\Q1951\\E", "shortCiteRegEx": "Robbins and Monro", "year": 1951}, {"title": "Minimizing Finite Sums with the Stochastic Average Gradient", "author": ["Schmidt", "Mark W", "Roux", "Nicolas Le", "Bach", "Francis R"], "venue": null, "citeRegEx": "Schmidt et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schmidt et al\\.", "year": 2013}, {"title": "Stochastic dual coordinate ascent methods for regularized loss", "author": ["Shalev-Shwartz", "Shai", "Zhang", "Tong"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2013}, {"title": "A stochastic PCA and SVD algorithm with an exponential convergence rate", "author": ["Shamir", "Ohad"], "venue": null, "citeRegEx": "Shamir and Ohad.,? \\Q2014\\E", "shortCiteRegEx": "Shamir and Ohad.", "year": 2014}, {"title": "Fast stochastic algorithms for SVD and PCA: Convergence properties and convexity", "author": ["Shamir", "Ohad"], "venue": null, "citeRegEx": "Shamir and Ohad.,? \\Q2015\\E", "shortCiteRegEx": "Shamir and Ohad.", "year": 2015}, {"title": "Scalable nonconvex inexact proximal splitting", "author": ["Sra", "Suvrit"], "venue": "In NIPS, pp", "citeRegEx": "Sra and Suvrit.,? \\Q2012\\E", "shortCiteRegEx": "Sra and Suvrit.", "year": 2012}, {"title": "A proximal stochastic gradient method with progressive variance reduction", "author": ["Xiao", "Lin", "Zhang", "Tong"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Xiao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Xiao et al\\.", "year": 2014}, {"title": "Univr: A universal variance reduction framework for proximal stochastic gradient method", "author": ["Zhu", "Zeyuan Allen", "Yuan", "Yang"], "venue": "CoRR, abs/1506.01972,", "citeRegEx": "Zhu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 26, "context": "Among these, of particular importance are variance reduced (VR) stochastic methods (Schmidt et al., 2013; Johnson & Zhang, 2013; Defazio et al., 2014a), which have delivered exciting progress such as linear convergence rates (for strongly convex functions) as opposed to sublinear rates of ordinary Sgd (Robbins & Monro, 1951; Nemirovski et al.", "startOffset": 83, "endOffset": 151}, {"referenceID": 18, "context": ", 2014a), which have delivered exciting progress such as linear convergence rates (for strongly convex functions) as opposed to sublinear rates of ordinary Sgd (Robbins & Monro, 1951; Nemirovski et al., 2009).", "startOffset": 160, "endOffset": 208}, {"referenceID": 26, "context": "The Svrg algorithm of (Johnson & Zhang, 2013) is particularly attractive here because of its low storage requirement in comparison to the algorithms in (Schmidt et al., 2013; Defazio et al., 2014a).", "startOffset": 152, "endOffset": 197}, {"referenceID": 3, "context": ", 2013; Johnson & Zhang, 2013; Defazio et al., 2014a), which have delivered exciting progress such as linear convergence rates (for strongly convex functions) as opposed to sublinear rates of ordinary Sgd (Robbins & Monro, 1951; Nemirovski et al., 2009). Similar (but not same) benefits of VR methods can also be seen in smooth convex functions. The Svrg algorithm of (Johnson & Zhang, 2013) is particularly attractive here because of its low storage requirement in comparison to the algorithms in (Schmidt et al., 2013; Defazio et al., 2014a). Despite the meteoric rise of VR methods, their analysis for general nonconvex problems is largely missing. Johnson & Zhang (2013) remark on convergence of Svrg when f \u2208 Fn is locally strongly convex and provide compelling experimental results (Fig.", "startOffset": 31, "endOffset": 675}, {"referenceID": 23, "context": "\u2022 For an interesting nonconvex subclass of Fn called gradient dominated functions (Polyak, 1963; Nesterov & Polyak, 2006), we propose a variant of Svrg that attains a global linear rate of convergence.", "startOffset": 82, "endOffset": 121}, {"referenceID": 18, "context": "A key reference for stochastic convex optimization (for minEz[F (x, z)]) is (Nemirovski et al., 2009).", "startOffset": 76, "endOffset": 101}, {"referenceID": 26, "context": ", (Defazio et al., 2014a; Johnson & Zhang, 2013; Schmidt et al., 2013; Kone\u010dn\u00fd et al., 2015; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b).", "startOffset": 2, "endOffset": 145}, {"referenceID": 13, "context": ", (Defazio et al., 2014a; Johnson & Zhang, 2013; Schmidt et al., 2013; Kone\u010dn\u00fd et al., 2015; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b).", "startOffset": 2, "endOffset": 145}, {"referenceID": 24, "context": "Asynchronous VR frameworks are developed in (Reddi et al., 2015; Mania et al., 2015).", "startOffset": 44, "endOffset": 84}, {"referenceID": 16, "context": "A similar rate for parallel and distributed Sgd was shown recently in (Lian et al., 2015).", "startOffset": 70, "endOffset": 89}, {"referenceID": 9, "context": "Finally, we note another interesting example, stochastic optimization of locally quasi-convex functions (Hazan et al., 2015), wherein actually a O(1/ ) convergence in function value is shown.", "startOffset": 104, "endOffset": 124}, {"referenceID": 3, "context": ", (Defazio et al., 2014a; Johnson & Zhang, 2013; Schmidt et al., 2013; Kone\u010dn\u00fd et al., 2015; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b). Asynchronous VR frameworks are developed in (Reddi et al., 2015; Mania et al., 2015). Agarwal & Bottou (2014) study lower-bounds for convex finite-sum problems.", "startOffset": 3, "endOffset": 257}, {"referenceID": 3, "context": ", (Defazio et al., 2014a; Johnson & Zhang, 2013; Schmidt et al., 2013; Kone\u010dn\u00fd et al., 2015; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b). Asynchronous VR frameworks are developed in (Reddi et al., 2015; Mania et al., 2015). Agarwal & Bottou (2014) study lower-bounds for convex finite-sum problems. ShalevShwartz (2015) prove linear convergence of stochastic dual coordinate ascent when the individual fi (i \u2208 [n]) are nonconvex but f is strongly convex.", "startOffset": 3, "endOffset": 329}, {"referenceID": 3, "context": ", (Defazio et al., 2014a; Johnson & Zhang, 2013; Schmidt et al., 2013; Kone\u010dn\u00fd et al., 2015; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b). Asynchronous VR frameworks are developed in (Reddi et al., 2015; Mania et al., 2015). Agarwal & Bottou (2014) study lower-bounds for convex finite-sum problems. ShalevShwartz (2015) prove linear convergence of stochastic dual coordinate ascent when the individual fi (i \u2208 [n]) are nonconvex but f is strongly convex. They do not study the general nonconvex case. Moreover, even in their special setting our results improve upon theirs for the high condition number regime. Nonconvex. Sgd dates at least to the seminal work (Robbins & Monro, 1951); and since then it has been developed in several directions (Poljak & Tsypkin, 1973; Ljung, 1977; Bottou, 1991; Kushner & Clark, 2012). In the (nonsmooth) finite-sum setting, Sra (2012) considers proximal splitting methods, and analyzes asymptotic convergence with nonvanishing gradient errors.", "startOffset": 3, "endOffset": 880}, {"referenceID": 3, "context": ", (Defazio et al., 2014a; Johnson & Zhang, 2013; Schmidt et al., 2013; Kone\u010dn\u00fd et al., 2015; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b). Asynchronous VR frameworks are developed in (Reddi et al., 2015; Mania et al., 2015). Agarwal & Bottou (2014) study lower-bounds for convex finite-sum problems. ShalevShwartz (2015) prove linear convergence of stochastic dual coordinate ascent when the individual fi (i \u2208 [n]) are nonconvex but f is strongly convex. They do not study the general nonconvex case. Moreover, even in their special setting our results improve upon theirs for the high condition number regime. Nonconvex. Sgd dates at least to the seminal work (Robbins & Monro, 1951); and since then it has been developed in several directions (Poljak & Tsypkin, 1973; Ljung, 1977; Bottou, 1991; Kushner & Clark, 2012). In the (nonsmooth) finite-sum setting, Sra (2012) considers proximal splitting methods, and analyzes asymptotic convergence with nonvanishing gradient errors. Hong (2014) studies a distributed nonconvex incremental ADMM algorithm.", "startOffset": 3, "endOffset": 1001}, {"referenceID": 3, "context": ", (Defazio et al., 2014a; Johnson & Zhang, 2013; Schmidt et al., 2013; Kone\u010dn\u00fd et al., 2015; Shalev-Shwartz & Zhang, 2013; Defazio et al., 2014b). Asynchronous VR frameworks are developed in (Reddi et al., 2015; Mania et al., 2015). Agarwal & Bottou (2014) study lower-bounds for convex finite-sum problems. ShalevShwartz (2015) prove linear convergence of stochastic dual coordinate ascent when the individual fi (i \u2208 [n]) are nonconvex but f is strongly convex. They do not study the general nonconvex case. Moreover, even in their special setting our results improve upon theirs for the high condition number regime. Nonconvex. Sgd dates at least to the seminal work (Robbins & Monro, 1951); and since then it has been developed in several directions (Poljak & Tsypkin, 1973; Ljung, 1977; Bottou, 1991; Kushner & Clark, 2012). In the (nonsmooth) finite-sum setting, Sra (2012) considers proximal splitting methods, and analyzes asymptotic convergence with nonvanishing gradient errors. Hong (2014) studies a distributed nonconvex incremental ADMM algorithm. These works, however, only prove expected convergence to stationary points and often lack analysis of rates. The first nonasymptotic convergence rate analysis for Sgd is in (Ghadimi & Lan, 2013), who show that Sgd ensures \u2016\u2207f\u2016 \u2264 in O(1/ ) iterations. A similar rate for parallel and distributed Sgd was shown recently in (Lian et al., 2015). GradientDescent is known to ensure \u2016\u2207f\u2016 \u2264 in O(1/ ) iterations (Nesterov, 2003, Chap. 1.2.3). The first analysis of nonconvex Svrg seems to be due to Shamir (2014), who considers the special problem of computing a few leading eigenvectors (e.", "startOffset": 3, "endOffset": 1567}, {"referenceID": 23, "context": "We also recall the class of gradient dominated functions (Polyak, 1963; Nesterov & Polyak, 2006), where a function f is called \u03c4 -gradient dominated if for any x \u2208 R f(x)\u2212 f(x\u2217) \u2264 \u03c4\u2016\u2207f(x)\u2016, (2)", "startOffset": 57, "endOffset": 96}, {"referenceID": 23, "context": "Note that GradientDescent can also achieve linear convergence rate for gradient dominated functions (Polyak, 1963).", "startOffset": 100, "endOffset": 114}, {"referenceID": 5, "context": "For a batch size of b, Sgd obtains a rate of O(1/ \u221a bT ) (Dekel et al., 2012) (obtainable by a simple modification of Theorem 1).", "startOffset": 57, "endOffset": 77}, {"referenceID": 15, "context": "In contrast, Sgd does not yield an efficient mini-batch strategy as it requires O(b/ ) IFO calls for achieving an -accurate solution (Li et al., 2014).", "startOffset": 133, "endOffset": 150}, {"referenceID": 26, "context": "Such initialization is standard for variance reduced schemes even for convex problems (Johnson & Zhang, 2013; Schmidt et al., 2013).", "startOffset": 86, "endOffset": 131}, {"referenceID": 6, "context": "In fact, Ge et al. (2015) add additional noise to the stochastic gradient in order to escape saddle points.", "startOffset": 9, "endOffset": 26}], "year": 2017, "abstractText": "We study nonconvex finite-sum problems and analyze stochastic variance reduced gradient (Svrg) methods for them. Svrg and related methods have recently surged into prominence for convex optimization given their edge over stochastic gradient descent (Sgd); but their theoretical analysis almost exclusively assumes convexity. In contrast, we prove non-asymptotic rates of convergence (to stationary points) of Svrg for nonconvex optimization, and show that it is provably faster than Sgd and gradient descent. We also analyze a subclass of nonconvex problems on which Svrg attains linear convergence to the global optimum. We extend our analysis to mini-batch variants of Svrg, showing (theoretical) linear speedup due to mini-batching in parallel settings.", "creator": "TeX"}}}