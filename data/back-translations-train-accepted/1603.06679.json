{"id": "1603.06679", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Mar-2016", "title": "Recursive Neural Conditional Random Fields for Aspect-based Sentiment Analysis", "abstract": "Aspect-based sentiment analysis has obtained substantial popularity due to its ability to extract useful information from customer reviews. In most cases, aspect terms in a review sentence have strong relations with opinion terms because an aspect is the target where an opinion is expressed. With this connection, some of the existing work focused on designing syntactic rules to double propagate information between aspect and opinion terms. However, these methods require large amount of efforts and domain knowledge to design precise syntactic rules and fail to handle uncertainty. In this paper, we propose a novel joint model that integrates recursive neural networks and conditional random fields into a unified framework for aspect-based sentiment analysis. Our task is to extract aspect and opinion terms/phrases for each review. The proposed model is able to learn high-level discriminative features and double propagate information between aspect and opinion terms simultaneously. Furthermore, it is flexible to incorporate linguistic or lexicon features into the proposed model to further boost its performance in terms of information extraction. Experimental results on the SemEval Challenge 2014 dataset show the superiority of our proposed model over several baseline methods as well as the winning systems.", "histories": [["v1", "Tue, 22 Mar 2016 05:59:00 GMT  (1804kb)", "https://arxiv.org/abs/1603.06679v1", null], ["v2", "Wed, 8 Jun 2016 06:24:06 GMT  (1544kb)", "http://arxiv.org/abs/1603.06679v2", null], ["v3", "Mon, 19 Sep 2016 14:00:43 GMT  (1416kb)", "http://arxiv.org/abs/1603.06679v3", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["wenya wang", "sinno jialin pan", "daniel dahlmeier", "xiaokui xiao"], "accepted": true, "id": "1603.06679"}, "pdf": {"name": "1603.06679.pdf", "metadata": {"source": "CRF", "title": "Recursive Neural Conditional Random Fields for Aspect-based Sentiment Analysis", "authors": ["Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier", "Xiaokui Xiao"], "emails": ["xkxiao}@ntu.edu.sg,", "d.dahlmeier@sap.com"], "sections": [{"heading": null, "text": "ar Xiv: 160 3.06 679v 3 [cs.C L] 19 Sep 20"}, {"heading": "1 Introduction", "text": "In fact it is so, that most of us are able to survive themselves, if they do not see themselves able to survive themselves, \"he said.\" But it is not so, that they feel able to survive themselves. \"Indeed:\" It is not as if they were able to survive themselves. \"In the second half of the 20th century, in the second half of the 20th century, in the second half of the 20th century, in the second half of the 20th century, in the second half of the 20th century, in the third half of the 20th century, in the third half of the 20th century, in the second half of the 20th century, in the second half of the 20th century, in the second half of the 20th century, in the second half of the 20th century, in the second half of the 20th century, in the second half of the 20th century, in the second half of the 20th, in the second half of the 20th century, in the second half of the 20th century, in the second half of the last"}, {"heading": "2 Related Work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Aspects and Opinions Co-Extraction", "text": "Hu et al. (2004a) proposed extracting product aspects by association mining and opinion terms by supplementing a seed opinion using synonyms and antonyms in WordNet. Subsequently, syntactical relationships are further exploited for aspect / opinion extraction (Popescu and Etzioni, 2005; Wu et al., 2009; Qiu et al., 2011). For example, Qiu et al. (2011) used syntactic relationships to duplicate and expand aspects and opinions. Although the above models are not monitored, they are heavily dependent on predefined rules for extraction and are also limited to certain types of POS tags for product aspects and opinions. Jin et al. (2009), Li et al. (2010), Jakob et al. (2010) and Ma et al. (2010) modelled the extraction problem as sequence tagging."}, {"heading": "2.2 Deep Learning for Sentiment Analysis", "text": "Recent studies have shown that deep learning models can automatically learn the inherent semantic and syntactic information from the data and thus achieve better performance for sensation analysis (Socher et al., 2011b; Socher et al., 2012; Socher et al., 2013; Glorot et al., 2011; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014). These methods generally belong to the sentence level or phrase / word group sensation polarity predictions. Deep recursive neural networks used for expression with respect to aspect-based sentiment analysis, Irsoy et al. (2014). Dong et al al al al al. (2014) proposed adaptive recursive neural networks for sensory polarity classification, where objectives or aspects are given as input. Tang et al. (2015) used Long-Term Memory (LSTM) (Hochreiter Schmidhuber and 1997) for the same task."}, {"heading": "3 Problem Statement", "text": "Suppose we get a set of customer reviews in a particular area, which are denoted by S = {s1,..., sN}, where N is the number of review sentences. For each si \u2032 S, there may be a set of aspect terms Ai = {ai1,..., ail}, where each Oir may be a single word or a sequence of words that express the subjective sentiment of the comment holder. The task is to learn a classifier to extract the set of aspect terms Ai = {oi1,..., oim} and the set of opinion terms Oi from each review sentence. This task can be formulated as a sequence tagging problem by using the BIO coding scheme. Specifically, each review sentence consists of a sequence of words si = {wi1,..."}, {"heading": "4 Recursive Neural CRFs", "text": "As described in Section 1, the RNCRF consists of two main components: 1) a DT-RNN to learn an overarching representation for each word in a sentence, and 2) a CRF to use the learned representation as input to capture the context around each word for the explicit extraction of aspects and concepts of opinion."}, {"heading": "4.1 Dependency-Tree RNNs", "text": "We begin by associating each word w in our vocabulary with a vector x-Rd that corresponds to a column of a word that embeds the matrix, where v is the size of the vocabulary. For each sentence, we build a DT-RNN based on the corresponding dependence on word embeddings as initialization. An example of the dependency parcel tree is shown in Figure 1 (a), where each edge begins from parentage and indicates its dependence on a syntactic relationship. In a DT-RNN, each node, including the nodes, internal nodes, and root nodes, is connected in a specific sentence to a word w, a hidden vector xw, and a hidden vector hn, which is in the same dimension as xw. Each dependency relationship r is connected to a separate matrix-Wr."}, {"heading": "4.2 Integration with CRFs", "text": "In the USA, the number of aged people compared to the aged people compared to the aged people compared to the aged people compared to the aged people compared to the aged people compared to the aged countries compared to the aged countries compared to the aged countries compared to the aged countries compared to the aged countries compared to the aged countries compared to the aged countries compared to the aged countries compared to the aged countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the years compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries compared to the countries"}, {"heading": "4.3 Joint Training for RNCRF", "text": "The aim of the maximum probability is to update the parameters of the RNCRF based on the parameters of the CRF (Unit Weight Matrices) by applying a chain rule to protocol errors. Following, the course of updates of the CRF (Unit Weight Matrices) is similar through the protocol potential of the paired clique gP (y \u2032 k, y \u2032 k + 1): \"Log\" U = \"Log\" p (y \u2032 k); \"Log\" gU (h, y \u2032 k); \"Log\" U (h, y \u2032 k); \"Log\" D \"U,\" (4); \"Log\" p (y | h); \"Log\" k \"gU\" (y \u2032 k); \"Log\" N \"(h);\" Log \"R\" h. \"The hidden representations of each word and the parameters of the DT-RP-k);\" Log \"N\" (y \u2032 k); \"Log\" 5 \"and\" Z \"(\")."}, {"heading": "5 Discussion", "text": "The best performing systems (Toh and Wang, 2014) for SemEval Challenge 2014 task 4 (Subtask 1) employs CRFs with extensive craftsmanship functions, including those induced by dependency trees. However, their experiments showed that the addition of dependency-induced characteristics does not improve performance, indicating the impracticality or difficulty of including dependency structures explicitly as input characteristics. Algorithm 1 Recursive Neural CRFs Input: A set of customer review sequences: S = s1,..., and attributes vectors of d dimensions for each word {xw} s, window size T for CRFs Output: N = {RNN, V} Initialization We use word2vec, and attributes vectors of d dimensions for each word."}, {"heading": "5.1 Adding Linguistic/Lexicon Features", "text": "RNCRF is an end-to-end model where feature engineering is not necessary. However, it is flexible to integrate lightweight handcrafted features into RNCRF to further enhance its performance, such as features with POS tags, name list or sentiment lexicon. These features can be attached to the hidden vector of each word, but remain stuck during training, unlike learnable neural inputs and CRF weights as described in Section 4.3. As shown in experiments, RNCRF easily outperforms the most powerful systems that require major efforts in feature engineering without handcrafted features, and RNCRF with Light Feature Engineering can achieve better performance."}, {"heading": "6 Experiment", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Dataset and Experimental Setup", "text": "In fact, it is the case that most of us are able to move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live."}, {"heading": "6.2 Experimental Results", "text": "This year it is more than ever before."}, {"heading": "7 Conclusion", "text": "We have presented a common model, RNCRF, that achieves state-of-the-art explicit aspect and opinion extraction from a benchmark dataset. DT-RNN enables high-level characteristics to be learned by encoding the underlying dual multiplication of aspects and opinion pairs. RNCRF combines the advantages of DT-RNNNs and CRFs, exceeding traditional rule-based methods in terms of flexibility, as aspect concepts and opinion concepts are not limited to specific observed relationships and POS tags. Compared to feature engineering methods with CRFs, the proposed model saves a lot of effort in composing characteristics and is able to extract superior characteristics from non-linear transformations."}, {"heading": "Acknowledgements", "text": "This research is partly funded by the Economic Development Board and the National Research Foundation of Singapore. Sinno J. Pan thanks the support of Fuji Xerox Corporation through joint research on multilingual semantic analysis and the NTU Singapore Nanyang Assistant Professorship (NAP) grant of M4081532.20."}], "references": [{"title": "Adaptive recursive neural network for target-dependent twitter sentiment classification", "author": ["Dong et al.2014] Li Dong", "Furu Wei", "Chuanqi Tan", "Duyu Tang", "Ming Zhou", "Ke Xu"], "venue": "In ACL,", "citeRegEx": "Dong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dong et al\\.", "year": 2014}, {"title": "The difficulty of training deep architectures and the effect of unsupervised pre-training", "author": ["Erhan et al.2009] Dumitru Erhan", "Pierre-Antoine Manzagol", "Yoshua Bengio", "Samy Bengio", "Pascal Vincent"], "venue": "In AISTATS,", "citeRegEx": "Erhan et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Erhan et al\\.", "year": 2009}, {"title": "Domain adaptation for largescale sentiment classification: A deep learning approach", "author": ["Glorot et al.2011] Xavier Glorot", "Antoine Bordes", "Yoshua Bengio"], "venue": "In ICML,", "citeRegEx": "Glorot et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Glorot et al\\.", "year": 2011}, {"title": "Learning task-dependent distributed representations by backpropagation through structure", "author": ["Goller", "K\u00fcchler1996] Christoph Goller", "Andreas K\u00fcchler"], "venue": "In ICNN,", "citeRegEx": "Goller et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Goller et al\\.", "year": 1996}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Mining and summarizing customer reviews", "author": ["Hu", "Liu2004a] Minqing Hu", "Bing Liu"], "venue": "In KDD,", "citeRegEx": "Hu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2004}, {"title": "Mining opinion features in customer reviews", "author": ["Hu", "Liu2004b] Minqing Hu", "Bing Liu"], "venue": "In AAAI,", "citeRegEx": "Hu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2004}, {"title": "Opinion mining with deep recurrent neural networks", "author": ["\u0130rsoy", "Cardie2014] Ozan \u0130rsoy", "Claire Cardie"], "venue": "In EMNLP,", "citeRegEx": "\u0130rsoy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "\u0130rsoy et al\\.", "year": 2014}, {"title": "A neural network for factoid question answering over paragraphs", "author": ["Iyyer et al.2014] Mohit Iyyer", "Jordan L. Boyd-Graber", "Leonardo Max Batista Claudino", "Richard Socher", "Hal Daum\u00e9 III"], "venue": null, "citeRegEx": "Iyyer et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Iyyer et al\\.", "year": 2014}, {"title": "Extracting opinion targets in a single- and cross-domain setting with conditional random fields", "author": ["Jakob", "Gurevych2010] Niklas Jakob", "Iryna Gurevych"], "venue": "In EMNLP,", "citeRegEx": "Jakob et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jakob et al\\.", "year": 2010}, {"title": "A novel lexicalized hmm-based learning framework for web opinion mining", "author": ["Jin", "Ho2009] Wei Jin", "Hung Hay Ho"], "venue": "In ICML,", "citeRegEx": "Jin et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jin et al\\.", "year": 2009}, {"title": "A convolutional neural network for modelling sentences", "author": ["Edward Grefenstette", "Phil Blunsom"], "venue": "In ACL,", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "In EMNLP,", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Accurate unlexicalized parsing", "author": ["Klein", "Manning2003] Dan Klein", "Christopher D. Manning"], "venue": "In ACL,", "citeRegEx": "Klein et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Klein et al\\.", "year": 2003}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["Andrew McCallum", "Fernando C.N. Pereira"], "venue": null, "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Aspect specific sentiment analysis using hierarchical deep learning", "author": ["Richard Socher", "Christopher D. Manning"], "venue": "In NIPS Workshop on Deep Learning and Representation Learning", "citeRegEx": "Lakkaraju et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lakkaraju et al\\.", "year": 2014}, {"title": "Distributed representations of sentences and documents", "author": ["Le", "Mikolov2014] Quoc V. Le", "Tomas Mikolov"], "venue": "In ICML,", "citeRegEx": "Le et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Le et al\\.", "year": 2014}, {"title": "Structure-aware review mining and summarization", "author": ["Li et al.2010] Fangtao Li", "Chao Han", "Minlie Huang", "Xiaoyan Zhu", "Ying-Ju Xia", "Shu Zhang", "Hao Yu"], "venue": "In COLING,", "citeRegEx": "Li et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Li et al\\.", "year": 2010}, {"title": "Opinion target extraction using word-based translation model", "author": ["Kang Liu", "Liheng Xu", "Jun Zhao"], "venue": "In EMNLP-CoNLL,", "citeRegEx": "Liu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Opinion target extraction using partially-supervised word alignment model", "author": ["Liu et al.2013a] Kang Liu", "Liheng Xu", "Yang Liu", "Jun Zhao"], "venue": "In IJCAI,", "citeRegEx": "Liu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2013}, {"title": "A logic programming approach to aspect extraction in opinion mining", "author": ["Liu et al.2013b] Qian Liu", "Zhiqiang Gao", "Bing Liu", "Yuanlin Zhang"], "venue": "In WI,", "citeRegEx": "Liu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2013}, {"title": "Fine-grained opinion mining with recurrent neural networks and word embeddings", "author": ["Liu et al.2015] Pengfei Liu", "Shafiq Joty", "Helen Meng"], "venue": "In EMNLP,", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Web Data Mining: Exploring Hyperlinks, Contents, and Usage Data", "author": ["Bing Liu"], "venue": "Second Edition. Data-Centric Systems and Applications. Springer", "citeRegEx": "Liu.,? \\Q2011\\E", "shortCiteRegEx": "Liu.", "year": 2011}, {"title": "Automatic construction of a context-aware sentiment lexicon: An optimization approach", "author": ["Lu et al.2011] Yue Lu", "Malu Castellanos", "Umeshwar Dayal", "ChengXiang Zhai"], "venue": "In WWW,", "citeRegEx": "Lu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2011}, {"title": "Opinion target extraction in chinese news comments", "author": ["Ma", "Wan2010] Tengfei Ma", "Xiaojun Wan"], "venue": "In COLING,", "citeRegEx": "Ma et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2010}, {"title": "Learning attitudes and attributes from multi-aspect reviews", "author": ["Jure Leskovec", "Dan Jurafsky"], "venue": "In ICDM,", "citeRegEx": "McAuley et al\\.,? \\Q2012\\E", "shortCiteRegEx": "McAuley et al\\.", "year": 2012}, {"title": "Image-based recommendations on styles and substitutes", "author": ["Christopher Targett", "Qinfeng Shi", "Anton van den Hengel"], "venue": "In SIGIR,", "citeRegEx": "McAuley et al\\.,? \\Q2015\\E", "shortCiteRegEx": "McAuley et al\\.", "year": 2015}, {"title": "Efficient estimation of word representations in vector space. CoRR, abs/1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Unsupervised commonsense knowledge enrichment for domain-specific sentiment analysis", "author": ["Ofek et al.2016] Nir Ofek", "Soujanya Poria", "Lior Rokach", "Erik Cambria", "Amir Hussain", "Asaf Shabtai"], "venue": "Cognitive Computation,", "citeRegEx": "Ofek et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ofek et al\\.", "year": 2016}, {"title": "Crfsuite: a fast implementation of conditional random fields (CRFs). http://www.chokkan.org/software/crfsuite", "author": ["Naoaki Okazaki"], "venue": null, "citeRegEx": "Okazaki.,? \\Q2007\\E", "shortCiteRegEx": "Okazaki.", "year": 2007}, {"title": "Opinion mining and sentiment analysis", "author": ["Pang", "Lee2008] Bo Pang", "Lillian Lee"], "venue": "Foundations and Trends in Information Retrieval,", "citeRegEx": "Pang et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2008}, {"title": "Extracting product features and opinions from reviews", "author": ["Popescu", "Etzioni2005] Ana-Maria Popescu", "Oren Etzioni"], "venue": "In EMNLP,", "citeRegEx": "Popescu et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Popescu et al\\.", "year": 2005}, {"title": "Opinion word expansion and target extraction through double propagation", "author": ["Qiu et al.2011] Guang Qiu", "Bing Liu", "Jiajun Bu", "Chun Chen"], "venue": null, "citeRegEx": "Qiu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Qiu et al\\.", "year": 2011}, {"title": "Learning Continuous Phrase Representations and Syntactic Parsing with Recursive Neural Networks", "author": ["Christopher D. Manning", "Andrew Y. Ng"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2010}, {"title": "Parsing natural scenes and natural language with recursive neural networks", "author": ["Cliff C. Lin", "Andrew Y. Ng", "Christopher D. Manning"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions", "author": ["Jeffrey Pennington", "Eric H. Huang", "Andrew Y. Ng", "Christopher D. Manning"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Semantic Compositionality Through Recursive Matrix-Vector Spaces", "author": ["Brody Huval", "Christopher D. Manning", "Andrew Y. Ng"], "venue": "In EMNLP,", "citeRegEx": "Socher et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2012}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Y. Ng", "Christopher Potts"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Grounded compositional semantics for finding and describing images with sentences", "author": ["Andrej Karpathy", "Quoc V. Le", "Christopher D. Manning", "Andrew Y. Ng"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2014}, {"title": "Target-dependent sentiment classification with long short term memory. CoRR, abs/1512.01100", "author": ["Tang et al.2015] Duyu Tang", "Bing Qin", "Xiaocheng Feng", "Ting Liu"], "venue": null, "citeRegEx": "Tang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2015}, {"title": "A joint model of text and aspect ratings for sentiment summarization", "author": ["Titov", "McDonald2008] Ivan Titov", "Ryan T. McDonald"], "venue": "In ACL,", "citeRegEx": "Titov et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Titov et al\\.", "year": 2008}, {"title": "Dlirec: Aspect term extraction and term polarity classification system", "author": ["Toh", "Wang2014] Zhiqiang Toh", "Wenting Wang"], "venue": "In SemEval,", "citeRegEx": "Toh et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Toh et al\\.", "year": 2014}, {"title": "Feature-rich part-of-speech tagging with a cyclic dependency network", "author": ["Dan Klein", "Christopher D. Manning", "Yoram Singer"], "venue": "In NAACL,", "citeRegEx": "Toutanova et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2003}, {"title": "A sentiment-aligned topic model for product aspect rating prediction", "author": ["Wang", "Ester2014] Hao Wang", "Martin Ester"], "venue": "In EMNLP,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Latent aspect rating analysis without aspect keyword supervision", "author": ["Wang et al.2011] Hongning Wang", "Yue Lu", "ChengXiang Zhai"], "venue": "In KDD,", "citeRegEx": "Wang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Structured training for neural network transition-based parsing", "author": ["Weiss et al.2015] David Weiss", "Chris Alberti", "Michael Collins", "Slav Petrov"], "venue": "In ACLIJCNLP,", "citeRegEx": "Weiss et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Weiss et al\\.", "year": 2015}, {"title": "Phrase dependency parsing for opinion mining", "author": ["Wu et al.2009] Yuanbin Wu", "Qi Zhang", "Xuanjing Huang", "Lide Wu"], "venue": "In EMNLP,", "citeRegEx": "Wu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2009}, {"title": "Unsupervised word and dependency path embeddings for aspect term extraction", "author": ["Yin et al.2016] Yichun Yin", "Furu Wei", "Li Dong", "Kaimeng Xu", "Ming Zhang", "Ming Zhou"], "venue": "In IJCAI,", "citeRegEx": "Yin et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yin et al\\.", "year": 2016}, {"title": "Extracting and ranking product features in opinion documents", "author": ["Zhang et al.2010] Lei Zhang", "Bing Liu", "Suk Hwan Lim", "Eamonn O\u2019Brien-Strain"], "venue": "In COLING,", "citeRegEx": "Zhang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2010}, {"title": "Movie review mining and summarization", "author": ["Zhuang et al.2006] Li Zhuang", "Feng Jing", "Xiao-Yan Zhu"], "venue": "In CIKM,", "citeRegEx": "Zhuang et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Zhuang et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 22, "context": "Aspect-based sentiment analysis (Pang and Lee, 2008; Liu, 2011) aims to extract important information, e.", "startOffset": 32, "endOffset": 63}, {"referenceID": 49, "context": "This task was first studied by Hu and Liu (2004a; 2004b), followed by (Popescu and Etzioni, 2005; Zhuang et al., 2006; Zhang et al., 2010; Qiu et al., 2011; Li et al., 2010).", "startOffset": 70, "endOffset": 173}, {"referenceID": 48, "context": "This task was first studied by Hu and Liu (2004a; 2004b), followed by (Popescu and Etzioni, 2005; Zhuang et al., 2006; Zhang et al., 2010; Qiu et al., 2011; Li et al., 2010).", "startOffset": 70, "endOffset": 173}, {"referenceID": 32, "context": "This task was first studied by Hu and Liu (2004a; 2004b), followed by (Popescu and Etzioni, 2005; Zhuang et al., 2006; Zhang et al., 2010; Qiu et al., 2011; Li et al., 2010).", "startOffset": 70, "endOffset": 173}, {"referenceID": 17, "context": "This task was first studied by Hu and Liu (2004a; 2004b), followed by (Popescu and Etzioni, 2005; Zhuang et al., 2006; Zhang et al., 2010; Qiu et al., 2011; Li et al., 2010).", "startOffset": 70, "endOffset": 173}, {"referenceID": 32, "context": "Among previous work, one of the approaches is to accumulate aspect and opinion terms from a seed collection without label information, by utilizing syntactic rules or modification relations between them (Qiu et al., 2011; Liu et al., 2013b).", "startOffset": 203, "endOffset": 240}, {"referenceID": 17, "context": "Another approach focuses on feature engineering based on predefined lexicons, syntactic analysis, etc (Jin and Ho, 2009; Li et al., 2010).", "startOffset": 102, "endOffset": 137}, {"referenceID": 33, "context": "The first component is to construct a recursive neural network (RNN)1 (Socher et al., 2010) based on a dependency tree of each sentence.", "startOffset": 70, "endOffset": 91}, {"referenceID": 14, "context": "The output of the RNN is then fed into a Conditional Random Field (CRF) (Lafferty et al., 2001)", "startOffset": 72, "endOffset": 95}, {"referenceID": 46, "context": "In follow-up work, syntactic relations are further exploited for aspect/opinion extraction (Popescu and Etzioni, 2005; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 91, "endOffset": 153}, {"referenceID": 32, "context": "In follow-up work, syntactic relations are further exploited for aspect/opinion extraction (Popescu and Etzioni, 2005; Wu et al., 2009; Qiu et al., 2011).", "startOffset": 91, "endOffset": 153}, {"referenceID": 18, "context": "Another direction is to use word alignment model to capture opinion relations among a sentence (Liu et al., 2012; Liu et al., 2013a).", "startOffset": 95, "endOffset": 132}, {"referenceID": 15, "context": "Besides explicit aspects and opinions extraction, there are also other lines of research related to aspect-based sentiment analysis, including aspect classification (Lakkaraju et al., 2014; McAuley et al., 2012), aspect rating (Titov and McDonald, 2008; Wang et al.", "startOffset": 165, "endOffset": 211}, {"referenceID": 25, "context": "Besides explicit aspects and opinions extraction, there are also other lines of research related to aspect-based sentiment analysis, including aspect classification (Lakkaraju et al., 2014; McAuley et al., 2012), aspect rating (Titov and McDonald, 2008; Wang et al.", "startOffset": 165, "endOffset": 211}, {"referenceID": 44, "context": ", 2012), aspect rating (Titov and McDonald, 2008; Wang et al., 2011; Wang and Ester, 2014), domainspecific and target-dependent sentiment classification (Lu et al.", "startOffset": 23, "endOffset": 90}, {"referenceID": 23, "context": ", 2011; Wang and Ester, 2014), domainspecific and target-dependent sentiment classification (Lu et al., 2011; Ofek et al., 2016; Dong et al., 2014; Tang et al., 2015).", "startOffset": 92, "endOffset": 166}, {"referenceID": 28, "context": ", 2011; Wang and Ester, 2014), domainspecific and target-dependent sentiment classification (Lu et al., 2011; Ofek et al., 2016; Dong et al., 2014; Tang et al., 2015).", "startOffset": 92, "endOffset": 166}, {"referenceID": 0, "context": ", 2011; Wang and Ester, 2014), domainspecific and target-dependent sentiment classification (Lu et al., 2011; Ofek et al., 2016; Dong et al., 2014; Tang et al., 2015).", "startOffset": 92, "endOffset": 166}, {"referenceID": 39, "context": ", 2011; Wang and Ester, 2014), domainspecific and target-dependent sentiment classification (Lu et al., 2011; Ofek et al., 2016; Dong et al., 2014; Tang et al., 2015).", "startOffset": 92, "endOffset": 166}, {"referenceID": 36, "context": "Recent studies have shown that deep learning models can automatically learn the inherent semantic and syntactic information from data and thus achieve better performance for sentiment analysis (Socher et al., 2011b; Socher et al., 2012; Socher et al., 2013; Glorot et al., 2011; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014).", "startOffset": 193, "endOffset": 338}, {"referenceID": 37, "context": "Recent studies have shown that deep learning models can automatically learn the inherent semantic and syntactic information from data and thus achieve better performance for sentiment analysis (Socher et al., 2011b; Socher et al., 2012; Socher et al., 2013; Glorot et al., 2011; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014).", "startOffset": 193, "endOffset": 338}, {"referenceID": 2, "context": "Recent studies have shown that deep learning models can automatically learn the inherent semantic and syntactic information from data and thus achieve better performance for sentiment analysis (Socher et al., 2011b; Socher et al., 2012; Socher et al., 2013; Glorot et al., 2011; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014).", "startOffset": 193, "endOffset": 338}, {"referenceID": 11, "context": "Recent studies have shown that deep learning models can automatically learn the inherent semantic and syntactic information from data and thus achieve better performance for sentiment analysis (Socher et al., 2011b; Socher et al., 2012; Socher et al., 2013; Glorot et al., 2011; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014).", "startOffset": 193, "endOffset": 338}, {"referenceID": 12, "context": "Recent studies have shown that deep learning models can automatically learn the inherent semantic and syntactic information from data and thus achieve better performance for sentiment analysis (Socher et al., 2011b; Socher et al., 2012; Socher et al., 2013; Glorot et al., 2011; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014).", "startOffset": 193, "endOffset": 338}, {"referenceID": 1, "context": ", 2013; Glorot et al., 2011; Kalchbrenner et al., 2014; Kim, 2014; Le and Mikolov, 2014). These methods generally belong to sentence-level or phrase/wordlevel sentiment polarity predictions. Regarding aspect-based sentiment analysis, Irsoy et al. (2014) applied deep recurrent neural networks for opinion expression extraction.", "startOffset": 8, "endOffset": 254}, {"referenceID": 0, "context": "Dong et al. (2014) proposed an adaptive recurrent neural network for target-dependent sentiment classification, where targets or aspects are given as input.", "startOffset": 0, "endOffset": 19}, {"referenceID": 0, "context": "Dong et al. (2014) proposed an adaptive recurrent neural network for target-dependent sentiment classification, where targets or aspects are given as input. Tang et al. (2015) used Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) for the same task.", "startOffset": 0, "endOffset": 176}, {"referenceID": 21, "context": "To the best of our knowledge, the most related works to ours are (Liu et al., 2015; Yin et al., 2016).", "startOffset": 65, "endOffset": 101}, {"referenceID": 47, "context": "To the best of our knowledge, the most related works to ours are (Liu et al., 2015; Yin et al., 2016).", "startOffset": 65, "endOffset": 101}, {"referenceID": 18, "context": "To the best of our knowledge, the most related works to ours are (Liu et al., 2015; Yin et al., 2016). Liu et al. (2015) proposed to combine recurrent neural network and word embeddings to extract explicit aspects.", "startOffset": 66, "endOffset": 121}, {"referenceID": 18, "context": "To the best of our knowledge, the most related works to ours are (Liu et al., 2015; Yin et al., 2016). Liu et al. (2015) proposed to combine recurrent neural network and word embeddings to extract explicit aspects. However, the proposed model simply uses recurrent neural network on top of word embeddings, and thus its performance heavily depends on the quality of word embeddings. In addition, it fails to explicitly model dependency relations or compositionalities within certain syntactic structure in a sentence. Recently, Yin et al. (2016) proposed an unsupervised learning method to improve word embeddings using dependency path embeddings.", "startOffset": 66, "endOffset": 546}, {"referenceID": 47, "context": "Different from (Yin et al., 2016), our model does not focus on developing a new unsupervised word embedding methods, but encoding the information of dependency paths into RNN for constructing syntactically meaningful and discriminative hidden rep-", "startOffset": 15, "endOffset": 33}, {"referenceID": 47, "context": "Moreover, we integrate RNN and CRF into a unified framework, and develop a joint optimization approach, instead of training word embeddings and a CRF separately as in (Yin et al., 2016).", "startOffset": 167, "endOffset": 185}, {"referenceID": 45, "context": "Note that Weiss et al. (2015) proposed to combine deep learning and structured learning for language parsing which can be learned by structured perceptron.", "startOffset": 10, "endOffset": 30}, {"referenceID": 33, "context": "Among deep learning methods, RNN has shown promising results on various NLP tasks, such as learning phrase representations (Socher et al., 2010), sentence-level sentiment analysis (Socher et al.", "startOffset": 123, "endOffset": 144}, {"referenceID": 37, "context": ", 2010), sentence-level sentiment analysis (Socher et al., 2013), language parsing (Socher et al.", "startOffset": 43, "endOffset": 64}, {"referenceID": 8, "context": ", 2011a), and question answering (Iyyer et al., 2014).", "startOffset": 33, "endOffset": 53}, {"referenceID": 33, "context": "In a constituency tree, all the words lie at leaf nodes, each internal node represents a phrase or a constituent of a sentence, and the root node represents the entire sentence (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013).", "startOffset": 177, "endOffset": 240}, {"referenceID": 36, "context": "In a constituency tree, all the words lie at leaf nodes, each internal node represents a phrase or a constituent of a sentence, and the root node represents the entire sentence (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013).", "startOffset": 177, "endOffset": 240}, {"referenceID": 37, "context": "In a constituency tree, all the words lie at leaf nodes, each internal node represents a phrase or a constituent of a sentence, and the root node represents the entire sentence (Socher et al., 2010; Socher et al., 2012; Socher et al., 2013).", "startOffset": 177, "endOffset": 240}, {"referenceID": 38, "context": "In a dependency tree, each node including terminal and nonterminal nodes, represents a word, with dependency connections to other nodes (Socher et al., 2014; Iyyer et al., 2014).", "startOffset": 136, "endOffset": 177}, {"referenceID": 8, "context": "In a dependency tree, each node including terminal and nonterminal nodes, represents a word, with dependency connections to other nodes (Socher et al., 2014; Iyyer et al., 2014).", "startOffset": 136, "endOffset": 177}, {"referenceID": 27, "context": "For word vector initialization, we train word embeddings with word2vec (Mikolov et al., 2013) on the Yelp Challenge dataset4 for the restaurant domain and on the Amazon reviews5 (McAuley et al.", "startOffset": 71, "endOffset": 93}, {"referenceID": 26, "context": ", 2013) on the Yelp Challenge dataset4 for the restaurant domain and on the Amazon reviews5 (McAuley et al., 2015) for the laptop domain.", "startOffset": 92, "endOffset": 114}, {"referenceID": 29, "context": "Regarding CRFs, we implement a linear-chain CRF using CRFSuite (Okazaki, 2007).", "startOffset": 63, "endOffset": 78}, {"referenceID": 1, "context": "error, which is a common strategy for deep learning (Erhan et al., 2009).", "startOffset": 52, "endOffset": 72}, {"referenceID": 42, "context": "For POS tags, we use Stanford POS tagger (Toutanova et al., 2003), and convert them to universal POS tags that have 15 different categories.", "startOffset": 41, "endOffset": 65}, {"referenceID": 21, "context": "\u2022 LSTM: an LSTM network built on top of word embeddings proposed by (Liu et al., 2015).", "startOffset": 68, "endOffset": 86}, {"referenceID": 21, "context": "We keep original settings in (Liu et al., 2015) but replace their word embeddings with ours (300 dimension).", "startOffset": 29, "endOffset": 47}, {"referenceID": 47, "context": "\u2022 WDEmb+B+CRF6: the model proposed by (Yin et al., 2016) using word and dependency path embeddings combined with linear context embedding features, dependency context embedding features and hand-crafted features (i.", "startOffset": 38, "endOffset": 56}, {"referenceID": 47, "context": "We report the best results from the original paper (Yin et al., 2016).", "startOffset": 51, "endOffset": 69}, {"referenceID": 21, "context": "LSTM has shown comparable results for aspect extraction (Liu et al., 2015).", "startOffset": 56, "endOffset": 74}], "year": 2016, "abstractText": "In aspect-based sentiment analysis, extracting aspect terms along with the opinions being expressed from user-generated content is one of the most important subtasks. Previous studies have shown that exploiting connections between aspect and opinion terms is promising for this task. In this paper, we propose a novel joint model that integrates recursive neural networks and conditional random fields into a unified framework for explicit aspect and opinion terms co-extraction. The proposed model learns high-level discriminative features and double propagates information between aspect and opinion terms, simultaneously. Moreover, it is flexible to incorporate hand-crafted features into the proposed model to further boost its information extraction performance. Experimental results on the dataset from SemEval Challenge 2014 task 4 show the superiority of our proposed model over several baseline methods as well as the winning systems of the challenge.", "creator": "LaTeX with hyperref package"}}}