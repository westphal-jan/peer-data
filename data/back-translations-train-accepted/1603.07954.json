{"id": "1603.07954", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Mar-2016", "title": "Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning", "abstract": "In traditional formulations, information extraction systems operate on a fixed collection of documents. In this work, we explore the task of acquiring and incorporating external evidence to improve extraction accuracy. This process entails query reformulation for search, extraction from new sources and reconciliation of extracted values, which are repeated until sufficient evidence is collected. We approach the problem using a reinforcement learning framework where our model learns to select optimal actions based on contextual information. We employ a deep Q-network, trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort. Our experiments on a publicly available database of shooting incidents demonstrate that our system outperforms traditional extractors by 7.2% on average.", "histories": [["v1", "Fri, 25 Mar 2016 16:38:54 GMT  (1314kb,D)", "http://arxiv.org/abs/1603.07954v1", "10 pages"], ["v2", "Tue, 14 Jun 2016 03:24:37 GMT  (1175kb,D)", "http://arxiv.org/abs/1603.07954v2", "Updated with additional experiments, 10 pages"], ["v3", "Tue, 27 Sep 2016 23:33:28 GMT  (1181kb,D)", "http://arxiv.org/abs/1603.07954v3", "Appearing in EMNLP 2016 (12 pages incl. supplementary material)"]], "COMMENTS": "10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["karthik narasimhan", "adam yala", "regina barzilay"], "accepted": true, "id": "1603.07954"}, "pdf": {"name": "1603.07954.pdf", "metadata": {"source": "CRF", "title": "Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning", "authors": ["Karthik Narasimhan", "Adam Yala", "Regina Barzilay"], "emails": ["karthikn@csail.mit.edu", "adamyala@mit.edu", "regina@csail.mit.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are in a position to put themselves in another world, in which they put themselves in another world, in which they find themselves in another world, in which they find themselves in another world, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they do not find themselves, in which they will not find themselves, in which they will not find themselves, in which they will not find themselves."}, {"heading": "2 Related Work", "text": "In fact, most of them are able to survive on their own if they do not put themselves in a position to survive on their own."}, {"heading": "3 Framework", "text": "We model the information extraction task as a Markov Decision Process (MDP), in which the model learns to use external sources to improve extractions from a source article (see Figure 3). The MDP framework allows us to integrate detailed predictions, while at the same time providing the flexibility to select the type of article from which to extract. At each step, the system must match the extracted values from a related article to the current values and decide on the next query for restoring further articles. We represent the MDP as a tuple < S, T, R, S}, is the space of all possible states where it is possible, A = (d, q)}} is the set of all actions, R (s) is the reward function, and T (s) is the transition function."}, {"heading": "4 Reinforcement Learning for Information Extraction", "text": "To learn a good policy for an agent, we use the paradigm of Reinforcement q Learning (RL). The MDP described in the previous section can be considered in terms of a sequence of transitions (s, a, r, s). The agent typically uses a state-action value function Q (s, a) to determine which action a will perform in state s. A commonly used technique for learning an optimal value function is Q-Learning (Watkins and Dayan, 1992), in which the agent calculates Q (s, a) iteratively using the rewards from episodes. Updates are derived from the Bellman equation (Sutton and Barto, 1998), which provides a recursive equation for the optimal value Q."}, {"heading": "5 Experimental Setup", "text": "We are conducting experiments with data collected by the Gun Violence Archive, 6 a website tracking Q = http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / http: / / / http: / / http: / / http: / / http: / / http: / / / http: / / / http: / / / / http: / / / / http: / / / http: / / http: / / http: / / http: / / http _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _ de _"}, {"heading": "6 Results", "text": "In fact, the fact is that most of them are able to show themselves, that they are able, that they are able, that they are able to move, and that they are able, that they are able, to be able, to be able."}, {"heading": "7 Conclusions", "text": "In this paper, we explore the task of collecting and incorporating external evidence to improve extraction accuracy. This process involves reformulating queries for searching, extracting from new sources, and matching extracted values that are repeated until there is sufficient evidence. We use a reinforcement learning framework and learn best practices to maximize extraction accuracy while punishing additional effort. We show that our model, which was trained as the Deep Q Network, outperforms traditional extractors by an average of 7.2%. We also show the importance of sequential decision making by comparing our model to a meta classifier that operates in the same space, achieving a 7% gain in accuracy."}, {"heading": "Acknowledgements", "text": "We thank Tao Lei, David Alvarez and Ramya Ramakrishnan for their helpful discussions and feedback. We also thank the members of the MIT NLP group for their insightful comments."}], "references": [{"title": "Snowball: Extracting relations from large plain-text collections", "author": ["Agichtein", "Gravano2000] Eugene Agichtein", "Luis Gravano"], "venue": "In Proceedings of the fifth ACM conference on Digital libraries,", "citeRegEx": "Agichtein et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Agichtein et al\\.", "year": 2000}, {"title": "Askmsr: Question answering using the worldwide web", "author": ["Banko et al.2002] Michele Banko", "Eric Brill", "Susan Dumais", "Jimmy Lin"], "venue": "In Proceedings of 2002 AAAI Spring Symposium on Mining Answers from Texts and Knowledge Bases,", "citeRegEx": "Banko et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Banko et al\\.", "year": 2002}, {"title": "Unsupervised event coreference resolution", "author": ["Bejan", "Sanda Harabagiu"], "venue": "Computational Linguistics,", "citeRegEx": "Bejan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bejan et al\\.", "year": 2014}, {"title": "The use of lexical semantics in information extraction", "author": ["Chai", "Biermann1997] Joyce Yue Chai", "Alan Biermann"], "venue": "In Proceedings of the ACL Workshop on Natural Language Learning. Citeseer", "citeRegEx": "Chai et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Chai et al\\.", "year": 1997}, {"title": "A joint model for entity analysis: Coreference", "author": ["Durrett", "Klein2014] Greg Durrett", "Dan Klein"], "venue": "typing, and linking. Transactions of the Association for Computational Linguistics,", "citeRegEx": "Durrett et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2014}, {"title": "Open information extraction: The second generation", "author": ["Etzioni et al.2011] Oren Etzioni", "Anthony Fader", "Janara Christensen", "Stephen Soderland", "Mausam Mausam"], "venue": "In IJCAI,", "citeRegEx": "Etzioni et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Etzioni et al\\.", "year": 2011}, {"title": "Identifying relations for open information extraction", "author": ["Fader et al.2011] Anthony Fader", "Stephen Soderland", "Oren Etzioni"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Fader et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Fader et al\\.", "year": 2011}, {"title": "Incorporating vector space similarity in random walk inference over knowledge bases", "author": ["Gardner et al.2014] Matt Gardner", "Partha Talukdar", "Jayant Krishnamurthy", "Tom Mitchell"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Nat-", "citeRegEx": "Gardner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gardner et al\\.", "year": 2014}, {"title": "Traversing knowledge graphs in vector space", "author": ["Guu et al.2015] Kelvin Guu", "John Miller", "Percy Liang"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Guu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Guu et al\\.", "year": 2015}, {"title": "Collective entity linking in web text: a graphbased method", "author": ["Han et al.2011] Xianpei Han", "Le Sun", "Jun Zhao"], "venue": "In Proceedings of the 34th interna-", "citeRegEx": "Han et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Han et al\\.", "year": 2011}, {"title": "Deep reinforcement learning with an action space defined by natural language. arXiv preprint arXiv:1511.04636", "author": ["He et al.2015] Ji He", "Jianshu Chen", "Xiaodong He", "Jianfeng Gao", "Lihong Li", "Li Deng", "Mari Ostendorf"], "venue": null, "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Semantics-based information extraction for detecting economic events", "author": ["Frederik Hogenboom", "Flavius Frasincar", "Kim Schouten", "Otto van der Meer"], "venue": "Multimedia Tools and Applications,", "citeRegEx": "Hogenboom et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hogenboom et al\\.", "year": 2013}, {"title": "Selecting actions for resource-bounded information extraction using reinforcement learning", "author": ["Kanani", "McCallum2012] Pallika H Kanani", "Andrew K McCallum"], "venue": "In Proceedings of the fifth ACM international conference on Web search and", "citeRegEx": "Kanani et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kanani et al\\.", "year": 2012}, {"title": "Joint entity and event coreference resolution across documents", "author": ["Lee et al.2012] Heeyoung Lee", "Marta Recasens", "Angel Chang", "Mihai Surdeanu", "Dan Jurafsky"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language", "citeRegEx": "Lee et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2012}, {"title": "Multi-field information extraction and cross-document fusion", "author": ["Mann", "Yarowsky2005] Gideon S Mann", "David Yarowsky"], "venue": "In Proceedings of the 43rd annual meeting on association for computational linguistics,", "citeRegEx": "Mann et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Mann et al\\.", "year": 2005}, {"title": "Human-level control through deep reinforcement learning", "author": ["Antonoglou", "Helen King", "Dharshan Kumaran", "Daan Wierstra", "Shane Legg", "Demis Hassabis."], "venue": "Nature, 518(7540):529\u2013533, 02.", "citeRegEx": "Antonoglou et al\\.,? 2015", "shortCiteRegEx": "Antonoglou et al\\.", "year": 2015}, {"title": "Relational learning of pattern-match rules for information extraction", "author": ["R Mooney"], "venue": "In Proceedings of the Sixteenth National Conference on Artificial Intelligence,", "citeRegEx": "Mooney.,? \\Q1999\\E", "shortCiteRegEx": "Mooney.", "year": 1999}, {"title": "Language understanding for text-based games using deep reinforcement learning", "author": ["Tejas Kulkarni", "Regina Barzilay"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language", "citeRegEx": "Narasimhan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Narasimhan et al\\.", "year": 2015}, {"title": "Compositional vector space models for knowledge", "author": ["Benjamin Roth", "Andrew McCallum"], "venue": null, "citeRegEx": "Neelakantan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2015}, {"title": "Joint inference in information extraction", "author": ["Poon", "Domingos2007] Hoifung Poon", "Pedro Domingos"], "venue": "In AAAI,", "citeRegEx": "Poon et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Poon et al\\.", "year": 2007}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["Danqi Chen", "Christopher D Manning", "Andrew Ng"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Introduction to reinforcement learning", "author": ["Sutton", "Barto1998] Richard S Sutton", "Andrew G Barto"], "venue": null, "citeRegEx": "Sutton et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1998}, {"title": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude", "author": ["Tieleman", "Hinton2012] Tijmen Tieleman", "Geoffrey Hinton"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Tieleman et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Tieleman et al\\.", "year": 2012}, {"title": "Knowledge base completion via search-based question answering", "author": ["West et al.2014] Robert West", "Evgeniy Gabrilovich", "Kevin Murphy", "Shaohua Sun", "Rahul Gupta", "Dekang Lin"], "venue": "In Proceedings of the 23rd international conference on World", "citeRegEx": "West et al\\.,? \\Q2014\\E", "shortCiteRegEx": "West et al\\.", "year": 2014}, {"title": "Open information extraction using wikipedia", "author": ["Wu", "Weld2010] Fei Wu", "Daniel S Weld"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,", "citeRegEx": "Wu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2010}, {"title": "Embedding entities and relations for learning and inference in knowledge bases", "author": ["Yang et al.2014] Bishan Yang", "Wen-tau Yih", "Xiaodong He", "Jianfeng Gao", "Li Deng"], "venue": "arXiv preprint arXiv:1412.6575", "citeRegEx": "Yang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 16, "context": "is to augment information extraction systems with elaborate semantic inference (Chai and Biermann, 1997; Mooney, 1999; Poon and Domingos, 2007; Hogenboom et al., 2013).", "startOffset": 79, "endOffset": 167}, {"referenceID": 11, "context": "is to augment information extraction systems with elaborate semantic inference (Chai and Biermann, 1997; Mooney, 1999; Poon and Domingos, 2007; Hogenboom et al., 2013).", "startOffset": 79, "endOffset": 167}, {"referenceID": 5, "context": "Open Information Extraction Existing work in open IE has used external sources from the web to improve extraction accuracy and coverage (Agichtein and Gravano, 2000; Etzioni et al., 2011; Fader et al., 2011; Wu and Weld, 2010).", "startOffset": 136, "endOffset": 226}, {"referenceID": 6, "context": "Open Information Extraction Existing work in open IE has used external sources from the web to improve extraction accuracy and coverage (Agichtein and Gravano, 2000; Etzioni et al., 2011; Fader et al., 2011; Wu and Weld, 2010).", "startOffset": 136, "endOffset": 226}, {"referenceID": 13, "context": "Therefore, the novel challenge of our task resides in performing event coreference (Lee et al., 2012; Bejan and Harabagiu, 2014) (i.", "startOffset": 83, "endOffset": 128}, {"referenceID": 9, "context": "Entity linking, multi-document extraction and event coreference Our work also relates to the task of multi-document information extraction, where the goal is to connect different mentions of the same entity across input documents (Mann and Yarowsky, 2005; Han et al., 2011; Durrett and Klein, 2014).", "startOffset": 230, "endOffset": 298}, {"referenceID": 20, "context": "Knowledge Base Completion and Online Search Recent work has explored several techniques to perform Knowledge Base Completion (KBC) such as vector space models and graph traversal (Socher et al., 2013; Yang et al., 2014; Gardner et al., 2014; Neelakantan et al., 2015; Guu et al., 2015).", "startOffset": 179, "endOffset": 285}, {"referenceID": 25, "context": "Knowledge Base Completion and Online Search Recent work has explored several techniques to perform Knowledge Base Completion (KBC) such as vector space models and graph traversal (Socher et al., 2013; Yang et al., 2014; Gardner et al., 2014; Neelakantan et al., 2015; Guu et al., 2015).", "startOffset": 179, "endOffset": 285}, {"referenceID": 7, "context": "Knowledge Base Completion and Online Search Recent work has explored several techniques to perform Knowledge Base Completion (KBC) such as vector space models and graph traversal (Socher et al., 2013; Yang et al., 2014; Gardner et al., 2014; Neelakantan et al., 2015; Guu et al., 2015).", "startOffset": 179, "endOffset": 285}, {"referenceID": 18, "context": "Knowledge Base Completion and Online Search Recent work has explored several techniques to perform Knowledge Base Completion (KBC) such as vector space models and graph traversal (Socher et al., 2013; Yang et al., 2014; Gardner et al., 2014; Neelakantan et al., 2015; Guu et al., 2015).", "startOffset": 179, "endOffset": 285}, {"referenceID": 8, "context": "Knowledge Base Completion and Online Search Recent work has explored several techniques to perform Knowledge Base Completion (KBC) such as vector space models and graph traversal (Socher et al., 2013; Yang et al., 2014; Gardner et al., 2014; Neelakantan et al., 2015; Guu et al., 2015).", "startOffset": 179, "endOffset": 285}, {"referenceID": 7, "context": ", 2014; Gardner et al., 2014; Neelakantan et al., 2015; Guu et al., 2015). Though our work also aims at increasing extraction recall for a database, traditional KBC approaches do not require searching for additional sources of information. West et al. (2014) explore query reformulation in the context of KBC.", "startOffset": 8, "endOffset": 259}, {"referenceID": 1, "context": "Our approach is also close in spirit to the AskMSR system (Banko et al., 2002) which aims at using information redundancy on the web to better answer questions.", "startOffset": 58, "endOffset": 78}, {"referenceID": 17, "context": "The DQN, in which the Q-function is approximated using a deep neural network, has been shown to learn better value functions than linear approximators (Narasimhan et al., 2015; He et al., 2015) and can capture nonlinear interactions between the different pieces of information in our state.", "startOffset": 151, "endOffset": 193}, {"referenceID": 10, "context": "The DQN, in which the Q-function is approximated using a deep neural network, has been shown to learn better value functions than linear approximators (Narasimhan et al., 2015; He et al., 2015) and can capture nonlinear interactions between the different pieces of information in our state.", "startOffset": 151, "endOffset": 193}], "year": 2016, "abstractText": "In traditional formulations, information extraction systems operate on a fixed collection of documents. In this work, we explore the task of acquiring and incorporating external evidence to improve extraction accuracy. This process entails query reformulation for search, extraction from new sources and reconciliation of extracted values, which are repeated until sufficient evidence is collected. We approach the problem using a reinforcement learning framework where our model learns to select optimal actions based on contextual information. We employ a deep Q-network, trained to optimize a reward function that reflects extraction accuracy while penalizing extra effort. Our experiments on a publicly available database of shooting incidents demonstrate that our system outperforms traditional extractors by 7.2% on average.1", "creator": "LaTeX with hyperref package"}}}