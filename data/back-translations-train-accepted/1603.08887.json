{"id": "1603.08887", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Mar-2016", "title": "Learning-Based Single-Document Summarization with Compression and Anaphoricity Constraints", "abstract": "We present a discriminative model for single-document summarization that integrally combines compression and anaphoricity constraints. Our model selects textual units to include in the summary based on a rich set of sparse features whose weights are learned on a large corpus. We allow for the deletion of content within a sentence when that deletion is licensed by compression rules; in our framework, these are implemented as dependencies between subsentential units of text. Anaphoricity constraints then improve cross-sentence coherence by guaranteeing that, for each pronoun included in the summary, the pronoun's antecedent is included as well or the pronoun is rewritten as a full mention. When trained end-to-end, our final system outperforms prior work on both ROUGE as well as on human judgments of linguistic quality.", "histories": [["v1", "Tue, 29 Mar 2016 18:58:42 GMT  (839kb,D)", "http://arxiv.org/abs/1603.08887v1", null], ["v2", "Wed, 8 Jun 2016 05:39:10 GMT  (859kb,D)", "http://arxiv.org/abs/1603.08887v2", "ACL 2016"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["greg durrett", "taylor berg-kirkpatrick", "dan klein"], "accepted": true, "id": "1603.08887"}, "pdf": {"name": "1603.08887.pdf", "metadata": {"source": "CRF", "title": "Learning-Based Single-Document Summarization with Compression and Anaphoricity Constraints", "authors": ["Greg Durrett", "Taylor Berg-Kirkpatrick", "Dan Klein"], "emails": ["gdurrett@cs.berkeley.edu", "tberg@cs.cmu.edu", "klein@cs.berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of us are able to outwit and outwit ourselves, both in terms of the way they move, in terms of the way they move, in terms of the way they move, in terms of the way they move, in terms of the way they move. In the way they move, it's not easy to identify, \"he said."}, {"heading": "2 Model", "text": "Our model is shown in Figure 1. Generally, our ILP takes a set of text units u = (u1,.., un) from a document and finds the highest score of extractive summaries by optimizing through variablesxUNIT = xUNIT1,.., x UNIT n, which are binary indicators of whether each unit is contained. Text units are contiguous parts of sentences that serve as basic units of extraction in our model. For a sentence-extractive model, these would be complete sentences, but for our compressing models we will have more fine-grained units, as shown in Figure 2 and described in Section 2.1. Text units are evaluated according to characteristics f and model parameters learned on training data. Finally, the extraction process is subject to a length restriction of k-words, which we cooperate in spirit with the formulations of several documents."}, {"heading": "2.1 Grammaticality Constraints", "text": "It is not as if it is a way in which we are able to compress the sentences so that we can put more information into a summary than we can include it in a summary. (2013) During the training, we will learn how to use the available compression options to summarize human-generated summaries as closely as possible. (2011).RST compressions we will explore two types of derivatives for compression: the RST-based compressions of Hirao et al. (2013) and the syntactic compressions of Berg-Kirkpatrick et al. (2011).RST compressions Figure 2a shows how to compress Rhetorical Structure Theory (Mann and Thompson, 1988; Carlson et al, 2001).We will show a set in elem-2a-2a-2a models as we show the compressions of Rhorical Structure Theory (Mann and Thompson, 2001, Compressions of Carlet Mann, 2001; and ST-R2a)."}, {"heading": "2.2 Anaphora Constraints", "text": "Many concepts of coherence are useful, including centering theory (Grosz et al., 1995) and lexical cohesion (Nishikawa et al., 2014), but one of the most pressing phenomena we need to address is pronoun anaphoras (Clarke et al., 2010). Cases of pronouns that are \"orphaned\" during extraction (their predecessors are deleted) are 3We also differ from previous work in that we do not apply transboundary RST restrictions (Hirao et al., 2013; Yoshida et al., 2014). We have experimented with these and found no improvement in their use, possibly because we have a feedback-based model rather than a heuristic selection process for content, and possibly because automatic discourse parsers are less good at restoring cross-sentence relations."}, {"heading": "2.2.1 Pronoun Replacement", "text": "One way to deal with these pronoun reference problems is to explicitly replace the pronoun with what it refers to. This replacement allows us to maintain maximum extraction flexibility, as we4We focus on the pronoun coreference, because it is the most pressing manifestation of this problem, and because existing coreference systems with pronouns perform well compared to harder instances of coreference (Durrett and Klein, 2013). We can make an isolated unit of text meaningful even if it contains a pronoun. Figure 3 shows how this process works. We run the Berkeley Entity Resolution System (Durrett and Klein, 2014) and calculate background points on possible associations for the pronoun. If the coreference system is sufficiently reliable in its prediction (i.e. maxi pi > \u03b1 for a certain threshold \u03b1 > 12), we allow ourselves to replace the pronoun with the first mention of the unit that most closely corresponds to the pronoun."}, {"heading": "2.2.2 Pronoun Antecedent Constraints", "text": "The explicit substitution of pronouns is risky: if the coreference system makes a false prediction, the intended meaning of the summary can be damaged. Fortunately, the posterior probabilities of the coreference model have proven to be well calibrated (Nguyen and O'Connor, 2015), which means that cases where it is likely to make mistakes are signaled by flatter posterior distributions. In this case, we enable a more conservative set of constraints that include additional content in the summary to make the pronoun clear without explicitly replacing it. We control for possessive pronouns by requiring the inclusion of any unit of text contained therein. 6If the proposed substitution is an appropriate mention, we simply replace the pronoun with the subset of mention that constitutes a named entity (and not the entire noun phrase), so that we control for possessive pronouns by adding \"s as an appropriate mention, or we may add an additional sum,\" before making a previous pronoun almost constitute a previous one."}, {"heading": "2.3 Features", "text": "The characteristics in our model (see Figure 1) consist of a series of surface indicators that capture mainly lexical and configurative information. Their primary role is to identify important document contents; the first three types of characteristics fire on text units, the last on pronoun substitutions.Lexical These include indicator characteristics on nonstopwords in the text unit that occur at least five times in the training set, and analog POS characteristics. Structural These characteristics also include various conjunctions of the position of the text unit in the document, its length, the length of the corresponding sentence, the index of the paragraph in which it occurs in the document (the index of the sentence that contains the text unit).Structural These characteristics include various conjunctions of the position of the text unit in the document, the length of the corresponding sentence, the length of the corresponding sentence, the index of the paragraph in which it occurs, and whether it begins a new paragraph (all values are the new paragraph).These characteristics include various conjunctions of the position of the text unit in the document, the length of the corresponding sentence, the length of the corresponding sentence, the index of the paragraph in which it occurs, and whether it contains a new paragraph number (all values are the values are bucketed)."}, {"heading": "3 Learning", "text": "We formulate our learning problem as a standard example of structured SVM, where our loss function is the ROUGE score of the predicted summary in relation to the reference (human) summary. We refer the reader to Smith (2011) for an introduction to structured SVM. We train the model using stochastic subgradient descent at the primary level (Ratliff et al., 2007; Kummerfeld et al., 2015). To calculate the subgradient for a particular training example, we need to locate the most violated constraint on the given instance by a cost-optimized decoding, which generally takes the form argmaxxw > f (x) + '(x, y). To calculate the subgradient for a particular training example, we need \"(xNGRAM, y) = max x, x, x, x."}, {"heading": "4 Experiments", "text": "We primarily evaluate our model using a review set of 3000 documents from the New York Times Annotated Corpus (Sandhaus, 2008) and also examine its performance on the RST Discourse Treebank (Carlson et al., 2001), but since this dataset is only 30 documents, it provides much less robust estimates of performance. [7] In this section, we have set the word budget for our summary text at the same length as the reference summaries after previous work (Hirao et al., 2013; Yoshida et al., 2014)."}, {"heading": "4.1 Preprocessing", "text": "We process all data using the Berkeley parser (Petrov et al., 2006), in particular the GPU-accelerated version of the parser by Hall et al. (2014), and the Berkeley Entity Resolution System (Durrett et al., 2014). For RST discourse analysis, we segment text into EDUs using a semiMarkov CRF trained on the RST tree bank, with features similar to those of Hernault et al. (2010), plus novel features across spans, including span and span identity for short spans. To follow the conditions of Yoshida et al. (2014) as closely as possible, we also build a discourse sparser in the style of Hirao et al. (2013), as their parser is not publicly available. In particular, we use the first-order projective analysis model by McDonald et al. (2005) and features of Soricut and Marcu hdency al. (2010), as their parser is not available."}, {"heading": "4.2 New York Times Corpus", "text": "This data set contains 110,540 articles with abstract summaries; we split them into 100,834 training examples and 9706 test examples based on the publication date (test are all articles published on January 1, 2007 or later). Examples of two documents from this data set are shown in Figure 4. The bottom example shows that some summaries are extremely short and formulaic (especially those for obituaries and editorials). To counteract this, we filter the raw data set by removing all documents with summaries shorter than 50 words. An advantage of filtering is that the length distribution of our resulting data set is more consistent with standard summaries such as DUC; it also ensures a sufficient number of tokens in the budget to produce non-trivial summaries. This filtered test set, which we call NYT50, includes 3,452 test examples from the original 9,706."}, {"heading": "4.3 New York Times Results", "text": "This year, it has reached the point where it is only half as much as it is half."}, {"heading": "4.4 RST Treebank", "text": "Following Hirao et al. (2013), we use Gold-EDU segmentation from the RST corpus, but automatic RST trees. We divide this into a 10-document development set and a 20-document test set. Table 2 shows the results from the RST corpus. Our system here is roughly comparable to the Tree Knapsack, and we note that none of the differences in the table is statistically significant. In addition, we observed significant variations between several runs of this corpus, with values changing by 1-2 ROUGE points for slightly different system variations.9"}, {"heading": "5 Conclusion", "text": "We introduced a system for summarizing individual documents, trained end-to-end on a large corpus. We integrate a compression model that enforces grammaticality and pronoun anaphorism constraints that enforce coherence. Our system improves considerably compared to base systems on ROUGE while maintaining good linguistic quality.9The system from Yoshida et al. (2014) is not available, so we use rhymplementation. Our results differ from theirs due to different discourse trees and high variance in the test theorem."}], "references": [{"title": "Fast and Robust Compressive Summarization with Dual Decomposition and Multi-Task Learning", "author": ["Miguel Almeida", "Andre Martins."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Almeida and Martins.,? 2013", "shortCiteRegEx": "Almeida and Martins.", "year": 2013}, {"title": "Modeling Local Coherence: An Entity-based Approach", "author": ["Regina Barzilay", "Mirella Lapata."], "venue": "Computational Linguistics, 34(1):1\u201334, March.", "citeRegEx": "Barzilay and Lapata.,? 2008", "shortCiteRegEx": "Barzilay and Lapata.", "year": 2008}, {"title": "Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization", "author": ["Regina Barzilay", "Lillian Lee."], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Barzilay and Lee.,? 2004", "shortCiteRegEx": "Barzilay and Lee.", "year": 2004}, {"title": "Sentence Ordering in Multidocument Summarization", "author": ["Regina Barzilay", "Noemie Elhadad", "Kathleen R. McKeown."], "venue": "Proceedings of the International Conference on Human Language Technology Research.", "citeRegEx": "Barzilay et al\\.,? 2001", "shortCiteRegEx": "Barzilay et al\\.", "year": 2001}, {"title": "Jointly Learning to Extract and Compress", "author": ["Taylor Berg-Kirkpatrick", "Dan Gillick", "Dan Klein."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Berg.Kirkpatrick et al\\.,? 2011", "shortCiteRegEx": "Berg.Kirkpatrick et al\\.", "year": 2011}, {"title": "The Use of MMR, Diversity-based Reranking for Reordering Documents and Producing Summaries", "author": ["Jaime Carbonell", "Jade Goldstein."], "venue": "Proceedings of the International ACM SIGIR Conference on Research and Development in Information", "citeRegEx": "Carbonell and Goldstein.,? 1998", "shortCiteRegEx": "Carbonell and Goldstein.", "year": 1998}, {"title": "Building a Discourse-tagged Corpus in the Framework of Rhetorical Structure Theory", "author": ["Lynn Carlson", "Daniel Marcu", "Mary Ellen Okurowski."], "venue": "Proceedings of the Second SIGDIAL Workshop on Discourse and Dialogue.", "citeRegEx": "Carlson et al\\.,? 2001", "shortCiteRegEx": "Carlson et al\\.", "year": 2001}, {"title": "Towards Coherent MultiDocument Summarization", "author": ["Janara Christensen", "Mausam", "Stephen Soderland", "Oren Etzioni."], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Christensen et al\\.,? 2013", "shortCiteRegEx": "Christensen et al\\.", "year": 2013}, {"title": "Global Inference for Sentence Compression an Integer Linear Programming Approach", "author": ["James Clarke", "Mirella Lapata."], "venue": "Journal of Artificial Intelligence Research, 31(1):399\u2013429, March.", "citeRegEx": "Clarke and Lapata.,? 2008", "shortCiteRegEx": "Clarke and Lapata.", "year": 2008}, {"title": "Discourse Constraints for Document Compression", "author": ["James Clarke", "Mirella Lapata."], "venue": "Computational Linguistics, 36(3):411\u2013441, September.", "citeRegEx": "Clarke and Lapata.,? 2010", "shortCiteRegEx": "Clarke and Lapata.", "year": 2010}, {"title": "A NoisyChannel Model for Document Compression", "author": ["III Hal Daum\u00e9", "Daniel Marcu."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Daum\u00e9 and Marcu.,? 2002", "shortCiteRegEx": "Daum\u00e9 and Marcu.", "year": 2002}, {"title": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization", "author": ["John Duchi", "Elad Hazan", "Yoram Singer."], "venue": "Journal of Machine Learning Research, 12:2121\u20132159, July.", "citeRegEx": "Duchi et al\\.,? 2011", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "A New Entity Salience Task with Millions of Training Examples", "author": ["Jesse Dunietz", "Daniel Gillick."], "venue": "Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).", "citeRegEx": "Dunietz and Gillick.,? 2014", "shortCiteRegEx": "Dunietz and Gillick.", "year": 2014}, {"title": "Easy Victories and Uphill Battles in Coreference Resolution", "author": ["Greg Durrett", "Dan Klein."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), October.", "citeRegEx": "Durrett and Klein.,? 2013", "shortCiteRegEx": "Durrett and Klein.", "year": 2013}, {"title": "A Joint Model for Entity Analysis: Coreference, Typing, and Linking", "author": ["Greg Durrett", "Dan Klein."], "venue": "Transactions of the Association for Computational Linguistics (TACL).", "citeRegEx": "Durrett and Klein.,? 2014", "shortCiteRegEx": "Durrett and Klein.", "year": 2014}, {"title": "A Scalable Global Model for Summarization", "author": ["Dan Gillick", "Benoit Favre."], "venue": "Proceedings of the Workshop on Integer Linear Programming for Natural Language Processing.", "citeRegEx": "Gillick and Favre.,? 2009", "shortCiteRegEx": "Gillick and Favre.", "year": 2009}, {"title": "Non-Expert Evaluation of Summarization Systems is Risky", "author": ["Dan Gillick", "Yang Liu."], "venue": "Proceedings of the NAACL Workshop on Creating Speech and Language Data with Amazon\u2019s Mechanical Turk.", "citeRegEx": "Gillick and Liu.,? 2010", "shortCiteRegEx": "Gillick and Liu.", "year": 2010}, {"title": "Logic and Conversation", "author": ["H.P. Grice."], "venue": "Syntax and Semantics 3: Speech Acts, pages 41\u201358.", "citeRegEx": "Grice.,? 1975", "shortCiteRegEx": "Grice.", "year": 1975}, {"title": "Centering: A Framework for Modeling the Local Coherence of Discourse", "author": ["Barbara J. Grosz", "Scott Weinstein", "Aravind K. Joshi."], "venue": "Computational Linguistics, 21(2):203\u2013225, June.", "citeRegEx": "Grosz et al\\.,? 1995", "shortCiteRegEx": "Grosz et al\\.", "year": 1995}, {"title": "Sparser, Better, Faster GPU Parsing", "author": ["David Hall", "Taylor Berg-Kirkpatrick", "John Canny", "Dan Klein."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Hall et al\\.,? 2014", "shortCiteRegEx": "Hall et al\\.", "year": 2014}, {"title": "HILDA: A discourse parser using support vector machine classification", "author": ["Hugo Hernault", "Helmut Prendinger", "David A. Duverle", "Mitsuru Ishizuka", "Tim Paek."], "venue": "Dialogue and Discourse, 1:1\u201333.", "citeRegEx": "Hernault et al\\.,? 2010", "shortCiteRegEx": "Hernault et al\\.", "year": 2010}, {"title": "Single-Document Summarization as a Tree Knapsack Problem", "author": ["Tsutomu Hirao", "Yasuhisa Yoshida", "Masaaki Nishino", "Norihito Yasuda", "Masaaki Nagata."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Hirao et al\\.,? 2013", "shortCiteRegEx": "Hirao et al\\.", "year": 2013}, {"title": "Improving the Estimation of Word Importance for News MultiDocument Summarization", "author": ["Kai Hong", "Ani Nenkova."], "venue": "Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).", "citeRegEx": "Hong and Nenkova.,? 2014", "shortCiteRegEx": "Hong and Nenkova.", "year": 2014}, {"title": "Combining Intra- and Multi-sentential Rhetorical Parsing for Documentlevel Discourse Analysis", "author": ["Shafiq Joty", "Giuseppe Carenini", "Raymond Ng", "Yashar Mehdad."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Joty et al\\.,? 2013", "shortCiteRegEx": "Joty et al\\.", "year": 2013}, {"title": "An Empirical Analysis of Optimization for Max-Margin NLP", "author": ["Jonathan K. Kummerfeld", "Taylor Berg-Kirkpatrick", "Dan Klein."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Kummerfeld et al\\.,? 2015", "shortCiteRegEx": "Kummerfeld et al\\.", "year": 2015}, {"title": "Using External Resources and Joint Learning for Bigram Weighting in ILP-Based Multi-Document Summarization", "author": ["Chen Li", "Yang Liu", "Lin Zhao."], "venue": "Proceedings of the North American Chapter of the Association for Computational Lin-", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "A Class of Submodular Functions for Document Summarization", "author": ["Hui Lin", "Jeff Bilmes."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Lin and Bilmes.,? 2011", "shortCiteRegEx": "Lin and Bilmes.", "year": 2011}, {"title": "Automatic Evaluation of Summaries Using N-gram CoOccurrence Statistics", "author": ["Chin-Yew Lin", "Eduard Hovy."], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Lin and Hovy.,? 2003", "shortCiteRegEx": "Lin and Hovy.", "year": 2003}, {"title": "Improving Summarization Performance by Sentence Compression: A Pilot Study", "author": ["Chin-Yew Lin."], "venue": "Proceedings of the International Workshop on Information Retrieval with Asian Languages.", "citeRegEx": "Lin.,? 2003", "shortCiteRegEx": "Lin.", "year": 2003}, {"title": "A Coherence Model Based on Syntactic Patterns", "author": ["Annie Louis", "Ani Nenkova."], "venue": "Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).", "citeRegEx": "Louis and Nenkova.,? 2012", "shortCiteRegEx": "Louis and Nenkova.", "year": 2012}, {"title": "Discourse Indicators for Content Selection in Summarization", "author": ["Annie Louis", "Aravind Joshi", "Ani Nenkova."], "venue": "Proceedings of the SIGDIAL 2010 Conference.", "citeRegEx": "Louis et al\\.,? 2010", "shortCiteRegEx": "Louis et al\\.", "year": 2010}, {"title": "AutomaticSummarization", "author": ["Inderjeet Mani."], "venue": "John Benjamins Publishing.", "citeRegEx": "Mani.,? 2001", "shortCiteRegEx": "Mani.", "year": 2001}, {"title": "Rhetorical Structure Theory: Toward a Functional Theory of Text Organization", "author": ["William C. Mann", "Sandra A. Thompson."], "venue": "Text, 8(3):243\u2013281.", "citeRegEx": "Mann and Thompson.,? 1988", "shortCiteRegEx": "Mann and Thompson.", "year": 1988}, {"title": "Improving summarization through rhetorical parsing tuning", "author": ["Daniel Marcu."], "venue": "Proceedings of the Workshop on Very Large Corpora.", "citeRegEx": "Marcu.,? 1998", "shortCiteRegEx": "Marcu.", "year": 1998}, {"title": "Summarization with a Joint Model for Sentence Extraction and Compression", "author": ["Andre Martins", "Noah A. Smith."], "venue": "Proceedings of the Workshop on Integer Linear Programming for Natural Language Processing.", "citeRegEx": "Martins and Smith.,? 2009", "shortCiteRegEx": "Martins and Smith.", "year": 2009}, {"title": "Online Large-margin Training of Dependency Parsers", "author": ["Ryan McDonald", "Koby Crammer", "Fernando Pereira."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "McDonald et al\\.,? 2005", "shortCiteRegEx": "McDonald et al\\.", "year": 2005}, {"title": "Discriminative Sentence Compression With Soft Syntactic Evidence", "author": ["Ryan McDonald."], "venue": "Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).", "citeRegEx": "McDonald.,? 2006", "shortCiteRegEx": "McDonald.", "year": 2006}, {"title": "Generating Concise Natural Language Summaries", "author": ["Kathleen McKeown", "Jacques Robin", "Karen Kukich."], "venue": "Information Processing and Management, 31(5):703\u2013733, September.", "citeRegEx": "McKeown et al\\.,? 1995", "shortCiteRegEx": "McKeown et al\\.", "year": 1995}, {"title": "Discourse Structures to Reduce Discourse Incoherence in Blog Summarization", "author": ["Shamima Mithun", "Leila Kosseim."], "venue": "Proceedings of Recent Advances in Natural Language Processing.", "citeRegEx": "Mithun and Kosseim.,? 2011", "shortCiteRegEx": "Mithun and Kosseim.", "year": 2011}, {"title": "Automatic summarization", "author": ["Ani Nenkova", "Kathleen McKeown."], "venue": "Foundations and Trends in Information Retrieval, 5(2?3):103\u2013233.", "citeRegEx": "Nenkova and McKeown.,? 2011", "shortCiteRegEx": "Nenkova and McKeown.", "year": 2011}, {"title": "Posterior Calibration and Exploratory Analysis for Natural Language Processing Models", "author": ["Khanh Nguyen", "Brendan O\u2019Connor"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Nguyen and O.Connor.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen and O.Connor.", "year": 2015}, {"title": "Learning to Generate Coherent Summary with Discriminative Hidden Semi-Markov Model", "author": ["Hitoshi Nishikawa", "Kazuho Arita", "Katsumi Tanaka", "Tsutomu Hirao", "Toshiro Makino", "Yoshihiro Matsuo."], "venue": "Proceedings of the International Confer-", "citeRegEx": "Nishikawa et al\\.,? 2014", "shortCiteRegEx": "Nishikawa et al\\.", "year": 2014}, {"title": "A Critical Reassessment of Evaluation Baselines for Speech Summarization", "author": ["Gerald Penn", "Xiaodan Zhu."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Penn and Zhu.,? 2008", "shortCiteRegEx": "Penn and Zhu.", "year": 2008}, {"title": "Learning Accurate, Compact, and Interpretable Tree Annotation", "author": ["Slav Petrov", "Leon Barrett", "Romain Thibaux", "Dan Klein."], "venue": "Proceedings of the Conference on Computational Linguistics and the Association for Computational Linguistics (ACL-", "citeRegEx": "Petrov et al\\.,? 2006", "shortCiteRegEx": "Petrov et al\\.", "year": 2006}, {"title": "Modelling Events through Memory-based, Open-IE Patterns for Abstractive Summarization", "author": ["Daniele Pighin", "Marco Cornolti", "Enrique Alfonseca", "Katja Filippova."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Pighin et al\\.,? 2014", "shortCiteRegEx": "Pighin et al\\.", "year": 2014}, {"title": "Online) Subgradient Methods for Structured Prediction", "author": ["Nathan J. Ratliff", "Andrew Bagnell", "Martin Zinkevich."], "venue": "Proceedings of the International Conference on Artificial Intelligence and Statistics.", "citeRegEx": "Ratliff et al\\.,? 2007", "shortCiteRegEx": "Ratliff et al\\.", "year": 2007}, {"title": "The New York Times Annotated Corpus", "author": ["Evan Sandhaus."], "venue": "Linguistic Data Consortium.", "citeRegEx": "Sandhaus.,? 2008", "shortCiteRegEx": "Sandhaus.", "year": 2008}, {"title": "Linguistic Structure Prediction", "author": ["Noah A. Smith."], "venue": "Morgan & Claypool Publishers, 1st edition.", "citeRegEx": "Smith.,? 2011", "shortCiteRegEx": "Smith.", "year": 2011}, {"title": "Sentence Level Discourse Parsing Using Syntactic and Lexical Information", "author": ["Radu Soricut", "Daniel Marcu."], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Soricut and Marcu.,? 2003", "shortCiteRegEx": "Soricut and Marcu.", "year": 2003}, {"title": "Supervised Sentence Fusion with Single-Stage Inference", "author": ["Kapil Thadani", "Kathleen McKeown."], "venue": "Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP).", "citeRegEx": "Thadani and McKeown.,? 2013", "shortCiteRegEx": "Thadani and McKeown.", "year": 2013}, {"title": "Multiple Aspect Summarization Using Integer Linear Programming", "author": ["Kristian Woodsend", "Mirella Lapata."], "venue": "Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language", "citeRegEx": "Woodsend and Lapata.,? 2012", "shortCiteRegEx": "Woodsend and Lapata.", "year": 2012}, {"title": "Dependency-based Discourse Parser for Single-Document Summarization", "author": ["Yasuhisa Yoshida", "Jun Suzuki", "Tsutomu Hirao", "Masaaki Nagata."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Yoshida et al\\.,? 2014", "shortCiteRegEx": "Yoshida et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 5, "context": "While multi-document summarization is wellstudied in the NLP literature (Carbonell and Goldstein, 1998; Gillick and Favre, 2009; Lin and Bilmes, 2011; Nenkova and McKeown, 2011), single-document summarization (McKeown et al.", "startOffset": 72, "endOffset": 177}, {"referenceID": 15, "context": "While multi-document summarization is wellstudied in the NLP literature (Carbonell and Goldstein, 1998; Gillick and Favre, 2009; Lin and Bilmes, 2011; Nenkova and McKeown, 2011), single-document summarization (McKeown et al.", "startOffset": 72, "endOffset": 177}, {"referenceID": 26, "context": "While multi-document summarization is wellstudied in the NLP literature (Carbonell and Goldstein, 1998; Gillick and Favre, 2009; Lin and Bilmes, 2011; Nenkova and McKeown, 2011), single-document summarization (McKeown et al.", "startOffset": 72, "endOffset": 177}, {"referenceID": 39, "context": "While multi-document summarization is wellstudied in the NLP literature (Carbonell and Goldstein, 1998; Gillick and Favre, 2009; Lin and Bilmes, 2011; Nenkova and McKeown, 2011), single-document summarization (McKeown et al.", "startOffset": 72, "endOffset": 177}, {"referenceID": 37, "context": "While multi-document summarization is wellstudied in the NLP literature (Carbonell and Goldstein, 1998; Gillick and Favre, 2009; Lin and Bilmes, 2011; Nenkova and McKeown, 2011), single-document summarization (McKeown et al., 1995; Marcu, 1998; Mani, 2001; Hirao et al., 2013) has received less attention in recent years and is generally viewed as more difficult.", "startOffset": 209, "endOffset": 276}, {"referenceID": 33, "context": "While multi-document summarization is wellstudied in the NLP literature (Carbonell and Goldstein, 1998; Gillick and Favre, 2009; Lin and Bilmes, 2011; Nenkova and McKeown, 2011), single-document summarization (McKeown et al., 1995; Marcu, 1998; Mani, 2001; Hirao et al., 2013) has received less attention in recent years and is generally viewed as more difficult.", "startOffset": 209, "endOffset": 276}, {"referenceID": 31, "context": "While multi-document summarization is wellstudied in the NLP literature (Carbonell and Goldstein, 1998; Gillick and Favre, 2009; Lin and Bilmes, 2011; Nenkova and McKeown, 2011), single-document summarization (McKeown et al., 1995; Marcu, 1998; Mani, 2001; Hirao et al., 2013) has received less attention in recent years and is generally viewed as more difficult.", "startOffset": 209, "endOffset": 276}, {"referenceID": 21, "context": "While multi-document summarization is wellstudied in the NLP literature (Carbonell and Goldstein, 1998; Gillick and Favre, 2009; Lin and Bilmes, 2011; Nenkova and McKeown, 2011), single-document summarization (McKeown et al., 1995; Marcu, 1998; Mani, 2001; Hirao et al., 2013) has received less attention in recent years and is generally viewed as more difficult.", "startOffset": 209, "endOffset": 276}, {"referenceID": 42, "context": "Content selection is tricky without redundancy across multiple input documents as a guide and simple positional information is often hard to beat (Penn and Zhu, 2008).", "startOffset": 146, "endOffset": 166}, {"referenceID": 46, "context": "edu urally occurring corpus\u2014the New York Times Annotated Corpus (Sandhaus, 2008) which contains around 100,000 news articles with abstractive summaries\u2014learning to select important content with lexical features.", "startOffset": 64, "endOffset": 80}, {"referenceID": 12, "context": "explored in related contexts (Dunietz and Gillick, 2014; Hong and Nenkova, 2014), but to our knowledge it has not been directly used for singledocument summarization.", "startOffset": 29, "endOffset": 80}, {"referenceID": 22, "context": "explored in related contexts (Dunietz and Gillick, 2014; Hong and Nenkova, 2014), but to our knowledge it has not been directly used for singledocument summarization.", "startOffset": 29, "endOffset": 80}, {"referenceID": 46, "context": "We focus our evaluation on the New York Times Annotated corpus (Sandhaus, 2008).", "startOffset": 63, "endOffset": 79}, {"referenceID": 15, "context": "According to ROUGE, our system outperforms a document prefix baseline, a bigram coverage baseline adapted from a strong multi-document system (Gillick and Favre, 2009), and a discourse-informed method from prior work (Yoshida et al.", "startOffset": 142, "endOffset": 167}, {"referenceID": 51, "context": "According to ROUGE, our system outperforms a document prefix baseline, a bigram coverage baseline adapted from a strong multi-document system (Gillick and Favre, 2009), and a discourse-informed method from prior work (Yoshida et al., 2014).", "startOffset": 217, "endOffset": 239}, {"referenceID": 30, "context": "Some work has focused on improving content selection using discourse structure (Louis et al., 2010; Hirao et al., 2013), topical structure (Barzilay and Lee, 2004), or related techniques (Mithun and Kosseim, 2011).", "startOffset": 79, "endOffset": 119}, {"referenceID": 21, "context": "Some work has focused on improving content selection using discourse structure (Louis et al., 2010; Hirao et al., 2013), topical structure (Barzilay and Lee, 2004), or related techniques (Mithun and Kosseim, 2011).", "startOffset": 79, "endOffset": 119}, {"referenceID": 2, "context": ", 2013), topical structure (Barzilay and Lee, 2004), or related techniques (Mithun and Kosseim, 2011).", "startOffset": 27, "endOffset": 51}, {"referenceID": 38, "context": ", 2013), topical structure (Barzilay and Lee, 2004), or related techniques (Mithun and Kosseim, 2011).", "startOffset": 75, "endOffset": 101}, {"referenceID": 3, "context": "Other work has used structure primarily to reorder summaries and ensure coherence (Barzilay et al., 2001; Barzilay and Lapata, 2008; Louis and Nenkova, 2012; Christensen et al., 2013) or to represent content for sentence fusion or abstraction (Thadani and McKeown, 2013; Pighin et al.", "startOffset": 82, "endOffset": 183}, {"referenceID": 1, "context": "Other work has used structure primarily to reorder summaries and ensure coherence (Barzilay et al., 2001; Barzilay and Lapata, 2008; Louis and Nenkova, 2012; Christensen et al., 2013) or to represent content for sentence fusion or abstraction (Thadani and McKeown, 2013; Pighin et al.", "startOffset": 82, "endOffset": 183}, {"referenceID": 29, "context": "Other work has used structure primarily to reorder summaries and ensure coherence (Barzilay et al., 2001; Barzilay and Lapata, 2008; Louis and Nenkova, 2012; Christensen et al., 2013) or to represent content for sentence fusion or abstraction (Thadani and McKeown, 2013; Pighin et al.", "startOffset": 82, "endOffset": 183}, {"referenceID": 7, "context": "Other work has used structure primarily to reorder summaries and ensure coherence (Barzilay et al., 2001; Barzilay and Lapata, 2008; Louis and Nenkova, 2012; Christensen et al., 2013) or to represent content for sentence fusion or abstraction (Thadani and McKeown, 2013; Pighin et al.", "startOffset": 82, "endOffset": 183}, {"referenceID": 49, "context": ", 2013) or to represent content for sentence fusion or abstraction (Thadani and McKeown, 2013; Pighin et al., 2014).", "startOffset": 67, "endOffset": 115}, {"referenceID": 44, "context": ", 2013) or to represent content for sentence fusion or abstraction (Thadani and McKeown, 2013; Pighin et al., 2014).", "startOffset": 67, "endOffset": 115}, {"referenceID": 15, "context": "This approach is similar in spirit to ILP formulations of multi-document summarization systems, though in those systems content is typically modeled in terms of bigrams (Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Hong and Nenkova, 2014; Li et al., 2015).", "startOffset": 169, "endOffset": 266}, {"referenceID": 4, "context": "This approach is similar in spirit to ILP formulations of multi-document summarization systems, though in those systems content is typically modeled in terms of bigrams (Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Hong and Nenkova, 2014; Li et al., 2015).", "startOffset": 169, "endOffset": 266}, {"referenceID": 22, "context": "This approach is similar in spirit to ILP formulations of multi-document summarization systems, though in those systems content is typically modeled in terms of bigrams (Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Hong and Nenkova, 2014; Li et al., 2015).", "startOffset": 169, "endOffset": 266}, {"referenceID": 25, "context": "This approach is similar in spirit to ILP formulations of multi-document summarization systems, though in those systems content is typically modeled in terms of bigrams (Gillick and Favre, 2009; Berg-Kirkpatrick et al., 2011; Hong and Nenkova, 2014; Li et al., 2015).", "startOffset": 169, "endOffset": 266}, {"referenceID": 20, "context": "(a) RST-based compression structure like that in Hirao et al. (2013), where we can delete the ELABORATION clause.", "startOffset": 49, "endOffset": 69}, {"referenceID": 4, "context": "(b) Two syntactic compression options from Berg-Kirkpatrick et al. (2011), namely deletion of a coordinate and deletion of a PP modifier.", "startOffset": 43, "endOffset": 74}, {"referenceID": 36, "context": "Following work on isolated sentence compression (McDonald, 2006; Clarke and Lapata, 2008) and", "startOffset": 48, "endOffset": 89}, {"referenceID": 8, "context": "Following work on isolated sentence compression (McDonald, 2006; Clarke and Lapata, 2008) and", "startOffset": 48, "endOffset": 89}, {"referenceID": 28, "context": "compressive summarization (Lin, 2003; Martins and Smith, 2009; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012; Almeida and Martins, 2013), we wish to be able to compress sentences so we can pack more information into a summary.", "startOffset": 26, "endOffset": 147}, {"referenceID": 34, "context": "compressive summarization (Lin, 2003; Martins and Smith, 2009; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012; Almeida and Martins, 2013), we wish to be able to compress sentences so we can pack more information into a summary.", "startOffset": 26, "endOffset": 147}, {"referenceID": 4, "context": "compressive summarization (Lin, 2003; Martins and Smith, 2009; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012; Almeida and Martins, 2013), we wish to be able to compress sentences so we can pack more information into a summary.", "startOffset": 26, "endOffset": 147}, {"referenceID": 50, "context": "compressive summarization (Lin, 2003; Martins and Smith, 2009; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012; Almeida and Martins, 2013), we wish to be able to compress sentences so we can pack more information into a summary.", "startOffset": 26, "endOffset": 147}, {"referenceID": 0, "context": "compressive summarization (Lin, 2003; Martins and Smith, 2009; Berg-Kirkpatrick et al., 2011; Woodsend and Lapata, 2012; Almeida and Martins, 2013), we wish to be able to compress sentences so we can pack more information into a summary.", "startOffset": 26, "endOffset": 147}, {"referenceID": 20, "context": "compressions of Hirao et al. (2013) and the syntactic compressions of Berg-Kirkpatrick et al.", "startOffset": 16, "endOffset": 36}, {"referenceID": 4, "context": "(2013) and the syntactic compressions of Berg-Kirkpatrick et al. (2011).", "startOffset": 41, "endOffset": 72}, {"referenceID": 32, "context": "RST compressions Figure 2a shows how to derive compressions from Rhetorical Structure Theory (Mann and Thompson, 1988; Carlson et al., 2001).", "startOffset": 93, "endOffset": 140}, {"referenceID": 6, "context": "RST compressions Figure 2a shows how to derive compressions from Rhetorical Structure Theory (Mann and Thompson, 1988; Carlson et al., 2001).", "startOffset": 93, "endOffset": 140}, {"referenceID": 0, "context": "The features in our model are actually rich enough to learn a sophisticated compression model, but the data we have (abstractive summaries) does not directly provide examples of correct compressions; past work has gotten around this with multi-task learning (Almeida and Martins, 2013), but we simply treat grammaticality as a constraint from upstream models.", "startOffset": 258, "endOffset": 285}, {"referenceID": 21, "context": "This is a more constrained form of compression than was used in past work (Hirao et al., 2013), but we find that it improves human judgments of fluency (Section 4.", "startOffset": 74, "endOffset": 94}, {"referenceID": 4, "context": "Syntactic compressions Figure 2b shows two examples of compressions arising from syntactic patterns (Berg-Kirkpatrick et al., 2011): deletion of the second part of a coordinated NP and deletion of a PP modifier to an NP.", "startOffset": 100, "endOffset": 131}, {"referenceID": 18, "context": "What kind of cross-sentential coherence do we need to ensure for the kinds of summaries our system produces? Many notions of coherence are useful, including centering theory (Grosz et al., 1995) and lexical cohesion (Nishikawa et al.", "startOffset": 174, "endOffset": 194}, {"referenceID": 41, "context": ", 1995) and lexical cohesion (Nishikawa et al., 2014), but one of the most pressing phenomena to deal with is pronoun anaphora (Clarke and Lapata, 2010).", "startOffset": 29, "endOffset": 53}, {"referenceID": 9, "context": ", 2014), but one of the most pressing phenomena to deal with is pronoun anaphora (Clarke and Lapata, 2010).", "startOffset": 81, "endOffset": 106}, {"referenceID": 21, "context": "We also differ from past work in that we do not use crosssentential RST constraints (Hirao et al., 2013; Yoshida et al., 2014).", "startOffset": 84, "endOffset": 126}, {"referenceID": 51, "context": "We also differ from past work in that we do not use crosssentential RST constraints (Hirao et al., 2013; Yoshida et al., 2014).", "startOffset": 84, "endOffset": 126}, {"referenceID": 14, "context": "It, which refers to Kellogg, has several possible antecedents from the standpoint of an automatic coreference system (Durrett and Klein, 2014).", "startOffset": 117, "endOffset": 142}, {"referenceID": 17, "context": "This kind of error is particularly concerning for summary interpretation and impedes the ability of summaries to convey information effectively (Grice, 1975).", "startOffset": 144, "endOffset": 157}, {"referenceID": 13, "context": "We focus on pronoun coreference because it is the most pressing manifestation of this problem and because existing coreference systems perform well on pronouns compared to harder instances of coreference (Durrett and Klein, 2013).", "startOffset": 204, "endOffset": 229}, {"referenceID": 14, "context": "We run the Berkeley Entity Resolution System (Durrett and Klein, 2014) and compute posteriors over possible links for the pronoun.", "startOffset": 45, "endOffset": 70}, {"referenceID": 40, "context": "Fortunately, the coreference model\u2019s posterior probabilities have been shown to be wellcalibrated (Nguyen and O\u2019Connor, 2015), meaning that cases where it is likely to make errors are signaled by flatter posterior distributions.", "startOffset": 98, "endOffset": 125}, {"referenceID": 45, "context": "We train the model via stochastic subgradient descent on the primal (Ratliff et al., 2007; Kummerfeld et al., 2015).", "startOffset": 68, "endOffset": 115}, {"referenceID": 24, "context": "We train the model via stochastic subgradient descent on the primal (Ratliff et al., 2007; Kummerfeld et al., 2015).", "startOffset": 68, "endOffset": 115}, {"referenceID": 45, "context": "We refer the reader to Smith (2011) for an introduction to structured SVM.", "startOffset": 23, "endOffset": 36}, {"referenceID": 11, "context": "For all experiments, we optimize our objective using AdaGrad (Duchi et al., 2011) with `1 regularization (\u03bb = 10\u22128, chosen by grid search), with a step size of 0.", "startOffset": 61, "endOffset": 81}, {"referenceID": 46, "context": "We primarily evaluate our model on a 3000document evaluation set from the New York Times Annotated Corpus (Sandhaus, 2008).", "startOffset": 106, "endOffset": 122}, {"referenceID": 6, "context": "vestigate its performance on the RST Discourse Treebank (Carlson et al., 2001), but because this dataset is only 30 documents it provides much less robust estimates of performance.", "startOffset": 56, "endOffset": 78}, {"referenceID": 21, "context": "summarizer to be the same length as the reference summaries, following previous work (Hirao et al., 2013; Yoshida et al., 2014).", "startOffset": 85, "endOffset": 127}, {"referenceID": 51, "context": "summarizer to be the same length as the reference summaries, following previous work (Hirao et al., 2013; Yoshida et al., 2014).", "startOffset": 85, "endOffset": 127}, {"referenceID": 43, "context": "We preprocess all data using the Berkeley Parser (Petrov et al., 2006), specifically the GPUaccelerated version of the parser from Hall et al.", "startOffset": 49, "endOffset": 70}, {"referenceID": 19, "context": ", 2006), specifically the GPUaccelerated version of the parser from Hall et al. (2014), and the Berkeley Entity Resolution Sys-", "startOffset": 68, "endOffset": 87}, {"referenceID": 14, "context": "tem (Durrett and Klein, 2014).", "startOffset": 4, "endOffset": 29}, {"referenceID": 13, "context": "tem (Durrett and Klein, 2014). For RST discourse analysis, we segment text into EDUs using a semiMarkov CRF trained on the RST treebank with features on boundaries similar to those of Hernault et al. (2010), plus novel features on spans including span length and span identity for short spans.", "startOffset": 5, "endOffset": 207}, {"referenceID": 44, "context": "To follow the conditions of Yoshida et al. (2014) as closely as possible, we also build a discourse parser in the style described in Hirao et al.", "startOffset": 28, "endOffset": 50}, {"referenceID": 20, "context": "(2014) as closely as possible, we also build a discourse parser in the style described in Hirao et al. (2013), since their parser is not publicly available.", "startOffset": 90, "endOffset": 110}, {"referenceID": 20, "context": "(2014) as closely as possible, we also build a discourse parser in the style described in Hirao et al. (2013), since their parser is not publicly available. Specifically, we use the first-order projective parsing model of McDonald et al. (2005) and features from Soricut and Marcu (2003), Hernault et al.", "startOffset": 90, "endOffset": 245}, {"referenceID": 20, "context": "(2014) as closely as possible, we also build a discourse parser in the style described in Hirao et al. (2013), since their parser is not publicly available. Specifically, we use the first-order projective parsing model of McDonald et al. (2005) and features from Soricut and Marcu (2003), Hernault et al.", "startOffset": 90, "endOffset": 288}, {"referenceID": 20, "context": "(2005) and features from Soricut and Marcu (2003), Hernault et al. (2010), and Joty et al.", "startOffset": 51, "endOffset": 74}, {"referenceID": 20, "context": "(2005) and features from Soricut and Marcu (2003), Hernault et al. (2010), and Joty et al. (2013). When using the same head annotation scheme as Yoshida et al.", "startOffset": 51, "endOffset": 98}, {"referenceID": 20, "context": "(2005) and features from Soricut and Marcu (2003), Hernault et al. (2010), and Joty et al. (2013). When using the same head annotation scheme as Yoshida et al. (2014), we outperform their discourse dependency parser on unlabeled dependency accuracy, getting 56% as opposed to 53%.", "startOffset": 51, "endOffset": 167}, {"referenceID": 27, "context": "We evaluate our system along two axes: first, on content selection, using ROUGE8 (Lin and Hovy, 2003), and second, on clarity of language and referential structure, using annotators from Amazon", "startOffset": 81, "endOffset": 101}, {"referenceID": 16, "context": "We follow the method of Gillick and Liu (2010) for this evaluation and ask Turkers to rate a summary on how grammatical it is using a 10-point Likert scale.", "startOffset": 24, "endOffset": 47}, {"referenceID": 16, "context": "Gillick and Liu (2010) showed that for linguistic quality judgments (as opposed to content judgments), Turkers reproduced the ranking of systems according to expert judgments.", "startOffset": 0, "endOffset": 23}, {"referenceID": 15, "context": "method of Gillick and Favre (2009). We also compare to our implementation of the Tree Knapsack", "startOffset": 10, "endOffset": 35}, {"referenceID": 46, "context": "Table 1: Results on the NYT50 test set (documents with summaries of at least 50 tokens) from the New York Times Annotated Corpus (Sandhaus, 2008).", "startOffset": 129, "endOffset": 145}, {"referenceID": 51, "context": "On content selection, our system substantially outperforms all baselines, our implementation of the tree knapsack system (Yoshida et al., 2014), and learned extractive systems with less compression, even an EDU-extractive system that sacrifices grammaticality.", "startOffset": 121, "endOffset": 143}, {"referenceID": 51, "context": "method of Yoshida et al. (2014), which matches", "startOffset": 10, "endOffset": 32}, {"referenceID": 6, "context": "Table 2: Results for RST Discourse Treebank (Carlson et al., 2001).", "startOffset": 44, "endOffset": 66}, {"referenceID": 6, "context": "Table 2: Results for RST Discourse Treebank (Carlson et al., 2001). Differences between our system and the Tree Knapsack system of Yoshida et al. (2014) are not statistically significant, consistent with a high variance in this small (20 document) test set.", "startOffset": 45, "endOffset": 153}, {"referenceID": 21, "context": "Following Hirao et al. (2013), we use the gold EDU segmentation from the RST corpus but automatic RST trees.", "startOffset": 10, "endOffset": 30}, {"referenceID": 51, "context": "The system of Yoshida et al. (2014) is unavailable, so we use a reimplementation.", "startOffset": 14, "endOffset": 36}], "year": 2016, "abstractText": "We present a discriminative model for single-document summarization that integrally combines compression and anaphoricity constraints. Our model selects textual units to include in the summary based on a rich set of sparse features whose weights are learned on a large corpus. We allow for the deletion of content within a sentence when that deletion is licensed by compression rules; in our framework, these are implemented as dependencies between subsentential units of text. Anaphoricity constraints then improve cross-sentence coherence by guaranteeing that, for each pronoun included in the summary, the pronoun\u2019s antecedent is included as well or the pronoun is rewritten as a full mention. When trained end-to-end, our final system1 outperforms prior work on both ROUGE as well as on human judgments of linguistic quality.", "creator": "TeX"}}}