{"id": "1603.09029", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2016", "title": "Adaptive Maximization of Pointwise Submodular Functions With Budget Constraint", "abstract": "We study the worst-case adaptive optimization problem with budget constraint. Unlike previous works, we consider the general setting where the cost is a set function on sets of decisions. For this setting, we investigate the near-optimality of greedy policies when the utility function satisfies a novel property called pointwise cost-sensitive submodularity. This property is an extension of cost-sensitive submodularity, which in turn is a generalization of submodularity to general cost functions. We prove that two simple greedy policies for the problem are not near-optimal but the best between them is near-optimal. With this result, we propose a combined policy that is near-optimal with respect to the optimal worst-case policy that uses half of the budget. We discuss applications of our theoretical results and also report experimental results comparing the greedy policies on the active learning problem.", "histories": [["v1", "Wed, 30 Mar 2016 03:27:41 GMT  (147kb,D)", "http://arxiv.org/abs/1603.09029v1", null], ["v2", "Mon, 22 May 2017 21:08:53 GMT  (447kb,D)", "http://arxiv.org/abs/1603.09029v2", "This paper was published at the 30th Conference on Neural Information Processing Systems (NIPS 2016)"]], "reviews": [], "SUBJECTS": "cs.AI cs.DM math.OC stat.ML", "authors": ["nguyen cuong", "huan xu"], "accepted": true, "id": "1603.09029"}, "pdf": {"name": "1603.09029.pdf", "metadata": {"source": "CRF", "title": "Maximize Pointwise Cost-sensitively Submodular Functions With Budget Constraint", "authors": ["Nguyen Viet Cuong", "Huan Xu"], "emails": ["NVCUONG@NUS.EDU.SG", "ISEXUH@NUS.EDU.SG"], "sections": [{"heading": "1. Introduction", "text": "This year, as never before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country,"}, {"heading": "2. Problem Description: Worst-case Adaptive Optimization with Budget Constraint", "text": "We now formalize the framework for worst-case adaptive optimization with budget constraints. LetX is a finite set of items (or decisions) and Y is a finite set of possible states (or outcomes). Each item in X can be in a particular state in Y. Let h: X \u2192 Y is a deterministic function that maps each item x \u00b2 X to its state. We call h a realization. Let H def = YX = {h: X \u2192 Y} be the realization set consisting of all possible realizations. We consider the problem where we continuously select a subset of items from X as follows: We select a position, observe its state, then we select the next item, observe its state, etc. After some iterations, our observations can so far be presented as a partial realization, which is a subfunction of mX toY. An adaptive strategy for selecting items takes into account the states of all previous items when we select the next item."}, {"heading": "3. Cost-sensitive Submodularity and Assumptions on the Utility", "text": "Adaptive optimization with any utility function is difficult, so we focus on a useful class of utility functions: the sensible cost-sensitive submodular functions. First, we formally define cost-sensitive submodularity, a generalization of submodularity that takes into account the general cost of items. Afterwards, we will present some useful assumptions, including the sensible cost-sensitive submodularity assumption."}, {"heading": "3.1. Cost-sensitive Submodularity", "text": "We remember that a specified function g: 2X \u2192 R submodular is if it fulfills the following decreasing property: for all A B X and x X\\ B, g (A), g (A), g (A), g (B), g (B), g (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u, u (B), u, u, u (B), u (B), u, u (B), u, u (B), u, u (B), u, u (B), u, u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B), u (B, u (B), u (B), u (B), u (B), u (B, u (B), u (B), u (B), u (B, u, u (B), u (B), u (B, u, u, u, u, u (B), u (B), u (B), u (B), u (B, u (B), u, u, u (B, u, u, u, u, u, u (B), u, u (B), u, u (B, u, u, u, B, B, u (B, B), u (B, B, u (B), u (B), u (B), u (B, u, u (B, u (B), u, u, u, u, u, u, u (B, u, u, u, B, B, B, B, B, B, B, B, B,"}, {"heading": "3.2. Pointwise Cost-sensitive Submodularity and Assumptions on the Utility Function", "text": "In our problem, the utility function f (S, h) depends on the selected items S as well as on the realization h, and we assume that it fulfills the reasonable cost-sensitive submodularity property below. Definition 2 (Pointwise Cost-sensitive submodularity) A utility function f (S, h) is reasonable cost-sensitive submodularity in relation to a cost function c, if the specified function fh (S) def = f (S, h) cost-sensitive items in relation to c.Pointwise cost-sensitive submodularity is an extension of the cost-sensitive submodularity in relation to the adaptive setting. It is also a generalization of the meaningless submodularity (Guillory & Bilmes, 2010; Golovin & Krause, 2011) in relation to a general cost dependency. Pointwise submodularity is an extension of the cost-sensitive submodularity in relation to the adjustment."}, {"heading": "4. Greedy Policies and Analyses", "text": "In this paper, we focus on greedy strategies for the problem of the worst adaptive optimization with budgetary constraints. We are interested in a theoretical guarantee for these strategies, called the near-optimality guarantee. Specifically, a policy is nearly optimal when its worst-case benefit lies within a constant algorithm 1 Cost Average Greedy Policy (\u03c01) D."}, {"heading": "4.1. Two Simple Greedy Policies", "text": "We consider two greedy strategies in algorithms 1 and 2. These strategies are the partial realization of the costs that we have observed so far, and XD def = {x, y, y, D for some y, Y} is the domain of D (i.e., the compilation of selected positions in D). We write \u03b4 (x, y) to denote the worst benefit when x, y, y, D is chosen after we define D. Formally, for each item x, \u03b4 (x, D) def = min y, Y {f (XD, x, y) {f}) \u2212 f (XD, D)}. In this definition, it should be noted that we have expanded the utility function f to take a partial realization as a second parameter (instead of a full realization). This expansion is possible because the utility function is assumed to satisfy the minimum dependence, and thus its value depends only on the partial realization that we have observed. The two costly algorithms 1 and 2 are very narrow."}, {"heading": "4.2. A Near-optimal Policy", "text": "Although the greedy policies \u03c01 and \u03c02 are not nearly optimal, we now show that the best policy between them is actually close to optimal. Specifically, let's define a policy \u03c01 so that: \u03c01 if fworst (\u03c01) > fworst (\u03c02) \u03c02 otherwise. (1) Theorem 4 below states that \u03c0 is roughly optimal for the worst-case adaptive optimization problem with budget constraints. (Cuong et al., 2014) and non-adaptive optimization with non-uniform modular costs (Khuller et al., 1999). Unlike the evidence in (Khuller et al., 1999), our evidence is about policy trees instead of sets. Moreover, earlier evidence techniques were originally used for modular cost functions, so we need to generalize the techniques to use them for general cost functions."}, {"heading": "4.3. A Combined Policy", "text": "With Theorem 4, a na\u00efve approach to the worst-case scenario problem of adaptive benefit optimization in previous work (Khuller 1999) is considered. < p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p p > p p p p p p > p p > p p p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p >"}, {"heading": "5. Applications", "text": "We discuss two applications of adaptive optimization with budget constraints: the budgeted adaptive coverage problem and the budgeted pool-based active learning problem, which were considered in (Golovin & Krause, 2011) for the average case with modular costs, while at worst we examine them at general costs."}, {"heading": "5.1. Budgeted Adaptive Coverage", "text": "In this problem, we get a number of places where we have to place some sensors to get the spatial information of the environment. If sensors are used in a number of sampling locations, we have to pay a cost depending on where the locations are. Once a sensor is used in a location, it may be in one of a few possible states (for example, this may be caused by a partial failure of the sensor), resulting in a different level of information that the sensor covers. The budgeted adaptive coverage problem can be stated as follows: given a cost budget K, where should we place the sensors to cover as much spatial information as possible? We can call this a worst-case adaptive optimization problem with the budget K. Let X be the amount of all possible locations where sensors can be used, and let Y be the amount of all possible states of the sensors."}, {"heading": "5.2. Budgeted Pool-based Active Learning", "text": "In the next iteration, we can use the previously observed labels to select the next example for the query. The budgeted pool-based active learning problem can be specified as follows: given a K cost budget, what examples should we query to train a good classifier? We can model this problem as a worst-case adaptive optimization problem with Budget K. Let X be the pool of unlabeled examples and let Y be the set of all possible labels. For each set of examples, S'X, c (S) are the costs of querying their labels. In this problem, realizing h is a labeling of all examples in Pool K. For pool-active learning, we have a guarantee of benefits."}, {"heading": "6. Experiments", "text": "We experiment with 3 binary classification datasets extracted from the 20 newsgroups data (Joachims, 1996): alt.atheism / comp.graphics (dataset 1), comp.sys.mac.hardware / comp.windows.x (dataset 2), and rec.motorcycles / rec.sport.baseball (dataset 3). We consider settings in which random costs and marginal costs are applied to the training examples. Since we use modular costs in the experiments, the costs are transferred to individual training examples, and the total cost is the sum of the costs of the selected examples. For each dataset, we compare 4 strategies for selecting training examples: passive learning (passive learning), costly greedy policies or minimal trust (LC), costaverage greedy policies (AvgLC), and budgeted least trust (budget plan)."}, {"heading": "6.1. Experiments with Random Costs", "text": "In this scenario, the cost of the training examples is calculated randomly. We will consider two scenarios: In the first scenario, some random examples will have costs from the distribution of gamma (80, 0.1) and the other examples will have costs 1. The results of this scenario can be found in Table 1, where AvgLC performs better than LC and BudgetLC usually achieves the second best results among the active learning algorithms. In the second scenario, all examples with label 1 will have costs from gamma (45, 0.1) and the others (examples with label 0) cost 1. The results for this scenario can be found in Table 2, where LC generally performs better than AvgLC. This is because the costs tend to be higher than those with label 0, so AvgLC prefers examples from this class. In this scenario, BudgetLC also performs second best among the active learning algorithms, although it is still significantly worse than LC."}, {"heading": "6.2. Experiments with Margin-Dependent Costs", "text": "Specifically, we train a logistics regression model based on all the data and calculate the likely prediction for each training example, and then the margin of an example is the scaled gap between 0.5 and its likely prediction. We also consider two scenarios. In the first scenario, we base higher costs on examples with lower margins. Results for this scenario are in Table 3, where AvgLC generally performs better than LC. BudgetLC performs better than both AvgLC and LC on record 2, and performs second best among active learning algorithms on record 1 and 3. In the second scenario, we place higher costs on examples with larger margins. Results for this scenario in Table 4 show that AvgLC performs better than LC on record 1, while LC performs better than AvgLC on record 2 and 3."}, {"heading": "7. Related Work", "text": "This year, it has come to the point that it has never been as far as this year."}, {"heading": "8. Conclusion", "text": "We examined worst-case adaptation optimizations with budget constraints, where cost can be a general fixed function and the benefits of meaningful cost-sensitive submodularity suffice. We demonstrated negative results on two intuitively greedy strategies for this problem, but also showed a near-optimal result for the best policy between them. From this result, we derived a combined policy that can achieve approximately optimal strategies against the optimal policy that uses half of the budget. We discussed the application of our theoretical results and reported on experiments for the greedy strategies for the pool-based active learning problem. Appendix"}, {"heading": "A. Proof of Theorem 1", "text": "As g1 and g2 (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) (A) ((A) (A) (A) (A) (A) (A) (A) (A) (A)"}, {"heading": "B. Proof of Theorem 2", "text": "In this problem, the supply function and the cost function are both modular, i.e. they can be divided into the sum of the supply services (or costs) of the individual items. Furthermore, all items have only one state, so it is essentially a non-adaptive problem. Consider the supply function: f (S, h) = x (S, h) w (3), where w: X \u00b7 Y \u2192 R {\u03b1 0 is the supply function for a item. Intuitively, w (x, y) is the supply function achieved by selecting position xmit state y, and f (S, h) is the sum of all supplies in S with states after h. It is easy to see that f is a meaningful monotone and also satisfies the minimal dependency.We now consider the problem of adaptable optimization with two positions {x1, x2} and a state {0}, which is a function (1 > w = 1)."}, {"heading": "C. Proof of Theorem 3", "text": "Similar to the proof of Theorem 2, the benefits and costs are modular and the elements have only one state. In particular, we will consider the problem of the worst adaptive optimization with n + 1 points {x0, x1,.., xn} and a state {0}. We will use the function f, defined by Equation (3), for i = 1,., n, and c (S) = 2 and w (xi, 0) = 1 for i = 1. Let the cost function be: c ({x0}) = n, for i = 1,., n, and c (S) = 1 x, S c ({x}), for other subsets of points. Similar to the proof of Theorem 2, the function f is dot. & xi.n With regard to the problem, we can only choose the function y and ignore it with regard to the minimal costs."}, {"heading": "D. Proof of Theorem 4", "text": "Without loss of universality, we assume that each element can be selected from at least one policy that corresponds to budget K. Otherwise, we can simply remove that element from the sentence. First, we consider the policy \u03c01. Let h1 = \u2212 \u2212 \u2212 arg minh f (x \u03c01 h, h) be the worst possible realization of this element (starting from the root). We have fworst (\u03c01) = {} {{} l (x\u03c01h1, h1). Let the items and states along this path (starting from the root) be: h1 = {h1, y1), (x2, y2), (x2, yxt),. (x | h1, y | h1). For each element xi along the path h1, let us imagine that we are conducting the optimal policy, immediately after selecting xi and then follow the paths in accordance with {x1, y1), xi, yi."}, {"heading": "E. Proof of Theorem 5", "text": "Let us leave h1 / 2 = arg minh f (x \u03c01 / 2 h, h) the worst realization of \u03c01 / 2. We have fworst (\u03c01 / 2) = f (x \u03c01 / 2 h1 / 2 h1 / 2, h1 / 2). Note that x \u03c01 / 2 h1 / 2 = x\u03c01h1 / 2 \u03c02 h1 / 2, where x\u03c01h1 / 2 and x \u03c02 h1 / 2 are the sentences chosen in politics \u03c01 / 2 according to the realization h1 / 2. Therefore, fworst (\u03c01 / 2) \u2265 f (x\u03c01h1 / 2, h1 / 2) and fworst (\u03c01h1 / 2) \u2265 f (x \u03c02 h1 / 2, h1 / 2) apply due to the pointed monotonicity of f."}, {"heading": "F. Discussion on \u03c01 versus \u03c0\u22171/2", "text": "In this section we show that it is not possible to construct a counter-example for politics."}], "references": [{"title": "Stochastic submodular maximization", "author": ["Asadpour", "Arash", "Nazerzadeh", "Hamid", "Saberi", "Amin"], "venue": "In Internet and Network Economics,", "citeRegEx": "Asadpour et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Asadpour et al\\.", "year": 2008}, {"title": "Active learning for probabilistic hypotheses using the maximum Gibbs error criterion", "author": ["Cuong", "Nguyen Viet", "Lee", "Wee Sun", "Ye", "Nan", "Chai", "Kian Ming A", "Chieu", "Hai Leong"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Cuong et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cuong et al\\.", "year": 2013}, {"title": "Nearoptimal adaptive pool-based active learning with general loss", "author": ["Cuong", "Nguyen Viet", "Lee", "Wee Sun", "Ye", "Nan"], "venue": "In Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Cuong et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cuong et al\\.", "year": 2014}, {"title": "Robustness of Bayesian pool-based active learning against prior misspecification", "author": ["Cuong", "Nguyen Viet", "Ye", "Nan", "Lee", "Wee Sun"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Cuong et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Cuong et al\\.", "year": 2016}, {"title": "Approximating the stochastic knapsack problem: The benefit of adaptivity", "author": ["Dean", "Brian C", "Goemans", "Michel X", "J. Vondrdk"], "venue": "In Annual IEEE Symposium on Foundations of Computer Science (FOCS),", "citeRegEx": "Dean et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dean et al\\.", "year": 2004}, {"title": "Adaptive submodularity: Theory and applications in active learning and stochastic optimization", "author": ["Golovin", "Daniel", "Krause", "Andreas"], "venue": "Journal of Artificial Intelligence Research (JAIR),", "citeRegEx": "Golovin et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Golovin et al\\.", "year": 2011}, {"title": "Interactive submodular set cover", "author": ["Guillory", "Andrew", "Bilmes", "Jeff"], "venue": "In International Conference on Machine Learning (ICML), pp", "citeRegEx": "Guillory et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Guillory et al\\.", "year": 2010}, {"title": "A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization", "author": ["Joachims", "Thorsten"], "venue": "DTIC Document,", "citeRegEx": "Joachims and Thorsten.,? \\Q1996\\E", "shortCiteRegEx": "Joachims and Thorsten.", "year": 1996}, {"title": "The budgeted maximum coverage problem", "author": ["Khuller", "Samir", "Moss", "Anna", "Naor", "Joseph Seffi"], "venue": "Information Processing Letters,", "citeRegEx": "Khuller et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Khuller et al\\.", "year": 1999}, {"title": "Near-optimal observation selection using submodular functions", "author": ["Krause", "Andreas", "Guestrin", "Carlos"], "venue": "In Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Krause et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2007}, {"title": "Nonmyopic active learning of Gaussian processes: An explorationexploitation approach", "author": ["Krause", "Andreas", "Guestrin", "Carlos"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Krause et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2007}, {"title": "Submodularity and its applications in optimized information gathering", "author": ["Krause", "Andreas", "Guestrin", "Carlos"], "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),", "citeRegEx": "Krause et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Krause et al\\.", "year": 2011}, {"title": "Approximately adaptive submodular maximization", "author": ["Kusner", "Matt J"], "venue": "In NIPS Workshop on Discrete and Combinatorial Problems in Machine Learning,", "citeRegEx": "Kusner and J.,? \\Q2014\\E", "shortCiteRegEx": "Kusner and J.", "year": 2014}, {"title": "Cost-effective outbreak detection in networks", "author": ["Leskovec", "Jure", "Krause", "Andreas", "Guestrin", "Carlos", "Faloutsos", "Christos", "VanBriesen", "Jeanne", "Glance", "Natalie"], "venue": "In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),", "citeRegEx": "Leskovec et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2007}, {"title": "Employing EM and pool-based active learning for text classification", "author": ["McCallum", "Andrew", "Nigam", "Kamal"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "McCallum et al\\.,? \\Q1998\\E", "shortCiteRegEx": "McCallum et al\\.", "year": 1998}, {"title": "Best algorithms for approximating the maximum of a submodular set function", "author": ["G.L. Nemhauser", "L.A. Wolsey"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Nemhauser and Wolsey,? \\Q1978\\E", "shortCiteRegEx": "Nemhauser and Wolsey", "year": 1978}, {"title": "Submodularity in data subset selection and active learning", "author": ["Wei", "Kai", "Iyer", "Rishabh", "Bilmes", "Jeff"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "Wei et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wei et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 3, "context": "As another example, in the pool-based active learning problem (McCallum & Nigam, 1998; Cuong et al., 2016), one needs to sequentially select unlabeled examples and query their labels, taking into account the previously observed labels.", "startOffset": 62, "endOffset": 106}, {"referenceID": 4, "context": "Adaptive optimization with budget constraint has been previously studied in the average case (Dean et al., 2004; Asadpour et al., 2008; Golovin & Krause, 2011).", "startOffset": 93, "endOffset": 159}, {"referenceID": 0, "context": "Adaptive optimization with budget constraint has been previously studied in the average case (Dean et al., 2004; Asadpour et al., 2008; Golovin & Krause, 2011).", "startOffset": 93, "endOffset": 159}, {"referenceID": 2, "context": "If the cost function is uniform and modular, it is known that these two policies are equivalent and are near-optimal (Cuong et al., 2014).", "startOffset": 117, "endOffset": 137}, {"referenceID": 2, "context": "Our proof for this result is built upon the proof techniques for worst-case adaptive optimization with uniform modular costs (Cuong et al., 2014) and non-adaptive optimization with non-uniform modular costs (Khuller et al.", "startOffset": 125, "endOffset": 145}, {"referenceID": 8, "context": ", 2014) and non-adaptive optimization with non-uniform modular costs (Khuller et al., 1999) but goes beyond them to handle general, possibly non-uniform and non-modular, costs.", "startOffset": 69, "endOffset": 91}, {"referenceID": 2, "context": "Pointwise submodularity is an extension of submodularity to the adaptive setting and it has been used for active learning (Guillory & Bilmes, 2010; Cuong et al., 2014).", "startOffset": 122, "endOffset": 167}, {"referenceID": 2, "context": "Pointwise monotonicity and minimal dependency were also assumed in (Cuong et al., 2014) for the modular and uniform cost setting.", "startOffset": 67, "endOffset": 87}, {"referenceID": 2, "context": "Proving this theorem requires a sophisticated combination of the proof techniques for worst-case adaptive optimization with uniform modular costs (Cuong et al., 2014) and non-adaptive optimization with non-uniform modular costs (Khuller et al.", "startOffset": 146, "endOffset": 166}, {"referenceID": 8, "context": ", 2014) and non-adaptive optimization with non-uniform modular costs (Khuller et al., 1999).", "startOffset": 69, "endOffset": 91}, {"referenceID": 8, "context": "Unlike the proof in (Khuller et al., 1999), our proof deals with policy trees instead of sets.", "startOffset": 20, "endOffset": 42}, {"referenceID": 8, "context": "The constant factor 12 (1 \u2212 1/e) in Theorem 4 is the same as the constant factor for the non-adaptive budgeted maximum coverage problem (Khuller et al., 1999).", "startOffset": 136, "endOffset": 158}, {"referenceID": 2, "context": "Although this implies the greedy policy is near-optimal, the constant factor 12 (1\u2212 1/e) in this case is not as good as the constant factor (1 \u2212 1/e) in (Cuong et al., 2014) for the uniform modular cost setting.", "startOffset": 153, "endOffset": 173}, {"referenceID": 8, "context": "Thus, the adaptive setting in our paper is more difficult than the non-adaptive setting considered in previous works (Khuller et al., 1999; Leskovec et al., 2007).", "startOffset": 117, "endOffset": 162}, {"referenceID": 13, "context": "Thus, the adaptive setting in our paper is more difficult than the non-adaptive setting considered in previous works (Khuller et al., 1999; Leskovec et al., 2007).", "startOffset": 117, "endOffset": 162}, {"referenceID": 1, "context": "If we consider a Bayesian setting with some prior on the set of realizations (Golovin & Krause, 2011; Cuong et al., 2013; 2016), we can sample a subset of realizations from the prior to estimate fworst.", "startOffset": 77, "endOffset": 127}, {"referenceID": 1, "context": "For poolbased active learning, previous works (Golovin & Krause, 2011; Cuong et al., 2013; 2014) have shown that the version space reduction utility is pointwise monotone submodular and satisfies minimal dependency.", "startOffset": 46, "endOffset": 96}, {"referenceID": 2, "context": "Theorem 5 can also be applied if we consider the total generalized version space reduction utility (Cuong et al., 2014) that incorporates an arbitrary loss.", "startOffset": 99, "endOffset": 119}, {"referenceID": 2, "context": "This utility was also shown to be pointwise monotone submodular and satisfy minimal dependency (Cuong et al., 2014), and thus the theorem still holds in this case for modular costs.", "startOffset": 95, "endOffset": 115}, {"referenceID": 8, "context": "Our work is related to (Khuller et al., 1999; Leskovec et al., 2007; Guillory & Bilmes, 2010; Cuong et al., 2014), but we consider a more general case than these works.", "startOffset": 23, "endOffset": 113}, {"referenceID": 13, "context": "Our work is related to (Khuller et al., 1999; Leskovec et al., 2007; Guillory & Bilmes, 2010; Cuong et al., 2014), but we consider a more general case than these works.", "startOffset": 23, "endOffset": 113}, {"referenceID": 2, "context": "Our work is related to (Khuller et al., 1999; Leskovec et al., 2007; Guillory & Bilmes, 2010; Cuong et al., 2014), but we consider a more general case than these works.", "startOffset": 23, "endOffset": 113}, {"referenceID": 2, "context": "These generalizations make the problem more complicated as we have shown in Section 4 that simple greedy policies, which are near-optimal in the uniform modular cost setting (Cuong et al., 2014), will not be near-optimal anymore.", "startOffset": 174, "endOffset": 194}, {"referenceID": 1, "context": ", 2007; Guillory & Bilmes, 2010; Cuong et al., 2014), but we consider a more general case than these works. Cuong et al. (2014) considered a similar worst-case setting as our work, but they assumed the utility is pointwise submodular and the cost function is uniform modular.", "startOffset": 33, "endOffset": 128}, {"referenceID": 13, "context": "Similar results were also shown in (Leskovec et al., 2007) for the outbreak detection problem.", "startOffset": 35, "endOffset": 58}, {"referenceID": 8, "context": "Furthermore, the class of utility functions in our work is even more general than the coverage utilities in (Khuller et al., 1999; Leskovec et al., 2007).", "startOffset": 108, "endOffset": 153}, {"referenceID": 13, "context": "Furthermore, the class of utility functions in our work is even more general than the coverage utilities in (Khuller et al., 1999; Leskovec et al., 2007).", "startOffset": 108, "endOffset": 153}, {"referenceID": 16, "context": "Submodularity has been successfully applied to many applications (Krause & Guestrin, 2007b; 2011; Wei et al., 2015).", "startOffset": 65, "endOffset": 115}, {"referenceID": 16, "context": "Submodularity has been successfully applied to many applications (Krause & Guestrin, 2007b; 2011; Wei et al., 2015). There are other ways to extend submodularity to the adaptive setting, e.g., adaptive submodularity (Golovin & Krause, 2011) and approximately adaptive submodularity (Kusner, 2014). When the utility is adaptive submodular, Golovin & Krause (2011) proved that the greedy policy that maximizes the average utility gain in each step is near-optimal in both the average and worst cases.", "startOffset": 98, "endOffset": 363}], "year": 2017, "abstractText": "We study the worst-case adaptive optimization problem with budget constraint. Unlike previous works, we consider the general setting where the cost is a set function on sets of decisions. For this setting, we investigate the near-optimality of greedy policies when the utility function satisfies a novel property called pointwise cost-sensitive submodularity. This property is an extension of cost-sensitive submodularity, which in turn is a generalization of submodularity to general cost functions. We prove that two simple greedy policies for the problem are not near-optimal but the best between them is near-optimal. With this result, we propose a combined policy that is nearoptimal with respect to the optimal worst-case policy that uses half of the budget. We discuss applications of our theoretical results and also report experimental results comparing the greedy policies on the active learning problem.", "creator": "TeX"}}}