{"id": "1603.09050", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Mar-2016", "title": "Robustness of Bayesian Pool-Based Active Learning Against Prior Misspecification", "abstract": "We study the robustness of active learning (AL) algorithms against prior misspecification: whether an algorithm achieves similar performance using a perturbed prior as compared to using the true prior. In both the average and worst cases of the maximum coverage setting, we prove that all $\\alpha$-approximate algorithms are robust (i.e., near $\\alpha$-approximate) if the utility is Lipschitz continuous in the prior. We further show that robustness may not be achieved if the utility is non-Lipschitz. This suggests we should use a Lipschitz utility for AL if robustness is required. For the minimum cost setting, we can also obtain a robustness result for approximate AL algorithms. Our results imply that many commonly used AL algorithms are robust against perturbed priors. We then propose the use of a mixture prior to alleviate the problem of prior misspecification. We analyze the robustness of the uniform mixture prior and show experimentally that it performs reasonably well in practice.", "histories": [["v1", "Wed, 30 Mar 2016 06:21:42 GMT  (233kb,D)", "http://arxiv.org/abs/1603.09050v1", "This paper is published at AAAI Conference on Artificial Intelligence (AAAI 2016)"]], "COMMENTS": "This paper is published at AAAI Conference on Artificial Intelligence (AAAI 2016)", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["nguyen viet cuong", "nan ye", "wee sun lee"], "accepted": true, "id": "1603.09050"}, "pdf": {"name": "1603.09050.pdf", "metadata": {"source": "CRF", "title": "Robustness of Bayesian Pool-based Active Learning Against Prior Misspecification", "authors": ["Nguyen Viet Cuong", "Nan Ye", "Wee Sun Lee"], "emails": ["nvcuong@nus.edu.sg", "n.ye@qut.edu.au", "leews@comp.nus.edu.sg"], "sections": [{"heading": "1 Introduction", "text": "We focus on the sequentially selected problems described from a pool of unlabeled data for creating a good classifier with as few labeled examples as possible (McCallum and Nigam 1998). In order to achieve approximate efficiency, it is widely believed that the most commonly used methods greedily select an example at a time based on some criteria. In this thesis, we consider the maximum performance of Bayesian Pool-based AL, the data labels are generated from a prior distribution. In theory, it is generally assumed that the actual performance is known (Golovin and Krause 2011; Cuong et al. 2013; Cuong, Lee, and Ye 2014). In practice, it is often unknown and incorrectly specified; that is, the previously used methods differ from the actual one. This work is the first study of the robustness of AL algorithms against previous misspecifications - i.e., whether an algorithm achieves similar performance with a perbified application."}, {"heading": "2 Preliminaries", "text": "Consider the hypothesis space H def = YX, which consists of all functions from X to Y. Each hypothesis h-H is a label of X. In Bayesian environments, we assume an unknown true label htrue, taken from a previous p0 [h] to H. After observing a labeled set D, we get the rear pD [h] def = p0 [h | D] using Bayes \"rule.The true label htrue can be generated by a complex process, rather than directly from a previous p0."}, {"heading": "3 Robustness: Maximum Coverage Problem", "text": "We now consider the robustness of AL algorithms for the maximum coverage problem: Find an adaptive policy to maximize the expected or worst possible benefit given a budget of k queries (Cuong et al. 2013; Cuong, Lee and Ye 2014). The benefit is a non-negative function f (S, h): 2X \u00d7 H \u2192 R \u2265 0. Intuitively, a utility measures the value of querying examples S if the true label is h. Utility values for AL usually depend on the previous one, so we will use the notation fp (S, h) to indicate that the benefit fp depends on a distribution point above H. fp. It is said that Lipschitz is continuous (in the previous one) with a Lipschitz constant L if for S, h and two priors p, p, \"fp\" (S, h) \u2212 fp \"is the distribution policy p\" (S, h)."}, {"heading": "3.1 The Average Case", "text": "In this case, our goal is to find a policy with maximum expected benefit. If p0 is the true procedure, then the expected utility of policy f avgp0 (\u03c0) def = Eh sp. # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #"}, {"heading": "3.2 The Worst Case", "text": "If p0 is the true case, the worst-case-utility-utility-utility-utility-utility-utility-utility-utility-utility-utility-utility-utility-utility-utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility-Utility"}, {"heading": "3.3 Discussions", "text": "We emphasize that our results are important because they enhance our understanding and confidence in existing AL algorithms. Moreover, if the benefit we want to maximize is not continuous, then even an exact AL algorithm for malfunctioning priors may not be robust, both on average and in the worst case. We prove this in Theorem 3 below (see Appendix F for proof). Theorem 3: For both the average and worst case, there is an AL problem with a non-Lipschitz benefit, as follows: for every C, \u03b1, > 0, there is a malfunctioning state before p1 satisfactory 0 < and an exact algorithm A satisfactory cp0 (p1) < maximum level f cp0 and level 5 satisfactory (p0) < maximum level f cp0 and level 5 satisfactory (p0)."}, {"heading": "4 Robustness: Minimum Cost Problem", "text": "In this section, we examine the robustness of AL algorithms for the minimum cost problem on average: Find an adaptive policy that minimizes the expected number of queries to identify the true label (Golovin and Krause 2011), which assumes that all hypotheses are removed from the current hypotheses space (also referred to as the version space) We stop when there is only one hypothesis that hypothesizes htrue left.We do not consider this problem at worst, because even the optimal worst-case algorithms are not robust.2 For example, if the true previous hypothesis exists a correct hypothesis, but there are positive probabilities for all hypotheses."}, {"heading": "5 Mixture Prior", "text": "We consider methods that minimize regularized loss. These methods are commonly used and are known to determine the maximum cost of a subsequent hypothesis with an appropriate approach. In practice, the best regularization constant is usually unknown, and a common method (in passive learning) is to divide the available data into training and a validation set that is used to select the best regularization constant based on the performance of the algorithms being trained on the basis of the training. We assume that we have a candidate set of previous distributions that correspond to different regularization constants, and the true hypothesis is first randomly generated by selecting a distribution and then selecting a hypothesis using that distribution, which corresponds to the assumption that the previous distribution is the distribution of the mixture distribution."}, {"heading": "As a result, if A is generalized binary search, then", "text": "cavgp0 (A (p1) \u2264 k (ln kminh p0 [h] 1) min \u03c0 cavgp1 (\u03c0), andcavgp0 (A (p1)) \u2264 (ln kminh p0) (h) + 1) (k \u2212 1 minh p0 [h] + 1) min \u03c0 cavgp0 (\u03c0).The algorithm for greedy AL with the mixture model is shown in algorithm 1 * 1. * In the algorithm, the undescribed example x * can be selected with any AL criterion. * The criterion can be calculated from the weight and posteriors obtained from the previous iteration. * For example, if the maximum Gibbs error algorithm is used in iteration, then we have used x x-arbitrary algorithms. * The criterion can be calculated from the weight and posteriors obtained from the previous iteration."}, {"heading": "6 Experiments", "text": "We use the logistic regression model with different L2 regularizers, which are known to impose a Gaussian Prior with a mean zero and a variance \u03c32 on the parameter space. Therefore, we can consider different priorities by varying the variance \u03c32 of the regularizer. We consider two experiments with the maximum Gibbs error algorithm. Since our data sets are all classified binary, this algorithm corresponds to the least trust and the maximum entropy algorithms. In our first experiment, we compare models that use different priors (equivalent: regularizers). In the second experiment, we perform the uniform mixing predecessor model and compare it with models that only use a previous one. For AL, we randomly select the first 10 examples as seed sets. The results are averaged over 100 runs of the experiments with different seed sets."}, {"heading": "6.1 Experiment with Different Priors", "text": "We execute maximum Gibbs errors with 1 / \u03c32 = 0.01, 0.1, 0.2, 1, 10 for tasks from the 20 newsgroups and UCI datasets (Joachims 1996; Bache and Lichman 2013) shown in the first column of Table 1. Figure 1 shows the average ranges below 78.88 76.99 75.5869.4358.6283.37 82.52 81.78 79.0273.480.01 0.1 0.2 1 1 1 1 10 (a) Passive Assets 74.07 72.4871.2266.8061.5077.05 76.43 75.86 74.6472.720.01 0.1 0.2 1 1 1 1 10 (b) Passive Active........ () i i i i.... () itiFigure 1: Average AUCs for passive learning and maximum Gibbs Error AL algorithms with 1 / 2 = 0.01, 0.1, AU\u03c32, 1 and 10 for the 20 newsgroups (Figure 1) and the selected data (AL)."}, {"heading": "6.2 Experiment with Mixture Prior", "text": "We examine the performance of the pre-mixing model proposed in algorithm 1. In this case, using the pre-mixing model is often impractical for AL to use a validation set to select the regulators beforehand, since we do not have any marked data at first. In this case, using the pre-mixing model is a reasonable choice. We perform the uniform mix beforehand with the regulators 1 / \u03c32 = 0.01, 0.1, 1, 10 and compare it with models using only one of these regulators. Table 1 shows the AUCs of the first 150 selected examples of these models in the 20 newsgroups and the UCI datasets. From the results, the pre-mixing model achieves the second-best AUCs for all tasks in the 20 newsgroups datasets. For the UCI datasets, the model achieves the best value in the ionosphere and the second-best values in three other tasks. For the remaining three tasks, it achieves the third-best values. On average, the pre-mixing model achieves the second values for all tasks in the 20 newsgroups datasets."}, {"heading": "7 Conclusion", "text": "We have shown that an optimal algorithm in disturbed priors that can be applied to various AL algorithms used in practice may not be robust if the benefit is not Lipschitz. Our results suggest that we should use a Lipschitz algorithm for AL when robustness is required. We have also previously demonstrated novel robustness limits for a uniform mixture and experimentally demonstrated that this priority is reasonable in practice. Recognition. We are grateful for the support of the Australian Research Council through an Australian Laureate Fellowship (FL110100281) and through the Australian Research Council Centre of Excellence for Mathematical and Statistical Frontiers (ACEMS) and from QUT through a research grant from the Vice-Chancellor. We are also grateful for the support of the Singapore MOE AcRF Tier Two Grant R-265-000-443-112.Appendix."}, {"heading": "A Proof of Theorem 1", "text": "Let us take C = L + M as a yardstick. \u2212 C = p1 \u2212 p0 \u2212 p0 (h) fp1 (x \u03c0 h, h) + (p = p0 [h] fp1 [h] fp1 [h] fp1 (x \u03c0 h, h)) + (p = p0 [h] fp1 [h] fp1 [h] fp1 (x \u03c0 h, h)) | p = p0 = p1 \u2212 p0 (p = p0), and g p0 (p = p0) p0 \u2212 p0 (p = p0) p0 (p = p0), and g p0 (p = p0) p0 \u2212 p0 (p)."}, {"heading": "B Proof of Corollary 1", "text": "Cuong et al. (2013) showed that the maximum Gibbs error algorithm provides a constant factor approximation to the optimal Gibbs error, corresponding to the expected revision space reduction for Avgp (\u03c0). Formally, they showed that the algorithm corresponds to \u2265 (1 \u2212 1e) max \u03c0 f avgp (\u03c0) for all previous p, f avgp (A (p))), where A is the maximum Gibbs error algorithm, i.e., the algorithm is average (1 \u2212 1 / e) -approximately. Moreover, the revision space reduction program is limited above M = 1; and for all priors p, p \u2032 we also have | fp (S, h) \u2212 fp \u2032 (S, h) | = | p \u2032 [h (S); S] \u2212 p [h (S); S] \u2212 p [h (S); S] \u2212 p (S); S] \u2212 p \u00b2 p \u00b2 p (S \u00b2)."}, {"heading": "C Proof of Theorem 2", "text": "We use the Lipschitz continuity of fp and the definition of fworstp0, h) \u2212 L: p0 \u2212 p1 (x: h0 h0, h0) - fp0 (x: h0, h0) - fp0 (x: h0, h0) - L: p0 (x: p0, h0) \u2212 L: p0 (x: p0 h, h) \u2212 L: p0 \u2212 p1 (h: p0) - L: p0 (x: p0, h0) - p0 (h: p0 (h: p1) - p1 (h: p1) - fworstp0 (h: p0) - L: p0 (h: p0) - fworstp0 (h: p1 - ph (1) - ph (1): 1 - ph (1)."}, {"heading": "D Proof of Corollary 3", "text": "Cuong, Lee, and Ye (2014) have shown that using the version space reduction algorithm (previously considered for the maximum Gibbs error algorithm) can achieve a constant factor approximation to the optimal worst-case version space reduction. Formally, fp (S, h) is the version space reduction program (previously considered for the maximum Gibbs error algorithm), then fworstp (\u03c0) is the worst-case version space reduction of p, and it was shown (Cuong, Lee, and Ye 2014) that for all previous p, fworstp (A (p))) \u2265 (1 \u2212 1e) max \u03c0 fworstp (\u03c0), with A being the least trusted algorithm."}, {"heading": "E Proof of Corollary 4", "text": "It was shown by Cuong, Lee and Ye (2014) that the worst-case generalized Gibbs error algorithm is the worst-case algorithm (1 \u2212 1 / e) -approximately. If we assume that the loss function L is limited by a constant m, then tp Lipschitz is continuously with L = 2m.In fact, for each S, h, p and p \u00b2 algorithm | tp (S, h) \u2212 tp (S, h) \u2212 h \u00b2 (S) 6 = h (S) 6 = h (S) L (h), h \u00b2 \u00b2 (h \u00b2) (h \u00b2) (h \u00b2) (h \u00b2) (h \u00b2) (h \u00b2 h \u00b2 h \u00b2 h \u00b2) p (h \u00b2 h \u00b2 h) h (h \u00b2 h) \u2212 tp (S, h) \u2212 h \u00b2 (S) h (h) 6 = h (S), h \u00b2 \u00b2 (h), h \u00b2 \u00b2 (h \u00b2) (h \u00b2) (h \u00b2) p (h \u00b2) p (h \u00b2) p (h \u00b2 h) h (h) \u00b2 h (h) \u00b2 h (h) \u00b2 h (h) \u00b2 h (h) \u00b2 h (h) \u00b2 h) h (h) h (h) \u00b2 h (h) h) h (h) h (h) h (h) h) h (h) \u00b2 h) h (h) h (h) h (h) h) h (h) h (h) h) h (h) h) h (h) h (h) h) h (h) h (h) h (h) h) h (h) h) h (h) h (h) h (h) \u00b2 (h) h) h (h) h (h) h (h) h (h) h (h) h (h) h) h (h (h) h) h (h) h (h) h (h) h) h (h) h (h) h (h) h) h (h) h) h (h) h) h (h) h) h) h (h) h) h (h (h) h) h) h (h) h) h) h (h) h) h (h) h) h) h (h"}, {"heading": "F Proof of Theorem 3", "text": "For the two average and worst cases, we look at the AL problem with the budget k = 1 and the utility fp = = > p (S, h) = > p [h '] > \u00b5 and h '( S) 6 = h (S)} |, for some very small \u00b5 > 0 in the worst case and \u00b5 = 0 in the average case.This utility indicates the number of hypotheses that have a significant probability (greater than \u00b5) and are incompatible with h on S. If there are two examples x0, x1 and 4 hypotheses h1, it is the number of hypotheses that are cut off from the version space.So this is a reasonable utility to maximize AL. It is easy to see that this utility is not lipschitz.Let's look at the case where there are two examples x0, x1 and 4 hypotheses h1."}, {"heading": "G Proof of Theorem 4", "text": "For all policy measures, the following applies: | cavgp0 (conceived) \u2212 c avg p1 (conceived) | = | \u2211 h p0 [h] c (conceived, h) \u2212 \u2211 h p1 [h] c (conceived, h) | = \u2211 h (p0 [h] \u2212 p1 [h]) c (\u03c0, h) | \u2264 K \u00b2 p0 \u2212 p1, the last inequality being c (conceived, h). Thus, we have cavgp0 (p1) \u2264 c avg p1 (conceived) + K \u00b2 p0 \u2212 p1, for all \u03c0, p0, p1.Let \u03c00 = conceived c avg p0 (conceived, h). We have cavgp0 (p1) \u2264 c avg p1 (p1) \u2264 c avg p1 (conceived) + K \u00b2 (conceived) + K \u00b2 (conceived), the first (conceived) and the second (conceived) + K \u00b2."}, {"heading": "H Proof of Theorem 5", "text": "If k = 1, then p1 = p0 and theorem 5 are trivial. Consider k = other k = 1. For each h, sincep0 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 [h] p1 \u2212 k \u2212 1.Hence, for any kind of politics."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "We study the robustness of active learning (AL) algorithms against prior misspecification: whether an algorithm achieves similar performance using a perturbed prior as compared to using the true prior. In both the average and worst cases of the maximum coverage setting, we prove that all \u03b1-approximate algorithms are robust (i.e., near \u03b1-approximate) if the utility is Lipschitz continuous in the prior. We further show that robustness may not be achieved if the utility is non-Lipschitz. This suggests we should use a Lipschitz utility for AL if robustness is required. For the minimum cost setting, we can also obtain a robustness result for approximate AL algorithms. Our results imply that many commonly used AL algorithms are robust against perturbed priors. We then propose the use of a mixture prior to alleviate the problem of prior misspecification. We analyze the robustness of the uniform mixture prior and show experimentally that it performs reasonably well in practice.", "creator": "LaTeX with hyperref package"}}}