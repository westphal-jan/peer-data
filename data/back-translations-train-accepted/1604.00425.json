{"id": "1604.00425", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Apr-2016", "title": "Cross-lingual Models of Word Embeddings: An Empirical Comparison", "abstract": "Despite interest in using cross-lingual knowledge to learn word embeddings for various tasks, a systematic comparison of the possible approaches is lacking in the literature. We perform an extensive evaluation of four popular approaches of inducing cross-lingual embeddings, each requiring a different form of supervision, on four typographically different language pairs. Our evaluation setup spans four different tasks, including intrinsic evaluation on mono-lingual and cross-lingual similarity, and extrinsic evaluation on downstream semantic and syntactic applications. We show that models which require expensive cross-lingual knowledge almost always perform better, but cheaply supervised models often prove competitive on certain tasks.", "histories": [["v1", "Fri, 1 Apr 2016 22:18:51 GMT  (225kb,D)", "http://arxiv.org/abs/1604.00425v1", null], ["v2", "Wed, 8 Jun 2016 03:14:08 GMT  (127kb,D)", "http://arxiv.org/abs/1604.00425v2", "To appear at ACL 2016"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["shyam upadhyay", "manaal faruqui", "chris dyer", "dan roth"], "accepted": true, "id": "1604.00425"}, "pdf": {"name": "1604.00425.pdf", "metadata": {"source": "CRF", "title": "Cross-lingual Models of Word Embeddings: An Empirical Comparison", "authors": ["Shyam Upadhyay", "Manaal Faruqui", "Chris Dyer", "Dan Roth"], "emails": ["upadhya3@illinois.edu,", "mfaruqui@cs.cmu.edu", "cdyer@cs.cmu.edu,", "danr@illinois.edu"], "sections": [{"heading": "1 Introduction", "text": "The quality of these word vectors can be significantly improved through the inclusion of linguistic distribution information (Klementiev et al., 2012; Zou et al., 2013; Vulic \u043e and Moens, 2013b; Mikolov et al., 2013b; Faruqui and Dyer, 2014; Hermann and Blunsom, 2014; Lauly et al., 2014, and others), with improvements in both monolingual (Faruqui and Dyer, 2014; Rastogi et al., 2015) and bilingual tasks (Guo et al., 2015; S\u00f8gaard et al., 2015; Guo et al., 2016). Several models for the production of translingual embedding have been proposed, each requiring a different form of translinguistic monitoring - some may use documentary alignments (Vulic and Movens, 2015)."}, {"heading": "2 Bilingual Embeddings", "text": "A general scheme for creating bilingual embeddings is shown in Figure 1. Our comparison focuses on dense, distributed fixed-length embeddings achieved through a form of cross-language supervision. [1] We briefly describe the embedding procedure for each of the selected bilingual word vector models, with the aim of providing a unified algorithmic perspective for all methods to facilitate better understanding and comparison. Our model selection includes various forms of supervision required for embedding, as illustrated in Figure 2. Let us leave W = {w1, w2,..., w | W |} the vocabulary of a language l1 with | W | words and W = R | W | \u00b7 l the corresponding word embedding length l. Let us leave V = {v1, v2,.., v | V |} the vocabulary of another language l1 with | V | words and V | the word embedding length l."}, {"heading": "2.1 Bilingual Skip-Gram Model (BiSkip)", "text": "Luong et al. (2015) proposed the bilingual SkipGram, a simple extension of the monolingual Skip-gram model, which enables bilingual embedding by using a parallel corpus together with word1We are comparing different cross-language word embeddings, which should not be confused with a collection of monolingual word embeddings, which are individually trained for different languages (Al-Rfou et al., 2013).The learning goal is a simple extension of the Skip-gram model, in which the context of a word is supplemented by bilingual links derived from word alignments, so that the model is trained to predict cross-linguistic words. In particular, given a word alignment link from the v-V in the l1 to w-W in the l2 language, the model can specify the contextual words of w with v and vice versa."}, {"heading": "2.2 Bilingual Compositional Model (BiCVM)", "text": "Hermann and Blunsom (2014) present a method that learns bilingual word vectors from a sentence of aligned corpus. Their model takes advantage of the fact that aligned sentences have an equivalent meaning, so their sentence representations should be similar. We designate two aligned sentences, ~ v = < x1,.., and ~ w = < y1,.. >, where xi-V, yi-W, are vectors that correspond to the words in the sentences. Let's have the functions f: ~ v \u2192 Rn and g: ~ w \u2192 Rn match the sentences to their semantic representations in Rn. BiCVM creates word vectors by minimizing the square '2 standard between the sentence representations of aligned sentences. To prevent this from resulting from the direct minimization of the' 2 standard, they use a sound-contrasting, large-scale actualization with randomly drawn sentence pairs (~ v, ~ wn) as examples (v-W, W)."}, {"heading": "2.3 Bilingual Correlation Based Embeddings (BiCCA)", "text": "The BiCCA model proposed by Faruqui and Dyer (2014) showed that when (independently trained) monolingual vector matrices W, V are projected using CCA (Hotelling, 1936) to respect a translation lexicon, their performance in word similarity and word analogy tasks is improved. First, they construct W W, V W \ufffd V \ufffd V \ufffd V \ufffd V so that the corresponding words (wi, vi) in the matrices are translations of each other. Then, the projection is calculated as follows: PW, PV = CCA (W \ufffd W \ufffd W \ufffd W, V \ufffd) (10) W \ufffd = WPW = VPV \ufffd V \ufffd (11), with PV \ufffd W \ufffd W \ufffd W \ufffd W \ufffd W \ufffd W \ufffd W \ufffd W \ufffd W \ufffd W \ufffd W"}, {"heading": "2.4 Bilingual Vectors from Comparable Data (BiVCD)", "text": "Another approach to induce bilingual word vectors, which we call BiVCD, was proposed by Vulic \u0301 and Moens (2015). Their approach is designed to use a comparable corpus between the source and target language pair to induce cross-lingual vectors.Let de and df denote a pair of comparable documents with the length p or q, respectively (assume p > q).BiVCD first merges these two comparable documents into a single pseudo-bilingual document using a deterministic strategy based on the length ratio of two documents R = bpq c. Every sixth word of the merged pseudo-bilingual document is sequentially selected from df. Finally, a skip gram model is trained on the corpus of pseudo-bilingual documents to generate vectors for all words in W \u00b2 V \u00b2. The vectors of the merged pseudo-bilingual document are then easily identifiable."}, {"heading": "3 Data", "text": "We train cross-language embedding for 4 language pairs: English-German (en-de), English-French (en-fr), English-Swedish (en-sv) and English-Chinese (en-zh). For en-de and en-sv we use the parallel corpus Europarl v7 (Koehn, 2005). For en-fr we use Europarl combined with the news commentary and the UN corpus record of WMT 2015.4 For en-zh we use the parallel corpus FBIS from the news section (LDC2003E14)."}, {"heading": "4 Evaluation", "text": "We measure the quality of induced cross-language word embedding in terms of performance when used as traits in the following tasks: \u2022 Monolingual word similarity for English \u2022 Lingual dictionary induction \u2022 Cross-lingual document classification \u2022 Cross-lingual syntactic dependence The first two tasks measure intrinsically how much monolingual and cross-lingual similarity benefit from linguistic training; the last two tasks measure the ability of bilingual trained vectors to facilitate model transfer between languages extrinsically for semantic and syntactic applications, respectively. These tasks have been used in previous work (Klementiev et al., 2012; Luong et al., 2015; Vulic 'and Moens, 2013a; Guo et al., 2015) to evaluate bilingual embedding, but there is no comparison that uses them in conjunction.To ensure fair comparison, all models with size 200 embedding are trained."}, {"heading": "4.1 Parameter Selection", "text": "We follow the BestAvg parameter selection strategy of Lu et al. (2015). We selected the parameters for all models by adjusting to a set of values (described below) and selecting the parameter setting that was best for the average of all tasks. BiSkip. All models were trained using a window size of 10 (tuned via {5, 10, 20} and 30 negative samples (tuned via {10, 20, 30}). Word alignments for training the model (available at github.com / lmthang / bivec) were trained using cdec et al., 2010. The number of trainings was set to 5 (no tuning). BiCVM. We use the tool (available at github.com / karlmoritz / bicvm)."}, {"heading": "4.2 Mono-lingual Evaluation", "text": "The task evaluates how well the concept of word similarity is emulated after humans in vector space. It is based on the rank-correlation coefficient of the spectrum (Myers and Well, 1995) between human rankings and rankings produced by calculating cosmic similarity between the vectors of two words. We use SimLex Dataset for English (Hill et al., 2014), which contains 999 pairs of English words, with a balanced set of noun, adjectives and verb pairs. SimLex Dataset for English (Hill et al., 2014), which contains the interpretation of words."}, {"heading": "4.3 Cross-lingual Dictionary Induction", "text": "The task of lingual dictionary induction (Vulic \u0301 and Moens, 2013a; Gouws et al., 2015; Mikolov et al., 2013b) assesses how good bilingual embeddings are at recognizing word pairs that are semantically similar between languages. We follow the setup of Vulic \u0301 and Moens (2013a), but instead of manually creating a bilingual gold dictionary, we derive our golden dictionaries using the multilingual word data published by Bond and Foster (2013). The data includes synset alignments in 26 languages with over 90% accuracy. First, we cut words out of any synset whose frequency number is below 1000 in the vocabulary of the training data. Then, each pair of aligned synsets forms s1 = {k1, k2, k2, s2 = s2 = s2, g2, s2 = s2, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s3, s2, s4, s2, 4, 4, s2, 4, s4, 4, s2, 4, s4, 4, s2, 4, 4, s2, 4, 4, s2, 4, 4, s2, 4, 4, s2, 4, 4, s2, 4, 4, s2, 4, s2, 4, 4, 4, 4, s2, 4, 4, s2, s2, s2."}, {"heading": "4.4 Cross-lingual Document Classification", "text": "We follow the structure of the Multilingual Document Classification (CLDC) by Klementiev et al. (2012), but extend it to all our language pairs. We use the Multilingual Reuters Corpus7 for our experiments.In this task, for one language pair (l1, l2), a document classifier is trained on the basis of document representations derived from word embedding in language l1, and then the trained model is tested on the basis of documents from language l2 (and vice versa).By using supervised training data in one language and evaluating it without further monitoring in another, CLDC assesses whether the learned multilingual representations are semantically consistent in multiple languages.6We will release these dictionaries. 7http: / / trec.nist.gov / data / reuters / reuters.htmlAll embedding is learned on the basis of the data described in \u00a7 3, and we only use the RCV \u2192 data to learn document classification models."}, {"heading": "4.5 Cross-lingual Dependency Parsing", "text": "In the neeisrcnllhSe nvo nlrf\u00fc ide eeisrVnlrteaeegnln rf\u00fc ide eeisrVnlrtee\u00fceegnln rf\u00fc ide eeisrVnlrteeeirln-eaeVnlrrrrteeeeeeoegnln in the eeisrdteeVnlrrlrrrrteeeeeeeeeeeVnlrlrrrteeeeeeeeeeeVnlrlrrrlrrlrrrrteeeeeeeeeeeVnrlrlrlrlrlrrrteeeeeeeeeeeeetnln in the eeirf\u00fc-eVnlrlrlrlrlrlrlrlrlrlrrrrrrrrrrrrrteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeaeVnln"}, {"heading": "5 Qualitative Analysis", "text": "Figure 3 illustrates the embedding of the word in a two-dimensional space using the t-SNE tool (Van der Maaten and Hinton, 2008). The figure shows projected embedding of some randomly selected words from the most common words in the English segment of the parallel en-fr corpus along with their French translations. We record the BiCVM, BiSkip and BiVCD vectors that are 200-dimensional.11 We can explain qualitatively why some models perform better in the task of linguistic similarity with Figure 3. BiVCD embedding moves pairs similar to (children, toddlers) and 11BiCCA could not be included as 100-dimensional and are incompatible with the tool. (war, guerre) apart, while BiCVM does the same with the pair (world, monde), but overall is better than BiVCD. BiSkip performs an almost perfect cross-alignment by matching each word to its corresponding translation."}, {"heading": "6 Discussion and Conclusion", "text": "We have presented the first systematic comparative evaluation of translingual embedding methods across several downstream NLP tasks, both intrinsic and extrinsic. We have provided a consistent representation for all approaches and present them as examples of a general algorithm. Our method choice covers a variety of approaches, each requiring a different form of alignment than monitoring. It will be interesting to see how these embedding methods perform in other tasks such as frame semantic parsing (Johannsen et al., 2015), supersense tagging (Gouws and S\u00f8gaard, 2015), etc. The paper does not cover all approaches that generate translingual word embedding. Some methods do not have publicly available code (Coulmance et al., 2015; Zou et al., 2013); for others, such as BilBOWA et al."}], "references": [{"title": "Polyglot: Distributed word representations for multilingual nlp", "author": ["Al-Rfou et al.2013] Rami Al-Rfou", "Bryan Perozzi", "Steven Skiena"], "venue": "In Proc. of CoNLL", "citeRegEx": "Al.Rfou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2013}, {"title": "Linking and extending an open multilingual wordnet", "author": ["Bond", "Foster2013] Francis Bond", "Ryan Foster"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),", "citeRegEx": "Bond et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bond et al\\.", "year": 2013}, {"title": "Conll-x shared task on multilingual dependency parsing", "author": ["Buchholz", "Marsi2006] Sabine Buchholz", "Erwin Marsi"], "venue": "In Proc. of CoNLL", "citeRegEx": "Buchholz et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Buchholz et al\\.", "year": 2006}, {"title": "Trans-gram, fast cross-lingual wordembeddings", "author": ["Jean-Marc Marty", "Guillaume Wenzek", "Amine Benhalloum"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language", "citeRegEx": "Coulmance et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Coulmance et al\\.", "year": 2015}, {"title": "cdec: A decoder, alignment, and learning framework for finite-state and context", "author": ["Dyer et al.2010] Chris Dyer", "Adam Lopez", "Juri Ganitkevitch", "Jonathan Weese", "Hendra Setiawan", "Ferhan Ture", "Vladimir Eidelman", "Phil Blunsom", "Philip Resnik"], "venue": null, "citeRegEx": "Dyer et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2010}, {"title": "Improving vector space word representations using multilingual correlation", "author": ["Faruqui", "Dyer2014] Manaal Faruqui", "Chris Dyer"], "venue": "In Proc. of EACL", "citeRegEx": "Faruqui et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2014}, {"title": "Placing search in context: the concept revisited", "author": ["Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin"], "venue": "In Proc. of WWW", "citeRegEx": "Finkelstein et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2001}, {"title": "Large margin classification using the perceptron algorithm", "author": ["Freund", "Schapire1999] Yoav Freund", "Robert E Schapire"], "venue": "Machine learning,", "citeRegEx": "Freund et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1999}, {"title": "Simple task-specific bilingual word embeddings", "author": ["Gouws", "S\u00f8gaard2015] Stephan Gouws", "Anders S\u00f8gaard"], "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language", "citeRegEx": "Gouws et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gouws et al\\.", "year": 2015}, {"title": "Bilbowa: Fast bilingual distributed representations without word alignments", "author": ["Gouws et al.2015] Stephan Gouws", "Yoshua Bengio", "Greg Corrado"], "venue": "In Proc. of ICML", "citeRegEx": "Gouws et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gouws et al\\.", "year": 2015}, {"title": "Cross-lingual dependency parsing based on distributed representations", "author": ["Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu"], "venue": "In Proc. of ACL", "citeRegEx": "Guo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2015}, {"title": "A representation learning framework for multi-source transfer parsing", "author": ["Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu"], "venue": "In Proc. of AAAI", "citeRegEx": "Guo et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2016}, {"title": "Canonical correlation analysis: An overview with application to learning methods", "author": ["Sandor Szedmak", "John Shawe-Taylor"], "venue": "Neural computation,", "citeRegEx": "Hardoon et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Hardoon et al\\.", "year": 2004}, {"title": "Multilingual Models for Compositional Distributional Semantics", "author": ["Hermann", "Blunsom2014] Karl Moritz Hermann", "Phil Blunsom"], "venue": "In Proc. of ACL", "citeRegEx": "Hermann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2014}, {"title": "Simlex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Hill et al.2014] Felix Hill", "Roi Reichart", "Anna Korhonen"], "venue": "arXiv preprint arXiv:1408.3456", "citeRegEx": "Hill et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2014}, {"title": "Anylanguage frame-semantic parsing", "author": ["H\u00e9ctor Mart\u0131\u0301nez Alonso", "Anders S\u00f8gaard"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Johannsen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Johannsen et al\\.", "year": 2015}, {"title": "Inducing crosslingual distributed representations of words", "author": ["Ivan Titov", "Binod Bhattarai"], "venue": "In Proc. of COLING", "citeRegEx": "Klementiev et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Klementiev et al\\.", "year": 2012}, {"title": "Europarl: A parallel corpus for statistical machine translation", "author": ["Philipp Koehn"], "venue": "In Proc. of MT summit", "citeRegEx": "Koehn.,? \\Q2005\\E", "shortCiteRegEx": "Koehn.", "year": 2005}, {"title": "An autoencoder approach to learning bilingual word representations", "author": ["Hugo Larochelle", "Mitesh Khapra", "Balaraman Ravindran", "Vikas C Raykar", "Amrita Saha"], "venue": "In Proc. of NIPS", "citeRegEx": "Lauly et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lauly et al\\.", "year": 2014}, {"title": "Deep multilingual correlation for improved word embeddings", "author": ["Lu et al.2015] Ang Lu", "Weiran Wang", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": "In Proceedings of NAACL", "citeRegEx": "Lu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2015}, {"title": "Bilingual word representations with monolingual quality in mind", "author": ["Luong et al.2015] Thang Luong", "Hieu Pham", "Christopher D. Manning"], "venue": "In Proc. of the Workshop on Vector Space Modeling for NLP", "citeRegEx": "Luong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781", "author": ["Kai Chen", "Greg Corrado", "Jeffrey Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Exploiting similarities among languages for machine translation", "author": ["Quoc V Le", "Ilya Sutskever"], "venue": "arXiv preprint arXiv:1309.4168", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Multiview lsa: Representation learning via generalized cca", "author": ["Benjamin Van Durme", "Raman Arora"], "venue": "In Proc. of NAACL", "citeRegEx": "Rastogi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rastogi et al\\.", "year": 2015}, {"title": "Inverted indexing for cross-lingual nlp", "author": ["\u017deljko Agi\u0107", "H\u00e9ctor Mart\u0131\u0301nez Alonso", "Barbara Plank", "Bernd Bohnet", "Anders Johannsen"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Compu-", "citeRegEx": "S\u00f8gaard et al\\.,? \\Q2015\\E", "shortCiteRegEx": "S\u00f8gaard et al\\.", "year": 2015}, {"title": "Tests for comparing elements of a correlation matrix", "author": ["James H Steiger"], "venue": "Psychological bulletin,", "citeRegEx": "Steiger.,? \\Q1980\\E", "shortCiteRegEx": "Steiger.", "year": 1980}, {"title": "Cross-lingual word clusters for direct transfer of linguistic structure", "author": ["R. McDonald", "J. Uszkoreit"], "venue": null, "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? \\Q2012\\E", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2012}, {"title": "A conditional random field word segmenter for sighan bakeoff", "author": ["Tseng et al.2005] Huihsin Tseng", "Pichuan Chang", "Galen Andrew", "Daniel Jurafsky", "Christopher Manning"], "venue": "In Proceedings of the Fourth SIGHAN Workshop on Chinese Lan-", "citeRegEx": "Tseng et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Tseng et al\\.", "year": 2005}, {"title": "Evaluation of word vector representations by subspace alignment", "author": ["Manaal Faruqui", "Wang Ling", "Guillaume Lample", "Chris Dyer"], "venue": "In Proc. of EMNLP", "citeRegEx": "Tsvetkov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2015}, {"title": "Visualizing data using t-sne", "author": ["Van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "Cross-lingual semantic similarity of words as the similarity of their semantic word responses", "author": ["Vuli\u0107", "Moens2013a] Ivan Vuli\u0107", "MarieFrancine Moens"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter", "citeRegEx": "Vuli\u0107 et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Vuli\u0107 et al\\.", "year": 2013}, {"title": "Bilingual word embeddings from non-parallel document-aligned data applied to bilingual lexicon induction", "author": ["Vuli\u0107", "Moens2015] Ivan Vuli\u0107", "Marie-Francine Moens"], "venue": "In Proc. of ACL", "citeRegEx": "Vuli\u0107 et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vuli\u0107 et al\\.", "year": 2015}, {"title": "Bilingual word embeddings for phrase-based machine translation", "author": ["Zou et al.2013] Will Y. Zou", "Richard Socher", "Daniel Cer", "Christopher D. Manning"], "venue": "In Proc. of EMNLP", "citeRegEx": "Zou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zou et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 23, "context": ", 2014, inter alia), with improvements observed both on mono-lingual (Faruqui and Dyer, 2014; Rastogi et al., 2015) and crosslingual tasks (Guo et al.", "startOffset": 69, "endOffset": 115}, {"referenceID": 10, "context": ", 2015) and crosslingual tasks (Guo et al., 2015; S\u00f8gaard et al., 2015; Guo et al., 2016).", "startOffset": 31, "endOffset": 89}, {"referenceID": 24, "context": ", 2015) and crosslingual tasks (Guo et al., 2015; S\u00f8gaard et al., 2015; Guo et al., 2016).", "startOffset": 31, "endOffset": 89}, {"referenceID": 11, "context": ", 2015) and crosslingual tasks (Guo et al., 2015; S\u00f8gaard et al., 2015; Guo et al., 2016).", "startOffset": 31, "endOffset": 89}, {"referenceID": 8, "context": "Several models for inducing cross-lingual embeddings have been proposed, each requiring a different form of cross-lingual supervision \u2013 some can use document-level alignments (Vuli\u0107 and Moens, 2015), others need alignments at the sentence (Hermann and Blunsom, 2014; Gouws et al., 2015) or word (Faruqui and Dyer, 2014; Gouws and S\u00f8gaard, 2015) level, while some require both sentence and word alignments (Luong et al.", "startOffset": 239, "endOffset": 286}, {"referenceID": 20, "context": ", 2015) or word (Faruqui and Dyer, 2014; Gouws and S\u00f8gaard, 2015) level, while some require both sentence and word alignments (Luong et al., 2015).", "startOffset": 126, "endOffset": 146}, {"referenceID": 0, "context": "We compare different cross-lingual word embeddings, which are not to be confused with a collection of monolingual word embeddings trained for different languages individually (Al-Rfou et al., 2013).", "startOffset": 175, "endOffset": 197}, {"referenceID": 12, "context": "5 (Hardoon et al., 2004) C(W,V) = \u2016W \u2212V\u2016+\u03b3 ( VW ) (13)", "startOffset": 2, "endOffset": 24}, {"referenceID": 17, "context": "For en-de and en-sv we use the Europarl v7 parallel corpus3 (Koehn, 2005).", "startOffset": 60, "endOffset": 73}, {"referenceID": 27, "context": "We use the Stanford Chinese Segmenter (Tseng et al., 2005) to preprocess the en-zh parallel corpus.", "startOffset": 38, "endOffset": 58}, {"referenceID": 16, "context": "These tasks have been used in previous works (Klementiev et al., 2012; Luong et al., 2015; Vuli\u0107 and Moens, 2013a; Guo et al., 2015) for evaluating bilingual embeddings, but no comparison exists which uses them in conjunction.", "startOffset": 45, "endOffset": 132}, {"referenceID": 20, "context": "These tasks have been used in previous works (Klementiev et al., 2012; Luong et al., 2015; Vuli\u0107 and Moens, 2013a; Guo et al., 2015) for evaluating bilingual embeddings, but no comparison exists which uses them in conjunction.", "startOffset": 45, "endOffset": 132}, {"referenceID": 10, "context": "These tasks have been used in previous works (Klementiev et al., 2012; Luong et al., 2015; Vuli\u0107 and Moens, 2013a; Guo et al., 2015) for evaluating bilingual embeddings, but no comparison exists which uses them in conjunction.", "startOffset": 45, "endOffset": 132}, {"referenceID": 19, "context": "We follow the BestAvg parameter selection strategy from Lu et al. (2015). We selected the parameters for all models by tuning on a set of values (described below) and picking the parameter setting which did best on an average across all tasks.", "startOffset": 56, "endOffset": 73}, {"referenceID": 4, "context": "com/lmthang/ bivec) were generated using cdec (Dyer et al., 2010).", "startOffset": 46, "endOffset": 65}, {"referenceID": 14, "context": "We use SimLex dataset for English (Hill et al., 2014) which contains 999 pairs of English words, with a balanced set of noun, adjective and verb pairs.", "startOffset": 34, "endOffset": 53}, {"referenceID": 6, "context": "SimLex is claimed to capture word similarity exclusively instead of WordSim-353 (Finkelstein et al., 2001) which captures both word similairty and relatedness.", "startOffset": 80, "endOffset": 106}, {"referenceID": 25, "context": "1 according to Steiger\u2019s method (Steiger, 1980) for calculating the statistical significant differences between two dependent correlation coefficients.", "startOffset": 32, "endOffset": 47}, {"referenceID": 28, "context": "Tsvetkov et al. (2015) proposed an intrinsic evaluation metric for estimating the quality of English word vectors.", "startOffset": 0, "endOffset": 23}, {"referenceID": 28, "context": "ferent reinforces the observation of Tsvetkov et al. (2015) that performance on word similarity tasks alone does not reflect quantification of linguistic properties of words.", "startOffset": 37, "endOffset": 60}, {"referenceID": 8, "context": "The task of cross-lingual dictionary induction (Vuli\u0107 and Moens, 2013a; Gouws et al., 2015; Mikolov et al., 2013b) judges how good bilingual embeddings are at detecting word pairs that are semantically similar across languages.", "startOffset": 47, "endOffset": 114}, {"referenceID": 8, "context": "The task of cross-lingual dictionary induction (Vuli\u0107 and Moens, 2013a; Gouws et al., 2015; Mikolov et al., 2013b) judges how good bilingual embeddings are at detecting word pairs that are semantically similar across languages. We follow the setup of Vuli\u0107 and Moens (2013a), but instead of manually creating a gold bilingual dictionary, we derived our gold dictionaries using the Open Multilingual Wordnet data released by Bond and Foster (2013).", "startOffset": 72, "endOffset": 275}, {"referenceID": 8, "context": "The task of cross-lingual dictionary induction (Vuli\u0107 and Moens, 2013a; Gouws et al., 2015; Mikolov et al., 2013b) judges how good bilingual embeddings are at detecting word pairs that are semantically similar across languages. We follow the setup of Vuli\u0107 and Moens (2013a), but instead of manually creating a gold bilingual dictionary, we derived our gold dictionaries using the Open Multilingual Wordnet data released by Bond and Foster (2013). The data includes synset alignments across 26 languages with over 90% accuracy.", "startOffset": 72, "endOffset": 447}, {"referenceID": 16, "context": "We follow the cross-lingual document classification (CLDC) setup of Klementiev et al. (2012), but extend it to cover all of our language pairs.", "startOffset": 68, "endOffset": 93}, {"referenceID": 26, "context": "The use of cross lingual similarity measures for direct-transfer of dependency parsers was first shown in T\u00e4ckstr\u00f6m et al. (2012). The idea behind direct-transfer is to train a dependency parsing model using embeddings for language l1 and", "startOffset": 106, "endOffset": 130}, {"referenceID": 16, "context": "tf-idf was computed using all documents for that language in RCV2 We use the implementation of Klementiev et al. (2012)", "startOffset": 95, "endOffset": 120}, {"referenceID": 10, "context": "For our experiments, we use the cross lingual transfer setup of Guo et al. (2015).10 Their framework trains a transition-based dependency parser using nonlinear activation function, with the source-side embeddings as lexical features.", "startOffset": 64, "endOffset": 82}, {"referenceID": 10, "context": "Since our goal is to determine the utility of word embeddings in dependency parsing, we turn off other features that can capture distributional information like brown clusters, which were originally used in Guo et al. (2015). We use the universal dependency treebank (McDonald et al.", "startOffset": 207, "endOffset": 225}, {"referenceID": 15, "context": "It will be interesting to see how these embedding methods fare on other such tasks like frame semantic parsing (Johannsen et al., 2015), super-sense tagging (Gouws and S\u00f8gaard, 2015) etc.", "startOffset": 111, "endOffset": 135}, {"referenceID": 3, "context": "Some methods do not have publicly available code (Coulmance et al., 2015; Zou et al., 2013); for others, like BilBOWA (Gouws et al.", "startOffset": 49, "endOffset": 91}, {"referenceID": 32, "context": "Some methods do not have publicly available code (Coulmance et al., 2015; Zou et al., 2013); for others, like BilBOWA (Gouws et al.", "startOffset": 49, "endOffset": 91}, {"referenceID": 8, "context": ", 2013); for others, like BilBOWA (Gouws et al., 2015), we identified problems in the available code, which caused it to consistently produced results that are inferior even to mono-lingually trained vectors.", "startOffset": 34, "endOffset": 54}, {"referenceID": 8, "context": "For example, BilBOWA (Gouws et al., 2015) and Bilingual Autoencoder (Lauly et al.", "startOffset": 21, "endOffset": 41}, {"referenceID": 18, "context": ", 2015) and Bilingual Autoencoder (Lauly et al., 2014) are similar to BiCVM in this respect and Multi-view CCA (Rastogi et al.", "startOffset": 34, "endOffset": 54}, {"referenceID": 23, "context": ", 2014) are similar to BiCVM in this respect and Multi-view CCA (Rastogi et al., 2015) and deep CCA (Lu et al.", "startOffset": 64, "endOffset": 86}, {"referenceID": 19, "context": ", 2015) and deep CCA (Lu et al., 2015) can be viewed as extensions of BiCCA.", "startOffset": 21, "endOffset": 38}], "year": 2017, "abstractText": "Despite interest in using cross-lingual knowledge to learn word embeddings for various tasks, a systematic comparison of the possible approaches is lacking in the literature. We perform an extensive evaluation of four popular approaches of inducing cross-lingual embeddings, each requiring a different form of supervision, on four typographically different language pairs. Our evaluation setup spans four different tasks, including intrinsic evaluation on mono-lingual and cross-lingual similarity, and extrinsic evaluation on downstream semantic and syntactic applications. We show that models which require expensive cross-lingual knowledge almost always perform better, but cheaply supervised models often prove competitive on certain tasks.", "creator": "LaTeX with hyperref package"}}}