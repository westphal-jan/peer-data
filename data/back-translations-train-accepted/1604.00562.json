{"id": "1604.00562", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Apr-2016", "title": "Reasoning about Pragmatics with Neural Listeners and Speakers", "abstract": "We present a model for pragmatically describing scenes, in which contrastive behavior results from a combination of inference-driven pragmatics and learned semantics. Like previous learned approaches to language generation, our model uses a simple feature-driven architecture (here a pair of neural \"listener\" and \"speaker\" models) to ground language in the world. Like inference-driven approaches to pragmatics, our model actively reasons about listener behavior when selecting utterances. For training, our approach requires only ordinary captions, annotated _without_ demonstration of the pragmatic behavior the model ultimately exhibits. In human evaluations on a referring expression game, our approach succeeds 81% of the time, compared to a 64% success rate using existing techniques.", "histories": [["v1", "Sat, 2 Apr 2016 21:52:03 GMT  (1172kb,D)", "http://arxiv.org/abs/1604.00562v1", null], ["v2", "Mon, 26 Sep 2016 13:48:20 GMT  (932kb,D)", "http://arxiv.org/abs/1604.00562v2", null]], "reviews": [], "SUBJECTS": "cs.CL cs.NE", "authors": ["jacob andreas", "dan klein"], "accepted": true, "id": "1604.00562"}, "pdf": {"name": "1604.00562.pdf", "metadata": {"source": "CRF", "title": "Reasoning About Pragmatics with Neural Listeners and Speakers", "authors": ["Jacob Andreas"], "emails": ["jda@cs.berkeley.edu", "klein@cs.berkeley.edu"], "sections": [{"heading": "1 Introduction", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2 Related Work", "text": "As an example of the direct approach mentioned in the introduction, FitzGerald et al. (2013) collect a series of man-made reference expressions via abstract representations of colored blocks. Faced with a series of blocks to be described, their model directly learns maximum entropy distribution via the set of logical expressions whose designation is the target. Other research focusing on the generation of direct reference expressions from the perspective of computer vision includes those by Mao et al. (2015) and Kazemzadeh et al. (2014). Derived Pragmatics The derived approach is illustrated by the work of Smith et al. (2013). This paper describes a series of nested Bayesian models in which intelligent listeners argue about the behavior of reflexive speakers and even higher speakers about these listeners. Experiments (Frank et al., 2009) show that this model explains human behavior well, but both computational and representative questions are very easy to address in this way (2010) and other works in this playful manner."}, {"heading": "3 Approach", "text": "Our goal is to develop a model that can play the role of the speaker S in neural architectures for a variety of tasks. Specifically, in the face of a target speaker (e.g. scene or object) r and a distractor r \u2032, we need to create a description d that uniquely identifies r. For the training, we have access to a series of contrast-free speakers {(ri, di)}: Each training description di is generated in isolation for the corresponding speaker ri. There is no guarantee that di would actually serve as a good reference expression for ri in a particular context. Therefore, we need to apply the training data to the basic language in speaker representations, but rely on reasoning to produce pragmatics. Our model architecture is compositional and hierarchical. In Section 3.2, we start by describing a collection of \"modules\": basic computational primitives for assignment between speakers, descriptions, and references built on reference models (here, linear or small neural networks implemented)."}, {"heading": "3.1 Preliminaries", "text": "Formally, we take a description d in such a way that it consists of a sequence of words d1, d2,.., dn taken from a vocabulary of known magnitude. To encode it, we also access a feature representation f (d) of the sentence (here a vector of indicator features on n-grams for the rest of this work).These two views - as a sequence of words di and a feature vector f (d) - form the basis of the modules \"interactions with language.Referent representations are similarly simple. Since the model never generates referents - only conditions on them and evaluates them - a vector-rated feature representation of referents is sufficient. Our approach is completely indifferent to the nature of this representation. While the experiments in this work use a vector of indicator features on objects and actions present in abstract scenes (Figure 1), it would be easy to use rehearsed contrarian representations instead to refer to natural images."}, {"heading": "3.2 Modules", "text": "All handset and speaker models are built from a kit of simple building blocks for working with multimodal representations of images and text < < < < / p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p < p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p > p \"p\" p \"p.\""}, {"heading": "3.3 Base models", "text": "The first of these models is a literal listener L0 = that takes a description and a series of speakers and selects the speaker who is most likely to be described, serving the same purpose as the random listener in the general derivative procedure described in the Introduction. We also construct a verbatim speaker S0 that isolates a speaker and outputs a description, the verbatim speaker being used for efficient inferences over the space of possible descriptions as described in Section 3.4. L0 is, essentially, a retrievable model, and S0 is a neural description model. Both base models are probabilistic: L0 produces a distribution over speaker decisions, and S0 produces a distribution over strings. They are represented with gray backgrounds in Figure 3.letter r."}, {"heading": "3.4 Reasoning model", "text": "As described in the introduction, the general derivative approach to pragmatism constructs a basic listener and then selects a description that allows the listener to behave correctly. As the assumption that the listener will behave deterministically is often bad, it is common for such derivative approaches to implement probabilistic policy decisions and maximize the likelihood of behaving correctly. L0, the neural verbatim listener described in the preceding section, is such a likely listener. In the face of a target i and a pair of speakers r1 and r2, it is natural to describe the behavior of an argumentative speaker as simple: max d pL0 (i, r1, r2). At first glance, the only thing that is necessary to implement this model is the representation of the literary listener himself. If the amount of possible utterances comes from a fixed vocabulary (Vogel et al al al., 2013) or a grammar small enough to be exhaustive."}, {"heading": "4 Evaluation", "text": "We evaluate our model on the reference game RG, which is described in the introduction. Specifically, we construct cases of RG using the Abstract Scenes Dataset introduced by Zitnick and Parikh (2013). Examples of abstract scenes are shown in Figure 1 and Figure 6. The dataset contains simple images constructed by humans and described in natural language. Scene representations are available both as rendered images and as features that contain the identity and location of each object; as mentioned in Section 3.1, we use this feature to produce our reference representation for (r), which was previously used for a variety of speech and visual tasks (e.g. Ortiz et al. (2015), Zitnick et al.) It consists of 10,020 scenes, each commented with up to 6 image differences. Abstract scenes are attractive for several reasons."}, {"heading": "4.1 How good are the base models?", "text": "In order to measure the performance of the basic models, we collect 10 samples for a subset of 100 pairs (r1, j, r2, j) in the Dev-All set. We collect human fluctuation and accuracy assessments for each of the 1000 samples. This allows us to perform a posthoc search for possible values of the mixing parameter \u03bb: For a range of \u03bb, we calculate the average accuracy and fluctuation of the sample with the highest score. By varying \u03bb, we can detect the trade-off between accuracy and fluctuation resulting from the interpolation between listener and speaker model - the setting \u03bb = 0 gives samples from pL0, and \u03bb = 1 gives samples from pS0.Figure 4 shows the resulting accuracy and fluctuation for different values of \u03bb. It is evident that relying solely on the listener gives the highest accuracy, but considerably degraded fluidity."}, {"heading": "4.2 How many samples are needed?", "text": "Next, we turn to the computational efficiency of the reasoning model. As with all sample-based conclusions, the number of samples to be drawn from the proposal is of crucial interest - if too many samples are required, the model will be too slow to be used in practice. After specifying \u03bb = 0.02 in the previous section, we measure the accuracy for versions of the reasoning model that draw 1, 10, 100 and 1000 samples. Results are shown in Table 1."}, {"heading": "4.3 Is reasoning necessary?", "text": "To investigate this, we constructed a \"compiled\" loudspeaker model as follows: In view of reference candidates r1 and r2 and target t, this model creates embedding e1 and e2, concatenates them to a \"contrast embedding\" [et, e \u2212 t], and then feeds this entire embedding into a string decoder module. Like S0, this model generates labels without the need for discriminatory rescoring; unlike S0, the contrast brick embedding means that this model can in principle learn to generate pragmatic captions if it has access to pragmatic training data. As there is no such training data, we train the compiled model using captions that are sampled by the arguing loudspeaker itself. This model is evaluated in Table 2. While the distribution of values is quite different than the results of this model are significantly smaller (significant differences compared to the results of S2)."}, {"heading": "4.4 Final evaluation", "text": "Based on the following sections, we stick to \u03bb = 0.02 and use 100 samples to generate predictions. We evaluate the test set and compare this Reasoning Model S1 with two baselines: Literal, a caption model that is normally trained on abstract scene captions (which is equivalent to our L0), and Contrastive, a model that trains with a soft contrast lens and was previously used to generate visual reference expressions (Mao et al., 2015). The results are in Table 3. Our argumentation model significantly exceeds both the literal baseline and previous work, achieving an improvement of 17% for all pairs and 15% for hard pairs. Figures 6 and 7 show different representative descriptions from the model."}, {"heading": "5 Conclusion", "text": "Our approach is based on a pair of simple basic neural models, a listener and a speaker, and a high-level model that bases its findings on pragmatic descriptions. In an evaluation of a standard reference term, the descriptions of our model significantly more often led to correct behavior in the human listener than existing foundations. Generally, for existing derivative approaches to pragmatics, much of the behavior of the system required manual engineering, and more generally for direct approaches (and neural networks in particular), training is only possible when supervision was available for the precise target task. By synthesizing these two approaches, we address both problems and obtain pragmatic behavior without domain knowledge and without targeted training data. We believe that this general strategy of reasoning is available to obtain novel contextual behavior from neural deciphering models could be applied much more broadly."}, {"heading": "Acknowledgments", "text": "We thank Lisa Anne Hendricks and Marcus Rohrbach for useful discussions about this work and Nvidia for a hardware scholarship. YES is supported by a National Science Foundation graduate scholarship."}], "references": [{"title": "Deep compositional question answering with neural module networks", "author": ["Jacob Andreas", "Marcus Rohrbach", "Trevor Darrell", "Dan Klein."], "venue": "arXiv:1511.02799.", "citeRegEx": "Andreas et al\\.,? 2015", "shortCiteRegEx": "Andreas et al\\.", "year": 2015}, {"title": "Long-term recurrent convolutional networks for visual recognition and description", "author": ["Jeffrey Donahue", "Lisa Anne Hendricks", "Sergio Guadarrama", "Marcus Rohrbach", "Subhashini Venugopalan", "Kate Saenko", "Trevor Darrell."], "venue": "Proceedings of the Confer-", "citeRegEx": "Donahue et al\\.,? 2015", "shortCiteRegEx": "Donahue et al\\.", "year": 2015}, {"title": "Learning distributions over logical forms for referring expression generation", "author": ["Nicholas FitzGerald", "Yoav Artzi", "Luke Zettlemoyer."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "FitzGerald et al\\.,? 2013", "shortCiteRegEx": "FitzGerald et al\\.", "year": 2013}, {"title": "Informative communication in word production and word learning", "author": ["Michael C Frank", "Noah D Goodman", "Peter Lai", "Joshua B Tenenbaum."], "venue": "Proceedings of the 31st annual conference of the cognitive science society, pages 1228\u20131233.", "citeRegEx": "Frank et al\\.,? 2009", "shortCiteRegEx": "Frank et al\\.", "year": 2009}, {"title": "A game-theoretic approach to generating spatial descriptions", "author": ["Dave Golland", "Percy Liang", "Dan Klein."], "venue": "Proceedings of the 2010 conference on Empirical Methods in Natural Language Processing, pages 410\u2013419. Association for Computational", "citeRegEx": "Golland et al\\.,? 2010", "shortCiteRegEx": "Golland et al\\.", "year": 2010}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio."], "venue": "Advances in Neural Information Processing Systems, pages 2672\u20132680.", "citeRegEx": "Goodfellow et al\\.,? 2014a", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Explaining and harnessing adversarial examples", "author": ["Ian Goodfellow", "Jonathon Shlens", "Christian Szegedy."], "venue": "arXiv preprint arXiv:1412.6572.", "citeRegEx": "Goodfellow et al\\.,? 2014b", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Referitgame: Referring to objects in photographs of natural scenes", "author": ["Sahar Kazemzadeh", "Vicente Ordonez", "Mark Matten", "Tamara L Berg."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 787\u2013798.", "citeRegEx": "Kazemzadeh et al\\.,? 2014", "shortCiteRegEx": "Kazemzadeh et al\\.", "year": 2014}, {"title": "Generation and comprehension of unambiguous object descriptions", "author": ["Junhua Mao", "Jonathan Huang", "Alexander Toshev", "Oana Camburu", "Alan Yuille", "Kevin Murphy."], "venue": "arXiv preprint arXiv:1511.02283.", "citeRegEx": "Mao et al\\.,? 2015", "shortCiteRegEx": "Mao et al\\.", "year": 2015}, {"title": "Learning in the rational speech acts model", "author": ["Will Monroe", "Christopher Potts."], "venue": "Proceedings of 20th Amsterdam Colloquium, Amsterdam, December. ILLC.", "citeRegEx": "Monroe and Potts.,? 2015", "shortCiteRegEx": "Monroe and Potts.", "year": 2015}, {"title": "Learning to interpret and describe abstract scenes", "author": ["Luis Gilberto Mateos Ortiz", "Clemens Wolff", "Mirella Lapata."], "venue": "Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Ortiz et al\\.,? 2015", "shortCiteRegEx": "Ortiz et al\\.", "year": 2015}, {"title": "Contrastive estimation: Training log-linear models on unlabeled data", "author": ["Noah A. Smith", "Jason Eisner."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics.", "citeRegEx": "Smith and Eisner.,? 2005", "shortCiteRegEx": "Smith and Eisner.", "year": 2005}, {"title": "Learning and using language via recursive pragmatic reasoning about other agents", "author": ["Nathaniel J Smith", "Noah Goodman", "Michael Frank."], "venue": "Advances in Neural Information Processing Systems, pages 3039\u20133047.", "citeRegEx": "Smith et al\\.,? 2013", "shortCiteRegEx": "Smith et al\\.", "year": 2013}, {"title": "Grounded compositional semantics for finding and describing images with sentences", "author": ["Richard Socher", "Andrej Karpathy", "Quoc V Le", "Christopher D Manning", "Andrew Y Ng."], "venue": "Transactions of the Association for Computational Linguistics,", "citeRegEx": "Socher et al\\.,? 2014", "shortCiteRegEx": "Socher et al\\.", "year": 2014}, {"title": "Emergence of Gricean maxims from multi-agent decision theory", "author": ["Adam Vogel", "Max Bodoia", "Christopher Potts", "Daniel Jurafsky."], "venue": "Proceedings of the Human Language Technology Conference of the North American Chapter of the Asso-", "citeRegEx": "Vogel et al\\.,? 2013", "shortCiteRegEx": "Vogel et al\\.", "year": 2013}, {"title": "Show, attend and tell: neural image caption generation with visual attention", "author": ["Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Aaron Courville", "Ruslan Salakhutdinov", "Richard Zemel", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1502.03044.", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Bringing semantics into focus using visual abstraction", "author": ["C Zitnick", "Devi Parikh."], "venue": "Proceedings of the Conference on Computer Vision and Pattern Recognition, pages 3009\u20133016.", "citeRegEx": "Zitnick and Parikh.,? 2013", "shortCiteRegEx": "Zitnick and Parikh.", "year": 2013}, {"title": "Adopting abstract images for semantic scene understanding", "author": ["C Lawrence Zitnick", "Ramakrishna Vedantam", "Devi Parikh"], "venue": null, "citeRegEx": "Zitnick et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zitnick et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 15, "context": "Independent of the application to RG, our model also resembles the suite of neural image captioning models that have been a popular subject of recent study (Xu et al., 2015).", "startOffset": 156, "endOffset": 173}, {"referenceID": 2, "context": "Direct pragmatics As an example of the direct approach mentioned in the introduction, FitzGerald et al. (2013) collect a set of human-generated referring expressions about abstract representations of sets of colored blocks.", "startOffset": 86, "endOffset": 111}, {"referenceID": 2, "context": "Direct pragmatics As an example of the direct approach mentioned in the introduction, FitzGerald et al. (2013) collect a set of human-generated referring expressions about abstract representations of sets of colored blocks. Given a set of blocks to describe, their model directly learns a maximum-entropy distribution over the set of logical expressions whose denotation is the target set. Other research, focused on direct referring expression generation from a computer vision perspective, includes that of Mao et al. (2015) and Kazemzadeh et al.", "startOffset": 86, "endOffset": 527}, {"referenceID": 2, "context": "Direct pragmatics As an example of the direct approach mentioned in the introduction, FitzGerald et al. (2013) collect a set of human-generated referring expressions about abstract representations of sets of colored blocks. Given a set of blocks to describe, their model directly learns a maximum-entropy distribution over the set of logical expressions whose denotation is the target set. Other research, focused on direct referring expression generation from a computer vision perspective, includes that of Mao et al. (2015) and Kazemzadeh et al. (2014).", "startOffset": 86, "endOffset": 556}, {"referenceID": 3, "context": "Experiments (Frank et al., 2009) show that this model explains human behavior well, but both computational and representational issues restrict its application to very simple reference games.", "startOffset": 12, "endOffset": 32}, {"referenceID": 11, "context": "Derived pragmatics The derived approach is exemplified by the work of Smith et al. (2013). This work describes a series of nested Bayesian models, in which intelligent listeners reason about the behavior of reflexive speakers, and even higher-order speakers reason about these listeners.", "startOffset": 70, "endOffset": 90}, {"referenceID": 11, "context": "Other work in this family includes that of Vogel et al. (2013), Golland et al.", "startOffset": 43, "endOffset": 63}, {"referenceID": 4, "context": "(2013), Golland et al. (2010), and Monroe and Potts (2015).", "startOffset": 8, "endOffset": 30}, {"referenceID": 4, "context": "(2013), Golland et al. (2010), and Monroe and Potts (2015). These approaches couple template-driven language generation with gametheoretic reasoning frameworks to produce contextually appropriate language.", "startOffset": 8, "endOffset": 59}, {"referenceID": 4, "context": "(2013), Golland et al. (2010), and Monroe and Potts (2015). These approaches couple template-driven language generation with gametheoretic reasoning frameworks to produce contextually appropriate language. While somewhat more expressive than the models of Smith et al. (2013), they still require both domain-specific engineering, controlled world representations, and pragmatically annotated training data.", "startOffset": 8, "endOffset": 276}, {"referenceID": 13, "context": "textual description (Socher et al., 2014), and neural conditional language models, which take a content representation and emit a sequence of tokens (Donahue et al.", "startOffset": 20, "endOffset": 41}, {"referenceID": 1, "context": ", 2014), and neural conditional language models, which take a content representation and emit a sequence of tokens (Donahue et al., 2015).", "startOffset": 115, "endOffset": 137}, {"referenceID": 5, "context": "While not trained end-to-end, our approach can also be viewed as a cooperative analog of the \u201cgenerative adversarial networks\u201d used for image generation (Goodfellow et al., 2014a).", "startOffset": 153, "endOffset": 179}, {"referenceID": 0, "context": "Reasoning with neural networks A general framework for constructing task-specific neural networks and composing them to produce novel behavior was explored in the context of visual question answering by Andreas et al. (2015). The current work can be thought of as a generalization of that approach, in which the high-level model actively reasons about the output of low-level modules, rather than directly composing them.", "startOffset": 203, "endOffset": 225}, {"referenceID": 4, "context": "This uniform random choice is important: it ensures that our approach is applicable even when there is not a naturally-occurring source of target\u2013 distractor pairs, as previous work (Golland et al., 2010; Monroe and Potts, 2015) has required.", "startOffset": 182, "endOffset": 228}, {"referenceID": 9, "context": "This uniform random choice is important: it ensures that our approach is applicable even when there is not a naturally-occurring source of target\u2013 distractor pairs, as previous work (Golland et al., 2010; Monroe and Potts, 2015) has required.", "startOffset": 182, "endOffset": 228}, {"referenceID": 4, "context": "This uniform random choice is important: it ensures that our approach is applicable even when there is not a naturally-occurring source of target\u2013 distractor pairs, as previous work (Golland et al., 2010; Monroe and Potts, 2015) has required. Note that this objective can also be viewed as the contrastive loss described by Smith and Eisner (2005), where it serves as an approximation to the likelihood objective that encourages L0 to prefer ri to every other possible referent simultaneously.", "startOffset": 183, "endOffset": 348}, {"referenceID": 4, "context": "These base models are intended to be the minimal learned equivalents of the hand-engineered speakers and hand-written grammars employed in previous derived approaches (Golland et al., 2010).", "startOffset": 167, "endOffset": 189}, {"referenceID": 1, "context": "Past work amply demonstrates that neural conditional language models are powerful enough to generate fluent and accurate (though not necessarily pragmatic) descriptions of images or structured representations (Donahue et al., 2015).", "startOffset": 209, "endOffset": 231}, {"referenceID": 14, "context": "When the set of possible utterances comes from a fixed vocabulary (Vogel et al., 2013) or a grammar small enough to exhaustively enumerate (Smith et al.", "startOffset": 66, "endOffset": 86}, {"referenceID": 12, "context": ", 2013) or a grammar small enough to exhaustively enumerate (Smith et al., 2013) the operation maxd in Equation 8 is practical.", "startOffset": 60, "endOffset": 80}, {"referenceID": 6, "context": "listener\u2019s judgments directly, the speaker model might accidentally discover the kinds of pathological optima that neural classification models are known to exhibit (Goodfellow et al., 2014b)\u2014in this case, sentences that cause exactly the right response from L0, but no longer bear any resemblance to human language use.", "startOffset": 165, "endOffset": 191}, {"referenceID": 15, "context": "In particular, we construct instances of RG using the Abstract Scenes Dataset introduced by Zitnick and Parikh (2013). Example abstract scenes are shown in Figure 1 and Figure 6.", "startOffset": 92, "endOffset": 118}, {"referenceID": 10, "context": "Ortiz et al. (2015), Zitnick et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 10, "context": "Ortiz et al. (2015), Zitnick et al. (2014)).", "startOffset": 0, "endOffset": 43}, {"referenceID": 8, "context": "\u201cContrastive\u201d is a reimplementation of the approach of Mao et al. (2015). \u201cReasoning\u201d is the reasoning model S1 from this paper.", "startOffset": 55, "endOffset": 73}, {"referenceID": 8, "context": "We evaluate on the test set, comparing this Reasoning model S1 to two baselines: Literal, an image captioning model trained normally on the abstract scene captions (corresponding to our L0), and Contrastive, a model trained with a soft contrastive objective, and previously used for visual referring expression generation (Mao et al., 2015).", "startOffset": 322, "endOffset": 340}], "year": 2017, "abstractText": "We present a model for pragmatically describing scenes, in which contrastive behavior results from a combination of inference-driven pragmatics and learned semantics. Like previous learned approaches to language generation, our model uses a simple feature-driven architecture (here a pair of neural \u201clistener\u201d and \u201cspeaker\u201d models) to ground language in the world. Like inference-driven approaches to pragmatics, our model actively reasons about listener behavior when selecting utterances. For training, our approach requires only ordinary captions, annotated without demonstration of the pragmatic behavior the model ultimately exhibits. In human evaluations on a referring expression game, our approach succeeds 81% of the time, compared to a 64% success rate using existing techniques.", "creator": "LaTeX with hyperref package"}}}