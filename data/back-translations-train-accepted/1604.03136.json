{"id": "1604.03136", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Apr-2016", "title": "Shallow Parsing Pipeline for Hindi-English Code-Mixed Social Media Text", "abstract": "In this study, the problem of shallow parsing of Hindi-English code-mixed social media text (CSMT) has been addressed. We have annotated the data, developed a language identifier, a normalizer, a part-of-speech tagger and a shallow parser. To the best of our knowledge, we are the first to attempt shallow parsing on CSMT. The pipeline developed has been made available to the research community with the goal of enabling better text analysis of Hindi English CSMT. The pipeline is accessible at", "histories": [["v1", "Mon, 11 Apr 2016 20:24:52 GMT  (135kb,D)", "http://arxiv.org/abs/1604.03136v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["arnav sharma", "sakshi gupta", "raveesh motlani", "piyush bansal", "manish srivastava", "radhika mamidi", "dipti m sharma"], "accepted": true, "id": "1604.03136"}, "pdf": {"name": "1604.03136.pdf", "metadata": {"source": "META", "title": "Shallow Parsing Pipeline for Hindi-English Code-Mixed Social Media Text", "authors": ["Arnav Sharma", "Sakshi Gupta", "Piyush Bansal", "Manish Shrivastava", "Radhika Mamidi", "Dipti M. Sharma"], "emails": ["piyush.bansal}@research.iiit.ac.in", "dipti}@iiit.ac.in"], "sections": [{"heading": null, "text": "In this study, the problem of shallow parsing of Hindi-English code mixed social media text (CSMT) was addressed. We commented on the data, developed a speech recognition, a normalizer, a part-of-speech tagger and a shallow parser. To the best of our knowledge, we are the first to try a shallow parser on CSMT. The developed pipeline has been made available to the research community with the aim of enabling better text analysis of Hindi-English CSMT."}, {"heading": "1 Introduction", "text": "Multilingual speakers tend to use code mixing and code switching in their language usage on social media platforms. Code mixing is the embedding of linguistic entities such as phrases, words, or morphemes of a language into an utterance of another language, whereas code switching refers to the simultaneous occurrence of language extracts from two different grammatical systems (Gumperz., 1982). Here, we use code mixing to refer to both scenarios. Hindi-English bilingual speakers produce enormous amounts of CSMT. Vyas et al. (2014) found that the complexity of analyzing CSMT stems from non-compliance with formal grammar, spelling variations, the lack of annotated data, the inherent conversational character of the text, and, of course, code mixing. Therefore, there is a need to use datasets and Natural1http: / / bitc.ly / Procapser-Mapping as the direction for this CSMapping Language."}, {"heading": "2 Background", "text": "Bali et al. (2014) collected data from Facebook generated by bilingual English-Hindi users who showed significant levels of code mixing during the analysis. Barman et al. (2014) examined word identification at the Bengali-Hindi CSMT level. They commented on a corpus of more than 180,000 tokens and achieved an accuracy of 95.76% using statistical models with monolingual dictionaries. Solorio and Liu (2008) experimented with POS marking for English-Spanish coded discourses by using existing markers for both languages and achieved an accuracy of 93.48%. However, the data used was transcribed manually and thus lacked the problems added by CSMT. Vyas et al (2014) formalized the problem, reported challenges in processing Hindi-English CSMT and conducted initial experiments on marking POS markings by POS."}, {"heading": "3 Data Preparation", "text": "CSMT was derived from social media posts shared for Subtask 1 of the FIRE-2014 Shared Task on Transsliterated Search. Existing annotations of the FIRE data set were removed, posts were divided into sentences, and 858 of these sentences were randomly selected for manual annotations. Table 1 and Table 2 show the distribution of the data set at the sentence or token level. 63.33% of the tokens in mixed sentences are Hindi. Based on the distribution, Hindi can be assumed to be the matrix language in most of the mixed sentences (Azuma, 1993; Myers-Scotton, 1997)."}, {"heading": "3.1 Dataset examples", "text": "1. hy... try fr sm gov job jiske forms niklte h... Gloss: He... try for some government job which forms give out... translation: He... try for some government job which gives forms... 2. to tum divya bharti mandir marriage kendra ko donate karna Gloss: Also you divya bharti temple marriage center to donate doTranslation: So you donate to divya bharti temple marriage centerThe record consists of sentences similar to those in Example 1 and 2. Example 1 shows code witching how the language switches from English to Hindi, while Example 2 shows code mixing, as some English words are embedded in a Hindi utterance. Spelling variations (sm - some, gov - government), ambiguous words (To - So in Hindi or To in English) and non-compliance with formal grammar (out place ellipsis -..., no or misplaced pointation) are some of the challenges obvious in the examples above."}, {"heading": "3.2 Annotation", "text": "The term \"rest\" was given to symbols, emoticons, punctuations, named units, acronyms, foreign words and words with sublexical code mixtures such as chapattis (gloss: chapatti - bread), which is a Hindu word (chapatti - bread) that follows the English morphology (plural marker -s). Normalization: Words with the linguistic tag \"hi\" in Roman script were given their standard form in the native script of Hindi, Devanagari and Potagari. Similarly, words with the linguistic tag \"en\" and \"annator\" were given their standard spelling."}, {"heading": "4 Shallow Parsing Pipeline", "text": "Our flat parsing pipeline consists of four main modules, as shown in Figure 1. These modules are, in order of use, Language Identification, Normalization, POS Tagger, and Shallow Parser. Our pipeline inputs a raw utterance in Roman script on which each module runs sequentially. Twokenizer2 (Owoputi et al., 2013) which2http: / / www.ark.cs.cmu.edu / TweetNLP / works well in Hindi-English CSMT (Jamatia et al., 2015) was used to tokenize the utterance into words. The Language Identification Identification Identification Module assigns a language character to each word."}, {"heading": "4.1 Language Identification", "text": "While document-level language identification is an established task (McNamee, 2005), the identification of language in social media posts poses certain challenges associated with it. Similar to (Barman et al., 2014), we conducted two experiments in which language identification was treated as a classification problem of the three classes (\"hi ',\" en', \"rest\").The aus - BNC: normalized frequency of the word in the British National Corpus (BNC) 3. LEXNORM: binary trait indicating the presence of the word in the lexical normalization dataset of Han et al. (2011).HINDI DICT: binary trait indicating the presence of the word in the British National Corpus (BNC)."}, {"heading": "4.2 Normalization", "text": "To fix this, a normalization module had to be created that performs language-specific transformations to get the correct spelling for a given word. Two language-specific normalizers, one for Hindi and one for English / Rest, each had two subnormers as described below. Both subnormers generated candidates, which then, as later in this subsection.1 Noisy Channel Framework: A generative model was trained to produce noisy (unnormalized) tokens from a given normalized word."}, {"heading": "4.3 Part-Of-Speech Tagging", "text": "The feature set consists of - Baseline: Word based features - affixes, context and the word itself. LANG: Language label of the token. NORM: Normalized lexical features. TPOS: Output of Twitter POS tagger (Owoputi et al., 2013). HPOS: Output of IIIT's Hindi POS tagger6. COMBINED: HPOS for Hindi words and TPOS for English and Rest. The results of POS Tagger can be found in Table 4.4https: / / github.com / libindic / spellchecker5http: / / aspell.net / 6http: / / ltrc.iiit.ac.in / showfile.php? filename = downloads / parshalphserp _."}, {"heading": "4.4 Shallow Parsing", "text": "A chunk consists of two aspects - the chunk boundary and the chunk label. Shallow parsing was modeled as three separate sequence labeling problems: Label, Boundary, and Combined, for which each CRF model was trained. The feature set consisted of - POS: POS tag of the word. POS context: POS tags in the context window of length 5, i.e. the two previous tags, the current day, and the next two tags. POS LEX: A feature consisting of the concatenation of POS and LEX. NORMLEX: The word in its normalized form. The results of this module are shown in Table 5."}, {"heading": "5 Pipeline Results", "text": "The most powerful model was selected by each module and used in the pipeline. Table 6 shows the step-by-step accuracy of the pipeline, calculated using 10-fold cross-validation."}, {"heading": "6 Conclusion and Future Work", "text": "In this study, we have developed a system for HindiEnglish CSMT data that can identify the language of words, normalize them to their standard forms, assign them their POS tag, and segment them into chunks. We have released the system. In the future, we intend to create further commented code-mixed social media data. We also want to improve the difficult problem of normalizing monolingual Hindi social sentences. We would also further expand our pipeline and build a full parser that has numerous applications in NLP."}], "references": [{"title": "Parsing by chunks", "author": ["Steven P Abney."], "venue": "Springer.", "citeRegEx": "Abney.,? 1992", "shortCiteRegEx": "Abney.", "year": 1992}, {"title": "The frame-content hypothesis in speech production: Evidence from intrasentential code switching", "author": ["Shoji Azuma."], "venue": "Linguistics, 31(6):1071\u20131094.", "citeRegEx": "Azuma.,? 1993", "shortCiteRegEx": "Azuma.", "year": 1993}, {"title": "i am borrowing ya mixing ? an analysis of english-hindi code mixing in facebook", "author": ["Kalika Bali", "Jatin Sharma", "Monojit Choudhury", "Yogarshi Vyas."], "venue": "Proceedings of the First Workshop on Computational Approaches to Code Switching, pages 116\u2013126, Doha,", "citeRegEx": "Bali et al\\.,? 2014", "shortCiteRegEx": "Bali et al\\.", "year": 2014}, {"title": "Code mixing: A challenge for language identification in the language of social media", "author": ["Utsab Barman", "Amitava Das", "Joachim Wagner", "Jennifer Foster."], "venue": "EMNLP 2014, page 13.", "citeRegEx": "Barman et al\\.,? 2014", "shortCiteRegEx": "Barman et al\\.", "year": 2014}, {"title": "Anncorra: Annotating corpora guidelines for pos and chunk annotation for indian languages", "author": ["Akshar Bharati", "Rajeev Sangal", "Dipti Misra Sharma", "Lakshmi Bai."], "venue": "LTRC-TR31.", "citeRegEx": "Bharati et al\\.,? 2006", "shortCiteRegEx": "Bharati et al\\.", "year": 2006}, {"title": "The leipzig corpora collection-monolingual corpora of standard size", "author": ["Chris Biemann", "Gerhard Heyer", "Uwe Quasthoff", "Matthias Richter."], "venue": "Proceedings of Corpus Linguistic.", "citeRegEx": "Biemann et al\\.,? 2007", "shortCiteRegEx": "Biemann et al\\.", "year": 2007}, {"title": "A coefficient of agreement for nominal scales", "author": ["Jacob Cohen."], "venue": "Educational and Psychological Measurement, 134:3746.", "citeRegEx": "Cohen.,? 1960", "shortCiteRegEx": "Cohen.", "year": 1960}, {"title": "Part-of-speech tagging for twitter: Annotation, features, and experiments", "author": ["Kevin Gimpel", "Nathan Schneider", "Brendan O\u2019Connor", "Dipanjan Das", "Daniel Mills", "Jacob Eisenstein", "Michael Heilman", "Dani Yogatama", "Jeffrey Flanigan", "Noah A Smith"], "venue": null, "citeRegEx": "Gimpel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gimpel et al\\.", "year": 2011}, {"title": "Discourse Strategies", "author": ["John J. Gumperz."], "venue": "Oxford University Press.", "citeRegEx": "Gumperz.,? 1982", "shortCiteRegEx": "Gumperz.", "year": 1982}, {"title": "Mining hindi-english transliteration pairs from online hindi lyrics", "author": ["Kanika Gupta", "Monojit Choudhury", "Kalika Bali."], "venue": "LREC, pages 2459\u20132465.", "citeRegEx": "Gupta et al\\.,? 2012", "shortCiteRegEx": "Gupta et al\\.", "year": 2012}, {"title": "Lexical normalisation of short text messages: Makn sens a# twitter", "author": ["Bo Han", "Timothy Baldwin."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Lan-", "citeRegEx": "Han and Baldwin.,? 2011", "shortCiteRegEx": "Han and Baldwin.", "year": 2011}, {"title": "Automatically constructing a normalisation dictionary for microblogs", "author": ["Bo Han", "Paul Cook", "Timothy Baldwin."], "venue": "Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning,", "citeRegEx": "Han et al\\.,? 2012", "shortCiteRegEx": "Han et al\\.", "year": 2012}, {"title": "Co-occurrence and transformation in linguistic structure", "author": ["Zellig S Harris."], "venue": "Language, pages 283\u2013340.", "citeRegEx": "Harris.,? 1957", "shortCiteRegEx": "Harris.", "year": 1957}, {"title": "Part-of-speech tagging for code-mixed englishhindi twitter and facebook chat messages", "author": ["Anupam Jamatia", "Bj\u00f6rn Gamb\u00e4ck", "Amitava Das."], "venue": "Proceedings of Recent Advances in Natural Language Processing, page 239.", "citeRegEx": "Jamatia et al\\.,? 2015", "shortCiteRegEx": "Jamatia et al\\.", "year": 2015}, {"title": "Exploring evidence for shallow parsing", "author": ["Xin Li", "Dan Roth."], "venue": "Proceedings of the 2001 workshop on Computational Natural Language Learning-Volume 7, page 6. Association for Computational Linguistics.", "citeRegEx": "Li and Roth.,? 2001", "shortCiteRegEx": "Li and Roth.", "year": 2001}, {"title": "A broadcoverage normalization system for social media language", "author": ["Fei Liu", "Fuliang Weng", "Xiao Jiang."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 1035\u20131044. Association for", "citeRegEx": "Liu et al\\.,? 2012", "shortCiteRegEx": "Liu et al\\.", "year": 2012}, {"title": "Language identification: a solved problem suitable for undergraduate instruction", "author": ["Paul McNamee."], "venue": "Journal of Computing Sciences in Colleges, 20(3):94\u2013101.", "citeRegEx": "McNamee.,? 2005", "shortCiteRegEx": "McNamee.", "year": 2005}, {"title": "Duelling languages: Grammatical structure in codeswitching", "author": ["Carol Myers-Scotton."], "venue": "Oxford University Press.", "citeRegEx": "Myers.Scotton.,? 1997", "shortCiteRegEx": "Myers.Scotton.", "year": 1997}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Franz Josef Och", "Hermann Ney."], "venue": "Computational Linguistics, 29(1):19\u201351.", "citeRegEx": "Och and Ney.,? 2003", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "Improved part-of-speech tagging for online conversational text with word", "author": ["Olutobi Owoputi", "Brendan O\u2019Connor", "Chris Dyer", "Kevin Gimpel", "Nathan Schneider", "Noah A Smith"], "venue": null, "citeRegEx": "Owoputi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Owoputi et al\\.", "year": 2013}, {"title": "A universal part-of-speech tagset", "author": ["Slav Petrov", "Dipanjan Das", "Ryan McDonald."], "venue": "arXiv preprint arXiv:1104.2086.", "citeRegEx": "Petrov et al\\.,? 2011", "shortCiteRegEx": "Petrov et al\\.", "year": 2011}, {"title": "Part-of-speech tagging for english-spanish code-switched text", "author": ["Thamar Solorio", "Yang Liu."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1051\u20131060. Association for Computational Linguistics.", "citeRegEx": "Solorio and Liu.,? 2008", "shortCiteRegEx": "Solorio and Liu.", "year": 2008}, {"title": "Pos tagging of english-hindi code-mixed social media content", "author": ["Yogarshi Vyas", "Spandana Gella", "Jatin Sharma", "Kalika Bali", "Monojit Choudhury."], "venue": "Proceedings of the First Workshop on Codeswitching, EMNLP.", "citeRegEx": "Vyas et al\\.,? 2014", "shortCiteRegEx": "Vyas et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 8, "context": "Code-Mixing is the embedding of linguistic units such as phrases, words or morphemes of one language into an utterance of another language whereas code-switching refers to the co-occurrence of speech extracts belonging to two different grammatical systems (Gumperz., 1982).", "startOffset": 256, "endOffset": 272}, {"referenceID": 22, "context": "Vyas et al. (2014) noted that the complexity in analyzing CSMT stems from nonadherence to a formal grammar, spelling variations, lack of annotated data, inherent conversational nature of the text and of course, code-mixing.", "startOffset": 0, "endOffset": 19}, {"referenceID": 22, "context": "Thus, language identification and normalization are critical for POS tagging (Vyas et al., 2014), which in turn is critical further down the pipeline for shallow parsing as evident in Table 5.", "startOffset": 77, "endOffset": 96}, {"referenceID": 7, "context": "gual social media text context, Gimpel et al. (2011) built a POS tagger for English tweets and achieved an accuracy of 89.", "startOffset": 32, "endOffset": 53}, {"referenceID": 7, "context": "gual social media text context, Gimpel et al. (2011) built a POS tagger for English tweets and achieved an accuracy of 89.95% on 1,827 annotated tweets. Owoputi et al. (2013) further improved this POS tagger, increasing the accuracy to 93%.", "startOffset": 32, "endOffset": 175}, {"referenceID": 1, "context": "Based on the distribution, it is reasonable to assume that Hindi is the matrix language (Azuma, 1993; Myers-Scotton, 1997) in most of the code-mixed sentences.", "startOffset": 88, "endOffset": 122}, {"referenceID": 17, "context": "Based on the distribution, it is reasonable to assume that Hindi is the matrix language (Azuma, 1993; Myers-Scotton, 1997) in most of the code-mixed sentences.", "startOffset": 88, "endOffset": 122}, {"referenceID": 20, "context": "Parts-of-Speech (POS): Universal POS tagset (Petrov et al., 2011) was used to label the POS of each word as this tagset is applicable to both English and Hindi words.", "startOffset": 44, "endOffset": 65}, {"referenceID": 4, "context": "The chunk label tagset is a coarser version of AnnCorra tagset (Bharati et al., 2006).", "startOffset": 63, "endOffset": 85}, {"referenceID": 6, "context": "The inter-annotator agreement calculated using Cohen\u2019s \u03ba (Cohen, 1960) came out to be 0.", "startOffset": 57, "endOffset": 70}, {"referenceID": 0, "context": "Shallow parsing is the task of identifying and segmenting text into syntactically correlated word groups (Abney, 1992; Harris, 1957).", "startOffset": 105, "endOffset": 132}, {"referenceID": 12, "context": "Shallow parsing is the task of identifying and segmenting text into syntactically correlated word groups (Abney, 1992; Harris, 1957).", "startOffset": 105, "endOffset": 132}, {"referenceID": 14, "context": "Shallow parsing is a viable alternative to full parsing as shown by (Li and Roth, 2001).", "startOffset": 68, "endOffset": 87}, {"referenceID": 19, "context": "Twokenizer2 (Owoputi et al., 2013) which", "startOffset": 12, "endOffset": 34}, {"referenceID": 13, "context": "performs well on Hindi-English CSMT (Jamatia et al., 2015) was used to tokenize the utterance into words.", "startOffset": 36, "endOffset": 58}, {"referenceID": 16, "context": "While language identification at the document level is a well-established task (McNamee, 2005), identifying language in social media posts has certain challenges associated to it.", "startOffset": 79, "endOffset": 94}, {"referenceID": 3, "context": "Similar to (Barman et al., 2014), we performed two experiments treating language identification as a three class (\u2018hi\u2019, \u2018en\u2019, \u2018rest\u2019) classification problem.", "startOffset": 11, "endOffset": 32}, {"referenceID": 3, "context": "Similar to (Barman et al., 2014), we performed two experiments treating language identification as a three class (\u2018hi\u2019, \u2018en\u2019, \u2018rest\u2019) classification problem. The feature set comprised of BNC: normalized frequency of the word in British National Corpus (BNC)3. LEXNORM: binary feature indicating presence of the word in the lexical normalization dataset released by Han et al. (2011). HINDI DICT: binary feature indicating presence of the word in a dictionary of 30,823 transliterated Hindi words as released by Gupta (2012).", "startOffset": 12, "endOffset": 383}, {"referenceID": 3, "context": "Similar to (Barman et al., 2014), we performed two experiments treating language identification as a three class (\u2018hi\u2019, \u2018en\u2019, \u2018rest\u2019) classification problem. The feature set comprised of BNC: normalized frequency of the word in British National Corpus (BNC)3. LEXNORM: binary feature indicating presence of the word in the lexical normalization dataset released by Han et al. (2011). HINDI DICT: binary feature indicating presence of the word in a dictionary of 30,823 transliterated Hindi words as released by Gupta (2012). NGRAM: word n-grams.", "startOffset": 12, "endOffset": 524}, {"referenceID": 18, "context": "First, we obtained character alignments between noisy Hindi words in Roman script (Hr) to normalized Hindi wordsformat(Hw) using GIZA++ (Och and Ney, 2003) on 30,823 Hindi word pairs of the form (Hw - Hr) (Gupta et al.", "startOffset": 136, "endOffset": 155}, {"referenceID": 9, "context": "First, we obtained character alignments between noisy Hindi words in Roman script (Hr) to normalized Hindi wordsformat(Hw) using GIZA++ (Och and Ney, 2003) on 30,823 Hindi word pairs of the form (Hw - Hr) (Gupta et al., 2012).", "startOffset": 205, "endOffset": 225}, {"referenceID": 5, "context": "Using this model, noisy Hr words were created for Hw words obtained from a dictionary of 1,17,789 Hindi words (Biemann et al., 2007).", "startOffset": 110, "endOffset": 132}, {"referenceID": 11, "context": "A similar approach was used for English text normalization, using the English normalization pairs from (Han et al., 2012) and (Liu et al.", "startOffset": 103, "endOffset": 121}, {"referenceID": 15, "context": ", 2012) and (Liu et al., 2012) for the noisy channel framework, and Aspell5 as the spell-checker.", "startOffset": 12, "endOffset": 30}, {"referenceID": 19, "context": "TPOS: Output of Twitter POS tagger (Owoputi et al., 2013).", "startOffset": 35, "endOffset": 57}], "year": 2016, "abstractText": "In this study, the problem of shallow parsing of Hindi-English code-mixed social media text (CSMT) has been addressed. We have annotated the data, developed a language identifier, a normalizer, a part-of-speech tagger and a shallow parser. To the best of our knowledge, we are the first to attempt shallow parsing on CSMT. The pipeline developed has been made available to the research community with the goal of enabling better text analysis of Hindi English CSMT. The pipeline is accessible at 1.", "creator": "LaTeX with hyperref package"}}}