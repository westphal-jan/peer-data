{"id": "1604.06285", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Apr-2016", "title": "A Novel Approach to Dropped Pronoun Translation", "abstract": "Dropped Pronouns (DP) in which pronouns are frequently dropped in the source language but should be retained in the target language are challenge in machine translation. In response to this problem, we propose a semi-supervised approach to recall possibly missing pronouns in the translation. Firstly, we build training data for DP generation in which the DPs are automatically labelled according to the alignment information from a parallel corpus. Secondly, we build a deep learning-based DP generator for input sentences in decoding when no corresponding references exist. More specifically, the generation is two-phase: (1) DP position detection, which is modeled as a sequential labelling task with recurrent neural networks; and (2) DP prediction, which employs a multilayer perceptron with rich features. Finally, we integrate the above outputs into our translation system to recall missing pronouns by both extracting rules from the DP-labelled training data and translating the DP-generated input sentences. Experimental results show that our approach achieves a significant improvement of 1.58 BLEU points in translation performance with 66% F-score for DP generation accuracy.", "histories": [["v1", "Thu, 21 Apr 2016 12:55:29 GMT  (328kb,D)", "http://arxiv.org/abs/1604.06285v1", "To appear in NAACL2016"]], "COMMENTS": "To appear in NAACL2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["longyue wang", "zhaopeng tu", "xiaojun zhang", "hang li", "andy way", "qun liu"], "accepted": true, "id": "1604.06285"}, "pdf": {"name": "1604.06285.pdf", "metadata": {"source": "CRF", "title": "A Novel Approach to Dropped Pronoun Translation", "authors": ["Longyue Wang", "Zhaopeng Tu", "Xiaojun Zhang", "Hang Li", "Andy Way", "Qun Liu"], "emails": ["qliu}@computing.dcu.ie", "hangli.hl}@huawei.com"], "sections": [{"heading": "1 Introduction", "text": "This year, we are in a position to find a solution in the first phase of the process, which begins in the second half of the twentieth decade and begins in the second half of the twentieth decade in the second half of the twentieth decade."}, {"heading": "2 Methodology", "text": "The architecture of our proposed method is shown in Figure 2, which can be divided into three phases: DP annotation, DP generation and SMT integration."}, {"heading": "2.1 DP Training Corpus Annotation", "text": "In fact, the fact is that most of them are not \"normal\" people, but people who are able to move."}, {"heading": "2.2 DP Generation", "text": "Given the recent success of using deep neural network technologies in natural language processing (Raymond and Riccardi, 2007; Mesnil et al., 2013), we propose a neural network-based DP generator over the DP-inserted corpus (Section 2.1). We first use an RNN to predict DP position, and then train a classifier that uses multilayer perceptrons to achieve our N-best DP results."}, {"heading": "2.2.1 DP detection", "text": "The task of DP position recognition is to label words if pronouns are missing before the words, which can intuitively be considered a sequence identifier problem. We expect the output to consist of a sequence of markups y (1: n) = (y (1), y (2), \u00b7 \u00b7, y (t), \u00b7 \u00b7, y (n), where y (t) is the label of the word w (t). In our task there are two markups L = {NA, DP} (corresponding to non-pro-drop or pro-drop pronouns), i.e. y (t). Word embeddings (Mikolov et al., 2013) the label of the word w (t)."}, {"heading": "2.2.2 DP prediction", "text": "Once the DP position is detected, the next step is to determine which pronoun should be inserted based on this result. Accordingly, we train a 22-class classifier, with each class focusing on a specific Chinese pronoun in Table 1. We select a number of features based on previous work (Xiang et al., 2013; Yang et al., 2015), including lexical, contextual, and syntactic features (as shown in Table 2). We set p as the DP position, S as the window size surrounding p, and X, Y as the window size surrounding the current sentence (which contains one). For features 1-4, we extract words, POS tags, and pronouns by p. For features 5-8, we also consider the pronouns and nouns between X / Y environment sets as a snippet. For features 9 and 10, to model the syntactic relationship, we use the characteristics of the y that combine the node of the tags."}, {"heading": "2.3 Integration into Translation", "text": "The basic SMT system uses the parallel body and input records without inserting / generating DPs. As shown in Figure 2, integration into the SMT system is twofold: DP-inserted translation model (DP-ins. TM) and DP-generated input (DP-gen. Input)."}, {"heading": "2.3.1 DP-inserted TM", "text": "We train an additional translation model on the new parallel corpus, whose source page is inserted with DPs derived from the landing page via the alignment matrix (Section 2.1). We assume that the DP insertion can contribute to better alignment, which can benefit the translation. Then, the entire translation process is based on the enhanced translation model, i.e. with DPs inserted. As for the TM combination, we feed Moses the multiple-phrase tables directly. The gain from the additional TM is mainly based on supplementary information about the recalled DPs from the annotated data."}, {"heading": "2.3.2 DP-generated input", "text": "Another option is to pre-edit the input set by inserting possible DPs into the DP generation model (Section 2.2) so that the DP input (Input ZH + DPs) is translated. Predicted DPs would be explicitly translated into the target language so that the possibly missing pronouns in the translation can be retrieved, making the input sets and DP-inserted TM more consistent in terms of retrieving DPs."}, {"heading": "2.3.3 N-best inputs", "text": "However, the above method has one major disadvantage: it uses only the 1-best prediction result for decoding, potentially resulting in translation errors due to the prevalence of prediction errors. To alleviate this problem, one obvious solution is to offer more alternatives. Recent studies have shown that SMT systems can benefit from extending the annotation pipeline (Liu et al., 2009; Tu et al., 2010; Tu et al., 2011; Liu et al., 2013). In the same vein, we suggest feeding the N-best prediction results to the decoder, which allows the system to choose between several ambiguous hypotheses from the upstream processing so that the best translation can be produced. The general method is to transfer the input with N-best DPs into a network of confusion. In our experiment, each prediction is assigned a weight of 1 / N."}, {"heading": "3 Related Work", "text": "The difference to our task is that ZP contains three steps (namely ZP detection, anaphorizontal determination, and co-reference link), while DP generation contains only the first two steps. Some researchers (Zhao and Ng, 2007; Kong and Zhou, 2013) suggest rich features based on different machine learning methods. For example, Chen and Ng (2013) suggest an SVM classifier that uses 32 features, including lexical, syntactic, and grammatical roles, etc., which are very useful in the ZP task."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Setup", "text": "For the Domain Training Data dialog, we extract about 1M sentence pairs (movie or TV episode subtitles) from two subtitle websites.4 We manually create both development and test data with DP annotation. Note that all sentences their con-3EC contains trace markers, drop pronouns, large PRO, etc., while we focus only on falling pronounces.4 Available at http: / / www.opensubtitles.org and http: / weisheshou.com.textual information at the discourse level that can be used for feature extraction in Section 2.1. detailed statistics are listed in Table 3. As far as the DP Training Corpus is concerned, we annotate the Chinese side of parallel data using the approach described in Section 2.1. There are two different language models for DP annotation (Section 2.1) and translation tasks, one being tracked to the 2.13TB Corpus, the other Web page being tracked during the Collection, etc."}, {"heading": "4.2 Evaluation of DP Generation", "text": "To this end, we follow the strategy of automatically and manually labeling the source pages of development and test data with their landing pages, and the match between automatic labels and manual labels in DP prediction is 94% and 95%, respectively, for development and test data, and 92% and 92%, respectively, for DP generation. This indicates that the automatic annotation strategy is relatively trustworthy. We then measure the accuracy (in words) of our generation models in two phases. \"DP prediction\" shows the performance of our sequence-shortening model based on RNN. We only look at the tag for each word (pro-drop or not pro-drop before the current word), without taking into account the exact pronoun for DPs. \"DP prediction\" shows the performance of the MLP classifier in determining the exact DP based on detection. Thus, we look at both the detected and the predicted pronouns Table 4. \"DP prediction lists the results of the DP generation based on the DP 88%, or DP models, respectively."}, {"heading": "4.3 Evaluation of DP Translation", "text": "In this section, we evaluate end-to-end translation quality by integrating DP results (Section 3.3). Table 5 summarizes the results of translation performance with different sources of DP information. \"Baseline\" uses the original input to feed the DP generation model. \"Oracle\" uses the input with the DPinserted training corpus, while \"DDP gene\" completes the other input sentences with the N generation models. \"Oracle\" uses the input with the manual (\"Manual\") or the automatic (\"Auto\") insertion of DPs by looking at the input sentences with the N generation models. \"We annotate the DPs by reference generation of DP-generated information (\" Oracle \")."}, {"heading": "5 Case Study", "text": "In Figure 4, we show an improved case (case A), an unchanged case (case B) and a worse case (case C) of the translation no- / using DP insertion (i.e., we give (a) the reference sentence and its translation, (c) the reference sentence, and (c) the reference sentence. In Figure A, \"Do you\" in the translation is compensated by adding DP (you) in (B), which gives a better translation than in Figure C, the reference sentence. In Figure A, \"Do you\" in the translation is compensated by adding DP."}, {"heading": "6 Conclusion and Future Work", "text": "Our analysis shows that the insertion of DPs greatly influences translation. Our main findings in this essay are three: \u2022 Bilingual information can help create monolingual models without manually annotated training data; \u2022 Neural network-based models work well without complex feature engineering work; \u2022 N-best DP integration works better than 1-best insertion. In the future, we plan to expand our work to different genres, languages and other types of dropped words to confirm the robustness of our approach."}, {"heading": "Acknowledgments", "text": "This work is supported by the ADAPT project of the Science Foundation of Ireland (SFI) (Grant No.: 13 / RC / 2106) and partly by the DCU-Huawei Joint Project (Grant No.: 201504032A (DCU), YB2015090061 (Huawei), partly by the Open Projects Program of National Laboratory of Pattern Recognition (Grant 201407353) and the Open Projects Program of Centre of Translation of GDUFS (Grant CTS201501)."}], "references": [{"title": "Theano: A cpu and gpu math expression compiler in python", "author": ["Olivier Breuleux", "Frederic Bastien", "Pascal Lamblin", "Razvan Pascanu", "Guillaume Desjardins", "Joseph Turian", "David WardeFarley", "Yoshua Bengio"], "venue": null, "citeRegEx": "Bergstra et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2010}, {"title": "Language-independent parsing with empty elements. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers ", "author": ["Cai et al.2011] Shu Cai", "David Chiang", "Yoav Goldberg"], "venue": null, "citeRegEx": "Cai et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cai et al\\.", "year": 2011}, {"title": "Chinese zero pronoun resolution: Some recent advances", "author": ["Chen", "Ng2013] Chen Chen", "Vincent Ng"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Effects of empty categories on machine translation", "author": ["Chung", "Gildea2010] Tagyoung Chung", "Daniel Gildea"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Chung et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2010}, {"title": "The European linguistic area: standard average European", "author": ["Martin Haspelmath"], "venue": "In Language typology and language universals. (Handbu\u0308cher zur Sprach-und Kommunikationswissenschaft),", "citeRegEx": "Haspelmath.,? \\Q2001\\E", "shortCiteRegEx": "Haspelmath.", "year": 2001}, {"title": "On the distribution and reference of empty pronouns", "author": ["C.-T. James Huang"], "venue": "Linguistic Inquiry,", "citeRegEx": "Huang.,? \\Q1984\\E", "shortCiteRegEx": "Huang.", "year": 1984}, {"title": "A tree kernel-based unified framework for chinese zero anaphora resolution", "author": ["Kong", "Zhou2010] Fang Kong", "Guodong Zhou"], "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Kong et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kong et al\\.", "year": 2010}, {"title": "Aiding pronoun translation with co-reference resolution", "author": ["Le Nagard", "Koehn2010] Ronan Le Nagard", "Philipp Koehn"], "venue": "In Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR,", "citeRegEx": "Nagard et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nagard et al\\.", "year": 2010}, {"title": "Weighted alignment matrices for statistical machine translation", "author": ["Liu et al.2009] Yang Liu", "Tian Xia", "Xinyan Xiao", "Qun Liu"], "venue": "In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume", "citeRegEx": "Liu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "A novel graph-based compact representation of word alignment", "author": ["Liu et al.2013] Qun Liu", "Zhaopeng Tu", "Shouxun Lin"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),", "citeRegEx": "Liu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2013}, {"title": "Investigation of recurrent-neural-network architectures and learning methods for spoken language understanding", "author": ["Xiaodong He", "Li Deng", "Yoshua Bengio"], "venue": "In Proceedings of the 14th Annual Conference", "citeRegEx": "Mesnil et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mesnil et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Proceedings of the 27th Annual Conference on Neural Information Processing Sys-", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Cross-lingual coreference resolution of pronouns", "author": ["Novak", "Zabokrtsky2014] Michal Novak", "Zdenek Zabokrtsky"], "venue": "In Proceedings of the 25th International Conference on Computational Linguistics,", "citeRegEx": "Novak et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Novak et al\\.", "year": 2014}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Och", "Ney2003] Franz Josef Och", "Hermann Ney"], "venue": "Computational Linguistics,", "citeRegEx": "Och et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Och et al\\.", "year": 2003}, {"title": "Minimum error rate training in statistical machine translation", "author": ["Franz Josef Och"], "venue": "In Proceedings of the 41st Annual Meeting on Association", "citeRegEx": "Och.,? \\Q2003\\E", "shortCiteRegEx": "Och.", "year": 2003}, {"title": "Bleu: A method for automatic evaluation of machine translation", "author": ["Salim Roukos", "Todd Ward", "Wei-Jing Zhu"], "venue": "In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,", "citeRegEx": "Papineni et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes", "author": ["Alessandro Moschitti", "Nianwen Xue", "Olga Uryupina", "Yuchen Zhang"], "venue": "In Proceedings of the 15th Conference on Computational", "citeRegEx": "Pradhan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2012}, {"title": "Generative and discriminative algorithms for spoken language understanding", "author": ["Raymond", "Riccardi2007] Christian Raymond", "Giuseppe Riccardi"], "venue": "In Proceedings of 8th Annual Conference of the International Speech Communication Association,", "citeRegEx": "Raymond et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Raymond et al\\.", "year": 2007}, {"title": "Combining outputs from multiple machine translation systems", "author": ["Necip Fazil Ayan", "Bing Xiang", "Spyridon Matsoukas", "Richard M Schwartz", "Bonnie J Dorr"], "venue": "In Proceedings of the Human Language Technology", "citeRegEx": "Rosti et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Rosti et al\\.", "year": 2007}, {"title": "Srilm - an extensible language modeling toolkit", "author": ["Andreas Stolcke"], "venue": "In Proceedings of the 7th International Conference on Spoken Language Processing,", "citeRegEx": "Stolcke.,? \\Q2002\\E", "shortCiteRegEx": "Stolcke.", "year": 2002}, {"title": "Zero pronoun resolution can improve the quality of j-e translation", "author": ["Katsuhito Sudoh", "Masaaki Nagata"], "venue": "In Proceedings of the 6th Workshop on Syntax, Semantics and Structure in Statistical Translation,", "citeRegEx": "Taira et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Taira et al\\.", "year": 2012}, {"title": "Dependency forest for statistical machine translation", "author": ["Tu et al.2010] Zhaopeng Tu", "Yang Liu", "Young-Sook Hwang", "Qun Liu", "Shouxun Lin"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics,", "citeRegEx": "Tu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tu et al\\.", "year": 2010}, {"title": "Extracting Hierarchical Rules from a Weighted Alignment Matrix", "author": ["Tu et al.2011] Zhaopeng Tu", "Yang Liu", "Qun Liu", "Shouxun Lin"], "venue": "In Proceedings of the 5th International Joint Conference on Natural Language Processing,", "citeRegEx": "Tu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tu et al\\.", "year": 2011}, {"title": "The automatic construction of discourse corpus for dialogue translation", "author": ["Wang et al.2016] Longyue Wang", "Xiaojun Zhang", "Zhaopeng Tu", "Andy Way", "Qun Liu"], "venue": "In Proceedings of the 10th Language Resources and Evaluation Conference,", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Enlisting the ghost: Modeling empty categories for machine translation", "author": ["Xiang et al.2013] Bing Xiang", "Xiaoqiang Luo", "Bowen Zhou"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Xiang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Xiang et al\\.", "year": 2013}, {"title": "Dependency-based empty category detection via phrase structure trees", "author": ["Xue", "Yang2013] Nianwen Xue", "Yaqin Yang"], "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-", "citeRegEx": "Xue et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2013}, {"title": "The Penn Chinese Treebank: Phrase structure annotation of a large corpus", "author": ["Xue et al.2005] Naiwen Xue", "Fei Xia", "Fu-Dong Chiou", "Marta Palmer"], "venue": "Natural language engineering,", "citeRegEx": "Xue et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Xue et al\\.", "year": 2005}, {"title": "Chasing the ghost: recovering empty categories in the Chinese treebank", "author": ["Yang", "Xue2010] Yaqin Yang", "Nianwen Xue"], "venue": "In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,", "citeRegEx": "Yang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2010}, {"title": "Recovering dropped pronouns from Chinese text messages", "author": ["Yang et al.2015] Yaqin Yang", "Yalin Liu", "Nianwen Xu"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Nat-", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "Dual subtitles as parallel corpora", "author": ["Zhang et al.2014] Shikun Zhang", "Wang Ling", "Chris Dyer"], "venue": "In Proceedings of the 10th International Conference on Language Resources and Evaluation,", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Identification and resolution of Chinese zero pronouns: A machine learning approach", "author": ["Zhao", "Ng2007] Shanheng Zhao", "Hwee Tou Ng"], "venue": "In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Compu-", "citeRegEx": "Zhao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Zhao et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 28, "context": "In pro-drop languages, certain classes of pronouns can be omitted to make the sentence compact yet comprehensible when the identity of the pronouns can be inferred from the context (Yang et al., 2015).", "startOffset": 181, "endOffset": 200}, {"referenceID": 5, "context": "Figure 1 shows an example, in which Chinese is a pro-drop language (Huang, 1984), while English is Figure 1: Examples of dropped pronouns in a parallel dialogue", "startOffset": 67, "endOffset": 80}, {"referenceID": 4, "context": "not (Haspelmath, 2001).", "startOffset": 4, "endOffset": 22}, {"referenceID": 28, "context": "Generally, this phenomenon is more common in informal genres such as dialogues and conversations than others (Yang et al., 2015).", "startOffset": 109, "endOffset": 128}, {"referenceID": 28, "context": "works either apply manual annotation (Yang et al., 2015) or use existing but small-scale resources such as the Penn Treebank (Chung and Gildea, 2010; Xiang et al.", "startOffset": 37, "endOffset": 56}, {"referenceID": 24, "context": ", 2015) or use existing but small-scale resources such as the Penn Treebank (Chung and Gildea, 2010; Xiang et al., 2013).", "startOffset": 76, "endOffset": 120}, {"referenceID": 18, "context": "To alleviate the propagation of DP prediction errors, we feed the translation system N -best prediction results via confusion network decoding (Rosti et al., 2007).", "startOffset": 143, "endOffset": 163}, {"referenceID": 15, "context": "61 BLEU points (Papineni et al., 2002) using the additional translation model trained on the DP-inserted cor-", "startOffset": 15, "endOffset": 38}, {"referenceID": 10, "context": "In light of the recent success of applying deep neural network technologies in natural language processing (Raymond and Riccardi, 2007; Mesnil et al., 2013), we propose a neural network-based DP generator via the DP-inserted corpus (Section 2.", "startOffset": 107, "endOffset": 156}, {"referenceID": 11, "context": "Word embeddings (Mikolov et al., 2013) are used for our generation models: given a word w(t), we try to produce an embedding representation v(t) \u2208 Rd where d is the dimension of the representation vectors.", "startOffset": 16, "endOffset": 38}, {"referenceID": 10, "context": "We employ an RNN (Mesnil et al., 2013) to learn the dependency of sentences, which can be formulated as Equation (2):", "startOffset": 17, "endOffset": 38}, {"referenceID": 24, "context": "We select a number of features based on previous work (Xiang et al., 2013; Yang et al., 2015), including lexical, contextual, and syntax features (as shown in Table 2).", "startOffset": 54, "endOffset": 93}, {"referenceID": 28, "context": "We select a number of features based on previous work (Xiang et al., 2013; Yang et al., 2015), including lexical, contextual, and syntax features (as shown in Table 2).", "startOffset": 54, "endOffset": 93}, {"referenceID": 8, "context": "Recent studies have shown that SMT systems can benefit from widening the annotation pipeline (Liu et al., 2009; Tu et al., 2010; Tu et al., 2011; Liu et al., 2013).", "startOffset": 93, "endOffset": 163}, {"referenceID": 21, "context": "Recent studies have shown that SMT systems can benefit from widening the annotation pipeline (Liu et al., 2009; Tu et al., 2010; Tu et al., 2011; Liu et al., 2013).", "startOffset": 93, "endOffset": 163}, {"referenceID": 22, "context": "Recent studies have shown that SMT systems can benefit from widening the annotation pipeline (Liu et al., 2009; Tu et al., 2010; Tu et al., 2011; Liu et al., 2013).", "startOffset": 93, "endOffset": 163}, {"referenceID": 9, "context": "Recent studies have shown that SMT systems can benefit from widening the annotation pipeline (Liu et al., 2009; Tu et al., 2010; Tu et al., 2011; Liu et al., 2013).", "startOffset": 93, "endOffset": 163}, {"referenceID": 1, "context": "Another line related to DP generation is using a wider range of empty categories (EC) (Yang and Xue, 2010; Cai et al., 2011; Xue and Yang, 2013), which aims to recover longdistance dependencies, discontinuous constituents and certain dropped elements3 in phrase structure treebanks (Xue et al.", "startOffset": 86, "endOffset": 144}, {"referenceID": 26, "context": ", 2011; Xue and Yang, 2013), which aims to recover longdistance dependencies, discontinuous constituents and certain dropped elements3 in phrase structure treebanks (Xue et al., 2005).", "startOffset": 165, "endOffset": 183}, {"referenceID": 1, "context": "Another line related to DP generation is using a wider range of empty categories (EC) (Yang and Xue, 2010; Cai et al., 2011; Xue and Yang, 2013), which aims to recover longdistance dependencies, discontinuous constituents and certain dropped elements3 in phrase structure treebanks (Xue et al., 2005). This work mainly focus on sentence-internal characteristics as opposed to contextual information at the discourse level. More recently, Yang et al. (2015) explore DP recovery for Chinese text messages based on both lines of work.", "startOffset": 107, "endOffset": 457}, {"referenceID": 20, "context": "These methods can also be used for DP translation using SMT (Chung and Gildea, 2010; Le Nagard and Koehn, 2010; Taira et al., 2012; Xiang et al., 2013).", "startOffset": 60, "endOffset": 151}, {"referenceID": 24, "context": "These methods can also be used for DP translation using SMT (Chung and Gildea, 2010; Le Nagard and Koehn, 2010; Taira et al., 2012; Xiang et al., 2013).", "startOffset": 60, "endOffset": 151}, {"referenceID": 20, "context": "These methods can also be used for DP translation using SMT (Chung and Gildea, 2010; Le Nagard and Koehn, 2010; Taira et al., 2012; Xiang et al., 2013). Taira et al. (2012) propose both sim-", "startOffset": 112, "endOffset": 173}, {"referenceID": 16, "context": "their results are not convincing due to the poor performance of the CR method (Pradhan et al., 2012).", "startOffset": 78, "endOffset": 100}, {"referenceID": 16, "context": "their results are not convincing due to the poor performance of the CR method (Pradhan et al., 2012). Chung and Gildea (2010) systematically examine the effects of EC on MT with three methods: pattern, CRF (which achieves best results) and parsing.", "startOffset": 79, "endOffset": 126}, {"referenceID": 23, "context": "13TB Chinese Web Page Collection Corpus5 while the other one is trained on all extracted 7M English subtitle data (Wang et al., 2016).", "startOffset": 114, "endOffset": 133}, {"referenceID": 19, "context": "thermore, we train 5-gram language models using the SRI Language Toolkit (Stolcke, 2002).", "startOffset": 73, "endOffset": 88}, {"referenceID": 14, "context": "6 We use minimum error rate training (Och, 2003) to optimize the feature weights.", "startOffset": 37, "endOffset": 48}, {"referenceID": 0, "context": "The RNN models are implemented using the common Theano neural network toolkit (Bergstra et al., 2010).", "startOffset": 78, "endOffset": 101}, {"referenceID": 15, "context": "For end-to-end evaluation, case-insensitive BLEU (Papineni et al., 2002) is used to measure", "startOffset": 49, "endOffset": 72}, {"referenceID": 29, "context": "Dual Subtitles \u2013 Mandarin-English Subtitles Parallel Corpus, extracted by Zhang et al. (2014) without contextual information at the discourse level.", "startOffset": 74, "endOffset": 94}], "year": 2016, "abstractText": "Dropped Pronouns (DP) in which pronouns are frequently dropped in the source language but should be retained in the target language are challenge in machine translation. In response to this problem, we propose a semisupervised approach to recall possibly missing pronouns in the translation. Firstly, we build training data for DP generation in which the DPs are automatically labelled according to the alignment information from a parallel corpus. Secondly, we build a deep learning-based DP generator for input sentences in decoding when no corresponding references exist. More specifically, the generation is two-phase: (1) DP position detection, which is modeled as a sequential labelling task with recurrent neural networks; and (2) DP prediction, which employs a multilayer perceptron with rich features. Finally, we integrate the above outputs into our translation system to recall missing pronouns by both extracting rules from the DP-labelled training data and translating the DP-generated input sentences. Experimental results show that our approach achieves a significant improvement of 1.58 BLEU points in translation performance with 66% F-score for DP generation accuracy.", "creator": "LaTeX with hyperref package"}}}