{"id": "1604.07706", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Apr-2016", "title": "Distributed Clustering of Linear Bandits in Peer to Peer Networks", "abstract": "We provide two distributed confidence ball algorithms for solving linear bandit problems in peer to peer networks with limited communication capabilities. For the first, we assume that all the peers are solving the same linear bandit problem, and prove that our algorithm achieves the optimal asymptotic regret rate of any centralised algorithm that can instantly communicate information between the peers. For the second, we assume that there are clusters of peers solving the same bandit problem within each cluster, and we prove that our algorithm discovers these clusters, while achieving the optimal asymptotic regret rate within each one. Through experiments on several real-world datasets, we demonstrate the performance of proposed algorithms compared to the state-of-the-art.", "histories": [["v1", "Tue, 26 Apr 2016 14:59:43 GMT  (1218kb)", "https://arxiv.org/abs/1604.07706v1", "To Appear in The 33rd International Conference on Machine Learning, New York, NY, USA, 2016"], ["v2", "Wed, 25 May 2016 06:12:46 GMT  (687kb,D)", "http://arxiv.org/abs/1604.07706v2", "The 33rd International Conference on Machine Learning, Journal of Machine Learning Research (JMLR), New York City, NY, USA (ICML 2016)"], ["v3", "Tue, 7 Jun 2016 08:06:23 GMT  (780kb,D)", "http://arxiv.org/abs/1604.07706v3", "The 33rd ICML, 2016"]], "COMMENTS": "To Appear in The 33rd International Conference on Machine Learning, New York, NY, USA, 2016", "reviews": [], "SUBJECTS": "cs.LG cs.AI stat.ML", "authors": ["nathan korda", "bal\u00e1zs sz\u00f6r\u00e9nyi", "shuai li"], "accepted": true, "id": "1604.07706"}, "pdf": {"name": "1604.07706.pdf", "metadata": {"source": "META", "title": "Distributed Clustering of Linear Bandits in Peer to Peer Networks", "authors": ["Nathan Korda", "Bal\u00e1zs Sz\u00f6r\u00e9nyi", "Shuai Li"], "emails": ["NATHAN@ROBOTS.OX.AC.UK", "SZORENYI.BALAZS@GMAIL.COM", "SHUAILI.SLI@GMAIL.COM"], "sections": [{"heading": "1. Introduction", "text": "The most important of these systems are recommendation systems, and they can also raise more general problems in the networks (see, for example, that they can simultaneously improve the performance of the entire network and each individual actor while increasing their robustness), but we want to avoid putting too much pressure on communication channels where a network of agents is trying to solve these collaborative linear bandit problems. Communicating each piece of information would only overload this chan-Proceedings of the 33rd International Conference on Machine Learning, New York, USA, 2016. JMLR: W & CP Volume 48. Copyright 2016 by the author (s).nels. The solution we propose is a gossip-based information protocol that makes it possible to disseminate information across the network at a low cost."}, {"heading": "2. Linear Bandits and the DCB Algorithm", "text": "The generic Confidence Ball (CB) algorithm is designed for a single agent linear bandit problem (i.e.: V = 1). The algorithm maintains a trust ball Ct-Rd within which it believes in the true parameter, with high probability. This trust ball is calculated by the observation pairs (xk, rk) k = 1,..., t (for the sake of simplicity, we have dropped the agent index, i). Typically, the covariance matrix At = 1 xkx T k and b vector, bt = 1 rkxk, are sufficient statistics to characterize this trust ball."}, {"heading": "2.1. Results for DCB", "text": "Theorem 1 (\u00b7): t \u2192 4 log (| V | 32 t). Then the regret of the DCB is limited with probability 1 \u2212 3 by Rt \u2264 (N (\u03b4) | V | + \u03bd (| V |, d, t)). (\u03b2 (t) + 4e2 (\u03b2 (t) + 4R) \u221a | V | t ln ((((1 + | V | t / d) d)), where \u03bd (| V | d, t): = (d + 1) d2 (4 | V | ln (| 32 t)) 3, N (\u03b4): = 3 / (1 \u2212 2 \u2212 14).), and\u03b2 (t): = R \u221a ln ((((1 + | V / d) d) d2 (2). (2) The term \u03bd (t, | V |, d)."}, {"heading": "COMMUNICATION COMPLEXITY", "text": "If the agents share their information with each other in each round without a central server, then each agent would have to communicate their chosen action and reward to each other in each round, resulting in communication costs of d | V | 2 per round. We call such an algorithm CBInstSharing. According to the gossip protocol that we propose, each agent requires no more than O (log2 (| V | t) d2 | V |) bits to be communicated per round. Therefore, a significant reduction in communication costs is achieved when protocol (| V | t) d | V |. Using an epochal approach such as in (Szo \ufffd re \ufffd nyi et al., 2013) the communication costs per round become O (d2 | V |). This improves efficiency across all horizons and only requires that d | V |, and the evidence of repentance performance are simple modifications of those for the DCB. Compared to growing buffer costs, however, this is a higher problem for C2."}, {"heading": "PROOF OF THEOREM 1", "text": "In the analysis, we show that the bias introduced by imperfect information transmission is mitigated by the delay in the inclusion of data in the estimation of parameters (1) (1). The evidence builds on the analysis in (Abbasi-Yadkori et al., 2011). The emphasis here is on dealing with the additional difficulty arising from imperfect information transmission, which results in the influence of the various biases that are unbalanced and appear with an accidental delay. (Abbasi-Yadkori et al., and default 1) are crucial, and are shifted to Appendix A.3.Step 1: Define modified trust ellipsoids. First, we need a transformation of trust ellipsoid theorem given to (Abbasi-Yadkori et al., 2011), which includes the bias introduced by the random weights."}, {"heading": "PROOF OF PROPOSITION 2", "text": "This proof forms the principal novation in the proof of theorem 1. Let us (yk) k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k k = k k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k = k"}, {"heading": "3. Clustering and the DCCB Algorithm", "text": "The analysis of DCB forms the backbone of the analysis of DCCB.DCCB Pruning Protocol (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1). (1. (1). (1). (1). (1). (1. (1). (1). (1). (1. (1). (1). (1. (1). (1). (1). (1. (1). (1). (1). (1. (1). (1). (1.). (1. (1). (1.). (1.). (1.). (1.). (1.). (1.). (1.). (1.). (1.). (1.). (1.). (1. (1.). (1.). (1.). (1.). (1.). (1. (1.).). (1.). (1.). (1.). (1.). (1.). (1.). (1.).). (1.). (1.). (1.). (1.).). (1.). (1.).).). (1. (1.).). (1.).). (1"}, {"heading": "3.1. Results for DCCB", "text": "Theorem 6. Let us assume that (A) holds, and let \u03b3 denote the smallest distance between the bandit parameters \u03b8k. Then there is a constant C = C (\u03b3, | V |, \u03bb, \u03b4), so that with probability 1 \u2212 \u03b4 the total cumulative regret of the cluster k, when the agents use DCCB, is delimited by Rt \u2264 [max {\u221a 2N (\u03b4), C + 4 log2 (| V | 3 2C)} | UK | + \u03bd (| Uk |, d, t)]]."}, {"heading": "4. Experiments and Discussion", "text": "It is about the question of what the future of the world is like, and about the question of what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future of the world is like, what the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future of the world, the future of the world, the future of the world, the future of the world, the future of the world, the world, the future, the future of the world, the world, the world, the future, the future, the future, the future of the world, the world, the future, the world, the future, the future, the future, the world, the future, the future, the future, the future of the world, the world, the world, the future, the future, the future, the world, the future, the future, the future, the future, the future, the future, the world, the future, the future, the future, the future, the future, the world, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, the future, it, the future, the future, the future, the future, the future, the future, the future, the future, the"}, {"heading": "Acknowledgments", "text": "We thank the anonymous reviewers for their helpful comments and Gergley Neu for very useful discussions. NK thanks the support of the EPSRC Autonomous Intelligent Systems project EP / I011587. SL thanks the support of MIUR, QCRIHBKU, Amazon Research Grant and Tsinghua University. The research that led to these results was funded by the European Research Council under the Seventh Framework Programme of the European Union (FP / 2007-2013) / ERC Grant Agreement n. 306638."}, {"heading": "A. Supplementary Material", "text": "A.1. Pseudocode for the generic CB algorithm and the DCB algorithm mAlgorithm 2 Confidence Ball Initialization: Set A0 = I and b0 = 0. for t = 0,.... doReceive action set Dt Construct the confidence ball Ct using At and bt Choose action and receive reward: Find (xt, \u043a) = arg max (x, \u03b8): Network V of agents, the function \u03c4: t \u2192 t \u2212 4 log2 (| V | 3 2 t).Initialization: Set A-i0 = Id and bt + 1 = bt + rtxt end for Algorithm 3 Distributed Confidence Ball Input: Network V of agents, the function \u03c4: t \u2212 4 log2 (| 3 2 t).Initialization: Set A-i0 = Id and b-i0 = 0, and the buffers Ai0 = \u03c3. for t = 0,.."}, {"heading": "A.2. More on Communication Complexity", "text": "Firstly, because agents want to communicate their information in each round without a central server, and secondly, because each agent must communicate his own action and reward in each round, resulting in a significant reduction in the communication costs that he is able to identify with, indeed, an era-based approach, as he has done in the past, and thirdly, because he has achieved a significant reduction in communication costs when he is able to use an era-based approach, as he has done in the past."}, {"heading": "A.3. Proofs of Intermediary Results for DCB", "text": "The proof of Proposition 1 follows the proof of Theory 2 in (Abbasi-Yadkori et al., 2011), which replaces appropriately weighted quantities.To simplify the representation, we define the abbreviations as follows: = (\u221a w1y1,.., wnyn) and \u03b7 = (\u221a w1\u03b71,., wnn) T, where the yi \"vectors with a norm are less than 1, are the\" i \"R-Subgaussian, zero mean, random variables, and the wi\" i \"are positive real numbers. Then the given samples (\u221a w1y1, \u221a w1\" i \"),., (\u221a wnyn\" wn \"n\" i \"),\" X \"X\" i \"), the most likely estimate of the\" i \"(X\" i \") and the\" i \"i.\""}, {"heading": "A.4. Proof of Theorem 6", "text": "Step 1: Let us show the true formation of clusters in finite time. First, we prove that with probability 1 - 3 the number of agents in different clusters exchanging information is limited. (Consider the statements: \"i,\" \"i,\" \"i,\" \"i,\" \"i,\" \"i,\" \"i,\" \"i,\" \"i,\" \"i,\" \"i,\" \"\" i, \"\" \"i,\" \"\" i, \"\" (17), \"i,\" i, \"i.\" (17), \"i,\" i, \"i.\" (18), \"i.\" (18), \"i.\" (18), \"(18),\" (18), \"(18),\" i., \"(18),\" (18), \"(18),\" i."}, {"heading": "A.5. Proofs of Intermediary Results for DCCB", "text": "The proof of Lemma 7 is that both agents will reset their buffers to their local information, scaled according to the size of their current neighbor sets. (It makes practically no difference whether they scale their buffers or not, since this effect is flushed out in the calculation of trust limits and local estimates. (However, it is convenient to assume that they do so for analysis.) Furthermore, no agent will share information with another agent who does not have the same local neighbors. (At event E, there is a time for each agent, i before the time C = C (V |, that is) when the agent resets its information to their local information, and their local neighbor becomes their local cluster, i.e. V es = Uk, that agent will only share information with other agents who also set their local neighbors to their local clusters."}], "references": [{"title": "Improved algorithms for linear stochastic bandits", "author": ["Abbasi-Yadkori", "Yasin", "P\u00e1l", "D\u00e1vid", "Szepesv\u00e1ri", "Csaba"], "venue": "In NIPS, pp", "citeRegEx": "Abbasi.Yadkori et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Abbasi.Yadkori et al\\.", "year": 2011}, {"title": "Thompson sampling for contextual bandits with linear payoffs", "author": ["Agrawal", "Shipra", "Goyal", "Navin"], "venue": "In ICML,", "citeRegEx": "Agrawal et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 2013}, {"title": "Randomized gossip algorithms", "author": ["Boyd", "Stephen", "Ghosh", "Arpita", "Prabhakar", "Balaji", "Shah", "Devavrat"], "venue": "IEEE/ACM Transactions on Networking (TON),", "citeRegEx": "Boyd et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Boyd et al\\.", "year": 2006}, {"title": "Stochastic linear optimization under bandit feedback", "author": ["Dani", "Varsha", "Hayes", "Thomas P", "Kakade", "Sham M"], "venue": "In COLT, pp", "citeRegEx": "Dani et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Dani et al\\.", "year": 2008}, {"title": "Online clustering of bandits", "author": ["Gentile", "Claudio", "Li", "Shuai", "Zappella", "Giovanni"], "venue": "In ICML,", "citeRegEx": "Gentile et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gentile et al\\.", "year": 2014}, {"title": "An efficient approach to generating location-sensitive recommendations in adhoc social network environments", "author": ["Hao", "Fei", "Li", "Shuai", "Min", "Geyong", "Kim", "Hee-Cheol", "Yau", "Stephen S", "Yang", "Laurence T"], "venue": "IEEE Transactions on Services Computing,", "citeRegEx": "Hao et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hao et al\\.", "year": 2015}, {"title": "Gossipbased aggregation in large dynamic networks", "author": ["M. Jelasity", "A. Montresor", "O. Babaoglu"], "venue": "ACM Trans. on Computer Systems,", "citeRegEx": "Jelasity et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Jelasity et al\\.", "year": 2005}, {"title": "Gossip-based peer sampling", "author": ["M. Jelasity", "S. Voulgaris", "R. Guerraoui", "A.M. Kermarrec", "M. van Steen"], "venue": "ACM Transactions on Computer Systems,", "citeRegEx": "Jelasity et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Jelasity et al\\.", "year": 2007}, {"title": "Decentralized learning for multiplayer multiarmed bandits", "author": ["Kalathil", "Dileep", "Nayyar", "Naumaan", "Jain", "Rahul"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "Kalathil et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalathil et al\\.", "year": 2014}, {"title": "Thompson sampling: An asymptotically optimal finitetime analysis", "author": ["Kaufmann", "Emilie", "Korda", "Nathaniel", "Munos", "R\u00e9mi"], "venue": "In Algorithmic Learning Theory,", "citeRegEx": "Kaufmann et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kaufmann et al\\.", "year": 2012}, {"title": "Gossip-based computation of aggregate information", "author": ["D. Kempe", "A. Dobra", "J. Gehrke"], "venue": "In Proc. 44th Annual IEEE Symposium on Foundations of Computer Science", "citeRegEx": "Kempe et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Kempe et al\\.", "year": 2003}, {"title": "A contextual-bandit approach to personalized news article recommendation", "author": ["Li", "Lihong", "Chu", "Wei", "Langford", "John", "Schapire", "Robert E"], "venue": "In Proceedings of the 19th international conference on World wide web,", "citeRegEx": "Li et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Li et al\\.", "year": 2010}, {"title": "Medicine rating prediction and recommendation in mobile social networks", "author": ["Li", "Shuai", "Hao", "Fei", "Mei", "Kim", "Hee-Cheol"], "venue": "In Proceedings of the International Conference on Grid and Pervasive Computing,", "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Graph clustering bandits for recommendation", "author": ["Li", "Shuai", "Gentile", "Claudio", "Karatzoglou", "Alexandros"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Collaborative filtering bandits", "author": ["Li", "Shuai", "Karatzoglou", "Alexandros", "Gentile", "Claudio"], "venue": "In The 39th SIGIR,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "On regret-optimal learning in decentralized multi-player multi-armed bandits", "author": ["Nayyar", "Naumaan", "Kalathil", "Dileep", "Jain", "Rahul"], "venue": null, "citeRegEx": "Nayyar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nayyar et al\\.", "year": 2015}, {"title": "Learning to optimize via posterior sampling", "author": ["Russo", "Daniel", "Van Roy", "Benjamin"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Russo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Russo et al\\.", "year": 2014}, {"title": "Contextual bandits with similarity information", "author": ["Slivkins", "Aleksandrs"], "venue": "JMLR,", "citeRegEx": "Slivkins and Aleksandrs.,? \\Q2014\\E", "shortCiteRegEx": "Slivkins and Aleksandrs.", "year": 2014}, {"title": "Gossip-based distributed stochastic bandit algorithms", "author": ["Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", "Busa-Fekete", "R\u00f3bert", "Heged\u0171s", "Istv\u00e1n", "Orm\u00e1ndi", "Jelasity", "M\u00e1rk", "K\u00e9gl"], "venue": "In ICML, pp", "citeRegEx": "Sz\u00f6r\u00e9nyi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sz\u00f6r\u00e9nyi et al\\.", "year": 2013}, {"title": "Distributed online learning via cooperative contextual bandits", "author": ["Tekin", "Cem", "van der Schaar", "Mihaela"], "venue": "IEEE Trans. Signal Processing,", "citeRegEx": "Tekin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tekin et al\\.", "year": 2013}, {"title": "Distributed average consensus with least-mean-square deviation", "author": ["L. Xiao", "S. Boyd", "Kim", "S.-J"], "venue": "Journal of Parallel and Distributed Computing,", "citeRegEx": "Xiao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Xiao et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 12, "context": ", (Li et al., 2013; Hao et al., 2015)).", "startOffset": 2, "endOffset": 37}, {"referenceID": 5, "context": ", (Li et al., 2013; Hao et al., 2015)).", "startOffset": 2, "endOffset": 37}, {"referenceID": 10, "context": ", (Kempe et al., 2003; Xiao et al., 2007; Jelasity et al., 2005; 2007)), in each round, an overlay protocol assigns to every agent another agent, with which it can share information.", "startOffset": 2, "endOffset": 70}, {"referenceID": 20, "context": ", (Kempe et al., 2003; Xiao et al., 2007; Jelasity et al., 2005; 2007)), in each round, an overlay protocol assigns to every agent another agent, with which it can share information.", "startOffset": 2, "endOffset": 70}, {"referenceID": 6, "context": ", (Kempe et al., 2003; Xiao et al., 2007; Jelasity et al., 2005; 2007)), in each round, an overlay protocol assigns to every agent another agent, with which it can share information.", "startOffset": 2, "endOffset": 70}, {"referenceID": 18, "context": "In (Sz\u00f6r\u00e9nyi et al., 2013) this was achieved by introducing an epoch structure into their algorithm, and emptying the buffers at the end of each epoch.", "startOffset": 3, "endOffset": 26}, {"referenceID": 0, "context": "The Distributed Confidence Ball Algorithm (DCB) We use a gossip-based information sharing protocol to produce a distributed variant of the generic Confidence Ball (CB) algorithm, (Abbasi-Yadkori et al., 2011; Dani et al., 2008; Li et al., 2010).", "startOffset": 179, "endOffset": 244}, {"referenceID": 3, "context": "The Distributed Confidence Ball Algorithm (DCB) We use a gossip-based information sharing protocol to produce a distributed variant of the generic Confidence Ball (CB) algorithm, (Abbasi-Yadkori et al., 2011; Dani et al., 2008; Li et al., 2010).", "startOffset": 179, "endOffset": 244}, {"referenceID": 11, "context": "The Distributed Confidence Ball Algorithm (DCB) We use a gossip-based information sharing protocol to produce a distributed variant of the generic Confidence Ball (CB) algorithm, (Abbasi-Yadkori et al., 2011; Dani et al., 2008; Li et al., 2010).", "startOffset": 179, "endOffset": 244}, {"referenceID": 18, "context": "Our approach is similar to (Sz\u00f6r\u00e9nyi et al., 2013) where the authors produced a distributed -greedy algorithm for the simpler multi-armed bandit problem.", "startOffset": 27, "endOffset": 50}, {"referenceID": 4, "context": "The Distributed Clustering Confidence Ball Algorithm (DCCB) The paper (Gentile et al., 2014) proposes the initial centralised approach to the problem of clustering linear bandits.", "startOffset": 70, "endOffset": 92}, {"referenceID": 0, "context": "DCB algorithm The OFUL algorithm (Abbasi-Yadkori et al., 2011) is an improvement of the confidence ball algorithm from (Dani et al.", "startOffset": 33, "endOffset": 62}, {"referenceID": 3, "context": ", 2011) is an improvement of the confidence ball algorithm from (Dani et al., 2008), which assumes that the confidence balls Ct can be characterised by At and bt.", "startOffset": 64, "endOffset": 83}, {"referenceID": 0, "context": "If the agents implement CB independently and do not share any information, which we call CB-NoSharing, then it follows from the results in (Abbasi-Yadkori et al., 2011), the equivalent regret bound would be", "startOffset": 139, "endOffset": 168}, {"referenceID": 18, "context": "Using an epoch-based approach, as in (Sz\u00f6r\u00e9nyi et al., 2013), the per-round communication cost of the gossip protocol becomes O(d2|V |).", "startOffset": 37, "endOffset": 60}, {"referenceID": 0, "context": "The proof builds on the analysis in (Abbasi-Yadkori et al., 2011).", "startOffset": 36, "endOffset": 65}, {"referenceID": 0, "context": "First we need a version of the confidence ellipsoid theorem given in (Abbasi-Yadkori et al., 2011) that incorporates the bias introduced by the random weights: Proposition 1.", "startOffset": 69, "endOffset": 98}, {"referenceID": 0, "context": "Then we can decompose the instantaneous regret, following a classic argument (see the proof of Theorem 3 in (Abbasi-Yadkori et al., 2011)):", "startOffset": 108, "endOffset": 137}, {"referenceID": 18, "context": "Using Lemma 4 in (Sz\u00f6r\u00e9nyi et al., 2013), by exploiting the random weights are identically distributed (i.", "startOffset": 17, "endOffset": 40}, {"referenceID": 0, "context": "Now, first applying Cauchy-Schwarz, then step 3b from above together with (9), and finally Lemma 11 from (Abbasi-Yadkori et al., 2011) yields that, with probability 1\u2212 ( 1 + \u2211\u221e t=1(|V |t)\u22122/(1\u2212 2\u22121/2) ) \u03b4 \u2265 1\u2212 3\u03b4,", "startOffset": 105, "endOffset": 134}, {"referenceID": 4, "context": "Here \u03bb is a parameter of an extra assumption that is needed, as in (Gentile et al., 2014), about the process generating the context sets Di t:", "startOffset": 67, "endOffset": 89}, {"referenceID": 4, "context": "We define c \u03bb (t), as in (Gentile et al., 2014), by", "startOffset": 25, "endOffset": 47}, {"referenceID": 4, "context": "Here is a parameter of an extra assumption that is needed, as in (Gentile et al., 2014), about the process generating the context sets Di t:", "startOffset": 65, "endOffset": 87}, {"referenceID": 4, "context": "We define c (t), as in (Gentile et al., 2014), by", "startOffset": 23, "endOffset": 45}, {"referenceID": 4, "context": "We adapt results from (Gentile et al., 2014) to show how long it will be before the true clusters are identified, in high probability.", "startOffset": 22, "endOffset": 44}, {"referenceID": 18, "context": "There is already work on distributed approaches to multi-agent, multi-armed bandits, not least (Sz\u00f6r\u00e9nyi et al., 2013) which examines -greedy strategies over a peer to peer network, and provided an initial inspiration for this current work.", "startOffset": 95, "endOffset": 118}, {"referenceID": 8, "context": "The paper (Kalathil et al., 2014) examines the extreme case when there is no communication channel across which the agents can communicate, and all communication must be performed through observation of action choices alone.", "startOffset": 10, "endOffset": 33}, {"referenceID": 15, "context": "Another approach to the multi-armed bandit case, (Nayyar et al., 2015), directly incorporates the communication cost into the regret.", "startOffset": 49, "endOffset": 70}, {"referenceID": 4, "context": ", 2016a) is a faster variant of (Gentile et al., 2014) which adopt the strategy of boosted training stage.", "startOffset": 32, "endOffset": 54}, {"referenceID": 0, "context": "Discussion Our analysis is tailored to adapt proofs from (Abbasi-Yadkori et al., 2011) about generic confidence ball algorithms to a distributed setting.", "startOffset": 57, "endOffset": 86}, {"referenceID": 9, "context": ", the Thompson sampling algorithms, (Agrawal & Goyal, 2013; Kaufmann et al., 2012; Russo & Van Roy, 2014).", "startOffset": 36, "endOffset": 105}, {"referenceID": 2, "context": "The work on distributed computation through gossip algorithms in (Boyd et al., 2006) could alleviate this issue.", "startOffset": 65, "endOffset": 84}, {"referenceID": 18, "context": "The current pruning algorithm for DCCB guarantees that techniques from (Sz\u00f6r\u00e9nyi et al., 2013) can be applied to our algorithms.", "startOffset": 71, "endOffset": 94}, {"referenceID": 2, "context": "However the results in (Boyd et al., 2006) are more powerful, and could be used even when the agents only identify a sub-network of the true clustering.", "startOffset": 23, "endOffset": 42}], "year": 2016, "abstractText": "We provide two distributed confidence ball algorithms for solving linear bandit problems in peer to peer networks with limited communication capabilities. For the first, we assume that all the peers are solving the same linear bandit problem, and prove that our algorithm achieves the optimal asymptotic regret rate of any centralised algorithm that can instantly communicate information between the peers. For the second, we assume that there are clusters of peers solving the same bandit problem within each cluster, and we prove that our algorithm discovers these clusters, while achieving the optimal asymptotic regret rate within each one. Through experiments on several real-world datasets, we demonstrate the performance of proposed algorithms compared to the state-of-the-art.", "creator": "LaTeX with hyperref package"}}}