{"id": "1604.08352", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Apr-2016", "title": "Joint Line Segmentation and Transcription for End-to-End Handwritten Paragraph Recognition", "abstract": "Offline handwriting recognition systems require cropped text line images for both training and recognition. On the one hand, the annotation of position and transcript at line level is costly to obtain. On the other hand, automatic line segmentation algorithms are prone to errors, compromising the subsequent recognition. In this paper, we propose a modification of the popular and efficient multi-dimensional long short-term memory recurrent neural networks (MDLSTM-RNNs) to enable end-to-end processing of handwritten paragraphs. More particularly, we replace the collapse layer transforming the two-dimensional representation into a sequence of predictions by a recurrent version which can recognize one line at a time. In the proposed model, a neural network performs a kind of implicit line segmentation by computing attention weights on the image representation. The experiments on paragraphs of Rimes and IAM database yield results that are competitive with those of networks trained at line level, and constitute a significant step towards end-to-end transcription of full documents.", "histories": [["v1", "Thu, 28 Apr 2016 09:08:30 GMT  (1297kb,D)", "http://arxiv.org/abs/1604.08352v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["th\u00e9odore bluche"], "accepted": true, "id": "1604.08352"}, "pdf": {"name": "1604.08352.pdf", "metadata": {"source": "CRF", "title": "Joint Line Segmentation and Transcription for End-to-End Handwritten Paragraph Recognition", "authors": ["Th\u00e9odore Bluche"], "emails": ["tb@a2ia.com"], "sections": [{"heading": "1 Introduction", "text": "In the last ten years, the number of those who are able to survive has multiplied, in the way that they are able to survive themselves, in the way that they are able to change the world, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it, as it is, as it is, as it is, as it is, as it, as it is, as it is, as it, as it is, as it is, as it is, as it, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is, as it is,"}, {"heading": "2 Related Work", "text": "Our work is clearly related to MDLSTM RNNNs [22], which we are improving by replacing the simple collapse layer with a sophisticated mechanism that itself consists of MDLSTM layers. The model we propose leads iteratively to implicit line segmentation at the intermediate representation level. Classical text line segmentation algorithms are largely based on image processing techniques and heuristics [32, 37, 38, 42, 45, 53]. However, some methods have been developed using statistical models and machine like hidden Markov models [8], conditional random fields [24] or neural networks [16, 35, 36]. In our model, line segmentation is performed implicitly and integrated into the neural network. Intermediate features are shared by transcription and segmentation models, and they are jointly trained to minimize transcription."}, {"heading": "3 Handwriting Recognition with MDLSTM and CTC", "text": "In this section, we will briefly introduce the MDLSTM RNNs [22]. MDLSTM layers generalize LSTMs to two-dimensional inputs, introduced for the first time in the context of handwriting recognition, the general architecture is shown in Figure 1. The MDLSTM layers scan input in the four possible directions, the inner state and output of the LSTM cell are calculated from the states and outputs of previous positions in horizontal and vertical direction. Each LSTM layer follows a revolutionary layer, the resolution of the learned representations is reduced by specifying a step size of the Convolutionary Filters greater than One. As the size of the Character Cards decreases, the number of extracted features increases. At the top of this network, there is a Character Card for each character. A Collapse Layer summarizes the characteristics along the vertical axis and results in a sequence of pre-vectors that are normalized with a max activation."}, {"heading": "4 An Iterative Weighted Collapse for End-to-End Handwriting Recognition", "text": "In this thesis, we replace the sum of Eq.1 with a weighted sum to focus on a particular part of the input.The weighted breakdown is defined as follows: z (t) i = H \u2211 j = 1 \u03c9 (t) ij aij (2), where \u03c9 (t) ij are scalar weights between 0 and 1, which are calculated at any time t for any position (i, j).The weights are calculated by a recursive neural network, as shown in Figure 2, which recognizes a line of text at any time.This breakdown, which is weighted by a neural network, can be interpreted as the \"attention module\" of a neural network similar to those of [3, 13, 51].This mechanism is differentiable and can be trained with backpropagation.Both this new and the previous architecture consist of an encoder (the MDLSTM network), an aggregation layer, and a decoder, as described below."}, {"heading": "4.1 Encoder", "text": "The lower part of the architecture presented in Section 3 remains the same. We can consider the MDLSTM network as a module for feature extraction or as an encoder of input image I in high-level features: a = (aij) (i, j) \u0442 [1, W] \u00b7 [1, H] = encoder (I) (3), where (i, j) are coordinates in the feature maps. In Section 3, a simple sum of a is calculated by a collapse layer. Here, we apply an attention mechanism to read lines of text."}, {"heading": "4.2 Attention", "text": "Weighted breakdown is an attention mechanism that provides a view of the encoded image in each timeframe in the form of a weighted sum of feature vector sequences. Attention Network calculates a score for the feature vectors at each position: \u03b1 (t) ij = Attention (a, \u03c9 (t \u2212 1))) (4) We refer to \u03c9 (t) = {\u03c9 (t) ij} (1 \u2264 i \u2264 W, 1 \u2264 j \u2264 H) as attention card at the time t, the calculation of which depends not only on the encoded image, but also on the previous attention characteristics. To do so, the output of the attention module at the iteration t, calculated with Equation 2., is a sequence of feature vectors intended to represent a text description. (5) This module is applied several times to the features from the encoder, but also to the previous attention characteristics of the iteration t, calculated with Equation 2. The output of the attention module is an Item, which is an equal number of attributes."}, {"heading": "4.3 Decoder", "text": "The last component of this architecture is a decoder that predicts a string of characters from the feature vectors. y = decoder (z) (6), where z is the concatenation of z (1), z (2),..., z (T). Alternatively, the decoder can be applied to z (i) s sub-sequences to obtain y (i) s and y the concatenation of y (1), y (2),..., y (T). In the standard MDLSTM architecture of section 3, the decoder is a simple softmax. However, a bidirectional LSTM decoder (BLSTM) could be applied to the collapsed representations. This is particularly interesting in the proposed model, as the BLSTM would potentially process the entire paragraph and allow modelling of dependencies across text lines."}, {"heading": "4.4 Training", "text": "This model can be trained with CTC. If the line breaks in the transcript are known, the CTC could be applied to the segments corresponding to each line prediction, with the line transcript. Furthermore, it will enforce the prediction in any timeframe to match a full line of text. Otherwise, CTC can be applied directly to the entire paragraph. The various training strategies of this model are shown in Figure 3.In this thesis, we have mainly examined the second strategy, with CTC training at paragraph level and with a BLSTM decoder applied to the concatenation of all the collapsing steps, for reasons to be developed in the next section."}, {"heading": "4.5 Limitations", "text": "Compared to the model presented in [6], the iterative decoder requires one step for each line of text instead of one step for each character, resulting in a tremendous acceleration of factor 20-30. However, we lose the ability to process arbitrary read jobs. Furthermore, the model in this version does not predict a \"stop\" token. Therefore, the network predicts an arbitrary number of T sequences set by the experimenter. In numerous cases, we observed that attention during these additional steps was located in interlines where the decoder can easily predict only non-characters. However, the lack of the ability to automatically determine the number of steps required is an important limitation that should be addressed in future work. Finally, the collapsing paradigm shift forces the model to output sequences that will replace the complete portions of the column but only be complete for a few lines of the lines discussed."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Experimental Setup", "text": "The IAM database [33] consists of handwritten English texts copied from the LOB corpus. There are 747 documents (6,482 lines) in the training set, 116 documents (976 lines) in the validation set and 336 documents (2,915 lines) in the test set. The Rimes database [1] contains handwritten letters in French. The data consists of a training set with 1,500 paragraphs (11,333 lines) and a test set with 100 paragraphs (778 lines). We considered the last 100 paragraphs of the training set as validation set.The networks have the following architecture. The encoder first calculates a 2x2-fold flow of the input and alternating MDLSTM layers of 4, 20 and 100 units and 2x4 turns of the training set as validation set.The last layer is a layer with outputs for STR102 and STRM respectively."}, {"heading": "5.2 Impact of the Decoder", "text": "As explained in Section 4.5, the method of weighted collapse is followed by a BLSTM decoder in our model. In this experiment, we compared the basic system (standard collapse followed by a softmax) with the proposed model. To separate the effects of the weighted collapse from those of the BLSTM decoder, we also trained an intermediate architecture with a BLSTM layer after the standard collapse, but still limited ourselves to text lines. Character error rates (CER%) on validation sets are given in Table 1 for 150dpi images. We observe that the proposed model exceeds the baseline by a large distance (relative 20% improvement over IAM, 50% over Rimes) and that the gain is due to both the BLSTM decoder and the attention mechanism."}, {"heading": "5.3 Impact of Line Segmentation", "text": "Our model performs implicit line segmentation to transcribe paragraphs. The baseline considered in the last section is somewhat deceptive because it was evaluated on the basis of baseline segmentation. In this experiment, we add to the comparison the baseline models evaluated in a real scenario, where they are applied to the result of an automatic line segmentation algorithm. In Table 2, we report on the CERs obtained with the baseline positions, with three different segmentation algorithms, and with our end-to-end system obtained validation sets of both databases with different input resolutions. We see that applying baseline networks to automatic segmentation increases error rates, at best by absolute 1%. We also observe that the models with higher resolutions are better. Our models perform better than methods that pay attention to explicit and automatic line segmentation, we show the baseline segmentation is weighted by means of an explicit and automatic line-based segmentation, or better in terms of a corresponding resolution)."}, {"heading": "5.4 Comparison to Published Results", "text": "In this section, we also calculate the word error rates (WHO%) and evaluate our models on the test sets to compare the proposed approach with existing systems. For IAM, we have applied a 3 gram language model with a lexicon of 50,000 words, trained on the LOB, Brown and Wellington Corpora1. This language model has a perplexity of 298 and an OOV rate of 4.3% on the validation set (329 and 3.7% on the test set). Results are presented in Table 3 for Rimes and in Table 4 for IAM, for different input resolutions. When comparing error rates, it is important to note that all systems in the literature used an explicit (basic truth) line segmentation and a language model. [17, 29, 34] used a hybrid sign / word model to address the problem of foreign words."}, {"heading": "6 Discussion", "text": "In fact, it is the case that you will be able to put yourself at the top without being able to do what you have to do in order to do it."}, {"heading": "7 Conclusion", "text": "We presented a model for transcribing complete paragraphs of handwritten texts without explicit line segmentation. Unlike traditional methods based on a two-step process (segment recognition), our system directly takes into account the paragraph image without complex pre-processing and outputs the complete transcription. We proposed a simple modification of the collapse layer in the standard MDLSTM architecture to focus iteratively on individual lines of text. This implicit line segmentation is learned with backpropagation along with the rest of the network to minimize the CTC error at the paragraph level.We reported comparable state-of-the-art error rates in two public databases. After switching from explicit to implicit characters and then word segmentation for handwriting, we showed that line segmentation can also be learned within the transcription model."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Offline handwriting recognition systems require cropped text line images for both<lb>training and recognition. On the one hand, the annotation of position and tran-<lb>script at line level is costly to obtain. On the other hand, automatic line seg-<lb>mentation algorithms are prone to errors, compromising the subsequent recogni-<lb>tion. In this paper, we propose a modification of the popular and efficient multi-<lb>dimensional long short-term memory recurrent neural networks (MDLSTM-<lb>RNNs) to enable end-to-end processing of handwritten paragraphs. More partic-<lb>ularly, we replace the collapse layer transforming the two-dimensional represen-<lb>tation into a sequence of predictions by a recurrent version which can recognize<lb>one line at a time. In the proposed model, a neural network performs a kind of<lb>implicit line segmentation by computing attention weights on the image represen-<lb>tation. The experiments on paragraphs of Rimes and IAM database yield results<lb>that are competitive with those of networks trained at line level, and constitute a<lb>significant step towards end-to-end transcription of full documents.", "creator": "LaTeX with hyperref package"}}}