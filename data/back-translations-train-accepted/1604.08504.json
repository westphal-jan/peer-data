{"id": "1604.08504", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Apr-2016", "title": "Detecting \"Smart\" Spammers On Social Network: A Topic Model Approach", "abstract": "Spammer detection on social network is a challenging problem. The rigid anti-spam rules have resulted in emergence of \"smart\" spammers. They resemble legitimate users who are difficult to identify. In this paper, we present a novel spammer classification approach based on Latent Dirichlet Allocation(LDA), a topic model. Our approach extracts both the local and the global information of topic distribution patterns, which capture the essence of spamming. Tested on one benchmark dataset and one self-collected dataset, our proposed method outperforms other state-of-the-art methods in terms of averaged F1-score.", "histories": [["v1", "Thu, 28 Apr 2016 16:36:35 GMT  (328kb,D)", "http://arxiv.org/abs/1604.08504v1", "NAACL-HLT 2016, Student Research Workshop"], ["v2", "Thu, 9 Jun 2016 06:50:36 GMT  (154kb,D)", "http://arxiv.org/abs/1604.08504v2", "NAACL-HLT 2016, Student Research Workshop"]], "COMMENTS": "NAACL-HLT 2016, Student Research Workshop", "reviews": [], "SUBJECTS": "cs.CL cs.SI", "authors": ["linqing liu", "yao lu", "ye luo", "renxian zhang", "laurent itti", "jianwei lu"], "accepted": true, "id": "1604.08504"}, "pdf": {"name": "1604.08504.pdf", "metadata": {"source": "CRF", "title": "Detecting \"Smart\" Spammers On Social Network: A Topic Model Approach", "authors": ["Linqing Liu", "Yao Lu", "Ye Luo", "Renxian Zhang", "Laurent Itti", "Jianwei Lu"], "emails": ["likicode@gmail.com,", "95luyao@tongji.edu.cn,", "rxzhang@tongji.edu.cn,", "kennyluo2008@hotmail.com,", "jwlu33@hotmail.com,", "itti@usc.edu"], "sections": [{"heading": "1 Introduction", "text": "There are millions of active users on the platform who stay connected to friends. Unfortunately, spammers also use it as a tool to post malicious links, send unsolicited messages to legitimate users, etc. However, a certain amount of spammers could influence public opinion and cause distrust of the social platform. Despite the use of rigid anti-spam rules, the spammers whose homepages contain photos, detailed profiles, etc. have emerged. Unlike previous \"simple\" spammers whose tweets contain only malicious links, these \"smart\" spammers are harder to distinguish from legitimate users through content-based features (Ferrara et al, 2014). Corresponding AuthorThere is a significant amount of previous work on spammer detection on social platforms. Researchers at Twitter Inc. (Chu et al., 2010) collect accounts and conduct analyses of user behavior and profile. Lee et al."}, {"heading": "2 Methodology", "text": "In this section, we first present some of the observations we have made after carefully examining the social network, and then introduce the LDA model. Based on the LDA model, the options for determining the topic probability vector for each user and the two topic-based characteristics are provided."}, {"heading": "2.1 Observation", "text": "After examining the homepages of a significant number of spammers, we have two observations. 1) Social spammers can be divided into two categories: One is the polluter of content, and their tweets revolve around certain types of advertising and campaigns. The other is fake accounts, and their tweets resemble legitimate users, but it seems that they are simply random copies of others so as not to be detected by anti-spam rules. 2) For legitimate users, content polluters and fake accounts focus on a wide range of topics that interest them. \u2022 Legitimate users mainly focus on limited topics that interest them. \u2022 They rarely post content that has nothing to do with their concerns. \u2022 Content polluters focus on specific topics. \u2022 Fake accounts focus on a wide range of topics that arise from random copying and retweeting of other users."}, {"heading": "2.2 LDA model", "text": "Blei et al. (2003) first presented the latent Dirichlet Allocation (LDA) as an example of the theme model. Each document i is considered a bag of words W = {wi1, wi2,..., wiM} and M is the number of words. Each word can be assigned to one of the themes in the document Z = {zi1, zi2,..., ziK} and K is the number of themes. q is a multinomial distribution across words for topic k. \u03b8i is another multinomial distribution across themes for document i. The smoothed generative model is shown in Figure 2. \u03b1 and \u03b2 are hyperparameters that influence the conciseness of the document and the theme-word distributions. In this paper, \u03b1, \u03b2 and K are empirically reduced to 0.3, 0.01 and 15. The entire content of each Twitter user is considered as one document."}, {"heading": "2.3 Topic-based Features", "text": "On the basis of the LDA model, each person in the dataset has a topic probability vector XI. Let's assume that xik-ig-Xi indicates the probability that the ith-Tweet account prefers the kest topic in the dataset. Our topic-related properties can be calculated as equivalents. (1): \"Global Outlier Standard Score\" measures the degree to which a user's tweet content is related to a particular topic compared to the other users. (1) \"GOSS\" value of the user i on the topic k. \"(xk):\" i = 1 xik-n, \"GOSS\" (xik) = xik-ig. \"(xik-topics)\" The value of GOSS (xik) indicates that person's level of interest in the kest topic. Specifically, if GOSS (xik) > GOSS (xik-topics) > xik-ig is that the ith person is more interested in the topic than the jth person."}, {"heading": "3 Dataset", "text": "We use a public dataset Social Honeypot Dataset and a self-collected dataset Weibo Dataset to measure the effectiveness of our proposed features. Social Honeypot Dataset: Lee et al. (2010) creates and deploys 60 seed social accounts on Twitter to attract spammers by reporting back which accounts interact with them. They collected 19,276 legitimate users and 22,223 spammers in their datasets along with their tweet content in 7 months. This is our first trial dataset.Our Weibo Dataset: Sina Weibo is one of the most famous social platforms in China. It has implemented many features of Twitter. The 2197 legitimate user accounts in this dataset are provided by Tianchi Competition1, which is held by Sina Weibo. The spammers are all purchased commercially by multiple sellers on the Internet. We have manually checked them and collected 802 suitable \"smart\" spammers accounts."}, {"heading": "4 Experiment", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Evaluation Metrics", "text": "The evaluation indicators in our model are in Table 2. We calculate accuracy, recall and F1 score (i.e. F1 score) as in Equation (3). Precision is the ratio of selected accounts that are spammers. Recall is the ratio of spammers that are detected this way. F1 score is the harmonious mean of precision and recall. Precision = TPTP + FP, Recall = TPTP + FNF1 \u2212 Score = 2 x precision \u00d7 Recall score + Recall (3)"}, {"heading": "4.2 Performance Comparisons with Baseline", "text": "We test each classification algorithm with scikit-learn (Pedregosa et al., 2011) and perform a 10-fold cross-validation. On each data set, the used classifiers are trained first with individual characteristics and then with the combination of the two characteristics. From Table 1, we can see that GOSS + LOSS achieves the best performance in F1 score of all the others. Furthermore, by combining LOSS and GOSS, classification can increase accuracy by more than 3% compared to the probability of raw topic distribution."}, {"heading": "4.3 Comparison with Other Features", "text": "In order to compare our extracted features with previously used spammer detection features, we use three particularly discriminatory feature sets according to Lee et al. (2011) (Table 4). Two classifiers (Adaboost and SVM) are selected to perform feature performance comparisons. With Adaboost, our LOSS + GOSS features outperform all other features except UFN, which is 2% higher in terms of accuracy on the honeypot record than ours. The best memory value of our LOSS + GOSS features using SVM is up to 6% higher than the results of other feature groups, which is similar to the behaviour of fake accounts. However, based on friendship networks, UFN is more useful for public accounts with a large number of followers. The best memory value of our LOSS + GOSS features using SVM is up to 6% higher than the results of other feature groups in terms of F1-USS outperform all our features."}, {"heading": "5 Conclusion", "text": "In this article, we propose a novel method of feature extraction to effectively detect \"smart\" spammers who post seemingly legitimate tweets and are therefore difficult to identify by existing spamming classification methods. Using the LDA model, we determine the topic probability for each Twitter user. By using the topic probability result, we extract our two topic-based features: GOSS and LOSS, which represent the account with global and local information. Experimental results on a public dataset and a homemade Chinese microblog dataset confirm the effectiveness of the proposed features."}, {"heading": "6 Future Work", "text": "In future work, the combination method of local and global information can be further improved to maximize its individual strengths; we will also apply decision theories to improve the performance of our proposed functions; we will also build larger datasets on Twitter and Weibo to validate our method; and larger datasets will be built on Twitter and Weibo to further validate our method."}], "references": [{"title": "Who is tweeting on twitter: human, bot, or cyborg", "author": ["Chu et al.2010] Zi Chu", "Steven Gianvecchio", "Haining Wang", "Sushil Jajodia"], "venue": "In Proceedings of the 26th annual computer security applications conference,", "citeRegEx": "Chu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Chu et al\\.", "year": 2010}, {"title": "Finding scientific topics", "author": ["Griffiths", "Steyvers2004] Thomas L Griffiths", "Mark Steyvers"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Griffiths et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Griffiths et al\\.", "year": 2004}, {"title": "Social spammer detection in microblogging", "author": ["Hu et al.2013] Xia Hu", "Jiliang Tang", "Yanchao Zhang", "Huan Liu"], "venue": "In Proceedings of the Twenty-Third international joint conference on Artificial Intelligence,", "citeRegEx": "Hu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2013}, {"title": "Devils, angels, and robots: Tempting destructive users in social media", "author": ["Lee et al.2010] Kyumin Lee", "Brian David Eoff", "James Caverlee"], "venue": null, "citeRegEx": "Lee et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2010}, {"title": "Seven months with the devils: A long-term study of content polluters on twitter", "author": ["Lee et al.2011] Kyumin Lee", "Brian David Eoff", "James Caverlee"], "venue": "In ICWSM. Citeseer", "citeRegEx": "Lee et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2011}, {"title": "Sdhm: A hybrid model for spammer detection in weibo", "author": ["Yu Liu", "Bin Wu", "Bai Wang", "Guanchen Li"], "venue": "In Advances in Social Networks Analysis and Mining (ASONAM),", "citeRegEx": "Liu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2014}, {"title": "Making the most of tweet-inherent features for social spam detection on twitter", "author": ["Wang et al.2015] Bo Wang", "Arkaitz Zubiaga", "Maria Liakata", "Rob Procter"], "venue": "arXiv preprint arXiv:1503.07405", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Don\u2019t follow me: Spam detection in twitter. In Security and Cryptography (SECRYPT)", "author": ["Alex Hai Wang"], "venue": "Proceedings of the 2010 International Conference on,", "citeRegEx": "Wang.,? \\Q2010\\E", "shortCiteRegEx": "Wang.", "year": 2010}, {"title": "Die free or live hard? empirical evaluation and new design for fighting evolving twitter spammers", "author": ["Yang et al.2011] Chao Yang", "Robert Chandler Harkreader", "Guofei Gu"], "venue": "In Recent Advances in Intrusion Detection,", "citeRegEx": "Yang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2011}, {"title": "Analyzing spammers\u2019 social networks for fun and profit: a case study of cyber criminal ecosystem on twitter", "author": ["Yang et al.2012] Chao Yang", "Robert Harkreader", "Jialong Zhang", "Seungwon Shin", "Guofei Gu"], "venue": "In Proceedings of the 21st international conference on", "citeRegEx": "Yang et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "(Chu et al., 2010) collect bot accounts and perform analysis on the user behavior and user profile features.", "startOffset": 0, "endOffset": 18}, {"referenceID": 9, "context": "Some researchers focus on the clustering of urls in tweets and network graph of social spammers (Yang et al., 2012; Wang et al., 2015; Wang, 2010; Yang et al., 2011), showing the power of social relationship features.", "startOffset": 96, "endOffset": 165}, {"referenceID": 6, "context": "Some researchers focus on the clustering of urls in tweets and network graph of social spammers (Yang et al., 2012; Wang et al., 2015; Wang, 2010; Yang et al., 2011), showing the power of social relationship features.", "startOffset": 96, "endOffset": 165}, {"referenceID": 7, "context": "Some researchers focus on the clustering of urls in tweets and network graph of social spammers (Yang et al., 2012; Wang et al., 2015; Wang, 2010; Yang et al., 2011), showing the power of social relationship features.", "startOffset": 96, "endOffset": 165}, {"referenceID": 8, "context": "Some researchers focus on the clustering of urls in tweets and network graph of social spammers (Yang et al., 2012; Wang et al., 2015; Wang, 2010; Yang et al., 2011), showing the power of social relationship features.", "startOffset": 96, "endOffset": 165}, {"referenceID": 2, "context": "As for content information modeling, (Hu et al., 2013) apply improved sparse learning methods.", "startOffset": 37, "endOffset": 54}, {"referenceID": 5, "context": "Some researchers (Liu et al., 2014) discuss topic characteristics of spamming posts, indicating that spammers are highly likely to dwell on some certain topics such as promotion.", "startOffset": 17, "endOffset": 35}, {"referenceID": 0, "context": "(Chu et al., 2010) collect bot accounts and perform analysis on the user behavior and user profile features. Lee et al. (2011) use the so-called social honeypot by alluring social spammers\u2019 retweet to build a benchmark dataset, which has been extensively explored in our paper.", "startOffset": 1, "endOffset": 127}, {"referenceID": 3, "context": "Social Honeypot Dataset: Lee et al. (2010) created and deployed 60 seed social accounts on Twitter to attract spammers by reporting back what accounts interact with them.", "startOffset": 25, "endOffset": 43}, {"referenceID": 3, "context": "To compare our extracted features with previously used features for spammer detection, we use three most discriminative feature sets according to Lee et al. (2011)(Table 4).", "startOffset": 146, "endOffset": 164}, {"referenceID": 3, "context": "To compare our extracted features with previously used features for spammer detection, we use three most discriminative feature sets according to Lee et al. (2011)(Table 4). Two classifiers (Adaboost and SVM) are selected to conduct feature performance comparisons. Using Adaboost, our LOSS+GOSS features outperform all other features except for UFN which is 2% higher than ours with regard to precision on the Honeypot dataset. It is caused by the incorrectly classified spammers who are mostly news source after our manual check. They keep posting all kinds of news pieces covering diverse topics, which is similar to the behavior of fake accounts. However, UFN based on friendship networks is more useful for public accounts who possess large number of followers. The best recall value of our LOSS+GOSS features using SVM is up to 6% higher than the results by other feature groups. Regarding F1-score, our features outperform all other features. To further show the advantages of our proposed features, we compare our combined LOSS+GOSS with the combination of all the features from Lee et al. (2011) (UFN+UC+UH).", "startOffset": 146, "endOffset": 1105}], "year": 2017, "abstractText": "Spammer detection on social network is a challenging problem. The rigid anti-spam rules have resulted in emergence of \"smart\" spammers. They resemble legitimate users who are difficult to identify. In this paper, we present a novel spammer classification approach based on Latent Dirichlet Allocation (LDA), a topic model. Our approach extracts both the local and the global information of topic distribution patterns, which capture the essence of spamming. Tested on one benchmark dataset and one self-collected dataset, our proposed method outperforms other stateof-the-art methods in terms of averaged F1score.", "creator": "LaTeX with hyperref package"}}}