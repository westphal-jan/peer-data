{"id": "1604.08772", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Apr-2016", "title": "Towards Conceptual Compression", "abstract": "We introduce a simple recurrent variational auto-encoder architecture that significantly improves image modeling. The system represents the state-of-the-art in latent variable models for both the ImageNet and Omniglot datasets. We show that it naturally separates global conceptual information from lower level details, thus addressing one of the fundamentally desired properties of unsupervised learning. Furthermore, the possibility of restricting ourselves to storing only global information about an image allows us to achieve high quality 'conceptual compression'.", "histories": [["v1", "Fri, 29 Apr 2016 11:02:52 GMT  (8449kb,D)", "http://arxiv.org/abs/1604.08772v1", "14 pages, 13 figures"]], "COMMENTS": "14 pages, 13 figures", "reviews": [], "SUBJECTS": "stat.ML cs.CV cs.LG", "authors": ["karol gregor", "frederic besse", "danilo jimenez rezende", "ivo danihelka", "daan wierstra"], "accepted": true, "id": "1604.08772"}, "pdf": {"name": "1604.08772.pdf", "metadata": {"source": "META", "title": "Towards Conceptual Compression", "authors": ["Karol Gregor", "Frederic Besse", "Danilo Jimenez Rezende", "Ivo Danihelka", "Daan Wierstra"], "emails": ["KAROLG@GOOGLE.COM", "FBESSE@GOOGLE.COM", "DANILOR@GOOGLE.COM", "DANIHELKA@GOOGLE.COM", "WIERSTRA@GOOGLE.COM"], "sections": [{"heading": "1. Introduction", "text": "In this paper, we propose a method that is capable of transforming an image into a progression of ever more detailed representations, ranging from global aspects to low details (see Figures 1 and 2), while improving the latent variability of image modeling compared to previous implementations of definitions of definitions."}, {"heading": "1.1. Variational Auto-Encoders", "text": "There are numerous techniques for unsupervised learning in deep networks, such as sparse auto encoders and sparse encoding (Kavukcuoglu et al., 2010; Le., 2013), denociation of auto encoders (Vincent et al., 2010), deconvolutionary networks (Goodfellow et al., 2010), limited Boltzmann machines (Hinton & Salakhutdinov, 2006), deep Boltzmann machines (Salakhutdinov & Hinton, 2009), generative adversarial networks (Goodfellow et al., 2014) and variant auto encoders (Kingma & Welling, 2014; Rezende et al., 2014). In this paper, we focus on the class of automatic encoding models (Goodfellow et al., 2014) and we are also interested in forced networking."}, {"heading": "1.2. Conceptual Compression", "text": "This year we have reached the point where we will be able to try to find a solution that we are able to find, that we will try to find a solution."}, {"heading": "1.3. The Importance of Recurrent Feedback", "text": "What are the challenges involved in converting latently variable models into state-of-the-art generative models of images? Many successful vision architectures (e.g. Simonyan & Zisserman, 2014) have highly supercomplete representations that contain many more neurons in hidden layers than pixels, but these representations need to be combined to obtain a very sharp distribution at the pixel level when the pixels are modeled independently, a distribution equivalent to salt and pepper noise that is not present in natural images on a perceptible plane."}, {"heading": "1.4. Comparison to Non-variational Models", "text": "In fact, the fact is that most of them will be able to demonstrate that they are able to achieve their objectives, including the way in which they are put into practice."}, {"heading": "2. Convolutional DRAW", "text": "In this section we describe the details of a single-layer version of the algorithm. Convolutional DRAW = = Voluminous DRAW contains the following variables: input x, reconstruction r, reconstruction error, state of the encoder recursive net er, state of the decoder recursive net HD and latent variable z. The variables er, hd and r are recursive (passed between different time steps) and are initialized with learned distortions. Then, in each time step. {1, T}, Convolutionary DRAW performs the following updates: = x \u2212 r (1) er = Rnn (x, er, hd) x (2) z \u00b2 q (z | er) p = p (4), Convolutionary DRAW = Rnn (z) (5) r = r + Whd (6) Lzt = KL (q | p)."}, {"heading": "2.1. Multi-layer Architectures", "text": "The second layer has the same structure: recursive encoder, recursive decoder and a stochastic layer. The input into the second layer is the mean value of the approximate posterior of the first layer. The output of the second layer distorts the state of the latent variables of the first layer and is also passed on as input into the first layer of the decoder. This is shown in Figure 3. We do not use reconstruction or errors in the second layer. Here, we describe a given calculation step in detail. Indexes 1 and 2 denote the variables of the layers 1 and 2, respectively. We also allow \u00b51 (q1) (1) (2) to be the mean of q1 (q1). Then the date at a given time step is given by = x \u2212 r (12) heddn = Rnn (x, h, qh, 1 qh Systems (q1) q1 (q1) (1) (1) (1) (2) 1 (2) p = 2 (2)."}, {"heading": "3. Compression", "text": "rrf\u00fc ide eeisrrrrrcnlehecehecehecehecehecehnlrreceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheeheceheceheceheceheceheeheceheceheeheceheeheceheceheeheceheceheceheceheceheceheceheeheceheceheceheceheeheceheceheceheceheceheeheceheceheceheceheceheceheceheeheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheceheeeceheceheeee"}, {"heading": "4. Results", "text": "We trained the models on Cifar-10 and ImageNet with 320 and 160 LSTM feature maps, respectively. We use the version of ImageNet presented in (van den Oord et al., 2016), which will soon be published as a standard dataset. We train the network using the Adam algorithm (Kingma & Ba, 2014) with a learning rate of 5 x 10 \u2212 4. Occasionally, we find that the costs suddenly increase dramatically, probably due to the Gaussian nature of the distribution when a given variable is produced too far from the mean in relation to Sigma. We observed this about once per run. To maintain the training, we store older parameters, detect such jumps, and return to the old parameters when they occur. Then, the network just holds on as if nothing happened."}, {"heading": "4.1. Modeling Quality", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1. OMNIGLOT", "text": "The recently introduced Omniglot dataset (Lake et al., 2015) consists of 1628 character classes of multiple alphabets with only 20 samples per class. Dubbed by many as the \"inverse of MNIST,\" it is designed to examine conceptual representations and generative models in a low-data regime. Table 1 shows probabilities of different models compared to ours. For our model, we only calculate the upper limit (variation limit), so the actual probability is actually better."}, {"heading": "4.1.2. CIFAR-10", "text": "Table 2 shows probabilities of different models on Cifar-10. We see that our method outperforms previous methods with the exception of the just published pixel RNN model (van den Oord et al., 2016). As already mentioned, the advantage of our model over such auto-regressive models is that it is a latent variable model that can be used for imaging learning and lossy compression. At the same time, the two approaches are orthogonal and can be combined, for example, by feeding the output of revolutionary DRAW into the recursive network of pixel RNN. We also report on the probability of a (non-recursive) variant auto-encoder and standard DRAW. For the variational auto-encoder, we tested architectures with multiple layers, both deterministic and stochastic, but with standard functional forms, and this was the best result we achieved."}, {"heading": "4.1.3. IMAGENET", "text": "The results are in Table 3. Note that no other methods have been reported on the new dataset. In Figure 6 and Figure 7 we show generations of the model. We trained networks with different input cost scales, as explained in the next section. Generations are sharp and contain many details, unlike previous versions of varying auto-encoders, which tend to produce blurred images."}, {"heading": "4.2. Input Cost Scaling", "text": "Each pixel (and color channel) of the data consists of 256 values, and as such, probability and lossless compression are clearly defined. In compressing the image, there is much to be gained by capturing precise correlations between nearby pixels. There are many more bits in these details at the low level than in the higher level structure that we are actually interested in when we learn higher level reprints. The network could focus on these details and ignore higher structures. One way to focus it less on detail is to reduce the cost of input relative to latents, i.e. \u03b2 < 1 in (11). Generations of different cost scales are shown in Figure 6, with the original goal being scale \u03b2 = 1. We see that lower scales actually have a \"cleaner\" high-level structure. Scale 1 contains a lot of information about the exact pixel values, and the network tries to capture this, although it is not realistic enough to produce and correct patterns."}, {"heading": "4.3. The Dependence on Computational Depth", "text": "However, we found that networks with a larger number of time steps per data sample train faster, as shown in Figure 8 (left). To investigate how they train in real time, we multiply the time scale of each input by the number of iterations as shown in Figure 8 (right). We see that despite multiple iterations, the Convolutionary DRAW does not take more time to train up to about nt < 16 than the same architecture with a smaller one. If larger, the training slows down, but ultimately performs better than if smaller."}, {"heading": "32\u00d7 32 Method NLL Validation (Train)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.4. Information Distribution", "text": "This information is only the KL divergence in (7) and (22). For a two-layer system with a twisted and fully bonded layer, this is shown in Figure 9.We see that the higher layer contains information mainly at the beginning of the calculation, while the lower layer begins with little information, which then gradually increases. This is desirable from a conceptual point of view. It suggests that the network first finds out about the overall structure of the image and then explains the details contained in that structure. A quick understanding of the overall structure is also useful when the algorithm needs to react promptly to observations."}, {"heading": "4.5. Lossy Compression", "text": "We can create an image with a loss of information by storing only a subset of latent variables, typically the high levels of the hierarchy. We can do this in multi-layered convolutional DRAW, storing only higher levels. However, we can also only do a subset of time steps at the beginning, and let the network's rest.The units that are not stored should be generated by the priority (Eq.4). But we can also generate a more likely image by changing the variance of the previous Gaussian. We show generations with full variance in the row 3 of Figure 4 and with zero variance in the row 4 of the figure. We see that with the original variance the network generates sharp details is not perfect, the resulting images are less realistic, since the resulting images are less realistic than we have the number of stored images in the series 3."}, {"heading": "5. Conclusion", "text": "In this paper, we introduced the Convolutionary DRAW, a state-of-the-art generative model that demonstrates the potential of sequential computation and recurrent neural networks in scaling latent variable models. Consequently, the algorithm arrives at a natural stratification of information, ranging from global aspects to low-level details, sequentially. An interesting feature of the method is that, if we limit ourselves to storing only the latent variables at the high level, we arrive at a \"conceptual compression algorithm\" that competes with the quality of JPEG2000. As a generative model, it surpasses previous latent variable models on both the Omniglot and the ImageNet dataset."}, {"heading": "Acknowledgements", "text": "We thank Aaron van den Oord, Diederik Kingma and Koray Kavukcuoglu for fruitful discussions."}], "references": [{"title": "Modeling highdimensional discrete data with multi-layer neural networks", "author": ["Bengio", "Yoshua", "Samy"], "venue": "In NIPS,", "citeRegEx": "Bengio et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1999}, {"title": "Deep generative image models using a Laplacian pyramid of adversarial networks", "author": ["Denton", "Emily L", "Chintala", "Soumith", "Fergus", "Rob"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Denton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Denton et al\\.", "year": 2015}, {"title": "Nice: Non-linear independent components estimation", "author": ["Dinh", "Laurent", "Krueger", "David", "Bengio", "Yoshua"], "venue": "arXiv preprint arXiv:1410.8516,", "citeRegEx": "Dinh et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dinh et al\\.", "year": 2014}, {"title": "Generative adversarial nets", "author": ["Goodfellow", "Ian", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Offline handwriting recognition with multidimensional recurrent neural networks", "author": ["Graves", "Alex", "Schmidhuber", "J\u00fcrgen"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Graves et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2009}, {"title": "Learning representations by maximizing compression", "author": ["Gregor", "Karol", "LeCun", "Yann"], "venue": "arXiv preprint arXiv:1108.1169,", "citeRegEx": "Gregor et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2011}, {"title": "Deep autoregressive networks", "author": ["Gregor", "Karol", "Danihelka", "Ivo", "Mnih", "Andriy", "Blundell", "Charles", "Wierstra", "Daan"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "Gregor et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2014}, {"title": "Draw: A recurrent neural network for image generation", "author": ["Gregor", "Karol", "Danihelka", "Ivo", "Graves", "Alex", "Rezende", "Danilo Jimenez", "Wierstra", "Daan"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning,", "citeRegEx": "Gregor et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2015}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["Hinton", "Geoffrey E", "Salakhutdinov", "Ruslan R"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Keeping the neural networks simple by minimizing the description length of the weights", "author": ["Hinton", "Geoffrey E", "Van Camp", "Drew"], "venue": "In Proceedings of the sixth annual conference on Computational learning theory,", "citeRegEx": "Hinton et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 1993}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Learning convolutional feature hierarchies for visual recognition", "author": ["Kavukcuoglu", "Koray", "Sermanet", "Pierre", "Boureau", "Y-Lan", "Gregor", "Karol", "Mathieu", "Micha\u00ebl", "LeCun", "Yann"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Kavukcuoglu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kavukcuoglu et al\\.", "year": 2010}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["Kingma", "Diederik P", "Welling", "Max"], "venue": "In Proceedings of the International Conference on Learning Representations (ICLR),", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Lake", "Brenden M", "Salakhutdinov", "Ruslan", "Tenenbaum", "Joshua B"], "venue": null, "citeRegEx": "Lake et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2015}, {"title": "The neural autoregressive distribution estimator", "author": ["Larochelle", "Hugo", "Murray", "Iain"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Larochelle et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Larochelle et al\\.", "year": 2011}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Le", "Quoc V"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Le and V.,? \\Q2013\\E", "shortCiteRegEx": "Le and V.", "year": 2013}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Radford", "Alec", "Metz", "Luke", "Chintala", "Soumith"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Rezende", "Danilo J", "Mohamed", "Shakir", "Wierstra", "Daan"], "venue": "In Proceedings of the 31st International Conference on Machine Learning,", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Deep boltzmann machines", "author": ["Salakhutdinov", "Ruslan", "Hinton", "Geoffrey E"], "venue": "In International Conference on Artificial Intelligence and Statistics, pp", "citeRegEx": "Salakhutdinov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Salakhutdinov et al\\.", "year": 2009}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Deep unsupervised learning using nonequilibrium thermodynamics", "author": ["Sohl-Dickstein", "Jascha", "Weiss", "Eric A", "Maheswaranathan", "Niru", "Ganguli", "Surya"], "venue": "arXiv preprint arXiv:1503.03585,", "citeRegEx": "Sohl.Dickstein et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sohl.Dickstein et al\\.", "year": 2015}, {"title": "Factoring variations in natural images with deep gaussian mixture models", "author": ["van den Oord", "Aaron", "Schrauwen", "Benjamin"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Oord et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Oord et al\\.", "year": 2014}, {"title": "Pixel recurrent neural networks", "author": ["van den Oord", "Aaron", "Kalchbrenner", "Nal", "Kavukcuoglu", "Koray"], "venue": "arXiv preprint arXiv:1601.06759,", "citeRegEx": "Oord et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Oord et al\\.", "year": 2016}, {"title": "Arithmetic coding for data compression", "author": ["Witten", "Ian H", "Neal", "Radford M", "Cleary", "John G"], "venue": "Communications of the ACM,", "citeRegEx": "Witten et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Witten et al\\.", "year": 1987}, {"title": "Deconvolutional networks", "author": ["Zeiler", "Matthew D", "Krishnan", "Dilip", "Taylor", "Graham W", "Fergus", "Rob"], "venue": "In Computer Vision and Pattern Recognition (CVPR),", "citeRegEx": "Zeiler et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 18, "context": "At the same time, our model greatly improves latent variable image modeling compared to earlier implementations of deep variational auto-encoders (Kingma & Welling, 2014; Rezende et al., 2014; Gregor et al., 2014).", "startOffset": 146, "endOffset": 213}, {"referenceID": 6, "context": "At the same time, our model greatly improves latent variable image modeling compared to earlier implementations of deep variational auto-encoders (Kingma & Welling, 2014; Rezende et al., 2014; Gregor et al., 2014).", "startOffset": 146, "endOffset": 213}, {"referenceID": 7, "context": "Furthermore, it has the advantage of being a simple homogeneous architecture not requiring complex design choices, which is similar to the recurrent structure of DRAW (Gregor et al., 2015).", "startOffset": 167, "endOffset": 188}, {"referenceID": 11, "context": "sparse auto-encoders and sparse coding (Kavukcuoglu et al., 2010; Le, 2013), denoising autoencoders (Vincent et al.", "startOffset": 39, "endOffset": 75}, {"referenceID": 25, "context": ", 2010), deconvolutional networks (Zeiler et al., 2010), restricted Boltzmann machines (Hinton & Salakhutdinov, 2006), deep Boltzmann machines (Salakhutdinov & Hinton, 2009), generative adversarial networks (Goodfellow et al.", "startOffset": 34, "endOffset": 55}, {"referenceID": 3, "context": ", 2010), restricted Boltzmann machines (Hinton & Salakhutdinov, 2006), deep Boltzmann machines (Salakhutdinov & Hinton, 2009), generative adversarial networks (Goodfellow et al., 2014) and variational autoencoders (Kingma & Welling, 2014; Rezende et al.", "startOffset": 159, "endOffset": 184}, {"referenceID": 18, "context": ", 2014) and variational autoencoders (Kingma & Welling, 2014; Rezende et al., 2014; Gregor et al., 2014).", "startOffset": 37, "endOffset": 104}, {"referenceID": 6, "context": ", 2014) and variational autoencoders (Kingma & Welling, 2014; Rezende et al., 2014; Gregor et al., 2014).", "startOffset": 37, "endOffset": 104}, {"referenceID": 7, "context": "Such a mechanism is provided by the DRAW algorithm (Gregor et al., 2015), which is a recurrent type of variational auto-encoder.", "startOffset": 51, "endOffset": 72}, {"referenceID": 6, "context": "We also experiment with making convolutional DRAW hierarchical in a similar way that we would build conventional deep variational auto-encoders (Gregor et al., 2014) \u2013 stacking more layers of latent and deterministic variables.", "startOffset": 144, "endOffset": 165}, {"referenceID": 1, "context": "GANs have been demonstrated to be able to generate realistic looking images (Denton et al., 2015; Radford et al., 2015), with properly aligned edges, using a simple feedforward generative network (Radford et al.", "startOffset": 76, "endOffset": 119}, {"referenceID": 17, "context": "GANs have been demonstrated to be able to generate realistic looking images (Denton et al., 2015; Radford et al., 2015), with properly aligned edges, using a simple feedforward generative network (Radford et al.", "startOffset": 76, "endOffset": 119}, {"referenceID": 17, "context": ", 2015), with properly aligned edges, using a simple feedforward generative network (Radford et al., 2015).", "startOffset": 84, "endOffset": 106}, {"referenceID": 17, "context": "as in (Radford et al., 2015), to obtain sufficient image diversity.", "startOffset": 6, "endOffset": 28}, {"referenceID": 2, "context": "Let us relate this discussion to two other families of generative models, specifically generative adversarial networks (GANs; Goodfellow et al. (2014)) and auto-regressive pixel models.", "startOffset": 126, "endOffset": 151}, {"referenceID": 18, "context": "Stochastic back-propagation through a sampling function is done as in variational auto-encoders (Kingma & Welling, 2014; Rezende et al., 2014).", "startOffset": 96, "endOffset": 142}, {"referenceID": 24, "context": "The underlying compression mechanism for all cases is arithmetic coding (Witten et al., 1987).", "startOffset": 72, "endOffset": 93}, {"referenceID": 14, "context": "The recently introduced Omniglot dataset (Lake et al., 2015) is comprised of 1628 character classes drawn from multiple alphabets with just 20 samples per class.", "startOffset": 41, "endOffset": 60}, {"referenceID": 2, "context": "[1] (Dinh et al., 2014), [2] (Sohl-Dickstein et al.", "startOffset": 4, "endOffset": 23}, {"referenceID": 21, "context": ", 2014), [2] (Sohl-Dickstein et al., 2015), [3] (van den Oord & Schrauwen, 2014), [4] (van den Oord et al.", "startOffset": 13, "endOffset": 42}], "year": 2016, "abstractText": "We introduce a simple recurrent variational autoencoder architecture that significantly improves image modeling. The system represents the stateof-the-art in latent variable models for both the ImageNet and Omniglot datasets. We show that it naturally separates global conceptual information from lower level details, thus addressing one of the fundamentally desired properties of unsupervised learning. Furthermore, the possibility of restricting ourselves to storing only global information about an image allows us to achieve high quality \u2018conceptual compression\u2019.", "creator": "LaTeX with hyperref package"}}}