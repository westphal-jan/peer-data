{"id": "1605.03529", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2016", "title": "On the Iteration Complexity of Oblivious First-Order Optimization Algorithms", "abstract": "We consider a broad class of first-order optimization algorithms which are \\emph{oblivious}, in the sense that their step sizes are scheduled regardless of the function under consideration, except for limited side-information such as smoothness or strong convexity parameters. With the knowledge of these two parameters, we show that any such algorithm attains an iteration complexity lower bound of $\\Omega(\\sqrt{L/\\epsilon})$ for $L$-smooth convex functions, and $\\tilde{\\Omega}(\\sqrt{L/\\mu}\\ln(1/\\epsilon))$ for $L$-smooth $\\mu$-strongly convex functions. These lower bounds are stronger than those in the traditional oracle model, as they hold independently of the dimension. To attain these, we abandon the oracle model in favor of a structure-based approach which builds upon a framework recently proposed in (Arjevani et al., 2015). We further show that without knowing the strong convexity parameter, it is impossible to attain an iteration complexity better than $\\tilde{\\Omega}\\left((L/\\mu)\\ln(1/\\epsilon)\\right)$. This result is then used to formalize an observation regarding $L$-smooth convex functions, namely, that the iteration complexity of algorithms employing time-invariant step sizes must be at least $\\Omega(L/\\epsilon)$.", "histories": [["v1", "Wed, 11 May 2016 17:30:08 GMT  (23kb)", "http://arxiv.org/abs/1605.03529v1", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG", "authors": ["yossi arjevani", "ohad shamir"], "accepted": true, "id": "1605.03529"}, "pdf": {"name": "1605.03529.pdf", "metadata": {"source": "CRF", "title": "On the Iteration Complexity of Oblivious First-Order Optimization Algorithms", "authors": ["Yossi Arjevani"], "emails": ["yossi.arjevani@weizmann.ac.il", "ohad.shamir@weizmann.ac.il"], "sections": [{"heading": null, "text": "ar Xiv: 160 5.03 529v 1 [mat h.O C] 11 M \u221a L / \u0442) for L-smooth convex functions, and B-smooth convex functions. These lower limits are stronger than those in the traditional oracle model, since they are independent of dimension. To achieve these, we abandon the oracle model in favor of a structure-based approach based on a framework recently proposed in [1]. We also show that without knowledge of the strong convexity parameter, it is impossible to achieve iteration complexity better than iteration complexity using time-invariant step sizes. This result is then used to formalize an observation regarding L-smooth convex functions, namely that the iteration complexity of algorithms using time-invariant step sizes must be at least L-convex."}, {"heading": "1 Introduction", "text": "The ever-increasing usefulness of mathematical optimization in machine learning and other areas has led to a great interest in understanding the mathematical limits of solving optimization problems."}, {"heading": "2 Framework", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Definitions", "text": "We begin with a precise definition of a class of optimization problems that are accompanied by some kind of optimization problems. (F, I) The domain of functions in F, I), where we consider a family of functions that are defined via the same domain, and I: F, I, I, I, I, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E"}, {"heading": "4 Side-Information in Oblivious Optimization", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 No Strong Convexity Parameter, No Acceleration", "text": "In particular, we show that the ability of oblivious p-CLIs to maintain the complexity of iteration, in the sense that stationary p-CLIs cannot obtain an iteration of the complexity of the function taking into account, iteration is not strongly convex functions, in the sense that stationary p-CLIs cannot obtain an iteration of the complexity of the function. The fact that reducing the number of page information increases the number of page information is the best demon-strated by a family of square functions that we have previously discussed, namely x-x-x, where Q-Rd-d is positive."}, {"heading": "4.2 No Acceleration for Stationary Algorithms over Smooth Convex Functions", "text": "This is an interesting consequence of the fact that some current methods for minimizing finite sums of functions such as SAG and SAGA (which are actually stationary p-CLIs) may not be optimal in this setting, and that timechanging coefficients are indispensable for achieving optimal prices, which motivates the use of current acceleration programs (e.g. [6, 10]) that transform a given stationary algorithm into a non-stationary oblivion. Evidence of this result is based on a reduction in the class of p-CLIs via L-CLIs via L-CLIs via L-CLIs, where the strong convex function is explicitly given."}, {"heading": "5 Summary", "text": "In this paper, we propose the framework of best-in-class p-CLIs and show that it can be efficiently used to deduce the limits of the iteration complexity of a broad class of optimization algorithms, namely obscene, possibly stochastic p-CLIs over smooth and strongly convex functions. We believe that these results are only the tip of the iceberg, and the generality that this framework provides can be successfully applied to many other classes of algorithms. For example, it is easy to deduce a lower limit for 1-CLIs over 1-CLIs over 1-Lipschitz (possibly non-smooth) convex functions by using the following feature set: \"x-c-c-c-c-c-Rd.\" How to deduce a lower limit for other types of p-CLIs in the non-smooth environment is left to future work."}, {"heading": "A Proofs", "text": "The proof for theorem 1Let us apply the given oblivious p-CLI algorithm = Then (Q = q = q = q = q function of the formf: Rd \u2192 R: x 7 \u2192 1 2 x Qx + q x, where Q = diag (\u03b7,.., \u03b7) and q = \u2212 v\u03b7 for any case numbers [\u00b5, L] and v 6 = 0 \u00b2 Rd. In particular, we have that the standard of the unique minimizer is the same in every case. (K) ij, B \u2212 Q \u2212 1q. We set the initialization points to zero, i.e., Exj = 0, j = 1, p, and denote the corresponding coefficients of A (k) ij, B (k) ij, Rd \u00b7 d. The crux of the evidence is that as long as it lies in [\u00b5, L] the lateral information {\u00b5, L} remains consistent, and therefore, the coefficients remain unchanged."}, {"heading": "B Technical Lemmas", "text": "In the following, we provide 3 lemmata used to calculate the quantity | s = q = q = q = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p p = p (p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p = p"}], "references": [{"title": "On lower and upper bounds for smooth and strongly convex optimization problems", "author": ["Yossi Arjevani", "Shai Shalev-Shwartz", "Ohad Shamir"], "venue": "arXiv preprint arXiv:1503.06833,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Algorithms and theory of computation handbook", "author": ["Mikhail J Atallah"], "venue": "CRC press,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1998}, {"title": "Saga: A fast incremental gradient method with support for non-strongly convex composite objectives", "author": ["Aaron Defazio", "Francis Bach", "Simon Lacoste-Julien"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2014}, {"title": "Contributions to the Complexity Analysis of Optimization Algorithms", "author": ["Yoel Drori"], "venue": "PhD thesis, Tel-Aviv University,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "From averaging to acceleration, there is only a step-size", "author": ["Nicolas Flammarion", "Francis Bach"], "venue": "arXiv preprint arXiv:1504.01577,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization", "author": ["Roy Frostig", "Rong Ge", "Sham M Kakade", "Aaron Sidford"], "venue": "arXiv preprint arXiv:1506.07512,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Analysis and design of optimization algorithms via integral quadratic constraints", "author": ["Laurent Lessard", "Benjamin Recht", "Andrew Packard"], "venue": "arXiv preprint arXiv:1408.3595,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "On an algorithm for the minimization of convex functions", "author": ["A Yu Levin"], "venue": "In Soviet Mathematics Doklady,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1965}, {"title": "A universal catalyst for first-order optimization", "author": ["Hongzhou Lin", "Julien Mairal", "Zaid Harchaoui"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Problem complexity and method efficiency in optimization", "author": ["AS Nemirovsky", "DB Yudin"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1983}, {"title": "A method of solving a convex programming problem with convergence rate O (1/k2)", "author": ["Yurii Nesterov"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1983}, {"title": "Introductory lectures on convex optimization, volume 87", "author": ["Yurii Nesterov"], "venue": "Springer Science & Business Media,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2004}, {"title": "Location of the maximum on unimodal surfaces", "author": ["Donald J Newman"], "venue": "Journal of the ACM (JACM),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1965}, {"title": "Introduction to optimization", "author": ["Boris T Polyak"], "venue": "Optimization Software New York,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1987}, {"title": "Minimizing finite sums with the stochastic average gradient", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "arXiv preprint arXiv:1309.2388,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Sdca without duality", "author": ["Shai Shalev-Shwartz"], "venue": "arXiv preprint arXiv:1502.06177,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Stochastic dual coordinate ascent methods for regularized loss", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2013}], "referenceMentions": [{"referenceID": 0, "context": "To attain these, we abandon the oracle model in favor of a structure-based approach which builds upon a framework recently proposed in [1].", "startOffset": 135, "endOffset": 138}, {"referenceID": 10, "context": "In their seminal work, Nemirovsky and Yudin [11] showed that for any first-order optimization algorithm, there exists an L-smooth and \u03bc-strongly convex function f : Rd \u2192 R such that the number of queries required to obtain an \u01eb-optimal solution x\u0303 which satisfies f(x\u0303) < min x\u2208Rd f(x) + \u01eb, is at least1 \u03a9\u0303 (", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "Concretely, it is achieved by a combination of Nesterov\u2019s well-known accelerated gradient descent (AGD, [12]) with an iteration complexity of \u00d5 (\u221a \u03ba ln(1/\u01eb) )", "startOffset": 104, "endOffset": 108}, {"referenceID": 8, "context": ", \u03bc = 0, and the center of gravity method (MCG, [9, 14]) whose iteration complexity is O(d ln(1/\u01eb)).", "startOffset": 48, "endOffset": 55}, {"referenceID": 13, "context": ", \u03bc = 0, and the center of gravity method (MCG, [9, 14]) whose iteration complexity is O(d ln(1/\u01eb)).", "startOffset": 48, "endOffset": 55}, {"referenceID": 0, "context": "To overcome this issue [1] recently proposed the framework of p-Stationary Canonical Linear Iterative (p-SCLI) in which, instead of modeling the way algorithms acquire information on the function at hand, one assumes certain dynamics which restricts the way new iterates are being generated.", "startOffset": 23, "endOffset": 26}, {"referenceID": 0, "context": "Nevertheless, [1] showed that this bound is actually tight for all p.", "startOffset": 14, "endOffset": 17}, {"referenceID": 0, "context": "\u2022 The formulation suggested in [1] does not allow generating more than one iterate at a time.", "startOffset": 31, "endOffset": 34}, {"referenceID": 0, "context": "\u2022 Lastly, whereas the proofs in [1] are elaborate and technically complex, the proofs we provide here are relatively short and simple.", "startOffset": 32, "endOffset": 35}, {"referenceID": 12, "context": "Another important example is a stationary variant of AGD [13] and the heavy-ball method (e.", "startOffset": 57, "endOffset": 61}, {"referenceID": 14, "context": ", [16]) which generates iterates according to", "startOffset": 2, "endOffset": 6}, {"referenceID": 15, "context": ", Stochastic Average Gradient (SAG, [17]), Stochastic Variance Reduction Gradient (SVRG, [7]), Stochastic Dual Coordinate Ascent (SDCA, [19]), Stochastic Dual Coordinate Ascent without Duality (SDCA without duality, [18]) and SAGA [3], to name a few, and as such, are subject to the same lower bounds established through this framework.", "startOffset": 36, "endOffset": 40}, {"referenceID": 6, "context": ", Stochastic Average Gradient (SAG, [17]), Stochastic Variance Reduction Gradient (SVRG, [7]), Stochastic Dual Coordinate Ascent (SDCA, [19]), Stochastic Dual Coordinate Ascent without Duality (SDCA without duality, [18]) and SAGA [3], to name a few, and as such, are subject to the same lower bounds established through this framework.", "startOffset": 89, "endOffset": 92}, {"referenceID": 17, "context": ", Stochastic Average Gradient (SAG, [17]), Stochastic Variance Reduction Gradient (SVRG, [7]), Stochastic Dual Coordinate Ascent (SDCA, [19]), Stochastic Dual Coordinate Ascent without Duality (SDCA without duality, [18]) and SAGA [3], to name a few, and as such, are subject to the same lower bounds established through this framework.", "startOffset": 136, "endOffset": 140}, {"referenceID": 16, "context": ", Stochastic Average Gradient (SAG, [17]), Stochastic Variance Reduction Gradient (SVRG, [7]), Stochastic Dual Coordinate Ascent (SDCA, [19]), Stochastic Dual Coordinate Ascent without Duality (SDCA without duality, [18]) and SAGA [3], to name a few, and as such, are subject to the same lower bounds established through this framework.", "startOffset": 216, "endOffset": 220}, {"referenceID": 2, "context": ", Stochastic Average Gradient (SAG, [17]), Stochastic Variance Reduction Gradient (SVRG, [7]), Stochastic Dual Coordinate Ascent (SDCA, [19]), Stochastic Dual Coordinate Ascent without Duality (SDCA without duality, [18]) and SAGA [3], to name a few, and as such, are subject to the same lower bounds established through this framework.", "startOffset": 231, "endOffset": 234}, {"referenceID": 14, "context": "Finally, we remark that this approach of modeling the structure of optimization algorithms, as opposed to the more traditional oracle model, can be also found in [16, 8, 5, 4].", "startOffset": 162, "endOffset": 175}, {"referenceID": 7, "context": "Finally, we remark that this approach of modeling the structure of optimization algorithms, as opposed to the more traditional oracle model, can be also found in [16, 8, 5, 4].", "startOffset": 162, "endOffset": 175}, {"referenceID": 4, "context": "Finally, we remark that this approach of modeling the structure of optimization algorithms, as opposed to the more traditional oracle model, can be also found in [16, 8, 5, 4].", "startOffset": 162, "endOffset": 175}, {"referenceID": 3, "context": "Finally, we remark that this approach of modeling the structure of optimization algorithms, as opposed to the more traditional oracle model, can be also found in [16, 8, 5, 4].", "startOffset": 162, "endOffset": 175}, {"referenceID": 0, "context": "1, we propose a novel framework which substantially generalizes the framework introduced in [1], and includes a large part of modern first-order optimization algorithms.", "startOffset": 92, "endOffset": 95}, {"referenceID": 0, "context": "We improve upon [1] by establishing lower bounds which hold both for smooth functions and smooth and strongly convex functions, using simpler and shorter proofs.", "startOffset": 16, "endOffset": 19}, {"referenceID": 15, "context": "See Section 3 in [17] and Section 5 in [3]).", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "See Section 3 in [17] and Section 5 in [3]).", "startOffset": 39, "endOffset": 42}, {"referenceID": 5, "context": "Acceleration schemes, such as [6, 10], are able to break this bound by re-scheduling these algorithms in a non-stationary (though oblivious) way.", "startOffset": 30, "endOffset": 37}, {"referenceID": 9, "context": "Acceleration schemes, such as [6, 10], are able to break this bound by re-scheduling these algorithms in a non-stationary (though oblivious) way.", "startOffset": 30, "endOffset": 37}, {"referenceID": 12, "context": "Notable stationary p-CLIs are: GD with fixed step size [13], stationary AGD [13] and the Heavy-Ball method [16].", "startOffset": 55, "endOffset": 59}, {"referenceID": 12, "context": "Notable stationary p-CLIs are: GD with fixed step size [13], stationary AGD [13] and the Heavy-Ball method [16].", "startOffset": 76, "endOffset": 80}, {"referenceID": 14, "context": "Notable stationary p-CLIs are: GD with fixed step size [13], stationary AGD [13] and the Heavy-Ball method [16].", "startOffset": 107, "endOffset": 111}, {"referenceID": 12, "context": "Notable algorithms here are GD and AGD with step sizes which are scheduled irrespectively of the function under consideration [13] and the Sub-Gradient Descent method (e.", "startOffset": 126, "endOffset": 130}, {"referenceID": 1, "context": ", [2]), will not be further considered in this paper.", "startOffset": 2, "endOffset": 5}, {"referenceID": 0, "context": "L/\u01eb), \u03bc = 0, where \u03ba := L/\u03bc As discussed in the introduction, Theorem 1 significantly improves upon the lower obtained by [1] in 3 major aspects: \u2022 It holds for both smooth functions, as well as smooth and strongly convex functions.", "startOffset": 122, "endOffset": 125}, {"referenceID": 0, "context": "See Theorem 8, [1]).", "startOffset": 15, "endOffset": 18}, {"referenceID": 10, "context": "The idea of reducing optimization bounds to polynomial approximation problems is not new, and is also found for instance in [11], where lower bounds under the oracle model are derived.", "startOffset": 124, "endOffset": 128}, {"referenceID": 12, "context": "It is instructive to contrast our approach with another structural approach for deriving lower bounds which was proposed by [13].", "startOffset": 124, "endOffset": 128}, {"referenceID": 12, "context": "Nesterov [13] considerably simplifies the technique employed by Nemirovsky and Yudin [11] at the cost of introducing additional assumption regarding the way new iterates are generated.", "startOffset": 9, "endOffset": 13}, {"referenceID": 10, "context": "Nesterov [13] considerably simplifies the technique employed by Nemirovsky and Yudin [11] at the cost of introducing additional assumption regarding the way new iterates are generated.", "startOffset": 85, "endOffset": 89}, {"referenceID": 10, "context": "Similarly to [11], this approach also does not yield dimension-independent lower bounds.", "startOffset": 13, "endOffset": 17}, {"referenceID": 0, "context": "[1], it is shown that if Q is given in advance, but q is unknown, then the iteration complexity of stationary p-CLIs which follows (4) is \u03a9\u0303( p \u221a \u03ba ln(1/\u01eb)).", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "It is further shown that this lower bound is tight (see Appendix A in [1]).", "startOffset": 70, "endOffset": 73}, {"referenceID": 15, "context": "Concretely, it implies that, in the absence of the strong convexity parameter, one is still able to schedule the step sizes according to the smoothness parameter so as to obtain exponential convergence rate, but only to the limited extent of linear dependency on the condition number (as mentioned before, this sub-optimality in terms of dependence on the condition number, can be also found in [17] and [3]).", "startOffset": 395, "endOffset": 399}, {"referenceID": 2, "context": "Concretely, it implies that, in the absence of the strong convexity parameter, one is still able to schedule the step sizes according to the smoothness parameter so as to obtain exponential convergence rate, but only to the limited extent of linear dependency on the condition number (as mentioned before, this sub-optimality in terms of dependence on the condition number, can be also found in [17] and [3]).", "startOffset": 404, "endOffset": 407}, {"referenceID": 5, "context": ", [6, 10]) which turn a given stationary algorithm into an non-stationary oblivious one.", "startOffset": 2, "endOffset": 9}, {"referenceID": 9, "context": ", [6, 10]) which turn a given stationary algorithm into an non-stationary oblivious one.", "startOffset": 2, "endOffset": 9}, {"referenceID": 11, "context": "In his seminal paper, Nesterov [12] presents the AGD algorithm and shows that it obtains a convergence rate of f(x)\u2212 f(x) \u2264 4L \u2225", "startOffset": 31, "endOffset": 35}, {"referenceID": 0, "context": "References [1] Yossi Arjevani, Shai Shalev-Shwartz, and Ohad Shamir.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Mikhail J Atallah.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Aaron Defazio, Francis Bach, and Simon Lacoste-Julien.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Yoel Drori.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Nicolas Flammarion and Francis Bach.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Roy Frostig, Rong Ge, Sham M Kakade, and Aaron Sidford.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Rie Johnson and Tong Zhang.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Laurent Lessard, Benjamin Recht, and Andrew Packard.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] A Yu Levin.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Hongzhou Lin, Julien Mairal, and Zaid Harchaoui.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] AS Nemirovsky and DB Yudin.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Yurii Nesterov.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Yurii Nesterov.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Donald J Newman.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16] Boris T Polyak.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17] Mark Schmidt, Nicolas Le Roux, and Francis Bach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[18] Shai Shalev-Shwartz.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19] Shai Shalev-Shwartz and Tong Zhang.", "startOffset": 0, "endOffset": 4}], "year": 2016, "abstractText": "We consider a broad class of first-order optimization algorithms which are oblivious, in the sense that their step sizes are scheduled regardless of the function under consideration, except for limited sideinformation such as smoothness or strong convexity parameters. With the knowledge of these two parameters, we show that any such algorithm attains an iteration complexity lower bound of \u03a9( \u221a L/\u01eb) for L-smooth convex functions, and \u03a9\u0303( \u221a L/\u03bc ln(1/\u01eb)) for L-smooth \u03bc-strongly convex functions. These lower bounds are stronger than those in the traditional oracle model, as they hold independently of the dimension. To attain these, we abandon the oracle model in favor of a structure-based approach which builds upon a framework recently proposed in [1]. We further show that without knowing the strong convexity parameter, it is impossible to attain an iteration complexity better than \u03a9\u0303 ((L/\u03bc) ln(1/\u01eb)). This result is then used to formalize an observation regarding L-smooth convex functions, namely, that the iteration complexity of algorithms employing time-invariant step sizes must be at least \u03a9(L/\u01eb).", "creator": "LaTeX with hyperref package"}}}