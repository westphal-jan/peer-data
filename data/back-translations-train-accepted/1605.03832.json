{"id": "1605.03832", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-May-2016", "title": "Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation Learning", "abstract": "We introduce polyglot language models, recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted. We apply these to the problem of modeling phone sequences---a domain in which universal symbol inventories and cross-linguistically shared feature representations are a natural fit. Intrinsic evaluation on held-out perplexity, qualitative analysis of the learned representations, and extrinsic evaluation in two downstream applications that make use of phonetic features show (i) that polyglot models better generalize to held-out data than comparable monolingual models and (ii) that polyglot phonetic feature representations are of higher quality than those learned monolingually.", "histories": [["v1", "Thu, 12 May 2016 14:37:51 GMT  (184kb,D)", "http://arxiv.org/abs/1605.03832v1", "Proceedings of NAACL 2016; 10 pages"]], "COMMENTS": "Proceedings of NAACL 2016; 10 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yulia tsvetkov", "sunayana sitaram", "manaal faruqui", "guillaume lample", "patrick littell", "david r mortensen", "alan w black", "lori s levin", "chris dyer"], "accepted": true, "id": "1605.03832"}, "pdf": {"name": "1605.03832.pdf", "metadata": {"source": "CRF", "title": "Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation Learning", "authors": ["Yulia Tsvetkov", "Sunayana Sitaram", "Manaal Faruqui", "Guillaume Lample", "Patrick Littell", "David Mortensen", "Alan W Black", "Lori Levin", "Chris Dyer"], "emails": ["ytsvetko@cs.cmu.edu", "ssitaram@cs.cmu.edu", "mfaruqui@cs.cmu.edu", "glample@cs.cmu.edu", "plittell@cs.cmu.edu", "dmortens@cs.cmu.edu", "awb@cs.cmu.edu", "lsl@cs.cmu.edu", "cdyer@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "This is not surprising given the historical significance of models in which each surface shape of a word is a separately modelled entity (English cat and Spanish gato would probably not benefit from sharing), but newer models that use distributed representations are a way to position themselves in this direction (Hermann and Blunsom, 2014; Faruqui and Dyer, 2014; Huang et al., 2015, and others). These models are applicable to multiple languages."}, {"heading": "2 Model", "text": "In this section, we first describe in \u00a7 2.1 the underlying framework of our model - RNNLM - a standard recursive neural network-based language model (Mikolov et al., 2010; Sundermeyer et al., 2012). Then, in \u00a7 2.2, we define a polyglot LM - a modification of the RNNLM to include both learned and artisanal language information. In phonological LM, telephones (sounds) are the basic units. The assignment of words to telephones is defined in pronunciation dictionaries. For example, \"cats\" [k\u00e6ts] is a sequence of four telephones. In view of a telephone code (1, 2,...), the task of the LM is to estimate the conditional probability of the next phone p (\u0441t, 1, 2,...)."}, {"heading": "2.1 RNNLM", "text": "In NLMs, a vocabulary V (here a series of telephones that compose all kinds of words in the language) is represented as a matrix of the parameters X, Rd, V, and V. X is often referred to as a lookup table. Phones in the input sequence are first converted into telephone vectors, where \u03c6i is represented by multiplying the telephone indicator (one-dimensional vector of length | V |) and the lookup table. At each step of time, most recent telephone prefixes and hidden states are transformed to ht \u2212 1 to compute a new hidden representation: ht = f (xt, ht \u2212 1), where f is a nonlinear transformation. In the original RNLMs (Mikolov et al., 2010), the transformation is as follows: ht = tanh (Whxxt + Whhht \u2212 bh).To overcome the notorious problem in the primeval disappearance theory, we are used in this context (peroloet) in 2010."}, {"heading": "2.2 Polyglot LM", "text": "We now describe our modifications to RNNLM to accommodate multilingualism, and the architecture is represented in Figure 1 = externalized. Our task is to estimate the conditional probability of the next phone in view of the previous phones and the language (\"): p (\u03c6t | \u03c61,.., \u03c6t \u2212 1,\").In a multilingual NLM, we define a vocabulary V * to be the union of the vocabulary of all educational languages, provided that all language vocabularies are assigned to a common representation (here, IPA).In addition, we maintain V 'with a special symbol for each language (e.g., \u03c6English, \u03c6Arabic).Language symbol vectors are parameters in the new selection table X'Rd \u00d7 | langs | (e.g., xenglish, xarabic).The inputs in the polyglot LM are the telephone vectors xt, the language character vx' and the characteristic vector vx '."}, {"heading": "3 Typological features", "text": "Typological information is fed into the model via vectors of 190 binary typological features, all of which are phonological (in terms of sound structure) in nature; these feature vectors are derived from extensive post-processing and analysis data from the WALS (Dryer and Haspelmath, 2013), PHOIBLE (Moran et al., 2014), and Ethnologue (Lewis et al., 2015) typological databases. 3 The features primarily concern the properties of sound inventories (i.e. the amount of phones or phonemes that occur in a language) and are largely of one of four types: 1. A single segment represented in an inventory; 3. This data resource provides standardized phonotypological information for 2,273 languages, is available at https: / / github.com / dmort27 / uriel-phonology / 0.1."}, {"heading": "4 Applications of Phonetic Vectors", "text": "Learned continuous word representations - word vectors - are an important by-product of neural LMs and are used as features in numerous NLP applications, including chunking (Turian et al., 2010), part-of-speech tagging (Ling et al., 2015), dependency parsing (Lazaridou et al., 2013; Bansal et al., 2014; Dyer et al., 2015; Watanabe and Sumita, 2015), entity recognition (Guo et al., 2014) and sentiment analysis (Socher et al., 2013; Wang et al., 2015). We evaluate telephone vectors learned from polyglot LMs in two downstream phonology-based applications: lexical borrowing modeling (\u00a7 4.1) and speech synthesis (\u00a7 4.2)."}, {"heading": "4.1 Lexical borrowing", "text": "In fact, borrowed words - also known as credit words - make up 10-70% of most linguistic lexicographs (Haspelmath, 2009); these are foreign-origin terms of content that are adapted in the language and are not perceived as foreign by the speakers. Computer-aided modeling of cross-border loanword transformations is effective in deriving lexical correspondence between languages with limited parallel data, favoring applications such as machine translation (Tsvetkov and Dyer, 2015). In the process of naming them in a foreign language, loanwords are primarily subject to phonological adaptations, namely the avoidance of telephones to adapt to the phonotactic constraints of the recipient language."}, {"heading": "4.2 Speech synthesis", "text": "Voice synthesis is the process of converting text to speech. It has various applications, such as screen readers for visually impaired and hands-free speech-based systems. Text-to-Speech (TTS) systems are also used as part of language-to-language translation systems and spoken dialogue systems, such as personal digital assistants. Natural and intelligible TTS systems exist today for a number of languages in the world. However, the construction of TTS systems remains prohibitive for many languages due to the lack of linguistic resources and data. Language-specific resources traditionally used to build TTS systems in a new language are: (1) audio recordings with transcripts; (2) pronunciation lexicon or letter for sound rules; and (3) a telephone set definition, which is now used by expert-designed telephones. Typically, these telephones also include phonetic features for each phoneme being used as the phoneme."}, {"heading": "5 Experiments", "text": "Our experimental evaluation of our proposed polyglot models consists of two parts: (i) an intrinsic evaluation, in which telephone sequences are modeled using independent models, and (ii) an extrinsic evaluation of the learned phonetic representations. Before discussing these results, we present details of the data resources we use."}, {"heading": "5.1 Resources and experimental setup", "text": "Resources. We are experimenting with the following languages: Arabic (AR), French (FR), Hindi (HI), Italian (IT), Maltese (MT), Romanian (RO), Swahili (SW), Tamil (TA) and Telugu (TE). In our language model experiments, two main data sources are automatically constructed using the \u00a7 3 dictionaries for AR, FR, HI, TA and TE are taken from internal speech recognition / synthesis systems. For the remaining languages, the dictionaries are automatically constructed using the omniglot grapheme-to-IPA conversion rules. 4We use two types of pronunciation dictionaries: (1) AR, FR, HI, IT, MT, RO, and SW dictionaries used in the dictionaries."}, {"heading": "5.2 Intrinsic perplexity evaluation", "text": "Perplexity is the standard evaluation value for language models that strongly correlate downstream applications with error rates (Klakow and Peters, 2002). We evaluated perplexity across multiple architectures and multiple monolingual and multilingual constellations. We kept the same hyperparameters across all constellations as in \u00a7 5. Perplexity of LMs trained on the two types of pronunciation dictionaries were evaluated separately; Table 3 summarizes perplexity of models trained on IPA dictionaries, and Table 4 summarizes perplexity of UniTran dictionaries. In columns, we compare three model architectures: Baseline refers to the standard RNLM architecture described in \u00a7 2.1; + lang refers to the polyglot-LM architecture described in \u00a7 2.2, with input language vectors, but without typological features and language layer."}, {"heading": "5.3 Lexical borrowing experiments", "text": "We reproduced complete lexical credit models described in (Tsvetkov and Dyer, 2016) for three language pairs: AR-SW, FR-RO and IT-MT. Train and test corpora are word pairs between giver and back in the language pairs. Company statistics are given in Table 5 (note that these are extremely small data sets, so a small number of highly informative features are necessary for good generalization) We use the reproduced systems as baselines and compare them with the corresponding systems that have been extended with telephone vectors, as described in Section 4.1. integrated vectors were derived from a single multilingual model with typology, which has been trained with IPA dictionaries in all languages. Compared to the results in Table 3, the perplexity of the model on the IT data set (used for rating is Section 5.2) is higher than the accuracy of the model in four languages."}, {"heading": "5.4 Speech synthesis experiments", "text": "A popular objective metric for measuring the quality of synthetic language is the Mel Cepstral Distortion (MCD) of 1997 (Hu and Loizou, 2008).The MCD metric calculates an L2 standard of the Mel Frequency Cepstral Coefficient (MFCCs) natural language from a pre-set test and synthetic language generated from the same test set. As it is a distance metric, a lower value of the MCD indicates better synthesis. MCD is a database-specific metric, but experiments by Kominek et al. (Kominek et al., 2008) have shown that a decrease of the MCD of 0.08 is perceptively significant, and a decrease of 0.12 is equivalent to a doubling of the TTS database. In our experiments we use MCD to measure the relative improvement achieved by our technical system."}, {"heading": "5.5 Qualitative analysis of vectors", "text": "An interesting question is whether these vectors capture the linguistic (phonological) qualities of the telephones they encode. To analyze the extent to which our vectors capture the linguistic properties of telephones, we use the QVEC - a tool for quantifying and interpreting the linguistic content of vector space models (Tsvetkov et al., 2015). The tool aligns dimensions in a matrix of learned distributed representations with the dimensions of a handmade linguistic matrix. (Alignments are induced via correlated columns in the distributed and linguistic matrix.) To analyze the content of the distributed matrix, annotations from the linguistic matrix are projected into the languages that are not present in the linguistic matrix."}, {"heading": "6 Related Work", "text": "Multilingual Language Models. Interpolation of monolingual LMs is an alternative to multilingual models (Harbeck et al., 1997; Weng et al., 1997). However, interpolated models still require a trained model per language and do not allow parameters to be shared during training. Bilingual language models trained on concatenated corpora have been studied mainly in the fields of speech recognition (Ward et al., 1998; Wang et al., 2002; F\u00fcgen et al., 2003). Adjustments have been proposed to apply language models in bilingual contexts in machine translation (Niehues et al., 2011) and code-switching (Adel et al., 2013). However, these approaches require adaptation to each language pair, and an adapted model cannot be applied to more than two languages. Independently of these, Ammar et al. (2016) used another multilingual architecture for multilingual dependency analysis."}, {"heading": "7 Conclusion", "text": "We presented a novel multilingual language model architecture. The model makes significant progress in reducing confusion and improving downstream text and speech applications. Although we focus on phonology, our approach is general and can be applied to problems that integrate divergent modalities, such as topic modeling and multilingual tagging and parsing."}, {"heading": "Acknowledgments", "text": "This work was supported by the National Science Foundation with the IIS-1526745 award and in part by the Defense Advanced Research Projects Agency (DARPA) Information Innovation Office (I2O). Program: Low Resource Languages for Emergent Incidents (LORELEI). Published by DARPA / I2O under contract number HR0011-15-C-0114."}], "references": [{"title": "Combination of recurrent neural networks and factored language models for codeswitching language modeling", "author": ["Adel et al.2013] Heike Adel", "Ngoc Thang Vu", "Tanja Schultz"], "venue": "In Proc. ACL,", "citeRegEx": "Adel et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Adel et al\\.", "year": 2013}, {"title": "Tailoring continuous word representations for dependency parsing", "author": ["Bansal et al.2014] Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": "In Proc. ACL", "citeRegEx": "Bansal et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bansal et al\\.", "year": 2014}, {"title": "Learning long-term dependencies with gradient descent is difficult", "author": ["Bengio et al.1994] Yoshua Bengio", "Patrice Simard", "Paolo Frasconi"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Bengio et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1994}, {"title": "Building synthetic voices. http: //festvox.org/bsv", "author": ["Black", "Lenzo2003] Alan W Black", "Kevin A Lenzo"], "venue": null, "citeRegEx": "Black et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Black et al\\.", "year": 2003}, {"title": "The Festival speech synthesis system: system documentation", "author": ["Black", "Taylor1997] Alan W Black", "Paul Taylor"], "venue": "Technical report,", "citeRegEx": "Black et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Black et al\\.", "year": 1997}, {"title": "CLUSTERGEN: a statistical parametric synthesizer using trajectory modeling", "author": ["Alan W Black"], "venue": "In Proc. Interspeech", "citeRegEx": "Black.,? \\Q2006\\E", "shortCiteRegEx": "Black.", "year": 2006}, {"title": "Transition-based dependency parsing with stack long short-term memory", "author": ["Dyer et al.2015] Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A Smith"], "venue": "In Proc. ACL", "citeRegEx": "Dyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2015}, {"title": "Improving vector space word representations using multilingual correlation", "author": ["Faruqui", "Dyer2014] Manaal Faruqui", "Chris Dyer"], "venue": "In Proc. EACL", "citeRegEx": "Faruqui et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2014}, {"title": "Efficient handling of multilingual language models", "author": ["Sebastian Stuker", "Hagen Soltau", "Florian Metze", "Tanja Schultz"], "venue": "In Proc. ASRU,", "citeRegEx": "F\u00fcgen et al\\.,? \\Q2003\\E", "shortCiteRegEx": "F\u00fcgen et al\\.", "year": 2003}, {"title": "Generating sequences with recurrent neural networks. CoRR, abs/1308.0850", "author": ["Alex Graves"], "venue": null, "citeRegEx": "Graves.,? \\Q2013\\E", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "Revisiting embedding features for simple semi-supervised learning", "author": ["Jiang Guo", "Wanxiang Che", "Haifeng Wang", "Ting Liu"], "venue": "In Proc. EMNLP", "citeRegEx": "Guo et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2014}, {"title": "Multilingual speech recognition", "author": ["Elmar N\u00f6th", "Heinrich Niemann"], "venue": "In Proc. 2nd SQEL Workshop on Multi-Lingual Information Retrieval Dialogs,", "citeRegEx": "Harbeck et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Harbeck et al\\.", "year": 1997}, {"title": "Multilingual Models for Compositional Distributional Semantics", "author": ["Hermann", "Blunsom2014] Karl Moritz Hermann", "Phil Blunsom"], "venue": "In Proc. ACL", "citeRegEx": "Hermann et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hermann et al\\.", "year": 2014}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Evaluation of objective quality measures for speech enhancement", "author": ["Hu", "Loizou2008] Yi Hu", "Philipos C Loizou"], "venue": "Audio, Speech, & Language Processing,", "citeRegEx": "Hu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2008}, {"title": "Translation invariant word embeddings", "author": ["Huang et al.2015] Kejun Huang", "Matt Gardner", "Evangelos Papalexakis", "Christos Faloutsos", "Nikos Sidiropoulos", "Tom Mitchell", "Partha P. Talukdar", "Xiao Fu"], "venue": "In Proc. EMNLP,", "citeRegEx": "Huang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2015}, {"title": "Adam: A method for stochastic optimization. CoRR, abs/1412.6980", "author": ["Kingma", "Ba2014] Diederik Kingma", "Jimmy Ba"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Multimodal neural language models", "author": ["Kiros", "Salakhutdinov2013] Ryan Kiros", "Ruslan Salakhutdinov"], "venue": "In Proc. NIPS Deep Learning Workshop", "citeRegEx": "Kiros et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kiros et al\\.", "year": 2013}, {"title": "Unifying visual-semantic embeddings with multimodal neural language models. TACL", "author": ["Kiros et al.2015] Ryan Kiros", "Ruslan Salakhutdinov", "Richard Zemel"], "venue": null, "citeRegEx": "Kiros et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kiros et al\\.", "year": 2015}, {"title": "Testing the correlation of word error rate and perplexity", "author": ["Klakow", "Peters2002] Dietrich Klakow", "Jochen Peters"], "venue": "Speech Communication,", "citeRegEx": "Klakow et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Klakow et al\\.", "year": 2002}, {"title": "Synthesizer voice quality of new languages calibrated with mean Mel Cepstral Distortion", "author": ["Kominek et al.2008] John Kominek", "Tanja Schultz", "Alan W Black"], "venue": "In Proc. SLTU,", "citeRegEx": "Kominek et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kominek et al\\.", "year": 2008}, {"title": "Fish transporters and miracle homes: How compositional distributional semantics can help NP parsing", "author": ["Eva Maria Vecchi", "Marco Baroni"], "venue": "In Proc. EMNLP", "citeRegEx": "Lazaridou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2013}, {"title": "Ethnologue: Languages of the world. Texas: SIL International", "author": ["Lewis et al.2015] M Paul Lewis", "Gary F Simons", "Charles D Fennig"], "venue": null, "citeRegEx": "Lewis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lewis et al\\.", "year": 2015}, {"title": "Finding function in form: Compositional character models for open vocabulary word representation", "author": ["Ling et al.2015] Wang Ling", "Tiago Lu\u00eds", "Lu\u00eds Marujo", "Ram\u00f3n Fernandez Astudillo", "Silvio Amir", "Chris Dyer", "Alan W Black", "Isabel Trancoso"], "venue": null, "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Bridgelanguage capitalization inference in Western Iranian: Sorani, Kurmanji, Zazaki, and Tajik", "author": ["David Mortensen", "Kartik Goyal", "Chris Dyer", "Lori Levin"], "venue": "In Proceedings of the Eleventh International Conference on Language", "citeRegEx": "Littell et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Littell et al\\.", "year": 2016}, {"title": "Deep multilingual correlation for improved word embeddings", "author": ["Lu et al.2015] Ang Lu", "Weiran Wang", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": "In Proc. NAACL", "citeRegEx": "Lu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lu et al\\.", "year": 2015}, {"title": "Recurrent neural network based language model", "author": ["Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "In Proc. Interspeech,", "citeRegEx": "Mikolov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Wider context by using bilingual language models in machine translation", "author": ["Niehues et al.2011] Jan Niehues", "Teresa Herrmann", "Stephan Vogel", "Alex Waibel"], "venue": "In Proc. WMT,", "citeRegEx": "Niehues et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Niehues et al\\.", "year": 2011}, {"title": "The IIIT-H Indic speech databases", "author": ["E. Naresh Kumar", "Venkatesh Keri", "S. Rajendran", "Alan W Black"], "venue": "In Proc. Interspeech", "citeRegEx": "Prahallad et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Prahallad et al\\.", "year": 2012}, {"title": "A Python toolkit for universal transliteration", "author": ["Malta LREC."], "venue": "Proc. LREC.", "citeRegEx": "LREC.,? 2010", "shortCiteRegEx": "LREC.", "year": 2010}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Y. Ng", "Christopher Potts"], "venue": "In Proc. EMNLP", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "LSTM neural networks for language modeling", "author": ["Ralf Schl\u00fcter", "Hermann Ney"], "venue": "In Proc. Interspeech", "citeRegEx": "Sundermeyer et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Sundermeyer et al\\.", "year": 2012}, {"title": "Language contact", "author": ["Thomason", "Kaufman2001] Sarah Grey Thomason", "Terrence Kaufman"], "venue": null, "citeRegEx": "Thomason et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Thomason et al\\.", "year": 2001}, {"title": "Lexicon stratification for translating out-ofvocabulary words", "author": ["Tsvetkov", "Dyer2015] Yulia Tsvetkov", "Chris Dyer"], "venue": "In Proc. ACL,", "citeRegEx": "Tsvetkov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2015}, {"title": "Cross-lingual bridges with models of lexical borrowing", "author": ["Tsvetkov", "Dyer2016] Yulia Tsvetkov", "Chris Dyer"], "venue": null, "citeRegEx": "Tsvetkov et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2016}, {"title": "Evaluation of word vector representations by subspace alignment", "author": ["Manaal Faruqui", "Wang Ling", "Guillaume Lample", "Chris Dyer"], "venue": "In Proc. EMNLP. https://github. com/ytsvetko/qvec", "citeRegEx": "Tsvetkov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tsvetkov et al\\.", "year": 2015}, {"title": "Word representations: a simple and general method for semi-supervised learning", "author": ["Turian et al.2010] Joseph Turian", "Lev Ratinov", "Yoshua Bengio"], "venue": "In Proc. ACL", "citeRegEx": "Turian et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Towards universal speech recognition", "author": ["Wang et al.2002] Zhirong Wang", "Umut Topkara", "Tanja Schultz", "Alex Waibel"], "venue": "In Proc. ICMI,", "citeRegEx": "Wang et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2002}, {"title": "Predicting polarities of tweets by composing word embeddings with long short-term memory", "author": ["Wang et al.2015] Xin Wang", "Yuanchao Liu", "Chengjie Sun", "Baoxun Wang", "Xiaolong Wang"], "venue": "In Proc. ACL,", "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Towards speech understanding across multiple languages", "author": ["Ward et al.1998] Todd Ward", "Salim Roukos", "Chalapathy Neti", "Jerome Gros", "Mark Epstein", "Satya Dharanipragada"], "venue": "In Proc. ICSLP", "citeRegEx": "Ward et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Ward et al\\.", "year": 1998}, {"title": "Transition-based neural constituent parsing", "author": ["Watanabe", "Sumita2015] Taro Watanabe", "Eiichiro Sumita"], "venue": "In Proc. ACL", "citeRegEx": "Watanabe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Watanabe et al\\.", "year": 2015}, {"title": "Sentence-level control vectors for deep neural network speech synthesis", "author": ["Watts et al.2015] Oliver Watts", "Zhizheng Wu", "Simon King"], "venue": "In Proc. Interspeech", "citeRegEx": "Watts et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Watts et al\\.", "year": 2015}, {"title": "A study of multilingual speech recognition", "author": ["Weng et al.1997] Fuliang Weng", "Harry Bratt", "Leonardo Neumeyer", "Andreas Stolcke"], "venue": "In Proc. EUROSPEECH,", "citeRegEx": "Weng et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Weng et al\\.", "year": 1997}], "referenceMentions": [{"referenceID": 26, "context": "1 the underlying framework of our model\u2014RNNLM\u2014a standard recurrent neural network based language model (Mikolov et al., 2010; Sundermeyer et al., 2012).", "startOffset": 103, "endOffset": 151}, {"referenceID": 31, "context": "1 the underlying framework of our model\u2014RNNLM\u2014a standard recurrent neural network based language model (Mikolov et al., 2010; Sundermeyer et al., 2012).", "startOffset": 103, "endOffset": 151}, {"referenceID": 26, "context": "In the original RNNLMs (Mikolov et al., 2010), the transformation is such that:", "startOffset": 23, "endOffset": 45}, {"referenceID": 2, "context": "To overcome the notorious problem in recurrent neural networks of vanishing gradients (Bengio et al., 1994), following Sundermeyer et al.", "startOffset": 86, "endOffset": 107}, {"referenceID": 2, "context": "To overcome the notorious problem in recurrent neural networks of vanishing gradients (Bengio et al., 1994), following Sundermeyer et al. (2012), in recurrent layer we use long short-term memory (LSTM) units (Hochreiter and Schmidhuber, 1997):2", "startOffset": 87, "endOffset": 145}, {"referenceID": 22, "context": ", 2014), and Ethnologue (Lewis et al., 2015) typological databases via extensive post-processing and analysis.", "startOffset": 24, "endOffset": 44}, {"referenceID": 36, "context": "Learned continuous word representations\u2014word vectors\u2014are an important by-product of neural LMs, and these are used as features in numerous NLP applications, including chunking (Turian et al., 2010), part-of-speech tagging (Ling et al.", "startOffset": 176, "endOffset": 197}, {"referenceID": 23, "context": ", 2010), part-of-speech tagging (Ling et al., 2015), dependency parsing (Lazaridou et al.", "startOffset": 32, "endOffset": 51}, {"referenceID": 21, "context": ", 2015), dependency parsing (Lazaridou et al., 2013; Bansal et al., 2014; Dyer et al., 2015; Watanabe and Sumita, 2015), named entity recognition (Guo et al.", "startOffset": 28, "endOffset": 119}, {"referenceID": 1, "context": ", 2015), dependency parsing (Lazaridou et al., 2013; Bansal et al., 2014; Dyer et al., 2015; Watanabe and Sumita, 2015), named entity recognition (Guo et al.", "startOffset": 28, "endOffset": 119}, {"referenceID": 6, "context": ", 2015), dependency parsing (Lazaridou et al., 2013; Bansal et al., 2014; Dyer et al., 2015; Watanabe and Sumita, 2015), named entity recognition (Guo et al.", "startOffset": 28, "endOffset": 119}, {"referenceID": 10, "context": ", 2015; Watanabe and Sumita, 2015), named entity recognition (Guo et al., 2014), and sentiment analysis (Socher et al.", "startOffset": 61, "endOffset": 79}, {"referenceID": 30, "context": ", 2014), and sentiment analysis (Socher et al., 2013; Wang et al., 2015).", "startOffset": 32, "endOffset": 72}, {"referenceID": 38, "context": ", 2014), and sentiment analysis (Socher et al., 2013; Wang et al., 2015).", "startOffset": 32, "endOffset": 72}, {"referenceID": 41, "context": "While prior work has explored TTS augmented with acoustic features (Watts et al., 2015), to the best of our knowledge, we are the first to replace manually engineered phonetic features in TTS systems with automatically constructed phone vectors.", "startOffset": 67, "endOffset": 87}, {"referenceID": 20, "context": "(Kominek et al., 2008) have shown that a decrease in MCD of 0.", "startOffset": 0, "endOffset": 22}, {"referenceID": 28, "context": "We conducted experiments on the IIIT-H Hindi voice database (Prahallad et al., 2012), a 2 hour single speaker database recorded by a professional male speaker.", "startOffset": 60, "endOffset": 84}, {"referenceID": 5, "context": "For all our voice-based experiments, we built CLUSTERGEN Statistical Parametric Synthesis voices (Black, 2006) using the Festvox voice building tools (Black and Lenzo, 2003) and the Festival speech synthesis engine (Black and Taylor, 1997).", "startOffset": 97, "endOffset": 110}, {"referenceID": 33, "context": "to quantify and interpret linguistic content of vector space models (Tsvetkov et al., 2015).", "startOffset": 68, "endOffset": 91}, {"referenceID": 24, "context": "This matrix is described in Littell et al. (2016) and is available at https://github.", "startOffset": 28, "endOffset": 50}, {"referenceID": 11, "context": "Interpolation of monolingual LMs is an alternative to obtain a multilingual model (Harbeck et al., 1997; Weng et al., 1997).", "startOffset": 82, "endOffset": 123}, {"referenceID": 42, "context": "Interpolation of monolingual LMs is an alternative to obtain a multilingual model (Harbeck et al., 1997; Weng et al., 1997).", "startOffset": 82, "endOffset": 123}, {"referenceID": 39, "context": "Bilingual language models trained on concatenated corpora were explored mainly in speech recognition (Ward et al., 1998; Wang et al., 2002; F\u00fcgen et al., 2003).", "startOffset": 101, "endOffset": 159}, {"referenceID": 37, "context": "Bilingual language models trained on concatenated corpora were explored mainly in speech recognition (Ward et al., 1998; Wang et al., 2002; F\u00fcgen et al., 2003).", "startOffset": 101, "endOffset": 159}, {"referenceID": 8, "context": "Bilingual language models trained on concatenated corpora were explored mainly in speech recognition (Ward et al., 1998; Wang et al., 2002; F\u00fcgen et al., 2003).", "startOffset": 101, "endOffset": 159}, {"referenceID": 27, "context": "Adaptations have been proposed to apply language models in bilingual settings in machine translation (Niehues et al., 2011) and code switching (Adel et al.", "startOffset": 101, "endOffset": 123}, {"referenceID": 0, "context": ", 2011) and code switching (Adel et al., 2013).", "startOffset": 27, "endOffset": 46}, {"referenceID": 18, "context": "Our work is inspired by the neural multimodal LMs (Kiros and Salakhutdinov, 2013; Kiros et al., 2015), which defined language models conditional on visual contexts, although we use a different language model architecture (recurrent vs.", "startOffset": 50, "endOffset": 101}], "year": 2016, "abstractText": "We introduce polyglot language models, recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted. We apply these to the problem of modeling phone sequences\u2014a domain in which universal symbol inventories and cross-linguistically shared feature representations are a natural fit. Intrinsic evaluation on held-out perplexity, qualitative analysis of the learned representations, and extrinsic evaluation in two downstream applications that make use of phonetic features show (i) that polyglot models better generalize to held-out data than comparable monolingual models and (ii) that polyglot phonetic feature representations are of higher quality than those learned monolingually.", "creator": "LaTeX with hyperref package"}}}