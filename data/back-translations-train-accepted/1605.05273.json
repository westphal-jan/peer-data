{"id": "1605.05273", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-May-2016", "title": "Learning Convolutional Neural Networks for Graphs", "abstract": "Numerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locallyconnected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.", "histories": [["v1", "Tue, 17 May 2016 18:13:13 GMT  (379kb,D)", "http://arxiv.org/abs/1605.05273v1", "To be presented at ICML 2016"], ["v2", "Wed, 18 May 2016 15:38:30 GMT  (379kb,D)", "http://arxiv.org/abs/1605.05273v2", "To be presented at ICML 2016"], ["v3", "Mon, 6 Jun 2016 13:33:38 GMT  (379kb,D)", "http://arxiv.org/abs/1605.05273v3", "To be presented at ICML 2016"], ["v4", "Wed, 8 Jun 2016 11:40:13 GMT  (379kb,D)", "http://arxiv.org/abs/1605.05273v4", "To be presented at ICML 2016"]], "COMMENTS": "To be presented at ICML 2016", "reviews": [], "SUBJECTS": "cs.LG cs.AI stat.ML", "authors": ["mathias niepert", "mohamed ahmed", "konstantin kutzkov"], "accepted": true, "id": "1605.05273"}, "pdf": {"name": "1605.05273.pdf", "metadata": {"source": "META", "title": "Learning Convolutional Neural Networks for Graphs", "authors": ["Mathias Niepert", "Mohamed Ahmed", "Konstantin Kutzkov"], "emails": ["MATHIAS.NIEPERT@NECLAB.EU", "M.AHMED@NECLAB.EU", "KONSTANTIN.KUTZKOV@NECLAB.EU"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is so that most people who live in the USA, live in the USA, in the USA, in the USA, where they live in the USA, in the USA, in Europe, in Europe, in Europe, in Europe, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in Europe, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the USA, in the"}, {"heading": "2. Related Work", "text": "An effective class of graph kernels are Yanfeiler-Weiler-Lehkl (Vishwanathan et al., 2010).Graphene kernels were originally defined as similarity functions based on the nodes of a single graph (Kondor & Lafferty et al., 2002).However, two representative classes of nuclei are the skew Spectrum kernels (Kondor & Borgwardt, 2008) and nuclei based on graphs (Kondor et al., 2009; Shervashidze et al., 2009).The latter are related to our work as they build nuclei on fixed-sized subgraphs. These subgraphs, often referred to as graphs or graphs, reflect functional network properties (Milo et al., 2002; Alon, 2007).However, due to the combinatorial complexity of subgraph enumeration, graphs are kernel-limited tubgraphs with few nodes."}, {"heading": "3. Background", "text": "We offer a brief introduction to the required background in coil networks and graph theory."}, {"heading": "3.1. Convolutional Neural Networks", "text": "CNNs were developed in the 1980s and applied to image, speech, text, and drug discovery problems (Atlas et al., 1988; LeCun et al., 1989; 1998; 2015; Wallach et al., 2015). A typical CNN consists of revolutionary and dense layers. The purpose of the first revolutionary layer is to extract common patterns found within local regions of the input images. CNNs convolute filters over the input image, calculate the inner product at each image location, and output the result as a tensor whose depth is the number of filters."}, {"heading": "3.2. Graphs", "text": "A graph G is a pair (V, E) with V = {v1, vn} the set of vertices and E V \u00b7 V the set of edges. Let n be the number of wells and m be the number of edges. An undirected graph is a graph in which edges have no direction. In this case we can say that vertex vi has a position i in A. In addition, if Ai, j = 1 we say vi and vj are adjacent. Node and edge attributes are features that attain one value for each node and edge of a graph. We use the term attribute value to avoid confusion with the graph theoretical concept of a label."}, {"heading": "4. Learning CNNs for Arbitrary Graphs", "text": "When CNNs are applied to images, a receptive field (a square grid) is moved over each image with a specific step size. < The receptive field reads the characteristic values of the pixels, once for each channel, and a patch of values is created for each channel. < Since the pixels of an image have an implicit arrangement - a spatial order - the receptive fields are always shifted from left to right and from top to bottom. \u2212 In addition, the spatial order clearly determines the nodes of each receptive field and the way its nodes are assigned to a vector space representation (see Figure 1 (b). Consequently, the values read from two pixels of the receptive field are assigned to the same relative position if and only if the structural roles of the pixels (their spatial position within the receptive field) are identical."}, {"heading": "4.1. Node Sequence Selection", "text": "Algorithm 1 lists such an approach. First, the vertices of the input graph are sorted in relation to a given graph label, turning the nodes of the graph into a sequence of nodes. Second, the resulting node sequence is traversed using a given step, and for each node visited, Algorithm 4 is executed to construct a receptive field until exact receptive fields are generated. Step s determines the distance between two consecutive nodes for which a receptive field is created. If the number of nodes is less than w, the algorithm generates receptive fields for padding targets. Several alternative methods for selecting the node sequence are possible. For example, depth traversing of the input graph by the values of the graph."}, {"heading": "4.2. Neighborhood Assembly", "text": "Algorithm 4 first calls algorithm 2 to assemble a local neighborhood for the input node. Neighborhood nodes are the candidates for the receiver field. Algorithm 2 lists the assembly procedure for the neighborhood. Input is a node v and the size of the receiver field k, the procedure performs a breadth search by examining vertices with increasing distance from v and adding these vertices to a group N. First, algorithm N1 (v) collects the 1 neighborhood of v. If the number of collected nodes is less than k, the 1 neighborhood of the vertices last added to N will be collected, and so on, until at least k vertices are in N, or until there are no more neighbors. Note that at this point, the size of N may differ from k."}, {"heading": "4.3. Graph Normalization", "text": "\"I think it's going to be a bit of a struggle,\" he said, \"but I think it's going to be a bit of a struggle, and I think it's going to be a bit of a struggle.\""}, {"heading": "4.4. Convolutional Architecture", "text": "PATCHY-SAN is capable of processing both corner and edge attributes (discrete and continuous). Let av be the number of corner attributes and ae be the number of edge attributes. For each input graph G, the normalized receiver fields for vertices and edges are applied, resulting in a (w, k, av) or (w, k, k, ae) tensor, which can now be redesigned to the two-dimensional (wk, av) or one (wk2, ae) tensor. Note that av and ae are the number of input channels. We can now apply a one-dimensional wave layer with step k to the first tensor with step k2 to the second tensor."}, {"heading": "5. Complexity and Implementation", "text": "Theorem 4. Let N be the number of graphs, let k be the receptive field quantity, w be the width, and O (f (n, m) be the complexity of calculating a given label \"for a graph with n vertices and m edges. PATCHY-SAN has a worst-case complexity of O (Nw (f (n, m) + n log (n) + exp (k))) for calculating the receptive fields for N graphs. Proof: Selecting the node sequences requires labeling each input graph and retrieving the k highest-stranded nodes (n, m)."}, {"heading": "6. Experiments", "text": "We conduct three types of experiments: a runtime analysis, a qualitative analysis of the learned characteristics, and a comparison with graph cores on benchmark datasets."}, {"heading": "6.1. Runtime Analysis", "text": "We evaluate the efficiency of PATCHY-SAN by applying it to real graphs. The goal is to compare the rates at which susceptible fields can be generated with the rate at which state-of-the-art CNNs learn. All graphs are part of the collection of the Python module GRAPH-TOOL1. For a given graph, we used PATCHY-SAN to calculate a susceptible field for all nodes by means of 1-WL normalization. torus is a periodic grid of 10,000 nodes; randomly, an undirected graph with the grades distribution P (k), 1 / k, and kmax = 3 is random; power is a network that represents the topology of a power grid in the U.S.; polbooks is a common network of books on U.S. policy published during the 2004 presidential election; preferred is a preferred annex-network model, in which eph-points are added to the autophysics; the autophysics are added to the autophysics."}, {"heading": "6.2. Feature Visualization", "text": "The aim of the visualization experiments is to qualitatively investigate whether popular models such as the restricted Boltzman machine (RBM) (Freund & Haussler, 1992) can be combined with PATCHY-SAN for unattended feature learning. For each input graph, we generated receptive fields for all nodes and used these as input for an RBM. The RBM had 100 hidden nodes and was trained for 30 epochs with contrast divergence and a learning rate of 0.01. We visualize the receptive fields of size 9 normalized by a single-layer RBM. Note that the characteristics learned by the RBM correspond to recurring receptive field patterns."}, {"heading": "6.3. Graph Classification", "text": "We use 6 standard benchmark datasets to compare runtime and classification accuracy with the current state of the art. (We use 6 standard benchmark datasets to compare runtime and classification accuracy with the current state of the art.) (We use 6 standard benchmark datasets to compare runtime and classification accuracy. (Debnath et al., 1991) is a dataset of 188 nitro compounds in which classes indicate that the compound has a mutagenic effect on a bacterium. PTC consists of 344 chemical compounds in which classes indicate carcinogenicity for male and female rats. (Toivonen et al., 2003). NCI1 and NCI109 are chemical compounds for activity against non-small cell lung cancer lines and ovariant cancer lines (Whales & Karypis, 2006)."}, {"heading": "7. Conclusion and Future Work", "text": "We have proposed a framework for learning graph representations that is particularly advantageous in conjunction with CNNs. It combines two complementary procedures: (a) selecting a node sequence that covers large parts of the graph, and (b) generating local, normalized neighborhood representations for each node in the sequence. Experiments show that the approach competes with modern graph cores. Future working guidelines include the use of alternative neural network architectures such as RNNs, combining different receptive field sizes, pre-training with RBMs and autoencoders, and statistical relationship models based on the ideas of the approach."}, {"heading": "ACKNOWLEDGMENTS", "text": "Many thanks to the anonymous ICML reviewers who have provided tremendously helpful comments."}], "references": [{"title": "Network motifs: theory and experimental approaches", "author": ["Alon", "Uri"], "venue": "Nature Reviews Genetics,", "citeRegEx": "Alon and Uri.,? \\Q2007\\E", "shortCiteRegEx": "Alon and Uri.", "year": 2007}, {"title": "An artificial neural network for spatio-temporal bipolar patterns: Application to phoneme classification", "author": ["Atlas", "Les E", "Homma", "Toshiteru", "Marks", "Robert J. II"], "venue": "Neural Information Processing Systems,", "citeRegEx": "Atlas et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Atlas et al\\.", "year": 1988}, {"title": "Random graph isomorphism", "author": ["Babai", "L\u00e1szl\u00f3", "Erd\u0151s", "Paul", "Selkow", "Stanley M"], "venue": "SIAM J. Computing,", "citeRegEx": "Babai et al\\.,? \\Q1980\\E", "shortCiteRegEx": "Babai et al\\.", "year": 1980}, {"title": "Emergence of scaling in random networks", "author": ["Barab\u00e1si", "Albert-Laszlo", "Albert", "R\u00e9ka"], "venue": null, "citeRegEx": "Barab\u00e1si et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Barab\u00e1si et al\\.", "year": 1999}, {"title": "Tight lower and upper bounds for the complexity of canonical colour refinement", "author": ["Berkholz", "Christoph", "Bonsma", "Paul S", "Grohe", "Martin"], "venue": "In Proceedings of the European Symposium on Algorithms,", "citeRegEx": "Berkholz et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Berkholz et al\\.", "year": 2013}, {"title": "Shortestpath kernels on graphs", "author": ["Borgwardt", "Karsten M", "Kriegel", "Hans-Peter"], "venue": "In Proceedings of the Fifth IEEE International Conference on Data Mining (ICDM), pp", "citeRegEx": "Borgwardt et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Borgwardt et al\\.", "year": 2005}, {"title": "Spectral networks and locally connected networks on graphs", "author": ["Bruna", "Joan", "Zaremba", "Wojciech", "Szlam", "Arthur", "LeCun", "Yann"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "Bruna et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bruna et al\\.", "year": 2014}, {"title": "Libsvm: A library for support vector machines", "author": ["Chang", "Chih-Chung", "Lin", "Chih-Jen"], "venue": "ACM Trans. Intell. Syst. Technol.,", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "Distinguishing enzyme structures from non-enzymes without alignments", "author": ["Dobson", "Paul D", "Doig", "Andrew J"], "venue": "Journal of Molecular Biology,", "citeRegEx": "Dobson et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Dobson et al\\.", "year": 2003}, {"title": "Unsupervised learning of distributions of binary vectors using two layer networks", "author": ["Freund", "Yoav", "Haussler", "David"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Freund et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Freund et al\\.", "year": 1992}, {"title": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position", "author": ["Fukushima", "Kunihiko"], "venue": "Biological Cybernetics,", "citeRegEx": "Fukushima and Kunihiko.,? \\Q1980\\E", "shortCiteRegEx": "Fukushima and Kunihiko.", "year": 1980}, {"title": "On graph kernels: Hardness results and efficient alternatives", "author": ["Gaertner", "Thomas", "Flach", "Peter", "Wrobel", "Stefan"], "venue": "In Proceedings of the 16th Annual Conference on Computational Learning Theory, pp", "citeRegEx": "Gaertner et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Gaertner et al\\.", "year": 2003}, {"title": "Convolution kernels on discrete structures", "author": ["Haussler", "David"], "venue": "Technical report, Department of Computer Science, University of California at Santa Cruz,", "citeRegEx": "Haussler and David.,? \\Q1999\\E", "shortCiteRegEx": "Haussler and David.", "year": 1999}, {"title": "Deep convolutional networks on graph-structured data", "author": ["Henaff", "Mikael", "Bruna", "Joan", "LeCun", "Yann"], "venue": "arXiv preprint arXiv:1506.05163,", "citeRegEx": "Henaff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Henaff et al\\.", "year": 2015}, {"title": "Receptive fields and functional architecture of monkey striate cortex", "author": ["Hubel", "David H", "Wiesel", "Torsten N"], "venue": "Journal of Physiology (London),", "citeRegEx": "Hubel et al\\.,? \\Q1968\\E", "shortCiteRegEx": "Hubel et al\\.", "year": 1968}, {"title": "Counting belief propagation", "author": ["Kersting", "Kristian", "Ahmadi", "Babak", "Natarajan", "Sriraam"], "venue": "In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI),", "citeRegEx": "Kersting et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kersting et al\\.", "year": 2009}, {"title": "Power iterated color refinement", "author": ["Kersting", "Kristian", "Mladenov", "Martin", "Garnett", "Roman", "Grohe"], "venue": "In Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Kersting et al\\.,? \\Q1904\\E", "shortCiteRegEx": "Kersting et al\\.", "year": 1904}, {"title": "The skew spectrum of graphs", "author": ["Kondor", "Risi", "Borgwardt", "Karsten M"], "venue": "In Proceedings of the 25th International Conference on Machine Learning (ICML),", "citeRegEx": "Kondor et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Kondor et al\\.", "year": 2008}, {"title": "Diffusion kernels on graphs and other discrete input spaces", "author": ["Kondor", "Risi", "Lafferty", "John"], "venue": "In Proceedings of the 19th International Conference on Machine Learning (ICML),", "citeRegEx": "Kondor et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Kondor et al\\.", "year": 2002}, {"title": "The graphlet spectrum", "author": ["Kondor", "Risi", "Shervashidze", "Nino", "Borgwardt", "Karsten M"], "venue": "In Proceedings of the 26th International Conference on Machine Learning (ICML),", "citeRegEx": "Kondor et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kondor et al\\.", "year": 2009}, {"title": "Backpropagation applied to handwritten zip code recognition", "author": ["Y. LeCun", "B. Boser", "J.S. Denker", "D. Henderson", "R.E. Howard", "W. Hubbard", "L.D. Jackel"], "venue": "Neural Comput.,", "citeRegEx": "LeCun et al\\.,? \\Q1989\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1989}, {"title": "Gradient-based learning applied to document recognition", "author": ["LeCun", "Yann", "Bottou", "L\u00e9on", "Bengio", "Yoshua", "Haffner", "Patrick"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters", "author": ["Leskovec", "Jure", "Lang", "Kevin J", "Dasgupta", "Anirban", "Mahoney", "Michael W"], "venue": "Internet Mathematics,", "citeRegEx": "Leskovec et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Leskovec et al\\.", "year": 2009}, {"title": "Gated graph sequence neural networks", "author": ["Li", "Yujia", "Tarlow", "Daniel", "Brockschmidt", "Marc", "Zemel", "Richard"], "venue": "arXiv preprint arXiv:1511.05493,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Isomorphism of graphs of bounded valence can be tested in polynomial time", "author": ["Luks", "Eugene M"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Luks and M.,? \\Q1982\\E", "shortCiteRegEx": "Luks and M.", "year": 1982}, {"title": "Practical graph isomorphism, {II", "author": ["McKay", "Brendan D", "Piperno", "Adolfo"], "venue": "Journal of Symbolic Computation,", "citeRegEx": "McKay et al\\.,? \\Q2014\\E", "shortCiteRegEx": "McKay et al\\.", "year": 2014}, {"title": "Network motifs: simple building blocks of complex", "author": ["Milo", "Ron", "Shen-Orr", "Shai", "Itzkovitz", "Shalev", "Kashtan", "Nadav", "Chklovskii", "Dmitri", "Alon", "Uri"], "venue": null, "citeRegEx": "Milo et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Milo et al\\.", "year": 2002}, {"title": "The complexity of mckays canonical labeling algorithm", "author": ["Miyazaki", "Takunari"], "venue": "In Groups and Computation II,", "citeRegEx": "Miyazaki and Takunari.,? \\Q1997\\E", "shortCiteRegEx": "Miyazaki and Takunari.", "year": 1997}, {"title": "The structure of scientific collaboration networks", "author": ["Newman", "Mark EJ"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Newman and EJ.,? \\Q2001\\E", "shortCiteRegEx": "Newman and EJ.", "year": 2001}, {"title": "Graph invariant kernels", "author": ["F. Orsini", "P. Frasconi", "Raedt", "L. De"], "venue": "In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "Orsini et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Orsini et al\\.", "year": 2015}, {"title": "The graph neural network model", "author": ["F. Scarselli", "M. Gori", "A.C. Tsoi", "M. Hagenbuchner", "G. Monfardini"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "Scarselli et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Scarselli et al\\.", "year": 2009}, {"title": "Weisfeiler-lehman graph kernels", "author": ["2009. Shervashidze", "Nino", "Schweitzer", "Pascal", "van Leeuwen", "Erik Jan", "Mehlhorn", "Kurt", "Borgwardt", "Karsten M"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Shervashidze et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shervashidze et al\\.", "year": 2011}, {"title": "Statistical evaluation of the predictive toxicology challenge 2000\u20132001", "author": ["Toivonen", "Hannu", "Srinivasan", "Ashwin", "King", "Ross D", "Kramer", "Stefan", "Helma", "Christoph"], "venue": null, "citeRegEx": "Toivonen et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Toivonen et al\\.", "year": 2003}, {"title": "Comparison of descriptor spaces for chemical compound retrieval and classification", "author": ["Wale", "Nikil", "Karypis", "George"], "venue": "In Proceedings of the International Conference on Data Mining (ICDM), pp", "citeRegEx": "Wale et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Wale et al\\.", "year": 2006}, {"title": "Atomnet: A deep convolutional neural network for bioactivity prediction in structure-based drug", "author": ["Wallach", "Izhar", "Dzamba", "Michael", "Heifets", "Abraham"], "venue": "discovery. CoRR,", "citeRegEx": "Wallach et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wallach et al\\.", "year": 2015}, {"title": "A reduction of a graph to a canonical form and an algebra arising during this reduction", "author": ["Weisfeiler", "Boris", "Lehman", "AA"], "venue": "Nauchno-Technicheskaya Informatsia,", "citeRegEx": "Weisfeiler et al\\.,? \\Q1968\\E", "shortCiteRegEx": "Weisfeiler et al\\.", "year": 1968}, {"title": "Deep graph kernels", "author": ["Yanardag", "Pinar", "S.V.N. Vishwanathan"], "venue": "In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Yanardag et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yanardag et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 1, "context": "The proposed approach builds on concepts from convolutional neural networks (CNNs) (Fukushima, 1980; Atlas et al., 1988; LeCun et al., 1998; 2015) for images and extends them to arbitrary graphs.", "startOffset": 83, "endOffset": 146}, {"referenceID": 21, "context": "The proposed approach builds on concepts from convolutional neural networks (CNNs) (Fukushima, 1980; Atlas et al., 1988; LeCun et al., 1998; 2015) for images and extends them to arbitrary graphs.", "startOffset": 83, "endOffset": 146}, {"referenceID": 26, "context": "Second, for a number of applications, ranging from computational biology to social network analysis, it is important to visualize learned network motifs (Milo et al., 2002).", "startOffset": 153, "endOffset": 172}, {"referenceID": 19, "context": "Two representative classes of kernels are the skew spectrum kernel (Kondor & Borgwardt, 2008) and kernels based on graphlets (Kondor et al., 2009; Shervashidze et al., 2009).", "startOffset": 125, "endOffset": 173}, {"referenceID": 26, "context": "These subgraphs, which are often called motifs or graphlets, reflect functional network properties (Milo et al., 2002; Alon, 2007).", "startOffset": 99, "endOffset": 130}, {"referenceID": 31, "context": "An effective class of graph kernels are the Weisfeiler-Lehman (WL) kernels (Shervashidze et al., 2011).", "startOffset": 75, "endOffset": 102}, {"referenceID": 29, "context": "Deep graph kernels (Yanardag & Vishwanathan, 2015) and graph invariant kernels (Orsini et al., 2015) compare graphs based on the existence or count of small substructures such as shortest paths (Borgwardt & Kriegel, 2005), graphlets, subtrees, and other graph invariants (Haussler, 1999; Orsini et al.", "startOffset": 79, "endOffset": 100}, {"referenceID": 29, "context": ", 2015) compare graphs based on the existence or count of small substructures such as shortest paths (Borgwardt & Kriegel, 2005), graphlets, subtrees, and other graph invariants (Haussler, 1999; Orsini et al., 2015).", "startOffset": 178, "endOffset": 215}, {"referenceID": 31, "context": "Moreover, while all graph kernels have a training complexity at least quadratic in the number of graphs (Shervashidze et al., 2011), which is prohibitive for large-scale problems, PATCHY-SAN scales linearly with the number of graphs.", "startOffset": 104, "endOffset": 131}, {"referenceID": 30, "context": "Graph neural networks (GNNs) (Scarselli et al., 2009) are a recurrent neural network architecture defined on graphs.", "startOffset": 29, "endOffset": 53}, {"referenceID": 23, "context": "Gated Graph Sequence Neural Networks modify GNNs to use gated recurrent units and to output sequences (Li et al., 2015).", "startOffset": 102, "endOffset": 119}, {"referenceID": 6, "context": "Recent work extended CNNs to topologies that differ from the low-dimensional grid structure (Bruna et al., 2014; Henaff et al., 2015).", "startOffset": 92, "endOffset": 133}, {"referenceID": 13, "context": "Recent work extended CNNs to topologies that differ from the low-dimensional grid structure (Bruna et al., 2014; Henaff et al., 2015).", "startOffset": 92, "endOffset": 133}, {"referenceID": 1, "context": "CNNs were developed in the 1980s and have been applied to image, speech, text, and drug discovery problems (Atlas et al., 1988; LeCun et al., 1989; 1998; 2015; Wallach et al., 2015).", "startOffset": 107, "endOffset": 181}, {"referenceID": 20, "context": "CNNs were developed in the 1980s and have been applied to image, speech, text, and drug discovery problems (Atlas et al., 1988; LeCun et al., 1989; 1998; 2015; Wallach et al., 2015).", "startOffset": 107, "endOffset": 181}, {"referenceID": 34, "context": "CNNs were developed in the 1980s and have been applied to image, speech, text, and drug discovery problems (Atlas et al., 1988; LeCun et al., 1989; 1998; 2015; Wallach et al., 2015).", "startOffset": 107, "endOffset": 181}, {"referenceID": 15, "context": "Color refinement has attracted considerable interest in the ML community as it can be applied to speed-up inference in graphical models (Kersting et al., 2009; 2014) and as a method to compute graph kernels (Shervashidze et al.", "startOffset": 136, "endOffset": 165}, {"referenceID": 31, "context": ", 2009; 2014) and as a method to compute graph kernels (Shervashidze et al., 2011).", "startOffset": 55, "endOffset": 82}, {"referenceID": 2, "context": "Due to the constant size k of the neighborhood graphs, the algorithm runs in time polynomial in the size of the original graph and, on average, in time linear in k (Babai et al., 1980).", "startOffset": 164, "endOffset": 184}, {"referenceID": 4, "context": "For instance, for the Weisfeiler-Lehman algorithm, which has a complexity of O((n + m) log(n)) (Berkholz et al., 2013), and constants w n and k n, the complexity of PATCHY-SAN is linear in N and quasi-linear in m and n.", "startOffset": 95, "endOffset": 118}, {"referenceID": 22, "context": "torus is a periodic lattice with 10, 000 nodes; random is a random undirected graph with degree distribution P (k) \u221d 1/k and kmax = 3; power is a network representing the topology of a power grid in the US; polbooks is a co-purchasing network of books about US politics published during the 2004 presidential election; preferential is a preferential attachment network model where newly added vertices have degree 3; astro-ph is a coauthorship network between authors of preprints posted on the astrophysics arxiv (Newman, 2001); email-enron is a communication network generated from about half a million sent emails (Leskovec et al., 2009).", "startOffset": 617, "endOffset": 640}, {"referenceID": 32, "context": "PTC consists of 344 chemical compounds where classes indicate carcinogenicity for male and female rats (Toivonen et al., 2003).", "startOffset": 103, "endOffset": 126}, {"referenceID": 11, "context": "We compared PATCHY-SAN with the shortest-path kernel (SP) (Borgwardt & Kriegel, 2005), the random walk kernel (RW) (Gaertner et al., 2003), the graphlet count kernel (GK) (Shervashidze et al.", "startOffset": 115, "endOffset": 138}, {"referenceID": 31, "context": ", 2009), and the Weisfeiler-Lehman subtree kernel (WL) (Shervashidze et al., 2011).", "startOffset": 55, "endOffset": 82}], "year": 2016, "abstractText": "Numerous important problems can be framed as learning from graph data. We propose a framework for learning convolutional neural networks for arbitrary graphs. These graphs may be undirected, directed, and with both discrete and continuous node and edge attributes. Analogous to image-based convolutional networks that operate on locally connected regions of the input, we present a general approach to extracting locally connected regions from graphs. Using established benchmark data sets, we demonstrate that the learned feature representations are competitive with state of the art graph kernels and that their computation is highly efficient.", "creator": "LaTeX with hyperref package"}}}