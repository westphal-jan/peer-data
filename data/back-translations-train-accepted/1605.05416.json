{"id": "1605.05416", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-May-2016", "title": "Leveraging Lexical Resources for Learning Entity Embeddings in Multi-Relational Data", "abstract": "Recent work in learning vector-space embeddings for multi-relational data has focused on combining relational information derived from knowledge bases with distributional information derived from large text corpora. We propose a simple approach that leverages the descriptions of entities or phrases available in lexical resources, in conjunction with distributional semantics, in order to derive a better initialization for training relational models. Applying this initialization to the TransE model results in significant new state-of-the-art performances on the WordNet dataset, decreasing the mean rank from the previous best of 212 to 51. It also results in faster convergence of the entity representations. We find that there is a trade-off between improving the mean rank and the hits@10 with this approach. This illustrates that much remains to be understood regarding performance improvements in relational models.", "histories": [["v1", "Wed, 18 May 2016 01:45:32 GMT  (432kb,D)", "http://arxiv.org/abs/1605.05416v1", "6 pages. Accepted to ACL 2016 (short paper)"]], "COMMENTS": "6 pages. Accepted to ACL 2016 (short paper)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["teng long", "ryan lowe", "jackie chi kit cheung", "doina precup"], "accepted": true, "id": "1605.05416"}, "pdf": {"name": "1605.05416.pdf", "metadata": {"source": "CRF", "title": "Leveraging Lexical Resources for Learning Entity Embeddings in Multi-Relational Data", "authors": ["Teng Long", "Ryan Lowe", "Jackie Chi", "Kit Cheung", "Doina Precup"], "emails": ["teng.long@mail.mcgill.ca", "ryan.lowe@cs.mcgill.ca", "jcheung@cs.mcgill.ca", "dprecup@cs.mcgill.ca", "hits@10"], "sections": [{"heading": "1 Introduction", "text": "This year, it has come to the point where you feel able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "2 Related Work", "text": "Dictionary definitions were the core component of early methodologies in the literal sense of the word disambiguation (WSD), such as the reading algorithm (1986). Chen et al. (2014) build on the use of synset glosses for WSD by using lexical resources, and our work continues to link these glosses to relational semantics, a link that has not yet been traced in literature. Integration of lexical resources into distributional semantics has been explored in other lexical semantic tasks, such as synonym expansion (Sinha and Mihalcea, 2009), relation extraction (Kambhatla, 2004), and calculation of the semantic distance between concepts (Mohammad, 2008; Marton et al, 2009). We aim to combine lexical resources and other semantic knowledge, but we do so in the context of neural network-based pre-semantic, rather than in-specific semantic."}, {"heading": "3 Architecture of the Approach", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 The TransE Model", "text": "The Translating Embedding (TransE) model (Bordes et al., 2013) has become one of the most popular multirelational models due to its relative simplicity, scalability to large data sets, and (until recently) state-of-the-art results. It assumes a simple additive interaction between vector representations of units and relationships. Specifically, one assumes that a given triplet (h, l, t) is valid; then the embedding of the object t should be very close to the embedding of the subject h plus any vector in Rk that applies to the relationship l3.For each positive triplet (h, l, t); a negative triplet (h, l, t) is constructed by randomly scanning a unit of E to replace either the subject h or the object t of the relationship."}, {"heading": "3.2 Initializing Representations with Entity Descriptions", "text": "We propose to use some external lexical resources to improve the quality of entity vector representations. Generally, this could consist of product descriptions in a product database or information from a web resource. We use entity descriptions that are readily available for WordNET and Freebase datasets. Although there are many ways to integrate this, we propose a simple method in which entity descriptions are used to initialize entity representations of the model, which we show to have empirical advantages. Specifically, we first dissect the description of a given entity into a sequence of word vectors and combine them into a single embedding by averaging. We then reduce dimensionality through the Principle Component Analysis (PCA), which we find 3Note that we use h, l, t, Rk to name both entities as entities and relationships, as the entities and the entifications as the entities."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Training and Testing Setup", "text": "We perform experiments on the WordNet (WN) (Miller, 1995) and Freebase (FB15k) (Bollacker et al., 2008) data sets used by the original TransE model. TransE hyperparameters include the learning rate \u03bb for stochastic gradient descent, the margin \u03b3 for hinge loss, the dimension of embedding k, and the imbalance metric d. For the TransE model with random initialization, we use the optimal hyperparameters (Bordes et al., 2013): for WN, \u03bb = 0.01, \u03b3 = 2, k = 20, and d = L1 standard; for FB15k, \u03bb = 0.5, k = L2 standard. The values of k were further tested to ensure that k = 20 and k = 50 were optimal."}, {"heading": "4.2 Results and Analysis", "text": "This year, it is only a matter of time before we reach an agreement."}, {"heading": "5 Conclusion and Future Work", "text": "We have shown that the use of external lexical resources, together with distribution semantics, can lead to both a significantly improved optimum and faster convergence when applied to the TransE relational data model. We have established new state-of-the-art results on WordNet and obtained small improvements in state-of-the-art relational raw data for Freebase. Our method is quite simple and could easily be applied to other models that use vector representations as input. Further research is needed to investigate whether performance can be improved in other NLP tasks by using available lexical resources in a similar way. Alternatively, more complex methods for initializing methods could easily be developed, e.g. by using inverse document frequency (idf) weighted averaging or by applying the work of Le et al. (2014) to sales vectors. Alternatively, the distribution secs could be used as a regulatory tool similar to leveraged results (e.g. laboratory and fictitious)."}], "references": [{"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Kurt Bollacker", "Colin Evans", "Praveen Paritosh", "Tim Sturge", "Jamie Taylor."], "venue": "Proceedings of SIGMOD.", "citeRegEx": "Bollacker et al\\.,? 2008", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Learning structured embeddings of knowledge bases", "author": ["Antoine Bordes", "Jason Weston", "Ronan Collobert", "Yoshua Bengio."], "venue": "Proceedings of AAAI.", "citeRegEx": "Bordes et al\\.,? 2011", "shortCiteRegEx": "Bordes et al\\.", "year": 2011}, {"title": "Translating embeddings for modeling multirelational data", "author": ["Antoine Bordes", "Nicolas Usunier", "Alberto GarciaDuran", "Jason Weston", "Oksana Yakhnenko."], "venue": "Proceedings of NIPS.", "citeRegEx": "Bordes et al\\.,? 2013", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "A unified model for word sense representation and disambiguation", "author": ["Xinxiong Chen", "Zhiyuan Liu", "Maosong Sun."], "venue": "EMNLP, pages 1025\u20131035. Citeseer.", "citeRegEx": "Chen et al\\.,? 2014", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Manaal Faruqui", "Jesse Dodge", "Sujay K Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A Smith."], "venue": "Proceedings of NAACL.", "citeRegEx": "Faruqui et al\\.,? 2015", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "Incorporating both distributional and relational semantics in word representations", "author": ["Daniel Fried", "Kevin Duh."], "venue": "In Proceedings of ICLR.", "citeRegEx": "Fried and Duh.,? 2015", "shortCiteRegEx": "Fried and Duh.", "year": 2015}, {"title": "Knowledge graph embedding via dynamic mapping matrix", "author": ["Guoliang Ji", "Shizhu He", "Liheng Xu", "Kang Liu", "Jun Zhao."], "venue": "Proceedings of ACL.", "citeRegEx": "Ji et al\\.,? 2015", "shortCiteRegEx": "Ji et al\\.", "year": 2015}, {"title": "Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations", "author": ["Nanda Kambhatla."], "venue": "Proceedings of ACL on Interactive Poster and Demonstration Sessions.", "citeRegEx": "Kambhatla.,? 2004", "shortCiteRegEx": "Kambhatla.", "year": 2004}, {"title": "Re-embedding words", "author": ["Igor Labutov", "Hod Lipson."], "venue": "Proceedings of ACL.", "citeRegEx": "Labutov and Lipson.,? 2013", "shortCiteRegEx": "Labutov and Lipson.", "year": 2013}, {"title": "Distributed representations of sentences and documents", "author": ["Quoc V Le", "Tomas Mikolov."], "venue": "Proceedings of ICML.", "citeRegEx": "Le and Mikolov.,? 2014", "shortCiteRegEx": "Le and Mikolov.", "year": 2014}, {"title": "Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone", "author": ["Michael Lesk."], "venue": "Proceedings of SIGDOC.", "citeRegEx": "Lesk.,? 1986", "shortCiteRegEx": "Lesk.", "year": 1986}, {"title": "Estimating semantic distance using soft semantic constraints in knowledge-source-corpus hybrid models", "author": ["Yuval Marton", "Saif Mohammad", "Philip Resnik."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Marton et al\\.,? 2009", "shortCiteRegEx": "Marton et al\\.", "year": 2009}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "Proceedings of ICLR.", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Linguistic regularities in continuous space word representations", "author": ["Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig."], "venue": "Proceedings of NAACLHLT.", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Wordnet: a lexical database for english", "author": ["George A Miller."], "venue": "Communications of the ACM, 38(11):39\u201341.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Measuring semantic distance using distributional profiles of concepts", "author": ["Saif Mohammad."], "venue": "Ph.D. thesis, University of Toronto.", "citeRegEx": "Mohammad.,? 2008", "shortCiteRegEx": "Mohammad.", "year": 2008}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Autoextend: Extending word embeddings to embeddings for synsets and lexemes", "author": ["Sascha Rothe", "Hinrich Sch\u00fctze."], "venue": "Proceedings of ACL.", "citeRegEx": "Rothe and Sch\u00fctze.,? 2015", "shortCiteRegEx": "Rothe and Sch\u00fctze.", "year": 2015}, {"title": "Combining lexical resources for contextual synonym expansion", "author": ["Ravi Sinha", "Rada Mihalcea."], "venue": "Proceedings of RANLP.", "citeRegEx": "Sinha and Mihalcea.,? 2009", "shortCiteRegEx": "Sinha and Mihalcea.", "year": 2009}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["Richard Socher", "Danqi Chen", "Christopher D Manning", "Andrew Ng."], "venue": "Proceedings of NIPS.", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "The mechanism of additive composition", "author": ["Ran Tian", "Naoaki Okazaki", "Kentaro Inui."], "venue": "arXiv preprint arXiv:1511.08407.", "citeRegEx": "Tian et al\\.,? 2015", "shortCiteRegEx": "Tian et al\\.", "year": 2015}, {"title": "Observed versus latent features for knowledge base and text inference", "author": ["Kristina Toutanova", "Danqi Chen."], "venue": "Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality.", "citeRegEx": "Toutanova and Chen.,? 2015", "shortCiteRegEx": "Toutanova and Chen.", "year": 2015}, {"title": "Towards universal paraphrastic sentence embeddings", "author": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu."], "venue": "arXiv preprint arXiv:1511.08198.", "citeRegEx": "Wieting et al\\.,? 2015", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "Rcnet: A general framework for incorporating knowledge into word representations", "author": ["Chang Xu", "Yalong Bai", "Jiang Bian", "Bin Gao", "Gang Wang", "Xiaoguang Liu", "Tie-Yan Liu."], "venue": "Proceedings of CIKM.", "citeRegEx": "Xu et al\\.,? 2014", "shortCiteRegEx": "Xu et al\\.", "year": 2014}, {"title": "Embedding entities and relations for learning and inference in knowledge bases", "author": ["Bishan Yang", "Wen-tau Yih", "Xiaodong He", "Jianfeng Gao", "Li Deng."], "venue": "Proceedings of ICLR.", "citeRegEx": "Yang et al\\.,? 2015", "shortCiteRegEx": "Yang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 12, "context": "For example, Mikolov et al. (2013b)", "startOffset": 13, "endOffset": 36}, {"referenceID": 1, "context": "Concurrent to that work, Bordes et al. (2013) proposed translating embeddings (TransE), which takes a pre-existing semantic hierarchy as inW2V GloVe Dataset Total found% found%", "startOffset": 25, "endOffset": 46}, {"referenceID": 4, "context": "A natural next step is to attempt to integrate the two approaches in order to develop a representation that is informed by both unstructured text and a structured knowledge base (Faruqui et al., 2015; Xu et al., 2014; Fried and Duh, 2015; Yang et al., 2015).", "startOffset": 178, "endOffset": 257}, {"referenceID": 23, "context": "A natural next step is to attempt to integrate the two approaches in order to develop a representation that is informed by both unstructured text and a structured knowledge base (Faruqui et al., 2015; Xu et al., 2014; Fried and Duh, 2015; Yang et al., 2015).", "startOffset": 178, "endOffset": 257}, {"referenceID": 5, "context": "A natural next step is to attempt to integrate the two approaches in order to develop a representation that is informed by both unstructured text and a structured knowledge base (Faruqui et al., 2015; Xu et al., 2014; Fried and Duh, 2015; Yang et al., 2015).", "startOffset": 178, "endOffset": 257}, {"referenceID": 24, "context": "A natural next step is to attempt to integrate the two approaches in order to develop a representation that is informed by both unstructured text and a structured knowledge base (Faruqui et al., 2015; Xu et al., 2014; Fried and Duh, 2015; Yang et al., 2015).", "startOffset": 178, "endOffset": 257}, {"referenceID": 14, "context": "This is demonstrated by achieving stateof-the-art mean rank on an entity ranking task on two very different data sets: WordNet synsets with lexical semantic relations (Miller, 1995), and Freebase named entities with general semantic relations (Bollacker et al.", "startOffset": 167, "endOffset": 181}, {"referenceID": 0, "context": "This is demonstrated by achieving stateof-the-art mean rank on an entity ranking task on two very different data sets: WordNet synsets with lexical semantic relations (Miller, 1995), and Freebase named entities with general semantic relations (Bollacker et al., 2008).", "startOffset": 243, "endOffset": 267}, {"referenceID": 9, "context": "Dictionary definitions were the core component of early methods in word sense disambiguation (WSD), such as the Lesk algorithm (1986). Chen et al.", "startOffset": 112, "endOffset": 134}, {"referenceID": 3, "context": "Chen et al. (2014) build on the use of synset glosses for WSD by leveraging lexical resources.", "startOffset": 0, "endOffset": 19}, {"referenceID": 18, "context": "such as synonym expansion (Sinha and Mihalcea, 2009), relation extraction (Kambhatla, 2004), and calculating the semantic distance between con-", "startOffset": 26, "endOffset": 52}, {"referenceID": 7, "context": "such as synonym expansion (Sinha and Mihalcea, 2009), relation extraction (Kambhatla, 2004), and calculating the semantic distance between con-", "startOffset": 74, "endOffset": 91}, {"referenceID": 15, "context": "cepts (Mohammad, 2008; Marton et al., 2009).", "startOffset": 6, "endOffset": 43}, {"referenceID": 11, "context": "cepts (Mohammad, 2008; Marton et al., 2009).", "startOffset": 6, "endOffset": 43}, {"referenceID": 23, "context": "Other approaches modify the objective function or change the structure of the model in order to integrate distributional and relational information (Xu et al., 2014; Fried and Duh, 2015; Toutanova and Chen, 2015).", "startOffset": 148, "endOffset": 212}, {"referenceID": 5, "context": "Other approaches modify the objective function or change the structure of the model in order to integrate distributional and relational information (Xu et al., 2014; Fried and Duh, 2015; Toutanova and Chen, 2015).", "startOffset": 148, "endOffset": 212}, {"referenceID": 21, "context": "Other approaches modify the objective function or change the structure of the model in order to integrate distributional and relational information (Xu et al., 2014; Fried and Duh, 2015; Toutanova and Chen, 2015).", "startOffset": 148, "endOffset": 212}, {"referenceID": 15, "context": "Rothe and Sch\u00fctze (2015) use Wordnet as a lexical resource to learn embeddings for synsets and lexemes.", "startOffset": 0, "endOffset": 25}, {"referenceID": 15, "context": "Rothe and Sch\u00fctze (2015) use Wordnet as a lexical resource to learn embeddings for synsets and lexemes. Perhaps most related to our work are previous relational models that initialize their embeddings via distributional semantics calculated from a larger corpus. Socher et al. (2013) propose the Neural Tensor Network (NTN), and Yang et al.", "startOffset": 0, "endOffset": 284}, {"referenceID": 15, "context": "Rothe and Sch\u00fctze (2015) use Wordnet as a lexical resource to learn embeddings for synsets and lexemes. Perhaps most related to our work are previous relational models that initialize their embeddings via distributional semantics calculated from a larger corpus. Socher et al. (2013) propose the Neural Tensor Network (NTN), and Yang et al. (2015) the Bilinear model using this technique.", "startOffset": 0, "endOffset": 348}, {"referenceID": 4, "context": "Faruqui et al. (2015) retrofit word vectors after they are trained according to distributional criteria.", "startOffset": 0, "endOffset": 22}, {"referenceID": 2, "context": "The Translating Embedding (TransE) model (Bordes et al., 2013) has become one of the most popu-", "startOffset": 41, "endOffset": 62}, {"referenceID": 12, "context": "these word vectors using distributed representations computed using word2vec (Mikolov et al., 2013a) and GloVe (Pennington et al.", "startOffset": 77, "endOffset": 100}, {"referenceID": 16, "context": ", 2013a) and GloVe (Pennington et al., 2014).", "startOffset": 19, "endOffset": 44}, {"referenceID": 20, "context": "Approximating compositionality by averaging vector representations is simple, yet has some theoretical justification (Tian et al., 2015) and can work well in practice (Wieting et al.", "startOffset": 117, "endOffset": 136}, {"referenceID": 22, "context": ", 2015) and can work well in practice (Wieting et al., 2015).", "startOffset": 38, "endOffset": 60}, {"referenceID": 14, "context": "We perform experiments on the WordNet (WN) (Miller, 1995) and Freebase (FB15k) (Bollacker et al.", "startOffset": 43, "endOffset": 57}, {"referenceID": 0, "context": "We perform experiments on the WordNet (WN) (Miller, 1995) and Freebase (FB15k) (Bollacker et al., 2008) datasets used by the original TransE model.", "startOffset": 79, "endOffset": 103}, {"referenceID": 2, "context": "For the TransE model with random initialization, we use the optimal hyperparameters from (Bordes et al., 2013): for WN, \u03bb = 0.", "startOffset": 89, "endOffset": 110}, {"referenceID": 2, "context": "We use the same train/test/validation split and evaluation procedure as (Bordes et al., 2013): for each test triplet (h, l, t), we remove entity h and t in turn, and rank each entity in the dictionary", "startOffset": 72, "endOffset": 93}, {"referenceID": 1, "context": "m od el s SE (Bordes et al., 2011) \u2014 1,011 985 68.", "startOffset": 13, "endOffset": 34}, {"referenceID": 6, "context": "8% TransD (unif) (Ji et al., 2015) \u2014 242 229 79.", "startOffset": 17, "endOffset": 34}, {"referenceID": 6, "context": "2% TransD (bern) (Ji et al., 2015) \u2014 224 212 79.", "startOffset": 17, "endOffset": 34}, {"referenceID": 1, "context": "We compare against the TransE model with random initialization, and the SE model (Bordes et al., 2011).", "startOffset": 81, "endOffset": 102}, {"referenceID": 6, "context": "We also compare against the state-ofthe-art TransD model (Ji et al., 2015).", "startOffset": 57, "endOffset": 74}, {"referenceID": 8, "context": "Alternatively, distributional semantics could be used as a regularizer, similar to (Labutov and Lipson, 2013), with learned embeddings being penalized for how far they stray from the pre-trained GloVe embeddings.", "startOffset": 83, "endOffset": 109}], "year": 2016, "abstractText": "Recent work in learning vector-space embeddings for multi-relational data has focused on combining relational information derived from knowledge bases with distributional information derived from large text corpora. We propose a simple approach that leverages the descriptions of entities or phrases available in lexical resources, in conjunction with distributional semantics, in order to derive a better initialization for training relational models. Applying this initialization to the TransE model results in significant new stateof-the-art performances on the WordNet dataset, decreasing the mean rank from the previous best of 212 to 51. It also results in faster convergence of the entity representations. We find that there is a tradeoff between improving the mean rank and the hits@10 with this approach. This illustrates that much remains to be understood regarding performance improvements in relational models.", "creator": "TeX"}}}