{"id": "1605.05433", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "18-May-2016", "title": "Relations such as Hypernymy: Identifying and Exploiting Hearst Patterns in Distributional Vectors for Lexical Entailment", "abstract": "We consider the task of predicting lexical entailment using distributional vectors. We focus experiments on one previous classifier which was shown to only learn to detect prototypicality of a word pair. Analysis shows that the model single-mindedly learns to detect Hearst Patterns, which are well known to be predictive of lexical relations. We present a new model which exploits this Hearst Detector functionality, matching or outperforming prior work on multiple data sets.", "histories": [["v1", "Wed, 18 May 2016 04:10:41 GMT  (70kb,D)", "https://arxiv.org/abs/1605.05433v1", null], ["v2", "Fri, 23 Sep 2016 20:31:51 GMT  (72kb,D)", "http://arxiv.org/abs/1605.05433v2", "EMNLP 2016"]], "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["stephen roller", "katrin erk"], "accepted": true, "id": "1605.05433"}, "pdf": {"name": "1605.05433.pdf", "metadata": {"source": "CRF", "title": "Relations such as Hypernymy: Identifying and Exploiting Hearst Patterns in Distributional Vectors for Lexical Entailment", "authors": ["Stephen Roller", "Katrin Erk"], "emails": ["roller@cs.utexas.edu", "katrin.erk@mail.utexas.edu"], "sections": [{"heading": "1 Introduction", "text": "As the field of natural language processing has evolved, more ambitious semantic tasks are therefore beginning to be addressed, such as answering questions (QA) and recognizing Textual Entailment (RTE). These systems often depend on the use of lexical resources such as WordNet to derive consequences for individual words, but these resources are expensive to develop and always have limited scope. To solve these problems, much work has been done on how lexical engagements can be automatically derived using distribution semantics. Some focus primarily on the use of unverified techniques and examine measures that emphasize specific word relationships (Baroni and Lenci, 2011). Many are based on the Distributional Inclusion Hypothesis, in which the contexts in which a hypernym appears are a superset of its hyponyms. \""}, {"heading": "2 Background", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight."}, {"heading": "3 Data and Resources", "text": "In fact, the majority of people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move"}, {"heading": "3.1 Distributional Vectors", "text": "In all experiments, we use a standard, count-based, syntactic distribution vector space. We use a corpus consisting of the concatenation of Gigaword, Wikipedia, BNC, and ukWaC. We calculate the corpus using Stanford CoreNLP 3.5.2 (Chen and Manning, 2014) for tokenization, lemmatization, POS tagging, and universal dependency savings. We calculate a syntactic distribution space for the 250k most common lemmats by counting their dependency neighbors throughout the corpus. We use only the top 1M most common dependency attachments as contexts. We use the \"collapsed dependencies\" of CoreNLP, in which prepositional dependencies are broken down, e.g. \"go to the store\" emits the tuples (go, prep: to + store) and (store, prep: \u2212 1)."}, {"heading": "4 Motivating Analysis", "text": "It is indeed the case that we are in a position to find a solution that is capable of finding a solution that is capable of solving, solving and solving the problems."}, {"heading": "4.1 H-Feature Detectors", "text": "In fact, most people are able to decide for themselves what they want and what they don't want."}, {"heading": "5 Proposed Model", "text": "In fact, we are able to find a solution that is capable of finding a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution and that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that enables us to find a solution that we are able to find a solution. \""}, {"heading": "6 Experimental Setup and Evaluation", "text": "In our experiments, we use a variation of 20x cross-validation, which constitutes lexical overlap. To simplify the explanation, we first explain how to create splits for training / testing, and then introduce validation methodology. We first bundle all the words from the previous page (LHS) of the data into a sentence and divide these lexical elements into 20 different cross-validation folds. For each fold Fi, we then use all pairs (w, H) in which w-Fi appears as test set pairs. That is, if \"car\" is in the test set fold, then \"car \u2192 vehicle\" and \"car 9 truck\" will appear as test set pairs. The training set will then be any pair that does not contain any overlap with the test set; for example, the training set will consist of all pairs that do not contain \"car,\" \"truck\" or \"vehicle,\" as either the speed or the result is dramatic."}, {"heading": "6.1 Hyperparameter Optimization", "text": "To handle hyperparameter selection, we actually create the test set with fold i and use fold i \u2212 1 as validation set (removal of pairs that would overlap with the test) and the remaining 18 folds as training (removal of pairs that would overlap with the test or validation). We select hyperparameters using the grid search. In all models, we optimize the regulation parameter C \u044e {10 \u2212 4, 10 \u2212 3,.,.., 104} and in our proposed model, the number of iterations n, {1,..., 6}. All other hyperparameters remain as default values of Scikit-Learn (Pedregosa et al., 2011), except for the use of balanced class weights. Without balanced class weights, some of the basic models learn degenerated functions (e.g., guess always unconnected)."}, {"heading": "7 Results", "text": "We compare our proposed model with several existing and alternative baselines from the literature. We include a Cosine base classifier that determines only one threshold that maximizes the F1 value on the training set; three linear models from previous work, Concat, Diff and Asym; and the RBF and Ksim models that have proven successful at Kruszewski et al. (2015) and Levy et al. (2015). We also include two other new baselines, Concat + Diff and Concat + Asym, which include a notion of distribution inclusion in the Concat base line but are still linear models. We cannot include baselines such as Ksim + Asym because Ksim is based on a tailored SVM core that is not suitable for combinations. Table 3 shows the results across all four datasets for all the models listed."}, {"heading": "7.1 Ablation Experiments", "text": "In order to assess how important each of the different F characteristics is to the model, we also conducted an ablation experiment in which the classifier is not given similarity (slot 1), prototype H characteristic detectors (slot 2 and 3), or inclusion characteristics (slot 4). To evaluate the importance of these characteristics, we set the regularization parameter at C = 1 and train all the completed classifiers in each training fold with the number of iterations n = 1. Table 4 shows the decrease (absolute difference) in performance between the complete and completed models on the development sets, so that higher numbers indicate a greater importance of the characteristics. We find that the similarity characteristics in the LEDS, BLESS and medical datasets are extremely important, which reinforces the results of Levy et al. (2015). The similarity characteristics are particularly important in the LEDS and BLESS datasets, although these negative characteristics are included in the LEESi and the medical datasets - although many of the LEESi are included in the LEESi examples."}, {"heading": "7.2 Analysis by Number of Iterations", "text": "To assess how iterative function extraction affects model performance, we fix the regularization parameter at C = 1 and train our model by setting the number of iterations to n = {1,.., 6}. We then measure the mean F1 score in the developmental folds and compare it to a baseline that uses only one iteration. Figure 2 shows these results in all four datasets, setting the 0 line at the performance of the n = 1 baseline. Models above 0 benefit from the additional iterations, while models below do not. In the figure, we see that the iterative method moderately improves the performance of LEDS while significantly improving the values of BLESS and TM14, but additional iterations on the medical dataset actually hurt performance. The different curves indicate that the optimal number of iterations is very specific and offers different amounts of improvements."}, {"heading": "8 Conclusion", "text": "Motivated by the fact that the Concat classifier acts as a strong baseline in the literature, we proposed a novel interpretation of the hyperplane of the model. We found that the Concat classifier overwhelmingly functioned as a feature detector that automatically identifies Hearst patterns in the distribution vectors. We proposed a novel model that fully encompasses these H-feature detectors and expands their modeling performance by an iterative process similar to principal component analysis. In each iteration of the process, an H-feature detector is learned and then removed from the data, allowing us to identify several different types of Hearst characteristics in the data. Our final model combines these H-feature detectors with measurements of general similarity and distributed inclusion to integrate the strengths of different models in previous work."}, {"heading": "Acknowledgments", "text": "The authors thank I. Beltagy, Vered Shwartz, Subhashini Venugopalan and the reviewers for their helpful comments and suggestions. This research was supported by the NSF grant IIS 1523637. We thank the Texas Advanced Computing Center for providing grid resources that contributed to these results."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "We consider the task of predicting lexical<lb>entailment using distributional vectors. We<lb>perform a novel qualitative analysis of one<lb>existing model which was previously shown<lb>to only measure the prototypicality of word<lb>pairs. We find that the model strongly learns<lb>to identify hypernyms using Hearst patterns,<lb>which are well known to be predictive of lexi-<lb>cal relations. We present a novel model which<lb>exploits this behavior as a method of fea-<lb>ture extraction in an iterative procedure sim-<lb>ilar to Principal Component Analysis. Our<lb>model combines the extracted features with<lb>the strengths of other proposed models in the<lb>literature, and matches or outperforms prior<lb>work on multiple data sets.", "creator": "LaTeX with hyperref package"}}}