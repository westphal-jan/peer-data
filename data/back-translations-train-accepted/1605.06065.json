{"id": "1605.06065", "review": {"conference": "icml", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-May-2016", "title": "One-shot Learning with Memory-Augmented Neural Networks", "abstract": "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \"one-shot learning.\" Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.", "histories": [["v1", "Thu, 19 May 2016 17:44:51 GMT  (2237kb,D)", "http://arxiv.org/abs/1605.06065v1", "13 pages, 8 figures"]], "COMMENTS": "13 pages, 8 figures", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["adam santoro", "sergey bartunov", "matthew botvinick", "daan wierstra", "timothy lillicrap"], "accepted": true, "id": "1605.06065"}, "pdf": {"name": "1605.06065.pdf", "metadata": {"source": "META", "title": "One-shot Learning with Memory-Augmented Neural Networks", "authors": ["Adam Santoro", "Sergey Bartunov", "Matthew Botvinick", "Daan Wierstra"], "emails": ["ADAMSANTORO@GOOGLE.COM", "SBOS@SBOS.IN", "BOTVINICK@GOOGLE.COM", "WIERSTRA@GOOGLE.COM", "COUNTZERO@GOOGLE.COM"], "sections": [{"heading": "1. Introduction", "text": "In fact, most of them are able to survive on their own if they are not able to flourish."}, {"heading": "2. Meta-Learning Task Methodology", "text": "Normally, we try to choose parameters to minimize the learning costs L in some data sets. However, we choose parameters for the metal arning to reduce the expected learning costs in a distribution of the data sets p (D). (1) To achieve this, the correct task definition is crucial (Hochreiter et al., 2001). In our setup, a task or episode includes the presentation of some data sets D = {dt} Tt = 1 = {(xt, yt) Tt = 1. For classification, yt is the class name for a picture text and for regression, yt is the value of a hidden function for a vector with real weighted elements xt, or simply a real number xt (here, for consistency, xt is used).In this setup, yt is both a target \u2212 and an input together with a text class that is time-staggered."}, {"heading": "3. Memory-Augmented Model", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Neural Turing Machines", "text": "The Neural Turing Machine is a fully differentiated implementation of a MAN. It consists of a controller, such as a feed-forward network, or LSTM, that interacts with an external memory module by using a number of read / write heads (Graves et al., 2014). Memory encoding and query in an external memory module (NTM) is fast, with vector representations potentially being placed in or taken out of memory at every step of the process. This capability makes the NTM a perfect candidate for meta-learning and low-shot prediction, as it is able to store both long-term memory by slowly updating its weights, as well as short-term storage via its external memory module. Thus, if an NTM can learn a general strategy for the types of representations it should place in memory and how it should use them later for predictions, then it should be able to predict its speed only once it can tell."}, {"heading": "3.2. Least Recently Used Access", "text": "In previous instances of the NTM (Graves et al., 2014), reminders were addressed by both the content and the location. Location-based addressing was used to promote iterative steps, similar to walking along a ribbon and jumping over long distances in memory. This method was advantageous for sequence-based prediction tasks, but this type of access is not optimal for tasks that emphasize a conjunctive encoding of information regardless of the sequence. \u2212 As such, writing to memory in our model involves using a newly designed access module called Least Recently Used Access (LRUA) module (LRUA), which is a pure content-based memory recorder that writes memories to either the least-used location or the least-used location. This module emphasizes the precise encoding of relevant (i.e., current) information and pure content-based retrieval."}, {"heading": "4. Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Data", "text": "Two data sources were used: Omniglot for classification and sampled functions of a Gaussian process (GP) with fixed hyperparameters for regression. The Omniglot dataset consists of over 1600 separate classes with only a few examples per class, which can aptly be called the transposition of MNIST (Lake et al., 2015). To reduce the risk of overfitting, we performed data augmentation by random translation and rotation of character images. In addition, we created new classes by 90-rotations, 180-rotations and 270-rotations of existing data. Training of all models was conducted on the data of 1200 original classes (plus augmentations), with the remainder of the 423 classes (plus augmentations) used for test experiments. To shorten the processing time of our experiments, we scaled the images to 20 x 20."}, {"heading": "4.2. Omniglot Classification", "text": "In fact, it is such that most of them will be able to move to another world, in which they will be able to move to another world, in which they will be able to move to another world, in which they will be able to move, in which they will move, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live in which they will live, in which they will live, in which they will live, in which they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that they will live, that"}, {"heading": "4.2.1. PERSISTENT MEMORY INTERFERENCE", "text": "A good strategy to use in this classification task, and the strategy that has been artificially imposed so far, is to erase the external memory from episode to episode. Since each episode contains unique classes with unique designations, any information that remains in memory throughout episodes inevitably acts as a disruption to the episode in question. To test the effects of memory interference, we performed the classification task without erasing the external memory between episodes. This task proved to be predictably difficult, and the network was less robust in its ability to achieve accurate classification (Figure 3). In the case of learning hot vector labels in an episode that included five unique classes, learning progressed much more slowly than in the memory erasure state and did not result in the characteristic rapid increase in accuracy that is observed in the memory erasure state (Figure 2). Interestingly, the learning conditions that did not exist in the memory erasure state were not impaired."}, {"heading": "4.2.2. CURRICULUM TRAINING", "text": "Given the successful classification of fifteen-grade episodes, we used a curriculum training program to further scale the model's classification capacities; the network was initially tasked with classifying fifteen classes per episode, and every 10,000 episodes of training thereafter, the maximum number of classes presented per episode was increased by one (Figure 4); the network maintained a high level of accuracy even as the number of classes increased during training; after training, the network was tested on episodes of 50 classes; similar tests continued, increasing the maximum number of classes to 100; the network generally showed gradual declining performance as the number of classes grew toward 100; the network's training limit did not appear to have been reached as its performance continued to rise to the 100,000 episode mark; and assessing the network's maximum capacity provides an interesting opportunity for future work."}, {"heading": "4.3. Regression", "text": "Since our MAN architecture has generated a broad meta-learning strategy, we argued that it would be able to adequately perform regression tasks for never-before-seen functions. To test this, we generated functions from a GP previously with a fixed set of hyperparameters and trained our network with unique functions in each episode. Each episode included the presentation of x values (either 1, 2 or 3-dimensional) along with time offset function values (i.e. f (xt \u2212 1)). A successful strategy involves binding x values with the corresponding function values and storing these bindings in external memory. Since individual x values were presented only once per episode, the successful function prediction included a precise content-based search for proximal information in memory. Unlike the image classification scenario, this task requires a broader reading from memory: The network must learn to read from previously seen points from what appears to be the most accurate memory strategy."}, {"heading": "5. Discussion & Future Work", "text": "In fact, the fact is that most of them will be able to demonstrate that they are able to achieve their goals."}, {"heading": "6. Acknowledgements", "text": "The authors thank Ivo Danihelka and Greg Wayne for helpful discussions and previous work on the NTM and LRU Access architecture, as well as Yori Zwols and many others at Google DeepMind for reviewing the manuscript."}, {"heading": "6.1. Additional model details", "text": "It consists of a number of different components: a), b), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c \", c\", c \", c\", c \", c., c., c., c., c., c., c., c., c., c., c., c., c., c., c., c.,\" c., c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c., \"c.,\" c. \"c.,\" c., \"c.,\" c., \"c.\" c., \"c.,\" c., \"c.\" c., \"c.,\" c. \"c.,\" c., \"c.\" c., \"c.,\" c., \"c.\" c., \"c.,\" c., \"c.\" c., \"c.,\" c., \"c.,\" c. \"c.,\" c., \"c.,\" c., \"c.\" c., \"c.,\" c. \"c., c.,\" c. \"c.,\" c., \"c.\" c., \"c.\" c., \"c.\" c., \"c., c.\" c. \"c.,\" c. \"c.,\" c., c. \"c.,\" c., c. \"c., c.\" c. \"c.,\" c. \"c., c., c.,\" c., c. \"c., c.\" c., c. \"c., c., c., c., c., c."}, {"heading": "6.2. Output distribution", "text": "The output of the controller, ot, is passed on to an output distribution. In classification tasks using one-hot labels, the output of the controller is first passed on to the output distribution by a linear level with an output size corresponding to the number of classes classified per episode. This linear output level is then passed on as input to the output distribution. In a one-hot classification, the output distribution is a categorical distribution that is implemented as a Softmax function.The categorical distribution generates a vector of class probabilities, pt, with elements: pt (i) = exp (Wop (i) ot) \u2211 j exp (Won (j) ot), (24), whereby Wop delivers the weights from the controller output to the linear output.For classification using string labels, the linear output size is kept at 25. This allows the output to be divided into five equal parts of the size 5, each of which is then sent to its independent parts, one of which is likely to have five."}, {"heading": "6.3. Learning", "text": "In the Unit Label Classification, given the probabilities returned by the network, pt, the network minimizes the episode loss of the input sequence: L (\u03b8) = \u2212 \u2211 t yTt logpt, (25) where yt at the time t is the target hot or string label (note: for a given one-hot-class label vector yt only one element takes the value 1, and for a string label vector five elements take the value 1, one per five-element piece \"). In the String Label Classification, the loss is similar: L (\u03b8) = \u2212 \u2211 t \u2211 c yTt (c) logpt (c). (26) Here, the (c) indexes a five-element\" chunk \"of the vector label, of which there are a total of five. In the regression, the output distribution of the network is a Gaussian, and as such receives two values from the linear layer in each time step: the actual distribution by the controller and the actual output layer."}, {"heading": "7. Classification input data", "text": "Input sequences consist of flattened, pixel-based representations of images xt and temporally offset labels yt \u2212 1 (see Figure 8 for an example sequence of images and class identities for an episode of length 50, with five unique classes). First, N unique classes are sampled from the Omniglot dataset, with N being the maximum number of unique classes per episode. N assumes a value of 5, 10, or 15 specified in the experiment description or result table in the main text. Samples from the Omniglot source collection are taken and stored if they are members of the group n unique classes for that episode and are otherwise discarded. 10N samples are retained and form the image data for that episode. Thus, in this constellation, the number of samples per unique class cannot necessarily be the same, and some classes cannot have representative samples. Omniglot images are translated by applying a random rotation between each of 16 and 16 classes at random."}, {"heading": "8. Task", "text": "Either 5, 10 or 15 unique classes per episode will be selected, with episode lengths ten times greater than the number of unique classes (i.e. 50, 100 or 150), unless explicitly stated otherwise. Training will take place for 100,000 episodes. At the 100,000 episode mark, the task will continue, but data will be taken from a fragmented test set (i.e. samples from classes 1201-1623 in the omniglot dataset), and weight updates will be discontinued, known as the \"test phase.\" Curriculum training will increase the maximum number of unique classes per episode by 1 in every 10,000 training episodes, increasing the episode length accordingly to ten times this new maximum."}, {"heading": "9. Parameters", "text": "9.0.1. OPTIMIZATION RmProp was used with a learning rate of 1e \u2212 4 and a maximum learning rate of 5e \u2212 1, a drop of 0.95 and a pulse of 0.9,9.0.2. The FREE GRID SEARCHA PARAMETER grid search was performed using a number of parameters, displaying the values in parentheses: disk space (128), memory size (40), controller size (200 hidden units for an LSTM), learning rate (1e \u2212 4) and number of reads from memory (4). Other free parameters were left constant: write weight breakdown (0.99), minibatch size (16),"}, {"heading": "9.1. Comparisons and controls evaluation metrics", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "9.1.1. HUMAN COMPARISON", "text": "In the human comparison task, participants perform exactly the same experiment as the network: they observe sequences of images and time-shifted labels (sequence length = 50, number of unique classes = 5) and are challenged to predict the class identity for the current input image by typing a single digit on a keyboard. However, participants see the class labels as integers from 1 to 5 and not as single-line vectors or strings. There is no time limit to their selection. Participants are informed about the objectives of the task before starting the task and perform a single, unevaluated test run before their evaluated study. Nine participants each conducted two evaluated studies."}, {"heading": "9.1.2. KNN", "text": "If no data is available (i.e. at the beginning of the training), the kNN classifier randomly returns a single class as a prediction. Therefore, the probability that the prediction is correct is 1N, where N is the number of unique classes in a particular episode. Afterwards, it predicts a class of classes it has observed. Therefore, all examples of samples not belonging to the first observed class cannot be correctly classified until at least one instance is passed to the classifier. As statistics are averaged across classes, the first instance accuracy becomes 1N (1 N + 0) = 1 N2, which corresponds to 4% or 0.4% for 5 or 15 classes per episode, respectively."}], "references": [{"title": "Motor task variation induces structural learning", "author": ["Braun", "Daniel A", "Aertsen", "Ad", "Wolpert", "Daniel M", "Mehring", "Carsten"], "venue": "Current Biology,", "citeRegEx": "Braun et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Braun et al\\.", "year": 2009}, {"title": "Ranking learning algorithms: Using ibl and meta-learning on accuracy and time results", "author": ["Brazdil", "Pavel B", "Soares", "Carlos", "Da Costa", "Joaquim Pinto"], "venue": "Machine Learning,", "citeRegEx": "Brazdil et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Brazdil et al\\.", "year": 2003}, {"title": "Multitask learning", "author": ["Caruana", "Rich"], "venue": "Machine learning,", "citeRegEx": "Caruana and Rich.,? \\Q1997\\E", "shortCiteRegEx": "Caruana and Rich.", "year": 1997}, {"title": "The magical mystery four how is working memory capacity limited, and why", "author": ["Cowan", "Nelson"], "venue": "Current Directions in Psychological Science,", "citeRegEx": "Cowan and Nelson.,? \\Q2010\\E", "shortCiteRegEx": "Cowan and Nelson.", "year": 2010}, {"title": "Introduction to the special issue on meta-learning", "author": ["Giraud-Carrier", "Christophe", "Vilalta", "Ricardo", "Brazdil", "Pavel"], "venue": "Machine learning,", "citeRegEx": "Giraud.Carrier et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Giraud.Carrier et al\\.", "year": 2004}, {"title": "Neural turing machines", "author": ["Graves", "Alex", "Wayne", "Greg", "Danihelka", "Ivo"], "venue": "arXiv preprint arXiv:1410.5401,", "citeRegEx": "Graves et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2014}, {"title": "Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "arXiv preprint arXiv:1502.01852,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Learning to learn using gradient descent", "author": ["Hochreiter", "Sepp", "Younger", "A Steven", "Conwell", "Peter R"], "venue": "In Artificial Neural NetworksICANN", "citeRegEx": "Hochreiter et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 2001}, {"title": "Meta-learning in computational intelligence, volume 358", "author": ["Jankowski", "Norbert", "Duch", "W\u0142odzis\u0142aw", "Grabczewski", "Krzysztof"], "venue": "Springer Science & Business Media,", "citeRegEx": "Jankowski et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jankowski et al\\.", "year": 2011}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Lake", "Brenden M", "Salakhutdinov", "Ruslan", "Tenenbaum", "Joshua B"], "venue": null, "citeRegEx": "Lake et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2015}, {"title": "Layered concept-learning and dynamically variable bias management", "author": ["Rendell", "Larry A", "Sheshu", "Raj", "Tcheng", "David K"], "venue": "In IJCAI,", "citeRegEx": "Rendell et al\\.,? \\Q1987\\E", "shortCiteRegEx": "Rendell et al\\.", "year": 1987}, {"title": "Shifting inductive bias with success-story algorithm, adaptive levin search, and incremental selfimprovement", "author": ["Schmidhuber", "J\u00fcrgen", "Zhao", "Jieyu", "Wiering", "Marco"], "venue": "Machine Learning,", "citeRegEx": "Schmidhuber et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Schmidhuber et al\\.", "year": 1997}, {"title": "Meta-learning in reinforcement learning", "author": ["Schweighofer", "Nicolas", "Doya", "Kenji"], "venue": "Neural Networks,", "citeRegEx": "Schweighofer et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Schweighofer et al\\.", "year": 2003}, {"title": "Lifelong learning algorithms", "author": ["Thrun", "Sebastian"], "venue": "In Learning to learn,", "citeRegEx": "Thrun and Sebastian.,? \\Q1998\\E", "shortCiteRegEx": "Thrun and Sebastian.", "year": 1998}, {"title": "Interference and forgetting", "author": ["Underwood", "Benton J"], "venue": "Psychological review,", "citeRegEx": "Underwood and J.,? \\Q1957\\E", "shortCiteRegEx": "Underwood and J.", "year": 1957}, {"title": "A perspective view and survey of meta-learning", "author": ["Vilalta", "Ricardo", "Drissi", "Youssef"], "venue": "Artificial Intelligence Review,", "citeRegEx": "Vilalta et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Vilalta et al\\.", "year": 2002}, {"title": "Automatic Speech Recognition", "author": ["Yu", "Dong", "Deng", "Li"], "venue": null, "citeRegEx": "Yu et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 6, "context": "This approach has achieved impressive results on many large-scale supervised tasks with raw sensory input, such as image classification (He et al., 2015), speech recognition (Yu & Deng, 2012), and games (Mnih et al.", "startOffset": 136, "endOffset": 153}, {"referenceID": 9, "context": "This kind of flexible adaptation is a celebrated aspect of human learning (Jankowski et al., 2011), manifesting in settings ranging from motor control (Braun et al.", "startOffset": 74, "endOffset": 98}, {"referenceID": 0, "context": ", 2011), manifesting in settings ranging from motor control (Braun et al., 2009) to the acquisition of abstract concepts (Lake et al.", "startOffset": 60, "endOffset": 80}, {"referenceID": 10, "context": ", 2009) to the acquisition of abstract concepts (Lake et al., 2015).", "startOffset": 48, "endOffset": 67}, {"referenceID": 12, "context": "Although the term has been used in numerous senses (Schmidhuber et al., 1997; Caruana, 1997; Schweighofer & Doya, 2003; Brazdil et al., 2003), meta-learning generally refers to a scenario in which an agent learns at two levels, each associated with different time scales.", "startOffset": 51, "endOffset": 141}, {"referenceID": 1, "context": "Although the term has been used in numerous senses (Schmidhuber et al., 1997; Caruana, 1997; Schweighofer & Doya, 2003; Brazdil et al., 2003), meta-learning generally refers to a scenario in which an agent learns at two levels, each associated with different time scales.", "startOffset": 51, "endOffset": 141}, {"referenceID": 4, "context": "This learning is guided by knowledge accrued more gradually across tasks, which captures the way in which task structure varies across target domains (Giraud-Carrier et al., 2004; Rendell et al., 1987; Thrun, 1998).", "startOffset": 150, "endOffset": 214}, {"referenceID": 11, "context": "This learning is guided by knowledge accrued more gradually across tasks, which captures the way in which task structure varies across target domains (Giraud-Carrier et al., 2004; Rendell et al., 1987; Thrun, 1998).", "startOffset": 150, "endOffset": 214}, {"referenceID": 8, "context": "It has been proposed that neural networks with memory capacities could prove quite capable of meta-learning (Hochreiter et al., 2001).", "startOffset": 108, "endOffset": 133}, {"referenceID": 8, "context": "For example, LSTMs trained to meta-learn can quickly learn never-before-seen quadratic functions with a low number of data samples (Hochreiter et al., 2001).", "startOffset": 131, "endOffset": 156}, {"referenceID": 5, "context": "However, recent architectures, such as Neural Turing Machines (NTMs) (Graves et al., 2014) and memory networks (Weston et al.", "startOffset": 69, "endOffset": 90}, {"referenceID": 5, "context": "Additionally, we outline a memory access module that emphasizes memory access by content, and not additionally on memory location, as in original implementations of the NTM (Graves et al., 2014).", "startOffset": 173, "endOffset": 194}, {"referenceID": 8, "context": "To accomplish this, proper task setup is critical (Hochreiter et al., 2001).", "startOffset": 50, "endOffset": 75}, {"referenceID": 5, "context": "It consists of a controller, such as a feed-forward network or LSTM, which interacts with an external memory module using a number of read and write heads (Graves et al., 2014).", "startOffset": 155, "endOffset": 176}, {"referenceID": 5, "context": "In previous instantiations of the NTM (Graves et al., 2014), memories were addressed by both content and location.", "startOffset": 38, "endOffset": 59}, {"referenceID": 10, "context": "The Omniglot dataset consists of over 1600 separate classes with only a few examples per class, aptly lending to it being called the transpose of MNIST (Lake et al., 2015).", "startOffset": 152, "endOffset": 171}], "year": 2016, "abstractText": "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \u201cone-shot learning.\u201d Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory locationbased focusing mechanisms.", "creator": "LaTeX with hyperref package"}}}