{"id": "1605.07683", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-May-2016", "title": "Learning End-to-End Goal-Oriented Dialog", "abstract": "End-to-end dialog systems, in which all components are learnt simultaneously, have recently obtained encouraging successes. However these were mostly on conversations related to chit-chat with no clear objective and for which evaluation is difficult. This paper proposes a set of tasks to test the capabilities of such systems on goal-oriented dialogs, where goal completion ensures a well-defined measure of performance. Built in the context of restaurant reservation, our tasks require to manipulate sentences and symbols, in order to properly conduct conversations, issue API calls and use the outputs of such calls. We show that an end-to-end dialog system based on Memory Networks can reach promising, yet imperfect, performance and learn to perform non-trivial operations. We confirm those results by comparing our system to a hand-crafted slot-filling baseline on data from the second Dialog State Tracking Challenge (Henderson et al., 2014a).", "histories": [["v1", "Tue, 24 May 2016 23:09:58 GMT  (2723kb,D)", "http://arxiv.org/abs/1605.07683v1", null], ["v2", "Thu, 9 Jun 2016 20:47:49 GMT  (1259kb,D)", "http://arxiv.org/abs/1605.07683v2", null], ["v3", "Wed, 25 Jan 2017 00:11:20 GMT  (1265kb,D)", "http://arxiv.org/abs/1605.07683v3", null], ["v4", "Thu, 30 Mar 2017 23:02:22 GMT  (1265kb,D)", "http://arxiv.org/abs/1605.07683v4", "Accepted as a conference paper at ICLR 2017"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["antoine bordes", "y-lan boureau", "jason weston"], "accepted": true, "id": "1605.07683"}, "pdf": {"name": "1605.07683.pdf", "metadata": {"source": "CRF", "title": "Learning End-to-End Goal-Oriented Dialog", "authors": ["Antoine Bordes", "Jason Weston"], "emails": ["abordes@fb.com", "jase@fb.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that most of them are able to survive on their own by taking responsibility for themselves. (...) Most of them are able to survive on their own. (...) Most of them are not able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are not able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are not able to survive on their own. (...) Most of them are not able to survive on their own. (...) Most of them are able to survive on their own. (...) Most of them are not able to survive on their own. (...) Most of them are not able to survive on their own. (...)"}, {"heading": "2 Related Work", "text": "The most successful goal-oriented dialog systems model conversation as partially observable Markov decision-making processes (POMDP) (Young et al., 2013), however, despite recent efforts to learn modules (Henderson et al., 2014b), require many manual functions for the representation of the state and the scope of action that limit their use to narrow areas. Our simulation, with which we generate goal-oriented data sets, can be considered equivalent to the user simulators with which POMDP is trained (Young et al., 2013; Pietquin and Hastie, 2013), but for the training of end-to-end systems. Serban et al. (2015b) list all available corporations for the training of dialogue systems, and unfortunately there are no reliable resources to train and test end-to-end models in goal-oriented scenarios. In fact, goal-oriented data sets are usually designed in such a way that end-to-situation questions (Henderson and Components only) are not suitable for end-to-situation questions (Henderson)."}, {"heading": "3 Goal-Oriented Dialog Tasks", "text": "All of our tasks include a restaurant reservation system where the user's goal in each conversation is to book a table in a restaurant. The first five tasks are created using a simulation, and the last one includes real human bot dialogs. Data for all tasks is available at http: / / fb.ai / babi."}, {"heading": "3.1 Restaurant Reservation Simulation", "text": "The simulation is based on an underlying KB, consisting of facts that define all the restaurants that can be booked and their characteristics. Each restaurant is defined by a type of cuisine (10 choices such as French, Thai, etc.), a location (10 choices such as London, Tokyo, etc.), a price range (cheap, moderate or expensive) and a rating (from 1 to 8). In addition, for the sake of simplicity, we assume that each restaurant only has availability for a single group size (2, 4, 6 or 8 people). Each restaurant also has an address and a phone number listed in KB. KB can be queried using API calls that return the list of facts related to the respective restaurants. Each query must contain four fields: a location, a type of cuisine, a price range and a group size. Facts about one, several or no restaurants (depending on the group size) can be returned."}, {"heading": "3.1.1 Task Definitions", "text": "Task 1 and 2 test dialog management to see if end-to-end systems can learn to implicitly track the status of the dialog (never explicitly stated), while Task 3 and 4 test whether they can learn to use KB facts in a dialog situation. Task 3 also requires them to learn to sort. Task 5 combines all the tasks. Task 1: Issuing API calls In response to a user request, a user request is generated that can contain from 0 to 4 of the required fields (uniformly sampled; in Figure 1 it contains 3). The bot must ask questions to fill in the missing fields and finally generate the correct corresponding API calls. The order in which the bot asks for information is dissuasive so that it can be predicted. Task 2: Updating API calls by executing an API call, as in Task 1."}, {"heading": "3.1.2 Datasets", "text": "We want to test the ability of systems to handle units that appear in the KB but not in the dialog training sets. To do this, we split types of kitchens and locations into two halves and create two KBs, one with all the facts about restaurants in the first half and another with the rest. As a result, we get 2 KBs with 4,200 facts and 600 restaurants (5 types of kitchens \u00d7 5 locations \u00d7 3 price ranges \u00d7 8 reviews) that only share price ranges, ratings and party sizes but have fragmented sets of restaurants, locations, kitchens and addresses. We use one of the KBs to generate the standard training, validation and test dialogs, and use the other KBs only to generate test dialogs that are called out-of-vocabulary. (OOV) Test sets, systems have access to the training examples and both KBs, and we evaluate both test dialogs."}, {"heading": "3.2 Dialog State Tracking Challenge", "text": "Since our tasks are based only on a synthetically generated language for the user, we also supplement our data set with real human bot conversations. We do this by using data from the 2nd Dialog State Tracking Challenge (Henderson et al., 2014a), which is also located in the restaurant booking area. In contrast to our tasks, user requests require only 3 fields: type of cuisine (91 choices), location (5 choices) and price range (3 choices). Originally, the data set was designed for dialogue status tracking, so each dialogue is labeled with a state (user intention + slots) that needs to be predicted. We did not use this, but converted the data into the format of our 5 tasks and as task 6.We used the language transcriptions provided to create the user and the bot expressions, and given the dialog states that we created the PI calls to the KB and added them to the dialogues that we added."}, {"heading": "4 Models", "text": "We evaluate various learning methods for our goal-oriented dialogue tasks: storage networks, supervised embedding, classical methods of obtaining information and rules-based systems."}, {"heading": "4.1 Memory Networks", "text": "We are using the MemN2N architecture of Sukhbaatar et al. (2015), with an additional modification to deal with exact matches and short-term model candidates for our tasks, which are briefly described. We are using the MemN2N architecture of Sukhbaatar et al. (2015) are a current class of models that have been applied to a number of natural language processing tasks, including answering questions (Weston et al., 2015b), language modeling (Sukhbaatar et al., 2015), and non-target dialogs (Dodge et al., 2016), to work well on these tasks and outperform other end-to-end architectures based on Recurrent Neural Networks. Hence, we chose them as end-to-end model candidates for our tasks of goal-oriented dialogs.We are using the MemN2N architecture of Sukhbaatar et al. (2015), with additional modifications to deal briefly with and accurately."}, {"heading": "4.2 Supervised Embedding Models", "text": "The embedding vectors are trained directly for this purpose. In contrast, word embedding is best known in the context of unsupervised training of raw text as in (Mikolov et al., 2013). Such models are trained by learning to predict the middle word based on the surrounding word window, or vice versa. However, given the training data consisting of dialogues, a much more direct and powerful training sequence can be used: predicting the next answer based on the previous conversation. In this setting, a candidate is judged against the input x: f (x, y) = (Ax) >, where A and B consist of word embedding, i.e. input and reaction are treated as summed bag embedding. We also consider the case of enforcing A = B, which sometimes works better, and optimize the choice for matrix validation, i.e. input and response are treated as combined bag embedding."}, {"heading": "4.3 Classical Information Retrieval Models", "text": "Classical information retrieval (IR) models without machine learning are standard basics that often perform surprisingly well in dialog tasks (Isbell et al., 2000; Jafarpour et al., 2010; Ritter et al., 2011; Sordoni et al., 2015). We have tried two standard variants: TF-IDF Match For each possible candidate response, we calculate a matching score between the input and the response, and rank the responses by score. The score is the weighted cosine similarity between the bag-of-words of the input and the bag-of-words of the candidate response. We consider the case of input either as the last utterance or as the entire conversation history, and select the variant that works best on the validation set (typically the latter). Next neighbor Based on the input, we find the most similar conversation in the training set and type the answer from this example. In this case, we consider the input to be the last word and the last word we consider the overlap."}, {"heading": "4.4 Rule-based Systems", "text": "Since our tasks T1-T5 are structured with a simulator in such a way that they are completely predictable, it follows that it is also possible to manually code a rules-based system that achieves 100% on them, similar to the bAbI tasks of Weston et al. (2015b). However, the point of these tasks is not whether a person is intelligent enough to be able to build a rules-based system to solve them, but rather to analyze the circumstances under which our machine learning algorithms are intelligent enough to function. However, in the task Dialog State Tracking Challenge (T6), which consists of real dialogues, the construction of a rules-based system is not as simple and does not end as accurately (where we expect machine learning to be useful). We implemented a rules-based system for this task in the following way. We initialized a dialogue status using the three relevant slots for this task: kitchen type, location and price range. Subsequently, we analyzed the word data and wrote the rules for selecting the trigger, which are a set of training answers."}, {"heading": "5 Experiments", "text": "This year is the highest in the history of the country."}, {"heading": "6 Conclusion", "text": "We have introduced a methodology for learning and evaluation of an end-to-end goal-oriented dialogue, which is an important area for the progress of end-to-end interlocutors because (i) the existing work does not have clearly defined performance metrics (Liu et al., 2016); (ii) the division of tasks will help to focus research and development to improve learning methods; and (iii) a goal-oriented dialogue in real-world applications has a clear benefit. We have shown that memory networks are an effective model for these tasks compared to other baselines, but are still lacking in some key areas identified by our tasks."}, {"heading": "A Examples of Predictions of a Memory Network", "text": "The following tables 3, 4, 5, and 6 show examples of predictions of the most powerful memory network (with 3 memory hops) using test examples from chapters 1-4 together with the values of attention to each memory for each memory (pi as defined in paragraph 4.1)."}], "references": [{"title": "Supervised semantic indexing", "author": ["B. Bai", "J. Weston", "D. Grangier", "R. Collobert", "K. Sadamasa", "Y. Qi", "O. Chapelle", "K. Weinberger"], "venue": "Proceedings of ACM CIKM, pages 187\u2013196. ACM.", "citeRegEx": "Bai et al\\.,? 2009", "shortCiteRegEx": "Bai et al\\.", "year": 2009}, {"title": "Movie-dic: a movie dialogue corpus for research and development", "author": ["R.E. Banchs"], "venue": "Proceedings of the 50th Annual Meeting of the ACL.", "citeRegEx": "Banchs,? 2012", "shortCiteRegEx": "Banchs", "year": 2012}, {"title": "Evaluating prerequisite qualities for learning end-to-end dialog systems", "author": ["J. Dodge", "A. Gane", "X. Zhang", "A. Bordes", "S. Chopra", "A. Miller", "A. Szlam", "J. Weston"], "venue": "Proc. of ICLR.", "citeRegEx": "Dodge et al\\.,? 2016", "shortCiteRegEx": "Dodge et al\\.", "year": 2016}, {"title": "The second dialog state tracking challenge", "author": ["M. Henderson", "B. Thomson", "J. Williams"], "venue": "15th Annual Meeting of the Special Interest Group on Discourse and Dialogue, page 263.", "citeRegEx": "Henderson et al\\.,? 2014a", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Word-based dialog state tracking with recurrent neural networks", "author": ["M. Henderson", "B. Thomson", "S. Young"], "venue": "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 292\u2013299.", "citeRegEx": "Henderson et al\\.,? 2014b", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Cobot in lambdamoo: A social statistics agent", "author": ["C.L. Isbell", "M. Kearns", "D. Kormann", "S. Singh", "P. Stone"], "venue": "AAAI/IAAI, pages 36\u201341.", "citeRegEx": "Isbell et al\\.,? 2000", "shortCiteRegEx": "Isbell et al\\.", "year": 2000}, {"title": "Filter, rank, and transfer the knowledge: Learning to chat", "author": ["S. Jafarpour", "C.J. Burges", "A. Ritter"], "venue": "Advances in Ranking, 10.", "citeRegEx": "Jafarpour et al\\.,? 2010", "shortCiteRegEx": "Jafarpour et al\\.", "year": 2010}, {"title": "An isu dialogue system exhibiting reinforcement learning of dialogue policies: generic slot-filling in the talk in-car system", "author": ["O. Lemon", "K. Georgila", "J. Henderson", "M. Stuttle"], "venue": "Proceedings of the 11th Conference of the European Chapter of the ACL: Posters & Demonstrations, pages 119\u2013122.", "citeRegEx": "Lemon et al\\.,? 2006", "shortCiteRegEx": "Lemon et al\\.", "year": 2006}, {"title": "How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation", "author": ["Liu", "C.-W.", "R. Lowe", "I.V. Serban", "M. Noseworthy", "L. Charlin", "J. Pineau"], "venue": "arXiv preprint arXiv:1603.08023.", "citeRegEx": "Liu et al\\.,? 2016", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems", "author": ["R. Lowe", "N. Pow", "I. Serban", "J. Pineau"], "venue": "arXiv preprint arXiv:1506.08909.", "citeRegEx": "Lowe et al\\.,? 2015", "shortCiteRegEx": "Lowe et al\\.", "year": 2015}, {"title": "Efficient estimation of word representations in vector space", "author": ["T. Mikolov", "K. Chen", "G. Corrado", "J. Dean"], "venue": "arXiv:1301.3781.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "A survey on metrics for the evaluation of user simulations", "author": ["O. Pietquin", "H. Hastie"], "venue": "The knowledge engineering review, 28(01), 59\u201373.", "citeRegEx": "Pietquin and Hastie,? 2013", "shortCiteRegEx": "Pietquin and Hastie", "year": 2013}, {"title": "Data-driven response generation in social media", "author": ["A. Ritter", "C. Cherry", "W.B. Dolan"], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Ritter et al\\.,? 2011", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["I.V. Serban", "A. Sordoni", "Y. Bengio", "A. Courville", "J. Pineau"], "venue": "Proc. of the AAAI Conference on Artificial Intelligence.", "citeRegEx": "Serban et al\\.,? 2015a", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "A survey of available corpora for building data-driven dialogue systems", "author": ["I.V. Serban", "R. Lowe", "L. Charlin", "J. Pineau"], "venue": "arXiv preprint arXiv:1512.05742.", "citeRegEx": "Serban et al\\.,? 2015b", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Neural responding machine for short-text conversation", "author": ["L. Shang", "Z. Lu", "H. Li"], "venue": "arXiv preprint arXiv:1503.02364.", "citeRegEx": "Shang et al\\.,? 2015", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["A. Sordoni", "M. Galley", "M. Auli", "C. Brockett", "Y. Ji", "M. Mitchell", "Nie", "J.-Y.", "J. Gao", "B. Dolan"], "venue": "Proceedings of NAACL.", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "End-to-end memory networks", "author": ["S. Sukhbaatar", "A. Szlam", "J. Weston", "R. Fergus"], "venue": "Proceedings of NIPS.", "citeRegEx": "Sukhbaatar et al\\.,? 2015", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "A neural conversational model", "author": ["O. Vinyals", "Q. Le"], "venue": "arXiv preprint arXiv:1506.05869.", "citeRegEx": "Vinyals and Le,? 2015", "shortCiteRegEx": "Vinyals and Le", "year": 2015}, {"title": "A dataset for research on short-text conversations", "author": ["H. Wang", "Z. Lu", "H. Li", "E. Chen"], "venue": "EMNLP.", "citeRegEx": "Wang et al\\.,? 2013", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "A simple and generic belief tracking mechanism for the dialog state tracking challenge: On the believability of observed information", "author": ["Z. Wang", "O. Lemon"], "venue": "Proceedings of the SIGDIAL 2013 Conference.", "citeRegEx": "Wang and Lemon,? 2013", "shortCiteRegEx": "Wang and Lemon", "year": 2013}, {"title": "Memory networks", "author": ["J. Weston", "S. Chopra", "A. Bordes"], "venue": "Proceedings of ICLR.", "citeRegEx": "Weston et al\\.,? 2015a", "shortCiteRegEx": "Weston et al\\.", "year": 2015}, {"title": "Towards ai-complete question answering: a set of prerequisite toy tasks", "author": ["J. Weston", "A. Bordes", "S. Chopra", "T. Mikolov"], "venue": "arXiv preprint arXiv:1502.05698.", "citeRegEx": "Weston et al\\.,? 2015b", "shortCiteRegEx": "Weston et al\\.", "year": 2015}, {"title": "Pomdp-based statistical spoken dialog systems: A review", "author": ["S. Young", "M. Gasic", "B. Thomson", "J.D. Williams"], "venue": "Proceedings of the IEEE, 101(5), 1160\u20131179.", "citeRegEx": "Young et al\\.,? 2013", "shortCiteRegEx": "Young et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 3, "context": "We confirm those results by comparing our system to a hand-crafted slot-filling baseline on data from the second Dialog State Tracking Challenge (Henderson et al., 2014a).", "startOffset": 145, "endOffset": 170}, {"referenceID": 23, "context": "Traditional dialog systems (Young et al., 2013) are composed of several modules including a language interpreter, a dialog state tracker and a response generator, usually each is separately hand-crafted or trained.", "startOffset": 27, "endOffset": 47}, {"referenceID": 7, "context": "Such systems are specialized for a single domain and rely heavily on expert knowledge; for instance, most of these systems, called slot-filling methods (Lemon et al., 2006; Wang and Lemon, 2013), require to predefine the structure of the dialog state as a form composed of a set of slots to be filled during the dialog.", "startOffset": 152, "endOffset": 194}, {"referenceID": 20, "context": "Such systems are specialized for a single domain and rely heavily on expert knowledge; for instance, most of these systems, called slot-filling methods (Lemon et al., 2006; Wang and Lemon, 2013), require to predefine the structure of the dialog state as a form composed of a set of slots to be filled during the dialog.", "startOffset": 152, "endOffset": 194}, {"referenceID": 15, "context": "End-to-end dialog systems, usually based on neural networks (Shang et al., 2015; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2015a; Dodge et al., 2016), currently generate a lot of interest because they do not have such limitations: all their components are directly trained on past dialogs and they make no asumption on the domain or on the structure of the dialog state.", "startOffset": 60, "endOffset": 166}, {"referenceID": 18, "context": "End-to-end dialog systems, usually based on neural networks (Shang et al., 2015; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2015a; Dodge et al., 2016), currently generate a lot of interest because they do not have such limitations: all their components are directly trained on past dialogs and they make no asumption on the domain or on the structure of the dialog state.", "startOffset": 60, "endOffset": 166}, {"referenceID": 16, "context": "End-to-end dialog systems, usually based on neural networks (Shang et al., 2015; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2015a; Dodge et al., 2016), currently generate a lot of interest because they do not have such limitations: all their components are directly trained on past dialogs and they make no asumption on the domain or on the structure of the dialog state.", "startOffset": 60, "endOffset": 166}, {"referenceID": 13, "context": "End-to-end dialog systems, usually based on neural networks (Shang et al., 2015; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2015a; Dodge et al., 2016), currently generate a lot of interest because they do not have such limitations: all their components are directly trained on past dialogs and they make no asumption on the domain or on the structure of the dialog state.", "startOffset": 60, "endOffset": 166}, {"referenceID": 2, "context": "End-to-end dialog systems, usually based on neural networks (Shang et al., 2015; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2015a; Dodge et al., 2016), currently generate a lot of interest because they do not have such limitations: all their components are directly trained on past dialogs and they make no asumption on the domain or on the structure of the dialog state.", "startOffset": 60, "endOffset": 166}, {"referenceID": 12, "context": "Those methods have reached promising performance in non goal-oriented chit-chat settings, where they were trained to predict the next utterrance in social media and forums threads (Ritter et al., 2011; Wang et al., 2013; Lowe et al., 2015) or movie conversations (Banchs, 2012).", "startOffset": 180, "endOffset": 239}, {"referenceID": 19, "context": "Those methods have reached promising performance in non goal-oriented chit-chat settings, where they were trained to predict the next utterrance in social media and forums threads (Ritter et al., 2011; Wang et al., 2013; Lowe et al., 2015) or movie conversations (Banchs, 2012).", "startOffset": 180, "endOffset": 239}, {"referenceID": 9, "context": "Those methods have reached promising performance in non goal-oriented chit-chat settings, where they were trained to predict the next utterrance in social media and forums threads (Ritter et al., 2011; Wang et al., 2013; Lowe et al., 2015) or movie conversations (Banchs, 2012).", "startOffset": 180, "endOffset": 239}, {"referenceID": 1, "context": ", 2015) or movie conversations (Banchs, 2012).", "startOffset": 31, "endOffset": 45}, {"referenceID": 8, "context": "However, evaluation of models is difficult (Liu et al., 2016) making their resulting utility in end applications unclear.", "startOffset": 43, "endOffset": 61}, {"referenceID": 22, "context": "To this end, in the spirit of the bAbI tasks designed as question answering test-beds (Weston et al., 2015b), we designed a set of tasks in the goal-oriented application of restaurant reservation.", "startOffset": 86, "endOffset": 108}, {"referenceID": 21, "context": "As an end-to-end neural model, we chose to apply Memory Networks (Weston et al., 2015a), an attention-based architecture, which has proved to be competitive for non goal-oriented dialog (Dodge et al.", "startOffset": 65, "endOffset": 87}, {"referenceID": 2, "context": ", 2015a), an attention-based architecture, which has proved to be competitive for non goal-oriented dialog (Dodge et al., 2016).", "startOffset": 107, "endOffset": 127}, {"referenceID": 3, "context": "Task 6 was converted from the 2 Dialog State Tracking Challenge (Henderson et al., 2014a).", "startOffset": 64, "endOffset": 89}, {"referenceID": 3, "context": "We confirm our findings on real human-machine dialogs from the restaurant reservation dataset of the 2 Dialog State Tracking Challenge (Henderson et al., 2014a), which we converted into our task format, showing that Memory Networks can outperform a dedicated slot-filling rule-based baseline.", "startOffset": 135, "endOffset": 160}, {"referenceID": 23, "context": "The most successful goal-oriented dialog systems model conversation as partially observable Markov decision processes (POMDP) (Young et al., 2013).", "startOffset": 126, "endOffset": 146}, {"referenceID": 4, "context": "However, in spite of recent efforts to learn modules (Henderson et al., 2014b), they still require many hand-crafted features for the state and action space representations, which restrict their usage to narrow domains.", "startOffset": 53, "endOffset": 78}, {"referenceID": 23, "context": "Our simulation, which we use to generate goal-oriented datasets can be seen as an equivalent of the user simulators used to train POMDP (Young et al., 2013; Pietquin and Hastie, 2013), but for training end-to-end systems.", "startOffset": 136, "endOffset": 183}, {"referenceID": 11, "context": "Our simulation, which we use to generate goal-oriented datasets can be seen as an equivalent of the user simulators used to train POMDP (Young et al., 2013; Pietquin and Hastie, 2013), but for training end-to-end systems.", "startOffset": 136, "endOffset": 183}, {"referenceID": 3, "context": "Indeed, goaloriented datasets are usually designed to train or evaluate dialog state tracker components (Henderson et al., 2014a) and are hence of limited scale and not suitable for end-to-end learning (annotated at the state level and noisy).", "startOffset": 104, "endOffset": 129}, {"referenceID": 2, "context": "The closest resource to ours might be the set of tasks described in (Dodge et al., 2016), since some of them can be seen as goal-oriented.", "startOffset": 68, "endOffset": 88}, {"referenceID": 3, "context": "We do so by using data from the 2 Dialog State Tracking Challenge (Henderson et al., 2014a), that is also in the restaurant booking domain.", "startOffset": 66, "endOffset": 91}, {"referenceID": 3, "context": "Our evaluation is different than in the challenge (we do not predict the dialog state), so we can not compare with the results from (Henderson et al., 2014a).", "startOffset": 132, "endOffset": 157}, {"referenceID": 21, "context": "Memory Networks (Weston et al., 2015a; Sukhbaatar et al., 2015) are a recent class of models that have been applied to a range of natural language processing tasks, including question answering (Weston et al.", "startOffset": 16, "endOffset": 63}, {"referenceID": 17, "context": "Memory Networks (Weston et al., 2015a; Sukhbaatar et al., 2015) are a recent class of models that have been applied to a range of natural language processing tasks, including question answering (Weston et al.", "startOffset": 16, "endOffset": 63}, {"referenceID": 22, "context": ", 2015) are a recent class of models that have been applied to a range of natural language processing tasks, including question answering (Weston et al., 2015b), language modeling (Sukhbaatar et al.", "startOffset": 138, "endOffset": 160}, {"referenceID": 17, "context": ", 2015b), language modeling (Sukhbaatar et al., 2015), and non-goal-oriented dialog (Dodge et al.", "startOffset": 28, "endOffset": 53}, {"referenceID": 2, "context": ", 2015), and non-goal-oriented dialog (Dodge et al., 2016).", "startOffset": 38, "endOffset": 58}, {"referenceID": 2, "context": "By first writing and then iteratively reading from a memory component that can store historical dialogs and short-term context to reason about the required response, they have shown in (Dodge et al., 2016) to perform well on those tasks and to outperform other end-to-end architectures based on Recurrent Neural Networks.", "startOffset": 185, "endOffset": 205}, {"referenceID": 17, "context": "We use the MemN2N architecture of Sukhbaatar et al. (2015), with an additional modification to deal with exact matches and out-of-vocabulary words, described shortly.", "startOffset": 34, "endOffset": 59}, {"referenceID": 2, "context": "Following Dodge et al. (2016), we represent each utterance as a bag-of-words and in memory it is represented as a vector using the embedding matrix A, i.", "startOffset": 10, "endOffset": 30}, {"referenceID": 0, "context": "Firstly, as words are embedded into a low dimensional space the model is often unable to differentiate between exact word matches, and matches between words with similar meaning (Bai et al., 2009).", "startOffset": 178, "endOffset": 196}, {"referenceID": 21, "context": "the name of a new restaurant), not seen before in training, no word embedding is available, resulting typically in failure (Weston et al., 2015a).", "startOffset": 123, "endOffset": 145}, {"referenceID": 10, "context": "In contrast, word embeddings are most well-known in the context of unsupervised training on raw text as in (Mikolov et al., 2013).", "startOffset": 107, "endOffset": 129}, {"referenceID": 0, "context": "This approach has been previously shown to be very effective in a range of contexts (Bai et al., 2009; Dodge et al., 2016).", "startOffset": 84, "endOffset": 122}, {"referenceID": 2, "context": "This approach has been previously shown to be very effective in a range of contexts (Bai et al., 2009; Dodge et al., 2016).", "startOffset": 84, "endOffset": 122}, {"referenceID": 5, "context": "Classical information retrieval (IR) models with no machine learning are standard baselines that often perform surprisingly well on dialog tasks (Isbell et al., 2000; Jafarpour et al., 2010; Ritter et al., 2011; Sordoni et al., 2015).", "startOffset": 145, "endOffset": 233}, {"referenceID": 6, "context": "Classical information retrieval (IR) models with no machine learning are standard baselines that often perform surprisingly well on dialog tasks (Isbell et al., 2000; Jafarpour et al., 2010; Ritter et al., 2011; Sordoni et al., 2015).", "startOffset": 145, "endOffset": 233}, {"referenceID": 12, "context": "Classical information retrieval (IR) models with no machine learning are standard baselines that often perform surprisingly well on dialog tasks (Isbell et al., 2000; Jafarpour et al., 2010; Ritter et al., 2011; Sordoni et al., 2015).", "startOffset": 145, "endOffset": 233}, {"referenceID": 16, "context": "Classical information retrieval (IR) models with no machine learning are standard baselines that often perform surprisingly well on dialog tasks (Isbell et al., 2000; Jafarpour et al., 2010; Ritter et al., 2011; Sordoni et al., 2015).", "startOffset": 145, "endOffset": 233}, {"referenceID": 21, "context": "As our tasks T1-T5 are built with a simulator in such a way as to be completely predictable, it therefore follows that it is also possible to hand-code a rule based system that achieves 100% on them, similar to the bAbI tasks of Weston et al. (2015b). However, the point of these tasks is not whether a human is smart enough to be able to build a rule-based system to solve them, but to help analyze in which circumstances our machine learning algorithms are smart enough to work.", "startOffset": 229, "endOffset": 251}, {"referenceID": 12, "context": "over dialogs on Twitter (Ritter et al., 2011) or Reddit (Dodge et al.", "startOffset": 24, "endOffset": 45}, {"referenceID": 2, "context": ", 2011) or Reddit (Dodge et al., 2016), where it was found that TF-IDF Match outperforms Nearest Neighbor, as general conversations on a given subject typically share many words.", "startOffset": 18, "endOffset": 38}, {"referenceID": 8, "context": "This is an important area for the progress of end-to-end conversational agents because (i) the existing work has no well defined measures of performance (Liu et al., 2016); (ii) the breakdown in tasks will help focus research and development to improve the learning methods; and (iii) goal-oriented dialog has clear utility in real applications.", "startOffset": 153, "endOffset": 171}], "year": 2016, "abstractText": "End-to-end dialog systems, in which all components are learnt simultaneously, have recently obtained encouraging successes. However these were mostly on conversations related to chit-chat with no clear objective and for which evaluation is difficult. This paper proposes a set of tasks to test the capabilities of such systems on goal-oriented dialogs, where goal completion ensures a well-defined measure of performance. Built in the context of restaurant reservation, our tasks require to manipulate sentences and symbols, in order to properly conduct conversations, issue API calls and use the outputs of such calls. We show that an end-to-end dialog system based on Memory Networks can reach promising, yet imperfect, performance and learn to perform non-trivial operations. We confirm those results by comparing our system to a hand-crafted slot-filling baseline on data from the second Dialog State Tracking Challenge (Henderson et al., 2014a).", "creator": "LaTeX with hyperref package"}}}