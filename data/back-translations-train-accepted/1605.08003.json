{"id": "1605.08003", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-May-2016", "title": "Tight Complexity Bounds for Optimizing Composite Objectives", "abstract": "We provide tight upper and lower bounds on the complexity of minimizing the average of m convex functions using gradient and prox oracles of the component functions. We show a significant gap between the complexity of deterministic vs randomized optimization. For smooth functions, we show that accelerated gradient descent (AGD) and Katyusha are optimal in the deterministic and randomized settings respectively, and that a gradient oracle is sufficient for the optimal rate. For non-smooth functions, having access to prox oracles reduces the complexity and we present optimal methods based on smoothing AGD that improve over methods using just gradient accesses.", "histories": [["v1", "Wed, 25 May 2016 18:44:54 GMT  (33kb)", "https://arxiv.org/abs/1605.08003v1", null], ["v2", "Thu, 27 Oct 2016 18:32:55 GMT  (35kb)", "http://arxiv.org/abs/1605.08003v2", null]], "reviews": [], "SUBJECTS": "math.OC cs.LG stat.ML", "authors": ["blake e woodworth", "nati srebro"], "accepted": true, "id": "1605.08003"}, "pdf": {"name": "1605.08003.pdf", "metadata": {"source": "CRF", "title": "Tight Complexity Bounds for Optimizing Composite Objectives", "authors": ["Blake Woodworth"], "emails": ["blake@ttic.edu", "nati@ttic.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 5.08 003v 2 [mat h.O C] 27 Oct 2"}, {"heading": "1 Introduction", "text": "We look at the mean of m-2 (m = 1), a prox oracle, and how much benefit it provides via gradient access alone is potentially much more powerful than it provides global, local information about the function."}, {"heading": "2 Optimizing Smooth Sums", "text": "We briefly review the best-known methods of optimization (1) when the components are \"smooth,\" resulting in the upper limits on the right half of Table 1. These upper limits can only be achieved by accessing component gradients without the need for the \"prox\" oracle. We can obtain exact gradients from \"F (x)\" by calculating general component gradients \"fi (x). Accelerated gradient departure (AGD) [12] to\" F (x) using these exact gradients \"reaches the upper complexity limits for deterministic algorithms and smooth problems (see Table 1). SAG [14], SVRG [8] and related methods use randomization on sample components, but also use the finite nature of the target to control the variance of the gradient estimator used. Acceleration of these methods using the\" catalyst \"framework [10] ensures that\" convex-E \"(exx) is strong."}, {"heading": "3 Leveraging Prox Oracles for Lipschitz Sums", "text": "In this section, we present algorithms for using the prox oracle to minimize (\u03b2) and limit (\u03b2) if each component is L-Lipschitz. This will be done by using the prox oracle to \"smooth\" each component, and by optimizing the new, smooth sum that approaches the original problem. This idea was used to apply Katyusha [3] and accelerated SDCA [17] to non-smooth targets. We are not aware of any previous explicit representation of the AGD-based deterministic algorithm that achieves the deterministic supercomplexity specified in the table. The key uses a prox oracle to obtain gradients of the \u03b2-Moreau envelope."}, {"heading": "4 Lower Bounds for Deterministic Algorithms", "text": "What we want to show is that for each deterministic optimization algorithm we can construct a \"hard\" function, for which the algorithm can only find a \"suboptimal\" solution if it has performed many oracles. Since the algorithm is deterministic, we can construct such a function by simulating the (deterministic) behavior of the algorithm. This can be considered a game in which an opponent controls the oracle used by the algorithm. In each iteration, the algorithm interrogates the oracle with a triplet (x, i, \u03b2) and the opponent responds with an answer. This answer must be consistent with all previous answers, but the opponent ensures that it is also consistent with a composite function (F). The \"hard\" function is then gradually defined in terms of behavior."}, {"heading": "4.1 Non-Smooth Components", "text": "We start by setting a lower limit for deterministic optimization of (1) if each component is not round. (<) < p > p > p > p > p > p > p > p > p (1) p > p > p > p > p (1) p > p > p > p (0) p \u2212 p > p > p (0) p \u2212 p > p > p (0) p \u2212 p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p.\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\". \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"."}, {"heading": "4.2 Smooth Components", "text": "If the components fi must be smooth, the construction with the lower limits is similar to (6), unless it is based on square differences instead of absolute differences. Let's consider the functions: fi (x) = 18 (\u03b4i, 1 (< x, v0 > 2 \u2212 2a < x, v0 >) + \u03b4i, k < x, vk > 2 + k \u00b2 r = 1\u03b4i, r (< x, vr \u2212 1 > \u2212 < x, vr >) 2) (8), where \u03b4i, r and vr are as before. Again, we can make requests based on Qi, r, vr for r < t. This construction yields the following lower limits (full details in Appendix B.3): Theorem 3. For every other construction, B, i > 0, each m \u00b2, and each m \u00b2, and each deterministic algorithm A with access to hF < < < there is a sufficiently large construction limited to d > (x), each m \u00b2, and m \u00b2."}, {"heading": "5 Lower Bounds for Randomized Algorithms", "text": "We now turn to randomized algorithms (1). In deterministic constructions, we rely on the ability to set vr and \u03b4i, r based on the predictable behavior of the algorithm. This is impossible for randomized algorithms, we have to choose the \"hard\" function before we know the random decisions the algorithm will make - so the function must be \"hard\" more general than before. Previously, we chose vectors vr orthogonal to all previous queries made by the algorithm. For randomized algorithms, this cannot be guaranteed. However, if we choose orthonormal vectors vr randomly in a high-dimensional space, they will be almost orthogonal to queries with high probability. Minor modification of the absolute or square difference from before makes the near orthogonality sufficient. This problem increases the required dimension, but does not otherwise affect the lower limits."}, {"heading": "5.1 Lipschitz Continuous Components", "text": "First of all we consider the not-smooth, not-strong-convex setting and assume that the simplicity m = 1 (otherwise we simply leave the last function null. < M (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S) S (n) S (n) S (n) S (n) S S (n) S S (n) S S (n) S S (n) S S S (n) S S (n) S S (n) S S (n) S (n) S S (n) S (n) S S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n) S (n S (n) S (n) S (n S (n) S (n S (n) S (n) S (n) S (n) S (n S (n) S (n) S (n) S (n S (n) S (n) S (n S (n) S (n S (n) S (n S"}, {"heading": "5.2 Smooth Components", "text": "If the functions fi are smooth and not strongly convex, we define another helper function throuc = > short-term (z) = short-term (z) = short-term (z | \u2212 c) 2 c < z \u2212 2c z2 \u2212 2c2 | z > 2c (11) and the following combinations of functions for i = 1,..., m / 2: fi, 1 (x) = 116 (< x, vi, 0 > 2 \u2212 2a < x, vi, 0 > + k \u00b2 r even\u03c6c (< x, vi, r >) (12) fi, 2 (x) = 116 (sp) (< x, vi, k >) + k \u00b2 r oddpercamp; c (< x, vi, vi \u2212 1 >), vi, r \u00b2 m \u00b2), that we (< x, x, x, x, x, x, x, x; that we (< < we < < < < < we < < < < x, x, x, x, x, x, x, x, x, x, x, x, x, x, x) that we (we)."}, {"heading": "6 Conclusion", "text": "We offer a narrow (up to a log factor) understanding of the optimization of finite sum problems of form (1) with a component prox oracle.Randomized optimization of (1) has been the subject of much research in recent years, starting with the presentation of SDCA and SAG, and continues with accelerated variants. It can be very useful to better understand the problem, because we know where it is possible or where other assumptions would be necessary to improve and establish the optimizability of optimization methods. In fact, several attempts have been made to better understand the problem. [1, 9] But as we explain in the introduction, these were unsatisfactory and covered only limited classes of methods. Here we show that in a fairly general sense accelerated SDCA, SVRG, SAG and Katyusha are optimal up to a log factor."}, {"heading": "A Upper bounds for non-smooth sums", "text": "If we look at the case in which the components are non-strong convex. As shown in lemma 1, we can use a single call to one Prox-Oracle x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "B Lower bounds for deterministic algorithms", "text": "\"It's not that we don't do it,\" he said. \"But it's not that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\" \"It's that we do it.\""}, {"heading": "C Lower bounds for randomized algorithms", "text": "In order to prove the deterministic lower limits, we will construct vectors vr that have all the following properties: We assume that they answer all the questions made by the algorithm. (...) In the randomized environment, this is impossible, since we cannot expect random query points. (...) Our solution was to draw the important statements vi, r and randomly in high dimensions instead. (...) The intuition is that a given vector, in this case the query made by the algorithm, will have a very small inner product with a high probability if the dimension is large. (...) Using this fact, we construct helper functions vi to replace the absolute and square difference used in the deterministic lower ranges. These functions are both flat on the interval [\u2212 c, c], meaning that the query of the algorithm has a significant inner product with vi r in front of the oracle to give this vector or gradient."}], "references": [{"title": "A lower bound for the optimization of finite sums", "author": ["Alekh Agarwal", "Leon Bottou"], "venue": "arXiv preprint arXiv:1410.0723,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Information-theoretic lower bounds on the oracle complexity of convex optimization", "author": ["Alekh Agarwal", "Martin J Wainwright", "Peter L Bartlett", "Pradeep K Ravikumar"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Katyusha: The first truly accelerated stochastic gradient descent", "author": ["Zeyuan Allen-Zhu"], "venue": "arXiv preprint arXiv:1603.05953,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Optimal black-box reductions between optimization objectives", "author": ["Zeyuan Allen-Zhu", "Elad Hazan"], "venue": "arXiv preprint arXiv:1603.05642,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Communication complexity of distributed convex learning and optimization", "author": ["Yossi Arjevani", "Ohad Shamir"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Convex analysis and monotone operator theory in Hilbert spaces", "author": ["Heinz H Bauschke", "Patrick L Combettes"], "venue": "Springer Science & Business Media,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2011}, {"title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "author": ["Stephen Boyd", "Neal Parikh", "Eric Chu", "Borja Peleato", "Jonathan Eckstein"], "venue": "Foundations and Trends R  \u00a9 in Machine Learning,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2011}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "An optimal randomized incremental gradient method", "author": ["Guanghui Lan"], "venue": "arXiv preprint arXiv:1507.02000,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "A universal catalyst for first-order optimization", "author": ["Hongzhou Lin", "Julien Mairal", "Zaid Harchaoui"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2015}, {"title": "Smooth minimization of non-smooth functions", "author": ["Yu Nesterov"], "venue": "Mathematical programming,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2005}, {"title": "A method of solving a convex programming problem with convergence rate o (1/k2)", "author": ["Yurii Nesterov"], "venue": "Soviet Mathematics Doklady,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 1983}, {"title": "Prisma: Proximal iterative smoothing algorithm", "author": ["Francesco Orabona", "Andreas Argyriou", "Nathan Srebro"], "venue": "arXiv preprint arXiv:1206.2372,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Minimizing finite sums with the stochastic average gradient", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "arXiv preprint arXiv:1309.2388,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Stochastic optimization for machine learning. Slides of presentation at \u201cOptimization Without Borders 2016", "author": ["Shai Shalev-Shwartz"], "venue": null, "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Stochastic dual coordinate ascent methods for regularized loss", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2013}, {"title": "Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization", "author": ["Shai Shalev-Shwartz", "Tong Zhang"], "venue": "Mathematical Programming,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Communication efficient distributed optimization using an approximate newton-type method", "author": ["Ohad Shamir", "Nathan Srebro", "Tong Zhang"], "venue": "arXiv preprint arXiv:1312.7853,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Assouad, fano, and le cam", "author": ["Bin Yu"], "venue": "In Festschrift for Lucien Le Cam,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 1997}], "referenceMentions": [{"referenceID": 6, "context": "ADMM [7], DANE [18], DISCO [20]) or for functions that can be decomposed into several \u201ceasy\u201d parts (e.", "startOffset": 5, "endOffset": 8}, {"referenceID": 17, "context": "ADMM [7], DANE [18], DISCO [20]) or for functions that can be decomposed into several \u201ceasy\u201d parts (e.", "startOffset": 15, "endOffset": 19}, {"referenceID": 12, "context": "PRISMA [13]).", "startOffset": 7, "endOffset": 11}, {"referenceID": 15, "context": "Recently, stochastic methods such as SDCA [16], SAG [14], SVRG [8], and other variants, have been presented which leverage the finite nature of the problem to reduce the variance in stochastic gradient estimates and obtain guarantees that dominate both batch and stochastic gradient descent.", "startOffset": 42, "endOffset": 46}, {"referenceID": 13, "context": "Recently, stochastic methods such as SDCA [16], SAG [14], SVRG [8], and other variants, have been presented which leverage the finite nature of the problem to reduce the variance in stochastic gradient estimates and obtain guarantees that dominate both batch and stochastic gradient descent.", "startOffset": 52, "endOffset": 56}, {"referenceID": 7, "context": "Recently, stochastic methods such as SDCA [16], SAG [14], SVRG [8], and other variants, have been presented which leverage the finite nature of the problem to reduce the variance in stochastic gradient estimates and obtain guarantees that dominate both batch and stochastic gradient descent.", "startOffset": 63, "endOffset": 66}, {"referenceID": 16, "context": "As methods with improved complexity, such as accelerated SDCA [17], accelerated SVRG, and Katyusha [3], have been presented, researchers have also tried to obtain lower bounds on the best possible complexity in this settings\u2014but as we survey below, these have not been satisfactory so far.", "startOffset": 62, "endOffset": 66}, {"referenceID": 2, "context": "As methods with improved complexity, such as accelerated SDCA [17], accelerated SVRG, and Katyusha [3], have been presented, researchers have also tried to obtain lower bounds on the best possible complexity in this settings\u2014but as we survey below, these have not been satisfactory so far.", "startOffset": 99, "endOffset": 102}, {"referenceID": 0, "context": "Agarwal and Bottou [1] presented a lower bound of \u03a9 ( m+ \u221a m\u03b3 \u03bb log 1 \u01eb ) .", "startOffset": 19, "endOffset": 22}, {"referenceID": 8, "context": "Improving upon this, Lan [9] shows a similar lower bound for a restricted class of randomized algorithms: the algorithm must select which component to query for a gradient by drawing an index from a fixed distribution, but the algorithm must otherwise be deterministic in how it uses the gradients, and its iterates must lie in the span of the gradients it has received.", "startOffset": 25, "endOffset": 28}, {"referenceID": 14, "context": "Another recent observation [15] was that with access only to random component subgradients without knowing the component\u2019s identity, an algorithm must make \u03a9(m) queries to optimize well.", "startOffset": 27, "endOffset": 31}, {"referenceID": 4, "context": "Our deterministic lower bounds are inspired by a lower bound on the number of rounds of communication required for optimization when each fi is held by a different machine and when iterates lie in the span of certain permitted calculations [5].", "startOffset": 240, "endOffset": 243}, {"referenceID": 11, "context": "Running accelerated gradient descent (AGD) [12] on F (x) using these exact gradients achieves the upper complexity bounds for deterministic algorithms and smooth problems (see Table 1).", "startOffset": 43, "endOffset": 47}, {"referenceID": 13, "context": "SAG [14], SVRG [8] and related methods use randomization to sample components, but also leverage the finite nature of the objective to control the variance of the gradient estimator used.", "startOffset": 4, "endOffset": 8}, {"referenceID": 7, "context": "SAG [14], SVRG [8] and related methods use randomization to sample components, but also leverage the finite nature of the objective to control the variance of the gradient estimator used.", "startOffset": 15, "endOffset": 18}, {"referenceID": 9, "context": "Accelerating these methods using the Catalyst framework [10] ensures that for \u03bb-strongly convex objectives we have E [ F (x(k))\u2212 F (x\u2217) ] < \u01eb after k = O (( m+ \u221a m\u03b3 \u03bb ) log \u01eb0 \u01eb ) iterations, where F (0)\u2212 F (x\u2217) = \u01eb0.", "startOffset": 56, "endOffset": 60}, {"referenceID": 2, "context": "Katyusha [3] is a more direct approach to accelerating SVRG which avoids extraneous log-factors, yielding the complexity k = O (( m+ \u221a m\u03b3 \u03bb ) log \u01eb0 \u01eb ) indicated in Table 1.", "startOffset": 9, "endOffset": 12}, {"referenceID": 3, "context": "The log-factor in the second term can be removed using the more delicate reduction of Allen-Zhu and Hazan [4], which involves optimizing F\u03bb(x) for progressively smaller values of \u03bb, yielding the upper bound in the table.", "startOffset": 106, "endOffset": 109}, {"referenceID": 16, "context": "Accelerated SDCA [17] achieves a similar complexity using gradient and prox oracle access.", "startOffset": 17, "endOffset": 21}, {"referenceID": 2, "context": "This idea was used in order to apply Katyusha [3] and accelerated SDCA [17] to non-smooth objectives.", "startOffset": 46, "endOffset": 49}, {"referenceID": 16, "context": "This idea was used in order to apply Katyusha [3] and accelerated SDCA [17] to non-smooth objectives.", "startOffset": 71, "endOffset": 75}, {"referenceID": 10, "context": "29], following [11]).", "startOffset": 15, "endOffset": 19}, {"referenceID": 3, "context": "To avoid this, we again apply the reduction of Allen-Zhu and Hazan [4], this time optimizing F\u0303 (\u03b2) for increasingly large values of \u03b2.", "startOffset": 67, "endOffset": 70}, {"referenceID": 2, "context": "\u2014this matches the presentation of Allen-Zhu [3] and is similar to that of Shalev-Shwartz and Zhang [17].", "startOffset": 44, "endOffset": 47}, {"referenceID": 16, "context": "\u2014this matches the presentation of Allen-Zhu [3] and is similar to that of Shalev-Shwartz and Zhang [17].", "startOffset": 99, "endOffset": 103}, {"referenceID": 1, "context": "Optimizing F (x) to within \u01eb accuracy then implies recovering the bias of the Bernoulli random variable, which requires \u03a9(1/\u01eb) queries based on a standard information theoretic result [2, 19].", "startOffset": 184, "endOffset": 191}, {"referenceID": 18, "context": "Optimizing F (x) to within \u01eb accuracy then implies recovering the bias of the Bernoulli random variable, which requires \u03a9(1/\u01eb) queries based on a standard information theoretic result [2, 19].", "startOffset": 184, "endOffset": 191}, {"referenceID": 0, "context": "Indeed, several attempts have been made at lower bounds for the finite sum setting [1, 9].", "startOffset": 83, "endOffset": 89}, {"referenceID": 8, "context": "Indeed, several attempts have been made at lower bounds for the finite sum setting [1, 9].", "startOffset": 83, "endOffset": 89}, {"referenceID": 4, "context": "This method attains a recent lower bound for distributed optimization, resolving a question raised by Arjevani and Shamir [5], and when the number of machines is very large improves over all other known distributed optimization methods for the problem.", "startOffset": 122, "endOffset": 125}, {"referenceID": 8, "context": ", in [9]), and could potentially be useful for establishing randomized lower bounds also in other settings.", "startOffset": 5, "endOffset": 8}, {"referenceID": 3, "context": "Acknowledgements: We thank Ohad Shamir for his helpful discussions and for pointing out [4].", "startOffset": 88, "endOffset": 91}, {"referenceID": 0, "context": "References [1] Alekh Agarwal and Leon Bottou.", "startOffset": 11, "endOffset": 14}, {"referenceID": 1, "context": "[2] Alekh Agarwal, Martin J Wainwright, Peter L Bartlett, and Pradeep K Ravikumar.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Zeyuan Allen-Zhu.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Zeyuan Allen-Zhu and Elad Hazan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Yossi Arjevani and Ohad Shamir.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Heinz H Bauschke and Patrick L Combettes.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Stephen Boyd, Neal Parikh, Eric Chu, Borja Peleato, and Jonathan Eckstein.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Rie Johnson and Tong Zhang.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Guanghui Lan.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Hongzhou Lin, Julien Mairal, and Zaid Harchaoui.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Yu Nesterov.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Yurii Nesterov.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Francesco Orabona, Andreas Argyriou, and Nathan Srebro.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Mark Schmidt, Nicolas Le Roux, and Francis Bach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] Shai Shalev-Shwartz.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] Shai Shalev-Shwartz and Tong Zhang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] Shai Shalev-Shwartz and Tong Zhang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] Ohad Shamir, Nathan Srebro, and Tong Zhang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] Bin Yu.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "The solution is the AdaptSmooth algorithm [4].", "startOffset": 42, "endOffset": 45}, {"referenceID": 0, "context": "+ \u03bb\u0303 2m \u2016x\u2016 When \u03bb\u0303 \u2208 [0, 1] these function are 1-smooth and \u03bb-strongly convex.", "startOffset": 22, "endOffset": 28}, {"referenceID": 1, "context": "By a standard information theoretic result [2, 19], achieving that probability of success at predicting the sign of Y implies a comparable level of accuracy at distinguishing between p = 0.", "startOffset": 43, "endOffset": 50}, {"referenceID": 18, "context": "By a standard information theoretic result [2, 19], achieving that probability of success at predicting the sign of Y implies a comparable level of accuracy at distinguishing between p = 0.", "startOffset": 43, "endOffset": 50}], "year": 2016, "abstractText": "We provide tight upper and lower bounds on the complexity of minimizing the average of m convex functions using gradient and prox oracles of the component functions. We show a significant gap between the complexity of deterministic vs randomized optimization. For smooth functions, we show that accelerated gradient descent (AGD) and an accelerated variant of SVRG are optimal in the deterministic and randomized settings respectively, and that a gradient oracle is sufficient for the optimal rate. For non-smooth functions, having access to prox oracles reduces the complexity and we present optimal methods based on smoothing that improve over methods using just gradient accesses.", "creator": "LaTeX with hyperref package"}}}