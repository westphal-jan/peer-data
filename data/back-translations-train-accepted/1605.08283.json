{"id": "1605.08283", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2016", "title": "Discrete Deep Feature Extraction: A Theory and New Architectures", "abstract": "First steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made---for the continuous-time case---in Mallat, 2012, and Wiatowski and B\\\"olcskei, 2015. This paper considers the discrete case, introduces new convolutional neural network architectures, and proposes a mathematical framework for their analysis. Specifically, we establish deformation and translation sensitivity results of local and global nature, and we investigate how certain structural properties of the input signal are reflected in the corresponding feature vectors. Our theory applies to general filters and general Lipschitz-continuous non-linearities and pooling operators. Experiments on handwritten digit classification and facial landmark detection---including feature importance evaluation---complement the theoretical findings.", "histories": [["v1", "Thu, 26 May 2016 13:55:07 GMT  (153kb,D)", "http://arxiv.org/abs/1605.08283v1", "Proc. of International Conference on Machine Learning (ICML), New York, USA, June 2016, to appear"]], "COMMENTS": "Proc. of International Conference on Machine Learning (ICML), New York, USA, June 2016, to appear", "reviews": [], "SUBJECTS": "cs.LG cs.CV cs.IT cs.NE math.IT stat.ML", "authors": ["thomas wiatowski", "michael tschannen", "aleksandar stanic", "philipp grohs", "helmut b\u00f6lcskei"], "accepted": true, "id": "1605.08283"}, "pdf": {"name": "1605.08283.pdf", "metadata": {"source": "META", "title": "Discrete Deep Feature Extraction: A Theory and New Architectures", "authors": ["Thomas Wiatowski", "Michael Tschannen", "Aleksandar Stani\u0107", "Philipp Grohs", "Helmut B\u00f6lcskei"], "emails": ["WITHOMAS@NARI.EE.ETHZ.CH", "MICHAELT@NARI.EE.ETHZ.CH", "ASTANIC@STUDENT.ETHZ.CH", "PHILIPP.GROHS@UNIVIE.AC.AT", "BOELCSKEI@NARI.EE.ETHZ.CH"], "sections": [{"heading": "1. Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2. The basic building block", "text": "The basic building block of a DCNN described in this section consists of a wave transformation followed by a nonlinearity and a pooling operation."}, {"heading": "2.1. Convolutional transform", "text": "A Convolutionary Transformation consists of a set of filters, but the filters - referred to as atoms - can be learned (in a supervised or unsupervised manner), pre-specified and unstructured such as random filters, or pre-specified and structured such as wavelengths, curvelets, shearlets, or Weyl-Heisenberg functions. Definition 1. Let's be a finite index set. Capture is a collection of random filters or pre-specified and structured such as wavelengths, curvelets, shearlets, or Weyl-Heisenberg functions. Definition 1. Let it be a finite index set."}, {"heading": "2.2. Non-linearities", "text": "Nonlinearity \u03c1: C \u2192 C we all consider meaningless and satisfy the Lipschitz property | \u03c1 (x) \u2212 \u03c1 (y) | \u2264 L | x \u2212 y |, \u0435x, y-C, for some L > 0."}, {"heading": "2.2.1. EXAMPLE NON-LINEARITIES", "text": "\u2022 The hyperbolic tangent nonlinearity, defined as \u03c1 (x) = tanh (Re (x)) + i tanh (Im (x)), where tanh (x) = ex \u2212 e \u2212 x ex + e \u2212 x, the Lipschitz constant L = 2. \u2022 The gerified linear unit nonlinearity is given by \u03c1 (x) = max {0, Re (x)} + imax {0, Im (x)} and has the Lipschitz constant L = 2. \u2022 The module nonlinearity is \u03c1 (x) = | x | and has the Lipschitz constant L = 1. \u2022 The logistic sigmoid nonlinearity is defined as \u03c1 (x) = sig (Re (x)) + i sig (Im (x)), where sig (x) = 1 + e \u2212 x, and has the Lipschitz constant L = 1 / 2. We refer the reader to (Wiatowski & B\u00c3 \u00bc lskei, the non-linearity examples)."}, {"heading": "2.3. Pooling operators", "text": "The essence of pooling is to reduce the signal dimensionality in the individual network layers and to ensure the robustness of the feature vector with deformations and translations. The theory developed in this paper applies to general pooling operators P: HN \u2192 HN / S, where N, S, N with N / S satisfying the Lipschitz property apply to some R > 0. The integer S is called the pooling factor and determines the \"size\" of the neighborhood values."}, {"heading": "2.3.1. EXAMPLE POOLING OPERATORS", "text": "\u2022 Sub-sample, defined as P: HN \u2192 HN / S, (Pf) [n] = f [Sn], n \u00b2 IN / S, has Lipschitz constant R = 1. For S = 1, P is the identity operator, which amounts to \"no merge.\" \u2022 Averaging, defined as P: HN \u2192 HN / S, (Pf) [n] = \u2211 Sn + S \u2212 1 k = Sn \u03b1k \u2212 Snf [k], n \u00b2 IN / S, has Lipschitz constant R = S1 / 2 maxk [0,..., S \u2212 1} | \u03b1k |. Weights can be learned (LeCun et al., 1998) or specified (Pinto et al., 2008) (e.g. uniform merging corresponds to the Lipitz constants."}, {"heading": "3. The network architecture", "text": "The architecture we are looking at is flexible in the following sense. In each layer we can feed into the function vector, either the signals that are passed up to this layer (i.e., the feature cards), filtered versions of it, or we can decide that this layer is not to function vector.The basic building blocks of our network are the triplets (i.e., the feature sketches) of the filters, non-linearities and pooling operators associated with the D-th network layer: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D: D."}, {"heading": "4. Sampled cartoon functions", "text": "While our main results for general signals f, we can provide a sophisticated analysis for the class of Sampled Cartoon Functions. (This allows us to understand how certain structural properties of the input signal, such as the presence of sharp edges, are reflected in the feature vector.) Cartoon Functions - as introduced in Continuous Time in (Donoho, 2001) - are piecewise \"smooth\" apart from curved discontinuities along KIFAR-100 (Krizhevsky, 2009) datasets, for images of handwritten digits (LeCun & Cortes, 1998) (see Fig. 2, middle), and for images of geometric objects of different shapes, sizes and colors as in Baby AI School dataset2.Boun."}, {"heading": "5. Analytical results", "text": "We analyze global and local trait vector properties with globality in terms of traits produced by merging traits at all network levels, and localizing attributes made explicit in individual layers."}, {"heading": "5.1. Global properties", "text": "We assume that the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1) and the Lipschitz constants (1)."}, {"heading": "5.2. Local properties", "text": "\"We cannot say that we will be able to solve the problem if we cannot solve it,\" he said. \"But we will not do it.\" (\"We will do it.\") \"We will do it.\" (\"We will do it.\") \"We will do it.\" (\"We will do it.\") \"We will do it.\" (\"We will do it.\") \"(\" We will do it. \")\" (\"We will do it.\" (\"We will do it.\") \"(\" We will do it. \")\" (\"We will do it.\" (\"We will do it.\") \"We will do it.\" (\"We will do it.\") \"(\" We will do it. \"(\" We will do it. \")\" (\"We will do it.\" (\"We will do it.\") \"(\" We will do it. \"(\" We will do it. \")\" (\"We will do it.\" (\"We will do it.\") \"(\" We will do it. \"(\" We will do it. \")\" (\"We will do it.\" (\"We will do it.\") \"(\" We will do it. \"(\" We will do it. \").\" (\"We will do it.\" (\"We will do it.\"). \"(\" We will do. \"(\" We will do. \").\" (\"We will do. (\" We will do. \").\" (\"We will do.\"). \"(\" We will do. (\"We will do.\"). \"(\" We will do. (\"We will do.\"). (\"We will do.\"). \"(\" We will do. (\"). (\" We will do. (\"We will do.\"). (\"We will do. (.\"). (\"We will do. (\"). (\"We will do. (\" We will do. (\"). (.\"). (\"We will do. (.\" We will do. (. \"). (\" We will do. \"). (. (\" We will do. (\"). (\" We will do. (. (\")."}, {"heading": "6.1. Handwritten digit classification", "text": "We use the MNIST dataset of handwritten digits (LeCun & Cortes, 1998), which includes 60,000 training sessions and 10,000 test images 28 x 28 in size. We set D = 3 and compare different network configurations, each defined by a single module (i.e. we use the same filters, nonlinearity and pooling operators in all layers), in particular we look at hair waves and reverse biorthogonal waves (Mallat, 2009), both with J = 3 scales, the nonlinearity described in Section 2.2.1, and the pooling operators described in Section 2.3.1 (with S1 = and S2 = 2), and we use a radial base SVM (RBF) for classification."}, {"heading": "6.2. Feature importance evaluation", "text": "The primary goal of this experiment is to demonstrate the practical relevance of the concept of local facial expression characteristics as defined in Section 5.2. In both cases, we fix the number of trees at 30 and select the tree depth using error estimates (noting that increasing the number of trees does not significantly increase accuracy); in both cases, we fix the number of trees at 30 and select the tree depth using out-of-pocket error estimates (noting that increasing the number of trees does not significantly increase accuracy); and the inaccuracy used for learning is the mean square error for face recognition and the Gini blur for handwritten digit classification; in both cases, the meaning of the features is evaluated using the Gini importance (Breiet al, 1984), averaged over all trees."}, {"heading": "Acknowledgments", "text": "The authors thank C. Geiger for the preparatory work for the experiments in section 6.2 and M. Lerjen for the help with arithmetic questions."}, {"heading": "A. Appendix: Additional numerical results", "text": "A.1. Handwritten Number Classification For the experiment of handwritten number classification described in Section 6.1, Table 3 shows the classification error for Daubechies wavelengths with 2 vanishing moments (DB2).A.2. Evaluation of the meaning of characteristicsFor the experiment of meaning of characteristics described in Section 6.2, Figure 4 shows the cumulative meaning of characteristics (per triplet of layer index, wavelength scale and direction averaged over all trees in the respective RF) in the recognition of facial marks (right eye and mouth)."}, {"heading": "B. Appendix: Lipschitz continuity of pooling operators", "text": "We verify the Lipschitz property: P (f) \u2212 k k (f) k (f) k (f) k) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k) k (f) k (f) k) k (f) k (f) k) k (f) k (f) k) k (f) k) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k (f) k) k (f) k (f) k) k (f) k (f) k (f) k (f) k) k (f) k (f) k (f) k (f) k) k (f) k (f) k (f) k) k (f) k (f) k) k (f) k (f) k) k (f) k) k (f) k (f) k) k (f) k) k (f) k) k (f) k (f) k) k (f) k) k (f) k) k (f) k) k (f) k (f) k (f) k) k (f) k (f) k) k (f) k (f) k) k (f) k (f) k) k (f) k (f) k (f) k) k (f) k (f) k (f) k) k (f) k (f) k (f) k (f) k) k (f) k (f) k (f) k (f) k (f) k) k (f) k (f) k (f) k (f) k (f) k) k (f) k (f) k (f) k (f) k) k (f) k (f) k (f) k (f) k) k) k (f) k (f) k (f) k (f) k (f) k) k (f) k ("}, {"heading": "C. Appendix: Proof of Theorem 1", "text": "The key idea of the evidence - similar to the proof of Proposition 4 in (Wiatowski & Bo \ufffd lcskei, 2015) - is that we must apply a series of arguments. \u2212 To simplify the notation, we allow: = U [q] f and hq: = U [q] h, for f, h and HN1, q and d1. \u2212 With (9) we have an answer to question (f) to question (h). \u2212 2 = D \u2212 1 = 0, q and hq: = 0, q and hq: 1, (fq \u2212 hq) to question (22). \u2212 The key step is then to show that ad can be limited upwards. \u2212 bd \u2212 bd \u2212 bd + 1, d = 0,."}, {"heading": "D. Appendix: Proposition D.1", "text": "Proposition D.1. For every N-N, every K > 0, and every A-Z-Z: R (1, 1). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F-Z). (F (F-Z). (F-Z). (F-Z). (F-Z). (F-Z)."}, {"heading": "E. Appendix: Theorem 2", "text": "We start by saying that if we are able to put ourselves in a position, if we are able to put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position, if we put ourselves in a position."}], "references": [{"title": "Deep scattering spectrum", "author": ["J. And\u00e9n", "S. Mallat"], "venue": "IEEE Trans. Sig. Process.,", "citeRegEx": "And\u00e9n and Mallat,? \\Q2014\\E", "shortCiteRegEx": "And\u00e9n and Mallat", "year": 2014}, {"title": "Pruning training sets for learning of object categories", "author": ["A. Angelova", "Y. Abu-Mostafa", "P. Perona"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Angelova et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Angelova et al\\.", "year": 2005}, {"title": "Representation learning: A review and new perspectives", "author": ["Y. Bengio", "A. Courville", "P. Vincent"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Bengio et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Discrete Zak transforms, polyphase transforms, and applications", "author": ["H. B\u00f6lcskei", "F. Hlawatsch"], "venue": "IEEE Trans. Sig. Process.,", "citeRegEx": "B\u00f6lcskei and Hlawatsch,? \\Q1997\\E", "shortCiteRegEx": "B\u00f6lcskei and Hlawatsch", "year": 1997}, {"title": "Classification and regression trees", "author": ["L. Breiman", "J. Friedman", "C.J. Stone", "R.A. Olshen"], "venue": null, "citeRegEx": "Breiman et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Breiman et al\\.", "year": 1984}, {"title": "Invariant scattering convolution networks", "author": ["J. Bruna", "S. Mallat"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Bruna and Mallat,? \\Q2013\\E", "shortCiteRegEx": "Bruna and Mallat", "year": 2013}, {"title": "Fast discrete curvelet transforms", "author": ["E.J. Cand\u00e8s", "L. Demanet", "D. Donoho", "L. Ying"], "venue": "Multiscale Modeling and Simulation,", "citeRegEx": "Cand\u00e8s et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Cand\u00e8s et al\\.", "year": 2006}, {"title": "Realtime facial feature detection using conditional regression forests", "author": ["M. Dantone", "J. Gall", "G. Fanelli", "L. Van Gool"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Dantone et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dantone et al\\.", "year": 2012}, {"title": "Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences", "author": ["S. Davis", "P. Mermelstein"], "venue": "IEEE Trans. Acoust., Speech, and Signal Process.,", "citeRegEx": "Davis and Mermelstein,? \\Q1980\\E", "shortCiteRegEx": "Davis and Mermelstein", "year": 1980}, {"title": "Sparse components of images and optimal atomic decompositions", "author": ["D. Donoho"], "venue": "Constructive Approximation,", "citeRegEx": "Donoho,? \\Q2001\\E", "shortCiteRegEx": "Donoho", "year": 2001}, {"title": "A course in abstract harmonic analysis, volume 29", "author": ["G.B. Folland"], "venue": "CRC Press,", "citeRegEx": "Folland,? \\Q2015\\E", "shortCiteRegEx": "Folland", "year": 2015}, {"title": "Matrix computations", "author": ["G.H. Golub", "C.F. Van Loan"], "venue": null, "citeRegEx": "Golub and Loan,? \\Q2013\\E", "shortCiteRegEx": "Golub and Loan", "year": 2013}, {"title": "Deep convolutional neural networks on cartoon functions", "author": ["P. Grohs", "T. Wiatowski", "H. B\u00f6lcskei"], "venue": "In Proc. of IEEE Int. Symp. on Inform. Theory (ISIT),", "citeRegEx": "Grohs et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Grohs et al\\.", "year": 2016}, {"title": "A real-time algorithm for signal analysis with the help of the wavelet transform", "author": ["M. Holschneider", "R. Kronland-Martinet", "J. Morlet", "P. Tchamitchian"], "venue": "In Wavelets,", "citeRegEx": "Holschneider et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Holschneider et al\\.", "year": 1989}, {"title": "Large-scale learning with SVM and convolutional nets for generic object categorization", "author": ["F.J. Huang", "Y. LeCun"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Huang and LeCun,? \\Q2006\\E", "shortCiteRegEx": "Huang and LeCun", "year": 2006}, {"title": "What is the best multi-stage architecture for object recognition", "author": ["K. Jarrett", "K. Kavukcuoglu", "M.A. Ranzato", "Y. LeCun"], "venue": "In Proc. of IEEE Int. Conf. on Computer Vision (ICCV),", "citeRegEx": "Jarrett et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Jarrett et al\\.", "year": 2009}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky"], "venue": "MS thesis, University of Toronto,", "citeRegEx": "Krizhevsky,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky", "year": 2009}, {"title": "Shearlets: Multiscale analysis for multivariate data", "author": ["G. Kutyniok", "Labate", "D. (eds"], "venue": null, "citeRegEx": "Kutyniok et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kutyniok et al\\.", "year": 2012}, {"title": "Introduction to shearlets. In Shearlets: Multiscale analysis for multivariate data, pp. 1\u201338", "author": ["G. Kutyniok", "D. Labate"], "venue": null, "citeRegEx": "Kutyniok and Labate,? \\Q2012\\E", "shortCiteRegEx": "Kutyniok and Labate", "year": 2012}, {"title": "The MNIST database of handwritten digits", "author": ["Y. LeCun", "C. Cortes"], "venue": "http://yann.lecun.com/exdb/ mnist/,", "citeRegEx": "LeCun and Cortes,? \\Q1998\\E", "shortCiteRegEx": "LeCun and Cortes", "year": 1998}, {"title": "Gradientbased learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "In Proc. of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Distinctive image features from scaleinvariant keypoints", "author": ["D.G. Lowe"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Lowe,? \\Q2004\\E", "shortCiteRegEx": "Lowe", "year": 2004}, {"title": "A wavelet tour of signal processing: The sparse way", "author": ["S. Mallat"], "venue": null, "citeRegEx": "Mallat,? \\Q2009\\E", "shortCiteRegEx": "Mallat", "year": 2009}, {"title": "Group invariant scattering", "author": ["S. Mallat"], "venue": "Comm. Pure Appl. Math.,", "citeRegEx": "Mallat,? \\Q2012\\E", "shortCiteRegEx": "Mallat", "year": 2012}, {"title": "Multiclass object recognition with sparse, localized features", "author": ["J. Mutch", "D.G. Lowe"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR), pp", "citeRegEx": "Mutch and Lowe,? \\Q2006\\E", "shortCiteRegEx": "Mutch and Lowe", "year": 2006}, {"title": "Deep roto-translation scattering for object classification", "author": ["E. Oyallon", "S. Mallat"], "venue": null, "citeRegEx": "Oyallon and Mallat,? \\Q2014\\E", "shortCiteRegEx": "Oyallon and Mallat", "year": 2014}, {"title": "Why is real-world visual object recognition hard", "author": ["N. Pinto", "D.D. Cox", "J.J. DiCarlo"], "venue": "PLoS Computational Biology,", "citeRegEx": "Pinto et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Pinto et al\\.", "year": 2008}, {"title": "Efficient learning of sparse representations with an energybased model", "author": ["M. Ranzato", "C. Poultney", "S. Chopra", "Y. LeCun"], "venue": "In Proc. of Int. Conf. on Neural Information Processing Systems (NIPS),", "citeRegEx": "Ranzato et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2006}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M.A. Ranzato", "F.J. Huang", "Y.L. Boureau", "Y. LeCun"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Ranzato et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2007}, {"title": "Object recognition with features inspired by visual cortex", "author": ["T. Serre", "L. Wolf", "T. Poggio"], "venue": "In Proc. of IEEE Conf. Comp. Vision Pattern Recog. (CVPR),", "citeRegEx": "Serre et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Serre et al\\.", "year": 2005}, {"title": "An efficient dense descriptor applied to wide-baseline stereo", "author": ["E. Tola", "V. Lepetit", "Fua", "P. Daisy"], "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,", "citeRegEx": "Tola et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Tola et al\\.", "year": 2010}, {"title": "Robust real-time face detection", "author": ["P. Viola", "M.J. Jones"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Viola and Jones,? \\Q2004\\E", "shortCiteRegEx": "Viola and Jones", "year": 2004}, {"title": "A mathematical theory of deep convolutional neural networks for feature extraction", "author": ["T. Wiatowski", "H. B\u00f6lcskei"], "venue": null, "citeRegEx": "Wiatowski and B\u00f6lcskei,? \\Q2015\\E", "shortCiteRegEx": "Wiatowski and B\u00f6lcskei", "year": 2015}], "referenceMentions": [{"referenceID": 2, "context": "Deep convolutional neural networks (DCNNs) have proven tremendously successful in a wide range of machine learning tasks (Bengio et al., 2013; LeCun et al., 2015).", "startOffset": 121, "endOffset": 162}, {"referenceID": 20, "context": "DCNNs are typically distinguished according to (i) whether the filters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al.", "startOffset": 109, "endOffset": 172}, {"referenceID": 15, "context": "DCNNs are typically distinguished according to (i) whether the filters employed are learned (in a supervised (LeCun et al., 1998; Huang & LeCun, 2006; Jarrett et al., 2009) or unsupervised (Ranzato et al.", "startOffset": 109, "endOffset": 172}, {"referenceID": 29, "context": ", wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al.", "startOffset": 11, "endOffset": 65}, {"referenceID": 23, "context": ", wavelets (Serre et al., 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al.", "startOffset": 11, "endOffset": 65}, {"referenceID": 28, "context": ", 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.", "startOffset": 83, "endOffset": 127}, {"referenceID": 15, "context": ", 2005; Mutch & Lowe, 2006; Mallat, 2012), or unstructured, such as random filters (Ranzato et al., 2007; Jarrett et al., 2009)), (ii) the non-linearities used (e.", "startOffset": 83, "endOffset": 127}, {"referenceID": 23, "context": "First steps towards addressing this question and developing a mathematical theory of DCNNs for feature extraction were made\u2014for the continuous-time case\u2014in (Mallat, 2012; Wiatowski & B\u00f6lcskei, 2015).", "startOffset": 156, "endOffset": 198}, {"referenceID": 23, "context": "Specifically, (Mallat, 2012) analyzed so-called scattering networks, where signals are propagated through layers that employ directional wavelet filters and modulus non-linearities but no intra-layer pooling.", "startOffset": 14, "endOffset": 28}, {"referenceID": 12, "context": "signals (Wiatowski & B\u00f6lcskei, 2015), cartoon functions (Grohs et al., 2016), and Lipschitz-continuous functions (Grohs et al.", "startOffset": 56, "endOffset": 76}, {"referenceID": 12, "context": ", 2016), and Lipschitz-continuous functions (Grohs et al., 2016), Lipschitz continuity of the feature extractor automatically leads to bounds on deformation sensitivity.", "startOffset": 44, "endOffset": 64}, {"referenceID": 12, "context": "Specifically, we follow the philosophy put forward in (Wiatowski & B\u00f6lcskei, 2015; Grohs et al., 2016).", "startOffset": 54, "endOffset": 102}, {"referenceID": 9, "context": "Specifically, we analyze the (local and global) deformation and translation sensitivity properties of feature vectors corresponding to sampled cartoon functions (Donoho, 2001).", "startOffset": 161, "endOffset": 175}, {"referenceID": 22, "context": "Examples of structured convolutional sets withA = B = 1 include, in the 1-D case, wavelets (Daubechies, 1992) and Weyl-Heisenberg functions (B\u00f6lcskei & Hlawatsch, 1997), and in the 2-D case, tensorized wavelets (Mallat, 2009), curvelets (Cand\u00e8s et al.", "startOffset": 211, "endOffset": 225}, {"referenceID": 6, "context": "Examples of structured convolutional sets withA = B = 1 include, in the 1-D case, wavelets (Daubechies, 1992) and Weyl-Heisenberg functions (B\u00f6lcskei & Hlawatsch, 1997), and in the 2-D case, tensorized wavelets (Mallat, 2009), curvelets (Cand\u00e8s et al., 2006), and shearlets (Kutyniok & Labate, 2012a).", "startOffset": 237, "endOffset": 258}, {"referenceID": 20, "context": "The weights {\u03b1k} k=0 can be learned (LeCun et al., 1998) or prespecified (Pinto et al.", "startOffset": 36, "endOffset": 56}, {"referenceID": 26, "context": ", 1998) or prespecified (Pinto et al., 2008) (e.", "startOffset": 24, "endOffset": 44}, {"referenceID": 21, "context": "It was argued in (Bruna & Mallat, 2013; And\u00e9n & Mallat, 2014; Oyallon & Mallat, 2014) that the features \u03a6\u03a9(f) when generated by wavelet filters, modulus non-linearities, without intra-layer pooling, and by employing output-generating atoms with low-pass characteristics, describe mel frequency cepstral coefficients (Davis & Mermelstein, 1980) in 1-D, and SIFT-descriptors (Lowe, 2004; Tola et al., 2010) in 2-D.", "startOffset": 373, "endOffset": 404}, {"referenceID": 30, "context": "It was argued in (Bruna & Mallat, 2013; And\u00e9n & Mallat, 2014; Oyallon & Mallat, 2014) that the features \u03a6\u03a9(f) when generated by wavelet filters, modulus non-linearities, without intra-layer pooling, and by employing output-generating atoms with low-pass characteristics, describe mel frequency cepstral coefficients (Davis & Mermelstein, 1980) in 1-D, and SIFT-descriptors (Lowe, 2004; Tola et al., 2010) in 2-D.", "startOffset": 373, "endOffset": 404}, {"referenceID": 9, "context": "Cartoon functions\u2014as introduced in continuous time in (Donoho, 2001)\u2014are piecewise \u201csmooth\u201d apart from curved discontinuities along Lipschitz-continuous hypersurfaces.", "startOffset": 54, "endOffset": 68}, {"referenceID": 16, "context": ", 2007) and the CIFAR-100 (Krizhevsky, 2009) datasets, for images of handwritten digits (LeCun & Cortes, 1998) (see Fig.", "startOffset": 26, "endOffset": 44}, {"referenceID": 12, "context": "Bounds on deformation sensitivity for cartoon functions in continuous-time DCNNs were recently reported in (Grohs et al., 2016).", "startOffset": 107, "endOffset": 127}, {"referenceID": 13, "context": "Circular convolutions with the 1-D filters underlying the tensorized wavelets are efficiently implemented using the algorithme \u00e0 trous (Holschneider et al., 1989).", "startOffset": 135, "endOffset": 162}, {"referenceID": 22, "context": "2) wavelets (Mallat, 2009), both with J = 3 scales, the non-linearities described in Section 2.", "startOffset": 12, "endOffset": 26}, {"referenceID": 4, "context": "In both cases, feature importance is assessed using the Gini importance (Breiman et al., 1984), averaged over all trees.", "startOffset": 72, "endOffset": 94}, {"referenceID": 1, "context": "We use the Caltech 10,000 Web Faces data base (Angelova et al., 2005).", "startOffset": 46, "endOffset": 69}, {"referenceID": 7, "context": "Following (Dantone et al., 2012) we report the localization error, i.", "startOffset": 10, "endOffset": 32}, {"referenceID": 7, "context": "As an aside, we note that these values are comparable with the ones reported in (Dantone et al., 2012) for a conditional RF using patch comparison features (evaluated on a different dataset and a larger set of facial landmarks).", "startOffset": 80, "endOffset": 102}, {"referenceID": 10, "context": "2) follows by Young\u2019s inequality (Folland, 2015).", "startOffset": 33, "endOffset": 48}], "year": 2016, "abstractText": "First steps towards a mathematical theory of deep convolutional neural networks for feature extraction were made\u2014for the continuous-time case\u2014 in Mallat, 2012, and Wiatowski and B\u00f6lcskei, 2015. This paper considers the discrete case, introduces new convolutional neural network architectures, and proposes a mathematical framework for their analysis. Specifically, we establish deformation and translation sensitivity results of local and global nature, and we investigate how certain structural properties of the input signal are reflected in the corresponding feature vectors. Our theory applies to general filters and general Lipschitz-continuous non-linearities and pooling operators. Experiments on handwritten digit classification and facial landmark detection\u2014including feature importance evaluation\u2014complement the theoretical findings.", "creator": "LaTeX with hyperref package"}}}