{"id": "1605.08375", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-May-2016", "title": "Generalization Properties and Implicit Regularization for Multiple Passes SGM", "abstract": "We study the generalization properties of stochastic gradient methods for learning with convex loss functions and linearly parameterized functions. We show that, in the absence of penalizations or constraints, the stability and approximation properties of the algorithm can be controlled by tuning either the step-size or the number of passes over the data. In this view, these parameters can be seen to control a form of implicit regularization. Numerical results complement the theoretical findings.", "histories": [["v1", "Thu, 26 May 2016 17:37:51 GMT  (54kb,D)", "http://arxiv.org/abs/1605.08375v1", "26 pages, 4 figures. To appear in ICML 2016"]], "COMMENTS": "26 pages, 4 figures. To appear in ICML 2016", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["junhong lin", "raffaello camoriano", "lorenzo rosasco"], "accepted": true, "id": "1605.08375"}, "pdf": {"name": "1605.08375.pdf", "metadata": {"source": "CRF", "title": "Generalization Properties and Implicit Regularization for Multiple Passes SGM", "authors": ["Junhong Lin", "Raffaello Camoriano", "Lorenzo Rosasco"], "emails": ["jhlin5@hotmail.com", "raffaello.camoriano@iit.it", "lrosasco@mit.edu"], "sections": [{"heading": "1 Introduction", "text": "This year, as never before in the history of a country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is not a country, but rather a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which"}, {"heading": "2 Learning with SGM", "text": "In this section, we present the supervised learning problem and the SGM algorithms, which generally constitute a fixed space. Let X be a probability space and Y a subset of R. Let's give a probability measurement on Z = X \u00b7 Y. Give a measurable loss function V: R \u00b7 R > R +, the associated risk E = EV is defined asE (f) = 1 of size M (y, f (x))). The distribution is assumed to be fixed, but unknown, and the goal is to find a function that minimizes the expected risk, since a sample z = {zi = (xi, yi)} mi (1 of size M).N will be independently drawn according to other examples of learning algorithms, based on empirical risk minimization that replaces the expected risk with the empirical risk that we have defined with the empirical risk Ez = EVz."}, {"heading": "3 Implicit Regularization for SGM", "text": "In this section, we present and discuss our main results. We start with a universal convergence result in Section 3.1 and then provide finite sample limits for smooth loss functions in Section 3.2 and for non-smooth functions in Section 3.3. As a logical consequence of these results, we conduct various implicit regulatory strategies for SGM.1 Specifically, j1, j2, \u00b7 \u00b7 \u00b7, jT are conditionally independent, as each z occurs."}, {"heading": "3.1 Convergence", "text": "We begin with the presentation of a convergence result that includes conditions regarding both the step variables and the number of iterations. We need some basic assumptions. Assumption 1: There is no evidence that the loss function is convex in relation to its second entry, and | V | 0: = supy - error Y (y, 0) < \u221e. Furthermore, its left-directed derivative V \u2032 \u2212 (y, \u00b7) is limited: the loss function selected is convex in relation to its second entry, and | V | 0: = supy - error Y (y, 0) < \u043c. Furthermore, its left-directed derivative V \u2032 (y, \u00b7) is limited: the deviation V \u2032 (y, a) is convex in relation to the second entry \u2264 a0, 0 \u2212 y error Y. (5) The above conditions are common in statistical learning theory [19, 9]. For example, they are satisfied with the hinge loss V \u2032 (a)."}, {"heading": "3.2 Finite Sample Bounds for Smooth Loss Functions", "text": "In this subsection, we give explicit, finite example functions that provide a suitable premise for approximating the error. (3) We assume that the adjustment errors (0, 1) and the approximation errors (2) are satisfactory. (7) We assume that the adjustment errors (0, 1) and the approximation errors (2) are satisfactory. (7) We misuse the term \"one pass\" to understand how difficult it is to achieve the expected risk."}, {"heading": "3.3 Finite Sample Bounds for Non-smooth Loss Functions", "text": "x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x x"}, {"heading": "In particular, (11) holds for t\u2217 = m.", "text": "Conclusion 8. Under assumptions 1 and 2, allow \u03b7t = t \u2212 2\u03b22\u03b2 + 1 for all t-N. Then for all t-N and gt = wt (or wt), E [E (gt) \u2212 inf w-F E (w)]. m \u2212 12 t 1 4\u03b2 + 2 log t + t \u2212 min (2\u03b2, 1) 2\u03b2 + 1 log t + t \u2212 \u03b2 2\u03b2 + 1."}, {"heading": "In particular, (11) holds for t\u2217 = m.", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.4 Discussion and Proof Sketch", "text": "The second series of work focuses on several procedures and references, the latter based on the analysis of a sequential prediction and then on taking into account the averaged iteration to reconsider the limits of the expected risk; the second series of work focuses on the quality of the corresponding comparisons, the latter based on the analysis of a sequential prediction and then on the consideration of the averaged iteration to reconsider the limits of the expected risk; and the second series of work focuses on the quality of the corresponding comparisons in relation to empirical risk. In this view, Algorithm 1 is seen as an instance of incremental methods for minimizing objective functions, which are sums of a large number of terms."}, {"heading": "4 Numerical Simulations", "text": "We run some numerical simulations to illustrate our results4. The experiments are performed ten times each, based on the benchmark data5 given in Table 1, which also shows the Gaussian kernel bandwidths \u03c3 used by SGM and SIGM6 for each learning problem. In this case, the loss function is the hinge loss7. The experimental platform is a server with 12 x Intelr Xeonr E5-2620 v2 (2.10GHz) CPUs and 132GB of RAM. Some of the experimental results, as stated below, were obtained by performing the experiments on subsets of randomly selected data samples. To apply hold-out cross-validation, the training set is divided into two parts: one for empirical risk minimization and the other for error validation (80% - 20% each)."}, {"heading": "4.1 Regularization in SGM and SIGM", "text": "In this subsection, we illustrate four concrete examples showing different control effects of the step size in SGM and the number of passes in SIGM. In all of these four examples, we look at the adult data set with sample size n = 1000. In the first experiment, the SIGM step size is calculated as \u03b7 = 1 / \u221a n. The test error calculated in terms of the hinge loss at each pass is shown in Figure 1 (a). Note that the minimum test error for a number of passes is less than 20, after which it increases significantly, a so-called overfitting regime. This result clearly illustrates the regulating effect of the number of passes. In the second experiment, we look at SIGM with decreasing step size (\u03b7 = 1 / 4 and \u03b8 = 1 / 2). As shown in Figure 1 (b), the overfitting is not observed in the first 100 passes. In this case, the multiplex appears as the optimal solution to the slowdown code."}, {"heading": "4.2 Accuracy and Computational Time Comparison", "text": "In this subsection, we compare SGM with the cross-validation and SIGM with the benchmark algorithm LIBSVM [8], both in terms of accuracy and computation time. For SGM, we use the cross-validation with 30 parameter assumptions to optimize the step size (either by setting \u03b8 = 0 while setting \u03b7, or by setting \u03b7 = 1 / 4 while setting \u03b8). For SIGM, we use two types of step size proposed in Section 3: \u03b7 = 1 / \u221a m and \u03b8 = 0, or \u03b7 = 1 / 4 and \u03b8 = 1 / 2. The test errors related to the hinge loss will be the relative misclassification errors and the computation times in Table 2.We begin with the comparison of accuracies. The results in Table 2 suggest that SGM with constant and decreasing step sizes and SIGM with fixed step sizes have comparable test errors that are consistent with the LIBM baseline."}, {"heading": "Acknowledgments", "text": "This material is based on the work supported by the Centre for Brains, Mind and Machines (CBMM), financed by the NSF STC Prize CCF-1231216. L. R. thanks for the financial support of the FIRB project of the Italian Ministry of Education, University and Research RBFR12M3AC. The authors thank Dr. Francesco Orabona for the fruitful discussions on this research topic and Dr. Silvia Villa and the referees for their valuable comments."}, {"heading": "A Basic Lemmas", "text": "The following basic Lemma is useful for our proofs, which are used several times. Its proof comes from the convexity of V (y, \u00b7) and the fact that V (y, a) has a limit. Lemma 1. Assuming 1, for all k, N and w, F, we have the convexity of V (y, \u00b7 w) and the fact that V, wk, 2 + (a0\u043c) 2\u03b72k + 2\u03b7k [V (yjk, < w,) >) \u2212 V (yjk, < wk,) >). (12) Proof. Since wk + 1 is given by (3), by extension of the inner product, we have the convexity of (wk, < w) > wk, 2 + w, the convexity of V (yjk, < w). (yjk, wk)."}, {"heading": "B Sample Errors", "text": "The difference between the generalization and empirical errors is a so-called sampling error. To estimate this sampling error, we present the following problem, which results in a uniform upper limit for sampling errors over a ball BR = (w). The proof is based on a standard symmetry technology and Rademacher complexity, e.g. [1, 13]. For completeness, we offer a proof here.Lemma 3. Assume (4) and (5). For all R > 0, we have a standard symmetry technique and Rademacher complexity, e.g. [1, 13]. For completeness, we offer a proof here.Lemma 3. Assume (4) and (5)."}, {"heading": "C Excess Errors for Weighted Averages", "text": "Lemma (T) and z (Z), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W, W, W, W, W, W, W, W, we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W), we (W (W), we (W), we (W), we (W), we (W), we (W), we (W (W), we (W), we (W (W), we (W), we (W), we (W (W), we (W), we (W (W), we (W), we (W (W), we (W, we (W), we (W, we (W), we (W, we (W), we (W (W), we (W (W), we (W (W), we (W, we (W), we (W), we (W, we (W), we (W), we (W (W, we (W), we (W, we (W), we (W), we (W"}, {"heading": "D From Weighted Averages to the Last Iterate", "text": "A basic tool for studying convergence for iterates is the following decomposition, as is often done in [18] for classical online learning or subordinate parentage algorithms [12]. It allows us to examine the weighted excess generalization error 2\u03b7tEz, J [E (wt) \u2212 infw [F E (w)] in terms of \"weighted averages\" and weighted averages. In what follows, we become Ez, J as E for short time.Lemma 9. We have 2\u03b7tE {E (wt) \u2212 infw F E (w)."}, {"heading": "E Explicit Convergence Rates", "text": "In this section, we first introduce the following basic estimated values: q = q q = q = q q = q = q = 1, q = 1, q = 1, q = 1, q = 1, q = 1, q = 1, q = 1, q = 1, q = 1, q = 1, q = 1, k = 1 \u2212 1 \u2212 1 \u2212 2 \u2212 k \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 1 \u2212 1 \u2212 1 \u2212 1 1 1 \u2212 1 1 \u2212 1 1 1 \u2212 1 1 \u2212 1 1 \u2212 1 \u2212 1 1 1 \u2212 1 \u2212 1 \u2212 1 1 1 1 \u2212 1 \u2212 1 1 \u2212 1 1 1 \u2212 1 1 \u2212 1 1 \u2212 1 \u2212 1, 1 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 1 \u2212 1 1 1 k k, k, k \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1, 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1, 1 \u2212 1 \u2212 1 \u2212 1, 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1, 1 \u2212 1 \u2212 1 \u2212 1 1 \u2212 1 1 \u2212 1 1 1 \u2212 1 1 \u2212 1 1 1 \u2212 1, 1 1 1 \u2212 1 1 \u2212 1 \u2212 1, 1 1 1 1 1 1 1 1 \u2212 1 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 1 1, 1 1 1 1 1 1 1 1 1 1 1 1 1 \u2212 1 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1 \u2212 1, 1 \u2212 1 \u2212 1 \u2212 1 1 1 1, 1 \u2212 1 1"}], "references": [{"title": "Local rademacher complexities", "author": ["Peter L Bartlett", "Olivier Bousquet", "Shahar Mendelson"], "venue": "Annals of Statistics,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Rademacher and gaussian complexities: Risk bounds and structural results", "author": ["Peter L Bartlett", "Shahar Mendelson"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Nonlinear Programming", "author": ["Dimitri P Bertsekas"], "venue": "Athena scientific,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1999}, {"title": "Incremental gradient, subgradient, and proximal methods for convex optimization: A survey", "author": ["Dimitri P Bertsekas"], "venue": "Optimization for Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2011}, {"title": "The tradeoffs of large scale learning", "author": ["Olivier Bousquet", "L\u00e9on Bottou"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2008}, {"title": "Stochastic subgradient methods", "author": ["Stephen Boyd", "Almir Mutapcic"], "venue": "Notes for EE364b,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2007}, {"title": "Subgradient methods", "author": ["Stephen Boyd", "Lin Xiao", "Almir Mutapcic"], "venue": "Lecture notes of EE392o,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2003}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Learning Theory: an Approximation", "author": ["Felipe Cucker", "Ding-Xuan Zhou"], "venue": "Theory Viewpoint,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2007}, {"title": "Non-parametric stochastic approximation with large step sizes", "author": ["Aymeric Dieuleveut", "Francis Bach"], "venue": "arXiv preprint arXiv:1408.0361,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Train faster, generalize better: Stability of stochastic gradient descent", "author": ["Moritz Hardt", "Benjamin Recht", "Yoram Singer"], "venue": "arXiv preprint arXiv:1509.01240,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Iterative regularization for learning with convex loss functions", "author": ["Junhong Lin", "Lorenzo Rosasco", "Ding-Xuan Zhou"], "venue": "The Journal of Machine Learning Research, To appear,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Generalization error bounds for Bayesian mixture algorithms", "author": ["Ron Meir", "Tong Zhang"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2003}, {"title": "Robust stochastic approximation approach to stochastic programming", "author": ["Arkadi Nemirovski", "Anatoli Juditsky", "Guanghui Lan", "Alexander Shapiro"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2009}, {"title": "Simultaneous model selection and optimization through parameter-free stochastic learning", "author": ["Francesco Orabona"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Learning with incremental iterative regularization", "author": ["Lorenzo Rosasco", "Silvia Villa"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Minimizing finite sums with the stochastic average gradient", "author": ["Mark Schmidt", "Nicolas Le Roux", "Francis Bach"], "venue": "arXiv preprint arXiv:1309.2388,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2013}, {"title": "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes", "author": ["Ohad Shamir", "Tong Zhang"], "venue": "In Proceedings of the 30th International Conference on Machine Learning,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2013}, {"title": "Support Vector Machines", "author": ["Ingo Steinwart", "Andreas Christmann"], "venue": "Springer Science Business Media,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2008}, {"title": "Online learning as stochastic approximation of regularization paths: Optimality and almost-sure convergence", "author": ["Pierre Tarres", "Yuan Yao"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}], "referenceMentions": [{"referenceID": 4, "context": "The stochastic gradient method (SGM), often called stochastic gradient descent, has become an algorithm of choice in machine learning, because of its simplicity and small computational cost especially when dealing with big data sets [5].", "startOffset": 233, "endOffset": 236}, {"referenceID": 13, "context": "[14] or [15] and references therein, while in practice multiple passes are usually considered.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[14] or [15] and references therein, while in practice multiple passes are usually considered.", "startOffset": 8, "endOffset": 12}, {"referenceID": 5, "context": "The effect of multiple passes has been studied extensively for the optimization of an empirical objective [6], but the role for generalization is less clear.", "startOffset": 106, "endOffset": 109}, {"referenceID": 19, "context": "One first series of results focus on least squares, either with one [21, 20, 10], or multiple (deterministic) passes over the data [16].", "startOffset": 68, "endOffset": 80}, {"referenceID": 9, "context": "One first series of results focus on least squares, either with one [21, 20, 10], or multiple (deterministic) passes over the data [16].", "startOffset": 68, "endOffset": 80}, {"referenceID": 15, "context": "One first series of results focus on least squares, either with one [21, 20, 10], or multiple (deterministic) passes over the data [16].", "startOffset": 131, "endOffset": 135}, {"referenceID": 15, "context": "In [16] it is shown that a universal step-size choice can be taken, if multiple passes are considered.", "startOffset": 3, "endOffset": 7}, {"referenceID": 11, "context": "Here, our starting points are the results in [12, 11, 15] considering convex loss functions.", "startOffset": 45, "endOffset": 57}, {"referenceID": 10, "context": "Here, our starting points are the results in [12, 11, 15] considering convex loss functions.", "startOffset": 45, "endOffset": 57}, {"referenceID": 14, "context": "Here, our starting points are the results in [12, 11, 15] considering convex loss functions.", "startOffset": 45, "endOffset": 57}, {"referenceID": 11, "context": "In [12], early", "startOffset": 3, "endOffset": 7}, {"referenceID": 10, "context": "stopping of a (kernelized) batch subgradient method is analyzed, whereas in [11] the stability properties of SGM for smooth loss functions are considered in a general stochastic optimization setting and certain convergence results are derived.", "startOffset": 76, "endOffset": 80}, {"referenceID": 14, "context": "In [15], a more complex variant of SGM is analyzed and shown to achieve optimal rates.", "startOffset": 3, "endOffset": 7}, {"referenceID": 18, "context": "(5) The above conditions are common in statistical learning theory [19, 9].", "startOffset": 67, "endOffset": 74}, {"referenceID": 8, "context": "(5) The above conditions are common in statistical learning theory [19, 9].", "startOffset": 67, "endOffset": 74}, {"referenceID": 2, "context": "Condition (B) is similar to the one required by stochastic gradient methods [3, 7, 6].", "startOffset": 76, "endOffset": 85}, {"referenceID": 6, "context": "Condition (B) is similar to the one required by stochastic gradient methods [3, 7, 6].", "startOffset": 76, "endOffset": 85}, {"referenceID": 5, "context": "Condition (B) is similar to the one required by stochastic gradient methods [3, 7, 6].", "startOffset": 76, "endOffset": 85}, {"referenceID": 18, "context": "More formally, the condition is related to classical terminologies in approximation theory, such as K-functionals and interpolation spaces [19, 9].", "startOffset": 139, "endOffset": 146}, {"referenceID": 8, "context": "More formally, the condition is related to classical terminologies in approximation theory, such as K-functionals and interpolation spaces [19, 9].", "startOffset": 139, "endOffset": 146}, {"referenceID": 8, "context": "Assumption 2 is standard in statistical learning theory when analyzing Tikhonov regularization [9, 19].", "startOffset": 95, "endOffset": 102}, {"referenceID": 18, "context": "Assumption 2 is standard in statistical learning theory when analyzing Tikhonov regularization [9, 19].", "startOffset": 95, "endOffset": 102}, {"referenceID": 8, "context": "Besides, it has been shown that Tikhonov regularization can achieve best performance by choosing an appropriate penalty parameter which depends on the unknown parameter \u03b2 [9, 19].", "startOffset": 171, "endOffset": 178}, {"referenceID": 18, "context": "Besides, it has been shown that Tikhonov regularization can achieve best performance by choosing an appropriate penalty parameter which depends on the unknown parameter \u03b2 [9, 19].", "startOffset": 171, "endOffset": 178}, {"referenceID": 11, "context": "The proof of the above result follows more or less directly from combining ideas and results in [12, 11] and is postponed to the appendix.", "startOffset": 96, "endOffset": 104}, {"referenceID": 10, "context": "The proof of the above result follows more or less directly from combining ideas and results in [12, 11] and is postponed to the appendix.", "startOffset": 96, "endOffset": 104}, {"referenceID": 17, "context": ", [18].", "startOffset": 2, "endOffset": 6}, {"referenceID": 18, "context": "These results follow by an argument similar to that in Chapter 6 from [19] and are omitted.", "startOffset": 70, "endOffset": 74}, {"referenceID": 11, "context": "The proof of the above theorem is based on ideas from [12], where tools from Rademacher complexity [2, 13] are employed.", "startOffset": 54, "endOffset": 58}, {"referenceID": 1, "context": "The proof of the above theorem is based on ideas from [12], where tools from Rademacher complexity [2, 13] are employed.", "startOffset": 99, "endOffset": 106}, {"referenceID": 12, "context": "The proof of the above theorem is based on ideas from [12], where tools from Rademacher complexity [2, 13] are employed.", "startOffset": 99, "endOffset": 106}, {"referenceID": 13, "context": "Approaches in this sense include classical results in optimization (see [14] and references therein), but also approaches based on so-called \u201conline to batch\u201d conversion (see [15] and references therein).", "startOffset": 72, "endOffset": 76}, {"referenceID": 14, "context": "Approaches in this sense include classical results in optimization (see [14] and references therein), but also approaches based on so-called \u201conline to batch\u201d conversion (see [15] and references therein).", "startOffset": 175, "endOffset": 179}, {"referenceID": 3, "context": "In this view, Algorithm 1 is seen as an instance of incremental methods for the minimization of objective functions that are sums of a finite, but possibly large, number of terms [4].", "startOffset": 179, "endOffset": 182}, {"referenceID": 4, "context": "Here, we follow the approach in [5] advocating the combination of statistical and computational errors.", "startOffset": 32, "endOffset": 35}, {"referenceID": 10, "context": "w\u0303 = w\u2217 z, this can be seen to be the choice made in [11].", "startOffset": 53, "endOffset": 57}, {"referenceID": 11, "context": "Following [12], we do this introducing Assumption (6) and choosing w\u0303 as the unique minimizer of E + \u03bb\u2016 \u00b7 \u2016, \u03bb > 0.", "startOffset": 10, "endOffset": 14}, {"referenceID": 10, "context": "For the generalization error, the stability results from [11] provide sharp estimates for smooth loss functions and in the \u2018capacity independent\u2019 limit, that is under no assumptions on the covering numbers of the considered function space.", "startOffset": 57, "endOffset": 61}, {"referenceID": 18, "context": "For this setting, the obtained bound is optimal in the sense that it matches the best available bound for Tikhonov regularization [19, 9].", "startOffset": 130, "endOffset": 137}, {"referenceID": 8, "context": "For this setting, the obtained bound is optimal in the sense that it matches the best available bound for Tikhonov regularization [19, 9].", "startOffset": 130, "endOffset": 137}, {"referenceID": 5, "context": "The computational error for the averaged iterates can be controlled using classic arguments [6], whereas for the last iterate the arguments in [12, 18] are needed.", "startOffset": 92, "endOffset": 95}, {"referenceID": 11, "context": "The computational error for the averaged iterates can be controlled using classic arguments [6], whereas for the last iterate the arguments in [12, 18] are needed.", "startOffset": 143, "endOffset": 151}, {"referenceID": 17, "context": "The computational error for the averaged iterates can be controlled using classic arguments [6], whereas for the last iterate the arguments in [12, 18] are needed.", "startOffset": 143, "endOffset": 151}, {"referenceID": 16, "context": "However, it would be very interesting to consider more sophisticated, \u2018accelerated\u2019 iterations [17], and assess the potential advantages in terms of computational and generalization aspects.", "startOffset": 95, "endOffset": 99}, {"referenceID": 11, "context": "[12], but others will require non-trivial extensions of results developed for Tikhonov regularization in the last few years.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "A remarkable result in this direction is derived in [15], where it is shown that, in the capacity independent setting, adaptive online parameter tuning is indeed possible.", "startOffset": 52, "endOffset": 56}, {"referenceID": 0, "context": "For the decaying step-size case, we fix \u03b71 = 1/4, and run SGM with different \u03b8 \u2208 [0, 1].", "startOffset": 81, "endOffset": 87}, {"referenceID": 7, "context": "2 Accuracy and Computational Time Comparison In this subsection, we compare SGM with cross-validation and SIGM with benchmark algorithm LIBSVM [8], both in terms of accuracy and computational time.", "startOffset": 143, "endOffset": 146}, {"referenceID": 0, "context": "[1] Peter L Bartlett, Olivier Bousquet, and Shahar Mendelson.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "[2] Peter L Bartlett and Shahar Mendelson.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] Dimitri P Bertsekas.", "startOffset": 0, "endOffset": 3}, {"referenceID": 3, "context": "[4] Dimitri P Bertsekas.", "startOffset": 0, "endOffset": 3}, {"referenceID": 4, "context": "[5] Olivier Bousquet and L\u00e9on Bottou.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "[6] Stephen Boyd and Almir Mutapcic.", "startOffset": 0, "endOffset": 3}, {"referenceID": 6, "context": "[7] Stephen Boyd, Lin Xiao, and Almir Mutapcic.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "[8] Chih-Chung Chang and Chih-Jen Lin.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "[9] Felipe Cucker and Ding-Xuan Zhou.", "startOffset": 0, "endOffset": 3}, {"referenceID": 9, "context": "[10] Aymeric Dieuleveut and Francis Bach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 10, "context": "[11] Moritz Hardt, Benjamin Recht, and Yoram Singer.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "[12] Junhong Lin, Lorenzo Rosasco, and Ding-Xuan Zhou.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "[13] Ron Meir and Tong Zhang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "[14] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander Shapiro.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[15] Francesco Orabona.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[16] Lorenzo Rosasco and Silvia Villa.", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "[17] Mark Schmidt, Nicolas Le Roux, and Francis Bach.", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[18] Ohad Shamir and Tong Zhang.", "startOffset": 0, "endOffset": 4}, {"referenceID": 18, "context": "[19] Ingo Steinwart and Andreas Christmann.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "[20] Pierre Tarres and Yuan Yao.", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "[1, 13].", "startOffset": 0, "endOffset": 7}, {"referenceID": 12, "context": "[1, 13].", "startOffset": 0, "endOffset": 7}, {"referenceID": 12, "context": "Using a standard symmetrization technique, for example in [13], we get", "startOffset": 58, "endOffset": 62}, {"referenceID": 0, "context": "[1], we derive", "startOffset": 0, "endOffset": 3}, {"referenceID": 10, "context": "9 from [11], we can control the sample errors as follows.", "startOffset": 7, "endOffset": 11}, {"referenceID": 10, "context": "8 from [11].", "startOffset": 7, "endOffset": 11}, {"referenceID": 17, "context": "A basic tool for studying the convergence for iterates is the following decomposition, as often done in [18] for classical online learning or subgradient descent algorithms [12].", "startOffset": 104, "endOffset": 108}, {"referenceID": 11, "context": "A basic tool for studying the convergence for iterates is the following decomposition, as often done in [18] for classical online learning or subgradient descent algorithms [12].", "startOffset": 173, "endOffset": 177}, {"referenceID": 1, "context": "Obviously, \u03b8 \u2208 [0, 2 3 ] since \u03b2 \u2208 (0, 1].", "startOffset": 15, "endOffset": 24}, {"referenceID": 2, "context": "Obviously, \u03b8 \u2208 [0, 2 3 ] since \u03b2 \u2208 (0, 1].", "startOffset": 15, "endOffset": 24}], "year": 2016, "abstractText": "We study the generalization properties of stochastic gradient methods for learning with convex loss functions and linearly parameterized functions. We show that, in the absence of penalizations or constraints, the stability and approximation properties of the algorithm can be controlled by tuning either the step-size or the number of passes over the data. In this view, these parameters can be seen to control a form of implicit regularization. Numerical results complement the theoretical findings.", "creator": "LaTeX with hyperref package"}}}