{"id": "1606.00787", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Jun-2016", "title": "Post-Inference Prior Swapping", "abstract": "While Bayesian methods are praised for their ability to incorporate useful prior knowledge, in practice, priors that allow for computationally convenient or tractable inference are more commonly used. In this paper, we investigate the following question: for a given model, is it possible to use any convenient prior to infer a false posterior, and afterwards, given some true prior of interest, quickly transform this result into the true posterior?", "histories": [["v1", "Thu, 2 Jun 2016 18:20:35 GMT  (743kb,D)", "http://arxiv.org/abs/1606.00787v1", null], ["v2", "Wed, 12 Jul 2017 18:01:17 GMT  (878kb,D)", "http://arxiv.org/abs/1606.00787v2", null]], "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG stat.CO stat.ME", "authors": ["willie neiswanger", "eric p xing"], "accepted": true, "id": "1606.00787"}, "pdf": {"name": "1606.00787.pdf", "metadata": {"source": "CRF", "title": "Prior Swapping for Data-Independent Inference", "authors": ["Willie Neiswanger", "Eric P. Xing"], "emails": ["WILLIE@CS.CMU.EDU", "EPXING@CS.CMU.EDU"], "sections": [{"heading": null, "text": "We present a method to accomplish this task: In the face of false posterior and true prior, our algorithm generates samples from the real posterior. This transformation process, which we call \"prior swapping,\" works for any prior. It is noteworthy that its costs are independent of the data size. It therefore allows us in some cases to apply significantly cheaper inference methods to more complex models than previously possible. It also allows us to quickly perform additional conclusions, such as with updated priors or for many different hyperparameter settings, without touching the data. We prove that our method can generate asymptotically exact samples and verify them empirically on a number of models and priors."}, {"heading": "1. Introduction", "text": "This year, it is closer than ever before in the history of the country."}, {"heading": "2. Prior Swapping", "text": "Suppose we have a dataset of n real, finite-dimensional vectors xn = finite-dimensional vectors x1,. (.) Suppose we are interested in a family of models defined by the probability function fx. (.) The probability and previous definition of a common model determined by the real, d-dimensional vector methods, however, is usually not given. (.) Suppose we have a previous distribution over the space of the model parameters. (.) Suppose we have a previous distribution over the x-dimensional methods. (.) Suppose we have a previous distribution over the x-dimensional methods. (.) In Bayesian Inference we are interested in calculating the posterior distribution - i.e. (.) A conditional distribution of this common model - with PDFf\u00da (.) x (.) We (.)"}, {"heading": "2.1 Theoretical Guarantees", "text": "At this point, we give theoretical guarantees about the accuracy of the samples generated by previous swap. First, it should be noted that if we have an exact analytical expression for the wrong posterior, the previous swap function is proportional to the actual posterior, i.e. f * eps = f * eps * f\u03b8 | x. To prove that we are generating asymptotically exact samples with a consistent false posterior swap target, and with existing guarantees, such as the production of asymptotically exact posterior samples [8, 45, 37]. In the second setting, we must show that f \u00b2 sps is consistent for fps and that Alg. 1 actually pulls samples from f * sps.Theorem 2.1."}, {"heading": "3. Empirical Results", "text": "We show empirical results on Bayesian generalized linear models (including linear and hierarchical logistic regression) with sparsity and heavy tailed priors, on latent factor models (including mixture models and theme models) with relational priorities over factors (e.g. diversity-enhancing, agglomerative, etc.), and feedforward neural networks where we show hyperparameter tuning of weight and decay models L2 regularization using previous swaps with normal priors. We aim to empirically show that previous swapping allows us to apply lower cost inference algorithms to more complex models than was previously possible, and that it efficiently provides correct samples of swap. We compare the following inference procedures: \u2022 MCMC on the true posterior: MCMC sampling algorithms run directly on f.x. \u2022 We run directly on the true inference algorithm:"}, {"heading": "3.1 Sparsity Inducing and Heavy Tailed Priors in Generalized Linear Models", "text": "We have gained a high degree of popularity in the last decade due to their ability to produce models with greater interpretability, predictable accuracy and parsimony. For example, the L1 standard was used to induce thrift with great effect [53, 39], and it has been shown that these methods correspond to a mean zero independent laplace before [53, 49, 32, 6]. In a Bayesian setting, the use of methods that presuppose thrift can be difficult, and researchers often resort to computationally intensive methods (such as Hamiltonian Monte Carlo) or biased approximations (e.g. expectation projection) that make factorization or parametric assumptions that offer a cheap but precise solution: first we use a more tractable previous one (such as a normal inference in closed form is possible), and then we quickly use the result in posterior given thrift."}, {"heading": "3.2 Relational Priors over Factors in Latent Variable Models", "text": "Many latent variable models in machine learning - such as blending models, topic models, probability matrix factorization, and various others - incorporate a number of latent factors (e.g. components or topics), and we often want to use priorities that encourage interesting behaviors between the factors. For example, we could use different factors via a diversity-enhancing previous [63, 24, 62] or for the factors to show some kind of splitting pattern [28, 23, 64]. Conclusions in such models are often arithmetically expensive or designed case by case [63, 23, 64]. However, when conjugated priors are placed above the factor parameters, collapsed Gibbs models can be applied. In this method, factor parameters are integrated, leaving only a subset of variables; on these we can analytically calculate conditional distributions, allowing Gibbs to stamp over these variables."}, {"heading": "3.3 Tuning L2 Regularization (Weight Decay) in Deep Neural Networks", "text": "Learning neural networks with weight decay (L2 regularization) can be seen as finding the MAP point estimate of a Bayesian neural network model with a normal previous value [47, 33, 17]. Since the previous swap function can be used as an optimization target for an MAP estimate, we aim to use a previous swap for fast hyperparameter adjustment of weight decay in neural networks. We compare this to determine the optimal weight decay using stochastic gradient descent [4] and stochastic gradient-Langevin dynamics [59] and draw conclusions in neural networks. These stochastic gradient methods have only a slight dependence on the data at each iteration; however, their updates may be loud or suboptimal [22, 57, 44, 11] while previous swap updates have exact gradient function (without previous stostility)."}, {"heading": "4. Conclusion", "text": "We have outlined procedures to perform the task of the previous exchange: Given a false rear exchange process (calculated using some convenient false precursors) and a real priority of interest, our algorithms generate samples from the real rear area. Empirically, we have shown that an earlier exchange can quickly produce correct samples on a number of models and precursors (1), (2) that less costly data-dependent inference algorithms can be applied to more complex models than previously possible, (3) allow quick model selection or hyperparameter tuning, and (4) can be applied directly to existing inference algorithms to add richer pre-information to the pre-calculated inference results without having to call up the data again. Theoretically, we have shown that this strategy can be applied to a stream of false rear samples to generate asymptotically exact samples from the real rear area. Furthermore, we hope that an existing black box replacement method can be successfully implemented as an earlier automated one."}, {"heading": "Appendix A. Proofs of Theoretical Guarantees", "text": "We expect that we will be able to follow these two theorems. (...) We expect that we will be able to follow these two theorems. (...) We expect that we will be able to follow these two theorems. (...) We expect that we will be able to follow these two theorems. (...) We expect that we will be able to follow these two theorems. (...) We expect that we will be able to follow these two theorems. (...) We expect that we will be able to follow them. (...) We expect that we will be able to follow them. (...) We expect that we will be able. (...) We expect that we will be able. (...) We expect that we will be able to follow these two theorems. (...) We expect that we will be able. (...) We expect that we will be able. (...) We expect that we will be able. (...) We expect that we will be able to follow these two theorems."}, {"heading": "Appendix B. Computational Complexity Summary", "text": "Here we summarize the complexity of our previous swapping algorithms. Suppose that we have executed an existing inference algorithm to either calculate an analytical expression of fixed complexity for the false-posterior density or draw T false-posterior samples because we have a dataset of n observations. Suppose we want to calculate S samples from the true-posterior. Given an analytical expression of fixed complexity for the false-posterior, each step (i.e. the generation of each sample) in an MCMC algorithm requires a constant number of operations O (1), and therefore pulling S samples using our method requires O (S) operations.Let us assume T samples from the false-posterior, the asymptotically exact (semiparametric) procedure in Alg. 1 must perform the fixed complexity procedure before swapping."}, {"heading": "Appendix C. Prior Swapping Pseudocode (for Fixed-Complexity f\u03c6|x)", "text": "Here we specify the pseudo-code for the previous swap procedure where a specified complexity (parametric) is specified. < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < <"}, {"heading": "Appendix D. Sample Combination Algorithm Pseudocode", "text": "Here we specify a pseudo code for a combination algorithm with product density [48, 37, 42]. We will write this algorithm for our setting (i.e. for generating samples from the product of two densities), although these algorithms are typically of a more general nature. We are essentially following Alg. 1 from [37]. The intuitive idea behind these algorithms is the following: There will be two sample sets with profiles {\u03b8 1t} T = 1 \u0445 f1 (\u03b8) and {\u03b8 2t} T = 1 \u0445 f2 (\u03b8) T t = 1 \u0445 f2 (\u03b8 1} Tt = 1, {\u03b8 2} Tt = {\u03b8t} T = 1 \u0445 1 Z f1 f2 (\u03b8) T =. For each iteration in this algorithm, four steps are performed: 1. Choose one of the two input sets (uniformly according to the random principle).2. Pull a sample k.3. Accept this 4. or assign the previously drawn combination."}, {"heading": "Appendix E. Incorporating observed prior information", "text": "The asymptotically exact method for previous swap transactions allows a related way to integrate the observed prior information more easily (or additionally). Frequently, we will extend our asymptotically exact previous swap procedures to this procedure. Assuming that we only have access to samples we want to derive from the true-previous swap procedure, this may lead to better data-driven procedures. (Assuming we only have access to samples from the true-previous swap procedure.) T = 1 from the true-previous swap procedure. (Note) T = 1 from the true-previous swap procedure. (Note) T = 1 from the true-previous swap procedure. (Note). (Note). (Note). (Note). (Note). (Note). (Note). (Note) (Note) (Note). (Note) (Note). (Note) (Note). (Note. (.........)..... (..... (.....)..... (Note. (.....)..... (.....)..... (Note. (.....)..... (.....)..... (Note. (.....)..... (.....)..... (Note.)..... (.....)..... (Note......)..... (.....)..... (Note.)..... (.....)..... (Note.)..... (.....).....)..... (Note.)..... (.....)..... (Note.)..... (.....).....)..... (.....)..... (Note.)..... (.....)..... (.....)..... (Note.)..... (.....).....)..... (.....).....)..... (.....). (.....)..... (.....). (.....).)."}], "references": [{"title": "Bayesian analysis of binary and polychotomous response data", "author": ["James H Albert", "Siddhartha Chib"], "venue": "Journal of the American statistical Association,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1993}, {"title": "An introduction to mcmc for machine learning", "author": ["Christophe Andrieu", "Nando De Freitas", "Arnaud Doucet", "Michael I Jordan"], "venue": "Machine learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Latent dirichlet allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2003}, {"title": "Large-scale machine learning with stochastic gradient descent", "author": ["L\u00e9on Bottou"], "venue": "In Proceedings of COMP- STAT\u20192010,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Stan: a probabilistic programming language", "author": ["Bob Carpenter", "Andrew Gelman", "Matt Hoffman", "Daniel Lee", "Ben Goodrich", "Michael Betancourt", "Marcus A Brubaker", "Jiqiang Guo", "Peter Li", "Allen Riddell"], "venue": "Journal of Statistical Software,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Handling sparsity via the horseshoe", "author": ["Carlos M Carvalho", "Nicholas G Polson", "James G Scott"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Stochastic gradient hamiltonian monte carlo", "author": ["Tianqi Chen", "Emily B Fox", "Carlos Guestrin"], "venue": "arXiv preprint arXiv:1402.4102,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Understanding the metropolis-hastings algorithm", "author": ["Siddhartha Chib", "Edward Greenberg"], "venue": "The american statistician,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1995}, {"title": "Conjugate priors for exponential families", "author": ["Persi Diaconis", "Donald Ylvisaker"], "venue": "The Annals of statistics,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1979}, {"title": "Estimation of finite mixture distributions through bayesian sampling", "author": ["Jean Diebolt", "Christian P Robert"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1994}, {"title": "Bayesian sampling using stochastic gradient thermostats", "author": ["Nan Ding", "Youhan Fang", "Ryan Babbush", "Changyou Chen", "Robert D Skeel", "Hartmut Neven"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "On sequential monte carlo sampling methods for bayesian filtering", "author": ["Arnaud Doucet", "Simon Godsill", "Christophe Andrieu"], "venue": "Statistics and computing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2000}, {"title": "Variational bayesian inference for linear and logistic regression", "author": ["Jan Drugowitsch"], "venue": "arXiv preprint arXiv:1310.5438,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "A compendium of conjugate priors", "author": ["Daniel Fink"], "venue": "See http://www.people.cornell.edu/pages/ df36/CONJINTRnewTEX.pdf,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1997}, {"title": "Objections to bayesian statistics", "author": ["Andrew Gelman"], "venue": "Bayesian Analysis,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Bayesian inference for generalized linear models for spiking neurons", "author": ["Sebastian Gerwinn", "Jakob H Macke", "Matthias Bethge"], "venue": "Frontiers in Computational Neuroscience,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2010}, {"title": "Keeping neural networks simple", "author": ["Geoffrey E Hinton", "Drew van Camp"], "venue": "In ICANN\u201993,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1993}, {"title": "Nonparametric density estimation with a parametric start", "author": ["Nils Lid Hjort", "Ingrid K Glad"], "venue": "The Annals of Statistics,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1995}, {"title": "The no-u-turn sampler: Adaptively setting path lengths in hamiltonian monte carlo", "author": ["Matthew D Hoffman", "Andrew Gelman"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Efficient simulation of bayesian logistic regression models", "author": ["C Holmes", "Leonhard Knorr-Held"], "venue": "Technical report, Discussion papers/Sonderforschungsbereich 386 der Ludwig-Maximilians-Universita\u0308t Mu\u0308nchen,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2003}, {"title": "Review papers: recent developments in nonparametric density estimation", "author": ["Alan Julian Izenman"], "venue": "Journal of the American Statistical Association,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1991}, {"title": "Accelerating stochastic gradient descent using predictive variance reduction", "author": ["Rie Johnson", "Tong Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Nonparametric bayesian sparse factor models with application to gene expression modeling", "author": ["David Knowles", "Zoubin Ghahramani"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2011}, {"title": "Priors for diversity in generative latent variable models", "author": ["James T Kwok", "Ryan P Adams"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2012}, {"title": "The mnist database of handwritten digits", "author": ["Yann LeCun", "Corinna Cortes", "Christopher JC Burges"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1998}, {"title": "Venture: a higher-order probabilistic programming platform with programmable inference", "author": ["Vikash Mansinghka", "Daniel Selsam", "Yura Perov"], "venue": "arXiv preprint arXiv:1404.0099,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Bayesian modelling and inference on mixtures of distributions", "author": ["Jean-Michel Marin", "Kerrie Mengersen", "Christian P Robert"], "venue": "Handbook of statistics,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2005}, {"title": "Sparse latent factor models with interactions: Analysis of gene expression data", "author": ["Vinicius Diniz Mayrink", "Joseph Edward Lucas"], "venue": "The Annals of Applied Statistics,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "Equation of state calculations by fast computing machines", "author": ["Nicholas Metropolis", "Arianna W Rosenbluth", "Marshall N Rosenbluth", "Augusta H Teller", "Edward Teller"], "venue": "The journal of chemical physics,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 1953}, {"title": "Bayesian linear regression", "author": ["Thomas Minka"], "venue": "Technical report, Citeseer,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2000}, {"title": "Expectation propagation for approximate bayesian inference", "author": ["Thomas P Minka"], "venue": "In Proceedings of the Seventeenth conference on Uncertainty in artificial intelligence,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2001}, {"title": "Bayesian and l1 approaches to sparse unsupervised learning", "author": ["Shakir Mohamed", "Katherine Heller", "Zoubin Ghahramani"], "venue": "arXiv preprint arXiv:1106.1157,", "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2011}, {"title": "A simple weight decay can improve generalization", "author": ["J Moody", "S Hanson", "Anders Krogh", "John A Hertz"], "venue": "Advances in neural information processing systems,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 1995}, {"title": "MCMC using hamiltonian dynamics", "author": ["R Neal"], "venue": "Handbook of Markov Chain Monte Carlo,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2011}, {"title": "Annealed importance sampling", "author": ["Radford M Neal"], "venue": "Statistics and Computing,", "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2001}, {"title": "Modeling citation networks using latent random offsets", "author": ["Willie Neiswanger", "Chong Wang", "Qirong Ho", "Eric P Xing"], "venue": "In Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2014}, {"title": "Asymptotically exact, embarrassingly parallel mcmc", "author": ["Willie Neiswanger", "Chong Wang", "Eric Xing"], "venue": "In Proceedings of the 30th Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2014}, {"title": "The dependent dirichlet process mixture of objects for detection-free tracking and object modeling", "author": ["Willie Neiswanger", "Frank Wood", "Eric P Xing"], "venue": "In The Seventeenth International Conference on Artificial Intelligence and Statistics (AISTATS", "citeRegEx": "38", "shortCiteRegEx": "38", "year": 2014}, {"title": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images", "author": ["Bruno A Olshausen"], "venue": null, "citeRegEx": "39", "shortCiteRegEx": "39", "year": 1996}, {"title": "A compilation target for probabilistic programming languages", "author": ["Brooks Paige", "Frank Wood"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "40", "shortCiteRegEx": "40", "year": 1935}, {"title": "Asynchronous anytime sequential monte carlo", "author": ["Brooks Paige", "Frank Wood", "Arnaud Doucet", "Yee Whye Teh"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "41", "shortCiteRegEx": "41", "year": 2014}, {"title": "Variational consensus monte carlo", "author": ["Maxim Rabinovich", "Elaine Angelino", "Michael I Jordan"], "venue": "arXiv preprint arXiv:1506.03074,", "citeRegEx": "42", "shortCiteRegEx": "42", "year": 2015}, {"title": "Identifiability of parameters in mcmc bayesian inference of phylogeny", "author": ["Bruce Rannala"], "venue": "Systematic Biology,", "citeRegEx": "43", "shortCiteRegEx": "43", "year": 2002}, {"title": "On variance reduction in stochastic gradient descent and its asynchronous variants", "author": ["Sashank J Reddi", "Ahmed Hefny", "Suvrit Sra", "Barnab\u00e1s P\u00f3czos", "Alex J Smola"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "44", "shortCiteRegEx": "44", "year": 2015}, {"title": "Simple conditions for the convergence of the gibbs sampler and metropolis-hastings algorithms", "author": ["Gareth O Roberts", "Adrian FM Smith"], "venue": "Stochastic processes and their applications,", "citeRegEx": "45", "shortCiteRegEx": "45", "year": 1994}, {"title": "Brownian dynamics as smart monte carlo simulation", "author": ["PJ Rossky", "JD Doll", "HL Friedman"], "venue": "The Journal of Chemical Physics,", "citeRegEx": "46", "shortCiteRegEx": "46", "year": 1978}, {"title": "Deep learning in neural networks: An overview", "author": ["J\u00fcrgen Schmidhuber"], "venue": "Neural Networks,", "citeRegEx": "47", "shortCiteRegEx": "47", "year": 2015}, {"title": "Bayes and big data: The consensus monte carlo algorithm", "author": ["Steven L. Scott", "Alexander W. Blocker", "Fernando V. Bonassi"], "venue": "In Bayes 250,", "citeRegEx": "48", "shortCiteRegEx": "48", "year": 2013}, {"title": "Bayesian inference and optimal design for the sparse linear model", "author": ["Matthias W Seeger"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "49", "shortCiteRegEx": "49", "year": 2008}, {"title": "Bayesian computation via the gibbs sampler and related markov chain monte carlo methods", "author": ["Adrian FM Smith", "Gareth O Roberts"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "50", "shortCiteRegEx": "50", "year": 1993}, {"title": "Bayesian inference of gaussian mixture models with noninformative priors", "author": ["Colin J Stoneking"], "venue": "arXiv preprint arXiv:1405.4895,", "citeRegEx": "51", "shortCiteRegEx": "51", "year": 2014}, {"title": "A collapsed variational bayesian inference algorithm for latent dirichlet allocation", "author": ["Yee W Teh", "David Newman", "Max Welling"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "52", "shortCiteRegEx": "52", "year": 2006}, {"title": "Regression shrinkage and selection via the lasso", "author": ["Robert Tibshirani"], "venue": "Journal of the Royal Statistical Society. Series B (Methodological),", "citeRegEx": "53", "shortCiteRegEx": "53", "year": 1996}, {"title": "Importance sampling: a review", "author": ["Surya T Tokdar", "Robert E Kass"], "venue": "Wiley Interdisciplinary Reviews: Computational Statistics,", "citeRegEx": "54", "shortCiteRegEx": "54", "year": 2010}, {"title": "Collaborative topic modeling for recommending scientific articles", "author": ["Chong Wang", "David M Blei"], "venue": "In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "55", "shortCiteRegEx": "55", "year": 2011}, {"title": "Variational inference in nonconjugate models", "author": ["Chong Wang", "David M Blei"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "56", "shortCiteRegEx": "56", "year": 2013}, {"title": "Variance reduction for stochastic gradient optimization", "author": ["Chong Wang", "Xi Chen", "Alex Smola", "Eric Xing"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "57", "shortCiteRegEx": "57", "year": 2013}, {"title": "All of nonparametric statistics", "author": ["Larry Wasserman"], "venue": "Springer Science & Business Media,", "citeRegEx": "58", "shortCiteRegEx": "58", "year": 2006}, {"title": "Bayesian learning via stochastic gradient Langevin dynamics", "author": ["Max Welling", "Yee W Teh"], "venue": "In Proceedings of the 28th International Conference on Machine Learning,", "citeRegEx": "59", "shortCiteRegEx": "59", "year": 2011}, {"title": "A non-parametric bayesian method for inferring hidden causes", "author": ["Frank Wood", "Thomas Griffiths", "Zoubin Ghahramani"], "venue": "arXiv preprint arXiv:1206.6865,", "citeRegEx": "60", "shortCiteRegEx": "60", "year": 2012}, {"title": "A new approach to probabilistic programming inference", "author": ["Frank Wood", "Jan Willem van de Meent", "Vikash Mansinghka"], "venue": "In Proceedings of the 17th International conference on Artificial Intelligence and Statistics,", "citeRegEx": "61", "shortCiteRegEx": "61", "year": 2014}, {"title": "Latent variable modeling with diversity-inducing mutual angular regularization", "author": ["Pengtao Xie", "Yuntian Deng", "Eric Xing"], "venue": "arXiv preprint arXiv:1512.07336,", "citeRegEx": "62", "shortCiteRegEx": "62", "year": 2015}, {"title": "Diversity-promoting bayesian learning of latent variable models", "author": ["Pengtao Xie", "Jun Zhu", "Eric Xing"], "venue": "In Proceedings of the 33st International Conference on Machine Learning", "citeRegEx": "63", "shortCiteRegEx": "63", "year": 2016}, {"title": "Bayesian learning in sparse graphical factor models via variational mean-field annealing", "author": ["Ryo Yoshida", "Mike West"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "64", "shortCiteRegEx": "64", "year": 2010}], "referenceMentions": [{"referenceID": 8, "context": "For example, \u2022 Conjugate priors yield posteriors with a known parametric form and therefore allow for noniterative, exact inference [9, 14].", "startOffset": 132, "endOffset": 139}, {"referenceID": 13, "context": "For example, \u2022 Conjugate priors yield posteriors with a known parametric form and therefore allow for noniterative, exact inference [9, 14].", "startOffset": 132, "endOffset": 139}, {"referenceID": 49, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 15, "endOffset": 27}, {"referenceID": 9, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 15, "endOffset": 27}, {"referenceID": 59, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 58, "endOffset": 70}, {"referenceID": 51, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 58, "endOffset": 70}, {"referenceID": 37, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 58, "endOffset": 70}, {"referenceID": 55, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 106, "endOffset": 114}, {"referenceID": 51, "context": "Gibbs sampling [50, 10, 65], sampling in collapsed models [60, 52, 38], or mean-field variational methods [56, 52]).", "startOffset": 106, "endOffset": 114}, {"referenceID": 1, "context": "the normal distribution) allow for computationally cheap density queries, maximization, and sampling [2], which can allow for easier use in iterative inference algorithms (e.", "startOffset": 101, "endOffset": 104}, {"referenceID": 28, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 20, "endOffset": 27}, {"referenceID": 7, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 20, "endOffset": 27}, {"referenceID": 33, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 49, "endOffset": 53}, {"referenceID": 11, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 81, "endOffset": 89}, {"referenceID": 40, "context": "Metropolis-Hastings [29, 8], gradient-based MCMC [34], or sequential Monte Carlo [12, 41]).", "startOffset": 81, "endOffset": 89}, {"referenceID": 42, "context": "\u2022 Certain priors mitigate issues of identifiability, and allow for simpler posteriors without multiple modes [43].", "startOffset": 109, "endOffset": 113}, {"referenceID": 14, "context": "This can encourage the use of convenient priors in practice, rather than priors that might yield a more realistic or accurate inference, which is a criticism of Bayesian methods [15].", "startOffset": 178, "endOffset": 182}, {"referenceID": 28, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 93, "endOffset": 100}, {"referenceID": 7, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 93, "endOffset": 100}, {"referenceID": 45, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 188, "endOffset": 192}, {"referenceID": 33, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 224, "endOffset": 232}, {"referenceID": 18, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 224, "endOffset": 232}, {"referenceID": 58, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 264, "endOffset": 271}, {"referenceID": 6, "context": "For example, we evaluate a function proportional to f\u03b8 |x(\u03b8 |xn) in Metropolis-Hastings (MH) [29, 8] and \u2207\u03b8 log f\u03b8 |x(\u03b8 |xn) in gradient-based MCMC methods (such as Langevin dynamics (LD) [46], Hamiltonian Monte Carlo (HMC) [34, 19], and their stochastic variants [59, 7]).", "startOffset": 264, "endOffset": 271}, {"referenceID": 57, "context": "Suppose we instead use a consistent false posterior density estimate, such as a nonparametric [58, 21] or semiparametric [18] estimate.", "startOffset": 94, "endOffset": 102}, {"referenceID": 20, "context": "Suppose we instead use a consistent false posterior density estimate, such as a nonparametric [58, 21] or semiparametric [18] estimate.", "startOffset": 94, "endOffset": 102}, {"referenceID": 17, "context": "Suppose we instead use a consistent false posterior density estimate, such as a nonparametric [58, 21] or semiparametric [18] estimate.", "startOffset": 121, "endOffset": 125}, {"referenceID": 17, "context": "To motivate this method, we choose a a consistent semiparametric false posterior estimate f\u0302 s \u03c6|x (see [18] for background and consistency guarantees), which can be viewed as the product of a parametric density estimate f\u0302 p \u03c6|x and a nonparametric correction function.", "startOffset": 104, "endOffset": 108}, {"referenceID": 57, "context": "\uf8fb , (5) where we use K to denote a probability density kernel, with bandwidth h, where h\u2192 0 as T \u2192\u221e (see [58] for details on probability density kernels and bandwidth selection).", "startOffset": 105, "endOffset": 109}, {"referenceID": 47, "context": "We therefore turn to sample combination methods for efficiently generating samples from the product of densities [48, 37, 42].", "startOffset": 113, "endOffset": 125}, {"referenceID": 36, "context": "We therefore turn to sample combination methods for efficiently generating samples from the product of densities [48, 37, 42].", "startOffset": 113, "endOffset": 125}, {"referenceID": 41, "context": "We therefore turn to sample combination methods for efficiently generating samples from the product of densities [48, 37, 42].", "startOffset": 113, "endOffset": 125}, {"referenceID": 1, "context": "This setting also has some relation to importance sampling (IS) [2].", "startOffset": 64, "endOffset": 67}, {"referenceID": 34, "context": "However, in practice, performance would only be adequate for false posteriors that are very similar to the true posterior (and not for arbitrary f\u03c6|x), especially in high dimensions [35, 54].", "startOffset": 182, "endOffset": 190}, {"referenceID": 53, "context": "However, in practice, performance would only be adequate for false posteriors that are very similar to the true posterior (and not for arbitrary f\u03c6|x), especially in high dimensions [35, 54].", "startOffset": 182, "endOffset": 190}, {"referenceID": 7, "context": "Using f \u2217 e ps in standard MCMC algorithms therefore carries out MCMC on an exact true posterior target and comes with existing guarantees, such as producing asymptotically-exact posterior samples [8, 45, 37].", "startOffset": 197, "endOffset": 208}, {"referenceID": 44, "context": "Using f \u2217 e ps in standard MCMC algorithms therefore carries out MCMC on an exact true posterior target and comes with existing guarantees, such as producing asymptotically-exact posterior samples [8, 45, 37].", "startOffset": 197, "endOffset": 208}, {"referenceID": 36, "context": "Using f \u2217 e ps in standard MCMC algorithms therefore carries out MCMC on an exact true posterior target and comes with existing guarantees, such as producing asymptotically-exact posterior samples [8, 45, 37].", "startOffset": 197, "endOffset": 208}, {"referenceID": 52, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 76, "endOffset": 84}, {"referenceID": 38, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 76, "endOffset": 84}, {"referenceID": 52, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 163, "endOffset": 178}, {"referenceID": 48, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 163, "endOffset": 178}, {"referenceID": 31, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 163, "endOffset": 178}, {"referenceID": 5, "context": "For example, the L1 norm has been used to induce sparsity with great effect [53, 39], and has been shown to be equivalent to a mean-zero independent Laplace prior [53, 49, 32, 6].", "startOffset": 163, "endOffset": 178}, {"referenceID": 30, "context": "expectation propagation [31]) that make factorization or parametric assumptions [49, 16].", "startOffset": 24, "endOffset": 28}, {"referenceID": 48, "context": "expectation propagation [31]) that make factorization or parametric assumptions [49, 16].", "startOffset": 80, "endOffset": 88}, {"referenceID": 15, "context": "expectation propagation [31]) that make factorization or parametric assumptions [49, 16].", "startOffset": 80, "endOffset": 88}, {"referenceID": 48, "context": "Our first set of experiments are on sparse Bayesian linear regression models [49, 30], which we can write as yi = X i\u03b8+\u03b5, \u03b5\u223cN (0,\u03c32), \u03b8 \u223c f\u03b8 , i = 1,.", "startOffset": 77, "endOffset": 85}, {"referenceID": 29, "context": "Our first set of experiments are on sparse Bayesian linear regression models [49, 30], which we can write as yi = X i\u03b8+\u03b5, \u03b5\u223cN (0,\u03c32), \u03b8 \u223c f\u03b8 , i = 1,.", "startOffset": 77, "endOffset": 85}, {"referenceID": 48, "context": "4/\u03c3} [49]) priors.", "startOffset": 5, "endOffset": 9}, {"referenceID": 19, "context": "Our second set of experiments are on a hierarchical Bayesian logistic regression model [20, 13], which we write as yi \u223c Bern(pi), pi = logistic(X i\u03b8 ), \u03b8 \u223c f\u03b8 , i = 1,.", "startOffset": 87, "endOffset": 95}, {"referenceID": 12, "context": "Our second set of experiments are on a hierarchical Bayesian logistic regression model [20, 13], which we write as yi \u223c Bern(pi), pi = logistic(X i\u03b8 ), \u03b8 \u223c f\u03b8 , i = 1,.", "startOffset": 87, "endOffset": 95}, {"referenceID": 19, "context": "Here, we also use a normal f\u03c6 (see [20, 1] for examples of convenient inference in Bayesian logistic regression under normal priors).", "startOffset": 35, "endOffset": 42}, {"referenceID": 0, "context": "Here, we also use a normal f\u03c6 (see [20, 1] for examples of convenient inference in Bayesian logistic regression under normal priors).", "startOffset": 35, "endOffset": 42}, {"referenceID": 12, "context": "For comparison methods, we use MH for MCMC, and a mean field approximation [13] for VI.", "startOffset": 75, "endOffset": 79}, {"referenceID": 62, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 78, "endOffset": 90}, {"referenceID": 23, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 78, "endOffset": 90}, {"referenceID": 61, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 78, "endOffset": 90}, {"referenceID": 27, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 148, "endOffset": 160}, {"referenceID": 22, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 148, "endOffset": 160}, {"referenceID": 63, "context": "For example, we might want dissimilar factors via a diversity-promoting prior [63, 24, 62] or for the factors to show some sort of sparsity pattern [28, 23, 64].", "startOffset": 148, "endOffset": 160}, {"referenceID": 62, "context": "Inference in such models is often computationally expensive or designed on a case-by-case basis [63, 23, 64].", "startOffset": 96, "endOffset": 108}, {"referenceID": 22, "context": "Inference in such models is often computationally expensive or designed on a case-by-case basis [63, 23, 64].", "startOffset": 96, "endOffset": 108}, {"referenceID": 63, "context": "Inference in such models is often computationally expensive or designed on a case-by-case basis [63, 23, 64].", "startOffset": 96, "endOffset": 108}, {"referenceID": 26, "context": "We first show results on a Gaussian mixture model (GMM) [27, 51], written x i \u223cN (\u03bczi ,\u03a3zi ), zi \u223c Dir(\u03b1), {\u03bcm} m=1 \u223c f\u03b8 , i = 1,.", "startOffset": 56, "endOffset": 64}, {"referenceID": 50, "context": "We first show results on a Gaussian mixture model (GMM) [27, 51], written x i \u223cN (\u03bczi ,\u03a3zi ), zi \u223c Dir(\u03b1), {\u03bcm} m=1 \u223c f\u03b8 , i = 1,.", "startOffset": 56, "endOffset": 64}, {"referenceID": 2, "context": "We also show results on a topic model (latent Dirichlet allocation (LDA) [3]) for text data (for the form of this model, see [3, 55]).", "startOffset": 73, "endOffset": 76}, {"referenceID": 2, "context": "We also show results on a topic model (latent Dirichlet allocation (LDA) [3]) for text data (for the form of this model, see [3, 55]).", "startOffset": 125, "endOffset": 132}, {"referenceID": 54, "context": "We also show results on a topic model (latent Dirichlet allocation (LDA) [3]) for text data (for the form of this model, see [3, 55]).", "startOffset": 125, "endOffset": 132}, {"referenceID": 35, "context": "For mixture models, we generate synthetic data from the above model (n=10,000, d=2, M=9), and for topic models, we use the Simple English Wikipedia\u2217 corpus (n=27,443 documents, vocab=10,192 words) [36], and set M=400 topics.", "startOffset": 197, "endOffset": 201}, {"referenceID": 46, "context": "3 Tuning L2 Regularization (Weight Decay) in Deep Neural Networks Learning neural networks with weight decay (L2 regularization) can be viewed as finding the MAP point estimate of a Bayesian neural network model with a normal prior [47, 33, 17].", "startOffset": 232, "endOffset": 244}, {"referenceID": 32, "context": "3 Tuning L2 Regularization (Weight Decay) in Deep Neural Networks Learning neural networks with weight decay (L2 regularization) can be viewed as finding the MAP point estimate of a Bayesian neural network model with a normal prior [47, 33, 17].", "startOffset": 232, "endOffset": 244}, {"referenceID": 16, "context": "3 Tuning L2 Regularization (Weight Decay) in Deep Neural Networks Learning neural networks with weight decay (L2 regularization) can be viewed as finding the MAP point estimate of a Bayesian neural network model with a normal prior [47, 33, 17].", "startOffset": 232, "endOffset": 244}, {"referenceID": 3, "context": "We will compare this to finding the optimal weight decay via stochastic gradient descent [4] and stochastic gradient Langevin dynamics [59], two popular methods for learning and inference in neural networks.", "startOffset": 89, "endOffset": 92}, {"referenceID": 58, "context": "We will compare this to finding the optimal weight decay via stochastic gradient descent [4] and stochastic gradient Langevin dynamics [59], two popular methods for learning and inference in neural networks.", "startOffset": 135, "endOffset": 139}, {"referenceID": 21, "context": "These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity.", "startOffset": 139, "endOffset": 155}, {"referenceID": 56, "context": "These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity.", "startOffset": 139, "endOffset": 155}, {"referenceID": 43, "context": "These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity.", "startOffset": 139, "endOffset": 155}, {"referenceID": 10, "context": "These stochastic gradient methods have only a weak dependence on data at each iteration; however, their updates may be noisy or suboptimal [22, 57, 44, 11], while prior swapping updates involve exact gradients (of the prior swap function) without any stochasticity.", "startOffset": 139, "endOffset": 155}, {"referenceID": 24, "context": "For data, we use the MNIST\u2020 handwritten digits classification dataset (n=60,000, d=784) [25].", "startOffset": 88, "endOffset": 92}, {"referenceID": 4, "context": "We furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26].", "startOffset": 187, "endOffset": 202}, {"referenceID": 60, "context": "We furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26].", "startOffset": 187, "endOffset": 202}, {"referenceID": 39, "context": "We furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26].", "startOffset": 187, "endOffset": 202}, {"referenceID": 25, "context": "We furthermore hope that prior swapping can be successfully implemented as a black box method, and paired with existing automatic inference engines or probabilistic programming languages [5, 61, 40, 26].", "startOffset": 187, "endOffset": 202}], "year": 2017, "abstractText": "While Bayesian methods are praised for their ability to incorporate useful prior knowledge, in practice, priors that allow for computationally convenient or tractable inference are more commonly used. In this paper, we investigate the following question: for a given model, is it possible to use any convenient prior to infer a false posterior, and afterwards, given some true prior of interest, quickly transform this result into the true posterior? We present a procedure to carry out this task: given an inferred false posterior and true prior, our algorithm generates samples from the true posterior. This transformation procedure, which we call \u201cprior swapping\u201d works for arbitrary priors. Notably, its cost is independent of data size. It therefore allows us, in some cases, to apply significantly less-costly inference procedures to more-sophisticated models than previously possible. It also lets us quickly perform any additional inferences, such as with updated priors or for many different hyperparameter settings, without touching the data. We prove that our method can generate asymptotically exact samples, and demonstrate it empirically on a number of models and priors.", "creator": "LaTeX with hyperref package"}}}