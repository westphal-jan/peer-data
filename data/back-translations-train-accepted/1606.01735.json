{"id": "1606.01735", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Jun-2016", "title": "Integrated perception with recurrent multi-task neural networks", "abstract": "Modern discriminative predictors have been shown to match natural intelligences in specific perceptual tasks in image classification, object and part detection, boundary extraction, etc. However, a major advantage that natural intelligences still have is that they work well for \\emph{all} perceptual problems together, solving them efficiently and coherently in an \\emph{integrated manner}. In order to capture some of these advantages in machine perception, we ask two questions: whether deep neural networks can learn universal image representations, useful not only for a single task but for all of them, and how the solutions to the different tasks can be integrated in this framework. We answer by proposing a new architecture, which we call \\emph{multinet}, in which not only deep image features are shared between tasks, but where tasks can interact in a recurrent manner by encoding the results of their analysis in a common shared representation of the data. In this manner, we show that the performance of individual tasks in standard benchmarks can be improved first by sharing features between them and then, more significantly, by integrating their solutions in the common representation.", "histories": [["v1", "Mon, 6 Jun 2016 13:27:25 GMT  (511kb,D)", "https://arxiv.org/abs/1606.01735v1", "9 pages, 3 figures, 2 tables"], ["v2", "Tue, 29 Nov 2016 14:38:00 GMT  (558kb,D)", "http://arxiv.org/abs/1606.01735v2", "9 pages, 3 figures, 2 tables"]], "COMMENTS": "9 pages, 3 figures, 2 tables", "reviews": [], "SUBJECTS": "stat.ML cs.CV cs.LG", "authors": ["hakan bilen", "andrea vedaldi"], "accepted": true, "id": "1606.01735"}, "pdf": {"name": "1606.01735.pdf", "metadata": {"source": "CRF", "title": "Integrated Perception with Recurrent Multi-Task Neural Networks", "authors": ["Hakan Bilen", "Andrea Vedaldi"], "emails": ["hbilen@robots.ox.ac.uk", "vedaldi@robots.ox.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "1.1 Related work", "text": "Multiple Task Learning (MTL): Multi-task learning [5, 25, 1] methods have been researched by the machine learning community for over two decades, based on the key idea that the tasks share a common low-dimensional representation that is learned along with task-specific parameters. While MLT trains many tasks in parallel, Mitchell and Thrun [18] propose a sequential transfer method called Explanation-Based Neural Nets (EBNN) that uses previously learned domain knowledge to initialize or limit the parameters of the current task. Breiman and Freidman [3] develop a hybrid method that first learns individual models and then improves their generalization by exploiting the correlation between the predictions. Multitask Learning in Computer Vision: MTL has been shown to improve results in many computer vision problems."}, {"heading": "2 Method", "text": "In this section we first present the Multinet architecture for integrated multi-task predictions (Section 2.1) and then discuss ordinary multi-task predictions as a special case of Multinet (Section 2.2)."}, {"heading": "2.1 Multinet: integrated multiple-task prediction", "text": "We propose a recurrent neural network architecture (Figs. 1 and 2) that can address multiple labeling tasks simultaneously. (For symmetry, however, we drop the usual distinction between input and output spaces and look at insteadK markup spacesX\u03b1 = 0, 1,., K. A label in alpha-th space is defined by the symbol x\u03b1, X\u03b1 and parts of the task. One reason why it is useful to keep the notation symmetrical is that it is possible to capture any label x\u03b1 and input it instead.Each task is associated with a corresponding encoder function."}, {"heading": "2.2 Ordinary multi-task learning", "text": "Normally, multitask learning [5, 25, 1] is based on the exchange of attributes or parameters between different tasks. Multinet reduces itself to ordinary multi-task learning when there is no repetition.With the first iteration t = 0, Multinet simply evaluates K predictor functions. While multi-task learning is conceptually simple, it is practically important because it allows learning a universal representation function throu0enc that works well for all tasks at the same time. The possibility of learning such a polyvalent representation, which can only be verified empirically, is a non-trivial and useful fact. Especially in our image understanding experiments (Section 4) we will see that learning such a common representation is not only possible and efficient for certain image analysis tasks, but that in some cases even the performance of the individual function can be improved."}, {"heading": "3 A multinet for classification, localization, and part detection", "text": "The main advantage of Multinet over traditional multi-task predictions is that the detected parts are contained within a detected object. Instead, Multinet can capture interactions between different labels and potentially learn to enforce such constraints, the latter done in a soft and distributed manner by integrating the output of each task into the common representation. Next, we will discuss in detail the specific architectural components used in our application. As a starting point, we will consider a standard CNN for image classification. While more powerful networks exist, we will choose a well-functioning model that is reasonably efficient at the same time, namely the VGG-10M network components."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Implementation details and training", "text": "In fact, it is such that the number of the feature channels in comparison to the predecessors in the field of definition of definition of definition and definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition and definition of definition of definition of definition of definition of definition of definition of definition of definition of definition and definition of definition of definition of definition of definition of definition of definition of definition and definition of definition of definition of definition of definition of definition and definition of definition of definition of definition of definition of definition of definition and definition of definition of definition of definition of definition of definition and definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition of definition and definition of definition of definition of definition of definition of definition of"}, {"heading": "4.2 Results", "text": "This year, it has reached the stage where it will be able to take the lead, in the same way as it has done in the past."}, {"heading": "5 Conclusions", "text": "In this paper, we presented multinet, a recurring neural network architecture for efficient and coordinated solution of multiple perceptual tasks. In addition to sharing features and parameters common to most multi-task learning methods, multinet combines the results of the different tasks by iteratively updating a common representation. Our results are encouraging. First, we have shown that such architectures can successfully integrate multiple tasks by sharing a large portion of the data representation, comparing or even surpassing specialized networks. Second, we have shown that iterative updating of a common representation is an effective method for sharing information between different tasks that further improves performance."}, {"heading": "Acknowledgments", "text": "This work acknowledges the support of the ERC Starting Grant Integrated and Detailed Image Understanding (EP / L024683 / 1)."}], "references": [{"title": "A model of inductive bias learning", "author": ["J. Baxter"], "venue": "J. Artif. Intell. Res.(JAIR), 12(149-198):3", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2000}, {"title": "Recurrent human pose estimation", "author": ["V. Belagiannis", "A. Zisserman"], "venue": "arXiv preprint arXiv:1605.02914", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2016}, {"title": "Predicting multivariate responses in multiple linear regression", "author": ["L. Breiman", "J.H. Friedman"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology), 59(1):3\u201354", "citeRegEx": "3", "shortCiteRegEx": null, "year": 1997}, {"title": "Human pose estimation with iterative error feedback", "author": ["J. Carreira", "P. Agrawal", "K. Fragkiadaki", "J. Malik"], "venue": "CVPR", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2016}, {"title": "Multitask learning", "author": ["R. Caruana"], "venue": "Machine Learning, 28(1)", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1997}, {"title": "Return of the devil in the details: Delving deep into convolutional nets", "author": ["K. Chatfield", "K. Simonyan", "A. Vedaldi", "A. Zisserman"], "venue": "BMVC", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Detect what you can: Detecting and representing objects using holistic models and body parts", "author": ["X. Chen", "R. Mottaghi", "X. Liu", "S. Fidler", "R. Urtasun", "A.L. Yuille"], "venue": "CVPR, pages 1971\u20131978", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Instance-aware semantic segmentation via multi-task network cascades", "author": ["J. Dai", "K. He", "J. Sun"], "venue": "CVPR", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2016}, {"title": "Decaf: A deep convolutional activation feature for generic visual recognition", "author": ["J. Donahue", "Y. Jia", "O. Vinyals", "J. Hoffman", "N. Zhang", "E. Tzeng", "T. Darrell"], "venue": "CoRR, abs/1310.1531", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2013}, {"title": "The PASCAL Visual Object Classes (VOC) challenge", "author": ["M. Everingham", "L. Van Gool", "C.K.I. Williams", "J. Winn", "A. Zisserman"], "venue": "IJCV, 88(2):303\u2013338", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2010}, {"title": "Fast r-cnn", "author": ["R. Girshick"], "venue": "ICCV", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2015}, {"title": "A novel connectionist system for unconstrained handwriting recognition", "author": ["A. Graves", "M. Liwicki", "S. Fern\u00e1ndez", "R. Bertolami", "H. Bunke", "J. Schmidhuber"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 31(5):855\u2013868", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2009}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A. Mohamed", "G. Hinton"], "venue": "ICASSP, pages 6645\u20136649. IEEE", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2013}, {"title": "Spatial pyramid pooling in deep convolutional networks for visual recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "ECCV, pages 346\u2013361", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2014}, {"title": "Reducing the dimensionality of data with neural networks", "author": ["G.E. Hinton", "R.R. Salakhutdinov"], "venue": "Science, 313(5786):504\u2013507", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2006}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation, 9(8):1735\u2013 1780", "citeRegEx": "16", "shortCiteRegEx": null, "year": 1997}, {"title": "Statistical Language Models Based on Neural Networks", "author": ["T. Mikolov"], "venue": "PhD thesis, Ph. D. thesis, Brno University of Technology", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2012}, {"title": "Explanation-based neural network learning for robot control", "author": ["T.M. Mitchell", "S.B. Thrun"], "venue": "NIPS, pages 287\u2013287", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1993}, {"title": "G-cnn: an iterative grid based object detector", "author": ["M. Najibi", "M. Rastegari", "L.S. Davis"], "venue": "CVPR", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Recurrent convolutional neural networks for scene parsing", "author": ["P.H.O. Pinheiro", "R. Collobert"], "venue": "arXiv preprint arXiv:1306.2795", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2013}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M.A. Ranzato", "F.J. Huang", "Y. Boureau", "Y. LeCun"], "venue": "CVPR, pages 1\u20138", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2007}, {"title": "Learning representations by back-propagating errors", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": "Cognitive modeling, 5(3):1", "citeRegEx": "22", "shortCiteRegEx": null, "year": 1988}, {"title": "Imagenet large scale visual recognition challenge", "author": ["O. Russakovsky", "J. Deng", "H. Su", "J. Krause", "S. Satheesh", "S. Ma", "S. Huang", "A. Karpathy", "A. Khosla", "M. Bernstein", "A.C. Berg", "F.F. Li"], "venue": "IJCV", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "NIPS, pages 3104\u20133112", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "editors", "author": ["S. Thrun", "L. Pratt"], "venue": "Learning to Learn. Kluwer Academic Publishers", "citeRegEx": "25", "shortCiteRegEx": null, "year": 1998}, {"title": "Segmentation as selective search for object recognition", "author": ["K. van de Sande", "J. Uijlings", "T. Gevers", "A. Smeulders"], "venue": "In ICCV,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2011}, {"title": "Matconvnet \u2013 convolutional neural networks for matlab", "author": ["A. Vedaldi", "K. Lenc"], "venue": "Proceeding of the ACM Int. Conf. on Multimedia", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["P. Vincent", "H. Larochelle", "Y. Bengio", "P.A. Manzagol"], "venue": "ICML, pages 1096\u20131103. ACM", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2008}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "CoRR, abs/1311.2901", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}, {"title": "Robust visual tracking via structured multi-task sparse learning", "author": ["T. Zhang", "B. Ghanem", "S. Liu", "N. Ahuja"], "venue": "IJCV, 101(2):367\u2013383", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2013}, {"title": "Facial landmark detection by deep multi-task learning", "author": ["Z. Zhang", "P. Luo", "C.C. Loy", "X. Tang"], "venue": "ECCV, pages 94\u2013108. Springer", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2014}], "referenceMentions": [{"referenceID": 8, "context": "In computer vision, fine-tuning or retraining has been show to be an effective method to transfer deep convolutional networks between different tasks [9, 29].", "startOffset": 150, "endOffset": 157}, {"referenceID": 28, "context": "In computer vision, fine-tuning or retraining has been show to be an effective method to transfer deep convolutional networks between different tasks [9, 29].", "startOffset": 150, "endOffset": 157}, {"referenceID": 4, "context": "Multiple task learning (MTL): Multitask learning [5, 25, 1] methods have been studied over two decades by the machine learning community.", "startOffset": 49, "endOffset": 59}, {"referenceID": 24, "context": "Multiple task learning (MTL): Multitask learning [5, 25, 1] methods have been studied over two decades by the machine learning community.", "startOffset": 49, "endOffset": 59}, {"referenceID": 0, "context": "Multiple task learning (MTL): Multitask learning [5, 25, 1] methods have been studied over two decades by the machine learning community.", "startOffset": 49, "endOffset": 59}, {"referenceID": 17, "context": "While MLT trains many tasks in parallel, Mitchell and Thrun [18] propose a sequential transfer method called Explanation-Based Neural Nets (EBNN) which exploits previously learnt domain knowledge to initialise or constraint the parameters of the current task.", "startOffset": 60, "endOffset": 64}, {"referenceID": 2, "context": "Breiman and Freidman [3] devise a hybrid method that first learns separate models and then improves their generalisation by exploiting the correlation between the predictions.", "startOffset": 21, "endOffset": 24}, {"referenceID": 29, "context": "Typically, researchers incorporate auxiliary tasks into their target tasks, jointly train them in parallel and achieve performance gains in object tracking [30], object detection [11], facial landmark detection [31].", "startOffset": 156, "endOffset": 160}, {"referenceID": 10, "context": "Typically, researchers incorporate auxiliary tasks into their target tasks, jointly train them in parallel and achieve performance gains in object tracking [30], object detection [11], facial landmark detection [31].", "startOffset": 179, "endOffset": 183}, {"referenceID": 30, "context": "Typically, researchers incorporate auxiliary tasks into their target tasks, jointly train them in parallel and achieve performance gains in object tracking [30], object detection [11], facial landmark detection [31].", "startOffset": 211, "endOffset": 215}, {"referenceID": 7, "context": "[8] propose multi-task network cascades in which convolutional layer parameters are shared between three tasks and the tasks are predicted sequentially.", "startOffset": 0, "endOffset": 3}, {"referenceID": 7, "context": "Unlike [8], our method can train multiple tasks in parallel and does not require a specification of task execution.", "startOffset": 7, "endOffset": 10}, {"referenceID": 21, "context": "Recurrent networks: Our work is also related to recurrent neural networks (RNN) [22] which has been successfully used in language modelling [17], speech recognition [13], hand-written recognition [12], semantic image segmentation [20] and human pose estimation [2].", "startOffset": 80, "endOffset": 84}, {"referenceID": 16, "context": "Recurrent networks: Our work is also related to recurrent neural networks (RNN) [22] which has been successfully used in language modelling [17], speech recognition [13], hand-written recognition [12], semantic image segmentation [20] and human pose estimation [2].", "startOffset": 140, "endOffset": 144}, {"referenceID": 12, "context": "Recurrent networks: Our work is also related to recurrent neural networks (RNN) [22] which has been successfully used in language modelling [17], speech recognition [13], hand-written recognition [12], semantic image segmentation [20] and human pose estimation [2].", "startOffset": 165, "endOffset": 169}, {"referenceID": 11, "context": "Recurrent networks: Our work is also related to recurrent neural networks (RNN) [22] which has been successfully used in language modelling [17], speech recognition [13], hand-written recognition [12], semantic image segmentation [20] and human pose estimation [2].", "startOffset": 196, "endOffset": 200}, {"referenceID": 19, "context": "Recurrent networks: Our work is also related to recurrent neural networks (RNN) [22] which has been successfully used in language modelling [17], speech recognition [13], hand-written recognition [12], semantic image segmentation [20] and human pose estimation [2].", "startOffset": 230, "endOffset": 234}, {"referenceID": 1, "context": "Recurrent networks: Our work is also related to recurrent neural networks (RNN) [22] which has been successfully used in language modelling [17], speech recognition [13], hand-written recognition [12], semantic image segmentation [20] and human pose estimation [2].", "startOffset": 261, "endOffset": 264}, {"referenceID": 3, "context": "[4] propose an iterative segmentation model that progressively updates an initial", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[19] propose an efficient grid based object detector that iteratively refine the predicted object coordinates by minimising the training error.", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "While these methods [4, 19] are also based on an iterative solution correcting mechanism, our main goal is to improve generalisation performance for multiple tasks by sharing the previous predictions across them and learning output correlations.", "startOffset": 20, "endOffset": 27}, {"referenceID": 18, "context": "While these methods [4, 19] are also based on an iterative solution correcting mechanism, our main goal is to improve generalisation performance for multiple tasks by sharing the previous predictions across them and learning output correlations.", "startOffset": 20, "endOffset": 27}, {"referenceID": 15, "context": "The idea of feeding back the network output for further processing exists in several existing recurrent architectures [16, 24]; however, in these cases it is used to process sequential data, passing back the output obtained from the last process element in the sequence; here, instead, the feedback is used to integrate different and complementary labelling tasks.", "startOffset": 118, "endOffset": 126}, {"referenceID": 23, "context": "The idea of feeding back the network output for further processing exists in several existing recurrent architectures [16, 24]; however, in these cases it is used to process sequential data, passing back the output obtained from the last process element in the sequence; here, instead, the feedback is used to integrate different and complementary labelling tasks.", "startOffset": 118, "endOffset": 126}, {"referenceID": 14, "context": "Our model is also reminiscent of encoder/decoder architectures [15, 21, 28]; however, in our case the encoder and decoder functions are associated to the output labels rather than to the input data.", "startOffset": 63, "endOffset": 75}, {"referenceID": 20, "context": "Our model is also reminiscent of encoder/decoder architectures [15, 21, 28]; however, in our case the encoder and decoder functions are associated to the output labels rather than to the input data.", "startOffset": 63, "endOffset": 75}, {"referenceID": 27, "context": "Our model is also reminiscent of encoder/decoder architectures [15, 21, 28]; however, in our case the encoder and decoder functions are associated to the output labels rather than to the input data.", "startOffset": 63, "endOffset": 75}, {"referenceID": 4, "context": "Ordinarily, multiple-task learning [5, 25, 1] is based on sharing features or parameters between different tasks.", "startOffset": 35, "endOffset": 45}, {"referenceID": 24, "context": "Ordinarily, multiple-task learning [5, 25, 1] is based on sharing features or parameters between different tasks.", "startOffset": 35, "endOffset": 45}, {"referenceID": 0, "context": "Ordinarily, multiple-task learning [5, 25, 1] is based on sharing features or parameters between different tasks.", "startOffset": 35, "endOffset": 45}, {"referenceID": 4, "context": "The main advantage of multinet compared to ordinary multi-task prediction is that, while sharing parameters across related tasks may improve generalization [5], it is not enough to capture correlations in the task input spaces.", "startOffset": 156, "endOffset": 159}, {"referenceID": 5, "context": "While more powerful networks exist, we choose here a good performing model which is at the same time reasonably efficient to train and evaluate, namely the VGG-M-1024 network of [6].", "startOffset": 178, "endOffset": 181}, {"referenceID": 22, "context": "This model is pre-trained for image classification from the ImageNet ILSVRC 2012 data [23] and was extended in [11] to object detection; here we follow such blueprints, and in particular the Fast R-CNN method of [11], to design the subnetworks for the three tasks.", "startOffset": 86, "endOffset": 90}, {"referenceID": 10, "context": "This model is pre-trained for image classification from the ImageNet ILSVRC 2012 data [23] and was extended in [11] to object detection; here we follow such blueprints, and in particular the Fast R-CNN method of [11], to design the subnetworks for the three tasks.", "startOffset": 111, "endOffset": 115}, {"referenceID": 10, "context": "This model is pre-trained for image classification from the ImageNet ILSVRC 2012 data [23] and was extended in [11] to object detection; here we follow such blueprints, and in particular the Fast R-CNN method of [11], to design the subnetworks for the three tasks.", "startOffset": 212, "endOffset": 216}, {"referenceID": 10, "context": "The object and part detection decoders are instead based on the Fast R-CNN architecture [11], and classify individual image regions as belonging to one of the object classes (part types) or background.", "startOffset": 88, "endOffset": 92}, {"referenceID": 25, "context": "To do so, the Selective Search Windows (SSW) method [26] is used to generate a shortlist of M region (bounding box) proposals B(ximg) = {b1, .", "startOffset": 52, "endOffset": 56}, {"referenceID": 13, "context": ",bM} from image ximg; this set is inputted to the spatial pyramid pooling (SPP) layer [14, 11] \u03c8SPP dec (h,B(ximg)), which extracts subsets of the feature map h in correspondence of each region using max pooling.", "startOffset": 86, "endOffset": 94}, {"referenceID": 10, "context": ",bM} from image ximg; this set is inputted to the spatial pyramid pooling (SPP) layer [14, 11] \u03c8SPP dec (h,B(ximg)), which extracts subsets of the feature map h in correspondence of each region using max pooling.", "startOffset": 86, "endOffset": 94}, {"referenceID": 13, "context": "Max pooling in SPP is performed in a grid of 6\u00d7 6 spatial bins as in [14, 11].", "startOffset": 69, "endOffset": 77}, {"referenceID": 10, "context": "Max pooling in SPP is performed in a grid of 6\u00d7 6 spatial bins as in [14, 11].", "startOffset": 69, "endOffset": 77}, {"referenceID": 10, "context": "Furthermore, we also train a branch performing bounding box refinement to improve the fit of the selective search region as proposed by [11].", "startOffset": 136, "endOffset": 140}, {"referenceID": 26, "context": "We use the publicly available CNN toolbox MatConvNet [27] in our experiments.", "startOffset": 53, "endOffset": 57}, {"referenceID": 9, "context": "PASCAL VOC 2010 [10] and Parts [7]: The dataset contains 4998 training and 5105 validation images for 20 object categories and ground truth bounding box annotations for target categories.", "startOffset": 16, "endOffset": 20}, {"referenceID": 6, "context": "PASCAL VOC 2010 [10] and Parts [7]: The dataset contains 4998 training and 5105 validation images for 20 object categories and ground truth bounding box annotations for target categories.", "startOffset": 31, "endOffset": 34}, {"referenceID": 6, "context": "We use the PASCAL-Part dataset [7] to obtain bounding box annotations of object parts which consists of 193 annotated part categories such as aeroplane engine, bicycle back-wheel, bird left-wing, person right-upper-leg.", "startOffset": 31, "endOffset": 34}, {"referenceID": 6, "context": "For the part detection, we follow [7] and report AP at a more relaxed 40% IoU threshold.", "startOffset": 34, "endOffset": 37}, {"referenceID": 10, "context": "For object and part detection, we use our implementation of Fast-RCNN [11].", "startOffset": 70, "endOffset": 74}, {"referenceID": 9, "context": "PASCAL VOC 2007 [10]: The dataset consists of 2501 training, 2510 validation, and 5011 test images containing bounding box annotations for 20 object categories.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "in [11].", "startOffset": 3, "endOffset": 7}], "year": 2016, "abstractText": "Modern discriminative predictors have been shown to match natural intelligences in specific perceptual tasks in image classification, object and part detection, boundary extraction, etc. However, a major advantage that natural intelligences still have is that they work well for all perceptual problems together, solving them efficiently and coherently in an integrated manner. In order to capture some of these advantages in machine perception, we ask two questions: whether deep neural networks can learn universal image representations, useful not only for a single task but for all of them, and how the solutions to the different tasks can be integrated in this framework. We answer by proposing a new architecture, which we call multinet, in which not only deep image features are shared between tasks, but where tasks can interact in a recurrent manner by encoding the results of their analysis in a common shared representation of the data. In this manner, we show that the performance of individual tasks in standard benchmarks can be improved first by sharing features between them and then, more significantly, by integrating their solutions in the common representation.", "creator": "LaTeX with hyperref package"}}}