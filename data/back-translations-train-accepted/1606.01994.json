{"id": "1606.01994", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2016", "title": "CFO: Conditional Focused Neural Question Answering with Large-scale Knowledge Bases", "abstract": "How can we enable computers to automatically answer questions like \"Who created the character Harry Potter\"? Carefully built knowledge bases provide rich sources of facts. However, it remains a challenge to answer factoid questions raised in natural language due to numerous expressions of one question. In particular, we focus on the most common questions --- ones that can be answered with a single fact in the knowledge base. We propose CFO, a Conditional Focused neural-network-based approach to answering factoid questions with knowledge bases. Our approach first zooms in a question to find more probable candidate subject mentions, and infers the final answers with a unified conditional probabilistic framework. Powered by deep recurrent neural networks and neural embeddings, our proposed CFO achieves an accuracy of 75.7% on a dataset of 108k questions - the largest public one to date. It outperforms the current state of the art by an absolute margin of 11.8%.", "histories": [["v1", "Tue, 7 Jun 2016 01:36:07 GMT  (67kb,D)", "http://arxiv.org/abs/1606.01994v1", "Accepted into ACL2015"], ["v2", "Mon, 4 Jul 2016 03:04:38 GMT  (67kb,D)", "http://arxiv.org/abs/1606.01994v2", "Accepted by ACL 2016"]], "COMMENTS": "Accepted into ACL2015", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zihang dai", "lei li", "wei xu"], "accepted": true, "id": "1606.01994"}, "pdf": {"name": "1606.01994.pdf", "metadata": {"source": "CRF", "title": "CFO: Conditional Focused Neural Question Answering with Large-scale Knowledge Bases", "authors": ["Zihang Dai", "Lei Li", "Wei Xu"], "emails": ["dzihang@andrew.cmu.edu", "lileicc@gmail.com", "xuwei06@baidu.com"], "sections": [{"heading": "1 Introduction", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2 Related Work", "text": "KB-supported QA research has evolved from earlier domain-specific QA (Zelle and Mooney, 1996; Tang and Mooney, 2001; Liang et al., 2013) to open-domain QA based on large-format KBs. However, an important line of research attempts to address the problem through semantic parsing that directly incorporates natural language questions into structured queries (Liang et al., 2013; Cai et al., 2013; Kwiatkowski et al., 2014; Yao and Van Durme, 2014). Recent advances include designing a specific logical representation and analysis of grammar (Berant et al., 2013) using remote supervision (Berant et al., 2013), exploiting paraphraseal information (Fader Fader et al., 2013; Berant and Liang, 2014) that requires little questioning (Reddy et al., 2014), and exploring ideas based on agenda."}, {"heading": "3 Overview", "text": "In this section, we formally formulate the problem of answering individual questions with knowledge bases. A knowledge base K contains three components: a set of units E, a set of relations R, and a set of facts F = {< s, r, o >} E \u00b7 R \u00b7 E, where s, o \u00b2 E are the subject and object entities, and r \u00b2 R is a binary relationship. E (r), E (s) are the vector representations of a relationship and a unit, or an entity. S \u00b2 r indicates that there is an entity o such that < s, r, o > F. For individual fact questions, a common assumption is that the answer o and some threefold < si, rk, o > E > F lie in the given knowledge base. The goal of our model is to find such a subject si and such a relationship rk that is mentioned or implied in the question."}, {"heading": "3.1 Conditional Factoid Factorization", "text": "Faced with a question q, the common conditional probability of the subject-relation pairs p (s, r | q) can be used to retrieve the answer based on the exact conclusion of Equation (1). However, since there can be millions of entities and thousands of relationships in a knowledge base, it is less effective to directly model p (s, r | q). Instead, we propose a conditional factoid factorization, p (s, r | q) = p (r | q) \u00b7 p (s | q, r) (2) and use two neural networks to parameterize each component, p (r | q) and p (s | q, r) respectively. Therefore, our proposed method contains two phases: to derive the implicit relationship r from the question q, and the mentioned subject unit s from the relation r and the question q.There is an alternative factorization model p (s, r | q) p (s,.q), but an asik relative to the number proposed."}, {"heading": "3.2 Inference via Focused Pruning", "text": "As defined in Equation (1), a solution must take into account all available q relationship pairs in the KB as candidates. In a large KB, the number of candidates can be notoriously large, resulting in an extremely noisy candidate pool. We propose a method to circumcise the candidate space. Circumcision corresponds to a function that uses a KB K and a question q as input, producing a much limited number of C pairings between candidates. H (K, q) \u2192 C (3) Cs and Cr are used to represent the subject and the relationship candidates accordingly. The basic intuition for circumcision is that the subject must be mentioned in the question by a textual substring (mention). Thus, the candidate space can be limited to units whose name / alias matches an n-gram of the question, as in (Yih et al., 2014; Yih et al., 2015)."}, {"heading": "4 Proposed CFO", "text": "In this section, we will first consider the gated recurrent unit (GRU), an RNN variant widely used in this work, and then describe the model parameterization of p (r | q) and p (s | q, r), as well as the focused intersection method as a conclusion."}, {"heading": "4.1 Review: Gated Recurrent Units", "text": "In this thesis we use GRU (Cho et al., 2014) as an RNN structure. In the time step t, a GRU calculates its hidden state ht using the following connection functions: z = sigmoid (Wxzxt + Whzht \u2212 1 + bz) (5) r = sigmoid (Wxrxt + Whrht \u2212 1 + br) (6) h = tanh (Wxhxt + r'Whhht \u2212 1 + bh) (7) ht = z'ht \u2212 1 + (1 \u2212 z) h (8), where W {\u00b7} and b {\u00b7} are feasible parameters. To better understand the context information on both sides, two GRUs with opposite directions can be combined to form a bi-directional GRU (BiGRU)."}, {"heading": "4.2 Model Parameterization", "text": "In this paper, the probability of the relationships given to a question, p (r | q), is modeled by the following network psychiatrist (r | q). However, since the relationship scoring function v (r, q) measures (r, q) the similarity between the question and the relationships (r, q), the type of embedding and the type of embedding. Specifically, the question q is presented as a sequence of tokens (potentially with unknowns). Then, the question embedding model f consists of a word-embedding layer to transform tokens into distributed representations, a two-layer BiGRU to project the question of the final states of the GRU network into space."}, {"heading": "4.3 Focused Pruning", "text": "As discussed in Section 3.2, N-gram circumcision is still subject to a large amount of q labeling due to many non-subjectively mentioned n-grams. Motivated by this problem, we propose to reduce this noise by focusing on more likely candidates using a special sequence labeling network. Basically, a sequence labeling model is trained to label some consecutive characters as mentioning the subject. Formally, let W (q) keep all n-grams of the question q, p (w | q) the probability that the n-gram w is the subject label to generate the candidate pool. Therefore, we refer to this method as focused circumcision. Formally, let W (q) leave all n-grams of the question q, p (w | q) the probability that the n-gram w is the subject label of q used as mentioning the subject."}, {"heading": "5 Parameter Estimation", "text": "In this section we discuss the parameter estimation for the neural models presented in Section 4.Using standard parameterization, the focused label model p\u0442 (w | q) can be trained directly by Maximum Probability Estimation (MLE) and Reverse Propagation. Therefore, we omit the discussion here and refer readers to (Huang et al., 2015) for details. Also, the problem of obtaining the training data is left to Section 6."}, {"heading": "5.1 Decomposable Log-Likelihood", "text": "To estimate the parameters of p\u03b8r (r | q) and p\u03b8s (s | r, q), MLE can be used to maximize the empirical (log-) probability of subject-relation pairings1 The approximate match is only used if there is no strict match. The proposed API takes a string as input and returns no more than 20 potentially matching entities. Following this idea, let {s (i), r (i), q (i)} Ni = 1 be the training data set, the MLE solution takes the formal MLE = arg max \u03b8r, \u03b8s N \u2211 i = 1 (log p\u03b8r (r (i)) | q (i)} Ni = 1 be the training data set, (15) Note that there are no common parameters between p\u03b8s (s | q, r) and p\u03b8r (etq)."}, {"heading": "5.2 Approximation with Negative Samples", "text": "Since the two problems defined by Equation (16) take the standard form of classification, theoretically q q entropy can be used as a training target. However, the calculation of the partition function is often difficult, especially for p\u03b8s (s | r, q), since there can be millions of entropy q in KB. Confronted with this problem, classical solutions include contrastive estimation (Smith and Eisner, 2005), meaning capture of approximation (Bengio et al., 2003) and hinge loss in negative samples (Collobert and Weston, 2008). In this paper, we use the hinge loss with negative samples as a training target. Specifically, the loss function w.r.t has dependence on \u2212 r the FormL (\u03b8r) = N = 1 Mr. Planj = 1 max [0, r \u2212 v (i), q (i), the plasticity (r (j), q (i))]] (17), where r (j) is one of the negative samples."}, {"heading": "6 Experiments", "text": "In this section we conduct experiments to evaluate the proposed system empirically."}, {"heading": "6.1 Dataset and Knowledge Base", "text": "We train and evaluate our method based on the SIMPLEQUESTIONS dataset 3 - the largest question / triple dataset. It consists of 108,442 questions written by human commentators in English. Each question is paired with a subject relation object triple dataset 3 from the freebase. We follow the same splitting for training (70%), validation (10%) and testing (20%) as (Bordes et al., 2015). We use the same subset of the freebase (FB5M) as the knowledge base so that the results are directly comparable. It includes 4,904,397 units, 7,523 relationships and 22,441,880 facts. Alternative datasets are available, such as WebQuestions (Berant et al., 2013) and3https: / research.facebook.com / Researchers / 154393453918934817 (Cai Yates, 2013)."}, {"heading": "6.2 Evaluation and Baselines", "text": "For evaluation, we consider the same metric introduced in (Bordes et al., 2015), which takes the prediction as correct if both the subject and the relationship are retrieved correctly. Based on this metric, we compare CFO with a few base systems that include both the Memory Network QA system (Bordes et al., 2015), and systems with alternative components and parameters from the existing work (Yih et al., 2014; Yih et al., 2015). We have not compared with alternative subject networks, because the only existing method (Yih et al., 2014) relies on unique textual names of each unit, the exploitation of which is usually not held in knowledge bases (except in REVERB). Alternative approaches to pruning method, relationship network and entity representation are described below. Pruning methods We consider two baseline methods that were previously used to cut the search space, the first baseline is N."}, {"heading": "6.3 Experiment Setting", "text": "During the training, all word embedding is initialized with the prefabricated GloVe (Pennington et al., 2014) and then refined in the subsequent training; the dimension of word embedding is set to 300, and the hidden BiGRU size 256. For pre-training of unit embedding using TransE (see Section 4.2), only the triples contained in FB5M are used; all other parameters are randomly initialized uniformly from [\u2212 0.08, 0.08] subsequently (Graves, 2013); both hinge losses are set to 0.1. Negative sampling sizes for Ms and Mr are both 1024. For optimization, the parameters are trained with momentum using mini-batch AdaGrad (Duchi et al., 2011) (Pham et al., 2015). The learning rates are 4In Freebase, each predefined relationship has a single humanly recognizable reference form, usually a sequence of words."}, {"heading": "6.4 Results", "text": "Table 1 shows the accuracy of these methods. We evaluated all combinations of circumcision methods, relation networks and entity representation schemes, as well as the result from the storage network as described in Section 6.1. CFO (focused cropping + BiGRU + type vector) achieves the best performance and outperforms all other methods by significant margins. By examining vertically within each cell in Table 1 according to the same circumcision methods and entity representation schemes, the BiGRU-based relationship evaluation network increases accuracy by 3.5% to 4.8% compared to the second best alternative. This evidence suggests the superiority of RNN in capturing the semantics of questionnaires. Surprisingly, Embed-AVG turns out to perform better than the more complex Lfo-CNN."}, {"heading": "6.5 Effectiveness of Pruning", "text": "According to the results in Section 6.4, the focused cut plays a crucial role in achieving the best performance. To get a deeper understanding of its effectiveness, we analyze how the cutting methods affect the accuracy of the system. Due to the space limitation, we focus on systems with BiGRU as a relation correction function and the type vector as a unit. Table 2 summarizes the callback - the percentage of truncated candidates that contain the answer - and the resulting accuracy. On a case-by-case basis, the scenario refers to the scenario that there is only one candidate unit in Cs (possibly with multiple relationships), and the multiple case means that there are multiple units in Cs. As the table shows, focused cut achieves a comparable recall rate with N-gram cut. 6 Given the state-of-the-art performance of sequence identification systems, this result should not come as a surprise."}, {"heading": "6.6 Additional Analysis", "text": "To further understand the meaning and sensitivity of this specific model design, we are examining some variants of these two models. However, the alternative focus with CRF RNN-CRF-based models is relatively straightforward in the sense that there are only two categories of labels - a subset of the subject designation (SUB) or not (O). Therefore, it is worth investigating whether RNN (BiGRU in our case) is still a critical component when the task becomes simple. Therefore, we are establishing a CRF baseline that uses traditional features as input."}, {"heading": "7 Conclusion", "text": "In this paper, we propose CFO, a novel approach to answering individual questions. We use conditional factoid factorization by deriving first the target relationship and then the target object associated with the candidate relationship. To solve representation for millions of companies, we proposed a type vector scheme that does not require training. Our focused cut reduces candidate space largely without loss of recall rate, resulting in a significant improvement in overall accuracy. Compared with multiple baselines across three aspects, our method achieves the state-of-the-art accuracy of a 108k question dataset, the largest publicly available dataset. Future work could expand the proposed method to address more complex questions."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "How can we enable computers to automat-<lb>ically answer questions like \u201cWho created<lb>the character Harry Potter\u201d? Carefully<lb>built knowledge bases provide rich sources<lb>of facts. However, it remains a chal-<lb>lenge to answer factoid questions raised<lb>in natural language due to numerous ex-<lb>pressions of one question. In particular,<lb>we focus on the most common questions<lb>\u2014 ones that can be answered with a sin-<lb>gle fact in the knowledge base. We pro-<lb>pose CFO, a Conditional Focused neural-<lb>network-based approach to answering fac-<lb>toid questions with knowledge bases. Our<lb>approach first zooms in a question to<lb>find more probable candidate subject men-<lb>tions, and infers the final answers with<lb>a unified conditional probabilistic frame-<lb>work. Powered by deep recurrent neural<lb>networks and neural embeddings, our pro-<lb>posed CFO achieves an accuracy of 75.7%<lb>on a dataset of 108k questions \u2013 the largest<lb>public one to date. It outperforms the cur-<lb>rent state of the art by an absolute margin<lb>of 11.8%.", "creator": "LaTeX with hyperref package"}}}