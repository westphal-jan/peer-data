{"id": "1606.02275", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Jun-2016", "title": "Measuring the reliability of MCMC inference with bidirectional Monte Carlo", "abstract": "Markov chain Monte Carlo (MCMC) is one of the main workhorses of probabilistic inference, but it is notoriously hard to measure the quality of approximate posterior samples. This challenge is particularly salient in black box inference methods, which can hide details and obscure inference failures. In this work, we extend the recently introduced bidirectional Monte Carlo technique to evaluate MCMC-based posterior inference algorithms. By running annealed importance sampling (AIS) chains both from prior to posterior and vice versa on simulated data, we upper bound in expectation the symmetrized KL divergence between the true posterior distribution and the distribution of approximate samples. We present Bounding Divergences with REverse Annealing (BREAD), a protocol for validating the relevance of simulated data experiments to real datasets, and integrate it into two probabilistic programming languages: WebPPL and Stan. As an example of how BREAD can be used to guide the design of inference algorithms, we apply it to study the effectiveness of different model representations in both WebPPL and Stan.", "histories": [["v1", "Tue, 7 Jun 2016 19:39:02 GMT  (380kb,D)", "http://arxiv.org/abs/1606.02275v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.CO stat.ML", "authors": ["roger b grosse", "siddharth ancha", "daniel m roy"], "accepted": true, "id": "1606.02275"}, "pdf": {"name": "1606.02275.pdf", "metadata": {"source": "CRF", "title": "Measuring the reliability of MCMC inference with bidirectional Monte Carlo", "authors": ["Roger B. Grosse", "Siddharth Ancha", "Daniel M. Roy"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "It is one of the most important classes of probable conclusions that are often overcome and underlie a variety of approaches to automatic inference [e.g. LTBS00; GMRB + 08; GS; CGHL + p]. Despite their widespread use, it is still difficult to verify the effectiveness of an MCMC inference algorithm. There are various approaches to diagnosing convergence (see Section 4), but reliable quantitative measures are hard to find, which creates difficulties for both end users of automatic inference systems and experienced researchers developing models and algorithms. First, we look at the perspective of the end user of an MCMC-based automatic inference system. The user would like to know whether the safe samples are a good representation of the posterior distribution. They wish to configure various algorithmic parameters (e.g. the number of steps for which the algorithm is executed) or to choose a problem representation."}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 WebPPL and Stan", "text": "We will focus on two specific probabilistic programming packages. First, we will look at WebPPL [GS], a lightweight probabilistic programming language based on JavaScript and largely intended to illustrate some of the important ideas in probabilistic programming. The conclusion is based on Metropolis-Hastings (M-H) updates of the execution track of a program, i.e. a record of all the stochastic decisions of the program. WebPPL has a small and clean implementation, and the entire implementation is described in an online tutorial on probabilistic programming [GS]. Second, we will look at Stan [CGHL + p], a sophisticated automatic inference system widely used by statisticians and intended to be applied to major problems. Stan is based on the No U-Turn Sampler (NUTS; [HG14]), a variant of the Hamiltonian Monte Carlo (MC), but can be adaptive to H11, HLength-capable at the same time."}, {"heading": "2.2 Annealed Importance Sampling", "text": "The final distribution in the sequence, pT, is called the target distribution; the first distribution, p1, is called the output distribution. It is necessary to obtain one or more exact samples from p1.1. Faced with a sequence of reversible MCMC transition operators T1, TT, where Tt leaves the target distribution, AIS produces a (non-negative) unbiased estimate of the ZT / Z1, as follows: first sample of a random output state x1 from p1 = 1. For each stage t that we update, we update the state xt to towt."}, {"heading": "2.3 Stochastic lower bounds on the log partition function ratio", "text": "AIS produces a non-negative unbiased estimate of the ratio R = ZT / Z1 of partition functions. Unfortunately, the variance can be extremely large or even infinite. For these reasons, it is more important to estimate logR. Unfortunately, the logarithm of a non-negative unbiased estimate (such as the AIS estimate) is generally a distorted estimate of the logarithm. Let A be a non-negative unbiased estimate for A = E [A]. Then, according to Jeffreys inequality, E [log A] \u2264 logE [A] = logA] = logA, and so log A... is a lower limit for logA in expectation. The estimation protocol A... fulfills another important property: due to Markow's inequality for non-negative random variables, Pr [log A] = logA] = logA > logA > logA > logA > logA > logA is unpredictable."}, {"heading": "2.4 Reverse AIS and Bidirectional Monte Carlo", "text": "So it is a key finding behind bidirectional Monte Carlo (BDMC; [GGA15]) that you have an exact sample from the target distribution pT, which allows for a variety of division functions, but we focus on AIS for pedagogical purposes.) More cautiously, for t = 1,.., T, define p = pT = pT \u2212 t and T \u2212 t = TT \u2212 1. Then p \u2212 t corresponds to our original target distribution T and T = 1., T, define p = pT = pT \u2212 t = pT."}, {"heading": "3 Methods", "text": "There are at least two criteria that we would like a sample-based approximate inference algorithm to use to make its samples representative of the true posterior distribution: We want the approximate distribution q (\u03b8, z; y) to cover all the high probability regions of the posterior p (\u03b8, z | y), and we want to avoid placing probability mass in low probability regions of the posterior p. The former criterion motivates the simultaneous measurement of the KL divergence (p, z | y). If we want both, it motivates us to draw attention to the Jeffreys divergence, which is defined as DJ (q, p) = DKL (q, p; y) \u2022 BKL (p, q) \u2022 BKL (p, c | y)."}, {"heading": "3.1 Upper bounding the Jeffreys divergence in expectation", "text": "(incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (incomplete) (in"}, {"heading": "3.2 Evaluating B and J on small examples", "text": "In the previous paragraph, we have derived an estimator B (V) which describes the deviation J (V) between the actual rate of re-distribution and the distribution of approximate samples of AIS, i.e., E [B] > J. It can be seen from Eqs (7) and (10) that the expectation B, E [B) and the deviation from the deviation between the distributions over the supply chains B (B) and the deviation from the expectations B (V) qfwd (B) qfwd (V).5 The deviation from the distributions between the supply chains B (B) + DKL (pT) q.6 The deviation from the deviation between the deviations B (V) and the deviations from the deviations B (V) is the deviation from the deviations."}, {"heading": "3.3 Application to real-world data", "text": "So far, we have focused on setting up simulated data where it is possible to obtain an exact posterior sample and then strictly bind the Jeffreys divergence using BDMC. However, we are more interested in evaluating the performance of conclusions on real data. Heuristically, we can generate simulated data to use as a proxy for the real data, but this requires that the datasets are similar enough for the results to be transmitted. We propose to simulate data using model hyperparameters derived from the real world dataset of interest, run BDMC on the simulated data, and then validate that AIS chains behave similarly between the two datasets. Often, we informally distinguish between parameters of a statistical model (e.g. regression weights) and hyperparameters (e.g. noise variance)."}, {"heading": "4 Related work", "text": "This is not the only reason why we are dealing with the diagnosis of Markov Chain Variance. (See e.g. [Gey11].) In general, a number of MCMC examples deal with the question of whether and to what extent people are able to identify themselves. (See indeed) We want to achieve an estimate with both low and low deviations. One often tries to reduce the bias by discarding all samples until a certain \"burn-in\" time is reached, in which the Markov chain is believed to be sufficiently mixed. Unfortunately, it is difficult to choose a good burn-in time because it is difficult to diagnose the mixture (it is also recommended from the rod to the rod to the rod to the rod to be believed). To initiate several chains in different regions of the state and to track different statistics of these chains over time. One wants to check whether the variance within the chain of statistics is small."}, {"heading": "5.1 Validation", "text": "As described above, BREAD returns strict limits to the Jeffreys divergence only if the data from the model distribution are scanned. Mathematically, it could potentially yield misleading results in three ways. First, the upper limit B could overestimate the true Jeffreys divergence J. Secondly, the results from the simulated data could not match the results from the real data if the simulated data were not representative of the real data. In this section, we tried to confirm that B is a good substitute for J, that the behavior of the method to the simulated 2This can happen if the reference distribution is particularly inaccurate. For example, if we consider a case in which x and y are constant, and z that the model distribution p (z) = p (z) = p (z, x), x), the inference distribution q (z) = (z) and J (r) are constant (0.0, 1) and the reference distributions (0, r) 0.1 (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1) (0.1)."}, {"heading": "5.1.1 How tight is the bound?", "text": "To validate the upper limit B as a measure of the accuracy of an approximate inference machine, therefore, we must first verify that it accurately reflects the true Jeffreys deviations J. This is difficult to do in realistic environments, since J is generally unavailable, but we can use both quantities on small toy distributions using the technique of Section 3.2.We consider several distributions of toys where domain X was considered a 7-7 grid. In all cases, the MCMC transition processor is Metropolis-Hastings, where the application distribution was uniform over a step in the four coordinate directions. (Moves that landed outside the network were rejected.) For the mean distribution, we used geometric averages with a linear timetable for \u03b2.First, we created random non-normalized target distributions f (x), where each entry was independently of g."}, {"heading": "5.1.2 Validation on real datasets", "text": "We are looking at a Bayesian linear regression model in Stan, in which weights of uniform Gaussian priors and the standard deviation of the generating Gaussian distribution are sampled from an invers-Gaussian prior. We are looking at two sets of data - a) a real dataset - a standardized version of the NHEFS dataset (http: / / cdn1.sph.harvard.edu / wp-content / uploads / sites / 1268 / 2015 / 07 / nhefs _ book.xlsx) and b) a simulated dataset. To validate the use of the synthetic data as a proxy for the real data, we generated the stochastic lower boundary curves on both datasets. The results are shown in Figure 4 (a). The curves seem to be at different values because there would be different protocol marginal probabilities, but they seem to be at roughly the same level, suggesting that the behavior of the two data is more consistent."}, {"heading": "5.1.3 Fixed hyperparameter scheme", "text": "To validate the fixed hyperparameter scheme of Section 3.3, we are considering a similar Bayesian regression model as in Section 5.1.2, with covariance hyperparameters associated with broad Cauchy priors. We have set the hyperparameter values in the simulation of data to 1. As described in Section 3.3, we have performed MCMC chains of length 10, 100, 1000, and 10,000 starting from (\u03b7real, \u03b8) to obtain an approximate posterior sample to initialize the reverse chain. Results are shown in Figure 4 (b). We find that the upper limit curve is indistinguishable for all step numbers. In fact, it has been determined that the variability is comparable to the variability between studies of independent and identical AIS runs, as in Figure 4 (b), suggesting that reverse AIS chains can be initialized by true hyperparameter values (instead of the number of acids followed by a small number of MC)."}, {"heading": "5.2.1 Comparing model representations", "text": "Many models can be written in more than one way, for example through the introduction or collapse of latent variables. Probabilistic programming language performance can be sensitive to such representation decisions, and the representation that provides the best performance can vary from language to language. Therefore, users of probabilistic programming languages may want to know which legal presentation to use for their language of choice, and BREAD can prove extremely useful in this regard. We consider the matrix factoring model, in which we approximate a low-ranking N \u00d7 D matrix Y, the product of the U and V matrices with dimensions N \u00d7 K and K \u00b7 D respectively (where K < min (N, D)). We use a spherical Gaussian observational model, and spherical Gaussian priors on U and V.uik \u0445 N (0, \u03c32u) vkj \u0445 N (Vkj \u00b2 V) ijijijijijiang (T2) We can derive this model."}, {"heading": "5.2.2 Debugging", "text": "In our experiment with WebPPL, we observed a case where the reverse AIS chain yielded significantly lower estimates than those produced by the forward chain, which was not in line with the theoretical warranty. As a result, we found a subtle error in the way WebPPL was sampled from a multivariate Gaussian distribution (causing the exact back samples used to initialize the reverse chain to be wrong).3 In these days when many new likely programming languages are emerging and many are in active development, such debugging capabilities provided by BREAD can potentially be very useful."}], "references": [{"title": "Quantifying the probable approximation error of probabilistic inference programs", "author": ["M.F. Cusumano-Towner", "V.K. Mansinghka"], "venue": null, "citeRegEx": "Cusumano.Towner and Mansinghka.,? \\Q2016\\E", "shortCiteRegEx": "Cusumano.Towner and Mansinghka.", "year": 2016}, {"title": "An Introduction to the Bootstrap", "author": ["B. Efron", "R.J. Tibshirani"], "venue": "Chapman & Hall/CRC,", "citeRegEx": "Efron and Tibshirani.,? \\Q1998\\E", "shortCiteRegEx": "Efron and Tibshirani.", "year": 1998}, {"title": "Studies in lower bounding probability of evidence using the Markov inequality", "author": ["V. Gogate", "B. Bidyuk", "R. Dechter"], "venue": "In: Conference on Uncertainty in AI", "citeRegEx": "Gogate et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Gogate et al\\.", "year": 2007}, {"title": "Introduction to Markov chain Monte Carlo", "author": ["C.J. Geyer"], "venue": "Handbook of Markov chain Monte Carlo. Chapman & Hall/CRC,", "citeRegEx": "Geyer.,? \\Q2011\\E", "shortCiteRegEx": "Geyer.", "year": 2011}, {"title": "Sandwiching the marginal likelihood with bidirectional Monte Carlo", "author": ["R.B. Grosse", "Z. Ghahramani", "R.P. Adams"], "venue": null, "citeRegEx": "Grosse et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Grosse et al\\.", "year": 2015}, {"title": "Measuring sample quality with Stein\u2019s method", "author": ["J. Gorham", "L. Mackey"], "venue": "Neural Information Processing Systems", "citeRegEx": "Gorham and Mackey.,? \\Q2015\\E", "shortCiteRegEx": "Gorham and Mackey.", "year": 2015}, {"title": "Church: a language for generative models", "author": ["N.D. Goodman", "V.K. Mansinghka", "D.M. Roy", "K. Bonawitz", "J.B. Tenenbaum"], "venue": "In: Conference on Uncertainty in AI", "citeRegEx": "Goodman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Goodman et al\\.", "year": 2008}, {"title": "Annealing between distributions by averaging moments", "author": ["R. Grosse", "C.J. Maddison", "R. Salakhutdinov"], "venue": "Neural Information Processing Systems", "citeRegEx": "Grosse et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Grosse et al\\.", "year": 2013}, {"title": "The No-U-turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo", "author": ["M.D. Homan", "A. Gelman"], "venue": "J. Mach. Learn. Res", "citeRegEx": "Homan and Gelman.,? \\Q2014\\E", "shortCiteRegEx": "Homan and Gelman.", "year": 2014}, {"title": "Sequential Monte Carlo samplers", "author": ["P. del Moral", "A. Doucet", "A. Jasra"], "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology)", "citeRegEx": "Moral et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Moral et al\\.", "year": 2006}, {"title": "MCMC using Hamiltonian dynamics", "author": ["R.M. Neal"], "venue": "Handbook of Markov Chain Monte Carlo", "citeRegEx": "Neal,? \\Q2011\\E", "shortCiteRegEx": "Neal", "year": 2011}, {"title": "Annealed importance sampling", "author": ["R.M. Neal"], "venue": "Statistics and Computing", "citeRegEx": "Neal.,? \\Q2001\\E", "shortCiteRegEx": "Neal.", "year": 2001}, {"title": "Optimal scaling for various Metropolis\u2013Hastings algorithms", "author": ["G.O. Roberts", "J.S. Rosenthal"], "venue": "Statistical Science", "citeRegEx": "Roberts and Rosenthal.,? \\Q2001\\E", "shortCiteRegEx": "Roberts and Rosenthal.", "year": 2001}], "referenceMentions": [], "year": 2016, "abstractText": "Markov chain Monte Carlo (MCMC) is one of the main workhorses of probabilistic inference, but it is notoriously hard to measure the quality of approximate posterior samples. This challenge is particularly salient in black box inference methods, which can hide details and obscure inference failures. In this work, we extend the recently introduced bidirectional Monte Carlo [GGA15] technique to evaluate MCMC-based posterior inference algorithms. By running annealed importance sampling (AIS) chains both from prior to posterior and vice versa on simulated data, we upper bound in expectation the symmetrized KL divergence between the true posterior distribution and the distribution of approximate samples. We present Bounding Divergences with REverse Annealing (BREAD), a protocol for validating the relevance of simulated data experiments to real datasets, and integrate it into two probabilistic programming languages: WebPPL [GS] and Stan [CGHL+ p]. As an example of how BREAD can be used to guide the design of inference algorithms, we apply it to study the effectiveness of different model representations in both WebPPL and Stan.", "creator": "LaTeX with hyperref package"}}}