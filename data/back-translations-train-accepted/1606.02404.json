{"id": "1606.02404", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "Clustering with Same-Cluster Queries", "abstract": "We propose a framework for Semi-Supervised Active Clustering framework (SSAC), where the learner is allowed to interact with a domain expert, asking whether two given instances belong to the same cluster or not. We study the query and computational complexity of clustering in this framework. We consider a setting where the expert conforms to a center-based clustering with a notion of margin. We show that there is a trade off between computational complexity and query complexity; We prove that for the case of $k$-means clustering (i.e., when the expert conforms to a solution of $k$-means), having access to relatively few such queries allows efficient solutions to otherwise NP hard problems.", "histories": [["v1", "Wed, 8 Jun 2016 05:28:14 GMT  (22kb)", "https://arxiv.org/abs/1606.02404v1", "Under Review"], ["v2", "Tue, 22 Nov 2016 18:16:44 GMT  (511kb)", "http://arxiv.org/abs/1606.02404v2", "NIPS 2016"]], "COMMENTS": "Under Review", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["hassan ashtiani", "shrinu kushagra", "shai ben-david"], "accepted": true, "id": "1606.02404"}, "pdf": {"name": "1606.02404.pdf", "metadata": {"source": "CRF", "title": "Clustering with Same-Cluster Queries", "authors": ["Hassan Ashtiani"], "emails": ["mhzokaei@uwaterloo.ca", "skushagr@uwaterloo.ca", "shai@uwaterloo.ca"], "sections": [{"heading": null, "text": "ar Xiv: 160 6.02 404v 2 [cs.L G] 2 (SSAC), where the learner may interact with a domain expert and ask whether two predefined cases belong to the same cluster or not. We examine the query and computational complexity of clusters within this framework. We consider an environment in which the expert corresponds to a center-based cluster with an idea of margin. We show that there is a trade-off between computational complexity and query complexity; we demonstrate that in the case of k-mean clusters (i.e., if the expert agrees to a solution of k-means), access to relatively few such queries provides efficient solutions to otherwise NP-hard problems. In particular, we provide a probabilistic polynomial time algorithm (BPP) for clustering in this environment, which O (k 2 log k + k log n) queries and sequences with time complexity O (kn log n n) have (the number of clusters we need to determine) an algorithm that is effective."}, {"heading": "1 Introduction", "text": "The second problem is that performing clusters under many natural models is mathematically difficult. Consider the task of dividing users of an online shopping service into different groups, and the result of this clustering can then be used, for example, to propose similar products for users in the same group, or to organize data so that it would be easier to read / analyze the monthly purchase reports. These different applications can lead to conflicting solution requirements. In such cases, domain knowledge must be used to better define the cluster problem. Aside from trial and error, a principled way of extracting domain knowledge is to perform clustering using a form of \"weak\" supervision. For example, Balcan andBlum has an interactive framework with \"merge\" queries for clustering \"queries.\""}, {"heading": "1.1 Contributions", "text": "The two most important contributions of this paper are the introduction of semi-supervised active clustering (SSAC) and the rather unusual demonstration that accessing simple query responses can turn an otherwise hard clustering problem into a practicable one. Before explaining these results, we also mention an idea of clustering capability (or \"input-networking\") that we are introducing. We define a new idea of networking of data, called \u03b3 margin property, which is related to the previously introduced notion of proximity to the center. The greater the value of \u03b3, the stronger the assumption becomes, which means clustering becomes easier. In relation to this \u03b3 parameter, we get a sharp \"phase transition\" between k-means that are hard and optimally solvable in polynomic time.1 The exact value of such a threshold depends on some more precise details of the cluster task, which means clustering becomes easier."}, {"heading": "1.2 Related Work", "text": "This paper combines two themes in cluster research; clustering with partial monitoring (especially monitoring in the form of query responses) and the computational complexity of cluster tasks. Supervision in clustering (sometimes referred to as \"semi-supervised clustering\") has been dealt with primarily in application-oriented work [BBM02, BBM04, KBDM09]. The most common method of mediating such monitoring is through a series of pairwise link / do-not-link constraints on the instances. Note that unlike the supervision we address here, the supervision in the papers cited above is not interactive. Balcan et. al [BB08] suggests a framework for interactive clustering with the help of a user (i.e. an oracle). The queries considered in this context differ from ours."}, {"heading": "2 Problem Formulation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Center-based clustering", "text": "The framework of clustering with queries can be applied to any type of clustering. In this work, however, we focus on a particular family of common clustering - centric clustering in Euclidean spaces3.Let X be a subset of a Euclidean space, Rd. Let CX = {C1,.., Ck} be a clustering (i.e. a division) of X. We say that clustering CX is centered when there is a set of centers \u00b5 = {\u00b51,.., \u00b5k}, Rn, so that clustering corresponds to the Voroni diagram above these centers. We say that clustering CX is centric when there is a set of centers \u00b5 = {\u00b51,..., \u00b5k}, so that clustering corresponds to the Voroni diagram above these centers."}, {"heading": "2.2 The \u03b3-margin property", "text": "Next, we introduce a concept of clusterability of a dataset, also referred to as a \"data usage property.\" Definition 1 (\u03b3 margin): letter X: points in metric space.M Let CX = {C1,.., Ck} be a center-based clustering of X caused by the centers \u00b51,..., \u00b5k margin. \"We say that CX fulfills the \u03b3 margin property if the following applies: For all i [k] and all x-Ci and y-X-Ci, 2In particular, the hardness result of [BDR14] is based on the ability to construct non-euclidean spacing functions. Later in this paper, we will prove hardness for \u03b3 \u2264 3.4 for euclidean instabilities. 3In fact, our results are all independent of the euclidean dimension and relate to all Hilbert distances."}, {"heading": "2.3 The algorithmic setup", "text": "For clustering C * = {C * 1,.. C * k}, a C * oracle is a function that answers queries according to this cluster formation. One can imagine such an oracle as a user who has an idea of his desired clustering, enough to answer the queries of the algorithm. The cluster algorithm then tries to restore C * oracle by querying a C * oracle. The following idea of query is probably the most intuitive. Definition 2 (query of the same cluster): A query of the same cluster asks if two instances x1 and x2 belong to the same cluster, i.e., OC * (x1, x2) = {true if x1 C * x2false o.w. (We leave the C * subscript out of context).Definition 3 (query complexity) is determined by the tuple (X *, C *).We consider an instance of such a script C * if it has a specific steroid state."}, {"heading": "3 An Efficient SSAC Algorithm", "text": "The setting is the one described in the previous section. Specifically, it is assumed that the oracle has a center-based clustering in its head that not only satisfies the same cluster queries, but also another type of query called below.Definition 4 (cluster assignment query).A cluster assignment query asks the center of instances in that cluster that an instance x belongs to a cluster. In other words, the OC query (x) = if and only if x. C assignment of each cluster assignment query can be replaced by a seed cluster (see Appendix A in supplementary material), we can express everything in terms of the more natural notion of the same cluster."}, {"heading": "4 Hardness Results", "text": "4.1 Hardness of the Euclidean k mean with MarginFinding k mean solution without the help of an oracle is generally mathematically difficult. In this section, we will show that solving the Euclidean k mean remains difficult even if we know that the optimal solution fulfills the n margin property for n value = 3.4. In particular, we will show the hardness for the case k = B value (0, 1). In Section 3, we have proposed a polynomial time algorithm that could restore the target margin property using O (k2 log k + k logn) queries, assuming that the cluster fulfills the g margin property for n > 1. Let's now assume that the oracle corresponds to the optimal kmeans clustering solution. In this case, for 1 < vice versa: Solving the k mean indication is the optimal one."}, {"heading": "4.1.1 Overview of the proof", "text": "Our method for detecting Thm. 10 is based on the approach used by [Vat09]. However, the original construction proposed in [Vat09] does not meet the \u03b3 margin property. Therefore, we must modify the proof by specifying the parameters of the construction more carefully. 5To be precise, note that the algorithm used for clustering with queries is likely, while the lower limit we provide is for deterministic algorithms. However, this also implies a lower limit for randomized algorithms, unless BPP 6 = PTo prove the theorem, we will provide a reduction in the problem of Exact Cover by 3 sets (X3C), which is NP-Complete [GJ02] for the decision version of k-Means. Definition 11 (X3C) means that a set U containing exactly 3m elements, and a collection of S1, a group of S1, S1, means that each Si contains exactly three elements."}, {"heading": "4.1.2 Reduction design", "text": "Considering an instance of X3C, these are the elements U = 1,.. j = 3, and the collection S, we construct a series of points X in the Euclidean plane that we want to group. Specifically, X consists of a series of points Hl, m in a grid-like manner, and the sentences Zi correspond to Si. In other words, X = Hl \u2212 1i = 1Zi. The row Hl, m is as in Fig. 1. The row Ri consists of 6m + 3 points {si, ri, 1,...., ri, 6m + 1, fi}. The row Gi consists of 3m points {gi,., gi, 3m}. The distances between the points are also in Fig. 1., all these points have a weight w, which simply means that each point is a set of w."}, {"heading": "4.2 Lower Bound on the Number of Queries", "text": "In the previous section, we showed that k-mean clustering is difficult even under the assumption that the algorithm has access to an oracle. In this section, we show a lower limit on the number of queries required to provide a polynomial time algorithm for k-mean clustering under the marginal assumption. Theorem 14. For each \u03b3 \u2264 \u221a 3.4, it is difficult to find the optimal solution for the k-mean objective function, even if the optimal cluster behavior meets the g-margin property and the algorithm O (log k + log | X |) can ask questions about the same cluster. Proof contradiction: Assuming that there is a polynomial time algorithm A that yields O (log k + log | X |), all queries for the same cluster can yield. < In this case, we show that there is another algorithm that poses a problem for this problem, but it is not a micro."}, {"heading": "5 Conclusions and Future Directions", "text": "In this work, we have introduced a framework for semi-supervised active clustering (SSAC) with sub-cluster queries, which can be seen as a natural way for a cluster mechanism to gain domain knowledge without clustering being an underdefined task. Our analysis focused on the computational and query complexity of such SSAC problems when the input dataset meets a condition for clusterability - the so-called \"margin property.\" Our main result shows that accessing a limited number of such queries (logarithmic in the size of the dataset and square in the number of clusters) enables an efficient successful clustering under conditions (marginal parameters between 1 and 3.4 \u2248 1.84) that make the problem NP-hard without the help of such a query mechanism. We have also set a lower limit indicating that at least log-kn queries are needed to analyze NP practically."}, {"heading": "Acknowledgments", "text": "We would like to thank Samira Samadi and Vinayak Pathak for the helpful discussions on the topics of this essay."}, {"heading": "A Relationships Between Query Models", "text": "Proposal 15. Any cluster assignment algorithm that uses only q queries with the same cluster can be customized to use 2q cluster assignment queries (and not queries with the same cluster) with the same time complexity. Proof 16. Any algorithm that uses only q cluster assignment queries can be customized to use kq cluster queries (and not cluster assignment queries) with at most a factor k, where k is the number of clusters. Proof proof. If the cluster algorithm has access to one instance from each of the k clusters (say xi-Xi), it can simply simulate the cluster assignment query by making samecluster queries (Q-x) when that algorithm accepts an instance from each of the k clusters (say) and not the cluster assignment queries."}, {"heading": "B Comparison of \u03b3-Margin and \u03b1-Center Proximity", "text": "In this paper, we have introduced the concept of the \"nullity\" property in various studies. We have further shown that upper and lower limits of the computational complexity of clustering do not exist under this premise. < < p) It is therefore important to compare this notion with other previously investigated cluster capability concepts. < p) An important notion of the nullity of the data for clustering, however, is the number of cluster properties. We say that a center-based cluster behavior CX = {C1,.,. c) Ck), that of centers c1,."}, {"heading": "C Proofs of Lemmas 12 and 13", "text": "In section 4 we have theorem 10 based on two technical results (i.e., GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI GI"}, {"heading": "D Concentration inequalities", "text": "Theorem 26 (Generalized Inequality of Hoeffding (e.g. [AG15]): Let X1,.... Xn be random vectors in a Hilbert space, so that for all i, as well as for I, Xi, 2 \u2264 R and E [Xi] = \u00b5. If n > c log (1 / \u03b4) and 2, then we have with a probability of at least 1 \u2212 \u043c that we have this equality."}], "references": [{"title": "Representation learning for clustering: A statistical framework", "author": ["Hassan Ashtiani", "Shai Ben-David"], "venue": "Uncertainty in AI (UAI),", "citeRegEx": "ABD15", "shortCiteRegEx": null, "year": 2015}, {"title": "Information Processing Letters", "author": ["Pranjal Awasthi", "Avrim Blum", "Or Sheffet. Center-based clustering under perturbation stability"], "venue": "112(1):49\u2013 54,", "citeRegEx": "ABS12", "shortCiteRegEx": null, "year": 2012}, {"title": "In Proceedings of The 1st International Workshop on \u201cFeature Extraction: Modern Questions and Challenges", "author": ["Hassan Ashtiani", "Ali Ghodsi. A dimension-independent generalization bound for kernel supervised principal component analysis"], "venue": "NIPS, pages 19\u201329,", "citeRegEx": "AG15", "shortCiteRegEx": null, "year": 2015}, {"title": "pages 316\u2013328", "author": ["Maria-Florina Balcan", "Avrim Blum. Clustering with interactive feedback. In Algorithmic Learning Theory"], "venue": "Springer,", "citeRegEx": "BB08", "shortCiteRegEx": null, "year": 2008}, {"title": "Semi-supervised clustering by seeding", "author": ["Sugato Basu", "Arindam Banerjee", "Raymond Mooney"], "venue": "In Proceedings of 19th International Conference on Machine Learning (ICML-2002,", "citeRegEx": "BBM02", "shortCiteRegEx": null, "year": 2002}, {"title": "pages 59\u201368", "author": ["Sugato Basu", "Mikhail Bilenko", "Raymond J Mooney. A probabilistic framework for semi-supervised clustering. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery", "data mining"], "venue": "ACM,", "citeRegEx": "BBM04", "shortCiteRegEx": null, "year": 2004}, {"title": "pages 671\u2013680", "author": ["Maria-Florina Balcan", "Avrim Blum", "Santosh Vempala. A discriminative framework for clustering via similarity functions. In Proceedings of the fortieth annual ACM symposium on Theory of computing"], "venue": "ACM,", "citeRegEx": "BBV08", "shortCiteRegEx": null, "year": 2008}, {"title": "Data stability in clustering: A closer look", "author": ["Shalev Ben-David", "Lev Reyzin"], "venue": "Theoretical Computer Science, 558:51\u201361,", "citeRegEx": "BDR14", "shortCiteRegEx": null, "year": 2014}, {"title": "CoRR", "author": ["Shai Ben-David. Computational feasibility of clustering under clusterability assumptions"], "venue": "abs/1501.00437,", "citeRegEx": "Ben15", "shortCiteRegEx": null, "year": 2015}, {"title": "pages 63\u201374", "author": ["Maria Florina Balcan", "Yingyu Liang. Clustering under perturbation resilience. In Automata", "Languages", "Programming"], "venue": "Springer,", "citeRegEx": "BL12", "shortCiteRegEx": null, "year": 2012}, {"title": "University of California", "author": ["Sanjoy Dasgupta. The hardness of k-means clustering. Department of Computer Science", "Engineering"], "venue": "San Diego,", "citeRegEx": "Das08", "shortCiteRegEx": null, "year": 2008}, {"title": "volume 29", "author": ["Michael R Garey", "David S Johnson. Computers", "intractability"], "venue": "wh freeman New York,", "citeRegEx": "GJ02", "shortCiteRegEx": null, "year": 2002}, {"title": "Semisupervised graph clustering: a kernel approach", "author": ["Brian Kulis", "Sugato Basu", "Inderjit Dhillon", "Raymond Mooney"], "venue": "Machine learning, 74(1):1\u201322,", "citeRegEx": "KBDM09", "shortCiteRegEx": null, "year": 2009}, {"title": "In WALCOM: Algorithms and Computation", "author": ["Meena Mahajan", "Prajakta Nimbhorkar", "Kasturi Varadarajan. The planar k-means problem is np-hard"], "venue": "pages 274\u2013285. Springer,", "citeRegEx": "MNV09", "shortCiteRegEx": null, "year": 2009}, {"title": "accessible at http://cseweb", "author": ["Andrea Vattani. The hardness of k-means clustering in the plane. Manuscript"], "venue": "ucsd. edu/avattani/papers/kmeans_hardness. pdf, 617,", "citeRegEx": "Vat09", "shortCiteRegEx": null, "year": 2009}], "referenceMentions": [{"referenceID": 3, "context": "Blum [BB08] propose to use an interactive framework with \u2019split/merge\u2019 queries for clustering.", "startOffset": 5, "endOffset": 11}, {"referenceID": 0, "context": "In another work, Ashtiani and Ben-David [ABD15] require the domain expert to provide the clustering of a \u2019small\u2019 subset of data.", "startOffset": 40, "endOffset": 47}, {"referenceID": 8, "context": "The quest for notions of niceness that are likely to occur in real data and allow clustering efficiency is still ongoing (see [Ben15] for a critical survey of work in that direction).", "startOffset": 126, "endOffset": 133}, {"referenceID": 1, "context": "We define a novel notion of niceness of data, called \u03b3-margin property that is related to the previously introduced notion of center proximity [ABS12].", "startOffset": 143, "endOffset": 150}, {"referenceID": 3, "context": "al [BB08] propose a framework for interactive clustering with the help of a user (i.", "startOffset": 3, "endOffset": 9}, {"referenceID": 0, "context": "Another example of the use of supervision in clustering was provided by Ashtiani and Ben-David [ABD15].", "startOffset": 95, "endOffset": 102}, {"referenceID": 10, "context": "For example, k-means clustering is NP-hard even for k = 2 [Das08], or in a 2-dimensional plane [Vat09, MNV09].", "startOffset": 58, "endOffset": 65}, {"referenceID": 8, "context": "some notions of niceness of data under which the clustering becomes easy have been considered (see [Ben15] for a survey).", "startOffset": 99, "endOffset": 106}, {"referenceID": 1, "context": "al [ABS12].", "startOffset": 3, "endOffset": 10}, {"referenceID": 9, "context": "Balcan and Liang [BL12] improve the assumption to \u03b1 > \u221a 2+1.", "startOffset": 17, "endOffset": 23}, {"referenceID": 7, "context": "Ben-David and Reyzin [BDR14] show that this problem is NP-Hard for \u03b1 < 2.", "startOffset": 21, "endOffset": 28}, {"referenceID": 7, "context": "2In particular, the hardness result of [BDR14] relies on the ability to construct non-Euclidean distance functions.", "startOffset": 39, "endOffset": 46}, {"referenceID": 7, "context": "This results extends the hardness result of [BDR14] to the case of Euclidean metric, rather than arbitrary one, and to the \u03b3-margin condition (instead of the \u03b1-center proximity there).", "startOffset": 44, "endOffset": 51}, {"referenceID": 14, "context": "10 is based on the approach employed by [Vat09].", "startOffset": 40, "endOffset": 47}, {"referenceID": 14, "context": "However, the original construction proposed in [Vat09] does not satisfy the \u03b3-margin property.", "startOffset": 47, "endOffset": 54}, {"referenceID": 11, "context": "To prove the theorem, we will provide a reduction from the problem of Exact Cover by 3-Sets (X3C) which is NP-Complete [GJ02], to the decision version of k-means.", "startOffset": 119, "endOffset": 125}, {"referenceID": 14, "context": "1 in [Vat09].", "startOffset": 5, "endOffset": 12}, {"referenceID": 14, "context": "This figure is adapted from [Vat09].", "startOffset": 28, "endOffset": 35}], "year": 2016, "abstractText": "We propose a framework for Semi-Supervised Active Clustering framework (SSAC), where the learner is allowed to interact with a domain expert, asking whether two given instances belong to the same cluster or not. We study the query and computational complexity of clustering in this framework. We consider a setting where the expert conforms to a center-based clustering with a notion of margin. We show that there is a trade off between computational complexity and query complexity; We prove that for the case of k-means clustering (i.e., when the expert conforms to a solution of k-means), having access to relatively few such queries allows efficient solutions to otherwise NP hard problems. In particular, we provide a probabilistic polynomial-time (BPP) algorithm for clustering in this setting that asks O ( k 2 log k + k log n) same-cluster queries and runs with time complexity O ( kn log n) (where k is the number of clusters and n is the number of instances). The algorithm succeeds with high probability for data satisfying margin conditions under which, without queries, we show that the problem is NP hard. We also prove a lower bound on the number of queries needed to have a computationally efficient clustering algorithm in this setting.", "creator": "LaTeX with hyperref package"}}}