{"id": "1606.02448", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "Multiple-Play Bandits in the Position-Based Model", "abstract": "Sequentially learning to place items in multi-position displays or lists is a task that can be cast into the multiple-play semi-bandit setting. However, a major concern in this context is when the system cannot decide whether the user feedback for each item is actually exploitable. Indeed, much of the content may have been simply ignored by the user. The present work proposes to exploit available information regarding the display position bias under the so-called Position-based click model (PBM). We first discuss how this model differs from the Cascade model and its variants considered in several recent works on multiple-play bandits. We then provide a novel regret lower bound for this model as well as computationally efficient algorithms that display good empirical and theoretical performance.", "histories": [["v1", "Wed, 8 Jun 2016 08:31:46 GMT  (527kb,D)", "http://arxiv.org/abs/1606.02448v1", null]], "reviews": [], "SUBJECTS": "cs.LG math.ST stat.TH", "authors": ["paul lagr\u00e9e", "claire vernade", "olivier capp\u00e9"], "accepted": true, "id": "1606.02448"}, "pdf": {"name": "1606.02448.pdf", "metadata": {"source": "CRF", "title": "Multiple-Play Bandits in the Position-Based Model", "authors": ["Paul Lagr\u00e9e", "Claire Vernade", "Olivier Capp\u00e9"], "emails": ["paul.lagree@u-psud.fr", "claire.vernade@telecom-paristech.fr", "cappe@enst.fr"], "sections": [{"heading": "1 Introduction", "text": "This year it is so far that it will only be a matter of time before it is so far, until it is so far."}, {"heading": "2 Setting and Parameter Estimation", "text": "We consider the binary stochastic Bandit model with K Bernoulli-distributed arms. The model parameters are arm expectations \u03b8 = (empirically seen, empirical) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) (empirically) (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) l (empirically) (empirically) l (empirically) (empirically) l (empirically) l (empirically) (empirically) (empirically) (empirically) l (empirically) (empirically) (empirically (empirically) (empirically) (empirically) (empirically) (empirically) l (empirically (empirically) (empirically) (empirically) (empirically) (empirically) (empirically) (empirically"}, {"heading": "3 Lower Bound on the Regret", "text": "In this section, we will consider the basic asymptotic limits of learning performance for online algorithms under PBM. These cannot be deduced from previous general outcomes, such as those of [10, 6], due to the censorship of feedback associated with each action. We will execute a simple and general scheme of evidence - using the results of [11] - that applies to both PBM and more general models. Lower limits of regret are based on measurement changes: the question is how much we can confuse the true parameters of the problem for others when we observe successive arms? Against this background, we will subscribe all expectations and probabilities by the parameter value and explicitly point out that the quantities \u00b5a, a, a, \u00b5, \u0445 a introduced in section 2 also depend on the parameters."}, {"heading": "3.1 Existing results for multiple-play bandit problems", "text": "Lower limits of regret will prove to be uniformly efficient algorithms in the sense of [15]: Definition 1. An algorithm shall be uniformly efficient if, for each bandit model parameterized by \u03b8 and for all \u03b1 parameters, it interprets its expected regret after T rounds in such a way that E\u03b8R (T) = o (T\u03b1). For the multiple-play MAB problem [1] the following limit was given inf T \u2192 \u221e E\u03b8R (T) log (T) \u2265 K \u0445 k = L + 1 \u03b8L \u2212 \u03b8k (\u03b8k, \u03b8L). (3) For the problem of \"ranking,\" where rewards follow the weighted cascade model with decreasing weights (wl) l = 1,..., L, [5] the following limit was derived inf T > Eelectork (T) log T \u2265 wL \u00b2 k = L \u2212 requik d (dependent) with decreasing weights (l) > = 1, L, [inf]."}, {"heading": "3.2 Lower bound step by step", "text": "Step 1: Calculation of the expected log probability ratio. If you interpret after Fs \u2212 1, you get the log probability ratio for the two values mentioned. (4) Lemma 2. For each position l and each element k define the local set of information according to Il (\u03b8k, \u03bbk): = Log p (Z (s); p (Z); p (Z); p (Zl); p (t); p). (4) Lemma 2. For each position l and each element k define the local set of information according to Il (\u03b8k, \u03bbk): = Log p (Zl (t); p (Zl); p); p (t)."}, {"heading": "3.3 Lower bound for the PBM", "text": "Theorem 6: For PBM, the following lower limit applies to any uniformly efficient algorithm: lim inf T \u2192 \u221e E\u03b8R (T) log T \u2265 K \u2211 k = L + 1 min l = 1,..., L).Proof. First, note that for PBM you have Il (\u03b8k, \u03bal\u03b8L) = d (\u03bal\u03b8k, \u03bal) = l: (1,.., l \u2212 p, l, l,. Proof. For PBM Il (\u03b8k, \u03bbk) = d (\u03bal\u03b8k, \u03bal).To get the expression in Theorem 6 of Corollary 5, we assumed that the optimal coefficients (ca) a cannot be zero, only for the K \u2212 L-L action, which puts the suboptimal arm k in position l, which reaches the minimum of L-vk."}, {"heading": "4 Algorithms", "text": "In this section we present two algorithms for the PBM. The first algorithm uses the CUCB strategy of [3] and requires a simple upper trust based on the estimator defined in (2); the second algorithm is based on the Parsimonious Item Exploration - PIE (L) scheme proposed in [5], which aims to achieve asymptotically optimal performance; and for this second algorithm, called PBM-PIE, it is also necessary to use a multi-position analogue of the well-known KL-UCB index [9], inspired by a result of [16]; the analysis of the PBM-PIE supports the relevance of the sub-points derived in Section 3.PBM-UCB; the first algorithm simply consists of sorting optimistic indices in decreasing order and dragging the corresponding L-arms."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Simulations", "text": "In order to evaluate our strategies, a simple problem is considered, in which the expectations of the poor are chosen in such a way that the asymptotic behavior can be observed over a reasonable time horizon. All results are averaged on the basis of 10,000 independent gradients of the algorithm. We present the results in Figure 1 (b), where PBM-UCB, PBM-PIE and PBM-TS are compared with RBA-KL-UCB. Results of PBM-PIE and PBM-TS are comparable, with the latter even being below the lower limit (a frequent observation, see [12], and due to the asymptotic nature of the lower limit). The curves confirm our analysis of PBM-PIE and lead us to suspect that the actual sampling policy may be asymptotically optimal."}, {"heading": "5.2 Real data experiments: search advertising", "text": "The record was provided for the KDD Cup 2012 Track 2 1 and includes session minutes from soso.com, a search engine owned by Tencent. It consists of ads inserted between search results. Each of the 150M lines from the log contains the user ID, the query, an ad, a position (1, 2 or 3) at which it was displayed, and a binary reward (click / no-click). First, for each query we excluded ads that were not displayed at least 1,000 times at each position. We also filtered queries that had less than 5 ads that met the previous limitations. As a1http: / / www.kddcup2012.org / result, we received 8 queries with at least 5 and up to 11 ads. For each query q, we calculated the matrix of average click rates (CTR) for the average click rates (CTR): Mq, the number of ads with at least 5 and up to 11 ads."}, {"heading": "Conclusion", "text": "This paper represents the first complete analysis of PBM in an online context. The proof scheme used to obtain the lower limit of regret is interesting in itself, as it can be generalized to various other settings. The tightness of the lower limit is confirmed by our analysis of PBM-PIE, but it would be an interesting future contribution to provide such guarantees for simpler algorithms such as PBM-TS or a \"PBM CLUCK\" using the trust regions of PBM-PIE. In practice, the algorithms are robust against small deviations in the values of (\u0421l) l, but it would be preferable to gain some control over the regret under uncertainty of these investigation parameters."}, {"heading": "A Properties of \u03b8\u0302k(t) (Section 2)", "text": "Depending on the actions A (1) to A (t \u2212 1), the protocol probability of the observations Z (1),.., Z (t \u2212 1) can be written ast \u2212 1 \u2211 s = K \u2211 k = 1 L \u2211 l = 1 {Al (t) = k} [Zl (t) log (\u03bal\u03b8k) + (1 \u2212 Zl (t))) log (1 \u2212 \u03bal\u03b8k)] = K \u2211 k = 1 L \u2211 l = 1 Sk, l (t) log (\u03bal\u03b8k) + (Nk, l (t) \u2212 Sk, l (t) log (1 \u2212 \u0441\u0442l\u03b8k).Differentiate twice with respect to \u041ak and the expectation of (Sk, l (t) l, conditionally to A (1),.., A (t \u2212 1) results in the expression of I (\u041ak) given in section 2."}, {"heading": "B Proof of Theorem 4", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "B.1 Proof of Lemma 2", "text": "According to the PBM, the conditional expectation of the log probability ratio, defined in (4) writesE\u03b8 ['(t) | A (1),.., A (t)] = E\u03b8 [t) s = 1 [A (s) = a] L-l = 1 log pal (Xl (s) Yl (s); \u03b8) pal (Xl (s) Yl (s); \u03bb) pal (Xl (s) Yl (s),..., A (t)] = t-l = 1 [A (s) 1 {A (s) = a} L-l = 1 E [log pal (Xl (s) Yl (s); \u03b8) pal (Xl (s) Yl (s),)."}, {"heading": "B.2 Details on the proof of Proposition 3", "text": "Lemma 12. We simply remember the following technical problem for completeness. Lemma 13. Let each event (1,..,.,.) stop for each event (A). Let two bandit models be such that the distributions of all arms in \u03b8 and \u03bb are absolutely continuous. Let it be a hold time in relation to (Ft) that (\u03c3 < + \u221e) a.s. among both models. Let it be an event that 0 < PTB (E) < 1. Then you have a hold time in relation to (Ft) that (Na (\u03c3) [D), (PTB), (E), where Ia (2001) is the conditional expectation of the log probability ratio for the interest model. The proof of this problem is directly derived from the above expressions of the log probability ratio and from the proof of Lemma 1 in Appendix A.1 of [11]. Let us simply remember the following technical problem for the completeness of each Lemma A (you)."}, {"heading": "B.3 Lower bound proof (Theorem 4)", "text": "In order to prove the simplified lower limit of theorem 4, we essentially have two arguments: 1. a lower limit of f (\u03b8) can be achieved by increasing the possible quantity, i.e. by loosening some constraints; 2. term 15 can be used to reduce the objective function of the problem. (9) We begin with the loosening of some constraints: We allow the change of the measure only if we belong to the sets Bk. (8).t inf \u00b2 B (s).a).A Ia (\u03b8) ca. (9) We begin with the loosening of some constraints: We only allow the change of the measurement quantity. (8)."}, {"heading": "C Proof of Proposition 8", "text": "In this section we fix an arm k = 1,., K) and get an upper confidence limit for the estimator p (t): = Sk (t) / N (t). We present the centered sequence of successive observations from the arm k (t), i = L (l) l = 1 {Al (\u03c4i) = k) (Xl (\u03c4i) Yl (\u03c4i) \u2212 2). We present the centered sequence of successive observations from the arm k (t). (15) We present the centered sequence of successive observations from the arm k (t). (1) We have the sequence of successive observations Gi = 1 \u2212 1, we have E (Z) k = 1 {Gi \u2212 1 = 0, and therefore the sequenceMk, n = n = n (Z) k (z) k)."}, {"heading": "E.1 Controlling leaders and estimations", "text": "Define that k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k k"}, {"heading": "E.2 Regret decomposition", "text": "We break down regret by distinguishing rounds into A-B and other rounds. Specifically, we introduce the following groups of rounds for arm k > L: Ek = {t \u2265 1: t / (B-C-D), L (t) = a, A (t) = vk, L}. The set of moments at which a suboptimal action is selected can now be expressed as follows: {t \u2265 1: A (t) 6 = a \u0445 (B-C-D). Through a compound boundary, we obtain the upper boundary E [R (T) \u2264 (L-L = 1 Pearl) E [| B-C-D |] + K \u0445 k = L + 1 \u0441vk, L (Containments) E [Ek].From previous boundaries, which all add up, there is C1 (E-L) and C3 (), so that (L-L = 1 Pearl) (E-B), E [Ek], E [Ek), Ek (Ek), Ek (E) and (L)."}, {"heading": "E.3 Bounding event Ek", "text": "s fix an arm k > L. Let t > Ek: Arm k is pulled into position L, i.e. by constructing the algorithm, we have this k + B (t) and hence Uk (t). First, we show that this implies that Uk (t)."}, {"heading": "F Lemmas", "text": "In this section, we recall two necessary concentration dilemmas taken directly from Lemma 4 and 5 in Appendix A of [5]. Although they are more likely to be involved from a probable viewpoint, these results are easier to determine than proposition 8 as their adaptation to the case of PBM, since they are based on a crude lower limit for N \u0441k (t), sufficient to prove Theorem 11.. Lemma 21."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "<lb>Sequentially learning to place items in multi-position displays or lists is a task that can be cast into the<lb>multiple-play semi-bandit setting. However, a major concern in this context is when the system cannot decide<lb>whether the user feedback for each item is actually exploitable. Indeed, much of the content may have been<lb>simply ignored by the user. The present work proposes to exploit available information regarding the display<lb>position bias under the so-called Position-based click model (PBM). We first discuss how this model differs<lb>from the Cascade model and its variants considered in several recent works on multiple-play bandits. We<lb>then provide a novel regret lower bound for this model as well as computationally efficient algorithms that<lb>display good empirical and theoretical performance.", "creator": "LaTeX with hyperref package"}}}