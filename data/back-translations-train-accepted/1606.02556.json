{"id": "1606.02556", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "DISCO Nets: DISsimilarity COefficient Networks", "abstract": "We present a new type of probabilistic model which we call DISsimilarity COefficient Networks (DISCO Nets). DISCO Nets allow us to efficiently sample from a posterior distribution parametrised by a neural network. During training, DISCO Nets are learned by minimising the dissimilarity coefficient between the true distribution and the estimated distribution. This allows us to tailor the training to the loss related to the task at hand. We empirically show that (i) by modeling uncertainty on the output value, DISCO Nets outperform equivalent non-probabilistic predictive networks and (ii) DISCO Nets accurately model the uncertainty of the output, outperforming existing probabilistic models based on deep neural networks.", "histories": [["v1", "Wed, 8 Jun 2016 13:57:44 GMT  (4407kb,D)", "http://arxiv.org/abs/1606.02556v1", null], ["v2", "Wed, 15 Jun 2016 16:01:04 GMT  (4408kb,D)", "http://arxiv.org/abs/1606.02556v2", null], ["v3", "Thu, 16 Jun 2016 07:45:20 GMT  (4410kb,D)", "http://arxiv.org/abs/1606.02556v3", null], ["v4", "Wed, 24 Aug 2016 15:19:45 GMT  (4410kb,D)", "http://arxiv.org/abs/1606.02556v4", null], ["v5", "Fri, 28 Oct 2016 11:27:45 GMT  (4377kb,D)", "http://arxiv.org/abs/1606.02556v5", null]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["diane bouchacourt", "m pawan kumar", "sebastian nowozin"], "accepted": true, "id": "1606.02556"}, "pdf": {"name": "1606.02556.pdf", "metadata": {"source": "CRF", "title": "DISCO Nets: DISsimilarity COefficient Networks", "authors": ["Diane Bouchacourt", "Sebastian Nowozin", "Pawan Kumar"], "emails": ["diane@robots.ox.ac.uk", "sebastian.nowozin@microsoft.com", "pawan@robots.ox.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "We are interested in the class of problems that require predicting a structured output y-Y = a simple example. Complex applications often have great uncertainty about the correct value of y. Consider, for example, the task of manually estimating depth images, where one wants to accurately estimate the pose of a hand that has given a depth image x. Depth images often have some occlusions and lack of depth values, and this leads to some uncertainties in the pose of the hand. Therefore, it is natural to use probability models that are able to represent this uncertainty. Often, the capacity of the model is limited and cannot perfectly represent the true distribution. In this case, the choice of the learning lens affects the final performance. Similar to Lacoste-Julien et al, we argue that the learning target should be tailored to the valuation loss in order to obtain the best performance in relation to this loss."}, {"heading": "2 Related Work", "text": "The idea behind it is that the idea of the idea of the real world is about that of the real world, namely the idea of the real world, the idea of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, of the real world, and of the real world, and of the real world, and of the real world, and of the real world, and of the real world."}, {"heading": "3 DISCO Nets", "text": "We begin by describing our model by defining how it can be used to generate samples from the posterior distribution, and how the samples can in turn be used to make a meaningful estimate. In the following subsection, we describe how to estimate the parameters of the model using a training dataset."}, {"heading": "3.1 Prediction", "text": "Sampling. A DISCO Net consists of several convolutionary and dense layers (interleaved by nonlinear function (s) and possibly pooling) and takes as input a pair (x, z) \u0445 X \u00b7 Z, where x is input data and z is some random noise. In the face of a pair (x, z), DISCO Net produces a value for output y. In the example of the manual estimation, the input depth image x is fed into the revolutionary layers. The output of the last Constitutional Layer is flattened and associated with a noise sample z. The resulting vector is fed into several dense layers, and the last dense layer outputs a y. From a single depth image x, DISCO Net produces different pose candidates for the depth image. This process is illustrated in Figure 2."}, {"heading": "3.2 Learning DISCO Nets", "text": "We want the DISCO networks to be modeled as accurately as possible, but with PG (y | x) is the actual probability of the data PT (y | x). In other words, PG (y | x) should be as similar as possible to PT (y | x). This similarity should be evaluated in terms of loss specific to the task at hand. Therefore, any non-negative symmetrical loss between two outputs (y, y) is with (y, y) Y \u00b7 Y, we employ a diversity coefficient that represents the expected loss between two random samples collected from the two distributions. PG (PG) The diversity coefficient is defined as: DIV (PT, PG) = X-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-diversity (y, y) PG-PG (x) PG-PG (y) PG-PG-PG (y) PG-x-x."}, {"heading": "4 Experiments : Hand Pose Estimation", "text": "In view of the depth x, which often contains occlusions and missing values, we would like to predict the hand posture y. We use the NYU Hand Pose dataset from Tompson et al. [26] to estimate the efficiency of DISCO networks for this task."}, {"heading": "4.1 Experimental Setup", "text": "It is the same kind of data processing as in Oberweger et al. [16, 17] and extracts a fixed quantity metric cube around the hand from the depth image. We reside the depth values within the depth image. We reside the depth processing as in Oberweger et al. [16, 17]. We reside the depth processing as in Oberweger et al. [16, 17], and extract a fixed quantity metric cube around the hand from the depth image. We reside the depth values within the depth image. We reside the depth processing as in Oberweger et al. [16, 17] and extract a fixed quantity metric cube around the hand from the depth image. We reside the depth values within the depth image."}, {"heading": "4.2 The Advantage of DISCO Nets over Non-Probabilistic Networks", "text": "Quantitative evaluation. Table 3 reports on the results of the test data set, crossing the parameters using the validation set of the two models we compared. We see that our probabilistic model DISCO\u03b2 = 1, \u03b3 = 0.5 outperforms the non-probabilistic models BASE\u03b2 = 1 in all metrics, confirming that DISCO\u03b2 = 1, \u03b3 = 0.5 performs best in all metrics for all values of C.Qualitative Evaluation. In Figure 3, we show candidate positions generated by DISCO\u03b2 = 1, \u03b3 = 0.5 for 3 test examples. The upper image shows the input depth image, and the lower image shows the ground-true pose (in grey) with 100 candidate outputs (overlaid in transparent red). The model predicts the joint positions and we interpolate the joints with an edge. If the input depth image, and the lower image set the uncertainty, the CO values are so different."}, {"heading": "4.3 Comparison with existing probabilistic models.", "text": "We consider the applications of the conditional generative adversarial network (cGAN) part of the training is fixed D by Mirza and Osindero [15] and to the best of our knowledge cGAN was not used to represent estimation. To compare cGAN with DISCO networks that do not require opponents represent estimation, several problems need to be overcome. First, we need to design a network architecture for the discriminator. This is a first disadvantage of cGAN compared to DISCO nets that do not require opponents. Second, as in Goodfellow et al. [6] and Radford et al. [20], GAN (and thus cGAN) require a very careful design of the network architecture and the training procedure. To make a fair comparison, we followed the work in Mirza and Osindero [15] and practical advice for GAN presented in Larsen and S\u00f8nDerby [12]. Generator G has the same network architecture as CODQU\u03b2 = 0.5 for the training."}, {"heading": "4.4 Reference state-of-the-art values.", "text": "We train the most powerful DISCO\u03b2 = 1, \u03b3 = 0.5 of Section 6.3 over the entire dataset and compare the performance with the most advanced methods in Table 5 and Figure 4. These state-of-the-art methods are specifically designed for estimating hand positions. In Oberweger et al. [16], a limited previous hand model, called NYU Prior, is refined on each hand to increase accuracy, called NYU Prior Refined. In Oberweger et al. [17], the entered depth image is transferred to a first network NYU Init, which issues a pose that synthesizes an image with a second network. The synthesized image is used with the entered depth image to derive an update of the pose. We refer to the entire model as NYU Feedback. On the contrary, DISCO Nets uses a single network whose architecture resembles the NYU Prior (without limitation to a previous) may be refined by embedding the embedded or the CO values."}, {"heading": "5 Discussion.", "text": "We introduced DISCO networks, a new family of probability models based on deep networks. DISCO networks use a prediction and training method based on minimizing a dissimilarity coefficient. Theoretically, this ensures that DISCO networks accurately capture uncertainty about the correct output in order to predict a given input. Experimental results in the task of manual estimation consistently support our theoretical hypothesis, since DISCO networks exceed non-probable equivalent models and existing probable models. In addition, DISCO networks can be tailored to the task to be performed, enabling a potential user to train them to solve various interesting problems. As their novelty mainly lies in their objective function, DISCO networks do not require a specific architecture and can easily be applied to new problems. We consider several directions for future work. First, we apply DISCO networks to other preliminary networks we would like to conduct on ISCO's secondary problems, or uncertainty about ISCO."}, {"heading": "6 Appendix", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Toy example experimental details.", "text": "In this section we provide details of the toy example presented in section 1. We used the following simple experimental estimate. All covariances for the bidimensional distributions are diagonal, so all bidimensional Gaussian distributions are parameterized by 4 parameters (\u00b51, \u00b52, \u03c31, \u03c32), where \u00b5 is a mean pair of variances on each dimension. We consider a data distribution that is a mixture of 2 bidimensional Gaussian distributions called GMM. The first Gaussian loss of the mixture, G1, is parameterized by (1, 1.5, 2, 0.8), and the second Gaussian loss is parameterized by (0, \u2212 0.5, 0.7, 0.6). The mixing weights are 0.7 and 0.3, so that GMM = 0.7 \u00b7 G1 \u00b7 G1 \u00b7 G2."}, {"heading": "6.2 Details on the MEU method", "text": "To select a single prediction y from the K candidate outputs recorded for x, the DISCO networks use the principle of the maximum expected utility (MEU).The prediction y task maximizes the expected benefit, or rather minimizes the expected task-specific loss. Formally, the prediction results as follows: y task = argmax k task [1, K] EU (yk) = argmin k task [1, K] K task (yk, y-k) (9), where (y1,..., yK) the candidate output corresponds to the single input x. For example, for a given input x we must select a pointer rotation to evaluate the Mean Joint Euclidean Error (MeJEE).We sample K candidate output values for the input x and select: y-MeJEE = argJ-JK [1, K] yk task (Mean-JEE) is evaluated."}, {"heading": "6.3 Experimental details", "text": "D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D\" D \"D."}], "references": [{"title": "Deep generative image models using a Laplacian pyramid of adversarial networks", "author": ["E.L. Denton", "S. Chintala", "A. Szlam", "R. Fergus"], "venue": "In NIPS", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Training generative neural networks via maximum mean discrepancy optimization", "author": ["G.K. Dziugaite", "D.M. Roy", "Z. Ghahramani"], "venue": "UAI", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Kernel Bayes\u2019 rule: Bayesian inference with positive definite kernels", "author": ["K. Fukumizu", "L. Song", "A. Gretton"], "venue": "JMLR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2013}, {"title": "Conditional generative adversarial nets for convolutional face generation", "author": ["J. Gauthier"], "venue": "Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2014}, {"title": "Strictly proper scoring rules", "author": ["T. Gneiting", "A.E. Raftery"], "venue": "prediction, and estimation. Journal of the American Statistical Association", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Generative adversarial nets", "author": ["I.J. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "Bing Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In NIPS", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "A kernel method for the two-sample problem", "author": ["A. Gretton", "K.M. Borgwardt", "M.J. Rasch", "B. Scholkopf", "A.J. Smola"], "venue": "NIPS", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2007}, {"title": "A kernel two-sample test", "author": ["A. Gretton", "K.M. Borgwardt", "M.J. Rasch", "B. Scholkopf", "A.J. Smola"], "venue": "JMLR", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Auto-encoding variational Bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "ICLR", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Modeling latent variable uncertainty for loss-based learning", "author": ["M.P. Kumar", "B. Packer", "D. Koller"], "venue": "ICML", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2012}, {"title": "Approximate inference for the loss-calibrated Bayesian", "author": ["S. Lacoste-Julien", "F. Huszar", "Z. Ghahramani"], "venue": "AISTATS", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2011}, {"title": "Generative moment matching networks", "author": ["Y. Li", "K. Swersky", "R. Zemel"], "venue": "ICML", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2015}, {"title": "Adversarial autoencoders", "author": ["A. Makhzani", "J. Shlens", "N. Jaitly", "I.J. Goodfellow"], "venue": "ICLR Workshop", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2015}, {"title": "Conditional generative adversarial nets", "author": ["M. Mirza", "S. Osindero"], "venue": "NIPS Deep Learning Workshop", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2014}, {"title": "Hands deep in deep learning for hand pose estimation", "author": ["M. Oberweger", "P. Wohlhart", "V. Lepetit"], "venue": "Computer Vision Winter Workshop", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2015}, {"title": "Training a Feedback Loop for Hand Pose Estimation", "author": ["M. Oberweger", "P. Wohlhart", "V. Lepetit"], "venue": "ICCV", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Some methods of speeding up the convergence of iteration methods", "author": ["B.T. Polyak"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1964}, {"title": "Empirical minimum Bayes risk prediction: How to extract an extra few% performance from vision models with just three more parameters", "author": ["V. Premachandran", "D. Tarlow", "D. Batra"], "venue": "CVPR", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "ICLR", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2015}, {"title": "Diversity and dissimilarity coefficients: A unified approach", "author": ["C.R. Rao"], "venue": "Theoretical Population Biology, pages Vol. 21, No. 1, pp 24\u201343", "citeRegEx": "21", "shortCiteRegEx": null, "year": 1982}, {"title": "Generative adversarial text to image synthesis", "author": ["S. Reed", "Z. Akata", "X. Yan", "L. Logeswaran", "H. Lee", "B. Schiele"], "venue": "ICML", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "The kernel trick for distances", "author": ["B. Sch\u00f6lkopf"], "venue": "In NIPS", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2001}, {"title": "Unsupervised and semi-supervised learning with categorical generative adversarial networks", "author": ["J.T. Springenberg"], "venue": "ICLR", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2016}, {"title": "The vitruvian Manifold: Inferring dense correspondences for oneshot human pose estimation", "author": ["J. Taylor", "J. Shotton", "T. Sharp", "A. Fitzgibbon"], "venue": "CVPR", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2012}, {"title": "Real-time continuous pose recovery of human hands using convolutional networks", "author": ["J. Tompson", "M. Stein", "Y. Lecun", "K. Perlin"], "venue": "ACM Transactions on Graphics", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2014}, {"title": "Attribute2image: Conditional image generation from visual attributes", "author": ["X. Yan", "J. Yang", "K. Sohn", "H. Lee"], "venue": "URL http://arxiv.org/abs/1512.00570", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}], "referenceMentions": [{"referenceID": 10, "context": "[11], we argue that the learning objective should be tailored to the evaluation loss in order to obtain the best performance with respect to this loss.", "startOffset": 0, "endOffset": 4}, {"referenceID": 19, "context": "The dissimilarity coefficient we employ was first introduced by Rao [21] and is defined for any non-negative symmetric loss function.", "startOffset": 68, "endOffset": 72}, {"referenceID": 5, "context": "[6] are very popular and have been used in several computer vision applications, for example in Denton et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[1], Radford et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20], Springenberg [24] and Yan et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "[20], Springenberg [24] and Yan et al.", "startOffset": 19, "endOffset": 23}, {"referenceID": 25, "context": "[27].", "startOffset": 0, "endOffset": 4}, {"referenceID": 5, "context": "[6] and Radford et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20], GAN models require very careful design of the networks\u2019 architecture.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "GAN models have been generalized to conditional GAN (cGAN) in Mirza and Osindero [15], where some additional input information can be fed to the Generator and the Discriminator.", "startOffset": 81, "endOffset": 85}, {"referenceID": 13, "context": "For example in Mirza and Osindero [15] a cGAN model generates tags corresponding to an image.", "startOffset": 34, "endOffset": 38}, {"referenceID": 3, "context": "Gauthier [4] applies cGAN to face generation.", "startOffset": 9, "endOffset": 12}, {"referenceID": 20, "context": "[22] propose to generate images of flowers with a cGAN model, where the conditional information is a word description of the flower to generate1.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2] and Li et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 11, "context": "[13] propose to train generative deep networks with an objective function based on the Maximum Mean Discrepancy (MMD) method.", "startOffset": 0, "endOffset": 4}, {"referenceID": 6, "context": "[7, 8], is a statistical hypothesis testing method to assess if two probabilistic", "startOffset": 0, "endOffset": 6}, {"referenceID": 7, "context": "[7, 8], is a statistical hypothesis testing method to assess if two probabilistic", "startOffset": 0, "endOffset": 6}, {"referenceID": 20, "context": "[22] and therefore cannot take advantage of this work in our experimental comparison.", "startOffset": 0, "endOffset": 4}, {"referenceID": 1, "context": "[2], the MMD test can been seen as playing the role of an adversary.", "startOffset": 0, "endOffset": 3}, {"referenceID": 8, "context": "The Variational Auto-Encoders (VAE) presented in Kingma and Welling [9] is composed of a probabilistic encoder and a probabilistic decoder.", "startOffset": 68, "endOffset": 71}, {"referenceID": 12, "context": "[14], where the authors propose to regularise autoencoders with an adversarial network.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[26], preprocessed as in Oberweger et al.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[19].", "startOffset": 0, "endOffset": 4}, {"referenceID": 0, "context": "DISC\u2206(PT , PG) = DIV\u2206(PT , PG)\u2212 \u03b3DIV\u2206(PG, PG)\u2212 (1\u2212 \u03b3)DIV\u2206(PT , PT ) (3) with \u03b3 \u2208 [0, 1].", "startOffset": 81, "endOffset": 87}, {"referenceID": 19, "context": "These coefficients were introduced by Rao [21] with \u03b3 = 1/2 and used for latent variable models in Kumar et al.", "startOffset": 42, "endOffset": 46}, {"referenceID": 9, "context": "[10].", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "However, if the dissimilarity coefficient of equation (4) is a strictly proper scoring rule as defined in Gneiting and Raftery [5], it is ensured to be minimised only when PG(y|x) is the true conditional distribution PT (y|x).", "startOffset": 127, "endOffset": 130}, {"referenceID": 4, "context": "By theorem 5 in Gneiting and Raftery [5], this is the case, for example, if we take as loss function \u2206\u03b2(y,y) = ||y \u2212 y||\u03b22 = ( \u2211dy i=1 |(y \u2212 y\u2032i|2) \u03b2/2 with \u03b2 \u2208 [0, 2] excluding 0 and 2, and use \u03b3 = 1 2 .", "startOffset": 37, "endOffset": 40}, {"referenceID": 1, "context": "By theorem 5 in Gneiting and Raftery [5], this is the case, for example, if we take as loss function \u2206\u03b2(y,y) = ||y \u2212 y||\u03b22 = ( \u2211dy i=1 |(y \u2212 y\u2032i|2) \u03b2/2 with \u03b2 \u2208 [0, 2] excluding 0 and 2, and use \u03b3 = 1 2 .", "startOffset": 161, "endOffset": 167}, {"referenceID": 6, "context": "[7, 8].", "startOffset": 0, "endOffset": 6}, {"referenceID": 7, "context": "[7, 8].", "startOffset": 0, "endOffset": 6}, {"referenceID": 21, "context": "Indeed as shown in Proposition 3 of Sch\u00f6lkopf [23], the function k : Y \u00d7 Y \u2192 R defined as k(y,y\u2032) = ||y \u2212 y||\u03b22 for 0 < \u03b2 \u2264 2 is a conditionally positive definite kernel, that is a specific type of positive definite kernel.", "startOffset": 46, "endOffset": 50}, {"referenceID": 24, "context": "[26] to estimate the efficiency of DISCO Nets for this task.", "startOffset": 0, "endOffset": 4}, {"referenceID": 24, "context": "[26] contains 8252 testing and 72,757 training frames of captured RGBD data with ground-truth hand pose information.", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16, 17] and use the same subset of J = 14 joints.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17] and use the same subset of J = 14 joints.", "startOffset": 0, "endOffset": 8}, {"referenceID": 14, "context": "[16, 17], and extract a fixed-size metric cube around the hand from the depth image.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17], and extract a fixed-size metric cube around the hand from the depth image.", "startOffset": 0, "endOffset": 8}, {"referenceID": 14, "context": "[16, 17] and Taylor et al.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17] and Taylor et al.", "startOffset": 0, "endOffset": 8}, {"referenceID": 23, "context": "[25], that", "startOffset": 0, "endOffset": 4}, {"referenceID": 14, "context": "[16, 17] present the metric FF as the most challenging metric for hand pose estimation.", "startOffset": 0, "endOffset": 8}, {"referenceID": 15, "context": "[16, 17] present the metric FF as the most challenging metric for hand pose estimation.", "startOffset": 0, "endOffset": 8}, {"referenceID": 2, "context": "[3], kernel density estimation fails in this scenario due to the high dimensionality of y.", "startOffset": 0, "endOffset": 3}, {"referenceID": 15, "context": "[17].", "startOffset": 0, "endOffset": 4}, {"referenceID": 16, "context": "9 (see Polyak [18]).", "startOffset": 14, "endOffset": 18}, {"referenceID": 13, "context": "We consider the applications of the conditional Generative Adversarial Networks (cGAN) model from Mirza and Osindero [15] and to the best of our knowledge cGAN has not been applied to pose estimation.", "startOffset": 117, "endOffset": 121}, {"referenceID": 5, "context": "[6] and Radford et al.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "[20], GAN (and thus cGAN) require very careful design of the networks\u2019 architecture and training procedure.", "startOffset": 0, "endOffset": 4}, {"referenceID": 13, "context": "In order to do a fair comparison, we followed the work in Mirza and Osindero [15] and practical advice for GAN presented in Larsen and S\u00f8nderby [12].", "startOffset": 77, "endOffset": 81}, {"referenceID": 13, "context": "This is a setting similar to the one employed for tag-annotation of images in Mirza and Osindero [15] 3.", "startOffset": 97, "endOffset": 101}, {"referenceID": 14, "context": "[16] a constrained prior hand model, referred as NYU-Prior, is refined on each hand joint position to increase accuracy, referred as NYU-Prior-Refined.", "startOffset": 0, "endOffset": 4}, {"referenceID": 15, "context": "[17], the input depth image is fed to a first network NYU-Init, that outputs a pose used to synthesize an image with a second network.", "startOffset": 0, "endOffset": 4}], "year": 2017, "abstractText": "We present a new type of probabilistic model which we call DISsimilarity COefficient Networks (DISCO Nets). DISCO Nets allow us to efficiently sample from a posterior distribution parametrised by a neural network. During training, DISCO Nets are learned by minimising the dissimilarity coefficient between the true distribution and the estimated distribution. This allows us to tailor the training to the loss related to the task at hand. We empirically show that (i) by modeling uncertainty on the output value, DISCO Nets outperform equivalent non-probabilistic predictive networks and (ii) DISCO Nets accurately model the uncertainty of the output, outperforming existing probabilistic models based on deep neural networks.", "creator": "LaTeX with hyperref package"}}}