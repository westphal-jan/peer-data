{"id": "1606.02638", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Jun-2016", "title": "Addressing Limited Data for Textual Entailment Across Domains", "abstract": "We seek to address the lack of labeled data (and high cost of annotation) for textual entailment in some domains. To that end, we first create (for experimental purposes) an entailment dataset for the clinical domain, and a highly competitive supervised entailment system, ENT, that is effective (out of the box) on two domains. We then explore self-training and active learning strategies to address the lack of labeled data. With self-training, we successfully exploit unlabeled data to improve over ENT by 15% F-score on the newswire domain, and 13% F-score on clinical data. On the other hand, our active learning experiments demonstrate that we can match (and even beat) ENT using only 6.6% of the training data in the clinical domain, and only 5.8% of the training data in the newswire domain.", "histories": [["v1", "Wed, 8 Jun 2016 16:56:19 GMT  (667kb,D)", "http://arxiv.org/abs/1606.02638v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["chaitanya p shivade", "preethi raghavan", "siddharth patwardhan"], "accepted": true, "id": "1606.02638"}, "pdf": {"name": "1606.02638.pdf", "metadata": {"source": "CRF", "title": "Addressing Limited Data for Textual Entailment Across Domains", "authors": ["Chaitanya Shivade", "Preethi Raghavan", "Siddharth Patwardhan"], "emails": ["shivade@cse.ohio-state.edu", "praghav@us.ibm.com", "siddharth@us.ibm.com"], "sections": [{"heading": "1 Introduction", "text": "The challenges of RTE (Bentivogli et al., 2009; Bentivogli et al., 2011) have led to a variety of approaches to text recognition via messaging, which was carried out during an internship at the IBMA's variation on this task, with the search for text transmissions as the focus of RTE-5 and subsequent challenges, with the goal of finding all sentences in a corpus that implies a predetermined hypothesis. The data generated by these challenges and the availability of disks has produced many creative solutions to this problem."}, {"heading": "2 Related work", "text": "This year it has come to the point where it will be able to retaliate, \"he said in an interview with the\" Welt am Sonntag. \""}, {"heading": "3 Datasets", "text": "In this section we describe the data sets from two areas, Newswire and Clinical, which we use in the development and evaluation of our work."}, {"heading": "3.1 Newswire Domain", "text": "For the Newswire domain, we use search data from the PASCAL RTE-5, RTE-6 and RTE-7 challenges (Bentivogli et al., 2009; Bentivogli et al., 2010; Bentivogli et al., 2011).The dataset consists of a corpus of news documents along with a set of hypotheses. The hypotheses originate from a separate summary task, where the summary sentences for a news story (with a topic) are created manually by human commentators. These summary sentences are used as hypotheses in the dataset. Entailment notes are then provided for a subset of sentences from the document corpus, based on a Lucene filter for each hypothesis. In this work, we use the RTE-5 development data to train our system (Newswire-train), RTE-5 test data to evaluate our systems (Newswiretest) and the combined data for the development of our RTE-6 and RTE-E-7 systems."}, {"heading": "3.2 Clinical Domain", "text": "rE \"s tis rf\u00fc eid rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the r"}, {"heading": "4 Supervised Entailment System", "text": "We begin in this section with the definition of our Monitored Withdrawal System (ENT), which serves as the basis for our self-training and active learning experiments.Our system is based on the characteristics and characteristics of systems that have previously been successful in the RTE challenges in the newswire area. We are expanding this system with new clinical-oriented features. The aim of this section is to demonstrate, through an experimental comparison with other withdrawal systems, that ENT is competitive in both areas and represents a reasonable supervised system that we can use in our studies of self-training and active learning."}, {"heading": "4.1 System Description", "text": "In fact, it is the case that most people who have established themselves in politics and business in recent years, in politics and business, have come up with the idea of outdoing themselves because they are able to outdo themselves, \"he told the Deutsche Presse-Agentur.\" I don't think we will be able to establish ourselves in politics, \"he said.\" But I think we will be able to change the world. \"He added,\" I don't think we will be able to change the world. \""}, {"heading": "4.2 System Performance", "text": "To compare the effectiveness of the ENG task, we chose two publicly available systems - EDITS and TIE - for comparison. Both systems are available under the Excitement Open Platform (EOP), one initiative (Kouylekov and Negri) is an open source system that provides a set of rules and resources to convert it into the hypothesis."}, {"heading": "5 Self-Training", "text": "Our goal is to exploit unlabeled data, with the hope of extending the limited threshold of annotated data in a given area. Self-training is a method that has been successfully used to address limited training data on many NLP tasks, such as parsing (McClosky et al., 2006), information extraction (Huang and Riloff, 2012; Patwardhan and Riloff, 2007), literal disambiguation (Mihalcea, 2004), etc. Self-training iteratively increases the size of the threshold of the training by automatically assigning labels to unlabeled examples, using a model that was trained in an earlier iteration of the self-training regime.For our message wire and clinical datasets, using the set of unlabeled text-hypotheses pairs U, we have the following training regime: A model was created using the training data Ln, and the unlabeled data were classified as having high levels of safety by all the unlabeled data pairs U."}, {"heading": "6 Active Learning", "text": "Active learning is a popular educational paradigm in machine learning (Settles, 2012), in which a learning agent interacts with his environment rather than passively obtaining independent samples from an underlying distribution, which is particularly relevant in the clinical field, where the input of a medical professional is sought only when it is really necessary because of the high price of such input. The purpose of exploring this paradigm is to achieve the best possible generalization performance at the lowest cost. Active learning is an iterative process and typically works as follows: a ModelM is trained using a minimal training dataset; a quantum frame is used to identify an instance of an unlabeled set of U that leads to maximum expected benefit."}, {"heading": "7 Effect of Class Distribution", "text": "After analyzing our experimental results, we considered a possible explanation for the improvements compared to the initial situation to be plausible due to the changes in class distribution. Table 1 shows that the distribution of classes in both areas is highly distorted (only 4-5% positive instances). Self-training and active learning dramatically change class distribution in education. To assess the impact of class distribution on performance, we conducted additional experiments described here.We first examined sub-sampling (Japkowicz, 2000) training data to address class imbalance, including sampling the majority class or increasing the minority class until the classes are balanced."}, {"heading": "8 Conclusion", "text": "We investigated the problem of finding text links in two areas - newswire and clinical - focusing on the cost of obtaining tagged data in specific areas, first creating a clinical dataset and a highly competitive, monitored ENT system that is effective (out of the box) in two areas, then examining two strategies - self-training and active learning - to address the lack of tagged data and finding some interesting results. Our ENT self-training system improved significantly over ENT, achieving an F-score gain of 15% in newswire and 13% in clinical, using only additional, untagged data. On the other hand, our active learning experiments showed that we were able to compare (and even exceed) the basic ENT system with only 6.6% of clinical training data and only 5.8% of newswire training data."}, {"heading": "Acknowledgments", "text": "We thank our in-house medical expert Jennifer Liang for providing guidance on data annotation, our medical annotators for annotating clinical data for us, and Murthy Devarakonda for valuable insights during the project. We also thank Eric Fosler-Lussier and Albert M. Lai for their help in designing this work."}], "references": [{"title": "The Fifth PASCAL Recognizing Textual Entailment Challenge", "author": ["Luisa Bentivogli", "Ido Dagan", "Hoa Trang Dang", "Danilo Giampiccolo", "Bernardo Magnini."], "venue": "Proceedings of the Second Text Analysis Conference, Gaithersburg, MD.", "citeRegEx": "Bentivogli et al\\.,? 2009", "shortCiteRegEx": "Bentivogli et al\\.", "year": 2009}, {"title": "The Sixth PASCAL Recognizing Textual Entailment Challenge", "author": ["Luisa Bentivogli", "Peter Clark", "Ido Dagan", "Danilo Giampiccolo."], "venue": "Proceedings of the Third Text Analysis Conference, Gaithersburg, MD.", "citeRegEx": "Bentivogli et al\\.,? 2010", "shortCiteRegEx": "Bentivogli et al\\.", "year": 2010}, {"title": "The Seventh PASCAL Recognizing Textual Entailment Challenge", "author": ["Luisa Bentivogli", "Peter Clark", "Ido Dagan", "Danilo Giampiccolo."], "venue": "Proceedings of the Fourth Text Analysis Conference, Gaithersburg, MD.", "citeRegEx": "Bentivogli et al\\.,? 2011", "shortCiteRegEx": "Bentivogli et al\\.", "year": 2011}, {"title": "The Unified Medical Language System (UMLS): Integrating Biomedical Terminology", "author": ["Olivier Bodenreider."], "venue": "Nucleic Acids Research, 32(Database Issue):D267\u2013D270.", "citeRegEx": "Bodenreider.,? 2004", "shortCiteRegEx": "Bodenreider.", "year": 2004}, {"title": "A large annotated corpus for learning natural language inference", "author": ["Samuel Bowman", "Gabor Angeli", "Christopher Potts", "Christopher Manning."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 632\u2013", "citeRegEx": "Bowman et al\\.,? 2015", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Generating an Entailment Corpus from News Headlines", "author": ["John Burger", "Lisa Ferro."], "venue": "Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, pages 49\u201354, Ann Arbor, MI.", "citeRegEx": "Burger and Ferro.,? 2005", "shortCiteRegEx": "Burger and Ferro.", "year": 2005}, {"title": "A Graph-based Semi-Supervised Learning for Question-Answering", "author": ["Asli Celikyilmaz", "Marcus Thint", "Zhiheng Huang."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on", "citeRegEx": "Celikyilmaz et al\\.,? 2009", "shortCiteRegEx": "Celikyilmaz et al\\.", "year": 2009}, {"title": "SMOTE: Synthetic Minority Over-sampling Technique", "author": ["Nitesh V. Chawla", "Kevin W. Bowyer", "Lawrence O. Hall", "W. Philip Kegelmeyer."], "venue": "Journal of Artificial Intelligence Research, 16:321\u2013357.", "citeRegEx": "Chawla et al\\.,? 2002", "shortCiteRegEx": "Chawla et al\\.", "year": 2002}, {"title": "Recognizing Textual Entailment: Models and Applications", "author": ["Ido Dagan", "Dan Roth", "Mark Sammons", "Fabio Massimo Zanzotto."], "venue": "Synthesis Lectures on Human Language Technologies, 6(4):1\u2013220.", "citeRegEx": "Dagan et al\\.,? 2013", "shortCiteRegEx": "Dagan et al\\.", "year": 2013}, {"title": "The WEKA Data Mining Software", "author": ["Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H. Witten."], "venue": "ACM SIGKDD Explorations Newsletter, 11(1):10.", "citeRegEx": "Hall et al\\.,? 2009", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "A Discourse Commitment-based Framework for Recognizing Textual Entailment", "author": ["Andrew Hickl", "Jeremy Bensley."], "venue": "Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 171\u2013176.", "citeRegEx": "Hickl and Bensley.,? 2007", "shortCiteRegEx": "Hickl and Bensley.", "year": 2007}, {"title": "Recognizing Textual Entailment with LCCs Groundhog System", "author": ["Andrew Hickl", "Jeremy Bensley", "John Williams", "Kirk Roberts", "Bryan Rink", "Ying Shi."], "venue": "Proceedings of the Second PASCAL Challenges Workshop.", "citeRegEx": "Hickl et al\\.,? 2006", "shortCiteRegEx": "Hickl et al\\.", "year": 2006}, {"title": "Bootstrapped Training of Event Extraction Classifiers", "author": ["Ruihong Huang", "Ellen Riloff."], "venue": "Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 286\u2013295, Avignon, France.", "citeRegEx": "Huang and Riloff.,? 2012", "shortCiteRegEx": "Huang and Riloff.", "year": 2012}, {"title": "Learning from Imbalanced Data Sets: A Comparison of Various Strategies", "author": ["Nathalie Japkowicz."], "venue": "AAAI Workshop on Learning from Imbalanced Data Sets, pages 10\u201315.", "citeRegEx": "Japkowicz.,? 2000", "shortCiteRegEx": "Japkowicz.", "year": 2000}, {"title": "PKUTM Participation at TAC 2010 RTE and Summarization Track", "author": ["Houping Jia", "Xiaojiang Huang", "Tengfei Ma", "Xiaojun Wan", "Jianguo Xiao."], "venue": "Proceedings of the Third Text Analysis Conference, Gaithersburg, MD.", "citeRegEx": "Jia et al\\.,? 2010", "shortCiteRegEx": "Jia et al\\.", "year": 2010}, {"title": "An Open-Source Package for Recognizing Textual Entailment", "author": ["Milen Kouylekov", "Matteo Negri."], "venue": "Proceedings of the ACL 2010 System Demonstrations, Uppsala, Sweden.", "citeRegEx": "Kouylekov and Negri.,? 2010", "shortCiteRegEx": "Kouylekov and Negri.", "year": 2010}, {"title": "A Sequential Algorithm for Training Text Classifiers", "author": ["David D. Lewis", "William A. Gale."], "venue": "Proceedings of the 17th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 3\u201312, Dublin, Ireland.", "citeRegEx": "Lewis and Gale.,? 1994", "shortCiteRegEx": "Lewis and Gale.", "year": 1994}, {"title": "The Excitement Open Platform for Textual Inferences", "author": ["Bernardo Magnini", "Roberto Zanoli", "Ido Dagan", "Kathrin Eichler", "Neumann Guenter", "Tae-Gil Noh", "Sebastian Pad\u00f3", "Asher Stern", "Omer Levy."], "venue": "Proceedings of 52nd Annual Meeting of the Associa-", "citeRegEx": "Magnini et al\\.,? 2014", "shortCiteRegEx": "Magnini et al\\.", "year": 2014}, {"title": "Effective Self-Training for Parsing", "author": ["David McClosky", "Eugene Charniak", "Mark Johnson."], "venue": "Proceedings of Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 152\u2013", "citeRegEx": "McClosky et al\\.,? 2006", "shortCiteRegEx": "McClosky et al\\.", "year": 2006}, {"title": "Slot Grammar: A System for Simpler Construction of Practical Natural Language Grammars", "author": ["Michael McCord."], "venue": "Proceedings of the International Symposium on Natural Language and Logic, pages 118\u2013145.", "citeRegEx": "McCord.,? 1989", "shortCiteRegEx": "McCord.", "year": 1989}, {"title": "UMLS-Interface and UMLSSimilarity : Open Source Software for Measuring Paths and Semantic Similarity", "author": ["Bridget T McInnes", "Ted Pedersen", "Serguei V.S. Pakhomov."], "venue": "Proceedings of the Annual Symposium of the American Medical In-", "citeRegEx": "McInnes et al\\.,? 2009", "shortCiteRegEx": "McInnes et al\\.", "year": 2009}, {"title": "Co-Training and Self-Training for Word Sense Disambiguation", "author": ["Rada Mihalcea."], "venue": "Proceedings of the Eighth Conference on Natural Language Learning, pages 33\u201340, Boston, MA.", "citeRegEx": "Mihalcea.,? 2004", "shortCiteRegEx": "Mihalcea.", "year": 2004}, {"title": "Addressing Discourse and Document Structure in the RTE Search Task", "author": ["Shachar Mirkin", "Roy Bar-Haim", "Jonathan Berant", "Ido Dagan", "Eyal Shnarch", "Asher Stern", "Idan Szpektor."], "venue": "Proceedings of the Second Text Analysis Conference, Gaithersburg,", "citeRegEx": "Mirkin et al\\.,? 2009", "shortCiteRegEx": "Mirkin et al\\.", "year": 2009}, {"title": "A Study on Convolution Kernels for Shallow Statistic Parsing", "author": ["Alessandro Moschitti."], "venue": "Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 335\u2013342, Barcelona, Spain.", "citeRegEx": "Moschitti.,? 2004", "shortCiteRegEx": "Moschitti.", "year": 2004}, {"title": "Effective Information Extraction with Semantic Affinity Patterns and Relevant Regions", "author": ["Siddharth Patwardhan", "Ellen Riloff."], "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computa-", "citeRegEx": "Patwardhan and Riloff.,? 2007", "shortCiteRegEx": "Patwardhan and Riloff.", "year": 2007}, {"title": "Measures of Semantic Similarity and Relatedness in the Biomedical Domain", "author": ["Ted Pedersen", "Serguei V.S. Pakhomov", "Siddharth Patwardhan", "Christopher G Chute."], "venue": "Journal of Biomedical Informatics, 40(3):288\u201399.", "citeRegEx": "Pedersen et al\\.,? 2007", "shortCiteRegEx": "Pedersen et al\\.", "year": 2007}, {"title": "Multi-Task Active Learning for Linguistic Annotations", "author": ["Roi Reichart", "Katrin Tomanek", "Udo Hahn", "Ari Rappoport."], "venue": "Proceedings of ACL-08: HLT, pages 861\u2013869, Columbus, OH.", "citeRegEx": "Reichart et al\\.,? 2008", "shortCiteRegEx": "Reichart et al\\.", "year": 2008}, {"title": "An Analysis of Active Learning Strategies for Sequence Labeling Tasks", "author": ["Burr Settles", "Mark Craven."], "venue": "Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 1070\u20131079, Honolulu, HI.", "citeRegEx": "Settles and Craven.,? 2008", "shortCiteRegEx": "Settles and Craven.", "year": 2008}, {"title": "Active Learning", "author": ["Burr Settles."], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning, 6(1):1\u2013114.", "citeRegEx": "Settles.,? 2012", "shortCiteRegEx": "Settles.", "year": 2012}, {"title": "Textual Inference for Eligibility Criteria Resolution in Clinical trials", "author": ["Chaitanya Shivade", "Courtney Hebert", "Marcelo Loptegui", "Marie-Catherine de Marneffe", "Eric Fosler-Lussier", "Albert M. Lai."], "venue": "Journal of Biomedical Informatics,", "citeRegEx": "Shivade et al\\.,? 2015", "shortCiteRegEx": "Shivade et al\\.", "year": 2015}, {"title": "IKOMA at TAC2011 : A Method for Recognizing Textual Entailment using Lexical-level and Sentence Structurelevel Features", "author": ["Masaaki Tsuchida", "Kai Ishikawa."], "venue": "Proceedings of the Fourth Text Analysis Conference, Gaithersburg, MD.", "citeRegEx": "Tsuchida and Ishikawa.,? 2011", "shortCiteRegEx": "Tsuchida and Ishikawa.", "year": 2011}, {"title": "Recognizing Textual Relatedness with Predicate-Argument Structures", "author": ["Rui Wang", "Yi Zhang."], "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 784\u2013792, Singapore.", "citeRegEx": "Wang and Zhang.,? 2009", "shortCiteRegEx": "Wang and Zhang.", "year": 2009}, {"title": "Relation Extraction with Relation Topics", "author": ["Chang Wang", "James Fan", "Aditya Kalyanpur", "David Gondek."], "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1426\u20131436, Edinburgh, UK.", "citeRegEx": "Wang et al\\.,? 2011", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Relation Extraction and Scoring in DeepQA", "author": ["Chang Wang", "Aditya Kalyanpur", "James Fan", "Branimir K. Boguraev", "David Gondek."], "venue": "IBM Journal of Research and Development, 56(3.4):9:1\u20139:12.", "citeRegEx": "Wang et al\\.,? 2012", "shortCiteRegEx": "Wang et al\\.", "year": 2012}, {"title": "Automatic Learning of Textual Entailments with Cross-Pair Similarities", "author": ["Fabio M. Zanzotto", "Alessandro Moschitti."], "venue": "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association", "citeRegEx": "Zanzotto and Moschitti.,? 2006", "shortCiteRegEx": "Zanzotto and Moschitti.", "year": 2006}, {"title": "Expanding Textual Entailment Corpora from Wikipedia using Co-training", "author": ["Fabio M. Zanzotto", "Marco Pennacchiotti."], "venue": "Proceedings of the 2nd Workshop on The People\u2019s Web Meets NLP: Collaboratively Constructed Semantic Resources,", "citeRegEx": "Zanzotto and Pennacchiotti.,? 2010", "shortCiteRegEx": "Zanzotto and Pennacchiotti.", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "The RTE challenges (Bentivogli et al., 2009; Bentivogli et al., 2011) have spurred considerable research in textual entailment over newswire data.", "startOffset": 19, "endOffset": 69}, {"referenceID": 2, "context": "The RTE challenges (Bentivogli et al., 2009; Bentivogli et al., 2011) have spurred considerable research in textual entailment over newswire data.", "startOffset": 19, "endOffset": 69}, {"referenceID": 4, "context": "This, along with the availability of large-scale datasets labeled with entailment information (Bowman et al., 2015), has resulted in a variety of approaches for textual entailment recognition.", "startOffset": 94, "endOffset": 115}, {"referenceID": 8, "context": "Recognizing Textual Entailment (RTE) shared tasks (Dagan et al., 2013) conducted annually", "startOffset": 50, "endOffset": 70}, {"referenceID": 0, "context": "RTE-5 (Bentivogli et al., 2009) then introduced the task of entailment", "startOffset": 6, "endOffset": 31}, {"referenceID": 1, "context": "Subsequently, RTE-6 (Bentivogli et al., 2010) and RTE-7 (Bentivogli et al.", "startOffset": 20, "endOffset": 45}, {"referenceID": 2, "context": ", 2010) and RTE-7 (Bentivogli et al., 2011) featured entailment search as the primary task, but constrained the search space to only those candidate sentences that were first retrieved by Lucene, an open source search engine1.", "startOffset": 18, "endOffset": 43}, {"referenceID": 22, "context": "Successful approaches for entailment (Mirkin et al., 2009; Jia et al., 2010; Tsuchida and Ishikawa, 2011) have relied on annotated data to either train classifiers, or to develop rules for detecting entailing sentences.", "startOffset": 37, "endOffset": 105}, {"referenceID": 14, "context": "Successful approaches for entailment (Mirkin et al., 2009; Jia et al., 2010; Tsuchida and Ishikawa, 2011) have relied on annotated data to either train classifiers, or to develop rules for detecting entailing sentences.", "startOffset": 37, "endOffset": 105}, {"referenceID": 30, "context": "Successful approaches for entailment (Mirkin et al., 2009; Jia et al., 2010; Tsuchida and Ishikawa, 2011) have relied on annotated data to either train classifiers, or to develop rules for detecting entailing sentences.", "startOffset": 37, "endOffset": 105}, {"referenceID": 5, "context": "Operating under the assumption that more labeled data would improve system performance, some researchers have sought to augment their training data with automatically or semi-automatically obtained labeled pairs (Burger and Ferro, 2005; Hickl et al., 2006; Hickl and Bensley, 2007; Zanzotto and Pennacchiotti, 2010; Celikyilmaz et al., 2009).", "startOffset": 212, "endOffset": 341}, {"referenceID": 11, "context": "Operating under the assumption that more labeled data would improve system performance, some researchers have sought to augment their training data with automatically or semi-automatically obtained labeled pairs (Burger and Ferro, 2005; Hickl et al., 2006; Hickl and Bensley, 2007; Zanzotto and Pennacchiotti, 2010; Celikyilmaz et al., 2009).", "startOffset": 212, "endOffset": 341}, {"referenceID": 10, "context": "Operating under the assumption that more labeled data would improve system performance, some researchers have sought to augment their training data with automatically or semi-automatically obtained labeled pairs (Burger and Ferro, 2005; Hickl et al., 2006; Hickl and Bensley, 2007; Zanzotto and Pennacchiotti, 2010; Celikyilmaz et al., 2009).", "startOffset": 212, "endOffset": 341}, {"referenceID": 35, "context": "Operating under the assumption that more labeled data would improve system performance, some researchers have sought to augment their training data with automatically or semi-automatically obtained labeled pairs (Burger and Ferro, 2005; Hickl et al., 2006; Hickl and Bensley, 2007; Zanzotto and Pennacchiotti, 2010; Celikyilmaz et al., 2009).", "startOffset": 212, "endOffset": 341}, {"referenceID": 6, "context": "Operating under the assumption that more labeled data would improve system performance, some researchers have sought to augment their training data with automatically or semi-automatically obtained labeled pairs (Burger and Ferro, 2005; Hickl et al., 2006; Hickl and Bensley, 2007; Zanzotto and Pennacchiotti, 2010; Celikyilmaz et al., 2009).", "startOffset": 212, "endOffset": 341}, {"referenceID": 10, "context": "Hickl et al. (2006) improves upon this work by including negative examples selected using heuristic rules (e.", "startOffset": 0, "endOffset": 20}, {"referenceID": 10, "context": "However, Hickl and Bensley (2007) achieves only a 1% accuracy improvement on RTE-3 using the same method, suggesting that it is not always as beneficial.", "startOffset": 9, "endOffset": 34}, {"referenceID": 4, "context": "Recent work by Bowman et al. (2015) describes a method for generating large scale annotated datasets, viz.", "startOffset": 15, "endOffset": 36}, {"referenceID": 34, "context": "Using a previously published system for RTE (Zanzotto and Moschitti, 2006), they show that their expanded corpus does not result in improvement for RTE-1, RTE-2 or RTE-3.", "startOffset": 44, "endOffset": 74}, {"referenceID": 6, "context": "Similarly, Celikyilmaz et al. (2009) address the", "startOffset": 11, "endOffset": 37}, {"referenceID": 0, "context": "For the newswire domain, we use entailment search data from the PASCAL RTE-5, RTE-6 and RTE-7 challenges (Bentivogli et al., 2009; Bentivogli et al., 2010; Bentivogli et al., 2011).", "startOffset": 105, "endOffset": 180}, {"referenceID": 1, "context": "For the newswire domain, we use entailment search data from the PASCAL RTE-5, RTE-6 and RTE-7 challenges (Bentivogli et al., 2009; Bentivogli et al., 2010; Bentivogli et al., 2011).", "startOffset": 105, "endOffset": 180}, {"referenceID": 2, "context": "For the newswire domain, we use entailment search data from the PASCAL RTE-5, RTE-6 and RTE-7 challenges (Bentivogli et al., 2009; Bentivogli et al., 2010; Bentivogli et al., 2011).", "startOffset": 105, "endOffset": 180}, {"referenceID": 30, "context": "Top systems (Tsuchida and Ishikawa, 2011; Mirkin et al., 2009) in the RTE challenges have used various types of passage matching ap-", "startOffset": 12, "endOffset": 62}, {"referenceID": 22, "context": "Top systems (Tsuchida and Ishikawa, 2011; Mirkin et al., 2009) in the RTE challenges have used various types of passage matching ap-", "startOffset": 12, "endOffset": 62}, {"referenceID": 9, "context": "In our system, we employ a logistic regression with ridge estimator (the Weka implementation (Hall et al., 2009)), powered by a variety of passage matching features described below.", "startOffset": 93, "endOffset": 112}, {"referenceID": 3, "context": "some medical domain term matchers as well \u2013 using UMLS (Bodenreider, 2004) and a rule-based \u201ctranslator\u201d of medical terms to layman terms3.", "startOffset": 55, "endOffset": 74}, {"referenceID": 29, "context": "UMLS concept overlap, and a measure of UMLS-based similarity (Shivade et al., 2015; Pedersen et al., 2007) using the UMLS::Similarity tool (McInnes et al.", "startOffset": 61, "endOffset": 106}, {"referenceID": 25, "context": "UMLS concept overlap, and a measure of UMLS-based similarity (Shivade et al., 2015; Pedersen et al., 2007) using the UMLS::Similarity tool (McInnes et al.", "startOffset": 61, "endOffset": 106}, {"referenceID": 20, "context": ", 2007) using the UMLS::Similarity tool (McInnes et al., 2009).", "startOffset": 40, "endOffset": 62}, {"referenceID": 31, "context": "Syntactic: Following the lead of several approaches textual entailment (Wang and Zhang, 2009; Mirkin et al., 2009; Kouylekov and Negri, 2010) we have a features measuring the similarity of parse trees.", "startOffset": 71, "endOffset": 141}, {"referenceID": 22, "context": "Syntactic: Following the lead of several approaches textual entailment (Wang and Zhang, 2009; Mirkin et al., 2009; Kouylekov and Negri, 2010) we have a features measuring the similarity of parse trees.", "startOffset": 71, "endOffset": 141}, {"referenceID": 15, "context": "Syntactic: Following the lead of several approaches textual entailment (Wang and Zhang, 2009; Mirkin et al., 2009; Kouylekov and Negri, 2010) we have a features measuring the similarity of parse trees.", "startOffset": 71, "endOffset": 141}, {"referenceID": 19, "context": "Our rule-based syntactic parser (McCord, 1989) produces dependency parses the text-hypothesis pair, whose nodes are aligned using all of the term matchers.", "startOffset": 32, "endOffset": 46}, {"referenceID": 23, "context": "The tree match feature is an aggregation of the aligned subgraphs in the tree (somewhat similar to a tree kernel (Moschitti, 2004)).", "startOffset": 113, "endOffset": 130}, {"referenceID": 32, "context": "htm Semantic: We apply open domain as well as medical entity and relation detectors (Wang et al., 2011; Wang et al., 2012) to the texts, and post features measuring overlap in detected entities and overlap in the detected relations across the text-hypothesis pair.", "startOffset": 84, "endOffset": 122}, {"referenceID": 33, "context": "htm Semantic: We apply open domain as well as medical entity and relation detectors (Wang et al., 2011; Wang et al., 2012) to the texts, and post features measuring overlap in detected entities and overlap in the detected relations across the text-hypothesis pair.", "startOffset": 84, "endOffset": 122}, {"referenceID": 17, "context": "Both these system are available under the Excitement Open Platform (EOP), an initiative (Magnini et al., 2014) to make tools for textual entailment freely available4 to the NLP community.", "startOffset": 88, "endOffset": 110}, {"referenceID": 31, "context": "The Textual Inference Engine (TIE) (Wang and Zhang, 2009) is a maximum entropy based entailment system relying on predicate argument structure matching.", "startOffset": 35, "endOffset": 57}, {"referenceID": 15, "context": "EDITS (Edit Distance Textual Entailment Suite) by Kouylekov and Negri (2010) is an open source textual entailment system that uses a set of rules and resources to perform \u201cedit\u201d operations on the text to convert it into the hypothesis.", "startOffset": 50, "endOffset": 77}, {"referenceID": 22, "context": "30 and the best system (Mirkin et al., 2009) achieved an F-Score of 0.", "startOffset": 23, "endOffset": 44}, {"referenceID": 18, "context": "Self-training is a method that has been successfully used to address limited training data on many NLP tasks, such as parsing (McClosky et al., 2006), information extraction (Huang and Riloff, 2012; Patwardhan and Riloff, 2007), word sense disambiguation (Mi-", "startOffset": 126, "endOffset": 149}, {"referenceID": 12, "context": ", 2006), information extraction (Huang and Riloff, 2012; Patwardhan and Riloff, 2007), word sense disambiguation (Mi-", "startOffset": 32, "endOffset": 85}, {"referenceID": 24, "context": ", 2006), information extraction (Huang and Riloff, 2012; Patwardhan and Riloff, 2007), word sense disambiguation (Mi-", "startOffset": 32, "endOffset": 85}, {"referenceID": 22, "context": "54 \u2013 substantially better than the best performing system of Mirkin et al. (2009) (F-score, 0.", "startOffset": 61, "endOffset": 82}, {"referenceID": 28, "context": "Active learning is a popular training paradigm in machine learning (Settles, 2012) where a learning agent interacts with its environment in acquiring a training set, rather than passively receiving independent samples from an underlying distribution.", "startOffset": 67, "endOffset": 82}, {"referenceID": 16, "context": "We carried out active learning in this setting using a querying framework known as uncertainty sampling (Lewis and Gale, 1994).", "startOffset": 104, "endOffset": 126}, {"referenceID": 27, "context": "Following previous work (Settles and Craven, 2008; Reichart et al., 2008) we evaluate active learning using learning curves on the test set.", "startOffset": 24, "endOffset": 73}, {"referenceID": 26, "context": "Following previous work (Settles and Craven, 2008; Reichart et al., 2008) we evaluate active learning using learning curves on the test set.", "startOffset": 24, "endOffset": 73}, {"referenceID": 13, "context": "We first investigated sub-sampling (Japkowicz, 2000) the training data to address class imbalance.", "startOffset": 35, "endOffset": 52}, {"referenceID": 7, "context": "ance is to apply Synthetic Minority Oversampling Technique (SMOTE) (Chawla et al., 2002).", "startOffset": 67, "endOffset": 88}], "year": 2016, "abstractText": "We seek to address the lack of labeled data (and high cost of annotation) for textual entailment in some domains. To that end, we first create (for experimental purposes) an entailment dataset for the clinical domain, and a highly competitive supervised entailment system, ENT, that is effective (out of the box) on two domains. We then explore self-training and active learning strategies to address the lack of labeled data. With self-training, we successfully exploit unlabeled data to improve over ENT by 15% F-score on the newswire domain, and 13% F-score on clinical data. On the other hand, our active learning experiments demonstrate that we can match (and even beat) ENT using only 6.6% of the training data in the clinical domain, and only 5.8% of the training data in the newswire domain.", "creator": "LaTeX with hyperref package"}}}