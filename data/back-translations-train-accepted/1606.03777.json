{"id": "1606.03777", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Jun-2016", "title": "Neural Belief Tracker: Data-Driven Dialogue State Tracking", "abstract": "Belief tracking is a core component of modern spoken dialogue system pipelines. However, most current approaches would have difficulty scaling to larger, more complex dialogue domains. This is due to their dependency on either: a) Spoken Language Understanding models that require large amounts of annotated training data; or b) hand-crafted semantic lexicons that capture the lexical variation in users' language. We propose a novel Neural Belief Tracking (NBT) framework which aims to overcome these problems by building on recent advances in semantic representation learning. The NBT models reason over continuous distributed representations of words, utterances and dialogue context. Our evaluation on two datasets shows that this approach overcomes both limitations, matching the performance of state-of-the-art models that have greater resource requirements.", "histories": [["v1", "Sun, 12 Jun 2016 22:59:14 GMT  (3391kb,D)", "http://arxiv.org/abs/1606.03777v1", "Submission under review for EMNLP 2016"], ["v2", "Fri, 21 Apr 2017 15:15:03 GMT  (628kb,D)", "http://arxiv.org/abs/1606.03777v2", "Accepted as a long paper for the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017)"]], "COMMENTS": "Submission under review for EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.LG", "authors": ["nikola mrksic", "diarmuid \u00f3 s\u00e9aghdha", "tsung-hsien wen", "blaise thomson", "steve j young"], "accepted": true, "id": "1606.03777"}, "pdf": {"name": "1606.03777.pdf", "metadata": {"source": "CRF", "title": "Neural Belief Tracker: Data-Driven Dialogue State Tracking", "authors": ["Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Tsung-Hsien Wen", "Blaise Thomson", "Steve Young"], "emails": ["sjy}@cam.ac.uk", "blaisethom}@apple.com"], "sections": [{"heading": "1 Introduction", "text": "Spoken dialog systems (SDS) allow users to interact with computer applications through conversations. Task-oriented dialog systems help users achieve goals, such as finding restaurants or booking flights. SDS's Dialogue State Tracking Component (DST) is used to interpret user input and update the state of belief, which is the system's internal representation of the state of the call. However, the Dialogue State Tracking Challenge (DSTC) set of common tasks has provided a common evaluation framework, accompanied by designated datasets (Williams et al., 2016). Within this framework, systems must track the search constraints expressed by users (goals) and ask users for search results (requests), taking into account the user's expressions (which are passed on by a language context of the Williams dialog) and the context of the data."}, {"heading": "2 Background", "text": "This means that the distribution mechanisms of a tracker of a user's intentions can be used to decide whether to perform an action or a request that is executed by the user. As mentioned above, the task is defined by an ontology that enumerates and institutionalizes a user's objectives, a standard evaluation paradigm (Williams et al., 2013; Henderson et al., 2012; Henderson et al., Henderson et al., 2012; Henderson et al.). In this setting, the task is defined by an ontology that informs a user's objectives and the attributes of entities that the user can request. Many different belief models have been proposed in the literature (Thomson and Young, 2010) and discriminatory (Henderson et al., 201d)."}, {"heading": "3 Neural Belief Tracker", "text": "The Neural Belief Tracker (NBT) is a model for recognizing the slot-value pairs expressed in any user statement during the dialog flow. Its input consists of the system dialog actions that precede the user input, the user statement itself, and a single slot value pair over which it must make a decision. To do this, we iterate over all candidate pairs (defined by the domain ontology) and use the NBT to decide which ones are expressed by the user. Figure 1 shows the information flow in the model. The first layer in the NBT hierarchy performs representation learning for the three model inputs, with vector representations for the user statement (r), the current candidate-slot-value pair (c), and the system dialog actions (tq, ts, tv). Subsequently, the learned vector representations interact through the context modelling pair of the user statement (s), the contextual intermediate and decoder pair of the final composition, represented by the composition of the user pair, and the submediate intermediate interface."}, {"heading": "3.1 Representation Learning", "text": "For each given utterance, system act (s) and candidate-slot-value pair, the representation-learning submodules produce vector representations that act as input for the downstream components of the model. All representation-learning subcomponents use upstream collections of word vectors. (2016), Specialization word vectors to express the semantic similarity rather than relationships-by-association is essential for improving faith-by-association performance. For this reason, we use the semantic-specialized word vectors (Wieting et al., 2015). The NBT training method captures these vectors: in this way, unseen words semantically related to familiar slot values (i.e. inteure to cheap) we are recognized by their position in the original vector space. This also means that candidate-slot-value pairs implicitly parameterise the NBT model."}, {"heading": "3.2 Semantic Decoding", "text": "The NBT diagram in Figure 1 shows that the representation of the statement r and the candidate-slot-value pair c interact directly through the semantic decoding module, which determines whether the user has explicitly expressed an intention that corresponds to the current candidate pair (i.e., without taking into account the dialog context). Examples of such matches would be \"I want Thai food\" with food = Thai, or more sophisticated ones like \"an expensive restaurant\" with price = expensive. Here, the use of high-quality, pre-trained word vectors comes into play: A delexicalization model could deal with the former example, but would be helpless in the latter case unless a human expert had provided a semantic dictionary listing all potential repetitions for each value in the domain ontologically. Let's leave the vector space representations of a candidate pair c representations of the current name of the value of the Vecc configurations of word configurations with Wcc-numbers and multiple word configurations by Wcc-numbers."}, {"heading": "3.3 Context Modelling", "text": "These \"decoders\" are not yet sufficient to confirm statements in the dialogue between man and machine. To understand some questions, the faith tracker needs to know the context, i.e. the dialog flow that leads to the user's most recent utterance. While all previous system and user utterances are important, the last system outward appearance in which the dialog system could be performed (among other things) is one of the following two measures: 1. System requirement: The system asks the user for the value of a certain slot Tq. If the system is utterance: \"What price range do you want?\" and the user answers with each, must derive the reference to the price range and not to other slots such as area or food type."}, {"heading": "4 Belief Tracking", "text": "In spoken dialog systems, faith tracking models work through the output of automated speech recognition (ASR). Despite constantly improving speech recognition, the need to make the most of imperfect ASR will remain as dialog systems are used in increasingly noisy environments. In this work, we use a simple rule-based mechanism for updating the faith state that can be applied to ASR N-best lists. Let's name a list of N ASR hypotheses hi with rear probabilities pi following system output systems. For each hypothesis h, slot s and slot value v-Vs, the NBT model estimates P (s, v-h, sys), i.e. the probability that (s, v) was expressed in h. The predictions for N such hypotheses are combined as follows: P (s, v-u) = N-value v-i = 1 slot (s, v-hi, sys) (11)."}, {"heading": "5 Experiments", "text": "Two sets of data were used for training and evaluation, both consisting of user conversations with task-oriented dialog systems designed to help users find suitable restaurants in Cambridge, U.K. The two companies share the same domain ontology, which includes three informable (i.e. destination) slots: type of food, area and price. Users can specify values for these slots to find restaurants that best meet their criteria. Once the system proposes a restaurant, users can ask for the values of up to eight available slots (phone number, address, etc.) The two sets of data are: 1. DSTC2: We use the transcriptions, ASR hypotheses and turn-level semantic labels provided for the Dialogue State Tracking Challenge 2 (Henderson et al., 2014a) The official transcriptions contain various spelling errors that we have corrected manually; the clean version of the data sets will be made available on the original author's website."}, {"heading": "6 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Belief Tracking Performance", "text": "Table 1 shows the transmission performance of models trained and evaluated on the basis of DSTC2 data. We compare it to a delexicalization-based RNN model introduced by Henderson et al. (2014d; 2014c). The baseline model does not use a semantic dictionary, while the improved baseline uses a handmade semantic dictionary. NBT models clearly exceed the first baseline in terms of average target accuracy, but perform slightly worse on requests. The target tracking performance of the NBT models is comparable to the improved baseline. This shows that these models can handle semantic relationships that otherwise had to be explicitly encoded in semantic dictionaries. Since the rule-based transmission state update of NBT is less complex than Henderson et al.'s NBT models are based on NBT transmission models, we believe that further gains are possible. The WBT data model provides a benchmarking capability for NBT based on NBT."}, {"heading": "6.2 General Models: Slot-Parameter Tying", "text": "In order to train a single model that can be applied to all slots in ontology (as opposed to using a separate model for each slot), we merge all training data and use it to train an NBT model. As Mrks ic \"et al. (2015) has shown, such a coupling of parameters can facilitate transmission learning and lead to improved performance in faith follow-up. Table 3 shows the effects of coupling parameters across all slots for NBT models that have been trained together on DSTC2 and WOZ: it increases NBT DNN performance and leads to an improved balance between the performance of NBT-CNN on informable and requestable slots. Figure 4 shows the t-SNE visualization (van der Maaten and Hinton, 2008) of the user's expressions generated by the NBT-DNN model with bound parameters. The figure shows that the model learns meaningful representations, the expressions associated with the pronouncements made by the NBT-DNN model, or the statements made in 2008, are not related to the statements (such as\" Yes \"or\" Yes \")."}, {"heading": "6.3 The Importance of Word Vector Spaces", "text": "The NBT models use the semantic relationships embedded in the pre-trained word vectors to handle semantic variations and produce high-quality intermediate representations. Table 4 shows the effect of using different word vectors to form the two NBT models. Interestingly, the use of GloVe vectors (Pennington et al., 2014) instead of Paragram-SL999 (Wieting et al., 2015) drastically reduced the target-tracking capabilities of the models. Interestingly, it had a much smaller effect on queries, suggesting that the training set is large enough for the NBT models to learn certain phrases that trigger them (\"How much?,\" \"Where is it?\"), but not to ensure coverage for the numerous repetitions of categorical slot values."}, {"heading": "7 Conclusion", "text": "The Neural Belief Tracker can use a single set of parameters to determine whether the given utterance (and its context) expresses the intentions defined by domain ontology by learning similarity metrics that function via intermediate representations composed of semantically specialized word vector representations. The NBT framework offers the well-known benefits of coupling spoken language understanding and dialogue state tracking without the use of (handmade) semantic lexicon to enhance SLU memory. Our evaluation shows these benefits, with NBT matching the performance of models that rely on such lexicon. Finally, we showed that sharing the parameters of NBT models across slots can increase the overall performance of faith control, which supports our argument that these models promise to scale to complex areas with different and unequally distributed slots."}, {"heading": "Acknowledgements", "text": "The authors thank Ulrich Paquet and members of the Cambridge Dialogue Systems Group for the helpful discussions."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org", "author": ["sudevan", "Fernanda Vi\u00e9gas", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng"], "venue": null, "citeRegEx": "sudevan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "sudevan et al\\.", "year": 2015}, {"title": "A \u201ck hypotheses + other\u201d belief updating model", "author": ["Bohus", "Rudnicky2006] Dan Bohus", "Alex Rudnicky"], "venue": "In Proceedings of the AAAI Workshop on Statistical and Empirical Methods in Spoken Dialogue Systems", "citeRegEx": "Bohus et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bohus et al\\.", "year": 2006}, {"title": "Natural language processing (almost) from scratch", "author": ["Jason Weston", "Leon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Collobert et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Discriminative Spoken Language Understanding Using Word Confusion Networks", "author": ["Milica Ga\u0161i\u0107", "Blaise Thomson", "Pirros Tsiakoulis", "Kai Yu", "Steve Young"], "venue": "In Spoken Language Technology Workshop,", "citeRegEx": "Henderson et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Henderson et al\\.", "year": 2012}, {"title": "The Second Dialog State Tracking Challenge", "author": ["Blaise Thomson", "Jason D. Wiliams"], "venue": "In Proceedings of SIGDIAL", "citeRegEx": "Henderson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "The Third Dialog State Tracking Challenge", "author": ["Blaise Thomson", "Jason D. Wiliams"], "venue": "In Proceedings of IEEE SLT", "citeRegEx": "Henderson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Robust Dialog State Tracking using Delexicalised Recurrent Neural Networks and Unsupervised Adaptation", "author": ["Blaise Thomson", "Steve Young"], "venue": "In Proceedings of IEEE SLT", "citeRegEx": "Henderson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Word-Based Dialog State Tracking with Recurrent Neural Networks", "author": ["Blaise Thomson", "Steve Young"], "venue": "In Proceedings of SIGDIAL", "citeRegEx": "Henderson et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "A Convolutional Neural Network for Modelling Sentences", "author": ["Edward Grefenstette", "Phil Blunsom"], "venue": "In Proceedings of ACL", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Convolutional Neural Networks for Sentence Classification", "author": ["Yoon Kim"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A Method for Stochastic Optimization", "author": ["Kingma", "Ba2015] Diederik P. Kingma", "Jimmy Ba"], "venue": "In Proceedings of ICLR", "citeRegEx": "Kingma et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2015}, {"title": "Dialog History Construction with Long-Short Term Memory for Robust Generative Dialog State Tracking", "author": ["Lee", "Kim2016] Byung-Jun Lee", "Kee-Eung Kim"], "venue": "Dialogue & Discourse,", "citeRegEx": "Lee et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2016}, {"title": "Spoken Language Understanding from Unaligned Data using Discriminative Classification Models", "author": ["Mairesse et al.2009] F. Mairesse", "M. Gasic", "F. Jurcicek", "S. Keizer", "B. Thomson", "K. Yu", "S. Young"], "venue": "Proceedings of ICASSP", "citeRegEx": "Mairesse et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mairesse et al\\.", "year": 2009}, {"title": "Using recurrent neural networks for slot filling in spoken language understanding", "author": ["Hakkani-Tur", "Xiaodong He", "Larry Heck", "Dong Yu", "Geoffrey Zweig."], "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, 23(3):530\u2013539.", "citeRegEx": "Hakkani.Tur et al\\.,? 2015", "shortCiteRegEx": "Hakkani.Tur et al\\.", "year": 2015}, {"title": "Multi-domain Dialog State Tracking using Recurrent Neural Networks", "author": ["Mrk\u0161i\u0107 et al.2015] Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Blaise Thomson", "Milica Ga\u0161i\u0107", "Pei-Hao Su", "David Vandyke", "Tsung-Hsien Wen", "Steve Young"], "venue": "Proceedings of ACL", "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2015}, {"title": "Counter-fitting Word Vectors to Linguistic Constraints", "author": ["Mrk\u0161i\u0107 et al.2016] Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Blaise Thomson", "Milica Ga\u0161i\u0107", "Lina Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "Tsung-Hsien Wen", "Steve Young"], "venue": "Proceedings of HLT-NAACL", "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2016}, {"title": "Glove: Global Vectors for Word Representation", "author": ["Richard Socher", "Christopher Manning"], "venue": "In Proceedings of EMNLP", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Spectral decomposition method of dialog state tracking via collective matrix factorization", "author": ["Julien Perez"], "venue": "Dialogue & Discourse,", "citeRegEx": "Perez.,? \\Q2016\\E", "shortCiteRegEx": "Perez.", "year": 2016}, {"title": "Generative and discriminative algorithms for spoken language understanding", "author": ["Raymond", "Ricardi2007] Christian Raymond", "Giuseppe Ricardi"], "venue": "In Proceedings of Interspeech", "citeRegEx": "Raymond et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Raymond et al\\.", "year": 2007}, {"title": "A study of using syntactic and semantic structures for concept segmentation and labeling", "author": ["Saleh et al.2014] Iman Saleh", "Shafiq Joty", "Llu\u0131\u0301s M\u00e0rquez", "Alessandro Moschitti", "Preslav Nakov", "Scott Cyphers", "Jim Glass"], "venue": "Proceedings of COLING", "citeRegEx": "Saleh et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Saleh et al\\.", "year": 2014}, {"title": "The SJTU System for Dialog State Tracking Challenge", "author": ["Sun et al.2014] Kai Sun", "Lu Chen", "Su Zhu", "Kai Yu"], "venue": "Proceedings of SIGDIAL", "citeRegEx": "Sun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2014}, {"title": "Recurrent Polynomial Network for Dialogue State Tracking", "author": ["Sun et al.2016] Kai Sun", "Qizhe Xie", "Kai Yu"], "venue": "Dialogue & Discourse,", "citeRegEx": "Sun et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2016}, {"title": "Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems", "author": ["Thomson", "Young2010] Blaise Thomson", "Steve Young"], "venue": "Computer Speech and Language", "citeRegEx": "Thomson et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Thomson et al\\.", "year": 2010}, {"title": "Semantic Parsing Using Word Confusion Networks With Conditional Random Fields", "author": ["Tur et al.2013] Gokhan Tur", "Anoop Deoras", "Dilek Hakkani-Tur"], "venue": "In Proceedings of Interspeech", "citeRegEx": "Tur et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Tur et al\\.", "year": 2013}, {"title": "Visualizing High-Dimensional Data Using t-SNE", "author": ["van der Maaten", "Geoffrey E. Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "A new corpus and imitation learning framework for context-dependent semantic parsing", "author": ["Vlachos", "Clark2014] Andreas Vlachos", "Stephen Clark"], "venue": null, "citeRegEx": "Vlachos et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Vlachos et al\\.", "year": 2014}, {"title": "A Simple and Generic Belief Tracking Mechanism for the Dialog State Tracking Challenge: On the believability of observed information", "author": ["Wang", "Lemon2013] Zhuoran Wang", "Oliver Lemon"], "venue": "Proceedings of SIGDIAL", "citeRegEx": "Wang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2013}, {"title": "Extracting Information From Spontaneous Speech", "author": ["Wayne Wang"], "venue": "In Proceedings of Interspeech", "citeRegEx": "Wang.,? \\Q1994\\E", "shortCiteRegEx": "Wang.", "year": 1994}, {"title": "A network-based end-to-end trainable task-oriented dialogue system", "author": ["Wen et al.2016] Tsung-Hsien Wen", "Milica Ga\u0161i\u0107", "Nikola Mrk\u0161i\u0107", "Lina M. Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "David Vandyke", "Steve Young"], "venue": null, "citeRegEx": "Wen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wen et al\\.", "year": 2016}, {"title": "From paraphrase database to compositional paraphrase model and back", "author": ["Wieting et al.2015] John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": null, "citeRegEx": "Wieting et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "Partially observable markov decision processes for spoken dialog systems", "author": ["Williams", "Young2007] Jason D. Williams", "Steve Young"], "venue": "Computer Speech and Language,", "citeRegEx": "Williams et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Williams et al\\.", "year": 2007}, {"title": "The Dialogue State Tracking Challenge", "author": ["Antoine Raux", "Deepak Ramachandran", "Alan W. Black"], "venue": "In Proceedings of SIGDIAL", "citeRegEx": "Williams et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Williams et al\\.", "year": 2013}, {"title": "The Dialog State Tracking Challenge series: A review", "author": ["Antoine Raux", "Matthew Henderson"], "venue": "Dialogue & Discourse,", "citeRegEx": "Williams et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Williams et al\\.", "year": 2016}, {"title": "Web-style ranking and SLU combination for dialog state tracking", "author": ["Jason D. Williams"], "venue": "In Proceedings of SIGDIAL", "citeRegEx": "Williams.,? \\Q2014\\E", "shortCiteRegEx": "Williams.", "year": 2014}, {"title": "Spoken language understanding using long short-term memory neural networks", "author": ["Yao et al.2014] Kaisheng Yao", "Baolin Peng", "Yu Zhang", "Dong Yu", "Geoffrey Zweig", "Yangyang Shi"], "venue": "Proceedings of ASRU", "citeRegEx": "Yao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2014}, {"title": "The hidden information state model: A practical framework for POMDP-based spoken dialogue management", "author": ["Young et al.2010] Steve Young", "Milica Ga\u0161i\u0107", "Simon Keizer", "Fran\u00e7ois Mairesse", "Jost Schatzmann", "Blaise Thomson", "Kai Yu"], "venue": null, "citeRegEx": "Young et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Young et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 32, "context": "The Dialogue State Tracking Challenge (DSTC) series of shared tasks has provided a common evaluation framework accompanied by labelled datasets (Williams et al., 2016).", "startOffset": 144, "endOffset": 167}, {"referenceID": 35, "context": "Models for probabilistic dialogue state tracking, or belief tracking, were introduced as components of spoken dialogue systems in order to better handle noisy speech recognition output and other sources of uncertainty in understanding a user\u2019s goals (Bohus and Rudnicky, 2006; Williams and Young, 2007; Young et al., 2010).", "startOffset": 250, "endOffset": 322}, {"referenceID": 31, "context": "As mentioned above, the DSTC shared tasks have spurred research on this problem and institutionalised a standard evaluation paradigm (Williams et al., 2013; Henderson et al., 2014b; Henderson et al., 2014a).", "startOffset": 133, "endOffset": 206}, {"referenceID": 17, "context": "The downstream DST model then combines this information with the past dialogue context to update the belief state (Thomson and Young, 2010; Wang and Lemon, 2013; Lee and Kim, 2016; Perez, 2016; Sun et al., 2016).", "startOffset": 114, "endOffset": 211}, {"referenceID": 21, "context": "The downstream DST model then combines this information with the past dialogue context to update the belief state (Thomson and Young, 2010; Wang and Lemon, 2013; Lee and Kim, 2016; Perez, 2016; Sun et al., 2016).", "startOffset": 114, "endOffset": 211}, {"referenceID": 27, "context": "In the DSTC challenges, some systems used the output of template-based matching systems such as Phoenix (Wang, 1994).", "startOffset": 104, "endOffset": 116}, {"referenceID": 12, "context": "Given enough data, these models can learn which lexical features are good indicators for a given value and can capture elements of paraphrasing (Mairesse et al., 2009).", "startOffset": 144, "endOffset": 167}, {"referenceID": 3, "context": "robust handling of rich ASR output (Henderson et al., 2012; Tur et al., 2013).", "startOffset": 35, "endOffset": 77}, {"referenceID": 23, "context": "robust handling of rich ASR output (Henderson et al., 2012; Tur et al., 2013).", "startOffset": 35, "endOffset": 77}, {"referenceID": 34, "context": "current Neural Networks can then be used (Raymond and Ricardi, 2007; Yao et al., 2014; Celikyilmaz and Hakkani-Tur, 2015; Mesnil et al., 2015).", "startOffset": 41, "endOffset": 142}, {"referenceID": 19, "context": "Other approaches adopt a more complex modelling structure inspired by semantic parsing (Saleh et al., 2014; Vlachos and Clark, 2014).", "startOffset": 87, "endOffset": 132}, {"referenceID": 20, "context": "Joint SLU/DST: Research on belief tracking has found it advantageous to reason about SLU and DST jointly, taking ASR predictions as input and generating belief states as output (Henderson et al., 2014d; Sun et al., 2014; Zilka and Jurcicek, 2015).", "startOffset": 177, "endOffset": 246}, {"referenceID": 14, "context": "As shown by Mrk\u0161i\u0107 et al. (2016), the use of such dictionaries is essential for the performance of current delexicalisation-based models.", "startOffset": 12, "endOffset": 33}, {"referenceID": 29, "context": "For this reason, we use the semantically-specialised Paragram-SL999 word vectors (Wieting et al., 2015) throughout this work.", "startOffset": 81, "endOffset": 103}, {"referenceID": 14, "context": "As shown by Mrk\u0161i\u0107 et al. (2016), specialising word vectors to express semantic similarity rather than relatedness-by-association is essential for improving belief tracking performance.", "startOffset": 12, "endOffset": 33}, {"referenceID": 28, "context": "WOZ: Wen et al. (2016) performed a Wizard of Oz style experiment in which Amazon Mechanical Turk users assumed the role of the system or the user of a task-oriented dialogue system based on the DSTC2 ontology.", "startOffset": 5, "endOffset": 23}, {"referenceID": 28, "context": "rating an RNN for belief state updates and a CNN for turn-level feature extraction (Wen et al., 2016).", "startOffset": 83, "endOffset": 101}, {"referenceID": 14, "context": "As shown by Mrk\u0161i\u0107 et al. (2015), such parameter tying can facilitate transfer learning and lead to improved belief tracking performance.", "startOffset": 12, "endOffset": 33}, {"referenceID": 16, "context": "Using GloVe vectors (Pennington et al., 2014) in place of Paragram-SL999 (Wieting et al.", "startOffset": 20, "endOffset": 45}, {"referenceID": 29, "context": ", 2014) in place of Paragram-SL999 (Wieting et al., 2015) drastically reduced the models\u2019 goal tracking capabilities.", "startOffset": 35, "endOffset": 57}], "year": 2016, "abstractText": "Belief tracking is a core component of modern spoken dialogue system pipelines. However, most current approaches would have difficulty scaling to larger, more complex dialogue domains. This is due to their dependency on either: a) Spoken Language Understanding models that require large amounts of annotated training data; or b) hand-crafted semantic lexicons that capture the lexical variation in users\u2019 language. We propose a novel Neural Belief Tracking (NBT) framework which aims to overcome these problems by building on recent advances in semantic representation learning. The NBT models reason over continuous distributed representations of words, utterances and dialogue context. Our evaluation on two datasets shows that this approach overcomes both limitations, matching the performance of state-of-the-art models that have greater resource requirements.", "creator": "LaTeX with hyperref package"}}}