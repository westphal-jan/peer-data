{"id": "1606.04279", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "Cross-Lingual Morphological Tagging for Low-Resource Languages", "abstract": "Morphologically rich languages often lack the annotated linguistic resources required to develop accurate natural language processing tools. We propose models suitable for training morphological taggers with rich tagsets for low-resource languages without using direct supervision. Our approach extends existing approaches of projecting part-of-speech tags across languages, using bitext to infer constraints on the possible tags for a given word type or token. We propose a tagging model using Wsabie, a discriminative embedding-based model with rank-based learning. In our evaluation on 11 languages, on average this model performs on par with a baseline weakly-supervised HMM, while being more scalable. Multilingual experiments show that the method performs best when projecting between related language pairs. Despite the inherently lossy projection, we show that the morphological tags predicted by our models improve the downstream performance of a parser by +0.6 LAS on average.", "histories": [["v1", "Tue, 14 Jun 2016 09:43:36 GMT  (90kb,D)", "http://arxiv.org/abs/1606.04279v1", "11 pages. ACL 2016"]], "COMMENTS": "11 pages. ACL 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jan buys", "jan a botha"], "accepted": true, "id": "1606.04279"}, "pdf": {"name": "1606.04279.pdf", "metadata": {"source": "CRF", "title": "Cross-Lingual Morphological Tagging for Low-Resource Languages", "authors": ["Jan Buys", "Jan A. Botha"], "emails": ["jan.buys@cs.ox.ac.uk", "jabot@google.com"], "sections": [{"heading": "1 Introduction", "text": "This year, more than ever before in the history of the city, where it is so far that it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place and a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place"}, {"heading": "2 Universal Morphological Tags", "text": "The tree banks commented on in the Universal Dependencies (UD) project (de Marneffe et al., 2014) are suitable for this purpose. All data are provided with universal POS tags, a group of 17 days1. We use UD v1.2 (Nivre et al., 2015), which contains 25 languages commented on with morphological attributes (so-called characteristics). In addition to POS, there are 17 universal attributes, each taking a set of values when commented on. The morphological mark of a token denotes the union of its morphological attribute value pairs, including its POS. Although the scheme is uniform across all languages, there are language-specific phenomena and considerations that lead to some discrepancies in a given language pair. One of the sources from which the word is inconsistent is the POS. Although the scheme is uniform, the annotological values are not uniform across all languages."}, {"heading": "3 Tag Projection across Bitext", "text": "Our approach to morphological tagger training is based on the paradigm of projecting token and type constraints, as proposed by Ta \ufffd ckstro \ufffd m et al. (2013). Training data consists of parallel text with resource-rich language on the source side and resource-poor language on the target side. Source-side text is marked with a supervised morphological tagger. Type and token constraints are used for each target set to construct a set of allowed tags for each token in the set, and these constraints are then used to train morphological taggers."}, {"heading": "3.1 Type and token constraints", "text": "To extract constraints from the parallel text, we first obtain bidirectional word alignments. To ensure high-quality alignment, alignment pairs with a consistency below a fixed threshold \u03b1 are removed. The motivation for using only highly consistent alignments is that incorrect alignments impair the performance of the model, while it is easier to use more parallel text to obtain a sufficient number of alignments for training. The first class of constraints we extract from the parallel text are type constraints. For each word type, we construct a distribution across the tags of the word by accumulating the number of source-side tokens aligned to spacing of the word type. The group of tags with a probability above a certain threshold is used as a tag dictionary entry for that word type."}, {"heading": "4 Learning from Projected Tags", "text": "Next, we propose models to learn a morphological marker from constraints projected across languages."}, {"heading": "4.1 Related work", "text": "HMMs have previously been used for weakly monitored learning from token or type constraints (Das and Petrov, 2011; Li et al., 2012; Ta \ufffd ckstro \ufffd m et al., 2013). HMMs are generative models, and in this setting, the words in the target sentence form the observed sequence, and the morphological markers form the hidden sequence. The projected markers are used as partially observed training data for the hidden sequence. Ta \ufffd ckstro \ufffd m et al. (2013) proposed a discriminatory CRF model based on the inclusion of two groups of constraints, one being a subset of the other. Ganchev and Das (2013) used a similar CRF model, but instead of using the projected markers as hard constraints, they were applied as soft constraints with posterior regulation."}, {"heading": "4.2 HMM model", "text": "As a base model, we use an HMM where the transition and emission distributions are parameterized by loglinear models (a feature HMM), which is performed using L-BFGS and not the EM algorithm. This parameterization was proposed by Berg-Kirkpatrick et al. (2010) and applied to lingual POS induction by Das andPetrov (2011) and Ta \ufffd ckstro \ufffd m et al. (2013). Let's take the target sentence and t the sequence of tags for the sentence. The marginal probability of any sequence during the training is (w1: n) = \u2211 t1: n, T'i = 1 p (ti | ti \u2212 1) p (wi | ti), where T is the tag sequence permitted by the type and token constraints. The probability of all other conference sequences is described as 0.The characteristics in our model are similar to those of Ta \ufffd ckm \ufffd (sequences |), where T is allowed by the type and T is allowed."}, {"heading": "4.3 Wsabie model", "text": "As a matter of fact, we will be able to find the aforementioned brainlcsrc\u00fc\u00fc\u00fceBtln The braindc\u00fceerwtcsrteeeitlrVnree\u00fcgn rf\u00fc ide hirnlc\u00fceeaeaeFnln rf\u00fc ide hirndc\u00fceerwtcsrteeeitlrVnree\u00fcgn rf\u00fc the brainlc\u00fceaeaeFnln rf\u00fc the brainlc\u00fceteeeaeWnn rf\u00fc the brainlcnteeteeeeeeeeeeaeWnn zu.nnekn\u00f6n"}, {"heading": "5 Experiments", "text": "We evaluate our model in two settings: the first is to measure the accuracy of cross-lingual taggers on language pairs where annotated data is available for both languages; the annotated target language data is used only during evaluation and not for training; and the second is to perform a downstream evaluation by including the morphological attributes predicted by the tagger as features in a dependency saver to assess the effectiveness of our approach in an environment where you do not have access to gold morphological annotations."}, {"heading": "5.1 Experimental setup", "text": "As a source of parallel training data, we use Europarl2 (Koehn, 2005) Version 7. Sentences are tokenized but not packed lower, and sentences longer than 80 words are excluded. In our experiments, we learn taggers for a number of 11 European languages, both of which have UD training data with morphological characteristics, and parallel data in Europarl: Bulgarian, Czech, Danish, Dutch, Finnish, Italian, Polish, Portuguese, Spanish, and Swedish. We train cross-border models in two setups: the first uses English as the source language; in the second, we train models with different source languages for each target language. Word alignments on the parallel data are obtained with FastAlign et al., 2013 we get High-2http: / www.statmt.org / confidence bidirectional word alignments that outperform each other."}, {"heading": "5.2 Tuning", "text": "The hyperparameters of the Wsabie taggers are adjusted to the English development set, and the same parameters are used for the Wsabie target side models trained on the projected tags. The optimal setting is a learning rate of 0.01, the embedding of dimensional size D = 50, margin 0.1 and 25 training processes. Hyperparameters for the projection models are set by adjusting the UD-Dev accuracy for English in Danish. English was chosen because it is the language with the most data available and the most likely use in projection into other languages; Danish simply because its body size is typical of the larger languages in Europarl. By means of a small grid search, we select the parameters that provide the best average accuracy across all four projection model instances that we take into account. This allows the use of the same hyperparameters for all these models, an important factor to make them comparable in the evaluation, since the hyperparameters determine the effective training parameters on these 8 are the ones set in this way."}, {"heading": "5.3 Tagging evaluation setup", "text": "In order to evaluate the induced markers on the annotated UD data for the target languages, we define two settings that avoid inconsistencies in the originally annotated data. In the STANDARD setting, minor corrections are made to certain predicted POS values in order to take into account inconsistencies in the originally annotated data. When predicting by the model, the values of the POS markers that are missing in the target language training corpus are deterministically mapped to the mostreated value present in the target language: PROPN to NOUN; SYM and INTJ to X; SYM and X to PUNCT. In addition to POS, the evaluation only takes into account those attribute types that occur in the training corpus of both languages, i.e. the set of attributes for which the model has been trained. Note that this will keep intact the cases in which the model predicts certain attribute values that only occur in one of the projector, i.e. if it is penalized under both languages; i.e. it is punished under both."}, {"heading": "5.4 Tagging results projecting from English", "text": "In fact, it is that we are able to assert ourselves, that we are able to put ourselves in a position to put ourselves at the top, \"he said in an interview with the\" Welt am Sonntag. \""}, {"heading": "5.5 Multilingual tagging results", "text": "The results for cross-border experiments on all pairs of target languages that are taken into account are therefore listed in Table 2, although the results of the STANDARD evaluation are not directly based on the setup. We use Wsabie for these experiments, as it is a more efficient model, which is particularly important when training models with large tag sets.We see that there are major differences in the morphological labelling of language pairs. In most cases, the source language for which we learn the most accurate model for morphological labelling of the target language is a related language. The Romance languages we are looking at (Spanish, Italian and Portuguese) seem to translate particularly well to each other. Swedish and Danish also translate well to each other, while English translates best to Dutch, which is most closely related to the languages that are compared with each other. However, there are also some cases of unrelated source languages that perform best: with Danish as the Quelllanguage, we give the most powerful models for Bulgarian."}, {"heading": "5.6 Parsing evaluation", "text": "In order to assess the impact of our models on a downstream task, we apply the translingual markers induced with English as the source language for the analysis of dependencies, in a scenario where a language might have a corpus commented with dependency trees and universal POS, but not for morphological attributes. However, we want to determine how much of the increase in performance comes from traits based on supervised morphological markers, which we can restore with the markers predicted by our model. As a starting point, we use a new implementation of Zhang and Nivre (2011), an arc-eager transition-based dependency saver with a rich functionality of 8, which is trained for 10 epochs with a structured perceptron. We assume that universal POS markers are available, with a supervisionary SVM marker for training and evaluation required to incorporate the markers we are referring to the word morphology we are referring to."}, {"heading": "6 Future Work", "text": "A major challenge in linguistic morphology is the relationship between source and target languages. Although we evaluate our models based on multiple source-target language pairs, more work is needed to investigate strategies for selecting the source language to be used for a target language with limited resources. Another direction is to construct models from multiple source languages, as our results show that the overall most powerful source language for a particular target language may not always perform best across all attributes. Another direction is to use dictionaries like Wiktionary to obtain type constraints, similar to previous work on poorly monitored POS tagging (Li et al., 2012; Ta \ufffd ckstro \ufffd m et al., 2013). Sylak-Glassman et al. (2015b) and SylakGlassman et al. (2015a) suggested a morphological scheme and a method of extracting annotations in this scheme from Wiktionary. Although we can turn this method into a morphological one, its extraction can be used."}, {"heading": "7 Conclusion", "text": "In this paper, we have proposed a method that can successfully generate morphological taggers for resource-poor languages by projecting tags over the bittext. It is based on access to a morphological tagger for a source language and a moderate amount of bittext. The method performs strongly in a number of language pairs. We showed that downstream tasks such as dependency parsing can be improved by using the predictions of the tagger as traits. Our results provide a strong foundation for future work in the field of weakly monitored morphological tagging."}, {"heading": "Acknowledgments", "text": "We thank Oscar Ta \ufffd ckstro \ufffd m, Kuzman Ganchev, Bernd Bohnet and Ryan McDonald for their valuable support and discussions about this work."}], "references": [{"title": "Paradigm classification in supervised learning of morphology", "author": ["Malin Ahlberg", "Markus Forsberg", "Mans Hulden."], "venue": "Proceedings of NAACL, pages 1024\u20131029.", "citeRegEx": "Ahlberg et al\\.,? 2015", "shortCiteRegEx": "Ahlberg et al\\.", "year": 2015}, {"title": "Painless unsupervised learning with features", "author": ["Taylor Berg-Kirkpatrick", "Alexandre Bouchard-C\u00f4t\u00e9", "John DeNero", "Dan Klein."], "venue": "Proceedings of NAACL, pages 582\u2013590.", "citeRegEx": "Berg.Kirkpatrick et al\\.,? 2010", "shortCiteRegEx": "Berg.Kirkpatrick et al\\.", "year": 2010}, {"title": "Automatic speech recognition for under-resourced languages: A survey", "author": ["Lauent Besacier", "Ettiene Barnard", "Alexey Karpov", "Tanja Schultz."], "venue": "Speech Communication, 56:85\u2013100.", "citeRegEx": "Besacier et al\\.,? 2014", "shortCiteRegEx": "Besacier et al\\.", "year": 2014}, {"title": "Unsupervised models for morpheme segmentation and morphology learning", "author": ["Mathias Creutz", "Krista Lagus."], "venue": "ACM Transactions on Speech and Language Processing, 4(1).", "citeRegEx": "Creutz and Lagus.,? 2007", "shortCiteRegEx": "Creutz and Lagus.", "year": 2007}, {"title": "Unsupervised part-of-speech tagging with bilingual graph-based projections", "author": ["Dipanjan Das", "Slav Petrov."], "venue": "Proceedings of ACL, pages 600\u2013609.", "citeRegEx": "Das and Petrov.,? 2011", "shortCiteRegEx": "Das and Petrov.", "year": 2011}, {"title": "Universal dependencies: A cross-linguistic typology", "author": ["Marie-Catherine de Marneffe", "Timothy Dozat", "Natalia Silveira", "Katri Haverinen", "Filip Ginter", "Joakim Nivre", "Christopher D. Manning."], "venue": "Proceedings of LREC.", "citeRegEx": "Marneffe et al\\.,? 2014", "shortCiteRegEx": "Marneffe et al\\.", "year": 2014}, {"title": "What can we get from 1000 tokens? A case study of multilingual pos tagging for resource-poor languages", "author": ["Long Duong", "Trevor Cohn", "Karin Verspoor", "Steven Bird", "Paul Cook."], "venue": "Proceedings of EMNLP, pages 886\u2013897.", "citeRegEx": "Duong et al\\.,? 2014", "shortCiteRegEx": "Duong et al\\.", "year": 2014}, {"title": "Supervised learning of complete morphological paradigms", "author": ["Greg Durrett", "John DeNero."], "venue": "Proceedings of NAACL, pages 1185\u20131195.", "citeRegEx": "Durrett and DeNero.,? 2013", "shortCiteRegEx": "Durrett and DeNero.", "year": 2013}, {"title": "A simple, fast, and effective reparameterization of IBM Model 2", "author": ["Chris Dyer", "Victor Chahuneau", "Noah A Smith."], "venue": "Proceeding of NAACL, pages 682\u2013686.", "citeRegEx": "Dyer et al\\.,? 2013", "shortCiteRegEx": "Dyer et al\\.", "year": 2013}, {"title": "Morpho-syntactic lexicon generation using graph-based semi-supervised learning", "author": ["Manaal Faruqui", "Ryan McDonald", "Radu Soricut."], "venue": "Transactions of the Association for Computational Linguistics, 4:1\u201316.", "citeRegEx": "Faruqui et al\\.,? 2016", "shortCiteRegEx": "Faruqui et al\\.", "year": 2016}, {"title": "Automatically inducing a part-of-speech tagger by projecting from multiple source languages across aligned corpora", "author": ["Victoria Fossum", "Steven Abney."], "venue": "Proceedings of IJCNLP, pages 862\u2013873.", "citeRegEx": "Fossum and Abney.,? 2005", "shortCiteRegEx": "Fossum and Abney.", "year": 2005}, {"title": "Crosslingual discriminative learning of sequence models with posterior regularization", "author": ["Kuzman Ganchev", "Dipanjan Das."], "venue": "Proceedings of EMNLP, pages 1996\u20132006.", "citeRegEx": "Ganchev and Das.,? 2013", "shortCiteRegEx": "Ganchev and Das.", "year": 2013}, {"title": "Europarl: A parallel corpus for statistical machine translation", "author": ["Philipp Koehn."], "venue": "MT summit, volume 5, pages 79\u201386.", "citeRegEx": "Koehn.,? 2005", "shortCiteRegEx": "Koehn.", "year": 2005}, {"title": "Wiki-ly supervised part-of-speech tagging", "author": ["Shen Li", "Jo\u00e3o Gra\u00e7a", "Ben Taskar."], "venue": "Proceedings of EMNLP-CoNLL, pages 1389\u20131398, July.", "citeRegEx": "Li et al\\.,? 2012", "shortCiteRegEx": "Li et al\\.", "year": 2012}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems, pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Robust morphological tagging with word representations", "author": ["Thomas M\u00fcller", "Hinrich Schuetze."], "venue": "Proceedings of NAACL, pages 526\u2013536, Denver, Colorado, May\u2013June.", "citeRegEx": "M\u00fcller and Schuetze.,? 2015", "shortCiteRegEx": "M\u00fcller and Schuetze.", "year": 2015}, {"title": "Universal dependencies 1.2. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles University in Prague", "author": ["Zhu"], "venue": null, "citeRegEx": "2015.,? \\Q2015\\E", "shortCiteRegEx": "2015.", "year": 2015}, {"title": "A universal part-of-speech tagset", "author": ["Slav Petrov", "Dipanjan Das", "Ryan McDonald."], "venue": "Proceedings of LREC.", "citeRegEx": "Petrov et al\\.,? 2012", "shortCiteRegEx": "Petrov et al\\.", "year": 2012}, {"title": "Unsupervised multilingual learning for morphological segmentation", "author": ["Benjamin Snyder", "Regina Barzilay."], "venue": "Proceedings of ACL, pages 737\u2013 745.", "citeRegEx": "Snyder and Barzilay.,? 2008", "shortCiteRegEx": "Snyder and Barzilay.", "year": 2008}, {"title": "A universal feature schema for rich morphological annotation and fine-grained cross-lingual part-of-speech tagging", "author": ["John Sylak-Glassman", "Christo Kirov", "Matt Post", "Roger Que", "David Yarowsky."], "venue": "In", "citeRegEx": "Sylak.Glassman et al\\.,? 2015a", "shortCiteRegEx": "Sylak.Glassman et al\\.", "year": 2015}, {"title": "A language-independent feature schema for inflectional morphology", "author": ["John Sylak-Glassman", "Christo Kirov", "David Yarowsky", "Roger Que."], "venue": "Proceedings of ACL-IJCNLP (short papers), pages 674\u2013 680.", "citeRegEx": "Sylak.Glassman et al\\.,? 2015b", "shortCiteRegEx": "Sylak.Glassman et al\\.", "year": 2015}, {"title": "Cross-lingual word clusters for direct transfer of linguistic structure", "author": ["Oscar T\u00e4ckstr\u00f6m", "Ryan McDonald", "Jakob Uszkoreit."], "venue": "Proceedings of NAACL, pages 477\u2013487.", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? 2012", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2012}, {"title": "Token and type constraints for cross-lingual part-of-speech tagging", "author": ["Oscar T\u00e4ckstr\u00f6m", "Dipanjan Das", "Slav Petrov", "Ryan McDonald", "Joakim Nivre."], "venue": "Transactions of the Association for Computational Linguistics, 1:1\u201312.", "citeRegEx": "T\u00e4ckstr\u00f6m et al\\.,? 2013", "shortCiteRegEx": "T\u00e4ckstr\u00f6m et al\\.", "year": 2013}, {"title": "Applying morphology generation models to machine translation", "author": ["Kristina Toutanova", "Hisami Suzuki", "Achim Ruopp."], "venue": "Proceedings of ACL-HLT, pages 558\u2013566.", "citeRegEx": "Toutanova et al\\.,? 2008", "shortCiteRegEx": "Toutanova et al\\.", "year": 2008}, {"title": "Statistical parsing of morphologically rich languages (SPMRL): what, how and whither", "author": ["Reut Tsarfaty", "Djam\u00e9 Seddah", "Yoav Goldberg", "Sandra K\u00fcbler", "Marie Candito", "Jennifer Foster", "Yannick Versley", "Ines Rehbein", "Lamia Tounsi."], "venue": "In", "citeRegEx": "Tsarfaty et al\\.,? 2010", "shortCiteRegEx": "Tsarfaty et al\\.", "year": 2010}, {"title": "Distributed word clustering for large scale class-based language modeling in machine translation", "author": ["Jakob Uszkoreit", "Thorsten Brants."], "venue": "Proceedings of ACL-HLT, pages 755\u2013762.", "citeRegEx": "Uszkoreit and Brants.,? 2008", "shortCiteRegEx": "Uszkoreit and Brants.", "year": 2008}, {"title": "Wsabie: Scaling up to large vocabulary image annotation", "author": ["Jason Weston", "Samy Bengio", "Nicolas Usunier."], "venue": "Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI).", "citeRegEx": "Weston et al\\.,? 2011", "shortCiteRegEx": "Weston et al\\.", "year": 2011}, {"title": "Crosslingual part-of-speech tagging through ambiguous learning", "author": ["Guillaume Wisniewski", "Nicolas Pcheux", "Souhir Gahbiche-Braham", "Franois Yvon."], "venue": "Proceedings of EMNLP, pages 1779\u2013 1785.", "citeRegEx": "Wisniewski et al\\.,? 2014", "shortCiteRegEx": "Wisniewski et al\\.", "year": 2014}, {"title": "Incuding multilingual text analysis tools via robust projection across aligned corpora", "author": ["David Yarowsky", "Grace Ngai", "Richard Wicentowski."], "venue": "Proceedings of HLT.", "citeRegEx": "Yarowsky et al\\.,? 2001", "shortCiteRegEx": "Yarowsky et al\\.", "year": 2001}, {"title": "Reusable tagset conversion using tagset drivers", "author": ["Daniel Zeman."], "venue": "Proceedings of LREC.", "citeRegEx": "Zeman.,? 2008", "shortCiteRegEx": "Zeman.", "year": 2008}, {"title": "Transition-based dependency parsing with rich non-local features", "author": ["Yue Zhang", "Joakim Nivre."], "venue": "Proceedings of ACL-HLT, pages 188\u2013193.", "citeRegEx": "Zhang and Nivre.,? 2011", "shortCiteRegEx": "Zhang and Nivre.", "year": 2011}], "referenceMentions": [{"referenceID": 3, "context": "Common morphological processing tasks include segmentation (Creutz and Lagus, 2007; Snyder and Barzilay, 2008), paradigm learning (Durrett and DeN-", "startOffset": 59, "endOffset": 110}, {"referenceID": 18, "context": "Common morphological processing tasks include segmentation (Creutz and Lagus, 2007; Snyder and Barzilay, 2008), paradigm learning (Durrett and DeN-", "startOffset": 59, "endOffset": 110}, {"referenceID": 15, "context": ", 2015) and morphological tagging (M\u00fcller and Schuetze, 2015).", "startOffset": 34, "endOffset": 61}, {"referenceID": 17, "context": "To enable cross-lingual learning, a small set of universal (coarse-grained) POS tags have been proposed (Petrov et al., 2012).", "startOffset": 104, "endOffset": 125}, {"referenceID": 29, "context": "attribute-feature values that makes the annotation more fine-grained (Zeman, 2008; Sylak-Glassman et al., 2015b).", "startOffset": 69, "endOffset": 112}, {"referenceID": 20, "context": "attribute-feature values that makes the annotation more fine-grained (Zeman, 2008; Sylak-Glassman et al., 2015b).", "startOffset": 69, "endOffset": 112}, {"referenceID": 24, "context": "Tagging text with morphologically-enriched labels has been shown to benefit downstream tasks such as parsing (Tsarfaty et al., 2010) and seman-", "startOffset": 109, "endOffset": 132}, {"referenceID": 23, "context": "In generation tasks such as machine translation these tags can help to generate the right form of a word and to model agreement (Toutanova et al., 2008).", "startOffset": 128, "endOffset": 152}, {"referenceID": 2, "context": "Morphological information can also benefit automatic speech recognition for low-resource languages (Besacier et al., 2014).", "startOffset": 99, "endOffset": 122}, {"referenceID": 28, "context": "A successful paradigm for learning without direct supervision is to make use of word-aligned parallel text, with a resourcerich language on one side and a resource-poor language on the other side (Yarowsky et al., 2001; Fossum and Abney, 2005; Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 196, "endOffset": 289}, {"referenceID": 10, "context": "A successful paradigm for learning without direct supervision is to make use of word-aligned parallel text, with a resourcerich language on one side and a resource-poor language on the other side (Yarowsky et al., 2001; Fossum and Abney, 2005; Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 196, "endOffset": 289}, {"referenceID": 4, "context": "A successful paradigm for learning without direct supervision is to make use of word-aligned parallel text, with a resourcerich language on one side and a resource-poor language on the other side (Yarowsky et al., 2001; Fossum and Abney, 2005; Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 196, "endOffset": 289}, {"referenceID": 22, "context": "A successful paradigm for learning without direct supervision is to make use of word-aligned parallel text, with a resourcerich language on one side and a resource-poor language on the other side (Yarowsky et al., 2001; Fossum and Abney, 2005; Das and Petrov, 2011; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 196, "endOffset": 289}, {"referenceID": 22, "context": "Our approach is based on projecting token and type constraints across parallel text, learning a tagger in a weakly-supervised manner from the projected constraints (T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 164, "endOffset": 188}, {"referenceID": 26, "context": "We propose an embedding-based model trained with the Wsabie algorithm (Weston et al., 2011), and compare this approach against a baseline HMM model.", "startOffset": 70, "endOffset": 91}, {"referenceID": 17, "context": "This extends, but is not fully consistent with, the set of 12 tags proposed by Petrov et al. (2012). ing treebanks which had used different annotation schemes.", "startOffset": 79, "endOffset": 100}, {"referenceID": 21, "context": "type constraints as proposed by T\u00e4ckstr\u00f6m et al. (2013). The training data consist of parallel text with the resource-rich language on the source-side and the low-resource language on the target side.", "startOffset": 32, "endOffset": 56}, {"referenceID": 21, "context": "Token constraints are combined with type constraints as proposed by T\u00e4ckstr\u00f6m et al. (2013): If a token is unaligned, its type constraints are used.", "startOffset": 68, "endOffset": 92}, {"referenceID": 4, "context": "HMMs have previously been used for weaklysupervised learning from token or type constraints (Das and Petrov, 2011; Li et al., 2012; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 92, "endOffset": 155}, {"referenceID": 13, "context": "HMMs have previously been used for weaklysupervised learning from token or type constraints (Das and Petrov, 2011; Li et al., 2012; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 92, "endOffset": 155}, {"referenceID": 22, "context": "HMMs have previously been used for weaklysupervised learning from token or type constraints (Das and Petrov, 2011; Li et al., 2012; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 92, "endOffset": 155}, {"referenceID": 11, "context": "Ganchev and Das (2013) used a similar CRF model, but instead of using the projected tags as hard constraints, they were employed as soft constraints with posterior regularization.", "startOffset": 0, "endOffset": 23}, {"referenceID": 27, "context": "The model of Wisniewski et al. (2014) makes greedy predictions with a history-based model, that includes previously predicted tags in the sequence, during training and testing.", "startOffset": 13, "endOffset": 38}, {"referenceID": 1, "context": "This parameterization was proposed by Berg-Kirkpatrick et al. (2010) and applied to cross-lingual POS induction by Das and", "startOffset": 38, "endOffset": 69}, {"referenceID": 21, "context": "Petrov (2011) and T\u00e4ckstr\u00f6m et al. (2013). Let w be the target sentence and t the sequence of tags for the sentence.", "startOffset": 18, "endOffset": 42}, {"referenceID": 21, "context": "The features in our model are similar to those used by T\u00e4ckstr\u00f6m et al. (2013), including features based on word and tag identity, suffixes up to length 3, punctuation and word clusters.", "startOffset": 55, "endOffset": 79}, {"referenceID": 25, "context": "words into 256 clusters with the Exchange algorithm (Uszkoreit and Brants, 2008), using the data and methodology detailed in T\u00e4ckstr\u00f6m et al.", "startOffset": 52, "endOffset": 80}, {"referenceID": 21, "context": "words into 256 clusters with the Exchange algorithm (Uszkoreit and Brants, 2008), using the data and methodology detailed in T\u00e4ckstr\u00f6m et al. (2012).", "startOffset": 125, "endOffset": 149}, {"referenceID": 26, "context": "We propose a discriminative model based on Wsabie (Weston et al., 2011), a shallow neural network that learns to optimize precision at the top of a ranked list of labels.", "startOffset": 50, "endOffset": 71}, {"referenceID": 14, "context": "The embeddings are trained with word2vec (Mikolov et al., 2013) on large corpora of newswire text.", "startOffset": 41, "endOffset": 63}, {"referenceID": 12, "context": "As source of parallel training data we use Europarl2 (Koehn, 2005) version 7.", "startOffset": 53, "endOffset": 66}, {"referenceID": 8, "context": "Word alignments over the parallel data are obtained using FastAlign (Dyer et al., 2013).", "startOffset": 68, "endOffset": 87}, {"referenceID": 21, "context": "T\u00e4ckstr\u00f6m et al. (2013) similarly found that for HMMs for POS projection, models with joint constraints do not perform better than those using only type constraints.", "startOffset": 0, "endOffset": 24}, {"referenceID": 6, "context": "It is possible to obtain further improvements in performance by learning jointly from a small annotated dataset and parallel data (Duong et al., 2014), but we leave that for future work.", "startOffset": 130, "endOffset": 150}, {"referenceID": 13, "context": "Another direction is to make use of dictionaries such as Wiktionary to obtain type constraints, similar to previous work on weakly-supervised POS tagging (Li et al., 2012; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 154, "endOffset": 195}, {"referenceID": 22, "context": "Another direction is to make use of dictionaries such as Wiktionary to obtain type constraints, similar to previous work on weakly-supervised POS tagging (Li et al., 2012; T\u00e4ckstr\u00f6m et al., 2013).", "startOffset": 154, "endOffset": 195}, {"referenceID": 13, "context": "Another direction is to make use of dictionaries such as Wiktionary to obtain type constraints, similar to previous work on weakly-supervised POS tagging (Li et al., 2012; T\u00e4ckstr\u00f6m et al., 2013). Sylak-Glassman et al. (2015b) and SylakGlassman et al.", "startOffset": 155, "endOffset": 227}, {"referenceID": 13, "context": "Another direction is to make use of dictionaries such as Wiktionary to obtain type constraints, similar to previous work on weakly-supervised POS tagging (Li et al., 2012; T\u00e4ckstr\u00f6m et al., 2013). Sylak-Glassman et al. (2015b) and SylakGlassman et al. (2015a) proposed a morphological schema and method to extract annotations in that schema from Wiktionary.", "startOffset": 155, "endOffset": 260}], "year": 2016, "abstractText": "Morphologically rich languages often lack the annotated linguistic resources required to develop accurate natural language processing tools. We propose models suitable for training morphological taggers with rich tagsets for low-resource languages without using direct supervision. Our approach extends existing approaches of projecting part-of-speech tags across languages, using bitext to infer constraints on the possible tags for a given word type or token. We propose a tagging model using Wsabie, a discriminative embeddingbased model with rank-based learning. In our evaluation on 11 languages, on average this model performs on par with a baseline weakly-supervised HMM, while being more scalable. Multilingual experiments show that the method performs best when projecting between related language pairs. Despite the inherently lossy projection, we show that the morphological tags predicted by our models improve the downstream performance of a parser by +0.6 LAS on average.", "creator": "TeX"}}}