{"id": "1606.04414", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-Jun-2016", "title": "The Parallel Knowledge Gradient Method for Batch Bayesian Optimization", "abstract": "In many applications of black-box optimization, one can evaluate multiple points simultaneously, e.g. when evaluating the performances of several different neural network architectures in a parallel computing environment. In this paper, we develop a novel batch Bayesian optimization algorithm --- the parallel knowledge gradient method. By construction, this method provides the one-step Bayes optimal batch of points to sample. We provide an efficient strategy for computing this Bayes-optimal batch of points, and we demonstrate that the parallel knowledge gradient method finds global optima significantly faster than previous batch Bayesian optimization algorithms on both synthetic test functions and when tuning hyperparameters of practical machine learning algorithms, especially when function evaluations are noisy.", "histories": [["v1", "Tue, 14 Jun 2016 15:12:01 GMT  (48kb)", "https://arxiv.org/abs/1606.04414v1", "12 pages, 4 figures"], ["v2", "Sat, 29 Oct 2016 05:47:09 GMT  (645kb,D)", "http://arxiv.org/abs/1606.04414v2", "12 pages, 5 figures, Neural Information Processing Systems (NIPS), 2016"], ["v3", "Sat, 21 Jan 2017 20:49:18 GMT  (646kb,D)", "http://arxiv.org/abs/1606.04414v3", "12 pages, 5 figures. Advances In Neural Information Processing Systems, pp. 3126-3134. 2016"]], "COMMENTS": "12 pages, 4 figures", "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG", "authors": ["jian wu", "peter i frazier"], "accepted": true, "id": "1606.04414"}, "pdf": {"name": "1606.04414.pdf", "metadata": {"source": "CRF", "title": "The Parallel Knowledge Gradient Method for Batch Bayesian Optimization", "authors": ["Jian Wu", "Peter I. Frazier"], "emails": ["pf98}@cornell.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it's gotten to the point that it will be able to put itself at the top, \"he said.\" It's too early to say what we're going to do, \"he said.\" But it's still too early to do it, \"he said.\" It's still too early to do it, \"he said,\" but it's still too early to do it. \""}, {"heading": "2 Related work", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "3 Background on Gaussian processes", "text": "In this section we give our previous results for f, briefly discuss known results for Gauss \"processes (GP) and introduce a later used notation. We put a Gaussian process before the function f: A \u2192 R, which is specified by its mean function \u00b5 (x): A \u2192 R and core function q q q q (q): A \u00b7 A \u2192 R. We assume that there are either exact or independent measurement errors, i.e. the evaluation y (xi) at the point xi satisfaction (xi) | f (xi) n (f (xi), 2 (xi))): A \u2192 R + is a known function that describes the variance of measurement errors. If we do not know, we can also estimate it as we have measured it in Section 6. Provided that we have measured f at n points x (1: n): = {x (1), x (2), \u00b7 \u00b7 \u00b7 \u00b7 which we receive the corresponding measurements."}, {"heading": "6 Numerical experiments", "text": "We conduct experiments in two different environments: in the Noise-Free setting and in the Noise-Free environment. In both environments, we test the algorithms on known synthetic functions selected from [1] and practical problems. Following previous literature [19], we use a constant mean and ARD Mate \u0301 rn 5 / 2. In the noisy environment, we assume \u03c32 (x) to be constant in domain A, and estimate it along with other hyperparameters in GP using Maximum Probability Estimation (MLE). We use M = 1000 to discredit the domain according to the strategy in Section 5.3. In general, the q-K algorithm performs as well or better than modern benchmark algorithms on synthetic and real problems. It performs particularly well in the noisy environment.Before describing the details of the empirical results, we highlight the implementation details of our method and the open source implementations of the UCUC benchmark methods."}, {"heading": "6.1 Noise-free problems", "text": "In this section, we focus on the noise-free environment in which we can accurately evaluate the target. We show that the parallel knowledge gap exceeds several known test functions or competes with state-of-the-art benchmarks and optimizes practical machine learning algorithms."}, {"heading": "6.1.1 Synthetic functions", "text": "First, we test our algorithm together with the benchmarks on 4 known synthetic test functions: Branin2 in domain [\u2212 15, 15] 2, Rosenbrock3 in domain [\u2212 2, 2] 3, Ackley5 in domain [\u2212 2, 2] 5 and Hartmann6 in domain [0, 1] 6. We initiate our algorithms by randomly selecting 2d + 2 points from a Latin hypercube design, where d is the dimension of the problem. Figure 5 indicates the mean and standard deviation of the base 10 logarithm of immediate regret by performing 100 random initializations with the batch size q = 4. Results show that q-KG is significantly better for Rosenbrock3, Ackley5 and Hartmann6 and slightly worse than the best of the other benchmarks in Branin2. In particular for Rosenbrock3 and Acky5-KG, dramatic progress is made in early iterations."}, {"heading": "6.1.2 Tuning logistic regression and convolutional neural networks (CNN)", "text": "In this section we test the algorithms for two practical problems: Tuning logistic regression on the MNIST dataset and Tuning CNN on the CIFAR10 dataset. We set the batch size to q = 4. First, we tune logistic regression on the MNIST dataset. This task is to classify handwritten digits from images, and it is a 10-class classification problem. We train logistic regression on a training parameter with 60000 instances with a given set of hyperparameters and test it on a test set of 10000 instances. We do 4 hyperparameters: mini-batch size from 10 to 2000, training parameters from 100 to 10000, the '2 regularization parameters from 0 to 1 and learning rate from 0 to 1. We report the mean and standard deviation of the test error for 20 independent runs. From the results you can see that both algorithms are making progress in the initial phase."}, {"heading": "6.2 Noisy problems", "text": "In this section, we examine problems with the assessment of noise functions. Our results show that the performance gains over q-KG benchmark algorithms, which are visible in the noise-free environment, are even greater in the noisy environment."}, {"heading": "6.2.1 Noisy synthetic functions", "text": "We test the same 4 synthetic functions from the noise-free setting and add independent Gaussian noise with standard deviation \u03c3 = 0.5 to the function evaluation. The algorithms do not obtain this standard deviation and must learn it from the data. Figure 4 shows that q-KG is consistently better or at least competitive with all competing methods. Furthermore, it should be noted that the performance advantage of q-KG is greater than for noise-free problems."}, {"heading": "6.2.2 Noisy logistic regression with small test sets", "text": "To speed up the synchronization of the hyperparameters, we can instead test the algorithm on a subset of the test data to approximate the test error to the full test set. We examine the performance of our algorithm and the benchmarks in this scenario, focusing on matching the logistic regression to MNIST. We train the logistic regression to the full test set of 60,000, but we test the algorithm by testing 1,000 randomly selected samples from the test set, which provides a noisy approximation of the test error across the entire test set. We report the mean and standard deviation of the test error to the full test set using the hyperparameters recommended by each parallel BO algorithm for 20 independent runs. The result shows that q-KG is better than both versions of parallel EI, and its final test error is close to the noiseless test set (which is much more expensive to obtain)."}, {"heading": "Acknowledgments", "text": "The authors were partially supported by NSF CAREER CMMI-1254298, NSF CMMI-1536895, NSF IIS-1247696, AFOSR FA9550-12-1-0200, AFOSR FA9550-15-1-0038 and AFOSR FA9550-16-10046."}, {"heading": "7 Conclusions", "text": "In this paper, we present a novel batch-based Bayesian optimization method q-KG, derived from a decision theory perspective, and develop a calculation method to efficiently implement it. We show that q-KG is superior or competitive to modern benchmark algorithms in several synthetic functions and in matching practical machine learning algorithms. Supplementary Material A Asynchronous q-KG Optimization The (A.1) corresponds to the synchronous q-KG optimization, where we wait until all q points from our previous batch are completed before looking for a new batch of q points. However, in some applications, we may want to create a new batch of points to be evaluated next, while p (< q) points are evaluated before we have their values. This is common in machine learning training where different machine learning models do not necessarily end at the same time."}, {"heading": "B Speed-up analysis", "text": "Next, we compare q-KG at different levels of parallelism with the fully sequential Kg algorithm. We test the algorithms with different batch sizes on two noise synthetic functions Branin2 and Hartmann6, whose standard deviation of noise \u03c3 = 0.5. From the results it emerges that our method of parallel knowledge gradient provides an acceleration of the increase of q."}, {"heading": "C The unbiasedness of the stochastic gradient estimator", "text": "Remember that in section 5 of the main document we expressed the q-Kg factor as follows: q q-Kg (z (1: q), A (1: q), A (z (1: q), A (1: q), A (1: q), A (1: q), A (1: q), A (1: q), A (1: q), A (1: q), A (1: q), A (1: q), Z (1: q), Z (1: q), Z (1: q), Z (1: q), Z (1: q), Z (1: q), Z (1: q), Z (1: q), Z (1: q), Zq (1: q), Zq (1: q), Zq (1: q), Z (x: x, Z), Zq (1: x), Z (1: x), Z (1: 1, 1: 1, Z (1), 1: (1), Z (1: 1, 1), Z (1: 1), Z (1: 1), Z (1: x), Z (1: x), Z (1: x)."}, {"heading": "D The convergence of stochastic gradient ascent", "text": "In this section we will prove that SGA converges to a stationary point. We follow the same idea to prove theorem 2 in [26]. First, it requires the step count \u03b3t satisfactorily \u03b3t \u2192 0 as t \u2192 \u221e, \u2211 \u221e t = 0 \u03b3t = \u221e and \u0445 \u221e t = 0 \u03b3 2 t < \u221e. Second, it requires the second moment of the gradient estimator is finite. In the above section 1.3 we have shown that | \u2202 zij g (z (1: q), A, Zq) | \u2264 2B + \u0445 q i = 1 \u0432i | zi |, then E (\u2202 \u2202 zijg (z (1: q), A, Zq))) 2 \u2264 4B2 + \u0445 q i + 4B."}], "references": [{"title": "Optimization test problems. http://www.sfu.ca/~ssurjano/optimization", "author": ["D. Bingham"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Fast computation of the multi-points expected improvement with applications in batch selection", "author": ["C. Chevalier", "D. Ginsbourger"], "venue": "In Learning and Intelligent Optimization,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2013}, {"title": "Parallel gaussian process optimization with upper confidence bound and pure exploration", "author": ["E. Contal", "D. Buffoni", "A. Robicquet", "N. Vayatis"], "venue": "In Machine Learning and Knowledge Discovery in Databases,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Deep learning: Methods and applications", "author": ["L. Deng", "D. Yu"], "venue": "Foundations and Trends in Signal Processing,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Parallelizing exploration-exploitation tradeoffs in gaussian process bandit optimization", "author": ["T. Desautels", "A. Krause", "J.W. Burdick"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2014}, {"title": "Gpoptimization. https://reine.cmla.ens-cachan.fr/e.contal/ gpoptimization", "author": ["E.C. etal"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2015}, {"title": "The knowledge-gradient policy for correlated normal beliefs", "author": ["P. Frazier", "W. Powell", "S. Dayanik"], "venue": "INFORMS journal on Computing,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2009}, {"title": "Bayesian optimization with inequality constraints", "author": ["J.R. Gardner", "M.J. Kusner", "Z.E. Xu", "K.Q. Weinberger", "J. Cunningham"], "venue": "In ICML,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2014}, {"title": "Bayesian optimization with unknown constraints", "author": ["M. Gelbart", "J. Snoek", "R. Adams"], "venue": "In Proceedings of the Thirtieth Conference Annual Conference on Uncertainty in Artificial Intelligence", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Kriging is well-suited to parallelize optimization", "author": ["D. Ginsbourger", "R. Le Riche", "L. Carraro"], "venue": "In Computational Intelligence in Expensive Optimization Problems,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Predictive entropy search for efficient global optimization of black-box functions", "author": ["J.M. Hern\u00e1ndez-Lobato", "M.W. Hoffman", "Z. Ghahramani"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2014}, {"title": "Efficient global optimization of expensive black-box functions", "author": ["D.R. Jones", "M. Schonlau", "W.J. Welch"], "venue": "Journal of Global optimization,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1998}, {"title": "A unified view of the IPA, SF, and LR gradient estimation techniques", "author": ["P. L\u2019Ecuyer"], "venue": "Management Science,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 1990}, {"title": "Differentiating the multipoint expected improvement for optimal batch design", "author": ["S. Marmin", "C. Chevalier", "D. Ginsbourger"], "venue": "In International Workshop on Machine Learning, Optimization and Big Data,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Gaussian processes for machine learning", "author": ["C.E. Rasmussen"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2006}, {"title": "The correlated knowledge gradient for simulation optimization of continuous parameters using gaussian process regression", "author": ["W. Scott", "P. Frazier", "W. Powell"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2011}, {"title": "Parallel predictive entropy search for batch global optimization of expensive objective functions", "author": ["A. Shah", "Z. Ghahramani"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2015}, {"title": "Practical bayesian optimization of machine learning algorithms. In Advances in neural information processing systems, pages 2951\u20132959", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": null, "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Input warping for bayesian optimization of non-stationary functions", "author": ["J. Snoek", "K. Swersky", "R. Zemel", "R. Adams"], "venue": "In Proceedings of the 31st International Conference on Machine Learning", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2014}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "M. Seeger", "S.M. Kakade"], "venue": "In Proceedings of the 27th International Conference on Machine Learning", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2010}, {"title": "Multi-task bayesian optimization. In Advances in neural information processing systems, pages 2004\u20132012", "author": ["K. Swersky", "J. Snoek", "R.P. Adams"], "venue": null, "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Elementary real analysis", "author": ["B.S. Thomson", "J.B. Bruckner", "A.M. Bruckner"], "venue": "ClassicalReal- Analysis. com", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2008}, {"title": "Global optimization, volume 350 of lecture notes in computer science", "author": ["A. T\u00f6rn", "A. Zilinskas"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 1989}, {"title": "Metrics optimization engine. http://yelp", "author": ["J. Wang", "S.C. Clark", "E. Liu", "P.I. Frazier"], "venue": "github.io/MOE/. Last accessed on 2016-01-21", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2014}, {"title": "Parallel bayesian global optimization of expensive functions", "author": ["J. Wang", "S.C. Clark", "E. Liu", "P.I. Frazier"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "Nested-batch-mode learning and stochastic optimization with an application to sequential multistage testing in materials science", "author": ["Y. Wang", "K.G. Reyes", "K.A. Brown", "C.A. Mirkin", "W.B. Powell"], "venue": "SIAM Journal on Scientific Computing,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2015}], "referenceMentions": [{"referenceID": 17, "context": "In Bayesian optimization [19] (BO), we wish to optimize a derivative-free expensive-to-evaluate function f with feasible domain A \u2286 R,", "startOffset": 25, "endOffset": 29}, {"referenceID": 17, "context": "In comparison with other global optimization algorithms, BO often finds \u201cnear optimal\u201d function values with fewer evaluations [19].", "startOffset": 126, "endOffset": 130}, {"referenceID": 3, "context": "ImageNet) [4].", "startOffset": 10, "endOffset": 13}, {"referenceID": 7, "context": "Recently, BO has become popular in machine learning as it is highly effective in tuning hyperparameters of machine learning algorithms [8, 9, 19, 22].", "startOffset": 135, "endOffset": 149}, {"referenceID": 8, "context": "Recently, BO has become popular in machine learning as it is highly effective in tuning hyperparameters of machine learning algorithms [8, 9, 19, 22].", "startOffset": 135, "endOffset": 149}, {"referenceID": 17, "context": "Recently, BO has become popular in machine learning as it is highly effective in tuning hyperparameters of machine learning algorithms [8, 9, 19, 22].", "startOffset": 135, "endOffset": 149}, {"referenceID": 20, "context": "Recently, BO has become popular in machine learning as it is highly effective in tuning hyperparameters of machine learning algorithms [8, 9, 19, 22].", "startOffset": 135, "endOffset": 149}, {"referenceID": 11, "context": "Most previous work in BO assumes that we evaluate the objective function sequentially [13], though a few recent papers have considered parallel evaluations [3, 5, 18, 26].", "startOffset": 86, "endOffset": 90}, {"referenceID": 2, "context": "Most previous work in BO assumes that we evaluate the objective function sequentially [13], though a few recent papers have considered parallel evaluations [3, 5, 18, 26].", "startOffset": 156, "endOffset": 170}, {"referenceID": 4, "context": "Most previous work in BO assumes that we evaluate the objective function sequentially [13], though a few recent papers have considered parallel evaluations [3, 5, 18, 26].", "startOffset": 156, "endOffset": 170}, {"referenceID": 16, "context": "Most previous work in BO assumes that we evaluate the objective function sequentially [13], though a few recent papers have considered parallel evaluations [3, 5, 18, 26].", "startOffset": 156, "endOffset": 170}, {"referenceID": 24, "context": "Most previous work in BO assumes that we evaluate the objective function sequentially [13], though a few recent papers have considered parallel evaluations [3, 5, 18, 26].", "startOffset": 156, "endOffset": 170}, {"referenceID": 24, "context": "Naively maximizing q-KG would be extremely computationally intensive, especially when q is large, and so, in this paper, we develop a method based on infinitesimal perturbation analysis (IPA) [26] to evaluate q-KG\u2019s gradient efficiently, allowing its efficient optimization.", "startOffset": 192, "endOffset": 196}, {"referenceID": 1, "context": "In our experiments on both synthetic functions and tuning practical machine learning algorithms, q-KG consistently finds better function values than other parallel BO algorithms, such as parallel EI [2, 19, 26], batch UCB [5] and parallel UCB with exploration [3].", "startOffset": 199, "endOffset": 210}, {"referenceID": 17, "context": "In our experiments on both synthetic functions and tuning practical machine learning algorithms, q-KG consistently finds better function values than other parallel BO algorithms, such as parallel EI [2, 19, 26], batch UCB [5] and parallel UCB with exploration [3].", "startOffset": 199, "endOffset": 210}, {"referenceID": 24, "context": "In our experiments on both synthetic functions and tuning practical machine learning algorithms, q-KG consistently finds better function values than other parallel BO algorithms, such as parallel EI [2, 19, 26], batch UCB [5] and parallel UCB with exploration [3].", "startOffset": 199, "endOffset": 210}, {"referenceID": 4, "context": "In our experiments on both synthetic functions and tuning practical machine learning algorithms, q-KG consistently finds better function values than other parallel BO algorithms, such as parallel EI [2, 19, 26], batch UCB [5] and parallel UCB with exploration [3].", "startOffset": 222, "endOffset": 225}, {"referenceID": 2, "context": "In our experiments on both synthetic functions and tuning practical machine learning algorithms, q-KG consistently finds better function values than other parallel BO algorithms, such as parallel EI [2, 19, 26], batch UCB [5] and parallel UCB with exploration [3].", "startOffset": 260, "endOffset": 263}, {"referenceID": 7, "context": "Within the past several years, the machine learning community has revisited BO [8, 9, 18, 19, 20, 22] due to its huge success in tuning hyperparameters of complex machine learning algorithms.", "startOffset": 79, "endOffset": 101}, {"referenceID": 8, "context": "Within the past several years, the machine learning community has revisited BO [8, 9, 18, 19, 20, 22] due to its huge success in tuning hyperparameters of complex machine learning algorithms.", "startOffset": 79, "endOffset": 101}, {"referenceID": 16, "context": "Within the past several years, the machine learning community has revisited BO [8, 9, 18, 19, 20, 22] due to its huge success in tuning hyperparameters of complex machine learning algorithms.", "startOffset": 79, "endOffset": 101}, {"referenceID": 17, "context": "Within the past several years, the machine learning community has revisited BO [8, 9, 18, 19, 20, 22] due to its huge success in tuning hyperparameters of complex machine learning algorithms.", "startOffset": 79, "endOffset": 101}, {"referenceID": 18, "context": "Within the past several years, the machine learning community has revisited BO [8, 9, 18, 19, 20, 22] due to its huge success in tuning hyperparameters of complex machine learning algorithms.", "startOffset": 79, "endOffset": 101}, {"referenceID": 20, "context": "Within the past several years, the machine learning community has revisited BO [8, 9, 18, 19, 20, 22] due to its huge success in tuning hyperparameters of complex machine learning algorithms.", "startOffset": 79, "endOffset": 101}, {"referenceID": 14, "context": "In practice, Gaussian Process (GP) [16] is the mostly widely used statistical model due to its flexibility and tractability.", "startOffset": 35, "endOffset": 39}, {"referenceID": 22, "context": "Maximizing this acquisition function usually provides a single point to evaluate next, with common acquisition functions for sequential Bayesian optimization including probability of improvement (PI)[24], expected improvement (EI) [13], upper confidence bound (UCB) [21], entropy search (ES) [11], and knowledge gradient (KG) [17].", "startOffset": 199, "endOffset": 203}, {"referenceID": 11, "context": "Maximizing this acquisition function usually provides a single point to evaluate next, with common acquisition functions for sequential Bayesian optimization including probability of improvement (PI)[24], expected improvement (EI) [13], upper confidence bound (UCB) [21], entropy search (ES) [11], and knowledge gradient (KG) [17].", "startOffset": 231, "endOffset": 235}, {"referenceID": 19, "context": "Maximizing this acquisition function usually provides a single point to evaluate next, with common acquisition functions for sequential Bayesian optimization including probability of improvement (PI)[24], expected improvement (EI) [13], upper confidence bound (UCB) [21], entropy search (ES) [11], and knowledge gradient (KG) [17].", "startOffset": 266, "endOffset": 270}, {"referenceID": 10, "context": "Maximizing this acquisition function usually provides a single point to evaluate next, with common acquisition functions for sequential Bayesian optimization including probability of improvement (PI)[24], expected improvement (EI) [13], upper confidence bound (UCB) [21], entropy search (ES) [11], and knowledge gradient (KG) [17].", "startOffset": 292, "endOffset": 296}, {"referenceID": 15, "context": "Maximizing this acquisition function usually provides a single point to evaluate next, with common acquisition functions for sequential Bayesian optimization including probability of improvement (PI)[24], expected improvement (EI) [13], upper confidence bound (UCB) [21], entropy search (ES) [11], and knowledge gradient (KG) [17].", "startOffset": 326, "endOffset": 330}, {"referenceID": 9, "context": "[10, 19] suggests parallelizing EI by iteratively constructing a batch, in each iteration adding the point with maximal single-evaluation EI averaged over the posterior distribution of previously selected points.", "startOffset": 0, "endOffset": 8}, {"referenceID": 17, "context": "[10, 19] suggests parallelizing EI by iteratively constructing a batch, in each iteration adding the point with maximal single-evaluation EI averaged over the posterior distribution of previously selected points.", "startOffset": 0, "endOffset": 8}, {"referenceID": 9, "context": "[10] also proposes an algorithm called \u201cconstant liar\", which iteratively constructs a batch of points to sample by maximizing singleevaluation while pretending that points previously added to the batch have already returned values.", "startOffset": 0, "endOffset": 4}, {"referenceID": 4, "context": "[5] proposes the GP-BUCB policy, which selects points sequentially by a UCB criterion until filling the batch.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[3] proposes an algorithm combining UCB with pure exploration, called GP-UCB-PE.", "startOffset": 0, "endOffset": 3}, {"referenceID": 1, "context": "Other recent papers that value points collectively include [2] which optimizes the parallel EI by a closed-form formula, [15, 26], in which gradient-based methods are proposed to jointly optimize a parallel EI criterion, and [18], which proposes a parallel version of the ES algorithm and uses Monte Carlo Sampling to optimize the parallel ES acquisition function.", "startOffset": 59, "endOffset": 62}, {"referenceID": 13, "context": "Other recent papers that value points collectively include [2] which optimizes the parallel EI by a closed-form formula, [15, 26], in which gradient-based methods are proposed to jointly optimize a parallel EI criterion, and [18], which proposes a parallel version of the ES algorithm and uses Monte Carlo Sampling to optimize the parallel ES acquisition function.", "startOffset": 121, "endOffset": 129}, {"referenceID": 24, "context": "Other recent papers that value points collectively include [2] which optimizes the parallel EI by a closed-form formula, [15, 26], in which gradient-based methods are proposed to jointly optimize a parallel EI criterion, and [18], which proposes a parallel version of the ES algorithm and uses Monte Carlo Sampling to optimize the parallel ES acquisition function.", "startOffset": 121, "endOffset": 129}, {"referenceID": 16, "context": "Other recent papers that value points collectively include [2] which optimizes the parallel EI by a closed-form formula, [15, 26], in which gradient-based methods are proposed to jointly optimize a parallel EI criterion, and [18], which proposes a parallel version of the ES algorithm and uses Monte Carlo Sampling to optimize the parallel ES acquisition function.", "startOffset": 225, "endOffset": 229}, {"referenceID": 6, "context": "Our method is also closely related to the knowledge gradient (KG) method [7, 17] for the non-batch (sequential) setting, which chooses the Bayes-optimal point to evaluate if only one iteration is left [17], and the final solution that we choose is not restricted to be one of the points we evaluate.", "startOffset": 73, "endOffset": 80}, {"referenceID": 15, "context": "Our method is also closely related to the knowledge gradient (KG) method [7, 17] for the non-batch (sequential) setting, which chooses the Bayes-optimal point to evaluate if only one iteration is left [17], and the final solution that we choose is not restricted to be one of the points we evaluate.", "startOffset": 73, "endOffset": 80}, {"referenceID": 15, "context": "Our method is also closely related to the knowledge gradient (KG) method [7, 17] for the non-batch (sequential) setting, which chooses the Bayes-optimal point to evaluate if only one iteration is left [17], and the final solution that we choose is not restricted to be one of the points we evaluate.", "startOffset": 201, "endOffset": 205}, {"referenceID": 25, "context": "Recently, [27] studies a nested batch knowledge gradient policy.", "startOffset": 10, "endOffset": 14}, {"referenceID": 6, "context": "In this section, we propose a novel parallel Bayesian optimization algorithm by generalizing the concept of the knowledge gradient from [7] to the parallel setting.", "startOffset": 136, "endOffset": 139}, {"referenceID": 6, "context": "The knowledge gradient policy in [7] for discrete A chooses the next sampling decision by maximizing the expected incremental value of a measurement, without assuming (as expected improvement does) that the point returned as the optimum must be a previously sampled point.", "startOffset": 33, "endOffset": 36}, {"referenceID": 6, "context": "1) Following [7], we express \u03bc(x) as \u03bc(x) = \u03bc(x) +K(x, z) ( K(z, z)", "startOffset": 13, "endOffset": 16}, {"referenceID": 12, "context": "This technique is called infinitesimal perturbation analysis (IPA) in gradient estimation [14].", "startOffset": 90, "endOffset": 94}, {"referenceID": 15, "context": "The discretization itself is an interesting research topic [17].", "startOffset": 59, "endOffset": 63}, {"referenceID": 10, "context": "In this paper, the discrete set An is not chosen statically, but evolves over time: specifically, we suggest drawing M samples from the global optima of the posterior distribution of the Gaussian process (please refer to [11, 18] for a description of this technique).", "startOffset": 221, "endOffset": 229}, {"referenceID": 16, "context": "In this paper, the discrete set An is not chosen statically, but evolves over time: specifically, we suggest drawing M samples from the global optima of the posterior distribution of the Gaussian process (please refer to [11, 18] for a description of this technique).", "startOffset": 221, "endOffset": 229}, {"referenceID": 0, "context": "In both settings, we test the algorithms on well-known synthetic functions chosen from [1] and practical problems.", "startOffset": 87, "endOffset": 90}, {"referenceID": 17, "context": "Following previous literature [19], we use a constant mean prior and the ARD Mat\u00e9rn 5/2 kernel.", "startOffset": 30, "endOffset": 34}, {"referenceID": 23, "context": "Our implementation inherits the open-source implementation of parallel EI from the Metrics Optimization Engine [25], which is fully implemented in C++ with a python interface.", "startOffset": 111, "endOffset": 115}, {"referenceID": 23, "context": "Besides comparing to parallel EI in [25], we also compare our method to a well-known heuristic parallel EI implemented in Spearmint [12], the parallel UCB algorithm (GP-BUCB) and parallel UCB with pure exploration (GP-UCB-PE) both implemented in Gpoptimization [6].", "startOffset": 36, "endOffset": 40}, {"referenceID": 5, "context": "Besides comparing to parallel EI in [25], we also compare our method to a well-known heuristic parallel EI implemented in Spearmint [12], the parallel UCB algorithm (GP-BUCB) and parallel UCB with pure exploration (GP-UCB-PE) both implemented in Gpoptimization [6].", "startOffset": 261, "endOffset": 264}, {"referenceID": 0, "context": "First, we test our algorithm along with the benchmarks on 4 well-known synthetic test functions: Branin2 on the domain [\u221215, 15], Rosenbrock3 on the domain [\u22122, 2], Ackley5 on the domain [\u22122, 2], and Hartmann6 on the domain [0, 1].", "startOffset": 224, "endOffset": 230}, {"referenceID": 0, "context": "Without loss of generality, we assume that (1) i and j are fixed in advance and (2) A = [0, 1], we would like to prove that (C.", "startOffset": 88, "endOffset": 94}, {"referenceID": 12, "context": "To prove it, we cite Theorem 1 in [14], which requires three conditions to make (C.", "startOffset": 34, "endOffset": 38}, {"referenceID": 21, "context": "25 on page 165 in [23]).", "startOffset": 18, "endOffset": 22}, {"referenceID": 24, "context": "We follow the same idea of proving the Theorem 2 in [26].", "startOffset": 52, "endOffset": 56}], "year": 2017, "abstractText": "In many applications of black-box optimization, one can evaluate multiple points simultaneously, e.g. when evaluating the performances of several different neural networks in a parallel computing environment. In this paper, we develop a novel batch Bayesian optimization algorithm \u2014 the parallel knowledge gradient method. By construction, this method provides the one-step Bayes optimal batch of points to sample. We provide an efficient strategy for computing this Bayes-optimal batch of points, and we demonstrate that the parallel knowledge gradient method finds global optima significantly faster than previous batch Bayesian optimization algorithms on both synthetic test functions and when tuning hyperparameters of practical machine learning algorithms, especially when function evaluations are noisy.", "creator": "LaTeX with hyperref package"}}}