{"id": "1606.06357", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jun-2016", "title": "Complex Embeddings for Simple Link Prediction", "abstract": "In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.", "histories": [["v1", "Mon, 20 Jun 2016 22:52:48 GMT  (697kb,D)", "http://arxiv.org/abs/1606.06357v1", "10+2 pages, accepted at ICML 2016"]], "COMMENTS": "10+2 pages, accepted at ICML 2016", "reviews": [], "SUBJECTS": "cs.AI cs.LG stat.ML", "authors": ["th\u00e9o trouillon", "johannes welbl", "sebastian riedel", "\u00e9ric gaussier", "guillaume bouchard"], "accepted": true, "id": "1606.06357"}, "pdf": {"name": "1606.06357.pdf", "metadata": {"source": "META", "title": "Complex Embeddings for Simple Link Prediction", "authors": ["Th\u00e9o Trouillon", "Johannes Welbl", "Sebastian Riedel", "\u00c9ric Gaussier", "Guillaume Bouchard"], "emails": ["THEO.TROUILLON@XRCE.XEROX.COM", "J.WELBL@CS.UCL.AC.UK", "S.RIEDEL@CS.UCL.AC.UK", "ERIC.GAUSSIER@IMAG.FR", "G.BOUCHARD@CS.UCL.AC.UK"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is in such a way that one will be able to enter another world, in which one must enter another world, in which one must enter another world, in which one must enter another world, in which one can enter another world, in which one can enter another world, in which one must live in another world, in which one must enter another world, in which one must enter a world, in one world, in one world, in one world, in which one can enter another world, in which one lives in another world, in which one lives in another world, in which one lives in another world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one world, in one, in one world, in one, in one, in one world, in one, in one, in one world, in one, in one, in one, in one, in one world, in one, in one, in one, in one, in one, in one, in one, in one, in one, in a world, in one, in fact, in fact, in fact, in this world, in fact, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this world, in this, in this world, this, in this world, in this world, in this, in this world, in this world, this world, in this, this world, in this, this, this world, in this, this world, this, in this, this, this, this, this world, this, this, this world, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this world, this, this, this, this, this, this, this, this, this, this, this,"}, {"heading": "2. Relations as Real Part of Low-Rank Normal Matrices", "text": "In this section we will discuss the use of complex embedding for the factorization of low-level matrices and illustrate this by looking at a simplified link prediction task with only one type of relation. Understanding the factorization in complex space leads to a better theoretical understanding of the class of matrices that can actually be approximated by point products of embedding, the so-called normal matrices, where the left and right embedding have the same uniform basis."}, {"heading": "2.1. Modelling Relations", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "2.2. Low-Rank Decomposition", "text": "In a link problem, the relation matrix Y is unknown and the goal is to recover it completely from the noisy observations. In order to make the model learnable, i.e. to generalize unobserved linkages, some regularity assumptions are required. Since we are dealing with binary relationships, we assume that they have a low character rank. (6) The character rank of a character matrix is the smallest rank of a real matrix that has the same character pattern as Y: rank \u00b1 (Y) = min A-rank (A) | character (A) = Y}. This is theoretically justified by the fact that the character rank is a natural measure of complexity for character matrices (Linial et al al al al al al al al, 2007) and is linked to learning ability (Alon et al al al al, 2015), and empirically confirmed by the broad success of factoring models (Nickel et al, 2016a)."}, {"heading": "3. Application to Binary Multi-Relational Data", "text": "The previous section focuses on a single type of relationship; we extend this model to several types of relationships. < Re > Re > Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re (Re) Re) Re (Re) Re (R) R) R (R) R (R) R (R) R (R) R (R) R (R) R (R) R (R) R) R (R) R (R) R (R) R) R (R) R (R) R) R (R) R (R) R) R (R) R (R) R) R (R) R (R) R (R) R (R) R (R) R (R) R (R) R) R (R) R (R) R) R (R) R (R) R) R (R) R (R) R (R) R) R (R) R (R) R (R) R) R (R) R (R) R (R) R) R (R) R (R) R) R (R) R (R) R) R (R) R (R) R) R (R) R) R (R) R (R) R) R (R) R) R (R) R) R (R) R (R) R) R (R) R) R (R) R) R (R (R) R) R (R) R) R (R) R) R (R) R) R (R) R (R) R (R) R (R) R) R (R) R (R) R (R) R) R (R) R (R) R) R (R) R (R) R (R) R (R) R (R) R) R (R) R (R) R (R) R (R) R (R) R) R (R) R (R) R (R) R (R) R) R (R) R) R) R (R (R) R) R (R) R (R) R"}, {"heading": "4. Experiments", "text": "To evaluate our proposal, we conducted experiments with both synthetic and real datasets. Synthetic datasets are based on relationships that are either symmetric or anti-symmetric, while real datasets include different types of relationships found in different standard KBs. We call our model ComplEx, for Complex Embeddings."}, {"heading": "4.1. Synthetic Task", "text": "To assess the ability of our proposal to accurately model symmetry and antisymmetry, we randomly generated a KB of two relationships and 30 units, one relationship being perfectly symmetrical and the other completely antisymmetrical, corresponding to a 2 x 30 x 30 tensor. Figure 2 shows part of this randomly generated tensor with a symmetrical disc and an antisymmetrical disc, broken down into training, validation and test sets. Diagonal is not observed as it is not relevant in this experiment.The tensile set contains 1392 observed triples, whereas validation and test sets each contain 174 triples. Figure 1 shows the best cross-validated average precision (range below precision recall curve) for different factorization models from ranks up to 50 symmetrical units."}, {"heading": "4.2. Datasets: FB15K and WN18", "text": "We have curated the performance of our model on the FB15K and WN18 datasets especially in the fields of Freebase, KB of general facts, while WN18 is a subset of WP. Both datasets contain only positive triples. As in Bordes et al. (2013b), we have assumed negatives with the local open world. That is, for a triple variation of the subject or the object randomly, these negative triples. (2013b), we have generated negatives with the logical world. eiD \"e\" s is, we change the substance or the object randomly to form a negative example."}, {"heading": "4.3. Results", "text": "WN18 describes lexical and semantic hierarchies between concepts and contains many antisymmetric relationships such as hypernymy, hyponymy, or being \"part of.\" In fact, the DistMult and TransE models here are surpassed by ComplEx and HolE, which are on par with the respective filtered MRR values of 0.941 and 0.938 respectively. Table 4 shows the filtered test set MRR for the models considered and each relationship of WN18, confirming the advantage of our model on antisymmetric relationships while losing nothing to the others. 2D projections of the relationship provided in Appendix B visually correlate the results of FB15K, the gap is much more pronounced and the ComplEx model largely surpasses HolE, with a filtered MRR of 0.692 and 59.9% of hits at 1, compared with 0.524 and 40.2% for HolE."}, {"heading": "4.4. Influence of Negative Samples", "text": "In the previous experiment, due to arithmetical limitations, the number of negatives per training sample, \u03b7, was confirmed among the possible numbers {1, 2, 5, 10}. We want to investigate here whether an increase in these numbers could lead to better results. To this end, we focused on FB15K, whereby the \u03bb, K, \u03b10 best validated from the previous experiment were achieved. Subsequently, we vary \u03b7 in {1, 2, 5, 10, 20, 50, 100, 200}. Figure 3 shows the influence of the number of negatives generated per positive training on the performance of our model on FB15K. Generating further negatives significantly improves the results, with a filtered MRR of 0.737 at 100 negative triples (and 64.8% of hits @ 1), before decreasing again with 200 negatives. The model also converges with fewer epochs, which partially compensates the additional training time per epoch, up to an early number of negatives, which then ranges between 50 and 50 as good negatives."}, {"heading": "5. Related Work", "text": "In the early age of spectral theory in linear algebra, complex numbers were not used for matrix factorization and mathematicians mostly focused on bi-linear forms (Beltrami, 1873).The self-decomposition in the complex domain as taught today in linear algebra courses came 40 years later (Autonomous, 1915).Also, most of the existing approaches to tensor factorization were based on decomposition processes in the real domain, such as canonical polyadics (Hitchcock, 1927).These methods are very effective in many fields of application that use different modes of tensors for different types of entities.But in linking prediction problem, anti-symmetry of relationships was quickly investigated as a problem and asymmetric extensions of tensors, mostly taking into account independent embedding (Sutskever, 2009) or taking into account relationships as matrices."}, {"heading": "6. Conclusion", "text": "We have described a simple approach to matrix and tensor factorization for link prediction data, which uses vectors with complex values and maintains the mathematical definition of the dot product. Normal matrix class is a natural adaptation to binary relationships, and the use of the real part allows for an efficient approximation of each learnable relationship. Results from standard benchmarks show that no further modifications are required to improve on the state of the art. There are several directions in which this work can be expanded. Another direction would be to merge our approach with known extensions of tensor factorization to further improve prediction results. For example, the use of paired embeddings along with complex numbers could lead to improved results in many situations that involve non-compositionality. Another direction would be the development of a smarter negative sampling method to generate more informative negatives in relation to the positive sample they were sampled from."}, {"heading": "Acknowledgements", "text": "This work was supported in part by the Paul Allen Foundation with an Allen Distinguished Investigator Fellowship and in part by a Google Focused Research Award."}, {"heading": "A. SGD algorithm", "text": "We describe the algorithm to learn the ComplEx model with Stochastic Gradient Descent, using only the real evaluated vectors. Let's rewrite Equation 11 by rewriting the real part of the embedding with prime numbers and the imaginary part with double prime numbers: e \u2032 i = Re (ei), e \u2032 i = Im (ei), w \u2032 r = Re (wr), and the scoring function includes only real vectors (r, o) = < w \u2032 r, e \u2032 s, e \u2032 s, e \u2032 r, w \u00b2 s, e \u00b2 s, and the scoring function includes only real vectors: (r, o;) = < w \u2032 r, e \u2032 s, e \u2032 s, e \u00b2 s, e \u00b2 s \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 e, e \u00b2 s, e \u00b2 s, e, e \u00b2 s, e \u00b2 s, e \u00b2 e, e, e \u00b2 s, e \u00b2 s, e \u00b2, e \u00b2 s, e \u00b2 s, e, e \u00b2 s, e \u00b2 s, e \u00b2 s, e \u00b2 e, e, e \u00b2 s, e \u00b2 s, e, e \u00b2 s, e \u00b2 s, e \u00b2 e \u00b2 e, e \u00b2 e, e, e \u00b2 s, e \u00b2 e, e, e \u00b2 e, e \u00b2 s, e \u00b2 e, e, e \u00b2 e, e, e, e \u00b2 e, e, e \u00b2 e, e \u00b2 e, e, e \u00b2 e, e \u00b2 e, e, e, e, e \u00b2 e, e \u00b2 e, e, e, e, e, e \u00b2 e, e, e \u00b2 e, e \u00b2 e, e, e, e \u00b2 e, e, e, e \u00b2 e, e, e, e, e, e, e \u00b2 e, e, e,"}, {"heading": "B. WN18 embeddings visualization", "text": "We used the Principal Component Analysis (PCA) to visualize the embedding of the relationships of the Words18 dataset. The first four components of the best DistMult and ComplEx models were presented in Figure 4. For the ComplEx model, we simply linked the real and imaginary parts of each embedding. Most WN18 relationships describe hierarchies and are therefore anti-symmetrical. Each of these hierarchical relationships has its inverse relationship in the dataset. For example: Hypernym / hyponym, part of / has part, synset domain theme of / member of a domain theme. Since DistMult is unable to model anti-symmetry, it correctly represents the nature of each pair of opposite relationships, but not the direction of the relationships. To put it loosely: In the Hypernym / hyponym pair, nature splits semantics, and the direction is that unity of the other semantics is more general."}], "references": [{"title": "Sign rank versus vc dimension", "author": ["Alon", "Noga", "Moran", "Shay", "Yehudayoff", "Amir"], "venue": "arXiv preprint arXiv:1503.07648,", "citeRegEx": "Alon et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Alon et al\\.", "year": 2015}, {"title": "Dbpedia: A nucleus for a web of open data", "author": ["Auer", "Sren", "Bizer", "Christian", "Kobilarov", "Georgi", "Lehmann", "Jens", "Ives", "Zachary"], "venue": "Intl Semantic Web Conference,", "citeRegEx": "Auer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2007}, {"title": "Sur les matrices hypohermitiennes et sur les matrices unitaires", "author": ["L. Autonne"], "venue": "Ann. Univ. Lyons, Nouvelle Srie I,", "citeRegEx": "Autonne,? \\Q1915\\E", "shortCiteRegEx": "Autonne", "year": 1915}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Bollacker", "Kurt", "Evans", "Colin", "Paritosh", "Praveen", "Sturge", "Tim", "Taylor", "Jamie"], "venue": "Proceedings of the 2008 ACM SIGMOD international conference on Management of data,", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Irreflexive and Hierarchical Relations as Translations", "author": ["Bordes", "Antoine", "Usunier", "Nicolas", "Garcia-Duran", "Alberto", "Weston", "Jason", "Yakhnenko", "Oksana"], "venue": "In CoRR,", "citeRegEx": "Bordes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "Translating embeddings for modeling multi-relational data", "author": ["Bordes", "Antoine", "Usunier", "Nicolas", "Garcia-Duran", "Alberto", "Weston", "Jason", "Yakhnenko", "Oksana"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Bordes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "On approximate reasoning capabilities of low-rank vector spaces", "author": ["Bouchard", "Guillaume", "Singh", "Sameer", "Trouillon", "Th\u00e9o"], "venue": "In AAAI Spring Syposium on Knowledge Representation and Reasoning (KRR): Integrating Symbolic and Neural Approaches,", "citeRegEx": "Bouchard et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bouchard et al\\.", "year": 2015}, {"title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion", "author": ["Sun", "Shaohua", "Zhang", "Wei"], "venue": "In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Sun et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi", "John", "Hazan", "Elad", "Singer", "Yoram"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Introduction to Statistical Relational Learning (Adaptive Computation and Machine Learning)", "author": ["Getoor", "Lise", "Taskar", "Ben"], "venue": null, "citeRegEx": "Getoor et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Getoor et al\\.", "year": 2007}, {"title": "The expression of a tensor or a polyadic as a sum of products", "author": ["F.L. Hitchcock"], "venue": "J. Math. Phys,", "citeRegEx": "Hitchcock,? \\Q1927\\E", "shortCiteRegEx": "Hitchcock", "year": 1927}, {"title": "A Latent Factor Model for Highly Multi-relational Data", "author": ["Jenatton", "Rodolphe", "Bordes", "Antoine", "Le Roux", "Nicolas", "Obozinski", "Guillaume"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Jenatton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jenatton et al\\.", "year": 2012}, {"title": "Matrix factorization techniques for recommender systems", "author": ["Koren", "Yehuda", "Bell", "Robert", "Volinsky", "Chris"], "venue": null, "citeRegEx": "Koren et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Koren et al\\.", "year": 2009}, {"title": "Complexity measures of sign", "author": ["Linial", "Nati", "Mendelson", "Shahar", "Schechtman", "Gideon", "Shraibman", "Adi"], "venue": "matrices. Combinatorica,", "citeRegEx": "Linial et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Linial et al\\.", "year": 2007}, {"title": "A Three-Way Model for Collective Learning on Multi-Relational Data", "author": ["Nickel", "Maximilian", "Tresp", "Volker", "Kriegel", "HansPeter"], "venue": "In 28th International Conference on Machine Learning,", "citeRegEx": "Nickel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2011}, {"title": "Reducing the rank in relational factorization models by including observable patterns", "author": ["Nickel", "Maximilian", "Jiang", "Xueyan", "Tresp", "Volker"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Nickel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2014}, {"title": "A review of relational machine learning for knowledge graphs", "author": ["Nickel", "Maximilian", "Murphy", "Kevin", "Tresp", "Volker", "Gabrilovich", "Evgeniy"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Nickel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2016}, {"title": "Holographic embeddings of knowledge graphs", "author": ["Nickel", "Maximilian", "Rosasco", "Lorenzo", "Poggio", "Tomaso A"], "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence,", "citeRegEx": "Nickel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2016}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["Socher", "Richard", "Chen", "Danqi", "Manning", "Christopher D", "Ng", "Andrew"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Modelling Relational Data using Bayesian Clustered Tensor Factorization", "author": ["Sutskever", "Ilya"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Sutskever and Ilya.,? \\Q2009\\E", "shortCiteRegEx": "Sutskever and Ilya.", "year": 2009}, {"title": "Decomposing real square matrices via unitary diagonalization", "author": ["Trouillon", "Th\u00e9o", "Dance", "Christopher R", "Gaussier", "\u00c9ric", "Bouchard", "Guillaume"], "venue": null, "citeRegEx": "Trouillon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Trouillon et al\\.", "year": 2016}, {"title": "A factorization machine framework for testing bigram embeddings in knowledgebase completion", "author": ["Welbl", "Johannes", "Bouchard", "Guillaume", "Riedel", "Sebastian"], "venue": null, "citeRegEx": "Welbl et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Welbl et al\\.", "year": 2016}, {"title": "Embedding entities and relations for learning and inference in knowledge bases", "author": ["Yang", "Bishan", "Yih", "Wen-tau", "He", "Xiaodong", "Gao", "Jianfeng", "Deng", "Li"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}, {"title": "WN18 embeddings visualization We used principal component analysis (PCA) to visualize embeddings of the relations of the wordnet dataset (WN18)", "author": ["Bordes"], "venue": null, "citeRegEx": "Bordes,? \\Q2013\\E", "shortCiteRegEx": "Bordes", "year": 2013}], "referenceMentions": [{"referenceID": 1, "context": "Web-scale knowledge bases (KBs) provide a structured representation of world knowledge, with projects such as DBPedia (Auer et al., 2007), Freebase (Bollacker et al.", "startOffset": 118, "endOffset": 137}, {"referenceID": 3, "context": ", 2007), Freebase (Bollacker et al., 2008) or the Google Knowledge Vault (Dong et al.", "startOffset": 18, "endOffset": 42}, {"referenceID": 12, "context": "Completion based on low-rank factorization or embeddings has been popularized with the Netflix challenge (Koren et al., 2009).", "startOffset": 105, "endOffset": 125}, {"referenceID": 4, "context": "As described in Bordes et al. (2013a), a relational model should (a) be able to learn ar X iv :1 60 6.", "startOffset": 16, "endOffset": 38}, {"referenceID": 6, "context": "Dot products of embeddings scale well and can naturally handle both symmetry and (ir-)reflexivity of relations; using an appropriate loss function even enables transitivity (Bouchard et al., 2015).", "startOffset": 173, "endOffset": 196}, {"referenceID": 14, "context": "However, dealing with antisymmetric relations has so far almost always implied an explosion of the number of parameters (Nickel et al., 2011; Socher et al., 2013) (see Table 1), making models prone to overfitting.", "startOffset": 120, "endOffset": 162}, {"referenceID": 18, "context": "However, dealing with antisymmetric relations has so far almost always implied an explosion of the number of parameters (Nickel et al., 2011; Socher et al., 2013) (see Table 1), making models prone to overfitting.", "startOffset": 120, "endOffset": 162}, {"referenceID": 14, "context": "It then seems natural to learn joint embeddings of the entities, which entails sharing the embeddings of the left and right factors, as proposed by several authors to solve the link prediction problem (Nickel et al., 2011; Bordes et al., 2013b; Yang et al., 2015).", "startOffset": 201, "endOffset": 263}, {"referenceID": 22, "context": "It then seems natural to learn joint embeddings of the entities, which entails sharing the embeddings of the left and right factors, as proposed by several authors to solve the link prediction problem (Nickel et al., 2011; Bordes et al., 2013b; Yang et al., 2015).", "startOffset": 201, "endOffset": 263}, {"referenceID": 14, "context": "RESCAL (Nickel et al., 2011) es Wreo Wr \u2208 R 2 O(K) O(K)", "startOffset": 7, "endOffset": 28}, {"referenceID": 18, "context": "NTN (Socher et al., 2013) ur f(esW [1.", "startOffset": 4, "endOffset": 25}, {"referenceID": 22, "context": "DistMult (Yang et al., 2015) < wr, es, eo > wr \u2208 R O(K) O(K) HolE (Nickel et al.", "startOffset": 9, "endOffset": 28}, {"referenceID": 20, "context": "In fact, performing this projection on the real subspace allows the exact decomposition of any real square matrix X and not only normal ones, as shown by Trouillon et al. (2016).", "startOffset": 154, "endOffset": 178}, {"referenceID": 13, "context": "This is theoretically justified by the fact that the signrank is a natural complexity measure of sign matrices (Linial et al., 2007) and is linked to learnability (Alon et al.", "startOffset": 111, "endOffset": 132}, {"referenceID": 0, "context": ", 2007) and is linked to learnability (Alon et al., 2015), and empirically confirmed by the wide success of factorization models (Nickel et al.", "startOffset": 38, "endOffset": 57}, {"referenceID": 20, "context": "That is, for any Y \u2208 {\u22121, 1}n\u00d7n, there always exists a matrix X = Re(EW\u0112 ) with the same sign pattern sign(X) = Y , where the rank of EW\u0112 is at most twice the sign-rank of Y (Trouillon et al., 2016).", "startOffset": 174, "endOffset": 198}, {"referenceID": 0, "context": "For example, the rank of the n \u00d7 n identity matrix I is n, but rank\u00b1(I) = 3 (Alon et al., 2015).", "startOffset": 76, "endOffset": 95}, {"referenceID": 15, "context": "By permutation of the columns 2j and 2j + 1, the I matrix corresponds to the relation marriedTo, a relation known to be hard to factorize (Nickel et al., 2014).", "startOffset": 138, "endOffset": 159}, {"referenceID": 8, "context": "Models were trained using Stochastic Gradient Descent with mini-batches and AdaGrad for tuning the learning rate (Duchi et al., 2011), by minimizing the negative log-likelihood of the logistic model with L regularization on the parameters \u0398 of the considered model:", "startOffset": 113, "endOffset": 133}, {"referenceID": 22, "context": "As expected, DistMult (Yang et al., 2015) is not able to model antisymmetry and only predicts the symmetric relations correctly.", "startOffset": 22, "endOffset": 41}, {"referenceID": 14, "context": "RESCAL (Nickel et al., 2011), with its large number of parameters, quickly overfits as the rank grows.", "startOffset": 7, "endOffset": 28}, {"referenceID": 10, "context": "Canonical Polyadic (CP) decomposition (Hitchcock, 1927) fails Figure 2.", "startOffset": 38, "endOffset": 55}, {"referenceID": 4, "context": "We use original training, validation and test set splits as provided by Bordes et al. (2013b). Table 3 summarizes the metadata of the two datasets.", "startOffset": 72, "endOffset": 94}, {"referenceID": 4, "context": "As in Bordes et al. (2013b), we generated negatives using the local closed world assumption.", "startOffset": 6, "endOffset": 28}, {"referenceID": 6, "context": "We chose to use the negative log-likelihood of the logistic model, as it is a continuous surrogate of the sign-rank, and has been shown to learn compact representations for several important relations, especially for transitive relations (Bouchard et al., 2015).", "startOffset": 238, "endOffset": 261}, {"referenceID": 22, "context": "Furthermore, we chose TransE, DistMult and HolE as baselines since they are the best performing models on those datasets to the best of our knowledge (Nickel et al., 2016b; Yang et al., 2015).", "startOffset": 150, "endOffset": 191}, {"referenceID": 14, "context": "Furthermore, we chose TransE, DistMult and HolE as baselines since they are the best performing models on those datasets to the best of our knowledge (Nickel et al., 2016b; Yang et al., 2015). We also compare with the CP model to emphasize empirically the importance of learning unique embeddings for entities. For experimental fairness, we reimplemented these methods within the same framework as the ComplEx model, using theano (Bergstra et al., 2010). However, due to time constraints and the complexity of an efficient implementation of HolE, we record the original results for HolE as reported in Nickel et al. (2016b).", "startOffset": 151, "endOffset": 624}, {"referenceID": 22, "context": "We think this may also explain the large gap of improvement our model provides on this dataset compared to previously published results \u2013 as DistMult results are also better than those previously reported (Yang et al., 2015) \u2013 along with the use of the log-likelihood objective.", "startOffset": 205, "endOffset": 224}, {"referenceID": 2, "context": "The eigen-decomposition in the complex domain as taught today in linear algebra courses came 40 years later (Autonne, 1915).", "startOffset": 108, "endOffset": 123}, {"referenceID": 10, "context": "Similarly, most of the existing approaches for tensor factorization were based on decompositions in the real domain, such as the Canonical Polyadic (CP) decomposition (Hitchcock, 1927).", "startOffset": 167, "endOffset": 184}, {"referenceID": 14, "context": "But in the link prediction problem, antisymmetry of relations was quickly seen as a problem and asymmetric extensions of tensors were studied, mostly by either considering independent embeddings (Sutskever, 2009) or considering relations as matrices instead of vectors in the RESCAL model (Nickel et al., 2011).", "startOffset": 289, "endOffset": 310}, {"referenceID": 11, "context": "Direct extensions were based on uni-,bi- and trigram latent factors for triple data, as well as a low-rank relation matrix (Jenatton et al., 2012).", "startOffset": 123, "endOffset": 146}, {"referenceID": 21, "context": "relations) while Welbl et al. (2016) extend this also to other pairs.", "startOffset": 17, "endOffset": 37}, {"referenceID": 18, "context": "In the Neural Tensor Network (NTN) model, Socher et al. (2013) combine linear transformations and multiple bilinear forms of subject and object embeddings to jointly feed them into a nonlinear neural layer.", "startOffset": 42, "endOffset": 63}, {"referenceID": 22, "context": "The original multi-linear DistMult model is symmetric in subject and object for every relation (Yang et al., 2015) and achieves good performance, presumably due to its simplicity.", "startOffset": 95, "endOffset": 114}, {"referenceID": 4, "context": "The TransE model from Bordes et al. (2013b) also embeds entities and relations in the same space and imposes a geometrical structural bias into the model: the subject entity vector should be close to the object entity vector once translated by the relation vector.", "startOffset": 22, "endOffset": 44}], "year": 2016, "abstractText": "In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.1", "creator": "LaTeX with hyperref package"}}}