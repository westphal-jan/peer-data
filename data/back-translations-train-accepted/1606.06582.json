{"id": "1606.06582", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Jun-2016", "title": "Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-scale Image Classification", "abstract": "Unsupervised learning and supervised learning are key research topics in deep learning. However, as high-capacity supervised neural networks trained with a large amount of labels have achieved remarkable success in many computer vision tasks, the availability of large-scale labeled images reduced the significance of unsupervised learning. Inspired by the recent trend toward revisiting the importance of unsupervised learning, we investigate joint supervised and unsupervised learning in a large-scale setting by augmenting existing neural networks with decoding pathways for reconstruction. First, we demonstrate that the intermediate activations of pretrained large-scale classification networks preserve almost all the information of input images except a portion of local spatial details. Then, by end-to-end training of the entire augmented architecture with the reconstructive objective, we show improvement of the network performance for supervised tasks. We evaluate several variants of autoencoders, including the recently proposed \"what-where\" autoencoder that uses the encoder pooling switches, to study the importance of the architecture design. Taking the 16-layer VGGNet trained under the ImageNet ILSVRC 2012 protocol as a strong baseline for image classification, our methods improve the validation-set accuracy by a noticeable margin.", "histories": [["v1", "Tue, 21 Jun 2016 14:12:52 GMT  (6265kb,D)", "http://arxiv.org/abs/1606.06582v1", "International Conference on Machine Learning (ICML), 2016"]], "COMMENTS": "International Conference on Machine Learning (ICML), 2016", "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["yuting zhang", "kibok lee", "honglak lee"], "accepted": true, "id": "1606.06582"}, "pdf": {"name": "1606.06582.pdf", "metadata": {"source": "CRF", "title": "Augmenting Supervised Neural Networks with Unsupervised Objectives for Large-scale Image Classification", "authors": ["Yuting Zhang", "Kibok Lee", "Honglak Lee"], "emails": ["YUTINGZH@UMICH.EDU", "KIBOK@UMICH.EDU", "HONGLAK@EECS.UMICH.EDU"], "sections": [{"heading": "1. Introduction", "text": "This year it is more than ever before in the history of the city."}, {"heading": "2. Related work", "text": "In fact, most of them will be able to move into a different world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they, in which they live."}, {"heading": "3. Methods", "text": "In this section, we describe the training objectives and architectures of the proposed extended network. In Section 3.1, we briefly look at the architectures of newer networks for visual tasks and present the general form of our method. In Section 3.2, we add auxiliaries from deconvolutionary architectures to the classification network to build fully mirrored autoencoders on which we specify the auxiliary functions of the lens."}, {"heading": "3.1. Unsupervised loss for intermediate representations", "text": "It is not possible for these layers to work together, as the trait extractor does for a particular scale, we refer to the group as the macro layer (see the left half of Figure 1). Fully connected inner productive layer and / or global average layer follow the convolution pooling layer for feeding the top layer of the classification of the classification of the classification of the classification of the classification of the network. It is the top layer of the network. It is the top layer of the network (see the left half of Figure 1). Fully connected inner product specific layer and / or global average layer follow the convolution pooling layer of the macro. It is the top layer of the macro layer in which we refer to the group as the macro layer (see the left half of Figure 1). Fully connected inner product layer and / or global middle layer follow the convolution pooling layer for feeding the top layer of the classification of the classification of the network layer."}, {"heading": "3.2. Network augmentation with autoencoders", "text": "In fact, it is a matter of a way in which people move in the most diverse worlds of life in the world. (...) In fact, it is a matter of people moving in the most diverse worlds of life in the world in a way that they do. (...) The fact is that people in the different regions of the world move in a way that they do. (...) It is as if they were able to change the world. \"(...) It is as if they were able to change the world.\" (...)"}, {"heading": "4. Experiments", "text": "In this section, we evaluated various variants of the extended network for image reconstruction and classification on the ImageNet ILSVRC 2012 dataset, using the training set for training and the validation set for evaluation, and our experiments were mainly based on the 16-layer VGGNet (Simonyan & Zisserman, 2015).1 To compare existing methods for inverting neural networks (Dosovitskiy & Brox, 2016), we also partially used the network of Krizhevsky et al. (2012) called AlexNet, which was trained on the ILSVRC2012 training set."}, {"heading": "4.1. Training procedure", "text": "In fact, it's that we're able to hold our own, that we're able to put ourselves in a position to put ourselves at the top, \"he said."}, {"heading": "4.2. Image reconstruction via decoding pathways", "text": "The idea behind it is not new, but it is not new either: \"It's not new,\" she says, \"but it's new.\" Nor is it new: \"It's not new that there have been repeated exaggerations in recent years.\" Indeed: \"It's been shown that there have been exaggerations in recent years.\""}, {"heading": "4.3. Image classification with augmented architectures", "text": "We have adopted as our basis the 16-layer VGGNet networks, which are about improving the networks that we have developed over the last few years. \"The results of the study show that the individual systems are only two schemes that differ in different ways.\" It's not the way the individual schemes deal with each other, \"he said.\" It's the way the individual schemes are dealt with with with each other. \"\" It's the way the individual schemes are dealt with with with with each other. \"\" It's the way the individual schemes are dealt with with with each other. \"\" It's the way the individual schemes are dealt with with. \"It's the way the individual schemes are outlined.\" \"It's the way the individual schemes are outlined.\""}, {"heading": "5. Conclusion", "text": "We proposed a simple and effective method to integrate unattended targets into large-scale classification networks by extending the existing network with reconstructive decoding paths. By using the resulting autoencoder for image reconstruction, we demonstrated the ability to obtain input information by intermediate representation as an important feature of modern deep neural networks trained for large-scale image classification. We continued to marginalize this property by training the extended network, which consists of both classification and decoding paths, which significantly improved the performance of the 16-layer VGG network, one of the best existing networks for image classification. We examined various variants of the autoencoder and showed that 1) the interconnections between the coding and decoding paths were helpful, but not crucial for improving the performance of the classification network in large-scale image classification processes, and we demonstrated that we could use the interconnections between the coding and decoding paths in order to achieve the objective of large-scale decoding, 2) the loss of a common coding solution."}, {"heading": "Acknowledgements", "text": "This work was funded by Software R & D Center, Samsung Electronics Co., Ltd.; ONR N00014-13-1-0762; and NSF CAREER IIS-1453651. We also thank NVIDIA for donating K40c and TITAN X GPUs. We thank Jimei Yang, Seunghoon Hong, Ruben Villegas, Wenling Shang, Kihyuk Sohn and other contributors for helpful discussions."}, {"heading": "A1. Parameters for VGGNet-based models", "text": "We report on the learning parameters for the 16-layer VGGNet-based model in Table A-1. We selected the learning rates that resulted in the largest reduction in reconstruction loss for each layer in the first 2000 iterations. \"Loss weighting\" is a compensating factor for reconstruction losses in different layers, which were varied to make them comparable in magnitude. Specifically, we calculated image reconstruction loss using RGB values normalized to [0.1], which differ in scale from intermediate features, and we did not normalize reconstruction loss with feature dimensions for each layer."}, {"heading": "A2. More experimental results and discussions", "text": "It is only a matter of time before it will happen, until it will happen."}], "references": [{"title": "Learning deep architectures for ai", "author": ["Y. Bengio"], "venue": "Foundation and Trends in Machine Learning,", "citeRegEx": "Bengio,? \\Q2009\\E", "shortCiteRegEx": "Bengio", "year": 2009}, {"title": "Greedy layer-wise training of deep networks", "author": ["Y. Bengio", "P. Lamblin", "D. Popovici", "H. Larochelle"], "venue": "In NIPS,", "citeRegEx": "Bengio et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2007}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["J. Deng", "W. Dong", "R. Socher", "Li", "L.-J", "K. Li", "L. Fei-Fei"], "venue": "In CVPR,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Unsupervised visual representation learning by context prediction", "author": ["C. Doersch", "A. Gupta", "A.A. Efros"], "venue": "In ICCV,", "citeRegEx": "Doersch et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Doersch et al\\.", "year": 2015}, {"title": "Nonlinear principal component analysis based on principal curves and neural networks", "author": ["D. Dong", "T.J. McAvoy"], "venue": "Computers & Chemical Engineering,", "citeRegEx": "Dong and McAvoy,? \\Q1996\\E", "shortCiteRegEx": "Dong and McAvoy", "year": 1996}, {"title": "Inverting visual representations with convolutional networks", "author": ["A. Dosovitskiy", "T. Brox"], "venue": "In CVPR,", "citeRegEx": "Dosovitskiy and Brox,? \\Q2016\\E", "shortCiteRegEx": "Dosovitskiy and Brox", "year": 2016}, {"title": "Region-based convolutional networks for accurate object detection and segmentation", "author": ["R. Girshick", "J. Donahue", "T. Darrell", "J. Malik"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Girshick et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Girshick et al\\.", "year": 2016}, {"title": "Multi-prediction deep boltzmann machines", "author": ["I. Goodfellow", "M. Mirza", "A. Courville", "Y. Bengio"], "venue": "In NIPS,", "citeRegEx": "Goodfellow et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2013}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": null, "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "A fast learning algorithm for deep belief nets", "author": ["G.E. Hinton", "S. Osindero", "Teh", "Y.-W"], "venue": "Neural computation,", "citeRegEx": "Hinton et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2006}, {"title": "Gradient flow in recurrent nets: the difficulty of learning long-term dependencies", "author": ["S. Hochreiter", "Y. Bengio", "P. Frasconi", "J. Schmidhuber"], "venue": "In A Field Guide to Dynamical Recurrent Networks", "citeRegEx": "Hochreiter et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 2001}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "In ICML,", "citeRegEx": "Ioffe and Szegedy,? \\Q2015\\E", "shortCiteRegEx": "Ioffe and Szegedy", "year": 2015}, {"title": "Caffe: Convolutional architecture for fast feature embedding", "author": ["Y. Jia", "E. Shelhamer", "J. Donahue", "S. Karayev", "J. Long", "R. Girshick", "S. Guadarrama", "T. Darrell"], "venue": null, "citeRegEx": "Jia et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Jia et al\\.", "year": 2014}, {"title": "Fast inference in sparse coding algorithms with applications to object recognition", "author": ["K. Kavukcuoglu", "M.A. Ranzato", "Y. LeCun"], "venue": null, "citeRegEx": "Kavukcuoglu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kavukcuoglu et al\\.", "year": 2010}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "In NIPS,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Classification using discriminative restricted boltzmann machines", "author": ["H. Larochelle", "Y. Bengio"], "venue": "In ICML,", "citeRegEx": "Larochelle and Bengio,? \\Q2008\\E", "shortCiteRegEx": "Larochelle and Bengio", "year": 2008}, {"title": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "author": ["H. Lee", "R. Grosse", "R. Ranganath", "A.Y. Ng"], "venue": "In ICML,", "citeRegEx": "Lee et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2009}, {"title": "Understanding deep image representations by inverting them", "author": ["A. Mahendran", "A. Vedaldi"], "venue": "In CVPR,", "citeRegEx": "Mahendran and Vedaldi,? \\Q2015\\E", "shortCiteRegEx": "Mahendran and Vedaldi", "year": 2015}, {"title": "Supervised dictionary learning", "author": ["J. Mairal", "J. Ponce", "G. Sapiro", "A. Zisserman", "F.R. Bach"], "venue": "In NIPS,", "citeRegEx": "Mairal et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Mairal et al\\.", "year": 2009}, {"title": "Winner-take-all autoencoders", "author": ["A. Makhzani", "B.J. Frey"], "venue": "In NIPS,", "citeRegEx": "Makhzani and Frey,? \\Q2015\\E", "shortCiteRegEx": "Makhzani and Frey", "year": 2015}, {"title": "Stacked convolutional auto-encoders for hierarchical feature extraction", "author": ["J. Masci", "U. Meier", "D. Cire\u015fan", "J. Schmidhuber"], "venue": "In International Conference on Artificial Neural Networks,", "citeRegEx": "Masci et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Masci et al\\.", "year": 2011}, {"title": "Semi-supervised learning of compact document representations with deep networks", "author": ["M.A. Ranzato", "M. Szummer"], "venue": "In ICML,", "citeRegEx": "Ranzato and Szummer,? \\Q2008\\E", "shortCiteRegEx": "Ranzato and Szummer", "year": 2008}, {"title": "Unsupervised learning of invariant feature hierarchies with applications to object recognition", "author": ["M.A. Ranzato", "F.J. Huang", "Boureau", "Y.-L", "Y. LeCun"], "venue": "In CVPR,", "citeRegEx": "Ranzato et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Ranzato et al\\.", "year": 2007}, {"title": "Semi-supervised learning with ladder network", "author": ["A. Rasmus", "H. Valpola", "M. Honkala", "M. Berglund", "T. Raiko"], "venue": "In NIPS,", "citeRegEx": "Rasmus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasmus et al\\.", "year": 2015}, {"title": "Deep boltzmann machines", "author": ["R. Salakhutdinov", "G.E. Hinton"], "venue": "In AISTATS,", "citeRegEx": "Salakhutdinov and Hinton,? \\Q2009\\E", "shortCiteRegEx": "Salakhutdinov and Hinton", "year": 2009}, {"title": "Nonlinear pca: a new hierarchical approach", "author": ["M. Scholz", "R. Vig\u00e1rio"], "venue": "In ESANN,", "citeRegEx": "Scholz and Vig\u00e1rio,? \\Q2002\\E", "shortCiteRegEx": "Scholz and Vig\u00e1rio", "year": 2002}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["K. Simonyan", "A. Zisserman"], "venue": "In ICLR,", "citeRegEx": "Simonyan and Zisserman,? \\Q2015\\E", "shortCiteRegEx": "Simonyan and Zisserman", "year": 2015}, {"title": "Learning and selecting features jointly with point-wise gated Boltzmann machines", "author": ["K. Sohn", "G. Zhou", "C. Lee", "H. Lee"], "venue": "In ICML,", "citeRegEx": "Sohn et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sohn et al\\.", "year": 2013}, {"title": "Rule-injection hints as a means of improving network performance and learning time", "author": ["S. Suddarth", "Y. Kergosien"], "venue": "Neural Networks,", "citeRegEx": "Suddarth and Kergosien,? \\Q1990\\E", "shortCiteRegEx": "Suddarth and Kergosien", "year": 1990}, {"title": "Rethinking the inception architecture for computer", "author": ["C. Szegedy", "V. Vanhoucke", "S. Ioffe", "J. Shlens", "Z. Wojna"], "venue": null, "citeRegEx": "Szegedy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2016}, {"title": "80 million tiny images: A large data set for nonparametric object and scene recognition", "author": ["A. Torralba", "R. Fergus", "W. Freeman"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Torralba et al\\.,? \\Q1958\\E", "shortCiteRegEx": "Torralba et al\\.", "year": 1958}, {"title": "From neural PCA to deep unsupervised learning", "author": ["H. Valpola"], "venue": "In Advances in Independent Component Analysis and Learning Machines (Chapter", "citeRegEx": "Valpola,? \\Q2015\\E", "shortCiteRegEx": "Valpola", "year": 2015}, {"title": "Extracting and composing robust features with denoising autoencoders", "author": ["P. Vincent", "H. Larochelle", "Y. Bengio", "P.A. Manzagol"], "venue": "In ICML,", "citeRegEx": "Vincent et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2008}, {"title": "Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion", "author": ["P. Vincent", "H. Larochelle", "I. Lajoie", "Y. Bengio", "Manzagol", "P.-A"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Vincent et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Vincent et al\\.", "year": 2010}, {"title": "Training deeper convolutional networks with deep supervision", "author": ["L. Wang", "Lee", "C.-Y", "Z. Tu", "S. Lazebnik"], "venue": null, "citeRegEx": "Wang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2015}, {"title": "Unsupervised learning of visual representations using videos", "author": ["X. Wang", "A. Gupta"], "venue": "In ICCV,", "citeRegEx": "Wang and Gupta,? \\Q2015\\E", "shortCiteRegEx": "Wang and Gupta", "year": 2015}, {"title": "Supervised translationinvariant sparse coding", "author": ["J. Yang", "K. Yu", "T. Huang"], "venue": "In CVPR,", "citeRegEx": "Yang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2010}, {"title": "Visualizing and understanding convolutional networks", "author": ["M.D. Zeiler", "R. Fergus"], "venue": "In ECCV,", "citeRegEx": "Zeiler and Fergus,? \\Q2014\\E", "shortCiteRegEx": "Zeiler and Fergus", "year": 2014}, {"title": "Adaptive deconvolutional networks for mid and high level feature learning", "author": ["M. Zeiler", "G. Taylor", "R. Fergus"], "venue": "In ICCV,", "citeRegEx": "Zeiler et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2011}, {"title": "Image reconstruction from pool5 features to images. The reconstruction loss is computed on the ILSVRC2012 validation set and measured with L2-distance with the ground truth (RGB values are in [0, 1]). The first 2 example images are from the ILSVRC2012 validation set (excluding the 100 categories). The rest are not in ImageNet", "author": [], "venue": null, "citeRegEx": "A.3.,? \\Q2012\\E", "shortCiteRegEx": "A.3.", "year": 2012}, {"title": "AlexNet reconstruction on ImageNet ILSVRC2012 validation set. (Best viewed when zoomed in on a screen", "author": ["Figure A"], "venue": null, "citeRegEx": "A.4.,? \\Q2012\\E", "shortCiteRegEx": "A.4.", "year": 2012}], "referenceMentions": [{"referenceID": 1, "context": "Many deep unsupervised models were proposed, such as stacked (denoising) autoencoders (Bengio et al., 2007; Vincent et al., 2010), deep belief networks (Hinton et al.", "startOffset": 86, "endOffset": 129}, {"referenceID": 33, "context": "Many deep unsupervised models were proposed, such as stacked (denoising) autoencoders (Bengio et al., 2007; Vincent et al., 2010), deep belief networks (Hinton et al.", "startOffset": 86, "endOffset": 129}, {"referenceID": 9, "context": ", 2010), deep belief networks (Hinton et al., 2006; Lee et al., 2009), sparse encoder-decoders (Ranzato et al.", "startOffset": 30, "endOffset": 69}, {"referenceID": 16, "context": ", 2010), deep belief networks (Hinton et al., 2006; Lee et al., 2009), sparse encoder-decoders (Ranzato et al.", "startOffset": 30, "endOffset": 69}, {"referenceID": 22, "context": ", 2009), sparse encoder-decoders (Ranzato et al., 2007; Kavukcuoglu et al., 2010), and deep Boltzmann machines (Salakhutdinov & Hinton, 2009).", "startOffset": 33, "endOffset": 81}, {"referenceID": 13, "context": ", 2009), sparse encoder-decoders (Ranzato et al., 2007; Kavukcuoglu et al., 2010), and deep Boltzmann machines (Salakhutdinov & Hinton, 2009).", "startOffset": 33, "endOffset": 81}, {"referenceID": 14, "context": "However, over the past few years, supervised learning without any unsupervised pretraining has achieved even better performance, and it has become the dominating approach to train deep neural networks for real-world tasks, such as image classification (Krizhevsky et al., 2012) and object detection (Girshick et al.", "startOffset": 252, "endOffset": 277}, {"referenceID": 6, "context": ", 2012) and object detection (Girshick et al., 2016).", "startOffset": 29, "endOffset": 52}, {"referenceID": 8, "context": ", 2015) and the residual structure (He et al., 2016), which were not limited by the modeling assumptions of unsupervised methods.", "startOffset": 35, "endOffset": 52}, {"referenceID": 23, "context": "Nonetheless, the existing validations (Rasmus et al., 2015; Pezeshki et al., 2016) were mostly on small-scale datasets like MNIST.", "startOffset": 38, "endOffset": 82}, {"referenceID": 0, "context": ", Ranzato & Szummer (2008); Larochelle & Bengio (2008); Sohn et al.", "startOffset": 41, "endOffset": 55}, {"referenceID": 0, "context": ", Ranzato & Szummer (2008); Larochelle & Bengio (2008); Sohn et al. (2013); Goodfellow et al.", "startOffset": 41, "endOffset": 75}, {"referenceID": 0, "context": ", Ranzato & Szummer (2008); Larochelle & Bengio (2008); Sohn et al. (2013); Goodfellow et al. (2013)) had been made to couple the unsupervised and supervised learning in the same phase, making unsupervised objectives able to impact the network training after supervised learning took place.", "startOffset": 41, "endOffset": 101}, {"referenceID": 0, "context": ", Ranzato & Szummer (2008); Larochelle & Bengio (2008); Sohn et al. (2013); Goodfellow et al. (2013)) had been made to couple the unsupervised and supervised learning in the same phase, making unsupervised objectives able to impact the network training after supervised learning took place. These methods unleashed new potential of unsupervised learning, but they have not yet been shown to scale to large amounts of labeled and unlabeled data. Rasmus et al. (2015) recently proposed an architecture that is easy to couple with a classification network by extending the stacked denoising autoencoder with lateral connections, i.", "startOffset": 41, "endOffset": 466}, {"referenceID": 0, "context": ", Ranzato & Szummer (2008); Larochelle & Bengio (2008); Sohn et al. (2013); Goodfellow et al. (2013)) had been made to couple the unsupervised and supervised learning in the same phase, making unsupervised objectives able to impact the network training after supervised learning took place. These methods unleashed new potential of unsupervised learning, but they have not yet been shown to scale to large amounts of labeled and unlabeled data. Rasmus et al. (2015) recently proposed an architecture that is easy to couple with a classification network by extending the stacked denoising autoencoder with lateral connections, i.e., from encoder to the same stages of the decoder, and their methods showed promising semi-supervised learning results. Nonetheless, the existing validations (Rasmus et al., 2015; Pezeshki et al., 2016) were mostly on small-scale datasets like MNIST. Recently, Zhao et al. (2015) proposed the \u201cwhatar X iv :1 60 6.", "startOffset": 41, "endOffset": 909}, {"referenceID": 37, "context": "where\u201d autoencoder (SWWAE) by extending the stacked convolutional autoencoder using Zeiler et al. (2011)\u2019s \u201cunpooling\u201d operator, which recovers the locational details (which was lost due to max-pooling) using the pooling switches from the encoder.", "startOffset": 84, "endOffset": 105}, {"referenceID": 33, "context": "Based on the above observations, we further improve the quality of reconstruction, an indication of the mutual information between the input and the feature representations (Vincent et al., 2010), by finetuning the entire augmented architecture with supervised and unsupervised objectives.", "startOffset": 173, "endOffset": 195}, {"referenceID": 2, "context": "To the best of our knowledge, this work is the first to show that unsupervised objective can improve the image classification accuracy of deep convolutional neural networks on largescale datasets, such as ImageNet (Deng et al., 2009).", "startOffset": 214, "endOffset": 233}, {"referenceID": 18, "context": "Mairal et al. (2009) proposed to combine the reconstruction loss of sparse coding and the classification loss of sparse features in a unified objective function.", "startOffset": 0, "endOffset": 21}, {"referenceID": 18, "context": "Mairal et al. (2009) proposed to combine the reconstruction loss of sparse coding and the classification loss of sparse features in a unified objective function. Yang et al. (2010) extended this supervised sparse coding with max-pooling to obtain translation-invariant local features.", "startOffset": 0, "endOffset": 181}, {"referenceID": 18, "context": "Mairal et al. (2009) proposed to combine the reconstruction loss of sparse coding and the classification loss of sparse features in a unified objective function. Yang et al. (2010) extended this supervised sparse coding with max-pooling to obtain translation-invariant local features. Zeiler et al. (2010) proposed deconvolutional networks for unsupervised feature learning that consist of multiple layers of convolutional sparse coding with max-pooling.", "startOffset": 0, "endOffset": 306}, {"referenceID": 18, "context": "Mairal et al. (2009) proposed to combine the reconstruction loss of sparse coding and the classification loss of sparse features in a unified objective function. Yang et al. (2010) extended this supervised sparse coding with max-pooling to obtain translation-invariant local features. Zeiler et al. (2010) proposed deconvolutional networks for unsupervised feature learning that consist of multiple layers of convolutional sparse coding with max-pooling. Each layer is trained to reconstruct the output of the previous layer. Zeiler et al. (2011) further introduced the \u201cunpooling with switches\u201d layer to deconvolutional networks to enable end-to-end training.", "startOffset": 0, "endOffset": 547}, {"referenceID": 0, "context": "As an alternative to sparse coding and discriminative convolutional networks, autoencoders (Bengio, 2009) are another class of models for representation learning, in particular for the non-linear principal component analysis (Dong & McAvoy, 1996; Scholz & Vig\u00e1rio, 2002) by minimizing the reconstruction errors of a bottlenecked neural network.", "startOffset": 91, "endOffset": 105}, {"referenceID": 1, "context": "The stacked autoencoder (SAE) (Bengio et al., 2007) is amenable for hierarchical representation learning.", "startOffset": 30, "endOffset": 51}, {"referenceID": 20, "context": "With pooling-induced sparsity bottlenecks (Makhzani & Frey, 2015), the convolutional SAE (Masci et al., 2011) can learn features from middle-size images.", "startOffset": 89, "endOffset": 109}, {"referenceID": 32, "context": "By injecting noises or corruptions to the input, denoising autoencoders (Vincent et al., 2008; 2010) can learn robust filters to recover the uncorrupted input.", "startOffset": 72, "endOffset": 100}, {"referenceID": 30, "context": "Valpola (2015) further added noises to intermediate layers of denoising autoencoders with lateral connections, which was called \u201cladder network\u201d.", "startOffset": 0, "endOffset": 15}, {"referenceID": 23, "context": "Rasmus et al. (2015) combined a classification task with the ladder network for semi-supervised learning, and they showed improved classification accuracy on MNIST and CIFAR-10.", "startOffset": 0, "endOffset": 21}, {"referenceID": 34, "context": "(2015)\u2019s \u201cdeeply supervised network\u201d incorporated classification objectives for intermediate layers, was able to improve the top-layer classification accuracy for reasonably large-scale networks (Wang et al., 2015).", "startOffset": 195, "endOffset": 214}, {"referenceID": 3, "context": "Recently, more task-specific unsupervised objectives for image and video representation learning were developed by using spatial context (Doersch et al., 2015) and video continuity (Wang & Gupta, 2015).", "startOffset": 137, "endOffset": 159}, {"referenceID": 15, "context": "As an alternative to the autoencoder, Lee et al. (2015)\u2019s \u201cdeeply supervised network\u201d incorporated classification objectives for intermediate layers, was able to improve the top-layer classification accuracy for reasonably large-scale networks (Wang et al.", "startOffset": 38, "endOffset": 56}, {"referenceID": 15, "context": "As an alternative to the autoencoder, Lee et al. (2015)\u2019s \u201cdeeply supervised network\u201d incorporated classification objectives for intermediate layers, was able to improve the top-layer classification accuracy for reasonably large-scale networks (Wang et al., 2015). In earlier work, Ranzato & Szummer (2008) conducted layerwise training by both classification and reconstruction objectives.", "startOffset": 38, "endOffset": 307}, {"referenceID": 14, "context": "(Krizhevsky et al., 2012) contain a single pathway of convolutional layers succeeded by nonlinear activation functions and interleaved with max-pooling layers to gradually transform features into high-level representations and gain spatial invariance at different scales.", "startOffset": 0, "endOffset": 25}, {"referenceID": 8, "context": "Recent networks (Simonyan & Zisserman, 2015; Szegedy et al., 2015; He et al., 2016; Szegedy et al., 2016) often nest a group of convolutional layers before applying a max-pooling layer.", "startOffset": 16, "endOffset": 105}, {"referenceID": 29, "context": "Recent networks (Simonyan & Zisserman, 2015; Szegedy et al., 2015; He et al., 2016; Szegedy et al., 2016) often nest a group of convolutional layers before applying a max-pooling layer.", "startOffset": 16, "endOffset": 105}, {"referenceID": 10, "context": "On the one hand, the training of lower intermediate layers might be problematic, because the gradient signals from the top layer can become vanished (Hochreiter et al., 2001) on its way to the bottom layer.", "startOffset": 149, "endOffset": 174}, {"referenceID": 8, "context": "Regularization by normalization (Ioffe & Szegedy, 2015) can alleviate this problem, but will also lead to large yet noisy gradients when networks are deep (He et al., 2016).", "startOffset": 155, "endOffset": 172}, {"referenceID": 23, "context": "Ladder network architectures Rasmus et al. (2015). : nodes; : noisy nodes; : encoder macro-layer; : decoder macro-layer; : inner-product layer; : reconstruction loss; : classification loss; : parameter tying.", "startOffset": 29, "endOffset": 50}, {"referenceID": 38, "context": "Inspired by Zeiler et al. (2011), we use Zhao", "startOffset": 12, "endOffset": 33}, {"referenceID": 23, "context": "Rasmus et al. (2015)\u2019s ladder network (Figure 3) is a more sophisticated way to augment existing sequential architectures with autoencoders.", "startOffset": 0, "endOffset": 21}, {"referenceID": 14, "context": "1 To compare with existing methods on inverting neural networks (Dosovitskiy & Brox, 2016), we also partially used Krizhevsky et al. (2012)\u2019s network, termed AlexNet, trained on ILSVRC2012 training set.", "startOffset": 115, "endOffset": 140}, {"referenceID": 14, "context": "we followed Krizhevsky et al. (2012)\u2019s data augmentation scheme, cropping an image at the center to make it square with the shorter edge unchanged, resizing the square to 256\u00d7256, and randomly sampling a 227\u00d7227 patch or its horizontally mirrored counterpart to feed the network.", "startOffset": 12, "endOffset": 37}, {"referenceID": 12, "context": "Our implementation was based on the Caffe framework (Jia et al., 2014).", "startOffset": 52, "endOffset": 70}], "year": 2016, "abstractText": "Unsupervised learning and supervised learning are key research topics in deep learning. However, as high-capacity supervised neural networks trained with a large amount of labels have achieved remarkable success in many computer vision tasks, the availability of large-scale labeled images reduced the significance of unsupervised learning. Inspired by the recent trend toward revisiting the importance of unsupervised learning, we investigate joint supervised and unsupervised learning in a large-scale setting by augmenting existing neural networks with decoding pathways for reconstruction. First, we demonstrate that the intermediate activations of pretrained large-scale classification networks preserve almost all the information of input images except a portion of local spatial details. Then, by end-to-end training of the entire augmented architecture with the reconstructive objective, we show improvement of the network performance for supervised tasks. We evaluate several variants of autoencoders, including the recently proposed \u201cwhat-where\" autoencoder that uses the encoder pooling switches, to study the importance of the architecture design. Taking the 16-layer VGGNet trained under the ImageNet ILSVRC 2012 protocol as a strong baseline for image classification, our methods improve the validation-set accuracy by a noticeable margin.", "creator": "LaTeX with hyperref package"}}}