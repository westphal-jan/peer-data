{"id": "1606.07035", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Jun-2016", "title": "Ancestral Causal Inference", "abstract": "Constraint-based causal discovery from limited data is a notoriously difficult challenge due to the many borderline independence test decisions. Several approaches to improve the reliability of the predictions by exploiting redundancy in the independence information have been proposed recently. Though promising, existing approaches can still be greatly improved in terms of accuracy and scalability. We present a novel method that reduces the combinatorial explosion of the search space by using a more coarse-grained representation of causal information, drastically reducing computation time. Additionally, we propose a method to score causal predictions based on their confidence. Crucially, our implementation also allows one to easily combine observational and interventional data and to incorporate various types of available background knowledge. We prove soundness and asymptotic consistency of our method and demonstrate that it can outperform the state-of-the-art on synthetic data, achieving a speedup of several orders of magnitude. We illustrate its practical feasibility by applying it on a challenging protein data set.", "histories": [["v1", "Wed, 22 Jun 2016 18:26:27 GMT  (7276kb,D)", "http://arxiv.org/abs/1606.07035v1", null], ["v2", "Fri, 11 Nov 2016 22:23:32 GMT  (1594kb,D)", "http://arxiv.org/abs/1606.07035v2", "Accepted in NIPS 2016"], ["v3", "Thu, 26 Jan 2017 14:26:27 GMT  (1603kb,D)", "http://arxiv.org/abs/1606.07035v3", "In Proceedings of Advances in Neural Information Processing Systems 29 (NIPS 2016)"]], "reviews": [], "SUBJECTS": "cs.LG cs.AI stat.ML", "authors": ["sara magliacane", "tom claassen", "joris m mooij"], "accepted": true, "id": "1606.07035"}, "pdf": {"name": "1606.07035.pdf", "metadata": {"source": "CRF", "title": "Ancestral Causal Inference", "authors": ["Sara Magliacane", "Tom Claassen", "Joris M. Mooij"], "emails": ["s.magliacane@uva.nl", "tomc@cs.ru.nl", "j.m.mooij@uva.nl"], "sections": [{"heading": "1 Introduction", "text": "This year, it is so far that it is only a matter of time before it is ready, until it is ready."}, {"heading": "2 Preliminaries and related work", "text": "We assume that the data generating the process can be modeled by a causal relationship between the individual variables. (D) We assume that the data generating the process can be modeled by a causal relationship between the individual variables. (D) We assume that the causal relationship between the two causal relationships is a direct causal relationship between Y and Y. (D) We assume that the causal relationship between Y and Y is a causal relationship between X and Y. (D) We write a series of variables W if there is a causal relationship between X and Y. If there is no causal relationship between X and Y, then there is no causal relationship between X and Y. (D) We assume that X and Y will have a causal relationship between X and Y. (X) We assume that we will have a causal relationship between X and Y."}, {"heading": "3 ACI: Ancestral Causal Inference", "text": "In this paper we are not able to get an idea of the reduction of the search space, but there are already more than 2.3 \u00b7 1015 encoding DAGs. ACI also allows weighted ancestral relationships as inputs, which make it possible to use interventional data as illustration in the real world."}, {"heading": "4 Scoring Causal Predictions", "text": "Restricted minimization (12) can produce several optimal solutions because the underlying structure may not be identifiable by the inputs. (W) To solve this problem, we propose to use the loss function (13) as follows to determine the security of a specific feature p (say, an ancestral relationship X 99K Y): C (p) = 99 W (W; I) = 99 W (W; I) = 99 W (W; I) = 99 W (W; I) = 99 W (W; I) = 99 W (W) = 99 W (W; I) = 99 W (W; I) = 99 W (W; I) = 99 W (W) = 99 W (W) = 99 W (W) = 99 W (W) = 99 W (W)."}, {"heading": "5 Evaluation", "text": "This year it is more than ever before in the history of the city."}, {"heading": "6 Discussion and conclusions", "text": "As our example illustrates, the determination of cause-and-effect relationships in real experiments is of the utmost importance, and ancestral structures are very well suited for this purpose. They also provide a natural opportunity to incorporate causal background knowledge, e.g. from other experiments. In addition, the ancestral structures can also be easily assigned to a finer-grained structural representation in the context of algorithms that aim at error correction, using redundant information, in order to show direct and indirect causal relationships, weighting the skeleton implied by output independence. Providing confidence estimates of causal predictions is extremely helpful in practice and can significantly increase the reliability of the results as perceived by researchers. Although standard methods for such as bootstrapping (C) FCI already provide reasonable estimates by providing a global optimization method that ensures all confidence in the input-independent results are not likely to be taken into account in the outcome."}, {"heading": "Acknowledgments", "text": "SM and JMM were supported by NWO, the Dutch Organisation for Scientific Research (VIDI funding 639.072.410). SM was also supported by the Dutch national programme COMMIT / as part of the Data2Semantics project. TC was supported by funds from the Seventh Framework Programme of the European Community (FP7 / 2007-2013) under Funding Agreement No 603016 (MATRICS)."}, {"heading": "7 Appendix A: Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1 ACI causal reasoning rules", "text": "For X, Y, U, W, W, Z, Z, W, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z, Z"}, {"heading": "7.2 Soundness", "text": "Theorem 3. Suppose the rules in R are solid. For each pair of variables X, Y, the confidence value C (X 99K Y) of (16) for oracle inputs with infinite weights is solid, i.e. C (X 99K Y) = \u221e, if X 99K Y is identifiable from the inputs, C (X 99K Y) = \u2212 \u221e, if X 699K Y is identifiable from the inputs, and C (X 99K Y) = 0 otherwise (neither is identifiable).Evidence. We assume that the process of generating data is described by a causal DAG that may contain additional latent variables, and that the distributions are faithful to the DAG. The theorem then follows directly from the solidity of the rules and the solidity of logical reasoning."}, {"heading": "7.3 Asymptotic consistency of scoring method", "text": "Theorem 4. Suppose the rules in R are sound: For each pair of variables X, Y is the confidence value C (X 99K Y) of (16) asymptotically consistent under assumption (14) or (15) in the main document, i.e., \u2022 C (X 99K Y) is consistent in the probability if X 99K Y is identifiable, \u2022 C (X 99K Y) is asymptotically consistent in the probability if X 99K Y is identifiable, \u2022 C (X 99K Y) \u2192 0 in the probability otherwise (neither is identifiable).Evidence. Since the number of statistical tests is fixed (or at least limited from above), the probability of an error in the test results converges asymptotically to 0. The loss function of all structures that do not correspond to the properties of true causal DAG converges in the probability to + \u221e, with the loss function of all structures that are asymptotically compatible with the true properties of the AG."}, {"heading": "8 Appendix B: Additional results on synthetic data", "text": "The overall results do not change: ACI and [9] overlap in the order c = 1 and they perform better than bootstrapped (C) FCI. In Figure (5) we show the performance of ACI and [9] in the higher order c = 4 in the same setting as Figure 2 (a-c) in the main work. As we see, the performance of ACI and [9] in the higher order does not really improve, but actually seems to deteriorate."}, {"heading": "9 Appendix C: Application on real data", "text": "The data consist of simultaneous measurements of the expression levels of eleven biochemical agents in individual cells of the human immune system under 14 different experimental conditions in which various activators and inhibitors were added to the cells. In Table 1 we show the subset of interventions we are considering in our experiments. In Figure 6 we show the inputs (first row) and the results for the different algorithms in which we investigate a setting similar to that in the main work, but now always the addition of intercellularity of the protein-2 (ICAM-2) reagent in combination with the other reagents."}], "references": [{"title": "Incorporating causal prior knowledge as path-constraints in bayesian networks and maximal ancestral graphs", "author": ["G. Borboudakis", "I. Tsamardinos"], "venue": "ICML, pages 1799\u20131806,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2012}, {"title": "A logical characterization of constraint-based causal discovery", "author": ["T. Claassen", "T. Heskes"], "venue": "UAI, pages 135\u2013144,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2011}, {"title": "A Bayesian approach to constraint-based causal inference", "author": ["T. Claassen", "T. Heskes"], "venue": "UAI, pages 207\u2013216,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Learning high-dimensional directed acyclic graphs with latent and selection variables", "author": ["D. Colombo", "M.H. Maathuis", "M. Kalisch", "T.S. Richardson"], "venue": "The Annals of Statistics, 40(1):294\u2013321,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2012}, {"title": "Exact Bayesian structure learning from uncertain interventions", "author": ["D. Eaton", "K. Murphy"], "venue": "AISTATS, pages 107\u2013114,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2007}, {"title": "Data-driven covariate selection for nonparametric estimation of causal effects", "author": ["D. Entner", "P.O. Hoyer", "P. Spirtes"], "venue": "AISTATS, volume 31 of JMLR Proceedings, pages 256\u2013264. JMLR.org,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2013}, {"title": "Clingo = ASP + control: Extended report", "author": ["M. Gebser", "R. Kaminski", "B. Kaufmann", "T. Schaub"], "venue": "Technical report, University of Potsdam,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2014}, {"title": "Answer sets", "author": ["M. Gelfond"], "venue": "F. van Harmelen, V. Lifschitz, and B. W. Porter, editors, Handbook of Knowledge Representation, volume 3 of Foundations of Artificial Intelligence, pages 285\u2013316. Elsevier,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2008}, {"title": "Constraint-based causal discovery: Conflict resolution with Answer Set Programming", "author": ["A. Hyttinen", "F. Eberhardt", "M. J\u00e4rvisalo"], "venue": "UAI, pages 340\u2013349,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2014}, {"title": "Estimating high-dimensional directed acyclic graphs with the PC-algorithm", "author": ["M. Kalisch", "P. B\u00fchlmann"], "venue": "JMLR, 8:613\u2013636, Mar.", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2007}, {"title": "Causal inference using graphical models with the R package pcalg", "author": ["M. Kalisch", "M. M\u00e4chler", "D. Colombo", "M. Maathuis", "P. B\u00fchlmann"], "venue": "Journal of Statistical Software, 47(1):1\u201326,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2012}, {"title": "What is answer set programming? In D", "author": ["V. Lifschitz"], "venue": "Fox and C. P. Gomes, editors, AAAI, pages 1594\u20131597. AAAI Press,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2008}, {"title": "Efficient Markov network discovery using particle filters", "author": ["D. Margaritis", "F. Bromberg"], "venue": "Computational Intelligence, 25(4):367\u2013394,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "Probabilistic soft interventions in conditional Gaussian networks", "author": ["F. Markowetz", "S. Grossmann", "R. Spang"], "venue": "AISTATS, pages 214\u2013221,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2005}, {"title": "Cyclic causal discovery from continuous equilibrium data", "author": ["J.M. Mooij", "T. Heskes"], "venue": "A. Nicholson and P. Smyth, editors, UAI, pages 431\u2013439. AUAI Press,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Causality: models, reasoning and inference", "author": ["J. Pearl"], "venue": "Cambridge University Press,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2009}, {"title": "Adjacency-faithfulness and conservative causal inference", "author": ["J. Ramsey", "J. Zhang", "P. Spirtes"], "venue": "UAI. AUAI Press,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2006}, {"title": "BACKSHIFT: Learning causal cyclic graphs from unknown shift interventions", "author": ["D. Rothenh\u00e4usler", "C. Heinze", "J. Peters", "N. Meinshausen"], "venue": "NIPS, pages 1513\u20131521. Curran Associates, Inc.,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Marginal causal consistency in constraint-based causal learning", "author": ["A. Roumpelaki", "G. Borboudakis", "S. Triantafillou", "I. Tsamardinos"], "venue": "UAI,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2016}, {"title": "Causal protein-signaling networks derived from multiparameter singlecell", "author": ["K. Sachs", "O. Perez", "D. Pe\u2019er", "D. Lauffenburger", "G. Nolan"], "venue": "data. Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2005}, {"title": "Causation, Prediction, and Search", "author": ["P. Spirtes", "C. Glymour", "R. Scheines"], "venue": "MIT press, 2nd edition,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2000}, {"title": "Causal discovery from changes", "author": ["J. Tian", "J. Pearl"], "venue": "UAI, pages 512\u2013521,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2001}, {"title": "Constraint-based causal discovery from multiple interventions over overlapping variable sets", "author": ["S. Triantafillou", "I. Tsamardinos"], "venue": "JMLR, 16:2147\u20132205,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "On the completeness of orientation rules for causal discovery in the presence of latent confounders and selection bias", "author": ["J. Zhang"], "venue": "Artif. Intell., 172(16-17):1873\u20131896, Nov.", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2008}], "referenceMentions": [{"referenceID": 15, "context": "In most cases, cause-effect relations are recovered from experimental data in which the variable of interest is perturbed, but seminal work like the do-calculus [16] and the PC/FCI algorithms [21, 24] demonstrate that, under certain assumptions (e.", "startOffset": 161, "endOffset": 165}, {"referenceID": 20, "context": "In most cases, cause-effect relations are recovered from experimental data in which the variable of interest is perturbed, but seminal work like the do-calculus [16] and the PC/FCI algorithms [21, 24] demonstrate that, under certain assumptions (e.", "startOffset": 192, "endOffset": 200}, {"referenceID": 23, "context": "In most cases, cause-effect relations are recovered from experimental data in which the variable of interest is perturbed, but seminal work like the do-calculus [16] and the PC/FCI algorithms [21, 24] demonstrate that, under certain assumptions (e.", "startOffset": 192, "endOffset": 200}, {"referenceID": 20, "context": ", the well-known Causal Markov and Faithfulness assumptions [21]), it is already possible to obtain significant causal information by using only observational data.", "startOffset": 60, "endOffset": 64}, {"referenceID": 16, "context": "Classical constraint-based algorithms are not able to resolve such conflicts, and often simply ignore, or at best try to avoid them [17].", "startOffset": 132, "endOffset": 136}, {"referenceID": 2, "context": "Different approaches to resolving such conflicts have been proposed recently [3, 23, 9].", "startOffset": 77, "endOffset": 87}, {"referenceID": 22, "context": "Different approaches to resolving such conflicts have been proposed recently [3, 23, 9].", "startOffset": 77, "endOffset": 87}, {"referenceID": 8, "context": "Different approaches to resolving such conflicts have been proposed recently [3, 23, 9].", "startOffset": 77, "endOffset": 87}, {"referenceID": 8, "context": "Several weighting schemes can be defined, from simple ways to attach weights to single independence statements [9] to more complicated schemes to obtain weights for combinations of independence statements [23, 3].", "startOffset": 111, "endOffset": 114}, {"referenceID": 22, "context": "Several weighting schemes can be defined, from simple ways to attach weights to single independence statements [9] to more complicated schemes to obtain weights for combinations of independence statements [23, 3].", "startOffset": 205, "endOffset": 212}, {"referenceID": 2, "context": "Several weighting schemes can be defined, from simple ways to attach weights to single independence statements [9] to more complicated schemes to obtain weights for combinations of independence statements [23, 3].", "startOffset": 205, "endOffset": 212}, {"referenceID": 22, "context": "Reasoning can then be formulated as a step-by-step approach in which the statements are processed in order of their weight and conflicts are ignored [23, 3], or as a global optimization problem as in [9].", "startOffset": 149, "endOffset": 156}, {"referenceID": 2, "context": "Reasoning can then be formulated as a step-by-step approach in which the statements are processed in order of their weight and conflicts are ignored [23, 3], or as a global optimization problem as in [9].", "startOffset": 149, "endOffset": 156}, {"referenceID": 8, "context": "Reasoning can then be formulated as a step-by-step approach in which the statements are processed in order of their weight and conflicts are ignored [23, 3], or as a global optimization problem as in [9].", "startOffset": 200, "endOffset": 203}, {"referenceID": 8, "context": "While offering a better accuracy than greedy approaches, one major challenge for the conflict resolution methods that use a global optimization like [9] consists in the scalability of the algorithms due to the vastness of the search space.", "startOffset": 149, "endOffset": 152}, {"referenceID": 1, "context": "One of the most flexible formulations of constraint-based causal discovery is in logic [2, 3, 23, 9].", "startOffset": 87, "endOffset": 100}, {"referenceID": 2, "context": "One of the most flexible formulations of constraint-based causal discovery is in logic [2, 3, 23, 9].", "startOffset": 87, "endOffset": 100}, {"referenceID": 22, "context": "One of the most flexible formulations of constraint-based causal discovery is in logic [2, 3, 23, 9].", "startOffset": 87, "endOffset": 100}, {"referenceID": 8, "context": "One of the most flexible formulations of constraint-based causal discovery is in logic [2, 3, 23, 9].", "startOffset": 87, "endOffset": 100}, {"referenceID": 0, "context": "This is not trivial in traditional constraint-based approaches like FCI that use a set of fixed rules following a strict order of execution, and even the common task of incorporating ancestral knowledge can require a complex post-processing step [1].", "startOffset": 246, "endOffset": 249}, {"referenceID": 8, "context": "ACI solves an optimization problem in the spirit of [9], but uses an entirely different encoding using novel ancestral reasoning rules that bypasses the construction of fine-grained representations and thereby can achieve speedups of several orders of magnitude over the method of [9].", "startOffset": 52, "endOffset": 55}, {"referenceID": 8, "context": "ACI solves an optimization problem in the spirit of [9], but uses an entirely different encoding using novel ancestral reasoning rules that bypasses the construction of fine-grained representations and thereby can achieve speedups of several orders of magnitude over the method of [9].", "startOffset": 281, "endOffset": 284}, {"referenceID": 8, "context": "We apply our method to score confidences of ancestral relations to both ACI and the method from [9] and show on synthetic data that it can outperform bootstrapped (C)FCI.", "startOffset": 96, "endOffset": 99}, {"referenceID": 19, "context": "We apply ACI to a challenging real-world data set [20] that so far had only been addressed with score-based methods and observe that it successfully recovers from faithfulness violations.", "startOffset": 50, "endOffset": 54}, {"referenceID": 20, "context": "We will assume that the Causal Markov Assumption and the Causal Faithfulness Assumption [21] both hold.", "startOffset": 88, "endOffset": 92}, {"referenceID": 1, "context": "Following [2] we define a minimal conditional independence by:", "startOffset": 10, "endOffset": 13}, {"referenceID": 1, "context": "Minimal conditional (in)dependences are closely related to ancestral relations, as pointed out in [2]: Lemma 1.", "startOffset": 98, "endOffset": 101}, {"referenceID": 16, "context": "Related work on conflict resolution One of the earliest algorithms to deal with conflicting inputs in constraint-based causal discovery is Conservative PC [17], which adds \u201credundant\u201d checks to the PC algorithm that allow to detect inconsistencies in the inputs, and then makes only predictions that do not rely on the ambiguous inputs.", "startOffset": 155, "endOffset": 159}, {"referenceID": 3, "context": "The same idea can be applied to FCI, yielding Conservative FCI (CFCI) [4, 11].", "startOffset": 70, "endOffset": 77}, {"referenceID": 10, "context": "The same idea can be applied to FCI, yielding Conservative FCI (CFCI) [4, 11].", "startOffset": 70, "endOffset": 77}, {"referenceID": 2, "context": "BCCD [3] uses Bayesian confidence estimates to process information in decreasing order of reliability, discarding contradictory input as they arise.", "startOffset": 5, "endOffset": 8}, {"referenceID": 22, "context": "COMBINE [23] is an algorithm that combines the output of FCI on several overlapping observational and experimental datasets into a single causal model by first pooling and recalibrating the independence test p-values, and then adding each constraint incrementally in order of reliability to a SAT instance.", "startOffset": 8, "endOffset": 12}, {"referenceID": 8, "context": "Our approach is inspired by recent work [9], in which causal discovery is formulated as a constrained discrete minimization problem.", "startOffset": 40, "endOffset": 43}, {"referenceID": 8, "context": "Given a list of weighted independence statements, the method by [9] searches for the optimal causal graph G that minimizes the sum of the weights of the independence statements that are violated according to G.", "startOffset": 64, "endOffset": 67}, {"referenceID": 8, "context": "builds on the work of [9], but rather than optimizing over encoding DAGs, ACI optimizes over the much simpler (but still very expressive) ancestral structures, giving a huge computational speedup.", "startOffset": 22, "endOffset": 25}, {"referenceID": 8, "context": "Ancestral Causal Inference rules The rules from [9] explicitly encode marginalization and conditioning operations on d-connection graphs, so they cannot be easily adapted to work directly with ancestral relations.", "startOffset": 48, "endOffset": 51}, {"referenceID": 8, "context": "Optimization of loss function In order to handle conflicts in the inputs, we follow [9] and formulate the causal discovery problem as an optimization problem where a loss function is optimized over possible causal structures.", "startOffset": 84, "endOffset": 87}, {"referenceID": 8, "context": "In [9], the possible structuresW correspond with all possible causal graphs (ADMGs in the acyclic case) and the rules correspond with operations on d-connection graphs, whereas in ACIW corresponds with all ancestral structures and the rulesR are rules (1)\u2013(11).", "startOffset": 3, "endOffset": 6}, {"referenceID": 8, "context": ", Answer Set Programming (ASP), is very convenient and is used both in [9] and in this paper.", "startOffset": 71, "endOffset": 74}, {"referenceID": 11, "context": "ASP is a widely used declarative programming language based on the stable model semantics[12, 8] that has successfully been applied to several NP-hard problems.", "startOffset": 89, "endOffset": 96}, {"referenceID": 7, "context": "ASP is a widely used declarative programming language based on the stable model semantics[12, 8] that has successfully been applied to several NP-hard problems.", "startOffset": 89, "endOffset": 96}, {"referenceID": 6, "context": "To implement ACI we use the state-of-the-art ASP solver clingo [7].", "startOffset": 63, "endOffset": 66}, {"referenceID": 15, "context": "This approach conveniently applies to various types of interventions: perfect interventions [16], soft interventions [14], mechanism changes [22], and activity interventions [15].", "startOffset": 92, "endOffset": 96}, {"referenceID": 13, "context": "This approach conveniently applies to various types of interventions: perfect interventions [16], soft interventions [14], mechanism changes [22], and activity interventions [15].", "startOffset": 117, "endOffset": 121}, {"referenceID": 21, "context": "This approach conveniently applies to various types of interventions: perfect interventions [16], soft interventions [14], mechanism changes [22], and activity interventions [15].", "startOffset": 141, "endOffset": 145}, {"referenceID": 14, "context": "This approach conveniently applies to various types of interventions: perfect interventions [16], soft interventions [14], mechanism changes [22], and activity interventions [15].", "startOffset": 174, "endOffset": 178}, {"referenceID": 8, "context": "For example, in combination with the method of [9] it can be used to score direct causal relations.", "startOffset": 47, "endOffset": 50}, {"referenceID": 8, "context": "Average execution time (s) n c ACI [9] 6 1 0.", "startOffset": 35, "endOffset": 38}, {"referenceID": 8, "context": "Instances (sorted by solu&on &me) Hy/nen14 [9]", "startOffset": 43, "endOffset": 46}, {"referenceID": 9, "context": "[10] show how this can be done for partial correlation tests assuming the distribution is multivariate Gaussian.", "startOffset": 0, "endOffset": 4}, {"referenceID": 8, "context": "Synthetic data We simulate the data using the simulator from [9]: for each experimental condition (e.", "startOffset": 61, "endOffset": 64}, {"referenceID": 9, "context": ", [10]) setting the significance level to \u03b1 = 0.", "startOffset": 2, "endOffset": 6}, {"referenceID": 12, "context": "For the Bayesian weights, we use the Bayesian test for conditional independence presented in [13] as implemented by [9] with a prior probability of 0.", "startOffset": 93, "endOffset": 97}, {"referenceID": 8, "context": "For the Bayesian weights, we use the Bayesian test for conditional independence presented in [13] as implemented by [9] with a prior probability of 0.", "startOffset": 116, "endOffset": 119}, {"referenceID": 8, "context": "We score confidences using (16) for ACI and for the acyclic causally insufficient models presented in [9], and use the same independence tests as input, optionally up to a maximum order c.", "startOffset": 102, "endOffset": 105}, {"referenceID": 8, "context": "On 7 variables, the scoring method with ACI is almost 3 orders of magnitude faster than [9], and the difference grows exponentially with n increases.", "startOffset": 88, "endOffset": 91}, {"referenceID": 8, "context": "On 8 variables the method from [9] is able to complete only four of the first 40 simulated models before the timeout 25\u00d7 10 s.", "startOffset": 31, "endOffset": 34}, {"referenceID": 8, "context": "Hyttinen14 [9] (c=1)", "startOffset": 11, "endOffset": 14}, {"referenceID": 8, "context": "Hyttinen14 [9] (c=1)", "startOffset": 11, "endOffset": 14}, {"referenceID": 8, "context": "Hyttinen14 [9] (c=1)", "startOffset": 11, "endOffset": 14}, {"referenceID": 23, "context": "use a bootstrapped version (which averages of the results of 100 executions using random subsets of half the data) of FCI [24] and Conservative FCI (CFCI) [4], as implemented in the pcalg R package [11].", "startOffset": 122, "endOffset": 126}, {"referenceID": 3, "context": "use a bootstrapped version (which averages of the results of 100 executions using random subsets of half the data) of FCI [24] and Conservative FCI (CFCI) [4], as implemented in the pcalg R package [11].", "startOffset": 155, "endOffset": 158}, {"referenceID": 10, "context": "use a bootstrapped version (which averages of the results of 100 executions using random subsets of half the data) of FCI [24] and Conservative FCI (CFCI) [4], as implemented in the pcalg R package [11].", "startOffset": 198, "endOffset": 202}, {"referenceID": 18, "context": "1 from [19].", "startOffset": 7, "endOffset": 11}, {"referenceID": 22, "context": "For reference we also include the (unbootstrapped) performance of COMBINE [23], although the method is not designed for this setting with only observational data.", "startOffset": 74, "endOffset": 78}, {"referenceID": 8, "context": "The performances of the scoring method with [9] and ACI coincide, performing significantly better for nonancestral predictions and the top ancestral predictions (see zoomed-in version in Figure 2(b)), even when using only as inputs independence test results up to maximum order c = 1, instead of independence test results of any order as FCI, CFCI and COMBINE.", "startOffset": 44, "endOffset": 47}, {"referenceID": 8, "context": "Nevertheless, our scoring approach (16) outperforms bootstrapped (C)FCI for both encodings [9] and ACI, suggesting that nontrivial error-correction is going on.", "startOffset": 91, "endOffset": 94}, {"referenceID": 8, "context": "In this setting the approach from [9] is too slow.", "startOffset": 34, "endOffset": 37}, {"referenceID": 19, "context": "Application on real data We consider the challenging task of reconstructing a signalling network from flow cytometry data [20].", "startOffset": 122, "endOffset": 126}, {"referenceID": 19, "context": "In contrast with likelihood-based approaches to causal discovery that have been applied in earlier work [20, 5, 15, 18], in our approach we do not need to model the interventions quantitatively.", "startOffset": 104, "endOffset": 119}, {"referenceID": 4, "context": "In contrast with likelihood-based approaches to causal discovery that have been applied in earlier work [20, 5, 15, 18], in our approach we do not need to model the interventions quantitatively.", "startOffset": 104, "endOffset": 119}, {"referenceID": 14, "context": "In contrast with likelihood-based approaches to causal discovery that have been applied in earlier work [20, 5, 15, 18], in our approach we do not need to model the interventions quantitatively.", "startOffset": 104, "endOffset": 119}, {"referenceID": 17, "context": "In contrast with likelihood-based approaches to causal discovery that have been applied in earlier work [20, 5, 15, 18], in our approach we do not need to model the interventions quantitatively.", "startOffset": 104, "endOffset": 119}, {"referenceID": 8, "context": "We note that the method of [9] is computationally infeasible, while COMBINE assumes perfect interventions (while here we mostly have activity interventions).", "startOffset": 27, "endOffset": 30}, {"referenceID": 8, "context": "On top of that, in the context of algorithms that aim for error-correction by exploiting redundant information, they also allow a huge computational advantage over existing edge-based representations such as [9].", "startOffset": 208, "endOffset": 211}, {"referenceID": 5, "context": "This is a strengthened version of rule R2(i) in [6]: note that the additional assumptions made there (Y 6 99K Z, Y 6 99K X) are redundant and not actually used in their proof.", "startOffset": 48, "endOffset": 51}, {"referenceID": 8, "context": "Bootstrapped (100) CFCI Bootstrapped (100) FCI Hyttinen14 [9] (c=1) ACI (c=1) CFCI FCI", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "Bootstrapped (100) CFCI Bootstrapped (100) FCI Hyttinen14 [9] (c=1) ACI (c=1) CFCI FCI", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "Bootstrapped (100) CFCI Bootstrapped (100) FCI Hyttinen14 [9] (c=1) ACI (c=1) CFCI FCI", "startOffset": 58, "endOffset": 61}, {"referenceID": 8, "context": "The overall conclusions do not change: ACI and [9] overlap for order c = 1 and they perform better than bootstrapped (C)FCI.", "startOffset": 47, "endOffset": 50}, {"referenceID": 8, "context": "In Figure (5) we show the performance of ACI and [9] for higher order c = 4 on the same setting as Figure 2 (a-c) in the main paper.", "startOffset": 49, "endOffset": 52}, {"referenceID": 8, "context": "As we see, the performances of ACI and [9] do not really improve with higher order but actually seem to deteriorate.", "startOffset": 39, "endOffset": 42}, {"referenceID": 19, "context": "We provide more details and more results on the real-world dataset we describe in the main paper, the flow cytometry data [20].", "startOffset": 122, "endOffset": 126}, {"referenceID": 8, "context": "Bootstrapped (100) CFCI COMBINE Bootstrapped (100) FCI Hyttinen14 [9] (c=1)", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "Hyttinen14 [9] (c=4)", "startOffset": 11, "endOffset": 14}, {"referenceID": 8, "context": "Bootstrapped (100) CFCI COMBINE Bootstrapped (100) FCI Hyttinen14 [9] (c=1)", "startOffset": 66, "endOffset": 69}, {"referenceID": 8, "context": "Hyttinen14 [9] (c=4) ACI (c=1) ACI (c=4) CFCI FCI", "startOffset": 11, "endOffset": 14}], "year": 2017, "abstractText": "Constraint-based causal discovery from limited data is a notoriously difficult challenge due to the many borderline independence test decisions. Several approaches to improve the reliability of the predictions by exploiting redundancy in the independence information have been proposed recently. Though promising, existing approaches can still be greatly improved in terms of accuracy and scalability. We present a novel method that reduces the combinatorial explosion of the search space by using a more coarse-grained representation of causal information, drastically reducing computation time. Additionally, we propose a method to score causal predictions based on their confidence. Crucially, our implementation also allows one to easily combine observational and interventional data and to incorporate various types of available background knowledge. We prove soundness and asymptotic consistency of our method and demonstrate that it can outperform the state-ofthe-art on synthetic data, achieving a speedup of several orders of magnitude. We illustrate its practical feasibility by applying it on a challenging protein data set.", "creator": "LaTeX with hyperref package"}}}