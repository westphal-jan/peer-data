{"id": "1606.07493", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Jun-2016", "title": "Sort Story: Sorting Jumbled Images and Captions into Stories", "abstract": "Temporal common sense has applications in AI tasks such as QA, multi-document summarization, and human-AI communication. We propose the task of sequencing -- given a jumbled set of aligned image-caption pairs that belong to a story, the task is to sort them such that the output sequence forms a coherent story. We present multiple approaches, via unary (position) and pairwise (order) predictions, and their ensemble-based combinations, achieving strong results on this task. As features, we use both text-based and image-based features, which depict complementary improvements. Using qualitative examples, we demonstrate that our models have learnt interesting aspects of temporal common sense.", "histories": [["v1", "Thu, 23 Jun 2016 21:54:44 GMT  (5382kb,D)", "https://arxiv.org/abs/1606.07493v1", "8 pages, 4 figures"], ["v2", "Thu, 30 Jun 2016 05:26:43 GMT  (4627kb,D)", "http://arxiv.org/abs/1606.07493v2", "8 pages, 4 figures"], ["v3", "Wed, 6 Jul 2016 19:56:36 GMT  (4632kb,D)", "http://arxiv.org/abs/1606.07493v3", "9 pages, 4 figures"], ["v4", "Sat, 24 Sep 2016 00:37:27 GMT  (4883kb,D)", "http://arxiv.org/abs/1606.07493v4", "To appear in EMNLP 2016"], ["v5", "Mon, 7 Nov 2016 18:48:13 GMT  (4888kb,D)", "http://arxiv.org/abs/1606.07493v5", "EMNLP 2016"]], "COMMENTS": "8 pages, 4 figures", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.CV cs.LG", "authors": ["harsh agrawal", "arjun chandrasekaran", "dhruv batra", "devi parikh", "mohit bansal"], "accepted": true, "id": "1606.07493"}, "pdf": {"name": "1606.07493.pdf", "metadata": {"source": "CRF", "title": "Sort Story: Sorting Jumbled Images and Captions into Stories", "authors": ["Harsh Agrawal", "Arjun Chandrasekaran", "Dhruv Batra", "Devi Parikh", "Mohit Bansal"], "emails": ["parikh}@vt.edu,", "mbansal@cs.unc.edu"], "sections": [{"heading": "1 Introduction", "text": "The task is to sort them in the correct order so that they form a coherent story in the face of a tangled series of images (and perhaps captions) that belong to a single story. Our motivation in this work is to enable AI systems to better understand and better predict the temporal nature of events in the world. To this end, we are training machine learning models to perform the task of \"sequencing.\" Temporal thinking has a number of applications, such as summarizing multiple sources of, say, news information, where the relative sequence of events can be useful to fuse information in a time-consistent manner. In question, answering tasks (Richardson et al., 2013; Denotes common contribution. \u2020 Part of this work was done during an internship at TTIC.Fader et al., 2014; Weston et al., 2015; Ren et al.), answers to questions related to events or events that may require a common contribution, we may require a common event to improve."}, {"heading": "2 Related Work", "text": "Contrary to the predictive models of NLP research. Scripts (Schank and Abelson, 2013) and more recently narrative chains (Chambers and Jurafsky, 2008) contain information about participants and causal relationships between events that enable the understanding of stories. A number of papers (Mani and Schiffman, 2005; Mani et al., 2006; Boguraev and Ando, 2005) learn temporal relationships and properties of news events from the dense, expert-annotated TimeBank corpus (Pustejovsky et al., 2003). However, in our work we use multimodal storydata that have no temporal annotations. A number of papers establish temporal orders by using manually defined linguistic cubes (Webber, 1988; Passonneau Dynamic, 1988; Lapata and Lascarides, 2006; Kehler, 2000)."}, {"heading": "3 Approach", "text": "In this section, we will first describe the two components of our approach: simple values that do not use context, and pairs of values that encode relative arrangements of elements. Next, we will describe how to combine these values through an electoral scheme."}, {"heading": "3.1 Unary Models", "text": "We use \u03c3i to indicate the position of the element i in the permutation \u03c3. A simple scoreSu (\u03c3) captures the appropriateness of each story element i in position \u03c3i: Su (\u03c3) = n \u2211 i = 1 P (\u03c3i | i) (1), where P (\u03c3i | i) describes the probability that the element i is in position \u03c3i, which is the output of an n-way softmax layer in a deep neural network. We experiment with 2 networks - (1) A language-independent simple model (SkipThought + MLP) that uses a gated recurrent unit proposed by Cho et al. (2014) to embed a caption in a vector space. We use the SkipThought model (Kiros et al., 2015), which is based on the BookCorpus (Zhu et al., 2015) to embed a caption in a vector space (not on a sketch)."}, {"heading": "3.2 Pairwise Models", "text": "Similar to learning marginal approaches (Hang, 2011), we develop pair scoring models that yield a pair of elements (i, j), learn to assign a score: S ([\u03c3i < \u03c3j]. < < < < p]. We develop and experiment with the following 3 pair-wise models: (1) A language-independent pair-wise model (Skip-Thought + MLP) that uses the Iverson bracket (which is 1 if the input argument is true and 0 different); (1) A linguistic pair-wise model (Skip-Thought + MLP) that uses as an embedding a pair of SkipThought embeddings and moves of an MLP (with hinge loss), the S ([\u03c3i < p]]."}, {"heading": "3.3 Voting-based Ensemble", "text": "To combine the complementary information gathered by the simple (Su) and paired (Sp) models, we use a voice-based ensemble. For each method in the whole ensemble, we find the top three permutations. Each of these permutations (\u03c3k) then selects a specific element to be placed at a specific position. Let V be a tuning matrix so that Vij stores the number of voices for the element associated with it at the jth position, i.e. Vij = \u2211 k [[\u03c3 k i = = = j]). We use the Hungarian algorithm to find the optimal permutation that maximizes the assigned voices, i.e. we determine the combination of paired skip-thought + CNN + MLP and neural embeddings that work best (based on a series of models)."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Data", "text": "We train and evaluate our model using personal multimodal stories from the ARE (Sequential Image Narrative Dataset) (Huang et al., 2016), where each story is a sequence of 5 images and corresponding historical captions. Captions in this dataset, such as \"Friends having a good time\" (as opposed to \"People sitting next to each other\") capture a sequential conversation language characteristic of stories. We use 40,155 stories for training, 4990 for validation, and 5055 stories for testing."}, {"heading": "4.2 Metrics", "text": "We evaluate the performance of our model in correctly arranging a tangled set of story elements using the following 3 metrics: Spearman's rank correlation (Spearman, 1904) measures whether the ranking of story elements in the predicted and ground truth order is monotonous (higher is better); in pairs, accuracy measures the fraction of the pairs of elements whose predicted relative order coincides with the ground truth order (higher is better); and average distance (dist) measures the average change in the position of all elements in the predicted story from their respective positions in the ground truth story (lower is better)."}, {"heading": "4.3 Results", "text": "Pairwise Models vs Unary Models As shown in Table 1, the pairwise models based on Skip-Thought features outperform the unary models in our task. However, the Pairwise Order Model performs worse than the unary Skip-Thought model, suggesting that the Skip-Thought features, which encode the context of a sentence, also provide a crucial signal for the timing of story sequences. Contribution from Image Features Augmenting the text features with image features leads to a visible improvement in the performance of both the model trained with unary features and the model trained with pairwise features. While image characteristics per se result in poor performance in this task, they seem to capture temporal information that complements the text."}, {"heading": "4.4 Qualitative Analysis", "text": "Visualizations of position predictions from our model show that it has learned the three-act structure (scooter, 1998) in stories - the build-up, the middle and the climax. We also present success and failure examples for predicting our sorting model. See the supplement for more details and figures. We visualize the temporal common sense of our model in Fig. 2. The word clouds shows discriminatory words - the words that the model believes point to sentence positions in a story. The size of a word is proportional to its frequency of occurring in that position to other positions. Some words such as \"party,\" \"\" wedding, \"etc., probably because our model believes that the beginning of the story describes the build-up - the occasion or event. People often tend to describe meetings with friends or family members, which is likely to include the discriminatory words such as\" people, \"\" friend, \"\" \"everyone\" in the second and third sentences. \"In addition, the model believes that the group will eventually tend to include the words like the large ones."}, {"heading": "5 Conclusion", "text": "We propose the task of \"sequencing\" in a series of image-label pairs, with the motivation to learn the common sense of the time. We implement multiple neural network models based on individual and pair-by-pair element-based predictions (and their ensemble), using both image and text properties to achieve a strong performance in the task. On average, our best system predicts the arrangement of sentences up to a distance of 0.8 (out of 5) positions. We also analyze our predictions and show qualitative examples demonstrating the common sense of the time."}, {"heading": "Acknowledgements", "text": "We thank Ramakrishna Vedantam and the anonymous critics for their helpful suggestions. This work was supported by: NSF CAREER Awards to DB and DP, ARO YIP Awards to DB and DP, ICTAS Junior Faculty Awards to DB and DP, Google Faculty Research Award to DP and DB, ARL Grant W911NF-15-2-0080 to DP and DB, ONR Grant N00014-14-1-0679 to DB and N00014-16-1-2713 to DP, ONR YIP Award to DP, Paul G. Allen Family Foundation Allen Distinguished Investigator Award to DP, Alfred P. Sloan Fellowship to DP, AWS in Education Research Grant to DB, NVIDIA GPU Donations to DB and MB, an IBM Faculty Award and Bloomberg Data Science Research Grant to MB.Anhang"}, {"heading": "A Confusion Matrix for Predicting Position of an Element", "text": "We visualize the 5-way classification confusion matrix for our best functioning method, i.e. the voting ensemble of Pairwise Skip-Thought + Image (CNN) and Pairwise Order (Neural Position Embedding (NPE)) in Fig. 3. The block diagonal matrix structure shows that the model predicts the first and the last element of a story relatively well, but is often confused by elements in the middle of the story. This visualization suggests that the model has learned the three-act structure in stories, i.e. the structure, the middle and the culmination."}, {"heading": "B Predicted Stories", "text": "We present qualitative examples of action orders predicted by the most powerful model in Fig. 4. Fig. 4a shows example stories in which the position of all elements is correctly predicted. Fig. 4b shows stories in which none of the positions are correctly predicted by our model. These two examples show that our model clearly fails when there is no inherent temporal order in history, either through language or through images."}, {"heading": "C Temporal Common Sense", "text": "In the word cloud in Fig. 5, we visualize the words that the model finds discriminatory in correct predictions, which are words from correctly predicted stories that the model believes indicate sentence positions in a story. The size of a word is proportional to the ratio of its frequency of occurring in that position to other positions. Our model captures events such as \"carnival,\" \"reunion\" and sports topics such as \"baseball,\" \"football,\" \"skate\" in the first position. This could be the case because the first sentence of a story usually introduces the event on which the story is based. In Fig. 5e (last sentence word cloud), we also observe that the model correctly learns keywords such as \"total\" and \"last.\" In addition, it learns words and events that often complete stories such as \"returned,\" \"tired,\" \"winner\" and \"celebration.\""}], "references": [{"title": "Timeml-compliant text analysis for temporal reasoning", "author": ["Boguraev", "Ando2005] Branimir Boguraev", "Rie Kubota Ando"], "venue": "In IJCAI", "citeRegEx": "Boguraev et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Boguraev et al\\.", "year": 2005}, {"title": "Learning prototypical event structure from photo albums", "author": ["Jianfu Chen", "David Warren", "Hannaneh Hajishirzi", "Yejin Choi"], "venue": "In ACL", "citeRegEx": "Bosselut et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bosselut et al\\.", "year": 2016}, {"title": "Unsupervised learning of narrative event chains", "author": ["Chambers", "Jurafsky2008] Nathanael Chambers", "Daniel Jurafsky"], "venue": "In ACL. Citeseer", "citeRegEx": "Chambers et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chambers et al\\.", "year": 2008}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["Chen", "Manning2014] Danqi Chen", "Christopher D Manning"], "venue": "In EMNLP", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Content modeling using latent permutations", "author": ["Chen et al.2009] Harr Chen", "SRK Branavan", "Regina Barzilay", "David R Karger"], "venue": "Journal of Artificial Intelligence Research", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Cho et al.2014] Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Video-story composition via plot analysis", "author": ["Choi et al.2016] Jinsoo Choi", "Tae-Hyun Oh", "In So Kweon"], "venue": null, "citeRegEx": "Choi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Choi et al\\.", "year": 2016}, {"title": "Open question answering over curated and extracted knowledge bases", "author": ["Fader et al.2014] Anthony Fader", "Luke Zettlemoyer", "Oren Etzioni"], "venue": "In ACM SIGKDD", "citeRegEx": "Fader et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fader et al\\.", "year": 2014}, {"title": "A short introduction to learning to rank", "author": ["LI Hang"], "venue": "IEICE TRANSACTIONS on Information and Systems", "citeRegEx": "Hang.,? \\Q2011\\E", "shortCiteRegEx": "Hang.", "year": 2011}, {"title": "Algorithms for analysing the temporal structure of discourse", "author": ["Marc Moens", "Claire Grover"], "venue": "In EACL", "citeRegEx": "Hitzeman et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hitzeman et al\\.", "year": 1995}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Coherence and the resolution of ellipsis", "author": ["Andrew Kehler"], "venue": "Linguistics and Philosophy", "citeRegEx": "Kehler.,? \\Q2000\\E", "shortCiteRegEx": "Kehler.", "year": 2000}, {"title": "Reconstructing storyline graphs for image recommendation from web community photos", "author": ["Kim", "Xing2014] Gunhee Kim", "Eric Xing"], "venue": "In CVPR", "citeRegEx": "Kim et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2014}, {"title": "Joint summarization of large-scale collections of web images and videos for storyline reconstruction", "author": ["Kim et al.2014] Gunhee Kim", "Leonid Sigal", "Eric Xing"], "venue": "In CVPR", "citeRegEx": "Kim et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2014}, {"title": "Joint photo stream and blog post summarization and exploration", "author": ["Kim et al.2015] Gunhee Kim", "Seungwhan Moon", "Leonid Sigal"], "venue": "In CVPR", "citeRegEx": "Kim et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2015}, {"title": "Temporally anchoring and ordering events in news. Time and Event Recognition in Natural Language", "author": ["Mani", "Schiffman2005] Inderjeet Mani", "Barry Schiffman"], "venue": null, "citeRegEx": "Mani et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Mani et al\\.", "year": 2005}, {"title": "Machine learning of temporal relations", "author": ["Mani et al.2006] Inderjeet Mani", "Marc Verhagen", "Ben Wellner", "Chong Min Lee", "James Pustejovsky"], "venue": "In COLING-ACL", "citeRegEx": "Mani et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Mani et al\\.", "year": 2006}, {"title": "Inducing neural models of script knowledge", "author": ["Modi", "Titov2014] Ashutosh Modi", "Ivan Titov"], "venue": "In CoNLL", "citeRegEx": "Modi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Modi et al\\.", "year": 2014}, {"title": "Event embeddings for semantic script modeling", "author": ["Ashutosh Modi"], "venue": "In CoNLL", "citeRegEx": "Modi.,? \\Q2016\\E", "shortCiteRegEx": "Modi.", "year": 2016}, {"title": "A corpus and cloze evaluation for deeper understanding of commonsense stories", "author": ["Mostafazadeh", "Nathanael Chambers", "Xiaodong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen."], "venue": "In", "citeRegEx": "Mostafazadeh et al\\.,? 2016", "shortCiteRegEx": "Mostafazadeh et al\\.", "year": 2016}, {"title": "Algorithms for the assignment and transportation problems", "author": ["James Munkres"], "venue": "Journal of the Society for Industrial and Applied Mathematics", "citeRegEx": "Munkres.,? \\Q1957\\E", "shortCiteRegEx": "Munkres.", "year": 1957}, {"title": "A computational model of the semantics of tense and aspect", "author": ["Rebecca J Passonneau"], "venue": "Computational Linguistics", "citeRegEx": "Passonneau.,? \\Q1988\\E", "shortCiteRegEx": "Passonneau.", "year": 1988}, {"title": "Seeing the arrow of time", "author": ["Zheng Pan", "Donglai Wei", "YiChang Shih", "Changshui Zhang", "Andrew Zisserman", "Bernhard Scholkopf", "William Freeman"], "venue": "In CVPR", "citeRegEx": "Pickup et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pickup et al\\.", "year": 2014}, {"title": "The timebank corpus", "author": ["Andrea Setzer", "Dragomir Radev", "Beth Sundheim", "David Day", "Lisa Ferro"], "venue": "In Corpus linguistics", "citeRegEx": "Setzer et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Setzer et al\\.", "year": 2003}, {"title": "Learning temporal embeddings for complex video analysis", "author": ["Kevin Tang", "Greg Mori", "Li Fei-Fei"], "venue": null, "citeRegEx": "Ramanathan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ramanathan et al\\.", "year": 2015}, {"title": "Exploring models and data for image question answering", "author": ["Ren et al.2015] Mengye Ren", "Ryan Kiros", "Richard Zemel"], "venue": "In NIPS", "citeRegEx": "Ren et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ren et al\\.", "year": 2015}, {"title": "Mctest: A challenge dataset for the open-domain machine comprehension of text", "author": ["Christopher JC Burges", "Erin Renshaw"], "venue": "In EMNLP", "citeRegEx": "Richardson et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Richardson et al\\.", "year": 2013}, {"title": "Scripts, plans, goals, and understanding: An inquiry into human knowledge structures", "author": ["Schank", "Abelson2013] Roger C Schank", "Robert P Abelson"], "venue": null, "citeRegEx": "Schank et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Schank et al\\.", "year": 2013}, {"title": "Learning visual storylines with skipping recurrent neural networks", "author": ["Xinlei Chen", "Abhinav Gupta"], "venue": "In ECCV", "citeRegEx": "Sigurdsson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sigurdsson et al\\.", "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Zisserman2014] Karen Simonyan", "Andrew Zisserman"], "venue": "arXiv preprint arXiv:1409.1556", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "The proof and measurement of association between two things", "author": ["Charles Spearman"], "venue": "The American journal of psychology", "citeRegEx": "Spearman.,? \\Q1904\\E", "shortCiteRegEx": "Spearman.", "year": 1904}, {"title": "The screenwriter\u2019s bible: A complete guide to writing, formatting, and selling your script", "author": ["David Trottier"], "venue": null, "citeRegEx": "Trottier.,? \\Q1998\\E", "shortCiteRegEx": "Trottier.", "year": 1998}, {"title": "Order-embeddings of images and language. In ICLR", "author": ["Vendrov et al.2016] Ivan Vendrov", "Ryan Kiros", "Sanja Fidler", "Raquel Urtasun"], "venue": null, "citeRegEx": "Vendrov et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vendrov et al\\.", "year": 2016}, {"title": "A lowrank approximation approach to learning joint embeddings of news stories and images for timeline summarization", "author": ["Yashar Mehdad", "Dragomir R Radev", "Amanda Stent"], "venue": "In NAACL", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Tense as discourse anaphor", "author": ["Bonnie Lynn Webber"], "venue": "Computational Linguistics", "citeRegEx": "Webber.,? \\Q1988\\E", "shortCiteRegEx": "Webber.", "year": 1988}, {"title": "Towards AIcomplete question answering: A set of prerequisite toy tasks", "author": ["Weston et al.2015] Jason Weston", "Antoine Bordes", "Sumit Chopra", "Tomas Mikolov"], "venue": "arXiv preprint arXiv:1502.05698", "citeRegEx": "Weston et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Weston et al\\.", "year": 2015}, {"title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books", "author": ["Zhu et al.2015] Yukun Zhu", "Ryan Kiros", "Rich Zemel", "Ruslan Salakhutdinov", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler"], "venue": "In CVPR", "citeRegEx": "Zhu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 16, "context": "A number of works (Mani and Schiffman, 2005; Mani et al., 2006; Boguraev and Ando, 2005) learn temporal relations and properties of news events from the dense, expert-annotated TimeBank corpus (Pustejovsky et al.", "startOffset": 18, "endOffset": 88}, {"referenceID": 34, "context": "A number of works also reason about temporal ordering by using manually defined linguistic cues (Webber, 1988; Passonneau, 1988; Lapata and Lascarides, 2006; Hitzeman et al., 1995; Kehler, 2000).", "startOffset": 96, "endOffset": 194}, {"referenceID": 21, "context": "A number of works also reason about temporal ordering by using manually defined linguistic cues (Webber, 1988; Passonneau, 1988; Lapata and Lascarides, 2006; Hitzeman et al., 1995; Kehler, 2000).", "startOffset": 96, "endOffset": 194}, {"referenceID": 9, "context": "A number of works also reason about temporal ordering by using manually defined linguistic cues (Webber, 1988; Passonneau, 1988; Lapata and Lascarides, 2006; Hitzeman et al., 1995; Kehler, 2000).", "startOffset": 96, "endOffset": 194}, {"referenceID": 11, "context": "A number of works also reason about temporal ordering by using manually defined linguistic cues (Webber, 1988; Passonneau, 1988; Lapata and Lascarides, 2006; Hitzeman et al., 1995; Kehler, 2000).", "startOffset": 96, "endOffset": 194}, {"referenceID": 18, "context": "Recent works (Modi and Titov, 2014; Modi, 2016) learn distributed representations for predicates in a sentence for the tasks of event ordering and cloze evaluation.", "startOffset": 13, "endOffset": 47}, {"referenceID": 22, "context": "Some works in vision (Pickup et al., 2014; Basha et al., 2012) also temporally order images; typically by finding correspondences between multiple images of the same scene using geometry-based approaches.", "startOffset": 21, "endOffset": 62}, {"referenceID": 14, "context": "A few other recent works (Kim et al., 2015; Kim et al., 2014; Kim and Xing, 2014; Sigurdsson et al., 2016; Bosselut et al., 2016; Wang et al., 2016) summarize hundreds of individual streams of information (images, text, videos) from the web that deal with a single concept or event, to learn a common theme or storyline or for timeline summarization.", "startOffset": 25, "endOffset": 148}, {"referenceID": 12, "context": "A few other recent works (Kim et al., 2015; Kim et al., 2014; Kim and Xing, 2014; Sigurdsson et al., 2016; Bosselut et al., 2016; Wang et al., 2016) summarize hundreds of individual streams of information (images, text, videos) from the web that deal with a single concept or event, to learn a common theme or storyline or for timeline summarization.", "startOffset": 25, "endOffset": 148}, {"referenceID": 28, "context": "A few other recent works (Kim et al., 2015; Kim et al., 2014; Kim and Xing, 2014; Sigurdsson et al., 2016; Bosselut et al., 2016; Wang et al., 2016) summarize hundreds of individual streams of information (images, text, videos) from the web that deal with a single concept or event, to learn a common theme or storyline or for timeline summarization.", "startOffset": 25, "endOffset": 148}, {"referenceID": 1, "context": "A few other recent works (Kim et al., 2015; Kim et al., 2014; Kim and Xing, 2014; Sigurdsson et al., 2016; Bosselut et al., 2016; Wang et al., 2016) summarize hundreds of individual streams of information (images, text, videos) from the web that deal with a single concept or event, to learn a common theme or storyline or for timeline summarization.", "startOffset": 25, "endOffset": 148}, {"referenceID": 33, "context": "A few other recent works (Kim et al., 2015; Kim et al., 2014; Kim and Xing, 2014; Sigurdsson et al., 2016; Bosselut et al., 2016; Wang et al., 2016) summarize hundreds of individual streams of information (images, text, videos) from the web that deal with a single concept or event, to learn a common theme or storyline or for timeline summarization.", "startOffset": 25, "endOffset": 148}, {"referenceID": 2, "context": "Chen et al. (2009) use a generalized Mallows model for modeling sequences for coherence within single documents.", "startOffset": 0, "endOffset": 19}, {"referenceID": 2, "context": "Chen et al. (2009) use a generalized Mallows model for modeling sequences for coherence within single documents. Their approach may also be applicable to our task. Recently, Mostafazadeh et al. (2016) presented the \u201cROCStories\u201d dataset of 5sentence stories with stereotypical causal and temporal relations between events.", "startOffset": 0, "endOffset": 201}, {"referenceID": 2, "context": "Chen et al. (2009) use a generalized Mallows model for modeling sequences for coherence within single documents. Their approach may also be applicable to our task. Recently, Mostafazadeh et al. (2016) presented the \u201cROCStories\u201d dataset of 5sentence stories with stereotypical causal and temporal relations between events. In our work though, we make use of a multi-modal story-dataset that contains both images and associated story-like captions. Some works in vision (Pickup et al., 2014; Basha et al., 2012) also temporally order images; typically by finding correspondences between multiple images of the same scene using geometry-based approaches. Similarly, Choi et al. (2016) compose a story out of multiple short video clips.", "startOffset": 0, "endOffset": 682}, {"referenceID": 1, "context": ", 2016; Bosselut et al., 2016; Wang et al., 2016) summarize hundreds of individual streams of information (images, text, videos) from the web that deal with a single concept or event, to learn a common theme or storyline or for timeline summarization. Our task, however, is to predict the correct sorting of a given story, which is different from summarization or retrieval. Ramanathan et al. (2015) attempt to learn temporal embeddings of video frames in complex events.", "startOffset": 8, "endOffset": 400}, {"referenceID": 36, "context": ", 2015) GRU, which is trained on the BookCorpus (Zhu et al., 2015) to predict the context (preceding and following sentences) of a given sentence.", "startOffset": 48, "endOffset": 66}, {"referenceID": 5, "context": "We experiment with 2 networks \u2013 (1) A language-alone unary model (SkipThought+MLP) that uses a Gated Recurrent Unit (GRU) proposed by Cho et al. (2014) to embed a caption into a vector space.", "startOffset": 134, "endOffset": 152}, {"referenceID": 20, "context": "In both cases, the best ordering of the story elements (optimal permutation) \u03c3\u2217 = arg max\u03c3\u2208\u03a3n Su(\u03c3) can be found efficiently in O(n3) time with the Hungarian algorithm (Munkres, 1957).", "startOffset": 168, "endOffset": 183}, {"referenceID": 8, "context": "Similar to learning to rank approaches (Hang, 2011), we develop pairwise scoring models that given a pair of elements (i, j), learn to assign a score: S([[\u03c3i < \u03c3j ]] | i, j) indicating whether element i should be placed before element j in the permutation \u03c3.", "startOffset": 39, "endOffset": 51}, {"referenceID": 8, "context": "Similar to learning to rank approaches (Hang, 2011), we develop pairwise scoring models that given a pair of elements (i, j), learn to assign a score: S([[\u03c3i < \u03c3j ]] | i, j) indicating whether element i should be placed before element j in the permutation \u03c3. Here, [[\u00b7]] indicates the Iverson bracket (which is 1 if the input argument is true and 0 otherwise). We develop and experiment with the following 3 pairwise models: (1) A language-alone pairwise model (SkipThought+MLP) that takes as input a pair of SkipThought embeddings and trains an MLP (with hinge-loss) that outputs S([[\u03c3i < \u03c3j ]] | i, j), the score for placing i before j. (2) A language+vision pairwise model (SkipThought+CNN+MLP) that concatenates the SkipThought and CNN embeddings for i and j and trains a similar MLP as above. (3) A language-alone neural position embedding (NPE) model. Instead of using frozen Skip-Thought embeddings, we learn a task-aware ordered distributed embedding for sentences. Specifically, each sentence in the story is embedded X = (x1, . . . ,xn), xi \u2208 R+, via an LSTM (Hochreiter and Schmidhuber, 1997) with ReLU non-linearities. Similar to the max-margin loss that is applied to negative examples by Vendrov et al. (2016), we use an asymmetric penalty that encourages sentences appearing early in the story to be placed closer to the origin than sentences appearing later in the story.", "startOffset": 40, "endOffset": 1224}, {"referenceID": 30, "context": ") (Spearman, 1904) measures if the ranking of story elements in the predicted and ground truth orders are monotonically related (higher is better).", "startOffset": 2, "endOffset": 18}, {"referenceID": 18, "context": "to duplicate the pipelined approach of Modi and Titov (2014). For this, we first parse our story sentences to extract SVO (subject, verb, object) tuples (using the Stanford Parser (Chen and Manning, 2014)).", "startOffset": 39, "endOffset": 61}, {"referenceID": 31, "context": "Visualizations of position predictions from our model demonstrate that it has learnt the three act structure (Trottier, 1998) in stories \u2013 the setup, the middle and the climax.", "startOffset": 109, "endOffset": 125}], "year": 2016, "abstractText": "Temporal common sense has applications in AI tasks such as QA, multi-document summarization, and human-AI communication. We propose the task of sequencing \u2013 given a jumbled set of aligned image-caption pairs that belong to a story, the task is to sort them such that the output sequence forms a coherent story. We present multiple approaches, via unary (position) and pairwise (order) predictions, and their ensemble-based combinations, achieving strong results on this task. We use both text-based and image-based features, which depict complementary improvements. Using qualitative examples, we demonstrate that our models have learnt interesting aspects of temporal common sense.", "creator": "LaTeX with hyperref package"}}}