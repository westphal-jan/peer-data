{"id": "1606.07548", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Jun-2016", "title": "A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization", "abstract": "We consider the problem of using sentence compression techniques to facilitate query-focused multi-document summarization. We present a sentence-compression-based framework for the task, and design a series of learning-based compression models built on parse trees. An innovative beam search decoder is proposed to efficiently find highly probable compressions. Under this framework, we show how to integrate various indicative metrics such as linguistic motivation and query relevance into the compression process by deriving a novel formulation of a compression scoring function. Our best model achieves statistically significant improvement over the state-of-the-art systems on several metrics (e.g. 8.0% and 5.4% improvements in ROUGE-2 respectively) for the DUC 2006 and 2007 summarization task.", "histories": [["v1", "Fri, 24 Jun 2016 02:57:04 GMT  (106kb,D)", "http://arxiv.org/abs/1606.07548v1", "ACL 2013"]], "COMMENTS": "ACL 2013", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["lu wang", "hema raghavan", "vittorio castelli", "radu florian", "claire cardie"], "accepted": true, "id": "1606.07548"}, "pdf": {"name": "1606.07548.pdf", "metadata": {"source": "CRF", "title": "A Sentence Compression Based Framework to Query-Focused Multi-Document Summarization", "authors": ["Lu Wang", "Hema Raghavan", "Vittorio Castelli", "Radu Florian", "Claire Cardie"], "emails": ["cardie}@cs.cornell.edu", "raduf}@us.ibm.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that most of the people who have come to the USA in recent years have the same problems as we do, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same, the same"}, {"heading": "2 Related Work", "text": "Existing research on query-based multidocument summarization (MDS) relies largely on extractive approaches, in which systems typically take a set of documents as input and select the most relevant sentences for inclusion in the final summary, using a wide range of methods.For unattended methods, the meaning of sentences can be estimated by calculating subject signatures (Lin and Hovy, 2000; Conroy et al., 2006), combining query similarity and centrality of documents within a graph-based model (Otterbacher et al., 2005), or by using a Bayesian model with complex conclusions (Daume \u0301 and Marcu, 2006).Keisy et al al al al al al al al al al. (2012) first learn the weights of terms by latent semantic analysis and then greedily select sentences that cover the maximum combined weighting. Supervised approaches have focused mainly on the application of discriminatory learning judgments (2007)."}, {"heading": "3 The Framework", "text": "The mentioned hsci-eSrcnlhsrc\u00fceSrlhsdc\u00fce nvo the eSrree\u00fcb in the eSrteeeirln rf\u00fc ide eSrteeeirln rf\u00fc ide eSrteeeirln rf\u00fc ide eSrteeu, nlrteew sdsa the eSrteeeeirln rf\u00fc the eSrteeeeeeeSrteeeSrteeSrrrrrreeeeSrh-eSrteeSrteeSrrrrrreSrteeSreSrteeSrreSrrrrh-eSrteeSrrteeSrrrrrrc-SrrllllrrrrlrrrrrrrteececeSreceSrrreSrreSrteeSrc-SrrrrrrteeSrrrrrh-SrteeSrteeceSrrrrh-SrteeSrteeSrteec-Srlrrrrrrrrrrrrrh-SrteeSrteeSrteeSrteec-SrteeSrnrrrrrrrrrllllrrrrrh-Srteecec-SrrrrrrrteeSrrrteec-SrrrrrrrreSrrrrrrreSrrreSrrrrteeSrh-SrteeSrteeceSrrrrrrh-SrteeSrrrrrlllrrrrrrrec-SrrrrrrreSrrrrrrec-SrteeSrrrrrreSrrrrrrrrrec-Srrr"}, {"heading": "4 Sentence Compression", "text": "Sentence compression is typically formulated as the problem of removing secondary information from a sentence while maintaining its grammaticality and semantic structure (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Clarke and Lapata, 2008). Other paraphrasing operations such as paraphrasing and rearranging will be left to future work. In the following, we describe the approaches to sentence compression developed in this research: RULE-BASED COMPRESSION, SEQUENCE-BASED COMPRESSION, and TREEBASED COMPRESSION."}, {"heading": "4.1 Rule-based Compression", "text": "Turner and Charniak (2005) have shown that the application of handmade sentence cropping rules can improve both content and linguistic quality. Our rules-based approach extends existing work (Conroy et al., 2006; Toutanova et al., 2007) to include the linguistic compression rules of Table 2. To avoid erroneous output, we prohibit compressions of more than 10 words per rule."}, {"heading": "4.2 Sequence-based Compression", "text": "As in McDonald (2006) and Clarke and Lapata (2008), our sequence-based compression model makes a binary \"keep or delete\" decision for each word in the sentence. In contrast, we consider compression to be a sequential problem and use linear chain random fields (CRFs) (Lafferty et al., 2001) to select the most likely compression. We present each sentence as a sequence of tokens, X = x0x1.. xn, and generate a sequence of labels, Y = y0y1.. yn, encoding tokens kept using a BIO label format: \"{B-RETAIN denotes the beginning of a retained sequence, IRETAIN denotes tokens\" within \"the retained sequence, O denotes tokens that makens that are to be removed.\" The CRF model is used in Table 3 indicates that RETAIN denotes the tokens associated with both of the tokens, whereby we are likely to create a tokens dependent on both of the AIN in both of the tokens."}, {"heading": "4.3 Tree-based Compression", "text": "Our tree-based methods are in line with syntax-driven approach (Galley and McKeown, 2007), where operations are performed on parse tree constituents. Unlike the previous work (Knight and Marcu, 2000; Galley and McKeown, 2007), we are not able to produce a new parse tree, but we focus on learning to identify the correct components that need to be removed. In particular, when a node is removed from the tree, all words that subsumed it will be deleted from the judgment reasoning. Formally, since a parse tree T of the sentence is to be compressed, it can be presented as a list of ordered constituted nodes, T = t0t1. Our goal is to find a set of labels, L = l0l1. lm, where li {RETAIN, REMOVE}. RETAIN (REM) and REMOVE (REM)."}, {"heading": "4.3.1 Improving Beam Search", "text": "CONTEXT-conscious search is based on the intuition that predictions about the previous context can be used to facilitate prediction of the current node. For example, parent nodes with children who have all been removed (retained) should be labeled REM (RET). Given this, we encode these contextual predictions as additional features of S, i.e., ALL-CHILDRENRENRENREMOVED / RETAINED, ANY-LEFTSIBLINGREMOVED / RETAINED / PARTLY REMOVED, LABEL-OF-LEFT-SIBLING / HEAD-NODE.HEAD-driven search modifies the BASIC postordertree traversal by visiting the head node first at each level, leaving other arrangements unchanged. In short, if the head node is omitted, its modifiers do not need to be retained."}, {"heading": "4.3.2 Task-Specific Sentence Compression", "text": "The current Scorer ScoreBasic is still rather na\u00efve as it focuses only on the characteristics of the set q to be compressed. However, out-of-court knowledge can also be important for query-focused MDS. For example, information about the relevance of the query could cause the decoder to create compressions that are better suited to the summary. To achieve this goal, we construct a compression function - the multiple-goal scorers list (MULTI) - that allows the inclusion of multiple task-specific scorers. Given a hypothesis at each stage of decoding that results in a sequence of words W = w0w1... wj, we suggest the following scoring components. \u2212 Query information should guide the compressor to identify the relevant contents. Query Q is expanded as described in Section 3."}, {"heading": "5 Experimental Setup", "text": "We evaluate our methods on the DUC 2005, 2006 and 2007 datasets (Dang, 2005; Dang, 2006; Dang, 2007), each of which is a collection of newswire articles. 50 complex queries (topics) are provided for DUC 2005 and 2006, 35 are collected for DUC 2007 main task. Relevant documents for each query are provided along with 4 to 9 human MDS abstracts. The task is to generate a summary within 250 words to address the query. We divide DUC 2005 into two parts: 40 topics to train the sentence ranking models, and 10 for ranking algorithm selection and parameter setting for the multitorector. DUC 2006 and DUC 2007 are reserved as reserved test sequences. Sentence Compression Compression. The dataset of Clarke and Lapata (2008) is used to train the CRF and MaxEnt classifiers (Section 4)."}, {"heading": "6 Results", "text": "This year is the highest in the history of the country."}, {"heading": "7 Conclusion", "text": "We have presented a query-focused summary framework for multiple documents based on sentence compression and propose three types of compression approaches: our tree-based compression method can easily integrate metrics such as query relevance, meaning of content, redundancy and speech quality into the compression process. By testing a standard dataset using the automatic metric ROUGE, our models show significant improvements over pure extraction-based methods and state-of-the-art systems; our best system also delivers better human pyramid-based evaluation results and comparable linguistic quality values."}, {"heading": "Acknowledgments", "text": "We thank Ding-Jung Han, YoungSuk Lee, Xiaoqiang Luo, Sameer Maskey, Myle Ott, Salim Roukos, Yiye Ruan, Ming Tan, Todd Ward, Bowen Zhou and the ACL critics for valuable suggestions and advice on various aspects of this work."}], "references": [{"title": "Syntax directed translations and the pushdown assembler", "author": ["Alfred V. Aho", "Jeffrey D. Ullman."], "venue": "J. Comput. Syst. Sci., 3(1):37\u201356.", "citeRegEx": "Aho and Ullman.,? 1969", "shortCiteRegEx": "Aho and Ullman.", "year": 1969}, {"title": "Inferring strategies for sentence ordering in multidocument news summarization", "author": ["Regina Barzilay", "Noemie Elhadad", "Kathleen R. McKeown."], "venue": "J. Artif. Int. Res., 17(1):35\u201355, August.", "citeRegEx": "Barzilay et al\\.,? 2002", "shortCiteRegEx": "Barzilay et al\\.", "year": 2002}, {"title": "Jointly learning to extract and compress", "author": ["Taylor Berg-Kirkpatrick", "Dan Gillick", "Dan Klein."], "venue": "ACL \u201911, pages 481\u2013490, Stroudsburg, PA, USA. Association for Computational Linguistics.", "citeRegEx": "Berg.Kirkpatrick et al\\.,? 2011", "shortCiteRegEx": "Berg.Kirkpatrick et al\\.", "year": 2011}, {"title": "A maximum entropy approach to natural language processing", "author": ["Adam L. Berger", "Vincent J. Della Pietra", "Stephen A. Della Pietra."], "venue": "Comput. Linguist., 22(1):39\u201371, March.", "citeRegEx": "Berger et al\\.,? 1996", "shortCiteRegEx": "Berger et al\\.", "year": 1996}, {"title": "Natural Language Processing with Python", "author": ["Steven Bird", "Ewan Klein", "Edward Loper."], "venue": "O\u2019Reilly Media.", "citeRegEx": "Bird et al\\.,? 2009", "shortCiteRegEx": "Bird et al\\.", "year": 2009}, {"title": "Robust accurate statistical annotation of general text", "author": ["T. Briscoe", "J. Carroll"], "venue": null, "citeRegEx": "Briscoe and Carroll.,? \\Q2002\\E", "shortCiteRegEx": "Briscoe and Carroll.", "year": 2002}, {"title": "Learning to rank with nonsmooth cost functions", "author": ["Christopher J.C. Burges", "Robert Ragno", "Quoc Viet Le."], "venue": "B. Sch\u00f6lkopf, J. Platt, and T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 193\u2013 200. MIT Press, Cambridge, MA.", "citeRegEx": "Burges et al\\.,? 2007", "shortCiteRegEx": "Burges et al\\.", "year": 2007}, {"title": "From RankNet to LambdaRank to LambdaMART: An overview", "author": ["Christopher J.C. Burges."], "venue": "Technical report, Microsoft Research.", "citeRegEx": "Burges.,? 2010", "shortCiteRegEx": "Burges.", "year": 2010}, {"title": "Discovery of topically coherent sentences for extractive summarization", "author": ["Asli Celikyilmaz", "Dilek Hakkani-T\u00fcr."], "venue": "ACL \u201911, pages 491\u2013499, Stroudsburg, PA, USA. Association for Computational Linguistics.", "citeRegEx": "Celikyilmaz and Hakkani.T\u00fcr.,? 2011", "shortCiteRegEx": "Celikyilmaz and Hakkani.T\u00fcr.", "year": 2011}, {"title": "Global inference for sentence compression an integer linear programming approach", "author": ["James Clarke", "Mirella Lapata."], "venue": "J. Artif. Int. Res., 31(1):399\u2013429, March.", "citeRegEx": "Clarke and Lapata.,? 2008", "shortCiteRegEx": "Clarke and Lapata.", "year": 2008}, {"title": "Back to Basics", "author": ["John M. Conroy", "Judith D. Schlesinger", "Dianne P. O\u2019Leary", "Jade Goldstein"], "venue": "CLASSY", "citeRegEx": "Conroy et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Conroy et al\\.", "year": 2006}, {"title": "Overview of DUC 2005", "author": ["Hoa T. Dang."], "venue": "Document Understanding Conference.", "citeRegEx": "Dang.,? 2005", "shortCiteRegEx": "Dang.", "year": 2005}, {"title": "Overview of DUC 2006", "author": ["Hoa Tran Dang."], "venue": "Proc. Document Understanding Workshop, page 10 pages. NIST.", "citeRegEx": "Dang.,? 2006", "shortCiteRegEx": "Dang.", "year": 2006}, {"title": "Overview of DUC 2007", "author": ["Hoa T. Dang."], "venue": "Document Understanding Conference.", "citeRegEx": "Dang.,? 2007", "shortCiteRegEx": "Dang.", "year": 2007}, {"title": "RankLib", "author": ["Van Dang."], "venue": "Online.", "citeRegEx": "Dang.,? 2011", "shortCiteRegEx": "Dang.", "year": 2011}, {"title": "Bayesian query-focused summarization", "author": ["III Hal Daum\u00e9", "Daniel Marcu."], "venue": "ACL \u201906, pages 305\u2013312, Stroudsburg, PA, USA. Association for Computational Linguistics.", "citeRegEx": "Daum\u00e9 and Marcu.,? 2006", "shortCiteRegEx": "Daum\u00e9 and Marcu.", "year": 2006}, {"title": "Occams - an optimal combinatorial covering algorithm for multi-document summarization", "author": ["Sashka T. Davis", "John M. Conroy", "Judith D. Schlesinger."], "venue": "ICDM Workshops, pages 454\u2013463.", "citeRegEx": "Davis et al\\.,? 2012", "shortCiteRegEx": "Davis et al\\.", "year": 2012}, {"title": "Hedge trimmer: a parse-and-trim approach to headline generation", "author": ["Bonnie J Dorr", "David Zajic", "Richard Schwartz."], "venue": "Proceedings of the HLT-NAACL 03 on Text summarization workshop - Volume 5, HLT-NAACLDUC \u201903, pages 1 \u2013 8, Stroudsburg, PA, USA. Association", "citeRegEx": "Dorr et al\\.,? 2003", "shortCiteRegEx": "Dorr et al\\.", "year": 2003}, {"title": "Lexrank: graphbased lexical centrality as salience in text summarization", "author": ["G\u00fcnes Erkan", "Dragomir R. Radev."], "venue": "J. Artif. Int. Res., 22(1):457\u2013479, December.", "citeRegEx": "Erkan and Radev.,? 2004", "shortCiteRegEx": "Erkan and Radev.", "year": 2004}, {"title": "A statistical model for multilingual entity detection and tracking", "author": ["Radu Florian", "Hany Hassan", "Abraham Ittycheriah", "Hongyan Jing", "Nanda Kambhatla", "Xiaoqiang Luo", "Nicolas Nicolov", "Salim Roukos."], "venue": "HLT-NAACL, pages 1\u20138.", "citeRegEx": "Florian et al\\.,? 2004", "shortCiteRegEx": "Florian et al\\.", "year": 2004}, {"title": "Support vector machines for query-focused summarization trained and evaluated on pyramid data", "author": ["Maria Fuentes", "Enrique Alfonseca", "Horacio Rodr\u0131\u0301guez"], "venue": "In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions,", "citeRegEx": "Fuentes et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Fuentes et al\\.", "year": 2007}, {"title": "Lexicalized Markov grammars for sentence compression", "author": ["Michel Galley", "Kathleen McKeown."], "venue": "NAACL \u201907, pages 180\u2013187, Rochester, New York, April. Association for Computational Linguistics.", "citeRegEx": "Galley and McKeown.,? 2007", "shortCiteRegEx": "Galley and McKeown.", "year": 2007}, {"title": "A scalable global model for summarization", "author": ["Dan Gillick", "Benoit Favre."], "venue": "Proceedings of the Workshop on Integer Linear Programming for Natural Langauge Processing, ILP \u201909, pages 10\u201318, Stroudsburg, PA, USA. Association for Computational Linguistics.", "citeRegEx": "Gillick and Favre.,? 2009", "shortCiteRegEx": "Gillick and Favre.", "year": 2009}, {"title": "Exploring content models for multi-document summarization", "author": ["Aria Haghighi", "Lucy Vanderwende."], "venue": "NAACL \u201909, pages 362\u2013370, Stroudsburg, PA, USA. Association for Computational Linguistics.", "citeRegEx": "Haghighi and Vanderwende.,? 2009", "shortCiteRegEx": "Haghighi and Vanderwende.", "year": 2009}, {"title": "The weka data mining software: an update", "author": ["Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H. Witten."], "venue": "SIGKDD Explor. Newsl., 11(1):10\u201318, November.", "citeRegEx": "Hall et al\\.,? 2009", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Query Independent Sentence Scoring approach to DUC", "author": ["Jagadeesh Jagarlamudi", "Prasad Pingali", "Vasudeva Varma"], "venue": null, "citeRegEx": "Jagarlamudi et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Jagarlamudi et al\\.", "year": 2006}, {"title": "Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel", "author": ["J. Peter Kincaid", "Robert P. Fishburne", "Richard L. Rogers", "Brad S. Chissom."], "venue": "Technical report, February.", "citeRegEx": "Kincaid et al\\.,? 1975", "shortCiteRegEx": "Kincaid et al\\.", "year": 1975}, {"title": "Statistics-based summarization - step one: Sentence compression", "author": ["Kevin Knight", "Daniel Marcu."], "venue": "AAAI \u201900, pages 703\u2013710. AAAI Press.", "citeRegEx": "Knight and Marcu.,? 2000", "shortCiteRegEx": "Knight and Marcu.", "year": 2000}, {"title": "LCCs gistexter at duc 2006: Multi-strategy multi-document summarization", "author": ["Finley Lacatusu", "Andrew Hickl", "Kirk Roberts", "Ying Shi", "Jeremy Bensley", "Bryan Rink", "Patrick Wang", "Lara Taylor"], "venue": null, "citeRegEx": "Lacatusu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Lacatusu et al\\.", "year": 2006}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira."], "venue": "In", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Syntax-directed transduction", "author": ["II P.M. Lewis", "R.E. Stearns."], "venue": "J. ACM, 15(3):465\u2013488, July.", "citeRegEx": "Lewis and Stearns.,? 1968", "shortCiteRegEx": "Lewis and Stearns.", "year": 1968}, {"title": "A class of submodular functions for document summarization", "author": ["Hui Lin", "Jeff Bilmes."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT \u201911, pages 510\u2013520, Stroudsburg, PA, USA. Associ-", "citeRegEx": "Lin and Bilmes.,? 2011", "shortCiteRegEx": "Lin and Bilmes.", "year": 2011}, {"title": "The automated acquisition of topic signatures for text summarization", "author": ["Chin-Yew Lin", "Eduard Hovy."], "venue": "Proceedings of the 18th conference on Computational linguistics - Volume 1, COLING \u201900, pages 495\u2013501, Stroudsburg, PA, USA. Association for Computational", "citeRegEx": "Lin and Hovy.,? 2000", "shortCiteRegEx": "Lin and Hovy.", "year": 2000}, {"title": "Automatic evaluation of summaries using n-gram co-occurrence statistics", "author": ["Chin-Yew Lin", "Eduard Hovy."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1,", "citeRegEx": "Lin and Hovy.,? 2003", "shortCiteRegEx": "Lin and Hovy.", "year": 2003}, {"title": "Improving summarization performance by sentence compression: a pilot study", "author": ["Chin-Yew Lin."], "venue": "Proceedings of the sixth international workshop on Information retrieval with Asian languages - Volume 11, AsianIR \u201903, pages 1\u20138, Stroudsburg, PA, USA. Association for", "citeRegEx": "Lin.,? 2003", "shortCiteRegEx": "Lin.", "year": 2003}, {"title": "Multi-lingual coreference resolution with syntactic features", "author": ["Xiaoqiang Luo", "Imed Zitouni."], "venue": "HLT/EMNLP.", "citeRegEx": "Luo and Zitouni.,? 2005", "shortCiteRegEx": "Luo and Zitouni.", "year": 2005}, {"title": "A mentionsynchronous coreference resolution algorithm based on the bell tree", "author": ["Xiaoqiang Luo", "Abraham Ittycheriah", "Hongyan Jing", "Nanda Kambhatla", "Salim Roukos."], "venue": "ACL, pages 135\u2013142.", "citeRegEx": "Luo et al\\.,? 2004", "shortCiteRegEx": "Luo et al\\.", "year": 2004}, {"title": "Summarization with a joint model for sentence extraction and compression", "author": ["Andr\u00e9 F.T. Martins", "Noah A. Smith."], "venue": "Proceedings of the Workshop on Integer Linear Programming for Natural Langauge Processing, ILP \u201909, pages 1\u20139, Stroudsburg, PA, USA. Association for", "citeRegEx": "Martins and Smith.,? 2009", "shortCiteRegEx": "Martins and Smith.", "year": 2009}, {"title": "Mallet: A machine learning for language toolkit", "author": ["Andrew Kachites McCallum."], "venue": "http://mallet.cs.umass.edu.", "citeRegEx": "McCallum.,? 2002", "shortCiteRegEx": "McCallum.", "year": 2002}, {"title": "Discriminative Sentence Compression with Soft Syntactic Constraints", "author": ["Ryan McDonald."], "venue": "Proceedings of the 11th \u0303EACL, Trento, Italy, April.", "citeRegEx": "McDonald.,? 2006", "shortCiteRegEx": "McDonald.", "year": 2006}, {"title": "Evaluating content selection in summarization: The pyramid method", "author": ["Ani Nenkova", "Rebecca Passonneau."], "venue": "Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings, pages 145\u2013 152, Boston, Massachusetts, USA, May 2 - May 7. Asso-", "citeRegEx": "Nenkova and Passonneau.,? 2004", "shortCiteRegEx": "Nenkova and Passonneau.", "year": 2004}, {"title": "Using random walks for question-focused sentence retrieval", "author": ["Jahna Otterbacher", "G\u00fcne\u015f Erkan", "Dragomir R. Radev."], "venue": "Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT \u201905, pages 915\u2013922, Strouds-", "citeRegEx": "Otterbacher et al\\.,? 2005", "shortCiteRegEx": "Otterbacher et al\\.", "year": 2005}, {"title": "Applying regression models to query-focused multidocument summarization", "author": ["You Ouyang", "Wenjie Li", "Sujian Li", "Qin Lu."], "venue": "Inf. Process. Manage., 47(2):227\u2013237, March.", "citeRegEx": "Ouyang et al\\.,? 2011", "shortCiteRegEx": "Ouyang et al\\.", "year": 2011}, {"title": "Learning to rank for queryfocused multi-document summarization", "author": ["Chao Shen", "Tao Li."], "venue": "Diane J. Cook, Jian Pei, Wei Wang 0010, Osmar R. Zaane, and Xindong Wu, editors, ICDM, pages 626\u2013634. IEEE.", "citeRegEx": "Shen and Li.,? 2011", "shortCiteRegEx": "Shen and Li.", "year": 2011}, {"title": "SRILM \u2013 an extensible language modeling toolkit", "author": ["Andreas Stolcke."], "venue": "Proceedings of ICSLP, volume 2, pages 901\u2013904, Denver, USA.", "citeRegEx": "Stolcke.,? 2002", "shortCiteRegEx": "Stolcke.", "year": 2002}, {"title": "The PYTHY Summarization System: Microsoft Research at DUC 2007", "author": ["Kristina Toutanova", "Chris Brockett", "Michael Gamon", "Jagadeesh Jagarlamudi", "Hisami Suzuki", "Lucy Vanderwende."], "venue": "Proc. of DUC.", "citeRegEx": "Toutanova et al\\.,? 2007", "shortCiteRegEx": "Toutanova et al\\.", "year": 2007}, {"title": "Supervised and unsupervised learning for sentence compression", "author": ["Jenine Turner", "Eugene Charniak."], "venue": "ACL \u201905, pages 290\u2013297, Stroudsburg, PA, USA. Association for Computational Linguistics.", "citeRegEx": "Turner and Charniak.,? 2005", "shortCiteRegEx": "Turner and Charniak.", "year": 2005}, {"title": "Sentence compression as a component of a multidocument summarization system", "author": ["David Zajic", "Bonnie J Dorr", "Jimmy Lin", "R. Schwartz."], "venue": "Proceedings of the 2006 Document Understanding Workshop, New York.", "citeRegEx": "Zajic et al\\.,? 2006", "shortCiteRegEx": "Zajic et al\\.", "year": 2006}], "referenceMentions": [{"referenceID": 18, "context": "specific or not\u2014remain largely extractive: their summaries are comprised exclusively of sentences selected directly from the documents to be summarized (Erkan and Radev, 2004; Haghighi and Vanderwende, 2009; Celikyilmaz and Hakkani-T\u00fcr, 2011).", "startOffset": 152, "endOffset": 242}, {"referenceID": 23, "context": "specific or not\u2014remain largely extractive: their summaries are comprised exclusively of sentences selected directly from the documents to be summarized (Erkan and Radev, 2004; Haghighi and Vanderwende, 2009; Celikyilmaz and Hakkani-T\u00fcr, 2011).", "startOffset": 152, "endOffset": 242}, {"referenceID": 8, "context": "specific or not\u2014remain largely extractive: their summaries are comprised exclusively of sentences selected directly from the documents to be summarized (Erkan and Radev, 2004; Haghighi and Vanderwende, 2009; Celikyilmaz and Hakkani-T\u00fcr, 2011).", "startOffset": 152, "endOffset": 242}, {"referenceID": 26, "context": "in terms of Flesch-Kincaid Reading Ease Score (Kincaid et al., 1975)).", "startOffset": 46, "endOffset": 68}, {"referenceID": 27, "context": "Sentence compression techniques (Knight and Marcu, 2000; Clarke and Lapata, 2008) are the standard for producing a compact and grammatical version of a sentence while preserving relevance, and prior research (e.", "startOffset": 32, "endOffset": 81}, {"referenceID": 9, "context": "Sentence compression techniques (Knight and Marcu, 2000; Clarke and Lapata, 2008) are the standard for producing a compact and grammatical version of a sentence while preserving relevance, and prior research (e.", "startOffset": 32, "endOffset": 81}, {"referenceID": 9, "context": "Sentence compression techniques (Knight and Marcu, 2000; Clarke and Lapata, 2008) are the standard for producing a compact and grammatical version of a sentence while preserving relevance, and prior research (e.g. Lin (2003)) has", "startOffset": 57, "endOffset": 225}, {"referenceID": 47, "context": "Similarly, strides have been made to incorporate sentence compression into query-focused MDS systems (Zajic et al., 2006).", "startOffset": 101, "endOffset": 121}, {"referenceID": 33, "context": "02 ROUGE-2 score (Lin and Hovy, 2003), a 8.", "startOffset": 17, "endOffset": 37}, {"referenceID": 16, "context": "2 (Davis et al., 2012)) on the", "startOffset": 2, "endOffset": 22}, {"referenceID": 16, "context": "8 (Davis et al., 2012)).", "startOffset": 2, "endOffset": 22}, {"referenceID": 40, "context": "the manual Pyramid (Nenkova and Passonneau, 2004) evaluation measure (26.", "startOffset": 19, "endOffset": 49}, {"referenceID": 25, "context": "9 (Jagarlamudi et al., 2006)); human annotators furthermore rate our system-generated summaries as having less redundancy and comparable quality w.", "startOffset": 2, "endOffset": 28}, {"referenceID": 32, "context": "by calculating topic signature words (Lin and Hovy, 2000; Conroy et al., 2006), combining query similarity and document centrality within a graph-based model (Otterbacher et al.", "startOffset": 37, "endOffset": 78}, {"referenceID": 10, "context": "by calculating topic signature words (Lin and Hovy, 2000; Conroy et al., 2006), combining query similarity and document centrality within a graph-based model (Otterbacher et al.", "startOffset": 37, "endOffset": 78}, {"referenceID": 41, "context": ", 2006), combining query similarity and document centrality within a graph-based model (Otterbacher et al., 2005), or using a Bayesian model with sophisticated", "startOffset": 87, "endOffset": 113}, {"referenceID": 15, "context": "inference (Daum\u00e9 and Marcu, 2006).", "startOffset": 10, "endOffset": 33}, {"referenceID": 20, "context": "Supervised approaches have mainly focused on applying discriminative learning for ranking sentences (Fuentes et al., 2007).", "startOffset": 100, "endOffset": 122}, {"referenceID": 15, "context": "inference (Daum\u00e9 and Marcu, 2006). Davis et al. (2012) first learn the term weights by Latent Semantic Analysis, and then greedily select sentences that cover the maximum combined weights.", "startOffset": 11, "endOffset": 55}, {"referenceID": 15, "context": "inference (Daum\u00e9 and Marcu, 2006). Davis et al. (2012) first learn the term weights by Latent Semantic Analysis, and then greedily select sentences that cover the maximum combined weights. Supervised approaches have mainly focused on applying discriminative learning for ranking sentences (Fuentes et al., 2007). Lin and Bilmes (2011) use a class of carefully designed submodular functions to reward the diversity of the summaries and select sentences greedily.", "startOffset": 11, "endOffset": 335}, {"referenceID": 47, "context": "Zajic et al. (2006) tackle the query-focused MDS problem using a", "startOffset": 0, "endOffset": 20}, {"referenceID": 34, "context": "A similar idea has been studied for MDS (Lin, 2003; Gillick and Favre, 2009),", "startOffset": 40, "endOffset": 76}, {"referenceID": 22, "context": "A similar idea has been studied for MDS (Lin, 2003; Gillick and Favre, 2009),", "startOffset": 40, "endOffset": 76}, {"referenceID": 37, "context": "Finally, although learning-based compression methods are promising (Martins and Smith, 2009; Berg-Kirkpatrick et al., 2011), it is unclear how well they handle issues of redundancy.", "startOffset": 67, "endOffset": 123}, {"referenceID": 2, "context": "Finally, although learning-based compression methods are promising (Martins and Smith, 2009; Berg-Kirkpatrick et al., 2011), it is unclear how well they handle issues of redundancy.", "startOffset": 67, "endOffset": 123}, {"referenceID": 27, "context": "Our research is also inspired by probabilistic sentence-compression approaches, such as the noisy-channel model (Knight and Marcu, 2000; Turner and Charniak, 2005), and its extension via synchronous context-free grammars (SCFG) (Aho", "startOffset": 112, "endOffset": 163}, {"referenceID": 46, "context": "Our research is also inspired by probabilistic sentence-compression approaches, such as the noisy-channel model (Knight and Marcu, 2000; Turner and Charniak, 2005), and its extension via synchronous context-free grammars (SCFG) (Aho", "startOffset": 112, "endOffset": 163}, {"referenceID": 21, "context": "and Ullman, 1969; Lewis and Stearns, 1968) for robust probability estimation (Galley and McKeown, 2007).", "startOffset": 77, "endOffset": 103}, {"referenceID": 21, "context": "and Ullman, 1969; Lewis and Stearns, 1968) for robust probability estimation (Galley and McKeown, 2007). Rather than attempt to derive a new parse tree like Knight and Marcu (2000) and Galley and McKeown (2007), we learn to safely remove a set of constituents in our parse tree-based", "startOffset": 78, "endOffset": 181}, {"referenceID": 21, "context": "and Ullman, 1969; Lewis and Stearns, 1968) for robust probability estimation (Galley and McKeown, 2007). Rather than attempt to derive a new parse tree like Knight and Marcu (2000) and Galley and McKeown (2007), we learn to safely remove a set of constituents in our parse tree-based", "startOffset": 78, "endOffset": 211}, {"referenceID": 38, "context": "Sentence-level compression has also been examined via a discriminative model McDonald (2006), and Clarke and Lapata (2008) also incorporate discourse in-", "startOffset": 77, "endOffset": 93}, {"referenceID": 9, "context": "Sentence-level compression has also been examined via a discriminative model McDonald (2006), and Clarke and Lapata (2008) also incorporate discourse in-", "startOffset": 98, "endOffset": 123}, {"referenceID": 6, "context": ", 1997) and LambdaMART (Burges et al., 2007).", "startOffset": 23, "endOffset": 44}, {"referenceID": 42, "context": "The former has been used previously for MDS (Ouyang et al., 2011).", "startOffset": 44, "endOffset": 65}, {"referenceID": 7, "context": "LambdaMart on the other hand has shown considerable success in information retrieval tasks (Burges, 2010); we are the first to apply it to summarization.", "startOffset": 91, "endOffset": 105}, {"referenceID": 11, "context": "queries) from the DUC 2005 corpus (Dang, 2005) along with their manually generated abstracts.", "startOffset": 34, "endOffset": 46}, {"referenceID": 45, "context": "As in previous work (Shen and Li, Basic Features relative/absolute position is among the first 1/3/5 sentences? number of words (with/without stopwords) number of words more than 5/10 (with/without stopwords) Query-Relevant Features unigram/bigram/skip bigram (at most four words apart) overlap unigram/bigram TF/TF-IDF similarity mention overlap subject/object/indirect object overlap semantic role overlap relation overlap Query-Independent Features average/total unigram/bigram IDF/TF-IDF unigram/bigram TF/TF-IDF similarity with the centroid of the cluster average/sum of sumBasic/SumFocus (Toutanova et al., 2007) average/sum of mutual information average/sum of number of topic signature words (Lin and Hovy, 2000) basic/improved sentence scorers from Conroy et al.", "startOffset": 594, "endOffset": 618}, {"referenceID": 32, "context": ", 2007) average/sum of mutual information average/sum of number of topic signature words (Lin and Hovy, 2000) basic/improved sentence scorers from Conroy et al.", "startOffset": 89, "endOffset": 109}, {"referenceID": 6, "context": ", 1997) and LambdaMART (Burges et al., 2007). The former has been used previously for MDS (Ouyang et al., 2011). LambdaMart on the other hand has shown considerable success in information retrieval tasks (Burges, 2010); we are the first to apply it to summarization. For training, we use 40 topics (i.e. queries) from the DUC 2005 corpus (Dang, 2005) along with their manually generated abstracts. As in previous work (Shen and Li, Basic Features relative/absolute position is among the first 1/3/5 sentences? number of words (with/without stopwords) number of words more than 5/10 (with/without stopwords) Query-Relevant Features unigram/bigram/skip bigram (at most four words apart) overlap unigram/bigram TF/TF-IDF similarity mention overlap subject/object/indirect object overlap semantic role overlap relation overlap Query-Independent Features average/total unigram/bigram IDF/TF-IDF unigram/bigram TF/TF-IDF similarity with the centroid of the cluster average/sum of sumBasic/SumFocus (Toutanova et al., 2007) average/sum of mutual information average/sum of number of topic signature words (Lin and Hovy, 2000) basic/improved sentence scorers from Conroy et al. (2006) Content Features contains verb/web link/phone number? contains/portion of words between parentheses", "startOffset": 24, "endOffset": 1177}, {"referenceID": 10, "context": "adopted and extended from Conroy et al. (2006). Then we conduct simple query expansion based on the title of the topic and cross-document coreference resolution.", "startOffset": 26, "endOffset": 47}, {"referenceID": 1, "context": "Then a Chronological Ordering algorithm (Barzilay et al., 2002) sorts the sentences for each query based first on the time stamp, and then the position in the source document.", "startOffset": 40, "endOffset": 63}, {"referenceID": 27, "context": "from a sentence while maintaining its grammaticality and semantic structure (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Clarke and Lapata, 2008).", "startOffset": 76, "endOffset": 167}, {"referenceID": 39, "context": "from a sentence while maintaining its grammaticality and semantic structure (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Clarke and Lapata, 2008).", "startOffset": 76, "endOffset": 167}, {"referenceID": 21, "context": "from a sentence while maintaining its grammaticality and semantic structure (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Clarke and Lapata, 2008).", "startOffset": 76, "endOffset": 167}, {"referenceID": 9, "context": "from a sentence while maintaining its grammaticality and semantic structure (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Clarke and Lapata, 2008).", "startOffset": 76, "endOffset": 167}, {"referenceID": 10, "context": "Our rule-based approach extends existing work (Conroy et al., 2006; Toutanova et al., 2007) to create the linguistically-motivated compression", "startOffset": 46, "endOffset": 91}, {"referenceID": 45, "context": "Our rule-based approach extends existing work (Conroy et al., 2006; Toutanova et al., 2007) to create the linguistically-motivated compression", "startOffset": 46, "endOffset": 91}, {"referenceID": 38, "context": "As in McDonald (2006) and Clarke and Lapata (2008), our sequence-based compression model makes a binary \u201ckeep-or-delete\u201d decision for each", "startOffset": 6, "endOffset": 22}, {"referenceID": 9, "context": "As in McDonald (2006) and Clarke and Lapata (2008), our sequence-based compression model makes a binary \u201ckeep-or-delete\u201d decision for each", "startOffset": 26, "endOffset": 51}, {"referenceID": 29, "context": "view compression as a sequential tagging problem and make use of linear-chain Conditional Random Fields (CRFs) (Lafferty et al., 2001) to se-", "startOffset": 111, "endOffset": 134}, {"referenceID": 21, "context": "Our tree-based compression methods are in line with syntax-driven approaches (Galley and McKeown, 2007), where operations are carried out on parse tree constituents.", "startOffset": 77, "endOffset": 103}, {"referenceID": 27, "context": "Unlike previous work (Knight and Marcu, 2000; Galley and McKeown, 2007), we do not produce a new parse tree,", "startOffset": 21, "endOffset": 71}, {"referenceID": 21, "context": "Unlike previous work (Knight and Marcu, 2000; Galley and McKeown, 2007), we do not produce a new parse tree,", "startOffset": 21, "endOffset": 71}, {"referenceID": 3, "context": "a Maximum Entropy classifier (Berger et al., 1996) trained at the constituent level using the features in Table 4.", "startOffset": 29, "endOffset": 50}, {"referenceID": 45, "context": "A query-independent importance score is defined as the average SumBasic (Toutanova et al., 2007) value in W , i.", "startOffset": 72, "endOffset": 96}, {"referenceID": 11, "context": "We evaluate our methods on the DUC 2005, 2006 and 2007 datasets (Dang, 2005; Dang, 2006; Dang, 2007), each of which is a collection of newswire articles.", "startOffset": 64, "endOffset": 100}, {"referenceID": 12, "context": "We evaluate our methods on the DUC 2005, 2006 and 2007 datasets (Dang, 2005; Dang, 2006; Dang, 2007), each of which is a collection of newswire articles.", "startOffset": 64, "endOffset": 100}, {"referenceID": 13, "context": "We evaluate our methods on the DUC 2005, 2006 and 2007 datasets (Dang, 2005; Dang, 2006; Dang, 2007), each of which is a collection of newswire articles.", "startOffset": 64, "endOffset": 100}, {"referenceID": 9, "context": "from Clarke and Lapata (2008) is used to train the CRF and MaxEnt classifiers (Section 4).", "startOffset": 5, "endOffset": 30}, {"referenceID": 19, "context": "full NLP pipeline, including token and sentence segmentation, parsing, semantic role labeling, and an information extraction pipeline consisting of mention detection, NP coreference, crossdocument resolution, and relation detection (Florian et al., 2004; Luo et al., 2004; Luo and Zitouni, 2005).", "startOffset": 232, "endOffset": 295}, {"referenceID": 36, "context": "full NLP pipeline, including token and sentence segmentation, parsing, semantic role labeling, and an information extraction pipeline consisting of mention detection, NP coreference, crossdocument resolution, and relation detection (Florian et al., 2004; Luo et al., 2004; Luo and Zitouni, 2005).", "startOffset": 232, "endOffset": 295}, {"referenceID": 35, "context": "full NLP pipeline, including token and sentence segmentation, parsing, semantic role labeling, and an information extraction pipeline consisting of mention detection, NP coreference, crossdocument resolution, and relation detection (Florian et al., 2004; Luo et al., 2004; Luo and Zitouni, 2005).", "startOffset": 232, "endOffset": 295}, {"referenceID": 24, "context": "We use Weka (Hall et al., 2009) to train a support vector regressor and experiment with various rankers in RankLib (Dang, 2011)3.", "startOffset": 12, "endOffset": 31}, {"referenceID": 14, "context": ", 2009) to train a support vector regressor and experiment with various rankers in RankLib (Dang, 2011)3.", "startOffset": 91, "endOffset": 103}, {"referenceID": 38, "context": "For sequencebased compression using CRFs, we employ Mallet (McCallum, 2002) and integrate the Table 2 rules during inference.", "startOffset": 59, "endOffset": 75}, {"referenceID": 4, "context": "NLTK (Bird et al., 2009)", "startOffset": 5, "endOffset": 24}, {"referenceID": 44, "context": "4 Sentence compressions are evaluated by a 5-gram language model trained on Gigaword (Graff, 2003) by SRILM (Stolcke, 2002).", "startOffset": 108, "endOffset": 123}, {"referenceID": 16, "context": ", 2007), system by Davis et al. (2012) that report the best R-2 score on DUC 2006 and 2007 thus far, and to the purely extractive methods of SVR and LambdaMART.", "startOffset": 19, "endOffset": 39}, {"referenceID": 40, "context": "The Pyramid (Nenkova and Passonneau, 2004) evaluation was developed to manually assess how many relevant facts or Summarization Content Units (SCUs) are captured by system summaries.", "startOffset": 12, "endOffset": 42}, {"referenceID": 16, "context": "5 -t 0 -a -d The system output from Davis et al. (2012) is not available, so significance tests are not conducted on it.", "startOffset": 36, "endOffset": 56}, {"referenceID": 16, "context": "90 Davis et al. (2012) \u2013 10.", "startOffset": 3, "endOffset": 23}, {"referenceID": 21, "context": "Table 6: Human evaluation on our multi-scorer based system, Jagarlamudi et al. (2006) (Best DUC system (ROUGE)), and Lacatusu et al.", "startOffset": 60, "endOffset": 86}, {"referenceID": 21, "context": "Table 6: Human evaluation on our multi-scorer based system, Jagarlamudi et al. (2006) (Best DUC system (ROUGE)), and Lacatusu et al. (2006) (Best DUC system (LQ)).", "startOffset": 60, "endOffset": 140}, {"referenceID": 11, "context": "We also examine linguistic quality (LQ) in Grammaticality (Gra), Non-redundancy (Non-Red), Referential clarity (Ref), Focus (Foc), and Structure and Coherence (Coh) like Dang (2006), each rated from 1 (very poor) to 5 (very good).", "startOffset": 170, "endOffset": 182}, {"referenceID": 11, "context": "We also examine linguistic quality (LQ) in Grammaticality (Gra), Non-redundancy (Non-Red), Referential clarity (Ref), Focus (Foc), and Structure and Coherence (Coh) like Dang (2006), each rated from 1 (very poor) to 5 (very good). Our system has better non-redundancy than Jagarlamudi et al. (2006) and is comparable to Jagarlamudi et al.", "startOffset": 170, "endOffset": 299}, {"referenceID": 11, "context": "We also examine linguistic quality (LQ) in Grammaticality (Gra), Non-redundancy (Non-Red), Referential clarity (Ref), Focus (Foc), and Structure and Coherence (Coh) like Dang (2006), each rated from 1 (very poor) to 5 (very good). Our system has better non-redundancy than Jagarlamudi et al. (2006) and is comparable to Jagarlamudi et al. (2006) and Lacatusu et al.", "startOffset": 170, "endOffset": 346}, {"referenceID": 11, "context": "We also examine linguistic quality (LQ) in Grammaticality (Gra), Non-redundancy (Non-Red), Referential clarity (Ref), Focus (Foc), and Structure and Coherence (Coh) like Dang (2006), each rated from 1 (very poor) to 5 (very good). Our system has better non-redundancy than Jagarlamudi et al. (2006) and is comparable to Jagarlamudi et al. (2006) and Lacatusu et al. (2006) in other metrics except grammaticality.", "startOffset": 170, "endOffset": 373}, {"referenceID": 25, "context": "ROUGE scores in DUC 2006 (Jagarlamudi et al., 2006) along with our system by the same annotator to make a meaningful comparison.", "startOffset": 25, "endOffset": 51}, {"referenceID": 11, "context": "We further evaluate the linguistic quality (LQ) of the summaries for the same 10 topics in accordance with the measurement in Dang (2006). Four native speakers who are undergraduate students in computer science (none are authors) performed the task, We compare our system based on HEAD-driven beam search with MULTI-scorer", "startOffset": 126, "endOffset": 138}, {"referenceID": 25, "context": "to the best systems in DUC 2006 achieving top ROUGE scores (Jagarlamudi et al., 2006) (Best DUC system (ROUGE)) and top linguistic quality scores (Lacatusu et al.", "startOffset": 59, "endOffset": 85}, {"referenceID": 28, "context": ", 2006) (Best DUC system (ROUGE)) and top linguistic quality scores (Lacatusu et al., 2006) (Best DUC system (LQ))7.", "startOffset": 68, "endOffset": 91}, {"referenceID": 25, "context": "attain better non-redundancy than Jagarlamudi et al. (2006), meaning that human raters perceive less replicative content in our summaries.", "startOffset": 34, "endOffset": 60}, {"referenceID": 25, "context": "for other metrics are comparable to Jagarlamudi et al. (2006) and Lacatusu et al.", "startOffset": 36, "endOffset": 62}, {"referenceID": 25, "context": "for other metrics are comparable to Jagarlamudi et al. (2006) and Lacatusu et al. (2006), which either uses minimal non-learning-based compression rules or is a pure extractive system.", "startOffset": 36, "endOffset": 89}, {"referenceID": 9, "context": "We also evaluate sentence compression separately on (Clarke and Lapata, 2008), adopting the same partitions as (Martins and Smith, 2009), i.", "startOffset": 52, "endOffset": 77}, {"referenceID": 37, "context": "We also evaluate sentence compression separately on (Clarke and Lapata, 2008), adopting the same partitions as (Martins and Smith, 2009), i.", "startOffset": 111, "endOffset": 136}, {"referenceID": 17, "context": "Our compression models are compared with Hedge Trimmer (Dorr et al., 2003), a discriminative model proposed by McDonald (2006) and a", "startOffset": 55, "endOffset": 74}, {"referenceID": 9, "context": "We also evaluate sentence compression separately on (Clarke and Lapata, 2008), adopting the same partitions as (Martins and Smith, 2009), i.e. 1, 188 sentences for training and 441 for testing. Our compression models are compared with Hedge Trimmer (Dorr et al., 2003), a discriminative model proposed by McDonald (2006) and a", "startOffset": 53, "endOffset": 321}, {"referenceID": 38, "context": "50 McDonald (2006) 70.", "startOffset": 3, "endOffset": 19}, {"referenceID": 37, "context": "55 Martins and Smith (2009) 71.", "startOffset": 3, "endOffset": 28}, {"referenceID": 39, "context": "there is no statistically significant difference between our models and McDonald (2006) / M & S (2009) with p > 0.", "startOffset": 72, "endOffset": 88}, {"referenceID": 39, "context": "there is no statistically significant difference between our models and McDonald (2006) / M & S (2009) with p > 0.", "startOffset": 72, "endOffset": 103}, {"referenceID": 37, "context": "dependency-tree based compressor (Martins and Smith, 2009)8.", "startOffset": 33, "endOffset": 58}, {"referenceID": 5, "context": "In addition, we also compute the F1 scores of grammatical relations which are annotated by RASP (Briscoe and Carroll, 2002) according to Clarke and Lapata (2008).", "startOffset": 96, "endOffset": 123}, {"referenceID": 35, "context": "dependency-tree based compressor (Martins and Smith, 2009)8. We adopt the metrics in Martins and Smith (2009) to measure the unigram-level macro precision, recall, and F1-measure with respect to human annotated compression.", "startOffset": 34, "endOffset": 110}, {"referenceID": 5, "context": "In addition, we also compute the F1 scores of grammatical relations which are annotated by RASP (Briscoe and Carroll, 2002) according to Clarke and Lapata (2008).", "startOffset": 97, "endOffset": 162}], "year": 2016, "abstractText": "We consider the problem of using sentence compression techniques to facilitate queryfocused multi-document summarization. We present a sentence-compression-based framework for the task, and design a series of learning-based compression models built on parse trees. An innovative beam search decoder is proposed to efficiently find highly probable compressions. Under this framework, we show how to integrate various indicative metrics such as linguistic motivation and query relevance into the compression process by deriving a novel formulation of a compression scoring function. Our best model achieves statistically significant improvement over the state-of-the-art systems on several metrics (e.g. 8.0% and 5.4% improvements in ROUGE-2 respectively) for the DUC 2006 and 2007 summarization task.", "creator": "TeX"}}}