{"id": "1607.01274", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Jul-2016", "title": "Temporal Topic Analysis with Endogenous and Exogenous Processes", "abstract": "We consider the problem of modeling temporal textual data taking endogenous and exogenous processes into account. Such text documents arise in real world applications, including job advertisements and economic news articles, which are influenced by the fluctuations of the general economy. We propose a hierarchical Bayesian topic model which imposes a \"group-correlated\" hierarchical structure on the evolution of topics over time incorporating both processes, and show that this model can be estimated from Markov chain Monte Carlo sampling methods. We further demonstrate that this model captures the intrinsic relationships between the topic distribution and the time-dependent factors, and compare its performance with latent Dirichlet allocation (LDA) and two other related models. The model is applied to two collections of documents to illustrate its empirical performance: online job advertisements from DirectEmployers Association and journalists' postings on BusinessInsider.com.", "histories": [["v1", "Mon, 4 Jul 2016 01:16:55 GMT  (347kb,D)", "http://arxiv.org/abs/1607.01274v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.IR cs.LG", "authors": ["baiyang wang", "diego klabjan"], "accepted": true, "id": "1607.01274"}, "pdf": {"name": "1607.01274.pdf", "metadata": {"source": "META", "title": "Temporal Topic Analysis with Endogenous and Exogenous Processes", "authors": ["Baiyang Wang", "Diego Klabjan"], "emails": ["baiyang@u.northwestern.edu", "d-klabjan@northwestern.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to do their work are also able to do their work. (...) Most people who are able to do their work are able to do their work. (...) Most of them are not able to do their work. (...) Most of them are able to do their work. (...) Most of them are able to do their work. (...) Most of them are able to do their work. (...) Most of them are able to do their work. (...) Most of them are not able to do their work. (...) Most of them are able to do their work. (...) Most of them are not able to do their work. (...) Most of them are not able to do their work. (...) Most of them are not able to do their work. (...) Most of them are not able to do their work. (...) Most of them are not able to do their work. (...) Most of them are not able to do their work."}, {"heading": "2 Review of Time-Dependent Topic Modeling", "text": "The LDA model is as follows: (1), (1), (1), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2, (2), (2), (2), (2), (2, (2), (2), (2), (2), (2, (2), (2), (2), (2, (2), (2), (2, (2), (2), (2, (2), (2), (2, (2), (2), (2), (2, (, (2), (2), (, (2), (2), (2), (, (, (, (2), (2), (, (2), (, (, (), (2), (2), (, (2), (, (, (), (, (2), (, (2), (, (, (), (2), (, (2), (,."}, {"heading": "3 Model and Algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Motivation: A Group-Correlated Hierarchical Dirichlet Process", "text": "We formulate our problem as follows: We get time periods t = 1,.., T, documents from each period dt, i, i = 1.,.., Nt, t = 1,.. \u2212, T, and the time indices of the words {xt, i, j} Jt, i j = 1 within each document dt, i from the first word to the last. Words are indexed by a dictionary containing a total of V-words. We start with a hierarchical dirichlet process in time 1: leave G1, DP (\u03b3, H), G1i | (\u03b11, G1) and DP (\u03b11, G1), where G1 is a random word distribution for time 1, and G1i is the random word distribution for document d1i. For G2,. GT, we have the following Markovian structure, p (Gt)."}, {"heading": "3.2 A Group-Correlated Temporal Topic Model: Stick-Breaking Truncation", "text": "In the following, we will consider a stick-breaking truncation of the model, since subsequent conclusions of the exact model can be tricky. (With the stick-breaking expression of G1 in (8), we have \u03c61, \u03c62,.., iid \u0445 H, \u03c01 = (\u03c011, \u03b2 12,..) \u0445 stick (\u03b3), G1 = \u2211 k = 1 \u03c01k\u03b4k. (9) Here, we set d (\u00b7, \u00b7) = topic if the two probability measures have different supports; this requires that all time periods share the same topics. Our intention is that the topics should remain the same to investigate their relations to endogenous and exogenous processes; otherwise, changes in the topics can blur the relationships and possibly lead to an overmatch. We apply the entire variation distance d (p, q) = \u03bb."}, {"heading": "3.3 Sampling the posterior: An MCMC Approach", "text": "Direct estimation of the posterior level is often intractable, since the expression in closed form, if it exists, is difficult to integrate, and therefore many approaches to approximate the posterior level have been suggested. Monte Carlo methods, which include a large number of samples from the posterior level as its approximation, are particularly helpful. In this essay, we adopt the Markov Monte Carlo chain (MCMC), which constructs samples from a Markov chain and is asymptotically accurate. In the following, we present the Metropolis within Gibbs method, which is tailored to our situation, which is a variant of the general MCMC approach. It only requires specification of the complete conditions of the unknown variables below. We consider the following variables Z = {zt, i} Jt, i} Jt, i j} Jt j = 1 Nt i = 1 T = 1 T t t, {sp} Tt = 1, {sp} Tt = 1, p = 1."}, {"heading": "4 Case Studies", "text": "The proposed model, \"GCLDA,\" will be demonstrated using two sets of data: (1) online job ads from my.jobs from February to September 2014 and (2) journalist listings in 2014 in the \"Finance\" section of BusinessInsider.com, an American business and technology news website. Our algorithm has been implemented in Java and we compare GCLDA with LDA, ToT and STM."}, {"heading": "4.1 Experiment Settings", "text": "We initialize the hyperparameters of LDA as follows: \u03b1 = (50 / K,.., 50 / K), \u03b2 = (0.01,.., 0.01), according to a rule of thumb performed in Berry and Kogan (2010) and Sridhar (2015). For ToT, we use the same alpha and \u03b2-space timestamps to make the calculation feasible. For GCLDA, we perform \u03b3 = 1, \u03c00 = (1 / K,., 1 / K), \u03b1t iid test forms (1, 1), p-and linear space timestamps to make the calculation feasible. We perform the Metropolis-within-Gibbs algorithm, as described in Section 3.3 for GCLDA, and perform 5,000 iterations of the Markov chain with 1,000 firing patterns for GCLDA, LDA, and ToT job; for LDA job, we apply the data from Griffley."}, {"heading": "4.2 My.jobs: Online Job Advertisements", "text": "The number of job ads on my.jobs from February to September 2014 amounts to 17,147,357 in total, and the number of ads per day varies greatly. Therefore, we collect a layered sample of 44,660 ads with an approximately equal number of samples for each day, so that we have sampled 0.26% of all documents in total. Training data consists of 40,449 ads, and the test theme data consists of 4,211 ads (9.4% of the sample). For the exogenous variable {yt} Tt = 1, we use the standardized consumer price index from February to September 2014, so that p = 1, and T = 8.Figure 1 implies that GCLDA predicts the words in the new documents better in terms of perplexity. This is due to the fact that the introduction of both endogenous and exogenous processes will show us more accurate conclusions on the subject of the documents in a specific period."}, {"heading": "4.3 BusinessInsider.com: Financial News Articles", "text": "We look at all posts in the \"Finance\" section of BusinessInsider.com on all trading days in 2014. There are a total of 15,659 articles divided into a training dataset of 12,527 articles and a test dataset of 3,132 articles (20% of all articles). We apply the daily price of the Chicago Board Options Market Volatility Index (VIX) as the exogenous process and measure the volatility of the US financial market. The other settings are the same as those in Section 4.2. We offer an analysis of the perplexity of the LDA, GCLDA and ToT in Figure 4. The lines are smoothed out by a range of 0.2 as there are large fluctuations in the market."}, {"heading": "5 Conclusion", "text": "We have developed a temporal thematic model that analyzes timestamped text documents with known exogenous processes. Our new model, GCLDA, takes into account both endogenous and exogenous processes and applies the Markov Monte Carlo sampling chain for calibration. We have shown that this model is more timely for documents when it comes to perplexity, and extracts good information from job ads and financial news articles. We suggest that one possible direction for the future may be to analyze the contents of temporal documents so that they can predict the trends of related exogenous processes."}, {"heading": "Acknowledgments", "text": "This research was conducted in collaboration with the Workforce Science Project of the Searle Center for Law, Regulation and Economic Growth at Northwestern University. We are grateful to Deborah Wei\u00df, Director of the Workforce Science Project, for introducing the topic of workers and providing guidance. We are also very grateful for the help and data provided by the DirectEmployers Association."}], "references": [{"title": "Text Mining: Applications and Theory", "author": ["M. Berry", "J. Kogan"], "venue": "Chichester, UK: Wiley.", "citeRegEx": "Berry and Kogan,? 2010", "shortCiteRegEx": "Berry and Kogan", "year": 2010}, {"title": "Dynamic topic models", "author": ["D. Blei", "J. Lafferty"], "venue": "23rd International Conference on Machine Learning.", "citeRegEx": "Blei and Lafferty,? 2006", "shortCiteRegEx": "Blei and Lafferty", "year": 2006}, {"title": "Latent dirichlet allocation", "author": ["D. Blei", "A. Ng", "M. Jordan"], "venue": "Journal of Machine Learning Research 3:993\u2013 1022.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "America\u2019s low-paying recovery: More jobs than ever, worse wages", "author": ["P. Coy"], "venue": "Bloomberg Business. www.bloomberg.com/bw/articles/2014-08-11/reportnew-jobs-in-u-dot-s-dot-offer-lower-wages-than-beforerecession.", "citeRegEx": "Coy,? 2014", "shortCiteRegEx": "Coy", "year": 2014}, {"title": "Dependent nonparametric trees for dynamic hierarchical clustering", "author": ["A. Dubey", "Q. Ho", "S. Williamson", "E. Xing"], "venue": "Advances in Neural Information Processing Systems 28. MIT Press.", "citeRegEx": "Dubey et al\\.,? 2014", "shortCiteRegEx": "Dubey et al\\.", "year": 2014}, {"title": "Bayesian analysis of some nonparametric problems", "author": ["T. Ferguson"], "venue": "Annals of Statistics 1:209\u2013230.", "citeRegEx": "Ferguson,? 1973", "shortCiteRegEx": "Ferguson", "year": 1973}, {"title": "Finding scientific topics", "author": ["T. Griffiths", "M. Steyvers"], "venue": "Proceedings of the National Academy of Sciences 101:5228\u20135235.", "citeRegEx": "Griffiths and Steyvers,? 2004", "shortCiteRegEx": "Griffiths and Steyvers", "year": 2004}, {"title": "Recovery has created far more low-wage jobs than better-paid ones", "author": ["A. Lowrey"], "venue": "The New York Times. www.nytimes.com/2014/04/28/business/economy/recoveryhas-created-far-more-low-wage-jobs-than-better-paidones.html.", "citeRegEx": "Lowrey,? 2014", "shortCiteRegEx": "Lowrey", "year": 2014}, {"title": "Hierarchical bayesian modeling of topics in time-stamped documents", "author": ["I. Pruteanu-Malinici", "L. Ren", "J. Paisley", "E. Wang", "L. Carin"], "venue": "IEEE Trans. Pattern Analysis Machine Intelligence 32:996\u20131011.", "citeRegEx": "Pruteanu.Malinici et al\\.,? 2010", "shortCiteRegEx": "Pruteanu.Malinici et al\\.", "year": 2010}, {"title": "The dynamic hierarchical dirichlet process", "author": ["L. Ren", "D. Dunson", "L. Carin"], "venue": "25th International Conference on Machine Learning.", "citeRegEx": "Ren et al\\.,? 2008", "shortCiteRegEx": "Ren et al\\.", "year": 2008}, {"title": "Monte Carlo Statistical Methods", "author": ["C. Robert", "G. Casella"], "venue": "New York: Springer, 2nd ed. edition.", "citeRegEx": "Robert and Casella,? 2004", "shortCiteRegEx": "Robert and Casella", "year": 2004}, {"title": "Harris recurrence of metropolis-within-gibbs and trans-dimensional markov chains", "author": ["G. Roberts", "J. Rosenthal"], "venue": "The Annals of Applied Probability 16:2123\u20132139.", "citeRegEx": "Roberts and Rosenthal,? 2006", "shortCiteRegEx": "Roberts and Rosenthal", "year": 2006}, {"title": "A model of text for experimentation in the social sciences", "author": ["M. Roberts", "B. Stewart", "E. Airoldi"], "venue": "scholar.harvard.edu/files/bstewart/files/stm.pdf.", "citeRegEx": "Roberts et al\\.,? 2015", "shortCiteRegEx": "Roberts et al\\.", "year": 2015}, {"title": "Navigating the local modes of big data: The case of topic models", "author": ["M. Roberts", "B. Stewart", "D. Tingley"], "venue": "Data Analytics in Social Science, Government, and Industry. New York: Cambridge University Press. forthcoming.", "citeRegEx": "Roberts et al\\.,? 2015", "shortCiteRegEx": "Roberts et al\\.", "year": 2015}, {"title": "A constructive definition of dirichlet priors", "author": ["J. Sethuraman"], "venue": "Statistica Sinica 4:639\u2013650.", "citeRegEx": "Sethuraman,? 1994", "shortCiteRegEx": "Sethuraman", "year": 1994}, {"title": "Unsupervised topic modeling for short texts using distributed representations of words", "author": ["V. Sridhar"], "venue": "Proceedings of NAACL-HLT 2015.", "citeRegEx": "Sridhar,? 2015", "shortCiteRegEx": "Sridhar", "year": 2015}, {"title": "Hierarchical dirichlet processes", "author": ["Y. Teh", "M. Jordan", "M. Beal", "D. Blei"], "venue": "Journal of the American Statistical Association 101:1566\u20131582.", "citeRegEx": "Teh et al\\.,? 2005", "shortCiteRegEx": "Teh et al\\.", "year": 2005}, {"title": "Evaluation methods for topic models", "author": ["H. Wallach", "I. Murray", "R. Salakhutdinov", "D. Mimno"], "venue": "26th International Conference on Machine Learning.", "citeRegEx": "Wallach et al\\.,? 2009", "shortCiteRegEx": "Wallach et al\\.", "year": 2009}, {"title": "Topics over time: A non-markov continuous-time model of topical trends", "author": ["X. Wang", "A. McCallum"], "venue": "12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.", "citeRegEx": "Wang and McCallum,? 2006", "shortCiteRegEx": "Wang and McCallum", "year": 2006}, {"title": "Online variational inference for the hierarchical dirichlet process", "author": ["C. Wang", "J. Paisley", "D. Blei"], "venue": "Artificial Intelligence and Statistics.", "citeRegEx": "Wang et al\\.,? 2011", "shortCiteRegEx": "Wang et al\\.", "year": 2011}, {"title": "Dynamic topic modeling for monitoring market competition from online text and image data", "author": ["H. Zhang", "G. Kim", "E. Xing"], "venue": "21st ACM SIGKDD Conference on knowledge Discovery and Data Mining.", "citeRegEx": "Zhang et al\\.,? 2015", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 18, "context": "Many timedependent topic models without the exogenous component have been proposed, such as the Topics over Time (ToT) model (Wang and McCallum 2006) and the dynamic topic model (DTM) (Blei and Lafferty 2006), to name a few.", "startOffset": 125, "endOffset": 149}, {"referenceID": 1, "context": "Many timedependent topic models without the exogenous component have been proposed, such as the Topics over Time (ToT) model (Wang and McCallum 2006) and the dynamic topic model (DTM) (Blei and Lafferty 2006), to name a few.", "startOffset": 184, "endOffset": 208}, {"referenceID": 1, "context": "For the endogenous part of our paper, we impose a Markovian structure on the topic distribution over time, similar to Blei and Lafferty (2006) and Dubey et al.", "startOffset": 118, "endOffset": 143}, {"referenceID": 1, "context": "For the endogenous part of our paper, we impose a Markovian structure on the topic distribution over time, similar to Blei and Lafferty (2006) and Dubey et al. (2014). For the exogenous process, we incorporate it into the topic distribution in each period, adjusting the endogenous topic evolution process.", "startOffset": 118, "endOffset": 167}, {"referenceID": 14, "context": "With the stick-breaking notation (Sethuraman 1994), we have", "startOffset": 33, "endOffset": 50}, {"referenceID": 5, "context": "More properties of the Dirichlet process can be found in Ferguson (1973).", "startOffset": 57, "endOffset": 73}, {"referenceID": 16, "context": "A hierarchical Dirichlet process (HDP) was proposed in the context of text modeling by Teh et al. (2005). The following hierarchical structure is assumed, \uf8f4\uf8f2\uf8f4\uf8f3 G0|\u03b3 \u223c DP (\u03b3,H), G1, .", "startOffset": 87, "endOffset": 105}, {"referenceID": 8, "context": "One approach is to impose a finite mixture structure on the topic distribution: a dynamic hierarchical Dirichlet process (dHDP) (Ren, Dunson, and Carin 2008) was proposed by adding a temporal dimension, and its variation was further applied on topic modeling with a stick-breaking truncation of Dirichlet processes (Pruteanu-Malinici et al. 2010).", "startOffset": 315, "endOffset": 346}, {"referenceID": 1, "context": "For instance, the dynamic topic model (DTM) (Blei and Lafferty 2006) is as follows, \uf8f1\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 \u03c6t,k|\u03c6t\u22121,k \u223c N(\u03c6t\u22121,k, \u03c3I), \u03b1t|\u03b1t\u22121 \u223c N(\u03b1t\u22121, \u03b4I), \u03b8t,i|\u03b1t iid \u223c N(\u03b1t, aI), zt,i,j |\u03b8t,i iid \u223c Cat(exp(\u03b8t,i)), xt,i,j |zt,i,j \u223c Cat(exp(\u03c6t,zt,i,j )).", "startOffset": 44, "endOffset": 68}, {"referenceID": 4, "context": "We apply the total variation distance d(p, q) = \u03bb \u00b7 \u222b |p\u2212 q|d\u03bc with \u03bb > 0, although many others can also be applied and lead to, for instance, a log-normal model in DTM, or a normal model (Dubey et al. 2014; Zhang, Kim, and Xing 2015).", "startOffset": 188, "endOffset": 234}, {"referenceID": 8, "context": "We note that a number of papers in topic modeling have put this approach into practice (Pruteanu-Malinici et al. 2010; Wang, Paisley, and Blei 2011).", "startOffset": 87, "endOffset": 148}, {"referenceID": 8, "context": "It has been shown (Pruteanu-Malinici et al. 2010) that when the truncation levelK is large, we may as well replace the distribution of \u03c01 with \u03c01 \u223c Dir(\u03b3\u03c00), where \u03b3 = 1, \u03c00 = (1/K, .", "startOffset": 18, "endOffset": 49}, {"referenceID": 8, "context": "We note that a number of papers in topic modeling have put this approach into practice (Pruteanu-Malinici et al. 2010; Wang, Paisley, and Blei 2011). It has been shown (Pruteanu-Malinici et al. 2010) that when the truncation levelK is large, we may as well replace the distribution of \u03c01 with \u03c01 \u223c Dir(\u03b3\u03c00), where \u03b3 = 1, \u03c00 = (1/K, . . . , 1/K). We also let H = Dir(\u03b2, . . . , \u03b2) as in the paper by Teh et al. (2005). We summarize our model, \uf8f1\uf8f4\uf8f2\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3 \u03c61, .", "startOffset": 88, "endOffset": 417}, {"referenceID": 16, "context": "The last two lines above are derived as in Teh et al. (2005). We note that here \u03c6k is the per-topic word distribution, \u03b8t,i is the per-document topic distribution, and zt,i,j is the actual topic for each word; they have the same meaning as in LDA.", "startOffset": 43, "endOffset": 61}, {"referenceID": 6, "context": "Following Griffiths and Steyvers (2004), conditioning on all other variables listed for sampling,", "startOffset": 10, "endOffset": 40}, {"referenceID": 6, "context": "Also following Griffiths and Steyvers (2004), we have for \u03b1t and \u03c0\u0303t p(\u03b1t, \u03c0\u0303t|rest) \u221d p(Z|\u03b1t, \u03c0\u0303t)p(\u03c01,.", "startOffset": 15, "endOffset": 45}, {"referenceID": 10, "context": "For the theoretical convergence properties of Metropolis-withinGibbs samplers, the reader can refer to Robert and Casella (2004) and Roberts and Rosenthal (2006).", "startOffset": 103, "endOffset": 129}, {"referenceID": 10, "context": "For the theoretical convergence properties of Metropolis-withinGibbs samplers, the reader can refer to Robert and Casella (2004) and Roberts and Rosenthal (2006).", "startOffset": 103, "endOffset": 162}, {"referenceID": 0, "context": "01), according to a rule of thumb which has been carried out in Berry and Kogan (2010) and Sridhar (2015).", "startOffset": 64, "endOffset": 87}, {"referenceID": 0, "context": "01), according to a rule of thumb which has been carried out in Berry and Kogan (2010) and Sridhar (2015). For ToT, we use the same \u03b1 and \u03b2 and linearly space the timestamps to make computation feasible.", "startOffset": 64, "endOffset": 106}, {"referenceID": 6, "context": "3 for GCLDA, and run 5,000 iterations of the Markov chain with 1,000 burn-in samples for GCLDA, LDA, and ToT; for LDA, we apply the collapsed Gibbs sampling as in Griffiths and Steyvers (2004). The number of topics is set to K = 50 for both data sets.", "startOffset": 163, "endOffset": 193}, {"referenceID": 17, "context": "We apply the \u201cLeft-to-right\u201d algorithm (Wallach et al. 2009) and apply point estimates for \u201c\u03a6\u201d and \u201c\u03b1m\u201d using the training data, as suggested in Section 3 in the same paper.", "startOffset": 39, "endOffset": 60}, {"referenceID": 7, "context": "This partly agrees with some news articles in 2014 in that while the labor market was recovering, there was relatively lower growth in traditional higher-paid job categories (Lowrey 2014; Coy 2014).", "startOffset": 174, "endOffset": 197}, {"referenceID": 3, "context": "This partly agrees with some news articles in 2014 in that while the labor market was recovering, there was relatively lower growth in traditional higher-paid job categories (Lowrey 2014; Coy 2014).", "startOffset": 174, "endOffset": 197}], "year": 2016, "abstractText": "We consider the problem of modeling temporal textual data taking endogenous and exogenous processes into account. Such text documents arise in real world applications, including job advertisements and economic news articles, which are influenced by the fluctuations of the general economy. We propose a hierarchical Bayesian topic model which imposes a \u201dgroupcorrelated\u201d hierarchical structure on the evolution of topics over time incorporating both processes, and show that this model can be estimated from Markov chain Monte Carlo sampling methods. We further demonstrate that this model captures the intrinsic relationships between the topic distribution and the time-dependent factors, and compare its performance with latent Dirichlet allocation (LDA) and two other related models. The model is applied to two collections of documents to illustrate its empirical performance: online job advertisements from DirectEmployers Association and journalists\u2019 postings on BusinessInsider.com.", "creator": "TeX"}}}