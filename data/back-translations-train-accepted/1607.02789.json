{"id": "1607.02789", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Jul-2016", "title": "Charagram: Embedding Words and Sentences via Character n-grams", "abstract": "We present Charagram embeddings, a simple approach for learning character-based compositional models to embed textual sequences. A word or sentence is represented using a character n-gram count vector, followed by a single nonlinear transformation to yield a low-dimensional embedding. We use three tasks for evaluation: word similarity, sentence similarity, and part-of-speech tagging. We demonstrate that Charagram embeddings outperform more complex architectures based on character-level recurrent and convolutional neural networks, achieving new state-of-the-art performance on several similarity tasks.", "histories": [["v1", "Sun, 10 Jul 2016 21:59:19 GMT  (36kb)", "http://arxiv.org/abs/1607.02789v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["john wieting", "mohit bansal", "kevin gimpel", "karen livescu"], "accepted": true, "id": "1607.02789"}, "pdf": {"name": "1607.02789.pdf", "metadata": {"source": "CRF", "title": "CHARAGRAM: Embedding Words and Sentences via Character n-grams", "authors": ["John Wieting", "Mohit Bansal Kevin Gimpel", "Karen Livescu"], "emails": ["jwieting@ttic.edu", "mbansal@ttic.edu", "kgimpel@ttic.edu", "klivescu@ttic.edu"], "sections": [{"heading": null, "text": "ar Xiv: 160 7.02 789v 1 [cs.C L] 10 Ju"}, {"heading": "1 Introduction", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live."}, {"heading": "2 Related Work", "text": "The simplest approaches append subword features to word embeddings (2011; El-Desoky Mousa et al., 2013), while others learned embeddings together for subword units and words by defining simple compositional architectures (often based on addition) to create word embeddings from subword embeddings (Lazaridou et al., 2013; Botha and Blunsom et al., 2014; Qiu et al., 2015). A current trend is to use richer functional architectures to create word embeddings from subword embeddings (Lazaridou et al., 2013; Botha and Blunsom et al., 2014; Qiu et al., 2014; Chen et al., 2015)."}, {"heading": "3 Models", "text": "We describe models that embed textual sequences with their characters, including our CHARAGRAM model and the baselines we compare. We designate a character-based textual sequence after x = < x1, x2,..., xm > that includes spaces between words as well as special start-of-sequence characters. We use xji to denote the sub-sequence of character actors from position i to position j inclusive, i.e., x j i = < xi + 1,..., xj >, and we define x i = xi.Our CHARAGRAM model refers to a character sequence x by adding the vectors of its character ngrams followed by an elementary nonlinearity: xi xi + 1, xj >, and we define x. \""}, {"heading": "4 Experiments", "text": "The aim of the first two (Section 4.1) is to produce embedding for text sequences in such a way that the embedding for paraphrases shows a high cosinal similarity. Our third evaluation (Section 4.2) is a classification task and follows the setup of the English part-of-speech tagging experiment by Ling et al. (2015a)."}, {"heading": "4.1 Word and Sentence Similarity", "text": "We compare the ability of our models to capture semantic similarities for both words and sentences. We train on noisy pairs of paraphrases from the Paraphrase Database (PPDB; Ganitkevitch et al., 2013) with an L2-regulated contrast loss objective function following the training sequence of Wieting et al. (2015) and Wieting et al. (2016)."}, {"heading": "4.1.1 Datasets", "text": "In terms of word similarity, we focus on two of the most commonly used datasets for evaluating the semantic similarity of word embedding: WordSim-353 (WS353) (Finkelstein et al., 2001) and SimLex-999 (SL999) (Hill et al., 2015). In addition, we evaluate our best model based on the Stanford Rare Word Similarity Dataset (Luong et al., 2013). In terms of sentence similarity, we evaluate a diverse set of 22 text similarity datasets, including all datasets from each SemEval Semantic Text similarity (STS) task from 2012 to 2015. In terms of sentence similarity, we also evaluate the SemEval 2015 Twitter task (Xu et al., 2015) and the SemEval 2014 SICK Semantic Relatedness Task (Marelli et al., 2014)."}, {"heading": "4.1.2 Preliminaries", "text": "For training data, we use pairs from the PPDB. For word similarity experiments, we train on word pairs, and for sentence similarity, we train on sentence pairs. PPDB comes in different sizes (S, M, L, XL, XXL and XXXL), with each larger size summarizing all the smaller ones. PPDB pairs are sorted according to a confidence measure, so the smaller sentences contain more precise paraphrases. Before training the CHARAGRAM model, we must fill V, the vocabulary of the n-gram characters contained in the model, which we obtain from the training data used for the final models in each setting, which is either the lexical or phratical section of the PPDB XXL. We vote whether to include the full n-gram sentences in these data sets or only those that occur more than once. When extracting n-grams, we include blanks and insert an additional space before each word, or after each of the evaluation dates, to ensure that the evaluation data is displayed strongly at the beginning and end of each word."}, {"heading": "4.1.3 Word Embedding Experiments", "text": "Training and Tuning For hyperparameter tuning, we used one epoch on the lexical section of PPDB XXL, which consists of 770,007 word pairs. We used either WS353 or SL999 for model selection (reported below). We then took the selected hyperparameters and dressed for 50 epochs to ensure that all models had a chance to converge.Full details of our tuning procedure are provided in Appendix B. In short, we tuned all models thoroughly, tuning the activation functions for CHARAGRAM and charCNN, as as the regularization strength, mini-batch size, and sampling type for all models. For charCNN, we experimented with two filters sets: one uses 175 filters for each n-gram size: {2, 3, 4}, and the other uses the set of filters from Kim et al. (2015), consisting of 25 filters of size 2, 75 of size 3, 100 of size 4, 125 of size, 5 and roof size 4, 4 of size."}, {"heading": "4.1.4 Sentence Embedding Experiments", "text": "We have the first training of our models using a passage through PPDB XL, which consists of 3,033,753 unique phrase pairs. Following Wieting et al. (2016), we use the annotated phrase pairs specified by Pavlick et al. (2015) as our validation, we use most powerful models and train on the basis of the 9,123,575 unique phrase pairs in the phrasing section of PPPDB XXL for 10 epochs. For all experiments, we fix the mini-batch size to 100, the margin of 0.4, and use sampling (see Appendix A). For the CHARAGRAM model, V contains all 122,610 character n-grams (n, 3, 4}) in the PPPPPPPDB XXL range. The other tuning settings are the same as in Section 4.1.3.For another baseline, we train the PARAGRAM model."}, {"heading": "4.2 POS Tagging Experiments", "text": "It also differs from the semantic similarity that allows us to evaluate our architectures based on a syntactical task. We replicate the POS tagging experiment set up by Ling et al. (2015a). Their model uses a bidirectional LSTM via character embedding to represent words. They then use the resulting word representations in another bidirectional LSTM that predicts the day for each word. We replace their bidirectional LSTM with our three architectures: char-CNN, charLSTM and CHARAGRAM. We use the part of the Penn Treebank by using sections 1-18 for training, 19-21 for tuning, and 22-24 for testing. We set the dimensionality of the character embedding to 50 and that of the word representation to 150."}, {"heading": "4.3 Convergence", "text": "One observation we made during our experiments was that different models converge at markedly different rates.Figure 1 plots the performance of the word similarity and the tagging tasks as a function of 2We did not consider ReLU for the similarity experiments because the final embedding is directly used to calculate cosinal similarities, but this resulted in poorer performance than limiting the embedding as not negative.3We also tried to add a second (300-dimensional) layer for the word and sentence embedding models and found that it violates the performance.The number of examples processed during the training. To increase the word similarity, we draw the oracle Spearmans on SL999 while recording the tagging accuracy on the validation theorem. We evaluate the performance of each quarter epoch (approximately all 194,252 word pairs) for word similarity and each epoch for the conference."}, {"heading": "4.4 Model Size Experiments", "text": "The default setting for our CHARAGRAM and CHARAGRAM-PHRASE models is the use of all characters bigram, trigrams and 4-gram, which occur at least C times in the training data, with C being tuned over the set {1, 2}. This results in a large number of parameters that could be considered an unfair advantage over the comparatively smaller charCNN and charLSTM models, which use up to 881,025 and 763,200 parameters respectively in the similarity experiments.4 On the other hand, for a certain training example, very few parameters are actually used in the CHARAGRAM model. For the charCNN and charLSTM models, on the other hand, all parameters except the character embeddings for these characters, which are not present in the example, are used. For a set of 100 characters and when using the 300-dimensional CHARAGRAM model with bigrams, trigrams and 4-grams, there are approximately 90,000 parameters in this set, which we have far fewer than we have used for the charms we use for the CNN models."}, {"heading": "5 Analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Quantitative Analysis", "text": "We have set ourselves the task of researching and understanding the various terms and concepts in the individual terms. We have a negative correlation between the individual terms and the way in which we find the individual terms and concepts in the individual terms and concepts in the different terms and concepts in the individual terms and concepts in the individual terms and terms in the different terms and concepts in the different terms and concepts in the different terms and concepts in the individual terms in the individual terms. We have shown the results in Table 6.The CHARAGRAM-PHRASE. We have the better terms for each number of unknown terms. The PARAGRAM-PHRASE models are present when there are more unknown words in the terms, presumably because it is forced to use the unknown word for all unknown terms. CHARAGRAM-PHRASE models have better terms for each number of unknown terms in the other terms."}, {"heading": "6 Conclusion", "text": "We conducted a careful empirical comparison of character-based compositional architectures to three NLP tasks. While most previous work looked at machine translation, language modeling, and syntactical analysis, we showed how character-level modeling can improve semantic similarity tasks both quantitatively and with extensive qualitative analysis. We found a consistent trend: the simplest architecture converts fastest to high performance. These results, along with those from Wieting et al. (2016), suggest that practitioners should start with simple architectures rather than immediately move to RNNNs and CNNs. We publish our code and trained models so that they can be used by the NLP community for universal, character-based text representation."}, {"heading": "Acknowledgments", "text": "We would like to thank the developers of Theano (Theano Development Team, 2016) and NVIDIA Corporation for donating GPUs used in this research."}, {"heading": "Appendix A Training", "text": "For word and sentence similarity, we follow the training process of Wieting et al. (2015) and Wieting et al. (2016) described below. For word and sentence similarity, we follow the English Penn Treebank Training Procedure of Ling et al. (2015a). For the similarity tasks, the training data consists of a sentence X of sentence pairs < x1, x2 > from the Paraphrase Database (PPDB; Ganitkevitch et al., 2013), in which x1 and x2 are assumed to be paraphrases. We optimize a sentence X of sentence pairs < x1, x2 > from the Paraphrase Database (PPDB; Ganitkevitch et al., 2013), in which x1 and x2 are assumed to be paraphrases assuming that margin-based losses < margin-based losses: min, x1 | X | (sp. < x1, x2 >; Xmax; Xcos (x1), a strategy (x1)."}, {"heading": "Appendix B Tuning Word Similarity", "text": "For all architectures, we set the minibatch size (25 or 50) and the type of scanning used (MIX or MAX) to 0.4 and the dimensionality d of each model to 300. For the CHARAGRAM model, we set the activation function h (tanh or linear) and the regularization coefficient \u03bb (above {10 \u2212 4, 10 \u2212 5, 10 \u2212 6}).The n-gram vocabulary V contained all 100,283 character n-grams (n \u0432 {2, 3, 4}) in the lexical section of PPDB XXL.For charCNN and charLSTM, we randomly initialized 300-dimensional character embedding for all unique characters in the training data. for charLSTM, we tuned whether to include an output gate. For charCNN, we set the activation function of the filter (linear or tanh) and the activation for the fully connected characters in the training data."}, {"heading": "Appendix C Full Sentence Similarity", "text": "Table 11 shows the complete results of our sentence similarity experiments."}], "references": [{"title": "SemEval-2012 task 6: A pilot on semantic textual similarity", "author": ["Agirre et al.2012] Eneko Agirre", "Mona Diab", "Daniel Cer", "Aitor Gonzalez-Agirre"], "venue": "In Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume", "citeRegEx": "Agirre et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2012}, {"title": "SEM 2013 shared task: Semantic textual similarity", "author": ["Agirre et al.2013] Eneko Agirre", "Daniel Cer", "Mona Diab", "Aitor Gonzalez-Agirre", "Weiwei Guo"], "venue": "In Second Joint Conference on Lexical and Computational Semantics (*SEM),", "citeRegEx": "Agirre et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2013}, {"title": "SemEval-2014 task 10: Multilingual semantic textual similarity", "author": ["Agirre et al.2014] Eneko Agirre", "Carmen Banea", "Claire Cardie", "Daniel Cer", "Mona Diab", "Aitor GonzalezAgirre", "Weiwei Guo", "Rada Mihalcea", "German Rigau", "Janyce Wiebe"], "venue": null, "citeRegEx": "Agirre et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Agirre et al\\.", "year": 2014}, {"title": "Factored neural language models", "author": ["Alexandrescu", "Katrin Kirchhoff"], "venue": "In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,", "citeRegEx": "Alexandrescu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Alexandrescu et al\\.", "year": 2006}, {"title": "Improved transition-based parsing by modeling characters instead of words", "author": ["Chris Dyer", "Noah A. Smith"], "venue": null, "citeRegEx": "Ballesteros et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ballesteros et al\\.", "year": 2015}, {"title": "Curriculum learning", "author": ["Bengio et al.2009] Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Ronan Collobert", "Jason Weston"], "venue": "In Proceedings of the 26th annual international conference on machine learning,", "citeRegEx": "Bengio et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2009}, {"title": "Compositional morphology for word representations and language modelling", "author": ["Botha", "Blunsom2014] Jan A. Botha", "Phil Blunsom"], "venue": "In International Conference on Machine Learning (ICML)", "citeRegEx": "Botha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Botha et al\\.", "year": 2014}, {"title": "A large annotated corpus for learning natural language inference. arXiv preprint arXiv:1508.05326", "author": ["Gabor Angeli", "Christopher Potts", "Christopher D Manning"], "venue": null, "citeRegEx": "Bowman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "A fast unified model for parsing and sentence understanding", "author": ["Jon Gauthier", "Abhinav Rastogi", "Raghav Gupta", "Christopher D. Manning", "Christopher Potts"], "venue": "Proceedings of ACL", "citeRegEx": "Bowman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2016}, {"title": "Joint learning of character and word embeddings", "author": ["Chen et al.2015] Xinxiong Chen", "Lei Xu", "Zhiyuan Liu", "Maosong Sun", "Huanbo Luan"], "venue": "In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI)", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "A character-level decoder without explicit segmentation for neural machine translation", "author": ["Chung et al.2016] Junyoung Chung", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1603.06147", "citeRegEx": "Chung et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2016}, {"title": "Characterbased neural machine translation", "author": ["Costa-Juss\u00e0", "Jos\u00e9 A.R. Fonollosa"], "venue": "arXiv preprint arXiv:1603.00810", "citeRegEx": "Costa.Juss\u00e0 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Costa.Juss\u00e0 et al\\.", "year": 2016}, {"title": "Boosting named entity recognition with neural character embeddings", "author": ["dos Santos", "Guimar\u00e3es2015] Cicero dos Santos", "Victor Guimar\u00e3es"], "venue": "In Proceedings of the Fifth Named Entity Workshop,", "citeRegEx": "Santos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Santos et al\\.", "year": 2015}, {"title": "Learning character-level representations for part-of-speech tagging", "author": ["dos Santos", "Bianca Zadrozny"], "venue": null, "citeRegEx": "Santos et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Santos et al\\.", "year": 2014}, {"title": "Morpheme-based feature-rich language models using deep neural networks for lvcsr of egyptian arabic", "author": ["Hong-Kwang Jeff Kuo", "Lidia Mangu", "Hagen Soltau"], "venue": null, "citeRegEx": "Mousa et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mousa et al\\.", "year": 2013}, {"title": "Elephant: Sequence labeling for word and sentence segmentation", "author": ["Evang et al.2013] Kilian Evang", "Valerio Basile", "Grzegorz Chrupa\u0142a", "Johan Bos"], "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,", "citeRegEx": "Evang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Evang et al\\.", "year": 2013}, {"title": "Non-distributional word vector representations. arXiv preprint arXiv:1506.05230", "author": ["Faruqui", "Dyer2015] Manaal Faruqui", "Chris Dyer"], "venue": null, "citeRegEx": "Faruqui et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "Placing search in context: The concept revisited", "author": ["Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin"], "venue": "In Proceedings of the 10th international conference on", "citeRegEx": "Finkelstein et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2001}, {"title": "Ppdb: The paraphrase database", "author": ["Benjamin Van Durme", "Chris Callison-Burch"], "venue": "In HLT-NAACL", "citeRegEx": "Ganitkevitch et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "Learning precise timing with lstm recurrent networks", "author": ["Gers et al.2003] Felix A Gers", "Nicol N Schraudolph", "J\u00fcrgen Schmidhuber"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Gers et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Gers et al\\.", "year": 2003}, {"title": "Generating sequences with recurrent neural networks. arXiv preprint arXiv:1308.0850", "author": ["Alex Graves"], "venue": null, "citeRegEx": "Graves.,? \\Q2013\\E", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "Multi-perspective sentence similarity modeling with convolutional neural networks", "author": ["He et al.2015] Hua He", "Kevin Gimpel", "Jimmy Lin"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Embedding word similarity with neural machine translation", "author": ["Hill et al.2014] Felix Hill", "Kyunghyun Cho", "Sebastien Jean", "Coline Devin", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1412.6448", "citeRegEx": "Hill et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2014}, {"title": "SimLex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Hill et al.2015] Felix Hill", "Roi Reichart", "Anna Korhonen"], "venue": null, "citeRegEx": "Hill et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Learning distributed representations of sentences from unlabelled data", "author": ["Hill et al.2016] Felix Hill", "Kyunghyun Cho", "Anna Korhonen"], "venue": "arXiv preprint arXiv:1602.03483", "citeRegEx": "Hill et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hill et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Hochreiter", "Schmidhuber1997] Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Learning deep structured semantic models for web search using clickthrough data", "author": ["Huang et al.2013] Po-Sen Huang", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Alex Acero", "Larry Heck"], "venue": "In Proceedings of the 22nd ACM international conference on Confer-", "citeRegEx": "Huang et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2013}, {"title": "Deep unordered composition rivals syntactic methods for text classification", "author": ["Iyyer et al.2015] Mohit Iyyer", "Varun Manjunatha", "Jordan Boyd-Graber", "Hal Daum\u00e9 III"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Iyyer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Iyyer et al\\.", "year": 2015}, {"title": "Exploring the limits of language modeling. CoRR, abs/1602.02410", "author": ["Oriol Vinyals", "Mike Schuster", "Noam Shazeer", "Yonghui Wu"], "venue": null, "citeRegEx": "J\u00f3zefowicz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "J\u00f3zefowicz et al\\.", "year": 2016}, {"title": "Character-aware neural language models. CoRR, abs/1508.06615", "author": ["Kim et al.2015] Yoon Kim", "Yacine Jernite", "David Sontag", "Alexander M. Rush"], "venue": null, "citeRegEx": "Kim et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2015}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Kim.,? \\Q2014\\E", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980", "author": ["Kingma", "Ba2014] Diederik Kingma", "Jimmy Ba"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Compositional-ly derived representations of morphologically complex words in distributional semantics", "author": ["Marco Marelli", "Roberto Zamparelli", "Marco Baroni"], "venue": "In Proceedings of the 51st Annual Meeting", "citeRegEx": "Lazaridou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lazaridou et al\\.", "year": 2013}, {"title": "Finding function in form: Compositional character models for open vocabulary word representation", "author": ["Ling et al.2015a] Wang Ling", "Chris Dyer", "Alan W Black", "Isabel Trancoso", "Ramon Fermandez", "Silvio Amir", "Luis Marujo", "Tiago Luis"], "venue": null, "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Characterbased neural machine translation", "author": ["Ling et al.2015b] Wang Ling", "Isabel Trancoso", "Chris Dyer", "Alan W. Black"], "venue": "arXiv preprint arXiv:1511.04586", "citeRegEx": "Ling et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Achieving open vocabulary neural machine translation with hybrid wordcharacter models. arXiv preprint arXiv:1604.00788", "author": ["Luong", "Manning2016] Minh-Thang Luong", "Christopher D. Manning"], "venue": null, "citeRegEx": "Luong et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2016}, {"title": "Better word representations with recursive neural networks for morphology", "author": ["Luong et al.2013] Thang Luong", "Richard Socher", "Christopher Manning"], "venue": "In Proceedings of the Seventeenth Conference on Computational Natural Language", "citeRegEx": "Luong et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2013}, {"title": "SemEval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness", "author": ["Luisa Bentivogli", "Marco Baroni", "Raffaella Bernardi", "Stefano Menini", "Roberto Zamparelli"], "venue": null, "citeRegEx": "Marelli et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Composition in distributional models of semantics", "author": ["Mitchell", "Lapata2010] Jeff Mitchell", "Mirella Lapata"], "venue": "Cognitive Science,", "citeRegEx": "Mitchell et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mitchell et al\\.", "year": 2010}, {"title": "Counter-fitting word vectors to linguistic constraints", "author": ["Mrk\u0161i\u0107 et al.2016] Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Blaise Thomson", "Milica Ga\u0161i\u0107", "Lina Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "TsungHsien Wen", "Steve Young"], "venue": null, "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2016}, {"title": "PPDB 2.0: Better paraphrase ranking, fine-grained entailment relations, word embeddings, and style classification", "author": ["Pushpendre Rastogi", "Juri Ganitkevich", "Benjamin Van Durme", "Chris Callison-Burch"], "venue": null, "citeRegEx": "Pavlick et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pavlick et al\\.", "year": 2015}, {"title": "Glove: Global vectors for word representation", "author": ["Richard Socher", "Christopher D Manning"], "venue": "Proceedings of Empirical Methods in Natural Language Processing (EMNLP", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Co-learning of word representations and morpheme representations", "author": ["Qiu et al.2014] Siyu Qiu", "Qing Cui", "Jiang Bian", "Bin Gao", "Tie-Yan Liu"], "venue": "In Proceedings of COLING", "citeRegEx": "Qiu et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Qiu et al\\.", "year": 2014}, {"title": "Symmetric pattern based word embeddings for improved word similarity prediction", "author": ["Roi Reichart", "Ari Rappoport"], "venue": "In Proceedings of CoNLL", "citeRegEx": "Schwartz et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Schwartz et al\\.", "year": 2015}, {"title": "Dynamic pooling and unfolding recursive autoencoders for paraphrase detection", "author": ["Ng."], "venue": "Advances in Neural Information Processing Systems.", "citeRegEx": "Ng.,? 2011", "shortCiteRegEx": "Ng.", "year": 2011}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Ng", "Christopher Potts"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Unsupervised morphology induction using word embeddings", "author": ["Soricut", "Och2015] Radu Soricut", "Franz Och"], "venue": "In Proc. NAACL", "citeRegEx": "Soricut et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Soricut et al\\.", "year": 2015}, {"title": "Letter n-gram-based input encoding for continuous space language models", "author": ["Sperr et al.2013] Henning Sperr", "Jan Niehues", "Alex Waibel"], "venue": "In Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality,", "citeRegEx": "Sperr et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sperr et al\\.", "year": 2013}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2014}, {"title": "Generating text with recurrent neural networks", "author": ["James Martens", "Geoffrey E Hinton"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "Sutskever et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2011}, {"title": "Improved semantic representations from tree-structured long short-term memory networks. arXiv preprint arXiv:1503.00075", "author": ["Tai et al.2015] Kai Sheng Tai", "Richard Socher", "Christopher D Manning"], "venue": null, "citeRegEx": "Tai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tai et al\\.", "year": 2015}, {"title": "From paraphrase database to compositional paraphrase model and back. Transactions of the ACL (TACL)", "author": ["Wieting et al.2015] John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu", "Dan Roth"], "venue": null, "citeRegEx": "Wieting et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}, {"title": "Towards universal paraphrastic sentence embeddings", "author": ["Wieting et al.2016] John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu"], "venue": "In Proceedings of International Conference on Learning Representations", "citeRegEx": "Wieting et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wieting et al\\.", "year": 2016}, {"title": "SemEval-2015 task 1: Paraphrase and semantic similarity in Twitter (PIT)", "author": ["Xu et al.2015] Wei Xu", "Chris Callison-Burch", "William B Dolan"], "venue": "In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval)", "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Character-level convolutional networks for text classification", "author": ["Zhang et al.2015] Xiang Zhang", "Junbo Zhao", "Yann LeCun"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 27, "context": "model compositionality in word sequences, ranging from simple averaging (Mitchell and Lapata, 2010; Iyyer et al., 2015) to functions with rich recursive structure (Socher et al.", "startOffset": 72, "endOffset": 119}, {"referenceID": 50, "context": ", 2015) to functions with rich recursive structure (Socher et al., 2011; Tai et al., 2015; Bowman et al., 2016).", "startOffset": 51, "endOffset": 111}, {"referenceID": 8, "context": ", 2015) to functions with rich recursive structure (Socher et al., 2011; Tai et al., 2015; Bowman et al., 2016).", "startOffset": 51, "endOffset": 111}, {"referenceID": 50, "context": "learning them specifically for the task of interest (Tai et al., 2015; He et al., 2015).", "startOffset": 52, "endOffset": 87}, {"referenceID": 21, "context": "learning them specifically for the task of interest (Tai et al., 2015; He et al., 2015).", "startOffset": 52, "endOffset": 87}, {"referenceID": 29, "context": "Examples include recurrent neural networks (RNNs) and convolutional neural networks (CNNs) on character sequences, showing improvements for several NLP tasks (Ling et al., 2015a; Kim et al., 2015; Ballesteros et al., 2015; dos Santos and Guimar\u00e3es, 2015).", "startOffset": 158, "endOffset": 254}, {"referenceID": 4, "context": "Examples include recurrent neural networks (RNNs) and convolutional neural networks (CNNs) on character sequences, showing improvements for several NLP tasks (Ling et al., 2015a; Kim et al., 2015; Ballesteros et al., 2015; dos Santos and Guimar\u00e3es, 2015).", "startOffset": 158, "endOffset": 254}, {"referenceID": 26, "context": "We represent a character sequence by a vector containing counts of character n-grams, inspired by Huang et al. (2013). This vector is embedded into a low-dimensional space using a single nonlinear transformation.", "startOffset": 98, "endOffset": 118}, {"referenceID": 23, "context": "achieving state-of-the-art performance on SimLex999 (Hill et al., 2015).", "startOffset": 52, "endOffset": 71}, {"referenceID": 22, "context": "achieving state-of-the-art performance on SimLex999 (Hill et al., 2015). When evaluated on a large suite of sentence-level semantic textual similarity tasks, CHARAGRAM embeddings again outperform the RNN and CNN architectures as well as the PARAGRAM-PHRASE embeddings of Wieting et al. (2016). We also consider English part-of-speech (POS) tagging using the bidirectional long short-term memory tagger of Ling et al.", "startOffset": 53, "endOffset": 293}, {"referenceID": 22, "context": "achieving state-of-the-art performance on SimLex999 (Hill et al., 2015). When evaluated on a large suite of sentence-level semantic textual similarity tasks, CHARAGRAM embeddings again outperform the RNN and CNN architectures as well as the PARAGRAM-PHRASE embeddings of Wieting et al. (2016). We also consider English part-of-speech (POS) tagging using the bidirectional long short-term memory tagger of Ling et al. (2015a). The three architectures reach", "startOffset": 53, "endOffset": 425}, {"referenceID": 32, "context": "subword embeddings (Lazaridou et al., 2013; Botha and Blunsom, 2014; Qiu et al., 2014; Chen et al., 2015).", "startOffset": 19, "endOffset": 105}, {"referenceID": 42, "context": "subword embeddings (Lazaridou et al., 2013; Botha and Blunsom, 2014; Qiu et al., 2014; Chen et al., 2015).", "startOffset": 19, "endOffset": 105}, {"referenceID": 9, "context": "subword embeddings (Lazaridou et al., 2013; Botha and Blunsom, 2014; Qiu et al., 2014; Chen et al., 2015).", "startOffset": 19, "endOffset": 105}, {"referenceID": 35, "context": "Luong et al. (2013) used recursive models to compose morphs into word", "startOffset": 0, "endOffset": 20}, {"referenceID": 10, "context": ", 2015b; Luong and Manning, 2016), or for generating entire translations character-bycharacter (Chung et al., 2016).", "startOffset": 95, "endOffset": 115}, {"referenceID": 31, "context": "Ling et al. (2015a) used a bidirectional long short-term memory (LSTM) RNN on characters to embed arbitrary word types, showing strong performance for language modeling and POS tagging.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "Ballesteros et al. (2015) used this model to represent words for dependency parsing.", "startOffset": 0, "endOffset": 26}, {"referenceID": 15, "context": "Others trained character-level RNN language models to provide features for NLP tasks, including tokenization and segmentation (Chrupa\u0142a, 2013; Evang et al., 2013), and text normalization (Chrupa\u0142a, 2014).", "startOffset": 126, "endOffset": 162}, {"referenceID": 19, "context": "(2011) and Graves (2013) used character-level RNNs for language modeling.", "startOffset": 11, "endOffset": 25}, {"referenceID": 29, "context": "CNNs with character n-gram filters have been used to embed arbitrary word types for several tasks, including language modeling (Kim et al., 2015), part-of-speech tagging (dos Santos and Zadrozny, 2014), named entity recognition (dos Santos and Guimar\u00e3es, 2015), text classification (Zhang et al.", "startOffset": 127, "endOffset": 145}, {"referenceID": 54, "context": ", 2015), part-of-speech tagging (dos Santos and Zadrozny, 2014), named entity recognition (dos Santos and Guimar\u00e3es, 2015), text classification (Zhang et al., 2015), and machine translation (Costa-Juss\u00e0 and Fonollosa, 2016).", "startOffset": 144, "endOffset": 164}, {"referenceID": 28, "context": "Combinations of CNNs and RNNs on characters have also been explored (J\u00f3zefowicz et al., 2016).", "startOffset": 68, "endOffset": 93}, {"referenceID": 26, "context": "Most closely-related to our approach is the DSSM (instantiated variously as \u201cdeep semantic similarity model\u201d or \u201cdeep structured semantic model\u201d) developed by Huang et al. (2013). For an information retrieval task, they represented words using feature vectors containing counts of character ngrams.", "startOffset": 159, "endOffset": 179}, {"referenceID": 26, "context": "Most closely-related to our approach is the DSSM (instantiated variously as \u201cdeep semantic similarity model\u201d or \u201cdeep structured semantic model\u201d) developed by Huang et al. (2013). For an information retrieval task, they represented words using feature vectors containing counts of character ngrams. Sperr et al. (2013) used a very similar technique to represent words in neural language models for machine translation.", "startOffset": 159, "endOffset": 319}, {"referenceID": 31, "context": "both words and sentences, outperforming character LSTMs like those used by Ling et al. (2015a) and character CNNs like those from Kim et al.", "startOffset": 75, "endOffset": 95}, {"referenceID": 29, "context": "(2015a) and character CNNs like those from Kim et al. (2015).", "startOffset": 43, "endOffset": 61}, {"referenceID": 26, "context": "This model is based on the letter n-gram hashing technique developed by Huang et al. (2013) for their DSSM approach.", "startOffset": 72, "endOffset": 92}, {"referenceID": 19, "context": "First we consider LSTM architectures (Hochreiter and Schmidhuber, 1997) over the character sequence x, using the version from Gers et al. (2003). We use a forward LSTM over the characters in x, then take the final LSTM hidden", "startOffset": 126, "endOffset": 145}, {"referenceID": 30, "context": "\u201d We use the architecture from Kim (2014) with a single convolutional layer followed by an optional fully-connected layer.", "startOffset": 31, "endOffset": 42}, {"referenceID": 29, "context": "which is identical to that used by Kim et al. (2015). Each filter operates over the entire sequence of character n-grams in x and we use max pooling for each filter.", "startOffset": 35, "endOffset": 53}, {"referenceID": 33, "context": "2) is a classification task, and follows the setup of the English part-of-speech tagging experiment from Ling et al. (2015a).", "startOffset": 105, "endOffset": 125}, {"referenceID": 18, "context": "We train on noisy paraphrase pairs from the Paraphrase Database (PPDB; Ganitkevitch et al., 2013) with an L2 regularized contrastive loss objective function, following the training procedure of Wieting et al.", "startOffset": 64, "endOffset": 97}, {"referenceID": 18, "context": "We train on noisy paraphrase pairs from the Paraphrase Database (PPDB; Ganitkevitch et al., 2013) with an L2 regularized contrastive loss objective function, following the training procedure of Wieting et al. (2015) and Wieting et al.", "startOffset": 71, "endOffset": 216}, {"referenceID": 18, "context": "We train on noisy paraphrase pairs from the Paraphrase Database (PPDB; Ganitkevitch et al., 2013) with an L2 regularized contrastive loss objective function, following the training procedure of Wieting et al. (2015) and Wieting et al. (2016). Key details are provided here, but see Appendix A for a", "startOffset": 71, "endOffset": 242}, {"referenceID": 17, "context": "For word similarity, we focus on two of the most commonly used datasets for evaluating semantic similarity of word embeddings: WordSim-353 (WS353) (Finkelstein et al., 2001) and SimLex-999", "startOffset": 147, "endOffset": 173}, {"referenceID": 23, "context": "(SL999) (Hill et al., 2015).", "startOffset": 8, "endOffset": 27}, {"referenceID": 36, "context": "We also evaluate our best model on the Stanford Rare Word Similarity Dataset (Luong et al., 2013).", "startOffset": 77, "endOffset": 97}, {"referenceID": 53, "context": "task (Xu et al., 2015) and the SemEval 2014 SICK Semantic Relatedness task (Marelli et al.", "startOffset": 5, "endOffset": 22}, {"referenceID": 37, "context": ", 2015) and the SemEval 2014 SICK Semantic Relatedness task (Marelli et al., 2014).", "startOffset": 60, "endOffset": 82}, {"referenceID": 0, "context": "Further details are provided in the official task descriptions (Agirre et al., 2012; Agirre et al., 2013; Agirre et al., 2014; Agirre et al., 2015).", "startOffset": 63, "endOffset": 147}, {"referenceID": 1, "context": "Further details are provided in the official task descriptions (Agirre et al., 2012; Agirre et al., 2013; Agirre et al., 2014; Agirre et al., 2015).", "startOffset": 63, "endOffset": 147}, {"referenceID": 2, "context": "Further details are provided in the official task descriptions (Agirre et al., 2012; Agirre et al., 2013; Agirre et al., 2014; Agirre et al., 2015).", "startOffset": 63, "endOffset": 147}, {"referenceID": 48, "context": "We also experimented with using dropout (Srivastava et al., 2014) on the inputs of the last layer of the charCNN model in place of L2 regularization, as well as removing the last feedforward layer.", "startOffset": 40, "endOffset": 65}, {"referenceID": 29, "context": "For charCNN, we experimented with two filter sets: one uses 175 filters for each n-gram size \u2208 {2, 3, 4}, and the other uses the set of filters from Kim et al. (2015), consisting of 25 filters of size 1, 50 of size 2, 75 of size 3, 100 of size 4, 125 of size 5, and 150 of size 6.", "startOffset": 149, "endOffset": 167}, {"referenceID": 22, "context": "Model SL999 Hill et al. (2014) 52 Schwartz et al.", "startOffset": 12, "endOffset": 31}, {"referenceID": 22, "context": "Model SL999 Hill et al. (2014) 52 Schwartz et al. (2015) 56 Faruqui and Dyer (2015) 58 Wieting et al.", "startOffset": 12, "endOffset": 57}, {"referenceID": 22, "context": "Model SL999 Hill et al. (2014) 52 Schwartz et al. (2015) 56 Faruqui and Dyer (2015) 58 Wieting et al.", "startOffset": 12, "endOffset": 84}, {"referenceID": 22, "context": "Model SL999 Hill et al. (2014) 52 Schwartz et al. (2015) 56 Faruqui and Dyer (2015) 58 Wieting et al. (2015) 66.", "startOffset": 12, "endOffset": 109}, {"referenceID": 39, "context": "Note that a higher SL999 number is reported in (Mrk\u0161i\u0107 et al., 2016), but the setting is not comparable to ours as they started with embeddings tuned on SL999.", "startOffset": 47, "endOffset": 68}, {"referenceID": 36, "context": "Lastly, we evaluated our model on the Stanford Rare Word Similarity Dataset (Luong et al., 2013), using SL999 for model selection.", "startOffset": 76, "endOffset": 96}, {"referenceID": 35, "context": "Lastly, we evaluated our model on the Stanford Rare Word Similarity Dataset (Luong et al., 2013), using SL999 for model selection. We obtained a Spearman\u2019s \u03c1 of 47.1, which outperforms the 41.8 result from Soricut and Och (2015) and is competitive with the 47.", "startOffset": 77, "endOffset": 229}, {"referenceID": 35, "context": "Lastly, we evaluated our model on the Stanford Rare Word Similarity Dataset (Luong et al., 2013), using SL999 for model selection. We obtained a Spearman\u2019s \u03c1 of 47.1, which outperforms the 41.8 result from Soricut and Och (2015) and is competitive with the 47.8 reported in Pennington et al. (2014), despite only using PPDB", "startOffset": 77, "endOffset": 299}, {"referenceID": 43, "context": "Training and Tuning We did initial training of our models using one pass through PPDB XL, which consists of 3,033,753 unique phrase pairs. Following Wieting et al. (2016), we use the annotated phrase pairs developed by Pavlick et al.", "startOffset": 6, "endOffset": 171}, {"referenceID": 40, "context": "(2016), we use the annotated phrase pairs developed by Pavlick et al. (2015) as our validation set, using Spearman\u2019s \u03c1 to rank the models.", "startOffset": 55, "endOffset": 77}, {"referenceID": 44, "context": "For another baseline, we train the PARAGRAMPHRASE model of Wieting et al. (2016), tuning its regularization strength over {10\u22125, 10\u22126, 10\u22127, 10\u22128}.", "startOffset": 64, "endOffset": 81}, {"referenceID": 5, "context": "This is similar to curriculum learning (Bengio et al., 2009).", "startOffset": 39, "endOffset": 60}, {"referenceID": 44, "context": "We emphasize that there are many other models that could be compared to, such as an LSTM over word embeddings. This and many other models were explored by Wieting et al. (2016). Their PARAGRAM-PHRASE model, which simply learns word embeddings within an averaging composition function, was among their best-performing models.", "startOffset": 106, "endOffset": 177}, {"referenceID": 24, "context": "The FastSent model (Hill et al., 2016) uses the 2014 STS task as part of its evaluation and reports an average Pearson\u2019s r of 61.", "startOffset": 19, "endOffset": 38}, {"referenceID": 33, "context": "We replicate the POS tagging experimental setup of Ling et al. (2015a). Their model uses a bidirectional LSTM over character embeddings to represent words.", "startOffset": 51, "endOffset": 71}, {"referenceID": 44, "context": "We conjecture that slow convergence could be the reason for the inferior performance of LSTMs for similarity tasks as reported by Wieting et al. (2016). Task # n-grams 2 2,3 2,3,4 2,3,4,5 2,3,4,5,6", "startOffset": 135, "endOffset": 152}, {"referenceID": 44, "context": "One of our primary motivations for character-based models is to address the issue of out-of-vocabulary (OOV) words, which were found to be one of the main sources of error for the PARAGRAM-PHRASE model from Wieting et al. (2016). They reported a negative correlation (Pearson\u2019s r of -0.", "startOffset": 212, "endOffset": 229}, {"referenceID": 45, "context": "This contained all words in PPDB-XXL, our evaluations, and in two other datasets: the Stanford Sentiment task (Socher et al., 2013) and the SNLI dataset (Bowman et al.", "startOffset": 110, "endOffset": 131}, {"referenceID": 7, "context": ", 2013) and the SNLI dataset (Bowman et al., 2015), resulting in 93,217 unique (up-to-casing) tokens.", "startOffset": 29, "endOffset": 50}, {"referenceID": 44, "context": "While most prior work has considered machine translation, language modeling, and syntactic analysis, we showed how characterlevel modeling can improve semantic similarity tasks, both quantitatively and with extensive qualitative analysis. We found a consistent trend: the simplest architecture converges fastest to high performance. These results, coupled with those from Wieting et al. (2016), suggest that practitioners should begin with simple architectures rather than moving immediately to RNNs and CNNs.", "startOffset": 60, "endOffset": 394}, {"referenceID": 42, "context": "For word and sentence similarity, we follow the training procedure of Wieting et al. (2015) and Wieting et al.", "startOffset": 54, "endOffset": 92}, {"referenceID": 42, "context": "For word and sentence similarity, we follow the training procedure of Wieting et al. (2015) and Wieting et al. (2016), described below.", "startOffset": 54, "endOffset": 118}, {"referenceID": 33, "context": "For part-ofspeech tagging, we follow the English Penn Treebank training procedure of Ling et al. (2015a).", "startOffset": 85, "endOffset": 105}, {"referenceID": 18, "context": "For the similarity tasks, the training data consists of a set X of phrase pairs \u3008x1, x2\u3009 from the Paraphrase Database (PPDB; Ganitkevitch et al., 2013), where x1 and x2 are assumed to be paraphrases.", "startOffset": 118, "endOffset": 151}], "year": 2016, "abstractText": "We present CHARAGRAM embeddings, a simple approach for learning character-based compositional models to embed textual sequences. A word or sentence is represented using a character n-gram count vector, followed by a single nonlinear transformation to yield a low-dimensional embedding. We use three tasks for evaluation: word similarity, sentence similarity, and part-of-speech tagging. We demonstrate that CHARAGRAM embeddings outperform more complex architectures based on character-level recurrent and convolutional neural networks, achieving new state-of-the-art performance on several similarity tasks.1", "creator": "LaTeX with hyperref package"}}}