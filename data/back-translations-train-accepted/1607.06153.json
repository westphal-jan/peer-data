{"id": "1607.06153", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Jul-2016", "title": "Compositional Sequence Labeling Models for Error Detection in Learner Writing", "abstract": "In this paper, we present the first experiments using neural network models for the task of error detection in learner writing. We perform a systematic comparison of alternative compositional architectures and propose a framework for error detection based on bidirectional LSTMs. Experiments on the CoNLL-14 shared task dataset show the model is able to outperform other participants on detecting errors in learner writing. Finally, the model is integrated with a publicly deployed self-assessment system, leading to performance comparable to human annotators.", "histories": [["v1", "Wed, 20 Jul 2016 23:26:33 GMT  (111kb,D)", "http://arxiv.org/abs/1607.06153v1", "Proceedings of ACL 2016"]], "COMMENTS": "Proceedings of ACL 2016", "reviews": [], "SUBJECTS": "cs.CL cs.NE", "authors": ["marek rei", "helen yannakoudakis"], "accepted": true, "id": "1607.06153"}, "pdf": {"name": "1607.06153.pdf", "metadata": {"source": "CRF", "title": "Compositional Sequence Labeling Models for Error Detection in Learner Writing", "authors": ["Marek Rei", "Helen Yannakoudakis"], "emails": ["marek.rei@cl.cam.ac.uk", "helen.yannakoudakis@cl.cam.ac.uk"], "sections": [{"heading": "1 Introduction", "text": "Most work in recent years has focused on error correction, where error detection performance has been measured as a by-product of correction performance (Ng et al., 2013; Ng et al., 2014). However, this assumes that systems are able to propose a correction for each error detected, and the exact systems for correction may not be optimal for detection. While closed errors such as incorrect prepositions and determinants are modeled using an overarching classification approach, content errors are the 3rd most common error types and pose a serious challenge to error correction (Leacock et al., 2014; Kochmar and Briscoe, 2014). Evaluation of error correction is also very subjective and human."}, {"heading": "2 Background and Related Work", "text": "Most of the work focused on coping with certain types of errors, such as the use of false prepositions (Tetreault and Khodorov, 2008; Khodorov and Briscoe, 2014).However, there was limited work on general error detection systems that could handle all kinds of errors in the learning process. Khodorov and Seneff, 2008) and adjective-noun pairs (Kochmar and Briscoe, 2014).However, there was limited work on the errors in the learning process."}, {"heading": "3 Sequence Labeling Architectures", "text": "The model receives only a set of symbols as input and outputs the probability of each individual symbol in the sentence that is correct or wrong in a given context. Architectures start with the vector representations of single words, [x1,... xT], where it is the length of the sentence that are then used to calculate a hidden vector representation of each token in context, [h1, hT]. These representations are guided through a softmax layer that produces a probability distribution over the possible labels for each token in context: pt = softmax (Woht), where the weight matrix switches between the hidden vector and the output layers. We examine six alternative neural network architectures for the task of error detection: convolutional, bidirectional recursive recursive recursive, bidirectional LM, and multidirectional variant of the respective network architecture."}, {"heading": "4 Experiments", "text": "We evaluate the alternative network structures with respect to the mentioned errors (FCE).The texts have been manually assigned a taxonomy of 77 error types. We use the released sentences to evaluate them."}, {"heading": "5 Results", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "6 Additional Training Data", "text": "There are essentially an infinite number of ways to make mistakes in the text and introduce additional training data that should alleviate some of the problems with data economy. We experimented with the gradual addition of other erroneous corpora to the training and measured the resulting performance, which allows us to provide some context to the results obtained through the use of each set of data and gives us an estimate of how much commented data is required for optimal performance in error detection. The records we are looking at are as follows: \u2022 FCE public - the publicly published subset of FCE (Yannakoudakis et al., 2011) as described in Section 4. \u2022 NUCLE - the NUS corpus of Learner English (Dahlmeier et al., 2013), used as the main training unit of FCE."}, {"heading": "7 CoNLL-14 Shared Task", "text": "In fact, it is such that most people who are able to solve themselves are able to help themselves are able to solve their problems by being able to solve themselves by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems by solving their problems, by solving their problems by solving their problems, by solving their problems by solving their problems, by solving their problems by solving their problems, by solving their problems by solving their problems by solving their problems, by solving their problems by solving their problems, by solving their problems by solving their own, by solving their problems by solving their problems by solving their own, by solving their problems by solving their problems by solving their problems, by solving their problems by solving their problems by solving their own, by solving their problems by solving their problems, by solving their problems by solving their problems by solving their problems, by solving their problems by solving their problems by solving their problems, by solving their problems by solving their own, by solving their problems, by solving their problems by solving their problems, by their problems by solving their problems, by their problems by their problems by their problems by their problems, by their problems, by their problems by their problems, by their problems by their problems, by their problems by their problems, by their problems by their problems, by their problems by their problems, by their problems, by their problems by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their problems, by their"}, {"heading": "8 Essay Scoring", "text": "In this section, we perform an extrinsic evaluation of the effectiveness of the error detection system and examine the extent to which it generalizes to the task of automated scoring of essays at higher levels of granularity. Specifically, we replicate experiments using the text error model described by Andersen et al. (2013), which is currently used in a self-assessment and tutoring system (SAT), an online automated writing tool actively used by language learners. 2The SAT system predicts an overall score for a given text that provides a holistic assessment of linguistic competence and language competence. Authors trained a verified ranking perceptron the FCE public dataset, using features such as error rate estimates from a language model and various lexical and grammatical properties of the text (e.g. word grammes, subgrammes, and phrasing rules)."}, {"heading": "9 Conclusions", "text": "In this paper, we presented the first experiments that used neural network models for the task of error detection when writing to learners. We evaluated six alternative compositional network architectures for context modeling, and based on the results, we propose a novel error detection framework that includes token-level embedding, bidirectional LSTMs for context representation, and a multi-layered architecture for learning more complex characteristics, which allows the model to classify each token as right or wrong, using the full set as context. LSTMs \"self-modulation architecture has also proven beneficial, as it allows the network to learn more advanced composition rules and memorize dependencies over longer distances. Significant performance improvements have been achieved by training the best model on addition datasets, and we found that the greatest benefit was obtained from training on 8 million text tokens of learners with different language skills."}, {"heading": "Acknowledgments", "text": "We would like to thank Prof. Ted Briscoe and the reviewers for their useful feedback."}], "references": [{"title": "Developing and testing a self-assessment and tutoring system", "author": ["\u00d8istein E. Andersen", "Helen Yannakoudakis", "Fiona Barker", "Tim Parish."], "venue": "Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications.", "citeRegEx": "Andersen et al\\.,? 2013", "shortCiteRegEx": "Andersen et al\\.", "year": 2013}, {"title": "Neural Machine Translation by Jointly Learning to Align and Translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "International Conference on Learning Representations.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "A Neural Probabilistic Language Model Yoshua", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Janvin."], "venue": "Journal of Machine Learning Research, 3.", "citeRegEx": "Bengio et al\\.,? 2003", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "How Far are We from Fully Automatic High Quality Grammatical Error Correction", "author": ["Christopher Bryant", "Hwee Tou Ng"], "venue": null, "citeRegEx": "Bryant and Ng.,? \\Q2015\\E", "shortCiteRegEx": "Bryant and Ng.", "year": 2015}, {"title": "One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling", "author": ["Ciprian Chelba", "Tom\u00e1\u0161 Mikolov", "Mike Schuster", "Qi Ge", "Thorsten Brants", "Phillipp Koehn", "Tony Robinson."], "venue": "arXiv preprint.", "citeRegEx": "Chelba et al\\.,? 2013", "shortCiteRegEx": "Chelba et al\\.", "year": 2013}, {"title": "On the Properties of Neural Machine Translation: EncoderDecoder Approaches", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Dzmitry Bahdanau", "Yoshua Bengio."], "venue": "Eighth Workshop on Syntax, Semantics and Structure in Statistical Transla-", "citeRegEx": "Cho et al\\.,? 2014a", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Learning Phrase Representations using RNN EncoderDecoder for Statistical Machine Translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "In", "citeRegEx": "Cho et al\\.,? 2014b", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "An unsupervised method for detecting grammatical errors", "author": ["Martin Chodorow", "Claudia Leacock."], "venue": "Proceedings of the first conference on North American chapter of the Association for Computational Linguistics.", "citeRegEx": "Chodorow and Leacock.,? 2000", "shortCiteRegEx": "Chodorow and Leacock.", "year": 2000}, {"title": "Detection of grammatical errors involving prepositions", "author": ["Martin Chodorow", "Joel R. Tetreault", "Na-Rae Han."], "venue": "Proceedings of the 4th ACLSIGSEM Workshop on Prepositions.", "citeRegEx": "Chodorow et al\\.,? 2007", "shortCiteRegEx": "Chodorow et al\\.", "year": 2007}, {"title": "Problems in evaluating grammatical error detection systems", "author": ["Martin Chodorow", "Markus Dickinson", "Ross Israel", "Joel Tetreault."], "venue": "COLING 2012.", "citeRegEx": "Chodorow et al\\.,? 2012", "shortCiteRegEx": "Chodorow et al\\.", "year": 2012}, {"title": "Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition", "author": ["George. E. Dahl", "Dong Yu", "Li Deng", "Alex Acero."], "venue": "IEEE Transactions on Audio, Speech, and Language Processing, 20.", "citeRegEx": "Dahl et al\\.,? 2012", "shortCiteRegEx": "Dahl et al\\.", "year": 2012}, {"title": "Building a large annotated corpus of learner English: The NUS corpus of learner English", "author": ["Daniel Dahlmeier", "Hwee Tou Ng", "Siew Mei Wu."], "venue": "Proceedings of the Eighth Workshop on Innovative Use of NLP for Building Educational Applications.", "citeRegEx": "Dahlmeier et al\\.,? 2013", "shortCiteRegEx": "Dahlmeier et al\\.", "year": 2013}, {"title": "Helping Our Own: The HOO 2011 Pilot Shared Task", "author": ["Robert Dale", "Adam Kilgarriff."], "venue": "Proceedings of the 13th European Workshop on Natural Language Generation.", "citeRegEx": "Dale and Kilgarriff.,? 2011", "shortCiteRegEx": "Dale and Kilgarriff.", "year": 2011}, {"title": "HOO 2012: A report on the Preposition and Determiner Error Correction Shared Task", "author": ["Robert Dale", "Ilya Anisimoff", "George Narroway."], "venue": "The Seventh Workshop on Building Educational Applications Using NLP.", "citeRegEx": "Dale et al\\.,? 2012", "shortCiteRegEx": "Dale et al\\.", "year": 2012}, {"title": "Finding structure in time", "author": ["Jeffrey L. Elman."], "venue": "Cognitive science, 14(2).", "citeRegEx": "Elman.,? 1990", "shortCiteRegEx": "Elman.", "year": 1990}, {"title": "Towards a standard evaluation method for grammatical error detection and correction", "author": ["Mariano Felice", "Ted Briscoe."], "venue": "The 2015 Annual Conference of the North American Chapter of the ACL.", "citeRegEx": "Felice and Briscoe.,? 2015", "shortCiteRegEx": "Felice and Briscoe.", "year": 2015}, {"title": "Grammatical error correction using hybrid systems and type filtering", "author": ["Mariano Felice", "Zheng Yuan", "\u00d8istein E. Andersen", "Helen Yannakoudakis", "Ekaterina Kochmar."], "venue": "Conference on Computational Natural Language Learning: Shared Task (CoNLL-", "citeRegEx": "Felice et al\\.,? 2014", "shortCiteRegEx": "Felice et al\\.", "year": 2014}, {"title": "High-Order Sequence Modeling for Language Learner Error Detection", "author": ["Michael Gamon."], "venue": "Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications.", "citeRegEx": "Gamon.,? 2011", "shortCiteRegEx": "Gamon.", "year": 2011}, {"title": "Hybrid speech recognition with Deep Bidirectional LSTM", "author": ["Alex Graves", "Navdeep Jaitly", "Abdel Rahman Mohamed."], "venue": "IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU 2013).", "citeRegEx": "Graves et al\\.,? 2013", "shortCiteRegEx": "Graves et al\\.", "year": 2013}, {"title": "Detecting Errors in English Article Usage with a Maximum Entropy Classifier Trained on a Large, Diverse Corpus", "author": ["Na-Rae Han", "Martin Chodorow", "Claudia Leacock."], "venue": "Proceedings of the 4th International Conference on Language Resources and", "citeRegEx": "Han et al\\.,? 2004", "shortCiteRegEx": "Han et al\\.", "year": 2004}, {"title": "Detecting errors in English article usage by non-native speakers", "author": ["Na-Rae Han", "Martin Chodorow", "Claudia Leacock."], "venue": "Natural Language Engineering, 12.", "citeRegEx": "Han et al\\.,? 2006", "shortCiteRegEx": "Han et al\\.", "year": 2006}, {"title": "Long Short-term Memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Computation, 9.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Opinion Mining with Deep Recurrent Neural Networks", "author": ["Ozan Irsoy", "Claire Cardie."], "venue": "EMNLP2014.", "citeRegEx": "Irsoy and Cardie.,? 2014", "shortCiteRegEx": "Irsoy and Cardie.", "year": 2014}, {"title": "The AMU System in the CoNLL-2014 Shared Task: Grammatical Error Correction by Data-Intensive and Feature-Rich Statistical Machine Translation", "author": ["Marcin Junczys-Dowmunt", "Roman Grundkiewicz."], "venue": "Proceedings of the Eighteenth Confer-", "citeRegEx": "Junczys.Dowmunt and Grundkiewicz.,? 2014", "shortCiteRegEx": "Junczys.Dowmunt and Grundkiewicz.", "year": 2014}, {"title": "Recurrent Continuous Translation Models", "author": ["Nal Kalchbrenner", "Phil Blunsom."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013).", "citeRegEx": "Kalchbrenner and Blunsom.,? 2013", "shortCiteRegEx": "Kalchbrenner and Blunsom.", "year": 2013}, {"title": "Adam: a Method for Stochastic Optimization", "author": ["Diederik P. Kingma", "Jimmy Lei Ba."], "venue": "International Conference on Learning Representations.", "citeRegEx": "Kingma and Ba.,? 2015", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Detecting Learner Errors in the Choice of Content Words Using Compositional Distributional Semantics", "author": ["Ekaterina Kochmar", "Ted Briscoe."], "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguis-", "citeRegEx": "Kochmar and Briscoe.,? 2014", "shortCiteRegEx": "Kochmar and Briscoe.", "year": 2014}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando Pereira."], "venue": "Proceedings of the 18th International Conference on Machine Learning. Citeseer.", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Automated Grammatical Error Detection for Language Learners: Second Edition", "author": ["Claudia Leacock", "Martin Chodorow", "Michael Gamon", "Joel R. Tetreault"], "venue": null, "citeRegEx": "Leacock et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Leacock et al\\.", "year": 2014}, {"title": "Correcting misuse of verb forms", "author": ["John Lee", "Stephanie Seneff."], "venue": "Proceedings of the 46th Annual Meeting of the ACL.", "citeRegEx": "Lee and Seneff.,? 2008", "shortCiteRegEx": "Lee and Seneff.", "year": 2008}, {"title": "Effective Approaches to Attentionbased Neural Machine Translation", "author": ["Mnih-Thang Luong", "Hieu Pham", "Christopher D. Manning."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Luong et al\\.,? 2015", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "RNNLM-Recurrent neural network language modeling toolkit", "author": ["Tom\u00e1\u0161 Mikolov", "Stefan Kombrink", "Anoop Deoras", "Luk\u00e1\u0161 Burget", "Jan \u010cernock\u00fd."], "venue": "ASRU 2011 Demo Session.", "citeRegEx": "Mikolov et al\\.,? 2011", "shortCiteRegEx": "Mikolov et al\\.", "year": 2011}, {"title": "Efficient Estimation of Word Representations in Vector Space", "author": ["Tom\u00e1\u0161 Mikolov", "Greg Corrado", "Kai Chen", "Jeffrey Dean."], "venue": "Proceedings of the International Conference on Learning Representations (ICLR 2013).", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Evaluating performance of grammatical error detection to maximize learning effect", "author": ["Ryo Nagata", "Kazuhide Nakatani."], "venue": "Coling 2010: Poster Volume.", "citeRegEx": "Nagata and Nakatani.,? 2010", "shortCiteRegEx": "Nagata and Nakatani.", "year": 2010}, {"title": "The CoNLL-2013 Shared Task on Grammatical Error Correction", "author": ["Hwee Tou Ng", "Yuanbin Wu", "Christian Hadiwinoto."], "venue": "Computational Natural Language Learning (CoNLL), Shared Task.", "citeRegEx": "Ng et al\\.,? 2013", "shortCiteRegEx": "Ng et al\\.", "year": 2013}, {"title": "The CoNLL-2014 Shared Task on Grammatical Error Correction", "author": ["Hwee Tou Ng", "Siew Mei Wu", "Ted Briscoe", "Christian Hadiwinoto", "Raymond Hendy Susanto", "Christopher Bryant."], "venue": "Proceedings of the Eighteenth Conference on Computational Natu-", "citeRegEx": "Ng et al\\.,? 2014", "shortCiteRegEx": "Ng et al\\.", "year": 2014}, {"title": "The Cambridge Learner Corpus - error coding and analysis for lexicography and ELT", "author": ["Diane Nicholls."], "venue": "Proceedings of the Corpus Linguistics 2003 Conference.", "citeRegEx": "Nicholls.,? 2003", "shortCiteRegEx": "Nicholls.", "year": 2003}, {"title": "Training Paradigms for Correcting Errors in Grammar and Usage", "author": ["Alla Rozovskaya", "Dan Roth."], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics.", "citeRegEx": "Rozovskaya and Roth.,? 2010", "shortCiteRegEx": "Rozovskaya and Roth.", "year": 2010}, {"title": "University of Illinois System in HOO Text Correction Shared Task", "author": ["Alla Rozovskaya", "Mark Sammons", "Joshua Gioja", "Dan Roth."], "venue": "Proceedings of the 13th European Workshop on Natural Language Generation (ENLG).", "citeRegEx": "Rozovskaya et al\\.,? 2011", "shortCiteRegEx": "Rozovskaya et al\\.", "year": 2011}, {"title": "The University of Illinois System in the CoNLL-2013 Shared Task", "author": ["Alla Rozovskaya", "Kai-Wei Chang", "Mark Sammons", "Dan Roth."], "venue": "Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task.", "citeRegEx": "Rozovskaya et al\\.,? 2013", "shortCiteRegEx": "Rozovskaya et al\\.", "year": 2013}, {"title": "The IllinoisColumbia System in the CoNLL-2014 Shared Task", "author": ["Alla Rozovskaya", "Kai-Wei Chang", "Mark Sammons", "Dan Roth", "Nizar Habash."], "venue": "Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared", "citeRegEx": "Rozovskaya et al\\.,? 2014", "shortCiteRegEx": "Rozovskaya et al\\.", "year": 2014}, {"title": "System Combination for Grammatical Error Correction", "author": ["Raymond Hendy Susanto", "Peter Phandi", "Hwee Tou Ng."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP-2014).", "citeRegEx": "Susanto et al\\.,? 2014", "shortCiteRegEx": "Susanto et al\\.", "year": 2014}, {"title": "The Ups and Downs of Preposition Error Detection in ESL Writing", "author": ["Joel R. Tetreault", "Martin Chodorow."], "venue": "Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008).", "citeRegEx": "Tetreault and Chodorow.,? 2008", "shortCiteRegEx": "Tetreault and Chodorow.", "year": 2008}, {"title": "Semantically Conditioned LSTM-based Natural Language Generation for Spoken Dialogue Systems", "author": ["Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Pei-Hao Su", "David Vandyke", "Steve Young."], "venue": "EMNLP 2015.", "citeRegEx": "Wen et al\\.,? 2015", "shortCiteRegEx": "Wen et al\\.", "year": 2015}, {"title": "A New Dataset and Method for Automatically Grading ESOL Texts", "author": ["Helen Yannakoudakis", "Ted Briscoe", "Ben Medlock."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technolo-", "citeRegEx": "Yannakoudakis et al\\.,? 2011", "shortCiteRegEx": "Yannakoudakis et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 34, "context": "Most work in recent years has focussed on error correction, with error detection performance measured as a byproduct of the correction output (Ng et al., 2013; Ng et al., 2014).", "startOffset": 142, "endOffset": 176}, {"referenceID": 35, "context": "Most work in recent years has focussed on error correction, with error detection performance measured as a byproduct of the correction output (Ng et al., 2013; Ng et al., 2014).", "startOffset": 142, "endOffset": 176}, {"referenceID": 28, "context": "errors such as incorrect prepositions and determiners can be modeled with a supervised classification approach, content-content word errors are the 3rd most frequent error type and pose a serious challenge to error correction frameworks (Leacock et al., 2014; Kochmar and Briscoe, 2014).", "startOffset": 237, "endOffset": 286}, {"referenceID": 26, "context": "errors such as incorrect prepositions and determiners can be modeled with a supervised classification approach, content-content word errors are the 3rd most frequent error type and pose a serious challenge to error correction frameworks (Leacock et al., 2014; Kochmar and Briscoe, 2014).", "startOffset": 237, "endOffset": 286}, {"referenceID": 3, "context": "Evaluation of error correction is also highly subjective and human annotators have rather low agreement on gold-standard corrections (Bryant and Ng, 2015).", "startOffset": 133, "endOffset": 154}, {"referenceID": 10, "context": ", 2003) and speech recognition (Dahl et al., 2012).", "startOffset": 31, "endOffset": 50}, {"referenceID": 6, "context": ", 2014a) or recurrent neural networks (Cho et al., 2014b; Bahdanau et al., 2015).", "startOffset": 38, "endOffset": 80}, {"referenceID": 1, "context": ", 2014a) or recurrent neural networks (Cho et al., 2014b; Bahdanau et al., 2015).", "startOffset": 38, "endOffset": 80}, {"referenceID": 42, "context": "Most work has focussed on tackling specific types of errors, such as usage of incorrect prepositions (Tetreault and Chodorow, 2008; Chodorow et al., 2007), articles (Han et al.", "startOffset": 101, "endOffset": 154}, {"referenceID": 8, "context": "Most work has focussed on tackling specific types of errors, such as usage of incorrect prepositions (Tetreault and Chodorow, 2008; Chodorow et al., 2007), articles (Han et al.", "startOffset": 101, "endOffset": 154}, {"referenceID": 19, "context": ", 2007), articles (Han et al., 2004; Han et al., 2006), verb forms (Lee and Seneff, 2008), and adjective-noun pairs (Kochmar and Briscoe, 2014).", "startOffset": 18, "endOffset": 54}, {"referenceID": 20, "context": ", 2007), articles (Han et al., 2004; Han et al., 2006), verb forms (Lee and Seneff, 2008), and adjective-noun pairs (Kochmar and Briscoe, 2014).", "startOffset": 18, "endOffset": 54}, {"referenceID": 29, "context": ", 2006), verb forms (Lee and Seneff, 2008), and adjective-noun pairs (Kochmar and Briscoe, 2014).", "startOffset": 20, "endOffset": 42}, {"referenceID": 26, "context": ", 2006), verb forms (Lee and Seneff, 2008), and adjective-noun pairs (Kochmar and Briscoe, 2014).", "startOffset": 69, "endOffset": 96}, {"referenceID": 7, "context": "Chodorow and Leacock (2000) proposed a method based on mutual information and the chi-square statistic to detect sequences of part-of-speech tags and func-", "startOffset": 0, "endOffset": 28}, {"referenceID": 17, "context": "Gamon (2011) used Maximum Entropy Markov Models with a range of features, such as POS tags, string features, and outputs from a constituency parser.", "startOffset": 0, "endOffset": 13}, {"referenceID": 12, "context": "Own shared task (Dale and Kilgarriff, 2011) also evaluated grammatical error detection of a number of different error types, though most systems were error-type specific and the best approach was heavily skewed towards article and preposition errors (Rozovskaya et al.", "startOffset": 16, "endOffset": 43}, {"referenceID": 38, "context": "Own shared task (Dale and Kilgarriff, 2011) also evaluated grammatical error detection of a number of different error types, though most systems were error-type specific and the best approach was heavily skewed towards article and preposition errors (Rozovskaya et al., 2011).", "startOffset": 250, "endOffset": 275}, {"referenceID": 12, "context": "past years, with four recent shared tasks highlighting several emerging directions (Dale and Kilgarriff, 2011; Dale et al., 2012; Ng et al., 2013; Ng et al., 2014).", "startOffset": 83, "endOffset": 163}, {"referenceID": 13, "context": "past years, with four recent shared tasks highlighting several emerging directions (Dale and Kilgarriff, 2011; Dale et al., 2012; Ng et al., 2013; Ng et al., 2014).", "startOffset": 83, "endOffset": 163}, {"referenceID": 34, "context": "past years, with four recent shared tasks highlighting several emerging directions (Dale and Kilgarriff, 2011; Dale et al., 2012; Ng et al., 2013; Ng et al., 2014).", "startOffset": 83, "endOffset": 163}, {"referenceID": 35, "context": "past years, with four recent shared tasks highlighting several emerging directions (Dale and Kilgarriff, 2011; Dale et al., 2012; Ng et al., 2013; Ng et al., 2014).", "startOffset": 83, "endOffset": 163}, {"referenceID": 16, "context": "techniques, essentially translating the incorrect source text into the corrected version (Felice et al., 2014; Junczys-Dowmunt and Grundkiewicz, 2014)", "startOffset": 89, "endOffset": 150}, {"referenceID": 23, "context": "techniques, essentially translating the incorrect source text into the corrected version (Felice et al., 2014; Junczys-Dowmunt and Grundkiewicz, 2014)", "startOffset": 89, "endOffset": 150}, {"referenceID": 40, "context": "Averaged Perceptrons and Naive Bayes classifiers making use of native-language error correction priors (Rozovskaya et al., 2014; Rozovskaya et al., 2013).", "startOffset": 103, "endOffset": 153}, {"referenceID": 39, "context": "Averaged Perceptrons and Naive Bayes classifiers making use of native-language error correction priors (Rozovskaya et al., 2014; Rozovskaya et al., 2013).", "startOffset": 103, "endOffset": 153}, {"referenceID": 14, "context": "This recurrent network structure is referred to as an Elman-type network, after Elman (1990). The bidirectional RNN (Figure 1c) consists of two recurrent components, moving in opposite directions through the sentence.", "startOffset": 54, "endOffset": 93}, {"referenceID": 31, "context": "Recurrent networks have been shown to perform well on the task of language modeling (Mikolov et al., 2011; Chelba et al., 2013), where", "startOffset": 84, "endOffset": 127}, {"referenceID": 4, "context": "Recurrent networks have been shown to perform well on the task of language modeling (Mikolov et al., 2011; Chelba et al., 2013), where", "startOffset": 84, "endOffset": 127}, {"referenceID": 21, "context": "The long-short term memory (LSTM) (Hochreiter and Schmidhuber, 1997) is an advanced alternative to the Elman-type networks that has recently become increasingly popular.", "startOffset": 34, "endOffset": 68}, {"referenceID": 20, "context": "Irsoy and Cardie (2014) created an extension of this architecture by connecting together multiple layers of bidirectional Elman-type recurrent network modules.", "startOffset": 0, "endOffset": 24}, {"referenceID": 18, "context": "LSTMs have been successfully applied to various tasks, such as speech recognition (Graves et al., 2013), machine translation (Luong et al.", "startOffset": 82, "endOffset": 103}, {"referenceID": 30, "context": ", 2013), machine translation (Luong et al., 2015), and natural language generation (Wen et al.", "startOffset": 29, "endOffset": 49}, {"referenceID": 43, "context": ", 2015), and natural language generation (Wen et al., 2015).", "startOffset": 41, "endOffset": 59}, {"referenceID": 27, "context": "For comparison with non-neural models, we also report results using CRFs (Lafferty et al., 2001), which are a popular choice for sequence labeling tasks.", "startOffset": 73, "endOffset": 96}, {"referenceID": 44, "context": "We evaluate the alternative network structures on the publicly released First Certificate in English dataset (FCE-public, Yannakoudakis et al. (2011)).", "startOffset": 122, "endOffset": 150}, {"referenceID": 35, "context": "5, which was also the measure adopted in the CoNLL-14 shared task on error correction (Ng et al., 2014).", "startOffset": 86, "endOffset": 103}, {"referenceID": 33, "context": "It combines both precision and recall, while assigning twice as much weight to precision, since accurate feedback is often more important than coverage in error detection applications (Nagata and Nakatani, 2010).", "startOffset": 184, "endOffset": 211}, {"referenceID": 35, "context": "Related evaluation measures, such as the M2-scorer (Ng et al., 2014) and the I-measure (Felice and", "startOffset": 51, "endOffset": 68}, {"referenceID": 8, "context": "Following Chodorow et al. (2012), we also report raw counts for predicted and correct tokens.", "startOffset": 10, "endOffset": 33}, {"referenceID": 32, "context": "300 and initialised using the publicly released pretrained Word2Vec vectors (Mikolov et al., 2013).", "startOffset": 76, "endOffset": 98}, {"referenceID": 25, "context": "001, the ADAM algorithm (Kingma and Ba, 2015) for dynamically adapting the learning rate, and batch size of 64 sentences.", "startOffset": 24, "endOffset": 45}, {"referenceID": 44, "context": "\u2022 FCE-public \u2013 the publicly released subset of FCE (Yannakoudakis et al., 2011), as described in Section 4.", "startOffset": 51, "endOffset": 79}, {"referenceID": 11, "context": "\u2022 NUCLE \u2013 the NUS Corpus of Learner English (Dahlmeier et al., 2013), used as the main training set for CoNLL shared tasks on error correction.", "startOffset": 44, "endOffset": 68}, {"referenceID": 36, "context": "\u2022 IELTS \u2013 a subset of the IELTS examination dataset extracted from the Cambridge Learner Corpus (CLC, Nicholls (2003)), containing 68,505 sentences from all proficiency", "startOffset": 102, "endOffset": 118}, {"referenceID": 16, "context": "levels, also used by Felice et al. (2014).", "startOffset": 21, "endOffset": 42}, {"referenceID": 35, "context": "The CoNLL-14 shared task (Ng et al., 2014) focussed on automatically correcting errors in learner writing.", "startOffset": 25, "endOffset": 42}, {"referenceID": 3, "context": "It has been shown before that correcting grammatical errors is highly subjective (Bryant and Ng, 2015), but these results indicate that trained annotators can disagree even on the number and location of errors.", "startOffset": 81, "endOffset": 102}, {"referenceID": 16, "context": "CAMB (Felice et al., 2014), CUUI (Rozovskaya et al.", "startOffset": 5, "endOffset": 26}, {"referenceID": 40, "context": ", 2014), CUUI (Rozovskaya et al., 2014), and AMU (Junczys-Dowmunt and Grundkiewicz, 2014).", "startOffset": 14, "endOffset": 39}, {"referenceID": 23, "context": ", 2014), and AMU (Junczys-Dowmunt and Grundkiewicz, 2014).", "startOffset": 17, "endOffset": 57}, {"referenceID": 41, "context": "After the official shared task, Susanto et al. (2014) published a system which combines several alternative models and outperforms the shared task participants when evaluated on error correction.", "startOffset": 32, "endOffset": 54}, {"referenceID": 0, "context": "More specifically, we replicate experiments using the text-level model described by Andersen et al. (2013), which is currently deployed in a self-assessment and tutoring system (SAT), an online automated writing feedback tool actively used by language learners.", "startOffset": 84, "endOffset": 107}, {"referenceID": 37, "context": ", Rozovskaya and Roth (2010)).", "startOffset": 2, "endOffset": 29}], "year": 2016, "abstractText": "In this paper, we present the first experiments using neural network models for the task of error detection in learner writing. We perform a systematic comparison of alternative compositional architectures and propose a framework for error detection based on bidirectional LSTMs. Experiments on the CoNLL-14 shared task dataset show the model is able to outperform other participants on detecting errors in learner writing. Finally, the model is integrated with a publicly deployed self-assessment system, leading to performance comparable to human annotators.", "creator": "TeX"}}}