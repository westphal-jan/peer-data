{"id": "1608.00869", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Aug-2016", "title": "SimVerb-3500: A Large-Scale Evaluation Set of Verb Similarity", "abstract": "Verbs play a critical role in the meaning of sentences, but these ubiquitous words have received little attention in recent distributional semantics research. We introduce SimVerb-3500, an evaluation resource that provides human ratings for the similarity of 3,500 verb pairs. SimVerb-3500 covers all normed verb types from the USF free-association database, providing at least three examples for every VerbNet class. This broad coverage facilitates detailed analyses of how syntactic and semantic phenomena together influence human understanding of verb meaning. Further, with significantly larger development and test sets than existing benchmarks, SimVerb-3500 enables more robust evaluation of representation learning architectures and promotes the development of methods tailored to verbs. We hope that SimVerb-3500 will enable a richer understanding of the diversity and complexity of verb semantics and guide the development of systems that can effectively represent and interpret this meaning.", "histories": [["v1", "Tue, 2 Aug 2016 15:35:12 GMT  (101kb,D)", "http://arxiv.org/abs/1608.00869v1", "EMNLP 2016"], ["v2", "Wed, 3 Aug 2016 15:39:53 GMT  (104kb,D)", "http://arxiv.org/abs/1608.00869v2", "EMNLP 2016"], ["v3", "Tue, 9 Aug 2016 06:20:24 GMT  (382kb,D)", "http://arxiv.org/abs/1608.00869v3", "EMNLP 2016"], ["v4", "Tue, 20 Sep 2016 14:35:14 GMT  (378kb,D)", "http://arxiv.org/abs/1608.00869v4", "EMNLP 2016"]], "COMMENTS": "EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["daniela gerz", "ivan vulic", "felix hill", "roi reichart", "anna korhonen"], "accepted": true, "id": "1608.00869"}, "pdf": {"name": "1608.00869.pdf", "metadata": {"source": "CRF", "title": "SimVerb-3500: A Large-Scale Evaluation Set of Verb Similarity", "authors": ["Daniela Gerz", "Ivan Vuli\u0107", "Felix Hill", "Roi Reichart", "Anna Korhonen"], "emails": [], "sections": [{"heading": "1 Introduction", "text": "Verbs are known to be both complex and variable, expressing the semantics of an event as well as the relational information between the participants in that event, and displaying a rich palette of syntactic and semantic behaviors (Jackendoff, 1972; Gruber, 1976; Levin, 1993). Verbs play a key role at almost every level of linguistic analysis. Information about their predicatist argumentation structure can favor many NLP tasks (e.g. parses, semantic role identification, information gathering) and applications (e.g. machine translation, text mining), as well as research on the acquisition and processing of human language (Korhonen, 2010). Precise methods for the representation and understanding of verb semantics will undoubtedly be necessary to interpret the meaning of sentences with similar accuracy, word processing). Numerous algorithms for the acquisition of word representations from text and / or structured knowledge have been developed in recent years (Micoloet)."}, {"heading": "2 Related Work", "text": "One natural way to evaluate the quality of representation is to assess the similarity of representations associated with similar words. Currently, the most popular assessment sets consist of pairs of words with similarity ratings created by human commentators.1 Nevertheless, we note that all available data sets of this kind are insufficient to assess the similarity of verbs due to their small size or narrow coverage of verbs.1 However, in some existing assessment sets, pairs are rated for their similarity, some of which overlap with similarities. SimVerb-3500 focuses on similarity because it is a more focused semantic relationship that appears to achieve greater agreement between human commentators. For a broader discussion see (Hill et al., 2015). Literature. Representative examples include RG-65 (Rubenstein and Goodenough, 1965) and WordSimme53 (Finkelstein et al al.)."}, {"heading": "3 The SimVerb-3500 Data Set", "text": "In this section, we will discuss the design principles behind SimVerb-3500. First, we will show that a new evaluation resource is needed for the similarity of verbs. Then, we will describe how the final pairs of verbs were selected with the aim of being representative, i.e. to ensure a broad coverage of two standard semantic resources: USF and VerbNet."}, {"heading": "3.1 Design Motivation", "text": "Hill et al. (2015) argue that comprehensive, high-quality evaluation resources must meet the following three criteria: (C1) Representative (the resource covers the full range of concepts occurring in the natural language); (C2) Clearly defines (it clearly defines the commented relationship, e.g. similarity); (C3) Durable and reliable (untrained native speakers must be able to uniformly quantify the target relationship using simple instructions) Building on the same annotation guidelines as Simlex-999, which explicitly seek similarity, we ensure that the criteria C2 and C3 are met; but even SimLex, as the most comprehensive evaluation resource for verb similarity currently available, is still of limited size, comprising only 222 verb pairs and 170 different verb lemmats in total. As 39 of 101 VerbNet classes are not fully represented in SimLex, while 20 classes have only one verb."}, {"heading": "3.2 Choice of Verb Pairs and Coverage", "text": "In fact, it is as if most of us are able to abide by the rules that they have imposed on themselves. (...) It is as if they were able to outdo themselves. (...) It is as if they were able to outdo themselves. (...) It is as if they were able to outdo themselves. (...) It is as if they were able to outdo themselves. (...) It is as if they were able to outdo themselves. (...) It is as if they are able to outdo themselves. (...) It is as if they are able to outdo themselves. (...) \"(...)\" (...) \"(...\") ((...) \"(...\") ((...) (...) (...) (...) () () ((...) () () (...) () () (() ()) (()) (()) (()) (()) (())) ((())) ((()))) ((())) (()) () () () () () () ()) () () () () ()) () () () () ()) () () () () () ()) () () () () () () ()) () () () () () () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () (() () () () () () (() () () () () () () () (() () () () () () () () (() () () () (() () () () () () () ((() () () (() (() () ()"}, {"heading": "4 Word Pair Scoring", "text": "We use the crowdsourcing platform Prolific Academic (PA), an online marketplace very similar to Amazon Mechanical Turk and CrowdFlower."}, {"heading": "4.1 Survey Structure", "text": "Following the SimLex-999 annotation guidelines, we had rated each of the 3,500 verb pairs by at least 10 annotators. To distribute the workload, we divided the 3,500 pairs into 70 tranches of 79 pairs each. Of the 79 pairs, 50 pairs are unique for one tranche, while 20 pairs are manually selected in all tranches to ensure consistency. The remaining 9 pairs are duplicate pairs that are displayed to the same participant several times to record inconsistent annotations. Participants see 7-8 pairs per page. Pairs are rated on a scale of 0-6 by moving a slider. The first page shows 7 pairs, 5 unique pairs and 2 from the consistency set. The following pages are structured equally, but show an additional pair from the previous page. Participants are explicitly asked to give these duplicate pairs the same rating. We use them as quality control so that we can identify and exclude participants who give multiple inconsistent answers."}, {"heading": "4.2 Post-Processing", "text": "We excluded ratings from commentators who (a) incorrectly answered one of the checkpoint questions (75% of the exclusions); (b) did not give equal ratings to duplicate pairs; (c) exhibited suspicious rating patterns (e.g., randomly alternating between two ratings or using a single rating throughout); and the final acceptance rate was 84%. We then calculated the average of all ratings from the accepted rating agencies (\u2265 10) for each pair, and the value was finally scaled linearly from 0-6 to the 0-10 interval as in (Hill et al., 2015)."}, {"heading": "5 Analysis", "text": "We employ two measurements. IAA-1 (in pairs) calculates the average Spearman correlation between any two raters - a common choice in the previous data collection in distribution semantics (Pad\u00f3 et al., 2007; Reisinger and Mooney, 2010a; Silberer and Lapata, 2014; Hill et al., 2015). A supplementary measurement would smooth out the individual annotator effects (IAA-2), a very good match compared to other benchmarks (see Tab. 2).Vector Space Models We compare the performance of prominent representation models on SimVerb-3500. We include models: (1) unattended models that learn from distribution information in text, including sketch negative models. We compare the performance of prominent representation models on SimVerb-3500."}, {"heading": "6 Evaluating Subsets", "text": "The wide range and magnitude of SimVerb-3500 enables the evaluation of words based on selected criteria. In this section we will show a few sample analyses. Frequency In the first analysis, we select pairs based on their lemma frequency in the BNC corpus, and form three groups, with 390-490 pairs in each group (fig. 1). The results from fig. 1 suggest that the performance of all models improves slightly as the frequency classes increase, with much steeper curves for the pure distribution models (e.g. SGNS and SymPat). The non-distributional, non-data-driven models of Faruqui and Dyer (2015) are only slightly affected by the frequency classes. WordNet synsets Intuitive, representations for verbs with more varied usage patterns are more difficult to learn with statistical models. To investigate this hypothesis, we resort to ordforms, referred to as Net (1995), where different usage patterns are used."}, {"heading": "7 Conclusions", "text": "SimVerb-3500 is a resource for the analysis and evaluation of verbs that will be useful to researchers who understand how humans or machines represent the meaning of verbs, and thus scenes, events, and entire sentences. The size and scope of syntactic-semantic phenomena in SimVerb3500 allows comparing the strengths and weaknesses of different representation models by means of statistically robust analyses of specific word classes. To demonstrate the usefulness of SimVerb-3500, we conducted a selection of analyses with existing models of representation and learning. One clear conclusion is that distribution models trained on raw text (e.g. SGNS) are very poorly targeted at low frequency and highly polysemme verbs. This deterioration in performance can be partially mitigated by focusing on more principled distribution contexts, such as those defined by symmetrical patterns. According to a general study, the results of such analyses, in order to improve the diversity of distributions algorithms, require a few examples in the 2011 spectrum of algorithms."}], "references": [{"title": "A study on similarity and relatedness using distributional and WordNet-based approaches", "author": ["Eneko Agirre", "Enrique Alfonseca", "Keith B. Hall", "Jana Kravalova", "Marius Pasca", "Aitor Soroa."], "venue": "NAACL-HLT, pages 19\u201327.", "citeRegEx": "Agirre et al\\.,? 2009", "shortCiteRegEx": "Agirre et al\\.", "year": 2009}, {"title": "The Berkeley FrameNet project", "author": ["Collin F. Baker", "Charles J. Fillmore", "John B. Lowe."], "venue": "ACLCOLING, pages 86\u201390.", "citeRegEx": "Baker et al\\.,? 1998", "shortCiteRegEx": "Baker et al\\.", "year": 1998}, {"title": "An unsupervised model for instance level subcategorization acquisition", "author": ["Simon Baker", "Roi Reichart", "Anna Korhonen."], "venue": "EMNLP, pages 278\u2013289.", "citeRegEx": "Baker et al\\.,? 2014", "shortCiteRegEx": "Baker et al\\.", "year": 2014}, {"title": "Multimodal distributional semantics", "author": ["Elia Bruni", "Nam-Khanh Tran", "Marco Baroni."], "venue": "Journal of Artificial Intelligence Research, 49:1\u201347.", "citeRegEx": "Bruni et al\\.,? 2014", "shortCiteRegEx": "Bruni et al\\.", "year": 2014}, {"title": "A unified architecture for natural language processing: deep neural networks with multitask learning", "author": ["Ronan Collobert", "Jason Weston."], "venue": "ICML, pages 160\u2013167.", "citeRegEx": "Collobert and Weston.,? 2008", "shortCiteRegEx": "Collobert and Weston.", "year": 2008}, {"title": "Non-distributional word vector representations", "author": ["Manaal Faruqui", "Chris Dyer."], "venue": "ACL, pages 464\u2013469.", "citeRegEx": "Faruqui and Dyer.,? 2015", "shortCiteRegEx": "Faruqui and Dyer.", "year": 2015}, {"title": "Retrofitting word vectors to semantic lexicons", "author": ["Manaal Faruqui", "Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Eduard H. Hovy", "Noah A. Smith."], "venue": "NAACL-HLT, pages 1606\u20131615.", "citeRegEx": "Faruqui et al\\.,? 2015", "shortCiteRegEx": "Faruqui et al\\.", "year": 2015}, {"title": "Problems with evaluation of word embeddings using word similarity tasks", "author": ["Manaal Faruqui", "Yulia Tsvetkov", "Pushpendre Rastogi", "Chris Dyer."], "venue": "CoRR, abs/1605.02276.", "citeRegEx": "Faruqui et al\\.,? 2016", "shortCiteRegEx": "Faruqui et al\\.", "year": 2016}, {"title": "Placing search in context: The concept revisited", "author": ["Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin."], "venue": "ACM Transactions on Information Systems, 20(1):116\u2013 131.", "citeRegEx": "Finkelstein et al\\.,? 2002", "shortCiteRegEx": "Finkelstein et al\\.", "year": 2002}, {"title": "Lexical structure in syntax and semantics", "author": ["Jeffrey Gruber."], "venue": "North-Holland Pub. Co.", "citeRegEx": "Gruber.,? 1976", "shortCiteRegEx": "Gruber.", "year": 1976}, {"title": "SimLex-999: Evaluating semantic models with (genuine) similarity estimation", "author": ["Felix Hill", "Roi Reichart", "Anna Korhonen."], "venue": "Computational Linguistics, 41(4):665\u2013695.", "citeRegEx": "Hill et al\\.,? 2015", "shortCiteRegEx": "Hill et al\\.", "year": 2015}, {"title": "Semantic interpretation in generative grammar", "author": ["Ray S. Jackendoff."], "venue": "MIT Press.", "citeRegEx": "Jackendoff.,? 1972", "shortCiteRegEx": "Jackendoff.", "year": 1972}, {"title": "Putting frequencies in the dictionary", "author": ["Adam Kilgarriff."], "venue": "International Journal of Lexicography, 10(2):135\u2013 155.", "citeRegEx": "Kilgarriff.,? 1997", "shortCiteRegEx": "Kilgarriff.", "year": 1997}, {"title": "Extending a verb-lexicon using a semantically annotated corpus", "author": ["Karin Kipper", "Benjamin Snyder", "Martha Palmer."], "venue": "LREC, pages 1557\u20131560.", "citeRegEx": "Kipper et al\\.,? 2004", "shortCiteRegEx": "Kipper et al\\.", "year": 2004}, {"title": "A large-scale classification of English verbs", "author": ["Karin Kipper", "Anna Korhonen", "Neville Ryant", "Martha Palmer."], "venue": "Language Resource and Evaluation, 42(1):21\u2013", "citeRegEx": "Kipper et al\\.,? 2008", "shortCiteRegEx": "Kipper et al\\.", "year": 2008}, {"title": "Automatic lexical classification: bridging research and practice", "author": ["Anna Korhonen."], "venue": "Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, 368(1924):3621\u2013 3632.", "citeRegEx": "Korhonen.,? 2010", "shortCiteRegEx": "Korhonen.", "year": 2010}, {"title": "One shot learning of simple visual concepts", "author": ["Brenden M. Lake", "Ruslan Salakhutdinov", "Jason Gross", "Joshua B. Tenenbaum."], "venue": "CogSci.", "citeRegEx": "Lake et al\\.,? 2011", "shortCiteRegEx": "Lake et al\\.", "year": 2011}, {"title": "English verb classes and alternation, A preliminary investigation", "author": ["Beth Levin."], "venue": "The University of Chicago Press.", "citeRegEx": "Levin.,? 1993", "shortCiteRegEx": "Levin.", "year": 1993}, {"title": "Dependency-based word embeddings", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "ACL, pages 302\u2013308.", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "Combining lexical resources: Mapping between PropBank and VerbNet", "author": ["Edward Loper", "Szu-Ting Yi", "Martha Palmer."], "venue": "IWCS.", "citeRegEx": "Loper et al\\.,? 2007", "shortCiteRegEx": "Loper et al\\.", "year": 2007}, {"title": "Better word representations with recursive neural networks for morphology", "author": ["Thang Luong", "Richard Socher", "Christopher Manning."], "venue": "CoNLL, pages 104\u2013113.", "citeRegEx": "Luong et al\\.,? 2013", "shortCiteRegEx": "Luong et al\\.", "year": 2013}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean."], "venue": "ICLR: Workshop Papers.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Wordnet: A lexical database for english", "author": ["George A. Miller."], "venue": "Communications of the ACM, 38(11):39\u201341.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Counter-fitting word vectors to linguistic constraints", "author": ["Nikola Mrk\u0161i\u0107", "Diarmuid \u00d3 S\u00e9aghdha", "Blaise Thomson", "Milica Ga\u0161i\u0107", "Lina Maria Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "Tsung-Hsien Wen", "Steve J. Young."], "venue": "NAACL-HLT.", "citeRegEx": "Mrk\u0161i\u0107 et al\\.,? 2016", "shortCiteRegEx": "Mrk\u0161i\u0107 et al\\.", "year": 2016}, {"title": "The University of South Florida free association, rhyme, and word fragment norms", "author": ["Douglas L. Nelson", "Cathy L. McEvoy", "Thomas A. Schreiber."], "venue": "Behavior Research Methods, Instruments, & Computers, 36(3):402\u2013407.", "citeRegEx": "Nelson et al\\.,? 2004", "shortCiteRegEx": "Nelson et al\\.", "year": 2004}, {"title": "Flexible, corpus-based modelling of human plausibility judgements", "author": ["Sebastian Pad\u00f3", "Ulrike Pad\u00f3", "Katrin Erk."], "venue": "EMNLP-CoNLL, pages 400\u2013409.", "citeRegEx": "Pad\u00f3 et al\\.,? 2007", "shortCiteRegEx": "Pad\u00f3 et al\\.", "year": 2007}, {"title": "The Proposition Bank: An annotated corpus of semantic roles", "author": ["Martha Palmer", "Paul Kingsbury", "Daniel Gildea."], "venue": "Computational Linguistics, 31(1):71\u2013106.", "citeRegEx": "Palmer et al\\.,? 2005", "shortCiteRegEx": "Palmer et al\\.", "year": 2005}, {"title": "GloVe: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "EMNLP, pages 1532\u20131543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "A mixture model with sharing for lexical semantics", "author": ["Joseph Reisinger", "Raymond J. Mooney."], "venue": "EMNLP, pages 1173\u20131182.", "citeRegEx": "Reisinger and Mooney.,? 2010a", "shortCiteRegEx": "Reisinger and Mooney.", "year": 2010}, {"title": "Multiprototype vector-space models of word meaning", "author": ["Joseph Reisinger", "Raymond J Mooney."], "venue": "NAACL-HTL, pages 109\u2013117.", "citeRegEx": "Reisinger and Mooney.,? 2010b", "shortCiteRegEx": "Reisinger and Mooney.", "year": 2010}, {"title": "Contextual correlates of synonymy", "author": ["Herbert Rubenstein", "John B Goodenough."], "venue": "Communications of the ACM, 8(10):627\u2013633.", "citeRegEx": "Rubenstein and Goodenough.,? 1965", "shortCiteRegEx": "Rubenstein and Goodenough.", "year": 1965}, {"title": "Symmetric pattern based word embeddings for improved word similarity prediction", "author": ["Roy Schwartz", "Roi Reichart", "Ari Rappoport."], "venue": "CoNLL, pages 258\u2013267.", "citeRegEx": "Schwartz et al\\.,? 2015", "shortCiteRegEx": "Schwartz et al\\.", "year": 2015}, {"title": "Learning grounded meaning representations with autoencoders", "author": ["Carina Silberer", "Mirella Lapata."], "venue": "ACL, pages 721\u2013732.", "citeRegEx": "Silberer and Lapata.,? 2014", "shortCiteRegEx": "Silberer and Lapata.", "year": 2014}, {"title": "Word representations: A simple and general method for semi-supervised learning", "author": ["Joseph P. Turian", "Lev-Arie Ratinov", "Yoshua Bengio."], "venue": "ACL, pages 384\u2013394.", "citeRegEx": "Turian et al\\.,? 2010", "shortCiteRegEx": "Turian et al\\.", "year": 2010}, {"title": "Word representations via Gaussian embedding", "author": ["Luke Vilnis", "Andrew McCallum."], "venue": "ICLR.", "citeRegEx": "Vilnis and McCallum.,? 2015", "shortCiteRegEx": "Vilnis and McCallum.", "year": 2015}, {"title": "From paraphrase database to compositional paraphrase model and back", "author": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu."], "venue": "Transactions of the ACL, 3:345\u2013358.", "citeRegEx": "Wieting et al\\.,? 2015", "shortCiteRegEx": "Wieting et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 11, "context": "They express the semantics of an event as well the relational information among participants in that event, and they display a rich range of syntactic and semantic behaviour (Jackendoff, 1972; Gruber, 1976; Levin, 1993).", "startOffset": 174, "endOffset": 219}, {"referenceID": 9, "context": "They express the semantics of an event as well the relational information among participants in that event, and they display a rich range of syntactic and semantic behaviour (Jackendoff, 1972; Gruber, 1976; Levin, 1993).", "startOffset": 174, "endOffset": 219}, {"referenceID": 17, "context": "They express the semantics of an event as well the relational information among participants in that event, and they display a rich range of syntactic and semantic behaviour (Jackendoff, 1972; Gruber, 1976; Levin, 1993).", "startOffset": 174, "endOffset": 219}, {"referenceID": 15, "context": "machine translation, text mining) as well as research on human language acquisition and processing (Korhonen, 2010).", "startOffset": 99, "endOffset": 115}, {"referenceID": 21, "context": "Numerous algorithms for acquiring word representations from text and/or more structured knowledge bases have been developed in recent years (Mikolov et al., 2013; Pennington et al., 2014; Faruqui et al., 2015).", "startOffset": 140, "endOffset": 209}, {"referenceID": 27, "context": "Numerous algorithms for acquiring word representations from text and/or more structured knowledge bases have been developed in recent years (Mikolov et al., 2013; Pennington et al., 2014; Faruqui et al., 2015).", "startOffset": 140, "endOffset": 209}, {"referenceID": 6, "context": "Numerous algorithms for acquiring word representations from text and/or more structured knowledge bases have been developed in recent years (Mikolov et al., 2013; Pennington et al., 2014; Faruqui et al., 2015).", "startOffset": 140, "endOffset": 209}, {"referenceID": 4, "context": "These representations (or embeddings) typically contain powerful features that are applicable to many language applications (Collobert and Weston, 2008; Turian et al., 2010).", "startOffset": 124, "endOffset": 173}, {"referenceID": 33, "context": "These representations (or embeddings) typically contain powerful features that are applicable to many language applications (Collobert and Weston, 2008; Turian et al., 2010).", "startOffset": 124, "endOffset": 173}, {"referenceID": 31, "context": "This is despite evidence that applying different learning algorithms to word types such as nouns, adjectives and verbs can significantly increase the ultimate usefulness of representations (Schwartz et al., 2015).", "startOffset": 189, "endOffset": 212}, {"referenceID": 3, "context": "Resources such as MEN (Bruni et al., 2014), Rare Words (Luong et al.", "startOffset": 22, "endOffset": 42}, {"referenceID": 20, "context": ", 2014), Rare Words (Luong et al., 2013) and SimLex-999 (Hill et al.", "startOffset": 20, "endOffset": 40}, {"referenceID": 10, "context": ", 2013) and SimLex-999 (Hill et al., 2015) focus either on words from a single class or small samples of different word types, with automatic approaches already reaching or surpassing the inter-annotator agreement ceiling.", "startOffset": 23, "endOffset": 42}, {"referenceID": 24, "context": "SimVerb-3500 includes 827 verb types from the University of South Florida Free Association Norms (USF) (Nelson et al., 2004), and at least 3 member verbs from each of the 101 top-level VerbNet classes (Kipper et al.", "startOffset": 103, "endOffset": 124}, {"referenceID": 14, "context": ", 2004), and at least 3 member verbs from each of the 101 top-level VerbNet classes (Kipper et al., 2008).", "startOffset": 84, "endOffset": 105}, {"referenceID": 22, "context": "This coverage enables researchers to better understand the complex diversity of syntactic-semantic verb behaviours, and provides direct links to other established semantic resources such as WordNet (Miller, 1995) and PropBank (Palmer et al.", "startOffset": 198, "endOffset": 212}, {"referenceID": 26, "context": "This coverage enables researchers to better understand the complex diversity of syntactic-semantic verb behaviours, and provides direct links to other established semantic resources such as WordNet (Miller, 1995) and PropBank (Palmer et al., 2005).", "startOffset": 226, "endOffset": 247}, {"referenceID": 10, "context": "For a broader discussion see (Hill et al., 2015).", "startOffset": 29, "endOffset": 48}, {"referenceID": 30, "context": "Representative examples include RG-65 (Rubenstein and Goodenough, 1965) and WordSim353 (Finkelstein et al.", "startOffset": 38, "endOffset": 71}, {"referenceID": 8, "context": "Representative examples include RG-65 (Rubenstein and Goodenough, 1965) and WordSim353 (Finkelstein et al., 2002; Agirre et al., 2009) which are small (65 and 353 word pairs, respectively).", "startOffset": 87, "endOffset": 134}, {"referenceID": 0, "context": "Representative examples include RG-65 (Rubenstein and Goodenough, 1965) and WordSim353 (Finkelstein et al., 2002; Agirre et al., 2009) which are small (65 and 353 word pairs, respectively).", "startOffset": 87, "endOffset": 134}, {"referenceID": 20, "context": "Larger evaluation sets such as the Rare Words evaluation set (Luong et al., 2013) (2034 word pairs) and the evaluations sets from Silberer and Lapata (2014) are dominated by noun pairs and the former also focuses on low-frequency phenomena.", "startOffset": 61, "endOffset": 81}, {"referenceID": 10, "context": "Therefore, these datasets do not provide a representative sample of verbs (Hill et al., 2015).", "startOffset": 74, "endOffset": 93}, {"referenceID": 0, "context": ", 2002; Agirre et al., 2009) which are small (65 and 353 word pairs, respectively). Larger evaluation sets such as the Rare Words evaluation set (Luong et al., 2013) (2034 word pairs) and the evaluations sets from Silberer and Lapata (2014) are dominated by noun pairs and the former also focuses on low-frequency phenomena.", "startOffset": 8, "endOffset": 241}, {"referenceID": 10, "context": "(2014) and Simlex-999 (Hill et al., 2015).", "startOffset": 22, "endOffset": 41}, {"referenceID": 1, "context": "Two datasets that do focus on verb pairs to some extent are the data set of Baker et al. (2014) and Simlex-999 (Hill et al.", "startOffset": 76, "endOffset": 96}, {"referenceID": 23, "context": "727 (Mrk\u0161i\u0107 et al., 2016).", "startOffset": 4, "endOffset": 25}, {"referenceID": 24, "context": "To ensure a wide coverage of a variety of syntacticosemantic phenomena (C1), the choice of verb pairs is steered by two standard semantic resources available online: (1) the USF norms data set3 (Nelson et al., 2004), and (2) the VerbNet verb lexicon4 (Kipper et al.", "startOffset": 194, "endOffset": 215}, {"referenceID": 13, "context": ", 2004), and (2) the VerbNet verb lexicon4 (Kipper et al., 2004; Kipper et al., 2008).", "startOffset": 43, "endOffset": 85}, {"referenceID": 14, "context": ", 2004), and (2) the VerbNet verb lexicon4 (Kipper et al., 2004; Kipper et al., 2008).", "startOffset": 43, "endOffset": 85}, {"referenceID": 17, "context": "VN is organised into verb classes extending the classes from Levin (1993) through further refinement to achieve syntactic and semantic coherence among class members.", "startOffset": 61, "endOffset": 74}, {"referenceID": 1, "context": "Finally, VerbNet enables further connections of SimVerb-3500 to other important lexical resources such as FrameNet (Baker et al., 1998), WordNet (Miller, 1995), and PropBank (Palmer et al.", "startOffset": 115, "endOffset": 135}, {"referenceID": 22, "context": ", 1998), WordNet (Miller, 1995), and PropBank (Palmer et al.", "startOffset": 17, "endOffset": 31}, {"referenceID": 26, "context": ", 1998), WordNet (Miller, 1995), and PropBank (Palmer et al., 2005) through the sets of mappings created by the SemLink project initiative (Loper et al.", "startOffset": 46, "endOffset": 67}, {"referenceID": 19, "context": ", 2005) through the sets of mappings created by the SemLink project initiative (Loper et al., 2007).", "startOffset": 79, "endOffset": 99}, {"referenceID": 12, "context": "We performed an initial frequency analysis of SimVerb-3500 relying on the BNC counts available online (Kilgarriff, 1997).", "startOffset": 102, "endOffset": 120}, {"referenceID": 10, "context": "The score was finally scaled linearly from the 0-6 to the 0-10 interval as in (Hill et al., 2015).", "startOffset": 78, "endOffset": 97}, {"referenceID": 25, "context": "IAA-1 (pairwise) computes the average pairwise Spearman\u2019s \u03c1 correlation between any two raters \u2013 a common choice in previous data collection in distributional semantics (Pad\u00f3 et al., 2007; Reisinger and Mooney, 2010a; Silberer and Lapata, 2014; Hill et al., 2015).", "startOffset": 169, "endOffset": 263}, {"referenceID": 28, "context": "IAA-1 (pairwise) computes the average pairwise Spearman\u2019s \u03c1 correlation between any two raters \u2013 a common choice in previous data collection in distributional semantics (Pad\u00f3 et al., 2007; Reisinger and Mooney, 2010a; Silberer and Lapata, 2014; Hill et al., 2015).", "startOffset": 169, "endOffset": 263}, {"referenceID": 32, "context": "IAA-1 (pairwise) computes the average pairwise Spearman\u2019s \u03c1 correlation between any two raters \u2013 a common choice in previous data collection in distributional semantics (Pad\u00f3 et al., 2007; Reisinger and Mooney, 2010a; Silberer and Lapata, 2014; Hill et al., 2015).", "startOffset": 169, "endOffset": 263}, {"referenceID": 10, "context": "IAA-1 (pairwise) computes the average pairwise Spearman\u2019s \u03c1 correlation between any two raters \u2013 a common choice in previous data collection in distributional semantics (Pad\u00f3 et al., 2007; Reisinger and Mooney, 2010a; Silberer and Lapata, 2014; Hill et al., 2015).", "startOffset": 169, "endOffset": 263}, {"referenceID": 5, "context": "Here, we use sparse binary vectors built from linguistic resources (Non-Distributional, (Faruqui and Dyer, 2015)), and vectors fine-tuned to a paraphrase database (Paragram, (Wieting et al.", "startOffset": 88, "endOffset": 112}, {"referenceID": 17, "context": "We include: (1) unsupervised models that learn from distributional information in text, including the skip-gram negative-sampling model (SGNS) with various contexts (BOW = bag of words; DEPS = dependency contexts) as in Levy and Goldberg (2014), and the symmetric-pattern based vectors by Schwartz et al.", "startOffset": 220, "endOffset": 245}, {"referenceID": 17, "context": "We include: (1) unsupervised models that learn from distributional information in text, including the skip-gram negative-sampling model (SGNS) with various contexts (BOW = bag of words; DEPS = dependency contexts) as in Levy and Goldberg (2014), and the symmetric-pattern based vectors by Schwartz et al. (2015); (2) Models that rely on linguistic hand-crafted resources or curated knowledge bases.", "startOffset": 220, "endOffset": 312}, {"referenceID": 23, "context": "2015)) further refined using linguistic constraints (Paragram+CF, (Mrk\u0161i\u0107 et al., 2016)).", "startOffset": 66, "endOffset": 87}, {"referenceID": 7, "context": "Previous works often optimise models on the entire dataset, which leads to overfitting (Faruqui et al., 2016) or use custom splits, e.", "startOffset": 87, "endOffset": 109}, {"referenceID": 31, "context": ", 10-fold cross-validation (Schwartz et al., 2015), which make results incomparable with others.", "startOffset": 27, "endOffset": 50}, {"referenceID": 5, "context": "The non-distributional non data-driven model of Faruqui and Dyer (2015) is only slightly affected by frequency.", "startOffset": 48, "endOffset": 72}, {"referenceID": 22, "context": "To examine this hypothesis, we resort to WordNet (Miller, 1995), where different semantic usages of words are listed as so-called synsets.", "startOffset": 49, "endOffset": 63}, {"referenceID": 16, "context": "More generally, the finding suggests that, in order to model the diverse spectrum of verb semantics, we may require algorithms that are better suited to fast learning from few examples (Lake et al., 2011), and have some flexibility with respect to sense-level distinctions (Reisinger and Mooney, 2010b; Vilnis and McCallum, 2015).", "startOffset": 185, "endOffset": 204}, {"referenceID": 29, "context": ", 2011), and have some flexibility with respect to sense-level distinctions (Reisinger and Mooney, 2010b; Vilnis and McCallum, 2015).", "startOffset": 76, "endOffset": 132}, {"referenceID": 34, "context": ", 2011), and have some flexibility with respect to sense-level distinctions (Reisinger and Mooney, 2010b; Vilnis and McCallum, 2015).", "startOffset": 76, "endOffset": 132}], "year": 2017, "abstractText": "Verbs play a critical role in the meaning of sentences, but these ubiquitous words have received little attention in recent distributional semantics research. We introduce SimVerb-3500, an evaluation resource that provides human ratings for the similarity of 3,500 verb pairs. SimVerb-3500 covers all normed verb types from the USF free-association database, providing at least three examples for every VerbNet class. This broad coverage facilitates detailed analyses of how syntactic and semantic phenomena together influence human understanding of verb meaning. Further, with significantly larger development and test sets than existing benchmarks, SimVerb-3500 enables more robust evaluation of representation learning architectures and promotes the development of methods tailored to verbs. We hope that SimVerb-3500 will enable a richer understanding of the diversity and complexity of verb semantics and guide the development of systems that can effectively represent and interpret this meaning.", "creator": "LaTeX with hyperref package"}}}