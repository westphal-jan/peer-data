{"id": "1608.06203", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "22-Aug-2016", "title": "Computational and Statistical Tradeoffs in Learning to Rank", "abstract": "For massive and heterogeneous modern datasets, it is of fundamental interest to provide guarantees on the accuracy of estimation when computational resources are limited. In the application of learning to rank, we provide a hierarchy of rank-breaking mechanisms ordered by the complexity in thus generated sketch of the data. This allows the number of data points collected to be gracefully traded off against computational resources available, while guaranteeing the desired level of accuracy. Theoretical guarantees on the proposed generalized rank-breaking implicitly provide such trade-offs, which can be explicitly characterized under certain canonical scenarios on the structure of the data.", "histories": [["v1", "Mon, 22 Aug 2016 15:58:31 GMT  (480kb,D)", "http://arxiv.org/abs/1608.06203v1", "30 pages 5 figures"]], "COMMENTS": "30 pages 5 figures", "reviews": [], "SUBJECTS": "cs.LG cs.IT math.IT stat.ML", "authors": ["ashish khetan", "sewoong oh"], "accepted": true, "id": "1608.06203"}, "pdf": {"name": "1608.06203.pdf", "metadata": {"source": "CRF", "title": "Computational and Statistical Tradeoffs in Learning to Rank", "authors": ["Ashish Khetan", "Sewoong Oh"], "emails": ["khetan2@illinois.edu", "swoh@illinois.edu"], "sections": [{"heading": "1. Introduction", "text": "We are usually interested in how more data improves accuracy, with few limitations or considerations on the individual aspects of coping with the problem. But it's not as if it's a way of answering questions, but rather the way in which it's about answering questions, answering questions of answering questions of answering questions of answering questions of answering questions of answering questions of answering questions of answering questions of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering of answering"}, {"heading": "1.1 Related work", "text": "In fact, most of us are able to set out in search of new paths to follow."}, {"heading": "2. Generalized rank-breaking", "text": "Considering the preferences of the users (e), it is the preferred number of Ej users (e) that specifies a set of ordered ratios and uses an estimator that considers each ordered relationship to be independent. Specifically, this means that we must first select a maximum ordered partition of Sj that is consistent with Figure 1. This is a partition with a linear order among the subsets that do not exist in the original Gj order. The extracted ordered partition is represented by a steered hypergraph that we call a rank refraction graph. Each edge e = (e), T (e) is a steered hyperedge from another group of nodes B (e) Sj, which we call a rank refraction graph."}, {"heading": "3. Comparison graph", "text": "The analysis of the optimization in (4) shows that, with a high probability, LRB (disturbance) (disturbance) (own weight) (own weight) (own weight) (own weight) (own weight)) (own weight) (own weight) (own weight) (own weight) (own weight) (own weight) (own weight) (own weight) (own weight) (own weight) ((own weight)) (own weight) () (own weight) (own weight) ((own weight) (own weight) ((own weight) (own weight) (own weight) (own weight) (own weight) (own weight) (own weight) () () () () () () () () () () () () () () () () () () () () () () () () () () () ()) () () ()) () () ()) () () () ()) () ()) () () ()) () ()) () ()) () ()) () ()) () ()) () ()) () ()) ()) () ()) ()) () ()) ()) () ()) () ()) ()) () ()) () ()) () ()) () ()) () () ()) ()) () ()) () () () () ()) () () () () ()) () () () () () () ()) () () () () () () () () () () () () () () () () () () () (() () () () () () () () () () () () () (() () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ("}, {"heading": "4. Main Results", "text": "We present the most important theoretical analyses and numerical simulations that confirm the theoretical predictions."}, {"heading": "4.1 Upper bound on the achievable error", "text": "We assume that each user provides a partial ranking according to his / her ordered partitions. Specifically, we assume that the set of offers Sj, the number of partial samples (number of partial samples) and their respective sizes (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples (number of partial samples) (number of partial samples) (number of partial samples (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples (number of partial samples) (number of partial samples) (number of partial samples (number of partial samples) (number of partial samples) (number of partial samples (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples (number of partial samples) (number of partial samples) (number of partial samples) (number of partial samples (number) (number of partial samples) (number of partial samples) (number of partial (number) (number of partial samples) (number of partial (number) (number) (number of partial samples) (number of partial samples) (number of partial (number) (number of partial (number) (number of partial points) (number of partial (number) (number) (number of partial (number) (number) (number of partial (number) (number) (number of partial (number) (number of partial (number) (partial (number) (number) (number of partial () (number) (number of partial (number) (number of partial (number) (number) () (number) (number of partial () (number) (number) (number of partial ((number) (number) (number of partial () (number of partial) (number) ((number) ("}, {"heading": "4.2 Lower bound on computationally unbounded estimators", "text": "We remember that it is a \"small\" error that applies to any unbiased estimator, even if there are no limitations on computational complexity. For each (j, a), we define a \"small\" error that applies to each unbiased estimator, even if it has no limitations on computational complexity. (r, a), we define a \"large\" error when the \"large\" error (r, a), a (r, a) m (n) m (r, a) m (r, a) m (r, a) m (r, b) m (r, b) m (n)."}, {"heading": "4.3 Computational and statistical tradeoff", "text": "However, for estimators with limited computing power, the lower limit mentioned above is not suitable for grasping dependence on permitted computing power. (This is outside the scope of this work, and we are instead examining the trade-off achieved by the proposed rank-breaking approach.) If we are limited to computing power, Theorem 4.1 implicitly grasps this dependence when using the ranking M break. (The dependence is indirectly grasped by the resulting ranking. (Gj, a) j [n] and its topology. We make this trade-off explicit by considering a simple but canonical example."}, {"heading": "4.4 Real-world datasets", "text": "For sushi preferences (Kamishima, 2003) and the Jester dataset (Goldberg et al., 2001), we improve in pairs and achieve the same performance as the oracle MLE. Full rankings of \u043c = 10 sushi types are randomly selected from d = 100 sushi types of n = 5000 individuals. As a reason, we use the ML estimate of PL weights across the entire data. In Figure 5, left field, we remove the known order among the top m and bottom (10 \u2212 m) sushi in each set and perform our estimator with a breaking edge between top m and bottom (10 \u2212 m) items. We compare our algorithm with inconsistent pairwise breaks (using optimal parameters from Khetan and Oh (2016)."}, {"heading": "5. Proofs", "text": "We provide the evidence for the most important results."}, {"heading": "5.1 Proof of Remark 2.1", "text": "Remember that when S = B (e) is offered, the likelihood that an agent will put the capture of items T (e) above B (e) is the likelihood that an agent will put the capture of items T (e) above B (e). We prove a slightly general result that works for a family of RUMs in the site family. Random Utility Models (RUM) are defined as a probabilistic model in which there is a realistically weighted utility parameter associated with each item i (S), and an agent independently identifies random utilities (Ui) i (RUM) for each item i with conditional distribution i (RUM). Then, the order of precedence is determined by sorting the items in decreasing order in which the items Ui's are observed. The location family is a subset of RUMs in which the shapes of the items are the only means of the items."}, {"heading": "5.2 Proof of Remark 2.2", "text": "Define Event E (e), [d] (B (e), T (e), T (e), E (e), T (e), T (e), T (e), T (e), T (e), T (e), E (e), the probability that the event B (e), T (e), T (e), T (e), T (e), T (e), T (e), T (e), T (e), E (e), the probability that the event B (e), T (e), T (e), T (e), T (e), T (e), (e), if the supply quantity, P \u2212 as Civility, Civility, Civility, Civility (e), Civility (e), c (c), Civility (c), Civility (c, c, Civility, c, c, c, Civility, c, c, c, c, c (c), Civility (c, c, c, c, c, Civility (c), c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, c, e, e, e, e, e, (e, e, e (e, e, e, e, e, T (e, e, e, e, e, e, e, e, e, e, e, e, e, e, e (e, e, e, e, e, e, e (e, e, e, e, e, e (e, e, e, e, e, e, e, e, e, e, e, e, e (e, e, e, e, e, e, e, e, e, e (e, e, e, e, e, e, e, e, e"}, {"heading": "5.3 Proof of Theorem 4.1", "text": "We define some additional notations. p \u00b2 (1 / n). p \u00b2 (1 / n). p \u00b2 (1 / n). p \u00b2 (1 / n). p \u00b2 (1 / n). p \u00b2 (1 / n). p \u00b2 (1 / n)."}, {"heading": "5.4 Proof of Lemma 5.2", "text": "Remember that ej, a is a random event where randomness falls into the top row (ej, a) and the bottom row (ej, a) and the bottom row (ej, a), if the offer is B (ej, a) or T (ej, a) in the sense of (3). Define, PTB, Sj [ej, a), Sj [ej, a) is the probability of observing B (ej, a) or T (ej, a) in the sense of (3). Define, PTB, Sj [ej, a), Sj (ej, a) is the conditional probability of observing B (ej, a) or T (ej, a), if the offer is Sj (ej, a), conditioned by the event that V (ej, a) is an offer."}, {"heading": "5.5 Proof of Lemma 5.3", "text": "We consider LRB as the final value of a single time vector-weighted martyrdom with values in Rd. Let us define L (ej, a) RB (Rd) as the gradient vector resulting from each rank-breaking edge (ej, a), a), a), a), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c), c)), c)), c)), c)), c))), c))), c))), c)))), c)))), c)))), c)))))), c))))))), c))))), c))))))))))))), c))))))))))))))))))))))), c))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))"}, {"heading": "5.5.1 Proof of Lemma 5.4", "text": "First, we (23) prove that we (by definition LRB) (by definition LRB) (by definition LRB) (by definition LRB) (by definition LRB) (by definition LRB) (by definition) (by definition) (by definition) (by definition) (by definition) \u2212 From equations (27) and (29), and from equations (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) (by definition) \u2212 From equations (by definition) (by definition). \u2212 From equations (27) and (29), and from (by definition) (by) (by), (by) (by), (by) (by), (by (by) and (by) (by). \u2212 From equations (27) and (29), and (by (by). \u2212 From."}, {"heading": "5.6 Proof of Lemma 5.5", "text": "Allegation (37): Since it is not possible to provide a lower boundary at the border with another country, we will construct a new set of parameters. (44) These new parameters are constructed so that it is both easy to calculate the probability as well as providing a lower boundary at the original distribution. (44) Let us define a lower boundary at the border with another country. (54) These new parameters are constructed so that the probability can be calculated so that they also have a lower boundary at the original distribution. (44) Let us define a lower boundary at the border.) (52) and (52) and (52), i), (52) and (52), (52) and (56), (56), (56) and (56), (56) and (56), (56) (56)."}, {"heading": "5.7 Proof of Theorem 4.2", "text": "Let us define H (\u03b8) - Sd = Hessian matrix so that Hii \u2032 (ligenz) = Hai \u2032 (ligenz) = Hai \u00b2 (ligenz) = Hai \u00b2 (ligenz) = Hai \u00b2 (ligenz) = Hai \u00b2 (Hai) = Hai \u00b2 (Hai) = Hai (Hai) = Hai (Hai) = Hai (Hai) = Hai (Hai) = Hai (Hai) = Hai (Hai) = Hai (Hai) = Hai (Hai), Hai (Hai) = Hai (Hai) = Hai (Hai), Hai (Hai) = Hai (Hai), Hai (Hai) = Hai (Hai), Hai (Hai) = Hai (Hai), Hai (Hai) (Hai), Hai (Hai) (Hai) (Hai), Hai (Hai) (Hai), Hai (Hai) (Hai), Hai (Hai) (Hai), Hai (Hai) (Hai) (Hai), Hai (Hai) (Hai), Hai (Hai) (Hai) (Hai), Hai (Hai) (Hai) (Hai), Hai (Hai) (Hai) (Hai), Hai (Hai) (Hai) (Hai), Hai (Hai) (Hai) (Hai) (Hai), Hai (Hai) (Hai), Hai (Hai) (Hai (Hai) (Hai), Hai (Hai) (Hai) (Hai) (Hai) (Hai, (Hai) (Hai) (Hai) (Hai) (Hai, (Hai) ((Hai) (Hai) (Hai) ((Hai) (Hai) (Hai), (Hai) (Hai) ((Hai) (Hai) (Hai), (Hai) (Hai) (Hai) ((Hai) (Hai) (Hai) (Hai"}, {"heading": "5.8 Tightening of Lemma 5.4", "text": "Remember that the number of terms in PL models, in which the number of terms can only grow as such, is limited, that we cannot assume that the number of terms in PL models, in which the number of terms is assumed only as a condition, is the same as the probability that the number of terms in PL models becomes too complex. In the following, it is easy to verify that all elements consisting of V (ej, a) in the Hessian matrix of logPledge (e) are not negative. However, since the number of terms in PL models (e) grows as m, the approach becomes too complex for m. In the following, we derive expressions for transverse derivatives in Hesse, for general m, using alternative definitions (sorting of the independent exponential r.v. s in increasing order)."}, {"heading": "Acknowledgements", "text": "This work is supported by the NSF SaTC Prize CNS-1527754 and the NSF CISE Prize CCF-1553452."}], "references": [{"title": "Oracle inequalities for computationally adaptive model selection", "author": ["A. Agarwal", "P.L. Bartlett", "J.C. Duchi"], "venue": "arXiv preprint arXiv:1208.0129,", "citeRegEx": "Agarwal et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Agarwal et al\\.", "year": 2012}, {"title": "Meil\u0103. Experiments with kemeny ranking: What works when", "author": ["M.A. Ali"], "venue": "Mathematical Social Sciences,", "citeRegEx": "Ali,? \\Q2012\\E", "shortCiteRegEx": "Ali", "year": 2012}, {"title": "Random utility theory for social choice", "author": ["H. Azari Soufiani", "D.C. Parkes", "L. Xia"], "venue": "In NIPS,", "citeRegEx": "Soufiani et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Soufiani et al\\.", "year": 2012}, {"title": "Generalized method-of-moments for rank aggregation", "author": ["H. Azari Soufiani", "W. Chen", "D. C Parkes", "L. Xia"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Soufiani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Soufiani et al\\.", "year": 2013}, {"title": "Computing parametric ranking models via rank-breaking", "author": ["H. Azari Soufiani", "D. Parkes", "L. Xia"], "venue": "In Proceedings of The 31st International Conference on Machine Learning,", "citeRegEx": "Soufiani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Soufiani et al\\.", "year": 2014}, {"title": "Theoretical and empirical evaluation of data reduction for exact kemeny rank aggregation", "author": ["N. Betzler", "R. Bredereck", "R. Niedermeier"], "venue": "Autonomous Agents and Multi-Agent Systems,", "citeRegEx": "Betzler et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Betzler et al\\.", "year": 2014}, {"title": "The tradeoffs of large scale learning", "author": ["O. Bousquet", "L. Bottou"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Bousquet and Bottou.,? \\Q2008\\E", "shortCiteRegEx": "Bousquet and Bottou.", "year": 2008}, {"title": "Computational and statistical tradeoffs via convex relaxation", "author": ["V. Chandrasekaran", "M.I. Jordan"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "Chandrasekaran and Jordan.,? \\Q2013\\E", "shortCiteRegEx": "Chandrasekaran and Jordan.", "year": 2013}, {"title": "Spectral mle: Top-k rank aggregation from pairwise comparisons", "author": ["Y. Chen", "C. Suh"], "venue": null, "citeRegEx": "Chen and Suh.,? \\Q2015\\E", "shortCiteRegEx": "Chen and Suh.", "year": 2015}, {"title": "Improved sum-of-squares lower bounds for hidden clique and hidden submatrix problems", "author": ["Y. Deshpande", "A. Montanari"], "venue": "arXiv preprint arXiv:1502.06590,", "citeRegEx": "Deshpande and Montanari.,? \\Q2015\\E", "shortCiteRegEx": "Deshpande and Montanari.", "year": 2015}, {"title": "Solution of a ranking problem from binary comparisons", "author": ["L.R. Ford Jr."], "venue": "The American Mathematical Monthly,", "citeRegEx": "Jr.,? \\Q1957\\E", "shortCiteRegEx": "Jr.", "year": 1957}, {"title": "Eigentaste: A constant time collaborative filtering algorithm", "author": ["K. Goldberg", "T. Roeder", "D. Gupta", "C. Perkins"], "venue": "Information Retrieval,", "citeRegEx": "Goldberg et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Goldberg et al\\.", "year": 2001}, {"title": "Minimax-optimal inference from partial rankings", "author": ["B. Hajek", "S. Oh", "J. Xu"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Hajek et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hajek et al\\.", "year": 2014}, {"title": "A large-deviation inequality for vector-valued martingales", "author": ["T.P. Hayes"], "venue": "Combinatorics, Probability and Computing,", "citeRegEx": "Hayes.,? \\Q2005\\E", "shortCiteRegEx": "Hayes.", "year": 2005}, {"title": "Mm algorithms for generalized bradley-terry models", "author": ["D.R. Hunter"], "venue": "Ann. of Stat., pages 384\u2013406,", "citeRegEx": "Hunter.,? \\Q2004\\E", "shortCiteRegEx": "Hunter.", "year": 2004}, {"title": "Nantonac collaborative filtering: recommendation based on order responses", "author": ["T. Kamishima"], "venue": "In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "Kamishima.,? \\Q2003\\E", "shortCiteRegEx": "Kamishima.", "year": 2003}, {"title": "Data-driven rank breaking for efficient rank aggregation", "author": ["A. Khetan", "S. Oh"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Khetan and Oh.,? \\Q2016\\E", "shortCiteRegEx": "Khetan and Oh.", "year": 2016}, {"title": "Tradeoffs for space, time, data and risk in unsupervised learning", "author": ["M. Lucic", "M.I. Ohannessian", "A. Karbasi", "A. Krause"], "venue": "In AISTATS,", "citeRegEx": "Lucic et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lucic et al\\.", "year": 2015}, {"title": "Fast and accurate inference of plackett-luce models", "author": ["L. Maystre", "M. Grossglauser"], "venue": "In Advances in Neural Information Processing Systems", "citeRegEx": "Maystre and Grossglauser.,? \\Q2015\\E", "shortCiteRegEx": "Maystre and Grossglauser.", "year": 2015}, {"title": "Sum-of-squares lower bounds for planted clique", "author": ["R. Meka", "A. Potechin", "A. Wigderson"], "venue": "In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,", "citeRegEx": "Meka et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Meka et al\\.", "year": 2015}, {"title": "Rank centrality: Ranking from pair-wise comparisons", "author": ["S. Negahban", "S. Oh", "D. Shah"], "venue": null, "citeRegEx": "Negahban et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Negahban et al\\.", "year": 2014}, {"title": "Logarithmic concave measures and related topics", "author": ["A. Pr\u00e9kopa"], "venue": "In Stochastic programming,", "citeRegEx": "Pr\u00e9kopa.,? \\Q1980\\E", "shortCiteRegEx": "Pr\u00e9kopa.", "year": 1980}, {"title": "Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence", "author": ["N.B. Shah", "S. Balakrishnan", "J. Bradley", "A. Parekh", "K. Ramchandran", "M.J. Wainwright"], "venue": null, "citeRegEx": "Shah et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shah et al\\.", "year": 2015}, {"title": "Stochastically transitive models for pairwise comparisons: Statistical and computational issues", "author": ["N.B. Shah", "S. Balakrishnan", "A. Guntuboyina", "M.J. Wainright"], "venue": "arXiv preprint arXiv:1510.05610,", "citeRegEx": "Shah et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shah et al\\.", "year": 2015}, {"title": "Svm optimization: inverse dependence on training set size", "author": ["S. Shalev-Shwartz", "N. Srebro"], "venue": "In Proceedings of the 25th international conference on Machine learning,", "citeRegEx": "Shalev.Shwartz and Srebro.,? \\Q2008\\E", "shortCiteRegEx": "Shalev.Shwartz and Srebro.", "year": 2008}, {"title": "Asymptotics when the number of parameters tends to infinity in the bradley-terry model for paired comparisons", "author": ["G. Simons", "Y. Yao"], "venue": "The Annals of Statistics,", "citeRegEx": "Simons and Yao.,? \\Q1999\\E", "shortCiteRegEx": "Simons and Yao.", "year": 1999}], "referenceMentions": [{"referenceID": 6, "context": "As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).", "startOffset": 207, "endOffset": 342}, {"referenceID": 24, "context": "As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).", "startOffset": 207, "endOffset": 342}, {"referenceID": 7, "context": "As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).", "startOffset": 207, "endOffset": 342}, {"referenceID": 0, "context": "As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).", "startOffset": 207, "endOffset": 342}, {"referenceID": 17, "context": "As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).", "startOffset": 207, "endOffset": 342}, {"referenceID": 9, "context": "For such traditional preferences, efficient schemes for learning to rank have been proposed, such as Ford Jr. (1957); Hunter (2004); Hajek et al.", "startOffset": 106, "endOffset": 117}, {"referenceID": 9, "context": "For such traditional preferences, efficient schemes for learning to rank have been proposed, such as Ford Jr. (1957); Hunter (2004); Hajek et al.", "startOffset": 106, "endOffset": 132}, {"referenceID": 9, "context": "For such traditional preferences, efficient schemes for learning to rank have been proposed, such as Ford Jr. (1957); Hunter (2004); Hajek et al. (2014); Chen and Suh (2015), which we explain in detail in Section 1.", "startOffset": 106, "endOffset": 153}, {"referenceID": 8, "context": "(2014); Chen and Suh (2015), which we explain in detail in Section 1.", "startOffset": 8, "endOffset": 28}, {"referenceID": 8, "context": "(2014); Chen and Suh (2015), which we explain in detail in Section 1.1. However, modern datasets are unstructured and heterogeneous. As Khetan and Oh (2016) show, this can lead to significant increase in the computational complexity, requiring exponential run-time in the size of the problem in the worst case.", "startOffset": 8, "endOffset": 157}, {"referenceID": 12, "context": "Hajek et al. (2014) provides full analysis of the statistical complexity of this MLE under traditional structures.", "startOffset": 0, "endOffset": 20}, {"referenceID": 14, "context": "comparisons in (Ford Jr., 1957; Hunter, 2004; Negahban et al., 2014; Shah et al., 2015a; Maystre and Grossglauser, 2015).", "startOffset": 15, "endOffset": 120}, {"referenceID": 20, "context": "comparisons in (Ford Jr., 1957; Hunter, 2004; Negahban et al., 2014; Shah et al., 2015a; Maystre and Grossglauser, 2015).", "startOffset": 15, "endOffset": 120}, {"referenceID": 18, "context": "comparisons in (Ford Jr., 1957; Hunter, 2004; Negahban et al., 2014; Shah et al., 2015a; Maystre and Grossglauser, 2015).", "startOffset": 15, "endOffset": 120}, {"referenceID": 16, "context": "For the precise condition for consistent rank-breaking we refer to (Azari Soufiani et al., 2013, 2014; Khetan and Oh, 2016).", "startOffset": 67, "endOffset": 123}, {"referenceID": 2, "context": "Azari Soufiani et al. (2014) showed that if we include all paired comparisons, then the resulting estimate can be statistically inconsistent due to the ignored correlations among the paired orderings, even with infinite samples.", "startOffset": 6, "endOffset": 29}, {"referenceID": 2, "context": "Azari Soufiani et al. (2014) showed that if we include all paired comparisons, then the resulting estimate can be statistically inconsistent due to the ignored correlations among the paired orderings, even with infinite samples. In the example from Figure 1, there are 12 paired relations implied by the DAG: (i6 \u227a i5), (i6 \u227a i4), (i6 \u227a i3), . . . , (i3 \u227a i1), (i4 \u227a i1). In order to get a consistent estimate, Azari Soufiani et al. (2014) provide a rule for choosing which pairs to include, and Khetan and Oh (2016) provide an estimator that optimizes how to weigh each of those chosen pairs to get the best finite sample complexity bound.", "startOffset": 6, "endOffset": 440}, {"referenceID": 2, "context": "Azari Soufiani et al. (2014) showed that if we include all paired comparisons, then the resulting estimate can be statistically inconsistent due to the ignored correlations among the paired orderings, even with infinite samples. In the example from Figure 1, there are 12 paired relations implied by the DAG: (i6 \u227a i5), (i6 \u227a i4), (i6 \u227a i3), . . . , (i3 \u227a i1), (i4 \u227a i1). In order to get a consistent estimate, Azari Soufiani et al. (2014) provide a rule for choosing which pairs to include, and Khetan and Oh (2016) provide an estimator that optimizes how to weigh each of those chosen pairs to get the best finite sample complexity bound.", "startOffset": 6, "endOffset": 517}, {"referenceID": 2, "context": "Azari Soufiani et al. (2014) showed that if we include all paired comparisons, then the resulting estimate can be statistically inconsistent due to the ignored correlations among the paired orderings, even with infinite samples. In the example from Figure 1, there are 12 paired relations implied by the DAG: (i6 \u227a i5), (i6 \u227a i4), (i6 \u227a i3), . . . , (i3 \u227a i1), (i4 \u227a i1). In order to get a consistent estimate, Azari Soufiani et al. (2014) provide a rule for choosing which pairs to include, and Khetan and Oh (2016) provide an estimator that optimizes how to weigh each of those chosen pairs to get the best finite sample complexity bound. However, such a consistent pairwise rank-breaking results in throwing away many of the ordered relations, resulting in significant loss in accuracy. For example, Including a paired relation from Gj in the example results in a biased estimator. None of the pairwise orderings can be used from Gj , without making the estimator inconsistent as shown in Azari Soufiani et al. (2013). Whether we include all paired comparisons or only a subset of consistent ones, there is a significant loss in accuracy as illustrated in Figure 3.", "startOffset": 6, "endOffset": 1021}, {"referenceID": 6, "context": "In the application of supervised learning, Bousquet and Bottou (2008) proposed the idea that weaker approximate optimization algorithms are sufficient for learning when more data is available.", "startOffset": 43, "endOffset": 70}, {"referenceID": 6, "context": "In the application of supervised learning, Bousquet and Bottou (2008) proposed the idea that weaker approximate optimization algorithms are sufficient for learning when more data is available. Various gradient based algorithms are analyzed that show the time-accuracy-sample tradeoff. In a similar context, Shalev-Shwartz and Srebro (2008) analyze a particular implementation of support vector machine and show that the target accuracy can be achieved faster when more data is available, by running the iterative algorithm for shorter amount of time.", "startOffset": 43, "endOffset": 340}, {"referenceID": 6, "context": "In the application of supervised learning, Bousquet and Bottou (2008) proposed the idea that weaker approximate optimization algorithms are sufficient for learning when more data is available. Various gradient based algorithms are analyzed that show the time-accuracy-sample tradeoff. In a similar context, Shalev-Shwartz and Srebro (2008) analyze a particular implementation of support vector machine and show that the target accuracy can be achieved faster when more data is available, by running the iterative algorithm for shorter amount of time. In the application of de-noising, Chandrasekaran and Jordan (2013) provide a hierarchy of convex relaxations where constraints are defined by convex geometry with increasing complexity.", "startOffset": 43, "endOffset": 618}, {"referenceID": 6, "context": "In the application of supervised learning, Bousquet and Bottou (2008) proposed the idea that weaker approximate optimization algorithms are sufficient for learning when more data is available. Various gradient based algorithms are analyzed that show the time-accuracy-sample tradeoff. In a similar context, Shalev-Shwartz and Srebro (2008) analyze a particular implementation of support vector machine and show that the target accuracy can be achieved faster when more data is available, by running the iterative algorithm for shorter amount of time. In the application of de-noising, Chandrasekaran and Jordan (2013) provide a hierarchy of convex relaxations where constraints are defined by convex geometry with increasing complexity. For unsupervised learning, Lucic et al. (2015) introduce a hierarchy of data representations that provide more representative elements when more data is available at no additional computation.", "startOffset": 43, "endOffset": 784}, {"referenceID": 5, "context": "posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition.", "startOffset": 14, "endOffset": 25}, {"referenceID": 5, "context": "posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition.", "startOffset": 14, "endOffset": 43}, {"referenceID": 5, "context": "posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights.", "startOffset": 14, "endOffset": 129}, {"referenceID": 5, "context": "posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. Maystre and Grossglauser (2015) provide a connection between those previous approaches, and give a unified random walk approach that finds the fixed point of the KKT conditions.", "startOffset": 14, "endOffset": 364}, {"referenceID": 5, "context": "posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. Maystre and Grossglauser (2015) provide a connection between those previous approaches, and give a unified random walk approach that finds the fixed point of the KKT conditions. On the theoretical side, when samples consist of pairwise comparisons, Simons and Yao (1999) first established consistency and asymptotic normality of the maximum likelihood estimate when all teams play against each other.", "startOffset": 14, "endOffset": 603}, {"referenceID": 5, "context": "posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. Maystre and Grossglauser (2015) provide a connection between those previous approaches, and give a unified random walk approach that finds the fixed point of the KKT conditions. On the theoretical side, when samples consist of pairwise comparisons, Simons and Yao (1999) first established consistency and asymptotic normality of the maximum likelihood estimate when all teams play against each other. For a broader class of scenarios where we allow for sparse observations, where the number of total comparisons grow linearly in the number of teams, Negahban et al. (2014) show that Rank Centrality achieves optimal sample complexity by comparing it to a lower bound on the minimax rate.", "startOffset": 14, "endOffset": 905}, {"referenceID": 5, "context": "posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. Maystre and Grossglauser (2015) provide a connection between those previous approaches, and give a unified random walk approach that finds the fixed point of the KKT conditions. On the theoretical side, when samples consist of pairwise comparisons, Simons and Yao (1999) first established consistency and asymptotic normality of the maximum likelihood estimate when all teams play against each other. For a broader class of scenarios where we allow for sparse observations, where the number of total comparisons grow linearly in the number of teams, Negahban et al. (2014) show that Rank Centrality achieves optimal sample complexity by comparing it to a lower bound on the minimax rate. For a more general class of traditional observations, including pairwise comparisons, Hajek et al. (2014) provide similar optimal guarantee for the maximum likelihood estimator.", "startOffset": 14, "endOffset": 1126}, {"referenceID": 4, "context": "Chen and Suh (2015) introduced Spectral MLE that applies Rank Centrality followed by MLE, and showed that the resulting estimate is optimal in L\u221e error as well as the previously analyzed L2 error.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "Chen and Suh (2015) introduced Spectral MLE that applies Rank Centrality followed by MLE, and showed that the resulting estimate is optimal in L\u221e error as well as the previously analyzed L2 error. Shah et al. (2015a) study a new measure of the error induced by the Laplacian of the comparisons graph and prove a sharper upper and lower bounds that match up to a constant factor.", "startOffset": 0, "endOffset": 217}, {"referenceID": 2, "context": "Although, statistical and computational tradeoffs have been investigated under other popular choice models such as the Mallows models by Betzler et al. (2014) or stochastically transitive models by Shah et al.", "startOffset": 137, "endOffset": 159}, {"referenceID": 2, "context": "Although, statistical and computational tradeoffs have been investigated under other popular choice models such as the Mallows models by Betzler et al. (2014) or stochastically transitive models by Shah et al. (2015b), the algorithmic solutions do not apply to random utility models and the analysis techniques do not extend.", "startOffset": 137, "endOffset": 218}, {"referenceID": 2, "context": "However, it is also known from Azari Soufiani et al. (2014), that for general RUMs there is no consistent rank-breaking, and the proposed approach does not generalize.", "startOffset": 37, "endOffset": 60}, {"referenceID": 2, "context": "In a special case when M = 1, this can be transformed into the traditional pairwise rank-breaking, where (i) this is a concave maximization; (ii) the estimate is (asymptotically) unbiased and consistent as shown in Azari Soufiani et al. (2013, 2014); and (iii) and the finite sample complexity have been analyzed in Khetan and Oh (2016). Although, this order-1 rank-breaking provides a significant gain in computational efficiency, the information contained in higher-order edges are unused, resulting in a significant loss in accuracy.", "startOffset": 221, "endOffset": 337}, {"referenceID": 2, "context": "As predicted by Azari Soufiani et al. (2014), this results in an inconsistent estimate, whose error does not vanish as we increase the sample size.", "startOffset": 22, "endOffset": 45}, {"referenceID": 1, "context": "This is different from learning Mallows models in Ali and Meil\u0103 (2012) where peaked distributions are easier to learn, and is related to the fact that we are not only interested in recovering the (ordinal) ranking but also the (cardinal) weight.", "startOffset": 50, "endOffset": 71}, {"referenceID": 9, "context": "planted clique problem (Deshpande and Montanari, 2015; Meka et al., 2015).", "startOffset": 23, "endOffset": 73}, {"referenceID": 19, "context": "planted clique problem (Deshpande and Montanari, 2015; Meka et al., 2015).", "startOffset": 23, "endOffset": 73}, {"referenceID": 15, "context": "On sushi preferences (Kamishima, 2003) and jester dataset (Goldberg et al.", "startOffset": 21, "endOffset": 38}, {"referenceID": 11, "context": "On sushi preferences (Kamishima, 2003) and jester dataset (Goldberg et al., 2001), we improve over pairwise breaking and achieves same performance as the oracle MLE.", "startOffset": 58, "endOffset": 81}, {"referenceID": 11, "context": "On sushi preferences (Kamishima, 2003) and jester dataset (Goldberg et al., 2001), we improve over pairwise breaking and achieves same performance as the oracle MLE. Full rankings over \u03ba = 10 types of sushi are randomly chosen from d = 100 types of sushi are provided by n = 5000 individuals. As the ground truth \u03b8\u2217, we use the ML estimate of PL weights over the entire data. In Figure 5, left panel, for each m \u2208 {3, 4, 5, 6, 7}, we remove the known ordering among the top-m and bottom-(10 \u2212m) sushi in each set, and run our estimator with one breaking edge between top-m and bottom-(10\u2212m) items. We compare our algorithm with inconsistent pairwise breaking (using optimal choice of parameters from Khetan and Oh (2016)) and the oracle MLE.", "startOffset": 59, "endOffset": 721}, {"referenceID": 18, "context": "We use the following Theorem from Pr\u00e9kopa (1980). A similar technique was used to prove concavity when |T (e)| = 1 in Azari Soufiani et al.", "startOffset": 34, "endOffset": 49}, {"referenceID": 2, "context": "A similar technique was used to prove concavity when |T (e)| = 1 in Azari Soufiani et al. (2012).", "startOffset": 74, "endOffset": 97}, {"referenceID": 21, "context": "1 (Theorem 9 in Pr\u00e9kopa (1980)).", "startOffset": 16, "endOffset": 31}, {"referenceID": 16, "context": "The proof sketch is inspired from Khetan and Oh (2016). The main difference and technical challenge is in showing the strict concavity of LRB(\u03b8) when restricted to \u03a9b.", "startOffset": 34, "endOffset": 55}, {"referenceID": 13, "context": "8, Hayes (2005)], we have", "startOffset": 3, "endOffset": 16}], "year": 2016, "abstractText": "For massive and heterogeneous modern datasets, it is of fundamental interest to provide guarantees on the accuracy of estimation when computational resources are limited. In the application of learning to rank, we provide a hierarchy of rank-breaking mechanisms ordered by the complexity in thus generated sketch of the data. This allows the number of data points collected to be gracefully traded off against computational resources available, while guaranteeing the desired level of accuracy. Theoretical guarantees on the proposed generalized rank-breaking implicitly provide such trade-offs, which can be explicitly characterized under certain canonical scenarios on the structure of the data.", "creator": "LaTeX with hyperref package"}}}