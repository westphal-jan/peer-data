{"id": "1608.06349", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "23-Aug-2016", "title": "Five dimensions of reasoning in the wild", "abstract": "Reasoning does not work well when done in isolation from its significance, both to the needs and interests of an agent and with respect to the wider world. Moreover, those issues may best be handled with a new sort of data structure that goes beyond the knowledge base and incorporates aspects of perceptual knowledge and even more, in which a kind of anticipatory action may be key.", "histories": [["v1", "Tue, 23 Aug 2016 00:40:27 GMT  (164kb)", "http://arxiv.org/abs/1608.06349v1", "minor typos corrected from AAAI version, Proceedings (Blue-Sky track) AAAI-2016, Phoenix AZ"]], "COMMENTS": "minor typos corrected from AAAI version, Proceedings (Blue-Sky track) AAAI-2016, Phoenix AZ", "reviews": [], "SUBJECTS": "cs.AI", "authors": ["don perlis"], "accepted": true, "id": "1608.06349"}, "pdf": {"name": "1608.06349.pdf", "metadata": {"source": "CRF", "title": "Five Dimensions of Reasoning in the Wild", "authors": ["Don Perlis"], "emails": ["perlis@cs.umd.edu"], "sections": [{"heading": null, "text": "And it has made a lot of progress, in the form of common sense (CSR), planning, automated theory testing, and more. But, I suspect, it has reached a barrier that needs to be overcome if we are to approach anything like a human conclusion. Here, I give evidence for such a barrier and ideas about how to deal with it, loosely based on evidence from human behavior. In broad summaries, reasoning does not work well when conducted in isolation from its broader meaning, both for the needs and interests of an agent and for the wider world. Moreover, these questions can best be handled with a new type of data structure that goes beyond the knowledge base and aspects of perceptual knowledge, and even more where some kind of anticipatory action plays a key role. I suspect that this has connections with recent calls to bring science back to AI (Levesque 2013, Langley 2012)."}, {"heading": "Proving", "text": "In fact, I would argue that mathematical thinking is much more a question of assessing where you stand, what you have done, and where you should go next, than a question of looking at the next steps, whether things look as expected, and so on. But even that - except in somewhat rare cases of raw calculation, say, an integral - is largely again a question of looking at whether things look as they look, and so on. Equally important is whether there is evidence of sufficient progress going in the same direction, or whether it is time to try something else. So I argue that mathematical skills involve large amounts of comprehensive knowledge of connections, not so much sequential depth."}, {"heading": "Planning", "text": "Suppose 500 sheets of paper are neatly stacked together (in what is known as a giant). If the task is to load them into a printer, this can be done one sheet at a time (terrible); or (possibly) the entire crack at once, or part of it. To tackle this problem itself, the stack must be multiplied as one (a giant) and many (sheets). Furthermore, stating the problem - if it is not to be a highly tasteless exercise in frustration - does not require that all 499 \"on\" relationships between successive sheets be specified. After all, there might not be 500 sheets, but rather an unspecific stack between (say) 400 and 600 sheets. This kind of problem has motivated some (Goldman 2009, Srivastava et al 2015) to address the need for planning systems that can consider loops (do-until) and other constructs that are not part of the usual planners."}, {"heading": "Understanding", "text": "This is the question that arises as to whether this is a political project, which is primarily a political project, which is about putting the interests of the people first, and a political project which is primarily about putting the interests of the people first."}, {"heading": "IRML Structures", "text": "It is, as it is, that we are dealing with an infinite time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, up to a time, in which we are dealing with a time, up to a time, up to a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with a time, in which we are dealing with time, in which we are dealing with time, in which we are dealing with a time, in which we are dealing with a time, in which"}, {"heading": "Related work", "text": "Of course, much work has been done in the field of hypothetical thinking, and even in conjunction with planning and perception; see for example (Gelfond & Lifschitz 1993, Lifschitz 1999 and Baral et al 1997), but as far as I can tell, this does not address the problems of the Winston problem, nor does it seem to be suitable for simulated (real-time dynamic) thinking; there seems to be a very limited work in the field of image processing related to thinking in the way I have described; see for example (Glasgow 1998, Chang et al 2014, Mohan et al 2012)."}, {"heading": "Conclusion", "text": "I suspect that AI - CSR and, of course, planning and vision, but also many other areas such as NLP and even machine learning - will approach human intelligence only if we take the real dynamic link between agent and environment much more seriously. On the other hand, I think that much of the work is clear enough to tackle it. An appropriate form of dynamic, movement-based vision could be part of the solution; the new AI buzzwords could be visions and assessments, rather than traditional generating and testing."}, {"heading": "Acknowledgements", "text": "Thanks to Mike Cox and Vikas Shivashankar for revealing discussions. This material is partly based on the work supported by ONR Grant # N00014-12-1-0430 and ARO Grant # W911NF-12-1-0471."}], "references": [{"title": "Representing actions: laws, observations and hypostheses", "author": ["C. Baral", "Gelfond M", "A. Provetti"], "venue": "J of Logic Programming", "citeRegEx": "Baral et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Baral et al\\.", "year": 1997}, {"title": "Embodied construction grammar in simulation-based language understanding. In Ostman and Fried (Eds) Construction Grammar(s): Cognitive and Cross-Language Dimensions", "author": ["B. Bergen", "N. Chang"], "venue": null, "citeRegEx": "Bergen and Chang,? \\Q2005\\E", "shortCiteRegEx": "Bergen and Chang", "year": 2005}, {"title": "Spatial reasoning in comparative analyses of physics diagrams", "author": ["M. Chang", "J. Wetzel", "K. Forbus"], "venue": "Lecture Notes in Artificial Intelligence", "citeRegEx": "Chang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2014}, {"title": "Mental Spaces", "author": ["G. Fauconnier"], "venue": null, "citeRegEx": "Fauconnier,? \\Q1985\\E", "shortCiteRegEx": "Fauconnier", "year": 1985}, {"title": "Four frames suffice", "author": ["J. Feldman"], "venue": "Behav and Brain Sciences", "citeRegEx": "Feldman,? \\Q1985\\E", "shortCiteRegEx": "Feldman", "year": 1985}, {"title": "Representing action and change by logic programs", "author": ["M. Gelfond", "V. Lifschitz"], "venue": "J. of Logic Programming,", "citeRegEx": "Gelfond and Lifschitz,? \\Q1993\\E", "shortCiteRegEx": "Gelfond and Lifschitz", "year": 1993}, {"title": "A computational framework for unifying vision and language", "author": ["J. Glasgow"], "venue": "International Journal of Psychology,", "citeRegEx": "Glasgow,? \\Q1998\\E", "shortCiteRegEx": "Glasgow", "year": 1998}, {"title": "Partial observability, quantification, and iteration for planning \u2013 work in progress. IACPS", "author": ["R. Goldman"], "venue": null, "citeRegEx": "Goldman,? \\Q2009\\E", "shortCiteRegEx": "Goldman", "year": 2009}, {"title": "Interpreting presuppositions using active logic: from contexts to utterances", "author": ["J. Gurney", "D. Perlis", "K. Puranbg"], "venue": "Computational Intelligence,", "citeRegEx": "Gurney et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Gurney et al\\.", "year": 1997}, {"title": "How much of symbolic manipulation is just symbol pushing", "author": ["D. Landy", "R. Goldstone"], "venue": "Proceedings of the 31st Annual Conference of the Cognitive Science Society (pp. 1072-1077)", "citeRegEx": "Landy and Goldstone,? \\Q2009\\E", "shortCiteRegEx": "Landy and Goldstone", "year": 2009}, {"title": "The cognitive systems paradigm", "author": ["P. Langley"], "venue": "Advances in Cognitive Systems,", "citeRegEx": "Langley,? \\Q2012\\E", "shortCiteRegEx": "Langley", "year": 2012}, {"title": "A cortical network for semantics: (de)constructing the N400", "author": ["E. Lau", "D. Poeppel", "C. Phillips"], "venue": "Nature Reviews Neuroscience,", "citeRegEx": "Lau et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Lau et al\\.", "year": 2008}, {"title": "Cyc: A large-scale investment in knowledge infrastructure", "author": ["D. Lenat"], "venue": "Comm. of ACM,", "citeRegEx": "Lenat,? \\Q1995\\E", "shortCiteRegEx": "Lenat", "year": 1995}, {"title": "Answer set planning", "author": ["V. Lifschitz"], "venue": "Logic Programming and Nonmonotonic Reasoning", "citeRegEx": "Lifschitz,? \\Q1999\\E", "shortCiteRegEx": "Lifschitz", "year": 1999}, {"title": "The mutilated checkerboard in set theory. QED meeting, Warsaw", "author": ["J. McCarthy"], "venue": null, "citeRegEx": "McCarthy,? \\Q1995\\E", "shortCiteRegEx": "McCarthy", "year": 1995}, {"title": "A view of ones past and other aspects of reasoned change in belief. PhD dissertation, University of Maryland", "author": ["M. Miller"], "venue": null, "citeRegEx": "Miller,? \\Q1993\\E", "shortCiteRegEx": "Miller", "year": 1993}, {"title": "Acquiring grounded representations of words with situated interactive instruction", "author": ["S. Mohan", "A. Mininger", "J. Kirk", "J. Laird"], "venue": "Advances in Cognitive Systems,", "citeRegEx": "Mohan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Mohan et al\\.", "year": 2012}, {"title": "Time-situated reasoning eiht tight dealidnes and realistic space and computation bounds", "author": ["M. Nirkhe"], "venue": "PhD dissertation, Comp Sci, U of Maryland,", "citeRegEx": "Nirkhe,? \\Q1994\\E", "shortCiteRegEx": "Nirkhe", "year": 1994}, {"title": "A sensorimotor accouint of vision and visual consciousness", "author": ["J.K. O\u2019Regan", "A. Noe"], "venue": "Behav and Brain Sciences", "citeRegEx": "O.Regan and Noe,? \\Q2001\\E", "shortCiteRegEx": "O.Regan and Noe", "year": 2001}, {"title": "On the consistency of commonsense reasoning", "author": ["D. Perlis"], "venue": "Computational Intelligence,", "citeRegEx": "Perlis,? \\Q1986\\E", "shortCiteRegEx": "Perlis", "year": 1986}, {"title": "How can a program mean? IJCAI", "author": ["D. Perlis"], "venue": null, "citeRegEx": "Perlis,? \\Q1987\\E", "shortCiteRegEx": "Perlis", "year": 1987}, {"title": "Commonsense set theory. In: Meta-level Architectures and Reflection, P", "author": ["D. Perlis"], "venue": null, "citeRegEx": "Perlis,? \\Q1988\\E", "shortCiteRegEx": "Perlis", "year": 1988}, {"title": "Sources of \u2013 and exploiting \u2013 inconsistency: preliminary report", "author": ["D. Perlis"], "venue": "Journal of Applied Non-Classical Logics", "citeRegEx": "Perlis,? \\Q1997\\E", "shortCiteRegEx": "Perlis", "year": 1997}, {"title": "Stop the world \u2013 I want to think", "author": ["D. Perlis", "J. Elgot-Drapkin", "M. Miller"], "venue": "International Journal of Intelligent Systems,", "citeRegEx": "Perlis et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Perlis et al\\.", "year": 1991}, {"title": "Cognitive Carpentry: A Blueprint for How to Build a Person", "author": ["J. Pollock"], "venue": null, "citeRegEx": "Pollock,? \\Q1995\\E", "shortCiteRegEx": "Pollock", "year": 1995}, {"title": "Bagged representations in PDDL", "author": ["P. Riddle", "M. Barley", "S. Franco", "J. Douglas"], "venue": "Workshop on the Intl Planning Competition,", "citeRegEx": "Riddle et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Riddle et al\\.", "year": 2015}, {"title": "Tractability of planning with loops", "author": ["Srivastava", "S.S. Zilberstein", "A. Gupta", "P. Abbeel", "S. Russell"], "venue": null, "citeRegEx": "Srivastava et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 2015}, {"title": "Moving the competition ahead towards more relevant scientific challenges", "author": ["P. Traverso", "M. Ghallab", "D. Nau"], "venue": "Workshop on the Intl Planning Competition,", "citeRegEx": "Traverso et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Traverso et al\\.", "year": 2015}, {"title": "Reasoning about a rule", "author": ["P. Wason"], "venue": "Quarterly Journal of Experimental Psychology,", "citeRegEx": "Wason,? \\Q1968\\E", "shortCiteRegEx": "Wason", "year": 1968}, {"title": "The strong story hypothesis and the directed perception hypothesis", "author": ["P. Winston"], "venue": "AAAI Fall Symposium", "citeRegEx": "Winston,? \\Q2011\\E", "shortCiteRegEx": "Winston", "year": 2011}], "referenceMentions": [{"referenceID": 28, "context": "One quick example at the outset: The Wason Selection Task (Wason 1968) shows that human inference is strongly aided when the details of the task at hand have real meaning that the subjects can relate to in terms of things that matter to them, helping keep attention on what is relevant; and this holds even when the task in the abstract is a matter of so-called pure logic.", "startOffset": 58, "endOffset": 70}, {"referenceID": 15, "context": "(Miller 1993) has made an encouraging start on this latter issue, but in an NLP and CSR setting; see also (Gurney et al 1997).", "startOffset": 0, "endOffset": 13}, {"referenceID": 29, "context": "Patrick Winston (Winston 2011) gives an example that will be instructive here; I paraphrase and elaborate for present purposes: A new table-saw has a red label with the warning \u201cDon\u2019t wear gloves when using this equipment\u201d.", "startOffset": 16, "endOffset": 30}, {"referenceID": 22, "context": "And if they were, it is highly likely that the result would be inconsistent (Perlis 1997).", "startOffset": 76, "endOffset": 89}, {"referenceID": 20, "context": "We switch our thoughts and speculations at will (Perlis 1987).", "startOffset": 48, "endOffset": 61}, {"referenceID": 24, "context": "Let\u2019s call these processes \u201cfast crawlers\u201d \u2013 they \u201ccrawl\u201d over the image again and again, and there are many of them, akin to the \u201cquick and inflexible\u201d modules of (Pollock 1995).", "startOffset": 164, "endOffset": 178}], "year": 2016, "abstractText": "Reasoning does not work well when done in isolation from its significance, both to the needs and interests of an agent and with respect to the wider world. Moreover, those issues may best be handled with a new sort of data structure that goes beyond the knowledge base and incorporates aspects of perceptual knowledge and even more, in which a kind of anticipatory action may be key. Out of the Ivory Tower Reasoning is one of the oldest topics in artificial intelligence (AI). And it has made lots of progress, in the form of commonsense reasoning (CSR), planning, automated theorem-proving, and more. But I suspect it has hit a barrier that must be surmounted if we are to approach anything like human-level inference. Here I give evidence for such a barrier, and ideas about dealing with it, loosely based on evidence from human behavior. In rough synopsis, reasoning does not work well when done in isolation from its broader significance, both for the needs and interests of an agent and for the wider world. Moreover, those issues may best be handled with a new sort of data structure that goes beyond the knowledge base (KB) and incorporates aspects of perceptual knowledge and even more, in which a kind of anticipatory action many be key. I suspect this has ties with recent calls to \u201cput the Science\u201d back in AI (Levesque 2013, Langley 2012). For what I am arguing, in some sense, is that reasoning should be regarded as \u201cin the wild\u201d as events unfold rather than confined to management of an isolated KB; and that this speaks to an agent interacting with the world, rather than a puzzle in abstract inference (yet I will also argue that even \u201cpure\u201d reasoning as in mathematics hugely benefits from many connections with the world). And finally, we then will end up studying the nature of world-embedded cognitive agents, humans included. But this is very broadbrushed and general, whereas my main point is a technical suggestion about reasoning informed by meaning, especially meaning concerning experience and action. This is a slightly modified version of a paper that appeared in AAAI2016. One quick example at the outset: The Wason Selection Task (Wason 1968) shows that human inference is strongly aided when the details of the task at hand have real meaning that the subjects can relate to in terms of things that matter to them, helping keep attention on what is relevant; and this holds even when the task in the abstract is a matter of so-called pure logic. While this could be seen as a defect in human reasoning, something computers would never trip up on, I think it points in the opposite direction: inference without broader meaning is not worth much, and not worth being good at. I will illustrate my main points with a series of examples based on the activities of proving, planning, and understanding.", "creator": "Word"}}}