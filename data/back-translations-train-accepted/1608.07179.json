{"id": "1608.07179", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2016", "title": "Minimizing Quadratic Functions in Constant Time", "abstract": "A sampling-based optimization method for quadratic functions is proposed. Our method approximately solves the following $n$-dimensional quadratic minimization problem in constant time, which is independent of $n$: $z^*=\\min_{\\mathbf{v} \\in \\mathbb{R}^n}\\langle\\mathbf{v}, A \\mathbf{v}\\rangle + n\\langle\\mathbf{v}, \\mathrm{diag}(\\mathbf{d})\\mathbf{v}\\rangle + n\\langle\\mathbf{b}, \\mathbf{v}\\rangle$, where $A \\in \\mathbb{R}^{n \\times n}$ is a matrix and $\\mathbf{d},\\mathbf{b} \\in \\mathbb{R}^n$ are vectors. Our theoretical analysis specifies the number of samples $k(\\delta, \\epsilon)$ such that the approximated solution $z$ satisfies $|z - z^*| = O(\\epsilon n^2)$ with probability $1-\\delta$. The empirical performance (accuracy and runtime) is positively confirmed by numerical experiments.", "histories": [["v1", "Thu, 25 Aug 2016 14:43:17 GMT  (186kb)", "http://arxiv.org/abs/1608.07179v1", "An extended abstract will appear in the proceedings of NIPS'16"]], "COMMENTS": "An extended abstract will appear in the proceedings of NIPS'16", "reviews": [], "SUBJECTS": "cs.LG cs.DS stat.ML", "authors": ["kohei hayashi", "yuichi yoshida"], "accepted": true, "id": "1608.07179"}, "pdf": {"name": "1608.07179.pdf", "metadata": {"source": "CRF", "title": "Minimizing Quadratic Functions in Constant Time", "authors": ["Kohei Hayashi"], "emails": ["hayashi.kohei@gmail.com", "yyoshida@nii.ac.jp"], "sections": [{"heading": null, "text": "ar Xiv: 160 8.07 179v 1 [cs.L G] 25 A"}, {"heading": "1 Introduction", "text": "It is one of the most important functional classes in machine learning, statistics and the data mining system. Many basic problems such as linear regression, clustering method, principal component analysis, support for vector machines and core methods can also be formulated as a minimization problem of a quadratic function. (However, in some applications it is sufficient to calculate the minimum value of a quadratic function rather than its solution.) They formulated the estimation problem as a minimization of a quadratic loss and showed that the Pearson divergence, which provides useful information about data, such as the density ratio [18]. They formulated the estimation problem as a minimization of a quadratic loss and showed that the Pearson divergence can be estimated from the minimum value. [19] The least quadratic mutual information is another example that can be calculated in a similar manner."}, {"heading": "2 Preliminaries", "text": "The notation a = b \u00b1 c means that b \u2212 c \u2264 a \u2264 b + c. In this essay we consider only measurable functions and quantities. Let S = (x1,.., xk) be a sequence of k indices in [n]. For a vector v-Rn we denote the constraint from v to S by v | S-Rk; that is, (v | S) i = vxi for each i [k]. For the matrix A-Rn \u00b7 n we denote the constraint from A to S by A | S-Rk \u00b7 k; thus (A | S) ij = axixj for each i, j-Rk]."}, {"heading": "2.1 Dikernels", "text": "Following [12] we designate a (measurable) function f: [0, 1] 2 \u2192 R a Dikernel. A Dikernel is a generalization of a graph [11] which is symmetrical and whose range is limited in [0, 1]. We can consider a Dikernel as a matrix whose index is given by a real value in [0, 1]. We emphasize that the term Dikernel has nothing to do with kernel methods. For two functions f: [0, 1] \u2192 R we define their internal product as < f > = 1 0 f (x) g (x) dx. For a Dikernel W: [0, 1] 2 \u2192 R and a function f: [0, 1] \u2192 R we define a function Wf: [0, 1] \u2192 R as [Wf] \u2192 R as (x) = < W (x, \u00b7), f >.Let W: [0, 1] 2 \u2192 R and a function f: [0]."}, {"heading": "2.2 Matrices and Dikernels", "text": "Let us define W: [0, 1] 2 \u2192 R be a Dikernel and S = (x1,.., xk) a sequence of elements in [0, 1]. Then we define the matrix W | S, Rk \u00b7 k so that (W | S) ij = W (xi, xj).We can construct the Dikernel A: [0, 1] 2 \u2192 R from the matrix A, Rn \u00b7 n as follows. Let us define I1 = [0, 1n], I2 = (1 n, 2 n],...., In = (n,..., 1]. For x, [0, 1] we define in (x, 1] [n] as a unique integer, so that x, Ii. Then we define A, (x, y) = Ain (x) in (y). The main motivation for creating a Dikernel from a matrix is that we can define in this way the distance between two elements that A and that are different from each other S."}, {"heading": "3 Sampling Theorem and the Properties of the Cut Norm", "text": "In this section, we prove the following theory, which states that if we have a sequence of individual elements in [0, 1], [1], [2], [3], [4], [5], [5], [6], [6], [6], [6], [6], [7], [7,], [8], [8], [8, [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8],], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8], [8],], [8], [8, [8], [8],], [8], [8], [8], [8], [8], [8],], [8],], [8], [8], [8], [8], [8], [8],], [8,],], [8],], ["}, {"heading": "4 Analysis of Algorithm 1", "text": "In this section we analyze algorithms that have a matrix and a b = > We assume that we have a continuous version of pn, a, d, b (callback (1).The real rated function Pn, a, d, b on the functions f: [0, 1] \u2192 R is defined as asPn, a, d, b (f) = < f, a, f, b, b, b on the functions f: [0, 1] < f, b, 1 on the functions f: [0, 1] \u2192 R is a function like f2 (x) = f (x) = f (x) 2 on each x x [0, 1] and 1: [0, 1] \u2192 R is the constant function that has a value of 1 everywhere. The following problem states that the minimizations of pn, A, d, b and Pn, A, d, b are equivalent: Lemma 4.1."}, {"heading": "5 Experiments", "text": "In this section, we demonstrate the effectiveness of our method by experiment. All experiments were performed on an Amazon EC2 c3.8xlarge instance. Error bars show the standard deviations over ten attempts with different random seedings. Numerical simulation We investigated the actual relationships between n, k and C. For this purpose, we processed synthetic data as follows: We randomly generated inputs such as Aij \u0445 U [\u2212 1.1], di \u00b2 U [0.1], and bi \u0445 U [\u2212 1.1] for i, j [n], where U [a, b] provided the uniform distribution with support [a, b]. Then we solved (1) by using algorithm 1 \u2212 and compared it with the exact solution achieved by QP.1 The result (Figure 1) shows the approximation errors were evenly controlled, independent of n, which corresponds to the error analysis (Theorem 4.2).Application to the kernel methods Next, we looked at the kernel approximation of the Pearson [-21]."}, {"heading": "6 Acknowledgments", "text": "We would like to thank Makoto Yamada for suggesting a motivating problem with our method. K. H. is supported by MEXT KAKENHI 15K16055. Y. is supported by MEXT Grant-in-Aid for Scientific Research on Innovative Areas (No. 24106001), JST, CREST, Foundations of Innovative Algorithms for Big Data and JST, ERATO, Kawarabayashi Large Graph Project."}], "references": [{"title": "Random sampling and approximation of MAX- CSP problems", "author": ["N. Alon", "W.F. de la Vega", "R. Kannan", "M. Karpinski"], "venue": "In STOC,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2002}, {"title": "A combinatorial characterization of the testable graph properties: It\u2019s all about regularity", "author": ["N. Alon", "E. Fischer", "I. Newman", "A. Shapira"], "venue": "SIAM Journal on Computing,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2009}, {"title": "Graph limits and parameter testing", "author": ["C. Borgs", "J. Chayes", "L. Lov\u00e1sz", "V.T. S\u00f3s", "B. Szegedy", "K. Vesztergombi"], "venue": "In STOC,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "Convergent sequences of dense graphs i: Subgraph frequencies, metric properties and testing", "author": ["C. Borgs", "J.T. Chayes", "L. Lov\u00e1sz", "V.T. S\u00f3s", "K. Vesztergombi"], "venue": "Advances in Mathematics,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2008}, {"title": "Stochastic learning", "author": ["L. Bottou"], "venue": "In Advanced Lectures on Machine Learning,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2004}, {"title": "Feasible real random access machines", "author": ["V. Brattka", "P. Hertling"], "venue": "Journal of Complexity,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 1998}, {"title": "Sublinear optimization for machine learning", "author": ["K.L. Clarkson", "E. Hazan", "D.P. Woodruff"], "venue": "Journal of the ACM,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2012}, {"title": "The regularity lemma and approximation schemes for dense problems", "author": ["A. Frieze", "R. Kannan"], "venue": "In FOCS,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1996}, {"title": "Property testing and its connection to learning and approximation", "author": ["O. Goldreich", "S. Goldwasser", "D. Ron"], "venue": "Journal of the ACM,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1998}, {"title": "Large Networks and Graph Limits", "author": ["L. Lov\u00e1sz"], "venue": "American Mathematical Society,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2012}, {"title": "Limits of dense graph sequences", "author": ["L. Lov\u00e1sz", "B. Szegedy"], "venue": "Journal of Combinatorial Theory, Series B,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2006}, {"title": "Non-deterministic graph property testing", "author": ["L. Lov\u00e1sz", "K. Vesztergombi"], "venue": "Combinatorics, Probability and Computing,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Yet another algorithm for dense max cut: go greedy", "author": ["C. Mathieu", "W. Schudy"], "venue": "In SODA,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2008}, {"title": "Machine learning: a probabilistic perspective", "author": ["K.P. Murphy"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Constant-time approximation algorithms via local improvements", "author": ["H.N. Nguyen", "K. Onak"], "venue": "In FOCS,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "A near-optimal sublinear-time algorithm for approximating the minimum vertex cover size", "author": ["K. Onak", "D. Ron", "M. Rosen", "R. Rubinfeld"], "venue": "In SODA,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Robust characterizations of polynomials with applications to program testing", "author": ["R. Rubinfeld", "M. Sudan"], "venue": "SIAM Journal on Computing,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1996}, {"title": "Density Ratio Estimation in Machine Learning", "author": ["M. Sugiyama", "T. Suzuki", "T. Kanamori"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2012}, {"title": "Least-Squares Independent Component Analysis", "author": ["T. Suzuki", "M. Sugiyama"], "venue": "Neural Computation,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Using the nystr\u00f6m method to speed up kernel machines", "author": ["C.K.I. Williams", "M. Seeger"], "venue": "In NIPS,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2001}, {"title": "Relative density-ratio estimation for robust distribution comparison", "author": ["M. Yamada", "T. Suzuki", "T. Kanamori", "H. Hachiya", "M. Sugiyama"], "venue": "In NIPS,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2011}, {"title": "Optimal constant-time approximation algorithms and (unconditional) inapproximability results for every bounded-degree CSP", "author": ["Y. Yoshida"], "venue": "In STOC,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "A characterization of locally testable affine-invariant properties via decomposition theorems", "author": ["Y. Yoshida"], "venue": "In STOC,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Gowers norm, function limits, and parameter estimation", "author": ["Y. Yoshida"], "venue": "In SODA,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2016}, {"title": "Improved constant-time approximation algorithms for maximum matchings and other optimization problems", "author": ["Y. Yoshida", "M. Yamamoto", "H. Ito"], "venue": "SIAM Journal on Computing,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}], "referenceMentions": [{"referenceID": 13, "context": "Many fundamental problems such as linear regression, k-means clustering, principal component analysis, support vector machines, and kernel methods [14] can be formulated as a minimization problem of a quadratic function.", "startOffset": 147, "endOffset": 151}, {"referenceID": 20, "context": "[21] proposed an efficient method for estimating the Pearson divergence, which provides useful information about data, such as the density ratio [18].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "[21] proposed an efficient method for estimating the Pearson divergence, which provides useful information about data, such as the density ratio [18].", "startOffset": 145, "endOffset": 149}, {"referenceID": 18, "context": "The least-squares mutual information [19] is another example that can be computed in a similar manner.", "startOffset": 37, "endOffset": 41}, {"referenceID": 4, "context": "A nice property of this method is that, if the objective function is strongly convex, it outputs a point that is sufficiently close to an optimal solution after a constant number of iterations [5].", "startOffset": 193, "endOffset": 196}, {"referenceID": 19, "context": "Another technique is lowrank approximation such as Nystr\u00f6m\u2019s method [20].", "startOffset": 68, "endOffset": 72}, {"referenceID": 6, "context": "[7] proposed sublinear-time algorithms for special cases of quadratic function minimization.", "startOffset": 0, "endOffset": 3}, {"referenceID": 5, "context": "Here, we assume the real RAM model [6], in which we can perform basic algebraic operations on real numbers in one step.", "startOffset": 35, "endOffset": 38}, {"referenceID": 10, "context": "To this end, we exploit graph limit theory, initiated by Lov\u00e1sz and Szegedy [11] (refer to [10] for a book), in which we measure the distance between two graphs on different number of vertices by considering continuous versions.", "startOffset": 76, "endOffset": 80}, {"referenceID": 9, "context": "To this end, we exploit graph limit theory, initiated by Lov\u00e1sz and Szegedy [11] (refer to [10] for a book), in which we measure the distance between two graphs on different number of vertices by considering continuous versions.", "startOffset": 91, "endOffset": 95}, {"referenceID": 7, "context": "Related work: Several constant-time approximation algorithms are known for combinatorial optimization problems such as the max cut problem on dense graphs [8, 13], constraint satisfaction problems [1, 22], and the vertex cover problem [15, 16, 25].", "startOffset": 155, "endOffset": 162}, {"referenceID": 12, "context": "Related work: Several constant-time approximation algorithms are known for combinatorial optimization problems such as the max cut problem on dense graphs [8, 13], constraint satisfaction problems [1, 22], and the vertex cover problem [15, 16, 25].", "startOffset": 155, "endOffset": 162}, {"referenceID": 0, "context": "Related work: Several constant-time approximation algorithms are known for combinatorial optimization problems such as the max cut problem on dense graphs [8, 13], constraint satisfaction problems [1, 22], and the vertex cover problem [15, 16, 25].", "startOffset": 197, "endOffset": 204}, {"referenceID": 21, "context": "Related work: Several constant-time approximation algorithms are known for combinatorial optimization problems such as the max cut problem on dense graphs [8, 13], constraint satisfaction problems [1, 22], and the vertex cover problem [15, 16, 25].", "startOffset": 197, "endOffset": 204}, {"referenceID": 14, "context": "Related work: Several constant-time approximation algorithms are known for combinatorial optimization problems such as the max cut problem on dense graphs [8, 13], constraint satisfaction problems [1, 22], and the vertex cover problem [15, 16, 25].", "startOffset": 235, "endOffset": 247}, {"referenceID": 15, "context": "Related work: Several constant-time approximation algorithms are known for combinatorial optimization problems such as the max cut problem on dense graphs [8, 13], constraint satisfaction problems [1, 22], and the vertex cover problem [15, 16, 25].", "startOffset": 235, "endOffset": 247}, {"referenceID": 24, "context": "Related work: Several constant-time approximation algorithms are known for combinatorial optimization problems such as the max cut problem on dense graphs [8, 13], constraint satisfaction problems [1, 22], and the vertex cover problem [15, 16, 25].", "startOffset": 235, "endOffset": 247}, {"referenceID": 8, "context": "A related notion is property testing [9, 17], which aims to design constant-time algorithms that distinguish inputs satisfying some predetermined property from inputs that are \u201cfar\u201d from satisfying it.", "startOffset": 37, "endOffset": 44}, {"referenceID": 16, "context": "A related notion is property testing [9, 17], which aims to design constant-time algorithms that distinguish inputs satisfying some predetermined property from inputs that are \u201cfar\u201d from satisfying it.", "startOffset": 37, "endOffset": 44}, {"referenceID": 1, "context": "Characterizations of constant-time testable properties are known for the properties of a dense graph [2, 3] and the affine-invariant properties of a function on a finite field [23, 24].", "startOffset": 101, "endOffset": 107}, {"referenceID": 2, "context": "Characterizations of constant-time testable properties are known for the properties of a dense graph [2, 3] and the affine-invariant properties of a function on a finite field [23, 24].", "startOffset": 101, "endOffset": 107}, {"referenceID": 22, "context": "Characterizations of constant-time testable properties are known for the properties of a dense graph [2, 3] and the affine-invariant properties of a function on a finite field [23, 24].", "startOffset": 176, "endOffset": 184}, {"referenceID": 23, "context": "Characterizations of constant-time testable properties are known for the properties of a dense graph [2, 3] and the affine-invariant properties of a function on a finite field [23, 24].", "startOffset": 176, "endOffset": 184}, {"referenceID": 11, "context": "1 Dikernels Following [12], we call a (measurable) function f : [0, 1] \u2192 R a dikernel.", "startOffset": 22, "endOffset": 26}, {"referenceID": 0, "context": "1 Dikernels Following [12], we call a (measurable) function f : [0, 1] \u2192 R a dikernel.", "startOffset": 64, "endOffset": 70}, {"referenceID": 10, "context": "A dikernel is a generalization of a graphon [11], which is symmetric and whose range is bounded in [0, 1].", "startOffset": 44, "endOffset": 48}, {"referenceID": 0, "context": "A dikernel is a generalization of a graphon [11], which is symmetric and whose range is bounded in [0, 1].", "startOffset": 99, "endOffset": 105}, {"referenceID": 0, "context": "We can regard a dikernel as a matrix whose index is specified by a real value in [0, 1].", "startOffset": 81, "endOffset": 87}, {"referenceID": 0, "context": "For two functions f, g : [0, 1] \u2192 R, we define their inner product as \u3008f, g\u3009 = \u222b 1 0 f(x)g(x)dx.", "startOffset": 25, "endOffset": 31}, {"referenceID": 0, "context": "For a dikernel W : [0, 1] \u2192 R and a function f : [0, 1] \u2192 R, we define a function Wf : [0, 1] \u2192 R as (Wf)(x) = \u3008W (x, \u00b7), f\u3009.", "startOffset": 19, "endOffset": 25}, {"referenceID": 0, "context": "For a dikernel W : [0, 1] \u2192 R and a function f : [0, 1] \u2192 R, we define a function Wf : [0, 1] \u2192 R as (Wf)(x) = \u3008W (x, \u00b7), f\u3009.", "startOffset": 49, "endOffset": 55}, {"referenceID": 0, "context": "For a dikernel W : [0, 1] \u2192 R and a function f : [0, 1] \u2192 R, we define a function Wf : [0, 1] \u2192 R as (Wf)(x) = \u3008W (x, \u00b7), f\u3009.", "startOffset": 87, "endOffset": 93}, {"referenceID": 0, "context": "Let W : [0, 1] \u2192 R be a dikernel.", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "The Lp norm \u2016W\u2016p for p \u2265 1 and the cut norm \u2016W\u2016 of W are defined as \u2016W\u2016p = (\u222b 1 0 \u222b 1 0 |W (x, y)|dxdy )1/p and \u2016W\u2016 = supS,T\u2286[0,1] \u2223\u2223 \u222b S \u222b T W (x, y)dxdy \u2223\u2223, respectively, where the supremum is over all pairs of subsets.", "startOffset": 125, "endOffset": 130}, {"referenceID": 0, "context": "A map \u03c0 : [0, 1] \u2192 [0, 1] is said to be measure-preserving, if the pre-image \u03c0(X) is measurable for every measurable set X , and \u03bb(\u03c0(X)) = \u03bb(X).", "startOffset": 10, "endOffset": 16}, {"referenceID": 0, "context": "A map \u03c0 : [0, 1] \u2192 [0, 1] is said to be measure-preserving, if the pre-image \u03c0(X) is measurable for every measurable set X , and \u03bb(\u03c0(X)) = \u03bb(X).", "startOffset": 19, "endOffset": 25}, {"referenceID": 0, "context": "For a measure preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] and a dikernel W : [0, 1] \u2192 R, we define the dikernel \u03c0(W ) : [0, 1] \u2192 R as \u03c0(W )(x, y) = W (\u03c0(x), \u03c0(y)).", "startOffset": 39, "endOffset": 45}, {"referenceID": 0, "context": "For a measure preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] and a dikernel W : [0, 1] \u2192 R, we define the dikernel \u03c0(W ) : [0, 1] \u2192 R as \u03c0(W )(x, y) = W (\u03c0(x), \u03c0(y)).", "startOffset": 48, "endOffset": 54}, {"referenceID": 0, "context": "For a measure preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] and a dikernel W : [0, 1] \u2192 R, we define the dikernel \u03c0(W ) : [0, 1] \u2192 R as \u03c0(W )(x, y) = W (\u03c0(x), \u03c0(y)).", "startOffset": 74, "endOffset": 80}, {"referenceID": 0, "context": "For a measure preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] and a dikernel W : [0, 1] \u2192 R, we define the dikernel \u03c0(W ) : [0, 1] \u2192 R as \u03c0(W )(x, y) = W (\u03c0(x), \u03c0(y)).", "startOffset": 117, "endOffset": 123}, {"referenceID": 0, "context": "2 Matrices and Dikernels Let W : [0, 1] \u2192 R be a dikernel and S = (x1, .", "startOffset": 33, "endOffset": 39}, {"referenceID": 0, "context": ", xk) be a sequence of elements in [0, 1].", "startOffset": 35, "endOffset": 41}, {"referenceID": 0, "context": "We can construct the dikernel \u00c2 : [0, 1] \u2192 R from the matrix A \u2208 R as follows.", "startOffset": 34, "endOffset": 40}, {"referenceID": 0, "context": "For x \u2208 [0, 1], we define in(x) \u2208 [n] as a unique integer such that x \u2208 Ii.", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "We note that the distribution of A|S , where S is a sequence of k indices that are uniformly and independently sampled from [n] exactly matches the distribution of \u00c2|S , where S is a sequence of k elements that are uniformly and independently sampled from [0, 1].", "startOffset": 256, "endOffset": 262}, {"referenceID": 0, "context": ",W : [0, 1] \u2192 [\u2212L,L], we can obtain a good approximation to them by sampling a sequence of a small number of elements in [0, 1].", "startOffset": 5, "endOffset": 11}, {"referenceID": 0, "context": ",W : [0, 1] \u2192 [\u2212L,L], we can obtain a good approximation to them by sampling a sequence of a small number of elements in [0, 1].", "startOffset": 121, "endOffset": 127}, {"referenceID": 0, "context": ",W : [0, 1] \u2192 [\u2212L,L] be dikernels.", "startOffset": 5, "endOffset": 11}, {"referenceID": 0, "context": "Let S be a sequence of k elements uniformly and independently sampled from [0, 1].", "startOffset": 75, "endOffset": 81}, {"referenceID": 0, "context": "Then, with a probability of at least 1\u2212 exp(\u2212\u03a9(kT/ log2 k)), there exists a measure-preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] such that, for any functions f, g : [0, 1] \u2192 [\u2212K,K] and t \u2208 [T ], we have |\u3008f,W g\u3009 \u2212 \u3008f, \u03c0(\u0174 |S)g\u3009| = O ( LK \u221a T/ log2 k ) .", "startOffset": 109, "endOffset": 115}, {"referenceID": 0, "context": "Then, with a probability of at least 1\u2212 exp(\u2212\u03a9(kT/ log2 k)), there exists a measure-preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] such that, for any functions f, g : [0, 1] \u2192 [\u2212K,K] and t \u2208 [T ], we have |\u3008f,W g\u3009 \u2212 \u3008f, \u03c0(\u0174 |S)g\u3009| = O ( LK \u221a T/ log2 k ) .", "startOffset": 118, "endOffset": 124}, {"referenceID": 0, "context": "Then, with a probability of at least 1\u2212 exp(\u2212\u03a9(kT/ log2 k)), there exists a measure-preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] such that, for any functions f, g : [0, 1] \u2192 [\u2212K,K] and t \u2208 [T ], we have |\u3008f,W g\u3009 \u2212 \u3008f, \u03c0(\u0174 |S)g\u3009| = O ( LK \u221a T/ log2 k ) .", "startOffset": 161, "endOffset": 167}, {"referenceID": 0, "context": "We start with the following lemma, which states that, if a dikernel W : [0, 1] \u2192 R has a small cut norm, then \u3008f,Wf\u3009 is negligible no matter what f is.", "startOffset": 72, "endOffset": 78}, {"referenceID": 0, "context": "Let \u01eb \u2265 0 and W : [0, 1] \u2192 R be a dikernel with \u2016W\u2016 \u2264 \u01eb.", "startOffset": 18, "endOffset": 24}, {"referenceID": 0, "context": "Then, for any functions f, g : [0, 1] \u2192 [\u2212K,K], we have |\u3008f,Wg\u3009| \u2264 \u01ebK.", "startOffset": 31, "endOffset": 37}, {"referenceID": 0, "context": "For \u03c4 \u2208 R and the function h : [0, 1] \u2192 R, let L\u03c4 (h) := {x \u2208 [0, 1] | h(x) = \u03c4} be the level set of h at \u03c4 .", "startOffset": 31, "endOffset": 37}, {"referenceID": 0, "context": "For \u03c4 \u2208 R and the function h : [0, 1] \u2192 R, let L\u03c4 (h) := {x \u2208 [0, 1] | h(x) = \u03c4} be the level set of h at \u03c4 .", "startOffset": 62, "endOffset": 68}, {"referenceID": 0, "context": ", Vp) of the interval [0, 1] is called an equipartition if \u03bb(Vi) = 1/p for every i \u2208 [p].", "startOffset": 22, "endOffset": 28}, {"referenceID": 0, "context": "For the dikernel W : [0, 1] \u2192 R and the equipartition P = (V1, .", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": ", Vp) of [0, 1], we define WP : [0, 1] \u2192 R as the function obtained by averaging each Vi \u00d7 Vj for i, j \u2208 [p].", "startOffset": 9, "endOffset": 15}, {"referenceID": 0, "context": ", Vp) of [0, 1], we define WP : [0, 1] \u2192 R as the function obtained by averaging each Vi \u00d7 Vj for i, j \u2208 [p].", "startOffset": 32, "endOffset": 38}, {"referenceID": 0, "context": "The following lemma states that any function W : [0, 1] \u2192 R can be well approximated by WP for the equipartition P into a small number of parts.", "startOffset": 49, "endOffset": 55}, {"referenceID": 0, "context": "3 (Weak regularity lemma for functions on [0, 1] [8]).", "startOffset": 42, "endOffset": 48}, {"referenceID": 7, "context": "3 (Weak regularity lemma for functions on [0, 1] [8]).", "startOffset": 49, "endOffset": 52}, {"referenceID": 0, "context": "Let P be an equipartition of [0, 1] into k sets.", "startOffset": 29, "endOffset": 35}, {"referenceID": 0, "context": "Then, for any dikernel W : [0, 1] \u2192 R and \u01eb > 0, there exists a refinement Q of P with |Q| \u2264 k2 2 for some constant C > 0 such that \u2016W \u2212WQ\u2016 \u2264 \u01eb\u2016W\u20162.", "startOffset": 27, "endOffset": 33}, {"referenceID": 0, "context": ",W : [0, 1] \u2192 R be dikernels.", "startOffset": 5, "endOffset": 11}, {"referenceID": 3, "context": "15) of [4]).", "startOffset": 7, "endOffset": 10}, {"referenceID": 0, "context": "Let W : [0, 1] \u2192 [\u2212L,L] be a dikernel and S be a sequence of k elements uniformly and independently sampled from [0, 1].", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "Let W : [0, 1] \u2192 [\u2212L,L] be a dikernel and S be a sequence of k elements uniformly and independently sampled from [0, 1].", "startOffset": 113, "endOffset": 119}, {"referenceID": 0, "context": ",W : [0, 1] \u2192 [\u2212L,L] be dikernels.", "startOffset": 5, "endOffset": 11}, {"referenceID": 0, "context": "Let S be a sequence of k elements uniformly and independently sampled from [0, 1].", "startOffset": 75, "endOffset": 81}, {"referenceID": 0, "context": "Then, with a probability of at least 1\u2212 exp(\u2212\u03a9(kT/ log2 k)), there exists a measure-preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] such that, for every t \u2208 [T ], we have \u2016W t \u2212 \u03c0(\u0174 |S)\u2016 = O ( L \u221a T/ log2 k ) .", "startOffset": 109, "endOffset": 115}, {"referenceID": 0, "context": "Then, with a probability of at least 1\u2212 exp(\u2212\u03a9(kT/ log2 k)), there exists a measure-preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] such that, for every t \u2208 [T ], we have \u2016W t \u2212 \u03c0(\u0174 |S)\u2016 = O ( L \u221a T/ log2 k ) .", "startOffset": 118, "endOffset": 124}, {"referenceID": 0, "context": "Then, for any measure-preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] and t \u2208 [T ], we have ES\u2016W t \u2212 \u03c0(\u0174 |S)\u2016 \u2264 \u2016W t \u2212W t P\u2016 +ES\u2016W t P \u2212 \u03c0(\u0174 t P |S)\u2016 +ES\u2016\u03c0(\u0174 t P |S)\u2212 \u03c0(\u0174 |S)\u2016 \u2264 2\u01ebL+ 8L k1/4 +ES\u2016W t P \u2212 \u03c0(\u0174 t P |S)\u2016 .", "startOffset": 47, "endOffset": 53}, {"referenceID": 0, "context": "Then, for any measure-preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] and t \u2208 [T ], we have ES\u2016W t \u2212 \u03c0(\u0174 |S)\u2016 \u2264 \u2016W t \u2212W t P\u2016 +ES\u2016W t P \u2212 \u03c0(\u0174 t P |S)\u2016 +ES\u2016\u03c0(\u0174 t P |S)\u2212 \u03c0(\u0174 |S)\u2016 \u2264 2\u01ebL+ 8L k1/4 +ES\u2016W t P \u2212 \u03c0(\u0174 t P |S)\u2016 .", "startOffset": 56, "endOffset": 62}, {"referenceID": 0, "context": ", xk} be a sequence of independent random variables that are uniformly distributed in [0, 1], and let Zi be the number of points xj that fall into the set Vi.", "startOffset": 86, "endOffset": 92}, {"referenceID": 0, "context": "The partition P \u2032 of [0, 1] is constructed into the sets V \u2032 1 , .", "startOffset": 21, "endOffset": 27}, {"referenceID": 0, "context": "For each t \u2208 [T ], we construct the dikernel W t : [0, 1] \u2192 R such that the value of W t on V \u2032 i \u00d7 V \u2032 j is the same as the value of W t P on Vi \u00d7 Vj .", "startOffset": 51, "endOffset": 57}, {"referenceID": 0, "context": "The real-valued function Pn,A,d,b on the functions f : [0, 1] \u2192 R is defined as Pn,A,d,b(f) = \u3008f, \u00c2f\u3009+ \u3008f , d\u03021\u22a41\u3009+ \u3008f, b\u03021\u22a41\u3009, where f : [0, 1] \u2192 R is a function such that f(x) = f(x) for every x \u2208 [0, 1] and 1 : [0, 1] \u2192 R is the constant function that has a value of 1 everywhere.", "startOffset": 55, "endOffset": 61}, {"referenceID": 0, "context": "The real-valued function Pn,A,d,b on the functions f : [0, 1] \u2192 R is defined as Pn,A,d,b(f) = \u3008f, \u00c2f\u3009+ \u3008f , d\u03021\u22a41\u3009+ \u3008f, b\u03021\u22a41\u3009, where f : [0, 1] \u2192 R is a function such that f(x) = f(x) for every x \u2208 [0, 1] and 1 : [0, 1] \u2192 R is the constant function that has a value of 1 everywhere.", "startOffset": 138, "endOffset": 144}, {"referenceID": 0, "context": "The real-valued function Pn,A,d,b on the functions f : [0, 1] \u2192 R is defined as Pn,A,d,b(f) = \u3008f, \u00c2f\u3009+ \u3008f , d\u03021\u22a41\u3009+ \u3008f, b\u03021\u22a41\u3009, where f : [0, 1] \u2192 R is a function such that f(x) = f(x) for every x \u2208 [0, 1] and 1 : [0, 1] \u2192 R is the constant function that has a value of 1 everywhere.", "startOffset": 199, "endOffset": 205}, {"referenceID": 0, "context": "The real-valued function Pn,A,d,b on the functions f : [0, 1] \u2192 R is defined as Pn,A,d,b(f) = \u3008f, \u00c2f\u3009+ \u3008f , d\u03021\u22a41\u3009+ \u3008f, b\u03021\u22a41\u3009, where f : [0, 1] \u2192 R is a function such that f(x) = f(x) for every x \u2208 [0, 1] and 1 : [0, 1] \u2192 R is the constant function that has a value of 1 everywhere.", "startOffset": 214, "endOffset": 220}, {"referenceID": 0, "context": "Then, we have min v\u2208[\u2212K,K]n pn,A,d,b(v) = n 2 \u00b7 inf f :[0,1]\u2192[\u2212K,K] Pn,A,d,b(f).", "startOffset": 55, "endOffset": 60}, {"referenceID": 0, "context": "First, we show that n \u00b7 inff :[0,1]\u2192[\u2212K,K] Pn,A,d,b(f) \u2264 minv\u2208[\u2212K,K]n pn,A,d,b(v).", "startOffset": 30, "endOffset": 35}, {"referenceID": 0, "context": "Given a vector v \u2208 [\u2212K,K], we define f : [0, 1] \u2192 [\u2212K,K] as f(x) = vin(x).", "startOffset": 41, "endOffset": 47}, {"referenceID": 0, "context": "Next, we show that minv\u2208[\u2212K,K]n pn,A,d,b(v) \u2264 n \u00b7 inff :[0,1]\u2192[\u2212K,K] Pn,A,d,b(f).", "startOffset": 56, "endOffset": 61}, {"referenceID": 0, "context": "Let f : [0, 1] \u2192 [\u2212K,K] be a measurable function.", "startOffset": 8, "endOffset": 14}, {"referenceID": 0, "context": "Then, for x \u2208 [0, 1], we have \u2202Pn,A,d,b(f(x)) \u2202f(x) = \u2211", "startOffset": 14, "endOffset": 20}, {"referenceID": 0, "context": "Note that the form of this partial derivative only depends on in(x); hence, in the optimal solution f : [0, 1] \u2192 [\u2212K,K], we can assume f(x) = f(y) if in(x) = in(y).", "startOffset": 104, "endOffset": 110}, {"referenceID": 0, "context": "For such f, we define the vector v \u2208 R as vi = f (x), where x \u2208 [0, 1] is any element in Ii.", "startOffset": 64, "endOffset": 70}, {"referenceID": 0, "context": "Then, with a probability of at least 1\u2212 \u03b4, there exists a measure preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] such that", "startOffset": 91, "endOffset": 97}, {"referenceID": 0, "context": "Then, with a probability of at least 1\u2212 \u03b4, there exists a measure preserving bijection \u03c0 : [0, 1] \u2192 [0, 1] such that", "startOffset": 100, "endOffset": 106}, {"referenceID": 0, "context": "max { |\u3008f, (\u00c2\u2212 \u03c0(\u00c2|S))f\u3009|, |\u3008f , (d\u03021\u22a4 \u2212 \u03c0(d\u03021|S))1\u3009|, |\u3008f, (b\u03021\u22a4 \u2212 \u03c0(b\u03021|S))1\u3009| } \u2264 \u01ebLK 3 for any function f : [0, 1] \u2192 [\u2212K,K].", "startOffset": 112, "endOffset": 118}, {"referenceID": 0, "context": "Then, we have z\u0303 = min v\u2208Rk pk,A|S ,d|S,b|S(v) = min v\u2208[\u2212K,K]k pk,A|S,d|S ,b|S(v) = k \u00b7 inf f :[0,1]\u2192[\u2212K,K] Pk,A|S ,d|S,b|S(f) (By Lemma 4.", "startOffset": 95, "endOffset": 100}, {"referenceID": 0, "context": "1) = k \u00b7 inf f :[0,1]\u2192[\u2212K,K] ( \u3008f, (\u03c0(\u00c2|S)\u2212 \u00c2)f\u3009+ \u3008f, \u00c2f\u3009+ \u3008f , (\u03c0(d\u03021|S)\u2212 d\u03021\u22a4)1\u3009+ \u3008f , d\u03021\u22a41\u3009+", "startOffset": 16, "endOffset": 21}, {"referenceID": 0, "context": "\u2264 k \u00b7 inf f :[0,1]\u2192[\u2212K,K] ( \u3008f, \u00c2f\u3009+ \u3008f, d\u03021\u22a41\u3009+ \u3008f, b\u03021\u22a41\u3009 \u00b1 \u01ebLK )", "startOffset": 13, "endOffset": 18}, {"referenceID": 0, "context": "We randomly generated inputs as Aij \u223c U[\u22121,1], di \u223c U[0,1], and bi \u223c U[\u22121,1] for i, j \u2208 [n], where U[a,b] denotes the uniform distribution with the support [a, b].", "startOffset": 53, "endOffset": 58}, {"referenceID": 20, "context": "Application to kernel methods Next, we considered the kernel approximation of the Pearson divergence [21].", "startOffset": 101, "endOffset": 105}, {"referenceID": 20, "context": "5; \u03c3 and \u03bb were chosen by 5-fold cross-validation as suggested in [21].", "startOffset": 66, "endOffset": 70}], "year": 2016, "abstractText": "A sampling-based optimization method for quadratic functions is proposed. Our method approximately solves the following n-dimensional quadratic minimization problem in constant time, which is independent of n: z = minv\u2208Rn\u3008v, Av\u3009 + n\u3008v, diag(d)v\u3009 + n\u3008b,v\u3009, where A \u2208 R is a matrix and d, b \u2208 R are vectors. Our theoretical analysis specifies the number of samples k(\u03b4, \u01eb) such that the approximated solution z satisfies |z \u2212 z| = O(\u01ebn) with probability 1\u2212 \u03b4. The empirical performance (accuracy and runtime) is positively confirmed by numerical experiments.", "creator": "LaTeX with hyperref package"}}}