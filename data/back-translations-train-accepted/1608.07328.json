{"id": "1608.07328", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "25-Aug-2016", "title": "Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing", "abstract": "Digital crowdsourcing (CS) is a modern approach to perform certain large projects using small contributions of a large crowd. In CS, a taskmaster typically breaks down the project into small batches of tasks and assigns them to so-called workers with imperfect skill levels. The crowdsourcer then collects and analyzes the results for inference and serving the purpose of the project. In this work, the CS problem, as a human-in-the-loop computation problem, is modeled and analyzed in an information theoretic rate-distortion framework. The purpose is to identify the ultimate fidelity that one can achieve by any form of query from the crowd and any decoding (inference) algorithm with a given budget. The results are established by a joint source channel (de)coding scheme, which represent the query scheme and inference, over parallel noisy channels, which model workers with imperfect skill levels. We also present and analyze a query scheme dubbed $k$-ary incidence coding and study optimized query pricing in this setting.", "histories": [["v1", "Thu, 25 Aug 2016 22:43:46 GMT  (84kb,D)", "http://arxiv.org/abs/1608.07328v1", "Accepted for NIPS 2016, Barcelona, Spain"]], "COMMENTS": "Accepted for NIPS 2016, Barcelona, Spain", "reviews": [], "SUBJECTS": "cs.LG cs.IT math.IT", "authors": ["farshad lahouti", "babak hassibi"], "accepted": true, "id": "1608.07328"}, "pdf": {"name": "1608.07328.pdf", "metadata": {"source": "CRF", "title": "Fundamental Limits of Budget-Fidelity Trade-off in Label Crowdsourcing", "authors": ["Farshad Lahouti"], "emails": ["lahouti@caltech.edu", "hassibi@caltech.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it is more than ever before."}, {"heading": "2 Modeling Crowdsourcing", "text": "In this section, we present a communication system model for crowdsourcing that, as illustrated in Figure 1a, allows an analysis of the basic performance limits of crowdsourcing."}, {"heading": "2.1 Data Set: Source", "text": "Consider a dataset X = {X1,.., XL}, which is composed of L elements, e.g. images. In practice, there are certain FunctionsB (X) and B (X) of the elements that are of interest for crowdsourcing and are considered to be the source here. The value of this function is to be determined for the given dataset by the mass. In the case of crowdsourcing clusters, B (Xi) = Bj-B (X) = {B1,..., BN} indicates the trash or cluster to which the element Xi ideally belongs. We have B (X1,.., Xn) = B (X1),.., B (Xn)). The number of clusters, | B (X) | = N, cannot or may not be a priori known."}, {"heading": "2.2 Crowd Workers: Channels", "text": "The ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the ref for the re"}, {"heading": "2.3 Query Scheme and Inference: Coding", "text": "A basic query is that the worker is asked for the value of B (X). In the example of crowdsourcing for labeling images that are suitable for children, is the query obviously incomplete or wrong? \"The decoder or crowdsourcer collects the answers from workers to the questions and attempts to determine the right label (cluster) for each of the images. This is while the answers collected may be generally incomplete or wrong. In the case of crowdsourcing for labeling a large number of dog images with their breeds, a query can be formed by showing two images at once and inquiring whether they are from the same breed. Indeed, the queries are presented as showing the elements of a binary incidence, A whose rows and columns correspond to X."}, {"heading": "2.4 Distortion and the Design Problem", "text": "In Figure 1a, we are interested in designing the CS code, i.e., the query and follow-up rate, so that a certain CS fidelity is optimized for a given budget. We consider fidelity to be an average distortion in relation to the source (dataset), for a distance function d (B (x), B (x)), for which d (B (xn), B (xn))) = 1n (B (xi), B (xi), B (xi))), for the mean distortion isD (B (X), B (X))) = Ed (B (Xn), B (Xn))) = Xn P (B (n)), B (Xn), B (Xn), X (n), X (n, X, X (n), Xn, X (n, Xn, Xn, Xn, Xn, X( X), X (n, Xn, X (n)."}, {"heading": "3 Information Theoretic CS Budget-Fidelity Limits", "text": "In the CS problem of budget fidelity optimization in (5), the code that provides the optimized solution must actually balance two opposing design criteria in order to achieve the desired CS fidelity: On the one hand, the design aims at efficiency of the query and the lowest possible number of queries; on the other, the code must take into account the imperfection of the response of the workers and include sufficient redundancy. In information theory (coding theory), the former corresponds to the source coding (compression) and the latter to the channel coding (error control coding), and the coding for both purposes is a common source channel coding. In this section, we will first present a brief overview of the coding of common source channels and the associated results in information theory. Next, we present the CS budget fidelity function in two cases of SL-UK and SL-CS, which are described in Section 2.2."}, {"heading": "3.1 Background", "text": "Consider the communication of a random source Z from a finite alphabet Z via a discrete memory scheme. (The source is first communicated by an encoder C and its output via the channel.) The source is iid distributed with the probability of mass function P (Z) and based on Shannon's source coding theorem is often characterized by a rate distortion function. (The rate distortion theorem function, characterizing rate distortion function, R-2). (The rate distortion theorem function, R-2). (The rate distortion theorem function, R-2). (The rate distortion theorem function is initially the case where the channel is error-free. (Z, Z). (8) where we refer to mutual information between two random variables. (Source coding is defined by the following two random variables: C, 2R), C."}, {"heading": "3.2 Basic Information Theoretic Bounds", "text": "We consider crowdsourcing within the framework presented and derive basic theoretical metrics from it. Following Section 2.1, we examine the case in which a large dataset X (L \u00b2) and a function of interest B (X) with a related probability of mass function P (B (X)) are available. We consider the number of workers in each skill class to be large. Here, we examine the two scenarios of SL-UK and SL-CS.In each given instance, a query is made to a random qualification level. We assume that there is no feedback (non-adaptive coding) and the quantities influence channel probabilities (no feedback).The following extensions remain for random qualification levels within the set, E. We assume that there is no feedback."}, {"heading": "4.2 Numerical Results", "text": "In order to obtain an information theory benchmark, Theorem 3 specializes in setting the interest in this paragraph. Conclusion 1 In crowdsourcing for binary identification of an evenly distributed data set with an SHC (q) employee pool - known as Crowdsourcer (SL-CS) - and the number of choices available when answering a query from M, the minimum quota for a given encoding scheme to obtain a probability of error of no more than 1%, isRmin = {1 \u2212 Hb (B) q log2M, 0 \u2264 0.5 0 elsewhere. Queries per point (14) Figure 2 show the information theory limit of Conclusion 1 and the limit reached in Theorem 4. For rates (budgets) greater than the previous limit, there is a code that provides crowdsourcing with the desired fidelity; and for rates below this limit, no such code exists. The coding theoretical sub-limits for analysis depend on kk and Delusion = 1 and Delusion = 1."}, {"heading": "A Proof of Theorem 2", "text": "The parallel MSC channels representing workers with random skill levels can be considered as a random state channel [7]. The proof is based on the optimum of separate source and channel coding [7] (according to Shannon) in large data sets and a labor pool regime that holds with a discrete memoryless source and discrete memoryless channel with random state. Here, we need a lossy source coder to bring the rate to R (D (X), B (X))), B (X))) =. \"If the source is memoryless, then we have R (D) (B), B (X)) = min I (B) \u2212 query (X), B \u2212 query (X) = H (B (X)))))) \u2212 H (D (D (D))), (15), where we have haveR (D), B (X), B (B), X (B), and then we have the RSC (X)."}, {"heading": "B Proof of Theorem 3", "text": "The proof follows the same steps as in Theorem 2. However, the capacity, if the skill levels are known to the crowdsourcer, is given by CSL \u2212 CS = max P (u) I (U; V |) = log2M \u2212 E (HM ()) (18), with the maximum occurring when P (u) = 1 / M. Again, since the task master does not know the skill levels, he can only forward the queries to the workers at an identical rate."}, {"heading": "C Proof of Lemma 1", "text": "The error probability when the query is made to a spammer in an SHC can be quantified as follows: P (E | C = S) = P (E: B \u00b2 (X) 6 = B (X) | C = S) = x (U \u00b2 v \u00b2 V (u, v | C = S) P (E | U = u, V = v, C = S) = x (U \u00b2 V = V) (19) The last uniformity is partly the result of the uniform distribution of the data set (P (B (X) = U = u, V = v, C = S) = x (U \u00b2 V \u00b2 M2P (E | U = u, V = v)."}, {"heading": "D Proof of Theorem 4", "text": "In the SHC model, we consider an oracle decoder that makes an error in task i only if it is assigned only to spammers. Formally, if only spammers are selected in all R \"queries per task (code word), the average error probability on the decoder is P (E: B\" (X) 6 = B (X)) = \u2211 C (E: B \"(X) 6 = B (X) | C1,..., CR\") P (C1,., CR \") = P (E: C = S) \u00b7 (1 \u2212 q) R\" = P (E: C = S) \u00b7 (1 \u2212 q) R \"The last equality follows because the decoder observes R\" spacing of spammers, has no further information than the observation of a single spammer. In the kIC, the number of queries per point X, R, R, is given by R = 1kR."}, {"heading": "E Pricing Strategy", "text": "Using Equation (21) (as proof of) the theorem KICBound, one can gain some insights into the design of a CS system based on kIC. In the following, we will consider this in the context of price queries. In particular, in crowdsourcing with kIC query scheme with a spammer-hammer distribution of the hammer probability q, we will consider two scenarios: (i) the case in which the price of the query per article is fixed at k and does not change at k, and (ii) the case in which the query price is a function of k, \u03c0 (k). In the first case, one can easily investigate that since P (E | C = S) grows very slowly with k in Lemma 1, any increase of k directly leads to a lower rate R and therefore crowdsourcing costs at a given crowdsourcing value (K). In the second case, however, the analysis kos highlights the appropriate price threshold."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Digital crowdsourcing (CS) is a modern approach to perform certain large projects<lb>using small contributions of a large crowd. In CS, a taskmaster typically breaks<lb>down the project into small batches of tasks and assigns them to so-called workers<lb>with imperfect skill levels. The crowdsourcer then collects and analyzes the results<lb>for inference and serving the purpose of the project. In this work, the CS problem,<lb>as a human-in-the-loop computation problem, is modeled and analyzed in an<lb>information theoretic rate-distortion framework. The purpose is to identify the<lb>ultimate fidelity that one can achieve by any form of query from the crowd and any<lb>decoding (inference) algorithm with a given budget. The results are established<lb>by a joint source channel (de)coding scheme, which represent the query scheme<lb>and inference, over parallel noisy channels, which model workers with imperfect<lb>skill levels. We also present and analyze a query scheme dubbed k-ary incidence<lb>coding and study optimized query pricing in this setting.", "creator": "LaTeX with hyperref package"}}}