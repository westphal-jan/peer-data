{"id": "1608.08182", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Aug-2016", "title": "Data Poisoning Attacks on Factorization-Based Collaborative Filtering", "abstract": "Recommendation and collaborative filtering systems are important in modern information and e-commerce applications. As these systems are becoming increasingly popular in the industry, their outputs could affect business decision making, introducing incentives for an adversarial party to compromise the availability or integrity of such systems. We introduce a data poisoning attack on collaborative filtering systems. We demonstrate how a powerful attacker with full knowledge of the learner can generate malicious data so as to maximize his/her malicious objectives, while at the same time mimicking normal user behavior to avoid being detected. While the complete knowledge assumption seems extreme, it enables a robust assessment of the vulnerability of collaborative filtering schemes to highly motivated attacks. We present efficient solutions for two popular factorization-based collaborative filtering algorithms: the \\emph{alternative minimization} formulation and the \\emph{nuclear norm minimization} method. Finally, we test the effectiveness of our proposed algorithms on real-world data and discuss potential defensive strategies.", "histories": [["v1", "Mon, 29 Aug 2016 19:09:27 GMT  (4874kb,D)", "https://arxiv.org/abs/1608.08182v1", null], ["v2", "Wed, 5 Oct 2016 22:26:13 GMT  (4874kb,D)", "http://arxiv.org/abs/1608.08182v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CR cs.IR", "authors": ["bo li", "yining wang", "aarti singh", "yevgeniy vorobeychik"], "accepted": true, "id": "1608.08182"}, "pdf": {"name": "1608.08182.pdf", "metadata": {"source": "CRF", "title": "Data Poisoning Attacks on Factorization-Based Collaborative Filtering", "authors": ["Bo Li", "Yining Wang"], "emails": ["bo.li.2@vanderbilt.edu", "ynwang.yining@gmail.com", "aarti@cs.cmu.edu", "yevgeniy.vorobeychik@vanderbilt.edu"], "sections": [{"heading": "1 Introduction", "text": "This year, it has come to the point where there is only one occasion when there is a scandal, and that is when there is a scandal."}, {"heading": "2 Preliminaries", "text": "First, we set up the collaborative filter / matrix completion problem and give an overview of existing low factorizations based approaches. Let M-Rm-n be a data matrix consisting of m-rows and n-columns. Mij for i-ranks [m] and j-ranks [n] would then correspond to the rating given by the ith user for the jth-item-item-item-item-item-Item-IX rate. We also use \"i-rate\" and \"j-rate\" for columns (rows) observable at the ith-row (jth-column). Then, the goal of collaborative filtering (also referred to as matrix completion in the statistical learning literature) is to restore the complete matrix rate."}, {"heading": "3 The Attack Model", "text": "In this section, we will describe the data poison attack model considered in this paper. For a data matrix consisting of m users and n items, the attacker is able to add M's malicious users to the data matrix, and each malicious user is entitled to point his / her preferences to most B items with any preference that is limited in range. Before describing the data matrix of all M's, we will first introduce some notations to facilitate presentation. We will use M's Rm \"n to refer to the original data matrix and M's Rm\" n \"n to refer to the data matrix of all M's as malicious users."}, {"heading": "4 Computing Optimal Attack Strategies", "text": "We describe practical algorithms to solve the optimization problem in Equation (6) for an optimal attack strategy that maximizes the attacker's benefit. First, we look at the alternating minimization formulation in Equation (4) and derive from it a projected gradient ascent method that resolves for the corresponding optimal attack strategy. Similar derivatives are then extended to the formulation of nuclear standardization in Equation (5). Finally, we discuss how to design malicious users who mimic normal user behavior to avoid detection."}, {"heading": "4.1 Attacking Alternating Minimization", "text": "We use the projected gradient method (PGA) to solve the optimization problem in Eq. (6) with respect to the alternating minimization formula in Eq. (4): in the iteration t we update M + 1) as follows: M (t + 1) = ProjM (t) + st \u00b7 M (t) + st \u00b7 M (M), (10) where ProjM () is the projection operator on the feasible region M and st is the step size in iteration. Note: the estimated matrix M depends on the model. (M) learned on the common data matrix, which further depends on the malicious users M. (M) is highly non-convex, we generate B-points uniformatively to rate each malicious user. The ProjM (\u00b7) operator then reduces to the projection of each malicious user."}, {"heading": "4.2 Attacking Nuclear Norm Minimization", "text": "We extend the projected gradient algorithm in Sec. 4.1 to compute optimal attack strategies for the nuclear norm minimization formulation in Eq. (5) Since the target in Eq. (5) is convex, the global optimal solution (X, X) can be achieved by conventional convexic optimization methods such as proximal gradient descendancy (a.k.a. singular value). Furthermore, the resulting estimate (X, X) is low due to the nuclear standard penalty [2]. Suppose (X, X) is ranked 3rd (m, n). We use the minimum qualitative requirements (m, n) as an alternative characterization of the learning model with a reduced number of parameters. Here X = U."}, {"heading": "4.3 Mimicing Normal User Behaviors", "text": "To mitigate this problem, we propose an alternative approach to data poisoning in this section, so that the resulting malicious users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users of M'mimics Normal users."}, {"heading": "5 Experimental Results", "text": "To evaluate the effectiveness of our proposed poisoning strategy in the enhanced version of the paper, we use the publicly available MovieLens data, which includes 20 million reviews and 465,000 brand applications applied to 27,000 movies from 138,000 users. [23] We shift the rating range to [\u2212 2, 2] for the calculation susceptibility. To avoid the \"cold start\" problem, we consider users who have rated at least 20 movies. Two metrics are used to measure the relative performance of the systems before and after data poisoning attacks. (15) This serves as a guide as should be determined in subsequent experiments. We use a paired t-test to compare the distributions of rated articles between normal and malicious users."}, {"heading": "6 Discussion and Concluding Remarks", "text": "Our ultimate goal in analyzing intoxication attacks is to develop possible defense strategies based on careful analysis of adversarial behavior. Because the intoxication data is optimized based on the malicious targets of the attacker, the correlations between traits within a trait vector can change to appear different from normal cases. Therefore, tracking and detecting deviations in trait correlations and other accuracy metrics can be a potential defense. In addition, the defender can also use combination models or sampling strategies such as bagging to reduce the impact of intoxication attacks."}, {"heading": "Acknowledgments", "text": "This research was partially supported by NSF (CNS-1238959, IIS-1526860), ONR (N00014-151-2621), ARO (W911NF-16-1-0069), AFRL (FA8750-14-2-0180), Sandia National Laboratories and Symantec Labs Graduate Research Fellowship."}, {"heading": "A Computation of\u2207\u0398R(M\u0302,M)", "text": "We provide details on how to calculate the \"simple\" gradient. (18) On the basis of the chain rule of differentiation, we obtain that all malicious utility functions taken into account in this essay are smooth and differentiable. Specifically, the availability attack on the Rav utility tool and the integrity attack on the Rin utility tool permit the following gradient calculations: Rav utility tool, Rin utility tool, Rin utility tool, Rin utility tool, Rin utility tool, Rin utility tool, Rin utility tool, Rin utility tool, M utility tool, Mij = 2 (Mij utility tool) \u00b7 I [(i, j) / utility tool, RinJ0 utility tool, Rin utility tool, Rin utility tool, Rin utility tool, Rin utility tool, Rin utility tool."}, {"heading": "B Derivation of\u2207M\u0303\u0398 = \u2207M\u0303(u, u\u0303,v, \u03c3) for nuclear norm minimization", "text": "Evaluation of \"M\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i.\" Evaluation of \"M\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \"Evaluation of\" M \"i\" i \"i\" i. \"Evaluation of\" M \"i\" i \"i\" i \"i.\" Evaluation of \"i\" i. \"Evaluation of\" i \"i.\" Evaluation of \"i\" i \"i\" i. \"i.\" i. \"i.\" i. \"i.\" Evaluation of \"i.\" i. \"Evaluation of\" i. \"Evaluation of\" i. \"Evaluation of\" i. \"i.\" i. \"Evaluation of\" i. \"i.\" i. \"Evaluation of\" i. \"i.\" i. \"Evaluation of\" i. \"i.\" i. \"Evaluation of\" i. \"i.\" i. \"Evaluation of\" i. \"i.\" i. \"Evaluation of\" i. \"i.\" i. \"Evaluation of\" i. \""}, {"heading": "C Additional experimental results", "text": "Here we analyze the trend of the p-value against different values of \u03b2. Figure 3 records P-values and RMSE / average ratings against different values of \u03b2. If B = 25 (remember that B is the maximum number of elements a malicious user is allowed to evaluate) with the increase of \u03b2, the P-value decreases as both the RMSE and average ratings per element increase. Then, we record the ratings of certain elements against the percentage of harmful profiles by setting \u00b52 = \u2212 1 to evaluate the performance of an attacker who reduces the popularity of the article, whose original predicted average rating is 0.8. Figure 5 and 6 show two settings of \u00b51 = 0, \u00b52 = \u2212 1 and \u00b51 = \u2212 1, \u00b52 = \u2212 1 for alternating minimization and nuclear minimization respectively. With alternating minimization algorithms, if \u00b51 = 0, \u00b52 = \u2212 1, the attacker tries to reduce the average ratings for a particular item without taking care of the recommendation error as a whole."}], "references": [{"title": "Unifying user-based and item-based collaborative filtering approaches by similarity fusion", "author": ["Jun Wang", "Arjen de Vires", "Marcel Reinders"], "venue": "In SIGIR,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2006}, {"title": "Exact matrix completion via convex optimization", "author": ["Emmanuel Cand\u00e8s", "Ben Recht"], "venue": "Foundations of Computational Mathematics,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2007}, {"title": "A singular value thresholding algorithm for matrix completion", "author": ["Jian-Feng Cai", "Emmanuel Cand\u00e8s", "Zuowei Shen"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 1956}, {"title": "Effective attack models for shilling item-based collaborative filtering systems", "author": ["Bamshad Mobasher", "Robin Burke", "Runa Bhaumik", "Chad Williams"], "venue": "In Proceedings of the 2005 WebKDD Workshop, held in conjuction with ACM SIGKDD\u20192005,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2005}, {"title": "Promoting recommendations: An attack on collaborative filtering", "author": ["Michael P O\u2019Mahony", "Neil J Hurley", "Guenole CM Silvestre"], "venue": "In Database and Expert Systems Applications,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2002}, {"title": "Low-rank matrix completion using alternating minimization", "author": ["Prateek Jain", "Praneeth Netrapalli", "Sujay Sanghavi"], "venue": "In STOC,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Is feature selection secure against training data poisoning", "author": ["Huang Xiao", "Battista Biggio", "Gavin Brown", "Giorgio Fumera", "Claudia Eckert", "Fabio Roli"], "venue": "In ICML,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "The security of latent dirichlet allocation", "author": ["Shike Mei", "Xiaojin Zhu"], "venue": "In AISTATS,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "Using machine teaching to identify optimal training-set attacks on machine learners", "author": ["Shike Mei", "Xiaojin Zhu"], "venue": "In AAAI,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2015}, {"title": "Bayesian learning via stochastic gradient langevin dynamics", "author": ["Max Welling", "Yee W Teh"], "venue": "In Proceedings of the 28th International Conference on Machine Learning", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Adversarial classification", "author": ["Nilesh Dalvi", "Pedro Domingos", "Sumit Sanghai", "Deepak Verma"], "venue": "In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2004}, {"title": "Adversarial learning", "author": ["Daniel Lowd", "Christopher Meek"], "venue": "In Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2005}, {"title": "Feature cross-substitution in adversarial classification", "author": ["Bo Li", "Yevgeniy Vorobeychik"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Scalable optimization of randomized operational decisions in adversarial classification settings", "author": ["Bo Li", "Yevgeniy Vorobeychik"], "venue": "In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Can machine learning be secure", "author": ["Marco Barreno", "Blaine Nelson", "Russell Sears", "Anthony D Joseph", "J Doug Tygar"], "venue": "In Proceedings of the 2006 ACM Symposium on Information, computer and communications security,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2006}, {"title": "Poisoning attacks against support vector machines", "author": ["Battista Biggio", "Blaine Nelson", "Pavel Laskov"], "venue": "In ICML,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2012}, {"title": "Data poisoning attacks against autoregressive models", "author": ["Scott Alfeld", "Xiaojin Zhu", "Paul Barford"], "venue": "In AAAI,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Robust matrix completion", "author": ["Olga Klopp", "Karim Lounici", "Alexandre Tsybakov"], "venue": null, "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "Robust matrix completion and corrupted columns", "author": ["Yudong Chen", "Huan Xu", "Constantine Caramanis", "Sujay Sanghavi"], "venue": "In ICML,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2011}, {"title": "Low-rank matrix recovery from errors and erasures", "author": ["Yudong Chen", "Ali Jalali", "Sujay Sanghavi", "Constantine Caramanis"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2013}, {"title": "Robust matrix completion via joint schatten p-norm and lp-norm minimization", "author": ["Feiping Nie", "Hua Wang", "Xiao Cai", "Heng Huang", "Chris Ding"], "venue": "In ICDM,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2012}, {"title": "Stability of matrix factorization for collaborative filtering", "author": ["Yu-Xiang Wang", "Huan Xu"], "venue": "In ICML,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "Existing approaches in the literature include nearest-neighbor methods, where a user\u2019s (item\u2019s) preference is determined by other users (items) with similar profiles [1], and factorization-based methods where the incomplete preference matrix is assumed to be approximately low-rank [2, 3].", "startOffset": 166, "endOffset": 169}, {"referenceID": 1, "context": "Existing approaches in the literature include nearest-neighbor methods, where a user\u2019s (item\u2019s) preference is determined by other users (items) with similar profiles [1], and factorization-based methods where the incomplete preference matrix is assumed to be approximately low-rank [2, 3].", "startOffset": 282, "endOffset": 288}, {"referenceID": 2, "context": "Existing approaches in the literature include nearest-neighbor methods, where a user\u2019s (item\u2019s) preference is determined by other users (items) with similar profiles [1], and factorization-based methods where the incomplete preference matrix is assumed to be approximately low-rank [2, 3].", "startOffset": 282, "endOffset": 288}, {"referenceID": 3, "context": "systems and their reliance on user-specified judgments for building profiles, various forms of attacks are possible and have been discussed, such as the random attack and random product push/nuke attack [4, 5].", "startOffset": 203, "endOffset": 209}, {"referenceID": 4, "context": "systems and their reliance on user-specified judgments for building profiles, various forms of attacks are possible and have been discussed, such as the random attack and random product push/nuke attack [4, 5].", "startOffset": 203, "endOffset": 209}, {"referenceID": 5, "context": "We focus on two most popular algorithms: alternating minimization [6] and nuclear norm minimization [3].", "startOffset": 66, "endOffset": 69}, {"referenceID": 2, "context": "We focus on two most popular algorithms: alternating minimization [6] and nuclear norm minimization [3].", "startOffset": 100, "endOffset": 103}, {"referenceID": 6, "context": "\u2022 Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].", "startOffset": 95, "endOffset": 104}, {"referenceID": 7, "context": "\u2022 Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].", "startOffset": 95, "endOffset": 104}, {"referenceID": 8, "context": "\u2022 Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].", "startOffset": 95, "endOffset": 104}, {"referenceID": 5, "context": "\u2022 Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].", "startOffset": 249, "endOffset": 252}, {"referenceID": 1, "context": "\u2022 Novel gradient computations: Building upon existing gradient-based data poisoning frameworks [7, 8, 9], we develop novel methods for gradient computation based on first-order KKT conditions for two widely used algorithms: alternating minimization [6] and nuclear norm minimization [2].", "startOffset": 283, "endOffset": 286}, {"referenceID": 9, "context": "In this paper we provide a novel technique based on stochastic gradient Langevin dynamics optimization [10] to produce malicious users that mimic normal user behaviors in order to avoid detection, while achieving attack objectives.", "startOffset": 103, "endOffset": 107}, {"referenceID": 10, "context": "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].", "startOffset": 109, "endOffset": 129}, {"referenceID": 11, "context": "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].", "startOffset": 109, "endOffset": 129}, {"referenceID": 12, "context": "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].", "startOffset": 109, "endOffset": 129}, {"referenceID": 13, "context": "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].", "startOffset": 109, "endOffset": 129}, {"referenceID": 14, "context": "Related Work: There has been extensive prior research concerning the security of machine learning algorithms [11, 12, 13, 14, 15].", "startOffset": 109, "endOffset": 129}, {"referenceID": 15, "context": "pioneered the research of optimizing malicious datadriven attacks for kernel-based learning algorithms such as SVM [16].", "startOffset": 115, "endOffset": 119}, {"referenceID": 6, "context": "Similar techniques were later generalized to optimize data poisoning attacks for several other important learning algorithms, such as Lasso regression [7], topic modeling [8], and autoregressive models [17].", "startOffset": 151, "endOffset": 154}, {"referenceID": 7, "context": "Similar techniques were later generalized to optimize data poisoning attacks for several other important learning algorithms, such as Lasso regression [7], topic modeling [8], and autoregressive models [17].", "startOffset": 171, "endOffset": 174}, {"referenceID": 16, "context": "Similar techniques were later generalized to optimize data poisoning attacks for several other important learning algorithms, such as Lasso regression [7], topic modeling [8], and autoregressive models [17].", "startOffset": 202, "endOffset": 206}, {"referenceID": 8, "context": "The reader may refer to [9] for a general algorithmic framework of the abovementioned methods.", "startOffset": 24, "endOffset": 27}, {"referenceID": 17, "context": "In terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21].", "startOffset": 261, "endOffset": 277}, {"referenceID": 18, "context": "In terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21].", "startOffset": 261, "endOffset": 277}, {"referenceID": 19, "context": "In terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21].", "startOffset": 261, "endOffset": 277}, {"referenceID": 20, "context": "In terms of collaborative filtering/matrix completion, there is another line of established research that focuses on robust matrix completion, in which a small portion of elements or rows in the underlying low-rank matrix is assumed to be arbitrarily perturbed [18, 19, 20, 21].", "startOffset": 261, "endOffset": 277}, {"referenceID": 21, "context": "Specifically, the stability of alternating minimization solutions was analyzed with respect to malicious data manipulations in [22].", "startOffset": 127, "endOffset": 131}, {"referenceID": 21, "context": "However, [22] assumes a globally optimal solution of alternating minimization can be obtained, which is rarely true in practice.", "startOffset": 9, "endOffset": 13}, {"referenceID": 1, "context": "The goal of collaborative filtering (also referred to as matrix completion in the statistical learning literature [2]) is then to recover the complete matrix M from few observations M\u03a9.", "startOffset": 114, "endOffset": 117}, {"referenceID": 2, "context": "(3) is a convex optimization function and can be solved using an iterative singular value thresholding algorithm [3].", "startOffset": 113, "endOffset": 116}, {"referenceID": 5, "context": "(2) and (3) provably approximate the true underlying data matrix M under certain conditions [6, 2].", "startOffset": 92, "endOffset": 98}, {"referenceID": 1, "context": "(2) and (3) provably approximate the true underlying data matrix M under certain conditions [6, 2].", "startOffset": 92, "endOffset": 98}, {"referenceID": 6, "context": "Inspired by [7, 8, 9], we exploit the KKT conditions of the optimization problem \u0398\u03bb(\u00b7) to approximately compute\u2207M\u0303\u0398\u03bb(M\u0303; M).", "startOffset": 12, "endOffset": 21}, {"referenceID": 7, "context": "Inspired by [7, 8, 9], we exploit the KKT conditions of the optimization problem \u0398\u03bb(\u00b7) to approximately compute\u2207M\u0303\u0398\u03bb(M\u0303; M).", "startOffset": 12, "endOffset": 21}, {"referenceID": 8, "context": "Inspired by [7, 8, 9], we exploit the KKT conditions of the optimization problem \u0398\u03bb(\u00b7) to approximately compute\u2207M\u0303\u0398\u03bb(M\u0303; M).", "startOffset": 12, "endOffset": 21}, {"referenceID": 2, "context": "singular value thresholding [3] for nuclear norm minimization).", "startOffset": 28, "endOffset": 31}, {"referenceID": 1, "context": "In addition, the resulting estimation (X; X\u0303) is low rank due to the nuclear norm penalty [2].", "startOffset": 90, "endOffset": 93}, {"referenceID": 1, "context": "The subdifferential of the nuclear norm function \u2202\u2016 \u00b7 \u2016\u2217 is also known [2]: \u2202\u2016X\u2016\u2217 = { UV + W : UW = WV = 0, \u2016W\u20162 \u2264 1 } ,", "startOffset": 71, "endOffset": 74}, {"referenceID": 9, "context": "To circumvent this problem, we apply Stochastic Gradient Langevin Dynamics (SGLD, [10]) to approximately sample M\u0303 from its posterior distribution in Eq.", "startOffset": 82, "endOffset": 86}], "year": 2016, "abstractText": "Recommendation and collaborative filtering systems are important in modern information and e-commerce applications. As these systems are becoming increasingly popular in the industry, their outputs could affect business decision making, introducing incentives for an adversarial party to compromise the availability or integrity of such systems. We introduce a data poisoning attack on collaborative filtering systems. We demonstrate how a powerful attacker with full knowledge of the learner can generate malicious data so as to maximize his/her malicious objectives, while at the same time mimicking normal user behavior to avoid being detected. While the complete knowledge assumption seems extreme, it enables a robust assessment of the vulnerability of collaborative filtering schemes to highly motivated attacks. We present efficient solutions for two popular factorizationbased collaborative filtering algorithms: the alternative minimization formulation and the nuclear norm minimization method. Finally, we test the effectiveness of our proposed algorithms on real-world data and discuss potential defensive strategies.", "creator": "TeX"}}}