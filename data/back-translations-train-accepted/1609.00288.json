{"id": "1609.00288", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Sep-2016", "title": "A Unified View of Multi-Label Performance Measures", "abstract": "Multi-label classification deals with the problem where each instance is associated with multiple class labels. Because evaluation in multi-label classification is more complicated than single-label setting, a number of performance measures have been proposed. It is noticed that an algorithm usually performs differently on different measures. Therefore, it is important to understand which algorithms perform well on which measure(s) and why. In this paper, we propose a unified margin view to revisit eleven performance measures in multi-label classification. In particular, we define label-wise margin and instance-wise margin, and prove that through maximizing these margins, different corresponding performance measures will be optimized. Based on the defined margins, a max-margin approach called LIMO is designed and empirical results verify our theoretical findings.", "histories": [["v1", "Thu, 1 Sep 2016 15:49:43 GMT  (24kb)", "http://arxiv.org/abs/1609.00288v1", null], ["v2", "Fri, 1 Sep 2017 08:18:33 GMT  (239kb,D)", "http://arxiv.org/abs/1609.00288v2", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["xi-zhu wu", "zhi-hua zhou"], "accepted": true, "id": "1609.00288"}, "pdf": {"name": "1609.00288.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Zhi-Hua Zhou"], "emails": ["zhouzh@lamda.nju.edu.cn"], "sections": [{"heading": null, "text": "ar Xiv: 160 9.00 288v 1 [cs.L G] 1S epMulti-label classification deals with the problem that each instance is associated with multiple class labels. As the evaluation is more complicated in multi-label classification than in single-label classification, a number of performance measures have been proposed. It is noted that an algorithm normally functions differently in different ratios. Therefore, it is important to understand which algorithms perform well in which ratios and why. In this paper, we propose a uniform margin view to review eleven performance measures in multi-label classification. In particular, we define the margin and instance-wide margin in terms of brands and demonstrate that by maximizing these margins different corresponding performance measures are optimized. On the basis of the defined margins, a maximum margin approach called LIMO is designed and empirical results confirm our theoretical findings. Keywords: Multi-label classification, Multi-label-Margin, view, Margin"}, {"heading": "1. Introduction", "text": "In fact, it is such that most of them will be able to move to another world, in which they can move to another world, in which they can move to another world, in which they can move to another world, in which they can move to another world, in which they can move to another world, in which they live to another world, in which they can move to another world, in which they live to another world, in which they live to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live."}, {"heading": "2. Preliminaries", "text": "In this section, we define the notations and multi-label performance measures used in this essay, which we will discuss in the next section."}, {"heading": "2.1. Notations", "text": "Suppose xi-Rd \u00b7 1 is a real value instance vector, yi-y- (0, 1) l \u00b7 1 is a label vector for xi. m denotes the number of training samples. Therefore, yij (i-y-), j-y- (1,.., l) is the jth label of the ith instance, and yij = 1 or 0 means the jth label is relevant or irrelevant. The instance matrix is X-y- (0, 1,.) and the label matrix is Y-y- (0, 1) m \u00b7 l. H: Rd \u2192 {0, 1} l is the multi-label classifier, and we consider a separate classifier on each label, so that H = {h1,.. hl} and hj (xi) the prediction of yij \u00b7 y- (1,) - (Y-y-) function is relevant."}, {"heading": "2.2. Multi-label Performance Measures", "text": "Table 1 summarizes the eleven multi-label performance metrics that we will examine in this paper: the first five metrics (hamming loss, ranking loss, one-error, coverage, average precision) are taken into account in Schapire and Singer (2000) and in a variety of papers, e.g. Zhang and Wu (2015) and Dembczynski et al. (2012); the next six metrics are F-Measure and AUC (the Area Under the ROC Curve) extensions in multi-label classification using different average strategies, popular in both algorithm evaluation (Liu and Tsang, 2015) and theoretical analysis (Dembczynski et al., 2011) (Koyejo et al., 2015)."}, {"heading": "3. Label-wise Margin vs. Instance-wise Margin", "text": "Here we define two new concepts: label-wise margin and instance-wise margin.Definition 1. In view of a multi-label definer F: Rd \u2192 Rl and F = {f1,..., a training set (X, Y), the label-wise margin on instance xi is defined as: \u03b3 labeli = min u, v {fu (xi) \u2212 fv (xi) | (u, v) \u0445 Y + i \u00b7 \u00b7 Y \u2212 i \u00b7 is the set of all (relevant, irrelevant) label index pairs of the instance i.Definition 2. In view of a multi-label predictor F: Rd \u2192 Rl and F = {f1,.), a training set (X, Y), the instance-wise margin of instance Y \u00b7 j is the instance positive margin of the instance i.Definition. Definition 2. Definition of a multi-label margin of the instance i.Definition: marish the margin of the instance positive margin of the instance i.Definition."}, {"heading": "3.1. F -based Performance Measures", "text": "Several multi-label performance measurements can be optimised empirically according to the following theories: Theorem 1 = \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "3.3. Summary of main results", "text": "According to the analysis in Section 3.1 and Section 3.2, the relationship between multiple labeling parameters and proposed margins can be summarized in Table 2. Since double effectiveness is a special case of brand-effective and excessive effectiveness, whenever a label parameter can be optimized by one of the two, a double-effective F. In the light of the analysis, performance on different label parameters can be expected by optimizing margins. For example, if one only maximizes the margin on each label incessively, there may be higher losses on ranking losses, coverage amounts, and some other measures marked in the excessive column \"\u2717.\" If one tries to maximize the brand-wise margin but does not pay attention to the incessional margin, he / she may perform well on average, but be bad on macro-F1 (e.g. Elisseeff and Westessige 2002), as well as on maximizing the best margins."}, {"heading": "4. The LIMO Approach", "text": "The above analysis shows that maximizing different margins optimizes different measures, and where possible, the double effective F is preferred, as it enjoys the benefits of maximizing both the margin on the label and the margin on the instance. Therefore, we propose the LIMO (Label-wise and Instance-wiseMargins Optimization) approach. LIMO is a single approach that can optimize both margins, and it can also be degenerated to optimize both margins separately via parameter settings."}, {"heading": "4.1. Formulation", "text": "Suppose F is a linear predictor, what F (X) = W TX means, where W = [w1, w2, \u00b7 \u00b7, wl]. We suggest the following formulation: argmin W, [w] w, [w] w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w, w"}, {"heading": "4.2. Algorithm", "text": "The objective Eq. (8) is difficult to solve directly due to the large number of constraints and slack variables. (1) To deal with the arithmetic problem, we solve Eq. (8) using the stochastic gradient (SGD). The central point of SGD is to find a random vector whose expected value is equal to the direction of iteration with each iteration. We weigh random samples of two types of triplets to fulfill this requirement. At each iteration t we stomp a triplet (xti, yiu, yiv) where iteration is relevant and a triplet (j, x t b) where x t is a positive instance and xtb is a negative instance."}, {"heading": "5. Experiments", "text": "We conduct experiments on eleven different levels to show that optimizing the label wisely or the instance-wise margin can lead to different outcomes. We select five benchmark multi-label datasets1 from different domains in our experiments: (i) A-Marge CAL500, (ii) an email dataset enron, (iii) a-Mara dataset medical, (iv) an image dataset corel5k, (v) a text dataset bibtex. The number of labels in these datasets varies from 45 to 374. We split each dataset into two parts, i.e. 70% for training and 30% for testing. The experiments are repeated ten times, and the average outcomes are report.Binary Relevance (BR) (BR and Zhou, 2014), ML-kNN and GFM al."}, {"heading": "6. Conclusion", "text": "Our main finding is that performance measures are optimized by maximizing label and instance margins. We have also proposed a LIMO approach to maximize margins, and experimental results confirm our theoretical findings. Our work offers a new view of multi-label performance measures and reveals that they have something in common. In the future, it is encouraging to explore more effective ways to optimize these margins, which sheds light on the design of novel multi-label algorithms."}, {"heading": "Appendix: Detailed Experimental Results", "text": "The ranking in Table 3 is given in Table 6. The ranking in Table 4 is given in Table 7 and the ranking in Table 5 is given in Table 8 and Table 9. The complete table with eleven multi-label indicators is too extensive. Therefore, we divide the table into two tables: Table 8 contains the first 6 measures and Table 9 the results of the last 5 measures."}], "references": [{"title": "Hierarchical multi-label prediction of gene function", "author": ["Z. Barut\u00e7uoglu", "R.E. Schapire", "O.G. Troyanskaya"], "venue": "Bioinformatics 22", "citeRegEx": "Barut\u00e7uoglu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Barut\u00e7uoglu et al\\.", "year": 2006}, {"title": "Learning multi-label scene classification", "author": ["M.R. Boutell", "J. Luo", "X. Shen", "C.M. Brown"], "venue": "Pattern Recognition", "citeRegEx": "Boutell et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Boutell et al\\.", "year": 2004}, {"title": "LIBSVM: A library for support vector machines", "author": ["C. Chang", "C. Lin"], "venue": "ACM TIST", "citeRegEx": "Chang and Lin,? \\Q2011\\E", "shortCiteRegEx": "Chang and Lin", "year": 2011}, {"title": "Consistent multilabel ranking through univariate losses", "author": ["K. Dembczynski", "W. Kotlowski", "E. H\u00fcllermeier"], "venue": null, "citeRegEx": "Dembczynski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dembczynski et al\\.", "year": 2012}, {"title": "Regret analysis for performance metrics in multi-label classification: the case of hamming and subset zero-one loss. In: ECML/PKDD", "author": ["K. Dembczynski", "W. Waegeman", "W. Cheng", "E. H\u00fcllermeier"], "venue": null, "citeRegEx": "Dembczynski et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dembczynski et al\\.", "year": 2010}, {"title": "An exact algorithm for F-measure maximization", "author": ["K. Dembczynski", "W. Waegeman", "W. Cheng", "E. H\u00fcllermeier"], "venue": null, "citeRegEx": "Dembczynski et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Dembczynski et al\\.", "year": 2011}, {"title": "A kernel method for multi-labelled classification", "author": ["A. Elisseeff", "J. Weston"], "venue": null, "citeRegEx": "Elisseeff and Weston,? \\Q2002\\E", "shortCiteRegEx": "Elisseeff and Weston", "year": 2002}, {"title": "On the consistency of multi-label learning", "author": ["W. Gao", "Zhou", "Z.-H"], "venue": "Artificial Intelligence", "citeRegEx": "Gao et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gao et al\\.", "year": 2013}, {"title": "Consistent multilabel classification", "author": ["O. Koyejo", "N. Natarajan", "P. Ravikumar", "I.S. Dhillon"], "venue": null, "citeRegEx": "Koyejo et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Koyejo et al\\.", "year": 2015}, {"title": "On the optimality of classifier chain for multilabel classification", "author": ["W. Liu", "I.W. Tsang"], "venue": null, "citeRegEx": "Liu and Tsang,? \\Q2015\\E", "shortCiteRegEx": "Liu and Tsang", "year": 2015}, {"title": "Multi-instance multi-label learning in the presence of novel class instances", "author": ["A.T. Pham", "R. Raich", "X.Z. Fern", "J.P. Arriaga"], "venue": "ICML. pp. 2427\u20132435", "citeRegEx": "Pham et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Pham et al\\.", "year": 2015}, {"title": "Boostexter: A boosting-based system for text categorization", "author": ["R.E. Schapire", "Y. Singer"], "venue": "Machine Learning", "citeRegEx": "Schapire and Singer,? \\Q2000\\E", "shortCiteRegEx": "Schapire and Singer", "year": 2000}, {"title": "Random k-labelsets for multilabel classification", "author": ["G. Tsoumakas", "I. Katakis", "I.P. Vlahavas"], "venue": "IEEE TKDE", "citeRegEx": "Tsoumakas et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tsoumakas et al\\.", "year": 2011}, {"title": "Semantic annotation and retrieval of music and sound effects", "author": ["D. Turnbull", "L. Barrington", "D.A. Torres", "G.R.G. Lanckriet"], "venue": "IEEE Transactions on Audio, Speech & Language Processing", "citeRegEx": "Turnbull et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Turnbull et al\\.", "year": 2008}, {"title": "On the bayes-optimality of F-measure maximizers", "author": ["W. Waegeman", "K. Dembczynski", "A. Jachnik", "W. Cheng", "E. H\u00fcllermeier"], "venue": "JMLR 15", "citeRegEx": "Waegeman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Waegeman et al\\.", "year": 2014}, {"title": "Optimizing F-measure: A tale of two approaches", "author": ["N. Ye", "K.M.A. Chai", "W.S. Lee", "H.L. Chieu"], "venue": null, "citeRegEx": "Ye et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Ye et al\\.", "year": 2012}, {"title": "ML-KNN: A lazy learning approach to multi-label learning", "author": ["M. Zhang", "Z. Zhou"], "venue": "Pattern Recognition", "citeRegEx": "Zhang and Zhou,? \\Q2007\\E", "shortCiteRegEx": "Zhang and Zhou", "year": 2007}, {"title": "LIFT: Multi-label learning with label-specific features", "author": ["Zhang", "M.-L", "L. Wu"], "venue": "IEEE TPAMI", "citeRegEx": "Zhang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "A review on multi-label learning algorithms", "author": ["Zhang", "M.-L", "Zhou", "Z.-H"], "venue": "IEEE TKDE", "citeRegEx": "Zhang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 11, "context": "In text categorization, a document may be associated with a range of topics, such as science, entertainment, news and so on (Schapire and Singer, 2000); In image classification, an image can have both field and mountain tags (Boutell et al.", "startOffset": 124, "endOffset": 151}, {"referenceID": 1, "context": "In text categorization, a document may be associated with a range of topics, such as science, entertainment, news and so on (Schapire and Singer, 2000); In image classification, an image can have both field and mountain tags (Boutell et al., 2004); In gene functional analysis, a gene belongs to the functions of protein synthesis, metabolism", "startOffset": 225, "endOffset": 247}, {"referenceID": 0, "context": "and transcription (Barut\u00e7uoglu et al., 2006); In music information retrieval, a piece of music could convey various messages such as classic, piano and passionate (Turnbull et al.", "startOffset": 18, "endOffset": 44}, {"referenceID": 13, "context": ", 2006); In music information retrieval, a piece of music could convey various messages such as classic, piano and passionate (Turnbull et al., 2008).", "startOffset": 126, "endOffset": 149}, {"referenceID": 12, "context": "Therefore, a number of multi-label performance measures focused on different aspects have been proposed, such as micro-F1, macro-F1 (Tsoumakas et al., 2011), hamming loss, ranking loss, one-error, average precision and coverage (Schapire and Singer, 2000).", "startOffset": 132, "endOffset": 156}, {"referenceID": 11, "context": ", 2011), hamming loss, ranking loss, one-error, average precision and coverage (Schapire and Singer, 2000).", "startOffset": 79, "endOffset": 106}, {"referenceID": 0, "context": "and transcription (Barut\u00e7uoglu et al., 2006); In music information retrieval, a piece of music could convey various messages such as classic, piano and passionate (Turnbull et al., 2008). In the traditional supervised classification, generalization performance of the learning system is usually evaluated by accuracy, or F-measure if misclassification costs are unequal. In contrast to single-label classification, performance evaluation in multi-label classification is more complicated, as each instance can be associated with multiple labels simultaneously. For example, it is difficult to tell which mistake is more serious: one instance with three incorrect labels vs. three instances each with one incorrect label. Therefore, a number of multi-label performance measures focused on different aspects have been proposed, such as micro-F1, macro-F1 (Tsoumakas et al., 2011), hamming loss, ranking loss, one-error, average precision and coverage (Schapire and Singer, 2000). Because different performance measures focus on different aspects, previous works often analyze few specific measures. Dembczynski et al. (2010) showed that hamming loss and subset 0/1 loss cannot be optimized at the same time.", "startOffset": 19, "endOffset": 1123}, {"referenceID": 0, "context": "and transcription (Barut\u00e7uoglu et al., 2006); In music information retrieval, a piece of music could convey various messages such as classic, piano and passionate (Turnbull et al., 2008). In the traditional supervised classification, generalization performance of the learning system is usually evaluated by accuracy, or F-measure if misclassification costs are unequal. In contrast to single-label classification, performance evaluation in multi-label classification is more complicated, as each instance can be associated with multiple labels simultaneously. For example, it is difficult to tell which mistake is more serious: one instance with three incorrect labels vs. three instances each with one incorrect label. Therefore, a number of multi-label performance measures focused on different aspects have been proposed, such as micro-F1, macro-F1 (Tsoumakas et al., 2011), hamming loss, ranking loss, one-error, average precision and coverage (Schapire and Singer, 2000). Because different performance measures focus on different aspects, previous works often analyze few specific measures. Dembczynski et al. (2010) showed that hamming loss and subset 0/1 loss cannot be optimized at the same time. Gao and Zhou (2013) studied the consistency of two performance measures: ranking loss and hamming loss.", "startOffset": 19, "endOffset": 1226}, {"referenceID": 0, "context": "and transcription (Barut\u00e7uoglu et al., 2006); In music information retrieval, a piece of music could convey various messages such as classic, piano and passionate (Turnbull et al., 2008). In the traditional supervised classification, generalization performance of the learning system is usually evaluated by accuracy, or F-measure if misclassification costs are unequal. In contrast to single-label classification, performance evaluation in multi-label classification is more complicated, as each instance can be associated with multiple labels simultaneously. For example, it is difficult to tell which mistake is more serious: one instance with three incorrect labels vs. three instances each with one incorrect label. Therefore, a number of multi-label performance measures focused on different aspects have been proposed, such as micro-F1, macro-F1 (Tsoumakas et al., 2011), hamming loss, ranking loss, one-error, average precision and coverage (Schapire and Singer, 2000). Because different performance measures focus on different aspects, previous works often analyze few specific measures. Dembczynski et al. (2010) showed that hamming loss and subset 0/1 loss cannot be optimized at the same time. Gao and Zhou (2013) studied the consistency of two performance measures: ranking loss and hamming loss. They proved that none convex surrogate loss is Bayes consistent with the ranking loss, and gave a consistent surrogate loss function for hamming loss in deterministic case. Ye et al. (2012) pointed out that algorithms for learning to maximize F-measures follow two approaches: the decision-theoretic approach (DTA) and the empirical utility maximization (EUM) approach.", "startOffset": 19, "endOffset": 1500}, {"referenceID": 0, "context": "and transcription (Barut\u00e7uoglu et al., 2006); In music information retrieval, a piece of music could convey various messages such as classic, piano and passionate (Turnbull et al., 2008). In the traditional supervised classification, generalization performance of the learning system is usually evaluated by accuracy, or F-measure if misclassification costs are unequal. In contrast to single-label classification, performance evaluation in multi-label classification is more complicated, as each instance can be associated with multiple labels simultaneously. For example, it is difficult to tell which mistake is more serious: one instance with three incorrect labels vs. three instances each with one incorrect label. Therefore, a number of multi-label performance measures focused on different aspects have been proposed, such as micro-F1, macro-F1 (Tsoumakas et al., 2011), hamming loss, ranking loss, one-error, average precision and coverage (Schapire and Singer, 2000). Because different performance measures focus on different aspects, previous works often analyze few specific measures. Dembczynski et al. (2010) showed that hamming loss and subset 0/1 loss cannot be optimized at the same time. Gao and Zhou (2013) studied the consistency of two performance measures: ranking loss and hamming loss. They proved that none convex surrogate loss is Bayes consistent with the ranking loss, and gave a consistent surrogate loss function for hamming loss in deterministic case. Ye et al. (2012) pointed out that algorithms for learning to maximize F-measures follow two approaches: the decision-theoretic approach (DTA) and the empirical utility maximization (EUM) approach. Waegeman et al. (2014) studied the DTA consistent F-measure optimization in multi-label classification setting, and presented a Bayes-optimal algorithm via estimating parameters of the joint distribution.", "startOffset": 19, "endOffset": 1703}, {"referenceID": 0, "context": "and transcription (Barut\u00e7uoglu et al., 2006); In music information retrieval, a piece of music could convey various messages such as classic, piano and passionate (Turnbull et al., 2008). In the traditional supervised classification, generalization performance of the learning system is usually evaluated by accuracy, or F-measure if misclassification costs are unequal. In contrast to single-label classification, performance evaluation in multi-label classification is more complicated, as each instance can be associated with multiple labels simultaneously. For example, it is difficult to tell which mistake is more serious: one instance with three incorrect labels vs. three instances each with one incorrect label. Therefore, a number of multi-label performance measures focused on different aspects have been proposed, such as micro-F1, macro-F1 (Tsoumakas et al., 2011), hamming loss, ranking loss, one-error, average precision and coverage (Schapire and Singer, 2000). Because different performance measures focus on different aspects, previous works often analyze few specific measures. Dembczynski et al. (2010) showed that hamming loss and subset 0/1 loss cannot be optimized at the same time. Gao and Zhou (2013) studied the consistency of two performance measures: ranking loss and hamming loss. They proved that none convex surrogate loss is Bayes consistent with the ranking loss, and gave a consistent surrogate loss function for hamming loss in deterministic case. Ye et al. (2012) pointed out that algorithms for learning to maximize F-measures follow two approaches: the decision-theoretic approach (DTA) and the empirical utility maximization (EUM) approach. Waegeman et al. (2014) studied the DTA consistent F-measure optimization in multi-label classification setting, and presented a Bayes-optimal algorithm via estimating parameters of the joint distribution. Koyejo et al. (2015) studied the EUM optimal multi-label classifier for F-measure, including instance-, micro- and macro-averages.", "startOffset": 19, "endOffset": 1906}, {"referenceID": 9, "context": "These F-measures are popluar both in algorithm evaluation (Liu and Tsang, 2015) and theoretical analysis (Dembczynski et al.", "startOffset": 58, "endOffset": 79}, {"referenceID": 5, "context": "These F-measures are popluar both in algorithm evaluation (Liu and Tsang, 2015) and theoretical analysis (Dembczynski et al., 2011) (Koyejo et al.", "startOffset": 105, "endOffset": 131}, {"referenceID": 8, "context": ", 2011) (Koyejo et al., 2015).", "startOffset": 8, "endOffset": 29}, {"referenceID": 5, "context": "The first five measures (hamming loss, ranking loss, one-error, coverage, average precision) are considered in Schapire and Singer (2000) and a multitude of works, e.", "startOffset": 111, "endOffset": 138}, {"referenceID": 5, "context": "The first five measures (hamming loss, ranking loss, one-error, coverage, average precision) are considered in Schapire and Singer (2000) and a multitude of works, e.g., Zhang and Wu (2015) and Dembczynski et al.", "startOffset": 111, "endOffset": 190}, {"referenceID": 3, "context": ", Zhang and Wu (2015) and Dembczynski et al. (2012). The next six measures are F-measure and AUC (the Area Under the ROC Curve) extensions in multi-label classification via different averaging strategies.", "startOffset": 26, "endOffset": 52}, {"referenceID": 3, "context": ", Zhang and Wu (2015) and Dembczynski et al. (2012). The next six measures are F-measure and AUC (the Area Under the ROC Curve) extensions in multi-label classification via different averaging strategies. These F-measures are popluar both in algorithm evaluation (Liu and Tsang, 2015) and theoretical analysis (Dembczynski et al., 2011) (Koyejo et al., 2015). AUC s are used for algorithm evaluation such as in Pham et al. (2015) Zhang and Wu (2015).", "startOffset": 26, "endOffset": 430}, {"referenceID": 3, "context": ", Zhang and Wu (2015) and Dembczynski et al. (2012). The next six measures are F-measure and AUC (the Area Under the ROC Curve) extensions in multi-label classification via different averaging strategies. These F-measures are popluar both in algorithm evaluation (Liu and Tsang, 2015) and theoretical analysis (Dembczynski et al., 2011) (Koyejo et al., 2015). AUC s are used for algorithm evaluation such as in Pham et al. (2015) Zhang and Wu (2015).", "startOffset": 26, "endOffset": 450}, {"referenceID": 6, "context": ", Elisseeff and Weston (2002)).", "startOffset": 2, "endOffset": 30}, {"referenceID": 16, "context": "Binary Relevance (BR) (Zhang and Zhou, 2014), ML-kNN (Zhang and Zhou, 2007) and GFM (Waegeman et al.", "startOffset": 53, "endOffset": 75}, {"referenceID": 14, "context": "Binary Relevance (BR) (Zhang and Zhou, 2014), ML-kNN (Zhang and Zhou, 2007) and GFM (Waegeman et al., 2014) are provided for comparison.", "startOffset": 84, "endOffset": 107}, {"referenceID": 2, "context": "For BR, L2-regularized SVM (Chang and Lin, 2011) with C=1 is used as base learner.", "startOffset": 27, "endOffset": 48}], "year": 2016, "abstractText": "Multi-label classification deals with the problem where each instance is associated with multiple class labels. Because evaluation in multi-label classification is more complicated than single-label setting, a number of performance measures have been proposed. It is noticed that an algorithm usually performs differently on different measures. Therefore, it is important to understand which algorithms perform well on which measure(s) and why. In this paper, we propose a unified margin view to revisit eleven performance measures in multi-label classification. In particular, we define label-wise margin and instance-wise margin, and prove that through maximizing these margins, different corresponding performance measures will be optimized. Based on the defined margins, a max-margin approach called LIMO is designed and empirical results verify our theoretical findings.", "creator": "LaTeX with hyperref package"}}}