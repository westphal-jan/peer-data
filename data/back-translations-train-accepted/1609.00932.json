{"id": "1609.00932", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Sep-2016", "title": "Spectral Learning of Dynamic Systems from Nonequilibrium Data", "abstract": "Observable operator models (OOMs) and related models are one of the most important and powerful tools for modeling and analyzing stochastic systems. They can exactly describe dynamics of finite-rank systems, and be efficiently learned from data by moment based algorithms. Almost all OOM learning algorithms are developed based on the assumption of equilibrium data which is very difficult to guarantee in real life, especially for complex processes with large time scales. In this paper, we derive a nonequilibrium learning algorithm for OOMs, which dismisses this assumption and can effectively extract the equilibrium dynamics of a system from nonequilibrium observation data. In addition, we propose binless OOMs for the application of nonequilibrium learning to continuous-valued systems. In comparison with the other OOMs with continuous observations, binless OOMs can achieve consistent estimation from nonequilibrium data with only linear computational complexity.", "histories": [["v1", "Sun, 4 Sep 2016 13:31:36 GMT  (576kb,D)", "http://arxiv.org/abs/1609.00932v1", "Accepted by 29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. Original title: Learning Observable Operator Models from Nonequilibrium Data"], ["v2", "Tue, 20 Jun 2017 20:30:33 GMT  (984kb,D)", "http://arxiv.org/abs/1609.00932v2", null]], "COMMENTS": "Accepted by 29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain. Original title: Learning Observable Operator Models from Nonequilibrium Data", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.SY math.PR physics.data-an", "authors": ["hao wu", "frank no\u00e9"], "accepted": true, "id": "1609.00932"}, "pdf": {"name": "1609.00932.pdf", "metadata": {"source": "CRF", "title": "Spectral learning of dynamic systems from nonequilibrium data\u2217", "authors": ["Hao Wu"], "emails": ["hao.wu@fu-berlin.de", "frank.noe@fu-berlin.de", "Folding@home"], "sections": [{"heading": "1 Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Notation", "text": "In this thesis we use P to indicate the probability distribution for discrete random variables and the probability density for continuous random variables, the indicator function of event e is denoted by 1e and the Dirac delta function centered on x by \u03b4x (\u00b7). For a given process {at} we write the subsequence (ak, ak + 1,..., ak \u00b2) as ak: k \u00b2 and E \u221e [at], limt \u2192 \u221e E [at] means the expected value of at in equilibrium if the limit exists."}, {"heading": "2.2 Observable operator models", "text": "Anm-Dimensional Operator Model (OOM) with Observation Space (OOM) = > Functions can be represented by a tuple. (> Function) Tupel-M = (\u03c9, {\u00b2 (x) x x x \u00b2, \u03c3), the vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-vector-"}, {"heading": "3 Learning OOMs using moments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Algorithm", "text": "Here and in the following we consider only the case that the observation room O is a finite quantity. (Learning with continuous observations is discussed in Section 5.) A large number of largely similar methods was designed to learn OMs from discrete data, and the general learning procedure of these methods is summarized in Algorithm 1 and C, 1.3 (x) in line 2 of the algorithm implementation and parameter selection are omitted as follows: The results of 1, 1N, N, n, the consequences of 1 (~ s, 1 n), 2, N, n, n, 1, 1, 2, 2, 2, C, 1.3 (x) in line 2 of the algorithm 1 are related as follows: The results of 1, 1N, n, 2, 3, 3, 3, n, 1 n), 1, 2, N, n, 1, 1, 1, 1, 1, 1, and L, the results of observations of 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 3, 3 (~ s, 1 n), 2, 3, 2, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5."}, {"heading": "3.2 Theoretical analysis", "text": "We now analyze the statistical properties of the OOM learning algorithm without assuming an equilibrium. Before giving our main result, some assumptions about observational data are listed as follows: Assumption 1: The observational data consist of I independent length courses T, which are generated by a stochastic process, and the data size tends towards infinity with (i) I \u2192 n and T = T0 or (ii) T \u2192 n and I = I0. Assumption 2: {xt} is driven by a m-dimensional process {xt}, and the data size tends towards infinity with (i) x-dimensional applications, x-dimensional applications, x-dimensional applications and x-dimensional applications, x-dimensional applications, x-dimensional applications and x-dimensional applications."}, {"heading": "4 Nonequilibrium learning of OOMs", "text": "Considering that the purpose of dynamic modeling is to predict properties of the system in equilibrium dynamics in many situations, we are only approximating equilibrium values of internal states of OOMs (see below) and not actual output vectors, since the latter of initial conditions of data generation and the former are physically more interesting for the analysis of equilibrium dynamics. Given parameters of Meq in Theorem 1, the equilibrium value of internal states is defined as equilibrium value of internal state. (see below) Equilibrium value of internal states is defined as equilibrium dynamics of internal state. (see below) Equilibrium dynamics of internal state. (see above) Equilibrium dynamics of internal state. (see below) Equilibrium dynamics of internal state."}, {"heading": "5 Binless learning of OOMs", "text": "We are now looking at how to learn OOMs from continuous data that simply perceive any available observation as an appropriate perceptual probability. (...) In the case of a real observation space O-Rd, M defines probability densities of paths of (1), and C1,3 (x) becomes a matrix evaluation function C1,3 (x) = 1dxE (1). Existing continuous learning algorithms overcome this problem by using parametric methods [19, 8] or kernel embeddings [20], but none of them can achieve a consistent estimate with low computational complexity like discrete learning algorithms even for equivalence data.Here we present a binary strategy for performing dynamic modeling with continuous and non-equilibrium data that simply considers any available observation probability as an approximate probability."}, {"heading": "6 Applications", "text": "This year it is as far as never before in the history of the Federal Republic of Germany."}, {"heading": "7 Conclusion", "text": "In this paper, we investigated the statistical properties of the general learning procedure of OOM for non-equilibrium data and developed a general framework for learning dynamic models from non-equilibrium data. In this framework, the existing learning approaches of OOM and the other related models can be conveniently and efficiently applied to non-equilibrium data (discrete or continuous) by using the non-equilibrium learning technique and the binless learning technique. The main ideas of the two techniques are the correction of model parameters by algebraic limitations under the equilibrium condition and the binding handling of continuous observations. Among the interesting directions of future research are the analysis of the approximation error of non-equilibrium learning with limited data size and the application of non-equilibrium learning to controlled systems."}, {"heading": "A Proofs", "text": "(G1) Proof of Theorem 1For convenience, this we define\u03c9 \u2032 (T) = > q (T) = > q (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Part (1) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (1) (1) (1)) We first show the theorem in the case of T = T0 and I. (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) (Q) ("}, {"heading": "B Settings in applications", "text": "B.1 ModelleThe diffusion processes in section 6 are determined by the Brownian dynamics dxt = \u2212 \u0432 V (xt) dt + \u221a 2\u03b2 \u2212 1dWt with \u03b2 = 0.3, sample interval 0.002 s, V (x) = \u2211 5 i = 1 (| x \u2212 ci | + 0.001) \u2212 2 ui \u2211 5i = 1 (| x \u2212 ci | + 0.001) \u2212 2for the one-dimensional process and \u03b2 = 2, sample interval 0.001 s, V (x) = \u2212 log (3 \u2211 i = 1 piN (x | \u00b5i))) \u2212 2 for the two-dimensional process in which c1: 5 = (\u2212 0.3, 0.5, 1.5, 2.3), u1: 5 = (21, 4, 8 \u2212 1, 20), p1: 3, 0.25, 0.5, 0.5 = (0, \u2212 0.5), 0.5), \u00b53 = (1 \u2212 0.5, \u2212 0.8, \u2212 1, 1, 0.1, 0.1, 0.2, \u2212 1, 20 \u2212, 1, 25, 1, 0.25, 2, 0.5, 1, 25, 1, 0.25, 1, 0.25, 1, 0.2, 1, 0.25, 1, 1, 0.25, 1, 0.25, 1, 1, 0.25, 1, 1, 0.25, 1, 1, 0.25, 1, 1, 1, 1, 1 0.25, 1, 1, 1, 1, 1 0.25, 1, 1, 1, 1 0.25, 1, 1, 1, 1 0.25, 1, 1, 1, 1 0.25, 1, 1, 1, 1, 1 0.25, 1, 1, 1 0.25, 1, 1, 1 0.25, 1, 1, 1, 1 0.25, 1, 1, 1, 1 0.25, 1, 1, 1, 1, 1, 1 0.25, 1, 1, 1, 1, 1 0.25, 1, 1 0.25, 1, 1, 1, 1, 1, 1, 1, 1, 1 0.25, 1, 1, 1, 1, 1, 1, 1, 1, 25, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,"}], "references": [{"title": "Large sample estimation and hypothesis testing", "author": ["W.K. Newey", "D. McFadden"], "venue": "Handbook of Econometrics, vol. 4, pp. 2111\u20132245, 1994.", "citeRegEx": "1", "shortCiteRegEx": null, "year": 1994}, {"title": "Multilayer feedforward networks are universal approximators", "author": ["K. Hornik", "M. Stinchcombe", "H.White"], "venue": "Neural Netw., vol. 2, no. 5, pp. 359\u2013366, 1989.", "citeRegEx": "2", "shortCiteRegEx": null, "year": 1989}, {"title": "Efficient estimation of rare-event kinetics", "author": ["B. Trendelkamp-Schroer", "F. No\u00e9"], "venue": "Phys. Rev. X, vol. 6, pp. 011009, 2016. 9", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}], "referenceMentions": [{"referenceID": 0, "context": "In the last two decades, a collection of highly related dynamical models including observable operator models (OOMs) [1\u20133], predictive state representations [4\u20136] and spectral learning based hidden Markov models [7, 8], have become powerful and increasingly popular tools for analysis of dynamical data.", "startOffset": 117, "endOffset": 122}, {"referenceID": 1, "context": "In the last two decades, a collection of highly related dynamical models including observable operator models (OOMs) [1\u20133], predictive state representations [4\u20136] and spectral learning based hidden Markov models [7, 8], have become powerful and increasingly popular tools for analysis of dynamical data.", "startOffset": 117, "endOffset": 122}, {"referenceID": 2, "context": "In the last two decades, a collection of highly related dynamical models including observable operator models (OOMs) [1\u20133], predictive state representations [4\u20136] and spectral learning based hidden Markov models [7, 8], have become powerful and increasingly popular tools for analysis of dynamical data.", "startOffset": 117, "endOffset": 122}, {"referenceID": 2, "context": ", [3, 8, 10] for", "startOffset": 2, "endOffset": 12}, {"referenceID": 1, "context": "(c) Estimates of the probability difference given by the empirical estimator, HMM and Binless OOM (BL-OOM) using nonequilibrium learning with O = [0, 2].", "startOffset": 146, "endOffset": 152}, {"referenceID": 1, "context": "2(a) shows the potential function of a one-dimensional diffusion process {xt} on [0, 2] driven by Brownian dynamics, where the state space is discretized into two clusters I, II.", "startOffset": 81, "endOffset": 87}, {"referenceID": 1, "context": "2(c) and 2(d) plot estimates of the equilibrium state distribution given by the empirical estimator, HMM and binless OOM using nonequilibrium learning under the condition that the value of xt is exactly known and O = [0, 2], where the empirical estimator calculates statistics through averaging over all observations.", "startOffset": 217, "endOffset": 223}], "year": 2016, "abstractText": "Observable operator models (OOMs) and related models are one of the most important and powerful tools for modeling and analyzing stochastic systems. They can exactly describe dynamics of finite-rank systems, and be efficiently learned from data by moment based algorithms. Almost all OOM learning algorithms are developed based on the assumption of equilibrium data which is very difficult to guarantee in real life, especially for complex processes with large time scales. In this paper, we derive a nonequilibrium learning algorithm for OOMs, which dismisses this assumption and can effectively extract the equilibrium dynamics of a system from nonequilibrium observation data. In addition, we propose binless OOMs for the application of nonequilibrium learning to continuous-valued systems. In comparison with the other OOMs with continuous observations, binless OOMs can achieve consistent estimation from nonequilibrium data with only linear computational complexity.", "creator": "LaTeX with hyperref package"}}}