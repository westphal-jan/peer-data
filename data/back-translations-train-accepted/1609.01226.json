{"id": "1609.01226", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Sep-2016", "title": "The Robustness of Estimator Composition", "abstract": "We formalize notions of robustness for composite estimators via the notion of a breakdown point. A composite estimator successively applies two (or more) estimators: on data decomposed into disjoint parts, it applies the first estimator on each part, then the second estimator on the outputs of the first estimator. And so on, if the composition is of more than two estimators. Informally, the breakdown point is the minimum fraction of data points which if significantly modified will also significantly modify the output of the estimator, so it is typically desirable to have a large breakdown point. Our main result shows that, under mild conditions on the individual estimators, the breakdown point of the composite estimator is the product of the breakdown points of the individual estimators. We also demonstrate several scenarios, ranging from regression to statistical testing, where this analysis is easy to apply, useful in understanding worst case robustness, and sheds powerful insights onto the associated data analysis.", "histories": [["v1", "Mon, 5 Sep 2016 17:27:22 GMT  (62kb,D)", "http://arxiv.org/abs/1609.01226v1", "14 pages, 2 figures, 29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain"]], "COMMENTS": "14 pages, 2 figures, 29th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["pingfan tang", "jeff m phillips"], "accepted": true, "id": "1609.01226"}, "pdf": {"name": "1609.01226.pdf", "metadata": {"source": "CRF", "title": "The Robustness of Estimator Composition", "authors": ["Pingfan Tang", "Jeff M. Phillips"], "emails": ["tang1984@cs.utah.edu", "jeffp@cs.utah.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that most people who are able to move, are able to move, are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "1.1 Examples of Estimator Composition", "text": "Composite estimators arise in many scenarios in data analysis. Uncertain data. For example, in the last ten years the emphasis has been placed on the study of uncertainty data [11, 9, 2], where instead of analyzing a data set, we are given a model of uncertainty of each data point. Consider the summary of a group of n people based on noisy GPS measurements. For each person we could get k measurements of their location Pi, and use these k measurements as a discrete probability distribution of where that person might be. To then represent the center of this group of people, it would be a natural thing to do to estimate the location of each person as xi E1 (Pi) and then use these estimates to summarize the entire group E2 (x2)."}, {"heading": "1.2 Main Results", "text": "This paper introduces the formal and general study of the robustness of compound estimators. \u2022 In Section 2.1, we give two formal definitions of breakthrough points, both of which are required to prove the composition theory. \u2022 One variant of the definition closely coincides with other formalizations [4, 3], while another is fundamentally different. \u2022 The main result provides general conditions under which an E1-E2 estimator with breakthrough points \u03b21 and \u03b22 has a breakthrough point \u03b21\u03b22 (sentence 2 in Section 2.2). \u2022 In addition, by showing examples in which our conditions are not strictly applicable, we gain an understanding of how to circumvent the above result. \u2022 One example is composite percentile estimators (e.g. E1 provides the 25th percentile and E2 the 75th percentile of a ranking). These compound estimators have a greater breakthrough point than \u03b21 \u00b7 \u03b22. \u2022 The main result can be based on multiple compositions, so that the composition analysis of E2-3 precipitates, for example."}, {"heading": "2 Robustness of Estimator Composition", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Formal Definitions of Breakdown Points", "text": "The first definition, Asymptotic Breakdown Point, is similar to the classic formal definitions in [4] and [3] (including their highly technical nature), although their definitions of the estimator are slightly different, leading to some minor differences in specific cases. However, our second definition, Asymptotic Onto-Breakdown Point, is a structurally new definition, and we illustrate how it can lead to significantly different values on some common and useful estimators. Our main theorem will require both definitions, and the differences in performance will become several new applications and insights.We define an estimator E as a function from the collection of some finite subsets of a metric space (X, d) to another metric space (X, d): E: A {X} < X} 7 \u2192 X \u2032."}, {"heading": "2.3 Multi-level Composition of Estimators", "text": "To examine the breakdown point of the composite estimators with more than two levels, we introduce the following estimators: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E2: E2: E2: E2: E2: E2: E2: E2: E2: E2: E2: E2: E2: E2: E2: E2: E3: E3: E3: E3: E3: E3: E3: E2: E2: E2: E3: E3: E3: E3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: 3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E3: E"}, {"heading": "3 Applications", "text": "Next, we will discuss some applications of our key theorems and observations. Applications 2 and 4 are direct applications of easy-to-use theorems. Applications 1 and 3 utilize some of the nuances in the definition, in particular the unexpected robustness of the composition of quantitative estimators."}, {"heading": "3.1 Application 1 : Balancing Percentiles", "text": "For n companies, for the sake of simplicity, we assume that each company has k employees. We are interested in the income of the regular employees of all companies, not the executives, who can either have exorbitant salaries. Let pi, j represent the income of the next employee in the company. Put Pflat = \u00b7 ni = 1Pi, where the ith company has a sentence Pi = {pi, 1, \u00b7 \u00b7, 2, \u00b7 \u00b7 \u00b7, \u00b7, \u00b7 R and for notational convenience pi, 1 \u2264 pi, 2 \u2264 \u00b7 \u00b7 pi, k for i {1, 2, \u00b7, n}. Let us suppose that the income data Pi of each company are pre-processed by a 45 percentile estimator E1 (median of the lowest 90% of income), with breakdown point \u03b21 = 0.45. In theory, E1 (Pi) can better reflect the income of the regular employees in a company (Pi), since it is about 10% of the employees can spend much higher than their usual income in the company management and their usual income."}, {"heading": "3.2 Application 2 : Regression of L1 Medians", "text": "Suppose we want to apply a linear regression to reliably predict a person's weight based on height, and we have several measurements of each person's height and weight. Raw data are Pflat =] ni = 1Pi, with a set of Pi = {pi, 1, pi, 2, \u00b7, pi, pi, k}, R2 and pi, j = (xi, j, yi, j) for i-value for the ith person. A \"robust\" method of processing these data is to first pre-process each Pi with its L1 median [1]: (x-median [1]: (x-median [i, y-value], where E1 (Pi) = 0.5-median (Pi), a value of 1 \u00b7 0.5."}, {"heading": "3.3 Application 3 : Significance Thresholds", "text": "Suppose we study the distribution of wing spread of fruit flies. To fulfill the hypothesis, we are interested in investigating the significance of true wing spread among these flies. (Since the variance of actual wing spread among these flies is in the order of 0.01 units, so we measure the spread of the fly's wing spread automatically and quickly, which implies the variance of each Pi, is usually very small, perhaps only 0.001 units, but there are outliers in Pi with low probability due to possible machine malfunctions. This malfunction may be correlated with individual flies, or it may have autocorrelation (the series of consecutive measurements)."}, {"heading": "3.4 Application 4 : 3-Level Composition", "text": "Suppose each state has n = 100 meteorological stations, and station i in state j measures the local temperature k = 24 times to obtain the data Pi, j = {ti, j, 1, ti, j, 2, \u00b7 \u00b7 \u00b7, ti, j, k}. We define P jflat =] n i = 1Pi, j, Pflat =] mj = 1P j flat and E1 (Pi, j) = Median (Pi, j), E2 (P j flat) = Median (E1 (P1, j), E1 (Pn, j))) E (Pflat) = E3 (E2 (P 1 flat), E2 (P 2 flat), E\u03b2a (E\u03b2a), E2 (P 2 flat), E\u03b23 (E\u03b23), E\u03b23 (E\u03b23) = E\u03b23, E\u03b23 (E\u03b23) = 3, E\u03b23 (E\u03b23), E\u03b23 (2), E\u03b23 (E\u03b23), E\u03b23 (E\u03b23), E\u03b23 (E\u03b23), E\u03b23), E\u03b23 (E\u03b23), E\u03b23 (E\u03b23), E\u03b23), E\u03b23 (E\u03b23)."}, {"heading": "4 Simulations", "text": "Next, we will describe a few more scenarios in which our new theory of estimator composition is relevant. To do this, we will simulate a few datasets to show how to construct interesting algorithms from these ideas."}, {"heading": "4.1 Simulation 1 : Estimator Manipulation", "text": "In this simulation, we actually construct a method to shift an estimator by changing the smallest possible number of points. We specifically target the L1 median of the L1 median, since it is somewhat non-trivial to the new position of the data points. In particular, we use the simulation to show that we only need to change the n-k points of the Pflat (=] ni = 1Pi, where Pi = {pi, 1 \u2212 xi, 2, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 pi, k} - R2, so that we can get a new set of Pflat (=] ni = 1Pi, where Pi = \u2212 xi \u2212 i so that the median (P-1), the median (P-2), the \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 pi (P-n), the median (P-n) (- n \u00b7 n - n - n), the median (P - n - n - n \u00b7 n), the median (P - n - n - n - n \u00b7 n - n), the median (P - n \u00b7 n - n - n - n \u00b7 n), the median (P - n \u00b7 n - n - n - n - n - n - n \u00b7 n), the median (P - n \u00b7 n - n - n - n - n - n - n - n - n), the median (P - n \u00b7 n - n - n - n - n - n - n - n - P - n - n), the median (P - n - n - n - n - n - n - n - P - n - n)."}, {"heading": "5 8 3 4 (10.7631, 11.0663) (10.7025 11.0623)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10 5 5 3 (-13.8252, -4.7462) (-13.8330, -4.7482)", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "100 50 50 25 ( -14.0778, 18.3665) ( -14.0773, 18.3658)", "text": "Since (28) the sufficient and necessary condition for L1-Median is if we can find ~ x and ~ y \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "4.2 Simulation 2 : Router Monitoring", "text": "In fact, most of them will be able to move to a different world, in which they will be able to move to a different world than they are able to move to a different world."}, {"heading": "5 Discussion", "text": "These definitions are technical, but necessary to understand the robustness of compound estimators. We highlight a few applications and believe that many other approaches exist. These results already provide important insights for complex data analytics that are common for large-scale automated data analysis. In addition, these approaches offer the worst case guarantees that are concrete about when outliers can or cannot create a problem, as opposed to some regulatory approaches that tend to work only on most data. We will also highlight a few more insights from this work, or discuss challenges for follow-ups.The common case of composing two estimators, each with a break-down point of 0.5 yields a compound estimate of 0.25. This means that if the result is anomalous, at least 25% of the data must be subtracted from the smaller cases."}], "references": [{"title": "Geometric measures of data depth", "author": ["G. Aloupis"], "venue": "Data Depth: Robust Multivariate Analysis, Computational Geometry and Applications. AMS,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2006}, {"title": "Approximation algorithms for clustering uncertain data", "author": ["G. Cormode", "A. McGregor"], "venue": "PODS,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "The breakdown point: Examples and counterexamples", "author": ["P. Davies", "U. Gather"], "venue": "REVSTAT \u2013 Statitical Journal, 5:1\u201317,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2007}, {"title": "A general qualitative definition mof robustness", "author": ["F.R. Hampel"], "venue": "Annals of Mathematical Statistics, 42:1887\u2013 1896,", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1971}, {"title": "Robust Statistics: The Approach Based on Influence Functions", "author": ["F.R. Hampel", "E.M. Ronchetti", "P.J. Rousseeuw", "W.A. Stahel"], "venue": "Wiley,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 1986}, {"title": "Breakdown robustness of tests", "author": ["X. He", "D.G. Simplson", "S.L. Portnoy"], "venue": "Journal of the Maerican Statistical Association, 85:446\u2013452,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 1990}, {"title": "Robust Statistics", "author": ["P.J. Huber"], "venue": "Wiley,", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1981}, {"title": "Breakdown point", "author": ["P.J. Huber", "E.M. Ronchetti"], "venue": "Robust Statistics, page 8. John Wiley & Sons, Inc.,", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2009}, {"title": "Geometric computation on indecisive points", "author": ["A.G. J\u00f8rgensen", "M. L\u00f6ffler", "J.M. Phillips"], "venue": "WADS,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2011}, {"title": "Frugal streaming for estimating quantiles: One (or two) memory suffices", "author": ["S.M. Ma", "Qiang", "M. Sandler"], "venue": "arXiv preprint arXiv: 1407.1121,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Representing uncertain data: models, properties, and algorithms", "author": ["A.D. Sarma", "O. Benjelloun", "A. Halevy", "S. Nabar", "J. Widom"], "venue": "VLDBJ, 18:989\u20131019,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2009}, {"title": "Robust regression using repeated medians", "author": ["A.F. Siegel"], "venue": "Biometrika, 82:242\u2013244,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 1982}, {"title": "On the point for which the sum of the distances to n given points is minimum", "author": ["E. Weiszfeld", "F. Plastria"], "venue": "Annals of Operations Research, 167:7\u201341,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2009}, {"title": "The standard deviation", "author": ["A.H. Welsh"], "venue": "Aspects of Statistical Inference, page 245. Wiley-Interscience;,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 1996}], "referenceMentions": [{"referenceID": 4, "context": "Robust statistical estimators [5, 7] (in particular, resistant estimators), such as the median, are an essential tool in data analysis since they are provably immune to outliers.", "startOffset": 30, "endOffset": 36}, {"referenceID": 6, "context": "Robust statistical estimators [5, 7] (in particular, resistant estimators), such as the median, are an essential tool in data analysis since they are provably immune to outliers.", "startOffset": 30, "endOffset": 36}, {"referenceID": 3, "context": "The breakdown point [4, 3] is a basic measure of robustness of an estimator.", "startOffset": 20, "endOffset": 26}, {"referenceID": 2, "context": "The breakdown point [4, 3] is a basic measure of robustness of an estimator.", "startOffset": 20, "endOffset": 26}, {"referenceID": 0, "context": "\u2022 Aloupis [1] write \u201cthe breakdown point is the proportion of data which must be moved to infinity so that the estimator will do the same.", "startOffset": 10, "endOffset": 13}, {"referenceID": 7, "context": "\u201d \u2022 Huber and Ronchetti [8] write \u201cthe breakdown point is the smallest fraction of bad observations that may cause an estimator to take on arbitrarily large aberrant values.", "startOffset": 24, "endOffset": 27}, {"referenceID": 13, "context": "\" \u2022 Dasgupta, Kumar, and Srikumar [14] write \u201cthe breakdown point of an estimator is the largest fraction of the data that can be moved arbitrarily without perturbing the estimator to the boundary of the parameter space.", "startOffset": 34, "endOffset": 38}, {"referenceID": 10, "context": "For instance, in the last decade there has been increased focus on the study of uncertainty data [11, 9, 2] where instead of analyzing a data set, we are given a model of the uncertainty of each data point.", "startOffset": 97, "endOffset": 107}, {"referenceID": 8, "context": "For instance, in the last decade there has been increased focus on the study of uncertainty data [11, 9, 2] where instead of analyzing a data set, we are given a model of the uncertainty of each data point.", "startOffset": 97, "endOffset": 107}, {"referenceID": 1, "context": "For instance, in the last decade there has been increased focus on the study of uncertainty data [11, 9, 2] where instead of analyzing a data set, we are given a model of the uncertainty of each data point.", "startOffset": 97, "endOffset": 107}, {"referenceID": 3, "context": "One variant of the definition closely aligns with other formalizations [4, 3], while another is fundamentally different.", "startOffset": 71, "endOffset": 77}, {"referenceID": 2, "context": "One variant of the definition closely aligns with other formalizations [4, 3], while another is fundamentally different.", "startOffset": 71, "endOffset": 77}, {"referenceID": 3, "context": "The first definition, Asymptotic Breakdown Point, is similar to the classic formal definitions in [4] and [3] (including their highly technical nature), although their definitions of the estimator are slightly different leading to some minor differences in special cases.", "startOffset": 98, "endOffset": 101}, {"referenceID": 2, "context": "The first definition, Asymptotic Breakdown Point, is similar to the classic formal definitions in [4] and [3] (including their highly technical nature), although their definitions of the estimator are slightly different leading to some minor differences in special cases.", "startOffset": 106, "endOffset": 109}, {"referenceID": 0, "context": "For example, the median, L1-median [1], and Siegel estimators [12] all have asymptotic breakdown points of 0.", "startOffset": 35, "endOffset": 38}, {"referenceID": 11, "context": "For example, the median, L1-median [1], and Siegel estimators [12] all have asymptotic breakdown points of 0.", "startOffset": 62, "endOffset": 66}, {"referenceID": 0, "context": "One \u201crobust\u201d way to process this data, is to first pre-process each Pi with its L1-median [1]: (x\u0304i, \u0233i)\u2190 E1(Pi), where E1(Pi) = L1-median(Pi) has breakdown point \u03b21 = 0.", "startOffset": 90, "endOffset": 93}, {"referenceID": 11, "context": "Then we could generate a linear model to predict weight \u0177i = ax+b from the Siegel Estimator [12]: E2(Z) = (a, b), with breakdown point \u03b22 = 0.", "startOffset": 92, "endOffset": 96}, {"referenceID": 5, "context": "05 [6].", "startOffset": 3, "endOffset": 6}, {"referenceID": 12, "context": "If (x0, y0) is the L1-median of the set {(xi, yi) | 1 \u2264 i \u2264 k}, then we have [13]:", "startOffset": 77, "endOffset": 81}, {"referenceID": 9, "context": "A router can use streaming algorithm to monitor a single percentile, for instance the frugal algorithm here [10] only needs a few bites per percentile maintained \u2013 it does not need to monitor all.", "startOffset": 108, "endOffset": 112}, {"referenceID": 3, "context": "These definitions are technical but necessary to understand the robustness of composite estimators; and they do not stray too far from prior formal definitions [4, 3].", "startOffset": 160, "endOffset": 166}, {"referenceID": 2, "context": "These definitions are technical but necessary to understand the robustness of composite estimators; and they do not stray too far from prior formal definitions [4, 3].", "startOffset": 160, "endOffset": 166}], "year": 2016, "abstractText": "We formalize notions of robustness for composite estimators via the notion of a breakdown point. A composite estimator successively applies two (or more) estimators: on data decomposed into disjoint parts, it applies the first estimator on each part, then the second estimator on the outputs of the first estimator. And so on, if the composition is of more than two estimators. Informally, the breakdown point is the minimum fraction of data points which if significantly modified will also significantly modify the output of the estimator, so it is typically desirable to have a large breakdown point. Our main result shows that, under mild conditions on the individual estimators, the breakdown point of the composite estimator is the product of the breakdown points of the individual estimators. We also demonstrate several scenarios, ranging from regression to statistical testing, where this analysis is easy to apply, useful in understanding worst case robustness, and sheds powerful insights onto the associated data analysis.", "creator": "LaTeX with hyperref package"}}}