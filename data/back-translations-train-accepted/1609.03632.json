{"id": "1609.03632", "review": {"conference": "HLT-NAACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "12-Sep-2016", "title": "Joint Extraction of Events and Entities within a Document Context", "abstract": "Events and entities are closely related; entities are often actors or participants in events and events without entities are uncommon. The interpretation of events and entities is highly contextually dependent. Existing work in information extraction typically models events separately from entities, and performs inference at the sentence level, ignoring the rest of the document. In this paper, we propose a novel approach that models the dependencies among variables of events, entities, and their relations, and performs joint inference of these variables across a document. The goal is to enable access to document-level contextual information and facilitate context-aware predictions. We demonstrate that our approach substantially outperforms the state-of-the-art methods for event extraction as well as a strong baseline for entity extraction.", "histories": [["v1", "Mon, 12 Sep 2016 23:27:37 GMT  (503kb,D)", "http://arxiv.org/abs/1609.03632v1", "11 pages, 2 figures, published at NAACL 2016"]], "COMMENTS": "11 pages, 2 figures, published at NAACL 2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["bishan yang", "tom m mitchell"], "accepted": true, "id": "1609.03632"}, "pdf": {"name": "1609.03632.pdf", "metadata": {"source": "CRF", "title": "Joint Extraction of Events and Entities within a Document Context", "authors": ["Bishan Yang", "Tom Mitchell"], "emails": ["bishan@cs.cmu.edu", "tom.mitchell@cs.cmu.edu"], "sections": [{"heading": null, "text": "The interpretation of events and entities is highly context-dependent. Existing work in information extraction typically models events separately from entities and draws conclusions at the sentence level, ignoring the rest of the document. In this paper, we propose a novel approach that models the dependencies between variables of events, entities, and their relationships, and draws common conclusions from these variables within a document, with the goal of enabling access to contextual information at the document level and facilitating context prediction. We show that our approach significantly exceeds the standardized methods for event extraction and a strong basis for entity extraction."}, {"heading": "1 Introduction", "text": "The events are things that happen or occur; they involve entities (people, objects, etc.) that are affected by the events and spatio-temporal aspects of the world. Understanding events and their descriptions in the text is necessary for all commonly used machine reading systems. It is also essential to facilitate practical applications such as summarizing news, information, and knowledge base constructions. Interpretation of event descriptions is highly contextual. In order to make accurate predictions, a model of mentions and entities must be taken into account along with the context of the discourse. Consider, for example, the following extract from a news report: \"On Thursday there was a massive U.S. airstrike in which more than 300 Tomahawk missiles were fired at Baghdad. Earlier Saturday, Baghdad was targeted again.\" The excertification describes two U.S. attacks on Baghdad."}, {"heading": "2 Task Definition", "text": "We adopt the ACE definition for entities ((LDC), 2005a) and events (LDC), 2005b): \u2022 Entity Mention: An entity is an object or group of objects in the world. An entity mention is a reference to an entity in the form of a noun phrase or pronoun. \u2022 Event trigger: the word or phrase that clearly expresses its occurrence. Event trigger can be verbs, nouns and occasional adjectives such as \"dead\" or \"bankrupt.\" \u2022 Event argument: Event arguments are entities that fill certain roles within the event. They mainly include participants (i.e. the entities involved in the event) and general event attributes such as place and time and some event-typical attributes that have specific values (e.g. JOB-TITLE, CRIME).We are interested in providing entities, mentions, event trigger arguments and events."}, {"heading": "3 Approach", "text": "In this section, we describe our approach to collectively extracting events and units within a document context. First, we break down the learning problem into three tractable sub-problems: learning with event structures, learning event-event relationships, and learning to extract units. Then, we describe the probabilistic models for learning these sub-problems. Then, we present a common follow-up framework that integrates these learned models into a single model to collectively extract events and units within a document."}, {"heading": "3.1 Learning Within-event Structures", "text": "As described in Section 2, in this paper we consider only one event as a trigger and a set of event arguments. Each event argument is also an entity argument with an entity type. (Each event is also a set of arguments indicating a set of entity candidates.) We have found a set of entity candidates that are potential arguments for trigger candidates. (4) We associate it with a discrete variable structure that indicates values from the 33 ACE event types and a NONE class that indicates other events or no events. (5) Denote the set of entity candidates that are potential arguments for trigger candidates. (4) We associate them with discrete variable roles that indicate the event-reasoning relationship between trigger candidates i and entity candidates j. It takes values from 28 semantic roles and a NONE class that indicates how these candidates appear in Section 4."}, {"heading": "3.2 Learning Event-Event Relations", "text": "So far, we have described a model of learning structures for a single event. However, the inference of event types for individual events may depend on other events mentioned in the document. To grasp this intuition, we develop a pair-wise model of event-event relationships in a document. Our training data consists of all pairs of trigger candidates that occur together in the same sentence or are connected by a corresponding subject / object when they are in different sentences.5 We would like to spread information between these trigger pairs as they are more likely to relate to each other. Formally, with a trigger-candidate pair (i, i) we estimate the probabilities for their event types (ti, ti), whether they (ti, ti \u2032 | x, i \u2032), (ti, \u2032, x \u2032), (ti, \u2032, x), (trigger-candidate pairs), (ti, ti \u2032), whether they have an event type (ti, ti \u2032), whether they have a dependence (ti, \u2032, whether they have a factor 1, whether they have a factor 1, whether they have a factor 1, whether they have a factor 1)."}, {"heading": "3.3 Entity Extraction", "text": "For the extraction of entities, we trained a standard linear chain conditional random field (CRF) (Lafferty et al., 2001) using the BIO scheme (i.e. to identify the beginning, inner and outer sides of the 5We use the Stanford coreference system (Lee et al., 2013) for text segments within entities. We use features similar to those of previous work (Ratinov and Roth, 2009): (1) current words and parts-of-speech tags; (2) context words in a size 2 window; (3) word types as fully capitalized, in uppercase and numerals; (4) gazetteer-based entities when the current word matches an entry in the gazetteer collected from Wikipedia (Ratinov and Roth, 2009). In addition, we consider pre-traced word entries (the microscope, the general word)."}, {"heading": "3.4 Joint Inference", "text": "To achieve this, we propose a common approach to conclusions that allows information flow between the three local models and finds globally optimal assignments of all variables, including trigger variables t, argument role variables r, and entity variables a. Specifically, we define the sum of trust results for individual event attributions based on parameter estimates from within the event model. E (ti, ri \u00b7, a \u00b7) can be further broken down into three parameters. E (ti, ri \u00b7, a \u00b7) + D (aj) + D (aj) (3) The first term is the sum of trust results for individual event attributions based on parameter estimates from within the event model."}, {"heading": "4 Experiments", "text": "We are conducting experiments on the ACE2005 corpus.6 It contains text documents from a variety of sources such as newsreel reports, weblogs, and discussion forums, using the same data breakdown as in Li et al. (2013).Table 2 shows the data statistics. We adopt the evaluation metrics for events as defined in Li et al. (2013).An event trigger is correctly identified if its offsets and event subtypes match those of a gold standard trigger; and it is correctly classified if its semantic role (a total of 28) is also correct with the subtype of the gold standard trigger. An event argument is correctly identified if its offsets and event subtypes match those of one of the reference argument mentions in the document; and it is correctly classified if its semantic role (a total of 28) is also correct. For entities, a predicted mention is correctly extracted / extracted if its header and entity type match those in the document (9)."}, {"heading": "4.1 Results", "text": "We compare the proposed models of WITHINEVENT (in Section 3.1) and JOINTEVENTITY (in Section 3.4) with two strong baselines; the other is STAGEDMAXENT, a typical two-step approach that recognizes the event first and then as an event; we use the same event that appeals to candidates and entities as input to all comparative models except JOINTBEAM, because JOINTBEAM only triggers the event and then argues; we consider a realistic experimental setting in which no gold standard annotations for entities are available; to get results from JOINTBEAM, we have the actual system mentions and assumptions; we consider a realistic experimental setting where no gold standard annotations for entities are available."}, {"heading": "4.2 Error Analysis", "text": "Most of the errors relate to missing triggers and only 3.7% relate to incorrectly classified event types (e.g. a DEMONSTRATION event is mistaken for a TRANSPORT event). Among the missing triggers, we examine the cases where the event types are correctly identified in a sentence but with correct triggers and find that there are only 5% of such cases. In the event arguments, the majority of errors relate to missing arguments and only 4.1% to incorrectly classified argument roles. Among the missing event arguments, 10% of them correctly identified entity types and find that the errors for the event extraction are often due to three reasons: (1) The lexical sparseness is expressed in the sentence \"At least three members of a family have been hacked to death.\""}, {"heading": "5 Related Work", "text": "To reduce the complexity of the task, the early work uses a pipeline of classification patterns that first trigger events and then determine their arguments (Ahn, 2006; Bjo \ufffd rne et al., 2009). Recently, revolutionary neural networks have been used to improve classification patterns in the pipeline (Nguyen and Grishman, 2015; Chen et al., 2015). Since pipeline approaches suffer from error propagation, researchers have proposed methods for collectively extracting event triggers and arguments that either use structured perceptrons (Li et al., 2013), Markov logic (Poon and Vanderwende, 2010) or dependence on parsing algorithms (McClosky et al., 2011). However, existing common models rely largely on heuristic search to aggressively shrink the search space."}, {"heading": "6 Conclusion", "text": "In this paper, we present a new approach to the automatic extraction of events and entities within a document. First, we break down the learning problem into three tractable sub-problems: learning within event structures, learning event relationships, and learning for the extraction of entities. Then, we integrate these learned models into a single model that achieves a common conclusion of all event triggers, semantic roles for events and entities throughout the document. Experimental results show that our approach far outperforms the state-of-the-art event extractors and significantly improves a strong entity extraction base. In future work, we plan to integrate entity and event conferences as additional components into the common conference framework."}, {"heading": "Acknowledgments", "text": "This work was supported partly by the NSF grant IIS1250956 and partly by the DARPA DEFT program under contract FA87501320005. We thank the members of the CMU NELL group for helpful comments and the anonymous reviewers for insightful suggestions."}], "references": [{"title": "The stages of event extraction", "author": ["David Ahn"], "venue": "In Proceedings of the Workshop on Annotating and Reasoning about Time and Events,", "citeRegEx": "Ahn.,? \\Q2006\\E", "shortCiteRegEx": "Ahn.", "year": 2006}, {"title": "Modeling biological processes for reading comprehension", "author": ["Vivek Srikumar", "PeiChun Chen", "Brad Huang", "Christopher D Manning", "Abby Vander Linden", "Brittany Harding", "Peter Clark"], "venue": "In Proceedings of the 2014 Con-", "citeRegEx": "Berant et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Berant et al\\.", "year": 2014}, {"title": "An empirical investigation of statistical significance in nlp", "author": ["David Burkett", "Dan Klein"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing", "citeRegEx": "Berg.Kirkpatrick et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Berg.Kirkpatrick et al\\.", "year": 2012}, {"title": "Extracting complex biological events with rich graph-based feature sets", "author": ["Bj\u00f6rne et al.2009] Jari Bj\u00f6rne", "Juho Heimonen", "Filip Ginter", "Antti Airola", "Tapio Pahikkala", "Tapio Salakoski"], "venue": "In Proceedings of the Workshop on Current Trends in Biomedi-", "citeRegEx": "Bj\u00f6rne et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bj\u00f6rne et al\\.", "year": 2009}, {"title": "Seed-based event trigger labeling: How far can event descriptions get us? In ACL Volume 2: Short Papers, pages 372\u2013376", "author": ["Ido Dagan", "Qi Li", "Heng Ji", "Anette Frank"], "venue": null, "citeRegEx": "Bronstein et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bronstein et al\\.", "year": 2015}, {"title": "Jointly combining implicit constraints improves temporal ordering", "author": ["Chambers", "Jurafsky2008] Nathanael Chambers", "Dan Jurafsky"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Chambers et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Chambers et al\\.", "year": 2008}, {"title": "Unsupervised learning of narrative schemas and their participants", "author": ["Chambers", "Jurafsky2009] Nathanael Chambers", "Dan Jurafsky"], "venue": "In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference", "citeRegEx": "Chambers et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chambers et al\\.", "year": 2009}, {"title": "Template-based information extraction without the templates", "author": ["Chambers", "Jurafsky2011] Nathanael Chambers", "Dan Jurafsky"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-", "citeRegEx": "Chambers et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chambers et al\\.", "year": 2011}, {"title": "Event extraction via dynamic multi-pooling convolutional neural networks", "author": ["Chen et al.2015] Yubo Chen", "Liheng Xu", "Kang Liu", "Daojian Zeng", "Jun Zhao"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "An exact dual decomposition algorithm for shallow semantic parsing with constraints", "author": ["Das et al.2012] Dipanjan Das", "Andr\u00e9 FT Martins", "Noah A Smith"], "venue": null, "citeRegEx": "Das et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Das et al\\.", "year": 2012}, {"title": "Joint inference for event timeline construction", "author": ["Do et al.2012] Quang Xuan Do", "Wei Lu", "Dan Roth"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-", "citeRegEx": "Do et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Do et al\\.", "year": 2012}, {"title": "The automatic content extraction (ace) program-tasks, data, and evaluation", "author": ["Alexis Mitchell", "Mark A Przybocki", "Lance A Ramshaw", "Stephanie Strassel", "Ralph M Weischedel"], "venue": "In Proceedings of the Fourth In-", "citeRegEx": "Doddington et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Doddington et al\\.", "year": 2004}, {"title": "Refining event extraction through crossdocument inference", "author": ["Ji", "Grishman2008] Heng Ji", "Ralph Grishman"], "venue": "In Proceedings of ACL-08: HLT,", "citeRegEx": "Ji et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2008}, {"title": "Event extraction as frame-semantic parsing", "author": ["Judea", "Strube2015] Alex Judea", "Michael Strube"], "venue": "Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM", "citeRegEx": "Judea et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Judea et al\\.", "year": 2015}, {"title": "Overview of bionlp\u201909 shared task on event extraction", "author": ["Kim et al.2009] Jin-Dong Kim", "Tomoko Ohta", "Sampo Pyysalo", "Yoshinobu Kano", "Jun\u2019ichi Tsujii"], "venue": "In Proceedings of the Workshop on Current Trends", "citeRegEx": "Kim et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2009}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["Andrew McCallum", "Fernando CN Pereira"], "venue": "In Proc. 18th International Conf. on Machine Learning (ICML),", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Deterministic coreference resolution based on entity-centric, precision-ranked rules", "author": ["Lee et al.2013] Heeyoung Lee", "Angel Chang", "Yves Peirsman", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky"], "venue": null, "citeRegEx": "Lee et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lee et al\\.", "year": 2013}, {"title": "Joint event extraction via structured prediction with global features", "author": ["Li et al.2013] Qi Li", "Heng Ji", "Liang Huang"], "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Constructing information networks using one single model", "author": ["Li et al.2014] Qi Li", "Heng Ji", "Yu Hong", "Sujian Li"], "venue": "In Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP),", "citeRegEx": "Li et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Using document level cross-event inference to improve event extraction", "author": ["Liao", "Grishman2010] Shasha Liao", "Ralph Grishman"], "venue": "In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Liao et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Liao et al\\.", "year": 2010}, {"title": "Nomlex: A lexicon of nominalizations", "author": ["Ralph Grishman", "Adam Meyers", "Leslie Barrett", "Ruth Reeves"], "venue": "In Proceedings of EURALEX,", "citeRegEx": "Macleod et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Macleod et al\\.", "year": 1998}, {"title": "An augmented lagrangian approach to constrained map inference", "author": ["Mario AT Figeuiredo", "Pedro MQ Aguiar", "Noah A Smith", "Eric P Xing"], "venue": "In Proceedings of the International Conference on Machine Learning", "citeRegEx": "Martins et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Martins et al\\.", "year": 2011}, {"title": "Learning constraints for consistent timeline extraction", "author": ["McClosky", "Manning2012] David McClosky", "Christopher D Manning"], "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational", "citeRegEx": "McClosky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "McClosky et al\\.", "year": 2012}, {"title": "Event extraction as dependency parsing", "author": ["Mihai Surdeanu", "Christopher D Manning"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Tech-", "citeRegEx": "McClosky et al\\.,? \\Q2011\\E", "shortCiteRegEx": "McClosky et al\\.", "year": 2011}, {"title": "Distributed representations of words and phrases and their", "author": ["Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": null, "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Event detection and domain adaptation with convolutional neural networks", "author": ["Nguyen", "Grishman2015] Thien Huu Nguyen", "Ralph Grishman"], "venue": "In Proceedings of ACL-IJCNLP 2015 Volume 2: Short Papers,", "citeRegEx": "Nguyen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2015}, {"title": "Joint inference for knowledge extraction from biomedical literature", "author": ["Poon", "Vanderwende2010] Hoifung Poon", "Lucy Vanderwende"], "venue": "In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association", "citeRegEx": "Poon et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Poon et al\\.", "year": 2010}, {"title": "Design challenges and misconceptions in named entity recognition", "author": ["Ratinov", "Roth2009] Lev Ratinov", "Dan Roth"], "venue": "In Proceedings of the Thirteenth Conference on Computational Natural Language Learning,", "citeRegEx": "Ratinov et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Ratinov et al\\.", "year": 2009}, {"title": "Fast and robust joint models for biomedical event extraction", "author": ["Riedel", "McCallum2011] Sebastian Riedel", "Andrew McCallum"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Riedel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2011}], "referenceMentions": [{"referenceID": 17, "context": "First, they extract events and entities in separate stages: entities such as people, organization, and locations are first extracted by a named entity tagger, and then these extracted entities are used as inputs for extracting events and their arguments (Li et al., 2013).", "startOffset": 254, "endOffset": 271}, {"referenceID": 17, "context": "In fact, previous work (Li et al., 2013) observes that using previously extracted entities in event extraction results in ar X iv :1 60 9.", "startOffset": 23, "endOffset": 40}, {"referenceID": 17, "context": "Second, most existing work extracts events independently from each individual sentence, ignoring the rest of the document (Li et al., 2013; Judea and Strube, 2015; Nguyen and Grishman, 2015).", "startOffset": 122, "endOffset": 190}, {"referenceID": 17, "context": "Second, most existing work extracts events independently from each individual sentence, ignoring the rest of the document (Li et al., 2013; Judea and Strube, 2015; Nguyen and Grishman, 2015). Very few attempts have been made to incorporate document context for event extraction. Ji and Grishman (2008) model the information flow in two stages: the first stage trains classifiers for event triggers and arguments within each sentence; the second stage applies heuristic rules to adjust the classifiers\u2019 outputs to satisfy document-wide (or document-cluster-wide) consistency.", "startOffset": 123, "endOffset": 302}, {"referenceID": 17, "context": "Second, most existing work extracts events independently from each individual sentence, ignoring the rest of the document (Li et al., 2013; Judea and Strube, 2015; Nguyen and Grishman, 2015). Very few attempts have been made to incorporate document context for event extraction. Ji and Grishman (2008) model the information flow in two stages: the first stage trains classifiers for event triggers and arguments within each sentence; the second stage applies heuristic rules to adjust the classifiers\u2019 outputs to satisfy document-wide (or document-cluster-wide) consistency. Liao and Grishman (2010) further improved the rule-based inference by training additional classifiers for event triggers and arguments using document-level information.", "startOffset": 123, "endOffset": 600}, {"referenceID": 17, "context": "Many of these features overlap with those used in previous work (Li et al., 2013; Li et al., 2014), except for the word embedding features for triggers and the features for entities which are derived from multiple entity resources.", "startOffset": 64, "endOffset": 98}, {"referenceID": 18, "context": "Many of these features overlap with those used in previous work (Li et al., 2013; Li et al., 2014), except for the word embedding features for triggers and the features for entities which are derived from multiple entity resources.", "startOffset": 64, "endOffset": 98}, {"referenceID": 15, "context": "For entity extraction, we trained a standard linearchain Conditional Random Field (CRF) (Lafferty et al., 2001) using the BIO scheme (i.", "startOffset": 88, "endOffset": 111}, {"referenceID": 16, "context": "We use the Stanford coreference system (Lee et al., 2013) for within-document entity coreference.", "startOffset": 39, "endOffset": 57}, {"referenceID": 20, "context": "nominalization of the words based on Nomlex (Macleod et al., 1998)", "startOffset": 44, "endOffset": 66}, {"referenceID": 4, "context": "similarity features between the head word and a list of trigger seeds based on WordNet (Bronstein et al., 2015) 5.", "startOffset": 87, "endOffset": 111}, {"referenceID": 18, "context": "semantic frames that associate with the head word and its p-o-s tag based on FrameNet (Li et al., 2014) 6.", "startOffset": 86, "endOffset": 103}, {"referenceID": 24, "context": "pre-trained vector for the head word (Mikolov et al., 2013)", "startOffset": 37, "endOffset": 59}, {"referenceID": 24, "context": "In addition, we consider pre-trained word embeddings (Mikolov et al., 2013) as dense features for each word in order to improve the generalizability of the model.", "startOffset": 53, "endOffset": 75}, {"referenceID": 21, "context": "the problem using a dual decomposition algorithm AD3 (Martins et al., 2011).", "startOffset": 53, "endOffset": 75}, {"referenceID": 9, "context": "AD3 has been shown to be orders of magnitude faster than a general purpose ILP solver in practice (Das et al., 2012).", "startOffset": 98, "endOffset": 116}, {"referenceID": 17, "context": "We use the same data split as in Li et al. (2013). Table 2 shows the data statistics.", "startOffset": 33, "endOffset": 50}, {"referenceID": 17, "context": "We adopt the evaluation metrics for events as defined in Li et al. (2013). An event trigger is correctly identified if its offsets match those of a goldstandard trigger; and it is correctly classified if its event subtype (33 in total) also match the subtype of the gold-standard trigger.", "startOffset": 57, "endOffset": 74}, {"referenceID": 17, "context": "One is JOINTBEAM (Li et al., 2013), a state-of-the-art event extractor that uses a structured perceptron with beam search for sentence-level joint extraction of event triggers and arguments.", "startOffset": 17, "endOffset": 34}, {"referenceID": 17, "context": "One is JOINTBEAM (Li et al., 2013), a state-of-the-art event extractor that uses a structured perceptron with beam search for sentence-level joint extraction of event triggers and arguments. The other is STAGEDMAXENT, a typical two-stage approach that detects event triggers first and then event arguments. We use the same event trigger candidates and entity mention candidates as input to all the comparing models except for JOINTBEAM, because JOINTBEAM only extracts event mentions and assumes entity mentions are given. We consider a realistic experimental setting where no gold-standard annotations are available for entities during testing. To obtain results from JOINTBEAM, we ran the actual system8 used in Li et al. (2013) using the entity mentions output by our CRF-based entity extractor.", "startOffset": 18, "endOffset": 731}, {"referenceID": 17, "context": "BIU-RPI-Event-Extraction-Project We report the micro-average scores as in previous work (Li et al., 2013).", "startOffset": 88, "endOffset": 105}, {"referenceID": 17, "context": "JOINTBEAM (Li et al., 2013) 76.", "startOffset": 10, "endOffset": 27}, {"referenceID": 2, "context": "All significance tests reported in this paper were computed using the paired bootstrap procedure (Berg-Kirkpatrick et al., 2012) with 10,000 samples of the test documents.", "startOffset": 97, "endOffset": 128}, {"referenceID": 11, "context": "Event extraction has been mainly studied using the ACE data (Doddington et al., 2004) and biomedical data for the BioNLP shared tasks (Kim et al.", "startOffset": 60, "endOffset": 85}, {"referenceID": 14, "context": ", 2004) and biomedical data for the BioNLP shared tasks (Kim et al., 2009).", "startOffset": 56, "endOffset": 74}, {"referenceID": 0, "context": "To reduce task complexity, early work employs a pipeline of classifiers that extracts event triggers first, and then determines their arguments (Ahn, 2006; Bj\u00f6rne et al., 2009).", "startOffset": 144, "endOffset": 176}, {"referenceID": 3, "context": "To reduce task complexity, early work employs a pipeline of classifiers that extracts event triggers first, and then determines their arguments (Ahn, 2006; Bj\u00f6rne et al., 2009).", "startOffset": 144, "endOffset": 176}, {"referenceID": 8, "context": "Recently, Convolutional Neural Networks have been used to improve the pipeline classifiers (Nguyen and Grishman, 2015; Chen et al., 2015).", "startOffset": 91, "endOffset": 137}, {"referenceID": 17, "context": "As pipeline approaches suffer from error propagation, researchers have proposed methods for joint extraction of event triggers and arguments, using either structured perceptron (Li et al., 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al.", "startOffset": 177, "endOffset": 194}, {"referenceID": 23, "context": ", 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al., 2011).", "startOffset": 85, "endOffset": 108}, {"referenceID": 0, "context": "To reduce task complexity, early work employs a pipeline of classifiers that extracts event triggers first, and then determines their arguments (Ahn, 2006; Bj\u00f6rne et al., 2009). Recently, Convolutional Neural Networks have been used to improve the pipeline classifiers (Nguyen and Grishman, 2015; Chen et al., 2015). As pipeline approaches suffer from error propagation, researchers have proposed methods for joint extraction of event triggers and arguments, using either structured perceptron (Li et al., 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al., 2011). However, existing joint models largely rely on heuristic search to aggressively shrink the search space. One exception is work in Riedel and McCallum (2011), which uses dual decomposition to solve joint inference with runtime guarantees.", "startOffset": 145, "endOffset": 771}, {"referenceID": 0, "context": "To reduce task complexity, early work employs a pipeline of classifiers that extracts event triggers first, and then determines their arguments (Ahn, 2006; Bj\u00f6rne et al., 2009). Recently, Convolutional Neural Networks have been used to improve the pipeline classifiers (Nguyen and Grishman, 2015; Chen et al., 2015). As pipeline approaches suffer from error propagation, researchers have proposed methods for joint extraction of event triggers and arguments, using either structured perceptron (Li et al., 2013), Markov Logic (Poon and Vanderwende, 2010), or dependency parsing algorithms (McClosky et al., 2011). However, existing joint models largely rely on heuristic search to aggressively shrink the search space. One exception is work in Riedel and McCallum (2011), which uses dual decomposition to solve joint inference with runtime guarantees. Our work is similar to Riedel and McCallum (2011). However, there are two main differences: first, our model extracts both event mentions and entity mentions; second, it performs joint inference across sentence boundaries.", "startOffset": 145, "endOffset": 902}, {"referenceID": 10, "context": "For general texts most work focuses on exploiting temporal event relations (Chambers and Jurafsky, 2008; Do et al., 2012; McClosky and Manning, 2012).", "startOffset": 75, "endOffset": 149}, {"referenceID": 1, "context": "Berant et al. (2014) exploits event-event relations, e.", "startOffset": 0, "endOffset": 21}], "year": 2016, "abstractText": "Events and entities are closely related; entities are often actors or participants in events and events without entities are uncommon. The interpretation of events and entities is highly contextually dependent. Existing work in information extraction typically models events separately from entities, and performs inference at the sentence level, ignoring the rest of the document. In this paper, we propose a novel approach that models the dependencies among variables of events, entities, and their relations, and performs joint inference of these variables across a document. The goal is to enable access to document-level contextual information and facilitate contextaware predictions. We demonstrate that our approach substantially outperforms the stateof-the-art methods for event extraction as well as a strong baseline for entity extraction.", "creator": "LaTeX with hyperref package"}}}