{"id": "1609.04779", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-Sep-2016", "title": "Characterizing the Language of Online Communities and its Relation to Community Reception", "abstract": "This work investigates style and topic aspects of language in online communities: looking at both utility as an identifier of the community and correlation with community reception of content. Style is characterized using a hybrid word and part-of-speech tag n-gram language model, while topic is represented using Latent Dirichlet Allocation. Experiments with several Reddit forums show that style is a better indicator of community identity than topic, even for communities organized around specific topics. Further, there is a positive correlation between the community reception to a contribution and the style similarity to that community, but not so for topic similarity.", "histories": [["v1", "Thu, 15 Sep 2016 19:07:17 GMT  (71kb,D)", "http://arxiv.org/abs/1609.04779v1", "EMNLP 2016"]], "COMMENTS": "EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["trang tran", "mari ostendorf"], "accepted": true, "id": "1609.04779"}, "pdf": {"name": "1609.04779.pdf", "metadata": {"source": "CRF", "title": "Characterizing the Language of Online Communities and its Relation to Community Reception", "authors": ["Trang Tran", "Mari Ostendorf"], "emails": ["ttmt001@uw.edu", "ostendor@uw.edu"], "sections": [{"heading": "1 Introduction", "text": "In addition, discussion platforms take various forms: articles on many news sites have a comment section, many websites are dedicated to answering questions (www.quora.com), and other platforms allow users to share personal stories, messages, and random discoveries (www.reddit.com). Like their offline counterparts, online communities are often made up of people with similar interests and opinions. However, online communication differs from personal communication in one interesting aspect: explicit and quantifiable feedback. Many discussion forums give users the ability to upload and / or download content that another user has uploaded and / or downloaded. These explicit reward / punitive markers provide valuable information about how users react in a community. In this work, we use the available response of users to examine the relationship between community reception and the degree of stylistic / current coherence with such communities."}, {"heading": "2 Related Work", "text": "It is well known that interlocutors become more linguistically similar when their dialogue develops on many aspects such as lexical, syntactic and acoustic features (Niederhoffer and Pennebaker, 2002; Levitan et al., 2011), a pattern observed even when the conversation is fictitious (Danescu-Niculescu-Mizil and Lee, 2011) or on social media (Danescu-NiculescuMizil et al., 2011). As for the language of online discussions, it has been shown that the linguistic patterns of individual users evolve into matchar Xiv: 160 9.04 779v 1 [cs.C L] 15 Sep 20those of the community in which they participate and over time attain a \"linguistic maturity\" (Nguyen and Rose, 2011; Danescu-Niculescu-Mizil et al., 2013)."}, {"heading": "3 Data", "text": "Reddit is a popular forum with thousands of subcommunities known as subreddits, each of which has a specific topic. We will interchangeably refer to subreddits and communities. Redditors can submit content to initiate a discussion thread to which we refer as a post. Under each post, users can discuss the post by adding a comment. Both posts and comments can be tuned up and down, and the net feedback is referred to as karma points. We use eight subbreddits that reflect Reddit's diverse topics, while we limit the amount of data to an appropriate size. In addition, we create an artificial distraction mechanism that serves as an open class in our classification tasks and normalizes results in correlation analysis. Statistics are listed in Table 1. The combined others contain 9 other subbreddits that are similar in size and content diversity to the previous ones: Books, Chicago, Nyc, Seattle, Explanations, Comments, Fnl."}, {"heading": "4 Models", "text": "For the modeling of style, a popular approach has been chosen to combine the selected words with speech modules (Part-of-Speech, POS) to construct models for genre recognition (Stamatos et al., 2000; Feldman et al., 2009; Bergsma et al., 2012) and data selection (Iyer and Ostendorf, 1999; Axelrod, 2014). A common approach to the topic is Latent Dirichlet Allocation (LDA) (Blei et al., 2003), which is an approach we pursue in our work, taking into account the challenge of a complete separation of previously raised style / genre and theme factors (Iyer and Ostendorf, 1999; Sarawgi et al., 2011; Petrenz and Webber, 2011; Axelrod, 2014), which is also reflected in our analysis. Generative language models are used to characterize both style and theme, as they are well suited to dealing with text of varying lengths."}, {"heading": "4.1 Representing Style", "text": "Replacing words with POS tags reduces the possibility that the style model is a learning topic, but re-replacing too many words loses useful community jargon. To explore this trade-off, we compared four trigram language models that represent different word uses versus POS tags in the vocabulary: \u2022 word _ only: a regular token-based language model (vocabulary: 156K words) \u2022 hyb-15k: a hybrid word-POS language model over a vocabulary of 15K most common words in all communities in our data; all other words are converted into POS tags (vocabulary: 15K words + 38 tags) \u2022 hyb-500.30: a hybrid word-POS language model over a vocabulary of 500 most common words in all communities in our data; all other words are converted into POS tags (combined with the union of the 30 most common words from each of the 17 subrescues sub-sub-38 word models) \u2022 all other words are only 854 words are combined into one POb-only:"}, {"heading": "4.2 Representing Topic", "text": "We train 100- and 200-dimensional LDA topic models (Lead et al., 2003) using gensim (R-ehu-r-eek and Sojka, 2010). We remove all stopwords (250 words) and use tf-idf normalized word counts in each comment (as documents). The vocabulary consists of 156K words, similar to the vocabulary of the word _ only language model. Theme models were trained using a subset of training data, using all the collected subreddits, but coincidentally about 15% of the training data of major subreddits of world news, today-learned and nfl.The topics learned show a combination of topics that reflect general characteristics of online discussions or topics that arise in many forums, some that have more specific topics, and others that do not appear particularly coherent. Topics (from LDA-100) that consistently have a high probability of topics appearing in all subedited topics."}, {"heading": "5 Community Classification", "text": "In fact, it is only one of many examples worth mentioning that are able to retaliate."}, {"heading": "6 Community Feedback Correlation", "text": "In this section, we will examine whether the style and / or topic values of a discussion or of a user are correlated with the response of the community; for user feedback, we will use karma points of the discussion format itself; for user feedback, we will calculate the subreddit-dependent k index of each user (Jaech et al., 2015), which is similarly defined to the well-known Hindex (Hirsch, 2005); specifically, the k index of a user in Subreddit j is the maximum holistic k topic, so that the user has at least k comments with karma greater than k in that subreddit. User k index values have a Zipfian distribution, as shown in Figure 1 for the World News Subreddit. We will calculate a standardized community similarity value s i, j = si, j \u2212 si, m, with si, m the corresponding value being composed of the subreddit model."}, {"heading": "7 Conclusion", "text": "In this paper, we use hybrid N-grams and theme models to characterize the style and theme of language in online communities. As communities focus on a common theme, theme characteristics are reflected in language style, but we find that the best model for determining community identity uses very few words and is largely based on POS patterns. We also use Reddit's Community Response System (Karma) to show that discussions and users with higher community support are more likely to correlate with the language style of the community, where the language model that best classifies the community also correlates most with community response. Furthermore, online users tend to have a more positive community response when they specialize in fewer subreddits. These results have implications for recognizing newcomers in a community and the popularity of posts, as well as for language generation."}, {"heading": "Acknowledgments", "text": "This paper is based on work supported by the DARPA DEFT Program. The views expressed are those of the authors and do not reflect the official policy or position of the Department of Defense or the U.S. Government. We thank the reviewers for their helpful feedback."}], "references": [{"title": "Data Selection for Statistical Machine Translation", "author": ["Amittai Axelrod"], "venue": "Ph.D. thesis,", "citeRegEx": "Axelrod.,? \\Q2014\\E", "shortCiteRegEx": "Axelrod.", "year": 2014}, {"title": "Stylometric analysis of scientific articles", "author": ["Matt Post", "David Yarowsky"], "venue": "In Proc. Conf. North American Chapter Assoc. for Computational Linguistics: Human Language Technologies (NAACL-HLT),", "citeRegEx": "Bergsma et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bergsma et al\\.", "year": 2012}, {"title": "Latent dirichlet allocation", "author": ["Blei et al.2003] David M. Blei", "Andrew Y. Ng", "Michael I. Jordan"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "Blei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Chameleons in imagined conversations: A new approach to understanding coordination of linguistic style in dialog", "author": ["Danescu-Niculescu-Mizil", "Lillian Lee"], "venue": null, "citeRegEx": "Danescu.Niculescu.Mizil et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Danescu.Niculescu.Mizil et al\\.", "year": 2011}, {"title": "Mark my words! Linguistic style accommodation in social media", "author": ["Michael Gamon", "Susan Dumais"], "venue": "In Proceedings of WWW", "citeRegEx": "DanescuNiculescu.Mizil et al\\.,? \\Q2011\\E", "shortCiteRegEx": "DanescuNiculescu.Mizil et al\\.", "year": 2011}, {"title": "No country for old members: User lifecycle and linguistic change in online communities", "author": ["Robert West", "Dan Jurafsky", "Jure Leskovec", "Christopher Potts"], "venue": "Proceedings of WWW", "citeRegEx": "DanescuNiculescu.Mizil et al\\.,? \\Q2013\\E", "shortCiteRegEx": "DanescuNiculescu.Mizil et al\\.", "year": 2013}, {"title": "Part-of-speech histogram features for genre classification of text", "author": ["Alex Marin", "Mari Ostendorf", "Maya Gupta"], "venue": "In Proc. ICASSP,", "citeRegEx": "Feldman et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Feldman et al\\.", "year": 2009}, {"title": "An index to quantify an individual\u2019s scientific research output", "author": ["Jorge E. Hirsch"], "venue": "Proceedings of the National Academy of Sciences of the United States of America,", "citeRegEx": "Hirsch.,? \\Q2005\\E", "shortCiteRegEx": "Hirsch.", "year": 2005}, {"title": "Relevance weighting for combining multidomain data for n-gram language modeling", "author": ["Iyer", "Ostendorf1999] Rukmini Iyer", "Mari Ostendorf"], "venue": null, "citeRegEx": "Iyer et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Iyer et al\\.", "year": 1999}, {"title": "Talking to the crowd: What do people react to in online discussions", "author": ["Jaech et al.2015] Aaron Jaech", "Victoria Zayats", "Hao Fang", "Mari Ostendorf", "Hannaneh Hajishirzi"], "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural", "citeRegEx": "Jaech et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jaech et al\\.", "year": 2015}, {"title": "What\u2019s in a name? Understanding the interplay between titles", "author": ["Julian McAuley", "Jure Leskovec"], "venue": null, "citeRegEx": "Lakkaraju et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lakkaraju et al\\.", "year": 2013}, {"title": "Entrainment in speech preceding backchannels", "author": ["Agust\u0131\u0301n Gravano", "Julia Hirschberg"], "venue": "In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,", "citeRegEx": "Levitan et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Levitan et al\\.", "year": 2011}, {"title": "The Stanford CoreNLP natural language processing toolkit. In Association for Computational Linguistics (ACL) System", "author": ["Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": null, "citeRegEx": "Manning et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Language use as a reflection of socialization in online communities", "author": ["Nguyen", "Ros\u00e92011] Dong Nguyen", "Carolyn P. Ros\u00e9"], "venue": "In Proceedings of the Workshop on Languages in Social Media,", "citeRegEx": "Nguyen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2011}, {"title": "Stable classification of text genres", "author": ["Petrenz", "Webber2011] Philipp Petrenz", "Bonnie Webber"], "venue": "Computational Linguistics,", "citeRegEx": "Petrenz et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Petrenz et al\\.", "year": 2011}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["\u0158eh\u016f\u0159ek", "Sojka2010] Radim \u0158eh\u016f\u0159ek", "Petr Sojka"], "venue": "In Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks,", "citeRegEx": "\u0158eh\u016f\u0159ek et al\\.,? \\Q2010\\E", "shortCiteRegEx": "\u0158eh\u016f\u0159ek et al\\.", "year": 2010}, {"title": "Gender attribution: Tracing stylometric evidence beyond topic and genre", "author": ["Kailash Gajulapalli", "Yejin Choi"], "venue": "In Proceedings of the Fifteenth Conference on Computational Natural Language Learning,", "citeRegEx": "Sarawgi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sarawgi et al\\.", "year": 2011}, {"title": "Text genre detection using common word frequencies", "author": ["Nikos Fakotakis", "George Kokkinakis"], "venue": "In Proceedings of the 18th Conference on Computational Linguistics - Volume", "citeRegEx": "Stamatatos et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Stamatatos et al\\.", "year": 2000}, {"title": "SRILM-an extensible language modeling toolkit", "author": ["Andreas Stolcke"], "venue": "In Proceedings International Conference on Spoken Language Processing,", "citeRegEx": "Stolcke.,? \\Q2002\\E", "shortCiteRegEx": "Stolcke.", "year": 2002}, {"title": "All who wander: On the prevalence and characteristics", "author": ["Tan", "Lee2015] Chenhao Tan", "Lillian Lee"], "venue": null, "citeRegEx": "Tan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tan et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 11, "context": "It is well known that conversation partners become more linguistically similar to each other as their dialogue evolves, via many aspects such as lexical, syntactic, as well as acoustic characteristics (Niederhoffer and Pennebaker, 2002; Levitan et al., 2011).", "startOffset": 201, "endOffset": 258}, {"referenceID": 3, "context": "those of the community they participate in, reaching \u201clinguistic maturity\u201d over time (Nguyen and Ros\u00e9, 2011; Danescu-Niculescu-Mizil et al., 2013). In a multi-community setting, Tan and Lee (2015) found", "startOffset": 109, "endOffset": 197}, {"referenceID": 10, "context": "Lakkaraju et al. (2013) proposed a community model to predict the popularity of a resubmitted content, revealing that its title plays", "startOffset": 0, "endOffset": 24}, {"referenceID": 9, "context": "Jaech et al. (2015) considered timing and a variety of language features in ranking comments for popularity, finding significant differences across different communities.", "startOffset": 0, "endOffset": 20}, {"referenceID": 17, "context": "For modeling style, a popular approach has been combining the selected words with part-of-speech (POS) tags to construct models for genre detection (Stamatatos et al., 2000; Feldman et al., 2009; Bergsma et al., 2012) and data selection (Iyer and Ostendorf, 1999; Axelrod, 2014).", "startOffset": 148, "endOffset": 217}, {"referenceID": 6, "context": "For modeling style, a popular approach has been combining the selected words with part-of-speech (POS) tags to construct models for genre detection (Stamatatos et al., 2000; Feldman et al., 2009; Bergsma et al., 2012) and data selection (Iyer and Ostendorf, 1999; Axelrod, 2014).", "startOffset": 148, "endOffset": 217}, {"referenceID": 1, "context": "For modeling style, a popular approach has been combining the selected words with part-of-speech (POS) tags to construct models for genre detection (Stamatatos et al., 2000; Feldman et al., 2009; Bergsma et al., 2012) and data selection (Iyer and Ostendorf, 1999; Axelrod, 2014).", "startOffset": 148, "endOffset": 217}, {"referenceID": 0, "context": ", 2012) and data selection (Iyer and Ostendorf, 1999; Axelrod, 2014).", "startOffset": 27, "endOffset": 68}, {"referenceID": 2, "context": "For topic, a common approach is Latent Dirichlet Allocation (LDA) (Blei et al., 2003).", "startOffset": 66, "endOffset": 85}, {"referenceID": 16, "context": "We follow such approaches in our work, acknowledging the challenge of completely separating style/genre and topic factors raised previously (Iyer and Ostendorf, 1999; Sarawgi et al., 2011; Petrenz and Webber, 2011; Axelrod, 2014), which also comes out in our analysis.", "startOffset": 140, "endOffset": 229}, {"referenceID": 0, "context": "We follow such approaches in our work, acknowledging the challenge of completely separating style/genre and topic factors raised previously (Iyer and Ostendorf, 1999; Sarawgi et al., 2011; Petrenz and Webber, 2011; Axelrod, 2014), which also comes out in our analysis.", "startOffset": 140, "endOffset": 229}, {"referenceID": 12, "context": "Tokenization and tagging are done using Stanford coreNLP (Manning et al., 2014).", "startOffset": 57, "endOffset": 79}, {"referenceID": 18, "context": "All language models are trigrams trained using the SRILM toolkit (Stolcke, 2002); modified KneserNey smoothing is applied to the word_only language model, while Witten-Bell smoothing is applied to the tag_only and both hybrid models.", "startOffset": 65, "endOffset": 80}, {"referenceID": 2, "context": "We train 100- and 200-dimensional LDA topic models (Blei et al., 2003) using gensim (\u0158eh\u016f\u0159ek and Sojka, 2010).", "startOffset": 51, "endOffset": 70}, {"referenceID": 9, "context": "For thread-level feedback, we use karma points of the discussion thread itself; for the user-level feedback, we compute each user\u2019s subreddit-dependent k-index (Jaech et al., 2015), defined similarly to the well-known hindex (Hirsch, 2005).", "startOffset": 160, "endOffset": 180}, {"referenceID": 7, "context": ", 2015), defined similarly to the well-known hindex (Hirsch, 2005).", "startOffset": 52, "endOffset": 66}], "year": 2016, "abstractText": "This work investigates style and topic aspects of language in online communities: looking at both utility as an identifier of the community and correlation with community reception of content. Style is characterized using a hybrid word and part-of-speech tag n-gram language model, while topic is represented using Latent Dirichlet Allocation. Experiments with several Reddit forums show that style is a better indicator of community identity than topic, even for communities organized around specific topics. Further, there is a positive correlation between the community reception to a contribution and the style similarity to that community, but not so for topic similarity.", "creator": "LaTeX with hyperref package"}}}