{"id": "1609.05796", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Sep-2016", "title": "Enabling Dark Energy Science with Deep Generative Models of Galaxy Images", "abstract": "Understanding the nature of dark energy, the mysterious force driving the accelerated expansion of the Universe, is a major challenge of modern cosmology. The next generation of cosmological surveys, specifically designed to address this issue, rely on accurate measurements of the apparent shapes of distant galaxies. However, shape measurement methods suffer from various unavoidable biases and therefore will rely on a precise calibration to meet the accuracy requirements of the science analysis. This calibration process remains an open challenge as it requires large sets of high quality galaxy images. To this end, we study the application of deep conditional generative models in generating realistic galaxy images. In particular we consider variations on conditional variational autoencoder and introduce a new adversarial objective for training of conditional generative networks. Our results suggest a reliable alternative to the acquisition of expensive high quality observations for generating the calibration data needed by the next generation of cosmological surveys.", "histories": [["v1", "Mon, 19 Sep 2016 15:48:03 GMT  (19176kb,D)", "https://arxiv.org/abs/1609.05796v1", null], ["v2", "Wed, 30 Nov 2016 16:57:52 GMT  (4403kb,D)", "http://arxiv.org/abs/1609.05796v2", null]], "reviews": [], "SUBJECTS": "astro-ph.IM astro-ph.CO cs.AI stat.ML", "authors": ["siamak ravanbakhsh", "francois lanusse", "rachel mandelbaum", "jeff g schneider", "barnab\u00e1s p\u00f3czos"], "accepted": true, "id": "1609.05796"}, "pdf": {"name": "1609.05796.pdf", "metadata": {"source": "CRF", "title": "Enabling Dark Energy Science with Deep Generative Models of Galaxy Images", "authors": ["Siamak Ravanbakhsh", "Fran\u00e7ois Lanusse", "Rachel Mandelbaum", "Jeff Schneider", "Barnab\u00e1s P\u00f3czos"], "emails": [], "sections": [{"heading": null, "text": "The last two decades have produced a very small but contiguous deformation of the background galaxy, while providing several great mysteries in our cosmological model. We now have compelling evidence that the expansion of the universe needs to be accelerated to capture the vast majority of the total energy fractions of the universe, but we have no understanding of what dark energy actually is, which is one of the major motivations for the next generation of cosmological studies, such as the LSST LSST Science Collaboration et al. (2011) and the WFIRST Green et al. (2012) These billion dollar projects are specifically designed for the light of dark energy by investigating the weak gravitational effect -i.e."}, {"heading": "I. WEAK GRAVITATIONAL LENSING", "text": "In the weak regime of gravitational lensing, followed by a simple modeling of the adapted function of galaxy images, interest is measured by an anisotropic shear, noted \u03b3, whose amplitude and orientation depend on the distribution of matter between the observer and these distant galaxies. However, this shear concerns in particular the apparent ellipticity of the galaxies, which is then used as a weak but unbiased scanning effect, assuming that background galaxies are randomly oriented, so that the ensemble average of shapes in the absence of Lensing would be reduced to zero on average. Their apparent ellipticity e can then be used as a noisy but unbiased estimator of the shearfield Higgs of galaxy distributions. The current approach to this problem in cosmology literature is to adapt analytical parametric light profiles (defined as a function of galaxy adapted to the size, intensity, and ellipticity function)."}, {"heading": "A. Data set", "text": "As our main dataset, we use the COSMOS survey to create a training and validation set of galaxy images and extract from the corresponding catalog a condition vector y with three characteristics: half-light radius (measure of size), brightness (measure of brightness), and redshift (cosmological measure of distance). To facilitate training, we align all galaxies along their main axis and generate 85,000 instances of 64x64 stamps with the GalSim package. In addition, we use the GALAXY ZOO dataset Willett et al. (2013) to demonstrate the capabilities of our alternative contrarian lens. Each of the 61,000 galaxy images in this dataset is accompanied by y elements created using a set of questions that form a decision tree."}, {"heading": "II. CONDITIONAL VARIATIONAL AUTOENCODER", "text": "In a latent variable model, we have introduced different versions of the \"conditional\" variable increase in variable power that we have learned in the past (2014) and in the future (2014). Although the architecture we are discussing here is similar to those of Kingma et al. (2014), there are some differences due to different objective aspects. (2015) We are interested in learning the conditional density p \"(x) for x\" X \"and y\" Y, \"since a number of observations D = (x), y\" 1), y \"X,\" y \"N,\" by learning model parameters that explain the conditional liquidity p \"X\" and y \"Y\" Y. \"(x) D\" pctuation \"(x) - e.g., for which COSMOS dataset X = < 64 x\" Y. \""}, {"heading": "A. Cross-Correlation", "text": "Inspired by the application of cross-correlation in the unbundling of factors in an autoencoder by Cheung et al. (2014), we are also considering an alternative method of conditioning in UAE. Let us start from a simple question: What happens here if we simplify the previous p\u03b81 (z | y) \u21d2 p\u03b81 (z)? In principle, the simplified C-UAE would try to generate the posterior q\u03c6 (z | x, y) independently of y.2 In this case, we could still scan z-pzip1 (\u00b7 y) for the generation of samples and then x-p\u04452 (\u00b7 y, z). In practice, we observe that z and y are more and more correlated during training, but this happens at a slow pace. We can further enforce this decoration by applying a minibatch model of cross-correlation between z ({y}), {z-def = empemp2-j-i-i (1)."}, {"heading": "B. Experiments", "text": "Figure 4 compares the reduction of the average cross relationship between y and z for the same network, with and without cross-correlation penalty. For numerical stability, we increase the penalty coefficient linearly from 0 to 1000 over iterations. These results refer to the COSMOS dataset. All C-VAE results use log pixel intensity, even for numerical stability. Figure 5 compares \u2212 log (p\u03b8 (x-y value) for three models: I use a neural network to encode p\u03b81 (z | y) II using pPh\u00e4nomen1 (z | y) = pPh\u00e4nomen1 (z | y) III pPh\u00e4nomen1 (z | y) = pPh\u00e4nomen1 (z) plus cross-correlation penalty. The figure suggests that the first scheme ultimately produces better models. It also shows that enforcing the independence of z and y reduces the probability only slightly compared to baseline II, where z and y remain highly dependent."}, {"heading": "III. A NEW OBJECTIVE FOR ADVERSARIAL TRAINING", "text": "A major problem with UAE-generated images is their blurring. (A few recent papers deal with this issue (2016); Larsen et al. (2015); Dosovitskiy and Brox (2016) - an alternative to generative modeling that does not suffer from this problem is offered by adversative generative network training. (2014) In the adversarial setting, a generator reduces this problem to some extent: Z \u2192 X Attempts to thwart discrimination. (0, 1] In classifying its false instances x = G (z) as real, while the discriminator's goal is to correctly classify the two sources of real versus generated instances."}, {"heading": "A. Experiments", "text": "Following Radford et al. (2015), we use (de) revolutionary layers with (broken) pedometers, which we use to measure the actual intensity of our measurements (batch normalization Ioffe and Szegedy (2015) and leaky-ReLU activation functions in our deep networks. For optimization, we use Adam Kingma and Ba (2014) with a reduced exponential decay rate of.5 for the first time estimates. Figure 6 reports the prediction loss \"(R, y) and\" (R, x) for the COSMOS dataset, where we use 4 (de) convolution layers. The figure suggests that prediction tendencies tend to keep the real images slightly higher than the generated images. We reduce both of these quantities over time, and their consistency with validation errors may monitor convergence."}], "references": [{"title": "Discovering hidden factors of variation in deep networks", "author": ["Brian Cheung", "Jesse A Livezey", "Arjun K Bansal", "Bruno A Olshausen"], "venue": "arXiv preprint arXiv:1412.6583,", "citeRegEx": "Cheung et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cheung et al\\.", "year": 2014}, {"title": "Deep generative image models using a laplacian pyramid of adversarial networks", "author": ["Emily L Denton", "Soumith Chintala", "Rob Fergus"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Denton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Denton et al\\.", "year": 2015}, {"title": "Generating images with perceptual similarity metrics based on deep networks", "author": ["Alexey Dosovitskiy", "Thomas Brox"], "venue": "arXiv preprint arXiv:1602.02644,", "citeRegEx": "Dosovitskiy and Brox.,? \\Q2016\\E", "shortCiteRegEx": "Dosovitskiy and Brox.", "year": 2016}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Wide-Field InfraRed Survey Telescope (WFIRST) Final Report", "author": ["J. Green", "P. Schechter", "C. Baltay", "R. Bean", "D. Bennett", "R. Brown", "C. Conselice", "M. Donahue"], "venue": null, "citeRegEx": "Green et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Green et al\\.", "year": 2012}, {"title": "Shear calibration biases in weaklensing surveys", "author": ["C. Hirata", "U. Seljak"], "venue": "Monthly Notices of the Royal Astronomical Society,", "citeRegEx": "Hirata and Seljak.,? \\Q2003\\E", "shortCiteRegEx": "Hirata and Seljak.", "year": 2003}, {"title": "A study of the sensitivity of shape measurements to the input parameters of weak lensing image simulations", "author": ["Henk Hoekstra", "Massimo Viola", "Ricardo Herbonnet"], "venue": "arXiv preprint arXiv:1609.03281,", "citeRegEx": "Hoekstra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hoekstra et al\\.", "year": 2016}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "Ioffe and Szegedy.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe and Szegedy.", "year": 2015}, {"title": "The des science verification weak lensing shear catalogues", "author": ["M Jarvis", "E Sheldon", "J Zuntz", "T Kacprzak", "SL Bridle", "A Amara", "R Armstrong", "MR Becker", "GM Bernstein", "C Bonnett"], "venue": "Monthly Notices of the Royal Astronomical Society,", "citeRegEx": "Jarvis et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jarvis et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling.,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "Semi-supervised learning with deep generative models", "author": ["Diederik P Kingma", "Shakir Mohamed", "Danilo Jimenez Rezende", "Max Welling"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Improving variational inference with inverse autoregressive flow", "author": ["Diederik P. Kingma", "Tim Salimans", "Max Welling"], "venue": null, "citeRegEx": "Kingma et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2016}, {"title": "Gravitational Lensing Accuracy Testing 2010 (GREAT10) Challenge Handbook", "author": ["T. Kitching", "S. Balan", "G. Bernstein", "M. Bethge", "S. Bridle", "F. Courbin", "M. Gentile", "A. Heavens"], "venue": null, "citeRegEx": "Kitching et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Kitching et al\\.", "year": 2010}, {"title": "Autoencoding beyond pixels using a learned similarity metric", "author": ["Anders Boesen Lindbo Larsen", "S\u00f8ren Kaae S\u00f8nderby", "Ole Winther"], "venue": "arXiv preprint arXiv:1512.09300,", "citeRegEx": "Larsen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Larsen et al\\.", "year": 2015}, {"title": "Euclid Definition Study Report", "author": ["R. Laureijs", "J. Amiaux", "S. Arduini", "J. . Augu\u00e8res", "J. Brinchmann", "R. Cole", "M. Cropper", "C. Dabin", "L. Duvet", "A. Ealet"], "venue": null, "citeRegEx": "Laureijs et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Laureijs et al\\.", "year": 2011}, {"title": "The Third Gravitational Lensing Accuracy Testing (GREAT3) Challenge Handbook", "author": ["R. Mandelbaum", "B. Rowe", "J. Bosch", "C. Chang", "F. Courbin", "M. Gill", "M. Jarvis", "A. Kannawadi"], "venue": "The Astrophysical Journal Supplement,", "citeRegEx": "Mandelbaum et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mandelbaum et al\\.", "year": 2014}, {"title": "A deep generative model", "author": ["J Regier", "J McAuliffe", "Prabhat"], "venue": null, "citeRegEx": "Regier et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Regier et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 14, "context": "(2009), Euclid Laureijs et al. (2011) and WFIRST Green et al.", "startOffset": 15, "endOffset": 38}, {"referenceID": 4, "context": "(2011) and WFIRST Green et al. (2012). These billion dollar projects are specifically designed to shed light on the nature of dark energy by probing the Universe through the weak gravitational lensing effect \u2013i.", "startOffset": 18, "endOffset": 38}, {"referenceID": 16, "context": "Image credit: Mandelbaum et al. (2014), adapted", "startOffset": 14, "endOffset": 39}, {"referenceID": 13, "context": "from Kitching et al. (2010).", "startOffset": 5, "endOffset": 28}, {"referenceID": 9, "context": "Two prominent approaches for training these models are variational autoencoder (VAE) Kingma and Welling (2013); Rezende et al.", "startOffset": 85, "endOffset": 111}, {"referenceID": 9, "context": "Two prominent approaches for training these models are variational autoencoder (VAE) Kingma and Welling (2013); Rezende et al. (2014) and generative adversarial network (GAN) Goodfellow et al.", "startOffset": 85, "endOffset": 134}, {"referenceID": 3, "context": "(2014) and generative adversarial network (GAN) Goodfellow et al. (2014). Our aim is to train a coditional variation of these models using existing HST data and generate new galaxy ar X iv :1 60 9.", "startOffset": 48, "endOffset": 73}, {"referenceID": 17, "context": "In related works in machine learning literature Regier et al. (2015b) use a convex combination of smooth and spiral templates in an (unconditioned) generative model of galaxy images and Regier et al.", "startOffset": 48, "endOffset": 70}, {"referenceID": 17, "context": "In related works in machine learning literature Regier et al. (2015b) use a convex combination of smooth and spiral templates in an (unconditioned) generative model of galaxy images and Regier et al. (2015a) propose using VAE for this task.", "startOffset": 48, "endOffset": 208}, {"referenceID": 6, "context": ", see Hoekstra et al. (2016); Appendix A.", "startOffset": 6, "endOffset": 29}, {"referenceID": 6, "context": ", see Hoekstra et al. (2016); Appendix A. However, simple parametric models of galaxy light profiles do not have the complex morphologies needed for calibration task. The only currently available alternative, if realistic galaxy morphologies are needed, is to use the training set images themselves as the input of the simulation pipeline. This involves subsampling the training set to match the distribution of size, redshift and brightness of the target galaxy simulations, leaving only a relatively small number of objects, reused several hundred times to simulate a large survey \u2013 e.g., see Jarvis et al. (2016); Section 6.", "startOffset": 6, "endOffset": 616}, {"referenceID": 11, "context": "Applications in semi-supervised learning and structured prediction have motivated different versions of the \u201cconditional\u201d variational autoencoder (C-VAE) in the past Kingma et al. (2014); Sohn et al.", "startOffset": 166, "endOffset": 187}, {"referenceID": 11, "context": "Applications in semi-supervised learning and structured prediction have motivated different versions of the \u201cconditional\u201d variational autoencoder (C-VAE) in the past Kingma et al. (2014); Sohn et al. (2015). Although the architecture that we discuss here resembles to those of Kingma et al.", "startOffset": 166, "endOffset": 207}, {"referenceID": 11, "context": "Applications in semi-supervised learning and structured prediction have motivated different versions of the \u201cconditional\u201d variational autoencoder (C-VAE) in the past Kingma et al. (2014); Sohn et al. (2015). Although the architecture that we discuss here resembles to those of Kingma et al. (2014); Sohn et al.", "startOffset": 166, "endOffset": 298}, {"referenceID": 11, "context": "Applications in semi-supervised learning and structured prediction have motivated different versions of the \u201cconditional\u201d variational autoencoder (C-VAE) in the past Kingma et al. (2014); Sohn et al. (2015). Although the architecture that we discuss here resembles to those of Kingma et al. (2014); Sohn et al. (2015), there are some differences due to different objectives.", "startOffset": 166, "endOffset": 318}, {"referenceID": 10, "context": "Fortunately, the reparametrization-trick by Kingma and Welling (2013); Rezende et al.", "startOffset": 44, "endOffset": 70}, {"referenceID": 10, "context": "Fortunately, the reparametrization-trick by Kingma and Welling (2013); Rezende et al. (2014); Williams (1992) enables the maximization of this lower-bound (i.", "startOffset": 44, "endOffset": 93}, {"referenceID": 10, "context": "Fortunately, the reparametrization-trick by Kingma and Welling (2013); Rezende et al. (2014); Williams (1992) enables the maximization of this lower-bound (i.", "startOffset": 44, "endOffset": 110}, {"referenceID": 0, "context": "Inspired by the application of cross-correlation in disentangling the factors in an autoencoder by Cheung et al. (2014), we also consider an alternative method of conditioning in VAE.", "startOffset": 99, "endOffset": 120}, {"referenceID": 10, "context": "A few recent works address this issue Kingma et al. (2016); Larsen et al.", "startOffset": 38, "endOffset": 59}, {"referenceID": 10, "context": "A few recent works address this issue Kingma et al. (2016); Larsen et al. (2015); Dosovitskiy and Brox (2016) \u2013 e.", "startOffset": 38, "endOffset": 81}, {"referenceID": 2, "context": "(2015); Dosovitskiy and Brox (2016) \u2013 e.", "startOffset": 8, "endOffset": 36}, {"referenceID": 3, "context": "An alternative to generative modeling that does not suffer from this problem is offered by adversarial training of generative networks Goodfellow et al. (2014). In the adversarial setting, a generator G\u03c9 : Z \u2192 X attempts to fool the discriminator D\u03c8 : X \u2192 [0, 1] into classifying its fake instances x = G(z) as real, while the discriminator\u2019s objective is to correctly classify the two sources of real versus generated instances.", "startOffset": 135, "endOffset": 160}, {"referenceID": 3, "context": "An alternative to generative modeling that does not suffer from this problem is offered by adversarial training of generative networks Goodfellow et al. (2014). In the adversarial setting, a generator G\u03c9 : Z \u2192 X attempts to fool the discriminator D\u03c8 : X \u2192 [0, 1] into classifying its fake instances x = G(z) as real, while the discriminator\u2019s objective is to correctly classify the two sources of real versus generated instances. Deep networks representing these adversaries are trained alternatively, and under some conditions pG (the implicit distribution of the generator G\u03c9 for z \u223c U(0, 1)) converges to p\u2217 \u2013i.e., at this fixed-point, the generator produces realistic images that are indistinguishable by the discriminator. The conditional variation of this method was first introduced by Mirza and Osindero (2014) and used in a cascade", "startOffset": 135, "endOffset": 819}, {"referenceID": 1, "context": "of conditional models with increasing resolution in Denton et al. (2015). In these conditional models, the generator G\u03c9 : Z\u00d7Y \u2192 X and the discriminator D\u03c8 : X \u00d7Y \u2192 [0, 1], are both deep neural networks that are now conditioned on the same observed variable \u0177 \u2208 D.", "startOffset": 52, "endOffset": 73}, {"referenceID": 3, "context": "In practice it is much more efficient to use a different loss function for the generator as it produces stronger gradients for the generator at the beginning Goodfellow et al. (2014):", "startOffset": 158, "endOffset": 183}, {"referenceID": 7, "context": "(2015) we use (de)convolutional layers with (fractional) stride, batch normalization Ioffe and Szegedy (2015) and leaky-ReLU activation functions in our deep networks.", "startOffset": 85, "endOffset": 110}, {"referenceID": 7, "context": "(2015) we use (de)convolutional layers with (fractional) stride, batch normalization Ioffe and Szegedy (2015) and leaky-ReLU activation functions in our deep networks. For optimization, we use Adam Kingma and Ba (2014) with reduced exponential decay rate of .", "startOffset": 85, "endOffset": 219}, {"referenceID": 5, "context": "To measure Q in practice, we use the adaptive moments method Hirata and Seljak (2003); Mandelbaum et al.", "startOffset": 61, "endOffset": 86}, {"referenceID": 5, "context": "To measure Q in practice, we use the adaptive moments method Hirata and Seljak (2003); Mandelbaum et al. (2005) which estimates the second order moments by fitting an elliptical Gaussian profile to the galaxy light profile.", "startOffset": 61, "endOffset": 112}], "year": 2016, "abstractText": "Understanding the nature of dark energy, the mysterious force driving the accelerated expansion of the Universe, is a major challenge of modern cosmology. The next generation of cosmological surveys, specifically designed to address this issue, rely on accurate measurements of the apparent shapes of distant galaxies. However, shape measurement methods suffer from various unavoidable biases and therefore will rely on a precise calibration to meet the accuracy requirements of the science analysis. This calibration process remains an open challenge as it requires large sets of high quality galaxy images. To this end, we study the application of deep conditional generative models in generating realistic galaxy images. In particular we consider variations on conditional variational autoencoder and introduce a new adversarial objective for training of conditional generative networks. Our results suggest a reliable alternative to the acquisition of expensive high quality observations for generating the calibration data needed by the next generation of cosmological surveys. The last two decades have greatly clarified the contents of the Universe, while leaving several large mysteries in our cosmological model. We now have compelling evidence that the expansion rate of the Universe is accelerating, suggesting that the vast majority of the total energy content of the Universe is the so-called dark energy. Yet we lack an understanding of what dark energy actually is, which provides one of the main motivations behind the next generation of cosmological surveys such as LSST LSST Science Collaboration et al. (2009), Euclid Laureijs et al. (2011) and WFIRST Green et al. (2012). These billion dollar projects are specifically designed to shed light on the nature of dark energy by probing the Universe through the weak gravitational lensing effect \u2013i.e., the minute deflection of the light from distant objects by the intervening massive large scale structures of the Universe. On cosmological scales, this lensing effect causes very small but coherent deformations of background galaxy images, which appear slightly sheared, providing a way to statistically map the matter distribution in the Universe. To measure the lensing signal, future surveys will image and measure the shapes of billions of galaxies, significantly driving down statistical errors compared to the current generation of surveys, to the level where dark energy models may become distinguishable. However, the quality of this analysis hinges on the accuracy of the shape measurement algorithms tasked with estimating the ellipticities of the galaxies in the survey. This point is particularly crucial to the success of these missions, as any unaccounted for measurement biases in their ensemble averages would impact the final cosmological analysis and potentially lead to false conclusions. In order to detect and/or calibrate any such biases, future surveys will heavily rely on image simulations, closely mimicking real observations but with a known ground truth lensing signal.", "creator": "LaTeX with hyperref package"}}}