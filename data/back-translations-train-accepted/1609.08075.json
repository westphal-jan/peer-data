{"id": "1609.08075", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Sep-2016", "title": "S-MART: Novel Tree-based Structured Learning Algorithms Applied to Tweet Entity Linking", "abstract": "Non-linear models recently receive a lot of attention as people are starting to discover the power of statistical and embedding features. However, tree-based models are seldom studied in the context of structured learning despite their recent success on various classification and ranking tasks. In this paper, we propose S-MART, a tree-based structured learning framework based on multiple additive regression trees. S-MART is especially suitable for handling tasks with dense features, and can be used to learn many different structures under various loss functions.", "histories": [["v1", "Mon, 26 Sep 2016 17:01:03 GMT  (134kb,D)", "http://arxiv.org/abs/1609.08075v1", "Appeared in ACL 2015 proceedings. This is an updated version. More details available in the pdf file"]], "COMMENTS": "Appeared in ACL 2015 proceedings. This is an updated version. More details available in the pdf file", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yi yang", "ming-wei chang"], "accepted": true, "id": "1609.08075"}, "pdf": {"name": "1609.08075.pdf", "metadata": {"source": "CRF", "title": "S-MART: Novel Tree-based Structured Learning Algorithms Applied to Tweet Entity Linking", "authors": ["Yi Yang", "Ming-Wei Chang"], "emails": ["yiyang@gatech.edu", "minchang@microsoft.com"], "sections": [{"heading": null, "text": "We apply S-MART to the task of linking Tweet entities - a core component of Tweet Information Extraction, which aims to identify and link attributions to entities in a knowledge base. To handle the specific structure of the task, a novel inference algorithm is proposed. Experimental results show that S-MART significantly outperforms the most advanced Tweet Entity Linking systems."}, {"heading": "1 Introduction", "text": "Many natural language processing (NLP) problems can be formalized as structured prediction. This classic combination of linear models and sparse features is challenged by the recent use of dense features such as statistical and embedded characteristics. Tasks with these low-dimensional dense features require models that are more complex to capture the relationships between characteristics. Therefore, nonlinear models begin to get more attention as they are often more expressive than linear models.Tree-based models such as augmented trees (Friedman, 2001) are flexible nonlinear models. They can handle categorical characteristics and count data better than other nonlinear models such as Neural Networks. Unfortunately, the best solution to our knowledge has been to little work using tree-based methods for structured prediction, with the exception of TreeCRF (Dietterich et al., 2004).In this paper, we propose a novel structured, structured learning system called S-MART."}, {"heading": "2 Structured Multiple Additive Regression Trees", "text": "The goal of a structured learning algorithm is to create a common scoring function S between an input x and an output structure y, S: (x, y) \u2192 R. Structured output y often contains many interdependent variables and the number of possible structures can be exponentially large in relation to the size of x.Standard learning algorithms often directly optimize the model parameters. For example, we assume that the common scoring function S is parameterized by parameterizing the common scoring algorithms. Then, gradient descent algorithms can be used to optimize the model parameters iteratively. More specifically, m = output structure m \u2212 1 \u2212 \u03b7m parameters of the model parameters are parameterized."}, {"heading": "3 S-MART for Tweet Entity Linking", "text": "As input, we get a tweet, an entity database (e.g. Wikipedia, where each article is an entity), and a lexicon2, which maps a surface shape into a series of entity candidates. For each incoming tweet, all n-grams of that tweet are used to find matches in the lexicon, and each hit forms a mention candidate. As output, we assign each mention candidate (e.g. \"New York Giants\") in the message to an entity (e.g. NEW YORK-GIANTS) or Nil (i.e. a non-entity). A mention candidate can often potentially link multiple entities that we call possible entity assignments. This task is a structured learning problem, as the final entity assignment of a tweet should not overlap with any other."}, {"heading": "3.1 Applying S-MART", "text": "We derive a specific model for tweet unit, the task associated with S-MART, and use logistic loss as a running example. The hinge loss version of the model can be derived in a similar way. Note that the tweet and the mention candidates are given. Let x be the tweet, uk the mapping of the k-th mention candidates. We use function F (x, yk = uk) to model the scoring value of the k-th mention candidates. 4 The entire scoring function can be broken down as follows: S (x, y = {uk} Kk = 1) = K \u2211 k = 1 F (x, yk = uk) S-MART uses regression trees to model the scoring function F (x, yk = uk), x, x, x, x, x, x, x, x, next functional gradient x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x,"}, {"heading": "3.2 Inference", "text": "The non-overlapping structure differs from linear chain chains and Semi-Markov chains (Saraw\u03b2 = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = K = K = K = K = K = K (Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q \u2212 Q = Q \u2212 K = K = K = K = K = K = K = K = Q = Q = Q = Q = Q = Q = Q = Q = Q \u2212 K \u2212 K \u2212 K = K = K = K = K = K = K = K = K = K = K = K = K = K = K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212 K \u2212"}, {"heading": "3.3 Beyond S-MART: Modeling entity-entity relationships", "text": "In practice, the algorithm is almost linear when it comes to making local decisions. For example, identifying the \"elite management\" of an entity leads to a strong indication of the association of \"New York Giants\" with the NFL team. Instead of defining a more complicated structure and learning everything together, we use a two-step approach as a solution for modelling relationships between entities after we have found that SMART achieves high precision and reasonable memory. Specifically, in the first stage, the system identifies all possible entities with basic characteristics, allowing the extraction of entity characteristics. In the second stage, we retrain the connection between entities (JMART) based on a combination of basic characteristics and entity characteristics."}, {"heading": "4 Experiments", "text": "Our experiments are designed to answer the following three research questions related to the linkage of tweet entities: \u2022 Do non-linear learning algorithms work better than linear learning algorithms? \u2022 Do structured entity linkages work better than non-structured ones? \u2022 How can we best understand the relationships between entities?"}, {"heading": "4.1 Evaluation Methodology and Data", "text": "We evaluate each entity linkage system with two evaluation policies: Information Extraction (IE) driven assessment and Information Retrieval (IR) driven evaluation. For both levels of evaluation, it is important that our data is constructed from two publicly available sources: Named Entity Extraction & Linking (NEEL) Challenge (Nanos et al., 2014) datasets, and the datasets issued by Fang and Chang (2014). We collect two datasets from Fang and Chang (2014) and they are used in two different evaluation systems. We refer to these two datasets as TACL-IE and TACL-IR."}, {"heading": "4.2 Experimental Settings", "text": "Most of them are able to play by the rules they have imposed on themselves."}, {"heading": "4.3 Results", "text": "In fact, \"it's not like you're able to trump yourself,\" he said, \"but it's not like you're able to trump yourself.\" He added, \"It's not like you've been able to trump yourself.\" He added, \"It's not like you've been able to trump yourself.\" He added, \"It's not like you've been able to trump yourself.\" He added, \"It's not like you've been able to trump yourself.\""}, {"heading": "5 Related Work", "text": "Linear structured learning methods have been proposed and widely used in literature. Popular models include problem solving such as Structured Perceptron (Collins, 2002), Conditional Random Field (Lafferty et al., 2001) and Structured SVM (Taskar et al., 2004; Tsochantaridis et al., 2005). Recently, many structured learning models based on neural networks have been proposed and are also widely used in language modeling (Bengio et al., 2006; Mikolov et al., 2010), emotion classification (Socher et al., 2013), and task analysis (Socher et al., 2011). Cortes et al. (2014) recently proposed a funding framework that treats different structured learning algorithms as the basis of learners to group structured predictive outcomes. Tree-based models have proven to be more robust and accurate than neural networks in some tasks of Computervision (Roe, Babet et al, 2011 and Li et et al.)."}, {"heading": "6 Conclusion and Future Work", "text": "In this article, we propose S-MART, a family of structured learning algorithms that is flexible in selecting loss functions and structures. We demonstrate the power of S-MART by applying it to the linkage of tweet entities, and it clearly surpasses current state-of-the-art entity linkage systems. In the future, we would like to explore the pros and cons between tree-based models and other nonlinear models such as deep neural networks or recurring neural networks. Thank you to the reviewers for their insightful feedback. We also thank Yin Li and Ana Smith for their valuable comments on earlier versions of this paper."}, {"heading": "A Appendix: Results of Full Datasets", "text": "The statistics of the complete NEEL and TACL-IE datasets are presented in Table 4. Table 5 presents the IE-based evaluation results on the datasets. On the NEEL test dataset, non-linear models perform significantly better than linear models, tree-based models perform much better than alternative methods, and our tree-based structured prediction method S-MART achieves the best results. The tree-based, non-structured model MART delivers the best performance on the TACL-IE dataset with basic features, slightly outperforming S-MART by 0.5% F1. Entity relationships improve the performance of S-MART on the TACL-IE dataset by 3.6 points from F1."}], "references": [{"title": "Predicting the future with social media", "author": ["Asur", "Huberman2010] S. Asur", "B.A. Huberman"], "venue": "arXiv preprint arXiv:1003.5699", "citeRegEx": "Asur et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Asur et al\\.", "year": 2010}, {"title": "Robust object tracking with online multiple instance learning", "author": ["Ming-Hsuan Yang", "Serge Belongie"], "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,", "citeRegEx": "Babenko et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Babenko et al\\.", "year": 2011}, {"title": "Neural probabilistic language models", "author": ["Bengio et al.2006] Yoshua Bengio", "Holger Schwenk", "Jean-S\u00e9bastien Sen\u00e9cal", "Fr\u00e9deric Morin", "JeanLuc Gauvain"], "venue": "In Innovations in Machine Learning,", "citeRegEx": "Bengio et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2006}, {"title": "Using encyclopedic knowledge for named entity disambiguation", "author": ["Bunescu", "Pasca2006] R. C Bunescu", "M. Pasca"], "venue": "In Proceedings of the European Chapter of the ACL (EACL),", "citeRegEx": "Bunescu et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Bunescu et al\\.", "year": 2006}, {"title": "Learning to rank with nonsmooth cost functions. In Advances in neural information processing systems (NIPS), pages 193\u2013200", "author": ["Robert Ragno", "Quoc Le", "Qu"], "venue": null, "citeRegEx": "Burges et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Burges et al\\.", "year": 2007}, {"title": "Making sense of microposts (# microposts2014) named entity extraction & linking challenge. Making Sense of Microposts", "author": ["Cano et al.2014] Amparo E Cano", "Giuseppe Rizzo", "Andrea Varga", "Matthew Rowe", "Milan Stankovic", "Aba-Sah Dadzie"], "venue": null, "citeRegEx": "Cano et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cano et al\\.", "year": 2014}, {"title": "Erd\u201914: entity recognition and disambiguation challenge", "author": ["Kuansan Wang."], "venue": "ACM SIGIR Forum, pages 63\u201377.", "citeRegEx": "Wang.,? 2014", "shortCiteRegEx": "Wang.", "year": 2014}, {"title": "Efficient second-order gradient boosting for conditional random fields", "author": ["Chen et al.2015] Tianqi Chen", "Sameer Singh", "Ben Taskar", "Carlos Guestrin"], "venue": "In Proceedings of the International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the conference on Empirical methods in natural language processing", "author": ["Michael Collins"], "venue": null, "citeRegEx": "Collins.,? \\Q2002\\E", "shortCiteRegEx": "Collins.", "year": 2002}, {"title": "Learning ensembles of structured prediction rules", "author": ["Vitaly Kuznetsov", "Mehryar Mohri"], "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL)", "citeRegEx": "Cortes et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cortes et al\\.", "year": 2014}, {"title": "Large-scale named entity disambiguation based on wikipedia data", "author": ["Silviu Cucerzan"], "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "Cucerzan.,? \\Q2007\\E", "shortCiteRegEx": "Cucerzan.", "year": 2007}, {"title": "The msr system for entity linking at tac", "author": ["Silviu Cucerzan"], "venue": "In Text Analysis Conference", "citeRegEx": "Cucerzan.,? \\Q2012\\E", "shortCiteRegEx": "Cucerzan.", "year": 2012}, {"title": "Training conditional random fields via gradient tree boosting", "author": ["Adam Ashenfelter", "Yaroslav Bulatov"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "Dietterich et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Dietterich et al\\.", "year": 2004}, {"title": "Entity linking on microblogs with spatial and temporal signals. Transactions of the Association for Computational Linguistics (ACL), pages 259\u2013272", "author": ["Fang", "Chang2014] Yuan Fang", "Ming-Wei Chang"], "venue": null, "citeRegEx": "Fang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Fang et al\\.", "year": 2014}, {"title": "TAGME: on-the-fly annotation of short text fragments (by Wikipedia entities)", "author": ["Ferragina", "Scaiella2010] P. Ferragina", "U. Scaiella"], "venue": "In Proceedings of ACM Conference on Information and Knowledge Management (CIKM),", "citeRegEx": "Ferragina et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ferragina et al\\.", "year": 2010}, {"title": "Greedy function approximation: a gradient boosting machine", "author": ["Jerome H Friedman"], "venue": "Annals of Statistics,", "citeRegEx": "Friedman.,? \\Q2001\\E", "shortCiteRegEx": "Friedman.", "year": 2001}, {"title": "To link or not to link? a study on end-to-end tweet entity linking", "author": ["Guo et al.2013] Stephen Guo", "Ming-Wei Chang", "Emre Kiciman"], "venue": "In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL),", "citeRegEx": "Guo et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Guo et al\\.", "year": 2013}, {"title": "Knowledge base population: Successful approaches and challenges", "author": ["Ji", "Grishman2011] Heng Ji", "Ralph Grishman"], "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Ji et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2011}, {"title": "Overview of the tac 2010 knowledge base population track", "author": ["Ji et al.2010] Heng Ji", "Ralph Grishman", "Hoa Trang Dang", "Kira Griffitt", "Joe Ellis"], "venue": "In Third Text Analysis Conference (TAC)", "citeRegEx": "Ji et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2010}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["Andrew McCallum", "Fernando CN Pereira"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Mcrank: Learning to rank using multiple classification and gradient boosting. In Advances in neural information processing systems (NIPS), pages 897\u2013904", "author": ["Li et al.2007] Ping Li", "Qiang Wu", "Christopher J Burges"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Li et al\\.", "year": 2007}, {"title": "Entity linking for tweets", "author": ["Liu et al.2013] Xiaohua Liu", "Yitong Li", "Haocheng Wu", "Ming Zhou", "Furu Wei", "Yi Lu"], "venue": "In Proceedings of the Association for Computational Linguistics (ACL),", "citeRegEx": "Liu et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2013}, {"title": "Twittermonitor: trend detection over the twitter stream", "author": ["Mathioudakis", "Koudas2010] Michael Mathioudakis", "Nick Koudas"], "venue": "In Proceedings of the ACM SIGMOD International Conference on Management of data (SIGMOD),", "citeRegEx": "Mathioudakis et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mathioudakis et al\\.", "year": 2010}, {"title": "Adding semantics to microblog posts", "author": ["Meij et al.2012] E. Meij", "W. Weerkamp", "M. de Rijke"], "venue": "In Proceedings of International Conference on Web Search and Web Data Mining (WSDM),", "citeRegEx": "Meij et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Meij et al\\.", "year": 2012}, {"title": "Recurrent neural network based language model", "author": ["Martin Karafi\u00e1t", "Lukas Burget", "Jan Cernock\u1ef3", "Sanjeev Khudanpur"], "venue": "In INTERSPEECH,", "citeRegEx": "Mikolov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2010}, {"title": "Learning to link with Wikipedia", "author": ["Milne", "Witten2008] D. Milne", "I.H. Witten"], "venue": "In Proceedings of ACM Conference on Information and Knowledge Management (CIKM),", "citeRegEx": "Milne et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Milne et al\\.", "year": 2008}, {"title": "Machine learning: a probabilistic perspective", "author": ["Kevin P Murphy"], "venue": null, "citeRegEx": "Murphy.,? \\Q2012\\E", "shortCiteRegEx": "Murphy.", "year": 2012}, {"title": "Named entity recognition in tweets: an experimental study", "author": ["Ritter et al.2011] A. Ritter", "S. Clark", "Mausam", "O. Etzioni"], "venue": "In Proceedings of the Conference on Empirical Methods for Natural Language Processing (EMNLP),", "citeRegEx": "Ritter et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Boosted decision trees as an alternative to artificial", "author": ["Roe et al.2005] Byron P Roe", "Hai-Jun Yang", "Ji Zhu", "Yong Liu", "Ion Stancu", "Gordon McGregor"], "venue": null, "citeRegEx": "Roe et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Roe et al\\.", "year": 2005}, {"title": "Semi-markov conditional random fields for information extraction", "author": ["Sarawagi", "Cohen2004] Sunita Sarawagi", "William W Cohen"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Sarawagi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Sarawagi et al\\.", "year": 2004}, {"title": "Re-ranking for joint named-entity recognition and linking", "author": ["Sil", "Yates2013] Avirup Sil", "Alexander Yates"], "venue": "In Proceedings of ACM Conference on Information and Knowledge Management (CIKM),", "citeRegEx": "Sil et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sil et al\\.", "year": 2013}, {"title": "Parsing natural scenes and natural language with recursive neural networks", "author": ["Cliff C Lin", "Chris Manning", "Andrew Y Ng"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "Socher et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2011}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts"], "venue": null, "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Max-margin markov networks", "author": ["Taskar et al.2004] Ben Taskar", "Carlos Guestrin", "Daphne Roller"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "Taskar et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Taskar et al\\.", "year": 2004}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["Thomas Hofmann", "Thorsten Joachims", "Yasemin Altun"], "venue": "In Proceedings of the International Conference", "citeRegEx": "Tsochantaridis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2004}, {"title": "Large margin methods for structured and interdependent output variables", "author": ["Thorsten Joachims", "Thomas Hofmann", "Yasemin Altun"], "venue": "In Journal of Machine Learning Research,", "citeRegEx": "Tsochantaridis et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2005}, {"title": "Adapting boosting for information retrieval measures", "author": ["Wu et al.2010] Qiang Wu", "Christopher JC Burges", "Krysta M Svore", "Jianfeng Gao"], "venue": "Information Retrieval,", "citeRegEx": "Wu et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Wu et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 19, "context": "Standard algorithms for structured learning include Conditional Random Field (CRF) (Lafferty et al., 2001) and Structured Supported Vector Machine (SSVM) (Tsochantaridis et al.", "startOffset": 83, "endOffset": 106}, {"referenceID": 34, "context": ", 2001) and Structured Supported Vector Machine (SSVM) (Tsochantaridis et al., 2004).", "startOffset": 55, "endOffset": 84}, {"referenceID": 15, "context": "Tree-based models such as boosted trees (Friedman, 2001) are flexible non-linear models.", "startOffset": 40, "endOffset": 56}, {"referenceID": 12, "context": "Unfortunately, to the best of our knowledge, little work has utilized tree-based methods for structured prediction, with the exception of TreeCRF (Dietterich et al., 2004).", "startOffset": 146, "endOffset": 171}, {"referenceID": 26, "context": "where hm(x,yk) is also called a basis function and \u03b7m can be simply set to 1 (Murphy, 2012).", "startOffset": 77, "endOffset": 91}, {"referenceID": 12, "context": "First, the model designed in (Dietterich et al., 2004) is tailored for sequence tagging problems.", "startOffset": 29, "endOffset": 54}, {"referenceID": 16, "context": "We define entity-entity features based on the Jaccard distance introduced by Guo et al. (2013). Let \u0393(ei) denotes the set of Wikipedia pages that contain a hyperlink to an entity ei and \u0393(t\u2212i) denotes the set of pages that contain a hyperlink to any identified entity ej of the tweet t in the first stage excluding ei.", "startOffset": 77, "endOffset": 95}, {"referenceID": 5, "context": "Our data is constructed from two publicly available sources: Named Entity Extraction & Linking (NEEL) Challenge (Cano et al., 2014) datasets,", "startOffset": 112, "endOffset": 131}, {"referenceID": 16, "context": "Most of the features are adopted from (Guo et al., 2013)8, including various statistical features such as the probability of the surface to be used as anchor text in Wikipedia.", "startOffset": 38, "endOffset": 56}, {"referenceID": 8, "context": "First, we consider two linear structured learning algorithms: Structured Perceptron (Collins, 2002) and Linear Structured SVM (SSVM) (Tsochantaridis et al.", "startOffset": 84, "endOffset": 99}, {"referenceID": 34, "context": "First, we consider two linear structured learning algorithms: Structured Perceptron (Collins, 2002) and Linear Structured SVM (SSVM) (Tsochantaridis et al., 2004).", "startOffset": 133, "endOffset": 162}, {"referenceID": 4, "context": "We also include LambdaRank (Burges et al., 2007), a neuralbased learning to rank algorithm, which is widely used in the information retrieval literature.", "startOffset": 27, "endOffset": 48}, {"referenceID": 16, "context": "Linear SSVM has been used in one of the stateof-the-art tweet entity linking systems (Guo et al., 2013), and the system based on MART is the winning system of the 2014 NEEL Challenge (Cano and others, 2014)10.", "startOffset": 85, "endOffset": 103}, {"referenceID": 35, "context": "Among the linear models, linear SSVM demonstrates its superiority over Structured Perceptron on all datasets, which aligns with the results of (Tsochantaridis et al., 2005) on the named entity recognition task.", "startOffset": 143, "endOffset": 172}, {"referenceID": 16, "context": "As Guo et al. (2013) shows that most mentions in tweets should be linked to the most popular entities, IE setting actually pays more attention on mention detection sub-problem.", "startOffset": 3, "endOffset": 21}, {"referenceID": 8, "context": "Popular models include Structured Perceptron (Collins, 2002), Conditional Random Field (Lafferty et al.", "startOffset": 45, "endOffset": 60}, {"referenceID": 19, "context": "Popular models include Structured Perceptron (Collins, 2002), Conditional Random Field (Lafferty et al., 2001) and Structured SVM (Taskar et al.", "startOffset": 87, "endOffset": 110}, {"referenceID": 33, "context": ", 2001) and Structured SVM (Taskar et al., 2004; Tsochantaridis et al., 2005).", "startOffset": 27, "endOffset": 77}, {"referenceID": 35, "context": ", 2001) and Structured SVM (Taskar et al., 2004; Tsochantaridis et al., 2005).", "startOffset": 27, "endOffset": 77}, {"referenceID": 2, "context": "Recently, many structured learning models based on neural networks have been proposed and are widely used in language modeling (Bengio et al., 2006; Mikolov et al., 2010), sentiment classification (Socher et al.", "startOffset": 127, "endOffset": 170}, {"referenceID": 24, "context": "Recently, many structured learning models based on neural networks have been proposed and are widely used in language modeling (Bengio et al., 2006; Mikolov et al., 2010), sentiment classification (Socher et al.", "startOffset": 127, "endOffset": 170}, {"referenceID": 32, "context": ", 2010), sentiment classification (Socher et al., 2013), as well as parsing (Socher et al.", "startOffset": 34, "endOffset": 55}, {"referenceID": 31, "context": ", 2013), as well as parsing (Socher et al., 2011).", "startOffset": 28, "endOffset": 49}, {"referenceID": 2, "context": "Recently, many structured learning models based on neural networks have been proposed and are widely used in language modeling (Bengio et al., 2006; Mikolov et al., 2010), sentiment classification (Socher et al., 2013), as well as parsing (Socher et al., 2011). Cortes et al. (2014) recently proposed a boosting framework which treats different structured learning algorithms as base learners to ensemble structured prediction results.", "startOffset": 128, "endOffset": 283}, {"referenceID": 28, "context": "vide more robust and accurate performances than neural networks in some tasks of computer vision (Roe et al., 2005; Babenko et al., 2011) and information retrieval (Li et al.", "startOffset": 97, "endOffset": 137}, {"referenceID": 1, "context": "vide more robust and accurate performances than neural networks in some tasks of computer vision (Roe et al., 2005; Babenko et al., 2011) and information retrieval (Li et al.", "startOffset": 97, "endOffset": 137}, {"referenceID": 20, "context": ", 2011) and information retrieval (Li et al., 2007; Wu et al., 2010), suggesting that it is worth to investigate tree-based non-linear models for structured learning problems.", "startOffset": 34, "endOffset": 68}, {"referenceID": 36, "context": ", 2011) and information retrieval (Li et al., 2007; Wu et al., 2010), suggesting that it is worth to investigate tree-based non-linear models for structured learning problems.", "startOffset": 34, "endOffset": 68}, {"referenceID": 12, "context": "To the best of our knowledge, TreeCRF (Dietterich et al., 2004) is the only work that explores tree-based methods for structured learning problems.", "startOffset": 38, "endOffset": 63}, {"referenceID": 10, "context": "Early research on entity linking has focused on well written documents (Bunescu and Pasca, 2006; Cucerzan, 2007; Milne and Witten, 2008).", "startOffset": 71, "endOffset": 136}, {"referenceID": 23, "context": "Due to the raise of social media, many techniques have been proposed or tailored to short texts including tweets, for the problem of entity linking (Ferragina and Scaiella, 2010; Meij et al., 2012; Guo et al., 2013) as well as the related problem of named entity recognition (NER) (Ritter et al.", "startOffset": 148, "endOffset": 215}, {"referenceID": 16, "context": "Due to the raise of social media, many techniques have been proposed or tailored to short texts including tweets, for the problem of entity linking (Ferragina and Scaiella, 2010; Meij et al., 2012; Guo et al., 2013) as well as the related problem of named entity recognition (NER) (Ritter et al.", "startOffset": 148, "endOffset": 215}, {"referenceID": 27, "context": ", 2013) as well as the related problem of named entity recognition (NER) (Ritter et al., 2011).", "startOffset": 73, "endOffset": 94}, {"referenceID": 18, "context": "The task of entity linking has attracted a lot of attention, and many shared tasks have been hosted to promote entity linking research (Ji et al., 2010; Ji and Grishman, 2011; Cano and others, 2014; Carmel et al., 2014).", "startOffset": 135, "endOffset": 219}, {"referenceID": 10, "context": "Earlier research on entity linking has been largely focused on the entity disambiguation problem, including most work on entity linking for wellwritten documents such as news and encyclopedia articles (Cucerzan, 2007) and also few for tweets (Liu et al.", "startOffset": 201, "endOffset": 217}, {"referenceID": 21, "context": "Earlier research on entity linking has been largely focused on the entity disambiguation problem, including most work on entity linking for wellwritten documents such as news and encyclopedia articles (Cucerzan, 2007) and also few for tweets (Liu et al., 2013).", "startOffset": 242, "endOffset": 260}, {"referenceID": 10, "context": "Earlier research on entity linking has been largely focused on the entity disambiguation problem, including most work on entity linking for wellwritten documents such as news and encyclopedia articles (Cucerzan, 2007) and also few for tweets (Liu et al., 2013). Recently, people have focused on building systems that consider mention detection and entity disambiguation jointly. For example, Cucerzan (2012) delays the mention detection decision and consider the mention detection and entity linking problem jointly.", "startOffset": 202, "endOffset": 408}, {"referenceID": 10, "context": "Earlier research on entity linking has been largely focused on the entity disambiguation problem, including most work on entity linking for wellwritten documents such as news and encyclopedia articles (Cucerzan, 2007) and also few for tweets (Liu et al., 2013). Recently, people have focused on building systems that consider mention detection and entity disambiguation jointly. For example, Cucerzan (2012) delays the mention detection decision and consider the mention detection and entity linking problem jointly. Similarly, Sil and Yates (2013) proposed to use a reranking approach to obtain overall better results on mention detection and entity disambiguation.", "startOffset": 202, "endOffset": 549}], "year": 2016, "abstractText": "Non-linear models recently receive a lot of attention as people are starting to discover the power of statistical and embedding features. However, tree-based models are seldom studied in the context of structured learning despite their recent success on various classification and ranking tasks. In this paper, we propose S-MART, a tree-based structured learning framework based on multiple additive regression trees. S-MART is especially suitable for handling tasks with dense features, and can be used to learn many different structures under various loss functions. We apply S-MART to the task of tweet entity linking \u2014 a core component of tweet information extraction, which aims to identify and link name mentions to entities in a knowledge base. A novel inference algorithm is proposed to handle the special structure of the task. The experimental results show that S-MART significantly outperforms state-of-the-art tweet entity linking systems.", "creator": "LaTeX with hyperref package"}}}