{"id": "1609.08084", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Sep-2016", "title": "Toward Socially-Infused Information Extraction: Embedding Authors, Mentions, and Entities", "abstract": "Entity linking is the task of identifying mentions of entities in text, and linking them to entries in a knowledge base. This task is especially difficult in microblogs, as there is little additional text to provide disambiguating context; rather, authors rely on an implicit common ground of shared knowledge with their readers. In this paper, we attempt to capture some of this implicit context by exploiting the social network structure in microblogs. We build on the theory of homophily, which implies that socially linked individuals share interests, and are therefore likely to mention the same sorts of entities. We implement this idea by encoding authors, mentions, and entities in a continuous vector space, which is constructed so that socially-connected authors have similar vector representations. These vectors are incorporated into a neural structured prediction model, which captures structural constraints that are inherent in the entity linking task. Together, these design decisions yield F1 improvements of 1%-5% on benchmark datasets, as compared to the previous state-of-the-art.", "histories": [["v1", "Mon, 26 Sep 2016 17:19:07 GMT  (10591kb,D)", "http://arxiv.org/abs/1609.08084v1", "Accepted to EMNLP 2016"]], "COMMENTS": "Accepted to EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yi yang", "ming-wei chang", "jacob eisenstein"], "accepted": true, "id": "1609.08084"}, "pdf": {"name": "1609.08084.pdf", "metadata": {"source": "CRF", "title": "Toward Socially-Infused Information Extraction: Embedding Authors, Mentions, and Entities", "authors": ["Yi Yang", "Ming-Wei Chang"], "emails": ["yiyang@gatech.edu", "minchang@microsoft.com", "jacobe@gatech.edu"], "sections": [{"heading": null, "text": "This task is particularly difficult in microblogs because there is little additional text that provides a clear context; rather, authors rely on an implicit common basis of knowledge with their readers. In this paper, we try to capture part of this implicit context by taking advantage of the social network structure in microblogs. We build on the theory of homophilia, which implies that socially connected individuals have common interests and are therefore likely to mention the same types of entities. We implement this idea by encoding authors, mentions, and entities in a continuous vector space constructed so that socially connected authors have similar vector representations. These vectors are embedded in a neural predictive model that captures structural constraints inherent in the linkage task. Together, these design decisions result in an improvement of 1% -5% on benchmark datasets compared to previous state-of-the-art."}, {"heading": "1 Introduction", "text": "Linking to short texts (e.g. Twitter messages) is of increasing interest, as it is an essential step for many downstream applications, such as market research (Asur and Huberman, 2010), topic recognition and tracking (Mathioudakis and Koudas, 2010), and answering questions (Yih et al., 2015). Linking topics is a particularly difficult problem, as the short context around a company is often insufficient for the presentation of entities. For example, as shown in Figure 1, the entity \"Giants\" in Tweet t1 can refer to the New York Giants football team or the MLB baseball team San Francisco Giants. In this example, it is impossible to distinguish between these entities solely on the basis of individual text messages.We beat the difficulty and improve the entity."}, {"heading": "2 Data", "text": "NEEL was originally collected and commented on for the Named Entity Extraction & Linking Challenge (Cano et al., 2014), and TACL was first used and published by Fang and Chang (2014), and then cleaned and standardized by Yang and Chang (2015). Data set statistics are presented in Table 1."}, {"heading": "3 Testing Entity Homophily", "text": "The hypothesis of the homophilic entity as presented in the introduction is that socially connected individuals mention similar entities rather than separate individuals. We are now testing the hypothesis on real data before starting to form our entity that links systems.Twitter social networks We are testing the assumption about the users in the NEEL train datasets. We are constructing three of the author's social networks based on the follower, mention, and retweet relationships between the 1317 authors in the NEEL train datasets, which we roughly refer to as FOLLOWER, MENTION, and RETWEET. Specifically, we are using the Twitter API to explore the friends of NEEL users (people they follow) and the mention / retweet links are induced from their most recent 3,200 tweets. We are using bi-directional links to create the undirected networks as bi-directional links, which have stronger social networks links as a consequence of Ku directed links in 2011;"}, {"heading": "4 Method", "text": "In this section, we present, NTEL, a novel neural-based Tweet Entity Linking Framework that is capable of.2We assume that each name corresponds to a single entity for that metric, so this metric approaches only one entity homophily.leverage social information. We first formally define the task of the Tweet Entity Linking. Suppose we get an entity database (e.g. Wikipedia or Freebase), and a lexicon that translates an interface shape into a series of entity candidates. For each input tweet, we consider all n-grams of the tweet that correspond to the lexicon as mentioning.3 The entity-linking system entity maps each mention candidate (e.g. \"Red Sox\") in the message to an entity (e.g. Boston Red Sox) or to Nile (i.e., no entity-linking-entity-entity-entity-linking.There are two requirements)."}, {"heading": "4.1 Modeling Surface Features", "text": "We include the 37 characteristics used by Yang and Chang (2015) as surface characteristics. These characteristics are extracted from various sources, including a named entity detector, entity type detection, and some statistics from Wikipedia pages. We use a multi-layer perceptron (MLP) to transform the surface characteristics into a real value. MLP output is formalized as follows: g1 (x, yt, t; 0) = \u03b2 > h + bh = tanh (W\u03c6 (x, yt, t) + b), (3) where \u03c6 (x, yt, t) is the feature function, W is an M \u00d7 D matrix, the weights b are bias terms, and h is the output of the hidden layer of the MLP. \u03b2 is an M-dimensional vector of the weights for the output score, and b is the bias term.} The parameters based on this, the 2015 MLW = LP, are not sufficient (the key to the MLP)."}, {"heading": "4.2 Modeling User, Mention, and Entity", "text": "In order to use the structure of the social network, we must first work out the deep-dimensional embeddings for the authors who use the social relationships. Mentions and entity presentations are made by the word embeddings and entity presentations of individual user types (u), E (e), E (e), E (e), E (e), E (e), E (e), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (e), E (e, E, E, E (e, E, E, E (n), E (e, E, E, E (e, E, E, E, E, E, E (e, E, E, E, E, E, E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (n), E (, E (n), E (, E (n), E (, E (n), E (n), E (, E (n), E (, E (, E (, E (, E (, E (,"}, {"heading": "4.3 Non-overlapping Inference", "text": "The non-overlapping constraint for entity assignments requires a follow-up method different from the standard Viterbi algorithm for a linear chain. We now present a variant of the Viterbi algorithm for the non-overlapping structure. Considering the overall evaluation function g (x, yt, u, t) for the t-th candidate selecting an entity, we sort the mentioned candidates by their entity indices and define the Viterbi recursion using: t = arg max yt, yxt, yt 6 = Nil g (x, yt, u, t) (6) a (1) = max (g, Nil, u, 1)) (7) a (t) = max (t) = candidate (Nile), yt (t, u, t), whether the mention of the candidate (8) = g (x, Nile, u, t) + a (t) (v), v (v) () (v)."}, {"heading": "4.4 Loss-augmented Training", "text": "The parameters to be learned during the training are \u0432 = [\u04451, {W (u, e), W (m, e)].5 We train NTEL by minimizing the following loss function for each training text: L (\u044b) = max y-Yx (\u0445 (y, y) + s (x, y, u) \u2212 s (x, y, u), (11) where y-Yx is the gold structure, Yx is the amount of valid production structures for x, and \u0445 (y, y) is the weighted hammer distance between the gold structure y and the valid structure y. The hammer loss is decomposable to the mentioned candidates, which allows efficient inferences. We set the hammer loss weight to 0.2 after a preliminary search. Note that the number of parameters in our composition model is large. Therefore, we include an L2 regulator on these parameters, which is omitted from Equation 11 for short-lived."}, {"heading": "5 Experiments", "text": "In this section, we evaluate NTEL using the NEEL and TACL datasets as described in paragraph 2, focusing on whether social information can improve the task, and comparing NTEL with the state-of-the-art system to date."}, {"heading": "5.1 Social network expansion", "text": "We were able to identify 2,312 authors for the tweets of the two sets of data in March 2016. Then, we used the Twitter API to search their friend links and timelines from which we can trigger the networks. We found that we fixed the pre-trained embed matrices during loss-absorbed training.The number of social connections (bi-directional links) between these users is relatively low. To learn better embedding of users, we are expanding the author nodes group to include nodes that contribute most to the densification of the author networks. For the follower network, we are adding more people who follow at least twenty authors in the original group. For the mention or retweet networks, we are adding all users who mentioned or retweeted at least ten authors in the original group. Statistics of the resulting networks are shown in Table 3."}, {"heading": "5.2 Experimental Settings", "text": "Following Yang and Chang (2015), we train all models with the NEEL pull dataset and evaluate different systems on the NEEL test and TACL datasets. In addition, 800 tweets from the NEEL pull dataset are scanned as our development set to perform parameter tuning. Note that Yang and Chang (2015) also try to optimize F1 values by balancing the precision and retrieval values on the development set; we do not refine our F1 system in this way so that we can apply a single trained system across different test sets. Metrics We follow previous work (Guo et al., 2013a; Yang and Chang, 2015) and perform the default evaluation for an end-to-end entity link system, computational accuracy, recall and F1 score according to the entity's references and system outputs. An output entity is considered correct if it matches the Gold and Entity boundaries."}, {"heading": "5.3 Results", "text": "In fact, the fact is that most of them will be able to demonstrate that they are able to achieve their goals and that they are able to achieve their goals."}, {"heading": "5.4 Error Analysis & Discussion", "text": "The results show that the composition of the mention organs improves the system's ability to tackle mention organs that are abbreviations such as \"WSJ\" (The Wall Street Journal) and \"SJSU\" (San Jose State University), resulting in higher recall values. The mention organism model also helps eliminate errors that non-entities erroneously associate with popular entities. For example, in the tweet \"I'm a be in Miami for sec to hit da radio!,\" the NTEL base system connects \"sec\" with the Southeast Conference, which is corrected by the mention organ composition model. The word semantic information encoded in the mention representations alleviates the distorted entity information given by the surface properties."}, {"heading": "6 Related Work", "text": "Previous work on entity linkage has focused mainly on well-written documentaries (Bunescu and Pasca, 2006; Cucerzan, 2007; Milne and Witten, 2008), in which entity checks are usually performed by maximizing the current global coherence between entities. However, due to the short and loud nature of the tweets, these approaches often lead to unsatisfactory performance in Twitter messages. To address this issue, collective tweet linkage methods have been proposed that effectively utilize extended context and metadata (Huang et al., 2014). Guo et al. (2013b) are looking for textually similar tweets for a target tweet and encourage these Twitter messages to include similar entities through label propagation. Shen et al. (2013) we use Twitter user account information to improve linking of entities, based on the intuition that all tweets are shared by the same user."}, {"heading": "7 Conclusion", "text": "We present a neural structured learning architecture for linking Tweet entities that exploits the tendency of socially connected individuals to share similar interests in named entities - the phenomenon of the homophilic entity. By modelling the composition of vector representations of author, entity and mention, our approach is able to use the social network as a source of contextual information. This vector compositional model is combined with nonlinear combinations of surface features, via a pioneering neural network. To avoid predictions of overlapping entity mentions, we use a structured prediction algorithm and train the system with loss-based decoding. Besides microblogs, social networks also emerge in other environments, such as websites and scientific research articles; the use of these networks is a possible direction for future work. We would also like to examine other metadata relevant to the task, such as time and spatial."}, {"heading": "A Appendix: Additional Results", "text": "In the first version of (Yang and Chang, 2015), Twitter messages that do not contain Ground Truth Entities are excluded from the experiments. For the sake of completeness, we now present the evaluation results of NTEL in this environment, which is set out in Table 6. The RETWEET + network is used to train author embedding. The best hyperparameters are the same as those described in Section 5, with the exception of the L2 regulatory penalty for the composition parameters, which is set here at 0.01. Results are generally better than those in Table 4. As shown, NTEL benefits from the distributed presentation of authors, mentions and entities that improve the average F1 value by 2.3 points. NTEL also delivers the best results in the datasets and outperforms S-MART on average by about 2% F1."}], "references": [{"title": "Latent dirichlet allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan."], "venue": "the Journal of machine Learning research, 3:993\u20131022.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Using encyclopedic knowledge for named entity disambiguation", "author": ["R. C Bunescu", "M. Pasca."], "venue": "Proceedings of the European Chapter of the Association for Computational Linguistics (EACL).", "citeRegEx": "Bunescu and Pasca.,? 2006", "shortCiteRegEx": "Bunescu and Pasca.", "year": 2006}, {"title": "Making sense of microposts (# microposts2014) named entity extraction & linking challenge", "author": ["Amparo E Cano", "Giuseppe Rizzo", "Andrea Varga", "Matthew Rowe", "Milan Stankovic", "Aba-Sah Dadzie."], "venue": "Making Sense of Microposts (# Microposts2014).", "citeRegEx": "Cano et al\\.,? 2014", "shortCiteRegEx": "Cano et al\\.", "year": 2014}, {"title": "Erd\u201914: entity recognition and disambiguation challenge", "author": ["David Carmel", "Ming-Wei Chang", "Evgeniy Gabrilovich", "Bo-June Paul Hsu", "Kuansan Wang."], "venue": "ACM SIGIR Forum, pages 63\u201377.", "citeRegEx": "Carmel et al\\.,? 2014", "shortCiteRegEx": "Carmel et al\\.", "year": 2014}, {"title": "Large-scale named entity disambiguation based on wikipedia data", "author": ["Silviu Cucerzan."], "venue": "Proceedings of Empirical Methods for Natural Language Processing (EMNLP).", "citeRegEx": "Cucerzan.,? 2007", "shortCiteRegEx": "Cucerzan.", "year": 2007}, {"title": "Entity linking on microblogs with spatial and temporal signals", "author": ["Yuan Fang", "Ming-Wei Chang."], "venue": "Transactions of the Association for Computational Linguistics (ACL).", "citeRegEx": "Fang and Chang.,? 2014", "shortCiteRegEx": "Fang and Chang.", "year": 2014}, {"title": "To link or not to link? a study on end-toend tweet entity linking", "author": ["Stephen Guo", "Ming-Wei Chang", "Emre Kiciman."], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL), Atlanta, GA.", "citeRegEx": "Guo et al\\.,? 2013a", "shortCiteRegEx": "Guo et al\\.", "year": 2013}, {"title": "Microblog entity linking by leveraging extra posts", "author": ["Yuhang Guo", "Bing Qin", "Ting Liu", "Sheng Li."], "venue": "Proceedings of Empirical Methods for Natural Language Processing (EMNLP), Seattle, WA.", "citeRegEx": "Guo et al\\.,? 2013b", "shortCiteRegEx": "Guo et al\\.", "year": 2013}, {"title": "Demographic factors improve classification performance", "author": ["Dirk Hovy."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), pages 752\u2013762, Beijing, China.", "citeRegEx": "Hovy.,? 2015", "shortCiteRegEx": "Hovy.", "year": 2015}, {"title": "Exploiting social relations for sentiment analysis in microblogging", "author": ["Xia Hu", "Lei Tang", "Jiliang Tang", "Huan Liu."], "venue": "Proceedings of the sixth ACM international conference on Web search and data mining (WSDM), pages 537\u2013546.", "citeRegEx": "Hu et al\\.,? 2013", "shortCiteRegEx": "Hu et al\\.", "year": 2013}, {"title": "Collective tweet wikification based on semi-supervised graph regularization", "author": ["Hongzhao Huang", "Yunbo Cao", "Xiaojiang Huang", "Heng Ji", "Chin-Yew Lin."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), Baltimore, MD.", "citeRegEx": "Huang et al\\.,? 2014", "shortCiteRegEx": "Huang et al\\.", "year": 2014}, {"title": "What is Twitter, a social network or a news media? In Proceedings of the Conference on World-Wide Web (WWW), pages 591\u2013600, New York", "author": ["Haewoon Kwak", "Changhyun Lee", "Hosung Park", "Sue Moon."], "venue": "ACM.", "citeRegEx": "Kwak et al\\.,? 2010", "shortCiteRegEx": "Kwak et al\\.", "year": 2010}, {"title": "Learning multi-faceted representations of individuals from heterogeneous evidence using neural networks", "author": ["Jiwei Li", "Alan Ritter", "Dan Jurafsky."], "venue": "arXiv preprint arXiv:1510.05198.", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Two/too simple adaptations of word2vec for syntax problems", "author": ["Wang Ling", "Chris Dyer", "Alan Black", "Isabel Trancoso."], "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL), Denver, CO.", "citeRegEx": "Ling et al\\.,? 2015", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Twittermonitor: trend detection over the twitter stream", "author": ["Michael Mathioudakis", "Nick Koudas."], "venue": "Proceedings of the ACM SIGMOD International Conference on Management of data (SIGMOD), pages 1155\u20131158.", "citeRegEx": "Mathioudakis and Koudas.,? 2010", "shortCiteRegEx": "Mathioudakis and Koudas.", "year": 2010}, {"title": "Birds of a feather: Homophily in social networks", "author": ["Miller McPherson", "Lynn Smith-Lovin", "James M Cook."], "venue": "Annual review of sociology, pages 415\u2013444.", "citeRegEx": "McPherson et al\\.,? 2001", "shortCiteRegEx": "McPherson et al\\.", "year": 2001}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Neural Information Processing Systems (NIPS), pages 3111\u20133119, Lake Tahoe.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Learning to link with Wikipedia", "author": ["D. Milne", "I.H. Witten."], "venue": "Proceedings of the International Conference on Information and Knowledge Management (CIKM).", "citeRegEx": "Milne and Witten.,? 2008", "shortCiteRegEx": "Milne and Witten.", "year": 2008}, {"title": "Improved part-of-speech tagging for online conversational text with word clusters", "author": ["Olutobi Owoputi", "Brendan O\u2019Connor", "Chris Dyer", "Kevin Gimpel", "Nathan Schneider", "Noah A. Smith"], "venue": "In Proceedings of the North American Chapter of the Association", "citeRegEx": "Owoputi et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Owoputi et al\\.", "year": 2013}, {"title": "Social links from latent topics in microblogs", "author": ["Kriti Puniyani", "Jacob Eisenstein", "Shay Cohen", "Eric P. Xing."], "venue": "Proceedings of NAACL Workshop on Social Media, Los Angeles.", "citeRegEx": "Puniyani et al\\.,? 2010", "shortCiteRegEx": "Puniyani et al\\.", "year": 2010}, {"title": "Named entity recognition in tweets: an experimental study", "author": ["Alan Ritter", "Sam Clark", "Mausam", "Oren Etzioni."], "venue": "Proceedings of Empirical Methods for Natural Language Processing (EMNLP).", "citeRegEx": "Ritter et al\\.,? 2011", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Linking named entities in tweets with knowledge base via user interest modeling", "author": ["Wei Shen", "Jianyong Wang", "Ping Luo", "Min Wang."], "venue": "Proceedings of Knowledge Discovery and Data Mining (KDD).", "citeRegEx": "Shen et al\\.,? 2013", "shortCiteRegEx": "Shen et al\\.", "year": 2013}, {"title": "Reasoning With Neural Tensor Networks For Knowledge Base Completion", "author": ["Richard Socher", "Danqi Chen", "Christopher D. Manning", "Andrew Y. Ng."], "venue": "Neural Information Processing Systems (NIPS), Lake Tahoe.", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Twitter polarity classification", "author": ["Michael Speriosu", "Nikita Sudan", "Sid Upadhyay", "Jason Baldridge"], "venue": null, "citeRegEx": "Speriosu et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Speriosu et al\\.", "year": 2011}, {"title": "User-level sentiment analysis incorporating social networks", "author": ["Chenhao Tan", "Lillian Lee", "Jie Tang", "Long Jiang", "Ming Zhou", "Ping Li."], "venue": "Proceedings of Knowledge Discovery and Data Mining (KDD).", "citeRegEx": "Tan et al\\.,? 2011", "shortCiteRegEx": "Tan et al\\.", "year": 2011}, {"title": "Line: Large-scale information network embedding", "author": ["Jian Tang", "Meng Qu", "Mingzhe Wang", "Ming Zhang", "Jun Yan", "Qiaozhu Mei."], "venue": "Proceedings of the Conference on World-Wide Web (WWW).", "citeRegEx": "Tang et al\\.,? 2015", "shortCiteRegEx": "Tang et al\\.", "year": 2015}, {"title": "Who says what to whom on twitter", "author": ["Shaomei Wu", "Jake M Hofman", "Winter A Mason", "Duncan J Watts."], "venue": "Proceedings of the Conference on WorldWide Web (WWW), pages 705\u2013714.", "citeRegEx": "Wu et al\\.,? 2011", "shortCiteRegEx": "Wu et al\\.", "year": 2011}, {"title": "S-mart: Novel tree-based structured learning algorithms applied to tweet entity linking", "author": ["Yi Yang", "Ming-Wei Chang."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), Beijing, China.", "citeRegEx": "Yang and Chang.,? 2015", "shortCiteRegEx": "Yang and Chang.", "year": 2015}, {"title": "Putting things in context: Community-specific embedding projections for sentiment analysis", "author": ["Yi Yang", "Jacob Eisenstein."], "venue": "arXiv preprint arXiv:1511.06052.", "citeRegEx": "Yang and Eisenstein.,? 2015", "shortCiteRegEx": "Yang and Eisenstein.", "year": 2015}, {"title": "Embedding entities and relations for learning and inference in knowledge bases", "author": ["Bishan Yang", "Wen-tau Yih", "Xiaodong He", "Jianfeng Gao", "Li Deng."], "venue": "arXiv preprint arXiv:1412.6575.", "citeRegEx": "Yang et al\\.,? 2014", "shortCiteRegEx": "Yang et al\\.", "year": 2014}, {"title": "Semantic parsing via staged query graph generation: Question answering with knowledge base", "author": ["Wen-tau Yih", "Ming-Wei Chang", "Xiaodong He", "Jianfeng Gao."], "venue": "Proceedings of the Association for Computational Linguistics (ACL), Beijing, China.", "citeRegEx": "Yih et al\\.,? 2015", "shortCiteRegEx": "Yih et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 14, "context": ", Twitter messages) is of increasing interest, as it is an essential step for many downstream applications, such as market research (Asur and Huberman, 2010), topic detection and tracking (Mathioudakis and Koudas, 2010), and question answering (Yih et al.", "startOffset": 188, "endOffset": 219}, {"referenceID": 30, "context": ", Twitter messages) is of increasing interest, as it is an essential step for many downstream applications, such as market research (Asur and Huberman, 2010), topic detection and tracking (Mathioudakis and Koudas, 2010), and question answering (Yih et al., 2015).", "startOffset": 244, "endOffset": 262}, {"referenceID": 15, "context": "The sociological theory of homophily asserts that socially connected individuals are more likely to have similar behaviors or share similar interests (McPherson et al., 2001).", "startOffset": 150, "endOffset": 174}, {"referenceID": 24, "context": "This property has been used to improve many natural language processing tasks such as sentiment analysis (Tan et al., 2011; Yang and Eisenstein, 2015), topic classification (Hovy, 2015) and user attribute inference (Li et al.", "startOffset": 105, "endOffset": 150}, {"referenceID": 28, "context": "This property has been used to improve many natural language processing tasks such as sentiment analysis (Tan et al., 2011; Yang and Eisenstein, 2015), topic classification (Hovy, 2015) and user attribute inference (Li et al.", "startOffset": 105, "endOffset": 150}, {"referenceID": 8, "context": ", 2011; Yang and Eisenstein, 2015), topic classification (Hovy, 2015) and user attribute inference (Li et al.", "startOffset": 57, "endOffset": 69}, {"referenceID": 12, "context": ", 2011; Yang and Eisenstein, 2015), topic classification (Hovy, 2015) and user attribute inference (Li et al., 2015).", "startOffset": 99, "endOffset": 116}, {"referenceID": 25, "context": "To exploit social information, we adopt the recent advance on embedding information networks (Tang et al., 2015), which induces low-dimensional representations for author nodes based on the network structure.", "startOffset": 93, "endOffset": 112}, {"referenceID": 6, "context": "Previously proposed approaches (Guo et al., 2013a; Yang and Chang, 2015) are based on hand-crafted features and off-the-shelf machine learning algorithms.", "startOffset": 31, "endOffset": 72}, {"referenceID": 27, "context": "Previously proposed approaches (Guo et al., 2013a; Yang and Chang, 2015) are based on hand-crafted features and off-the-shelf machine learning algorithms.", "startOffset": 31, "endOffset": 72}, {"referenceID": 27, "context": "\u2022 The complete system, NTEL, outperforms the previous state-of-the-art (Yang and Chang, 2015) by 3% average F1 on two benchmark datasets.", "startOffset": 71, "endOffset": 93}, {"referenceID": 2, "context": "NEEL is originally collected and annotated for the Named Entity Extraction & Linking Challenge (Cano et al., 2014), and TACL is first used and released by Fang and Chang (2014).", "startOffset": 95, "endOffset": 114}, {"referenceID": 2, "context": "NEEL is originally collected and annotated for the Named Entity Extraction & Linking Challenge (Cano et al., 2014), and TACL is first used and released by Fang and Chang (2014). The datasets are then cleaned and unified by Yang and Chang (2015).", "startOffset": 96, "endOffset": 177}, {"referenceID": 2, "context": "NEEL is originally collected and annotated for the Named Entity Extraction & Linking Challenge (Cano et al., 2014), and TACL is first used and released by Fang and Chang (2014). The datasets are then cleaned and unified by Yang and Chang (2015). The statistics of the datasets are presented in Table 1.", "startOffset": 96, "endOffset": 245}, {"referenceID": 11, "context": "1 We exploit bi-directed links to create the undirected networks, as bi-directed links result in stronger social network ties than directed links (Kwak et al., 2010; Wu et al., 2011).", "startOffset": 146, "endOffset": 182}, {"referenceID": 26, "context": "1 We exploit bi-directed links to create the undirected networks, as bi-directed links result in stronger social network ties than directed links (Kwak et al., 2010; Wu et al., 2011).", "startOffset": 146, "endOffset": 182}, {"referenceID": 20, "context": "For a user ui, we employ a Twitter NER system (Ritter et al., 2011) to detect entity mentions in the timeline, which we use to construct a user entity vector u i , so that u (ent) i,j = 1 iff user i has mentioned entity j.", "startOffset": 46, "endOffset": 67}, {"referenceID": 27, "context": "We adopted the same entity database and lexicon as those used by Yang and Chang (2015).", "startOffset": 65, "endOffset": 87}, {"referenceID": 27, "context": "We include the 37 features used by Yang and Chang (2015) as our surface feature set.", "startOffset": 35, "endOffset": 57}, {"referenceID": 27, "context": "Yang and Chang (2015) argue that non-linearity is the key for obtaining good results on the task, as linear models are not expressive enough to capture the high-order relationships between the dense features.", "startOffset": 0, "endOffset": 22}, {"referenceID": 25, "context": "User embeddings We obtain low-dimensional Twitter author embeddings E(u) using LINE \u2014 the recently proposed model for embedding information networks (Tang et al., 2015).", "startOffset": 149, "endOffset": 168}, {"referenceID": 22, "context": "As each mention is typically one to three words, the simple representations often perform surprisingly well (Socher et al., 2013).", "startOffset": 108, "endOffset": 129}, {"referenceID": 13, "context": "We adopt the structured skip-gram model (Ling et al., 2015) to learn the word embeddings E(w) on a Twitter corpus with 52 million tweets (Owoputi et al.", "startOffset": 40, "endOffset": 59}, {"referenceID": 18, "context": ", 2015) to learn the word embeddings E(w) on a Twitter corpus with 52 million tweets (Owoputi et al., 2013).", "startOffset": 85, "endOffset": 107}, {"referenceID": 16, "context": "4 The embeddings are trained with the skip-gram model (Mikolov et al., 2013) on 100 billion words from various news articles.", "startOffset": 54, "endOffset": 76}, {"referenceID": 22, "context": "Similar bilinear formulation has been used in the literature of knowledge base completion and inference (Socher et al., 2013; Yang et al., 2014).", "startOffset": 104, "endOffset": 144}, {"referenceID": 29, "context": "Similar bilinear formulation has been used in the literature of knowledge base completion and inference (Socher et al., 2013; Yang et al., 2014).", "startOffset": 104, "endOffset": 144}, {"referenceID": 27, "context": "Following Yang and Chang (2015), we train all the models with the NEEL-train dataset and evaluate different systems on the NEEL-test and TACL datasets.", "startOffset": 10, "endOffset": 32}, {"referenceID": 27, "context": "Following Yang and Chang (2015), we train all the models with the NEEL-train dataset and evaluate different systems on the NEEL-test and TACL datasets. In addition, 800 tweets from the NEELtrain dataset are sampled as our development set to perform parameter tuning. Note that Yang and Chang (2015) also attempt to optimize F1 scores by balancing precision and recall scores on the development set; we do not fine tune our F1 in this way, so that we can apply a single trained system across different test sets.", "startOffset": 10, "endOffset": 299}, {"referenceID": 6, "context": "Metrics We follow prior work (Guo et al., 2013a; Yang and Chang, 2015) and perform the standard evaluation for an end-to-end entity linking system, computing precision, recall, and F1 score according to the entity references and the system outputs.", "startOffset": 29, "endOffset": 70}, {"referenceID": 27, "context": "Metrics We follow prior work (Guo et al., 2013a; Yang and Chang, 2015) and perform the standard evaluation for an end-to-end entity linking system, computing precision, recall, and F1 score according to the entity references and the system outputs.", "startOffset": 29, "endOffset": 70}, {"referenceID": 3, "context": "More details about the metrics are described by Carmel et al. (2014).", "startOffset": 48, "endOffset": 69}, {"referenceID": 27, "context": "Table 4 summarizes the empirical findings for our approach and S-MART (Yang and Chang, 2015) on the tweet entity linking task.", "startOffset": 70, "endOffset": 92}, {"referenceID": 27, "context": "With structured inference but without embeddings, NTEL performs roughly the same as S-MART, showing that a feedforward neural network offers similar expressivity to the regression trees employed by Yang and Chang (2015).", "startOffset": 198, "endOffset": 220}, {"referenceID": 0, "context": "(2010) show that the mention network has stronger linguistic properties than the follower network, as it gives better correlations on each author\u2019s distribution over latent topics as induced by latent Dirichlet allocation (Blei et al., 2003).", "startOffset": 222, "endOffset": 241}, {"referenceID": 18, "context": "Puniyani et al. (2010) show that the mention network has stronger linguistic properties than the follower network, as it gives better correlations on each author\u2019s distribution over latent topics as induced by latent Dirichlet allocation (Blei et al.", "startOffset": 0, "endOffset": 23}, {"referenceID": 1, "context": "Tweet entity linking Previous work on entity linking mainly focuses on well-written documents (Bunescu and Pasca, 2006; Cucerzan, 2007; Milne and Witten, 2008), where entity disambiguation is usually performed by maximizing the global topical coherence between entities.", "startOffset": 94, "endOffset": 159}, {"referenceID": 4, "context": "Tweet entity linking Previous work on entity linking mainly focuses on well-written documents (Bunescu and Pasca, 2006; Cucerzan, 2007; Milne and Witten, 2008), where entity disambiguation is usually performed by maximizing the global topical coherence between entities.", "startOffset": 94, "endOffset": 159}, {"referenceID": 17, "context": "Tweet entity linking Previous work on entity linking mainly focuses on well-written documents (Bunescu and Pasca, 2006; Cucerzan, 2007; Milne and Witten, 2008), where entity disambiguation is usually performed by maximizing the global topical coherence between entities.", "startOffset": 94, "endOffset": 159}, {"referenceID": 10, "context": "To tackle this problem, collective tweet entity linking methods that leverage enriched context and metadata information have been proposed (Huang et al., 2014).", "startOffset": 139, "endOffset": 159}, {"referenceID": 1, "context": "Tweet entity linking Previous work on entity linking mainly focuses on well-written documents (Bunescu and Pasca, 2006; Cucerzan, 2007; Milne and Witten, 2008), where entity disambiguation is usually performed by maximizing the global topical coherence between entities. However, these approaches often yield unsatisfactory performance on Twitter messages, due to the short and noisy nature of the tweets. To tackle this problem, collective tweet entity linking methods that leverage enriched context and metadata information have been proposed (Huang et al., 2014). Guo et al. (2013b) search for textually similar tweets for a target tweet, and encourage these Twitter messages to contain similar entities through label propagation.", "startOffset": 95, "endOffset": 586}, {"referenceID": 1, "context": "Tweet entity linking Previous work on entity linking mainly focuses on well-written documents (Bunescu and Pasca, 2006; Cucerzan, 2007; Milne and Witten, 2008), where entity disambiguation is usually performed by maximizing the global topical coherence between entities. However, these approaches often yield unsatisfactory performance on Twitter messages, due to the short and noisy nature of the tweets. To tackle this problem, collective tweet entity linking methods that leverage enriched context and metadata information have been proposed (Huang et al., 2014). Guo et al. (2013b) search for textually similar tweets for a target tweet, and encourage these Twitter messages to contain similar entities through label propagation. Shen et al. (2013) employ Twitter user account information to improve entity linking, based on the intuition that all tweets posted by the same user share an underlying topic distribution.", "startOffset": 95, "endOffset": 753}, {"referenceID": 1, "context": "Tweet entity linking Previous work on entity linking mainly focuses on well-written documents (Bunescu and Pasca, 2006; Cucerzan, 2007; Milne and Witten, 2008), where entity disambiguation is usually performed by maximizing the global topical coherence between entities. However, these approaches often yield unsatisfactory performance on Twitter messages, due to the short and noisy nature of the tweets. To tackle this problem, collective tweet entity linking methods that leverage enriched context and metadata information have been proposed (Huang et al., 2014). Guo et al. (2013b) search for textually similar tweets for a target tweet, and encourage these Twitter messages to contain similar entities through label propagation. Shen et al. (2013) employ Twitter user account information to improve entity linking, based on the intuition that all tweets posted by the same user share an underlying topic distribution. Fang and Chang (2014) demonstrate that spatial and temporal signals are critical for the task, and they advance the performance by associating entity prior distributions with different timestamps and locations.", "startOffset": 95, "endOffset": 945}, {"referenceID": 23, "context": "Speriosu et al. (2011) construct a heterogeneous network with", "startOffset": 0, "endOffset": 23}, {"referenceID": 23, "context": "Tan et al. (2011) and Hu et al.", "startOffset": 0, "endOffset": 18}, {"referenceID": 9, "context": "(2011) and Hu et al. (2013) leverage social relations for sentiment analysis by exploiting a factor graph model and the graph Laplacian technique respectively, so that the tweets belonging to social connected users share similar label distributions.", "startOffset": 11, "endOffset": 28}], "year": 2016, "abstractText": "Entity linking is the task of identifying mentions of entities in text, and linking them to entries in a knowledge base. This task is especially difficult in microblogs, as there is little additional text to provide disambiguating context; rather, authors rely on an implicit common ground of shared knowledge with their readers. In this paper, we attempt to capture some of this implicit context by exploiting the social network structure in microblogs. We build on the theory of homophily, which implies that socially linked individuals share interests, and are therefore likely to mention the same sorts of entities. We implement this idea by encoding authors, mentions, and entities in a continuous vector space, which is constructed so that socially-connected authors have similar vector representations. These vectors are incorporated into a neural structured prediction model, which captures structural constraints that are inherent in the entity linking task. Together, these design decisions yield F1 improvements of 1%-5% on benchmark datasets, as compared to the previous state-of-the-art.", "creator": "TeX"}}}