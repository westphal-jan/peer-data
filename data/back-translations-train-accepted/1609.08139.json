{"id": "1609.08139", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "26-Sep-2016", "title": "An Unsupervised Probability Model for Speech-to-Translation Alignment of Low-Resource Languages", "abstract": "For many low-resource languages, spoken language resources are more likely to be annotated with translations than with transcriptions. Translated speech data is potentially valuable for documenting endangered languages or for training speech translation systems. A first step towards making use of such data would be to automatically align spoken words with their translations. We present a model that combines Dyer et al.'s reparameterization of IBM Model 2 (fast-align) and k-means clustering using Dynamic Time Warping as a distance metric. The two components are trained jointly using expectation-maximization. In an extremely low-resource scenario, our model performs significantly better than both a neural model and a strong baseline.", "histories": [["v1", "Mon, 26 Sep 2016 19:50:59 GMT  (1353kb,D)", "http://arxiv.org/abs/1609.08139v1", "accepted at EMNLP 2016"]], "COMMENTS": "accepted at EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["antonios anastasopoulos", "david chiang", "long duong"], "accepted": true, "id": "1609.08139"}, "pdf": {"name": "1609.08139.pdf", "metadata": {"source": "CRF", "title": "An Unsupervised Probability Model for Speech-to-Translation Alignment of Low-Resource Languages", "authors": ["Antonios Anastasopoulos", "David Chiang"], "emails": ["aanastas@nd.edu", "dchiang@nd.edu", "lduong@student.unimelb.edu.au"], "sections": [{"heading": "1 Introduction", "text": "And because language transcription is a costly and slow process, language is more likely to be commented on with translations than with transcriptions. To make a collection of language data usable for future language studies, something like glossy interlinear text (transcription, morphological analysis, word glosses, free translation) is at least required. New technologies are being developed to facilitate the collection of translations (Bird et al., 2014), and there are already current examples of parallel survey efforts focusing on vulnerable languages (Blachon et al., 2016; Adda et al., 2016)."}, {"heading": "2 Background", "text": "In this section, we will briefly describe the existing models on which the two components of our model are based. In the next section, we will describe how to adapt and combine them to the current task. \u2212 2.1 IBM Model 2 and fast _ alignment The IBM translation models (Brown et al., 1993) aim to model the distribution p (e | f) for an English sentence e = e1 \u00b7 \u00b7 \u00b7 el, giving a French sentence f = f1 \u00b7 \u00b7 \u00b7 em. They all introduce a hidden variable a = a1 \u00b7 al, which gives the position of the French word to which each English word is aligned. The general form of IBM Models 1, 2 and fast _ alignn isp (e, a | f) = p (l) l (ei | fai) l (ai | i, m) g (ai, l, m), where t (e | f) is the probability of translating the French word f into the English word e, p (j = l, m)."}, {"heading": "2.2 DTW and DBA", "text": "Dynamic Time Distortion (DTW) (Berndt and Clifford, 1994) is a dynamic programming method for measuring the distance between two time sequences of different lengths and for calculating an orientation based on that distance. In the light of two sequences \u03c6, \u03c6 \u2032 of length m and m \u2032, respectively, DTWeine constructs m \u00b7 m \u00b2 matrix w, where the distorting path can be found by evaluating the following repetition: wi, j = d (\u03c6i, \u03c6 \u2032 j) + min {wi \u2212 1, j \u2212 1, wi, j \u2212 1}, where d is a distance metrix. In this paper, we normalize the cost of the distorting sequence: DTW (\u03c6, \u03c6 \u2032) = wm, m \u00b2 m + m \u00b2, which lies between zero and one. DTW Barycenter Averaging (DBA et al., 2011) is an iterative approximate method that attempts to find a centric sequence."}, {"heading": "3 Model", "text": "We use a generative model of a source language segment composed of attribute boxes. (...) We use a generative model of a source language segment composed of attribute boxes. (...) We use a generative model of a source language segment composed of words. (...) We have chosen a model in which it is easier to integrate DTW. (...) The other direction is also possible, and we plan to explore it in future work. (...) In addition to the source language set e, our model will include a sequence f = f1 \u00b7 fl of source language clusters (intuitive, source language, source language, Spanish and spans (...) the source signal that aligns each target word. (...) The clusters f = f1 \u00b7 fl and the spans a = a1,. (...) al and b = b1, (...) are the hidden variables of the model (...)."}, {"heading": "4 Training", "text": "We use the hard (Viterbi) version of the ExpectationMaximization (EM) algorithm to estimate the parameters of our model, because calculating the expected numbers in full would be prohibitively expensive and would require sums of all possible alignments. Remember that the hidden variables of the model include the alignments (ai, bi) and the source words (fi). The parameters are the translation probabilities t (ei) and the prototypes (\u03c6 f). The (hard) E step uses the current model and prototypes to find the best source segment for each target word, to align it with the best source word and align it with the best source word. The M step re-estimates the probabilities (e) and the prototypes f. We describe each of these steps in detail. Initialization is particularly important because we use the parameters that we initialize the hidden variables and then perform a step."}, {"heading": "5 Related Work", "text": "A first step to modeling parallel language can be done by modelling phone-to-word alignment, rather than working directly on continuous language. Thus, Stahlberg et al. (2012) extend IBM Model 3 to aligning telephones with words to build linguistic pronunciation axicons. Pialign (Neubig et al., 2012) aligns signs and can just as well be applied to telephones. Duong et al. (2016) use an extension of the neural attention model by Bahdanau et al. (2015) to align telephones with words and language with words; we discuss this model in Section 6.2 below. There are several monitored approaches that attempt to integrate speech recognition and machine translation, but they rely heavily on the wealth of training data, pronunciation axicons, or speech models, and therefore cannot be applied in a low or zero-resource setting."}, {"heading": "6 Experiments", "text": "We evaluate our method using two language pairs, Spanish-English and Griko-Italian, using two basic methods, a naive baseline and the model of Duong et al. (2016)."}, {"heading": "6.1 Data", "text": "For each language pair, we need a sentence-oriented parallel corpus of source and target-language text. A subset of these sentences should be span-to-word adapted for use as the gold standard."}, {"heading": "6.1.1 Spanish-English", "text": "For Spanish-English, we use the Spanish CALLHOME corpus (LDC96S35) and the Fisher corpus (LDC2010T04), which consists of telephone calls between native Spanish speakers based in the United States and their relatives abroad, along with English translations by Post et al. (2013). Spanish is obviously not a low-resource language, but we pretend it is low-resource by not using Spanish ASR or resources such as transcribed speech or pronunciation icons. As there are no gold standard matches between Spanish speech and English words, we use the \"silver\" standard matches from Duong et al. (2016) for the CALLHOME corpus and followed the same procedure for the Fisher corpus. To obtain them, we first used a forced aligner to align the speech with their transcription, and GIZA + with the English symmetry based on the SAL333 of the Spanish translation."}, {"heading": "6.1.2 Griko-Italian", "text": "We also execute our model on a corpus consisting of approximately 20 minutes of speech in Griko, an endangered minority dialect of Greek spoken in southern Italy, together with text translations into Italian (Lekakou et al., 2013).2 The corpus consists of 330 utterances, mostly initiated by nine native speakers. Although the corpus is very small, we use it to demonstrate the effectiveness of our method in a harsh environment with extremely limited resources.All utterances were commented and transcribed manually by a trained linguist and bilingual speaker of both languages, who created the Griko transcriptions and Italian glossaries. We created complete translations into Italian and manually aligned the translations to the Griko transcriptions. We then created com-2http: / / griko.project.uoi.gr / combining the two orientations (speech-transcription and transcription-translation to-match)."}, {"heading": "6.1.3 Preprocessing", "text": "In both data settings, we treat the voice data as a sequence of 39-dimensional Perceptual Linear Prediction (PLP) vectors encoding the power spectrum of the voice signal (Hermansky, 1990), calculated in 10ms intervals. We also normalize the features at the expression level, moving and scaling them to zero mean and unit variance."}, {"heading": "6.2 Baselines", "text": "Our naive baseline assumes that there is no reordering between source and target language, and aligns each target word ei to a span of source whose length in frames is proportional to the length of ei in characters. Indeed, this works very well for language pairs that have minimal or no reordering, and language pairs that have common or related vocabulary. The other baseline we compare with is the Neural Network Attention Model by Duong et al. (2016), which expands the care model of Bahdanau et al. (2015) to be used for language alignment and translation, and, together with several modifications, achieves good results in the task of phone-to-word alignment, achieving almost the output in the task of word-to-word alignment."}, {"heading": "7 Results", "text": "To evaluate an automatic alignment between the language and its translation to the Gold-Silver standard alignment, we calculate the accuracy of alignment, retrieval and F score as usual, but based on connections between source-language frames and target-language words."}, {"heading": "7.1 Overview", "text": "Table 1 shows the accuracy, recall and balanced fscore of the three models of the Spanish-English CALLHOME corpus (both the 2000 sentence subset and the full sentence), the Spanish-English Fisher corpus and the Griko-Italian corpus. In all cases, our model outperforms both the naive base and the neural attention model. Our model significantly improves in precision compared to the baseline, while slightly undercutting the na\u00efve baseline on retrieval. In certain applications, greater precision may be desirable: in language documentation, for example, it is probably better to err on the side of precision; in phrase-based translation, more precise alignments lead to more extracted phrases. The rest of the section provides further analysis of the results, focusing on the extremely resource-poor Griko-Italian dataset."}, {"heading": "7.2 Speaker robustness", "text": "Figure 2 shows the alignments generated by our model for three expressions of the same sentence from the Griko-Italian dataset of three different speakers. The performance of our model is roughly consistent in relation to these expressions. In general, the model does not appear to be significantly affected by speaker-specific deviations, as shown in Table 2. However, we find that the performance of male speakers is slightly higher than that of female speakers. This could be because the expressions of female speakers are on average about 2 words longer than that of male speakers."}, {"heading": "7.3 Word level analysis", "text": "As shown in Figure 3, the longer the utterance of the word, the easier it is for our model to calculate F scores for each type of Italian word. Longer utterances seem to contain enough information to make our DTW-based measurement work properly. On the other hand, shorter utterances are more difficult to align; the vast majority of Griko utterances, which have less than 20 frames and are less accurately aligned, correspond to monosyllabic determinants (o, i, a, to, ta) or conjunctions and prepositions (ka, ce, en, na, an). With such short utterances, several parts of the signal may possibly match the prototype, causing the cluster component to prefer to align with false spans.In addition, we note that rare word types tend to be correctly aligned. The average F score for hapax legomena (on the Italian side) is 3.62, with 753% of them aligned with a higher F-0.ore."}, {"heading": "7.4 Comparison with proper model", "text": "As mentioned in section 3, our model is insufficient, but it performs much better than the model, which boils down to one (henceforth the \"right\" model): In the Spanish-English dataset (example 2000), the correct model achieves an F score of 32.1, performing worse than the na\u00efve baseline; in the Grico-Italian dataset, it achieves an F score of 44.3, which is better than the fundamentals, but even worse than our model. To further investigate why this happens, we performed three EM iterations on the Grico-Italian dataset with our model (in our experience, three iterations are usually sufficient for convergence), and then calculated another E step with our model to ensure that the two models align the datasets using the same prototypes and that their results are comparable."}, {"heading": "8 Conclusion", "text": "Adapting the language to text translation is a relatively new task, with particular relevance for languages with limited resources or at-risk languages. The model proposed here, which combines rapid _ alignment and k-mean clustering using DTW and DBA, outperforms both a very strong na\u00efve base model and a neural attention model for three tasks of varying magnitude. The language pairs we are working on do not have much word reordering, and more divergent language pairs should prove more difficult. In this case, the na\u00efve baseline should be much less competitive. Similarly, the fast _ alignment-based distortion model could become less applicable; we could turn the hyperparameter \u03bb downwards, bringing it closer to IBM Model 1, but we plan to integrate IBM Model 3 or the HMM alignment Model (Vogel et al., 1996). Finally, we will examine downstream applications of our alignment methods as well as language documentation in areas."}], "references": [{"title": "Breaking the unwritten language barrier: The BULB", "author": ["Adda et al.2016] Gilles Adda", "Sebastian St\u00fcker", "Martine Adda-Decker", "Odette Ambouroue", "Laurent Besacier", "David Blachon", "H\u00e9l\u00e8ne Bonneau-Maynard", "Pierre Godard", "Fatima Hamlaoui", "Dmitry Idiatov"], "venue": null, "citeRegEx": "Adda et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Adda et al\\.", "year": 2016}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Kyunghyun Cho", "Yoshua Bengio"], "venue": "In Proceedings of ICLR", "citeRegEx": "Bahdanau et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Speech translation without speech recognition. Master\u2019s thesis, University of Edinburgh", "author": ["Sameer Bansal"], "venue": null, "citeRegEx": "Bansal.,? \\Q2015\\E", "shortCiteRegEx": "Bansal.", "year": 2015}, {"title": "Using dynamic time warping to find patterns in time series", "author": ["Berndt", "Clifford1994] Donald J. Berndt", "James Clifford"], "venue": "In Proc. KDD,", "citeRegEx": "Berndt et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Berndt et al\\.", "year": 1994}, {"title": "Collecting bilingual audio in remote indigenous communities", "author": ["Bird et al.2014] Steven Bird", "Lauren Gawne", "Katie Gelbart", "Isaac McAlister"], "venue": "In Proc. COLING,", "citeRegEx": "Bird et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bird et al\\.", "year": 2014}, {"title": "Parallel speech collection for under-resourced language studies using the Lig-Aikuma mobile device app", "author": ["Elodie Gauthier", "Laurent Besacier", "Guy-No\u00ebl Kouarata", "Martine AddaDecker", "Annie Rialland"], "venue": null, "citeRegEx": "Blachon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Blachon et al\\.", "year": 2016}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Brown et al.1993] Peter F. Brown", "Vincent J. Della Pietra", "Stephen A. Della Pietra", "Robert L. Mercer"], "venue": null, "citeRegEx": "Brown et al\\.,? \\Q1993\\E", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "An attentional model for speech translation without transcription", "author": ["Duong et al.2016] Long Duong", "Antonios Anastasopoulos", "David Chiang", "Steven Bird", "Trevor Cohn"], "venue": "In Proceedings of the 2016 Conference of the North American Chapter of the Associa-", "citeRegEx": "Duong et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Duong et al\\.", "year": 2016}, {"title": "A simple, fast, and effective reparameterization of IBM Model 2", "author": ["Dyer et al.2013] Chris Dyer", "Victor Chahuneau", "Noah A Smith"], "venue": "In Proc. NAACL HLT", "citeRegEx": "Dyer et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Dyer et al\\.", "year": 2013}, {"title": "Perceptual linear predictive (PLP) analysis of speech", "author": ["Hynek Hermansky"], "venue": "J. Acoustical Society of America,", "citeRegEx": "Hermansky.,? \\Q1990\\E", "shortCiteRegEx": "Hermansky.", "year": 1990}, {"title": "Towards spoken term discovery at scale with zero resources", "author": ["Jansen et al.2010] Aren Jansen", "Kenneth Church", "Hynek Hermansky"], "venue": "In Proc INTERSPEECH,", "citeRegEx": "Jansen et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Jansen et al\\.", "year": 2010}, {"title": "Unsupervised word segmentation and lexicon discovery using acoustic word embeddings", "author": ["Kamper et al.2016] Herman Kamper", "Aren Jansen", "Sharon Goldwater"], "venue": "IEEE Trans. Audio,", "citeRegEx": "Kamper et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kamper et al\\.", "year": 2016}, {"title": "Phonetic segmentation of speech signal using local singularity analysis", "author": ["Khalid Daoudi", "Oriol Pont", "Hussein Yahia"], "venue": "Digital Signal Processing", "citeRegEx": "Khanagha et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Khanagha et al\\.", "year": 2014}, {"title": "Documentation and analysis of an endangered language: aspects of the grammar of Griko", "author": ["Valeria Baldiserra", "Antonis Anastasopoulos"], "venue": null, "citeRegEx": "Lekakou et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Lekakou et al\\.", "year": 2013}, {"title": "Audio keyword extraction by unsupervised word discovery", "author": ["Guillaume Gravier", "Fr\u00e9d\u00e9ric Bimbot"], "venue": "In Proc. INTERSPEECH", "citeRegEx": "Muscariello et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Muscariello et al\\.", "year": 2009}, {"title": "Machine translation without words through substring alignment", "author": ["Neubig et al.2012] Graham Neubig", "Taro Watanabe", "Shinsuke Mori", "Tatsuya Kawahara"], "venue": "In Proc. ACL,", "citeRegEx": "Neubig et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Neubig et al\\.", "year": 2012}, {"title": "Unsupervised pattern discovery in speech", "author": ["Park", "Glass2008] Alex S. Park", "James R. Glass"], "venue": "IEEE Trans. Audio, Speech, and Language Processing,", "citeRegEx": "Park et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Park et al\\.", "year": 2008}, {"title": "A global averaging method for dynamic time warping, with applications to clustering", "author": ["Alain Ketterlin", "Pierre Gan\u00e7arski"], "venue": "Pattern Recognition,", "citeRegEx": "Petitjean et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Petitjean et al\\.", "year": 2011}, {"title": "Improved speech-to-text translation with the Fisher and Callhome Spanish\u2013 English speech translation corpus", "author": ["Post et al.2013] Matt Post", "Gaurav Kumar", "Adam Lopez", "Damianos Karakos", "Chris Callison-Burch", "Sanjeev Khudanpur"], "venue": "In Proc. IWSLT", "citeRegEx": "Post et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Post et al\\.", "year": 2013}, {"title": "Learning string-edit distance", "author": ["Ristad", "Yianilos1998] Eric Sven Ristad", "Peter N Yianilos"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Ristad et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Ristad et al\\.", "year": 1998}, {"title": "A computational model for unsupervised word discovery", "author": ["Ten Bosch", "Cranen2007] Louis Ten Bosch", "Bert Cranen"], "venue": "In Proc. INTERSPEECH,", "citeRegEx": "Bosch et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bosch et al\\.", "year": 2007}, {"title": "HMM-based word alignment in statistical translation", "author": ["Vogel et al.1996] Stephan Vogel", "Hermann Ney", "Christoph Tillmann"], "venue": "In Proc. COLING,", "citeRegEx": "Vogel et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Vogel et al\\.", "year": 1996}, {"title": "Towards multi-speaker unsupervised speech pattern discovery", "author": ["Zhang", "Glass2010] Yaodong Zhang", "James R Glass"], "venue": "In Proc. ICASSP,", "citeRegEx": "Zhang et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 4, "context": "New technologies are being developed to facilitate collection of translations (Bird et al., 2014), and there already exist recent examples of parallel speech collection efforts focused on endangered languages (Blachon et al.", "startOffset": 78, "endOffset": 97}, {"referenceID": 5, "context": ", 2014), and there already exist recent examples of parallel speech collection efforts focused on endangered languages (Blachon et al., 2016; Adda et al., 2016).", "startOffset": 119, "endOffset": 160}, {"referenceID": 0, "context": ", 2014), and there already exist recent examples of parallel speech collection efforts focused on endangered languages (Blachon et al., 2016; Adda et al., 2016).", "startOffset": 119, "endOffset": 160}, {"referenceID": 8, "context": "\u2019s reparameterization of IBM Model 2 (Dyer et al., 2013), more commonly known as fast_align, and k-means clustering using Dynamic Time Warping (Berndt and Clifford, 1994) as a distance metric.", "startOffset": 37, "endOffset": 56}, {"referenceID": 13, "context": "The other is Griko-Italian; Griko is an endangered language for which we created (and make freely available)1 gold-standard translations and word alignments (Lekakou et al., 2013).", "startOffset": 157, "endOffset": 179}, {"referenceID": 7, "context": "In all cases, our model outperforms both a naive but strong baseline and a neural model (Duong et al., 2016).", "startOffset": 88, "endOffset": 108}, {"referenceID": 6, "context": "The IBM translation models (Brown et al., 1993) aim to model the distribution p(e | f) for an English sentence e = e1 \u00b7 \u00b7 \u00b7 el, given a French sentence f = f1 \u00b7 \u00b7 \u00b7 em.", "startOffset": 27, "endOffset": 47}, {"referenceID": 8, "context": "Dyer et al. (2013) propose a reparameterization of Model 2, known as fast_align:", "startOffset": 0, "endOffset": 19}, {"referenceID": 17, "context": "DTW Barycenter Averaging (DBA) (Petitjean et al., 2011) is an iterative approximate method that attempts to find a centroid of a set of sequences, minimizing the sum of squared DTW distances.", "startOffset": 31, "endOffset": 55}, {"referenceID": 12, "context": "In order to reduce the search space for a and b, we use the unsupervised phonetic boundary detection method of Khanagha et al. (2014). This method operates directly on the speech signal and provides us with candidate phone boundaries, on which we restrict the possible values for a and b, creating a list of candidate utterance spans.", "startOffset": 111, "endOffset": 134}, {"referenceID": 15, "context": "Pialign (Neubig et al., 2012) aligns characters and can be applied equally well to phones.", "startOffset": 8, "endOffset": 29}, {"referenceID": 6, "context": "Duong et al. (2016) use an extension of the neural attentional model of Bahdanau et al.", "startOffset": 0, "endOffset": 20}, {"referenceID": 1, "context": "(2016) use an extension of the neural attentional model of Bahdanau et al. (2015) for aligning phones to words and speech to words; we discuss this model below in Section 6.", "startOffset": 59, "endOffset": 82}, {"referenceID": 14, "context": "Various approaches (Ten Bosch and Cranen, 2007; Park and Glass, 2008; Muscariello et al., 2009; Zhang and Glass, 2010; Jansen et al., 2010) have been tried, in order to spot keywords, using segmental DTW to identify repeated trajectories in the speech signal.", "startOffset": 19, "endOffset": 139}, {"referenceID": 10, "context": "Various approaches (Ten Bosch and Cranen, 2007; Park and Glass, 2008; Muscariello et al., 2009; Zhang and Glass, 2010; Jansen et al., 2010) have been tried, in order to spot keywords, using segmental DTW to identify repeated trajectories in the speech signal.", "startOffset": 19, "endOffset": 139}, {"referenceID": 2, "context": "Bansal (2015) attempts to build a speech translation system in a low-resource setting, by using as source input the simulated output of an unsupervised term discovery system.", "startOffset": 0, "endOffset": 14}, {"referenceID": 7, "context": "We evaluate our method on two language pairs, Spanish-English and Griko-Italian, against two baseline methods, a naive baseline, and the model of Duong et al. (2016).", "startOffset": 146, "endOffset": 166}, {"referenceID": 17, "context": "For Spanish-English, we use the Spanish CALLHOME corpus (LDC96S35) and the Fisher corpus (LDC2010T04), which consist of telephone conversations between Spanish native speakers based in the US and their relatives abroad, together with English translations produced by Post et al. (2013). Spanish is obviously not a low-resource language, but we pretend that it is low-resource by not making use of any Spanish ASR or resources like transcribed speech or pronunciation lexicons.", "startOffset": 267, "endOffset": 286}, {"referenceID": 7, "context": "Since there do not exist gold standard alignments between the Spanish speech and English words, we use the \u201csilver\u201d standard alignments produced by Duong et al. (2016) for the CALLHOME corpus, and followed the same procedure for the Fisher corpus as well.", "startOffset": 148, "endOffset": 168}, {"referenceID": 13, "context": "We also run our model on a corpus that consists of about 20 minutes of speech in Griko, an endangered minority dialect of Greek spoken in south Italy, along with text translations into Italian (Lekakou et al., 2013).", "startOffset": 193, "endOffset": 215}, {"referenceID": 9, "context": "In both data settings, we treat the speech data as a sequence of 39-dimensional Perceptual Linear Prediction (PLP) vectors encoding the power spectrum of the speech signal (Hermansky, 1990), computed at 10ms intervals.", "startOffset": 172, "endOffset": 189}, {"referenceID": 6, "context": "The other baseline that we compare against is the neural network attentional model of Duong et al. (2016), which extends the attentional model of Bahdanau et al.", "startOffset": 86, "endOffset": 106}, {"referenceID": 1, "context": "(2016), which extends the attentional model of Bahdanau et al. (2015) to be used for aligning and translating speech, and, along with several modifications, achieve good results on the phone-to-word alignment task, and almost match the baseline performance on the speech-to-word alignment task.", "startOffset": 47, "endOffset": 70}, {"referenceID": 21, "context": "Similarly, the fast_align-based distortion model may become less appopriate; we could turn the hyperparameter \u03bb down, bringing it closer to IBM Model 1, but we plan to try incorporating IBM Model 3 or the HMM alignment model (Vogel et al., 1996) instead.", "startOffset": 225, "endOffset": 245}], "year": 2016, "abstractText": "For many low-resource languages, spoken language resources are more likely to be annotated with translations than with transcriptions. Translated speech data is potentially valuable for documenting endangered languages or for training speech translation systems. A first step towards making use of such data would be to automatically align spoken words with their translations. We present a model that combines Dyer et al.\u2019s reparameterization of IBM Model 2 (fast_align) and k-means clustering using Dynamic Time Warping as a distance metric. The two components are trained jointly using expectationmaximization. In an extremely low-resource scenario, our model performs significantly better than both a neural model and a strong baseline.", "creator": "LaTeX with hyperref package"}}}