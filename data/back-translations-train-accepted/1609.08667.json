{"id": "1609.08667", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Sep-2016", "title": "Deep Reinforcement Learning for Mention-Ranking Coreference Models", "abstract": "Coreference resolution systems are typically trained with heuristic loss functions that require careful tuning. In this paper we instead apply reinforcement learning to directly optimize a neural mention-ranking model for coreference evaluation metrics. We experiment with two approaches: the REINFORCE policy gradient algorithm and a reward-rescaled max-margin objective. We find the latter to be more effective, resulting in significant improvements over the current state-of-the-art on the English and Chinese portions of the CoNLL 2012 Shared Task.", "histories": [["v1", "Tue, 27 Sep 2016 21:00:26 GMT  (924kb,D)", "http://arxiv.org/abs/1609.08667v1", "To appear in EMNLP 2016"], ["v2", "Thu, 20 Oct 2016 21:58:34 GMT  (924kb,D)", "http://arxiv.org/abs/1609.08667v2", "To appear in EMNLP 2016"], ["v3", "Mon, 31 Oct 2016 20:30:15 GMT  (924kb,D)", "http://arxiv.org/abs/1609.08667v3", "To appear in EMNLP 2016"]], "COMMENTS": "To appear in EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kevin clark", "christopher d manning"], "accepted": true, "id": "1609.08667"}, "pdf": {"name": "1609.08667.pdf", "metadata": {"source": "CRF", "title": "Deep Reinforcement Learning for Mention-Ranking Coreference Models", "authors": ["Kevin Clark", "Christopher D. Manning"], "emails": ["kevclark@cs.stanford.edu", "manning@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "However, most measures of coreference resolution performance do not decompose through local decisions, meaning that the benefits of a particular decision are not known until all other decisions are made. Due to this difficulty, coreference systems are usually formed with loss functions that define the quality of a particular coreference decision. These losses contain hyperparameters that are carefully selected to ensure that the model functions well according to coreference evaluation metrics, making training more difficult, especially in other languages and datasets where systems work best with different hyperparameter settings. To explore this, we use two variants of amplification to directly optimize a coreference system for coreference evaluation. Specifically, we modify the max margin coreference target proposed by Wiseman et al."}, {"heading": "2 Neural Mention-Ranking Model", "text": "We use the neural mention ranking model described in Clark and Manning (2016), which we will briefly skip in this section. In the face of a mention m and a candidate predecessor c, the mention ranking model generates a score for the pairs s (c, m), indicating their compatibility for co-references with a feedforward neural network. The candidate precursor can be any mention that occurs before m in the document or NA, indicating that m has no precursors. Input layer. For each mention, the model extracts different words (e.g. the mention header) and word groups (e.g. all words in the mention sentence) that are fed into the neural network. Each word is represented by a vector wi-Rdw. Each word group is represented by the average of the vectors of each word in the group. In addition to the embedding, all words (e.g. all words in the mention header, all words in the mention groups) are included in the group."}, {"heading": "3 Learning Algorithms", "text": "These hyperparameters are usually given as costs for various types of errors that are used to make the co-reference system tend to create more or less co-reference links. In this section, we first describe a heuristic loss function that takes up this idea from Wiseman et al. (2015), and then propose new training methods based on reinforcement learning that are directly optimized for co-reference evaluation metrics instead."}, {"heading": "3.1 Heuristic Max-Margin Objective", "text": "The heuristic loss of Wiseman et al. is determined by the following error types, first proposed by Durrett et al. (2013). Suppose the training set consists of N mentions m1, m2,..., mN. Let C (mi) have the set of candidates antecedents of a mention mi (i.e., mentions before mi and NA) and T (mi) the set of true antecedents of mi (i.e., mentions before mi that correlate with it or {NA} if mi has no ancestor. Then we define the following costs for linking mi to a candidate antecedent c (mi):."}, {"heading": "3.2 Reinforcement Learning", "text": "Finding the best hyperparameter settings for heuristic loss requires training in many variants of the model, and at best results in a target that is correlated with the co-reference metrics. To address this, we present a precedence of measures that include a series of measures a1: T = a1, a2,..., aT, where T is the number of mentions in the current document, and suggest methods that directly optimize the model for co-reference metrics. Each action combines mentions in the mi document with a candidate. Formally, we designate the series of measures that are referred to for ith mentions as Ai = {c, mi): c, mi: c, mi: c, C (mi)}, where an action (c, m) correlates mentions c and m: The menu ranking model assigns each action."}, {"heading": "4 Experiments and Results", "text": "We conduct experiments with the English and Chinese parts of the CoNLL 2012 shared task data (Pradhan et al., 2012) and evaluate them using the metrics MUC, B3 and CEAF\u03c64. Our experiments were conducted using predicted mentions from the rule-based coreference system of Stanford (Raghunathan et al., 2010). We follow the training method of Clark and Manning (2016): hidden size layers M1 = 1000, M2 = M3 = 500, the RMSprop optimizer (Hinton and Tieleman, 2012), Dropout (Hinton et al., 2012) at a rate of 0.5, and pretraining with the classification tasks for all pairs and top pairs. However, we improve the previous system by using better detection, more effective hypoparameters and more training epochs."}, {"heading": "4.1 Results", "text": "We find that REINFORCE performs slightly better than heuristic loss, but the recalculation of rewards in both languages performs significantly better. We attribute the modest improvement in REINFORCE to the fact that it is poorly suited for a ranking task. During the training, it optimizes the performance of the model in anticipation, but at test time, it takes the most likely sequence of actions. This imbalance even occurs at the level of individual decision-making: the model associates the current mention with only a single precursor, but is trained to assign a high probability to all correct precursors. We believe that the advantage of REINFORCE is guided by co-reference rating metrics, offset by this disadvantage that does not occur in the maximum margin approaches."}, {"heading": "4.2 The Benefits of Reinforcement Learning", "text": "In this section, we examine the reward-based cost function and perform error analyses to increase the error rate. In English, the average is 0.79 for FN errors and 0.38 for FA errors if the costs are scaled so that the average value of a WL error is 1.0, which is very close to the hyperparameter values (FN, A, E) = (0.4, E).nbsp"}, {"heading": "5 Related Work", "text": "These models are typically trained with heuristic loss functions that assign costs to different error types, such as the heuristic loss described in Section 3.1 (Fernandes et al., 2012; Durrett et al., 2013; Bjo \ufffd rkelund and Kuhn, 2014; Wiseman et al., 2015; Martschat and Strube, 2015; Wiseman et al., 2016).To the best of our knowledge, learning to enhance correlation resolution has not yet been used. However, imitated learning algorithms such as SEARN (thumb \ufffd III et al., 2009) have been used to train correlation resolvers (thumb \ufffd III, 2006; Ma et al., 2014; Clark et al., 2015). These algorithms are also directly optimized for correlation evaluation metrics, but they require policies that rely solely on rewards."}, {"heading": "6 Conclusion", "text": "We propose to use reinforcement learning to optimize mention ranking models directly for co-reference evaluation metrics, eliminating the need for hyperparameters that need to be carefully selected for each language, data set, and rating metric. Our reward rescaling approach also increases the accuracy of the model, resulting in significant gains over current technology."}, {"heading": "Acknowledgments", "text": "We thank Kelvin Guu, William Hamilton, Will Monroe and the anonymous critics for their thoughtful comments and suggestions. This work was supported by the NSF Award IIS-1514268."}], "references": [{"title": "Algorithms for scoring coreference chains", "author": ["Bagga", "Baldwin1998] Amit Bagga", "Breck Baldwin"], "venue": "In The First International Conference on Language Resources and Evaluation Workshop on Linguistics Coreference,", "citeRegEx": "Bagga et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Bagga et al\\.", "year": 1998}, {"title": "Learning structured perceptrons for coreference resolution with latent antecedents and non-local features", "author": ["Bj\u00f6rkelund", "Kuhn2014] Anders Bj\u00f6rkelund", "Jonas Kuhn"], "venue": "In Association of Computational Linguistics (ACL)", "citeRegEx": "Bj\u00f6rkelund et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bj\u00f6rkelund et al\\.", "year": 2014}, {"title": "Entity-centric coreference resolution with model stacking", "author": ["Clark", "Manning2015] Kevin Clark", "Christopher D. Manning"], "venue": null, "citeRegEx": "Clark et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2015}, {"title": "Improving coreference resolution with entity-level distributed representations. In Association for Computational Linguistics (ACL)", "author": ["Clark", "Manning2016] Kevin Clark", "Christopher D. Manning"], "venue": null, "citeRegEx": "Clark et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Clark et al\\.", "year": 2016}, {"title": "Search-based structured prediction", "author": ["John Langford", "Daniel Marcu"], "venue": "Machine Learning,", "citeRegEx": "III et al\\.,? \\Q2009\\E", "shortCiteRegEx": "III et al\\.", "year": 2009}, {"title": "A ranking approach to pronoun resolution", "author": ["Denis", "Baldridge2007] Pascal Denis", "Jason Baldridge"], "venue": "In International Joint Conferences on Artificial Intelligence (IJCAI)", "citeRegEx": "Denis et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Denis et al\\.", "year": 2007}, {"title": "Easy victories and uphill battles in coreference resolution", "author": ["Durrett", "Klein2013] Greg Durrett", "Dan Klein"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Durrett et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2013}, {"title": "Decentralized entity-level modeling for coreference resolution. In Association for Computational Linguistics (ACL)", "author": ["Durrett et al.2013] Greg Durrett", "David Leo Wright Hall", "Dan Klein"], "venue": null, "citeRegEx": "Durrett et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Durrett et al\\.", "year": 2013}, {"title": "Latent structure perceptron with feature induction for unrestricted coreference resolution", "author": ["C\u0131\u0301cero Nogueira Dos Santos", "Ruy Luiz Milidi\u00fa"], "venue": "In Proceedings of the Joint Conference on Empirical", "citeRegEx": "Fernandes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Fernandes et al\\.", "year": 2012}, {"title": "Coreference resolution in a modular, entitycentered model. In Human Language Technology and North American Association for Computational Linguistics (HLT-NAACL)", "author": ["Haghighi", "Klein2010] Aria Haghighi", "Dan Klein"], "venue": null, "citeRegEx": "Haghighi et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Haghighi et al\\.", "year": 2010}, {"title": "Lecture 6.5-RmsProp: Divide the gradient by a running average of its recent magnitude", "author": ["Hinton", "Tieleman2012] Geoffrey Hinton", "Tijmen Tieleman"], "venue": "COURSERA: Neural Networks for Machine Learning,", "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580", "author": ["Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "On coreference resolution performance metrics. In Empirical Methods in Natural Language Processing (EMNLP)", "author": ["Xiaoqiang Luo"], "venue": null, "citeRegEx": "Luo.,? \\Q2005\\E", "shortCiteRegEx": "Luo.", "year": 2005}, {"title": "Prune-andscore: Learning for greedy coreference resolution", "author": ["Ma et al.2014] Chao Ma", "Janardhan Rao Doppa", "J Walker Orr", "Prashanth Mannem", "Xiaoli Fern", "Tom Dietterich", "Prasad Tadepalli"], "venue": "In Empirical Methods in Natural Language Processing", "citeRegEx": "Ma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ma et al\\.", "year": 2014}, {"title": "Latent structures for coreference resolution. Transactions of the Association for Computational Linguistics (TACL), 3:405\u2013418", "author": ["Martschat", "Strube2015] Sebastian Martschat", "Michael Strube"], "venue": null, "citeRegEx": "Martschat et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Martschat et al\\.", "year": 2015}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["Nair", "Hinton2010] Vinod Nair", "Geoffrey E. Hinton"], "venue": "In International Conference on Machine Learning (ICML)", "citeRegEx": "Nair et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Nair et al\\.", "year": 2010}, {"title": "Conll-2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes", "author": ["Alessandro Moschitti", "Nianwen Xue", "Olga Uryupina", "Yuchen Zhang"], "venue": "In Proceedings of the Joint Conference on Empirical", "citeRegEx": "Pradhan et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Pradhan et al\\.", "year": 2012}, {"title": "A multi-pass sieve for coreference resolution", "author": ["Heeyoung Lee", "Sudarshan Rangarajan", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky", "Christopher Manning"], "venue": null, "citeRegEx": "Raghunathan et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Raghunathan et al\\.", "year": 2010}, {"title": "Supervised models for coreference resolution", "author": ["Rahman", "Ng2009] Altaf Rahman", "Vincent Ng"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP)", "citeRegEx": "Rahman et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Rahman et al\\.", "year": 2009}, {"title": "Reinforcement learning: An introduction", "author": ["Sutton", "Barto1998] Richard S Sutton", "Andrew G Barto"], "venue": null, "citeRegEx": "Sutton et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1998}, {"title": "A model-theoretic coreference scoring scheme", "author": ["Vilain et al.1995] Marc Vilain", "John Burger", "John Aberdeen", "Dennis Connolly", "Lynette Hirschman"], "venue": "In Proceedings of the 6th conference on message understanding", "citeRegEx": "Vilain et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Vilain et al\\.", "year": 1995}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["Ronald J Williams"], "venue": "Machine learning,", "citeRegEx": "Williams.,? \\Q1992\\E", "shortCiteRegEx": "Williams.", "year": 1992}, {"title": "Learning anaphoricity and antecedent ranking features for coreference resolution", "author": ["Wiseman et al.2015] Sam Wiseman", "Alexander M. Rush", "Stuart M. Shieber", "Jason Weston"], "venue": "In Association of Computational Linguistics (ACL)", "citeRegEx": "Wiseman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Wiseman et al\\.", "year": 2015}, {"title": "Learning global features for coreference resolution. In Human Language Technology and North American Association for Computational Linguistics (HLT-NAACL)", "author": ["Wiseman et al.2016] Sam Wiseman", "Alexander M. Rush", "Stuart M. Shieber"], "venue": null, "citeRegEx": "Wiseman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wiseman et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 21, "context": "We also test the REINFORCE policy gradient algorithm (Williams, 1992).", "startOffset": 53, "endOffset": 69}, {"referenceID": 21, "context": "In particular, we modify the max-margin coreference objective proposed by Wiseman et al. (2015) by incorporating the reward associated with each coreference decision into the loss\u2019s slack rescaling.", "startOffset": 74, "endOffset": 96}, {"referenceID": 22, "context": ", Haghighi and Klein, 2010), mention-ranking models are fast, scalable, and simple to train, causing them to be the dominant approach to coreference in recent years (Durrett and Klein, 2013; Wiseman et al., 2015).", "startOffset": 165, "endOffset": 212}, {"referenceID": 22, "context": "In this section we first describe a heuristic loss function incorporating this idea from Wiseman et al. (2015). We then propose new training procedures based on reinforcement learning that instead directly optimize for coreference evaluation metrics.", "startOffset": 89, "endOffset": 111}, {"referenceID": 6, "context": "is governed by the following error types, which were first proposed by Durrett et al. (2013).", "startOffset": 71, "endOffset": 93}, {"referenceID": 20, "context": "Although our system evaluation also includes the MUC (Vilain et al., 1995) and CEAF\u03c64 (Luo, 2005) metrics, we do not incorporate them into the loss because MUC has the flaw of treating all errors equally and CEAF\u03c64 is slow to compute.", "startOffset": 53, "endOffset": 74}, {"referenceID": 12, "context": ", 1995) and CEAF\u03c64 (Luo, 2005) metrics, we do not incorporate them into the loss because MUC has the flaw of treating all errors equally and CEAF\u03c64 is slow to compute.", "startOffset": 19, "endOffset": 30}, {"referenceID": 21, "context": "We also explore using the REINFORCE policy gradient algorithm (Williams, 1992).", "startOffset": 62, "endOffset": 78}, {"referenceID": 16, "context": "We run experiments on the English and Chinese portions of the CoNLL 2012 Shared Task data (Pradhan et al., 2012) and evaluate with the MUC, B3, and CEAF\u03c64 metrics.", "startOffset": 90, "endOffset": 112}, {"referenceID": 17, "context": "Our experiments were run using predicted mentions from Stanford\u2019s rule-based coreference system (Raghunathan et al., 2010).", "startOffset": 96, "endOffset": 122}, {"referenceID": 16, "context": "We run experiments on the English and Chinese portions of the CoNLL 2012 Shared Task data (Pradhan et al., 2012) and evaluate with the MUC, B3, and CEAF\u03c64 metrics. Our experiments were run using predicted mentions from Stanford\u2019s rule-based coreference system (Raghunathan et al., 2010). We follow the training methodology from Clark and Manning (2016): hidden layers of sizes M1 = 1000, M2 = M3 = 500, the RMSprop optimizer", "startOffset": 91, "endOffset": 353}, {"referenceID": 10, "context": "(Hinton and Tieleman, 2012), dropout (Hinton et al., 2012) with a rate of 0.", "startOffset": 37, "endOffset": 58}, {"referenceID": 8, "context": "1 (Fernandes et al., 2012; Durrett et al., 2013; Bj\u00f6rkelund and Kuhn, 2014; Wiseman et al., 2015; Martschat and Strube, 2015; Wiseman et al., 2016).", "startOffset": 2, "endOffset": 147}, {"referenceID": 6, "context": "1 (Fernandes et al., 2012; Durrett et al., 2013; Bj\u00f6rkelund and Kuhn, 2014; Wiseman et al., 2015; Martschat and Strube, 2015; Wiseman et al., 2016).", "startOffset": 2, "endOffset": 147}, {"referenceID": 22, "context": "1 (Fernandes et al., 2012; Durrett et al., 2013; Bj\u00f6rkelund and Kuhn, 2014; Wiseman et al., 2015; Martschat and Strube, 2015; Wiseman et al., 2016).", "startOffset": 2, "endOffset": 147}, {"referenceID": 23, "context": "1 (Fernandes et al., 2012; Durrett et al., 2013; Bj\u00f6rkelund and Kuhn, 2014; Wiseman et al., 2015; Martschat and Strube, 2015; Wiseman et al., 2016).", "startOffset": 2, "endOffset": 147}, {"referenceID": 13, "context": ", 2009) have been used to train coreference resolvers (Daum\u00e9 III, 2006; Ma et al., 2014; Clark and Manning, 2015).", "startOffset": 54, "endOffset": 113}], "year": 2017, "abstractText": "Coreference resolution systems are typically trained with heuristic loss functions that require careful tuning. In this paper we instead apply reinforcement learning to directly optimize a neural mention-ranking model for coreference evaluation metrics. We experiment with two approaches: the REINFORCE policy gradient algorithm and a rewardrescaled max-margin objective. We find the latter to be more effective, resulting in significant improvements over the current state-ofthe-art on the English and Chinese portions of the CoNLL 2012 Shared Task.", "creator": "LaTeX with hyperref package"}}}