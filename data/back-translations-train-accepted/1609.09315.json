{"id": "1609.09315", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2016", "title": "Semantic Parsing with Semi-Supervised Sequential Autoencoders", "abstract": "We present a novel semi-supervised approach for sequence transduction and apply it to semantic parsing. The unsupervised component is based on a generative model in which latent sentences generate the unpaired logical forms. We apply this method to a number of semantic parsing tasks focusing on domains with limited access to labelled training data and extend those datasets with synthetically generated logical forms.", "histories": [["v1", "Thu, 29 Sep 2016 12:20:13 GMT  (807kb,D)", "http://arxiv.org/abs/1609.09315v1", null]], "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.NE", "authors": ["tom\u00e1s kocisk\u00fd", "g\u00e1bor melis", "edward grefenstette", "chris dyer", "wang ling", "phil blunsom", "karl moritz hermann"], "accepted": true, "id": "1609.09315"}, "pdf": {"name": "1609.09315.pdf", "metadata": {"source": "CRF", "title": "Semantic Parsing with Semi-Supervised Sequential Autoencoders", "authors": ["Tom\u00e1\u0161 Ko\u010disk\u00fd", "G\u00e1bor Melis", "Edward Grefenstette", "Chris Dyer", "Wang Ling", "Phil Blunsom", "Karl Moritz Hermann"], "emails": ["tkocisky@google.com", "melisgl@google.com", "etg@google.com", "cdyer@google.com", "lingwang@google.com", "pblunsom@google.com", "kmh@google.com"], "sections": [{"heading": null, "text": "We present a novel semi-supervised approach to sequence transduction and apply it to semantic parsing. The unattended component is based on a generative model in which latent sentences generate the unpaired logical forms. We apply this method to a set of semantic parsing tasks that focus on areas with limited access to marked training data, and expand these data sets with synthetically generated logical forms."}, {"heading": "1 Introduction", "text": "In this paper, we focus on learning input sequences in domains where the latter are easy to achieve, but the requirement for effective training in the form of (x, y) pairs is sparse or expensive to produce a novel architecture that converts semi-sequences into sequences."}, {"heading": "2 Model", "text": "Our sequential autoencoder is shown in Figure 1. At a high level, it can be considered as two sequence-to-sequence models with attention (Bahdanau et al., 2015) that are concatenated. Specifically, the model consists of four LSTMs (Hochreiter and Schmidhuber, 1997), hence the name SEQ4. The first, a bidirectional LSTM, encodes the sequence y; next, an LSTM with stochastic output, as described below, draws a sequence of x distributions across words in the vocabulary. The third LSTM encodes these distributions for the last one to visit and reconstruct y-as-y."}, {"heading": "2.1 Encoding y", "text": "The first LSTM of the encoder half of the model reads the sequence y, represented as a sequence of one-hot vectors above the vocabulary \u0442y, using a bidirectional RNN into a sequence of vectors hy1: Ly, where Ly is the sequence length of y, hyt = (f \u2192 y (yt, h y, \u2192 t \u2212 1); f \u2190 y (yt, h y, \u2190 t + 1)), (1) where f \u2192 y, f \u2190 y are each nonlinear functions applied to the current token yt and its recurring states hy, \u2192 t \u2212 1, h y, \u2190 t + 1. Both the forward and backward functions project the one-hot vector via an embedding matrix into a dense vector that serves as an input to an LSTM."}, {"heading": "2.2 Predicting a Latent Sequence x\u0303", "text": "The prediction of a discrete order of symbols by dragging from multinomial distributions over a vocabulary is not an option, since we would not be able to spread us through this discrete choice backwards (which we would have to specify manually) using the vocabulary size as a basis. To enable a backward spread, we instead forecast a sequence of distributions x over the symbols x x, where the number of strings is exponentially in the maximum length (which we would have to specify manually) using the vocabulary size as a base. (To enable a backward spread, we instead forecast a sequence of distributions x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x, x"}, {"heading": "2.3 Encoding x", "text": "Now we come to the decoder part of our model, in the third LSTM, and embed 2 and code x-x: hxt = (f \u2192 x (x-t, h x, \u2192 t-1); f \u2190 x (x-t, h x, \u2190 t + 1))) (8) If x is observed, during the supervised training and also when making predictions, we feed the hot coded x into this part of the model instead of the distribution x-t."}, {"heading": "2.4 Reconstructing y", "text": "In the final LSTM we decipher in y: p (y-x-1) = Ly-t = 1 p (y-t-1, \u00b7 \u00b7, y-t-1, hx-1) (9) Equation 9 is implemented as an LSTM that goes beyond hx-1 and produces a sequence of symbols y-t on the basis of recurring states hy-t, which aims to reproduce input y: hy-t = fy (y-t-1, h-y-t-1, h-x-1) (10) y-t-soft-max (l-t-1) (11), where fy-t is the non-linear function and the actual probabilities are given by a Softmax function after a linear transformation l-t-1 of hy."}, {"heading": "2.5 Loss function", "text": "The complete model described in this section gives a reconstruction function y 7 \"y\" p. \"We define a loss on this reconstruction that takes up the unattended case in which x is not observed in the training data, and the monitored case in which (x, y) pairs are available. Together, these allow us to train the SEQ4 model in a semi-monitored environment in which experiments will show some advantages over a purely monitored training regime. Unmonitored cases If x is not observed, the loss we minimize during training is the reconstruction loss on y, expressed as the negative logarithelihood NLL (y, y) of the true label y in terms of predictions y.\" To this we add as regularising2Multiplication of the distribution over words and an embedding of the matrix the word embedding of the entire vocabulary x. \""}, {"heading": "3 Tasks and Data Generation", "text": "We apply our model to three tasks outlined in this section. In addition, we explain how we generated additional unattended training data for two of these tasks. Examples from all data sets can be found in Table 1."}, {"heading": "3.1 GeoQuery", "text": "The first task we are considering is to predict a query about the GEO corpus, a commonly used benchmark for semantic parsing. It contains 880 questions about US geography along with executable queries representing these questions. We follow the approach established by Zettlemoyer and Collins (2005) and divide the corpus into 600 training and 280 test cases. According to common practice, we expand the data set by referring to the database during training and testing time. Specifically, we use the database to identify and anonymize variables (cities, states, countries and rivers) according to the method described in Dong and Lapata (2016)."}, {"heading": "3.2 Open Street Maps", "text": "The second task we are tackling with our model is the Haas and Riezler NLMAPS dataset (2016), which contains 1,500 training cases and 880 test cases on natural language issues with corresponding machine-readable queries via the OpenStreetMap geographic database. The dataset contains natural language questions in both English and German, but we focus only on monolingual semantic parsing, similar to the first task in Haas and Riezler (2016). We use the data as it is, with the only pre-processing step being tokenization of both the natural language and the query form3."}, {"heading": "3.3 Navigational Instructions to Actions", "text": "The SAIL corpus and task are designed to train agents to follow free-form navigation routes in a labyrinth environment (MacMahon et al., 2006; Chen and Mooney, 2011). It consists of a small number of labyrinths that contain features such as objects, wall and floor types.These labyrinths come along with a large number of human instructions paired with the required action4 to achieve the objective.3We removed quotes, inserted spaces () and separated the question mark from the last word in each question.4There are four actions: LEFT, RIGHT, GO, STOP.state, which are described in these instructions.We use the sentence-oriented version of the SAIL route instruction dataset with 3,236 sentences (Chen and Mooney, 2011). After previous work, we accept an action sequence as correct, and only if the final position and orientation do not match those of the data."}, {"heading": "3.4 Data Generation", "text": "As previously argued, we focus on tasks where aligned data is sparse and expensive to obtain, while it should be cheap to obtain unattended, monomodal data. Although this is a reasonable assumption for real data, the data sets under consideration have no such component, so the approach used here is to generate random database queries or labyrinth paths, i.e. generate the machine-readable side of the data and train a semi-supervised model. The alternative, which is not examined here, would be to generate questions or statements in natural language instead, but that is more difficult to achieve without human intervention. Therefore, we generate the machine-readable side of the data for GEOQUERY and SAIL tasks. For GEOQUERY, we match a 3-gram Kneser-Ney model (Chen and Goodman, 1999) to the queries in the training set, and sample about 7 million queries for the training tasks, but make sure the validity is different."}, {"heading": "4 Experiments", "text": "Next, we can download our randomly generated, unattended data sets from http: / / deepmind.com / publicationand compare our SEQ4 model in a semi-monitored environment across the entire data set with the additional monomodal training data described in the previous paragraph. Finally, we perform an \"ablation study\" in which we discard some of the training data and compare S2S with SEQ4. S2S is trained solely on the reduced data in a monitored manner, while SEQ4 is trained semi-monitored again on the same reduced data plus the machine-readable portion of the discarded data (SEQ4 +) or on the additional data generated (SEQ4 +). Since none of the data sets used here contains development sets, we adjust hyperparameters by checking the results of the AIDS training for each case (weighted) and the results for the weighted SL tests in 2016."}, {"heading": "4.1 GeoQuery", "text": "The score for GEOQUERY is the accuracy of accurately predicting the machine-readable query. As the results in Table 2 show, our monitored S2S base model performs slightly better than the comparable model of Dong and Lapata (2016). The semi-monitored SEQ4 model with the additionally generated queries continues to improve. The ablation study in Table 3 shows a growing gap between monitored and semi-6Jia and Liang (2016), who use handmade grammars to generate additional monitored training data."}, {"heading": "5% 21.9 30.1 26.2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10% 39.7 42.1 42.1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "25% 62.4 70.4 67.1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "50% 80.3 81.2 80.4", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "75% 85.3 84.1 85.1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "100% 86.5 86.5 87.3", "text": "This indicates that our model can use unlabeled data even when only small amounts of labeled data are available."}, {"heading": "4.2 Open Street Maps", "text": "We report in Table 4 on the results of the NLMAPS corpus and compare the monitored S2S model with the results of Haas and Riezler (2016). While their model used a semantic parsing pipeline with alignment, stemming, speech modeling, and CFG conclusions, the strong performance of the S2S model shows the strength of sequence-to-sequence models based on fairly paternal attention. It should be noted that the previous work indicates the number of correct answers when queries were executed against the data set, while we evaluate the rigorous accuracy of the queries generated. Although we expect these numbers to be roughly equivalent, our assessment is strictly more difficult as it does not allow for reordering query arguments and similar relativizations. We examine the SEQ4 model only through the deposition study in Table 5 and find little gain from the semi-monitored target, our attempt to base the unapproved task on the probability of completing the data."}, {"heading": "4.3 Navigational Instructions to Actions", "text": "The experiments for the SAIL task differ slightly from the other two tasks in that language input is not sufficient to select a task."}, {"heading": "5% 3.22 3.74", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10% 17.61 17.12", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "25% 33.74 33.50", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "50% 49.52 53.72", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "75% 66.93 66.45", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "100% 78.03 78.03", "text": "While a simple statement such as \"turn left\" can easily be translated into the action sequence LEFT-STOP, more complex statements such as \"go forward until you see a lamp\" require knowledge of the position of the agent in the labyrinth. To achieve this, we modify the model as follows: First, when coding action sequences, we associate each action with a representation of the labyrinth at the given position, which represents the Mazestate with a vector full of characteristics similar to Mei et al. (2016). Second, when decoding action sequences, the RNN outputs an action that is used to update the position of the agent, and the representation of this new position is fed into the RNN as the next input."}, {"heading": "5 Discussion", "text": "For GEOQUERY, S2S performs significantly better than the most comparable model from literature (Dong and Lapata, 2016), which is mainly due to the fact that y and x have the same values as most comparable models from literature (Dong and Lapata, 2016)."}, {"heading": "5% 37.79 41.48 43.44", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "10% 40.77 41.26 48.67", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "25% 43.76 43.95 51.19", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "50% 48.01 49.42 55.97", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "75% 48.99 49.20 57.40", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "100% 49.49 49.49 58.28", "text": "It is only a matter of time before it will happen, until it will happen."}, {"heading": "6 Related Work", "text": "Semantic parsing The tasks in this thesis all fall into the field of semantic parsing, which describes the process of mapping natural language to a formal representation of its meaning. This is extended in the SAIL navigation task, where formal representation is both a function of language teaching and a predetermined environment.Semantic parsing is a well-studied problem with numerous approaches, including inductive logical programming (Cell and Mooney, 1996), stringto-tree (Galley et al., 2004) and string-to-graph (Jones et al., 2012) converters, grammar induction (Kwiatkowski et al., 2011; Artzi and Zettlemoyer, 2014) or machine translation (Wong and Mooney, 2006; Andreas et al., 2013).While a large number of relevant literature fo-cuses on the definition of logical forms (Zettlemoyer and Collins, 2005), is learning other logical models from pairing (2016)."}, {"heading": "7 Conclusion", "text": "We described a method of adding an autocoding lens to a supervised sequence transduction lens, enabling semi-supervised training where previously a lack of aligned data might have slowed the performance of the model. Across several semantic analysis tasks, we demonstrated the effectiveness of this approach and improved the performance of the model by training randomly generated, unsupervised data in addition to the original data. While we focused on tasks with little supervised data and additional unsupervised data in y, it would be easy to reverse the model to train it with additional marked data in x, i.e. on the side of natural language. A natural extension would also be a formulation where semi-supervised training was performed in both x and y."}], "references": [{"title": "Conditional Random Field Autoencoders for Unsupervised Structured Prediction", "author": ["Waleed Ammar", "Chris Dyer", "Noah A. Smith."], "venue": "Proceedings of NIPS.", "citeRegEx": "Ammar et al\\.,? 2014", "shortCiteRegEx": "Ammar et al\\.", "year": 2014}, {"title": "Alignment-based Compositional Semantics for Instruction Following", "author": ["Jacob Andreas", "Dan Klein."], "venue": "Proceedings of EMNLP, September.", "citeRegEx": "Andreas and Klein.,? 2015", "shortCiteRegEx": "Andreas and Klein.", "year": 2015}, {"title": "Semantic Parsing as Machine Translation", "author": ["Jacob Andreas", "Andreas Vlachos", "Stephen Clark."], "venue": "Proceedings of ACL, August.", "citeRegEx": "Andreas et al\\.,? 2013", "shortCiteRegEx": "Andreas et al\\.", "year": 2013}, {"title": "Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions", "author": ["Yoav Artzi", "Luke Zettlemoyer."], "venue": "Transactions of the Association for Computational Linguistics, 1(1):49\u201362.", "citeRegEx": "Artzi and Zettlemoyer.,? 2013", "shortCiteRegEx": "Artzi and Zettlemoyer.", "year": 2013}, {"title": "Learning Compact Lexicons for CCG Semantic Parsing", "author": ["Yoav Artzi", "Dipanjan Das", "Slav Petrov."], "venue": "Proceedings of EMNLP, October.", "citeRegEx": "Artzi et al\\.,? 2014", "shortCiteRegEx": "Artzi et al\\.", "year": 2014}, {"title": "Neural Machine Translation by Jointly Learning to Align and Translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "Proceedings of ICLR.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Semantic Parsing via Paraphrasing", "author": ["Jonathan Berant", "Percy Liang."], "venue": "Proceedings of ACL, June.", "citeRegEx": "Berant and Liang.,? 2014", "shortCiteRegEx": "Berant and Liang.", "year": 2014}, {"title": "An empirical study of smoothing techniques for language modeling", "author": ["Stanley F Chen", "Joshua Goodman."], "venue": "Computer Speech & Language, 13(4):359\u2013393.", "citeRegEx": "Chen and Goodman.,? 1999", "shortCiteRegEx": "Chen and Goodman.", "year": 1999}, {"title": "Learning to Interpret Natural Language Navigation Instructions from Observations", "author": ["David L. Chen", "Raymond J. Mooney."], "venue": "Proceedings of AAAI, August.", "citeRegEx": "Chen and Mooney.,? 2011", "shortCiteRegEx": "Chen and Mooney.", "year": 2011}, {"title": "Language to Logical Form with Neural Attention", "author": ["Li Dong", "Mirella Lapata."], "venue": "arXiv preprint arXiv:1601.01280.", "citeRegEx": "Dong and Lapata.,? 2016", "shortCiteRegEx": "Dong and Lapata.", "year": 2016}, {"title": "What\u2019s in a translation rule", "author": ["Michel Galley", "Mark Hopkins", "Kevin Knight", "Daniel Marcu"], "venue": "In Proceedings of HLT-NAACL,", "citeRegEx": "Galley et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Galley et al\\.", "year": 2004}, {"title": "On Using Monolingual Corpora", "author": ["\u00c7aglar G\u00fcl\u00e7ehre", "Orhan Firat", "Kelvin Xu", "Kyunghyun Cho", "Lo\u0131\u0308c Barrault", "Huei-Chi Lin", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": null, "citeRegEx": "G\u00fcl\u00e7ehre et al\\.,? \\Q2015\\E", "shortCiteRegEx": "G\u00fcl\u00e7ehre et al\\.", "year": 2015}, {"title": "A corpus and semantic parser for multilingual natural language querying of openstreetmap", "author": ["Carolin Haas", "Stefan Riezler."], "venue": "Proceedings of NAACL, June.", "citeRegEx": "Haas and Riezler.,? 2016", "shortCiteRegEx": "Haas and Riezler.", "year": 2016}, {"title": "Long Short-Term Memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Computation, 9(8):1735\u20131780, November.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Data recombination for neural semantic parsing", "author": ["Robin Jia", "Percy Liang."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Jia and Liang.,? 2016", "shortCiteRegEx": "Jia and Liang.", "year": 2016}, {"title": "SemanticsBased Machine Translation with Hyperedge Replacement Grammars", "author": ["Bevan Jones", "Jacob Andreas", "Daniel Bauer", "Karl Moritz Hermann", "Kevin Knight."], "venue": "Proceedings of COLING 2012, December.", "citeRegEx": "Jones et al\\.,? 2012", "shortCiteRegEx": "Jones et al\\.", "year": 2012}, {"title": "Unsupervised PCFG Induction for Grounded Language Learning with Highly Ambiguous Supervision", "author": ["Joohyun Kim", "Raymond J. Mooney."], "venue": "Proceedings of EMNLP-CoNLL, July.", "citeRegEx": "Kim and Mooney.,? 2012", "shortCiteRegEx": "Kim and Mooney.", "year": 2012}, {"title": "Adapting Discriminative Reranking to Grounded Language Learning", "author": ["Joohyun Kim", "Raymond Mooney."], "venue": "Proceedings of ACL, August.", "citeRegEx": "Kim and Mooney.,? 2013", "shortCiteRegEx": "Kim and Mooney.", "year": 2013}, {"title": "AutoEncoding Variational Bayes", "author": ["Diederik P. Kingma", "Max Welling."], "venue": "Proceedings of ICLR.", "citeRegEx": "Kingma and Welling.,? 2014", "shortCiteRegEx": "Kingma and Welling.", "year": 2014}, {"title": "Lexical Generalization in CCG Grammar Induction for Semantic Parsing", "author": ["Tom Kwiatkowski", "Luke Zettlemoyer", "Sharon Goldwater", "Mark Steedman."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Kwiatkowski et al\\.,? 2011", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2011}, {"title": "Scaling semantic parsers with on-the-fly ontology matching", "author": ["Tom Kwiatkowski", "Eunsol Choi", "Yoav Artzi", "Luke Zettlemoyer."], "venue": "In Proceedings of EMNLP. Citeseer.", "citeRegEx": "Kwiatkowski et al\\.,? 2013", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2013}, {"title": "Learning Dependency-based Compositional Semantics", "author": ["Percy Liang", "Michael I. Jordan", "Dan Klein."], "venue": "Proceedings of the ACL-HLT.", "citeRegEx": "Liang et al\\.,? 2011", "shortCiteRegEx": "Liang et al\\.", "year": 2011}, {"title": "Learning dependency-based compositional semantics", "author": ["Percy Liang", "Michael I Jordan", "Dan Klein."], "venue": "Computational Linguistics, 39(2):389\u2013446.", "citeRegEx": "Liang et al\\.,? 2013", "shortCiteRegEx": "Liang et al\\.", "year": 2013}, {"title": "Walk the Talk: Connecting Language, Knowledge, and Action in Route Instructions", "author": ["Matt MacMahon", "Brian Stankiewicz", "Benjamin Kuipers."], "venue": "Proceedings of AAAI.", "citeRegEx": "MacMahon et al\\.,? 2006", "shortCiteRegEx": "MacMahon et al\\.", "year": 2006}, {"title": "Discrete-state variational autoencoders for joint discovery and factorization of relations", "author": ["Diego Marcheggiani", "Ivan Titov."], "venue": "Transactions of ACL.", "citeRegEx": "Marcheggiani and Titov.,? 2016", "shortCiteRegEx": "Marcheggiani and Titov.", "year": 2016}, {"title": "Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences", "author": ["Hongyuan Mei", "Mohit Bansal", "Matthew R. Walter."], "venue": "Proceedings of AAAI.", "citeRegEx": "Mei et al\\.,? 2016", "shortCiteRegEx": "Mei et al\\.", "year": 2016}, {"title": "Large-scale Semantic Parsing without QuestionAnswer Pairs", "author": ["Siva Reddy", "Mirella Lapata", "Mark Steedman."], "venue": "Transactions of the Association for Computational Linguistics, 2:377\u2013392.", "citeRegEx": "Reddy et al\\.,? 2014", "shortCiteRegEx": "Reddy et al\\.", "year": 2014}, {"title": "Bilingual Learning of Multi-sense Embeddings with Discrete Autoencoders", "author": ["Simon Suster", "Ivan Titov", "Gertjan van Noord."], "venue": "CoRR, abs/1603.09128.", "citeRegEx": "Suster et al\\.,? 2016", "shortCiteRegEx": "Suster et al\\.", "year": 2016}, {"title": "Grammar as a Foreign Language", "author": ["Oriol Vinyals", "\u0141ukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton."], "venue": "Proceedings of NIPS.", "citeRegEx": "Vinyals et al\\.,? 2015", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Learning for Semantic Parsing with Statistical Machine Translation", "author": ["Yuk Wah Wong", "Raymond J. Mooney."], "venue": "Proceedings of NAACL.", "citeRegEx": "Wong and Mooney.,? 2006", "shortCiteRegEx": "Wong and Mooney.", "year": 2006}, {"title": "Learning to Parse Database Queries using Inductive Logic Programming", "author": ["John M. Zelle", "Raymond J. Mooney."], "venue": "Proceedings of AAAI/IAAI, pages 1050\u2013 1055, August.", "citeRegEx": "Zelle and Mooney.,? 1996", "shortCiteRegEx": "Zelle and Mooney.", "year": 1996}, {"title": "Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars", "author": ["Luke S. Zettlemoyer", "Michael Collins."], "venue": "UAI, pages 658\u2013666. AUAI Press.", "citeRegEx": "Zettlemoyer and Collins.,? 2005", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2005}, {"title": "Online Learning of Relaxed CCG Grammars for Parsing to Logical Form", "author": ["Luke Zettlemoyer", "Michael Collins."], "venue": "Proceedings of EMNLP-CoNLL, June.", "citeRegEx": "Zettlemoyer and Collins.,? 2007", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2007}, {"title": "Type-driven incremental semantic parsing with polymorphism", "author": ["Kai Zhao", "Liang Huang."], "venue": "arXiv preprint arXiv:1411.5379.", "citeRegEx": "Zhao and Huang.,? 2014", "shortCiteRegEx": "Zhao and Huang.", "year": 2014}, {"title": "End-to-end Learning of Semantic Role Labeling Using Recurrent Neural Networks", "author": ["Jie Zhou", "Wei Xu."], "venue": "Proceedings of ACL.", "citeRegEx": "Zhou and Xu.,? 2015", "shortCiteRegEx": "Zhou and Xu.", "year": 2015}], "referenceMentions": [{"referenceID": 5, "context": "Neural approaches, in particular attention-based sequence-to-sequence models, have shown great promise and obtained state-of-the-art performance for sequence transduction tasks including machine translation (Bahdanau et al., 2015), syntactic constituency parsing (Vinyals et al.", "startOffset": 207, "endOffset": 230}, {"referenceID": 28, "context": ", 2015), syntactic constituency parsing (Vinyals et al., 2015), and semantic role labelling (Zhou and Xu, 2015).", "startOffset": 40, "endOffset": 62}, {"referenceID": 34, "context": ", 2015), and semantic role labelling (Zhou and Xu, 2015).", "startOffset": 37, "endOffset": 56}, {"referenceID": 18, "context": "To avoid this intractable marginalisation, we introduce a novel differentiable alternative for draws from a softmax which can be used with the reparametrisation trick of Kingma and Welling (2014). Rather than drawing a discrete symbol in \u03a3x from a softmax, we draw a distribution over symbols from a logistic-normal distribution at each time step.", "startOffset": 170, "endOffset": 196}, {"referenceID": 30, "context": "We demonstrate the effectiveness of our proposed model on three semantic parsing tasks: the GEOQUERY benchmark (Zelle and Mooney, 1996; Wong and Mooney, 2006), the SAIL maze navigation task (MacMahon et al.", "startOffset": 111, "endOffset": 158}, {"referenceID": 29, "context": "We demonstrate the effectiveness of our proposed model on three semantic parsing tasks: the GEOQUERY benchmark (Zelle and Mooney, 1996; Wong and Mooney, 2006), the SAIL maze navigation task (MacMahon et al.", "startOffset": 111, "endOffset": 158}, {"referenceID": 23, "context": "We demonstrate the effectiveness of our proposed model on three semantic parsing tasks: the GEOQUERY benchmark (Zelle and Mooney, 1996; Wong and Mooney, 2006), the SAIL maze navigation task (MacMahon et al., 2006) and the Natural Language Querying corpus (Haas and Riezler, 2016) on OpenStreetMap.", "startOffset": 190, "endOffset": 213}, {"referenceID": 12, "context": ", 2006) and the Natural Language Querying corpus (Haas and Riezler, 2016) on OpenStreetMap.", "startOffset": 49, "endOffset": 73}, {"referenceID": 5, "context": "At a high level, it can be seen as two sequenceto-sequence models with attention (Bahdanau et al., 2015) chained together.", "startOffset": 81, "endOffset": 104}, {"referenceID": 13, "context": "More precisely, the model consists of four LSTMs (Hochreiter and Schmidhuber, 1997), hence the name SEQ4.", "startOffset": 49, "endOffset": 83}, {"referenceID": 18, "context": "We use the reparametrisation trick from Kingma and Welling (2014) to draw from the logistic normal, allowing us to backpropagate through the sampling process.", "startOffset": 40, "endOffset": 66}, {"referenceID": 18, "context": "We use a closed form of these individual KL divergences, described by Kingma and Welling (2014).", "startOffset": 70, "endOffset": 96}, {"referenceID": 30, "context": "We follow the approach established by Zettlemoyer and Collins (2005) and split the corpus into 600 training and 280 test cases.", "startOffset": 38, "endOffset": 69}, {"referenceID": 9, "context": "In particular, we use the database to identify and anonymise variables (cities, states, countries and rivers) following the method described in Dong and Lapata (2016). Most prior work on the GEO corpus relies on standard semantic parsing methods together with custom heuristics or pipelines for this corpus.", "startOffset": 144, "endOffset": 167}, {"referenceID": 9, "context": "In particular, we use the database to identify and anonymise variables (cities, states, countries and rivers) following the method described in Dong and Lapata (2016). Most prior work on the GEO corpus relies on standard semantic parsing methods together with custom heuristics or pipelines for this corpus. The recent paper by Dong and Lapata (2016) is of note, as it uses a sequence-to-sequence model for training which is the unidirectional equivalent to S2S, and also to the decoder part of our SEQ4 network.", "startOffset": 144, "endOffset": 351}, {"referenceID": 12, "context": "The second task we tackle with our model is the NLMAPS dataset by Haas and Riezler (2016). The dataset contains 1,500 training and 880 testing instances of natural language questions with corresponding machine readable queries over the geographical OpenStreetMap database.", "startOffset": 66, "endOffset": 90}, {"referenceID": 12, "context": "The second task we tackle with our model is the NLMAPS dataset by Haas and Riezler (2016). The dataset contains 1,500 training and 880 testing instances of natural language questions with corresponding machine readable queries over the geographical OpenStreetMap database. The dataset contains natural language question in both English and German but we focus only on single language semantic parsing, similar to the first task in Haas and Riezler (2016). We use the data as it is, with the only pre-processing step being the tokenization of both natural language and query form3.", "startOffset": 66, "endOffset": 455}, {"referenceID": 23, "context": "The SAIL corpus and task were developed to train agents to follow free-form navigational route instructions in a maze environment (MacMahon et al., 2006; Chen and Mooney, 2011).", "startOffset": 130, "endOffset": 176}, {"referenceID": 8, "context": "The SAIL corpus and task were developed to train agents to follow free-form navigational route instructions in a maze environment (MacMahon et al., 2006; Chen and Mooney, 2011).", "startOffset": 130, "endOffset": 176}, {"referenceID": 8, "context": "We use the sentence-aligned version of the SAIL route instruction dataset containing 3,236 sentences (Chen and Mooney, 2011).", "startOffset": 101, "endOffset": 124}, {"referenceID": 7, "context": "For GEOQUERY, we fit a 3-gram Kneser-Ney (Chen and Goodman, 1999) model to the queries in the training set and sample about 7 million queries from it.", "startOffset": 41, "endOffset": 65}, {"referenceID": 19, "context": "1 Liang et al. (2013) 87.", "startOffset": 2, "endOffset": 22}, {"referenceID": 19, "context": "9 Kwiatkowski et al. (2011) 88.", "startOffset": 2, "endOffset": 28}, {"referenceID": 19, "context": "9 Kwiatkowski et al. (2011) 88.6 Zhao and Huang (2014) 88.", "startOffset": 2, "endOffset": 55}, {"referenceID": 19, "context": "9 Kwiatkowski et al. (2011) 88.6 Zhao and Huang (2014) 88.9 Kwiatkowski et al. (2013) 89.", "startOffset": 2, "endOffset": 86}, {"referenceID": 31, "context": "using the train/test split from (Zettlemoyer and Collins, 2005).", "startOffset": 32, "endOffset": 63}, {"referenceID": 25, "context": "In the case of the SAIL corpus we train on three folds (two mazes for training and validation, one for test each) and report weighted results across the folds following prior work (Mei et al., 2016).", "startOffset": 180, "endOffset": 198}, {"referenceID": 9, "context": "As results in Table 2 show, our supervised S2S baseline model performs slightly better than the comparable model by Dong and Lapata (2016). The semi-supervised SEQ4 model with the additional generated queries improves on it further.", "startOffset": 116, "endOffset": 139}, {"referenceID": 12, "context": "We report results for the NLMAPS corpus in Table 4, comparing the supervised S2S model to the results posted by Haas and Riezler (2016). While their model used a semantic parsing pipeline including alignment, stemming, language modelling and CFG inference, the strong performance of the S2S model demonstrates the strength of fairly vanilla attentionbased sequence-to-sequence models.", "startOffset": 112, "endOffset": 136}, {"referenceID": 25, "context": "First, when encoding action sequences, we concatenate each action with a representation of the maze at the given position, representing the mazestate akin to Mei et al. (2016) with a bag-of-features vector.", "startOffset": 158, "endOffset": 176}, {"referenceID": 25, "context": "Mei et al. (2016)).", "startOffset": 0, "endOffset": 18}, {"referenceID": 25, "context": "Mei et al. (2016)). Both our supervised and semi-supervised model perform worse than the state-of-the-art (see Table 6), but the latter enjoys a comfortable margin over the former. As the S2S model broadly reimplements the work of Mei et al. (2016), we put the discrepancy in performance down to the particular design choices that we did not follow in order to keep the model here as general as possible and comparable across tasks.", "startOffset": 0, "endOffset": 249}, {"referenceID": 9, "context": "For GEOQUERY, S2S performs significantly better than the most similar model from the literature (Dong and Lapata, 2016), mostly due to the fact that y and x are", "startOffset": 96, "endOffset": 119}, {"referenceID": 1, "context": "22 Andreas and Klein (2015) 59.", "startOffset": 3, "endOffset": 28}, {"referenceID": 1, "context": "22 Andreas and Klein (2015) 59.60 Kim and Mooney (2013) 62.", "startOffset": 3, "endOffset": 56}, {"referenceID": 1, "context": "22 Andreas and Klein (2015) 59.60 Kim and Mooney (2013) 62.81 Artzi et al. (2014) 64.", "startOffset": 3, "endOffset": 82}, {"referenceID": 1, "context": "22 Andreas and Klein (2015) 59.60 Kim and Mooney (2013) 62.81 Artzi et al. (2014) 64.36 Artzi and Zettlemoyer (2013) 65.", "startOffset": 3, "endOffset": 117}, {"referenceID": 25, "context": "As the models are broadly equivalent we attribute this difference to a number of taskspecific choices and optimisations7 made in Mei et al. (2016) which we did not reimplement for the sake of using a common model across all three tasks.", "startOffset": 129, "endOffset": 147}, {"referenceID": 30, "context": "Semantic parsing is a well-studied problem with numerous approaches including inductive logic programming (Zelle and Mooney, 1996), stringto-tree (Galley et al.", "startOffset": 106, "endOffset": 130}, {"referenceID": 10, "context": "Semantic parsing is a well-studied problem with numerous approaches including inductive logic programming (Zelle and Mooney, 1996), stringto-tree (Galley et al., 2004) and string-to-graph (Jones et al.", "startOffset": 146, "endOffset": 167}, {"referenceID": 15, "context": ", 2004) and string-to-graph (Jones et al., 2012) transducers, grammar induction (Kwiatkowski et al.", "startOffset": 28, "endOffset": 48}, {"referenceID": 19, "context": ", 2012) transducers, grammar induction (Kwiatkowski et al., 2011; Artzi and Zettlemoyer, 2013; Reddy et al., 2014) or machine translation (Wong and Mooney, 2006; Andreas et al.", "startOffset": 39, "endOffset": 114}, {"referenceID": 3, "context": ", 2012) transducers, grammar induction (Kwiatkowski et al., 2011; Artzi and Zettlemoyer, 2013; Reddy et al., 2014) or machine translation (Wong and Mooney, 2006; Andreas et al.", "startOffset": 39, "endOffset": 114}, {"referenceID": 26, "context": ", 2012) transducers, grammar induction (Kwiatkowski et al., 2011; Artzi and Zettlemoyer, 2013; Reddy et al., 2014) or machine translation (Wong and Mooney, 2006; Andreas et al.", "startOffset": 39, "endOffset": 114}, {"referenceID": 29, "context": ", 2014) or machine translation (Wong and Mooney, 2006; Andreas et al., 2013).", "startOffset": 31, "endOffset": 76}, {"referenceID": 2, "context": ", 2014) or machine translation (Wong and Mooney, 2006; Andreas et al., 2013).", "startOffset": 31, "endOffset": 76}, {"referenceID": 31, "context": "While a large number of relevant literature focuses on defining the grammar of the logical forms (Zettlemoyer and Collins, 2005), other models learn purely from aligned pairs of text and logical form (Berant and Liang, 2014), or from more weakly supervised signals such as question-answer pairs together with a database (Liang et al.", "startOffset": 97, "endOffset": 128}, {"referenceID": 6, "context": "While a large number of relevant literature focuses on defining the grammar of the logical forms (Zettlemoyer and Collins, 2005), other models learn purely from aligned pairs of text and logical form (Berant and Liang, 2014), or from more weakly supervised signals such as question-answer pairs together with a database (Liang et al.", "startOffset": 200, "endOffset": 224}, {"referenceID": 21, "context": "While a large number of relevant literature focuses on defining the grammar of the logical forms (Zettlemoyer and Collins, 2005), other models learn purely from aligned pairs of text and logical form (Berant and Liang, 2014), or from more weakly supervised signals such as question-answer pairs together with a database (Liang et al., 2011).", "startOffset": 320, "endOffset": 340}, {"referenceID": 6, "context": "While a large number of relevant literature focuses on defining the grammar of the logical forms (Zettlemoyer and Collins, 2005), other models learn purely from aligned pairs of text and logical form (Berant and Liang, 2014), or from more weakly supervised signals such as question-answer pairs together with a database (Liang et al., 2011). Recent work of Jia and Liang (2016) induces a synchronous context-free grammar and generates additional training examples (x, y), which is one way to address data scarcity issues.", "startOffset": 201, "endOffset": 378}, {"referenceID": 0, "context": ") This work presents a first approach to using effectively discretised sequential information as the latent representation without resorting to draconian assumptions (Ammar et al., 2014) to make marginalisation tractable.", "startOffset": 166, "endOffset": 186}, {"referenceID": 0, "context": ") This work presents a first approach to using effectively discretised sequential information as the latent representation without resorting to draconian assumptions (Ammar et al., 2014) to make marginalisation tractable. While our model is not exactly marginalisable either, the continuous relaxation makes training far more tractable. A related idea was recently presented in G\u00fcl\u00e7ehre et al. (2015), who use monolingual data to improve machine translation by fusing a sequence-to-sequence model and a language model.", "startOffset": 167, "endOffset": 401}], "year": 2016, "abstractText": "We present a novel semi-supervised approach for sequence transduction and apply it to semantic parsing. The unsupervised component is based on a generative model in which latent sentences generate the unpaired logical forms. We apply this method to a number of semantic parsing tasks focusing on domains with limited access to labelled training data and extend those datasets with synthetically generated logical forms.", "creator": "LaTeX with hyperref package"}}}