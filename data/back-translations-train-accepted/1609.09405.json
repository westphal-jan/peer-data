{"id": "1609.09405", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Sep-2016", "title": "Evaluating Induced CCG Parsers on Grounded Semantic Parsing", "abstract": "We compare the effectiveness of four different syntactic CCG parsers for a semantic slot-filling task to explore how much syntactic supervision is required for downstream semantic analysis. This extrinsic, task-based evaluation also provides a unique window into the semantics captured (or missed) by unsupervised grammar induction systems.", "histories": [["v1", "Thu, 29 Sep 2016 16:09:29 GMT  (377kb,D)", "http://arxiv.org/abs/1609.09405v1", "6 pages, short paper, EMNLP 2016"], ["v2", "Tue, 31 Jan 2017 16:25:39 GMT  (332kb,D)", "http://arxiv.org/abs/1609.09405v2", "EMNLP 2016, Table 2 erratum, Code and Freebase Semantic Parsing data URL"]], "COMMENTS": "6 pages, short paper, EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["yonatan bisk", "siva reddy", "john blitzer", "julia hockenmaier", "mark steedman"], "accepted": true, "id": "1609.09405"}, "pdf": {"name": "1609.09405.pdf", "metadata": {"source": "CRF", "title": "Evaluating Induced CCG Parsers on Grounded Semantic Parsing", "authors": ["Yonatan Bisk", "Siva Reddy", "John Blitzer", "Julia Hockenmaier", "Mark Steedman"], "emails": ["ybisk@isi.edu,", "siva.reddy@ed.ac.uk,", "blitzer@google.com,", "juliahmr@illinois.edu,", "steedman@inf.ed.ac.uk,"], "sections": [{"heading": "1 Introduction", "text": "We have seen significant progress in unattended grammar induction in recent years (Carroll and Charniak, 1992; Yuret, 1998; Klein and Manning, 2004; Spitkovsky et al., 2010; Garrette et al., 2015; Bisk and Hockenmaier, 2015), but how useful are unattended syntactic parsers for downstream NLP tasks? What phenomena can they capture, and where would additional comments be needed? Instead of standard intrinsic assessments - which depend heavily on the gold bank's respective annotation styles - we are investigating the usefulness of unattended and poorly supervised parsers for semantics. We are conducting an extrinsic evaluation of unattended and poorly supervised CCG parsers on a grounded semantic parser task that sheds light on the extent to which these systems acquire semantic information."}, {"heading": "2 CCG Intrinsic Evaluations", "text": "CCG (Steedman, 2000) is a lexicalized formalism in which words are assigned syntactic types, also known as supertags, encoding sub-categorization information. Consider the sentence Google acquired in 2014 and its CCG derivatives shown in Figure 1. In (a) and (b), the supertag of acquired (S\\ NP) / NP indicates that it has two arguments, and the 2014 preposition pass is an addendum, whereas in (c) the supertag (((S\\ NP) / PP) / NP indicates three acquired arguments, including the preposition pass. In (a) and (b), the derivative form differs from in depending on the supertag. If they are formed on marked tree branches, (a) is preferred. However, it should be noted that all of these derivatives may lead to the same semantics (e.g. the logical form of equation 1)."}, {"heading": "3 Our Proposed Evaluation", "text": "The above syntax-based evaluation metrics hide the real performance differences and their impact on downstream tasks. Here, we propose an extrinsic evaluation in which we evaluate our ability to convert sentences into freebase logical forms based on CCG derivatives. Our motivation is that most sentences can only have a single realization in freebase, and any derivative that could lead to this finding is potentially a correct derivative. For example, the freebase logical form is shown for the example sentence in Figure 1 below, and none of its derivatives is penalized if it can lead to this logical form.The employment (e, GOOGLE) companies acquired (e, NEST) date (e, 2014) and none of their derivatives are taken into consideration if they could lead to this logical form."}, {"heading": "4 Sentences to Freebase Logical Forms", "text": "CCG provides a clean interface between syntax and semantics, i.e. each argument of a syntactic category of words corresponds to an argument of the lambda expression defining its semantic interpretation (e.g. the lambda expression corresponding to the category (S\\ NP) / NP of the acquired verb can be constructed by the composition of word level lambda expressions after the syntactic derivative (Bos et al., 2004). In Figure 2 we show two syntactical derivatives for the same sentence, and the corresponding logical form for the complete sentence can be constructed by the composition of word level lambda expressions after the syntactic derivative (Bos et al., 2004)."}, {"heading": "5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Training and Evaluation Datasets", "text": "Our data set SPADES (Semantic PArsing of DEclarative Sentences) has been constructed based on the declarative sentences collected by Reddy et al. (2014) from CLUEWEB09 (Gabrilovich et al., 2013) based on the following limitations: 1) There is at least a one-to-one match between freebase diagrams and freebase logical forms. 3 Please refer to Section 4.3 of Reddy et al. (2016) for details. An isomorphic freebase diagram for non-rounded representation of the input set; 2) There are no variable nodes in the non-rounded diagram (e.g. Google has acquired a company that is discarded while Google has selected the company Nest). We divide this data into Training (85%), Development (5%) and Testing (10%). Unlike execution, we insert empty slots into these sentences by randomly removing one unit, while our SPES data is directly bound to the system (other year our SPES can be found at http: / www.faces.it / is a set of this and http: / www.face.com."}, {"heading": "5.2 Our Models", "text": "For the UNSUPERVISED scenario, we use the Bisk and Hockenmaier parser (2015), which uses a small set of universal rules to automatically trigger and weight a large set of lexical categories. In the UNSUPERVISED scenario, we examine two options - SEMI-SUPERVISED-WORD and SEMI-SUPERVISEDPOS. We use Bisk et al. in both scenarios, but we restrict its lexicon manually rather than reinventing it from scratch. In the former, we restrict the top 200 words in English so that they only appear in the CCG categories, which account for 95% of the occurrence of a word in Section 22 of the WSJ / CCGbank. In the latter, we restrict the POS tags and restrict them to words instead. For the SUPERVISED scenario, we use EasyCCG (Lewis and Steedman, 2014), in which CCSCCJ / CCGbank we learn a set of two very competitive words, similar to the one we learn from the other."}, {"heading": "5.3 Results and Discussion", "text": "To highlight the differences, we present section 23, in which we analyze the performance of our four models (Table 2). Dependency performance is evaluated using both the simplified formula of Bisk and Hockenmaier (2015) and the formula Undirected Unlabeled F1. Although the monitored parser performs almost twice as well as the semi-monitored parsers of CCGbank LF1 (53 vs 84), we see a comparatively small gain in performance in our semantic evaluation (43 vs 46). It is interesting that such weakly monitored models are able to achieve more than 90% of the performance of a fully monitored parser. To investigate this further, we break down the semantic performance of all our models by the number of units in a set. Each set indicates two, three or four units, one of which is omitted for prediction."}, {"heading": "5.4 The Benefits of Annotation", "text": "The performance of SEMI-SUPERVISED-POS and SEMI-SUPERVISED-WORD suggests that, when resources are scarce, it is advantageous to create even a small lexicon of CCG categories. We analyze this further in Figure 3. Here, we show how performance varies depending on the number of lexicon types labeled. Our values range from 0 to 1000 lexicon types. We see syntactical improvements of 16pts and seman Table 1 Annotated Words Syntax Semantics 0 37.1 37.3 100 48.49 40.9 200 53.5 43.2 500 53.36 42.41000 49.87 42.41tic gains of 6pts with 200 words before performance deteriorates. It is possible that increasing comments only benefit fully monitored models. Finally, when calculating the most common lexicon types, we found a performance decline of 3pt in restricting commuters to the category (they are usually in our section of knowledge)."}, {"heading": "5.5 Common Errors", "text": "Bisk and Hockenmaier (2015) conducted an in-depth analysis of the types of categories that were learned from their models and used correctly (the same models as this paper) and based their analysis on a syntactical evaluation to CCGbank. Specifically, they found the most egregious \"semantic\" errors in the misuse of verb chains, possessives, and PP appendices (see Table 3 below). Now that we have access to a purely semantic evaluation, we can ask whether these errors exist here and how common they are. We do this analysis in two steps. First, we manually analyzed parasis for which the unmonitored model could not predict the correct semantics, but where the monitored parasis succeeded. The top of Table 3 presents several of the most common reasons for the failure. These errors were more mundane (e.g. the incorrect use of a conjunction) than parasis, as parasis, as parasis, as parasis, as parasis, as parasis, as parasis, or as parasis, or as we have found the most common reasons for the failure."}, {"heading": "6 Conclusion", "text": "Our goal in this paper was to present the first semantic evaluation of induced grammars in order to better understand their benefits and strengths. We demonstrated that induced grammars learn a more semantically useful structure than a bag-of-words model. Furthermore, we demonstrated how minimal syntactic monitoring can bring significant benefits in semantic evaluation. In our ongoing work, we explore the creation of a syntax semantics loop in which each benefits the other without the human being (annotation) being in the loop."}, {"heading": "Acknowledgments", "text": "This work is based in part on work done when the first and second authors were interns at Google, and on work supported by the NSF 1053856 Scholarship to JH and a Google PhD Fellowship to SR."}], "references": [{"title": "Semantic parsing on Freebase from question-answer pairs", "author": ["Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1533\u20131544, Seattle, Washington,", "citeRegEx": "Berant et al\\.,? 2013", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "An HDP Model for Inducing Combinatory Categorial Grammars", "author": ["Yonatan Bisk", "Julia Hockenmaier."], "venue": "Transactions of the Association for Computational Linguistics, pages 75\u201388.", "citeRegEx": "Bisk and Hockenmaier.,? 2013", "shortCiteRegEx": "Bisk and Hockenmaier.", "year": 2013}, {"title": "Probing the linguistic strengths and limitations of unsupervised grammar induction", "author": ["Yonatan Bisk", "Julia Hockenmaier."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, Beijing,China, July.", "citeRegEx": "Bisk and Hockenmaier.,? 2015", "shortCiteRegEx": "Bisk and Hockenmaier.", "year": 2015}, {"title": "Wide-coverage semantic representations from a CCG parser", "author": ["Johan Bos", "Stephen Clark", "Mark Steedman", "James R Curran", "Julia Hockenmaier."], "venue": "Proceedings of the 20th international conference on Computational Linguistics, page 1240.", "citeRegEx": "Bos et al\\.,? 2004", "shortCiteRegEx": "Bos et al\\.", "year": 2004}, {"title": "Semantic parsing freebase: Towards open-domain semantic parsing", "author": ["Qingqing Cai", "Alexander Yates."], "venue": "Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic", "citeRegEx": "Cai and Yates.,? 2013", "shortCiteRegEx": "Cai and Yates.", "year": 2013}, {"title": "Two Experiments on Learning Probabilistic Dependency Grammars from Corpora", "author": ["Glenn Carroll", "Eugene Charniak."], "venue": "Working Notes of the Workshop Statistically-Based NLP Techniques, pages 1\u201315, March.", "citeRegEx": "Carroll and Charniak.,? 1992", "shortCiteRegEx": "Carroll and Charniak.", "year": 1992}, {"title": "FACC1: Freebase annotation of ClueWeb corpora, Version 1 (Release date 2013-06-26, Format version 1, Correction level", "author": ["Evgeniy Gabrilovich", "Michael Ringgaard", "Amarnag Subramanya"], "venue": null, "citeRegEx": "Gabrilovich et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gabrilovich et al\\.", "year": 2013}, {"title": "Weakly-Supervised Grammar-Informed Bayesian CCG Parser Learning", "author": ["Dan Garrette", "Chris Dyer", "Jason Baldridge", "Noah A Smith."], "venue": "Proceedings of the Association for the Advancement of Artificial Intelligence.", "citeRegEx": "Garrette et al\\.,? 2015", "shortCiteRegEx": "Garrette et al\\.", "year": 2015}, {"title": "Teaching machines to read and comprehend", "author": ["Karl Moritz Hermann", "Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom."], "venue": "Advances in Neural Information Processing Systems 28, pages 1693\u20131701.", "citeRegEx": "Hermann et al\\.,? 2015", "shortCiteRegEx": "Hermann et al\\.", "year": 2015}, {"title": "CorpusBased Induction of Syntactic Structure: Models of Dependency and Constituency", "author": ["Dan Klein", "Christopher D Manning."], "venue": "Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL\u201904), Main Volume, pages 478\u2013485,", "citeRegEx": "Klein and Manning.,? 2004", "shortCiteRegEx": "Klein and Manning.", "year": 2004}, {"title": "A* CCG Parsing with a Supertag-factored Model", "author": ["Mike Lewis", "Mark Steedman."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 990\u20131000, Doha, Qatar, October.", "citeRegEx": "Lewis and Steedman.,? 2014", "shortCiteRegEx": "Lewis and Steedman.", "year": 2014}, {"title": "Large-scale Semantic Parsing without QuestionAnswer Pairs", "author": ["Siva Reddy", "Mirella Lapata", "Mark Steedman."], "venue": "Transactions of the Association for Computational Linguistics, pages 1\u201316, June.", "citeRegEx": "Reddy et al\\.,? 2014", "shortCiteRegEx": "Reddy et al\\.", "year": 2014}, {"title": "Transforming Dependency Structures to Logical Forms for Semantic Parsing", "author": ["Siva Reddy", "Oscar T\u00e4ckstr\u00f6m", "Michael Collins", "Tom Kwiatkowski", "Dipanjan Das", "Mark Steedman", "Mirella Lapata."], "venue": "Transactions of the Association for Computational Lin-", "citeRegEx": "Reddy et al\\.,? 2016", "shortCiteRegEx": "Reddy et al\\.", "year": 2016}, {"title": "From Baby Steps to Leapfrog: How \u201cLess is More\u201d in Unsupervised Dependency Parsing", "author": ["Valentin I Spitkovsky", "Hiyan Alshawi", "Daniel Jurafsky."], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association", "citeRegEx": "Spitkovsky et al\\.,? 2010", "shortCiteRegEx": "Spitkovsky et al\\.", "year": 2010}, {"title": "The Syntactic Process", "author": ["Mark Steedman."], "venue": "The MIT Press, September.", "citeRegEx": "Steedman.,? 2000", "shortCiteRegEx": "Steedman.", "year": 2000}, {"title": "Discovery of Linguistic Relations Using Lexical Attraction", "author": ["Deniz Yuret."], "venue": "Ph.D. thesis, Massachusetts Institute of Technology.", "citeRegEx": "Yuret.,? 1998", "shortCiteRegEx": "Yuret.", "year": 1998}, {"title": "Computational approaches to sentence completion", "author": ["Geoffrey Zweig", "John C. Platt", "Christopher Meek", "Christopher J.C. Burges", "Ainur Yessenalina", "Qiang Liu."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1:", "citeRegEx": "Zweig et al\\.,? 2012", "shortCiteRegEx": "Zweig et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 5, "context": "The past several years have seen significant progress in unsupervised grammar induction (Carroll and Charniak, 1992; Yuret, 1998; Klein and Manning, 2004; Spitkovsky et al., 2010; Garrette et al., 2015; Bisk and Hockenmaier, 2015).", "startOffset": 88, "endOffset": 230}, {"referenceID": 15, "context": "The past several years have seen significant progress in unsupervised grammar induction (Carroll and Charniak, 1992; Yuret, 1998; Klein and Manning, 2004; Spitkovsky et al., 2010; Garrette et al., 2015; Bisk and Hockenmaier, 2015).", "startOffset": 88, "endOffset": 230}, {"referenceID": 9, "context": "The past several years have seen significant progress in unsupervised grammar induction (Carroll and Charniak, 1992; Yuret, 1998; Klein and Manning, 2004; Spitkovsky et al., 2010; Garrette et al., 2015; Bisk and Hockenmaier, 2015).", "startOffset": 88, "endOffset": 230}, {"referenceID": 13, "context": "The past several years have seen significant progress in unsupervised grammar induction (Carroll and Charniak, 1992; Yuret, 1998; Klein and Manning, 2004; Spitkovsky et al., 2010; Garrette et al., 2015; Bisk and Hockenmaier, 2015).", "startOffset": 88, "endOffset": 230}, {"referenceID": 7, "context": "The past several years have seen significant progress in unsupervised grammar induction (Carroll and Charniak, 1992; Yuret, 1998; Klein and Manning, 2004; Spitkovsky et al., 2010; Garrette et al., 2015; Bisk and Hockenmaier, 2015).", "startOffset": 88, "endOffset": 230}, {"referenceID": 2, "context": "The past several years have seen significant progress in unsupervised grammar induction (Carroll and Charniak, 1992; Yuret, 1998; Klein and Manning, 2004; Spitkovsky et al., 2010; Garrette et al., 2015; Bisk and Hockenmaier, 2015).", "startOffset": 88, "endOffset": 230}, {"referenceID": 14, "context": "CCG (Steedman, 2000) is a lexicalized formalism in which words are assigned syntactic types, also known as supertags, encoding subcategorization information.", "startOffset": 4, "endOffset": 20}, {"referenceID": 4, "context": "But such datasets do not exist in the Freebase semantic parsing literature (Cai and Yates, 2013; Berant et al., 2013).", "startOffset": 75, "endOffset": 117}, {"referenceID": 0, "context": "But such datasets do not exist in the Freebase semantic parsing literature (Cai and Yates, 2013; Berant et al., 2013).", "startOffset": 75, "endOffset": 117}, {"referenceID": 1, "context": "Please see Bisk and Hockenmaier (2013) for more details.", "startOffset": 11, "endOffset": 39}, {"referenceID": 3, "context": "acquired(e) \u2227 f(x) \u2227 g(y) \u2227 arg1(e, y)\u2227arg2(e, x)), and the logical form for the complete sentence can be constructed by composing word level lambda expressions following the syntactic derivation (Bos et al., 2004).", "startOffset": 196, "endOffset": 214}, {"referenceID": 11, "context": "In Figure 2 we show two syntactic derivations for the same sentence, and the corresponding logical forms and equivalent graph representations derived by GRAPHPARSER (Reddy et al., 2014).", "startOffset": 165, "endOffset": 185}, {"referenceID": 11, "context": "2 Like Reddy et al. (2014), we treat this problem as a graph matching problem.", "startOffset": 7, "endOffset": 27}, {"referenceID": 6, "context": "(2014) from CLUEWEB09 (Gabrilovich et al., 2013) based on the following constraints: 1) There exists at least", "startOffset": 22, "endOffset": 48}, {"referenceID": 10, "context": "Our dataset SPADES (Semantic PArsing of DEclarative Sentences) is constructed from the declarative sentences collected by Reddy et al. (2014) from CLUEWEB09 (Gabrilovich et al.", "startOffset": 122, "endOffset": 142}, {"referenceID": 11, "context": "3 of Reddy et al. (2016) for details.", "startOffset": 5, "endOffset": 25}, {"referenceID": 16, "context": "There has been other recent interest in similar datasets for sentence completion (Zweig et al., 2012) and machine reading (Hermann et al.", "startOffset": 81, "endOffset": 101}, {"referenceID": 8, "context": ", 2012) and machine reading (Hermann et al., 2015), but unlike other corpora our data is tied directly to Freebase and requires the execution of a semantic parse to correctly predict the missing entity.", "startOffset": 28, "endOffset": 50}, {"referenceID": 1, "context": "For the UNSUPERVISED scenario, we use Bisk and Hockenmaier (2015)\u2019s parser which", "startOffset": 38, "endOffset": 66}, {"referenceID": 10, "context": "For the SUPERVISED scenario, we use EasyCCG (Lewis and Steedman, 2014) trained on CCGbank.", "startOffset": 44, "endOffset": 70}, {"referenceID": 1, "context": "Dependency performance is evaluated on both the simplified labeled F1 of Bisk and Hockenmaier (2015) and Undirected Unlabeled F1.", "startOffset": 73, "endOffset": 101}, {"referenceID": 1, "context": "Bisk and Hockenmaier (2015) found that their unsupervised parser made mistakes on many very simple categories.", "startOffset": 0, "endOffset": 28}], "year": 2017, "abstractText": "We compare the effectiveness of four different syntactic CCG parsers for a semantic slotfilling task to explore how much syntactic supervision is required for downstream semantic analysis. This extrinsic, task-based evaluation also provides a unique window into the semantics captured (or missed) by unsupervised grammar induction systems.", "creator": "LaTeX with hyperref package"}}}