{"id": "1609.09869", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Sep-2016", "title": "Structured Inference Networks for Nonlinear State Space Models", "abstract": "Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood.", "histories": [["v1", "Fri, 30 Sep 2016 19:53:11 GMT  (2875kb,D)", "http://arxiv.org/abs/1609.09869v1", "Main paper: 13 pages, 12 Figures"], ["v2", "Mon, 5 Dec 2016 19:10:10 GMT  (996kb,D)", "http://arxiv.org/abs/1609.09869v2", "To appear in the Thirty-First AAAI Conference on Artificial Intelligence, February 2017, 13 pages, 11 figures with supplement, changed to AAAI formatting style, added references"]], "COMMENTS": "Main paper: 13 pages, 12 Figures", "reviews": [], "SUBJECTS": "stat.ML cs.AI cs.LG", "authors": ["rahul g krishnan", "uri shalit", "david sontag"], "accepted": true, "id": "1609.09869"}, "pdf": {"name": "1609.09869.pdf", "metadata": {"source": "CRF", "title": "Structured Inference Networks for Nonlinear State Space Models", "authors": ["Rahul G. Krishnan", "Uri Shalit", "David Sontag"], "emails": ["dsontag}@cs.nyu.edu"], "sections": [{"heading": "1. Introduction", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they are able to live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they, in which they, in which they live, in fact, in which they are"}, {"heading": "2. Background", "text": "Gaussian State Space Models: We consider both inference and learning in a class of latent variable models given by: zt \u0445 N (G\u03b1 \u2212 1, \u2206 t), S\u03b2 (zt \u2212 1, \u2206 t))) (transition) xt. The multivariate observations xt are distributed according to a distribution (e.g., independent Bernoullis if the data are binary) whose parameters are a function of the corresponding latent state zt. Collectively, we refer to the parameters of the generative model. Equation. 1 subsumes a large family of linear and non-linear Gaussian State Space Models."}, {"heading": "3. A Factorized Variational Lower Bound", "text": "We use stochastic back-propagation to learn generative models given by Eq. 1, according to the graphic model in Figure 1. Our understanding is that, for the purpose of inference, we can use the Markov properties of the generative model to guide us in deriving a structured approximation to the posterior plane. (3) This factorization follows conditional dependencies in the model and is detailed in Appendix C. We directly imitate the structure of the posterior model with the following factorization: q\u03c6 (~ z | x) = T = 1 q\u03c6. (zt) This factorization follows conditional dependencies in the model and is detailed in Appendix C. We imitate the structure of the posterior model with the following factorizations."}, {"heading": "4. Structured Inference Networks", "text": "This parameterization can generally not be considered equivalent to the various decisions for consequence networks that we evaluate. The Deep Kalman Smoother, DKS, corresponds exactly to the functional form that is proposed by Eq. 3, and is our proposed approximation of variation. The DKS smoothes information from the past and the future (xt). xT) to approximate posterior.We also evaluate other possibilities for the variation models (inference networks) q2: two are midfield models (MF) and two structured models (they will). We distinguish them based on information."}, {"heading": "5. Deep Markov Models", "text": "Following Raiko et al. (2006), we apply the ideas of deep learning to non-linear \u03b2-units of the continuous state space. Where the transition and the emission function have an unknown functional form, we parameterise G\u03b1, S\u03b2, F\u0442 of Eq. 1 with deep neural networks. See Figure 1 (right) for an illustration of the graphic model. Emission function: We parameterise the emission function using a two-layer MLP (multi-layer perceptron), MLP (x, NL1, NL2) = NL2 (W2NL1 (W1x + b1) + b2), where NL \u2212 \u2212 \u2212 \u2212 units parameterise the non-linearity such as ReLU, Sigmoid or Tanh units, which are applied elementally to the input vector. For modelling binary data, we are uniform (zt) = Sigmoid (WeLLid) = Sigmoid (WeLP), WeLP)."}, {"heading": "6. Evaluation", "text": "Our models and learning algorithms are implemented in Theano (Theano Development Team, 2016). We use Adam (Kingma and Ba, 2015) with a learning rate of 0.0008 to train DMM. Our code can be found at https: / / github.com / clinicalml / structuredinference."}, {"heading": "6.1 Datasets", "text": "Synthetic: We look at simple linear and non-linear GSSMs. We compare our results using the training value of variation-bound L (~ x; (\u03b8, \u03c6)) (Eq. 6) and RMSE = 1 N \u2211 N i = 1 T \u2211 T t = 1 [\u00b5\u03c6 (xi, t) \u2212 z \u0432 i, t] 2, where z \u0445 corresponds to the true underlying zs that the data generated. Polyphonic music: We train DMMs using polyphonic music data (Boulanger-lewandowski et al., 2012). One instance in the sequence includes an 88-dimensional binary vector corresponding to the annotations of a piano."}, {"heading": "6.2 Compiling Exact Inference", "text": "For this experiment, we optimize Eq. 6 over \u03c6, while \u03b8 is fixed on a synthetic distribution given by a one-dimensional GSSM. We compare the results obtained by various approximations with those obtained by Kalman smoothing (Duckworth, 2016), which performs the exact conclusions. Fig. 4 shows our results. The proposed DKS (i.e. ST-R) and ST-LR exceed the variation method MF-L, which considers only information from the past. However, MF-LR is often able to catch up with RMSE, emphasizing the role that information from the future plays in performing posterior inference, as is evident in the posterior factorization (3)."}, {"heading": "6.3 Inference for Parameter Estimation", "text": "Similarly, on synthetic nonlinear data sets (see Appendix E), we find that the structured variation approximations are more likely to generalize invisible data, while they can draw conclusions using a smoothed unscented Kalman filter (Wan et al., 2000). Finally, Figure 3 illustrates a toy example where we perform parameter estimates in a synthetic, two-dimensional, nonlinear GSSM.0 5 10 15 20 25 10 50 5 10 15 20 25 6 4 20246."}, {"heading": "6.4 Mean-Field vs Structured Inference", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.5 A Generalization of the DMM", "text": "In order to demonstrate the effectiveness of our inference algorithm to model variants beyond the first order Markov models, we extend the DMM by adding edges from xt \u2212 1 to zt and from xt \u2212 1 to xt. We refer to the resulting generative model as DMM augmented (Aug.). Extending the DMM by additional edges creates a richer class of generative models. The baselines we compare in Table 3 also have more complex generative models than the DMM. STORN has edges from xt \u2212 1 to zt given by the reciprocal update, and TSBN has edges from xt \u2212 1 to zt and from xt \u2212 1 to xt. HMSBN exhibits the same structural properties as the DMM, but is learned using a simpler inference network. We show that DKS can be used as an inference for a more complex generative model than DMM, while achieving gains at the given probability."}, {"heading": "6.6 EHR Patient Data", "text": "These models could, for example, be used to understand which drugs work best, for whom. In this section, we show that the DMM, which is based on EHR data, can be used for just such an application. We highlight some of the challenges we overcome in order to perform the learning in these data: \u2022 We use the temporally different drug prescriptions for each patient. We expand the DMM transition phenomenon as an example. N (G\u03b1-1, ut-1, \u2206 t), S\u03b2 (zt-1, ut-t) (cf.), where we have a binary indicator vector of eight diabetic drugs including metformin and insulin. Metformin is the most commonly prescribed first line anti-diabetic drugs. \u2022 A subset of observations (such as A1C and glucose values) is often missing in the data we do not understand."}, {"heading": "7. Discussion", "text": "We present a general algorithm for scalable learning in a rich family of latent variable models for time series data. The spatial complexity of our learning algorithm does not depend on the sequence length T nor on the training set size N, which offers huge savings compared to classical variable inference methods. As we use RNNs only in the inference network, it should be possible to further increase their capacity and condition to various modalities that could be relevant for posterior inferences without having to revise the data. Finally, we presented an application of the learning algorithm for modelling longitudinal patient data in electronic medical records and derived treatment effects."}, {"heading": "Acknowledgements", "text": "The Tesla K40 used for this research was donated by NVIDIA Corporation. The authors are grateful for the support of the DARPA Probabilistic Programming for Advanced Machine Learning (PPAML) Program under AFRL Prime Contract Number FA8750-14-C-0005, ONR # N00014-131-0646 and NSF CAREER Award # 1350965. We thank the anonymous critics for their comments."}, {"heading": "Appendix A. Lower Bound on the Likelihood of data", "text": "We can derive the deviation from the probability L (~ x; \u03b8, \u03c6) q = q (q = q) as follows: The deviation (~ x) from the deviation from the deviation from the deviation from the deviation from the deviation from the deviation. The deviation from the deviation from the deviation from the deviation from the deviation is determined by the deviation from the deviation. The deviation from the deviation from the deviation from the deviation from the deviation from the deviation from the deviation is determined by the deviation from the deviation from the deviation. The deviation from the deviation from the deviation from the deviation from the deviation from the deviation from the deviation is determined by the deviation from the deviation from the deviation from the deviation from the deviation from the deviation. The deviation from the deviation from the deviation from the deviation from the deviation from the deviation from the deviation from the deviation is determined by the deviation from the deviation from the deviation from the deviation from the deviation from the deviation from the deviation."}, {"heading": "Appendix B. KL divergence between Prior and Posterior", "text": "The maximum probability that we learn requires that we calculate the following: KL (z1,., zT) = closed (zT) | p (z1,., zT) = p (z1,.,. \u2212 \u2212 \u2212 p (z1)) + T \u2212 p = 2 E q (zt \u2212 1) [KL (zt | qt) | p (zt \u2212 1)] (10) The KL divergence between two multivariate Gaussians q, p with respective averages and covariances \u00b5q, q, \u00b5p, p can be written as: KL (q \u2212 1)."}, {"heading": "Appendix C. Learning Algorithm", "text": "Algorithm 1 provides an overview of the learning algorithm. We outline the algorithm for a mini-batch of size one, but in practice, the gradients are averaged using stochastically sampled mini-batches of the training set to mitigate the effects of using a single sample (K = 1) during training to estimate expectations and corresponding gradients. We take a gradient step in \u03b8 and \u03c6, typically with an adaptive learning rate such as Kingma and Ba (2015). For the results in Table 3 of the main paper, as in (Kaae S\u00f8nderby et al., 2016), we found that the KL divergence in the limit of variation (L (~ x; (\u03b8, \u03c6))) from 0 to 1 has better results over 5000 parameter updates.Factorization of the posterior distribution We use the independence statements implied by the graphic model in Figure 1 of the main paper to determine ~ x (or \u2212 p) that the result is true."}, {"heading": "Appendix D. Polyphonic Music Generation", "text": "Experimental setup: For the polyphonic experiments we used double-layered MLPs in the emission and (gated) transition function. The hidden dimension was set to 100 for the emission distribution and 200 for the transition function. Typically, we used an RNN size of one of {400, 600} and a latent dimension of size 100. Samples: Figure 6 shows the mean probability of samples from the generative model of trained JSB Chorales (Boulanger-lewandowski et al., 2012). MP3 songs corresponding to two different samples from the best DMM model learned on each of the four polyphonic data sets can be used in the code repository. Experiments with NADE: We also experiment with neural autoregressive density testimators (NADE) (Larochelle and Murray, 2011) in the emission distribution for DMM-eye-NADE and refer to it as a PiMM-Aug state we see the NADE in the NADE-MADE table."}, {"heading": "Appendix E. Experimental Results on Synthetic Data", "text": "Experimental Setup: We used an RNN size of 40 in the inference networks used for the synthetic experiments. Linear SSMs: Figure 7 (N = 500, T = 25) shows the performance of inference networks with the same setup as in the main work, only now with data held up to evaluate the RMSE and the upper limit. We find that the results match those in the training set and that the inference networks, especially the structured ones, are able to generalize compiled inferences. Non-linear SSMs: Figure 8 looks at learning inference networks on a synthetic nonlinear dynamic system (N = 5000, T = 25). We find again that inference networks that match the posterior allow both faster convergence and better education (and validation). Visualizing inferences: In Figure 9 we visualize the posteriors obtained by estimating the inferential networks."}, {"heading": "Appendix F. Generative Models of Medical Data", "text": "This year it is more than ever before."}], "references": [{"title": "Black box variational inference for state space models", "author": ["Evan Archer", "Il Memming Park", "Lars Buesing", "John Cunningham", "Liam Paninski"], "venue": "arXiv preprint arXiv:1511.07367,", "citeRegEx": "Archer et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Archer et al\\.", "year": 2015}, {"title": "Learning stochastic recurrent networks", "author": ["Justin Bayer", "Christian Osendorfer"], "venue": "arXiv preprint arXiv:1411.7610,", "citeRegEx": "Bayer and Osendorfer.,? \\Q2014\\E", "shortCiteRegEx": "Bayer and Osendorfer.", "year": 2014}, {"title": "Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription", "author": ["Nicolas Boulanger-lewandowski", "Yoshua Bengio", "Pascal Vincent"], "venue": "In ICML,", "citeRegEx": "Boulanger.lewandowski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Boulanger.lewandowski et al\\.", "year": 2012}, {"title": "Fisher scoring and a mixture of modes approach for approximate inference and learning in nonlinear state space models", "author": ["Thomas Briegel", "Volker Tresp"], "venue": "In NIPS,", "citeRegEx": "Briegel and Tresp.,? \\Q1999\\E", "shortCiteRegEx": "Briegel and Tresp.", "year": 1999}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1412.3555,", "citeRegEx": "Chung et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "A recurrent latent variable model for sequential data", "author": ["Junyoung Chung", "Kyle Kastner", "Laurent Dinh", "Kratarth Goel", "Aaron Courville", "Yoshua Bengio"], "venue": "In NIPS,", "citeRegEx": "Chung et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2015}, {"title": "Kalman filter, kalman smoother, and em library for python", "author": ["Daniel Duckworth"], "venue": "https://pykalman. github.io/,", "citeRegEx": "Duckworth.,? \\Q2016\\E", "shortCiteRegEx": "Duckworth.", "year": 2016}, {"title": "Variational recurrent auto-encoders", "author": ["Otto Fabius", "Joost R van Amersfoort"], "venue": null, "citeRegEx": "Fabius and Amersfoort.,? \\Q2014\\E", "shortCiteRegEx": "Fabius and Amersfoort.", "year": 2014}, {"title": "Deep temporal sigmoid belief networks for sequence modeling", "author": ["Zhe Gan", "Chunyuan Li", "Ricardo Henao", "David E Carlson", "Lawrence Carin"], "venue": "In NIPS,", "citeRegEx": "Gan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gan et al\\.", "year": 2015}, {"title": "DRAW: A recurrent neural network for image generation", "author": ["Karol Gregor", "Ivo Danihelka", "Alex Graves", "Danilo Jimenez Rezende", "Daan Wierstra"], "venue": "In ICML,", "citeRegEx": "Gregor et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2015}, {"title": "Neural adaptive sequential monte carlo", "author": ["Shixiang Gu", "Zoubin Ghahramani", "Richard E Turner"], "venue": "In NIPS,", "citeRegEx": "Gu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gu et al\\.", "year": 2015}, {"title": "The\" wake-sleep\" algorithm for unsupervised neural networks", "author": ["Geoffrey E Hinton", "Peter Dayan", "Brendan J Frey", "Radford M Neal"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 1995}, {"title": "Structured VAEs: Composing probabilistic graphical models and variational autoencoders", "author": ["Matthew J Johnson", "David Duvenaud", "Alexander B Wiltschko", "Sandeep R Datta", "Ryan P Adams"], "venue": "arXiv preprint arXiv:1603.06277,", "citeRegEx": "Johnson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2016}, {"title": "How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks", "author": ["C. Kaae S\u00f8nderby", "T. Raiko", "L. Maal\u00f8e", "S. Kaae S\u00f8nderby", "O. Winther"], "venue": null, "citeRegEx": "S\u00f8nderby et al\\.,? \\Q2016\\E", "shortCiteRegEx": "S\u00f8nderby et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba"], "venue": "In ICLR,", "citeRegEx": "Kingma and Ba.,? \\Q2015\\E", "shortCiteRegEx": "Kingma and Ba.", "year": 2015}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "In ICLR,", "citeRegEx": "Kingma and Welling.,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2014}, {"title": "Deep kalman filters", "author": ["Rahul G Krishnan", "Uri Shalit", "David Sontag"], "venue": "arXiv preprint arXiv:1511.05121,", "citeRegEx": "Krishnan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Krishnan et al\\.", "year": 2015}, {"title": "The neural autoregressive distribution estimator", "author": ["Hugo Larochelle", "Iain Murray"], "venue": "In AISTATS,", "citeRegEx": "Larochelle and Murray.,? \\Q2011\\E", "shortCiteRegEx": "Larochelle and Murray.", "year": 2011}, {"title": "Neural variational inference and learning in belief networks", "author": ["Andriy Mnih", "Karol Gregor"], "venue": "In ICML,", "citeRegEx": "Mnih and Gregor.,? \\Q2014\\E", "shortCiteRegEx": "Mnih and Gregor.", "year": 2014}, {"title": "Variational bayesian learning of nonlinear hidden state-space models for model predictive control", "author": ["Tapani Raiko", "Matti Tornio"], "venue": null, "citeRegEx": "Raiko and Tornio.,? \\Q2009\\E", "shortCiteRegEx": "Raiko and Tornio.", "year": 2009}, {"title": "State inference in variational bayesian nonlinear state-space models", "author": ["Tapani Raiko", "Matti Tornio", "Antti Honkela", "Juha Karhunen"], "venue": "In International Conference on ICA and Signal Separation,", "citeRegEx": "Raiko et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Raiko et al\\.", "year": 2006}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Danilo J. Rezende", "Shakir Mohamed", "Daan Wierstra"], "venue": "In ICML,", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "An EM algorithm for identification of nonlinear dynamical systems", "author": ["Sam Roweis", "Zoubin Ghahramani"], "venue": null, "citeRegEx": "Roweis and Ghahramani.,? \\Q2000\\E", "shortCiteRegEx": "Roweis and Ghahramani.", "year": 2000}, {"title": "System identification of nonlinear state-space models", "author": ["Thomas B Sch\u00f6n", "Adrian Wills", "Brett Ninness"], "venue": null, "citeRegEx": "Sch\u00f6n et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Sch\u00f6n et al\\.", "year": 2011}, {"title": "An unsupervised ensemble learning method for nonlinear dynamic state-space models", "author": ["Harri Valpola", "Juha Karhunen"], "venue": "Neural computation,", "citeRegEx": "Valpola and Karhunen.,? \\Q2002\\E", "shortCiteRegEx": "Valpola and Karhunen.", "year": 2002}, {"title": "The unscented kalman filter for nonlinear estimation", "author": ["Eric Wan", "Ronell Van Der Merwe"], "venue": "In Adaptive Systems for Signal Processing, Communications, and Control Symposium", "citeRegEx": "Wan and Merwe,? \\Q2000\\E", "shortCiteRegEx": "Wan and Merwe", "year": 2000}, {"title": "Dual kalman filtering methods for nonlinear prediction, smoothing and estimation", "author": ["Eric A. Wan", "Alex T. Nelson"], "venue": "In NIPS,", "citeRegEx": "Wan and Nelson.,? \\Q1996\\E", "shortCiteRegEx": "Wan and Nelson.", "year": 1996}, {"title": "Embed to control: A locally linear latent dynamics model for control from raw images", "author": ["Manuel Watter", "Jost Tobias Springenberg", "Joschka Boedecker", "Martin Riedmiller"], "venue": "In NIPS,", "citeRegEx": "Watter et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Watter et al\\.", "year": 2015}, {"title": "For the results in Table 3 in the main paper, as in (Kaae S\u00f8nderby et al., 2016), we found annealing the KL divergence in the variational bound (L(~x; (\u03b8, \u03c6))) from 0 to 1 over 5000 parameter", "author": ["Kingma", "Ba"], "venue": null, "citeRegEx": "Kingma and Ba,? \\Q2015\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2015}], "referenceMentions": [{"referenceID": 26, "context": "dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Sch\u00f6n et al.", "startOffset": 28, "endOffset": 50}, {"referenceID": 3, "context": "dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Sch\u00f6n et al.", "startOffset": 77, "endOffset": 131}, {"referenceID": 22, "context": "dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Sch\u00f6n et al.", "startOffset": 77, "endOffset": 131}, {"referenceID": 23, "context": "dual extended Kalman filter (Wan and Nelson, 1996), expectation maximization (Briegel and Tresp, 1999; Roweis and Ghahramani, 2000) or particle filters (Sch\u00f6n et al., 2011).", "startOffset": 152, "endOffset": 172}, {"referenceID": 1, "context": "1 with edges from the observations xt to the latent states of the following time step zt+1, then the DMM can be seen to be similar to, though more restrictive than, stochastic RNNs (Bayer and Osendorfer, 2014) and variational RNNs (Chung et al.", "startOffset": 181, "endOffset": 209}, {"referenceID": 5, "context": "1 with edges from the observations xt to the latent states of the following time step zt+1, then the DMM can be seen to be similar to, though more restrictive than, stochastic RNNs (Bayer and Osendorfer, 2014) and variational RNNs (Chung et al., 2015).", "startOffset": 231, "endOffset": 251}, {"referenceID": 11, "context": "This idea was originally used in the wake-sleep algorithm for unsupervised learning (Hinton et al., 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al.", "startOffset": 84, "endOffset": 105}, {"referenceID": 15, "context": ", 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al., 2014).", "startOffset": 107, "endOffset": 178}, {"referenceID": 18, "context": ", 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al., 2014).", "startOffset": 107, "endOffset": 178}, {"referenceID": 21, "context": ", 1995), and has since led to state-of-the-art results for unsupervised learning of deep generative models (Kingma and Welling, 2014; Mnih and Gregor, 2014; Rezende et al., 2014).", "startOffset": 107, "endOffset": 178}, {"referenceID": 5, "context": "By looking at the structure of the true posterior, we show both theoretically and empirically that inference for a latent state should be performed using information from its future, as opposed to recent work which performed inference using only information from the past (Chung et al., 2015; Gan et al., 2015; Gregor et al., 2015).", "startOffset": 272, "endOffset": 331}, {"referenceID": 8, "context": "By looking at the structure of the true posterior, we show both theoretically and empirically that inference for a latent state should be performed using information from its future, as opposed to recent work which performed inference using only information from the past (Chung et al., 2015; Gan et al., 2015; Gregor et al., 2015).", "startOffset": 272, "endOffset": 331}, {"referenceID": 9, "context": "By looking at the structure of the true posterior, we show both theoretically and empirically that inference for a latent state should be performed using information from its future, as opposed to recent work which performed inference using only information from the past (Chung et al., 2015; Gan et al., 2015; Gregor et al., 2015).", "startOffset": 272, "endOffset": 331}, {"referenceID": 19, "context": "Related Work: Learning GSSMs with MLPs for the transition distribution was considered by (Raiko and Tornio, 2009).", "startOffset": 89, "endOffset": 113}, {"referenceID": 24, "context": "They approximate the posterior with non-linear dynamic factor analysis (Valpola and Karhunen, 2002), which scales quadratically with the observed dimension and is impractical for large-scale learning.", "startOffset": 71, "endOffset": 99}, {"referenceID": 0, "context": "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks.", "startOffset": 0, "endOffset": 21}, {"referenceID": 0, "context": "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields.", "startOffset": 0, "endOffset": 149}, {"referenceID": 0, "context": "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables.", "startOffset": 0, "endOffset": 301}, {"referenceID": 0, "context": "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables.", "startOffset": 0, "endOffset": 338}, {"referenceID": 0, "context": "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables. Chung et al. (2015) apply a similar model to speech data, sharing parameters between the RNNs for the generative model and the inference network.", "startOffset": 0, "endOffset": 508}, {"referenceID": 0, "context": "Archer et al. (2015) propose using a block-diagonal Gaussian approximation to the posterior, parameterized by neural networks. Johnson et al. (2016) consider learning structured time-series models by approximating the posterior distribution with conditional random fields. Bayer and Osendorfer (2014) and Fabius and van Amersfoort (2014) create a stochastic variant of RNNs by making the hidden state of the RNN at every time step be a function of independently sampled latent variables. Chung et al. (2015) apply a similar model to speech data, sharing parameters between the RNNs for the generative model and the inference network. Gan et al. (2015) learn a model with", "startOffset": 0, "endOffset": 652}, {"referenceID": 16, "context": "This paper expands an earlier work (Krishnan et al. 2015).", "startOffset": 35, "endOffset": 57}, {"referenceID": 16, "context": "The current paper instantiates the inference scheme presented in (Krishnan et al., 2015) [Thm.", "startOffset": 65, "endOffset": 88}, {"referenceID": 4, "context": "discrete random variables, using a structured inference network that only considers information from the past, similar to Chung et al. (2015) and Gregor et al.", "startOffset": 122, "endOffset": 142}, {"referenceID": 4, "context": "discrete random variables, using a structured inference network that only considers information from the past, similar to Chung et al. (2015) and Gregor et al. (2015). In contrast to these works, we use information from the future within a structured inference network, which we show to be preferable both theoretically and practically.", "startOffset": 122, "endOffset": 167}, {"referenceID": 4, "context": "discrete random variables, using a structured inference network that only considers information from the past, similar to Chung et al. (2015) and Gregor et al. (2015). In contrast to these works, we use information from the future within a structured inference network, which we show to be preferable both theoretically and practically. Additionally, we systematically evaluate the impact of the different variational approximations on learning. Watter et al. (2015) construct a first-order Markov model using inference networks.", "startOffset": 122, "endOffset": 467}, {"referenceID": 11, "context": "The key technical innovation is the introduction of an inference network or recognition network (Hinton et al., 1995), a neural network which approximates the intractable posterior.", "startOffset": 96, "endOffset": 117}, {"referenceID": 15, "context": "Kingma and Welling (2014); Rezende et al.", "startOffset": 0, "endOffset": 26}, {"referenceID": 15, "context": "Kingma and Welling (2014); Rezende et al. (2014) use a neural net (with parameters \u03c6) to parameterize q\u03c6.", "startOffset": 0, "endOffset": 49}, {"referenceID": 15, "context": "We use stochastic backpropagation (Kingma and Welling, 2014; Rezende et al., 2014) for estimating the gradient w.", "startOffset": 34, "endOffset": 82}, {"referenceID": 21, "context": "We use stochastic backpropagation (Kingma and Welling, 2014; Rezende et al., 2014) for estimating the gradient w.", "startOffset": 34, "endOffset": 82}, {"referenceID": 4, "context": "This is in contrast to the variational bound obtained by Chung et al. (2015) in Eq.", "startOffset": 57, "endOffset": 77}, {"referenceID": 4, "context": "Gated Transition Function: Instead of MLPs, we use a gated transition function inspired by Gated Recurrent Units (Chung et al., 2014).", "startOffset": 113, "endOffset": 133}, {"referenceID": 18, "context": "Deep Markov Models Following Raiko et al. (2006), we apply the ideas of deep learning to non-linear continuous state space models.", "startOffset": 29, "endOffset": 49}, {"referenceID": 14, "context": "We use Adam (Kingma and Ba, 2015) with a learning rate of 0.", "startOffset": 12, "endOffset": 33}, {"referenceID": 2, "context": "Polyphonic Music: We train DMMs on polyphonic music data (Boulanger-lewandowski et al., 2012).", "startOffset": 57, "endOffset": 93}, {"referenceID": 8, "context": "This is an upper bound on the NLL, which facilitates comparison to RNNs; From inspecting the code for TSBN (Gan et al., 2015) we found that they report c = 1 N \u2211N i=1 1 Ti L(~x; \u03b8, \u03c6).", "startOffset": 107, "endOffset": 125}, {"referenceID": 6, "context": "We compare results obtained by the various approximations we propose to those obtained by Kalman smoothing (Duckworth, 2016) which performs exact inference.", "startOffset": 107, "endOffset": 124}, {"referenceID": 9, "context": "ST-L is a structured variational approximation that only considers information from the past and, up to implementation details, is comparable to the one used by Gregor et al. (2015). Comparing the negative log-likelihoods of the learned models, we see that the looseness in the variational bound (which we first observed in the synthetic setting in Fig.", "startOffset": 161, "endOffset": 182}, {"referenceID": 2, "context": "Table Legend: RNN (Boulanger-lewandowski et al., 2012), LV-RNN (Gu et al.", "startOffset": 18, "endOffset": 54}, {"referenceID": 10, "context": ", 2012), LV-RNN (Gu et al., 2015), STORN (Bayer and Osendorfer, 2014), TSBN, HMSBN (Gan et al.", "startOffset": 16, "endOffset": 33}, {"referenceID": 1, "context": ", 2015), STORN (Bayer and Osendorfer, 2014), TSBN, HMSBN (Gan et al.", "startOffset": 15, "endOffset": 43}, {"referenceID": 8, "context": ", 2015), STORN (Bayer and Osendorfer, 2014), TSBN, HMSBN (Gan et al., 2015).", "startOffset": 57, "endOffset": 75}], "year": 2016, "abstractText": "Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood.", "creator": "LaTeX with hyperref package"}}}