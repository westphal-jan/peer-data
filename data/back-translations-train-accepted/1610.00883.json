{"id": "1610.00883", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "4-Oct-2016", "title": "Are Word Embedding-based Features Useful for Sarcasm Detection?", "abstract": "This paper makes a simple increment to state-of-the-art in sarcasm detection research. Existing approaches are unable to capture subtle forms of context incongruity which lies at the heart of sarcasm. We explore if prior work can be enhanced using semantic similarity/discordance between word embeddings. We augment word embedding-based features to four feature sets reported in the past. We also experiment with four types of word embeddings. We observe an improvement in sarcasm detection, irrespective of the word embedding used or the original feature set to which our features are augmented. For example, this augmentation results in an improvement in F-score of around 4\\% for three out of these four feature sets, and a minor degradation in case of the fourth, when Word2Vec embeddings are used. Finally, a comparison of the four embeddings shows that Word2Vec and dependency weight-based features outperform LSA and GloVe, in terms of their benefit to sarcasm detection.", "histories": [["v1", "Tue, 4 Oct 2016 07:50:06 GMT  (23kb)", "http://arxiv.org/abs/1610.00883v1", "The paper will be presented at Conference on Empirical Methods in Natural Language Processing (EMNLP) 2016 in November 2016.this http URL"]], "COMMENTS": "The paper will be presented at Conference on Empirical Methods in Natural Language Processing (EMNLP) 2016 in November 2016.this http URL", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["aditya joshi", "vaibhav tripathi", "kevin patel", "pushpak bhattacharyya", "mark james carman"], "accepted": true, "id": "1610.00883"}, "pdf": {"name": "1610.00883.pdf", "metadata": {"source": "CRF", "title": "Are Word Embedding-based Features Useful for Sarcasm Detection?", "authors": ["Aditya Joshi", "Vaibhav Tripathi", "Kevin Patel", "Pushpak Bhattacharyya", "Mark Carman"], "emails": ["adityaj@cse.iitb.ac.in,", "kevin.patel@cse.iitb.ac.in,", "pb@cse.iitb.ac.in,", "mark.carman@monash.edu"], "sections": [{"heading": null, "text": "ar Xiv: 161 0.00 883v 1 [cs.C L] 4O ctThis work represents a simple increase in the state of research on sarcasm detection. Existing approaches are not able to capture subtle forms of context congruence underlying sarcasm. We are investigating whether previous work can be improved by semantic similarities / discordances between word embeddings. We are expanding word embeddings to include four traits reported in the past. We are also experimenting with four types of word embeddings. We are observing an improvement in the detection of sarcasm, regardless of the word used or the original trait set to which our traits are extended. For example, this extension leads to an improvement of the F score by about 4% for three of these four trait sets and a slight degradation in the case of the fourth when Word2Vec embeddings are used. Finally, a comparison of the four embeddings shows that W2c expresses its utility vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-vis-"}, {"heading": "1 Introduction", "text": "Sarcasm is a form of verbal irony aimed at expressing contempt or ridicule for a classic sentiment. Linguistic studies show that the notion of context congruence is at the heart of sarcasm (Ivanko and Pexman, 2003). A popular trend in automatic detection of sarcasm is the semi-supervised extraction of patterns that capture the underlying contextual congruences (Davidov et al., 2010; Joshi et al., 2015; Riloff et al., 2013). Techniques for extracting these patterns, however, rely on sentimental words and may capture unnuanced forms of sarcasm. Consider the phrase \"With a sense of humor like this, one could live a life as a garbage man across the country.\" The speaker makes a subtle, disparaging remark about the 1All the examples in this paper are actual examples of our datasets."}, {"heading": "2 Motivation", "text": "In our literature study on detection of sarcasm (Joshi et al., 2016), we note that a popular trend is the semi-supervised extraction of patterns with implicit sensation. However, such a work comes from Riloff et al. (2013), which gives a bootstrapping algorithm that reveals a series of positive verbs and negative / undesirable situations. However, this simplification (presenting sarcasm merely as a positive verbs followed by a negative situation) cannot capture difficult forms of context congruence. Consider the sarcastic sentence \"A woman needs a man like a fish needs a bicycle.\" 2. The sarcasm in this sentence is understood from the fact that a fish does not need a bicycle - and therefore the sentence ridicules the goal of \"a man.\" However, this sentence does not contain a sentimental word. Existing sarcasm detection systems that rely on the sensory incongruence (as in the case of our previous work, which Joset al cases are reported as 2015) are not similar to the one we feel."}, {"heading": "3 Background: Features from prior work", "text": "We extend our word-embedding-based features by the following four feature sets that have been reported: 1. Liebrecht et al. (2013): They consider unigrams, bigrams, and trigrams as features. 2. Gonza'lez-Iba'nez et al. (2011a): They suggest two feature sets: unigrams and dictionaries. The latter are words from a lexical resource called LIWC. We use words from LIWC that have been commented as emotional and psychological process words, as described in the original paper. 3. Buschmeier et al. (2014): In addition to unigrams, they suggest features such as: (a) hypersentiment (captured by three positive or negative words in succession), (b) quotation marks and ellipsis, (c) positive / negative sensation words, followed by exclamation marks or question marks, (d) positive / negative sensation marks, followed by irpsis (Dunpus), (Dunpus), (Dunpus), (Dunpina), and (Dunpus)."}, {"heading": "4 Word Embedding-based Features", "text": "In this section, we will now describe our word embedding characteristics. We repeat that these characteristics are supplemented by characteristics from previous work (described in Section 3). As explained in Section 2, our word embedding characteristics are based on similarity values between word embedding values. The similarity value is the cosinal similarity between vectors of two words. To illustrate our characteristics, we will use our example: \"A woman needs a man like a fish needs a bicycle.\" The values for all word pairs in this sentence will be shown in Table 1. Using these similarity values, we will calculate two sets of characteristics: 1. Unweighted characteristics of similarity (S): We will first calculate similarity values for all word pairs (with the exception of holding words). We will then return four characteristic values per sentence. 3: \u2022 Maximum score of most similar word pairs \u2022 Minimum score of most similar word pairs \u2022 Maximum score of most similar word pairs \u2022 Maximum score of most similar word pairs."}, {"heading": "5 Experiment Setup", "text": "We create a dataset of quotes on GoodReads 4. GoodReads describes itself as \"the world's largest page for readers and book recommendations.\" On the site, users can also post quotes from books. These quotes are excerpts from books labeled by the user with tags of their choice. We ensure that no quotation has both tags, resulting in a dataset of 3629 quotations, of which 759 are labeled sarcastic. This distortion is similar to sketches observed in datasets where sarcasm detection experiments have been reported in the past (Riloff et al., 2013). We report five-fold cross-validation results on the above datasets. We use SVMperf from Joachims (2006) with 20, w as 3 and compare this function with four weighted F versions, while we work four weighted F functions, each with 7M-weighted."}, {"heading": "6 Results", "text": "The embedding in this case is no more than four different types of justifications (S), weighted similarity to word embeddings (S), while only the unweighted and weighted features of word embeddings (WS) and both (WS) and the unweighted similarities to word embeddings are shown of 72.53%, while only the unweighted and weighted features of F score of 69.49% and 58.26% respectively are shown the unweighted similarities to word embeddings of 72.53%, while only the unweighted and weighted features of F score of 69.49% and 58.26% respectively are shown the unweighted similarities to word embeddings. This validates our intuition.Words.com 5http: / / www.lingexp.uni-tuebingen.de / z2 / LSAspaces / 6http: / / nlp.stanford.edu / 7 https / / / / lexer.com / p.04"}, {"heading": "7 Error Analysis", "text": "Some categories of mistakes made by our system are: 1. Embedding problems due to wrong senses: Since words can have multiple senses, some embedding leads to errors, as in \"Great. Relationship advice from one of America's most wanted.\" 2. Contextual sarcasm: Take the sarcastic quote \"Oh, and I believe the apple ate the cheese.\" The similarity value between \"apple\" and \"cheese\" is 0.4119. This results in the maximum similar pair. The most unequal pair is \"assus\" and \"apple\" with a similarity value of 0.1414. The sarcasm in this sentence can only be understood in the context of the complete conversation to which it belongs. 3. Metaphors in non-sarcastic text: Figurative language can compare concepts that are not directly related to each other, but nevertheless exhibit slight similarities. Take the nonsarcastic quote \"Oh my love, I like to disappear in you like a rile disappears in an ocean - slowly and endlessly.\""}, {"heading": "8 Related Work", "text": "Research on early detection of sarcasm focused on language (Tepperman et al., 2006) and lexical traits (Cross and Caucci, 2007). Several other traits were suggested (Cross and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonza \u0301 lez-Iba \u0301 nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace et al., 2014; Veale and Hao, 2010; Gonza \u0301 lez-Iba \u0301 nez et al., 2011b; Reyes et al., 2012). Of particular relevance to our work are essays that aim to extract initial patterns that are relevant to detection of sarcasm. Davidov et al. (2010) use a semi-monitored approach in which stigma-bearing patterns are used for detection of sarcasm. (Joshi et al., 2015) a stigma, a stigma, an extraction stigma, a stigma, a stigma, a stigma, a stigma, a stigma, a situation, a stigma, a stigma, a stigma, a stigma, a stigma, a stigma, a stigma, a stigma, a stigma, a stigma."}, {"heading": "9 Conclusion", "text": "We are experimenting with four previous work on sarcasm detection, in which we extend our word embedding-based characteristics to include their character sets. Our characteristics use the similarity values determined by word embedding and are divided into two categories: similarity values (taking into account the maximum / minimum similarity value of most similar / dissimilar word pairs with the linear distance between the two words in the sentence) and weighted similarity values (taking into account the maximum / minimum similarity values of most similar / dissimilar word pairs with the linear distance between the two words in the sentence). We are experimenting with four types of word embedding: LSA, GloVe, Dependency Values, and Word2Vec. In the case of Word2Vec, we can observe an improvement of no more than 5% in the F score for three of these past character sets to which our characteristics have been extended."}], "references": [{"title": "An impact analysis of features in a classification approach to irony detection in product reviews", "author": ["Konstantin Buschmeier", "Philipp Cimiano", "Roman Klinger."], "venue": "Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 42\u201349.", "citeRegEx": "Buschmeier et al\\.,? 2014", "shortCiteRegEx": "Buschmeier et al\\.", "year": 2014}, {"title": "Semisupervised recognition of sarcastic sentences in twitter and amazon", "author": ["Dmitry Davidov", "Oren Tsur", "Ari Rappoport."], "venue": "Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 107\u2013116. Association for Computational Linguistics.", "citeRegEx": "Davidov et al\\.,? 2010", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Sarcastic or not: Word embeddings to predict the literal or sarcastic meaning of words", "author": ["Debanjan Ghosh", "Weiwei Guo", "Smaranda Muresan."], "venue": "EMNLP.", "citeRegEx": "Ghosh et al\\.,? 2015", "shortCiteRegEx": "Ghosh et al\\.", "year": 2015}, {"title": "Identifying sarcasm in twitter: a closer look", "author": ["Roberto Gonz\u00e1lez-Ib\u00e1nez", "Smaranda Muresan", "Nina Wacholder."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technolo-", "citeRegEx": "Gonz\u00e1lez.Ib\u00e1nez et al\\.,? 2011a", "shortCiteRegEx": "Gonz\u00e1lez.Ib\u00e1nez et al\\.", "year": 2011}, {"title": "Identifying sarcasm in twitter: a closer look", "author": ["Roberto Gonz\u00e1lez-Ib\u00e1nez", "Smaranda Muresan", "Nina Wacholder."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technolo-", "citeRegEx": "Gonz\u00e1lez.Ib\u00e1nez et al\\.,? 2011b", "shortCiteRegEx": "Gonz\u00e1lez.Ib\u00e1nez et al\\.", "year": 2011}, {"title": "Context incongruity and irony processing", "author": ["Stacey L Ivanko", "Penny M Pexman."], "venue": "Discourse Processes, 35(3):241\u2013279.", "citeRegEx": "Ivanko and Pexman.,? 2003", "shortCiteRegEx": "Ivanko and Pexman.", "year": 2003}, {"title": "Training linear svms in linear time", "author": ["Thorsten Joachims."], "venue": "Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 217\u2013226. ACM.", "citeRegEx": "Joachims.,? 2006", "shortCiteRegEx": "Joachims.", "year": 2006}, {"title": "Harnessing context incongruity for sarcasm detection", "author": ["Aditya Joshi", "Vinita Sharma", "Pushpak Bhattacharyya."], "venue": "Proceedings of the 53rd Annual Meeting of the As-", "citeRegEx": "Joshi et al\\.,? 2015", "shortCiteRegEx": "Joshi et al\\.", "year": 2015}, {"title": "Automatic sarcasm detection: A survey", "author": ["Aditya Joshi", "Pushpak Bhattacharyya", "Mark James Carman."], "venue": "arXiv preprint arXiv:1602.03426.", "citeRegEx": "Joshi et al\\.,? 2016", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Your sentiment precedes you: Using an authors historical tweets to predict sarcasm", "author": ["Anupam Khattri", "Aditya Joshi", "Pushpak Bhattacharyya", "Mark James Carman."], "venue": "In", "citeRegEx": "Khattri et al\\.,? 2015", "shortCiteRegEx": "Khattri et al\\.", "year": 2015}, {"title": "Lexical influences on the perception of sarcasm", "author": ["Roger J Kreuz", "Gina M Caucci."], "venue": "Proceedings of the Workshop on computational approaches to Figurative Language, pages 1\u20134. Association for Computational Linguistics.", "citeRegEx": "Kreuz and Caucci.,? 2007", "shortCiteRegEx": "Kreuz and Caucci.", "year": 2007}, {"title": "A solution to platos problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge", "author": ["Thomas K Landauer", "Susan T. Dumais."], "venue": "PSYCHOLOGICAL REVIEW, 104(2):211\u2013240.", "citeRegEx": "Landauer and Dumais.,? 1997", "shortCiteRegEx": "Landauer and Dumais.", "year": 1997}, {"title": "Dependency-based word embeddings", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014, June 22-27, 2014, Baltimore, MD, USA, Volume 2: Short Papers, pages 302\u2013308.", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "The perfect solution for detecting sarcasm in tweets", "author": ["CC Liebrecht", "FA Kunneman", "APJ van den Bosch"], "venue": null, "citeRegEx": "Liebrecht et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liebrecht et al\\.", "year": 2013}, {"title": "Scikit-learn: Machine learning in python", "author": ["Fabian Pedregosa", "Ga\u00ebl Varoquaux", "Alexandre Gramfort", "Vincent Michel", "Bertrand Thirion", "Olivier Grisel", "Mathieu Blondel", "Peter Prettenhofer", "Ron Weiss", "Vincent Dubourg"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Pedregosa et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Pedregosa et al\\.", "year": 2011}, {"title": " sure, i did the right thing\u201d: a system for sarcasm detection in speech", "author": ["Rachel Rakov", "Andrew Rosenberg."], "venue": "INTERSPEECH, pages 842\u2013846.", "citeRegEx": "Rakov and Rosenberg.,? 2013", "shortCiteRegEx": "Rakov and Rosenberg.", "year": 2013}, {"title": "Software Framework for Topic Modelling with Large Corpora", "author": ["Radim \u0158eh\u016f\u0159ek", "Petr Sojka."], "venue": "Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks, pages 45\u201350, Valletta, Malta, May. ELRA. http://is.muni.cz/publication/884893/en.", "citeRegEx": "\u0158eh\u016f\u0159ek and Sojka.,? 2010", "shortCiteRegEx": "\u0158eh\u016f\u0159ek and Sojka.", "year": 2010}, {"title": "From humor recognition to irony detection: The figurative language of social media", "author": ["Antonio Reyes", "Paolo Rosso", "Davide Buscaldi."], "venue": "Data & Knowledge Engineering, 74:1\u201312.", "citeRegEx": "Reyes et al\\.,? 2012", "shortCiteRegEx": "Reyes et al\\.", "year": 2012}, {"title": "Sarcasm as contrast between a positive sentiment and negative situation", "author": ["Ellen Riloff", "Ashequl Qadir", "Prafulla Surve", "Lalindra De Silva", "Nathan Gilbert", "Ruihong Huang."], "venue": "EMNLP, pages 704\u2013714.", "citeRegEx": "Riloff et al\\.,? 2013", "shortCiteRegEx": "Riloff et al\\.", "year": 2013}, {"title": " yeah right\u201d: sarcasm recognition for spoken dialogue systems", "author": ["Joseph Tepperman", "David R Traum", "Shrikanth Narayanan."], "venue": "INTERSPEECH. Citeseer.", "citeRegEx": "Tepperman et al\\.,? 2006", "shortCiteRegEx": "Tepperman et al\\.", "year": 2006}, {"title": "Icwsma great catchy name: Semi-supervised recognition of sarcastic sentences in online product reviews", "author": ["Oren Tsur", "Dmitry Davidov", "Ari Rappoport."], "venue": "ICWSM.", "citeRegEx": "Tsur et al\\.,? 2010", "shortCiteRegEx": "Tsur et al\\.", "year": 2010}, {"title": "Detecting ironic intent in creative comparisons", "author": ["Tony Veale", "Yanfen Hao."], "venue": "ECAI, volume 215, pages 765\u2013770.", "citeRegEx": "Veale and Hao.,? 2010", "shortCiteRegEx": "Veale and Hao.", "year": 2010}, {"title": "Humans require context to infer ironic intent (so computers probably do, too)", "author": ["Byron C Wallace", "Laura Kertz Do Kook Choe", "Eugene Charniak."], "venue": "Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), pages 512\u2013516.", "citeRegEx": "Wallace et al\\.,? 2014", "shortCiteRegEx": "Wallace et al\\.", "year": 2014}, {"title": "Sparse, contextually informed models for irony detection: Exploiting user communities,entities and sentiment", "author": ["Byron C Wallace."], "venue": "ACL.", "citeRegEx": "Wallace.,? 2015", "shortCiteRegEx": "Wallace.", "year": 2015}, {"title": "Performance obtained on augmenting word embedding features to features from four prior works, for four word embeddings", "author": ["J: Joshi"], "venue": "L: Liebrecht et al", "citeRegEx": "85", "shortCiteRegEx": "85", "year": 2013}], "referenceMentions": [{"referenceID": 5, "context": "Linguistic studies show that the notion of context incongruity is at the heart of sarcasm (Ivanko and Pexman, 2003).", "startOffset": 90, "endOffset": 115}, {"referenceID": 1, "context": "A popular trend in automatic sarcasm detection is semi-supervised extraction of patterns that capture the underlying context incongruity (Davidov et al., 2010; Joshi et al., 2015; Riloff et al., 2013).", "startOffset": 137, "endOffset": 200}, {"referenceID": 7, "context": "A popular trend in automatic sarcasm detection is semi-supervised extraction of patterns that capture the underlying context incongruity (Davidov et al., 2010; Joshi et al., 2015; Riloff et al., 2013).", "startOffset": 137, "endOffset": 200}, {"referenceID": 18, "context": "A popular trend in automatic sarcasm detection is semi-supervised extraction of patterns that capture the underlying context incongruity (Davidov et al., 2010; Joshi et al., 2015; Riloff et al., 2013).", "startOffset": 137, "endOffset": 200}, {"referenceID": 8, "context": "In our literature survey of sarcasm detection (Joshi et al., 2016), we observe that a popular trend is semi-supervised extraction of patterns with implicit sentiment.", "startOffset": 46, "endOffset": 66}, {"referenceID": 7, "context": "In our literature survey of sarcasm detection (Joshi et al., 2016), we observe that a popular trend is semi-supervised extraction of patterns with implicit sentiment. One such work is by Riloff et al. (2013) who give a bootstrapping algorithm that discovers a set of positive verbs and", "startOffset": 47, "endOffset": 208}, {"referenceID": 7, "context": "Existing sarcasm detection systems relying on sentiment incongruity (as in the case of our past work reported as Joshi et al. (2015)) may not work well in such cases of sarcasm.", "startOffset": 113, "endOffset": 133}, {"referenceID": 13, "context": "Liebrecht et al. (2013): They consider unigrams, bigrams and trigrams as features.", "startOffset": 0, "endOffset": 24}, {"referenceID": 3, "context": "Gonz\u00e1lez-Ib\u00e1nez et al. (2011a): They propose two sets of features: unigrams and dictionary-based.", "startOffset": 0, "endOffset": 31}, {"referenceID": 0, "context": "Buschmeier et al. (2014): In addition to unigrams, they propose features such as: (a) Hyperbole (captured by three positive or negative words in a row), (b) Quotation marks and ellipsis, (c) Positive/Negative Sentiment words followed by an exclamation mark or question mark, (d) Positive/Negative Sentiment Scores followed by ellipsis (represented by a \u2018.", "startOffset": 0, "endOffset": 25}, {"referenceID": 7, "context": "Joshi et al. (2015): In addition to unigrams, they use features based on implicit and explicit incongruity.", "startOffset": 0, "endOffset": 20}, {"referenceID": 18, "context": "This skew is similar to skews observed in datasets on which sarcasm detection experiments have been reported in the past (Riloff et al., 2013).", "startOffset": 121, "endOffset": 142}, {"referenceID": 6, "context": "We use SVMperf by Joachims (2006) with c as 20, w as 3, and loss function as F-score optimization.", "startOffset": 18, "endOffset": 34}, {"referenceID": 11, "context": "LSA: This approach was reported in Landauer and Dumais (1997). We use pre-trained word embeddings based on LSA5.", "startOffset": 35, "endOffset": 62}, {"referenceID": 12, "context": "Dependency Weights: We use pre-trained vectors7 weighted using dependency distance, as given in Levy and Goldberg (2014). The vocabulary size is 174,015.", "startOffset": 96, "endOffset": 121}, {"referenceID": 16, "context": "To interact with these pretrained vectors, as well as compute various features, we use gensim library (\u0158eh\u016f\u0159ek and Sojka, 2010).", "startOffset": 102, "endOffset": 127}, {"referenceID": 14, "context": "To interact with the first three pre-trained vectors, we use scikit library (Pedregosa et al., 2011).", "startOffset": 76, "endOffset": 100}, {"referenceID": 0, "context": "Following this, we show performance using features presented in four prior works: Buschmeier et al. (2014), Liebrecht et al.", "startOffset": 82, "endOffset": 107}, {"referenceID": 0, "context": "Following this, we show performance using features presented in four prior works: Buschmeier et al. (2014), Liebrecht et al. (2013), Joshi et al.", "startOffset": 82, "endOffset": 132}, {"referenceID": 0, "context": "Following this, we show performance using features presented in four prior works: Buschmeier et al. (2014), Liebrecht et al. (2013), Joshi et al. (2015) and Gonz\u00e1lezIb\u00e1nez et al.", "startOffset": 82, "endOffset": 153}, {"referenceID": 0, "context": "Following this, we show performance using features presented in four prior works: Buschmeier et al. (2014), Liebrecht et al. (2013), Joshi et al. (2015) and Gonz\u00e1lezIb\u00e1nez et al. (2011a), and compare them with augmented versions in Table 3.", "startOffset": 82, "endOffset": 187}, {"referenceID": 10, "context": "In case of Liebrecht et al. (2013) for Word2Vec, the overall improvement in F-score is 4%.", "startOffset": 11, "endOffset": 35}, {"referenceID": 10, "context": "In case of Liebrecht et al. (2013) for Word2Vec, the overall improvement in F-score is 4%. Precision increases by 8% while recall remains nearly unchanged. For features given in Gonz\u00e1lezIb\u00e1nez et al. (2011a), there is a negligible degradation of 0.", "startOffset": 11, "endOffset": 208}, {"referenceID": 0, "context": "For Buschmeier et al. (2014) for Word2Vec, we observe an improvement in F-score from 76.", "startOffset": 4, "endOffset": 29}, {"referenceID": 0, "context": "For Buschmeier et al. (2014) for Word2Vec, we observe an improvement in F-score from 76.61% to 78.09%. Precision remains nearly unchanged while recall increases. In case of Joshi et al. (2015) and Word2Vec, we observe a slight improvement of 0.", "startOffset": 4, "endOffset": 193}, {"referenceID": 13, "context": "The maximum improvement is observed in case of Liebrecht et al. (2013). It is around 4% in case of LSA, 5% in case of GloVe, 6% in case of Dependency weight-based and 4% in case of Word2Vec.", "startOffset": 47, "endOffset": 71}, {"referenceID": 19, "context": "Early sarcasm detection research focused on speech (Tepperman et al., 2006) and lexical features (Kreuz and Caucci, 2007).", "startOffset": 51, "endOffset": 75}, {"referenceID": 10, "context": ", 2006) and lexical features (Kreuz and Caucci, 2007).", "startOffset": 29, "endOffset": 53}, {"referenceID": 10, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 7, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 9, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 13, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 3, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 15, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 23, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 22, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 21, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 4, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 17, "context": "Several other features have been proposed (Kreuz and Caucci, 2007; Joshi et al., 2015; Khattri et al., 2015; Liebrecht et al., 2013; Gonz\u00e1lez-Ib\u00e1nez et al., 2011a; Rakov and Rosenberg, 2013; Wallace, 2015; Wallace et al., 2014; Veale and Hao, 2010; Gonz\u00e1lez-Ib\u00e1nez et al., 2011b; Reyes et al., 2012).", "startOffset": 42, "endOffset": 299}, {"referenceID": 1, "context": "Davidov et al. (2010) use a semi-supervised approach that extracts sentiment-bearing patterns for sarcasm detection.", "startOffset": 0, "endOffset": 22}, {"referenceID": 1, "context": "Davidov et al. (2010) use a semi-supervised approach that extracts sentiment-bearing patterns for sarcasm detection. Joshi et al. (2015) extract phrases corresponding to implicit incongruity i.", "startOffset": 0, "endOffset": 137}, {"referenceID": 1, "context": "Davidov et al. (2010) use a semi-supervised approach that extracts sentiment-bearing patterns for sarcasm detection. Joshi et al. (2015) extract phrases corresponding to implicit incongruity i.e. the situation where sentiment is expressed without use of sentiment words. Riloff et al. (2013) describe a bootstrapping algorithm that iteratively discovers a set of positive verbs and negative situation phrases, which are later used in a sarcasm detection algorithm.", "startOffset": 0, "endOffset": 292}, {"referenceID": 1, "context": "Davidov et al. (2010) use a semi-supervised approach that extracts sentiment-bearing patterns for sarcasm detection. Joshi et al. (2015) extract phrases corresponding to implicit incongruity i.e. the situation where sentiment is expressed without use of sentiment words. Riloff et al. (2013) describe a bootstrapping algorithm that iteratively discovers a set of positive verbs and negative situation phrases, which are later used in a sarcasm detection algorithm. Tsur et al. (2010) also perform semi-supervised extraction of patterns for sarcasm detection.", "startOffset": 0, "endOffset": 484}, {"referenceID": 1, "context": "Davidov et al. (2010) use a semi-supervised approach that extracts sentiment-bearing patterns for sarcasm detection. Joshi et al. (2015) extract phrases corresponding to implicit incongruity i.e. the situation where sentiment is expressed without use of sentiment words. Riloff et al. (2013) describe a bootstrapping algorithm that iteratively discovers a set of positive verbs and negative situation phrases, which are later used in a sarcasm detection algorithm. Tsur et al. (2010) also perform semi-supervised extraction of patterns for sarcasm detection. The only prior work which uses word embeddings for a related task of sarcasm detection is by Ghosh et al. (2015). They model sarcasm detection as a word sense disambiguation task, and use embeddings to identify whether a word is used in the sarcastic or nonsarcastic sense.", "startOffset": 0, "endOffset": 672}], "year": 2016, "abstractText": "This paper makes a simple increment to state-ofthe-art in sarcasm detection research. Existing approaches are unable to capture subtle forms of context incongruity which lies at the heart of sarcasm. We explore if prior work can be enhanced using semantic similarity/discordance between word embeddings. We augment word embedding-based features to four feature sets reported in the past. We also experiment with four types of word embeddings. We observe an improvement in sarcasm detection, irrespective of the word embedding used or the original feature set to which our features are augmented. For example, this augmentation results in an improvement in F-score of around 4% for three out of these four feature sets, and a minor degradation in case of the fourth, when Word2Vec embeddings are used. Finally, a comparison of the four embeddings shows that Word2Vec and dependency weight-based features outperform LSA and GloVe, in terms of their benefit to sarcasm detection.", "creator": "dvips(k) 5.991 Copyright 2011 Radical Eye Software"}}}