{"id": "1610.01698", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Oct-2016", "title": "Human Decision-Making under Limited Time", "abstract": "Subjective expected utility theory assumes that decision-makers possess unlimited computational resources to reason about their choices; however, virtually all decisions in everyday life are made under resource constraints - i.e. decision-makers are bounded in their rationality. Here we experimentally tested the predictions made by a formalization of bounded rationality based on ideas from statistical mechanics and information-theory. We systematically tested human subjects in their ability to solve combinatorial puzzles under different time limitations. We found that our bounded-rational model accounts well for the data. The decomposition of the fitted model parameter into the subjects' expected utility function and resource parameter provide interesting insight into the subjects' information capacity limits. Our results confirm that humans gradually fall back on their learned prior choice patterns when confronted with increasing resource limitations.", "histories": [["v1", "Thu, 6 Oct 2016 00:40:14 GMT  (357kb,D)", "http://arxiv.org/abs/1610.01698v1", "9 pages, 4 figures, NIPS Advances in Neural Information Processing Systems 29, 2016"]], "COMMENTS": "9 pages, 4 figures, NIPS Advances in Neural Information Processing Systems 29, 2016", "reviews": [], "SUBJECTS": "stat.ML cs.AI", "authors": ["pedro a ortega", "alan a stocker"], "accepted": true, "id": "1610.01698"}, "pdf": {"name": "1610.01698.pdf", "metadata": {"source": "CRF", "title": "Human Decision-Making under Limited Time", "authors": ["Pedro A. Ortega", "Alan A. Stocker"], "emails": ["ope@seas.upenn.edu", "astocker@sas.upenn.edu"], "sections": [{"heading": "1 Introduction", "text": "Most of our decisions are not applicable in such cases because they ignore information-processing resources, provided that decision-makers always make the optimal choice [10]. However, it is well known that patterns of human decision-making differ qualitatively from the perfectly rational ideal with increasing resource constraints. It has been suggested that such constraints in decision-making can be formalized using ideas from statistical mechanics [9] and information theory [16]. These frameworks suggest that decision-makers act as if their election probabilities were an optimal compromise between maximizing the expected benefit and minimizing KL divergence from a series of previous election probabilities where the trade-off is determined by the amount of resources available. This optimization scheme reduces the decision problem to the conclusion of optimal choice from a stimulus."}, {"heading": "2 A Probabilistic Model of Bounded-Rational Choices", "text": "We model a limited-rational decision maker as an expected utility maximizer subject to information security (\u03b2 = \u03b2-certainty). Formally, X and Y are two finite sets, the former corresponding to a set of stimuli and the latter to a set of decisions; and let P (y) be a prior distribution of optimal choices y that the decision maker may have learned from experience. This transformation is modeled as the optimization of a regulated expected benefit known as free energy functionality: F [Q (y) into posterior election probabilities P (y | x) and then generates a choice according to P (y | x). This transformation is modeled as the optimization of a regulated benefit known as free energy functionality."}, {"heading": "3 Experimental Methods", "text": "We conducted a selection experiment in which the subjects had to solve puzzles under pressure of time. Each puzzle consisted of a Boolean formula in the subjunctive normal form (CNF) which was camouflaged as an arrangement of circular patterns (see Figure 1). The task was to find a truth assignment corresponding to the formula. Subjects were able to select an assignment by marking the colors of a central pattern in gray. Formally, the puzzles and assignments corresponded to the stimuli x-X or the decisions y-Y, and the duration of the puzzle was the resource parameter we controlled (see Eq.1). We limited our puzzles to a series of five CNF formulas with 6 clauses, 2 words per sentence, and 3 variables. The subjects were trained only on the first four puzzles, whereas the last one was used as a control puzzle during the test phase. All the selected puzzles had a single solution consisting of the only possible assignments of 23-F and we chose a decision-8 in contrast between them."}, {"heading": "3.1 Data Collection", "text": "Two symmetrical versions of the experiment were conducted on Amazon Mechanical Turk. For each study, we collected selection data from 15 anonymous participants residing in the United States, a total of 30 subjects. Subjects were given $10 to complete the experiment. Typical duration of the experiment ranged from 50 to 130 minutes. For each subject, we recorded a sequence of 90 training and 285 tests. Riddles were displayed throughout the study, during which subjects were able to change their choice at will. Training experiments allowed subjects to familiarize themselves with the task and stimuli, while the test experiments measured their adapted selection behavior as a function of stimulus and task duration. Training experiments were presented in blocks of 18 for a long, fixed duration; the test experiments, which were of variable duration, were presented in blocks of 19 (block of 18 regular + 1 control studies). To avoid collecting poor quality data, they were presented in blocks of 18 for a long, fixed duration; the test experiments were presented in blocks of 19 (block of 18 regular + 1 control studies)."}, {"heading": "4 Analysis", "text": "Recorded data D consists of a series of tuples (x, r, y), where x-X is a stimulus, r-R is a resource parameter (i.e. duration), and y-Y is a choice. To analyze the data, we made the following assumptions: 1. Transition regime: During the training experiments, subjects approached a set of subjective preferences over decisions that depended only on the stimulus. 2. Permanent regime: During the tests, subjects did not significantly change the preferences they learned during the training experiments, especially the decisions in the same stimulus duration group during the entire test phase.3. Negligible noise: We assumed that the operation of the input device and the keyword signaling the imminent end of the study did not have a significant impact on the distribution across the selection.Our analysis focused only on the test experiments."}, {"heading": "4.1 Inferring Preferences", "text": "By adapting the model, we divided the selection probabilities into: (a) an inverse temperature function \u03b2: R \u2192 R; and (b) a series of subjective supply functions Ux: Y \u2212 R, one for each stimulus x. We assumed that the propositions X, R, and Y were finite, and we used vector representations for \u03b2 and the Ux. To perform the decomposition, we minimized the average Kullback Leibler divergenceJ = x, r P (x, r) [x, r] Log P (y, x, r) Q (y) Q (y, r) Q (y) x, r), (6) w.r.t. the inverse temperatures \u03b2 (r) and the supply functions Ux (y) by the probabilities Q (y | x, r) of the choice y (x, r) as derived from the context (x, r)."}, {"heading": "4.2 Expected Utility and Decision Bandwidth", "text": "The model derived from this is useful for studying the performance of the decision maker under different settings of the resource parameter - in particular for determining the asymptotic performance limits. Two quantities are of particular interest: the expected benefit averaged via the stimuli, and the mutual information between the stimulus and the choice, both as a function of the reverse temperature \u03b2. In view of \u03b2, we define these quantities as EU\u03b2: = x, y P (x) Q\u03b2 (y | x) Ux (y) and I\u03b2: = x, y P (x) Q\u03b2 (y | x) log Q\u03b2 (y | x) Q\u03b2 (y) (12) resp. Both definitions are based on the common distribution P (x) Q\u03b2 (y | x), in which Q\u03b2 (y) exp {\u03b2Ux (x)} is the distribution of Gibbs derived from the previous P (y) and the auxiliary functions Ux (y)."}, {"heading": "5 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Decomposition into prior, utility, and inverse temperature", "text": "For each of the 30 subjects, we first calculated the empirical selection probabilities and then estimated their decomposition into an inverse temperature \u03b2 and usage functionUx using the method described in the previous section. The mean error of fit was very low (0.0347 \u00b1 0.0024 bits), which implies that the selection probabilities are well explained by the model. As an example, Figure 2 shows the decomposition of subject 1 (error 0.0469 bits, 83% percentile value) along with a comparison between the empirical posterior and the rear model, which is calculated from the derived components using Equation (7). As the duration of the experiment increases and \u03b2, the model captures the gradual shift from the previous to the optimal selection distribution. As seen in Figure 3, the resulting decomposition is stable and shows little variability between subjects. The stimuli of the experiment's version B were differentiated by the fact that they were only colored."}, {"heading": "5.2 Extrapolation of performance measures", "text": "We calculated the expected benefit and mutual information as a function of the inverse temperature using (12).The resulting curves for subject 1 and the average subject are shown in Fig. 4 together with the predicted percentage of correct decisions.All curves are monotonously rising and limited upward.The expected benefit and percentage of correct decisions are concave at the inverse temperature, indicating slightly decreasing yields with longer duration.Similarly, the mutual information approaches asymptotically the upper limit set by the stimulus entropy H (X) \u2248 1,792 bits (excluding the untrained stimulus)."}, {"heading": "6 Discussion and Conclusion", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "Acknowledgements", "text": "This work was supported by the Office of Naval Research (Grant N000141110744) and the University of Pennsylvania."}], "references": [{"title": "Clustering with Bregman Divergences", "author": ["A. Banerjee", "S. Merugu", "I.S. Dhillon", "J. Ghosh"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2005}, {"title": "Regret in decision making under uncertainty", "author": ["D.E. Bell"], "venue": "Operations Research,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1982}, {"title": "Regret theory: A bold alternative to the alternatives", "author": ["H. Bleichrodt", "P.P. Wakker"], "venue": "The Economic Journal,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "The Foundations of Expected Utility", "author": ["P.C. Fishburn"], "venue": "D. Reidel Publishing,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1982}, {"title": "Random belief equilibrium in normal form games", "author": ["J.W. Friedman", "C. Mezzetti"], "venue": "Games and Economic Behavior,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2005}, {"title": "Bounded rationality: the adaptive toolbox", "author": ["G. Gigerenzer", "R. Selten"], "venue": null, "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2001}, {"title": "Algorithm selection by rational metareasoning as a model of human strategy selection", "author": ["F. Lieder", "D. Plunkett", "J.B. Hamrick", "S.J. Russell", "N. Hay", "T. Griffiths"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Regret theory: An alternative approach to rational choice under uncertainty", "author": ["G. Loomes", "R. Sugden"], "venue": "Economic Journal,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 1982}, {"title": "Thermodynamics as a theory of decision-making with informationprocessing costs", "author": ["P.A. Ortega", "D.A. Braun"], "venue": "Proceedings of the Royal Society A: Mathematical, Physical and Engineering Science,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2013}, {"title": "Modeling bounded rationality", "author": ["A. Rubinstein"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1998}, {"title": "The Foundations of Statistics", "author": ["L.J. Savage"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 1954}, {"title": "The expected value of control: an integrative theory of anterior cingulate cortex", "author": ["A. Shenhav", "M.M. Botvinick", "J.D. Cohen"], "venue": "function. Neuron,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Models of Bounded Rationality", "author": ["H. Simon"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1984}, {"title": "Rational inference of relative preferences", "author": ["N. Srivastava", "P.R. Schrater"], "venue": "Advances in neural information processing systems,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2012}, {"title": "Magnitude-sensitive preference formation", "author": ["N. Srivastava", "E. Vul", "P.R. Schrater"], "venue": "Advances in neural information processing systems,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2014}, {"title": "Information Theory of Decisions and Actions", "author": ["N. Tishby", "D. Polani"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Theory of Games and Economic Behavior", "author": ["J. Von Neumann", "O. Morgenstern"], "venue": null, "citeRegEx": "17", "shortCiteRegEx": "17", "year": 1944}, {"title": "Maximum Entropy Inverse Reinforcement Learning", "author": ["B.D. Ziebart", "A.L. Maas", "J.A. Bagnell", "A.K. Dey"], "venue": "In AAAI,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2008}], "referenceMentions": [{"referenceID": 5, "context": "Most of our choices are constrained by many factors such as perceptual ambiguity, time, lack of knowledge, or computational effort [6].", "startOffset": 131, "endOffset": 134}, {"referenceID": 9, "context": "Classical theories of rational choice do not apply in such cases because they ignore information-processing resources, assuming that decision-makers always pick the optimal choice [10].", "startOffset": 180, "endOffset": 184}, {"referenceID": 8, "context": "It has been suggested that such limitations in decision-making can be formalized using ideas from statistical mechanics [9] and information theory [16].", "startOffset": 120, "endOffset": 123}, {"referenceID": 15, "context": "It has been suggested that such limitations in decision-making can be formalized using ideas from statistical mechanics [9] and information theory [16].", "startOffset": 147, "endOffset": 151}, {"referenceID": 8, "context": "where Z\u03b2(x) is a normalizing constant [9].", "startOffset": 38, "endOffset": 41}, {"referenceID": 8, "context": "The objective function (1) can be motivated as a trade-off between maximizing expected utility and minimizing information cost [9, 16].", "startOffset": 127, "endOffset": 134}, {"referenceID": 15, "context": "The objective function (1) can be motivated as a trade-off between maximizing expected utility and minimizing information cost [9, 16].", "startOffset": 127, "endOffset": 134}, {"referenceID": 1, "context": "Bounded-rational decision-making is related to regret theory [2, 4, 8].", "startOffset": 61, "endOffset": 70}, {"referenceID": 3, "context": "Bounded-rational decision-making is related to regret theory [2, 4, 8].", "startOffset": 61, "endOffset": 70}, {"referenceID": 7, "context": "Bounded-rational decision-making is related to regret theory [2, 4, 8].", "startOffset": 61, "endOffset": 70}, {"referenceID": 2, "context": "Accordingly, the difference in log-probability is proportional to the negative regret [3].", "startOffset": 86, "endOffset": 89}, {"referenceID": 8, "context": "risk-sensitive estimation [9].", "startOffset": 26, "endOffset": 29}, {"referenceID": 0, "context": "We used the objective function (6) because it is the Bregman divergence over the simplex of choice probabilities [1].", "startOffset": 113, "endOffset": 116}, {"referenceID": 12, "context": "It has long been recognized that the model of perfect rationality does not adequately capture human decision-making because it neglects the numerous resource limitations that prevent the selection of the optimal choice [13].", "startOffset": 219, "endOffset": 223}, {"referenceID": 10, "context": "Thus, our results conflict with the predictions made by models that lack a prior choice distribution\u2014most notably with expected utility theory [11, 17] and the choice models based on the Softmax function (typical in reinforcement learning, but also in e.", "startOffset": 143, "endOffset": 151}, {"referenceID": 16, "context": "Thus, our results conflict with the predictions made by models that lack a prior choice distribution\u2014most notably with expected utility theory [11, 17] and the choice models based on the Softmax function (typical in reinforcement learning, but also in e.", "startOffset": 143, "endOffset": 151}, {"referenceID": 4, "context": "the logit rule of quantal response equilibria [5] or in maximum entropy inverse reinforcement learning [18]).", "startOffset": 46, "endOffset": 49}, {"referenceID": 17, "context": "the logit rule of quantal response equilibria [5] or in maximum entropy inverse reinforcement learning [18]).", "startOffset": 103, "endOffset": 107}, {"referenceID": 2, "context": "Utilities are stimulus-contingent enhancers/inhibitors that act upon the prior choice probabilities, consistent with the role of utility as a measure of relative desirability in regret theory [3] and also related to the cognitive functions attributed to the dorsal anterior cingulate cortex [12].", "startOffset": 192, "endOffset": 195}, {"referenceID": 11, "context": "Utilities are stimulus-contingent enhancers/inhibitors that act upon the prior choice probabilities, consistent with the role of utility as a measure of relative desirability in regret theory [3] and also related to the cognitive functions attributed to the dorsal anterior cingulate cortex [12].", "startOffset": 291, "endOffset": 295}, {"referenceID": 6, "context": "This assumption does not comply with the necessary conditions for rational meta-reasoning, wherein decision-makers can utilize the knowledge about their own resources in their strategy [7].", "startOffset": 185, "endOffset": 188}, {"referenceID": 13, "context": "Other avenues are explored in [14, 15] and references therein.", "startOffset": 30, "endOffset": 38}, {"referenceID": 14, "context": "Other avenues are explored in [14, 15] and references therein.", "startOffset": 30, "endOffset": 38}], "year": 2016, "abstractText": "Subjective expected utility theory assumes that decision-makers possess unlimited computational resources to reason about their choices; however, virtually all decisions in everyday life are made under resource constraints\u2014i.e. decision-makers are bounded in their rationality. Here we experimentally tested the predictions made by a formalization of bounded rationality based on ideas from statistical mechanics and information-theory. We systematically tested human subjects in their ability to solve combinatorial puzzles under different time limitations. We found that our bounded-rational model accounts well for the data. The decomposition of the fitted model parameter into the subjects\u2019 expected utility function and resource parameter provide interesting insight into the subjects\u2019 information capacity limits. Our results confirm that humans gradually fall back on their learned prior choice patterns when confronted with increasing resource limitations.", "creator": "LaTeX with hyperref package"}}}