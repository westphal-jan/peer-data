{"id": "1610.06210", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Oct-2016", "title": "A Theme-Rewriting Approach for Generating Algebra Word Problems", "abstract": "Texts present coherent stories that have a particular theme or overall setting, for example science fiction or western. In this paper, we present a text generation method called {\\it rewriting} that edits existing human-authored narratives to change their theme without changing the underlying story. We apply the approach to math word problems, where it might help students stay more engaged by quickly transforming all of their homework assignments to the theme of their favorite movie without changing the math concepts that are being taught. Our rewriting method uses a two-stage decoding process, which proposes new words from the target theme and scores the resulting stories according to a number of factors defining aspects of syntactic, semantic, and thematic coherence. Experiments demonstrate that the final stories typically represent the new theme well while still testing the original math concepts, outperforming a number of baselines. We also release a new dataset of human-authored rewrites of math word problems in several themes.", "histories": [["v1", "Wed, 19 Oct 2016 20:49:23 GMT  (128kb,D)", "http://arxiv.org/abs/1610.06210v1", "To appear EMNLP 2016"]], "COMMENTS": "To appear EMNLP 2016", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["rik koncel-kedziorski", "ioannis konstas", "luke zettlemoyer", "hannaneh hajishirzi"], "accepted": true, "id": "1610.06210"}, "pdf": {"name": "1610.06210.pdf", "metadata": {"source": "CRF", "title": "A Theme-Rewriting Approach for Generating Algebra Word Problems", "authors": ["Rik Koncel-Kedziorski", "Ioannis Konstas", "Luke Zettlemoyer", "Hannaneh Hajishirzi"], "emails": ["kedzior@uw.edu,", "hannaneh}@cs.washington.edu"], "sections": [{"heading": "1 Introduction", "text": "It is the complex activity of expressing a plot, its events and participants in the problems of an audience. Automatic narrative systems can be used for customized sports commentaries that provide video games with personalized or dynamic plot lines (Barros and Musse, 2007). In this paper, we focus on generating narrative style problems (Figure 1) and show that it is possible to design an algorithm without altering the underlying story, for example, to do more homework that is able to produce a popular movie."}, {"heading": "2 Related Work", "text": "Our approach refers to previous work in story creation (e.g. McIntyre and Lapata (2010)) and sentence transcription (e.g., text simplification (Xu et1Data and code available at https: / / gitlab.cs. washington.edu / kedzior / rewriter /.al., 2016), as discussed in this section. There are three main differences from all of these approaches: First, we focus on multi-sentence stories, where maintaining coherence, discourse relationships, and solvability is essential. Previous work mainly focused on rewriting individual sentences. Second, we build a theme from a text corpus and show how stories can be adapted to new themes. Third, our method uses man-made history to capture the semantic skeleton and plot of current history, rather than synthesize the plot."}, {"heading": "3 Problem Formulation", "text": "Our system takes a story s and a theme t as input and prints the best paraphrases from generated candidates. A theme t is defined as a textual corpus describing a theme or a domain. It is a deliberately broad definition that allows a variety of textual resources to serve as themes. For example, the collection of all science fiction stories from Project Gutenberg can be a theme or script of a single movie or a sampling of fan fiction from the Internet. This flexibility increases the value of our work as different amounts of thematic text may be available. The generated candidate s is the most thematically appropriate problem that is syntactically and semantically coherent in the face of the original problem and the new theme. We present a story with respect to the words it contains, so that s = {w1, w2,."}, {"heading": "4 Scoring Stories", "text": "The scoring function R is divided into three components and covers aspects of syntactic compatibility, semantic coherence and thematicism: R (s) | s, t; \u03b8) = \u03b1 \u00b7 Sem (s) + \u03b2 \u00b7 Syn (s) (2) + \u03b3 \u00b7 Th (s) | s, t) The syntactic (Syn) and semantic (Sem) components of coherence measure the coherence of words in the new history s \u00b2 and their compatibility with the syntactic and semantic relationships in the original history. On the other hand, thematicality (Th) evaluates the relevance and importance of words in relation to the theme. We describe each of these components and the decoding process in the following sections."}, {"heading": "4.1 Thematicity", "text": "Remember that a theme t is defined as a collection of documents that share a common theme, such as science fiction books or horror film scripts. We define the theme of a word w \u2032 as a measure of emphasis, or how discriminatory that word is for a particular theme. 3 For example, robots and spaceships are expected to be highly thematic in relation to Star Wars. In our setting, we expand this definition to include a candidate problem s \"and t\" as: Th (s, \"t) = | s\" i Sal (w \"i, t\") (3), where w \"i\" is a word from the candidate problem, and Sal is its emphasis in relation to the topic. In the context of this work, we argue that the thematic adaptation of the substantive words, i.e. nouns, verbs, named entities and adjectives, play the most important role in the formation of a new thematic problem."}, {"heading": "4.2 Syntactic compatibility", "text": "The syntactical constructs in a document play a special role in maintaining cohesion across sentences. We consider the man-made syntax of the original story s the gold standard and use it to evaluate a candidate problem s, taking into account how well the syntactical relations from s to s are applicable. Formally, we define the syntactical score for all sentences in s as: Syn (s, wj, l) from an extract of a sentence in s, we calculate the probability of the corresponding triple (w \u2032 i, w \u2032 j, l) for w \u2032 i, w \u2032 j in s. \"We define the syntactical score for all sentences in s\" as follows: Syn (s \u2032 | s) = i, j, l | (wi, wj, l): Dep (s): Dep (w \u2032 i, l)."}, {"heading": "4.3 Semantic Coherence", "text": "The semantic coherence component expresses how well a candidate paraphrases individual words and realizes the semantic relationships that exist in the human-written history. (wi) Ideally, we want to preserve enough of the semantics of the words to produce a coherent history, but we populate them with words that come from an unrelated topic. Therefore, we model the semantics of a story in terms of lexical semantics carried by individual words as well as semantic relationships that exist between their elements. Note that relationships transcend the boundaries of sentences and promote discourse coherence. We decompose semantic relationships in a series of local, lexical relationships between word pairs. Specifically, we consider semantic relationships for noun-noun-noun and verb-pairs provided by WordNet (Miller, 1995). Since some relationships are not directly sketched in these resources (for example, their resemblance to their preference pairs), we look at their relationships in blue."}, {"heading": "5 Decoding", "text": "Our decoding process begins by first identifying the substantive words wi (nouns, verbs, adjectives and named units) in the original problem s, which are taken as starting points for rewriting. For each of these lexical classes, we extract the most important thematic words and trivial nouns from the topic. For example, in Figure 2, candidates are nouns: \"ships,\" \"robots,\" droids, \"etc., and for verbs:\" explosion, \"\" soar, \"\" command, \"etc. Remember that the space in which candidate rewrites is large, and forbids an exhaustive enumeration. Therefore, we roughly look for a bar, taking into account all possible paths starting at the various starting points at the same time. At each step, the decoder considers an additional rewrite from the list of candidates, adds it to the existing hypotheses path, and evaluates it according to the function R (we are already observing the optimal equation, since they are all the result of a new problem in every count)."}, {"heading": "6 Data Collection", "text": "For the series of man-made stories {s} we use a corpus of mathematical word problems described in KoncelKedziorski et al. (2016). We select a subset of 150 problems aimed at fifth and sixth grade wars, all of which involve a single equation in a variable. These problems have an average of 2.7 sentences and 29.4 words, 12.6 of which are considered satisfied words by our system. To optimize and evaluate our model, we collect a corpus of man-made revisions produced by workers from Amazon Mechanical Turk on the basis of two themes: Star Wars and Adventure Time (a children's cartoon).We experimented with various methods to define the theme for the workers, including offering automatically generated word clouds or enforcing that an answer to one of several key words is included. In practice, we have found that the use of certain cultural elements as themes (such as famous movies or cartoons) that already attract higher-quality workers has a higher level."}, {"heading": "7 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "7.1 Setup", "text": "In fact, most of us are able to play by the rules that they have imposed on ourselves in order to play by the rules, \"he said.\" We have to play by the rules, \"he said.\" We have to play by the rules that we have imposed on ourselves. \"He added:\" We have to play by the rules that we have imposed on ourselves. \"He added:\" We have to play by the rules, \"\" we have to play by the rules. \"We have to play by the rules that we have imposed on ourselves.\" He added: \"We have to play by the rules,\" \"we have to play by the rules,\" \"we have to play by the rules.\" We have to play by the rules. \"We have to play by the rules.\" We have to play by the rules, \"\" we have to play by the rules, \"\" we have to play by the rules. \"We have to play by the rules,\" \"we have to play by the rules.\""}, {"heading": "7.2 Results", "text": "Table 1 reports on METEOR; we note that eliminating the semantic coherence values in -SEM impairs performance compared to FULL; this confirms our assertion that semantic compatibility is critical for building coherent stories. On the other hand, -SYN performs similarly to FULL. A closer look at the results of the -SYN system shows a greater variety of thematic elements due to relaxed syntactical compatibility constraints. Therefore, it is more likely that there is greater overlap with other reference descriptions, leading to higher METEOR ratings. However, a laborious comparison between FULL and -SYN (Table 2) shows that human subjects consistently prefer the output of -SYN in both STARtest and CARTOON. Table 2 also reports that HUMAN exceeds the results of the FULL model, and a painful comparison of overall FULL and thematic reflection of the results clearly reflects the issues of the METEM with the specific components."}, {"heading": "7.3 Qualitative Examples", "text": "Remember that our system does not require annotated thematic training data, which we can easily generate from any topic in which thematic text is available. To demonstrate this fact, we insert generated examples into a Western theme from novels by Project Gutenberg Corpus. Many of the results of our system are very legible, with only minor mismatches. Coherent, thematic semantic relationships are evident in problems such as s \u00b2 1, in which ships, guns and weapons combine to create the Star Wars theme; this is also evident in s \u00b2 5, where people trade in cigarettes with Western-sounding names such as Kurt and Madeline, an old-fashioned precursor of e-cigarettes. In some cases, semantic discrepancies lead to strange-sounding problems, as in s \u00b2 6, where the main character receives \"Wheat from Grub,\" but due to the syntactical compatibility components, which rate this candidate higher because the link between \"wheat and the\" less \"problem of interaction between the characters.\""}, {"heading": "8 Conclusion", "text": "We formalized the problem of rewriting stories as an automatic change of the topic of a text without trumping the underlying story, and developed an approach to rewriting algebra word problems that optimized the rewriting model for a number of metrics of overall text coherence. Experiments with a newly collected data set showed that our model can produce theme-related texts that are normally solvable. Future work could improve thematicism and solvability components by incorporating domain-specific and healthy knowledge and harnessing information extraction. In addition, neural network architectures (e.g. LSTMs, seq2seq) can be trained to rewrite coherently without having to rely on brittle syntactic parses. In addition, we plan to explore rewriting in other areas such as children's short stories and expand the model to include mathematical word problems directly from image symbols, eventually generating problems."}, {"heading": "Acknowledgments", "text": "This research was supported by the NSF (IIS 1616112), the Allen Institute for AI (66-9175), the Allen Distinguished Investigator Award, DARPA (FA8750-13-2-0008) and a Google Research Faculty Award. We thank the anonymous reviewers for their helpful comments."}], "references": [{"title": "Planning algorithms for interactive storytelling", "author": ["Leandro Motta Barros", "Soraia Raupp Musse."], "venue": "Computers in Entertainment (CIE), 5(1):4.", "citeRegEx": "Barros and Musse.,? 2007", "shortCiteRegEx": "Barros and Musse.", "year": 2007}, {"title": "Expanding teacher work roles: a resource for retention or a recipe for overwork", "author": ["Lora Bartlett"], "venue": "Journal of Education", "citeRegEx": "Bartlett.,? \\Q2004\\E", "shortCiteRegEx": "Bartlett.", "year": 2004}, {"title": "Unsupervised Learning of Narrative Schemas and Their Participants", "author": ["Nathanael Chambers", "Dan Jurafsky."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Pro-", "citeRegEx": "Chambers and Jurafsky.,? 2009", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2009}, {"title": "Collecting highly parallel data for paraphrase evaluation", "author": ["David Chen", "William B. Dolan."], "venue": "Proceedings of the Association for Computational Linguistics (ACL).", "citeRegEx": "Chen and Dolan.,? 2011", "shortCiteRegEx": "Chen and Dolan.", "year": 2011}, {"title": "A fast and accurate dependency parser using neural networks", "author": ["Danqi Chen", "Christopher Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 740\u2013750, Doha, Qatar, October. Association for", "citeRegEx": "Chen and Manning.,? 2014", "shortCiteRegEx": "Chen and Manning.", "year": 2014}, {"title": "The role of rewording and context personalization in the solving of mathematical word problems", "author": ["Judy Davis-Dorsey", "Steven M Ross", "Gary R Morrison."], "venue": "Journal of Educational Psychology, 83(1):61.", "citeRegEx": "Davis.Dorsey et al\\.,? 1991", "shortCiteRegEx": "Davis.Dorsey et al\\.", "year": 1991}, {"title": "Meteor Universal: Language Specific Translation Evaluation", "author": ["Michael Denkowski", "Alon Lavie"], "venue": null, "citeRegEx": "Denkowski and Lavie.,? \\Q2014\\E", "shortCiteRegEx": "Denkowski and Lavie.", "year": 2014}, {"title": "Dependency tree based sentence compression", "author": ["K. Filippova", "M. Strube."], "venue": "Proceedings of the Fifth International Natural Language Generation Conference (INLG)).", "citeRegEx": "Filippova and Strube.,? 2008", "shortCiteRegEx": "Filippova and Strube.", "year": 2008}, {"title": "Incorporating non-local information into information extraction systems by gibbs sampling", "author": ["Jenny Rose Finkel", "Trond Grenager", "Christopher Manning."], "venue": "Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL \u201905,", "citeRegEx": "Finkel et al\\.,? 2005", "shortCiteRegEx": "Finkel et al\\.", "year": 2005}, {"title": "Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation", "author": ["J. Ganitkevitch", "C. Callison-Burch", "C. Napoles", "B. Van Durme."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Ganitkevitch et al\\.,? 2011", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2011}, {"title": "PPDB: The paraphrase database", "author": ["Juri Ganitkevitch", "Benjamin Van Durme", "Chris Callison-Burch."], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo-", "citeRegEx": "Ganitkevitch et al\\.,? 2013", "shortCiteRegEx": "Ganitkevitch et al\\.", "year": 2013}, {"title": "A Dataset of syntactic-Ngrams over Time from a Very Large Corpus of English Books", "author": ["Yoav Goldberg", "Jon Orwant."], "venue": "Second Joint Conference on Lexical and Computational Semantics (* SEM), volume 1, pages 241\u2013247.", "citeRegEx": "Goldberg and Orwant.,? 2013", "shortCiteRegEx": "Goldberg and Orwant.", "year": 2013}, {"title": "Movie script summarization as graph-based scene extraction", "author": ["Philip John Gorinski", "Mirella Lapata."], "venue": "Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL.", "citeRegEx": "Gorinski and Lapata.,? 2015", "shortCiteRegEx": "Gorinski and Lapata.", "year": 2015}, {"title": "What happens next? event prediction using a compositional neural network model", "author": ["Mark Granroth-Wilding", "Stephen Clark."], "venue": "Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI-16), Phoenix, Arizona.", "citeRegEx": "Granroth.Wilding and Clark.,? 2016", "shortCiteRegEx": "Granroth.Wilding and Clark.", "year": 2016}, {"title": "The Effect of Personalized Word Problems", "author": ["Janis M Hart."], "venue": "Teaching Children Mathematics, 2(8):504\u2013 505.", "citeRegEx": "Hart.,? 1996", "shortCiteRegEx": "Hart.", "year": 1996}, {"title": "KenLM: Faster and smaller language model queries", "author": ["Kenneth Heafield."], "venue": "Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT \u201911, pages 187\u2013197, Stroudsburg, PA, USA. Association for Computational Linguistics.", "citeRegEx": "Heafield.,? 2011", "shortCiteRegEx": "Heafield.", "year": 2011}, {"title": "Learning to Solve Arithmetic Word Problems with Verb Categorization", "author": ["Mohammad Javad Hosseini", "Hannaneh Hajishirzi", "Oren Etzioni", "Nate Kushman."], "venue": "EMNLP, pages 523\u2013533.", "citeRegEx": "Hosseini et al\\.,? 2014", "shortCiteRegEx": "Hosseini et al\\.", "year": 2014}, {"title": "How well do computers", "author": ["Danqing Huang", "Shuming Shi", "Chin-Yew Lin", "Jian Yin", "Wei-Ying Ma"], "venue": null, "citeRegEx": "Huang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2016}, {"title": "Aligning Sentences from Standard Wikipedia to Simple Wikipedia", "author": ["William Hwang", "Hannaneh Hajishirzi", "Mari Ostendorf", "Wei Wu."], "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).", "citeRegEx": "Hwang et al\\.,? 2015", "shortCiteRegEx": "Hwang et al\\.", "year": 2015}, {"title": "Improving text simplification language modeling using unsimplified text data", "author": ["David Kauchak."], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL).", "citeRegEx": "Kauchak.,? 2013", "shortCiteRegEx": "Kauchak.", "year": 2013}, {"title": "Parsing Algebraic Word Problems into Equations", "author": ["Rik Koncel-Kedziorski", "Hannaneh Hajishirzi", "Ashish Sabharwal", "Oren Etzioni", "Siena Ang."], "venue": "TACL, 3.", "citeRegEx": "Koncel.Kedziorski et al\\.,? 2015a", "shortCiteRegEx": "Koncel.Kedziorski et al\\.", "year": 2015}, {"title": "Parsing algebraic word problems into equations", "author": ["Rik Koncel-Kedziorski", "Hannaneh Hajishirzi", "Ashish Sabharwal", "Oren Etzioni", "Siena Ang."], "venue": "Transactions of the Association for Computational Linguistics, 3:585\u2013597.", "citeRegEx": "Koncel.Kedziorski et al\\.,? 2015b", "shortCiteRegEx": "Koncel.Kedziorski et al\\.", "year": 2015}, {"title": "MAWPS: A Math Word Problem Repository", "author": ["Rik Koncel-Kedziorski", "Subhro Roy", "Aida Aimini", "Nate Kushman", "Hannaneh Hajishirzi."], "venue": "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Hu-", "citeRegEx": "Koncel.Kedziorski et al\\.,? 2016", "shortCiteRegEx": "Koncel.Kedziorski et al\\.", "year": 2016}, {"title": "Learning to Automatically Solve Algebra Word Problems", "author": ["Nate Kushman", "Yoav Artzi", "Luke Zettlemoyer", "Regina Barzilay."], "venue": "ACL, pages 271\u2013 281.", "citeRegEx": "Kushman et al\\.,? 2014", "shortCiteRegEx": "Kushman et al\\.", "year": 2014}, {"title": "A Fast and Portable Realizer for Text Generation Systems", "author": ["Benoit Lavoie", "Owen Rambow."], "venue": "Proceedings of the fifth conference on Applied natural language processing, pages 265\u2013268. Association for Computational Linguistics.", "citeRegEx": "Lavoie and Rambow.,? 1997", "shortCiteRegEx": "Lavoie and Rambow.", "year": 1997}, {"title": "Planning Stories", "author": ["Michael Lebowitz."], "venue": "Proceedings of the cognitive science society, Hillsdale, pages 234\u2013242.", "citeRegEx": "Lebowitz.,? 1987", "shortCiteRegEx": "Lebowitz.", "year": 1987}, {"title": "DependencyBased Word Embeddings", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "ACL, pages 302\u2013308.", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "Story generation with crowdsourced plot graphs", "author": ["Boyang Li", "Stephen Lee-Urban", "George Johnston", "Mark O. Riedl."], "venue": "Proceedings of AAAI Conferece on Artificial Intelligence (AAAI).", "citeRegEx": "Li et al\\.,? 2013", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "MAKEBELIEVE: Using Commonsense Knowledge to Generate Stories", "author": ["Hugo Liu", "Push Singh."], "venue": "AAAI/IAAI, pages 957\u2013958.", "citeRegEx": "Liu and Singh.,? 2002", "shortCiteRegEx": "Liu and Singh.", "year": 2002}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky."], "venue": "Proceedings of the Conference of the Association for Computational Linguistics: System", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Learning to Tell Tales: A Data-driven Approach to Story Generation", "author": ["Neil McIntyre", "Mirella Lapata."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Pro-", "citeRegEx": "McIntyre and Lapata.,? 2009", "shortCiteRegEx": "McIntyre and Lapata.", "year": 2009}, {"title": "Plot Induction and Evolutionary Search for Story Generation", "author": ["Neil McIntyre", "Mirella Lapata."], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1562\u20131572. Association for Computational Linguistics.", "citeRegEx": "McIntyre and Lapata.,? 2010", "shortCiteRegEx": "McIntyre and Lapata.", "year": 2010}, {"title": "The Metanovel: Writing Stories by Computer", "author": ["James Richard Meehan."], "venue": "Technical report, DTIC Document.", "citeRegEx": "Meehan.,? 1976", "shortCiteRegEx": "Meehan.", "year": 1976}, {"title": "Efficient Estimation of Word Representations in Vector Space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "WordNet: A Lexical Database for English", "author": ["George A Miller."], "venue": "Communications of the ACM, 38(11):39\u2013", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Learning to automatically solve logic grid puzzles", "author": ["Arindam Mitra", "Chitta Baral."], "venue": "EMNLP.", "citeRegEx": "Mitra and Baral.,? 2015", "shortCiteRegEx": "Mitra and Baral.", "year": 2015}, {"title": "A corpus and evaluation framework for deeper understanding of commonsense stories", "author": ["Nasrin Mostafazadeh", "Nathanael Chambers", "Xiaodong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen."], "venue": "Proceedings of the 2016", "citeRegEx": "Mostafazadeh et al\\.,? 2016", "shortCiteRegEx": "Mostafazadeh et al\\.", "year": 2016}, {"title": "Text simplification for langauge learners: A corpus analysis", "author": ["Sarah Petersen", "Mari Ostendorf."], "venue": "Proceedings of the Speech and Language Technology in Education Workshop (SLaTE).", "citeRegEx": "Petersen and Ostendorf.,? 2007", "shortCiteRegEx": "Petersen and Ostendorf.", "year": 2007}, {"title": "Learning statistical scripts with LSTM recurrent neural networks", "author": ["Karl Pichotta", "Raymond J. Mooney."], "venue": "Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI-16), Phoenix, Arizona.", "citeRegEx": "Pichotta and Mooney.,? 2016", "shortCiteRegEx": "Pichotta and Mooney.", "year": 2016}, {"title": "Personalized Mathematical Word Problem Generation", "author": ["Oleksandr Polozov", "Eleanor ORourke", "Adam M Smith", "Luke Zettlemoyer", "Sumit Gulwani", "Zoran Popovic."], "venue": "Proceedings of the 24th International Joint Conference on Artificial Intelligence", "citeRegEx": "Polozov et al\\.,? 2015", "shortCiteRegEx": "Polozov et al\\.", "year": 2015}, {"title": "Individual interest as context in expository text and mathematical word problems", "author": ["KA Renninger", "L Ewen", "AK Lasher."], "venue": "Learning and Instruction, 12(4):467\u2013490.", "citeRegEx": "Renninger et al\\.,? 2002", "shortCiteRegEx": "Renninger et al\\.", "year": 2002}, {"title": "Solving General Arithmetic Word Problems", "author": ["Subhro Roy", "Dan Roth."], "venue": "EMNLP.", "citeRegEx": "Roy and Roth.,? 2015", "shortCiteRegEx": "Roy and Roth.", "year": 2015}, {"title": "2016. Equation parsing : Mapping sentences to grounded", "author": ["Subhro Roy", "Shyam Upadhyay", "Dan Roth"], "venue": null, "citeRegEx": "Roy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Roy et al\\.", "year": 2016}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Alexander M Rush", "Sumit Chopra", "Jason Weston."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Rush et al\\.,? 2015", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Scripts, Plans, Goals, and Understanding: An Inquiry into Human Knowledge Structures", "author": ["Roger C Schank", "Robert P Abelson."], "venue": "Hillsdale, NJ: Lawrence Erlbaum.", "citeRegEx": "Schank and Abelson.,? 1977", "shortCiteRegEx": "Schank and Abelson.", "year": 1977}, {"title": "Diagram Understanding in Geometry Questions", "author": ["Min Joon Seo", "Hannaneh Hajishirzi", "Ali Farhadi", "Oren Etzioni."], "venue": "AAAI.", "citeRegEx": "Seo et al\\.,? 2014", "shortCiteRegEx": "Seo et al\\.", "year": 2014}, {"title": "Solving Geometry Problems: Combining Text and Diagram Interpretation", "author": ["Minjoon Seo", "Hannaneh Hajishirzi", "Ali Farhadi", "Oren Etzioni", "Clint Malcolm."], "venue": "EMNLP.", "citeRegEx": "Seo et al\\.,? 2015", "shortCiteRegEx": "Seo et al\\.", "year": 2015}, {"title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning", "author": ["Shuming Shi", "Yuehui Wang", "Chin-Yew Lin", "Xiaojiang Liu", "Yong Rui."], "venue": "EMNLP.", "citeRegEx": "Shi et al\\.,? 2015", "shortCiteRegEx": "Shi et al\\.", "year": 2015}, {"title": "Syntactic simplification and text cohesion", "author": ["Advaith Siddharthan."], "venue": "Research on Language and Computation, 4(1):77\u2013109.", "citeRegEx": "Siddharthan.,? 2004", "shortCiteRegEx": "Siddharthan.", "year": 2004}, {"title": "Minstrel: A Computer Model of Creativity and Storytelling", "author": ["Scott R Turner"], "venue": null, "citeRegEx": "Turner.,? \\Q1993\\E", "shortCiteRegEx": "Turner.", "year": 1993}, {"title": "Beyond sumbasic: Task-focused summarization with sentence simplification and lexical expansion", "author": ["Lucy Vanderwende", "Hisami Suzuki", "Chris Brockett", "Ani Nenkova."], "venue": "Information Processing and Management.", "citeRegEx": "Vanderwende et al\\.,? 2007", "shortCiteRegEx": "Vanderwende et al\\.", "year": 2007}, {"title": "Sentence simplification for semantic role labeling", "author": ["David Vickrey", "Daphne Koller."], "venue": "Proceedings of the Conference of the Association for Computational Linguistics (ACL), pages 344\u2013352.", "citeRegEx": "Vickrey and Koller.,? 2008", "shortCiteRegEx": "Vickrey and Koller.", "year": 2008}, {"title": "Learning to simplify sentences with quasi-synchronous grammar and integer programming", "author": ["Kristian Woodsend", "Mirella Lapata."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Woodsend and Lapata.,? 2011a", "shortCiteRegEx": "Woodsend and Lapata.", "year": 2011}, {"title": "Wikisimple: Automatic simplification of wikipedia articles", "author": ["Kristian Woodsend", "Mirella Lapata."], "venue": "Proceedings of the Association for Advancement of Artificial Intelligence Conference on Artificial Intelligence (AAAI), pages 927\u2013932, San Francisco, CA.", "citeRegEx": "Woodsend and Lapata.,? 2011b", "shortCiteRegEx": "Woodsend and Lapata.", "year": 2011}, {"title": "Sentence simplification by monolingual", "author": ["Sander Wubben", "Antal Van Den Bosch", "Emiel Krahmer"], "venue": null, "citeRegEx": "Wubben et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Wubben et al\\.", "year": 2012}, {"title": "Optimizing statistical machine translation for text simplification", "author": ["Wei Xu", "Courtney Napoles", "Ellie Pavlick", "Quanze Chen", "Chris Callison-Burch."], "venue": "Transactions of Association of Computational Linguistics.", "citeRegEx": "Xu et al\\.,? 2016", "shortCiteRegEx": "Xu et al\\.", "year": 2016}, {"title": "For the sake of simplicity: Unsupervised extraction of lexical simplifications from wikipedia", "author": ["Mark Yatskar", "Bo Pang", "Cristian Danescu-NiculescuMizil", "Lillian Lee."], "venue": "Proceedings of the Conference of the North American Chapter of the Associa-", "citeRegEx": "Yatskar et al\\.,? 2010", "shortCiteRegEx": "Yatskar et al\\.", "year": 2010}, {"title": "Learn to Solve Algebra Word Problems Using Quadratic Programming", "author": ["Lipu Zhou", "Shuaixiang Dai", "Liwei Chen."], "venue": "EMNLP.", "citeRegEx": "Zhou et al\\.,? 2015", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}, {"title": "A monolingual tree-based translation model for sentence simplification", "author": ["Zhemin Zhu", "Delphine Bernhard", "Iryna Gurevych."], "venue": "Proceedings of the International Conference on Computational Linguistics (COLING).", "citeRegEx": "Zhu et al\\.,? 2010", "shortCiteRegEx": "Zhu et al\\.", "year": 2010}], "referenceMentions": [{"referenceID": 0, "context": "Automatic storytelling systems can be used for customized sport commentaries, enriching video games with personalized or dynamic plot-lines (Barros and Musse, 2007), or providing customized learning materials which meet each individual student\u2019s needs and interests (Bartlett, 2004).", "startOffset": 140, "endOffset": 164}, {"referenceID": 1, "context": "Automatic storytelling systems can be used for customized sport commentaries, enriching video games with personalized or dynamic plot-lines (Barros and Musse, 2007), or providing customized learning materials which meet each individual student\u2019s needs and interests (Bartlett, 2004).", "startOffset": 266, "endOffset": 282}, {"referenceID": 14, "context": ", 2002), and personalizing word problems increases student understanding, engagement, and performance in the problem solving process (Hart, 1996; Davis-Dorsey et al., 1991).", "startOffset": 133, "endOffset": 172}, {"referenceID": 5, "context": ", 2002), and personalizing word problems increases student understanding, engagement, and performance in the problem solving process (Hart, 1996; Davis-Dorsey et al., 1991).", "startOffset": 133, "endOffset": 172}, {"referenceID": 30, "context": "Rather than synthesizing first a story plot (McIntyre and Lapata, 2009; McIntyre and Lapata, 2010) or script (Chambers and Jurafsky, 2009; Pichotta and", "startOffset": 44, "endOffset": 98}, {"referenceID": 31, "context": "Rather than synthesizing first a story plot (McIntyre and Lapata, 2009; McIntyre and Lapata, 2010) or script (Chambers and Jurafsky, 2009; Pichotta and", "startOffset": 44, "endOffset": 98}, {"referenceID": 30, "context": ", McIntyre and Lapata (2010)) and sentence rewriting (e.", "startOffset": 2, "endOffset": 29}, {"referenceID": 32, "context": "researchers (Meehan, 1976; Lebowitz, 1987; Turner, 1993; Liu and Singh, 2002; Mostafazadeh et al., 2016).", "startOffset": 12, "endOffset": 104}, {"referenceID": 25, "context": "researchers (Meehan, 1976; Lebowitz, 1987; Turner, 1993; Liu and Singh, 2002; Mostafazadeh et al., 2016).", "startOffset": 12, "endOffset": 104}, {"referenceID": 49, "context": "researchers (Meehan, 1976; Lebowitz, 1987; Turner, 1993; Liu and Singh, 2002; Mostafazadeh et al., 2016).", "startOffset": 12, "endOffset": 104}, {"referenceID": 28, "context": "researchers (Meehan, 1976; Lebowitz, 1987; Turner, 1993; Liu and Singh, 2002; Mostafazadeh et al., 2016).", "startOffset": 12, "endOffset": 104}, {"referenceID": 36, "context": "researchers (Meehan, 1976; Lebowitz, 1987; Turner, 1993; Liu and Singh, 2002; Mostafazadeh et al., 2016).", "startOffset": 12, "endOffset": 104}, {"referenceID": 25, "context": "researchers (Meehan, 1976; Lebowitz, 1987; Turner, 1993; Liu and Singh, 2002; Mostafazadeh et al., 2016). Recent methods in story generation first synthesize candidate plots for a story and then compile those plots into text. Li et al. (2013) use crowd-", "startOffset": 27, "endOffset": 243}, {"referenceID": 44, "context": "McIntyre and Lapata (2009; 2010) address story generation through the automatic deduction and reassembly of scripts (Schank and Abelson, 1977), or structured representations of events and their participants, and causal", "startOffset": 116, "endOffset": 142}, {"referenceID": 2, "context": "Leveraging the automatic script learning methods of Chambers and Jurafsky (2009), McIntyre and Lapata (2010) learn candidate entity-centered plot graphs, or possible events involving the entity and an ordering between these events, with the use of a genetic algorithm.", "startOffset": 52, "endOffset": 81}, {"referenceID": 2, "context": "Leveraging the automatic script learning methods of Chambers and Jurafsky (2009), McIntyre and Lapata (2010) learn candidate entity-centered plot graphs, or possible events involving the entity and an ordering between these events, with the use of a genetic algorithm.", "startOffset": 52, "endOffset": 109}, {"referenceID": 24, "context": "plots are compiled into stories through the use of a rule-based text surface realizer (Lavoie and Rambow, 1997) and reranked using a language model.", "startOffset": 86, "endOffset": 111}, {"referenceID": 54, "context": "2 Additionally, there is related work in text simplification (Wubben et al., 2012; Kauchak, 2013; Zhu et al., 2010; Vanderwende et al., 2007; Woodsend and Lapata, 2011b; Hwang et al., 2015), sentence", "startOffset": 61, "endOffset": 189}, {"referenceID": 19, "context": "2 Additionally, there is related work in text simplification (Wubben et al., 2012; Kauchak, 2013; Zhu et al., 2010; Vanderwende et al., 2007; Woodsend and Lapata, 2011b; Hwang et al., 2015), sentence", "startOffset": 61, "endOffset": 189}, {"referenceID": 58, "context": "2 Additionally, there is related work in text simplification (Wubben et al., 2012; Kauchak, 2013; Zhu et al., 2010; Vanderwende et al., 2007; Woodsend and Lapata, 2011b; Hwang et al., 2015), sentence", "startOffset": 61, "endOffset": 189}, {"referenceID": 50, "context": "2 Additionally, there is related work in text simplification (Wubben et al., 2012; Kauchak, 2013; Zhu et al., 2010; Vanderwende et al., 2007; Woodsend and Lapata, 2011b; Hwang et al., 2015), sentence", "startOffset": 61, "endOffset": 189}, {"referenceID": 53, "context": "2 Additionally, there is related work in text simplification (Wubben et al., 2012; Kauchak, 2013; Zhu et al., 2010; Vanderwende et al., 2007; Woodsend and Lapata, 2011b; Hwang et al., 2015), sentence", "startOffset": 61, "endOffset": 189}, {"referenceID": 18, "context": "2 Additionally, there is related work in text simplification (Wubben et al., 2012; Kauchak, 2013; Zhu et al., 2010; Vanderwende et al., 2007; Woodsend and Lapata, 2011b; Hwang et al., 2015), sentence", "startOffset": 61, "endOffset": 189}, {"referenceID": 22, "context": "plots are compiled into stories through the use of a rule-based text surface realizer (Lavoie and Rambow, 1997) and reranked using a language model. Polozov et al. (2015) automatically generate math word problems tailored to a student\u2019s interest using Answer Set Programming to satisfy a collection of pedagogical and narrative requirements.", "startOffset": 87, "endOffset": 171}, {"referenceID": 39, "context": "According to Polozov et al. (2015) building small thematic ontologies of types, relations, and discourse tropes (100-200 entries) for each of only 3 literary settings took 1-2 person months.", "startOffset": 13, "endOffset": 35}, {"referenceID": 7, "context": "compression (Filippova and Strube, 2008; Rush et al., 2015), and paraphrasing (Ganitkevitch et al.", "startOffset": 12, "endOffset": 59}, {"referenceID": 43, "context": "compression (Filippova and Strube, 2008; Rush et al., 2015), and paraphrasing (Ganitkevitch et al.", "startOffset": 12, "endOffset": 59}, {"referenceID": 10, "context": ", 2015), and paraphrasing (Ganitkevitch et al., 2013; Chen and Dolan, 2011; Ganitkevitch et al., 2011).", "startOffset": 26, "endOffset": 102}, {"referenceID": 3, "context": ", 2015), and paraphrasing (Ganitkevitch et al., 2013; Chen and Dolan, 2011; Ganitkevitch et al., 2011).", "startOffset": 26, "endOffset": 102}, {"referenceID": 9, "context": ", 2015), and paraphrasing (Ganitkevitch et al., 2013; Chen and Dolan, 2011; Ganitkevitch et al., 2011).", "startOffset": 26, "endOffset": 102}, {"referenceID": 36, "context": "Different rule-based and data-driven approaches are introduced by Petersen and Ostendorf (2007), Vickrey and Koller (2008), and Siddharthan (2004).", "startOffset": 66, "endOffset": 96}, {"referenceID": 36, "context": "Different rule-based and data-driven approaches are introduced by Petersen and Ostendorf (2007), Vickrey and Koller (2008), and Siddharthan (2004).", "startOffset": 66, "endOffset": 123}, {"referenceID": 14, "context": "Different rule-based and data-driven approaches are introduced by Petersen and Ostendorf (2007), Vickrey and Koller (2008), and Siddharthan (2004). Most data-driven approaches take advantage", "startOffset": 132, "endOffset": 147}, {"referenceID": 56, "context": "of machine translation techniques, use source-target sentence pairs, and learn rewrite operations (Yatskar et al., 2010; Woodsend and Lapata, 2011a), or use additional external paraphrasing resources (Xu et al.", "startOffset": 98, "endOffset": 148}, {"referenceID": 52, "context": "of machine translation techniques, use source-target sentence pairs, and learn rewrite operations (Yatskar et al., 2010; Woodsend and Lapata, 2011a), or use additional external paraphrasing resources (Xu et al.", "startOffset": 98, "endOffset": 148}, {"referenceID": 55, "context": ", 2010; Woodsend and Lapata, 2011a), or use additional external paraphrasing resources (Xu et al., 2016).", "startOffset": 87, "endOffset": 104}, {"referenceID": 47, "context": "Specific topics include number word problems (Shi et al., 2015), logic puzzle problems (Mitra and Baral, 2015), arithmetic word problems (Hosseini et al.", "startOffset": 45, "endOffset": 63}, {"referenceID": 35, "context": ", 2015), logic puzzle problems (Mitra and Baral, 2015), arithmetic word problems (Hosseini et al.", "startOffset": 31, "endOffset": 54}, {"referenceID": 23, "context": "2014; Roy and Roth, 2015), algebra word problems (Kushman et al., 2014; Zhou et al., 2015; Koncel-Kedziorski et al., 2015a; Roy et al., 2016), and geometry word problems (Seo et al.", "startOffset": 49, "endOffset": 141}, {"referenceID": 57, "context": "2014; Roy and Roth, 2015), algebra word problems (Kushman et al., 2014; Zhou et al., 2015; Koncel-Kedziorski et al., 2015a; Roy et al., 2016), and geometry word problems (Seo et al.", "startOffset": 49, "endOffset": 141}, {"referenceID": 20, "context": "2014; Roy and Roth, 2015), algebra word problems (Kushman et al., 2014; Zhou et al., 2015; Koncel-Kedziorski et al., 2015a; Roy et al., 2016), and geometry word problems (Seo et al.", "startOffset": 49, "endOffset": 141}, {"referenceID": 42, "context": "2014; Roy and Roth, 2015), algebra word problems (Kushman et al., 2014; Zhou et al., 2015; Koncel-Kedziorski et al., 2015a; Roy et al., 2016), and geometry word problems (Seo et al.", "startOffset": 49, "endOffset": 141}, {"referenceID": 46, "context": ", 2016), and geometry word problems (Seo et al., 2015; Seo et al., 2014).", "startOffset": 36, "endOffset": 72}, {"referenceID": 45, "context": ", 2016), and geometry word problems (Seo et al., 2015; Seo et al., 2014).", "startOffset": 36, "endOffset": 72}, {"referenceID": 22, "context": "available (Koncel-Kedziorski et al., 2016; Huang et al., 2016), though none address the need for thematic text.", "startOffset": 10, "endOffset": 62}, {"referenceID": 17, "context": "available (Koncel-Kedziorski et al., 2016; Huang et al., 2016), though none address the need for thematic text.", "startOffset": 10, "endOffset": 62}, {"referenceID": 34, "context": "Specifically, we consider semantic relations for noun-noun and verb-verb pairs as provided by WordNet (Miller, 1995).", "startOffset": 102, "endOffset": 116}, {"referenceID": 33, "context": "The Analogy function, inspired by Mikolov et al. (2013), computes the analogy of w\u2032 j fromw\u2032 i given the relationship that holds betweenwi and wj in the vector space.", "startOffset": 34, "endOffset": 56}, {"referenceID": 29, "context": "Implementation Details We pre-process the themes using the Stanford CoreNLP tools (Manning et al., 2014) for tokenization, Named Entity Recognition (Finkel et al.", "startOffset": 82, "endOffset": 104}, {"referenceID": 8, "context": ", 2014) for tokenization, Named Entity Recognition (Finkel et al., 2005), and dependency", "startOffset": 51, "endOffset": 72}, {"referenceID": 4, "context": "parsing (Chen and Manning, 2014).", "startOffset": 8, "endOffset": 32}, {"referenceID": 12, "context": "For calculating salience scores, we use the ScriptBase dataset of movie scripts (Gorinski and Lapata, 2015).", "startOffset": 80, "endOffset": 107}, {"referenceID": 21, "context": "To prohibit overgeneration, we forbid the transformation of stop words or math-specific words (Survivors, 2013; Koncel-Kedziorski et al., 2015b).", "startOffset": 94, "endOffset": 144}, {"referenceID": 11, "context": "tion 4) we use the English Fiction subset of the Google Syntactic N-grams corpus (Goldberg and Orwant, 2013) and train a 3-gram language model using KenLM (Heafield, 2011).", "startOffset": 81, "endOffset": 108}, {"referenceID": 15, "context": "tion 4) we use the English Fiction subset of the Google Syntactic N-grams corpus (Goldberg and Orwant, 2013) and train a 3-gram language model using KenLM (Heafield, 2011).", "startOffset": 155, "endOffset": 171}, {"referenceID": 6, "context": "Finally, we tune the parameters of our model (Equation 2) on the development set STARdev and pick those values5 that maximize METEOR score (Denkowski and Lavie, 2014) against 3 human references.", "startOffset": 139, "endOffset": 166}, {"referenceID": 25, "context": "the pretrained word embeddings of Levy and Goldberg (2014). These embeddings are trained using dependency contexts rather than windows of adjacent words, allowing them to capture functional word similarity.", "startOffset": 34, "endOffset": 59}], "year": 2016, "abstractText": "Texts present coherent stories that have a particular theme or overall setting, for example science fiction or western. In this paper, we present a text generation method called rewriting that edits existing human-authored narratives to change their theme without changing the underlying story. We apply the approach to math word problems, where it might help students stay more engaged by quickly transforming all of their homework assignments to the theme of their favorite movie without changing the math concepts that are being taught. Our rewriting method uses a twostage decoding process, which proposes new words from the target theme and scores the resulting stories according to a number of factors defining aspects of syntactic, semantic, and thematic coherence. Experiments demonstrate that the final stories typically represent the new theme well while still testing the original math concepts, outperforming a number of baselines. We also release a new dataset of human-authored rewrites of math word problems in several themes.", "creator": "LaTeX with hyperref package"}}}