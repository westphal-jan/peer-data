{"id": "1610.06525", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Oct-2016", "title": "ChoiceRank: Identifying Preferences from Node Traffic in Networks", "abstract": "Understanding how users navigate in a network is of high interest in many applications. We consider a setting where only aggregate node-level traffic is observed and tackle the task of learning edge transition probabilities. We cast it as a preference learning problem, and we study a model where choices follow Luce's axiom. In this case, the $O(n)$ marginal counts of node visits are a sufficient statistic for the $O(n^2)$ transition probabilities. We show how to make the inference problem well-posed regardless of the network's structure, and we present ChoiceRank, an iterative algorithm that scales to networks that contains billions of nodes and edges. We apply the model to a month-long clickstream of the English Wikipedia and one year of rides on New York City's bicycle-sharing system. In both cases, we successfully recover the transition probabilities using only the network structure and marginal (node-level) traffic data.", "histories": [["v1", "Thu, 20 Oct 2016 18:19:07 GMT  (118kb,D)", "https://arxiv.org/abs/1610.06525v1", null], ["v2", "Thu, 15 Jun 2017 15:14:54 GMT  (104kb,D)", "http://arxiv.org/abs/1610.06525v2", "Accepted at ICML 2017"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG cs.SI", "authors": ["lucas maystre", "matthias grossglauser"], "accepted": true, "id": "1610.06525"}, "pdf": {"name": "1610.06525.pdf", "metadata": {"source": "CRF", "title": "ChoiceRank: Identifying Preferences from Node Traffic in Networks", "authors": ["Lucas Maystre", "Matthias Grossglauser"], "emails": ["lucas.maystre@epfl.ch", "matthias.grossglauser@epfl.ch"], "sections": [{"heading": "1 Introduction", "text": "We are looking at the problem of estimating the likelihood of clicking on links between pages of a website. We are looking at the actual amount of information about the number of visits to each page. Naively, one might expect that the probability of clicking on a particular link should be roughly proportional to the traffic of the link destination. However, this neglects important structural effects: traffic on a page is influenced by the number of incoming links, b) the traffic on the pages pointing to it, and c) the traffic absorbed by competing links. Therefore, in order to successfully infer the likelihood of clicking, it is necessary to unravel the preferences for a page (i.e., the intrinsic tendency of a user to click on a link pointing to it). We get exposure from pages linking to it. Building on recent work by Kumar et al. [2015] we present a statistical framework that addresses a general formulation of the problem."}, {"heading": "2 Network Choice Model", "text": "Let G = (V, E) be a directed graph on n nodes (corresponding to item) and m edges. We denote the out neighborhood of the node i by N + i and its in neighborhood by N \u2212 i. We consider the following selection process on G. A user starts at a node i and stands in front of alternatives N + i. The user selects item j and moves to the corresponding node. At node j the user stands in front of alternatives N + j and selects k etc. At any time the user can stop. Figure 1 gives an example of a graph and the alternatives available in one step of the process. To define the transition probabilities, we set Luce's well-known selection axiom, which states that the probability of choosing item over item j does not depend on the rest of the alternatives [Luce, 1959]. This axiom leads to a unique probability model of choice."}, {"heading": "3 Related Work", "text": "A variant of the network selection model was recently presented by Kumar et al. [2015], in an article that lays much of the groundwork for the present paper. Their generative traffic model and the parameterization of transition probabilities based on Luce's axiom form the basis of our work. Kumar et al. define the equilibrium state reversal problem as follows: Faced with a diagram G and a destination-stationary distribution, you will find transition probabilities that lead to the desired stationary distribution. This formulation of the problem assumes that G satisfies restrictive structural properties (strong networking, aperiodicity) and is only asymptotically valid when the sequences of user decisions are very long. Our formulation, on the other hand, is that we eliminate all assumptions about the structure of G and deal with finite data in a principled way."}, {"heading": "4 Statistical Properties", "text": "In this section, we describe some important statistical properties of the network selection model. We begin by observing that O (n) values summarizing traffic at each node are sufficient statistics for the O (n2) entries of the Markov chain transition matrix. Then, we link our statistical model to the stationary inversion problem defined by Kumar et al. [2015]. Guided by this context, we examine the estimation of the model parameters with maximum probability (ML), but find that the estimate is likely to be inaccurate in many scenarios of practical interest. Finally, we examine how this problem can be overcome by introducing a prior distribution of parameters \u03bb; the previous guarantees that the follow-up problem is well positioned. To simplify exposure, we present our results for the standard Luce selection model defined in (1). Our developments extend to the model variant proposed by Kumar et al. [2015], which we can describe the probability weights of adjustments by our modulations."}, {"heading": "4.1 Aggregate Traffic Is a Sufficient Statistic", "text": "Let cij specify the number of transitions that took place along the edge gradient (i, j). Based on the transition probability defined in (1), we can define the log probability of the specified data D = (i, j) \"E\" as \"(\u03bb; D) = (i, j)\" Ecij \"(log)\" Log \"(c)\" N + i \"(c)\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c\" c \"c."}, {"heading": "4.2 Connection to the Steady-State Inversion Problem", "text": "In the most recent work, Kumar et al. [2015] define the problem of stationary inversion as follows: In the face of a strongly coherent directed diagram G = (V, E) and a target distribution across nodes \u03c0, you find a Markov chain on G with stationary distribution \u03c0. Since there are m = O (n2) degrees of freedom (the transition probabilities) for n constraints (the stationary distribution), the problem is underlined in most cases. Following Luce's concepts, the transition probabilities must be proportional to a latent value of the target node according to (1), whereby the number of parameters from m to n denote of P (s) is the Markov chain transition parameterized version with values s. The score vector s is a solution to the stationary inversion problem if and only if the quantity inversion is c."}, {"heading": "4.3 Maximum-Likelihood Estimate", "text": "The protocol probability (2) is not concave in \u03bb, but it can be made concave by simple repair \u03bbi = e\u03b8i. Therefore, any local minimum of probability is a global minimum. Unfortunately, it turns out that the conditions that guarantee that the ML estimate is well defined (i.e. that it exists and is unique) are restrictive and impractical. We illustrate this by providing a necessary condition, and shortly we will postpone the comprehensive analysis of the ML estimate in Appendix B. We start with a definition that uses the term hypergraph, a generalized diagram in which edges represent a non-empty subset of nodes. Definition (Comparison Hypergraph G = (V, E), the comparison Hypergraph H = (V, A), which uses the term hypergraph, is a hypergraph where the term hypergraph H = N + i | i,} is induced by the intuitive hypergraph of the alternatives."}, {"heading": "4.4 Well-Posed Inference", "text": "Following the ideas of Caron and Doucet [2012], we introduce an independent gamma before each parameter, i.e., we can log the log-posterior aslog p (\u03bb | D) = n \u2211 i = 1 [(c \u2212 i + \u03b1 \u2212 1). Adding the log-before the log probability, we can log the log-posterior aslog p (\u03bb | D) = n \u2211 i = 1 [c \u2212 i + \u03b1 \u2212 1). The log-before the log probability has a positive effect, as the following theorem shows. Theorem 2. If the log-before the log probability is (5) where it is a constant that is independent of \u03bb. The gamma precedent translates into a form of regulation that makes the inference problem well posed, as the following theorem shows. Theorem 2. If i.i.d. \u03bb1,"}, {"heading": "5 Inference Algorithm", "text": "In the spirit of Hunter's algorithms [2004] for variants of the Luce election model, we are developing a minimization-maximization algorithm (MM). Simply put, the algorithm iteratively refines an estimate of the maximizer by solving a sequence of surrogates of the log posterior. If we use the isolation protocol x-x / x-1 (with equality if and only if x-x), we can solve the log posterior (5) by solving surrogates of the log posterior (t) (t) (n-i). Let us use the isolation protocol x-x-x-x-x-1 (with equality, only if x-x-x-x-x), which we call the log posterior (5) (t)."}, {"heading": "6 Experimental Evaluation", "text": "In this section, we examine a) the ability of the network selection model to accurately restore transitions in real-world scenarios, and b) the potential of ChoiceRank to scale to very large networks."}, {"heading": "6.1 Accuracy on Real-World Data", "text": "We evaluate the network selection model using three sets of data representative of two different application areas. Each set can be represented as a set of transition numbers using a directed graph G = (V, E). We aggregate the transition numbers into marginal traffic data {(c \u2212 i, c + i) and adjust a network selection model using ChoiceRank. We set \u03b1 = 2.0 and \u03b2 = 1.0 (these small values simply guarantee the convergence of the algorithm) and explain convergence when we specify the convergence of quantum selection (t) (t \u2212 1). (n < 10 \u2212 8. With this in mind, we estimate the transition probabilities from quantum selection based on quantum selection and quantum selection based on quantum selection."}, {"heading": "6.1.1 Clickstream Data", "text": "The Wikimedia Foundation has a long history of publicly sharing aggregated, page-based web traffic datas1. Recently, it also released clickstream data from the English version of Wikipedia [Wulczyn and Taraborelli, 2016], which provide us with essential ground truth transition level data. We are looking at a data set that contains information extracted from server logs about traffic on each page of English Wikipedia during the month of March 2016. Each page of incoming traffic is grouped by HTTP referees, i.e. from the page visited prior to the request. We ignore traffic generated by external sites such as search engines and only hold internal traffic (18% of all traffic in the dataset). In summary, we get counts of transitions on the hyperlink graph of English Wikipedia articles. The graph contains n = 2316 032 nodes and m = 13 181 698 edges, and we are looking at slightly more than 1.2 billion transitions over the edges."}, {"heading": "6.1.2 NYC Bicycle-Sharing Data", "text": "Next, we look at the route data from Citi Bike, the bicycle rental system of New York City3. For each ride on the system that was performed in 2015, we extract the pick-up and drop-off points and the duration of the ride. As we want to focus on direct rides, we exclude rides that take longer than an hour. We also exclude pairs between source and destination that average less than 1 ride per day (most of the source-destination pairs appear at least once in the dataset).The resulting data consists of 3.4 million rides on a graph that contains n = 497 nodes and m = 5209 edges. ChoiceRank converges after 7508 iterations. We calculate the error distribution in the same way as for the Clickstream datasets. The two most right-hand charts in Figure 4 show the results. The observations made on the Clickstream dataset transfer to this mobility dataset, though to a lesser extent the transition is available there between a significant link between a bicycle network and a click."}, {"heading": "6.2 Scaling ChoiceRank to Billions of Nodes", "text": "To demonstrate scalability, we are developing a simple implementation in the Rust programming language, based on the ideas of COST [McSherry et al., 2015] Our code is available online. It repeats edges from the hard disk and keeps four floating-point values per node in memory: the number of messages and the sum of messages. Therefore, the list of edges and the way they are used in iteration will be beneficial. As edges can be processed in any order, it may be advantageous to rearrange the edges in a way that speeds up compatibility. Therefore, we will perform the list of edges and reorders in Hilbert Curve order5. This results in better cache locality and results in a significant speeddup.We are testing our implementation on a hypergraph extracted from the 2012 Common Crawl Web corpus6."}, {"heading": "7 Conclusion", "text": "In this paper, we present a method that addresses the problem of determining transition probabilities along the margins of a network, taking into account only the structure of the network and aggregated traffic data at the node level. This method generalizes and expands ideas recently presented by Kumar et al. [2015]. We show that, despite the strong model assumptions required to learn O (n2) probabilities from O (n) observations, the method still manages to attribute transition probabilities to two clickstream datasets with a good degree of accuracy, and is promising for applications beyond clickstream data. In summary, we believe that our method will be useful for practitioners interested in understanding navigation patterns in networks from aggregated traffic data that are widely available, e.g. in public datasets. We thank Holly Cogliati-Bauereis, Ksenia Konyushkova, Brunelli Spinella, and anonymous readers for providing helpful corrective comments."}, {"heading": "A Extensions and Proofs", "text": "In this section we begin by generalizing the network selection model to take into account the edge weights. Then we present formal evidence for a) the (minimal) sufficiency of the edge weights and b) the effectiveness of the MAP conclusions in the general weighted network selection model. (1) The generalization of the model G = (V, E) is a weighted, directed graph with edge weights weij > 0 for all (i, j). (7) We refer to this model as Luce's weighted network selection model. Faced with a parameter vector vector Rn > 0, define the selection probabilities sought in the respective edge weights. (7) We refer to this model as the weighted network selection model. Intuitively, the strength of each alternative is weighted by the respective edge weight; Luce's original choicemodel is achieved by the constant."}, {"heading": "B Maximum-Likelihood Estimation", "text": "In this section we will go into the analysis of the ML estimator in depth. From the definition of the election probabilities in (7) it is clear that the probability is invariable to recalculate the parameters, i.e. that the ML estimation is well defined, so we will expand the definition of comparison hypergraphy in Section 4.3.Definition (comparison diagram). Let G = (V, E) is a directional graph and {aij) is a condition that guarantees that the ML estimation is well defined, let us expand the definition of comparison hypergraphy presented in Section 4.3.Definition (comparison diagram). Let G = (V, E) is a directional graph and {aij) is not a negative number."}, {"heading": "C ChoiceRank Algorithm", "text": "In this section, we begin by generalizing the ChoiceRank algorithm to the weighted network choice model. We then demonstrate the convergence of this generalized algorithm. Finally, we show how the same algorithm can be achieved from an EM point of view by introducing appropriate latent variables."}], "references": [{"title": "Generalized Method-of-Moments for Rank Aggregation", "author": ["H. Azari Soufiani", "W.Z. Chen", "D.C. Parkes", "L. Xia"], "venue": "NIPS", "citeRegEx": "Soufiani et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Soufiani et al\\.", "year": 2013}, {"title": "Rank Analysis of Incomplete Block Designs: I", "author": ["R.A. Bradley", "M.E. Terry"], "venue": "The Method of Paired Comparisons. Biometrika,", "citeRegEx": "Bradley and Terry.,? \\Q1952\\E", "shortCiteRegEx": "Bradley and Terry.", "year": 1952}, {"title": "The Anatomy of a Large-Scale Hypertextual Web Search Engine", "author": ["S. Brin", "L. Page"], "venue": "In WWW\u201998,", "citeRegEx": "Brin and Page.,? \\Q1998\\E", "shortCiteRegEx": "Brin and Page.", "year": 1998}, {"title": "Efficient Bayesian Inference for Generalized Bradley\u2013Terry models", "author": ["F. Caron", "A. Doucet"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "Caron and Doucet.,? \\Q2012\\E", "shortCiteRegEx": "Caron and Doucet.", "year": 2012}, {"title": "Statistical Inference", "author": ["G. Casella", "R.L. Berger"], "venue": "Duxbury Press, second edition,", "citeRegEx": "Casella and Berger.,? \\Q2002\\E", "shortCiteRegEx": "Casella and Berger.", "year": 2002}, {"title": "On Positive Solutions of a System of Linear Equations", "author": ["L.L. Dines"], "venue": "Annals of Mathematics,", "citeRegEx": "Dines.,? \\Q1926\\E", "shortCiteRegEx": "Dines.", "year": 1926}, {"title": "The Rating Of Chess Players", "author": ["A. Elo"], "venue": "Past & Present. Arco,", "citeRegEx": "Elo.,? \\Q1978\\E", "shortCiteRegEx": "Elo.", "year": 1978}, {"title": "Graphx: Graph Processing in a Distributed Dataflow Framework", "author": ["J.E. Gonzalez", "R.S. Xin", "A. Dave", "D. Crankshaw", "M.J. Franklin", "I. Stoica"], "venue": "In OSDI\u201914,", "citeRegEx": "Gonzalez et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Gonzalez et al\\.", "year": 2014}, {"title": "Minimax-optimal Inference from Partial Rankings", "author": ["B. Hajek", "S. Oh", "J. Xu"], "venue": "NIPS", "citeRegEx": "Hajek et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hajek et al\\.", "year": 2014}, {"title": "Classification by pairwise coupling", "author": ["T. Hastie", "R. Tibshirani"], "venue": "The Annals of Statistics,", "citeRegEx": "Hastie and Tibshirani.,? \\Q1998\\E", "shortCiteRegEx": "Hastie and Tibshirani.", "year": 1998}, {"title": "MM algorithms for generalized Bradley\u2013Terry models", "author": ["D.R. Hunter"], "venue": "The Annals of Statistics,", "citeRegEx": "Hunter.,? \\Q2004\\E", "shortCiteRegEx": "Hunter.", "year": 2004}, {"title": "Inverting a Steady-State", "author": ["R. Kumar", "A. Tomkins", "S. Vassilvitskii", "E. Vee"], "venue": null, "citeRegEx": "Kumar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kumar et al\\.", "year": 2015}, {"title": "Optimization Transfer Using Surrogate Objective Functions", "author": ["K. Lange", "D.R. Hunter", "I. Yang"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "Lange et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Lange et al\\.", "year": 2000}, {"title": "BrowseRank: Letting Web Users Vote For Page Importance", "author": ["Y. Liu", "B. Gao", "T.-Y. Liu", "Y. Zhang", "Z. Ma", "S. He", "H. Li"], "venue": "In SIGIR\u201908,", "citeRegEx": "Liu et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2008}, {"title": "Individual Choice behavior: A Theoretical Analysis", "author": ["R.D. Luce"], "venue": null, "citeRegEx": "Luce.,? \\Q1959\\E", "shortCiteRegEx": "Luce.", "year": 1959}, {"title": "Pregel: A System for Large-Scale Graph Processing", "author": ["G. Malewicz", "M.H. Austern", "A.J.C. Bik", "J.C. Dehnert", "I. Horn", "N. Leiser", "G. Czajkowski"], "venue": "In SIGMOD\u201910,", "citeRegEx": "Malewicz et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Malewicz et al\\.", "year": 2010}, {"title": "Fast and Accurate Inference of Plackett\u2013Luce Models", "author": ["L. Maystre", "M. Grossglauser"], "venue": "NIPS", "citeRegEx": "Maystre and Grossglauser.,? \\Q2015\\E", "shortCiteRegEx": "Maystre and Grossglauser.", "year": 2015}, {"title": "Conditional logit analysis of qualitative choice behavior", "author": ["D. McFadden"], "venue": "Frontiers in Econometrics,", "citeRegEx": "McFadden.,? \\Q1973\\E", "shortCiteRegEx": "McFadden.", "year": 1973}, {"title": "Scalability! But at what COST", "author": ["F. McSherry", "M. Isard", "D.G. Murray"], "venue": "In HotOS XV,", "citeRegEx": "McSherry et al\\.,? \\Q2015\\E", "shortCiteRegEx": "McSherry et al\\.", "year": 2015}, {"title": "Graph Structure in the Web\u2014Revisited: A Trick of the Heavy Tail", "author": ["R. Meusel", "S. Vigna", "O. Lehmberg", "C. Bizer"], "venue": "In WWW\u201914 Companion,", "citeRegEx": "Meusel et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Meusel et al\\.", "year": 2014}, {"title": "Iterative Ranking from Pair-wise Comparisons", "author": ["S. Negahban", "S. Oh", "D. Shah"], "venue": "NIPS", "citeRegEx": "Negahban et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Negahban et al\\.", "year": 2012}, {"title": "A New Paradigm for Ranking Pages on the World Wide Web", "author": ["J.A. Tomlin"], "venue": "In WWW\u201903,", "citeRegEx": "Tomlin.,? \\Q2003\\E", "shortCiteRegEx": "Tomlin.", "year": 2003}, {"title": "Discrete Choice Methods with Simulation", "author": ["K.E. Train"], "venue": null, "citeRegEx": "Train.,? \\Q2009\\E", "shortCiteRegEx": "Train.", "year": 2009}, {"title": "Parameter Estimation for Generalized Thurstone Choice Models", "author": ["M. Vojnovic", "S.-Y. Yun"], "venue": "In ICML 2016,", "citeRegEx": "Vojnovic and Yun.,? \\Q2016\\E", "shortCiteRegEx": "Vojnovic and Yun.", "year": 2016}, {"title": "URL https://dx", "author": ["E. Wulczyn", "D. Taraborelli. Wikipedia Clickstream. Apr."], "venue": "doi.org/10.6084/m9.figshare.1305770.v16.", "citeRegEx": "Wulczyn and Apr.,? 2016", "shortCiteRegEx": "Wulczyn and Apr.", "year": 2016}, {"title": "Die Berechnung der Turnier-Ergebnisse als ein Maximumproblem der Wahrscheinlichkeitsrechnung", "author": ["E. Zermelo"], "venue": "Mathematische Zeitschrift,", "citeRegEx": "Zermelo.,? \\Q1928\\E", "shortCiteRegEx": "Zermelo.", "year": 1928}], "referenceMentions": [{"referenceID": 11, "context": "Building upon recent work by Kumar et al. [2015], we present a statistical framework that tackles a general formulation of the problem: given a network (representing possible transitions between nodes) and the marginal traffic at each node, recover the transition probabilities.", "startOffset": 29, "endOffset": 49}, {"referenceID": 14, "context": "Choices are assumed to be independent and generated according to Luce\u2019s model [Luce, 1959]: each node in the network is chararacterized by a latent strength parameter, and (stochastic) choice outcomes tend to favor nodes with greater strengths.", "startOffset": 78, "endOffset": 90}, {"referenceID": 2, "context": "Users navigate from node to node along the edges of the network by making a choice between adjacent nodes at each step, reminiscent of the random-surfer model introduced by Brin and Page [1998]. Choices are assumed to be independent and generated according to Luce\u2019s model [Luce, 1959]: each node in the network is chararacterized by a latent strength parameter, and (stochastic) choice outcomes tend to favor nodes with greater strengths.", "startOffset": 173, "endOffset": 194}, {"referenceID": 14, "context": "To define the transition probabilities, we posit Luce\u2019s well-known choice axiom that states that the odds of choosing item j over item j\u2032 do not depend on the rest of the alternatives [Luce, 1959].", "startOffset": 184, "endOffset": 196}, {"referenceID": 11, "context": "3 Related Work A variant of the network choice model was recently introduced by Kumar et al. [2015], in an article that lays much of the groundwork for the present paper.", "startOffset": 80, "endOffset": 100}, {"referenceID": 14, "context": "Several decades before Luce\u2019s seminal book [Luce, 1959], Zermelo [1928] proposed a model and an algorithm that estimates the strengths of chess players based on pairwise comparison outcomes (his model would later be rediscovered by Bradley and Terry [1952]).", "startOffset": 43, "endOffset": 55}, {"referenceID": 17, "context": "Finally, we note that models based on Luce\u2019s axiom have been successfully applied to problems ranging from ranking players based on game outcomes [Zermelo, 1928, Elo, 1978] to understanding consumer behavior based on discrete choices [McFadden, 1973], and to discriminating among multiple classes based on the output of pairwise classifiers [Hastie and Tibshirani, 1998].", "startOffset": 234, "endOffset": 250}, {"referenceID": 9, "context": "Finally, we note that models based on Luce\u2019s axiom have been successfully applied to problems ranging from ranking players based on game outcomes [Zermelo, 1928, Elo, 1978] to understanding consumer behavior based on discrete choices [McFadden, 1973], and to discriminating among multiple classes based on the output of pairwise classifiers [Hastie and Tibshirani, 1998].", "startOffset": 341, "endOffset": 370}, {"referenceID": 0, "context": "Several decades before Luce\u2019s seminal book [Luce, 1959], Zermelo [1928] proposed a model and an algorithm that estimates the strengths of chess players based on pairwise comparison outcomes (his model would later be rediscovered by Bradley and Terry [1952]).", "startOffset": 232, "endOffset": 257}, {"referenceID": 0, "context": "Several decades before Luce\u2019s seminal book [Luce, 1959], Zermelo [1928] proposed a model and an algorithm that estimates the strengths of chess players based on pairwise comparison outcomes (his model would later be rediscovered by Bradley and Terry [1952]). More recently, Hunter [2004] explained Zermelo\u2019s algorithm from the perspective of the minorization-maximization (MM) method.", "startOffset": 232, "endOffset": 288}, {"referenceID": 0, "context": "Several decades before Luce\u2019s seminal book [Luce, 1959], Zermelo [1928] proposed a model and an algorithm that estimates the strengths of chess players based on pairwise comparison outcomes (his model would later be rediscovered by Bradley and Terry [1952]). More recently, Hunter [2004] explained Zermelo\u2019s algorithm from the perspective of the minorization-maximization (MM) method. This method is easily generalized to other models that are based on Luce\u2019s axiom, and it yields simple, provably convergent algorithms for maximum-likelihood (ML) or maximuma-posteriori point estimates. Caron and Doucet [2012] observe that these MM algorithms can be further recast as expectation-maximization (EM) algorithms by introducing suitable latent variables.", "startOffset": 232, "endOffset": 612}, {"referenceID": 2, "context": "A method that has undoubtedly had a tremendous impact in this context is PageRank [Brin and Page, 1998].", "startOffset": 82, "endOffset": 103}, {"referenceID": 13, "context": "At the other end of the spectrum, BrowseRank [Liu et al., 2008] uses detailed data collected in users\u2019 browsers to improve on PageRank.", "startOffset": 45, "endOffset": 63}, {"referenceID": 20, "context": "The HOTness method proposed by Tomlin [2003] is somewhat related, but tries to tackle a harder problem.", "startOffset": 31, "endOffset": 45}, {"referenceID": 11, "context": "We then connect our statistical model to the steady-state inversion problem defined by Kumar et al. [2015]. Guided by this connection, we study the maximum-likelihood (ML) estimate of model parameters, but find that the estimate is likely to be ill-defined in many scenarios of practical interest.", "startOffset": 87, "endOffset": 107}, {"referenceID": 11, "context": "We then connect our statistical model to the steady-state inversion problem defined by Kumar et al. [2015]. Guided by this connection, we study the maximum-likelihood (ML) estimate of model parameters, but find that the estimate is likely to be ill-defined in many scenarios of practical interest. Lastly, we study how to overcome this issue by introducing a prior distribution on the parameters \u03bb; the prior guarantees that the inference problem is well-posed. For simplicity of exposition, we present our results for Luce\u2019s standard choice model defined in (1). Our developments extend to the model variant proposed by Kumar et al. [2015], where choice probabilities can be modulated by edge weights.", "startOffset": 87, "endOffset": 641}, {"referenceID": 11, "context": "2 Connection to the Steady-State Inversion Problem In recent work, Kumar et al. [2015] define the problem of steady-state inversion as follows: Given a strongly-connected directed graph G = (V,E) and a target distribution over the nodes \u03c0, find a Markov chain on G with stationary distribution \u03c0.", "startOffset": 67, "endOffset": 87}, {"referenceID": 10, "context": "Equipped with this definition, we can state the following theorem that is a reformulation of a well-known result for Luce\u2019s choice model [Hunter, 2004].", "startOffset": 137, "endOffset": 151}, {"referenceID": 3, "context": "4 Well-Posed Inference Following the ideas of Caron and Doucet [2012], we introduce an independent Gamma prior on each parameter, i.", "startOffset": 46, "endOffset": 70}, {"referenceID": 10, "context": "In the spirit of the algorithms of Hunter [2004] for variants of Luce\u2019s choice model, we develop a minorization-maximization (MM) algorithm.", "startOffset": 35, "endOffset": 49}, {"referenceID": 12, "context": "Furthermore, it is known that MM algorithms exhibit geometric convergence in a neighborhood of the maximizer [Lange et al., 2000].", "startOffset": 109, "endOffset": 129}, {"referenceID": 15, "context": "Furthermore, the algorithm can be conveniently expressed in the well-known vertex-centric programming model [Malewicz et al., 2010].", "startOffset": 108, "endOffset": 131}, {"referenceID": 7, "context": "This makes it easy to implement ChoiceRank inside scalable, optimized graph-processing systems such as Apache Spark [Gonzalez et al., 2014].", "startOffset": 116, "endOffset": 139}, {"referenceID": 3, "context": "The update (6) can also be explained from an expectation-maximization (EM) viewpoint, by introducing suitable latent variables [Caron and Doucet, 2012].", "startOffset": 127, "endOffset": 151}, {"referenceID": 18, "context": "2 Scaling ChoiceRank to Billions of Nodes To demonstrate ChoiceRank\u2019s scalability, we develop a simple implementation in the Rust programming language, based on the ideas of COST [McSherry et al., 2015].", "startOffset": 179, "endOffset": 202}, {"referenceID": 19, "context": "5 billion nodes and 128 billion edges [Meusel et al., 2014].", "startOffset": 38, "endOffset": 59}, {"referenceID": 15, "context": "It is worth noting that despite tackling different problems, the ChoiceRank algorithm exhibits interesting similarities with a message-passing implementation of PageRank commonly used in scalable graph-parallel systems such as Pregel [Malewicz et al., 2010] and Spark [Gonzalez et al.", "startOffset": 234, "endOffset": 257}, {"referenceID": 7, "context": ", 2010] and Spark [Gonzalez et al., 2014].", "startOffset": 18, "endOffset": 41}, {"referenceID": 18, "context": "For comparison, using the COST code [McSherry et al., 2015] we run 20 iterations of PageRank on the same hardware and data.", "startOffset": 36, "endOffset": 59}, {"referenceID": 11, "context": "This method generalizes and extends ideas recently presented by Kumar et al. [2015]. We demonstrate that in spite of the strong model assumptions needed to learn O(n) probabilities from O(n) observations, the method still manages to recover the transition probabilities to a good level of accuracy on two clickstream datasets, and shows promise for applications beyond clickstream data.", "startOffset": 64, "endOffset": 84}, {"referenceID": 11, "context": "Kumar et al. [2015] propose the following generalization of Luce\u2019s choice model.", "startOffset": 0, "endOffset": 20}, {"referenceID": 4, "context": "13 in Casella and Berger [2002] states that {(ci , c+i )} is a minimally sufficient statistic for \u03bb if and only if, for any {cij} and {dij} in the support of f , f({cij} | \u03bb) f({dij} | \u03bb) is independent of \u03bb \u21d0\u21d2 (ci , c+i ) = (di , d+i ) \u2200i.", "startOffset": 6, "endOffset": 32}, {"referenceID": 10, "context": "The proof borrows from Hunter [2004], in particular from the proofs of Lemmas 1 and 2.", "startOffset": 23, "endOffset": 37}, {"referenceID": 10, "context": "The proof follows that of Hunter\u2019s Theorem 1 [2004]. Proof.", "startOffset": 26, "endOffset": 52}, {"referenceID": 3, "context": "2 EM Viewpoint The MM algorithm can be seen from an EM viewpoint, following the ideas of Caron and Doucet [2012]. We introduce n independent random variables Z = {Zi | i = 1, .", "startOffset": 89, "endOffset": 113}], "year": 2017, "abstractText": "Understanding how users navigate in a network is of high interest in many applications. We consider a setting where only aggregate node-level traffic is observed and tackle the task of learning edge transition probabilities. We cast it as a preference learning problem, and we study a model where choices follow Luce\u2019s axiom. In this case, the O(n) marginal counts of node visits are a sufficient statistic for the O(n2) transition probabilities. We show how to make the inference problem well-posed regardless of the network\u2019s structure, and we present ChoiceRank, an iterative algorithm that scales to networks that contains billions of nodes and edges. We apply the model to two clickstream datasets and show that it successfully recovers the transition probabilities using only the network structure and marginal (node-level) traffic data. Finally, we also consider an application to mobility networks and apply the model to one year of rides on New York City\u2019s bicycle-sharing system.", "creator": "LaTeX with hyperref package"}}}