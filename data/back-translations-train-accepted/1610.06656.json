{"id": "1610.06656", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Oct-2016", "title": "Single Pass PCA of Matrix Products", "abstract": "In this paper we present a new algorithm for computing a low rank approximation of the product $A^TB$ by taking only a single pass of the two matrices $A$ and $B$. The straightforward way to do this is to (a) first sketch $A$ and $B$ individually, and then (b) find the top components using PCA on the sketch. Our algorithm in contrast retains additional summary information about $A,B$ (e.g. row and column norms etc.) and uses this additional information to obtain an improved approximation from the sketches. Our main analytical result establishes a comparable spectral norm guarantee to existing two-pass methods; in addition we also provide results from an Apache Spark implementation that shows better computational and statistical performance on real-world and synthetic evaluation datasets.", "histories": [["v1", "Fri, 21 Oct 2016 02:45:46 GMT  (407kb)", "https://arxiv.org/abs/1610.06656v1", "24 pages, 4 figures, NIPS 2016"], ["v2", "Wed, 26 Oct 2016 13:58:24 GMT  (407kb)", "http://arxiv.org/abs/1610.06656v2", "24 pages, 4 figures, NIPS 2016"]], "COMMENTS": "24 pages, 4 figures, NIPS 2016", "reviews": [], "SUBJECTS": "stat.ML cs.DS cs.IT cs.LG math.IT", "authors": ["shanshan wu", "srinadh bhojanapalli", "sujay sanghavi", "alexandros g dimakis"], "accepted": true, "id": "1610.06656"}, "pdf": {"name": "1610.06656.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["Shanshan Wu"], "emails": ["shanshan@utexas.edu", "srinadh@ttic.edu", "sanghavi@mail.utexas.edu", "dimakis@austin.utexas.edu"], "sections": [{"heading": null, "text": "ar Xiv: 161 0.06 656v 2 [stat.ML]"}, {"heading": "1 Introduction", "text": "Considering the two large matrices A and B, we can examine the problem of approximate approximation to the product ATB (with only a single step over the matrix elements). (Another example is a slight approximation to the matrix matrix from the large logs, for example, A can be a user matrix, and B can be a user matrix, so ATB calculates the common numbers for each query ad pair. The matrix A and B can also be two large word matrices. (In this case, each entry of ATB is the number of times common words occur.) As a fourth example, ATB can be a transboundary covariance matrix between two groups of variables, e.g., A and B can be genotype and phenotypic."}, {"heading": "2 Problem setting and algorithms", "text": "Consider the following problem: In view of two matrices A-Rd \u00b7 n1 and B-Rd \u00b7 n2 stored on the hard disk, we find a rank-r approximation of their product ATB. In particular, we are interested in the setting in which both A, B and ATB are too large to fit into the memory. This is common for modern machine learning applications. For this setting, we develop a single-pass algorithm SMP-PCA, which calculates the rank-r approximation without explicitly forming the entire matrix ATB. We use A-F for Frobenius standard and A-A for spectral (or operator) standard. The optimal rank-r approximation of matrix A is Ar, which can be found by SVD-Rd \u00b7 n1."}, {"heading": "2.1 SMP-PCA", "text": "In fact, it is not as if this is a reactionary act, but a reactionary diversionary manoeuvre, which involves a manner and manner in which the cessation of relationships is concerned with the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of relationships, which is about the cessation of cessation of relationships, which is about the cessation of cessation of relationships, which is about the cessation of cessation of cessation of relationships, which is about the cessation of cessation of cessation of cessation of cessation of relationships, which is about the cessation of cessation of cessation of cessation of relationships, which is about the cessation of cessation of cessation of cessation of cessation of cessation of cessations, which is about the cessation of cessation of cessation of cessation of cessation of cessation of cessation of cessations, which is about the cessation of cessation of cessation of cessation of cessation of cessation of cessation of cessations, which is about the cessation of cessation of cessation of cessation of cessation of cessation of cessations, which is about the cessation of cessation of cessation of cessation of cessation of cessation of cessations and of cessation of cessations and of cessations, which is about the cessation of cessation of cessation of cessation of cessation of cessation of cessation of cessations, which is about the cessation of cessation of cessation of cessation of cessation and of cessation of cessation of cessation of cessation of cessation"}, {"heading": "3 Analysis", "text": "We imagine the most important theoretical results. (...) We are the best possible rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) Define r. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...) We are the best rate of ATB. (...)"}, {"heading": "4 Numerical Experiments", "text": "This year it is more than ever before."}, {"heading": "5 Conclusion", "text": "We are developing a novel one-pass algorithm, SMP-PCA, which directly calculates a slight approximation of a matrix product, using ideas of matrix sketching and entry-level scanning. As a subroutine of our algorithm, we propose to re-scale JL to evaluate ATB entries that have fewer errors than the standard estimator A-T B. We believe this can be extended to other applications. In addition, SMP-PCA allows the non-zero entries of A and B to be presented in any order and thus can be used for attenuation applications. We are designing a distributed implementation for SMP-PCA. Our experimental results show that this is possible using a standard power iteration-based method without explicitly shaping the product matrix A-T B, which is too large to fit into the memory as we assume."}, {"heading": "A Weighted alternating minimization", "text": "Algorithm 2 provides a detailed explanation of the WAltMin, which follows a standard procedure for matrix completion. (i, j) The algorithm (A) = w, j, p (A) for (i, j) for (i, j) for (i, j) for (i, j) for (A) (i, j) for (i, j) for (i, j) for (i, j) for (i, j) for (i, j) for (i, j) for the weight matrix R1 / 2 (A) as R 1 / 2 (A) (i, j) = w (i, j) for (A) (i, j) for (i, j) for (i, j). The algorithm contains two parts: the initialization (step 2-6) and the weighted alternating minimization (step 7-10)."}, {"heading": "B Technical Lemmas", "text": "s Inequality [33]) Consider p independent random matrices X1,...., Xp in Rn \u00b7 n, where each matrix has a limited deviation from its mean: | | Xi \u2212 E [Xi] | | \u2264 L, \u0435i."}, {"heading": "Let the norm of the covariance matrix be", "text": "\u03c32 = max {This is why it is so important that the number of employees working in China has increased in recent years. [P-I = 1 (Xi-E [Xi]) (Xi-E [Xi]) T-I-I [P-I = 1 (Xi-E [Xi]) T (Xi-E [Xi])]"}, {"heading": "Then the following holds for all t \u2265 0:", "text": "The following question is whether it is a random matrix, which is a JL transformation with the parameters \"A,\" \"A,\" \"A,\" \"A,\" \"B,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V, \"V,\" V."}, {"heading": "C Proofs", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C.1 Proof overview", "text": "As a first step, we show that the sampled matrix provides a good approximation of the actual matrix ATB (see line 4 of the algorithm 2).The detailed proof can be summarized in Appendix C.2. For consistency, we will use Ci (i = 1, 2,...) to specify a global constant that may vary from step to step. Lemma C.1. (Initialization) Let m and k meet the following conditions for sufficiently large constants C1 and C2: m."}, {"heading": "C.2 Proof of Lemma C.1", "text": "We first prove the following problem, which shows that the ratio (M) is very close to the ratio (M). \"For the simplicity of the representation, we define the ratio (A):\" The ratio (A) follows the ratio (A). \"Suppose the ratio (A) is fixed and is\" beautiful. \"Let's define the ratio (C1) as a sufficiently large global constant C1, then the following is applicable:\" Ratio (M) \u2212 M (ATB). \"-\" F. \"Proof.\" This problem can be proved in the same way as the proof for the ratio (B).2 in [3]. The key idea is to use the matrix amber-inquality. Let Xij = (Lemm) - \"q\" wijM \"wijj\" wijj \"wijj\" wijj \"wijj,\" where the ratio (F) variably indicates whether the value is (j) variable."}, {"heading": "C.3 Proof of Lemma C.2", "text": "We first have to prove the following problem, which is a counterpart to Lemma C.5 in [3]. (...) For the simplicity of the representation (...) we use M (...) for sufficiently large global constants C1 and C2, then we consider the following steps with a probability of at least 1 \u2212 (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) (...) () (...) () () (...) () () (...) () () ()... () () ()... \"()... () ()... () () () (...\" ()... \"() ()... () ()... () ()... () ()... () () ()... () ()... () () ()... ()... () ()... () ()... ()... () ()... ()... () () ()... ()...\" ()... \"()...\" ()... \"()...\" ()... \"()...\" ()... \"()...\" ()... \"()... ()...\" ()... \"()...\" ()... \"()...\" ()."}, {"heading": "C.4 Proof of Theorem 3.1", "text": "We are proving our main theory for case number 1 here. \u2212 \u2212 \u2212 \u2212 Have a look at a similar line of argument and you can get it by combining the current evidence with the ranking of the LELA analyses. \u2212 Have a look at the previous section? \u2212 See how we get the corresponding standardized vectors.The closed solution for WAltMin updating in t + 1 iteration is: \u2212 Have a look at the closed form for WAltMin updating in t + 1 iteration. \u2212 Have a look at the closed form for WAltMin updating in t + 1 iteration?"}, {"heading": "C.5 Sampling", "text": "We describe a way to sample m elements in O (m log (n)) time using the distribution qij defined in Equation (1). Naively, we can calculate all n2 entries of min {qij, 1} and throw a coin for each entry, which requires O (n2) time. Instead of this binomial sample, we can switch to a line-by-line multinomial sample. To do this, we first have to evaluate the expected number of samples per line mi = m (| Ai | | 22 | | | A | | 2 F + 12n). Now, sample m1 entries from row 1 are evaluated according to the multinomial distribution q = m m1 \u00b7 (| A1 | 2 2F + | | Bj | | 2 2n | | | B | 2F) only in the line (B | 2F | | 2F) in the time range (A1 | 22n | | Bj | 22n | 2 mi)."}, {"heading": "D Related work", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Approximate matrix multiplication:", "text": "This year, the time has come for an agreement to be reached, \"he told the German Press Agency in an interview with\" Welt am Sonntag. \""}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "In this paper we present a new algorithm for computing a low rank approximation of the product<lb>AB by taking only a single pass of the two matrices A and B. The straightforward way to do this is to<lb>(a) first sketch A and B individually, and then (b) find the top components using PCA on the sketch. Our<lb>algorithm in contrast retains additional summary information about A,B (e.g. row and column norms<lb>etc.) and uses this additional information to obtain an improved approximation from the sketches. Our<lb>main analytical result establishes a comparable spectral norm guarantee to existing two-pass methods; in<lb>addition we also provide results from an Apache Spark implementation that shows better computational<lb>and statistical performance on real-world and synthetic evaluation datasets.", "creator": "LaTeX with hyperref package"}}}