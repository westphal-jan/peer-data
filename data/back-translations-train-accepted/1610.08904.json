{"id": "1610.08904", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Oct-2016", "title": "Local Similarity-Aware Deep Feature Embedding", "abstract": "Existing deep embedding methods in vision tasks are capable of learning a compact Euclidean space from images, where Euclidean distances correspond to a similarity metric. To make learning more effective and efficient, hard sample mining is usually employed, with samples identified through computing the Euclidean feature distance. However, the global Euclidean distance cannot faithfully characterize the true feature similarity in a complex visual feature space, where the intraclass distance in a high-density region may be larger than the interclass distance in low-density regions. In this paper, we introduce a Position-Dependent Deep Metric (PDDM) unit, which is capable of learning a similarity metric adaptive to local feature structure. The metric can be used to select genuinely hard samples in a local neighborhood to guide the deep embedding learning in an online and robust manner. The new layer is appealing in that it is pluggable to any convolutional networks and is trained end-to-end. Our local similarity-aware feature embedding not only demonstrates faster convergence and boosted performance on two complex image retrieval datasets, its large margin nature also leads to superior generalization results under the large and open set scenarios of transfer learning and zero-shot learning on ImageNet 2010 and ImageNet-10K datasets.", "histories": [["v1", "Thu, 27 Oct 2016 17:51:18 GMT  (629kb,D)", "http://arxiv.org/abs/1610.08904v1", "9 pages, 4 figures, 2 tables. Accepted to NIPS 2016"]], "COMMENTS": "9 pages, 4 figures, 2 tables. Accepted to NIPS 2016", "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["chen huang", "chen change loy", "xiaoou tang"], "accepted": true, "id": "1610.08904"}, "pdf": {"name": "1610.08904.pdf", "metadata": {"source": "CRF", "title": "Local Similarity-Aware Deep Feature Embedding", "authors": ["Chen Huang", "Chen Change Loy", "Xiaoou Tang"], "emails": ["chuang@ie.cuhk.edu.hk", "ccloy@ie.cuhk.edu.hk", "xtang@ie.cuhk.edu.hk"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to survive on their own, without having to orient themselves in a different direction."}, {"heading": "2 Related work", "text": "It is the core of many successful solutions, for example, in terms of recording people who live in a country. [27] Similarly, it is also associated with the embedding of people into the world of work. [29] In fact, the number of people living in a country is very high. [29] In fact, the number of people living in a country is very high. [29] In fact, the number of people living in a country where they live is very high."}, {"heading": "3 Local similarity-aware deep embedding", "text": "Letter X = {(xi, yi)} should be an image dataset in which yi is the class name of the image xi. Our goal is to jointly learn a deep attribute that embeds f (x) from image x into a attribute space Rd, and a similarity metric Si, j = S (f (xi), f (xj)), as well as R1, so that the metric can robustly select hard samples online to learn discriminatory similarity perception. Ideally, the learned characteristics (f (xi), f (xj))) from the set of positive pairs P = (i, j) | yi = yj} should be close to each other, while the learned characteristics from the set of negative pairs N = (i, j) | yi 6 = yj} from the set of positive pairs P = (i, j) | yj} from the series of positive pairs P = (i) in the series of positive pairs P = (P), negative in the series of positive pairs, j = P in the series of number pairs (P)."}, {"heading": "3.1 PDDM learning and hard sample mining", "text": "We use the parameters W (xi), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), fW (xj), W (xp), W (xp), S (xp), S (xp), S (xp), S (xp), S (S), S (xp), S (S), S (xp, S (S), S (xp, S (xp), S (xp), S (xp, S (xp), S (xp), S (xp), fW (xp), S (xp), S (xp), S (xp, S (xp), S (xp, S), fW (xp), fW (xj), fW (xj, fW (xj), fW (xj, fW (xj), fW (xj, fW (xj), fW (xj (xj), fW (xj (xj, fW (xj), fW (xj, fW (xj), fW (xj (xp (xj), fW (xp (xj), fW (xp (xj), S (xp (xp (xj), S (xp), S (xp (xp), S (xp), S (xp (xp), S (xp), S (xp (xp), S (xp), S (xp (xp), S (xp), S (xp), S (xp (xp), S (xp), S ("}, {"heading": "3.2 Joint metric and embedding optimization", "text": "Considering the learned PDDM and the diminished hard samples in a mini-batch, we can use them for a better, local similarity-conscious embedding in the same time. (D) What follows is that we can reuse the double positive features, but restrict the profound features of that time. (D) The goal is to ensure the distance between the hard negative features (D). (D) The goal is to ensure the distance between the hard negative features (D). (D) The goal is to ensure the distance between the hard negative features (D). (D) The goal is to ensure the distance between the hard positive features (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D). (D. (D). (D). (D. (D). (D. (D). (D. (D). (D). (D. (D). (D). (D. (D). (D). (D. (D). (D). (D). (D). (D. (D). (D). (D). (D. (D). (D). (D. (D). (D). (D. (D). (D. (D). (D). (D. (D). (D. (D). (D). (D. (D). (D. (D). (D.). (D. (D). (D.). (D. (D. (D). (D). (D. (D). (D. (D). (D. (D). (D. (D). (D. (D). (D). (D. (D). (D. (D). (D). (D. (D. (D). (D). (D. (D. (D). (D.). (D. (D). (D). (D. (D). (D. (D. (D). (D). (D"}, {"heading": "3.3 Implementation details", "text": "We use GoogLeNet [31] (feature dimension d = 128) and CaffeNet [16] (d = 4096) as our base network architectures for the retrieval and transfer of learning tasks. They are initialized with their pre-trained parameters in the ImageNet classification. The fully connected layers of our PDDM unit are initialized with random weights and followed by a dropout [30] with p = 0.5. For all experiments, we select the mini battery size m = 64, initial learning rate 1 x 10 \u2212 4, impulse 0.9, boundary parameters \u03b1 = 0.5, \u03b2 = 1 in equations (3, 4) and regulation parameters f = 0.5, g = 5 x 10 \u2212 4 (\u03bb balances the metric loss Em against the embedding loss Ee) by grid searches. To find meaningful hard positives in our hard quadruplets, we make sure that each class in a mini batch has at least 4 samples and we always scale from 400 to the total equaliser."}, {"heading": "4 Results", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "5 Conclusion", "text": "In this paper, we developed a method for learning local, similarity-conscious, deep feature embedding in an end-to-end manner. PDDM is proposed to adaptively measure local feature similarity in a heterogeneous space, so it is valuable for high-quality online hard sample mining, which can better guide embedding learning. Double-header hinge loss in both similarity metrics and feature embedding is optimized under the large margin criterion. Experiments demonstrate the effectiveness of our learned feature embedding in demanding image retrieval tasks and point to its potential to generalize new classes in large and open scenarios such as transfer learning and zero-shot learning. In the future, it will be interesting to investigate the generalization performance if one supports the common attributes or visual-semantic embedding in place of ImageNet Zero Learning for Senarching.Hong Kong Hierarchie-Learng Limited."}], "references": [{"title": "Learning visual similarity for product design with convolutional neural networks", "author": ["S. Bell", "K. Bala"], "venue": "TOG, 34(4):98:1\u201398:10", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2015}, {"title": "Towards open world recognition", "author": ["A. Bendale", "T. Boult"], "venue": "CVPR", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2015}, {"title": "Fine-grained categorization and dataset bootstrapping using deep metric learning with humans in the loop", "author": ["Y. Cui", "F. Zhou", "Y. Lin", "S. Belongie"], "venue": "CVPR", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2016}, {"title": "Histograms of oriented gradients for human detection", "author": ["N. Dalal", "B. Triggs"], "venue": "CVPR", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2005}, {"title": "and L", "author": ["J. Deng", "A.C. Berg", "K. Li"], "venue": "Fei-Fei. What does classifying more than 10,000 image categories tell us? In ECCV", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2010}, {"title": "One-shot learning of object categories", "author": ["L. Fei-Fei", "R. Fergus", "P. Perona"], "venue": "TPAMI, 28(4):594\u2013611", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2006}, {"title": "Object detection with discriminatively trained part-based models", "author": ["P.F. Felzenszwalb", "R.B. Girshick", "D. McAllester", "D. Ramanan"], "venue": "TPAMI, 32(9):1627\u20131645", "citeRegEx": "7", "shortCiteRegEx": null, "year": 2010}, {"title": "DeViSE: A deep visual-semantic embedding model", "author": ["A. Frome", "G.S. Corrado", "J. Shlens", "S. Bengio", "J. Dean", "M.A. Ranzato", "T. Mikolov"], "venue": "NIPS", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning globally-consistent local distance functions for shape-based image retrieval and classification", "author": ["A. Frome", "Y. Singer", "F. Sha", "J. Malik"], "venue": "ICCV", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2007}, {"title": "Zero-shot object recognition by semantic manifold distance", "author": ["Z. Fu", "T.A. Xiang", "E. Kodirov", "S. Gong"], "venue": "CVPR", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Neighbourhood components analysis", "author": ["J. Goldberger", "G.E. Hinton", "S.T. Roweis", "R.R. Salakhutdinov"], "venue": "NIPS", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2005}, {"title": "Learning distance metrics with contextual constraints for image retrieval", "author": ["S.C.H. Hoi", "W. Liu", "M.R. Lyu", "W.-Y. Ma"], "venue": "CVPR", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2006}, {"title": "Learning deep representation for imbalanced classification", "author": ["C. Huang", "Y. Li", "C.C. Loy", "X. Tang"], "venue": "CVPR", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Unsupervised learning of discriminative attributes and visual representations", "author": ["C. Huang", "C.C. Loy", "X. Tang"], "venue": "CVPR", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2016}, {"title": "3D object representations for fine-grained categorization", "author": ["J. Krause", "M. Stark", "J. Deng", "L. Fei-Fei"], "venue": "ICCVW", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2013}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"], "venue": "NIPS", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2012}, {"title": "Attribute-based classification for zero-shot visual object categorization", "author": ["C.H. Lampert", "H. Nickisch", "S. Harmeling"], "venue": "TPAMI, 36(3):453\u2013465", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2014}, {"title": "Building high-level features using large scale unsupervised learning", "author": ["Q. Le", "M. Ranzato", "R. Monga", "M. Devin", "K. Chen", "G. Corrado", "J. Dean", "A. Ng"], "venue": "ICML", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2012}, {"title": "Visualizing high-dimensional data using t-SNE", "author": ["L. Maaten", "G.E. Hinton"], "venue": "JMLR, 9:2579\u20132605", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2008}, {"title": "PCA versus LDA", "author": ["A.M. Martinez", "A.C. Kak"], "venue": "TPAMI, 23(2):228\u2013233", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2001}, {"title": "Distance-based image classification: Generalizing to new classes at near-zero cost", "author": ["T. Mensink", "J. Verbeek", "F. Perronnin", "G. Csurka"], "venue": "TPAMI, 35(11):2624\u20132637", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2013}, {"title": "Zero-shot learning by convex combination of semantic embeddings", "author": ["M. Norouzi", "T. Mikolov", "S. Bengio", "Y. Singer", "J. Shlens", "A. Frome", "G. Corrado", "J. Dean"], "venue": "ICLR", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2014}, {"title": "Towards good practice in large-scale learning for image classification", "author": ["F. Perronnin", "Z. Akata", "Z. Harchaoui", "C. Schmid"], "venue": "CVPR", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2012}, {"title": "Transfer learning in a transductive setting", "author": ["M. Rohrbach", "S. Ebert", "B. Schiele"], "venue": "NIPS", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2013}, {"title": "Evaluating knowledge transfer and zero-shot learning in a large-scale setting", "author": ["M. Rohrbach", "M. Stark", "B. Schiele"], "venue": "CVPR", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2011}, {"title": "High-dimensional signature compression for large-scale image classification", "author": ["J. Sanchez", "F. Perronnin"], "venue": "CVPR", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2011}, {"title": "FaceNet: A unified embedding for face recognition and clustering", "author": ["F. Schroff", "D. Kalenichenko", "J. Philbin"], "venue": "CVPR", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2015}, {"title": "Fracking deep convolutional image descriptors", "author": ["E. Simo-Serra", "E. Trulls", "L. Ferraz", "I. Kokkinos", "F. Moreno-Noguer"], "venue": "arXiv preprint, arXiv:1412.6537v2", "citeRegEx": "28", "shortCiteRegEx": null, "year": 2015}, {"title": "Deep metric learning via lifted structured feature embedding", "author": ["H.O. Song", "Y. Xiang", "S. Jegelka", "S. Savarese"], "venue": "CVPR", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2016}, {"title": "Dropout: A simple way to prevent neural networks from overfitting", "author": ["N. Srivastava", "G. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"], "venue": "JMLR, 15(1):1929\u20131958", "citeRegEx": "30", "shortCiteRegEx": null, "year": 2014}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "CVPR", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2015}, {"title": "The Caltech-UCSD Birds-200-2011 Dataset", "author": ["C. Wah", "S. Branson", "P. Welinder", "P. Perona", "S. Belongie"], "venue": "Technical Report CNS-TR-2011-001, California Institute of Technology", "citeRegEx": "32", "shortCiteRegEx": null, "year": 2011}, {"title": "Learning fine-grained image similarity with deep ranking", "author": ["J. Wang", "Y. Song", "T. Leung", "C. Rosenberg", "J. Wang", "J. Philbin", "B. Chen", "Y. Wu"], "venue": "CVPR", "citeRegEx": "33", "shortCiteRegEx": null, "year": 2014}, {"title": "Unsupervised learning of visual representations using videos", "author": ["X. Wang", "A. Gupta"], "venue": "ICCV", "citeRegEx": "34", "shortCiteRegEx": null, "year": 2015}, {"title": "Distance metric learning for large margin nearest neighbor classification", "author": ["K.Q. Weinberger", "L.K. Saul"], "venue": "JMLR, 10:207\u2013244", "citeRegEx": "35", "shortCiteRegEx": null, "year": 2009}, {"title": "Distance metric learning with application to clustering with side-information", "author": ["E.P. Xing", "M.I. Jordan", "S.J. Russell", "A.Y. Ng"], "venue": "NIPS", "citeRegEx": "36", "shortCiteRegEx": null, "year": 2003}, {"title": "Random forests for metric learning with implicit pairwise position dependence", "author": ["C. Xiong", "D. Johnson", "R. Xu", "J.J. Corso"], "venue": "SIGKDD", "citeRegEx": "37", "shortCiteRegEx": null, "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "They have been increasingly adopted in a variety of vision tasks such as product visual search [1, 14, 29, 33] and face verification [13, 27].", "startOffset": 95, "endOffset": 110}, {"referenceID": 13, "context": "They have been increasingly adopted in a variety of vision tasks such as product visual search [1, 14, 29, 33] and face verification [13, 27].", "startOffset": 95, "endOffset": 110}, {"referenceID": 28, "context": "They have been increasingly adopted in a variety of vision tasks such as product visual search [1, 14, 29, 33] and face verification [13, 27].", "startOffset": 95, "endOffset": 110}, {"referenceID": 32, "context": "They have been increasingly adopted in a variety of vision tasks such as product visual search [1, 14, 29, 33] and face verification [13, 27].", "startOffset": 95, "endOffset": 110}, {"referenceID": 12, "context": "They have been increasingly adopted in a variety of vision tasks such as product visual search [1, 14, 29, 33] and face verification [13, 27].", "startOffset": 133, "endOffset": 141}, {"referenceID": 26, "context": "They have been increasingly adopted in a variety of vision tasks such as product visual search [1, 14, 29, 33] and face verification [13, 27].", "startOffset": 133, "endOffset": 141}, {"referenceID": 0, "context": "The embedding objective is usually in a Euclidean sense: the Euclidean distance Di,j = \u2016f(xi)\u2212 f(xj)\u20162 between two feature vectors should preserve their semantic relationship encoded pairwise (by contrastive loss [1]), in triplets [27, 33] or even higher order relationships (e.", "startOffset": 213, "endOffset": 216}, {"referenceID": 26, "context": "The embedding objective is usually in a Euclidean sense: the Euclidean distance Di,j = \u2016f(xi)\u2212 f(xj)\u20162 between two feature vectors should preserve their semantic relationship encoded pairwise (by contrastive loss [1]), in triplets [27, 33] or even higher order relationships (e.", "startOffset": 231, "endOffset": 239}, {"referenceID": 32, "context": "The embedding objective is usually in a Euclidean sense: the Euclidean distance Di,j = \u2016f(xi)\u2212 f(xj)\u20162 between two feature vectors should preserve their semantic relationship encoded pairwise (by contrastive loss [1]), in triplets [27, 33] or even higher order relationships (e.", "startOffset": 231, "endOffset": 239}, {"referenceID": 28, "context": ", by lifted structured loss [29]).", "startOffset": 28, "endOffset": 32}, {"referenceID": 2, "context": "Selecting overly easy samples can in practice lead to slow convergence and poor performance since many of them satisfy the constraint well and give nearly zero loss, without exerting any effect on parameter update during the back-propagation [3].", "startOffset": 242, "endOffset": 245}, {"referenceID": 6, "context": "Hence hard example mining [7] becomes an indispensable step in state-of-the-art deep embedding methods.", "startOffset": 26, "endOffset": 29}, {"referenceID": 26, "context": "For instance, in [27, 29], hard negatives with small Euclidean distances are found online in a mini-batch.", "startOffset": 17, "endOffset": 25}, {"referenceID": 28, "context": "For instance, in [27, 29], hard negatives with small Euclidean distances are found online in a mini-batch.", "startOffset": 17, "endOffset": 25}, {"referenceID": 32, "context": "An exception is [33] where an online reservoir importance sampling scheme is proposed to sample discriminative triplets by relevance scores.", "startOffset": 16, "endOffset": 20}, {"referenceID": 26, "context": "Deep Euclidean metric Triplet loss [27,33] Position-Dependent Deep Metric Double header hinge loss", "startOffset": 35, "endOffset": 42}, {"referenceID": 32, "context": "Deep Euclidean metric Triplet loss [27,33] Position-Dependent Deep Metric Double header hinge loss", "startOffset": 35, "endOffset": 42}, {"referenceID": 18, "context": "Figure 1: (a) 2-D feature embedding (by t-SNE [19]) of the CUB-200-2011 [32] test set.", "startOffset": 46, "endOffset": 50}, {"referenceID": 31, "context": "Figure 1: (a) 2-D feature embedding (by t-SNE [19]) of the CUB-200-2011 [32] test set.", "startOffset": 72, "endOffset": 76}, {"referenceID": 10, "context": "We observed similar phenomenon for the global Mahalanobis metric [11, 12, 21, 35, 36] in our experiments.", "startOffset": 65, "endOffset": 85}, {"referenceID": 11, "context": "We observed similar phenomenon for the global Mahalanobis metric [11, 12, 21, 35, 36] in our experiments.", "startOffset": 65, "endOffset": 85}, {"referenceID": 20, "context": "We observed similar phenomenon for the global Mahalanobis metric [11, 12, 21, 35, 36] in our experiments.", "startOffset": 65, "endOffset": 85}, {"referenceID": 34, "context": "We observed similar phenomenon for the global Mahalanobis metric [11, 12, 21, 35, 36] in our experiments.", "startOffset": 65, "endOffset": 85}, {"referenceID": 35, "context": "We observed similar phenomenon for the global Mahalanobis metric [11, 12, 21, 35, 36] in our experiments.", "startOffset": 65, "endOffset": 85}, {"referenceID": 2, "context": "[3] resorted to human intervention for harvesting genuinely hard samples.", "startOffset": 0, "endOffset": 3}, {"referenceID": 12, "context": "Existing studies [13, 14, 27, 29, 33] only consider the two latter objectives but not together with the first.", "startOffset": 17, "endOffset": 37}, {"referenceID": 13, "context": "Existing studies [13, 14, 27, 29, 33] only consider the two latter objectives but not together with the first.", "startOffset": 17, "endOffset": 37}, {"referenceID": 26, "context": "Existing studies [13, 14, 27, 29, 33] only consider the two latter objectives but not together with the first.", "startOffset": 17, "endOffset": 37}, {"referenceID": 28, "context": "Existing studies [13, 14, 27, 29, 33] only consider the two latter objectives but not together with the first.", "startOffset": 17, "endOffset": 37}, {"referenceID": 32, "context": "Existing studies [13, 14, 27, 29, 33] only consider the two latter objectives but not together with the first.", "startOffset": 17, "endOffset": 37}, {"referenceID": 31, "context": "Image retrieval experiments on two challenging real-world vision datasets, CUB-200-2011 [32] and CARS196 [15], show that our local similarity-aware feature embedding significantly outperforms state-of-the-art deep embedding methods that come without the online metric learning and associated hard sample mining scheme.", "startOffset": 88, "endOffset": 92}, {"referenceID": 14, "context": "Image retrieval experiments on two challenging real-world vision datasets, CUB-200-2011 [32] and CARS196 [15], show that our local similarity-aware feature embedding significantly outperforms state-of-the-art deep embedding methods that come without the online metric learning and associated hard sample mining scheme.", "startOffset": 105, "endOffset": 109}, {"referenceID": 28, "context": ", [29]), which need to compute a fully connected dense matrix of pairwise distances in a mini-batch.", "startOffset": 2, "endOffset": 6}, {"referenceID": 4, "context": "This is validated in the transfer learning and zero-shot learning (using the ImageNet hierarchy as auxiliary knowledge) tasks on ImageNet 2010 and ImageNet-10K [5] datasets.", "startOffset": 160, "endOffset": 163}, {"referenceID": 3, "context": "pedestrian detection [4, 7].", "startOffset": 21, "endOffset": 27}, {"referenceID": 6, "context": "pedestrian detection [4, 7].", "startOffset": 21, "endOffset": 27}, {"referenceID": 26, "context": "In a similar spirit, contemporary deep embedding methods [27, 29] choose hard samples in a mini-batch by computing the Euclidean distance in the embedding space.", "startOffset": 57, "endOffset": 65}, {"referenceID": 28, "context": "In a similar spirit, contemporary deep embedding methods [27, 29] choose hard samples in a mini-batch by computing the Euclidean distance in the embedding space.", "startOffset": 57, "endOffset": 65}, {"referenceID": 26, "context": "[27] selected online the semi-hard negative samples with relatively small Euclidean distances.", "startOffset": 0, "endOffset": 4}, {"referenceID": 32, "context": "[33] proposed an online reservoir importance sampling algorithm to sample triplets by relevance scores, which are computed offline with different distance metrics.", "startOffset": 0, "endOffset": 4}, {"referenceID": 27, "context": "Similar studies on image descriptor learning [28] and unsupervised feature learning [34] also select hard samples according to the Euclidean distance-based losses in their respective CNNs.", "startOffset": 45, "endOffset": 49}, {"referenceID": 33, "context": "Similar studies on image descriptor learning [28] and unsupervised feature learning [34] also select hard samples according to the Euclidean distance-based losses in their respective CNNs.", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "Similarities can be encoded pairwise with a contrastive loss [1] or in more flexible triplets [27, 33].", "startOffset": 61, "endOffset": 64}, {"referenceID": 26, "context": "Similarities can be encoded pairwise with a contrastive loss [1] or in more flexible triplets [27, 33].", "startOffset": 94, "endOffset": 102}, {"referenceID": 32, "context": "Similarities can be encoded pairwise with a contrastive loss [1] or in more flexible triplets [27, 33].", "startOffset": 94, "endOffset": 102}, {"referenceID": 28, "context": "[29] extended to even higher order similarity constraints by lifting the pairwise distances within a mini-batch to the dense matrix of pairwise distances.", "startOffset": 0, "endOffset": 4}, {"referenceID": 11, "context": "Representative works [12, 36] minimize the Mahalanobis distance between positive sample pairs while maximizing the distance between negative pairs.", "startOffset": 21, "endOffset": 29}, {"referenceID": 35, "context": "Representative works [12, 36] minimize the Mahalanobis distance between positive sample pairs while maximizing the distance between negative pairs.", "startOffset": 21, "endOffset": 29}, {"referenceID": 10, "context": "Alternatives directly optimize the Mahalanobis metric for nearest neighbor classification via the method of Neighbourhood Component Analysis (NCA) [11], Large Margin Nearest Neighbor (LMNN) [35] or Nearest Class Mean (NCM) [21].", "startOffset": 147, "endOffset": 151}, {"referenceID": 34, "context": "Alternatives directly optimize the Mahalanobis metric for nearest neighbor classification via the method of Neighbourhood Component Analysis (NCA) [11], Large Margin Nearest Neighbor (LMNN) [35] or Nearest Class Mean (NCM) [21].", "startOffset": 190, "endOffset": 194}, {"referenceID": 20, "context": "Alternatives directly optimize the Mahalanobis metric for nearest neighbor classification via the method of Neighbourhood Component Analysis (NCA) [11], Large Margin Nearest Neighbor (LMNN) [35] or Nearest Class Mean (NCM) [21].", "startOffset": 223, "endOffset": 227}, {"referenceID": 8, "context": "An intuitive remedy would be to learn multiple metrics [9], which would be computationally expensive though.", "startOffset": 55, "endOffset": 58}, {"referenceID": 36, "context": "[37] proposed a single adaptive metric using the absolute position information in random forest classifiers.", "startOffset": 0, "endOffset": 4}, {"referenceID": 36, "context": "Our approach shares the similar intuition, but incorporates the position information by a deep CNN in a more principled way, and can jointly learn similarity-aware deep features instead of using hand-crafted ones as in [37].", "startOffset": 219, "endOffset": 223}, {"referenceID": 36, "context": "Specifically, inspired by [37], apart from the feature difference vector u, we additionally incorporate the feature mean vector v = (f(xi) + f(xj))/2 to encode the absolute position.", "startOffset": 26, "endOffset": 30}, {"referenceID": 36, "context": "Unlike [37], we formulate a principled learnable similarity metric from u and v in our CNN.", "startOffset": 7, "endOffset": 11}, {"referenceID": 36, "context": "Or alternatively, we can cast the problem as a binary classification one as in [37].", "startOffset": 79, "endOffset": 83}, {"referenceID": 19, "context": "One intuitive option is to impose the Fisher criterion [20] on the similarity scores, i.", "startOffset": 55, "endOffset": 59}, {"referenceID": 26, "context": "Since all features are `2-normalized (see Figure 2), we have \u03b2+D\u00ee,\u0135\u2212D\u00ee,k\u0302 = \u03b2\u22122f(x\u00ee)f(x\u0135)+2f(x\u00ee)f(xk\u0302), and can conveniently derive the gradients as those in triplet-based methods [27, 33].", "startOffset": 180, "endOffset": 188}, {"referenceID": 32, "context": "Since all features are `2-normalized (see Figure 2), we have \u03b2+D\u00ee,\u0135\u2212D\u00ee,k\u0302 = \u03b2\u22122f(x\u00ee)f(x\u0135)+2f(x\u00ee)f(xk\u0302), and can conveniently derive the gradients as those in triplet-based methods [27, 33].", "startOffset": 180, "endOffset": 188}, {"referenceID": 0, "context": "The contrastive [1], triplet [27, 33] and lifted structured [29] embeddings select hard samples by the Euclidean distance that is not adaptive to the local feature structure.", "startOffset": 16, "endOffset": 19}, {"referenceID": 26, "context": "The contrastive [1], triplet [27, 33] and lifted structured [29] embeddings select hard samples by the Euclidean distance that is not adaptive to the local feature structure.", "startOffset": 29, "endOffset": 37}, {"referenceID": 32, "context": "The contrastive [1], triplet [27, 33] and lifted structured [29] embeddings select hard samples by the Euclidean distance that is not adaptive to the local feature structure.", "startOffset": 29, "endOffset": 37}, {"referenceID": 28, "context": "The contrastive [1], triplet [27, 33] and lifted structured [29] embeddings select hard samples by the Euclidean distance that is not adaptive to the local feature structure.", "startOffset": 60, "endOffset": 64}, {"referenceID": 0, "context": "Contrastive [1] embedding is trained on pairwise data {(xi, xj , yi,j)}, and tries to minimize the distance between the positive feature pair and penalize the distance between negative feature pair for being smaller than a margin \u03b1.", "startOffset": 12, "endOffset": 15}, {"referenceID": 26, "context": "Triplet embedding [27, 33] samples the triplet data {(xa, xp, xn)} where xa is an anchor point and xp, xn are from the same and different class, respectively.", "startOffset": 18, "endOffset": 26}, {"referenceID": 32, "context": "Triplet embedding [27, 33] samples the triplet data {(xa, xp, xn)} where xa is an anchor point and xp, xn are from the same and different class, respectively.", "startOffset": 18, "endOffset": 26}, {"referenceID": 28, "context": "While lifted structured embedding [29] considers all the positive feature pairs (e.", "startOffset": 34, "endOffset": 38}, {"referenceID": 28, "context": "Also, our method is more efficient than the lifted structured embedding [29] that requires computing dense pairwise distances within a mini-batch.", "startOffset": 72, "endOffset": 76}, {"referenceID": 30, "context": "3 Implementation details We use GoogLeNet [31] (feature dimension d = 128) and CaffeNet [16] (d = 4096) as our base network architectures for retrieval and transfer learning tasks respectively.", "startOffset": 42, "endOffset": 46}, {"referenceID": 15, "context": "3 Implementation details We use GoogLeNet [31] (feature dimension d = 128) and CaffeNet [16] (d = 4096) as our base network architectures for retrieval and transfer learning tasks respectively.", "startOffset": 88, "endOffset": 92}, {"referenceID": 29, "context": "The fully-connected layers of our PDDM unit are initialized with random weights and followed by dropout [30] with p = 0.", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": "And, we always scale S\u00ee,\u0135 into the range [0, 1] by the similarity graph in the batch.", "startOffset": 41, "endOffset": 47}, {"referenceID": 31, "context": "Specifically, we use the CUB-200-2011 [32] dataset with 200 bird classes and 11,788", "startOffset": 38, "endOffset": 42}, {"referenceID": 31, "context": "CUB-200-2011 Figure 4: Top: a comparison of the training convergence curves of our method with Euclidean- and PDDM-based hard quadruplet mining on the test sets of CUB-200-2011 [32] and CARS196 [15] datasets.", "startOffset": 177, "endOffset": 181}, {"referenceID": 14, "context": "CUB-200-2011 Figure 4: Top: a comparison of the training convergence curves of our method with Euclidean- and PDDM-based hard quadruplet mining on the test sets of CUB-200-2011 [32] and CARS196 [15] datasets.", "startOffset": 194, "endOffset": 198}, {"referenceID": 31, "context": "Table 1: Recall@K (%) on the test sets of CUB-200-2011 [32] and CARS196 [15] datasets.", "startOffset": 55, "endOffset": 59}, {"referenceID": 14, "context": "Table 1: Recall@K (%) on the test sets of CUB-200-2011 [32] and CARS196 [15] datasets.", "startOffset": 72, "endOffset": 76}, {"referenceID": 0, "context": "CUB-200-2011 CARS196 K 1 2 4 8 16 32 1 2 4 8 16 32 Contrastive [1] 26.", "startOffset": 63, "endOffset": 66}, {"referenceID": 26, "context": "4 Triplet [27, 33] 36.", "startOffset": 10, "endOffset": 18}, {"referenceID": 32, "context": "4 Triplet [27, 33] 36.", "startOffset": 10, "endOffset": 18}, {"referenceID": 28, "context": "8 LiftedStruct [29] 47.", "startOffset": 15, "endOffset": 19}, {"referenceID": 14, "context": "Another used dataset is CARS196 [15] with 196 car classes and 16,185 images.", "startOffset": 32, "endOffset": 36}, {"referenceID": 28, "context": "Note the two resulting approaches both incur lower computational costs than [29], with a near linear rather than quadratic [29] complexity in mini-batches.", "startOffset": 76, "endOffset": 80}, {"referenceID": 28, "context": "Note the two resulting approaches both incur lower computational costs than [29], with a near linear rather than quadratic [29] complexity in mini-batches.", "startOffset": 123, "endOffset": 127}, {"referenceID": 0, "context": "In particular, our full \u2018PDDM+Quadruplet\u2019 method yields large gains (8%+ Recall@K=1) over previous works [1, 27, 29, 33] all using the Euclidean distance for hard sample mining.", "startOffset": 105, "endOffset": 120}, {"referenceID": 26, "context": "In particular, our full \u2018PDDM+Quadruplet\u2019 method yields large gains (8%+ Recall@K=1) over previous works [1, 27, 29, 33] all using the Euclidean distance for hard sample mining.", "startOffset": 105, "endOffset": 120}, {"referenceID": 28, "context": "In particular, our full \u2018PDDM+Quadruplet\u2019 method yields large gains (8%+ Recall@K=1) over previous works [1, 27, 29, 33] all using the Euclidean distance for hard sample mining.", "startOffset": 105, "endOffset": 120}, {"referenceID": 32, "context": "In particular, our full \u2018PDDM+Quadruplet\u2019 method yields large gains (8%+ Recall@K=1) over previous works [1, 27, 29, 33] all using the Euclidean distance for hard sample mining.", "startOffset": 105, "endOffset": 120}, {"referenceID": 4, "context": "Table 2: The flat top-1 accuracy (%) of transfer learning on ImageNet-10K [5] and flat top-5 accuracy (%) of zero-shot learning on ImageNet 2010.", "startOffset": 74, "endOffset": 77}, {"referenceID": 4, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 70, "endOffset": 73}, {"referenceID": 25, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 74, "endOffset": 78}, {"referenceID": 22, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 79, "endOffset": 83}, {"referenceID": 17, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 84, "endOffset": 88}, {"referenceID": 20, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 89, "endOffset": 93}, {"referenceID": 21, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 105, "endOffset": 109}, {"referenceID": 7, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 117, "endOffset": 120}, {"referenceID": 23, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 125, "endOffset": 129}, {"referenceID": 24, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 130, "endOffset": 134}, {"referenceID": 20, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 135, "endOffset": 139}, {"referenceID": 9, "context": "Transfer learning on ImageNet-10K Zero-shot learning on ImageNet 2010 [5] [26] [23] [18] [21] Ours ConSE [22] DeViSE [8] PST [24] [25] [21] AMP [10] Ours 6.", "startOffset": 144, "endOffset": 148}, {"referenceID": 5, "context": "Existing methods explored the knowledge of part detectors [6] or attribute classifiers [17] across classes.", "startOffset": 58, "endOffset": 61}, {"referenceID": 16, "context": "Existing methods explored the knowledge of part detectors [6] or attribute classifiers [17] across classes.", "startOffset": 87, "endOffset": 91}, {"referenceID": 16, "context": "The description can be in terms of attributes [17], WordNet hierarchy [21, 25], semantic class label graph [10, 24], or text data [8, 22].", "startOffset": 46, "endOffset": 50}, {"referenceID": 20, "context": "The description can be in terms of attributes [17], WordNet hierarchy [21, 25], semantic class label graph [10, 24], or text data [8, 22].", "startOffset": 70, "endOffset": 78}, {"referenceID": 24, "context": "The description can be in terms of attributes [17], WordNet hierarchy [21, 25], semantic class label graph [10, 24], or text data [8, 22].", "startOffset": 70, "endOffset": 78}, {"referenceID": 9, "context": "The description can be in terms of attributes [17], WordNet hierarchy [21, 25], semantic class label graph [10, 24], or text data [8, 22].", "startOffset": 107, "endOffset": 115}, {"referenceID": 23, "context": "The description can be in terms of attributes [17], WordNet hierarchy [21, 25], semantic class label graph [10, 24], or text data [8, 22].", "startOffset": 107, "endOffset": 115}, {"referenceID": 7, "context": "The description can be in terms of attributes [17], WordNet hierarchy [21, 25], semantic class label graph [10, 24], or text data [8, 22].", "startOffset": 130, "endOffset": 137}, {"referenceID": 21, "context": "The description can be in terms of attributes [17], WordNet hierarchy [21, 25], semantic class label graph [10, 24], or text data [8, 22].", "startOffset": 130, "endOffset": 137}, {"referenceID": 1, "context": "These learning scenarios are also related to the open set one [2] where new classes grow continuously.", "startOffset": 62, "endOffset": 65}, {"referenceID": 20, "context": "For transfer learning, we follow [21] to train our feature embeddings and a Nearest Class Mean (NCM) classifier [21] on the large-scale ImageNet 20101 dataset, which contains 1,000 classes and more than 1.", "startOffset": 33, "endOffset": 37}, {"referenceID": 20, "context": "For transfer learning, we follow [21] to train our feature embeddings and a Nearest Class Mean (NCM) classifier [21] on the large-scale ImageNet 20101 dataset, which contains 1,000 classes and more than 1.", "startOffset": 112, "endOffset": 116}, {"referenceID": 4, "context": "Then we apply the NCM classifier to the larger ImageNet-10K [5] dataset with 10,000 classes, thus do not use any auxiliary knowledge such as parts and attributes.", "startOffset": 60, "endOffset": 63}, {"referenceID": 17, "context": "Table 2 shows that our features outperform state-of-the-art methods by a large margin, including the deep feature-based ones [18, 21].", "startOffset": 125, "endOffset": 133}, {"referenceID": 20, "context": "Table 2 shows that our features outperform state-of-the-art methods by a large margin, including the deep feature-based ones [18, 21].", "startOffset": 125, "endOffset": 133}, {"referenceID": 20, "context": "For zero-shot learning, we follow the standard settings in [21, 25] on ImageNet 2010: we learn our feature embeddings on 800 classes, and test on the remaining 200 classes.", "startOffset": 59, "endOffset": 67}, {"referenceID": 24, "context": "For zero-shot learning, we follow the standard settings in [21, 25] on ImageNet 2010: we learn our feature embeddings on 800 classes, and test on the remaining 200 classes.", "startOffset": 59, "endOffset": 67}], "year": 2016, "abstractText": "Existing deep embedding methods in vision tasks are capable of learning a compact Euclidean space from images, where Euclidean distances correspond to a similarity metric. To make learning more effective and efficient, hard sample mining is usually employed, with samples identified through computing the Euclidean feature distance. However, the global Euclidean distance cannot faithfully characterize the true feature similarity in a complex visual feature space, where the intraclass distance in a high-density region may be larger than the interclass distance in low-density regions. In this paper, we introduce a Position-Dependent Deep Metric (PDDM) unit, which is capable of learning a similarity metric adaptive to local feature structure. The metric can be used to select genuinely hard samples in a local neighborhood to guide the deep embedding learning in an online and robust manner. The new layer is appealing in that it is pluggable to any convolutional networks and is trained end-to-end. Our local similarity-aware feature embedding not only demonstrates faster convergence and boosted performance on two complex image retrieval datasets, its large margin nature also leads to superior generalization results under the large and open set scenarios of transfer learning and zero-shot learning on ImageNet 2010 and ImageNet-10K datasets.", "creator": "LaTeX with hyperref package"}}}