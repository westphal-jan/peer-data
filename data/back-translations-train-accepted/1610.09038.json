{"id": "1610.09038", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Oct-2016", "title": "Professor Forcing: A New Algorithm for Training Recurrent Networks", "abstract": "The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network's own one-step-ahead predictions to do multi-step sampling. We introduce the Professor Forcing algorithm, which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps. We apply Professor Forcing to language modeling, vocal synthesis on raw waveforms, handwriting generation, and image generation. Empirically we find that Professor Forcing acts as a regularizer, improving test likelihood on character level Penn Treebank and sequential MNIST. We also find that the model qualitatively improves samples, especially when sampling for a large number of time steps. This is supported by human evaluation of sample quality. Trade-offs between Professor Forcing and Scheduled Sampling are discussed. We produce T-SNEs showing that Professor Forcing successfully makes the dynamics of the network during training and sampling more similar.", "histories": [["v1", "Thu, 27 Oct 2016 23:54:31 GMT  (597kb,D)", "http://arxiv.org/abs/1610.09038v1", "NIPS 2016 Accepted Paper"]], "COMMENTS": "NIPS 2016 Accepted Paper", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["anirudh goyal", "alex lamb", "ying zhang", "saizheng zhang", "aaron c courville", "yoshua bengio"], "accepted": true, "id": "1610.09038"}, "pdf": {"name": "1610.09038.pdf", "metadata": {"source": "CRF", "title": "Professor Forcing: A New Algorithm for Training Recurrent Networks", "authors": ["Alex Lamb", "Aaron Courville"], "emails": ["anirudhgoyal9119@gmail.com", "lambalex@iro.umontreal.ca", "ying.zhlisa@gmail.com", "saizhenglisa@gmail.com", "aaron.courville@gmail.com", "yoshua.umontreal@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is so that most of them are able to surpass themselves. In fact, it is so that they are able to surpass themselves. In fact, it is so that they are able to surpass themselves. In fact, it is so that they are able to surpass themselves. In fact, it is so that they are able to surpass themselves. In fact, it is so that they are able to surpass themselves. In fact, it is so that they are able to surpass themselves. In fact, it is so that they are able to surpass themselves. In fact, it is so that they are able to surpass themselves. In fact, it is so that they are able to surpass themselves."}, {"heading": "2 Proposed Approach: Professor Forcing", "text": "The basic idea of Professor Forcing is simple: while we want the generative RNN to match the training data, we also want the behavior of the network (both in its outputs and in the dynamics of its hidden states) to be indistinguishable, whether the network is trained with its inputs attached to a training sequence (teacher forcing mode) or whether its inputs are self-generated (free-running generative mode).Since we can only compare the distribution of these sequences, it makes sense to use the generative Adversarial Networks (GANs) framework (Goodfellow et al., 2014) to achieve this second goal, to match the two distributions across sequences (which were observed in teacher forcing mode and which were observed in free-wheeling mode).Therefore, in addition to the generative RNN, we will train a second model that we call a discriminator and which can also process variable length inputs well (which we can use in the experiments in the past for the directional behavior of the NN)."}, {"heading": "2.1 Definitions and Notation", "text": "An output sequence y can also be generated by the generator RNN, if an input sequence x is given, corresponding to the sequence to the sequence model distribution P\u03b8g (y | x). An output sequence y can also be generated by the generator RNN, if an input sequence x is given. The discriminator is trained as a probabilistic classifier, which takes a behavior sequence b derived from the activity of the generative RNN as input (hiddens and outputs), if it either creates or limits a sequence y, possibly in the context of an input sequence x (frequently, but not necessarily of the same length). Behavior sequence b is either the result of executing the generative RNN in teacher compulsory mode (with y from a training sequence with input x) or in freewheeling mode (with a self-generated input sequence x) the results generated from the data x. The behavior sequence b is either the result of executing the generative RNN in teacher compulsory mode (with y from a training sequence x) the results generated by the generating mode x (with the resulting RNN in the compulsory mode)."}, {"heading": "2.2 Training Objective", "text": "The discriminator parameters \u03b8d are trained as one would expect, i.e. to maximize the probability of a correct classification of a behavioral sequence (success probability): Cd (success probability, success probability): Cd (success probability, success probability): Cd (success probability, success probability) = E (success probability, success probability, success probability). (1) Practically, this is achieved with a variant of the stochastic sequence (success probability, success probability) by combining N sequences from teacher compulsion mode and N sequences from freewheeling mode. (1) Note also that as success changes, the task optimized by the discriminator changes is also optimized, and it must track the generator, as in other GAN setups, hence the notation Cd (success probability, success probability)."}, {"heading": "3 Related Work", "text": "In fact, it is not so that it is an attempt to reform the system, but rather an attempt to reform the system. (...) It is not so that it is able to reform it. (...) It is not so that it is able to reform it. (...) It is not so that it is able to reform it. (...) It is not so that it is able to reform it. (...) It is not so that it is able to reform it. (...) It is not so that it is able to reform it. (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (...). (.).). (.). (.).). (.). (....).........................................................................................................................................................................................................................................."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Networks Architecture and Professor Forcing Setup", "text": "The generative RNN has a single hidden layer of gated recurrent units (GRU), previously introduced by (Cho et al., 2014b) as a mathematically cheaper alternative to discriminated LSTM units (Hochreiter and Schmidhuber, 1997). At any time, the generative RNN reads an element of the input sequence (if any) and an element of the output sequence yt (either derived from the training data or generated by the RNN in the previous step). It then updates its state ht as a function of its previous state ht \u2212 1 and the current input sequence (xt, yt). It then calculates a probability distribution P\u03b8g (yt + 1 | ht) = P\u03b8g (yt + 1 | x1,.., xt, yt)."}, {"heading": "4.2 Character-Level Language Modeling", "text": "We evaluate Professor Forcing at character level Language modeling on Penn-Treebank Corpus, which has an alphabet size of 50 and consists of 5059 characters for training, 396 characters for validation, and 446 characters for testing. We divide the training set into non-overlapping sequences with each length of 500. During training, we monitor the negative log probability (NLL) of the output sequences. The final model is evaluated metrically by bits per character (BPC). The generative RNN implements a 1 hidden layer GRU with 1024 hidden units. We use Adam algorithm for optimization with a learning rate of 0.0001. We feed both the hidden states and character level embedding into the discriminator. All shifts in the discriminator consist of 2048 hidden units. The output activation of the last shift is truncated between -10 and 10. We see that the training costs of Professor Forcing Network decrease faster than the teachers force the network."}, {"heading": "4.3 Sequential MNIST", "text": "We used the binarized MNIST standard data set Murray and Salakhutdinov (2009). We selected hyperparameters for our model on the validation set and chose 512 hidden states and a learning rate of 0.0001. For all experiments we used a 3-layer GRU as generator. In contrast to our other experiments we used a revolutionary network for the discriminator instead of a bidirectional RNN, because the pixels have a 2D spatial structure. We found that our model achieves the second best probability for this task, after PixelRNN, which used a much more complicated architecture for its generator van den Oord et al. (2016)."}, {"heading": "4.4 Handwriting Generation", "text": "With this task, we wanted to investigate whether Professor Forcing can be used to perform a domain adjustment from a training set of short sequences to sampling much longer sequences. We trained the Teacher Forcing model using only 50 steps of text-conditioned handwriting (corresponding to some letters) and then 1000 time steps. We let the model learn a sequence of (x, y) coordinates along with binary indicators for pen-up vs. pen-down, using the standard IAM-OnDB handwriting dataset, which consists of 13,040 handwritten lines written by 500 writers Liwicki and Bunke (2005). For our Teacher Forcing Model, we use the open source implementation Brebisson (2016) and use its hyperparameters, which are based on the model in Graves (2013). For the Professor Forcing Model, we sample 1000 time steps and perform a separate segmentation of the number of steps not overlapping in the 50 steps."}, {"heading": "4.5 Music Synthesis on Raw Waveforms", "text": "We looked at the task of voice synthesis on raw waveforms. For this task, we used three hours of monk song audio scraped from YouTube (https: / / www.youtube.com / watch? v = 9-pD28iSiTU). We sampled the audio at a rate of 1 kHz and took four seconds for each training and validation example. At each step of the raw audio waveform, we recorded the value of the signal in 8,000 vessels with uniformly drawn boundaries between the smallest and largest signal values in the dataset. We then modeled the raw audio waveform as a 4000-long sequence with 8000 potential values in each time step. We evaluated the quality of our voice synthesis model based on two criteria. First, we demonstrated a regulating effect and improvement in negative log probability. Second, we observed an improvement in the quality of the samples (we observed a generative improvement in the quality of the samples."}, {"heading": "4.6 Negative Results on Shorter Sequences", "text": "At the Penn Treebank word level, we observed no difference between teacher forcing and professor forcing. One possible explanation for this difference is the increasing importance of long-term dependencies in character-level language modeling. Also, in speech synthesis, we observed no difference between teacher forcing and professor forcing while practicing sequences of less than 100 length."}, {"heading": "5 Conclusion", "text": "The idea of matching the behavior of a model when it runs alone, making predictions, generating samples, etc., versus when it is forced to be consistent with the observed data is old and powerful. In this essay, we introduce Professor Forcing, a novel instance of this idea, when the interest model is a recursive generative one and is based on the formation of an auxiliary model, the discriminator, to detect the differences in behavior between these two behaviors. An important motivation for this approach is that the discriminator can look at behavioral statistics and not just the one-step predictions, which forces the generator to behave the same when constrained by the data and when it generates itself sequences that can be much longer than the training sequences. This, of course, leads to better generalization over sequences that are much longer than the training sequences, as we have found. We also found that it has helped to add better sequences to the predictive sequences, which we may actually be very promising (if we do)."}, {"heading": "6 Acknowledgments", "text": "We thank Martin Arjovsky, Dzmitry Bahdanau, Nan Rosemary Ke, Kyle Kastner, Jos\u00e9 Manuel Rodr\u00edguez Sotelo, Alexandre de Br\u00e9bisson, Olexa Bilaniuk, Hal Daum\u00e9 III, Kari Torkkola and David Krueger for their helpful feedback."}], "references": [{"title": "Domain-Adversarial Neural Networks", "author": ["H. Ajakan", "P. Germain", "H. Larochelle", "F. Laviolette", "M. Marchand"], "venue": "ArXiv e-prints.", "citeRegEx": "Ajakan et al\\.,? 2014", "shortCiteRegEx": "Ajakan et al\\.", "year": 2014}, {"title": "Theano: A python framework for fast computation of mathematical expressions. CoRR, abs/1605.02688", "author": ["R. Al-Rfou", "G. Alain", "A. Almahairi"], "venue": null, "citeRegEx": "Al.Rfou et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Al.Rfou et al\\.", "year": 2016}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "arXiv preprint arXiv:1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "End-to-end attention-based large vocabulary speech recognition", "author": ["D. Bahdanau", "J. Chorowski", "D. Serdyuk", "P. Brakel", "Y. Bengio"], "venue": "arXiv preprint arXiv:1508.04395.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "An Actor-Critic Algorithm for Sequence Prediction", "author": ["D. Bahdanau", "P. Brakel", "K. Xu", "A. Goyal", "R. Lowe", "J. Pineau", "A. Courville", "Y. Bengio"], "venue": "ArXiv e-prints.", "citeRegEx": "Bahdanau et al\\.,? 2016", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2016}, {"title": "Scheduled sampling for sequence prediction with recurrent neural networks", "author": ["S. Bengio", "O. Vinyals", "N. Jaitly", "N. Shazeer"], "venue": "Advances in Neural Information Processing Systems, pages 1171\u20131179.", "citeRegEx": "Bengio et al\\.,? 2015", "shortCiteRegEx": "Bengio et al\\.", "year": 2015}, {"title": "Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation", "author": ["Y. Bengio", "N. L\u00e9onard", "A. Courville"], "venue": "ArXiv e-prints.", "citeRegEx": "Bengio et al\\.,? 2013", "shortCiteRegEx": "Bengio et al\\.", "year": 2013}, {"title": "Conditional handwriting generation in theano", "author": ["A. Brebisson"], "venue": "https://github.com/adbrebs/ handwriting.", "citeRegEx": "Brebisson,? 2016", "shortCiteRegEx": "Brebisson", "year": 2016}, {"title": "Mind\u2019s eye: A recurrent visual representation for image caption generation", "author": ["X. Chen", "C. Lawrence Zitnick"], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2422\u20132431.", "citeRegEx": "Chen and Zitnick,? 2015", "shortCiteRegEx": "Chen and Zitnick", "year": 2015}, {"title": "Learning phrase representations using RNN encoder\u2013decoder for statistical machine translation", "author": ["K. Cho", "B. Van Merri\u00ebnboer", "\u00c7. G\u00fcl\u00e7ehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1724\u20131734, Doha, Qatar. Association for Computational Linguistics.", "citeRegEx": "Cho et al\\.,? 2014a", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. Van Merri\u00ebnboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "arXiv preprint arXiv:1406.1078.", "citeRegEx": "Cho et al\\.,? 2014b", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "Attention-based models for speech recognition", "author": ["J.K. Chorowski", "D. Bahdanau", "D. Serdyuk", "K. Cho", "Y. Bengio"], "venue": "Advances in Neural Information Processing Systems, pages 577\u2013585.", "citeRegEx": "Chorowski et al\\.,? 2015", "shortCiteRegEx": "Chorowski et al\\.", "year": 2015}, {"title": "Search-based Structured Prediction", "author": ["III Daum\u00e9", "H.", "J. Langford", "D. Marcu"], "venue": "ArXiv e-prints.", "citeRegEx": "Daum\u00e9 et al\\.,? 2009", "shortCiteRegEx": "Daum\u00e9 et al\\.", "year": 2009}, {"title": "Domain-Adversarial Training of Neural Networks", "author": ["Y. Ganin", "E. Ustinova", "H. Ajakan", "P. Germain", "H. Larochelle", "F. Laviolette", "M. Marchand", "V. Lempitsky"], "venue": "ArXiv e-prints.", "citeRegEx": "Ganin et al\\.,? 2015", "shortCiteRegEx": "Ganin et al\\.", "year": 2015}, {"title": "Made: Masked autoencoder for distribution estimation", "author": ["M. Germain", "K. Gregor", "I. Murray", "H. Larochelle"], "venue": "arXiv preprint arXiv:1502.03509.", "citeRegEx": "Germain et al\\.,? 2015", "shortCiteRegEx": "Germain et al\\.", "year": 2015}, {"title": "Generative adversarial networks", "author": ["I.J. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "NIPS\u20192014.", "citeRegEx": "Goodfellow et al\\.,? 2014", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Supervised Sequence Labelling with Recurrent Neural Networks", "author": ["A. Graves"], "venue": "Studies in Computational Intelligence. Springer.", "citeRegEx": "Graves,? 2012", "shortCiteRegEx": "Graves", "year": 2012}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "Technical report, arXiv:1308.0850.", "citeRegEx": "Graves,? 2013", "shortCiteRegEx": "Graves", "year": 2013}, {"title": "Generating Sequences With Recurrent Neural Networks", "author": ["A. Graves"], "venue": "ArXiv e-prints.", "citeRegEx": "Graves,? 2013", "shortCiteRegEx": "Graves", "year": 2013}, {"title": "Draw: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D. Wierstra"], "venue": "arXiv preprint arXiv:1502.04623.", "citeRegEx": "Gregor et al\\.,? 2015", "shortCiteRegEx": "Gregor et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Comput., 9(8), 1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber", "year": 1997}, {"title": "How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary? ArXiv e-prints", "author": ["F. Husz\u00e1r"], "venue": null, "citeRegEx": "Husz\u00e1r,? \\Q2015\\E", "shortCiteRegEx": "Husz\u00e1r", "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980.", "citeRegEx": "Kingma and Ba,? 2014", "shortCiteRegEx": "Kingma and Ba", "year": 2014}, {"title": "The neural autoregressive distribution estimator", "author": ["H. Larochelle", "I. Murray"], "venue": null, "citeRegEx": "Larochelle and Murray,? \\Q2011\\E", "shortCiteRegEx": "Larochelle and Murray", "year": 2011}, {"title": "Iam-ondb - an on-line english sentence database acquired from handwritten text on a whiteboard", "author": ["M. Liwicki", "H. Bunke"], "venue": "Eighth International Conference on Document Analysis and Recognition (ICDAR\u201905), pages 956\u2013961 Vol. 2.", "citeRegEx": "Liwicki and Bunke,? 2005", "shortCiteRegEx": "Liwicki and Bunke", "year": 2005}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov"], "venue": null, "citeRegEx": "Mikolov,? \\Q2010\\E", "shortCiteRegEx": "Mikolov", "year": 2010}, {"title": "Context dependent recurrent neural network language model", "author": ["T. Mikolov", "G. Zweig"], "venue": null, "citeRegEx": "Mikolov and Zweig,? \\Q2012\\E", "shortCiteRegEx": "Mikolov and Zweig", "year": 2012}, {"title": "Evaluating probabilities under high-dimensional latent variable models", "author": ["I. Murray", "R.R. Salakhutdinov"], "venue": "D. Koller, D. Schuurmans, Y. Bengio, and L. Bottou, editors, Advances in Neural Information Processing Systems 21, pages 1137\u20131144. Curran Associates, Inc.", "citeRegEx": "Murray and Salakhutdinov,? 2009", "shortCiteRegEx": "Murray and Salakhutdinov", "year": 2009}, {"title": "Iterative neural autoregressive distribution estimator NADE-k", "author": ["T. Raiko", "L. Yao", "K. Cho", "Y. Bengio"], "venue": "Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 27 (NIPS 2014), pages 325\u2013333. Curran Associates, Inc.", "citeRegEx": "Raiko et al\\.,? 2014", "shortCiteRegEx": "Raiko et al\\.", "year": 2014}, {"title": "A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning", "author": ["S. Ross", "G.J. Gordon", "J.A. Bagnell"], "venue": "ArXiv e-prints.", "citeRegEx": "Ross et al\\.,? 2010", "shortCiteRegEx": "Ross et al\\.", "year": 2010}, {"title": "Markov chain monte carlo and variational inference: Bridging the gap", "author": ["T. Salimans", "D.P. Kingma", "M. Welling"], "venue": "arXiv preprint arXiv:1410.6460.", "citeRegEx": "Salimans et al\\.,? 2014", "shortCiteRegEx": "Salimans et al\\.", "year": 2014}, {"title": "Sequence to sequence learning with neural networks", "author": ["I. Sutskever", "O. Vinyals", "Q.V. Le"], "venue": "Advances in neural information processing systems, pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "A note on the evaluation of generative models. ArXiv e-prints", "author": ["L. Theis", "A. van den Oord", "M. Bethge"], "venue": null, "citeRegEx": "Theis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Theis et al\\.", "year": 2015}, {"title": "A learning algorithm for continually running fully recurrent neural networks", "author": ["R.J. Williams", "D. Zipser"], "venue": "Neural computation, 1(2), 270\u2013280.", "citeRegEx": "Williams and Zipser,? 1989", "shortCiteRegEx": "Williams and Zipser", "year": 1989}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "A. Courville", "R. Salakhutdinov", "R. Zemel", "Y. Bengio"], "venue": "arXiv preprint arXiv:1502.03044.", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 16, "context": "Recurrent neural networks (RNNs) have become to be the generative models of choice for sequential data (Graves, 2012) with impressive results in language modeling (Mikolov, 2010; Mikolov and Zweig, 2012), speech recognition (Bahdanau et al.", "startOffset": 103, "endOffset": 117}, {"referenceID": 25, "context": "Recurrent neural networks (RNNs) have become to be the generative models of choice for sequential data (Graves, 2012) with impressive results in language modeling (Mikolov, 2010; Mikolov and Zweig, 2012), speech recognition (Bahdanau et al.", "startOffset": 163, "endOffset": 203}, {"referenceID": 26, "context": "Recurrent neural networks (RNNs) have become to be the generative models of choice for sequential data (Graves, 2012) with impressive results in language modeling (Mikolov, 2010; Mikolov and Zweig, 2012), speech recognition (Bahdanau et al.", "startOffset": 163, "endOffset": 203}, {"referenceID": 3, "context": "Recurrent neural networks (RNNs) have become to be the generative models of choice for sequential data (Graves, 2012) with impressive results in language modeling (Mikolov, 2010; Mikolov and Zweig, 2012), speech recognition (Bahdanau et al., 2015; Chorowski et al., 2015), Machine Translation (Cho et al.", "startOffset": 224, "endOffset": 271}, {"referenceID": 11, "context": "Recurrent neural networks (RNNs) have become to be the generative models of choice for sequential data (Graves, 2012) with impressive results in language modeling (Mikolov, 2010; Mikolov and Zweig, 2012), speech recognition (Bahdanau et al., 2015; Chorowski et al., 2015), Machine Translation (Cho et al.", "startOffset": 224, "endOffset": 271}, {"referenceID": 9, "context": ", 2015), Machine Translation (Cho et al., 2014a; Sutskever et al., 2014; Bahdanau et al., 2014), handwriting generation (Graves, 2013), image caption generation (Xu et al.", "startOffset": 29, "endOffset": 95}, {"referenceID": 31, "context": ", 2015), Machine Translation (Cho et al., 2014a; Sutskever et al., 2014; Bahdanau et al., 2014), handwriting generation (Graves, 2013), image caption generation (Xu et al.", "startOffset": 29, "endOffset": 95}, {"referenceID": 2, "context": ", 2015), Machine Translation (Cho et al., 2014a; Sutskever et al., 2014; Bahdanau et al., 2014), handwriting generation (Graves, 2013), image caption generation (Xu et al.", "startOffset": 29, "endOffset": 95}, {"referenceID": 17, "context": ", 2014), handwriting generation (Graves, 2013), image caption generation (Xu et al.", "startOffset": 32, "endOffset": 46}, {"referenceID": 34, "context": ", 2014), handwriting generation (Graves, 2013), image caption generation (Xu et al., 2015; Chen and Lawrence Zitnick, 2015), etc.", "startOffset": 73, "endOffset": 123}, {"referenceID": 33, "context": "In the RNN literature, this form of training is also known as teacher forcing (Williams and Zipser, 1989), due to the use of the ground-truth samples yt being fed back into the model to be conditioned on for the prediction of later outputs.", "startOffset": 78, "endOffset": 105}, {"referenceID": 5, "context": "Recently, (Bengio et al., 2015) proposed to remedy that issue by mixing two kinds of inputs during training: those from the ground-truth training sequence and those generated from the model.", "startOffset": 10, "endOffset": 31}, {"referenceID": 5, "context": "Recently, (Bengio et al., 2015) proposed to remedy that issue by mixing two kinds of inputs during training: those from the ground-truth training sequence and those generated from the model. However, when the model generates several consecutive yt\u2019s, it is not clear anymore that the correct target (in terms of its distribution) remains the one in the ground truth sequence. This is mitigated in various ways, by making the self-generated subsequences short and annealing the probability of using self-generated vs ground truth samples. However, as remarked by Husz\u00e1r (2015), scheduled sampling yields a biased estimator, in that even as the number of examples and the capacity go to infinity, this procedure may not converge to the correct model.", "startOffset": 11, "endOffset": 576}, {"referenceID": 15, "context": "Because we can only compare the distribution of these sequences, it makes sense to take advantage of the generative adversarial networks (GANs) framework (Goodfellow et al., 2014) to achieve that second objective of matching the two distributions over sequences (the one observed in teacher forcing mode vs the one observed in free-running mode).", "startOffset": 154, "endOffset": 179}, {"referenceID": 15, "context": "Professor Forcing is an adversarial method for learning generative models that is closely related to Generative Adversarial Networks (Goodfellow et al., 2014) and Adversarial Domain Adaptation Ajakan et al.", "startOffset": 133, "endOffset": 158}, {"referenceID": 12, "context": "(2015), which is closely related to SEARN (Daum\u00e9 et al., 2009) and DAGGER Ross et al.", "startOffset": 42, "endOffset": 62}, {"referenceID": 0, "context": ", 2014) and Adversarial Domain Adaptation Ajakan et al. (2014); Ganin et al.", "startOffset": 42, "endOffset": 63}, {"referenceID": 0, "context": ", 2014) and Adversarial Domain Adaptation Ajakan et al. (2014); Ganin et al. (2015). Our approach is similar to generative adversarial networks (GANs) because both use a discriminative classifier to provide gradients for training a generative model.", "startOffset": 42, "endOffset": 84}, {"referenceID": 0, "context": ", 2014) and Adversarial Domain Adaptation Ajakan et al. (2014); Ganin et al. (2015). Our approach is similar to generative adversarial networks (GANs) because both use a discriminative classifier to provide gradients for training a generative model. However, Professor Forcing is different because the classifier discriminates between hidden states from sampling mode and teacher forcing mode, whereas the GAN\u2019s classifier discriminates between real samples and generated samples. One practical advantage of Professor Forcing over GANs is that Professor Forcing can be used to learn a generative model over discrete random variables without requiring to approximate backpropagation through discrete spaces Bengio et al. (2013). The Adversarial Domain Adaptation uses a classifier to discriminate between the hidden states of the network with inputs from the source domain and the hidden states of the network with inputs from the target domain.", "startOffset": 42, "endOffset": 727}, {"referenceID": 0, "context": ", 2014) and Adversarial Domain Adaptation Ajakan et al. (2014); Ganin et al. (2015). Our approach is similar to generative adversarial networks (GANs) because both use a discriminative classifier to provide gradients for training a generative model. However, Professor Forcing is different because the classifier discriminates between hidden states from sampling mode and teacher forcing mode, whereas the GAN\u2019s classifier discriminates between real samples and generated samples. One practical advantage of Professor Forcing over GANs is that Professor Forcing can be used to learn a generative model over discrete random variables without requiring to approximate backpropagation through discrete spaces Bengio et al. (2013). The Adversarial Domain Adaptation uses a classifier to discriminate between the hidden states of the network with inputs from the source domain and the hidden states of the network with inputs from the target domain. However this method was not applied in the context of generative models, more specifically, was not applied to the task of improving long-term generation from recurrent networks. Alternative non-adversarial methods have been explored for improving long-term generation from recurrent networks. The scheduled sampling method Bengio et al. (2015), which is closely related to SEARN (Daum\u00e9 et al.", "startOffset": 42, "endOffset": 1290}, {"referenceID": 0, "context": ", 2014) and Adversarial Domain Adaptation Ajakan et al. (2014); Ganin et al. (2015). Our approach is similar to generative adversarial networks (GANs) because both use a discriminative classifier to provide gradients for training a generative model. However, Professor Forcing is different because the classifier discriminates between hidden states from sampling mode and teacher forcing mode, whereas the GAN\u2019s classifier discriminates between real samples and generated samples. One practical advantage of Professor Forcing over GANs is that Professor Forcing can be used to learn a generative model over discrete random variables without requiring to approximate backpropagation through discrete spaces Bengio et al. (2013). The Adversarial Domain Adaptation uses a classifier to discriminate between the hidden states of the network with inputs from the source domain and the hidden states of the network with inputs from the target domain. However this method was not applied in the context of generative models, more specifically, was not applied to the task of improving long-term generation from recurrent networks. Alternative non-adversarial methods have been explored for improving long-term generation from recurrent networks. The scheduled sampling method Bengio et al. (2015), which is closely related to SEARN (Daum\u00e9 et al., 2009) and DAGGER Ross et al. (2010), involves randomly using the network\u2019s predictions as its inputs (as in sampling mode) with some probability that increases over the course of training.", "startOffset": 42, "endOffset": 1376}, {"referenceID": 0, "context": ", 2014) and Adversarial Domain Adaptation Ajakan et al. (2014); Ganin et al. (2015). Our approach is similar to generative adversarial networks (GANs) because both use a discriminative classifier to provide gradients for training a generative model. However, Professor Forcing is different because the classifier discriminates between hidden states from sampling mode and teacher forcing mode, whereas the GAN\u2019s classifier discriminates between real samples and generated samples. One practical advantage of Professor Forcing over GANs is that Professor Forcing can be used to learn a generative model over discrete random variables without requiring to approximate backpropagation through discrete spaces Bengio et al. (2013). The Adversarial Domain Adaptation uses a classifier to discriminate between the hidden states of the network with inputs from the source domain and the hidden states of the network with inputs from the target domain. However this method was not applied in the context of generative models, more specifically, was not applied to the task of improving long-term generation from recurrent networks. Alternative non-adversarial methods have been explored for improving long-term generation from recurrent networks. The scheduled sampling method Bengio et al. (2015), which is closely related to SEARN (Daum\u00e9 et al., 2009) and DAGGER Ross et al. (2010), involves randomly using the network\u2019s predictions as its inputs (as in sampling mode) with some probability that increases over the course of training. This forces the network to be able to stay in a reasonable regime when receiving the network\u2019s predictions as inputs instead of observed inputs. While Scheduled Sampling shows improvement on some tasks, it is not a consistent estimation strategy. This limitation arises because the outputs sampled from the network could correspond to a distribution that is not consistent with the sequence that the network is trained to generate. This issue is discussed in detail in Husz\u00e1r (2015). A practical advantage of Scheduled Sampling over Professor Forcing is that Scheduled Sampling does not require the additional overhead of having to train a discriminator network.", "startOffset": 42, "endOffset": 2012}, {"referenceID": 0, "context": ", 2014) and Adversarial Domain Adaptation Ajakan et al. (2014); Ganin et al. (2015). Our approach is similar to generative adversarial networks (GANs) because both use a discriminative classifier to provide gradients for training a generative model. However, Professor Forcing is different because the classifier discriminates between hidden states from sampling mode and teacher forcing mode, whereas the GAN\u2019s classifier discriminates between real samples and generated samples. One practical advantage of Professor Forcing over GANs is that Professor Forcing can be used to learn a generative model over discrete random variables without requiring to approximate backpropagation through discrete spaces Bengio et al. (2013). The Adversarial Domain Adaptation uses a classifier to discriminate between the hidden states of the network with inputs from the source domain and the hidden states of the network with inputs from the target domain. However this method was not applied in the context of generative models, more specifically, was not applied to the task of improving long-term generation from recurrent networks. Alternative non-adversarial methods have been explored for improving long-term generation from recurrent networks. The scheduled sampling method Bengio et al. (2015), which is closely related to SEARN (Daum\u00e9 et al., 2009) and DAGGER Ross et al. (2010), involves randomly using the network\u2019s predictions as its inputs (as in sampling mode) with some probability that increases over the course of training. This forces the network to be able to stay in a reasonable regime when receiving the network\u2019s predictions as inputs instead of observed inputs. While Scheduled Sampling shows improvement on some tasks, it is not a consistent estimation strategy. This limitation arises because the outputs sampled from the network could correspond to a distribution that is not consistent with the sequence that the network is trained to generate. This issue is discussed in detail in Husz\u00e1r (2015). A practical advantage of Scheduled Sampling over Professor Forcing is that Scheduled Sampling does not require the additional overhead of having to train a discriminator network. Actor-critic methods have also been explored for improving modeling of long-term dependencies in generative recurrent neural networks Bahdanau et al. (2016). Finally, the idea of matching the behavior of the model when it is generating in a free-running way with its behavior when it is constrained by the observed data (being clamped on the \"visible units\") is precisely that which one obtains when zeroing the maximum likelihood gradient on undirected graphical models with latent variables such as the Boltzmann machine.", "startOffset": 42, "endOffset": 2349}, {"referenceID": 10, "context": "The generative RNN has single hidden layer of gated recurrent units (GRU), previously introduced by (Cho et al., 2014b) as a computationally cheaper alternative to LSTM units (Hochreiter and Schmidhuber, 1997).", "startOffset": 100, "endOffset": 119}, {"referenceID": 20, "context": ", 2014b) as a computationally cheaper alternative to LSTM units (Hochreiter and Schmidhuber, 1997).", "startOffset": 64, "endOffset": 98}, {"referenceID": 22, "context": "Both networks are trained by minibatch stochastic gradient descent with adaptive learning rates and momentum determined by the Adam algorithm (Kingma and Ba, 2014).", "startOffset": 142, "endOffset": 163}, {"referenceID": 1, "context": "All of our experiments were implemented using the Theano framework (Al-Rfou et al., 2016).", "startOffset": 67, "endOffset": 89}, {"referenceID": 14, "context": "Method MNIST NLL DBN 2hl (Germain et al., 2015) \u2248 84.", "startOffset": 25, "endOffset": 47}, {"referenceID": 23, "context": "55 NADE (Larochelle and Murray, 2011) 88.", "startOffset": 8, "endOffset": 37}, {"referenceID": 28, "context": "33 EoNADE-5 2hl (Raiko et al., 2014) 84.", "startOffset": 16, "endOffset": 36}, {"referenceID": 30, "context": "68 DLGM 8 leapfrog steps (Salimans et al., 2014) \u2248 85.", "startOffset": 25, "endOffset": 48}, {"referenceID": 19, "context": "51 DARN 1hl (Gregor et al., 2015) \u2248 84.", "startOffset": 12, "endOffset": 33}, {"referenceID": 19, "context": "13 DRAW (Gregor et al., 2015) \u2264 80.", "startOffset": 8, "endOffset": 29}, {"referenceID": 27, "context": "We use the standard binarized MNIST dataset Murray and Salakhutdinov (2009). We selected hyperparameters for our model on the validation set and elected to use 512 hidden states and a learning rate of 0.", "startOffset": 44, "endOffset": 76}, {"referenceID": 27, "context": "We use the standard binarized MNIST dataset Murray and Salakhutdinov (2009). We selected hyperparameters for our model on the validation set and elected to use 512 hidden states and a learning rate of 0.0001. For all experiments we used a 3-layer GRU as our generator. Unlike our other experiments, we used a convolutional network for the discriminator instead of a bi-directional RNN, as the pixels have a 2D spatial structure. We note that our model achieves the second best reported likelihood on this task, after the PixelRNN, which used a significantly more complicated architecture for its generator van den Oord et al. (2016). Combining Professor Forcing with the PixelRNN would be an interesting area for future research.", "startOffset": 44, "endOffset": 633}, {"referenceID": 20, "context": "pen-down, using the standard handwriting IAM-OnDB dataset, which consists of 13,040 handwritten lines written by 500 writers Liwicki and Bunke (2005). For our teacher forcing model, we use the open source implementation Brebisson (2016) and use their hyperparameters which is based on the model in Graves (2013).", "startOffset": 125, "endOffset": 150}, {"referenceID": 7, "context": "For our teacher forcing model, we use the open source implementation Brebisson (2016) and use their hyperparameters which is based on the model in Graves (2013).", "startOffset": 69, "endOffset": 86}, {"referenceID": 7, "context": "For our teacher forcing model, we use the open source implementation Brebisson (2016) and use their hyperparameters which is based on the model in Graves (2013). For the professor forcing model, we sample for 1000 time steps and run a separate discriminator on non-overlapping segments of length 50 (the number of steps used in the teacher forcing model).", "startOffset": 69, "endOffset": 161}, {"referenceID": 32, "context": "This issue was discussed in Theis et al. (2015). However, this is unlikely to be an issue with our evaluation because our method also improved validation set likelihood, whereas a model that achieves quality samples by dropping coverage would have poorer validation set likelihood.", "startOffset": 28, "endOffset": 48}], "year": 2016, "abstractText": "The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network\u2019s own one-stepahead predictions to do multi-step sampling. We introduce the Professor Forcing algorithm, which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps. We apply Professor Forcing to language modeling, vocal synthesis on raw waveforms, handwriting generation, and image generation. Empirically we find that Professor Forcing acts as a regularizer, improving test likelihood on character level Penn Treebank and sequential MNIST. We also find that the model qualitatively improves samples, especially when sampling for a large number of time steps. This is supported by human evaluation of sample quality. Trade-offs between Professor Forcing and Scheduled Sampling are discussed. We produce T-SNEs showing that Professor Forcing successfully makes the dynamics of the network during training and sampling more similar.", "creator": "LaTeX with hyperref package"}}}