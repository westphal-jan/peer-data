{"id": "1610.09369", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "28-Oct-2016", "title": "Discriminative Gaifman Models", "abstract": "We present discriminative Gaifman models, a novel family of relational machine learning models. Gaifman models learn feature representations bottom up from representations of locally connected and bounded-size regions of knowledge bases (KBs). Considering local and bounded-size neighborhoods of knowledge bases renders logical inference and learning tractable, mitigates the problem of overfitting, and facilitates weight sharing. Gaifman models sample neighborhoods of knowledge bases so as to make the learned relational models more robust to missing objects and relations which is a common situation in open-world KBs. We present the core ideas of Gaifman models and apply them to large-scale relational learning problems. We also discuss the ways in which Gaifman models relate to some existing relational machine learning approaches.", "histories": [["v1", "Fri, 28 Oct 2016 11:57:26 GMT  (636kb,D)", "http://arxiv.org/abs/1610.09369v1", "NIPS 2016"]], "COMMENTS": "NIPS 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["mathias niepert"], "accepted": true, "id": "1610.09369"}, "pdf": {"name": "1610.09369.pdf", "metadata": {"source": "CRF", "title": "Discriminative Gaifman Models", "authors": ["Mathias Niepert"], "emails": ["mathias.niepert@neclabs.eu"], "sections": [{"heading": "1 Introduction", "text": "In this context, it should be noted that the case is a case of an accident in which a person has been killed."}, {"heading": "2 Background", "text": "First, we examine some important concepts and notations in first-order logic."}, {"heading": "2.1 Relational First-order Logic", "text": "An atom r (t1,..., tn) consists of predicate r of unity n followed by n arguments, which are either elements of a finite domain D = {a, b,...} or logical variables {x, y,...}. We use the terms domain element and object synonymous. A base atom is an atom without logical variables. Formulas are formed from atoms using the usual Boolean connectives and existential and universal quantification. A free variable in a first order formula is a variable x, which is not within the scope of a quantifier."}, {"heading": "2.2 Gaifman\u2019s Locality Theorem", "text": "The Gaifman graph of an R structure D is the graph GD with the vertice D and an edge between two vertices d, d, and D, if and only if there is an r-R and a tuple (d1,..., dk). The distance dD (d1, d2) between two elements d1, d2, and D of a structure D is the length of the shortest path in GD that connects d1 and d2. For r-1 and d-D we define the r neighborhood of a d formula that should be Nr (d, d2)."}, {"heading": "3 Learning Gaifman Models", "text": "Instead of applying the costly approach to applying the relationship model and the conclusions directly to the entire knowledge base, we offer a detailed description of Gaifman's approach. (...) In addition, the results of the Gaifman models are applied from a given knowledge base (or collection of knowledge bases), a set of knowledge and a set of knowledge used for learning. (...) In the face of an R-structureD, a discriminatory Gaifman model forD is a tuple (q, k, M) like this: \"It is a first order formula designated as a target query with at least one free variable;\" It is the depth of the Gaifman neighborhoods; \"k is the size limitation of the Gaifman neighborhoods;\" We have a set of formulas of the first order (the relational characteristics); \"M is the basis of the model class (loss, hyperparameters, Gaifman models, etc.) We offer detailed explanations of the Gaifman models, etc."}, {"heading": "3.1 Learning Distributions for Relational Queries", "text": "rE's hta, \"he says,\" is that we are able to hide. \"ndU's hta,\" he says. \"It's an eeisn,\" he says. \"It's as if we are able to be in a position.\" It's as if we are able to hide, \"he says.\" \"It's as if we are able to be in a position.\" \"We,\" he says, \"are able to be in a position.\" \"We,\" he says, \"are able to be.\""}, {"heading": "3.2 Structure Learning", "text": "Structural learning is the problem of determining the set of relationship characteristics and. In addition, we provide some directions and leave the problem to future work. In view of a collection of neighborhoods of limited size of the Gaifman diagram, the goal is to determine suitable relationship characteristics for the present problem. There are a number of characteristics that we have considered to be most effective, for example formulas of the form x r (s1, x), x r (s1, x), r (x, s2) and x, y r1 (s1, x) r2 (x, y) as well as formulas formulas of the form x (y, s2) for all relationships. The latter formulas capture paths of fixed length between s1 and s2 in the neighborhoods. Therefore, characteristics of the Path Ranking [15] can be used in Gaifman models as a specific relational feature class."}, {"heading": "3.3 Prior Confidence Values, Types, and Numerical Attributes", "text": "Numerous existing knowledge bases assign confidence values (probabilities, weights, etc.) to their statements. Gaifman models can include confidence values during the sampling and learning process. Instead of adding random noise to the representations, which we found advantageous, noise can be added inversely proportional to the confidence values. Statements where the previous confidence values are lower are more likely to fail during the training than statements with higher confidence values. In addition, Gaifman models can directly include object types such as actors and action movies, as well as numerical features such as location and height. All you have to do is set a fixed position in the neighborhood representation v for each object position within the input tupel d."}, {"heading": "4 Related Work", "text": "We will focus on a few methods that we consider directly to be Gaifman models and refer the interested reader to the above article. Their method is not applicable to large KB's and depends on predetermined thresholds. [15] Examples of this are a logistic regression classifier with path characteristics to perform KB completion, the idea being to perform a random walk between objects and to exploit the paths as characteristics. SFE [10] improves the generation of random migrations to be more efficient. Newer methods for embedding methods in KB's with methods for embedding KB [17]. Gaifman models support a much broader class of relational characteristics."}, {"heading": "6 Conclusion and Future Work", "text": "The Gaifman models are a novel family of relational machine learning models that perform learning and conclusions within and across locally connected regions of relational structures. Future research directions include structural learning, more sophisticated base model classes, and the application of Gaifman models to additional relational ML problems."}, {"heading": "Acknowledgements", "text": "Many thanks to Alberto Garc\u00eda-Dur\u00e1n, Mohamed Ahmed and Kristian Kersting for their helpful feedback."}], "references": [{"title": "Global learning of typed entailment rules", "author": ["J. Berant", "I. Dagan", "J. Goldberger"], "venue": "Annual Meeting of the Association for Computational Linguistics, pages 610\u2013619,", "citeRegEx": "1", "shortCiteRegEx": null, "year": 2011}, {"title": "Freebase: A collaboratively created graph database for structuring human knowledge", "author": ["K. Bollacker", "C. Evans", "P. Paritosh", "T. Sturge", "J. Taylor"], "venue": "SIGMOD, pages 1247\u20131250,", "citeRegEx": "2", "shortCiteRegEx": null, "year": 2008}, {"title": "Joint learning of words and meaning representations for open-text semantic parsing", "author": ["A. Bordes", "X. Glorot", "J. Weston", "Y. Bengio"], "venue": "Conference on Artificial Intelligence and Statistics, pages 127\u2013135,", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2012}, {"title": "Translating embeddings for modeling multi-relational data", "author": ["A. Bordes", "N. Usunier", "A. Garcia-Duran", "J. Weston", "O. Yakhnenko"], "venue": "Neural Information Processing Systems, pages 2787\u20132795.", "citeRegEx": "4", "shortCiteRegEx": null, "year": 2013}, {"title": "Learning structured embeddings of knowledge bases", "author": ["A. Bordes", "J. Weston", "R. Collobert", "Y. Bengio"], "venue": "AAAI Conference on Artificial Intelligence,", "citeRegEx": "5", "shortCiteRegEx": null, "year": 2011}, {"title": "Toward an architecture for never-ending language learning", "author": ["A. Carlson", "J. Betteridge", "B. Kisiel", "B. Settles", "E.R. Hruschka", "T.M. Mitchell"], "venue": "Twenty-Fourth AAAI Conference on Artificial Intelligence,", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2010}, {"title": "Open-world probabilistic databases", "author": ["I.I. Ceylan", "A. Darwiche", "G. Van den Broeck"], "venue": "In Proceedings of the 15th International Conference on Principles of Knowledge Representation and Reasoning (KR),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "ProbLog2: Probabilistic logic programming", "author": ["A. Dries", "A. Kimmig", "W. Meert", "J. Renkens", "G. Van den Broeck", "J. Vlasselaer", "L. De Raedt"], "venue": "Lecture Notes in Computer Science,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "On local and non-local properties", "author": ["H. Gaifman"], "venue": "Proceedings of the herbrand symposium, logic colloquium, volume 81, pages 105\u2013135,", "citeRegEx": "9", "shortCiteRegEx": null, "year": 1982}, {"title": "Efficient and expressive knowledge base completion using subgraph feature extraction", "author": ["M. Gardner", "T.M. Mitchell"], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1488\u20131498,", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2015}, {"title": "Yago2: A spatially and temporally enhanced knowledge base from wikipedia", "author": ["J. Hoffart", "F.M. Suchanek", "K. Berberich", "G. Weikum"], "venue": "Artif. Intell., 194:28\u201361,", "citeRegEx": "11", "shortCiteRegEx": null, "year": 2013}, {"title": "A latent factor model for highly multi-relational data", "author": ["R. Jenatton", "N.L. Roux", "A. Bordes", "G.R. Obozinski"], "venue": "Neural Information Processing Systems, pages 3167\u20133175,", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2012}, {"title": "Knowledge graph completion with adaptive sparse transfer matrix", "author": ["G. Ji", "K. Liu", "S. He", "J. Zhao"], "venue": "D. Schuurmans and M. P. Wellman, editors, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pages 985\u2013991,", "citeRegEx": "13", "shortCiteRegEx": null, "year": 2016}, {"title": "Lifted probabilistic inference", "author": ["K. Kersting"], "venue": "European Conference on Artificial Intelligence, pages 33\u201338,", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2012}, {"title": "Random walk inference and learning in a large scale knowledge base", "author": ["N. Lao", "T. Mitchell", "W.W. Cohen"], "venue": "Empirical Methods in Natural Language Processing, pages 529\u2013539,", "citeRegEx": "15", "shortCiteRegEx": null, "year": 2011}, {"title": "Elements Of Finite Model Theory", "author": ["L. Libkin"], "venue": "SpringerVerlag,", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2004}, {"title": "Modeling relation paths for representation learning of knowledge bases", "author": ["Y. Lin", "Z. Liu", "H. Luan", "M. Sun", "S. Rao", "S. Liu"], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 705\u2013714,", "citeRegEx": "17", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning entity and relation embeddings for knowledge graph completion", "author": ["Y. Lin", "Z. Liu", "M. Sun", "Y. Liu", "X. Zhu"], "venue": "AAAI Conference on Artificial Intelligence, pages 2181\u20132187,", "citeRegEx": "18", "shortCiteRegEx": null, "year": 2015}, {"title": "Probabilistic Models with Unknown Objects", "author": ["B.C. Milch"], "venue": "PhD thesis,", "citeRegEx": "19", "shortCiteRegEx": null, "year": 2006}, {"title": "A review of relational machine learning for knowledge graphs", "author": ["M. Nickel", "K. Murphy", "V. Tresp", "E. Gabrilovich"], "venue": "Proceedings of the IEEE, 104(1):11\u201333,", "citeRegEx": "20", "shortCiteRegEx": null, "year": 2016}, {"title": "A three-way model for collective learning on multi-relational data", "author": ["M. Nickel", "V. Tresp", "H.-P. Kriegel"], "venue": "International conference on machine learning (ICML), pages 809\u2013816,", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2011}, {"title": "Markov logic networks", "author": ["M. Richardson", "P. Domingos"], "venue": "Machine learning, 62(1-2):107\u2013136,", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2006}, {"title": "Relation extraction with matrix factorization and universal schemas", "author": ["S. Riedel", "L. Yao", "B.M. Marlin", "A. McCallum"], "venue": "HLT-NAACL,", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2013}, {"title": "Injecting logical background knowledge into embeddings for relation extraction", "author": ["T. Rockt\u00e4schel", "S. Singh", "S. Riedel"], "venue": "Conference of the North American Chapter of the ACL (NAACL),", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning first-order horn clauses from web text", "author": ["S. Schoenmackers", "O. Etzioni", "D.S. Weld", "J. Davis"], "venue": "Conference on Empirical Methods in Natural Language Processing, pages 1088\u20131098,", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["R. Socher", "D. Chen", "C.D. Manning", "A. Ng"], "venue": "Neural Information Processing Systems, pages 926\u2013934.", "citeRegEx": "26", "shortCiteRegEx": null, "year": 2013}, {"title": "Complex embeddings for simple link prediction", "author": ["T. Trouillon", "J. Welbl", "S. Riedel", "\u00c9. Gaussier", "G. Bouchard"], "venue": "Proceedings of the 33nd International Conference on Machine Learning, volume 48, pages 2071\u20132080,", "citeRegEx": "27", "shortCiteRegEx": null, "year": 2016}, {"title": "Lifted inference and learning in statistical relational models", "author": ["G. Van den Broeck"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2013}, {"title": "The complexity of relational query languages", "author": ["M.Y. Vardi"], "venue": "ACM symposium on Theory of computing, pages 137\u2013146,", "citeRegEx": "29", "shortCiteRegEx": null, "year": 1982}, {"title": "Embedding entities and relations for learning and inference in knowledge bases", "author": ["B. Yang", "W.-t. Yih", "X. He", "J. Gao", "L. Deng"], "venue": "In International Conference on Learning Representations,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Unsupervised resolution of objects and relations on the web", "author": ["A. Yates", "O. Etzioni"], "venue": "Conference of the North American Chapter of the Association for Computational Linguistics,", "citeRegEx": "31", "shortCiteRegEx": null, "year": 2007}], "referenceMentions": [{"referenceID": 1, "context": "Knowledge bases are attracting considerable interest both from industry and academia [2, 6, 15, 10].", "startOffset": 85, "endOffset": 99}, {"referenceID": 5, "context": "Knowledge bases are attracting considerable interest both from industry and academia [2, 6, 15, 10].", "startOffset": 85, "endOffset": 99}, {"referenceID": 14, "context": "Knowledge bases are attracting considerable interest both from industry and academia [2, 6, 15, 10].", "startOffset": 85, "endOffset": 99}, {"referenceID": 9, "context": "Knowledge bases are attracting considerable interest both from industry and academia [2, 6, 15, 10].", "startOffset": 85, "endOffset": 99}, {"referenceID": 1, "context": "Instances of knowledge bases are the web graph, social and citation networks, and multi-relational knowledge graphs such as Freebase [2] and YAGO [11].", "startOffset": 133, "endOffset": 136}, {"referenceID": 10, "context": "Instances of knowledge bases are the web graph, social and citation networks, and multi-relational knowledge graphs such as Freebase [2] and YAGO [11].", "startOffset": 146, "endOffset": 150}, {"referenceID": 21, "context": "Research in statistical relational learning (SRL) has focused on particular formalisms such as Markov logic [22] and PROBLOG [8] and is often concerned with improving the efficiency of inference and learning [14, 28].", "startOffset": 108, "endOffset": 112}, {"referenceID": 7, "context": "Research in statistical relational learning (SRL) has focused on particular formalisms such as Markov logic [22] and PROBLOG [8] and is often concerned with improving the efficiency of inference and learning [14, 28].", "startOffset": 125, "endOffset": 128}, {"referenceID": 13, "context": "Research in statistical relational learning (SRL) has focused on particular formalisms such as Markov logic [22] and PROBLOG [8] and is often concerned with improving the efficiency of inference and learning [14, 28].", "startOffset": 208, "endOffset": 216}, {"referenceID": 27, "context": "Research in statistical relational learning (SRL) has focused on particular formalisms such as Markov logic [22] and PROBLOG [8] and is often concerned with improving the efficiency of inference and learning [14, 28].", "startOffset": 208, "endOffset": 216}, {"referenceID": 4, "context": "Examples are knowledge base factorization and embedding approaches [5, 21, 23, 26] and random-walk based ML models [15, 10].", "startOffset": 67, "endOffset": 82}, {"referenceID": 20, "context": "Examples are knowledge base factorization and embedding approaches [5, 21, 23, 26] and random-walk based ML models [15, 10].", "startOffset": 67, "endOffset": 82}, {"referenceID": 22, "context": "Examples are knowledge base factorization and embedding approaches [5, 21, 23, 26] and random-walk based ML models [15, 10].", "startOffset": 67, "endOffset": 82}, {"referenceID": 25, "context": "Examples are knowledge base factorization and embedding approaches [5, 21, 23, 26] and random-walk based ML models [15, 10].", "startOffset": 67, "endOffset": 82}, {"referenceID": 14, "context": "Examples are knowledge base factorization and embedding approaches [5, 21, 23, 26] and random-walk based ML models [15, 10].", "startOffset": 115, "endOffset": 123}, {"referenceID": 9, "context": "Examples are knowledge base factorization and embedding approaches [5, 21, 23, 26] and random-walk based ML models [15, 10].", "startOffset": 115, "endOffset": 123}, {"referenceID": 8, "context": "Gaifman\u2019s locality theorem [9] is a result in the area of finite model theory [16].", "startOffset": 27, "endOffset": 30}, {"referenceID": 15, "context": "Gaifman\u2019s locality theorem [9] is a result in the area of finite model theory [16].", "startOffset": 78, "endOffset": 82}, {"referenceID": 6, "context": "The problem also touches on the problem of open-world probabilistic KBs [7] since tuples whose prior probability is zero will often have a non-zero probability in the query answer.", "startOffset": 72, "endOffset": 75}, {"referenceID": 8, "context": "[9] Every first-order sentence is equivalent to a Boolean combination of local sentences.", "startOffset": 0, "endOffset": 3}, {"referenceID": 18, "context": "Moreover, the sampling strategy makes Gaifman models more robust to object uncertainty [19].", "startOffset": 87, "endOffset": 91}, {"referenceID": 28, "context": "The combined complexity of model checking is PSPACEcomplete [29] and there exists a ||D||O(||\u03c6||) algorithm for both problems where || \u00b7 || is the size of an encoding.", "startOffset": 60, "endOffset": 64}, {"referenceID": 14, "context": "Hence, Path Ranking type features [15] can be used in Gaifman models as a particular relational feature class.", "startOffset": 34, "endOffset": 38}, {"referenceID": 19, "context": "Recent work on relational machine learning for knowledge graphs is surveyed in [20].", "startOffset": 79, "endOffset": 83}, {"referenceID": 30, "context": "Examples include [31] and [1] where inference rules of length one are learned; and [25] where general inference rules are learned by applying a support threshold.", "startOffset": 17, "endOffset": 21}, {"referenceID": 0, "context": "Examples include [31] and [1] where inference rules of length one are learned; and [25] where general inference rules are learned by applying a support threshold.", "startOffset": 26, "endOffset": 29}, {"referenceID": 24, "context": "Examples include [31] and [1] where inference rules of length one are learned; and [25] where general inference rules are learned by applying a support threshold.", "startOffset": 83, "endOffset": 87}, {"referenceID": 14, "context": "[15] train a logistic regression classifier with path features to perform KB completion.", "startOffset": 0, "endOffset": 4}, {"referenceID": 9, "context": "SFE [10] improves PRA by making the generation of random walks more efficient.", "startOffset": 4, "endOffset": 8}, {"referenceID": 16, "context": "More recent embedding methods have combined paths in KBs with KB embedding methods [17].", "startOffset": 83, "endOffset": 87}, {"referenceID": 20, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 59, "endOffset": 71}, {"referenceID": 22, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 59, "endOffset": 71}, {"referenceID": 25, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 59, "endOffset": 71}, {"referenceID": 4, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 93, "endOffset": 114}, {"referenceID": 2, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 93, "endOffset": 114}, {"referenceID": 3, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 93, "endOffset": 114}, {"referenceID": 17, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 93, "endOffset": 114}, {"referenceID": 12, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 93, "endOffset": 114}, {"referenceID": 26, "context": "Examples of latent feature models are tensor factorization [21, 23, 26] and embedding models [5, 3, 4, 18, 13, 27].", "startOffset": 93, "endOffset": 114}, {"referenceID": 22, "context": "For instance, the universal schema [23] considers pairs of objects where relation membership variables comprise the model\u2019s features.", "startOffset": 35, "endOffset": 39}, {"referenceID": 22, "context": "We have the following interesting relationship between universal schemas [23] and Gaifman models.", "startOffset": 73, "endOffset": 77}, {"referenceID": 22, "context": "The Gaifman model for D with r = 0, k = 2, \u03a6 = \u22c3r\u2208R{r(s1, s2), r(s2, s1)}, w = 1 and w\u0303 = 0 is equivalent to the Universal Schema [23] for D up to the base model classM.", "startOffset": 130, "endOffset": 134}, {"referenceID": 23, "context": "More recent methods combine embedding methods and inference-based logical approaches for relation extraction [24].", "startOffset": 109, "endOffset": 113}, {"referenceID": 19, "context": "Contrary to most existing multi-relational ML models [20], Gaifman models natively support higher-arity relations, functional and type constraints, numerical features, and complex target queries.", "startOffset": 53, "endOffset": 57}, {"referenceID": 1, "context": "We evaluate the proposed class of models with two data sets derived from the knowledge bases WORDNET and FREEBASE [2].", "startOffset": 114, "endOffset": 117}, {"referenceID": 3, "context": "For a detailed description of the data sets, whose statistics are listed in Table 1, we refer the reader to previous work [4].", "startOffset": 122, "endOffset": 125}, {"referenceID": 20, "context": "Data Set WN18 FB15K Metric Mean rank Hits@10 Hits@1 Mean rank Hits@10 Hits@1 RESCAL[21] 1,163 52.", "startOffset": 83, "endOffset": 87}, {"referenceID": 4, "context": "1 SE[5] 985 80.", "startOffset": 4, "endOffset": 7}, {"referenceID": 11, "context": "8 LFM[12] 456 81.", "startOffset": 5, "endOffset": 9}, {"referenceID": 3, "context": "1 TransE[4] 251 89.", "startOffset": 8, "endOffset": 11}, {"referenceID": 17, "context": "1 TransR[18] 219 91.", "startOffset": 8, "endOffset": 12}, {"referenceID": 29, "context": "5 DistMult[30] 902 93.", "startOffset": 10, "endOffset": 14}, {"referenceID": 0, "context": "8 Gaifman [1, 20, 1, 2] 357 88.", "startOffset": 10, "endOffset": 23}, {"referenceID": 19, "context": "8 Gaifman [1, 20, 1, 2] 357 88.", "startOffset": 10, "endOffset": 23}, {"referenceID": 0, "context": "8 Gaifman [1, 20, 1, 2] 357 88.", "startOffset": 10, "endOffset": 23}, {"referenceID": 1, "context": "8 Gaifman [1, 20, 1, 2] 357 88.", "startOffset": 10, "endOffset": 23}, {"referenceID": 0, "context": "1 Gaifman [1, 20, 5, 25] 392 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 19, "context": "1 Gaifman [1, 20, 5, 25] 392 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 4, "context": "1 Gaifman [1, 20, 5, 25] 392 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 24, "context": "1 Gaifman [1, 20, 5, 25] 392 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 1, "context": "6 Gaifman [2, 20, 5, 25] 378 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 19, "context": "6 Gaifman [2, 20, 5, 25] 378 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 4, "context": "6 Gaifman [2, 20, 5, 25] 378 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 24, "context": "6 Gaifman [2, 20, 5, 25] 378 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 2, "context": "5 Gaifman [3, 20, 5, 25] 352 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 19, "context": "5 Gaifman [3, 20, 5, 25] 352 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 4, "context": "5 Gaifman [3, 20, 5, 25] 352 93.", "startOffset": 10, "endOffset": 24}, {"referenceID": 24, "context": "5 Gaifman [3, 20, 5, 25] 352 93.", "startOffset": 10, "endOffset": 24}], "year": 2016, "abstractText": "We present discriminative Gaifman models, a novel family of relational machine learning models. Gaifman models learn feature representations bottom up from representations of locally connected and bounded-size regions of knowledge bases (KBs). Considering local and bounded-size neighborhoods of knowledge bases renders logical inference and learning tractable, mitigates the problem of overfitting, and facilitates weight sharing. Gaifman models sample neighborhoods of knowledge bases so as to make the learned relational models more robust to missing objects and relations which is a common situation in open-world KBs. We present the core ideas of Gaifman models and apply them to large-scale relational learning problems. We also discuss the ways in which Gaifman models relate to some existing relational machine learning approaches.", "creator": "LaTeX with hyperref package"}}}