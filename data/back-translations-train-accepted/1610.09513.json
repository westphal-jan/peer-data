{"id": "1610.09513", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "29-Oct-2016", "title": "Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences", "abstract": "Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. However, current RNN models are ill-suited to process irregularly sampled data triggered by events generated in continuous time by sensors or other neurons. Such data can occur, for example, when the input comes from novel event-driven artificial sensors that generate sparse, asynchronous streams of events or from multiple conventional sensors with different update intervals. In this work, we introduce the Phased LSTM model, which extends the LSTM unit by adding a new time gate. This gate is controlled by a parametrized oscillation with a frequency range that produces updates of the memory cell only during a small percentage of the cycle. Even with the sparse updates imposed by the oscillation, the Phased LSTM network achieves faster convergence than regular LSTMs on tasks which require learning of long sequences. The model naturally integrates inputs from sensors of arbitrary sampling rates, thereby opening new areas of investigation for processing asynchronous sensory events that carry timing information. It also greatly improves the performance of LSTMs in standard RNN applications, and does so with an order-of-magnitude fewer computes at runtime.", "histories": [["v1", "Sat, 29 Oct 2016 14:05:10 GMT  (1016kb,D)", "http://arxiv.org/abs/1610.09513v1", "Selected for an oral presentation at NIPS, 2016"]], "COMMENTS": "Selected for an oral presentation at NIPS, 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["daniel neil", "michael pfeiffer", "shih-chii liu"], "accepted": true, "id": "1610.09513"}, "pdf": {"name": "1610.09513.pdf", "metadata": {"source": "CRF", "title": "Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences", "authors": ["Daniel Neil", "Michael Pfeiffer"], "emails": ["shih}@ini.uzh.ch"], "sections": [{"heading": "1 Introduction", "text": "Interest in recursive neural networks (RNNs) has grown rapidly in recent years as larger training databases, more powerful computer resources and better training algorithms have enabled breakthroughs in both processing and modeling of time sequences. Applications include speech recognition [1, 20] and attention-based models for structured prediction [5, 29]. RNNs are attractive because they provide neural networks with memories, and the introduction of belt units such as LSTM and GRU has greatly contributed to making learning of these networks manageable."}, {"heading": "2 Model Description", "text": "The main differences to classical RNNs are the use of the gating functions it, ft, ot, which represent the input, and the output gate at the time of activation of the cell. [16] (fig. 1 (a)) are the hidden functions. [16] (fig. 1 (a)) are important components for modern deep RNN architectures. We first define their updated equations in the commonly used version of [12]: it = ft ct \u2212 1 + it (xtWxc + wci ct) ct \u2212 1 + bi) (3) ft = p (xtWxo + ht \u2212 1Whf ct ct ct ct) (2) ct \u2212 1 + it (xtWxc + ht \u2212 1Whc). The main difference to classical RNs is the use of the gating functions it, ft, ot, which represent the input, and output gate at the moment."}, {"heading": "3 Results", "text": "In the following sections, we will examine the advantages of the phased LSTM model in a variety of scenarios that require either precise timing of updates or learning from a long sequence. Adam [18] trained the networks for all of the results presented here, setting the preset learning rate parameters using Theano [2] with lasagna [9]. Unless otherwise specified, the leakage rate was set to \u03b1 = 0.001 during training and \u03b1 = 0 during testing. Phase shift s was uniformly selected from the interval [0, \u03c4] for each neuron. Parameters \u03c4 and s were learned during training, while the open ratio ron was set to 0.05 and not adjusted during training, except in the first task to show that the model can successfully train while all parameters are learned."}, {"heading": "3.1 Frequency Discrimination Task", "text": "In this first experiment, the network is regularly distinguished between two classes of sine waves in different frequency ranges (125)."}, {"heading": "3.2 Adding Task", "text": "To investigate how the introduction of time gates helps to learn when a long memory is needed, we review an original LSTM task, which is called the addition of a task [16]. In this task, a sequence of random numbers is presented along with an indicator input stream. If there is a 0 in the indicator input stream, the displayed value should be ignored; a 1 indicates that the value should be added. At the end of the presentation, the network produces a sum of all the indicated values. Unlike the previous tasks, there is no inherent periodicity in the input, and it is one of the original tasks that LSTM should solve well. This seems to work against the advantages of phased-LSTM, but the use of a longer period for the time frame could allow for more effective training, as one unit during the training only opens a few periods, and it is one of the original tasks that LSTM has been well solved."}, {"heading": "3.3 N-MNIST Event-Based Visual Recognition", "text": "The recordings come from an event-based image sensor that is sensitive to local temporal contrast changes [26].An event is generated from one pixel when its local contrast variation exceeds a threshold. Each event is generated as a 4-tuple < x, y, p > with position x, y of the pixel, a polarity bit p (indicating contrast increase or decrease), and a timestamp indicating the time in which the event is generated. Recordings consist of events generated by the visual sensor, while the sensor undergoes three saccadian motions showing a static digit from the MNIST data (Fig. 5a).An example of the event response can be seen in Fig. 5c."}, {"heading": "3.4 Visual-Auditory Sensor Fusion for Lip Reading", "text": "In fact, most of us are able to play by the rules that they have imposed on themselves, and they are able to play by the rules that they have imposed on themselves, \"he told the Deutsche Presse-Agentur.\" We have to play by the rules, \"he said.\" We have to play by the rules. \"He added:\" We have to play by the rules that we have to play by, and we have to play by the rules that we play by. \""}, {"heading": "4 Discussion", "text": "The Phased LSTM has many surprising advantages. With its rhythmic periodicity, it acts like a learnable gated Fourier transformation on its input, allowing for very fine timing discrimination. Alternatively, rhythmic periodicity can be seen as a kind of permanent dropout that preserves the state [27] and increases the variety of models. Rhythmic inactivation can even be seen as an abbreviation of the past for gradient backpropagation and speeds up training. The results presented support these interpretations and demonstrate the ability to distinguish rhythmic signals and learn long memory traces. Importantly, in all experiments, Phased LSTM converges faster and theoretically only 5% of the calculations at runtime, while accuracy frequently improves compared to standard LSTM. The methods presented can also easily be extended to GRUs [6], and it is likely that even simpler models, such as those using a quadratic oscillation, will work more efficiently through STM and STROsillers]."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Theano: a CPU and GPU math expression compiler", "author": ["J. Bergstra", "O. Breuleux", "F. Bastien", "P. Lamblin", "R. Pascanu", "G. Desjardins", "J. Turian", "D. Warde-Farley", "Y. Bengio"], "venue": "In Proceedings of the Python for scientific computing conference (SciPy),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2010}, {"title": "Rhythms of the Brain", "author": ["G. Buzsaki"], "venue": null, "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2006}, {"title": "An analog VLSI recurrent neural network learning a continuous-time trajectory", "author": ["G. Cauwenberghs"], "venue": "IEEE Transactions on Neural Networks,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 1996}, {"title": "Describing multimedia content using attention-based encoder-decoder networks", "author": ["K. Cho", "A. Courville", "Y. Bengio"], "venue": "IEEE Transactions on Multimedia,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["K. Cho", "B. van Merrienboer", "C. Gulcehre", "F. Bougares", "H. Schwenk", "Y. Bengio"], "venue": "arXiv preprint arXiv:1406.1078,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Skimming digits: Neuromorphic classification of spike-encoded images", "author": ["G.K. Cohen", "G. Orchard", "S.H. Ieng", "J. Tapson", "R.B. Benosman", "A. van Schaik"], "venue": "Frontiers in Neuroscience,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2016}, {"title": "An audio-visual corpus for speech perception and automatic speech recognition", "author": ["M. Cooke", "J. Barker", "S. Cunningham", "X. Shao"], "venue": "The Journal of the Acoustical Society of America,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2006}, {"title": "Approximation of dynamical systems by continuous time recurrent neural networks", "author": ["K.-I. Funahashi", "Y. Nakamura"], "venue": "Neural Networks,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 1993}, {"title": "Recurrent nets that time and count", "author": ["F.A. Gers", "J. Schmidhuber"], "venue": "In Neural Networks,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2000}, {"title": "Generating sequences with recurrent neural networks", "author": ["A. Graves"], "venue": "arXiv preprint arXiv:1308.0850,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2013}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["A. Graves", "A.-R. Mohamed", "G. Hinton"], "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2013}, {"title": "Deep speech: Scaling up end-to-end speech recognition", "author": ["A. Hannun", "C. Case", "J. Casper", "B. Catanzaro", "G. Diamos", "E. Elsen", "R. Prenger", "S. Satheesh", "S. Sengupta", "A. Coates"], "venue": "arXiv preprint arXiv:1412.5567,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "In The IEEE International Conference on Computer Vision (ICCV),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 1997}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "A clockwork rnn", "author": ["J. Koutnik", "K. Greff", "F. Gomez", "J. Schmidhuber"], "venue": "arXiv preprint arXiv:1402.3511,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2014}, {"title": "Recurrent neural network based language model", "author": ["T. Mikolov", "M. Karafi\u00e1t", "L. Burget", "J. Cernock\u1ef3", "S. Khudanpur"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2010}, {"title": "Effective sensor fusion with event-based sensors and deep network architectures", "author": ["D. Neil", "S.-C. Liu"], "venue": "In IEEE Int. Symposium on Circuits and Systems (ISCAS),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity", "author": ["B. Nessler", "M. Pfeiffer", "L. Buesing", "W. Maass"], "venue": "PLoS Comput Biol,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2013}, {"title": "Real-time classification and sensor fusion with a spiking Deep Belief Network", "author": ["P. O\u2019Connor", "D. Neil", "S.-C. Liu", "T. Delbruck", "M. Pfeiffer"], "venue": "Frontiers in Neuroscience,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2013}, {"title": "Converting static image datasets to spiking neuromorphic datasets using saccades", "author": ["G. Orchard", "A. Jayawant", "G. Cohen", "N. Thakor"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Learning state space trajectories in recurrent neural networks", "author": ["B.A. Pearlmutter"], "venue": "Neural Computation,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 1989}, {"title": "Retinomorphic event-based vision sensors: bioinspired cameras with spiking outputs", "author": ["C. Posch", "T. Serrano-Gotarredona", "B. Linares-Barranco", "T. Delbruck"], "venue": "Proceedings of the IEEE,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2014}, {"title": "Recurrent dropout without memory", "author": ["S. Semeniuta", "A. Severyn", "E. Barth"], "venue": "loss. arXiv,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2016}, {"title": "Lipreading with long short-term memory", "author": ["M. Wand", "J. Koutn\u00edk", "J. Schmidhuber"], "venue": "arXiv preprint arXiv:1601.08188,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["K. Xu", "J. Ba", "R. Kiros", "K. Cho", "A. Courville", "R. Salakhutdinov", "R. Zemel", "Y. Bengio"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}], "referenceMentions": [{"referenceID": 11, "context": "Applications include speech recognition [13], natural language processing [1, 20], and attention-based models for structured prediction [5, 29].", "startOffset": 40, "endOffset": 44}, {"referenceID": 0, "context": "Applications include speech recognition [13], natural language processing [1, 20], and attention-based models for structured prediction [5, 29].", "startOffset": 74, "endOffset": 81}, {"referenceID": 17, "context": "Applications include speech recognition [13], natural language processing [1, 20], and attention-based models for structured prediction [5, 29].", "startOffset": 74, "endOffset": 81}, {"referenceID": 4, "context": "Applications include speech recognition [13], natural language processing [1, 20], and attention-based models for structured prediction [5, 29].", "startOffset": 136, "endOffset": 143}, {"referenceID": 26, "context": "Applications include speech recognition [13], natural language processing [1, 20], and attention-based models for structured prediction [5, 29].", "startOffset": 136, "endOffset": 143}, {"referenceID": 14, "context": "RNNs are attractive because they equip neural networks with memories, and the introduction of gating units such as LSTM and GRU [16, 6] has greatly helped in making the learning of these networks manageable.", "startOffset": 128, "endOffset": 135}, {"referenceID": 5, "context": "RNNs are attractive because they equip neural networks with memories, and the introduction of gating units such as LSTM and GRU [16, 6] has greatly helped in making the learning of these networks manageable.", "startOffset": 128, "endOffset": 135}, {"referenceID": 22, "context": "Although early work such as [25, 10, 4] has realized the resulting limitations and suggested continuous-time dynamical systems approaches towards RNNs, the great majority of modern RNN implementations uses fixed time steps.", "startOffset": 28, "endOffset": 39}, {"referenceID": 8, "context": "Although early work such as [25, 10, 4] has realized the resulting limitations and suggested continuous-time dynamical systems approaches towards RNNs, the great majority of modern RNN implementations uses fixed time steps.", "startOffset": 28, "endOffset": 39}, {"referenceID": 3, "context": "Although early work such as [25, 10, 4] has realized the resulting limitations and suggested continuous-time dynamical systems approaches towards RNNs, the great majority of modern RNN implementations uses fixed time steps.", "startOffset": 28, "endOffset": 39}, {"referenceID": 14, "context": "Long short-term memory (LSTM) units [16] (Fig.", "startOffset": 36, "endOffset": 40}, {"referenceID": 10, "context": "We first define their update equations in the commonly-used version from [12]:", "startOffset": 73, "endOffset": 77}, {"referenceID": 9, "context": "Optional peephole [11] connection weights wci, wcf , wco further influence the operation of the input, forget, and output gates.", "startOffset": 18, "endOffset": 22}, {"referenceID": 13, "context": "The leak with rate \u03b1 is active in the closed phase, and plays a similar role as the leak in a parametric \u201cleaky\u201d rectified linear unit [15] by propagating important gradient information even when the gate is closed.", "startOffset": 135, "endOffset": 139}, {"referenceID": 16, "context": "In contrast to traditional RNNs, and even sparser variants of RNNs [19], updates in Phased LSTM can optionally be performed at irregularly sampled time points tj .", "startOffset": 67, "endOffset": 71}, {"referenceID": 15, "context": "For all the results presented here, the networks were trained with Adam [18] set to default learning rate parameters, using Theano [2] with Lasagne [9].", "startOffset": 72, "endOffset": 76}, {"referenceID": 1, "context": "For all the results presented here, the networks were trained with Adam [18] set to default learning rate parameters, using Theano [2] with Lasagne [9].", "startOffset": 131, "endOffset": 134}, {"referenceID": 12, "context": "We compare our Phased LSTM configuration to regular LSTM, and batch-normalized (BN) LSTM which has found success in certain applications [14].", "startOffset": 137, "endOffset": 141}, {"referenceID": 21, "context": "(b) Frame-based representation of an \u20188\u2019 digit from the N-MNIST dataset [24] obtained by integrating all input spikes for each pixel.", "startOffset": 72, "endOffset": 76}, {"referenceID": 14, "context": "To investigate how introducing time gates helps learning when long memory is required, we revisit an original LSTM task called the adding task [16].", "startOffset": 143, "endOffset": 147}, {"referenceID": 21, "context": "To test performance on real-world asynchronously sampled data, we make use of the publiclyavailable N-MNIST [24] dataset for neuromorphic vision.", "startOffset": 108, "endOffset": 112}, {"referenceID": 23, "context": "The recordings come from an event-based vision sensor that is sensitive to local temporal contrast changes [26].", "startOffset": 107, "endOffset": 111}, {"referenceID": 18, "context": "In previous work using event-based input data [21, 23], the timing information was sometimes removed and instead a frame-based representation was generated by computing the pixel-wise event-rate over some time period (as shown in Fig.", "startOffset": 46, "endOffset": 54}, {"referenceID": 20, "context": "In previous work using event-based input data [21, 23], the timing information was sometimes removed and instead a frame-based representation was generated by computing the pixel-wise event-rate over some time period (as shown in Fig.", "startOffset": 46, "endOffset": 54}, {"referenceID": 21, "context": "It is also worth noting that these results form a new state-of-the-art accuracy for this dataset [24, 7].", "startOffset": 97, "endOffset": 104}, {"referenceID": 6, "context": "It is also worth noting that these results form a new state-of-the-art accuracy for this dataset [24, 7].", "startOffset": 97, "endOffset": 104}, {"referenceID": 7, "context": "For this task, we use the GRID dataset [8].", "startOffset": 39, "endOffset": 42}, {"referenceID": 25, "context": "15% compares favorably against lipreading-focused state-of-the-art approaches [28] while avoiding manually-crafted features.", "startOffset": 78, "endOffset": 82}, {"referenceID": 24, "context": "Alternatively, the rhythmic periodicity can be viewed as a kind of persistent dropout that preserves state [27], enhancing model diversity.", "startOffset": 107, "endOffset": 111}, {"referenceID": 5, "context": "The presented methods can also easily be extended to GRUs [6], and it is likely that even simpler models, such as ones that use a square-wave-like oscillation, will perform well, thereby making even more efficient and encouraging alternative Phased LSTM formulations.", "startOffset": 58, "endOffset": 61}, {"referenceID": 2, "context": "An inspiration for using oscillations in recurrent networks comes from computational neuroscience [3], where rhythms have been shown to play important roles for synchronization and plasticity [22].", "startOffset": 98, "endOffset": 101}, {"referenceID": 19, "context": "An inspiration for using oscillations in recurrent networks comes from computational neuroscience [3], where rhythms have been shown to play important roles for synchronization and plasticity [22].", "startOffset": 192, "endOffset": 196}], "year": 2016, "abstractText": "Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. However, current RNN models are ill-suited to process irregularly sampled data triggered by events generated in continuous time by sensors or other neurons. Such data can occur, for example, when the input comes from novel event-driven artificial sensors that generate sparse, asynchronous streams of events or from multiple conventional sensors with different update intervals. In this work, we introduce the Phased LSTM model, which extends the LSTM unit by adding a new time gate. This gate is controlled by a parametrized oscillation with a frequency range that produces updates of the memory cell only during a small percentage of the cycle. Even with the sparse updates imposed by the oscillation, the Phased LSTM network achieves faster convergence than regular LSTMs on tasks which require learning of long sequences. The model naturally integrates inputs from sensors of arbitrary sampling rates, thereby opening new areas of investigation for processing asynchronous sensory events that carry timing information. It also greatly improves the performance of LSTMs in standard RNN applications, and does so with an order-of-magnitude fewer computes at runtime.", "creator": "LaTeX with hyperref package"}}}