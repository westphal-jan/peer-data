{"id": "1611.00094", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Nov-2016", "title": "Learning recurrent representations for hierarchical behavior modeling", "abstract": "We propose a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, using a generative recurrent neural network. The network has a discriminative part (classifying actions) and a generative part (predicting motion), whose recurrent cells are laterally connected, allowing higher levels of the network to represent high level phenomena. We test our framework on two types of data, fruit fly behavior and online handwriting. Our results show that 1) taking advantage of unlabeled sequences, by predicting future motion, significantly improves action detection performance when training labels are scarce, 2) the network learns to represent high level phenomena such as writer identity and fly gender, without supervision, and 3) simulated motion trajectories, generated by treating motion prediction as input to the network, look realistic and may be used to qualitatively evaluate whether the model has learnt generative control rules.", "histories": [["v1", "Tue, 1 Nov 2016 01:03:53 GMT  (5366kb,D)", "http://arxiv.org/abs/1611.00094v1", null], ["v2", "Thu, 3 Nov 2016 23:39:43 GMT  (7526kb,D)", "http://arxiv.org/abs/1611.00094v2", null], ["v3", "Tue, 15 Nov 2016 18:06:10 GMT  (7527kb,D)", "http://arxiv.org/abs/1611.00094v3", null]], "reviews": [], "SUBJECTS": "cs.AI cs.CV", "authors": ["eyrun eyjolfsdottir", "kristin branson", "yisong yue", "pietro perona"], "accepted": true, "id": "1611.00094"}, "pdf": {"name": "1611.00094.pdf", "metadata": {"source": "CRF", "title": "LEARNING RECURRENT REPRESENTATIONS FOR HIERARCHICAL BEHAVIOR MODELING", "authors": ["Eyrun Eyjolfsdottir", "Kristin Branson", "Yisong Yue", "Pietro Perona"], "emails": [], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, most of them are able to determine for themselves what they want and what they want."}, {"heading": "2 BACKGROUND", "text": "The motivating assumption for HMMs is that there is a process in which the transitions between states are limited, and that emissions distribution is generally accepted as a gas supplier, although the generalizations of the model fall into the category of dynamic networks."}, {"heading": "3 MODEL", "text": "Our model is a relapsing neural network with long-term short-term memory that simultaneously classifies actions and predicts future movements of actors (insects, animals, and humans). Our model is not a function of the relapsing state, as is common practice, but embeds actions in relapsing state units. Thus, the relapsing function encodes the probabilities for the transition of actions and motion prediction is a direct function of actions, similar to an HMM. The network takes the movements and sensory inputs of an actor as input at each step and returns the next step of the actor according to a strategy that is effectively learned through imitation learning. Similar to autoencoders, our model has a discriminatory path that is used to embed high-level information, and a generative path that is used to reconstruct the input domain, in our case the future movement being filled out by auto-encoders."}, {"heading": "3.1 ARCHITECTURE", "text": "The model can be thought of as two parallel, recurring networks: the discriminatory network takes as input a unit of motion, x, and ambient sensory input, v, and propagates it through its hidden states encoding high-level information, including action labels, y. The generative network decodes the states of the discriminatory network, propagates information downwards to predict agent locomotion at the next step, x - the two networks have the same number of levels and are connected diagonally at each level in such a way that the information in the hidden units of the discriminatory network is transferred to the corresponding level of the generative network. Diagonal connections allow higher levels of the network to represent phenomena at a high level such as goals or individuality, while lower levels represent information such as movement. Our experiments confirm this intuition without action labels."}, {"heading": "3.2 MULTIMODAL PREDICTION", "text": "There are indications that the behavior of the animals is not deterministic (Roberts et al., 2016), so the motion forecast can be better represented as a probability distribution than as a function. If future movements are multimodal, the best regression model will select the average motion of the various modes that may not be within one of the actual modes (visualized in supplementary material).This observation was made by others in connection with the modeling of real sequences with RNNNs (Graves, 2013) model the output of an RNN as a Gaussian mixing model and (Chung et al., 2015) model the hidden recurring states as random variables in addition. We take a non-parametric approach and make no assumptions about the form of distribution xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"}, {"heading": "3.3 SIMULATION", "text": "In view of a model that can predict the future movement of an agent from its current state, a virtual agent can be simulated by iteratively feeding the predicted movement x-i + 1 as input xi + 1 into the network. We select a container by selecting random from the distribution given by x-i + 1 and assign a real value to xi + 1 by sampling evenly from the selected container. Perception of an agent's environment depends on the location of the agent, so sensory characteristics vi + 1 must be calculated for each forward simulation step from the agent's perspective at a time i + 1. In the simulation of multiple agents interacting with each other, each agent is moved according to its xi + 1 and then vi + 1 is calculated for each agent based on the new configuration of all agents.1www.vision.caltech.edu / \u02dc eeyjolfs / modeling _ behavior"}, {"heading": "4 DATA", "text": "In fact, it is a way in which people are able to determine for themselves what they want and what they want."}, {"heading": "5 EXPERIMENTS AND ANALYSIS", "text": "We evaluate our framework based on three objectives: classification, simulation and discovery. For classification, we show the usefulness of motion prediction as an auxiliary task, compare our performance on fly-vs-fly with previous work, and analyze performance on IAM-OnDB. We qualitatively show that simulation results for the behavior and handwriting of flies look convincing, and that the model is able to learn control laws used to generate the SynthFly dataset. To discover, we show that hidden states of the model, trained only to predict movements (without action markers), accurately capture high-level phenomena that affect behavior, such as the sex of the fly and the identity of the writer. Model Details: We trained a separate model for each dataset with a sequence length of 50, a batch size of 20, and 51 containers per dimension for predicting 200 movements of cells, and the overall behavior of the cells we used for each of the GRU units (for a total of 2 levels of 6)."}, {"heading": "5.1 CLASSIFICATION", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "5.2 MOTION PREDICTION", "text": "Before looking at the simulation results, we quantitatively measure the accuracy of single-stage predictions. We calculate the log probability of FlyBowl test sequences within the scope of the motion prediction model: loglik (x) = \u2211 T \u2212 1 i = 1 \u2211 8 d = 1 log (x-d i + 1 \u00b7 x-di + 1), where x-di + 1 is the ground-level truth indicator for vessels of the motion dimension d, with a non-zero entry, and x-di + 1 is a probability distribution over the vessels predicted by the model. We compare our model with the following motion prediction strategies: 1) uniform distribution over vessels, 2) distribution over vessels calculated from the training set, 3) constant motion policy, which copies previous indicator vectors as a motion forecast, and 4) a smooth version of 3) learning by means of an optimized Gaussian nuclear filter, 3) constant motion policy, which shows that the results are clearly reflected in 5, the recurring policies."}, {"heading": "5.3 SIMULATION", "text": "To get a better idea of the fact that we are looking at simulations produced by the learned models, which can be thought of as very long-term predictions. As the motion prediction is more likely, comparing long-term predictions with the truth on the ground becomes difficult as the domain of probable positions becomes exponentially large. Qualitative inspection, however, gives a good intuition as to whether the simulated agent has learned reasonable control laws. b) Simulated trajectories c) real trajectories c) real trajectories c) 10 x 20-frame lookaheads for test flight models, the visually generated text characters injecting original text injections d text injections while the underlying generative processes for the movement of real flies are unknown, simulations from the model trained to imitate them suggest that the model has learned a reasonable political prediction."}, {"heading": "5.4 DISCOVERY", "text": "We motivated the structure of our network, in particular the diagonal connections between discriminating and generative cells, with the intuition that it would allow higher levels of the network to better represent phenomena at the high level. To verify this, we train models to predict only future movements, without a classification goal, and visualize what the hidden states capture. We apply the model to [x, v] to map hidden state vectors hl and h, l, l,..., L, and prediction x, mapping the data points (time steps of each fly / writer) for each state on two dimensions using t-distributed stochastic neighboring embedding (tSNE, Maaten & Hinton (2008)), and drawing them in colors based on known phenomena. Drawing data points of a plane (L = 2) of the model trained at FlyBowl level is well embedded in this low-dimensional model, encoded by gender, color coded, and very right wing."}, {"heading": "6 CONCLUSION", "text": "We have proposed a framework for modeling the behavior of animals that simultaneously classifies their actions and predicts their movements. We have shown empirically that the prediction of movements (a goal for which no expert labeling is required) is a good auxiliary task for the training of action classifiers, especially when labels are scarce. We have also shown that the generative task can be used to simulate trajectories that seem natural to the human eye, and that the activation of classification units increases the frequency of this action in the simulation. Finally, we have shown that our model is well suited to the discovery of high-level information from the data."}], "references": [{"title": "Toward a science of computational ethology", "author": ["David J Anderson", "Pietro Perona"], "venue": null, "citeRegEx": "Anderson and Perona.,? \\Q2014\\E", "shortCiteRegEx": "Anderson and Perona.", "year": 2014}, {"title": "Autoencoders, unsupervised learning, and deep architectures", "author": ["Pierre Baldi"], "venue": "ICML unsupervised and transfer learning,", "citeRegEx": "Baldi.,? \\Q2012\\E", "shortCiteRegEx": "Baldi.", "year": 2012}, {"title": "Vehicles Experiments in Synthetic Psychology", "author": ["Valentino Braitenberg"], "venue": null, "citeRegEx": "Braitenberg.,? \\Q1984\\E", "shortCiteRegEx": "Braitenberg.", "year": 1984}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1406.1078,", "citeRegEx": "Cho et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "A recurrent latent variable model for sequential data", "author": ["Junyoung Chung", "Kyle Kastner", "Laurent Dinh", "Kratarth Goel", "Aaron C Courville", "Yoshua Bengio"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Chung et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chung et al\\.", "year": 2015}, {"title": "Integrated person tracking using stereo, color, and pattern detection", "author": ["T. Darrell", "G. Gordon", "M. Harville", "J. Woodfill"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Darrell et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Darrell et al\\.", "year": 2000}, {"title": "Detecting social actions of fruit flies", "author": ["Eyrun Eyjolfsdottir", "Steve Branson", "Xavier P Burgos-Artizzu", "Eric D Hoopfer", "Jonathan Schor", "David J Anderson", "Pietro Perona"], "venue": "In Computer Vision\u2013 ECCV", "citeRegEx": "Eyjolfsdottir et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Eyjolfsdottir et al\\.", "year": 2014}, {"title": "Speech recognition with deep recurrent neural networks", "author": ["Alan Graves", "Abdel-rahman Mohamed", "Geoffrey Hinton"], "venue": "In Acoustics, Speech and Signal Processing (ICASSP),", "citeRegEx": "Graves et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2013}, {"title": "Generating sequences with recurrent neural networks", "author": ["Alex Graves"], "venue": "arXiv preprint arXiv:1308.0850,", "citeRegEx": "Graves.,? \\Q2013\\E", "shortCiteRegEx": "Graves.", "year": 2013}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Jaaba: interactive machine learning for automatic annotation of animal", "author": ["Mayank Kabra", "Alice A Robie", "Marta Rivera-Alba", "Steven Branson", "Kristin Branson"], "venue": "behavior. nature methods,", "citeRegEx": "Kabra et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kabra et al\\.", "year": 2013}, {"title": "Iam-ondb-an on-line english sentence database acquired from handwritten text on a whiteboard", "author": ["Marcus Liwicki", "Horst Bunke"], "venue": "In Document Analysis and Recognition,", "citeRegEx": "Liwicki and Bunke.,? \\Q2005\\E", "shortCiteRegEx": "Liwicki and Bunke.", "year": 2005}, {"title": "Visualizing data using t-sne", "author": ["Laurens van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten and Hinton.,? \\Q2008\\E", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Human-level control through deep reinforcement learning", "author": ["Volodymyr Mnih", "Koray Kavukcuoglu", "David Silver", "Andrei A Rusu", "Joel Veness", "Marc G Bellemare", "Alex Graves", "Martin Riedmiller", "Andreas K Fidjeland", "Georg Ostrovski"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "Some thoughts on the relation between behavior analysis and behavioral neuroscience", "author": ["J Moore"], "venue": "The Psychological Record,", "citeRegEx": "Moore.,? \\Q2002\\E", "shortCiteRegEx": "Moore.", "year": 2002}, {"title": "Dynamic bayesian networks: representation, inference and learning", "author": ["Kevin Patrick Murphy"], "venue": "PhD thesis,", "citeRegEx": "Murphy.,? \\Q2002\\E", "shortCiteRegEx": "Murphy.", "year": 2002}, {"title": "Semisupervised learning with ladder networks", "author": ["Antti Rasmus", "Mathias Berglund", "Mikko Honkala", "Harri Valpola", "Tapani Raiko"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Rasmus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasmus et al\\.", "year": 2015}, {"title": "A stochastic neuronal model predicts random search behaviors at multiple spatial scales in c", "author": ["William M Roberts", "Steven B Augustine", "Kristy J Lawton", "Theodore H Lindsay", "Tod R Thiele", "Eduardo J Izquierdo", "Serge Faumont", "Rebecca A Lindsay", "Matthew Cale Britton", "Navin Pokala"], "venue": "elegans. eLife,", "citeRegEx": "Roberts et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Roberts et al\\.", "year": 2016}, {"title": "Learning internal representation by error propagation, parallel distributed processing", "author": ["DE Rumenlhart", "Geoffrey E Hinton", "Ronald J Williams"], "venue": "Explor. Microstruct. Cognition,", "citeRegEx": "Rumenlhart et al\\.,? \\Q1986\\E", "shortCiteRegEx": "Rumenlhart et al\\.", "year": 1986}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": "search. Nature,", "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "The sciences of the artificial", "author": ["Herbert A Simon"], "venue": "MIT press,", "citeRegEx": "Simon.,? \\Q1996\\E", "shortCiteRegEx": "Simon.", "year": 1996}, {"title": "Fruitless, doublesex and the genetics of social behavior in drosophila melanogaster", "author": ["Kathleen K Siwicki", "Edward A Kravitz"], "venue": "Current opinion in neurobiology,", "citeRegEx": "Siwicki and Kravitz.,? \\Q2009\\E", "shortCiteRegEx": "Siwicki and Kravitz.", "year": 2009}, {"title": "The ethovision video tracking system\u2014a tool for behavioral phenotyping of transgenic mice", "author": ["AJ Spink", "RAJ Tegelenbosch", "MOS Buma", "LPJJ Noldus"], "venue": "Physiology & behavior,", "citeRegEx": "Spink et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Spink et al\\.", "year": 2001}, {"title": "On aims and methods of ethology", "author": ["Niko Tinbergen"], "venue": "Zeitschrift fu\u0308r Tierpsychologie,", "citeRegEx": "Tinbergen.,? \\Q1963\\E", "shortCiteRegEx": "Tinbergen.", "year": 1963}, {"title": "From neural pca to deep unsupervised learning", "author": ["Harri Valpola"], "venue": "Adv. in Independent Component Analysis and Learning Machines,", "citeRegEx": "Valpola.,? \\Q2015\\E", "shortCiteRegEx": "Valpola.", "year": 2015}], "referenceMentions": [{"referenceID": 23, "context": "Behavioral scientists strive to decode the functional relationship between sensory input and motor output of the brain (Tinbergen, 1963; Moore, 2002).", "startOffset": 119, "endOffset": 149}, {"referenceID": 14, "context": "Behavioral scientists strive to decode the functional relationship between sensory input and motor output of the brain (Tinbergen, 1963; Moore, 2002).", "startOffset": 119, "endOffset": 149}, {"referenceID": 22, "context": "The analysis of behavior may therefore be divided into two steps: (a) detection and tracking (Spink et al., 2001; Darrell et al., 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al.", "startOffset": 93, "endOffset": 135}, {"referenceID": 5, "context": "The analysis of behavior may therefore be divided into two steps: (a) detection and tracking (Spink et al., 2001; Darrell et al., 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al.", "startOffset": 93, "endOffset": 135}, {"referenceID": 10, "context": ", 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al., 2013; Eyjolfsdottir et al., 2014), where motion is segmented into meaningful intervals, each one of which is associated with a goal or a purpose.", "startOffset": 114, "endOffset": 162}, {"referenceID": 6, "context": ", 2000), where the pose of the body over time is estimated and (b) action / activity detection and classification (Kabra et al., 2013; Eyjolfsdottir et al., 2014), where motion is segmented into meaningful intervals, each one of which is associated with a goal or a purpose.", "startOffset": 114, "endOffset": 162}, {"referenceID": 20, "context": "A model that can simulate realistic behavior has learnt to emulate the generative control laws underlying behavior, which could be a useful tool for behavior analysis (Simon, 1996; Braitenberg, 1984).", "startOffset": 167, "endOffset": 199}, {"referenceID": 2, "context": "A model that can simulate realistic behavior has learnt to emulate the generative control laws underlying behavior, which could be a useful tool for behavior analysis (Simon, 1996; Braitenberg, 1984).", "startOffset": 167, "endOffset": 199}, {"referenceID": 15, "context": "This model is limited in that its transition functions are linear, state space is discrete, and emission distribution is generally assumed to be Gaussian, although generalizations of the model that fall under the category of dynamic Bayesian networks are more expressive (Murphy, 2002).", "startOffset": 271, "endOffset": 285}, {"referenceID": 7, "context": "Recurrent neural networks (RNNs) have recently been shown to be extremely successful in classifying time series data, especially with the popularization of long short term memory cells (Hochreiter & Schmidhuber, 1997), in applications such as speech recognition (Graves et al., 2013).", "startOffset": 262, "endOffset": 283}, {"referenceID": 8, "context": "RNNs have also been used for generative sequence prediction of handwriting (Graves, 2013) as well as speech synthesis (Chung et al.", "startOffset": 75, "endOffset": 89}, {"referenceID": 4, "context": "RNNs have also been used for generative sequence prediction of handwriting (Graves, 2013) as well as speech synthesis (Chung et al., 2015).", "startOffset": 118, "endOffset": 138}, {"referenceID": 13, "context": "This strategy is used in (Mnih et al., 2015) where an agent is trained to play Atari games, and in (Silver et al.", "startOffset": 25, "endOffset": 44}, {"referenceID": 19, "context": ", 2015) where an agent is trained to play Atari games, and in (Silver et al., 2016) for mastering the game of GO.", "startOffset": 62, "endOffset": 83}, {"referenceID": 18, "context": "Autoencoders (Rumenlhart et al., 1986) have been used in semi-supervised classification to pretrain a network on an auxiliary task, such as denoising, to prevent overfitting on a small number of labeled data (Baldi, 2012).", "startOffset": 13, "endOffset": 38}, {"referenceID": 1, "context": ", 1986) have been used in semi-supervised classification to pretrain a network on an auxiliary task, such as denoising, to prevent overfitting on a small number of labeled data (Baldi, 2012).", "startOffset": 177, "endOffset": 190}, {"referenceID": 16, "context": "Recent work in this area (Rasmus et al., 2015) proposes to train on the primary and auxiliary task concurrently and using lateral connections (Valpola, 2015) between encoding and decoding layers to allow higher layers of the network to focus on high level features.", "startOffset": 25, "endOffset": 46}, {"referenceID": 24, "context": ", 2015) proposes to train on the primary and auxiliary task concurrently and using lateral connections (Valpola, 2015) between encoding and decoding layers to allow higher layers of the network to focus on high level features.", "startOffset": 103, "endOffset": 118}, {"referenceID": 24, "context": "Each discriminative recurrent cell is fully connected with its corresponding generative cell, allowing higher level states to represent higher level information, similar to the idea of Ladder networks (Valpola, 2015).", "startOffset": 201, "endOffset": 216}, {"referenceID": 3, "context": "For our experiments we found that 2-3 levels of recurrent cells with 100-200 units worked well, with f as a gated recurrent unit (GRU) cell (Cho et al., 2014) and g as linear transformation.", "startOffset": 140, "endOffset": 158}, {"referenceID": 17, "context": "Evidence suggests that animal behavior is nondeterministic (Roberts et al., 2016), thus, motion prediction may be better represented as a probability distribution than a function.", "startOffset": 59, "endOffset": 81}, {"referenceID": 8, "context": "This observation has been made by others in the context of modeling real-valued sequences with RNNs, (Graves, 2013) model the output of an RNN as a Gaussian mixture model and (Chung et al.", "startOffset": 101, "endOffset": 115}, {"referenceID": 4, "context": "This observation has been made by others in the context of modeling real-valued sequences with RNNs, (Graves, 2013) model the output of an RNN as a Gaussian mixture model and (Chung et al., 2015) additionally model the hidden recurrent states as random variables.", "startOffset": 175, "endOffset": 195}, {"referenceID": 6, "context": "With the datasets selected for our experiments, listed below, we are interested in answering the following questions: 1) does motion prediction improve action classification, 2) can the model generate realistic simulations (does it learn the sensory-motor control), and 3) can the model discover novel behavioral phenomena? Fly-vs-fly (Eyjolfsdottir et al., 2014) contains pairs of fruit flies engaging in 10 labeled courtshipand aggressive behaviors.", "startOffset": 335, "endOffset": 363}, {"referenceID": 6, "context": "In order to compare our model with methods presented in Eyjolfsdottir et al. (2014), independently of feature representation, we use the 36 features provided with the Fly-vs-Fly dataset.", "startOffset": 56, "endOffset": 84}, {"referenceID": 6, "context": "b) Performance on Fly-vs-Fly compared with results from Eyjolfsdottir et al. (2014). c) Frame-wise confusion for IAM-OnDB and fraction of training examples for each character.", "startOffset": 56, "endOffset": 84}, {"referenceID": 6, "context": "To account for both duration and counting accuracy we use the performance measures described in Eyjolfsdottir et al. (2014), namely the F1 score (harmonic mean of precision and recall), on a per-frame and per-bout level.", "startOffset": 96, "endOffset": 124}, {"referenceID": 6, "context": "Our results show that filtering significantly improves the bout-wise performance and that our performance on the Fly-vs-Fly test set is comparable with that of Eyjolfsdottir et al. (2014), using no handcrafting and no context of future frames (apart from smoothing).", "startOffset": 160, "endOffset": 188}], "year": 2016, "abstractText": "We propose a framework for detecting action patterns from motion sequences and modeling the sensory-motor relationship of animals, using a generative recurrent neural network. The network has a discriminative part (classifying actions) and a generative part (predicting motion), whose recurrent cells are laterally connected, allowing higher levels of the network to represent high level behavioral phenomena. We test our framework on two types of data, fruit fly behavior and online handwriting. Our results show that 1) taking advantage of unlabeled sequences, by predicting future motion, significantly improves action detection performance when training labels are scarce, 2) the network learns to represent high level phenomena such as writer identity and fly gender, without supervision, and 3) simulated motion trajectories, generated by treating motion prediction as input to the network, look realistic and may be used to qualitatively evaluate whether the model has learnt generative control rules.", "creator": "LaTeX with hyperref package"}}}