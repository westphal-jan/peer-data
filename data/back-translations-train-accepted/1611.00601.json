{"id": "1611.00601", "review": {"conference": "aaai", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Nov-2016", "title": "Ordinal Common-sense Inference", "abstract": "Humans have the capacity to draw common-sense inferences from natural language: various things that are likely but not certain to hold based on established discourse, and are rarely stated explicitly. We propose an evaluation of automated common-sense inference based on an extension of recognizing textual entailment: predicting ordinal human responses of subjective likelihood of an inference holding in a given context. We describe a framework for extracting common-sense knowledge for corpora, which is then used to construct a dataset for this ordinal entailment task, which we then use to train and evaluate a sequence to sequence neural network model. Further, we annotate subsets of previously established datasets via our ordinal annotation protocol in order to then analyze the distinctions between these and what we have constructed.", "histories": [["v1", "Wed, 2 Nov 2016 13:38:32 GMT  (236kb,D)", "http://arxiv.org/abs/1611.00601v1", null], ["v2", "Thu, 3 Nov 2016 01:44:41 GMT  (237kb,D)", "http://arxiv.org/abs/1611.00601v2", null], ["v3", "Fri, 2 Jun 2017 13:54:23 GMT  (358kb,D)", "http://arxiv.org/abs/1611.00601v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["sheng zhang", "rachel rudinger", "kevin duh", "benjamin van durme"], "accepted": true, "id": "1611.00601"}, "pdf": {"name": "1611.00601.pdf", "metadata": {"source": "CRF", "title": "Ordinal Common-sense Inference", "authors": ["Sheng Zhang", "Rachel Rudinger", "Kevin Duh", "Benjamin Van Durme"], "emails": ["vandurme}@cs.jhu.edu"], "sections": [{"heading": null, "text": "Humans are able to deduce common sense from natural language: various things that are probable, but not certain, based on established discourse, and rarely explicitly stated. We propose an evaluation of automated common sense conclusions based on an extension of the recognition of textual problems: predicting ordinary human responses with the subjective likelihood of an inference occurring in a given context. We describe a framework for generating common knowledge for corpora, which is then used to construct a dataset for this ordinal withdrawal task, with which we then train and evaluate a sequence for sequencing neural network models. We also comment on subsets of already established datasets via our ordinal annotation protocol, in order to analyze the distinctions between them and what we have constructed."}, {"heading": "1 Introduction", "text": "We use words to talk about the world (Gordon and Van Durme, 2013), to understand what words mean, we need to have a prior explanation of how we see the world. - Hobbs (1987) Researchers in artificial intelligence and (computer) linguistics have long understood the requirement of common sense in language. This knowledge is regarded as key1Schank (1975): it is obvious... within a relatively sparse channel that the ultimate limit to our solution... would be our ability to characterize world knowledge. Component in filling the gaps between the telegraphic style of natural language statements: we are able to convey considerable information in a relatively sparse channel that presumably owes a partially shared model at the beginning of any discourse."}, {"heading": "2 Background", "text": "In fact, it is not that it is a mere self-portrait, but rather a story in which it is a matter of putting oneself and oneself at the centre. (...) It is not that it is a self-portrait. (...) It is as if it is a self-portrait. (...) It is as if it is a self-portrait. (...) It is as if it is a self-portrait. (...) It is as if it is a self-portrait. (...) It is as if it is a self-portrait. (...) It is as if it is a self-portrait. (...) It is as if it is a self-portrait. (...) It is as if it is a self-portrait. (...) It is a self-portrait."}, {"heading": "3 Ordinal Common-sense Inference", "text": "Based on the observed deficiencies of previous work, we propose the term Ordinal Common-sense Inference (OCI). OCI echoes the notion of Dagan et al. (2006) by looking at human judgments about whether something is probable. However, rather than weakening the notion of logical truth to create containers with (most likely) true and (most likely) false, possibly grey areas in between, we refine the task definition to directly capture the subjective probability at the orderly level. People placed before a Context C are asked whether a provided conclusion I is very likely, probable, plausible, technically possible or impossible. Furthermore, an important part of this process is the generation of ego by automatic methods aimed at avoiding the bias of many previous work."}, {"heading": "4 Framework for collecting JOCI", "text": "We now describe our framework for collecting ordinal common sense conclusions. It is natural to collect this data in two phases: In the first phase (\u00a7 4.1) we automatically generate context candidates. These are referred to as automatically generated common sense candidates (AGCI-NN), and we propose two broad approaches that use either general world knowledge (AGCI-WK) or neural sequence-to-sequence methods (AGCI-NN). In the second phase (\u00a7 4.2) we comment on AGCI with ordal labels."}, {"heading": "4.1 Generation of Common-sense Inference Candidates", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1.1 Generation based on World Knowledge", "text": "\"Our motivation for this approach was first introduced by Schubert (2002). There is a largely untapped source of general knowledge in texts that lie at a level below the explicit claimed content, which consists of relationships that are implicit in the world, or, under certain conditions, implied to be normal or commonplace in the world. As shown in Fig 2, this approach generates common sense inference candidates in four steps: (a) extracting arguments with predicate argumentation structures from texts, (b) deriving templates for concepts, (c) deriving properties of concepts via different strategies, and (d) possible conclusions from contexts. (a) extracting predicate argumentation structures."}, {"heading": "4.1.2 Generation via Neural Methods", "text": "As an alternative to the knowledge-based methods described above, we also adapt a neural sequence and sentence equation model (Vinyals et al., 2015; Bahdanau et al., 2014) to directly generate conclusions from given contexts; the model is trained on pairs of sentences called \"withdrawal\" from the SNLI corpus train (Bowman et al., 2015), in which case the SNLI premise is the input to the network (i.e. context), and the SNLI hypothesis is the output (inference).9 Senses that share a hypernym are called coheryponyms (e.g. book.n.01, magazine.n.01, and collections.n.02 are co-hyponyms of publication.n.01).10 We use the Pattern.en module (http: / / www.clips. ua.ac.be / pages / pattern-en)."}, {"heading": "4.2 Ordinal Label Annotation", "text": "At this stage, we turn to human efforts to comment on AGCI with order labels. The commentator receives a context and is then asked if the probability of the conclusion is true. These context pairs are provided with one of the five labels: very likely, probable, plausible, technically possible and impossible, according to the order values of {5,4,3,2,1} or accordingly. In the event that the conclusion does not make sense or has grammatical errors, the judges can provide an additional marking, NA, so that we can filter these conclusions in post-processing. Combining AGCI with human filtering attempts to avoid the problem of survey distortion."}, {"heading": "5 JOCI Corpus", "text": "The main part of our corpus consists of contexts selected from SNLI and ROCStories, paired with autogenerated conclusions using methods described in \u00a7 4.1. These pairs are then crowdsourced with ordinals (\u00a7 4.2). In addition, we include context inference pairs that come directly from SNLI and other corpora (e.g. as presumption-hypotheses pairs), and recomment them with ordinals."}, {"heading": "5.1 Data sources for Context-Inference Pairs", "text": "To compare with existing conclusions, we select contexts from two sources: (1) the first sentence in the pairs of sentences of the SNLI corpus (Bowman et al., 2015), which are labels from the Flickr30k corpus (Young et al., 2014), and (2) the first sentence in the stories of the ROCStories corpus (Mostafazadeh et al., 2016). We then automatically generated common sense (AGCI) against these contexts. Specifically, in the SNLI train, there are over 150K of different first sentences containing 7,414 different arguments according to predicate argument extraction. We randomly select 4,600 arguments. For each argument, we stamp a first sentence that has the argument, and use AGCI against it as context. We also do the same generation for the SNLI definition and the test sentence."}, {"heading": "5.2 Crowdsourced Ordinal Label Annotation", "text": "We use Amazon Mechanical Turk to comment on the conclusions with neat labels. In each HIT (Human Intelligence Task), a worker is presented with a context and one or two conclusions, as shown in Fig. 4. First, the commentator sees an \"initial sentence\" (context), e.g. \"John's goal was to learn how to draw well,\" and is then asked about the plausibility of the conclusion, e.g. \"A person reaches the goal.\" Specifically, we ask the commentator how plausible the conclusion is during or shortly after, because without this limitation, most sentences are technically plausible in any imaginary world. If the conclusion does not make sense11, the workers can check the box below the question and skip the ordinary comment. In the note, about 25% of the AGCI are marked as not meaningful and are removed from our data."}, {"heading": "5.3 Corpus Characteristics", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before in the history of the city."}, {"heading": "6 Predicting Ordinal Judgments", "text": "Our goal in this section is to determine baseline results and to investigate what types of characteristics are useful for predicting ordinal inference of common sense. To do this, we train and test a logistic ordinal regression model g\u03b8 (\u03c6 (C, I)) that outputs ordinal labels using characteristics \u03c6 defined on context inference pairs. This is a regression model where \u03b8 serve as trained parameters; we train with the margin-based method of (Rennie and Srebro, 2005) implemented in (Pedregosa-Izquierdo, 2015) 14."}, {"heading": "6.1 Features", "text": "Pouch by pouch word characteristics (BOW): We calculate (1) \"BOW overlap\" (size of word overlap in C and I), and (2) BOW overlap divided by the length of I. Similarity characteristics (SIM): With Google's word2vec vectors preschooled to 100 billion tokens from GoogleNews, we sum up (1) the vectors in both14LogisticSE: http: / / github.com / fabianp / mordthe context and calculate the cosine similarity of the resulting two vectors (\"similarity of the average\"), and (2) calculate the cosine similarity of all word pairs via context and inference, and calculate an average of these similarities (\"average of similarity\") and calculate the cosine similarity of the resulting two vectors (\"similarity of the average of the two vectors\"). Seq2q difference points (Sq model of log2C (S2S-2P) is only generated in five pairs (S2P)."}, {"heading": "6.2 Analysis", "text": "In fact, the fact is that most of us are able to play by the rules that they have imposed on themselves, and that they are able to play by the rules that they have imposed on themselves, \"he told the Deutsche Presse-Agentur.\" We have to play by the rules, \"he said in an interview with\" Welt am Sonntag. \""}, {"heading": "7 Conclusions and Future Work", "text": "As motivation for automatically building collections of common sense, Clark et al. (2003) wrote: \"China launched a meteorological satellite into orbit on Wednesday.\" suggests to a human reader that there has been a rocket launch (among other things); China probably owns the satellite; the satellite is used to monitor the weather; the orbit is around the Earth; etc. The use of \"etc.\" summarizes an unlimited number of other statements that a human reader would consider highly likely, probable, technically plausible or impossible given the context provided. Preferably, we could build systems that would learn common sense exclusively from available corpora; we extract not only statements about what is possible, but also the associated probabilities of how likely certain things are to be obtained in a given context. We are unaware of the existing work that has shown that this is feasible."}], "references": [{"title": "Semeval-2012 task 6: A pilot on semantic textual similarity", "author": ["Eneko Agirre", "Mona Diab", "Daniel Cer", "Aitor Gonzalez-Agirre."], "venue": "Proceedings of the Sixth International Workshop on Semantic Evaluation.", "citeRegEx": "Agirre et al\\.,? 2012", "shortCiteRegEx": "Agirre et al\\.", "year": 2012}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "CoRR, abs/1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "The berkeley framenet project", "author": ["Collin F. Baker", "Charles J. Fillmore", "John B. Lowe."], "venue": "Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1,", "citeRegEx": "Baker et al\\.,? 1998", "shortCiteRegEx": "Baker et al\\.", "year": 1998}, {"title": "Strategies for Lifelong Knowledge Extraction from the Web", "author": ["Michele Banko", "Oren Etzioni."], "venue": "Proceedings of K-CAP.", "citeRegEx": "Banko and Etzioni.,? 2007", "shortCiteRegEx": "Banko and Etzioni.", "year": 2007}, {"title": "Montague meets markov: Deep semantics with probabilistic logical form", "author": ["Islam Beltagy", "Cuong Chau", "Gemma Boleda", "Dan Garrette", "Katrin Erk", "Raymond Mooney."], "venue": "2nd Joint Conference on Lexical and Computational Semantics: Proceeding of the", "citeRegEx": "Beltagy et al\\.,? 2013", "shortCiteRegEx": "Beltagy et al\\.", "year": 2013}, {"title": "Global learning of typed entailment rules", "author": ["Jonathan Berant", "Ido Dagan", "Jacob Goldberger."], "venue": "Proceedings of ACL.", "citeRegEx": "Berant et al\\.,? 2011", "shortCiteRegEx": "Berant et al\\.", "year": 2011}, {"title": "A large annotated corpus for learning natural language inference", "author": ["Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Bowman et al\\.,? 2015", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Unsupervised Learning of Narrative Event Chains", "author": ["Nathanael Chambers", "Dan Jurafsky."], "venue": "Proceedings of ACL.", "citeRegEx": "Chambers and Jurafsky.,? 2008", "shortCiteRegEx": "Chambers and Jurafsky.", "year": 2008}, {"title": "LEARNER: A System for Acquiring Commonsense Knowledge by Analogy", "author": ["Timothy Chklovski."], "venue": "Proceedings of Second International Conference on Knowledge Capture (K-CAP 2003).", "citeRegEx": "Chklovski.,? 2003", "shortCiteRegEx": "Chklovski.", "year": 2003}, {"title": "A knowledge-driven approach to text meaning processing", "author": ["Peter Clark", "Phil Harrison", "John Thompson."], "venue": "Proceedings of the HLT-NAACL 2003 workshop on Text meaning-Volume 9, pages 1\u20136. Association for Computational Linguistics.", "citeRegEx": "Clark et al\\.,? 2003", "shortCiteRegEx": "Clark et al\\.", "year": 2003}, {"title": "Bridging", "author": ["Herbert H. Clark."], "venue": "R. C. Schank and B. L. Nash-Webber, editors, Theoretical issues in natural language processing. Association for Computing Machinery, New York.", "citeRegEx": "Clark.,? 1975", "shortCiteRegEx": "Clark.", "year": 1975}, {"title": "The pascal recognising textual entailment challenge", "author": ["Ido Dagan", "Oren Glickman", "Bernardo Magnini."], "venue": "Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment.", "citeRegEx": "Dagan et al\\.,? 2006", "shortCiteRegEx": "Dagan et al\\.", "year": 2006}, {"title": "Concretely Annotated Corpora", "author": ["Francis Ferraro", "Max Thomas", "Matthew R. Gormley", "Travis Wolfe", "Craig Harman", "Benjamin Van Durme."], "venue": "4th Workshop on Automated Knowledge Base Construction (AKBC).", "citeRegEx": "Ferraro et al\\.,? 2014", "shortCiteRegEx": "Ferraro et al\\.", "year": 2014}, {"title": "Project halo: Towards a digital aristotle", "author": ["Noah S Friedland", "Paul G Allen", "Gavin Matthews", "Michael Witbrock", "David Baxter", "Jon Curtis", "Blake Shepard", "Pierluigi Miraglia", "Jurgen Angele", "Steffen Staab"], "venue": "AI magazine,", "citeRegEx": "Friedland et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Friedland et al\\.", "year": 2004}, {"title": "Integrating logical representations with probabilistic information using markov logic", "author": ["Dan Garrette", "Katrin Erk", "Raymond Mooney."], "venue": "Proceedings of the Ninth International Conference on Computational Semantics, pages 105\u2013114. Association for Computa-", "citeRegEx": "Garrette et al\\.,? 2011", "shortCiteRegEx": "Garrette et al\\.", "year": 2011}, {"title": "The fourth pascal recognizing textual entailment challenge", "author": ["Danilo Giampiccolo", "Hoa Trang Dang", "Bernardo Magnini", "Ido Dagan", "Elena Cabrio", "Bill Dolan."], "venue": "Proceedings of TAC 2008.", "citeRegEx": "Giampiccolo et al\\.,? 2008", "shortCiteRegEx": "Giampiccolo et al\\.", "year": 2008}, {"title": "Reporting bias and knowledge extraction", "author": ["Jonathan Gordon", "Benjamin Van Durme."], "venue": "Automated Knowledge Base Construction (AKBC): The 3rd Workshop on Knowledge Extraction at CIKM.", "citeRegEx": "Gordon and Durme.,? 2013", "shortCiteRegEx": "Gordon and Durme.", "year": 2013}, {"title": "ConceptNet 3: a Flexible, Multilingual Semantic Network for Common Sense Knowledge", "author": ["Catherine Havasi", "Robert Speer", "Jason Alonso."], "venue": "Proceedings of RANLP.", "citeRegEx": "Havasi et al\\.,? 2007", "shortCiteRegEx": "Havasi et al\\.", "year": 2007}, {"title": "Automatic Acquisition of Hyponyms from Large Text Corpora", "author": ["Marti Hearst."], "venue": "Proceedings of COLING.", "citeRegEx": "Hearst.,? 1992", "shortCiteRegEx": "Hearst.", "year": 1992}, {"title": "Methodology for knowledge acquisition (unpublished manuscript)", "author": ["Jerry R. Hobbs", "Costanza Navarretta."], "venue": "http://www.isi.edu/h\u0303obbs/damage.text.", "citeRegEx": "Hobbs and Navarretta.,? 1993", "shortCiteRegEx": "Hobbs and Navarretta.", "year": 1993}, {"title": "Interpretation as abduction", "author": ["Jerry R Hobbs", "Mark Stickel", "Paul Martin", "Douglas Edwards."], "venue": "Proceedings of the 26th annual meeting on Association for Computational Linguistics, pages 95\u2013103. Association for Computational Linguistics.", "citeRegEx": "Hobbs et al\\.,? 1988", "shortCiteRegEx": "Hobbs et al\\.", "year": 1988}, {"title": "World Knowledge And Word Meaning", "author": ["Jerry R. Hobbs."], "venue": "Theoretical Issues In Natural Language Processing.", "citeRegEx": "Hobbs.,? 1987", "shortCiteRegEx": "Hobbs.", "year": 1987}, {"title": "Cyc: A large-scale investment in knowledge infrastructure", "author": ["Douglas B Lenat."], "venue": "Communications of the ACM, 38(11):33\u201338.", "citeRegEx": "Lenat.,? 1995", "shortCiteRegEx": "Lenat.", "year": 1995}, {"title": "The winograd schema challenge", "author": ["Hector J. Levesque", "Ernest Davis", "Leora Morgenstern."], "venue": "AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning.", "citeRegEx": "Levesque et al\\.,? 2011", "shortCiteRegEx": "Levesque et al\\.", "year": 2011}, {"title": "From Trees to Predicate Argument Structures", "author": ["Maria Liakata", "Stephen Pulman."], "venue": "Proceedings of COLING.", "citeRegEx": "Liakata and Pulman.,? 2002", "shortCiteRegEx": "Liakata and Pulman.", "year": 2002}, {"title": "DIRT - Discovery of Inference Rules from Text", "author": ["Dekang Lin", "Patrick Pantel."], "venue": "Proceedings of KDD.", "citeRegEx": "Lin and Pantel.,? 2001", "shortCiteRegEx": "Lin and Pantel.", "year": 2001}, {"title": "Natural logic for textual inference", "author": ["Bill MacCartney", "Christopher D. Manning."], "venue": "Proceedings of ACL: Workshop on Textual Entailment and Paraphrasing.", "citeRegEx": "MacCartney and Manning.,? 2007", "shortCiteRegEx": "MacCartney and Manning.", "year": 2007}, {"title": "A SICK cure for the evaluation of compositional distributional semantic models", "author": ["Marco Marelli", "Stefano Menini", "Marco Baroni", "Luisa Bentivogli", "Raffaella Bernardi", "Roberto Zamparelli."], "venue": "Proceedings of the Ninth International Conference on Lan-", "citeRegEx": "Marelli et al\\.,? 2014", "shortCiteRegEx": "Marelli et al\\.", "year": 2014}, {"title": "Programs with common sense", "author": ["John McCarthy."], "venue": "Proceedings of the Teddington Conference on the Mechanization of Thought Processes, London: Her Majesty\u2019s Stationery Office.", "citeRegEx": "McCarthy.,? 1959", "shortCiteRegEx": "McCarthy.", "year": 1959}, {"title": "Semantic feature production norms for a large set of living and nonliving things", "author": ["Ken McRae", "George S. Cree", "Mark S. Seidenberg", "Chris McNorgan."], "venue": "Behavior Research Methods, Instruments, & Computers, 37(4):547\u2013559.", "citeRegEx": "McRae et al\\.,? 2005", "shortCiteRegEx": "McRae et al\\.", "year": 2005}, {"title": "Wordnet: a lexical database for english", "author": ["George A Miller."], "venue": "Communications of the ACM, 38(11):39\u201341.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "Seeing through the human reporting bias: Visual classifiers from noisy humancentric labels", "author": ["Ishan Misra", "C. Lawrence Zitnick", "Margaret Mitchell", "Ross Girshick."], "venue": "Proceedings of CVPR.", "citeRegEx": "Misra et al\\.,? 2016", "shortCiteRegEx": "Misra et al\\.", "year": 2016}, {"title": "A corpus and cloze evaluation for deeper understanding of commonsense stories", "author": ["Nasrin Mostafazadeh", "Nathanael Chambers", "Xiaodong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen."], "venue": "Proceedings of the 2016 Confer-", "citeRegEx": "Mostafazadeh et al\\.,? 2016", "shortCiteRegEx": "Mostafazadeh et al\\.", "year": 2016}, {"title": "What You Seek is What You Get: Extraction of Class Attributes from Query Logs", "author": ["Marius Pa\u015fca", "Benjamin Van Durme."], "venue": "Proceedings of IJCAI.", "citeRegEx": "Pa\u015fca and Durme.,? 2007", "shortCiteRegEx": "Pa\u015fca and Durme.", "year": 2007}, {"title": "Isp: Learning inferential selectional preferences", "author": ["Patrick Pantel", "Rahul Bhagat", "Bonaventura Coppola", "Timothy Chklovski", "Eduard H Hovy."], "venue": "HLTNAACL, pages 564\u2013571.", "citeRegEx": "Pantel et al\\.,? 2007", "shortCiteRegEx": "Pantel et al\\.", "year": 2007}, {"title": "English gigaword fifth edition, june", "author": ["Robert Parker", "David Graff", "Junbo Kong", "Ke Chen", "Kazuaki Maeda."], "venue": "Linguistic Data Consortium, LDC2011T07.", "citeRegEx": "Parker et al\\.,? 2011", "shortCiteRegEx": "Parker et al\\.", "year": 2011}, {"title": "Turning web text and search queries into factual knowledge: Hierarchical class attribute extraction", "author": ["Marius Pasca"], "venue": null, "citeRegEx": "Pasca.,? \\Q2008\\E", "shortCiteRegEx": "Pasca.", "year": 2008}, {"title": "Feature extraction and supervised learning on fMRI: from practice to theory", "author": ["Fabian Pedregosa-Izquierdo."], "venue": "Ph.D. thesis, Universit\u00e9 Pierre et Marie CurieParis VI.", "citeRegEx": "Pedregosa.Izquierdo.,? 2015", "shortCiteRegEx": "Pedregosa.Izquierdo.", "year": 2015}, {"title": "Learning statistical scripts with lstm recurrent neural networks", "author": ["Karl Pichotta", "Raymond J Mooney."], "venue": "Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI).", "citeRegEx": "Pichotta and Mooney.,? 2016", "shortCiteRegEx": "Pichotta and Mooney.", "year": 2016}, {"title": "Loss functions for preference levels: Regression with discrete ordered labels", "author": ["Jason DM Rennie", "Nathan Srebro."], "venue": "Proceedings of the IJCAI multidisciplinary workshop on advances in preference handling, pages 180\u2013186. Kluwer Norwell, MA.", "citeRegEx": "Rennie and Srebro.,? 2005", "shortCiteRegEx": "Rennie and Srebro.", "year": 2005}, {"title": "Markov logic networks", "author": ["Matthew Richardson", "Pedro Domingos."], "venue": "Machine learning, 62(12):107\u2013136.", "citeRegEx": "Richardson and Domingos.,? 2006", "shortCiteRegEx": "Richardson and Domingos.", "year": 2006}, {"title": "MindNet: Acquiring and Structuring Semantic Information from Text", "author": ["Stephen D. Richardson", "William B. Dolan", "Lucy Vanderwende."], "venue": "Proceedings of ACL.", "citeRegEx": "Richardson et al\\.,? 1998", "shortCiteRegEx": "Richardson et al\\.", "year": 1998}, {"title": "Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning", "author": ["Melissa Roemmele", "Cosmin Adrian Bejan", "Andrew S. Gordon."], "venue": "AAAI Spring Symposium on Logical Formalizations of Commonsense Reasoning, Stanford Univer-", "citeRegEx": "Roemmele et al\\.,? 2011", "shortCiteRegEx": "Roemmele et al\\.", "year": 2011}, {"title": "Is the stanford dependency representation semantic? In ACL Workshop: EVENTS", "author": ["Rachel Rudinger", "Benjamin Van Durme"], "venue": null, "citeRegEx": "Rudinger and Durme.,? \\Q2014\\E", "shortCiteRegEx": "Rudinger and Durme.", "year": 2014}, {"title": "Script induction as language modeling", "author": ["Rachel Rudinger", "Pushpendre Rastogi", "Francis Ferraro", "Benjamin Van Durme."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Rudinger et al\\.,? 2015", "shortCiteRegEx": "Rudinger et al\\.", "year": 2015}, {"title": "Using knowledge to understand", "author": ["Roger C. Schank."], "venue": "TINLAP \u201975: Proceedings of the 1975 workshop on Theoretical issues in natural language processing.", "citeRegEx": "Schank.,? 1975", "shortCiteRegEx": "Schank.", "year": 1975}, {"title": "Can we derive general world knowledge from texts", "author": ["Lenhart Schubert"], "venue": null, "citeRegEx": "Schubert.,? \\Q2002\\E", "shortCiteRegEx": "Schubert.", "year": 2002}, {"title": "The public acquisition of commonsense knowledge", "author": ["Push Singh."], "venue": "Proceedings of AAAI Spring Symposium: Acquiring (and Using) Linguistic (and World) Knowledge for Information Access. AAAI.", "citeRegEx": "Singh.,? 2002", "shortCiteRegEx": "Singh.", "year": 2002}, {"title": "Semantic Taxonomy Induction from Heterogenous Evidence", "author": ["Rion Snow", "Daniel Jurafsky", "Andrew Y. Ng."], "venue": "Proceedings of COLING-ACL.", "citeRegEx": "Snow et al\\.,? 2006", "shortCiteRegEx": "Snow et al\\.", "year": 2006}, {"title": "YAGO: A Core of Semantic Knowledge Unifying WordNet and Wikipedia", "author": ["Fabian M. Suchanek", "Gjergji Kasneci", "Gerhard Weikum."], "venue": "Proceedings of WWW.", "citeRegEx": "Suchanek et al\\.,? 2007", "shortCiteRegEx": "Suchanek et al\\.", "year": 2007}, {"title": "Discourse context and sentence perception", "author": ["Michael K. Tanenhaus", "Mark S. Seidenberg."], "venue": "Technical Report 176, Center for the Study of Reading, Illinois University, Urbana.", "citeRegEx": "Tanenhaus and Seidenberg.,? 1980", "shortCiteRegEx": "Tanenhaus and Seidenberg.", "year": 1980}, {"title": "Open knowledge extraction through compositional language processing", "author": ["Benjamin Van Durme", "Lenhart Schubert."], "venue": "Proceedings of the 2008 Conference on Semantics in Text Processing, pages 239\u2013254. Association for Computational Linguistics.", "citeRegEx": "Durme and Schubert.,? 2008", "shortCiteRegEx": "Durme and Schubert.", "year": 2008}, {"title": "Deriving generalized knowledge from corpora using WordNet abstraction", "author": ["Benjamin Van Durme", "Phillip Michalak", "Lenhart Schubert."], "venue": "Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 808\u2013816, Athens,", "citeRegEx": "Durme et al\\.,? 2009", "shortCiteRegEx": "Durme et al\\.", "year": 2009}, {"title": "Extracting implicit knowledge from text", "author": ["Benjamin Van Durme."], "venue": "Ph.D. thesis, University of Rochester, Department of Computer Science, Rochester, NY 14627-0226.", "citeRegEx": "Durme.,? 2010", "shortCiteRegEx": "Durme.", "year": 2010}, {"title": "Grammar as a foreign language", "author": ["Oriol Vinyals", "\u0141 ukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton."], "venue": "C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems 28,", "citeRegEx": "Vinyals et al\\.,? 2015", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions", "author": ["Peter Young", "Alice Lai", "Micah Hodosh", "Julia Hockenmaier."], "venue": "Transactions of the Association for Computational Linguistics, 2:67\u201378.", "citeRegEx": "Young et al\\.,? 2014", "shortCiteRegEx": "Young et al\\.", "year": 2014}], "referenceMentions": [{"referenceID": 21, "context": "\u2013 Hobbs (1987)", "startOffset": 2, "endOffset": 15}, {"referenceID": 10, "context": ", many of the bridging inferences of Clark (1975) make use of common-sense knowledge, such as the following example of \u201cProbable part\u201d: I walked into the room.", "startOffset": 37, "endOffset": 50}, {"referenceID": 44, "context": "rately considered models of language, rather than of the world (Rudinger et al., 2015).", "startOffset": 63, "endOffset": 86}, {"referenceID": 51, "context": "For further background see discussions by Van Durme (2010), Gordon and Van Durme (2013), Rudinger et al.", "startOffset": 46, "endOffset": 59}, {"referenceID": 51, "context": "For further background see discussions by Van Durme (2010), Gordon and Van Durme (2013), Rudinger et al.", "startOffset": 46, "endOffset": 88}, {"referenceID": 43, "context": "For further background see discussions by Van Durme (2010), Gordon and Van Durme (2013), Rudinger et al. (2015) and Misra et al.", "startOffset": 89, "endOffset": 112}, {"referenceID": 31, "context": "(2015) and Misra et al. (2016). 2 Background", "startOffset": 11, "endOffset": 31}, {"referenceID": 19, "context": "Mining Common Sense Building large collections of common-sense knowledge can be done manually via professionals (Hobbs and Navarretta, 1993), but at considerable time and expense (Miller, 1995; Lenat, 1995; Baker et al.", "startOffset": 112, "endOffset": 140}, {"referenceID": 30, "context": "Mining Common Sense Building large collections of common-sense knowledge can be done manually via professionals (Hobbs and Navarretta, 1993), but at considerable time and expense (Miller, 1995; Lenat, 1995; Baker et al., 1998; Friedland et al., 2004).", "startOffset": 179, "endOffset": 250}, {"referenceID": 22, "context": "Mining Common Sense Building large collections of common-sense knowledge can be done manually via professionals (Hobbs and Navarretta, 1993), but at considerable time and expense (Miller, 1995; Lenat, 1995; Baker et al., 1998; Friedland et al., 2004).", "startOffset": 179, "endOffset": 250}, {"referenceID": 2, "context": "Mining Common Sense Building large collections of common-sense knowledge can be done manually via professionals (Hobbs and Navarretta, 1993), but at considerable time and expense (Miller, 1995; Lenat, 1995; Baker et al., 1998; Friedland et al., 2004).", "startOffset": 179, "endOffset": 250}, {"referenceID": 13, "context": "Mining Common Sense Building large collections of common-sense knowledge can be done manually via professionals (Hobbs and Navarretta, 1993), but at considerable time and expense (Miller, 1995; Lenat, 1995; Baker et al., 1998; Friedland et al., 2004).", "startOffset": 179, "endOffset": 250}, {"referenceID": 47, "context": "Efforts have pursued volunteers (Singh, 2002; Havasi et al., 2007) and games with a purpose (Chklovski, 2003), but are still left fully reliant on human labor.", "startOffset": 32, "endOffset": 66}, {"referenceID": 17, "context": "Efforts have pursued volunteers (Singh, 2002; Havasi et al., 2007) and games with a purpose (Chklovski, 2003), but are still left fully reliant on human labor.", "startOffset": 32, "endOffset": 66}, {"referenceID": 8, "context": ", 2007) and games with a purpose (Chklovski, 2003), but are still left fully reliant on human labor.", "startOffset": 33, "endOffset": 50}, {"referenceID": 18, "context": "Many have pursued automating the process, such as in expanding lexical hierarchies (Hearst, 1992; Snow et al., 2006), constructing inference patterns (Lin and Pantel, 2001; Berant et al.", "startOffset": 83, "endOffset": 116}, {"referenceID": 48, "context": "Many have pursued automating the process, such as in expanding lexical hierarchies (Hearst, 1992; Snow et al., 2006), constructing inference patterns (Lin and Pantel, 2001; Berant et al.", "startOffset": 83, "endOffset": 116}, {"referenceID": 25, "context": ", 2006), constructing inference patterns (Lin and Pantel, 2001; Berant et al., 2011), reading reference materials (Richardson et al.", "startOffset": 41, "endOffset": 84}, {"referenceID": 5, "context": ", 2006), constructing inference patterns (Lin and Pantel, 2001; Berant et al., 2011), reading reference materials (Richardson et al.", "startOffset": 41, "endOffset": 84}, {"referenceID": 41, "context": ", 2011), reading reference materials (Richardson et al., 1998; Suchanek et al., 2007), mining search engine query logs (Pa\u015fca and Van Durme, 2007), and most relevant here: abstracting from instance-level predications discovered in descriptive texts (Schubert, 2002; Liakata and Pulman, 2002; Clark et al.", "startOffset": 37, "endOffset": 85}, {"referenceID": 49, "context": ", 2011), reading reference materials (Richardson et al., 1998; Suchanek et al., 2007), mining search engine query logs (Pa\u015fca and Van Durme, 2007), and most relevant here: abstracting from instance-level predications discovered in descriptive texts (Schubert, 2002; Liakata and Pulman, 2002; Clark et al.", "startOffset": 37, "endOffset": 85}, {"referenceID": 46, "context": ", 2007), mining search engine query logs (Pa\u015fca and Van Durme, 2007), and most relevant here: abstracting from instance-level predications discovered in descriptive texts (Schubert, 2002; Liakata and Pulman, 2002; Clark et al., 2003; Banko and Etzioni, 2007).", "startOffset": 171, "endOffset": 258}, {"referenceID": 24, "context": ", 2007), mining search engine query logs (Pa\u015fca and Van Durme, 2007), and most relevant here: abstracting from instance-level predications discovered in descriptive texts (Schubert, 2002; Liakata and Pulman, 2002; Clark et al., 2003; Banko and Etzioni, 2007).", "startOffset": 171, "endOffset": 258}, {"referenceID": 9, "context": ", 2007), mining search engine query logs (Pa\u015fca and Van Durme, 2007), and most relevant here: abstracting from instance-level predications discovered in descriptive texts (Schubert, 2002; Liakata and Pulman, 2002; Clark et al., 2003; Banko and Etzioni, 2007).", "startOffset": 171, "endOffset": 258}, {"referenceID": 3, "context": ", 2007), mining search engine query logs (Pa\u015fca and Van Durme, 2007), and most relevant here: abstracting from instance-level predications discovered in descriptive texts (Schubert, 2002; Liakata and Pulman, 2002; Clark et al., 2003; Banko and Etzioni, 2007).", "startOffset": 171, "endOffset": 258}, {"referenceID": 6, "context": ", 1996), or they rely on crowdsourced elicitation (Bowman et al., 2015).", "startOffset": 50, "endOffset": 71}, {"referenceID": 22, "context": ", the Winograd Schema Challenge discussed by Levesque et al. (2011). The data for these tasks are either smaller, carefully constructed evaluation sets by professionals, following efforts such the construction of the FRACAS test suite (Cooper et al.", "startOffset": 45, "endOffset": 68}, {"referenceID": 27, "context": "ent people of the same image), which were modified through a series of rule-based transformations then judged by humans (Marelli et al., 2014).", "startOffset": 120, "endOffset": 142}, {"referenceID": 11, "context": "Textual Entailment A multi-year source of textual inference examples were generated under the Recognizing Textual Entailment (RTE) Challenges, introduced by Dagan et al. (2006):", "startOffset": 157, "endOffset": 177}, {"referenceID": 15, "context": "While Giampiccolo et al. (2008) extended binary RTE with an \u201cunknown\u201d category, the entailment community has primarily focussed on issues such as paraphrase and monotonicity (such as captured by MacCartney and Manning (2007)).", "startOffset": 6, "endOffset": 32}, {"referenceID": 15, "context": "While Giampiccolo et al. (2008) extended binary RTE with an \u201cunknown\u201d category, the entailment community has primarily focussed on issues such as paraphrase and monotonicity (such as captured by MacCartney and Manning (2007)).", "startOffset": 6, "endOffset": 225}, {"referenceID": 40, "context": "(2013) introduced weighted inference rules based words/phrases similarity, and treated textual entailment as probabilistic logical inference in Markov Logic Networks (Richardson and Domingos, 2006).", "startOffset": 166, "endOffset": 197}, {"referenceID": 4, "context": "(2011) and Beltagy et al. (2013) introduced weighted inference rules based words/phrases similarity, and treated textual entailment as probabilistic logical inference in Markov Logic Networks (Richardson and Domingos, 2006).", "startOffset": 11, "endOffset": 33}, {"referenceID": 4, "context": "(2011) and Beltagy et al. (2013) introduced weighted inference rules based words/phrases similarity, and treated textual entailment as probabilistic logical inference in Markov Logic Networks (Richardson and Domingos, 2006). Supported by Hobbs et al. (1988), who proposed viewing natural language interpretation as abductive inference, their approach to weighted inference is to measure how likely H is best entailed, i.", "startOffset": 11, "endOffset": 258}, {"referenceID": 0, "context": "Agirre et al. (2012) piloted a Textual Similarity evaluation which has been refined in each subsequent year: systems produce scalar values corresponding to predictions of how similar the meaning is between two provided sentences.", "startOffset": 0, "endOffset": 21}, {"referenceID": 42, "context": "The Choice of Plausible Alternative (COPA) task (Roemmele et al., 2011) was a reaction to RTE, similarly motivated to probe a system\u2019s ability to understand inferences that are not strictly entailed: a single context was provided, with two alternative inferences, and a system had to judge which was more plausible.", "startOffset": 48, "endOffset": 71}, {"referenceID": 7, "context": "The Narrative Cloze task (Chambers and Jurafsky, 2008) requires a system to score candidate inferences as to how likely they are to appear in a document that also included the provided context.", "startOffset": 25, "endOffset": 54}, {"referenceID": 32, "context": "The ROCStories corpus (Mostafazadeh et al., 2016) elicited a more \u201cplausible\u201d collection of documents in order to retain the narrative cloze in the context of commonsense inference; we consider this dataset in \u00a7 5.", "startOffset": 22, "endOffset": 49}, {"referenceID": 38, "context": "Alongside the narrative cloze, Pichotta and Mooney (2016) made use of a 5-point Likert scale (very likely to very unlikely) as a secondary evaluation of various script induction techniques.", "startOffset": 31, "endOffset": 58}, {"referenceID": 11, "context": "OCI embraces the notion of Dagan et al. (2006), in that we are concerned with human judgements of whether something is likely.", "startOffset": 27, "endOffset": 47}, {"referenceID": 46, "context": "Our motivation for this approach was first introduced by Schubert (2002):", "startOffset": 57, "endOffset": 73}, {"referenceID": 46, "context": "Following Schubert (2002) and Van Durme and Schubert (2008), we define an approach for abstracting over explicit assertions derived from corpora, leading to a large-scale collection of general possibilistic statements.", "startOffset": 10, "endOffset": 26}, {"referenceID": 46, "context": "Following Schubert (2002) and Van Durme and Schubert (2008), we define an approach for abstracting over explicit assertions derived from corpora, leading to a large-scale collection of general possibilistic statements.", "startOffset": 10, "endOffset": 60}, {"referenceID": 53, "context": "Following Rudinger and Van Durme (2014), we define a series of conversion rules for post-processing a sentential syntactic dependency tree into zero or more predicate argument structures.", "startOffset": 27, "endOffset": 40}, {"referenceID": 35, "context": "We use the Gigaword corpus (Parker et al., 2011) for extracting propositions as it is a comprehensive text archive.", "startOffset": 27, "endOffset": 48}, {"referenceID": 12, "context": "There exists a version containing automatically generated syntactic annotation (Ferraro et al., 2014), which bootstraps large-scale knowledge extraction.", "startOffset": 79, "endOffset": 101}, {"referenceID": 30, "context": "Here we choose WordNet (Miller, 1995) noun synsets8 as the semantic-class set.", "startOffset": 23, "endOffset": 37}, {"referenceID": 49, "context": ") When selecting the correct sense for an argument, we adopt a fast and relatively accurate method: always taking the first sense which is usually the most commonly used sense (Suchanek et al., 2007; Pasca, 2008).", "startOffset": 176, "endOffset": 212}, {"referenceID": 36, "context": ") When selecting the correct sense for an argument, we adopt a fast and relatively accurate method: always taking the first sense which is usually the most commonly used sense (Suchanek et al., 2007; Pasca, 2008).", "startOffset": 176, "endOffset": 212}, {"referenceID": 52, "context": "The abstracted propositions are turned into templates by replacing the sense\u2019s corresponding argument with a placeholder, similar to Van Durme et al. (2009). (See Fig 2 (b).", "startOffset": 137, "endOffset": 157}, {"referenceID": 34, "context": "In order to avoid too general senses, we set cut points at the depth of 4 (Pantel et al., 2007) to truncate the hierarchy and consider all 81,861 senses below these points.", "startOffset": 74, "endOffset": 95}, {"referenceID": 45, "context": "PyStanfordDependencies See Schubert (2002) for detail.", "startOffset": 27, "endOffset": 43}, {"referenceID": 50, "context": "(d) Generating inference candidates: As shown in Fig 2 (d), given a discourse context (Tanenhaus and Seidenberg, 1980), we first extract an argument of the context, then select the derived properties for the argument.", "startOffset": 86, "endOffset": 118}, {"referenceID": 54, "context": "As an alternative to the knowledge-based methods described above, we also adapt a neural sequence-tosequence model (Vinyals et al., 2015; Bahdanau et al., 2014) to directly generate inferences given contexts.", "startOffset": 115, "endOffset": 160}, {"referenceID": 1, "context": "As an alternative to the knowledge-based methods described above, we also adapt a neural sequence-tosequence model (Vinyals et al., 2015; Bahdanau et al., 2014) to directly generate inferences given contexts.", "startOffset": 115, "endOffset": 160}, {"referenceID": 6, "context": "The model is trained on sentence pairs labeled \u201centailment\u201d from the train set of the SNLI corpus (Bowman et al., 2015).", "startOffset": 98, "endOffset": 119}, {"referenceID": 6, "context": "In order to compare with existing inference corpora, we choose contexts from two resources: (1) the first sentence in the sentence pairs of the SNLI corpus (Bowman et al., 2015) which are captions from the Flickr30k corpus (Young et al.", "startOffset": 156, "endOffset": 177}, {"referenceID": 55, "context": ", 2015) which are captions from the Flickr30k corpus (Young et al., 2014), and (2) the first sentence in the stories of the ROCStories corpus (Mostafazadeh et al.", "startOffset": 53, "endOffset": 73}, {"referenceID": 32, "context": ", 2014), and (2) the first sentence in the stories of the ROCStories corpus (Mostafazadeh et al., 2016).", "startOffset": 76, "endOffset": 103}, {"referenceID": 39, "context": "Here, g\u03b8(\u00b7) is a regression model with \u03b8 as trained parameters; we train using the margin-based method of (Rennie and Srebro, 2005), implemented in (Pedregosa-Izquierdo, 2015)14.", "startOffset": 106, "endOffset": 131}, {"referenceID": 37, "context": "Here, g\u03b8(\u00b7) is a regression model with \u03b8 as trained parameters; we train using the margin-based method of (Rennie and Srebro, 2005), implemented in (Pedregosa-Izquierdo, 2015)14.", "startOffset": 148, "endOffset": 175}, {"referenceID": 9, "context": "In motivating the need for automatically building collections of common-sense knowledge, Clark et al. (2003) wrote:", "startOffset": 89, "endOffset": 109}], "year": 2016, "abstractText": "Humans have the capacity to draw commonsense inferences from natural language: various things that are likely but not certain to hold based on established discourse, and are rarely stated explicitly. We propose an evaluation of automated common-sense inference based on an extension of recognizing textual entailment: predicting ordinal human responses of subjective likelihood of an inference holding in a given context. We describe a framework for extracting common-sense knowledge for corpora, which is then used to construct a dataset for this ordinal entailment task, which we then use to train and evaluate a sequence to sequence neural network model. Further, we annotate subsets of previously established datasets via our ordinal annotation protocol in order to then analyze the distinctions between these and what we have constructed.", "creator": "LaTeX with hyperref package"}}}