{"id": "1611.01673", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "5-Nov-2016", "title": "Generative Multi-Adversarial Networks", "abstract": "Generative adversarial networks (GANs) are a framework for producing a generative model by way of a two-player minimax game. In this paper, we propose the \\emph{Generative Multi-Adversarial Network} (GMAN), a framework that extends GANs to multiple discriminators. In previous work, the successful training of GANs requires modifying the minimax objective to accelerate training early on. In contrast, GMAN can be reliably trained with the original, untampered objective. We explore a number of design perspectives with the discriminator role ranging from formidable adversary to forgiving teacher. Image generation tasks comparing the proposed framework to standard GANs demonstrate GMAN produces higher quality samples in a fraction of the iterations when measured by a pairwise GAM-type metric.", "histories": [["v1", "Sat, 5 Nov 2016 16:56:44 GMT  (4132kb,D)", "http://arxiv.org/abs/1611.01673v1", "Submitted as a conference paper at ICLR 2017"], ["v2", "Wed, 23 Nov 2016 15:33:09 GMT  (4133kb,D)", "http://arxiv.org/abs/1611.01673v2", "Submitted as a conference paper at ICLR 2017"], ["v3", "Thu, 2 Mar 2017 21:20:59 GMT  (4465kb,D)", "http://arxiv.org/abs/1611.01673v3", "Accepted as a conference paper (poster) at ICLR 2017"]], "COMMENTS": "Submitted as a conference paper at ICLR 2017", "reviews": [], "SUBJECTS": "cs.LG cs.MA cs.NE", "authors": ["ishan durugkar", "ian gemp", "sridhar mahadevan"], "accepted": true, "id": "1611.01673"}, "pdf": {"name": "1611.01673.pdf", "metadata": {"source": "CRF", "title": "GENERATIVE MULTI-ADVERSARIAL NETWORKS", "authors": ["Ishan Durugkar", "Ian Gemp", "Sridhar Mahadevan"], "emails": ["idurugkar@cs.umass.edu", "imgemp@cs.umass.edu", "mahadeva@cs.umass.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "Generative adversarial networks (Goodfellow et al. (2014)) (GANs) are a framework for producing a generative model by a two-player minimax game; one player, the generator, tries to generate realistic data samples by transforming noisy samples, z, drawn from a simple distribution (e.g., z \u0445 N (0, 1))) using a transformation function G\u03b8 (z) with learned weight, \u03b8. The generator receives feedback as to how realistic its synthetic sample is from another player, the discriminator, which tries to discern between synthetic data samples produced by the generator and samples drawn from an actual dataset using a function Dassault (z) with learned weights, elector.The GAN framework is one of the more recent successes in a line of research on adversarial training in machine learning (Schmidhuber (1992); Bagnell (2005); Ajakan et al al al al al. (2014) where games between learners are carefully crafted so that Nash equilibride with some specials at at at at."}, {"heading": "2 GENERATIVE ADVERSARIAL NETWORKS", "text": "The original formulation of a GAN et al. (2014) is a minimax game between a generator, G\u03b8 (z): z \u2192 x, and a discriminator, D\u03c9 (x): x \u2192 [0, 1], min G max D-DV (D, G) = Basic pdata (x) [log (D (x))] + Ez \u0445 pz (z) [log (1 \u2212 D (G))))], (1) where pdata (x) is the true data distribution and pz (z) is a simple (normally fixed) distribution that is easy to extract samples from (e.g. N (0, 1). We distinguish between the functional space of discriminators, D \u2212 and elements of that space, D. Let pG (x) the distribution be induced by the generator, G\u03b8 (z). We assume that D, G to obtain deep neural networks as typical cases."}, {"heading": "3 MULTIPLE DISCRIMINATORS", "text": "The introduction of multiple discriminators entails a number of design possibilities. At this point, we will examine approaches that lie between two extremes: 1) a more differentiated D (a better approximation to maxD V (D, G) and 2) a D that is better adapted to the capabilities of the generator. Mathematically, G's goal is formulated as minG maxDTeam F (V (D1, G),..., V (DN, G)) for various F options (see Figure 1), whereby DTeam denotes the combinatorial space of discriminator teams. On the other hand, each Di is still expected to independently maximize its own V (Di, G). Sometimes, we shorten V (G) with Vi and F (V1,..., VN) with FG (Vi)."}, {"heading": "3.1 MAXIMIZING V(D,G)", "text": "For a specified G, maximizing FG (Vi) with F: = max and N randomly instantiated copies of our discriminator is functionally equivalent to optimizing V (e.g. stochastic gradient ascent) with random parallel restarts and then displaying maxi-V (Di, G) as a loss for the generator - a very pragmatic approach to the difficulties caused by the non-convexity of V due to the deep mesh. The generator must minimize the maximum forces G in order to generate highly accurate samples that must withstand scrutiny of all N discriminators, each potentially representing a certain local maximum.In practice, maxDi-D V (Di, G) is not performed to convergence (or global optimality), so that the above problem is oversimplified. Furthermore, the introduction of N discriminators affects the dynamics of the game affecting the trajectories of the discriminators (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1)."}, {"heading": "3.2 BOOSTING", "text": "We may also consider using the maximum differentiation via N discriminators as a form of increase for the online classification problem of the discriminator (online, because G can generate an infinite stream of data).The increased discriminator receives a sample and must predict whether it came from the generator or from the dataset. The booster then makes its prediction using the predictions of the N weaker di.There are a few differences between the maximum (case 1) and the online increase (case 2).In case 1, our booster is limited to selecting a single weak discriminator (i.e., a pure strategy), while in case 2 many boosting algorithms use more general linear combinations of the discriminators. In addition, in case 2, a booster must make a prediction before it receives a loss function. In case 1, we assume that the loss function is available at the prediction time, allowing us to present the max.It is possible to use the weak discriminators by means of boosting, and then ignoring the Vmax boosting effects of the booster."}, {"heading": "3.3 REGULATING THE DISCRIMINATOR", "text": "The previous perspectives focus on improving the discriminator in order to provide a better approximation of maxD V (D, G) to the generator. Our third perspective raises the question: \"Is maxD V (D, G) too harsh a critic?\" 3.3.1 Soft-DISCRIMINATORIn practice, training against a far superior discriminator can hamper the generator's learning, because the generator is unlikely to generate samples that are considered \"realistic\" by discriminator standards, and the generator therefore receives uniformly negative feedback. This is problematic because the information contained in the gradient only dictates from negative feedback where the pG (x) can be shut down, not specifically where the pG (x) should be increased. Furthermore, lowering pG (x) necessarily increases pG (x) in other regions of X (to maintain pG (x) = 1), which may be samples from the true datasheet dilemma."}, {"heading": "3.3.2 USING THE ORIGINAL MINIMAX OBJECTIVE", "text": "To illustrate the effect of Softmax on training, note that the component of AMsoft (V, 0) that is relevant for training the generator can be rewritten as 1NN-iEx-pG (x) [log (1 \u2212 Di (x)] = 1N Ex-pG (x) [log (z)]. (6) where z = N i (1 \u2212 Di (x)). Note that the generator gradient, | \u2202 log (z) \u2202 z |, is minimized at z = 1 above z (0, 1]. From this form, z = 1 if and only if Di = 0 \u0441i, i.e. G receives a vanishing gradient only if all Di agree that the sample is wrong; this is especially unlikely for large N. In other words, G only needs to fool a singleDi to get constructive feedback, this result allows the generator to successfully minimize the original generator objective, log (1 \u2212 D)."}, {"heading": "3.3.3 MAINTAINING MULTIPLE HYPOTHESES", "text": "We also argue for this ensemble approach on a more fundamental level. Here, we use the estimation perspective of the density ratio of GANs (Uehara et al. (2016). The original GAN evidence assumes that we have access to pdata (x), albeit only implicitly. In most cases of interest, the discriminator only has access to a finite dataset sampled from pdata (x); therefore, when calculating the expectations of V (D, G), we only take samples from our finite dataset. This corresponds to the formation of a GAN with pdata (x) = p \"data, which is a distribution of dot masses across all data points in the dataset. So let's say we form a discriminator and generator, each 1\" GV \"= \u2212.\" i \"Di\" D \"D\" J \"6 = i\" tenner \"for all data points in the dataset."}, {"heading": "3.4 AUTOMATING REGULATION", "text": "The problem of balancing discriminator and generator has been widely recognized in previous work with GANs. Problems with unstable dynamics, oscillatory behavior, and generator collapse are not uncommon. Furthermore, the discriminator is often able to achieve a high degree of classification accuracy (generating a single scalar) before the generator has made sufficient progress in what is arguably the more difficult generative task (generating a high-dimensional sample). Salimane et al. (2016) suggested smoothing the label to reduce the generator's susceptibility to a relatively superior discriminator. Here, we examine an approach that allows the generator to automatically moderate the performance of the discriminator when needed, but nevertheless encourages the generator to defend itself against more precise adversaries. Specifically, we are expanding the generator objective: min G, \u03bb > 0FG (Vi) \u2212 f (\u03bb) \u2212 f (7), where the generator is most monotonous (1)."}, {"heading": "4 EVALUATION", "text": "In their original paper, Goodfellow et al. (2014) report on probability estimates from Gaussian Parzen windows, which they admit have high variance and do not perform well in high-dimensional environments. Salimans et al. (2016) recommend an Inception Score, which assumes, however, that labels exist for the dataset. Recently, Im et al. (2016) introduced Generative Adversarial Metric (GAM) to make pair comparisons between independently trained GAN models. The basic idea behind their approach are two generators, discriminator pairs (G1, D1) and (G2, D2), which we should be able to learn their relative performance by judging each generator by the discriminator of the opponent."}, {"heading": "4.1 METRIC", "text": "We introduce a variant of GAM, the generative multiadversarial metric (GMAM), which is suitable for training with multiple discriminators, GMAM = log (F aGb (V ai) F aGa (V a i) / F aGa (V bi) F bGb (V b i)). (8) where a and b refer to the two GMAN variants (see 3 for the notation FG (Vi)). The idea is similar: If G2 performs better than G1 in both D1 and D2, then GMAM > 0 (always V \u2264 0). If G1 performs better in both cases, GMAM < 0, otherwise the result is indeterminate."}, {"heading": "4.2 EXPERIMENTS", "text": "We evaluate the variations of GMAN mentioned above against a variety of image generation tasks: MNIST (LeCun et al. (1998), CIFAR-10 (Krizhevsky (2009)), and CelebA (Liu et al. (2015)). We focus on steady-state convergence rates along with the quality of the steady-state generator according to the GMAM metric. To summarize: In a loose sequence of increasing discriminator forbearance, we compare \u2022 F-Boost: A single AdaBoost.OL-enhanced discriminator (see Appendix A.5). \u2022 P-Boost: Di is presented according to AdaBoost.OL. A max on the weak learning losses to the generator instead of the increased prediction (see Appendix A.5). \u2022 GMAN-max: max {Vi} is presented to the generator. \u2022 GAN: Standard GAN \u2212 Boost with a single discriminator (see Appendix 1.3) \u2022 Momified GAN-Diversification Networks with GAN)."}, {"heading": "4.2.1 MNIST", "text": "Figures 3 and 4 show that increasing the number of discriminators reduces the number of stationary iterations in MNIST by two times; increasing N (the size of the discriminator ensemble) also has the added advantage of reducing the variance in game dynamics. Figure 5 confirms this conclusion with recognizable digits appearing about one epoch before each discriminator run; numbers in the stationary state also appear slightly sharper. Our GMAM measure (see Table 1) matches the relative quality of the images in Figure 5, with GMAN \u0445 achieving the best overall performance. Figure 6 shows GMAN's attempt to regulate the difficulty of the game to accelerate learning."}, {"heading": "4.2.2 CELEBA & CIFAR-10", "text": "We see a similar accelerated convergence behavior for the CelebA dataset in Figure 8. Figure 9 shows images generated from GMAN-0 to CIFAR-10. See Appendix A.1 for more results.We also found that GMAN is robust against the unimodal behavior seen in GANs, where the generator always sends the same point. We believe this is due to the fact that the generator in GMAN must appease a variety of discriminators in each minibatch. Outputting a single point will do well for a single discriminator at the expense of the other discriminators."}, {"heading": "5 CONCLUSION", "text": "We introduced several discriminators into the GAN framework and examined discriminator roles ranging from a forgiving opponent to a forgiving teacher. We found that GMAN variants achieved faster convergence to a higher-quality equilibrium state as measured by a GAM metric (GMAM). In addition, GMAN enables the use of the original GAN target by increasing the likelihood that the generator will receive constructive feedback. In future work, we will look at more complex mechanisms that allow the generator to control the game, as well as other ways to ensure diversity among discriminators. Introducing multiple generators is an obvious next step conceptually, but we expect difficulties due to more complex game dynamics, which is why game theory and game design will likely be important."}, {"heading": "ACKNOWLEDGMENTS", "text": "We appreciate helpful conversations with Stefan Dernbach, Archan Ray, Luke Vilnis, Ben Turtel, Stephen Giguere, Rajarshi Das and Subhransu Maji."}, {"heading": "A APPENDIX", "text": "In fact, it is in fact in such a way that it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, in which it is about a way, and in which it is about a way, and in which it is about a way, and in which it is about a way, and in which it is about a way, and in which it is about a way, in which it is about a way, and in which it is about a way, in which it is about a way, in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and in which it is about which it is about a way and in which it is about a way and in which it is about which it is about a way and which it is about which it is about which it is about a way and in which it is about which it is about which it is about a way and in which it is about which it is about which it is about which it is about a way and which it is about which it is about which it is about which it is about a way and which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about which it is about"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Generative adversarial networks (GANs) are a framework for producing a gen-<lb>erative model by way of a two-player minimax game. In this paper, we propose<lb>the Generative Multi-Adversarial Network (GMAN), a framework that extends<lb>GANs to multiple discriminators. In previous work, the successful training of<lb>GANs requires modifying the minimax objective to accelerate training early on.<lb>In contrast, GMAN can be reliably trained with the original, untampered objec-<lb>tive. We explore a number of design perspectives with the discriminator role rang-<lb>ing from formidable adversary to forgiving teacher. Image generation tasks com-<lb>paring the proposed framework to standard GANs demonstrate GMAN produces<lb>higher quality samples in a fraction of the iterations when measured by a pairwise<lb>GAM-type metric.", "creator": "LaTeX with hyperref package"}}}