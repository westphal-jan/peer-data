{"id": "1611.01989", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": "DeepCoder: Learning to Write Programs", "abstract": "We develop a first line of attack for solving programming competition-style problems from input-output examples using deep learning. The approach is to train a neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network's predictions to augment search techniques from the programming languages community, including enumerative search and an SMT-based solver. Empirically, we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent Neural Network approach, and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites.", "histories": [["v1", "Mon, 7 Nov 2016 11:09:45 GMT  (140kb,D)", "http://arxiv.org/abs/1611.01989v1", "Submitted to ICLR 2017"], ["v2", "Wed, 8 Mar 2017 11:50:33 GMT  (259kb,D)", "http://arxiv.org/abs/1611.01989v2", "Submitted to ICLR 2017"]], "COMMENTS": "Submitted to ICLR 2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["matej balog", "alexander l gaunt", "marc brockschmidt", "sebastian nowozin", "daniel tarlow"], "accepted": true, "id": "1611.01989"}, "pdf": {"name": "1611.01989.pdf", "metadata": {"source": "CRF", "title": "DEEPCODER: LEARNING TO WRITE PROGRAMS", "authors": ["Matej Balog", "Alexander L. Gaunt", "Marc Brockschmidt", "Sebastian Nowozin", "Daniel Tarlow"], "emails": [], "sections": [{"heading": "1 INTRODUCTION", "text": "(.). (.). (.). (.). (.). (.). In fact, it is so that it is a way in which people are able to determine for themselves what they want and what they want. (.). (.) It is so that people are able to decide whether they want it or not. (.). (.). (.) It is as if they do not want it. (.). (.). (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). (.). (.). (.). (.). (.). \"(.).\" (.). \"(.).\" (.). \"(.\" (.). \"(.).\" (.). \"(.\" (.). \"(.).\" (.). \"(.\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.).). \"(.).\" (.). \"(.\" (.). \"(.).).\" (. \"(.).\" (.). \"(.).\" (.). \"(.\" (.).). \"(.).).\" (. \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.).\" (.). \"(.\" (.).). \"(.).\" (.). \"(.\" (.).). \"(.).\" (.). \"(.).).).\" (. \"(.). (.).\" (.). (.).).). (.)."}, {"heading": "2 BACKGROUND ON INDUCTIVE PROGRAM SYNTHESIS", "text": "This year, it is more than ever in the history of the city, where it is more than ever, that it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, where it is a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a place, a, a place, a place, a place, a place, a place, a place, a, a place, a place, a place, a place, a place, a, a, a place, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a, a"}, {"heading": "3 LEARNING INDUCTIVE PROGRAM SYNTHESIS (LIPS)", "text": "In this section, we outline the general approach we follow in this work, which we call Learning Inductive Program Synthesis (LIPS). Details of our instantiation of LIPS appear in Section 4. The components of LIPS are (1) a DSL specification, (2) a method of data generation, (3) a machine learning model that leads from input-output examples to program attributes, and (4) a search method that searches the program space in an order that corresponds to (3) the formulation of Menon et al. (2013) the relationship and key differences are discussed in Sector 6. (1) DSL and attributes are important, as it is in every program attribute attribute attribute."}, {"heading": "4 DEEPCODER", "text": "Here we describe DeepCoder, our instantiation of LIPS with a choice of DSL, a strategy for data generation, models for encoding input-output sets and algorithms for searching in program memory."}, {"heading": "4.1 DOMAIN SPECIFIC LANGUAGE AND ATTRIBUTES", "text": "We consider binary attributes that indicate the presence or absence of high-level functions in the target program. To make this effective, the selected DSL must contain constructs that are not so low that they should all occur in the vast majority of programs, but at the same time be so widespread that their occurrence can be successfully predicted using input-output examples. Following this observation, our DSL is loosely inspired by query languages such as SQL or LINQ, in which high-level functions are used in order to manipulate data. A program in our DSL is a sequence of function calls in which the result of each call is initialized a fresh variable that is either a singleton (integer) or an (integer) array. Functions can be applied to all inputs or are previously compiled (intermediate) variables."}, {"heading": "4.2 DATA GENERATION", "text": "To create a dataset, we list programs in the DSL and heuristically truncate those with easily identifiable problems, such as a redundant variable whose value does not affect program output, or, more generally, the existence of a shorter equivalent program (equivalence can be overstated by identical behavior to randomly or carefully selected inputs).To generate valid input for a program, we impose a limitation of the output value, limiting the integers to a given range, and then propagate these limitations backwards through the program to obtain a range of valid values for each input. If one of these ranges is empty, we discard the program. Otherwise, we can create input pairs by selecting input from the precalculated valid ranges and executing the program to obtain the output ranges. The binary attribute vectors are easy to calculate from the program source codes."}, {"heading": "4.3 MACHINE LEARNING MODEL", "text": "The fact is that we will find ourselves in a position to be in a position to be in the position we are in."}, {"heading": "4.4 SEARCH", "text": "One of the central ideas of this paper is the use of a neural network to guide the search for a program that is consistent with a set of input and output examples, rather than directly predicting the entire source code. This section briefly describes the search techniques and how they integrate the predicted attributes. We use an optimized version of DFS to search for programs with a specified maximum length T. (see Appendix D for details) When the search procedure adds a new function to a subprogram, it must try out the functions in the DSL in a certain order. At this point, DFS can decide to view the functions as grouped according to its predicted probabilities from the neural network. \"Sort and add\" enumeration. A stronger way to use the predicted probabilities of functions in an enumerative search procedure is to use a sort and add scheme that maintains a set of active functions and builds the DFS with the active function group only as a sketch."}, {"heading": "4.5 TRAINING LOSS FUNCTION", "text": "We use negative cross entropy loss to train the neural network described in paragraph 4.3 so that its predictions about each function can be interpreted as marginal probabilities. LIPS framework dictates learning q (a | E), the common distribution of all attributes of a given input-output example, and it is not clear from the outset how much DeepCoder loses by ignoring correlations between functions. However, under the simplistic assumption that the runtime of searching for a program of length T with C functions provided to a search routine is proportional to the CT, the following result for sorting and adding procedures shows that its runtime can be optimized using marginal probabilities. Lemma 1. For each fixed program length T, the expected total runtime of a sorting and addition search scheme can be limited by a quantity minimized by adding the functions in order of decreasing the true marginal probabilities."}, {"heading": "5 EXPERIMENTS", "text": "In this section, we report on results from two categories of experiments. Our main experiments (Section 5.1) show that the LIPS framework can lead to significant performance gains in solving IPS by demonstrating such gains with DeepCoder. In Section 5.2, we demonstrate the robustness of the method by demonstrating a strong type of generalization capability across programs of varying lengths."}, {"heading": "5.1 DEEPCODER COMPARED TO BASELINES", "text": "We trained a neural network, as described in Section 4.3, to predict the functions used by input-output examples, and constructed a test set of P = 100 programs, which ensured semantically separation from all programs on which the neural network was trained. For each test program, we generated M = 5 input-output examples comprising whole sizes up to 256 experiment, fed the examples to the trained neural network and fed the obtained predictions to the search procedures in Section 4.4 experiment. We also considered an RNN-based decoder generating programs by beam search experiment (see Section 5.3 for details experiment experiment experiment). In order to evaluate experiment DeepCoder, we then recorded the time needed for the search procedures to find a program that is consistent with the M-input-output-output experiment experiment, experiment, smaller experiment, smaller experiment, smaller experiment, smaller experiment, to evaluate experiment, probability procedures, to find the search procedures, to find a program that is consistent with the M-input-output-output experiments, experiments. As a baseline, we also conducted all search procedures, which are calculated as simple experimental probabilities, global probabilities, which are used, global probabilities, first, experiments, first, experiments, M-input-output examples."}, {"heading": "5.2 GENERALIZATION ACROSS PROGRAM LENGTHS", "text": "To investigate the generalization capability of the encoder in programs of varying length, we trained a network to predict functions used using input-output examples generated from programs of length Ttrain (1,.., 4), and then we used each of these networks to predict functions on 5 test sets containing input-output examples generated from programs of length Ttest (1,.., 5), the test programs of a given length T were semantically separated from all training programs of same length T and also from all training and test programs of shorter length T (T. For each of the combinations of Ttrain and Ttest, the enumerative search was performed both with and without using the predictions of the neural network (in the latter case using earlier probabilities) until it solved 20% of the test set tasks. Figure 3b shows the relative acceleration of the solver that had access to predictions from the trained neural networks (in the latter case, the latter were corrected to the latter's length)."}, {"heading": "5.3 ALTERNATIVE MODELS", "text": "Encoder We investigated the replacement of the encoder for the feed-forward architecture (Section 4.3) with an RNN, a natural baseline. Using a GRU-based RNN, we achieved almost as good results as using the feed-forward architecture, but found the RNN encoder more difficult to train. We also considered a purely neural network-based approach in which an RNN decoder is trained to predict the entire program token-by-token. We combined this with our feed-forward encoder by initializing the RNN using the pooled last layer of the encoder. We found it much more difficult to train an RNN decoder to predict an RNN decoder an RNN decoder compared to our feed-forward encoder using the independent binary classifiers used above. The beam search was used to explore probable programs predicted by the RNN decoder, an RNN decoder to train an RNN decoder an RNN decoder, an RNN decoder to train an RNN decoder, compared to the independent binary classifiers used above."}, {"heading": "6 RELATED WORK", "text": "The most closely related work is that of Menon et al. (2013), in which a hand-coded set of characteristics of input-output examples are used as \"clues.\" This work shares the idea of learning to take the search beyond the program space, conditioned by input-output examples. A difference lies in the areas in which the results are available. Menon et al. (2013) operate on short string manipulation programs, where it is easier to detect patterns in the input-output examples (e.g. if the outputs are based on the output examples). Output-output strategies are short string manipulation programs, in which it is easier to detect patterns in the input-output examples (if the outputs are always permutations or substrings of the input programs). Our work shows that there are strong patterns in the input-output examples."}, {"heading": "7 DISCUSSION AND FUTURE WORK", "text": "Our empirical results show that for many programs, this technique improves the runtime of a wide range of IPS baselines by 1-3 jobs. We have found several problems in real-world online programming problems that can be solved with a program in our language, confirming the relevance of the problem class we have studied in this work. In summary, this suggests that we have made significant progress in solving competitive programming problems, and the machine learning component plays an important role in making them more tractable. However, some limitations remain. First, the programs we can synthesize are only the simplest problems in programming competitive websites and are simpler than most competitive problems. Many problems require more complex algorithmic solutions such as dynamic programming and searching, which are currently beyond our reach."}, {"heading": "ACKNOWLEDGMENTS", "text": "The authors would like to thank Rishabh Singh for his valuable guide to using the Sketch synthesis system."}, {"heading": "A EXAMPLE PROGRAMS", "text": "This section shows sample programs in our Domain Specific Language (DSL), along with input examples and short descriptions. These programs were inspired by simple tasks that appear on real \u2190 websites and are intended to enhance the expressiveness of our DSL. Program 0: k \u2190 int b \u2190 [int] c \u2190 b \u2190 TAKE k \u2190 SUM dInput-Output Example: Input-Output Example: 2, [3 4 7 5] Output: [7] Description: A new store near you sells n paintings. You have k < n friends and you want to buy each of your friends a painting."}, {"heading": "B EXPERIMENTAL RESULTS", "text": "The results presented in Section 5.1 showed the calculation times obtained from the LIPS framework (using DeepCoder), as opposed to solving each program synthesis problem with only the information about the global incidence of functions in the source code. For the sake of completeness, we show diagrams of the raw calculation times of each search to solve a given number of problems. Fig.5 shows the calculation times of DFS, the enumerative search with a sorting and addition scheme, the sketch solver with a sorting and addition scheme, and the beam search when searching for a program that matches input-output examples from P = 100 different test programs of the length T = 3. As discussed in Section 5.1, it was ensured that these test programs are semantically separated from all programs that are used to train the neural networks, as well as from all programs of shorter length (as discussed in Section 4.2).6 shows the calculation times and the DFS were created using a calculation scheme."}, {"heading": "C THE NEURAL NETWORK", "text": "As briefly described in Section 4.3, we used the following simple Feed Architecture encoders: \u2022 For each input output example in the set generated from a single Ground Truth program: - Pad arrays that appear in the inputs and output to a maximum length L = 20 with a special NULL value. - Set the type (singleton integer or integer array) of each input and output using a one-hot encoding vector. - Embed each integer into the valid integer range (\u2212 256 to 255) using a learned embedding in E = 20 dimensional space. Also learn how to embed the filling NULL value. - Connect the representations of the input types, the embedding of integers into the input range (\u2212 256 to 255) using a learned embedding in E = 20 dimensional space. - Connect the embedding of the output type and the output type, and the embedding of the integer type of the last unit (the type of the FID and the output type of the FID) with the output Vx7."}, {"heading": "D DEPTH-FIRST SEARCH", "text": "We use an optimized C + + implementation of the Depth Search (DFS) to search for programs with a specified maximum length T. In the Depth Search, we first select the first function (and its arguments) of a potential solution program, and then look recursively at all possibilities to fill out the rest of the program (up to length T), before proceeding to the next selection of the first instruction (if no solution has yet been found). A program is considered a solution if it is consistent with all M = 5 provided input output examples. Note that all candidate programs need to be evaluated on the M inputs and the results need to be checked for parity with the provided M outputs. Our implementation of DFS takes advantage of the sequential structure of programs in our DSL by caching the results of the evaluation of all prefixes of the currently considered program on the sample inputs, allowing us to efficiently reuse the calculation between candidate programs with common prefixes per second, at approximately the rate of 3."}, {"heading": "E TRAINING LOSS FUNCTION", "text": "In the sect. 4.5 we outlined a justification for using marginal probabilities of individual functions as a useful intermediate representation to provide a solution approach using a sorting and addition scheme (we considered the Enumerative Search and the Sketch Solver with this scheme).Here we provide a more detailed discussion. Predicting program components from input-output examples can be considered a multi-label classification problem, where each instance (set of input-output examples) is associated with a set of relevant designations (functions appearing in the code that generates the examples).We designate the number of labels (functions) by C, and note that during this work C = 34. If the task is predictive of a subset of labels y, {0, 1} C, different loss functions can be used to measure the prediction error of a classification (function) (x) or ranking (f)."}, {"heading": "F DOMAIN SPECIFIC LANGUAGE OF DEEPCODER", "text": "In this case, NULL is a special value, e.g. referring to an integer outside the working integer range.Specified array \u2022 Specified empty arrays: Specified arrays \u2022 Specified empty arrays: Specified arrays: [int] - > int lambda xs: xs [0] if len (xs) > 0 otherwise 0 otherwise zero Specified arrays (or NULL s if the array is empty). \u2022 LAST: [int] - > int lambda xs: xs: xs: xs, if len (xs) > 0 otherwise 0 Specified arrays - or NULL s if the array is empty."}], "references": [{"title": "DeepMath deep sequence models for premise selection", "author": ["Alex A. Alemi", "Fran\u00e7ois Chollet", "Geoffrey Irving", "Christian Szegedy", "Josef Urban"], "venue": "In Proceedings of the 29th Conference on Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Alemi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Alemi et al\\.", "year": 2016}, {"title": "The helmholtz machine", "author": ["Peter Dayan", "Geoffrey E Hinton", "Radford M Neal", "Richard S Zemel"], "venue": "Neural computation,", "citeRegEx": "Dayan et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Dayan et al\\.", "year": 1995}, {"title": "On label dependence and loss minimization in multi-label classification", "author": ["Krzysztof Dembczy\u0144ski", "Willem Waegeman", "Weiwei Cheng", "Eyke H\u00fcllermeier"], "venue": "Machine Learning,", "citeRegEx": "Dembczy\u0144ski et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dembczy\u0144ski et al\\.", "year": 2012}, {"title": "Hllermeier. Bayes optimal multilabel classification via probabilistic classifier chains", "author": ["Krzysztof J. Dembczynski", "Weiwei Cheng", "Eyke"], "venue": "In Proceedings of the 27th International Conference on Machine Learning", "citeRegEx": "Dembczynski et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Dembczynski et al\\.", "year": 2010}, {"title": "Synthesizing data structure transformations from input-output examples", "author": ["John K. Feser", "Swarat Chaudhuri", "Isil Dillig"], "venue": "In Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI),", "citeRegEx": "Feser et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Feser et al\\.", "year": 2015}, {"title": "Terpret: A probabilistic programming language for program induction", "author": ["Alexander L. Gaunt", "Marc Brockschmidt", "Rishabh Singh", "Nate Kushman", "Pushmeet Kohli", "Jonathan Taylor", "Daniel Tarlow"], "venue": "CoRR, abs/1608.04428,", "citeRegEx": "Gaunt et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gaunt et al\\.", "year": 2016}, {"title": "Hybrid computing using a neural network with dynamic external memory", "author": ["Alex Graves", "Greg Wayne", "Malcolm Reynolds", "Tim Harley", "Ivo Danihelka", "Agnieszka GrabskaBarwi\u0144ska", "Sergio G\u00f3mez Colmenarejo", "Edward Grefenstette", "Tiago Ramalho", "John Agapiou"], "venue": null, "citeRegEx": "Graves et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2016}, {"title": "Programming by examples: Applications, algorithms, and ambiguity resolution", "author": ["Sumit Gulwani"], "venue": "In Proceedings of the 8th International Joint Conference on Automated Reasoning (IJCAR),", "citeRegEx": "Gulwani.,? \\Q2016\\E", "shortCiteRegEx": "Gulwani.", "year": 2016}, {"title": "Synthesis of loop-free programs", "author": ["Sumit Gulwani", "Susmit Jha", "Ashish Tiwari", "Ramarathnam Venkatesan"], "venue": "In Proceedings of the 32nd ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), pp", "citeRegEx": "Gulwani et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gulwani et al\\.", "year": 2011}, {"title": "Learning to pass expectation propagation messages", "author": ["Nicolas Heess", "Daniel Tarlow", "John Winn"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Heess et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Heess et al\\.", "year": 2013}, {"title": "The informed sampler: A discriminative approach to bayesian inference in generative computer vision models", "author": ["Varun Jampani", "Sebastian Nowozin", "Matthew Loper", "Peter V Gehler"], "venue": "Computer Vision and Image Understanding,", "citeRegEx": "Jampani et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Jampani et al\\.", "year": 2015}, {"title": "Inferring algorithmic patterns with stack-augmented recurrent nets", "author": ["Armand Joulin", "Tomas Mikolov"], "venue": "In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems", "citeRegEx": "Joulin and Mikolov.,? \\Q2015\\E", "shortCiteRegEx": "Joulin and Mikolov.", "year": 2015}, {"title": "Neural gpus learn algorithms", "author": ["\u0141ukasz Kaiser", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations.,", "citeRegEx": "Kaiser and Sutskever.,? \\Q2016\\E", "shortCiteRegEx": "Kaiser and Sutskever.", "year": 2016}, {"title": "Auto-encoding variational bayes", "author": ["Diederik P Kingma", "Max Welling"], "venue": "CoRR, abs/1312.6114,", "citeRegEx": "Kingma and Welling.,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "Neural random-access machines", "author": ["Karol Kurach", "Marcin Andrychowicz", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations 2016,", "citeRegEx": "Kurach et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kurach et al\\.", "year": 2015}, {"title": "Gated graph sequence neural networks", "author": ["Yujia Li", "Daniel Tarlow", "Marc Brockschmidt", "Richard S. Zemel"], "venue": "In Proceedings of the 4th International Conference on Learning Representations (ICLR),", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A machine learning framework for programming by example", "author": ["Aditya Krishna Menon", "Omer Tamuz", "Sumit Gulwani", "Butler W Lampson", "Adam Kalai"], "venue": "In Proceedings of the International Conference on Machine Learning (ICML),", "citeRegEx": "Menon et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Menon et al\\.", "year": 2013}, {"title": "Neural programmer: Inducing latent programs with gradient descent", "author": ["Arvind Neelakantan", "Quoc V. Le", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations", "citeRegEx": "Neelakantan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2016}, {"title": "Learning program embeddings to propagate feedback on student code", "author": ["Chris Piech", "Jonathan Huang", "Andy Nguyen", "Mike Phulsuksombati", "Mehran Sahami", "Leonidas J. Guibas"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning (ICML),", "citeRegEx": "Piech et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Piech et al\\.", "year": 2015}, {"title": "Flashmeta: a framework for inductive program synthesis", "author": ["Oleksandr Polozov", "Sumit Gulwani"], "venue": "In OOPSLA,", "citeRegEx": "Polozov and Gulwani.,? \\Q2015\\E", "shortCiteRegEx": "Polozov and Gulwani.", "year": 2015}, {"title": "Neural programmer-interpreters", "author": ["Scott E. Reed", "Nando de Freitas"], "venue": "In Proceedings of the 4th International Conference on Learning Representations", "citeRegEx": "Reed and Freitas.,? \\Q2016\\E", "shortCiteRegEx": "Reed and Freitas.", "year": 2016}, {"title": "Programming with a differentiable forth interpreter", "author": ["Sebastian Riedel", "Matko Bosnjak", "Tim Rockt\u00e4schel"], "venue": "CoRR, abs/1605.06640,", "citeRegEx": "Riedel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2016}, {"title": "Stochastic program optimization", "author": ["Eric Schkufza", "Rahul Sharma", "Alex Aiken"], "venue": "Commununications of the ACM,", "citeRegEx": "Schkufza et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Schkufza et al\\.", "year": 2016}, {"title": "Real-time human pose recognition in parts from single depth images", "author": ["Jamie Shotton", "Toby Sharp", "Alex Kipman", "Andrew Fitzgibbon", "Mark Finocchio", "Andrew Blake", "Mat Cook", "Richard Moore"], "venue": "Communications of the ACM,", "citeRegEx": "Shotton et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Shotton et al\\.", "year": 2013}, {"title": "Predicting a correct program in programming by example", "author": ["Rishabh Singh", "Sumit Gulwani"], "venue": "In Proceedings of the 27th Conference on Computer Aided Verification (CAV),", "citeRegEx": "Singh and Gulwani.,? \\Q2015\\E", "shortCiteRegEx": "Singh and Gulwani.", "year": 2015}, {"title": "Program Synthesis By Sketching", "author": ["Armando Solar-Lezama"], "venue": "PhD thesis, EECS Dept., UC Berkeley,", "citeRegEx": "Solar.Lezama.,? \\Q2008\\E", "shortCiteRegEx": "Solar.Lezama.", "year": 2008}, {"title": "Learning stochastic inverses", "author": ["Andreas Stuhlm\u00fcller", "Jessica Taylor", "Noah D. Goodman"], "venue": "In Advances in Neural Information Processing Systems (NIPS)", "citeRegEx": "Stuhlm\u00fcller et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Stuhlm\u00fcller et al\\.", "year": 2013}, {"title": "End-to-end memory networks. In Advances in Neural Information Processing Systems", "author": ["Sainbayar Sukhbaatar", "Arthur Szlam", "Jason Weston", "Rob Fergus"], "venue": "Annual Conference on Neural Information Processing Systems", "citeRegEx": "Sukhbaatar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Learning simple algorithms from examples", "author": ["Wojciech Zaremba", "Tomas Mikolov", "Armand Joulin", "Rob Fergus"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "citeRegEx": "Zaremba et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 14, "context": "Recently, there has been much interest in program-like neural network models (Graves et al., 2014; Weston et al., 2014; Kurach et al., 2015; Joulin & Mikolov, 2015; Sukhbaatar et al., 2015; Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Zaremba et al., 2016; Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code.", "startOffset": 77, "endOffset": 309}, {"referenceID": 27, "context": "Recently, there has been much interest in program-like neural network models (Graves et al., 2014; Weston et al., 2014; Kurach et al., 2015; Joulin & Mikolov, 2015; Sukhbaatar et al., 2015; Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Zaremba et al., 2016; Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code.", "startOffset": 77, "endOffset": 309}, {"referenceID": 17, "context": "Recently, there has been much interest in program-like neural network models (Graves et al., 2014; Weston et al., 2014; Kurach et al., 2015; Joulin & Mikolov, 2015; Sukhbaatar et al., 2015; Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Zaremba et al., 2016; Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code.", "startOffset": 77, "endOffset": 309}, {"referenceID": 28, "context": "Recently, there has been much interest in program-like neural network models (Graves et al., 2014; Weston et al., 2014; Kurach et al., 2015; Joulin & Mikolov, 2015; Sukhbaatar et al., 2015; Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Zaremba et al., 2016; Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code.", "startOffset": 77, "endOffset": 309}, {"referenceID": 6, "context": "Recently, there has been much interest in program-like neural network models (Graves et al., 2014; Weston et al., 2014; Kurach et al., 2015; Joulin & Mikolov, 2015; Sukhbaatar et al., 2015; Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Zaremba et al., 2016; Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code.", "startOffset": 77, "endOffset": 309}, {"referenceID": 5, "context": "Recently, there has been much interest in program-like neural network models (Graves et al., 2014; Weston et al., 2014; Kurach et al., 2015; Joulin & Mikolov, 2015; Sukhbaatar et al., 2015; Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Zaremba et al., 2016; Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code. Only very recently, Riedel et al. (2016); Bunel et al.", "startOffset": 78, "endOffset": 448}, {"referenceID": 5, "context": "Recently, there has been much interest in program-like neural network models (Graves et al., 2014; Weston et al., 2014; Kurach et al., 2015; Joulin & Mikolov, 2015; Sukhbaatar et al., 2015; Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Zaremba et al., 2016; Graves et al., 2016), but none of these can write programs; that is, they do not generate human-readable source code. Only very recently, Riedel et al. (2016); Bunel et al. (2016); Gaunt et al.", "startOffset": 78, "endOffset": 469}, {"referenceID": 5, "context": "(2016); Gaunt et al. (2016) explored the use of gradient descent to induce source code from input-output examples via differentiable interpreters.", "startOffset": 8, "endOffset": 28}, {"referenceID": 5, "context": "(2016); Gaunt et al. (2016) explored the use of gradient descent to induce source code from input-output examples via differentiable interpreters. However, Gaunt et al. (2016) show that differentiable interpreter-based program induction is inferior to discrete search-based techniques used by the programming languages community.", "startOffset": 8, "endOffset": 176}, {"referenceID": 4, "context": "This approach can be combined with pruning based on types and other logical reasoning (Feser et al., 2015).", "startOffset": 86, "endOffset": 106}, {"referenceID": 25, "context": ", Sketch (Solar-Lezama, 2008) and Brahma (Gul-", "startOffset": 9, "endOffset": 29}, {"referenceID": 22, "context": "One of the most successful recent examples is the STOKE super-optimization system (Schkufza et al., 2016), which uses stochastic local search to find assembly programs that have the same semantics as an input program but execute faster.", "startOffset": 82, "endOffset": 105}, {"referenceID": 7, "context": "A popular choice for ranking is to choose the shortest program consistent with inputoutput examples (Gulwani, 2016).", "startOffset": 100, "endOffset": 115}, {"referenceID": 16, "context": "The framework is related to the formulation of Menon et al. (2013); the relationship and key differences are discussed in Sect.", "startOffset": 47, "endOffset": 67}, {"referenceID": 25, "context": "Sketch (Solar-Lezama, 2008) is a successful SMT-based program synthesis tool from the programming languages research community.", "startOffset": 7, "endOffset": 27}, {"referenceID": 3, "context": "Dembczynski et al. (2010) showed that in multi-label classification under a so-called Rank loss, it is Bayes optimal to rank the labels according to their marginal probabilities.", "startOffset": 0, "endOffset": 26}, {"referenceID": 16, "context": "The most closely related work is that of Menon et al. (2013), in which a hand-coded set of features of input-output examples are used as \u201cclues.", "startOffset": 41, "endOffset": 61}, {"referenceID": 16, "context": "The most closely related work is that of Menon et al. (2013), in which a hand-coded set of features of input-output examples are used as \u201cclues.\u201d When a clue appears in the input-output examples (e.g., the output is a permutation of the input), it reweights the probabilities of productions in a probabilistic context free grammar by a learned amount. This work shares the idea of learning to guide the search over program space conditional on input-output examples. One difference is in the domains. Menon et al. (2013) operate on short string manipulation programs, where it is arguably easier to hand-code features to recognize patterns in the input-output examples (e.", "startOffset": 41, "endOffset": 521}, {"referenceID": 16, "context": "The most closely related work is that of Menon et al. (2013), in which a hand-coded set of features of input-output examples are used as \u201cclues.\u201d When a clue appears in the input-output examples (e.g., the output is a permutation of the input), it reweights the probabilities of productions in a probabilistic context free grammar by a learned amount. This work shares the idea of learning to guide the search over program space conditional on input-output examples. One difference is in the domains. Menon et al. (2013) operate on short string manipulation programs, where it is arguably easier to hand-code features to recognize patterns in the input-output examples (e.g., if the outputs are always permutations or substrings of the input). Our work shows that there are strong cues in patterns in input-output examples in the domain of numbers and lists. However, the main difference is the scale. Menon et al. (2013) learns from a small (280 examples), manually-constructed dataset, which limits the capacity of the machine learning model that can be trained.", "startOffset": 41, "endOffset": 922}, {"referenceID": 16, "context": "The most closely related work is that of Menon et al. (2013), in which a hand-coded set of features of input-output examples are used as \u201cclues.\u201d When a clue appears in the input-output examples (e.g., the output is a permutation of the input), it reweights the probabilities of productions in a probabilistic context free grammar by a learned amount. This work shares the idea of learning to guide the search over program space conditional on input-output examples. One difference is in the domains. Menon et al. (2013) operate on short string manipulation programs, where it is arguably easier to hand-code features to recognize patterns in the input-output examples (e.g., if the outputs are always permutations or substrings of the input). Our work shows that there are strong cues in patterns in input-output examples in the domain of numbers and lists. However, the main difference is the scale. Menon et al. (2013) learns from a small (280 examples), manually-constructed dataset, which limits the capacity of the machine learning model that can be trained. Thus, it forces the machine learning component to be relatively simple. Indeed, Menon et al. (2013) use a log-linear model and rely on hand-constructed features.", "startOffset": 41, "endOffset": 1165}, {"referenceID": 17, "context": "Piech et al. (2015) propose to learn joint embeddings of program states and programs to automatically extend teacher feedback to many similar programs in the MOOC setting.", "startOffset": 0, "endOffset": 20}, {"referenceID": 15, "context": "Li et al. (2016) use graph neural networks (GNNs) to predict logical descriptions from program states, focusing on data structure shapes instead of numerical and list data.", "startOffset": 0, "endOffset": 17}, {"referenceID": 0, "context": "Very recently, Alemi et al. (2016) used neural sequence models in tandem with an automated theorem prover.", "startOffset": 15, "endOffset": 35}, {"referenceID": 0, "context": "Very recently, Alemi et al. (2016) used neural sequence models in tandem with an automated theorem prover. Similar to our setup, a neural network component is trained to select premises that the theorem prover can use to prove a theorem. The main differences are in the domains, and that they train on an existing corpus of theorems. More broadly, if we view a DSL as defining a model and search as a form of inference algorithm, then there is a large body of work on using discriminatively-trained models to aid inference in generative models. Examples include Dayan et al. (1995); Kingma & Welling (2013); Shotton et al.", "startOffset": 15, "endOffset": 582}, {"referenceID": 0, "context": "Very recently, Alemi et al. (2016) used neural sequence models in tandem with an automated theorem prover. Similar to our setup, a neural network component is trained to select premises that the theorem prover can use to prove a theorem. The main differences are in the domains, and that they train on an existing corpus of theorems. More broadly, if we view a DSL as defining a model and search as a form of inference algorithm, then there is a large body of work on using discriminatively-trained models to aid inference in generative models. Examples include Dayan et al. (1995); Kingma & Welling (2013); Shotton et al.", "startOffset": 15, "endOffset": 607}, {"referenceID": 0, "context": "Very recently, Alemi et al. (2016) used neural sequence models in tandem with an automated theorem prover. Similar to our setup, a neural network component is trained to select premises that the theorem prover can use to prove a theorem. The main differences are in the domains, and that they train on an existing corpus of theorems. More broadly, if we view a DSL as defining a model and search as a form of inference algorithm, then there is a large body of work on using discriminatively-trained models to aid inference in generative models. Examples include Dayan et al. (1995); Kingma & Welling (2013); Shotton et al. (2013); Stuhlm\u00fcller et al.", "startOffset": 15, "endOffset": 630}, {"referenceID": 0, "context": "Very recently, Alemi et al. (2016) used neural sequence models in tandem with an automated theorem prover. Similar to our setup, a neural network component is trained to select premises that the theorem prover can use to prove a theorem. The main differences are in the domains, and that they train on an existing corpus of theorems. More broadly, if we view a DSL as defining a model and search as a form of inference algorithm, then there is a large body of work on using discriminatively-trained models to aid inference in generative models. Examples include Dayan et al. (1995); Kingma & Welling (2013); Shotton et al. (2013); Stuhlm\u00fcller et al. (2013); Heess et al.", "startOffset": 15, "endOffset": 657}, {"referenceID": 0, "context": "Very recently, Alemi et al. (2016) used neural sequence models in tandem with an automated theorem prover. Similar to our setup, a neural network component is trained to select premises that the theorem prover can use to prove a theorem. The main differences are in the domains, and that they train on an existing corpus of theorems. More broadly, if we view a DSL as defining a model and search as a form of inference algorithm, then there is a large body of work on using discriminatively-trained models to aid inference in generative models. Examples include Dayan et al. (1995); Kingma & Welling (2013); Shotton et al. (2013); Stuhlm\u00fcller et al. (2013); Heess et al. (2013); Jampani et al.", "startOffset": 15, "endOffset": 678}, {"referenceID": 0, "context": "Very recently, Alemi et al. (2016) used neural sequence models in tandem with an automated theorem prover. Similar to our setup, a neural network component is trained to select premises that the theorem prover can use to prove a theorem. The main differences are in the domains, and that they train on an existing corpus of theorems. More broadly, if we view a DSL as defining a model and search as a form of inference algorithm, then there is a large body of work on using discriminatively-trained models to aid inference in generative models. Examples include Dayan et al. (1995); Kingma & Welling (2013); Shotton et al. (2013); Stuhlm\u00fcller et al. (2013); Heess et al. (2013); Jampani et al. (2015).", "startOffset": 15, "endOffset": 701}], "year": 2016, "abstractText": "We develop a first line of attack for solving programming competition-style problems from input-output examples using deep learning. The approach is to train a neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network\u2019s predictions to augment search techniques from the programming languages community, including enumerative search and an SMT-based solver. Empirically, we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent Neural Network approach, and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites.", "creator": "LaTeX with hyperref package"}}}