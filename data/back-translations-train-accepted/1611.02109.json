{"id": "1611.02109", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": "Differentiable Programs with Neural Libraries", "abstract": "We introduce and develop solutions for the problem of Lifelong Perceptual Programming By Example (LPPBE). The problem is to induce a series of programs that require understanding perceptual data like images or text. LPPBE systems learn from weak supervision (input-output examples) and incrementally construct a shared library of components that grows and improves as more tasks are solved. Methodologically, we extend differentiable interpreters to operate on perceptual data and to share components across tasks. Empirically we show that this leads to a lifelong learning system that transfers knowledge to new tasks more effectively than baselines, and the performance on earlier tasks continues to improve even as the system learns on new, different tasks.", "histories": [["v1", "Mon, 7 Nov 2016 15:25:53 GMT  (1704kb,D)", "http://arxiv.org/abs/1611.02109v1", "Submitted to ICLR 2017"], ["v2", "Thu, 2 Mar 2017 13:34:48 GMT  (2397kb,D)", "http://arxiv.org/abs/1611.02109v2", null]], "COMMENTS": "Submitted to ICLR 2017", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["alexander l gaunt", "marc brockschmidt", "nate kushman", "daniel tarlow"], "accepted": true, "id": "1611.02109"}, "pdf": {"name": "1611.02109.pdf", "metadata": {"source": "CRF", "title": "LIFELONG PERCEPTUAL PROGRAMMING BY EXAMPLE", "authors": ["Alexander L. Gaunt", "Marc Brockschmidt", "Nate Kushman", "Daniel Tarlow"], "emails": [], "sections": [{"heading": "1 INTRODUCTION", "text": "In fact, most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to dance, to"}, {"heading": "2 PERCEPTUAL PROGRAMMING BY EXAMPLE", "text": "We briefly look at the language TERPRET (Gaunt et al., 2016) to construct differentiated interpreters. To address LPPBE, we develop NEURAL TERPRET, an extension to support lifelong learning, perception data types and classifiers of neural networks. We also define our tasks."}, {"heading": "2.1 TERPRET", "text": "TERPRET programs describe differentiable interpreters by defining the relationship between inputs and outputs through a series of obscure parameters that define an executable program, and Vars that store intermediate results. TERPRET requires all of these variables to be finite integers. To learn by descending gradients, the model is differentiated by a compilation step that highlights relationships between integers specified by the TERPRET code to relationships between boundary distributions over integers in finite ranges. In this compilation process, there are two key operations: \u2022 Function Application. The z.set to (foo (x, y) statement is translated into \u00b5zi = \u2211 jk Iijk\u00b5 x jk\u00b5 y k, where \u00b5a represents the boundary distribution for variable a and I is an indicator sor 1 [i = foo (j, k)]. This approach extends to all functions that map arbitrarily many integer arguments to an integer output."}, {"heading": "2.2 NEURAL TERPRET", "text": "To deal with perceptual data, we relax the restriction that all variables must be finite integers. We introduce a new type of tensor whose dimensions are fixed on declaration and which is suitable for storing perceptual data. In addition, we introduce learnable functions that can process vector variables. A learnable function is declared using @ Learn ([d1,.., dD], dout, hidden quantities = ['1,.,' L]), with the first component specifying the dimensions d1,., dD of the input (which can be finite integers or tensors) and the second specifying the dimension of the output. NTPT compiles such functions to a fully connected upstream neural network whose layout can be controlled by the hid-size component, which specifies the number of inputs (which can be finite integers or tensors) and the second dimension of the output."}, {"heading": "2.3 TASKS", "text": "To demonstrate the benefits of our approach to combining neural networks with a program-like architecture, we will consider three toy scenarios consisting of several related tasks presented in Figure 2.ADD2X2: The first scenario in Figure 2 (a) uses a 2 x 2 grid of MNIST digits. We will set 4 tasks based on this grid: Calculate the sum of the digits in the (1) top line, (2) left column, (3) bottom line, (4) right column. All tasks require a classification of the MNIST digits, but require different programs to calculate the result. As training examples, we will only provide a grid and the resulting sum. Therefore, we will never directly label a MNIST digit with its class.APPLY2X2 scenario: The second scenario in Figure 2 (b) presents a 2 x 2 grid of handwritten arithmetic operators."}, {"heading": "3 MODELS", "text": "We design an NTPT model for each of the three scenarios outlined above. Knowledge transfer is achieved by defining a library of two neural networks that are shared for all tasks and scenarios. Training on each task should produce a task-specific source code solution (from the ground up) and improve the overall usefulness of the shared networks. Below, we outline the details of the specific models for each scenario along with basic models."}, {"heading": "3.1 SHARED COMPONENTS", "text": "We refer to the two networks in the shared library as net 0 and net 1. Both networks have similar architectures: They take a 28 x 28 cm monochrome image as input and pass it sequentially through two completely connected layers, each with 256 neurons and ReLU activations. The last hidden vector is passed through a fully connected layer and a softmax to generate a 10-dimensional output (net 0) or 4-dimensional output (net 1), which is fed to the differentiable interpreter. Note that the output sizes are chosen so that they correspond to the number of classes of MNIST digits and computational operators. If we create an interpreter model that contains N networks, and a part of the interpreter uses a parameter network selection = param (N) to decide which network to apply, then the system effectively sees a large network that after the training does not have meaningful access to the networked components, so that we cannot separate the networked component to avoid this first task."}, {"heading": "3.2 ADD2X2 MODEL", "text": "For the ADD2X2 scenario, we build a model that is capable of writing short linear algorithms with up to 4 statements; the model consists of a read head containing the net 0 and the net 1 (except for the very first task, which only has access to the net 0, as discussed above), which is connected to a series of registers, each able to hold integers in the range of 0...., M, where M = 18. The head is initialized by reading the upper left cell of the 2 x 2 grid, and at each step of the program, a statement from the following statement set of instructions can be executed: \u2022 NOOP: a trivial statement without operation 1Note that our toy system ignores the operator's priority and performs operations from left to right - i.e. the sequence in the text is executed as (d1 op1 d2) opd3)."}, {"heading": "3.3 APPLY2X2 MODEL", "text": "We adjust the ADD2X2 model to the APPLY2X2 scenario by swapping three fixed registers with the auxiliary integers, each delivered with 2 x 2 operator networks [see Fig. 2 (b)]. In addition, we swap the ADD (\u00b7, \u00b7) statement for APPLY (\u00b7, \u00b7, \u00b7). The effect of APPLY (a, b, op) is to interpret the integer stored in op as an arithmetic operator and calculate an operator. All operations are executed modulo (M + 1) and the division by zero results in M. In total, this model frees up a program space of the size \u0445 1012 syntactically different programs. Baseline Additional task-specific networks are added to the baseline of the ADD2X2 model. These networks link embeddings from the common networks with uniform representations of the auxiliary integers before they are guided through 3 hidden layers of 128 neurons."}, {"heading": "3.4 MATH MODEL", "text": "A natural solution for executing the expression on the tape is to create a loop with a body that alternately moves the head and applies the operators [see fig. 4 (b)]. This loopy solution has the advantage of generalizing the handling of arbitrary length arithmetic expressions. 3Using a validation dataset, we determine that a deeper task-specific network is required to achieve good performance in the APPLY2X2 tasks. Since the perceptive part of this task is very simple, we believe that the additional capacity is required to handle the nonlinear arithmetic operations.Figure 4 (a) shows the basic architecture of the interpreter used in this scenario. We provide a set of blocks, each containing the MOVE or APPLY statement. A MOVE statement increases the position of the header and loads the new symbol into a specific block head, defining it as a network block block, either by specifying a register 1 or by specifying a register 1."}, {"heading": "4 EXPERIMENTS", "text": "In this section, we report on results from three groups of experiments: We first show that weak-supervision learning is possible in the proposed settings by examining a single task, and then we demonstrate that NTPT has significant advantages over the base model when learning from a sequence of related tasks. Finally, we demonstrate the generalization properties of learned NTPT models provided by the source code representation. 4.1 WEAK SUPERVISIONFig. 5 shows a comparison of the test accuracy of our weakly supervised NTPT model at the first ADD2X2 task (top row summary) with two alternative models: (1) a highly supervised model (a classifier (identical to net 0) trained directly on described digits), and (2) the purely neural baseline described above. In each case, we report the accuracy of the task on a given test set, with only two sets of data, each of which we extract 10k and each model using only two fictional components."}, {"heading": "4.2 LIFELONG LEARNING", "text": "In order to explore the transfer of knowledge between the tasks we have outlined at the top of a probability distribution across all 8 tasks in the ADD2X2 and APPLY2X2 in the period following the plan, the identity of the task is marked with each batch in such a way that the correct NTPT model or the specific base network can be chosen. The learning rate for the shared networks and task-specific components is coordinated separately, and no reason for tolerance is given."}, {"heading": "5 RELATED WORK", "text": "In fact, it is so that most of them are able to survive themselves by taking themselves to task. (...) In fact, it is so that they are able to survive themselves. (...) It is so that they are able to survive themselves. (...) It is so that they are able to survive themselves. (...) It is so that they are able to survive themselves. (...) It is so that they are able to survive themselves. (...) It is as if they are able to survive themselves. (...). (...). \"(...).\" (...). \"(...).\" It is so. \"(...).\" It is so. \"(...).\" (...). \"(...).\" (...). \"(...).\" It is so. \"(...).\" It is. (...). \"It is. (...). (...). (...).\" It is. (...). (...). \"It is. (...).\" It is. (...). \"It is. (...).\" It is. (...). \"It is. (...).\" It is. (...). \"It is.\" It is. (...). (...). (...). (...). It is. (...). (...). It is. It is. (. (...). (...). (...). (...). (...). It is. (...). It is. (...). It is. (...). It is. (. (...). (...). (...). It is. It is. (...). It is. (...). It is. (. (). It is. (). It is. (. (). It is. (. It is. (). It is. (). (). It is. (). It is. (. (). (). It is. It is. (). It is. (. (). It is. (). It is. (. (). (). It is. (. (). It is. (). (. (). It is. (). It is. It is. ()."}, {"heading": "6 DISCUSSION", "text": "We have presented NEURAL TERPRET, a framework for building consistently feasible models that structure their solution as a library of functions presented as source code or neural networks. Experimental results show that these models can be successfully trained in the context of lifelong learning, and they may be resistant to catastrophic forgetting; in fact, they show that even after cases of previous tasks that are no longer submitted to the model, performance still improves. Second, learning neural network models within differentiated interpreters has several advantages. First, learning programs impose a bias that favors learning models that exhibit strong generalization, as illustrated by much work on program-like neural networks. Second, the source code components are interpretable by humans, which describes the shape of the problem through the source code structure. Third, source code components can be verified, and the neural network components can be verified with specific instances that we expect to perform."}], "references": [{"title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems", "author": ["Mart\u0131n Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": "arXiv preprint arXiv:1603.04467,", "citeRegEx": "Abadi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Abadi et al\\.", "year": 2016}, {"title": "Learning efficient algorithms with hierarchical attentive memory", "author": ["Marcin Andrychowicz", "Karol Kurach"], "venue": "arXiv preprint arXiv:1602.03218,", "citeRegEx": "Andrychowicz and Kurach.,? \\Q2016\\E", "shortCiteRegEx": "Andrychowicz and Kurach.", "year": 2016}, {"title": "Curriculum learning", "author": ["Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Ronan Collobert", "Jason Weston"], "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning (ICML),", "citeRegEx": "Bengio et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 2009}, {"title": "Multitask learning", "author": ["Rich Caruana"], "venue": "Machine Learning,", "citeRegEx": "Caruana.,? \\Q1997\\E", "shortCiteRegEx": "Caruana.", "year": 1997}, {"title": "Lifelong learning for sentiment classification", "author": ["Zhiyuan Chen", "Nianzu Ma", "Bing Liu"], "venue": "In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL),", "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Neural functional programming. 2016", "author": ["John K. Feser", "Marc Brockschmidt", "Alexander L. Gaunt", "Daniel Tarlow"], "venue": null, "citeRegEx": "Feser et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Feser et al\\.", "year": 2017}, {"title": "Terpret: A probabilistic programming language for program induction", "author": ["Alexander L. Gaunt", "Marc Brockschmidt", "Rishabh Singh", "Nate Kushman", "Pushmeet Kohli", "Jonathan Taylor", "Daniel Tarlow"], "venue": "CoRR, abs/1608.04428,", "citeRegEx": "Gaunt et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Gaunt et al\\.", "year": 2016}, {"title": "Hybrid computing using a neural network with dynamic external memory", "author": ["Alex Graves", "Greg Wayne", "Malcolm Reynolds", "Tim Harley", "Ivo Danihelka", "Agnieszka GrabskaBarwi\u0144ska", "Sergio G\u00f3mez Colmenarejo", "Edward Grefenstette", "Tiago Ramalho", "John Agapiou"], "venue": null, "citeRegEx": "Graves et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2016}, {"title": "Learning to transduce with unbounded memory", "author": ["Edward Grefenstette", "Karl Moritz Hermann", "Mustafa Suleyman", "Phil Blunsom"], "venue": "In Proceedings of the 28th Conference on Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Grefenstette et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Grefenstette et al\\.", "year": 2015}, {"title": "Inferring algorithmic patterns with stack-augmented recurrent nets", "author": ["Armand Joulin", "Tomas Mikolov"], "venue": "In Advances in Neural Information Processing Systems 2, [NIPS Conference,", "citeRegEx": "Joulin and Mikolov.,? \\Q1989\\E", "shortCiteRegEx": "Joulin and Mikolov.", "year": 1989}, {"title": "Neural GPUs learn algorithms", "author": ["\u0141ukasz Kaiser", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations (ICLR),", "citeRegEx": "Kaiser and Sutskever.,? \\Q2016\\E", "shortCiteRegEx": "Kaiser and Sutskever.", "year": 2016}, {"title": "Learning task grouping and overlap in multi-task learning", "author": ["Abhishek Kumar", "Hal Daume III"], "venue": "arXiv preprint arXiv:1206.6417,", "citeRegEx": "Kumar and III.,? \\Q2012\\E", "shortCiteRegEx": "Kumar and III.", "year": 2012}, {"title": "Neural random-access machines", "author": ["Karol Kurach", "Marcin Andrychowicz", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations 2016,", "citeRegEx": "Kurach et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kurach et al\\.", "year": 2015}, {"title": "Multi-task sequence to sequence learning", "author": ["Minh-Thang Luong", "Quoc V Le", "Ilya Sutskever", "Oriol Vinyals", "Lukasz Kaiser"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Luong et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Luong et al\\.", "year": 2015}, {"title": "Catastrophic interference in connectionist networks: The sequential learning problem", "author": ["Michael McCloskey", "Neal J Cohen"], "venue": "Psychology of learning and motivation,", "citeRegEx": "McCloskey and Cohen.,? \\Q1989\\E", "shortCiteRegEx": "McCloskey and Cohen.", "year": 1989}, {"title": "Neural programmer: Inducing latent programs with gradient descent", "author": ["Arvind Neelakantan", "Quoc V. Le", "Ilya Sutskever"], "venue": "In Proceedings of the 4th International Conference on Learning Representations", "citeRegEx": "Neelakantan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2016}, {"title": "A survey on transfer learning", "author": ["Sinno Jialin Pan", "Qiang Yang"], "venue": "IEEE Transactions on knowledge and data engineering,", "citeRegEx": "Pan and Yang.,? \\Q2010\\E", "shortCiteRegEx": "Pan and Yang.", "year": 2010}, {"title": "Actor-mimic: Deep multitask and transfer reinforcement learning", "author": ["Emilio Parisotto", "Lei Jimmy Ba", "Ruslan Salakhutdinov"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "Parisotto et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Parisotto et al\\.", "year": 2015}, {"title": "Connectionist models of recognition memory: constraints imposed by learning and forgetting functions", "author": ["Roger Ratcliff"], "venue": "Psychological review,", "citeRegEx": "Ratcliff.,? \\Q1990\\E", "shortCiteRegEx": "Ratcliff.", "year": 1990}, {"title": "Programming with a differentiable forth interpreter", "author": ["Sebastian Riedel", "Matko Bosnjak", "Tim Rockt\u00e4schel"], "venue": "CoRR, abs/1605.06640,", "citeRegEx": "Riedel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Riedel et al\\.", "year": 2016}, {"title": "Catastrophic forgetting, rehearsal and pseudorehearsal", "author": ["Anthony Robins"], "venue": "Connection Science,", "citeRegEx": "Robins.,? \\Q1995\\E", "shortCiteRegEx": "Robins.", "year": 1995}, {"title": "Ella: An efficient lifelong learning algorithm", "author": ["Paul Ruvolo", "Eric Eaton"], "venue": "ICML (1),", "citeRegEx": "Ruvolo and Eaton.,? \\Q2013\\E", "shortCiteRegEx": "Ruvolo and Eaton.", "year": 2013}, {"title": "Knowledge-based cascade-correlation: Using knowledge to speed learning", "author": ["Thomas R Shultz", "Francois Rivest"], "venue": "Connection Science,", "citeRegEx": "Shultz and Rivest.,? \\Q2001\\E", "shortCiteRegEx": "Shultz and Rivest.", "year": 2001}, {"title": "The task rehearsal method of life-long learning: Overcoming impoverished data", "author": ["Daniel L Silver", "Robert E Mercer"], "venue": "In Conference of the Canadian Society for Computational Studies of Intelligence,", "citeRegEx": "Silver and Mercer.,? \\Q2002\\E", "shortCiteRegEx": "Silver and Mercer.", "year": 2002}, {"title": "Machine life-long learning with csmtl networks", "author": ["Daniel L Silver", "Ryan Poirier"], "venue": "In AAAI,", "citeRegEx": "Silver and Poirier.,? \\Q2006\\E", "shortCiteRegEx": "Silver and Poirier.", "year": 2006}, {"title": "Lifelong machine learning systems: Beyond learning algorithms", "author": ["Daniel L Silver", "Qiang Yang", "Lianghao Li"], "venue": "In AAAI Spring Symposium: Lifelong Machine Learning,", "citeRegEx": "Silver et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2013}, {"title": "A lifelong learning perspective for mobile robot control", "author": ["Sebastian Thrun"], "venue": "In Proceedings of IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),", "citeRegEx": "Thrun.,? \\Q1994\\E", "shortCiteRegEx": "Thrun.", "year": 1994}, {"title": "Discovering structure in multiple learning tasks: The TC algorithm", "author": ["Sebastian Thrun", "Joseph O\u2019Sullivan"], "venue": "In Machine Learning, Proceedings of the Thirteenth International Conference (ICML),", "citeRegEx": "Thrun and O.Sullivan.,? \\Q1996\\E", "shortCiteRegEx": "Thrun and O.Sullivan.", "year": 1996}, {"title": "Learning simple algorithms from examples", "author": ["Wojciech Zaremba", "Tomas Mikolov", "Armand Joulin", "Rob Fergus"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "citeRegEx": "Zaremba et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zaremba et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 3, "context": "However, despite some work showing promise towards multitask learning (training on many tasks at once) and transfer learning (using source tasks to improve learning in a later target task) (Caruana, 1997; Luong et al., 2015; Parisotto et al., 2015; Rusu et al., 2016), most successes of neural networks today come from training a single network on a single task, indicating that this goal is highly challenging to achieve.", "startOffset": 189, "endOffset": 267}, {"referenceID": 13, "context": "However, despite some work showing promise towards multitask learning (training on many tasks at once) and transfer learning (using source tasks to improve learning in a later target task) (Caruana, 1997; Luong et al., 2015; Parisotto et al., 2015; Rusu et al., 2016), most successes of neural networks today come from training a single network on a single task, indicating that this goal is highly challenging to achieve.", "startOffset": 189, "endOffset": 267}, {"referenceID": 17, "context": "However, despite some work showing promise towards multitask learning (training on many tasks at once) and transfer learning (using source tasks to improve learning in a later target task) (Caruana, 1997; Luong et al., 2015; Parisotto et al., 2015; Rusu et al., 2016), most successes of neural networks today come from training a single network on a single task, indicating that this goal is highly challenging to achieve.", "startOffset": 189, "endOffset": 267}, {"referenceID": 6, "context": "integers) from input-output examples (Gaunt et al., 2016; Riedel et al., 2016; Bunel et al., 2016).", "startOffset": 37, "endOffset": 98}, {"referenceID": 19, "context": "integers) from input-output examples (Gaunt et al., 2016; Riedel et al., 2016; Bunel et al., 2016).", "startOffset": 37, "endOffset": 98}, {"referenceID": 18, "context": "The approach is resilient to catastrophic forgetting (McCloskey & Cohen, 1989; Ratcliff, 1990); on the contrary, results show that performance continues to improve on earlier tasks even when only training on later tasks.", "startOffset": 53, "endOffset": 94}, {"referenceID": 6, "context": "We briefly review the TERPRET language (Gaunt et al., 2016) for constructing differentiable interpreters.", "startOffset": 39, "endOffset": 59}, {"referenceID": 6, "context": "More complex statements follow a similar pattern, with details given in Gaunt et al. (2016).", "startOffset": 72, "endOffset": 92}, {"referenceID": 0, "context": "This compilation process yields a TensorFlow Abadi et al. (2016) computation graph containing many of these two operations, which can then be trained using standard methods.", "startOffset": 45, "endOffset": 65}, {"referenceID": 5, "context": "We follow Feser et al. (2016) and allow each line to store its result in a separate immutable register.", "startOffset": 10, "endOffset": 30}, {"referenceID": 26, "context": "We operate in the paradigm of Lifelong Machine Learning (LML) (Thrun, 1994; 1995; Thrun & O\u2019Sullivan, 1996; Silver et al., 2013; Chen et al., 2015), where a", "startOffset": 62, "endOffset": 147}, {"referenceID": 25, "context": "We operate in the paradigm of Lifelong Machine Learning (LML) (Thrun, 1994; 1995; Thrun & O\u2019Sullivan, 1996; Silver et al., 2013; Chen et al., 2015), where a", "startOffset": 62, "endOffset": 147}, {"referenceID": 4, "context": "We operate in the paradigm of Lifelong Machine Learning (LML) (Thrun, 1994; 1995; Thrun & O\u2019Sullivan, 1996; Silver et al., 2013; Chen et al., 2015), where a", "startOffset": 62, "endOffset": 147}, {"referenceID": 3, "context": "This is distinct from related paradigms of multitask learning (presentation of a finite set of tasks simultenaously rather than in sequence (Caruana, 1997; Kumar & Daume III, 2012; Luong et al., 2015; Rusu et al., 2016)), transfer learning (transfer of knowledge from a source to target domain without notion of knowledge retention (Pan & Yang, 2010)), and curriculum learning (training a single model for a single task of varying difficulty (Bengio et al.", "startOffset": 140, "endOffset": 219}, {"referenceID": 13, "context": "This is distinct from related paradigms of multitask learning (presentation of a finite set of tasks simultenaously rather than in sequence (Caruana, 1997; Kumar & Daume III, 2012; Luong et al., 2015; Rusu et al., 2016)), transfer learning (transfer of knowledge from a source to target domain without notion of knowledge retention (Pan & Yang, 2010)), and curriculum learning (training a single model for a single task of varying difficulty (Bengio et al.", "startOffset": 140, "endOffset": 219}, {"referenceID": 2, "context": ", 2016)), transfer learning (transfer of knowledge from a source to target domain without notion of knowledge retention (Pan & Yang, 2010)), and curriculum learning (training a single model for a single task of varying difficulty (Bengio et al., 2009)).", "startOffset": 230, "endOffset": 251}, {"referenceID": 20, "context": "This knowledge base allows either (1) rehearsal on historical examples (Robins, 1995), (2) rehearsal on virtual examples generated by the frozen networks (Silver & Mercer, 2002; Silver & Poirier, 2006) or (3) creation of new networks containing frozen sub networks from the historical tasks (Rusu et al.", "startOffset": 71, "endOffset": 85}, {"referenceID": 2, "context": ", 2016)), transfer learning (transfer of knowledge from a source to target domain without notion of knowledge retention (Pan & Yang, 2010)), and curriculum learning (training a single model for a single task of varying difficulty (Bengio et al., 2009)). The challenge for LML with neural networks is the problem of catastrophic forgetting: if the distribution of examples changes during training, then neural networks are prone to forget knowledge gathered from early examples. Solutions to this problem involve instantiating a knowledge repository (KR) either directly storing data from earlier tasks or storing (sub)networks trained on the earlier tasks with their weights frozen. This knowledge base allows either (1) rehearsal on historical examples (Robins, 1995), (2) rehearsal on virtual examples generated by the frozen networks (Silver & Mercer, 2002; Silver & Poirier, 2006) or (3) creation of new networks containing frozen sub networks from the historical tasks (Rusu et al., 2016; Shultz & Rivest, 2001) To frame our approach in these terms, our KR contains partially-trained neural network classifiers which we call from learned source code. Crucially, we never freeze the weights of the networks in the KR: all parts of the KR can be updated during the training of all tasks - this allows us to improve performance on earlier tasks by continuing training on later tasks (so-called reverse transfer). Reverse transfer has been demonstrated previously in systems which assume that each task can be solved by a model parameterized by an (uninterpretable) task-specific linear combination of shared basis weights (Ruvolo & Eaton, 2013). The representation of task-specific knowledge as source code, learning from weak supervision, and shared knowledge as a deep neural networks distinguishes this work from the linear model used in Ruvolo & Eaton (2013).", "startOffset": 231, "endOffset": 1865}, {"referenceID": 8, "context": "Recently, extensions of neural networks with primitives such as memory and discrete computation units have been studied to learn algorithms from inputoutput data (Graves et al., 2014; Weston et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2015; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Bunel et al., 2016; Andrychowicz & Kurach, 2016; Zaremba et al., 2016; Graves et al., 2016; Riedel et al., 2016; Gaunt et al., 2016; Feser et al., 2016).", "startOffset": 162, "endOffset": 480}, {"referenceID": 12, "context": "Recently, extensions of neural networks with primitives such as memory and discrete computation units have been studied to learn algorithms from inputoutput data (Graves et al., 2014; Weston et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2015; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Bunel et al., 2016; Andrychowicz & Kurach, 2016; Zaremba et al., 2016; Graves et al., 2016; Riedel et al., 2016; Gaunt et al., 2016; Feser et al., 2016).", "startOffset": 162, "endOffset": 480}, {"referenceID": 28, "context": "Recently, extensions of neural networks with primitives such as memory and discrete computation units have been studied to learn algorithms from inputoutput data (Graves et al., 2014; Weston et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2015; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Bunel et al., 2016; Andrychowicz & Kurach, 2016; Zaremba et al., 2016; Graves et al., 2016; Riedel et al., 2016; Gaunt et al., 2016; Feser et al., 2016).", "startOffset": 162, "endOffset": 480}, {"referenceID": 7, "context": "Recently, extensions of neural networks with primitives such as memory and discrete computation units have been studied to learn algorithms from inputoutput data (Graves et al., 2014; Weston et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2015; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Bunel et al., 2016; Andrychowicz & Kurach, 2016; Zaremba et al., 2016; Graves et al., 2016; Riedel et al., 2016; Gaunt et al., 2016; Feser et al., 2016).", "startOffset": 162, "endOffset": 480}, {"referenceID": 19, "context": "Recently, extensions of neural networks with primitives such as memory and discrete computation units have been studied to learn algorithms from inputoutput data (Graves et al., 2014; Weston et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2015; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Bunel et al., 2016; Andrychowicz & Kurach, 2016; Zaremba et al., 2016; Graves et al., 2016; Riedel et al., 2016; Gaunt et al., 2016; Feser et al., 2016).", "startOffset": 162, "endOffset": 480}, {"referenceID": 6, "context": "Recently, extensions of neural networks with primitives such as memory and discrete computation units have been studied to learn algorithms from inputoutput data (Graves et al., 2014; Weston et al., 2014; Joulin & Mikolov, 2015; Grefenstette et al., 2015; Kurach et al., 2015; Kaiser & Sutskever, 2016; Reed & de Freitas, 2016; Bunel et al., 2016; Andrychowicz & Kurach, 2016; Zaremba et al., 2016; Graves et al., 2016; Riedel et al., 2016; Gaunt et al., 2016; Feser et al., 2016).", "startOffset": 162, "endOffset": 480}, {"referenceID": 7, "context": "With the exception of Reed & de Freitas (2016) and (Graves et al., 2016), the methods above operate on inputs that are (arrays of) integers.", "startOffset": 51, "endOffset": 72}, {"referenceID": 5, "context": ", 2016; Feser et al., 2016). Whereas many of these works use a neural network controller managing a differentiable computer architecture, we flip this relationship. The controller in our approach is a differentiable interpreter that is expressible as source code and can make calls to neural network components. With the exception of Reed & de Freitas (2016) and (Graves et al.", "startOffset": 8, "endOffset": 359}, {"referenceID": 5, "context": ", 2016; Feser et al., 2016). Whereas many of these works use a neural network controller managing a differentiable computer architecture, we flip this relationship. The controller in our approach is a differentiable interpreter that is expressible as source code and can make calls to neural network components. With the exception of Reed & de Freitas (2016) and (Graves et al., 2016), the methods above operate on inputs that are (arrays of) integers. In Reed & de Freitas (2016), this comes at the price of extremely strong supervision, where the learner is shown all intermediate steps to solving a problem; our learner only observes input and output examples.", "startOffset": 8, "endOffset": 481}, {"referenceID": 5, "context": ", 2016; Feser et al., 2016). Whereas many of these works use a neural network controller managing a differentiable computer architecture, we flip this relationship. The controller in our approach is a differentiable interpreter that is expressible as source code and can make calls to neural network components. With the exception of Reed & de Freitas (2016) and (Graves et al., 2016), the methods above operate on inputs that are (arrays of) integers. In Reed & de Freitas (2016), this comes at the price of extremely strong supervision, where the learner is shown all intermediate steps to solving a problem; our learner only observes input and output examples. Reed & de Freitas (2016) also show the performance of their system in a multitask setting, however, in some cases additional tasks harm performance of the model and they freeze parts of their model when adding to their library of functions.", "startOffset": 8, "endOffset": 689}, {"referenceID": 5, "context": ", 2016; Feser et al., 2016). Whereas many of these works use a neural network controller managing a differentiable computer architecture, we flip this relationship. The controller in our approach is a differentiable interpreter that is expressible as source code and can make calls to neural network components. With the exception of Reed & de Freitas (2016) and (Graves et al., 2016), the methods above operate on inputs that are (arrays of) integers. In Reed & de Freitas (2016), this comes at the price of extremely strong supervision, where the learner is shown all intermediate steps to solving a problem; our learner only observes input and output examples. Reed & de Freitas (2016) also show the performance of their system in a multitask setting, however, in some cases additional tasks harm performance of the model and they freeze parts of their model when adding to their library of functions. Only Bunel et al. (2016), Riedel et al.", "startOffset": 8, "endOffset": 930}, {"referenceID": 5, "context": ", 2016; Feser et al., 2016). Whereas many of these works use a neural network controller managing a differentiable computer architecture, we flip this relationship. The controller in our approach is a differentiable interpreter that is expressible as source code and can make calls to neural network components. With the exception of Reed & de Freitas (2016) and (Graves et al., 2016), the methods above operate on inputs that are (arrays of) integers. In Reed & de Freitas (2016), this comes at the price of extremely strong supervision, where the learner is shown all intermediate steps to solving a problem; our learner only observes input and output examples. Reed & de Freitas (2016) also show the performance of their system in a multitask setting, however, in some cases additional tasks harm performance of the model and they freeze parts of their model when adding to their library of functions. Only Bunel et al. (2016), Riedel et al. (2016) and Gaunt et al.", "startOffset": 8, "endOffset": 952}, {"referenceID": 5, "context": ", 2016; Feser et al., 2016). Whereas many of these works use a neural network controller managing a differentiable computer architecture, we flip this relationship. The controller in our approach is a differentiable interpreter that is expressible as source code and can make calls to neural network components. With the exception of Reed & de Freitas (2016) and (Graves et al., 2016), the methods above operate on inputs that are (arrays of) integers. In Reed & de Freitas (2016), this comes at the price of extremely strong supervision, where the learner is shown all intermediate steps to solving a problem; our learner only observes input and output examples. Reed & de Freitas (2016) also show the performance of their system in a multitask setting, however, in some cases additional tasks harm performance of the model and they freeze parts of their model when adding to their library of functions. Only Bunel et al. (2016), Riedel et al. (2016) and Gaunt et al. (2016) aim to consume and produce source code that can be provided by a human (e.", "startOffset": 8, "endOffset": 976}], "year": 2017, "abstractText": "We introduce and develop solutions for the problem of Lifelong Perceptual Programming By Example (LPPBE). The problem is to induce a series of programs that require understanding perceptual data like images or text. LPPBE systems learn from weak supervision (input-output examples) and incrementally construct a shared library of components that grows and improves as more tasks are solved. Methodologically, we extend differentiable interpreters to operate on perceptual data and to share components across tasks. Empirically we show that this leads to a lifelong learning system that transfers knowledge to new tasks more effectively than baselines, and the performance on earlier tasks continues to improve even as the system learns on new, different tasks.", "creator": "LaTeX with hyperref package"}}}