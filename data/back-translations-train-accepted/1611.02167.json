{"id": "1611.02167", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": "Designing Neural Network Architectures using Reinforcement Learning", "abstract": "At present, designing convolutional neural network (CNN) architectures requires both human expertise and labor. New architectures are handcrafted by careful experimentation or modified from a handful of existing networks. We propose a meta-modelling approach based on reinforcement learning to automatically generate high-performing CNN architectures for a given learning task. The learning agent is trained to sequentially choose CNN layers using Q-learning with an $\\epsilon$-greedy exploration strategy and experience replay. The agent explores a large but finite space of possible architectures and iteratively discovers designs with improved performance on the learning task. On image classification benchmarks, the agent-designed networks (consisting of only standard convolution, pooling, and fully-connected layers) beat existing networks designed with the same layer types and are competitive against the state-of-the-art methods that use more complex layer types. We also outperform existing network design meta-modelling approaches on image classification.", "histories": [["v1", "Mon, 7 Nov 2016 16:49:43 GMT  (3590kb,D)", "http://arxiv.org/abs/1611.02167v1", null], ["v2", "Wed, 30 Nov 2016 20:26:41 GMT  (3711kb,D)", "http://arxiv.org/abs/1611.02167v2", null], ["v3", "Wed, 22 Mar 2017 20:08:30 GMT  (3721kb,D)", "http://arxiv.org/abs/1611.02167v3", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["bowen baker", "otkrist gupta", "nikhil naik", "ramesh raskar"], "accepted": true, "id": "1611.02167"}, "pdf": {"name": "1611.02167.pdf", "metadata": {"source": "CRF", "title": "DESIGNING NEURAL NETWORK ARCHITECTURES", "authors": ["REINFORCEMENT LEARNING", "Bowen Baker", "Otkrist Gupta", "Nikhil Naik", "Ramesh Raskar"], "emails": ["raskar}@mit.edu"], "sections": [{"heading": "1 INTRODUCTION", "text": "A typical CNN architecture consists of multiple convolution, pooling and fully connected layers. While constructing a CNN, a network designer must make numerous design decisions: the number of layers of each type, the arrangement of layers and the design parameters for each layer, e.g. the receptive field size, step and number of receptive fields for a convolution layer. The number of possible choices makes the design space of CNN architectures extremely large and hence, unfeasible for an exhaustive manual search. While there has been some work (Pinto et al., 2009; Bergstra et al., 2013; Domhan et al., 2015) on automated or computer-assisted neural network design, new CNN architectures are primarily developed by researchers."}, {"heading": "2 RELATED WORK", "text": "The development of neural network architectures: Research on the automation of neural network design dates back to the 1980s, when genetic algorithm-based approaches were proposed to find both architectures and weights (Schaffer et al., 1992), but to the best of their knowledge, networks designed with genetic algorithms, such as those generated with the NEAT algorithm (Stanley & Miikkulainen, 2002), were unable to match the performance of handmade networks on standard benchmarks (Verbancsics & Harguess, 2013); other biologically inspired ideas were also explored; motivated by screening methods in genetics, Pinto et al al al. (2009) a high-level network selection approach was proposed, in which they randomly selected thousands of architectures and selected promising ones for further training."}, {"heading": "3 BACKGROUND", "text": "Our method is based on Q-Learning, a kind of enhancement of learning. We will now summarize the theoretical formulation of Q-Learning as applied to our problem. Consider the task of teaching an agent in order to find optimal ways as a Markov decision-making process (MDP) in a finite horizon environment. Restricting the environment to finite horizons ensures that the agent will deterrently forego a finite number of time steps. Furthermore, we limit the environment to a discrete and finite state space S as well as to a scope of action U. For each state there is a finite set of measures, U (si), which the agent can select from an environment with stochastic transitions."}, {"heading": "4.1 THE STATE SPACE", "text": "Each state is defined as a tuple of all relevant layer parameters. We allow five different types of layers: folding (C), pooling (P), fully connected (FC), global average pooling (GAP), and softmax (SM), although the general method is not limited to this sentence. Table 1 shows the relevant parameters for each layer type and also the discretization we have chosen for each parameter. Each layer has a maximum layer depth (represented as layer 1, 2,... in Figure 2). Adding layer depth to the state space allows us to restrict the action space so that the state diagram is directed and acyclic (DAG) and also allows us to specify a maximum number of layers that the agent can select before finishing. Each layer type also has a parameter called representation size (R-size) that compresses the constellation networks progressively and compresses the original representation as the signal."}, {"heading": "4.2 THE ACTION SPACE", "text": "We restrict the agent from taking certain actions in order to both limit the state scope of action and make learning comprehensible. First, we allow the agent to terminate a path at any point, i.e. he can select a termination state from any non-termination state. Furthermore, we only allow transitions for a state with layer depth i to a state with layer depth i + 1, which ensures that there are no loops in the graphics. This restriction ensures that the state action graph is always a DAG. Any state in the maximum layer depth as specified in Table 1 can only transition to a termination layer.Furthermore, we limit the number of fully connected (FC) layers that can be at a maximum of two layers, because a large number of FC layers can lead to learnable parameters. The agent in a state with type FC can switch to another state with type FC and only if the number of consecutive FC states is less than the maximum allowed."}, {"heading": "5 EXPERIMENT DETAILS", "text": "During the model phase, we discussed each network topology with a fast and aggressive training. We created a validity that depends on the training, so that the class distributions are unchangeable."}, {"heading": "6 RESULTS", "text": "This year, it will be able to achieve the objectives I have mentioned, in the way that they are able to achieve their objectives."}, {"heading": "7 CONCLUDING REMARKS", "text": "In this paper, we take a step toward this goal and show that a metamodeling approach, using reinforcement learning, is able to generate custom CNN designs for different image classification tasks. Our MetaQNN networks outperform previous metamodeling methods, as well as handmade networks that use the same layer types. While we report results for image classification problems, our method could be applied to different problem settings, including monitored (e.g. classification, regression) and unattended (e.g. auto encoders). MetaQNN could also support constraint-based network design by optimizing parameters such as size, speed, and accuracy. For example, one could add a threshold in the state action space that prevents the agent from building models that are larger than the desired limit. In addition, one could modify the reward function by selecting QU- and QU- test-phase-Q for a slow-sharpening model."}, {"heading": "ACKNOWLEDGMENTS", "text": "We thank Peter Downs for creating the project website and contributing illustrations. We thank the Center for Bits and Atoms at MIT for their help in providing computer resources. Finally, we thank the members of the Camera Culture Group at MIT Media Lab for their help and support."}, {"heading": "A ALGORITHM", "text": "First, we describe the main components of the MetaQNN algorithm. Algorithm 1 shows the main loop in which the parameter M would determine how many models to execute for a given period of time, and parameter K would determine how often the playback database is used to update Q values for each iteration. TRAIN refers to the training of the specified network and provides validation accuracy. Finally, algorithm 3 implements the update of the Q value in detail in Equation 3, setting the disconnection factor to 1, for an entire state sequence in reverse order. Algorithm 1 Q-learning For CNN Topologies Initialize: Replay Memory Memories Memory Keeping (Q) to an algorithm \u2212 3 implements an entire state sequence in reverse order."}, {"heading": "B REPRESENTATION SIZE BINNING", "text": "As mentioned in Section 4.1 of the main text, we introduce a parameter called representation size, which prevents the agent from taking measures that can reduce the intermediate signal representation to a size that is too small for further processing. However, this process leads to uncertainties in the state transitions, as illustrated in Figure A1, which is handled by the standard Q Learning formula. P (2,2) R size: 18 R size waste bin: 1R size: 9 R size waste bin: 1 (2,2) R size waste bin: 1R size: 14 R size waste bin: 1 (b) state actions: 1 2 pR size waste bin: 1 R size waste bin: 2P (2,2) (c) Figure A1: representation size waste bin: In this figure we show three sample size state transitions. The true representation size (binding size) is contained in the actual state image to show the actual state."}, {"heading": "C MNIST EXPERIMENT", "text": "\"We did not limit the number of consecutive, fully connected layers.\" \"We also did not allow any further combinations of receptive field sizes and increments to be logdistributed between 2 and 3 logdistribution sizes.\" \"We also did not allow any representation sizes for any type of receptive field size and increment to be logdistributed.\" \"We also did not allow any representation sizes for any representation size.\" \"To train each network, we added a dropout layer with a 0.5 drop-out probability after each fully connected layer and any non-linearity.\" \"We will allow each individual layer and any non-linearity as ELU (Clevert al, 2015).\" We added a one-time representation size for each representation size. \"\" We have a drop-out layer with 0.5 probability after each fully connected layer and any non-linearity."}, {"heading": "E TOP TOPOLOGIES SELECTED BY ALGORITHM", "text": "In Tables A2 to A4 we present the five model architectures selected with Q-Learning (129.1) (128.1) (128.1) (128.1) (128.1) (128.1) (128.1) (128.1) (258.1) (258.1) (128.1) (258.3.1) (258.3.1) (258.5.1) (258.5.1) (258.5.1) (258.1) (256.1) (256.1) (256.1) (256.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1) (258.1)"}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "At present, designing convolutional neural network (CNN) architectures requires<lb>both human expertise and labor. New architectures are handcrafted by careful<lb>experimentation or modified from a handful of existing networks. We propose a<lb>meta-modelling approach based on reinforcement learning to automatically gen-<lb>erate high-performing CNN architectures for a given learning task. The learning<lb>agent is trained to sequentially choose CNN layers using Q-learning with an -<lb>greedy exploration strategy and experience replay. The agent explores a large but<lb>finite space of possible architectures and iteratively discovers designs with im-<lb>proved performance on the learning task. On image classification benchmarks,<lb>the agent-designed networks (consisting of only standard convolution, pooling,<lb>and fully-connected layers) beat existing networks designed with the same layer<lb>types and are competitive against the state-of-the-art methods that use more com-<lb>plex layer types. We also outperform existing network design meta-modelling<lb>approaches on image classification.", "creator": "LaTeX with hyperref package"}}}