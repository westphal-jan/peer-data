{"id": "1611.02305", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Nov-2016", "title": "Learning Influence Functions from Incomplete Observations", "abstract": "We study the problem of learning influence functions under incomplete observations of node activations. Incomplete observations are a major concern as most (online and real-world) social networks are not fully observable. We establish both proper and improper PAC learnability of influence functions under randomly missing observations. Proper PAC learnability under the Discrete-Time Linear Threshold (DLT) and Discrete-Time Independent Cascade (DIC) models is established by reducing incomplete observations to complete observations in a modified graph. Our improper PAC learnability result applies for the DLT and DIC models as well as the Continuous-Time Independent Cascade (CIC) model. It is based on a parametrization in terms of reachability features, and also gives rise to an efficient and practical heuristic. Experiments on synthetic and real-world datasets demonstrate the ability of our method to compensate even for a fairly large fraction of missing observations.", "histories": [["v1", "Mon, 7 Nov 2016 21:28:40 GMT  (115kb,D)", "http://arxiv.org/abs/1611.02305v1", "Full version of paper \"Learning Influence Functions from Incomplete Observations\" in NIPS16"]], "COMMENTS": "Full version of paper \"Learning Influence Functions from Incomplete Observations\" in NIPS16", "reviews": [], "SUBJECTS": "cs.SI cs.LG stat.ML", "authors": ["xinran he", "ke xu", "david kempe 0001", "yan liu"], "accepted": true, "id": "1611.02305"}, "pdf": {"name": "1611.02305.pdf", "metadata": {"source": "CRF", "title": "Learning Influence Functions from Incomplete Observations", "authors": ["Xinran He", "Ke Xu", "David Kempe", "Yan Liu"], "emails": ["yanliu.cs}@usc.edu"], "sections": [{"heading": "1 Introduction", "text": "This year it is so far that it will only take one year to move on to the next round."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Models of Diffusion and Incomplete Observations", "text": "The social network is represented as a directed diagram that represents the strength of the user's influence on v. We assume that the graph structure (the edge number E) is known, while the parameters wuv must be learned. Depending on the diffusion model, there are various ways to represent the strength of the influence between individuals. Nodes can be in one of two states, inactive or active. We say that a node is activated when it adopts the opinion / product / behavior under the diffusion process. In this work, we focus on progressive diffusion models, where a node remains active as soon as it activates a set of seed nodes."}, {"heading": "2.2 Objective Functions and Learning Goals", "text": "For two n-dimensional vectors, the function q (seeds) is x, y, the square loss is defined as \"sq (x, y) = 1n \u00b7 | x \u2212 y | 2. We also use this notation when one or both arguments are set: If an argument is a set, we write\" sq \"(A, F (S) = 1n | | F (S) | 2 2.We now formally define the problem of learning influence from incomplete observations. Let P be a distribution over seeds (i.e. a distribution over 2V) and fix a diffusion modelM and parameters that together form a distribution over S."}, {"heading": "3 Proper PAC Learning under Incomplete Observations", "text": "In this area, we are able to remember the basics on which we can rely. (...) In this area, we are able to learn the basics of learning. (...) In this area, we are able to learn the basics of learning. (...) In this area, we are able to learn the basics of learning. (...) In this area, we are able to learn the basics of learning. (...) Our main theoretical results are summarized in Theorem 1 and Theorem 2 Theorem 1. (...) Let us learn the basics of learning under the DIC model, in which all edge activation probabilities are fulfilled. (...) In this area, we are able to research the basics of learning. (...) In this area, we are able to research the basics of learning. (...)"}, {"heading": "4 Efficient Improper Learning Algorithm", "text": "In this section, we develop improper learning algorithms for efficiently influencing functionality. Instead of analyzing the influencing factors based on the edge parameters, we assume the model-free influencing of the functioning of the functioning, which we then present as the sum of the weighted basic functions. (From now on, we focus on the influencing factors of the functioning of a single fixed node v.2 [16] shows that the DLT model can be learned with defined thresholds under complete cascades. We examine the DLT model when the thresholds are uniformally distributed. (Interfering with the functioning of the functioning) Parameterization for all three diffusion models (CIC, DIC and DLT), the diffusion process can be characterized as equivalent to live edge graphs. (Specifically, the results of the [10, 4] states that exist for each instance of the CIC, DIC and DLT models, there is a live channel distribution."}, {"heading": "5 Experiments", "text": "In this section we experimentally evaluate the algorithm from Section 4. Since no other methods explicitly take incomplete observations into account, we compare it with various modern methods for influencing function learning with complete information. Therefore, the main objective of the comparison is to investigate to what extent the effects of missing data can be mitigated by being aware of them. We compare our algorithm with the following approaches: (1) CIC is an approach that corresponds to the parameters of a CIC model and uses the NetRate algorithm [7] with exponential delay distribution. (2) The DIC adapts the activation probabilities of a DIC model using the method in [18]. (3) InfluLearner is the model-free approach proposed by Du et al. in [3] and discussed in Section 4. (4) Logistics uses logistic regression to learn the influencing functions Fu (S) = f (> S \u00b7 cu + b) for each unit, giving cinigical access to each unit (S), whereby an erear regression is an 11."}, {"heading": "5.1 Synthetic cascades", "text": "In fact, it is so that it is about a way and a way in which it is about a way and a way in which it is about the question, in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way and a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way and a way in which it is about a way in which it is about a way"}, {"heading": "5.2 Influence Estimation on real cascades", "text": "We continue to evaluate the performance of our method on the real dataset MemeTracker7 [11]. The dataset consists of the propagation of short text phrases that are referred to as memes, about the publication of blog posts and main stream media news articles between March 2011 and February 2012. Specifically, the dataset contains seven groups of cascades that correspond to the propagation of memes with certain keywords, namely \"apple and jobs,\" \"tsunami earthquake,\" \"William Kate-Marriage,\" \"air strikes,\" \"Egypt\" and \"elections.\" Each cascade group consists of 6The truncation could lead to a distortion of the mean of r. Empirical simulations, however, show that the distortion is negligible (only 0.001 when it is executed = 0.2).7We use the pre-processed version of the dataset set, which is provided by Du et al. [3] and available at http: / ccg.du / gate.gate- 0.000000000000.0000.0000.0000.0000.0000.0000.0000.0000.0000.000.000.00.000.00.000.00.000.00.000.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0"}, {"heading": "6 Model Extensions", "text": "So far, we have assumed that the maintenance rate is the same for all nodes, but our approach can easily be generalized to the case where each node has a different (but known) maintenance rate. (The proofs of all theorems from this section are given in Appendix C.) Theorem 5: Let us know that all edge activation probabilities are satisfactory if each node can be v's maintenance rate. (The proofs of all theorems from this section are in Appendix C.) The class of influence functions within the DIC model, in which all edge activation probabilities are satisfied, is PAC learnable with the example O (r) 2n3m. \u2022 The class of influence functions within the DLT model is such that the edge weights are satisfactory for each edge."}, {"heading": "7 Conclusion and Future Work", "text": "We investigated the problem of learning influence functions under incomplete observations common in real-world applications. We established proper PAC learning of influence functions under two popular diffusion models, the DIC and DLT models. Incompleteness has only a moderate impact on sample complexity, but computational efficiency would require an oracle to efficiently empirically minimize risk. Next, we designed an efficient improper learning algorithm with learning guarantees for the DIC, DLT and CIC models. Our framework is easy to generalize to cope with the non-uniform (but independent) loss of node activations. We also have partial results that theoretically justify the robustness of miscalculations of r (which we have observed experimentally in Section 5)."}, {"heading": "Acknowledgments", "text": "We thank anonymous reviewers for useful feedback. The research was sponsored in part by the NSF research grant IIS-1254206 and by the U.S. Defense Advanced Research Projects Agency (DARPA) under the Social Media in Strategic Communication (SMISC) program, contract number W911NF-12-1-0034. The views and conclusions are those of the authors and should not be interpreted to represent the official policies of the funding agency or the U.S. government."}, {"heading": "A Proofs for Section 3", "text": "For the converted graph G (S) we consider only the influences on the function of these nodes."}, {"heading": "B Proof of Theorem 4", "text": "We will show that for each node we will create a protocol of all n nodes. We will then create a protocol of all n nodes that represents the functional class of all truncated functions. We will replace the functional class of all truncated functions. We will replace the functional class of all truncated functions. We will change the functional class of all truncated functions. We will replace the functional class (M): = ESi \"P, (i) i\" i \"i\" uniform ({\u2212 1,1} M) [sup \"M\" M \"i\" i \"i\" F \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i. \""}, {"heading": "C Proofs for Section 6", "text": "C.1 Evidence of theorem 5Let ri be the retention rate of node i and \u03b5 \"i\" s the desired error guarantee for learning the influence function Fvi. It is directly derivable from the proofs of theorems 1 and 2 that M = maxi (S) 2 \"(n3m).The estimation error for the total influence is sufficient to guarantee that the average influence on the influence possibilities i.\" In view of the non-uniform maintenance rates ri we can opt for non-uniform maintenance rates, so that the example complexity can be minimized. The corresponding optimization problem is the following: Minimize max i1\u03b5. \""}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "We study the problem of learning influence functions under incomplete observations of node<lb>activations. Incomplete observations are a major concern as most (online and real-world) social<lb>networks are not fully observable. We establish both proper and improper PAC learnability<lb>of influence functions under randomly missing observations. Proper PAC learnability under<lb>the Discrete-Time Linear Threshold (DLT) and Discrete-Time Independent Cascade (DIC)<lb>models is established by reducing incomplete observations to complete observations in a modified<lb>graph. Our improper PAC learnability result applies for the DLT and DIC models as well as the<lb>Continuous-Time Independent Cascade (CIC) model. It is based on a parametrization in terms<lb>of reachability features, and also gives rise to an efficient and practical heuristic. Experiments<lb>on synthetic and real-world datasets demonstrate the ability of our method to compensate even<lb>for a fairly large fraction of missing observations.", "creator": "LaTeX with hyperref package"}}}