{"id": "1611.03530", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Nov-2016", "title": "Understanding deep learning requires rethinking generalization", "abstract": "Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training.", "histories": [["v1", "Thu, 10 Nov 2016 22:02:36 GMT  (296kb,D)", "http://arxiv.org/abs/1611.03530v1", null], ["v2", "Sun, 26 Feb 2017 19:36:40 GMT  (308kb,D)", "http://arxiv.org/abs/1611.03530v2", "Published in ICLR 2017"]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["chiyuan zhang", "samy bengio", "moritz hardt", "benjamin recht", "oriol vinyals"], "accepted": true, "id": "1611.03530"}, "pdf": {"name": "1611.03530.pdf", "metadata": {"source": "CRF", "title": "UNDERSTANDING DEEP LEARNING REQUIRES RE- THINKING GENERALIZATION", "authors": ["Chiyuan Zhang", "Samy Bengio"], "emails": ["chiyuan@mit.edu", "bengio@google.com", "mrtz@google.com", "recht@berkeley.edu", "vinyals@google.com"], "sections": [{"heading": "1 INTRODUCTION", "text": "However, some of these models exhibit remarkably low generalization errors, i.e. a difference between \"training errors\" and \"test errors.\" At the same time, it is certainly easy to develop natural model architectures that generalize poorly, so what distinguishes neural networks that generalize well from those that do not? A satisfactory answer to this question would not only help to make neural networks more interpretable, but could also lead to more principled and reliable model architecture. To answer such a question, statistical learning theory has proposed a number of different measures of complexity that are capable of controlling generalization errors, including the VC dimension (Vapnik, 1998), the wheel-maker complexity (Bartlett & Mendelson, 2003), and uniform stability (Mukherjee et al., 2002; Bousquet & Elisseeff, 2002; Poggio et al, 2004)."}, {"heading": "1.1 OUR CONTRIBUTIONS", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is not a country, but in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city and in which it is a country, in which it is a country, in which it is a country and in which it is a country."}, {"heading": "1.2 RELATED WORK", "text": "Hardt et al. (2016) set an upper limit on the generalization error of a model formed with stochastic gradient descent in terms of the number of steps that gradient descent has taken. Their analysis explores the notion of universal stability (Mukherjee et al., 2002; Bousquet & Elisseeff, 2002; Poggio et al., 2004). As we show in this paper, the universal stability of a learning algorithm is independent of the labeling of the training data. Therefore, the concept is not strong enough to distinguish between models trained on the true labels (small generalization error) and models trained on random labels (high generalization error).This also underscores why the analysis by Hardt et al. (2016) for non-convex optimization was rather pessimistic and allows very few transitions over the data. Our results show that even empirically trained neural networks are not consistent for many of the transitions."}, {"heading": "2 EFFECTIVE CAPACITY OF NEURAL NETWORKS", "text": "To achieve this goal, we choose a method inspired by non-parametric randomization tests. Specifically, we take a candidate architecture and train it both on the basis of the true data and on a copy of the data in which the true labels have been replaced by random labels. In the second case, there is no longer any relationship between the instances and the class labels. As a result, learning is impossible. Intuition suggests that this impossibility should manifest itself clearly during training, for example, by training that is not significantly converged or slowed down. To our surprise, the training process for several standard architectures is largely unaffected by this transformation of the labels. This poses a conceptual challenge. Whatever justification we had to expect a small generalization error that must begin by no longer applying to the case of random labels. To gain further insight into this phenomenon, we experiment with different levels of marginalization by completely destroying the continuum between the general Label and the ARC."}, {"heading": "2.1 FITTING RANDOM LABELS AND PIXELS", "text": "We carry out our experiments with the following modifications of labels and illustrations: \u2022 Real labels without modification. \u2022 Partly corrupt labels: random permutation of labels is selected and then the same label is applied to all labels. \u2022 Random labels are split on all labels."}, {"heading": "2.2 IMPLICATIONS", "text": "In view of our randomization experiments, we will discuss how our results exclude several traditional approaches to generalization.Rademacher complexity and VC dimension. Rademacher complexity is commonly used and flexible measure of complexity of a hypothesis class. The empirical Rademacher complexity of a hypothesis klasH on a dataset {x1,.., xn} is defined asR (H) = E\u03c3 [sup h, H, n, i = 1\u03c3ih (xi)] (1), where \u03c31,., \u03c3n, (\u00b1 1) are defined uniform random variables very similar to our randomization tests."}, {"heading": "3 THE ROLE OF REGULARIZATION", "text": "rE \"s rf\u00fc ide rf\u00fc ide rf\u00fc ide rf\u00fc ide rf\u00fc ide rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the f\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf the rf the rf the rf the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf the rf the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf the rf\u00fc the rf\u00fc the rf\u00fc the rf the rf the rf the rf the"}, {"heading": "3.1 IMPLICIT REGULARIZATIONS", "text": "In Table 2 in the appendix, we show the best test accuracy in parentheses, as a reference for potential performance gains for early cessation, but on the CIFAR10 dataset we see no potential benefit for early cessation. Batch normalization (Ioffe & Szegedy, 2015) is an operator that normalizes layer reactions within each mini-batch and has been used in many modern neural network architectures, such as Inception et al."}, {"heading": "4 FINITE-SAMPLE EXPRESSIVITY", "text": "Great efforts have been made to characterize the expressivity of neural networks, e.g. Cybenko (1989); Mhaskar (1993); Delalleau & Bengio (2011); Mhaskar & Poggio (2016); Eldan & Shamir (2016); Telgarsky (2016); Cohen & Shashua (2016). Almost all of these results are at the \"population level\" and show which functions of the entire domain can and cannot be represented by certain classes of neural networks with the same number of parameters. For example, it is known that at the population level depth k is generally more powerful than depth k \u2212 1. We argue that what is more relevant in practice is the expressive power of neural networks on a finite sample of size n. It is possible to transfer results at the population level to finite sample results by using uniform convergence theorems."}, {"heading": "5 IMPLICIT REGULARIZATION: AN APPEAL TO LINEAR MODELS", "text": "Although we remain mysterious for many reasons, we note in this section that it is not necessarily easy to understand the source of generalization for linear models. Indeed, it is useful to refer to the simple case of linear models to see if there are parallel insights that can help us better understand the neural networks. Suppose we collect n different data points (ERM) where we can rely on d-dimensional characteristics. (2) If we designate a non-negative loss with loss (y, y) = 0, we consider the empirical risk of minimization (ERM) problematic (Rd, 1) n-dimensional loss (w, yi) then we can adjust any label. But is it then possible to generalize with such a rich model class and not make explicit regulation? Let X denote the n-dimensional data matrix of which i-th series is xi."}, {"heading": "6 CONCLUSION", "text": "The classical view of machine learning is based on the idea of thrift. In almost every formulation, learning boils down to extracting patterns of low complexity from data. Brutal memorization is not typically considered an effective form of learning. At the same time, it is possible that memorization alone may in part be an effective problem-solving strategy for natural tasks. Our results challenge the classical view of learning by showing that many successful neural networks easily have the effective ability to memorize. This leads us to believe that these models may well fall back on massive memorization when addressing the problems they are supposed to solve. It is likely that traditional learning is still partially taking place, but it seems deeply intertwined with massive memorization. Classical approaches are therefore ill-suited to arguing why these models are well generalized.We believe that understanding neural networks requires a rethinking about generalization."}, {"heading": "A EXPERIMENTAL SETUP", "text": "We focus on two image classification datasets, the CIFAR10 dataset (Krizhevsky & Hinton, 2009) and the ImageNet (Russakovsky et al., 2015) ILSVRC 2012 dataset.The CIFAR10 dataset contains 50,000 training and 10,000 validation images, split into 10 classes. Each image is 32 x 32 in size, with 3 color channels. We divide the pixel values by 255 to get them into [0, 1], crop from the center to 28x28 inputs, and then normalize them by subtracting the mean and dividing the adjusted deviation indexently for each image with the per _ image _ whitening function in TENSORFLOW et al., 2015).For the experiment on CIFAR10, we test a simplified Inception et al."}, {"heading": "B DETAILED RESULTS ON IMAGENET", "text": "Table 2 shows the performance of Imagenet with real or random labels."}, {"heading": "C PROOF OF THEOREM 1", "text": "The second claim follows directly from the fact that a lower triangular matrix has all its eigenvalues."}, {"heading": "D RESULTS OF IMPLICIT REGULARIZATION FOR LINEAR MODELS", "text": "Table 3 lists the test results of linear models described in section 5."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems", "author": ["cent Vanhoucke", "Vijay Vasudevan", "Fernanda Vi\u00e9gas", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng"], "venue": null, "citeRegEx": "Vanhoucke et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vanhoucke et al\\.", "year": 2015}, {"title": "Rademacher and gaussian complexities: risk bounds and structural results", "author": ["Peter L Bartlett", "Shahar Mendelson"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bartlett and Mendelson.,? \\Q2003\\E", "shortCiteRegEx": "Bartlett and Mendelson.", "year": 2003}, {"title": "Stability and generalization", "author": ["Olivier Bousquet", "Andr\u00e9 Elisseeff"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bousquet and Elisseeff.,? \\Q2002\\E", "shortCiteRegEx": "Bousquet and Elisseeff.", "year": 2002}, {"title": "The loss surfaces of multilayer networks", "author": ["Anna Choromanska", "Mikael Henaff", "Michael Mathieu", "G\u00e9rard Ben Arous", "Yann LeCun"], "venue": "In AISTATS,", "citeRegEx": "Choromanska et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Choromanska et al\\.", "year": 2015}, {"title": "Learning feature representations with k-means", "author": ["Adam Coates", "Andrew Y. Ng"], "venue": "In Neural Networks: Tricks of the Trade, Reloaded. Springer,", "citeRegEx": "Coates and Ng.,? \\Q2012\\E", "shortCiteRegEx": "Coates and Ng.", "year": 2012}, {"title": "Convolutional Rectifier Networks as Generalized Tensor Decompositions", "author": ["Nadav Cohen", "Amnon Shashua"], "venue": "In ICML,", "citeRegEx": "Cohen and Shashua.,? \\Q2016\\E", "shortCiteRegEx": "Cohen and Shashua.", "year": 2016}, {"title": "Approximation by superposition of sigmoidal functions", "author": ["G Cybenko"], "venue": "Mathematics of Control, Signals and Systems,", "citeRegEx": "Cybenko.,? \\Q1989\\E", "shortCiteRegEx": "Cybenko.", "year": 1989}, {"title": "Shallow vs. Deep Sum-Product Networks", "author": ["Olivier Delalleau", "Yoshua Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Delalleau and Bengio.,? \\Q2011\\E", "shortCiteRegEx": "Delalleau and Bengio.", "year": 2011}, {"title": "Randomization Tests. Statistics: A Series of Textbooks and Monographs", "author": ["E. Edgington", "P. Onghena"], "venue": "Taylor & Francis,", "citeRegEx": "Edgington and Onghena.,? \\Q2007\\E", "shortCiteRegEx": "Edgington and Onghena.", "year": 2007}, {"title": "The Power of Depth for Feedforward Neural Networks", "author": ["Ronen Eldan", "Ohad Shamir"], "venue": "In COLT,", "citeRegEx": "Eldan and Shamir.,? \\Q2016\\E", "shortCiteRegEx": "Eldan and Shamir.", "year": 2016}, {"title": "Train faster, generalize better: Stability of stochastic gradient descent", "author": ["Moritz Hardt", "Benjamin Recht", "Yoram Singer"], "venue": "In ICML,", "citeRegEx": "Hardt et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hardt et al\\.", "year": 2016}, {"title": "Deep Residual Learning for Image Recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"], "venue": null, "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift", "author": ["Sergey Ioffe", "Christian Szegedy"], "venue": "In ICML,", "citeRegEx": "Ioffe and Szegedy.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe and Szegedy.", "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["Alex Krizhevsky", "Geoffrey Hinton"], "venue": "Technical report,", "citeRegEx": "Krizhevsky and Hinton.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Hinton.", "year": 2009}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Generalization properties and implicit regularization for multiple passes sgm", "author": ["Junhong Lin", "Raffaello Camoriano", "Lorenzo Rosasco"], "venue": "arXiv preprint arXiv:1605.08375,", "citeRegEx": "Lin et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2016}, {"title": "On the computational efficiency of training neural networks", "author": ["Roi Livni", "Shai Shalev-Shwartz", "Ohad Shamir"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Livni et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Livni et al\\.", "year": 2014}, {"title": "Deep vs. shallow networks : An approximation theory perspective", "author": ["Hrushikesh Mhaskar", "Tomaso A. Poggio"], "venue": "CoRR, abs/1608.03287,", "citeRegEx": "Mhaskar and Poggio.,? \\Q2016\\E", "shortCiteRegEx": "Mhaskar and Poggio.", "year": 2016}, {"title": "Approximation properties of a multilayered feedforward artificial neural network", "author": ["Hrushikesh Narhar Mhaskar"], "venue": "Advances in Computational Mathematics,", "citeRegEx": "Mhaskar.,? \\Q1993\\E", "shortCiteRegEx": "Mhaskar.", "year": 1993}, {"title": "Statistical learning: Stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization", "author": ["Sayan Mukherjee", "Partha Niyogi", "Tomaso Poggio", "Ryan Rifkin"], "venue": "Technical Report AI Memo 2002-024,", "citeRegEx": "Mukherjee et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Mukherjee et al\\.", "year": 2002}, {"title": "General conditions for predictivity in learning", "author": ["Tomaso Poggio", "Ryan Rifkin", "Sayan Mukherjee", "Partha Niyogi"], "venue": "theory. Nature,", "citeRegEx": "Poggio et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Poggio et al\\.", "year": 2004}, {"title": "Imagenet large scale visual recognition challenge", "author": ["Olga Russakovsky", "Jia Deng", "Hao Su", "Jonathan Krause", "Sanjeev Satheesh", "Sean Ma", "Zhiheng Huang", "Andrej Karpathy", "Aditya Khosla", "Michael Bernstein", "Alexander C. Berg", "Li FeiFei"], "venue": "International Journal of Computer Vision,", "citeRegEx": "Russakovsky et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Russakovsky et al\\.", "year": 2015}, {"title": "A generalized representer theorem", "author": ["Bernhard Sch\u00f6lkopf", "Ralf Herbrich", "Alex J Smola"], "venue": "In COLT,", "citeRegEx": "Sch\u00f6lkopf et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Sch\u00f6lkopf et al\\.", "year": 2001}, {"title": "Learnability, stability and uniform convergence", "author": ["Shai Shalev-Shwartz", "Ohad Shamir", "Nathan Srebro", "Karthik Sridharan"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Shalev.Shwartz et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Shalev.Shwartz et al\\.", "year": 2010}, {"title": "Dropout: a simple way to prevent neural networks from overfitting", "author": ["Nitish Srivastava", "Geoffrey E Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Srivastava et al\\.,? \\Q1929\\E", "shortCiteRegEx": "Srivastava et al\\.", "year": 1929}, {"title": "Rethinking the inception architecture for computer", "author": ["Christian Szegedy", "Vincent Vanhoucke", "Sergey Ioffe", "Jonathon Shlens", "Zbigniew Wojna"], "venue": "vision. CoRR,", "citeRegEx": "Szegedy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2015}, {"title": "Benefits of depth in neural networks", "author": ["Matus Telgarsky"], "venue": "In COLT,", "citeRegEx": "Telgarsky.,? \\Q2016\\E", "shortCiteRegEx": "Telgarsky.", "year": 2016}, {"title": "Statistical Learning Theory. Adaptive and learning systems for signal processing, communications, and control", "author": ["Vladimir N. Vapnik"], "venue": null, "citeRegEx": "Vapnik.,? \\Q1998\\E", "shortCiteRegEx": "Vapnik.", "year": 1998}, {"title": "On early stopping in gradient descent learning", "author": ["Yuan Yao", "Lorenzo Rosasco", "Andrea Caponnetto"], "venue": "Constructive Approximation,", "citeRegEx": "Yao et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2007}], "referenceMentions": [{"referenceID": 27, "context": "These include VC dimension (Vapnik, 1998), Rademacher complexity (Bartlett & Mendelson, 2003), and uniform stability (Mukherjee et al.", "startOffset": 27, "endOffset": 41}, {"referenceID": 19, "context": "These include VC dimension (Vapnik, 1998), Rademacher complexity (Bartlett & Mendelson, 2003), and uniform stability (Mukherjee et al., 2002; Bousquet & Elisseeff, 2002; Poggio et al., 2004).", "startOffset": 117, "endOffset": 190}, {"referenceID": 20, "context": "These include VC dimension (Vapnik, 1998), Rademacher complexity (Bartlett & Mendelson, 2003), and uniform stability (Mukherjee et al., 2002; Bousquet & Elisseeff, 2002; Poggio et al., 2004).", "startOffset": 117, "endOffset": 190}, {"referenceID": 14, "context": "As reported by Krizhevsky et al. (2012), `2-regularization (weight decay) sometimes even helps optimization, illustrating its poorly understood nature in deep learning.", "startOffset": 15, "endOffset": 40}, {"referenceID": 16, "context": "A previous construction due to Livni et al. (2014) achieved a similar result with far more parameters, namely, O(dn).", "startOffset": 31, "endOffset": 51}, {"referenceID": 26, "context": "contrast to existing depth separations (Delalleau & Bengio, 2011; Eldan & Shamir, 2016; Telgarsky, 2016; Cohen & Shashua, 2016) in function space, our result shows that even depth-2 networks of linear size can already represent any labeling of the training data.", "startOffset": 39, "endOffset": 127}, {"referenceID": 19, "context": "Their analysis goes through the notion of uniform stability (Mukherjee et al., 2002; Bousquet & Elisseeff, 2002; Poggio et al., 2004).", "startOffset": 60, "endOffset": 133}, {"referenceID": 20, "context": "Their analysis goes through the notion of uniform stability (Mukherjee et al., 2002; Bousquet & Elisseeff, 2002; Poggio et al., 2004).", "startOffset": 60, "endOffset": 133}, {"referenceID": 6, "context": "There has been much work on the representational power of neural networks, starting from universal approximation theorems for multi-layer perceptrons (Cybenko, 1989; Mhaskar, 1993; Delalleau & Bengio, 2011; Mhaskar & Poggio, 2016; Eldan & Shamir, 2016; Telgarsky, 2016; Cohen & Shashua, 2016).", "startOffset": 150, "endOffset": 292}, {"referenceID": 18, "context": "There has been much work on the representational power of neural networks, starting from universal approximation theorems for multi-layer perceptrons (Cybenko, 1989; Mhaskar, 1993; Delalleau & Bengio, 2011; Mhaskar & Poggio, 2016; Eldan & Shamir, 2016; Telgarsky, 2016; Cohen & Shashua, 2016).", "startOffset": 150, "endOffset": 292}, {"referenceID": 26, "context": "There has been much work on the representational power of neural networks, starting from universal approximation theorems for multi-layer perceptrons (Cybenko, 1989; Mhaskar, 1993; Delalleau & Bengio, 2011; Mhaskar & Poggio, 2016; Eldan & Shamir, 2016; Telgarsky, 2016; Cohen & Shashua, 2016).", "startOffset": 150, "endOffset": 292}, {"referenceID": 21, "context": "The experiments are run on two image classification datasets, the CIFAR10 dataset (Krizhevsky & Hinton, 2009) and the ImageNet (Russakovsky et al., 2015) ILSVRC 2012 dataset.", "startOffset": 127, "endOffset": 153}, {"referenceID": 25, "context": "We test the Inception V3 (Szegedy et al., 2015) architecture on ImageNet and a smaller version of Inception, Alexnet (Krizhevsky et al.", "startOffset": 25, "endOffset": 47}, {"referenceID": 14, "context": ", 2015) architecture on ImageNet and a smaller version of Inception, Alexnet (Krizhevsky et al., 2012), and MLPs on CIFAR10.", "startOffset": 77, "endOffset": 102}, {"referenceID": 19, "context": "This is commonly done with some notion of stability, such as uniform stability (Mukherjee et al., 2002; Bousquet & Elisseeff, 2002; Poggio et al., 2004).", "startOffset": 79, "endOffset": 152}, {"referenceID": 20, "context": "This is commonly done with some notion of stability, such as uniform stability (Mukherjee et al., 2002; Bousquet & Elisseeff, 2002; Poggio et al., 2004).", "startOffset": 79, "endOffset": 152}, {"referenceID": 23, "context": "It is possible to define weaker notions of stability (Shalev-Shwartz et al., 2010).", "startOffset": 53, "endOffset": 82}, {"referenceID": 27, "context": "Regularizers are the standard tool in theory and practice to mitigate overfitting in the regime when there are more parameters than data points (Vapnik, 1998).", "startOffset": 144, "endOffset": 158}, {"referenceID": 14, "context": "38% top-5 accuracy without regularization, while the reported number of the winner of ILSVRC 2012 (Krizhevsky et al., 2012) achieved 83.", "startOffset": 98, "endOffset": 123}, {"referenceID": 28, "context": "Early stopping was shown to implicitly regularize on some convex learning problems (Yao et al., 2007; Lin et al., 2016).", "startOffset": 83, "endOffset": 119}, {"referenceID": 15, "context": "Early stopping was shown to implicitly regularize on some convex learning problems (Yao et al., 2007; Lin et al., 2016).", "startOffset": 83, "endOffset": 119}, {"referenceID": 25, "context": "It has been widely adopted in many modern neural network architectures such as Inception (Szegedy et al., 2015) and Residual Networks (He et al.", "startOffset": 89, "endOffset": 111}, {"referenceID": 11, "context": ", 2015) and Residual Networks (He et al., 2016).", "startOffset": 30, "endOffset": 47}, {"referenceID": 6, "context": "g, Cybenko (1989); Mhaskar (1993); Delalleau & Bengio (2011); Mhaskar & Poggio (2016); Eldan & Shamir (2016); Telgarsky (2016); Cohen & Shashua (2016).", "startOffset": 3, "endOffset": 18}, {"referenceID": 6, "context": "g, Cybenko (1989); Mhaskar (1993); Delalleau & Bengio (2011); Mhaskar & Poggio (2016); Eldan & Shamir (2016); Telgarsky (2016); Cohen & Shashua (2016).", "startOffset": 3, "endOffset": 34}, {"referenceID": 6, "context": "g, Cybenko (1989); Mhaskar (1993); Delalleau & Bengio (2011); Mhaskar & Poggio (2016); Eldan & Shamir (2016); Telgarsky (2016); Cohen & Shashua (2016).", "startOffset": 3, "endOffset": 61}, {"referenceID": 6, "context": "g, Cybenko (1989); Mhaskar (1993); Delalleau & Bengio (2011); Mhaskar & Poggio (2016); Eldan & Shamir (2016); Telgarsky (2016); Cohen & Shashua (2016).", "startOffset": 3, "endOffset": 86}, {"referenceID": 6, "context": "g, Cybenko (1989); Mhaskar (1993); Delalleau & Bengio (2011); Mhaskar & Poggio (2016); Eldan & Shamir (2016); Telgarsky (2016); Cohen & Shashua (2016).", "startOffset": 3, "endOffset": 109}, {"referenceID": 6, "context": "g, Cybenko (1989); Mhaskar (1993); Delalleau & Bengio (2011); Mhaskar & Poggio (2016); Eldan & Shamir (2016); Telgarsky (2016); Cohen & Shashua (2016).", "startOffset": 3, "endOffset": 127}, {"referenceID": 6, "context": "g, Cybenko (1989); Mhaskar (1993); Delalleau & Bengio (2011); Mhaskar & Poggio (2016); Eldan & Shamir (2016); Telgarsky (2016); Cohen & Shashua (2016). Almost all of these results are at the \u201cpopulation level\u201d showing what functions of the entire domain can and cannot be represented by certain classes of neural networks with the same number of parameters.", "startOffset": 3, "endOffset": 151}, {"referenceID": 3, "context": "But in the linear case, the curvature of all optimal solutions is the same (Choromanska et al., 2015).", "startOffset": 75, "endOffset": 101}, {"referenceID": 22, "context": "We have thus derived the \u201ckernel trick\u201d (Sch\u00f6lkopf et al., 2001)\u2014albeit in a roundabout fashion.", "startOffset": 40, "endOffset": 64}], "year": 2016, "abstractText": "Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.", "creator": "LaTeX with hyperref package"}}}