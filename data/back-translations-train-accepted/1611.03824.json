{"id": "1611.03824", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Nov-2016", "title": "Learning to Learn without Gradient Descent by Gradient Descent", "abstract": "We present a learning to learn approach for training recurrent neural networks to perform black-box global optimization. In the meta-learning phase we use a large set of smooth target functions to learn a recurrent neural network (RNN) optimizer, which is either a long-short term memory network or a differentiable neural computer. After learning, the RNN can be applied to learn policies in reinforcement learning, as well as other black-box learning tasks, including continuous correlated bandits and experimental design. We compare this approach to Bayesian optimization, with emphasis on the issues of computation speed, horizon length, and exploration-exploitation trade-offs.", "histories": [["v1", "Fri, 11 Nov 2016 19:33:01 GMT  (2836kb,D)", "http://arxiv.org/abs/1611.03824v1", null], ["v2", "Fri, 18 Nov 2016 14:13:13 GMT  (2836kb,D)", "http://arxiv.org/abs/1611.03824v2", null], ["v3", "Tue, 29 Nov 2016 21:32:13 GMT  (2836kb,D)", "http://arxiv.org/abs/1611.03824v3", "Accepted by Deep Reinforcement Learning Workshop, NIPS 2016"], ["v4", "Tue, 9 May 2017 07:59:07 GMT  (658kb,D)", "http://arxiv.org/abs/1611.03824v4", "Previous version \"Learning to Learn for Global Optimization of Black Box Functions\" was published in the Deep Reinforcement Learning Workshop, NIPS 2016"], ["v5", "Mon, 5 Jun 2017 14:15:01 GMT  (1138kb,D)", "http://arxiv.org/abs/1611.03824v5", "Accepted by ICML 2017. Previous version \"Learning to Learn for Global Optimization of Black Box Functions\" was published in the Deep Reinforcement Learning Workshop, NIPS 2016"], ["v6", "Mon, 12 Jun 2017 11:19:30 GMT  (569kb,D)", "http://arxiv.org/abs/1611.03824v6", "Accepted by ICML 2017. Previous version \"Learning to Learn for Global Optimization of Black Box Functions\" was published in the Deep Reinforcement Learning Workshop, NIPS 2016"]], "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["yutian chen", "matthew w hoffman", "sergio gomez colmenarejo", "misha denil", "timothy p lillicrap", "matthew botvinick", "nando de freitas"], "accepted": true, "id": "1611.03824"}, "pdf": {"name": "1611.03824.pdf", "metadata": {"source": "CRF", "title": "Learning to Learn for Global Optimization of Black Box Functions", "authors": ["Yutian Chen", "Matthew W. Hoffman", "Sergio G\u00f3mez Colmenarejo", "Misha Denil", "Timothy P. Lillicrap", "Nando de Freitas"], "emails": ["yutianc@google.com", "mwhoffman@google.com", "sergomez@google.com", "mdenil@google.com", "countzero@google.com", "nandodefreitas@google.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them are able to determine for themselves what they want and what they don't want."}, {"heading": "2 Learning Black-box Optimization", "text": "An example of this optimization is the following loop: 1. Given the current state of knowledge, we will now propose a query point xt 2. (Note the answer to this question) (Note that the answer to this question cannot simply be taken as a starting point and a combined update and query rule is parameterized with a recurrent neural network (RNN) in which the updated step computes statistics and the query step uses these statistics for exploration. (3) Intuitively, this rule can be seen as updating its hidden state with data from the previous time step and then proposing a new query point. (What follows, we will apply to these RNN, with common parameters, to many steps of a black box optimization process."}, {"heading": "3 Experiments", "text": "We present several experiments that show the breadth of generalization achieved by our learned algorithms. We train our algorithm to optimize very simple functions - samples from a GP with a fixed length scale - and show that the learned algorithm is able to generalize from these simple functions a variety of other test functions that were not seen during the training. Our results are remarkable in several respects. First, we show that although the learned algorithms do not compete with GP-based Bayesian optimization methods (BO) when the training and test distributions match, our algorithm is competitive with GP-based methods in terms of generalizing across multiple tasks. In addition to achieving competitive performance, our learned algorithms are significantly faster than GP-based methods because they avoid multiple costs: the inversion of the GP coanzmatrix, the optimization of the capture function, and the sample-based SGP-DN."}, {"heading": "3.1 Functions from a GP Prior", "text": "In the first experiments, we train our model on the basis of functions previously sampled by a general practitioner with fixed hyperparameters. In this case, at Spearmint, we assume a previous distribution corresponding to the training distribution, so this method knows the reason and thus represents a very competitive starting point."}, {"heading": "3.1.1 Generalization to Functions Sampled from the Training Distribution", "text": "Figure 2 shows the best observed functional values depending on search step t, an average of over 10,000 scanned functions. As expected, Spearmint proves to be the best model among most settings because it uses the basic truth of the previous distribution. However, if the input dimension is 6, neural network models perform better than Spearmint, and we suspect that it is because global optimization in higher dimensional space is more difficult within the time frames in which we apply these algorithms. Among NN models, those trained with expected / empirical improvements perform better than the model trained with functional observations or GP-UCB. Figure 3 shows the trajectories of xt for different models on a typical functional sample. All models first perform exploration and later orient around a mode and look more locally. The EI-trained model behaves most similar to the trajectories of spearmint models, while less trained models are observed."}, {"heading": "3.1.2 Generalization to Functions Sampled with a Different Length-Scale", "text": "We compare the neural network models with Spearmint with a length scale fixed at the same value as the training distribution. Figure 4 shows the loss of DNC models for functions captured on the length scale, while the training length scale is 0.3. If \"<\" traction functions vary faster than the training examples and models assuming a smoother functional class, the global minimum between the detected modes may be missed. We observe that the performance of RNN models changes in the same tendency of Spearmint, except for the model that is trained with observations. For functions with very short length scales, DNC OI begins to exceed the performance of fixed length scales due to its exploratory behavior."}, {"heading": "3.1.3 Evaluating Transfer of Optimizer on Five Benchmark Functions", "text": "We compare the algorithms using five standard black box optimization benchmark functions with dimensions from 1 to 6. To get a more robust evaluation of the performance of each model, we create multiple instances for each benchmark function by applying a random translation (\u2212 0.1 percent 0.1 percent), scaling (0.9 percent 1.1 percent), mirroring and dimensional permutation in the input domain. Figure 5 shows the loss compared to a random baseline, spearmint with a length scale set on the training length scale, and spearmint with automatic inference of GP hyperparameter values and input distortion when dealing with instationary [Snoek et al., 2014]. All neural network models show competitive performance compared to spearmint methods with the exception of the 1D Gramacy & Lee function up to the training horizon, T = 30. The Gramacy & Lee function has a much smaller length scale than one of 0.3 and is one of the models in the training horizon."}, {"heading": "3.1.4 Evaluating Transfer of the Global Learner to a Simple RL Problem", "text": "In this problem, we are simulating a physical system consisting of a number of repellents that influence the fall of particles through a 2D space. The goal is to guide the path of the particles through high reward regions of the state space and to maximize the accumulated discounted reward. The four-dimensional state space in this problem consists of the position and velocity of the particles. The path of the particles can be controlled by the placement of repellers that push the particles directly away with a force inversely proportional to their distance from the particle. In our experiments, we are looking at a problem with 2 repellers, i.e. 6 parameters. The control guideline for this problem consists of 3 learned parameters for each repeller: 2d location and the strength of the repeller."}, {"heading": "4 Discussion and Future Work", "text": "The experiments showed that up to the training horizon, T = 30, the learned global RNN optimizers were trained on both Spearmint with fixed hyperparameters and Spearmint with derived hyperparameters and input warping. Our RNN optimizer was trained on functions generated with a GP with fixed hyperparameters. Therefore, we recommend the use of RNN optimizers for applications that concern a known horizon or where speed plays a role. However, the RNN optimizers also seem to have deficits. Training for very long horizons is much faster than training for Spearmins, as it has recently been documented in Duan et al 2016 [Also from hard man formation, 7 and 6 networks ultimately work well]."}, {"heading": "A Related work", "text": "In fact, most of them will be able to move to another world, in which they will be able to move to another world, in which they will be able to move, in which they will be able to move."}], "references": [{"title": "Learning to poke by poking: Experiential learning of intuitive physics", "author": ["P. Agrawal", "A. Nair", "P. Abbeel", "J. Malik"], "venue": "In Neural Information Processing Systems,", "citeRegEx": "Agrawal et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Agrawal et al\\.", "year": 2016}, {"title": "Thompson sampling for contextual bandits with linear payoffs", "author": ["S. Agrawal", "N. Goyal"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Agrawal and Goyal.,? \\Q2013\\E", "shortCiteRegEx": "Agrawal and Goyal.", "year": 2013}, {"title": "Learning to learn by gradient descent by gradient descent", "author": ["M. Andrychowicz", "M. Denil", "S. Gomez", "M.W. Hoffman", "D. Pfau", "T. Schaul", "B. Shillingford", "N. de Freitas"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Andrychowicz et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Andrychowicz et al\\.", "year": 2016}, {"title": "Data-efficient learning of feedback policies from image pixels using deep dynamical models", "author": ["J.-A.M. Assael", "N. Wahlstr\u00f6m", "T.B. Sch\u00f6n", "M.P. Deisenroth"], "venue": "arXiv preprint arXiv:1510.02173,", "citeRegEx": "Assael et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Assael et al\\.", "year": 2015}, {"title": "On the search for new learning rules for ANNs", "author": ["S. Bengio", "Y. Bengio", "J. Cloutier"], "venue": "Neural Processing Letters,", "citeRegEx": "Bengio et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1995}, {"title": "Learning a synaptic learning", "author": ["Y. Bengio", "S. Bengio", "J. Cloutier"], "venue": "rule. Universite\u0301 de Montre\u0301al, De\u0301partement d\u2019informatique et de recherche ope\u0301rationnelle,", "citeRegEx": "Bengio et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1990}, {"title": "On the optimization of a synaptic learning rule", "author": ["Y. Bengio", "S. Bengio", "J. Cloutier", "J. Gecsei"], "venue": "In in Conference on Optimality in Biological and Artificial Networks,", "citeRegEx": "Bengio et al\\.,? \\Q1992\\E", "shortCiteRegEx": "Bengio et al\\.", "year": 1992}, {"title": "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning", "author": ["E. Brochu", "V.M. Cora", "N. de Freitas"], "venue": "Technical Report UBC TR-2009-23 and arXiv:1012.2599v1, Dept. of Computer Science,", "citeRegEx": "Brochu et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Brochu et al\\.", "year": 2009}, {"title": "Pure exploration in multi-armed bandits problems", "author": ["S. Bubeck", "R. Munos", "G. Stoltz"], "venue": "In International Conference on Algorithmic Learning Theory,", "citeRegEx": "Bubeck et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bubeck et al\\.", "year": 2009}, {"title": "An empirical evaluation of Thompson sampling", "author": ["O. Chapelle", "L. Li"], "venue": "Advances in Neural Information Processing Systems, pages 2249\u20132257,", "citeRegEx": "Chapelle and Li.,? \\Q2011\\E", "shortCiteRegEx": "Chapelle and Li.", "year": 2011}, {"title": "Multi-bandit best arm identification", "author": ["V. Gabillon", "M. Ghavamzadeh", "A. Lazaric", "S. Bubeck"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gabillon et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gabillon et al\\.", "year": 2011}, {"title": "Best arm identification: A unified approach to fixed budget and fixed confidence", "author": ["V. Gabillon", "M. Ghavamzadeh", "A. Lazaric"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Gabillon et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gabillon et al\\.", "year": 2012}, {"title": "Hybrid computing using a neural network with dynamic external memory. Nature, 2016", "author": ["A. Graves", "G. Wayne", "M. Reynolds", "T. Harley", "I. Danihelka", "A. Grabska-Barwi\u00c5ska", "S.G. Colmenarejo", "E. Grefenstette", "T. Ramalho", "J. Agapiou", "A.A.P. Badia", "K.M. Hermann", "Y. Zwols", "G. Ostrovski", "A. Cain", "H. King", "C. Summerfield", "P. Blunsom", "K. Kavukcuoglu", "D. Hassabis"], "venue": null, "citeRegEx": "Graves et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Graves et al\\.", "year": 2016}, {"title": "The formation of learning sets", "author": ["H.F. Harlow"], "venue": "Psychological review,", "citeRegEx": "Harlow.,? \\Q1949\\E", "shortCiteRegEx": "Harlow.", "year": 1949}, {"title": "Entropy search for information-efficient global optimization", "author": ["P. Hennig", "C. Schuler"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Hennig and Schuler.,? \\Q2012\\E", "shortCiteRegEx": "Hennig and Schuler.", "year": 2012}, {"title": "Predictive entropy search for Bayesian optimization with unknown constraints", "author": ["J.M. Hern\u00e1ndez-Lobato", "M.A. Gelbart", "M.W. Hoffman", "R.P. Adams", "Z. Ghahramani"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Hern\u00e1ndez.Lobato et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hern\u00e1ndez.Lobato et al\\.", "year": 2015}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "Hochreiter and Schmidhuber.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Learning to learn using gradient descent", "author": ["S. Hochreiter", "A.S. Younger", "P.R. Conwell"], "venue": "In International Conference on Artificial Neural Networks,", "citeRegEx": "Hochreiter et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 2001}, {"title": "On correlation and budget constraints in model-based bandit optimization with application to automatic machine learning", "author": ["M. Hoffman", "B. Shahriari", "N. de Freitas"], "venue": "In AI and Statistics,", "citeRegEx": "Hoffman et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 2014}, {"title": "New inference strategies for solving Markov decision processes using reversible jump MCMC", "author": ["M.W. Hoffman", "H. Kueck", "N. de Freitas", "A. Doucet"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "Hoffman et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hoffman et al\\.", "year": 2009}, {"title": "A taxonomy of global optimization methods based on response", "author": ["D. Jones"], "venue": "surfaces. J. of Global Optimization,", "citeRegEx": "Jones.,? \\Q2001\\E", "shortCiteRegEx": "Jones.", "year": 2001}, {"title": "Efficient global optimization of expensive black-box functions", "author": ["D. Jones", "M. Schonlau", "W. Welch"], "venue": "J. of Global optimization,", "citeRegEx": "Jones et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Jones et al\\.", "year": 1998}, {"title": "On bayesian upper confidence bounds for bandit problems", "author": ["E. Kaufmann", "O. Capp\u00e9", "A. Garivier"], "venue": "In International Conference on Artificial Intelligence and Statistics,", "citeRegEx": "Kaufmann et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Kaufmann et al\\.", "year": 2012}, {"title": "A layered network model of associative learning: learning to learn and configuration", "author": ["E.J. Kehoe"], "venue": "Psychological review,", "citeRegEx": "Kehoe.,? \\Q1988\\E", "shortCiteRegEx": "Kehoe.", "year": 1988}, {"title": "Controlled experiments on the web: survey and practical guide", "author": ["R. Kohavi", "R. Longbotham", "D. Sommerfield", "R.M. Henne"], "venue": "Data mining and knowledge discovery,", "citeRegEx": "Kohavi et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kohavi et al\\.", "year": 2009}, {"title": "A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise", "author": ["H.J. Kushner"], "venue": "Journal of Fluids Engineering,", "citeRegEx": "Kushner.,? \\Q1964\\E", "shortCiteRegEx": "Kushner.", "year": 1964}, {"title": "Asymptotically efficient adaptive allocation rules", "author": ["T.L. Lai", "H. Robbins"], "venue": "Advances in applied mathematics,", "citeRegEx": "Lai and Robbins.,? \\Q1985\\E", "shortCiteRegEx": "Lai and Robbins.", "year": 1985}, {"title": "Learning to navigate in complex environments", "author": ["P. Mirowski", "R. Pascanu", "F. Viola", "H. Soyer", "A. Ballard", "A. Banino", "M. Denil", "R. Goroshin", "L. Sifre", "K. Kavukcuoglu", "D. Kumaran", "R. Hadsell"], "venue": null, "citeRegEx": "Mirowski et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mirowski et al\\.", "year": 2016}, {"title": "The Bayesian approach to global optimization", "author": ["J. Mo\u010dkus"], "venue": "In Systems Modeling and Optimization,", "citeRegEx": "Mo\u010dkus.,? \\Q1982\\E", "shortCiteRegEx": "Mo\u010dkus.", "year": 1982}, {"title": "The application of Bayesian methods for seeking the extremum", "author": ["J. Mo\u010dkus", "V. Tiesis", "A. \u017dilinskas"], "venue": "Toward Global Optimization,", "citeRegEx": "Mo\u010dkus et al\\.,? \\Q1978\\E", "shortCiteRegEx": "Mo\u010dkus et al\\.", "year": 1978}, {"title": "Meta-neural networks that learn by learning", "author": ["D.K. Naik", "R. Mammone"], "venue": "In International Joint Conference on Neural Networks,", "citeRegEx": "Naik and Mammone.,? \\Q1992\\E", "shortCiteRegEx": "Naik and Mammone.", "year": 1992}, {"title": "Evolution and design of distributed learning rules", "author": ["T.P. Runarsson", "M.T. Jonsson"], "venue": "In IEEE Symposium on Combinations of Evolutionary Computation and Neural Networks,", "citeRegEx": "Runarsson and Jonsson.,? \\Q2000\\E", "shortCiteRegEx": "Runarsson and Jonsson.", "year": 2000}, {"title": "Learning to optimize via posterior sampling", "author": ["D. Russo", "B. Van Roy"], "venue": "Mathematics of Operations Research,", "citeRegEx": "Russo and Roy.,? \\Q2014\\E", "shortCiteRegEx": "Russo and Roy.", "year": 2014}, {"title": "Meta-learning with memory-augmented neural networks", "author": ["A. Santoro", "S. Bartunov", "M. Botvinick", "D. Wierstra", "T. Lillicrap"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Santoro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santoro et al\\.", "year": 2016}, {"title": "Evolutionary Principles in Self-Referential Learning. On Learning how to Learn: The MetaMeta-Meta...-Hook", "author": ["J. Schmidhuber"], "venue": "PhD thesis, Institut f. Informatik, Tech. Univ. Munich,", "citeRegEx": "Schmidhuber.,? \\Q1987\\E", "shortCiteRegEx": "Schmidhuber.", "year": 1987}, {"title": "Learning to control fast-weight memories: An alternative to dynamic recurrent networks", "author": ["J. Schmidhuber"], "venue": "Neural Computation,", "citeRegEx": "Schmidhuber.,? \\Q1992\\E", "shortCiteRegEx": "Schmidhuber.", "year": 1992}, {"title": "A neural network that embeds its own meta-levels", "author": ["J. Schmidhuber"], "venue": "In International Conference on Neural Networks,", "citeRegEx": "Schmidhuber.,? \\Q1993\\E", "shortCiteRegEx": "Schmidhuber.", "year": 1993}, {"title": "Local gain adaptation in stochastic gradient descent", "author": ["N.N. Schraudolph"], "venue": "In International Conference on Artificial Neural Networks,", "citeRegEx": "Schraudolph.,? \\Q1999\\E", "shortCiteRegEx": "Schraudolph.", "year": 1999}, {"title": "A modern Bayesian look at the multi-armed bandit", "author": ["S.L. Scott"], "venue": "Applied Stochastic Models in Business and Industry,", "citeRegEx": "Scott.,? \\Q2010\\E", "shortCiteRegEx": "Scott.", "year": 2010}, {"title": "An entropy search portfolio", "author": ["B. Shahriari", "Z. Wang", "M.W. Hoffman", "A. Bouchard-C\u00f4t\u00e9", "N. de Freitas"], "venue": "In NIPS workshop on Bayesian Optimization,", "citeRegEx": "Shahriari et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Shahriari et al\\.", "year": 2014}, {"title": "Taking the human out of the loop: A review of Bayesian optimization", "author": ["B. Shahriari", "K. Swersky", "Z. Wang", "R.P. Adams", "N. de Freitas"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Shahriari et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shahriari et al\\.", "year": 2016}, {"title": "Practical Bayesian optimization of machine learning algorithms", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Input warping for Bayesian optimization of non-stationary functions", "author": ["J. Snoek", "K. Swersky", "R.S. Zemel", "R.P. Adams"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Snoek et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2014}, {"title": "Gaussian process optimization in the bandit setting: No regret and experimental design", "author": ["N. Srinivas", "A. Krause", "S.M. Kakade", "M. Seeger"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Srinivas et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Srinivas et al\\.", "year": 2010}, {"title": "Adapting bias by gradient descent: An incremental version of delta-bar-delta", "author": ["R.S. Sutton"], "venue": "In Association for the Advancement of Artificial Intelligence,", "citeRegEx": "Sutton.,? \\Q1992\\E", "shortCiteRegEx": "Sutton.", "year": 1992}, {"title": "Multi-task Bayesian optimization", "author": ["K. Swersky", "J. Snoek", "R.P. Adams"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Swersky et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Swersky et al\\.", "year": 2013}, {"title": "On the likelihood that one unknown probability exceeds another in view of the evidence of two samples", "author": ["W.R. Thompson"], "venue": null, "citeRegEx": "Thompson.,? \\Q1933\\E", "shortCiteRegEx": "Thompson.", "year": 1933}, {"title": "Learning to learn", "author": ["S. Thrun", "L. Pratt"], "venue": "Springer Science & Business Media,", "citeRegEx": "Thrun and Pratt.,? \\Q1998\\E", "shortCiteRegEx": "Thrun and Pratt.", "year": 1998}, {"title": "An informational approach to the global optimization of expensiveto-evaluate functions", "author": ["J. Villemonteix", "E. Vazquez", "E. Walter"], "venue": "J. of Global Optimization,", "citeRegEx": "Villemonteix et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Villemonteix et al\\.", "year": 2009}, {"title": "Theoretical analysis of Bayesian optimisation with unknown Gaussian process hyper-parameters", "author": ["Z. Wang", "N. de Freitas"], "venue": "arXiv preprint arXiv:1406.7758,", "citeRegEx": "Wang and Freitas.,? \\Q2014\\E", "shortCiteRegEx": "Wang and Freitas.", "year": 2014}, {"title": "Bayesian multi-scale optimistic optimization", "author": ["Z. Wang", "B. Shakibi", "L. Jin", "N. de Freitas"], "venue": "In AI and Statistics,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Reminiscence and rote learning", "author": ["L.B. Ward"], "venue": "Psychological Monographs,", "citeRegEx": "Ward.,? \\Q1937\\E", "shortCiteRegEx": "Ward.", "year": 1937}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["R.J. Williams"], "venue": "Machine learning,", "citeRegEx": "Williams.,? \\Q1992\\E", "shortCiteRegEx": "Williams.", "year": 1992}, {"title": "Neural architecture search with reinforcement learning", "author": ["B. Zoph", "Q.V. Le"], "venue": "Technical report, submitted to ICLR", "citeRegEx": "Zoph and Le.,? \\Q2016\\E", "shortCiteRegEx": "Zoph and Le.", "year": 2016}, {"title": "2016] also learn update rules for optimization, but in a way that is more", "author": ["Andrychowicz"], "venue": null, "citeRegEx": "Andrychowicz,? \\Q2016\\E", "shortCiteRegEx": "Andrychowicz", "year": 2016}], "referenceMentions": [{"referenceID": 2, "context": "In Andrychowicz et al. [2016] the product of meta-learning is a trained RNN, which is subsequently used as an optimization algorithm to fit other models to data or optimize any differentiable objective function.", "startOffset": 3, "endOffset": 30}, {"referenceID": 2, "context": "In Andrychowicz et al. [2016] the product of meta-learning is a trained RNN, which is subsequently used as an optimization algorithm to fit other models to data or optimize any differentiable objective function. In contrast, in Zoph and Le [2016] the output of meta-learning may also be an RNN, but in their case the RNN is subsequently used as a model that is fit to data using a classical optimizer.", "startOffset": 3, "endOffset": 247}, {"referenceID": 40, "context": "The model can be a Beta-Bernoulli bandit, a random forest with frequentist confidence estimates, a Dirichlet process prior, a Bayesian neural network, or a Gaussian process [Shahriari et al., 2016].", "startOffset": 173, "endOffset": 197}, {"referenceID": 50, "context": "It also raises some theoretical concerns [Wang et al., 2014].", "startOffset": 41, "endOffset": 60}, {"referenceID": 15, "context": "We will make use of two types of RNN: long-short-term memory networks (LSTMs) by Hochreiter and Schmidhuber [1997] and differentiable neural computers (DNCs) by Graves et al.", "startOffset": 81, "endOffset": 115}, {"referenceID": 12, "context": "We will make use of two types of RNN: long-short-term memory networks (LSTMs) by Hochreiter and Schmidhuber [1997] and differentiable neural computers (DNCs) by Graves et al. [2016]. In our experiments the RNN uses its memory to store information about previous queries and learns to access its memory to make decisions about which parts of the domain to explore or exploit next.", "startOffset": 161, "endOffset": 182}, {"referenceID": 19, "context": "We are therefore considering the finite horizon setting that is popular in AB tests Kohavi et al. [2009], Scott [2010] and is often studied under the umbrella of best arm identification in the bandits literature [Bubeck et al.", "startOffset": 84, "endOffset": 105}, {"referenceID": 19, "context": "We are therefore considering the finite horizon setting that is popular in AB tests Kohavi et al. [2009], Scott [2010] and is often studied under the umbrella of best arm identification in the bandits literature [Bubeck et al.", "startOffset": 84, "endOffset": 119}, {"referenceID": 2, "context": "This loss was considered by Andrychowicz et al. [2016] in the context of learning first-order optimizers, but ultimately rejected in favor of", "startOffset": 28, "endOffset": 55}, {"referenceID": 52, "context": "If even at training time the derivatives of f are not available then it would be necessary to approximate these derivatives via an algorithm such as REINFORCE [Williams, 1992].", "startOffset": 159, "endOffset": 175}, {"referenceID": 28, "context": "Also the posterior expected improvement used within LEI can be easily computed Mo\u010dkus [1982] and differentiated as well.", "startOffset": 79, "endOffset": 93}, {"referenceID": 43, "context": "For the first set of experiments we also compare against training with a loss based on GP-UCB [Srinivas et al., 2010], which we refer to as DNC UCB.", "startOffset": 94, "endOffset": 117}, {"referenceID": 42, "context": "Figure 5 shows the loss compared with a random baseline, Spearmint with length scale fixed to the training length scale, and Spearmint with automatic inference of the GP hyper-parameter values and input warping to deal with non-stationarity [Snoek et al., 2014].", "startOffset": 241, "endOffset": 261}, {"referenceID": 18, "context": "We also consider an application to a simple reinforcement learning task described by Hoffman et al. [2009]. In this problem we simulate a physical system consisting of a number of repellers which affect the fall of particles through a 2D-space.", "startOffset": 85, "endOffset": 107}], "year": 2016, "abstractText": "We present a learning to learn approach for training recurrent neural networks to perform black-box global optimization. In the meta-learning phase we use a large set of smooth target functions to learn a recurrent neural network (RNN) optimizer, which is either a long-short term memory network or a differentiable neural computer. After learning, the RNN can be applied to learn policies in reinforcement learning, as well as other black-box learning tasks, including continuous correlated bandits and experimental design. We compare this approach to Bayesian optimization, with emphasis on the issues of computation speed, horizon length, and exploration-exploitation trade-offs.", "creator": "LaTeX with hyperref package"}}}