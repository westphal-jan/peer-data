{"id": "1611.04088", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Nov-2016", "title": "Batched Gaussian Process Bandit Optimization via Determinantal Point Processes", "abstract": "Gaussian Process bandit optimization has emerged as a powerful tool for optimizing noisy black box functions. One example in machine learning is hyper-parameter optimization where each evaluation of the target function requires training a model which may involve days or even weeks of computation. Most methods for this so-called \"Bayesian optimization\" only allow sequential exploration of the parameter space. However, it is often desirable to propose batches or sets of parameter values to explore simultaneously, especially when there are large parallel processing facilities at our disposal. Batch methods require modeling the interaction between the different evaluations in the batch, which can be expensive in complex scenarios. In this paper, we propose a new approach for parallelizing Bayesian optimization by modeling the diversity of a batch via Determinantal point processes (DPPs) whose kernels are learned automatically. This allows us to generalize a previous result as well as prove better regret bounds based on DPP sampling. Our experiments on a variety of synthetic and real-world robotics and hyper-parameter optimization tasks indicate that our DPP-based methods, especially those based on DPP sampling, outperform state-of-the-art methods.", "histories": [["v1", "Sun, 13 Nov 2016 05:52:58 GMT  (1044kb,D)", "http://arxiv.org/abs/1611.04088v1", "To appear at NIPS 2016"]], "COMMENTS": "To appear at NIPS 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["tarun kathuria", "amit deshpande", "pushmeet kohli"], "accepted": true, "id": "1611.04088"}, "pdf": {"name": "1611.04088.pdf", "metadata": {"source": "CRF", "title": "Batched Gaussian Process Bandit Optimization via Determinantal Point Processes", "authors": ["Tarun Kathuria", "Amit Deshpande", "Pushmeet Kohli"], "emails": ["pkohli}@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "Optimizing an unknown function on the basis of noisy observations is a fundamental problem in various areas of the real world, such as engineering design [34], finance [37], and hyperparameter optimization [30]. In recent years, an increasingly popular direction has been to model smoothness assumptions about function by means of a Gaussian process (GP) that provides a simple method of calculating the posterior distribution of the unknown function, and thus uncertainty estimates that help decide where the function should be evaluated next, in search of an optimum. This Bajesian optimization framework (BO) has received considerable attention in coordinating hyperparameters for complex models and algorithms in Machine Learning, Robotics, and Computer Vision [16, 32, 30, 12]. Apart from a few notable exceptions [9, 8, 11] most methods for Bajesian optimization work are by examining a parameter value at a particular point in time."}, {"heading": "1.1 Our Contributions", "text": "In view of the fact that the functions of GPs usually have a certain degree of smoothness, it is desirable to choose batches that are diverse."}, {"heading": "1.2 Related Work", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "2 Preliminaries", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Gaussian Process Bandit Optimization", "text": "We address the problem of determining, in the lowest possible number of iterations, the maximum (m) of an unknown function f: X \u2192 R, where X-Rd, i.e., m = f (x-x) = max x-X (x-x).We consider the domain as discrete, since it is widely known how to obtain remorse limits for continuous, compact domains via appropriate discreditations [31]. At each iteration, we select a series {xt, b} 1 \u2264 B of the B points and then simultaneously observe the noisy values taken by f at these points, yt = f (xt, b), b, where t, k is i.e. The function is assumed to be drawn by a Gaussian process (i.e., f-GP), f-GP (0, k), where k."}, {"heading": "2.2 Determinantal Point Processes", "text": "In view of a DPP core K-Rm \u00b7 m of m elements {1,.., m}, the k-DPP distribution defined on 2Y is defined as selection B, a k subset of [m] with a probability proportional to det (KB). Formally, Pr (B) = det (KB) \u2211 | S | = k det (KS) The problem of selecting a set of size k that maximizes the determinant and scanning a set according to the k-DPP distribution has received considerable attention [23, 7, 6, 10, 1, 18]. The maximization problem in general is NP-hard and also has a hardness of the approximation result of 1 / ck for some c > 1. The best-known approximation algorithm is around [23] with a factor of 1 / ek that almost coincides with the lower limit. However, its algorithm is a complicated and expensive convex program based on a simple logger on a large PHP, which does not give a simple algorithm (this one logger on a large Ps)."}, {"heading": "3 Main Results", "text": "In this section, we present our DPP-based algorithms. To allow a fair comparison of the different methods, we first demonstrate the limits of regret for the EST version of BUCB, i.e. B-EST. Then, we demonstrate the equivalence between UCB-PE and UCB-DPP maximization, as well as the limits of regret for the EST version of PE / DPP-MAX. Then, we present the DPP sampling methods (DPP-SAMPLE) for UCB and EST and offer limits of regret. In Annex 4, we provide a simpler proof with improved limits for the maximum information gain for the RBF core, while borrowing ideas from [27]."}, {"heading": "3.1 The Batched-EST algorithm", "text": "The BUCB has a feedback mapping fb, which indicates that at a given time t > (only in this case we will select a total number of TB schedules), the iteration up to which the actual function values are available. In the batch setting, this is only b (t \u2212 1) / BcB. The BUCB and B-EST, its EST variant algorithms are represented in algorithm 1. (Lemma 2.1 in [35]) The point selected by EST is essentially the same as the point selected by EST as a variant of UCB. This is shown in the following Lemma 3.1. (Lemma 2.1 in [35]) The point \u2212 2 selected by EST is the same as the point selected by a variant of UCB with \u03b2 1 / 2 t = minx X (m \u2212 \u00b5t \u2212 1 (x) / p \u2212 1 (x)."}, {"heading": "3.2 Equivalence of Pure Exploration (PE) and DPP Maximization", "text": "We present the equivalence between Pure Exploration and a procedure that involves DPP maximization = impacts on the Greedy algorithm. For the next two sections, we will first describe a generic framework for BBO inspired by UCB-PE: In each iteration, the first point is selected by selecting the one that maximizes UCB or EST, which can be considered a variant of UCB per Lemma 3.1. A relevance region R + t is defined, which contains arg maxx. X + t) with high probability. Let y \u2022 t = f \u2212 t (x \u2022 t), where x \u2022 t = arg maxx."}, {"heading": "3.3 Batch Bayesian Optimization via DPP Sampling", "text": "In the previous subsection, we considered the limits of regret achieved by the DPP maximization, and a natural question that we must then ask ourselves is whether the other subset of the selection method for DPPs, namely the DPP sample, gives us equal or better limits of regret. Please note that in this case, the regret would have to be defined as an expected regret. The reason to believe this is well founded, since the sample of k-DPPs, namely the sample of k-DPPs, produces better results, both in theory and in practice, for an approximation to the low matrix [10] and the copy selection for Nystrom methods [20]. In accordance with the framework described in the previous subsection, the subset to be selected must be of size B \u2212 1 and the kernel should be Kt, 1 at each iteration. Instead of the maximization, we can choose a sample from an algorithm (we \u2212 B), DPP \u2212 2."}, {"heading": "4 Experiments", "text": "In this section, we will examine the performance of DPP-based algorithms, especially DPP-SAMPLE against some existing baselines. In particular, the methods we are considering are BUCB [9], B-EST, UCB-PE / UCBDPP-MAX [8], EST-PE / EST-DPP-MAX, UCB-SAMPLE, EST-DPP-SAMPLE and UCB with local penalization (LP-UCB) [11]. We used the publicly available code for BUCB and PE1. The code has been modified to include the code for the EST counterparts with code 2. For the LP-UCB, we are using the publicly available GPyOpt codebase 3 and implementing the MCMC algorithms of [1] for k-DPP sampling with = 0.01 as variation distance error."}, {"heading": "5 Conclusion", "text": "We have proposed a new method of Batch-Gauss Process Bandit Optimization (Batch-Bayesian) based on DPPs, which are desirable in this case as they promote diversity in batches. The DPP kernel is automatically detected in advance, which allows us to show limits of regret for DPP maximization and sample-based methods for this problem. We have shown that this framework restores exactly one popular algorithm for BBO, the UCB-PE, when we look at DPP maximization with the greedy algorithm. We have shown that the regret for the sample-based method is always less than the maximization-based method. We have also derived their EST equivalents and provided a simpler proof of the information gain for RBF cores, which leads to a slight improvement of the most well-known ones. Our experiments with a variety of synthetic and real tasks confirm our theoretical claims that sampling works better and other methods than maximizing."}, {"heading": "6 APPENDIX", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 The Batched-EST Algorithm", "text": "The proofs for B-EST are relatively simple, resulting from the combination of the proofs of [9] and [35]. We provide them here for the sake of completeness. First, we need a set of supporting lemmas, which are variants of the UCB's lemmas for EST. These require different limits of trust than those of BUCB.Lemma 6.1. (Lemma 3.2 in [35]) Let us select a set of supporting lemmas, which are derived from [0, 1) and let us set a definitive proof for [2]. Then, for an arbitrary sequence of actions x1, x2. (Pr [f) \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 p \u2212 t = 2 log (\u03c02t2 / 6\u043c). Then it is for an arbitrary sequence of actions x1, x2,."}, {"heading": "6.2 Batch Bayesian Optimization via DPP-Maximization", "text": "Since the GP-UCBDPP-MAX is the same as GP-UCB-PE, we will focus on GP-EST-DPP-MAX. \u2022 We will first repeat the EST part of theorem 3.3. Firstly, none of our evidence will depend on the order in which the batch was selected, but for the sake of clarity of exposure, whenever necessary, we can consider any order of B \u2212 1 points obtained by maximizing one (B \u2212 1) DPP or sampling from it.theorem 6.3. Iterating t, fix ppi > 0 and leave t = [min x \u2212 m \u2212 \u00b5t \u2212 1 (x) the order of B \u2212 1 points obtained by maximizing one (B \u2212 1) -DPP or sampling from it.theorem 6.3."}, {"heading": "6.3 Batch Bayesian Optimization via DPP sampling", "text": "In this section we confirm the KPP-SAMPLE of DPP-SAMPLE (PP = PP = TB = TB = TB = TB = TB KKB = KPP KB = KPP = TB = TB = TB = TB = B = KPP = KPP = PP KB = KPP = KPP KB = KPP = KPP KB = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = PP = B = B = PP = B = B = B = B = B = PP = PP = B = B = PP = B = B = B = B = B = PP = B = B = PP = B = B = B = K = KPP = KB = KB = KPP = KB = KB = KB = KB = KB = KB = TB = TB = TB = TB = TB = TB = TB = TB = TB = TB = TB = TB = TB = KB = KB = KB = KB = KB = KPP = KPP = KB = KPP = KB = KB = KPP = KB = KB = KPP = KB = KB = KPP = KB = KPP = KB = KB = KB = KB = KPP = KB = KB = KPP = KB = KB = KB = KB = KB KB = KB = KB KB KB KB = KB KB KB = KB KB KB = KB KB KB = KB KB KB = KB KB = KB KPP = KB = PP = KB = KB KB KB KB = KB KB KB = KB KB = KB KB KB KB = KB KB KB = KB KB KB = KB = PP = KB KB KB = KB KB = KB = KB KB = KB KB KB KB = KB = KB KB = KB = KB KB KB = KB = KB ="}, {"heading": "6.4 Bounds on Information Gain for RBF kernels", "text": "Theorem 6.8. The maximum information gain for the RBF kernel according to the S timestep is O (((log | S |) d) proof. Let xS be the vector of the points from the subset S, i.e. xS = (x) x-S, and the noisy evaluations of a function f at these points are denoted by a vector yS = fS + S, where fS = (f (x)) x-S and S-N (0, \u03c32I). In Bayesian experimental design, the information gain of S is denoted by the reciprocal information between f and these observations I (yS; f) = H (yS) \u2212 H (yS) \u2212 H (yS | f). If f is modeled using the aGaussian method, it is represented by the mean function \u00b5 (x) = Ef (x) and the covariance or kernel function k (x)."}, {"heading": "6.5 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.5.1 Synthetic Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.5.2 Real-World Experiments", "text": "We first provide the results of the Abalone experiment and then the Prec @ 1 values for the FastXML experiment of the Delicious experiment."}], "references": [{"title": "Monte carlo markov chains algorithms for sampling strongly rayleigh distributions and determinantal point processes", "author": ["N. Anari", "S.O. Gharan", "A. Rezaei"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2016}, {"title": "A nonparametric approach to noisy and costly optimization", "author": ["B.S. Anderson", "A.W. Moore", "D. Cohn"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2000}, {"title": "Using confidence bounds for exploration-exploitation", "author": ["P. Auer"], "venue": "trade-offs. JMLR,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2002}, {"title": "Batch bayesian optimization via simulation matching", "author": ["J. Azimi", "A. Fern", "X. Fern"], "venue": null, "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2010}, {"title": "Determinantal identities: Gauss, schur, cauchy, sylvester, kronecker, jacobi, binet, laplace, muir, and cayley", "author": ["R. Brualdi", "H. Schneider"], "venue": "Linear Algebra and its Applications,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1983}, {"title": "On selecting a maximum volume sub-matrix of a matrix and related problems", "author": ["A. \u00c7ivril", "M. Magdon-Ismail"], "venue": "Theor. Comput. Sci.,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Exponential inapproximability of selecting a maximum volume sub-matrix", "author": ["A. \u00c7ivril", "M. Magdon-Ismail"], "venue": null, "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2013}, {"title": "Parallel gaussian process optimization with upper confidence bound and pure exploration", "author": ["E. Contal", "D. Buffoni", "D. Robicquet", "N. Vayatis"], "venue": null, "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2013}, {"title": "Parallelizing exploration-exploitation tradeoffs in gaussian process bandit optimization", "author": ["T. Desautels", "A. Krause", "J.W. Burdick"], "venue": "JMLR, 15:4053\u20134103,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2014}, {"title": "Efficient volume sampling for row/column subset selection", "author": ["A. Deshpande", "L. Rademacher"], "venue": null, "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2010}, {"title": "Batch bayesian optimization via local penalization", "author": ["J. Gonzalez", "Z. Dai", "P. Hennig", "N. Lawrence"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "GLASSES: relieving the myopia of bayesian optimisation", "author": ["J. Gonz\u00e1lez", "M.A. Osborne", "N.D. Lawrence"], "venue": null, "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2016}, {"title": "Entropy search for information-efficient global optimization", "author": ["P. Hennig", "C. Schuler"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2012}, {"title": "Predicitive entropy search for efficient global optimization of black-box functions", "author": ["J.M. Hernandex-Lobato", "M.W. Hoffman", "Z. Ghahramani"], "venue": null, "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2014}, {"title": "Multilabel text classification for automated tag suggestion", "author": ["I. Katakis", "G. Tsoumakas", "I. Vlahavas"], "venue": "ECML/PKDD Discovery Challenge,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2008}, {"title": "Contextual gaussian process bandit optimization", "author": ["A. Krause", "C.S. Ong"], "venue": null, "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies", "author": ["Andreas Krause", "Ajit Singh", "Carlos Guestrin"], "venue": "J. Mach. Learn. Res.,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2008}, {"title": "k-dpps: Fixed-size determinantal point processes", "author": ["Alex Kulesza", "Ben Taskar"], "venue": "In ICML,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Determinantal Point Processes for Machine Learning", "author": ["Alex Kulesza", "Ben Taskar"], "venue": "Found. Trends Mach. Learn.,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2012}, {"title": "Fast dpp sampling for nystrm with application to kernel methods", "author": ["C. Li", "S. Jegelka", "S. Sra"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Pratical bayesian optimization", "author": ["D. Lizotte"], "venue": "PhD thesis, University of Alberta,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2008}, {"title": "Determinantal probability measures", "author": ["R. Lyons"], "venue": "Publications Mathe\u0301matiques de l\u2019Institut des Hautes E\u0301tudes Scientifiques,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2003}, {"title": "Randomized rounding for the largest simplex problem", "author": ["A. Nikolov"], "venue": "In STOC, pages 861\u2013870,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2015}, {"title": "Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning", "author": ["Y. Prabhu", "M. Varma"], "venue": null, "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2014}, {"title": "Gaussian processes for machine learning", "author": ["C. Rasmussen", "C. Williams"], "venue": null, "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2008}, {"title": "Some aspects of the sequential design of experiments", "author": ["H. Robbins"], "venue": "Bul. Am. Math. Soc.,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 1952}, {"title": "Information consistency of nonparametric gaussian process methods", "author": ["M.W. Seeger", "S.M. Kakade", "D.P. Foster"], "venue": "IEEE Tr. Inf. Theo.,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2008}, {"title": "Parallel predictive entropy search for batch global optimization of expensive objective functions", "author": ["A. Shah", "Z. Ghahramani"], "venue": null, "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2015}, {"title": "Random point fields associated with certain fredholm determinants i: fermion, poisson and boson point processes", "author": ["T. Shirai", "Y. Takahashi"], "venue": "Journal of Functional Analysis,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2003}, {"title": "Practical bayesian optimization of machine learning", "author": ["J. Snoek", "H. Larochelle", "R.P. Adams"], "venue": null, "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2012}, {"title": "Information-theoretic regret bounds for gaussian process optimization in the bandit setting", "author": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"], "venue": "IEEE Transactions on Information Theory,", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2012}, {"title": "Auto-weka : combined selection and hyper-parameter optimization of classification", "author": ["C. Thornton", "F. Hutter", "H.H. Hoos", "K. Leyton-Brown"], "venue": null, "citeRegEx": "32", "shortCiteRegEx": "32", "year": 2003}, {"title": "Effective and efficient multilabel classification in domains with large number of labels", "author": ["G. Tsoumakas", "I. Katakis", "I. Vlahavas"], "venue": "ECML/PKDD 2008 Workshop on Mining Multidimensional Data,", "citeRegEx": "33", "shortCiteRegEx": "33", "year": 2008}, {"title": "Review of metamodeling techniques in support of engineering design optimization", "author": ["G. Wang", "S. Shan"], "venue": "Journal of Mechanical Design,", "citeRegEx": "34", "shortCiteRegEx": "34", "year": 2007}, {"title": "Optimization as estimation with gaussian processes in bandit settings", "author": ["Z. Wang", "B. Zhou", "S. Jegelka"], "venue": null, "citeRegEx": "35", "shortCiteRegEx": "35", "year": 2016}, {"title": "Feedback control of dynamic bipedal robot locomotion", "author": ["E. Westervelt", "J. Grizzle"], "venue": "Control and Automation Series,", "citeRegEx": "36", "shortCiteRegEx": "36", "year": 2007}, {"title": "Stochastic optimization models in finance", "author": ["W. Ziemba", "R. Vickson"], "venue": "World Scientific Singapore,", "citeRegEx": "37", "shortCiteRegEx": "37", "year": 2006}], "referenceMentions": [{"referenceID": 33, "context": ", engineering design [34], finance [37] and hyper-parameter optimization [30].", "startOffset": 21, "endOffset": 25}, {"referenceID": 36, "context": ", engineering design [34], finance [37] and hyper-parameter optimization [30].", "startOffset": 35, "endOffset": 39}, {"referenceID": 29, "context": ", engineering design [34], finance [37] and hyper-parameter optimization [30].", "startOffset": 73, "endOffset": 77}, {"referenceID": 15, "context": "This Bayesian optimization (BO) framework has received considerable attention in tuning of hyper-parameters for complex models and algorithms in Machine Learning, Robotics and Computer Vision [16, 32, 30, 12].", "startOffset": 192, "endOffset": 208}, {"referenceID": 31, "context": "This Bayesian optimization (BO) framework has received considerable attention in tuning of hyper-parameters for complex models and algorithms in Machine Learning, Robotics and Computer Vision [16, 32, 30, 12].", "startOffset": 192, "endOffset": 208}, {"referenceID": 29, "context": "This Bayesian optimization (BO) framework has received considerable attention in tuning of hyper-parameters for complex models and algorithms in Machine Learning, Robotics and Computer Vision [16, 32, 30, 12].", "startOffset": 192, "endOffset": 208}, {"referenceID": 11, "context": "This Bayesian optimization (BO) framework has received considerable attention in tuning of hyper-parameters for complex models and algorithms in Machine Learning, Robotics and Computer Vision [16, 32, 30, 12].", "startOffset": 192, "endOffset": 208}, {"referenceID": 8, "context": "Apart from a few notable exceptions [9, 8, 11], most methods for Bayesian optimization work by exploring one parameter value at a time.", "startOffset": 36, "endOffset": 46}, {"referenceID": 7, "context": "Apart from a few notable exceptions [9, 8, 11], most methods for Bayesian optimization work by exploring one parameter value at a time.", "startOffset": 36, "endOffset": 46}, {"referenceID": 10, "context": "Apart from a few notable exceptions [9, 8, 11], most methods for Bayesian optimization work by exploring one parameter value at a time.", "startOffset": 36, "endOffset": 46}, {"referenceID": 8, "context": "Indeed, this is the motivation behind many popular BBO methods like the BUCB [9], UCB-PE [8] and Local Penalization", "startOffset": 77, "endOffset": 80}, {"referenceID": 7, "context": "Indeed, this is the motivation behind many popular BBO methods like the BUCB [9], UCB-PE [8] and Local Penalization", "startOffset": 89, "endOffset": 92}, {"referenceID": 10, "context": "[11].", "startOffset": 0, "endOffset": 4}, {"referenceID": 28, "context": "DPPs are probability measures over subsets of a ground set that promote diversity, have applications in statistical physics and random matrix theory [29, 22], and have efficient sampling algorithms [18, 19].", "startOffset": 149, "endOffset": 157}, {"referenceID": 21, "context": "DPPs are probability measures over subsets of a ground set that promote diversity, have applications in statistical physics and random matrix theory [29, 22], and have efficient sampling algorithms [18, 19].", "startOffset": 149, "endOffset": 157}, {"referenceID": 17, "context": "DPPs are probability measures over subsets of a ground set that promote diversity, have applications in statistical physics and random matrix theory [29, 22], and have efficient sampling algorithms [18, 19].", "startOffset": 198, "endOffset": 206}, {"referenceID": 18, "context": "DPPs are probability measures over subsets of a ground set that promote diversity, have applications in statistical physics and random matrix theory [29, 22], and have efficient sampling algorithms [18, 19].", "startOffset": 198, "endOffset": 206}, {"referenceID": 7, "context": "Following UCB-PE [8], our methods also choose the first point via an acquisition function, and then the rest of the points are selected from a relevance region using a DPP.", "startOffset": 17, "endOffset": 20}, {"referenceID": 34, "context": "The acquisition functions we consider are EST [35], a recently proposed sequential MAP-estimate based Bayesian optimization algorithm with regret bounds independent of the size of the domain, and UCB [31].", "startOffset": 46, "endOffset": 50}, {"referenceID": 30, "context": "The acquisition functions we consider are EST [35], a recently proposed sequential MAP-estimate based Bayesian optimization algorithm with regret bounds independent of the size of the domain, and UCB [31].", "startOffset": 200, "endOffset": 204}, {"referenceID": 26, "context": "In the appendix, we also provide a simpler proof of the information gain for the widely-used RBF kernel which also improves the bound from O((log T )) [27, 31] to O((log T )).", "startOffset": 151, "endOffset": 159}, {"referenceID": 30, "context": "In the appendix, we also provide a simpler proof of the information gain for the widely-used RBF kernel which also improves the bound from O((log T )) [27, 31] to O((log T )).", "startOffset": 151, "endOffset": 159}, {"referenceID": 25, "context": "This exploration-exploitation trade off naturally leads to modeling this problem in the multi-armed bandit paradigm [26], where the goal is to maximize cumulative reward by optimally balancing this trade-off.", "startOffset": 116, "endOffset": 120}, {"referenceID": 30, "context": "[31] analyzed the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm, a simple and intuitive Bayesian method [3] to achieve the first sub-linear regret bounds for Gaussian process bandit optimization.", "startOffset": 0, "endOffset": 4}, {"referenceID": 2, "context": "[31] analyzed the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm, a simple and intuitive Bayesian method [3] to achieve the first sub-linear regret bounds for Gaussian process bandit optimization.", "startOffset": 117, "endOffset": 120}, {"referenceID": 34, "context": "[35] considered an intuitive MAP-estimate based strategy (EST) which involves estimating the maximum value of a function and choosing a point which has maximum probability of achieving this maximum value.", "startOffset": 0, "endOffset": 4}, {"referenceID": 12, "context": "Along with these, there is also work on Entropy search (ES) [13] and its variant, predictive entropy search (PES) [14] which instead aims at minimizing the uncertainty about the location of the optimum of the function.", "startOffset": 60, "endOffset": 64}, {"referenceID": 13, "context": "Along with these, there is also work on Entropy search (ES) [13] and its variant, predictive entropy search (PES) [14] which instead aims at minimizing the uncertainty about the location of the optimum of the function.", "startOffset": 114, "endOffset": 118}, {"referenceID": 27, "context": "Indeed this is the criticism of these two methods by a recently proposed BBO strategy PPES [28], which parallelizes predictive entropy search based methods and shows considerable improvements over the BUCB and UCB-PE methods.", "startOffset": 91, "endOffset": 95}, {"referenceID": 10, "context": "Another recently proposed method is the Local Penalization (LP) [11], which assumes that the function is Lipschitz continuous and tries to estimate the Lipschitz constant.", "startOffset": 64, "endOffset": 68}, {"referenceID": 30, "context": "We consider the domain to be discrete as it is well-known how to obtain regret bounds for continous, compact domains via suitable discretizations [31].", "startOffset": 146, "endOffset": 150}, {"referenceID": 24, "context": "Given the observations Dt = {(x\u03c4 , y\u03c4 )\u03c4=1} up to time t, we obtain the posterior mean and covariance functions [25] via the kernel matrix Kt = [k(xi, xj)]xi,xj\u2208Dt and kt(x) = [k(xi, x)]xi\u2208Dt : \u03bct(x) = kt(x) T (Kt + \u03c3 I)yt and kt(x, x \u2032) = k(x, x\u2032)\u2212 kt(x) (Kt + \u03c3I)kt(x).", "startOffset": 112, "endOffset": 116}, {"referenceID": 8, "context": "Define the Upper Confidence Bound (UCB) f + and Lower Confidence Bound (LCB) f\u2212 as f t (x) = \u03bct\u22121(x) + \u03b2 1/2 t \u03c3t\u22121(x) f \u2212 t (x) = \u03bct\u22121(x)\u2212 \u03b2 1/2 t \u03c3t\u22121(x) A crucial observation made in BUCB [9] and UCB-PE [8] is that the posterior covariance and variance functions do not depend on the actual function values at the set of points.", "startOffset": 191, "endOffset": 194}, {"referenceID": 7, "context": "Define the Upper Confidence Bound (UCB) f + and Lower Confidence Bound (LCB) f\u2212 as f t (x) = \u03bct\u22121(x) + \u03b2 1/2 t \u03c3t\u22121(x) f \u2212 t (x) = \u03bct\u22121(x)\u2212 \u03b2 1/2 t \u03c3t\u22121(x) A crucial observation made in BUCB [9] and UCB-PE [8] is that the posterior covariance and variance functions do not depend on the actual function values at the set of points.", "startOffset": 206, "endOffset": 209}, {"referenceID": 34, "context": "The EST algorithm in [35] chooses at each timestep t,the point which has the maximum posterior probability of attaining the maximum value m, i.", "startOffset": 21, "endOffset": 25}, {"referenceID": 34, "context": "[35] get around this by using an approximation m\u0302 which, under certain conditions specified in their paper, is an upper bound on m.", "startOffset": 0, "endOffset": 4}, {"referenceID": 34, "context": "We refer the reader to [35] for details of the two estimates and refer to ESTa as EST.", "startOffset": 23, "endOffset": 27}, {"referenceID": 30, "context": "The regret for both the UCB and the EST algorithms are presented in the following theorem which is a combination of Theorem 1 in [31] and Theorem 3.", "startOffset": 129, "endOffset": 133}, {"referenceID": 34, "context": "1 in [35].", "startOffset": 5, "endOffset": 9}, {"referenceID": 22, "context": "Pr(B) = det(KB) \u2211 |S|=k det(KS) The problem of picking a set of size k which maximizes the determinant and sampling a set according to the k-DPP distribution has received considerable attention [23, 7, 6, 10, 1, 18].", "startOffset": 194, "endOffset": 215}, {"referenceID": 6, "context": "Pr(B) = det(KB) \u2211 |S|=k det(KS) The problem of picking a set of size k which maximizes the determinant and sampling a set according to the k-DPP distribution has received considerable attention [23, 7, 6, 10, 1, 18].", "startOffset": 194, "endOffset": 215}, {"referenceID": 5, "context": "Pr(B) = det(KB) \u2211 |S|=k det(KS) The problem of picking a set of size k which maximizes the determinant and sampling a set according to the k-DPP distribution has received considerable attention [23, 7, 6, 10, 1, 18].", "startOffset": 194, "endOffset": 215}, {"referenceID": 9, "context": "Pr(B) = det(KB) \u2211 |S|=k det(KS) The problem of picking a set of size k which maximizes the determinant and sampling a set according to the k-DPP distribution has received considerable attention [23, 7, 6, 10, 1, 18].", "startOffset": 194, "endOffset": 215}, {"referenceID": 0, "context": "Pr(B) = det(KB) \u2211 |S|=k det(KS) The problem of picking a set of size k which maximizes the determinant and sampling a set according to the k-DPP distribution has received considerable attention [23, 7, 6, 10, 1, 18].", "startOffset": 194, "endOffset": 215}, {"referenceID": 17, "context": "Pr(B) = det(KB) \u2211 |S|=k det(KS) The problem of picking a set of size k which maximizes the determinant and sampling a set according to the k-DPP distribution has received considerable attention [23, 7, 6, 10, 1, 18].", "startOffset": 194, "endOffset": 215}, {"referenceID": 22, "context": "The best known approximation algorithm is by [23] with a factor of 1/e, which almost matches the lower bound.", "startOffset": 45, "endOffset": 49}, {"referenceID": 9, "context": "For sampling from k-DPPs, an exact sampling algorithm exists due to [10].", "startOffset": 68, "endOffset": 72}, {"referenceID": 0, "context": "A recently proposed alternative is an MCMC based method by [1] which is much faster.", "startOffset": 59, "endOffset": 62}, {"referenceID": 26, "context": "In Appendix 4, while borrowing ideas from [27], we provide a simpler proof with improved bounds on the maximum information gain for the RBF kernel.", "startOffset": 42, "endOffset": 46}, {"referenceID": 34, "context": "The algorithm mainly comes from the observation made in [35] that the point chosen by EST is the same as a variant of UCB.", "startOffset": 56, "endOffset": 60}, {"referenceID": 34, "context": "1 in [35]) At any timestep t, the point selected by EST is the same as the point selected by a variant of UCB with \u03b2 1/2 t = minx\u2208X (m\u0302\u2212 \u03bct\u22121(x))/\u03c3t\u22121(x).", "startOffset": 5, "endOffset": 9}, {"referenceID": 8, "context": "In the algorithm, C \u2032 is chosen to be exp(2C), where C is an upper bound on the maximum conditional mutual information I(f(x); yfb[t]+1:t\u22121|y1:fb[t]) (refer to [9] for details).", "startOffset": 160, "endOffset": 163}, {"referenceID": 8, "context": "This is corrected in [9] by two-stage BUCB which first chooses an initial batch of size T init by greedily choosing points based on the (updated) posterior variances.", "startOffset": 21, "endOffset": 24}, {"referenceID": 8, "context": "We refer the reader to the Table 1 in [9] for values of C \u2032 and T init for common kernels.", "startOffset": 38, "endOffset": 41}, {"referenceID": 8, "context": "Choose \u03b1t = ( minx\u2208X m\u0302\u2212\u03bcfb[t](x) \u03c3t\u22121(x) )2 and \u03b2t = (C )\u03b1t, B \u2265 2, \u03b4 > 0 and the C \u2032 and T init values are chosen according to Table 1 in [9].", "startOffset": 140, "endOffset": 143}, {"referenceID": 7, "context": "The proof of the regret bounds of UCB-PE go through a few steps but in one of the intermediate steps (Lemma 5 of [8]), it is shown that the sum of regrets over a batch at an iteration t is upper bounded as", "startOffset": 113, "endOffset": 116}, {"referenceID": 4, "context": "From the final log-product term, it can be seen (from Schur\u2019s determinant identity [5] and the definition of \u03c3t,b(xt,b)) that the product of the last B \u2212 1 terms is exactly the B \u2212 1 principal minor of Kt,1 formed by the indices corresponding to S = {xt,b}b=2.", "startOffset": 83, "endOffset": 86}, {"referenceID": 9, "context": "The reason to believe this is well-founded as indeed sampling from k-DPPs results in better results, in both theory and practice, for low-rank matrix approximation [10] and exemplar-selection for Nystrom methods [20].", "startOffset": 164, "endOffset": 168}, {"referenceID": 19, "context": "The reason to believe this is well-founded as indeed sampling from k-DPPs results in better results, in both theory and practice, for low-rank matrix approximation [10] and exemplar-selection for Nystrom methods [20].", "startOffset": 212, "endOffset": 216}, {"referenceID": 8, "context": "In particular, the methods we consider are BUCB [9], B-EST, UCB-PE/UCBDPP-MAX [8], EST-PE/EST-DPP-MAX, UCB-DPP-SAMPLE, EST-DPP-SAMPLE and UCB with local penalization (LP-UCB) [11].", "startOffset": 48, "endOffset": 51}, {"referenceID": 7, "context": "In particular, the methods we consider are BUCB [9], B-EST, UCB-PE/UCBDPP-MAX [8], EST-PE/EST-DPP-MAX, UCB-DPP-SAMPLE, EST-DPP-SAMPLE and UCB with local penalization (LP-UCB) [11].", "startOffset": 78, "endOffset": 81}, {"referenceID": 10, "context": "In particular, the methods we consider are BUCB [9], B-EST, UCB-PE/UCBDPP-MAX [8], EST-PE/EST-DPP-MAX, UCB-DPP-SAMPLE, EST-DPP-SAMPLE and UCB with local penalization (LP-UCB) [11].", "startOffset": 175, "endOffset": 179}, {"referenceID": 0, "context": "For LP-UCB, we use the publicly available GPyOpt codebase 3 and implemented the MCMC algorithm by [1] for k-DPP sampling with = 0.", "startOffset": 98, "endOffset": 101}, {"referenceID": 27, "context": "Furthermore, as shown in the experiments in [28], PPES is very slow and does not scale beyond batch sizes of 4-5.", "startOffset": 44, "endOffset": 48}, {"referenceID": 3, "context": "Since UCB-PE almost always performs better than the simulation matching algorithm of [4] in all experiments that we could find in previous papers [28, 8], we forego a comparison against simulation matching as well to avoid clutter in the graphs.", "startOffset": 85, "endOffset": 88}, {"referenceID": 27, "context": "Since UCB-PE almost always performs better than the simulation matching algorithm of [4] in all experiments that we could find in previous papers [28, 8], we forego a comparison against simulation matching as well to avoid clutter in the graphs.", "startOffset": 146, "endOffset": 153}, {"referenceID": 7, "context": "Since UCB-PE almost always performs better than the simulation matching algorithm of [4] in all experiments that we could find in previous papers [28, 8], we forego a comparison against simulation matching as well to avoid clutter in the graphs.", "startOffset": 146, "endOffset": 153}, {"referenceID": 20, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including Branin-Hoo [21], a mixture of cosines [2] and the Hartmann-6 function [21].", "startOffset": 105, "endOffset": 109}, {"referenceID": 1, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including Branin-Hoo [21], a mixture of cosines [2] and the Hartmann-6 function [21].", "startOffset": 132, "endOffset": 135}, {"referenceID": 20, "context": "Our first set of experiments is on a set of synthetic benchmark objective functions including Branin-Hoo [21], a mixture of cosines [2] and the Hartmann-6 function [21].", "startOffset": 164, "endOffset": 168}, {"referenceID": 35, "context": "The first function we consider, robot, returns the walking speed of a bipedal robot [36].", "startOffset": 84, "endOffset": 88}, {"referenceID": 0, "context": "The function\u2019s input parameters, which live in [0, 1], are the robot\u2019s controller.", "startOffset": 47, "endOffset": 53}, {"referenceID": 7, "context": "The second function, Abalone is a test function used in [8].", "startOffset": 56, "endOffset": 59}, {"referenceID": 7, "context": "Similar to [8], we will use it as a maximization problem.", "startOffset": 11, "endOffset": 14}, {"referenceID": 23, "context": "A recent popular approach for extreme classification is the FastXML algorithm [24].", "startOffset": 78, "endOffset": 82}, {"referenceID": 23, "context": "Our task is to perform hyper-parameter optimization on these 5 hyper-parameters with the aim to maximize the Precision@k for k = 1, which is the metric used in [24] to evaluate the performance of FastXML compared to other algorithms as well.", "startOffset": 160, "endOffset": 164}, {"referenceID": 23, "context": "While the authors of [24] run extensive tests on a variety of datasets, we focus on two small datasets : Bibtex [15] and Delicious[33].", "startOffset": 21, "endOffset": 25}, {"referenceID": 14, "context": "While the authors of [24] run extensive tests on a variety of datasets, we focus on two small datasets : Bibtex [15] and Delicious[33].", "startOffset": 112, "endOffset": 116}, {"referenceID": 32, "context": "While the authors of [24] run extensive tests on a variety of datasets, we focus on two small datasets : Bibtex [15] and Delicious[33].", "startOffset": 130, "endOffset": 134}], "year": 2016, "abstractText": "Gaussian Process bandit optimization has emerged as a powerful tool for optimizing noisy black box functions. One example in machine learning is hyper-parameter optimization where each evaluation of the target function requires training a model which may involve days or even weeks of computation. Most methods for this so-called \u201cBayesian optimization\u201d only allow sequential exploration of the parameter space. However, it is often desirable to propose batches or sets of parameter values to explore simultaneously, especially when there are large parallel processing facilities at our disposal. Batch methods require modeling the interaction between the different evaluations in the batch, which can be expensive in complex scenarios. In this paper, we propose a new approach for parallelizing Bayesian optimization by modeling the diversity of a batch via Determinantal point processes (DPPs) whose kernels are learned automatically. This allows us to generalize a previous result as well as prove better regret bounds based on DPP sampling. Our experiments on a variety of synthetic and real-world robotics and hyper-parameter optimization tasks indicate that our DPP-based methods, especially those based on DPP sampling, outperform state-of-the-art methods.", "creator": "LaTeX with hyperref package"}}}