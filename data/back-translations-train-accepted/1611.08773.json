{"id": "1611.08773", "review": {"conference": "AAAI", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Nov-2016", "title": "Embedded Bandits for Large-Scale Black-Box Optimization", "abstract": "Random embedding has been applied with empirical success to large-scale black-box optimization problems with low effective dimensions. This paper proposes the EmbeddedHunter algorithm, which incorporates the technique in a hierarchical stochastic bandit setting, following the optimism in the face of uncertainty principle and breaking away from the multiple-run framework in which random embedding has been conventionally applied similar to stochastic black-box optimization solvers. Our proposition is motivated by the bounded mean variation in the objective value for a low-dimensional point projected randomly into the decision space of Lipschitz-continuous problems. In essence, the EmbeddedHunter algorithm expands optimistically a partitioning tree over a low-dimensional---equal to the effective dimension of the problem---search space based on a bounded number of random embeddings of sampled points from the low-dimensional space. In contrast to the probabilistic theoretical guarantees of multiple-run random-embedding algorithms, the finite-time analysis of the proposed algorithm presents a theoretical upper bound on the regret as a function of the algorithm's number of iterations. Furthermore, numerical experiments were conducted to validate its performance. The results show a clear performance gain over recently proposed random embedding methods for large-scale problems, provided the intrinsic dimensionality is low.", "histories": [["v1", "Sun, 27 Nov 2016 02:18:09 GMT  (320kb,D)", "http://arxiv.org/abs/1611.08773v1", "To appear at AAAI 2017"]], "COMMENTS": "To appear at AAAI 2017", "reviews": [], "SUBJECTS": "cs.AI math.OC", "authors": ["abdullah al-dujaili", "sundaram suresh"], "accepted": true, "id": "1611.08773"}, "pdf": {"name": "1611.08773.pdf", "metadata": {"source": "CRF", "title": "Embedded Bandits for Large-Scale Black-Box Optimization", "authors": ["Abdullah Al-Dujaili", "S. Suresh"], "emails": ["aldujail001@e.ntu.edu.sg,", "ssundaram@ntu.edu.sg"], "sections": [{"heading": "Introduction", "text": "The question is whether and to what extent the USA, the EU, the USA, the EU, the USA, the USA, the EU, the USA, the USA, the USA, the USA, the USA, the USA, the EU, the USA, the USA, the USA, the EU, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the USA, the"}, {"heading": "Optimistic Optimization Meets Random Embeddings", "text": "Optimistic methods, i.e. methods that implement optimism in the face of uncertainty, have proven to be practicable for black box optimization, a principle that finds its basis in the machine learning field, where the exploration vs. exploitation dilemma known as the multiarming bandit problem is found. In the context of functional optimization, optimistic approaches formulate the complex problem of optimization (1) over space X as a hierarchy of simple bandit problems (Kocsis and Szepesva) in the form of the spatial partition tree search. In step t, the algorithm optimistically expands a lead node (partitions containing the corresponding subspace) that can contain the global optimum. Previous empirical methods have shown that optimistic methods - e.g. SOO (Munos 2011) and NMSO (Al-Dujaili and Suresh 2016) - are not suitable for high-dimensional problems."}, {"heading": "EMBEDDEDHUNTER", "text": "The hierarchical division can be represented by a K-ary tree T, in which nodes of the same depth h correspond to a partition of Kh subspaces / cells. (i.e.) The ith node at depth h, denoted by (h, i), corresponds to the subspace / cell Yh, i such that Y = 0 \u2264 i < KhYh, i), is assigned to each node (h, i), a base point yh, i (center of Yh), at which f is evaluated once or more. That is to say, for each new assessment of the node (h, i), i, i is randomly projected at f-level."}, {"heading": "Theoretical Analysis", "text": "In this section we analyze the performance of the EMBEDDEDHUNTER algorithms and the associated optimal execution possibilities (2). To derive from this a measure of the quantity of the approximate optimal points, we must leave the number of -optimal points such as Y def = y Y def = y-minp gp = y-minp gp = y-minp gp (y-minp gp) and leave g (Y) def = [f-minp gp = y-minp) and g (Y) def = y-minp gp (y)."}, {"heading": "Empirical Analysis", "text": "In this section, the effectiveness of the proposed method is empirically validated."}, {"heading": "Conclusion", "text": "In this paper, the EMBEDDEDHUNTER algorithm was presented, a different approach to random embedding in large-scale black box optimizations. While the majority of the random embedding techniques in literature use the multiple-run paradigm, which scans a new random projection for each run to maximize probable convergence with the optimal solution, EMBEDDEDHUNTER seeks the optimal solution by building stochastic hierarchical bandits (so-called trees) over a low-dimensional search space Y, in which stochasticity has been shown to be on average proportional to the standard of the base points of the nodes. EMBEDDEDHUNTER's distinctive advantage is that its search tree implicitly classifies the Y regions across its depth / standard-wise visits and distributes the assessment budget accordingly. In fact, other algorithms (e.g. RESODHUNTER) can reserve the center of its EMBEVER function as a zero-based VER."}, {"heading": "A.3 On the Generality of Assumption 1", "text": "The class of functions fulfilling the Lipschitz condition is very broad. Indeed, in [2, 1] it has been shown that among the Lipschitz continuous functions all convex / concave functions are extended over a closed domain and continuously differentiable functions. [4] Visual description and proof of Lemma 1 Consider Figure 1, where all nodes in depth h = 0 have been expanded with the loss of generality. It can be seen that if all nodes in Im1 (1) 1 have been expanded, then in later iterations at depth h = 1 node at depth h = 1\\ Im1 (1) 1. Consequently, before iterations at depth h = 2, the minimum value in Im1\u043c (1) 1 is f, the depth m1\u043c (1)."}, {"heading": "A.5 Proof of Lemma 2", "text": "Lemma 2. Leave the depth h = 0, hmax}, we have the proof. The proof is provided by contradiction. To this end, we assume that there are some h = 0, hmax} which are defined in such a way that | Im \u00b2 (h) h | > C (m \u00b2 (h) \u2212 d \u00b2. On the one hand, the definition 23 of Im \u00b2 (h) h indicates that their starting points are in Ym \u00b2 (h). On the other hand, assumption 3 of the main paper indicates that cells of nodes at depth h contain a sphere of radius m \u00b2 (h) = mm \u00b2 \u00b7 m \u00b2 (h). Since the cells are separated and emerge from definition 2 of the main paper, we have a contradiction that d \u00b2 is the m / m \u00b2 near optimum dimension."}, {"heading": "A.6 Proof of Theorem 2", "text": "Theorem 2. (r (t) for EMBEDDEDHUNTER) We define h (t) as the smallest h \u2265 0, so that the regret of EMBEDDEDHUNTER is limited as follows: r (t) \u2264 l = 0 (m \u00b2 (l) \u2212 d \u00b2 (h (t), where t is the number of iterations. (3) Proof. From the definition of h (t) and Lemma 2 results in a limit to th (t) \u2212 1 of equation (1), which can be spelled as follows. th (t) \u2212 1 = hmaxh (t) \u2212 1 = hmaxh (t), l = 0 | Im (l) l \u00b2 (l) l | \u2264 Chmax h (t) \u2212 1 l = 0 (m \u00b2 h) < t. Then results by Lemma 1 (t) \u2212 1 = hmaxh (t) and the fact that the best (l) l \u00b2 h \u00b2 h \u00b2 (n), Chmax h = 0 (m \u00b2), h \u00b2, h, h \u00b2 h, h, h, h \u00b2 h, h, h, h, h, h, h, h, h, h, \u00b2 h, h, h, h, h, h, h, h, h, h, h, \u00b2, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h \u00b2, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h, h \u00b2, h, h, h, h, h, h, h, h, h, h, h,"}], "references": [{"title": "Modifications of the Direct Algorithm", "author": ["J.M. Gablonsky"], "venue": "PhD thesis, North Carolina State University,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2001}, {"title": "Global optimization in action: continuous and Lipschitz optimization: algorithms, implementations and applications, volume 6", "author": ["J\u00e1nos Pint\u00e9r"], "venue": "Springer Science & Business Media,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 1995}], "referenceMentions": [], "year": 2016, "abstractText": "Random embedding has been applied with empirical success to large-scale black-box optimization problems with low effective dimensions. This paper proposes the EMBEDDEDHUNTER algorithm, which incorporates the technique in a hierarchical stochastic bandit setting, following the optimism in the face of uncertainty principle and breaking away from the multiple-run framework in which random embedding has been conventionally applied similar to stochastic black-box optimization solvers. Our proposition is motivated by the bounded mean variation in the objective value for a low-dimensional point projected randomly into the decision space of Lipschitz-continuous problems. In essence, the EMBEDDEDHUNTER algorithm expands optimistically a partitioning tree over a low-dimensional\u2014equal to the effective dimension of the problem\u2014search space based on a bounded number of random embeddings of sampled points from the low-dimensional space. In contrast to the probabilistic theoretical guarantees of multiple-run randomembedding algorithms, the finite-time analysis of the proposed algorithm presents a theoretical upper bound on the regret as a function of the algorithm\u2019s number of iterations. Furthermore, numerical experiments were conducted to validate its performance. The results show a clear performance gain over recently proposed random embedding methods for large-scale problems, provided the intrinsic dimensionality is low. Introduction Problem. This paper is concerned with the large-scale black-box optimization problem given a finite number of function evaluations. Mathematically, the problem has the form: minimize f(x) subject to x \u2208 X , (1) where f : X \u2286 R \u2192 R and n 10. Without loss of generality, it is assumed that X = [\u22121, 1], and there exists at least one global optimizer x\u2217 whose objective value is denoted by f\u2217, i.e., minx\u2208X f(x) = f(x\u2217) = f\u2217. Solving the optimization problem (1) is notoriously difficult as the sole source of information about its objective function f is available through a black-box or an oracle, which one can query Copyright c \u00a9 2017, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. for the value of f at a specific solution (point ) x \u2208 X . Highorder information (e.g., derivatives) are unavailable symbolically nor numerically or are tedious to compute compared to zero-order information\u2014i.e., point-wise function evaluations. Thus, the task is to find the (or one) optimal solution x\u2217 \u2208 X to (1) or a good approximation using a finite number v of function evaluations, which is commonly referred to as the evaluation budget. The quality of the returned solution x(v) \u2208 X after v function evaluations, denoted by f\u2217 v , is assessed by the regret, r(v) = f\u2217 v \u2212 f\u2217 . (2) Besides the aforementioned challenging nature of black-box problems, the high dimensionality n of the decision space X poses another challenge towards finding the global optimum. Despite their witnessed success, the effectiveness of most black-box optimization algorithms is restricted to moderate dimensions (typically, n < 100) and they do not scale well to high-dimensional (say, n 10) problems. As the dimensionality increases, the number of evaluations (sampled points) required to cover X increases exponentially. Despite the curse of dimensionality, it has been noted that for artificial intelligence (AI) applications, most dimensions of certain classes of the associated optimization problems do not affect the objective function significantly. In other words, such problems have low effective dimensionality, e.g., hyper-parameter optimization for neural and deep belief networks (Bergstra and Bengio 2012). Related Work. The literature on black-box optimization is huge and we only highlight here works that are closely related to the paper\u2019s contribution. The bulk of algorithmic work on large-scale black-box optimization has been following one of two approaches: decomposition and embedding. Decomposition algorithms break the problem into several subproblems, and solutions for the original problem are recognized in a coordinated manner. In (Kandasamy, Schneider, and P\u00f3czos 2015), Bayesian optimization was scaled to high-dimensional problems whose objectives have an additive structure. i.e., the function f is the sum of several sub-functions with smaller dimensions, such that no two sub-functions share one or more variables. On the other hand, Friesen and Domingos (2015) proposed to decompose the function into approximately locally independent sub-functions and optimize them separately. Chen et ar X iv :1 61 1. 08 77 3v 1 [ cs .A I] 2 7 N ov 2 01 6 al. (2010) addressed interdependent sub-functions and proposed to consider all entries of the decision vector x independent and discover their relations gradually. In general, decomposition methods employ axis-aligned decomposability, which may limit their applicability. Embedding algorithms exploit the assumption/empirical observation of low effective dimensionality. Chen, Krause, and Castro (2012) presented a variable selection method to discover the effective axis-aligned subspace, while Djolonga, Krause, and Cevher (2013) sought to learn the effective subspace using a low-rank matrix recovery technique. In (Carpentier, Munos, and others 2012), compressed sensing was applied to deal with linear-bandit problems with a high degree of sparsity. Recent works\u2014motivated by the empirical success of random search in leveraging low effective dimensionality without knowing which variables are important (Bergstra and Bengio 2012)\u2014presented random embedding techniques based on the random matrix theory (Wang et al. 2013; Kaban, Bootkrajang, and Durrant 2013) and provided probabilistic theoretical guarantees. In (Qian and Yu 2016), the Simultaneous Optimistic Optimization (SOO) algorithm (Munos 2011) was scaled via random embedding. Problems, whose all dimensions are effective but many of them have a small bounded effect, were addressed in (Qian, Hu, and Yu 2016) where the random embedding technique was incorporated in a sequential framework. In general, random embedding methods employ multiple runs to substantiate the probabilistic theoretical performance. Our Contributions. This paper aims to tackle large-scale black-box optimization (1) based on the random embedding technique. Previous propositions put the technique in a framework of multiple runs\u2014be it parallel (Qian and Yu 2016) or sequential (Qian, Hu, and Yu 2016)\u2014to maximize the performance guarantee. In this paper, we seek to break away from the multiple-run framework and follow the optimism in the face of uncertainty principle, or so-called optimistic optimization. To this end, we incorporate the random embedding technique in a stochastic hierarchical bandit setting and present EMBEDDEDHUNTER: an algorithmic instance of the sought approach. Similar to other optimistic methods, EMBEDDEDHUNTER iteratively expands a partitioning tree over a low-dimensional space Y based on randomly projecting sampled points to the original highdimensional space X once or more times. This approach is motivated by the proof that the mean variation in the objective function f value for a point y \u2208 Y projected randomly to f \u2019s decision spaceX is bounded for objective functions that are Lipschitz-continuous. EMBEDDEDHUNTER\u2019s regret (2) is upper bounded in terms of the number of iterations required to expand near-optimal nodes in the (effective) low-dimensional space based on the Lipschitz continuity assumption and that random embedding can preserve local distance. The rest of the paper is organized as follows. First, a formal motivation is presented, followed by an introduction to EMBEDDEDHUNTER. Then, the algorithm\u2019s finite-time performance is studied and complemented by an empirical validation. Towards the end, the paper is concluded. Optimistic Optimization Meets Random Embeddings Optimistic methods, i.e., methods that implement the optimism in the face of uncertainty principle have proved to be viable for black-box optimization. Such a principle finds its foundations in the machine learning field addressing the exploration-vs.-exploitation dilemma, known as the multi-armed bandit problem. Within the context of function optimization, optimistic approaches formulate the complex problem of optimization (1) over the space X as a hierarchy of simple bandit problems (Kocsis and Szepesv\u00e1ri 2006) in the form of space-partitioning tree search. At step t, the algorithm optimistically expands a leaf node (partitions the corresponding subspace) that may contain the global optimum. Previous empirical studies have shown that optimistic methods\u2014e.g., SOO (Munos 2011) and NMSO (Al-Dujaili and Suresh 2016)\u2014are not suitable for problems with high dimensionality. Random embedding has emerged as a practical tool for large-scale optimization with an experimental success and probabilistic theoretical guarantees. It assumes the problem (1) has an implicit low effective dimension d much lower than the explicit (original) dimension n. In essence, for an optimizer x\u2217 \u2208 X = [\u22121, 1] and a random matrix A \u2208 Rn\u00d7d whose entries are sampled independently from a normal distribution, there exists a point y\u2217 \u2208 Y = [\u2212d/\u03b7, d/\u03b7] such that its Euclidean random projection to X , PX (Ay\u2217), is x\u2217 with a probability at least 1 \u2212 \u03b7 where \u03b7 \u2208 (0, 1). That is to say, f(PX (Ay\u2217)) = f(x\u2217) = f\u2217. The Euclidean random projection of the ith coordinate [y]i to [X ]i is defined as follows.", "creator": "LaTeX with hyperref package"}}}