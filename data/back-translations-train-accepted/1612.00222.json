{"id": "1612.00222", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Dec-2016", "title": "Interaction Networks for Learning about Objects, Relations and Physics", "abstract": "Reasoning about objects, relations, and physics is central to human intelligence, and a key goal of artificial intelligence. Here we introduce the interaction network, a model which can reason about how objects in complex systems interact, supporting dynamical predictions, as well as inferences about the abstract properties of the system. Our model takes graphs as input, performs object- and relation-centric reasoning in a way that is analogous to a simulation, and is implemented using deep neural networks. We evaluate its ability to reason about several challenging physical domains: n-body problems, rigid-body collision, and non-rigid dynamics. Our results show it can be trained to accurately simulate the physical trajectories of dozens of objects over thousands of time steps, estimate abstract quantities such as energy, and generalize automatically to systems with different numbers and configurations of objects and relations. Our interaction network implementation is the first general-purpose, learnable physics engine, and a powerful general framework for reasoning about object and relations in a wide variety of complex real-world domains.", "histories": [["v1", "Thu, 1 Dec 2016 12:34:54 GMT  (1488kb,D)", "http://arxiv.org/abs/1612.00222v1", "Published in NIPS 2016"]], "COMMENTS": "Published in NIPS 2016", "reviews": [], "SUBJECTS": "cs.AI cs.LG", "authors": ["peter w battaglia", "razvan pascanu", "matthew lai", "danilo jimenez rezende", "koray kavukcuoglu"], "accepted": true, "id": "1612.00222"}, "pdf": {"name": "1612.00222.pdf", "metadata": {"source": "CRF", "title": "Interaction Networks for Learning about Objects, Relations and Physics", "authors": ["Peter W. Battaglia", "Razvan Pascanu"], "emails": ["peterbattaglia@google.com", "razp@google.com", "matthewlai@google.com", "danilor@google.com", "korayk@google.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, most people who are able to move, to move and to move, to move, to move, to move, to move, to move, to move, to move and to move, to move, to move and to move, to move and to move, to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move and to move, to move, to move and to move."}, {"heading": "2 Model", "text": "(Definition) To describe our model, we use physical thinking as an example (fig. 1a), and build from a simple model on the whole interaction network (abbreviated to IN). To predict the dynamics of a single object, one could use an object-centric function that represents the state of the object at a different time and outputs a future state, ot + 1. If two or more objects are governed by the same dynamics, one could apply fO independently to each object to predict their respective future states, but if the objects interact with each other, then fO is insufficient because it does not capture their relationship. If one assumes two objects and a directed relationship, a fixed object can be attached to a freely moving mass, the first (the sender, o1) influences the second (the receiver, o2) through its interaction. The effect of this interaction, et 1, can be predicted by a relationship."}, {"heading": "3 Experiments", "text": "In fact, it is such that most of them will be able to move to another world, in which they will be able to move to another world, in which they will be able to move to another world, in which they will be able to move, in which they will move, in which they will move, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which they will live, in which will live, in which they will live, in which they will live, in which they will live, in which they will live, in which will live, in which will live, in which they will live, in which they will live, in which they will live, in which they will live, in which"}, {"heading": "4 Results", "text": "The results show that the IN can predict the dynamics of our tasks very accurately after training, with orders of magnitude lower test errors than the alternative models (Fig. 3a, d and g, and Table 2). Since the dynamics of each domain depends crucially on interactions between objects, the IN was able to learn to use these relationships for its predictions. The dynamics-only IN had no mechanism for processing interactions and led similarly to the constant velocity model. The connectivity of the MLP makes it possible to learn the interactions, but that would require learning how to use the relationship indices to process their relationships."}, {"heading": "5 Discussion", "text": "We have introduced interaction networks as a flexible and efficient model for explicitly looking at objects and relationships in complex systems, and our results provide surprisingly strong evidence of their ability to learn precise physical simulations and generalize their training to new systems with different numbers and configurations of objects and relationships. The alternative models we have tested have made bigger mistakes. Simulation using rich mental models is seen as a crucial mechanism for how people think about physics and other complex domains [5, 12, 10], and Battaglia et al."}, {"heading": "A Supplementary material", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Experimental details", "text": "A.1.1 Physics Engine DetailsEach simulated trajectory contained the states of the objects in the system in each frame of a sequence of 1000 time steps in the millisecond range. The parameters of each system were chosen in such a way that a varied series of dynamics could unfold within the trajectory. At each step, the physics engine took as input the current state of the system, calculated the forces associated with each interaction between the units, and applied them as accelerations to the individual units by dividing by the mass of the entity, parameterized as inverse mass, a = Fm \u2212 1 in both the motor and the model input. Thus, static objects can be represented as m \u2212 1 = 0. Previous positions and speeds and recalculated accelerations were entered into an Euler integrator to update the current speeds and positions of the entities."}, {"heading": "A.1.2 Physical domains", "text": "In fact, most of them will be able to put themselves in a situation where they are facing themselves and their fellow human beings."}, {"heading": "A.2 Results details", "text": "The generalization power of the MSE of the prediction experiment is shown in Table 3. Links to the videos associated with all stills in Figure 2 are shown in Table 1."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "Reasoning about objects, relations, and physics is central to human intelligence, and<lb>a key goal of artificial intelligence. Here we introduce the interaction network, a<lb>model which can reason about how objects in complex systems interact, supporting<lb>dynamical predictions, as well as inferences about the abstract properties of the<lb>system. Our model takes graphs as input, performs objectand relation-centric<lb>reasoning in a way that is analogous to a simulation, and is implemented using<lb>deep neural networks. We evaluate its ability to reason about several challenging<lb>physical domains: n-body problems, rigid-body collision, and non-rigid dynamics.<lb>Our results show it can be trained to accurately simulate the physical trajectories of<lb>dozens of objects over thousands of time steps, estimate abstract quantities such<lb>as energy, and generalize automatically to systems with different numbers and<lb>configurations of objects and relations. Our interaction network implementation<lb>is the first general-purpose, learnable physics engine, and a powerful general<lb>framework for reasoning about object and relations in a wide variety of complex<lb>real-world domains.", "creator": "LaTeX with hyperref package"}}}