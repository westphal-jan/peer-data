{"id": "1612.01010", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Dec-2016", "title": "DeepBach: a Steerable Model for Bach Chorales Generation", "abstract": "The composition of polyphonic chorale music in the style of J.S Bach has represented a major challenge in automatic music composition over the last decades. The art of Bach chorales composition involves combining four-part harmony with characteristic rhythmic patterns and typical melodic movements to produce musical phrases which begin, evolve and end (cadences) in a harmonious way. To our knowledge, no model so far was able to solve all these problems simultaneously using an agnostic machine-learning approach. This paper introduces DeepBach, a statistical model aimed at modeling polyphonic music and specifically four parts, hymn-like pieces. We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach. We evaluate how indistinguishable our generated chorales are from existing Bach chorales with a listening test. The results corroborate our claim. A key strength of DeepBach is that it is agnostic and flexible. Users can constrain the generation by imposing some notes, rhythms or cadences in the generated score. This allows users to reharmonize user-defined melodies. DeepBach's generation is fast, making it usable for interactive music composition applications. Several generation examples are provided and discussed from a musical point of view.", "histories": [["v1", "Sat, 3 Dec 2016 19:17:29 GMT  (1459kb,D)", "http://arxiv.org/abs/1612.01010v1", "20 pages, 11 figures"], ["v2", "Sat, 17 Jun 2017 17:25:58 GMT  (2839kb,D)", "http://arxiv.org/abs/1612.01010v2", "10 pages, ICML2017 version"]], "COMMENTS": "20 pages, 11 figures", "reviews": [], "SUBJECTS": "cs.AI cs.SD", "authors": ["ga\u00ebtan hadjeres", "fran\u00e7ois pachet", "frank nielsen"], "accepted": true, "id": "1612.01010"}, "pdf": {"name": "1612.01010.pdf", "metadata": {"source": "CRF", "title": "DeepBach: a Steerable Model for Bach chorales generation", "authors": ["Ga\u00ebtan Hadjeres", "Fran\u00e7ois Pachet"], "emails": ["gaetan.hadjeres@etu-upmc.fr", "pachetcsl@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "This year, there will be a realignment in which there will be a realignment."}, {"heading": "2 DeepBach", "text": "In this article we present a new generative model that takes into account the distinction between voices. Section 2.1 shows how we pre-processed the corpus of Bach chorale harmonies, and Section 2.2 presents the architecture of the model."}, {"heading": "2.1 Data Representation", "text": "We represent a chorale as a tuple of six lists (V1, V2, V3, V4, S, F), (1) where the Vi represents the four voices (soprano, alto, tenor and bass), to which we add two more lists: S the list of Bach subdivisions and F the list of fermata. All lists are indexed by a time index t and have the same size. Since Bach chorales contain only single bar frequencies, we discredit the time with sixteenth notes, which means that each bar is divided into four equal parts. Since there is no smaller subdivision in Bach choirs, there is no loss of information in this process. Since each voice Vi contains the midi pitch of the notes played, it is a unique integer for each note, without distinction between harmonic equivalent notes. To represent the rhythm in a compact way, we insert an additional symbol for the pitches that encode whether the preceding note is held or not."}, {"heading": "2.2 Model Architecture", "text": "For clarification, we assume in this section that our data set consists of only one chorale as described in Eq.1. We introduce a family of probability models p, which is parameterized by a parameter \u03b8 on our representation defined in paragraph 2.1. We do not model the sequences S or F probabilistically, but consider them fixed. Thus, the negative probability of our data is defined by \u2212 log p (V1, V2, V3, V4 | S, F, \u03b8). (2) We must find a parameter that minimizes this loss. In order to have a mathematically comprehensible training criterion, we introduce the pseudo-probability of our data [7,4]. This approach has been successful in many real problems [14] and consists of approximating the negative protocol probability of these models."}, {"heading": "2.3 Generation", "text": "In our case, this consists of the following algorithm: Algorithm 1 Gibbs sampling requirement: chorale length L, lists S and F of length L, probability distributions (P1, P2, P3, P4), maximum number of iterations M1: Create four lists (V1, V2, V3, V4) of length L. The lists are often initialized with random values drawn from the ranges of corresponding voices 2: for 1 to M do 3: Choose voice i uniformally between 1 and 4 4: Choose time t uniformally between 1 and L 5: Re-sample Vti from Vti\\ i, t, S, F, mode of action i) 6: End-Forreturn (V1, V2, V3, V4, V4: The advantage of this method is that we can enforce user-defined constraints by tweets."}, {"heading": "2.4 Implementation Details", "text": "We implemented DeepBach using Keras [9] with the tensor flow [1] backend. We used the J.S. Bach Choral Harmonization Database, which is included in the music21 [11] toolkit. After removing chorals with instrumental voices and chorals that contain parts with two simultaneous notes (bass voices sometimes split for the last chord), we arrived at 352 pieces. In contrast to other approaches, which transpose all chorals into the same key (usually in C major or A minor), we choose to expand our data set by adding all chorale transpositions that lie within the pitches defined by the source body. Thus, we obtain a corpus of 2503 chorales and divide it between a training set (80%) and a validation set (20%). The vocal ranges contain less than 30 different pitches for each voice (21, 21, 21, 28, and the soprano voices)."}, {"heading": "3 Experimental Results", "text": "We are now evaluating the quality of our model with two experiments: an online test conducted on human listeners, and an analysis of plagiarism in chorales created by DeepBach.9."}, {"heading": "3.1 Listening Test", "text": "In fact: it is not that men are able to save themselves, and that they are not able to save themselves. (...) It is not that men are able to save themselves. (...) It is not that men are able to save themselves. (...) It is not that men are able to save themselves. (...) It is as if men were able to save themselves. (...) It is as if men were able to save themselves. (...) It is as if men were able to save themselves. (...) It is as if men were able to save themselves. (...) It is as if men were able to save themselves. (...) It is as if men were able to save themselves. (...) It is as if men were able to save themselves. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (...) It is. (it is. (...) It is. (it is. (...) It is. (it is. (...) It is. (it is. (...) It is. (it is. (it is.) It is. (it is. (it is. (it is.). (it is. It is. (it is.). (it is. (it is.). (it is. (it is. (it is.). (it is.). (it is. (it is.). (it is. (it is. (it is.). (it is. It is. (it. (it is.). (it is. (it is.). (it is. (it is.). (it is. (it is.). (it is."}, {"heading": "3.2 Plagiarism Analysis", "text": "We evaluate the creativity and originality of DeepBach's productions. We use it as a benchmark for plagiarism, for a particular chorale, for the length of the longest choreography to be found identically in our curriculum. Fig 8 shows histograms of this quantity for three different cases: - 50 original (non-transposed) J.S. Bach chorales from the test set. - 50 chorales (of the same length as the above) produced by DeepBach without restrictions. - 50 reharmonizations of DeepBach, where the soprano is limited to the same 50 J.S. Bach chorales."}, {"heading": "4 Commented examples", "text": "In fact, it is the case that one sees oneself in a position to go in search of a solution that does justice to people's interests. (...) In fact, it is not the case that one sees oneself in a position to go in search of solutions. (...) In fact, it is the case that one has to go in search of solutions. (...) In fact, it is the case that one has to go in search of solutions. (...) In fact, it is the case that one has to go in search of solutions. (...) In fact, it is the case that one has to go in search of solutions. (...) (...) (...) () (...) () () (...) () () () (...) () () () ()) (...) () ()) (...) () ()) (...) ()) (()) (())) (())) (() ())) (()) () () () ()) () ()) () ()) () () ()) ()) () () ()) () () ()) ()) () ()) () ()) () ()) () ()) () ()) ()) () ()) ()) () ()) () ()) ()) () ()) ()) () ()) () ()) () ()) () () () () () ()) () ()) () () ()) () () ()) () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ()) () () () () ()) () () ("}, {"heading": "5 Discussion and future work", "text": "We have described DeepBach, a probabilistic model combined with a sampling method that is flexible and efficient and delivers musically compelling results even for professional ears. We believe that the strength of our method is the ability to impose simple limitations on the user, which is often neglected in probabilistic music models. We have shown that DeepBach does not suffer from plagiarism, while it can be reproduced and used to create musically compelling harmonies in J.S. Bach's style. We now plan to develop a graphical music editor on top of the music21 toolkit to facilitate interactive composition with DeepBach. This method is not only applicable to Bach chorales, but covers a wide range of polyphonic choral music, from Palestrina to Take 6."}, {"heading": "Acknowledgment", "text": "We would like to thank Emmanuel Deruty for the audio rendering part, Jason Sakellariou for the fruitful discussions and Frank Nielsen for his helpful comments. This research is being carried out as part of the Flow Machines project funded by the European Research Council under the Seventh Framework Programme of the European Union (FP / 2007-2013) / ERC Funding Agreement No. 291156.19."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems (2015), http://tensorflow.org/, software available from tensorflow.org", "author": ["M. Abadi", "A. Agarwal", "P. Barham", "E. Brevdo", "Z. Chen", "C. Citro", "G.S. Corrado", "A. Davis", "J. Dean", "M. Devin", "S. Ghemawat", "I. Goodfellow", "A. Harp", "G. Irving", "M. Isard", "Y. Jia", "R. Jozefowicz", "L. Kaiser", "M. Kudlur", "J. Levenberg", "D. Man\u00e9", "R. Monga", "S. Moore", "D. Murray", "C. Olah", "M. Schuster", "J. Shlens", "B. Steiner", "I. Sutskever", "K. Talwar", "P. Tucker", "V. Vanhoucke", "V. Vasudevan", "F. Vi\u00e9gas", "O. Vinyals", "P. Warden", "M. Wattenberg", "M. Wicke", "Y. Yu", "X. Zheng"], "venue": null, "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Categorical Data Analysis, pp. 206\u2013208", "author": ["A. Agresti", "M. Kateri"], "venue": null, "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2011}, {"title": "Harmonising chorales by probabilistic inference", "author": ["M. Allan", "C.K. Williams"], "venue": "Advances in neural information processing systems 17, 25\u201332", "citeRegEx": "3", "shortCiteRegEx": null, "year": 2005}, {"title": "Pseudolikelihood estimation: some examples", "author": ["B.C. Arnold", "D. Strauss"], "venue": "Sankhy\u0101: The Indian Journal of Statistics, Series B pp. 233\u2013243", "citeRegEx": "4", "shortCiteRegEx": null, "year": 1991}, {"title": "Chorales (Choral-Gesange): SATB (German Language Edition)", "author": ["J. Bach"], "venue": "Kalmus Classic Edition, Alfred Publishing Company", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1985}, {"title": "Music in Theory and Practice Volume 1", "author": ["B. Benward"], "venue": "McGraw-Hill Higher Education", "citeRegEx": "6", "shortCiteRegEx": null, "year": 2014}, {"title": "Statistical analysis of non-lattice data", "author": ["J. Besag"], "venue": "The statistician pp. 179\u2013195", "citeRegEx": "7", "shortCiteRegEx": null, "year": 1975}, {"title": "Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription", "author": ["N. Boulanger-lewandowski", "Y. Bengio", "P. Vincent"], "venue": "Proceedings of the 29th International Conference on Machine Learning (ICML-12). pp. 1159\u20131166", "citeRegEx": "8", "shortCiteRegEx": null, "year": 2012}, {"title": "Keras", "author": ["F. Chollet"], "venue": "https://github.com/fchollet/keras", "citeRegEx": "9", "shortCiteRegEx": null, "year": 2015}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["J. Chung", "C. Gulcehre", "K. Cho", "Y. Bengio"], "venue": "arXiv preprint arXiv:1412.3555", "citeRegEx": "10", "shortCiteRegEx": null, "year": 2014}, {"title": "music21: A toolkit for computer-aided musicology and symbolic music data", "author": ["M.S. Cuthbert", "C. Ariza"], "venue": null, "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2010}, {"title": "Ensuring rapid mixing and low bias for asynchronous gibbs sampling", "author": ["C. De Sa", "K. Olukotun", "C. R\u00e9"], "venue": "arXiv preprint arXiv:1602.07415", "citeRegEx": "12", "shortCiteRegEx": null, "year": 2016}, {"title": "An expert system for harmonizing four-part chorales", "author": ["K. Ebcioglu"], "venue": "Computer Music Journal 12(3),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 1988}, {"title": "Improved contact prediction in proteins: using pseudolikelihoods to infer potts models", "author": ["M. Ekeberg", "C. L\u00f6vkvist", "Y. Lan", "M. Weigt", "E. Aurell"], "venue": "Physical Review E 87(1), 012707", "citeRegEx": "14", "shortCiteRegEx": null, "year": 2013}, {"title": "Stochastic relaxation, gibbs distributions, and the bayesian restoration of images", "author": ["S. Geman", "D. Geman"], "venue": "IEEE Transactions on pattern analysis and machine intelligence (6), 721\u2013741", "citeRegEx": "15", "shortCiteRegEx": null, "year": 1984}, {"title": "Style imitation and chord invention in polyphonic music with exponential families", "author": ["G. Hadjeres", "J. Sakellariou", "F. Pachet"], "venue": "arXiv preprint arXiv:1609.05152", "citeRegEx": "16", "shortCiteRegEx": null, "year": 2016}, {"title": "Harmonet: A neural net for harmonizing chorales in the style of js bach", "author": ["H. Hild", "J. Feulner", "W. Menzel"], "venue": "Advances in neural information processing systems. pp. 267\u2013274", "citeRegEx": "17", "shortCiteRegEx": null, "year": 1992}, {"title": "Long short-term memory", "author": ["S. Hochreiter", "J. Schmidhuber"], "venue": "Neural computation 9(8), 1735\u20131780", "citeRegEx": "18", "shortCiteRegEx": null, "year": 1997}, {"title": "Trait\u00e9 de l\u2019harmonie: en 3 volumes, vol", "author": ["C. Koechlin"], "venue": "1. Eschig", "citeRegEx": "19", "shortCiteRegEx": null, "year": 1928}, {"title": "Statistical Mechanics: Algorithms and Computations. Oxford Master Series in Physics, Oxford University Press, UK (2006), https://books.google", "author": ["W. Krauth"], "venue": null, "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2006}, {"title": "Constructing long short-term memory based deep recurrent neural networks for large vocabulary speech recognition", "author": ["X. Li", "X. Wu"], "venue": "2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). pp. 4520\u20134524. IEEE", "citeRegEx": "21", "shortCiteRegEx": null, "year": 2015}, {"title": "Bachbot", "author": ["F. Liang"], "venue": "https://github.com/feynmanliang/bachbot", "citeRegEx": "22", "shortCiteRegEx": null, "year": 2016}, {"title": "Modelling high-dimensional sequences with lstm-rtrbm: application to polyphonic music generation", "author": ["Q. Lyu", "Z. Wu", "J. Zhu", "H. Meng"], "venue": "Proceedings of the 24th International Conference on Artificial Intelligence. pp. 4138\u20134139. AAAI Press", "citeRegEx": "23", "shortCiteRegEx": null, "year": 2015}, {"title": "Learning longer memory in recurrent neural networks", "author": ["T. Mikolov", "A. Joulin", "S. Chopra", "M. Mathieu", "M. Ranzato"], "venue": "arXiv preprint arXiv:1412.7753", "citeRegEx": "24", "shortCiteRegEx": null, "year": 2014}, {"title": "Rectified linear units improve restricted boltzmann machines", "author": ["V. Nair", "G.E. Hinton"], "venue": "Proceedings of the 27th International Conference on Machine Learning (ICML-10). pp. 807\u2013814", "citeRegEx": "25", "shortCiteRegEx": null, "year": 2010}, {"title": "Assisted Lead Sheet Composition Using FlowComposer, pp. 769\u2013785", "author": ["A. Papadopoulos", "P. Roy", "F. Pachet"], "venue": null, "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}, {"title": "M.E.T.: Rank analysis of incomplete block designs: I. the method of paired comparisons", "author": ["Ralph Allan Bradley"], "venue": "Biometrika 39(3/4),", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 1952}, {"title": "Music generation from statistical models of harmony", "author": ["R.P. Whorley", "D. Conklin"], "venue": "Journal of New Music Research 45(2),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Multiple viewpoint systems: Time complexity and the construction of domains for complex musical viewpoints in the harmonization problem", "author": ["R.P. Whorley", "G.A. Wiggins", "C. Rhodes", "M.T. Pearce"], "venue": "Journal of New Music Research 42(3), 237\u2013 266", "citeRegEx": "29", "shortCiteRegEx": null, "year": 2013}], "referenceMentions": [{"referenceID": 4, "context": "The corpus of the chorale harmonizations by Johann Sebastian Bach is remarkable by its homogeneity and its size (389 chorales in [5]).", "startOffset": 129, "endOffset": 132}, {"referenceID": 12, "context": "From the point of view of automatic music generation , the first solution to this apparently highly combinatorial problem was proposed by [13] in 1988.", "startOffset": 138, "endOffset": 142}, {"referenceID": 16, "context": "A neural-network-based solution was later developed by [17].", "startOffset": 55, "endOffset": 59}, {"referenceID": 2, "context": "A similar approach is adopted in [3], but uses Hidden Markov Models (HMMs) instead", "startOffset": 33, "endOffset": 36}, {"referenceID": 28, "context": "In [29,28], authors elaborate on those methods by introducing multiple viewpoints and variations on the sampling method (generated sequences which violate \u201crules of harmony\u201d are put aside for instance).", "startOffset": 3, "endOffset": 10}, {"referenceID": 27, "context": "In [29,28], authors elaborate on those methods by introducing multiple viewpoints and variations on the sampling method (generated sequences which violate \u201crules of harmony\u201d are put aside for instance).", "startOffset": 3, "endOffset": 10}, {"referenceID": 7, "context": "In [8], chords are modeled with Restricted Boltzmann Machines (RBMs).", "startOffset": 3, "endOffset": 6}, {"referenceID": 22, "context": "Variations of these architectures have been developed, based on Long Short-Term Memory (LSTM) units [23] or GRUs (Gated Recurrent Units) [10].", "startOffset": 100, "endOffset": 104}, {"referenceID": 9, "context": "Variations of these architectures have been developed, based on Long Short-Term Memory (LSTM) units [23] or GRUs (Gated Recurrent Units) [10].", "startOffset": 137, "endOffset": 141}, {"referenceID": 21, "context": "The most recent advances in chorale harmonization is arguably the BachBot model [22], a LSTM-based approach specifically designed to deal with Bach chorales.", "startOffset": 80, "endOffset": 84}, {"referenceID": 25, "context": "Its efficiency opens up new ways of creating interesting Bach-like chorales for non experts similarly to what is proposed in [26] for leadsheets.", "startOffset": 125, "endOffset": 129}, {"referenceID": 0, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 1, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 2, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 3, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 0, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 1, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 2, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 3, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 0, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 1, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 2, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 3, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 0, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 1, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 2, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 3, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 200, "endOffset": 249}, {"referenceID": 0, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 250, "endOffset": 299}, {"referenceID": 0, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 250, "endOffset": 299}, {"referenceID": 0, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 250, "endOffset": 299}, {"referenceID": 0, "context": "[74,__,76,77,74,__,__,__,72,__,__,__,76,__,__,__] [69,__,__,__,67,__,65,__,64,__,__,__,64,__,__,__] [60,__,__,__,59,__,__,__,55,__,__,__,57,__,__,__] [53,__,50,__,55,__,__,__,48,__,__,__,49,__,__,__] [ 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4] [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]", "startOffset": 250, "endOffset": 299}, {"referenceID": 6, "context": "In order to have a computationally tractable training criterion, we introduce the pseudolikelihood of our data [7,4].", "startOffset": 111, "endOffset": 116}, {"referenceID": 3, "context": "In order to have a computationally tractable training criterion, we introduce the pseudolikelihood of our data [7,4].", "startOffset": 111, "endOffset": 116}, {"referenceID": 13, "context": "This approach was successful in many real-life problems [14] and consists in an approximation of the negative log-likelihood function by the sum over all variables:", "startOffset": 56, "endOffset": 60}, {"referenceID": 3, "context": "t log pi(V i |V\\i,t,S,F , \u03b8i), for i \u2208 [4].", "startOffset": 39, "endOffset": 42}, {"referenceID": 17, "context": "We implement them using neural networks based on LSTMs [18,24].", "startOffset": 55, "endOffset": 62}, {"referenceID": 23, "context": "We implement them using neural networks based on LSTMs [18,24].", "startOffset": 55, "endOffset": 62}, {"referenceID": 14, "context": "Generation is performed using Gibbs sampling [15].", "startOffset": 45, "endOffset": 49}, {"referenceID": 11, "context": "Even if it known that this approach is biased [12] (since we can update simultaneously variables which are not conditionally independent), we experimentally observed that for small batch sizes (16 or 32), DeepBach still generates samples of great musicality while running ten times faster than the sequential version.", "startOffset": 46, "endOffset": 50}, {"referenceID": 19, "context": "9 in [20]) to appropriately choose all the time indexes at which we parallelly resample so that:", "startOffset": 5, "endOffset": 9}, {"referenceID": 8, "context": "We implemented DeepBach using Keras [9] with the Tensorflow [1] backend.", "startOffset": 36, "endOffset": 39}, {"referenceID": 0, "context": "We implemented DeepBach using Keras [9] with the Tensorflow [1] backend.", "startOffset": 60, "endOffset": 63}, {"referenceID": 10, "context": "Bach included in the music21 [11] toolkit.", "startOffset": 29, "endOffset": 33}, {"referenceID": 24, "context": "4a a neural network with one hidden layer of size 200 and ReLU [25] nonlinearity and as the \u201cStacked LSTMs brick\u201d two LSTMs on top of each other, each one being of size 200 (see Fig.", "startOffset": 63, "endOffset": 67}, {"referenceID": 20, "context": "2 (f) in [21]).", "startOffset": 9, "endOffset": 13}, {"referenceID": 15, "context": "We compared our model with two other models: a Maximum Entropy model (MaxEnt) as in [16] (Fig.", "startOffset": 84, "endOffset": 88}, {"referenceID": 24, "context": "The Multilayer Perceptron model we chose takes as input elements in V\\i,t \u222a S \u222a F , is a neural network with one hidden layer of size 500 and uses a ReLU [25] nonlinearity.", "startOffset": 154, "endOffset": 158}, {"referenceID": 26, "context": "In order to give a general ranking from these binary confrontations, we used the Bradley-Terry model [27,2] to infer potentials \u03b2j 7 https://www.", "startOffset": 101, "endOffset": 107}, {"referenceID": 1, "context": "In order to give a general ranking from these binary confrontations, we used the Bradley-Terry model [27,2] to infer potentials \u03b2j 7 https://www.", "startOffset": 101, "endOffset": 107}], "year": 2016, "abstractText": "The composition of polyphonic chorale music in the style of J.S Bach has represented a major challenge in automatic music composition over the last decades. The art of Bach chorales composition involves combining four-part harmony with characteristic rhythmic patterns and typical melodic movements to produce musical phrases which begin, evolve and end (cadences) in a harmonious way. To our knowledge, no model so far was able to solve all these problems simultaneously using an agnostic machine-learning approach. This paper introduces DeepBach, a statistical model aimed at modeling polyphonic music and specifically four parts, hymn-like pieces. We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach. We evaluate how indistinguishable our generated chorales are from existing Bach chorales with a listening test. The results corroborate our claim. A key strength of DeepBach is that it is agnostic and flexible. Users can constrain the generation by imposing some notes, rhythms or cadences in the generated score. This allows users to reharmonize user-defined melodies. DeepBach\u2019s generation is fast, making it usable for interactive music composition applications. Several generation examples are provided and discussed from a musical point of view.", "creator": "LaTeX with hyperref package"}}}