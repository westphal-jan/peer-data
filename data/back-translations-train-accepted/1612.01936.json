{"id": "1612.01936", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Dec-2016", "title": "A Probabilistic Framework for Deep Learning", "abstract": "We develop a probabilistic framework for deep learning based on the Deep Rendering Mixture Model (DRMM), a new generative probabilistic model that explicitly capture variations in data due to latent task nuisance variables. We demonstrate that max-sum inference in the DRMM yields an algorithm that exactly reproduces the operations in deep convolutional neural networks (DCNs), providing a first principles derivation. Our framework provides new insights into the successes and shortcomings of DCNs as well as a principled route to their improvement. DRMM training via the Expectation-Maximization (EM) algorithm is a powerful alternative to DCN back-propagation, and initial training results are promising. Classification based on the DRMM and other variants outperforms DCNs in supervised digit classification, training 2-3x faster while achieving similar accuracy. Moreover, the DRMM is applicable to semi-supervised and unsupervised learning tasks, achieving results that are state-of-the-art in several categories on the MNIST benchmark and comparable to state of the art on the CIFAR10 benchmark.", "histories": [["v1", "Tue, 6 Dec 2016 18:15:40 GMT  (5731kb,D)", "http://arxiv.org/abs/1612.01936v1", "arXiv admin note: substantial text overlap witharXiv:1504.00641"]], "COMMENTS": "arXiv admin note: substantial text overlap witharXiv:1504.00641", "reviews": [], "SUBJECTS": "stat.ML cs.LG cs.NE", "authors": ["ankit b patel", "minh tan nguyen", "richard g baraniuk"], "accepted": true, "id": "1612.01936"}, "pdf": {"name": "1612.01936.pdf", "metadata": {"source": "CRF", "title": "A Probabilistic Framework for Deep Learning", "authors": ["Ankit B. Patel", "Tan Nguyen", "Richard G. Baraniuk"], "emails": ["mn15@rice.edu", "richb@rice.edu"], "sections": [{"heading": "1 Introduction", "text": "In this context, it should be noted that solving problems that have occurred in the past is not about solving problems, but about solving problems that have occurred in the past, but about solving problems that have occurred in the past."}, {"heading": "2 Related Work", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move."}, {"heading": "3 The Deep Rendering Mixture Model: Capturing Nuisance Variation", "text": "Although we will focus on DRMM in this paper, we will define and explore several other interesting variants, including the Deep Rendering Factor Model (DRFM) and the Evolutionary DRMM (EDRMM), both of which are explained in more detail in [18] and in the Appendix. E-DRMM is particularly important because its maximum sum inference algorithm produces a decision tree of the type used in a random decision forest classifier [5]."}, {"heading": "3.1 The (Shallow) Rendering Mixture Model", "text": "The RMM is a generative probability model for images that explicitly show the relationship between images I and II of the same object (1). (1) We assume that there is a function of class c and nuisance g (2). (2) The switch variable A = {ON, OFF} determines whether the template is reproduced in a particular patch; a sparseness before a patch therefore encourages each patch to have a few causes. Noise distribution is from the exponential family, but without loss of the Gaussian noiseN (0, 21).We assume that the noise category has a few causes."}, {"heading": "3.2 The Deep Rendering Mixture Model: Capturing Levels of Abstraction", "text": "We will start all the configurations of the high-dimensional nuisance variables g (1), g (2),.., g (L) at different levels of abstraction, the DRMM image generation processes begin at the highest level of abstraction (\"= L), with the random selection of object class c (L) and the general nuance g (L). It is then followed by random decisions of the lower level g (\") (we absorb the switching variables in g for brevity), progressively becoming more concrete information layer by layer (\"\u2192 \u2212 1), until the process finally leads to a fully ordered D-dimensional image."}, {"heading": "3.3 Learning the Deep Rendering Model via the Expectation-Maximization (EM) Algorithm", "text": "We describe how the DRMM steps from the hard-EM steps to the hard-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-step-"}, {"heading": "3.4 New Insights into Deep Convnets", "text": "The DRMM follow-up algorithm is therefore synonymous with performing max sum product messages via the DRMM note that by \"max sum product\" we mean a novel combination of max sums and max products, as described in more detail in the evidence in the appendix. The factor graph encodes the same information as the generative model, but organizes it in a way that simplifies the definition and execution of inference algorithms [10]. Such follow-up algorithms are called message delivery algorithms because they work by being called messages along the edges between nodes. In DRMM, the messages sent from finer to coarser levels are actually the feature formulas that provide a powerful interpretation: the conversion, max pooling, and ReLu operations in a DCN."}, {"heading": "4 Experimental Results", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move and to move."}, {"heading": "5 Conclusions", "text": "In this paper, we have introduced a new family of hierarchical generative models whose inference algorithms for two different models reproduce deep convective networks or decision trees. Our initial implementation of the DRMM-EG algorithm outperforms DCN back propagation for both supervised and unsupervised classification tasks, achieving comparable / state-of-the-art performance for several semi-supervised classification tasks without architectural hyperparameter tuning [17, 19] receipts, thanks to Xaq Pitkow and Ben Poole for helpful discussions and feedback. ABP and RGB were supported by IARPA via DoI / IBC contract D16PC00003. RGB was also supported by NSF CCF-1527501, AFOSR FA9550-14-1-0088, ARO W911NF-15-1-0316 and ONIGR N0014-TGE-1279-TF."}, {"heading": "A From the Rendering Mixture Model Classifier to a DCN Layer", "text": "s \"s.\" S \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"S\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" S \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s.\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s. \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\" s \"s\""}, {"heading": "B From the Deep Rendering Mixture Model to DCNs", "text": "Here we define the DRMM in full detail.Definition B.1 (Deep Rendering Mixture Definition Model (DRMM) (Deep Rendering Mixture Definition Model (DRMM)) (Deep Rendering Mixture Definition Model (Deep Rendering Mixture Definition)) (Deep Rendering MixP Definition) (Deep Rendering MixP Definition) (Deep Rendering MixP Definition) (Deep Rendering MixP Definition) (Deep Rendering MixP Definition) (Deep Rendering MixP Definition) (Deep Rendering MixP) (Definition) (Deep Rendering MixP) (Definition) (Rendering MixP) (Rendering MixP) (Rendering MixP) (Rendering MixP) (Rendering MixP) (Rendering MixP) (Definition) (Rendering MixP) (Rendering MixP) (Definition) (Rendering MixP) (Definition) (Rendering MixP) (Definition) (Rendering MixP) (Definition) (Rendering MixP) (Definition) (Rendering MixP) (Definition) (Definition) (Rendering MixP) (Rendering MixP) (Definition) (Definition) (Rendering MixP) (Definition) (Definition) (Definition) (Deep Rendering MixP) (Definition MixP) (Definition) (Definition) (Definition MixP) (Definition (Definition) (Definition MixP) (Definition) (Deep Rendering MixP) (Rendering MixP) (Definition MixP) (Definition (Definition MixP) (Definition MixP) (Definition MixP) (Definition MixM) (Definition MixP) (Definition MixP) (Deep Rendering MixP) (Definition MixP) (Definition Mix"}, {"heading": "C Rendering Factor Model (RFM) Architecture", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "D Transforming a Generative Classifier into a Discriminative One", "text": "A generative classifier is the common distribution p (c) p (c) p (c) p (c) p (c) p (c) p (c) p (c) p (c) p (c) p (n) p (c) p (c) p (n) p (c) p (c) p (c) p (c) p (c) p (c) p (c) p (c) p (c) p c c c c (c) c c (c) p (c) p (p) p (p) p) p (p) p (p) p (p) p (p) p (p) p) p (c) p (c) p (p) p (p) p (p) p) p (c) c c (c) c c (c) p (c) p (c) p (c) p (p) p (p) p) p (p) p (p) p) p (c) p (p) p) p (p) p) p (c) p (c) p (c) p (c) p) p (p) p (p) p) p (p) p (p) p) p (p) p (p) p (p) p (p) p) p (p) p (p) p (p) p (p) p) p (p) p (p) p (p) p (p) p) p (p (p) p (p) p) p (p) p) p (p (p) p) p (p (p) p) p (p) p) p (p (p) p) p (p) p (p (p) p) p (p) p) p (p (p) p (p) p) p) p (p (p) p (p) p (p) p) p (p) p (p) p (p) p (p) p (p) p) p (p (p) p) p (p) p (p) p (p) p (p) p) p (p (p) p) p) p (p (p) p) p (p) p) p (p) p (p (p) p) p (p"}, {"heading": "E Derivation of Closed-Form Expression for Activity-Maximizing Images", "text": "The results of the ongoing activity maximization are shown for completeness in Fig. 5. Mathematically, we search for the image I that maximizes the score S (c | I) of a particular object class. By means of the DRM, we find the image I S (c (L) | I) = max I max g \u00b2 G < 1 \u03c32 \u00b5 (c (c (L), g (') | I > max g \u00b2 G max I < \u00b5 (c (L), g) | I > = max g \u00b2 G max IP1 \u00b7 max IPp < \u00b5 (c (L), g \u00b2 P IPi > = max g \u00b2 G \u00b2 Pi < \u00b5 (c (L), g \u00b2 P max IPi < \u00b5 (c) > IPi > = max g \u00b2 G \u00b2 P < Pi > (Pi) (P &lti), p \u00b2 P, P) < p \u00b2 (P, P) < &lt\u00b2 (< &lt\u00b2 P; < < &lt\u00b2 P; < &ltp; < &ltp; &lti) &lti (Pi) (P &lti), P \u00b2 P, P) < P (P) &lti (P) < < &ltp; &ltp; &ltp \u00b2 P (P) &ltp; &ltp; &ltp; &ltp; &ltp; &ltp; &ltp; &ltp; &ltp \u00b2 P) &lti (P) &ltp; P (P, P) &ltp) &ltp (P (P) &ltp) &ltp (P, P, P, P) &ltp (P) &ltp) &ltp (P (P, P) &ltp) &ltp (P, P (P) &ltp) &ltp; &ltp; &ltp; &ltp; &ltp; &ltp; &ltp; &ltp \u00b2 (P (P) &ltp) &ltp, P (P (P) &p) &ltp) &ltp (P (P, P"}, {"heading": "F From the DRMM to Decision Trees", "text": "In this section we show that, as in the DRMM, the Random Decision Forests (RDFs) (see Eq.47) can also be derived from the DRMM model. Instead of translational and alternating nuisances, we will show that an additive mutation process that generates a hierarchy of categories (e.g. the evolution of a taxonomy of living organisms) is at the core of the RDF.F.1 The Evolutionary Deep Rendering Mixture ModelWe define the evolutionary DRMM (E-DRMM) as a DRMM with an evolutionary tree of categories. Samples from the model are generated by starting from the root pedigree and random mutation of the templates. Each child is an additive \"mutation\" of its parents where the specific mutation does not depend on the parents (see Eq.47 below)."}, {"heading": "G Unifying the Probabilistic and Neural Network Perspectives", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "H Additional Experimental Results", "text": "H.1 Learned filters and image reconstructions Filters and reconstructed images are shown in Fig. 6.H.2 Additional training resultsMore results and comparison to other related work are shown in Table 3."}, {"heading": "I Model Configurations", "text": "In our experiments, the configurations of the RFM and the 2-layer DRFM LeNet5 [11] and its variants are similar. In addition, the configurations of the 5-layer DRMM (for MNIST) and the 9-layer DRMM (for CIFAR10) are similar to the Conv-Small or Conv-Large architectures in [29, 20]."}], "references": [], "referenceMentions": [], "year": 2016, "abstractText": "<lb>We develop a probabilistic framework for deep learning based on the Deep Render-<lb>ing Mixture Model (DRMM), a new generative probabilistic model that explicitly<lb>capture variations in data due to latent task nuisance variables. We demonstrate<lb>that max-sum inference in the DRMM yields an algorithm that exactly reproduces<lb>the operations in deep convolutional neural networks (DCNs), providing a first<lb>principles derivation. Our framework provides new insights into the successes and<lb>shortcomings of DCNs as well as a principled route to their improvement. DRMM<lb>training via the Expectation-Maximization (EM) algorithm is a powerful alternative<lb>to DCN back-propagation, and initial training results are promising. Classification<lb>based on the DRMM and other variants outperforms DCNs in supervised digit<lb>classification, training 2-3\u00d7 faster while achieving similar accuracy. Moreover, the<lb>DRMM is applicable to semi-supervised and unsupervised learning tasks, achiev-<lb>ing results that are state-of-the-art in several categories on the MNIST benchmark<lb>and comparable to state of the art on the CIFAR10 benchmark.", "creator": "LaTeX with hyperref package"}}}