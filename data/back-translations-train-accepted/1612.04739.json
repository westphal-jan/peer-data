{"id": "1612.04739", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-Dec-2016", "title": "An Architecture for Deep, Hierarchical Generative Models", "abstract": "We present an architecture which lets us train deep, directed generative models with many layers of latent variables. We include deterministic paths between all latent variables and the generated output, and provide a richer set of connections between computations for inference and generation, which enables more effective communication of information throughout the model during training. To improve performance on natural images, we incorporate a lightweight autoregressive model in the reconstruction distribution. These techniques permit end-to-end training of models with 10+ layers of latent variables. Experiments show that our approach achieves state-of-the-art performance on standard image modelling benchmarks, can expose latent class structure in the absence of label information, and can provide convincing imputations of occluded regions in natural images.", "histories": [["v1", "Thu, 8 Dec 2016 11:17:16 GMT  (5553kb,D)", "http://arxiv.org/abs/1612.04739v1", "Published in NIPS 2016"]], "COMMENTS": "Published in NIPS 2016", "reviews": [], "SUBJECTS": "cs.LG", "authors": ["philip bachman"], "accepted": true, "id": "1612.04739"}, "pdf": {"name": "1612.04739.pdf", "metadata": {"source": "CRF", "title": "An Architecture for Deep, Hierarchical Generative Models", "authors": ["Philip Bachman"], "emails": ["phil.bachman@maluuba.com"], "sections": [{"heading": "1 Introduction", "text": "This year, it is as far as ever in the history of the city, where it is as far as never before."}, {"heading": "2 The Matryoshka Network Architecture", "text": "Matryoshka Networks combines three components: a top-down network (abbreviation TD network), a bottom-up network (abbreviation BU network), and a series of merge modules that merge information from the BU and TD networks. In the context of stochastic variations [10], all three components contribute to the approximate posterior distributions used during inference / training, but only the TD network participates in the generation. We first formally describe the MatNet model and then provide a procedural description of its three components. The complete architecture is summarized in Fig. 1.1A. A major drawback of LapGANs and diffusion networks is that they define their inference mechanisms a priori, which is convenient from a computational point of view, but prevents the model from learning abstract representations."}, {"heading": "2.1 Formal Description", "text": "The distribution p (x) generated by a MatNet is encoded in its top-down network. To model q (x), the TD network splits the common distribution p (x, z) by observing x and a sequence of latent variables z (z0,..., zd) into a sequence of simpler conditional distributions: p (x) = p (zd,..., z0) p (zd) p (zd) p (zd)... p (zi)... p (zi)... p (zi) | zi \u2212 1, z0)... p (z0)... p (z0), (1) which we marginalize in relation to the latent variables in order to obtain p (x). The TD network is designed so that any conditional p (zi) p (zi \u2212 1, z0) can be reduced to the distribution."}, {"heading": "2.2 Procedural Description", "text": "If we define the TD modules accordingly, we can reproduce the architectures for LapGANs, Diffusion Nets, and Probabilistic Ladder Networks [23] by appropriately defining the TD modules that associate the latent variables with the top-down state after which the transformed values are returned to the top-down state. If we associate the latent variables with the top-down state, the transformed values are added before further processing."}, {"heading": "2.3 Model Extensions", "text": "We are also developing several extensions to the MatNet architecture. The first is to replace the zero mean, unit variance Gaussian before z0 with a Gaussian mixture model, which we form simultaneously with the rest of the model. If we use a mixture before, we use an analytical approximation to the required KL divergence. For the Gaussian distribution q and the Gaussian mixture p with components {p1,..., pk} with uniform mixing weights we use the KL approximation: KL (q | p) \u2248 log 1 p = 1 e \u2212 KL (q | pi). (12) Our tests with mixture-based priors are only concerned with qualitative behavior, so we do not worry about the approximation error in Eqn. 12.The second extension is a technique for regulating the inference model to prevent overadjustment beyond what is present in the generator."}, {"heading": "3 Experiments", "text": "This year, it has reached the stage where it will be able to take the lead."}, {"heading": "4 Related Work and Discussion", "text": "These approaches are comparable to solving laboratories that start at the end and work backwards, or learning how an object functions by repeatedly disassembling and reassembling it. Examples of this are LapGANs [3], which deconstruct an image by repeatedly deconstructing it, and diffusion networks [21], which deconstruct arbitrary data by subjecting it to a long sequence of small random perturbations. The power of these approaches stems from the fact that the data is gradually deconstructed, which in turn lead to a well-formed observation."}], "references": [{"title": "Data generation as sequential decision making", "author": ["P. Bachman", "D. Precup"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2015}, {"title": "Importance weighted auto-encoders", "author": ["Y. Burda", "R. Grosse", "R. Salakhutdinov"], "venue": "[cs.LG],", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2015}, {"title": "Deep generative models using a laplacian pyramid of adversarial networks", "author": ["E.L. Denton", "S. Chintala", "A. Szlam", "R. Fergus"], "venue": "[cs.CV],", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2015}, {"title": "Attend, infer, repeat: Fast scene understanding with generative models", "author": ["S.M.A. Eslami", "N. Heess", "T. Weber", "Y. Tassa", "K. Kavucuoglu", "G.E. Hinton"], "venue": "[cs.CV],", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Draw: A recurrent neural network for image generation", "author": ["K. Gregor", "I. Danihelka", "A. Graves", "D. Wierstra"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2015}, {"title": "Towards conceptual compression", "author": ["K. Gregor", "F. Besse", "D.J. Rezende", "I. Danihelka", "D. Wierstra"], "venue": "In arXiv:1604.08772v1 [stat.ML],", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2016}, {"title": "Deep residual learning for image recognition", "author": ["K. He", "X. Zhang", "S. Ren", "J. Sun"], "venue": "[cs.CV],", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2015}, {"title": "Recombinator networks: Learning coarse-to-fine feature aggregation", "author": ["S. Honari", "J. Yosinski", "P. Vincent", "C. Pal"], "venue": "In Computer Vision and Pattern Recognition", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Neural gpus learn algorithms", "author": ["L. Kaiser", "I. Sutskever"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2016}, {"title": "Auto-encoding variational bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "In International Conference on Learning Representations (ICLR),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Improving variational inference with inverse autoregressive flow", "author": ["D.P. Kingma", "T. Salimans", "M. Welling"], "venue": "[cs.LG],", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2016}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G.E. Hinton"], "venue": "Master\u2019s thesis, University of Toronto,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2009}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["B.M. Lake", "R. Salakhutdinov", "J.B. Tenebaum"], "venue": null, "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2015}, {"title": "Deep learning face attributes in the wild", "author": ["Z. Liu", "P. Luo", "X. Wang", "X. Tang"], "venue": "In International Conference on Computer Vision (ICCV),", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2015}, {"title": "Auxiliary deep generative models", "author": ["L. Maal\u00f8e", "C.K. S\u00f8nderby", "S.K. S\u00f8nderby", "O. Winther"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Hierarchical variational models", "author": ["R. Ranganath", "D. Tran", "D.M. Blei"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2016}, {"title": "Semi-supervised learning with ladder networks", "author": ["A. Rasmus", "H. Valpola", "M. Honkala", "M. Berglund", "T. Raiko"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2014}, {"title": "One-shot generalization in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "I. Danihelka", "K. Gregor", "D. Wierstra"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "On the quantitative analysis of deep belief networks", "author": ["R. Salakhutdinov", "I. Murray"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2008}, {"title": "Deep unsupervised learning using nonequilibrium thermodynamics", "author": ["J. Sohl-Dickstein", "E.A. Weiss", "N. Maheswaranathan", "S. Ganguli"], "venue": "In International Conference on Machine Learning (ICML),", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2015}, {"title": "Learning structured output representation using deep conditional generative models", "author": ["K. Sohn", "H. Lee", "X. Yan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2015}, {"title": "How to train deep variational autoencoders and probabilistic ladder networks", "author": ["C.K. S\u00f8nderby", "T. Raiko", "L. Maal\u00f8e", "S.K. S\u00f8nderby", "O. Winther"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}, {"title": "Generative image modeling using spatial lstms", "author": ["L. Theis", "M. Bethge"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2015}, {"title": "Kavucuoglu. Pixel recurrent neural networks", "author": ["A. van den Oord", "N. Kalchbrenner"], "venue": "International Conference on Machine Learning (ICML),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2016}, {"title": "Conditional image generation with pixelcnn decoders", "author": ["A. van den Oord", "N. Kalchbrenner", "O. Vinyals", "L. Espeholt", "A. Graves", "K. Kavucuoglu"], "venue": "[cs.CV],", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2016}], "referenceMentions": [{"referenceID": 4, "context": "[5] and explored further in [1, 19, 22].", "startOffset": 0, "endOffset": 3}, {"referenceID": 0, "context": "[5] and explored further in [1, 19, 22].", "startOffset": 28, "endOffset": 39}, {"referenceID": 18, "context": "[5] and explored further in [1, 19, 22].", "startOffset": 28, "endOffset": 39}, {"referenceID": 21, "context": "[5] and explored further in [1, 19, 22].", "startOffset": 28, "endOffset": 39}, {"referenceID": 16, "context": "[17], and has been developed further for, e.", "startOffset": 0, "endOffset": 4}, {"referenceID": 7, "context": "generative modelling and image processing in [8, 23].", "startOffset": 45, "endOffset": 52}, {"referenceID": 22, "context": "generative modelling and image processing in [8, 23].", "startOffset": 45, "endOffset": 52}, {"referenceID": 2, "context": "LapGANs [3] and Diffusion Nets [21] to learn hierarchicallydeep generative models with the power of jointly-trained inference/generation1.", "startOffset": 8, "endOffset": 11}, {"referenceID": 20, "context": "LapGANs [3] and Diffusion Nets [21] to learn hierarchicallydeep generative models with the power of jointly-trained inference/generation1.", "startOffset": 31, "endOffset": 35}, {"referenceID": 6, "context": "\u2022 Use lateral connections, shortcut connections, and residual connections [7] to provide direct paths through the inference network to the latent variables, and from the latent variables to the generated output \u2014 this makes hierarchically-deep models easily trainable in practice.", "startOffset": 74, "endOffset": 77}, {"referenceID": 9, "context": "In the context of stochastic variational inference [10], all three components contribute to the approximate posterior distributions used during inference/training, but only the TD network participates in generation.", "startOffset": 51, "endOffset": 55}, {"referenceID": 9, "context": "This module draws conditional samples of the latent variables via reparametrization [10].", "startOffset": 84, "endOffset": 88}, {"referenceID": 9, "context": "MatNets are well-suited to training with Stochastic Gradient Variational Bayes [10].", "startOffset": 79, "endOffset": 83}, {"referenceID": 9, "context": "See [10, 18] for more details about this technique.", "startOffset": 4, "endOffset": 12}, {"referenceID": 17, "context": "See [10, 18] for more details about this technique.", "startOffset": 4, "endOffset": 12}, {"referenceID": 22, "context": "By defining the TD modules appropriately, we can reproduce the architectures for LapGANs, Diffusion Nets, and Probabilistic Ladder Networks [23].", "startOffset": 140, "endOffset": 144}, {"referenceID": 6, "context": "Motivated by the success of LapGANs and ResNets [7], we use TD modules in which the latent variables are concatenated with the top-down state, then transformed, after which the transformed values are added back to the top-down state prior to further processing.", "startOffset": 48, "endOffset": 51}, {"referenceID": 15, "context": "Our BU networks are all deterministic and feedforward, but sensibly augmenting them with auxiliary latent variables [16, 15] and/or recurrence is a promising topic for future work.", "startOffset": 116, "endOffset": 124}, {"referenceID": 14, "context": "Our BU networks are all deterministic and feedforward, but sensibly augmenting them with auxiliary latent variables [16, 15] and/or recurrence is a promising topic for future work.", "startOffset": 116, "endOffset": 124}, {"referenceID": 9, "context": "The final module, f b 0 , provides means and log-variances for sampling z0 via reparametrization [10].", "startOffset": 97, "endOffset": 101}, {"referenceID": 18, "context": "The stochastic convolutional GRU is particularly interesting when applied depth-wise (rather than time-wise as in [19]), as it implements a stochastic Neural GPU [9] trainable by variational inference and capable of multi-modal dynamics.", "startOffset": 114, "endOffset": 118}, {"referenceID": 8, "context": "The stochastic convolutional GRU is particularly interesting when applied depth-wise (rather than time-wise as in [19]), as it implements a stochastic Neural GPU [9] trainable by variational inference and capable of multi-modal dynamics.", "startOffset": 162, "endOffset": 165}, {"referenceID": 10, "context": "Our models used independent Bernoullis, diagonal Gaussians, or \u201cintegrated\u201d Logistics (see [11]) for the final output distribution p(x|zd, .", "startOffset": 91, "endOffset": 95}, {"referenceID": 24, "context": "We use a simplified version of the masked convolutions in the PixelCNN of [25], modified to condition on the output of the final TD module in a MatNet.", "startOffset": 74, "endOffset": 78}, {"referenceID": 25, "context": "Larger, more powerful mechanisms for combining local autoregressions and conditioning information are explored in [26].", "startOffset": 114, "endOffset": 118}, {"referenceID": 12, "context": "We measured quantitative performance of MatNets on three datasets: MNIST, Omniglot [13], and CIFAR 10 [12].", "startOffset": 83, "endOffset": 87}, {"referenceID": 11, "context": "We measured quantitative performance of MatNets on three datasets: MNIST, Omniglot [13], and CIFAR 10 [12].", "startOffset": 102, "endOffset": 106}, {"referenceID": 1, "context": "We used the 28x28 version of Omniglot described in [2], which can be found at: https://github.", "startOffset": 51, "endOffset": 54}, {"referenceID": 21, "context": "The lower-right table presents results from the structured prediction task in [22], in which 1-3 quadrants of an MNIST digit are visible, and NLL is measured on predictions for the unobserved quadrants.", "startOffset": 78, "endOffset": 82}, {"referenceID": 23, "context": "terms of negative log-likelihood, with the CIFAR 10 scores rescaled to bits-per-pixel and corrected for discrete/continuous observations as described in [24].", "startOffset": 153, "endOffset": 157}, {"referenceID": 1, "context": "We used the IWAE bound from [2] to evaluate our models, with 2500 samples in the bound.", "startOffset": 28, "endOffset": 31}, {"referenceID": 13, "context": "We performed additional experiments measuring the qualitative performance of MatNets using Omniglot, CelebA faces [14], LSUN 2015 towers, and LSUN 2015 churches.", "startOffset": 114, "endOffset": 118}, {"referenceID": 1, "context": "The first tests measured generative performance on dynamically-binarized images using a fully-connected model (for comparison with [2, 23]) and on the fixed binarization from [20] using a convolutional model (for comparison with [25, 19]).", "startOffset": 131, "endOffset": 138}, {"referenceID": 22, "context": "The first tests measured generative performance on dynamically-binarized images using a fully-connected model (for comparison with [2, 23]) and on the fixed binarization from [20] using a convolutional model (for comparison with [25, 19]).", "startOffset": 131, "endOffset": 138}, {"referenceID": 19, "context": "The first tests measured generative performance on dynamically-binarized images using a fully-connected model (for comparison with [2, 23]) and on the fixed binarization from [20] using a convolutional model (for comparison with [25, 19]).", "startOffset": 175, "endOffset": 179}, {"referenceID": 24, "context": "The first tests measured generative performance on dynamically-binarized images using a fully-connected model (for comparison with [2, 23]) and on the fixed binarization from [20] using a convolutional model (for comparison with [25, 19]).", "startOffset": 229, "endOffset": 237}, {"referenceID": 18, "context": "The first tests measured generative performance on dynamically-binarized images using a fully-connected model (for comparison with [2, 23]) and on the fixed binarization from [20] using a convolutional model (for comparison with [25, 19]).", "startOffset": 229, "endOffset": 237}, {"referenceID": 21, "context": "For this, we recreated the tests described in [22].", "startOffset": 46, "endOffset": 50}, {"referenceID": 23, "context": "We trained two models on this data \u2014 one with a Gaussian reconstruction distribution and dequantization as described in [24], and the other which added a local autoregression and used the \u201cintegrated Logistic\u201d likelihood described in [11].", "startOffset": 120, "endOffset": 124}, {"referenceID": 10, "context": "We trained two models on this data \u2014 one with a Gaussian reconstruction distribution and dequantization as described in [24], and the other which added a local autoregression and used the \u201cintegrated Logistic\u201d likelihood described in [11].", "startOffset": 234, "endOffset": 238}, {"referenceID": 5, "context": "The Gaussian model fell just short of the best previously reported result for a variational method (from [6]), and well short of the Pixel RNN presented in [25].", "startOffset": 105, "endOffset": 108}, {"referenceID": 24, "context": "The Gaussian model fell just short of the best previously reported result for a variational method (from [6]), and well short of the Pixel RNN presented in [25].", "startOffset": 156, "endOffset": 160}, {"referenceID": 1, "context": "Our final quantitative test used the Omniglot handwritten character dataset, rescaled to 28x28 as in [2].", "startOffset": 101, "endOffset": 104}, {"referenceID": 2, "context": "Examples include LapGANs [3], which deconstruct an image by repeatedly downsampling it, and Diffusion Nets [21], which deconstruct arbitrary data by subjecting it to a long sequence of small random perturbations.", "startOffset": 25, "endOffset": 28}, {"referenceID": 20, "context": "Examples include LapGANs [3], which deconstruct an image by repeatedly downsampling it, and Diffusion Nets [21], which deconstruct arbitrary data by subjecting it to a long sequence of small random perturbations.", "startOffset": 107, "endOffset": 111}, {"referenceID": 2, "context": "In the generative models of [3, 21], the deconstruction processes were defined a priori, which avoided the need for trained inference.", "startOffset": 28, "endOffset": 35}, {"referenceID": 20, "context": "In the generative models of [3, 21], the deconstruction processes were defined a priori, which avoided the need for trained inference.", "startOffset": 28, "endOffset": 35}, {"referenceID": 22, "context": "the Probabilistic Ladder Networks of [23], which are a special case of our architecture in which the deterministic paths from latent variables to observations are removed and the conditioning mechanism in inference is more restricted.", "startOffset": 37, "endOffset": 41}, {"referenceID": 12, "context": "[13].", "startOffset": 0, "endOffset": 4}, {"referenceID": 3, "context": "Techniques for training coupled generation and inference have now reached a level that makes it possible to investigate these ideas while learning models end-to-end [4].", "startOffset": 165, "endOffset": 168}], "year": 2016, "abstractText": "We present an architecture which lets us train deep, directed generative models with many layers of latent variables. We include deterministic paths between all latent variables and the generated output, and provide a richer set of connections between computations for inference and generation, which enables more effective communication of information throughout the model during training. To improve performance on natural images, we incorporate a lightweight autoregressive model in the reconstruction distribution. These techniques permit end-to-end training of models with 10+ layers of latent variables. Experiments show that our approach achieves state-of-the-art performance on standard image modelling benchmarks, can expose latent class structure in the absence of label information, and can provide convincing imputations of occluded regions in natural images.", "creator": "LaTeX with hyperref package"}}}