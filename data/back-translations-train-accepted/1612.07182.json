{"id": "1612.07182", "review": {"conference": "iclr", "VERSION": "v1", "DATE_OF_SUBMISSION": "21-Dec-2016", "title": "Multi-Agent Cooperation and the Emergence of (Natural) Language", "abstract": "The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the \"word meanings\" induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents' code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively.", "histories": [["v1", "Wed, 21 Dec 2016 15:27:06 GMT  (316kb,D)", "http://arxiv.org/abs/1612.07182v1", "Under submission at ICLR 2017"], ["v2", "Sun, 5 Mar 2017 21:40:51 GMT  (1961kb,D)", "http://arxiv.org/abs/1612.07182v2", "Accepted at ICLR 2017"]], "COMMENTS": "Under submission at ICLR 2017", "reviews": [], "SUBJECTS": "cs.CL cs.CV cs.GT cs.LG cs.MA", "authors": ["angeliki lazaridou", "alexander peysakhovich", "marco baroni"], "accepted": true, "id": "1612.07182"}, "pdf": {"name": "1612.07182.pdf", "metadata": {"source": "CRF", "title": null, "authors": ["(NATURAL) LANGUAGE", "Angeliki Lazaridou", "Alexander Peysakhovich", "Marco Baroni"], "emails": ["marco.baroni}@unitn.it,", "alexpeys@fb.com"], "sections": [{"heading": null, "text": "This passive learning is problematic when we are interested in developing interactive machines, such as conversation agents. We propose a framework for language acquisition based on communication with multi-agents. We study this learning in the context of reference games. In these games, sender and receiver see a pair of images. The sender is told that one of them is the target and that he is allowed to send a message from a fixed, arbitrary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of necessity to communicate. We show that two networks with simple configurations are able to learn to coordinate in the reference game. We also explore how to make changes to the game environment so that the \"word meanings\" generated in the game better reflect the intuitive semantic properties of the images."}, {"heading": "1 INTRODUCTION", "text": "This coordination is impossible without communication, and if the coordinating partners are able to involve people, the most natural channel of communication is a natural language. Therefore, the use of natural language is a key step towards a world populated by other actors. Given the success of in-depth learning models tested in related fields such as picture caption or machine translation, it seems reasonable to view the problem of language practice as an instance of superior learning."}, {"heading": "2 GENERAL FRAMEWORK", "text": "Our general framework includes K players, each parameterized by \u03b8k, a collection of tasks / games that players must perform, a communication protocol V that allows players to communicate with each other in sequence and payouts that are assigned to players as a deterministic function of a well-defined goal. In this work, we focus on a specific version of this: reference games. These games are structured as follows: 1. There are a number of images represented by vectors {i1,.., iN} - the sender receives input from this sentence, let's call them (iL, iR), one of them is selected as \"target\" t, {L, R} 2. There are two players, one sender and one receiver, each seeing the images - the sender receives input instead of S (iL, iR, t) 3. There is a vocabulary V of size K and the sender selects an icon to send to the recipient."}, {"heading": "3 EXPERIMENTAL SETUP", "text": "\"We are using the McRae et al.'s (2005) set of 463 base-level concrete concepts (e.g., cat, apple, car.), which spans 20 general categories (e.g., animal, fruit / vegetable, vehicle.) We randomly have 100 images of each concept from ImageNet (Deng et al., 2009). To create target / distractor pairs, we have to randomly select two concepts, one image for each concept and whether the first or second image will serve as a target. We apply a forward pass through the pretrained VGG ConvNet (Simonyan & Zisserman, 2014) to each image, and represent it with the activations of either the Top 1000-D softmax layer (sm) or the Second-to-last 4096-D fully connected layer (fc).Agent players Both transmitters and receivers are simple forward networks. For the transmitter, we are experimenting with the two architectures represented in Figure 1."}, {"heading": "4 LEARNING TO COMMUNICATE", "text": "In fact, most people are able to decide for themselves what they want and what they want."}, {"heading": "4.1 OBJECT-LEVEL REFERENCE", "text": "We have found that our agents can solve the coordination problem, and we have at least preliminary evidence that they do so by developing symbolic meanings consistent with our semantic intuition. We are now turning to a simple method to optimize the game configuration, to encourage agents to continue pursuing high-level semantics (Brandenburger et al., 2014). The strategy for us is to remove some aspects of \"common knowledge\" from the game. Common knowledge, in game theory parlance, is facts that everyone knows everyone knows, and so on. Coordination can only take place when the basis of coordination is common knowledge (Rubinstein, 1989), so if we remove some facts from common knowledge, we will prevent our agents from coordinating on it. In our case, we want to remove facts that relate to the details of the input images, thus forcing agents to coordinate on more abstract properties (Chihies, 1989)."}, {"heading": "5 GROUNDING AGENTS\u2019 COMMUNICATION IN HUMAN LANGUAGE", "text": "In fact, most of them will be able to put themselves in a situation where they are able, in which they are able to assert themselves, and in which they are able, in which they are able, in which they are in and in which they are able to assert themselves."}, {"heading": "6 DISCUSSION", "text": "Our results confirmed that relatively simple agents of neural networks can learn to coordinate in a reference game in which they have to communicate via a large number of real images. Furthermore, they suggest that if the environment is designed correctly, the meanings that agents assign to symbols can capture the general conceptual properties of the objects depicted in the image, not the low visual properties. We have also shown a way to ground communication in natural language by mixing the game with a supervised task. In future work, encouraged by our preliminary experiments with object naming, we want to investigate how we can ensure that emerging communication remains close to human natural language. Forward-looking learning should be preserved as an important building block of intelligent agents and focus on teaching them structural properties of language."}], "references": [{"title": "Hierarchies of beliefs and common knowledge", "author": ["Adam Brandenburger", "Eddie Dekel"], "venue": null, "citeRegEx": "Brandenburger and Dekel,? \\Q1998\\E", "shortCiteRegEx": "Brandenburger and Dekel", "year": 1998}, {"title": "Learning to communicate to solve riddles with deep distributed recurrent q-networks", "author": ["Jakob N. Foerster", "Yannis M. Assael", "Nando de Freitas", "Shimon Whiteson"], "venue": "Technical Report arXiv:1602.02672,", "citeRegEx": "Foerster et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Foerster et al\\.", "year": 2016}, {"title": "Recency, records and recaps: learning and nonequilibrium behavior in a simple decision problem", "author": ["Drew Fudenberg", "Alexander Peysakhovich"], "venue": "In Proceedings of the fifteenth ACM conference on Economics and Computation,", "citeRegEx": "Fudenberg and Peysakhovich.,? \\Q2014\\E", "shortCiteRegEx": "Fudenberg and Peysakhovich.", "year": 2014}, {"title": "Generative adversarial nets", "author": ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Learning to play guess who? and inventing a grounded language as a consequence", "author": ["Emilio Jorge", "Mikael K\u00e5geb\u00e4ck", "Emil Gustavsson"], "venue": "arXiv preprint arXiv:1611.03218,", "citeRegEx": "Jorge et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jorge et al\\.", "year": 2016}, {"title": "Referitgame: Referring to objects in photographs of natural scenes", "author": ["Sahar Kazemzadeh", "Vicente Ordonez", "Mark Matten", "Tamara L Berg"], "venue": "In EMNLP, pp", "citeRegEx": "Kazemzadeh et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kazemzadeh et al\\.", "year": 2014}, {"title": "Semantic feature production norms for a large set of living and nonliving things", "author": ["Ken McRae", "George Cree", "Mark Seidenberg", "Chris McNorgan"], "venue": "Behavior Research Methods,", "citeRegEx": "McRae et al\\.,? \\Q2005\\E", "shortCiteRegEx": "McRae et al\\.", "year": 2005}, {"title": "A roadmap towards machine intelligence", "author": ["Tomas Mikolov", "Armand Joulin", "Marco Baroni"], "venue": "arXiv preprint arXiv:1511.08130,", "citeRegEx": "Mikolov et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2015}, {"title": "The Generative Lexicon", "author": ["James Pustejovsky"], "venue": null, "citeRegEx": "Pustejovsky.,? \\Q1995\\E", "shortCiteRegEx": "Pustejovsky.", "year": 1995}, {"title": "Learning in extensive-form games: Experimental data and simple dynamic models in the intermediate term", "author": ["Alvin E Roth", "Ido Erev"], "venue": "Games and economic behavior,", "citeRegEx": "Roth and Erev.,? \\Q1995\\E", "shortCiteRegEx": "Roth and Erev.", "year": 1995}, {"title": "The electronic mail game: Strategic behavior under \u2018almost common knowledge", "author": ["Ariel Rubinstein"], "venue": "The American Economic Review, pp", "citeRegEx": "Rubinstein.,? \\Q1989\\E", "shortCiteRegEx": "Rubinstein.", "year": 1989}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Christopher J. Maddison"], "venue": "search. Nature,", "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan and Zisserman.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan and Zisserman.", "year": 2014}, {"title": "Signals: Evolution, learning, and information", "author": ["Brian Skyrms"], "venue": null, "citeRegEx": "Skyrms.,? \\Q2010\\E", "shortCiteRegEx": "Skyrms.", "year": 2010}, {"title": "Towards collaborative and adversarial learning: A case study in robotic soccer", "author": ["Peter Stone", "Manuela Veloso"], "venue": "International Journal of Human-Computer Studies,", "citeRegEx": "Stone and Veloso.,? \\Q1998\\E", "shortCiteRegEx": "Stone and Veloso.", "year": 1998}, {"title": "Learning multiagent communication with backpropagation", "author": ["Sainbayar Sukhbaatar", "Arthur Szlam", "Rob Fergus"], "venue": "arXiv preprint arXiv:1605.07736,", "citeRegEx": "Sukhbaatar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc Le"], "venue": "In Proceedings of NIPS,", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Reinforcement Learning: An Introduction", "author": ["Richard Sutton", "Andrew Barto"], "venue": null, "citeRegEx": "Sutton and Barto.,? \\Q1998\\E", "shortCiteRegEx": "Sutton and Barto.", "year": 1998}, {"title": "Visualizing data using t-SNE", "author": ["Laurens Van der Maaten", "Geoffrey Hinton"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Maaten and Hinton.,? \\Q2008\\E", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le"], "venue": "In Proceedings of the ICML Deep Learning Workshop, Lille, France,", "citeRegEx": "Vinyals and Le.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}, {"title": "Progress in the simulation of emergent communication and language", "author": ["Kyle Wagner", "James A Reggia", "Juan Uriagereka", "Gerald S Wilkinson"], "venue": "Adaptive Behavior,", "citeRegEx": "Wagner et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Wagner et al\\.", "year": 2003}, {"title": "Learning language games through interaction", "author": ["S.I. Wang", "P. Liang", "C. Manning"], "venue": "In Association for Computational Linguistics (ACL),", "citeRegEx": "Wang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Simple statistical gradient-following algorithms for connectionist reinforcement learning", "author": ["Ronald J Williams"], "venue": "Machine learning,", "citeRegEx": "Williams.,? \\Q1992\\E", "shortCiteRegEx": "Williams.", "year": 1992}, {"title": "Procedures as a representation for data in a computer program for understanding natural language", "author": ["Terry Winograd"], "venue": "Technical Report AI 235, Massachusetts Institute of Technology,", "citeRegEx": "Winograd.,? \\Q1971\\E", "shortCiteRegEx": "Winograd.", "year": 1971}, {"title": "Philosophical Investigations", "author": ["Ludwig Wittgenstein"], "venue": null, "citeRegEx": "Wittgenstein.,? \\Q1953\\E", "shortCiteRegEx": "Wittgenstein.", "year": 1953}, {"title": "An introduction to multiagent systems", "author": ["Michael Wooldridge"], "venue": null, "citeRegEx": "Wooldridge.,? \\Q2009\\E", "shortCiteRegEx": "Wooldridge.", "year": 2009}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Kyunghyun Cho", "Aaron Courville", "Ruslan Salakhudinov", "Rich Zemel", "Yoshua Bengio"], "venue": "In Proceedings of ICML,", "citeRegEx": "Xu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Visualizing and understanding convolutional networks", "author": ["Matthew Zeiler", "Rob Fergus"], "venue": "In Proceedings of ECCV (Part", "citeRegEx": "Zeiler and Fergus.,? \\Q2014\\E", "shortCiteRegEx": "Zeiler and Fergus.", "year": 2014}, {"title": "Criterion functions for document clustering: Experiments and analysis", "author": ["Ying Zhao", "George Karypis"], "venue": "Technical Report 01-40,", "citeRegEx": "Zhao and Karypis.,? \\Q2003\\E", "shortCiteRegEx": "Zhao and Karypis.", "year": 2003}], "referenceMentions": [{"referenceID": 25, "context": "1 INTRODUCTION One of the most ambitious goals in AI is to develop agents that can cooperate with others to achieve goals (Wooldridge, 2009).", "startOffset": 122, "endOffset": 140}, {"referenceID": 26, "context": "Given the success of deep learning models trained on end-task examples in related domains such as image captioning or machine translation (e.g., Sutskever et al., 2014; Xu et al., 2015), it would seem reasonable to cast the problem of training conversational agents as an instance of supervised learning (Vinyals & Le, 2015).", "startOffset": 138, "endOffset": 185}, {"referenceID": 24, "context": ", that humans use words to coordinate with others and make things happen (Austin, 1962; Clark, 1996; Wittgenstein, 1953).", "startOffset": 73, "endOffset": 120}, {"referenceID": 7, "context": "A third branch of research focuses on \u201cWizard-of-Oz\u201d environments, where agents learn to play games by interacting with a complex scripted environment (Mikolov et al., 2015).", "startOffset": 151, "endOffset": 173}, {"referenceID": 3, "context": "(Goodfellow et al., 2014) and game playing (Silver et al.", "startOffset": 0, "endOffset": 25}, {"referenceID": 11, "context": ", 2014) and game playing (Silver et al., 2016) approaches show that learning can be bootstrapped from competition between agents.", "startOffset": 25, "endOffset": 46}, {"referenceID": 10, "context": "Most related to our work Sukhbaatar et al. (2016) and Foerster et al.", "startOffset": 25, "endOffset": 50}, {"referenceID": 1, "context": "(2016) and Foerster et al. (2016) show that neural networks can evolve communication in the context of games without a pre-coded communication protocol.", "startOffset": 11, "endOffset": 34}, {"referenceID": 1, "context": "(2016) and Foerster et al. (2016) show that neural networks can evolve communication in the context of games without a pre-coded communication protocol. We pursue the same question, but further ask how we can change our environment to make the emergent language more interpretable. Others (e.g., SHRLDU program of Winograd (1971) or the games of Wang et al.", "startOffset": 11, "endOffset": 330}, {"referenceID": 5, "context": "3 EXPERIMENTAL SETUP Images We use the McRae et al.\u2019s (2005) set of 463 base-level concrete concepts (e.", "startOffset": 39, "endOffset": 61}, {"referenceID": 4, "context": "For example, Jorge et al. (2016) explore agents playing a \u201cGuess Who\u201d game to learn about the emergence of question-asking and answering in language.", "startOffset": 13, "endOffset": 33}, {"referenceID": 22, "context": "Parameters are updated through the Reinforce rule (Williams, 1992).", "startOffset": 50, "endOffset": 66}, {"referenceID": 6, "context": "The objects in our images were categorized into 20 broader categories (such as weapon and mammal) by McRae et al. (2005). If the agents converged to higher level semantic meanings for the symbols, we would expect that objects belonging to the same category would activate the same symbols, e.", "startOffset": 101, "endOffset": 121}, {"referenceID": 10, "context": "Coordination can only occur if the basis of the coordination is common knowledge (Rubinstein, 1989), therefore if we remove some facts from common knowledge, we will preclude our agents from coordinating on them.", "startOffset": 81, "endOffset": 99}, {"referenceID": 11, "context": "Taking inspiration from AlphaGo (Silver et al., 2016), an AI that reached the Go master level by combining interactive learning in games of self-play with passive supervised learning from a large set of human games, we combine the usual referential game, in which agents interactively develop their communication protocol, with a supervised image labeling task, where the sender must learn to assign objects their conventional names.", "startOffset": 32, "endOffset": 53}], "year": 2016, "abstractText": "The current mainstream approach to train natural language systems is to expose them to large amounts of text. This passive learning is problematic if we are interested in developing interactive machines, such as conversational agents. We propose a framework for language learning that relies on multi-agent communication. We study this learning in the context of referential games. In these games, a sender and a receiver see a pair of images. The sender is told one of them is the target and is allowed to send a message from a fixed, arbitary vocabulary to the receiver. The receiver must rely on this message to identify the target. Thus, the agents develop their own language interactively out of the need to communicate. We show that two networks with simple configurations are able to learn to coordinate in the referential game. We further explore how to make changes to the game environment to cause the \u201cword meanings\u201d induced in the game to better reflect intuitive semantic properties of the images. In addition, we present a simple strategy for grounding the agents\u2019 code into natural language. Both of these are necessary steps towards developing machines that are able to communicate with humans productively.", "creator": "LaTeX with hyperref package"}}}