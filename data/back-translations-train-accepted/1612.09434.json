{"id": "1612.09434", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Dec-2016", "title": "Data driven estimation of Laplace-Beltrami operator", "abstract": "Approximations of Laplace-Beltrami operators on manifolds through graph Lapla-cians have become popular tools in data analysis and machine learning. These discretized operators usually depend on bandwidth parameters whose tuning remains a theoretical and practical problem. In this paper, we address this problem for the unnormalized graph Laplacian by establishing an oracle inequality that opens the door to a well-founded data-driven procedure for the bandwidth selection. Our approach relies on recent results by Lacour and Massart [LM15] on the so-called Lepski's method.", "histories": [["v1", "Fri, 30 Dec 2016 09:33:07 GMT  (234kb,D)", "http://arxiv.org/abs/1612.09434v1", null]], "reviews": [], "SUBJECTS": "cs.CG cs.LG math.ST stat.TH", "authors": ["fr\u00e9d\u00e9ric chazal", "ilaria giulini", "bertrand michel"], "accepted": true, "id": "1612.09434"}, "pdf": {"name": "1612.09434.pdf", "metadata": {"source": "CRF", "title": "Data driven estimation of Laplace-Beltrami operator", "authors": ["Fr\u00e9d\u00e9ric Chazal", "Ilaria Giulini"], "emails": ["frederic.chazal@inria.fr", "ilaria.giulini@me.com", "bertrand.michel@ec-nantes.fr"], "sections": [{"heading": "1 Introduction", "text": "The Laplace-Beltrami operator is a basic and widely studied mathematical tool that contains a lot of intrinsic topological and geometric information about the Riemannian method. [BN08] Over the past fifteen years, we have faced many efforts leading to an enormous literature to understand the convergence of graphs Laplacian operators. [BN08] and a (unified) central boundary theorem to LaplaceBeltrami operators. [BN08] and a (unified) functional system of Laplacian operators has been achieved in LaplaceBeltrami operators. [BN05] The results have also been established in [BN08] and [HAL07], and a (unified) central boundary theorem."}, {"heading": "2 Lepski\u2019s procedure for estimating the Laplace-Beltrami operator", "text": "Remember that for a compact d-dimensional smooth belt manifold M with volume dimension \u00b5, the Laplace-Beltrami operator is the linear operator defined in the space of smooth functions on M, such as (f) = \u2212 div (f), where [f) is the gradient vector field and the divergence operator div. In other words, when using the Stoxos formula, [f] is the only linear operator, the [f) fdm (f) fdm. Replace the volume dimension with a distribution P, which is absolutely continuous in relation to [f], the weighted Laplace-Beltrami operator [P] is defined as \"Laplace-f + 1p < [f] fm.f > (f) fdm.\""}, {"heading": "2.1 Lepski\u2019s procedure", "text": "Let us first briefly explain the ideas of Lepski's method. Let us consider a target quantity, a collection of estimators, and a loss function. A standard object in the selection of s \u00b2 h tries to minimize the risk E '(s, s \u00b2 h) in the estimator family. In most cases, however, the concept of variance can be controlled fairly precisely. Lepski's method requires that the variance of each estimator s \u00b2 h can be limited by a quantity v (h). In most cases, the bias can be written as \"(s, s \u00b2 h), where s \u00b2 h (s, s \u00b2 h) is the average version of s \u00b2 h."}, {"heading": "2.2 Variance of the graph Laplacian for smooth functions", "text": "In order to control the concept of variance, we consider for this work the set of F smooth functions f: M \u00b2 R uniformly limited to the third order. For some constant CF > 0, letF = {f \u00b2 C3 (M, R), as well as f (k) smooth functions \u2264 CF, k = 0,.., 3 (5) Here we mean that in any normal coordinate system all partial derivatives of the order k \u00b2 of f are limited by CF. We present some notation before we call the concept of variance for f \u00b2 F. DefineD\u03b1 = 1 (4\u03c0) d \u00b2 Rd \u00b2 Rd \u00b2 Rd (C \u00b2 \u00b2 \u00b2 2 + C1 \u00b2 u \u00b2 s \u00b2 of the order k \u00b2 / 4 du (6) D = 1 (4\u03c0) d / 2 \u00b2 Rd \u00b2 d \u00b2 s (C \u00b2 s \u00b2 s \u00b2 s)."}, {"heading": "3 Results", "text": "s performance is almost as good as it would be if we knew the risks of each appraiser. Specifically, it performs a (almost) optimal trade-off between the variance concept V (h) and the approximation concept V (h) = Df (h) = max (p) P \u2212 E [p])) f \u00b2 2, M, suph \u00b2 h (E [p) \u2212 E [p], [p], f \u00b2, [p], [p \u00b2, p \u00b2, p \u00b2, p \u00b2, p \u00b2, p \u00b2, p \u00b2, p \u00b2, p \u00b2, p \u00b2, p \u00b2, p \u00b2, p, p, p \u00b2 p, p, p \u00b2 p, p, p \u00b2 p, p, p \u00b2 p, p \u00b2 p, p \u00b2, p \u00b2, p \u00b2 p, p, p \u00b2 p, p \u00b2 p, p, p, p, p, p, p, p \u00b2 p, p, p, p, p, p, p \u00b2 p, p, p, p, p, p, p \u00b2, p, p, p, p, p, p \u00b2, p, p, p, p, p, p, p \u00b2, p, p, p, p, p, p \u00b2, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p, p,"}, {"heading": "4 Sketch of the proof of Theorem 3.1", "text": "We note that the following inequality (p) P (h) + aV (h). (13) Indeed (for h). (13) Indeed (for h). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H). (H).). (H. (H. (H). (H). (H). (H. (H). (H). (H). (H.). (H.). (H.). (H.). (H. (H. (H.). (H. (H.). (H.). (H.). (H.). (H.). (H. (H. (H.). (H.).). (H. (H. (H.)."}, {"heading": "5 Numerical illustration", "text": "In this section, we will illustrate the results of the previous section with a simple example. In Section 5.1, we will describe a practical procedure for sampling the data set X for M according to the uniform measurement, a numerical representation given to us in Section 5.2 if M is the unit of 2-dimensional sphere in R3."}, {"heading": "5.1 Practical application of the Lepksi\u2019s method", "text": "Lepskis method, which is presented in section 2, cannot be applied directly in practice for two reasons: firstly, we cannot calculate the L2 standard because it is unknown. Secondly, the terms of variance involved in Lepskis method are not fully explicit.With regard to the first edition, we cannot approximate the results of the L2 standard by dividing the data into two samples: an estimate sample X1 for the calculation of the estimator and a validation sample X2 for the evaluation of this norm. To be more precise: There will be two estimators working with X1, the quantity number X1, the quantity X1, the quantity X1, the quantity h, the quantification h, the quantification h, the quantification X22, the range X2, the quantification X2, the quantification X2, the quantification X2, the quantification X2, the quantification X2, the quantification, the quantification X2, the quantification, the quantification, the quantification, the quantification X2, the quantification, the quantification, the quantification, the quantification X2, the quantification, the quantification, the quantification X2, the quantification, the quantification, the X2, the quantification, the quantification, the quantification X2, the quantification, the X2, the quantification, the X2, the quantification, the X2, the quantification, the X2, the quantification, the X2, the quantification, the quantification, the X2 and the quantification X2, the X2, the quantification X2, the quantification, the quantification, the quantification X2, the quantification, the quantification, the quantification, the quantification X2, the quantification, the quantification, the quantification X2 and the quantification X2, the X2, the quantification, the quantification, the quantification X2, the quantification, the quantification, the quantification, the quantity and the X2, the X2, the quantification, the quantification, the quantification, the quantification, the quantification, the quantity, the quantitative, the quantification X2, the quantitative, the quantitative, the quantitative and the quantit"}, {"heading": "5.2 Illustration on the sphere", "text": "In this section, we illustrate the full method using a simple example with evenly generated data points on the sphere S2 in R3. In this case, the weighted Laplace Beltrami Operator is equal to the (unweighted) Laplace Beltrami Operator on the sphere. We observe the function f (x, y, z) = (x2 + y2 + z) sinx cosx. The limitation of this function on the sphere is well known that the Laplace Beltrami Operator on the sphere has the following representation in spherical coordinates: f (see section 3 in [Gri09]): \"S2u = 1sin2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 2% 3% 3% 3% 3% 3% 3% 3% 3% 3% 3% 4% 4% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5% 5%"}, {"heading": "6 Discussion", "text": "This paper is a first attempt for a complete and well-founded data-based method for deriving LaplaceBeltrami operators from data points. Our results suggest various extensions and raise some interesting questions. For example, other versions of the Laplacian diagram have been studied in the literature (see, for example, [HAL07, BN08]), for example, when data is not consistently sampled. It would be relevant to propose a method for bandwidth selection for these alternative estimators as well. From a practical point of view, as explained in Section 5, there is a gap between the theory we receive in the thesis and what can be done in practice. To close this gap, a first goal is to demonstrate an oracle inequality in the sense of theorem 3.1 for a distortion concept defined in practice, which is calculated in terms of empirical standards. A second goal is to adapt mathematically well-founded heuristics for calibration of the parameters and bce.ing bandwidth estimation for the current practice of the LaplaceBeltrami operators."}, {"heading": "Appendix: the geometric constants C and C1", "text": "The following classical problem (see e.g. [GK06] [Prop. 2.2 and Eq. 3.20]) sets the constants C and C1 introduced in equations (6) and (7) in relation to the geometric structure of M. Lemma 6.1. There are constants C, C1 > 0 and a positive real number r > 0, so that for each x-M and each v-TxM, so that each x-T-M, each x-T-M, each x-T-M is the exponential map and (gi, j) i, j, j, 2d and 2d-T are the components of the metric tensors."}, {"heading": "Acknowledgments", "text": "The authors thank Pascal Massart for helpful discussions about Lepski's method and Antonio Rieser for his careful reading and identification of a technical error in a preliminary version of this work. This work was supported by the ANR project TopData ANR-13-BS01-0008 and ERC Gudhi No. 339025."}, {"heading": "Appendix: Proofs", "text": "For the sake of simplicity, we introduce the renamed kernelHh (y) = 1hd + 2 K (y / h) = 1hd + 2 (4\u03c0) d / 2 e \u2212 2 m / 4h 2, y \u2212 Rm, so that Xn is a finite point cloud (i.i.d.) sampled for M. Note that the expectation \u00b2 h (y \u2212 Xi) [f (y) \u2212 f (y) = Hh (y \u2212 x) [f (x) \u2212 f (y)] dP (x).We present a technical result that is useful below and whose proof is deferred to Section 6.5.Lemma 6.2."}, {"heading": "6.1 Proof of Proposition 2.1", "text": "To obtain the limit V (h) for E, we note that the sample is according to the definition of \u0445\u0430\u043b\u0435h and using the fact that the sample is i.i.d., E [\u0432 (E [\u0432 [\u0445\u044bh] \u2212 \u0445\u044b\u0435 h) f \u0442 22, M] \u2264 1 n E [\u0432 | Hh (y \u2212 X) (f (X) \u2212 f (y) | 2 d\u00b5 (y)] \u2264 1 n I2 (h), with the last line of Lemma 6.2 following."}, {"heading": "6.2 Proof of Theorem 3.1", "text": "According to the sketch of the evidence in section 4, we only need to prove Proposition 4.2 and Proposition 4.3."}, {"heading": "6.2.1 Proof of Proposition 4.2", "text": "Considering the definition of B (h), da, for each h (h), for each h (h), for each h (h), for each h (h), for each h (h), for each h (h), for each (h), for each h (h), for each h (h), for each h (h), for each h (h), for each h (h), for each h (h), for each (h), for each (h), for each (h), for each (h), for each (h), for each (h), for each (h), for each (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h), for (h, for (h), for (h), for (h), for (h, for (h), for (h), for (h, for (h), for (h), for (h), for (h, for (h), for (h), for (h, for (h), for (h), for, for (h, for), for (h (h), for (h (h), for), for, for (h (h, for), for), for (h (h (h, for), for), for (h (h, for), for, h (h (h (h (h), for), for), for, for (h (h (h (h), for, for), for, h (h (h (h (h), for), for, h (h (h (h), for), for, for, for, for, h (h (h (h), for, h (h (h"}, {"heading": "6.2.2 Proof of Proposition 4.3", "text": "(V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (V) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H) (H (H) (H) (H) (H) (H (H) (H) (H) (H (H) (H) (H (H) (H) (H) (H) (H (H) (H (H) (H) (H (H) (H (H) (H) (H (H) (H (H) (H) (H (H) (H (H) (H (H) (H) (H (H (H) (H (H) (H) (H) (H (H) (H) (H (H) (H (H (H) (H) (H (H) (H) (H (H) (H (H (H (H) (H) (H (H) (H"}, {"heading": "6.3 Proof of Proposition 3.2", "text": "We first show that if x / 2h / 2h / 2h / 2h / 2h / 2h / 2h / 2h / 2h / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b / 2b"}, {"heading": "6.4 Proof of Theorem 3.3", "text": "(For f, F), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (n), (, (,), (, (,), (, (,), (, (, (,), (, (,,,,,, (,), (, (,), (, (,,,,,, (,), (, (,,), (, (,), (, (,,), (, (,,,,, (,), (, (,), (,, (,), (,, (,), (,,, (,,,,,,,, (,), (, (,,), (, (,), (, (,), (, (,), (, (,,), (, (,), (,, (,), (, (,), (, (,),), (, (,, (, (,,), (, (,), (, (,), (, (, (,),, (, (,,,, (, (,), (,), (, (,,, (, (,), (, (,,), (,, (,), (, (,),, (, (,), (, (,,,,, (,),, (, (, (,), (, (,),, (,),, (,),, (, (, (,"}, {"heading": "6.5 Proof of Lemma 6.2", "text": "To prove this, we must first look at the integral system on B and we will first consider the x-normal coordinates. Taking into account the fact that the measurement has a density, we will include the x-normal coordinates detgij in the x-normal coordinates, we will consider the x-normal coordinates."}, {"heading": "6.6 Proofs of the technical lemmas in section 6.3", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.6.1 Proof of Lemma 6.7", "text": "(1), (2), (2), (1), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2), (2"}, {"heading": "6.6.2 Proof of Lemma 6.8", "text": "After eq. (14) I2f. (x) p. \u2212 p. \u2212 p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (v) p. (p.) (.) (.) (p.) (.) (.) (p.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (.) (."}], "references": [{"title": "A survey of cross-validation procedures for model selection", "author": ["Sylvain Arlot", "Alain Celisse"], "venue": "Statistics surveys,", "citeRegEx": "Arlot and Celisse,? \\Q2010\\E", "shortCiteRegEx": "Arlot and Celisse", "year": 2010}, {"title": "Data-driven calibration of penalties for least-squares regression", "author": ["Sylvain Arlot", "Pascal Massart"], "venue": "The Journal of Machine Learning Research,", "citeRegEx": "Arlot and Massart.,? \\Q2009\\E", "shortCiteRegEx": "Arlot and Massart.", "year": 2009}, {"title": "Minimal penalties for gaussian model selection", "author": ["Lucien Birg\u00e9", "Pascal Massart"], "venue": "Probability theory and related fields,", "citeRegEx": "Birg\u00e9 and Massart.,? \\Q2007\\E", "shortCiteRegEx": "Birg\u00e9 and Massart.", "year": 2007}, {"title": "Slope heuristics: overview and implementation", "author": ["Jean-Patrick Baudry", "Cathy Maugis", "Bertrand Michel"], "venue": "Statistics and Computing,", "citeRegEx": "Baudry et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Baudry et al\\.", "year": 2012}, {"title": "Laplacian eigenmaps for dimensionality reduction and data representation", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Neural computation,", "citeRegEx": "Belkin and Niyogi.,? \\Q2003\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2003}, {"title": "Semi-supervised learning on riemannian manifolds", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Machine learning,", "citeRegEx": "Belkin and Niyogi.,? \\Q2004\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2004}, {"title": "Towards a theoretical foundation for laplacian-based manifold methods", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "In Learning theory,", "citeRegEx": "Belkin and Niyogi.,? \\Q2005\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2005}, {"title": "Convergence of laplacian eigenmaps", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Advances in Neural Information Processing Systems,", "citeRegEx": "Belkin and Niyogi.,? \\Q2007\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2007}, {"title": "Towards a theoretical foundation for laplacian-based manifold methods", "author": ["Mikhail Belkin", "Partha Niyogi"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Belkin and Niyogi.,? \\Q2008\\E", "shortCiteRegEx": "Belkin and Niyogi.", "year": 2008}, {"title": "Empirical graph laplacian approximation of laplace\u2013beltrami operators: Large sample results", "author": ["E. Gin\u00e9", "V. Koltchinskii"], "venue": "In High dimensional probability,", "citeRegEx": "Gin\u00e9 and Koltchinskii.,? \\Q2006\\E", "shortCiteRegEx": "Gin\u00e9 and Koltchinskii.", "year": 2006}, {"title": "Universal pointwise selection rule in multivariate function estimation", "author": ["Alexander Goldenshluger", "Oleg Lepski"], "venue": null, "citeRegEx": "Goldenshluger and Lepski,? \\Q2008\\E", "shortCiteRegEx": "Goldenshluger and Lepski", "year": 2008}, {"title": "Structural adaptation via lp-norm oracle inequalities", "author": ["A. Goldenshluger", "O. Lepski"], "venue": "Probability Theory and Related Fields,", "citeRegEx": "Goldenshluger and Lepski.,? \\Q2009\\E", "shortCiteRegEx": "Goldenshluger and Lepski.", "year": 2009}, {"title": "Heat kernel and analysis on manifolds, volume 47", "author": ["Alexander Grigoryan"], "venue": "American Mathematical Soc.,", "citeRegEx": "Grigoryan.,? \\Q2009\\E", "shortCiteRegEx": "Grigoryan.", "year": 2009}, {"title": "Graph laplacians and their convergence on random neighborhood graphs", "author": ["M. Hein", "JY Audibert", "U.von Luxburg"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Hein et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hein et al\\.", "year": 2007}, {"title": "On problems of adaptive estimation in white gaussian noise", "author": ["Oleg V Lepski"], "venue": "Topics in nonparametric estimation,", "citeRegEx": "Lepski.,? \\Q1992\\E", "shortCiteRegEx": "Lepski.", "year": 1992}, {"title": "Asymptotically minimax adaptive estimation", "author": ["OV Lepskii"], "venue": "i: Upper bounds. optimally adaptive estimates. Theory of Probability & Its Applications,", "citeRegEx": "Lepskii.,? \\Q1992\\E", "shortCiteRegEx": "Lepskii.", "year": 1992}, {"title": "Asymptotically minimax adaptive estimation. ii. schemes without optimal adaptation: Adaptive estimators", "author": ["OV Lepskii"], "venue": "Theory of Probability & Its Applications,", "citeRegEx": "Lepskii.,? \\Q1993\\E", "shortCiteRegEx": "Lepskii.", "year": 1993}, {"title": "Minimal penalty for goldenshluger-lepski method", "author": ["Claire Lacour", "Pascal Massart"], "venue": "arXiv preprint arXiv:1503.00946,", "citeRegEx": "Lacour and Massart.,? \\Q2015\\E", "shortCiteRegEx": "Lacour and Massart.", "year": 2015}, {"title": "Estimator selection: a new method with applications to kernel density estimation", "author": ["Claire Lacour", "Pascal Massart", "Vincent Rivoirard"], "venue": "arXiv preprint arXiv:1607.05091,", "citeRegEx": "Lacour et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lacour et al\\.", "year": 2016}, {"title": "Optimal spatial adaptation to inhomogeneous smoothness: an approach based on kernel estimates with variable bandwidth selectors", "author": ["Oleg V Lepski", "Enno Mammen", "Vladimir G Spokoiny"], "venue": "The Annals of Statistics,", "citeRegEx": "Lepski et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Lepski et al\\.", "year": 1997}, {"title": "Diffusion maps, spectral clustering and reaction coordinates of dynamical systems", "author": ["B. Nadler", "S. Lafon", "RR Coifman", "IG Kevrekidis"], "venue": "Applied and Computational Harmonic Analysis,", "citeRegEx": "Nadler et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Nadler et al\\.", "year": 2006}, {"title": "A topological approach to spectral clustering", "author": ["Antonio Rieser"], "venue": null, "citeRegEx": "Rieser.,? \\Q2015\\E", "shortCiteRegEx": "Rieser.", "year": 2015}, {"title": "The Laplacian on a Riemannian manifold: an introduction to analysis on manifolds. Number 31", "author": ["Steven Rosenberg"], "venue": null, "citeRegEx": "Rosenberg.,? \\Q1997\\E", "shortCiteRegEx": "Rosenberg.", "year": 1997}, {"title": "An analysis of the convergence of graph laplacians", "author": ["Daniel Ting", "Ling Huang", "Michael Jordan"], "venue": "arXiv preprint arXiv:1101.5435,", "citeRegEx": "Ting et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ting et al\\.", "year": 2011}, {"title": "Consistency of spectral clustering", "author": ["Ulrike Von Luxburg", "Mikhail Belkin", "Olivier Bousquet"], "venue": "The Annals of Statistics,", "citeRegEx": "Luxburg et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Luxburg et al\\.", "year": 2008}], "referenceMentions": [], "year": 2017, "abstractText": "Approximations of Laplace-Beltrami operators on manifolds through graph Laplacians have become popular tools in data analysis and machine learning. These discretized operators usually depend on bandwidth parameters whose tuning remains a theoretical and practical problem. In this paper, we address this problem for the unnormalized graph Laplacian by establishing an oracle inequality that opens the door to a well-founded data-driven procedure for the bandwidth selection. Our approach relies on recent results by Lacour and Massart [LM15] on the so-called Lepski\u2019s method.", "creator": "LaTeX with hyperref package"}}}