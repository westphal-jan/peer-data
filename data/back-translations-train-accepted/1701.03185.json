{"id": "1701.03185", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-Jan-2017", "title": "Generating High-Quality and Informative Conversation Responses with Sequence-to-Sequence Models", "abstract": "Building general-purpose conversation agents is a very challenging task, but necessary on the road toward intelligent agents that can interact with humans in natural language. Neural conversation models -- purely data-driven systems trained end-to-end on dialogue corpora -- have shown great promise recently, yet they often produce short and generic responses. This work presents new training and decoding methods that improve the quality, coherence, and diversity of long responses generated using sequence-to-sequence models. Our approach adds self-attention to the decoder to maintain coherence in longer responses, and we propose a practical approach, called the glimpse-model, for scaling to large datasets. We introduce a stochastic beam-search algorithm with segment-by-segment reranking which lets us inject diversity earlier in the generation process. We trained on a combined data set of over 2.3B conversation messages mined from the web. In human evaluation studies, our method produces longer responses overall, with a higher proportion rated as acceptable and excellent as length increases, compared to baseline sequence-to-sequence models with explicit length-promotion. A back-off strategy produces better responses overall, in the full spectrum of lengths.", "histories": [["v1", "Wed, 11 Jan 2017 22:55:04 GMT  (178kb,D)", "http://arxiv.org/abs/1701.03185v1", "Submitted to ICLR 2017"], ["v2", "Mon, 31 Jul 2017 16:53:33 GMT  (232kb,D)", "http://arxiv.org/abs/1701.03185v2", "To appear in EMNLP 2017"]], "COMMENTS": "Submitted to ICLR 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["yuanlong shao", "stephan gouws", "denny britz", "anna goldie", "brian strope", "ray kurzweil"], "accepted": true, "id": "1701.03185"}, "pdf": {"name": "1701.03185.pdf", "metadata": {"source": "CRF", "title": "NEURAL CONVERSATION MODELS", "authors": ["Louis Shao", "Stephan Gouws", "Denny Britz", "Anna Goldie", "Brian Strope", "Ray Kurzweil"], "emails": ["overmind@google.com", "sgouws@google.com", "dennybritz@google.com", "agoldie@google.com", "bps@google.com", "raykurzweil@google.com"], "sections": [{"heading": null, "text": "Building universal talking agents is a very demanding task, but necessary on the path to intelligent agents that can interact with humans in natural language. Neural talking models - purely data-driven systems trained end-to-end on dialog corpora - have recently proven promising, but often lead to short and generic answers. This work presents new training and decryption methods that improve the quality, coherence, and variety of long answers generated using sequence-to-sequence models. Our approach gives the decoder additional self-esteem to maintain coherence in longer answers, and we propose a practical approach, called the Glight Model, to scale to large data sets. We introduce a stochastic beam search algorithm with segment-by-segment reranking that allows us to inject diversity earlier in the generation process."}, {"heading": "1 INTRODUCTION", "text": "Building computer systems that are universally applicable is a challenging problem, but it is a necessary step toward building intelligent agents that can interact with humans through natural language and eventually pass the Turing test. Sequence-to-sequence (seq2seq) has proven to be a data-driven approach in areas that can be considered learn-to-and-variable-length sequences, including machine translation (Sutskever et al., 2014; Wu et al., 2016). Neural conversation models are the latest development in the field of conversation modeling, with the promise of converting computers into end-to-end mode (Vinyals & Le, 2015; Shang et al., 2015; Sordoni et al., 2015). Despite promising results, there are still many challenges with this approach."}, {"heading": "2 OVERVIEW AND MOTIVATION", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "3 SEQ2SEQ MODEL WITH ATTENTION ON TARGET", "text": "In this setting, there is a source sequence X = (x1, x2,..., xM) and a target sequence Y = (y0, y1, y2,..., yN). We assume that y0 is always the start-of-sequence symbol and yN is the end-of-sequence symbol. In a typical sequence-to-sequence model, the encoder receives its input from the source sequence X and the decoder model of the conditional language model P (Y | X) of the target sequence Y, since X.Seq2seq models with attention (Bahdanau et al, 2014) parameterise the condition probability as: P (yi | Y [0: i \u2212 1] = P (yi, y1, yi \u2212 1, x3,..., xM)."}, {"heading": "4 STOCHASTIC DECODING WITH SEGMENT-BY-SEGMENT RERANKING", "text": "Our strategy is to perform re-ranking with a normalized result at the segment level, where we generate the candidate segments with a trained insight model and use a stochastic beam search method that we discuss next. However, the complete decoding algorithm proceeds segment by segment. The standard beam search algorithm generates symbols step-by-step using a series of B-scanning beams that have been generated so far in each step 2. The algorithm adds all possible single-token enhancements to each existing beam and then selects the top B-beams that are used in our stochastic beam search algorithm by replacing this deterministic top B selection with a stochastic sampling operation to encourage variation. Furthermore, in order to discourage a single beam from searching and reduce the final response diversity, we perform a two-step ampling: 1."}, {"heading": "5 EXPERIMENTAL RESULTS", "text": "In this section, we present experimental results to evaluate the Target-glimpse model and the stochastic decryption method that we have presented. We train the model using Google's Neural Machine Translation Model (GNMT, Wu et al. (2016)) based on a data set that combines multiple web-derived sources: 2beams are also referred to as \"hypotheses,\" and B is referred to as \"beam width.\" 1. The full Reddit data3, which contains 1.7 billion messages (221 million conversations); 2. The open subtitles data of 2009 (0.5 million conversations, Tiedemann (2009); 3. The stack exchange data (0.8 million conversations); 4. Dialog-like texts that we have detected and extracted from the web (17 million conversations). For all of these data sets, we extract pairs of messages, where one can be viewed as a response to the other."}, {"heading": "5.1 EVALUATION METRIC", "text": "It is difficult to find an objective answer to the question of whether it is a purely problem or not."}, {"heading": "5.2 MOTIVATING EXPERIMENTS", "text": "To see if generating long answers is actually a challenging problem, we trained the simple seq2seq with the GNMT model, in which the encoder holds the source sequence and the decoder the target sequence. We experimented with standard beam search and beam search with length normalization \u03b1 = 0.8 similar to Wu et al. (2016). With this length normalization, the answers generated are actually longer, but they are more often semantically incoherent. \"I have no idea what you are talking about.\" More frequently, similarly observed in Li et al. (2016). Human evaluation results are summarized in Figure 3 (a). Methods that generate longer answers have more bad and less excellent / good ratings. We also performed the N-select-1 evaluation based on the baseline model, using different normalization schemes. The results are shown in Table 2 (a), no normalization means that we are using Y | X for the evaluation."}, {"heading": "5.3 LARGE-SCALE EXPERIMENTS", "text": "For our large-scale experiments, we have set our target flash model to the full combined dataset. Figure 2 (b) shows the training curve. In this figure, we also include the curve for K = 1, that is, the flash model with the decoder length 1. It is clear that this model is much slower, so we finish it early. This means that the flash model with K = 10 progresses faster than the base model with only the source-side attention, because the model is fixed on examples with the decoder length, while the average response length is 38 in our data."}, {"heading": "6 CONCLUSION", "text": "Research into the design of end-to-end systems that can conduct universal conversations is in its infancy, but more significant advances are expected with more advanced neural architectures, but our findings in this paper show that minimal modeling changes and a slightly more advanced decoding technique, combined with training on very large datasets, can still lead to noticeable improvements in the quality of responses generated using neural conversation models. Overall, we found that using fixed lengths in the decoder facilitates training on large datasets and allows us to improve the diversity and coherence of responses generated earlier during generation when they have the greatest impact. While the focus of this work was on conversation modeling, we expect some of these findings to be applied to other sequence settings, such as machine translation or captions."}, {"heading": "ACKNOWLEDGMENTS", "text": "We would like to thank Quoc Le, Oriol Vinyals and Jakob Uszkoreit for many helpful discussions, as well as Scott Benson, Fuchun Peng for collecting the context-free prompt and Amin Ahmad for setting up the human evaluation and Rami Eid, Daniel Cer for collecting training records and Yonghui Wu, Zhifeng Chen, Mike Schuster for helping train the GNMT model."}, {"heading": "A THE CONTEXT-FREE PROMPT LIST AND EVALUATION RESULTS", "text": "That is why we have to wait so long to be able to get things back on track."}], "references": [{"title": "TensorFlow: Large-scale machine learning on heterogeneous systems", "author": ["cent Vanhoucke", "Vijay Vasudevan", "Fernanda Vi\u00e9gas", "Oriol Vinyals", "Pete Warden", "Martin Wattenberg", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng"], "venue": null, "citeRegEx": "Vanhoucke et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vanhoucke et al\\.", "year": 2015}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "The fisher corpus: a resource for the next generations of speech-to-text", "author": ["Christopher Cieri David", "David Miller", "Kevin Walker"], "venue": "In in Proceedings 4th International Conference on Language Resources and Evaluation,", "citeRegEx": "David et al\\.,? \\Q2004\\E", "shortCiteRegEx": "David et al\\.", "year": 2004}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan"], "venue": "arXiv preprint arXiv:1510.03055,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Deep reinforcement learning for dialogue generation", "author": ["Jiwei Li", "Will Monroe", "Alan Ritter", "Michel Galley", "Jianfeng Gao", "Dan Jurafsky"], "venue": "CoRR, abs/1606.01541,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Neural responding machine for short-text conversation", "author": ["Lifeng Shang", "Zhengdong Lu", "Hang Li"], "venue": "arXiv preprint arXiv:1503.02364,", "citeRegEx": "Shang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan"], "venue": "arXiv preprint arXiv:1506.06714,", "citeRegEx": "Sordoni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le"], "venue": "Advances in Neural Information Processing Systems", "citeRegEx": "Sutskever et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "News from OPUS - A Collection of Multilingual Parallel Corpora with Tools and Interfaces", "author": ["J\u00f6rg Tiedemann"], "venue": "Recent Advances in Natural Language Processing (vol V),", "citeRegEx": "Tiedemann.,? \\Q2009\\E", "shortCiteRegEx": "Tiedemann.", "year": 2009}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le"], "venue": "arXiv preprint arXiv:1506.05869,", "citeRegEx": "Vinyals and Le.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}], "referenceMentions": [{"referenceID": 7, "context": "The sequence-to-sequence (seq2seq) model has proven very popular as a purely data-driven approach in domains that can be cast as learning to map to and from variable-length sequences, with state-of-the art results in many domains, including machine translation (Cho et al., 2014; Sutskever et al., 2014; Wu et al., 2016).", "startOffset": 261, "endOffset": 320}, {"referenceID": 5, "context": "Neural conversation models are the latest development in the domain of conversation modeling, with the promise of training computers to converse in an end-to-end fashion (Vinyals & Le, 2015; Shang et al., 2015; Sordoni et al., 2015).", "startOffset": 170, "endOffset": 232}, {"referenceID": 6, "context": "Neural conversation models are the latest development in the domain of conversation modeling, with the promise of training computers to converse in an end-to-end fashion (Vinyals & Le, 2015; Shang et al., 2015; Sordoni et al., 2015).", "startOffset": 170, "endOffset": 232}, {"referenceID": 6, "context": "In particular, these models produce short, generic responses that lack diversity (Sordoni et al., 2015; Li et al., 2015).", "startOffset": 81, "endOffset": 120}, {"referenceID": 3, "context": "In particular, these models produce short, generic responses that lack diversity (Sordoni et al., 2015; Li et al., 2015).", "startOffset": 81, "endOffset": 120}, {"referenceID": 1, "context": "In the seq2seq approach, the decoder network therefore only has to keep track of where it is in the output, and the content to generate can be transformed from the relevant parts in the source via the attention mechanism (Bahdanau et al., 2014).", "startOffset": 221, "endOffset": 244}, {"referenceID": 8, "context": "We were able to achieve small perplexity gains using this idea on the small OpenSubtitles 2009 data set (Tiedemann, 2009).", "startOffset": 104, "endOffset": 121}, {"referenceID": 3, "context": "Another approach to explicitly create variation in the generated responses is to rerank the N -best MAP-decoded list of responses from the model using diversity-promoting heuristics (Li et al., 2015).", "startOffset": 182, "endOffset": 199}, {"referenceID": 1, "context": "Seq2seq models with attention (Bahdanau et al., 2014) parameterize the per-symbol conditional probability as:", "startOffset": 30, "endOffset": 53}, {"referenceID": 3, "context": "In the case of reranking whole target sequences Y, this becomes the marginal P (Y), which corresponds to the same diversity-promoting objective used in Li et al. (2015). However, we found that our approximation works better in terms of N-choose-1 accuracy (see Section 5.", "startOffset": 152, "endOffset": 169}, {"referenceID": 8, "context": "5 million conversations, Tiedemann (2009)).", "startOffset": 25, "endOffset": 42}, {"referenceID": 2, "context": "The Fisher corpus (David et al., 2004).", "startOffset": 18, "endOffset": 38}, {"referenceID": 3, "context": "\u201d more often, similarly observed in Li et al. (2016). The human evaluation results are summarized in Figure 3(a).", "startOffset": 36, "endOffset": 53}, {"referenceID": 3, "context": "\u201d more often, similarly observed in Li et al. (2016). The human evaluation results are summarized in Figure 3(a). Methods that generate longer responses have more Bad and less Excellent / Good ratings. We also performed the N-choose-1 evaluation on the baseline model using different normalization schemes. The results are shown in Table 2(a). No Normalization means that we use P (Y|X) for scoring, Normalize by Marginal uses P (Y|X)/P (Y), as suggested in Li et al. (2015), and Normalize by Random Prompts is our scoring objective described in Section 4.", "startOffset": 36, "endOffset": 475}, {"referenceID": 3, "context": "\u201d more often, similarly observed in Li et al. (2016). The human evaluation results are summarized in Figure 3(a). Methods that generate longer responses have more Bad and less Excellent / Good ratings. We also performed the N-choose-1 evaluation on the baseline model using different normalization schemes. The results are shown in Table 2(a). No Normalization means that we use P (Y|X) for scoring, Normalize by Marginal uses P (Y|X)/P (Y), as suggested in Li et al. (2015), and Normalize by Random Prompts is our scoring objective described in Section 4. The significant boost when using both normalization schemes indicates that the conditional log probability predicted by the model may be biased towards the language model probability of P (Y). After adding the normalization, the score may be closer to the true conditional log probability. Overall, this reranking evaluation indicates that our heuristic is preferred to scoring using the marginal. However, it is unfortunately hard to directly make use of this score during beam search decoding (i.e. generation), since the resulting sequences are usually ungrammatical, as also observed by Li et al. (2015). This is the motivation for using a segment-by-segment reranking procedure, as described in Section 4.", "startOffset": 36, "endOffset": 1165}, {"referenceID": 3, "context": "In our experiments, we were unable to generate better long, coherent responses using the whole-sequence level reranking method from Li et al. (2015) compared to using standard beam search with length-normalization6.", "startOffset": 132, "endOffset": 149}], "year": 2017, "abstractText": "Building general-purpose conversation agents is a very challenging task, but necessary on the road toward intelligent agents that can interact with humans in natural language. Neural conversation models \u2013 purely data-driven systems trained end-to-end on dialogue corpora \u2013 have shown great promise recently, yet they often produce short and generic responses. This work presents new training and decoding methods that improve the quality, coherence, and diversity of long responses generated using sequence-to-sequence models. Our approach adds selfattention to the decoder to maintain coherence in longer responses, and we propose a practical approach, called the glimpse-model, for scaling to large datasets. We introduce a stochastic beam-search algorithm with segment-by-segment reranking which lets us inject diversity earlier in the generation process. We trained on a combined data set of over 2.3B conversation messages mined from the web. In human evaluation studies, our method produces longer responses overall, with a higher proportion rated as acceptable and excellent as length increases, compared to baseline sequence-to-sequence models with explicit length-promotion. A backoff strategy produces better responses overall, in the full spectrum of lengths.", "creator": "LaTeX with hyperref package"}}}