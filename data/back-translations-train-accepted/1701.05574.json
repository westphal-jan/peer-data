{"id": "1701.05574", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "19-Jan-2017", "title": "Harnessing Cognitive Features for Sarcasm Detection", "abstract": "In this paper, we propose a novel mechanism for enriching the feature vector, for the task of sarcasm detection, with cognitive features extracted from eye-movement patterns of human readers. Sarcasm detection has been a challenging research problem, and its importance for NLP applications such as review summarization, dialog systems and sentiment analysis is well recognized. Sarcasm can often be traced to incongruity that becomes apparent as the full sentence unfolds. This presence of incongruity- implicit or explicit- affects the way readers eyes move through the text. We observe the difference in the behaviour of the eye, while reading sarcastic and non sarcastic sentences. Motivated by his observation, we augment traditional linguistic and stylistic features for sarcasm detection with the cognitive features obtained from readers eye movement data. We perform statistical classification using the enhanced feature set so obtained. The augmented cognitive features improve sarcasm detection by 3.7% (in terms of F-score), over the performance of the best reported system.", "histories": [["v1", "Thu, 19 Jan 2017 19:32:06 GMT  (292kb,D)", "http://arxiv.org/abs/1701.05574v1", "The 54th Annual Meeting of The Association for Computational Linguistics (ACL 2016)"]], "COMMENTS": "The 54th Annual Meeting of The Association for Computational Linguistics (ACL 2016)", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["abhijit mishra", "diptesh kanojia", "seema nagar", "kuntal dey", "pushpak bhattacharyya"], "accepted": true, "id": "1701.05574"}, "pdf": {"name": "1701.05574.pdf", "metadata": {"source": "CRF", "title": "Harnessing Cognitive Features for Sarcasm Detection", "authors": ["Abhijit Mishra", "Diptesh Kanojia", "Seema Nagar", "Kuntal Dey", "Pushpak Bhattacharyya"], "emails": ["pb}@cse.iitb.ac.in", "kuntadey}@in.ibm.com"], "sections": [{"heading": "1 Introduction", "text": "This year, more than ever before in the history of the country in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a city."}, {"heading": "2 Related Work", "text": "One of the pioneering works Jorgensen et al. (1984) explained how sarcasm arises when a figurative meaning is used over the literal meaning of the enunciation. In the words Clark and Gerrig (1984), the processing of sarcasm is replaced by an indirect negated message. Giora (1995), defines sarcasm as a kind of indirect negation that requires the processing of negated and implicit messages. Ivanko and Pexman define sarcasm as a six-fold entity consisting of a speaker."}, {"heading": "3 Eye-tracking Database for Sarcasm Analysis", "text": "Sarcasm often assumes inconsistencies (Campbell and Katz, 2012) that force the brain to re-analyze it (Kutas and Hillyard, 1980), which in turn influences the way the eyes move through the text. Therefore, when sarcasm is successfully processed in the text, characteristic patterns of eye movement can be observed, as opposed to verbatim texts. This hypothesis forms the core of our method for detecting sarcasm, and we confirm this using our previously freely available sarcasm dataset 2 (Mishra et al., 2016), enriched with gaze2http: / / www.cfilt.iitb.ac.in / cognitive-nlpinformation."}, {"heading": "3.1 Document Description", "text": "The database consists of 1,000 short texts of 10-40 words each, 350 of which are sarcastic and are collected as follows: (a) 103 sentences are taken from two popular sarcastic quotation websites3; (b) 76 sarcastic short film reviews are manually extracted from Amazon Movie Corpus (Pang and Lee, 2004) by two linguists; (c) 171 tweets are downloaded from Twitter using the hashtag # sarcasm; the 650 non-sarcastic texts are either downloaded from Twitter or extracted from Amazon Movie Review Corpus; the sentences do not contain words / phrases that are highly thematic or culturally specific; the tweets have been normalized to make them linguistically good, in order to avoid difficulties in interpreting the social media language; each sentence in our data set contains positive or negative opinions on certain \"aspects.\" For example, the sentence \"The film is extremely well-staffed\" has a positive attitude to the \"cast\" aspect; \"the commentators were given seven PhD students with scientific background and scientific instructions before receiving them."}, {"heading": "3.2 Task Description", "text": "The task assigned to the commentators was to read sentences individually and attach binary tags to them indicating polarity (i.e., positive / negative). Note that participants not3http: / / www.sarcasmsociety.com, http: / / www.themarysue.com / funny-amazon-reviewstructed whether a sentence is sarcastic or not, in order to exclude the primation effect (i.e., if sarcasm is expected beforehand, the processing of discrepancies becomes relatively easier (Gibbs, 1986). The setup ensures its \"ecological validity\" in two respects: (1) Readers will have no idea that they need to treat sarcasm with particular attention."}, {"heading": "4 Analysis of Eye-movement Data", "text": "We observe a pronounced behavior when reading sarcasm by analyzing the \"fixation time on the text\" (also referred to in illumination literature as \"dwell time\") and \"scan paths\" of the readers."}, {"heading": "4.1 Variation in the Average Fixation Duration per Word", "text": "Since sarcasm in the text can be expected to induce cognitive stress, it is reasonable to assume that it would require more processing time (Ivanko and Pexman, 2003). Therefore, the fixation time normalized over the total number of words for a sarcastic text should generally be higher than for a non-sarcastic text. To test statistical significance, we perform a two-step t-test (assuming unequal variance) to compare the average fixation time per word for sarcastic and non-sarcastic texts. The hypothesized mean difference is set to 0 and the margin of error (\u03b1) is set to 0.05. The t-test analysis presented in Table 1 shows that for all participants there is a statistically significant difference between the average fixation time per word and the non-sarcastic texts."}, {"heading": "I will always cherish the", "text": "When we looked at readability (Flesch readability ease-score (1948)), the number of words in a sentence, and the average character per word, together with the sarcasm label, as predictors for the average fixation time according to a linear model with mixed effects (Barr et al., 2013), sarcasm proved to be the most significant predictor with a maximum slope. This indicates that the average fixation time per word has a strong link to the sarcasm nature of the text, at least in our data sets. We are now analyzing scan paths to gain more insight into the sarcasm understanding process."}, {"heading": "4.2 Analysis of Scanpaths", "text": "Scanning paths are line diagrams that contain fixations as nodes and saccades as edges; the radii of the nodes represent the fixation duration. A scan path corresponds to the eye movement pattern of a participant when reading a particular sentence. Figure 1 represents scan paths of three participants for the sarcastic sentence S1 and the non-sarcastic sentence S2. The x-axis of the diagram represents the order of the words a reader reads, and the y-axis represents a temporal order in milliseconds. Consider a sarcastic text containing incongruent phrases A and B. Our qualitative scan pathology analysis shows that scan paths have two typical characteristics in terms of processing sarcasms. Frequently, a long regression - a saccade going to a previously visited segment - is observed when a reader begins to read B after skimming by A, and in some cases the fixation duration B is significantly higher than the fixed duration in some cases."}, {"heading": "5 Features for Sarcasm Detection", "text": "We describe the characteristics used to detect sarcasm in Table 2. Characteristics listed under lexical, implicit miscongruence and explicit miscongruence come from various literature (mainly Joshi et al. (2015)), which are indispensable for separating sarcasm from other forms of semantic miscongruence in the text (e.g. ambiguity due to semantic ambiguity or metaphors), and two other textual characteristics, namely readability and number of words in the text, are also taken into account, which are used to reduce the impact of text hardness and length on eye movement patterns."}, {"heading": "5.1 Simple Gaze Based Features", "text": "Readers \"behavior in eye movements, characterized by fixations, saccades, jumps, and regressions, can be quantified directly by simple statistical aggregation (i.e. either by calculating characteristics for individual participants and then averaging or conducting a multi-stage learning process, as explained in Section 6) Since these characteristics of eye movements affect the cognitive process of reading (Rayner and Sereno, 1994), we consider these characteristics to be characteristics in our model. Some of these characteristics have been reported by Mishra et al. (2016) for modelling the intelligibility of readers\" sarcasm. However, as far as we know, these characteristics are introduced for the first time in NLP tasks such as recognition of text sarcasm. It is assumed that the values of these characteristics increase with the increase of the surprising extent caused by mismatch in the text (except for the number of skipped movements, which will decrease)."}, {"heading": "5.2 Complex Gaze Based Features", "text": "For these characteristics, we rely on a graph structure, namely \"highlighting graphs,\" which are derived from the information of the moment and word sequences in the text. Highlighting graphs: For each reader and sentence, we construct an \"highlighting graph\" representing the characteristics of the reader. An highlighting graph for a sentence S for a reader, represented as G = (V, E), is a graph with vertices (V) and edges (E), where each vertex v \u00b2 V corresponds to a word in S. (cannot be unique) and there is an edge E between vertices v1 and v2, if R has at least one chord between the words v1 and v2.Figure 2 shows an example of a highlighting graph. A highlighting graph can be weighted, but not necessarily connected, for a given text (as words can exist in the given text without being fixed to it)."}, {"heading": "6 The Sarcasm Classifier", "text": "We interpret sarcasm detection as a binary classification problem. The training data includes 994 examples created using our eye movement database to detect sarcasm. To verify the effectiveness of our functionality, we observe the performance of multiple classification techniques on our dataset through a layered 10-fold cross validation. In addition, we compare the classification accuracy of our system with the best available systems proposed by Riloff et al. (2013) and Joshi et al. (2015) on our dataset. With Weka (Hall et al., 2009) and LibSVM (Chang and Lin, 2011) APIs, we implement the following classifiers: \u2022 Na \u00bc ive Bayes classifier \u2022 Support Vector Machines (Cortes and Vapnik, 1995) with default hyper-paramaters \u2022 Multilayer Feed Forward Neural Network \u2022 Multi Instance Logistic Regression (MILR), Xu (2004) and Frank)."}, {"heading": "6.1 Results", "text": "Table 3 shows the classification results taking into account different combinations of features for different classifiers and other systems. These are: \u2022 Unigram (with key components of Unikram feature vectors), \u2022 Sarcasm (the feature set reported by Joshi et al. (2015), subsuming Unikram features and features from other reported systems) \u2022 Gauze (the simple and complex cognitive features that we introduce along with readability and word counting features) and \u2022 Gauze + Sarcasm (the full set of features). For all regular classifiers, the visual features are averaged between the participants and supplemented by linguistic and sarcasm-related features. For the MILR classifier, the visual features derived from each participant are compared with linguistic features, and thus, for each sentence in the training data, a multi-level \"bag\" of features is formed for each sentence that we distinguish in each sentence."}, {"heading": "6.2 Considering Reading Time as a Cognitive Feature along with Sarcasm Features", "text": "It can be argued that looking at simple measures of reading effort such as \"reading time\" as a cognitive trait, rather than the expensive eye-tracking capabilities for detecting sarcasm, can be a cost-effective solution. To investigate this, we repeated our experiments with \"reading time,\" which is considered the only cognitive trait, supplemented by textual traits. F-values of all classifiers are similar to those of classifiers that only take the sarcasm trait into account, and the difference in improvement is not statistically significant (p > 0.05)."}, {"heading": "6.3 How Effective are the Cognitive Features", "text": "We examine the effectiveness of cognitive traits on classification accuracy by varying the size of the input preference data. To investigate this, we create an astracified (constant) random pull test split of 80%: 20%. We train our classifier with 100%, 90%, 80% and 70% of the training data using our entire feature set and the feature combination of Joshi et al. (2015). The quality of our system is demonstrated by improvements in F-score and Kappa statistics shown in Figure 3. We further analyze the importance of traits by evaluating the traits using (a) Chi-square test and (b) Information-Gain test using Weka's attribute selection module. Figure 4 shows the 20 most ranked traits produced by both tests. In both cases, we consider 16 of the 20 most important traits to be considered eye traits using each of the Weka attribute selection module."}, {"heading": "6.4 Example Cases", "text": "Table 4 shows some examples from the experiment with layered 80% -20% traction test fragments. \u2022 Example sentence 1 is sarcastic and requires extralinguistic knowledge (about the poor living conditions in Manchester). Therefore, the sarcasm detector, which relies only on textual characteristics, is unable to detect the underlying incongruity. However, our system successfully predicts the label, possibly aided by the visual characteristics. \u2022 Also, sentence 3 represents a false-negative case in which even people found it difficult to detect sarcasm. This is why our visual characteristics (and subsequently the complete characteristics) concern the system only with linguistic characteristics. \u2022 Sentence 3 represents a false-negative case in which even people found it difficult to detect sarcasm."}, {"heading": "6.5 Error Analysis", "text": "Errors committed by our system are caused by several factors, ranging from limitations on Eyetracker hardware to errors committed by language tools and resources. In addition, the aggregation of different eye tracking parameters to extract cognitive characteristics may have led to information loss in the regular classification setting."}, {"heading": "7 Conclusion", "text": "We have hypothesized that characteristic eye movement patterns associated with reading sarcastic texts enable improved recognition of sarcasm. We have extended traditional linguistic traits to include cognitive traits derived from the reader's eye movement data in the form of simple, look-based traits and complex traits derived from a graph structure. This extended trait set improved the success rate of the sarcasm detector by 3.7% over the best system available. The use of cognitive traits in an NLP processing system like ours is the first proposal of its kind. Our general approach could be useful in other NLP sub-areas such as sentiment and emotion analysis, text summary and question answers, where the consideration of textual cues alone does not prove sufficient. We propose to complement this work in the future by developing deeper graphical and visual traits, and we also propose to develop visual models for the purpose of displaying the individual pattern of movement."}, {"heading": "Acknowledgments", "text": "We thank the members of the CFILT Lab, especially Jaya Jha and Meghna Singh, and the students of IIT Bombay for their help and support."}], "references": [{"title": "Modelling sarcasm in twitter, a novel approach", "author": ["Horacio Saggion", "Francesco Ronzano"], "venue": "ACL", "citeRegEx": "Barbieri et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Barbieri et al\\.", "year": 2014}, {"title": "Random effects structure for confirmatory hypothesis testing", "author": ["Barr et al.2013] Dale J Barr", "Roger Levy", "Christoph Scheepers", "Harry J Tily"], "venue": null, "citeRegEx": "Barr et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Barr et al\\.", "year": 2013}, {"title": "The interplay of discourse congruence and lexical association during sentence processing: Evidence from {ERPs} and eye tracking", "author": ["Peter C. Gordon", "Tamara Y. Swaab"], "venue": "Journal of Memory and Language,", "citeRegEx": "Camblin et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Camblin et al\\.", "year": 2007}, {"title": "Are there necessary conditions for inducing a sense of sarcastic irony? Discourse Processes, 49(6):459\u2013480", "author": ["Campbell", "Katz2012] John D Campbell", "Albert N Katz"], "venue": null, "citeRegEx": "Campbell et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Campbell et al\\.", "year": 2012}, {"title": "Clues for detecting irony in user-generated contents: oh...!! it\u2019s so easy;-)", "author": ["Lu\u0131\u0301s Sarmento", "M\u00e1rio J Silva", "Eug\u00e9nio De Oliveira"], "venue": "In Proceedings of the 1st international CIKM workshop on Topic-sentiment analy-", "citeRegEx": "Carvalho et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Carvalho et al\\.", "year": 2009}, {"title": "LIBSVM: A library for support vector machines", "author": ["Chang", "Lin2011] Chih-Chung Chang", "Chih-Jen Lin"], "venue": "ACM Transactions on Intelligent Systems and Technology,", "citeRegEx": "Chang et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chang et al\\.", "year": 2011}, {"title": "Semi-supervised recognition of sarcastic sentences in twitter and amazon", "author": ["Oren Tsur", "Ari Rappoport"], "venue": "In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,", "citeRegEx": "Davidov et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Davidov et al\\.", "year": 2010}, {"title": "Testing theories of irony processing using eye-tracking and erps. Journal of Experimental Psychology: Learning, Memory, and Cognition, 40(3):811\u2013828", "author": ["Hartmut", "Wallington Katie", "Page Jemma Filik", "Ruth", "Leuthold"], "venue": null, "citeRegEx": "Hartmut et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Hartmut et al\\.", "year": 2014}, {"title": "A new readability yardstick", "author": ["Rudolph Flesch"], "venue": "Journal of applied psychology,", "citeRegEx": "Flesch.,? \\Q1948\\E", "shortCiteRegEx": "Flesch.", "year": 1948}, {"title": "Comprehension and memory for nonliteral utterances: The problem of sarcastic indirect requests", "author": ["Raymond W. Gibbs"], "venue": "Acta Psychologica,", "citeRegEx": "Gibbs.,? \\Q1986\\E", "shortCiteRegEx": "Gibbs.", "year": 1986}, {"title": "On irony and negation", "author": ["Rachel Giora"], "venue": "Discourse processes,", "citeRegEx": "Giora.,? \\Q1995\\E", "shortCiteRegEx": "Giora.", "year": 1995}, {"title": "Identifying sarcasm in twitter: a closer look", "author": ["Smaranda Muresan", "Nina Wacholder"], "venue": "In Proceedings of the 49th Annual Meeting of the Association", "citeRegEx": "Gonz\u00e1lezIb\u00e1nez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Gonz\u00e1lezIb\u00e1nez et al\\.", "year": 2011}, {"title": "The weka data mining software: an update", "author": ["Hall et al.2009] Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H Witten"], "venue": "ACM SIGKDD explorations newsletter,", "citeRegEx": "Hall et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Hall et al\\.", "year": 2009}, {"title": "Eye tracking: A comprehensive guide to methods and measures", "author": ["Marcus Nystr\u00f6m", "Richard Andersson", "Richard Dewhurst", "Halszka Jarodzka", "Joost Van de Weijer"], "venue": null, "citeRegEx": "Holmqvist et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Holmqvist et al\\.", "year": 2011}, {"title": "Context incongruity and irony processing", "author": ["Ivanko", "Pexman2003] Stacey L Ivanko", "Penny M Pexman"], "venue": "Discourse Processes,", "citeRegEx": "Ivanko et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Ivanko et al\\.", "year": 2003}, {"title": "Test of the mention theory of irony", "author": ["George A Miller", "Dan Sperber"], "venue": "Journal of Experimental Psychology: General,", "citeRegEx": "Jorgensen et al\\.,? \\Q1984\\E", "shortCiteRegEx": "Jorgensen et al\\.", "year": 1984}, {"title": "Harnessing context incongruity for sarcasm detection", "author": ["Joshi et al.2015] Aditya Joshi", "Vinita Sharma", "Pushpak Bhattacharyya"], "venue": "Proceedings of 53rd Annual Meeting of the Association for Computational Linguistics, Beijing,", "citeRegEx": "Joshi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2015}, {"title": "Automatic sarcasm detection: A survey", "author": ["Joshi et al.2016] Aditya Joshi", "Pushpak Bhattacharyya", "Mark James Carman"], "venue": null, "citeRegEx": "Joshi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Joshi et al\\.", "year": 2016}, {"title": "Reading senseless sentences: Brain potentials reflect semantic incongruity", "author": ["Kutas", "Hillyard1980] Marta Kutas", "Steven A Hillyard"], "venue": null, "citeRegEx": "Kutas et al\\.,? \\Q1980\\E", "shortCiteRegEx": "Kutas et al\\.", "year": 1980}, {"title": "The perfect solution for detecting sarcasm in tweets", "author": ["Florian Kunneman", "Antal van den Bosch"], "venue": "WASSA", "citeRegEx": "Liebrecht et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Liebrecht et al\\.", "year": 2013}, {"title": "Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis", "author": ["Maynard", "Greenwood2014] Diana Maynard", "Mark A Greenwood"], "venue": "In Proceedings of LREC", "citeRegEx": "Maynard et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Maynard et al\\.", "year": 2014}, {"title": "Predicting readers\u2019 sarcasm understandability by modeling gaze behavior", "author": ["Diptesh Kanojia", "Pushpak Bhattacharyya"], "venue": "In Proceedings of AAAI", "citeRegEx": "Mishra et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Mishra et al\\.", "year": 2016}, {"title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts", "author": ["Pang", "Lee2004] Bo Pang", "Lillian Lee"], "venue": "In Proceedings of the 42nd annual meeting on Association for Computational Linguistics,", "citeRegEx": "Pang et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Pang et al\\.", "year": 2004}, {"title": "Eye movements in reading: Psycholinguistic studies", "author": ["Rayner", "Sereno1994] Keith Rayner", "Sara C Sereno"], "venue": null, "citeRegEx": "Rayner et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Rayner et al\\.", "year": 1994}, {"title": "Sarcasm as contrast between a positive sentiment and negative situation", "author": ["Riloff et al.2013] Ellen Riloff", "Ashequl Qadir", "Prafulla Surve", "Lalindra De Silva", "Nathan Gilbert", "Ruihong Huang"], "venue": null, "citeRegEx": "Riloff et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Riloff et al\\.", "year": 2013}, {"title": "Logistic regression and boosting for labeled bags of instances", "author": ["Xu", "Frank2004] Xin Xu", "Eibe Frank"], "venue": "In Advances in knowledge discovery and data mining,", "citeRegEx": "Xu et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Xu et al\\.", "year": 2004}], "referenceMentions": [{"referenceID": 16, "context": "This is apparent from the results reported by the survey from Joshi et al. (2016). The following discussion brings more insights into this.", "startOffset": 62, "endOffset": 82}, {"referenceID": 15, "context": "In one of the pioneering works Jorgensen et al. (1984) explained how sarcasm arises when a figurative meaning is", "startOffset": 31, "endOffset": 55}, {"referenceID": 10, "context": "Giora (1995), on the other hand, define sarcasm as a mode of indirect negation that requires processing of both negated and implicated messages.", "startOffset": 0, "endOffset": 13}, {"referenceID": 10, "context": "Giora (1995), on the other hand, define sarcasm as a mode of indirect negation that requires processing of both negated and implicated messages. Ivanko and Pexman (2003) define sarcasm as a six tuple entity consisting of a speaker,", "startOffset": 0, "endOffset": 170}, {"referenceID": 4, "context": "Computational linguists have previously addressed this problem using rule based and statistical techniques, that make use of : (a) Unigrams and Pragmatic features (Carvalho et al., 2009; Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al.", "startOffset": 163, "endOffset": 259}, {"referenceID": 0, "context": "Computational linguists have previously addressed this problem using rule based and statistical techniques, that make use of : (a) Unigrams and Pragmatic features (Carvalho et al., 2009; Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al.", "startOffset": 163, "endOffset": 259}, {"referenceID": 16, "context": "Computational linguists have previously addressed this problem using rule based and statistical techniques, that make use of : (a) Unigrams and Pragmatic features (Carvalho et al., 2009; Gonz\u00e1lez-Ib\u00e1nez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al.", "startOffset": 163, "endOffset": 259}, {"referenceID": 6, "context": ", 2015) (b) Stylistic patterns (Davidov et al., 2010) and patterns related to situational disparity (Riloff et al.", "startOffset": 31, "endOffset": 53}, {"referenceID": 24, "context": ", 2010) and patterns related to situational disparity (Riloff et al., 2013) and (c) Hastag", "startOffset": 54, "endOffset": 75}, {"referenceID": 19, "context": "interpretations (Liebrecht et al., 2013; Maynard and Greenwood, 2014).", "startOffset": 16, "endOffset": 69}, {"referenceID": 2, "context": "Camblin et al. (2007) show that in multi-sentence passages, discourse congruence has robust effects on eye movements.", "startOffset": 0, "endOffset": 22}, {"referenceID": 21, "context": "In our previous work (Mishra et al., 2016), we augment cognitive features, derived from eye-movement patterns of readers, with textual features to detect whether a human reader has realized the presence of sarcasm in text or not.", "startOffset": 21, "endOffset": 42}, {"referenceID": 21, "context": "This hypothesis forms the crux of our method for sarcasm detection and we validate this using our previously released freely available sarcasm dataset2 (Mishra et al., 2016) enriched with gaze", "startOffset": 152, "endOffset": 173}, {"referenceID": 9, "context": ", if sarcasm is expected beforehand, processing incongruity becomes relatively easier (Gibbs, 1986)).", "startOffset": 86, "endOffset": 99}, {"referenceID": 13, "context": "The eye-tracking experiment is conducted by following the standard norms in eye-movement research (Holmqvist et al., 2011).", "startOffset": 98, "endOffset": 122}, {"referenceID": 8, "context": "dataset, when we considered readability (Flesch readability ease-score (Flesch, 1948)), number of words in a sentence and average character per word along with the sarcasm label as the predictors of average fixation duration following a linear mixed effect model (Barr et al.", "startOffset": 71, "endOffset": 85}, {"referenceID": 1, "context": "dataset, when we considered readability (Flesch readability ease-score (Flesch, 1948)), number of words in a sentence and average character per word along with the sarcasm label as the predictors of average fixation duration following a linear mixed effect model (Barr et al., 2013), sarcasm label turned out to be the most significant predictor with a maximum slope.", "startOffset": 263, "endOffset": 282}, {"referenceID": 16, "context": "The features enlisted under lexical,implicit incongruity and explicit incongruity are borrowed from various literature (predominantly from Joshi et al. (2015)).", "startOffset": 139, "endOffset": 159}, {"referenceID": 21, "context": "Some of these features have been reported by Mishra et al. (2016) for modeling sarcasm understandability of readers.", "startOffset": 45, "endOffset": 66}, {"referenceID": 8, "context": "Readability (RED) Real Flesch Readability Ease (Flesch, 1948) score of the sentence Textual Number of Words (LEN) Integer Number of words in the sentence Avg.", "startOffset": 47, "endOffset": 61}, {"referenceID": 12, "context": "Using Weka (Hall et al., 2009) and LibSVM (Chang and Lin, 2011) APIs, we implement the following classifiers:", "startOffset": 11, "endOffset": 30}, {"referenceID": 21, "context": "racy of our system and the best available systems proposed by Riloff et al. (2013) and Joshi et al.", "startOffset": 62, "endOffset": 83}, {"referenceID": 15, "context": "(2013) and Joshi et al. (2015) on our dataset.", "startOffset": 11, "endOffset": 31}, {"referenceID": 16, "context": "\u2022 Sarcasm (the feature-set reported by Joshi et al. (2015) subsuming unigram features and features from other reported systems)", "startOffset": 39, "endOffset": 59}, {"referenceID": 16, "context": "For all the classifiers, our feature combination outperforms the baselines (considering only unigram features) as well as (Joshi et al., 2015), with the MILR classifier getting an F-score improvement of 3.", "startOffset": 122, "endOffset": 142}, {"referenceID": 16, "context": "tection by Joshi et al. (2015) and the output of the MILR classifier with the complete set of features are compared, setting threshold \u03b1 = 0.", "startOffset": 11, "endOffset": 31}, {"referenceID": 16, "context": "We train our classifier with 100%, 90%, 80% and 70% of the training data with our whole feature set, and the feature combination from Joshi et al. (2015). The goodness of our system is demonstrated by improvements in F-score and Kappa statistics, shown in Figure 3.", "startOffset": 134, "endOffset": 154}], "year": 2017, "abstractText": "In this paper, we propose a novel mechanism for enriching the feature vector, for the task of sarcasm detection, with cognitive features extracted from eye-movement patterns of human readers. Sarcasm detection has been a challenging research problem, and its importance for NLP applications such as review summarization, dialog systems and sentiment analysis is well recognized. Sarcasm can often be traced to incongruity that becomes apparent as the full sentence unfolds. This presence of incongruityimplicit or explicitaffects the way readers eyes move through the text. We observe the difference in the behaviour of the eye, while reading sarcastic and non sarcastic sentences. Motivated by this observation, we augment traditional linguistic and stylistic features for sarcasm detection with the cognitive features obtained from readers eye movement data. We perform statistical classification using the enhanced feature set so obtained. The augmented cognitive features improve sarcasm detection by 3.7% (in terms of Fscore), over the performance of the best reported system.", "creator": "LaTeX with hyperref package"}}}