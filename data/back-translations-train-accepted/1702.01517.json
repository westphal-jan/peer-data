{"id": "1702.01517", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-Feb-2017", "title": "Opinion Recommendation using Neural Memory Model", "abstract": "We present opinion recommendation, a novel task of jointly predicting a custom review with a rating score that a certain user would give to a certain product or service, given existing reviews and rating scores to the product or service by other users, and the reviews that the user has given to other products and services. A characteristic of opinion recommendation is the reliance of multiple data sources for multi-task joint learning, which is the strength of neural models. We use a single neural network to model users and products, capturing their correlation and generating customised product representations using a deep memory network, from which customised ratings and reviews are constructed jointly. Results show that our opinion recommendation system gives ratings that are closer to real user ratings on Yelp.com data compared with Yelp's own ratings, and our methods give better results compared to several pipelines baselines using state-of-the-art sentiment rating and summarization systems.", "histories": [["v1", "Mon, 6 Feb 2017 07:29:01 GMT  (512kb,D)", "http://arxiv.org/abs/1702.01517v1", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["zhongqing wang", "yue zhang"], "accepted": true, "id": "1702.01517"}, "pdf": {"name": "1702.01517.pdf", "metadata": {"source": "CRF", "title": "Opinion Recommendation using Neural Memory Model", "authors": ["Zhongqing Wang", "Yue Zhang"], "emails": ["zhang}@sutd.edu.sg"], "sections": [{"heading": null, "text": "1Opinion Recommendation using Neural Memory Model"}, {"heading": "1 Introduction", "text": "We offer a channel for customers to share opinions and give results on products and services, but can be rather inaccurate for individuals. There is a very influential source of information that customers refer to to to make purchasing decisions. Popular examples include IMDB1 on the movie domain, Epinions2 on the product domain, and Yelp3 on the service domain. Figure 1 shows a screenshot of a restaurant review page on Yelp.com that offers two main types of user reviews: the rating of user reviews that have two main types of user reviews listed under the name of the restaurant; second, detailed user reviews are under the rating. Although they provide a useful overview and details of a product or service, such information has several limitations. First, the overall rating is general and not necessarily acceptable to the taste of individual customers."}, {"heading": "2 Related Work", "text": "In recent years, it has been shown that most people who are able to survive are able to survive themselves, and that they are able to survive themselves, \"he said.\" I don't think they are able to survive me, \"he said.\" I don't think they will be able to survive me. \"Most people who are able to survive themselves are able to survive themselves.\" I don't think they are able to survive me, \"he said.\" I don't think they are able to survive me. \"Most people who are able to survive themselves will survive themselves.\""}, {"heading": "3 Model", "text": "Formally, entering our model is a tuple < RT, RU, RN >, where RT = {rT1, rT2,..., rTnt} is the set of existing ratings of a target product, RU = {rU1, rU2,..., rUnu} is the set of ratings throughout the user's course, and RN = {rN1, rN2,..., rNnn} is the set of ratings in the user's neighborhood. All ratings are sorted in time. The result is a pair < YS, YR >, where YS is a real number between 0 and 5 representing the rating of the target product, and YR is a tailor-made rating. In order to capture both general and personalized information, we first create a product model, a user model, and a neighborhood model, and then use a storage network model to integrate these three types of information, creating an overall model based on a tailor-made product assessment and finally a customized assessment."}, {"heading": "3.1 Review Model", "text": "A customer rating is the basis of our model, from which we derive representations of both a user and a target product. In particular, a user profile can be achieved by modeling all the reviews of the user RE, and a target product profile can be achieved by using all existing reviews of the product RT. We use the average of word embeddings to model a rating. Formally, with a rating r = {x1, x2,..., xm}, where m is the length of the rating, each word xk is represented with a dimensional embedding ewk (Mikolov et al., 2013)."}, {"heading": "3.2 User Model", "text": "A standard LSTM (Hochreiter and Schmidhuber, 1997) without coupled input and forgetfulness gates or peephole connections is used to learn the hidden states of the values. hUnu) refers to the recurring function at step t as LSTM (xt, ht \u2212 1), and we get a sequence of hidden state vectors {hU1, hU2,..., hUnu} recurrently by feeding {ed (rU1), ed (rU2),..., edrUnu} as inputs, where hUi = LSTM (ed (rUi), hUi \u2212 1). The initial state and all LSTM parameters are randomly initialized and tuned during the training. Not all evaluations contribute equally to the representation of a user. We introduce an attention mechanism (Bahdanau et al., 2014; Yang et al., 2016) to extract the evaluations that are relative to the representation and aggregate the evaluations."}, {"heading": "3.3 Finding Neighbor Users", "text": "We use neighborhood ratings to improve the user model because a user may not have sufficient ratings to construct a reliable model. (Here, a neighbor refers to a user who has a similar taste to the target user (Koren, 2008; Desrosiers and Karypis, 2011). The same as the user model, we construct the neighborhood model vN using neighborhood ratings RN = {rN1, rN2,..., rNnn} with a recurring network.A key issue in building the neighborhood model is how to find a specific user's neighbors. In this study, we use matrix factorization (Koren, 2008) to identify neighbors, which is a standard approach to recommendations (Ding et al., 2006; Li et al., 2009; 5 Er et al., 2016). Specifically, user ratings of products are used to form a matrix matrix matrix matrix matrix matrix matrix capability."}, {"heading": "3.4 Product Model", "text": "In view of the representation of existing evaluations {e (rT1), e (rT2),..., erTnt} of the product, we use an LSTM to model their temporal orders, obtaining a sequence of hidden state vectors hT = {hT1, hT2,..., hTnt} by repeatedly entering {e (rT1), e (rT2),..., erTnt} as inputs. Hidden state vectors hT are used to represent the product."}, {"heading": "3.5 Customized Product Model", "text": "We use the user representation vU and the adjacent representation vN to transform the target product representation hT = {hT1, hT2,..., hTnt} into a customized product representation vC tailored to the user's taste. In particular, a dynamic storage network (Sukhbaatar et al., 2015; Xiong et al., 2016) is used to iteratively find increasingly abstract representations of ht by injecting vU and vN information. The storage model consists of several dynamic computing layers (hops), each of which contains an attention layer and a linear layer. In the first calculation layer (hops 1), we take the hidden variables hTi (0 \u2264 i \u2264 i \u2264 nt) of the product model as input, with the adaptive selection of important evidence by an attention layer using vU and vN."}, {"heading": "3.6 Customized Review Generation", "text": "The goal of the user-defined review generation is to generate a review YR from the user-defined product representation vC, consisting of a sequence of 6 words yR1,..., yRnr. We break down the YR prediction into a sequence of word-level predictions: logP (YR | vC) = \u2211 j P (yRj | yR1,..., yRj \u2212 1, vC) (10), each word yRj being predicted depending on the previously generated yR1,..., yRj \u2212 1 and the input vC. The probability is estimated by using the default word softmax: P (yRj | yR1,..., vC) = softmax (hRj) (11), where hRj is the hidden state variable at the time of the time stamp j, which is modeled as LSTM (uj \u2212 1, Rj)."}, {"heading": "3.7 Customized Opinion Rating Prediction", "text": "We consider two factors for a user-defined rating, namely the existing rating results and the custom product rating vC. A basic rating system such as Yelp.com uses only the prior information, typically taking into account the average of existing rating results. To incorporate user preferences into the rating, we instead take a weighted average of existing rating cores of 1.28 (out of 5), so that the results of ratings closer to user preferences are weighted higher. As a second factor, we calculate a rating independent of the custom representation of existing ratings, without taking into account the rating results. The motivation is twofold. Firstly, existing ratings may be relatively low and therefore, using their ratings alone may not be sufficient to achieve a safe score. Secondly, existing ratings may all deviate from a personal rating if the existing ratings do not come from the user's score, and if we work through the average rating i."}, {"heading": "3.8 Training", "text": "The loss function for the former is defined as: L (\u0443) = N \u2211 i = 1 (Y \u0445 Si \u2212 YSi) 2 + \u03bb 2 | | \u0432 | | 2 (14), where Y \u0445 Si is the predicted rating score, YSi is the rating score in the training data, \u044b is the set of model parameters and \u03bb is a parameter for the L2 regularization. We train the adjusted rating generation model by maximizing the protocol probability of Eq.10 (Sutskever et al., 2014; Rush et al., 2015). The standard back-propagation is performed to optimize parameters where gradients also spread from the scoring target to the evaluation generation target by maximizing the protocol probability of Eq.13 (Sutskever et al., 2014; Rush et al., 2015). We apply the model wheel optimization (2011, using Adchi)."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Experimental Settings", "text": "Our data is taken from the academic dataset yelp, provided by Yelp.com, a popular restaurant review site. The dataset contains three types of objects: business, user and review objects, in which business objects contain basic information about local businesses (e.g. restaurants), review objects contain review texts and star ratings, and user objects provide aggregated information about a single user across Yelp. Table 1 illustrates the overall statistics of the dataset. To evaluate our model, we select 4,755 user product pairs from the dataset. For each pair, the existing ratings of the target service (restaurant) are used for the product model. The rating value given by each user to the target service is considered a customized rating value in gold, and each user's review of the target service is used as a customized rating for the user. The remaining ratings of each user (restaurant) will be used for the test data provided by the user model of the UktGE to train the user model of the 1,000th user pair we will use as a customized rating for the GE model."}, {"heading": "4.2 Development Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1 Ablation Test", "text": "The effects of different configurations of our model are presented in Table 2, where Joint is the complete model of this paper, -user ablates the user model, -neighbor ablates the neighbor model, -rating is a single-task model that provides a rating without the rating 5https: / / www.yelp.com / academic datasetRating Generation Joint 0.904 0.267 -user 1,254 0.220 -neighbor 1,162 0.245 -user, -neighbor 1,342 0.205 -rating - 0.254 -generation 1.042 -table 2: Feature ablation tests.HOP Bais 0 1,342 0 1,102 1 1,102 1 0,904 2 1,046 2 1,067 3 0,904 3 0,904 3 1,136 4 0,987 4 1,206 5 1,102 5 1,227 6 1,045 7 1,126 8 1,172 9 1,152 10 1,1670,900.900.951,101,151,201,250 1 \""}, {"heading": "4.2.2 Influence of Hops", "text": "We show the influence of hops from the storage network on the evaluation of the forecast in Figure 3. Note that the model would only take into account the general product ratings (\u2212 user, \u2212 neighbor) if hops are = 0. It is clear from the figure that the performance is best for hops = 3. It indicates that several hops can gather more abstract evidence from the external memory to improve performance. However, too many hops lead to an overadaptation and thus impair performance. Consequently, we select 3 as the number of hops in our final test. 8HOP Bais 0 1,342 0 1,102 1 1,102 1 0,904 2 1,046 2 1,067 3 0,904 3 1,136 4 0,987 4 1,206 5 1,102 5 1,227 6 6 6 6 6 1,045 7 1,126 8 1,172 9 1,152 10 1,167 0.90 0.95 1.00 1.05 1.05 1.10 1.25 1.25 1 Result of 1.25 1.0 1.25 1.0 1.25."}, {"heading": "4.2.3 Influence of \u00b5", "text": "In Figure 4, we show the influence of the bias weight parameter \u00b5 on the rating forecast. Since \u00b5 is 0, the model uses the weighted sum of existing ratings to evaluate the product. If \u00b5 is very large, the system tends to use only the customized product representation vc to evaluate the product, and therefore ignores existing ratings results, which are a useful source of information. Our results show that when \u00b5 1 is, the performance is optimal, suggesting that both existing ratings results and rating content are equally useful."}, {"heading": "4.3 Final Results", "text": "We show the final results for the recommendation of the opinion by comparing our proposed model with the following state-of-the-art base systems: \u2022 RS-Linear estimates the weighting value that a user would give with sui = sall + su + si (Ricci et al., 2011), where su and si are the training deviations of the user u or product i, respectively. \u2022 RS-Item applies kNN to estimate the weighting value (Sarwar et al., 2001). We choose the cosmic similarity between vc to measure the distance between product and product. \u2022 RS-MF is a state-of-the-art recommendation model that uses matrix factoring to predict the weighting result (Ding et al., 2006; Li et al., 2009; RSmarp al., 2016, based on a frame of 1.0)."}, {"heading": "5 Conclusion", "text": "We presented a Dynamic Storage Model for Opinion Recommendations, a novel task for collectively predicting the assessment and evaluation value that a particular user would give to a particular product or service. Specifically, a deep memory network was used to find the link between the user and the product and to jointly obtain the evaluation value and a tailor-made evaluation. Results show that our methods provide better results compared to multiple pipeline baselines that use state-of-the-art sentiment rating and summarizing systems.9"}], "references": [{"title": "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions", "author": ["Gediminas Adomavicius", "Alexander Tuzhilin."], "venue": "IEEE transactions on knowledge and data engineering 17(6):734\u2013749.", "citeRegEx": "Adomavicius and Tuzhilin.,? 2005", "shortCiteRegEx": "Adomavicius and Tuzhilin.", "year": 2005}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."], "venue": "CoRR abs/1409.0473. http://arxiv.org/abs/1409.0473.", "citeRegEx": "Bahdanau et al\\.,? 2014", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Neural network for heterogeneous annotations", "author": ["Hongshen Chen", "Yue Zhang", "Qun Liu."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas,", "citeRegEx": "Chen et al\\.,? 2016a", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Neural sentiment classification with user and product attention", "author": ["Huimin Chen", "Maosong Sun", "Cunchao Tu", "Yankai Lin", "Zhiyuan Liu."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Chen et al\\.,? 2016b", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel P. Kuksa."], "venue": "Journal of Machine Learning Research 12:2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "A comprehensive survey of neighborhood-based recommendation methods", "author": ["Christian Desrosiers", "George Karypis."], "venue": "Recommender Systems Handbook, pages 107\u2013144.", "citeRegEx": "Desrosiers and Karypis.,? 2011", "shortCiteRegEx": "Desrosiers and Karypis.", "year": 2011}, {"title": "Orthogonal nonnegative matrix t-factorizations for clustering", "author": ["Chris Ding", "Tao Li", "Wei Peng", "Haesun Park."], "venue": "Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, pages 126\u2013135.", "citeRegEx": "Ding et al\\.,? 2006", "shortCiteRegEx": "Ding et al\\.", "year": 2006}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["John C. Duchi", "Elad Hazan", "Yoram Singer."], "venue": "Journal of Machine Learning Research 12:2121\u20132159. http://dl.acm.org/citation.cfm?id=2021068.", "citeRegEx": "Duchi et al\\.,? 2011", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions", "author": ["Kavita Ganesan", "ChengXiang Zhai", "Jiawei Han."], "venue": "Proceedings of the 23rd international conference on computational linguistics. Association for Compu-", "citeRegEx": "Ganesan et al\\.,? 2010", "shortCiteRegEx": "Ganesan et al\\.", "year": 2010}, {"title": "Modeling user leniency and product popularity for sentiment classification", "author": ["Wenliang Gao", "Naoki Yoshinaga", "Nobuhiro Kaji", "Masaru Kitsuregawa."], "venue": "IJCNLP. pages 1107\u20131111.", "citeRegEx": "Gao et al\\.,? 2013", "shortCiteRegEx": "Gao et al\\.", "year": 2013}, {"title": "Neural turing machines", "author": ["Alex Graves", "Greg Wayne", "Ivo Danihelka."], "venue": "CoRR abs/1410.5401. http://arxiv.org/abs/1410.5401.", "citeRegEx": "Graves et al\\.,? 2014", "shortCiteRegEx": "Graves et al\\.", "year": 2014}, {"title": "Fast matrix factorization for online recommendation with implicit feedback", "author": ["Xiangnan He", "Hanwang Zhang", "Min-Yen Kan", "Tat-Seng Chua."], "venue": "Proceedings of the 39th International ACM SIGIR conference on Research and De-", "citeRegEx": "He et al\\.,? 2016", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Multilingual joint parsing of syntactic and semantic dependencies with a latent variable model", "author": ["James Henderson", "Paola Merlo", "Ivan Titov", "Gabriele Musillo."], "venue": "Computational Linguistics 39(4):949\u2013998.", "citeRegEx": "Henderson et al\\.,? 2013", "shortCiteRegEx": "Henderson et al\\.", "year": 2013}, {"title": "Improving neural networks by preventing co-adaptation of feature detectors", "author": ["Geoffrey E. Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."], "venue": "CoRR abs/1207.0580. http://arxiv.org/abs/1207.0580.", "citeRegEx": "Hinton et al\\.,? 2012", "shortCiteRegEx": "Hinton et al\\.", "year": 2012}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Computation 9(8):1735\u20131780. https://doi.org/10.1162/neco.1997.9.8.1735.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Mining and summarizing customer reviews", "author": ["Minqing Hu", "Bing Liu."], "venue": "Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Seattle, Washington, USA, August 22-25, 2004. pages 168\u2013177.", "citeRegEx": "Hu and Liu.,? 2004", "shortCiteRegEx": "Hu and Liu.", "year": 2004}, {"title": "Opinion mining with deep recurrent neural networks", "author": ["Ozan Irsoy", "Claire Cardie."], "venue": "EMNLP. pages 720\u2013728.", "citeRegEx": "Irsoy and Cardie.,? 2014", "shortCiteRegEx": "Irsoy and Cardie.", "year": 2014}, {"title": "Extracting opinion targets in a single and cross-domain setting with conditional random fields", "author": ["Niklas Jakob", "Iryna Gurevych."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP", "citeRegEx": "Jakob and Gurevych.,? 2010", "shortCiteRegEx": "Jakob and Gurevych.", "year": 2010}, {"title": "Recommender systems handbook", "author": ["Paul B Kantor", "Lior Rokach", "Francesco Ricci", "Bracha Shapira"], "venue": null, "citeRegEx": "Kantor et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kantor et al\\.", "year": 2011}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Spe-", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model", "author": ["Yehuda Koren."], "venue": "Proceedings of the 14th ACM SIGKDD", "citeRegEx": "Koren.,? 2008", "shortCiteRegEx": "Koren.", "year": 2008}, {"title": "Ask me anything: Dynamic memory networks for natural language processing", "author": ["Ankit Kumar", "Ozan Irsoy", "Peter Ondruska", "Mohit Iyyer", "James Bradbury", "Ishaan Gulrajani", "Victor Zhong", "Romain Paulus", "Richard Socher."], "venue": "In", "citeRegEx": "Kumar et al\\.,? 2016", "shortCiteRegEx": "Kumar et al\\.", "year": 2016}, {"title": "Integrating collaborative filtering and sentiment analysis: A rating inference approach", "author": ["Cane WK Leung", "Stephen CF Chan", "Fu-lai Chung."], "venue": "Proceedings of the ECAI 2006 workshop on recommender systems. pages 62\u201366.", "citeRegEx": "Leung et al\\.,? 2006", "shortCiteRegEx": "Leung et al\\.", "year": 2006}, {"title": "Incorporating reviewer and product information for review rating prediction", "author": ["Fangtao Li", "Nathan Nan Liu", "Hongwei Jin", "Kai Zhao", "Qiang Yang", "Xiaoyan Zhu."], "venue": "IJCAI 2011, Proceedings of the 22nd International Joint Confer-", "citeRegEx": "Li et al\\.,? 2011", "shortCiteRegEx": "Li et al\\.", "year": 2011}, {"title": "Suit: A supervised user-item based topic model for sentiment analysis", "author": ["Fangtao Li", "Sheng Wang", "Shenghua Liu", "Ming Zhang."], "venue": "AAAI. pages 1636\u20131642.", "citeRegEx": "Li et al\\.,? 2014", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "A nonnegative matrix tri-factorization approach to sentiment classification with lexical prior knowledge", "author": ["Tao Li", "Yi Zhang", "Vikas Sindhwani."], "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International", "citeRegEx": "Li et al\\.,? 2009", "shortCiteRegEx": "Li et al\\.", "year": 2009}, {"title": "Joint sentiment/topic model for sentiment analysis", "author": ["Chenghua Lin", "Yulan He."], "venue": "Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM 2009, Hong Kong,", "citeRegEx": "Lin and He.,? 2009", "shortCiteRegEx": "Lin and He.", "year": 2009}, {"title": "Rouge: A package for automatic evaluation of summaries", "author": ["Chin-Yew Lin."], "venue": "Text summarization branches out: Proceedings of the ACL-04 workshop. Barcelona, Spain, volume 8.", "citeRegEx": "Lin.,? 2004", "shortCiteRegEx": "Lin.", "year": 2004}, {"title": "Fine-grained opinion mining with recurrent neural networks and word embeddings", "author": ["Pengfei Liu", "Shafiq R. Joty", "Helen M. Meng."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon,", "citeRegEx": "Liu et al\\.,? 2015", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean."], "venue": "Advances in Neural Information Processing Systems 26: 27th Annual Conference", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Optimizing informativeness and readability for sentiment summarization", "author": ["Hitoshi Nishikawa", "Takaaki Hasegawa", "Yoshihiro Matsuo", "Gen-ichiro Kikui."], "venue": "ACL 2010, Proceedings of the 48th Annual Meeting of the Association", "citeRegEx": "Nishikawa et al\\.,? 2010", "shortCiteRegEx": "Nishikawa et al\\.", "year": 2010}, {"title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales", "author": ["Bo Pang", "Lillian Lee."], "venue": "ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 25-30", "citeRegEx": "Pang and Lee.,? 2005", "shortCiteRegEx": "Pang and Lee.", "year": 2005}, {"title": "Opinion mining and sentiment analysis", "author": ["Bo Pang", "Lillian Lee."], "venue": "Foundations and trends in information retrieval 2(1-2):1\u2013135.", "citeRegEx": "Pang and Lee.,? 2008", "shortCiteRegEx": "Pang and Lee.", "year": 2008}, {"title": "Opinion word expansion and target extraction through double propagation", "author": ["Guang Qiu", "Bing Liu", "Jiajun Bu", "Chun Chen."], "venue": "Computational Linguistics 37(1):9\u201327.", "citeRegEx": "Qiu et al\\.,? 2011", "shortCiteRegEx": "Qiu et al\\.", "year": 2011}, {"title": "The bag-of-opinions method for review rating prediction from sparse text patterns", "author": ["Lizhen Qu", "Georgiana Ifrim", "Gerhard Weikum."], "venue": "COLING 2010, 23rd International Conference on Computational Linguistics, Proceedings of the Conference,", "citeRegEx": "Qu et al\\.,? 2010", "shortCiteRegEx": "Qu et al\\.", "year": 2010}, {"title": "A neural attention model for abstractive sentence summarization", "author": ["Alexander M. Rush", "Sumit Chopra", "Jason Weston."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon,", "citeRegEx": "Rush et al\\.,? 2015", "shortCiteRegEx": "Rush et al\\.", "year": 2015}, {"title": "Item-based collaborative filtering recommendation algorithms", "author": ["Badrul M. Sarwar", "George Karypis", "Joseph A. Konstan", "John Riedl."], "venue": "Proceedings of the Tenth International", "citeRegEx": "Sarwar et al\\.,? 2001", "shortCiteRegEx": "Sarwar et al\\.", "year": 2001}, {"title": "Context-sensitive lexicon features for neural sentiment analysis", "author": ["Zhiyang Teng", "Duy-Tin Vo", "Yue Zhang."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas,", "citeRegEx": "Teng et al\\.,? 2016", "shortCiteRegEx": "Teng et al\\.", "year": 2016}, {"title": "Recurrent memory networks for language modeling", "author": ["Ke M. Tran", "Arianna Bisazza", "Christof Monz."], "venue": "NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-", "citeRegEx": "Tran et al\\.,? 2016", "shortCiteRegEx": "Tran et al\\.", "year": 2016}, {"title": "Co-regression for cross-language review rating prediction", "author": ["Xiaojun Wan."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013, 4-9 August 2013, Sofia, Bulgaria, Volume 2: Short Papers. pages", "citeRegEx": "Wan.,? 2013", "shortCiteRegEx": "Wan.", "year": 2013}, {"title": "A pilot study of opinion summarization in conversations", "author": ["Dong Wang", "Yang Liu."], "venue": "The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference, 19-24", "citeRegEx": "Wang and Liu.,? 2011", "shortCiteRegEx": "Wang and Liu.", "year": 2011}, {"title": "Neural networkbased abstract generation for opinions and arguments", "author": ["Lu Wang", "Wang Ling."], "venue": "NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-", "citeRegEx": "Wang and Ling.,? 2016", "shortCiteRegEx": "Wang and Ling.", "year": 2016}, {"title": "Memory-enhanced decoder for neural machine translation", "author": ["Mingxuan Wang", "Zhengdong Lu", "Hang Li", "Qun Liu."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin,", "citeRegEx": "Wang et al\\.,? 2016", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "FLAME: A probabilistic model combining aspect based opinion mining and collaborative filtering", "author": ["Yao Wu", "Martin Ester."], "venue": "Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, WSDM 2015, Shang-", "citeRegEx": "Wu and Ester.,? 2015", "shortCiteRegEx": "Wu and Ester.", "year": 2015}, {"title": "Dynamic memory networks for visual and textual question answering", "author": ["Caiming Xiong", "Stephen Merity", "Richard Socher."], "venue": "Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York", "citeRegEx": "Xiong et al\\.,? 2016", "shortCiteRegEx": "Xiong et al\\.", "year": 2016}, {"title": "Joint inference for fine-grained opinion extraction", "author": ["Bishan Yang", "Claire Cardie."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013, 4-9 August 2013, Sofia, Bulgaria,", "citeRegEx": "Yang and Cardie.,? 2013", "shortCiteRegEx": "Yang and Cardie.", "year": 2013}, {"title": "A survey of collaborative filtering based social recommender systems", "author": ["Xiwang Yang", "Yang Guo", "Yong Liu", "Harald Steck."], "venue": "Computer Communications 41:1\u201310.", "citeRegEx": "Yang et al\\.,? 2014", "shortCiteRegEx": "Yang et al\\.", "year": 2014}, {"title": "Hierarchical attention networks for document classification", "author": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy."], "venue": "NAACL 2016, 15th Annual Conference of the North American Chapter of the Association for Computa-", "citeRegEx": "Yang et al\\.,? 2016", "shortCiteRegEx": "Yang et al\\.", "year": 2016}, {"title": "Explicit factor models for explainable recommendation based on phrase-level sentiment analysis", "author": ["Yongfeng Zhang", "Guokun Lai", "Min Zhang", "Yi Zhang", "Yiqun Liu", "Shaoping Ma."], "venue": "The 37th International ACM SIGIR Confer-", "citeRegEx": "Zhang et al\\.,? 2014", "shortCiteRegEx": "Zhang et al\\.", "year": 2014}, {"title": "Stackpropagation: Improved representation learning for syntax", "author": ["Yuan Zhang", "David Weiss."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12,", "citeRegEx": "Zhang and Weiss.,? 2016", "shortCiteRegEx": "Zhang and Weiss.", "year": 2016}], "referenceMentions": [{"referenceID": 15, "context": "The first is sentiment analysis (Hu and Liu, 2004; Pang and Lee, 2008), which is to give a rating score based on a customer review.", "startOffset": 32, "endOffset": 70}, {"referenceID": 32, "context": "The first is sentiment analysis (Hu and Liu, 2004; Pang and Lee, 2008), which is to give a rating score based on a customer review.", "startOffset": 32, "endOffset": 70}, {"referenceID": 30, "context": "The second is opinion summarization (Nishikawa et al., 2010; Wang and Ling, 2016), which is to generate a summary based on reviews of a product.", "startOffset": 36, "endOffset": 81}, {"referenceID": 41, "context": "The second is opinion summarization (Nishikawa et al., 2010; Wang and Ling, 2016), which is to generate a summary based on reviews of a product.", "startOffset": 36, "endOffset": 81}, {"referenceID": 46, "context": "The third is recommendation (Su and Khoshgoftaar, 2009; Yang et al., 2014), which is to give a ranking score for a certain product or service based on the purchase history of the user and other customers who have purchased the target product.", "startOffset": 28, "endOffset": 74}, {"referenceID": 4, "context": "Deep learning is a relatively more feasible choice, offering viabilities of information fusion by fully connected hidden layers (Collobert et al., 2011; Henderson et al., 2013).", "startOffset": 128, "endOffset": 176}, {"referenceID": 12, "context": "Deep learning is a relatively more feasible choice, offering viabilities of information fusion by fully connected hidden layers (Collobert et al., 2011; Henderson et al., 2013).", "startOffset": 128, "endOffset": 176}, {"referenceID": 6, "context": "Third, to address potential sparsity of a user\u2019s history reviews, neighbor users are identified by collaborative filtering (Ding et al., 2006), and a vector representation is learned by using a neural neighborhood model, which consolidates their history reviews.", "startOffset": 123, "endOffset": 142}, {"referenceID": 32, "context": "Our task is related to document-level sentiment classification (Pang and Lee, 2008), which is to infer the sentiment polarity of a given document.", "startOffset": 63, "endOffset": 83}, {"referenceID": 19, "context": "Recently, various neural network models are used to capture the sentimental information automatically, including convolutional neural networks (Kim, 2014), recursive neural network (Socher et al.", "startOffset": 143, "endOffset": 154}, {"referenceID": 37, "context": ", 2013) and recurrent neural network (Teng et al., 2016; Tai et al., 2015), which have been shown to achieve competitive results across different benchmarks.", "startOffset": 37, "endOffset": 74}, {"referenceID": 34, "context": "Most subsequent work focuses on designing effective textural features of reviews (Qu et al., 2010; Li et al., 2011; Wan, 2013).", "startOffset": 81, "endOffset": 126}, {"referenceID": 23, "context": "Most subsequent work focuses on designing effective textural features of reviews (Qu et al., 2010; Li et al., 2011; Wan, 2013).", "startOffset": 81, "endOffset": 126}, {"referenceID": 39, "context": "Most subsequent work focuses on designing effective textural features of reviews (Qu et al., 2010; Li et al., 2011; Wan, 2013).", "startOffset": 81, "endOffset": 126}, {"referenceID": 19, "context": "Recently, various neural network models are used to capture the sentimental information automatically, including convolutional neural networks (Kim, 2014), recursive neural network (Socher et al., 2013) and recurrent neural network (Teng et al., 2016; Tai et al., 2015), which have been shown to achieve competitive results across different benchmarks. Different from binary classification, review rating prediction aims to predict the numeric rating of a given review. Pang and Lee (2005) pioneered this task by regarding it as a classification/regression problem.", "startOffset": 144, "endOffset": 490}, {"referenceID": 19, "context": "Recently, various neural network models are used to capture the sentimental information automatically, including convolutional neural networks (Kim, 2014), recursive neural network (Socher et al., 2013) and recurrent neural network (Teng et al., 2016; Tai et al., 2015), which have been shown to achieve competitive results across different benchmarks. Different from binary classification, review rating prediction aims to predict the numeric rating of a given review. Pang and Lee (2005) pioneered this task by regarding it as a classification/regression problem. Most subsequent work focuses on designing effective textural features of reviews (Qu et al., 2010; Li et al., 2011; Wan, 2013). Recently, Tang et al. (2015) proposed a neural network model to predict the rating score by using both lexical semantic and user model.", "startOffset": 144, "endOffset": 723}, {"referenceID": 7, "context": "For example, Gao et al. (2013) developed user-specific features to capture user leniency, and Li et al.", "startOffset": 13, "endOffset": 31}, {"referenceID": 7, "context": "For example, Gao et al. (2013) developed user-specific features to capture user leniency, and Li et al. (2014) incorporated textual topic and userword factors through topic modeling.", "startOffset": 13, "endOffset": 111}, {"referenceID": 7, "context": "For example, Gao et al. (2013) developed user-specific features to capture user leniency, and Li et al. (2014) incorporated textual topic and userword factors through topic modeling. For integrating user information into neural network models, Tang et al. (2015) predicted the rating score given a review by using both lexical semantic information and a user embedding model.", "startOffset": 13, "endOffset": 263}, {"referenceID": 2, "context": "Chen et al. (2016b) proposed a neural network to incorporate global user and product information for sentiment classification via an attention mechanism.", "startOffset": 0, "endOffset": 20}, {"referenceID": 15, "context": "Our work also overlaps with to the area of opinion summarization, which constructs natural language summaries for multiple product reviews (Hu and Liu, 2004).", "startOffset": 139, "endOffset": 157}, {"referenceID": 15, "context": "Typical approaches include association mining of frequent candidate aspects (Hu and Liu, 2004; Qiu et al., 2011), sequence labeling based methods (Jakob and Gurevych, 2010; Yang and Cardie, 2013), as well as topic modeling techniques (Lin and He, 2009).", "startOffset": 76, "endOffset": 112}, {"referenceID": 33, "context": "Typical approaches include association mining of frequent candidate aspects (Hu and Liu, 2004; Qiu et al., 2011), sequence labeling based methods (Jakob and Gurevych, 2010; Yang and Cardie, 2013), as well as topic modeling techniques (Lin and He, 2009).", "startOffset": 76, "endOffset": 112}, {"referenceID": 17, "context": ", 2011), sequence labeling based methods (Jakob and Gurevych, 2010; Yang and Cardie, 2013), as well as topic modeling techniques (Lin and He, 2009).", "startOffset": 41, "endOffset": 90}, {"referenceID": 45, "context": ", 2011), sequence labeling based methods (Jakob and Gurevych, 2010; Yang and Cardie, 2013), as well as topic modeling techniques (Lin and He, 2009).", "startOffset": 41, "endOffset": 90}, {"referenceID": 26, "context": ", 2011), sequence labeling based methods (Jakob and Gurevych, 2010; Yang and Cardie, 2013), as well as topic modeling techniques (Lin and He, 2009).", "startOffset": 129, "endOffset": 147}, {"referenceID": 16, "context": "Recently, word embeddings and recurrent neural networks are also used to extract aspect terms (Irsoy and Cardie, 2014; Liu et al., 2015).", "startOffset": 94, "endOffset": 136}, {"referenceID": 28, "context": "Recently, word embeddings and recurrent neural networks are also used to extract aspect terms (Irsoy and Cardie, 2014; Liu et al., 2015).", "startOffset": 94, "endOffset": 136}, {"referenceID": 28, "context": "To address this, Nishikawa et al. (2010) generated summaries by selecting and ordering sentences taken from multiple review texts according to affirmativeness and readability of the sentence order.", "startOffset": 17, "endOffset": 41}, {"referenceID": 28, "context": "To address this, Nishikawa et al. (2010) generated summaries by selecting and ordering sentences taken from multiple review texts according to affirmativeness and readability of the sentence order. Wang and Liu (2011) adopted both sentence-ranking and graphbased methods to extract summaries on an opinion conversation dataset.", "startOffset": 17, "endOffset": 218}, {"referenceID": 8, "context": "While all the methods above are extractive, Ganesan et al. (2010) presented a graph-based summarization framework to generate concise abstractive summaries of highly redundant opinions, and Wang and Ling (2016) used an attention-based neural network model to absorb information from multiple text units and generate summaries of movie reviews.", "startOffset": 44, "endOffset": 66}, {"referenceID": 8, "context": "While all the methods above are extractive, Ganesan et al. (2010) presented a graph-based summarization framework to generate concise abstractive summaries of highly redundant opinions, and Wang and Ling (2016) used an attention-based neural network model to absorb information from multiple text units and generate summaries of movie reviews.", "startOffset": 44, "endOffset": 211}, {"referenceID": 0, "context": "There are two main approaches, which are content-based and collaborative-filtering (CF) based (Adomavicius and Tuzhilin, 2005; Yang et al., 2014), respectively.", "startOffset": 94, "endOffset": 145}, {"referenceID": 46, "context": "There are two main approaches, which are content-based and collaborative-filtering (CF) based (Adomavicius and Tuzhilin, 2005; Yang et al., 2014), respectively.", "startOffset": 94, "endOffset": 145}, {"referenceID": 18, "context": "Most existing social recommendation systems are CF-based, and can be further grouped into model-based CF and neighborhood-based CF (Kantor et al., 2011; Su and Khoshgoftaar, 2009).", "startOffset": 131, "endOffset": 179}, {"referenceID": 6, "context": ", ratings, clicks, purchases) to improve the accuracy of traditional recommendation systems, which only factorize user-item feedback data (Ding et al., 2006; Koren, 2008; He et al., 2016).", "startOffset": 138, "endOffset": 187}, {"referenceID": 20, "context": ", ratings, clicks, purchases) to improve the accuracy of traditional recommendation systems, which only factorize user-item feedback data (Ding et al., 2006; Koren, 2008; He et al., 2016).", "startOffset": 138, "endOffset": 187}, {"referenceID": 11, "context": ", ratings, clicks, purchases) to improve the accuracy of traditional recommendation systems, which only factorize user-item feedback data (Ding et al., 2006; Koren, 2008; He et al., 2016).", "startOffset": 138, "endOffset": 187}, {"referenceID": 22, "context": "There has been work integrating sentiment analysis and recommendation systems, which use recommendation strategies such as matrix factorization to improve the performance of sentiment analysis (Leung et al., 2006; Singh et al., 2011).", "startOffset": 193, "endOffset": 233}, {"referenceID": 43, "context": ", 2011) or probabilistic graph models (Wu and Ester, 2015).", "startOffset": 38, "endOffset": 58}, {"referenceID": 22, "context": "There has been work integrating sentiment analysis and recommendation systems, which use recommendation strategies such as matrix factorization to improve the performance of sentiment analysis (Leung et al., 2006; Singh et al., 2011). These methods typically use ensemble learning (Singh et al., 2011) or probabilistic graph models (Wu and Ester, 2015). For example, Zhang et al. (2014) who proposed a factor graph model to recommend opinion rating scores by using explicit product features as hidden variables.", "startOffset": 194, "endOffset": 387}, {"referenceID": 4, "context": "Multi-task learning has been recognised as a strength of neural network models for natural language processing (Collobert et al., 2011; Henderson et al., 2013; Zhang and Weiss, 2016; Chen et al., 2016a), where hidden feature layers are shared between different tasks that have common basis.", "startOffset": 111, "endOffset": 202}, {"referenceID": 12, "context": "Multi-task learning has been recognised as a strength of neural network models for natural language processing (Collobert et al., 2011; Henderson et al., 2013; Zhang and Weiss, 2016; Chen et al., 2016a), where hidden feature layers are shared between different tasks that have common basis.", "startOffset": 111, "endOffset": 202}, {"referenceID": 49, "context": "Multi-task learning has been recognised as a strength of neural network models for natural language processing (Collobert et al., 2011; Henderson et al., 2013; Zhang and Weiss, 2016; Chen et al., 2016a), where hidden feature layers are shared between different tasks that have common basis.", "startOffset": 111, "endOffset": 202}, {"referenceID": 2, "context": "Multi-task learning has been recognised as a strength of neural network models for natural language processing (Collobert et al., 2011; Henderson et al., 2013; Zhang and Weiss, 2016; Chen et al., 2016a), where hidden feature layers are shared between different tasks that have common basis.", "startOffset": 111, "endOffset": 202}, {"referenceID": 10, "context": "Dynamic memory network models are inspired by neural turing machines (Graves et al., 2014), and have been applied for NLP tasks such as question answering (Sukhbaatar et al.", "startOffset": 69, "endOffset": 90}, {"referenceID": 21, "context": ", 2014), and have been applied for NLP tasks such as question answering (Sukhbaatar et al., 2015; Kumar et al., 2016), language modeling (Tran et al.", "startOffset": 72, "endOffset": 117}, {"referenceID": 38, "context": ", 2016), language modeling (Tran et al., 2016) and machine translation (Wang et al.", "startOffset": 27, "endOffset": 46}, {"referenceID": 42, "context": ", 2016) and machine translation (Wang et al., 2016).", "startOffset": 32, "endOffset": 51}, {"referenceID": 29, "context": ", xm}, where m is the length of the review, each word xk is represented with a Kdimensional embedding ek (Mikolov et al., 2013).", "startOffset": 105, "endOffset": 127}, {"referenceID": 14, "context": "A standard LSTM (Hochreiter and Schmidhuber, 1997) without coupled input and forget gates or peephole connections is used to learn the hidden states of the reviews.", "startOffset": 16, "endOffset": 50}, {"referenceID": 1, "context": "We introduce an attention mechanism (Bahdanau et al., 2014; Yang et al., 2016) to extract the reviews that are relatively more important, and aggregate the representation of reviews to form a vector.", "startOffset": 36, "endOffset": 78}, {"referenceID": 47, "context": "We introduce an attention mechanism (Bahdanau et al., 2014; Yang et al., 2016) to extract the reviews that are relatively more important, and aggregate the representation of reviews to form a vector.", "startOffset": 36, "endOffset": 78}, {"referenceID": 20, "context": "Here a neighbor refers to a user that has similar tastes to the target user (Koren, 2008; Desrosiers and Karypis, 2011).", "startOffset": 76, "endOffset": 119}, {"referenceID": 5, "context": "Here a neighbor refers to a user that has similar tastes to the target user (Koren, 2008; Desrosiers and Karypis, 2011).", "startOffset": 76, "endOffset": 119}, {"referenceID": 20, "context": "In this study, we use matrix factorization (Koren, 2008) to detect neighbors, which is a standard approach for recommendation (Ding et al.", "startOffset": 43, "endOffset": 56}, {"referenceID": 6, "context": "We approximate it using three factors, which specify soft membership of products and users (Ding et al., 2006) by finding:", "startOffset": 91, "endOffset": 110}, {"referenceID": 44, "context": "In particular, a dynamic memory network (Sukhbaatar et al., 2015; Xiong et al., 2016) is utilized to iteratively find increasingly abstract representations of ht, by injecting vU and vN information.", "startOffset": 40, "endOffset": 85}, {"referenceID": 35, "context": "10 (Sutskever et al., 2014; Rush et al., 2015).", "startOffset": 3, "endOffset": 46}, {"referenceID": 7, "context": "We apply online training, where model parameters are optimized by using Adagrad (Duchi et al., 2011).", "startOffset": 80, "endOffset": 100}, {"referenceID": 29, "context": "We train word embeddings using the Skip-gram algorithm (Mikolov et al., 2013)4, using a window size of 5 and vector size of 128.", "startOffset": 55, "endOffset": 77}, {"referenceID": 13, "context": "In order to avoid over-fitting, dropout (Hinton et al., 2012) is used for word embedding with a ratio of 0.", "startOffset": 40, "endOffset": 61}, {"referenceID": 27, "context": "5 (Lin, 2004) toolkit for evaluating the performance of customized review generation, and report unigram overlap (ROUGE-1) as a means of assessing informativeness.", "startOffset": 2, "endOffset": 13}, {"referenceID": 39, "context": "We use Mean Square Error (MSE) (Wan, 2013; Tang et al., 2015) is used as the evaluation metric for measuring the performance of customized rating score prediction.", "startOffset": 31, "endOffset": 61}, {"referenceID": 36, "context": "\u2022 RS-Item applies kNN to estimate the rating score (Sarwar et al., 2001).", "startOffset": 51, "endOffset": 72}, {"referenceID": 6, "context": "\u2022 RS-MF is a state-of-the-art recommendation model, which uses matrix factorisation to predict rating score (Ding et al., 2006; Li et al., 2009; He et al., 2016).", "startOffset": 108, "endOffset": 161}, {"referenceID": 25, "context": "\u2022 RS-MF is a state-of-the-art recommendation model, which uses matrix factorisation to predict rating score (Ding et al., 2006; Li et al., 2009; He et al., 2016).", "startOffset": 108, "endOffset": 161}, {"referenceID": 11, "context": "\u2022 RS-MF is a state-of-the-art recommendation model, which uses matrix factorisation to predict rating score (Ding et al., 2006; Li et al., 2009; He et al., 2016).", "startOffset": 108, "endOffset": 161}, {"referenceID": 8, "context": "\u2022 Sum-Opinosis uses a graph-based framework to generate abstractive summarisation given redundant opinions (Ganesan et al., 2010).", "startOffset": 107, "endOffset": 129}, {"referenceID": 35, "context": "\u2022 Sum-LSTM-Att is a state-of-the-art neural abstractive summariser, which uses an attentional neural model to consolidate information from multiple text sources, generating summaries using LSTM decoding (Rush et al., 2015; Wang and Ling, 2016).", "startOffset": 203, "endOffset": 243}, {"referenceID": 41, "context": "\u2022 Sum-LSTM-Att is a state-of-the-art neural abstractive summariser, which uses an attentional neural model to consolidate information from multiple text sources, generating summaries using LSTM decoding (Rush et al., 2015; Wang and Ling, 2016).", "startOffset": 203, "endOffset": 243}], "year": 2017, "abstractText": "We present opinion recommendation, a novel task of jointly predicting a custom review with a rating score that a certain user would give to a certain product or service, given existing reviews and rating scores to the product or service by other users, and the reviews that the user has given to other products and services. A characteristic of opinion recommendation is the reliance of multiple data sources for multi-task joint learning, which is the strength of neural models. We use a single neural network to model users and products, capturing their correlation and generating customised product representations using a deep memory network, from which customised ratings and reviews are constructed jointly. Results show that our opinion recommendation system gives ratings that are closer to real user ratings on Yelp.com data compared with Yelp\u2019s own ratings, and our methods give better results compared to several pipelines baselines using state-of-the-art sentiment rating and summarization systems.", "creator": "LaTeX with hyperref package"}}}