{"id": "1702.02098", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Feb-2017", "title": "Fast and Accurate Entity Recognition with Iterated Dilated Convolutions", "abstract": "Bi-directional LSTMs have emerged as a standard method for obtaining per-token vector representations serving as input to various token labeling tasks (whether followed by Viterbi prediction or independent classification). This paper proposes an alternative to Bi-LSTMs for this purpose: iterated dilated convolutional neural networks (ID-CNNs), which have better capacity than traditional CNNs for large context and structured prediction. We describe a distinct combination of network structure, parameter sharing and training procedures that is not only more accurate than Bi-LSTM-CRFs, but also 8x faster at test time on long sequences. Moreover, ID-CNNs with independent classification enable a dramatic 14x test-time speedup, while still attaining accuracy comparable to the Bi-LSTM-CRF. We further demonstrate the ability of ID-CNNs to combine evidence over long sequences by demonstrating their improved accuracy on whole-document (rather than per-sentence) inference. Unlike LSTMs whose sequential processing on sentences of length N requires O(N) time even in the face of parallelism, IDCNNs permit fixed-depth convolutions to run in parallel across entire documents. Today when many companies run basic NLP on the entire web and large-volume traffic, faster methods are paramount to saving time and energy costs.", "histories": [["v1", "Tue, 7 Feb 2017 16:58:18 GMT  (48kb,D)", "http://arxiv.org/abs/1702.02098v1", null], ["v2", "Wed, 8 Feb 2017 14:21:59 GMT  (48kb,D)", "http://arxiv.org/abs/1702.02098v2", null], ["v3", "Sat, 22 Jul 2017 04:04:30 GMT  (53kb,D)", "http://arxiv.org/abs/1702.02098v3", "In Conference on Empirical Methods in Natural Language Processing (EMNLP). Copenhagen, Denmark. September 2017"]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["emma strubell", "patrick verga", "david belanger", "andrew mccallum"], "accepted": true, "id": "1702.02098"}, "pdf": {"name": "1702.02098.pdf", "metadata": {"source": "CRF", "title": "Fast and Accurate Sequence Labeling with Iterated Dilated Convolutions", "authors": ["Emma Strubell", "Patrick Verga", "David Belanger", "Andrew McCallum"], "emails": ["mccallum}@cs.umass.edu"], "sections": [{"heading": "1 Introduction", "text": "It is not only a question of expression, but also of the way the people in the individual countries interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other with each other, how they interact with each other with each other, how they interact with each other, how they interact with each other, how they interact with each other with each other, how they interact with each other with each other, how they interact with each other,"}, {"heading": "2 Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1 Conditional Probability Models for Tagging", "text": "Let x = [x1,.., xT] be our input text and y = [y1,.., yT] be per-token output tag. Let D be the domain size of each yi. We predict the most likely y because a conditional model is given P (y | x). This paper takes into account two factorizations of conditional distribution. First, we have P (y | x) = T-T (yt | F (x)))), (1) where the tags are conditionally independent, as some characteristics are given for x. Given these characteristics, the O (D) prediction is simple and parallelisable across the length of the sequence. However, feature extraction may not necessarily be parallelisable. RNN-based characteristics require iterative transitions along the length of x.We also consider a linear chain CRF model that links all y-x together."}, {"heading": "3 Dilated Convolutions", "text": "CNNs in NLP are typically one-dimensional, applied to a sequence of vectors representing symbols, rather than to a two-dimensional grid of vectors representing pixels. In this setting, a Convolutionary Neural Network Layer corresponds to the application of an affine transformation, Wc to a sliding window with r symbols on either side of each symbol in the sequence. Here, and throughout the paper, we do not explicitly write the bias terms into affine transformations. Convolution is defined over a broader receptive field by jumping over the inputs of the symbol at one point in time, where \u043c is the vector concatenation. Advanced Convolutions perform the same process except by transforming adjacent inputs by skipping the inputs of the symbol at another time, where \u03b4 is the disposition."}, {"heading": "3.1 Multi-Scale Context Aggregation", "text": "We can leverage the ability of extended coils to integrate the global context without losing important local information by stacking extended coils with increasing width. Yu and Koltun (2016), who were first described for pixel classification in computer vision, achieve state-of-the-art results in image segmentation benchmarks by stacking extended coils with exponentially increasing elongation rate, a technique they call multi-scale context aggregation. By feeding the results of each extended coil as input into the next, non-local information is increasingly incorporated into the representation of each pixel. By performing a Dilation-1 convolution in the first layer, no pixels are excluded within the receptive field of any pixel. By doubling the elongation width on each layer, the size of the receptive field grows exponentially, while the number of parameters only grows linearly with the number of layers, so that a global pixel-rich evidence is quickly captured."}, {"heading": "4 Iterated Dilated CNNs", "text": "Stacked extended CNNs can easily contain global information from a whole set or document. For example, the receiver field of each token with a radius of 1 and 4 layers of extended turns is 31 wide, exceeding the average record length (23) in the Penn TreeBank corpus. With a radius of size 2 and 8 layers of extended turns, the receiver field exceeds 1,000 tokens, long enough to encode many complete documentations. Unfortunately, the mere increase in the depth of stacked extended CNNs results in considerable overmatch in our experiments. In response, we present Iterated extended CNNs (ID-CNNs) that instead iterate a small number of extended turns. Repeatedly using the same parameters in a recursive manner provides both broad receptive fields and desirable generating capacities."}, {"heading": "4.1 Model Architecture", "text": "The network takes as input a sequence of T-vectors xt of the dimension dw and outputs a sequence of pro-class values ht, which serve either as local conditional distributions of the model (1) or as local factors of the model (2). The first layer in the network is a dilatation-1 wave formation D (1) 1, which transforms the input into a representation of the dimension dc: it = D (0) 1 xt (5) Next, Lc \u2212 1 layers of dilatory wave formation of exponentially increasing dilatation width are applied to it, which folds on each layer in an ever broader context into the embedded representation of xt, followed by a dilatation-1 wave formation. Let us suggest r () a ReLU activation function (Glorot et al., 2011): Lack et al. \u2212 Starting with ct (0) = they define the stack of layers with the following binding-1 c, followed by a binding-1 (a binding) we (a binding-1)."}, {"heading": "4.2 Training", "text": "Our main focus is on the application of ID-CNN as a feature extraction for the first conditional model described in Sec. 2.1, where tags are conditionally independent, as this allows a prediction that is parallelizable in the length of the input sequence. Here, the maximum probability training is simple because the probability is added to the sum of the probabilities of independent logistical regression problems for each day, with natural parameters given by (8). We present an alternative training method that bridges the gap between these two techniques. We can also use ID-CNN as input characteristics for the CRF model (2), where the partitioning function and its gradients are assembled. We present an alternative training method that helps close the gap between the two techniques."}, {"heading": "5 Related work", "text": "The state of the art for sequence labeling includes a deduction step that scans the space of possible output sequences of a concatenated graphical model from 2016 (2016), or approaches this search with a beam (Collobert et al., 2011; Weiss et al., 2015; Lample et al., 2016; Ma and Hovy, 2016; Chiu and Nichols, 2016), exceeding similar systems that use the same characteristics, but also independent local predictions. On the other hand, the greedy sequential prediction (Daume III et al., 2009) approach of Ratinov and Roth (2009) using lexicalized functions is gazetteers, and word clusters that exceed CRFs with similar characteristics. LSTMs (Hochreiter and Schmidhuber, 1997) were used for NER as early as the CoNLL common task in 2003 (Hammerton, 2003; Tjong Kim Sang Sang and De Meulder, 2003)."}, {"heading": "6 Experimental Results", "text": "On CoNLL-2003 English NER, our ID-CNN outperforms a Bi-LSTM as a feature extractor for a CRF, and with greedy decoding, our ID-CNN achieves performance on par with the Bi-LSTM-CRF while running at more than 14 times the speed. In addition, on almost all models, we observe a performance boost when context is expanded to include entire documents, resulting in an average F1 of 90.65 for CoNL2003, exceeding the Bi-LSTM-CRF, while decoding occurs at almost eight times the speed."}, {"heading": "6.1 Data and Evaluation", "text": "We evaluate using marked data from the joint task CoNLL2003 (Tjong Kim Sang and De Meulder, 2003) and OntoNotes 5.0 (Hovy et al., 2006; Pradhan et al., 2006). After previous work, we use the same OntoNotes data distribution that was used for the joint task CoNLL-2012 (Pradhan et al., 2012). For both sets of data, we convert IOB boundary coding to BILOU, just as earlier work led this coding to improved performance (Ratinov and Roth, 2009). As in previous work, we evaluate the performance of our models using a micro-averaged F1 value at the segment level. Hyperparameters that led to the best performance in the validation set were selected via the web search. A more detailed description of the data, evaluation, optimization and data pre-processing can be found in the appendix."}, {"heading": "6.2 Baselines", "text": "We compare our ID-CNN with strong LSTM and CNN baselines: one Bi-LSTM with local decoding and one with CRF decoding (Bi-LSTMCRF). We also compare with a non-dilated CNN architecture with the same number of contextual layers as our dilated network (4-layer CNN) and one with enough layers to integrate a receptive field of the same size as the dilated network (5-layer CNN) to show that the dilated context information aggregates more effectively than simple context information (i.e., use fewer parameters).We compare our ID-CNNs at the document level with a baseline that does not divide parameters between blocks (noshare) and one that composes losses only at the last block, rather than after each iterated block of dilated convolutions (1-loss).We compare our STN architectures with a baseline that does not divide parameters between blocks (noshare) and one that does not compose losses at the last block, rather than after each iterated block of dilated convolutions (1-loss).We compare our STN architectures with a baseline that does not use complex models for more complex reasons or to build these complex or complex models for a number of reasons:"}, {"heading": "6.3 CoNLL-2003 English NER", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.3.1 Sentence-level prediction", "text": "Table 1 lists F1 results from models executed with set-level context on CoNLL-2003. Viterbi decoding Bi-LSTM-CRF and ID-CNNCRF each yield the highest averages, with the ID-CNN-CRF outperforming the Bi-LSTM-CRF sets by an average of 0.11 points. BiLSTM-CRF also outperforms the results of greedy ID-CNN by 0.11 points. Our greedy ID-CNN models outperform all other greedy models, including the 4-layer CNN, which uses the same number of parameters as the ID-CNN, and the 5-layer CNN, which uses CNN more parameters than CNN, which uses more parameters but covers the receptive field. All CNN models outperform the Bi-LSTM when paired with greedy decoding, suggesting that CNN's are better feature extractors than Bi-LMs for independent logistic regression."}, {"heading": "6.3.2 Document-level prediction", "text": "In Table 4, we show that adding document-level contexts improves each model on CoNLL2003. When incorporating document-level contexts, our greedy ID-CNN model outperforms the Bi-LSTM-CRF, averaging 90.65 F1. We believe that this model outperforms the Bi-LSTMCRF due to the ID-CNN learning function, which is better suited to depict a broad context, as opposed to the Bi-LSTM, which, while better than a simple RNN at encoding long sequences, can reach its limit when it uses sequences of more than 1,000 tokens such as whole documents. We also find that our combination of training target (Eqn. 10) and bound parameters (Eqn. 7) learn more effectively to aggregate this broad context than a vanilla cross-entropy loss or deep CNN feedback formation from the last neural network layer BM, comparing our entire document layer (Eqn. 5) is faster than using scripted documents in the SID section 6.6, where we train the models on it faster than using documents in the entire document section 6.6."}, {"heading": "6.4 OntoNotes 5.0 English NER", "text": "We observe similar patterns on OntoNotes as on CoNLL. Table 7 lists the total number of F1 values of our models compared to those in the existing literature; the greedy Bi-LSTM exceeds the lexicalized greedy model of Ratinov and Roth (2009); and our ID-CNN exceeds the Bi-LSTM as well as the more complex model of Durrett and Klein (2014), which uses the parallel coreference note available in the OntoNotes corpus to link and reference named entities together with entities; our greedy model is exceeded by the Bi-LSTM-CRF model reported in Chiu and Nichols (2016), as well as by our own re-implementation, which appears to be the state-of-the-art on this database."}, {"heading": "7 Conclusion", "text": "We present iterated advanced Convolutionary Neural Networks, fast feature extractors that efficiently aggregate a broad context without losing resolution, delivering impressive speed improvements in sequence labeling, especially when processing entire documents at once. In the future, we hope to extend this work to NLP tasks with richer structured output, such as Parsing.5 results reported in Durrett and Klein (2014), as this data sharing did not exist at the time of publication. According to the ACL wiki page on CoNLL-2003: \"The corpus contains a very high percentage of metonymic references (city names representing sports teams).\""}, {"heading": "A Appendix", "text": "This year, it has reached the stage where it will be able to take the lead."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "Bi-directional LSTMs have emerged as a standard method for obtaining per-token vector representations serving as input to various token labeling tasks (whether followed by Viterbi prediction or independent classification). This paper proposes an alternative to Bi-LSTMs for this purpose: iterated dilated convolutional neural networks (ID-CNNs), which have better capacity than traditional CNNs for large context and structured prediction. We describe a distinct combination of network structure, parameter sharing and training procedures that is not only more accurate than Bi-LSTM-CRFs, but also 8x faster at test time on long sequences. Moreover, ID-CNNs with independent classification enable a dramatic 14x testtime speedup, while still attaining accuracy comparable to the Bi-LSTM-CRF. We further demonstrate the ability of IDCNNs to combine evidence over long sequences by demonstrating their improved accuracy on whole-document (rather than per-sentence) inference. Unlike LSTMs whose sequential processing on sentences of length N requires O(N) time even in the face of parallelism, IDCNNs permit fixed-depth convolutions to run in parallel across entire documents. Today when many companies run basic NLP on the entire web and large-volume traffic, faster methods are paramount to saving time and energy costs.", "creator": "LaTeX with hyperref package"}}}