{"id": "1702.03040", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2017", "title": "Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities", "abstract": "The follow the leader (FTL) algorithm, perhaps the simplest of all online learning algorithms, is known to perform well when the loss functions it is used on are convex and positively curved. In this paper we ask whether there are other \"lucky\" settings when FTL achieves sublinear, \"small\" regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polytope domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL.", "histories": [["v1", "Fri, 10 Feb 2017 01:59:02 GMT  (1791kb,D)", "http://arxiv.org/abs/1702.03040v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["ruitong huang", "tor lattimore", "andr\u00e1s gy\u00f6rgy", "csaba szepesv\u00e1ri"], "accepted": true, "id": "1702.03040"}, "pdf": {"name": "1702.03040.pdf", "metadata": {"source": "CRF", "title": "Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities\u2217", "authors": ["Ruitong Huang", "Tor Lattimore", "Andr\u00e1s Gy\u00f6rgy", "Csaba Szepesv\u00e1ri"], "emails": [], "sections": [{"heading": null, "text": "In this paper, we ask if there are other \"happy\" settings when FTL reaches sublinear, \"small\" regret. In particular, we examine the fundamental problem of linear predictions about a non-empty convex, compact domain. Among other things, we prove that the curvature of the domain boundary can act as if the losses were curved: in this case, we prove that FTL, as long as the mean of the loss vectors has positive lengths that are limited from zero, has a logarithmic growth rate of regret, while for polytopic domains and stochastic data, for example, it enjoys finite, expected regret. Building on a previously known meta algorithm, we also get an algorithm that has both the worst guarantees and the limits available for FTL."}, {"heading": "1 Introduction", "text": "The question is how it came to be that such a process has occurred. (...) The question is whether such a process can occur. (...) The question is how it can occur. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process. (...) The question is whether there will be such a process."}, {"heading": "2 Preliminaries, online learning and the follow the leader algorithm", "text": "We look at the standard framework of online convex optimization, in which a learner and an environment interact in n rounds in a sequential manner: In round of each round t = 1,.., n, first the learner predicts wt-W. Then the environment selects a loss function 't-L, and the learner suffers losses' t (wt) and observes'. Here, W is a non-empty, compact convex subset of Rd and L is a series of convex functions that maps W to the reals. The elements of L are called loss functions. The performance of the learner is measured in terms of regret, Rn = n-t (wt) \u2212 min w-W n-t-t (w).The easiest possible case that will be at the center of this work is when the losses are linear, i.e., when the losses are linear, i.e."}, {"heading": "2.1 Support functions", "text": "It follows that the support function, which represents the maximum linear and therefore convex functions, is itself convex. Furthermore, it is positively homogeneous: for a definitive 0 and a definitive 0 and 1 >.Denote by a definitive (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) ((definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive (definitive) (definitive) (definitive) (definitive) (definitive (definitive) (definitive) (definitive) (definitive (definitive) (definitive) (definitive) (definitive (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive) (definitive (definitive) (definitive) (definitive) (definitive) (definitive) (definitive (definitive) (definitive) (definitive) (definitive (definitive) (definitive) (definitive) (definitive) (definitive () (definitive) (definitive) (definitive) ((definitive) () (definitive (definitive) ((definitive) ((definitive) (definitive) (definitive) () ((definitive) ((definitive) (definitive) (() (definitive) (definitive () () (definitive) (definitive) (definitive) (() (definitive) ((definitive) (() (definitive) ((definitive) () (definitive) (() (definitive) (() (definitive) (("}, {"heading": "3 Non-stochastic analysis of FTL", "text": "We start by rewriting the regret of FTL in an equivalent form, showing that we can expect a small regret when successive weight vectors move little. < < < < < < < < < < < < < < < < \"The result is a direct consequence of Lemma 9 by McMahan (2010), which applies to any sequence of losses, even in the absence of convexity. It is also an appreciation of the known inequality Rn. t (wt + 1), which in turn applies to arbitrary loss sequences (e.g. Lemma 2.1 by Shalev-Shwartz (2012)."}, {"heading": "3.1 Constraint sets with positive curvature", "text": "s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s (s) s (s) s (s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s) s (s (s) s (s) s (s) s (s (s (s) s) s (s (s) s (s) s (s (s) s (s) s (s (s) s) s (s (s) s (s (s) s) s (s (s) s (s (s (s) s (s (s (s) s (s (s) s (s (s (s) s (s) s (s) s (s (s) s (s (s (s (s) s (s (s (s (s) s) s (s (s (s (s) s (s (s) s (s) s (s (s) s (s (s (s (s (s) s) s (s (s (s) s (s (s) s (s (s (s) s (s (s) s (s (s (s) s (s (s (s (s) s (s (s) s (s ("}, {"heading": "3.2 Other regularities", "text": "So far we have looked at the case where FTL has reached a low regret due to the curvature of bd (W). < The next result characterizes the regret of FTL if it is a case that has a flat, non-smooth limit and is therefore not applicable. < The next result describes the regret of FTL if it is a case that has a flat, non-smooth limit and is therefore not applicable. < <"}, {"heading": "4 Adaptive algorithm for the linear game", "text": "While Theorem 3.3 shows that FTL can exploit the curvature of the surface to achieve O (logn) repentance, it requires the curvature state and mint (FTRL) algorithm (see e.g. Shalev-Shwartz, 2012) to achieve a repentance guarantee for O (\u221a n) even for the worst data in the linear setting. \u2212 This raises the question of whether one can have an algorithm that can achieve constant or O (logn) repentance in the respective settings of Corollary 3.9 or Theorem 3.3, while still obtaining O (\u221a n) repentance for the worst data in the linear setting. \u2212 This raises the question of whether one can have an algorithm that obtains constant or O (logn) repentance in the respective settings of Corollary 3.9 or Theorem 3.3, while still obtaining O (\u221a n) repentance for the worst data in the linear setting."}, {"heading": "4.1 Adaptive Algorithms for the Unit Ball Constraint Set", "text": "In this section, we provide some interesting results about adaptive algorithms in case W is the standard ball in Rd (of course, the results can easily be generalized to any ball centered at the origin). First, we show that a variant of FTL that uses shrinkage as regularization, O (log (n)) has remorse if the standard ball and loss vectors are stochastic, but it also has O (\u221a n) worst-case guarantee. Furthermore, we show that the standard FTRL algorithm is adaptive if the standard ball and loss vectors are stochastic."}, {"heading": "4.1.1 Follow the Shrunken Leader", "text": "In this section we will analyze a combination of the FTL algorithm and the idea of shrinkage is often used for regulation purposes in statistics. < n = > Un = > n max. (max.) + > n max. (max.) + > n max. (max.) + > n max. (max.) + > n max. (max.) + > n max. (max.) + + > n max. (max.) + > n max. (max.) + > n. (max.) n. (max.) + > n max. (max.) + > n. (max.) + > n. (max.) + > n. (max.) + > n. (max.) + > n. (max.) + > n. (max.) + > n. (max.)"}, {"heading": "4.1.2 FTRL for the case of the unit ball constraint set", "text": "This section is intended to show that in the case where W is the unit of measurement ball in \"2 norm,\" FTRL with R (w) = > remorse (w) = > remorse (w) = = remorse (w) = remorse (w) if t > 1 and w1 = 0. It is generally known that FTRL with \"t\" = 1 / 4 t \u2212 1 guarantees to achieve O (n) remorse in the adversarial setting, see, for example, (Shalev-Shwartz, 2012). It remains to be noted that FTRL actually achieves a fast rate in stochastic setting. Theorem 4.3. Assuming that the sequence of loss vectors, f1,."}, {"heading": "5 Simulations", "text": "We performed three simulations to illustrate the differences between FTL, FTRL and QW."}, {"heading": "6 Conclusion", "text": "FTL is a simple method that is known to work well in many environments, while the existing worst-case results cannot explain its good performance. While we take a thorough look at why and when FTL can achieve low regret, we have found that the curvature of the limit of constraint, and the fact that the average loss vectors are limited from zero, help to keep the regret of FTL low. These conditions differ significantly from previous conditions on the curvature of loss functions, which have been extensively considered in the literature. It would be interesting to investigate this phenomenon further for other algorithms or in other learning environments."}, {"heading": "A Appendix: Technical results", "text": "iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii"}, {"heading": "Acknowledgements", "text": "This work was supported in part by Alberta Innovates Technology Futures through the Alberta Ingenuity Centre for Machine Learning and NSERC. T. Lattimore was part of the Department of Computing Science at the University of Alberta."}], "references": [{"title": "Forced-exploration based algorithms for playing in bandits with large action sets", "author": ["Y. Abbasi-Yadkori"], "venue": "Library and Archives Canada,", "citeRegEx": "Abbasi.Yadkori.,? \\Q2010\\E", "shortCiteRegEx": "Abbasi.Yadkori.", "year": 2010}, {"title": "Optimal strategies and minimax lower bounds for online convex games", "author": ["J. Abernethy", "P.L. Bartlett", "A. Rakhlin", "A. Tewari"], "venue": "In 21st Annual Conference on Learning Theory (COLT),", "citeRegEx": "Abernethy et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Abernethy et al\\.", "year": 2008}, {"title": "Adaptive online gradient descent", "author": ["P.L. Bartlett", "E. Hazan", "A. Rakhlin"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Bartlett et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Bartlett et al\\.", "year": 2007}, {"title": "Nonlinear Programming", "author": ["D. Bertsekas"], "venue": "Athena Scientific,", "citeRegEx": "Bertsekas.,? \\Q1999\\E", "shortCiteRegEx": "Bertsekas.", "year": 1999}, {"title": "Prediction, Learning, and Games", "author": ["N. Cesa-Bianchi", "G. Lugosi"], "venue": null, "citeRegEx": "Cesa.Bianchi and Lugosi.,? \\Q2006\\E", "shortCiteRegEx": "Cesa.Bianchi and Lugosi.", "year": 2006}, {"title": "On the generalization ability of on-line learning algorithms", "author": ["N. Cesa-Bianchi", "A. Conconi", "C. Gentile"], "venue": "IEEE Trans. Information Theory,", "citeRegEx": "Cesa.Bianchi et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Cesa.Bianchi et al\\.", "year": 2004}, {"title": "Adaptive online learning", "author": ["D.J. Foster", "A. Rakhlin", "K. Sridharan"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Foster et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Foster et al\\.", "year": 2015}, {"title": "A decision-theoretic generalization of on-line learning and an application to boosting", "author": ["Y. Freund", "R. Schapire"], "venue": "Journal of Computer and System Sciences,", "citeRegEx": "Freund and Schapire.,? \\Q1997\\E", "shortCiteRegEx": "Freund and Schapire.", "year": 1997}, {"title": "Stochastic nonstationary optimization for finding universal portfolios", "author": ["A.A. Gaivoronski", "F. Stella"], "venue": "Annals of Operations Research,", "citeRegEx": "Gaivoronski and Stella.,? \\Q2000\\E", "shortCiteRegEx": "Gaivoronski and Stella.", "year": 2000}, {"title": "Faster rates for the frank-wolfe method over strongly-convex sets", "author": ["D. Garber", "E. Hazan"], "venue": "In Proceedings of the 32nd International Conference on Machine Learning (ICML),", "citeRegEx": "Garber and Hazan.,? \\Q2015\\E", "shortCiteRegEx": "Garber and Hazan.", "year": 2015}, {"title": "Logarithmic regret algorithms for online convex optimization", "author": ["E. Hazan", "A. Agarwal", "S. Kale"], "venue": "Machine Learning,", "citeRegEx": "Hazan et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Hazan et al\\.", "year": 2007}, {"title": "Generalized power method for sparse principal component analysis", "author": ["M. Journ\u00e9e", "Y. Nesterov", "P. Richt\u00e1rik", "R. Sepulchre"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Journ\u00e9e et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Journ\u00e9e et al\\.", "year": 2010}, {"title": "Mind the duality gap: Logarithmic regret algorithms for online optimization", "author": ["S.M. Kakade", "S. Shalev-Shwartz"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Kakade and Shalev.Shwartz.,? \\Q2009\\E", "shortCiteRegEx": "Kakade and Shalev.Shwartz.", "year": 2009}, {"title": "Minimax strategy for prediction with expert advice under stochastic assumptions", "author": ["W. Kot\u0142owski"], "venue": "Algorithmic Learning Theory (ALT),", "citeRegEx": "Kot\u0142owski.,? \\Q2016\\E", "shortCiteRegEx": "Kot\u0142owski.", "year": 2016}, {"title": "Constrained minimization methods", "author": ["E.S. Levitin", "B.T. Polyak"], "venue": "USSR Computational Mathematics and Mathematical Physics,", "citeRegEx": "Levitin and Polyak.,? \\Q1966\\E", "shortCiteRegEx": "Levitin and Polyak.", "year": 1966}, {"title": "Follow-the-regularized-leader and mirror descent: Equivalence theorems and implicit updates", "author": ["H.B. McMahan"], "venue": "arXiv,", "citeRegEx": "McMahan.,? \\Q2010\\E", "shortCiteRegEx": "McMahan.", "year": 2010}, {"title": "Universal sequential learning and decision from individual data sequences", "author": ["N. Merhav", "M. Feder"], "venue": "In 5th Annual ACM Workshop on Computational Learning Theory (COLT),", "citeRegEx": "Merhav and Feder.,? \\Q1992\\E", "shortCiteRegEx": "Merhav and Feder.", "year": 1992}, {"title": "Beyond logarithmic bounds in online learning", "author": ["F. Orabona", "N. Cesa-Bianchi", "C. Gentile"], "venue": "In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS),", "citeRegEx": "Orabona et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Orabona et al\\.", "year": 2012}, {"title": "Strongly convex analysis", "author": ["E.S. Polovinkin"], "venue": "Sbornik: Mathematics,", "citeRegEx": "Polovinkin.,? \\Q1996\\E", "shortCiteRegEx": "Polovinkin.", "year": 1996}, {"title": "Elementary differential geometry", "author": ["A.N. Pressley"], "venue": "Springer Science & Business Media,", "citeRegEx": "Pressley.,? \\Q2010\\E", "shortCiteRegEx": "Pressley.", "year": 2010}, {"title": "Online learning with predictable sequences", "author": ["A. Rakhlin", "K. Sridharan"], "venue": "In 26th Annual Conference on Learning Theory (COLT),", "citeRegEx": "Rakhlin and Sridharan.,? \\Q2013\\E", "shortCiteRegEx": "Rakhlin and Sridharan.", "year": 2013}, {"title": "Exploiting easy data in online optimization", "author": ["A. Sani", "G. Neu", "A. Lazaric"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Sani et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Sani et al\\.", "year": 2014}, {"title": "Convex Bodies: The Brunn\u2013Minkowski Theory. Encyclopedia of Mathematics and its Applications", "author": ["R. Schneider"], "venue": null, "citeRegEx": "Schneider.,? \\Q2014\\E", "shortCiteRegEx": "Schneider.", "year": 2014}, {"title": "Online learning and online convex optimization", "author": ["S. Shalev-Shwartz"], "venue": "Foundations and trends in Machine Learning,", "citeRegEx": "Shalev.Shwartz.,? \\Q2012\\E", "shortCiteRegEx": "Shalev.Shwartz.", "year": 2012}, {"title": "Understanding Machine Learning: From Theory to Algorithms", "author": ["S. Shalev-Shwartz", "S. Ben-David"], "venue": null, "citeRegEx": "Shalev.Shwartz and Ben.David.,? \\Q2014\\E", "shortCiteRegEx": "Shalev.Shwartz and Ben.David.", "year": 2014}, {"title": "Fast rates in statistical and online learning", "author": ["T. van Erven", "P. Gr\u00fcnwald", "N. Mehta", "M. Reid", "R. Williamson"], "venue": "Journal of Machine Learning Research (JMLR),", "citeRegEx": "Erven et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Erven et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 4, "context": "Realizing that these assumptions are not necessarily critical, much work has been devoted recently to studying learning algorithms in the so-called online learning framework (Cesa-Bianchi and Lugosi, 2006).", "startOffset": 174, "endOffset": 205}, {"referenceID": 5, "context": "The online learning framework makes minimal assumptions about the data generating mechanism, while allowing one to replicate results of the statistical framework through online-to-batch conversions (Cesa-Bianchi et al., 2004).", "startOffset": 198, "endOffset": 225}, {"referenceID": 17, "context": "1 Introduction Learning theory traditionally has been studied in a statistical framework, discussed at length, for example, by Shalev-Shwartz and Ben-David (2014). The issue with this approach is that the analysis of the performance of learning methods seems to critically depend on whether the data generating mechanism satisfies some probabilistic assumptions.", "startOffset": 127, "endOffset": 163}, {"referenceID": 4, "context": "2015, Foster et al. 2015). In this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are multiple ways online learning problems can present data that allows for small regret, even for FTL. As is it well known, in the worst case, FTL suffers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)).", "startOffset": 6, "endOffset": 888}, {"referenceID": 4, "context": "2015, Foster et al. 2015). In this paper we contribute to this growing literature by studying online linear prediction and the follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest yet fundamental of all the learning settings, and lies at the heart of online convex optimization, while it also serves as an abstraction of core learning problems such as prediction with expert advice. FTL, the online analogue of empirical risk minimization of statistical learning, is the simplest learning strategy, one can think of. Although the linear setting of course removes the possibility of exploiting the curvature of losses, as we will see, there are multiple ways online learning problems can present data that allows for small regret, even for FTL. As is it well known, in the worst case, FTL suffers a linear regret (e.g., Example 2.2 of Shalev-Shwartz (2012)). However, for \u201ccurved\u201d losses (e.g., exp-concave losses), FTL was shown to achieve small (logarithmic) regret (see, e.g., Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.", "startOffset": 6, "endOffset": 1035}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.", "startOffset": 27, "endOffset": 58}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al.", "startOffset": 27, "endOffset": 89}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)).", "startOffset": 27, "endOffset": 110}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees.", "startOffset": 27, "endOffset": 767}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently \u201ccurved\u201d boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( \u221a n logn) regret and the smaller regret bounds, which we prove here for \u201ceasy data.", "startOffset": 27, "endOffset": 1669}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently \u201ccurved\u201d boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( \u221a n logn) regret and the smaller regret bounds, which we prove here for \u201ceasy data.\u201d We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL) algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve logarithmic regret for easy data. Simulation results on artificial data complement the theoretical findings. While we believe that we are the first to point out that the curvature of the constraint set W can help in speeding up learning, this effect is known in convex optimization since at least the work of Levitin and Polyak (1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm of the gradients of the objective function admit a uniform lower bound.", "startOffset": 27, "endOffset": 2378}, {"referenceID": 3, "context": ", Merhav and Feder (1992); Cesa-Bianchi and Lugosi (2006); Gaivoronski and Stella (2000); Hazan et al. (2007)). In this paper we take a thorough look at FTL in the case when the losses are linear, but the problem perhaps exhibits other regularities. The motivation comes from the simple observation that, for prediction over the simplex, when the loss vectors are selected independently of each other from a distribution with a bounded support with a nonzero mean, FTL quickly locks onto selecting the loss-minimizing vertex of the simplex, achieving finite expected regret. In this case, FTL is arguably an excellent algorithm. In fact, FTL is shown to be the minimax optimizer for the binary losses in the stochastic expert setting in the paper of Kot\u0142owski (2016). Thus, we ask the question of whether there are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result shows that when the decision set (or constraint set) has a sufficiently \u201ccurved\u201d boundary (equivalently, if it is strongly convex) and the linear loss is bounded away from 0, FTL is able to achieve logarithmic regret even in the adversarial setting, thus opening up a new way to prove fast rates not based on the curvature of losses, but on that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower bound we show that this regret bound is essentially unimprovable. We also show an alternate bound for polytope constraint sets, which allows us to prove that (under certain technical conditions) for stochastic problems the expected regret of FTL will be finite. To finish, we use (A, B)-prod of Sani et al. (2014) to design an algorithm that adaptively interpolates between the worst case O( \u221a n logn) regret and the smaller regret bounds, which we prove here for \u201ceasy data.\u201d We also show that if the constraint set is the unit ball, both the follow the regularized leader (FTRL) algorithm and a combination of FTL and shrinkage, which we call follow the shrunken leader (FTSL), achieve logarithmic regret for easy data. Simulation results on artificial data complement the theoretical findings. While we believe that we are the first to point out that the curvature of the constraint set W can help in speeding up learning, this effect is known in convex optimization since at least the work of Levitin and Polyak (1966), who showed that exponential rates are attainable for strongly convex constraint sets if the norm of the gradients of the objective function admit a uniform lower bound. More recently, Garber and Hazan (2015) proved an O(1/n2) optimization error bound (with problem-dependent constants) for the Frank-Wolfe algorithm for strongly convex and smooth objectives and strongly convex constraint sets.", "startOffset": 27, "endOffset": 2587}, {"referenceID": 0, "context": "The effect of the shape of the constraint set was also discussed by Abbasi-Yadkori (2010) who demonstrated O( \u221a n) regret in the linear bandit setting.", "startOffset": 68, "endOffset": 90}, {"referenceID": 15, "context": "The result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses, even in the lack of convexity.", "startOffset": 47, "endOffset": 62}, {"referenceID": 15, "context": "The result is a direct corollary of Lemma 9 of McMahan (2010), which holds for any sequence of losses, even in the lack of convexity. It is also a tightening of the well-known inequality Rn \u2264 \u2211n t=1 `t(wt)\u2212 `t(wt+1), which again holds for arbitrary loss sequences (e.g., Lemma 2.1 of Shalev-Shwartz (2012)).", "startOffset": 47, "endOffset": 306}, {"referenceID": 14, "context": "A related concept that has been used in convex optimization to show fast rates is that of a strongly convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is \u03bb-strongly convex with respect to the norm \u2016\u00b7\u2016 if, for any x, y \u2208 W and \u03b3 \u2208 [0, 1], the \u2016\u00b7\u2016-ball with origin \u03b3x+ (1\u2212 \u03b3)y and radius \u03b3(1 \u2212 \u03b3)\u03bb \u2016x\u2212 y\u2016 /2 is included in W.", "startOffset": 123, "endOffset": 173}, {"referenceID": 9, "context": "A related concept that has been used in convex optimization to show fast rates is that of a strongly convex constraint set (Levitin and Polyak, 1966; Garber and Hazan, 2015): W is \u03bb-strongly convex with respect to the norm \u2016\u00b7\u2016 if, for any x, y \u2208 W and \u03b3 \u2208 [0, 1], the \u2016\u00b7\u2016-ball with origin \u03b3x+ (1\u2212 \u03b3)y and radius \u03b3(1 \u2212 \u03b3)\u03bb \u2016x\u2212 y\u2016 /2 is included in W.", "startOffset": 123, "endOffset": 173}, {"referenceID": 22, "context": "4Following Schneider (2014), a convex body of Rd is any non-empty, compact, convex subset of Rd.", "startOffset": 11, "endOffset": 28}, {"referenceID": 21, "context": "One way to design an adaptive algorithm is to use the (A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result: Proposition 4.", "startOffset": 79, "endOffset": 98}, {"referenceID": 21, "context": "One way to design an adaptive algorithm is to use the (A, B)-prod algorithm of Sani et al. (2014), trivially leading to the following result: Proposition 4.1. Consider (A, B)-prod of Sani et al. (2014), where algorithm A is chosen to be FTRL with an appropriate regularization term, while B is chosen to be FTL.", "startOffset": 79, "endOffset": 202}, {"referenceID": 1, "context": "Our proof follows the idea of Abernethy et al. (2008). We compute the upper bound on the value of the game for each round backwards for t = n, n\u2212 1, .", "startOffset": 30, "endOffset": 54}, {"referenceID": 23, "context": ", (Shalev-Shwartz, 2012).", "startOffset": 2, "endOffset": 24}, {"referenceID": 1, "context": "\u201cHalf-adversarial\u201d data The half-adversarial data used in this experiment is the optimal solution for the adversary in the linear game when W is the unit ball (Abernethy et al., 2008).", "startOffset": 159, "endOffset": 183}, {"referenceID": 17, "context": "Condition (ii), which is actually the definition of Polovinkin (1996) for strongly convex sets, means that W can be obtained as the intersection of closed balls of radius 1/\u03bb, such that there is one ball for every boundary point w and tangent hyperplane P where the ball touches P in w.", "startOffset": 52, "endOffset": 70}, {"referenceID": 11, "context": ", by Example 13 of Journ\u00e9e et al. (2010). Proof.", "startOffset": 19, "endOffset": 41}, {"referenceID": 11, "context": ", by Example 13 of Journ\u00e9e et al. (2010). Proof. We show that (i) implies (ii), (ii) implies (iii), and (iii) implies (i). We start with showing that (i) implies (ii). First note that all principal curvatures of the d-dimensional ball B = B1/\u03bb(0) with radius 1/\u03bb (centered at the origin) are \u03bb. Therefore, (i) and Theorem 3.2.9 of Schneider (2014) implies that there is a convex body M such that W +M = B, where for two sets, S1, S2 \u2282 R, S1 +S2 is defined as {s1 + s2 | s1 \u2208 S1, s2 \u2208 S2}.", "startOffset": 19, "endOffset": 348}, {"referenceID": 19, "context": "1 of Pressley (2010), the curvature of \u03b3 at p can be obtained as f \u2032\u2032(s) \u221a 1 + f \u2032(s)2 \u2223\u2223\u2223\u2223 s=0 = f \u2032\u2032(0) .", "startOffset": 5, "endOffset": 21}], "year": 2017, "abstractText": "The follow the leader (FTL) algorithm, perhaps the simplest of all online learning algorithms, is known to perform well when the loss functions it is used on are convex and positively curved. In this paper we ask whether there are other \u201clucky\u201d settings when FTL achieves sublinear, \u201csmall\u201d regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polytope domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL.", "creator": "LaTeX with hyperref package"}}}