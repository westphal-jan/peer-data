{"id": "1702.03274", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Feb-2017", "title": "Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning", "abstract": "End-to-end learning of recurrent neural networks (RNNs) is an attractive solution for dialog systems; however, current techniques are data-intensive and require thousands of dialogs to learn simple behaviors. We introduce Hybrid Code Networks (HCNs), which combine an RNN with domain-specific knowledge encoded as software and system action templates. Compared to existing end-to-end approaches, HCNs considerably reduce the amount of training data required, while retaining the key benefit of inferring a latent representation of dialog state. In addition, HCNs can be optimized with supervised learning, reinforcement learning, or a mixture of both. HCNs attain state-of-the-art performance on the bAbI dialog dataset, and outperform two commercially deployed customer-facing dialog systems.", "histories": [["v1", "Fri, 10 Feb 2017 18:24:13 GMT  (1499kb,D)", "http://arxiv.org/abs/1702.03274v1", null], ["v2", "Mon, 24 Apr 2017 14:39:27 GMT  (1500kb,D)", "http://arxiv.org/abs/1702.03274v2", "Accepted as a long paper for the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017)"]], "reviews": [], "SUBJECTS": "cs.AI cs.CL", "authors": ["jason d williams", "kavosh asadi", "geoffrey zweig"], "accepted": true, "id": "1702.03274"}, "pdf": {"name": "1702.03274.pdf", "metadata": {"source": "CRF", "title": "Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning", "authors": ["Jason D. Williams", "Kavosh Asadi", "Geoffrey Zweig"], "emails": ["jason.williams@microsoft.com", "kavosh@brown.edu", "g2zweig@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "In the past, these dialog systems were built as a pipeline, with modules for speech understanding, state tracking, action selection, and speech generation. However, the interdependencies between modules require considerable complexity - for example, it is often unclear how to define the dialog state, but action selection is based solely on the state of input. In addition, training each module requires specialized labels. Currently, JPMorgan ChaseRecently, end-to-end approaches to recursive neural networks (RNs) are used directly on text transcripts."}, {"heading": "2 Model description", "text": "In fact, it is not so that such a step could involve a textual action or an API call. Secondly, it is such that an expression that refers to an expression as if the user makes an expression (step 1). The expression is characterized in several respects by a vector of words that form as a vector (step 2). Secondly, an expression that refers to a pre-fabricated execution model. An Entity Extraction Module identifies Entity MenMenMenMenMenMenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmenmen"}, {"heading": "3 Related work", "text": "In general, there are two lines of work that apply machine learning to dialog control, the first of which splits a dialog system into a pipeline that typically includes language understanding, dialogue tracking, policy choices, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014). Specifically, with respect to HCNs, previous work has implemented policy as feeder-oriented neural networks (Wen et al., 2016), trained with supervised learning, followed by enhanced learning (Su et al., 2016). In this work, policy is non-recurring - that is, policy depends on the government tracker to summarize observable dialog functions into government functions."}, {"heading": "4 Supervised learning evaluation I", "text": "In fact, it is a way in which people are able to determine for themselves how they want to behave."}, {"heading": "5 Supervised learning evaluation II", "text": "In fact, it is so that most of them are able to put themselves at the centre, not only because they do not want it, but also because they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) It is so that they do not want it. (...) \"(...\" () \"()\" (... \") (\") (\") (...\" (\") (\") (\") (...\") (\") (\") (... \"(\") (\") (\") (... \") (\") (... \"(\") (\") (...\") (\") (...\" () () (\") () () (...\" () () () (... \") () () () () () () () () ()) () () ()) () () ()) () ()) () () ()) () ()) () () () () () ()) () ()) () () () () () ()) () () () () ()) () () () () () ()) () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () () ("}, {"heading": "6 Reinforcement learning illustration", "text": "In the previous sections, supervised learning (SL) is parameterised by a distribution from which the individual actions are guided; \"We have adapted the mimic dialogues provided by the system developer in each case.\" Therefore, once a system works on a scale of 1 and interacts with a large number of users, it is desirable that the system continues to learn autonomously with the help of reinforcement learning (RL). With RL, each round receives a measurement of goodness, which is called a reward; the agent examines different action sequences in different situations and makes adjustments to maximise the expected discounted sum of rewards, which is called a return. For optimisation, we have selected a political gradient (Williams, 1992), which has been successfully applied to dialogue systems (Jurc, 2011), robotics (Kohl and Stone, 2004), and the board game Go (Silver et al., 2016)."}, {"heading": "7 Conclusion", "text": "Compared to existing end-to-end approaches, HCNs offer more developer control and require less training data at the expense of a small amount of developer effort. The results in this paper examined three different dialog areas: In a public restaurant benchmark, HCNs outperformed the performance of purely learned models; the results in two troubleshooting areas outperformed the performance of a commercially deployed rule-based system. Finally, the results from the dialogue simulation show that HCNs can also be optimized with a mix of reinforcement and supervised learning."}, {"heading": "A Supplemental Material", "text": "In fact, it is the case that most people are in a position to move into another world, in which they can move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they, in which they live, in which they, in which they, in which they live, in which they live, in which they, in which they live."}], "references": [{"title": "Learning end-to-end goal-oriented dialog", "author": ["Antoine Bordes", "Jason Weston."], "venue": "CoRR abs/1605.07683. http://arxiv.org/abs/1605.07683.", "citeRegEx": "Bordes and Weston.,? 2016", "shortCiteRegEx": "Bordes and Weston.", "year": 2016}, {"title": "Keras", "author": ["Franois Chollet."], "venue": "https://github. com/fchollet/keras.", "citeRegEx": "Chollet.,? 2015", "shortCiteRegEx": "Chollet.", "year": 2015}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "Proc NIPS 2014 Deep Learning and Representation Learning Workshop.", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "A copy-augmented sequence-to-sequence architecture gives good performance on taskoriented dialogue", "author": ["Mihail Eric", "Christopher D Manning."], "venue": "CoRR abs/1701.04024. https://arxiv.org/abs/1701.04024.", "citeRegEx": "Eric and Manning.,? 2017", "shortCiteRegEx": "Eric and Manning.", "year": 2017}, {"title": "A statistical approach to spoken dialog systems design and evaluation", "author": ["David Griol", "Llus F. Hurtado", "Encarna Segarra", "Emilio Sanchis."], "venue": "Speech Communication 50(8\u20139).", "citeRegEx": "Griol et al\\.,? 2008", "shortCiteRegEx": "Griol et al\\.", "year": 2008}, {"title": "The second dialog state tracking challenge", "author": ["Matthew Henderson", "Blaise Thomson", "Jason Williams."], "venue": "Proc SIGdial Workshop on Discourse and Dialogue, Philadelphia, USA.", "citeRegEx": "Henderson et al\\.,? 2014", "shortCiteRegEx": "Henderson et al\\.", "year": 2014}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "Jurgen Schmidhuber."], "venue": "Neural Computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Statistical dialog management applied to WFSTbased dialog systems", "author": ["Chiori Hori", "Kiyonori Ohtake", "Teruhisa Misu", "Hideki Kashioka", "Satoshi Nakamura."], "venue": "Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE", "citeRegEx": "Hori et al\\.,? 2009", "shortCiteRegEx": "Hori et al\\.", "year": 2009}, {"title": "Natural actor and belief critic: Reinforcement algorithm for learning parameters of dialogue systems modelled as pomdps", "author": ["Filip Jur\u010d\u0131\u0301\u010dek", "Blaise Thomson", "Steve Young"], "venue": "ACM Transactions on Speech and Language Processing", "citeRegEx": "Jur\u010d\u0131\u0301\u010dek et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Jur\u010d\u0131\u0301\u010dek et al\\.", "year": 2011}, {"title": "Policy gradient reinforcement learning for fast quadrupedal locomotion", "author": ["Nate Kohl", "Peter Stone."], "venue": "Robotics and Automation, 2004. Proceedings. ICRA\u201904. 2004 IEEE International Conference on. IEEE, volume 3, pages 2619\u20132624.", "citeRegEx": "Kohl and Stone.,? 2004", "shortCiteRegEx": "Kohl and Stone.", "year": 2004}, {"title": "Example-based dialog modeling for practical multi-domain dialog system", "author": ["Cheongjae Lee", "Sangkeun Jung", "Seokhwan Kim", "Gary Geunbae Lee."], "venue": "Speech Communication 51(5):466\u2013484.", "citeRegEx": "Lee et al\\.,? 2009", "shortCiteRegEx": "Lee et al\\.", "year": 2009}, {"title": "A stochastic model of human-machine interaction for learning dialogue strategies", "author": ["Esther Levin", "Roberto Pieraccini", "Wieland Eckert."], "venue": "IEEE Trans on Speech and Audio Processing 8(1):11\u201323.", "citeRegEx": "Levin et al\\.,? 2000", "shortCiteRegEx": "Levin et al\\.", "year": 2000}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."], "venue": "Proc HLT-NAACL, San Diego, California, USA.", "citeRegEx": "Li et al\\.,? 2016a", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A persona-based neural conversation model", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Georgios Spithourakis", "Jianfeng Gao", "Bill Dolan."], "venue": "Proc Association for Computational Linguistics, Berlin, Germany.", "citeRegEx": "Li et al\\.,? 2016b", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Deep reinforcement learning for dialogue generation", "author": ["Jiwei Li", "Will Monroe", "Alan Ritter", "Michel Galley", "Jianfeng Gao", "Dan Jurafsky."], "venue": "Proc Conference on Empirical Methods in Natural Language Processing, Austin, Texas, USA.", "citeRegEx": "Li et al\\.,? 2016c", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Temporal supervised learning for inferring a dialog policy from example conversations", "author": ["Lihong Li", "He He", "Jason D. Williams."], "venue": "Proc IEEE Workshop on Spoken Language Technologies (SLT), South Lake Tahoe, Nevada, USA.", "citeRegEx": "Li et al\\.,? 2014", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Gated end-toend memory networks", "author": ["Fei Liu", "Julien Perez."], "venue": "CoRR abs/1610.04211. http://arxiv.org/abs/1610.04211.", "citeRegEx": "Liu and Perez.,? 2016", "shortCiteRegEx": "Liu and Perez.", "year": 2016}, {"title": "Training end-to-end dialogue systems with the ubuntu dialogue corpus", "author": ["Ryan Thomas Lowe", "Nissan Pow", "Iulian Vlad Serban", "Laurent Charlin", "Chia-Wei Liu", "Joelle Pineau."], "venue": "Dialogue and Discourse 8(1).", "citeRegEx": "Lowe et al\\.,? 2017", "shortCiteRegEx": "Lowe et al\\.", "year": 2017}, {"title": "LSTM based conversation models", "author": ["Yi Luan", "Yangfeng Ji", "Mari Ostendorf."], "venue": "CoRR abs/1603.09457. http://arxiv.org/abs/1603.09457.", "citeRegEx": "Luan et al\\.,? 2016", "shortCiteRegEx": "Luan et al\\.", "year": 2016}, {"title": "Coherent dialogue with attentionbased language models", "author": ["Hongyuan Mei", "Mohit Bansal", "Matthew R. Walter."], "venue": "CoRR abs/1611.06997. http://arxiv.org/abs/1611.06997.", "citeRegEx": "Mei et al\\.,? 2016", "shortCiteRegEx": "Mei et al\\.", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Proc Advances in Neural Information Processing Systems, Lake Tahoe, USA. pages 3111\u2013", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Query-regression networks for machine comprehension", "author": ["Min Joon Seo", "Hannaneh Hajishirzi", "Ali Farhadi."], "venue": "CoRR abs/1606.04582. http://arxiv.org/abs/1606.04582.", "citeRegEx": "Seo et al\\.,? 2016", "shortCiteRegEx": "Seo et al\\.", "year": 2016}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["Iulian V. Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau."], "venue": "Proceedings of the Thirtieth AAAI Conference on Artificial Intel-", "citeRegEx": "Serban et al\\.,? 2016", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "A hierarchical latent variable encoder-decoder model for generating dialogues", "author": ["Iulian Vlad Serban", "Alessandro Sordoni", "Ryan Lowe", "Laurent Charlin", "Joelle Pineau", "Aaron Courville", "Yoshua Bengio"], "venue": null, "citeRegEx": "Serban et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Serban et al\\.", "year": 2017}, {"title": "Neural responding machine for short-text conversation", "author": ["Lifeng Shang", "Zhengdong Lu", "Hang Li"], "venue": "In Proc Association for Computational Linguistics,", "citeRegEx": "Shang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "Mastering the game of Go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J. Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": null, "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "Optimizing dialogue management with reinforcement leaning: experiments with the NJFun system", "author": ["Satinder Singh", "Diane J Litman", "Michael Kearns", "Marilyn A Walker."], "venue": "Journal of Artificial Intelligence 16:105\u2013133.", "citeRegEx": "Singh et al\\.,? 2002", "shortCiteRegEx": "Singh et al\\.", "year": 2002}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Meg Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan."], "venue": "Proc HLT-NAACL,", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Continuously learning neural dialogue management", "author": ["Pei-Hao Su", "Milica Ga\u0161i\u0107", "Nikola Mrk\u0161i\u0107", "Lina RojasBarahona", "Stefan Ultes", "David Vandyke", "TsungHsien Wen", "Steve Young."], "venue": "arXiv preprint: 1606.02689.", "citeRegEx": "Su et al\\.,? 2016", "shortCiteRegEx": "Su et al\\.", "year": 2016}, {"title": "End-to-end memory networks", "author": ["Sainbayar Sukhbaatar", "Arthur Szlam", "Jason Weston", "Rob Fergus."], "venue": "Proc Advances in Neural Information Processing Systems (NIPS), Montreal, Canada.", "citeRegEx": "Sukhbaatar et al\\.,? 2015", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Theano: A Python framework for fast computation of mathematical expressions", "author": ["Theano Development Team."], "venue": "arXiv e-prints abs/1605.02688. http://arxiv.org/abs/1605.02688.", "citeRegEx": "Team.,? 2016", "shortCiteRegEx": "Team.", "year": 2016}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le."], "venue": "Proc ICML Deep Learning Workshop.", "citeRegEx": "Vinyals and Le.,? 2015", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}, {"title": "A network-based end-to-end trainable taskoriented dialogue system", "author": ["Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Lina Maria Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "David Vandyke", "Steve J. Young."], "venue": "CoRR abs/1604.04562.", "citeRegEx": "Wen et al\\.,? 2016", "shortCiteRegEx": "Wen et al\\.", "year": 2016}, {"title": "The best of both worlds: Unifying conventional dialog systems and POMDPs", "author": ["Jason D. Williams."], "venue": "Proc Intl Conf on Spoken Language Processing (ICSLP), Brisbane, Australia.", "citeRegEx": "Williams.,? 2008", "shortCiteRegEx": "Williams.", "year": 2008}, {"title": "Partially observable Markov decision processes for spoken dialog systems", "author": ["Jason D. Williams", "Steve Young."], "venue": "Computer Speech and Language 21(2):393\u2013422.", "citeRegEx": "Williams and Young.,? 2007", "shortCiteRegEx": "Williams and Young.", "year": 2007}, {"title": "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning", "author": ["Ronald J Williams."], "venue": "Machine learning 8(3-4):229\u2013256.", "citeRegEx": "Williams.,? 1992", "shortCiteRegEx": "Williams.", "year": 1992}, {"title": "Incorporating loosestructured knowledge into LSTM with recall gate for conversation modeling", "author": ["Zhen Xu", "Bingquan Liu", "Baoxun Wang", "Chengjie Sun", "Xiaolong Wang."], "venue": "CoRR abs/1605.05110. http://arxiv.org/abs/1605.05110.", "citeRegEx": "Xu et al\\.,? 2016", "shortCiteRegEx": "Xu et al\\.", "year": 2016}, {"title": "Attention with intention for a neural network conversation model", "author": ["Kaisheng Yao", "Geoffrey Zweig", "Baolin Peng."], "venue": "Proc NIPS workshop on Machine Learning for Spoken Language Understanding and Interaction.", "citeRegEx": "Yao et al\\.,? 2015", "shortCiteRegEx": "Yao et al\\.", "year": 2015}, {"title": "POMDP-based Statistical Spoken Dialogue Systems: a Review", "author": ["Steve Young", "Milica Gasic", "Blaise Thomson", "Jason D. Williams."], "venue": "Proceedings of the IEEE PP(99):1\u201320.", "citeRegEx": "Young et al\\.,? 2013", "shortCiteRegEx": "Young et al\\.", "year": 2013}, {"title": "ADADELTA: an adaptive learning rate method", "author": ["Matthew D. Zeiler."], "venue": "CoRR abs/1212.5701. http://arxiv.org/abs/1212.5701.", "citeRegEx": "Zeiler.,? 2012", "shortCiteRegEx": "Zeiler.", "year": 2012}], "referenceMentions": [{"referenceID": 0, "context": "HCNs attain stateof-the-art performance on the bAbI dialog dataset (Bordes and Weston, 2016), and outperform two commercially deployed customer-facing dialog systems.", "startOffset": 67, "endOffset": 92}, {"referenceID": 0, "context": "Section 4 applies HCNs to the bAbI dialog dataset (Bordes and Weston, 2016).", "startOffset": 50, "endOffset": 75}, {"referenceID": 6, "context": "This vector is passed to an RNN, such as a long shortterm memory (LSTM) (Hochreiter and Schmidhuber, 1997) or gated recurrent unit (GRU) (Chung et al.", "startOffset": 72, "endOffset": 106}, {"referenceID": 2, "context": "This vector is passed to an RNN, such as a long shortterm memory (LSTM) (Hochreiter and Schmidhuber, 1997) or gated recurrent unit (GRU) (Chung et al., 2014).", "startOffset": 137, "endOffset": 157}, {"referenceID": 11, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 26, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 34, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 33, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 7, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 10, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 4, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 38, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 15, "context": "The first decomposes a dialog system into a pipeline, typically including language understanding, dialog state tracking, action selection policy, and language generation (Levin et al., 2000; Singh et al., 2002; Williams and Young, 2007; Williams, 2008; Hori et al., 2009; Lee et al., 2009; Griol et al., 2008; Young et al., 2013; Li et al., 2014).", "startOffset": 170, "endOffset": 346}, {"referenceID": 32, "context": "Specifically related to HCNs, past work has implemented the policy as feed-forward neural networks (Wen et al., 2016), trained with supervised learning followed by reinforcement learning (Su et al.", "startOffset": 99, "endOffset": 117}, {"referenceID": 28, "context": ", 2016), trained with supervised learning followed by reinforcement learning (Su et al., 2016).", "startOffset": 77, "endOffset": 94}, {"referenceID": 27, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 24, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 31, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 37, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 22, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 18, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 36, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 13, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 19, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 17, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 23, "context": "The second, more recent line of work applies recurrent neural networks (RNNs) to learn \u201cendto-end\u201d models, which map from an observable dialog history directly to a sequence of output words (Sordoni et al., 2015; Shang et al., 2015; Vinyals and Le, 2015; Yao et al., 2015; Serban et al., 2016; Li et al., 2016a,c; Luan et al., 2016; Xu et al., 2016; Li et al., 2016b; Mei et al., 2016; Lowe et al., 2017; Serban et al., 2017).", "startOffset": 190, "endOffset": 425}, {"referenceID": 0, "context": "These systems can be applied to task-oriented domains by adding special \u201cAPI call\u201d actions, enumerating database output as a sequence of tokens (Bordes and Weston, 2016), then learning an RNN using Memory Networks (Sukhbaatar et al.", "startOffset": 144, "endOffset": 169}, {"referenceID": 29, "context": "These systems can be applied to task-oriented domains by adding special \u201cAPI call\u201d actions, enumerating database output as a sequence of tokens (Bordes and Weston, 2016), then learning an RNN using Memory Networks (Sukhbaatar et al., 2015), gated memory networks (Liu and Perez, 2016), query reduction networks (Seo et al.", "startOffset": 214, "endOffset": 239}, {"referenceID": 16, "context": ", 2015), gated memory networks (Liu and Perez, 2016), query reduction networks (Seo et al.", "startOffset": 31, "endOffset": 52}, {"referenceID": 21, "context": ", 2015), gated memory networks (Liu and Perez, 2016), query reduction networks (Seo et al., 2016), and copyaugmented networks (Eric and Manning, 2017).", "startOffset": 79, "endOffset": 97}, {"referenceID": 3, "context": ", 2016), and copyaugmented networks (Eric and Manning, 2017).", "startOffset": 36, "endOffset": 60}, {"referenceID": 0, "context": "In this section we compare HCNs to existing approaches on the public \u201cbAbI dialog\u201d dataset (Bordes and Weston, 2016).", "startOffset": 91, "endOffset": 116}, {"referenceID": 5, "context": "Task6 draws on human-computer dialog data from the second dialog state tracking challenge (DSTC2), where usability subjects (crowd-workers) interacted with several variants of a spoken dialog system (Henderson et al., 2014).", "startOffset": 199, "endOffset": 223}, {"referenceID": 6, "context": "We selected an LSTM for the recurrent layer (Hochreiter and Schmidhuber, 1997), with the AdaDelta optimizer (Zeiler, 2012).", "startOffset": 44, "endOffset": 78}, {"referenceID": 39, "context": "We selected an LSTM for the recurrent layer (Hochreiter and Schmidhuber, 1997), with the AdaDelta optimizer (Zeiler, 2012).", "startOffset": 108, "endOffset": 122}, {"referenceID": 20, "context": "Utterance embeddings were formed by averaging word embeddings, using a publicly available 300dimensional word embedding model trained using word2vec on web data (Mikolov et al., 2013).", "startOffset": 161, "endOffset": 183}, {"referenceID": 0, "context": "We compare to four past end-to-end approaches (Bordes and Weston, 2016; Liu and Perez, 2016; Eric and Manning, 2017; Seo et al., 2016).", "startOffset": 46, "endOffset": 134}, {"referenceID": 16, "context": "We compare to four past end-to-end approaches (Bordes and Weston, 2016; Liu and Perez, 2016; Eric and Manning, 2017; Seo et al., 2016).", "startOffset": 46, "endOffset": 134}, {"referenceID": 3, "context": "We compare to four past end-to-end approaches (Bordes and Weston, 2016; Liu and Perez, 2016; Eric and Manning, 2017; Seo et al., 2016).", "startOffset": 46, "endOffset": 134}, {"referenceID": 21, "context": "We compare to four past end-to-end approaches (Bordes and Weston, 2016; Liu and Perez, 2016; Eric and Manning, 2017; Seo et al., 2016).", "startOffset": 46, "endOffset": 134}, {"referenceID": 0, "context": "We emphasize that past approaches have applied purely sequence-to-sequence models, or (as a baseline) purely programmed rules (Bordes and Weston, 2016).", "startOffset": 126, "endOffset": 151}, {"referenceID": 0, "context": "Table 1: Results on bAbI dialog Task5-OOV and Task6 (Bordes and Weston, 2016).", "startOffset": 52, "endOffset": 77}, {"referenceID": 0, "context": "Table 1: Results on bAbI dialog Task5-OOV and Task6 (Bordes and Weston, 2016). Results for \u201cRules\u201d taken from Bordes and Weston (2016). Note that, unlike cited past work, HCNs make use of domainspecific procedural knowledge.", "startOffset": 53, "endOffset": 135}, {"referenceID": 35, "context": "For optimization, we selected a policy gradient approach (Williams, 1992), which has been successfully applied to dialog systems (Jur\u010d\u0131\u0301\u010dek et al.", "startOffset": 57, "endOffset": 73}, {"referenceID": 8, "context": "For optimization, we selected a policy gradient approach (Williams, 1992), which has been successfully applied to dialog systems (Jur\u010d\u0131\u0301\u010dek et al., 2011), robotics (Kohl and Stone, 2004), and the board game Go (Silver et al.", "startOffset": 129, "endOffset": 153}, {"referenceID": 9, "context": ", 2011), robotics (Kohl and Stone, 2004), and the board game Go (Silver et al.", "startOffset": 18, "endOffset": 40}, {"referenceID": 25, "context": ", 2011), robotics (Kohl and Stone, 2004), and the board game Go (Silver et al., 2016).", "startOffset": 64, "endOffset": 85}, {"referenceID": 35, "context": ", the variance) (Williams, 1992).", "startOffset": 16, "endOffset": 32}, {"referenceID": 33, "context": "Additional experiments, not shown for space, found that ablating the action mask slowed training, agreeing with Williams (2008).", "startOffset": 112, "endOffset": 128}], "year": 2017, "abstractText": "End-to-end learning of recurrent neural networks (RNNs) is an attractive solution for dialog systems; however, current techniques are data-intensive and require thousands of dialogs to learn simple behaviors. We introduce Hybrid Code Networks (HCNs), which combine an RNN with domain-specific knowledge encoded as software and system action templates. Compared to existing end-toend approaches, HCNs considerably reduce the amount of training data required, while retaining the key benefit of inferring a latent representation of dialog state. In addition, HCNs can be optimized with supervised learning, reinforcement learning, or a mixture of both. HCNs attain stateof-the-art performance on the bAbI dialog dataset (Bordes and Weston, 2016), and outperform two commercially deployed customer-facing dialog systems.", "creator": "LaTeX with hyperref package"}}}