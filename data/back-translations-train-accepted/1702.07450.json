{"id": "1702.07450", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Feb-2017", "title": "Strongly-Typed Agents are Guaranteed to Interact Safely", "abstract": "As artificial agents proliferate, it is becoming increasingly important to ensure that their interactions with one another are well-behaved. In this paper, we formalize a common-sense notion of when algorithms are well-behaved: an algorithm is safe if it does no harm. Motivated by recent progress in deep learning, we focus on the specific case where agents update their actions according to gradient descent. The first result is that gradient descent converges to a Nash equilibrium in safe games.", "histories": [["v1", "Fri, 24 Feb 2017 02:30:15 GMT  (360kb,D)", "http://arxiv.org/abs/1702.07450v1", "13 pages"]], "COMMENTS": "13 pages", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.GT", "authors": ["david balduzzi"], "accepted": true, "id": "1702.07450"}, "pdf": {"name": "1702.07450.pdf", "metadata": {"source": "CRF", "title": "Strongly-Typed Agents are Guaranteed to Interact Safely", "authors": ["David Balduzzi"], "emails": ["<dbalduzzi@gmail.com>."], "sections": [{"heading": null, "text": "The main contribution is to define highly typed agents and to show that their safe interaction is ensured. A number of examples show that strong typing generalizes certain key features of convectivity and is closely related to blind source separation. Analysis opens up a new perspective on classic multilinear games based on tensor decomposition."}, {"heading": "1. Introduction \u201cFirst, do no harm\u201d", "text": "This year, it has come to the point where there is only one occasion when there is a scandal, and that is when there is a scandal."}, {"heading": "2. Safety", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Types and orthogonal projections", "text": "Let's remember some basic facts about orthogonal projections. Let (V, < \u2022, \u2022 >) be a vector space equipped with an inner product. An orthogonal projection is a linear transformation \u03c0: V \u2192 V, which is O1. idempotent, \u03c02 = \u03c0, andO2. self-completing, < \u03c0v, v \u2032 > = < v, \u03c0v \u2032 > for each v, v \u00b2 V.Lemma 1. Let P have an (n \u00b7 k) matrix with orthogonal columns p1,.., pk. Then the (n \u00b7 n) matrix PPP = \u2211 k i = 1 pi < pi, \u2022 > = \u0445k i = 1 pip i is an (orthogonal) projection. Lemma 2. If two orthogonal projections have this type, then your product is an orthogonal projection."}, {"heading": "2.2. Safe games", "text": "Definition 2. A game consists of a type of TV, feasibly set H-V, player [N]: = {1,.., N}, losses'n: H-R, and an assignment: [N] \u2192 [R] from player to project.The type structure and assignments specify the coordinates controlled by each player. In turn t, player n specifies the coordinates of the joint action vector that player n can change. Example 1. In a block game, actions w-V = 1 RDn decompose as w = (w1,.., wN) specify the coordinates of the joint action vector that player n can change. Example 1. In a block game actions w-V = 1 RDn decompose as w = (w1,.., wN), where the next player can change the coordinates in shape."}, {"heading": "2.3. Convergence", "text": "A block game is convex if the achievable quantity H is compact and convex and the losses'n: H \u2192 R are convex in the coordinates controlled by the respective players. \u2212 nash balances are guaranteed to be present in convex block games (Nash, 1950). However, they are often difficult to find (Daskalakis et al., 2009). We show gradient descend converges to a Nash balance in safe convex games (Theorem 1st grade descend converts to a Nash balance in safe convex games with smooth losses. Proof. Introduce potential function (w) = Convergence N = 1 Convergence n (w), where a game is absolutely positive. Then < Convergence converts to a Nash balance in safe convex games with smooth losses."}, {"heading": "3. Strongly-Typed Games", "text": "The Fourier transformation diagonalizes differentiation and folding at the same time: F (df dx) = 2\u03c0i\u03c9F (f) and F (f \u0445 g) = F (f) \u00b7 F (g) The SVD diagonalizes any arbitrary matrix: QMP = D. Finally, the legendary transformation f (\u03b7) = max\u03b8 (f (\u03b8)} calls infimal folding (f g) into question. Diagonalization finds a latent orthogonal basis that is mathematically more accessible than the naturally occurring coordinate system. The strong typing is based on an extension of the diagonalization to nonlinear functions."}, {"heading": "3.1. Warmup: When are two-player games safe?", "text": "To orient the reader, let's consider a minimal example that illustrates most of the main ideas of the paper: Bilinear games with two players (von Neumann & Morgenstern, 1944); a block game with two players with loss functions' 1 (v, w) = v'Aw and '2 (v, w) = vBwand projections \u03c01 / 2 (v, w) = (v, 0) and (0, w); the gradations are safe if < 1 (vjAij) + viAij (v, w) = (wAA, vA) and 2 = (wB, vB); the game is safe if < 1 (v1), 2 > = wBw (wBw) and < Bw \u2265 0 and < Q2 (v2) > symmetrical components are safe."}, {"heading": "3.2. Warmup: When is Newton\u2019s method safe?", "text": "It was observed in Dauphin et al. (2014) that applying the Newtonian method to neural networks is problematic because it is attracted by saddle points and can increase the loss in case of non-convex problems. We reformulate their observation in the language of security. Let's consider an open game of a single player with double differentiable loss \": V \u2192 R and projection = IV. Newton's method is optimized\" by weight updates wt + 1 = wt \u2212 t with t = t \u00b7 H \u2212 1 (wt) \u00b7 (wt), whereby Hip \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" \"p\" p \"p\" \"p\" p \"p\" p \"\" p \"p\" p \"p\" \"p\" p \"p\" p \"p\" p \"\" p \"p\" p \"\" p \"p\" p \"p\" \"p\" p \"p\" \"p\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" \"p\" p \"p\" p \"p\" p \"p\" p \"p\" \"p\" p \"p\" p \"p\" p \"p\" p \"p\" \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" \"p\" \"p\" \"\" \"p\" p \"\" p \"p\" p \"p\" \"p\" p \"p\" \"p\" p \"p\" p \"p\" p \"\" p \"\" p \"p\" p \"\" p \"p\" p \"\" p \"\" p \"p\" \"p\" \"\" p \"\" p \"p\" p \"\" \"p\" p \"p\" p \"p\" p \"p\" p \"p\" p \"\" p \"p\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" p \"p\" p \"\" p \"p\" p \"p\" p \"p\" p \"(w\" p \"p\" p"}, {"heading": "3.3. Strongly-typed games are safe", "text": "We apply the lessons from the heats to define a factorization of nonlinear functions. Definition 4. The functions {'n: V \u2192 R} Nn = 1: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0: 0:"}, {"heading": "3.4. Comparison with potential games", "text": "The evidence for Theorem 1 suggests that safe games are related to potential games (Monderer & Shapley, 1996).In our notation, a block game is a weighted potential game if there is a potential function \u03a6 and scalar weights \u03b1n > 0 that are satisfactory to all w, v \u00b2 V and n \u00b2 [N].We provide two counter-examples to show that strongly typed games differ from potential games.Example 5 (a strongly typed game that is not a potential game): Let '1 (x, y) = x1y1 + 2x2y2 and' 2 (x, y) = 3x1y1 + 4x2y2."}, {"heading": "4. Quadratic Games", "text": "For a collection of (D \u00b7 D) matrices {A (n)} Nn = 1 andDvectors {b (n)}, the corresponding square game has loss functions'n (w) = 1 2 wA (n) w + wb (n).We assume that the matrices A (n) are symmetrical without losing their universality."}, {"heading": "4.1. Open quadratic games", "text": "This year, it has reached the point where it will be able to retaliate."}, {"heading": "4.2. Block Quadratic Games", "text": "In fact, most of them are able to abide by the rules they have imposed on themselves, and they are, \"he told the Deutsche Presse-Agentur in an interview with\" Frankfurter Allgemeine Zeitung \"(Friday).\" I think they will be able to abide by the rules, \"he told the Deutsche Presse-Agentur.\" I don't think they will be able to abide by the rules, \"he told the Deutsche Presse-Agentur.\" I don't think they will be able to abide by the rules. \""}, {"heading": "5. Multi-Player Games and Tensor-SVD", "text": "A classic example of this is that it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is about a way in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is not in which it is"}, {"heading": "6. Biologically Plausible Backpropagation", "text": "Our ultimate goal is to safely optimize neural networks with multiple loss functions (Marblestone et al., 2016), which requires the construction of feedback variants that allow the propagation of multiple error signals. Initial steps in this direction have been taken with biologically plausible feedback models that introduce additional degrees of freedom into the algorithm. Feedback is a recently proposed algorithm with comparable empirical feedback power. It is also biologically more plausible as it loosens the feedback requirement that the weights used for pre-feedback and feedback are symmetric (Lillicrap et et et et al., 2016). The main theoretical result of the paper, see its supplementary information, is theorem. Let us feedback the errors."}, {"heading": "7. Conclusion", "text": "It provides a general-purpose tool for training interesting differentiated modules as long as they share a single goal. However, effectively training populations of neural networks on multiple, potentially conflicting tasks, as they automatically exploit synergies and avoid harmful incompatibilities (such as unlearning old features because they are not useful for a new task), requires fundamentally new ideas. A key piece of the puzzle is the development of typing systems that can be used to safely perform certain optimizations and trigger potential conflicts so that the incompatible optimization problems can be separated from each other. The paper provides a first step in this direction, convex methods have played a huge role in optimization, but their relevance for deep learning is limited. The approach to strong typing here is inspired and extends certain features of the constellation constellation."}, {"heading": "A1. The natural gradient is safe", "text": "The natural gradient was introduced in Amari (1998) and is often used in machine learning. Theorem. the direction of the steepest gradient is the direction G \u2212 1 (wt) \u00b7 1 (wt) \u00b7 1 (wt).Proof. We follow Amari (1998). The problem is reduced to the limited minimization argmin (wt).The natural gradient is the direction G \u2212 1 (wt) \u00b7 1 (wt). (wt) Types (wt). (wt) Types. (wt) Types. (wt) Types. (wt) Types. (wt). (wt) Types. (wt) Type. (wt.) Type. (wt.) Type. (wt.) Type. (wt.) Type. (wt.) Type. (wt.) Type. (wt.) Type. (wt.) Type. (wt.) Type."}, {"heading": "A2. Mirror descent is safe", "text": "& & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & & &"}, {"heading": "A3. Direct proofs of corollaries 1 and 2", "text": "Direct proof of inference 1.Evidence. Safety requires < p > = (A (n) w \u2212 b (n)) (A (m) w \u2212 b (m)) \u2265 0.1 Proof of assumptions results in < p > = (w \u2212 b) PD (n) D (m) P (w \u2212 b) \u2265 0which is positive by inspection. Direct proof of inference 2.Evidence. Safety requires that (w \u2212 b) A (m) \u2022 m A (n) m (n) m (n) + b (n) and \u03c0n (n) = wA (n) \u2022 n + b (n) nAfter the introduction of b (n) = A (n) b the safety requires that (w \u2212 b) A (m) \u2022 m A (n) m \u2022 (w \u2212 b) \u2265 0 for all w \u2212 m and n.Annex x x x x = RP (w \u2212 b) obtainsxD (m) \u2022 m (Rm) that (Rm) \u2022 (Rm) \u2265 D (Rm)"}, {"heading": "A4. Higher-order SVD", "text": "In this section we recall the concept of the HOSVD and show why a simultaneous HOSVD \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "A5. Kickback is safe", "text": "Kickback is a complementary feedback algorithm that is motivated by the observation that neurons communicate via a single type of signal, spikes, rather than using the two types of signals (feedback sweep and backward propagated errors) required by Backprop (Balduzzi et al., 2015).Kickback is a shortened version of Backprop that calculates gradient estimates using the feedback sweep along with global error / reward signals. The error signals take the form of a single scalar value that is transmitted to the entire network, for example via neuromodulators. One of the main findings of the paper is: Theorem. If neurons are coherent, Kickback secures. See Theorem 4 by Balduzzi et al. (2015). Coherence is essentially a positivity condition for synaptic weights that ensures positives are calculated by kickback gradients."}, {"heading": "A6. Comparison with Strongly-Typed RNNs", "text": "Typed linear algebra was proposed in Balduzzi & Ghifary (2016) (STNN), where the framework for analyzing and simplifying recurrent neural networks was applied. The definition of typed vector space in this paper is more general than in STNN - it replaces an orthogonal basis with orthogonal projections. STNN did not give a formal definition of strong typing. Informally, STNN explained: \"We call architectures strongly typed if they both (i) maintain the type structure of their characteristics and (ii) separate the learned parameters from state dependence.\" The definition of strong typing in the main text differs from the definition of strong typing in STNN, although it relies on similar intuitions."}], "references": [{"title": "Concrete Problems in AI Safety", "author": ["Amodei", "Dario", "Olah", "Chris", "Steinhardt", "Jacob", "Christiano", "Paul", "Schulman", "John", "Man\u00e9", "Dan"], "venue": "In arXiv:1606.06565,", "citeRegEx": "Amodei et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Amodei et al\\.", "year": 2016}, {"title": "Kickback cuts Backprop\u2019s red-tape: Biologically plausible credit assignment in neural networks", "author": ["D Balduzzi", "H Vanchinathan", "J. Buhmann"], "venue": "In AAAI,", "citeRegEx": "Balduzzi et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Balduzzi et al\\.", "year": 2015}, {"title": "Grammars for Games: A Gradient-Based, Game-Theoretic Framework for Optimization in Deep Learning", "author": ["Balduzzi", "David"], "venue": "Frontiers in Robotics and AI,", "citeRegEx": "Balduzzi and David.,? \\Q2016\\E", "shortCiteRegEx": "Balduzzi and David.", "year": 2016}, {"title": "Strongly-Typed Recurrent Neural Networks", "author": ["Balduzzi", "David", "Ghifary", "Muhammad"], "venue": "In ICML,", "citeRegEx": "Balduzzi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Balduzzi et al\\.", "year": 2016}, {"title": "Deep Learning of Representations: Looking Forward", "author": ["Bengio", "Yoshua"], "venue": "Statistical Language and Speech Processing. Springer,", "citeRegEx": "Bengio and Yoshua.,? \\Q2013\\E", "shortCiteRegEx": "Bengio and Yoshua.", "year": 2013}, {"title": "Deep Generalized Canonical Correlation Analysis", "author": ["Benton", "Adrian", "Khayrallah", "Huda", "Gujral", "Biman", "Reisinger", "Drew", "Zhang", "Sheng", "Arora", "Raman"], "venue": "In arXiv:1702.02519,", "citeRegEx": "Benton et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Benton et al\\.", "year": 2017}, {"title": "Safe learning of regions of attraction for uncertain, nonlinear systems with gaussian processes", "author": ["F Berkenkamp", "R Moriconi", "A Schoellig", "A. Krause"], "venue": "In IEEE CDC,", "citeRegEx": "Berkenkamp et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Berkenkamp et al\\.", "year": 2016}, {"title": "Convex Optimization: Algorithms and Complexity", "author": ["Bubeck", "S\u00e9bastien"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "Bubeck and S\u00e9bastien.,? \\Q2015\\E", "shortCiteRegEx": "Bubeck and S\u00e9bastien.", "year": 2015}, {"title": "On the tensor SVD and the optimal low rank orthogonal approximation of tensors", "author": ["Chen", "Jie", "Saad", "Yousef"], "venue": "SIAM J. Matrix Anal. Appl.,", "citeRegEx": "Chen et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2009}, {"title": "The recent excitement about neural networks", "author": ["Crick", "Francis"], "venue": "Nature, 337(12):129\u2013132,", "citeRegEx": "Crick and Francis.,? \\Q1989\\E", "shortCiteRegEx": "Crick and Francis.", "year": 1989}, {"title": "The Complexity of Computing a Nash Equilibrium", "author": ["Daskalakis", "Constantinos", "Goldberg", "Paul W", "Papadimitriou", "Christos"], "venue": "SIAM J. Computing,", "citeRegEx": "Daskalakis et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Daskalakis et al\\.", "year": 2009}, {"title": "Identifying and attacking the saddle point problem in high-dimensional non-convex optimization", "author": ["Dauphin", "Yann", "Pascanu", "Razvan", "Gulcehre", "Caglar", "Cho", "Kyunghyun", "Ganguli", "Surya", "Bengio", "Yoshua"], "venue": "In NIPS,", "citeRegEx": "Dauphin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dauphin et al\\.", "year": 2014}, {"title": "A multilinear singular value decomposition", "author": ["de Lathauwer", "Lieven", "de Moor", "Bart", "Vandewalle", "Joos"], "venue": "SIAM J. Matrix Anal. Appl.,", "citeRegEx": "Lathauwer et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Lathauwer et al\\.", "year": 2000}, {"title": "PathNet: Evolution Channels Gradient Descent in Super Neural Networks", "author": ["C Fernando", "D Banarse", "C Blundell", "Y Zwols", "D Ha", "A Rusu", "A Pritzel", "D. Wierstra"], "venue": null, "citeRegEx": "Fernando et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Fernando et al\\.", "year": 2017}, {"title": "Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups", "author": ["G Hinton"], "venue": "IEEE Signal Proc Magazine,", "citeRegEx": "Hinton,? \\Q2012\\E", "shortCiteRegEx": "Hinton", "year": 2012}, {"title": "Independent Component Analysis", "author": ["Hyv\u00e4rinen", "Aapo", "Karhunen", "Juha", "Oja", "Erkki"], "venue": null, "citeRegEx": "Hyv\u00e4rinen et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Hyv\u00e4rinen et al\\.", "year": 2001}, {"title": "Multi-view Regression Via Canonical Correlation Analysis", "author": ["Kakade", "Sham", "Foster", "Dean P"], "venue": "In COLT,", "citeRegEx": "Kakade et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Kakade et al\\.", "year": 2007}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["A Krizhevsky", "I Sutskever", "Hinton", "G E"], "venue": "In Advances in Neural Information Processing Systems (NIPS),", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Random feedback weights support error backpropagation for deep learning", "author": ["Lillicrap", "Timothy P", "Cownden", "Daniel", "Tweed", "Douglas B", "Ackerman", "Colin J"], "venue": "Nature Communications,", "citeRegEx": "Lillicrap et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lillicrap et al\\.", "year": 2016}, {"title": "Towards an Integration of Deep Learning and Neuroscience", "author": ["Marblestone", "Adam H", "Wayne", "Greg", "Kording", "Konrad P"], "venue": "Front. Comput. Neurosci.,", "citeRegEx": "Marblestone et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Marblestone et al\\.", "year": 2016}, {"title": "Correlated random features for fast semi-supervised learning", "author": ["McWilliams", "Brian", "Balduzzi", "David", "Buhmann", "Joachim"], "venue": "In NIPS,", "citeRegEx": "McWilliams et al\\.,? \\Q2013\\E", "shortCiteRegEx": "McWilliams et al\\.", "year": 2013}, {"title": "Human-level control through deep reinforcement learning", "author": ["Mnih", "Volodymyr", "Kavukcuoglu", "Koray", "Silver", "David"], "venue": "Nature, 518(7540):529\u2013533,", "citeRegEx": "Mnih et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2015}, {"title": "Equilibrium Points in n-Person Games", "author": ["Nash", "John F"], "venue": "Proc Natl Acad Sci U S A,", "citeRegEx": "Nash and F.,? \\Q1950\\E", "shortCiteRegEx": "Nash and F.", "year": 1950}, {"title": "Optimization, learning, and games with predictable sequences", "author": ["Rakhlin", "Alexander", "Sridharan", "Karthik"], "venue": "In NIPS,", "citeRegEx": "Rakhlin et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rakhlin et al\\.", "year": 2013}, {"title": "The Information Geometry of Mirror Descent", "author": ["G Raskutti", "S. Mukherjee"], "venue": "IEEE Trans. Inf. Theory,", "citeRegEx": "Raskutti and Mukherjee,? \\Q2015\\E", "shortCiteRegEx": "Raskutti and Mukherjee", "year": 2015}, {"title": "Mastering the game of go with deep neural networks and tree search", "author": ["Silver", "David", "Huang", "Aja"], "venue": null, "citeRegEx": "Silver et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Silver et al\\.", "year": 2016}, {"title": "Fast Convergence of Regularized Learning in Games", "author": ["Syrgkanis", "Vasilis", "Agarwal", "Alekh", "Luo", "Haipeng", "Schapire", "Robert"], "venue": "In NIPS,", "citeRegEx": "Syrgkanis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Syrgkanis et al\\.", "year": 2015}, {"title": "Tensor Switching Networks", "author": ["Tsai", "Chuan-Yung", "Saxe", "Andrew", "Cox", "David"], "venue": "In NIPS,", "citeRegEx": "Tsai et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tsai et al\\.", "year": 2016}, {"title": "Safe Exploration in Finite Markov Decision Processes with Gaussian Processes", "author": ["Turchetta", "Matteo", "Berkenkamp", "Felix", "Krause", "Andreas"], "venue": "In NIPS,", "citeRegEx": "Turchetta et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Turchetta et al\\.", "year": 2016}, {"title": "Theory of Games and Economic Behavior", "author": ["von Neumann", "John", "Morgenstern", "Oskar"], "venue": null, "citeRegEx": "Neumann et al\\.,? \\Q1944\\E", "shortCiteRegEx": "Neumann et al\\.", "year": 1944}, {"title": "Learning deep control policies for autonomous aerial vehicles with mpc-guided policy search", "author": ["T Zhang", "G Kahn", "S Levine", "P. Abbeel"], "venue": null, "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Rank-one approximation to higher order tensors", "author": ["Zhang", "Tong", "Golub", "Gene H"], "venue": "SIAM J. Matrix Anal. Appl.,", "citeRegEx": "Zhang et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2001}], "referenceMentions": [{"referenceID": 17, "context": "Recent years have seen rapid progress on core problems in artificial intelligence such as object and voice recognition (Hinton & et al, 2012; Krizhevsky et al., 2012), playing video and board games (Mnih et al.", "startOffset": 119, "endOffset": 166}, {"referenceID": 21, "context": ", 2012), playing video and board games (Mnih et al., 2015; Silver et al., 2016), and driving autonomous vehicles (Zhang et al.", "startOffset": 39, "endOffset": 79}, {"referenceID": 25, "context": ", 2012), playing video and board games (Mnih et al., 2015; Silver et al., 2016), and driving autonomous vehicles (Zhang et al.", "startOffset": 39, "endOffset": 79}, {"referenceID": 30, "context": ", 2016), and driving autonomous vehicles (Zhang et al., 2016).", "startOffset": 41, "endOffset": 61}, {"referenceID": 0, "context": "A weakness of the approach is that it conceives safety more narrowly than, for example, Amodei et al. (2016) which is concerned with societal risks arising from artificial intelligence.", "startOffset": 88, "endOffset": 109}, {"referenceID": 1, "context": "Sections 6 and A5 switch to neural networks and analyze two biologically plausible variants of backpropagation (Balduzzi et al., 2015; Lillicrap et al., 2016).", "startOffset": 111, "endOffset": 158}, {"referenceID": 18, "context": "Sections 6 and A5 switch to neural networks and analyze two biologically plausible variants of backpropagation (Balduzzi et al., 2015; Lillicrap et al., 2016).", "startOffset": 111, "endOffset": 158}, {"referenceID": 28, "context": "The literature on safety is mostly focused on problems arising in reinforcement learning, for example ensuring agents avoid dangerous outcomes (Turchetta et al., 2016; Amodei et al., 2016; Berkenkamp et al., 2016).", "startOffset": 143, "endOffset": 213}, {"referenceID": 0, "context": "The literature on safety is mostly focused on problems arising in reinforcement learning, for example ensuring agents avoid dangerous outcomes (Turchetta et al., 2016; Amodei et al., 2016; Berkenkamp et al., 2016).", "startOffset": 143, "endOffset": 213}, {"referenceID": 6, "context": "The literature on safety is mostly focused on problems arising in reinforcement learning, for example ensuring agents avoid dangerous outcomes (Turchetta et al., 2016; Amodei et al., 2016; Berkenkamp et al., 2016).", "startOffset": 143, "endOffset": 213}, {"referenceID": 19, "context": "A recent survey paper argues the brain optimizes a family of complementary loss functions (Marblestone et al., 2016) without considering how the complementarity of the loss functions could be checked or enforced.", "startOffset": 90, "endOffset": 116}, {"referenceID": 0, "context": ", 2016; Amodei et al., 2016; Berkenkamp et al., 2016). Gradients are typically not available in reinforcement learning problems. We study interactions between algorithms with clearly defined objectives that utilize gradient-based optimization, which gives a more technical perspective. The idea of a population of neural networks solving multiple related tasks is developed in Fernando et al. (2017), which uses genetic algorithms to adapt components to new tasks.", "startOffset": 8, "endOffset": 400}, {"referenceID": 0, "context": ", 2016; Amodei et al., 2016; Berkenkamp et al., 2016). Gradients are typically not available in reinforcement learning problems. We study interactions between algorithms with clearly defined objectives that utilize gradient-based optimization, which gives a more technical perspective. The idea of a population of neural networks solving multiple related tasks is developed in Fernando et al. (2017), which uses genetic algorithms to adapt components to new tasks. However, they repeatedly reinitialize components to undo the damage done by the genetic algorithm. Our work is intended, ultimately, to help design algorithms that detect and avoid damaging updates. A recent survey paper argues the brain optimizes a family of complementary loss functions (Marblestone et al., 2016) without considering how the complementarity of the loss functions could be checked or enforced. The idea of investigating game-theoretic and mechanism design questions specific to certain classes of algorithms is introduced in Rakhlin & Sridharan (2013); Syrgkanis et al.", "startOffset": 8, "endOffset": 1035}, {"referenceID": 0, "context": ", 2016; Amodei et al., 2016; Berkenkamp et al., 2016). Gradients are typically not available in reinforcement learning problems. We study interactions between algorithms with clearly defined objectives that utilize gradient-based optimization, which gives a more technical perspective. The idea of a population of neural networks solving multiple related tasks is developed in Fernando et al. (2017), which uses genetic algorithms to adapt components to new tasks. However, they repeatedly reinitialize components to undo the damage done by the genetic algorithm. Our work is intended, ultimately, to help design algorithms that detect and avoid damaging updates. A recent survey paper argues the brain optimizes a family of complementary loss functions (Marblestone et al., 2016) without considering how the complementarity of the loss functions could be checked or enforced. The idea of investigating game-theoretic and mechanism design questions specific to certain classes of algorithms is introduced in Rakhlin & Sridharan (2013); Syrgkanis et al. (2015). The papers consider how convergence in games can be accelerated if the players use variants of mirror descent.", "startOffset": 8, "endOffset": 1060}, {"referenceID": 10, "context": "However, finding them is often intractable (Daskalakis et al., 2009).", "startOffset": 43, "endOffset": 68}, {"referenceID": 11, "context": "Warmup: When is Newton\u2019s method safe? It was observed in Dauphin et al. (2014) that applying Newton\u2019s method to neural networks is problematic because it is attracted to saddle points and can increase the loss on nonconvex problems.", "startOffset": 57, "endOffset": 79}, {"referenceID": 20, "context": "The blocks can be thought of as generating multiple views on a single latent signal, (Kakade & Foster, 2007; McWilliams et al., 2013; Benton et al., 2017).", "startOffset": 85, "endOffset": 154}, {"referenceID": 5, "context": "The blocks can be thought of as generating multiple views on a single latent signal, (Kakade & Foster, 2007; McWilliams et al., 2013; Benton et al., 2017).", "startOffset": 85, "endOffset": 154}, {"referenceID": 12, "context": "We use the n-mode product notation \u00d7n, see de Lathauwer et al. (2000). Not all tensors admit a tensor-SVD.", "startOffset": 46, "endOffset": 70}, {"referenceID": 15, "context": "ICA recovers S from the cumulants of X, see Hyv\u00e4rinen et al. (2001). The main insight is that the 4th-order cumulant tensor admits a tensor-SVD: A[i, j, k, l] = cum(xi, xj , xk, xl)", "startOffset": 44, "endOffset": 68}, {"referenceID": 19, "context": "Our ultimate goal is to apply strong-typing to safely optimize neural nets with multiple loss functions (Marblestone et al., 2016).", "startOffset": 104, "endOffset": 130}, {"referenceID": 18, "context": "It is also more biologically plausible since it loosens backprop\u2019s requirement that the weights used for forward- and back- propagation are symmetric (Lillicrap et al., 2016).", "startOffset": 150, "endOffset": 174}, {"referenceID": 18, "context": "See theorem 2 of Lillicrap et al. (2016).", "startOffset": 17, "endOffset": 41}, {"referenceID": 1, "context": "Another variant of backprop is kickback, which loosens backprop\u2019s requirement that there are distinct forward- and backward signals (Balduzzi et al., 2015).", "startOffset": 132, "endOffset": 155}, {"referenceID": 16, "context": "In fact, Lillicrap et al. (2016) provide experimental and theoretical evidence that feedback alignment learns to align the feedforward weights with the pseudoinverse of the backconnections.", "startOffset": 9, "endOffset": 33}, {"referenceID": 1, "context": "Another variant of backprop is kickback, which loosens backprop\u2019s requirement that there are distinct forward- and backward signals (Balduzzi et al., 2015). Kickback truncates backprop\u2019s error signals so that the network learns from just the feedforward sweep together with scalar error signals. One of the main results of Balduzzi et al. (2015) is that kickback is safe, see section A5.", "startOffset": 133, "endOffset": 346}], "year": 2017, "abstractText": "As artificial agents proliferate, it is becoming increasingly important to ensure that their interactions with one another are well-behaved. In this paper, we formalize a common-sense notion of when algorithms are well-behaved: an algorithm is safe if it does no harm. Motivated by recent progress in deep learning, we focus on the specific case where agents update their actions according to gradient descent. The first result is that gradient descent converges to a Nash equilibrium in safe games. The paper provides sufficient conditions that guarantee safe interactions. The main contribution is to define strongly-typed agents and show they are guaranteed to interact safely. A series of examples show that strong-typing generalizes certain key features of convexity and is closely related to blind source separation. The analysis introduce a new perspective on classical multilinear games based on tensor decomposition.", "creator": "LaTeX with hyperref package"}}}