{"id": "1702.08400", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Feb-2017", "title": "Asymmetric Tri-training for Unsupervised Domain Adaptation", "abstract": "Deep-layered models trained on a large number of labeled samples boost the accuracy of many tasks. It is important to apply such models to different domains because collecting many labeled samples in various domains is expensive. In unsupervised domain adaptation, one needs to train a classifier that works well on a target domain when provided with labeled source samples and unlabeled target samples. Although many methods aim to match the distributions of source and target samples, simply matching the distribution cannot ensure accuracy on the target domain. To learn discriminative representations for the target domain, we assume that artificially labeling target samples can result in a good representation. Tri-training leverages three classifiers equally to give pseudo-labels to unlabeled samples, but the method does not assume labeling samples generated from a different domain.In this paper, we propose an asymmetric tri-training method for unsupervised domain adaptation, where we assign pseudo-labels to unlabeled samples and train neural networks as if they are true labels. In our work, we use three networks asymmetrically. By asymmetric, we mean that two networks are used to label unlabeled target samples and one network is trained by the samples to obtain target-discriminative representations. We evaluate our method on digit recognition and sentiment analysis datasets. Our proposed method achieves state-of-the-art performance on the benchmark digit recognition datasets of domain adaptation.", "histories": [["v1", "Mon, 27 Feb 2017 17:48:17 GMT  (1078kb)", "https://arxiv.org/abs/1702.08400v1", null], ["v2", "Thu, 16 Mar 2017 15:11:14 GMT  (1078kb)", "http://arxiv.org/abs/1702.08400v2", null], ["v3", "Sat, 13 May 2017 05:44:03 GMT  (1078kb)", "http://arxiv.org/abs/1702.08400v3", "TBA on ICML2017"]], "reviews": [], "SUBJECTS": "cs.CV cs.AI", "authors": ["kuniaki saito", "yoshitaka ushiku", "tatsuya harada"], "accepted": true, "id": "1702.08400"}, "pdf": {"name": "1702.08400.pdf", "metadata": {"source": "META", "title": "Asymmetric Tri-training for Unsupervised Domain Adaptation", "authors": ["Kuniaki Saito", "Yoshitaka Ushiku", "Tatsuya Harada"], "emails": ["<k-saito@mi.t.u-tokyo.ac.jp>,", "<ushiku@mi.t.u-tokyo.ac.jp>,", "<harada@mi.t.u-tokyo.ac.jp>."], "sections": [{"heading": null, "text": "ar Xiv: 170 2.08 400v 3 [cs.C V] May 13, 201 7of marked samples increase the accuracy of many tasks. It is important to apply such models to different areas, because collecting many marked samples in different areas is expensive. In unattended samples, it is necessary to train a classifier that works well on a target domain if it is provided with marked samples and unmarked samples. Although many methods aim to match the distributions of starting and target samples, simple distribution matching cannot guarantee accuracy on the target domain. To learn differentiating representations for the target domain, we assume that artificial labeling of target samples can lead to good representation. Tri-Training uses three classifiers equally to give unmarked samples pseudo-labels, but the method does not assume that the samples are generated from another domain. In this essay we will use a net-point trunmarked three-symmetric training method to achieve an unmarked training area."}, {"heading": "1. Introduction", "text": "It's about the question of whether it's about a way and a way, in which it's about a way and a way, in which it's about a way and a way, in which it's about a way and a way, in which it's about a way and a way, in which it's about a way and a way, in which it's about a way and a way, in which it's about a way and a way, in which it's about a way and a way and a way, in which it's about a way and a way, in which it's about a way and a way and a way, in which it's about a way and a way and a way and a way, in which it's about a way and a way and a way and a way it's about a way and a way and a way it's about a way and a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way and a way it's about a way and a way it's about a way and a way it's about a way and a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a way and a way it's about a way and a way it's about a way and a way it's about a way and a way it's about a way and a"}, {"heading": "2. Related Work", "text": "Since many methods have been proposed to address different tasks in domain adaptation, we present details of the research most closely related to our papers; a number of previous methods have attempted to realize the adaptation by applying the measurement of divergence between different domains (Ganin & Lempitsky, 2014; Long et al., 2015b; Li et al., 2016); the methods are based on the theory proposed in (Ben-David et al., 2010), which states that the expected loss for a target domain is limited by three terms: (i) expected losses for the source domain; (ii) domain divergence between source and target; and target; and (iii) the minimum value of an expected loss. The shared expectation means that the loss is limited to the source and target domain. As the third term, which is usually considered very low, cannot be evaluated when tagged target samples are retrieved, most attempt to minimize the first term and the second term."}, {"heading": "3. Method", "text": "In this section, we provide details of the proposed domain matching model. We aim to build a target-specific network using pseudo-marked target patterns. At the same time, we expect two labeling networks to obtain target discriminatory representations and gradually increase accuracy on the target domain. We show our proposed network structure in Fig. 2. F describes the network that outputs common features between three networks, F1 and F2 classify features generated from F. Their predictions are used to give pseudo-labels. The classifier Ft classifies features generated from F, which is a target-specific network. Here, F1, F2 learn from source and pseudo-marked target patterns, and Ft learns only from pseudo-marked target patterns. The common network F learns from all streams of F1, F2, Ft. Without such a common network, we can imagine this to be another option for the network architecture."}, {"heading": "3.1. Loss for Multiview Features Network", "text": "In the existing work (Chen et al., 2011) on co-training on domain fitting, pre-defined characteristics are divided into different parts and considered to be different points of view. As we aim to label target samples with high accuracy, we expect the samples to be classified on the basis of different points of view. Therefore, we place a limitation on the weight of F1, F2 in order to distinguish their inputs from each other. We add the term | W1TW2 | to the cost function, whereby W1, W2 denote fully connected layer weights of F1 and F2, which are applied initially to characteristic F (xi). Each network will learn from different characteristics with this limitation. The goal for learning F1, F2 is defined as E (successF, successF2) = 1nn \u2211 i = 1 [Ly (F1-F (xi)), yi) + Ly (F2), yi)."}, {"heading": "3.2. Learning Procedure and Labeling Method", "text": "The second requirement is that the YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy"}, {"heading": "3.3. Batch Normalization for Domain Adaptation", "text": "Batch Normalization (BN) (Ioffe & Szegedy, 2015), which lightens the output of the hidden layer in a CNN, is an effective technique to speed up the training speed and increase the accuracy of the model. Furthermore, lightening the output of the hidden layer is effective to improve performance, making the distribution of indifferent domains similar (Sun et al., 2016; Li et al., 2016).Input samples of F1, F2 include both pseudo-labeled target samples and source samples. Introduction of BN will be useful to balance the distribution and improve performance. We add the BN layer in the last shift in F."}, {"heading": "4. Analysis", "text": "In this section, we provide a theoretical analysis of our approach. First, we provide an insight into the existing theory, then we introduce a simple extension of the theory related to our methodology.In (Ben-David et al., 2010), an equation was introduced showing that the upper limit of the expected error in the target domain depends approximately on three terms, which include the divergence between different domains and the error of an ideal common hypothesis. Divergence between source and target domains, H distance, is defined as follows: dH (S, T) = 2 sup (h, h \"). Divergence between source and target domain, H distance, is defined as follows: dH distance is often used to measure adaptability between different domains.The ideal common hypothesis is defined as h hypothesis."}, {"heading": "5. Experiment and Evaluation", "text": "Visual Domain Adaptation For visual domain adaptation, we perform our evaluation on the digits datasets and traffic signs. Dials include MNIST (LeCun et al., 1998), MNIST-M (Ganin & Lempitsky, 2014), Street View House Numbers (Netzer et al., 2011), and Synthetic Digits (SYN DIGITS) (Ganin & Lempitsky, 2014). We evaluate our method on traffic sign data aspects (SYN SIGN SIGNS)."}, {"heading": "5.1. Implementation Detail", "text": "In experiments with image data sets, we use the architecture of CNN used in (Ganin & Lempitsky, 2014).To make a fair comparison, we separate the network from the hidden layer from which discrimination networks were constructed (Ganin & Lempitsky, 2014).Therefore, when we look at a classifier, for example formula F, the architecture is identical to previous work. We also follow (Ganin & Lempitsky, 2014) in the other protocols. We set the threshold for the labeling method in MNIST \u2192 SVHN to 0.95. In other scenarios, we set it to 0.9. We use MomentumSGD for optimization and set the dynamics to 0.9, while the learning rate is set to validation splits and either [0.01, 0.05] is used."}, {"heading": "5.2. Experimental Result", "text": "This year, as never before in the history of a country in which it is a country, in which it is a country, in which it is a country, in which it is not a country, in which it is not a country, but a country, in which it is a country, in which it is a country, in which it is not a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which is a country, in which it is a country, in which is a country, in which it is a country, in which is a country, in which is a country, in which is a country, in which it is a country, in which is a country, in which it is a country, in which it is a country, in which is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which it is a country, in which is a country, in which is a country, in which is a country, in which is a country"}, {"heading": "6. Conclusion", "text": "In this paper, we proposed a new asymmetric tri-training method for unattended domain matching that is easy to implement. The goal was to learn differentiated representations by using pseudo-labels assigned to blank target samples. We used three classifiers, two networks assigned pseudo-labels to blank target samples, and the remaining network learns from them. We evaluated our method in terms of both domain matching to a visual recognition task and mood analysis, outperforming other methods. Specifically, our method outperformed the other methods in the MNIST \u2192 SVHN matching task by more than 10%."}, {"heading": "7. Acknowledgement", "text": "This work was funded by the ImPACT programme of the Council for Science, Technology and Innovation (Cabinet Office, Government of Japan) and supported by CREST, JST."}], "references": [{"title": "Vqa: Visual question answering", "author": ["Antol", "Stanislaw", "Agrawal", "Aishwarya", "Lu", "Jiasen", "Mitchell", "Margaret", "Batra", "Dhruv", "C. Lawrence Zitnick", "Parikh", "Devi"], "venue": "In ICCV,", "citeRegEx": "Antol et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Antol et al\\.", "year": 2015}, {"title": "Contour detection and hierarchical image segmentation", "author": ["Arbelaez", "Pablo", "Maire", "Michael", "Fowlkes", "Charless", "Malik", "Jitendra"], "venue": null, "citeRegEx": "Arbelaez et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Arbelaez et al\\.", "year": 2011}, {"title": "Cotraining and expansion: Towards bridging theory and practice", "author": ["Balcan", "Maria-Florina", "Blum", "Avrim", "Yang", "Ke"], "venue": "In NIPS,", "citeRegEx": "Balcan et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Balcan et al\\.", "year": 2004}, {"title": "A theory of learning from different domains", "author": ["Ben-David", "Shai", "Blitzer", "John", "Crammer", "Koby", "Kulesza", "Alex", "Pereira", "Fernando", "Vaughan", "Jennifer Wortman"], "venue": "Machine learning,", "citeRegEx": "Ben.David et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ben.David et al\\.", "year": 2010}, {"title": "Domain adaptation with structural correspondence learning", "author": ["Blitzer", "John", "McDonald", "Ryan", "Pereira", "Fernando"], "venue": "In EMNLP,", "citeRegEx": "Blitzer et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Blitzer et al\\.", "year": 2006}, {"title": "Combining labeled and unlabeled data with co-training", "author": ["Blum", "Avrim", "Mitchell", "Tom"], "venue": "In COLT,", "citeRegEx": "Blum et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Blum et al\\.", "year": 1998}, {"title": "Domain separation networks", "author": ["Bousmalis", "Konstantinos", "Trigeorgis", "George", "Silberman", "Nathan", "Krishnan", "Dilip", "Erhan", "Dumitru"], "venue": "In NIPS,", "citeRegEx": "Bousmalis et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Bousmalis et al\\.", "year": 2016}, {"title": "Co-training for domain adaptation", "author": ["Chen", "Minmin", "Weinberger", "Kilian Q", "Blitzer", "John"], "venue": "In NIPS,", "citeRegEx": "Chen et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2011}, {"title": "Pac generalization bounds for co-training", "author": ["Dasgupta", "Sanjoy", "Littman", "Michael L", "McAllester", "David"], "venue": "In NIPS,", "citeRegEx": "Dasgupta et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Dasgupta et al\\.", "year": 2001}, {"title": "Imagenet: A large-scale hierarchical image database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-Jia", "Kai", "Fei-Fei"], "venue": "In CVPR,", "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi", "John", "Hazan", "Elad", "Singer", "Yoram"], "venue": "JMLR, 12(7):2121\u20132159,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "Unsupervised domain adaptation by backpropagation", "author": ["Ganin", "Yaroslav", "Lempitsky", "Victor"], "venue": "In ICML,", "citeRegEx": "Ganin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ganin et al\\.", "year": 2014}, {"title": "Deep reconstructionclassification networks for unsupervised domain adaptation", "author": ["Ghifary", "Muhammad", "Kleijn", "W Bastiaan", "Zhang", "Mengjie", "Balduzzi", "David", "Li", "Wen"], "venue": null, "citeRegEx": "Ghifary et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ghifary et al\\.", "year": 2016}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Girshick", "Ross", "Donahue", "Jeff", "Darrell", "Trevor", "Malik", "Jitendra"], "venue": "In CVPR,", "citeRegEx": "Girshick et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Girshick et al\\.", "year": 2014}, {"title": "A kernel two-sample test", "author": ["Gretton", "Arthur", "Borgwardt", "Karsten M", "Rasch", "Malte J", "Sch\u00f6lkopf", "Bernhard", "Smola", "Alexander"], "venue": "JMLR, 13(3):723\u2013773,", "citeRegEx": "Gretton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Gretton et al\\.", "year": 2012}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Ioffe", "Sergey", "Szegedy", "Christian"], "venue": null, "citeRegEx": "Ioffe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe et al\\.", "year": 2015}, {"title": "Coconut: Co-classification with output space regularization", "author": ["Khamis", "Sameh", "Lampert", "Christoph H"], "venue": "In BMVC,", "citeRegEx": "Khamis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Khamis et al\\.", "year": 2014}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": "In NIPS,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Gradient-based learning applied to document recognition", "author": ["LeCun", "Yann", "Bottou", "L\u00e9on", "Bengio", "Yoshua", "Haffner", "Patrick"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks", "author": ["Lee", "Dong-Hyun"], "venue": "In ICML workshop on Challenges in Representation Learning,", "citeRegEx": "Lee and Dong.Hyun.,? \\Q2013\\E", "shortCiteRegEx": "Lee and Dong.Hyun.", "year": 2013}, {"title": "Unsupervised improvement of visual detectors using co-training", "author": ["Levin", "Anat", "Viola", "Paul A", "Freund", "Yoav"], "venue": "In ICCV,", "citeRegEx": "Levin et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Levin et al\\.", "year": 2003}, {"title": "Revisiting batch normalization for practical domain adaptation", "author": ["Li", "Yanghao", "Wang", "Naiyan", "Shi", "Jianping", "Liu", "Jiaying", "Hou", "Xiaodi"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Long", "Jonathan", "Shelhamer", "Evan", "Darrell", "Trevor"], "venue": "In CVPR,", "citeRegEx": "Long et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "Learning transferable features with deep adaptation networks", "author": ["Long", "Mingsheng", "Cao", "Yue", "Wang", "Jianmin", "Jordan", "Michael I"], "venue": "In ICML,", "citeRegEx": "Long et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "Unsupervised domain adaptation with residual transfer networks", "author": ["Long", "Mingsheng", "Zhu", "Han", "Wang", "Jianmin", "Jordan", "Michael I"], "venue": "In NIPS,", "citeRegEx": "Long et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Long et al\\.", "year": 2016}, {"title": "The variational fair autoencoder", "author": ["Louizos", "Christos", "Swersky", "Kevin", "Li", "Yujia", "Welling", "Max", "Zemel", "Richard"], "venue": null, "citeRegEx": "Louizos et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Louizos et al\\.", "year": 2015}, {"title": "Visualizing data using t-sne", "author": ["Maaten", "Laurens van der", "Hinton", "Geoffrey"], "venue": "JMLR, 9(11):2579\u20132605,", "citeRegEx": "Maaten et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Maaten et al\\.", "year": 2008}, {"title": "Evaluation of traffic sign recognition methods trained on synthetically generated data", "author": ["Moiseev", "Boris", "Konev", "Artem", "Chigorin", "Alexander", "Konushin", "Anton"], "venue": "ACIVS,", "citeRegEx": "Moiseev et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Moiseev et al\\.", "year": 2013}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Netzer", "Yuval", "Wang", "Tao", "Coates", "Adam", "Bissacco", "Alessandro", "Wu", "Bo", "Ng", "Andrew Y"], "venue": "In NIPS workshop on deep learning and unsupervised feature learning,", "citeRegEx": "Netzer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Netzer et al\\.", "year": 2011}, {"title": "Transfer learning in a transductive setting", "author": ["Rohrbach", "Marcus", "Ebert", "Sandra", "Schiele", "Bernt"], "venue": "In NIPS,", "citeRegEx": "Rohrbach et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Rohrbach et al\\.", "year": 2013}, {"title": "Adapting visual category models to new domains", "author": ["Saenko", "Kate", "Kulis", "Brian", "Fritz", "Mario", "Darrell", "Trevor"], "venue": "In ECCV,", "citeRegEx": "Saenko et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Saenko et al\\.", "year": 2010}, {"title": "Learning transferrable representations for unsupervised domain adaptation", "author": ["Sener", "Ozan", "Song", "Hyun Oh", "Saxena", "Ashutosh", "Savarese", "Silvio"], "venue": "In NIPS,", "citeRegEx": "Sener et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sener et al\\.", "year": 2016}, {"title": "The german traffic sign recognition benchmark: a multi-class classification competition", "author": ["Stallkamp", "Johannes", "Schlipsing", "Marc", "Salmen", "Jan", "Igel", "Christian"], "venue": "In IJCNN,", "citeRegEx": "Stallkamp et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Stallkamp et al\\.", "year": 2011}, {"title": "Return of frustratingly easy domain adaptation", "author": ["Sun", "Baochen", "Feng", "Jiashi", "Saenko", "Kate"], "venue": "In AAAI,", "citeRegEx": "Sun et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sun et al\\.", "year": 2016}, {"title": "Ensemble based co-training", "author": ["Tanha", "Jafar", "van Someren", "Maarten", "Afsarmanesh", "Hamideh"], "venue": "BNAIC,", "citeRegEx": "Tanha et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Tanha et al\\.", "year": 2011}, {"title": "Show and tell: A neural image caption generator", "author": ["Vinyals", "Oriol", "Toshev", "Alexander", "Bengio", "Samy", "Erhan", "Dumitru"], "venue": "In CVPR,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Co-training for cross-lingual sentiment classification", "author": ["Wan", "Xiaojun"], "venue": "In ACL,", "citeRegEx": "Wan and Xiaojun.,? \\Q2009\\E", "shortCiteRegEx": "Wan and Xiaojun.", "year": 2009}, {"title": "Tri-training: Exploiting unlabeled data using three", "author": ["Zhou", "Zhi-Hua", "Li", "Ming"], "venue": "classifiers. TKDE,", "citeRegEx": "Zhou et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2005}, {"title": "Semi-supervised learning literature survey", "author": ["Zhu", "Xiaojin"], "venue": "Technical report,", "citeRegEx": "Zhu and Xiaojin.,? \\Q2005\\E", "shortCiteRegEx": "Zhu and Xiaojin.", "year": 2005}], "referenceMentions": [{"referenceID": 17, "context": "(Krizhevsky et al., 2012), the recognition abilities of images and languages have improved dramatically.", "startOffset": 0, "endOffset": 25}, {"referenceID": 13, "context": "For object detection or segmentation, we can transfer the knowledge of a CNN trained with a large-scale dataset by fine-tuning it on a relatively small dataset (Girshick et al., 2014; Long et al., 2015a).", "startOffset": 160, "endOffset": 203}, {"referenceID": 9, "context": "Moreover, features from a CNN trained on ImageNet (Deng et al., 2009) are useful for multimodal learning tasks including image captioning (Vinyals et al.", "startOffset": 50, "endOffset": 69}, {"referenceID": 35, "context": ", 2009) are useful for multimodal learning tasks including image captioning (Vinyals et al., 2015) and visual question answering (Antol et al.", "startOffset": 76, "endOffset": 98}, {"referenceID": 0, "context": ", 2015) and visual question answering (Antol et al., 2015).", "startOffset": 38, "endOffset": 58}, {"referenceID": 3, "context": "However, as shown in (Ben-David et al., 2010), theoretically, if a classifier that works well on both the source and the target domains does not exist, we cannot expect a discriminative classifier for the target domain.", "startOffset": 21, "endOffset": 45}, {"referenceID": 21, "context": "A number of previous methods attempted to realize adaptation by utilizing the measurement of divergence between different domains (Ganin & Lempitsky, 2014; Long et al., 2015b; Li et al., 2016).", "startOffset": 130, "endOffset": 192}, {"referenceID": 3, "context": "The methods are based on the theory proposed in (Ben-David et al., 2010), which states that the expected loss for a target domain is bounded by three terms: (i) expected loss for the source domain; (ii) domain divergence between source and target; and (iii) the minimum value of a shared expected loss.", "startOffset": 48, "endOffset": 72}, {"referenceID": 14, "context": "With regards to training deep architectures, the maximum mean discrepancy (MMD) or a loss of domain classifier network is utilized to measure the divergence corresponding to the second term (Gretton et al., 2012; Ganin & Lempitsky, 2014; Long et al., 2015b; 2016; Bousmalis et al., 2016).", "startOffset": 190, "endOffset": 287}, {"referenceID": 6, "context": "With regards to training deep architectures, the maximum mean discrepancy (MMD) or a loss of domain classifier network is utilized to measure the divergence corresponding to the second term (Gretton et al., 2012; Ganin & Lempitsky, 2014; Long et al., 2015b; 2016; Bousmalis et al., 2016).", "startOffset": 190, "endOffset": 287}, {"referenceID": 24, "context": "In (Long et al., 2016) the focus was on the point we have stated and a target-specific classifier was constructed using a residual network structure.", "startOffset": 3, "endOffset": 22}, {"referenceID": 29, "context": "Several transductive methods use similarity of features to provide labels for unlabeled samples (Rohrbach et al., 2013; Khamis & Lampert, 2014).", "startOffset": 96, "endOffset": 143}, {"referenceID": 31, "context": "For unsupervised domain adaptation, in (Sener et al., 2016), a method was proposed to learn labeling metrics by using the k-nearest neighbors between unlabeled target samples and labeled source samples.", "startOffset": 39, "endOffset": 59}, {"referenceID": 34, "context": "Co-training utilizes two classifiers, which have different views on one sample, to provide pseudo-labels (Blum & Mitchell, 1998; Tanha et al., 2011).", "startOffset": 105, "endOffset": 148}, {"referenceID": 2, "context": "The generalization ability of co-training is theoretically ensured (Balcan et al., 2004; Dasgupta et al., 2001) under some assumptions and applied to various tasks (Wan, 2009; Levin et al.", "startOffset": 67, "endOffset": 111}, {"referenceID": 8, "context": "The generalization ability of co-training is theoretically ensured (Balcan et al., 2004; Dasgupta et al., 2001) under some assumptions and applied to various tasks (Wan, 2009; Levin et al.", "startOffset": 67, "endOffset": 111}, {"referenceID": 20, "context": ", 2001) under some assumptions and applied to various tasks (Wan, 2009; Levin et al., 2003).", "startOffset": 60, "endOffset": 91}, {"referenceID": 7, "context": "In (Chen et al., 2011), the idea of co-training was incorporated into domain adaptation.", "startOffset": 3, "endOffset": 22}, {"referenceID": 7, "context": "In the existing works (Chen et al., 2011) on co-training for domain adaptation, given features are divided into separate parts and considered to be different views.", "startOffset": 22, "endOffset": 41}, {"referenceID": 33, "context": "In addition, in domain adaptation, whitening the hidden layer\u2019s output is effective for improving the performance, which make the distribution in different domains similar (Sun et al., 2016; Li et al., 2016).", "startOffset": 172, "endOffset": 207}, {"referenceID": 21, "context": "In addition, in domain adaptation, whitening the hidden layer\u2019s output is effective for improving the performance, which make the distribution in different domains similar (Sun et al., 2016; Li et al., 2016).", "startOffset": 172, "endOffset": 207}, {"referenceID": 3, "context": "In (Ben-David et al., 2010), an equation was introduced showing that the upper bound of the expected error in the target domain depends on three terms, which include the divergence between different domains and the error of an ideal joint hypothesis.", "startOffset": 3, "endOffset": 27}, {"referenceID": 3, "context": "(Ben-David et al., 2010) LetH be the hypothesis class.", "startOffset": 0, "endOffset": 24}, {"referenceID": 18, "context": "Digits datasets include MNIST (LeCun et al., 1998), MNIST-M (Ganin & Lempitsky, 2014), Street View House Numbers (SVHN) (Netzer et al.", "startOffset": 30, "endOffset": 50}, {"referenceID": 28, "context": ", 1998), MNIST-M (Ganin & Lempitsky, 2014), Street View House Numbers (SVHN) (Netzer et al., 2011), and Synthetic Digits (SYN DIGITS) (Ganin & Lempitsky, 2014).", "startOffset": 77, "endOffset": 98}, {"referenceID": 27, "context": "We further evaluate our method on traffic sign datasets including Synthetic Traffic Signs (SYN SIGNS) (Moiseev et al., 2013) and German Traffic Signs Recognition Benchmark (Stallkamp et al.", "startOffset": 102, "endOffset": 124}, {"referenceID": 32, "context": ", 2013) and German Traffic Signs Recognition Benchmark (Stallkamp et al., 2011) (GTSRB).", "startOffset": 55, "endOffset": 79}, {"referenceID": 30, "context": "We do not evaluate our method on Office (Saenko et al., 2010), which is the most commonly used dataset for visual domain adaptation.", "startOffset": 40, "endOffset": 61}, {"referenceID": 6, "context": "As pointed out by (Bousmalis et al., 2016), some labels in that dataset are noisy and some images contain other classes\u2019 objects.", "startOffset": 18, "endOffset": 42}, {"referenceID": 4, "context": "Adaptation in Amazon Reviews To investigate the behavior on language datasets, we also evaluated our method on the Amazon Reviews dataset (Blitzer et al., 2006) with the same preprocessing as used by (Chen et al.", "startOffset": 138, "endOffset": 160}, {"referenceID": 7, "context": ", 2006) with the same preprocessing as used by (Chen et al., 2011; Ganin et al., 2016).", "startOffset": 47, "endOffset": 86}, {"referenceID": 12, "context": ", 2015b), Domain Adversarial Neural Network (DANN) (Ganin & Lempitsky, 2014), Deep Reconstruction Classification Network (DRCN) (Ghifary et al., 2016), Domain Separation Networks (DSN) (Bousmalis et al.", "startOffset": 128, "endOffset": 150}, {"referenceID": 6, "context": ", 2016), Domain Separation Networks (DSN) (Bousmalis et al., 2016), and k-Nearest Neighbor based adaptation (kNN-Ad) (Sener et al.", "startOffset": 42, "endOffset": 66}, {"referenceID": 31, "context": ", 2016), and k-Nearest Neighbor based adaptation (kNN-Ad) (Sener et al., 2016).", "startOffset": 58, "endOffset": 78}, {"referenceID": 6, "context": "We cite the results of MMD from (Bousmalis et al., 2016).", "startOffset": 32, "endOffset": 56}, {"referenceID": 25, "context": "We compare our method with Variational Fair AutoEncoder (VFAE) (Louizos et al., 2015) and DANN (Ganin et al.", "startOffset": 63, "endOffset": 85}, {"referenceID": 10, "context": "Since the input is sparse, we use Adagrad (Duchi et al., 2011) for optimization.", "startOffset": 42, "endOffset": 62}, {"referenceID": 12, "context": "7 DRCN (Ghifary et al., 2016) 82.", "startOffset": 7, "endOffset": 29}, {"referenceID": 6, "context": "1 DSN (Bousmalis et al., 2016) 83.", "startOffset": 6, "endOffset": 30}, {"referenceID": 31, "context": "1 kNN-Ad (Sener et al., 2016) 86.", "startOffset": 9, "endOffset": 29}, {"referenceID": 6, "context": "In source only results, we show the results reported in (Bousmalis et al., 2016) and (Ghifary et al.", "startOffset": 56, "endOffset": 80}, {"referenceID": 12, "context": ", 2016) and (Ghifary et al., 2016) in parentheses.", "startOffset": 12, "endOffset": 34}, {"referenceID": 1, "context": "MNIST-M is composed by merging the clip of the background from BSDS500 datasets (Arbelaez et al., 2011).", "startOffset": 80, "endOffset": 103}, {"referenceID": 28, "context": "We evaluate adaptation between SVHN (Netzer et al., 2011) and MNIST in a ten-class classification problem.", "startOffset": 36, "endOffset": 57}, {"referenceID": 32, "context": "We use the SYN SIGNS dataset (Ganin & Lempitsky, 2014) for the source dataset and the GTSRB dataset (Stallkamp et al., 2011) for the target dataset, which consist of real traffic sign images.", "startOffset": 100, "endOffset": 124}, {"referenceID": 3, "context": "A-distance From the theoretical results in (Ben-David et al., 2010), A-distance is usually used as a measure of domain discrepancy.", "startOffset": 43, "endOffset": 67}, {"referenceID": 25, "context": "The accuracy (%) of the proposed method is shown with the result of VFAE (Louizos et al., 2015) and DANN (Ganin et al.", "startOffset": 73, "endOffset": 95}, {"referenceID": 25, "context": "From the results in Table 3, our method performs better than VFAE (Louizos et al., 2015) and DANN (Ganin et al.", "startOffset": 66, "endOffset": 88}], "year": 2017, "abstractText": "Deep-layered models trained on a large number of labeled samples boost the accuracy of many tasks. It is important to apply such models to different domains because collecting many labeled samples in various domains is expensive. In unsupervised domain adaptation, one needs to train a classifier that works well on a target domain when provided with labeled source samples and unlabeled target samples. Although many methods aim to match the distributions of source and target samples, simply matching the distribution cannot ensure accuracy on the target domain. To learn discriminative representations for the target domain, we assume that artificially labeling target samples can result in a good representation. Tri-training leverages three classifiers equally to give pseudo-labels to unlabeled samples, but the method does not assume labeling samples generated from a different domain. In this paper, we propose an asymmetric tri-training method for unsupervised domain adaptation, where we assign pseudo-labels to unlabeled samples and train neural networks as if they are true labels. In our work, we use three networks asymmetrically. By asymmetric, we mean that two networks are used to label unlabeled target samples and one network is trained by the samples to obtain targetdiscriminative representations. We evaluate our method on digit recognition and sentiment analysis datasets. Our proposed method achieves state-of-the-art performance on the benchmark digit recognition datasets of domain adaptation.", "creator": "LaTeX with hyperref package"}}}