{"id": "1703.00356", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-Mar-2017", "title": "Graph-based Isometry Invariant Representation Learning", "abstract": "Learning transformation invariant representations of visual data is an important problem in computer vision. Deep convolutional networks have demonstrated remarkable results for image and video classification tasks. However, they have achieved only limited success in the classification of images that undergo geometric transformations. In this work we present a novel Transformation Invariant Graph-based Network (TIGraNet), which learns graph-based features that are inherently invariant to isometric transformations such as rotation and translation of input images. In particular, images are represented as signals on graphs, which permits to replace classical convolution and pooling layers in deep networks with graph spectral convolution and dynamic graph pooling layers that together contribute to invariance to isometric transformations. Our experiments show high performance on rotated and translated images from the test set compared to classical architectures that are very sensitive to transformations in the data. The inherent invariance properties of our framework provide key advantages, such as increased resiliency to data variability and sustained performance with limited training sets.", "histories": [["v1", "Wed, 1 Mar 2017 15:51:13 GMT  (3851kb,D)", "http://arxiv.org/abs/1703.00356v1", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["renata khasanova", "pascal frossard"], "accepted": true, "id": "1703.00356"}, "pdf": {"name": "1703.00356.pdf", "metadata": {"source": "META", "title": "Graph-based Isometry Invariant Representation Learning", "authors": ["Renata Khasanova", "Pascal Frossard"], "emails": ["RENATA.KHASANOVA@EPFL.CH", "PASCAL.FROSSARD@EPFL.CH", "nata.khasanova@epfl.ch>."], "sections": [{"heading": "1. Introduction", "text": "This year is the highest in the history of the country."}, {"heading": "2. Related work", "text": "Most of the recent architectures (LeCun et al., 2001; Krizhevsky et al., 2012) have been very successful in processing natural images, but not necessarily in properly handling geometric transformations in the data. Below we describe some of the recent attempts to construct transformation-invariant architectures."}, {"heading": "2.1. Transformation-invariant deep learning", "text": "In fact, it is such that most of them will be able to move into another world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they live."}, {"heading": "2.2. Deep learning and graph signal processing", "text": "While there is a great deal of research into the application of deep learning methods to traditional data such as 1-D speech signals or 2-D images, researchers have only recently begun to consider analyzing network or graph data with such architectures (Kipf & Welling, 2016; Henaff et al., 2015; Duvenaud et al., 2015). Working in (Bruna et al., 2014) is one of the pioneering efforts to bridge the gap between graph-based learning and deep learning methods, the authors calculate the projection of graph signals onto the space defined by the characteristics of the laplac matrix, which itself describes the geometry of the data."}, {"heading": "3. Graph signal processing elements", "text": "We represent an input image as a signal y (vn) on the nodal points (i.e., the picture graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph graph"}, {"heading": "4. Graph-based convolutional network", "text": "We now present the overview of our new architecture shown in Figure 2. Input into our system can be characterized by a normalized laplac matrix L, calculated on the grid diagram G. The signal y0 = (y0 (v1),..., y0 (vN), where y0 (vj) is the intensity of the pixel j in the input image and N is the number of pixels in the images. Finally, our network provides a class name for each input signal. In detail, our deep learning architecture consists of an alternation of spectral folding layers F l and dynamic compaction layers P. It is followed by a statistical layerH and a sequence of fully connected layers (FC) preceding a Softmax operator (SM) that generates a categorical distribution over labels to classify the input data. Both the spectral folding and the dynamic compaction of the layers contained in the graphical layer, are classified by the F and specified by the F layer."}, {"heading": "4.1. Spectral convolutional layer", "text": "In the eeisn eeisrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrln rf\u00fc ide eeisrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrso \"rrrrrrrrso\" rrrrrrrrrrrrso \"rrrrrrrrrrso\" rrrrrrrrrrrrso \"rrrrrrrrrrrrrrrso\" rrrrrrrrrrrrrrso \"rrrrrrrrrrrrrrrrrrrso\" rrrrrrrrrrrrrrrrso \"rrrrrrrrrrrrrrrrrrcso\" rrrrrrrrrrrrrrrrrrcso \"rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrcso\" cso \"rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrcso\" cso \"cso\" rrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "4.2. Dynamic pooling layer", "text": "In the classic ConvNets, the goal of the pooling layers is to summarize the outputs of the filters for each level of networking. (n) \"We only have the most important characteristics at each level of networking.\" (n) \"We have a dynamic pooling layer, which we call the dynamic pooling layer.\" (n) \"We only have the most important characteristics at each level of networking.\" (n) \"We then have a dynamic pooling layer, which is essentially of the series of graph vertices ofinterest l, which encompass all the nodes of the graph.\" (n) \"It is then successively realized along the multiple layers of the network.\" (n) \"We select the Jl values that are part of the graph.\" (n) \"We have the highest values in zli. (n) The indexes of these largest values of the nodesN layers form a series of nodes\" (n)."}, {"heading": "4.3. Upper layers", "text": "After the series of alternating spectral convolutions and dynamic pooling layers, we will add the initial layers that compute the label probability distributions for the input images (see Fig. 2). Instead of directly connecting a fully connected layer as in classic ConvNet architectures, we will first insert a new statistical layer, the output of which will then be fed into fully connected layers (see Fig. 2). The main motivation for the statistical layer is our goal to design a transformation-invariant classification architecture. If fully connected layers are added directly on top of the last dynamic pooling layers, their neurons would need to store large amounts of information corresponding to the different positions and rotations of the visual objects. Instead, we propose to insert a new statistical layer that compiles transformation-invariant statistics of the input signal distributions. In more detail, the statistical layer estimates the values of the active layer after the last nodes."}, {"heading": "4.4. Training", "text": "We use supervised learning and train our network so that it maximizes the log probability of estimating the correct class of training samples via logistic regression. Overall, we need to calculate the values of parameters in each revolutionary and fully connected layer. However, the other layers have no estimated parameters. We train the network using a classic back-propagation algorithm and learn the parameters using ADAM stochastic optimization (Kingma & Ba, 2014).We provide more details here about the calculation specific to our new architecture. We refer the reader (Rumelhart et al., 1988) for more details on the entire training process. Back propagation in the spectral convolution layer is determined by evaluating the partial derivatives relative to the parameters we are trained on."}, {"heading": "5. Experiments", "text": "In this section, we analyze the results and compare our network with modern transformation invariant classification algorithms. First, we describe the experimental settings, then we analyze our architecture and the influence of the various design parameters. Finally, we compare our network with modern transformation invariant classification algorithms."}, {"heading": "5.1. Experimental settings", "text": "The initialization of the system may have a certain influence on the actual values of the parameters selected after the training. We have decided to initialize the parameters \u03b1li, m (Eq. 8) of our spectral convolution filters, so that the various filters uniformly cover the complete spectral behavior. We initially developed a series of overlapping rectangular functions that cover the entire spectrum of normalized images. (D) D \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"(Eq\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i"}, {"heading": "5.2. TIGraNet Analysis", "text": "We analyze the performance of our new architecture on the MNIST-012 dataset. We first give some examples of features produced by our network. We then illustrate the spectral nuclei learned from our system and discuss the influence of dynamic pooling operators. We confirm the transformation of immutable properties of our architecture. We illustrate this in the form of images without any transformations, it is able to correctly classify rotating images in the test set, since our spectral layer is filters characterized by isometric transformations. We illustrate this in the form of Fig. 5, which shows several examples of features rotating in the second layer."}, {"heading": "5.3. Performance evaluation", "text": "This year it is more than ever before."}, {"heading": "6. Conclusion", "text": "In this paper, we present a new transformational invariant classification architecture that combines the power of graph-based isometry invariant representation learning. Misclassified images are identified by red delimitation fields (best in color), deep networks and graph signal processing, enabling filters to be developed that are equivalent to translation and rotation. A novel statistical layer makes our entire network additionally invariant to isometric translations, enabling advanced algorithms to outperform various illustrative benchmarks. Our new method is able to correctly classify rotated and translated images even when such transformed images do not appear in the training set, confirming its high potential in practical environments where training sets are limited but high data variability is expected."}, {"heading": "7. Acknowledgment", "text": "The authors thank Dr. Dorina Thanou, Damian Foucard and Dr. Andreas Loukas for comments that help improve the work, and we thank NVIDIA Corporation for their support by donating the Tesla K40 GPU used for this research."}], "references": [{"title": "Pattern Recognition and Machine Learning", "author": ["C.M. Bishop"], "venue": null, "citeRegEx": "Bishop,? \\Q2006\\E", "shortCiteRegEx": "Bishop", "year": 2006}, {"title": "A Theoretical Analysis of Feature Pooling in Visual Recognition", "author": ["Y.L. Boureau", "J. Ponce", "Y. LeCun"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Boureau et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Boureau et al\\.", "year": 2010}, {"title": "Invariant scattering convolution networks", "author": ["J. Bruna", "S. Mallat"], "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,", "citeRegEx": "Bruna and Mallat,? \\Q2013\\E", "shortCiteRegEx": "Bruna and Mallat", "year": 2013}, {"title": "Spectral Networks and Locally Connected Networks on Graphs", "author": ["J. Bruna", "W. Zaremba", "A. Szlam", "Y. LeCun"], "venue": "In International Conference for Learning Representations,", "citeRegEx": "Bruna et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bruna et al\\.", "year": 2014}, {"title": "Group equivariant convolutional networks", "author": ["T.S. Cohen", "M. Welling"], "venue": "arXiv preprint,", "citeRegEx": "Cohen and Welling,? \\Q2016\\E", "shortCiteRegEx": "Cohen and Welling", "year": 2016}, {"title": "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering", "author": ["M. Defferrard", "X. Bresson", "P. Vandergheynst"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Defferrard et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Defferrard et al\\.", "year": 2016}, {"title": "Rotationinvariant convolutional neural networks for galaxy morphology prediction", "author": ["S. Dieleman", "K.W. Willett", "J. Dambre"], "venue": "Monthly notices of the royal astronomical society,", "citeRegEx": "Dieleman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dieleman et al\\.", "year": 2015}, {"title": "Exploiting cyclic symmetry in convolutional neural networks", "author": ["S. Dieleman", "J.D. Fauw", "K. Kavukcuoglu"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "Dieleman et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dieleman et al\\.", "year": 2016}, {"title": "Convolutional networks on graphs for learning molecular fingerprints", "author": ["P. R"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "R.,? \\Q2015\\E", "shortCiteRegEx": "R.", "year": 2015}, {"title": "The art of data augmentation", "author": ["D.A. Dyk", "Meng", "X.-L"], "venue": "Journal of Computational and Graphical Statistics,", "citeRegEx": "Dyk et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Dyk et al\\.", "year": 2012}, {"title": "Rotation-invariant neoperceptron", "author": ["B. Fasel", "D. Gatica-Perez"], "venue": "In International Conference on Pattern Recognition,", "citeRegEx": "Fasel and Gatica.Perez,? \\Q2006\\E", "shortCiteRegEx": "Fasel and Gatica.Perez", "year": 2006}, {"title": "Deep convolutional networks on graph-structured data", "author": ["M. Henaff", "J. Bruna", "Y. LeCun"], "venue": "arXiv preprint,", "citeRegEx": "Henaff et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Henaff et al\\.", "year": 2015}, {"title": "A Convolutional Neural Network for Modelling Sentences", "author": ["N. Kalchbrenner", "E. Grefenstette", "P. Blunsom"], "venue": "arXiv Preprint,", "citeRegEx": "Kalchbrenner et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv Preprint,", "citeRegEx": "Kingma and Ba,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2014}, {"title": "Semi-supervised classification with graph convolutional networks", "author": ["T.N. Kipf", "M. Welling"], "venue": "arXiv preprint,", "citeRegEx": "Kipf and Welling,? \\Q2016\\E", "shortCiteRegEx": "Kipf and Welling", "year": 2016}, {"title": "The Art of Computer Programming: Sorting and Searching", "author": ["D.E. Knuth"], "venue": null, "citeRegEx": "Knuth,? \\Q1998\\E", "shortCiteRegEx": "Knuth", "year": 1998}, {"title": "ImageNet Classification with Deep Convolutional Neural Networks", "author": ["A. Krizhevsky", "I. Sutskever", "E.H. Geoffrey"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "TI-Pooling: Transformation-Invariant Pooling for Feature Learning in Convolutional Neural Networks", "author": ["D. Laptev", "N. Savinov", "J.M. Buhmann", "M. Pollefeys"], "venue": "In Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Laptev et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Laptev et al\\.", "year": 2016}, {"title": "GradientBased Learning Applied to Document Recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "In Intelligent Signal Processing,", "citeRegEx": "LeCun et al\\.,? \\Q2001\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2001}, {"title": "Analyzing appearance and contour based methods for object categorization", "author": ["B. Leibe", "B. Schiele"], "venue": "In Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Leibe and Schiele,? \\Q2003\\E", "shortCiteRegEx": "Leibe and Schiele", "year": 2003}, {"title": "Learning rotation invariant convolutional filters for texture classification", "author": ["D. Marcos", "M. Volpi", "D. Tuia"], "venue": "arXiv preprint,", "citeRegEx": "Marcos et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Marcos et al\\.", "year": 2016}, {"title": "Geodesic Convolutional Neural Networks on Riemannian Manifolds", "author": ["J. Masci", "D. Boscaini", "M.M. Bronstein", "P. Vandergheynst"], "venue": "In International Conference on Computer Vision Workshops,", "citeRegEx": "Masci et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Masci et al\\.", "year": 2015}, {"title": "Deep roto-translation scattering for object classification", "author": ["E. Oyallon", "S. Mallat"], "venue": "In Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "Oyallon and Mallat,? \\Q2015\\E", "shortCiteRegEx": "Oyallon and Mallat", "year": 2015}, {"title": "Deepwalk: Online learning of social representations", "author": ["B. Perozzi", "R. Al-Rfou", "S. Skiena"], "venue": "In International Conference on Knowledge Discovery and Data Mining,", "citeRegEx": "Perozzi et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Perozzi et al\\.", "year": 2014}, {"title": "U-net: Convolutional networks for biomedical image segmentation", "author": ["O. Ronneberger", "P. Fischer", "T. Brox"], "venue": "In Medical Image Computing and Computer-Assisted Intervention,", "citeRegEx": "Ronneberger et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ronneberger et al\\.", "year": 2015}, {"title": "Learning representations by back-propagating errors", "author": ["D.E. Rumelhart", "G.E. Hinton", "R.J. Williams"], "venue": "Cognitive modeling,", "citeRegEx": "Rumelhart et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1988}, {"title": "Chebyshev polynomial approximation for distributed signal processing", "author": ["D.I. Shuman", "P. Vandergheynst", "P. Frossard"], "venue": "In IEEE International Conference on Distributed Computing in Sensor Systems,", "citeRegEx": "Shuman et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Shuman et al\\.", "year": 2011}, {"title": "The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains", "author": ["D.I. Shuman", "S.K. Narang", "P. Frossard", "A. Ortega", "P. Vandergheynst"], "venue": "IEEE Signal Processing Magazine,", "citeRegEx": "Shuman et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Shuman et al\\.", "year": 2013}, {"title": "Learning parametric dictionaries for signals on graphs", "author": ["D. Thanou", "D.I. Shuman", "P. Frossard"], "venue": "IEEE Transactions on Signal Processing,", "citeRegEx": "Thanou et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Thanou et al\\.", "year": 2014}, {"title": "Harmonic networks: Deep translation and rotation equivariance", "author": ["D.E. Worrall", "S.J. Garbin", "D. Turmukhambetov", "G.J. Brostow"], "venue": "arXiv Preprint,", "citeRegEx": "Worrall et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Worrall et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 16, "context": "Deep convolutional networks (ConvNets) have achieved impressive results for various computer vision tasks, such as image classification (Krizhevsky et al., 2012) and segmentation (Ronneberger et al.", "startOffset": 136, "endOffset": 161}, {"referenceID": 24, "context": ", 2012) and segmentation (Ronneberger et al., 2015).", "startOffset": 25, "endOffset": 51}, {"referenceID": 1, "context": "Rotated test images, along with their classification label obtained from ConvNets (Conv) (Boureau et al., 2010), Spatial-Transformer Network (STN) (Jaderberg et al.", "startOffset": 89, "endOffset": 111}, {"referenceID": 18, "context": "Most of the recent architectures (LeCun et al., 2001; Krizhevsky et al., 2012) have been very successful in processing natural images, but not necessarily in properly handling geometric transformations in the data.", "startOffset": 33, "endOffset": 78}, {"referenceID": 16, "context": "Most of the recent architectures (LeCun et al., 2001; Krizhevsky et al., 2012) have been very successful in processing natural images, but not necessarily in properly handling geometric transformations in the data.", "startOffset": 33, "endOffset": 78}, {"referenceID": 17, "context": "Then, the authors in (Laptev et al., 2016) extend this multi-column deep neural networks with averaging the output of all the columns to provide the final classification label.", "startOffset": 21, "endOffset": 42}, {"referenceID": 20, "context": "Then, the work in (Marcos et al., 2016) suggests using rotated filter banks and a special max pooling operation to combine their outcomes and improve invariance to transformations.", "startOffset": 18, "endOffset": 39}, {"referenceID": 6, "context": "Finally, the authors in (Dieleman et al., 2015) exploit rotation symmetry in the Convolutional Network for the specific problem of galaxy morphology prediction.", "startOffset": 24, "endOffset": 47}, {"referenceID": 7, "context": "This work has been extended in (Dieleman et al., 2016) which introduces an additional layer that makes the network to be partially invariant to rotations.", "startOffset": 31, "endOffset": 54}, {"referenceID": 29, "context": "The methods in (Oyallon & Mallat, 2015; Bruna & Mallat, 2013; Worrall et al., 2016) are the closest in spirit to ours.", "startOffset": 15, "endOffset": 83}, {"referenceID": 29, "context": "Finally, a very recent work (Worrall et al., 2016) proposes a so called Harmonic Network, which uses specifically designed complex valued filters to make feature representations equivariant to rotations.", "startOffset": 28, "endOffset": 50}, {"referenceID": 11, "context": "While there has been a lot of research efforts related to the application of deep learning methods to traditional data like 1-D speech signals or 2-D images, it is only recently that researchers have started to consider the analysis of network or graph data with such architectures (Kipf & Welling, 2016; Henaff et al., 2015; Duvenaud et al., 2015; Jain et al., 2015).", "startOffset": 282, "endOffset": 367}, {"referenceID": 3, "context": "The work in (Bruna et al., 2014) has been among the pioneering efforts in trying to bridge the gap between graph-based learning and deep learning methods.", "startOffset": 12, "endOffset": 32}, {"referenceID": 5, "context": "The authors in (Defferrard et al., 2016) later propose an alternative to analyse network data, which is built on a vertex domain feature representation and on fast spectral convolutional filters.", "startOffset": 15, "endOffset": 40}, {"referenceID": 21, "context": "For example, the authors in (Masci et al., 2015) generalize the ConvNets paradigm to the extraction of feature descriptors for 3D shapes that are defined on different graphs.", "startOffset": 28, "endOffset": 48}, {"referenceID": 23, "context": "In (Perozzi et al., 2014), the authors introduce deep networks to analyze web-scale graphs using random walks, which can be used for social network classification tasks.", "startOffset": 3, "endOffset": 25}, {"referenceID": 27, "context": "Similarly to regular 1-D or 2-D signals, the graph signals can be efficiently analysed via harmonic analysis and processed in the spectral domain (Shuman et al., 2013).", "startOffset": 146, "endOffset": 167}, {"referenceID": 28, "context": "Finally, we can define the generalized translation operator Tvn for a graph signal y as the convolution of y with a delta function \u03b4vn centered at vertex vn (Thanou et al., 2014):", "startOffset": 157, "endOffset": 178}, {"referenceID": 27, "context": "More details about the above graph signal processing operators can be found in (Shuman et al., 2013).", "startOffset": 79, "endOffset": 100}, {"referenceID": 28, "context": "(3), we choose to design our graph filters as smooth polynomial filters of order M (Thanou et al., 2014), which can be written as", "startOffset": 83, "endOffset": 104}, {"referenceID": 28, "context": "Each column of this N \u00d7 N operator corresponds to an instance of the graph filter centered at a different vertex of the graph (Thanou et al., 2014).", "startOffset": 126, "endOffset": 147}, {"referenceID": 12, "context": "Inspired by (Kalchbrenner et al., 2014) we introduce a novel layer that we refer to as dynamic pooling layer, which basically consists in preserving only the most important features at each level of the network.", "startOffset": 12, "endOffset": 39}, {"referenceID": 15, "context": "Using the selection algorithm (Knuth, 1998) we can reach the average computational complexity of O(N).", "startOffset": 30, "endOffset": 43}, {"referenceID": 26, "context": "These polynomials have the advantage of a fast computation due to their iterative construction, and they can be adapted to distributed implementations (Shuman et al., 2011).", "startOffset": 151, "endOffset": 172}, {"referenceID": 5, "context": "As suggested in (Defferrard et al., 2016), for each input feature map z\u0303i we iteratively construct a set of signals ti,k using graph Chebyshev polynomials of order k, with k \u2264 Kmax, as", "startOffset": 16, "endOffset": 41}, {"referenceID": 0, "context": "The output of the fully-connected layers is then fed to a softmax layer (Bishop, 2006), which finally returns the probability distribution of a given input sample to belong to a given set of classes.", "startOffset": 72, "endOffset": 86}, {"referenceID": 25, "context": "We refer the reader to (Rumelhart et al., 1988) for more details about the over-", "startOffset": 23, "endOffset": 47}, {"referenceID": 26, "context": "where \u2202ti,k/\u2202z\u0303i are simply the derivatives of Chebyshev polynomials (Shuman et al., 2011) with maximum order Kmax.", "startOffset": 69, "endOffset": 90}, {"referenceID": 25, "context": "Finally, the parameters of the fully-connected layers are trained in a classical way, similarly to the training of fully-connected layers in ConvNet architectures (Rumelhart et al., 1988).", "startOffset": 163, "endOffset": 187}, {"referenceID": 1, "context": "Experiments on MNIST-012 ConvNet (Boureau et al., 2010) C[3]-P[2]-C[6]-P[2]-FC[50]-FC[30]-FC[10] STN (Jaderberg et al.", "startOffset": 33, "endOffset": 55}, {"referenceID": 1, "context": "Other experiments ConvNet (Boureau et al., 2010) C[10]-P[2]-C[20]-P[2]-FC[500]-FC[300]-FC[100] STN (Jaderberg et al.", "startOffset": 26, "endOffset": 48}, {"referenceID": 29, "context": ", 2015) C[10]-ST[6]-C[20]-ST[6]-FC[500]-FC[300]-FC[100] DeepScat (Oyallon & Mallat, 2015) W[2, 5]-PCA[20] HarmNet (Worrall et al., 2016) HRC[1, 10]-HCN[10]-HRC[10, 10]-HRC[10, 20]-HCN[20]-HRC[20, 20] TIGraNet SC[10, 4]-DP[600]-SC[20, 4]-DP[300]-S[12]-FC[500]-FC[300]-FC[100]", "startOffset": 114, "endOffset": 136}, {"referenceID": 1, "context": ", ConvNet (Boureau et al., 2010), Spatial Transformer Network (STN) (Jaderberg et al.", "startOffset": 10, "endOffset": 32}, {"referenceID": 29, "context": ", 2015), Deep Scattering (DeepScat) (Oyallon & Mallat, 2015) and Harmonic Networks (HarmNet) (Worrall et al., 2016).", "startOffset": 93, "endOffset": 115}, {"referenceID": 1, "context": "1 ConvNet (Boureau et al., 2010) 80.", "startOffset": 10, "endOffset": 32}, {"referenceID": 29, "context": "3 HarmNet (Worrall et al., 2016) 94.", "startOffset": 10, "endOffset": 32}], "year": 2017, "abstractText": "Learning transformation invariant representations of visual data is an important problem in computer vision. Deep convolutional networks have demonstrated remarkable results for image and video classification tasks. However, they have achieved only limited success in the classification of images that undergo geometric transformations. In this work we present a novel Transformation Invariant Graph-based Network (TIGraNet), which learns graph-based features that are inherently invariant to isometric transformations such as rotation and translation of input images. In particular, images are represented as signals on graphs, which permits to replace classical convolution and pooling layers in deep networks with graph spectral convolution and dynamic graph pooling layers that together contribute to invariance to isometric transformations. Our experiments show high performance on rotated and translated images from the test set compared to classical architectures that are very sensitive to transformations in the data. The inherent invariance properties of our framework provide key advantages, such as increased resiliency to data variability and sustained performance with limited training sets.", "creator": "LaTeX with hyperref package"}}}