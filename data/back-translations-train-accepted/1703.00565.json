{"id": "1703.00565", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ", "abstract": "Scattertext is an open source tool for visualizing linguistic variation between document categories in a language-independent way. The tool presents a scatterplot, where each axis corresponds to the rank-frequency a term occurs in a category of documents. Through a tie-breaking strategy, the tool is able to display thousands of visible term-representing points and find space to legibly label hundreds of them. Scattertext also lends itself to a query-based visualization of how the use of terms with similar embeddings differs between document categories, as well as a visualization for comparing the importance scores of bag-of-words features to univariate metrics.", "histories": [["v1", "Thu, 2 Mar 2017 00:48:15 GMT  (1627kb,D)", "http://arxiv.org/abs/1703.00565v1", "6 pages, 5 figures. Seethis https URLfor source code and documentation"], ["v2", "Mon, 6 Mar 2017 19:15:04 GMT  (3923kb,D)", "http://arxiv.org/abs/1703.00565v2", "6 pages, 5 figures. See this Githup repothis https URLfor source code and documentation"], ["v3", "Thu, 20 Apr 2017 21:39:34 GMT  (3924kb,D)", "http://arxiv.org/abs/1703.00565v3", "ACL 2017 Demos. 6 pages, 5 figures. See the Githup repothis https URLfor source code and documentation"]], "COMMENTS": "6 pages, 5 figures. Seethis https URLfor source code and documentation", "reviews": [], "SUBJECTS": "cs.CL cs.IR", "authors": ["jason s kessler"], "accepted": true, "id": "1703.00565"}, "pdf": {"name": "1703.00565.pdf", "metadata": {"source": "CRF", "title": "Scattertext: a Browser-Based Tool for Visualizing how Corpora Differ", "authors": ["Jason S. Kessler"], "emails": ["jason.kessler@gmail.com"], "sections": [{"heading": "1 Introduction", "text": "As a matter of fact, most people are able to go in search of a new way, which leads them to another world: to the USA, to Europe, to Turkey, to Europe, to Europe, to Europe, to Europe, to Europe, to the USA, to the USA, to Europe, to Europe, to the USA, to Europe, to Europe, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to Europe, to Europe, to the USA, to Europe, to Europe, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to Europe, to Turkey, to the USA, to the USA, to Turkey, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to Europe, to the USA, to Europe, to the USA, to Europe, to Europe, to Europe, to Europe, to Europe, to the USA, to Europe, to the USA, to Europe, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to the USA, to"}, {"heading": "2 On text visualization", "text": "The simplest visualization, a list of words sorted by their results, is easy to produce, interpret, and is therefore very common in literature. There are numerous ways to produce word ratings for ranking, which are thoroughly covered in previous work. Readers turn to Monroe et al. (2008) (hereinafter referred to as MCQ) to get an overview of model-based term rating algorithms. It is also interesting that Bitvai and Cohn (2015) present a method to find sparse words and phrase ratings from a trained ANN (with bag and word characteristics) and its training data. Regardless of how complex the calculation is, word ratings capture a number of different metrics for word associations that can be viewed independently, rather than as part of a unified assessment. These loosely logical metrics include: precision The discriminating power of a word regardless of its frequency. A term that appears once corrected will have a perfect correctification in the prefix."}, {"heading": "3 Past work and design motivation", "text": "It is difficult to compare the two most intense terms. (2013), two literal terms, each appearing in a category of texts, are each compared in a different category of texts. (2013), two literal terms, each appearing in a different category of texts, are determined by their linear regression coefficients (a composite metric of precision, recollection and redundancy) and by the frequency of their use. (2014), which also describe a word cloud for discriminatory terms, but for categories that are both small subsets of much greater interest. (They include a third, medium cloud for terms that appear characteristic.) It is difficult to compare the two terms."}, {"heading": "4 Scattertext", "text": "In practice, the parameters may be different in other areas of the world. (...) It may be that we leave the number of documents we use in practice the same. (...) It may be that the number of documents we have seen in the past is the same. (...) It may be that the number of documents we have seen in the past is the same. (...) It may not be that the number of documents we have seen in the past is the same. (...) It may be that the number of documents we have seen in the past is the same. (...) Let us reduce the number of documents we have seen in the past. (...) Let us be the jth word in the past. (...) In practice, it may be. (...) The parameter may be. (...) Other representations. (...) We can. (...)"}, {"heading": "5 Topical category discriminators", "text": "In 2012, how did Republicans and Democrats use the language regarding \"jobs,\" \"health care\" or \"military\" to create jobs that create jobs overseas. \"In 2012, how did Republicans and Democrats create the most jobs overseas that create jobs in companies that created jobs overseas? Figure 5 shows how prosperous overseas companies are, like\" jobs \"that resemble\" jobs \"that are characteristic of political participation. There has been a lot of work in the visualization of Vectors8 and none of my knowledge has resulted in the number of workers overseas being higher than the number of workers in the US."}, {"heading": "6 Conclusion", "text": "We have described Scattertext, a tool to make comprehensive visualizations of labeled corpora readable. We have shown how it can be used to examine the meanings of wordbag traits and visualize word representations through a category-associated lens."}], "references": [{"title": "Dynamic map labeling", "author": ["Ken Been", "Eli Daiches", "Chee Yap."], "venue": "IEEE-VCG .", "citeRegEx": "Been et al\\.,? 2007", "shortCiteRegEx": "Been et al\\.", "year": 2007}, {"title": "Non-linear text regression with a deep convolutional neural network", "author": ["Zsolt Bitvai", "Trevor Cohn."], "venue": "ACL.", "citeRegEx": "Bitvai and Cohn.,? 2015", "shortCiteRegEx": "Bitvai and Cohn.", "year": 2015}, {"title": "At the national conventions, the words they used", "author": ["Mike Bostock", "Shan Carter", "Matthew Ericson."], "venue": "The New York Times.", "citeRegEx": "Bostock et al\\.,? 2012", "shortCiteRegEx": "Bostock et al\\.", "year": 2012}, {"title": "Dynamic wordclouds and vennclouds for exploratory data analysis", "author": ["Glen Coppersmith", "Erin Kelly."], "venue": "ACL-ILLVI.", "citeRegEx": "Coppersmith and Kelly.,? 2014", "shortCiteRegEx": "Coppersmith and Kelly.", "year": 2014}, {"title": "Representational Style: The Central Role of Communication in Representation", "author": ["Justin Ryan Grimmer."], "venue": "Ph.D. thesis, Harvard University.", "citeRegEx": "Grimmer.,? 2010", "shortCiteRegEx": "Grimmer.", "year": 2010}, {"title": "Movie reviews and revenues: An experiment in text regression", "author": ["Mahesh Joshi", "Dipanjan Das", "Kevin Gimpel", "Noah A. Smith."], "venue": "HLT-NAACL.", "citeRegEx": "Joshi et al\\.,? 2010", "shortCiteRegEx": "Joshi et al\\.", "year": 2010}, {"title": "Narrative framing of consumer sentiment in online restaurant reviews", "author": ["Dan Jurafsky", "Victor Chahuneau", "Bryan Routledge", "Noah Smith."], "venue": "First Monday .", "citeRegEx": "Jurafsky et al\\.,? 2014", "shortCiteRegEx": "Jurafsky et al\\.", "year": 2014}, {"title": "Fast synthesis of fast collections", "author": ["Calvin Loncaric", "Emina Torlak", "Michael D. Ernst."], "venue": "PLDI.", "citeRegEx": "Loncaric et al\\.,? 2016", "shortCiteRegEx": "Loncaric et al\\.", "year": 2016}, {"title": "Fightin\u2019 words: Lexical feature selection and evaluation for identifying the content of political conflict", "author": ["Burt L. Monroe", "Michael P. Colaresi", "Kevin M. Quinn."], "venue": "Political Analysis .", "citeRegEx": "Monroe et al\\.,? 2008", "shortCiteRegEx": "Monroe et al\\.", "year": 2008}, {"title": "Geovisual Analytics Approach to Exploring Public Political Discourse on Twitter", "author": ["J. Nelson", "S. Quinn", "B. Swedberg", "W. Chu", "A. MacEachren."], "venue": "ISPRS-IJGI .", "citeRegEx": "Nelson et al\\.,? 2015", "shortCiteRegEx": "Nelson et al\\.", "year": 2015}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."], "venue": "EMNLP.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Dataclysm: Who We Are (When We Think No One\u2019s Looking)", "author": ["Christian Rudder."], "venue": "Crown Publishing Group.", "citeRegEx": "Rudder.,? 2014", "shortCiteRegEx": "Rudder.", "year": 2014}, {"title": "Genderdistinguishing features in film dialogue", "author": ["Alexandra Schofield", "Leo Mehr."], "venue": "NAACLCLfL .", "citeRegEx": "Schofield and Mehr.,? 2016", "shortCiteRegEx": "Schofield and Mehr.", "year": 2016}, {"title": "Personality, gender, and age in the language of social media: The openvocabulary approach", "author": ["H. Andrew Schwartz", "Johannes C. Eichstaedt", "Margaret L. et al. Kern."], "venue": "PLOS ONE .", "citeRegEx": "Schwartz et al\\.,? 2013", "shortCiteRegEx": "Schwartz et al\\.", "year": 2013}, {"title": "tidytext: Text mining and analysis using tidy data principles in r", "author": ["Julia Silge", "David Robinson."], "venue": "JOSS .", "citeRegEx": "Silge and Robinson.,? 2016", "shortCiteRegEx": "Silge and Robinson.", "year": 2016}], "referenceMentions": [{"referenceID": 8, "context": "For example, finding words that are most characteristic of a political party in congressional speeches can help political scientists identify means of partisan framing (Monroe et al., 2008; Grimmer, 2010), while identifying differences in word usage between male and female characters in films can highlight narrative archetypes (Schofield and Mehr, 2016).", "startOffset": 168, "endOffset": 204}, {"referenceID": 4, "context": "For example, finding words that are most characteristic of a political party in congressional speeches can help political scientists identify means of partisan framing (Monroe et al., 2008; Grimmer, 2010), while identifying differences in word usage between male and female characters in films can highlight narrative archetypes (Schofield and Mehr, 2016).", "startOffset": 168, "endOffset": 204}, {"referenceID": 12, "context": ", 2008; Grimmer, 2010), while identifying differences in word usage between male and female characters in films can highlight narrative archetypes (Schofield and Mehr, 2016).", "startOffset": 147, "endOffset": 173}, {"referenceID": 13, "context": "Language use in social media can inform understanding of personality types (Schwartz et al., 2013), and provides insights into customers\u2019 evaluations of restaurants (Jurafsky et al.", "startOffset": 75, "endOffset": 98}, {"referenceID": 6, "context": ", 2013), and provides insights into customers\u2019 evaluations of restaurants (Jurafsky et al., 2014).", "startOffset": 74, "endOffset": 97}, {"referenceID": 5, "context": "Measuring redundancy is non-trivial, and has traditionally been approached through penalized logistic regression (Joshi et al., 2010), as well as through other feature selection techniques.", "startOffset": 113, "endOffset": 133}, {"referenceID": 6, "context": "The reader is directed to Monroe et al. (2008) (subsequently referred to as MCQ) for an overview of model-based term scoring algorithms.", "startOffset": 26, "endOffset": 47}, {"referenceID": 1, "context": "Also of interest, Bitvai and Cohn (2015) present a method for finding sparse words and phrase scores from a trained ANN (with bag-of-words features) and its training data.", "startOffset": 18, "endOffset": 41}, {"referenceID": 3, "context": "(Coppersmith and Kelly, 2014).", "startOffset": 0, "endOffset": 29}, {"referenceID": 2, "context": "(Coppersmith and Kelly, 2014). 3 Past work and design motivation Text visualizations manipulate the position and appearance of words or points representing them to indicate their relative scores in these measures. For example, in Schwartz et al. (2013), two word clouds are given, one per each category of text being compared.", "startOffset": 1, "endOffset": 253}, {"referenceID": 2, "context": "(Coppersmith and Kelly, 2014). 3 Past work and design motivation Text visualizations manipulate the position and appearance of words or points representing them to indicate their relative scores in these measures. For example, in Schwartz et al. (2013), two word clouds are given, one per each category of text being compared. Words (and selected ngrams) are sized by their linear regression coefficients (a composite metric of precision, recall, and redundancy) and colored by frequency. Only words occurring in geq1% of documents and having Bonferroni-corrected coefficient p-values of <0.001 were shown. Given that these words are highly correlated to their class of interest, the frequency of use is likely a good proxy for recall. Coppersmith and Kelly (2014) also describe a word-cloud based visualization for discriminating terms, but intend it for categories which are both small subsets of a much larger corpus.", "startOffset": 1, "endOffset": 765}, {"referenceID": 2, "context": "Bostock et al. (2012)2 employed an interesting, interactive word-bubble visualization for exploring different word usage among Republicans and Democrats in the 2012 American Political Conventions.", "startOffset": 0, "endOffset": 22}, {"referenceID": 2, "context": "Bostock et al. (2012)2 employed an interesting, interactive word-bubble visualization for exploring different word usage among Republicans and Democrats in the 2012 American Political Conventions. A bubble represents each term, and its size increases with its frequency of use. Its precision is represented by its coloring\u2013 each bubble is colored blue and red, with the blue portion proportionally colored to a term\u2019s relative use by Democrats. Terms were manually chosen, and arranged along the x-axis based on their discriminative power. When clicked, sentences from speeches containing the word used are listed below the visualization. This bubble approach to word clouds inspired Nelson et al. (2015). nytimes.", "startOffset": 0, "endOffset": 705}, {"referenceID": 2, "context": "Bostock et al. (2012)2 employed an interesting, interactive word-bubble visualization for exploring different word usage among Republicans and Democrats in the 2012 American Political Conventions. A bubble represents each term, and its size increases with its frequency of use. Its precision is represented by its coloring\u2013 each bubble is colored blue and red, with the blue portion proportionally colored to a term\u2019s relative use by Democrats. Terms were manually chosen, and arranged along the x-axis based on their discriminative power. When clicked, sentences from speeches containing the word used are listed below the visualization. This bubble approach to word clouds inspired Nelson et al. (2015). nytimes.com/interactive/2012/09/06/us/politics/conventionword-counts.html The dataset used in Bostock et al. (2012) is used to demonstrate the capabilities of Scattertext in each of these figures.", "startOffset": 0, "endOffset": 822}, {"referenceID": 14, "context": "The tidytext R-package (Silge and Robinson, 2016) documentation includes a non-interactive ggplot2-based scatter plot that is very similar to Scattertext.", "startOffset": 23, "endOffset": 49}, {"referenceID": 12, "context": "Schofield and Mehr (2016) use essentially the same visualization, but plot over 100 corresponding n-grams next to an unlabeled frequency/zscore plot.", "startOffset": 0, "endOffset": 26}, {"referenceID": 11, "context": "4 Scattertext Scattertext builds on tinytext and Rudder (2014). It plots a set of unigrams and bigrams (we will refer to these as \u201cterms\u201d) found in a corpus of docuThis type of visualization may have first been introduced in Rudder (2014).", "startOffset": 49, "endOffset": 63}, {"referenceID": 11, "context": "4 Scattertext Scattertext builds on tinytext and Rudder (2014). It plots a set of unigrams and bigrams (we will refer to these as \u201cterms\u201d) found in a corpus of docuThis type of visualization may have first been introduced in Rudder (2014). ments assigned to one of two categories on a twodimensional scatterplot.", "startOffset": 49, "endOffset": 239}, {"referenceID": 11, "context": "4 Scattertext Scattertext builds on tinytext and Rudder (2014). It plots a set of unigrams and bigrams (we will refer to these as \u201cterms\u201d) found in a corpus of docuThis type of visualization may have first been introduced in Rudder (2014). ments assigned to one of two categories on a twodimensional scatterplot. In the following notation, user-supplied parameters are in bold typeface. Consider a corpus of documents C with disjoint subsets A and B s.t. A \u222aB \u2261 C. Let \u03c6T (t, C) be the number of times term t occurs in C, \u03c6T (t, A) be the the number of times t occurs in A. Let \u03c6D(t, . . .) refer to the number of documents containing t. Let tij be the jth word in term ti. In practice, j \u2208 {1, 2}. The parameter \u03c6 may be \u03c6T or \u03c6D.4 Other feature representations (ex., tf.idf) may be used for \u03c6. Pr[ti] = \u03c6(ti, C) \u2211 t\u2208C\u2227|t|\u2261|ti|\u03c6(t, C) . (1) The construction of the set of terms included in the visualization V is a two-step process. Terms must occur at least m times, and if bigrams, appear to be phrases. In order to keep the approach language neutral, we follow Schartz et al. (2013), and use a pointwise mutual information score to filter out bigrams that do not occur far more frequently than would be expected.", "startOffset": 49, "endOffset": 1087}, {"referenceID": 0, "context": "Maximal non-overlapping labeling of scatterplots is NP-hard (Been et al., 2007).", "startOffset": 60, "endOffset": 79}, {"referenceID": 7, "context": "An optimized data structure automatically constructed using Cozy (Loncaric et al., 2016) holds the locations of drawn points and labels.", "startOffset": 65, "endOffset": 88}, {"referenceID": 9, "context": "Rudder (2014) observed terms closer to the lower-right corner were used frequently in A and infrequently in B, indicating they have both high recall and precision wrt category A.", "startOffset": 0, "endOffset": 14}], "year": 2017, "abstractText": "Scattertext is an open source tool for visualizing linguistic variation between document categories in a language-independent way. The tool presents a scatterplot, where each axis corresponds to the rankfrequency a term occurs in a category of documents. Through a tie-breaking strategy, the tool is able to display thousands of visible term-representing points and find space to legibly label hundreds of them. Scattertext also lends itself to a query-based visualization of how the use of terms with similar embeddings differs between document categories, as well as a visualization for comparing the importance scores of bag-of-words features to univariate metrics.", "creator": "LaTeX with hyperref package"}}}