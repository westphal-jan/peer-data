{"id": "1703.00572", "review": {"conference": "EMNLP", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Structural Embedding of Syntactic Trees for Machine Comprehension", "abstract": "This paper develops a model that addresses syntactic embedding for machine comprehension, a key task of natural language understanding. Our proposed model, structural embedding of syntactic trees (SEST), takes each word in a sentence, constructs a sequence of syntactic nodes extracted from syntactic parse trees, and encodes the sequence into a vector representation. The learned vector is then incorporated into neural attention models, which allows learning the mapping of syntactic structures between question and context pairs. We evaluate our approach on SQuAD dataset and demonstrate that our model can accurately identify the syntactic boundaries of the sentences and to extract answers that are syntactically coherent over the baseline methods.", "histories": [["v1", "Thu, 2 Mar 2017 01:08:10 GMT  (1054kb,D)", "http://arxiv.org/abs/1703.00572v1", null], ["v2", "Thu, 20 Apr 2017 00:45:25 GMT  (1171kb,D)", "http://arxiv.org/abs/1703.00572v2", null], ["v3", "Thu, 31 Aug 2017 23:20:59 GMT  (1414kb,D)", "http://arxiv.org/abs/1703.00572v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["rui liu", "junjie hu", "wei wei", "zi yang", "eric nyberg"], "accepted": true, "id": "1703.00572"}, "pdf": {"name": "1703.00572.pdf", "metadata": {"source": "CRF", "title": "Structural Embedding of Syntactic Trees for Machine Comprehension", "authors": ["Rui Liu", "Junjie Hu", "Wei Wei", "Zi Yang", "Eric Nyberg"], "emails": ["ehn}@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, most of them will be able to play by the rules they have established in the past, and they will be able to play by the rules they have established in the past."}, {"heading": "2 Methodology", "text": "The general framework of our model is illustrated in Figure 3. Here, the input of the model consists of embedding the context and the question, while the output consists of two indexes displaying the start and end indices of the answer in context space.The input of the model consists of two parts: the word / character model and the syntactic model. The shaded part of our model in Figure 3 represents the encrypted syntactical information of both the context and the question that is fed into the model. To gain an insight into how the encoding works, we consider a sentence consisting of four nodes (o1, o2, o3, o4).A specific word is represented to be a sequence of nodes from its impact on the root. We will cover how this process works in detail in Section 3.1.1 and 3.1.2. Another input embedded in a deep learning model is the embedding of characters and information."}, {"heading": "3 Structural Embedding of Syntactic Tree", "text": "There are two models that we will look at in this section, for example the Structural Embedding of Constituency Trees Model (SECT) and the Structural Embedding of Dependency Trees Model (SEDT). We assume that the syntactic information was already generated in the pre-processing step with tools such as Stanford CoreNLP [10], and this section deals only with the problem of converting syntactic information into embeddings that can be used in the deep neural models."}, {"heading": "3.1 Syntactic Sequence Extraction", "text": "We first extract a syntactic collection C (p) for each word p, which consists of a series of nodes {o1, o2,..., od \u2212 1, od} in the syntactic parse tree T. Each node oi can be a word, a grammatical category (e.g. part-of-speech tagging), or a dependency link label, depending on the type of syntactic tree we use. To construct syntactic embeddings, we must first define a specific processing sequence A via the syntactic collection C (p), in which way we can extract a syntactic sequence S (p) for the word p."}, {"heading": "3.1.1 Structural Embedding of Constituency Trees (SECT)", "text": "The sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequ"}, {"heading": "3.1.2 Structural Embedding of Dependency Trees (SEDT)", "text": "The dependency tree is a syntactic tree constructed by dependency grammatics [9] that defines the way words are linked by directional links that represent dependencies. A dependency tree is able to capture both long and short-distance dependencies of words. Relationships to links vary in their functions and are labeled with different categories. In the dependency tree shown in Figure 2, the link from \"unit\" to \"conference\" indicates that the target node is a nominal subject (i.e. NSUBJ) of the source node. The processing sequence A (p) for dependency tree is then defined as p children, each represented by its word, which is associated with a vector that uniquely identifies the dependency designation. The processing sequence A (p) for dependency tree is then used as the original sequence of the learning sequence, similar to the one reported in the 4.T dependency tree set."}, {"heading": "3.2 Syntactic Sequence Encoding", "text": "Similar to the previous paper [1, 7], we use a neural network to encode a variable-length syntactic sequence into a fixed-length vector representation; the encoder can be a recursive neural network (RNN) or a Convolutionary Neural Network (CNN) that learns a structural embedding for each node, so that the embedding of nodes under similar syntactic trees in their embedding space is near; we can use a bi-directional LSTM as our RNN encoder, in which the hidden state hpt is updated according to Equation 1. Here, x p t is the tallest node in the syntactic sequence of the word p, which is a vector that uniquely identifies each syntactic node; we get the structural embedding of the given word p, upBi-LSTM = i-l we use the structural element (Bupfunction STi-Li)."}, {"heading": "4 Experiments", "text": "We conducted systematic experiments with the SQuAD dataset [14], a comprehensive question-and-answer dataset to evaluate the performance of our proposed SEST methods. We compared our methods with the Bi-Directional Attention Flow (BiDAF), a state-of-the-art model for machine understanding, as well as with those in Section 3. Our analyses show that SEST methods are better than basic methods in both the development and testing of SQuAD. For a detailed description of the SQuAD dataset, see [14]."}, {"heading": "4.1 Preprocessing", "text": "To ensure that the deep neural models get the correct input, there are a few pre-processing steps. We segmented context and questions into sentences using the full-stop sentence segment2 of NLTK. Words in sentences were then converted into symbols using PTB tokenizer3. Syntactic information including POS tags and syntactic trees was captured by Stanford's CoreNLP utilities [10]. For the parser, we captured constituent relationships and dependency relationships for each word through tree comments or improved dependency comments. To create syntactic sequences, we removed sequences whose first node is a punctuation (\"$,\":, \"\" #, \"\", \"\", \"\", \",\" \"). To use dependency labels, we removed all subcategories (e.g.\" nmod: poss, \"\u21d2\" nmod \")."}, {"heading": "4.2 Experiment Setting", "text": "We have tried our models on a machine that contains a single GTX 1080 GPU with 8GB of VRAM. We use both SECT and SEDT models to compare them with the base models, which are the BiDAF model [15] and the POS model introduced in Section 3.1.1. All four models have the same settings for character embedding and word embedding. As introduced in Section 2, we use a variable character embedding together with a fixed, pre-trained word embedding that will serve as part of the input into the model. Character embedding is done with CNN with a one-dimensional level of 100 units with a channel size of 5. It has an input depth of 8. The maximum length of the SQuAD is 16, which means that there is a maximum of 16 words in a set. Fixed word embedding has a dimension of 100 provided by the GloVe data set."}, {"heading": "4.3 Predictive Performance", "text": "We first compared the performance of individual models between the BiDAF baseline approach and the proposed SEST approaches, including SEPOS, SECT-LSTM, SECTCNN, SEDT-LSTM, and SEDT-CNN, on the SQuAD development dataset. For each model, we conducted 5 separate experiments and evaluated them using two metrics: \"Exact Match\" (EM), which calculates the ratio of questions correctly answered by a rigorous string comparison, and the F1 score, which calculates the harmonic mean of precision and callback between predicted answers and actual character-level responses. As shown in Table 1, we reported on the maximum, mean, and standard deviation of EM and F1 values in each individual run for each approach, and raised the best model with bold font. SEDT-LSTM is the second best method that confirms the predictive power of the different types of syntactical information."}, {"heading": "4.4 Contribution of Syntactic Sequence", "text": "To take a closer look at how syntactic sequences affect performance, we have removed character / word embedding from our model shown in Figure 3 and conducted experiments based on syntactic input. In particular, we are interested in two aspects related to syntactic sequences: First, the ability to predict responses to questions about syntactic sequences compared to complete random sequences; second, the impact that our random sequence order proposed in Section 3.1.1 and Section 3.1.2 has on the performance of models that use syntactic information along their original sequence (i.e. SECT-Only and SEDT-Only), compared to their counterparts with the same syntactic tree nodes but with randomly mixed sequences (i.e. SECTRandom Order and SEDT-Random Order); and we have compared the performance of models using syntactical information along their original sequence (i.e. SET-Only and SET-Only)."}, {"heading": "4.5 Window Size Analysis", "text": "In practice, we found that limiting the window size also benefits the performance of our models. In Table 4, we compared the predictive performance of SECT and SEDT models by changing the length of their window sizes from 1 to maximum to the amount of development. In general, the results show that the performance of the models increases with the length of the window. However, we found that in the SECT model, the average performance peaked while the standard deviations decrease when the window size reaches 10. We also observed that larger window sizes do not produce predictive results that are as good as those with the window size 10. This suggests that there is an optimal window size for the constituency tree. One possible explanation is the increase in the window size leads to an increase in the number of syntactic nodes in the extracted syntactic sequence. Although sub-trees between context and question may be similar, it is very unlikely that the complete trees are the same."}, {"heading": "4.6 Overlapping Analysis", "text": "In order to further understand the advantages of integrating syntactic information in answering the problem, we can take a look at the questions that the models do not share. Figure 4 is the vein chart on the questions that have been corrected by SECT, SEDT, and the baseline BiDAF model. Here, we see that the vast majority of correctly answered questions are shared in all three models, the rest of which show that questions that the models do not match and are fairly evenly distributed. To understand the types of questions that syntactic models can better solve, we extracted three questions that were correctly answered by SECT and SEDT, but not the baseline model. In Table 5, all three questions are \"Wh questions\" and expect an answer from the noun phrase (NP). Without knowing the syntactic information, BiDAF answered questions with unnecessary structures such as verb phrases (vp) (vp)."}, {"heading": "5 Related Work", "text": "In fact, most of them are able to survive on their own."}, {"heading": "6 Conclusion", "text": "In this paper, we proposed methods for embedding syntactical information in the deep neural models to improve the accuracy of our predictive model in the machine understanding task. We started our work with definitions of the SEST framework and proposed two examples: the structural embedding of constituency trees (SECT) and the structural embedding of dependency trees (SEDT). Experimental results from the SQuAD dataset showed that our proposed approaches exceed the state-of-the-art BiDAF model and demonstrate that the proposed embedding plays an important role in the correct identification of answers for the task of machine understanding. Specifically, we found that our model can work particularly well with accurate match metrics that require syntactical information to accurately locate the boundaries of the answers."}], "references": [{"title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart van Merrienboer", "\u00c7aglar G\u00fcl\u00e7ehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"], "venue": "In EMNLP,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2014}, {"title": "Very deep convolutional networks for text classification", "author": ["Alexis Conneau", "Holger Schwenk", "Lo\u0131\u0308c Barrault", "Yann Lecun"], "venue": "In European Chapter of the Association for Computational Linguistics", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2017}, {"title": "Attention-over-attention neural networks for reading comprehension", "author": ["Yiming Cui", "Zhipeng Chen", "Si Wei", "Shijin Wang", "Ting Liu", "Guoping Hu"], "venue": "arXiv preprint arXiv:1607.04423,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2016}, {"title": "Gated-attention readers for text comprehension", "author": ["Bhuwan Dhingra", "Hanxiao Liu", "William W Cohen", "Ruslan Salakhutdinov"], "venue": "arXiv preprint arXiv:1606.01549,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2016}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber"], "venue": "Neural computation,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 1997}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "arXiv preprint arXiv:1408.5882,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2014}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim"], "venue": "In EMNLP, pages 1746\u20131751,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Learning recurrent span representations for extractive question answering", "author": ["Kenton Lee", "Tom Kwiatkowski", "Ankur Parikh", "Dipanjan Das"], "venue": "arXiv preprint arXiv:1611.01436,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2016}, {"title": "Foundations of statistical natural language processing, volume 999", "author": ["Christopher D Manning", "Hinrich Sch\u00fctze"], "venue": null, "citeRegEx": "9", "shortCiteRegEx": "9", "year": 1999}, {"title": "The Stanford CoreNLP natural language processing toolkit", "author": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky"], "venue": "In Association for Computational Linguistics (ACL) System Demonstrations,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2013}, {"title": "Glove: Global vectors for word representation. In EMNLP, pages 1532\u20131543", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning"], "venue": "Association for Computational Linguistics,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2014}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning"], "venue": "In Empirical Methods in Natural Language Processing (EMNLP),", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Squad: 100,000+ questions for machine comprehension of text", "author": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"], "venue": "In EMNLP,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2016}, {"title": "Bidirectional attention flow for machine comprehension", "author": ["Minjoon Seo", "Aniruddha Kembhavi", "Ali Farhadi", "Hannaneh Hajishirzi"], "venue": "arXiv preprint arXiv:1611.01603,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2016}, {"title": "Improved semantic representations from tree-structured long short-term memory networks", "author": ["Kai Sheng Tai", "Richard Socher", "Christopher D. Manning"], "venue": "In IN PROC. ACL,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2015}, {"title": "Newsqa: A machine comprehension dataset", "author": ["Adam Trischler", "Tong Wang", "Xingdi Yuan", "Justin Harris", "Alessandro Sordoni", "Philip Bachman", "Kaheer Suleman"], "venue": "arXiv preprint arXiv:1611.09830,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2016}, {"title": "Machine comprehension using match-lstm and answer pointer", "author": ["Shuohang Wang", "Jing Jiang"], "venue": "arXiv preprint arXiv:1608.07905,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Multiperspective context matching for machine comprehension", "author": ["Zhiguo Wang", "Haitao Mi", "Wael Hamza", "Radu Florian"], "venue": "arXiv preprint arXiv:1612.04211,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2016}, {"title": "Dynamic coattention networks for question answering", "author": ["Caiming Xiong", "Victor Zhong", "Richard Socher"], "venue": "arXiv preprint arXiv:1611.01604,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2016}, {"title": "Words or characters? fine-grained gating for reading comprehension", "author": ["Zhilin Yang", "Bhuwan Dhingra", "Ye Yuan", "Junjie Hu", "William W Cohen", "Ruslan Salakhutdinov"], "venue": "arXiv preprint arXiv:1611.01724,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2016}, {"title": "End-to-end answer chunk extraction and ranking for reading comprehension", "author": ["Yang Yu", "Wei Zhang", "Kazi Hasan", "Mo Yu", "Bing Xiang", "Bowen Zhou"], "venue": "arXiv preprint arXiv:1610.09996,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2016}], "referenceMentions": [{"referenceID": 13, "context": "Machine comprehension on question answering is a problem that requires machines to generate answers by locating a phase inside a context paragraph [14, 17], which is especially challenging since the algorithm has to come up with an answer that matches exactly with what human would do.", "startOffset": 147, "endOffset": 155}, {"referenceID": 16, "context": "Machine comprehension on question answering is a problem that requires machines to generate answers by locating a phase inside a context paragraph [14, 17], which is especially challenging since the algorithm has to come up with an answer that matches exactly with what human would do.", "startOffset": 147, "endOffset": 155}, {"referenceID": 3, "context": "[4, 15, 19, 21, 22].", "startOffset": 0, "endOffset": 19}, {"referenceID": 14, "context": "[4, 15, 19, 21, 22].", "startOffset": 0, "endOffset": 19}, {"referenceID": 17, "context": "[4, 15, 19, 21, 22].", "startOffset": 0, "endOffset": 19}, {"referenceID": 19, "context": "[4, 15, 19, 21, 22].", "startOffset": 0, "endOffset": 19}, {"referenceID": 20, "context": "[4, 15, 19, 21, 22].", "startOffset": 0, "endOffset": 19}, {"referenceID": 13, "context": "Here we are particularly interested in two types of syntactic information, Constituency Tree and Dependency Tree, which have been reported to be some of the most important features for modeling question answering problem using a logistic regression model [14].", "startOffset": 255, "endOffset": 259}, {"referenceID": 8, "context": "In a constituency tree [9], a sentence is decomposed to a tree structure diagram with internal nodes representing phrase structure grammars and terminal nodes representing the actual words presented.", "startOffset": 23, "endOffset": 26}, {"referenceID": 8, "context": "On the other hand, a dependency tree [9] is constructed based on the dependency structure of a sentence.", "startOffset": 37, "endOffset": 40}, {"referenceID": 12, "context": "We choose GloVe [13] to obtain a pre-tained and fixed vector for each word.", "startOffset": 16, "endOffset": 20}, {"referenceID": 10, "context": "There are other alternatives exist such as word2vec [11].", "startOffset": 52, "endOffset": 56}, {"referenceID": 5, "context": "Instead of using a fixed embedding, we use Convolutional Neural Networks (CNN) to model character level embedding, which values can be changed during training [6].", "startOffset": 159, "endOffset": 162}, {"referenceID": 4, "context": "Here we choose a multi-layer bi-directional Long Short Term Memory (LSTM) [5] to obtain more abstract representations for words in the contexts and questions.", "startOffset": 74, "endOffset": 77}, {"referenceID": 19, "context": "Examples are Dynamic Coattention Network [21], Bi-directional Attention flow [15], Multi-Perspective Context Matching [20] and match-LSTM [19].", "startOffset": 41, "endOffset": 45}, {"referenceID": 14, "context": "Examples are Dynamic Coattention Network [21], Bi-directional Attention flow [15], Multi-Perspective Context Matching [20] and match-LSTM [19].", "startOffset": 77, "endOffset": 81}, {"referenceID": 18, "context": "Examples are Dynamic Coattention Network [21], Bi-directional Attention flow [15], Multi-Perspective Context Matching [20] and match-LSTM [19].", "startOffset": 118, "endOffset": 122}, {"referenceID": 17, "context": "Examples are Dynamic Coattention Network [21], Bi-directional Attention flow [15], Multi-Perspective Context Matching [20] and match-LSTM [19].", "startOffset": 138, "endOffset": 142}, {"referenceID": 9, "context": "We assume that the syntactic information have already been generated in the preprocessing step using tools such as the Stanford CoreNLP [10] and this section only concerns with the problem of converting syntactic information into embeddings that can be used in the deep neural models.", "startOffset": 136, "endOffset": 140}, {"referenceID": 8, "context": "The constituency tree is a syntactic parse tree constructed by phrase structure grammars [9], which defines the way to hierarchically construct a sentence from words in a bottom-up manner based on constituency relations.", "startOffset": 89, "endOffset": 92}, {"referenceID": 8, "context": "The dependency tree is a syntactic tree constructed by dependency grammars [9], which defines the way to connect words by directed links that represent dependencies.", "startOffset": 75, "endOffset": 78}, {"referenceID": 0, "context": "Similar to previous work [1, 7], we use a neural network to encode a variable-length syntactic sequence into a fixed-length vector representation.", "startOffset": 25, "endOffset": 31}, {"referenceID": 6, "context": "Similar to previous work [1, 7], we use a neural network to encode a variable-length syntactic sequence into a fixed-length vector representation.", "startOffset": 25, "endOffset": 31}, {"referenceID": 13, "context": "We conducted systematic experiments on the SQuAD dataset [14], a massive question answer dataset to evaluate the performance of our proposed SEST methods.", "startOffset": 57, "endOffset": 61}, {"referenceID": 13, "context": "Detailed description of the SQuAD dataset can be found in [14].", "startOffset": 58, "endOffset": 62}, {"referenceID": 9, "context": "Syntactic information including POS tags and syntactic trees were acquired by Stanford CoreNLP utilities [10].", "startOffset": 105, "endOffset": 109}, {"referenceID": 14, "context": "We use both SECT and SEDT models to compare against the baseline models, which are BiDAF model [15] and the POS model introduced in Section 3.", "startOffset": 95, "endOffset": 99}, {"referenceID": 11, "context": "The fixed word embedding has a dimension of 100, which is provided by the GloVe data set [12].", "startOffset": 89, "endOffset": 93}, {"referenceID": 13, "context": "They use logistic regression with pos tagging information [14] and provided a strong baseline for all subsequent models.", "startOffset": 58, "endOffset": 62}, {"referenceID": 7, "context": "A steep improvement is given by the RaSoR model [8] which utilizes recurrent neural networks which consider all possible subphrases of the context and evaluate them one by one.", "startOffset": 48, "endOffset": 51}, {"referenceID": 17, "context": "To avoid comparing all possible candidates and to improve the performance, Match-LSTM [19] is proposed by using a pointer network [18] to extract the answer span from the context.", "startOffset": 86, "endOffset": 90}, {"referenceID": 14, "context": "The same idea was taken to the BiDAF [15] model by introducing a bi-directional attention mechanism.", "startOffset": 37, "endOffset": 41}, {"referenceID": 2, "context": "One of the main issues in reading comprehension is to identify the latent representations of texts and words [3, 8, 20, 21, 23].", "startOffset": 109, "endOffset": 127}, {"referenceID": 7, "context": "One of the main issues in reading comprehension is to identify the latent representations of texts and words [3, 8, 20, 21, 23].", "startOffset": 109, "endOffset": 127}, {"referenceID": 18, "context": "One of the main issues in reading comprehension is to identify the latent representations of texts and words [3, 8, 20, 21, 23].", "startOffset": 109, "endOffset": 127}, {"referenceID": 19, "context": "One of the main issues in reading comprehension is to identify the latent representations of texts and words [3, 8, 20, 21, 23].", "startOffset": 109, "endOffset": 127}, {"referenceID": 21, "context": "One of the main issues in reading comprehension is to identify the latent representations of texts and words [3, 8, 20, 21, 23].", "startOffset": 109, "endOffset": 127}, {"referenceID": 10, "context": "Many pre-trained libraries such as word2vec [11] and Glove[12] exists that can be used to map words into a high dimensional embedding space.", "startOffset": 44, "endOffset": 48}, {"referenceID": 11, "context": "Many pre-trained libraries such as word2vec [11] and Glove[12] exists that can be used to map words into a high dimensional embedding space.", "startOffset": 58, "endOffset": 62}, {"referenceID": 5, "context": "Another approach is to generate embeddings by using neural networks models such as Character Embedding [6] and Tree-LSTM [16].", "startOffset": 103, "endOffset": 106}, {"referenceID": 15, "context": "Another approach is to generate embeddings by using neural networks models such as Character Embedding [6] and Tree-LSTM [16].", "startOffset": 121, "endOffset": 125}, {"referenceID": 14, "context": "Many machine comprehension models include both pre-trained embeddings and variable embeddings that can be changed through training stage [15, 22].", "startOffset": 137, "endOffset": 145}, {"referenceID": 20, "context": "Many machine comprehension models include both pre-trained embeddings and variable embeddings that can be changed through training stage [15, 22].", "startOffset": 137, "endOffset": 145}, {"referenceID": 1, "context": "Future work involves integrating our proposed model SEST with deeper neural networks such as VD-CNN [2] to improve learning capacity for syntactic embedding.", "startOffset": 100, "endOffset": 103}], "year": 2017, "abstractText": "This paper develops a model that addresses syntactic embedding for machine comprehension, a key task of natural language understanding. Our proposed model, structural embedding of syntactic trees (SEST), takes each word in a sentence, constructs a sequence of syntactic nodes extracted from syntactic parse trees, and encodes the sequence into a vector representation. The learned vector is then incorporated into neural attention models, which allows learning the mapping of syntactic structures between question and context pairs. We evaluate our approach on SQuAD dataset and demonstrate that our model can accurately identify the syntactic boundaries of the sentences and to extract answers that are syntactically coherent over the baseline methods.", "creator": "LaTeX with hyperref package"}}}