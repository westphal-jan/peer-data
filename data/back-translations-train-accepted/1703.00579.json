{"id": "1703.00579", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Active Learning for Accurate Estimation of Linear Models", "abstract": "We explore the sequential decision making problem where the goal is to estimate uniformly well a number of linear models, given a shared budget of random contexts independently sampled from a known distribution. The decision maker must query one of the linear models for each incoming context, and receives an observation corrupted by noise levels that are unknown, and depend on the model instance. We present Trace-UCB, an adaptive allocation algorithm that learns the noise levels while balancing contexts accordingly across the different linear functions, and derive guarantees for simple regret in both expectation and high-probability. Finally, we extend the algorithm and its guarantees to high dimensional settings, where the number of linear models times the dimension of the contextual space is higher than the total budget of samples. Simulations with real data suggest that Trace-UCB is remarkably robust, outperforming a number of baselines even when its assumptions are violated.", "histories": [["v1", "Thu, 2 Mar 2017 01:29:57 GMT  (111kb,D)", "https://arxiv.org/abs/1703.00579v1", "37 pages, 8 figures"], ["v2", "Sat, 29 Jul 2017 19:41:29 GMT  (3585kb,D)", "http://arxiv.org/abs/1703.00579v2", "37 pages, 8 figures, International Conference on Machine Learning, ICML 2017"]], "COMMENTS": "37 pages, 8 figures", "reviews": [], "SUBJECTS": "stat.ML cs.LG", "authors": ["carlos riquelme", "mohammad ghavamzadeh", "alessandro lazaric"], "accepted": true, "id": "1703.00579"}, "pdf": {"name": "1703.00579.pdf", "metadata": {"source": "META", "title": "Active Learning for Accurate Estimation of Linear Models", "authors": ["Carlos Riquelme", "Mohammad Ghavamzadeh", "Alessandro Lazaric"], "emails": ["<rikel@stanford.edu>."], "sections": [{"heading": "1. Introduction", "text": "The problem faced by a policymaker whose goal is to estimate a number of regression problems is equally good (i.e., it is a small prediction for each of them), and a limited number of examples of the problems must be given in order to collect information and improve their estimates. Two aspects of problem formulation are key concepts and driving forces of algorithm construction: 1) The \"severity\" of learning each parameter depends on the way in which the problems related to the relationship between X and Y are pointed out in each problem. 2) The \"severity\" of learning each parameter is unknown and may vary beyond the problems. In particular, we1Stanford University, Stanford, CA, USA. 2DeepMind, Mountain View, CA, USA (The work was done when the author was with Adobe Research)."}, {"heading": "2. Preliminaries", "text": "We consider m linear regression problems where each instance i [m] = 1,.., m] is characterized by a parameter (s) that requires a certain distribution N (0, 2)., We designate a random distribution Y (2)., (1) where the noise i (1) requires an i.i.d realization of a Gaussian distribution N (0, 2)., We designate a random distribution of n (0, 2) and the largest and the average variance, respectively., We define a sequential decision problem about n rounds in which in each round t [n] the learning algorithm A draws a context Xt i.d. of N (0, 2), selects an instance It, and observes a random sample YIt, t after (1).At the end of the experiment, a training set Dn = {Xt, Es, Y."}, {"heading": "3. The TRACE-UCB Algorithm", "text": "In this section, we present and analyze an algorithm of form discussed at the end of section 2, what we call TRACE-UCB, whose pseudo-code in algorithm 1 is TRACE-UCB algorithm 1: for i = 1,.., m do 2: Select problem instance i exactly d + 1 times 3: Calculation of its OLS estimates \u03b2, m (d + 1) and 2: end for 5: for steps t = m (d + 1) + 1,., n do 6: for problem 1 \u2264 i do 7: Compute Score (t \u2212 1) is defined in (11) si: end for steps t \u2212 1 = 2, t \u2212 1 + 1: for steps t \u2212 1 ki, t \u2212 1 ki, t \u2212 1 Tr (t \u2212 1)."}, {"heading": "4. Simulations", "text": "In this section, we provide empirical evidence to support our theoretical results. We look at both synthetic and real-world problems and compare the performance (in terms of normalized MSEs) of TRACE-UCB to unified sampling, optimal static mapping (which requires knowledge of perturbation variances), and the context-free algorithm VAR-UCB (see Remark 2). We do not compare with GFSP-MAX and GAFS-MAX (Antos et al., 2008), as they are surpassed by CH-AS Carpentier et al. (2011) and VAR-UCB is the same as CH-AS, except for the fact that we use the concentration quality in Prop. 3, as we estimate the variance of a regression problem using OLS. First, we use synthetic data to ensure that all assumptions of our model are met, namely we use linear regression models with Gaussian context and deal with noise."}, {"heading": "5. Conclusions", "text": "We investigated the problem of adaptive assignment of n contextual samples of dimension d to estimate m linear functions equally well, under heterogeneous noise levels \u03c32i, which depend on the linear instance and are unknown to decision makers. We proposed TRACE-UCB, an optimistic algorithm that successfully solves the exploration dilemma by simultaneously learning the \u03c32i's, assigning the samples according to their estimates, and balancing the contextual information about the instances. We also offer strong theoretical guarantees for two losses of interest: expectation and high probability. Simulations have been conducted in multiple environments, with both synthetic and real data. The favorable results suggest that TRACE-UCB is reliable and remarkably robust, even in environments that are outside its assumptions, i.e. a useful and simple tool that can be implemented in practice."}, {"heading": "A. Optimal Static Allocation", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1. Proof of Proposition 1", "text": "Proposition. Given m linear regression problems, each characterized by a parameter \u03b2i = \u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2\u03b2"}, {"heading": "B. Loss of an OLS-based Learning Algorithm (Proof of Lemma 2)", "text": "Contrary to the results of Proposition 1, if the number of draws is random and depends on the values of the previous observations (by Dn), then generally the OLS estimates \u03b2 + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S 1S + 1S 1S 1S 1S 1S + 1S 1S 1S + 1S 1S + 1S 1S + 1S + 1S 1S + 1S + 1S 1S + 1S + 1S 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S + 1S +"}, {"heading": "C. Concentration Inequalities (Proofs of Propositions 3 and 4)", "text": "In the next two subsections, we prove the positions 3 and 4, respectively. In addition, we show a confidence ellipsoid result for the \u03b2 estimates and a concentration inequality for the norm of the observations Xt."}, {"heading": "C.1. Concentration Inequality for the Variance (Proof of Proposition 3)", "text": "We use the following concentration inequality for sub-exponential random variables. Proposition 10: \"X\" is a mean zero (\u03c42, b) -subexponential random variable. (34) See Proposition 2.2 in (Wainwright, 2015). First, we prove the concentration inequality for a single instance. Proposition 11. Let us be t > d, Xt, Rt \u00b7 d a random matrix whose entries are independent default random variables, Yt = XTt \u03b2 + t, where the noise does not apply. (0, 2t Id) is independent of Xt, and Proposition (0, 3 / 4]. Then we will most likely have at least one such matrix whose entries are independent of normal random variables, Yt = XTt \u03b2 + t, where the noise does not apply."}, {"heading": "C.2. Concentration Inequality for the Trace (Proof of Proposition 4)", "text": "For any arbitrary matrix A-Rn-d = > dn = the i-th singular value si (A) is equivalent to si (A) 2 = \u03bbi (A TA), where \u03bbi is the i-th eigenvalue. The smallest and largest singular value (A) is equivalent to si (A) 2 = \u03bbi (A) 2 \u2264 2 for all x-th Rd.The extreme singular values measure the maximum and minimum distortion of points and their distance when going from Rd to Rn over the linear operator A. We also remember that the spectral standard of A (A) 2 = sup x x x-Rd = 0-Rd-1-2 = sup x-x x-Sn \u2212 2 = sup x-te x-values and their distance from Rn over the linear operator A. We also remember that the spectral standard of A-2 is given with x-2."}, {"heading": "C.3. Concentration Inequality for \u03b2\u0302 Estimates", "text": "We modify theorem 2 of (Abbasi-Yadkori et al., 2011) slightly to obtain a confidence elisoid above \u03b2-\u03b2-i's. Theorem 13. Let {Ft} \u221e t = 0 be a filtration. Let a stochastic process be a real value, so \u03b7t is measurable and \u03b7t causes R-subgaussian for some R \u2265 0, i.e. that Xt is a measurable process. Suppose that V is a d \u00b7 d positive definitive matrix. Suppose that for each t \u2265 0, defined V + t \u00b2 s = 1 XsX \u2212 s is a stochastic process, so that Xt \u2212 1 is measurable. Suppose that V is a d \u00b7 d positive definitive matrix."}, {"heading": "C.4. Bounded Norm Lemma", "text": "Lemma 14. Let X1,.., Xt, Rd be iid subgaussian random variables.If, X1, 2 is subexponential with parameters (a2, b), then, for \u03b1 > 0P 1 t, if \u03b1 > 0P 1 t, j = 1, Xj, 2, E [.) Proof. The proof immediately follows Proposition 10 by defining the subordinate random variable Z with parameters (a2 / t, b / t) Z = 1t, j = 1, Xj, 2 \u2212 E 1 t, j = 1, Xj, 2,. (43) Corollary 15. Let X1,., Xt,."}, {"heading": "D. Performance Guarantees for TRACE-UCB", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "D.1. Lower Bound on Number of Samples (Proof of Theorem 5)", "text": "We derive the high probability guarantee from the number of times in which each instance selected.q = q q q = q q q = 0. With probability at least 1 \u2212 \u03b4 is the total number of contexts that TRACE-UCB assigns to each problem instance, i after n rounds satisfieski, n q q q q = q q q, i, n \u2212 C + 8CTr\u03c32min \u221a p (54), where R \u2264 2max is known according to the algorithm, and we defined C = 16R log (2mn / q), CTr = 1 + 8CTr\u03c32min + p (4nm / p) / d, and p = 2 min = 2 min / p. Proof. We designate the common event on which propositions 3 and 4 are held simultaneously with an overall probability that we hold 1 \u2212 p."}, {"heading": "D.2. Regret Bound (Proof of Theorem 6)", "text": "n (1), (2), (2), (2), (2), (2), (2), (2), (2), (3), (3), (3), (3), (3), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5, (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5), (5"}, {"heading": "D.3. High Probability Bound for Trace-UCB Loss (Proof of Theorem 7)", "text": "In this section we start with the definition of a new loss function for the algorithms A: L: n (A) = max i: 1 (A) = max i: 1 (A) = max i: 1 (A) = max i: 0 (A) = max i: 1 (A) = max i: 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A) = 0 (A).0 (A) = 0 (A).0 (A).0 (A).0 (A) = 0 (A): (0): A) (0): (A): (0): (A) (0): (A) (0): A) (0): (A) (0): (A): (0) (A): 0: (A) (A): 0: (A)."}, {"heading": "E. Loss of a RLS-based Learning Algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "E.1. Distribution of RLS estimates", "text": "Proposition 16. In the case of a linear regression problem with observations Y = XTX + with Gaussian noise with variance \u03c32 after n contexts X and the corresponding observations Y, we obtain the comb estimation of the parameter \u03bb with observations Y = (XTX + \u03bbI) \u2212 1XTY = WXTY, with W = (XTX + \u03bbI) \u2212 1, and its distribution due to X is easily derived from the RLS estimator as\u03b2 = (XTX + \u03bbI) \u2212 1 (XTX) (XTX) \u2212 2 W (WT)). (95) Proof. With reference to the definition of the OLS estimator \u03b2 (assuming it exists), we can simply rewrite the RLS estimator as\u03b2 = (XTX + \u03bbI) \u2212 1 (XTX + \u03bbI)."}, {"heading": "E.2. Loss Function of a RLS-based Algorithm", "text": "Let us start with the proof of the loss function in the case of a static algorithm. Let us be a learning algorithm that selects the instance i for ki, n times in which ki, n is a fixed quantity selected in advance, and which returns the estimates achieved by RLS with regularization. Then its loss can be expressed in n steps asLn (Astat) = max i [m] Tr (Xi) \u2212 E is the matrix with ki, n + \u03bb 2\u03b2i\u00df T i) WTi, n]), (96) where Wi, n = (XTi, nXi, n + \u03bbI) \u2212 1, and Xni is the matrix with ki, n contexts from the instance in i.Proof. The proof follows the same steps as in app. A to Eq. 22, where we haveLn (Astat) = max i [m] Tr."}, {"heading": "F. Sparse Trace-UCB Algorithm", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "F.1. Summary", "text": "There are also cases where these scenarios require special attention, especially algorithms such as TRACE-UCB, which are more robust in their allocation strategy than their context-free counterparameters. A natural assumption in such scenarios is frugal, i.e., only a small subset of characteristics is relevant to the prediction problem (have no coefficient). In our setting of m problem instances, it is often reasonable to assume that these instances are related, and therefore it makes sense to extend the concept of thrift to common thrift, i.e., a frugal pattern in relation to common problem instances is that we assume that these instances are related to each other."}, {"heading": "F.2. A note on the Static Allocation", "text": "What is the optimal static performance in this setting when the \u03c32s are known? Suppose we pull arm i exactly (\u03c32i / \u2211 j \u03c3 2 j) n times. We are interested in lasso guarantees with respect to the number of observations (see (Hastie et al., 2015; Raskutti et al., 2010). With a high probability, we can adjust \u03bbi as a function of \u03c32i is required in most lasso analyses, because \u03c3 2 i is known. A common guarantee is as follows (see (Hastie et al., 2015; Raskutti et al., 2010). With a high probability, the probability is limited, and c is a universal constant, where k is the number of observations, d is the ambient dimension, s the efficient dimension, \u03b3 is the limited natural constant for the duration of the observations, vice versa > 2 is the parameter that limits the probability, c is a universal constant."}, {"heading": "F.3. Simultaneous Support Recovery", "text": "There is a large amount of research on the way we perform simultaneous support for the multiple regressions. Let M be the matrix whose i-th column is M (i) = \u03b2i.A common objective function when we have a common problem in which we have the same problems as we have them. (There are only a few differences between the most popular parts of the work.) Negahban and Wainwright (Negahban) consider random Gaussian designs. (There are a few differences between the most popular parts of the work.) Negahban and Wainwright (Negahban and Wainwright, 2011). (There are few differences between the most popular parts of the work. (Negahban and Wainwright, 2011). (Negahban and Wainwright, 2011). (Negahban and Wainwright, 2011)."}, {"heading": "F.4. High-Dimensional Trace-UCB Guarantees", "text": "If the overlap of support is complete, we can decrease the sample complexity of the first stage by a factor of m (> \u03b2 + probability); we only need Lm > 2 (1 + v) s log (d \u2212 s) \u03c1u (\u03a3 (1: m) SCSC | S) Cmin \u03b32 (112) observations in total, for some small constant v > 0.Now we show our main result for high-dimensional trace UCB, theorem 20. Theorem. Suppose that the overlap function defined in (Obozinski et al., 2011) is true for all i, for some Z > 0, and assume that the parameters (n, s, \u03b2i, \u03a3) fulfill the conditions C1 to C5 in (Wang et al., 2013). Suppose that the overlap function defined in (Obozinski et al., 2011) is true. If we are marginalized by L > 2 (1 + v) log (d \u2212 s), we will assume the conditions C1 to C5 (Wang et al.) that we have the overlapping function in (Wang et al.)."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "We explore the sequential decision-making problem where the goal is to estimate a number of linear models uniformly well, given a shared budget of random contexts independently sampled from a known distribution. For each incoming context, the decision-maker selects one of the linear models and receives an observation that is corrupted by the unknown noise level of that model. We present Trace-UCB, an adaptive allocation algorithm that learns the models\u2019 noise levels while balancing contexts accordingly across them, and prove bounds for its simple regret in both expectation and high-probability. We extend the algorithm and its bounds to the high dimensional setting, where the number of linear models times the dimension of the contexts is more than the total budget of samples. Simulations with real data suggest that Trace-UCB is remarkably robust, outperforming a number of baselines even when its assumptions are violated.", "creator": "LaTeX with hyperref package"}}}