{"id": "1703.00767", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Attentive Recurrent Comparators", "abstract": "Many problems in Artificial Intelligence and Machine Learning can be reduced to the problem of quantitative comparison of two entities. In Deep Learning the ubiquitous architecture used for this task is the Siamese Neural Network which maps each entity to a representation through a learnable function and expresses similarity through the distances among the entities in the representation space. In this paper, we argue that such a static and invariant mapping is both naive and unnatural. We develop a novel neural model called Attentive Recurrent Comparators (ARCs) that dynamically compares two entities and test the model extensively on the Omniglot dataset. In the task of similarity learning, our simplistic model that does not use any convolutions performs on par with Deep Convolutional Siamese Networks and significantly better when convolutional layers are also used. In the challenging task of one-shot learning on the same dataset, an ARC based model achieves the first super-human performance for a neural method with an error rate of 1.5\\%.", "histories": [["v1", "Thu, 2 Mar 2017 12:47:40 GMT  (288kb,D)", "http://arxiv.org/abs/1703.00767v1", null], ["v2", "Sun, 5 Mar 2017 12:23:16 GMT  (288kb,D)", "http://arxiv.org/abs/1703.00767v2", null], ["v3", "Fri, 30 Jun 2017 07:37:56 GMT  (392kb,D)", "http://arxiv.org/abs/1703.00767v3", null]], "reviews": [], "SUBJECTS": "cs.CV cs.LG", "authors": ["pranav shyam", "shubham gupta", "ambedkar dukkipati"], "accepted": true, "id": "1703.00767"}, "pdf": {"name": "1703.00767.pdf", "metadata": {"source": "META", "title": "Attentive Recurrent Comparators", "authors": ["Pranav Shyam", "Shubham Gupta", "Ambedkar Dukkipati"], "emails": ["PRANAVM.CS13@RVCE.EDU.IN", "SHUBHAM.GUPTA@CSA.IISC.ERNET.IN", "AD@CSA.IISC.ERNET.IN"], "sections": [{"heading": "1. Introduction", "text": "This year, it has reached the stage where it will be able to take the lead in order to achieve the objectives I have mentioned."}, {"heading": "2. Attentive Recurrent Comparators", "text": "Our ARC model is an algorithmic imitation of the human path, which is discussed in Section 1 with Deep Neural Networks. In this section we describe the ARC model, which can compare two images and assess their similarity, but it is trivial to generalize it to more images and / or other modalities. See Figure 1 for a visual representation of this model. The model consists of a recurring area of responsibility and an attention mechanism that takes a specially constructed presentation sequence as input. In the face of two images {xa, xb} we alternate between the two images for a limited number of presentations of each image to form the presentation sequence xa, xb, xa, xb.... The model repeats both images, treating only one image at a time step.In time step, the represented image is given by:"}, {"heading": "It \u2190\u2212 xa if t % 2 is 0 else xb", "text": "Over many time steps, the model observes many aspects of both images. The observations are made by the model at each step, drawing its attention to a region of interest to each input. Since the model is a recursive neural network, this circular, cyclic representation of images allows for an early merging of information from all images, making the model aware of the context in which it works. Consequently, this provides feedback to the attention mechanism, which pays attention to the relevant and crucial parts of each sample, taking into account the observations made so far. The attention mechanism focuses on a specific region of the image to get a view of Gt."}, {"heading": "Gt \u2190\u2212 attend(It,\u2126t) where \u2126t = Wght\u22121", "text": "For each step, we use the previous hidden state of the RNN contoller ht \u2212 1 to calculate the next hidden state. Wg is the projection matrix that maps the hidden state to the required number of attention parameters. Next, both the volatile state and the previous hidden state can be used to form the next hidden state. ht \u2190 \u2212 RNN (Gt, ht \u2212 1) RNN (.) is the update function for the used recurring state. This could simply be RNN or an LSTM. If we make g fleeting glances (or observations) of each image, the hidden state of the RNN contoller in the last time step ht = h2g can be used as a consistent representation of xa in relation to xb or vice versa."}, {"heading": "2.1. Attention Mechanism", "text": "The attention mechanism we use is incrementally derived from zoomable and differential image observation mechanisms by DRAW Gregor et al. (2015). The attention window is defined by an N \u00b7 N 2D grid of Cauchy cores. We found that the heavy tail of the Cauchy curve helps alleviate some of the problems with the vanishing gradient, and that it also accompanies the training. The distance between two adjacent Cauchy cores is defined either vertically or horizontally. In other words, the elementary square of the 2D grid Y is the size of (x, y), with the central Cauchy kernel being the size of (x, y). The distance between two adjacent Cauchy cores is defined either vertically or horizontally."}, {"heading": "2.2. Use of Convolutions", "text": "As will be seen in the following experimental sections, the use of folding feature extractors resulted in a significant increase in performance. Attention to raw images and deep resnets, but we found great improvements through the use of folding feature extractors. In the face of an image, the application of multiple layers of folding features generates a 3D body of activations (or a stack of 2D feature cards). Attention to this is equivalent to applying the same 2D attention (described in Section 2.1 above) to the entire depth of the 3D feature card. The treated subbody is then flattened and used as a fleeting glance."}, {"heading": "3. Experiments and Analysis", "text": "To understand the empirical workings of an ARC and identify factors that affect its performance, both qualitative and quantitative studies are needed. Qualitative analyses show us what the model does when it compares two images and how this affects human comparisons. Quantitative analyses show the performance fluctuations when certain aspects of the model are changed, thus providing an estimate of their significance. For the analysis shown below, we use the simple ARC model (without coils) described in Section 2 above and trained for the verification task (or similarity learning) on the Omniglot dataset. The verification task is a binary classification problem in which the model is trained to predict whether or not the two drawings of the provided characters belong to the same character."}, {"heading": "3.1. Empirical Analysis", "text": "Omniglot is a dataset from (Lake et al., 2015) specifically designed to compare and contrast the learning abilities of humans and machines, containing handwritten characters from 50 languages / alphabets. Although there are 1623 characters, there are only 20 samples for each character drawn by different individuals, so the dataset is in a diagonally opposite position to MNIST or ImageNetdatasets. Data samples in the Omniglot dataset have an intelligible structure with characters consisting of simple strokes drawn on a clean canvas. The dataset is also very diverse, allowing us to study various properties of our model under a wide range of conditions. As our main result in the paper is also based on the Omniglot dataset (next section), we train the ARC on the same dataset for this analysis to get an insight into the kind of performance gains that are achieved by this architecture."}, {"heading": "3.1.1. QUALITATIVE ANALYSIS", "text": "The following conclusions were drawn after examining several cases of ARC operation: 1. The observations in one image clearly depend on the observations in the other image, as can be seen in Figures 2a and 2b. 2. The ARC appears to have learned a fairly regular parsing strategy from left to right, with the attention window gradually narrowing, similar to strategies found in other sequential attentive models such as DRAW (Gregor et al., 2015). 3. A deviation from such a regular parsing strategy occurs when the model finds an interesting feature in both characters, which results in the attention being fixed for a few subsequent glances at that particular region of the character. 4. There is no strict coordination or chronological correspondence between the visited regions of the two images. While cases of ARC focusing on the same aspect / dash of two characters were common, there were many other cases where the ARC focused on different aspects during an interval / dash."}, {"heading": "3.1.2. QUANTITATIVE ANALYSIS", "text": "We conducted a simple but very revealing ablation study to understand the dynamics of ARC. ARC collects information about the two input images through a series of attentive observations. To see how the information content changed with the overvations, we trained 8 separate binary classifiers to classify images in each even time step as similar or not based on the hidden states of the LSTM controller. The performance of these classifiers is described in Table 1. Since the ARC has an attention window of only 4 x 4 pixels, in the first step it can hardly see anything where its attention is distributed over the entire image. With more glances, finer observations bring more precise information and the recurring transitions use this knowledge, resulting in higher accuracy. We also used the 8 binary classifiers to investigate how confidence in models with more glances grows, and such a good example is provided in Figure 3."}, {"heading": "3.2. Similarity Learning Performance Compared to Siamese Networks", "text": "In this section, we compare ARCs with other methods of deep learning, especially Siamese neural networks on two representative datasets: Omniglot and CASIA WebFace Dataset. We consider strong convolutionary baselines that have proven time and again to be outstanding in such visual tasks. In particular, we use Wide Resnets (WRNs) (Zagoruyko & Komodakis, 2016), which correspond to the current state of the art in image classification. Wide ResNets contain 4 blocks of Convolutionary Feature Extractors. ConvARC models also use Wide Resnets for feature extraction, but with one block less. We used moderate data augmentation consisting of translation, flipping, rotation and scissors, which we considered crucial for the formation of ARC models (WRNs were also trained with the same augmentation). Hyper parameters were set for reasonable values for all our ARC models and no hyperparameters were used."}, {"heading": "3.2.1. OMNIGLOT", "text": "The data distribution of the Omniglot dataset used for this comparison differs from those mentioned above: 30 alphabets were used for training, 10 for validation and 10 for testing (to be compatible with ConvNets in (Koch et al.)) The results are summarized in Table 2. Our simple ARC model without using any corrugated layers achieves performance consistent with a 6-layer AlexNet-style Deep Convnet."}, {"heading": "3.2.2. CASIA WEBFACE", "text": "CASIA Webface is the largest public face archive, consisting of 494,414 unique images of over 10,000 people. We divided the data as follows: training set: 70% (7402 people), validation set: 15% (1586 people) and test set: 15% (1587 people). Images were scaled down to 32 x 32 pixels and used an attention window of 4x4 pixels. The rest of the architecture corresponds to the Omniglot model. The results are presented in table 3."}, {"heading": "4. Relative Representations for One Shot Classification", "text": "A classic example of such a learning behavior is that of a human child learning about the animal giraffe (Vinyals et al., 2016). The child does not see thousands of images of giraffes to learn about them. Rather, the child can only recognize from a single example not only at a later stage, but also speculate about its other characteristics. While humans excel in this task, current deep learning systems are at the opposite end of the spectrum, where they are trained on millions of samples to achieve the kind of results for which they are known. It is easy to argue that one-off learning is a crucial ingredient in the development of machine intelligence on a human level that can learn quickly and continuously."}, {"heading": "4.1. Dynamic and Relative Representations", "text": "In fact, it is the case that most people who are able are able to determine for themselves what they want and what they do not want."}, {"heading": "4.2. Models", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.2.1. NAIVE ARC MODEL", "text": "This is a trivial extension of ARC to verify this task. The test image from the evaluation set is compared with all images from the support set. It1Again, this is limited to some features that ARC has learned to recognize, but it is much more general than simple feed-forward feature extractors. It is mapped to the sample with maximum similarity and the corresponding class is the prediction of the model. Here, we reduce the relative representations directly to similarity values. The entire context of the relative representation space is not taken into account, so this also functions as a base model compared to our full context model."}, {"heading": "4.2.2. FULL CONTEXT ARC", "text": "While the Naive ARC model is simple and efficient, it does not take into account the entire context in which our model is supposed to make the similarity decision. If the test sample is compared with all the support samples, the comparisons are made independently of each other. As with the Naive method, we compare the test sample from the evaluation with each image from the support samples in pairs, but instead of immediately providing a similarity value, we collect the relative representations of each comparison. Relative representations are the last hidden state of the controller when comparing the test image T with the image Sj from the support set: ej = hLT, Sj. These embeddings are further processed by a bi-directional LSTM layer. This brings together the information from all comparisons and thus provides the necessary context before the emission. A similar method is also used in Matching Networks (Vinyals et al, 2016)."}, {"heading": "4.3. Omniglot", "text": "A shot classification on this dataset is a very difficult task, as most deep learning systems do not work well. (Lake et al., 2015) The dataset contains 1623 alphabets and is divided into a background group and a rating group. The background group contains 30 alphabets (964 characters) and only this group should be used to perform all learning (e.g. hyperparameter inference or feature learning), with the remaining 20 alphabets for evaluation purposes only. Each character is a 105 x 105 image.A one-shot classification task is as follows: From a randomly selected alphabet, 20 characters are selected to become a support set. One character among these 20 becomes a test character. 2 drawers are selected, one each for support and the test character. The task is to form a letter combination to support the letter combination in the drawing."}, {"heading": "4.3.1. BASELINES AND OTHER METHODS", "text": "We compare the two models discussed above with other methods in the literature: from the simplest baseline of k-Nearest Neighbors to the latest meta-learning methods. Training and evaluation practices are not consistent. Across Alphabets: Many recent works, such as Matching Networks (Vinyals et al., 2016) and MANNs (Santoro et al., 2016) have used 1200 characters for background representation (instead of 964 by (Lake et al., 2015)). The remaining 423 characters are used for testing. Most importantly, the characters that were scanned for both training and evaluation are distributed across all alphabets in the training environment.Within alphabets: This corresponds to the default Omniglot setting, where characters are scanned within an alphabet, and only the 30 background characters are used for training and validation. The alphabet task is much easier, as they belong to the same language, not to the same subset in depth."}, {"heading": "4.3.2. RESULTS", "text": "The results are presented in Tables 4 and 5. Our ARC models surpass all previous methods according to both test protocols and establish the corresponding state of the art."}, {"heading": "4.4. miniImageNet", "text": "ONKONONONKONKONKON4KONONONKONKONVONS 48.4% ONONONONONONKONKONVONS 46.1% ONKONKONONONONKONKONVONKONS 48.4% ONKONONONONKONONONKONVONKONVONKONS 46.1% ONKONONKONVONKONKONVONS 48.4% ONKONONKONKONKONKONVONKONVONS 46.1% ONKONKONKONKONKONKONVONKONKONKONVONKONKONKONVONKONKONVONKONKONVONKONVONKONKONVONKONVONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONKONK"}, {"heading": "5. Related Work", "text": "Deep Neural Networks (Schmidhuber, 2015) (LeCun et al., 2015) are very complex parameterized functions that can be customized to have the required behavior by specifying an appropriate objective function. Our overall model is a simple combination of the attention mechanism and recursive neural networks (RNs). We test our model by analyzing the processing load in the area of similarity, using it in a model built for the challenging task of a handwritten character symbol. It is known that attention arises in the processing of information while it reduces the processing load (Desimone & Duncan, 1995). Attention and neural networks were combined in Schmidhuber & Huber to learn fovea tractories."}, {"heading": "6. Conclusion and Future Work", "text": "We have shown that this model is not only practicable, but also much better than today's widely used Siamese neural networks in terms of performance and generalization. But taking a step back, we showed the value of dynamic representations and presented a novel way of approximating this model roughly. Our main result is the abandonment of the one-shot classification of the Omniglot dataset, where we have reached a state of the art that exceeds the performance of HBPL and humans. A potential disadvantage of this model is that, due to the sequential execution of the recurring core and design of the model, it could be computationally more expensive than a distance metric method. However, we believe that advancing hardware speeds, such costs are outweighed by the benefits of ARCs. Although ARCs are presented in the context of images, they can be used in any model. There are countless ways to enhance these control mechanisms in a more complex, more complex, attention-grabbing way, etc."}], "references": [{"title": "Multiple object recognition with visual attention", "author": ["Ba", "Jimmy", "Mnih", "Volodymyr", "Kavukcuoglu", "Koray"], "venue": "arXiv preprint arXiv:1412.7755,", "citeRegEx": "Ba et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Ba et al\\.", "year": 2014}, {"title": "A survey on metric learning for feature vectors and structured data", "author": ["Bellet", "Aur\u00e9lien", "Habrard", "Amaury", "Sebban", "Marc"], "venue": "arXiv preprint arXiv:1306.6709,", "citeRegEx": "Bellet et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bellet et al\\.", "year": 2013}, {"title": "Learning a similarity metric discriminatively, with application to face verification", "author": ["Chopra", "Sumit", "Hadsell", "Raia", "LeCun", "Yann"], "venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR\u201905),", "citeRegEx": "Chopra et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Chopra et al\\.", "year": 2005}, {"title": "Neural mechanisms of selective visual attention", "author": ["Desimone", "Robert", "Duncan", "John"], "venue": "Annual review of neuroscience,", "citeRegEx": "Desimone et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Desimone et al\\.", "year": 1995}, {"title": "A bayesian approach to unsupervised one-shot learning of object categories", "author": ["Fe-Fei", "Li", "Fergus", "Robert", "Perona", "Pietro"], "venue": "In Computer Vision,", "citeRegEx": "Fe.Fei et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Fe.Fei et al\\.", "year": 2003}, {"title": "Learning to forget: Continual prediction with lstm", "author": ["Gers", "Felix A", "Schmidhuber", "J\u00fcrgen", "Cummins", "Fred"], "venue": "Neural computation,", "citeRegEx": "Gers et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Gers et al\\.", "year": 2000}, {"title": "Generating sequences with recurrent neural networks", "author": ["Graves", "Alex"], "venue": "arXiv preprint arXiv:1308.0850,", "citeRegEx": "Graves and Alex.,? \\Q2013\\E", "shortCiteRegEx": "Graves and Alex.", "year": 2013}, {"title": "Draw: A recurrent neural network for image generation", "author": ["Gregor", "Karol", "Danihelka", "Ivo", "Graves", "Alex", "Rezende", "Danilo Jimenez", "Wierstra", "Daan"], "venue": "arXiv preprint arXiv:1502.04623,", "citeRegEx": "Gregor et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gregor et al\\.", "year": 2015}, {"title": "Long shortterm memory", "author": ["Hochreiter", "Sepp", "Schmidhuber", "J\u00fcrgen"], "venue": "Neural computation,", "citeRegEx": "Hochreiter et al\\.,? \\Q1997\\E", "shortCiteRegEx": "Hochreiter et al\\.", "year": 1997}, {"title": "Human-level concept learning through probabilistic program induction", "author": ["Lake", "Brenden M", "Salakhutdinov", "Ruslan", "Tenenbaum", "Joshua B"], "venue": null, "citeRegEx": "Lake et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2015}, {"title": "Building machines that learn and think like people", "author": ["Lake", "Brenden M", "Ullman", "Tomer D", "Tenenbaum", "Joshua B", "Gershman", "Samuel J"], "venue": "CoRR, abs/1604.00289,", "citeRegEx": "Lake et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lake et al\\.", "year": 2016}, {"title": "Learning to combine foveal glimpses with a third-order boltzmann machine", "author": ["Larochelle", "Hugo", "Hinton", "Geoffrey E"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Larochelle et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Larochelle et al\\.", "year": 2010}, {"title": "Recurrent models of visual attention", "author": ["Mnih", "Volodymyr", "Heess", "Nicolas", "Graves", "Alex"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Mnih et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Mnih et al\\.", "year": 2014}, {"title": "One-shot learning with memory-augmented neural networks", "author": ["Santoro", "Adam", "Bartunov", "Sergey", "Botvinick", "Matthew", "Wierstra", "Daan", "Lillicrap", "Timothy"], "venue": "arXiv preprint arXiv:1605.06065,", "citeRegEx": "Santoro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Santoro et al\\.", "year": 2016}, {"title": "Learning to generate artificial fovea trajectories for target detection", "author": ["Schmidhuber", "Juergen", "Huber", "Rudolf"], "venue": "International Journal of Neural Systems,", "citeRegEx": "Schmidhuber et al\\.,? \\Q1991\\E", "shortCiteRegEx": "Schmidhuber et al\\.", "year": 1991}, {"title": "Deep learning in neural networks: An overview", "author": ["Schmidhuber", "J\u00fcrgen"], "venue": "Neural Networks,", "citeRegEx": "Schmidhuber and J\u00fcrgen.,? \\Q2015\\E", "shortCiteRegEx": "Schmidhuber and J\u00fcrgen.", "year": 2015}, {"title": "Matching networks for one shot learning", "author": ["Vinyals", "Oriol", "Blundell", "Charles", "Lillicrap", "Timothy", "Kavukcuoglu", "Koray", "Wierstra", "Daan"], "venue": "arXiv preprint arXiv:1606.04080,", "citeRegEx": "Vinyals et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2016}, {"title": "Wide residual networks", "author": ["Zagoruyko", "Sergey", "Komodakis", "Nikos"], "venue": "CoRR, abs/1605.07146,", "citeRegEx": "Zagoruyko et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zagoruyko et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 10, "context": "Advancing Deep Learning systems to solve Artificial Intelligence tasks requires that models be capable of performing continual and rapid learning (Lake et al., 2016).", "startOffset": 146, "endOffset": 165}, {"referenceID": 13, "context": "But top-down hierarchical designs of models to perform such tasks are not very successful on real world data and there are many reasons for this (Santoro et al., 2016).", "startOffset": 145, "endOffset": 167}, {"referenceID": 7, "context": "The attention mechanism we use is incrementally derived from zoomable and differential image observation mechanism of DRAW Gregor et al. (2015). The attention window is defined by an N \u00d7 N 2D grid of Cauchy kernels.", "startOffset": 123, "endOffset": 144}, {"referenceID": 9, "context": "Omniglot is a dataset by (Lake et al., 2015) that is specially designed to compare and contrast the learning abilities of humans and machines.", "startOffset": 25, "endOffset": 44}, {"referenceID": 5, "context": "The particular model under consideration has an LSTM controller (Hochreiter & Schmidhuber, 1997) with forget gates (Gers et al., 2000).", "startOffset": 115, "endOffset": 134}, {"referenceID": 9, "context": "Out of the 50 alphabets provided in the dataset, 30 were used for training and validation and the last 20 for testing, as per the Omniglot usage protocol followed by (Lake et al., 2015).", "startOffset": 166, "endOffset": 185}, {"referenceID": 7, "context": "This is quite similar to strategies found in other sequential attentive models like DRAW (Gregor et al., 2015).", "startOffset": 89, "endOffset": 110}, {"referenceID": 16, "context": "A classic example is of such learning behaviour is that of a human kid learning about the animal giraffe (Vinyals et al., 2016).", "startOffset": 105, "endOffset": 127}, {"referenceID": 13, "context": "One way of training such systems is to have a meta learning system where in the model is trained to represent entities in space (rather than being trained to represent a entity) (Schaul & Schmidhuber, 2010) (Santoro et al., 2016).", "startOffset": 207, "endOffset": 229}, {"referenceID": 16, "context": "A similar method is also used in Matching Networks (Vinyals et al., 2016).", "startOffset": 51, "endOffset": 73}, {"referenceID": 9, "context": "(Lake et al., 2015) developed a dedicated system for such rapid knowledge acquisition called Bayesian Programming Learning, which surpasses human performance and is the current state of the art of all methods.", "startOffset": 0, "endOffset": 19}, {"referenceID": 16, "context": "Across Alphabets: Many papers recently, like Matching Networks (Vinyals et al., 2016) and MANNs (Santoro et al.", "startOffset": 63, "endOffset": 85}, {"referenceID": 13, "context": ", 2016) and MANNs (Santoro et al., 2016) have used 1200 chars for background set (instead of 964 specified by (Lake et al.", "startOffset": 18, "endOffset": 40}, {"referenceID": 9, "context": ", 2016) have used 1200 chars for background set (instead of 964 specified by (Lake et al., 2015)).", "startOffset": 77, "endOffset": 96}, {"referenceID": 16, "context": "Recently, Vinyals et al. (2016) introduced a One Shot learning task taken based off of the popular ImageNet dataset and uses a testing protocol similar to Omniglot.", "startOffset": 10, "endOffset": 32}, {"referenceID": 7, "context": "A specialised form of location based soft attention mechanism, well suited for 2D images was developed for the DRAW architecture (Gregor et al., 2015), and this forms the basis of our attention mechanism in ARC.", "startOffset": 129, "endOffset": 150}, {"referenceID": 10, "context": "Hard Attention mechanism based on Reinforcement Learning was used in Mnih et al. (2014) and further extended to multiple objects in Ba et al.", "startOffset": 69, "endOffset": 88}, {"referenceID": 0, "context": "(2014) and further extended to multiple objects in Ba et al. (2014); both of these models showed that the computation required at inference is significantly less compared to highly parallel Convolutional Networks, while still achieving good performance.", "startOffset": 51, "endOffset": 68}, {"referenceID": 0, "context": "(2014) and further extended to multiple objects in Ba et al. (2014); both of these models showed that the computation required at inference is significantly less compared to highly parallel Convolutional Networks, while still achieving good performance. A soft or differentiable attention mechanisms have been used in Graves (2013). A specialised form of location based soft attention mechanism, well suited for 2D images was developed for the DRAW architecture (Gregor et al.", "startOffset": 51, "endOffset": 332}, {"referenceID": 16, "context": "Matching Networks (Vinyals et al., 2016) and Memory Augmented Neural Networks (Santoro et al.", "startOffset": 18, "endOffset": 40}, {"referenceID": 13, "context": ", 2016) and Memory Augmented Neural Networks (Santoro et al., 2016) are other approaches to perform continual or meta learning in the low data regime.", "startOffset": 45, "endOffset": 67}, {"referenceID": 1, "context": "A survey of the methods and importance of measuring similarity of samples in Machine Learning is presented in Bellet et al. (2013). With respect to deep learning methods, the most popular architecture family is that of Siamese Networks (Bromley et al.", "startOffset": 110, "endOffset": 131}, {"referenceID": 1, "context": "A survey of the methods and importance of measuring similarity of samples in Machine Learning is presented in Bellet et al. (2013). With respect to deep learning methods, the most popular architecture family is that of Siamese Networks (Bromley et al., 1993). The energy based derivation of the same is presented in Chopra et al. (2005). A bayesian framework for one shot visual recognition was presented in Fe-Fei et al.", "startOffset": 110, "endOffset": 337}, {"referenceID": 1, "context": "A survey of the methods and importance of measuring similarity of samples in Machine Learning is presented in Bellet et al. (2013). With respect to deep learning methods, the most popular architecture family is that of Siamese Networks (Bromley et al., 1993). The energy based derivation of the same is presented in Chopra et al. (2005). A bayesian framework for one shot visual recognition was presented in Fe-Fei et al. (2003). Lake et al.", "startOffset": 110, "endOffset": 429}, {"referenceID": 1, "context": "A survey of the methods and importance of measuring similarity of samples in Machine Learning is presented in Bellet et al. (2013). With respect to deep learning methods, the most popular architecture family is that of Siamese Networks (Bromley et al., 1993). The energy based derivation of the same is presented in Chopra et al. (2005). A bayesian framework for one shot visual recognition was presented in Fe-Fei et al. (2003). Lake et al. (2015) extensively study One Shot Learning and present a novel probabilistic framework called Hierarchical Bayesian Program Learning (HBPL) for rapid learning.", "startOffset": 110, "endOffset": 449}], "year": 2017, "abstractText": "Rapid and continual learning models require that the representation space they use be dynamic and constantly changing as the model encounters new evidence. While recently there have been many end-to-end, meta-learning based approaches, they have significant drawbacks. We present a novel model that crudely approximates having a dynamic representation space at inference time. The entire representation space is defined relative to the test example and the entire context of this relative representation space is considered before the model makes a prediction. We extensively test all aspects of our model across various real world datasets. In the challenging task of one-shot learning on the Omniglot dataset, our model achieves the first superhuman performance for a neural method with an error rate of 1.5%.", "creator": "LaTeX with hyperref package"}}}