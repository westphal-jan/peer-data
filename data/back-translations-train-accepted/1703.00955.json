{"id": "1703.00955", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "2-Mar-2017", "title": "Toward Controlled Generation of Text", "abstract": "Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible natural language sentences, whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns highly interpretable representations from even only word annotations, and produces realistic sentences with desired attributes. Quantitative evaluation validates the accuracy of sentence and attribute generation.", "histories": [["v1", "Thu, 2 Mar 2017 21:23:47 GMT  (84kb,D)", "http://arxiv.org/abs/1703.00955v1", "updated discussions and references"], ["v2", "Tue, 11 Jul 2017 21:15:43 GMT  (85kb,D)", "http://arxiv.org/abs/1703.00955v2", "ICML 2017 camera-ready + more discussions"]], "COMMENTS": "updated discussions and references", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CL stat.ML", "authors": ["zhiting hu", "zichao yang", "xiaodan liang", "ruslan salakhutdinov", "eric p xing"], "accepted": true, "id": "1703.00955"}, "pdf": {"name": "1703.00955.pdf", "metadata": {"source": "META", "title": "Controllable Text Generation", "authors": ["Zhiting Hu", "Zichao Yang", "Xiaodan Liang", "Ruslan Salakhutdinov", "Eric P. Xing"], "emails": ["zhitingh@cs.cmu.edu", "zichaoy@cs.cmu.edu", "xiaodan1@cs.cmu.edu", "rsalakhu@cs.cmu.edu", "epxing@cs.cmu.edu"], "sections": [{"heading": "1. Introduction", "text": "In fact, most people who are able to survive themselves are able to survive themselves, \"he told the German Press Agency in an interview with\" Welt am Sonntag \":\" I don't think we will be able to change the world. \""}, {"heading": "2. Related Work", "text": "In recent years it has become clear that the problem is a problem that cannot be solved, but that it must be solved, \"he told the Deutsche Presse-Agentur in an interview with the news agency dapd.\" I don't think there will be a solution, \"he told the Deutsche Presse-Agentur.\" I think there will be a solution. \""}, {"heading": "3. Controllable Text Generation", "text": "Our model aims to generate plausible sentences based on representation vectors equipped with specific semantic structures. For example, to control sentence feeling, our model assigns a dimension of latent representation to encode \"positive\" and \"negative\" semantics, and generates samples with desired sensation by simply specifying a particular code. Each of these codes benefits from the untangled structure and is able to capture a prominent attribute and be independent of other characteristics. Our deep text generative model has several merits over previous work, as it 1) facilitates the effective imposition of latent code semantics by enabling global decriminalists to direct discrete text generator learning; 2) improves the model's interpretative capability by explicitly enforcing the limitations of independent attribute controls; 3) enables efficient semi-supervised learning and bootstrapping by synthesizing sleep variations with an auto-encoded approach."}, {"heading": "3.1. Model Overview", "text": "We build our framework from variable autoencoders (section 2) used to generate texts (2015; Semeniuta et al., 2017) in which sentences x are generated based on latent code z. Vanilla UAE uses an unstructured vector in which the dimensions are interwoven. In order to model the attributes of interest in an interpretative way, we extend the unstructured variables z with a series of structured variables c aiming at a distinctive and independent semantic property. We want the vector to achieve a state in which the vector is located."}, {"heading": "3.2. Model Structure", "text": "We now describe our model in detail by introducing the learning of generators or discriminators."}, {"heading": "Generator Learning", "text": "The question for the \"why,\" according to the title, \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\" \"why,\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\" \",\", \"\", \"\", \",\", \",\" \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\", \",\" \",\", \",\", \",\" \",\" \",\", \"\", \",\" \",\" \",\" \",\" \",\", \"\", \",\" \"\", \",\", \"\", \"\", \",\" \",\", \",\", \"\", \",\", \"\", \",\" \",\", \",\" \",\", \",\", \"\", \",\", \"\", \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \"\", \",\", \"\", \",\", \",\", \",\" \",\", \",\", \"\", \",\", \",\", \"\", \",\", \",\", \"\", \",\" \",\" \",\", \",\", \",\", \",\", \"\", \",\", \"\", \",\", \",\", \",\", \",\", \"\" \",\", \"\" \",\", \",\" \",\", \",\", \""}, {"heading": "Discriminator Learning", "text": "The discriminator D is trained to accurately derive the sentence attribute and to assess the error of restoring the desired attribute according to the latent code. For example, the discriminator can be defined as a discriminator for categorical attributes, while a probabilistic regressor can be used for continuous objectives. The discriminator is learned differently from the UAE encoder because the target attributes can be discriminatory that are not supported within the UAE framework. Furthermore, unlike the unstructured code z, which is controlled in an unsupervisedalgorithm 1 text generation input: A large corpus of unmarked sentences X = {x} A few sentence attribute labels XL = (xL, cL)} Parameters: \u03bbz, \u03b2u, \u03b2 - compensatory parameter1: compensatory parameter VAE by minimizing Eq."}, {"heading": "Summarization and Discussion", "text": "We have derived our model and its learning procedure in the sections above. First, the generator is initialized by training the base UAE on a large corpus of unmarked sentences, with the aim of minimizing equality (4) with the latent code c, which is sampled at this time from the previous distribution p (c). Learning the entire model then proceeds by alternating the optimization of the generator and the discriminator. The detailed learning procedure is summarized in Algorithm 1. our model can be seen as a combination of the VAE framework with an advanced wake-sleep method, as shown in Figure 2. Specifically, in Equation (10) the samples are produced by the generator and used as targets for maximum probability training of the discriminator. This model is similar to the sleep phase of the wake-sleep algorithm. Equations (6) - (7) continue to use the generated samples to improve the generator."}, {"heading": "4. Experiments", "text": "We evaluate our approach with both quantitative and qualitative experiments. Our model is effective in generating sentences with controlled sentiment attributes and tensions. Compared to previous generative models, our method improves the accuracy of both attribute generation and classification. From a few highlighted examples or even just word comments, we learn a highly untangled representation. We confirm the effect of the proposed independence restriction on interpretable generation and show that our model is capable of producing compelling sentences with desired attributes."}, {"heading": "4.1. Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Datasets", "text": "We use a large IMDB text corpus (Diao et al., 2014) to train the generative models. This is a collection of 350K movie reviews. We select sentences that contain no more than 16 words and replace rare words with the token. \"\" The resulting data set contains about 1.4 million sentences with the vocabulary size of 16K.Sentiment. To control the mood (\"positive\" or \"negative\") of the generated sentences, we test on the following labeled mood data: (1) Stanford Sentiment Treebank-2 (SST-full) (Socher et al., 2013) consists of 6920 / 872 / 1821 movie review sets with binary sentiment notes on the trains / dev / test sets. We use the 2837 training examples with the sentence length \u2264 16 and rate the classification accuracy on the original test set. (2) SSTsmall."}, {"heading": "Parameter Setting", "text": "We implement both the generator and the encoder as single 2www.timeml.orglayer LSTM RNNs with input and hidden dimension of 300 and maximum sample length of 16. Discriminators are parameterized as Convolutionary Networks. We specify the detailed structural configurations in the supplements. To avoid infinitesimal KL terms in the UAE (Bowman et al., 2015), we use a KL term weight linear from 0 to 1 during the training. Neural parameters are trained using SGD with the Adam updating rule (Kingma & Ba, 2014)."}, {"heading": "4.2. Accuracy of Generated Attributes", "text": "We measure the performance of attachments to sentences by evaluating the accuracy of the sensations generated, and the effect of the generated samples on sensitivity. We compare our model with the sentences mentioned, and there will be no discrimination. We use one of the few noteworthy models that are able to reconstruct the sentences mentioned."}, {"heading": "4.3. Disentangled Representation", "text": "We will now examine the interpretable representations learned through our model. We will demonstrate the importance of the explicit limitation of independence that we introduce for untangled attribute control and interpretable text generation. Furthermore, we will show that our model produces convincing natural-language sentences and allows for convenient and accurate control of the generated attributes. We will first examine the effects of the limitation of independence on the unstructured code z, as introduced in Equation (7). Table 2 compares the samples generated by models with and without the conditional term. In the left column where the limitation applies, each sentence pair, caused by different sentiment codes, are highly relevant in terms of e.g. subject, tone and formulation, which are not explicitly modelled in the structured code c, while instead, implicitly in the unstructured code z is encoded. The variation of the sentient of being precisely changes the mood of the sentences generated (and paraphrases, if necessary, to ensure other aspects remain unchanged)."}, {"heading": "5. Conclusions & Discussions", "text": "Our approach combines VAEs with attribute discriminators and imposes explicit independence constraints on attribute controls, enabling learning of unbundled latent code. Semi-monitored learning within the extended UAE / Wake-Sleep framework is effective with little or incomplete monitoring. We show meaningful generation results and improved generation accuracy. Our method shows a strong potential for generating more complex texts and structured data. The interpretability of latent representations not only allows dynamic control of generated attributes, but also provides an interface that combines the end-to-end neural model with conventionally structured methods, enabling us to process structured constraints (e.g. logical rules or probable structured models) using the latent code generated to integrate prior knowledge or human intentions (Hu et al, 2016a; b)."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Bahdanau", "Dzmitry", "Cho", "Kyunghyun", "Bengio", "Yoshua"], "venue": "arXiv preprint arXiv:1409.0473,", "citeRegEx": "Bahdanau et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2014}, {"title": "Generating sentences from a continuous space", "author": ["Bowman", "Samuel R", "Vilnis", "Luke", "Vinyals", "Oriol", "Dai", "Andrew M", "Jozefowicz", "Rafal", "Bengio", "Samy"], "venue": "arXiv preprint arXiv:1511.06349,", "citeRegEx": "Bowman et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets", "author": ["Chen", "Xi", "Duan", "Yan", "Houthooft", "Rein", "Schulman", "John", "Sutskever", "Ilya", "Abbeel", "Pieter"], "venue": "In NIPS,", "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars)", "author": ["Diao", "Qiming", "Qiu", "Minghui", "Wu", "Chao-Yuan", "Smola", "Alexander J", "Jiang", "Jing", "Wang", "Chong"], "venue": "In KDD,", "citeRegEx": "Diao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Diao et al\\.", "year": 2014}, {"title": "Generating images with perceptual similarity metrics based on deep networks", "author": ["Dosovitskiy", "Alexey", "Brox", "Thomas"], "venue": "arXiv preprint arXiv:1602.02644,", "citeRegEx": "Dosovitskiy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dosovitskiy et al\\.", "year": 2016}, {"title": "A neural algorithm of artistic style", "author": ["Gatys", "Leon A", "Ecker", "Alexander S", "Bethge", "Matthias"], "venue": "arXiv preprint arXiv:1508.06576,", "citeRegEx": "Gatys et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gatys et al\\.", "year": 2015}, {"title": "Generative adversarial nets", "author": ["Goodfellow", "Ian", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"], "venue": "In NIPS,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Semi-supervised learning by entropy minimization", "author": ["Grandvalet", "Yves", "Bengio", "Yoshua"], "venue": "In NIPS,", "citeRegEx": "Grandvalet et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Grandvalet et al\\.", "year": 2004}, {"title": "The \u201cwake-sleep\u201d algorithm for unsupervised neural networks", "author": ["Hinton", "Geoffrey E", "Dayan", "Peter", "Frey", "Brendan J", "Neal", "Radford M"], "venue": null, "citeRegEx": "Hinton et al\\.,? \\Q1995\\E", "shortCiteRegEx": "Hinton et al\\.", "year": 1995}, {"title": "Harnessing deep neural networks with logic rules", "author": ["Hu", "Zhiting", "Ma", "Xuezhe", "Liu", "Zhengzhong", "Hovy", "Eduard", "Xing", "Eric"], "venue": "In ACL,", "citeRegEx": "Hu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2016}, {"title": "Deep neural networks with massive learned knowledge", "author": ["Hu", "Zhiting", "Yang", "Zichao", "Salakhutdinov", "Ruslan", "Xing", "Eric P"], "venue": "In EMNLP,", "citeRegEx": "Hu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hu et al\\.", "year": 2016}, {"title": "Adam: A method for stochastic optimization", "author": ["Kingma", "Diederik", "Ba", "Jimmy"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Auto-encoding variational bayes", "author": ["Kingma", "Diederik P", "Welling", "Max"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2013}, {"title": "Semi-supervised learning with deep generative models", "author": ["Kingma", "Diederik P", "Mohamed", "Shakir", "Rezende", "Danilo Jimenez", "Welling", "Max"], "venue": "In NIPS,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Deep convolutional inverse graphics network", "author": ["Kulkarni", "Tejas D", "Whitney", "William F", "Kohli", "Pushmeet", "Tenenbaum", "Josh"], "venue": "In NIPS, pp", "citeRegEx": "Kulkarni et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kulkarni et al\\.", "year": 2015}, {"title": "GANs for sequences of discrete elements with the gumbel-softmax distribution", "author": ["Kusner", "Matt", "Hernndez-Lobato", "Jos"], "venue": "arXiv preprint arXiv:1611.04051,", "citeRegEx": "Kusner et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kusner et al\\.", "year": 2016}, {"title": "Autoencoding beyond pixels using a learned similarity metric", "author": ["Larsen", "Anders Boesen Lindbo", "S\u00f8nderby", "S\u00f8ren Kaae", "Winther", "Ole"], "venue": "In ICML,", "citeRegEx": "Larsen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Larsen et al\\.", "year": 2016}, {"title": "Conditional image synthesis with auxiliary classifier gans", "author": ["Odena", "Augustus", "Olah", "Christopher", "Shlens", "Jonathon"], "venue": "arXiv preprint arXiv:1610.09585,", "citeRegEx": "Odena et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Odena et al\\.", "year": 2016}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["Radford", "Alec", "Metz", "Luke", "Chintala", "Soumith"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Training deep neural networks on noisy labels with bootstrapping", "author": ["Reed", "Scott", "Lee", "Honglak", "Anguelov", "Dragomir", "Szegedy", "Christian", "Erhan", "Dumitru", "Rabinovich", "Andrew"], "venue": "arXiv preprint arXiv:1412.6596,", "citeRegEx": "Reed et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reed et al\\.", "year": 2014}, {"title": "A hybrid convolutional variational autoencoder for text generation", "author": ["Semeniuta", "Stanislau", "Severyn", "Aliaksei", "Barth", "Erhardt"], "venue": "arXiv preprint arXiv:1702.02390,", "citeRegEx": "Semeniuta et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Semeniuta et al\\.", "year": 2017}, {"title": "Learning disentangled representations in deep generative models", "author": ["N. Siddharth", "Paige", "Brooks", "Desmaison", "Alban", "Meent", "Jan-Willem van de", "Wood", "Frank", "Goodman", "Noah D", "Kohli", "Pushmeet", "Torr", "Philip H.S"], "venue": null, "citeRegEx": "Siddharth et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Siddharth et al\\.", "year": 2017}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Socher", "Richard", "Perelygin", "Alex", "Wu", "Jean Y", "Chuang", "Jason", "Manning", "Christopher D", "Ng", "Andrew Y", "Potts", "Christopher"], "venue": "In EMNLP,", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Unsupervised sentence representation learning with adversarial auto-encoder", "author": ["Tang", "Shuai", "Jin", "Hailin", "Fang", "Chen", "Wang", "Zhaowen"], "venue": null, "citeRegEx": "Tang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Tang et al\\.", "year": 2016}, {"title": "Pixel recurrent neural networks", "author": ["van den Oord", "Aaron", "Kalchbrenner", "Nal", "Kavukcuoglu", "Koray"], "venue": "In ICML,", "citeRegEx": "Oord et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Oord et al\\.", "year": 2016}, {"title": "Show and tell: A neural image caption generator", "author": ["Vinyals", "Oriol", "Toshev", "Alexander", "Bengio", "Samy", "Erhan", "Dumitru"], "venue": "In CVPR,", "citeRegEx": "Vinyals et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Recognizing contextual polarity in phrase-level sentiment analysis", "author": ["Wilson", "Theresa", "Wiebe", "Janyce", "Hoffmann", "Paul"], "venue": "In EMNLP,", "citeRegEx": "Wilson et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Wilson et al\\.", "year": 2005}, {"title": "Pomdp-based statistical spoken dialog systems: A review", "author": ["Young", "Steve", "Ga\u0161i\u0107", "Milica", "Thomson", "Blaise", "Williams", "Jason D"], "venue": "Proceedings of the IEEE,", "citeRegEx": "Young et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Young et al\\.", "year": 2013}, {"title": "SeqGAN: sequence generative adversarial nets with policy gradient", "author": ["Yu", "Lantao", "Zhang", "Weinan", "Wang", "Jun", "Yong"], "venue": "In AAAI,", "citeRegEx": "Yu et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Yu et al\\.", "year": 2017}, {"title": "Generating text via adversarial training", "author": ["Zhang", "Yizhe", "Gan", "Zhe", "Carin", "Lawrence"], "venue": "In NIPS Workshop on Adversarial Training,", "citeRegEx": "Zhang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Generative visual manipulation on the natural image manifold", "author": ["Zhu", "Jun-Yan", "Kr\u00e4henb\u00fchl", "Philipp", "Shechtman", "Eli", "Efros", "Alexei A"], "venue": "In ECCV,", "citeRegEx": "Zhu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zhu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 6, "context": "There is a surge of research interest in deep generative models, such as Variational Autoencoders (VAEs) (Kingma & Welling, 2013), Generative Adversarial Nets (GANs) (Goodfellow et al., 2014), and auto-regressive models (van den Oord et al.", "startOffset": 166, "endOffset": 191}, {"referenceID": 18, "context": "Despite their impressive advances in visual domain, such as image generation (Radford et al., 2015), learning interpretable image representations (Chen et al.", "startOffset": 77, "endOffset": 99}, {"referenceID": 2, "context": ", 2015), learning interpretable image representations (Chen et al., 2016), and image editing (Zhu et al.", "startOffset": 54, "endOffset": 73}, {"referenceID": 30, "context": ", 2016), and image editing (Zhu et al., 2016), applications to natural language generation have been relatively less studied.", "startOffset": 27, "endOffset": 45}, {"referenceID": 0, "context": "Previous work have been mostly limited to task-specific applications in supervised settings, including machine translation (Bahdanau et al., 2014) and", "startOffset": 123, "endOffset": 146}, {"referenceID": 25, "context": "image captioning (Vinyals et al., 2015).", "startOffset": 17, "endOffset": 39}, {"referenceID": 1, "context": "Very few recent attempts of using VAEs (Bowman et al., 2015; Tang et al., 2016) and GANs (Yu et al.", "startOffset": 39, "endOffset": 79}, {"referenceID": 23, "context": "Very few recent attempts of using VAEs (Bowman et al., 2015; Tang et al., 2016) and GANs (Yu et al.", "startOffset": 39, "endOffset": 79}, {"referenceID": 28, "context": ", 2016) and GANs (Yu et al., 2017; Zhang et al., 2016) have been made to investigate generic text generation, while their generated text is largely randomized and uncontrollable.", "startOffset": 17, "endOffset": 54}, {"referenceID": 29, "context": ", 2016) and GANs (Yu et al., 2017; Zhang et al., 2016) have been made to investigate generic text generation, while their generated text is largely randomized and uncontrollable.", "startOffset": 17, "endOffset": 54}, {"referenceID": 2, "context": "The resulting non-differentiability hinders the use of global discriminators that assess generated samples and back-propagate gradients to guide the optimization of generators in a holistic manner, as shown to be highly effective in continuous image generation and representation modeling (Chen et al., 2016; Larsen et al., 2016; Dosovitskiy & Brox, 2016).", "startOffset": 289, "endOffset": 355}, {"referenceID": 16, "context": "The resulting non-differentiability hinders the use of global discriminators that assess generated samples and back-propagate gradients to guide the optimization of generators in a holistic manner, as shown to be highly effective in continuous image generation and representation modeling (Chen et al., 2016; Larsen et al., 2016; Dosovitskiy & Brox, 2016).", "startOffset": 289, "endOffset": 355}, {"referenceID": 28, "context": "A number of recent approaches attempt to address the non-differentiability through policy learning (Yu et al., 2017) which tends to suffer from high variance during training, or continuous approximations (Zhang et al.", "startOffset": 99, "endOffset": 116}, {"referenceID": 29, "context": ", 2017) which tends to suffer from high variance during training, or continuous approximations (Zhang et al., 2016; Kusner & Hernndez-Lobato, 2016) where only preliminary qualitative results are presented.", "startOffset": 95, "endOffset": 147}, {"referenceID": 11, "context": "As an alternative to the discriminator based learning, semi-supervised VAEs (Kingma et al., 2014) minimize element-wise reconstruction error on observed examples and are applicable to discrete visibles.", "startOffset": 76, "endOffset": 97}, {"referenceID": 2, "context": "Prior methods (Chen et al., 2016; Odena et al., 2016) on structured representation learning lack explicit enforcement of the independence property on the full latent representation, and varying individual code may result in unexpected variation of other unspecified attributes in addition to the desired one.", "startOffset": 14, "endOffset": 53}, {"referenceID": 17, "context": "Prior methods (Chen et al., 2016; Odena et al., 2016) on structured representation learning lack explicit enforcement of the independence property on the full latent representation, and varying individual code may result in unexpected variation of other unspecified attributes in addition to the desired one.", "startOffset": 14, "endOffset": 53}, {"referenceID": 8, "context": "Our model can be interpreted as enhancing VAEs with an extended wake-sleep procedure (Hinton et al., 1995), where the sleep phase enables incorporation of generated samples for learning both the generator and discriminators in an alternating manner.", "startOffset": 85, "endOffset": 106}, {"referenceID": 8, "context": "The wake-sleep algorithm (Hinton et al., 1995) introduced for training deep directed graphical models shares similarity with VAEs by also combining an inference network with the generator.", "startOffset": 25, "endOffset": 46}, {"referenceID": 6, "context": "For instance, GANs (Goodfellow et al., 2014) use a discriminator to feedback the probability of a sample being recognized as a real example.", "startOffset": 19, "endOffset": 44}, {"referenceID": 2, "context": "For instance, InfoGAN (Chen et al., 2016), which resembles the sleep procedure of our extended VAE/wakesleep algorithm, disentangles latent representation in an unsupervised manner, while the semantic of each dimension is observed after training rather than designated by users in a controllable way.", "startOffset": 22, "endOffset": 41}, {"referenceID": 3, "context": "For instance, GANs (Goodfellow et al., 2014) use a discriminator to feedback the probability of a sample being recognized as a real example. Larsen et al. (2016) combine VAEs with GANs for enhanced image generation.", "startOffset": 20, "endOffset": 162}, {"referenceID": 3, "context": "For instance, GANs (Goodfellow et al., 2014) use a discriminator to feedback the probability of a sample being recognized as a real example. Larsen et al. (2016) combine VAEs with GANs for enhanced image generation. Dosovitskiy & Brox (2016); Gatys et al.", "startOffset": 20, "endOffset": 242}, {"referenceID": 3, "context": "Dosovitskiy & Brox (2016); Gatys et al. (2015) use discriminator networks for measuring high-level perceptual similarity.", "startOffset": 27, "endOffset": 47}, {"referenceID": 3, "context": "Dosovitskiy & Brox (2016); Gatys et al. (2015) use discriminator networks for measuring high-level perceptual similarity. Applying discriminators to text generation is difficult due to the non-differentiability of the discrete samples. Yu et al. (2017) resort to policy learning which tends to have high variance during training.", "startOffset": 27, "endOffset": 253}, {"referenceID": 3, "context": "Dosovitskiy & Brox (2016); Gatys et al. (2015) use discriminator networks for measuring high-level perceptual similarity. Applying discriminators to text generation is difficult due to the non-differentiability of the discrete samples. Yu et al. (2017) resort to policy learning which tends to have high variance during training. Zhang et al. (2016); Kusner & Hernndez-Lobato (2016) apply continuous approximations with only preliminary qualitative results.", "startOffset": 27, "endOffset": 350}, {"referenceID": 3, "context": "Dosovitskiy & Brox (2016); Gatys et al. (2015) use discriminator networks for measuring high-level perceptual similarity. Applying discriminators to text generation is difficult due to the non-differentiability of the discrete samples. Yu et al. (2017) resort to policy learning which tends to have high variance during training. Zhang et al. (2016); Kusner & Hernndez-Lobato (2016) apply continuous approximations with only preliminary qualitative results.", "startOffset": 27, "endOffset": 383}, {"referenceID": 1, "context": "Bowman et al. (2015); Tang et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 1, "context": "Bowman et al. (2015); Tang et al. (2016) instead use VAEs without discriminators.", "startOffset": 0, "endOffset": 41}, {"referenceID": 1, "context": "Bowman et al. (2015); Tang et al. (2016) instead use VAEs without discriminators. All these text generation methods do not learn disentangled latent representations, resulting in randomized and uncontrollable samples. In contrast, disentangled generation in visual domain has made impressive progress. For instance, InfoGAN (Chen et al., 2016), which resembles the sleep procedure of our extended VAE/wakesleep algorithm, disentangles latent representation in an unsupervised manner, while the semantic of each dimension is observed after training rather than designated by users in a controllable way. Siddharth et al. (2017); Kulkarni et al.", "startOffset": 0, "endOffset": 627}, {"referenceID": 1, "context": "Bowman et al. (2015); Tang et al. (2016) instead use VAEs without discriminators. All these text generation methods do not learn disentangled latent representations, resulting in randomized and uncontrollable samples. In contrast, disentangled generation in visual domain has made impressive progress. For instance, InfoGAN (Chen et al., 2016), which resembles the sleep procedure of our extended VAE/wakesleep algorithm, disentangles latent representation in an unsupervised manner, while the semantic of each dimension is observed after training rather than designated by users in a controllable way. Siddharth et al. (2017); Kulkarni et al. (2015); Kingma et al.", "startOffset": 0, "endOffset": 651}, {"referenceID": 1, "context": "Bowman et al. (2015); Tang et al. (2016) instead use VAEs without discriminators. All these text generation methods do not learn disentangled latent representations, resulting in randomized and uncontrollable samples. In contrast, disentangled generation in visual domain has made impressive progress. For instance, InfoGAN (Chen et al., 2016), which resembles the sleep procedure of our extended VAE/wakesleep algorithm, disentangles latent representation in an unsupervised manner, while the semantic of each dimension is observed after training rather than designated by users in a controllable way. Siddharth et al. (2017); Kulkarni et al. (2015); Kingma et al. (2014) build in the context of VAEs and obtain disentangled image representations with semi-supervised learning.", "startOffset": 0, "endOffset": 673}, {"referenceID": 1, "context": "We build our framework starting from variational autoencoders (section 2) which have been used for text generation (Bowman et al., 2015; Semeniuta et al., 2017), where sentence x\u0302 is generated conditioned on latent code z.", "startOffset": 115, "endOffset": 160}, {"referenceID": 20, "context": "We build our framework starting from variational autoencoders (section 2) which have been used for text generation (Bowman et al., 2015; Semeniuta et al., 2017), where sentence x\u0302 is generated conditioned on latent code z.", "startOffset": 115, "endOffset": 160}, {"referenceID": 7, "context": "To alleviate the issue of noisy data and ensure robustness of model optimization, we incorporate a minimum entropy regularization term (Grandvalet et al., 2004; Reed et al., 2014).", "startOffset": 135, "endOffset": 179}, {"referenceID": 19, "context": "To alleviate the issue of noisy data and ensure robustness of model optimization, we incorporate a minimum entropy regularization term (Grandvalet et al., 2004; Reed et al., 2014).", "startOffset": 135, "endOffset": 179}, {"referenceID": 3, "context": "We use a large IMDB text corpus (Diao et al., 2014) for training the generative models.", "startOffset": 32, "endOffset": 51}, {"referenceID": 22, "context": "To control the sentiment (\u201cpositive\u201d or \u201cnegative\u201d) of generated sentences, we test on the following labeled sentiment data: (1) Stanford Sentiment Treebank-2 (SST-full) (Socher et al., 2013) consists of 6920/872/1821 movie review sentences with binary sentiment annotations in the train/dev/test sets, respectively.", "startOffset": 170, "endOffset": 191}, {"referenceID": 26, "context": "The lexicon from (Wilson et al., 2005) contains 2700 words with sentiment labels.", "startOffset": 17, "endOffset": 38}, {"referenceID": 11, "context": "model (Kingma et al., 2014).", "startOffset": 6, "endOffset": 27}, {"referenceID": 1, "context": "To avoid vanishingly small KL term in the VAE (Bowman et al., 2015), we use a KL term weight linearly annealing from 0 to 1 during training.", "startOffset": 46, "endOffset": 67}, {"referenceID": 11, "context": "We compare our model with the semi-supervised variational autoencoder (S-VAE) (Kingma et al., 2014), one of the few existing deep generative models capable of conditional sentence generation.", "startOffset": 78, "endOffset": 99}, {"referenceID": 27, "context": ", 2016a;b); or plug the disentangled generation model into dialog systems to generate natural language responses from structured dialog states (Young et al., 2013).", "startOffset": 143, "endOffset": 163}], "year": 2017, "abstractText": "Generic generation and manipulation of text is challenging and has limited success compared to recent deep generative modeling in visual domain. This paper aims at generating plausible natural language sentences, whose attributes are dynamically controlled by learning disentangled latent representations with designated semantics. We propose a new neural generative model which combines variational auto-encoders and holistic attribute discriminators for effective imposition of semantic structures. With differentiable approximation to discrete text samples, explicit constraints on independent attribute controls, and efficient collaborative learning of generator and discriminators, our model learns highly interpretable representations from even only word annotations, and produces realistic sentences with desired attributes. Quantitative evaluation validates the accuracy of sentence and attribute generation.", "creator": "LaTeX with hyperref package"}}}