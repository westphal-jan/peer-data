{"id": "1703.01014", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2017", "title": "Active Learning for Cost-Sensitive Classification", "abstract": "We design an active learning algorithm for cost-sensitive multiclass classification: problems where different errors have different costs. Our algorithm, COAL, makes predictions by regressing on each label's cost and predicting the smallest. On a new example, it uses a set of regressors that perform well on past data to estimate possible costs for each label. It queries only the labels that could be the best, ignoring the sure losers. We prove COAL can be efficiently implemented for any regression family that admits squared loss optimization; it also enjoys strong guarantees with respect to predictive performance and labeling effort. We empirically compare COAL to passive learning, showing significant improvements in labeling effort and test cost.", "histories": [["v1", "Fri, 3 Mar 2017 02:17:13 GMT  (178kb,D)", "http://arxiv.org/abs/1703.01014v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["akshay krishnamurthy", "alekh agarwal", "tzu-kuo huang", "hal daum\u00e9 iii", "john langford"], "accepted": true, "id": "1703.01014"}, "pdf": {"name": "1703.01014.pdf", "metadata": {"source": "CRF", "title": "Active Learning for Cost-Sensitive Classification", "authors": ["Akshay Krishnamurthy", "Alekh Agarwal", "Tzu-Kuo Huang", "John Langford"], "emails": ["akshay@cs.umass.edu", "alekha@microsoft.com", "tkhuang@protonmail.com", "hal@umiacs.umd.edu", "jcl@microsoft.com"], "sections": [{"heading": "1 Introduction", "text": "The question is about the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way in which they learn from the way"}, {"heading": "2 Problem Setting and Notations", "text": "And I think it's important to say that I'm not going to talk about it, but I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about it, and I'm going to talk about"}, {"heading": "3 Cost Overlapped Active Learning", "text": "The pseudo-codes for our algorithms, Cost Overlapped Active Learning (COAL), are given in algorithm 1 (example x, COAL), which queries the cost of some of the labels y for x. These costs are determined by (1) calculating an approximate version space based on past data, (2) calculating the range of predictions that can be achieved by the version space, and (3) querying any y that could be the best designation and has significant uncertainty. We now detail each step. Algorithm 1: Cost Overlapped Active Learning (COAL) 1: Input: Regressor G, Failure probability (0, security)."}, {"heading": "3.1 Efficient Computation of Cost Range", "text": "In this section we describe the subroutines MAXCOST and MINCOST, which use the oracle to calculate approximations to the maximum and minimum cost, those of Gi (y), the current version of Space (Eq. (2). The description of the algorithm requires additional notation. Given the empirical risk (g; y) over a set of examples (g; y) over a set of examples (g; y) over a set of examples (g; y) over a set of examples (g; y) over a set of examples (g; y) over a set of examples (g) over a set of examples (g). (g, c) over a weighted risk (g, c; y)."}, {"heading": "4 Generalization Analysis", "text": "In this section we derive generalization guarantees for COAL. Our analysis assumes that the regressor set G is large but limited. We examine two different settings: one with minimal assumptions and one with low-noise adjustment.Our low-noise assumption refers to the state of Massart [21], which assumes in the binary classification that the optimal Bayes predictor of 1 / 2 for all x. Our condition generalizes this to CSMC and postulates that the expected cost of the best label is separated from the expected cost of all other labels. Assumption 2: A distribution D supports over (x, c) pairs meet the state of Massart Noise, if there is such a condition that for all x (with D) > 0) > 0), f? (x; y? (x) \u2264 y?"}, {"heading": "5 Label Complexity Analysis", "text": "Without distribution assumptions, distribution coefficients are defined as such. (...) Without distribution assumptions, distribution coefficients are defined as such. (...) Without distribution assumptions, distribution coefficients are defined as such. (...) Without distribution assumptions, distribution coefficients are defined as such. (...) Without distribution assumptions, distribution coefficients are defined as such. (...) Without distribution assumptions, distribution coefficients are defined as such. (...) Without distribution assumptions, distribution coefficients are defined as such. (...) Without distribution assumptions, distribution coefficients are defined as such. (...) Without distribution assumptions, distribution coefficients are defined as such. (...)"}, {"heading": "5.1 Some Examples", "text": "Our first example shows that querying only the non-dominated labels can dramatically reduce label complexity. Consider a problem under assumption 2, where the optimal costs are accurately predicted, the second best costs are worse, and all other costs are much worse, but with variations in predictions. Since all classifiers predict the correct label, we get Phenomen1 = Phenomen2 = 0, so our label complexity limit is O (1). Since each regressor is always sure of the optimal label and its cost, we do not actually perform queries. On the other hand, all sub-optimal labels have large cost ranges, and therefore the query is highly complex based solely on cost criteria. A related example shows the improvement in our query control over na\u00efve labels, where we either do not query labels or all labels, which is the natural generalization of the query criteria of large label complexities."}, {"heading": "6 Experiments", "text": "To calculate the efficiency, we have implemented an approximate version of algorithm 1, which is based on the online linear regression of the smallest squares. The algorithm processes the data in one operation and calculates an approximate ERM and cost ranges, as described below. Concretely, we define a sensitivity value s (x, c, goi, y) \u2265 0, which is the derivative of the prediction on x as a function of the importance weight w, for a fresh example x and costs c = 0 or c = 1 (for the approximation of c \u2212 or c +). Then, we approach c \u2212 via goi, y (x) \u2212 where \u00b7 s (x, 0, goi, y), y) where where where where where where where where where where where where where where where where the greatest weight is satisfactory (gow, or c +), where we use the gow (y), y (y \u2212), y (where we use \u2212), y (y) where."}, {"heading": "6.1 Simulated Active Learning", "text": "We conducted simulated learning experiments with three sets of data. ImageNet 20 and 40 are sub-trees of the ImageNet hierarchy, covering 20 and 40 most common classes, each example having a single zero-cost label and the cost of false labels being the tree distance to the correct ones. The feature vectors are the top layer of the Inception neural network [29]. The third dataset, RCV1-v2 [19], is a multi-label text categorization dataset, which has 103 topic names, organized as a tree with a similar tree distance cost structure to the ImageNet data. Some dataset statistics are in Figure 2 (upper right). We compare our online version of COAL to passive online learning. We use the cost-sensitive one-against-all (CSOAA) implementation in Vowpal Wabbit4, which performs linear regression for each label separately."}, {"heading": "6.2 Learning to Search", "text": "We are experimenting with COAL as the basis leaner in Learning-to-Search [13, 11], which reduces common prediction problems to CSMC. Within this framework, a common prediction example defines a search space in which a sequence of decisions is made to generate the structured label. Here, we focus on sequence markers in which the input is a sequence of words and the output is a sequence of labels (specific, parts of the speech, or named entities). Learning-to-Search solves common prediction problems by conditioning the input x on all previous decisions. Since errors lead to compounding errors, it is natural to present the decision space as a CSMC problem in which the classes are available for a word."}, {"heading": "7 Discussion", "text": "This paper presents a new active learning algorithm for the cost-sensitive classification of multi-classes. The algorithm enjoys strong theoretical guarantees in terms of runtime, generalization errors, and label complexity, and also outperforms passive baselines in both CSMC and structured predictions. We conclude with some interesting questions: 1. Can we use a square loss oracle for other partial information problems such as contextual bandits? 2. Can we avoid the security parameter to achieve optimum complexity in the low-noise case? We hope to answer these questions in future work."}, {"heading": "A Experimental Details", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A.1 Finding Cost Ranges with Online Approximation", "text": "Consider the maximum and minimum costs of a specified label y in round i, both of which can be suppressed. (Due to the monotonous property of R (g, w, c; y) (Lemma 1), an alternative to MINCOST and MAXCOST it is possible to consider the maximum (g) costs (g, y) as the minimum and maximum costs (g, y) as the minimum and maximum costs (g, y) as the minimum and maximum costs (g, y) as the minimum and maximum costs (g, y) as the minimum and maximum costs (g, y) as the minimum and maximum costs (x, y) as the minimum and maximum costs (x), where the minimum costs (g) as the minimum and maximum costs (g) as the maximum costs (g)."}, {"heading": "A.2 Choosing the Learning Rate", "text": "For all experiments, we show the results obtained by the best learning rate for each softness on each dataset. We select the best learning rate as follows: For each dataset, we leave perf (m, l, q, t) the test performance of the algorithm using softness m and learning rate l on the tth permutation of the training data under a query budget of 2 (q \u2212 1) \u00b7 10 \u00b7 K, q \u2265 1. Let the query (m, l, q, t) specify the number of queries actually made. Note that query (m, l, q, t) < 2 (q \u2212 1) \u00b7 10 \u00b7 K if the algorithm runs out of training data before reaching the qth query 6. To evaluate the trade between test performance and number of queries, we define the following performance measurement: AUC (m, l, t) = 12 qmax."}, {"heading": "A.3 Additional Figures for Simulated Active Learning", "text": "Figure 3 shows the test error depending on the number of examples for which at least one query has been requested, for each data set and each mellowness parameter. Experimentally, this corresponds to the term L1 in our label complexity analysis. 6In fact, we only check test performance between examples, so the query (m, l, q, t) may be greater than 2 (q \u2212 1) \u00b7 10 \u00b7 K by an additive factor K, which is negligibly low. Compared to Figure 2, which includes the total number of queries, the improvements through active learning here are a little less dramatic. This suggests that our algorithm only queries a few labels for each example, but in most examples it does end up with at least one query. Nevertheless, with a factor of 2-16 less labeling effort compared to L1, you can achieve test costs that are competitive with passive learning."}, {"heading": "B Running time analysis", "text": "We focus on the approximation of c + (x, G) \u2212 g (see Eqs. (2) and (7), where the approximation of the minimum cost is very similar. To simplify the notation, we drop the dependence on x and y. (We also remember some other important notation parts, which are suitably simplified for brevityR (g) = E (g) \u2212 c (y) \u2212 c (y) (y), unless we leave the dependence on both y and i fixed in this appendix. (We also remember some other important notation parts, which are suitably simplified for brevityR (g) \u2212 c (y) \u2212 c (y) \u2212 c (y), which are set to x) G (g) = {g)."}, {"heading": "C Generalization analysis", "text": "To limit the generalization error of algorithm 1, we start with the definition of the central random variable in the analysis. In round i, we remember our notation Qi (y) = 1 (query y on example xi), which indicates the query rule. (12) The central random variable we examine is Mi (g; y), (g (xi) \u2212 ci (y)) 2 \u2212 (f? (xi; y) 2) Qi (y). (12) Here (xi, ci) is the ith example and the costs presented to the algorithm. For simplicity, we write Mi when the dependence on g and y is clear from the context. For a vector regressor f, we write Mi (f; y), Mi (f (y); y).We also remember some of the key constants and notations defined in algorithm 1 and used heavily in this appendix."}, {"heading": "C.1 Supporting Lemmata", "text": "Theorem 7 (Freedman-type Inequality = 8, 2]. Let X1,., XT be a sequence of real-weighted random variables. (Xt \u2212 1) Suppose that for all t-type Inequality = 8, 2,., T that | Xt | \u2264 R and E [Xt | X1,., Xt \u2212 1 = 0. Define S = \u2212 xi \u2212 \u2212 T = \u2264 E [X2t | X1,., Xt \u2212 1]. For all other Qt (0, 1) and \u03bb [0, 1 / R], with a probability of at least 1 \u2212 x, S \u2264 (e \u2212 2)."}, {"heading": "C.2 Proof of Theorem 3", "text": "The condition for the high probability event in Lemon 5 is that we confirm the theorem by induction. Let's define that i = min {1, \u03ba\u03bdn i \u2212 1}, sound n = log (2n2 | G \u00b2 K \u00b2). Furthermore, we will apply the following simple fact that applies since i \u2264 n, so that the premultiplier on i is at least 1st fact 1. for all i \u00b2 -1 and Ex, c [c (hfi (x))), we will consider the inductive hypothesis: \"i \u00b2 1, R \u00b2 i (f? (\u00b7 y); y) \u2264 min g \u00b2, g \u00b2 G R \u00b2 i (g; y), sound n and Ex, c [c (hf? (x)))))). Let's assume that we have the minimum requirement > 0 {s \u00b2 i (13), where c0 = 10. The first assertion implies that f? (y)."}, {"heading": "D Label complexity analysis", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "D.1 Supporting Lemmata", "text": "Our label complexity analysis is based on the following definition, which uses the sentences G? \u03b2 and G? \u03b2 (\u03b2) and G? \u03b2 (\u03b2), whose definitions we reproduce. (\u03b2; y), (g), (n), (n), (n), (n), (n), (b), (g), (g), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c), (c, (c), (c), (c), (c), (c), (c), (c), (c, (c), (c, (c), (c), (c), (c), (c, (c), (c), (), (, (), (, (), (), (, (), (, (), (, (, (), (, (), (, (), (, (, (, (, (), (,), (, (, (, (,), (, (, (,), (, (, (, (,), (,, (,, (,),, (,), (, (, (, (,), (,), (,), (, (, (,), (, (, (,), (,), (,, (,),"}, {"heading": "In both bounds, all the cost ranges are computed using Fcsr(rI\u03b2(i)).", "text": "Prove that y-y-i-xi-i-xi-i-xi-i-xi-i-xi-i-xi-i-xi-xi-i-xi-xi-i-xi-xi-i-xi-xi-i-xi-xi-i-xi-i-xi-i-xi-xi-i-xi-xi-i-xi-xi-xi-xi-i-xi-xi-i-xi-xi-i-xi-xi-i-xi-xi-i-xi-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-xi-xi-xi-xi-xi-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-xi-xi-xi-xi-xi-xi-xi-xi-xi-i-xi-i-i-xi-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-i-xi-xi-i-i-i-xi-i-i-xi-i-i-i-i-xi-i-i-i-xi-i-i-i-xi-i-i-i-i-xi-i-i-i-i-xi-i-i-i-i-xi-i-i-i-xi-i-i-xi-i-i-xi-i-i-i-i-xi-xi-i-i-i-i-xi-i-i-i-i-i-i-xi-i-i-i-i-xi-xi-i-i-xi-xi-i-i-xi-i-i-i-xi-xi-i-i-i-i-i-i-xi-i-xi-i-i-i-xi-xi-i-xi-i-i-i-xi-xi-i-i-i"}, {"heading": "D.2 Low Noise (Massart) Case (Theorem 6)", "text": "We have to do two things with qi (y), so we have to make sure that there is a vector regressor that is used in round i (y). (i) We have to do two things with qi (y). (i) We have to do two things with qi (y). (i) We have to do two things with qi (y). (i) We have to do two things with qi (y). (i) We have to do two things with qi (y). (i) We have to do two things with qi (y). (i) We have to do two things with qi (y). (i) We have to do two things with qi. (i) We have to do two things with qi."}, {"heading": "D.3 High noise case (Theorem 5)", "text": "There are a number of vector regressors that are used in the Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi Gi"}], "references": [{"title": "Selective sampling algorithms for cost-sensitive multiclass prediction", "author": ["A. Agarwal"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 2013}, {"title": "Taming the monster: A fast and simple algorithm for contextual bandits", "author": ["A. Agarwal", "D. Hsu", "S. Kale", "J. Langford", "L. Li", "R.E. Schapire"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2014}, {"title": "Active and passive learning of linear separators under log-concave distributions", "author": ["M.-F. Balcan", "P. Long"], "venue": "In Conference on Learning Theory,", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2013}, {"title": "Agnostic active learning", "author": ["M.-F. Balcan", "A. Beygelzimer", "J. Langford"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2006}, {"title": "Margin based active learning", "author": ["M.-F. Balcan", "A. Broder", "T. Zhang"], "venue": "In Conference on Learning Theory,", "citeRegEx": "5", "shortCiteRegEx": "5", "year": 2007}, {"title": "Importance weighted active learning", "author": ["A. Beygelzimer", "S. Dasgupta", "J. Langford"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2009}, {"title": "Agnostic active learning without constraints", "author": ["A. Beygelzimer", "D. Hsu", "J. Langford", "T. Zhang"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2010}, {"title": "Contextual bandit algorithms with supervised learning guarantees", "author": ["A. Beygelzimer", "J. Langford", "L. Li", "L. Reyzin", "R.E. Schapire"], "venue": "In Artificial Intelligence and Statistics,", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2011}, {"title": "Minimax bounds for active learning", "author": ["R.M. Castro", "R.D. Nowak"], "venue": "Transaction on Information Theory,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2008}, {"title": "Learning noisy linear classifiers via adaptive and selective sampling", "author": ["G. Cavallanti", "N. Cesa-Bianchi", "C. Gentile"], "venue": "Machine Learning,", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2011}, {"title": "Learning to search better than your teacher", "author": ["K.-W. Chang", "A. Krishnamurthy", "A. Agarwal", "H. Daum\u00e9 III", "J. Langford"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2015}, {"title": "A general agnostic active learning algorithm", "author": ["S. Dasgupta", "D. Hsu", "C. Monteleoni"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2007}, {"title": "Search-based structured prediction", "author": ["H. Daum\u00e9 III", "J. Langford", "D. Marcu"], "venue": "Machine Learning,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2009}, {"title": "Robust selective sampling from single and multiple teachers", "author": ["O. Dekel", "C. Gentile", "K. Sridharan"], "venue": "In Conference on Learning Theory,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2010}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer"], "venue": "In Conference on Learning Theory,", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2010}, {"title": "Theory of disagreement-based active learning", "author": ["S. Hanneke"], "venue": "Foundations and Trends in Machine Learning,", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2014}, {"title": "Efficient and parsimonious agnostic active learning", "author": ["T.-K. Huang", "A. Agarwal", "D.J. Hsu", "J. Langford", "R.E. Schapire"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2015}, {"title": "Online importance weight aware updates", "author": ["N. Karampatziakis", "J. Langford"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 2011}, {"title": "Rcv1: A new benchmark collection for text categorization research", "author": ["D.D. Lewis", "Y. Yang", "T.G. Rose", "F. Li"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2004}, {"title": "The weighted majority algorithm", "author": ["N. Littlestone", "M.K. Warmuth"], "venue": "In Foundations of Computer Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 1989}, {"title": "Risk bounds for statistical learning", "author": ["P. Massart", "\u00c9. N\u00e9d\u00e9lec"], "venue": "The Annals of Statistics,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 2006}, {"title": "Better algorithms for selective sampling", "author": ["F. Orabona", "N. Cesa-Bianchi"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 2011}, {"title": "Reinforcement and imitation learning via interactive no-regret learning", "author": ["S. Ross", "J.A. Bagnell"], "venue": null, "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2014}, {"title": "Normalized online learning", "author": ["S. Ross", "P. Mineiro", "J. Langford"], "venue": "In Uncertainty in Artificial Intelligence,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2013}, {"title": "Active learning", "author": ["B. Settles"], "venue": "Synthesis Lectures on Artificial Intelligence and Machine Learning,", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2012}, {"title": "Learning where to sample in structured prediction", "author": ["T. Shi", "J. Steinhardt", "P. Liang"], "venue": "In Artificial Intelligence and Statistics,", "citeRegEx": "26", "shortCiteRegEx": "26", "year": 2015}, {"title": "A survey of hierarchical classification across different application domains", "author": ["C.N. Silla Jr.", "A.A. Freitas"], "venue": "Data Mining and Knowledge Discovery,", "citeRegEx": "27", "shortCiteRegEx": "27", "year": 2011}, {"title": "Efficient algorithms for adversarial contextual learning", "author": ["V. Syrgkanis", "A. Krishnamurthy", "R.E. Schapire"], "venue": "In International Conference on Machine Learning,", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2016}, {"title": "Going deeper with convolutions", "author": ["C. Szegedy", "W. Liu", "Y. Jia", "P. Sermanet", "S.E. Reed", "D. Anguelov", "D. Erhan", "V. Vanhoucke", "A. Rabinovich"], "venue": "In Computer Vision and Pattern Recognition,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2015}, {"title": "Beyond disagreement-based agnostic active learning", "author": ["C. Zhang", "K. Chaudhuri"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2014}], "referenceMentions": [{"referenceID": 5, "context": "This computation, and COAL as a whole, only requires that the regression set admits efficient squared loss optimization, in contrast with prior algorithms that require 0/1 loss optimization [6, 16].", "startOffset": 190, "endOffset": 197}, {"referenceID": 15, "context": "This computation, and COAL as a whole, only requires that the regression set admits efficient squared loss optimization, in contrast with prior algorithms that require 0/1 loss optimization [6, 16].", "startOffset": 190, "endOffset": 197}, {"referenceID": 26, "context": "For example, CSMC can naturally express partial failure in hierarchical classification [27].", "startOffset": 87, "endOffset": 91}, {"referenceID": 12, "context": "CSMC also forms the basis of learning to avoid cascading failures in joint prediction tasks [13, 23, 11] like structured prediction and reinforcement learning.", "startOffset": 92, "endOffset": 104}, {"referenceID": 22, "context": "CSMC also forms the basis of learning to avoid cascading failures in joint prediction tasks [13, 23, 11] like structured prediction and reinforcement learning.", "startOffset": 92, "endOffset": 104}, {"referenceID": 10, "context": "CSMC also forms the basis of learning to avoid cascading failures in joint prediction tasks [13, 23, 11] like structured prediction and reinforcement learning.", "startOffset": 92, "endOffset": 104}, {"referenceID": 10, "context": "As our second application, we consider learning to search algorithms for joint (or structured) prediction [11], which operate by a reduction to CSMC.", "startOffset": 106, "endOffset": 110}, {"referenceID": 22, "context": "We show that using COAL within the AGGRAVATE algorithm [23, 11] reduces the number of roll-outs by a factor of 14 to 3 4 on several joint prediction tasks.", "startOffset": 55, "endOffset": 63}, {"referenceID": 10, "context": "We show that using COAL within the AGGRAVATE algorithm [23, 11] reduces the number of roll-outs by a factor of 14 to 3 4 on several joint prediction tasks.", "startOffset": 55, "endOffset": 63}, {"referenceID": 24, "context": "We recommend the survey of Settles [25] for an overview of more empirical research.", "startOffset": 35, "endOffset": 39}, {"referenceID": 8, "context": "Castro and Nowak [9] study active learning for binary classification with non-parametric decision sets, while Balcan et al.", "startOffset": 17, "endOffset": 20}, {"referenceID": 4, "context": "[5], Balcan and Long [3] focus on linear representations under distributional assumptions.", "startOffset": 0, "endOffset": 3}, {"referenceID": 2, "context": "[5], Balcan and Long [3] focus on linear representations under distributional assumptions.", "startOffset": 21, "endOffset": 24}, {"referenceID": 9, "context": "Additionally, the selective sampling framework from the online learning community derives regret and label complexity bounds for stream-based active learning of linear separators under adversarial assumptions [10, 14, 22, 1].", "startOffset": 209, "endOffset": 224}, {"referenceID": 13, "context": "Additionally, the selective sampling framework from the online learning community derives regret and label complexity bounds for stream-based active learning of linear separators under adversarial assumptions [10, 14, 22, 1].", "startOffset": 209, "endOffset": 224}, {"referenceID": 21, "context": "Additionally, the selective sampling framework from the online learning community derives regret and label complexity bounds for stream-based active learning of linear separators under adversarial assumptions [10, 14, 22, 1].", "startOffset": 209, "endOffset": 224}, {"referenceID": 0, "context": "Additionally, the selective sampling framework from the online learning community derives regret and label complexity bounds for stream-based active learning of linear separators under adversarial assumptions [10, 14, 22, 1].", "startOffset": 209, "endOffset": 224}, {"referenceID": 15, "context": "Our work falls into the framework of disagreement-based active learning, which studies general hypothesis spaces typically in an agnostic setup (see Hanneke [16] for an excellent survey).", "startOffset": 157, "endOffset": 161}, {"referenceID": 3, "context": "In contrast, prior work either explicitly enumerates the version space [4, 30] or uses a 0/1 loss classification oracle for the search [12, 6, 7, 17].", "startOffset": 71, "endOffset": 78}, {"referenceID": 29, "context": "In contrast, prior work either explicitly enumerates the version space [4, 30] or uses a 0/1 loss classification oracle for the search [12, 6, 7, 17].", "startOffset": 71, "endOffset": 78}, {"referenceID": 11, "context": "In contrast, prior work either explicitly enumerates the version space [4, 30] or uses a 0/1 loss classification oracle for the search [12, 6, 7, 17].", "startOffset": 135, "endOffset": 149}, {"referenceID": 5, "context": "In contrast, prior work either explicitly enumerates the version space [4, 30] or uses a 0/1 loss classification oracle for the search [12, 6, 7, 17].", "startOffset": 135, "endOffset": 149}, {"referenceID": 6, "context": "In contrast, prior work either explicitly enumerates the version space [4, 30] or uses a 0/1 loss classification oracle for the search [12, 6, 7, 17].", "startOffset": 135, "endOffset": 149}, {"referenceID": 16, "context": "In contrast, prior work either explicitly enumerates the version space [4, 30] or uses a 0/1 loss classification oracle for the search [12, 6, 7, 17].", "startOffset": 135, "endOffset": 149}, {"referenceID": 1, "context": "Supervised learning oracles that solve NP-hard optimization problems in the worst case have been used in other problems including contextual bandits [2, 28] and structured prediction [13].", "startOffset": 149, "endOffset": 156}, {"referenceID": 27, "context": "Supervised learning oracles that solve NP-hard optimization problems in the worst case have been used in other problems including contextual bandits [2, 28] and structured prediction [13].", "startOffset": 149, "endOffset": 156}, {"referenceID": 12, "context": "Supervised learning oracles that solve NP-hard optimization problems in the worst case have been used in other problems including contextual bandits [2, 28] and structured prediction [13].", "startOffset": 183, "endOffset": 187}, {"referenceID": 0, "context": ",K}, and a distribution D supported on X \u00d7 [0, 1] .", "startOffset": 43, "endOffset": 49}, {"referenceID": 0, "context": "Let G , {g : X 7\u2192 [0, 1]} denote a set of base regressors and let F , G denote a set of vector regressors where the yth coordinate of f \u2208 F is written as f(\u00b7; y).", "startOffset": 18, "endOffset": 24}, {"referenceID": 21, "context": "Similar querying strategies were used in prior works on binary and multiclass classification [22, 14, 1], but specialized to linear representations.", "startOffset": 93, "endOffset": 104}, {"referenceID": 13, "context": "Similar querying strategies were used in prior works on binary and multiclass classification [22, 14, 1], but specialized to linear representations.", "startOffset": 93, "endOffset": 104}, {"referenceID": 0, "context": "Similar querying strategies were used in prior works on binary and multiclass classification [22, 14, 1], but specialized to linear representations.", "startOffset": 93, "endOffset": 104}, {"referenceID": 20, "context": "Our low-noise assumption is related to the Massart noise condition [21], which in binary classification posits that the Bayes optimal predictor is bounded away from 1/2 for all x.", "startOffset": 67, "endOffset": 71}, {"referenceID": 19, "context": "To compare, the standard generalization bound is \u00d5( \u221a log(|F|/\u03b4)/i) [20], which agrees with our bound since |F| = |G| in our case.", "startOffset": 68, "endOffset": 72}, {"referenceID": 20, "context": "This agrees with the literature on active learning for classification [21] and can be viewed as a generalization to CSMC.", "startOffset": 70, "endOffset": 74}, {"referenceID": 15, "context": "The definition is a natural adaptation from binary classification [16], where a similar disagreement region to DIS(r, y) is used.", "startOffset": 66, "endOffset": 70}, {"referenceID": 15, "context": "The 1/r scaling leads to bounded coefficients in many examples [16], and we also scale by the cost range parameter \u03b71, so that the favorable settings for active learning can be concisely expressed as having \u03b81, \u03b82 bounded, as opposed to a complex function of \u03b71.", "startOffset": 63, "endOffset": 67}, {"referenceID": 11, "context": "In binary classification, ideas based on hallucinating labels for unqueried examples address this issue [12], but this technique does not seem applicable here since the only safe choice of hallucinated cost that avoids eliminating f\u2217 appears to be f\u2217(x; y), which is naturally unknown.", "startOffset": 104, "endOffset": 108}, {"referenceID": 0, "context": "classification [1].", "startOffset": 15, "endOffset": 18}, {"referenceID": 28, "context": "The feature vectors are the top layer of the Inception neural network [29].", "startOffset": 70, "endOffset": 74}, {"referenceID": 18, "context": "The third dataset, RCV1-v2 [19], is a multilabel text-categorization dataset, which has 103 topic labels, organized as a tree with similar tree-distance cost structure as the ImageNet data.", "startOffset": 27, "endOffset": 31}, {"referenceID": 23, "context": "net/~vw 5We use the default online learning algorithm in Vowpal Wabbit, which is a scale-free [24] importance weight invariant [18] form of AdaGrad [15].", "startOffset": 94, "endOffset": 98}, {"referenceID": 17, "context": "net/~vw 5We use the default online learning algorithm in Vowpal Wabbit, which is a scale-free [24] importance weight invariant [18] form of AdaGrad [15].", "startOffset": 127, "endOffset": 131}, {"referenceID": 14, "context": "net/~vw 5We use the default online learning algorithm in Vowpal Wabbit, which is a scale-free [24] importance weight invariant [18] form of AdaGrad [15].", "startOffset": 148, "endOffset": 152}, {"referenceID": 12, "context": "2 Learning to Search We also experiment with COAL as the base leaner in learning-to-search [13, 11], which reduces joint prediction problems to CSMC.", "startOffset": 91, "endOffset": 99}, {"referenceID": 10, "context": "2 Learning to Search We also experiment with COAL as the base leaner in learning-to-search [13, 11], which reduces joint prediction problems to CSMC.", "startOffset": 91, "endOffset": 99}, {"referenceID": 25, "context": "[26].", "startOffset": 0, "endOffset": 4}, {"referenceID": 22, "context": "We specifically use AGGRAVATE [23, 11], which runs a learned policy to produce a backbone sequence of labels.", "startOffset": 30, "endOffset": 38}, {"referenceID": 10, "context": "We specifically use AGGRAVATE [23, 11], which runs a learned policy to produce a backbone sequence of labels.", "startOffset": 30, "endOffset": 38}, {"referenceID": 0, "context": "The online update guarantees that g i,y(x) \u2208 [0, 1].", "startOffset": 45, "endOffset": 51}, {"referenceID": 0, "context": "\u21d2 2\u2206 + wt,h [ (c\u2212 g`(x)) + (c\u2212 gh(x)) ] \u2264 2wt,h ( c\u2212 gh(x) + g`(x) 2 )2 + 2\u2206 since c, g`(x) \u2208 [0, 1] \u21d2 1 2 (c\u2212 g`(x)) + 1 2 (c\u2212 gh(x)) \u2264 ( c\u2212 gh(x) + g`(x) 2 )2 .", "startOffset": 94, "endOffset": 100}, {"referenceID": 7, "context": "1 Supporting Lemmata Theorem 7 (Freedman-type Inequality [8, 2]).", "startOffset": 57, "endOffset": 63}, {"referenceID": 1, "context": "1 Supporting Lemmata Theorem 7 (Freedman-type Inequality [8, 2]).", "startOffset": 57, "endOffset": 63}, {"referenceID": 0, "context": "Moreover, because the excess cost-sensitive classification risk is always upper-bounded by 1, it is trivially bounded by 2K\u2206 \u2032 1 \u03b6 for any \u03b6 \u2208 [0, 1].", "startOffset": 143, "endOffset": 149}], "year": 2017, "abstractText": "We design an active learning algorithm for cost-sensitive multiclass classification: problems where different errors have different costs. Our algorithm, COAL, makes predictions by regressing on each label\u2019s cost and predicting the smallest. On a new example, it uses a set of regressors that perform well on past data to estimate possible costs for each label. It queries only the labels that could be the best, ignoring the sure losers. We prove COAL can be efficiently implemented for any regression family that admits squared loss optimization; it also enjoys strong guarantees with respect to predictive performance and labeling effort. We empirically compare COAL to passive learning, showing significant improvements in labeling effort and test cost.", "creator": "LaTeX with hyperref package"}}}