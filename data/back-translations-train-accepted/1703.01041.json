{"id": "1703.01041", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "3-Mar-2017", "title": "Large-Scale Evolution of Image Classifiers", "abstract": "Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Evolutionary algorithms provide a technique to discover such networks automatically. Despite significant computational requirements, we show that evolving models that rival large, hand-designed architectures is possible today. We employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions. To do this, we use novel and intuitive mutation operators that navigate large search spaces. We stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.", "histories": [["v1", "Fri, 3 Mar 2017 05:41:30 GMT  (3033kb,D)", "http://arxiv.org/abs/1703.01041v1", null], ["v2", "Sun, 11 Jun 2017 08:42:28 GMT  (3143kb,D)", "http://arxiv.org/abs/1703.01041v2", "Accepted for publication at ICML 2017 (34th International Conference on Machine Learning)"]], "reviews": [], "SUBJECTS": "cs.NE cs.AI cs.CV cs.DC", "authors": ["esteban real", "sherry moore", "andrew selle", "saurabh saxena", "yutaka leon suematsu", "jie tan", "quoc v le", "alexey kurakin"], "accepted": true, "id": "1703.01041"}, "pdf": {"name": "1703.01041.pdf", "metadata": {"source": "CRF", "title": "Large-Scale Evolution of Image Classifiers", "authors": ["Esteban Real", "Sherry Moore", "Andrew Selle", "Saurabh Saxena", "Yutaka Leon Suematsu", "Quoc Le", "Alex Kurakin"], "emails": ["<ereal@google.com>."], "sections": [{"heading": "1. Introduction", "text": "Even within the specific problem of image classification, the state of the art has been achieved through many years of focused study by hundreds of researchers (Krizhevsky et al.). Unsurprisingly, techniques for the automatic discovery of these architectures have gained popularity in recent years (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016)."}, {"heading": "2. Related Work", "text": "The idea behind it is that people in the city in which they live get along in a different world than in the world in which they live, and that they live in the world in which they live. \"The idea behind it is that people live in the world in which they live, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the world, in the, in the world, in the world, in the world, in the world, in the world, in the, in the world, in the world, in the, in the, in the, in the, in the world, in the, in the world, in the, in the world, in the, in the world, in the, in the world, in the, in the, in the, in the, in the, in the, in the, in the world, in the, in the world, in the, in the, in the, in the, in the, in the, in the, in, in the, in the, in the, in the, in the"}, {"heading": "3. Methods", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. Evolutionary Algorithm", "text": "To automatically search for powerful neural network architectures, we develop a population of models. Each model - or individual - is a trained architecture. The accuracy of the model on a separate validation dataset is a measure of the quality or fitness of the individual. During each evolutionary step, a computer - a worker - randomly selects two individuals from that population and compares their suitability. The worst of the pair is immediately removed from the population - it is killed. The best of the pair is selected as the parent, that is, it undergoes reproduction. By this, we mean that the worker creates a copy of the match and modifies that copy by applying a mutation as described below. We refer to this modified copy as a child. After the worker creates the child, he trains that child, evaluates it on the validation set and brings it back into the population. The child then comes alive - that is free to act as a parent."}, {"heading": "3.2. Encoding and Mutations", "text": "This year it has come to the point where it will be able to take the lead, \"he said in an interview with the German Press Agency.\" We have never hesitated so long, \"he said.\" We have never hesitated so long until we were able to retaliate, \"he said."}, {"heading": "3.3. Initial Conditions", "text": "Each evolutionary experiment starts with a population of simple individuals who do not contain any coils and have a learning rate of 0.1. They are all very poor performers. Each initial individual is merely a basic linear regression model. This conscious choice of poor initial conditions 3 In fact, we store and mutate a floating-point value in integer DNA parameters, allowing several small mutations to have cumulative effects despite integer rotation. This forces evolution to make the discoveries itself. The experimenter contributes mainly by selecting mutations that define a search space. Overall, the use of poor initial conditions and a large search space limits the effect of the experimenter. In other words, it prevents the experimenter from \"manipulating\" the experiment in order to succeed."}, {"heading": "3.4. Training and Validation", "text": "This dataset consists of 50,000 training examples and 10,000 test examples, all of which consist of 32 x 32 color images labeled with 1 of 10 common object classes (Krizhevsky & Hinton, 2009); 5,000 of the training examples are presented in a validation set; the remaining 45,000 examples represent our actual training set; the training set is expanded as in He et al. (2016); the CIFAR 100 dataset has the same number of dimensions, colors, and examples as CIFAR-10, but uses 100 classes, making it much more challenging; the training is performed with TensorFlow (Abadi et al., 2016), using SGD with a pulse of 0.9 (Sutskever et al., 2013), a stack size of 50 and a weight loss of 0.0001; each training runs at 25,600 steps, a value chosen so that each individual can be trained in a few seconds, with the training size limited to a few hours."}, {"heading": "3.5. Computation cost", "text": "To estimate the calculation costs, we have identified the basic TensorFlow (TF) operations used in our model training and validation, such as waves, generic matrix multiplications, etc. For each of these TF operations, we have estimated the theoretical number of floating point operations (FLOPs) required, resulting in a map of TF operation to FLOPs valid for all of our experiments.For each one, in an evolutionary experiment, we calculate the total FLOPs generated by the TF operations in its architecture, both during its training (Ft FLOPs) and during its validation (Fv FLOPs).Then, we assign to the individual the cost of FtNtE + FvNv, with Nt and Nv each being the number of training and validation examples, and E being the number of training periods."}, {"heading": "3.6. Weight Inheritance", "text": "If this does not happen, we are forced to retrain the best model at the end and possibly explore its hyperparameters. Such additional research tends to depend on the details of the model being retrained. On the other hand, 25,600 steps are not enough to fully train each individual. To train a large model to completion is prohibitively slow for evolution. To solve this dilemma, we allow children to inherit parents \"weights whenever possible. Namely, if a layer has suitable shapes, the weights are retained. Consequently, some mutations retain all weights (such as identity or learning rate mutations), some retain none (weight setting mutation), and most retain some, but not all. An example of the latter is filter size mutation: only the filters of mutated confusion are discarded."}, {"heading": "3.7. Reporting Methodology", "text": "Every time we speak of \"the best model,\" we mean the model with the highest validation accuracy. However, we always report on the test accuracy. This applies not only to the selection of the best individual within an experiment, but also to the selection of the best experiment. Furthermore, we only include experiments that we were able to reproduce unless explicitly mentioned. Any statistical analysis was fully decided upon before we saw the results of the experiment in order to avoid our analysis being tailored to our experimental data (Simmons et al., 2011)."}, {"heading": "4. Experiments and Results", "text": "We want to answer the following questions: \u2022 Can a simple unilateral evolutionary process proceed from trivial initial conditions and fully trained models designed by hand? \u2022 What are the variabilities of the results, the parallelism and the calculation costs of the method? \u2022 Can an algorithm applied to CIFAR-10 even apply to achieve CIFAR-100 and still produce competitive models? We have used the algorithm in Section 3 to perform several experiments, each of which develops from the example in Figure 1, which contains examples of the architecture that turns out to be surprisingly simple."}, {"heading": "5. Analysis", "text": "This year is the highest in the history of the country."}, {"heading": "6. Conclusion", "text": "In this paper, we have shown that (i) neuroevolution is able to build large, precise networks for two demanding and popular image classification benchmarks; (ii) neuroevolution can do this from trivial starting points in the search for a very large space; (iii) the described process, once started, does not require the involvement of the experimenter; and (iv) the process produces fully formed models. To train models to completion, weight inheritance was crucial (Section 3.6). Unlike amplification learning, evolution provides a natural framework for weight inheritance: mutations can be constructed to ensure a high degree of similarity between the original and the mutated models - as we have done. While we have not focused on reducing computing costs in this work, we hope that future improvements in algorithms and hardware will enable economic implementation."}, {"heading": "Acknowledgements", "text": "We would like to thank Vincent Vanhoucke, Megan Kacholia, Rajat Monga and especially Jeff Dean for their support and valuable input; Geoffrey Hinton, Samy Bengio, Tom Breuel, Mark DePristo, Martin Abadi, Noam Shazeer, Yoram Singer, Dumitru Erhan, Pierre Sermanet, Xiaoqiang Zheng and Vijay Vasudevan for helpful discussions; Thomas Breuel, Xin Pan and Andy Davis for coding contributions; Shan Carter for technical advice; and the larger Google Brain team for helping with TensorFlow and training vision models."}], "references": [{"title": "Designing neural network architectures using reinforcement learning", "author": ["Baker", "Bowen", "Gupta", "Otkrist", "Naik", "Nikhil", "Raskar", "Ramesh"], "venue": "arXiv preprint arXiv:1611.02167,", "citeRegEx": "Baker et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Baker et al\\.", "year": 2016}, {"title": "Evolving memory cell structures for sequence learning", "author": ["Bayer", "Justin", "Wierstra", "Daan", "Togelius", "Julian", "Schmidhuber", "J\u00fcrgen"], "venue": "In International Conference on Artificial Neural Networks,", "citeRegEx": "Bayer et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Bayer et al\\.", "year": 2009}, {"title": "Random search for hyper-parameter optimization", "author": ["Bergstra", "James", "Bengio", "Yoshua"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Bergstra et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bergstra et al\\.", "year": 2012}, {"title": "Automlp: Simple, effective, fully automated learning rate and size adjustment", "author": ["Breuel", "Thomas", "Shafait", "Faisal"], "venue": "In The Learning Workshop. Utah,", "citeRegEx": "Breuel et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Breuel et al\\.", "year": 2010}, {"title": "Convolution by evolution: Differentiable pattern producing networks", "author": ["Fernando", "Chrisantha", "Banarse", "Dylan", "Reynolds", "Malcolm", "Besse", "Frederic", "Pfau", "David", "Jaderberg", "Max", "Lanctot", "Marc", "Wierstra", "Daan"], "venue": "In Proceedings of the 2016 on Genetic and Evolutionary", "citeRegEx": "Fernando et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Fernando et al\\.", "year": 2016}, {"title": "Genetic synthesis of modular neural networks", "author": ["Gruau", "Frederic"], "venue": "In Proceedings of the 5th International Conference on Genetic Algorithms,", "citeRegEx": "Gruau and Frederic.,? \\Q1993\\E", "shortCiteRegEx": "Gruau and Frederic.", "year": 1993}, {"title": "Learning both weights and connections for efficient neural network", "author": ["Han", "Song", "Pool", "Jeff", "Tran", "John", "Dally", "William"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Han et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Han et al\\.", "year": 2015}, {"title": "Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "In Proceedings of the IEEE international conference on computer vision,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"], "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,", "citeRegEx": "He et al\\.,? \\Q2016\\E", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Densely connected convolutional networks", "author": ["Huang", "Gao", "Liu", "Zhuang", "Weinberger", "Kilian Q", "van der Maaten", "Laurens"], "venue": "arXiv preprint arXiv:1608.06993,", "citeRegEx": "Huang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2016}, {"title": "Deep networks with stochastic depth", "author": ["Huang", "Gao", "Sun", "Yu", "Liu", "Zhuang", "Sedra", "Daniel", "Weinberger", "Kilian Q"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "Huang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2016}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["Ioffe", "Sergey", "Szegedy", "Christian"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "Ioffe et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ioffe et al\\.", "year": 2015}, {"title": "Deep clustered convolutional kernels", "author": ["Kim", "Minyoung", "Rigazio", "Luca"], "venue": "arXiv preprint arXiv:1503.01824,", "citeRegEx": "Kim et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Kim et al\\.", "year": 2015}, {"title": "Learning multiple layers of features from tiny images", "author": ["Krizhevsky", "Alex", "Hinton", "Geoffrey"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2009}, {"title": "Imagenet classification with deep convolutional neural networks. In Advances in neural information processing", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "The mnist database of handwritten digits", "author": ["LeCun", "Yann", "Cortes", "Corinna", "Burges", "Christopher JC"], "venue": null, "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Designing neural networks using genetic algorithms", "author": ["Miller", "Geoffrey F", "Todd", "Peter M", "Hegde", "Shailesh U"], "venue": "In Proceedings of the third international conference on Genetic algorithms,", "citeRegEx": "Miller et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Miller et al\\.", "year": 1989}, {"title": "Simple evolutionary optimization can rival stochastic gradient descent in neural networks", "author": ["Morse", "Gregory", "Stanley", "Kenneth O"], "venue": "In Proceedings of the 2016 on Genetic and Evolutionary Computation Conference,", "citeRegEx": "Morse et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Morse et al\\.", "year": 2016}, {"title": "Evolving multimodal controllers with hyperneat", "author": ["Pugh", "Justin K", "Stanley", "Kenneth O"], "venue": "In Proceedings of the 15th annual conference on Genetic and evolutionary computation,", "citeRegEx": "Pugh et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Pugh et al\\.", "year": 2013}, {"title": "Learning representations by back-propagating errors", "author": ["Rumelhart", "David E", "Hinton", "Geoffrey E", "Williams", "Ronald J"], "venue": "Cognitive modeling,", "citeRegEx": "Rumelhart et al\\.,? \\Q1988\\E", "shortCiteRegEx": "Rumelhart et al\\.", "year": 1988}, {"title": "Convolutional neural fabrics", "author": ["Saxena", "Shreyas", "Verbeek", "Jakob"], "venue": "In Advances In Neural Information Processing Systems,", "citeRegEx": "Saxena et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Saxena et al\\.", "year": 2016}, {"title": "False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant", "author": ["Simmons", "Joseph P", "Nelson", "Leif D", "Simonsohn", "Uri"], "venue": "Psychological science,", "citeRegEx": "Simmons et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Simmons et al\\.", "year": 2011}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Simonyan", "Karen", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1409.1556,", "citeRegEx": "Simonyan et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2014}, {"title": "Practical bayesian optimization of machine learning algorithms", "author": ["Snoek", "Jasper", "Larochelle", "Hugo", "Adams", "Ryan P"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Snoek et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Snoek et al\\.", "year": 2012}, {"title": "Striving for simplicity: The all convolutional net", "author": ["Springenberg", "Jost Tobias", "Dosovitskiy", "Alexey", "Brox", "Thomas", "Riedmiller", "Martin"], "venue": "arXiv preprint arXiv:1412.6806,", "citeRegEx": "Springenberg et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Springenberg et al\\.", "year": 2014}, {"title": "Compositional pattern producing networks: A novel abstraction of development", "author": ["Stanley", "Kenneth O"], "venue": "Genetic programming and evolvable machines,", "citeRegEx": "Stanley and O.,? \\Q2007\\E", "shortCiteRegEx": "Stanley and O.", "year": 2007}, {"title": "Evolving neural networks through augmenting topologies", "author": ["Stanley", "Kenneth O", "Miikkulainen", "Risto"], "venue": "Evolutionary computation,", "citeRegEx": "Stanley et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Stanley et al\\.", "year": 2002}, {"title": "A hypercube-based encoding for evolving largescale neural networks", "author": ["Stanley", "Kenneth O", "D\u2019Ambrosio", "David B", "Gauci", "Jason"], "venue": "Artificial life,", "citeRegEx": "Stanley et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Stanley et al\\.", "year": 2009}, {"title": "On the importance of initialization and momentum in deep learning", "author": ["Sutskever", "Ilya", "Martens", "James", "Dahl", "George E", "Hinton", "Geoffrey E"], "venue": "ICML (3),", "citeRegEx": "Sutskever et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Sutskever et al\\.", "year": 2013}, {"title": "Generative neuroevolution for deep learning", "author": ["Verbancsics", "Phillip", "Harguess", "Josh"], "venue": "arXiv preprint arXiv:1312.5355,", "citeRegEx": "Verbancsics et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Verbancsics et al\\.", "year": 2013}, {"title": "Rapid evolutionary escape by large populations from local fitness peaks is likely in nature", "author": ["Weinreich", "Daniel M", "Chao", "Lin"], "venue": null, "citeRegEx": "Weinreich et al\\.,? \\Q2005\\E", "shortCiteRegEx": "Weinreich et al\\.", "year": 2005}, {"title": "Planet-photo geolocation with convolutional neural networks", "author": ["Weyand", "Tobias", "Kostrikov", "Ilya", "Philbin", "James"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "Weyand et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Weyand et al\\.", "year": 2016}, {"title": "Wide residual networks", "author": ["Zagoruyko", "Sergey", "Komodakis", "Nikos"], "venue": "arXiv preprint arXiv:1605.07146,", "citeRegEx": "Zagoruyko et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zagoruyko et al\\.", "year": 2016}, {"title": "An empirical exploration of recurrent network architectures", "author": ["Zaremba", "Wojciech"], "venue": null, "citeRegEx": "Zaremba and Wojciech.,? \\Q2015\\E", "shortCiteRegEx": "Zaremba and Wojciech.", "year": 2015}, {"title": "Neural architecture search with reinforcement learning", "author": ["Zoph", "Barret", "Le", "Quoc V"], "venue": "arXiv preprint arXiv:1611.01578,", "citeRegEx": "Zoph et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Zoph et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 7, "context": "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016).", "startOffset": 108, "endOffset": 167}, {"referenceID": 31, "context": "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016).", "startOffset": 108, "endOffset": 167}, {"referenceID": 23, "context": "It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016).", "startOffset": 139, "endOffset": 239}, {"referenceID": 6, "context": "It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016).", "startOffset": 139, "endOffset": 239}, {"referenceID": 0, "context": "It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity (Bergstra & Bengio, 2012; Snoek et al., 2012; Han et al., 2015; Baker et al., 2016; Zoph & Le, 2016).", "startOffset": 139, "endOffset": 239}, {"referenceID": 5, "context": "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al.", "startOffset": 109, "endOffset": 435}, {"referenceID": 5, "context": "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al.", "startOffset": 109, "endOffset": 464}, {"referenceID": 5, "context": "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al. (2015); He et al.", "startOffset": 109, "endOffset": 487}, {"referenceID": 5, "context": "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al. (2015); He et al. (2016); Huang et al.", "startOffset": 109, "endOffset": 505}, {"referenceID": 5, "context": "Neural networks can successfully perform difficult tasks where large amounts of training data are available (He et al., 2015; Weyand et al., 2016; Silver et al., 2016). Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers (Krizhevsky et al. (2012); Simonyan & Zisserman (2014); Szegedy et al. (2015); He et al. (2016); Huang et al. (2016a), among many others).", "startOffset": 109, "endOffset": 527}, {"referenceID": 16, "context": "liest such \u201cneuro-discovery\u201d methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).", "startOffset": 57, "endOffset": 293}, {"referenceID": 1, "context": "liest such \u201cneuro-discovery\u201d methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).", "startOffset": 57, "endOffset": 293}, {"referenceID": 27, "context": "liest such \u201cneuro-discovery\u201d methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).", "startOffset": 57, "endOffset": 293}, {"referenceID": 4, "context": "liest such \u201cneuro-discovery\u201d methods was neuro-evolution (Miller et al., 1989; Stanley & Miikkulainen, 2002; Stanley, 2007; Bayer et al., 2009; Stanley et al., 2009; Breuel & Shafait, 2010; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Zaremba, 2015; Fernando et al., 2016; Morse & Stanley, 2016).", "startOffset": 57, "endOffset": 293}, {"referenceID": 0, "context": "Despite the promising results, the deep learning community generally perceives evolutionary algorithms to be incapable of matching the accuracies of handdesigned models (Verbancsics & Harguess, 2013; Baker et al., 2016; Zoph & Le, 2016).", "startOffset": 169, "endOffset": 236}, {"referenceID": 9, "context": "The \u2020 indicates a result reported by Huang et al. (2016b) instead of the original author.", "startOffset": 37, "endOffset": 58}, {"referenceID": 9, "context": "The \u2020 indicates a result reported by Huang et al. (2016b) instead of the original author. Much of this table was based on that presented in Huang et al. (2016a).", "startOffset": 37, "endOffset": 161}, {"referenceID": 21, "context": "ability in our results in addition to the top value, we account for researcher degrees of freedom (Simmons et al., 2011), we study the dependence on the meta-parameters, and we disclose the amount of computation necessary to reach the main results.", "startOffset": 98, "endOffset": 120}, {"referenceID": 16, "context": "Neuro-evolution dates back many years (Miller et al., 1989), originally being used only to evolve the weights of a fixed architecture.", "startOffset": 38, "endOffset": 59}, {"referenceID": 27, "context": "The alternative paradigm, indirect encoding, has been the subject of much neuro-evolution research (Gruau, 1993; Stanley et al., 2009; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Fernando et al., 2016).", "startOffset": 99, "endOffset": 200}, {"referenceID": 4, "context": "The alternative paradigm, indirect encoding, has been the subject of much neuro-evolution research (Gruau, 1993; Stanley et al., 2009; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Fernando et al., 2016).", "startOffset": 99, "endOffset": 200}, {"referenceID": 27, "context": "For example, the CPPN (Stanley, 2007; Stanley et al., 2009) allows for the evolution of repeating features at different scales.", "startOffset": 22, "endOffset": 59}, {"referenceID": 15, "context": "Neuro-evolution dates back many years (Miller et al., 1989), originally being used only to evolve the weights of a fixed architecture. Stanley & Miikkulainen (2002) showed that it was advantageous to simultaneously evolve the architecture using the NEAT algorithm.", "startOffset": 39, "endOffset": 165}, {"referenceID": 4, "context": ", 2009; Pugh & Stanley, 2013; Kim & Rigazio, 2015; Fernando et al., 2016). For example, the CPPN (Stanley, 2007; Stanley et al., 2009) allows for the evolution of repeating features at different scales. Also, Kim & Rigazio (2015) use an indirect encoding to improve the convolution filters in an initially highly-optimized fixed architecture.", "startOffset": 51, "endOffset": 230}, {"referenceID": 19, "context": "Research on weight evolution is still ongoing (Morse & Stanley, 2016) but the broader machine learning community defaults to back-propagation for optimizing neural network weights (Rumelhart et al., 1988).", "startOffset": 180, "endOffset": 204}, {"referenceID": 18, "context": "Research on weight evolution is still ongoing (Morse & Stanley, 2016) but the broader machine learning community defaults to back-propagation for optimizing neural network weights (Rumelhart et al., 1988). Back-propagation and evolution can be combined as in Stanley et al. (2009), where only the structure is evolved.", "startOffset": 181, "endOffset": 281}, {"referenceID": 18, "context": "Research on weight evolution is still ongoing (Morse & Stanley, 2016) but the broader machine learning community defaults to back-propagation for optimizing neural network weights (Rumelhart et al., 1988). Back-propagation and evolution can be combined as in Stanley et al. (2009), where only the structure is evolved. Their algorithm follows an alternation of architectural mutations and weight back-propagation. Similarly, Breuel & Shafait (2010) use this approach for hyper-parameter search.", "startOffset": 181, "endOffset": 449}, {"referenceID": 4, "context": "Fernando et al. (2016) also use back-propagation, allowing the trained weights to be inherited through the structural modifications.", "startOffset": 0, "endOffset": 23}, {"referenceID": 8, "context": "The above studies create neural networks that are small in comparison to the typical modern architectures used for image classification (He et al., 2016; Huang et al., 2016a).", "startOffset": 136, "endOffset": 174}, {"referenceID": 15, "context": "When it comes to images, some neuro-evolution results reach the computational scale required to succeed on the MNIST dataset (LeCun et al., 1998).", "startOffset": 125, "endOffset": 145}, {"referenceID": 22, "context": "Snoek et al. (2012) used Bayesian optimization to tune 9 hyper-parameters for a fixed-depth architecture, reaching a new state of the art at the time.", "startOffset": 0, "endOffset": 20}, {"referenceID": 22, "context": "Snoek et al. (2012) used Bayesian optimization to tune 9 hyper-parameters for a fixed-depth architecture, reaching a new state of the art at the time. Zoph & Le (2016) used reinforcement learning on a deeper fixed-length architecture.", "startOffset": 0, "endOffset": 168}, {"referenceID": 0, "context": ") Baker et al. (2016) use", "startOffset": 2, "endOffset": 22}, {"referenceID": 1, "context": "Tangentially, there has also been neuro-evolution work on LSTM structure (Bayer et al., 2009; Zaremba, 2015), but this is beyond the scope of this paper.", "startOffset": 73, "endOffset": 108}, {"referenceID": 1, "context": "Tangentially, there has also been neuro-evolution work on LSTM structure (Bayer et al., 2009; Zaremba, 2015), but this is beyond the scope of this paper. Also related to this work is that of Saxena & Verbeek (2016), who embed convolutions with different parameters into a species of \u201csupernetwork\u201d with many parallel paths.", "startOffset": 74, "endOffset": 215}, {"referenceID": 1, "context": "Tangentially, there has also been neuro-evolution work on LSTM structure (Bayer et al., 2009; Zaremba, 2015), but this is beyond the scope of this paper. Also related to this work is that of Saxena & Verbeek (2016), who embed convolutions with different parameters into a species of \u201csupernetwork\u201d with many parallel paths. Their algorithm then selects and ensembles paths in the super-network. Finally, canonical approaches to hyper-parameter search are grid search (used in Zagoruyko & Komodakis (2016), for example) and random search, the latter being the better of the two (Bergstra & Bengio, 2012).", "startOffset": 74, "endOffset": 505}, {"referenceID": 7, "context": "The activations coming from the non-primary edges are reshaped through zerothorder interpolation in the case of the size and through truncation/padding in the case of the number of channels, as in He et al. (2016). In addition to the graph, the learning-rate", "startOffset": 197, "endOffset": 214}, {"referenceID": 7, "context": "\u2022 RESET-WEIGHTS (sampled as in He et al. (2015), for example).", "startOffset": 31, "endOffset": 48}, {"referenceID": 7, "context": "The training set is augmented as in He et al. (2016). The CIFAR-100 dataset has the same number of dimensions, colors and examples as CIFAR-10, but uses 100 classes, making it much more challenging.", "startOffset": 36, "endOffset": 53}, {"referenceID": 28, "context": "9 (Sutskever et al., 2013), a batch size of 50, and a weight decay of 0.", "startOffset": 2, "endOffset": 26}, {"referenceID": 21, "context": "Any statistical analysis was fully decided upon before seeing the results of the experiment reported, to avoid tailoring our analysis to our experimental data (Simmons et al., 2011).", "startOffset": 159, "endOffset": 181}], "year": 2017, "abstractText": "Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Evolutionary algorithms provide a technique to discover such networks automatically. Despite significant computational requirements, we show that evolving models that rival large, hand-designed architectures is possible today. We employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions. To do this, we use novel and intuitive mutation operators that navigate large search spaces. We stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.", "creator": "LaTeX with hyperref package"}}}