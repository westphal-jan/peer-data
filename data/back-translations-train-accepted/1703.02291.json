{"id": "1703.02291", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2017", "title": "Triple Generative Adversarial Nets", "abstract": "Generative adversarial nets (GANs) are good at generating realistic images and have been extended for semi-supervised classification. However, under a two-player formulation, existing work shares competing roles of identifying fake samples and predicting labels via a single discriminator network, which can lead to undesirable incompatibility. We present triple generative adversarial net (Triple-GAN), a flexible game-theoretical framework for classification and class-conditional generation in semi-supervised learning. Triple-GAN consists of three players - a generator, a discriminator and a classifier, where the generator and classifier characterize the conditional distributions between images and labels, and the discriminator solely focuses on identifying fake image-label pairs. With designed utilities, the distributions characterized by the classifier and generator both concentrate to the data distribution under nonparametric assumptions. We further propose unbiased regularization terms to make the classifier and generator strongly coupled and some biased techniques to boost the performance of Triple-GAN in practice. Our results on several datasets demonstrate the promise in semi-supervised learning, where Triple-GAN achieves comparable or superior performance than state-of-the-art classification results among DGMs; it is also able to disentangle the classes and styles and transfer smoothly on the data level via interpolation on the latent space class-conditionally.", "histories": [["v1", "Tue, 7 Mar 2017 09:26:56 GMT  (6799kb,D)", "http://arxiv.org/abs/1703.02291v1", null], ["v2", "Mon, 3 Apr 2017 09:12:51 GMT  (6799kb,D)", "http://arxiv.org/abs/1703.02291v2", null], ["v3", "Fri, 2 Jun 2017 08:21:45 GMT  (6924kb,D)", "http://arxiv.org/abs/1703.02291v3", null]], "reviews": [], "SUBJECTS": "cs.LG cs.CV", "authors": ["chongxuan li", "kun xu", "jun zhu", "bo zhang"], "accepted": true, "id": "1703.02291"}, "pdf": {"name": "1703.02291.pdf", "metadata": {"source": "META", "title": "Triple Generative Adversarial Nets", "authors": ["Chongxuan Li", "Kun Xu", "Jun Zhu", "Bo Zhang"], "emails": ["LICX14@MAILS.TSINGHUA.EDU.CN", "XU-K16@MAILS.TSINGHUA.EDU.CN", "DCSZJ@MAILS.TSINGHUA.EDU.CN", "DCSZB@MAILS.TSINGHUA.EDU.CN"], "sections": [{"heading": null, "text": "Generative Adversarial Networks (GANs) are good at producing realistic images and have been extended for semi-supervised classification. However, under a two-player formulation, existing work shares competing roles in identifying forged samples and predicting labels over a single discriminator network, which can lead to undesirable incompatibility. We present Triple-GAN, a flexible game theoretical framework for classification and class-based generation in semi-supervised learning. Triple-GAN consists of three actors - a generator, a discriminator and a classifier, where generator and classifier characterise conditional distributions between images and labels, and the discriminator focuses exclusively on identifying forged image-label pairs. With constructed utilities, the distributions characterised by the classifier and generator focus on data distribution under non-parametric assumptions."}, {"heading": "1. Introduction", "text": "In fact, it is not that it is a pure project, but that it is a project that is about putting people's interests at the centre, both in terms of the way in which people understand it and in terms of the way in which they do it, as well as in terms of the way in which they do it. (...) It is not that it is a project that is about putting people's interests at the centre. (...) It is not that it is a project that is \"about a project,\" but that it is a project \"about a project\" that is \"about.\" (...) \"It is a project.\" (...) \"It is a project that is about a project that is\" (...). \"It is not a project that is...\" (...)."}, {"heading": "2. Related Work", "text": "In recent years, the number of unemployed people residing in Germany has multiplied in recent years, both in Germany and in Europe."}, {"heading": "3. Method", "text": "We are looking at learning deep generative models in the semi-monitored environment, 1 where we have a partially labeled data set in which x denotes the input and y denotes the output, the goal being to predict the labels y for unlabeled data and generate new samples x. This differs from the unsupervised learning environment for the pure generation, where the primary goal is to determine whether or not a sample x is generated from the true distribution p (x) of the input; therefore, a two-player game with an input generator and a discriminator is sufficient to describe the process as in GANs. Since the label information y is incomplete (i.e. insecure), our density model should characterize the uncertainty of x and y, hence a common distribution p (x, y) of input-label pairs. A simple application of the two-player game (GAN) is impracticable due to the lack of values on y. In contrast to previous work on the Salan's semi-monitored class (2015), the input layer (GANx) is limited to the input level."}, {"heading": "3.1. A Game with Three Players", "text": "Triple-GAN consists of three components: (1) a classifier C, which (approximate) the conditional discrimination distribution PC (y | x) \u2248 p (y | x) x x x); (2) a class-conditioned generator G, which (approximate) the conditional distribution in the other direction pg (x | y) \u2248 p (x | y) and (3) a discriminator D, which distinguishes whether a data pair (x, y) comes from the true distribution p (x, y). All components are parameterized as neural networks. Our desired balance is that the common distributions defined by the classifier and generator focus on the true data distributions. To this end, we are designing a game with compatible tools for triple players as follows. We are making the mild assumption that the samples from both p (x) and p (y) can be easily obsolete."}, {"heading": "3.2. Theoretical Analysis", "text": "We offer a formal theoretical analysis of TripleGAN under non-parametric assumptions = 3. To ensure clarity of the main text, we move the evidence details to Appendix A. First, we can show that the optimalD is balanced between the true data distribution and the mixture distribution defined by C and G. For all fixed C and G, the optimal discriminator D of the game defined by the usage function U (C, G, D) may look like this: D \u0445 C, G (x, y) p (x, y) p (x, y) p (x, y), (3), with the optimal discriminator D of the game (x, y): = (1 \u2212 \u03b1) pg (x, y) + \u03b1pc (x, y) being essentially a valid distribution.Given D, y) p (x, we can omit the discriminator and the minimax game with the value function U: V (C, li.G) expose."}, {"heading": "3.3. Unbiased Regularization", "text": "Despite the discriminatory loss for the classifier (x), we are adding more unbiased regulatory terms to enhance the performance of our algorithm (x)."}, {"heading": "3.4. Practical Techniques", "text": "In this subsection, we present several practical techniques for Triple-GAN that can theoretically lead to a distorted solution, but work well in practice.A key problem with Triple-GAN in semi-supervised learning is that the discriminator for delta distribution can collapse on the labeled data of small size and reject other types of samples that actually originate from the true data distribution. Consequently, the generator would also focus on empirical distribution and generate certain labeled data, regardless of what the latent variable is. To address this problem, we stitch some unlabeled data and create pseudo-labels by the classifier and use this data as real labeled data for training the discriminator. Note that we only use PC (y | x) to train p (y | x) but not C to optimize this term. This approach introduces slight bias to Triple-GAN because the target distribution shifts a little toward PC (x), y."}, {"heading": "4. Experiments", "text": "We present the results of the widely used MNIST data (LeCun et al., 1998), SVHN (Netzer et al., 2011) and CIFAR10 (Krizhevsky & Hinton, 2009) datasets. MNIST consists of 60,000 training samples and 10,000 test samples of handwritten digits 28 x 28 pixels in size. SVHN consists of 73,257 training samples and 26,032 test samples and each is a color 32 x 32 image containing a sequence of digits with different backgrounds. CIFAR10 consists of color images distributed across 10 general classes - aircraft, car, bird, cat, deer, dog, frog, horse and truck. There are 50,000 training samples and 10,000 size 32 x 32 samples in CIFAR10. We follow (Salimans et al al al, 2016) to see the pixels of SVHN and CIFAR10 data in \u2212 1 cale."}, {"heading": "4.1. Classification", "text": "We first evaluate our method with 20, 50, 100 and 200 marked samples at MNIST for a systematic comparison with previous methods. We train C exclusively with \u03b1B = 1 for 30 epochs to reduce the variance given to no more than 100 labels. Table 1 summarizes the quantitative results. In view of 100 labels, our method is competitive with the state of the art under a large corpus of approaches. Under other conditions, Triple-GAN consistently performs better than ImprovedGAN, as shown in the last two lines. Furthermore, we can see that Triple-GAN achieves more significant improvements as the number of designated data decreases, indicating the effectiveness of the pseudo-discriminatory loss. We also evaluate our Triple-GAN in supervised learning, where we blank out all regulatory terms and techniques except the pseudo-discriminatory loss. The result confirms once again that the compatible utilities Triple-GAN are better than the last two-layered column SVN in the last 1,000 column of the GANN."}, {"heading": "4.2. Generation", "text": "We show that we can achieve the desired balances by creating different ways to use in the half-hearted classification; the generative models and number of brand names are the same as the previous methods (Salimans et al., 2014); the number of brand names and brand names used in each country is the same as the number of brand names and brand names that are relevant in each country."}, {"heading": "5. Conclusions", "text": "We present triple generative adversary networks (TripleGAN), a unified game theory framework with three actors - a generator, a discriminator and a classifier to operate semi-supervised learning with compatible utilities.The distributions characterized by the classifier and the class-based generator focus on data distribution under non-parametric assumptions. The classifier benefits from the generator by enforcing the discriminator directly and the pseudo-discriminatory loss, and the generator generates class-specific images in semi-supervised learning thanks to the classifier that can derive the labels for unlabeled data. Our empirical results across multiple datasets show the promise - Triple-GAN achieves comparable or superior classification performance as state-of-the-art DGMs, while retaining the ability to generate meaningful images when the label information is incomplete. Furthermore, Triple-GAN can resolve the labeling space and the labelless."}, {"heading": "A. Detailed Theoretical Analysis", "text": "For all fixed C and G, the optimal discriminator D of the game (defined by the auxiliary function U (C, G, D) isD * C, G (x, y) = p (x, y) = p (x, y) = p (x, y), (4) where p\u03b1 (x, y): = (1 \u2212 \u03b1) pg (x, y) + p (x, y) is a valid distribution. Due to the classifier and generator, the auxiliary function can be rewritten asU (C, G, D) = p (x, y), p (x, y) logD (x, y) dydx (1 \u2212 pc) pg (z) log (1 \u2212 D (z, y), y), y (z, y) dydz + p (x), x pc (x), y (x), y (x), x (x), x (x), x (x), y (x), x, y (x, y), x (x), x, y (x, y), x (x), x (x, x, y (x)."}, {"heading": "B. Unconditional Generation", "text": "We compare the samples generated from Triple-GAN and Improved-GAN on the MNIST and CIFAR10 datasets as in Fig. 6, where Triple-GAN shares the same architecture of the generator and the number of labeled data with the baseline. It is evident that Triple-GAN outperforms the GANs trained with the feature matching criterion to generate indistinguishable samples."}, {"heading": "C. Class-conditional Generation on CIFAR10", "text": "We show further class-related generation results for CIFAR10 in Fig. 7. Here, too, we can see that triple-GAN can generate meaningful images in certain classes. D. Interpolation on the MNIST dataset We present the class-related interpolation on the MNIST dataset as in Fig. 8. We come to the same conclusion as in the main text that triple-GAN is able to transmit smoothly on the data level with clear semantics."}, {"heading": "E. Detailed Architectures", "text": "We list the detailed architectures of Triple-GAN on MNIST, SVHN, and CIFAR10 datasets in Table 4, Table 5, and Table 6, respectively."}], "references": [{"title": "The Laplacian pyramid as a compact image code", "author": ["P. Burt", "E. Adelson"], "venue": "IEEE Transactions on communications,", "citeRegEx": "Burt and Adelson,? \\Q1983\\E", "shortCiteRegEx": "Burt and Adelson", "year": 1983}, {"title": "InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets", "author": ["X. Chen", "Y. Duan", "R. Houthooft", "J. Schulman", "I. Sutskever", "P. Abbeel"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "Deep generative image models using a Laplacian pyramid of adversarial networks", "author": ["E.L. Denton", "S. Chintala", "R. Fergus"], "venue": "In NIPS,", "citeRegEx": "Denton et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Denton et al\\.", "year": 2015}, {"title": "Adversarial feature learning", "author": ["J. Donahue", "P. Kr\u00e4henb\u00fchl", "T. Darrell"], "venue": "arXiv preprint arXiv:1605.09782,", "citeRegEx": "Donahue et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Donahue et al\\.", "year": 2016}, {"title": "Adversarially learned inference", "author": ["V. Dumoulin", "I. Belghazi", "B. Poole", "A. Lamb", "M. Arjovsky", "O. Mastropietro", "A. Courville"], "venue": "arXiv preprint arXiv:1606.00704,", "citeRegEx": "Dumoulin et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dumoulin et al\\.", "year": 2016}, {"title": "Training generative neural networks via maximum mean discrepancy optimization", "author": ["G.K. Dziugaite", "D.M. Roy", "Z. Ghahramani"], "venue": "arXiv preprint arXiv:1505.03906,", "citeRegEx": "Dziugaite et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Dziugaite et al\\.", "year": 2015}, {"title": "Generative adversarial nets", "author": ["I. Goodfellow", "J. Pouget-Abadie", "M. Mirza", "B. Xu", "D. Warde-Farley", "S. Ozair", "A. Courville", "Y. Bengio"], "venue": "In NIPS,", "citeRegEx": "Goodfellow et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2014}, {"title": "Noise-contrastive estimation: A new estimation principle for unnormalized statistical models", "author": ["M. Gutmann", "A. Hyv\u00e4rinen"], "venue": "In AISTATS,", "citeRegEx": "Gutmann and Hyv\u00e4rinen,? \\Q2010\\E", "shortCiteRegEx": "Gutmann and Hyv\u00e4rinen", "year": 2010}, {"title": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "author": ["S. Ioffe", "C. Szegedy"], "venue": "arXiv preprint arXiv:1502.03167,", "citeRegEx": "Ioffe and Szegedy,? \\Q2015\\E", "shortCiteRegEx": "Ioffe and Szegedy", "year": 2015}, {"title": "Adam: A method for stochastic optimization", "author": ["D. Kingma", "J. Ba"], "venue": "arXiv preprint arXiv:1412.6980,", "citeRegEx": "Kingma and Ba,? \\Q2014\\E", "shortCiteRegEx": "Kingma and Ba", "year": 2014}, {"title": "Auto-encoding variational Bayes", "author": ["D.P. Kingma", "M. Welling"], "venue": "arXiv preprint arXiv:1312.6114,", "citeRegEx": "Kingma and Welling,? \\Q2013\\E", "shortCiteRegEx": "Kingma and Welling", "year": 2013}, {"title": "Semi-supervised learning with deep generative models", "author": ["D.P. Kingma", "S. Mohamed", "D.J. Rezende", "M. Welling"], "venue": "In NIPS,", "citeRegEx": "Kingma et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Learning multiple layers of features from tiny images", "author": ["A. Krizhevsky", "G. Hinton"], "venue": "Citeseer,", "citeRegEx": "Krizhevsky and Hinton,? \\Q2009\\E", "shortCiteRegEx": "Krizhevsky and Hinton", "year": 2009}, {"title": "Temporal ensembling for semisupervised learning", "author": ["S. Laine", "T. Aila"], "venue": "arXiv preprint arXiv:1610.02242,", "citeRegEx": "Laine and Aila,? \\Q2016\\E", "shortCiteRegEx": "Laine and Aila", "year": 2016}, {"title": "Gradientbased learning applied to document recognition", "author": ["Y. LeCun", "L. Bottou", "Y. Bengio", "P. Haffner"], "venue": "Proceedings of the IEEE,", "citeRegEx": "LeCun et al\\.,? \\Q1998\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1998}, {"title": "Max-margin deep generative models for (semi-) supervised learning", "author": ["C. Li", "J. Zhu", "B. Zhang"], "venue": "arXiv preprint arXiv:1611.07119,", "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Generative moment matching networks", "author": ["Y. Li", "K. Swersky", "R.S. Zemel"], "venue": "In ICML,", "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Auxiliary deep generative models", "author": ["L. Maal\u00f8e", "C.K. S\u00f8nderby", "S.K. S\u00f8nderby", "O. Winther"], "venue": "arXiv preprint arXiv:1602.05473,", "citeRegEx": "Maal\u00f8e et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Maal\u00f8e et al\\.", "year": 2016}, {"title": "Distributional smoothing with virtual adversarial training", "author": ["T. Miyato", "Maeda", "S.-i", "M. Koyama", "K. Nakae", "S. Ishii"], "venue": "arXiv preprint arXiv:1507.00677,", "citeRegEx": "Miyato et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Miyato et al\\.", "year": 2015}, {"title": "Reading digits in natural images with unsupervised feature learning", "author": ["Y. Netzer", "T. Wang", "A. Coates", "A. Bissacco", "B. Wu", "A.Y. Ng"], "venue": "In NIPS workshop on deep learning and unsupervised feature learning,", "citeRegEx": "Netzer et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Netzer et al\\.", "year": 2011}, {"title": "Semi-supervised learning with generative adversarial networks", "author": ["A. Odena"], "venue": "arXiv preprint arXiv:1606.01583,", "citeRegEx": "Odena,? \\Q2016\\E", "shortCiteRegEx": "Odena", "year": 2016}, {"title": "Unsupervised representation learning with deep convolutional generative adversarial networks", "author": ["A. Radford", "L. Metz", "S. Chintala"], "venue": "arXiv preprint arXiv:1511.06434,", "citeRegEx": "Radford et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Radford et al\\.", "year": 2015}, {"title": "Semi-supervised learning with ladder networks", "author": ["A. Rasmus", "M. Berglund", "M. Honkala", "H. Valpola", "T. Raiko"], "venue": "In NIPS,", "citeRegEx": "Rasmus et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Rasmus et al\\.", "year": 2015}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["D.J. Rezende", "S. Mohamed", "D. Wierstra"], "venue": "arXiv preprint arXiv:1401.4082,", "citeRegEx": "Rezende et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "Improved techniques for training GANs", "author": ["T. Salimans", "I. Goodfellow", "W. Zaremba", "V. Cheung", "A. Radford", "X. Chen"], "venue": "In NIPS,", "citeRegEx": "Salimans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Salimans et al\\.", "year": 2016}, {"title": "Unsupervised and semi-supervised learning with categorical generative adversarial networks", "author": ["J.T. Springenberg"], "venue": "arXiv preprint arXiv:1511.06390,", "citeRegEx": "Springenberg,? \\Q2015\\E", "shortCiteRegEx": "Springenberg", "year": 2015}, {"title": "A note on the evaluation of generative models", "author": ["L. Theis", "Oord", "A. v. d", "M. Bethge"], "venue": "arXiv preprint arXiv:1511.01844,", "citeRegEx": "Theis et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Theis et al\\.", "year": 2015}, {"title": "Weaklysupervised disentangling with recurrent transformations for 3d view synthesis", "author": ["J. Yang", "S.E. Reed", "Yang", "M.-H", "H. Lee"], "venue": "In NIPS,", "citeRegEx": "Yang et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 6, "context": "Recently, significant progress has been made on generating realistic images based on Generative Adversarial Nets (GANs) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).", "startOffset": 120, "endOffset": 188}, {"referenceID": 2, "context": "Recently, significant progress has been made on generating realistic images based on Generative Adversarial Nets (GANs) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).", "startOffset": 120, "endOffset": 188}, {"referenceID": 21, "context": "Recently, significant progress has been made on generating realistic images based on Generative Adversarial Nets (GANs) (Goodfellow et al., 2014; Denton et al., 2015; Radford et al., 2015).", "startOffset": 120, "endOffset": 188}, {"referenceID": 6, "context": "Given a generator and the defined distribution pg , the optimal discriminator is D(x) = p(x) pg(x)+p(x) under the assumption of infinite capacity, and the global equilibrium of this game achieves if and only if pg(x) = p(x) (Goodfellow et al., 2014), which is desired in terms of image generation.", "startOffset": 224, "endOffset": 249}, {"referenceID": 11, "context": "GANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability.", "startOffset": 80, "endOffset": 101}, {"referenceID": 25, "context": "Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples.", "startOffset": 49, "endOffset": 69}, {"referenceID": 11, "context": "GANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability. Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples. Odena (2016) and Salimans et al.", "startOffset": 81, "endOffset": 459}, {"referenceID": 11, "context": "GANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability. Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples. Odena (2016) and Salimans et al. (2016) augment the categorical discriminator with one more class, corresponding to the fake data generated by the generator.", "startOffset": 81, "endOffset": 486}, {"referenceID": 11, "context": "GANs and DGMs in general have also proven effective in semi-supervised learning (Kingma et al., 2014), while retaining the generative capability. Under the same twoplayer game framework, Cat-GAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function that minimizes the conditional entropy of predictions given data while maximizes the conditional entropy of predictions given generated samples. Odena (2016) and Salimans et al. (2016) augment the categorical discriminator with one more class, corresponding to the fake data generated by the generator. Salimans et al. (2016) further propose two alternative training objectives that work well for either semi-supervised classification or image generation, but not both.", "startOffset": 81, "endOffset": 627}, {"referenceID": 27, "context": "In addition, disentangling meaningful physical factors like object category from latent representations with limited supervision is of general interest (Yang et al., 2015).", "startOffset": 152, "endOffset": 171}, {"referenceID": 14, "context": "Our results on the widely adopted MNIST (LeCun et al., 1998), SVHN (Netzer et al.", "startOffset": 40, "endOffset": 60}, {"referenceID": 19, "context": ", 1998), SVHN (Netzer et al., 2011) and CIFAR10 (Krizhevsky & Hinton, 2009) datasets demonstrate that Triple-GAN can make accurate predictions without sacrificing generation quality.", "startOffset": 14, "endOffset": 35}, {"referenceID": 23, "context": "Various approaches have been developed to learn DGMs, including MLE-based models such as Variational Autoencoders (VAEs) (Kingma & Welling, 2013; Rezende et al., 2014), Generative Moment Matching Networks (GMMNs) (Li et al.", "startOffset": 121, "endOffset": 167}, {"referenceID": 16, "context": ", 2014), Generative Moment Matching Networks (GMMNs) (Li et al., 2015; Dziugaite et al., 2015) and Generative Adversarial Nets (GANs) (Goodfellow et al.", "startOffset": 53, "endOffset": 94}, {"referenceID": 5, "context": ", 2014), Generative Moment Matching Networks (GMMNs) (Li et al., 2015; Dziugaite et al., 2015) and Generative Adversarial Nets (GANs) (Goodfellow et al.", "startOffset": 53, "endOffset": 94}, {"referenceID": 6, "context": ", 2015) and Generative Adversarial Nets (GANs) (Goodfellow et al., 2014), which can be viewed as an instance of Noise Contrastive Estimation (NCE) (Gutmann & Hyv\u00e4rinen, 2010).", "startOffset": 47, "endOffset": 72}, {"referenceID": 26, "context": "These criteria are systematically compared in (Theis et al., 2015).", "startOffset": 46, "endOffset": 66}, {"referenceID": 2, "context": "Specifically, LAPGAN (Denton et al., 2015) leverages a series of GANs to upscale the generated samples to high resolution images through the Laplacian pyramid framework (Burt & Adelson, 1983).", "startOffset": 21, "endOffset": 42}, {"referenceID": 21, "context": "DCGAN (Radford et al., 2015) adopts (fractionally) strided convolution networks and batch normalization (Ioffe & Szegedy, 2015) in GANs and generate realistic natural images.", "startOffset": 6, "endOffset": 28}, {"referenceID": 1, "context": "For instance, InfoGAN (Chen et al., 2016) learns interpretable latent codes from unlabeled data by regularizing the original GANs via variational mutual information maximization.", "startOffset": 22, "endOffset": 41}, {"referenceID": 4, "context": "In ALI (Dumoulin et al., 2016; Donahue et al., 2016), the inference network infers the latent variables from true data and the discriminator estimates the probability that a pair of latent variable and data comes from the inference network instead of the generator, which make the joint distributions defined by the generator and inference network to be same.", "startOffset": 7, "endOffset": 52}, {"referenceID": 3, "context": "In ALI (Dumoulin et al., 2016; Donahue et al., 2016), the inference network infers the latent variables from true data and the discriminator estimates the probability that a pair of latent variable and data comes from the inference network instead of the generator, which make the joint distributions defined by the generator and inference network to be same.", "startOffset": 7, "endOffset": 52}, {"referenceID": 11, "context": "To handle partially labeled data, the class-conditional VAE (Kingma et al., 2014) treats the missing labels", "startOffset": 60, "endOffset": 81}, {"referenceID": 17, "context": "ADGM (Maal\u00f8e et al., 2016) introduces auxiliary variables to build a more expressive variational distribution and improve the predictive performance.", "startOffset": 5, "endOffset": 26}, {"referenceID": 22, "context": "The Ladder Network (Rasmus et al., 2015) employs lateral connections between a variation of denoising autoencoders and obtains excellent semi-supervised classification results.", "startOffset": 19, "endOffset": 40}, {"referenceID": 25, "context": "CatGAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function.", "startOffset": 7, "endOffset": 27}, {"referenceID": 17, "context": "ADGM (Maal\u00f8e et al., 2016) introduces auxiliary variables to build a more expressive variational distribution and improve the predictive performance. The Ladder Network (Rasmus et al., 2015) employs lateral connections between a variation of denoising autoencoders and obtains excellent semi-supervised classification results. CatGAN (Springenberg, 2015) generalizes GANs with a categorical discriminative network and an objective function. Salimans et al. (2016) propose empirical techniques to stabilize the training of GANs and improve the performance on semi-supervised learning and image generation under incompatible learning criteria.", "startOffset": 6, "endOffset": 464}, {"referenceID": 25, "context": "Unlike the previous work on semi-supervised GANs (Springenberg, 2015; Salimans et al., 2016), which is restricted to the twoplayer framework and can lead to incompatible objectives, we build our game-theoretic objective based on the insight that the joint distribution can be factorized in two ways, namely, p(x, y) = p(x)p(y|x) and p(x, y) = p(y)p(x|y), and that the conditional distributions p(y|x) and p(x|y) are of interest for classification and class-conditional generation, respectively.", "startOffset": 49, "endOffset": 92}, {"referenceID": 24, "context": "Unlike the previous work on semi-supervised GANs (Springenberg, 2015; Salimans et al., 2016), which is restricted to the twoplayer framework and can lead to incompatible objectives, we build our game-theoretic objective based on the insight that the joint distribution can be factorized in two ways, namely, p(x, y) = p(x)p(y|x) and p(x, y) = p(y)p(x|y), and that the conditional distributions p(y|x) and p(x|y) are of interest for classification and class-conditional generation, respectively.", "startOffset": 49, "endOffset": 92}, {"referenceID": 25, "context": "Consequently, it is necessary to regularize C heuristically as in recent advances (Springenberg, 2015; Laine & Aila, 2016) to make more accurate predictions.", "startOffset": 82, "endOffset": 122}, {"referenceID": 25, "context": "Confidence and balance loss Springenberg (2015) minimizes the conditional entropy of pc(y|x) and the cross entropy between p(y) and pc(y), weighted by a hyperparameter \u03b1B, as follows:", "startOffset": 28, "endOffset": 48}, {"referenceID": 15, "context": "The similar idea has been proven effective in (Li et al., 2016) with a large margin classifier.", "startOffset": 46, "endOffset": 63}, {"referenceID": 14, "context": "We now present results on the widely adopted MNIST (LeCun et al., 1998), SVHN (Netzer et al.", "startOffset": 51, "endOffset": 71}, {"referenceID": 19, "context": ", 1998), SVHN (Netzer et al., 2011), and CIFAR10 (Krizhevsky & Hinton, 2009) datasets.", "startOffset": 14, "endOffset": 35}, {"referenceID": 24, "context": "We follow (Salimans et al., 2016) to rescale the pixels of SVHN and CIFAR10 data into (\u22121, 1).", "startOffset": 10, "endOffset": 33}, {"referenceID": 25, "context": "The labeled data is distributed equally across classes and the results are averaged over 10 times with different random splits of training data, following (Springenberg, 2015; Salimans et al., 2016).", "startOffset": 155, "endOffset": 198}, {"referenceID": 24, "context": "The labeled data is distributed equally across classes and the results are averaged over 10 times with different random splits of training data, following (Springenberg, 2015; Salimans et al., 2016).", "startOffset": 155, "endOffset": 198}, {"referenceID": 21, "context": "3 Our network architectures are highly referred to existing work on GANs (Radford et al., 2015; Springenberg, 2015; Salimans et al., 2016) and the details are listed in Appendix E.", "startOffset": 73, "endOffset": 138}, {"referenceID": 25, "context": "3 Our network architectures are highly referred to existing work on GANs (Radford et al., 2015; Springenberg, 2015; Salimans et al., 2016) and the details are listed in Appendix E.", "startOffset": 73, "endOffset": 138}, {"referenceID": 24, "context": "3 Our network architectures are highly referred to existing work on GANs (Radford et al., 2015; Springenberg, 2015; Salimans et al., 2016) and the details are listed in Appendix E.", "startOffset": 73, "endOffset": 138}, {"referenceID": 6, "context": "We train G to maximize logD(G(y, z), y) instead of minimizing log(1 \u2212 D(G(y, z), y)) as suggested in (Goodfellow et al., 2014; Radford et al., 2015).", "startOffset": 101, "endOffset": 148}, {"referenceID": 21, "context": "We train G to maximize logD(G(y, z), y) instead of minimizing log(1 \u2212 D(G(y, z), y)) as suggested in (Goodfellow et al., 2014; Radford et al., 2015).", "startOffset": 101, "endOffset": 148}, {"referenceID": 15, "context": "We refer (Li et al., 2016) to set \u03b1B = 1/300 and \u03b1U = 0.", "startOffset": 9, "endOffset": 26}, {"referenceID": 24, "context": "average of the parameters in the classifier for stable evaluation as in (Salimans et al., 2016).", "startOffset": 72, "endOffset": 95}, {"referenceID": 24, "context": "In our experiments, we find that these training techniques for the original twoplayer GANs are sufficient to stabilize the optimization of Triple-GAN and the convergence speed is comparable to previous work (Salimans et al., 2016).", "startOffset": 207, "endOffset": 230}, {"referenceID": 24, "context": "The generative model and the number of labels are the same to the previous method (Salimans et al., 2016).", "startOffset": 82, "endOffset": 105}, {"referenceID": 11, "context": "Algorithm n = 20 n = 50 n = 100 n = 200 All M1+M2 (Kingma et al., 2014) 3.", "startOffset": 50, "endOffset": 71}, {"referenceID": 18, "context": "96 VAT (Miyato et al., 2015) 2.", "startOffset": 7, "endOffset": 28}, {"referenceID": 22, "context": "64 Ladder (Rasmus et al., 2015) 1.", "startOffset": 10, "endOffset": 31}, {"referenceID": 22, "context": "57 Conv-Ladder (Rasmus et al., 2015) 0.", "startOffset": 15, "endOffset": 36}, {"referenceID": 17, "context": "50) ADGM (Maal\u00f8e et al., 2016) 0.", "startOffset": 9, "endOffset": 30}, {"referenceID": 17, "context": "02) SDGM (Maal\u00f8e et al., 2016) 1.", "startOffset": 9, "endOffset": 30}, {"referenceID": 15, "context": "07) MMCVA (Li et al., 2016) 1.", "startOffset": 10, "endOffset": 27}, {"referenceID": 25, "context": "31 CatGAN (Springenberg, 2015) 1.", "startOffset": 10, "endOffset": 30}, {"referenceID": 24, "context": "48 Improved-GAN (Salimans et al., 2016) 16.", "startOffset": 16, "endOffset": 39}, {"referenceID": 11, "context": "M1+M2 (Kingma et al., 2014) 36.", "startOffset": 6, "endOffset": 27}, {"referenceID": 18, "context": "10) VAT (Miyato et al., 2015) 24.", "startOffset": 8, "endOffset": 29}, {"referenceID": 17, "context": "63 ADGM (Maal\u00f8e et al., 2016) 22.", "startOffset": 8, "endOffset": 29}, {"referenceID": 17, "context": "86 \u2020 SDGM (Maal\u00f8e et al., 2016) 16.", "startOffset": 10, "endOffset": 31}, {"referenceID": 15, "context": "24)\u2020 MMCVA (Li et al., 2016) 4.", "startOffset": 11, "endOffset": 28}, {"referenceID": 24, "context": "18) \u2020 Improved-GAN (Salimans et al., 2016) 8.", "startOffset": 19, "endOffset": 42}, {"referenceID": 4, "context": "3) ALI (Dumoulin et al., 2016) 7.", "startOffset": 7, "endOffset": 30}, {"referenceID": 22, "context": "Ladder (Rasmus et al., 2015) 20.", "startOffset": 7, "endOffset": 28}, {"referenceID": 25, "context": "47) CatGAN (Springenberg, 2015) 19.", "startOffset": 11, "endOffset": 31}, {"referenceID": 24, "context": "58) Improved-GAN (Salimans et al., 2016) 18.", "startOffset": 17, "endOffset": 40}, {"referenceID": 4, "context": "32) ALI (Dumoulin et al., 2016) 18.", "startOffset": 8, "endOffset": 31}, {"referenceID": 24, "context": "6, we first compare the quality of images generated by Triple-GAN on SVHN and the Improved-GAN with feature matching (Salimans et al., 2016)4, which works well for semi-supervised classification.", "startOffset": 117, "endOffset": 140}, {"referenceID": 24, "context": "We also evaluate the samples on CIFAR10 quantitatively via inception score following (Salimans et al., 2016).", "startOffset": 85, "endOffset": 108}, {"referenceID": 24, "context": "Though the Improved-GAN trained with minibatch discrimination (Salimans et al., 2016) can generate good samples, it fails to predict labels accurately.", "startOffset": 62, "endOffset": 85}, {"referenceID": 24, "context": "09 while that of the Improved-GAN trained without minibatch discrimination (Salimans et al., 2016) is 3.", "startOffset": 75, "endOffset": 98}, {"referenceID": 21, "context": "DCGAN (Radford et al., 2015) and ALI (Dumoulin et al.", "startOffset": 6, "endOffset": 28}, {"referenceID": 4, "context": ", 2015) and ALI (Dumoulin et al., 2016) can generate data class-conditionally given full labels, while TripleGAN can do similar thing given incomplete label information.", "startOffset": 16, "endOffset": 39}], "year": 2017, "abstractText": "Generative adversarial nets (GANs) are good at generating realistic images and have been extended for semi-supervised classification. However, under a two-player formulation, existing work shares competing roles of identifying fake samples and predicting labels via a single discriminator network, which can lead to undesirable incompatibility. We present triple generative adversarial net (Triple-GAN), a flexible game-theoretical framework for classification and class-conditional generation in semisupervised learning. Triple-GAN consists of three players\u2014a generator, a discriminator and a classifier, where the generator and classifier characterize the conditional distributions between images and labels, and the discriminator solely focuses on identifying fake image-label pairs. With designed utilities, the distributions characterized by the classifier and generator both concentrate to the data distribution under nonparametric assumptions. We further propose unbiased regularization terms to make the classifier and generator strongly coupled and some biased techniques to boost the performance of Triple-GAN in practice. Our results on several datasets demonstrate the promise in semi-supervised learning, where Triple-GAN achieves comparable or superior performance than state-of-the-art classification results among DGMs; it is also able to disentangle the classes and styles and transfer smoothly on the data level via interpolation on the latent space class-conditionally.", "creator": "LaTeX with hyperref package"}}}