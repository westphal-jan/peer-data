{"id": "1703.02622", "review": {"conference": "NIPS", "VERSION": "v1", "DATE_OF_SUBMISSION": "7-Mar-2017", "title": "Online Convex Optimization with Unconstrained Domains and Losses", "abstract": "We propose an online convex optimization algorithm (RescaledExp) that achieves optimal regret in the unconstrained setting without prior knowledge of any bounds on the loss functions. We prove a lower bound showing an exponential separation between the regret of existing algorithms that require a known bound on the loss functions and any algorithm that does not require such knowledge. RescaledExp matches this lower bound asymptotically in the number of iterations. RescaledExp is naturally hyperparameter-free and we demonstrate empirically that it matches prior optimization algorithms that require hyperparameter optimization.", "histories": [["v1", "Tue, 7 Mar 2017 22:14:53 GMT  (392kb,D)", "http://arxiv.org/abs/1703.02622v1", null]], "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["ashok cutkosky", "kwabena a boahen"], "accepted": true, "id": "1703.02622"}, "pdf": {"name": "1703.02622.pdf", "metadata": {"source": "CRF", "title": "Online Convex Optimization with Unconstrained Domains and Losses", "authors": ["Ashok Cutkosky", "Kwabena Boahen"], "emails": ["ashokc@cs.stanford.edu", "boahen@stanford.edu"], "sections": [{"heading": "1 Online Convex Optimization", "text": "The deplorable values of learners in relation to some other definitions of learning are. \"(bit.ly)\" The deplorable values of learners. \"(bit.ly)\" The deplorable values of learners. \"(bit.ly)\" The deplorable values of learners. \"(bit.ly)\" The learners. \"(bit.ly)\" The learners. \"(bit.e)\" The learners. \"(bit.e)\" The learners. \"(bit.e)\" The learners. \"(bit.e)\" The learners. \"(bit.e)\" The learners. \"(bit.e). (bit.e). (bit.e). (bit.e). (bit.e). (bit.e). (bit.e). (bit.e). (bit.e). (bit.e). (bit.e). (bit.e)."}, {"heading": "3 RESCALEDEXP", "text": "This is not the first time that we have embarked on a new Lmax algorithm to prove that our well-known Lmax algorithm does not suffer too much remorse if it is a gt-Lmax algorithm that has its adopted Bound. Our well-known Lmax algorithm uses to prove that this scheme is effective, we show (Lemma 3) that our well-known Lmax algorithm does not suffer too much remorse if it violates a gt-Lmax algorithm that has its adopted Bound. Our well-known Lmax algorithm uses the Follow Regularized Leader (FTRL) framework. FTRL is an intuitive way to design OCO algorithms."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Linear Classification", "text": "To validate our theoretical results in practice, we evaluated RESCALEDEXP on the basis of 8 classification datasets. Data for each task were taken from the libsvm website [15] and can be found individually in a variety of sources [16, 17, 18, 19, 20, 21, 22]. We use linear classifiers with loss of hinges for each task and compare RESCALEDEXP with five other optimization algorithms: ADAGRAD [5], SCALEINVARIANT [23], PISTOL [24], ADAM [25] and ADADELTA [26]. Each of these algorithms requires adjusting some hyperparameters for unlimited problems with unknown Lmax (usually a scale factor for a learning rate). In contrast, our RESCALEDEXP does not require such adjustment. We evaluate each algorithm with the average loss after passing through the data, calculate a prediction that values match an error, a parameter that does not match one with the other, and a model that does not match all of the parameters."}, {"heading": "4.2 Convolutional Neural Networks", "text": "We have also evaluated RESCALEDEXP using two convolutionary neural network models, which have shown remarkable success in computer vision tasks and are becoming increasingly popular in a variety of areas, but may require significant hyperparameter adjustment to be trained. We are looking at the tasks of image classification according to MNIST [18] and CIFAR-10 [27]. Our MNIST architecture consisted of two consecutive 5 x 5 folding layers and 2 x 2 max pooling layers followed by a 512 neuron layer with full cross-linking. Our CIFAR-10 architecture consisted of two consecutive 5 x 5-5 folding layers and 3 x 3 max pooling layers followed by a 384 neuron layer with full cross-linking and a 192 neuron layer with full cross-linking. These models are highly non-convex, so none of our theoretical analysis is true."}, {"heading": "5 Conclusions", "text": "We have introduced RESCALEDEXP, an online convex optimization algorithm in which Lmax = max.gt (t) 2) is unknown in advance. Since RESCALEDEXP does not use any prior knowledge of the losses or the comparison vector u, it is free of hyperparameters and therefore does not require any adjustment of learning rates. We also demonstrate a lower limit that shows that any algorithm referring to the unknown-Lmax scenario must suffer an exponential penalty in regret. We compare RESCALEDEXP empirically with previous optimization algorithms and show that it is consistent with their performance. While our lower limit corresponds to our regret regarding RESCALEDEXP, there is clearly still much work to be done. For example, if RESCALEDEXP is based on the exponential loss that is subsequently shown in our superior analysis that the lower limit for RESCALEDEXP is consistent with the overmatch of the overmatch that may be in relation to the overmatch."}, {"heading": "A Follow-the-Regularized-Leader (FTRL) Regret", "text": "Remember that the FTRL algorithm has the strategy wt + 1 = argminited u (w) + \u2211 t (u) t (u) t (u) t (w) t (u) t (u) t (u) t (u) t (u) t (u) t (w) t (u) t (u) t (u) t (u) t (u) t (u) t (u) t (u) t (u) t (u) t (u) t (u) t (u) t (t) t (w) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (t) t (wt) t (t) wt (t) t (t) t (t) t (t) t (t) t) wt (t) t (t) t (t) t (t) wt) t (t) t."}, {"heading": "B Proof of Lemma 3", "text": "Let's start with the calculation of FTRL updates with regulators \u0432 (w) / \u03b7t: \u0435\u0432 (w) = log (\u0102W + 1) w \u0418w \u0430 so that wT + 1 = argmin 1\u03b7T \u0443 (w) + T \u0445 t = 1 gt \u00b7 w = \u2212 g1: t: t (exp (\u03b7T \u0418\u0430g1: T) \u2212 1) Our goal will be to show that the terms (1 \u03b7t \u2212 1 \u2212 1 \u03b7t) \u0443 (wt + 1) + gt \u00b7 (wt \u2212 wt + 1) are negative in sum in (4). Note in particular that the sequence of events does not increase so that (1 throut \u2212 1 \u2212 1 throut) \u0432 (wt + 1) \u2264 0 for all. Thus, our strategy will be bound to gt \u00b7 (wt \u2212 wt + 1)."}, {"heading": "B.1 Reduction to one dimension", "text": "t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t. \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" t \"t\" \"\" t \"t\" t \"t\" \"t\" t \"\" \"\" t \"\" \"\" \"\" \"t\" \"\" \"\" \"t\" \"\" t \"\" \"t\" t \"\" t \"\" \"\" t \"\" \"\" \"\" \"\" \"\" \"t\" t \"\" \"\" \"t\" \"\" \"\" \"\" \"\" \"\" \"\" \"t\" \"\" t \"\" t \"t\""}, {"heading": "B.2 One dimensional FTRL", "text": "In this section, we analyze the regret of our FTRL algorithm with the ultimate goal of proving Lemma 3: \"We make heavy use of Theorem 5 to allow us to look only at the drop sign (gt) = \u2212 \u2212 \u2212 \u2212 \u2212 sign (g1: \u2212 1). In this context, we can identify the 1-dimensional space spanned by gt and g1: 1 with R. We believe that this notation and assumption of intuition occurs in the visualization of the following results. Lemma 7. Suppose sign (gt) = sign (g1: t \u2212 1) and occasionally assume that g1: t \u2212 1 > 0 counts as WLOG. We feel that this notation and assumption applies intuition in the visualization of the following results."}, {"heading": "C Additional Experimental Details", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "C.1 Hyperparameter Optimization", "text": "For the linear classification tasks, we optimized hyperparameters in a two-step process. First, we tested each 10-power from 10 \u2212 5 to 102. Second, if \u03bb was the best hyperparameter setting in step 1, we also tested \u03b2\u03bb for \u03b2 values of 0.2, 0.4, 0.8, 2.0, 4.0, 6.0, 8.0}. For the neural network models, we optimized ADAM and ADAGRAD learning rates by testing each 10-power from 10 \u2212 5 to 100. For stochastic gradient descent, we used an exponentially decreasing learning rate plan defined in the example codes of Tensorflow (https: / / www.tensorflow.org /) MNIST and CIFAR-10."}, {"heading": "C.2 Coordinate-wise updates", "text": "We have proven all our results in arbitrarily many dimensions, resulting in a dimensionally independent regret limit. However, it is also possible to achieve dimensional limits by running an independent version of our algorithm on each coordinate. Formally, for OLO RT (u) = T \u2211 t = 1 gt (wt \u2212 u) = d \u2211 i = 1 T \u2211 t = 1 gt, i (wt, i \u2212 ui) = d \u2211 i = 1 R1T (ui), where R1T is the regret of a one-dimensional instance of the algorithm. This reduction can result in much better limits if the gradients are known (but can be much worse if they are not). We use this coordinate-wise update strategy for our linear classification experiments for RESCALEDEXP. We also consider coordinate-wise updates and non-coordinate updates for the other algorithms, using the best execution of the two."}, {"heading": "C.3 Re-centering RESCALEDEXP", "text": "For the non-convex neural network tasks we used a variant of RESCALEDEXP, in which we re-center our FTRL algorithm at the beginning of each epoch. Formally, the pseudo-code is provided below: Algorithm 2 RESCALEDEXP Recentered RESCALEDEXP Initialized: k \u2190 2, M0 \u2190 0, w1 \u2190 0, t? \u2190 1, w? \u2190 0for t = 1 to T Play wt, get subgradient gt gt \"t (wt). If t = 1 then L1\" g1 \"p\" 1 / L1end \"if Mt\" max \"(Mt \u2212 1, gt? gt?: t)."}, {"heading": "C.4 Aggregating Studies", "text": "It is difficult to interpret the results of a study such as our linear classification experiments (see section 4), where no particular algorithm is always the \"winner\" for each set of data. Consider in particular the case of an analyst who wants to run one of these algorithms on a new set of data and does not have the resources or inclination to implement and tune each algorithm. Which one should she choose? We propose the following heuristics: Let us choose the algorithm with the lowest loss of all data sets. This heuristics is problematic because records in which all algorithms perform very poorly will dominate the average of cross data sets. To solve this problem and correctly compare losses across data sets, we calculate a normalized loss for each algorithm and data set. The normalized loss for an algorithm on a data set is determined by taking into account the loss made by the algorithm on that data set."}], "references": [], "referenceMentions": [], "year": 2017, "abstractText": "We propose an online convex optimization algorithm (RESCALEDEXP) that achieves<lb>optimal regret in the unconstrained setting without prior knowledge of any bounds<lb>on the loss functions. We prove a lower bound showing an exponential sep-<lb>aration between the regret of existing algorithms that require a known bound<lb>on the loss functions and any algorithm that does not require such knowledge.<lb>RESCALEDEXP matches this lower bound asymptotically in the number of itera-<lb>tions. RESCALEDEXP is naturally hyperparameter-free and we demonstrate empir-<lb>ically that it matches prior optimization algorithms that require hyperparameter<lb>optimization. 1 Online Convex Optimization Online Convex Optimization (OCO) [1, 2] provides an elegant framework for modeling noisy,<lb>antagonistic or changing environments. The problem can be stated formally with the help of the<lb>following definitions:<lb>Convex Set: A setW is convex ifW is contained in some real vector space and tw+(1\u2212 t)w\u2032 \u2208W<lb>for all w,w\u2032 \u2208W and t \u2208 [0, 1].<lb>Convex Function: f :W \u2192 R is a convex function if f(tw + (1\u2212 t)w\u2032) \u2264 tf(w) + (1\u2212 t)f(w\u2032)<lb>for all w,w\u2032 \u2208W and t \u2208 [0, 1]. An OCO problem is a game of repeated rounds in which on round t a learner first chooses an element<lb>wt in some convex space W , then receives a convex loss function `t, and suffers loss `t(wt). The<lb>regret of the learner with respect to some other u \u2208W is defined by", "creator": "LaTeX with hyperref package"}}}