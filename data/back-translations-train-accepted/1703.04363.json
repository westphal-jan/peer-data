{"id": "1703.04363", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Mar-2017", "title": "Deep Value Networks Learn to Evaluate and Iteratively Refine Structured Outputs", "abstract": "We approach structured output prediction by learning a deep value network (DVN) that evaluates different output structures for a given input. For example, when applied to image segmentation, the value network takes an image and a segmentation mask as inputs and predicts a scalar score evaluating the mask quality and its correspondence with the image. Once the value network is optimized, at inference, it finds output structures that maximize the score of the value net via gradient descent on continuous relaxations of structured outputs. Thus DVN takes advantage of the joint modeling of the inputs and outputs. Our framework applies to a wide range of structured output prediction problems. We conduct experiments on multi-label classification based on text data and on image segmentation problems. DVN outperforms several strong baselines and the state-of-the-art results on these benchmarks. In addition, on image segmentation, the proposed deep value network learns complex shape priors and effectively combines image information with the prior to obtain competitive segmentation results.", "histories": [["v1", "Mon, 13 Mar 2017 12:49:20 GMT  (769kb,D)", "http://arxiv.org/abs/1703.04363v1", "Submitted to ICML 2017"], ["v2", "Tue, 8 Aug 2017 08:10:34 GMT  (1587kb,D)", "http://arxiv.org/abs/1703.04363v2", "Published at ICML 2017"]], "COMMENTS": "Submitted to ICML 2017", "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CV", "authors": ["michael gygli", "mohammad norouzi", "anelia angelova"], "accepted": true, "id": "1703.04363"}, "pdf": {"name": "1703.04363.pdf", "metadata": {"source": "META", "title": "Deep Value Networks Learn toEvaluate and Iteratively Refine Structured Outputs", "authors": ["Michael Gygli", "Mohammad Norouzi", "Anelia Angelova"], "emails": ["gygli@vision.ee.ethz.ch", "mnorouzi@google.com", "anelia@google.com"], "sections": [{"heading": "1. Introduction", "text": "The fact is that we are able to change and change the world, and that we are able to change the world, to change it, to change it."}, {"heading": "2. Background", "text": "Structured output prediction is a supervised learning problem that results in learning an imaging of some input objects. (This is often a classic prediction of some input-output pairs. (This is a typical prediction of input-output structures in a high-dimensional space where the quality of an imaging is often unfeasible, you measure the quality of an imaging using a loss function. \"(Y):\" R +, which evaluates the distance between different output structures. \"In the face of such a loss function, the quality of an imaging is measured by empirical losses."}, {"heading": "3. Learning a Deep Value Network", "text": "We propose a deep-value network architecture called v (x, y; \u03b8) to evaluate a common configuration of an input and corresponding output over a neural network. Specifically, the deep-value network assumes both x and y as input and, after several layers, predicts a scalar v (x, y; \u03b8) that evaluates the quality of an output y and its compatibility with x. We assume that during the training, one has access to an oracle value function v (y, y) = \u2212 (y, y) that positively affects the quality of the masks. Such an oracle value function assigns optimal values to all input-output pairs. During the training, the goal is to optimize the parameters of a value network called a \"maxy\" in order to mimic the behavior of the oracle value function v (y, y) as much as possible."}, {"heading": "3.1. Gradient based inference", "text": "Since v (x, y; \u03b8) is a complex nonlinear function of (x, y) caused by a neural network, determining y (x, y) is not easy, and approximate inference algorithms based on graph-cut (Boykov et al., 2001) or loopy faith propagation (Murphy et al., 1999) are not easily applicable. Instead, we advocate the use of a simple gradient descend optimizer for inference. To facilitate this, we relax the structured output variables to live in a real evaluated space. Instead of, for example, using y (0, 1} M, we use y (0, 1) M. The key to making this inference algorithm work is to ensure that during the training that our valuations are optimized along the inference orbit."}, {"heading": "3.2. Optimization", "text": "To train a DVN using an oracle value function, it is first necessary to expand the range of v * (y, y *) learning functions so that it is applicable to continuous results y *. For our IOU and F1 values, we simply extend the concepts of intersection and union by using min and max operators, y * y * = \u2211 Mi = 1 min (yi, y * i), (9) y * y * (6) and (7) generalizing IOU and F1 values to [0, 1] M * [0, 1] M *. Our training goal is to minimize the discrepancy between v (i), y (i) and v * (i) in a training set of triplets and (v *)."}, {"heading": "3.3. Generating training tuples", "text": "The way in which training stuples are generated significantly influences the performance of our structured prediction algorithms. In particular, it is important that the tuples are chosen so that they provide good coverage of the space of possible outcomes and outcomes in a large learning signal. There are several ways to generate training stuples, including: \u2022 ongoing gradient-based inference during training. \u2022 generation of adversarial tuples that have a large discrepancy between v (x, y;) and v (y, y). \u2022 random samples from Y, possibly biased towards y. We work on these methods below and present a comparison of their performance in Section 5.4. Our unloading experiments suggest that the combination of examples of gradients with adversarial tuples works."}, {"heading": "4. Related work", "text": "Our approach is partly inspired by the success of previous work on value-based enhancement of learning processes (RL) such as Q-learning (Watkins, 1989; Watkins & Dayan, 1992) (see Sutton & Barto, 1998) for an overview).The main idea is to learn an estimate of future reward under optimal behavioral policies at any time. Newer RL algorithms use a neural network function as a model to estimate action values (Van Hasselt et al., 2016).We adopt similar ideas for future reward, where we use task loss as an optimal appreciator.Unlike RL, we use a gradient based on Inferenece algorithm to find optimal solutions at test time.Gradient inference, sometimes referred to as deep dreaming, has resulted in impressive artwork and has been influential in designing DVN (Gatys et al., 2015; Mordvintal v al al, 2016 al, al; al, al; al."}, {"heading": "5. Experimental evaluation", "text": "We evaluate the proposed Deep Value Networks based on three tasks: multi-class text analysis (Section 5.1), binary image segmentation (Section 5.2), and three-class face segmentation (Section 5.3); Section 5.4 examines scanning mechanisms; and Section 5.5 visualizes the prior distribution of the labels the model has learned."}, {"heading": "5.1. Multi-label classification", "text": "We use standard benchmarks in multi-label classification, namely Bibtex and Bookmarks, introduced in (Katakis et al., 2008).In this task, multiple labels per example are possible and the correct number is unknown.Given the structure in the label space, methods for modeling label correlations often exceed models with independent label predictions.We compare our method with standard baselines, including per-label logistic regression (Lin et al., 2014), and a dual-layer neural network with entropy loss (Belanger & McCallum, 2016), as well as SPENs (Belanger & McCallum, 2016) and PRLR (Lin et al., 2014), which is the state of the art on these datasets."}, {"heading": "5.2. Weizmann horses", "text": "The Weizmann Horse Datasets (Borenstein & Ullman, 2004) are a commonly used dataset for evaluating image segmentation algorithms (Li et al., 2013; Yang et al., 2014; Safar & Yang, 2015).The dataset consists of 328 images of left-oriented horses and their binary segmentation masks. We follow (Li et al., 2013; Yang et al., 2014; Safar & Yang, 2015) and evaluate the segmentation results in 32 \u00d7 32 dimensions. This dataset is well established in the literature for segmentation and proper segmentation of horses, requiring strong form priors to learn. The low resolution of 32 \u00d7 32 is challenging because parts such as the legs are barely visible in the RGB image, so we rely on a learned, complex form model. We follow the experimental protocol and report the test results on the same split (Li et) as in 2013."}, {"heading": "5.3. Labeled Faces in the Wild", "text": "The Labeled Faces in the Wild (LFW) introduced in (Huang et al., 2007) is a data set designed for face recognition and contains more than 13,000 images. A subset of 2927 was later commented on for segmentation by (Kae et al., 2013). The labels are commented on at the superpixel level and consist of three classes: face, hair and background. We use this data to test the adaptation of our approach to multiclass segmentation problems. In fact, we use the same trait, validation and test splits as (Kae et al., 2013; Tsogkas et al., 2015). Since our method predicts labels for each pixel, we follow (Tsogkas et al., 2015) and map them to superpixels, using the most common designation in a superpixel as its class. To train the value network, we say pixel accuracy instead of superpixel prediction for the efficiency of the label calculation."}, {"heading": "5.4. Ablation experiments", "text": "In this section we will analyze different configurations of our method. As already mentioned, the generation of suitable training data for our method is the key to learning valuable networks. We compare three main approaches: 1) Inference + soil truth, 2) Inference + stratified sampling, and 3) Inference + adversarial training. These experiments are performed on the Weizmann data set described above. Table 4, upper part, shows IOU results for different approaches to training the data set. As can be seen, including adversarial training works best, followed by stratified sampling. Both methods help to better explore the space of the segmentation masks near the soil truth masks, rather than just including the soil truth masks. Advertible examples work better than stratified sampling, as the opposing examples are the masks on which the model is least accurate. Therefore, these masks provide useful trench information to improve modeling."}, {"heading": "5.5. Visualizing the learned correlations", "text": "To illustrate what the model has learned, we perform our inference algorithm based on the middle image of the Weizmann dataset (training division). Optionally, we disrupt the middle image by adding some Gaussian noise. The masks obtained by this method are shown in Figure 5. As can be seen, the segmentation masks found by the value network on (noisy) center images resemble a side view of a horse with some uncertainty in leg and head positions. These parts show the largest variation in the dataset. Although noisy images do not contain horses, the value network hallucinates real horse silhouettes on which our model is trained."}, {"heading": "6. Conclusion", "text": "This paper provides a framework for structured output predictions by learning an in-depth value network that predicts the quality of different output hypotheses for a given input. As the DVN learns to predict a value based on input and output, it implicitly learns a previous value via output variables and uses joint modeling of the inputs and outputs. By visualizing the previous value for image segmentation, we actually find that our model learns realistic form priors. Moreover, we learn a model not by optimizing a surrogate loss, but by using DVNs directly to predict a network precisely the desired performance metric (e.g. IOU), even if it is not differentiable. We apply our method to multiple standard datasets in multi-label classification and image segmentation. Our experiments show that DVNs are applicable to various structured pre-problem types of state-of-the-results."}, {"heading": "7. Acknowledgment", "text": "We thank Kevin Murphy, Ryan & George Dahl, Vincent Vanhoucke, Zhifeng Chen and the Google Brain team for their insightful comments and discussions."}], "references": [{"title": "Semantic segmentation using regions and parts", "author": ["Arbelaez", "Pablo", "Hariharan", "Bharath", "Gu", "Chunhui", "Gupta", "Saurabh", "Bourdev", "Lubomir", "Malik", "Jitendra"], "venue": null, "citeRegEx": "Arbelaez et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Arbelaez et al\\.", "year": 2012}, {"title": "Structured prediction energy networks", "author": ["Belanger", "David", "McCallum", "Andrew"], "venue": null, "citeRegEx": "Belanger et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Belanger et al\\.", "year": 2016}, {"title": "Fast approximate energy minimization via graph cuts", "author": ["Boykov", "Yuri", "Veksler", "Olga", "Zabih", "Ramin"], "venue": "IEEE Trans. PAMI,", "citeRegEx": "Boykov et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Boykov et al\\.", "year": 2001}, {"title": "Semantic segmentation with second-order pooling", "author": ["Carreira", "Joao", "Caseiro", "Rui", "Batista", "Jorge", "Sminchisescu", "Cristian"], "venue": null, "citeRegEx": "Carreira et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Carreira et al\\.", "year": 2012}, {"title": "Semantic image segmentation with deep convolutional nets and fully connected crfs", "author": ["Chen", "Liang-Chieh", "Papandreou", "George", "Kokkinos", "Iasonas", "Murphy", "Kevin", "Yuille", "Alan L"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Learning deep structured models", "author": ["Chen", "Liang-Chieh", "Schwing", "Alexander", "Yuille", "Alan", "Urtasun", "Raquel"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs", "author": ["Chen", "Liang-Chieh", "Papandreou", "Iasonas", "Murphy", "Kevin", "Yuille", "Alan L"], "venue": null, "citeRegEx": "Chen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2016}, {"title": "ImageNet: A Large-Scale Hierarchical Image Database", "author": ["Deng", "Jia", "Dong", "Wei", "Socher", "Richard", "Li", "Li-Jia", "Kai", "Fei-Fei"], "venue": null, "citeRegEx": "Deng et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Deng et al\\.", "year": 2009}, {"title": "A learned representation for artistic style", "author": ["Dumoulin", "Vincent", "Shlens", "Jonathon", "Kudlur", "Manjunath"], "venue": null, "citeRegEx": "Dumoulin et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Dumoulin et al\\.", "year": 2016}, {"title": "Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture", "author": ["Eigen", "David", "Fergus", "Rob"], "venue": null, "citeRegEx": "Eigen et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Eigen et al\\.", "year": 2015}, {"title": "The shape boltzmann machine: a strong model of object", "author": ["Eslami", "SM Ali", "Heess", "Nicolas", "Williams", "Christopher KI", "Winn", "John"], "venue": null, "citeRegEx": "Eslami et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Eslami et al\\.", "year": 2014}, {"title": "A neural algorithm of artistic style", "author": ["Gatys", "Leon A", "Ecker", "Alexander S", "Bethge", "Matthias"], "venue": null, "citeRegEx": "Gatys et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Gatys et al\\.", "year": 2015}, {"title": "Rich feature hierarchies for accurate object detection and semantic segmentation", "author": ["Girshick", "Ross", "Donahue", "Jeff", "Darrell", "Trevor", "Malik", "Jitendra"], "venue": null, "citeRegEx": "Girshick et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Girshick et al\\.", "year": 2014}, {"title": "Explaining and harnessing adversarial examples", "author": ["Goodfellow", "Ian J", "Shlens", "Jonathon", "Szegedy", "Christian"], "venue": "ICLR,", "citeRegEx": "Goodfellow et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Goodfellow et al\\.", "year": 2015}, {"title": "Hypercolumns for object segmentation and fine-grained localization", "author": ["Hariharan", "Bharath", "Arbelaez", "Pablo", "Girshick", "Ross"], "venue": null, "citeRegEx": "Hariharan et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Hariharan et al\\.", "year": 2015}, {"title": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "author": ["Huang", "Gary B", "Ramesh", "Manu", "Berg", "Tamara", "Learned-Miller", "Erik"], "venue": null, "citeRegEx": "Huang et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Huang et al\\.", "year": 2007}, {"title": "Perceptual losses for real-time style transfer and superresolution", "author": ["Johnson", "Justin", "Alahi", "Alexandre", "Fei-Fei", "Li"], "venue": null, "citeRegEx": "Johnson et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Johnson et al\\.", "year": 2016}, {"title": "Augmenting crfs with boltzmann machine shape priors for image labeling", "author": ["Kae", "Andrew", "Sohn", "Kihyuk", "Lee", "Honglak", "LearnedMiller", "Erik"], "venue": null, "citeRegEx": "Kae et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Kae et al\\.", "year": 2013}, {"title": "Multilabel text classification for automated tag suggestion", "author": ["Katakis", "Ioannis", "Tsoumakas", "Grigorios", "Vlahavas"], "venue": "ECML PKDD discovery challenge,", "citeRegEx": "Katakis et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Katakis et al\\.", "year": 2008}, {"title": "Robust higher order potentials for enforcing label consistency", "author": ["Kohli", "Pushmeet", "Torr", "Philip HS"], "venue": null, "citeRegEx": "Kohli et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Kohli et al\\.", "year": 2009}, {"title": "Efficient inference in fully connected crfs with gaussian edge potentials", "author": ["Kr\u00e4henb\u00fchl", "Philipp", "Koltun", "Vladlen"], "venue": null, "citeRegEx": "Kr\u00e4henb\u00fchl et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Kr\u00e4henb\u00fchl et al\\.", "year": 2011}, {"title": "Imagenet classification with deep convolutional neural networks", "author": ["Krizhevsky", "Alex", "Sutskever", "Ilya", "Hinton", "Geoffrey E"], "venue": null, "citeRegEx": "Krizhevsky et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Krizhevsky et al\\.", "year": 2012}, {"title": "Inference methods for crfs with cooccurrence statistics", "author": ["Ladick\u1ef3", "L\u2019ubor", "Russell", "Chris", "Kohli", "Pushmeet", "Torr", "Philip HS"], "venue": null, "citeRegEx": "Ladick\u1ef3 et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Ladick\u1ef3 et al\\.", "year": 2013}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["Lafferty", "John", "McCallum", "Andrew", "Pereira", "Fernando"], "venue": null, "citeRegEx": "Lafferty et al\\.,? \\Q2001\\E", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "A tutorial on energy-based learning", "author": ["LeCun", "Yann", "Chopra", "Sumit", "Hadsell", "Raia", "M Ranzato", "F. Huang"], "venue": "Predicting structured data,", "citeRegEx": "LeCun et al\\.,? \\Q2006\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 2006}, {"title": "Object segmentation with deep regression", "author": ["Li", "Jianchao", "Wang", "Dan", "Yan", "Canxiang", "Shan", "Shiguang"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "Iterative instance segmentation", "author": ["Li", "Ke", "Hariharan", "Bharath", "Malik", "Jitendra"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Exploring compositional high order pattern potentials for structured output learning", "author": ["Li", "Yujia", "Tarlow", "Daniel", "Zemel", "Richard"], "venue": null, "citeRegEx": "Li et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Li et al\\.", "year": 2013}, {"title": "Multi-label learning with posterior regularization", "author": ["Lin", "Victoria (Xi", "Singh", "Sameer", "He", "Luheng", "Taskar", "Ben", "Zettlemoyer", "Luke"], "venue": "NIPS Workshop on Modern Machine Learning and Natural Language Processing,", "citeRegEx": "Lin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2014}, {"title": "Fully convolutional networks for semantic segmentation", "author": ["Long", "Jonathan", "Shelhamer", "Evan", "Darrell", "Trevor"], "venue": null, "citeRegEx": "Long et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Long et al\\.", "year": 2015}, {"title": "Inceptionism: Going deeper into neural networks", "author": ["Mordvintsev", "Alexander", "Olah", "Christopher", "Tyka", "Mike"], "venue": "Google Research Blog.,", "citeRegEx": "Mordvintsev et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Mordvintsev et al\\.", "year": 2015}, {"title": "Loopy belief propagation for approximate inference: An empirical study", "author": ["Murphy", "Kevin P", "Weiss", "Yair", "Jordan", "Michael I"], "venue": null, "citeRegEx": "Murphy et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Murphy et al\\.", "year": 1999}, {"title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks", "author": ["Nguyen", "Anh", "Dosovitskiy", "Alexey", "Yosinski", "Jason", "Brox", "Thomas", "Clune", "Jeff"], "venue": null, "citeRegEx": "Nguyen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "Learning deconvolution network for semantic segmentation", "author": ["Noh", "Hyeonwoo", "Hong", "Seunghoon", "Han", "Bohyung"], "venue": null, "citeRegEx": "Noh et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Noh et al\\.", "year": 2015}, {"title": "Reward augmented maximum likelihood for neural structured prediction", "author": ["Norouzi", "Mohammad", "Bengio", "Samy", "Chen", "Zhifeng", "Jaitly", "Navdeep", "Schuster", "Mike", "Wu", "Yonghui", "Schuurmans", "Dale"], "venue": null, "citeRegEx": "Norouzi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Norouzi et al\\.", "year": 2016}, {"title": "Learning to refine object segments", "author": ["P. Pinheiro", "Lin", "T.-Y", "R. Collobert", "P. Dollar"], "venue": null, "citeRegEx": "Pinheiro et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Pinheiro et al\\.", "year": 2016}, {"title": "Unet: Convolutional networks for biomedical image segmentation", "author": ["Ronneberger", "Olaf", "Fischer", "Philipp", "Brox", "Thomas"], "venue": null, "citeRegEx": "Ronneberger et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ronneberger et al\\.", "year": 2015}, {"title": "Learning shape priors for object segmentation via neural networks", "author": ["Safar", "Simon", "Yang", "Ming-Hsuan"], "venue": null, "citeRegEx": "Safar et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Safar et al\\.", "year": 2015}, {"title": "Training deep neural networks via direct loss minimization", "author": ["Song", "Yang", "Schwing", "Alexander", "Zemel", "Richard", "Urtasun", "Raquel"], "venue": null, "citeRegEx": "Song et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Song et al\\.", "year": 2016}, {"title": "Reinforcement learning: An introduction", "author": ["Sutton", "Richard", "Barto", "Andrew"], "venue": null, "citeRegEx": "Sutton et al\\.,? \\Q1998\\E", "shortCiteRegEx": "Sutton et al\\.", "year": 1998}, {"title": "Intriguing properties of neural networks", "author": ["Szegedy", "Christian", "Zaremba", "Wojciech", "Sutskever", "Ilya", "Bruna", "Joan", "Erhan", "Dumitru", "Goodfellow", "Ian", "Fergus", "Rob"], "venue": null, "citeRegEx": "Szegedy et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Szegedy et al\\.", "year": 2013}, {"title": "Support vector machine learning for interdependent and structured output spaces", "author": ["I. Tsochantaridis", "T. Hofmann", "T. Joachims", "Y. Altun"], "venue": null, "citeRegEx": "Tsochantaridis et al\\.,? \\Q2004\\E", "shortCiteRegEx": "Tsochantaridis et al\\.", "year": 2004}, {"title": "Deep learning for semantic part segmentation with high-level guidance", "author": ["Tsogkas", "Stavros", "Kokkinos", "Iasonas", "Papandreou", "George", "Vedaldi", "Andrea"], "venue": null, "citeRegEx": "Tsogkas et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Tsogkas et al\\.", "year": 2015}, {"title": "Deep reinforcement learning with double q-learning", "author": ["Van Hasselt", "Hado", "Guez", "Arthur", "Silver", "David"], "venue": null, "citeRegEx": "Hasselt et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Hasselt et al\\.", "year": 2016}, {"title": "Learning from delayed rewards", "author": ["Watkins", "Christopher JCH"], "venue": "PhD thesis, University of Cambridge England,", "citeRegEx": "Watkins and JCH.,? \\Q1989\\E", "shortCiteRegEx": "Watkins and JCH.", "year": 1989}, {"title": "Maxmargin boltzmann machines for object segmentation", "author": ["Yang", "Jimei", "Safar", "Simon", "Ming-Hsuan"], "venue": null, "citeRegEx": "Yang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2014}, {"title": "Conditional random fields as recurrent neural networks", "author": ["Zheng", "Shuai", "Jayasumana", "Sadeep", "Romera-Paredes", "Bernardino", "Vineet", "Vibhav", "Su", "Zhizhong", "Du", "Dalong", "Huang", "Chang", "Torr", "Philip HS"], "venue": null, "citeRegEx": "Zheng et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zheng et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 23, "context": ", Lafferty et al. (2001); Tsochantaridis et al.", "startOffset": 2, "endOffset": 25}, {"referenceID": 23, "context": ", Lafferty et al. (2001); Tsochantaridis et al. (2004)) has focused on relatively weak linear graphical models with", "startOffset": 2, "endOffset": 55}, {"referenceID": 13, "context": "We also generate output hypotheses by finding adversarial cases (Goodfellow et al., 2015; Szegedy et al., 2013) \u2013 output structures that have a large disagreement between the value network scores and the loss function.", "startOffset": 64, "endOffset": 111}, {"referenceID": 40, "context": "We also generate output hypotheses by finding adversarial cases (Goodfellow et al., 2015; Szegedy et al., 2013) \u2013 output structures that have a large disagreement between the value network scores and the loss function.", "startOffset": 64, "endOffset": 111}, {"referenceID": 7, "context": "Our model is able to outperforms methods that are pre-trained on large datasets such as ImageNet (Deng et al., 2009) or methods that operate on larger input dimensions.", "startOffset": 97, "endOffset": 116}, {"referenceID": 41, "context": "Some structured output prediction methods (Taskar et al., 2003; Tsochantaridis et al., 2004) learn a mapping from inputs to outputs via a score function s(x,y;\u03b8), which evaluates different joint configurations of inputs and outputs based on a linear function of some joint input-output features \u03c8(x,y),", "startOffset": 42, "endOffset": 92}, {"referenceID": 41, "context": "Structural SVM formulations (Taskar et al., 2003; Tsochantaridis et al., 2004) introduce a margin violation (slack) variable for each training pair, and define a continuous upper bound on the empirical loss.", "startOffset": 28, "endOffset": 78}, {"referenceID": 41, "context": "Previous work (Taskar et al., 2003; Tsochantaridis et al., 2004), defines a surrogate objective on the empirical loss,", "startOffset": 14, "endOffset": 64}, {"referenceID": 2, "context": "Since v(x,y;\u03b8) represents a complex non-linear function of (x,y) induced by a neural network, finding \u0177 is not straightforward, and approximate inference algorithms based on graph-cut (Boykov et al., 2001) or loopy belief propagation (Murphy et al.", "startOffset": 184, "endOffset": 205}, {"referenceID": 31, "context": ", 2001) or loopy belief propagation (Murphy et al., 1999) are not easily applicable.", "startOffset": 36, "endOffset": 57}, {"referenceID": 34, "context": "We follow (Norouzi et al., 2016) and sample from the exponentiated value distribution using stratified sampling, where we group y\u2019s according to their values.", "startOffset": 10, "endOffset": 32}, {"referenceID": 13, "context": ", see (Goodfellow et al., 2015; Szegedy et al., 2013).", "startOffset": 6, "endOffset": 53}, {"referenceID": 40, "context": ", see (Goodfellow et al., 2015; Szegedy et al., 2013).", "startOffset": 6, "endOffset": 53}, {"referenceID": 11, "context": "Gradient based inference, sometimes called deep dreaming has led to impressive artwork and has been influential in designing DVN (Gatys et al., 2015; Mordvintsev et al., 2015; Nguyen et al., 2016; Dumoulin et al., 2016).", "startOffset": 129, "endOffset": 219}, {"referenceID": 30, "context": "Gradient based inference, sometimes called deep dreaming has led to impressive artwork and has been influential in designing DVN (Gatys et al., 2015; Mordvintsev et al., 2015; Nguyen et al., 2016; Dumoulin et al., 2016).", "startOffset": 129, "endOffset": 219}, {"referenceID": 32, "context": "Gradient based inference, sometimes called deep dreaming has led to impressive artwork and has been influential in designing DVN (Gatys et al., 2015; Mordvintsev et al., 2015; Nguyen et al., 2016; Dumoulin et al., 2016).", "startOffset": 129, "endOffset": 219}, {"referenceID": 8, "context": "Gradient based inference, sometimes called deep dreaming has led to impressive artwork and has been influential in designing DVN (Gatys et al., 2015; Mordvintsev et al., 2015; Nguyen et al., 2016; Dumoulin et al., 2016).", "startOffset": 129, "endOffset": 219}, {"referenceID": 16, "context": "Such methods often use a pre-trained network to define a notion of a perceptual loss (Johnson et al., 2016).", "startOffset": 85, "endOffset": 107}, {"referenceID": 46, "context": "There has been a surge of recent interest in using neural networks for structured prediction (Zheng et al., 2015; Chen et al., 2015; Song et al., 2016).", "startOffset": 93, "endOffset": 151}, {"referenceID": 5, "context": "There has been a surge of recent interest in using neural networks for structured prediction (Zheng et al., 2015; Chen et al., 2015; Song et al., 2016).", "startOffset": 93, "endOffset": 151}, {"referenceID": 38, "context": "There has been a surge of recent interest in using neural networks for structured prediction (Zheng et al., 2015; Chen et al., 2015; Song et al., 2016).", "startOffset": 93, "endOffset": 151}, {"referenceID": 24, "context": "The Structured Prediction Energy Network (SPEN) of (Belanger & McCallum, 2016) based on (LeCun et al., 2006) is the one most related to the DVN architecture as SPENs also assign a non-linear score to each input-output configuration and use a gradient based inference algorithm to find a final solution.", "startOffset": 88, "endOffset": 108}, {"referenceID": 0, "context": "Image segmentation (Arbelaez et al., 2012; Carreira et al., 2012; Girshick et al., 2014; Hariharan et al., 2015), is a key problem in computer vision and a canonical example of structured prediction.", "startOffset": 19, "endOffset": 112}, {"referenceID": 3, "context": "Image segmentation (Arbelaez et al., 2012; Carreira et al., 2012; Girshick et al., 2014; Hariharan et al., 2015), is a key problem in computer vision and a canonical example of structured prediction.", "startOffset": 19, "endOffset": 112}, {"referenceID": 12, "context": "Image segmentation (Arbelaez et al., 2012; Carreira et al., 2012; Girshick et al., 2014; Hariharan et al., 2015), is a key problem in computer vision and a canonical example of structured prediction.", "startOffset": 19, "endOffset": 112}, {"referenceID": 14, "context": "Image segmentation (Arbelaez et al., 2012; Carreira et al., 2012; Girshick et al., 2014; Hariharan et al., 2015), is a key problem in computer vision and a canonical example of structured prediction.", "startOffset": 19, "endOffset": 112}, {"referenceID": 12, "context": "Many segmentation approaches based on Convolutional Neural Networks (CNN) have been proposed (Girshick et al., 2014; Chen et al., 2014; Eigen & Fergus, 2015; Long et al., 2015; Ronneberger et al., 2015; Noh et al., 2015).", "startOffset": 93, "endOffset": 220}, {"referenceID": 4, "context": "Many segmentation approaches based on Convolutional Neural Networks (CNN) have been proposed (Girshick et al., 2014; Chen et al., 2014; Eigen & Fergus, 2015; Long et al., 2015; Ronneberger et al., 2015; Noh et al., 2015).", "startOffset": 93, "endOffset": 220}, {"referenceID": 29, "context": "Many segmentation approaches based on Convolutional Neural Networks (CNN) have been proposed (Girshick et al., 2014; Chen et al., 2014; Eigen & Fergus, 2015; Long et al., 2015; Ronneberger et al., 2015; Noh et al., 2015).", "startOffset": 93, "endOffset": 220}, {"referenceID": 36, "context": "Many segmentation approaches based on Convolutional Neural Networks (CNN) have been proposed (Girshick et al., 2014; Chen et al., 2014; Eigen & Fergus, 2015; Long et al., 2015; Ronneberger et al., 2015; Noh et al., 2015).", "startOffset": 93, "endOffset": 220}, {"referenceID": 33, "context": "Many segmentation approaches based on Convolutional Neural Networks (CNN) have been proposed (Girshick et al., 2014; Chen et al., 2014; Eigen & Fergus, 2015; Long et al., 2015; Ronneberger et al., 2015; Noh et al., 2015).", "startOffset": 93, "endOffset": 220}, {"referenceID": 4, "context": "Different ways to incorporate pairwise dependencies within a segmentation mask to obtain more expressive models are proposed in (Chen et al., 2014; 2016; Ladick\u1ef3 et al., 2013; Zheng et al., 2015).", "startOffset": 128, "endOffset": 195}, {"referenceID": 22, "context": "Different ways to incorporate pairwise dependencies within a segmentation mask to obtain more expressive models are proposed in (Chen et al., 2014; 2016; Ladick\u1ef3 et al., 2013; Zheng et al., 2015).", "startOffset": 128, "endOffset": 195}, {"referenceID": 46, "context": "Different ways to incorporate pairwise dependencies within a segmentation mask to obtain more expressive models are proposed in (Chen et al., 2014; 2016; Ladick\u1ef3 et al., 2013; Zheng et al., 2015).", "startOffset": 128, "endOffset": 195}, {"referenceID": 25, "context": "Such methods perform joint inference of the segmentation mask dimensions via graph-cut (Li et al., 2015), message passing (Kr\u00e4henb\u00fchl & Koltun, 2011) or loopy belief propagation (Murphy et al.", "startOffset": 87, "endOffset": 104}, {"referenceID": 31, "context": ", 2015), message passing (Kr\u00e4henb\u00fchl & Koltun, 2011) or loopy belief propagation (Murphy et al., 1999), to name a few variants.", "startOffset": 81, "endOffset": 102}, {"referenceID": 19, "context": "Some methods incorporate higher order potentials in CRFs (Kohli et al., 2009) or model global shape priors with Restricted Boltzmann Machines (Li et al.", "startOffset": 57, "endOffset": 77}, {"referenceID": 27, "context": ", 2009) or model global shape priors with Restricted Boltzmann Machines (Li et al., 2013; Kae et al., 2013; Yang et al., 2014; Eslami et al., 2014).", "startOffset": 72, "endOffset": 147}, {"referenceID": 17, "context": ", 2009) or model global shape priors with Restricted Boltzmann Machines (Li et al., 2013; Kae et al., 2013; Yang et al., 2014; Eslami et al., 2014).", "startOffset": 72, "endOffset": 147}, {"referenceID": 45, "context": ", 2009) or model global shape priors with Restricted Boltzmann Machines (Li et al., 2013; Kae et al., 2013; Yang et al., 2014; Eslami et al., 2014).", "startOffset": 72, "endOffset": 147}, {"referenceID": 10, "context": ", 2009) or model global shape priors with Restricted Boltzmann Machines (Li et al., 2013; Kae et al., 2013; Yang et al., 2014; Eslami et al., 2014).", "startOffset": 72, "endOffset": 147}, {"referenceID": 35, "context": "Other methods do not rely on a graphical model, but instead learn to iteratively refine an initial prediction with CNNs, which may just be a coarse segmentation mask (Safar & Yang, 2015; Pinheiro et al., 2016; Li et al., 2016).", "startOffset": 166, "endOffset": 226}, {"referenceID": 26, "context": "Other methods do not rely on a graphical model, but instead learn to iteratively refine an initial prediction with CNNs, which may just be a coarse segmentation mask (Safar & Yang, 2015; Pinheiro et al., 2016; Li et al., 2016).", "startOffset": 166, "endOffset": 226}, {"referenceID": 18, "context": "We use standard benchmarks in multi-label classification, namely Bibtex and Bookmarks, introduced in (Katakis et al., 2008).", "startOffset": 101, "endOffset": 123}, {"referenceID": 28, "context": "We compare our method to standard baselines including per-label logistic regression from (Lin et al., 2014), and a two-layer neural network with cross entropy loss (Belanger & McCallum, 2016), as well as SPENs (Belanger & McCallum, 2016) and PRLR (Lin et al.", "startOffset": 89, "endOffset": 107}, {"referenceID": 28, "context": ", 2014), and a two-layer neural network with cross entropy loss (Belanger & McCallum, 2016), as well as SPENs (Belanger & McCallum, 2016) and PRLR (Lin et al., 2014), which is the state-of-the-art on these datasets.", "startOffset": 147, "endOffset": 165}, {"referenceID": 18, "context": "We use standard benchmarks in multi-label classification, namely Bibtex and Bookmarks, introduced in (Katakis et al., 2008). In this task, multiple labels are possible per example, and the correct number is not known. Given the structure in the label space, methods modeling label correlations often outperform models with independent label predictions. We compare our method to standard baselines including per-label logistic regression from (Lin et al., 2014), and a two-layer neural network with cross entropy loss (Belanger & McCallum, 2016), as well as SPENs (Belanger & McCallum, 2016) and PRLR (Lin et al., 2014), which is the state-of-the-art on these datasets. To allow direct comparison with SPENs, we adopt the same architecture in this paper. Such an architecture combines local predictions that are non-linear in x, but linear in y, with a so-called global network, which scores label configuration with a non-linear function of y independent of x (see Belanger & McCallum (2016), Eqs.", "startOffset": 102, "endOffset": 993}, {"referenceID": 28, "context": "Logistic regression (Lin et al., 2014) 37.", "startOffset": 20, "endOffset": 38}, {"referenceID": 28, "context": "4 PRLR (Lin et al., 2014) 44.", "startOffset": 7, "endOffset": 25}, {"referenceID": 28, "context": "All results except ours are taken from (Lin et al., 2014; Belanger & McCallum, 2016)", "startOffset": 39, "endOffset": 84}, {"referenceID": 28, "context": "Our results even outperform (Lin et al., 2014).", "startOffset": 28, "endOffset": 46}, {"referenceID": 27, "context": "The Weizmann horse dataset (Borenstein & Ullman, 2004) is a commonly used dataset for evaluating image segmentation algorithms (Li et al., 2013; Yang et al., 2014; Safar & Yang, 2015).", "startOffset": 127, "endOffset": 183}, {"referenceID": 45, "context": "The Weizmann horse dataset (Borenstein & Ullman, 2004) is a commonly used dataset for evaluating image segmentation algorithms (Li et al., 2013; Yang et al., 2014; Safar & Yang, 2015).", "startOffset": 127, "endOffset": 183}, {"referenceID": 27, "context": "We follow (Li et al., 2013; Yang et al., 2014; Safar & Yang, 2015) and evaluate the segmentation results at 32\u00d732 dimensions.", "startOffset": 10, "endOffset": 66}, {"referenceID": 45, "context": "We follow (Li et al., 2013; Yang et al., 2014; Safar & Yang, 2015) and evaluate the segmentation results at 32\u00d732 dimensions.", "startOffset": 10, "endOffset": 66}, {"referenceID": 27, "context": "We follow the experimentation protocol and report results on the same test split as (Li et al., 2013).", "startOffset": 84, "endOffset": 101}, {"referenceID": 27, "context": "In pu ts iz e 3 2 \u00d7 3 2 CHOPPS (Li et al., 2013) 69.", "startOffset": 31, "endOffset": 48}, {"referenceID": 45, "context": "1 2 8 \u00d7 1 2 8 MMBM2 (Yang et al., 2014) - 72.", "startOffset": 20, "endOffset": 39}, {"referenceID": 45, "context": "MMBM2 + GC (Yang et al., 2014) - 75.", "startOffset": 11, "endOffset": 30}, {"referenceID": 45, "context": "Our method outperforms all previous methods, despite using a much lower input resolution than (Yang et al., 2014) and (Safar & Yang, 2015).", "startOffset": 94, "endOffset": 113}, {"referenceID": 21, "context": "For training data augmentation purposes we randomly crop the image, similar to (Krizhevsky et al., 2012).", "startOffset": 79, "endOffset": 104}, {"referenceID": 29, "context": "For comparison we also implemented a Fully Convolutional Network (FCN) baseline (Long et al., 2015), by using the same convolutional layers as for the value network (cf.", "startOffset": 80, "endOffset": 99}, {"referenceID": 29, "context": "If not explicitly stated, masks are averaged over over 36 crops for our model and (Long et al., 2015) (see below).", "startOffset": 82, "endOffset": 101}, {"referenceID": 27, "context": "We show qualitative results for CHOPPS (Li et al., 2013), our implementation of fully convolutional networks (FCN) (Long et al.", "startOffset": 39, "endOffset": 56}, {"referenceID": 29, "context": ", 2013), our implementation of fully convolutional networks (FCN) (Long et al., 2015), and our DVN model in Figure 3.", "startOffset": 66, "endOffset": 85}, {"referenceID": 29, "context": "(2013) [2] Our implementation of FCN (Long et al., 2015)", "startOffset": 37, "endOffset": 56}, {"referenceID": 25, "context": "References: [1] Li et al. (2013) [2] Our implementation of FCN (Long et al.", "startOffset": 16, "endOffset": 33}, {"referenceID": 15, "context": "The Labeled Faces in the Wild (LFW) introduced in (Huang et al., 2007) is a dataset designed for face recognition and contains more than 13000 images.", "startOffset": 50, "endOffset": 70}, {"referenceID": 17, "context": "A subset of 2927 was later annotated for segmentation by (Kae et al., 2013).", "startOffset": 57, "endOffset": 75}, {"referenceID": 17, "context": "We use the same train, validation and test splits as (Kae et al., 2013; Tsogkas et al., 2015).", "startOffset": 53, "endOffset": 93}, {"referenceID": 42, "context": "We use the same train, validation and test splits as (Kae et al., 2013; Tsogkas et al., 2015).", "startOffset": 53, "endOffset": 93}, {"referenceID": 42, "context": "As our method predicts labels for each pixel, we follow (Tsogkas et al., 2015) and map these to superpixels by using the most frequent label in a superpixel as its class.", "startOffset": 56, "endOffset": 78}, {"referenceID": 17, "context": "23 GLOC (Kae et al., 2013) 94.", "startOffset": 8, "endOffset": 26}, {"referenceID": 17, "context": "2 5 0 2 CRF (as in Kae et al. (2013)) 93.", "startOffset": 19, "endOffset": 37}, {"referenceID": 42, "context": "DNN (Tsogkas et al., 2015) 96.", "startOffset": 4, "endOffset": 26}, {"referenceID": 42, "context": "DNN+CRF+SBM (Tsogkas et al., 2015) 96.", "startOffset": 12, "endOffset": 34}, {"referenceID": 42, "context": "(i) the pre-training and more direct optimization of the perpixel prediction methods of (Tsogkas et al., 2015; Long et al., 2015), (ii) the input resolution and (iii) the properties of the dataset.", "startOffset": 88, "endOffset": 129}, {"referenceID": 29, "context": "(i) the pre-training and more direct optimization of the perpixel prediction methods of (Tsogkas et al., 2015; Long et al., 2015), (ii) the input resolution and (iii) the properties of the dataset.", "startOffset": 88, "endOffset": 129}, {"referenceID": 29, "context": "Thus, a feed forward method as used in (Long et al., 2015), which produces coarser and smooth predictions is sufficient to obtain good results.", "startOffset": 39, "endOffset": 58}], "year": 2017, "abstractText": "We approach structured output prediction by learning a deep value network (DVN) that evaluates different output structures for a given input. For example, when applied to image segmentation, the value network takes an image and a segmentation mask as inputs and predicts a scalar score evaluating the mask quality and its correspondence with the image. Once the value network is optimized, at inference, it finds output structures that maximize the score of the value net via gradient descent on continuous relaxations of structured outputs. Thus DVN takes advantage of the joint modeling of the inputs and outputs. Our framework applies to a wide range of structured output prediction problems. We conduct experiments on multi-label classification based on text data and on image segmentation problems. DVN outperforms several strong baselines and the state-of-the-art results on these benchmarks. In addition, on image segmentation, the proposed deep value network learns complex shape priors and effectively combines image information with the prior to obtain competitive segmentation results.", "creator": "LaTeX with hyperref package"}}}