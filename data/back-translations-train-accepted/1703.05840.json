{"id": "1703.05840", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "16-Mar-2017", "title": "Conditional Accelerated Lazy Stochastic Gradient Descent", "abstract": "In this work we introduce a conditional accelerated lazy stochastic gradient descent algorithm with optimal number of calls to a stochastic first-order oracle and convergence rate $O\\left(\\frac{1}{\\varepsilon^2}\\right)$ improving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate $O\\left(\\frac{1}{\\varepsilon^4}\\right)$.", "histories": [["v1", "Thu, 16 Mar 2017 22:15:17 GMT  (4860kb,D)", "http://arxiv.org/abs/1703.05840v1", "33 pages, 9 figures"], ["v2", "Fri, 24 Mar 2017 20:28:16 GMT  (4861kb,D)", "http://arxiv.org/abs/1703.05840v2", "33 pages, 9 figures"], ["v3", "Wed, 5 Apr 2017 13:24:06 GMT  (4861kb,D)", "http://arxiv.org/abs/1703.05840v3", "33 pages, 9 figures"], ["v4", "Mon, 10 Apr 2017 16:43:11 GMT  (4861kb,D)", "http://arxiv.org/abs/1703.05840v4", "33 pages, 9 figures"]], "COMMENTS": "33 pages, 9 figures", "reviews": [], "SUBJECTS": "cs.LG stat.ML", "authors": ["guanghui lan", "sebastian pokutta", "yi zhou", "daniel zink"], "accepted": true, "id": "1703.05840"}, "pdf": {"name": "1703.05840.pdf", "metadata": {"source": "META", "title": "Conditional Accelerated Lazy Stochastic Gradient Descent", "authors": ["Guanghui Lan", "Sebastian Pokutta", "Yi Zhou", "Daniel Zink"], "emails": ["george.lan@isye.gatech.edu", "sebastian.pokutta@isye.gatech.edu", "yizhou@gatech.edu", "daniel.zink@gatech.edu"], "sections": [{"heading": null, "text": "\u03b52) Improvement over the projection-free, Frank Wolfe-based stochastic gradient drop of Hazan and Kale [2012] with convergence rate O (1\u03b54)."}, {"heading": "1 Introduction", "text": "The conditional gradient method (also known as: Frank-Wolfe algorithm), which is proposed in Frank and Wolfe (1956), gained much popularity in recent years due to its simple projection freedom and quick practical convergence rates. We consider the basic convex programming (CP) as problematic. (1), where X Rn is a closed convex method, and f: X R is a smooth convex function as it L > 0, f \"(y),\" X, \"\" \",\" \"\", \"\" \",\" \"\", \"\" \",\" \"\", \"\" \",\" \"\", \"\", \"\", \"\", \"\", \"\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\", \",\" \",\", \",\", \"\", \",\", \"\", \"\", \",\", \",\" \"\" \",\", \",\" \",\", \"\", \",\" \",\", \",\" \",\", \"\" \",\", \",\" \"\", \",\""}, {"heading": "1.1 Notation and terminology", "text": "Let X-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y-Y"}, {"heading": "2 Conditional Accelerated Lazy Stochastic Gradient Descent", "text": "We now present a new method for stochastic gradient descent based on the Stochastic Conditional Gradient Sliding (SCGS) method and the parameter-free lazy conditional gradient (LCG) method from Section 2.2, which we call the Conditional Accelerated Lazy Stochastic Gradient Descent (CALSGD). We consider the stochastic optimization problem satisfactory (2)."}, {"heading": "2.1 The algorithm", "text": "During this section we assume that there is a stochastic problem of first order (SFO) (SFO), which causes a stochastic gradient F \"(zk\") for a search point zk \"X\" - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk\") - f \"(zk) - (zk - (zk) (zk - (zk) (zk) (zk) (zk - (zk) (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk - (zk) - (zk) - (zk) - (zk) - (zk) - (zk - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk) - (zk)"}, {"heading": "2.2 The parameter-free lazy conditional gradient procedure", "text": "The classical CG method is a widely used, projection-free algorithm that requires only the solution of a linear optimization problem (3) and not the projection via X per iteration. Therefore, it is possible to go several steps further than the CG and even the LCG method. First, it replaces the LO oracle with a weaker separation oracle LOsep, which is no harder than the linear optimization and often much simpler. Second, it uses a stronger termination criterion than the Frank Wolfe gap (cf.), the vanilla LCG method. Finally, it maintains the same order of convergence rate as the CG method."}, {"heading": "2.3 The convergence properties of CALSGD", "text": "This subsection is devoted to determining the most important convergence properties of the CALSGD method. Since the algorithm is stochastic, we will first determine a simple technical result from Lan and Zhou (2014, Lemma 2.1) that we will apply. First, let us specify a simple technical result from Lan and Zhou (2014, Lemma 2.1) that we will apply. Let us give wt (0, 1, 2,.). Let us also denoteWt: = 1 t = 1 (1 \u2212 wt) Wt \u2212 1 that Wt > 0 is for all t = 2, and that the sequence {2,.,.) t = 1,."}, {"heading": "3 Deterministic CALSGD", "text": "Our goal in this section is to present a deterministic version of CALSGD, which we call CALGD. Instead of invoking the SFO oracle to calculate the stochastic gradients, we assume that we have access to the exact gradients of f. Therefore, the CALGD method invokes the FO oracle to obtain the exact gradients f (zk), which is the same as the f (zk) algorithm except that steps (12) and (13) are replaced by the CALGD method."}, {"heading": "4 Generalizations to other optimization problems", "text": "We generalize the CALGD and CALSGD methods to solve two other classes of problems that are common in machine learning. In particular, we discuss the CALGD method with a restart technique to solve smooth and strongly convex problems in Section 4.1, and in Section 4.3 we expand the CALGD method to solve a specific class of non-smooth problems. Discussions for similar extensions of the CALSGD method can be found in Section 4.2 and 4.4."}, {"heading": "4.1 Strongly convex optimization", "text": "In this subsection, we assume that the objective function f is not only smooth (i.e., (6) holds), but also strongly convex, i.e. that we first determine the convergence rate for the deterministic case, i.e. we have access to the exact gradients of the objective function f. The shrinkage convergence method in Lan [2013] must make additional assumptions about the LO convergence in order to obtain a linear convergence rate. However, we will now show that we can obtain a linear convergence rate in relation to the number of calls to the FO oracle and O (LD2X /) in relation to the total number of calls to the LO convergence."}, {"heading": "4.2 Strongly convex stochastic optimization", "text": "Analogous to the deterministic case, we present an optimal algorithm for solving stochastic smooth and strongly convex problems."}, {"heading": "4.3 Non-smooth optimization: Saddle point problems", "text": "For the sake of simplicity, let us consider the deterministic case, i.e., the problem of interest is an important class of saddle performance problems with f in the form off (x) = max y Y {< Ax, y > \u2212 f (y)}, (58) where A: Rn \u2192 Rm denotes a linear operator, the function f () in (58) is a simple convex function. Since the objective function f is not smooth, we cannot directly apply the CALGD method presented in the previous section. However, as shown by Nesterov [2005], the function f () in (58) can be closely aligned with a class of smooth convex functions. Specifically, let us allow Y \u2192 R to assume a strongly convex function with strongly convex modulus."}, {"heading": "4.4 Non-smooth stochastic optimization: stochastic saddle point problems", "text": "In this subsection, we briefly discuss stochastic saddle point problems, i.e., only stochastic gradients of f\u0432 are available (cf. (59). In particular, we consider the situation in which the original objective function f in (1) of f (x) = E [max y-Y < A\u0441x, y > \u2212 f (y)] is given, (67) in the f function is simply concave for all, and A\u0442 is a random linear operator, i.e. E [max y-Y < L2A (68) \u2264 L2A (68) We can solve this stochastic saddle point problem by replacing (61) with xk = LCG (gk, xk \u2212 1, \u03b2k), where gk = 1Bk = Bk = 1 F \u00b2 Bk = 1 F \u00b2 (zk, \u0441k, j) this stochastic saddle point problem is represented by a proper specification of {xk}, {xk}, this number and the Sollpoint number can be determined by (the Sollpoint number)."}, {"heading": "5 Experimental results", "text": "This year it is more than ever before in the history of the city."}], "references": [{"title": "A Modified Frank-Wolfe Algorithm for Computing Minimum-Area Enclosing Ellipsoidal Cylinders: Theory and Algorithms", "author": ["S. Ahipasaoglu", "M. Todd"], "venue": "Computational Geometry,", "citeRegEx": "Ahipasaoglu and Todd.,? \\Q2013\\E", "shortCiteRegEx": "Ahipasaoglu and Todd.", "year": 2013}, {"title": "On the equivalence between herding and conditional gradient algorithms", "author": ["F. Bach", "S. Lacoste-Julien", "G. Obozinski"], "venue": "In the 29th International Conference on Machine Learning,", "citeRegEx": "Bach et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bach et al\\.", "year": 2012}, {"title": "A conditional gradient method with linear rate of convergence for solving convex linear systems", "author": ["A. Beck", "M. Teboulle"], "venue": "Math. Methods Oper. Res.,", "citeRegEx": "Beck and Teboulle.,? \\Q2004\\E", "shortCiteRegEx": "Beck and Teboulle.", "year": 2004}, {"title": "Lazifying conditional gradient algorithms", "author": ["G. Braun", "S. Pokutta", "D. Zink"], "venue": "arXiv preprint arXiv:1610.05120,", "citeRegEx": "Braun et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Braun et al\\.", "year": 2016}, {"title": "Optimal primal-dual methods for a class of saddle point problems", "author": ["Y. Chen", "G. Lan", "Y. Ouyang"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Chen et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2014}, {"title": "Coresets, sparse greedy approximation, and the frank-wolfe algorithm", "author": ["K.L. Clarkson"], "venue": "ACM Trans. Algorithms,", "citeRegEx": "Clarkson.,? \\Q2010\\E", "shortCiteRegEx": "Clarkson.", "year": 2010}, {"title": "Dual subgradient algorithms for large-scale nonsmooth learning problems", "author": ["B. Cox", "A. Juditsky", "A.S. Nemirovski"], "venue": "Manuscript, School of ISyE, Georgia Tech, Atlanta, GA,", "citeRegEx": "Cox et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Cox et al\\.", "year": 2013}, {"title": "An algorithm for quadratic programming", "author": ["M. Frank", "P. Wolfe"], "venue": "Naval Research Logistics Quarterly,", "citeRegEx": "Frank and Wolfe.,? \\Q1956\\E", "shortCiteRegEx": "Frank and Wolfe.", "year": 1956}, {"title": "New Analysis and Results for the Frank-Wolfe Method", "author": ["R.M. Freund", "P. Grigas"], "venue": "ArXiv e-prints,", "citeRegEx": "Freund and Grigas.,? \\Q2013\\E", "shortCiteRegEx": "Freund and Grigas.", "year": 2013}, {"title": "A Linearly Convergent Conditional Gradient Algorithm with Applications to Online and Stochastic Optimization", "author": ["D. Garber", "E. Hazan"], "venue": null, "citeRegEx": "Garber and Hazan.,? \\Q2013\\E", "shortCiteRegEx": "Garber and Hazan.", "year": 2013}, {"title": "Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, I: a generic algorithmic framework", "author": ["S. Ghadimi", "G. Lan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Ghadimi and Lan.,? \\Q2012\\E", "shortCiteRegEx": "Ghadimi and Lan.", "year": 2012}, {"title": "Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, II: shrinking procedures and optimal algorithms", "author": ["S. Ghadimi", "G. Lan"], "venue": "SIAM Journal on Optimization,", "citeRegEx": "Ghadimi and Lan.,? \\Q2013\\E", "shortCiteRegEx": "Ghadimi and Lan.", "year": 2013}, {"title": "Conditional gradient algorithms for machine learning", "author": ["Z. Harchaoui", "A. Juditsky", "A.S. Nemirovski"], "venue": "NIPS OPT workshop,", "citeRegEx": "Harchaoui et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Harchaoui et al\\.", "year": 2012}, {"title": "Sparse approximate solutions to semidefinite programs", "author": ["E. Hazan"], "venue": "LATIN 2008: Theoretical Informatics,", "citeRegEx": "Hazan.,? \\Q2008\\E", "shortCiteRegEx": "Hazan.", "year": 2008}, {"title": "Projection-free online learning", "author": ["E. Hazan", "S. Kale"], "venue": "arXiv preprint arXiv:1206.4657,", "citeRegEx": "Hazan and Kale.,? \\Q2012\\E", "shortCiteRegEx": "Hazan and Kale.", "year": 2012}, {"title": "Sparse Convex Optimization Methods for Machine Learning", "author": ["M. Jaggi"], "venue": "PhD thesis, ETH Zu\u0308rich,", "citeRegEx": "Jaggi.,? \\Q2011\\E", "shortCiteRegEx": "Jaggi.", "year": 2011}, {"title": "Revisiting frank-wolfe: Projection-free sparse convex optimization", "author": ["M. Jaggi"], "venue": "In the 30th International Conference on Machine Learning,", "citeRegEx": "Jaggi.,? \\Q2013\\E", "shortCiteRegEx": "Jaggi.", "year": 2013}, {"title": "Sulovsk\u00fd. A simple algorithm for nuclear norm regularized problems", "author": ["M.M. Jaggi"], "venue": "In the 27th International Conference on Machine Learning,", "citeRegEx": "Jaggi,? \\Q2010\\E", "shortCiteRegEx": "Jaggi", "year": 2010}, {"title": "Efficient image and video co-localization with frank-wolfe algorithm", "author": ["A. Joulin", "K. Tang", "L. Fei-Fei"], "venue": "In European Conference on Computer Vision,", "citeRegEx": "Joulin et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Joulin et al\\.", "year": 2014}, {"title": "Convex optimization under inexact first-order information", "author": ["G. Lan"], "venue": "Ph.D. dissertation, School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta, GA 30332,", "citeRegEx": "Lan.,? \\Q2009\\E", "shortCiteRegEx": "Lan.", "year": 2009}, {"title": "An optimal method for stochastic composite optimization", "author": ["G. Lan"], "venue": "Mathematical Programming,", "citeRegEx": "Lan.,? \\Q2012\\E", "shortCiteRegEx": "Lan.", "year": 2012}, {"title": "The complexity of large-scale convex programming under a linear optimization oracle", "author": ["G. Lan"], "venue": "Technical Report,", "citeRegEx": "Lan.,? \\Q2013\\E", "shortCiteRegEx": "Lan.", "year": 2013}, {"title": "Conditional gradient sliding for convex optimization", "author": ["G. Lan", "Y. Zhou"], "venue": "Optimization-Online preprint (4605),", "citeRegEx": "Lan and Zhou.,? \\Q2014\\E", "shortCiteRegEx": "Lan and Zhou.", "year": 2014}, {"title": "Conditional gradient algorithms for rank one matrix approximations with a sparsity constraint", "author": ["R. Luss", "M. Teboulle"], "venue": "SIAM Review,", "citeRegEx": "Luss and Teboulle.,? \\Q2013\\E", "shortCiteRegEx": "Luss and Teboulle.", "year": 2013}, {"title": "A method for unconstrained convex minimization problem with the rate of convergence O(1/k)", "author": ["Y.E. Nesterov"], "venue": "Doklady AN SSSR,", "citeRegEx": "Nesterov.,? \\Q1983\\E", "shortCiteRegEx": "Nesterov.", "year": 1983}, {"title": "Introductory Lectures on Convex Optimization: a basic course", "author": ["Y.E. Nesterov"], "venue": "Kluwer Academic Publishers,", "citeRegEx": "Nesterov.,? \\Q2004\\E", "shortCiteRegEx": "Nesterov.", "year": 2004}, {"title": "Smooth minimization of nonsmooth functions", "author": ["Y.E. Nesterov"], "venue": "Mathematical Programming,", "citeRegEx": "Nesterov.,? \\Q2005\\E", "shortCiteRegEx": "Nesterov.", "year": 2005}, {"title": "Positive semidefinite metric learning using boosting-like algorithms", "author": ["C. Shen", "J. Kim", "L. Wang", "A. van den Hengel"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Shen et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Shen et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 13, "context": "Abstract In this work we introduce a conditional accelerated lazy stochastic gradient descent algorithm with optimal number of calls to a stochastic first-order oracle and convergence rate O( 1 \u03b52 ) improving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate O( 1 \u03b54 ).", "startOffset": 291, "endOffset": 313}, {"referenceID": 7, "context": "The conditional gradient method (also known as: Frank-Wolfe algorithm) proposed in Frank and Wolfe [1956], gained much popularity in recent years due to its simple projection-free scheme and fast practical convergence rates.", "startOffset": 83, "endOffset": 106}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al.", "startOffset": 2, "endOffset": 30}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al.", "startOffset": 2, "endOffset": 50}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al.", "startOffset": 2, "endOffset": 76}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al.", "startOffset": 2, "endOffset": 95}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al.", "startOffset": 2, "endOffset": 112}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al.", "startOffset": 2, "endOffset": 138}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al.", "startOffset": 2, "endOffset": 152}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al.", "startOffset": 2, "endOffset": 177}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al.", "startOffset": 2, "endOffset": 224}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al.", "startOffset": 2, "endOffset": 250}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al.", "startOffset": 2, "endOffset": 270}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al.", "startOffset": 2, "endOffset": 293}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al.", "startOffset": 2, "endOffset": 305}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al.", "startOffset": 2, "endOffset": 326}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]).", "startOffset": 2, "endOffset": 347}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3).", "startOffset": 2, "endOffset": 592}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method.", "startOffset": 2, "endOffset": 692}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3).", "startOffset": 2, "endOffset": 1019}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.", "startOffset": 2, "endOffset": 1156}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.", "startOffset": 2, "endOffset": 1171}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]).", "startOffset": 2, "endOffset": 1553}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]).", "startOffset": 2, "endOffset": 1565}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods.", "startOffset": 2, "endOffset": 1695}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X.", "startOffset": 2, "endOffset": 1985}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X.", "startOffset": 2, "endOffset": 2009}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014].", "startOffset": 2, "endOffset": 2434}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014]. We overcome this impasse by carefully modifying both techniques.", "startOffset": 2, "endOffset": 2582}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014]. We overcome this impasse by carefully modifying both techniques. It should be mentioned that Hazan and Kale [2012] proposed the online Frank-Wolfe (OFW) algorithm, which obtains O(1/ ) rate of convergence for stochastic problems.", "startOffset": 2, "endOffset": 2698}, {"referenceID": 0, "context": ", Ahipasaoglu and Todd [2013], Bach et al. [2012], Beck and Teboulle [2004], Cox et al. [2013], Clarkson [2010], Freund and Grigas [2013], Hazan [2008], Harchaoui et al. [2012], Jaggi [2011, 2013], Jaggi and Sulovsk\u00fd [2010], Luss and Teboulle [2013], Shen et al. [2012], Hazan and Kale [2012], Lan [2013], Lan and Zhou [2014], Braun et al. [2016]). It should be noted that even the computational cost for LO oracle to solve the linear optimization subproblem (3) is high for some complex feasible regions. Recently, several approaches have been considered to address this issue. Jaggi [2013] demonstrated practical speed up for the CG method by approximately solving (3). Braun et al. [2016] proposed a class of modified CG methods, namely the lazy conditional gradient (LCG) algorithms, which call a weak separation oracle rather than solving the linear subproblem (3) in the classical CG method. In fact, the weak separation oracle is computationally more efficient than approximate minimization used in Jaggi [2013], at the expense of not providing any guarantee for function value improvement with respect to (3). Furthermore, as shown in Jaggi [2013] and Lan [2013], the total number of iterations for the LCP methods to find an -solution of (1) (i.e., a point x\u0304 \u2208 X, s.t. f(x\u0304) \u2212 f\u2217 \u2264 ) cannot be smaller than O(1/ ), which is not improvable even when the objective function f is strongly convex. Improved complexity results can only be obtained under stronger assumptions on the LO oracle or the feasible set (see, e.g., Garber and Hazan [2013], Lan [2013]). However, the O(1/ ) bound does not preclude the existence of more efficient LCP algorithms for solving (1). Lan and Zhou [2014] proposed a class of conditional gradient sliding methods (CGS), which significantly improve the complexity bounds in terms of the number of gradient evaluations while maintaining optimal complexity bounds for the LO oracle calls required by the LCP methods. Inspired by Braun et al. [2016] and Lan and Zhou [2014], in this paper we focus on a class of modified LCP methods that require only improving solutions for a certain separation problem rather than solving the linear optimization subproblem (3) explicitly through LO oracle calls while simultaneously minimizing the number of gradient evaluations when performing weak separation over the feasible set X. At first these two objectives seem to be incompatible as Braun et al. [2016] gives up the dual guarantee to simplify the oracle, while the dual guarantee of CG iterations is at the core of the analysis in Lan and Zhou [2014]. We overcome this impasse by carefully modifying both techniques. It should be mentioned that Hazan and Kale [2012] proposed the online Frank-Wolfe (OFW) algorithm, which obtains O(1/ ) rate of convergence for stochastic problems. Indeed, if we consider the objective function f(x) := E[F (x, \u03be)] for stochastic optimization, the OFW method can be applied to solve (1) by viewing the iteratively observed function ft as the current realization of the true objective function f , i.e., ft(\u00b7) = F (\u00b7, \u03bet). Without re-evaluating the (sub)gradients at the updated points, the OFW obtains O(T\u22121/4) bound for any (smooth or non-smooth) objective functions (see Theorem 4.4 in Hazan and Kale [2012]), which implies O(1/ ) rate of convergence in terms of the number of (sub)gradient evaluations for stochastic optimization.", "startOffset": 2, "endOffset": 3274}, {"referenceID": 3, "context": "By incorporating a modified LCG procedure [Braun et al., 2016] into a modified CGS method [Lan and Zhou, 2014] we obtain a new conditional accelerated lazy stochastic gradient descent algorithm (CALSGD) and we show that the number of calls to the weak separation oracle can be optimally bounded by O(1/ ), while the optimal bound of O(1/ ) on the total number of calls to the SFO oracle can be maintained.", "startOffset": 42, "endOffset": 62}, {"referenceID": 22, "context": ", 2016] into a modified CGS method [Lan and Zhou, 2014] we obtain a new conditional accelerated lazy stochastic gradient descent algorithm (CALSGD) and we show that the number of calls to the weak separation oracle can be optimally bounded by O(1/ ), while the optimal bound of O(1/ ) on the total number of calls to the SFO oracle can be maintained.", "startOffset": 35, "endOffset": 55}, {"referenceID": 19, "context": "Our algorithmic framework is inspired by the SCGS method by Lan and Zhou [2014]. However, instead of applying the classic CG method to solve the projection subproblem appearing in the accelerated gradient (AG) method, the CALSGD method utilizes a modified parameter-free LCG algorithm (see Section 2.", "startOffset": 60, "endOffset": 80}, {"referenceID": 19, "context": "Secondly, in view of the SCGS method in Lan and Zhou [2014], xk obtained in (13) should be an approximate solution to the gradient sliding subproblem", "startOffset": 40, "endOffset": 60}, {"referenceID": 19, "context": ", \u03b7k = 0), then CALSGD will reduce to the accelerated stochastic approximation method by Lan [2009, 2012]. However, by employing the LCG procedure (see Procedure 1 in Subsection 2.2), we only need to use a weak separation oracle, but still maintaining the optimal bounds on stochastic first-order oracle as in Lan [2009, 2012], Lan and Zhou [2014]. Thirdly, observe that the CALSGD method so far is conceptual only as we have not yet specified the LCG procedure and the parameters {Bk}, {\u03b2k}, {\u03b3k}, and {\u03b7k}.", "startOffset": 89, "endOffset": 348}, {"referenceID": 3, "context": "The LCG procedure presented in this subsection, a modification of the vanilla LCG method in Braun et al. [2016], goes several steps further than CG and even vanilla LCG method.", "startOffset": 92, "endOffset": 112}, {"referenceID": 3, "context": "We present the LCG procedure based on Braun et al. [2016] below.", "startOffset": 38, "endOffset": 58}, {"referenceID": 3, "context": "1 of Braun et al. [2016]), and it halves the value of \u03a6t only when the current oracle call is negative.", "startOffset": 5, "endOffset": 25}, {"referenceID": 3, "context": "1 in Braun et al. [2016], it is clear that the number of iterations in the first phase can be bounded as", "startOffset": 5, "endOffset": 25}, {"referenceID": 3, "context": "1 in Braun et al. [2016], we obtain that the total number of positive calls in this phase can be bounded by 4\u03b1 C\u03c6 \u03b7 , if \u03b7 < \u03b1C\u03c6, or by 4\u03b1 if \u03b7 \u2265 \u03b1C\u03c6.", "startOffset": 5, "endOffset": 25}, {"referenceID": 16, "context": "The shrinking conditional gradient method in Lan [2013] needs to make additional assumptions on the LO oracle to obtain a linear rate of convergence.", "startOffset": 45, "endOffset": 56}, {"referenceID": 15, "context": "In view of the lower complexity bound established for the LO oracle to solve strongly convex problems in Jaggi [2013] and Lan [2013], our bound for the LOsep oracle is not improvable.", "startOffset": 105, "endOffset": 118}, {"referenceID": 15, "context": "In view of the lower complexity bound established for the LO oracle to solve strongly convex problems in Jaggi [2013] and Lan [2013], our bound for the LOsep oracle is not improvable.", "startOffset": 105, "endOffset": 133}, {"referenceID": 19, "context": "5 in Lan and Zhou [2014], we conclude that S = \u2308 log2 max ( 1, \u03b40 )\u2309 .", "startOffset": 5, "endOffset": 25}, {"referenceID": 19, "context": "Moreover, in view of the complexity results established in Lan [2013] and the fact that the LOsep oracle is weaker than the LO oracle, the bound on the total number of calls to the LOsep oracle (cf.", "startOffset": 59, "endOffset": 70}, {"referenceID": 19, "context": "4 in Lan and Zhou [2014], the total number of phases, S, performed by CALSGD method to find a stochastic -solution of problem (1)-(8) is bounded by (53).", "startOffset": 5, "endOffset": 25}, {"referenceID": 24, "context": "However, as shown by Nesterov [2005], the function f(\u00b7) in (58) can be closely approximated by a class of smooth convex functions.", "startOffset": 21, "endOffset": 37}, {"referenceID": 24, "context": "Moreover, Nesterov [2005] shows that f\u03c4 (\u00b7) is differentiable and its gradients are Lipschitz continuous with the Lipschitz constant given by L\u03c4 := \u2016A\u2016 2 \u03c4\u03c3\u03c9 .", "startOffset": 10, "endOffset": 26}, {"referenceID": 19, "context": "1 in Lan and Zhou [2014], and hence omitted.", "startOffset": 5, "endOffset": 25}, {"referenceID": 19, "context": "2 of Lan and Zhou [2014], our first bound in (65) immediately follows.", "startOffset": 5, "endOffset": 25}, {"referenceID": 4, "context": "In view of the discussions in Chen et al. [2014], the obtained bound on the total number of operator evaluations (cf.", "startOffset": 30, "endOffset": 49}, {"referenceID": 4, "context": "In view of the discussions in Chen et al. [2014], the obtained bound on the total number of operator evaluations (cf. first bound in (65)) is not improvable for solving the saddle point problems in (1)-(58). Moreover, according to Lan [2013] and the fact that the LOsep oracle is weaker than LO oracle, the O(1/ ) bound on the total number of calls to the LOsep is not improvable.", "startOffset": 30, "endOffset": 242}, {"referenceID": 18, "context": "As shown by Joulin et al. [2014] this problem can be solved by quadratic programming over a path/flow polytope.", "startOffset": 12, "endOffset": 33}, {"referenceID": 13, "context": "In the example of the Birkhoff polytope it almost looks like as if OFW converges suboptimally, however this is due to the large number of iterations required: the convergence rate of OFW as shown by Hazan and Kale [2012] is O(T\u22121/4), so if we compute the improvement with logarithmic scale, from, e.", "startOffset": 199, "endOffset": 221}, {"referenceID": 13, "context": "In the example of the Birkhoff polytope it almost looks like as if OFW converges suboptimally, however this is due to the large number of iterations required: the convergence rate of OFW as shown by Hazan and Kale [2012] is O(T\u22121/4), so if we compute the improvement with logarithmic scale, from, e.g., iteration 1500 to iteration 4500, we get \u22121/4(log(1500)\u2212 log(4500)) \u2248 0.", "startOffset": 199, "endOffset": 359}], "year": 2017, "abstractText": "In this work we introduce a conditional accelerated lazy stochastic gradient descent algorithm with optimal number of calls to a stochastic first-order oracle and convergence rate O( 1 \u03b52 ) improving over the projection-free, Online Frank-Wolfe based stochastic gradient descent of Hazan and Kale [2012] with convergence rate O( 1 \u03b54 ).", "creator": "LaTeX with hyperref package"}}}