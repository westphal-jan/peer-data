{"id": "1703.10960", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "31-Mar-2017", "title": "Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders", "abstract": "While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved by introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making.", "histories": [["v1", "Fri, 31 Mar 2017 15:55:00 GMT  (2438kb,D)", "https://arxiv.org/abs/1703.10960v1", "Accepted as a long paper in ACL 2017"], ["v2", "Fri, 25 Aug 2017 03:38:58 GMT  (2438kb,D)", "http://arxiv.org/abs/1703.10960v2", "Added URL to data and model implementation. Accepted as a long paper in ACL 2017"], ["v3", "Sat, 21 Oct 2017 04:58:20 GMT  (2560kb,D)", "http://arxiv.org/abs/1703.10960v3", "Appeared in ACL2017 proceedings as a long paper. Correct a calculation mistake in Table 1 E-bow &amp; A-bow and results into higher scores"]], "COMMENTS": "Accepted as a long paper in ACL 2017", "reviews": [], "SUBJECTS": "cs.CL cs.AI", "authors": ["tiancheng zhao", "ran zhao", "maxine esk\u00e9nazi"], "accepted": true, "id": "1703.10960"}, "pdf": {"name": "1703.10960.pdf", "metadata": {"source": "CRF", "title": "Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders", "authors": ["Tiancheng Zhao", "Ran Zhao", "Maxine Eskenazi"], "emails": ["tianchez@cs.cmu.edu", "ranzhao1@cs.cmu.edu", "max+@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is the case that most of them are in a position to go into a different world, in which they are able to move, in which they move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they live, in which they, in which they, in which they are able to move, in which they are able to move, in which they are able to move, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they live, in which they, in which they live, in which they, in which they are able"}, {"heading": "2 Related Work", "text": "Our work relates both to recent advances in encoder decoder dialog models and to generative models based on CVAE."}, {"heading": "2.1 Encoder-decoder Dialog Models", "text": "Since the emergence of the model of neural dialogue, the issue of output diversity has received much attention in the research community. Ideal output responses should be both coherent and diverse. However, most models end with generic and boring answers. To address this problem, a research line focuses on expanding the input of encoder decoder models with richer context information to generate more specific responses. Li et al., (2016a) captured the characteristics of the speakers by encoding background information and speaking style into the distributed embedding that are used to reorder the generated response from an encoder decoder model. Xing et al., (2016) consider coding the topic based on latent dirichlet allocation (Blei et al., 2003) of the conversation to encourage the model to generate coherent responses."}, {"heading": "2.2 Conditional Variational Autoencoder", "text": "The variable autoencoder (UAE) (Kingma and Welling, 2013; Rezende et al., 2014) is one of the most popular frames for image generation. UAE's basic idea is to encode the input x in a probability distribution z rather than a dot encoded in the autoencoder. UAE then applies a decoder network to reconstruct the original input using examples from e.g. N (0, I). To generate images, VAE first receives a sample of z from the previous distribution, e.g. N (0, I), and then produces an image via the decoder network. A more advanced model, the conditional VAE (CVAE), is a recent modification of VAE to generate various images conditioned to specific attributes, e.g. the generation of different human faces based on skin color (Yan et al, 2015; et al.)."}, {"heading": "3 Proposed Models", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1 Conditional Variational Autoencoder (CVAE) for Dialog Generation", "text": "Each dyadic conversation can be represented by three random variables: the dialog context c (context window size k \u2212 1), the response x (the kth utterance), and a latent variable z, which is used to capture the latent distribution over the valid answers. We then define the conditional distribution p (x, z | c) = p (x, c) p (z | c) p (z | c) p (z | c) p (z | c) and our goal is to use deep neural networks (parameterized by prediction) and p (x | z, c). We point to the toparized distribution (z | c) as the previous network and psychic system (x, z, c) as a reaction decoder."}, {"heading": "3.2 Knowledge-Guided CVAE (kgCVAE)", "text": "In practice, CVAE training is a challenging optimization problem and often requires a large amount of data. On the other hand, the dialog managers (Litman and Allen, 1987; Raux et al., 2005; Zhao and Eskenazi, 2016) have used a variety of dialog files (Poesio and Dream, 1998) to illustrate the propositional function of the system. Therefore, we suspect that it will be beneficial for the model to learn latent z (Litman and Allen, 1987; Raux et al., 2005; Raux et al., 2005; Zhao and Eskenazi, 2016) to incorporate the linguistic features into the basic CVAE model. Therefore, we suspect that it will be useful for the model to learn latent z if it is provided with explicitly extracted discourse features during the training."}, {"heading": "3.3 Optimization Challenges", "text": "A simple UAE with RNN decoder fails to encode meaningful information in z due to the vanishing latent variable problem (Bowman et al., 2015). Bowman et al., (2015) proposed two solutions: (1) KL annealing: gradually increasing the weight of the KL term from 0 to 1 during training; (2) Word drop decoding: setting a certain percentage of target words to 0. We found that CVAE suffers from the same problem when the decoder is an RNN. Also, we did not consider decoding the word because Bowman et al. (2015) have shown that it can impair performance if the fall rate is too high. As a result, we propose a simple but novel technique to deal with the vanishing latent variable problem: word loss: sack-of-word loss. The idea is a word network that requires the word to encode x in the word (x)."}, {"heading": "4 Experiment Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Dataset", "text": "We chose the Switchboard (SW) 1 Release 2 Corpus (Godfrey and Holliman, 1997) to evaluate the proposed models. SW has 2400 two-page phone calls with manually transcribed language and orientation. At the beginning of the call, a computer operator gave recorded instructions to callers defining the topic to be discussed. 70 topics are available. We randomly divide the data into 2316 / 60 / 62 train / validation / test dialogs. Preprocessing includes (1) tokenizing with the NLTK tokenizer (Vogel et al., 2009); (2) removing nonverbal symbols and repeated words due to false starts; (3) keeping the most common 10K word types as vocabulary. The final data have 207, 833 / 5, 225 / 5, 481 (c, x) pairs for train / validation / test. In addition, a subset of SW was manually edited with the SW-2000 SW dialog (SW extract)."}, {"heading": "4.2 Training", "text": "We trained with the following hyperparameters (corresponding to the loss of the validation data set): Word embedding is size 200 and is shared everywhere. We initialize the word embedding of glove embedding that was previously trained on Twitter (Pennington et al., 2014). The statement encoder has a hidden size of 300 for each direction. The context encoder has a hidden size of 600 and the response encoder a hidden size of 400. The previous network and the MLP for predicting y both have a hidden layer of size 400 and tanh nonlinearity. The latent variable z has a size of 200. The context window k is 10. All initial weights are scanned from a uniform distribution [-0.08, 0.08]. The minibatch size is 30. The models are trained end-to-end with the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 5. We obtained the best BOD on a loss of 0.0001 and the best BOD loss on a diameter basis."}, {"heading": "5 Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Experiments Setup", "text": "We compared three neural dialog models: a strong base model, CVAE and kgCVAE. The base model is a neural dialog model between encoder and decoder without latent variables, similar to (Serban et al., 2016a).The base model encoder uses the same context encoder to encode the dialog history and meta functions as in Figure 3. The encoded context c is fed directly into the decoder networks as the initial state. Hyperparameters of the baseline are the same as in Section 4.2, and the baseline is trained to minimize the standard entropy loss of the decoder model RNN without additional loss.Also, to compare the variety introduced by stochasticity in the proposed latent variable, compared to the Softmax variable of RNN at each decoding step, we generate N responses from the base line by scanning the softline."}, {"heading": "5.2 Quantitative Analysis", "text": "This year, it has reached the point where it will be able to retaliate until it is able to retaliate."}, {"heading": "5.3 Qualitative Analysis", "text": "In Example 1, caller A starts with an open question. The kgCVAE model generated highly different answers covering several plausible dialog acts. In addition, we note that the generated text has similar dialog acts compared to the answers predicted separately from the model, implying the consistency of the natural language generation based on y. On the contrary, the answers from the base model are limited to local n-gram variations and share a similar prefix, i.e. \"I am.\" Example 2 is a situation in which caller A tells B stories. The down-to-earth truth response is a back channel and the range of valid answers is more limited than Example 1, since B plays the role of a listener. The baseline successfully predicts \"uh-huh.\" The kgCVAE model is able to generate different types of back-channeling, implying that the latent caller postrope is able to capture the network in a high-contextual area of the network."}, {"heading": "5.4 Results for Bag-of-Word Loss", "text": "Finally, we evaluate the effectiveness of bag-ofword (BOW) loss for training UAE / CVAE with the RNN decoder. To compare with the previous work (Bowman et al., 2015), we performed the same voice modeling (LM) task on Penn Treebank with UAE. However, the network architecture is the same unless we use GRU instead of LSTM. We compared four different training facilities: (1) Standard UAE without heuristics; (2) UAE with KL Annealing (KLA); (3) UAE with BOW loss; (4) UAE with both BOW loss and KLA. Intuitively, a well-trained model should result in a low reconstruction loss and small but non-trivial KL cost. For all models with KLA, the KL weight increases linearly from 0 to 1 in the first 5000 batches."}, {"heading": "6 Conclusion and Future Work", "text": "Finally, we have identified the one-to-many nature of open domain conversations and proposed two new models that demonstrate superior performance in generating diverse and appropriate responses at the discourse level. While the current paper focuses on diversifying responses to dialog acts, this work is part of a broader research direction that aims to leverage both past linguistic insights and the learning ability of deep neural networks to better understand the latent factors in dialog. In turn, the results of this novel neural dialog model will be easier for humans to explain and control. In addition to dialog files, we plan to apply our kgCVAE model to capture other linguistic phenomena, including feelings, named entities, etc. Last but not least, the recognition network in our model will serve as the basis for developing a data-driven dialogue manager that automatically detects useful intentions at a high level."}, {"heading": "7 Acknowledgements", "text": "This work was funded by the NSF grant CNS1512973. Opinions expressed in this paper do not necessarily reflect those of the NSF."}, {"heading": "A Supplemental Material", "text": "As a result, we have: L (v, c, y) + EqB (z, c, y) + EqB (z, c) + EqB (z, y) [log p, c, y)] + EqB (z, y) [log p, y, c)] + EqB (z, c) + EqB (z, y) [log p, c, y)] (collection of multiple reference responses We have set several reference responses for the test."}], "references": [{"title": "Fine-grained analysis of sentence embeddings using auxiliary prediction tasks", "author": ["Yossi Adi", "Einat Kermany", "Yonatan Belinkov", "Ofer Lavi", "Yoav Goldberg."], "venue": "arXiv preprint arXiv:1608.04207 .", "citeRegEx": "Adi et al\\.,? 2016", "shortCiteRegEx": "Adi et al\\.", "year": 2016}, {"title": "Natural language processing with Python", "author": ["Steven Bird", "Ewan Klein", "Edward Loper."], "venue": "\u201d O\u2019Reilly Media, Inc.\u201d.", "citeRegEx": "Bird et al\\.,? 2009", "shortCiteRegEx": "Bird et al\\.", "year": 2009}, {"title": "Latent dirichlet allocation", "author": ["David M Blei", "Andrew Y Ng", "Michael I Jordan."], "venue": "Journal of machine Learning research 3(Jan):993\u20131022.", "citeRegEx": "Blei et al\\.,? 2003", "shortCiteRegEx": "Blei et al\\.", "year": 2003}, {"title": "Ravenclaw: Dialog management using hierarchical task decomposition and an expectation agenda", "author": ["Dan Bohus", "Alexander I Rudnicky"], "venue": null, "citeRegEx": "Bohus and Rudnicky.,? \\Q2003\\E", "shortCiteRegEx": "Bohus and Rudnicky.", "year": 2003}, {"title": "Generating sentences from a continuous space", "author": ["Samuel R Bowman", "Luke Vilnis", "Oriol Vinyals", "Andrew M Dai", "Rafal Jozefowicz", "Samy Bengio."], "venue": "arXiv preprint arXiv:1511.06349 .", "citeRegEx": "Bowman et al\\.,? 2015", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "A systematic comparison of smoothing techniques for sentencelevel bleu", "author": ["Boxing Chen", "Colin Cherry."], "venue": "ACL 2014 page 362.", "citeRegEx": "Chen and Cherry.,? 2014", "shortCiteRegEx": "Chen and Cherry.", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1412.3555 .", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Bootstrapping dialog systems with word embeddings", "author": ["Gabriel Forgues", "Joelle Pineau", "Jean-Marie Larchev\u00eaque", "R\u00e9al Tremblay."], "venue": "NIPS, Modern Machine Learning and Natural Language Processing Workshop.", "citeRegEx": "Forgues et al\\.,? 2014", "shortCiteRegEx": "Forgues et al\\.", "year": 2014}, {"title": "Switchboard-1 release 2", "author": ["John J Godfrey", "Edward Holliman."], "venue": "Linguistic Data Consortium, Philadelphia .", "citeRegEx": "Godfrey and Holliman.,? 1997", "shortCiteRegEx": "Godfrey and Holliman.", "year": 1997}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "arXiv preprint arXiv:1412.6980 .", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Autoencoding variational bayes", "author": ["Diederik P Kingma", "Max Welling."], "venue": "arXiv preprint arXiv:1312.6114 .", "citeRegEx": "Kingma and Welling.,? 2013", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."], "venue": "arXiv preprint arXiv:1510.03055 .", "citeRegEx": "Li et al\\.,? 2015", "shortCiteRegEx": "Li et al\\.", "year": 2015}, {"title": "A persona-based neural conversation model", "author": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."], "venue": "arXiv preprint arXiv:1603.06155 .", "citeRegEx": "Li et al\\.,? 2016a", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Deep reinforcement learning for dialogue generation", "author": ["Jiwei Li", "Will Monroe", "Alan Ritter", "Dan Jurafsky."], "venue": "arXiv preprint arXiv:1606.01541 .", "citeRegEx": "Li et al\\.,? 2016b", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A plan recognition model for subdialogues in conversations", "author": ["Diane J Litman", "James F Allen."], "venue": "Cognitive science 11(2):163\u2013200.", "citeRegEx": "Litman and Allen.,? 1987", "shortCiteRegEx": "Litman and Allen.", "year": 1987}, {"title": "How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation", "author": ["Chia-Wei Liu", "Ryan Lowe", "Iulian V Serban", "Michael Noseworthy", "Laurent Charlin", "Joelle Pineau."], "venue": "arXiv preprint", "citeRegEx": "Liu et al\\.,? 2016", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "Visualizing data using t-sne", "author": ["Laurens van der Maaten", "Geoffrey Hinton."], "venue": "Journal of Machine Learning Research 9(Nov):2579\u20132605.", "citeRegEx": "Maaten and Hinton.,? 2008", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Bleu: a method for automatic evaluation of machine translation", "author": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."], "venue": "Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational", "citeRegEx": "Papineni et al\\.,? 2002", "shortCiteRegEx": "Papineni et al\\.", "year": 2002}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP. volume 14, pages 1532\u2013", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Towards an axiomatization of dialogue acts", "author": ["Massimo Poesio", "David Traum."], "venue": "Proceedings of the Twente Workshop on the Formal Semantics and Pragmatics of Dialogues (13th Twente Workshop on Language Technology. Citeseer.", "citeRegEx": "Poesio and Traum.,? 1998", "shortCiteRegEx": "Poesio and Traum.", "year": 1998}, {"title": "Lets go public! taking a spoken dialog system to the real world", "author": ["Antoine Raux", "Brian Langner", "Dan Bohus", "Alan W Black", "Maxine Eskenazi."], "venue": "in Proc. of Interspeech 2005. Citeseer.", "citeRegEx": "Raux et al\\.,? 2005", "shortCiteRegEx": "Raux et al\\.", "year": 2005}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Danilo Jimenez Rezende", "Shakir Mohamed", "Daan Wierstra."], "venue": "arXiv preprint arXiv:1401.4082 .", "citeRegEx": "Rezende et al\\.,? 2014", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "The influence of context on dialogue act recognition", "author": ["Eug\u00e9nio Ribeiro", "Ricardo Ribeiro", "David Martins de Matos."], "venue": "arXiv preprint arXiv:1506.00839 .", "citeRegEx": "Ribeiro et al\\.,? 2015", "shortCiteRegEx": "Ribeiro et al\\.", "year": 2015}, {"title": "Termweighting approaches in automatic text retrieval", "author": ["Gerard Salton", "Christopher Buckley."], "venue": "Information processing & management 24(5):513\u2013 523.", "citeRegEx": "Salton and Buckley.,? 1988", "shortCiteRegEx": "Salton and Buckley.", "year": 1988}, {"title": "Bidirectional recurrent neural networks", "author": ["Mike Schuster", "Kuldip K Paliwal."], "venue": "IEEE Transactions on Signal Processing 45(11):2673\u20132681.", "citeRegEx": "Schuster and Paliwal.,? 1997", "shortCiteRegEx": "Schuster and Paliwal.", "year": 1997}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["Iulian V Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau."], "venue": "Proceedings of the 30th AAAI Conference on Artificial Intelligence", "citeRegEx": "Serban et al\\.,? 2016a", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "A hierarchical latent variable encoder-decoder model for generating dialogues", "author": ["Iulian Vlad Serban", "Alessandro Sordoni", "Ryan Lowe", "Laurent Charlin", "Joelle Pineau", "Aaron Courville", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1605.06069 .", "citeRegEx": "Serban et al\\.,? 2016b", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "Learning structured output representation using deep conditional generative models", "author": ["Kihyuk Sohn", "Honglak Lee", "Xinchen Yan."], "venue": "Advances in Neural Information Processing Systems. pages 3483\u20133491.", "citeRegEx": "Sohn et al\\.,? 2015", "shortCiteRegEx": "Sohn et al\\.", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan."], "venue": "arXiv preprint", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Dialogue act modeling for automatic tagging and recognition", "author": ["Andreas Stolcke", "Noah Coccaro", "Rebecca Bates", "Paul Taylor", "Carol Van Ess-Dykema", "Klaus Ries", "Elizabeth Shriberg", "Daniel Jurafsky", "Rachel Martin", "Marie Meteer"], "venue": null, "citeRegEx": "Stolcke et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Stolcke et al\\.", "year": 2000}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in neural information processing systems. pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Least squares support vector machine classifiers", "author": ["Johan AK Suykens", "Joos Vandewalle."], "venue": "Neural processing letters 9(3):293\u2013300.", "citeRegEx": "Suykens and Vandewalle.,? 1999", "shortCiteRegEx": "Suykens and Vandewalle.", "year": 1999}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le."], "venue": "arXiv preprint arXiv:1506.05869 .", "citeRegEx": "Vinyals and Le.,? 2015", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}, {"title": "Partially observable markov decision processes for spoken dialog systems", "author": ["Jason D Williams", "Steve Young."], "venue": "Computer Speech & Language 21(2):393\u2013422.", "citeRegEx": "Williams and Young.,? 2007", "shortCiteRegEx": "Williams and Young.", "year": 2007}, {"title": "Sequence-to-sequence learning as beam-search optimization", "author": ["Sam Wiseman", "Alexander M Rush."], "venue": "arXiv preprint arXiv:1606.02960 .", "citeRegEx": "Wiseman and Rush.,? 2016", "shortCiteRegEx": "Wiseman and Rush.", "year": 2016}, {"title": "Topic augmented neural response generation with a joint attention mechanism", "author": ["Chen Xing", "Wei Wu", "Yu Wu", "Jie Liu", "Yalou Huang", "Ming Zhou", "Wei-Ying Ma."], "venue": "arXiv preprint arXiv:1606.08340 .", "citeRegEx": "Xing et al\\.,? 2016", "shortCiteRegEx": "Xing et al\\.", "year": 2016}, {"title": "Attribute2image: Conditional image generation from visual attributes", "author": ["Xinchen Yan", "Jimei Yang", "Kihyuk Sohn", "Honglak Lee."], "venue": "arXiv preprint arXiv:1512.00570 .", "citeRegEx": "Yan et al\\.,? 2015", "shortCiteRegEx": "Yan et al\\.", "year": 2015}, {"title": "Strategy and policy learning for nontask-oriented conversational systems", "author": ["Zhou Yu", "Ziyu Xu", "Alan W Black", "Alex I Rudnicky."], "venue": "17th Annual Meeting of the Special Interest Group on Discourse and Dialogue. volume 2, page 7.", "citeRegEx": "Yu et al\\.,? 2016", "shortCiteRegEx": "Yu et al\\.", "year": 2016}, {"title": "Recurrent neural network regularization", "author": ["Wojciech Zaremba", "Ilya Sutskever", "Oriol Vinyals."], "venue": "arXiv preprint arXiv:1409.2329 .", "citeRegEx": "Zaremba et al\\.,? 2014", "shortCiteRegEx": "Zaremba et al\\.", "year": 2014}, {"title": "Towards end-to-end learning for dialog state tracking and management using deep reinforcement learning", "author": ["Tiancheng Zhao", "Maxine Eskenazi."], "venue": "arXiv preprint arXiv:1606.02560 .", "citeRegEx": "Zhao and Eskenazi.,? 2016", "shortCiteRegEx": "Zhao and Eskenazi.", "year": 2016}], "referenceMentions": [{"referenceID": 3, "context": "Specifically, it typically takes a new utterance and the dialog context as input, and generates discourse-level decisions (Bohus and Rudnicky, 2003; Williams and Young, 2007).", "startOffset": 122, "endOffset": 174}, {"referenceID": 33, "context": "Specifically, it typically takes a new utterance and the dialog context as input, and generates discourse-level decisions (Bohus and Rudnicky, 2003; Williams and Young, 2007).", "startOffset": 122, "endOffset": 174}, {"referenceID": 37, "context": "different strategies to recover from non-understanding (Yu et al., 2016).", "startOffset": 55, "endOffset": 72}, {"referenceID": 33, "context": "com/snakeztc/NeuralDialog-CVAE the conventional approach of designing a dialog manager (Williams and Young, 2007) does not scale well to open-domain conversation models because of the vast quantity of possible decisions.", "startOffset": 87, "endOffset": 113}, {"referenceID": 30, "context": "encoder-decoder models (Sutskever et al., 2014) for modeling open-domain conversation (Vinyals and Le, 2015; Serban et al.", "startOffset": 23, "endOffset": 47}, {"referenceID": 32, "context": ", 2014) for modeling open-domain conversation (Vinyals and Le, 2015; Serban et al., 2016a).", "startOffset": 46, "endOffset": 90}, {"referenceID": 25, "context": ", 2014) for modeling open-domain conversation (Vinyals and Le, 2015; Serban et al., 2016a).", "startOffset": 46, "endOffset": 90}, {"referenceID": 11, "context": ", I don\u2019t know), rather than meaningful and specific answers (Li et al., 2015; Serban et al., 2016b).", "startOffset": 61, "endOffset": 100}, {"referenceID": 26, "context": ", I don\u2019t know), rather than meaningful and specific answers (Li et al., 2015; Serban et al., 2016b).", "startOffset": 61, "endOffset": 100}, {"referenceID": 35, "context": "Other features should be extracted and provided to the models as conditionals in order to generate more specific responses (Xing et al., 2016; Li et al., 2016a); (2) the second category aims to improve the encoder-decoder model itself, including decoding with beam search and its variations (Wiseman and Rush, 2016), encouraging responses that have long-term payoff (Li et al.", "startOffset": 123, "endOffset": 160}, {"referenceID": 12, "context": "Other features should be extracted and provided to the models as conditionals in order to generate more specific responses (Xing et al., 2016; Li et al., 2016a); (2) the second category aims to improve the encoder-decoder model itself, including decoding with beam search and its variations (Wiseman and Rush, 2016), encouraging responses that have long-term payoff (Li et al.", "startOffset": 123, "endOffset": 160}, {"referenceID": 34, "context": ", 2016a); (2) the second category aims to improve the encoder-decoder model itself, including decoding with beam search and its variations (Wiseman and Rush, 2016), encouraging responses that have long-term payoff (Li et al.", "startOffset": 139, "endOffset": 163}, {"referenceID": 13, "context": ", 2016a); (2) the second category aims to improve the encoder-decoder model itself, including decoding with beam search and its variations (Wiseman and Rush, 2016), encouraging responses that have long-term payoff (Li et al., 2016b), etc.", "startOffset": 214, "endOffset": 232}, {"referenceID": 36, "context": "We present a novel neural dialog model adapted from conditional variational autoencoders (CVAE) (Yan et al., 2015; Sohn et al., 2015),", "startOffset": 96, "endOffset": 133}, {"referenceID": 27, "context": "We present a novel neural dialog model adapted from conditional variational autoencoders (CVAE) (Yan et al., 2015; Sohn et al., 2015),", "startOffset": 96, "endOffset": 133}, {"referenceID": 4, "context": "We develop a training method in addressing the difficulty of optimizing CVAE for natural language generation (Bowman et al., 2015).", "startOffset": 109, "endOffset": 130}, {"referenceID": 2, "context": ", (2016) maintain topic encoding based on Latent Dirichlet Allocation (LDA) (Blei et al., 2003) of the conversation to encourage the model to output more topic coherent responses.", "startOffset": 76, "endOffset": 95}, {"referenceID": 10, "context": "Li et al., (2016a) captured speakers\u2019 characteristics by encoding background information and speaking style into the distributed embeddings, which are used to re-rank the generated response from an encoder-decoder model.", "startOffset": 0, "endOffset": 19}, {"referenceID": 10, "context": "Li et al., (2016a) captured speakers\u2019 characteristics by encoding background information and speaking style into the distributed embeddings, which are used to re-rank the generated response from an encoder-decoder model. Xing et al., (2016) maintain topic encoding based on Latent Dirichlet Allocation (LDA) (Blei et al.", "startOffset": 0, "endOffset": 241}, {"referenceID": 34, "context": "Wiseman and Rush (2016) focused on improving the decoder network by alleviating the biases between", "startOffset": 0, "endOffset": 24}, {"referenceID": 11, "context": "ing beam search, Li et al., (2016b) pointed out that the MLE objective of an encoder-decoder model is unable to approximate the real-world goal of the conversation.", "startOffset": 17, "endOffset": 36}, {"referenceID": 10, "context": "The variational autoencoder (VAE) (Kingma and Welling, 2013; Rezende et al., 2014) is one of the most popular frameworks for image generation.", "startOffset": 34, "endOffset": 82}, {"referenceID": 21, "context": "The variational autoencoder (VAE) (Kingma and Welling, 2013; Rezende et al., 2014) is one of the most popular frameworks for image generation.", "startOffset": 34, "endOffset": 82}, {"referenceID": 4, "context": "Bowman et al., (2015) have used VAE with Long-Short Term Memory (LSTM)-based recognition and decoder networks to generate sentences from a latent Gaussian variable.", "startOffset": 0, "endOffset": 22}, {"referenceID": 4, "context": "Bowman et al., (2015) have used VAE with Long-Short Term Memory (LSTM)-based recognition and decoder networks to generate sentences from a latent Gaussian variable. They showed that their model is able to generate diverse sentences with even a greedy LSTM decoder. They also reported the difficulty of training because the LSTM decoder tends to ignore the latent variable. We refer to this issue as the vanishing latent variable problem. Serban et al., (2016b) have applied a latent variable hierarchical encoder-decoder dialog model to introduce utterance-level variations and facilitate longer re-", "startOffset": 0, "endOffset": 461}, {"referenceID": 27, "context": "As proposed in (Sohn et al., 2015; Yan et al., 2015), CVAE can be efficiently trained with the Stochastic Gradient Variational Bayes (SGVB) framework (Kingma and Welling, 2013) by maximizing the variational lower bound of the conditional log likelihood.", "startOffset": 15, "endOffset": 52}, {"referenceID": 36, "context": "As proposed in (Sohn et al., 2015; Yan et al., 2015), CVAE can be efficiently trained with the Stochastic Gradient Variational Bayes (SGVB) framework (Kingma and Welling, 2013) by maximizing the variational lower bound of the conditional log likelihood.", "startOffset": 15, "endOffset": 52}, {"referenceID": 10, "context": ", 2015), CVAE can be efficiently trained with the Stochastic Gradient Variational Bayes (SGVB) framework (Kingma and Welling, 2013) by maximizing the variational lower bound of the conditional log likelihood.", "startOffset": 105, "endOffset": 131}, {"referenceID": 24, "context": "The utterance encoder is a bidirectional recurrent neural network (BRNN) (Schuster and Paliwal, 1997) with a gated recurrent unit (GRU) (Chung et al.", "startOffset": 73, "endOffset": 101}, {"referenceID": 6, "context": "The utterance encoder is a bidirectional recurrent neural network (BRNN) (Schuster and Paliwal, 1997) with a gated recurrent unit (GRU) (Chung et al., 2014) to encode each utterance into fixedsize vectors by concatenating the last hidden states of the forward and backward RNN ui = [~ hi, ~ hi].", "startOffset": 136, "endOffset": 156}, {"referenceID": 10, "context": "We then use the reparametrization trick (Kingma and Welling, 2013) to obtain samples of z either from N (z;\u03bc, \u03c32I) predicted by the recognition network (training) or N (z;\u03bc\u2032, \u03c3\u20322I) predicted by the prior network (testing).", "startOffset": 40, "endOffset": 66}, {"referenceID": 19, "context": "For example, dialog acts (Poesio and Traum, 1998) have been widely used in the dialog managers (Litman and Allen, 1987; Raux et al.", "startOffset": 25, "endOffset": 49}, {"referenceID": 14, "context": "For example, dialog acts (Poesio and Traum, 1998) have been widely used in the dialog managers (Litman and Allen, 1987; Raux et al., 2005; Zhao and Eskenazi, 2016) to represent the propositional function of the system.", "startOffset": 95, "endOffset": 163}, {"referenceID": 20, "context": "For example, dialog acts (Poesio and Traum, 1998) have been widely used in the dialog managers (Litman and Allen, 1987; Raux et al., 2005; Zhao and Eskenazi, 2016) to represent the propositional function of the system.", "startOffset": 95, "endOffset": 163}, {"referenceID": 39, "context": "For example, dialog acts (Poesio and Traum, 1998) have been widely used in the dialog managers (Litman and Allen, 1987; Raux et al., 2005; Zhao and Eskenazi, 2016) to represent the propositional function of the system.", "startOffset": 95, "endOffset": 163}, {"referenceID": 4, "context": "A straightforward VAE with RNN decoder fails to encode meaningful information in z due to the vanishing latent variable problem (Bowman et al., 2015).", "startOffset": 128, "endOffset": 149}, {"referenceID": 4, "context": "A straightforward VAE with RNN decoder fails to encode meaningful information in z due to the vanishing latent variable problem (Bowman et al., 2015). Bowman et al., (2015) proposed two solutions: (1) KL annealing: gradually increasing the weight of the KL term from 0 to 1 during training; (2) word drop decoding: setting a certain percentage of the target words to 0.", "startOffset": 129, "endOffset": 173}, {"referenceID": 4, "context": "A straightforward VAE with RNN decoder fails to encode meaningful information in z due to the vanishing latent variable problem (Bowman et al., 2015). Bowman et al., (2015) proposed two solutions: (1) KL annealing: gradually increasing the weight of the KL term from 0 to 1 during training; (2) word drop decoding: setting a certain percentage of the target words to 0. We found that CVAE suffers from the same issue when the decoder is an RNN. Also we did not consider word drop decoding because Bowman et al,. (2015) have shown that it may hurt the performance when the drop rate is too high.", "startOffset": 129, "endOffset": 519}, {"referenceID": 8, "context": "We chose the Switchboard (SW) 1 Release 2 Corpus (Godfrey and Holliman, 1997) to evaluate the proposed models.", "startOffset": 49, "endOffset": 77}, {"referenceID": 1, "context": "The pre-processing includes (1) tokenize using the NLTK tokenizer (Bird et al., 2009); (2) remove non-verbal symbols and repeated words due to false starts; (3) keep the top 10K frequent word types as the vocabulary.", "startOffset": 66, "endOffset": 85}, {"referenceID": 29, "context": "Furthermore, a subset of SW was manually labeled with dialog acts (Stolcke et al., 2000).", "startOffset": 66, "endOffset": 88}, {"referenceID": 22, "context": "We extracted dialog act labels based on the dialog act recognizer proposed in (Ribeiro et al., 2015).", "startOffset": 78, "endOffset": 100}, {"referenceID": 31, "context": "We trained a Support Vector Machine (SVM) (Suykens and Vandewalle, 1999) with linear kernel on the subset of SW with human annotations.", "startOffset": 42, "endOffset": 72}, {"referenceID": 18, "context": "We initialize the word embedding from Glove embedding pre-trained on Twitter (Pennington et al., 2014).", "startOffset": 77, "endOffset": 102}, {"referenceID": 9, "context": "The models are trained end-to-end using the Adam optimizer (Kingma and Ba, 2014) with a", "startOffset": 59, "endOffset": 80}, {"referenceID": 25, "context": "The baseline model is an encoder-decoder neural dialog model without latent variables similar to (Serban et al., 2016a).", "startOffset": 97, "endOffset": 119}, {"referenceID": 15, "context": "Automatically evaluating an open-domain generative dialog model is an open research challenge (Liu et al., 2016).", "startOffset": 94, "endOffset": 112}, {"referenceID": 5, "context": "Smoothed Sentence-level BLEU (Chen and Cherry, 2014): BLEU is a popular metric that measures the geometric mean of modified ngram precision with a length penalty (Papineni et al.", "startOffset": 29, "endOffset": 52}, {"referenceID": 17, "context": "Smoothed Sentence-level BLEU (Chen and Cherry, 2014): BLEU is a popular metric that measures the geometric mean of modified ngram precision with a length penalty (Papineni et al., 2002; Li et al., 2015).", "startOffset": 162, "endOffset": 202}, {"referenceID": 11, "context": "Smoothed Sentence-level BLEU (Chen and Cherry, 2014): BLEU is a popular metric that measures the geometric mean of modified ngram precision with a length penalty (Papineni et al., 2002; Li et al., 2015).", "startOffset": 162, "endOffset": 202}, {"referenceID": 7, "context": "Cosine Distance of Bag-of-word Embedding: a simple method to obtain sentence embeddings is to take the average or extrema of all the word embeddings in the sentences (Forgues et al., 2014; Adi et al., 2016).", "startOffset": 166, "endOffset": 206}, {"referenceID": 0, "context": "Cosine Distance of Bag-of-word Embedding: a simple method to obtain sentence embeddings is to take the average or extrema of all the word embeddings in the sentences (Forgues et al., 2014; Adi et al., 2016).", "startOffset": 166, "endOffset": 206}, {"referenceID": 28, "context": "Inspired by (Sordoni et al., 2015), we utilized information retrieval techniques (see Appendix A) to gather 10 extra candidate reference responses/context from other conversations with the same topics.", "startOffset": 12, "endOffset": 34}, {"referenceID": 10, "context": "In addition, past work (Kingma and Welling, 2013) has shown that the recognition network is able to learn to cluster high-dimension data, so we conjecture that posterior z outputted from the recognition network should cluster the responses into meaningful groups.", "startOffset": 23, "endOffset": 49}, {"referenceID": 16, "context": "Figure 5 visualizes the posterior z of responses in the test dataset in 2D space using t-SNE (Maaten and Hinton, 2008).", "startOffset": 93, "endOffset": 118}, {"referenceID": 4, "context": "To compare with past work (Bowman et al., 2015), we conducted the same language modelling (LM) task on Penn Treebank using VAE.", "startOffset": 26, "endOffset": 47}, {"referenceID": 38, "context": "The standard VAE fails to learn a meaningful latent variable by having a KL cost close to 0 and a reconstruction perplexity similar to a small LSTM LM (Zaremba et al., 2014).", "startOffset": 151, "endOffset": 173}], "year": 2017, "abstractText": "While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved by introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making.1", "creator": "LaTeX with hyperref package"}}}