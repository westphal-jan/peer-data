{"id": "1704.02685", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "10-Apr-2017", "title": "Learning Important Features Through Propagating Activation Differences", "abstract": "The purported \"black box\"' nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. A detailed video tutorial on the method is at", "histories": [["v1", "Mon, 10 Apr 2017 02:23:57 GMT  (1205kb,D)", "http://arxiv.org/abs/1704.02685v1", "9 pages, 6 figures"]], "COMMENTS": "9 pages, 6 figures", "reviews": [], "SUBJECTS": "cs.CV cs.LG cs.NE", "authors": ["avanti shrikumar", "peyton greenside", "anshul kundaje"], "accepted": true, "id": "1704.02685"}, "pdf": {"name": "1704.02685.pdf", "metadata": {"source": "META", "title": "Learning Important Features Through Propagating Activation Differences", "authors": ["Avanti Shrikumar", "Peyton Greenside", "Anshul Kundaje"], "emails": ["(avanti@stanford.edu),", "(pgreens@stanford.edu),", "(akundaje@stanford.edu)."], "sections": [{"heading": "1. Introduction", "text": "As neural networks become increasingly popular, their reputation as black boxes is an obstacle to adoption when interpretability comes first. At this point, we introduce DeepLIFT (Deep Learning Important FeaTures), a novel algorithm that assigns a value to inputs for a given output. Unlike most gradient-based methods, our approach is unique in two ways: First, it raises the question of the importance of differences to a \"reference state,\" where the \"reference value\" is selected by the user according to the problem at hand. Unlike most gradient-based methods, DeepLIFT allows a meaning signal to be disseminated even in situations where the gradient is zero and avoids artifacts caused by gradient discontinuity. Second, by optionally considering the effects of positive and negative contribu-1Stanford University, Stanford, California, USA."}, {"heading": "2. Previous Work", "text": "This section provides an overview of existing approaches to assigning importance values for a given task and an input example."}, {"heading": "2.1. Perturbation-based forward propagation approaches", "text": "Zeiler & Fergus (Zeiler & Fergus, 2013) have occluded different segments of an input image and visualized changes in the activation of subsequent layers. \"In-silico mutagenesis\" (Zhou & Troyanskaya, 2015) has introduced virtual mutations at individual positions in a genomic sequence and quantified their effects on output. Zintgraf et al. (Zintgraf et al., 2017) have proposed a clever strategy for analyzing the difference in a prediction after they have been marginalized across each input range. However, such methods can be computationally inefficient as each disturbance requires a separate propagation through the network. They may also underestimate the importance of features that have saturated their contribution to output (Fig. 1).ar Xiv: 170 4.02 685v 1 [cs.C V] 10 April 207"}, {"heading": "2.2. Backpropagation-based approaches", "text": "In contrast to disturbance methods, back propagation approaches are computationally efficient because they propagate an important signal from the initial neuron backwards through the layers to the input in a single pass. DeepLIFT belongs to this family of approaches."}, {"heading": "2.2.1. GRADIENTS, DECONVOLUTIONAL NETWORKS AND GUIDED BACKPROPAGATION", "text": "Simonyan et al. (Simonyan et al., 2013) proposed using the gradient of the output w.r.t. pixels of an input image to calculate a \"saliency map\" of the image in the context of image classification, which the authors showed to be similar to derevolutionary networks (Zeiler & Fergus, 2013), except for the handling of nonlinearity in linear units (ReLUs). In reverse propagation using gradients, the gradient entering a ReLU during reverse is zero if the input to the ReLU is negative during forward propagation. In contrast, when a meaning signal is propagated backwards in deconventional networks, the importance signal entering a ReLU during reverse is zero, and only if it is negative."}, {"heading": "2.2.2. LAYERWISE RELEVANCE PROPAGATION AND GRADIENT \u00d7 INPUT", "text": "Bach et al. (Bach et al., 2015) proposed an approach for disseminating meaning values called Layerwise Relevance Propagation (LRP). Shrikumar et al. and Kindermans et al. (Shrikumar et al., 2016; Kindermans et al., 2016) showed that the original LRP rules were equivalent to an elementary product between the highlighting maps of Simonyan et al. and the input (in other words: gradient input) without any changes in numerical stability within a scaling factor. In our experiments, we compare DeepLIFT with gradient input, as the latter can easily be implemented on a GPU, whereas LRP currently does not have GPU implementations available."}, {"heading": "2.2.3. INTEGRATED GRADIENTS", "text": "Instead of calculating the gradients only by the current value of the input, one can integrate the gradients by scaling the input from a starting value (e.g. all zeros) to its current value (Sundararajan et al., 2016). This addresses the saturation and threshold problems of Fig. 1 and Fig. 2, but achieving high-quality integrals numerically increases the computational effort. Moreover, this approach can still provide highly misleading results (see Section 3.4.3)."}, {"heading": "2.3. Grad-CAM and Guided CAM", "text": "Grad-CAM (Selvaraju et al., 2016) calculates a coarse-grained feature-importance map by linking the feature cards in the last folding layer with specific classes based on the gradients of each class and each feature card, and then using the weighted activations of the feature cards as an indication of which inputs are most important. To obtain a finer-grained feature-importance, the authors proposed to perform an elementary product between the values from Grad-CAM and the values from Guided Backpropagation, called Guided Grad-CAM. However, this strategy inherits the limitations of Guided Backpropagation caused by balancing negative gradients during backpropagation. It is also specific to evolutionary neural networks."}, {"heading": "3. The DeepLIFT Method", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.1. The DeepLIFT Philosophy", "text": "DeepLIFT explains the difference in the output of a \"reference result\" in relation to the difference in the input from a \"reference result.\" Formally, the \"reference result\" represents a standard or \"neutral\" input, which is selected according to what is appropriate for the problem at hand (see Section 3.3 for more details). Let us not represent any target result neuron of interest and let x1, x2,... xn represent some neurons in an intermediate layer or set of layers that are necessary and sufficient to calculate t. Let t0 activate the reference of. We define the quantity \u2206 t as a difference-by-reference, that is \u0445t = t \u2212 t0. DeepLIFT assigns the contribution results the values C, xi \u0445 t to \u0432.t. This difference in relation to LIFT is important even if the difference between LIFT and the Ejar function is attributed."}, {"heading": "3.2. Multipliers and the Chain Rule", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "3.2.1. DEFINITION OF MULTIPLIERS", "text": "For a given input neuron x with difference-from-reference point \u2206 x and target neuron t with difference-from-reference point \u2206 t to which we want to calculate the contribution, we define the multiplier m \u2206 x \u2206 t as follows: m \u2206 x \u0445 t = C \u2206 x \u0445 x (2) In other words, the multiplier m \u2206 x \u2206 t is the contribution from \u2206 x to \u2206 t divided by \u0445 x. Note the close analogy to its partial derivative: The partial derivative \u2202 t \u2202 x is the infinitesimal change in t caused by an infinitesimal change in x divided by the infinitesimal change in x. The multiplier is similar in the spirit of a partial derivative, but over finite rather than infinitesimal differences."}, {"heading": "3.2.2. THE CHAIN RULE FOR MULTIPLIERS", "text": "Suppose we have an input layer with neurons x1,..., xn, a hidden layer with neurons y1,..., yn and some target output neurons. By specifying values for m \u2206 xi \u2206 yj \u2206 z, the following definition of m \u0445 xi \u0445 z corresponds to the addition-to-delta property in Equation 1 (see Appendix A for proof): m \u0445 xi \u0445 z = \u2211 j m xxi \u0445 yyym \u0445 yj \u0445 z (3) We refer to Equation 3 as the chain rule for multipliers. By specifying the multipliers for each neuron to its immediate successors, we can efficiently calculate the multipliers for each neuron to a specific target neuron by back propagation - analogous to how the chain rule for partial derivatives allows us to calculate the output by back propagation."}, {"heading": "3.3. Defining the reference", "text": "When formulating the DeepLIFT rules described in Section 3.5, we assume that the reference of a neuron is its activation on the reference input. Formally, we can say that we have a neuron x with the inputs i1, i2,..., so that x = f (i1, i2,...). Given the reference activations i01, i 0 2,... of the inputs, we can find the reference activation x0 of the output as: x0 = f (i01, i 0 2,...) (4) i.e. references for all neurons by selecting a reference input and propagating activations through the network. Choosing a reference input is crucial to get insightful results from DeepLIFT. In practice, choosing a good reference input would be based on domain-specific knowledge, and in some cases it is best to calculate DeepLIFT scores against multiple different references."}, {"heading": "3.4. Separating positive and negative contributions", "text": "In Section 3.5.3, we will see that in some situations it is essential to treat positive and negative contributions differently. To do this, we will introduce for each neuron xi \u2206 x + i and \u2206 x \u2212 i, which represent the positive and negative components of \u2206 xi, so that the significance of this will become apparent in the discussion of the disclosure rule (Section 3.5.3), where we will find that m \u00b2 x + i \u00b2 t and m \u00b2 x \u2212 i \u00b2 t can be different. However, for the linear and rescale rules (Section 3.5.1 and Section 3.5.2), we have m \u00b2 xi \u00b2 t = m \u00b2 x + i \u00b2 t = m \u00b2 x \u2212 i \u00b2."}, {"heading": "3.5. Rules for assigning contribution scores", "text": "We present the rules for assigning contribution values for each neuron to its immediate inputs. In conjunction with the chain rule for multipliers (Section 3.2), these rules can be used to find the contributions of all inputs (not just direct inputs) to a target output by backpropagation."}, {"heading": "3.5.1. THE LINEAR RULE", "text": "Let y be a linear function of its inputs xi, so that y = b + p \u00b2 i wixi. We have \u2206 y = p \u00b2 i \u00b2 xi. we define the positive and negative parts of \u2206 y as follows: \u2206 y + = p \u00b2 i 1 {wi \u00b2 xi > 0} wi = p = p \u00b2 i 1 {wi \u00b2 xi > 0} wi = p = p \u00b2 i 1 {wi \u00b2 xi > 0} wi (x + p \u00b2 x \u2212 i) p = p \u00b2 i 1 {wi p \u00b2 i 1 {wi p \u00b2 xi < 0} wi = p = p \u00b2 x \u2212 i) p = p \u00b2 p \u00b2 p = p \u00b2 x \u00b2 p p = p \u00b2 p p p p \u00b2 p = p \u00b2 p p p p = p \u00b2 p p p = p \u00b2 p = p \u00b2 p p = p \u00b2 p = p \u00b2 p p p = p \u00b2 p p p = p \u00b2 p p p = p \u00b2 p = p \u00b2 p p = p \u00b2 p = p \u00b2 p = p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p = p \u00b2 p \u00b2 p \u00b2 p \u00b2 p \u00b2 p p \u00b2 p p p \u00b2 p = p p \u00b2 p \u00b2 p \u00b2 p p p p p \u00b2 p"}, {"heading": "3.5.2. THE RESCALE RULE", "text": "This rule applies to nonlinear transformations that require a single input, such as ReLU, Tanh, or sigmoid operations. Let neuron y be a nonlinear transformation of its input x, so that y = f (x). Since y has only one input, we have, by summing-to-delta, C \u2206 x \u2206 y = \u2206 y, and consequently m \u00b2 x \u00b2 y = \u2206 y \u00b2 x. For the rescale rule, we set \"y\" + and \"y \u2212 proportional to\" x \"and\" x \"as follows:\" y + = \"y \u00b2 x \u00b2 x \u00b2 x \u00b2 x,\" and consequently \"y \u00b2 x \u00b2 x \u00b2 x \u00b2.\" As a starting point for the rescale rule, we use: m \u00b2 x \u00b2 and \"y \u00b2 x \u00b2 x,\" where \"ig \u00b2 y \u00b2 x \u00b2 x x and.\" as a starting point for the input and \"y \u2212 y \u2212 proportional to\" x \"and\" x \u00b2 x \u00b2 x. \""}, {"heading": "3.5.3. AN IMPROVED APPROXIMATION OF THE", "text": "SHAPELY VALUES: THE REVEALCANCEL RULEWhile the Rescale rule better on simply using gradients, there are still some situation, where it can be misleading results. Consider the min (i1, i2) operation shown in Figure 3, with reference values of i1 = 0 and i2 = 0. To understand why this happens, consider the case when i1 > i2 assigns all meaning to either i1 or i2 (whichever is smaller). We have h1 = (i1 \u2212 i2) > h2 = max (0, h1) = h1 = h1. Using the linear rule, we calculate that C-1 = i1 and C-2 = i2."}, {"heading": "3.6. Choice of target layer", "text": "In the case of Softmax or Sigmoid output, one would prefer to calculate contributions to the linear layer that precedes the final nonlinearity rather than the final nonlinearity itself, which would mean avoiding an attribution caused by the summation-to-delta property described in Section 3.1. For example, consider a sigmoid output o = \u03c3 (y), where y is the logit of the sigmoid function. Suppose y = x1 + x2, where x01 = x 0 is 2 = 0. If x1 = 50 and x2 = 0, the output o saturates very close to 1 and the contributions of x1 and x2 are 0.5 and 0 respectively. However, if x1 = 100 and x2 = 100 the output o is still very close to 0, but the contributions of x1 and x2 are now both very close to the final sum, this can be misleading when comparing the results of x1 and x2, because a stronger contribution to the normal classes would not always translate into a higher LIFT class."}, {"heading": "4. Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1. Digit classification (MNIST)", "text": "We train a Convolutionary Neural Network on MNIST (LeCun et al., 1999) with Keras (Chollet, 2015) to perform a number classification and obtain an accuracy of 99.2% of the test kits; the architecture consists of two Convolutionary layers followed by a fully connected layer followed by the softmax output layer (see Appendix D for full details of model architecture and training); we used convolutions with step > 1 instead of layers that did not cause a performance drop consistent with previous work (Springenberg et al., 2014); for DeepLIFT and integrated gradients, we used a reference input of all the zero values obtained by various methods, we design the following task: Based on an image that originally belongs to class co, we determine which pixels are deleted to convert the image into a specific target class."}, {"heading": "4.2. Classifying regulatory DNA sequences (Genomics)", "text": "This year it is more than ever before."}, {"heading": "5. Conclusion", "text": "We have introduced DeepLIFT, a novel approach to calculating meaning values based on explaining the difference in the output of some \"reference outputs\" in terms of the differences between the inputs and their \"reference inputs.\" Using the difference-by-reference allows information to be disseminated even when the gradient is zero (Fig. 1), which could prove particularly useful in recursive neural networks where saturating activations such as Sigmoid or Tanh are popular. DeepLIFT avoids placing potentially misleading meaning on bias terms (as opposed to gradient * inputs - see Fig. 2). By treating positive and negative inputs separately, the DeepLIFT RevealCancel rule can identify dependencies that are overlooked by other methods (Fig. 3). Open questions include how to apply DeepLIFT to RNNNNNNNNs, how to calculate a good reference from maxim data, and how to use it in propagated RNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn"}, {"heading": "6. Appendix", "text": "The annex can be downloaded from https: / / goo.gl / T114x4"}, {"heading": "7. Author Contributions", "text": "AS & PG designed DeepLIFT; AS implemented DeepLIFT; AS conducted experiments on MNIST; AS & PG conducted experiments on genomic data; AK gave guidance and feedback; AS, PG and AK wrote the manuscript."}, {"heading": "8. Acknowledgements", "text": "We thank Anna Shcherbina for early experiments on the application of DeepLIFT to image data and beta testing."}], "references": [{"title": "Systematic discovery and characterization of regulatory motifs in encode tf binding experiments", "author": ["Kheradpour", "Pouya", "Kellis", "Manolis"], "venue": "Nucleic acids research,", "citeRegEx": "Kheradpour et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Kheradpour et al\\.", "year": 2014}, {"title": "Investigating the influence of noise and distractors on the interpretation of neural networks", "author": ["Kindermans", "Pieter-Jan", "Schtt", "Kristof", "Mller", "KlausRobert", "Dhne", "Sven"], "venue": "CoRR, abs/1611.07270,", "citeRegEx": "Kindermans et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Kindermans et al\\.", "year": 2016}, {"title": "The mnist database of handwritten digits", "author": ["LeCun", "Yann", "Cortes", "Corinna", "Burges", "Christopher J.C"], "venue": "http://yann.lecun.com/exdb/mnist/,", "citeRegEx": "LeCun et al\\.,? \\Q1999\\E", "shortCiteRegEx": "LeCun et al\\.", "year": 1999}, {"title": "An unexpected unity among methods for interpreting model predictions", "author": ["Lundberg", "Scott", "Lee", "Su-In"], "venue": "CoRR, abs/1611.07478,", "citeRegEx": "Lundberg et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Lundberg et al\\.", "year": 2016}, {"title": "Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based localization", "author": ["tra", "Dhruv"], "venue": "CoRR, abs/1610.02391,", "citeRegEx": "tra and Dhruv.,? \\Q2016\\E", "shortCiteRegEx": "tra and Dhruv.", "year": 2016}, {"title": "Not just a black box: Learning important features through propagating activation differences", "author": ["Shrikumar", "Avanti", "Greenside", "Peyton", "Shcherbina", "Anna", "Kundaje", "Anshul"], "venue": "arXiv preprint arXiv:1605.01713,", "citeRegEx": "Shrikumar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Shrikumar et al\\.", "year": 2016}, {"title": "Deep inside convolutional networks: Visualising image classification models and saliency maps", "author": ["Simonyan", "Karen", "Vedaldi", "Andrea", "Zisserman", "Andrew"], "venue": "arXiv preprint arXiv:1312.6034,", "citeRegEx": "Simonyan et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Simonyan et al\\.", "year": 2013}, {"title": "Striving for simplicity: The all convolutional net", "author": ["Springenberg", "Jost Tobias", "Dosovitskiy", "Alexey", "Brox", "Thomas", "Riedmiller", "Martin A"], "venue": "CoRR, abs/1412.6806,", "citeRegEx": "Springenberg et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Springenberg et al\\.", "year": 2014}, {"title": "Gradients of counterfactuals", "author": ["Sundararajan", "Mukund", "Taly", "Ankur", "Yan", "Qiqi"], "venue": "CoRR, abs/1611.02639,", "citeRegEx": "Sundararajan et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sundararajan et al\\.", "year": 2016}, {"title": "Visualizing and understanding convolutional networks", "author": ["Zeiler", "Matthew D", "Fergus", "Rob"], "venue": "CoRR, abs/1311.2901,", "citeRegEx": "Zeiler et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Zeiler et al\\.", "year": 2013}, {"title": "Predicting effects of noncoding variants with deep learning-based sequence model", "author": ["Zhou", "Jian", "Troyanskaya", "Olga G"], "venue": "Nat Methods,", "citeRegEx": "Zhou et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Zhou et al\\.", "year": 2015}, {"title": "Visualizing deep neural network decisions: Prediction difference analysis", "author": ["Zintgraf", "Luisa M", "Cohen", "Taco S", "Adel", "Tameem", "Welling", "Max"], "venue": "ICLR,", "citeRegEx": "Zintgraf et al\\.,? \\Q2017\\E", "shortCiteRegEx": "Zintgraf et al\\.", "year": 2017}], "referenceMentions": [{"referenceID": 11, "context": "(Zintgraf et al., 2017) proposed a clever strategy for analyzing the difference in a prediction after marginalizing over each input patch.", "startOffset": 0, "endOffset": 23}, {"referenceID": 6, "context": "(Simonyan et al., 2013) proposed using the gradient of the output w.", "startOffset": 0, "endOffset": 23}, {"referenceID": 7, "context": ", (Springenberg et al., 2014) combined these two approaches into Guided Backpropagation, which zero\u2019s out the importance signal at a ReLU if either the input to the ReLU during the forward pass is negative or the importance signal during the backward pass is negative.", "startOffset": 2, "endOffset": 29}, {"referenceID": 5, "context": "(Shrikumar et al., 2016; Kindermans et al., 2016) showed that absent modifications to deal with numerical stability, the original LRP rules were equivalent within a scaling factor to an elementwise product between the saliency maps of Simonyan et al.", "startOffset": 0, "endOffset": 49}, {"referenceID": 1, "context": "(Shrikumar et al., 2016; Kindermans et al., 2016) showed that absent modifications to deal with numerical stability, the original LRP rules were equivalent within a scaling factor to an elementwise product between the saliency maps of Simonyan et al.", "startOffset": 0, "endOffset": 49}, {"referenceID": 8, "context": "Instead of computing the gradients at only the current value of the input, one can integrate the gradients as the inputs are scaled up from some starting value (eg: all zeros) to their current value (Sundararajan et al., 2016).", "startOffset": 199, "endOffset": 226}, {"referenceID": 2, "context": "We train a convolutional neural network on MNIST (LeCun et al., 1999) using Keras (Chollet, 2015) to perform digit classification and obtain 99.", "startOffset": 49, "endOffset": 69}, {"referenceID": 7, "context": "We used convolutions with stride > 1 instead of pooling layers, which did not result in a drop in performance as is consistent with previous work (Springenberg et al., 2014).", "startOffset": 146, "endOffset": 173}], "year": 2017, "abstractText": "The purported \u201cblack box\u201d nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its \u2018reference activation\u2019 and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. A detailed video tutorial on the method is at http://goo.gl/qKb7pL and code is at http://goo.gl/RM8jvH.", "creator": "LaTeX with hyperref package"}}}