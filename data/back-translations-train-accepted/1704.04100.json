{"id": "1704.04100", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-Apr-2017", "title": "Cross-lingual and cross-domain discourse segmentation of entire documents", "abstract": "Discourse segmentation is a crucial step in building end-to-end discourse parsers. However, discourse segmenters only exist for a few languages and domains. Typically they only detect intra-sentential segment boundaries, assuming gold standard sentence and token segmentation, and relying on high-quality syntactic parses and rich heuristics that are not generally available across languages and domains. In this paper, we propose statistical discourse segmenters for five languages and three domains that do not rely on gold pre-annotations. We also consider the problem of learning discourse segmenters when no labeled data is available for a language. Our fully supervised system obtains 89.5% F1 for English newswire, with slight drops in performance on other domains, and we report supervised and unsupervised (cross-lingual) results for five languages in total.", "histories": [["v1", "Thu, 13 Apr 2017 12:54:30 GMT  (27kb)", "https://arxiv.org/abs/1704.04100v1", "To appear in Proceedings of ACL 2017"], ["v2", "Mon, 24 Apr 2017 14:03:10 GMT  (28kb)", "http://arxiv.org/abs/1704.04100v2", "To appear in Proceedings of ACL 2017"]], "COMMENTS": "To appear in Proceedings of ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["chlo\u00e9 braud", "oph\u00e9lie lacroix", "anders s\u00f8gaard"], "accepted": true, "id": "1704.04100"}, "pdf": {"name": "1704.04100.pdf", "metadata": {"source": "CRF", "title": "Cross-lingual and cross-domain discourse segmentation of entire documents", "authors": ["Chlo\u00e9 Braud"], "emails": ["chloe.braud@gmail.com", "lacroix@di.ku.dk", "soegaard@di.ku.dk"], "sections": [{"heading": null, "text": "ar Xiv: 170 4.04 100v 2 [cs.C L] 24 Apr 201 7Discourse segmentation is a critical step in building end-to-end discourse savers. However, discourse segmentators exist only for a few languages and domains. Normally, they only recognize intra-sentential segment boundaries, assume gold standard sentences and token segmentation, and rely on high-quality syntactical parsing and rich heuristics that are not generally available across languages and domains. In this paper, we suggest statistical discourse segmentators for five languages and three domains that do not rely on gold preannotation. We also consider the problem of learning discourse segmentation when there is no marked data available for one language. Our fully monitored system achieves 89.5% F1 for English news broadcasts, with slight drops in performance in other domains, and we report monitored and unattended (total) linguistic results for five languages."}, {"heading": "1 Introduction", "text": "The aim is to identify the minimum units - called elementary discourse units (EDU) - in the documents, which are then linked by discourse relations. For example, sentences (1a) and (1b) 1 are each divided into two sentences, each connected by a CONTRAST and an ATTRIBUTION relationship. Editors are usually clauses and can cover a full sentence. This step is crucial: a segmentation error leads to an error in the final analysis. Discourse segmentation can also inform other tasks, such as the argumentations.The examples come from the RST discourse Treebank.mining, anaphora resolution or redeactivity. (Sidarenka et al, 2015)."}, {"heading": "2 Related work", "text": "For English RST-DT, the best discourse segmentation results were presented in Xuan Bach et al. (2012) (F1 91.0% with automatic analysis, 93.7% with gold analysis) - and in Joty et al. (2015) for the Instructional Corpus (Subba and Di Eugenio, 2009) (F1 80.9% with 10-fold analysis); segmentators based on handwritten rules were developed for Brazilian Portuguese (Pardo and Nunes, 2008) (51.3% to 56.8%, depending on the genre), Spanish (da Cunha et al., 2010, 2012) and Dutch (van der Vliet, 2010) (73% with automatic analysis, 82% with gold analysis).2Most statistical discourse segmentators are based on classifiers (Fisher and Roark, 2007) that are not based on synchronized knowledge (Joty et al., 2015)."}, {"heading": "3 Discourse segmentation", "text": "The annotation guidelines define what the essence of the EDU is, relying largely on lexical and syntactical references. When sentences and independent clauses are always minimal units, the task becomes difficult. In English RST-DT (Carlson and Marcu, 2001), lexical information is of crucial importance: for example, the presence of the discourse binding \"but\" in Example (1a) 3 indicates the beginning of an EDU. Furthermore, clerical additions to verbs are generally not treated as EDU. Exceptions are the additions to associations, as in (1b), and the infinitive clauses, which characterize a PURPOSE relationship as a second EDU relationship."}, {"heading": "4 Cross-lingual/-domain segmentation", "text": "To form statistical segmentators for new, resource-poor languages and domains, we propose combining corpora within a learning environment with multiple tasks (Section 5) to build a system for one (target) language (or domain). Cross-domain models are trained on all other (source) domains (or domains) and the parameters are matched to data for the target domain. This allows us to improve performance when commenting only a few data points (i.e. development records) for a particular domain (semi-monitored environment). Cross-lingual For lingual experiments, we align the parameters of our system with data for three languages with sufficient data sets (i.e. German, Spanish and Portuguese)."}, {"heading": "5 Multi-task learning", "text": "Our models perform the sequence marking based on a stacked k-layer of bidirectional LSTMs, a variant of LSTMs (Hochreiter and Schmidhuber, 1997) that reads the input in regular and reverse order, taking into account both the left and right context (Graves and Schmidhuber, 2005). For our task, for example, this allows us to distinguish between coordinated nouns and clauses; the sequence goes through an embedding layer, and we calculate the predictions of forward and backward stacked states for the k-stacked layers; at the upper level, we calculate the Softmax predictions for each word using pre-trained vectors; the sequence goes through a fictitious layer, and we calculate the predictions of forward and backward stacked states for the k-stacked layers; at the upper level, we calculate the Softmax predictions for each word based on a linear transformation."}, {"heading": "6 Corpora", "text": "Table 1 summarizes the statistics on the data. In English, we use four corporas that allow us to evaluate cross-domain performance: the RST-DT4We used a modified version of (Plank et al., 2016), which specified the random seed and used the standard SGD. (En-DT), consisting of articles from the Wall Street Journal; the SFU Review Corpus5 (En-SFU-DT), which included product ratings, news, travel guides and guides. For cross-lingual experiments, we use commented corpus for Spanish (Subba and Di Eugenio, 2009), which are based on instructions for use; and the GUM Corpus6 (En-Gum-DT), which includes interviews, news, travel guides and guides. For cross-lingual experiments, we use commented corpus for Spanish (EsDT) (EsDT) (Deunda Ciede, Neumann, 2004, D7) and (German)."}, {"heading": "7 Experiments", "text": "The data we use is only a part of ourselves. (The others we are able to reconsider the results, we are able to analyze the results, we are able to analyze the results, we are able to analyze the results, we are able to grasp the boundaries between the different languages, we are able to analyze the results, we are able to analyze the boundaries of UDPipe (UDP-S), 8 and (b) when the boundaries of EDU boundaries are added we are able to grasp the boundaries between each token5https: / / www.sfu.ca / mtaboada 6https: / georgetown.edu / 7We use only the test set from the annotator A. http: / ufal.mff.cuni.Ucz / PodP-interface, or \"UNT-DP-PEP.\""}, {"heading": "8 Conclusion", "text": "We proposed new good-performing discourse segmentators for many languages and document-level domains, within a fully predicted framework and only using language-independent tools."}, {"heading": "Acknowledgements", "text": "We thank the anonymous reviewers for their comments. This research is funded by the ERC Starting Grant LOWLANDS No. 313695."}], "references": [{"title": "CSTNews - a discourse-annotated corpus for single and multi", "author": ["Paula C.F. Cardoso", "Erick G. Maziero", "Mara Luca Castro Jorge", "Eloize R.M. Seno", "Ariani Di Felippo", "Lucia Helena Machado Rino", "Maria das Gracas Volpe Nunes", "Thiago A.S. Pardo"], "venue": null, "citeRegEx": "Cardoso et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Cardoso et al\\.", "year": 2011}, {"title": "Discourse tagging reference manual", "author": ["Lynn Carlson", "Daniel Marcu."], "venue": "Technical report, University of Southern California Information Sciences Institute.", "citeRegEx": "Carlson and Marcu.,? 2001", "shortCiteRegEx": "Carlson and Marcu.", "year": 2001}, {"title": "Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory", "author": ["Lynn Carlson", "Daniel Marcu", "Mary Ellen Okurowski."], "venue": "Proceedings of the Second SIGdial Workshop on Discourse and Dialogue.", "citeRegEx": "Carlson et al\\.,? 2001", "shortCiteRegEx": "Carlson et al\\.", "year": 2001}, {"title": "Multitask learning: a knowledgebased source of inductive bias", "author": ["Rich Caruana."], "venue": "Proceedings of ICML.", "citeRegEx": "Caruana.,? 1993", "shortCiteRegEx": "Caruana.", "year": 1993}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "The Journal of Machine Learning Research 12:2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Summ-it: Um corpus anotado com informa\u00e7oes discursivas visandoa sumariza\u00e7ao autom\u00e1tica", "author": ["Sandra Collovini", "Thiago I Carbonel", "Juliana Thiesen Fuchs", "Jorge C\u00e9sar Coelho", "L\u00facia Rino", "Renata Vieira."], "venue": "Proceedings of TIL.", "citeRegEx": "Collovini et al\\.,? 2007", "shortCiteRegEx": "Collovini et al\\.", "year": 2007}, {"title": "DiSeg: Un segmentador discursivo autom\u00e1tico para el espa\u00f1ol", "author": ["Iria da Cunha", "Eric SanJuan", "Juan-Manuel TorresMoreno", "Marina Lloberas", "Irene Castell\u00f3n."], "venue": "Procesamiento del lenguaje natural 45:145\u2013152.", "citeRegEx": "Cunha et al\\.,? 2010", "shortCiteRegEx": "Cunha et al\\.", "year": 2010}, {"title": "DiSeg 1.0: The first system for Spanish discourse segmentation", "author": ["Iria da Cunha", "Eric SanJuan", "Juan-Manuel TorresMoreno", "Marina Lloberes", "Irene Castell\u00f3n"], "venue": "Expert Syst. Appl. 39(2):1671\u20131678", "citeRegEx": "Cunha et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Cunha et al\\.", "year": 2012}, {"title": "On the development of the RST Spanish Treebank", "author": ["Iria da Cunha", "Juan-Manuel Torres-Moreno", "Gerardo Sierra."], "venue": "Proceedings of LAW.", "citeRegEx": "Cunha et al\\.,? 2011", "shortCiteRegEx": "Cunha et al\\.", "year": 2011}, {"title": "A lineartime bottom-up discourse parser with constraints and post-editing", "author": ["Vanessa Wei Feng", "Graeme Hirst."], "venue": "Proceedings of ACL.", "citeRegEx": "Feng and Hirst.,? 2014", "shortCiteRegEx": "Feng and Hirst.", "year": 2014}, {"title": "The utility of parse-derived features for automatic discourse segmentation", "author": ["Seeger Fisher", "Brian Roark."], "venue": "Proceedings ACL.", "citeRegEx": "Fisher and Roark.,? 2007", "shortCiteRegEx": "Fisher and Roark.", "year": 2007}, {"title": "Framewise phoneme classification with bidirectional lstm and other neural network architectures", "author": ["Alex Graves", "Jrgen Schmidhuber."], "venue": "Neural Networks pages 5\u20136.", "citeRegEx": "Graves and Schmidhuber.,? 2005", "shortCiteRegEx": "Graves and Schmidhuber.", "year": 2005}, {"title": "HILDA: A discourse parser using support vector machine classification", "author": ["Hugo Hernault", "Helmut Prendinger", "David A. duVerle", "Mitsuru Ishizuka."], "venue": "Dialogue and Discourse 1:1\u201333.", "citeRegEx": "Hernault et al\\.,? 2010", "shortCiteRegEx": "Hernault et al\\.", "year": 2010}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural Computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "The RST Basque Treebank: an online search interface to check rhetorical relations", "author": ["Mikel Iruskieta", "Mar\u0131\u0301a J. Aranzabe", "Arantza Diaz de Ilarraza", "Itziar Gonzalez-Dios", "Mikel Lersundi", "Oier Lopez de la Calle"], "venue": "In Proceedings of the 4th Workshop", "citeRegEx": "Iruskieta et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Iruskieta et al\\.", "year": 2013}, {"title": "Representation learning for text-level discourse parsing", "author": ["Yangfeng Ji", "Jacob Eisenstein."], "venue": "Proceedings of ACL.", "citeRegEx": "Ji and Eisenstein.,? 2014", "shortCiteRegEx": "Ji and Eisenstein.", "year": 2014}, {"title": "Codra: A novel discriminative framework for rhetorical analysis", "author": ["Shafiq Joty", "Giuseppe Carenini", "Raymond T. Ng."], "venue": "Computational Linguistics 41:3.", "citeRegEx": "Joty et al\\.,? 2015", "shortCiteRegEx": "Joty et al\\.", "year": 2015}, {"title": "Combining intra- and multi-sentential rhetorical parsing for documentlevel discourse analysis", "author": ["Shafiq R. Joty", "Giuseppe Carenini", "Raymond T. Ng", "Yashar Mehdad."], "venue": "Proceedings of ACL.", "citeRegEx": "Joty et al\\.,? 2013", "shortCiteRegEx": "Joty et al\\.", "year": 2013}, {"title": "Improving sentence compression by learning to predict gaze", "author": ["Sigrid Klerke", "Yoav Goldberg", "Anders S\u00f8gaard."], "venue": "Proceedings of NAACL.", "citeRegEx": "Klerke et al\\.,? 2016", "shortCiteRegEx": "Klerke et al\\.", "year": 2016}, {"title": "A strong baseline for learning cross-lingual word embeddings from sentence alignments", "author": ["Omer Levy", "Anders S\u00f8gaard", "Yoav Goldberg."], "venue": "Proceedings of EACL.", "citeRegEx": "Levy et al\\.,? 2017", "shortCiteRegEx": "Levy et al\\.", "year": 2017}, {"title": "Recursive deep models for discourse parsing", "author": ["Jiwei Li", "Rumeng Li", "Eduard H. Hovy."], "venue": "Proceedings of EMNLP.", "citeRegEx": "Li et al\\.,? 2014", "shortCiteRegEx": "Li et al\\.", "year": 2014}, {"title": "Rhetorical Structure Theory: Toward a functional theory of text organization", "author": ["William C. Mann", "Sandra A. Thompson."], "venue": "Text 8:243\u2013281.", "citeRegEx": "Mann and Thompson.,? 1988", "shortCiteRegEx": "Mann and Thompson.", "year": 1988}, {"title": "Adaptation of discourse parsing models for Portuguese language", "author": ["Erick G. Maziero", "Graeme Hirst", "Thiago A.S. Pardo."], "venue": "Proceedings of the Brazilian Conference on Intelligent Systems (BRACIS).", "citeRegEx": "Maziero et al\\.,? 2015", "shortCiteRegEx": "Maziero et al\\.", "year": 2015}, {"title": "Universal dependencies 1.3. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles", "author": ["Veronika Vincze", "Jing Xian Wang", "Jonathan North Washington", "Zden\u011bk \u017dabokrtsk\u00fd", "Daniel Zeman", "Hanzhi Zhu"], "venue": null, "citeRegEx": "Vincze et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Vincze et al\\.", "year": 2016}, {"title": "A constru\u00e7\u00e3o de um corpus de textos cient\u0131\u0301ficos em Portugu\u00eas do Brasil e sua marca\u00e7\u00e3o ret\u00f3rica", "author": ["Thiago A.S. Pardo", "Maria das Gra\u00e7as Volpe Nunes."], "venue": "Technical report, Universidade de S\u00e3o Paulo.", "citeRegEx": "Pardo and Nunes.,? 2003", "shortCiteRegEx": "Pardo and Nunes.", "year": 2003}, {"title": "Rela\u00e7\u00f5es ret\u00f3ricas e seus marcadores superficiais: An\u00e1lise de um corpus de textos cient\u0131\u0301ficos em Portugu\u00eas do Brasil", "author": ["Thiago A.S. Pardo", "Maria das Gra\u00e7as Volpe Nunes."], "venue": "Relat\u00f3rio T\u00e9cnico NILC .", "citeRegEx": "Pardo and Nunes.,? 2004", "shortCiteRegEx": "Pardo and Nunes.", "year": 2004}, {"title": "On the development and evaluation of a Brazilian Portuguese discourse parser", "author": ["Thiago A.S. Pardo", "Maria das Gra\u00e7as Volpe Nunes."], "venue": "Revista de Inform\u00e1tica Te\u00f3rica e Aplicada 15(2):43\u201364.", "citeRegEx": "Pardo and Nunes.,? 2008", "shortCiteRegEx": "Pardo and Nunes.", "year": 2008}, {"title": "Rhetalho: Um corpus de refer\u0142ncia anotado retoricamente", "author": ["Thiago A.S. Pardo", "Eloize R.M. Seno."], "venue": "Proceedings of Encontro de Corpora.", "citeRegEx": "Pardo and Seno.,? 2005", "shortCiteRegEx": "Pardo and Seno.", "year": 2005}, {"title": "Multilingual part-of-speech tagging with bidirectional long short-term memory models and auxiliary loss", "author": ["Barbara Plank", "Anders S\u00f8gaard", "Yoav Goldberg."], "venue": "Proceedings of ACL.", "citeRegEx": "Plank et al\\.,? 2016", "shortCiteRegEx": "Plank et al\\.", "year": 2016}, {"title": "Multilayer discourse annotation of a dutch text corpus", "author": ["Gisela Redeker", "Ildik Berzlnovich", "Nynke van der Vliet", "Gosse Bouma", "Markus Egg."], "venue": "Proceedings of LREC.", "citeRegEx": "Redeker et al\\.,? 2012", "shortCiteRegEx": "Redeker et al\\.", "year": 2012}, {"title": "Discourse segmentation of german texts", "author": ["Uladzimir Sidarenka", "Andreas Peldszus", "Manfred Stede."], "venue": "Journal of Language Technology and Computational Linguistics 30(1):71\u201398.", "citeRegEx": "Sidarenka et al\\.,? 2015", "shortCiteRegEx": "Sidarenka et al\\.", "year": 2015}, {"title": "Sentence level discourse parsing using syntactic and lexical information", "author": ["Radu Soricut", "Daniel Marcu."], "venue": "Proceedings of NAACL.", "citeRegEx": "Soricut and Marcu.,? 2003", "shortCiteRegEx": "Soricut and Marcu.", "year": 2003}, {"title": "Discourse chunking and its application to sentence compression", "author": ["Caroline Sporleder", "Mirella Lapata."], "venue": "Proceedings of HLT/EMNLP.", "citeRegEx": "Sporleder and Lapata.,? 2005", "shortCiteRegEx": "Sporleder and Lapata.", "year": 2005}, {"title": "The potsdam commentary corpus", "author": ["Manfred Stede."], "venue": "Proceedings of the ACL Workshop on Discourse Annotation.", "citeRegEx": "Stede.,? 2004", "shortCiteRegEx": "Stede.", "year": 2004}, {"title": "Potsdam commentary corpus 2.0: Annotation for discourse research", "author": ["Manfred Stede", "Arne Neumann"], "venue": "In Proceedings of LREC", "citeRegEx": "Stede and Neumann.,? \\Q2014\\E", "shortCiteRegEx": "Stede and Neumann.", "year": 2014}, {"title": "UDPipe: Trainable Pipeline for Processing CoNLL-U Files Performing Tokenization, Morphological Analysis, POS Tagging and Parsing", "author": ["Milan Straka", "Jan Haji\u010d", "Strakov\u00e1."], "venue": "Proceedings of LREC.", "citeRegEx": "Straka et al\\.,? 2016", "shortCiteRegEx": "Straka et al\\.", "year": 2016}, {"title": "An approach to discourse parsing using sangati and Rhetorical Structure Theory", "author": ["C N Subalalitha", "Ranjani Parthasarathi."], "venue": "Proceedings of the Workshop on Machine Translation and Parsing in Indian Languages (MTPIL-2012).", "citeRegEx": "Subalalitha and Parthasarathi.,? 2012", "shortCiteRegEx": "Subalalitha and Parthasarathi.", "year": 2012}, {"title": "Automatic discourse segmentation using neural networks", "author": ["Rajen Subba", "Barbara Di Eugenio."], "venue": "Workshop on the Semantics and Pragmatics of Dialogue.", "citeRegEx": "Subba and Eugenio.,? 2007", "shortCiteRegEx": "Subba and Eugenio.", "year": 2007}, {"title": "An effective discourse parser that uses rich linguistic information", "author": ["Rajen Subba", "Barbara Di Eugenio."], "venue": "Proceedings of ACL-HLT.", "citeRegEx": "Subba and Eugenio.,? 2009", "shortCiteRegEx": "Subba and Eugenio.", "year": 2009}, {"title": "Syntax-based discourse segmentation of Dutch text", "author": ["Nynke van der Vliet."], "venue": "15th Student Session, ESSLLI.", "citeRegEx": "Vliet.,? 2010", "shortCiteRegEx": "Vliet.", "year": 2010}, {"title": "Building a discourse-annotated Dutch text corpus", "author": ["Nynke Van Der Vliet", "Ildik\u00f3 Berzlnovich", "Gosse Bouma", "Markus Egg", "Gisela Redeker."], "venue": "S. Dipper and H. Zinsmeister (Eds.), Beyond Semantics, Bochumer Linguistische Arbeitsberichte 3.", "citeRegEx": "Vliet et al\\.,? 2011", "shortCiteRegEx": "Vliet et al\\.", "year": 2011}, {"title": "A new ranking method for Chinese discourse tree building", "author": ["Yunfang Wu", "Fuqiang Wan", "Yifeng Xu", "Xueqiang L\u00fc."], "venue": "Acta Scientiarum Naturalium Universitatis Pekinensis 52(1):65\u201374.", "citeRegEx": "Wu et al\\.,? 2016", "shortCiteRegEx": "Wu et al\\.", "year": 2016}, {"title": "A reranking model for discourse segmentation using subtree features", "author": ["Ngo Xuan Bach", "Nguyen LeMinh", "Akira Shimazu."], "venue": "Proceedings of Sigdial.", "citeRegEx": "Bach et al\\.,? 2012", "shortCiteRegEx": "Bach et al\\.", "year": 2012}], "referenceMentions": [{"referenceID": 30, "context": "mining, anaphora resolution, or speech act assignment (Sidarenka et al., 2015).", "startOffset": 54, "endOffset": 78}, {"referenceID": 21, "context": "ory (RST) (Mann and Thompson, 1988) \u2013 and", "startOffset": 10, "endOffset": 35}, {"referenceID": 2, "context": "resources such as the RST Discourse Treebank (RST-DT) (Carlson et al., 2001) \u2013 in which discourse structures are trees covering the documents.", "startOffset": 54, "endOffset": 76}, {"referenceID": 15, "context": "Most recent works on RST discourse parsing focuses on the task of tree building, relying on a gold discourse segmentation (Ji and Eisenstein, 2014; Feng and Hirst, 2014; Li et al., 2014; Joty et al., 2013).", "startOffset": 122, "endOffset": 205}, {"referenceID": 9, "context": "Most recent works on RST discourse parsing focuses on the task of tree building, relying on a gold discourse segmentation (Ji and Eisenstein, 2014; Feng and Hirst, 2014; Li et al., 2014; Joty et al., 2013).", "startOffset": 122, "endOffset": 205}, {"referenceID": 20, "context": "Most recent works on RST discourse parsing focuses on the task of tree building, relying on a gold discourse segmentation (Ji and Eisenstein, 2014; Feng and Hirst, 2014; Li et al., 2014; Joty et al., 2013).", "startOffset": 122, "endOffset": 205}, {"referenceID": 17, "context": "Most recent works on RST discourse parsing focuses on the task of tree building, relying on a gold discourse segmentation (Ji and Eisenstein, 2014; Feng and Hirst, 2014; Li et al., 2014; Joty et al., 2013).", "startOffset": 122, "endOffset": 205}, {"referenceID": 16, "context": "However, discourse parsers\u2019 performance drops by 12-14% when relying on predicted segmentation (Joty et al., 2015), underscoring the importance of discourse segmentation.", "startOffset": 95, "endOffset": 114}, {"referenceID": 26, "context": "Segmenters based on handwritten rules have been developed for Brazilian Portuguese (Pardo and Nunes, 2008) (51.", "startOffset": 83, "endOffset": 106}, {"referenceID": 33, "context": "For English RST-DT, the best discourse segmentation results were presented in Xuan Bach et al. (2012) (F1 91.", "startOffset": 83, "endOffset": 102}, {"referenceID": 13, "context": "7 with gold parse) \u2013 and in Joty et al. (2015) for the Instructional corpus (Subba and Di Eugenio, 2009) (F1 80.", "startOffset": 28, "endOffset": 47}, {"referenceID": 10, "context": "Most statistical discourse segmenters are based on classifiers (Fisher and Roark, 2007; Joty et al., 2015).", "startOffset": 63, "endOffset": 106}, {"referenceID": 16, "context": "Most statistical discourse segmenters are based on classifiers (Fisher and Roark, 2007; Joty et al., 2015).", "startOffset": 63, "endOffset": 106}, {"referenceID": 10, "context": "Most statistical discourse segmenters are based on classifiers (Fisher and Roark, 2007; Joty et al., 2015). Subba and Di Eugenio (2007) were the first to use a neural network, and", "startOffset": 64, "endOffset": 136}, {"referenceID": 32, "context": "Sporleder and Lapata (2005) present arguments for a knowledge-lean system that can be used for low-resourced languages.", "startOffset": 0, "endOffset": 28}, {"referenceID": 30, "context": "2 For German (Sidarenka et al., 2015) propose a segmenter in clauses (that may be EDU or not).", "startOffset": 13, "endOffset": 37}, {"referenceID": 1, "context": "In the English RST-DT (Carlson and Marcu, 2001), lexical information is crucial: for instance, the presence of the discourse connective \u201cbut\u201d in example (1a) indicates the beginning of an EDU.", "startOffset": 22, "endOffset": 47}, {"referenceID": 2, "context": "All the examples given come from (Carlson et al., 2001).", "startOffset": 33, "endOffset": 55}, {"referenceID": 13, "context": "Our models perform sequence labeling based on a stacked k-layer bi-directional LSTM, a variant of LSTMs (Hochreiter and Schmidhuber, 1997) that reads the input in both regular and reversed order, allowing to take into account both left and right contexts (Graves and Schmidhuber, 2005).", "startOffset": 104, "endOffset": 138}, {"referenceID": 11, "context": "Our models perform sequence labeling based on a stacked k-layer bi-directional LSTM, a variant of LSTMs (Hochreiter and Schmidhuber, 1997) that reads the input in both regular and reversed order, allowing to take into account both left and right contexts (Graves and Schmidhuber, 2005).", "startOffset": 255, "endOffset": 285}, {"referenceID": 3, "context": "Specifically, we train models based on hard parameters sharing (Caruana, 1993; Collobert et al., 2011; Klerke et al., 2016; Plank et al., 2016): each task is associated with a specific output layer, whereas the inner layers \u2013 the stacked LSTMs \u2013 are shared across the tasks.", "startOffset": 63, "endOffset": 143}, {"referenceID": 4, "context": "Specifically, we train models based on hard parameters sharing (Caruana, 1993; Collobert et al., 2011; Klerke et al., 2016; Plank et al., 2016): each task is associated with a specific output layer, whereas the inner layers \u2013 the stacked LSTMs \u2013 are shared across the tasks.", "startOffset": 63, "endOffset": 143}, {"referenceID": 18, "context": "Specifically, we train models based on hard parameters sharing (Caruana, 1993; Collobert et al., 2011; Klerke et al., 2016; Plank et al., 2016): each task is associated with a specific output layer, whereas the inner layers \u2013 the stacked LSTMs \u2013 are shared across the tasks.", "startOffset": 63, "endOffset": 143}, {"referenceID": 28, "context": "Specifically, we train models based on hard parameters sharing (Caruana, 1993; Collobert et al., 2011; Klerke et al., 2016; Plank et al., 2016): each task is associated with a specific output layer, whereas the inner layers \u2013 the stacked LSTMs \u2013 are shared across the tasks.", "startOffset": 63, "endOffset": 143}, {"referenceID": 28, "context": "We used a modified version of (Plank et al., 2016) fixing the random seed and using standard SGD.", "startOffset": 30, "endOffset": 50}, {"referenceID": 33, "context": ", 2011), German (DeDT) (Stede, 2004; Stede and Neumann, 2014), Dutch (Nl-DT) (Vliet et al.", "startOffset": 23, "endOffset": 61}, {"referenceID": 34, "context": ", 2011), German (DeDT) (Stede, 2004; Stede and Neumann, 2014), Dutch (Nl-DT) (Vliet et al.", "startOffset": 23, "endOffset": 61}, {"referenceID": 40, "context": ", 2011), German (DeDT) (Stede, 2004; Stede and Neumann, 2014), Dutch (Nl-DT) (Vliet et al., 2011; Redeker et al., 2012) and, for Brazilian Portuguese, we merged four corpora (Pt-DT) (Cardoso et al.", "startOffset": 77, "endOffset": 119}, {"referenceID": 29, "context": ", 2011), German (DeDT) (Stede, 2004; Stede and Neumann, 2014), Dutch (Nl-DT) (Vliet et al., 2011; Redeker et al., 2012) and, for Brazilian Portuguese, we merged four corpora (Pt-DT) (Cardoso et al.", "startOffset": 77, "endOffset": 119}, {"referenceID": 0, "context": ", 2012) and, for Brazilian Portuguese, we merged four corpora (Pt-DT) (Cardoso et al., 2011; Collovini et al., 2007; Pardo and Seno, 2005; Pardo and Nunes, 2003, 2004) as done in (Maziero et al.", "startOffset": 70, "endOffset": 167}, {"referenceID": 5, "context": ", 2012) and, for Brazilian Portuguese, we merged four corpora (Pt-DT) (Cardoso et al., 2011; Collovini et al., 2007; Pardo and Seno, 2005; Pardo and Nunes, 2003, 2004) as done in (Maziero et al.", "startOffset": 70, "endOffset": 167}, {"referenceID": 27, "context": ", 2012) and, for Brazilian Portuguese, we merged four corpora (Pt-DT) (Cardoso et al., 2011; Collovini et al., 2007; Pardo and Seno, 2005; Pardo and Nunes, 2003, 2004) as done in (Maziero et al.", "startOffset": 70, "endOffset": 167}, {"referenceID": 22, "context": ", 2007; Pardo and Seno, 2005; Pardo and Nunes, 2003, 2004) as done in (Maziero et al., 2015).", "startOffset": 70, "endOffset": 92}, {"referenceID": 14, "context": "not able to obtain cross-lingual word embeddings for Basque (Iruskieta et al., 2013) and Chinese (Wu et al.", "startOffset": 60, "endOffset": 84}, {"referenceID": 41, "context": ", 2013) and Chinese (Wu et al., 2016), and could not obtain the data for Tamil (Subalalitha and Parthasarathi, 2012).", "startOffset": 20, "endOffset": 37}, {"referenceID": 36, "context": ", 2016), and could not obtain the data for Tamil (Subalalitha and Parthasarathi, 2012).", "startOffset": 49, "endOffset": 86}, {"referenceID": 35, "context": "Baselines As baselines at the document level, we report the scores obtained (a) when only considering the sentence boundaries predicted using UDPipe (Straka et al., 2016) (UDP-S), and (b) when EDU boundaries are added after each token", "startOffset": 149, "endOffset": 170}, {"referenceID": 19, "context": "We experiment with randomly initialized and pre-trained cross-lingual word embeddings built on Europarl (Levy et al., 2017), keeping either the full 500 dimensions, or the first 50 ones.", "startOffset": 104, "endOffset": 123}, {"referenceID": 12, "context": "Interestingly, our simple system beats HILDA (Hernault et al., 2010) (74.", "startOffset": 45, "endOffset": 68}, {"referenceID": 31, "context": "1% in F1), is as good as the other neural network based system (Subba and Di Eugenio, 2007), and is close to SPADE (Soricut and Marcu, 2003) (85.", "startOffset": 115, "endOffset": 140}, {"referenceID": 16, "context": "2% in F1) (Joty et al., 2015), while all of these systems use parse tree information.", "startOffset": 10, "endOffset": 29}, {"referenceID": 32, "context": "This score ignores the sentences containing only one EDU (Sporleder and Lapata, 2005).", "startOffset": 57, "endOffset": 85}, {"referenceID": 2, "context": "\u201c[when rates are rising] [and shift out at times]\u201d \u2013 that should be split (Carlson et al., 2001), a distinction hard to make without syntactic trees.", "startOffset": 74, "endOffset": 96}], "year": 2017, "abstractText": "Discourse segmentation is a crucial step in building end-to-end discourse parsers. However, discourse segmenters only exist for a few languages and domains. Typically they only detect intra-sentential segment boundaries, assuming gold standard sentence and token segmentation, and relying on high-quality syntactic parses and rich heuristics that are not generally available across languages and domains. In this paper, we propose statistical discourse segmenters for five languages and three domains that do not rely on gold preannotations. We also consider the problem of learning discourse segmenters when no labeled data is available for a language. Our fully supervised system obtains 89.5% F1 for English newswire, with slight drops in performance on other domains, and we report supervised and unsupervised (cross-lingual) results for five languages in total.", "creator": "LaTeX with hyperref package"}}}