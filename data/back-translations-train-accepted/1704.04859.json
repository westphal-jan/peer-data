{"id": "1704.04859", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "17-Apr-2017", "title": "Learning Character-level Compositionality with Visual Features", "abstract": "Previous work has modeled the compositionality of words by creating character-level models of meaning, reducing problems of sparsity for rare words. However, in many writing systems compositionality has an effect even on the character-level: the meaning of a character is derived by the sum of its parts. In this paper, we model this effect by creating embeddings for characters based on their visual characteristics, creating an image for the character and running it through a convolutional neural network to produce a visual character embedding. Experiments on a text classification task demonstrate that such model allows for better processing of instances with rare characters in languages such as Chinese, Japanese, and Korean. Additionally, qualitative analyses demonstrate that our proposed model learns to focus on the parts of characters that carry semantic content, resulting in embeddings that are coherent in visual space.", "histories": [["v1", "Mon, 17 Apr 2017 03:30:30 GMT  (774kb,D)", "http://arxiv.org/abs/1704.04859v1", "Accepted to ACL 2017"], ["v2", "Sat, 6 May 2017 15:13:24 GMT  (717kb,D)", "http://arxiv.org/abs/1704.04859v2", "Accepted to ACL 2017"]], "COMMENTS": "Accepted to ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["frederick liu", "han lu", "chieh lo", "graham neubig"], "accepted": true, "id": "1704.04859"}, "pdf": {"name": "1704.04859.pdf", "metadata": {"source": "CRF", "title": "Learning Character-level Compositionality with Visual Features", "authors": ["Frederick Liu", "Han Lu", "Chieh Lo", "Graham Neubig"], "emails": ["fliu1@cs.cmu.edu", "hlu2@cs.cmu.edu", "gneubig@cs.cmu.edu", "chiehl@andrew.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is so that most of them are able to survive themselves, and that they are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...) Most of them are able to survive themselves. (...)"}, {"heading": "2 Dataset", "text": "Before delving into the details of our model, we first describe a data set that we have constructed to examine the ability of our model to understand the compositional properties of characters. Specifically, the data set must meet two desiderates: (1) it must be necessary to use every character in input fully to achieve high accuracy, and (2) there must be sufficient regularity and composition in the characters of the language. In order to meet these desiderates, we create a text classification data set where the input is a Wikipedia article title in Chinese, Japanese or Korean and the output is the category to which the article belongs. (3) This fulfils (1) because Wikipedia titles are short and therefore each character in the title will be important for our decision on its category."}, {"heading": "2.1 Dataset Collection", "text": "As we would like to predict, we use 12 different main categories of the Wikipedia website: Geography, Sports, Art, Military, Economy, Transportation, Health Sciences, Education, Food Culture, Religion and Belief, Agriculture and Electronics. Wikipedia has a hierarchical structure in which each of these main categories has a number of subcategories, and each subcategory has its own subcategories, etc. We traverse this hierarchical structure by adding all the main categories to all their offspring in this subcategory tree structure. In the case that a particular article is the offspring of several main categories, we prefer the main category that minimizes the depth of the 3The link to the record and the crawling scripts - https: / / github.com / frederick0329 / Wikipedia _ title _ datasetarticle in the tree (e.g. if an article is two steps away from sport and three steps away from art, we get the \"Sports Label\") by also removing some filtering pages."}, {"heading": "2.2 Statistics", "text": "For Chinese, Japanese, and Korean, the number of articles is 593k / 810k / 46.6k, and the average length and standard deviation of the title is 6.25 \u00b1 3.96 / 8.60 \u00b1 5.58 / 6.10 \u00b1 3.71. As shown in Fig. 2, the order of characters in all three languages follows the 80 / 20 rule (Newman, 2005) (i.e. the top 20% of the order of characters having more than 80% of the total frequency), showing that the characters in these languages belong to a long-tail distribution. We further divide the data set into training, validation, and test sets at a ratio of 6: 2: 2. The category distribution for each language is shown in Tab. 1."}, {"heading": "3 Model", "text": "Our overall model for the classification task follows the encoder model of Sutskever et al. (2014).We calculate character representations, use an RNN to combine the character representations into a sentence representation, and then add a softmax layer to predict the probability for each class. As shown in Figure 2.1, the base model, which we refer to as LOOKUP model, will calculate the representation for each character by embedding it in a character matrix. Our suggested model, the VISUAL model, learns the representation of each character via CNN.LOOKUP model, calculates the representation for each character by looking it up in a character embedded matrix. Our proposed character model, the VISUAL model, instead learns the representation of each character via CNN.LOOKUP model, which is a character vocabulary vocabulary vocabulary vocabulary vocabulary vocabulary vocabulary vocabulary vocabulary, the character matrix, the character part vocabulary for LOP, the character vocabulary VISULOKUP model for the part of the VOKUP model."}, {"heading": "4 Fusion-based Models", "text": "The LOOKUP model learns the embedding, which captures the semantics of each character symbol without exchanging information with each other. In contrast, the proposed VISUAL model learns directly the embedding of characters from visual information, which naturally share information between visually similar characters. This property gives the VISUAL model the ability to better generalize rare characters, but also has the potential disadvantage of introducing noise for characters with similar appearance but different meanings. Considering the complementary nature of these two models, we continue to combine the two embedding schemes to achieve better performance. We adopt three fusion schemes, early fusion, late fusion (described by Snoek et al. (2005) and Karpathy et al. (2014), and fallback fusion, a method specific to this paper."}, {"heading": "5 Experiments and Results", "text": "In this section, we will compare our proposed VISUAL model with the baseline model LOOKUP through three different experiments. First, we will examine whether our model is capable of classifying text and achieving a performance similar to the baseline model. Second, we will examine the hypothesis that our model will surpass the baseline model in handling low frequency characters. Finally, we will examine the fusion methods described in Section 4."}, {"heading": "5.1 Experimental Configurations", "text": "The dimension of the embedding and the lot size for both models are set to dc = 128 or B = 400. We build our proposed model with Torch (Collobert et al., 2002) and use Adam (Kingma and Ba, 2014) with a learning rate \u03b7 = 0.001 for stochastic optimization. The length of each instance is truncated or increased to 10 characters for batch training."}, {"heading": "5.2 Comparison with the Baseline Model", "text": "In this experiment, we will examine whether our VISUAL model performs similarly with the LOOKUP model in terms of classification accuracy; the results in Tab. 3 show that the VISUAL model performs 1-2% better in four sets of data; this is due to the fact that the LOOKUP model can learn character embeddings that capture the semantics of each character symbol for common characters; in contrast, the VISUAL model learns embeddings of visual information that restrict characters with similar appearance in order to have similar embeddings; this is an advantage for rare characters, but a disadvantage for high-frequency characters, as the similarity in appearance does not always lead to similar semantics. To show that this is indeed the case, in addition to considering the general classification accuracy, we will also examine the performance in classifying low frequency instances sorted according to the average common signs contained therein."}, {"heading": "5.3 Experiments on Different Training Sizes", "text": "In our second experiment, we looked at two smaller training variables (i.e. 50% and 12.5% of the total training size) marked by green and red lines in Fig. 4. We conducted this experiment under the hypothesis that the intersection of the two models will shift to the right due to the increase in the number of cases with low average character frequency. As we can see in Fig. 4, the intersection of 100% training data lies between the intersection of 50% training data and 12.5%. This contradicts our hypothesis; this is probably because the number of low frequency characters increases, but smaller amounts of data also affect CNN's ability to learn useful visual features, and therefore there is no clear gain or loss in using the proposed method. As a more extreme test of the ability of our proposed framework to deal with the invisible characters, the Chinese model is classified in such a way as to allow full transmission of the scripts compared to most other Chinese data."}, {"heading": "5.4 Experiment on Different Fusion Methods", "text": "The results of different fusion methods can be found in Tab. 5. Results show that late fusion performs best among all fusion programs combining the LOOKUP model and the proposed VISUAL model. Early fusion achieves small improvements for all languages except Japanese, where it shows a slight decrease. Unsurprisingly, fallback fusion performs better than the LOOKUP model and the VISUAL model alone because it directly targets the weakness of the LOOKUP model (e.g. rare characters) and replaces the results with the VISUAL model. These results show that easy integration is beneficial regardless of which schemes we use, showing that both methods capture complementary information."}, {"heading": "5.5 Visualization of Character Embeddings", "text": "In fact, most of them are able to move, to move, to move, to move, to move, to move, to move, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush, to rush. \""}, {"heading": "6 Related Work", "text": "However, word2vec (Mikolov et al., 2013) requires, for example, the storage of an extremely large vector table for all word types. However, due to the size of the word types in Twitter tweets, work has been done to generate vector representations of tweets at character level (Dhingra et al., 2016). Work is also underway to understand mathematical expressions using a revolutionary network for text and layout recognition using an attention-based neural machine translation system (Deng et al., 2016). They tested mathematical expressions rendered on realworld paired with LaTeX markup and show that the system is effective at generating precise markup. In addition, there are several works that combine visual information with text to improve machine translation (Sutskever et al., 2014), answer visual questions, text generation (Xu et al., 2015, wc.)."}, {"heading": "7 Conclusion and Future Work", "text": "In this thesis, we proposed a new framework that uses the appearance of signs, revolutionary neural networks, recurrent neural networks to learn embeddings that are composed in the constituent parts of the signs. Specifically, we collected a Wikipedia dataset consisting of short titles of three different languages and complying with composition in the signs of the language. Next, we proposed an end-to-end model that learns visual embeddings for signs using CNN and showed that the features taken from CNN contain both visual and semantic information.In summary, we showed that our VISUAL model exceeds the LOOKUP base model in low frequency instances. In addition, by visual examination of character embeddings, we found that our VISUAL model is capable of learning visually related embeddings. In summary, we have tackled the problem of rare signs in the future by using unpreformed systems, as we have learned other predefined methods in this thesis."}, {"heading": "Acknowledgments", "text": "We thank Taylor Berg-Kirkpatrick, Adhiguna Kuncoro, Chen-Hsuan Lin, Wei-Cheng Chang, Wei-Ning Hsu and the anonymous critics for their insightful comments and feedback."}], "references": [{"title": "Compositional morphology for word representations and language modelling", "author": ["Jan A Botha", "Phil Blunsom."], "venue": "ICML. pages 1899\u20131907.", "citeRegEx": "Botha and Blunsom.,? 2014", "shortCiteRegEx": "Botha and Blunsom.", "year": 2014}, {"title": "Empirical evaluation of gated recurrent neural networks on sequence modeling", "author": ["Junyoung Chung", "Caglar Gulcehre", "KyungHyun Cho", "Yoshua Bengio."], "venue": "arXiv preprint arXiv:1412.3555 .", "citeRegEx": "Chung et al\\.,? 2014", "shortCiteRegEx": "Chung et al\\.", "year": 2014}, {"title": "Torch: A modular machine learning software", "author": ["Ronan Collobert", "Samy Bengio", "Johnny Marithoz"], "venue": null, "citeRegEx": "Collobert et al\\.,? \\Q2002\\E", "shortCiteRegEx": "Collobert et al\\.", "year": 2002}, {"title": "Advances in neural information processing systems", "author": ["Y. Le Cun", "B. Boser", "J.S. Denker", "R.E. Howard", "W. Habbard", "L.D. Jackel", "D. Henderson"], "venue": null, "citeRegEx": "Cun et al\\.,? \\Q1990\\E", "shortCiteRegEx": "Cun et al\\.", "year": 1990}, {"title": "The world\u2019s writing systems", "author": ["Peter T Daniels", "William Bright."], "venue": "Oxford University Press.", "citeRegEx": "Daniels and Bright.,? 1996", "shortCiteRegEx": "Daniels and Bright.", "year": 1996}, {"title": "Domain adaptation for machine translation by mining unseen words", "author": ["Hal Daum\u00e9", "Jagadeesh Jagarlamudi."], "venue": "ACL-HLT . pages 407\u2013412.", "citeRegEx": "Daum\u00e9 and Jagarlamudi.,? 2011", "shortCiteRegEx": "Daum\u00e9 and Jagarlamudi.", "year": 2011}, {"title": "What you get is what you see: A visual markup decompiler", "author": ["Yuntian Deng", "Anssi Kanervisto", "Alexander M. Rush."], "venue": "arXiv preprint arXiv:1609.04938 .", "citeRegEx": "Deng et al\\.,? 2016", "shortCiteRegEx": "Deng et al\\.", "year": 2016}, {"title": "Tweet2vec: Character-based distributed representations for social media", "author": ["Bhuwan Dhingra", "Zhong Zhou", "Dylan Fitzpatrick", "Michael Muehl", "William W Cohen."], "venue": "ACL .", "citeRegEx": "Dhingra et al\\.,? 2016", "shortCiteRegEx": "Dhingra et al\\.", "year": 2016}, {"title": "The foundations of arithmetic: A logico-mathematical enquiry into the concept of number", "author": ["Gottlob Frege", "John Langshaw Austin."], "venue": "Northwestern University Press.", "citeRegEx": "Frege and Austin.,? 1980", "shortCiteRegEx": "Frege and Austin.", "year": 1980}, {"title": "Multilingual language processing from bytes", "author": ["Dan Gillick", "Cliff Brunk", "Oriol Vinyals", "Amarnag Subramanya."], "venue": "arXiv preprint arXiv:1512.00103 .", "citeRegEx": "Gillick et al\\.,? 2015", "shortCiteRegEx": "Gillick et al\\.", "year": 2015}, {"title": "Four techniques for online handling of out-of-vocabulary words in Arabic-English statistical machine translation", "author": ["Nizar Habash."], "venue": "HLT-Short. pages 57\u201360.", "citeRegEx": "Habash.,? 2008", "shortCiteRegEx": "Habash.", "year": 2008}, {"title": "Deep unordered composition rivals syntactic methods for text classification", "author": ["Mohit Iyyer", "Varun Manjunatha", "Jordan L BoydGraber."], "venue": "ACL.", "citeRegEx": "Iyyer et al\\.,? 2015", "shortCiteRegEx": "Iyyer et al\\.", "year": 2015}, {"title": "A convolutional neural network for modelling sentences", "author": ["Nal Kalchbrenner", "Edward Grefenstette", "Phil Blunsom."], "venue": "ACL pages 655\u2013665.", "citeRegEx": "Kalchbrenner et al\\.,? 2014", "shortCiteRegEx": "Kalchbrenner et al\\.", "year": 2014}, {"title": "Large-scale video classification with convolutional neural networks", "author": ["Andrej Karpathy", "George Toderici", "Sanketh Shetty", "Thomas Leung", "Rahul Sukthankar", "Li Fei-Fei."], "venue": "CVPR. pages 1725\u20131732.", "citeRegEx": "Karpathy et al\\.,? 2014", "shortCiteRegEx": "Karpathy et al\\.", "year": 2014}, {"title": "Exploiting Wikipedia as external knowledge for named entity recognition", "author": ["Jun\u2019ichi Kazama", "Kentaro Torisawa"], "venue": "In EMNLP-CoNLL", "citeRegEx": "Kazama and Torisawa.,? \\Q2007\\E", "shortCiteRegEx": "Kazama and Torisawa.", "year": 2007}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "EMNLP. pages 1746\u2013 1751.", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "arXiv preprint arXiv:1412.6980 .", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Skip-thought vectors", "author": ["Ryan Kiros", "Yukun Zhu", "Ruslan R Salakhutdinov", "Richard Zemel", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler."], "venue": "NIPS. pages 3294\u20133302.", "citeRegEx": "Kiros et al\\.,? 2015", "shortCiteRegEx": "Kiros et al\\.", "year": 2015}, {"title": "Finding function in form: Compositional character models for open vocabulary word representation", "author": ["Wang Ling", "Chris Dyer", "Alan W Black", "Isabel Trancoso", "Ramon Fermandez", "Silvio Amir", "Luis Marujo", "Tiago Luis."], "venue": "EMNLP. pages 1520\u2013", "citeRegEx": "Ling et al\\.,? 2015", "shortCiteRegEx": "Ling et al\\.", "year": 2015}, {"title": "Achieving open vocabulary neural machine translation with hybrid word-character models", "author": ["Minh-Thang Luong", "Christopher D Manning."], "venue": "ACL pages 1054\u20131063.", "citeRegEx": "Luong and Manning.,? 2016", "shortCiteRegEx": "Luong and Manning.", "year": 2016}, {"title": "Better word representations with recursive neural networks for morphology", "author": ["Thang Luong", "Richard Socher", "Christopher Manning."], "venue": "CoNLL. pages 104\u2013113.", "citeRegEx": "Luong et al\\.,? 2013", "shortCiteRegEx": "Luong et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "NIPS. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Power laws, Pareto distributions and Zipf\u2019s law", "author": ["Mej Newman."], "venue": "CONTEMP PHYS pages 323\u2013351.", "citeRegEx": "Newman.,? 2005", "shortCiteRegEx": "Newman.", "year": 2005}, {"title": "Design challenges and misconceptions in named entity recognition", "author": ["Lev Ratinov", "Dan Roth."], "venue": "CoNLL. pages 147\u2013155.", "citeRegEx": "Ratinov and Roth.,? 2009", "shortCiteRegEx": "Ratinov and Roth.", "year": 2009}, {"title": "Neural machine translation of rare words with subword units", "author": ["Rico Sennrich", "Barry Haddow", "Alexandra Birch."], "venue": "ACL pages 1715\u20131725.", "citeRegEx": "Sennrich et al\\.,? 2015", "shortCiteRegEx": "Sennrich et al\\.", "year": 2015}, {"title": "Radical embedding: Delving deeper to chinese radicals", "author": ["Xinlei Shi", "Junjie Zhai", "Xudong Yang", "Zehua Xie", "Chao Liu."], "venue": "ACL. pages 594\u2013598.", "citeRegEx": "Shi et al\\.,? 2015", "shortCiteRegEx": "Shi et al\\.", "year": 2015}, {"title": "Early versus late fusion in semantic video analysis", "author": ["Cees GM Snoek", "Marcel Worring", "Arnold WM Smeulders."], "venue": "ACM MM. pages 399\u2013402.", "citeRegEx": "Snoek et al\\.,? 2005", "shortCiteRegEx": "Snoek et al\\.", "year": 2005}, {"title": "Recursive deep models for semantic compositionality over a sentiment treebank", "author": ["Richard Socher", "Alex Perelygin", "Jean Y Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts."], "venue": "EMNLP. pages 1631\u20131642.", "citeRegEx": "Socher et al\\.,? 2013", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "NIPS. pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Compositionality", "author": ["Zolt\u00e1n Gendler Szab\u00f3."], "venue": "Stanford encyclopedia of philosophy .", "citeRegEx": "Szab\u00f3.,? 2010", "shortCiteRegEx": "Szab\u00f3.", "year": 2010}, {"title": "A proposal to automatically build and maintain gazetteers for named entity recognition by using wikipedia", "author": ["Antonio Toral", "Rafael Munoz."], "venue": "EACL. pages 56\u201361.", "citeRegEx": "Toral and Munoz.,? 2006", "shortCiteRegEx": "Toral and Munoz.", "year": 2006}, {"title": "Cnn-rnn: A unified framework for multi-label image classification", "author": ["Jiang Wang", "Yi Yang", "Junhua Mao", "Zhiheng Huang", "Chang Huang", "Wei Xu."], "venue": "CVPR. pages 2285\u20132294.", "citeRegEx": "Wang et al\\.,? 2016", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Show, attend and tell: Neural image caption generation with visual attention", "author": ["Kelvin Xu", "Jimmy Ba", "Ryan Kiros", "Kyunghyun Cho", "Aaron C Courville", "Ruslan Salakhutdinov", "Richard S Zemel", "Yoshua Bengio."], "venue": "ICML.", "citeRegEx": "Xu et al\\.,? 2015", "shortCiteRegEx": "Xu et al\\.", "year": 2015}, {"title": "Visualizing and understanding convolutional networks", "author": ["Matthew D Zeiler", "Rob Fergus."], "venue": "ECCV . Springer, pages 818\u2013833.", "citeRegEx": "Zeiler and Fergus.,? 2014", "shortCiteRegEx": "Zeiler and Fergus.", "year": 2014}, {"title": "Character-level convolutional networks for text classification", "author": ["Xiang Zhang", "Junbo Zhao", "Yann LeCun."], "venue": "NIPS. pages 649\u2013657.", "citeRegEx": "Zhang et al\\.,? 2015", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}, {"title": "Visual7w: Grounded question answering in images", "author": ["Yuke Zhu", "Oliver Groth", "Michael Bernstein", "Li FeiFei."], "venue": "CVPR. pages 4995\u20135004.", "citeRegEx": "Zhu et al\\.,? 2016", "shortCiteRegEx": "Zhu et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 8, "context": "Compositionality\u2014the fact that the meaning of a complex expression is determined by its structure and the meanings of its constituents\u2014is a hallmark of every natural language (Frege and Austin, 1980; Szab\u00f3, 2010).", "startOffset": 175, "endOffset": 212}, {"referenceID": 29, "context": "Compositionality\u2014the fact that the meaning of a complex expression is determined by its structure and the meanings of its constituents\u2014is a hallmark of every natural language (Frege and Austin, 1980; Szab\u00f3, 2010).", "startOffset": 175, "endOffset": 212}, {"referenceID": 11, "context": "This is done using models of various levels of sophistication, from simpler bag-of-words (Iyyer et al., 2015) and linear recurrent neural network (RNN) models (Sutskever et al.", "startOffset": 89, "endOffset": 109}, {"referenceID": 28, "context": ", 2015) and linear recurrent neural network (RNN) models (Sutskever et al., 2014; Kiros et al., 2015), to more sophisticated models using treeKalb K\u00e4lber a Do Do'(polite)", "startOffset": 57, "endOffset": 101}, {"referenceID": 17, "context": ", 2015) and linear recurrent neural network (RNN) models (Sutskever et al., 2014; Kiros et al., 2015), to more sophisticated models using treeKalb K\u00e4lber a Do Do'(polite)", "startOffset": 57, "endOffset": 101}, {"referenceID": 27, "context": "structured (Socher et al., 2013) or convolutional networks (Kalchbrenner et al.", "startOffset": 11, "endOffset": 32}, {"referenceID": 12, "context": ", 2013) or convolutional networks (Kalchbrenner et al., 2014).", "startOffset": 34, "endOffset": 61}, {"referenceID": 18, "context": "For example, several works have proposed models that represent words by composing together the characters into a representation of the word itself (Ling et al., 2015; Zhang et al., 2015; Dhingra et al., 2016).", "startOffset": 147, "endOffset": 208}, {"referenceID": 34, "context": "For example, several works have proposed models that represent words by composing together the characters into a representation of the word itself (Ling et al., 2015; Zhang et al., 2015; Dhingra et al., 2016).", "startOffset": 147, "endOffset": 208}, {"referenceID": 7, "context": "For example, several works have proposed models that represent words by composing together the characters into a representation of the word itself (Ling et al., 2015; Zhang et al., 2015; Dhingra et al., 2016).", "startOffset": 147, "endOffset": 208}, {"referenceID": 20, "context": "Additionally, for languages with productive word formation (such as agglutination and compounding), models calculating morphologysensitive word representations have been found effective (Luong et al., 2013; Botha and Blunsom, 2014).", "startOffset": 186, "endOffset": 231}, {"referenceID": 0, "context": "Additionally, for languages with productive word formation (such as agglutination and compounding), models calculating morphologysensitive word representations have been found effective (Luong et al., 2013; Botha and Blunsom, 2014).", "startOffset": 186, "endOffset": 231}, {"referenceID": 3, "context": "Our method is relatively simple, and generalizable to a wide variety of languages: we first transform each character from its Unicode representation to a rendering of its shape as an image, then calculate a representation of the image using Convolutional Neural Networks (CNNs) (Cun et al., 1990).", "startOffset": 278, "endOffset": 296}, {"referenceID": 4, "context": "Other prominent examples are largely for extinct languages: Egyptian hieroglyphics, Mayan glyphs, and Sumerian cuneiform scripts (Daniels and Bright, 1996).", "startOffset": 129, "endOffset": 155}, {"referenceID": 26, "context": "We also show that the learned representations are particularly effective under low-resource scenarios and complementary with standard character embeddings; combining the two representations through three different fusion methods (Snoek et al., 2005; Karpathy et al., 2014) leads to consistent improvements over the strongest baseline without visual features.", "startOffset": 229, "endOffset": 272}, {"referenceID": 13, "context": "We also show that the learned representations are particularly effective under low-resource scenarios and complementary with standard character embeddings; combining the two representations through three different fusion methods (Snoek et al., 2005; Karpathy et al., 2014) leads to consistent improvements over the strongest baseline without visual features.", "startOffset": 229, "endOffset": 272}, {"referenceID": 30, "context": "While this task in itself is novel, it is similar to previous work in named entity type inference using Wikipedia (Toral and Munoz, 2006; Kazama and Torisawa, 2007; Ratinov and Roth, 2009), which has proven useful for downstream named entity recognition systems.", "startOffset": 114, "endOffset": 188}, {"referenceID": 14, "context": "While this task in itself is novel, it is similar to previous work in named entity type inference using Wikipedia (Toral and Munoz, 2006; Kazama and Torisawa, 2007; Ratinov and Roth, 2009), which has proven useful for downstream named entity recognition systems.", "startOffset": 114, "endOffset": 188}, {"referenceID": 23, "context": "While this task in itself is novel, it is similar to previous work in named entity type inference using Wikipedia (Toral and Munoz, 2006; Kazama and Torisawa, 2007; Ratinov and Roth, 2009), which has proven useful for downstream named entity recognition systems.", "startOffset": 114, "endOffset": 188}, {"referenceID": 22, "context": "2, the character rank-frequency distributions of all three languages follows the 80/20 rule (Newman, 2005) (i.", "startOffset": 92, "endOffset": 106}, {"referenceID": 28, "context": "Our overall model for the classification task follows the encoder model by Sutskever et al. (2014).", "startOffset": 75, "endOffset": 99}, {"referenceID": 1, "context": "Encoder and Classifier For both the LOOKUP and the VISUAL models, we adopt an RNN encoder using Gated Recurrent Units (GRUs) (Chung et al., 2014).", "startOffset": 125, "endOffset": 145}, {"referenceID": 25, "context": "We adopt three fusion schemes, early fusion, late fusion (described by Snoek et al. (2005) and Karpathy et al.", "startOffset": 71, "endOffset": 91}, {"referenceID": 13, "context": "(2005) and Karpathy et al. (2014)), and fallback fusion, a method specific to this paper.", "startOffset": 11, "endOffset": 34}, {"referenceID": 2, "context": "We build our proposed model using Torch (Collobert et al., 2002), and use Adam (Kingma and Ba, 2014) with a learning rate \u03b7 = 0.", "startOffset": 40, "endOffset": 64}, {"referenceID": 16, "context": ", 2002), and use Adam (Kingma and Ba, 2014) with a learning rate \u03b7 = 0.", "startOffset": 22, "endOffset": 43}, {"referenceID": 33, "context": "Emphasis of the VISUAL Model In order to delve deeper into what the VISUAL model has learned, we measure a modified version of the occlusion sensitivity proposed by Zeiler and Fergus (2014) by masking the original character image in four ways, and examine the importance of each part of the character to the model\u2019s calculated representations.", "startOffset": 165, "endOffset": 190}, {"referenceID": 21, "context": "However, word2vec (Mikolov et al., 2013), for example, requires storing an extremely large table of vectors for all word types.", "startOffset": 18, "endOffset": 40}, {"referenceID": 7, "context": "For example, due to the size of word types in twitter tweets, work has been done to generate vector representations of tweets at character-level (Dhingra et al., 2016).", "startOffset": 145, "endOffset": 167}, {"referenceID": 6, "context": "There is also work done in understanding mathematical expressions with a convolutional network for text and layout recognition by using an attention-based neural machine translation system (Deng et al., 2016).", "startOffset": 189, "endOffset": 208}, {"referenceID": 28, "context": "Other than that, there are several works that combine visual information with text in improving machine translation (Sutskever et al., 2014), visual question answering, caption generation (Xu et al.", "startOffset": 116, "endOffset": 140}, {"referenceID": 32, "context": ", 2014), visual question answering, caption generation (Xu et al., 2015), etc.", "startOffset": 55, "endOffset": 72}, {"referenceID": 35, "context": "These works extract image representations from a pre-trained CNN (Zhu et al., 2016; Wang et al., 2016).", "startOffset": 65, "endOffset": 102}, {"referenceID": 31, "context": "These works extract image representations from a pre-trained CNN (Zhu et al., 2016; Wang et al., 2016).", "startOffset": 65, "endOffset": 102}, {"referenceID": 15, "context": "Unrelated to images, CNNs have also been used for text classification (Kim, 2014; Zhang et al., 2015).", "startOffset": 70, "endOffset": 101}, {"referenceID": 34, "context": "Unrelated to images, CNNs have also been used for text classification (Kim, 2014; Zhang et al., 2015).", "startOffset": 70, "endOffset": 101}, {"referenceID": 10, "context": "Several techniques for reducing the rare words effects have been introduced in the literature, including spelling expansion (Habash, 2008), dictionary term expansion (Habash, 2008), proper name transliteration (Daum\u00e9 and Jagarlamudi, 2011), treating words as a sequence of characters (Luong and Manning, 2016), subword units (Sennrich et al.", "startOffset": 124, "endOffset": 138}, {"referenceID": 10, "context": "Several techniques for reducing the rare words effects have been introduced in the literature, including spelling expansion (Habash, 2008), dictionary term expansion (Habash, 2008), proper name transliteration (Daum\u00e9 and Jagarlamudi, 2011), treating words as a sequence of characters (Luong and Manning, 2016), subword units (Sennrich et al.", "startOffset": 166, "endOffset": 180}, {"referenceID": 5, "context": "Several techniques for reducing the rare words effects have been introduced in the literature, including spelling expansion (Habash, 2008), dictionary term expansion (Habash, 2008), proper name transliteration (Daum\u00e9 and Jagarlamudi, 2011), treating words as a sequence of characters (Luong and Manning, 2016), subword units (Sennrich et al.", "startOffset": 210, "endOffset": 239}, {"referenceID": 19, "context": "Several techniques for reducing the rare words effects have been introduced in the literature, including spelling expansion (Habash, 2008), dictionary term expansion (Habash, 2008), proper name transliteration (Daum\u00e9 and Jagarlamudi, 2011), treating words as a sequence of characters (Luong and Manning, 2016), subword units (Sennrich et al.", "startOffset": 284, "endOffset": 309}, {"referenceID": 24, "context": "Several techniques for reducing the rare words effects have been introduced in the literature, including spelling expansion (Habash, 2008), dictionary term expansion (Habash, 2008), proper name transliteration (Daum\u00e9 and Jagarlamudi, 2011), treating words as a sequence of characters (Luong and Manning, 2016), subword units (Sennrich et al., 2015), and reading text as bytes (Gillick et al.", "startOffset": 325, "endOffset": 348}, {"referenceID": 9, "context": ", 2015), and reading text as bytes (Gillick et al., 2015).", "startOffset": 35, "endOffset": 57}, {"referenceID": 25, "context": "Finally, there is one work by Shi et al. (2015) on \u201cradical embedding\u201d, which explicitly splits Chinese characters into radicals based on a dictionary", "startOffset": 30, "endOffset": 48}], "year": 2017, "abstractText": "Previous work has modeled the compositionality of words by creating characterlevel models of meaning, reducing problems of sparsity for rare words. However, in many writing systems compositionality has an effect even on the character-level: the meaning of a character is derived by the sum of its parts. In this paper, we model this effect by creating embeddings for characters based on their visual characteristics, creating an image for the character and running it through a convolutional neural network to produce a visual character embedding. Experiments on a text classification task demonstrate that such model allows for better processing of instances with rare characters in languages such as Chinese, Japanese, and Korean. Additionally, qualitative analyses demonstrate that our proposed model learns to focus on the parts of characters that carry semantic content, resulting in embeddings that are coherent in visual space.", "creator": "LaTeX with hyperref package"}}}