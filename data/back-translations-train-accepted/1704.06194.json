{"id": "1704.06194", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "20-Apr-2017", "title": "Improved Neural Relation Detection for Knowledge Base Question Answering", "abstract": "Relation detection is a core component for many NLP applications including Knowledge Base Question Answering (KBQA). In this paper, we propose a hierarchical recurrent neural network enhanced by residual learning that detects KB relations given an input question. Our method uses deep residual bidirectional LSTMs to compare questions and relation names via different hierarchies of abstraction. Additionally, we propose a simple KBQA system that integrates entity linking and our proposed relation detector to enable one enhance another. Experimental results evidence that our approach achieves not only outstanding relation detection performance, but more importantly, it helps our KBQA system to achieve state-of-the-art accuracy for both single-relation (SimpleQuestions) and multi-relation (WebQSP) QA benchmarks.", "histories": [["v1", "Thu, 20 Apr 2017 15:48:05 GMT  (299kb,D)", "https://arxiv.org/abs/1704.06194v1", "Accepted by ACL 2017"], ["v2", "Sat, 27 May 2017 17:45:35 GMT  (922kb,D)", "http://arxiv.org/abs/1704.06194v2", "Accepted by ACL 2017 (updated for camera-ready)"]], "COMMENTS": "Accepted by ACL 2017", "reviews": [], "SUBJECTS": "cs.CL cs.AI cs.NE", "authors": ["mo yu", "wenpeng yin 0001", "kazi saidul hasan", "c\u00edcero nogueira dos santos", "bing xiang", "bowen zhou"], "accepted": true, "id": "1704.06194"}, "pdf": {"name": "1704.06194.pdf", "metadata": {"source": "CRF", "title": "Improved Neural Relation Detection for Knowledge Base Question Answering", "authors": ["Mo Yu", "Wenpeng Yin", "Kazi Saidul Hasan", "Cicero dos Santos", "Bing Xiang", "Bowen Zhou"], "emails": ["yum@us.ibm.com,", "kshasan@us.ibm.com,", "cicerons@us.ibm.com,", "bingxia@us.ibm.com,", "zhou@us.ibm.com,", "wenpeng@cis.lmu.de"], "sections": [{"heading": "1 Introduction", "text": "This year it is more than ever before."}, {"heading": "2 Related Work", "text": "The general research in this area usually does not work on a (small) predefined relation, where one paragraph of text and two target groups is the goal of determining whether the text indicates any type of relationship between entities or not. Consequently, RE is usually formulated as a classification task. Traditional RE methods rely on a large amount of handmade features (Zhou et al., 2005; Rink and Harabagiu, 2010; Sun et al., 2011). Recent research results benefit from the advancement of deep learning processes: from word embedding (Nguyen and Grishman, 2014; Gormley et al., 2015) to deep networks such as CNNs and LSTMs (Zeng et al., 2014; dos Santos et al., 2015; Vu et al., 2016) and attention models (Zhou et al., 2016).The relationship described above is a closed one."}, {"heading": "3 Background: Different Granularity in", "text": "In this case, each relationship name is treated as a unique symbol. The problem with this approach is that it suffers from low coverage due to the limited amount of training data, so it cannot be generalized well. In Figure 1, each relationship name is treated as a unique symbol. The problem with this approach is that it has low coverage due to the limited amount of training data, so the large number of open relationships cannot be generalized well. In Figure 1, it will be difficult to match the relationship names \"episodes written\" and \"star roles\" questions if they do not appear in the training data."}, {"heading": "4 Improved KB Relation Detection", "text": "This section describes our hierarchical sequence synchronization with a residual learning approach to relationship recognition. To assign the question to different aspects of a relationship (with different levels of abstraction), we treat three problems with regard to the presentation of learning questions / relationships as follows."}, {"heading": "4.1 Relation Representations from Different Granularity", "text": "We provide our model with both types of relation representations: word and relationship level. Therefore, the input relationship becomes r = {rword1, \u00b7 \u00b7, rwordM1}, where the first M1 characters are words (e.g. {episode, written}) and the last M2 characters are relation names, e.g. {episode written} or {starring roles, series} (if the target is a chain as in Figure 1 (b)))). We transform each of these symbols into its word embedding and then use two BiLSTMs (with common parameters) to obtain their hidden representations [Bword1: M1: Brel1: M2] (each row vector \u03b2i is the concatenation between forward / backward representations at i). We initialize the relation sequence LSTMs with the final state representations of the word sequence, as a back-off for invisible relations."}, {"heading": "4.2 Different Abstractions of Questions Representations", "text": "From Table 1, we can see that different parts of a relationship may coincide with different contexts of question texts. Normally, relation names could coincide with longer phrases in the question, and relation words with short phrases. Nevertheless, different words might coincide with phrases of different lengths. Consequently, we hope that the questions could also include vectors that summarize different phrase information (different levels of abstraction) to assign relation representations of different granularity. We deal with this problem by applying deep BiLSTMs to questions. The first layer of BiLSTM works on embedding question words q = {q1, \u00b7 \u00b7, qN} and obtains hidden representations."}, {"heading": "4.3 Hierarchical Matching between Relation and Question", "text": "In contrast to the standard use of deep BiLSTMs, which uses the last-level representations for prediction, we expect that two levels of questions can complement each other, and both should be compared with the same hierarchical matching, which is important for our task, since each relation identifier can correspond to phrases of different lengths, mainly due to syntactical variations. For example, in Table 1, the written relation word could match either the same single word in the question or a much longer phrase. We could perform the above hierarchical mapping by calculating the similarity between each level of the hierarchy and the hour separately, and performing the (weighted) sum between the two levels, but there is no significant improvement (see Table 2). Our analysis in Section 6.2 shows that this naive method suffers from training difficulties."}, {"heading": "5 KBQA Enhanced by Relation Detection", "text": "This section describes our KBQA pipeline system. We make minimal effort on the formation of the relation-scoring model, making the entire system easy to build.After previous work (Yih et al., 2015; Xu et al., 2016), our KBQA system takes an existing entity linker to input the top K-related entities, ELK (q), for a question q (\"Initial Entity Linking\"). Then we generate the KB requests for q according to the four steps set out in algorithm 1.algorithm 1: KBQA with two-step relation-recognition input: question q, Knowledge-Base KB, the initial K-Entity-candidate ELK candidates (q) Output: top query-tupie-candidate-tupie-tupie, (c, rc)} 1 Entity Re-Ranking-base-recognition-Entity-Entity-Entity-K, Entity-Entity-K-Entity-Enty-Enty-K, Entity-Entity-Entity-K, Entity-K-Entity-Entity-Entity-B, Entity-ELtity-Entity-K)."}, {"heading": "5.1 Entity Re-Ranking", "text": "Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Scores-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Scores-Scores-Scores-Scores-Scores-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-Score-"}, {"heading": "5.2 Relation Detection", "text": "In this step, we use the question text as input to a relation detector to evaluate all relationships associated with unit e in KB.4. Since we have a single topic unit in this step, we perform the following question formatting: We replace the mention of the unit of candidate e in 4Note that the number of units and the number of relation candidates will be much smaller than those in the previous step.q with a symbol \"< e >.\" This helps the model to better distinguish the relative position of each word relative to the unit. We use the HR-BiLSTM model to anticipate the value of each relationship. Re: srel (r; e, q)."}, {"heading": "5.3 Query Generation", "text": "Finally, the system outputs the < unit, relationship (or core chain) > pair (e, r) according to: s (e, r, q) = max e, EL, K (q), r, Re (\u03b2 \u00b7 srerank (e; q) + (1 \u2212 \u03b2) \u00b7 srel (r; e, q)), where \u03b2 is a hyperparameter to be tuned."}, {"heading": "5.4 Constraint Detection", "text": "Similar to (Yih et al., 2015), we are introducing an additional step for recognizing constraints based on text matching. Our method can be considered a link on a KB subgraph. It includes two steps: (1) Generating subgraphs: Given the query with the highest score of 5 generated by the previous three steps, we collect for each node v (response node or the CVT node as shown in Figure 1 (b) all nodes c that are associated with v (with relation rc) in any relationship, and create a subgraph associated with the original query. (2) Linking subgraphs: We calculate a matching score between each n-gram in the input query (without overlapping the topic) and the entity names of c (with the exception of the node in the original query) by taking into account the maximum overlap of characters between them (see Appendix c for details of the date name and the original answer type)."}, {"heading": "6 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Task Introduction & Settings", "text": "We use the SimpleQuestions (Bordes et al., 2015) and WebQSP (Yih et al., 2016) datasets. Each question in these datasets is labeled with the Gold Semantics Analysis. Therefore, we can independently evaluate the detection performance of relations and evaluate on the KBQA final task. 5In future work, we will leave the beam search and function extraction on the beam for the final answer reassessment as in previous research. SimpleQuestions (SQ): It is a single-relation KBQA task that we use to demonstrate the benefit of our relationship detection model. We will leave the beam work and feature extraction on the beam for the final answer reassessment as in previous research. SimpleQuestions (SQ): It is a single-relation KBQA task. The KB we use consists of a freebase subset with 2M units (F2M) of the Research (B2M) to Boret (2015)."}, {"heading": "6.2 Relation Detection Results", "text": "In fact, it is that it is a matter of a way in which people are able to survive themselves, not only by surviving themselves, but also by surviving themselves, but also by seeing themselves able to survive themselves. (...) It is not that people are able to survive themselves. (...) It is not that they are able to survive themselves. (...) It is not that they are able to survive themselves. \"(...) It is not that they are able to survive themselves.\" (...) It is not that they are able to survive themselves. (...) It is not that they are able to survive themselves. \"(...) It is not that they want to survive themselves.\" (...) It is not that they are able to survive themselves, as if they do it, as if they want to. \"(...) It is not that they want to survive themselves.\" (...) It is not that they are able to survive themselves."}, {"heading": "6.3 KBQA End-Task Results", "text": "Table 3 compares our system with two published baselines (1) STAGG (Yih et al., 2015), the state of the art on WebQSP11 and (2) AMPCNN (Yin et al., 2016), the state of the art on SimpleQuestions. Because these two baselines are specifically designed / tuned for a particular data set, they do not generalize well when applied to the other data set. To highlight the effect of different detection models on the KBQA end task, we have also implemented another baseline that uses our KBQA system, but replaces HR-BiLSTM with our implementation of AMPCNN (for SimpleQuestions) or the Char-3-gram BiCNN (for WebQSP) relationship detectors (second block in Table 3)."}, {"heading": "7 Conclusion", "text": "The detection of KB relationships is a key step in KBQA and differs significantly from general tasks for detecting relationships. We propose a novel KB relationship detection model, HR-BiLSTM, which performs a hierarchical comparison between questions and KB relationships. Our model surpasses previous methods for detecting KB relationships and allows our KBQA system to reach the state of the art. In future work, we will also examine the integration of our HR-BiLSTM into end-to-end systems, for example, our model could be integrated into the decoder (Liang et al., 2016) to provide better sequence prediction."}, {"heading": "Appendix A: Detailed Score Computation for Constraint Detection", "text": "Considering an input query q and an entity name e in KB, we designate the lengths of the question and the entity name as | q | and | ne |. For mentioning m of entity e, which is an n-gram in q, we calculate the longest consecutive common sub-sequence between m and e and designate its length as | m-e |. All of the above lengths are measured by the number of letters. Based on the above numbers, we calculate the ratio of the length of overlap between entity mention and entity name (in letters) in the entity name | m-e | | e | and in the question | m-e | q |; The end result of the question indicates a mention related to e-isslinker (e; q) = max m-m-e | | q | + | m-e-e-e |."}, {"heading": "Appendix B: Special Rules for Constraint Detection", "text": "1. Special Threshold for Date Restrictions. The timestamps in KB usually follow the format of the year-month day, while the time in WebQSP is usually years, which reduces the overlap between the date units in questions and the KB entity names (the length of overlap is usually 4).To handle this, we only check if the data in the questions might match the years in KB, and therefore have a special threshold of \u03b8 = 1 for date restrictions. 2. Filter the constraints on answer nodes. Sometimes, the answer node could connect with a large number of other nodes, e.g. when the question is asked about a country or city and we have an answer candidate for the U.S. Based on the observation on the WebQSP datasets, we have found that the gold constraints on answers for most of the time are their entity types (e.g., if the question asks about a country or city)."}, {"heading": "Appendix C: Effects of Entity Re-Ranking on SimpleQuestions", "text": "Removing the re-ranking step leads to a significant drop in performance (see Table 3, the row without re-ranking). Table 4 rates our re-ranking as a separate task. Our re-ranking results in a big improvement, especially if the bar sizes are smaller than 10. This points to another important use of our proposed improved relationship recognition model in linking re-ranking."}], "references": [{"title": "Constraint-based question answering with knowledge graph", "author": ["Junwei Bao", "Nan Duan", "Zhao Yan", "Ming Zhou", "Tiejun Zhao."], "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers.", "citeRegEx": "Bao et al\\.,? 2016", "shortCiteRegEx": "Bao et al\\.", "year": 2016}, {"title": "More accurate question answering on freebase", "author": ["Hannah Bast", "Elmar Haussmann."], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, pages 1431\u20131440.", "citeRegEx": "Bast and Haussmann.,? 2015", "shortCiteRegEx": "Bast and Haussmann.", "year": 2015}, {"title": "Semantic parsing on Freebase from question-answer pairs", "author": ["Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational", "citeRegEx": "Berant et al\\.,? 2013", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "Large-scale simple question answering with memory networks", "author": ["Antoine Bordes", "Nicolas Usunier", "Sumit Chopra", "Jason Weston."], "venue": "arXiv preprint arXiv:1506.02075 .", "citeRegEx": "Bordes et al\\.,? 2015", "shortCiteRegEx": "Bordes et al\\.", "year": 2015}, {"title": "Translating embeddings for modeling multirelational data", "author": ["Antoine Bordes", "Nicolas Usunier", "Alberto GarciaDuran", "Jason Weston", "Oksana Yakhnenko."], "venue": "Advances in Neural Information Processing Systems. pages 2787\u20132795.", "citeRegEx": "Bordes et al\\.,? 2013", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "Cfo: Conditional focused neural question answering with largescale knowledge bases", "author": ["Zihang Dai", "Lei Li", "Wei Xu."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Asso-", "citeRegEx": "Dai et al\\.,? 2016", "shortCiteRegEx": "Dai et al\\.", "year": 2016}, {"title": "Classifying relations by ranking with convolutional neural networks", "author": ["Cicero dos Santos", "Bing Xiang", "Bowen Zhou."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint", "citeRegEx": "Santos et al\\.,? 2015", "shortCiteRegEx": "Santos et al\\.", "year": 2015}, {"title": "Paraphrase-driven learning for open question answering", "author": ["Anthony Fader", "Luke S Zettlemoyer", "Oren Etzioni."], "venue": "ACL (1). Citeseer, pages 1608\u20131618.", "citeRegEx": "Fader et al\\.,? 2013", "shortCiteRegEx": "Fader et al\\.", "year": 2013}, {"title": "Character-level question answering with attention", "author": ["David Golub", "Xiaodong He."], "venue": "arXiv preprint arXiv:1604.00727 .", "citeRegEx": "Golub and He.,? 2016", "shortCiteRegEx": "Golub and He.", "year": 2016}, {"title": "Improved relation extraction with feature-rich compositional embedding models", "author": ["Matthew R. Gormley", "Mo Yu", "Mark Dredze."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Compu-", "citeRegEx": "Gormley et al\\.,? 2015", "shortCiteRegEx": "Gormley et al\\.", "year": 2015}, {"title": "Deep residual learning for image recognition", "author": ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pages 770\u2013778.", "citeRegEx": "He et al\\.,? 2016", "shortCiteRegEx": "He et al\\.", "year": 2016}, {"title": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision", "author": ["Chen Liang", "Jonathan Berant", "Quoc Le", "Kenneth D Forbus", "Ni Lao."], "venue": "arXiv preprint arXiv:1611.00020 .", "citeRegEx": "Liang et al\\.,? 2016", "shortCiteRegEx": "Liang et al\\.", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Employing word representations and regularization for domain adaptation of relation extraction", "author": ["Thien Huu Nguyen", "Ralph Grishman."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short", "citeRegEx": "Nguyen and Grishman.,? 2014", "shortCiteRegEx": "Nguyen and Grishman.", "year": 2014}, {"title": "A decomposable attention model for natural language inference", "author": ["Ankur Parikh", "Oscar T\u00e4ckstr\u00f6m", "Dipanjan Das", "Jakob Uszkoreit."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association", "citeRegEx": "Parikh et al\\.,? 2016", "shortCiteRegEx": "Parikh et al\\.", "year": 2016}, {"title": "Utd: Classifying semantic relations by combining lexical and semantic resources", "author": ["Bryan Rink", "Sanda Harabagiu."], "venue": "Proceedings of the 5th International Workshop on Semantic Evaluation. Association for Computational Linguistics, Uppsala, Swe-", "citeRegEx": "Rink and Harabagiu.,? 2010", "shortCiteRegEx": "Rink and Harabagiu.", "year": 2010}, {"title": "On generating characteristic-rich question sets for qa evaluation", "author": ["Yu Su", "Huan Sun", "Brian Sadler", "Mudhakar Srivatsa", "Izzeddin Gur", "Zenghui Yan", "Xifeng Yan."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natu-", "citeRegEx": "Su et al\\.,? 2016", "shortCiteRegEx": "Su et al\\.", "year": 2016}, {"title": "Semi-supervised relation extraction with large-scale word clustering", "author": ["Ang Sun", "Ralph Grishman", "Satoshi Sekine."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Associa-", "citeRegEx": "Sun et al\\.,? 2011", "shortCiteRegEx": "Sun et al\\.", "year": 2011}, {"title": "Combining recurrent and convolutional neural networks for relation classification", "author": ["Ngoc Thang Vu", "Heike Adel", "Pankaj Gupta", "Hinrich Sch\u00fctze."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for", "citeRegEx": "Vu et al\\.,? 2016", "shortCiteRegEx": "Vu et al\\.", "year": 2016}, {"title": "Relation classification via multi-level attention cnns", "author": ["Linlin Wang", "Zhu Cao", "Gerard de Melo", "Zhiyuan Liu."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Association for", "citeRegEx": "Wang et al\\.,? 2016", "shortCiteRegEx": "Wang et al\\.", "year": 2016}, {"title": "Learning natural language inference with lstm", "author": ["Shuohang Wang", "Jing Jiang."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-", "citeRegEx": "Wang and Jiang.,? 2016", "shortCiteRegEx": "Wang and Jiang.", "year": 2016}, {"title": "Bilateral multi-perspective matching for natural language sentences", "author": ["Zhiguo Wang", "Wael Hamza", "Radu Florian."], "venue": "arXiv preprint arXiv:1702.03814 .", "citeRegEx": "Wang et al\\.,? 2017", "shortCiteRegEx": "Wang et al\\.", "year": 2017}, {"title": "Question answering on freebase via relation extraction and textual evidence", "author": ["Kun Xu", "Siva Reddy", "Yansong Feng", "Songfang Huang", "Dongyan Zhao."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1:", "citeRegEx": "Xu et al\\.,? 2016", "shortCiteRegEx": "Xu et al\\.", "year": 2016}, {"title": "S-mart: Novel tree-based structured learning algorithms applied to tweet entity linking", "author": ["Yi Yang", "Ming-Wei Chang."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Confer-", "citeRegEx": "Yang and Chang.,? 2015", "shortCiteRegEx": "Yang and Chang.", "year": 2015}, {"title": "Freebase qa: Information extraction or semantic parsing", "author": ["Xuchen Yao", "Jonathan Berant", "Benjamin Van Durme"], "venue": "ACL", "citeRegEx": "Yao et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yao et al\\.", "year": 2014}, {"title": "Information extraction over structured data: Question answering with freebase", "author": ["Xuchen Yao", "Benjamin Van Durme."], "venue": "ACL (1). Citeseer, pages 956\u2013966.", "citeRegEx": "Yao and Durme.,? 2014", "shortCiteRegEx": "Yao and Durme.", "year": 2014}, {"title": "Semantic parsing via staged query graph generation: Question answering with knowledge base", "author": ["Wen-tau Yih", "Ming-Wei Chang", "Xiaodong He", "Jianfeng Gao."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Yih et al\\.,? 2015", "shortCiteRegEx": "Yih et al\\.", "year": 2015}, {"title": "Semantic parsing for single-relation question answering", "author": ["Wen-tau Yih", "Xiaodong He", "Christopher Meek."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association", "citeRegEx": "Yih et al\\.,? 2014", "shortCiteRegEx": "Yih et al\\.", "year": 2014}, {"title": "The value of semantic parse labeling for knowledge base question", "author": ["Wen-tau Yih", "Matthew Richardson", "Chris Meek", "MingWei Chang", "Jina Suh"], "venue": null, "citeRegEx": "Yih et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Yih et al\\.", "year": 2016}, {"title": "Simple question answering by attentive convolutional neural network", "author": ["Wenpeng Yin", "Mo Yu", "Bing Xiang", "Bowen Zhou", "Hinrich Sch\u00fctze."], "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Techni-", "citeRegEx": "Yin et al\\.,? 2016", "shortCiteRegEx": "Yin et al\\.", "year": 2016}, {"title": "Embedding lexical features via lowrank tensors", "author": ["Mo Yu", "Mark Dredze", "Raman Arora", "Matthew R. Gormley."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language", "citeRegEx": "Yu et al\\.,? 2016", "shortCiteRegEx": "Yu et al\\.", "year": 2016}, {"title": "Relation classification via convolutional deep neural network", "author": ["Daojian Zeng", "Kang Liu", "Siwei Lai", "Guangyou Zhou", "Jun Zhao."], "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers.", "citeRegEx": "Zeng et al\\.,? 2014", "shortCiteRegEx": "Zeng et al\\.", "year": 2014}, {"title": "Exploring various knowledge in relation extraction", "author": ["GuoDong Zhou", "Jian Su", "Jie Zhang", "Min Zhang."], "venue": "Association for Computational Linguistics. pages 427\u2013434.", "citeRegEx": "Zhou et al\\.,? 2005", "shortCiteRegEx": "Zhou et al\\.", "year": 2005}, {"title": "Attentionbased bidirectional long short-term memory networks for relation classification", "author": ["Peng Zhou", "Wei Shi", "Jun Tian", "Zhenyu Qi", "Bingchen Li", "Hongwei Hao", "Bo Xu."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Com-", "citeRegEx": "Zhou et al\\.,? 2016", "shortCiteRegEx": "Zhou et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 2, "context": "Knowledge Base Question Answering (KBQA) systems answer questions by obtaining information from KB tuples (Berant et al., 2013; Yao et al., 2014; Bordes et al., 2015; Bast and Haussmann, 2015; Yih et al., 2015; Xu et al., 2016).", "startOffset": 106, "endOffset": 227}, {"referenceID": 24, "context": "Knowledge Base Question Answering (KBQA) systems answer questions by obtaining information from KB tuples (Berant et al., 2013; Yao et al., 2014; Bordes et al., 2015; Bast and Haussmann, 2015; Yih et al., 2015; Xu et al., 2016).", "startOffset": 106, "endOffset": 227}, {"referenceID": 3, "context": "Knowledge Base Question Answering (KBQA) systems answer questions by obtaining information from KB tuples (Berant et al., 2013; Yao et al., 2014; Bordes et al., 2015; Bast and Haussmann, 2015; Yih et al., 2015; Xu et al., 2016).", "startOffset": 106, "endOffset": 227}, {"referenceID": 1, "context": "Knowledge Base Question Answering (KBQA) systems answer questions by obtaining information from KB tuples (Berant et al., 2013; Yao et al., 2014; Bordes et al., 2015; Bast and Haussmann, 2015; Yih et al., 2015; Xu et al., 2016).", "startOffset": 106, "endOffset": 227}, {"referenceID": 26, "context": "Knowledge Base Question Answering (KBQA) systems answer questions by obtaining information from KB tuples (Berant et al., 2013; Yao et al., 2014; Bordes et al., 2015; Bast and Haussmann, 2015; Yih et al., 2015; Xu et al., 2016).", "startOffset": 106, "endOffset": 227}, {"referenceID": 22, "context": "Knowledge Base Question Answering (KBQA) systems answer questions by obtaining information from KB tuples (Berant et al., 2013; Yao et al., 2014; Bordes et al., 2015; Bast and Haussmann, 2015; Yih et al., 2015; Xu et al., 2016).", "startOffset": 106, "endOffset": 227}, {"referenceID": 3, "context": "KBQA even a small KB, like Freebase2M (Bordes et al., 2015), contains more than 6,000 relation types.", "startOffset": 38, "endOffset": 59}, {"referenceID": 3, "context": "For example, the SimpleQuestions (Bordes et al., 2015) data set has 14% of the golden test relations not observed in golden training tuples.", "startOffset": 33, "endOffset": 54}, {"referenceID": 2, "context": "Third, as shown in Figure 1(b), for some KBQA tasks like WebQuestions (Berant et al., 2013), we need to predict a chain of relations instead of a single relation.", "startOffset": 70, "endOffset": 91}, {"referenceID": 26, "context": "Following Yih et al. (2015), here topic entity refers to the root of the (directed) query tree; and core-chain is the directed path of relation from root to the answer node.", "startOffset": 10, "endOffset": 28}, {"referenceID": 32, "context": "Traditional RE methods rely on large amount of hand-crafted features (Zhou et al., 2005; Rink and Harabagiu, 2010; Sun et al., 2011).", "startOffset": 69, "endOffset": 132}, {"referenceID": 15, "context": "Traditional RE methods rely on large amount of hand-crafted features (Zhou et al., 2005; Rink and Harabagiu, 2010; Sun et al., 2011).", "startOffset": 69, "endOffset": 132}, {"referenceID": 17, "context": "Traditional RE methods rely on large amount of hand-crafted features (Zhou et al., 2005; Rink and Harabagiu, 2010; Sun et al., 2011).", "startOffset": 69, "endOffset": 132}, {"referenceID": 13, "context": "Recent research benefits a lot from the advancement of deep learning: from word embeddings (Nguyen and Grishman, 2014; Gormley et al., 2015) to deep networks like CNNs and LSTMs (Zeng et al.", "startOffset": 91, "endOffset": 140}, {"referenceID": 9, "context": "Recent research benefits a lot from the advancement of deep learning: from word embeddings (Nguyen and Grishman, 2014; Gormley et al., 2015) to deep networks like CNNs and LSTMs (Zeng et al.", "startOffset": 91, "endOffset": 140}, {"referenceID": 31, "context": ", 2015) to deep networks like CNNs and LSTMs (Zeng et al., 2014; dos Santos et al., 2015; Vu et al., 2016) and attention models (Zhou et al.", "startOffset": 45, "endOffset": 106}, {"referenceID": 18, "context": ", 2015) to deep networks like CNNs and LSTMs (Zeng et al., 2014; dos Santos et al., 2015; Vu et al., 2016) and attention models (Zhou et al.", "startOffset": 45, "endOffset": 106}, {"referenceID": 33, "context": ", 2016) and attention models (Zhou et al., 2016; Wang et al., 2016).", "startOffset": 29, "endOffset": 67}, {"referenceID": 19, "context": ", 2016) and attention models (Zhou et al., 2016; Wang et al., 2016).", "startOffset": 29, "endOffset": 67}, {"referenceID": 30, "context": "Yu et al. (2016) proposed to use relation embeddings in a low-rank tensor method.", "startOffset": 0, "endOffset": 17}, {"referenceID": 1, "context": "Relation Detection in KBQA Systems Relation detection for KBQA also starts with featurerich approaches (Yao and Van Durme, 2014; Bast and Haussmann, 2015) towards usages of deep networks (Yih et al.", "startOffset": 103, "endOffset": 154}, {"referenceID": 26, "context": "Relation Detection in KBQA Systems Relation detection for KBQA also starts with featurerich approaches (Yao and Van Durme, 2014; Bast and Haussmann, 2015) towards usages of deep networks (Yih et al., 2015; Xu et al., 2016; Dai et al., 2016) and attention models (Yin et al.", "startOffset": 187, "endOffset": 240}, {"referenceID": 22, "context": "Relation Detection in KBQA Systems Relation detection for KBQA also starts with featurerich approaches (Yao and Van Durme, 2014; Bast and Haussmann, 2015) towards usages of deep networks (Yih et al., 2015; Xu et al., 2016; Dai et al., 2016) and attention models (Yin et al.", "startOffset": 187, "endOffset": 240}, {"referenceID": 5, "context": "Relation Detection in KBQA Systems Relation detection for KBQA also starts with featurerich approaches (Yao and Van Durme, 2014; Bast and Haussmann, 2015) towards usages of deep networks (Yih et al., 2015; Xu et al., 2016; Dai et al., 2016) and attention models (Yin et al.", "startOffset": 187, "endOffset": 240}, {"referenceID": 7, "context": "Many of the above relation detection research could naturally support large relation vocabulary and open relation sets (especially for QA with OpenIE KB like ParaLex (Fader et al., 2013)), in order to fit the goal of", "startOffset": 166, "endOffset": 186}, {"referenceID": 4, "context": "(Bordes et al., 2013)), like (Dai et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 5, "context": ", 2013)), like (Dai et al., 2016); (2) factorize the relation names to sequences and formulate relation detection as a sequence matching and ranking task.", "startOffset": 15, "endOffset": 33}, {"referenceID": 3, "context": "(Bordes et al., 2013)), like (Dai et al., 2016); (2) factorize the relation names to sequences and formulate relation detection as a sequence matching and ranking task. Such factorization works because that the relation names usually comprise meaningful word sequences. For example, Yin et al. (2016) split relations to word sequences for single-relation detection.", "startOffset": 1, "endOffset": 301}, {"referenceID": 3, "context": "(Bordes et al., 2013)), like (Dai et al., 2016); (2) factorize the relation names to sequences and formulate relation detection as a sequence matching and ranking task. Such factorization works because that the relation names usually comprise meaningful word sequences. For example, Yin et al. (2016) split relations to word sequences for single-relation detection. Liang et al. (2016) also achieve good performance on WebQSP with wordlevel relation representation in an end-to-end neural programmer model.", "startOffset": 1, "endOffset": 386}, {"referenceID": 3, "context": "(Bordes et al., 2013)), like (Dai et al., 2016); (2) factorize the relation names to sequences and formulate relation detection as a sequence matching and ranking task. Such factorization works because that the relation names usually comprise meaningful word sequences. For example, Yin et al. (2016) split relations to word sequences for single-relation detection. Liang et al. (2016) also achieve good performance on WebQSP with wordlevel relation representation in an end-to-end neural programmer model. Yih et al. (2015) use character tri-grams as inputs on both question and relation sides.", "startOffset": 1, "endOffset": 525}, {"referenceID": 3, "context": "(Bordes et al., 2013)), like (Dai et al., 2016); (2) factorize the relation names to sequences and formulate relation detection as a sequence matching and ranking task. Such factorization works because that the relation names usually comprise meaningful word sequences. For example, Yin et al. (2016) split relations to word sequences for single-relation detection. Liang et al. (2016) also achieve good performance on WebQSP with wordlevel relation representation in an end-to-end neural programmer model. Yih et al. (2015) use character tri-grams as inputs on both question and relation sides. Golub and He (2016) propose a generative framework for single-relation KBQA which predicts relation with a character-level sequenceto-sequence model.", "startOffset": 1, "endOffset": 616}, {"referenceID": 13, "context": "features (Nguyen and Grishman, 2014; Gormley et al., 2015) or attention mechanisms (Wang et al.", "startOffset": 9, "endOffset": 58}, {"referenceID": 9, "context": "features (Nguyen and Grishman, 2014; Gormley et al., 2015) or attention mechanisms (Wang et al.", "startOffset": 9, "endOffset": 58}, {"referenceID": 19, "context": ", 2015) or attention mechanisms (Wang et al., 2016) based on the entity information (e.", "startOffset": 32, "endOffset": 51}, {"referenceID": 26, "context": "Previous research (Yih et al., 2015; Yin et al., 2016) formulates KB relation detection as a sequence matching problem.", "startOffset": 18, "endOffset": 54}, {"referenceID": 29, "context": "Previous research (Yih et al., 2015; Yin et al., 2016) formulates KB relation detection as a sequence matching problem.", "startOffset": 18, "endOffset": 54}, {"referenceID": 10, "context": "To overcome the above difficulties, we adopt the idea from Residual Networks (He et al., 2016) for hierarchical matching by adding shortcut connec-", "startOffset": 77, "endOffset": 94}, {"referenceID": 14, "context": "(Parikh et al., 2016), to find the correspondence between different levels of representations.", "startOffset": 0, "endOffset": 21}, {"referenceID": 26, "context": "Following previous work (Yih et al., 2015; Xu et al., 2016), our KBQA system takes an existing entity linker to produce the top-K linked entities, ELK(q), for a question q (\u201cinitial entity linking\u201d).", "startOffset": 24, "endOffset": 59}, {"referenceID": 22, "context": "Following previous work (Yih et al., 2015; Xu et al., 2016), our KBQA system takes an existing entity linker to produce the top-K linked entities, ELK(q), for a question q (\u201cinitial entity linking\u201d).", "startOffset": 24, "endOffset": 59}, {"referenceID": 26, "context": "Similar to (Yih et al., 2015), we adopt an additional constraint detection step based on text matching.", "startOffset": 11, "endOffset": 29}, {"referenceID": 3, "context": "We use the SimpleQuestions (Bordes et al., 2015) and WebQSP (Yih et al.", "startOffset": 27, "endOffset": 48}, {"referenceID": 28, "context": ", 2015) and WebQSP (Yih et al., 2016) datasets.", "startOffset": 19, "endOffset": 37}, {"referenceID": 3, "context": "The KB we use consists of a Freebase subset with 2M entities (FB2M) (Bordes et al., 2015), in order to compare with previous research.", "startOffset": 68, "endOffset": 89}, {"referenceID": 23, "context": "(2016), we use S-MART (Yang and Chang, 2015) entity-linking outputs.", "startOffset": 22, "endOffset": 44}, {"referenceID": 3, "context": "The KB we use consists of a Freebase subset with 2M entities (FB2M) (Bordes et al., 2015), in order to compare with previous research. Yin et al. (2016) also evaluated their relation extractor on this data set and released their proposed question-relation pairs, so we run our relation detection model on their data set.", "startOffset": 69, "endOffset": 153}, {"referenceID": 3, "context": "The KB we use consists of a Freebase subset with 2M entities (FB2M) (Bordes et al., 2015), in order to compare with previous research. Yin et al. (2016) also evaluated their relation extractor on this data set and released their proposed question-relation pairs, so we run our relation detection model on their data set. For the KBQA evaluation, we also start with their entity linking results6. Therefore, our results can be compared with their reported results on both tasks. WebQSP (WQ): A multi-relation KBQA task. We use the entire Freebase KB for evaluation purposes. Following Yih et al. (2016), we use S-MART (Yang and Chang, 2015) entity-linking outputs.", "startOffset": 69, "endOffset": 602}, {"referenceID": 12, "context": "All word vectors are initialized with 300-d pretrained word embeddings (Mikolov et al., 2013).", "startOffset": 71, "endOffset": 93}, {"referenceID": 29, "context": "The AMPCNN result is from (Yin et al., 2016), which yielded state-of-the-art scores by outperforming several attention-based meth-", "startOffset": 26, "endOffset": 44}, {"referenceID": 29, "context": "Accuracy Model Relation Input Views SimpleQuestions WebQSP AMPCNN (Yin et al., 2016) words 91.", "startOffset": 66, "endOffset": 84}, {"referenceID": 26, "context": "3 BiCNN (Yih et al., 2015) char-3-gram 90.", "startOffset": 8, "endOffset": 26}, {"referenceID": 14, "context": "65 replacing residual with attention (Parikh et al., 2016) words + rel names 92.", "startOffset": 37, "endOffset": 58}, {"referenceID": 26, "context": "We re-implemented the BiCNN model from (Yih et al., 2015), where both questions and relations are represented with the word hash trick on", "startOffset": 39, "endOffset": 57}, {"referenceID": 14, "context": "For the attention-based baseline, we tried the model from (Parikh et al., 2016) and its one-way variations, where the one-way model gives better results10.", "startOffset": 58, "endOffset": 79}, {"referenceID": 20, "context": "We hypothesize that the idea of hierarchical matching with attention mechanism may work better for long sequences, and the new advanced attention mechanisms (Wang and Jiang, 2016; Wang et al., 2017) might help hierarchical matching.", "startOffset": 157, "endOffset": 198}, {"referenceID": 21, "context": "We hypothesize that the idea of hierarchical matching with attention mechanism may work better for long sequences, and the new advanced attention mechanisms (Wang and Jiang, 2016; Wang et al., 2017) might help hierarchical matching.", "startOffset": 157, "endOffset": 198}, {"referenceID": 26, "context": "baselines (1) STAGG (Yih et al., 2015), the stateof-the-art on WebQSP11 and (2) AMPCNN (Yin et al.", "startOffset": 20, "endOffset": 38}, {"referenceID": 29, "context": ", 2015), the stateof-the-art on WebQSP11 and (2) AMPCNN (Yin et al., 2016), the state-of-the-art on SimpleQuestions.", "startOffset": 56, "endOffset": 74}, {"referenceID": 0, "context": "The STAGG score on SQ is from (Bao et al., 2016).", "startOffset": 30, "endOffset": 48}, {"referenceID": 29, "context": "9 AMPCNN (Yin et al., 2016) 76.", "startOffset": 9, "endOffset": 27}, {"referenceID": 26, "context": "in (Yih et al., 2015), constraint detection is crucial for our system12.", "startOffset": 3, "endOffset": 21}, {"referenceID": 26, "context": "Finally, like STAGG, which uses multiple relation detectors (see Yih et al. (2015) for the three models used), we also try to use the top-3 relation detectors from Section 6.", "startOffset": 65, "endOffset": 83}, {"referenceID": 11, "context": "For example, our model could be integrated into the decoder in (Liang et al., 2016), to provide better se-", "startOffset": 63, "endOffset": 83}, {"referenceID": 16, "context": "We will also investigate new emerging datasets like GraphQuestions (Su et al., 2016) and ComplexQuestions (Bao et al.", "startOffset": 67, "endOffset": 84}, {"referenceID": 0, "context": ", 2016) and ComplexQuestions (Bao et al., 2016) to handle more characteristics of general QA.", "startOffset": 29, "endOffset": 47}], "year": 2017, "abstractText": "Relation detection is a core component of many NLP applications including Knowledge Base Question Answering (KBQA). In this paper, we propose a hierarchical recurrent neural network enhanced by residual learning which detects KB relations given an input question. Our method uses deep residual bidirectional LSTMs to compare questions and relation names via different levels of abstraction. Additionally, we propose a simple KBQA system that integrates entity linking and our proposed relation detector to make the two components enhance each other. Our experimental results show that our approach not only achieves outstanding relation detection performance, but more importantly, it helps our KBQA system achieve state-of-the-art accuracy for both single-relation (SimpleQuestions) and multi-relation (WebQSP) QA benchmarks.", "creator": "LaTeX with hyperref package"}}}