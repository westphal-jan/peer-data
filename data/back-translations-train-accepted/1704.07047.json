{"id": "1704.07047", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Apr-2017", "title": "Fast and Accurate Neural Word Segmentation for Chinese", "abstract": "Neural models with minimal feature engineering have achieved competitive performance against traditional methods for the task of Chinese word segmentation. However, both training and working procedures of the current neural models are computationally inefficient. This paper presents a greedy neural word segmenter with balanced word and character embedding inputs to alleviate the existing drawbacks. Our segmenter is truly end-to-end, capable of performing segmentation much faster and even more accurate than state-of-the-art neural models on Chinese benchmark datasets.", "histories": [["v1", "Mon, 24 Apr 2017 05:50:29 GMT  (3422kb,D)", "http://arxiv.org/abs/1704.07047v1", "To appear in ACL2017"]], "COMMENTS": "To appear in ACL2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["deng cai", "hai zhao", "zhisong zhang", "yuan xin", "yongjian wu", "feiyue huang"], "accepted": true, "id": "1704.07047"}, "pdf": {"name": "1704.07047.pdf", "metadata": {"source": "CRF", "title": "Fast and Accurate Neural Word Segmentation for Chinese", "authors": ["Deng Cai", "Hai Zhao", "Zhisong Zhang", "Yuan Xin", "Yongjian Wu", "Feiyue Huang"], "emails": ["thisisjcykcd@gmail.com,", "{zhaohai@cs,", "zzs2011@}sjtu.edu.cn", "macxin@tencent.com", "littlekenwu@tencent.com", "garyhuang@tencent.com"], "sections": [{"heading": "1 Introduction", "text": "This year, the time has come for us to put ourselves in a position to take the lead, \"he said in an interview with the Deutsche Presse-Agentur.\" We have never hesitated so long, \"he said.\" But we are not yet as far as we imagined. \""}, {"heading": "2 Related Work", "text": "Statistical Chinese word segmentation has been studied for decades (Huang and Zhao, 2007). (Xue, 2003) was the first to present it as a character-based tagging problem. Peng et al. (2004) showed that CRF-based model is particularly effective for solving CWS in sequence labeling, a method that was followed by most subsequent segmentators (Tseng et al., 2005; Zhao et al., 2006; Zhao and Kit, 2008c; Zhao et al., 2010; Sun et al., 2012; Zhang et al., 2013), and by most neural models (Zheng et al., 2013; Pei et al., 2014; Chen et al., 2015a, b; Ma and Hinrichs, 2015; Xu and Sun, 2016)."}, {"heading": "3 Models", "text": "To segment a string, we use neural networks to determine the probability that a candidate sequence is a true set, and the one with the highest score is selected as the output."}, {"heading": "3.1 Neural Scorer", "text": "In fact, most of us are able to hide in order to understand the terms they have made their own. (mA) D \"n\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"n\" i \"n.\" A \"n\" c \"n\" n \"i\" i \"i\" i \"n\" i. \"A\" n \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"c\" i \"i\" i \"i.\" c \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" c \"c\" c \"h\" i \"i\" i \"i\" i \"i\" c \"c\" c \"h\" i \"i\" i \"i\" i \"i\" i \"i\" i \"c\" c \"c\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"c\" i \"i\" i \"i\" i \"i\" i \"i\" i \"c\" i \"i\" i \"i\" i \"i\" i \"i\" c \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" c \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" c \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"c\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" c \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"c\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i \"c\" c \"i\" i \"i\" i \"i\" i \"i\" i \"c\" i \"i\" i \"i\" i \"i\" i \"i\" i \"i\" i"}, {"heading": "3.2 Search", "text": "The number of possible segmented sentences grows exponentially with the length of the input sequence. Most existing methods use Markov assumptions to make the exact search.2 However, such assumptions cannot be made in our model, because the LSTM component takes full advantage of the segmentation history. We then use a bar search scheme that works iteratively on each prefix of the input sequence, approximating the k-highest-rated word sequences of each prefix (i.e. k is the bar size).The time complexity of our bar search is O (wkn), with w being the maximum word length and n the input sequence length."}, {"heading": "3.3 Training Criteria", "text": "Our segmentator is trained using max margin methods (Taskar et al., 2005), where the structured margin loss is defined as \u00b5 times the number of incorrectly segmented characters (Cai and Zhao, 2016). However, according to (Huang et al., 2012), standard parameter updating cannot guarantee convergence in the event of an inaccurate search. Therefore, we additionally consider two strategies as the following. Early update This strategy, proposed in (Collins and Roark, 2004), can be simplified in \"update once the golden answer.\" In our case, if the relevant character prefix can be correctly segmented, but the correct one falls off the bar, an update operation is performed and the remaining part is ignored. One disadvantage of the early update is that the search can never reach the end of a training instance, meaning that the remaining part of the instance is \"wasted.\" Otherwise, the 2005 LaSO'Method (Su'O) and III will continue."}, {"heading": "4 Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Datasets and Settings", "text": "We conduct experiments with two popular benchmark datasets, PKU and MSR, based on the second international Chinese word segmentation Bakeoff (Emerson, 2005) (Bakeoff-2005). Data statistics are in Table 1.During this work, we use the same model setting as in Table 2. These numbers are matched to development sets. 3 We follow (Dyer et al., 2015) to train model parameters. In epoch t, the learning rate is set as \u03b7t = 0.2 / (1 + \u03b3t), with \u03b3 = 0.1 for PKU datasets and \u03b3 = 0.2 for MSR datasets. Character embedding is either randomly initialized or pre-trained by word2vec (Mikolov et al., 2013) toolkit on Chinese Wikipedia corpus (indicated by + Pre-Train tables), while word embedding is always randomly initialized."}, {"heading": "4.2 Model Analysis", "text": "To our surprise, the change in beam size has little impact on performance, because the simple incremental greedy search achieves almost the best performance, suggesting that word segmentation can be greedily solvable at the word level. It may be because the model is currently optimal. 3The other experiments will therefore only evaluate the results of our greedy segmentation table.Comparing the different update methods Table 3 compares the three training strategies in question. We find that early updates lead to faster convergence and slightly better performance both at the character level (Ma and Hinrichs, 2015) and at the standard as well as at the LaSO level. Character composition versus word embedding under Section 3.1, the direct use of word embedding results in rapid convergence and less effect of words, which we initially find in comparison to standard and LaSO classification."}, {"heading": "4.3 Main Results", "text": "Table 4 compares our final results (greedy search is determined by setting k = 1) with previous neural models; embedding characters before training on a large, unlabeled corpus (not limited to the training corpus) has proven helpful for additional performance improvement; the results with or without pre-trained character embedding are listed separately to follow the strict closed test environment of SIGHAN Bakeoff, which allows no linguistic resource other than the training corpus; and we present the current results in (Zhao and Kit, 2008b) traditional methods; the comparison shows that our neural word segmentator outperforms all state-of-the-art neural systems with much lower computing costs; and finally, we present the results on all four Bakeoff 2005 datasets compared to (Zhao and Kit, 2008c) in Table 5. Note (Zhao and Kit, 2005 8c) compared with the Zhao, 2008c) datasets used in the training, 2008V, and 2008V datasets (all)."}, {"heading": "5 Conclusion", "text": "In this paper, we introduced a fast and precise word segmentator that uses neural networks. Our experiments show a significant improvement over existing state-of-the-art neural models by adopting the following key model refinements. (1) A novel mechanism for generating word representations between letters and words. (2) A more efficient model for character composition by dropping unnecessary designs. (3) Early updating strategies during maximum margin training. (4) With the above modifications, we discover that bar size has little impact on performance. In fact, greedy searching achieves very high accuracy. These improvements in both neural models and linguistic motivation make our model easier, faster and more accurate."}], "references": [{"title": "A hybrid markov/semi-markov conditional random field for sequence segmentation", "author": ["Galen Andrew."], "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing. Sydney, Australia, pages 465\u2013472.", "citeRegEx": "Andrew.,? 2006", "shortCiteRegEx": "Andrew.", "year": 2006}, {"title": "A neural probabilistic language model", "author": ["Yoshua Bengio", "R\u00e9jean Ducharme", "Pascal Vincent", "Christian Janvin."], "venue": "The Journal of Machine Learning Research 3:1137\u20131155.", "citeRegEx": "Bengio et al\\.,? 2003", "shortCiteRegEx": "Bengio et al\\.", "year": 2003}, {"title": "Neural word segmentation learning for Chinese", "author": ["Deng Cai", "Hai Zhao."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Berlin, Germany, pages 409\u2013420.", "citeRegEx": "Cai and Zhao.,? 2016", "shortCiteRegEx": "Cai and Zhao.", "year": 2016}, {"title": "Gated recursive neural network for Chinese word segmentation", "author": ["Xinchi Chen", "Xipeng Qiu", "Chenxi Zhu", "Xuanjing Huang."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint", "citeRegEx": "Chen et al\\.,? 2015a", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Long short-term memory neural networks for Chinese word segmentation", "author": ["Xinchi Chen", "Xipeng Qiu", "Chenxi Zhu", "Pengfei Liu", "Xuanjing Huang."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Lisbon,", "citeRegEx": "Chen et al\\.,? 2015b", "shortCiteRegEx": "Chen et al\\.", "year": 2015}, {"title": "Incremental parsing with the perceptron algorithm", "author": ["Michael Collins", "Brian Roark."], "venue": "Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Main Volume. Barcelona, Spain, pages 111\u2013118.", "citeRegEx": "Collins and Roark.,? 2004", "shortCiteRegEx": "Collins and Roark.", "year": 2004}, {"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "The Journal of Machine Learning Research 12:2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "Learning as search optimization: Approximate large margin methods for structured prediction", "author": ["Hal Daum\u00e9 III", "Daniel Marcu."], "venue": "Proceedings of the 22nd international conference on Machine learning. Bonn, Germany, pages 169\u2013176.", "citeRegEx": "III and Marcu.,? 2005", "shortCiteRegEx": "III and Marcu.", "year": 2005}, {"title": "Transitionbased dependency parsing with stack long shortterm memory", "author": ["Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Lin-", "citeRegEx": "Dyer et al\\.,? 2015", "shortCiteRegEx": "Dyer et al\\.", "year": 2015}, {"title": "The second international Chinese word segmentation bakeoff", "author": ["Thomas Emerson."], "venue": "Proceedings of the fourth SIGHAN workshop on Chinese language Processing. Jeju Island, Korea, pages 123\u2013133.", "citeRegEx": "Emerson.,? 2005", "shortCiteRegEx": "Emerson.", "year": 2005}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Which is essential for Chinese word segmentation: Character versus word", "author": ["Chang-Ning Huang", "Hai Zhao."], "venue": "The 20th Pacific Asia Conference on Language, Information and Computation. Wuhan, China, pages 1\u201312.", "citeRegEx": "Huang and Zhao.,? 2006", "shortCiteRegEx": "Huang and Zhao.", "year": 2006}, {"title": "Chinese word segmentation: A decade review", "author": ["Changning Huang", "Hai Zhao."], "venue": "Journal of Chinese Information Processing 21(3):8\u201320.", "citeRegEx": "Huang and Zhao.,? 2007", "shortCiteRegEx": "Huang and Zhao.", "year": 2007}, {"title": "Structured perceptron with inexact search", "author": ["Liang Huang", "Suphan Fayong", "Yang Guo."], "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.", "citeRegEx": "Huang et al\\.,? 2012", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data", "author": ["John Lafferty", "Andrew McCallum", "Fernando CN Pereira."], "venue": "Proceedings of the Eighteenth Interntional Conference on Machine Learning. San", "citeRegEx": "Lafferty et al\\.,? 2001", "shortCiteRegEx": "Lafferty et al\\.", "year": 2001}, {"title": "Exploring segment representations for neural segmentation models", "author": ["Yijia Liu", "Wanxiang Che", "Jiang Guo", "Bing Qin", "Ting Liu."], "venue": "Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence. New York, USA, pages 2880\u2013", "citeRegEx": "Liu et al\\.,? 2016", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "A maximum entropy approach to Chinese word segmentation", "author": ["Jin Kiat Low", "Hwee Tou Ng", "Wenyuan Guo."], "venue": "Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing. Jeju Island, Korea, pages 448\u2013455.", "citeRegEx": "Low et al\\.,? 2005", "shortCiteRegEx": "Low et al\\.", "year": 2005}, {"title": "Accurate linear-time Chinese word segmentation via embedding matching", "author": ["Jianqiang Ma", "Erhard Hinrichs."], "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference", "citeRegEx": "Ma and Hinrichs.,? 2015", "shortCiteRegEx": "Ma and Hinrichs.", "year": 2015}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781 .", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Dynet: The dynamic neural network toolkit", "author": ["Lingpeng Kong", "Adhiguna Kuncoro", "Gaurav Kumar", "Chaitanya Malaviya", "Paul Michel", "Yusuke Oda", "Matthew Richardson", "Naomi Saphra", "Swabha Swayamdipta", "Pengcheng Yin."], "venue": "arXiv preprint", "citeRegEx": "Kong et al\\.,? 2017", "shortCiteRegEx": "Kong et al\\.", "year": 2017}, {"title": "Maxmargin tensor neural network for Chinese word segmentation", "author": ["Wenzhe Pei", "Tao Ge", "Baobao Chang."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Baltimore, Maryland,", "citeRegEx": "Pei et al\\.,? 2014", "shortCiteRegEx": "Pei et al\\.", "year": 2014}, {"title": "Chinese segmentation and new word detection using conditional random fields", "author": ["Fuchun Peng", "Fangfang Feng", "Andrew McCallum."], "venue": "Proceedings of the 20th international conference on Computational Linguistics. Geneva, Switzerland, pages", "citeRegEx": "Peng et al\\.,? 2004", "shortCiteRegEx": "Peng et al\\.", "year": 2004}, {"title": "Deep learning for character-based information extraction", "author": ["Yanjun Qi", "Sujatha G Das", "Ronan Collobert", "Jason Weston."], "venue": "Advances in Information Retrieval, pages 668\u2013674.", "citeRegEx": "Qi et al\\.,? 2014", "shortCiteRegEx": "Qi et al\\.", "year": 2014}, {"title": "Word-based and character-based word segmentation models: Comparison and combination", "author": ["Weiwei Sun."], "venue": "Proceedings of the 23rd International Conference on Computational Linguistics. Beijing, China, pages 1211\u20131219.", "citeRegEx": "Sun.,? 2010", "shortCiteRegEx": "Sun.", "year": 2010}, {"title": "Fast online training with frequency-adaptive learning rates for Chinese word segmentation and new word detection", "author": ["Xu Sun", "Houfeng Wang", "Wenjie Li."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics. Jeju", "citeRegEx": "Sun et al\\.,? 2012", "shortCiteRegEx": "Sun et al\\.", "year": 2012}, {"title": "LSTM neural networks for language modeling", "author": ["Martin Sundermeyer", "Ralf Schl\u00fcter", "Hermann Ney."], "venue": "13th Annual Conference of the International Speech Communication Association. Portland, Oregon, USA, pages 194\u2013197.", "citeRegEx": "Sundermeyer et al\\.,? 2012", "shortCiteRegEx": "Sundermeyer et al\\.", "year": 2012}, {"title": "Learning structured prediction models: A large margin approach", "author": ["Ben Taskar", "Vassil Chatalbashev", "Daphne Koller", "Carlos Guestrin."], "venue": "Proceedings of the 22nd international conference on Machine learning. Bonn, Germany, pages 896\u2013903.", "citeRegEx": "Taskar et al\\.,? 2005", "shortCiteRegEx": "Taskar et al\\.", "year": 2005}, {"title": "A conditional random field word segmenter for SIGHAN bakeoff 2005", "author": ["Huihsin Tseng", "Pichuan Chang", "Galen Andrew", "Daniel Jurafsky", "Christopher Manning."], "venue": "Proceedings of the fourth SIGHAN workshop on Chinese language Processing. Jeju Is-", "citeRegEx": "Tseng et al\\.,? 2005", "shortCiteRegEx": "Tseng et al\\.", "year": 2005}, {"title": "Two knives cut better than one: Chinese word segmentation with dual decomposition", "author": ["Mengqiu Wang", "Rob Voigt", "Christopher D. Manning."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume", "citeRegEx": "Wang et al\\.,? 2014", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "Dependency-based gated recursive neural network for Chinese word segmentation", "author": ["Jingjing Xu", "Xu Sun."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Berlin, Germany,", "citeRegEx": "Xu and Sun.,? 2016", "shortCiteRegEx": "Xu and Sun.", "year": 2016}, {"title": "Chinese word segmentation as character tagging", "author": ["Nianwen Xue."], "venue": "Computational Linguistics and Chinese Language Processing 8(1):29\u201348.", "citeRegEx": "Xue.,? 2003", "shortCiteRegEx": "Xue.", "year": 2003}, {"title": "Graph-based semi-supervised model for joint Chinese word segmentation and partof-speech tagging", "author": ["Xiaodong Zeng", "Derek F. Wong", "Lidia S. Chao", "Isabel Trancoso."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational", "citeRegEx": "Zeng et al\\.,? 2013", "shortCiteRegEx": "Zeng et al\\.", "year": 2013}, {"title": "Exploring representations from unlabeled data with co-training for Chinese word segmentation", "author": ["Longkai Zhang", "Houfeng Wang", "Xu Sun", "Mairgup Mansur."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Pro-", "citeRegEx": "Zhang et al\\.,? 2013", "shortCiteRegEx": "Zhang et al\\.", "year": 2013}, {"title": "Transition-based neural word segmentation", "author": ["Meishan Zhang", "Yue Zhang", "Guohong Fu."], "venue": "Proceedings of the 54nd Annual Meeting of the Association for Computational Linguistics. Berlin, Germany, pages 421\u2013431.", "citeRegEx": "Zhang et al\\.,? 2016", "shortCiteRegEx": "Zhang et al\\.", "year": 2016}, {"title": "Chinese segmentation with a word-based perceptron algorithm", "author": ["Yue Zhang", "Stephen Clark."], "venue": "Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. Prague, Czech Republic, pages 840\u2013847.", "citeRegEx": "Zhang and Clark.,? 2007", "shortCiteRegEx": "Zhang and Clark.", "year": 2007}, {"title": "Syntactic processing using the generalized perceptron and beam search", "author": ["Yue Zhang", "Stephen Clark."], "venue": "Computational linguistics 37(1):105\u2013151.", "citeRegEx": "Zhang and Clark.,? 2011", "shortCiteRegEx": "Zhang and Clark.", "year": 2011}, {"title": "A hybrid model for Chinese spelling check", "author": ["Hai Zhao", "Deng Cai", "Yang Xin", "Wang Yuzhu", "Zhongye Jia."], "venue": "ACM Transactions on Asian and Low-Resource Language Information Processing 16(3).", "citeRegEx": "Zhao et al\\.,? 2017", "shortCiteRegEx": "Zhao et al\\.", "year": 2017}, {"title": "Effective tag set selection in Chinese word segmentation via conditional random field modeling", "author": ["Hai Zhao", "Chang-Ning Huang", "Mu Li", "Bao-Liang Lu."], "venue": "The 20th Pacific Asia Conference on Language, Information and Computation. Wuhan,", "citeRegEx": "Zhao et al\\.,? 2006", "shortCiteRegEx": "Zhao et al\\.", "year": 2006}, {"title": "A unified character-based tagging framework for Chinese word segmentation", "author": ["Hai Zhao", "Chang-Ning Huang", "Mu Li", "Bao-Liang Lu."], "venue": "ACM Transactions on Asian Language Information Processing 16(21).", "citeRegEx": "Zhao et al\\.,? 2010", "shortCiteRegEx": "Zhao et al\\.", "year": 2010}, {"title": "An empirical comparison of goodness measures for unsupervised Chinese word segmentation with a unified framework", "author": ["Hai Zhao", "Chunyu Kit."], "venue": "Proceedings of the Third International Joint Conference on Natural Language Processing. Hyder-", "citeRegEx": "Zhao and Kit.,? 2008a", "shortCiteRegEx": "Zhao and Kit.", "year": 2008}, {"title": "Exploiting unlabeled text with different unsupervised segmentation criteria for Chinese word segmentation", "author": ["Hai Zhao", "Chunyu Kit."], "venue": "Research in Computing Science 33:93\u2013104.", "citeRegEx": "Zhao and Kit.,? 2008b", "shortCiteRegEx": "Zhao and Kit.", "year": 2008}, {"title": "Unsupervised segmentation helps supervised learning of character tagging for word segmentation and named entity recognition", "author": ["Hai Zhao", "Chunyu Kit."], "venue": "The Sixth SIGHAN Workshop on Chinese Language Processing. Hyderabad, India,", "citeRegEx": "Zhao and Kit.,? 2008c", "shortCiteRegEx": "Zhao and Kit.", "year": 2008}, {"title": "Integrating unsupervised and supervised word segmentation", "author": ["Hai Zhao", "Chunyu Kit"], "venue": null, "citeRegEx": "Zhao and Kit.,? \\Q2011\\E", "shortCiteRegEx": "Zhao and Kit.", "year": 2011}, {"title": "Deep learning for Chinese word segmentation and POS tagging", "author": ["Xiaoqing Zheng", "Hanyang Chen", "Tianyu Xu."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Seattle, Washington, USA, pages 647\u2013", "citeRegEx": "Zheng et al\\.,? 2013", "shortCiteRegEx": "Zheng et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 36, "context": ", (Zhao et al., 2017).", "startOffset": 2, "endOffset": 21}, {"referenceID": 30, "context": "Since (Xue, 2003), most methods formalize this task as a sequence labeling problem.", "startOffset": 6, "endOffset": 17}, {"referenceID": 16, "context": "In a supervised learning fashion, sequence labeling may adopt various models such as Maximum Entropy (ME) (Low et al., 2005) and Conditional Random Fields (CRF) (Lafferty et al.", "startOffset": 106, "endOffset": 124}, {"referenceID": 14, "context": ", 2005) and Conditional Random Fields (CRF) (Lafferty et al., 2001; Peng et al., 2004).", "startOffset": 44, "endOffset": 86}, {"referenceID": 21, "context": ", 2005) and Conditional Random Fields (CRF) (Lafferty et al., 2001; Peng et al., 2004).", "startOffset": 44, "endOffset": 86}, {"referenceID": 6, "context": "(2013) first adapted the sliding-window based sequence labeling (Collobert et al., 2011) with character embeddings", "startOffset": 64, "endOffset": 88}, {"referenceID": 13, "context": ", 2005) and Conditional Random Fields (CRF) (Lafferty et al., 2001; Peng et al., 2004). However, these models rely heavily on hand-crafted features. \u2217Corresponding author. This paper was partially supported by Cai Yuanpei Program (CSC No. 201304490199 and No. 201304490171), National Natural Science Foundation of China (No. 61170114, No. 61672343 and No. 61272248), National Basic Research Program of China (No. 2013CB329401), Major Basic Research Program of Shanghai Science and Technology Committee (No. 15JC1400103), Art and Science Interdisciplinary Funds of Shanghai Jiao Tong University (No. 14JCRZ04), Key Project of National Society Science Foundation of China (No. 15-ZDA041), and the joint research project with Youtu Lab of Tencent. To minimize the efforts in feature engineering, neural word segmentation has been actively studied recently. Zheng et al. (2013) first adapted the sliding-window based sequence labeling (Collobert et al.", "startOffset": 45, "endOffset": 874}, {"referenceID": 43, "context": "A number of other researchers have attempted to improve the segmenter of (Zheng et al., 2013) by augmenting it with additional complexity.", "startOffset": 73, "endOffset": 93}, {"referenceID": 18, "context": "Pei et al. (2014) introduced tag embeddings.", "startOffset": 0, "endOffset": 18}, {"referenceID": 3, "context": "Chen et al. (2015a) proposed to model n-", "startOffset": 0, "endOffset": 20}, {"referenceID": 10, "context": "(2015b) used a Long shortterm memory network (LSTM) (Hochreiter and Schmidhuber, 1997) to capture long-distance context.", "startOffset": 52, "endOffset": 86}, {"referenceID": 3, "context": "Chen et al. (2015b) used a Long shortterm memory network (LSTM) (Hochreiter and Schmidhuber, 1997) to capture long-distance context.", "startOffset": 0, "endOffset": 20}, {"referenceID": 3, "context": "Chen et al. (2015b) used a Long shortterm memory network (LSTM) (Hochreiter and Schmidhuber, 1997) to capture long-distance context. Xu and Sun (2016) integrated both GRNN", "startOffset": 0, "endOffset": 151}, {"referenceID": 30, "context": "Besides sequence labeling schemes, Zhang et al. (2016) proposed a transition-based framework.", "startOffset": 35, "endOffset": 55}, {"referenceID": 14, "context": "Liu et al. (2016) used a zero-order semiCRF based model.", "startOffset": 0, "endOffset": 18}, {"referenceID": 2, "context": "Most closely related to this work, Cai and Zhao (2016) proposed to score candidate segmented outputs directly, employing a gated combination neural network over characters for word representation generation and an LSTM scoring model for segmentation result evaluation.", "startOffset": 35, "endOffset": 55}, {"referenceID": 12, "context": "Statistical Chinese word segmentation has been studied for decades (Huang and Zhao, 2007).", "startOffset": 67, "endOffset": 89}, {"referenceID": 30, "context": "(Xue, 2003) was the first to cast it as a characterbased tagging problem.", "startOffset": 0, "endOffset": 11}, {"referenceID": 27, "context": "This method has been followed by most later segmenters (Tseng et al., 2005; Zhao et al., 2006; Zhao and Kit, 2008c; Zhao et al., 2010; Sun et al., 2012; Zhang et al., 2013).", "startOffset": 55, "endOffset": 172}, {"referenceID": 37, "context": "This method has been followed by most later segmenters (Tseng et al., 2005; Zhao et al., 2006; Zhao and Kit, 2008c; Zhao et al., 2010; Sun et al., 2012; Zhang et al., 2013).", "startOffset": 55, "endOffset": 172}, {"referenceID": 41, "context": "This method has been followed by most later segmenters (Tseng et al., 2005; Zhao et al., 2006; Zhao and Kit, 2008c; Zhao et al., 2010; Sun et al., 2012; Zhang et al., 2013).", "startOffset": 55, "endOffset": 172}, {"referenceID": 38, "context": "This method has been followed by most later segmenters (Tseng et al., 2005; Zhao et al., 2006; Zhao and Kit, 2008c; Zhao et al., 2010; Sun et al., 2012; Zhang et al., 2013).", "startOffset": 55, "endOffset": 172}, {"referenceID": 24, "context": "This method has been followed by most later segmenters (Tseng et al., 2005; Zhao et al., 2006; Zhao and Kit, 2008c; Zhao et al., 2010; Sun et al., 2012; Zhang et al., 2013).", "startOffset": 55, "endOffset": 172}, {"referenceID": 32, "context": "This method has been followed by most later segmenters (Tseng et al., 2005; Zhao et al., 2006; Zhao and Kit, 2008c; Zhao et al., 2010; Sun et al., 2012; Zhang et al., 2013).", "startOffset": 55, "endOffset": 172}, {"referenceID": 11, "context": "Statistical Chinese word segmentation has been studied for decades (Huang and Zhao, 2007). (Xue, 2003) was the first to cast it as a characterbased tagging problem. Peng et al. (2004) showed CRF based model is particularly effective to solve CWS in the sequence labeling fashion.", "startOffset": 68, "endOffset": 184}, {"referenceID": 0, "context": "Andrew (2006) proposed a semi-CRF model.", "startOffset": 0, "endOffset": 14}, {"referenceID": 15, "context": "Both of them have been followed by neural model versions (Liu et al., 2016) and (Zhang et al.", "startOffset": 57, "endOffset": 75}, {"referenceID": 33, "context": ", 2016) and (Zhang et al., 2016) respectively.", "startOffset": 12, "endOffset": 32}, {"referenceID": 11, "context": "and word-based segmenters (Huang and Zhao, 2006; Sun, 2010; Wang et al., 2014) and semisupervised learning (Zhao and Kit, 2008b, 2011; Zeng et al.", "startOffset": 26, "endOffset": 78}, {"referenceID": 23, "context": "and word-based segmenters (Huang and Zhao, 2006; Sun, 2010; Wang et al., 2014) and semisupervised learning (Zhao and Kit, 2008b, 2011; Zeng et al.", "startOffset": 26, "endOffset": 78}, {"referenceID": 28, "context": "and word-based segmenters (Huang and Zhao, 2006; Sun, 2010; Wang et al., 2014) and semisupervised learning (Zhao and Kit, 2008b, 2011; Zeng et al.", "startOffset": 26, "endOffset": 78}, {"referenceID": 31, "context": ", 2014) and semisupervised learning (Zhao and Kit, 2008b, 2011; Zeng et al., 2013; Zhang et al., 2013).", "startOffset": 36, "endOffset": 102}, {"referenceID": 32, "context": ", 2014) and semisupervised learning (Zhao and Kit, 2008b, 2011; Zeng et al., 2013; Zhang et al., 2013).", "startOffset": 36, "endOffset": 102}, {"referenceID": 2, "context": "Unlike most previous works, which extract features within a fixed sized sliding window, Cai and Zhao (2016) proposed a direct segmentation framework that extends the feature window to cover complete input and segmentation history and uses beam search for decoding.", "startOffset": 88, "endOffset": 108}, {"referenceID": 17, "context": "Another notable exception of embedding based methods is (Ma and Hinrichs, 2015), which used character-specified tags matching for fast decoding and resulted in a character-based greedy segmenter.", "startOffset": 56, "endOffset": 79}, {"referenceID": 1, "context": "The most straightforward solution is to use a lookup table for word vectors (Bengio et al., 2003).", "startOffset": 76, "endOffset": 97}, {"referenceID": 2, "context": "Figure 2: The difference between (Cai and Zhao, 2016) (left) and our model (right).", "startOffset": 33, "endOffset": 53}, {"referenceID": 2, "context": "In contrast, the model in (Cai and Zhao, 2016) further combined COMP(\u00b7) and character embeddings ci via an update gate z (As in Figure 2), which has been shown helpless to the performance but requires huge computational cost according to our empirical study.", "startOffset": 26, "endOffset": 46}, {"referenceID": 25, "context": "Linking To capture word interactions within a word sequence, the resulted word vectors are then linked sequentially via an LSTM (Sundermeyer et al., 2012).", "startOffset": 128, "endOffset": 154}, {"referenceID": 26, "context": "ods (Taskar et al., 2005) where the structured margin loss is defined as \u03bc times the number of incorrectly segmented characters (Cai and Zhao, 2016).", "startOffset": 4, "endOffset": 25}, {"referenceID": 2, "context": ", 2005) where the structured margin loss is defined as \u03bc times the number of incorrectly segmented characters (Cai and Zhao, 2016).", "startOffset": 110, "endOffset": 130}, {"referenceID": 13, "context": "However, according to (Huang et al., 2012), standard parameter update cannot guarantee conver-", "startOffset": 22, "endOffset": 42}, {"referenceID": 5, "context": "Early update This strategy proposed in (Collins and Roark, 2004) can be simplified into \u201cupdate once the golden answer is unreachable\u201d.", "startOffset": 39, "endOffset": 64}, {"referenceID": 9, "context": "We conduct experiments on two popular benchmark datasets, namely PKU and MSR, from the second international Chinese word segmentation bakeoff (Emerson, 2005) (Bakeoff-2005).", "startOffset": 142, "endOffset": 157}, {"referenceID": 8, "context": "3 We follow (Dyer et al., 2015) to train model parameters.", "startOffset": 12, "endOffset": 31}, {"referenceID": 18, "context": "are either randomly initialized or pre-trained by word2vec (Mikolov et al., 2013) toolkit on Chinese Wikipedia corpus (which will be indicated by +pre-train in tables.", "startOffset": 59, "endOffset": 81}, {"referenceID": 17, "context": "In fact, similar phenomenon was observed at character-level (Ma and Hinrichs, 2015).", "startOffset": 60, "endOffset": 83}, {"referenceID": 41, "context": ") (Zhao and Kit, 2008c) 95.", "startOffset": 2, "endOffset": 23}, {"referenceID": 3, "context": "6 (Chen et al., 2015a) 94.", "startOffset": 2, "endOffset": 22}, {"referenceID": 4, "context": "1* 100 120 (Chen et al., 2015b) 94.", "startOffset": 11, "endOffset": 31}, {"referenceID": 17, "context": "0* 117 120 (Ma and Hinrichs, 2015) 95.", "startOffset": 11, "endOffset": 34}, {"referenceID": 33, "context": "6 3 28 (Zhang et al., 2016) 95.", "startOffset": 7, "endOffset": 27}, {"referenceID": 15, "context": "0 - 13 125 (Liu et al., 2016) 93.", "startOffset": 11, "endOffset": 29}, {"referenceID": 2, "context": "21 (Cai and Zhao, 2016) 95.", "startOffset": 3, "endOffset": 23}, {"referenceID": 2, "context": "Results with * are from (Cai and Zhao, 2016).", "startOffset": 24, "endOffset": 44}, {"referenceID": 40, "context": "We also show the state-of-the-art results in (Zhao and Kit, 2008b) of traditional methods.", "startOffset": 45, "endOffset": 66}, {"referenceID": 41, "context": "Finally, we present the results on all four Bakeoff-2005 datasets compared to (Zhao and Kit, 2008c) in Table 5.", "startOffset": 78, "endOffset": 99}, {"referenceID": 41, "context": "Note (Zhao and Kit, 2008c) used AV features, which are derived from global", "startOffset": 5, "endOffset": 26}, {"referenceID": 33, "context": "To distinguish the performance improvement from model optimization, we especially list the results of standalone neural models in (Zhang et al., 2016) and (Liu et al.", "startOffset": 130, "endOffset": 150}, {"referenceID": 15, "context": ", 2016) and (Liu et al., 2016).", "startOffset": 12, "endOffset": 30}, {"referenceID": 33, "context": "All the running time results are from our runs of released implementations on a single CPU (Intel i7-5960X) with two threads only, except for those of (Zhang et al., 2016) which are from personal communication.", "startOffset": 151, "endOffset": 171}, {"referenceID": 29, "context": "The results of (Xu and Sun, 2016) are not listed due to their use of external Chinese idiom dictionary.", "startOffset": 15, "endOffset": 33}, {"referenceID": 41, "context": "Models PKU MSR CityU AS (Zhao and Kit, 2008c) 95.", "startOffset": 24, "endOffset": 45}, {"referenceID": 39, "context": "way of unsupervised segmentation (Zhao and Kit, 2008a), for performance enhancement.", "startOffset": 33, "endOffset": 54}, {"referenceID": 20, "context": "To our knowledge, none of previous neural models has ever performed a complete evaluation over all four segmentation corpora of Bakeoff-2005, in which only two, PKU and MSR, are used since (Pei et al., 2014).", "startOffset": 189, "endOffset": 207}], "year": 2017, "abstractText": "Neural models with minimal feature engineering have achieved competitive performance against traditional methods for the task of Chinese word segmentation. However, both training and working procedures of the current neural models are computationally inefficient. This paper presents a greedy neural word segmenter with balanced word and character embedding inputs to alleviate the existing drawbacks. Our segmenter is truly end-toend, capable of performing segmentation much faster and even more accurate than state-of-the-art neural models on Chinese benchmark datasets.", "creator": "LaTeX with hyperref package"}}}