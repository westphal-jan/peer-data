{"id": "1704.07130", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Apr-2017", "title": "Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings", "abstract": "We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.", "histories": [["v1", "Mon, 24 Apr 2017 10:38:24 GMT  (1204kb,D)", "http://arxiv.org/abs/1704.07130v1", "ACL 2017"]], "COMMENTS": "ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["he he", "anusha balakrishnan", "mihail eric", "percy liang"], "accepted": true, "id": "1704.07130"}, "pdf": {"name": "1704.07130.pdf", "metadata": {"source": "CRF", "title": "Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings", "authors": ["He He", "Anusha Balakrishnan"], "emails": ["hehe@cs.stanford.edu", "anusha28@cs.stanford.edu", "meric@cs.stanford.edu", "pliang@cs.stanford.edu"], "sections": [{"heading": "1 Introduction", "text": "Most of us have a pre-defined dialogue status (e.g., slots such as type of food and price range for a restaurant search task) and a fixed set of dialogue acts (e.g., request, information). However, human conversation often requires richer states of dialogue and more nuanced, pragmatic dialogue activities. The newer, open dialogue systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2017; Mei et al., 2017) learn directly from previous statements on the next aspects of dialogue. While these models capture open aspects of dialogue, the lack of structured dialogue prevents them from being applied directly to settings that require linking to structured knowledge."}, {"heading": "2 Symmetric Collaborative Dialogue", "text": "We start with the introduction of a collaborative task between two actors and describe the process of capturing human-human dialogue. We show that our data exhibit a variety of interesting linguistic phenomena. 1The data set is publicly available at https: / / stanfordnlp.github.io / cocoa /."}, {"heading": "2.1 Task Definition", "text": "In the symmetrical dialog, there are two agents, A and B, who each have a private knowledge base - KBA and KBB, respectively. Each knowledge base contains a list of elements in which each element has a value for each attribute. In the MutualFriends setting, for example, elements are friends, and attributes are name, school, etc. There is a common element that A and B both have; their goal is to talk to each other in order to determine and select the common element. Formally, an agent is a mapping of his private KB and the previous dialogue (sequence of statements) to the next statement that is generated or selected. A dialogue is considered successful if both agents select the common element correctly. This setting shows parallels in the human-computer collaboration in which each agent has complementary expertise."}, {"heading": "2.2 Data collection", "text": "To determine linguistic and strategic variants, we create a random scenario for each task by varying the number of elements (5 to 12), the number of attributes (3 or 4), and the distribution of values for each attribute (distorted by uniform). Details of the scheme and scenario generation can be found in Appendix A and B. We have crowdsourced dialogues through AMT by randomly assembling workers within 5 minutes to complete the task. 2 Our chat interface is shown in Figure 2. To discourage random guesses, we prevent workers from selecting more than once every 10 seconds. Our task was very popular and we col-2When workers exceed the deadline, the dialogue is marked as unsuccessful (but still logged)."}, {"heading": "2.3 Dataset statistics", "text": "We show the basic statistics of our dataset in Table 3. An expression is defined as a message sent by one of the agents. The average length of the utterance is short due to the informality of the chat, but an agent usually sends several utterances in one turn. Some sample dialogues are shown in Table 6 and Appendix I. We categorize utterances in rough types - inform, ask, answer, greet, excuse - by pattern matching (Appendix E.) There are 7.4% multi-typical utterances, and 30.9% utterances contain more than one unit. In Table 1 we show example utterances with rich semantics that cannot be adequately represented by traditional slot values. 3tasks are put in sequence; the total time excludes intervals between Ivans. 4Entity names are replaced by their entity types. Some of the standard utterances are also not trivial due to correspondence and logical composition."}, {"heading": "3 Dynamic Knowledge Graph Network", "text": "The diverse semantics in our data motivates us to combine the unstructured representation of dialog history with structured knowledge.Our goal is to model human behavior in such a way that we do not discuss the optimal strategy here. The model consists of three components shown in Figure 3: (i) a dynamic knowledge graph that represents the agent's private KB and shared dialogue history as a graph (Section 3.1), (ii) a graph embedded across the nodes (Section 3.2), and (iii) an expression generator (Section 3.3).The knowledge graph represents units and relationships in the agent's private KBK, e.g. Item-1 google. As the conversation unfolds, utterances are embedded and embedded in node embeddings of aforementioned entities. In Figure 3, for example, each column \"went to\" the column to update the embedding of the column."}, {"heading": "3.1 Knowledge Graph", "text": "In a dialog of T expressions, we construct graph (Gt) Tt = 1 above the KB and dialog history for Agent A.6. There are three types of nodes: item nodes, attribute nodes, and entity nodes. Edges between nodes represent their relationships. For example, (Item-1, hasSchool, Colombia) means that the first element has attribute school, the values of which 6 It is important to differentiate the perspectives of the two agents because they have different KBs. Then, we assume the perspective of Agent A, i.e., we only access KBA for A and point to B as a partner. An example diagram is shown in Figure 3. The graph Gt is updated based on expression t by taking Gt \u2212 1 and adding a new node for each entity mentioned in expression t but not in KBA.7."}, {"heading": "3.2 Graph Embedding", "text": "The question we have asked ourselves is whether we are able to represent this type of information as a feature vector vector vector Ft (v), which represents the degree and type (item, attribute or entity) of the node v, and whether it is mentioned in the current inversion. Each function is represented as a uniform vector vector vector Ft (v), which represents the degree and type (item, attribute or entity) of the node v, and whether it is mentioned in the current inversion."}, {"heading": "3.3 Utterance Embedding and Generation", "text": "We embed and generate expressions using Long Short Term Memory (LSTM) networks that embed the graph in accountability (V = 2016). On the other hand, we define the vocabulary (V = LSTMenc (ht, j \u2212 1, At (xt, j \u2212)), (4) where ht, 0 = ht \u2212 1, and At is an entity abstraction function explained below. The last hidden state ht, nt is used as an expression that updates the mention of vectors, as in Section 3.2.In our dialog task, the identity of an entity is unimportant. For example, replacing Google with an alphabet in Figure 1 should make little difference to conversation. Instead, the role of an entity is determined by its relationship to other entities and relevant expressions. We define the identity of an entity as unimportant."}, {"heading": "4 Experiments", "text": "We compare our model with a rules-based system and a basic neural model. Automatic as well as human evaluations are performed to test the models for fluidity, correctness, cooperation and similarity to humans. Results show that DynoNet is able to communicate with humans in a coherent and strategic way."}, {"heading": "4.1 Setup", "text": "We use a single-layer LSTM with 100 hidden units and 100-dimensional word vectors for both the encoder and the decoder (Section 3.3). Each successful dialog is turned into two examples, each from the perspective of one of the two agents. We maximize the log probability of all utterances in the dialogs. The parameters are optimized by AdaGrad (Duchi et al., 2010) with an initial learning rate of 0.5. We trained for at least 10 epochs; then the training stops if there is no improvement in the dev set for 5 epochs. By default, we perform K = 2 iterations of messages to calculate node embedding (Section 3.2). For decoding, we use the disk data distribution with a softmax temperature of 0.5,11 hypoparameters."}, {"heading": "4.2 Evaluation", "text": "In fact, most of them will be able to play by the rules they have imposed on themselves."}, {"heading": "4.3 Ablation Studies", "text": "Our model has two new designs: Entity abstraction and Message Delivery for Node Embedding. Table 7 shows what happens when we remove them. If the number of iterations of Message Delivery, K, is reduced from 2 to 0, the loss is steadily increasing. Removing the entity abstraction - i.e. adding entity embedding to Node Embedding and LSTM input embedding - also reduces performance. This shows that DynoNet benefits from context-defined structural node embedding rather than those based on a classic reference table."}, {"heading": "5 Discussion and Related Work", "text": "There is a recent increase in interest in these data systems, although no full dialogue system has been established, although progress is limited by the size of available datasets (Serban et al., 2015a). Most work focuses on information-gathering tasks that can be easily gathered as natural human conversations using Wizard-of-Oz data collection (Williams et al., 2016) or simulators (Bordes and Weston, 2017; Li et al., 2016d), but collaborative dialogues are easy to collect as natural human conversations and are also challenging enough given the large number of scenarios and different forms of conversation. There are some interesting strategic dialogue datasets - and modes of action of Catan (Afantenos et al., 2012) and the maps corpus (1.3K dialogues), as well as work on dialogue strategies (Keizer et al., 2017; Vogel et al.)."}, {"heading": "A Knowledge Base Schema", "text": "The setA attribute for the MutualFriends task contains name, school, major, company, hobby, daily time preference and location preference. Each attribute a has a set of possible values (units) Ea. For name, school, major, company and hobby, we have compiled a large number of values from various online sources.14 We used three possible values (morning, afternoon and evening) for the daily time preference and two possible values (indoor and outdoor) for location preference."}, {"heading": "B Scenario Generation", "text": "A scenario S is characterized by the number of items (NS), the attribute set (AS), the size of which is MS, and the values for each attribute in the two CBS. A scenario is generated as follows: 1. Sample NS and MS uniformly from {5,.., 12} and {3, 4}, respectively. 2. Generate AS from a random sample MS attributes from A.3. For each attribute, an AS is generated, sample of the concentration parameter \u03b1a uniformly from the set {0,3, 1, 3}. 4. Generate two CBS from a rich multinomic distribution over the value set Ea with the concentration parameter \u0430 by sampling NS values for each attribute. We repeat the last step until the two CBS have a unique common element."}, {"heading": "C Chat Interface", "text": "To capture the dialogue between people in real time, we set up a web server and redirect AMT employees to our website. Visitors are paired randomly upon arrival. For each pair, we select a random scenario and randomly assign a KB of 14 names: http: / / www.ssa.gov / oact / babynames / decades / century.html Schools: http: / / doors.stanford.edu / \u02dc sr / universities.html Majors: http: / / www.a2zcolleges.com / majors Companies: https: / / en.wikipedia.org / wiki / List _ of _ companies _ of _ the _ United _ States Hobbies: https: / / en.wikipedia.org / wiki / List _ majors Companies: https: / / en.wikipedia.org / wiki / List _ of _ United _ wiges.com / Majors / Companibkibbies: https / / en.wikikikipediaki / Hobbiemajors / List _ states / pedipedipedi.aki / majors Companies: https: / / en.wiki / en.wiki / List of _ United _ wibieges.com / majors / hobiepediaki _ companies / https / encryption / encryption / encryption / encryption / encryption / encryption / encryption."}, {"heading": "D Entity Linking and Realization", "text": "For each unit in the scheme, we calculate various variations of its canonical name, including acronyms, strings with a specific processing distance, prefixes, and morphological variants. Based on a span of text, we obtain a series of candidate entities by string matching. A heuristic marker then evaluates each candidate (e.g. considering whether the span is a subline of a candidate, the processing distance between the span and a candidate, etc.).The candidate with the highest score is returned. A connected entity is considered a single symbol and its surface shape is ignored in all models. At the time of generation, we realize an entity by selecting an entity from the empirical distribution of its surface shapes in the training set."}, {"heading": "E Utterance Categorization", "text": "We categorize statements in the form of information, questions, answers, greetings, apologies heuristically according to pattern matching. \u2022 A question utterance asks for information about the partner's KB. We recognize these statements by checking the presence of a \"?\" and / or a question word such as \"do,\" \"does,\" \"what,\" etc. \u2022 An answer utterance provides information about the agent's KB. We define them as statements that mention units in the KB and are not question utterances. \u2022 An answer utterance merely provides a positive / negative answer to a question that contains words such as \"yes,\" \"no,\" \"nope,\" etc. \u2022 A greeting utterance contains words such as \"hi\" or \"hello\"; it often occurs at the beginning of a dialogue. \u2022 An apology contains the word \"sorry,\" which is typically associated with corrections and incorrect selections.Examples of these expressions are Table 2 and Table 1."}, {"heading": "F Strategy", "text": "When creating the scenario, we varied the number of attributes, the number of items in each KB, and the distribution of values for each attribute. We found that as the number of items and / or attributes increased, so did the dialog length and completion time, indicating that the task became more difficult. We also assumed that variation in the value of \u03b1 would affect the overall strategy (e.g. the order in which attributes are mentioned), since \u03b1 controls the skew of the value distribution for an attribute. When we examined the data, we found that people tend to mention attributes with a skewed (i.e. less uniform) value distribution first. Specifically, we put the \u03b1 values of all attributes in a scenario (see step 3 in section B) and put them into three distribution groups - the least uniform, average, and most uniform attributes, according to the order in which higher \u03b1 values correspond to more uniform distributions."}, {"heading": "G Rule-based System", "text": "The rules-based bot performs the following actions: greeting, information or questions about a group of units, answering a question and selecting an item. The number of units to inform / ask is randomly selected based on the entity weight. First, each entity is weighted according to its number in KB. Then, we increase or decrease the weight of the units connected by the partner and its associated units (in the same row or column), depending on whether the mention is positive or negative. A negative mention contains words such as \"no,\" \"none,\" \"n't,\" etc. Likewise, each element has an initial weight of 1, which is updated depending on the mention of the partner about its attributes. If there is an element with a weight greater than 1, the bot selects the most highly weighted element with a probability of 0.3. If a question has been received, the bot informs the facts about the entities to question, e.g. \"someone went to Colombia?,\" \"I have selected 2 friends to put together the patterns of the column and the other."}, {"heading": "H Turn-taking Rules", "text": "In order to prevent the Bot from constantly generating statements and forming a monologue, we allow it to send at most one utterance if the utterance contains an entity, and otherwise two utterances. If it sends more than one utterance in a row, the Bot must wait between 1 and 2 seconds. Furthermore, after an utterance has been generated by the model (almost immediately), the Bot must record some time to simulate the input of messages before sending. We used a typing speed of 7 characters / sec and added an additional random delay of 0 to 1.5 seconds after \"typing.\" The rules are applied to all models."}, {"heading": "I Additional Human-Bot Dialogue", "text": "In Table 8 we show another group of human bot / human chats. In this scenario the distribution of values is more uniform than in Table 6. Nevertheless, we see that StanoNet and DynoNet have still learned to start from relatively high frequency units, they also appear more cooperative and mention relevant units in the dialog context compared to rule."}, {"heading": "J Histograms of Ratings from Human Evaluations", "text": "As these illustrations show, there are some obvious discrepancies between the ratings of agents chatting with the bot and those of an \"objective\" third party. These ratings provide some interesting insights into how dialogue participants perceive their partners in this task and what constitutes a \"human-like\" or \"fluent\" partner."}, {"heading": "K Example Comments from Partner and Third-party Evaluations", "text": "In Table 9, we show several pairs of human similarity ratings and comments for the same dialogue, both when evaluating a partner and when evaluating a third party. As an interlocutor, the interlocutor often judges from the perspective of collaboration and strategy, while the third party often relies more on linguistic features (e.g. length, spelling, formality).1 2 3 4 5 0102030405060P e rce n tag eFluencyHumanRuleStanoNetDynoNet1 2 3 4 5CorrectnessCooperationHuman-likeness1 2 3 4 5 010203040506070P e rce n tag eFluencyHumanRuleStanoNetDynoNet1 2 3 4 5CorrectnessCooperationHuman-likeness"}], "references": [{"title": "Developing a corpus of strategic conversation in the settlers of catan", "author": ["S. Afantenos", "N. Asher", "F. Benamara", "A. Cadilhac", "C. D\u00e9gremont", "P. Denis", "M. Guhe", "S. Keizer", "A. Lascarides", "O. Lemon", "P. Muller", "S. Paul", "V. Rieser", "L. Vieu."], "venue": "SeineDial 2012 -", "citeRegEx": "Afantenos et al\\.,? 2012", "shortCiteRegEx": "Afantenos et al\\.", "year": 2012}, {"title": "Frames: A corpus for adding memory to goaloriented dialogue systems", "author": ["L.E. Asri", "H. Schulz", "S. Sharma", "J. Zumer", "J. Harris", "E. Fine", "R. Mehrotra", "K. Suleman."], "venue": "Maluuba Technical Report .", "citeRegEx": "Asri et al\\.,? 2016", "shortCiteRegEx": "Asri et al\\.", "year": 2016}, {"title": "Neural machine translation by jointly learning to align and translate", "author": ["D. Bahdanau", "K. Cho", "Y. Bengio."], "venue": "International Conference on Learning Representations (ICLR).", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "Learning end-to-end goal-oriented dialog", "author": ["A. Bordes", "J. Weston."], "venue": "International Conference on Learning Representations (ICLR).", "citeRegEx": "Bordes and Weston.,? 2017", "shortCiteRegEx": "Bordes and Weston.", "year": 2017}, {"title": "End-to-end reinforcement learning of dialogue agents for information access", "author": ["B. Dhingra", "L. Li", "X. Li", "J. Gao", "Y. Chen", "F. Ahmed", "L. Deng."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Dhingra et al\\.,? 2017", "shortCiteRegEx": "Dhingra et al\\.", "year": 2017}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["J. Duchi", "E. Hazan", "Y. Singer."], "venue": "Conference on Learning Theory (COLT).", "citeRegEx": "Duchi et al\\.,? 2010", "shortCiteRegEx": "Duchi et al\\.", "year": 2010}, {"title": "Tracking the world state with recurrent entity networks", "author": ["M. Henaff", "J. Weston", "A. Szlam", "A. Bordes", "Y. LeCun."], "venue": "International Conference on Learning Representations (ICLR).", "citeRegEx": "Henaff et al\\.,? 2017", "shortCiteRegEx": "Henaff et al\\.", "year": 2017}, {"title": "Dialogue act tagging for instant messaging chat sessions", "author": ["E. Ivanovic."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Ivanovic.,? 2005", "shortCiteRegEx": "Ivanovic.", "year": 2005}, {"title": "Data recombination for neural semantic parsing", "author": ["R. Jia", "P. Liang."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Jia and Liang.,? 2016", "shortCiteRegEx": "Jia and Liang.", "year": 2016}, {"title": "Evaluating persuasion strategies and deep reinforcement learning methods for negotiation dialogue agents", "author": ["S. Keizer", "M. Guhe", "H. Cuayahuitl", "I. Efstathiou", "K. Engelbrecht", "M. Dobre", "A. Lascarides", "O. Lemon."], "venue": "European Association for", "citeRegEx": "Keizer et al\\.,? 2017", "shortCiteRegEx": "Keizer et al\\.", "year": 2017}, {"title": "Globally coherent text generation with neural checklist models", "author": ["C. Kiddon", "L.S. Zettlemoyer", "Y. Choi."], "venue": "Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Kiddon et al\\.,? 2016", "shortCiteRegEx": "Kiddon et al\\.", "year": 2016}, {"title": "A persona-based neural conversation model", "author": ["J. Li", "M. Galley", "C. Brockett", "J. Gao", "B. Dolan."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Li et al\\.,? 2016a", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A diversity-promoting objective function for neural conversation models", "author": ["J. Li", "M. Galley", "C. Brockett", "J. Gao", "W.B. Dolan."], "venue": "Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL).", "citeRegEx": "Li et al\\.,? 2016b", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "Deep reinforcement learning for dialogue generation", "author": ["J. Li", "W. Monroe", "A. Ritter", "D. Jurafsky", "M. Galley", "J. Gao."], "venue": "Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Li et al\\.,? 2016c", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "A user simulator for taskcompletion dialogues", "author": ["X. Li", "Z.C. Lipton", "B. Dhingra", "L. Li", "J. Gao", "Y. Chen."], "venue": "arXiv .", "citeRegEx": "Li et al\\.,? 2016d", "shortCiteRegEx": "Li et al\\.", "year": 2016}, {"title": "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation", "author": ["C. Liu", "R. Lowe", "I.V. Serban", "M. Noseworthy", "L. Charlin", "J. Pineau."], "venue": "Empirical Methods in Natural Language", "citeRegEx": "Liu et al\\.,? 2016", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "Training End-to-End dialogue systems with the ubuntu dialogue corpus", "author": ["R.T. Lowe", "N. Pow", "I. Serban", "L. Charlin", "C. Liu", "J. Pineau."], "venue": "Dialogue and Discourse 8.", "citeRegEx": "Lowe et al\\.,? 2017", "shortCiteRegEx": "Lowe et al\\.", "year": 2017}, {"title": "What to talk about and how? selective generation using LSTMs with coarse-to-fine alignment", "author": ["H. Mei", "M. Bansal", "M.R. Walter."], "venue": "Human Language Technology and North American Association for Computational Linguistics (HLT/NAACL).", "citeRegEx": "Mei et al\\.,? 2016", "shortCiteRegEx": "Mei et al\\.", "year": 2016}, {"title": "Coherent dialogue with attention-based language models", "author": ["H. Mei", "M. Bansal", "M.R. Walter."], "venue": "Association for the Advancement of Artificial Intelligence (AAAI).", "citeRegEx": "Mei et al\\.,? 2017", "shortCiteRegEx": "Mei et al\\.", "year": 2017}, {"title": "Goal-driven answers in the Cards dialogue corpus", "author": ["C. Potts."], "venue": "Proceedings of the 30th West Coast Conference on Formal Linguistics.", "citeRegEx": "Potts.,? 2012", "shortCiteRegEx": "Potts.", "year": 2012}, {"title": "Multiresolution recurrent neural networks: An application to dialogue response generation", "author": ["I. Serban", "T. Klinger", "G. Tesauro", "K. Talamadupula", "B. Zhou", "Y. Bengio", "A.C. Courville."], "venue": "Association for the Advancement of Artificial Intelligence", "citeRegEx": "Serban et al\\.,? 2017a", "shortCiteRegEx": "Serban et al\\.", "year": 2017}, {"title": "A hierarchical latent variable encoder-decoder model for generating dialogues", "author": ["I. Serban", "A. Sordoni", "R. Lowe", "L. Charlin", "J. Pineau", "A.C. Courville", "Y. Bengio."], "venue": "Association for the Advancement of Artificial Intelligence (AAAI).", "citeRegEx": "Serban et al\\.,? 2017b", "shortCiteRegEx": "Serban et al\\.", "year": 2017}, {"title": "A survey of available corpora for building data-driven dialogue systems", "author": ["I.V. Serban", "R. Lowe", "L. Charlin", "J. Pineau."], "venue": "arXiv preprint arXiv:1512.05742 .", "citeRegEx": "Serban et al\\.,? 2015a", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["I.V. Serban", "A. Sordoni", "Y. Bengio", "A. Courville", "J. Pineau."], "venue": "arXiv preprint arXiv:1507.04808 .", "citeRegEx": "Serban et al\\.,? 2015b", "shortCiteRegEx": "Serban et al\\.", "year": 2015}, {"title": "Neural responding machine for short-text conversation", "author": ["L. Shang", "Z. Lu", "H. Li."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Shang et al\\.,? 2015", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["A. Sordoni", "M. Galley", "M. Auli", "C. Brockett", "Y. Ji", "M. Mitchell", "J. Nie", "J. Gao", "B. Dolan."], "venue": "North American Association for Computational Linguis-", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Continuously learning neural dialogue management", "author": ["P. Su", "M. Gasic", "N. Mrksic", "L.M. Rojas-Barahona", "S. Ultes", "D. Vandyke", "T. Wen", "S.J. Young."], "venue": "arXiv preprint arXiv:1606.02689 .", "citeRegEx": "Su et al\\.,? 2016", "shortCiteRegEx": "Su et al\\.", "year": 2016}, {"title": "Emergence of gricean maxims from multi-agent decision theory", "author": ["A. Vogel", "M. Bodoia", "C. Potts", "D. Jurafsky."], "venue": "North American Association for Computational Linguistics (NAACL). pages 1072\u2013 1081.", "citeRegEx": "Vogel et al\\.,? 2013", "shortCiteRegEx": "Vogel et al\\.", "year": 2013}, {"title": "A network-based end-to-end trainable task-oriented dialogue system", "author": ["T. Wen", "M. Gasic", "N. Mrksic", "L.M. Rojas-Barahona", "P. Su", "S. Ultes", "D. Vandyke", "S. Young."], "venue": "European Association for Computational Linguistics (EACL).", "citeRegEx": "Wen et al\\.,? 2017", "shortCiteRegEx": "Wen et al\\.", "year": 2017}, {"title": "Hybrid code networks: Practical and efficient end-toend dialog control with supervised and reinforcement learning", "author": ["J.D. Williams", "K. Asadi", "G. Zweig."], "venue": "Association for Computational Linguistics (ACL).", "citeRegEx": "Williams et al\\.,? 2017", "shortCiteRegEx": "Williams et al\\.", "year": 2017}, {"title": "The dialog state tracking challenge series: A review", "author": ["J.D. Williams", "A. Raux", "M. Henderson."], "venue": "Dialogue and Discourse 7.", "citeRegEx": "Williams et al\\.,? 2016", "shortCiteRegEx": "Williams et al\\.", "year": 2016}, {"title": "Partially observable Markov decision processes for spoken dialog systems", "author": ["J.D. Williams", "S. Young."], "venue": "Computer Speech & Language 21(2):393\u2013 422.", "citeRegEx": "Williams and Young.,? 2007", "shortCiteRegEx": "Williams and Young.", "year": 2007}, {"title": "POMDP-based statistical spoken dialog systems: A review", "author": ["S. Young", "M. Gasic", "B. Thomson", "J.D. Williams."], "venue": "Proceedings of the IEEE 101(5):1160\u20131179.", "citeRegEx": "Young et al\\.,? 2013", "shortCiteRegEx": "Young et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 32, "context": "Current task-oriented dialogue systems (Young et al., 2013; Wen et al., 2017; Dhingra et al., 2017) require a pre-defined dialogue state (e.", "startOffset": 39, "endOffset": 99}, {"referenceID": 28, "context": "Current task-oriented dialogue systems (Young et al., 2013; Wen et al., 2017; Dhingra et al., 2017) require a pre-defined dialogue state (e.", "startOffset": 39, "endOffset": 99}, {"referenceID": 4, "context": "Current task-oriented dialogue systems (Young et al., 2013; Wen et al., 2017; Dhingra et al., 2017) require a pre-defined dialogue state (e.", "startOffset": 39, "endOffset": 99}, {"referenceID": 24, "context": "Recent opendomain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2017; Mei et al., 2017) learn a mapping directly from previous utterances to the next utterance.", "startOffset": 31, "endOffset": 150}, {"referenceID": 23, "context": "Recent opendomain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2017; Mei et al., 2017) learn a mapping directly from previous utterances to the next utterance.", "startOffset": 31, "endOffset": 150}, {"referenceID": 25, "context": "Recent opendomain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2017; Mei et al., 2017) learn a mapping directly from previous utterances to the next utterance.", "startOffset": 31, "endOffset": 150}, {"referenceID": 11, "context": "Recent opendomain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2017; Mei et al., 2017) learn a mapping directly from previous utterances to the next utterance.", "startOffset": 31, "endOffset": 150}, {"referenceID": 16, "context": "Recent opendomain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2017; Mei et al., 2017) learn a mapping directly from previous utterances to the next utterance.", "startOffset": 31, "endOffset": 150}, {"referenceID": 18, "context": "Recent opendomain chat systems (Shang et al., 2015; Serban et al., 2015b; Sordoni et al., 2015; Li et al., 2016a; Lowe et al., 2017; Mei et al., 2017) learn a mapping directly from previous utterances to the next utterance.", "startOffset": 31, "endOffset": 150}, {"referenceID": 6, "context": "Our model is similar to EntNet (Henaff et al., 2017) in that node/entity embeddings are updated recurrently given new utterances.", "startOffset": 31, "endOffset": 52}, {"referenceID": 2, "context": "An attention-based mechanism (Bahdanau et al., 2015) over the node embeddings drives generation of new utterances.", "startOffset": 29, "endOffset": 52}, {"referenceID": 28, "context": ", 2016b,c), we also conduct partner evaluation (Wen et al., 2017) where AMT workers rate their conversational partners (other workers or our models) based on fluency, correctness, cooperation, and human-likeness.", "startOffset": 47, "endOffset": 65}, {"referenceID": 7, "context": ", italic utterances in Figure 1), a common characteristic of online chat (Ivanovic, 2005).", "startOffset": 73, "endOffset": 89}, {"referenceID": 2, "context": "We compute the weights through standard attention mechanism (Bahdanau et al., 2015):", "startOffset": 60, "endOffset": 83}, {"referenceID": 8, "context": "Finally, we define a distribution over both words in the vocabulary and nodes in Gt using the copying mechanism of Jia and Liang (2016):", "startOffset": 115, "endOffset": 136}, {"referenceID": 5, "context": "The parameters are optimized by AdaGrad (Duchi et al., 2010) with an initial learning rate of 0.", "startOffset": 40, "endOffset": 60}, {"referenceID": 12, "context": "Compared to Rule, the neural models tend to generate shorter utterances (Li et al., 2016b; Serban et al., 2017b).", "startOffset": 72, "endOffset": 112}, {"referenceID": 21, "context": "Compared to Rule, the neural models tend to generate shorter utterances (Li et al., 2016b; Serban et al., 2017b).", "startOffset": 72, "endOffset": 112}, {"referenceID": 22, "context": "There has been a recent surge of interest in end-to-end task-oriented dialogue systems, though progress has been limited by the size of available datasets (Serban et al., 2015a).", "startOffset": 155, "endOffset": 177}, {"referenceID": 30, "context": "Most work focuses on information-querying tasks, using Wizard-ofOz data collection (Williams et al., 2016; Asri et al., 2016) or simulators (Bordes and Weston, 2017; Li et al.", "startOffset": 83, "endOffset": 125}, {"referenceID": 1, "context": "Most work focuses on information-querying tasks, using Wizard-ofOz data collection (Williams et al., 2016; Asri et al., 2016) or simulators (Bordes and Weston, 2017; Li et al.", "startOffset": 83, "endOffset": 125}, {"referenceID": 3, "context": ", 2016) or simulators (Bordes and Weston, 2017; Li et al., 2016d), In contrast, collaborative dialogues are easy to collect as natural human conversations, and are also challenging enough given the large number of scenarios and diverse conversation phenomena.", "startOffset": 22, "endOffset": 65}, {"referenceID": 14, "context": ", 2016) or simulators (Bordes and Weston, 2017; Li et al., 2016d), In contrast, collaborative dialogues are easy to collect as natural human conversations, and are also challenging enough given the large number of scenarios and diverse conversation phenomena.", "startOffset": 22, "endOffset": 65}, {"referenceID": 0, "context": "There are some interesting strategic dialogue datasets\u2014settlers of Catan (Afantenos et al., 2012) (2K turns) and the cards corpus (Potts, 2012) (1.", "startOffset": 73, "endOffset": 97}, {"referenceID": 19, "context": ", 2012) (2K turns) and the cards corpus (Potts, 2012) (1.", "startOffset": 40, "endOffset": 53}, {"referenceID": 9, "context": "3K dialogues), as well as work on dialogue strategies (Keizer et al., 2017; Vogel et al., 2013), though no full dialogue system has been built for these datasets.", "startOffset": 54, "endOffset": 95}, {"referenceID": 27, "context": "3K dialogues), as well as work on dialogue strategies (Keizer et al., 2017; Vogel et al., 2013), though no full dialogue system has been built for these datasets.", "startOffset": 54, "endOffset": 95}, {"referenceID": 31, "context": "Most task-oriented dialogue systems follow the POMDP-based approach (Williams and Young, 2007; Young et al., 2013).", "startOffset": 68, "endOffset": 114}, {"referenceID": 32, "context": "Most task-oriented dialogue systems follow the POMDP-based approach (Williams and Young, 2007; Young et al., 2013).", "startOffset": 68, "endOffset": 114}, {"referenceID": 28, "context": "Despite their success (Wen et al., 2017; Dhingra et al., 2017; Su et al., 2016), the requirement for handcrafted slots limits their scalability to new domains and burdens data collection with extra state labeling.", "startOffset": 22, "endOffset": 79}, {"referenceID": 4, "context": "Despite their success (Wen et al., 2017; Dhingra et al., 2017; Su et al., 2016), the requirement for handcrafted slots limits their scalability to new domains and burdens data collection with extra state labeling.", "startOffset": 22, "endOffset": 79}, {"referenceID": 26, "context": "Despite their success (Wen et al., 2017; Dhingra et al., 2017; Su et al., 2016), the requirement for handcrafted slots limits their scalability to new domains and burdens data collection with extra state labeling.", "startOffset": 22, "endOffset": 79}, {"referenceID": 6, "context": "Our network architecture is most similar to EntNet (Henaff et al., 2017), where memories are also updated by input sentences recurrently.", "startOffset": 51, "endOffset": 72}, {"referenceID": 3, "context": "To go past this limit, Bordes and Weston (2017) proposed a Memory-Networks-based approach without domain-specific features.", "startOffset": 23, "endOffset": 48}, {"referenceID": 3, "context": "To go past this limit, Bordes and Weston (2017) proposed a Memory-Networks-based approach without domain-specific features. However, the memory is unstructured and interfacing with KBs relies on API calls, whereas our model embeds both the dialogue history and the KB structurally. Williams et al. (2017) use an LSTM to automatically infer the dialogue state, but as they focus on dialogue control rather than the full problem, the response is modeled as a templated action, which restricts the generation of richer utterances.", "startOffset": 23, "endOffset": 305}, {"referenceID": 17, "context": "Our work is also related to language generation conditioned on knowledge bases (Mei et al., 2016; Kiddon et al., 2016).", "startOffset": 79, "endOffset": 118}, {"referenceID": 10, "context": "Our work is also related to language generation conditioned on knowledge bases (Mei et al., 2016; Kiddon et al., 2016).", "startOffset": 79, "endOffset": 118}, {"referenceID": 20, "context": ", attending to items or attributes first, then selecting entities; generating high-level concepts before composing them to natural tokens (Serban et al., 2017a).", "startOffset": 138, "endOffset": 160}], "year": 2017, "abstractText": "We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.", "creator": "LaTeX with hyperref package"}}}