{"id": "1704.07157", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "24-Apr-2017", "title": "Watset: Automatic Induction of Synsets from a Graph of Synonyms", "abstract": "This paper presents a new graph-based approach that induces synsets using synonymy dictionaries and word embeddings. First, we build a weighted graph of synonyms extracted from commonly available resources, such as Wiktionary. Second, we apply word sense induction to deal with ambiguous words. Finally, we cluster the disambiguated version of the ambiguous input graph into synsets. Our meta-clustering approach lets us use an efficient hard clustering algorithm to perform a fuzzy clustering of the graph. Despite its simplicity, our approach shows excellent results, outperforming five competitive state-of-the-art methods in terms of F-score on three gold standard datasets for English and Russian derived from large-scale manually constructed lexical resources.", "histories": [["v1", "Mon, 24 Apr 2017 11:49:08 GMT  (281kb,D)", "http://arxiv.org/abs/1704.07157v1", "12 pages, 3 figures, 6 tables, accepted to ACL 2017"]], "COMMENTS": "12 pages, 3 figures, 6 tables, accepted to ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["dmitry ustalov", "alexander panchenko", "chris biemann"], "accepted": true, "id": "1704.07157"}, "pdf": {"name": "1704.07157.pdf", "metadata": {"source": "CRF", "title": "Watset: Automatic Induction of Synsets from a Graph of Synonyms", "authors": ["Dmitry Ustalov", "Alexander Panchenko", "Chris Biemann"], "emails": ["dmitry.ustalov@urfu.ru", "panchenko@informatik.uni-hamburg.de", "biemann@informatik.uni-hamburg.de"], "sections": [{"heading": "1 Introduction", "text": "In fact, we have to be able to assert ourselves, we have to be able, we will be able to be able, we will be able to be able, \"he said.\" We have to be able to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position, we have to put ourselves in a position. \""}, {"heading": "2 Related Work", "text": "These are the main advantages of our approach compared to lexical resources, that there is no manual synthesis in which the encoding is required. Methods based on word meanings based on word meanings try to induce a general specification for the representation of lexical resources and links between them. The main advantage of our approach compared to lexical resources is that no manual synthesis is required in the encoding. Methods based on word meanings based on word meanings that induce an initial lexical resource and links between them. The main advantage of our approach compared to lexical resources is that no manual syntax encoding is required. Methods are based on word meanings that induce an initial lexical resource by extracting semantic relationships from text."}, {"heading": "3 The WATSET Method", "text": "The aim of our method is to induce a series of unique synsets by grouping individual ambiguous synonyms. A sketch of the proposed approach is presented in Figure 1. The method takes a dictionary of ambiguous synonymic relationships and a text corpus as input and output synsets. Note that the method can be used without a background corpus, but as our experiments will show, corpus-based information improves the results when used to weight the edges of the wordgraph. A synonymic dictionary can be perceived as a graph in which the nodes correspond to lexical entries (words) and connect the edges pairs of the nodes if the synonymous relationship between them holds. Of course, the cliques in such a graph are closely related sets of synonyms that correspond to concepts (Gfeller et al., 2005). Given that the solution of the cliquetype problem is inductive, it is complete in one of thousands of graphs (NP)."}, {"heading": "3.1 Learning Word Embeddings", "text": "Since different graph cluster algorithms are sensitive to edge weighting, we consider a semantic similarity based on Word embedding on a distributional basis as a possible edge weighting approach for our synonymy graph. As we further show, this approach improves over unweighted versions and delivers the best overall results."}, {"heading": "3.2 Construction of a Synonymy Graph", "text": "We construct the synonymous graph G = (V, E) as follows: The set of nodes V encompasses each lexeme that appears in the synonymous input dictionaries; the set of undirected edges E consists of all edges (u, v) that are retrieved from one of the synonymous input dictionaries; we consider three edge weight representations: \u2022 those that assign a constant weight of 1 to each edge; \u2022 Count that the edge (u, v) is weighted as often as the synonymous pair has appeared in the input dictionaries; \u2022 simulation that assigns a weight to each edge (u, v) that corresponds to the cosmic similarity of word vectors to the skipped gram (Mikolov et al., 2013). Since the graph G will probably have polysemme words, the goal is to separate individual word senses using graph-based word induction."}, {"heading": "3.3 Local Clustering: Word Sense Induction", "text": "To facilitate the global fuzziness of the graph, we perform a disambiguation of its ambiguous nodes, as shown in Figure 2. First, we use a graph-based literal induction method similar to the curvature-based approach of Dorow and Widdows (2003). Specifically, the removal of the nodes involved in many triangles tends to split the original graph into several interconnected components. Thus, with one word u, we extract a network of its closest neighbors from the synonymous graph G. Then we remove the original word u from this network and operate a hardgraph cluster algorithm that assigns one node to one and only one cluster. In our experiments, we test Chinese Whispers and Markov Clustering. The expected result is that each cluster represents a different sense of the word u, e.g.: Bank1 {Stream Bank, Riverbank,..} bank2 {Bank Building, Bank Building, Bank Building, Bank Building, Bank Building, Bank Building, Bank Building, Bank Building, Bank Building, Bank Building, Bank Building, Bank Building, 4, Bank Building)."}, {"heading": "3.4 Disambiguation of Neighbors", "text": "The previous step leads to word nodes being divided into (one or more) meaning nodes. However, the closest neighbours of each meaning node are still ambiguous, e.g. (bank3, building?). To restore these meaning nodes of the adjacent words, we use the sense-disambiguation approach proposed by Faralli et al. (2016). For each word u in the context of ctx (s) of the sense s we find the meaning of that word that appears most similar to the context and we use the cosine similarity measure between the context of the sense and the context of each candidate u \u2032 of the word u: u: u = argmax u \u00b2 senses (u) cos (ctx (s), ctx (u \u2032)).A context ctx (\u00b7) is represented by a sparse vector in a vector space of all ambiguous words of all contexts, resulting in a disamuated context (c)."}, {"heading": "3.5 Global Clustering: Synset Induction", "text": "Finally, we construct the word sense diagram G \"= (V,\" E \") by using the unambiguous senses instead of the original words and defining the edges between these unambiguous senses: V\" = u \"u\" V \"senses (u), E\" = s \"V\" \u00b7 c \"tx (s). Running a hard cluster algorithm on G\" generates the desired synsets as our end result. Figure 2 illustrates the process of ambiguity of an input diagram using the example of the word \"bank.\" As can be seen, the ambiguity of the closest neighbors is a necessity in order to be able to construct a global version of the meaning-conscious diagram. Note that current approaches to WSI, e.g. (Ve \"ronis,\" 2004; Biemann, 2006; Hope and Keller, 2013), do not aim at a global representation, but only perform local clustering of the diagram."}, {"heading": "3.6 Local-Global Fuzzy Graph Clustering", "text": "In this work, while applying our approach to synset induction, the core of our method is the \"localglobal\" fuzzy graph cluster algorithm, which can be applied to any graph (see Figure 1). This method, summarized in Algorithm 1, takes an undirected graph G = (V, E) as input and outputs a set of fuzzy clusters of its nodes V. It is a meta-algorithm based on two hard cluster algorithms called cluster local and cluster global, such as CW or MCL. In the first phase of the algorithm, its senses are induced for each node via first-person network clustering (lines 1-7). Next, the disambiguity of each first-person network (lines 8-15) is achieved by applying the hard cluster algorithm on the ambiguous graphs (line 16)."}, {"heading": "4 Evaluation", "text": "We conduct our experiments with resources from two different languages. We evaluate our approach on two sets of data for English to demonstrate its performance on a resource-rich language. Additionally, we evaluate it on two sets of Russian data, as Russian is a good example of an underfunded language with a clear need for synset induction."}, {"heading": "4.1 Gold Standard Datasets", "text": "For each language, we used two differently constructed lexical semantic resources listed in Table 1 for gold standard synsets.English. We used WordNet8, a popular English lexical database constructed by specialist lexicographers. WordNet contains generic vocabulary pairs and8https: / / wordnet.princeton.eduAlgorithm 1 WATSET fuzzy graph clustering input: a set of nodes V and a set of edges E. Output: a set of fuzzy clusters of V.1: for all u-V do 2: C clusterlocal (u) / / C = {C1,... ele.C1} 3: for i-networks."}, {"heading": "4.2 Evaluation Metrics", "text": "To evaluate the quality of the induced synsets, we converted them into binary synonymous relationships and calculated precision, retrieval and F score based on the overlap of these binary relationships with the binary relationships from the gold standard datasets. Given a synset that contains n words, we generate a set of n (n \u2212 1) 2 synonymous pairs. The F score thus calculated is known as the Paired F score (Manandhar et al., 2010; Hope and Keller, 2013). The advantage of this measurement over other cluster evaluation measures such as Fuzzy B-Cubed (Jurgens and Klapaftis, 2013) is its ease of interpretation."}, {"heading": "4.3 Word Embeddings", "text": "English. We use the standard 300-dimensional word embeddings trained on the 100 billion token corpus of Google News (Mikolov et al., 2013).12 Russian. We use the 500-dimensional word embeddings trained on a 12.9 billion token corpus of books using the Skip-gram negative scan model (Mikolov et al., 2013), using a context window size of 10 with the minimum word frequency of 5. These embeddings have been proven to produce state-of-the-art results in the shared RUSSE Task13 and are part of the Russian Distributional Thesaurus (RDT) (Panchenko et al., 2017b).14"}, {"heading": "4.4 Input Dictionary of Synonyms", "text": "The statistics of the graphs used as input in the subsequent experiments are presented in Table 2.12https: / / code.google.com / p / word2vec 13http: / / www.dialog-21.ru / en / evaluation / 2015 / semantic _ similarity 14http: / / russe.nlpub.ru / downloadsEnglish. Synonyms were extracted from the English Wiktionary15, which is currently the largest Wiktionary in terms of lexical coverage, using the tool DKPro JWKTL by Zesch et al. (2008). English words were extracted from the dump.Russian. Synonyms from three sources were combined to improve lexical coverage of the input dictionary and to force trust in jointly observed synonyms: (1) Synonyms listed in the Russian Wikictionary. Synonyms from three sources were combined (Daslexowski), the most of which are available in the Russian Wikictionary (Daslexowski)."}, {"heading": "5 Results", "text": "We compare WATSET with five state-of-the-art diagram clustering methods presented in Section 2: Chinese Whispers (CW), Markov Clustering (MCL), MaxMax, ECO Clustering and the Clique Percolation Method (CPM). The first two algorithms perform hard clustering, while the last three, like our method, are blurred clustering methods. In our experiments, we rely on our own implementation of MaxMax and ECO as reference implementations are not available. For CW17, we used the Wiktionary dumps of February 1, 2017. 16We used the YARN dumps of February 7, 2017."}, {"heading": "5.1 Impact of Graph Weighting Schema", "text": "Figure 3 gives an overview of the evaluation results of both sets of data. The first step common to all synset induction methods tested is graph construction. Therefore, we started with an analysis of three ways of weighting the edges of the graph introduced in Section 3.2: binary values (ones), frequencies (counting), and semantic similarity values (simulation) based on word vector similarity. Results in different configurations and methods suggest that using weights based on the similarity values provided by word embedding is the best strategy for all methods except MaxMax based on English data sets. However, its performance using one-weighting does not exceed the other methods using simulation weighting. Therefore, we report all other results based on simulation weights. The edge weighting scheme has a stronger impact on Russian for most algorithms. However, the CW algorithm remains sensitive to the weighting of the English data sets due to its edge-sensitive nature."}, {"heading": "5.2 Comparative Analysis", "text": "Dre rf\u00fc nde eeisrcnlhsrteee\u00fccnlhsrrrteeGsrteeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeBnlrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr"}, {"heading": "6 Discussion", "text": "The results of all the gold standards (Figure 3) show similar trends in the relative ranking of the methods, but the absolute values of YARN and RuWordNet differ significantly due to the inherent difference in these data sets. RuWordNet is more domain specific in terms of vocabulary, so our input set of generic synonymic dictionaries has limited coverage of this data set. On the other hand, the callback calculated on YARN is much higher because this resource was built manually on the basis of synonymic dictionaries used in our experiments. The reason for the low absolute numbers in the ratings is an inherent discrepancy between the input dictionaries of synonyms and the gold data sets. To confirm this hypothesis, we conducted a cross-resource evaluation, which is presented in Table 5."}, {"heading": "7 Conclusion", "text": "We have introduced a new robust approach to fuzzy graph clustering based on hard graph clustering. First-person network clustering is used to split the nodes of multiple local communities into multiple nodes belonging to each community, and the transformed \"ambiguous\" graph is then clustered using an efficient hard graph clustering algorithm, resulting in fuzzy clustering. The ambiguous graph makes clustering easier because it contains fewer nodes that are unrelated to other communities. We apply this meta-clustering algorithm to the task of synset induction in two languages to achieve the best results on three datasets and competitive results on a dataset in terms of F-Score compared to five advanced graph clustering methods."}, {"heading": "Acknowledgments", "text": "We would like to thank the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) for the support of the project \"JOIN-T,\" the DAAD, the RFBR within the project 16-37-00354 mol a and the RFH within the project 16-04-12019. Furthermore we would like to thank three anonymous reviewers for their helpful comments, Andrew Krizhanovsky for providing an evaluated Wiktionary, Natalia Loukachevitch for the provided data set RuWordNet and Denis Shirgin, who suggested the name WATSET."}], "references": [{"title": "Structure Discovery in Natu", "author": [], "venue": null, "citeRegEx": "Biemann.,? \\Q2012\\E", "shortCiteRegEx": "Biemann.", "year": 2012}, {"title": "Ego network betweenness", "author": ["Martin Everett", "Stephen P. Borgatti."], "venue": "Social Networks 27(1):31\u201338. https://doi.org/10.1016/j.socnet.2004.11.007.", "citeRegEx": "Everett and Borgatti.,? 2005", "shortCiteRegEx": "Everett and Borgatti.", "year": 2005}, {"title": "Linked Disambiguated Distributional Semantic Networks", "author": ["Stefano Faralli", "Alexander Panchenko", "Chris Biemann", "Simone P. Ponzetto."], "venue": "The Semantic Web \u2013 ISWC 2016: 15th International Semantic Web Conference, Kobe, Japan, Oc-", "citeRegEx": "Faralli et al\\.,? 2016", "shortCiteRegEx": "Faralli et al\\.", "year": 2016}, {"title": "Synonym Dictionary Improvement through Markov Clustering and Clustering Stability", "author": ["David Gfeller", "Jean-C\u00e9dric Chappelier", "Paulo De Los Rios."], "venue": "Proceedings of the International Symposium on Applied Stochastic Models and Data Anal-", "citeRegEx": "Gfeller et al\\.,? 2005", "shortCiteRegEx": "Gfeller et al\\.", "year": 2005}, {"title": "ECO and Onto.PT: a flexible approach for creating a Portuguese wordnet automatically. Language Resources and Evaluation 48(2):373\u2013393", "author": ["Hugo Gon\u00e7alo Oliveira", "Paolo Gomes"], "venue": null, "citeRegEx": "Oliveira and Gomes.,? \\Q2014\\E", "shortCiteRegEx": "Oliveira and Gomes.", "year": 2014}, {"title": "Web Query Expansion by WordNet", "author": ["Zhiguo Gong", "Chan Wa Cheang", "U. Leong Hou."], "venue": "Proceedings of the 16th International Conference on Database and Expert Systems Applications - DEXA \u201905, Springer Berlin Hei-", "citeRegEx": "Gong et al\\.,? 2005", "shortCiteRegEx": "Gong et al\\.", "year": 2005}, {"title": "UBY \u2013 A Large-Scale Unified Lexical-Semantic Resource Based on LMF", "author": ["Iryna Gurevych", "Judith Eckle-Kohler", "Silvana Hartmann", "Michael Matuschek", "Christian M. Meyer", "Christian Wirth."], "venue": "Proceedings of the 13th Conference of the Euro-", "citeRegEx": "Gurevych et al\\.,? 2012", "shortCiteRegEx": "Gurevych et al\\.", "year": 2012}, {"title": "Linked Lexical Knowledge Bases: Foundations and Applications", "author": ["Iryna Gurevych", "Judith Eckle-Kohler", "Michael Matuschek."], "venue": "Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers.", "citeRegEx": "Gurevych et al\\.,? 2016", "shortCiteRegEx": "Gurevych et al\\.", "year": 2016}, {"title": "Modelling Word Similarity: an Evaluation of Automatic Synonymy Extraction Algorithms", "author": ["Kris Heylen", "Yves Peirsman", "Dirk Geeraerts", "Dirk Speelman."], "venue": "Proceedings of the Sixth International Conference on Language", "citeRegEx": "Heylen et al\\.,? 2008", "shortCiteRegEx": "Heylen et al\\.", "year": 2008}, {"title": "MaxMax: A GraphBased Soft Clustering Algorithm Applied to Word Sense Induction", "author": ["David Hope", "Bill Keller."], "venue": "Computational Linguistics", "citeRegEx": "Hope and Keller.,? 2013", "shortCiteRegEx": "Hope and Keller.", "year": 2013}, {"title": "Creating Russian Word", "author": ["Boris V. Dobrov"], "venue": null, "citeRegEx": "Dobrov.,? \\Q2016\\E", "shortCiteRegEx": "Dobrov.", "year": 2016}, {"title": "Distributed Representations of Words and Phrases and their Compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S. Corrado", "Jeffrey Dean."], "venue": "Advances in Neural Information Processing Systems 26, Curran Associates,", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "WordNet: A Lexical Database for English", "author": ["George A. Miller"], "venue": null, "citeRegEx": "Miller.,? \\Q1995\\E", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network", "author": ["Roberto Navigli", "Simone P. Ponzetto."], "venue": "Artificial Intelligence 193:217\u2013250. https://doi.org/10.1016/j.artint.2012.07.001.", "citeRegEx": "Navigli and Ponzetto.,? 2012", "shortCiteRegEx": "Navigli and Ponzetto.", "year": 2012}, {"title": "Uncovering the overlapping community structure of complex networks in nature and society", "author": ["Gergely Palla", "Imre Derenyi", "Illes Farkas", "Tamas Vicsek."], "venue": "Nature 435:814\u2013818. https://doi.org/10.1038/nature03607.", "citeRegEx": "Palla et al\\.,? 2005", "shortCiteRegEx": "Palla et al\\.", "year": 2005}, {"title": "Comparison of the Baseline Knowledge-, Corpus-, and Web-based Similarity Measures for Semantic Relations Extraction", "author": ["Alexander Panchenko."], "venue": "Proceedings of the GEMS 2011 Workshop on GEometrical Models of Natural", "citeRegEx": "Panchenko.,? 2011", "shortCiteRegEx": "Panchenko.", "year": 2011}, {"title": "Unsupervised Does Not Mean Uninterpretable: The Case for Word Sense Induction and Disambiguation", "author": ["Alexander Panchenko", "Eugen Ruppert", "Stefano Faralli", "Simone P. Ponzetto", "Chris Biemann."], "venue": "Proceedings of the", "citeRegEx": "Panchenko et al\\.,? 2017a", "shortCiteRegEx": "Panchenko et al\\.", "year": 2017}, {"title": "Human and Machine Judgements for Russian Semantic Relatedness", "author": ["Alexander Panchenko", "Dmitry Ustalov", "Nikolay Arefyev", "Denis Paperno", "Natalia Konstantinova", "Natalia Loukachevitch", "Chris Biemann."], "venue": "Analysis of Images, Social", "citeRegEx": "Panchenko et al\\.,? 2017b", "shortCiteRegEx": "Panchenko et al\\.", "year": 2017}, {"title": "Discovering Word Senses from Text", "author": ["Patrick Pantel", "Dekang Lin."], "venue": "Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, Edmonton, Alberta, Canada, KDD \u201902, pages 613\u2013619.", "citeRegEx": "Pantel and Lin.,? 2002", "shortCiteRegEx": "Pantel and Lin.", "year": 2002}, {"title": "Making Sense of Word Embeddings", "author": ["Maria Pelevina", "Nikolay Arefiev", "Chris Biemann", "Alexander Panchenko."], "venue": "Proceedings of the 1st Workshop on Representation Learning for NLP. Association for Computational Linguistics, Berlin, Germany, pages", "citeRegEx": "Pelevina et al\\.,? 2016", "shortCiteRegEx": "Pelevina et al\\.", "year": 2016}, {"title": "Graph Clustering by Flow Simulation", "author": ["Stijn van Dongen."], "venue": "Ph.D. thesis, University of Utrecht.", "citeRegEx": "Dongen.,? 2000", "shortCiteRegEx": "Dongen.", "year": 2000}, {"title": "HyperLex: lexical cartography for information retrieval", "author": ["Jean V\u00e9ronis."], "venue": "Computer Speech & Language 18(3):223\u2013252. https://doi.org/10.1016/j.csl.2004.05.002.", "citeRegEx": "V\u00e9ronis.,? 2004", "shortCiteRegEx": "V\u00e9ronis.", "year": 2004}, {"title": "Extracting Lexical Semantic Knowledge from Wikipedia and Wiktionary", "author": ["Torsten Zesch", "Christof M\u00fcller", "Iryna Gurevych."], "venue": "Proceedings of the 6th International Conference on Language Resources and Evaluation. Euro-", "citeRegEx": "Zesch et al\\.,? 2008", "shortCiteRegEx": "Zesch et al\\.", "year": 2008}, {"title": "Improving Question Retrieval in Community Question Answering Using World Knowledge", "author": ["Guangyou Zhou", "Yang Liu", "Fang Liu", "Daojian Zeng", "Jun Zhao."], "venue": "Proceedings of the Twenty-Third International Joint Confer-", "citeRegEx": "Zhou et al\\.,? 2013", "shortCiteRegEx": "Zhou et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 12, "context": "Synsets represent word senses and are building blocks of WordNet (Miller, 1995) and similar resources such as thesauri and lexical ontologies.", "startOffset": 65, "endOffset": 79}, {"referenceID": 5, "context": "These resources are crucial for many natural language processing applications that require common sense reasoning, such as information retrieval (Gong et al., 2005) and question answering (Kwok et al.", "startOffset": 145, "endOffset": 164}, {"referenceID": 23, "context": ", 2005) and question answering (Kwok et al., 2001; Zhou et al., 2013).", "startOffset": 31, "endOffset": 69}, {"referenceID": 5, "context": "These resources are crucial for many natural language processing applications that require common sense reasoning, such as information retrieval (Gong et al., 2005) and question answering (Kwok et al., 2001; Zhou et al., 2013). However, for most languages, no manually-constructed resource is available that is comparable to the English WordNet in terms of coverage and quality. For instance, Kiselev et al. (2015) present a comparative analysis of lexical resources available for the Russian language concluding that there is no resource compared to WordNet in terms of coverage and quality for Russian.", "startOffset": 146, "endOffset": 415}, {"referenceID": 6, "context": "Methods based on resource linking surveyed by Gurevych et al. (2016) gather various existing lexical resources and perform their linking to obtain a machine-readable repository of lexical semantic", "startOffset": 46, "endOffset": 69}, {"referenceID": 13, "context": "For instance, BabelNet (Navigli and Ponzetto, 2012) relies in its core on a linking of WordNet and Wikipedia.", "startOffset": 23, "endOffset": 51}, {"referenceID": 6, "context": "UBY (Gurevych et al., 2012) is a general-purpose specification for the representation of lexical-semantic resources and", "startOffset": 4, "endOffset": 27}, {"referenceID": 1, "context": "An ego network consists of a single node (ego) together with the nodes they are connected to (alters) and all the edges among those alters (Everett and Borgatti, 2005).", "startOffset": 139, "endOffset": 167}, {"referenceID": 4, "context": "A notable exception is the ECO approach by Gon\u00e7alo Oliveira and Gomes (2014), which", "startOffset": 51, "endOffset": 77}, {"referenceID": 9, "context": "MaxMax (Hope and Keller, 2013) is a fuzzy clustering algorithm particularly designed for the word sense induction task.", "startOffset": 7, "endOffset": 30}, {"referenceID": 14, "context": "Clique Percolation Method (CPM) (Palla et al., 2005) is a fuzzy clustering algorithm for", "startOffset": 32, "endOffset": 52}, {"referenceID": 3, "context": "The cliques in such a graph naturally form densely connected sets of synonyms corresponding to concepts (Gfeller et al., 2005).", "startOffset": 104, "endOffset": 126}, {"referenceID": 0, "context": "The concept of a disambiguated graph is described in (Biemann, 2012).", "startOffset": 53, "endOffset": 68}, {"referenceID": 11, "context": "\u2022 sim that assigns every edge (u, v) a weight equal to the cosine similarity of skip-gram word vectors (Mikolov et al., 2013).", "startOffset": 103, "endOffset": 125}, {"referenceID": 2, "context": "proach proposed by Faralli et al. (2016). For each word u in the context ctx(s) of the sense s, we find the most similar sense of that word \u00fb to the context.", "startOffset": 19, "endOffset": 41}, {"referenceID": 21, "context": ", (V\u00e9ronis, 2004; Biemann, 2006; Hope and Keller, 2013), do not perform this step, but perform only local clustering of the graph since they do not aim at a global representation of synsets.", "startOffset": 2, "endOffset": 55}, {"referenceID": 9, "context": ", (V\u00e9ronis, 2004; Biemann, 2006; Hope and Keller, 2013), do not perform this step, but perform only local clustering of the graph since they do not aim at a global representation of synsets.", "startOffset": 2, "endOffset": 55}, {"referenceID": 9, "context": "appears to be de facto gold standard in similar tasks (Hope and Keller, 2013).", "startOffset": 54, "endOffset": 77}, {"referenceID": 9, "context": "The F-score calculated this way is known as Paired F-score (Manandhar et al., 2010; Hope and Keller, 2013).", "startOffset": 59, "endOffset": 106}, {"referenceID": 11, "context": "word embeddings trained on the 100 billion tokens Google News corpus (Mikolov et al., 2013).", "startOffset": 69, "endOffset": 91}, {"referenceID": 11, "context": "We use the 500-dimensional word embeddings trained using the skip-gram model with negative sampling (Mikolov et al., 2013) using a context window size of 10 with the minimal word frequency of 5 on a 12.", "startOffset": 100, "endOffset": 122}, {"referenceID": 17, "context": "These embeddings were shown to produce state-of-the-art results in the RUSSE shared task13 and are part of the Russian Distributional Thesaurus (RDT) (Panchenko et al., 2017b).", "startOffset": 150, "endOffset": 175}, {"referenceID": 22, "context": "Synonyms were extracted from the English Wiktionary15, which is the largest Wiktionary at the present moment in terms of the lexical coverage, using the DKPro JWKTL tool by Zesch et al. (2008). English words have been extracted from the dump.", "startOffset": 173, "endOffset": 193}], "year": 2017, "abstractText": "This paper presents a new graph-based approach that induces synsets using synonymy dictionaries and word embeddings. First, we build a weighted graph of synonyms extracted from commonly available resources, such as Wiktionary. Second, we apply word sense induction to deal with ambiguous words. Finally, we cluster the disambiguated version of the ambiguous input graph into synsets. Our meta-clustering approach lets us use an efficient hard clustering algorithm to perform a fuzzy clustering of the graph. Despite its simplicity, our approach shows excellent results, outperforming five competitive state-of-the-art methods in terms of F-score on three gold standard datasets for English and Russian derived from large-scale manually constructed lexical resources.", "creator": "LaTeX with hyperref package"}}}