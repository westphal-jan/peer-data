{"id": "1704.08387", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "27-Apr-2017", "title": "Learning Structured Natural Language Representations for Semantic Parsing", "abstract": "We introduce a neural semantic parser which is interpretable and scalable. Our model converts natural language utterances to intermediate, domain-general natural language representations in the form of predicate-argument structures, which are induced with a transition system and subsequently mapped to target domains. The semantic parser is trained end-to-end using annotated logical forms or their denotations. We obtain competitive results on various datasets. The induced predicate-argument structures shed light on the types of representations useful for semantic parsing and how these are different from linguistically motivated ones.", "histories": [["v1", "Thu, 27 Apr 2017 00:24:20 GMT  (38kb)", "http://arxiv.org/abs/1704.08387v1", null], ["v2", "Wed, 17 May 2017 09:57:29 GMT  (34kb)", "http://arxiv.org/abs/1704.08387v2", null], ["v3", "Wed, 14 Jun 2017 04:18:26 GMT  (34kb)", "http://arxiv.org/abs/1704.08387v3", null]], "reviews": [], "SUBJECTS": "cs.CL", "authors": ["jianpeng cheng 0001", "siva reddy", "vijay saraswat", "mirella lapata"], "accepted": true, "id": "1704.08387"}, "pdf": {"name": "1704.08387.pdf", "metadata": {"source": "CRF", "title": "Learning Structured Natural Language Representations for Semantic Parsing", "authors": ["Jianpeng Cheng", "Siva Reddy", "Vijay Saraswat"], "emails": ["jianpeng.cheng@ed.ac.uk,", "siva.reddy@ed.ac.uk,", "vsaraswa@us.ibm.com,", "mlap@inf.ed.ac.uk"], "sections": [{"heading": null, "text": "ar Xiv: 170 4.08 387v 1 [cs.C L] 27 Apr 201 7which is interpretable and scalable. Our model converts natural speech expressions into intermediate, cross-domain natural speech representations in the form of predicate argument structures induced with a transition system and then mapped to target domains. The semantic parser is trained end-to-end using commented logical forms or their designations. We reach the state of the art on SPADES and GRAPHQUESTIONS and achieve competitive results on GEOQUERY and WEBQUESTIONS. The induced predicate argument structures provide information on which types of representations are useful for semantic parsing and how they differ from linguistically motivated ones."}, {"heading": "1 Introduction", "text": "It is a question of whether and in what form and in what form people in this country should learn their language. It is a question of whether and in which form they should learn their language. It is a question of whether and in which language they should learn. It is a question of whether and in which language they should learn. It is a question of whether and in which language and in which language they should learn. It is a question of whether and in which language and in which language they should learn. It is a question of whether and in which language and in which language they should learn. It is a question of whether and in which language and in which language they should learn. It is a question of whether and in which language and in which language they should learn. It is a question of in which language and in which language, in which language, in which language and in which language they should learn."}, {"heading": "2 Preliminaries", "text": "Let K denote a knowledge base or, more generally, an argumentation system, and x denote a statement coupled with a grounded mean-2We discuss the merits and limitations of this assumption in Section 5.ing Representation G or its denomination. Our problem is to learn a semantic parser that connects x to G via an intermediate ungrounded representation U. When G is executed against K, there is also a grounded meaning representation y.Grounded Meaning Representation We represent grounded meaning representations in FunQL (Kate et al., 2005) among many other alternatives such as Lambda Calculus (Zettlemoyer and Collins, 2005), there is the denotation y.Grounded Meaning Representation (Liang, 2013) or Graph Queries (Holzschuher and Peinl, 2013). FunQL is a variable-free query language in which treats any predicate as a function symbol that modifies an argument list."}, {"heading": "3 Modeling", "text": "In this section, we will discuss our neural model, which maps expressions to logical target forms. We will break down the semantic parsing task into two phases: first, we will explain how an expression is transformed into an intermediate representation (Section 3.1), and then we will describe how it is grounded to a knowledge base (Section 3.2)."}, {"heading": "3.1 Generating Ungrounded Representations", "text": "This year it has come to the point that it has never come as far as this year."}, {"heading": "3.2 Generating Grounded Representations", "text": "Since we force the network to learn ungrounded structures that are isomorphically aligned to the representation of the objective meaning, the transformation from ungrounded to grounded representations becomes a simple lexical imaging problem. For the sake of simplicity, we do not distinguish between natural language and domain general predicates. In order to convert an ungrounded term ut to a grounded term gt, we calculate the conditional probability of gt ut with a bilinear neural network: p (gt | ut) exp ~ ut \u00b7 Wug \u00b7 gt (5), where ~ ut is the contextual representation of the ungrounded term given by the bi-directional LSTM, ~ gt is the grounded term embedding, and Wug is the weight matrix.The above grounding step can be interpreted as learning a lexicon: The model is based exclusively on the intermediate representation U to predict the representation of the objective meaning G, without taking into account the additional features of the usage."}, {"heading": "3.3 Training Objective", "text": "When the target meaning representation is available, we compare it directly with our predictions and back propagation. If only terms are available, we compare substitute meaning representations with our predictions (Reddy et al., 2014). Replacements are those with the correct terms. If there are multiple substitute expressions, we choose a random and retroactive one (Neelakantan et al., 2017). The global effect of the above updating rule is close to maximizing the marginal probability of denotations, which differs from recent work on poorly supervised semantic terms. (Neelakantan et al., 2017).4The average freebase replacement representations achieved with the highest denotation probability (F1) is 1.4. Consider the expression x with the unsubstantiated meaning representation U and the grounded meaning representation x. Both U and G are defined with a sequence of transition actions (U and G)."}, {"heading": "3.4 Reranker", "text": "In all of the Freebase experiments, we followed previous work (Berant et al., 2013; Berant et al., 2014; Reddy et al., 2014) to also train a discriminatory Ranker that recalculates grounded representations globally, using a maximum entropy model (Berant et al., 2013) to maximize the log probability of the correct response y by summarizing all grounded candidates G with denotation y (i.e., [[G] K = y): Ly = 1 (x, y), Tlog. [[G] K = yp (G | x) (8) p (G | x) and exp {f (G, x)} (9), with f (G, x) being a trait we use in the maps as a trait v2."}, {"heading": "4 Experiments", "text": "In this section, we will empirically verify that our semantic parser derives useful meaning representations, give details of the rating data sets and baselines used for comparison, and describe implementation details and the features used in the discriminatory rankings."}, {"heading": "4.1 Datasets", "text": "We have evaluated our model using the following data sets covering different areas and using different types of training data, i.e. pairs of natural speech and grounded meanings or question-and-answer pairs. GEOQUERY (Zelle and Mooney, 1996) contains 880 questions and database queries about US geography. The expressions are compositional, but the language is simple and the vocabulary size is small. The majority of the questions consist of no more than one unit. SPADES (Bisk et al., 2016) contains 93,319 questions derived from CLUEWEB09 (Gabrilovich et al., 2013) sentences. Specifically, the questions were created by randomly removing a unit, generating pairs of sentence denotation (Reddy et al., 2014). The sentences comprise two or more units and although they are not very compositional, they represent a large data set for training neural networks. WEBQUESTIONS (more compositional, 2013, although they contain two or more phrases) based on RAES."}, {"heading": "4.2 Implementation Details", "text": "Among the four sets of data described above, GEOQUERY has commented logical forms that we use directly for training, and for the other three, we treat surrogate meaning representations that lead to the correct answer as the gold standard. Surrogates were selected from a subset of free-base diagrams obtained by linking entities. Entity mentions in SPADES were automatically commented on with free-base entities (Gabrilovich et al., 2013). For WEBQUESTIONS and GRAPHQUESTIONS, we follow the procedure described in Reddy et al. (2016). We identify potential entity parameters that include seven handmade speech patterns and associate them with free-base entities that are entities from the free-base / KG API.5 We use a structured perceptron that identifies entities in WEQUITY entity entity entity entities as entities-entities entities entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entities-entity-entities-entities-entities-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entities-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entities-entity-entity-entity-entity-entity-entity-entity-entity-entities-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-activity-entity-entity-entity-entity-entity-entity-entity-entity-entity-entity-enti"}, {"heading": "4.3 Results", "text": "In fact, most of us are able to play by the rules that they have imposed on themselves in order to play by the rules, \"he told the Deutsche Presse-Agentur.\" We have to play by the rules, \"he said.\" We have to play by the rules. \""}, {"heading": "4.4 Analysis of Intermediate Representations", "text": "This year, it is more than ever in the history of the city, where it is so far that it is a place, where it is a place, where it is a place, where it is a place."}, {"heading": "5 Discussion", "text": "Compared to previous neural semantic parsers, our model is easier to interpret because the intermediate structures are useful to verify what the model has learned and whether it matches linguistic intuition. An assumption that our model imposes is that odd and grounded representations are structurally isomorphic. An advantage of this assumption is that tokens in the unrounded and grounded representations are strictly aligned to linguistic intuition, allowing the neural network to focus on parsing and lexical mapping, and to bypass the challenging structural mapping problem that would lead to greater search space and variance. On the negative side, the structural isomorphic assumption limits the meaningfulness of the model."}], "references": [{"title": "Neural machine translation by jointly learning to align and translate", "author": ["Dzmitry Bahdanau", "KyunghyunCho", "Yoshua Bengio."], "venue": "Proceedings of ICLR 2015. San Diego, California.", "citeRegEx": "Bahdanau et al\\.,? 2015", "shortCiteRegEx": "Bahdanau et al\\.", "year": 2015}, {"title": "More accurate question answering on Freebase", "author": ["Hannah Bast", "Elmar Haussmann."], "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management. ACM, pages 1431\u20131440.", "citeRegEx": "Bast and Haussmann.,? 2015", "shortCiteRegEx": "Bast and Haussmann.", "year": 2015}, {"title": "Layers of interpretation: On grammar and compositionality", "author": ["Emily M Bender", "Dan Flickinger", "Stephan Oepen", "Woodley Packard", "Ann Copestake."], "venue": "Proceedings of the 11th International Conference on Computational Semantics. London, UK,", "citeRegEx": "Bender et al\\.,? 2015", "shortCiteRegEx": "Bender et al\\.", "year": 2015}, {"title": "Semantic parsing on Freebase from question-answer pairs", "author": ["Jonathan Berant", "AndrewChou", "Roy Frostig", "Percy Liang."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Seattle, Washington, pages 1533\u2013", "citeRegEx": "Berant et al\\.,? 2013", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "Semantic parsing via paraphrasing", "author": ["Jonathan Berant", "Percy Liang."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Baltimore, Maryland, pages 1415\u20131425.", "citeRegEx": "Berant and Liang.,? 2014", "shortCiteRegEx": "Berant and Liang.", "year": 2014}, {"title": "Imitation learning of agenda-based semantic parsers", "author": ["Jonathan Berant", "Percy Liang."], "venue": "Transactions of the Association for Computational Linguistics 3:545\u2013558.", "citeRegEx": "Berant and Liang.,? 2015", "shortCiteRegEx": "Berant and Liang.", "year": 2015}, {"title": "Evaluating induced CCG parsers on grounded semantic parsing", "author": ["Yonatan Bisk", "Siva Reddy", "John Blitzer", "Julia Hockenmaier", "Mark Steedman."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Austin,", "citeRegEx": "Bisk et al\\.,? 2016", "shortCiteRegEx": "Bisk et al\\.", "year": 2016}, {"title": "Question answering with subgraph embeddings", "author": ["Antoine Bordes", "Sumit Chopra", "Jason Weston."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Doha, Qatar, pages 615\u2013620.", "citeRegEx": "Bordes et al\\.,? 2014", "shortCiteRegEx": "Bordes et al\\.", "year": 2014}, {"title": "Large-scale semantic parsing via schema matching and lexicon", "author": ["Qingqing Cai", "Alexander Yates"], "venue": null, "citeRegEx": "Cai and Yates.,? \\Q2013\\E", "shortCiteRegEx": "Cai and Yates.", "year": 2013}, {"title": "Parsing as language modeling", "author": ["Do Kook Choe", "Eugene Charniak."], "venue": "Proceedings of the 2016", "citeRegEx": "Choe and Charniak.,? 2016", "shortCiteRegEx": "Choe and Charniak.", "year": 2016}, {"title": "Language to logical form with neural attention", "author": ["Li Dong", "Mirella Lapata."], "venue": "Proceedings of the", "citeRegEx": "Dong and Lapata.,? 2016", "shortCiteRegEx": "Dong and Lapata.", "year": 2016}, {"title": "Question answering over Freebase with multicolumn convolutional neural networks", "author": ["Li Dong", "Furu Wei", "Ming Zhou", "Ke Xu."], "venue": "Proceed-", "citeRegEx": "Dong et al\\.,? 2015", "shortCiteRegEx": "Dong et al\\.", "year": 2015}, {"title": "Transitionbased dependency parsing with stack long shortterm memory", "author": ["Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith."], "venue": "Proceedings of the 53rd Annual", "citeRegEx": "Dyer et al\\.,? 2015", "shortCiteRegEx": "Dyer et al\\.", "year": 2015}, {"title": "Recurrent neural network grammars", "author": ["Chris Dyer", "Adhiguna Kuncoro", "Miguel Ballesteros", "Noah A. Smith."], "venue": "Proceedings of the 2016 Con-", "citeRegEx": "Dyer et al\\.,? 2016", "shortCiteRegEx": "Dyer et al\\.", "year": 2016}, {"title": "A discriminative graph-based parser for the abstract meaning representation", "author": ["Jeffrey Flanigan", "Sam Thomson", "Jaime Carbonell", "Chris Dyer", "Noah A. Smith."], "venue": "Proceedings of the 52nd Annual", "citeRegEx": "Flanigan et al\\.,? 2014", "shortCiteRegEx": "Flanigan et al\\.", "year": 2014}, {"title": "FACC1: Freebase annotation of ClueWeb corpora, version 1 (release date 2013-06-26, format version 1, correction level", "author": ["Evgeniy Gabrilovich", "Michael Ringgaard", "Amarnag Subramanya"], "venue": null, "citeRegEx": "Gabrilovich et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Gabrilovich et al\\.", "year": 2013}, {"title": "OpenVocabulary Semantic Parsing with both Distributional Statistics and Formal Knowledge", "author": ["Matt Gardner", "Jayant Krishnamurthy."], "venue": "Pro-", "citeRegEx": "Gardner and Krishnamurthy.,? 2017", "shortCiteRegEx": "Gardner and Krishnamurthy.", "year": 2017}, {"title": "Graph parsing with s-graph grammars", "author": ["Jonas Groschwitz", "Alexander Koller", "Christoph Teichmann."], "venue": "Proceedings of the 53rd Annual Meet-", "citeRegEx": "Groschwitz et al\\.,? 2015", "shortCiteRegEx": "Groschwitz et al\\.", "year": 2015}, {"title": "Incorporating copying mechanism in sequence-to-sequence learning", "author": ["Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor OK Li."], "venue": "ACL .", "citeRegEx": "Gu et al\\.,? 2016", "shortCiteRegEx": "Gu et al\\.", "year": 2016}, {"title": "SPARQL 1.1 query language. W3C recommendation", "author": ["Steve Harris", "Andy Seaborne", "Eric Prud\u2019hommeaux"], "venue": null, "citeRegEx": "Harris et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Harris et al\\.", "year": 2013}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "Performance of graph query languages: comparison of cypher, gremlin and native access in Neo4j", "author": ["Florian Holzschuher", "Ren\u00e9 Peinl."], "venue": "Proceedings of the Joint EDBT/ICDT 2013 Workshops. ACM, pages 195\u2013204.", "citeRegEx": "Holzschuher and Peinl.,? 2013", "shortCiteRegEx": "Holzschuher and Peinl.", "year": 2013}, {"title": "Data recombination for neural semantic parsing", "author": ["Robin Jia", "Percy Liang."], "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Berlin, Germany, pages 12\u201322.", "citeRegEx": "Jia and Liang.,? 2016", "shortCiteRegEx": "Jia and Liang.", "year": 2016}, {"title": "Learning to Transform Natural to Formal Languages", "author": ["Rohit J. Kate", "Yuk Wah Wong", "Raymond J. Mooney."], "venue": "Proceedings for the 20th National Conference on Artificial Intelligence. Pittsburgh, Pennsylvania, pages 1062\u20131068.", "citeRegEx": "Kate et al\\.,? 2005", "shortCiteRegEx": "Kate et al\\.", "year": 2005}, {"title": "Segmental recurrent neural networks", "author": ["Lingpeng Kong", "Chris Dyer", "Noah A Smith."], "venue": "Proceedings of ICLR 2016. San Juan, Puerto Rico.", "citeRegEx": "Kong et al\\.,? 2016", "shortCiteRegEx": "Kong et al\\.", "year": 2016}, {"title": "Semantic parsing with semi-supervised sequential autoencoders", "author": ["Tom\u00e1\u0161 Ko\u010disk\u00fd", "G\u00e1bor Melis", "Edward Grefenstette", "Chris Dyer", "Wang Ling", "Phil Blunsom", "Karl Moritz Hermann."], "venue": "Proceedings of the 2016 Conference on Empirical Meth-", "citeRegEx": "Ko\u010disk\u00fd et al\\.,? 2016", "shortCiteRegEx": "Ko\u010disk\u00fd et al\\.", "year": 2016}, {"title": "Weakly supervised training of semantic parsers", "author": ["Jayant Krishnamurthy", "Tom Mitchell."], "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Jeju Is-", "citeRegEx": "Krishnamurthy and Mitchell.,? 2012", "shortCiteRegEx": "Krishnamurthy and Mitchell.", "year": 2012}, {"title": "Learning a Compositional Semantics for Freebase with an Open Predicate Vocabulary", "author": ["Jayant Krishnamurthy", "Tom M. Mitchell."], "venue": "Transactions of the Association for Computational Linguistics 3:257\u2013270.", "citeRegEx": "Krishnamurthy and Mitchell.,? 2015", "shortCiteRegEx": "Krishnamurthy and Mitchell.", "year": 2015}, {"title": "Inducing probabilistic CCG grammars from logical form with higherorder unification", "author": ["Tom Kwiatkowksi", "Luke Zettlemoyer", "Sharon Goldwater", "Mark Steedman."], "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language", "citeRegEx": "Kwiatkowksi et al\\.,? 2010", "shortCiteRegEx": "Kwiatkowksi et al\\.", "year": 2010}, {"title": "Scaling Semantic Parsers with On-the-Fly Ontology Matching", "author": ["Tom Kwiatkowski", "Eunsol Choi", "Yoav Artzi", "Luke Zettlemoyer."], "venue": "Proceedings of", "citeRegEx": "Kwiatkowski et al\\.,? 2013", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2013}, {"title": "Lexical generalization in CCG grammar induction for semantic parsing", "author": ["Tom Kwiatkowski", "Luke Zettlemoyer", "Sharon Goldwater", "Mark Steedman."], "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing.", "citeRegEx": "Kwiatkowski et al\\.,? 2011", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2011}, {"title": "Rationalizing neural predictions", "author": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola."], "venue": "Proceedings of", "citeRegEx": "Lei et al\\.,? 2016", "shortCiteRegEx": "Lei et al\\.", "year": 2016}, {"title": "A* CCG parsing with a supertag-factored model", "author": ["Mike Lewis", "Mark Steedman."], "venue": "Proceed-", "citeRegEx": "Lewis and Steedman.,? 2014", "shortCiteRegEx": "Lewis and Steedman.", "year": 2014}, {"title": "Lambda dependency-based compositional semantics", "author": ["Percy Liang."], "venue": "arXiv preprint arXiv:1309.4408 .", "citeRegEx": "Liang.,? 2013", "shortCiteRegEx": "Liang.", "year": 2013}, {"title": "Learning dependency-based compositional semantics", "author": ["Percy Liang", "Michael Jordan", "Dan Klein."], "venue": "Proceedings of the 49th Annual Meeting", "citeRegEx": "Liang et al\\.,? 2011", "shortCiteRegEx": "Liang et al\\.", "year": 2011}, {"title": "The stanford corenlp natural language processing toolkit", "author": ["Christopher Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven Bethard", "David McClosky."], "venue": "Proceedings of 52nd Annual", "citeRegEx": "Manning et al\\.,? 2014", "shortCiteRegEx": "Manning et al\\.", "year": 2014}, {"title": "Learning a natural language interface with neural programmer", "author": ["Arvind Neelakantan", "Quoc V Le", "Martin Abadi", "Andrew McCallum", "Dario Amodei."], "venue": "Proceedings of ICLR 2017. Toulon, France.", "citeRegEx": "Neelakantan et al\\.,? 2017", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2017}, {"title": "Compositional semantic parsing on semi-structured tables", "author": ["Panupong Pasupat", "Percy Liang."], "venue": "Proceedings of the 53rd Annual Meeting of the", "citeRegEx": "Pasupat and Liang.,? 2015", "shortCiteRegEx": "Pasupat and Liang.", "year": 2015}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."], "venue": "Proceedings of the 2014 Con-", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Large-scale semantic parsing without questionanswer pairs. Transactions of the Association for Computational Linguistics 2:377\u2013392", "author": ["Siva Reddy", "Mirella Lapata", "andMark Steedman"], "venue": null, "citeRegEx": "Reddy et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Reddy et al\\.", "year": 2014}, {"title": "Transforming dependency structures to logical forms for semantic parsing", "author": ["Siva Reddy", "Oscar T\u00e4ckstr\u00f6m", "Michael Collins", "Tom Kwiatkowski", "Dipanjan Das", "Mark Steedman", "Mirella Lapata"], "venue": null, "citeRegEx": "Reddy et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Reddy et al\\.", "year": 2016}, {"title": "Semimarkov conditional random fields for information extraction", "author": ["Sunita Sarawagi", "William W Cohen."], "venue": "Advances in Neural Information Processing Systems 17, MIT Press, pages 1185\u20131192.", "citeRegEx": "Sarawagi and Cohen.,? 2005", "shortCiteRegEx": "Sarawagi and Cohen.", "year": 2005}, {"title": "On generating characteristic-rich question sets for qa evaluation", "author": ["Yu Su", "Huan Sun", "Brian Sadler", "Mudhakar Srivatsa", "Izzeddin Gur", "Zenghui Yan", "Xifeng Yan."], "venue": "Proceedings of the 2016 Confer-", "citeRegEx": "Su et al\\.,? 2016", "shortCiteRegEx": "Su et al\\.", "year": 2016}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in Neural Information Processing Systems 27, MIT Press, pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "Simple and effective question answering with recurrent neural networks", "author": ["Ferhan Ture", "Oliver Jojic."], "venue": "arXiv preprint arXiv:1606.05029 .", "citeRegEx": "Ture and Jojic.,? 2016", "shortCiteRegEx": "Ture and Jojic.", "year": 2016}, {"title": "Grammar as a foreign language", "author": ["Oriol Vinyals", "\u0141ukasz Kaiser", "Terry Koo", "Slav Petrov", "Ilya Sutskever", "Geoffrey Hinton."], "venue": "Advances in Neural Information Processing Systems 28. MIT Press, pages 2773\u20132781.", "citeRegEx": "Vinyals et al\\.,? 2015", "shortCiteRegEx": "Vinyals et al\\.", "year": 2015}, {"title": "Learning for semantic parsing with statistical machine translation", "author": ["Yuk Wah Wong", "Raymond Mooney."], "venue": "Proceedings of the Human Language", "citeRegEx": "Wong and Mooney.,? 2006", "shortCiteRegEx": "Wong and Mooney.", "year": 2006}, {"title": "Question answering on Freebase via relation extraction and textual evidence", "author": ["Kun Xu", "Siva Reddy", "Yansong Feng", "Songfang Huang", "Dongyan Zhao."], "venue": "Proceedings of the 54th AnnualMeeting of", "citeRegEx": "Xu et al\\.,? 2016", "shortCiteRegEx": "Xu et al\\.", "year": 2016}, {"title": "Information extraction over structured data: Question answering with Freebase", "author": ["Xuchen Yao", "Benjamin Van Durme."], "venue": "Proceedings of the 52nd", "citeRegEx": "Yao and Durme.,? 2014", "shortCiteRegEx": "Yao and Durme.", "year": 2014}, {"title": "Semantic parsing via staged query graph generation: Question answering with knowledge base", "author": ["Wen-tau Yih", "Ming-Wei Chang", "Xiaodong He", "Jianfeng Gao."], "venue": "Proceedings of the 53rd Annual", "citeRegEx": "Yih et al\\.,? 2015", "shortCiteRegEx": "Yih et al\\.", "year": 2015}, {"title": "The value of semantic parse labeling for knowledge base question answering", "author": ["Wen-tau Yih", "Matthew Richardson", "Chris Meek", "MingWei Chang", "Jina Suh."], "venue": "Proceedings of the 54th Annual Meet-", "citeRegEx": "Yih et al\\.,? 2016", "shortCiteRegEx": "Yih et al\\.", "year": 2016}, {"title": "Learning to Parse Database Queries Using Inductive Logic Programming", "author": ["John M. Zelle", "Raymond J. Mooney."], "venue": "Proceedings of the 13th National Conference on Artificial Intelligence. Portland, Oregon, pages 1050\u20131055.", "citeRegEx": "Zelle and Mooney.,? 1996", "shortCiteRegEx": "Zelle and Mooney.", "year": 1996}, {"title": "Online learning of relaxed CCG grammars for parsing to logical form", "author": ["Luke Zettlemoyer", "Michael Collins."], "venue": "Proceedings of the 2007 Joint Con-", "citeRegEx": "Zettlemoyer and Collins.,? 2007", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2007}, {"title": "Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars", "author": ["Luke S. Zettlemoyer", "Michael Collins."], "venue": "Proceedings of 21st Conference in Uncertainilty in Artificial Intelligence. Edinburgh,", "citeRegEx": "Zettlemoyer and Collins.,? 2005", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2005}, {"title": "Type-driven incremental semantic parsing with polymorphism", "author": ["Kai Zhao", "Liang Huang."], "venue": "In", "citeRegEx": "Zhao and Huang.,? 2015", "shortCiteRegEx": "Zhao and Huang.", "year": 2015}], "referenceMentions": [{"referenceID": 51, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 53, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 46, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 28, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 34, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 3, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 14, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 37, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 17, "context": "Under the first approach, an utterance is parsed and grounded to a meaning representation directly via learning a task-specific grammar (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Wong and Mooney, 2006; Kwiatkowksi et al., 2010; Liang et al., 2011; Berant et al., 2013; Flanigan et al., 2014; Pasupat and Liang, 2015; Groschwitz et al., 2015).", "startOffset": 136, "endOffset": 354}, {"referenceID": 29, "context": "then mapped to a grounded representation (Kwiatkowski et al., 2013; Reddy et al., 2016, 2014; Krishnamurthy and Mitchell, 2015; Gardner and Krishnamurthy, 2017).", "startOffset": 41, "endOffset": 160}, {"referenceID": 27, "context": "then mapped to a grounded representation (Kwiatkowski et al., 2013; Reddy et al., 2016, 2014; Krishnamurthy and Mitchell, 2015; Gardner and Krishnamurthy, 2017).", "startOffset": 41, "endOffset": 160}, {"referenceID": 16, "context": "then mapped to a grounded representation (Kwiatkowski et al., 2013; Reddy et al., 2016, 2014; Krishnamurthy and Mitchell, 2015; Gardner and Krishnamurthy, 2017).", "startOffset": 41, "endOffset": 160}, {"referenceID": 2, "context": "A merit of the two-stage approach is that it creates reusable intermediate interpretations, which potentially enables the handling of unseen words and knowledge transfer across domains (Bender et al., 2015).", "startOffset": 185, "endOffset": 206}, {"referenceID": 0, "context": "The successful application of encoder-decoder models (Bahdanau et al., 2015; Sutskever et al., 2014) to a variety of NLP tasks has provided strong impetus to treat semantic parsing as a sequence transduction problem where an utterance is mapped to a target meaning representation in string format (Dong and Lapata, 2016; Jia and Liang, 2016; Ko\u010disk\u00fd et al.", "startOffset": 53, "endOffset": 100}, {"referenceID": 43, "context": "The successful application of encoder-decoder models (Bahdanau et al., 2015; Sutskever et al., 2014) to a variety of NLP tasks has provided strong impetus to treat semantic parsing as a sequence transduction problem where an utterance is mapped to a target meaning representation in string format (Dong and Lapata, 2016; Jia and Liang, 2016; Ko\u010disk\u00fd et al.", "startOffset": 53, "endOffset": 100}, {"referenceID": 10, "context": ", 2014) to a variety of NLP tasks has provided strong impetus to treat semantic parsing as a sequence transduction problem where an utterance is mapped to a target meaning representation in string format (Dong and Lapata, 2016; Jia and Liang, 2016; Ko\u010disk\u00fd et al., 2016).", "startOffset": 204, "endOffset": 270}, {"referenceID": 22, "context": ", 2014) to a variety of NLP tasks has provided strong impetus to treat semantic parsing as a sequence transduction problem where an utterance is mapped to a target meaning representation in string format (Dong and Lapata, 2016; Jia and Liang, 2016; Ko\u010disk\u00fd et al., 2016).", "startOffset": 204, "endOffset": 270}, {"referenceID": 25, "context": ", 2014) to a variety of NLP tasks has provided strong impetus to treat semantic parsing as a sequence transduction problem where an utterance is mapped to a target meaning representation in string format (Dong and Lapata, 2016; Jia and Liang, 2016; Ko\u010disk\u00fd et al., 2016).", "startOffset": 204, "endOffset": 270}, {"referenceID": 51, "context": "Such models still fall under the first approach, however, in contrast to previous work (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011) they reduce the need for domain-specific assumptions, grammar learning, and more generally extensive feature engineering.", "startOffset": 87, "endOffset": 162}, {"referenceID": 53, "context": "Such models still fall under the first approach, however, in contrast to previous work (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011) they reduce the need for domain-specific assumptions, grammar learning, and more generally extensive feature engineering.", "startOffset": 87, "endOffset": 162}, {"referenceID": 34, "context": "Such models still fall under the first approach, however, in contrast to previous work (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011) they reduce the need for domain-specific assumptions, grammar learning, and more generally extensive feature engineering.", "startOffset": 87, "endOffset": 162}, {"referenceID": 29, "context": "(Kwiatkowski et al., 2013), we induce intermediate representations in the form of predicateargument structures from data.", "startOffset": 0, "endOffset": 26}, {"referenceID": 26, "context": "Compared to most existing semantic parsers which employ a CKY style bottomup parsing strategy (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013; Berant et al., 2013; Berant and Liang, 2014), the transition-based approach we proposed does not require feature decomposition over structures and thereby enables the exploration of rich, non-local features.", "startOffset": 94, "endOffset": 194}, {"referenceID": 8, "context": "Compared to most existing semantic parsers which employ a CKY style bottomup parsing strategy (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013; Berant et al., 2013; Berant and Liang, 2014), the transition-based approach we proposed does not require feature decomposition over structures and thereby enables the exploration of rich, non-local features.", "startOffset": 94, "endOffset": 194}, {"referenceID": 3, "context": "Compared to most existing semantic parsers which employ a CKY style bottomup parsing strategy (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013; Berant et al., 2013; Berant and Liang, 2014), the transition-based approach we proposed does not require feature decomposition over structures and thereby enables the exploration of rich, non-local features.", "startOffset": 94, "endOffset": 194}, {"referenceID": 4, "context": "Compared to most existing semantic parsers which employ a CKY style bottomup parsing strategy (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013; Berant et al., 2013; Berant and Liang, 2014), the transition-based approach we proposed does not require feature decomposition over structures and thereby enables the exploration of rich, non-local features.", "startOffset": 94, "endOffset": 194}, {"referenceID": 6, "context": "We conduct experiments on four datasets, including GEOQUERY (which has logical forms; Zelle and Mooney 1996), SPADES (Bisk et al., 2016), WEBQUESTIONS (Berant et al.", "startOffset": 117, "endOffset": 136}, {"referenceID": 3, "context": ", 2016), WEBQUESTIONS (Berant et al., 2013), and GRAPHQUESTIONS (Su et al.", "startOffset": 22, "endOffset": 43}, {"referenceID": 42, "context": ", 2013), and GRAPHQUESTIONS (Su et al., 2016) (which have denotations).", "startOffset": 28, "endOffset": 45}, {"referenceID": 31, "context": "A sideproduct of our modeling framework is that the induced intermediate representations can contribute to rationalizing neural predictions (Lei et al., 2016).", "startOffset": 140, "endOffset": 158}, {"referenceID": 23, "context": "Grounded Meaning Representation We represent grounded meaning representations in FunQL (Kate et al., 2005) amongst many other alternatives such as lambda calculus (Zettlemoyer and Collins, 2005), \u03bb-DCS (Liang, 2013) or graph queries (Holzschuher and Peinl, 2013; Harris et al.", "startOffset": 87, "endOffset": 106}, {"referenceID": 53, "context": ", 2005) amongst many other alternatives such as lambda calculus (Zettlemoyer and Collins, 2005), \u03bb-DCS (Liang, 2013) or graph queries (Holzschuher and Peinl, 2013; Harris et al.", "startOffset": 64, "endOffset": 95}, {"referenceID": 33, "context": ", 2005) amongst many other alternatives such as lambda calculus (Zettlemoyer and Collins, 2005), \u03bb-DCS (Liang, 2013) or graph queries (Holzschuher and Peinl, 2013; Harris et al.", "startOffset": 103, "endOffset": 116}, {"referenceID": 21, "context": ", 2005) amongst many other alternatives such as lambda calculus (Zettlemoyer and Collins, 2005), \u03bb-DCS (Liang, 2013) or graph queries (Holzschuher and Peinl, 2013; Harris et al., 2013).", "startOffset": 134, "endOffset": 184}, {"referenceID": 19, "context": ", 2005) amongst many other alternatives such as lambda calculus (Zettlemoyer and Collins, 2005), \u03bb-DCS (Liang, 2013) or graph queries (Holzschuher and Peinl, 2013; Harris et al., 2013).", "startOffset": 134, "endOffset": 184}, {"referenceID": 45, "context": "to be predicted with recurrent neural networks (Vinyals et al., 2015; Choe and Charniak, 2016; Dyer et al., 2016).", "startOffset": 47, "endOffset": 113}, {"referenceID": 9, "context": "to be predicted with recurrent neural networks (Vinyals et al., 2015; Choe and Charniak, 2016; Dyer et al., 2016).", "startOffset": 47, "endOffset": 113}, {"referenceID": 13, "context": "to be predicted with recurrent neural networks (Vinyals et al., 2015; Choe and Charniak, 2016; Dyer et al., 2016).", "startOffset": 47, "endOffset": 113}, {"referenceID": 33, "context": "A more compact logical formulation which our method also applies to is \u03bb-DCS (Liang, 2013).", "startOffset": 77, "endOffset": 90}, {"referenceID": 13, "context": "We can generate the tree with a top-down, depth first transition system reminiscent of recurrent neural network grammars (RNNGs; Dyer et al. 2016).", "startOffset": 121, "endOffset": 146}, {"referenceID": 37, "context": "Alternative solutions in the traditional semantic parsing literature include a floating chart parser (Pasupat and Liang, 2015) which allows to construct logical predicates out of thin air.", "startOffset": 101, "endOffset": 126}, {"referenceID": 20, "context": "we encode the input buffer with a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) and the output stack with a stack-LSTM (Dyer et al.", "startOffset": 53, "endOffset": 87}, {"referenceID": 12, "context": "we encode the input buffer with a bidirectional LSTM (Hochreiter and Schmidhuber, 1997) and the output stack with a stack-LSTM (Dyer et al., 2015).", "startOffset": 127, "endOffset": 146}, {"referenceID": 0, "context": "We therefore compute at each time step an adaptively weighted representation of bt (Bahdanau et al., 2015) conditioned on the stack representation st.", "startOffset": 83, "endOffset": 106}, {"referenceID": 22, "context": "To choose a natural language term, we directly compute a probability distribution of all natural language terms (in the buffer) conditioned on the stack representation st and select the most relevant term (Jia and Liang, 2016; Gu et al., 2016):", "startOffset": 205, "endOffset": 243}, {"referenceID": 18, "context": "To choose a natural language term, we directly compute a probability distribution of all natural language terms (in the buffer) conditioned on the stack representation st and select the most relevant term (Jia and Liang, 2016; Gu et al., 2016):", "startOffset": 205, "endOffset": 243}, {"referenceID": 12, "context": "For the choice of composition function, we use a single-layer neural network as in Dyer et al. (2015), which takes as input the concatenated representation of the predicate and argument of the subtree.", "startOffset": 83, "endOffset": 102}, {"referenceID": 39, "context": "When only denotations are available, we compare surrogate meaning representations against our predictions (Reddy et al., 2014).", "startOffset": 106, "endOffset": 126}, {"referenceID": 36, "context": "mantic parsing based on reinforcement learning (Neelakantan et al., 2017).", "startOffset": 47, "endOffset": 73}, {"referenceID": 31, "context": "We optimize this objective with the method described in Lei et al. (2016).", "startOffset": 56, "endOffset": 74}, {"referenceID": 3, "context": "For all Freebase experiments, we followed previous work (Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) in additionally training a discriminative ranker to rerank grounded representations globally.", "startOffset": 56, "endOffset": 121}, {"referenceID": 4, "context": "For all Freebase experiments, we followed previous work (Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) in additionally training a discriminative ranker to rerank grounded representations globally.", "startOffset": 56, "endOffset": 121}, {"referenceID": 39, "context": "For all Freebase experiments, we followed previous work (Berant et al., 2013; Berant and Liang, 2014; Reddy et al., 2014) in additionally training a discriminative ranker to rerank grounded representations globally.", "startOffset": 56, "endOffset": 121}, {"referenceID": 3, "context": "The discriminative ranker is a maximumentropy model (Berant et al., 2013).", "startOffset": 52, "endOffset": 73}, {"referenceID": 51, "context": "GEOQUERY (Zelle and Mooney, 1996) contains 880 questions and database queries about US geography.", "startOffset": 9, "endOffset": 33}, {"referenceID": 6, "context": "SPADES (Bisk et al., 2016) con-", "startOffset": 7, "endOffset": 26}, {"referenceID": 15, "context": "tains 93,319 questions derived from CLUEWEB09 (Gabrilovich et al., 2013) sentences.", "startOffset": 46, "endOffset": 72}, {"referenceID": 39, "context": "the questions were created by randomly removing an entity, thus producing sentence-denotation pairs (Reddy et al., 2014).", "startOffset": 100, "endOffset": 120}, {"referenceID": 3, "context": "WEBQUESTIONS (Berant et al., 2013) contains 5,810 question-answer pairs.", "startOffset": 13, "endOffset": 34}, {"referenceID": 42, "context": "Finally, GRAPHQUESTIONS (Su et al., 2016) contains 5,166 question-answer pairs which were created by showing 500 Freebase graph queries to Amazon Mechanical Turk workers and asking them to paraphrase them into natural language.", "startOffset": 24, "endOffset": 41}, {"referenceID": 15, "context": "Entity mentions in SPADES have been automatically annotated with Freebase entities (Gabrilovich et al., 2013).", "startOffset": 83, "endOffset": 109}, {"referenceID": 15, "context": "Entity mentions in SPADES have been automatically annotated with Freebase entities (Gabrilovich et al., 2013). For WEBQUESTIONS and GRAPHQUESTIONS, we follow the procedure described in Reddy et al. (2016). We identify potential entity spans using seven handcrafted partof-speech patterns and associate them with Freebase entities obtained from the Freebase/KG API.", "startOffset": 84, "endOffset": 205}, {"referenceID": 47, "context": "tures includes the answer type as indicated by the last word in the Freebase relation (Xu et al., 2016).", "startOffset": 86, "endOffset": 103}, {"referenceID": 38, "context": "The word embeddings were initialized with Glove embeddings (Pennington et al., 2014).", "startOffset": 59, "endOffset": 84}, {"referenceID": 1, "context": "9 Bast and Haussmann (2015) 49.", "startOffset": 2, "endOffset": 28}, {"referenceID": 1, "context": "9 Bast and Haussmann (2015) 49.4 Berant and Liang (2015) 49.", "startOffset": 2, "endOffset": 57}, {"referenceID": 1, "context": "9 Bast and Haussmann (2015) 49.4 Berant and Liang (2015) 49.7 Reddy et al. (2016) 50.", "startOffset": 2, "endOffset": 82}, {"referenceID": 3, "context": "SEMPRE (Berant et al., 2013) 10.", "startOffset": 7, "endOffset": 28}, {"referenceID": 4, "context": "80 PARASEMPRE (Berant and Liang, 2014) 12.", "startOffset": 14, "endOffset": 38}, {"referenceID": 42, "context": "Numbers for comparison systems are from Su et al. (2016).", "startOffset": 40, "endOffset": 57}, {"referenceID": 10, "context": "All previous neural systems (Dong and Lapata, 2016; Jia and Liang, 2016) treat semantic parsing as a sequence transduction problem and use LSTMs to directly map utterances to logical forms.", "startOffset": 28, "endOffset": 72}, {"referenceID": 22, "context": "All previous neural systems (Dong and Lapata, 2016; Jia and Liang, 2016) treat semantic parsing as a sequence transduction problem and use LSTMs to directly map utterances to logical forms.", "startOffset": 28, "endOffset": 72}, {"referenceID": 10, "context": "All previous neural systems (Dong and Lapata, 2016; Jia and Liang, 2016) treat semantic parsing as a sequence transduction problem and use LSTMs to directly map utterances to logical forms. SCANNER yields performance improvements over these systems when using comparable data sources for training. Jia and Liang (2016) achieve better results with synthetic data that expands GEO-", "startOffset": 29, "endOffset": 319}, {"referenceID": 3, "context": "use average F1 (Berant et al., 2013) as our evaluation metric.", "startOffset": 15, "endOffset": 36}, {"referenceID": 3, "context": "use average F1 (Berant et al., 2013) as our evaluation metric. Previous work on this dataset has used a semantic parsing framework similar to ours where natural language is converted to an intermediate syntactic representation and then grounded to Freebase. Specifically, Bisk et al. (2016) evaluate the effectiveness of four different CCG parsers on the semantic parsing task when varying the amount of supervision required.", "startOffset": 16, "endOffset": 291}, {"referenceID": 28, "context": "1 Kwiatkowksi et al. (2010) 87.", "startOffset": 2, "endOffset": 28}, {"referenceID": 28, "context": "1 Kwiatkowksi et al. (2010) 87.9 Kwiatkowski et al. (2011) 88.", "startOffset": 2, "endOffset": 59}, {"referenceID": 28, "context": "1 Kwiatkowksi et al. (2010) 87.9 Kwiatkowski et al. (2011) 88.6 Kwiatkowski et al. (2013) 88.", "startOffset": 2, "endOffset": 90}, {"referenceID": 28, "context": "1 Kwiatkowksi et al. (2010) 87.9 Kwiatkowski et al. (2011) 88.6 Kwiatkowski et al. (2013) 88.0 Zhao and Huang (2015) 88.", "startOffset": 2, "endOffset": 117}, {"referenceID": 28, "context": "1 Kwiatkowksi et al. (2010) 87.9 Kwiatkowski et al. (2011) 88.6 Kwiatkowski et al. (2013) 88.0 Zhao and Huang (2015) 88.9 Liang et al. (2011) 91.", "startOffset": 2, "endOffset": 142}, {"referenceID": 6, "context": "Unsupervised CCG (Bisk et al., 2016) 24.", "startOffset": 17, "endOffset": 36}, {"referenceID": 6, "context": "8 Semi-supervised CCG (Bisk et al., 2016) 28.", "startOffset": 22, "endOffset": 41}, {"referenceID": 6, "context": "6 Supervised CCG (Bisk et al., 2016) 30.", "startOffset": 17, "endOffset": 36}, {"referenceID": 6, "context": "9 Rule-based system (Bisk et al., 2016) 31.", "startOffset": 20, "endOffset": 39}, {"referenceID": 44, "context": "For fair comparison, we also built a neural baseline that encodes an utterance with a recurrent neural network and then predicts a grounded meaning representation directly (Ture and Jojic, 2016; Yih et al., 2016).", "startOffset": 172, "endOffset": 212}, {"referenceID": 50, "context": "For fair comparison, we also built a neural baseline that encodes an utterance with a recurrent neural network and then predicts a grounded meaning representation directly (Ture and Jojic, 2016; Yih et al., 2016).", "startOffset": 172, "endOffset": 212}, {"referenceID": 1, "context": "It is important to note that Bast and Haussmann (2015) develop a question answering system, which contrary to ours cannot produce meaning representations whereas Berant and Liang (2015) propose a sophisticated agenda-based parser which is trained borrowing ideas from imitation learning.", "startOffset": 29, "endOffset": 55}, {"referenceID": 1, "context": "It is important to note that Bast and Haussmann (2015) develop a question answering system, which contrary to ours cannot produce meaning representations whereas Berant and Liang (2015) propose a sophisticated agenda-based parser which is trained borrowing ideas from imitation learning.", "startOffset": 29, "endOffset": 186}, {"referenceID": 1, "context": "It is important to note that Bast and Haussmann (2015) develop a question answering system, which contrary to ours cannot produce meaning representations whereas Berant and Liang (2015) propose a sophisticated agenda-based parser which is trained borrowing ideas from imitation learning. SCANNER is conceptually similar to Reddy et al. (2016) who also learn a semantic parser via intermediate representations which they generate based on the output of a dependency parser.", "startOffset": 29, "endOffset": 343}, {"referenceID": 1, "context": "It is important to note that Bast and Haussmann (2015) develop a question answering system, which contrary to ours cannot produce meaning representations whereas Berant and Liang (2015) propose a sophisticated agenda-based parser which is trained borrowing ideas from imitation learning. SCANNER is conceptually similar to Reddy et al. (2016) who also learn a semantic parser via intermediate representations which they generate based on the output of a dependency parser. SCANNER performs competitively despite not having access to any linguistically-informed syntactic structures. The second block in Table 3 reports the results of several neural systems. Xu et al. (2016) represent the state of the art on WEBQUESTIONS.", "startOffset": 29, "endOffset": 675}, {"referenceID": 42, "context": "the neural baseline model, and three symbolic systems presented in Su et al. (2016). SCANNER achieves a new state of the art on this dataset with a gain of 4.", "startOffset": 67, "endOffset": 84}, {"referenceID": 32, "context": "Specifically, we converted the questions to event-argument structures with EASYCCG (Lewis and Steedman, 2014), a high coverage and high accuracy CCG parser.", "startOffset": 83, "endOffset": 109}, {"referenceID": 35, "context": "icates based on the output of the Stanford POStagger (Manning et al., 2014) following the ordering VBD\u226bVBN\u226bVB\u226bVBP\u226bVBZ\u226bMD.", "startOffset": 53, "endOffset": 75}, {"referenceID": 29, "context": "Previous work (Kwiatkowski et al., 2013) models such cases by introducing collapsing (for manyto-one mapping) and expansion (for one-to-many mapping) operators.", "startOffset": 14, "endOffset": 40}, {"referenceID": 41, "context": "Within our current framework, these two types of structural mismatches can be handled with semi-Markov assumptions (Sarawagi and Cohen, 2005; Kong et al., 2016) in the parsing (i.", "startOffset": 115, "endOffset": 160}, {"referenceID": 24, "context": "Within our current framework, these two types of structural mismatches can be handled with semi-Markov assumptions (Sarawagi and Cohen, 2005; Kong et al., 2016) in the parsing (i.", "startOffset": 115, "endOffset": 160}], "year": 2017, "abstractText": "We introduce a neural semantic parser which is interpretable and scalable. Our model converts natural language utterances to intermediate, domain-general natural language representations in the form of predicate-argument structures, which are induced with a transition system and subsequently mapped to target domains. The semantic parser is trained end-to-end using annotated logical forms or their denotations. We achieve the state of the art on SPADES and GRAPHQUESTIONS and obtain competitive results on GEOQUERY and WEBQUESTIONS. The induced predicate-argument structures shed light on the types of representations useful for semantic parsing and how these are different from linguistically motivated ones.", "creator": "LaTeX with hyperref package"}}}