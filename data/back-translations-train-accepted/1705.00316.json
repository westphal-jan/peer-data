{"id": "1705.00316", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "30-Apr-2017", "title": "A Conditional Variational Framework for Dialog Generation", "abstract": "Deep latent variable models have been shown to facilitate the response generation for open-domain dialog systems. However, these latent variables are highly randomized, leading to uncontrollable generated responses. In this paper, we propose a framework allowing conditional response generation based on specific attributes. These attributes can be either manually assigned or automatically detected. Moreover, the dialog states for both speakers are modeled separately in order to reflect personal features. We validate this framework on two different scenarios, where the attribute refers to genericness and sentiment states respectively. The experiment result testified the potential of our model, where meaningful responses can be generated in accordance with the specified attributes.", "histories": [["v1", "Sun, 30 Apr 2017 13:52:49 GMT  (89kb,D)", "https://arxiv.org/abs/1705.00316v1", "Accepted by ACL2017"], ["v2", "Fri, 26 May 2017 08:08:53 GMT  (89kb,D)", "http://arxiv.org/abs/1705.00316v2", "Accepted by ACL2017"], ["v3", "Wed, 31 May 2017 19:58:49 GMT  (89kb,D)", "http://arxiv.org/abs/1705.00316v3", "Accepted by ACL2017"], ["v4", "Thu, 6 Jul 2017 09:03:45 GMT  (89kb,D)", "http://arxiv.org/abs/1705.00316v4", "Accepted by ACL2017"]], "COMMENTS": "Accepted by ACL2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["xiaoyu shen", "hui su", "yanran li", "wenjie li", "shuzi niu", "yang zhao", "akiko aizawa", "guoping long"], "accepted": true, "id": "1705.00316"}, "pdf": {"name": "1705.00316.pdf", "metadata": {"source": "CRF", "title": "A Conditional Variational Framework for Dialog Generation", "authors": ["Xiaoyu Shen", "Hui Su", "Yanran Li", "Wenjie Li", "Shuzi Niu", "Yang Zhao", "Akiko Aizawa", "Guoping Long"], "emails": ["(suhui15@mails.ucas.ac.cn)", "(xshen@lsv.uni-saarland.de)."], "sections": [{"heading": "1 Introduction", "text": "In fact, it is such that most people who are able to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to fight, to move, to fight, to fight, to fight, to move, to fight, to fight, to fight, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to fight, to move, to fight, to fight, to move, to move, to move, to move, to fight, to move, to fight, to move, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to fight, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move, to move,"}, {"heading": "2 Models", "text": "In order to create a better dialog context, we build a hierarchically recurring encoder decoder with separate context models (SPHRED). In this section, we first present the concept of SPHRED, then explain the conditional variation framework and two application scenarios."}, {"heading": "2.1 SPHRED", "text": "Let w1,.., wN be a dialogue with N utterances, where wn = (wn, 1,.., wn, Mn) is the n-th utterance. The probability distribution of the utterance sequence factorises the dialog context up to step. If we model the dialog context through a single recurring neural network (RNN), it can only represent a general dialog state, but does not capture the respective status for different speakers. This is not applicable if we derive implicit personal attributes from it and use them to influence the comprehension process."}, {"heading": "2.2 Conditional Variational Framework", "text": "UAEs have been used for text generation in (Bowman et al., 2015; Semeniuta et al., 2017), where texts are synthesized from latent variables. Based on this idea, we assume that every utterance wn comes with a corresponding label yn and latent variable zn. The generation of zn and wn is conditioned by the dialogue context provided by SPHRED, and this additional class designation yn. This includes 2 situations in which the label of the next sequence is known (as for scenario 1 in section 2.3) or not (Section 2.4). For each utterance, the latent variable zn is first sampled from a previous distribution. The entire dialogue can be explained by the generative process: P\u03b8 (zn, wn \u2212 11) = N (before, before) or not (2)."}, {"heading": "2.3 Scenario 1", "text": "A major focus in current research is on avoiding generic responses, so in the first scenario, we have the label y specify whether the corresponding sequence is a generic response, with y = 1 if the sequence is generic and y = 0 otherwise. To obtain these labels, we manually have a list of generic sentences such as \"I have no idea,\" \"I don't know,\" etc. Sequences containing such a phrase are defined as generic, which together account for about 2 percent of the entire corpus. If the label is set to 0, we expect at test time that the generated response should be largely assigned to the non-generic class. No prediction is required, so the training costs do not include the first item in formula 5. This scenario is intended to show that our framework can explicitly control which class of responses should be generated by assigning corresponding values to the label."}, {"heading": "2.4 Scenario 2", "text": "In the second scenario, we experiment with the assignment of imitated sentiment tags to generated responses. The personal sentiment is simulated by appending:),: (or: P to the end of each utterance, representing positive, negative or neutral sentiment. For example, if we append \":)\" to the original \"OK,\" the resulting \"OK:)\" becomes positive. The initial utterance of each speaker is randomly marked. We consider two rules for the tags of the next utterance. Rule 1 restricts the sentiment tag to remain constant for both speakers. Rule 2 assigns the sentiment of the next utterance to the average of the previous two. Namely, if one is positive and the other negative, the next response would be neutral. The label y represents the sentiment tag, which is unknown at the time of the test and must be predicted from the context. The probability qIV (yn | wn \u2212 11) is modelled by supplying neural networks."}, {"heading": "3 Experiments", "text": "We conducted our experiments with the Ubuntu dialog Corpus (Lowe et al., 2015), which contains about 500,000 multiturn dialogs, with the vocabulary set to the most common 20,000 words, all letters translated into lowercase letters, and words from the out-of-vocabulary (OOV) processed as \"tokens.\""}, {"heading": "3.1 Training Procedures", "text": "Hyperparameters of the model were set as in the VHRED model, except that we halved the RNN context dimension. Encoders, context and decoder RNNNs all use the structure of the Gated Recurrent Unit (GRU) (Cho et al., 2014). Labels were initialized on size 100 embedding and word vectors with the pubic Word2Vec embedding trained on Google News Corpus1. Subsequently (Bowman et al., 2015), 25% of the words in the decoder were randomly discarded. We multiplied the KL divergence and classification error by a scalar that starts from zero and gradually increases so that the training would initially focus on stochastic latent variables. At test time, we distributed the answers by beam search by beam size to 5 (Graves, 2012) and the tokens were not generated."}, {"heading": "3.2 Evaluation", "text": "Accurate automatic evaluation of dialogue generation is difficult (Galley et al., 2015; Pietquin and Hastie, 2013).In our experiment, we performed three embedded assessments (average, greedy and extreme) of all our models that map responses into vector space and calculate cosinal similarity. Although not necessarily accurate, embedded metrics can largely measure semantic similarity and test the ability to successfully generate an answer that shares a similar theme with the golden answer. In (Liu et al., 2016), the results of a GRU language model (LM), HRED and VHRED were also provided for comparison. For the two scenarios in our framework, we continued to measure the percentage of responses generated that correspond to the correct labels (accuracy).In (Liu et al., 2016), current popular metrics were not well correlated with human judgments."}, {"heading": "3.3 Results of Metric-based Evaluation", "text": "As shown in Table 1, SPHRED outperforms both HRED and LM on all three embedded metrics. This implies that separating the single-line context RNN into two independent parts can actually result in better context representation. It is worth noting that the size of the context RNN hidden states in SPHRED is only half as large as in HRED, but it still behaves better with fewer parameters. Therefore, it makes sense to apply this context information to our frame.The last 4 lines in Table 1 show the results of our framework applied in two scenarios mentioned in Section 2.3 and 2.4. SCENE1-B correspond to Scenario 1 with the label fixed as 1 and 0. 90.9% of the responses generated2All volunteers are well-educated students who have a bachelor's degree in computer science or above."}, {"heading": "3.4 Results of Human Evaluation", "text": "We conducted human assessments of VHRED and our framework (Table 3). All models have similar values, except SCENE1-A receive lower values in terms of coherence. This can be explained by the fact that SCENE1-A is trained to generate only generic responses, limiting its ability to account for coherence. VHRED and Scenario 2 are close to each other. Scenario 1 receives extreme values for diversity due to the label's effect. Generally, the statistical results of human assessments of sentence quality are very similar between the VHRED model and our framework. This is consistent with the metric results and supports the conclusion of Section 3.3. Although the sample size is relatively small and human judgments can necessarily be disturbed by subjective factors, we believe that these results may shed some light on our understanding of our framework. A portion of the responses generated can be viewed in Table 2."}, {"heading": "4 Discussion and future work", "text": "In this paper, we propose a conditional frame of variation for dialogue generation and verify it using two scenarios. To model the state of dialogue for both speakers separately, we first developed the SPHRED structure to provide the context vector for our framework. Our evaluation results show that SPHRED itself can provide a better context representation than HRED and help generate higher quality responses. In both scenarios, our framework can successfully learn to generate answers according to the predefined labels. Although limited to an external label, the score of the generated responses has not significantly decreased, which means that we restrict generation within a certain class while maintaining the quality.The manually defined rules, although primitive, represent two most frequently occurring mood changes in reality. The results showed the potential of our model to adapt to future scenarios, we just need to apply the classifier to cope with the complex emotions."}, {"heading": "5 Acknowledgement", "text": "This work was supported by the National Natural Science of China under grant numbers 61602451, 61672445 and JSPS KAKENHI grant numbers 15H02754, 16K12546."}], "references": [{"title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems", "author": ["Mart\u0131\u0301n Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"], "venue": null, "citeRegEx": "Abadi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Abadi et al\\.", "year": 2016}, {"title": "Generating sentences from a continuous space", "author": ["Samuel R Bowman", "Luke Vilnis", "Oriol Vinyals", "Andrew M Dai", "Rafal Jozefowicz", "Samy Bengio."], "venue": "arXiv preprint arXiv:1511.06349 .", "citeRegEx": "Bowman et al\\.,? 2015", "shortCiteRegEx": "Bowman et al\\.", "year": 2015}, {"title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation", "author": ["Kyunghyun Cho", "Bart Van Merri\u00ebnboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."], "venue": "arXiv preprint", "citeRegEx": "Cho et al\\.,? 2014", "shortCiteRegEx": "Cho et al\\.", "year": 2014}, {"title": "deltableu: A discriminative metric for generation tasks with intrinsically diverse targets", "author": ["Michel Galley", "Chris Brockett", "Alessandro Sordoni", "Yangfeng Ji", "Michael Auli", "Chris Quirk", "Margaret Mitchell", "Jianfeng Gao", "Bill Dolan."], "venue": "arXiv", "citeRegEx": "Galley et al\\.,? 2015", "shortCiteRegEx": "Galley et al\\.", "year": 2015}, {"title": "Sequence transduction with recurrent neural networks", "author": ["Alex Graves."], "venue": "arXiv preprint arXiv:1211.3711 .", "citeRegEx": "Graves.,? 2012", "shortCiteRegEx": "Graves.", "year": 2012}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "arXiv preprint arXiv:1412.6980 .", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Semi-supervised learning with deep generative models", "author": ["Diederik P Kingma", "Shakir Mohamed", "Danilo Jimenez Rezende", "Max Welling."], "venue": "Advances in Neural Information Processing Systems. pages 3581\u20133589.", "citeRegEx": "Kingma et al\\.,? 2014", "shortCiteRegEx": "Kingma et al\\.", "year": 2014}, {"title": "Autoencoding variational bayes", "author": ["Diederik P Kingma", "Max Welling."], "venue": "arXiv preprint arXiv:1312.6114 .", "citeRegEx": "Kingma and Welling.,? 2013", "shortCiteRegEx": "Kingma and Welling.", "year": 2013}, {"title": "How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation", "author": ["Chia-Wei Liu", "Ryan Lowe", "Iulian V Serban", "Michael Noseworthy", "Laurent Charlin", "Joelle Pineau."], "venue": "arXiv preprint", "citeRegEx": "Liu et al\\.,? 2016", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "The ubuntu dialogue corpus: A large dataset for research in unstructured multi-turn dialogue systems", "author": ["Ryan Lowe", "Nissan Pow", "Iulian Serban", "Joelle Pineau."], "venue": "arXiv preprint arXiv:1506.08909 .", "citeRegEx": "Lowe et al\\.,? 2015", "shortCiteRegEx": "Lowe et al\\.", "year": 2015}, {"title": "A survey on metrics for the evaluation of user simulations", "author": ["Olivier Pietquin", "Helen Hastie."], "venue": "The knowledge engineering review 28(01):59\u201373.", "citeRegEx": "Pietquin and Hastie.,? 2013", "shortCiteRegEx": "Pietquin and Hastie.", "year": 2013}, {"title": "Stochastic backpropagation and approximate inference in deep generative models", "author": ["Danilo Jimenez Rezende", "Shakir Mohamed", "Daan Wierstra."], "venue": "arXiv preprint arXiv:1401.4082 .", "citeRegEx": "Rezende et al\\.,? 2014", "shortCiteRegEx": "Rezende et al\\.", "year": 2014}, {"title": "A hybrid convolutional variational autoencoder for text generation", "author": ["Stanislau Semeniuta", "Aliaksei Severyn", "Erhardt Barth."], "venue": "arXiv preprint arXiv:1702.02390 .", "citeRegEx": "Semeniuta et al\\.,? 2017", "shortCiteRegEx": "Semeniuta et al\\.", "year": 2017}, {"title": "Building end-to-end dialogue systems using generative hierarchical neural network models", "author": ["Iulian V Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau."], "venue": "AAAI .", "citeRegEx": "Serban et al\\.,? 2016", "shortCiteRegEx": "Serban et al\\.", "year": 2016}, {"title": "A hierarchical latent variable encoder-decoder model for generating dialogues", "author": ["Iulian Vlad Serban", "Alessandro Sordoni", "Ryan Lowe", "Laurent Charlin", "Joelle Pineau", "Aaron Courville", "Yoshua Bengio."], "venue": "AAAI .", "citeRegEx": "Serban et al\\.,? 2017", "shortCiteRegEx": "Serban et al\\.", "year": 2017}, {"title": "Neural responding machine for short-text conversation", "author": ["Lifeng Shang", "Zhengdong Lu", "Hang Li."], "venue": "arXiv preprint arXiv:1503.02364 .", "citeRegEx": "Shang et al\\.,? 2015", "shortCiteRegEx": "Shang et al\\.", "year": 2015}, {"title": "Learning structured output representation using deep conditional generative models", "author": ["Kihyuk Sohn", "Honglak Lee", "Xinchen Yan."], "venue": "Advances in Neural Information Processing Systems. pages 3483\u20133491.", "citeRegEx": "Sohn et al\\.,? 2015", "shortCiteRegEx": "Sohn et al\\.", "year": 2015}, {"title": "A neural network approach to context-sensitive generation of conversational responses", "author": ["Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Margaret Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan."], "venue": "arXiv preprint", "citeRegEx": "Sordoni et al\\.,? 2015", "shortCiteRegEx": "Sordoni et al\\.", "year": 2015}, {"title": "Sequence to sequence learning with neural networks", "author": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."], "venue": "Advances in neural information processing systems. pages 3104\u20133112.", "citeRegEx": "Sutskever et al\\.,? 2014", "shortCiteRegEx": "Sutskever et al\\.", "year": 2014}, {"title": "A neural conversational model", "author": ["Oriol Vinyals", "Quoc Le."], "venue": "arXiv preprint arXiv:1506.05869 .", "citeRegEx": "Vinyals and Le.,? 2015", "shortCiteRegEx": "Vinyals and Le.", "year": 2015}, {"title": "Attribute2image: Conditional image generation from visual attributes", "author": ["Xinchen Yan", "Jimei Yang", "Kihyuk Sohn", "Honglak Lee."], "venue": "European Conference on Computer Vision. Springer, pages 776\u2013 791.", "citeRegEx": "Yan et al\\.,? 2016", "shortCiteRegEx": "Yan et al\\.", "year": 2016}, {"title": "Attention with intention for a neural network conversation model", "author": ["Kaisheng Yao", "Geoffrey Zweig", "Baolin Peng."], "venue": "arXiv preprint arXiv:1510.08565 .", "citeRegEx": "Yao et al\\.,? 2015", "shortCiteRegEx": "Yao et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 18, "context": "Seq2seq neural networks, ever since the successful application in machine translation (Sutskever et al., 2014), have demonstrated impressive results on dialog generation and spawned a great deal of variants (Vinyals and Le, 2015; Yao et al.", "startOffset": 86, "endOffset": 110}, {"referenceID": 19, "context": ", 2014), have demonstrated impressive results on dialog generation and spawned a great deal of variants (Vinyals and Le, 2015; Yao et al., 2015; Sordoni et al., 2015; Shang et al., 2015).", "startOffset": 104, "endOffset": 186}, {"referenceID": 21, "context": ", 2014), have demonstrated impressive results on dialog generation and spawned a great deal of variants (Vinyals and Le, 2015; Yao et al., 2015; Sordoni et al., 2015; Shang et al., 2015).", "startOffset": 104, "endOffset": 186}, {"referenceID": 17, "context": ", 2014), have demonstrated impressive results on dialog generation and spawned a great deal of variants (Vinyals and Le, 2015; Yao et al., 2015; Sordoni et al., 2015; Shang et al., 2015).", "startOffset": 104, "endOffset": 186}, {"referenceID": 15, "context": ", 2014), have demonstrated impressive results on dialog generation and spawned a great deal of variants (Vinyals and Le, 2015; Yao et al., 2015; Sordoni et al., 2015; Shang et al., 2015).", "startOffset": 104, "endOffset": 186}, {"referenceID": 14, "context": "cope with this problem, (Serban et al., 2017) proposed a variational hierarchical encoder-decoder model (VHRED) that brought the idea of varia-", "startOffset": 24, "endOffset": 45}, {"referenceID": 7, "context": "tional auto-encoders (VAE) (Kingma and Welling, 2013; Rezende et al., 2014) into dialog generation.", "startOffset": 27, "endOffset": 75}, {"referenceID": 11, "context": "tional auto-encoders (VAE) (Kingma and Welling, 2013; Rezende et al., 2014) into dialog generation.", "startOffset": 27, "endOffset": 75}, {"referenceID": 6, "context": "model (Kingma et al., 2014).", "startOffset": 6, "endOffset": 27}, {"referenceID": 16, "context": "The whole network structure functions like a conditional VAE (Sohn et al., 2015; Yan et al., 2016).", "startOffset": 61, "endOffset": 98}, {"referenceID": 20, "context": "The whole network structure functions like a conditional VAE (Sohn et al., 2015; Yan et al., 2016).", "startOffset": 61, "endOffset": 98}, {"referenceID": 13, "context": "We decomposes a dialog into two levels: sequences of utterances and sub-sequences of words, as in (Serban et al., 2016).", "startOffset": 98, "endOffset": 119}, {"referenceID": 1, "context": "VAEs have been used for text generation in (Bowman et al., 2015; Semeniuta et al., 2017), where texts are synthesized from latent variables.", "startOffset": 43, "endOffset": 88}, {"referenceID": 12, "context": "VAEs have been used for text generation in (Bowman et al., 2015; Semeniuta et al., 2017), where texts are synthesized from latent variables.", "startOffset": 43, "endOffset": 88}, {"referenceID": 9, "context": "We conducted our experiments on the Ubuntu dialog Corpus (Lowe et al., 2015), which contains", "startOffset": 57, "endOffset": 76}, {"referenceID": 2, "context": "text and decoder RNNs all make use of the Gated Recurrent Unit (GRU) structure (Cho et al., 2014).", "startOffset": 79, "endOffset": 97}, {"referenceID": 1, "context": "Following (Bowman et al., 2015), 25% of the words in the decoder were randomly dropped.", "startOffset": 10, "endOffset": 31}, {"referenceID": 4, "context": "At test time, we outputted responses using beam search with beam size set to 5 (Graves, 2012) and <unk> tokens were prevented from being generated.", "startOffset": 79, "endOffset": 93}, {"referenceID": 0, "context": "We implemented all the models with the open-sourced Python library Tensorflow (Abadi et al., 2016) and optimized using the Adam optimizer (Kingma and Ba, 2014).", "startOffset": 78, "endOffset": 98}, {"referenceID": 5, "context": ", 2016) and optimized using the Adam optimizer (Kingma and Ba, 2014).", "startOffset": 47, "endOffset": 68}, {"referenceID": 3, "context": "Accurate automatic evaluation of dialog generation is difficult (Galley et al., 2015; Pietquin and Hastie, 2013).", "startOffset": 64, "endOffset": 112}, {"referenceID": 10, "context": "Accurate automatic evaluation of dialog generation is difficult (Galley et al., 2015; Pietquin and Hastie, 2013).", "startOffset": 64, "endOffset": 112}, {"referenceID": 8, "context": "In our experiment, we conducted three embedding-based evaluations (average, greedy and extrema) (Liu et al., 2016) on all our models, which map responses into vector space and compute the cosine similarity.", "startOffset": 96, "endOffset": 114}, {"referenceID": 8, "context": "In (Liu et al., 2016), current popular", "startOffset": 3, "endOffset": 21}], "year": 2017, "abstractText": "Deep latent variable models have been shown to facilitate the response generation for open-domain dialog systems. However, these latent variables are highly randomized, leading to uncontrollable generated responses. In this paper, we propose a framework allowing conditional response generation based on specific attributes. These attributes can be either manually assigned or automatically detected. Moreover, the dialog states for both speakers are modeled separately in order to reflect personal features. We validate this framework on two different scenarios, where the attribute refers to genericness and sentiment states respectively. The experiment result testified the potential of our model, where meaningful responses can be generated in accordance with the specified attributes.", "creator": "LaTeX with hyperref package"}}}