{"id": "1705.00441", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-May-2017", "title": "Learning Topic-Sensitive Word Representations", "abstract": "Distributed word representations are widely used for modeling words in NLP tasks. Most of the existing models generate one representation per word and do not consider different meanings of a word. We present two approaches to learn multiple topic-sensitive representations per word by using Hierarchical Dirichlet Process. We observe that by modeling topics and integrating topic distributions for each document we obtain representations that are able to distinguish between different meanings of a given word. Our models yield statistically significant improvements for the lexical substitution task indicating that commonly used single word representations, even when combined with contextual information, are insufficient for this task.", "histories": [["v1", "Mon, 1 May 2017 08:16:56 GMT  (359kb,D)", "http://arxiv.org/abs/1705.00441v1", "5 pages, 1 figure, Accepted at ACL 2017"]], "COMMENTS": "5 pages, 1 figure, Accepted at ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["marzieh fadaee", "arianna bisazza", "christof monz"], "accepted": true, "id": "1705.00441"}, "pdf": {"name": "1705.00441.pdf", "metadata": {"source": "CRF", "title": "Learning Topic-Sensitive Word Representations", "authors": ["Marzieh Fadaee", "Arianna Bisazza", "Christof Monz"], "emails": ["m.fadaee@uva.nl", "a.bisazza@uva.nl", "c.monz@uva.nl"], "sections": [{"heading": "1 Introduction", "text": "Word representations in the form of dense vectors, or word embeddings, capture multiple semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016). Most of the existing models generate one representation per word and do not differentiate between different meanings of a word. However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010). Several attempts have been made to build repositories for the meaning of a word (Miller, 1995; Navigli and Ponzetto, 2010), but this is cumbersome and limited to a few languages. Furthermore, defining a universal set of words is challenging, as ambiguous words can exist on many levels of grandeur."}, {"heading": "2 Topic-Sensitive Representations", "text": "In this section we describe the proposed models. To learn topics from a corpus, we use HDP (Teh et al., 2006; Lau et al., 2014). The main advantage of this model compared to non-hierarchical methods such as the Chinese Restaurant Process (CRP) is that each document in the corpus is modeled using a hybrid model of topics shared between all documents (Teh et al., 2005; Brody and Lapata, 2009). HDP provides two groups of distributions that we use in our methods: distributions of topics for words in the vocabulary and distributions of topics for documents in the corpus. Similar to Neelakantan et al. (2014), we use adjacent words to recognize the meaning of the context, but we also use the two HDP-ar Xiv: 170 5.00 441v 1 [cs.C L] 1M ay2 017tributions."}, {"heading": "2.1 Hard Topic-Labeled Representations", "text": "Our first model variant (Figure 1 (a)) is based on hard labeling, simply treating each word-topic pair as a separate vocabulary entry. To reduce the conciseness on the context page and share information between similar contexts at the word level, we use topic representations for target words (input to the network) and default word representations for context words (output). Note that this results in different input and output vocabularies. The training goal is then to determine the log probability of context words wi'j against the target word-topic pair w\u03c4i: LHardT -SG \"1II\" 1\u0442'c\u010fj\u010fc j \u2030 0log ppwi'j | w\u03c4i qwhere I is the number of words in the training corpus, c is the context size and square the topic achieved by HDP extraction of the word HDP-q context."}, {"heading": "2.2 Soft Topic-Labeled Representations", "text": "As a soft alternative, we can directly include the distributions estimated by the HDP for each document (Figure 1 (c)). Specifically, for each update, we use the distribution of topics to calculate a weighted sum of the word-topic representations (r2): hSTLEpwiq \"T \u00ffk\" 1 pp\u03c4k | diq r2pw\u03c4ki q (3), where T is the total number of topics, di is the document containing wi, and pp\u03c4k | diq is the probability that the HDP will assign the topic \u03c4k to Document di. The training objective for this model is: LSoftT -SG \"1II \u0432ki q\" 1\u0442'c\u010fj\u010fc j \u0445 0log ppwi'j | wi, \u03c4qwhere. This is the topic of the document learned from the HDP. The STLE model has the advantage of applying the distribution directly to the topics of the Skipgram model."}, {"heading": "2.3 Embeddings for Polysemous Words", "text": "The representations derived from our models are designed to capture the meaning of a word in different themes. We will now examine whether these representations can distinguish between different word senses. Table 1 provides examples of the closest neighbours. For comparison, we include our own baseline, i.e. embeddings that we have learned with Skipgram on our corpus, as well as Word2Vec (Mikolov et al., 2013b) and GloVe embeddings (Pennington et al., 2014), which are pre-trained on large data sets. In the first example, the word bat has two different meanings: animal or sports equipment. We can see that the closest neighbours of the baseline and pre-trained word representations either revolve around a primary, i.e. most often the meaning of the word, or it is a mixture of different meanings. Theme-sensitive representations, on the other hand, correctly distinguish between the two different meanings. A similar pattern is observed for the word jaguar and its two meanings: the word or animal. The last example illustrates that despite the fact that we are more sensitive to different meanings, it is not."}, {"heading": "3 Evaluation", "text": "In this section we present the structure of our experiments and evaluate empirically our approach to contextual word similarity and lexical substitution tasks."}, {"heading": "3.1 Experimental setup", "text": "All word representations are learned on the English Wikipedia corpus, which contains 4.8M documents (1B characters). Once the topics are learned, we run HDP on the entire corpus to obtain the word topic name (see Section 2.1) and the topic distribution at document level (Section 2.2). We randomly train each model variant with window size c \"10 and different embedding sizes (100, 300, 600). We compare our models with multiple baselines: Skipgram (SGE) and the most powerful multisense embedding model per word type (MSSG) (Neelakantan et al., 2014). All model variants are trained with the same settings based on the same training data and follow suggestions from Mikolov et al. (2013a) and Levy et al. (2015)."}, {"heading": "3.2 Context-Aware Word Similarity Task", "text": "Despite its shortcomings (Faruqui et al., 2016), word similarity remains the most commonly used method of evaluation in literature. Several test sets are available, but in almost all of them pairs of words are taken out of context. To our knowledge, the only word similarity data set that provides the word context is SCWS (Huang et al., 2012). To evaluate our models on SCWS, we use HDP on the data that treat the context of each word as a separate document. We calculate the similarity of each word pair as follows: Simpw1, w2q \"cosphpw1q, hpw2qqwhere hpwiq refers to one of the topic-sensitive representations defined in Section 2. Note that w1 and w2 can refer to the same word.Table 2 provides the correlation values of the spearman for different models compared to the human ranking. We see that with the dimensions 100 and 300 of our models achieve slight improvements over the basic line of SSG (the 2014 MSG model)."}, {"heading": "3.3 Lexical Substitution Task", "text": "This task requires identifying the best substitutions for a word in a sentential context. The premise of many polysemous target words makes this task more suitable for evaluating meaning embeddings. (2015) We have the largest substitutions of different instances and rank them by the number of annotations they have selected for a given context. We use two evaluation approaches: LS-SE07 and Navigli, 2007), and LS-CIC (2014).Unlike previous work (Szarvas et al., 2013; Kremer et al., 2014; Melamud et al., 2015) we do not use syntactic information motivated by the fact that high-quality parsers are not available for most languages. The evaluation is done by calculating the Generalized Average Precision (GAP) (Kishida, 2005)."}, {"heading": "4 Related Work", "text": "While the most commonly used approaches learn embedding per word type (Mikolov et al., 1We use the non-parametric rank-based Mann-Whitney-Wilcoxon test (Sprent and Smeeton, 2016) to verify statistically significant differences between word strokes. 2013a; Pennington et al., 2014), current studies focus on multiple embedding per word due to the ambiguous nature of language (Qiu et al., 2016). Huang et al. (2012) group word contexts and use the average embedding of each cluster as a literal embedding, which results in improvements in a word similarity task. Neelakantan et al. (2014) suggest two approaches, both based on clustering word contexts: In the first, they fix the number of senses manually, and in the second, they use an ad-hoc-gifted method that assigns a new meaning to a given word to explain a particular representation between two existing contexts, when used in two contexts)."}, {"heading": "5 Conclusions", "text": "We have introduced an approach to learning topic-sensitive word representation that takes advantage of the context of words at the document level and does not require annotated data or linguistic resources. Our assessment of the lexical substitution task suggests that topic distributions capture the meaning of the word to some extent. Furthermore, we achieve statistically significant improvements in the lexical substitution task without using syntactical information, and the best results are achieved by our hard-to-label model, which learns topic-sensitive representations by assigning topics to target words."}, {"heading": "Acknowledgments", "text": "This research was partly funded by the Dutch Organisation for Scientific Research (NWO) under project numbers 639,022,213 and 639,021,646, as well as a Google Faculty Research Award. We thank the anonymous reviewers for their helpful comments."}], "references": [{"title": "Bayesian word sense induction", "author": ["Samuel Brody", "Mirella Lapata."], "venue": "Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009). Association for Computational Linguistics, Athens, Greece, pages 103\u2013111.", "citeRegEx": "Brody and Lapata.,? 2009", "shortCiteRegEx": "Brody and Lapata.", "year": 2009}, {"title": "Problems with evaluation of word embeddings using word similarity tasks", "author": ["Manaal Faruqui", "Yulia Tsvetkov", "Pushpendre Rastogi", "Chris Dyer."], "venue": "Proc. of the 1st Workshop on Evaluating Vector Space Representations for NLP.", "citeRegEx": "Faruqui et al\\.,? 2016", "shortCiteRegEx": "Faruqui et al\\.", "year": 2016}, {"title": "A word embedding approach to identifying verb\u2013noun idiomatic combinations", "author": ["Waseem Gharbieh", "Virendra C Bhavsar", "Paul Cook."], "venue": "Proc. of the 12th Workshop on Multiword Expressions MWE 2016. page 112.", "citeRegEx": "Gharbieh et al\\.,? 2016", "shortCiteRegEx": "Gharbieh et al\\.", "year": 2016}, {"title": "Improving word representations via global context and multiple word prototypes", "author": ["Eric Huang", "Richard Socher", "Christopher Manning", "Andrew Ng."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics", "citeRegEx": "Huang et al\\.,? 2012", "shortCiteRegEx": "Huang et al\\.", "year": 2012}, {"title": "I don\u2019t believe in word senses", "author": ["Adam Kilgarriff."], "venue": "Computers and the Humanities 31(2):91\u2013113.", "citeRegEx": "Kilgarriff.,? 1997", "shortCiteRegEx": "Kilgarriff.", "year": 1997}, {"title": "Property of average precision and its generalization: An examination of evaluation indicator for information retrieval experiments", "author": ["Kazuaki Kishida."], "venue": "National Institute of Informatics Tokyo, Japan.", "citeRegEx": "Kishida.,? 2005", "shortCiteRegEx": "Kishida.", "year": 2005}, {"title": "What substitutes tell us - analysis of an \u201call-words\u201d lexical substitution corpus", "author": ["Gerhard Kremer", "Katrin Erk", "Sebastian Pad\u00f3", "Stefan Thater."], "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computa-", "citeRegEx": "Kremer et al\\.,? 2014", "shortCiteRegEx": "Kremer et al\\.", "year": 2014}, {"title": "Learning word sense distributions, detecting unattested senses and identifying novel senses using topic models", "author": ["Jey Han Lau", "Paul Cook", "Diana McCarthy", "Spandana Gella", "Timothy Baldwin."], "venue": "Proceedings of the 52nd Annual Meeting of the", "citeRegEx": "Lau et al\\.,? 2014", "shortCiteRegEx": "Lau et al\\.", "year": 2014}, {"title": "Dependencybased word embeddings", "author": ["Omer Levy", "Yoav Goldberg."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Association for Computational Lin-", "citeRegEx": "Levy and Goldberg.,? 2014", "shortCiteRegEx": "Levy and Goldberg.", "year": 2014}, {"title": "Improving distributional similarity with lessons learned from word embeddings", "author": ["Omer Levy", "Yoav Goldberg", "Ido Dagan."], "venue": "Transactions of the Association for Computational Linguistics 3:211\u2013225. https://transacl.org/ojs/index.php/tacl/article/view/570.", "citeRegEx": "Levy et al\\.,? 2015", "shortCiteRegEx": "Levy et al\\.", "year": 2015}, {"title": "Do multisense embeddings improve natural language understanding? In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing", "author": ["Jiwei Li", "Dan Jurafsky."], "venue": "Association for Computational", "citeRegEx": "Li and Jurafsky.,? 2015", "shortCiteRegEx": "Li and Jurafsky.", "year": 2015}, {"title": "Semeval2007 task 10: English lexical substitution task", "author": ["Diana McCarthy", "Roberto Navigli."], "venue": "Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval2007). Association for Computational Linguis-", "citeRegEx": "McCarthy and Navigli.,? 2007", "shortCiteRegEx": "McCarthy and Navigli.", "year": 2007}, {"title": "A simple word embedding model for lexical substitution", "author": ["Oren Melamud", "Omer Levy", "Ido Dagan."], "venue": "Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing. Association for Computa-", "citeRegEx": "Melamud et al\\.,? 2015", "shortCiteRegEx": "Melamud et al\\.", "year": 2015}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781 .", "citeRegEx": "Mikolov et al\\.,? 2013a", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in Neural Information Processing Systems 26, Curran Associates, Inc.,", "citeRegEx": "Mikolov et al\\.,? 2013b", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Wordnet: A lexical database for english", "author": ["George A. Miller."], "venue": "Commun. ACM 38(11):39\u201341.", "citeRegEx": "Miller.,? 1995", "shortCiteRegEx": "Miller.", "year": 1995}, {"title": "SOFSEM 2012: Theory and Practice of Computer Science: 38th Conference on Current Trends in Theory and Practice of Computer Science, \u0160pindler\u016fv Ml\u00fdn, Czech Republic, January 21-27, 2012", "author": ["Roberto Navigli."], "venue": "Proceedings, Springer Berlin Heidel-", "citeRegEx": "Navigli.,? 2012", "shortCiteRegEx": "Navigli.", "year": 2012}, {"title": "Babelnet: Building a very large multilingual semantic network", "author": ["Roberto Navigli", "Simone Paolo Ponzetto."], "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational", "citeRegEx": "Navigli and Ponzetto.,? 2010", "shortCiteRegEx": "Navigli and Ponzetto.", "year": 2010}, {"title": "Efficient nonparametric estimation of multiple embeddings per word in vector space", "author": ["Arvind Neelakantan", "Jeevan Shankar", "Alexandre Passos", "Andrew McCallum."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Lan-", "citeRegEx": "Neelakantan et al\\.,? 2014", "shortCiteRegEx": "Neelakantan et al\\.", "year": 2014}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computa-", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Contextdependent sense embedding", "author": ["Lin Qiu", "Kewei Tu", "Yong Yu."], "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Austin, Texas, pages 183\u2013191.", "citeRegEx": "Qiu et al\\.,? 2016", "shortCiteRegEx": "Qiu et al\\.", "year": 2016}, {"title": "Multi-prototype vector-space models of word meaning", "author": ["Joseph Reisinger", "Raymond J. Mooney."], "venue": "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Lin-", "citeRegEx": "Reisinger and Mooney.,? 2010", "shortCiteRegEx": "Reisinger and Mooney.", "year": 2010}, {"title": "Applied nonparametric statistical methods", "author": ["Peter Sprent", "Nigel C Smeeton."], "venue": "CRC Press.", "citeRegEx": "Sprent and Smeeton.,? 2016", "shortCiteRegEx": "Sprent and Smeeton.", "year": 2016}, {"title": "Learning to rank lexical substitutions", "author": ["Gy\u00f6rgy Szarvas", "R\u00f3bert Busa-Fekete", "Eyke H\u00fcllermeier."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguis-", "citeRegEx": "Szarvas et al\\.,? 2013", "shortCiteRegEx": "Szarvas et al\\.", "year": 2013}, {"title": "Learning sentimentspecific word embedding for twitter sentiment classification", "author": ["Duyu Tang", "Furu Wei", "Nan Yang", "Ming Zhou", "Ting Liu", "Bing Qin."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Tang et al\\.,? 2014", "shortCiteRegEx": "Tang et al\\.", "year": 2014}, {"title": "Sharing clusters among related groups: Hierarchical dirichlet processes", "author": ["Yee W. Teh", "Michael I. Jordan", "Matthew J. Beal", "David M. Blei."], "venue": "L. K. Saul, Y. Weiss, and L. Bottou, editors, Advances in Neural Information Process-", "citeRegEx": "Teh et al\\.,? 2005", "shortCiteRegEx": "Teh et al\\.", "year": 2005}, {"title": "Hierarchical dirichlet processes", "author": ["Yee Whye Teh", "Michael I. Jordan", "Matthew J. Beal", "David M. Blei."], "venue": "Journal of the American Statistical Association 101(476):1566\u20131581.", "citeRegEx": "Teh et al\\.,? 2006", "shortCiteRegEx": "Teh et al\\.", "year": 2006}, {"title": "Nonparametric bayesian word sense induction", "author": ["Xuchen Yao", "Benjamin van Durme."], "venue": "Graph-based Methods for Natural Language Processing. The Association for Computer Linguistics, pages 10\u201314.", "citeRegEx": "Yao and Durme.,? 2011", "shortCiteRegEx": "Yao and Durme.", "year": 2011}, {"title": "Bilingual word embeddings for phrase-based machine translation", "author": ["Will Y. Zou", "Richard Socher", "Daniel Cer", "Christopher D. Manning."], "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Pro-", "citeRegEx": "Zou et al\\.,? 2013", "shortCiteRegEx": "Zou et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 13, "context": "Word representations in the form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al.", "startOffset": 114, "endOffset": 162}, {"referenceID": 19, "context": "Word representations in the form of dense vectors, or word embeddings, capture semantic and syntactic information (Mikolov et al., 2013a; Pennington et al., 2014) and are widely used in many NLP tasks (Zou et al.", "startOffset": 114, "endOffset": 162}, {"referenceID": 28, "context": ", 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016).", "startOffset": 46, "endOffset": 131}, {"referenceID": 8, "context": ", 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016).", "startOffset": 46, "endOffset": 131}, {"referenceID": 24, "context": ", 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016).", "startOffset": 46, "endOffset": 131}, {"referenceID": 2, "context": ", 2014) and are widely used in many NLP tasks (Zou et al., 2013; Levy and Goldberg, 2014; Tang et al., 2014; Gharbieh et al., 2016).", "startOffset": 46, "endOffset": 131}, {"referenceID": 21, "context": "However, many tasks can benefit from using multiple representations per word to capture polysemy (Reisinger and Mooney, 2010).", "startOffset": 97, "endOffset": 125}, {"referenceID": 15, "context": "There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages.", "startOffset": 71, "endOffset": 113}, {"referenceID": 17, "context": "There have been several attempts to build repositories for word senses (Miller, 1995; Navigli and Ponzetto, 2010), but this is laborious and limited to few languages.", "startOffset": 71, "endOffset": 113}, {"referenceID": 4, "context": "Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels of granularity (Kilgarriff, 1997; Navigli, 2012).", "startOffset": 125, "endOffset": 158}, {"referenceID": 16, "context": "Moreover, defining a universal set of word senses is challenging as polysemous words can exist at many levels of granularity (Kilgarriff, 1997; Navigli, 2012).", "startOffset": 125, "endOffset": 158}, {"referenceID": 26, "context": "To learn topics from a corpus we use HDP (Teh et al., 2006; Lau et al., 2014).", "startOffset": 41, "endOffset": 77}, {"referenceID": 7, "context": "To learn topics from a corpus we use HDP (Teh et al., 2006; Lau et al., 2014).", "startOffset": 41, "endOffset": 77}, {"referenceID": 25, "context": "The main advantage of this model compared to non-hierarchical methods like the Chinese Restaurant Process (CRP) is that each document in the corpus is modeled using a mixture model with topics shared between all documents (Teh et al., 2005; Brody and Lapata, 2009).", "startOffset": 222, "endOffset": 264}, {"referenceID": 0, "context": "The main advantage of this model compared to non-hierarchical methods like the Chinese Restaurant Process (CRP) is that each document in the corpus is modeled using a mixture model with topics shared between all documents (Teh et al., 2005; Brody and Lapata, 2009).", "startOffset": 222, "endOffset": 264}, {"referenceID": 18, "context": "Similarly to Neelakantan et al. (2014), we use neighboring words to detect the meaning of the context, however, we also use the two HDP disar X iv :1 70 5.", "startOffset": 13, "endOffset": 39}, {"referenceID": 13, "context": "We modify the Skipgram model (Mikolov et al., 2013a) to obtain multiple topic-sensitive representations per word type using topic distributions.", "startOffset": 29, "endOffset": 52}, {"referenceID": 13, "context": "w2v and GloVe are pre-trained embeddings from (Mikolov et al., 2013a) and (Pennington et al.", "startOffset": 46, "endOffset": 69}, {"referenceID": 19, "context": ", 2013a) and (Pennington et al., 2014) respectively.", "startOffset": 13, "endOffset": 38}, {"referenceID": 14, "context": ", embeddings learned with Skipgram on our corpus, as well as Word2Vec (Mikolov et al., 2013b) and GloVe embeddings (Pennington et al.", "startOffset": 70, "endOffset": 93}, {"referenceID": 19, "context": ", 2013b) and GloVe embeddings (Pennington et al., 2014) pre-trained on large data.", "startOffset": 30, "endOffset": 55}, {"referenceID": 25, "context": "The topics are learned on a 100K-document subset of this corpus using the HDP implementation of Teh et al. (2006). Once the topics have been learned, we run HDP on the whole corpus to obtain the word-topic labeling (see Section 2.", "startOffset": 96, "endOffset": 114}, {"referenceID": 13, "context": "SGE + C (Mikolov et al., 2013a) 0.", "startOffset": 8, "endOffset": 31}, {"referenceID": 18, "context": "62 MSSG (Neelakantan et al., 2014) 0.", "startOffset": 8, "endOffset": 34}, {"referenceID": 18, "context": "We compare our models to several baselines: Skipgram (SGE) and the best-performing multisense embeddings model per word type (MSSG) (Neelakantan et al., 2014).", "startOffset": 132, "endOffset": 158}, {"referenceID": 12, "context": "All model variants are trained on the same training data with the same settings, following suggestions by Mikolov et al. (2013a) and Levy et al.", "startOffset": 106, "endOffset": 129}, {"referenceID": 9, "context": "(2013a) and Levy et al. (2015). For MSSG we use the best performing similarity measure (avgSimC) as proposed by Neelakantan et al.", "startOffset": 12, "endOffset": 31}, {"referenceID": 9, "context": "(2013a) and Levy et al. (2015). For MSSG we use the best performing similarity measure (avgSimC) as proposed by Neelakantan et al. (2014).", "startOffset": 12, "endOffset": 138}, {"referenceID": 1, "context": "Despite its shortcomings (Faruqui et al., 2016), word similarity remains the most frequently used method of evaluation in the literature.", "startOffset": 25, "endOffset": 47}, {"referenceID": 3, "context": "To the best of our knowledge, the only word similarity data set providing word context is SCWS (Huang et al., 2012).", "startOffset": 95, "endOffset": 115}, {"referenceID": 18, "context": "The MSSG model of Neelakantan et al. (2014) performs only slightly better than our HLTE model by requiring considerably more parameters (600 vs.", "startOffset": 18, "endOffset": 44}, {"referenceID": 11, "context": "We use two evaluation sets: LS-SE07 (McCarthy and Navigli, 2007), and LS-CIC (Kremer et al.", "startOffset": 36, "endOffset": 64}, {"referenceID": 6, "context": "We use two evaluation sets: LS-SE07 (McCarthy and Navigli, 2007), and LS-CIC (Kremer et al., 2014).", "startOffset": 77, "endOffset": 98}, {"referenceID": 23, "context": "Unlike previous work (Szarvas et al., 2013; Kremer et al., 2014; Melamud et al., 2015) we do not use any syntactic information, motivated by the fact that high-quality parsers are not available for most languages.", "startOffset": 21, "endOffset": 86}, {"referenceID": 6, "context": "Unlike previous work (Szarvas et al., 2013; Kremer et al., 2014; Melamud et al., 2015) we do not use any syntactic information, motivated by the fact that high-quality parsers are not available for most languages.", "startOffset": 21, "endOffset": 86}, {"referenceID": 12, "context": "Unlike previous work (Szarvas et al., 2013; Kremer et al., 2014; Melamud et al., 2015) we do not use any syntactic information, motivated by the fact that high-quality parsers are not available for most languages.", "startOffset": 21, "endOffset": 86}, {"referenceID": 5, "context": "The evaluation is performed by computing the Generalized Average Precision (GAP) score (Kishida, 2005).", "startOffset": 87, "endOffset": 102}, {"referenceID": 9, "context": "Following Melamud et al. (2015) we pool substitutions from different instances and rank them by the number of annotators that selected them for a given context.", "startOffset": 10, "endOffset": 32}, {"referenceID": 22, "context": "We use the nonparametric rank-based Mann-WhitneyWilcoxon test (Sprent and Smeeton, 2016) to check for statistically significant differences between runs.", "startOffset": 62, "endOffset": 88}, {"referenceID": 20, "context": ", 2014), recent studies have focused on learning multiple embeddings per word due to the ambiguous nature of language (Qiu et al., 2016).", "startOffset": 118, "endOffset": 136}, {"referenceID": 3, "context": "Huang et al. (2012) cluster word contexts and use the average embedding of each cluster as word sense embeddings, which yields improvements on a word similarity task.", "startOffset": 0, "endOffset": 20}, {"referenceID": 3, "context": "Huang et al. (2012) cluster word contexts and use the average embedding of each cluster as word sense embeddings, which yields improvements on a word similarity task. Neelakantan et al. (2014) propose two approaches, both based on clustering word contexts: In the first, they fix the number of senses manually, and in the second, they use an ad-hoc greedy procedure that allocates a new representation to a word if existing representations explain the context below a certain threshold.", "startOffset": 0, "endOffset": 193}, {"referenceID": 3, "context": "Huang et al. (2012) cluster word contexts and use the average embedding of each cluster as word sense embeddings, which yields improvements on a word similarity task. Neelakantan et al. (2014) propose two approaches, both based on clustering word contexts: In the first, they fix the number of senses manually, and in the second, they use an ad-hoc greedy procedure that allocates a new representation to a word if existing representations explain the context below a certain threshold. Li and Jurafsky (2015) used a CRP model to distinguish between senses of words and train vectors for senses, where the number of senses is not fixed.", "startOffset": 0, "endOffset": 510}], "year": 2017, "abstractText": "Distributed word representations are widely used for modeling words in NLP tasks. Most of the existing models generate one representation per word and do not consider different meanings of a word. We present two approaches to learn multiple topic-sensitive representations per word by using Hierarchical Dirichlet Process. We observe that by modeling topics and integrating topic distributions for each document we obtain representations that are able to distinguish between different meanings of a given word. Our models yield statistically significant improvements for the lexical substitution task indicating that commonly used single word representations, even when combined with contextual information, are insufficient for this task.", "creator": "LaTeX with hyperref package"}}}