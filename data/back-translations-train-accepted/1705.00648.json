{"id": "1705.00648", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "1-May-2017", "title": "\"Liar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News Detection", "abstract": "Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present liar: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from PolitiFact.com, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate meta-data with text. We show that this hybrid approach can improve a text-only deep learning model.", "histories": [["v1", "Mon, 1 May 2017 18:20:47 GMT  (121kb,D)", "http://arxiv.org/abs/1705.00648v1", "ACL 2017"]], "COMMENTS": "ACL 2017", "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["william yang wang"], "accepted": true, "id": "1705.00648"}, "pdf": {"name": "1705.00648.pdf", "metadata": {"source": "CRF", "title": "\u201cLiar, Liar Pants on Fire\u201d: A New Benchmark Dataset for Fake News Detection", "authors": ["William Yang Wang"], "emails": ["william@cs.ucsb.edu"], "sections": [{"heading": "1 Introduction", "text": "In this past election cycle for the 45th President of the United States, the world has witnessed a growing epidemic of fake news, and the scourge of fake news not only poses serious threats to the integrity of journalism, but has also caused turmoil in the political world. Indeed, the worst real consequences are that fake news seems to create real fears: last year, a man with an AR-15 rifle was arrested and taken for a walk in a Washington DC pizzeria because he recently read online that \"this pizzeria houses young children as sex slaves as part of a child abuse ring led by Hillary Clinton.\" 1 The man was later arrested by police and charged with shooting an assault rifle at a restaurant (Kang and Goldman, 2016).The broad problem of deception detection (Mihalcea and Strapparava, 2009) is not new in the natural language processing community. (A relatively early study by Ott et al."}, {"heading": "2 LIAR: a New Benchmark Dataset", "text": "The most important resources for misleading rating detection are Crowdsourced Datasets (Ott et al., 2011; Pe \u0301 rez-Rosas and Mihalcea, 2015), which are very useful for detecting deceptions, but the positive training data is primarily collected from a simulated environment. More importantly, these datasets are not suitable for fake statements because fake news on TVs and social media is much shorter than customer reviews. Vlachos and Riedel (2014) are the first to construct fake news and fact checks of datasets. They have 221 statements from CHANNEL 42 and POLITIFACT.COM3, a Pulitzer website covering political topics, and they provide detailed ratings."}, {"heading": "3 Automatic Fake News Detection", "text": "One of the most obvious applications of our dataset is to facilitate the development of machine learning models for the automatic detection of fake news. In this task, we include this as a 6-way problem of multi-class classification of text. And the research questions are: \u2022 How well can machine learning algorithms classify a short statement into a fine-grained category of falsehood? \u2022 Can we design a deep architecture of neural networks to integrate loudspeaker metadata with text to improve the performance of fake news detection? Since Convolutionary neural network architectures (CNNs) (Collobert et al., 2011; Kim et al., 2014; Zhang et al., 2015) have received the latest results from many text classification datasets, we are building our neural network model on a recently proposed CNN model (Kim et al., 2011; Zhang et al., 2015)."}, {"heading": "4 LIAR: Benchmark Evaluation", "text": "In this section we first describe the experimental setup and the baselines. Afterwards we present the empirical results and compare different models."}, {"heading": "4.1 Experimental Settings", "text": "We used five baselines: a majority baseline, a regulated logistic regression classifier (LR), a supporting vector machine classifier (SVM) (Crammer and Singer, 2001), a bidirectional long-term short-term memory network model (Bi-LSTMs) (Hochreiter and Schmidhuber, 1997; Graves and Schmidhuber, 2005), and a convolutionary neural network model (CNNs) (Kim, 2014). For LR and SVM, we used the LIBSHORTTEXT toolkit6, which has proven to be very powerful in short-text classification problems (Wang and Yang, 2015). For Bi-LSTMs and CNNs, we used TensorFlow for implementation. We used pre-formed 300-dimensional word2vec embeddings from Google News (Mikolov et al., 2013) to heat up the text embeddings."}, {"heading": "4.2 Results", "text": "We outline our empirical results in Table 2. First, we compare different models using text features only. We see that the majority of the baseline data on this dataset has about 0.204 and 0.208 accuracy on the validation and test sets, respectively. Standard text classifiers such as SVMs and LR models made significant improvements. Due to the overmatch, the Bi-LSTMs did not perform well. CNNs performed better than all models, resulting in an accuracy of 0.270 on the heldout test set. We compare the predictions from the CNN model with SVMs using a two-tailed paired t test, and CNN was significantly better (p <.0001). Taking all metadata and text into account, the model achieved the best result on the test data."}, {"heading": "5 Conclusion", "text": "LIAR is an order of magnitude larger than previous datasets, enabling the development of statistical and computational approaches to fake news detection. LIAR's authentic, real-world short statements from different contexts with different speakers also enable research into the development of a broad-based fake news detector. We show that by combining metadata with text, significant improvements in the fine-grained detection of fake news can be achieved. Given the detailed analysis report and the links to source documents in this dataset, it is also possible to investigate the task of automated fact-checking of knowledge base in the future. Our corpus can also be used for position classification, reasoning mining, topic modeling, rumour detection and political NLP research."}], "references": [{"title": "Natural language processing (almost) from scratch", "author": ["Ronan Collobert", "Jason Weston", "L\u00e9on Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."], "venue": "Journal of Machine Learning Research 12(Aug):2493\u20132537.", "citeRegEx": "Collobert et al\\.,? 2011", "shortCiteRegEx": "Collobert et al\\.", "year": 2011}, {"title": "On the algorithmic implementation of multiclass kernel-based vector machines", "author": ["Koby Crammer", "Yoram Singer."], "venue": "Journal of machine learning research 2(Dec):265\u2013292.", "citeRegEx": "Crammer and Singer.,? 2001", "shortCiteRegEx": "Crammer and Singer.", "year": 2001}, {"title": "Syntactic stylometry for deception detection", "author": ["Song Feng", "Ritwik Banerjee", "Yejin Choi."], "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2. Association for Computational", "citeRegEx": "Feng et al\\.,? 2012", "shortCiteRegEx": "Feng et al\\.", "year": 2012}, {"title": "Emergent: a novel data-set for stance classification", "author": ["William Ferreira", "Andreas Vlachos."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.", "citeRegEx": "Ferreira and Vlachos.,? 2016", "shortCiteRegEx": "Ferreira and Vlachos.", "year": 2016}, {"title": "Framewise phoneme classification with bidirectional lstm and other neural network architectures", "author": ["Alex Graves", "J\u00fcrgen Schmidhuber."], "venue": "Neural Networks 18(5):602\u2013610.", "citeRegEx": "Graves and Schmidhuber.,? 2005", "shortCiteRegEx": "Graves and Schmidhuber.", "year": 2005}, {"title": "Deceptive review spam detection via exploiting task relatedness and unlabeled data", "author": ["Zhen Hai", "Peilin Zhao", "Peng Cheng", "Peng Yang", "XiaoLi Li", "Guangxia Li", "Ant Financial."], "venue": "EMNLP.", "citeRegEx": "Hai et al\\.,? 2016", "shortCiteRegEx": "Hai et al\\.", "year": 2016}, {"title": "Long short-term memory", "author": ["Sepp Hochreiter", "J\u00fcrgen Schmidhuber."], "venue": "Neural computation 9(8):1735\u20131780.", "citeRegEx": "Hochreiter and Schmidhuber.,? 1997", "shortCiteRegEx": "Hochreiter and Schmidhuber.", "year": 1997}, {"title": "In washington pizzeria attack, fake news brought real guns", "author": ["Cecilia Kang", "Adam Goldman."], "venue": "the New York Times.", "citeRegEx": "Kang and Goldman.,? 2016", "shortCiteRegEx": "Kang and Goldman.", "year": 2016}, {"title": "Convolutional neural networks for sentence classification", "author": ["Yoon Kim."], "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).", "citeRegEx": "Kim.,? 2014", "shortCiteRegEx": "Kim.", "year": 2014}, {"title": "The lie detector: Explorations in the automatic recognition of deceptive language", "author": ["Rada Mihalcea", "Carlo Strapparava."], "venue": "Proceedings of the ACLIJCNLP 2009 Conference Short Papers.", "citeRegEx": "Mihalcea and Strapparava.,? 2009", "shortCiteRegEx": "Mihalcea and Strapparava.", "year": 2009}, {"title": "Efficient estimation of word representations in vector space", "author": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."], "venue": "arXiv preprint arXiv:1301.3781 .", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Finding deceptive opinion spam by any stretch of the imagination", "author": ["Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey T Hancock."], "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language", "citeRegEx": "Ott et al\\.,? 2011", "shortCiteRegEx": "Ott et al\\.", "year": 2011}, {"title": "Experiments in open domain deception detection", "author": ["Ver\u00f3nica P\u00e9rez-Rosas", "Rada Mihalcea."], "venue": "EMNLP. pages 1120\u20131125.", "citeRegEx": "P\u00e9rez.Rosas and Mihalcea.,? 2015", "shortCiteRegEx": "P\u00e9rez.Rosas and Mihalcea.", "year": 2015}, {"title": "Fact checking: Task definition and dataset construction", "author": ["Andreas Vlachos", "Sebastian Riedel."], "venue": "Proceedings of the ACL 2014 Workshop on Language Technology and Computational Social Science .", "citeRegEx": "Vlachos and Riedel.,? 2014", "shortCiteRegEx": "Vlachos and Riedel.", "year": 2014}, {"title": "That\u2019s so annoying!!!: A lexical and frame-semantic embedding based data augmentation approach to automatic categorization of annoying behaviors using #petpeeve tweets", "author": ["William Yang Wang", "Diyi Yang."], "venue": "Proceedings of the 2015 Con-", "citeRegEx": "Wang and Yang.,? 2015", "shortCiteRegEx": "Wang and Yang.", "year": 2015}, {"title": "Character-level convolutional networks for text classification", "author": ["Xiang Zhang", "Junbo Zhao", "Yann LeCun."], "venue": "Advances in neural information processing systems. pages 649\u2013657.", "citeRegEx": "Zhang et al\\.,? 2015", "shortCiteRegEx": "Zhang et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 7, "context": "The man was later arrested by police, and he was charged for firing an assault rifle in the restaurant (Kang and Goldman, 2016).", "startOffset": 103, "endOffset": 127}, {"referenceID": 9, "context": "The broadly-related problem of deception detection (Mihalcea and Strapparava, 2009) is not new to the natural language processing community.", "startOffset": 51, "endOffset": 83}, {"referenceID": 2, "context": "Recent studies have also proposed stylometric (Feng et al., 2012), semi-supervised learning (Hai et al.", "startOffset": 46, "endOffset": 65}, {"referenceID": 5, "context": ", 2012), semi-supervised learning (Hai et al., 2016), and linguistic approaches (P\u00e9rez-Rosas and Mihalcea, 2015) to detect deceptive text on crowdsourced datasets.", "startOffset": 34, "endOffset": 52}, {"referenceID": 12, "context": ", 2016), and linguistic approaches (P\u00e9rez-Rosas and Mihalcea, 2015) to detect deceptive text on crowdsourced datasets.", "startOffset": 35, "endOffset": 67}, {"referenceID": 5, "context": "The man was later arrested by police, and he was charged for firing an assault rifle in the restaurant (Kang and Goldman, 2016). The broadly-related problem of deception detection (Mihalcea and Strapparava, 2009) is not new to the natural language processing community. A relatively early study by Ott et al. (2011) focuses on detecting deceptive review opinions in sentiment analysis, using a crowdsourcing approach to create training data for the positive class, and then combine with truthful opinions from TripAdvisor.", "startOffset": 104, "endOffset": 316}, {"referenceID": 2, "context": "Recent studies have also proposed stylometric (Feng et al., 2012), semi-supervised learning (Hai et al., 2016), and linguistic approaches (P\u00e9rez-Rosas and Mihalcea, 2015) to detect deceptive text on crowdsourced datasets. Even though crowdsourcing is an important approach to create labeled training data, there is a mismatch between training and testing. When testing on real-world review datasets, the results could be suboptimal since the positive training data was created in a completely different, simulated platform. The problem of fake news detection is more challenging than detecting deceptive reviews, since the political language on TV interviews, posts on Facebook and Twitters are mostly short statements. However, the lack of manually labeled fake news dataset is still a bottleneck for advancing computational-intensive, broadcoverage models in this direction. Vlachos and Riedel (2014) are the first to release a public fake news detection and fact-checking dataset, but it only includes 221 statements, which does not permit machine learning based assessments.", "startOffset": 47, "endOffset": 903}, {"referenceID": 13, "context": "With such volume and a time span of a decade, LIAR is an order of magnitude larger than the currently available resources (Vlachos and Riedel, 2014; Ferreira and Vlachos, 2016) of similiar type.", "startOffset": 122, "endOffset": 176}, {"referenceID": 3, "context": "With such volume and a time span of a decade, LIAR is an order of magnitude larger than the currently available resources (Vlachos and Riedel, 2014; Ferreira and Vlachos, 2016) of similiar type.", "startOffset": 122, "endOffset": 176}, {"referenceID": 6, "context": "The baselines include logistic regression, support vector machines, long short-term memory networks (Hochreiter and Schmidhuber, 1997), and a convolutional neural network model (Kim, 2014).", "startOffset": 100, "endOffset": 134}, {"referenceID": 8, "context": "The baselines include logistic regression, support vector machines, long short-term memory networks (Hochreiter and Schmidhuber, 1997), and a convolutional neural network model (Kim, 2014).", "startOffset": 177, "endOffset": 188}, {"referenceID": 11, "context": "The major resources for deceptive detection of reviews are crowdsourced datasets (Ott et al., 2011; P\u00e9rez-Rosas and Mihalcea, 2015).", "startOffset": 81, "endOffset": 131}, {"referenceID": 12, "context": "The major resources for deceptive detection of reviews are crowdsourced datasets (Ott et al., 2011; P\u00e9rez-Rosas and Mihalcea, 2015).", "startOffset": 81, "endOffset": 131}, {"referenceID": 10, "context": "The major resources for deceptive detection of reviews are crowdsourced datasets (Ott et al., 2011; P\u00e9rez-Rosas and Mihalcea, 2015). They are very useful datasets to study deception detection, but the positive training data are collected from a simulated environment. More importantly, these datasets are not suitable for fake statements detection, since the fake news on TVs and social media are much shorter than customer reviews. Vlachos and Riedel (2014) are the first to construct fake news and fact-checking datasets.", "startOffset": 82, "endOffset": 459}, {"referenceID": 3, "context": "Recently, Ferreira and Vlachos (2016) have released the Emergent dataset, which includes 300 labeled rumors from PolitiFact.", "startOffset": 10, "endOffset": 38}, {"referenceID": 0, "context": "Since convolutional neural networks architectures (CNNs) (Collobert et al., 2011; Kim, 2014; Zhang et al., 2015) have obtained the state-of-theart results on many text classification datasets, we build our neural networks model based on a recently proposed CNN model (Kim, 2014).", "startOffset": 57, "endOffset": 112}, {"referenceID": 8, "context": "Since convolutional neural networks architectures (CNNs) (Collobert et al., 2011; Kim, 2014; Zhang et al., 2015) have obtained the state-of-theart results on many text classification datasets, we build our neural networks model based on a recently proposed CNN model (Kim, 2014).", "startOffset": 57, "endOffset": 112}, {"referenceID": 15, "context": "Since convolutional neural networks architectures (CNNs) (Collobert et al., 2011; Kim, 2014; Zhang et al., 2015) have obtained the state-of-theart results on many text classification datasets, we build our neural networks model based on a recently proposed CNN model (Kim, 2014).", "startOffset": 57, "endOffset": 112}, {"referenceID": 8, "context": ", 2015) have obtained the state-of-theart results on many text classification datasets, we build our neural networks model based on a recently proposed CNN model (Kim, 2014).", "startOffset": 162, "endOffset": 173}, {"referenceID": 1, "context": "We used five baselines: a majority baseline, a regularized logistic regression classifier (LR), a support vector machine classifier (SVM) (Crammer and Singer, 2001), a bi-directional long short-term memory networks model (Bi-LSTMs) (Hochreiter and Schmidhuber, 1997; Graves and Schmidhuber, 2005), and a convolutional neural network model (CNNs) (Kim, 2014).", "startOffset": 138, "endOffset": 164}, {"referenceID": 6, "context": "We used five baselines: a majority baseline, a regularized logistic regression classifier (LR), a support vector machine classifier (SVM) (Crammer and Singer, 2001), a bi-directional long short-term memory networks model (Bi-LSTMs) (Hochreiter and Schmidhuber, 1997; Graves and Schmidhuber, 2005), and a convolutional neural network model (CNNs) (Kim, 2014).", "startOffset": 232, "endOffset": 296}, {"referenceID": 4, "context": "We used five baselines: a majority baseline, a regularized logistic regression classifier (LR), a support vector machine classifier (SVM) (Crammer and Singer, 2001), a bi-directional long short-term memory networks model (Bi-LSTMs) (Hochreiter and Schmidhuber, 1997; Graves and Schmidhuber, 2005), and a convolutional neural network model (CNNs) (Kim, 2014).", "startOffset": 232, "endOffset": 296}, {"referenceID": 8, "context": "We used five baselines: a majority baseline, a regularized logistic regression classifier (LR), a support vector machine classifier (SVM) (Crammer and Singer, 2001), a bi-directional long short-term memory networks model (Bi-LSTMs) (Hochreiter and Schmidhuber, 1997; Graves and Schmidhuber, 2005), and a convolutional neural network model (CNNs) (Kim, 2014).", "startOffset": 346, "endOffset": 357}, {"referenceID": 14, "context": "For LR and SVM, we used the LIBSHORTTEXT toolkit6, which was shown to provide very strong performances on short text classification problems (Wang and Yang, 2015).", "startOffset": 141, "endOffset": 162}, {"referenceID": 10, "context": "We used pretrained 300-dimensional word2vec embeddings from Google News (Mikolov et al., 2013) to warm-start the text embeddings.", "startOffset": 72, "endOffset": 94}], "year": 2017, "abstractText": "Automatic fake news detection is a challenging problem in deception detection, and it has tremendous real-world political and social impacts. However, statistical approaches to combating fake news has been dramatically limited by the lack of labeled benchmark datasets. In this paper, we present LIAR: a new, publicly available dataset for fake news detection. We collected a decade-long, 12.8K manually labeled short statements in various contexts from POLITIFACT.COM, which provides detailed analysis report and links to source documents for each case. This dataset can be used for fact-checking research as well. Notably, this new dataset is an order of magnitude larger than previously largest public fake news datasets of similar type. Empirically, we investigate automatic fake news detection based on surface-level linguistic patterns. We have designed a novel, hybrid convolutional neural network to integrate metadata with text. We show that this hybrid approach can improve a text-only deep learning model.", "creator": "LaTeX with hyperref package"}}}