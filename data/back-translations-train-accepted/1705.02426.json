{"id": "1705.02426", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "6-May-2017", "title": "Analogical Inference for Multi-relational Embeddings", "abstract": "Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledge-based inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the \\textit{analogical} properties of the embedded entities and relations. By formulating the learning objective in a differentiable fashion, our model enjoys both theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.", "histories": [["v1", "Sat, 6 May 2017 01:40:28 GMT  (77kb,D)", "https://arxiv.org/abs/1705.02426v1", null], ["v2", "Thu, 6 Jul 2017 16:58:24 GMT  (77kb,D)", "http://arxiv.org/abs/1705.02426v2", null]], "reviews": [], "SUBJECTS": "cs.LG cs.AI cs.CL", "authors": ["hanxiao liu", "yuexin wu", "yiming yang"], "accepted": true, "id": "1705.02426"}, "pdf": {"name": "1705.02426.pdf", "metadata": {"source": "META", "title": "Analogical Inference for Multi-relational Embeddings", "authors": ["Hanxiao Liu", "Yuexin Wu", "Yiming Yang"], "emails": ["<hanxiaol@cs.cmu.edu>."], "sections": [{"heading": "1. Introduction", "text": "This year, it is only a matter of time before an agreement is reached."}, {"heading": "2. Related Background", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "2.1. Notations", "text": "Let E and R be the space of all beings and their relations. A knowledge base K is a collection of triplets (s, r, o), where s-E, o-E, r-R stand for the subject, object and their relationship. Use v-R | E | \u00b7 m to denote an overview table in which ve-Rm is the vector that embeds unit e, and use the tensor W-R | R-m-m to denote another overview table in which Wr-Rm-m is the matrix that embeds the relationship r. Both v and W are to be learned from K."}, {"heading": "2.2. Relations as Linear Maps", "text": "We formulate any relation r as a linear map that transforms the subject from its original position in vector space to the proximity of object o. In other words, we expect the latent representations to be too satisfactory for all valid (s, r, o), that is, we define a bilinear score function as: \u03c6 (s, r, o) = < v > s Wr, vo > = v > s Wrvo (2). Our goal is to quantify v and W in such a way that \u03c6 (s, r, o) values valid triples with high values and low values with invalid ones.Unlike some previous models (Bordes et al., 2013), in which relationships are modeled as additive operators, namely as opposed to empirical operators, the natural relationship between the subject and the operator is defined as multiplier."}, {"heading": "2.3. Normal Transformations", "text": "Definition 2.1 (Normal Matrix) A real matrix A is normal if and only if A > A = AA >. Normal matrices have beautiful theoretical properties that are often desirable, e.g. by being uniformly diagonalizable and thus easily analyzed by the spectral theorem (Dunford et al., 1971). Representative members of the normal family include: \u2022 symmetrical matrices for which WrW > r Wr = W > r Wr 2r. These include all diagonal matrices and positive semidefinitive matrices that are symmetrical matrices, and the symmetry implies that r matrices are symmetrical relationships."}, {"heading": "3. Proposed Analogical Inference Framework", "text": "It is well known that analog thinking plays a central role in human knowledge induction (Gentner, 1983; Minsky, 1988; Holyoak et al., 1996; Hofstadter, 2001).At this point, we offer a mathematical formulation of the analog structures that are of interest to the multirelational embedding in a latent semantic space in order to support algorithmic conclusions about the embedding of entities and relationships in a knowledge graph."}, {"heading": "3.1. Analogical Structures", "text": "Consider the famous example in the word embedding literature (Mikolov et al., 2013; Pennington et al., 2014), for the following entities and relationships among themselves: \"The man is to the king as well as the woman to the queen.\" In an abstract term, we designate the entities by a (as a man), b (as a king), c (as a woman) and d (as a queen), and the relationships by r (as crown) and r. \"These give us the subject object triplets as follows: a r \u2192 b, c \u2192 d, a r \u00b2 s, c \u00b2 r \u00b2 c, b \u00b2 c \u00b2 r \u00b2 r \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2, c, c \u00b2 c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 c, c c c, c c c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 c, c c c c c c, c c, c \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 s \u00b2 c c c c c, c c, c c, c c c, c c, c c \u00b2 s \u00b2 s \u00b2 s \u00b2 c c, c c, c c c, c c c c c, c, c c, c, c, c, c, c, c, c, c, c, c, c c c c, c, c, c, c, c, c, c c c, c, c, c, c, c, c, c, c, c, c, c, c"}, {"heading": "3.2. Commutative Constraint for Linear Maps", "text": "Although it is tempting to explore all the potentially interesting parallelograms in the modeling of analog structures, it is mathematically difficult to examine the entire powerset of entities as a candidate space of analog structures. A more reasonable strategy is to identify some desirable properties of the analog structures that we want to model, and to use these properties as constraints on the reduction of the candidate space.A desirable feature of the linear maps we want is that all directed paths with the same start node and end node form the compositional equivalence.The designation by the composition operator between two relationships, the parallelogram in Figure 2 contains two equivalent compositions such as: r-r-r-r-r-r-r (4), which means that there is a connection to d via both paths. We call this the pendulum property of linear maps, which is a necessary condition for the formation of pendulum analogues and therefore the corresponding structures."}, {"heading": "3.3. The Optimization Objective", "text": "The general goal of multirelational embedding is to find entity and relation representations, so that positive triples marked as y = + 1 get a higher score than negative triples marked as y = \u2212 1. This can be formulated in such a way that asmin v, WEs, r, o, y \u0445 D '(\u03c6v, W (s, r, o) = v > s Wrvo is our score function based on the embedding, \"is our loss function, and D is the data distribution based on the training set K.In order to impose analog structures on the representations, we additionally need the linear maps associated with relationships to form a pendulum family of normal matrices. This gives us the objective function for ANALOGY: min v, WEs, r, o, y, D '( s, r, o), y (7)."}, {"heading": "4. Efficient Inference Algorithm", "text": "The limited optimization (7) is mathematically difficult due to the large number of model parameters in tensor W = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = > Q = = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q = Q Q Q = Q = Q = Q Q = Q = Q = Q = Q = Q = Q = Q Q = Q = Q = Q Q Q Q = Q = Q = Q Q Q Q = Q = Q Q Q Q"}, {"heading": "5. Unified View of Representative Methods", "text": "In the following, we offer a unified view of several embedding models (Yang et al., 2014; Trouillon et al., 2016; Nickel et al., 2016) by showing that they are limited versions within our framework and thus implicitly exhibit analog properties, which explains their strong empirical performance compared to other baselines (\u00a7 6)."}, {"heading": "5.1. DistMult", "text": "DistMult (Yang et al., 2014) embeds both entities and relationships as vectors and defines the score function as\u03c6 (s, r, o) = < vs, vr, vo > (14), where vs, vr, vo Rm, Woods, r, o (15), where < \u00b7, \u00b7 > denotes the generalized inner product. Sentence 5.1. DistMult embeddings can be fully restored by ANALOGY embeddings if n = m.Proof. This is trivial to verify, since the score function (15) can be rewritten as \u03c6 (s, r, o) = v > s Brvo, whereas Br is a diagonal matrix given by Br = diag (vr). Entity analogies are promoted in DistMult because the diagonal matrices diag (vr) s are both normal and reciprocal, but limited to Mo (Mo)."}, {"heading": "5.2. Complex Embeddings (ComplEx)", "text": "ComplEx (Trouillon et al., 2016) extends the embedding to complex domain C, which defines that x denotes the complex conjugate of x. Proposition 5.2. Embedding size m can be fully recovered by ANALOGY embedding size 2 m at n = 0, Proof. Let < (x) and = (x) be the real and imaginary parts of a complex vector x. We reconstruct in (16) the embedding of (r, s, o) = + < (vr), < (vs), < (vs), < (vo), < (vo), the embedding size 2 m."}, {"heading": "5.3. Holographic Embeddings (HolE)", "text": "Hole E (Nickel et al., 2016) defines the score function as\u03c6 (s, r, o) = < vr, vs, vo > (23), where vs, vr, vo Rm, s, r, o (24), where the association of s and o is implemented via a circular correlation designated by Celsius. This formulation is motivated by the holographic reduced representation (Plate, 2003). To relate HolE to ANALOGY, we write (24) in bilinear form with a circular matrix C (vr), in which the holographic reduced representation (r, o) vs vs, v > s C (vr) vo (25), where entries of a circular matrix are defined, asC (x) = x1 xm \u00b7 xm \u00b7 x3 x2 x1 xm xm x3... x2 xm x3... x1."}, {"heading": "6. Experiments", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1. Datasets", "text": "We evaluate the ANALOGY and baselines using two benchmark data sets for multirelational embedding published in previous work (Bordes et al., 2013), namely a subset of Freebase (FB15K) for generic facts and WordNet (WN18) for lexical relationships between words. Data set statistics are summarized in Table 1."}, {"heading": "6.2. Baselines", "text": "We compare the performance of ANALOGY with a variety of multirelational embedding models developed in recent years, which can be categorized as: \u2022 translation-based models that model relationships as translation operators in the embedding space, including TransE (Bordes et al., 2013) and its variants TransH (Wang et al., 2015), TransR (Lin et al., 2015b), TransD (Ji et al., 2015), STransTransE (Nguyen et al., 2016) and RTransE (Garcia-Duran et al., 2015). \u2022 multirelational latent factor models, including LFM (Jenatton et al., 2012) and RESCAL (Nickel et al., 2011) are based on collective matrix factorization. \u2022 Models that use neural network components such as neural tensor networks (Socher et al., 2013) and transstranslation models (Let.)."}, {"heading": "6.3. Evaluation Metrics", "text": "Drawing on the literature on multirelational embedding, we use the conventional metrics Hits @ k and Mean Reciprocal Rank (MRR), which evaluate each system-produced ranking for each test instance and calculate the values of all rankings for the entire set of instances on average.The two metrics would be flawed for the negative instances that were created as rankings in the test phase and could include some positive instances in the training and validation sets (Bordes et al., 2013).One recommended remedy we followed is to remove all training and validation set triples from all rankings during the test. We use \"Filt.\" and \"Roh\" to display the evaluation metrics with or without filtering. In the first set of our experiments, we used Hits @ k with k = 10, which has been reported for most methods in the literature."}, {"heading": "6.4. Implementation Details", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.4.1. LOSS FUNCTION", "text": "We use the logistic loss for ANALOGY in all experiments, namely \"(\u03c6 (s, r, o), y) = \u2212 log \u03c3 (y\u03c6 (s, r, o)), where \u03c3 is the sigmoid activation function. Empirically, we have found that this simple loss function works reasonably well compared to more complex ranking loss functions."}, {"heading": "6.4.2. ASYNCHRONOUS ADAGRAD", "text": "Our C + + implementation2 runs over a CPU, as ANALOGY requires only light linear algebra routines. To optimize, we use asynchronous stochastic gradient descendence (SGD), in which gradients are evaluated for different mini-batches in multiple threads simultaneously and gradient updates for the common model parameters are performed without synchronization. Asynchronous SGD is highly efficient and causes little performance loss when parameters associated with different mini-batches are highly likely to be mutually separated (Recht et al., 2011). We adjust the learning rate using historical gradients with AdaGrad (Duchi et al., 2011)."}, {"heading": "6.4.3. CREATION OF NEGATIVE SAMPLES", "text": "Since only valid triples (positive instances) are explicitly specified in the training set, invalid triples (negative instances) must be artificially created. Specifically, for each positive example (s, r, o) we create three negative instances (s, r, o), (s, r, o), (s, r, o) by corrupting s, r, o with random entities / relationships s \u00b2 E, r \u00b2 R, o \u00b2 E. The unification of all positive and negative instances defines our data distribution D for SGD updates. 2Code available at https: / / github.com / quark0 / ANALOGY."}, {"heading": "6.4.4. MODEL SELECTION", "text": "We performed a grid search to find the hyperparameters of ANALOGY that maximize the filtered MRR on the validation set by enumerating all combinations of embedding size m = 100, 150, 200}, '2 weight decay factor \u03bb = 10 \u2212 1, 10 \u2212 2, 10 \u2212 3} of model coefficients v and W and the ratio of negative to positive sample \u03b1 = 3, 6}. The resulting hyperparameters for the WN18 dataset are m = 200, \u03bb = 10 \u2212 2, \u03b1 = 3, and those for the FB15K dataset are m = 200, \u03bb = 10 \u2212 3, \u03b1 = 6. The number of scalars on the diagonal of each Br is always set to m2. We set the initial learning rate for both datasets to 0.1 and adjust it during optimization with AdaGrad. All models are trained for 500 epochs."}, {"heading": "6.5. Results", "text": "In fact, it is the case that most of them are able to abide by the rules that they have imposed on themselves, and that they are able to abide by the rules that they have imposed on themselves. (...) Most of them are able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are not able to abide by the rules. (...) Most of them are able to abide by the rules. (...) Most of them are not able to abide by the rules. (...)"}, {"heading": "7. Conclusion", "text": "We have presented a novel framework for explicit modeling of analog structures in multirelational embedding, along with a differentiated objective function and a linear time sequencing algorithm for large-scale embedding of knowledge graphs. The proposed approach achieves the latest results on two popular benchmark datasets, exceeding in most cases a large number of strong baselines. Although we focused only on multirelational inference for embedding knowledge bases, we believe that analog structures exist in many other problems that go beyond the scope of this work. We hope that this work will shed light on a wide range of important issues where scalable conclusions for analog analysis would be effective, such as machine translation and image captions (both problems require modeling cross-domain analogies)."}, {"heading": "Acknowledgments", "text": "We thank the reviewers for their helpful comments. This work is partially supported by the National Science Foundation (NSF) under funding number IIS-1546329."}], "references": [{"title": "Dbpedia: A nucleus for a web of open data", "author": ["Auer", "S\u00f6ren", "Bizer", "Christian", "Kobilarov", "Georgi", "Lehmann", "Jens", "Cyganiak", "Richard", "Ives", "Zachary"], "venue": "In The semantic web,", "citeRegEx": "Auer et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Auer et al\\.", "year": 2007}, {"title": "Freebase: a collaboratively created graph database for structuring human knowledge", "author": ["Bollacker", "Kurt", "Evans", "Colin", "Paritosh", "Praveen", "Sturge", "Tim", "Taylor", "Jamie"], "venue": "In Proceedings of the 2008 ACM SIGMOD international conference on Management of data,", "citeRegEx": "Bollacker et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Bollacker et al\\.", "year": 2008}, {"title": "Learning structured embeddings of knowledge bases", "author": ["Bordes", "Antoine", "Weston", "Jason", "Collobert", "Ronan", "Bengio", "Yoshua"], "venue": "In Conference on artificial intelligence,", "citeRegEx": "Bordes et al\\.,? \\Q1923\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 1923}, {"title": "Joint learning of words and meaning representations for open-text semantic parsing", "author": ["Bordes", "Antoine", "Glorot", "Xavier", "Weston", "Jason", "Bengio", "Yoshua"], "venue": "In AISTATS,", "citeRegEx": "Bordes et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2012}, {"title": "Translating embeddings for modeling multi-relational data", "author": ["Bordes", "Antoine", "Usunier", "Nicolas", "Garcia-Duran", "Alberto", "Weston", "Jason", "Yakhnenko", "Oksana"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Bordes et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Bordes et al\\.", "year": 2013}, {"title": "Category theory: an abstract setting for analogy and comparison", "author": ["Brown", "Ronald", "Porter", "Tim"], "venue": "In What is category theory,", "citeRegEx": "Brown et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Brown et al\\.", "year": 2006}, {"title": "Learning new facts from knowledge bases with neural tensor networks and semantic word vectors", "author": ["Chen", "Danqi", "Socher", "Richard", "Manning", "Christopher D", "Ng", "Andrew Y"], "venue": "arXiv preprint arXiv:1301.3618,", "citeRegEx": "Chen et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Chen et al\\.", "year": 2013}, {"title": "Entity query feature expansion using knowledge base links", "author": ["Dalton", "Jeffrey", "Dietz", "Laura", "Allan", "James"], "venue": "In Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,", "citeRegEx": "Dalton et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Dalton et al\\.", "year": 2014}, {"title": "Adaptive subgradient methods for online learning and stochastic optimization", "author": ["Duchi", "John", "Hazan", "Elad", "Singer", "Yoram"], "venue": "Journal of Machine Learning Research,", "citeRegEx": "Duchi et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Duchi et al\\.", "year": 2011}, {"title": "The structure-mapping engine: Algorithm and examples", "author": ["Falkenhainer", "Brian", "Forbus", "Kenneth D", "Gentner", "Dedre"], "venue": "Artificial intelligence,", "citeRegEx": "Falkenhainer et al\\.,? \\Q1989\\E", "shortCiteRegEx": "Falkenhainer et al\\.", "year": 1989}, {"title": "Building watson: An overview of the deepqa project", "author": ["Ferrucci", "David", "Brown", "Eric", "Chu-Carroll", "Jennifer", "Fan", "James", "Gondek", "Kalyanpur", "Aditya A", "Lally", "Adam", "Murdock", "J William", "Nyberg", "Prager", "John"], "venue": "AI magazine,", "citeRegEx": "Ferrucci et al\\.,? \\Q2010\\E", "shortCiteRegEx": "Ferrucci et al\\.", "year": 2010}, {"title": "Wikipediabased semantic interpretation for natural language processing", "author": ["Gabrilovich", "Evgeniy", "Markovitch", "Shaul"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Gabrilovich et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Gabrilovich et al\\.", "year": 2009}, {"title": "Composing relationships with translations", "author": ["Garcia-Duran", "Alberto", "Bordes", "Antoine", "Usunier", "Nicolas"], "venue": "PhD thesis, CNRS, Heudiasyc,", "citeRegEx": "Garcia.Duran et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Garcia.Duran et al\\.", "year": 2015}, {"title": "Structure-mapping: A theoretical framework for analogy", "author": ["Gentner", "Dedre"], "venue": "Cognitive science,", "citeRegEx": "Gentner and Dedre.,? \\Q1983\\E", "shortCiteRegEx": "Gentner and Dedre.", "year": 1983}, {"title": "Introduction to statistical relational learning", "author": ["Getoor", "Lise"], "venue": "MIT press,", "citeRegEx": "Getoor and Lise.,? \\Q2007\\E", "shortCiteRegEx": "Getoor and Lise.", "year": 2007}, {"title": "Traversing knowledge graphs in vector space", "author": ["Guu", "Kelvin", "Miller", "John", "Liang", "Percy"], "venue": "arXiv preprint arXiv:1506.01094,", "citeRegEx": "Guu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Guu et al\\.", "year": 2015}, {"title": "Learning to represent knowledge graphs with gaussian embedding", "author": ["He", "Shizhu", "Liu", "Kang", "Ji", "Guoliang", "Zhao", "Jun"], "venue": "In Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,", "citeRegEx": "He et al\\.,? \\Q2015\\E", "shortCiteRegEx": "He et al\\.", "year": 2015}, {"title": "Analogy as the core of cognition. The analogical mind: Perspectives from cognitive science", "author": ["Hofstadter", "Douglas R"], "venue": null, "citeRegEx": "Hofstadter and R.,? \\Q2001\\E", "shortCiteRegEx": "Hofstadter and R.", "year": 2001}, {"title": "Mental leaps: Analogy in creative thought", "author": ["Holyoak", "Keith J", "Keith James", "Thagard", "Paul"], "venue": "MIT press,", "citeRegEx": "Holyoak et al\\.,? \\Q1996\\E", "shortCiteRegEx": "Holyoak et al\\.", "year": 1996}, {"title": "A latent factor model for highly multi-relational data", "author": ["Jenatton", "Rodolphe", "Roux", "Nicolas L", "Bordes", "Antoine", "Obozinski", "Guillaume R"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Jenatton et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Jenatton et al\\.", "year": 2012}, {"title": "Knowledge graph completion with adaptive sparse transfer matrix", "author": ["Ji", "Guoliang", "Liu", "Kang", "He", "Shizhu", "Zhao", "Jun"], "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17,", "citeRegEx": "Ji et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Ji et al\\.", "year": 2016}, {"title": "Modeling relation paths for representation learning of knowledge bases", "author": ["Lin", "Yankai", "Liu", "Zhiyuan", "Luan", "Huanbo", "Sun", "Maosong", "Rao", "Siwei", "Song"], "venue": "arXiv preprint arXiv:1506.00379,", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Learning entity and relation embeddings for knowledge graph completion", "author": ["Lin", "Yankai", "Liu", "Zhiyuan", "Sun", "Maosong", "Yang", "Zhu", "Xuan"], "venue": "In AAAI,", "citeRegEx": "Lin et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Lin et al\\.", "year": 2015}, {"title": "Bipartite edge prediction via transductive learning over product graphs", "author": ["Liu", "Hanxiao", "Yang", "Yiming"], "venue": "In ICML, pp", "citeRegEx": "Liu et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Cross-graph learning of multi-relational associations", "author": ["Liu", "Hanxiao", "Yang", "Yiming"], "venue": "In Proceedings of The 33rd International Conference on Machine Learning,", "citeRegEx": "Liu et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Liu et al\\.", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Mikolov", "Tomas", "Sutskever", "Ilya", "Chen", "Kai", "Corrado", "Greg S", "Dean", "Jeff"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Mikolov et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distant supervision for relation extraction with an incomplete knowledge base", "author": ["Min", "Bonan", "Grishman", "Ralph", "Wan", "Li", "Wang", "Chang", "Gondek", "David"], "venue": "In HLTNAACL,", "citeRegEx": "Min et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Min et al\\.", "year": 2013}, {"title": "Stranse: a novel embedding model of entities and relationships in knowledge bases", "author": ["Nguyen", "Dat Quoc", "Sirts", "Kairit", "Qu", "Lizhen", "Johnson", "Mark"], "venue": "arXiv preprint arXiv:1606.08140,", "citeRegEx": "Nguyen et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nguyen et al\\.", "year": 2016}, {"title": "A three-way model for collective learning on multi-relational data", "author": ["Nickel", "Maximilian", "Tresp", "Volker", "Kriegel", "HansPeter"], "venue": "In Proceedings of the 28th international conference on machine learning", "citeRegEx": "Nickel et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2011}, {"title": "A review of relational machine learning for knowledge graphs", "author": ["Nickel", "Maximilian", "Murphy", "Kevin", "Tresp", "Volker", "Gabrilovich", "Evgeniy"], "venue": "arXiv preprint arXiv:1503.00759,", "citeRegEx": "Nickel et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2015}, {"title": "Holographic embeddings of knowledge graphs", "author": ["Nickel", "Maximilian", "Rosasco", "Lorenzo", "Poggio", "Tomaso A"], "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, February 12-17,", "citeRegEx": "Nickel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Nickel et al\\.", "year": 2016}, {"title": "Glove: Global vectors for word representation", "author": ["Pennington", "Jeffrey", "Socher", "Richard", "Manning", "Christopher D"], "venue": "In EMNLP,", "citeRegEx": "Pennington et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Holographic reduced representation: Distributed representation for cognitive structures", "author": ["Plate", "Tony A"], "venue": null, "citeRegEx": "Plate and A.,? \\Q2003\\E", "shortCiteRegEx": "Plate and A.", "year": 2003}, {"title": "Hogwild: A lock-free approach to parallelizing stochastic gradient descent", "author": ["Recht", "Benjamin", "Re", "Christopher", "Wright", "Stephen", "Niu", "Feng"], "venue": "In Advances in Neural Information Processing Systems,", "citeRegEx": "Recht et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Recht et al\\.", "year": 2011}, {"title": "Introducing the knowledge graph: things, not strings", "author": ["Singhal", "Amit"], "venue": "Official google blog,", "citeRegEx": "Singhal and Amit.,? \\Q2012\\E", "shortCiteRegEx": "Singhal and Amit.", "year": 2012}, {"title": "Reasoning with neural tensor networks for knowledge base completion", "author": ["Socher", "Richard", "Chen", "Danqi", "Manning", "Christopher D", "Ng", "Andrew"], "venue": "In Advances in neural information processing systems,", "citeRegEx": "Socher et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Socher et al\\.", "year": 2013}, {"title": "Observed versus latent features for knowledge base and text inference", "author": ["Toutanova", "Kristina", "Chen", "Danqi"], "venue": "In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality,", "citeRegEx": "Toutanova et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Toutanova et al\\.", "year": 2015}, {"title": "Complex embeddings for simple link prediction", "author": ["Trouillon", "Th\u00e9o", "Welbl", "Johannes", "Riedel", "Sebastian", "Gaussier", "\u00c9ric", "Bouchard", "Guillaume"], "venue": "In Proceedings of the 33nd International Conference on Machine Learning,", "citeRegEx": "Trouillon et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Trouillon et al\\.", "year": 2016}, {"title": "The latent relation mapping engine: Algorithm and experiments", "author": ["Turney", "Peter D"], "venue": "Journal of Artificial Intelligence Research,", "citeRegEx": "Turney and D.,? \\Q2008\\E", "shortCiteRegEx": "Turney and D.", "year": 2008}, {"title": "Knowledge graph embedding by translating on hyperplanes", "author": ["Wang", "Zhen", "Zhang", "Jianwen", "Feng", "Jianlin", "Chen", "Zheng"], "venue": "In AAAI,", "citeRegEx": "Wang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Wang et al\\.", "year": 2014}, {"title": "The algebraic eigenvalue problem, volume 87", "author": ["Wilkinson", "James Hardy"], "venue": null, "citeRegEx": "Wilkinson et al\\.,? \\Q1965\\E", "shortCiteRegEx": "Wilkinson et al\\.", "year": 1965}, {"title": "Embedding entities and relations for learning and inference in knowledge bases", "author": ["Yang", "Bishan", "Yih", "Wen-tau", "He", "Xiaodong", "Gao", "Jianfeng", "Deng", "Li"], "venue": "CoRR, abs/1412.6575,", "citeRegEx": "Yang et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Yang et al\\.", "year": 2014}, {"title": "A re-examination of text categorization methods", "author": ["Yang", "Yiming", "Liu", "Xin"], "venue": "In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval,", "citeRegEx": "Yang et al\\.,? \\Q1999\\E", "shortCiteRegEx": "Yang et al\\.", "year": 1999}], "referenceMentions": [{"referenceID": 1, "context": "This problem has become increasingly important in recent machine learning due to the broad range of important applications of large-scale knowledge bases, such as Freebase (Bollacker et al., 2008), DBpedia (Auer et al.", "startOffset": 172, "endOffset": 196}, {"referenceID": 0, "context": ", 2008), DBpedia (Auer et al., 2007) and Google\u2019s Knowledge Graph (Singhal, 2012), including question-answering (Ferrucci et al.", "startOffset": 17, "endOffset": 36}, {"referenceID": 10, "context": ", 2007) and Google\u2019s Knowledge Graph (Singhal, 2012), including question-answering (Ferrucci et al., 2010), information retrieval (Dalton et al.", "startOffset": 83, "endOffset": 106}, {"referenceID": 7, "context": ", 2010), information retrieval (Dalton et al., 2014) and natural language processing (Gabrilovich & Markovitch, 2009).", "startOffset": 31, "endOffset": 52}, {"referenceID": 26, "context": "world knowledge graph is both extremely large and highly incomplete by nature (Min et al., 2013).", "startOffset": 78, "endOffset": 96}, {"referenceID": 29, "context": "Various statistical relational learning methods (Getoor, 2007; Nickel et al., 2015) have been proposed for this task, among which vector-space embedding models are most particular due to their advantageous performance and scalability (Bordes et al.", "startOffset": 48, "endOffset": 83}, {"referenceID": 4, "context": ", 2015) have been proposed for this task, among which vector-space embedding models are most particular due to their advantageous performance and scalability (Bordes et al., 2013).", "startOffset": 158, "endOffset": 179}, {"referenceID": 28, "context": "Representative models of this kind include tensor factorization (Singhal, 2012; Nickel et al., 2011), neural tensor networks (Socher et al.", "startOffset": 64, "endOffset": 100}, {"referenceID": 35, "context": ", 2011), neural tensor networks (Socher et al., 2013; Chen et al., 2013), translationbased models (Bordes et al.", "startOffset": 32, "endOffset": 72}, {"referenceID": 6, "context": ", 2011), neural tensor networks (Socher et al., 2013; Chen et al., 2013), translationbased models (Bordes et al.", "startOffset": 32, "endOffset": 72}, {"referenceID": 4, "context": ", 2013), translationbased models (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015b), bilinear models and its variants (Yang et al.", "startOffset": 33, "endOffset": 92}, {"referenceID": 39, "context": ", 2013), translationbased models (Bordes et al., 2013; Wang et al., 2014; Lin et al., 2015b), bilinear models and its variants (Yang et al.", "startOffset": 33, "endOffset": 92}, {"referenceID": 41, "context": ", 2015b), bilinear models and its variants (Yang et al., 2014; Trouillon et al., 2016), pathwise methods (Guu et al.", "startOffset": 43, "endOffset": 86}, {"referenceID": 37, "context": ", 2015b), bilinear models and its variants (Yang et al., 2014; Trouillon et al., 2016), pathwise methods (Guu et al.", "startOffset": 43, "endOffset": 86}, {"referenceID": 15, "context": ", 2016), pathwise methods (Guu et al., 2015), embeddings based on holographic representations (Nickel et al.", "startOffset": 26, "endOffset": 44}, {"referenceID": 30, "context": ", 2015), embeddings based on holographic representations (Nickel et al., 2016), and product graphs that utilizes additional site information for the predictions of unseen edges in a semi-supervised manner (Liu & Yang, 2015; 2016).", "startOffset": 57, "endOffset": 78}, {"referenceID": 9, "context": "Although analogical reasoning was an active research topic in classic AI (artificial intelligence), early computational models mainly focused on non-differentiable rulebased reasoning (Gentner, 1983; Falkenhainer et al., 1989; Turney, 2008), which can hardly scale to very large KBs such as Freebase or Google\u2019s Knowledge Graph.", "startOffset": 184, "endOffset": 240}, {"referenceID": 25, "context": "It is worth mentioning that analogical structures have been observed in the output of several word/entity embedding models (Mikolov et al., 2013; Pennington et al., 2014).", "startOffset": 123, "endOffset": 170}, {"referenceID": 31, "context": "It is worth mentioning that analogical structures have been observed in the output of several word/entity embedding models (Mikolov et al., 2013; Pennington et al., 2014).", "startOffset": 123, "endOffset": 170}, {"referenceID": 4, "context": "In contrast to some previous models (Bordes et al., 2013) where relations are modeled as additive translating operators, namely vs + wr \u2248 vo, the multiplicative formulation in (1) offers a natural analogy to the first-order logic where each relation is treated as a predicate operator over input arguments (subject and object in our case).", "startOffset": 36, "endOffset": 57}, {"referenceID": 28, "context": "Multiplicative models are also found to substantially outperform additive models empirically (Nickel et al., 2011; Yang et al., 2014).", "startOffset": 93, "endOffset": 133}, {"referenceID": 41, "context": "Multiplicative models are also found to substantially outperform additive models empirically (Nickel et al., 2011; Yang et al., 2014).", "startOffset": 93, "endOffset": 133}, {"referenceID": 30, "context": ", 2006), which have been implicitly used in recent work on holographic representations (Nickel et al., 2016).", "startOffset": 87, "endOffset": 108}, {"referenceID": 18, "context": "Analogical reasoning is known to play a central role in human induction about knowledge (Gentner, 1983; Minsky, 1988; Holyoak et al., 1996; Hofstadter, 2001).", "startOffset": 88, "endOffset": 157}, {"referenceID": 25, "context": "Consider the famous example in the word embedding literature (Mikolov et al., 2013; Pennington et al., 2014), for the following entities and relations among them:", "startOffset": 61, "endOffset": 108}, {"referenceID": 31, "context": "Consider the famous example in the word embedding literature (Mikolov et al., 2013; Pennington et al., 2014), for the following entities and relations among them:", "startOffset": 61, "endOffset": 108}, {"referenceID": 41, "context": "The composition of two relations (linear maps) is naturally implemented via matrix multiplication (Yang et al., 2014; Guu et al., 2015), hence equation (4) indicates", "startOffset": 98, "endOffset": 135}, {"referenceID": 15, "context": "The composition of two relations (linear maps) is naturally implemented via matrix multiplication (Yang et al., 2014; Guu et al., 2015), hence equation (4) indicates", "startOffset": 98, "endOffset": 135}, {"referenceID": 41, "context": "In the following we provide a unified view of several embedding models (Yang et al., 2014; Trouillon et al., 2016; Nickel et al., 2016), by showing that they are restricted versions under our framework, hence are implicitly imposing analogical properties.", "startOffset": 71, "endOffset": 135}, {"referenceID": 37, "context": "In the following we provide a unified view of several embedding models (Yang et al., 2014; Trouillon et al., 2016; Nickel et al., 2016), by showing that they are restricted versions under our framework, hence are implicitly imposing analogical properties.", "startOffset": 71, "endOffset": 135}, {"referenceID": 30, "context": "In the following we provide a unified view of several embedding models (Yang et al., 2014; Trouillon et al., 2016; Nickel et al., 2016), by showing that they are restricted versions under our framework, hence are implicitly imposing analogical properties.", "startOffset": 71, "endOffset": 135}, {"referenceID": 41, "context": "DistMult (Yang et al., 2014) embeds both entities and relations as vectors, and defines the score function as", "startOffset": 9, "endOffset": 28}, {"referenceID": 37, "context": "ComplEx (Trouillon et al., 2016) extends the embeddings to the complex domain C, which defines \u03c6(s, r, o) = < (\u3008vs, vr, vo\u3009) (16) where vs, vr, vo \u2208 C,\u2200s, r, o (17)", "startOffset": 8, "endOffset": 32}, {"referenceID": 30, "context": "HolE (Nickel et al., 2016) defines the score function as", "startOffset": 5, "endOffset": 26}, {"referenceID": 4, "context": "We evaluate ANALOGY and the baselines over two benchmark datasets for multi-relational embedding released by previous work (Bordes et al., 2013), namely a subset of Freebase (FB15K) for generic facts and WordNet (WN18) for lexical relationships between words.", "startOffset": 123, "endOffset": 144}, {"referenceID": 4, "context": "\u2022 Translation-based models where relations are modeled as translation operators in the embedding space, including TransE (Bordes et al., 2013) and its variants TransH (Wang et al.", "startOffset": 121, "endOffset": 142}, {"referenceID": 39, "context": ", 2013) and its variants TransH (Wang et al., 2014), TransR (Lin et al.", "startOffset": 32, "endOffset": 51}, {"referenceID": 27, "context": ", 2015), STransE (Nguyen et al., 2016) and RTransE (Garcia-Duran et al.", "startOffset": 17, "endOffset": 38}, {"referenceID": 12, "context": ", 2016) and RTransE (Garcia-Duran et al., 2015).", "startOffset": 20, "endOffset": 47}, {"referenceID": 19, "context": "\u2022 Multi-relational latent factor models including LFM (Jenatton et al., 2012) and RESCAL (Nickel et al.", "startOffset": 54, "endOffset": 77}, {"referenceID": 28, "context": ", 2012) and RESCAL (Nickel et al., 2011) based collective matrix factorization.", "startOffset": 19, "endOffset": 40}, {"referenceID": 35, "context": "\u2022 Models involving neural network components such as neural tensor networks (Socher et al., 2013) and PTransE-RNN (Lin et al.", "startOffset": 76, "endOffset": 97}, {"referenceID": 41, "context": "\u2022 Models subsumed under our proposed framework (\u00a75), including DistMult (Yang et al., 2014) based simple multiplicative interactions, ComplEx (Trouillon et al.", "startOffset": 72, "endOffset": 91}, {"referenceID": 37, "context": ", 2014) based simple multiplicative interactions, ComplEx (Trouillon et al., 2016) using complex coefficients and HolE (Nickel et al.", "startOffset": 58, "endOffset": 82}, {"referenceID": 30, "context": ", 2016) using complex coefficients and HolE (Nickel et al., 2016) based on holographic representations.", "startOffset": 44, "endOffset": 65}, {"referenceID": 4, "context": "The two metrics would be flawed for the negative instances created in the test phase as a ranked list may contain some positive instances in the training and validation sets (Bordes et al., 2013).", "startOffset": 174, "endOffset": 195}, {"referenceID": 33, "context": "Asynchronous SGD is highly efficient, and causes little performance drop when parameters associated with different mini-batches are mutually disjoint with a high probability (Recht et al., 2011).", "startOffset": 174, "endOffset": 194}, {"referenceID": 8, "context": "We adapt the learning rate based on historical gradients using AdaGrad (Duchi et al., 2011).", "startOffset": 71, "endOffset": 91}, {"referenceID": 4, "context": "Models WN18 FB15K Unstructured (Bordes et al., 2013) 38.", "startOffset": 31, "endOffset": 52}, {"referenceID": 28, "context": "3 RESCAL (Nickel et al., 2011) 52.", "startOffset": 9, "endOffset": 30}, {"referenceID": 35, "context": "1 NTN (Socher et al., 2013) 66.", "startOffset": 6, "endOffset": 27}, {"referenceID": 3, "context": "4 SME (Bordes et al., 2012) 74.", "startOffset": 6, "endOffset": 27}, {"referenceID": 19, "context": "8 LFM (Jenatton et al., 2012) 81.", "startOffset": 6, "endOffset": 29}, {"referenceID": 39, "context": "1 TransH (Wang et al., 2014) 86.", "startOffset": 9, "endOffset": 28}, {"referenceID": 4, "context": "4 TransE (Bordes et al., 2013) 89.", "startOffset": 9, "endOffset": 30}, {"referenceID": 12, "context": "4 RTransE (Garcia-Duran et al., 2015) \u2013 76.", "startOffset": 10, "endOffset": 37}, {"referenceID": 16, "context": "2 KG2E (He et al., 2015) 93.", "startOffset": 7, "endOffset": 24}, {"referenceID": 27, "context": "0 STransE (Nguyen et al., 2016) 93.", "startOffset": 10, "endOffset": 31}, {"referenceID": 41, "context": "7 DistMult (Yang et al., 2014) 93.", "startOffset": 11, "endOffset": 30}, {"referenceID": 20, "context": "4 TransSparse (Ji et al., 2016) 93.", "startOffset": 14, "endOffset": 31}, {"referenceID": 37, "context": "0 ComplEx (Trouillon et al., 2016) 94.", "startOffset": 10, "endOffset": 34}, {"referenceID": 30, "context": "0 HolE (Nickel et al., 2016) 94.", "startOffset": 7, "endOffset": 28}, {"referenceID": 37, "context": "the results published in (Trouillon et al., 2016) and (Nickel et al.", "startOffset": 25, "endOffset": 49}, {"referenceID": 30, "context": ", 2016) and (Nickel et al., 2016), respectively.", "startOffset": 12, "endOffset": 33}, {"referenceID": 28, "context": ") RESCAL (Nickel et al., 2011) 89.", "startOffset": 9, "endOffset": 30}, {"referenceID": 4, "context": "9 TransE (Bordes et al., 2013) 45.", "startOffset": 9, "endOffset": 30}, {"referenceID": 41, "context": "2 DistMult (Yang et al., 2014) 82.", "startOffset": 11, "endOffset": 30}, {"referenceID": 30, "context": "3 HolE (Nickel et al., 2016) 93.", "startOffset": 7, "endOffset": 28}, {"referenceID": 37, "context": "3 ComplEx (Trouillon et al., 2016) 94.", "startOffset": 10, "endOffset": 34}], "year": 2017, "abstractText": "Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledgebased inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the analogical properties of the embedded entities and relations. By formulating the learning objective in a differentiable fashion, our model enjoys both theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.", "creator": "LaTeX with hyperref package"}}}