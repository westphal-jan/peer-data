{"id": "1705.02735", "review": {"conference": "acl", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2017", "title": "Combating Human Trafficking with Deep Multimodal Models", "abstract": "Human trafficking is a global epidemic affecting millions of people across the planet. Sex trafficking, the dominant form of human trafficking, has seen a significant rise mostly due to the abundance of escort websites, where human traffickers can openly advertise among at-will escort advertisements. In this paper, we take a major step in the automatic detection of advertisements suspected to pertain to human trafficking. We present a novel dataset called Trafficking-10k, with more than 10,000 advertisements annotated for this task. The dataset contains two sources of information per advertisement: text and images. For the accurate detection of trafficking advertisements, we designed and trained a deep multimodal model called the Human Trafficking Deep Network (HTDN).", "histories": [["v1", "Mon, 8 May 2017 03:48:01 GMT  (15878kb,D)", "http://arxiv.org/abs/1705.02735v1", "ACL 2017 Long Paper"]], "COMMENTS": "ACL 2017 Long Paper", "reviews": [], "SUBJECTS": "cs.CL cs.CY", "authors": ["edmund tong", "amir zadeh", "cara jones", "louis-philippe morency"], "accepted": true, "id": "1705.02735"}, "pdf": {"name": "1705.02735.pdf", "metadata": {"source": "CRF", "title": "Combating Human Trafficking with Deep Multimodal Models", "authors": ["Edmund Tong", "Amir Zadeh", "Cara Jones"], "emails": ["edtong@cmu.edu", "abagherz@cs.cmu.edu", "cara@marinusanalytics.com", "morency@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "The number of cases reported rose from 3,279 to 7,572 in 2016 - more than twice as many as the number of cases where the issue is whether and how the people are, who they are, and whether it is even about the issue of how the people are, who they are, the way it is about the people, the way it is about the people, the way it is about the people and the way it is about the people, the way it is about the people and the way it is about the people and the way it is about the people."}, {"heading": "2 Related Works", "text": "Most of these approaches use simplistic methods such as multimedia matching (Zhou et al., 2016), text-based filter classifiers such as random forests, logistical regression and SVMs (Dubrawski et al., 2015), and recognition of content using text information (Zhou et al., 2016). Multimodal approaches have gained popularity in recent years and have been used for medical purposes, such as detection of suicide risks, PTSD and depression (Scherer et al., 2016)."}, {"heading": "3 Trafficking-10k Dataset", "text": "In this section, we present the data set for our studies. We formalize the problem of recognizing the sex trade as a machine learning task. The input data is text and images; these are mapped to determine a measure of how suspicious the advertising regarding human trafficking is."}, {"heading": "3.1 Data Acquisition and Preprocessing", "text": "The distribution of advertising in the United States and Canada is illustrated in Figure 1, which shows the diversity of advertising in Trafficking-10k. This diversity ensures that models trained on Trafficking-10k can be applicable nationwide. 10,000 ads collected are only made available to the scientific community, each consisting of text and zero or more images. The text in the record is in plain text format, derived from removing the HTML tags from the raw source of advertising. The string in each ad is encoded as UTF-8, as there is abundant use of smilies and non-English characters. Advertising is shortened to the first 184 words, as they cover more than 90% of advertising. Images are reduced to 224 x 224 pixels with RGB channels."}, {"heading": "3.2 Trafficking Annotation", "text": "To determine whether or not an ad is suspicious requires years of practice and experience in working closely with law enforcement. As a result, the comment is a highly complicated and expensive process that cannot be scaled through crowdsourcing. In our data set, comments are made by two experts, each with at least five years of experience in detecting human trafficking, and another annotator with one year of experience. In our data set, comments are made by three experts: one expert has over a year of experience, and the other two have over five years of experience in detecting human trafficking. To calculate the Interannotator Agreement, each annotator receives the same set of 1,000 comments and the nominal agreement is found: There was an 83% match in pairs (0.62 Krippendorff alpha). Also, to ensure that the comments are non-formal."}, {"heading": "3.3 Analysis of Language", "text": "The nature of the text content in these ads raises the question of how we can draw conclusions in a linguistic environment with an ever-evolving lexicon. Language used in the Trafficking 10k dataset is highly at odds with standard grammar. Often, words are obscured by emojis and symbols, the word sequence is inconsistent, and there is rarely any form of electorate. This form of language is completely different from spoken and written English. These attributes make accompanying ads appear somewhat similar to tweets, especially since these ads are usually short (more than 90% of the ads have a maximum of 184 words). Another point of complexity in these ads is the high number of unigrams due to the use of unusual words and obfuscation. In addition to the complexity of the unigram, advertisers are continually changing their writing patterns, making this problem more complex."}, {"heading": "3.4 Dataset Statistics", "text": "There are 106,954 unique specimens, 353,324 unique bigrams and 565,403 trigrams in the Trafficking 10k dataset. There are 60,337 images. The total number of unique characters, including spaces, punctuations and hexadecimal characters, is 182. The average length of an ad is 137 words, with a2This option is grayed out for 10 seconds to encourage commenters to make an intuitive decision. Advertising prolongs standard deviation from 74, median 133. The shortest advertisement has 7 unique specimens, and the longest advertisement has 1810 unique specimens. There are 106,954 unique specimens, 353,324 unique bigrams and 565,403 trigrams in the Trafficking 10k dataset. The average number of images in an advertisement is 5.9; the median is 0, and the maximum is 90.The length of suspicious bigrams and 565,403 trigrams in the Trafficking 10k dataset."}, {"heading": "4 Model", "text": "In this section, we present our deep multimodal network called the Human Trafficking Deep Network (HTDN). The HTDN is a multimodal network with voice and image components. The input to the HTDN consists of advertising, text and images. The HTDN is shown in Figure 3. Later in this section, we will outline the different parts of the HTDN and the input functions for each component."}, {"heading": "4.1 Trafficking Word Embeddings", "text": "Our approach to dealing with the adversarial environment of escort ads is to use word vectors that define words not on the basis of their constituent characters, but on the basis of their context. Consider, for example, the two uniigrams \"cash\" and \"\u00a9 a $h.\" Although these contain different characters, they are semantically the same, and they occur in the same context. Therefore, we expect both uniigrams to be associated with similar vectors. Word embeddings that are pre-trained for general domains do not cover most of the uniigrams in Trafficking 10k. For example, the GloVe embedding (Pennington et al., 2014), which was trained on Wikipedia, covers only 49.7% of our uniigrams. The first step in the HTDN pipeline is to train word vectors (Mikolov et al., 2013), based on the Skip-gram model."}, {"heading": "4.2 Language Network", "text": "Our language network is designed to deal with two challenging aspects of escort advertising: (1) constituency infringement and (2) presence of irrelevant information that has nothing to do with commerce but is present in advertising. We address these two problems by learning time-dependent embedding at word level, which allows the model not to rely on constituencies and also to memorize useful information from the past should the model be flooded with irrelevant information. Our proposed language network, Fl, uses a sequence of word vectors w = [w1,..., wt] as input, and outputs a neural language representation hl. In a first step, Fl uses the word embedding as input into a Long Short Term Memory (LSTM) network and produces a new, contextual word embedding u = [u1,...,...,...,..., and then the word embedding is associated with the 0.5 Rut = the STi output."}, {"heading": "4.3 Vision Network", "text": "Parallel to the voice network, the Vision Network Fv takes advertising images as input and extracts visual representations hv. The Vision Network takes a maximum of five images; the mean number of images per ad in Trafficking-10k is 5. To learn contextual and abstract information from images, we use a deep revolutionary neural network called Trafficking-VGG (T-VGG), a fine instance of the well-known VGG network (Simonyan and Zisserman, 2014). T-VGG is a deep model with 13 successive revolutionary layers followed by 2 fully connected layers; it does not include the Softmax layer of VGG. The T-VGG fine-tuning process maps each image to a label derived from advertising, and then performs an end-to-end training."}, {"heading": "4.4 Multimodal Fusion", "text": "Escort advertising has a complex dynamic between text and images. Often, neither linguistic nor visual stimuli alone are sufficient to determine whether an ad is suspicious. Interactions between linguistic and visual stimuli cannot be trivial, so an explicit common representation is required for each neuron in linguistic and visual representations. In our multimodal fusion approach, we address this by calculating an external product between language and visual representations hl and hv to form the full space of possible results: hm = hl hv, (5) where an outer product of the two representations is. This results in a common multimodal tensor called hm for language and visual modalities. In this tensor, each neuron in the language representation is multiplied by each neuron in the visual representation, creating a new representation that contains the information of both."}, {"heading": "4.5 Convolutional Decision Network", "text": "The multimodal representation hm serves as input into the revolutionary decision network Fd. Fd has two layers of folding and max pooling with a failure rate of p = 0.5, followed by a fully connected layer of 150 neurons with a failure rate of p = 0.5. By performing turns in this space, the model can treat small areas of linguistic and visual stimuli and thus find correspondences between certain combinations of linguistic and visual representations. The final decision is made by a single sigmoid neuron."}, {"heading": "5 Experiments", "text": "In our experiments, we compare the HTDN with previously used approaches to detecting illegal advertising. In addition, we compare the HTDN with the performance of its unimodal components. In all our experiments, we perform a binary classification of whether advertising is suspected of being related to human trafficking. The most important comparison method we use is weighted accuracy and the F1 score (due to an imbalance in the data set). The formulation for weighted accuracy is as follows: Wt. Acc. = TP \u00d7 N / P + TN2N (6), where TP (or TN) are true positive (or true negative) predictions and P (or N) is the total number of positive (or negative) examples."}, {"heading": "5.1 Baselines", "text": "We compare the performance of the HTDN network with baseline models, which are divided into 4 main categories: Bag-of-Words Baselines. This set of baselines is designed to assess the performance of standard classifiers and basic language traits. We train random forest, logistic regression and linear SVMs to show the performance of simple linguistic models. Keyword baselines show the performance of models that use a set of 108 keywords, all strongly related to human trafficking, provided by law enforcers. 3 A binary uniform vector representing these keywords is used to train the random forest, logistic regression and linear SVM models.108 One-Hot Baseline, we use feature selection techniques-3Not presented in this paper due to the sensitive nature of these keywords."}, {"heading": "5.2 Training Parameters", "text": "The HTDN model is trained with the Adam Optimizer (Kingma and Ba, 2014), the neural weights were randomly initialized using the Xavier initialization technique (Glorot and Bengio, 2010), and the random forest model uses 10 estimators with no maximum depth and a minimum sample split value of 2. The linear SVM model uses a \"2 penalty and a square hinge loss with C = 1."}, {"heading": "6 Results and Discussion", "text": "The results of our experiments are presented in Table 1. We report the results using three metrics: F1 score, weighted accuracy and accuracy. Due to the imbalance between the number of positive and negative samples, weighted accuracy is more informative than unweighted accuracy, so we focus on the earlier HTDN. The first observation from Table 1 is that the HTDN model outperforms all proposed baselines. There is a significant gap between the HTDN (and variants) and other non-neural approaches. This better performance is an indicator of complex interactions in detecting the dynamics of human trafficking, that of the HTDN. Both modalities are helpful. Both modalities are helpful in predicting signs of human trafficking (Fl and Fv [T-VGG]). Fine-tuning of VGG network parameters shows an improvement over previously trained VGG parameters. Because GG is more important language than FG indicates better performance for trading [FG]."}, {"heading": "7 Conclusion and Future Work", "text": "We have designed a novel dataset called the Human Trafficking Deep Network (HTDN). We have compared the performance of the HTDN with various models that use language and vision alone. HTDN has surpassed all of these models, suggesting that using information from both sources can be more helpful than using just one. Exploring language through character modeling. To eliminate the need to retrain word vectors as the language of the domain evolves, we plan to use character models to learn a better language model for commerce. As new blurred words are introduced to accompany advertising, our hope is that character models remain unchangeable as the language of the domain evolves."}, {"heading": "Acknowledgements", "text": "We would like to thank William Chargin for compiling numbers and revising this essay. We would also like to thank Torsten Wo \ufffd rtwein for his help in visualizing our data. We would also like to thank our anonymous reviewers for their valuable feedback. Finally, we would like to thank employees of Marinus Analytics for the time and effort they put into annotating ads for the record, and for allowing us to use their ad data."}], "references": [{"title": "Vqa: Visual question answering", "author": ["Stanislaw Antol", "Aishwarya Agrawal", "Jiasen Lu", "Margaret Mitchell", "Dhruv Batra", "C Lawrence Zitnick", "Devi Parikh."], "venue": "Proceedings of the IEEE International Conference on Computer Vision. pages 2425\u20132433.", "citeRegEx": "Antol et al\\.,? 2015", "shortCiteRegEx": "Antol et al\\.", "year": 2015}, {"title": "Long-term recurrent convolutional networks for visual recognition and description", "author": ["Jeffrey Donahue", "Lisa Anne Hendricks", "Sergio Guadarrama", "Marcus Rohrbach", "Subhashini Venugopalan", "Kate Saenko", "Trevor Darrell."], "venue": "Proceedings of the IEEE", "citeRegEx": "Donahue et al\\.,? 2015", "shortCiteRegEx": "Donahue et al\\.", "year": 2015}, {"title": "Leveraging publicly available data to discern patterns of human-trafficking activity", "author": ["Artur Dubrawski", "Kyle Miller", "Matthew Barnes", "Benedikt Boecking", "Emily Kennedy."], "venue": "Journal of Human Trafficking 1(1):65\u201385.", "citeRegEx": "Dubrawski et al\\.,? 2015", "shortCiteRegEx": "Dubrawski et al\\.", "year": 2015}, {"title": "Understanding the difficulty of training deep feedforward neural networks", "author": ["Xavier Glorot", "Yoshua Bengio."], "venue": "Aistats. volume 9, pages 249\u2013256.", "citeRegEx": "Glorot and Bengio.,? 2010", "shortCiteRegEx": "Glorot and Bengio.", "year": 2010}, {"title": "Hotline statistics", "author": ["National Human Trafficking Hotline."], "venue": "https://humantraffickinghotline.org/states.", "citeRegEx": "Hotline.,? 2017", "shortCiteRegEx": "Hotline.", "year": 2017}, {"title": "Predictive patterns of sex trafficking online", "author": ["Emily Kennedy."], "venue": "Dietrich College Honors Theses .", "citeRegEx": "Kennedy.,? 2012", "shortCiteRegEx": "Kennedy.", "year": 2012}, {"title": "Adam: A method for stochastic optimization", "author": ["Diederik Kingma", "Jimmy Ba."], "venue": "arXiv preprint arXiv:1412.6980 .", "citeRegEx": "Kingma and Ba.,? 2014", "shortCiteRegEx": "Kingma and Ba.", "year": 2014}, {"title": "Visualizing data using t-sne", "author": ["Laurens van der Maaten", "Geoffrey Hinton."], "venue": "Journal of Machine Learning Research 9(Nov):2579\u20132605.", "citeRegEx": "Maaten and Hinton.,? 2008", "shortCiteRegEx": "Maaten and Hinton.", "year": 2008}, {"title": "Human trafficking and the new slavery", "author": ["Lauren A McCarthy."], "venue": "Annual Review of Law and Social Science 10:221\u2013242.", "citeRegEx": "McCarthy.,? 2014", "shortCiteRegEx": "McCarthy.", "year": 2014}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "Advances in neural information processing systems. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "An entity resolution approach to isolate instances of human trafficking online", "author": ["Chirag Nagpal", "Kyle Miller", "Benedikt Boecking", "Artur Dubrawski."], "venue": "arXiv preprint arXiv:1509.06659 .", "citeRegEx": "Nagpal et al\\.,? 2015", "shortCiteRegEx": "Nagpal et al\\.", "year": 2015}, {"title": "GloVe: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP. volume 14, pages 1532\u2013 1543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "A review of affective computing: From unimodal analysis to multimodal fusion", "author": ["Soujanya Poria", "Erik Cambria", "Rajiv Bajpai", "Amir Hussain."], "venue": "Information Fusion 1:34.", "citeRegEx": "Poria et al\\.,? 2017", "shortCiteRegEx": "Poria et al\\.", "year": 2017}, {"title": "Convolutional mkl based multimodal emotion recognition and sentiment analysis", "author": ["Soujanya Poria", "Iti Chaturvedi", "Erik Cambria", "Amir Hussain."], "venue": "2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, pages 439\u2013448.", "citeRegEx": "Poria et al\\.,? 2016", "shortCiteRegEx": "Poria et al\\.", "year": 2016}, {"title": "Self-reported symptoms of depression and ptsd are associated with reduced vowel space in screening interviews", "author": ["Stefan Scherer", "Gale M Lucas", "Jonathan Gratch", "Albert Skip Rizzo", "Louis-Philippe Morency."], "venue": "IEEE Transactions on Affective Comput-", "citeRegEx": "Scherer et al\\.,? 2016", "shortCiteRegEx": "Scherer et al\\.", "year": 2016}, {"title": "Very deep convolutional networks for large-scale image recognition", "author": ["Karen Simonyan", "Andrew Zisserman."], "venue": "arXiv preprint arXiv:1409.1556 .", "citeRegEx": "Simonyan and Zisserman.,? 2014", "shortCiteRegEx": "Simonyan and Zisserman.", "year": 2014}, {"title": "A shared task on multimodal machine translation and crosslingual image description", "author": ["Lucia Specia", "Stella Frank", "Khalil Sima\u2019an", "Desmond Elliott"], "venue": "In Proceedings of the First Conference on Machine Translation,", "citeRegEx": "Specia et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Specia et al\\.", "year": 2016}, {"title": "Depression, mood, and emotion recognition workshop", "author": ["Michel Valstar", "Jonathan Gratch", "Bj\u00f6rn Schuller", "Fabien Ringeval", "Dennis Lalanne", "Mercedes Torres Torres", "Stefan Scherer", "Giota Stratou", "Roddy Cowie", "Maja Pantic"], "venue": "Avec", "citeRegEx": "Valstar et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Valstar et al\\.", "year": 2016}, {"title": "Adolescent suicidal risk assessment in clinician-patient interaction", "author": ["Verena Venek", "Stefan Scherer", "Louis-Philippe Morency", "Albert Rizzo", "John Pestian."], "venue": "IEEE Transactions on Affective Computing .", "citeRegEx": "Venek et al\\.,? 2016", "shortCiteRegEx": "Venek et al\\.", "year": 2016}, {"title": "Image captioning with semantic attention", "author": ["Quanzeng You", "Hailin Jin", "Zhaowen Wang", "Chen Fang", "Jiebo Luo."], "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pages 4651\u20134659.", "citeRegEx": "You et al\\.,? 2016", "shortCiteRegEx": "You et al\\.", "year": 2016}, {"title": "Multimodal prediction of psychological disorders: Learning verbal and nonverbal commonalities in adjacency pairs", "author": ["Zhou Yu", "Stefen Scherer", "David Devault", "Jonathan Gratch", "Giota Stratou", "Louis-Philippe Morency", "Justine Cassell."], "venue": "Semdial 2013", "citeRegEx": "Yu et al\\.,? 2013", "shortCiteRegEx": "Yu et al\\.", "year": 2013}, {"title": "Mosi: Multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos", "author": ["Amir Zadeh", "Rowan Zellers", "Eli Pincus", "LouisPhilippe Morency."], "venue": "arXiv preprint arXiv:1606.06259 .", "citeRegEx": "Zadeh et al\\.,? 2016a", "shortCiteRegEx": "Zadeh et al\\.", "year": 2016}, {"title": "Multimodal sentiment intensity analysis in videos: Facial gestures and verbal messages", "author": ["Amir Zadeh", "Rowan Zellers", "Eli Pincus", "LouisPhilippe Morency."], "venue": "IEEE Intelligent Systems 31(6):82\u201388.", "citeRegEx": "Zadeh et al\\.,? 2016b", "shortCiteRegEx": "Zadeh et al\\.", "year": 2016}, {"title": "Multimedia metadata-based forensics in human trafficking web data", "author": ["Andrew Jie Zhou", "Jiyun Luo", "Lewis John McGibbney."], "venue": "Vanessa Murdock, Charles LA Clarke, Jaap page 10.", "citeRegEx": "Zhou et al\\.,? 2016", "shortCiteRegEx": "Zhou et al\\.", "year": 2016}], "referenceMentions": [{"referenceID": 4, "context": "The number of cases reported rose from 3,279 in 2012 to 7,572 in 2016\u2014more than doubling over the course of five years (Hotline, 2017).", "startOffset": 119, "endOffset": 134}, {"referenceID": 8, "context": "Sex trafficking is a form of human trafficking, and is a global epidemic affecting millions of people each year (McCarthy, 2014).", "startOffset": 112, "endOffset": 128}, {"referenceID": 2, "context": "While previous methods (Dubrawski et al., 2015) have used simplistic classifiers, we build an end-to-end-trained multimodal deep model called the Human Trafficking Deep Network (HTDN).", "startOffset": 23, "endOffset": 47}, {"referenceID": 23, "context": "Most of these approaches use simplistic methods such as multimedia matching (Zhou et al., 2016), text-based filtering classifiers such as random forests, logistic regression, and SVMs (Dubrawski et al.", "startOffset": 76, "endOffset": 95}, {"referenceID": 2, "context": ", 2016), text-based filtering classifiers such as random forests, logistic regression, and SVMs (Dubrawski et al., 2015), and named-entity recognition to isolate the instances of trafficking (Nagpal", "startOffset": 96, "endOffset": 120}, {"referenceID": 5, "context": "Studies have suggested using statistical methods to find keywords and signs of trafficking from data to help law enforcement agencies (Kennedy, 2012) as well as adult content filtering using textual information (Zhou et al.", "startOffset": 134, "endOffset": 149}, {"referenceID": 23, "context": "Studies have suggested using statistical methods to find keywords and signs of trafficking from data to help law enforcement agencies (Kennedy, 2012) as well as adult content filtering using textual information (Zhou et al., 2016).", "startOffset": 211, "endOffset": 230}, {"referenceID": 14, "context": "These multimodal models have been used for medical purposes, such as detection of suicidal risk, PTSD and depression (Scherer et al., 2016; Venek et al., 2016; Yu et al., 2013; Valstar et al., 2016); sentiment analysis (Zadeh et al.", "startOffset": 117, "endOffset": 198}, {"referenceID": 18, "context": "These multimodal models have been used for medical purposes, such as detection of suicidal risk, PTSD and depression (Scherer et al., 2016; Venek et al., 2016; Yu et al., 2013; Valstar et al., 2016); sentiment analysis (Zadeh et al.", "startOffset": 117, "endOffset": 198}, {"referenceID": 20, "context": "These multimodal models have been used for medical purposes, such as detection of suicidal risk, PTSD and depression (Scherer et al., 2016; Venek et al., 2016; Yu et al., 2013; Valstar et al., 2016); sentiment analysis (Zadeh et al.", "startOffset": 117, "endOffset": 198}, {"referenceID": 17, "context": "These multimodal models have been used for medical purposes, such as detection of suicidal risk, PTSD and depression (Scherer et al., 2016; Venek et al., 2016; Yu et al., 2013; Valstar et al., 2016); sentiment analysis (Zadeh et al.", "startOffset": 117, "endOffset": 198}, {"referenceID": 22, "context": ", 2016); sentiment analysis (Zadeh et al., 2016b; Poria et al., 2016; Zadeh et al., 2016a); emotion recognition (Poria et al.", "startOffset": 28, "endOffset": 90}, {"referenceID": 13, "context": ", 2016); sentiment analysis (Zadeh et al., 2016b; Poria et al., 2016; Zadeh et al., 2016a); emotion recognition (Poria et al.", "startOffset": 28, "endOffset": 90}, {"referenceID": 21, "context": ", 2016); sentiment analysis (Zadeh et al., 2016b; Poria et al., 2016; Zadeh et al., 2016a); emotion recognition (Poria et al.", "startOffset": 28, "endOffset": 90}, {"referenceID": 12, "context": ", 2016a); emotion recognition (Poria et al., 2017); image captioning and media description (You et al.", "startOffset": 30, "endOffset": 50}, {"referenceID": 19, "context": ", 2017); image captioning and media description (You et al., 2016; Donahue et al., 2015); question answering (Antol et al.", "startOffset": 48, "endOffset": 88}, {"referenceID": 1, "context": ", 2017); image captioning and media description (You et al., 2016; Donahue et al., 2015); question answering (Antol et al.", "startOffset": 48, "endOffset": 88}, {"referenceID": 0, "context": ", 2015); question answering (Antol et al., 2015); and multimodal translation (Specia et al.", "startOffset": 28, "endOffset": 48}, {"referenceID": 16, "context": ", 2015); and multimodal translation (Specia et al., 2016).", "startOffset": 36, "endOffset": 57}, {"referenceID": 11, "context": "For instance, the GloVe embedding (Pennington et al., 2014) trained on Wikipedia covers only 49.", "startOffset": 34, "endOffset": 59}, {"referenceID": 9, "context": "The first step of the HTDN pipeline is to train word vectors (Mikolov et al., 2013) based on the skip-gram model.", "startOffset": 61, "endOffset": 83}, {"referenceID": 15, "context": "To learn contextual and abstract information from images, we use a deep convolutional neural network called Trafficking-VGG (T-VGG), a finetuned instance of the well-known VGG network (Simonyan and Zisserman, 2014).", "startOffset": 184, "endOffset": 214}, {"referenceID": 7, "context": "Figure 4 shows the 2D t-SNE (Maaten and Hinton, 2008) representation of the training data in our dataset according to the Bag-of-Words (top right) models, expert keywords (top left), average word vectors (bottom right), and the visual representation hv bottom left.", "startOffset": 28, "endOffset": 53}, {"referenceID": 6, "context": "The HTDN model is trained using the Adam optimizer (Kingma and Ba, 2014).", "startOffset": 51, "endOffset": 72}, {"referenceID": 3, "context": "The neural weights were initialized randomly using Xavier initialization technique (Glorot and Bengio, 2010).", "startOffset": 83, "endOffset": 108}], "year": 2017, "abstractText": "Human trafficking is a global epidemic affecting millions of people across the planet. Sex trafficking, the dominant form of human trafficking, has seen a significant rise mostly due to the abundance of escort websites, where human traffickers can openly advertise among at-will escort advertisements. In this paper, we take a major step in the automatic detection of advertisements suspected to pertain to human trafficking. We present a novel dataset called Trafficking-10k, with more than 10,000 advertisements annotated for this task. The dataset contains two sources of information per advertisement: text and images. For the accurate detection of trafficking advertisements, we designed and trained a deep multimodal model called the Human Trafficking Deep Network (HTDN).", "creator": "LaTeX with hyperref package"}}}