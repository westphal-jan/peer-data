{"id": "1705.02955", "review": {"conference": "nips", "VERSION": "v1", "DATE_OF_SUBMISSION": "8-May-2017", "title": "Safe and Nested Subgame Solving for Imperfect-Information Games", "abstract": "Unlike perfect-information games, imperfect-information games cannot be solved by decomposing the game into subgames that are solved independently. Instead, all decisions must consider the strategy of the game as a whole, and more computationally intensive algorithms are used. While it is not possible to solve an imperfect-information game exactly through decomposition, it is possible to approximate solutions, or improve existing strategies, by solving disjoint subgames. This process is referred to as subgame solving. We introduce subgame solving techniques that outperform prior methods both in theory and practice. We also show how to adapt them, and past subgame solving techniques, to respond to opponent actions that are outside the original action abstraction; this significantly outperforms the prior state-of-the-art approach, action translation. Finally, we show that subgame solving can be repeated as the game progresses down the tree, leading to lower exploitability. Subgame solving is a key component of Libratus, the first AI to defeat top humans in heads-up no-limit Texas hold'em poker.", "histories": [["v1", "Mon, 8 May 2017 16:27:48 GMT  (809kb,D)", "http://arxiv.org/abs/1705.02955v1", null], ["v2", "Fri, 26 May 2017 21:44:39 GMT  (804kb,D)", "http://arxiv.org/abs/1705.02955v2", null]], "reviews": [], "SUBJECTS": "cs.AI cs.GT", "authors": ["noam brown", "tuomas sandholm"], "accepted": true, "id": "1705.02955"}, "pdf": {"name": "1705.02955.pdf", "metadata": {"source": "CRF", "title": "Safe and Nested Subgame Solving for Imperfect-Information Games\u2217", "authors": ["Noam Brown"], "emails": ["noamb@cs.cmu.edu", "sandholm@cs.cmu.edu"], "sections": [{"heading": "1 Introduction", "text": "This year, it will be able to put itself at the top of the group."}, {"heading": "2 Coin Toss", "text": "In this case, it is as if it were a reactionary party that is able to choose a party that is able to choose a party."}, {"heading": "3 Notation and Background", "text": "In a game with imperfect information, there is a finite set of players, P = 1 and 2 = i = 2. In a game with imperfect information, there is a finite set of players, P = 1. H is the set of all possible stories (nodes) in the game tree, represented as a sequence of actions and containing the empty story. A (h) is the plot available in a story, and P (h) P is the player acting in that story, while c is the parent of h. If there is a sequence of actions from h to h, then h is a fixed probability known to all players. (and h \"is an action taken in h is a child of h, represented by h.\" H \"is the player, while h\" is the parent of h. \"If there is a sequence of actions from h, then h\" is an ancestor of h \"is a descendant of h.\""}, {"heading": "4 Prior Approaches to Subgame Solving in Imperfect-Information Games", "text": "Our new algorithm then builds on some of the ideas and notes. In this section, we refer to the coin-toss game shown in Figure 1a. We focus on the play undergame. If P1 chooses to sell, the game moves on to a separate undergame (which is usually quite far from a Nash balance, although it is a Nash balance in the abstract game). We refer to this strategy profile throughout the game as a body. The goal of subgame solving is to improve the hull by changing the strategy in only one subgame (which is typically quite far from a Nash balance, although it is a Nash balance in the abstract game)."}, {"heading": "4.1 Unsafe Subgame Solving", "text": "We first review the most intuitive form of the subgame solution, which we call insecure subgame-solving. (2, 10, 11, 8) This form of subgame solution assumes that both players play according to their master strategies outside the subgame. In other words, all nodes outside the subgame are fixed and can be treated as random nodes with probabilities determined by the master strategy. (4) In many large games, the master strategy is far from optimal, either because the equilibrium-finding algorithm was not sufficiently converged or because the game was too large and needed to be abstracted. (5) The example drink strategy shown here could be trivially improved; we use it for the simplicity of exposure. (5) In all subgame-solving algorithms, an extended subgame that contains S but is much smaller than the strategy, the game is to define the subgame solution based on the fact that both player's subgame strategies are based on their subgame-solving strategies (these subgame-6)."}, {"heading": "4.2 Subgame Re-Solving", "text": "In the subgame Re-Solving [4] a safe strategy for P2 in the subgame is calculated (re-relation) by building the extended subgame shown in Figure 4 and calculating a balance strategy for it. Clearly, the extended subgame differs from the Unsafe subgame solution in that it gives P1 the option to opt-out from participating in the subgame and instead receive the value it could receive for entering the subgame if P2 is played according to the master strategy. Specifically, for each earliest achievable game, one can select a strategy h in the subgame (that is, any h-R), let hr be his parents and aS be the action that leads to such that hr \u00b7 aS = h. We require to be a P1 story; if it is not, then we can simply insert a P1 story with just a single action between hr and h."}, {"heading": "4.3 Maxmargin Solving", "text": "Maxmargin solving [19] is similar to Re-solving, except that it wants to improve P2 Re's strategy in the subgame strategy as much as possible. While Re-solving seeks a strategy for P2 in S that would simply prevent P1 from entering S, Maxmargin solving additionally tries to punish P1 as much as possible if P1 nonetheless decides to enter S. A subgame margin is defined for each infoset in Sr that represents the difference in value between entering the subgame versus choosing alternative playing techniques. Specifically, for each infoset I-Sr and action aS that leads to S, the subgame margin is M\u03c3 S (I, aS) = v-S (I, a-T) \u2212 vurch-S (I, a-S) \u2212 vill-S (I, a-S)."}, {"heading": "5 Reach Subgame Solving", "text": "In this section, we present Reach Subgame Solving, an improvement of both re-solving and Maxmargin subgame solving, which takes into account the gains that can be made from other ways in the game. First, we consider the case of solving a single sub-game, and then we deal independently with solving several sub-games."}, {"heading": "5.1 Solving a Single Subgame", "text": "This can be improved by including information about what payouts players might receive by not reaching the undergame. The solution that solves the undergame would result in P1 getting an EV of \u2212 14 by opting for the margin of \u2212 14, and 14 in the margins (EV) of 0.5 by selecting Sell in the stages of heads, and \u2212 0.5 in the tails states. The solution that solves the underplay would result in P1 simply always selecting Sell in the stages of heads and Play in the tails states against the strategy of P2 and receiving an EV of 38. Subplay strategy improves with Re-solve and Maxmargin underplay solutions by taking into account all actions P1 that could take the way to the undergame. If there is an action that leads away from the undergame that leads to a higher expected value than the action that leads to the game, then P1 would make a mistake by making the difference to the selection of that game."}, {"heading": "5.2 Solving Multiple Subgames Independently", "text": "Other partial game methods have also taken into account the cost of achieving a partial game [31, 13]. However, these approaches (and the version of Reach Subgame Solving described above) are only theoretically correct when applied to a single partial game. Typically, we want to solve several partial game techniques independently - or, equivalent, each partial game that is achieved at runtime. This is a problem because the structure of the extended partial game assumes that all P2 nodes outside the partial game have strategies that are fixed according to the suitcase strategy. If this assumption is violated by changing the strategy in multiple partial games, then the security of the partial game solution becomes apparent (that is, the guarantee that exploitation will not be inferior to the boot). To address this problem, we need to make two changes, we need to make sure that we do not double count \"gifts\" given to P1 by using an entire talent in multiple partial games."}, {"heading": "6 Modeling Error in a Subgame", "text": "In this section, we will consider the case where we have a good estimate of what the counterfactual values of subgames would mean for each game. (In practice, however, this approach leads to significantly lower exploitability, since solving multiple P2 subgames requires a minimal exploitation strategy, which could only be calculated by changing the strategies in the subgames. (In practice, this approach can lead to significantly lower exploitability, since the strategy of P2 is fixed outside the subgames, but it is the next one that can be achieved by changing the strategy in the subgames.) However, the strategy of blindness can only be guaranteed by solving all subgames together, since the optimal strategy in one subgame depends on the optimal strategy in other subgames. Nevertheless, we assume that we know CBV."}, {"heading": "6.1 Distributional Alternative Payoffs", "text": "One problem with existing secure subgame solution techniques is that they \"miss\" the alternative problem, even if we use estimates. Consider, for example, a subgame that could enter P1 from two different sets of information I1 and I2. Suppose the counterfactual value of P1 is estimated at 1, and for I2 is 10. Suppose that P2 has a choice between two different strategies; the first strategy would yield the value for entering the subgame from I1 to 0.99 and from I2 to 9.99; the second reduces the value of P1 for entering the subgame from I1 to 1.01 and from I2 to 0. The safe subgame solution method so far would choose the first strategy because the second strategy leaves one of the margins negative. However, the second strategy is probably the better option because it is more resilient to errors in the model."}, {"heading": "7 Nested Subgame Solving", "text": "As we have discussed, large games need to be abstracted in order to reduce the game to a tractable size. This is particularly common in games with large or continuous action spaces, such as an auction where a bidder can select any price in any area. In this case, the action space can be discredited by action space, so that only a few actions are included in the abstraction. While we can limit ourselves to the actions we are included in the abstraction, an opponent could select actions that are not in the abstraction. In this case, the action space can be allocated to an action that is included in the abstraction, and the strategy from the abstraction can be applied. In an auction game, for example, we could include a bid of $100 in our abstraction, if a player simply treats this as a bid of $100. This is referred to as action translation [12, 28, 6]."}, {"heading": "8 Experiments", "text": "In fact, it is the case that you are able to hide without being able to play by the rules."}, {"heading": "8.1 Evaluation Against Top Humans", "text": "The techniques in this essay are a key component of the AI Libratus, which in January 2017 defeated four top human specialists in heads-up No-Limit Texas Hold'em in the Brains vs. AI competition. Headsup No-Limit Texas Hold'em was the primary benchmark challenge for AI in imperfect information games. The competition was played over a 20-day period and included 120,000 hands of poker. A prize pool of $200,000 was divided among the four human professionals based on their performance against the AI to create incentives for strong play. AI clearly defeated the team of human players by a lead of 147 mbb / hand, with a p value of 0.0002 and a statistical significance of 99.98% (see Figure 7). This was the first time an AI defeated top humans in heads-up No-Limit Texas Hold'em poker."}, {"heading": "9 Conclusion", "text": "We introduced a subgame solution technology for imperfect information games that offers stronger theoretical guarantees and better practical performance than previous subgame solution methods. We presented results on the usability of both secure and insecure subgame solution techniques. We also introduced a method for nested subgame solutions in response to the actions of the opponent and demonstrated that this leads to dramatically better performance than the usual approach of action translation. To our knowledge, this is the first time that the usability of subgame solution techniques has been measured in big games. Finally, we demonstrated the effectiveness of these techniques in practice against top human professionals in heads-up no-limit Texas Hold'em poker, the main benchmark challenge for AI in imperfect information games. In the Brains vs. AI 2017 competition, our AI library became the first AI to reach the milestone of defeating top people in heads-up no-Limit Texas Hold'em."}, {"heading": "Appendix: Supplementary Material", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "A Description of Gadget Game", "text": "Solving the extended sub-game described in Maxmargin Solving and Reach-Maxmargin Solving does not necessarily result in maximizing the minimum margin. While LP Solvers can easily accomplish this goal, the process is more difficult for iterative algorithms such as Counterfactual Regret Minimization (CFR) and Excessive Gap Technique (EGT), for which iterative algorithms the extended sub-game can be modified into a gadget game that, once solved, provides a nash balance for the extended sub-game and also maximizes the minimum margin [19]. This gadget game is unnecessary if it uses distributional alternative payouts introduced in Section 6.1. The gadget game differs from the extended sub-game in two ways: first, all P1 payouts achieved from the original I-Sr information set are shifted by the alternative payout of I. Second, by starting a game with a probability that each game will commit to a particular sub-game in 1."}, {"heading": "B Hedge for Distributional Subgame Solving", "text": "In this essay, we use CFR [32] with Hedge in Sr, which allows us to use a useful property of the hedge algorithm [18] to update all information sets resulting from the results of XI at the same time.11 When using Hedge, action a \u2032 S is applied to iteration t with the probability of e\u03b7tv (I, a \u2032 S) e\u03b7tv (I, a \u2032 S) + e\u03b7tv (I, a \u2032 T).11Another option is to apply CFR-BR [15] only to the initial P1 node when deciding between a \"T\" and a \"S. Where v\" (I, a \"T) is the observed expected value of action a\" T, v \"(I, a\" S) is the observed expected value of action a \"S,\" and \"t\" is a tuning parameter where action a \"T\" (I, a \"S) is the parameter used where all the results of the game (Iteration) are identical to the Iteration (Iteration) of the Iteration (S)."}, {"heading": "C Proof of Theorem 1", "text": "Evidence. Let's assume that Mssr (I, aS) has the highest probability for any information I've entered in Sr for an underplay, and let's leave = minIMssr (I, aS). For any information I've given in QS (I), I'm the earliest information specified in QS (I). Then let's assume \u03c0 < BR (I) = 0. Then let's consider either \u03c0 < BR (I) \u00b2 2 > (I) < BR (I) + 2 > (I) = 0. Then let's assume both < BR (II), 2 > (I) < BR (I) < B2 > (I) < BR (I) < BR (II) = 0 > (I)."}, {"heading": "D Scaling of Gifts", "text": "In most of the games we have experimented with, the further the gifts have been scaled, the less recoverable they are. However, Figure 9 shows a case where we observe that recoverability increases when the gifts are scaled too far. Figure 9 shows recoverability when the gifts are scaled by several factors. At 0, the algorithm is identical to MaxMargin. at 1, the algorithm is the theoretically correct form of Reach-Maxmargin. Optimal performance in this game occurs when the gifts are scaled by a factor of about 1,000. Scaling the gifts by 100,000 results in performance that is worse than the Maxmargin solution. This shows empirically that scaling gifts can lead to better performance in some cases (since an entire gift is probably not used in every subgame that receives one)."}, {"heading": "E Proof of Theorem 2", "text": "Proof: Similar to Theorem 1, we assume that Lord (I, aS) for each set of information 0 (I, I, I, I, I) and leave = minI (Sr) Lord (I, aS). We show that for each P1 Infoset I (I, a), CBV (2, I), 2 (I, I), 2 (I, I), 2 (I, I), 2 (I, I), 2 (I, I), 2 (I), 2 (I), 2 (I), 2 (I, I), 2 (I), 2 (I), 2 (I), I (I), 2 (I), 2 (I), 2 (I), 2 (I), 2 (I), 2 (I), I (I), I (I, I, I, I (I), I (I, I, I (I), I (I, I, I (I), 2 (I), 2 (I), 2 (I), 2 (I), I (I), 2 (I), 2 (I), 2 (I (I), 2 (I), 2 (I (I), 2 (I), 2 (I (I), 2 (I), 2 (I (I), 2 (I), 2 (I (I), 2 (I), 2 (I (I), 2 (I (I), I (I), 2 (I (I), I (I, I (I), I (I (I, I, I), I (I (I, I, I, I), I (I (I, I, I, I), I (I (I), I (I (I, I (I, I, I), I (I (I, I), I (I (I, I, I (I), I (I (I, I (I, I), I (I, I (I), I (I (I, I, I), I (I (I, I, I, I), I (I (I, I), I (I (I (I, I), I (I, I"}, {"heading": "F Proof of Theorem 3", "text": "Prove that the strategy created according to the Re-solution is applied to every sub-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-S-"}, {"heading": "G Proof of Theorem 4", "text": "Proof. We inductively prove that the use of CFR in S, \"while choosing the action that leads to S,\" of any I \"S\" r with probability P (XI \"vt (I,\" a \"\u2032 S\") leads to a game that is identical to CFR in S and CFR-BR [15] in Sr, resulting in a Nash equilibrium. Finally, for each P2 set of information I \"2 in S,\" there is exactly one corresponding set of information I2 in S that is achieved through the same actions, ignoring random variables. Each P1 set of information I \"1 in S\" corresponds to a set of information sets in S that are achieved through the same actions, with the elements in the set differing only by the result of the random variables. We prove that in each iteration the instinctive regret for that corresponding set of information is identical (and thus the average strategy played in the P2 information sets is x identical)."}], "references": [{"title": "On the application of dynamic programming to the determination of optimal play in chess and checkers", "author": ["Richard Bellman"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "1", "shortCiteRegEx": "1", "year": 1965}, {"title": "Approximating game-theoretic optimal strategies for fullscale poker", "author": ["Darse Billings", "Neil Burch", "Aaron Davidson", "Robert Holte", "Jonathan Schaeffer", "Terence Schauenberg", "Duane Szafron"], "venue": "In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "2", "shortCiteRegEx": "2", "year": 2003}, {"title": "Dynamic thresholding and pruning for regret minimization", "author": ["Noam Brown", "Christian Kroer", "Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "3", "shortCiteRegEx": "3", "year": 2017}, {"title": "Solving imperfect information games using decomposition", "author": ["Neil Burch", "Michael Johanson", "Michael Bowling"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "4", "shortCiteRegEx": "4", "year": 2014}, {"title": "Action translation in extensive-form games with large action spaces: Axioms, paradoxes, and the pseudo-harmonic mapping", "author": ["Sam Ganzfried", "Tuomas Sandholm"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "6", "shortCiteRegEx": "6", "year": 2013}, {"title": "Potential-aware imperfect-recall abstraction with earth mover\u2019s distance in imperfect-information games", "author": ["Sam Ganzfried", "Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "7", "shortCiteRegEx": "7", "year": 2014}, {"title": "Endgame solving in large imperfect-information games", "author": ["Sam Ganzfried", "Tuomas Sandholm"], "venue": "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "8", "shortCiteRegEx": "8", "year": 2015}, {"title": "First-order algorithm with O(ln(1/ )) convergence for -equilibrium in two-person zero-sum games", "author": ["Andrew Gilpin", "Javier Pe\u00f1a", "Tuomas Sandholm"], "venue": "Mathematical Programming,", "citeRegEx": "9", "shortCiteRegEx": "9", "year": 2012}, {"title": "A competitive Texas Hold\u2019em poker player via automated abstraction and real-time equilibrium computation", "author": ["Andrew Gilpin", "Tuomas Sandholm"], "venue": "In Proceedings of the National Conference on Artificial Intelligence (AAAI),", "citeRegEx": "10", "shortCiteRegEx": "10", "year": 2006}, {"title": "Better automated abstraction techniques for imperfect information games, with application to Texas Hold\u2019em poker", "author": ["Andrew Gilpin", "Tuomas Sandholm"], "venue": "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "11", "shortCiteRegEx": "11", "year": 2007}, {"title": "A heads-up no-limit Texas Hold\u2019em poker player: Discretized betting models and automatically generated equilibriumfinding programs", "author": ["Andrew Gilpin", "Tuomas Sandholm", "Troels Bjerre S\u00f8rensen"], "venue": "In International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS),", "citeRegEx": "12", "shortCiteRegEx": "12", "year": 2008}, {"title": "A time and space efficient algorithm for approximately solving large imperfect information games", "author": ["Eric Jackson"], "venue": "In AAAI Workshop on Computer Poker and Imperfect Information,", "citeRegEx": "13", "shortCiteRegEx": "13", "year": 2014}, {"title": "Measuring the size of large no-limit poker games", "author": ["Michael Johanson"], "venue": "Technical report, University of Alberta,", "citeRegEx": "14", "shortCiteRegEx": "14", "year": 2013}, {"title": "Finding optimal abstract strategies in extensive-form games", "author": ["Michael Johanson", "Nolan Bard", "Neil Burch", "Michael Bowling"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "15", "shortCiteRegEx": "15", "year": 2012}, {"title": "Accelerating best response calculation in large extensive games", "author": ["Michael Johanson", "Kevin Waugh", "Michael Bowling", "Martin Zinkevich"], "venue": "In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "16", "shortCiteRegEx": "16", "year": 2011}, {"title": "Theoretical and practical advances on smoothing for extensive-form games", "author": ["Christian Kroer", "Kevin Waugh", "Fatma Kilinc-Karzan", "Tuomas Sandholm"], "venue": "arXiv preprint arXiv:1702.04849,", "citeRegEx": "17", "shortCiteRegEx": "17", "year": 2017}, {"title": "The weighted majority algorithm", "author": ["Nick Littlestone", "M.K. Warmuth"], "venue": "Information and Computation,", "citeRegEx": "18", "shortCiteRegEx": "18", "year": 1994}, {"title": "Refining subgames in large imperfect information games", "author": ["Matej Moravcik", "Martin Schmid", "Karel Ha", "Milan Hladik", "Stephen Gaukrodger"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "19", "shortCiteRegEx": "19", "year": 2016}, {"title": "Deepstack: Expert-level artificial intelligence in no-limit", "author": ["M. Morav\u010d\u00edk", "M. Schmid", "N. Burch", "V. Lis\u00fd", "D. Morrill", "N. Bard", "T. Davis", "K. Waugh", "M. Johanson", "M. Bowling"], "venue": "poker. Science,", "citeRegEx": "20", "shortCiteRegEx": "20", "year": 2017}, {"title": "Equilibrium points in n-person games", "author": ["John Nash"], "venue": "Proceedings of the National Academy of Sciences,", "citeRegEx": "21", "shortCiteRegEx": "21", "year": 1950}, {"title": "Non-cooperative games", "author": ["John Nash"], "venue": "PhD thesis, Priceton University,", "citeRegEx": "22", "shortCiteRegEx": "22", "year": 1950}, {"title": "Excessive gap technique in nonsmooth convex minimization", "author": ["Yurii Nesterov"], "venue": "SIAM Journal of Optimization,", "citeRegEx": "23", "shortCiteRegEx": "23", "year": 2005}, {"title": "The state of solving large incomplete-information games, and application to poker", "author": ["Tuomas Sandholm"], "venue": "AI Magazine,", "citeRegEx": "24", "shortCiteRegEx": "24", "year": 2010}, {"title": "Abstraction for solving large incomplete-information games", "author": ["Tuomas Sandholm"], "venue": "In AAAI Conference on Artificial Intelligence (AAAI),", "citeRegEx": "25", "shortCiteRegEx": "25", "year": 2015}, {"title": "Probabilistic state translation in extensive games with large action sets", "author": ["David Schnizlein", "Michael Bowling", "Duane Szafron"], "venue": "In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "28", "shortCiteRegEx": "28", "year": 2009}, {"title": "Mastering the game of go with deep neural networks and tree", "author": ["David Silver", "Aja Huang", "Chris J Maddison", "Arthur Guez", "Laurent Sifre", "George Van Den Driessche", "Julian Schrittwieser", "Ioannis Antonoglou", "Veda Panneershelvam", "Marc Lanctot"], "venue": "search. Nature,", "citeRegEx": "29", "shortCiteRegEx": "29", "year": 2016}, {"title": "Solving heads-up limit Texas hold\u2019em", "author": ["Oskari Tammelin", "Neil Burch", "Michael Johanson", "Michael Bowling"], "venue": "In Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI),", "citeRegEx": "30", "shortCiteRegEx": "30", "year": 2015}, {"title": "Strategy grafting in extensive games", "author": ["Kevin Waugh", "Nolan Bard", "Michael Bowling"], "venue": "In Proceedings of the Annual Conference on Neural Information Processing Systems (NIPS),", "citeRegEx": "31", "shortCiteRegEx": "31", "year": 2009}], "referenceMentions": [{"referenceID": 20, "context": "In such games, the typical goal is to find a Nash equilibrium [22], which is a profile of strategies\u2014one for each player\u2014such that no player can improve by unilaterally deviating to a different strategy.", "startOffset": 62, "endOffset": 66}, {"referenceID": 0, "context": "Subgame solving is a standard technique in perfect-information games such as chess and checkers [1] in which a piece of the game is solved in isolation.", "startOffset": 96, "endOffset": 99}, {"referenceID": 25, "context": "This decomposition was key to AIs being able to defeat top humans in chess [5] and Go [29].", "startOffset": 86, "endOffset": 90}, {"referenceID": 12, "context": "benchmark problem in imperfect-information game solving\u2014which has 10 decision points, or can even be infinite in size if fractional bets are allowed [14].", "startOffset": 149, "endOffset": 153}, {"referenceID": 22, "context": "2 The standard approach to computing strategies in such large games is to first generate an abstraction of the game, which is a smaller version of the game that retains as much as possible the strategic characteristics of the original game [24, 26, 25].", "startOffset": 240, "endOffset": 252}, {"referenceID": 23, "context": "2 The standard approach to computing strategies in such large games is to first generate an abstraction of the game, which is a smaller version of the game that retains as much as possible the strategic characteristics of the original game [24, 26, 25].", "startOffset": 240, "endOffset": 252}, {"referenceID": 19, "context": "A Nash equilibrium [21] is a strategy profile \u03c3\u2217 such that \u2200i, ui(\u03c3 i , \u03c3\u2217 \u2212i) = max\u03c3\u2032 i\u2208\u03a3i ui(\u03c3 \u2032 i, \u03c3 \u2217 \u2212i).", "startOffset": 19, "endOffset": 23}, {"referenceID": 17, "context": "A counterfactual best response [19] CBRi(\u03c3\u2212i) is similar to a best response, but additionally maximizes counterfactual value at every infoset.", "startOffset": 31, "endOffset": 35}, {"referenceID": 1, "context": "We first review the most intuitive form of subgame solving, which we refer to as Unsafe subgame solving [2, 10, 11, 8].", "startOffset": 104, "endOffset": 118}, {"referenceID": 8, "context": "We first review the most intuitive form of subgame solving, which we refer to as Unsafe subgame solving [2, 10, 11, 8].", "startOffset": 104, "endOffset": 118}, {"referenceID": 9, "context": "We first review the most intuitive form of subgame solving, which we refer to as Unsafe subgame solving [2, 10, 11, 8].", "startOffset": 104, "endOffset": 118}, {"referenceID": 6, "context": "We first review the most intuitive form of subgame solving, which we refer to as Unsafe subgame solving [2, 10, 11, 8].", "startOffset": 104, "endOffset": 118}, {"referenceID": 3, "context": "In subgame re-solving [4], a safe strategy is computed for P2 in the subgame by constructing the augmented subgame shown in Figure 4, and computing an equilibrium strategy \u03c3 for it.", "startOffset": 22, "endOffset": 25}, {"referenceID": 17, "context": "Maxmargin solving [19] is similar to Re-solving, except that it seeks to improve P2\u2019s strategy in the subgame strategy as much as possible.", "startOffset": 18, "endOffset": 22}, {"referenceID": 21, "context": "In order to use iterative algorithms such as the Excessive Gap Technique [23, 9, 17] or Counterfactual Regret Minimization (CFR) [32], one can use the gadget game described by Moravcik et al.", "startOffset": 73, "endOffset": 84}, {"referenceID": 7, "context": "In order to use iterative algorithms such as the Excessive Gap Technique [23, 9, 17] or Counterfactual Regret Minimization (CFR) [32], one can use the gadget game described by Moravcik et al.", "startOffset": 73, "endOffset": 84}, {"referenceID": 15, "context": "In order to use iterative algorithms such as the Excessive Gap Technique [23, 9, 17] or Counterfactual Regret Minimization (CFR) [32], one can use the gadget game described by Moravcik et al.", "startOffset": 73, "endOffset": 84}, {"referenceID": 17, "context": "[19].", "startOffset": 0, "endOffset": 4}, {"referenceID": 17, "context": "This theorem statement is similar to that of Maxmargin [19], but the margins here are higher than (or equal to) those in Maxmargin.", "startOffset": 55, "endOffset": 59}, {"referenceID": 27, "context": "Other subgames solving methods have also considered the cost of reaching a subgame [31, 13].", "startOffset": 83, "endOffset": 91}, {"referenceID": 11, "context": "Other subgames solving methods have also considered the cost of reaching a subgame [31, 13].", "startOffset": 83, "endOffset": 91}, {"referenceID": 11, "context": "When solving only a single subgame, techniques that are similar to Reach subgame solving exist that achieve even better theoretical performance, and indeed are provably optimal [13].", "startOffset": 177, "endOffset": 181}, {"referenceID": 18, "context": "Subsequent to our study, the AI DeepStack used a technique similar to this form of subgame solving [20].", "startOffset": 99, "endOffset": 103}, {"referenceID": 13, "context": "(When solving via CFR, it is the expected value on each iteration, as described in CFR-BR [15]).", "startOffset": 90, "endOffset": 94}, {"referenceID": 16, "context": "Another option which also solves the game but has better empirical performance relies on the softmax (also known as Hedge) algorithm [18].", "startOffset": 133, "endOffset": 137}, {"referenceID": 10, "context": "This is referred to as action translation [12, 28, 6].", "startOffset": 42, "endOffset": 53}, {"referenceID": 24, "context": "This is referred to as action translation [12, 28, 6].", "startOffset": 42, "endOffset": 53}, {"referenceID": 4, "context": "This is referred to as action translation [12, 28, 6].", "startOffset": 42, "endOffset": 53}, {"referenceID": 4, "context": "The leading action translation mapping used by most of the top teams in the ACPC is the pseudoharmonic mapping [6].", "startOffset": 111, "endOffset": 114}, {"referenceID": 14, "context": "Poker was chosen because we can leverage certain domain-specific optimizations to speed up computation by multiple orders of magnitude, allowing us to solve and calculate exploitability for large-scale games [16].", "startOffset": 208, "endOffset": 212}, {"referenceID": 26, "context": "For equilibrium finding, we used a version of CFR called CFR+ [30].", "startOffset": 62, "endOffset": 66}, {"referenceID": 5, "context": "On the flop, there are 1,286,792 infosets for each betting sequence; the abstraction buckets them into 200, 2,000, or 30,000 abstract ones (using a leading information abstraction algorithm [7]).", "startOffset": 190, "endOffset": 193}], "year": 2017, "abstractText": "Unlike perfect-information games, imperfect-information games cannot be solved by decomposing the game into subgames that are solved independently. Instead, all decisions must consider the strategy of the game as a whole, and more computationally intensive algorithms are used. While it is not possible to solve an imperfect-information game exactly through decomposition, it is possible to approximate solutions, or improve existing strategies, by solving disjoint subgames. This process is referred to as subgame solving. We introduce subgame solving techniques that outperform prior methods both in theory and practice. We also show how to adapt them, and past subgame solving techniques, to respond to opponent actions that are outside the original action abstraction; this significantly outperforms the prior state-of-the-art approach, action translation. Finally, we show that subgame solving can be repeated as the game progresses down the tree, leading to lower exploitability. Subgame solving is a key component of Libratus, the first AI to defeat top humans in heads-up no-limit Texas hold\u2019em poker.", "creator": "LaTeX with hyperref package"}}}