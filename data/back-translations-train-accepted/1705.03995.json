{"id": "1705.03995", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "11-May-2017", "title": "Learning with Noise: Enhance Distantly Supervised Relation Extraction with Dynamic Transition Matrix", "abstract": "Distant supervision significantly reduces human efforts in building training data for many classification tasks. While promising, this technique often introduces noise to the generated training data, which can severely affect the model performance. In this paper, we take a deep look at the application of distant supervision in relation extraction. We show that the dynamic transition matrix can effectively characterize the noise in the training data built by distant supervision. The transition matrix can be effectively trained using a novel curriculum learning based method without any direct supervision about the noise. We thoroughly evaluate our approach under a wide range of extraction scenarios. Experimental results show that our approach consistently improves the extraction results and outperforms the state-of-the-art in various evaluation scenarios.", "histories": [["v1", "Thu, 11 May 2017 02:56:29 GMT  (6150kb,D)", "http://arxiv.org/abs/1705.03995v1", "10 pages, accepted by ACL 2017"]], "COMMENTS": "10 pages, accepted by ACL 2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["bingfeng luo", "yansong feng", "zheng wang", "zhanxing zhu", "songfang huang", "rui yan", "dongyan zhao"], "accepted": true, "id": "1705.03995"}, "pdf": {"name": "1705.03995.pdf", "metadata": {"source": "CRF", "title": "Learning with Noise: Enhance Distantly Supervised Relation Extraction with Dynamic Transition Matrix", "authors": ["Bingfeng Luo", "Yansong Feng", "Zheng Wang", "Zhanxing Zhu", "Songfang Huang", "Rui Yan", "Dongyan Zhao"], "emails": ["luo@pku.edu.cn", "fengyansong@pku.edu.cn", "zhanxing.zhu@pku.edu.cn", "ruiyan@pku.edu.cn", "zhaody@pku.edu.cn", "z.wang@lancaster.ac.uk", "huangsf@cn.ibm.com"], "sections": [{"heading": "1 Introduction", "text": "In fact, it is so that most of us are able to surpass ourselves by focusing on ourselves. (...) It is so that they are able to surpass themselves. \"(...)\" It is so, as if. \"(...)\" It is so, as if. \"(...)\" It is so, as if. \"(...)\" It is so. \"(...)\" It is so. \"(...)\" It is so. \"(...)\" (...) \"It is so.\" (...) \"(...)\" (it is so. \"(...)\" (...) \"(it is so.\" (...) \"(...)\" (It is so. \"(...)\" (...) \"(It is so.\" (...) \"(...)\" (It is so. (...) \"()\" (It is so. \"(...)\" () \"(It is so. (...)\" () \"(It is so.\" (...) \"()\" (It is so. \"(). ()\" () \"(It is so.\" (). () \"(It is so.\" (... \"().\" () \"()"}, {"heading": "2 Problem Definition", "text": "The task of remote relation extraction is to extract knowledge triples < subj, rel, obj > from the free text containing the training data constructed by arranging existing KB triples with a large corpus. Specifically, DS, with a triple in KB, can first retrieve all sentences containing both Subj and Obj of the triple, and then construct the training data by viewing these sentences as support for the existence of the triple. This task can be performed both in the sentence planes and in the cul-de-sac planes. The former takes as input a sentence s containing both Subj and Obj, and outputs the relationship expressed by the sentence between Subj and Obj. The latter setting alleviates the noisy data problem by using the at least one assumption that at least one of the retrieved sentences containing both Subj and Obj supports < subj, rel, obj > Triple."}, {"heading": "3 Our approach", "text": "To deal with the noisy training data obtained by DS, our approach follows four steps, as illustrated in Figure 1: First, each input set is fed to a record encoder to generate an embedding vector; then, our model takes the record embedding as input and generates a predicted relation distribution, p, for the input set (or input set); at the same time, our model dynamically generates a transition matrix, T, to characterize the noise pattern of the set (or set); finally, the predicted distribution is multiplied by the transition matrix to generate the observed relation distribution, o, which is used to match the noisy relation labels assigned by DS, while the predicted relation distribution p serves as the output of our model during the test. One of the most important challenges of our approach is determining the element values of the transition matrix described in Section 4."}, {"heading": "3.1 Sentence-level Modeling", "text": "Sentence Embedding and Prediction In this paper, we use a piecemeal revolutionary neural network (Zeng et al., 2015) for sentence encoding, but other sentence embedding models can also be used. We feed the sentence that is embedded in a complete connecting layer, and use Softmax to generate the predicted relation distribution, p.Noise Modeling First, each sentence that generates x, b-sentence encoders, is passed to a complete connecting layer as nonlinearity to obtain the sentence that is specifically used for noise modeling. We then use Softmax to calculate the transmission matrix T, for each sentence: Tij = exp (wTijxn + b)."}, {"heading": "3.2 Bag Level Modeling", "text": "In this paper we experiment with two methods, namely the average and attention aggregation (Lin et al., 2016), the former calculates the embedding of the bag, s, by averaging the embedding of each set and then transferring it to a Softmax classifier for classification of the relations. Attention aggregation calculates an attention value, aij, for each set i in the bag taking into account each relation j, and aggregates to the bag level as sj, according to the following equations: sj = n \u2211 i aijxi; aij = exp (xTi rj) \u0432n i \u2032 exp (x T i \u2032 rj) (3), where xi is the embedding of the set i, n the number of sentences in the bag, and rj the randomly initialized embedding for j."}, {"heading": "4 Curriculum Learning based Training", "text": "One of the most important challenges of this work is how to train and produce the transition matrix for modelling noise in the training data without direct guidance and human involvement. A simple solution is to align the observed distribution directly with the loud names by minimizing the sum of the two terms: CrossEntropy (o) + regularization. However, this does not guarantee that the predictive distribution, p, will match the true relation distribution. Therefore, we need a technique to gradually adapt our model to the loud training data, e.g. to learn something simple, and then to try to deal with the sounds. 1While (Lin et al., 2016) we use the bilinear function to calculate aij, we simply use a product that we can learn in a more direct way, as we can perform these functions in both our training data."}, {"heading": "4.1 Trace Regularization", "text": "Before going into the details of the training, we will first discuss how to characterize the sound level of the data by controlling the track of its transition matrix. Intuitively, if the noise is small, the transition matrix T will tend to become an identity matrix, i.e. in a set of commented training sets, the observed relationships and their true relationships are almost identical. Since each set of T sums to 1, the similarity between the transition matrix and the identity matrix can be represented by its track, track (T). The larger the track (T), the larger the diagonal elements are and the more similar the transition matrix T is to the identity matrix, indicating a lower level of noise. Therefore, we can characterize the noise pattern by controlling the expected value of the track (T) in the form of regulation."}, {"heading": "4.2 Training", "text": "In other words, we focus first on the loss of the predictive distribution p, and then we take sound modelling into account gradually along the training process, i.e. we gradually increase the importance of loss from the observed distribution o, while reducing the importance of learning. In this way, the predictive branch is roughly trained before the model manages noise management, thereby avoiding being pushed into a bad local optimum. Thus, we define the meaning of the following loss function: L = N = 1 \u2212 (1 \u2212) log (oiyi) log (piyi) +) \u2212 \u03b2trace (Ti), where 0 < A = 1 and \u03b2 > 0 are two weight parameters, yi is the relationship assigned by DS to the i-th instance, N is the total number of training instances, oiyi is the probability that is observed."}, {"heading": "5 Evaluation Methodology", "text": "Our experiments aim to answer two main questions: (1) Is it possible to model the noise in the training data generated by DS, even if there is no prior knowledge that could guide us? and (2) whether prior knowledge of data quality can help us better manage the noise. We apply our approach to both set level and bag level extraction models and evaluate in situations where we have no prior knowledge of data quality and where such prior knowledge is available."}, {"heading": "5.1 Datasets", "text": "We evaluate our approach on two sets of data. TIMERE We build TIMERE by using DS to align time-related Wikidata (Vrandec-ic-and-Kro-tzsch, 2014) KB triples on Wikipedia text. It contains 278,141 sentences with 12 types of relationship between an entity mention and a time expression. We choose to use time-related relationships because time expressions speak for themselves in terms of reliability. That's, given a KB-triple < e, rel, t > and its aligned sentences, the time expression appears in the sentence, the more likely is the existence of this triangle. For example, a sentence containing both Alphabet and October-2-2015 is very likely to express the beginning time of Alphabet, while a sentence containing both Alphabet and 2015 could talk about many events."}, {"heading": "5.2 Experimental Setup", "text": "Hyper-parameter We use 200 folding cores with widow size 3. During training, we use stochastic gradient parentage (SGD) with batch size 20. The learning rates for sentence level and bag level models are 0.1 and 0.01, respectively, and 0.1. Sentence level experiments are conducted on TIMERE, with 100-d word embedding being pre-trained, using GloVe (Pennington et al., 2014) on Wikipedia and Gigaword (Parker et al., 2011) and 20-d vectors for distance embedding. Each of the three subsets of TIMERE is added after the previous phase, which ran for 15 epochs. The trace regulation weights are \u03b21 = 0.01, \u03b23 = \u2212 0.1 and \u03b23 = \u2212 0.1, respectively, from the most reliable to the most unreliable, with the ratio of \u03b23 and \u03b22."}, {"heading": "6 Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "6.1 Performance on TIMERE", "text": "This year, we will be able to put ourselves at the top, \"he said in an interview with the German Press Agency.\" We have to put ourselves at the top, \"he said.\" We have to put ourselves at the top, \"he said."}, {"heading": "6.2 Performance on ENTITYRE", "text": "As shown in Figure 5, it is not surprising that the base model with attention aggregation (att) significantly exceeds the average performance (avg), with att being injected into our bag embedding in the spirit similar to (Lin et al., 2016), which has reported current performance on ENTITYRE. When injected with our transition matrix approach, both att TM and avg TM significantly exceed their basic versions. Similar to the situations in TIMERE, since att has taken into account at least one assumption through its attention-based bag embedding mechanism, the improvement through att TM is not as great as through avg TM. We also include a comparison with three function-based methods: Mintz (Mintz et al., 2009) is a multiclass logistic regression model; MultiR (Hoffmann et al., 2011) is a paradigmatic model that can handle an overlap of the IMM-ML in the general relationship; this model does not work effectively."}, {"heading": "7 Related Work", "text": "In fact, it is the case that most of them are able to play by the rules that they have shown in recent years. (...) In fact, it is the case that they are able to play by the rules. (...) In fact, it is the case that they are able to play by the rules. (...) In fact, it is the case that they are able to play by the rules. (...) In fact, it is the case that they are able to play by the rules. (...) In fact, it is the case that they are able to play by the rules. (...) In fact, it is the case that they are able to play by the rules. (...)"}, {"heading": "8 Conclusions", "text": "In this paper, we examine the noise problem inherent in DS-style training data. We argue that the data speaks for itself by providing useful clues to show their noise patterns. We therefore propose a novel transition matrix-based method for dynamically characterizing the noise underlying such training data in a consistent framework along the original predictive target. One of our key innovations is to use a curriculum-based training method to gradually learn to model the underlying noise pattern without direct guidance, and to provide the flexibility to leverage any prior knowledge of data quality to further improve the effectiveness of the transition matrix."}, {"heading": "Acknowledgement", "text": "This work is supported by the National High Technology R & D Program of China (2015AA015403); the National Natural Science Foundation of China (61672057, 61672058); KLSTSPI Key Lab. of Intelligent Press Media Technology; the UK Engineering and Physical Sciences Research Council under the auspices of EP / M01567X / 1 (SANDeRs) and EP / M015793 / 1 (DIVIDEND); and the Royal Society International Collaboration Grant (IE161012)."}], "references": [{"title": "Curriculum learning", "author": ["Yoshua Bengio", "J\u00e9r\u00f4me Louradour", "Ronan Collobert", "Jason Weston."], "venue": "ICML. ACM, pages 41\u201348.", "citeRegEx": "Bengio et al\\.,? 2009", "shortCiteRegEx": "Bengio et al\\.", "year": 2009}, {"title": "Webly supervised learning of convolutional networks", "author": ["Xinlei Chen", "Abhinav Gupta."], "venue": "ICCV . pages 1431\u20131439.", "citeRegEx": "Chen and Gupta.,? 2015", "shortCiteRegEx": "Chen and Gupta.", "year": 2015}, {"title": "Learning when to trust distant supervision: An application to lowresource pos tagging using cross-lingual projection", "author": ["Meng Fang", "Trevor Cohn."], "venue": "CONLL. pages 178\u2013186.", "citeRegEx": "Fang and Cohn.,? 2016", "shortCiteRegEx": "Fang and Cohn.", "year": 2016}, {"title": "Twitter sentiment classification using distant supervision", "author": ["Alec Go", "Richa Bhayani", "Lei Huang."], "venue": "CS224N Project Report, Stanford 1(12).", "citeRegEx": "Go et al\\.,? 2009", "shortCiteRegEx": "Go et al\\.", "year": 2009}, {"title": "Knowledgebased weak supervision for information extraction of overlapping relations", "author": ["Raphael Hoffmann", "Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S Weld."], "venue": "Proceedings of ACL. pages 541\u2013550.", "citeRegEx": "Hoffmann et al\\.,? 2011", "shortCiteRegEx": "Hoffmann et al\\.", "year": 2011}, {"title": "Neural relation extraction with selective attention over instances", "author": ["Yankai Lin", "Shiqi Shen", "Zhiyuan Liu", "Huanbo Luan", "Maosong Sun."], "venue": "ACL. volume 1, pages 2124\u20132133.", "citeRegEx": "Lin et al\\.,? 2016", "shortCiteRegEx": "Lin et al\\.", "year": 2016}, {"title": "Distributed representations of words and phrases and their compositionality", "author": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."], "venue": "NIPS. pages 3111\u20133119.", "citeRegEx": "Mikolov et al\\.,? 2013", "shortCiteRegEx": "Mikolov et al\\.", "year": 2013}, {"title": "Distant supervision for relation extraction with an incomplete knowledge base", "author": ["Bonan Min", "Ralph Grishman", "Li Wan", "Chang Wang", "David Gondek."], "venue": "HLT-NAACL. pages 777\u2013782.", "citeRegEx": "Min et al\\.,? 2013", "shortCiteRegEx": "Min et al\\.", "year": 2013}, {"title": "Distant supervision for relation extraction without labeled data", "author": ["Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky."], "venue": "ACL. pages 1003\u2013 1011.", "citeRegEx": "Mintz et al\\.,? 2009", "shortCiteRegEx": "Mintz et al\\.", "year": 2009}, {"title": "Seeing through the human reporting bias: Visual classifiers from noisy humancentric labels", "author": ["Ishan Misra", "C Lawrence Zitnick", "Margaret Mitchell", "Ross Girshick."], "venue": "CVPR. pages 2930\u20132939.", "citeRegEx": "Misra et al\\.,? 2016", "shortCiteRegEx": "Misra et al\\.", "year": 2016}, {"title": "English gigaword fifth edition, linguistic data consortium", "author": ["Robert Parker", "David Graff", "Junbo Kong", "Ke Chen", "Kazuaki Maeda."], "venue": "Technical report, Linguistic Data Consortium, Philadelphia.", "citeRegEx": "Parker et al\\.,? 2011", "shortCiteRegEx": "Parker et al\\.", "year": 2011}, {"title": "Glove: Global vectors for word representation", "author": ["Jeffrey Pennington", "Richard Socher", "Christopher D Manning."], "venue": "EMNLP. volume 14, pages 1532\u2013 1543.", "citeRegEx": "Pennington et al\\.,? 2014", "shortCiteRegEx": "Pennington et al\\.", "year": 2014}, {"title": "Training deep neural networks on noisy labels with bootstrapping", "author": ["Scott Reed", "Honglak Lee", "Dragomir Anguelov", "Christian Szegedy", "Dumitru Erhan", "Andrew Rabinovich."], "venue": "arXiv preprint arXiv:1412.6596 .", "citeRegEx": "Reed et al\\.,? 2014", "shortCiteRegEx": "Reed et al\\.", "year": 2014}, {"title": "Modeling relations and their mentions without labeled text", "author": ["Sebastian Riedel", "Limin Yao", "Andrew McCallum."], "venue": "Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, pages 148\u2013163.", "citeRegEx": "Riedel et al\\.,? 2010", "shortCiteRegEx": "Riedel et al\\.", "year": 2010}, {"title": "Named entity recognition in tweets: an experimental study", "author": ["Alan Ritter", "Sam Clark", "Oren Etzioni"], "venue": "In EMNLP. Association for Computational Linguistics,", "citeRegEx": "Ritter et al\\.,? \\Q2011\\E", "shortCiteRegEx": "Ritter et al\\.", "year": 2011}, {"title": "Modeling missing data in distant supervision for information extraction", "author": ["Alan Ritter", "Luke Zettlemoyer", "Mausam", "Oren Etzioni."], "venue": "TACL 1:367\u2013378.", "citeRegEx": "Ritter et al\\.,? 2013", "shortCiteRegEx": "Ritter et al\\.", "year": 2013}, {"title": "Training convolutional networks with noisy labels", "author": ["Sainbayar Sukhbaatar", "Joan Bruna", "Manohar Paluri", "Lubomir Bourdev", "Rob Fergus."], "venue": "ICLR.", "citeRegEx": "Sukhbaatar et al\\.,? 2015", "shortCiteRegEx": "Sukhbaatar et al\\.", "year": 2015}, {"title": "Multi-instance multi-label learning for relation extraction", "author": ["Mihai Surdeanu", "Julie Tibshirani", "Ramesh Nallapati", "Christopher D Manning."], "venue": "EMNLP-CoNLL. pages 455\u2013465.", "citeRegEx": "Surdeanu et al\\.,? 2012", "shortCiteRegEx": "Surdeanu et al\\.", "year": 2012}, {"title": "Reducing wrong labels in distant supervision for relation extraction", "author": ["Shingo Takamatsu", "Issei Sato", "Hiroshi Nakagawa."], "venue": "ACL. pages 721\u2013729.", "citeRegEx": "Takamatsu et al\\.,? 2012", "shortCiteRegEx": "Takamatsu et al\\.", "year": 2012}, {"title": "Wikidata: a free collaborative knowledgebase", "author": ["Denny Vrande\u010di\u0107", "Markus Kr\u00f6tzsch."], "venue": "Communications of the ACM 57(10):78\u201385.", "citeRegEx": "Vrande\u010di\u0107 and Kr\u00f6tzsch.,? 2014", "shortCiteRegEx": "Vrande\u010di\u0107 and Kr\u00f6tzsch.", "year": 2014}, {"title": "Learning from massive noisy labeled data for image classification", "author": ["Tong Xiao", "Tian Xia", "Yi Yang", "Chang Huang", "Xiaogang Wang."], "venue": "CVPR. pages 2691\u20132699.", "citeRegEx": "Xiao et al\\.,? 2015", "shortCiteRegEx": "Xiao et al\\.", "year": 2015}, {"title": "Filling knowledge base gaps for distant supervision of relation extraction", "author": ["Wei Xu", "Raphael Hoffmann", "Le Zhao", "Ralph Grishman."], "venue": "ACL. pages 665\u2013670.", "citeRegEx": "Xu et al\\.,? 2013", "shortCiteRegEx": "Xu et al\\.", "year": 2013}, {"title": "Distant supervision for relation extraction via piecewise convolutional neural networks", "author": ["Daojian Zeng", "Kang Liu", "Yubo Chen", "Jun Zhao."], "venue": "EMNLP. pages 1753\u20131762.", "citeRegEx": "Zeng et al\\.,? 2015", "shortCiteRegEx": "Zeng et al\\.", "year": 2015}], "referenceMentions": [{"referenceID": 8, "context": "Distant supervision (DS) is rapidly emerging as a viable means for supporting various classification tasks \u2013 from relation extraction (Mintz et al., 2009) and sentiment classification (Go et al.", "startOffset": 134, "endOffset": 154}, {"referenceID": 3, "context": ", 2009) and sentiment classification (Go et al., 2009) to cross-lingual semantic analysis (Fang and Cohn, 2016).", "startOffset": 37, "endOffset": 54}, {"referenceID": 2, "context": ", 2009) to cross-lingual semantic analysis (Fang and Cohn, 2016).", "startOffset": 43, "endOffset": 64}, {"referenceID": 18, "context": "Prior works (Takamatsu et al., 2012; Ritter et al., 2013) show that DS often mistakenly labels real posi-", "startOffset": 12, "endOffset": 57}, {"referenceID": 15, "context": "Prior works (Takamatsu et al., 2012; Ritter et al., 2013) show that DS often mistakenly labels real posi-", "startOffset": 12, "endOffset": 57}, {"referenceID": 18, "context": "Previous works have tried to remove sentences containing unreliable syntactic patterns (Takamatsu et al., 2012), design", "startOffset": 87, "endOffset": 111}, {"referenceID": 13, "context": "new models to capture certain types of noise or aggregate multiple predictions under the at-leastone assumption that at least one of the aligned sentences supports the triple in KB (Riedel et al., 2010; Surdeanu et al., 2012; Ritter et al., 2013; Min et al., 2013).", "startOffset": 181, "endOffset": 264}, {"referenceID": 17, "context": "new models to capture certain types of noise or aggregate multiple predictions under the at-leastone assumption that at least one of the aligned sentences supports the triple in KB (Riedel et al., 2010; Surdeanu et al., 2012; Ritter et al., 2013; Min et al., 2013).", "startOffset": 181, "endOffset": 264}, {"referenceID": 15, "context": "new models to capture certain types of noise or aggregate multiple predictions under the at-leastone assumption that at least one of the aligned sentences supports the triple in KB (Riedel et al., 2010; Surdeanu et al., 2012; Ritter et al., 2013; Min et al., 2013).", "startOffset": 181, "endOffset": 264}, {"referenceID": 7, "context": "new models to capture certain types of noise or aggregate multiple predictions under the at-leastone assumption that at least one of the aligned sentences supports the triple in KB (Riedel et al., 2010; Surdeanu et al., 2012; Ritter et al., 2013; Min et al., 2013).", "startOffset": 181, "endOffset": 264}, {"referenceID": 5, "context": "Recent breakthrough in neural networks provides a new way to reduce the influence of incorrectly labeled data by aggregating multiple training instances attentively for relation classification, without explicitly characterizing the inherent noise (Lin et al., 2016; Zeng et al., 2015).", "startOffset": 247, "endOffset": 284}, {"referenceID": 22, "context": "Recent breakthrough in neural networks provides a new way to reduce the influence of incorrectly labeled data by aggregating multiple training instances attentively for relation classification, without explicitly characterizing the inherent noise (Lin et al., 2016; Zeng et al., 2015).", "startOffset": 247, "endOffset": 284}, {"referenceID": 22, "context": "Sentence Embedding and Prediction In this work, we use a piecewise convolutional neural network (Zeng et al., 2015) for sentence encoding, but other sentence embedding models can also be used.", "startOffset": 96, "endOffset": 115}, {"referenceID": 22, "context": "Rather than using the predicted distribution p to directly match the relation labeled by DS (Zeng et al., 2015; Lin et al., 2016), here we utilize o to match the noisy labels during training and still use p as output during testing, which actually captures the procedure of how the noisy label is produced and thus protects p from the noise.", "startOffset": 92, "endOffset": 129}, {"referenceID": 5, "context": "Rather than using the predicted distribution p to directly match the relation labeled by DS (Zeng et al., 2015; Lin et al., 2016), here we utilize o to match the noisy labels during training and still use p as output during testing, which actually captures the procedure of how the noisy label is produced and thus protects p from the noise.", "startOffset": 92, "endOffset": 129}, {"referenceID": 5, "context": "In this work, we experiment two methods, namely average and attention aggregation (Lin et al., 2016).", "startOffset": 82, "endOffset": 100}, {"referenceID": 5, "context": "In similar spirit to (Lin et al., 2016), the resulting bag embedding sj is fed to a softmax classifier to predict the probability of relation j for the given bag.", "startOffset": 21, "endOffset": 39}, {"referenceID": 5, "context": "While (Lin et al., 2016) use bilinear function to calculate aij , we simply use dot product since we find these two functions perform similarly in our experiments.", "startOffset": 6, "endOffset": 24}, {"referenceID": 0, "context": "The idea of curriculum learning (Bengio et al., 2009) is simple: starting with the easiest aspect of a task, and leveling up the difficulty gradually, which fits well to our problem.", "startOffset": 32, "endOffset": 53}, {"referenceID": 13, "context": "base to the New York Times (NYT) corpus (Riedel et al., 2010).", "startOffset": 40, "endOffset": 61}, {"referenceID": 17, "context": "Since the sentence level annotations in ENTITYRE are too noisy to serve as gold standard, we only evaluate bag-level models on ENTITYRE, a standard practice in previous works (Surdeanu et al., 2012; Zeng et al., 2015; Lin et al., 2016).", "startOffset": 175, "endOffset": 235}, {"referenceID": 22, "context": "Since the sentence level annotations in ENTITYRE are too noisy to serve as gold standard, we only evaluate bag-level models on ENTITYRE, a standard practice in previous works (Surdeanu et al., 2012; Zeng et al., 2015; Lin et al., 2016).", "startOffset": 175, "endOffset": 235}, {"referenceID": 5, "context": "Since the sentence level annotations in ENTITYRE are too noisy to serve as gold standard, we only evaluate bag-level models on ENTITYRE, a standard practice in previous works (Surdeanu et al., 2012; Zeng et al., 2015; Lin et al., 2016).", "startOffset": 175, "endOffset": 235}, {"referenceID": 11, "context": "Sentence level experiments are performed on TIMERE, using 100-d word embeddings pretrained using GloVe (Pennington et al., 2014) on Wikipedia and Gigaword (Parker et al.", "startOffset": 103, "endOffset": 128}, {"referenceID": 10, "context": ", 2014) on Wikipedia and Gigaword (Parker et al., 2011), and 20-d vectors for distance embeddings.", "startOffset": 34, "endOffset": 55}, {"referenceID": 5, "context": "As shown in Figure 5, it is not surprising that the basic model with attention aggregation (att) significantly outperforms the average one (avg), where att in our bag embedding is similar in spirit to (Lin et al., 2016), which has reported the-state-of-the-art performance on ENTITYRE.", "startOffset": 201, "endOffset": 219}, {"referenceID": 8, "context": "We also include the comparison with three feature-based methods: Mintz (Mintz et al., 2009) is a multiclass logistic regression model; MultiR (Hoffmann et al.", "startOffset": 71, "endOffset": 91}, {"referenceID": 4, "context": ", 2009) is a multiclass logistic regression model; MultiR (Hoffmann et al., 2011) is a probabilistic graphical model that can handle overlapping relations; MIML (Surdeanu et al.", "startOffset": 58, "endOffset": 81}, {"referenceID": 17, "context": ", 2011) is a probabilistic graphical model that can handle overlapping relations; MIML (Surdeanu et al., 2012) is also a probabilistic graphical model but operates in the multiinstance multi-label paradigm.", "startOffset": 87, "endOffset": 110}, {"referenceID": 3, "context": ", tweet sentiment classification (Go et al., 2009), tweet named entity classifying (Ritter et al.", "startOffset": 33, "endOffset": 50}, {"referenceID": 14, "context": ", 2009), tweet named entity classifying (Ritter et al., 2011), etc.", "startOffset": 40, "endOffset": 61}, {"referenceID": 18, "context": "The work presented by (Takamatsu et al., 2012) removes potential noisy sentences by identifying bad syntactic patterns at the preprocessing stage.", "startOffset": 22, "endOffset": 46}, {"referenceID": 21, "context": "(Xu et al., 2013) use pseudorelevance feedback to find possible false nega-", "startOffset": 0, "endOffset": 17}, {"referenceID": 13, "context": "(Riedel et al., 2010) make the at-leastone assumption and propose to alleviate the noise problem by considering RE as a multi-instance classification problem.", "startOffset": 0, "endOffset": 21}, {"referenceID": 4, "context": "ing probabilistic graphic models (Hoffmann et al., 2011; Surdeanu et al., 2012), and neural network methods (Zeng et al.", "startOffset": 33, "endOffset": 79}, {"referenceID": 17, "context": "ing probabilistic graphic models (Hoffmann et al., 2011; Surdeanu et al., 2012), and neural network methods (Zeng et al.", "startOffset": 33, "endOffset": 79}, {"referenceID": 22, "context": ", 2012), and neural network methods (Zeng et al., 2015).", "startOffset": 36, "endOffset": 55}, {"referenceID": 5, "context": "Recently, (Lin et al., 2016) propose to use attention mechanism to reduce the noise within a sentence bag.", "startOffset": 10, "endOffset": 28}, {"referenceID": 15, "context": "(Ritter et al., 2013) and (Min et al.", "startOffset": 0, "endOffset": 21}, {"referenceID": 7, "context": ", 2013) and (Min et al., 2013) try to employ a set of latent variables to represent the true relation.", "startOffset": 12, "endOffset": 30}, {"referenceID": 16, "context": "(Sukhbaatar et al., 2015) utilize a global transition matrix with weight decay to transform the true label distribution to the observed.", "startOffset": 0, "endOffset": 25}, {"referenceID": 12, "context": "(Reed et al., 2014) use a hidden layer to represent the true label distribution but try to force it to predict both the noisy label and the input.", "startOffset": 0, "endOffset": 19}, {"referenceID": 1, "context": "(Chen and Gupta, 2015; Xiao et al., 2015) first estimate the transition matrix on a clean dataset and apply to the noisy data.", "startOffset": 0, "endOffset": 41}, {"referenceID": 20, "context": "(Chen and Gupta, 2015; Xiao et al., 2015) first estimate the transition matrix on a clean dataset and apply to the noisy data.", "startOffset": 0, "endOffset": 41}, {"referenceID": 9, "context": "Our model shares similar spirit with (Misra et al., 2016) in that we", "startOffset": 37, "endOffset": 57}, {"referenceID": 2, "context": "In NLP, the only work in neural-network-based noise modeling is to use one single global transition matrix to model the noise introduced by crosslingual projection of training data (Fang and Cohn, 2016).", "startOffset": 181, "endOffset": 202}], "year": 2017, "abstractText": "Distant supervision significantly reduces human efforts in building training data for many classification tasks. While promising, this technique often introduces noise to the generated training data, which can severely affect the model performance. In this paper, we take a deep look at the application of distant supervision in relation extraction. We show that the dynamic transition matrix can effectively characterize the noise in the training data built by distant supervision. The transition matrix can be effectively trained using a novel curriculum learning based method without any direct supervision about the noise. We thoroughly evaluate our approach under a wide range of extraction scenarios. Experimental results show that our approach consistently improves the extraction results and outperforms the state-of-the-art in various evaluation scenarios.", "creator": "LaTeX with hyperref package"}}}