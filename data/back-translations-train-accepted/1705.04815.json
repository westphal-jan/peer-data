{"id": "1705.04815", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "13-May-2017", "title": "Learning Semantic Correspondences in Technical Documentation", "abstract": "We consider the problem of translating high-level textual descriptions to formal representations in technical documentation as part of an effort to model the meaning of such documentation. We focus specifically on the problem of learning translational correspondences between text descriptions and grounded representations in the target documentation, such as formal representation of functions or code templates. Our approach exploits the parallel nature of such documentation, or the tight coupling between high-level text and the low-level representations we aim to learn. Data is collected by mining technical documents for such parallel text-representation pairs, which we use to train a simple semantic parsing model. We report new baseline results on sixteen novel datasets, including the standard library documentation for nine popular programming languages across seven natural languages, and a small collection of Unix utility manuals.", "histories": [["v1", "Sat, 13 May 2017 12:29:39 GMT  (97kb,D)", "http://arxiv.org/abs/1705.04815v1", "accepted to ACL-2017"]], "COMMENTS": "accepted to ACL-2017", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kyle richardson", "jonas kuhn"], "accepted": true, "id": "1705.04815"}, "pdf": {"name": "1705.04815.pdf", "metadata": {"source": "CRF", "title": "Learning Semantic Correspondences in Technical Documentation", "authors": ["Kyle Richardson"], "emails": ["kyle@ims.uni-stuttgart.de", "jonas@ims.uni-stuttgart.de", "@param", "@param", "@return", "@see", "@param", "@see"], "sections": [{"heading": "1 Introduction", "text": "This year, it is only a matter of time before a solution can be found in which an agreement can be reached."}, {"heading": "2 Related Work", "text": "Our work is part of research on semantic parsing, which focuses on the problem of generating formal representations of meaning from text for applications in understanding natural language (Berant et al., 2013), robot control (Matuszek et al., 2012), and text generation (Wong and Mooney, 2007a).While creating representations for understanding natural language is a complex task, most studies focus on translation or the generational problem independently of other semantic or knowledge representation problems. Previous work considered assisted learning of logical representations using sample pairs of text from statistical machine translation (Wong and Mooney, 2006) and parsing (Zettlemoyer and Collins, 2009).These methods are intended to be applicable to a wide range of translation problems and types of representation."}, {"heading": "3 Mapping Text to Representations", "text": "In this section we will formulate the basic problem of translation in representations in the technical documentation."}, {"heading": "3.1 Problem Description", "text": "We use the term technical documentation to refer to two types of resources: text descriptions within source code collections and computer manuals. In this paper, the first type contains high-level descriptions of functions in the source code collection of the standard library. The second type includes a collection of Unix manuals, also known as man pages. Both types include text and code representations. We refer to the targets in these resources as API components or components. In the source code, components are formal representations of functions or function signatures (Deng and Chrupa\u0142a, 2014). The form of a function signature varies by resource, but generally specifies how a function is named and structured. The sample function signatures in Figure 3 all specify a function name, a list of arguments, and other optional information such as a return value and a name space."}, {"heading": "3.2 Language Modeling Baselines", "text": "In view of the simplicity of our API representations, we opt for a simple semantic parsing model that exploits the finality of our target representations. (Deng and Chru\u0142a, 2014); in view of the simplicity of our API representations, we opt for a simple semantic parsing model that exploits the finality of our target representations. (Deng and Chru\u0142a, 2014); in view of the simplicity of our API representations, we opt for a simple semantic parsing model that exploits the finality of our target representations."}, {"heading": "3.3 Ranking and Decoding", "text": "Algorithm 1 shows how to classify API components. At text input x, we iterate through all known API components C and assign a score based on Model A. We then evaluate the components based on their scores using a K-BEST function. This method serves as a kind of word-based decoding algorithm simplified by the finiteness of the target language. The complexity of the scoring procedure, lines 3-5, runs linearly across the number components m in C. In practice, we implement the K-BEST sorting function on line 6 as a binary insertion sorting in line 5, resulting in an overall complexity of O (m log m). While iteration via m-API components may not be feasible given more complicated formal languages with recursion, a clever decoding algorithm could be applied, e.g. one based on the grid decoding approach of Dyer (2008)."}, {"heading": "4 Discriminative Approach", "text": "In this section, we present a new model that aims to improve the basic methodologies used to date. While previous models are limited to word-level information, we extend this approach by using a discriminatory reranking model that captures phrase information to see if this leads to improvement. This model can also capture document-level information from the APIs, such as the additional textual descriptions of parameters, see also declarations or classes of related functions and syntax information."}, {"heading": "4.1 Modeling", "text": "As in most semantic parsing approaches (Zettlemoyer and Collins, 2009; Liang et al., 2011), our model is defined as a conditional log linear model using the components z, C with the parameters \u03b8 and Rb and a series of characteristic functions \u03c6 (x, z): p (z, x): \u03b8). Formally, our training objective is to maximize the conditional log probability of the correct component output z for each input x: O (\u03b8) = \u2211 ni = 1 log p (zi | xi; \u03b8)."}, {"heading": "4.2 Features", "text": "Our model uses word-level characteristics such as word match, word pairs, and information from the underlying alignment model such as Viterbi alignment information and model score. Below, two additional categories of non-word characteristics are described. An image of the alignment process is shown in Figure 5. 1.Phrases characteristics We extract phrase characteristics (e.g. (hyper. cosinus, cosh) in Figure 5) from sample text component pairs by forming symmetrical word alignments and applying standard word-level heuristics (Koehn et al., 2003). Additional features such as phrase match / overlap, tree positions of phrases are defined using the extracted phrases. We also extract hierarchical phrases (Chiang, 2007) using a variant of the Zollmann and Venugopal SAMT method (2006) and the component syntax trees."}, {"heading": "4.3 Learning", "text": "To optimize our goal, we use algorithm 2. We estimate the model parameters \u03b8 based on a Kbest approximation of the standard stochastic gradient updates (lines 6-7) and a Ranker function RANK. We note that although we use the Ranker described in algorithm 1, any suitable Ranker method or decoding method could be used here."}, {"heading": "5 Experimental Setup", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Datasets", "text": "Source code documentation Our source code documentation consists of the standard library for nine programming languages listed in Figure 3. We also use the translated version of the PHP collection for six other languages, the details of which are shown in Figure 6. The Java data set was initially used in DC, while we extracted all other data sets for this work. The size of the different data sets is detailed in both figures. The number of pairs is the number of individual records paired with function representations that make up the core component of these data sets. The number of descriptions is the number of additional text descriptions that are provided in the overall document, such as parameter descriptions or return values.We also quantify the different data sets in terms of unique symbols in the target representations that are presented as symbols. All function representations and code sequences are linearized and in some cases further tokenized, for example by converting camel cases or removing the text from the pages of the Item-1 and subfile-1."}, {"heading": "5.2 Evaluation", "text": "For evaluation, we divide our data sets into separate training, validation and test sets. In Java, we reserve 60% of the data for training and the remaining 40% for validation (20%) and testing (20%). For all other data sets, we use a split of 70% -30%. From the retrieval perspective, these provided descriptions are used to imitate invisible queries of our model. After training, we evaluate these sets by evaluating all known components in each resource using algorithm 1. A predicted component is counted as correct if it accurately matches a gold component. Following DC, we report on the accuracy of predicting the correct representation at the top of the ranking (Accuracy @ 1) and within the top 10 positions (Accuracy @ 10). We also report on the mean reciprocessional rank MRR or the multiplicative inversion of the rank of the correct answers."}, {"heading": "6 Results and Discussion", "text": "In fact, most of us are able to play by the rules that have marginalized them in recent years. \"We have to play by the rules,\" he says, \"but it's too early to understand them.\""}, {"heading": "7 Future Work", "text": "We see two possible uses for this data: First, for benchmarking semantic parsing models to perform semantic translation. Although there is a trend towards learning executable semantic parsers (Berant et al., 2013; Liang, 2016), there is also renewed interest in the supervised learning of formal representations associated with neural semantic parsing models (Dong and Lapata, 2016; Jia and Liang, 2016). We believe that a good performance of our data sets should lead to better performance in more conventional semantic parsing tasks and raise new challenges related to sparse and multilingual learning. We also consider these resources useful for studies on natural language programming. While our experiments investigate rudimentary translation correspondences between text and code, a next step could be to synthesize executable programs using these translations (Desai et al., 2016; Raza et al., 2015)."}, {"heading": "Acknowledgements", "text": "This work was funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) via SFB 732, Project D2. Thanks also to our IMS colleagues, especially Christian Scheible, for feedback on earlier drafts and to Jonathan Berant for helpful discussions."}], "references": [{"title": "Bimodal modelling of source code and natural language", "author": ["Miltiadis Allamanis", "Daniel Tarlow", "Andrew D Gordon", "Yi Wei."], "venue": "Proceedings of the 32th International Conference on Machine Learning. volume 951, page 2015.", "citeRegEx": "Allamanis et al\\.,? 2015", "shortCiteRegEx": "Allamanis et al\\.", "year": 2015}, {"title": "Broad-coverage CCG semantic parsing with AMR", "author": ["Yoav Artzi", "Kenton Lee", "Luke Zettlemoyer."], "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. pages 1699\u20131710.", "citeRegEx": "Artzi et al\\.,? 2015", "shortCiteRegEx": "Artzi et al\\.", "year": 2015}, {"title": "Abstract meaning representation for sembanking", "author": ["Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Martha Palmer", "Nathan Schneider."], "venue": "In Proceedings of the 7th Linguistic", "citeRegEx": "Banarescu et al\\.,? 2013", "shortCiteRegEx": "Banarescu et al\\.", "year": 2013}, {"title": "Semantic parsing on Freebase from question-answer pairs", "author": ["Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang."], "venue": "in Proceedings of EMNLP-2013. pages 1533\u20131544.", "citeRegEx": "Berant et al\\.,? 2013", "shortCiteRegEx": "Berant et al\\.", "year": 2013}, {"title": "Semantic parsing via paraphrasing", "author": ["Jonathan Berant", "Percy Liang."], "venue": "Proceedings of ACL2014. pages 1415\u20131425.", "citeRegEx": "Berant and Liang.,? 2014", "shortCiteRegEx": "Berant and Liang.", "year": 2014}, {"title": "Reducing grounded learning tasks to grammatical inference", "author": ["Benjamin B\u00f6rschinger", "Bevan K. Jones", "Mark Johnson."], "venue": "Proceedings of EMNLP2011. pages 1416\u20131425.", "citeRegEx": "B\u00f6rschinger et al\\.,? 2011", "shortCiteRegEx": "B\u00f6rschinger et al\\.", "year": 2011}, {"title": "The mathematics of statistical machine translation: Parameter estimation", "author": ["Peter F Brown", "Vincent J Della Pietra", "Stephen A Della Pietra", "Robert L Mercer."], "venue": "Computational linguistics 19(2):263\u2013311.", "citeRegEx": "Brown et al\\.,? 1993", "shortCiteRegEx": "Brown et al\\.", "year": 1993}, {"title": "Learning to sportscast: A test of grounded language acquisition", "author": ["David L. Chen", "Raymond J. Mooney."], "venue": "Proceedings of ICML-2008. pages 128\u2013 135.", "citeRegEx": "Chen and Mooney.,? 2008", "shortCiteRegEx": "Chen and Mooney.", "year": 2008}, {"title": "Hierarchical phrase-based translation", "author": ["David Chiang."], "venue": "computational linguistics 33(2):201\u2013228.", "citeRegEx": "Chiang.,? 2007", "shortCiteRegEx": "Chiang.", "year": 2007}, {"title": "Natural language interfaces: what is the problem?\u2013a datadriven quantitative analysis", "author": ["Philipp Cimiano", "Michael Minock."], "venue": "International Conference on Application of Natural Language to Information Systems. Springer, pages 192\u2013206.", "citeRegEx": "Cimiano and Minock.,? 2009", "shortCiteRegEx": "Cimiano and Minock.", "year": 2009}, {"title": "Semantic approaches to software component retrieval with English queries", "author": ["Huijing Deng", "Grzegorz Chrupa\u0142a."], "venue": "Proceedings of LREC-14. pages 441\u2013450.", "citeRegEx": "Deng and Chrupa\u0142a.,? 2014", "shortCiteRegEx": "Deng and Chrupa\u0142a.", "year": 2014}, {"title": "Program synthesis using natural language", "author": ["Aditya Desai", "Sumit Gulwani", "Vineet Hingorani", "Nidhi Jain", "Amey Karkare", "Mark Marron", "Subhajit Roy"], "venue": "In Proceedings of the 38th International Conference on Software Engineering", "citeRegEx": "Desai et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Desai et al\\.", "year": 2016}, {"title": "Language to logical form with neural attention", "author": ["Li Dong", "Mirella Lapata."], "venue": "arXiv preprint arXiv:1601.01280 .", "citeRegEx": "Dong and Lapata.,? 2016", "shortCiteRegEx": "Dong and Lapata.", "year": 2016}, {"title": "Generalizing word lattice translation", "author": ["Christopher Dyer", "Smaranda Muresan", "Philip Resnik."], "venue": "Proceedings of ACL-08 page 1012.", "citeRegEx": "Dyer et al\\.,? 2008", "shortCiteRegEx": "Dyer et al\\.", "year": 2008}, {"title": "Deep API Learning", "author": ["Xiaodong Gu", "Hongyu Zhang", "Dongmei Zhang", "Sunghun Kim."], "venue": "arXiv preprint arXiv:1605.08535 .", "citeRegEx": "Gu et al\\.,? 2016", "shortCiteRegEx": "Gu et al\\.", "year": 2016}, {"title": "Summarizing source code using a neural attention model", "author": ["Srinivasan Iyer", "Ioannis Kostas", "Alvin Cheung", "Luke Zettlemoyer."], "venue": "Proceedings of ACL2016 .", "citeRegEx": "Iyer et al\\.,? 2016", "shortCiteRegEx": "Iyer et al\\.", "year": 2016}, {"title": "Data recombination for neural semantic parsing", "author": ["Robin Jia", "Percy Liang."], "venue": "arXiv preprint arXiv:1606.03622 .", "citeRegEx": "Jia and Liang.,? 2016", "shortCiteRegEx": "Jia and Liang.", "year": 2016}, {"title": "Statistical phrase-based translation", "author": ["Philipp Koehn", "Franz Josef Och", "Daniel Marcu."], "venue": "Proceedings of the NACL-2003. pages 48\u201354.", "citeRegEx": "Koehn et al\\.,? 2003", "shortCiteRegEx": "Koehn et al\\.", "year": 2003}, {"title": "Learning to automatically solve algebra word problems", "author": ["Nate Kushman", "Yoav Artzi", "Luke Zettlemoyer", "Regina Barzilay."], "venue": "Proceedings of ACL-2014. pages 271\u2013281.", "citeRegEx": "Kushman et al\\.,? 2014", "shortCiteRegEx": "Kushman et al\\.", "year": 2014}, {"title": "Using semantic unification to generate regular expressions from natural language", "author": ["Nate Kushman", "Regina Barzilay."], "venue": "Proceedings of NAACL2013.", "citeRegEx": "Kushman and Barzilay.,? 2013", "shortCiteRegEx": "Kushman and Barzilay.", "year": 2013}, {"title": "Inducing probabilistic CCG grammars from logical form with higherorder unification", "author": ["Tom Kwiatkowski", "Luke Zettlemoyer", "Sharon Goldwater", "Mark Steedman."], "venue": "Proceedings of EMNLP-2010. pages 1223\u20131233.", "citeRegEx": "Kwiatkowski et al\\.,? 2010", "shortCiteRegEx": "Kwiatkowski et al\\.", "year": 2010}, {"title": "Learning dependency-based compositional semantics", "author": ["P. Liang", "M.I. Jordan", "D. Klein."], "venue": "Proceedings of ACL-11. pages 590\u2013599.", "citeRegEx": "Liang et al\\.,? 2011", "shortCiteRegEx": "Liang et al\\.", "year": 2011}, {"title": "Learning executable semantic parsers for natural language understanding", "author": ["Percy Liang."], "venue": "Communications of the ACM 59(9):68\u201376.", "citeRegEx": "Liang.,? 2016", "shortCiteRegEx": "Liang.", "year": 2016}, {"title": "Codehow: Effective code search based on api understanding and extended boolean model (e)", "author": ["Fei Lv", "Hongyu Zhang", "Jian-guang Lou", "Shaowei Wang", "Dongmei Zhang", "Jianjun Zhao."], "venue": "Automated Software Engineering (ASE), 2015", "citeRegEx": "Lv et al\\.,? 2015", "shortCiteRegEx": "Lv et al\\.", "year": 2015}, {"title": "Integrating programming by example and natural language programming", "author": ["Mehdi Hafezi Manshadi", "Daniel Gildea", "James F Allen."], "venue": "Proceedings of AAAI-2013.", "citeRegEx": "Manshadi et al\\.,? 2013", "shortCiteRegEx": "Manshadi et al\\.", "year": 2013}, {"title": "Learning to parse natural language commands to a robot control system", "author": ["Cynthia Matuszek", "Evan Herbst", "Luke Zettlemoyer", "Dieter Fox."], "venue": "Proceedings of the International Symposium on Experimental Robotics (ISER).", "citeRegEx": "Matuszek et al\\.,? 2012", "shortCiteRegEx": "Matuszek et al\\.", "year": 2012}, {"title": "A systematic comparison of various statistical alignment models", "author": ["Franz Josef Och", "Hermann Ney."], "venue": "Computational linguistics 29(1):19\u201351.", "citeRegEx": "Och and Ney.,? 2003", "shortCiteRegEx": "Och and Ney.", "year": 2003}, {"title": "Learning to generate pseudo-code from source code using statistical machine translation (t)", "author": ["Yusuke Oda", "Hiroyuki Fudaba", "Graham Neubig", "Hideaki Hata", "Sakriani Sakti", "Tomoki Toda", "Satoshi Nakamura."], "venue": "Automated Software Engi-", "citeRegEx": "Oda et al\\.,? 2015", "shortCiteRegEx": "Oda et al\\.", "year": 2015}, {"title": "Compositional semantic parsing on semi-structured tables", "author": ["Panupong Pasupat", "Percy Liang."], "venue": "Proceedings of ACL-2015.", "citeRegEx": "Pasupat and Liang.,? 2015", "shortCiteRegEx": "Pasupat and Liang.", "year": 2015}, {"title": "A Synchronous Hyperedge Replacement Grammar based approach for AMR parsing", "author": ["Xiaochang Peng", "Linfeng Song", "Daniel Gildea."], "venue": "Proceedings of CoNLL-2015 page 32.", "citeRegEx": "Peng et al\\.,? 2015", "shortCiteRegEx": "Peng et al\\.", "year": 2015}, {"title": "Language to code: Learning semantic parsers for if-this-then-that recipes", "author": ["Chris Quirk", "Raymond J Mooney", "Michel Galley."], "venue": "Proceedings of ACL2015. pages 878\u2013888.", "citeRegEx": "Quirk et al\\.,? 2015", "shortCiteRegEx": "Quirk et al\\.", "year": 2015}, {"title": "Compositional program synthesis from natural language and examples", "author": ["Mohammad Raza", "Sumit Gulwani", "Natasa MilicFrayling."], "venue": "IJCAI. pages 792\u2013800.", "citeRegEx": "Raza et al\\.,? 2015", "shortCiteRegEx": "Raza et al\\.", "year": 2015}, {"title": "Large-scale semantic parsing without questionanswer pairs", "author": ["Siva Reddy", "Mirella Lapata", "Mark Steedman."], "venue": "Transactions of the Association for Computational Linguistics 2:377\u2013392.", "citeRegEx": "Reddy et al\\.,? 2014", "shortCiteRegEx": "Reddy et al\\.", "year": 2014}, {"title": "UnixMan corpus: A resource for language learning in the Unix domain", "author": ["Kyle Richardson", "Jonas Kuhn."], "venue": "Proceedings of LREC-2014.", "citeRegEx": "Richardson and Kuhn.,? 2014", "shortCiteRegEx": "Richardson and Kuhn.", "year": 2014}, {"title": "Learning to make inferences in a semantic parsing task", "author": ["Kyle Richardson", "Jonas Kuhn."], "venue": "Transactions of the Association for Computational Linguistics 4:155\u2013168.", "citeRegEx": "Richardson and Kuhn.,? 2016", "shortCiteRegEx": "Richardson and Kuhn.", "year": 2016}, {"title": "A general language model for information retrieval", "author": ["F. Song", "W.B Croft."], "venue": "in Proceedings International Conference on Information and Knowledge Management.", "citeRegEx": "Song and Croft.,? 1999", "shortCiteRegEx": "Song and Croft.", "year": 1999}, {"title": "Parallel data, tools and interfaces in opus", "author": ["J\u00f6rg Tiedemann."], "venue": "LREC. volume 2012, pages 2214\u2013 2218.", "citeRegEx": "Tiedemann.,? 2012", "shortCiteRegEx": "Tiedemann.", "year": 2012}, {"title": "Learning for semantic parsing with statistical machine translation", "author": ["Yuk Wah Wong", "Raymond J. Mooney."], "venue": "Proceedings of HLT-NAACL-2006. pages 439\u2013446.", "citeRegEx": "Wong and Mooney.,? 2006", "shortCiteRegEx": "Wong and Mooney.", "year": 2006}, {"title": "Generation by inverting a semantic parser that uses statistical machine translation", "author": ["Yuk Wah Wong", "Raymond J Mooney."], "venue": "Proceedings of HLTNAACL-2007. pages 172\u2013179.", "citeRegEx": "Wong and Mooney.,? 2007a", "shortCiteRegEx": "Wong and Mooney.", "year": 2007}, {"title": "Learning synchronous grammars for semantic parsing with lambda calculus", "author": ["Yuk Wah Wong", "Raymond J. Mooney."], "venue": "Proceedings of ACL2007. Prague, Czech Republic.", "citeRegEx": "Wong and Mooney.,? 2007b", "shortCiteRegEx": "Wong and Mooney.", "year": 2007}, {"title": "Learning to parse database queries using inductive logic programming", "author": ["John M Zelle", "Raymond J Mooney."], "venue": "Proceedings of AAAI-1996. pages 1050\u20131055.", "citeRegEx": "Zelle and Mooney.,? 1996", "shortCiteRegEx": "Zelle and Mooney.", "year": 1996}, {"title": "Learning context-dependent mappings from sentences to logical form", "author": ["Luke S. Zettlemoyer", "Michael Collins."], "venue": "Proceedings of ACL-2009. pages 976\u2013984.", "citeRegEx": "Zettlemoyer and Collins.,? 2009", "shortCiteRegEx": "Zettlemoyer and Collins.", "year": 2009}, {"title": "Syntax augmented machine translation via chart parsing", "author": ["Andreas Zollmann", "Ashish Venugopal."], "venue": "Proceedings of the Workshop on Statistical Machine Translation. pages 138\u2013141.", "citeRegEx": "Zollmann and Venugopal.,? 2006", "shortCiteRegEx": "Zollmann and Venugopal.", "year": 2006}], "referenceMentions": [{"referenceID": 10, "context": "We achieved initial baselines using the language modeling and translation approach of Deng and Chrupa\u0142a (2014). We also show that modest improvements can be achieved by using a more conventional", "startOffset": 86, "endOffset": 111}, {"referenceID": 41, "context": "discriminative model (Zettlemoyer and Collins, 2009) that, in part, exploits document-level features from the technical documentation sets.", "startOffset": 21, "endOffset": 52}, {"referenceID": 3, "context": "Recent interest in this topic has centered around learning meaning representation from example text-meaning pairs, for applications such as automated question-answering (Berant et al., 2013), robot control (Matuszek et al.", "startOffset": 169, "endOffset": 190}, {"referenceID": 25, "context": ", 2013), robot control (Matuszek et al., 2012) and text generation (Wong and Mooney, 2007a).", "startOffset": 23, "endOffset": 46}, {"referenceID": 38, "context": ", 2012) and text generation (Wong and Mooney, 2007a).", "startOffset": 28, "endOffset": 52}, {"referenceID": 37, "context": "Earlier work looks at supervised learning of logical representations using example text-meaning pairs using tools from statistical machine translation (Wong and Mooney, 2006) and parsing (Zettlemoyer and Collins, 2009).", "startOffset": 151, "endOffset": 174}, {"referenceID": 41, "context": "Earlier work looks at supervised learning of logical representations using example text-meaning pairs using tools from statistical machine translation (Wong and Mooney, 2006) and parsing (Zettlemoyer and Collins, 2009).", "startOffset": 187, "endOffset": 218}, {"referenceID": 3, "context": "While attempts have been made to do open-domain semantic parsing using larger, more complex datasets (Berant et al., 2013; Pasupat and Liang, 2015), such resources are still scarce.", "startOffset": 101, "endOffset": 147}, {"referenceID": 28, "context": "While attempts have been made to do open-domain semantic parsing using larger, more complex datasets (Berant et al., 2013; Pasupat and Liang, 2015), such resources are still scarce.", "startOffset": 101, "endOffset": 147}, {"referenceID": 40, "context": "In Figure 3, we compare the details of one widely used dataset, Geoquery (Zelle and Mooney, 1996), to our new datasets.", "startOffset": 73, "endOffset": 97}, {"referenceID": 22, "context": "Within semantic parsing, there has also been work on situated or grounded learning, that involves learning in domains with weak supervision and indirect cues (Liang, 2016; Richardson and Kuhn, 2016).", "startOffset": 158, "endOffset": 198}, {"referenceID": 34, "context": "Within semantic parsing, there has also been work on situated or grounded learning, that involves learning in domains with weak supervision and indirect cues (Liang, 2016; Richardson and Kuhn, 2016).", "startOffset": 158, "endOffset": 198}, {"referenceID": 7, "context": "This has sometimes involved learning from automatically generated parallel data and representations (Chen and Mooney, 2008) of the type we consider in this paper.", "startOffset": 100, "endOffset": 123}, {"referenceID": 24, "context": "Here one can find work in technical domains, including learning to generate regular expressions (Manshadi et al., 2013; Kushman and Barzilay, 2013) and other types of source code (Quirk et al.", "startOffset": 96, "endOffset": 147}, {"referenceID": 19, "context": "Here one can find work in technical domains, including learning to generate regular expressions (Manshadi et al., 2013; Kushman and Barzilay, 2013) and other types of source code (Quirk et al.", "startOffset": 96, "endOffset": 147}, {"referenceID": 30, "context": ", 2013; Kushman and Barzilay, 2013) and other types of source code (Quirk et al., 2015), which ultimately aim to solve the problem of natural language programming.", "startOffset": 67, "endOffset": 87}, {"referenceID": 23, "context": "Robustly learning the translation from language to code representations can help to facilitate natural language querying of API collections (Lv et al., 2015).", "startOffset": 140, "endOffset": 157}, {"referenceID": 0, "context": "These studies primarily focus on learning longer programs (Allamanis et al., 2015) as opposed to function representations, or focus narrowly on a single programming language such as Java (Gu et al.", "startOffset": 58, "endOffset": 82}, {"referenceID": 14, "context": ", 2015) as opposed to function representations, or focus narrowly on a single programming language such as Java (Gu et al., 2016) or on related tasks such as text generation (Iyer et al.", "startOffset": 112, "endOffset": 129}, {"referenceID": 15, "context": ", 2016) or on related tasks such as text generation (Iyer et al., 2016; Oda et al., 2015).", "startOffset": 52, "endOffset": 89}, {"referenceID": 27, "context": ", 2016) or on related tasks such as text generation (Iyer et al., 2016; Oda et al., 2015).", "startOffset": 52, "endOffset": 89}, {"referenceID": 9, "context": "Our work is also related to software components retrieval and builds on the approach of Deng and Chrupa\u0142a (2014). Robustly learning the translation from language to code representations can help to facilitate natural language querying of API collections (Lv et al.", "startOffset": 88, "endOffset": 113}, {"referenceID": 10, "context": "In source code, components are formal representations of functions, or function signatures (Deng and Chrupa\u0142a, 2014).", "startOffset": 91, "endOffset": 116}, {"referenceID": 10, "context": "In source code, components are formal representations of functions, or function signatures (Deng and Chrupa\u0142a, 2014). The form of a function signature varies depending on the resource, but in general gives a specification of how a function is named and structured. The example function signatures in Figure 3 all specify a function name, a list of arguments, and other optional information such as a return value and a namespace. Components in utility manuals are short executable code sequences intended to show an example use of a utility. We assume typed code sequences following Richardson and Kuhn (2014), where the constituent parts of the sequences are abstracted by type.", "startOffset": 92, "endOffset": 610}, {"referenceID": 10, "context": "For a given input, therefore, the goal is to find the best candidate function translation within the space of the total API components C (Deng and Chrupa\u0142a, 2014).", "startOffset": 137, "endOffset": 162}, {"referenceID": 18, "context": "Given these constraints, our setup closely resembles that of Kushman et al. (2014), who learn to parse algebra word problems using a small set of equation templates.", "startOffset": 61, "endOffset": 83}, {"referenceID": 5, "context": "Existing approaches to semantic parsing formalize the mapping from language to logic using a variety of formalisms including CFGs (B\u00f6rschinger et al., 2011), CCGs (Kwiatkowski et al.", "startOffset": 130, "endOffset": 156}, {"referenceID": 20, "context": ", 2011), CCGs (Kwiatkowski et al., 2010), synchronous CFGs (Wong and Mooney, 2007b).", "startOffset": 14, "endOffset": 40}, {"referenceID": 39, "context": ", 2010), synchronous CFGs (Wong and Mooney, 2007b).", "startOffset": 26, "endOffset": 50}, {"referenceID": 2, "context": "For example, recent interest in learning graph-based representations such as those in the AMR bank (Banarescu et al., 2013)", "startOffset": 99, "endOffset": 123}, {"referenceID": 1, "context": "requires parsing models that can generate complex graph shaped derivations such as CCGs (Artzi et al., 2015) or HRGs (Peng et al.", "startOffset": 88, "endOffset": 108}, {"referenceID": 29, "context": ", 2015) or HRGs (Peng et al., 2015).", "startOffset": 16, "endOffset": 35}, {"referenceID": 10, "context": "Following ((Deng and Chrupa\u0142a, 2014); henceforth DC), we treat the problem of component translation as a language modeling problem (Song and Croft, 1999).", "startOffset": 11, "endOffset": 36}, {"referenceID": 35, "context": "Following ((Deng and Chrupa\u0142a, 2014); henceforth DC), we treat the problem of component translation as a language modeling problem (Song and Croft, 1999).", "startOffset": 131, "endOffset": 153}, {"referenceID": 26, "context": "In this paper, we limit ourselves to sequence-based word alignment models (Och and Ney, 2003), which factor in the following manner:", "startOffset": 74, "endOffset": 93}, {"referenceID": 6, "context": "Models (1-2) are the classic IBM word-alignment models of Brown et al. (1993). IBM Model 1, for example, assumes a uniform distribution over all positions, and is the main model investigated in DC.", "startOffset": 58, "endOffset": 78}, {"referenceID": 6, "context": "Learning is done by applying the standard EM training procedure of Brown et al. (1993).", "startOffset": 67, "endOffset": 87}, {"referenceID": 8, "context": "Below are Hiero rules (Chiang, 2007) extracted from the alignment and tree information.", "startOffset": 22, "endOffset": 36}, {"referenceID": 13, "context": ", one based on the lattice decoding approach of (Dyer et al., 2008).", "startOffset": 48, "endOffset": 67}, {"referenceID": 41, "context": "Like in most semantic parsing approaches (Zettlemoyer and Collins, 2009; Liang et al., 2011), our model is defined as a conditional log-linear z: function float cosh float $arg", "startOffset": 41, "endOffset": 92}, {"referenceID": 21, "context": "Like in most semantic parsing approaches (Zettlemoyer and Collins, 2009; Liang et al., 2011), our model is defined as a conditional log-linear z: function float cosh float $arg", "startOffset": 41, "endOffset": 92}, {"referenceID": 17, "context": "cosine,cosh) in Figure 5) from example text component pairs by training symmetric word aligners and applying standard word-level heuristics (Koehn et al., 2003).", "startOffset": 140, "endOffset": 160}, {"referenceID": 8, "context": "We also extract hierarchical phrases (Chiang, 2007) using a variant of the SAMT method of Zollmann and Venugopal (2006) and the component syntax trees.", "startOffset": 37, "endOffset": 51}, {"referenceID": 8, "context": "We also extract hierarchical phrases (Chiang, 2007) using a variant of the SAMT method of Zollmann and Venugopal (2006) and the component syntax trees.", "startOffset": 38, "endOffset": 120}, {"referenceID": 33, "context": "Man pages The collection of man pages is from Richardson and Kuhn (2014) and includes 921 text-code pairs that span 330 Unix utilities and man pages.", "startOffset": 46, "endOffset": 73}, {"referenceID": 26, "context": "While Model 2 is known to outperform Model 1 on more conventional translation tasks (Och and Ney, 2003), it appears that such improvements are not reflected in this type of semantic translation context.", "startOffset": 84, "endOffset": 103}, {"referenceID": 9, "context": "In many benchmark semantic parsing datasets, such sparsity issues do not occur (Cimiano and Minock, 2009), suggesting that state-of-the-art methods will have similar problems when applied to our datasets.", "startOffset": 79, "endOffset": 105}, {"referenceID": 4, "context": "Recent approaches to open-domain semantic parsing have dealt with this problem by using paraphrasing techniques (Berant and Liang, 2014) or distant supervision (Reddy et al.", "startOffset": 112, "endOffset": 136}, {"referenceID": 32, "context": "Recent approaches to open-domain semantic parsing have dealt with this problem by using paraphrasing techniques (Berant and Liang, 2014) or distant supervision (Reddy et al., 2014).", "startOffset": 160, "endOffset": 180}, {"referenceID": 36, "context": "We expect that these methods can be used to improve our models and results, especially given the wide availability of technical documentation, for example, distributed within the Opus project (Tiedemann, 2012).", "startOffset": 192, "endOffset": 209}, {"referenceID": 3, "context": "While there has been a trend towards learning executable semantic parsers (Berant et al., 2013; Liang, 2016), there has also been renewed interest in supervised learning of formal representations in the context of neural semantic parsing models (Dong and Lapata, 2016; Jia and Liang, 2016).", "startOffset": 74, "endOffset": 108}, {"referenceID": 22, "context": "While there has been a trend towards learning executable semantic parsers (Berant et al., 2013; Liang, 2016), there has also been renewed interest in supervised learning of formal representations in the context of neural semantic parsing models (Dong and Lapata, 2016; Jia and Liang, 2016).", "startOffset": 74, "endOffset": 108}, {"referenceID": 12, "context": ", 2013; Liang, 2016), there has also been renewed interest in supervised learning of formal representations in the context of neural semantic parsing models (Dong and Lapata, 2016; Jia and Liang, 2016).", "startOffset": 157, "endOffset": 201}, {"referenceID": 16, "context": ", 2013; Liang, 2016), there has also been renewed interest in supervised learning of formal representations in the context of neural semantic parsing models (Dong and Lapata, 2016; Jia and Liang, 2016).", "startOffset": 157, "endOffset": 201}, {"referenceID": 11, "context": "While our experiments look at learning rudimentary translational correspondences between text and code, a next step might be learning to synthesize executable programs via these translations, along the lines of (Desai et al., 2016; Raza et al., 2015).", "startOffset": 211, "endOffset": 250}, {"referenceID": 31, "context": "While our experiments look at learning rudimentary translational correspondences between text and code, a next step might be learning to synthesize executable programs via these translations, along the lines of (Desai et al., 2016; Raza et al., 2015).", "startOffset": 211, "endOffset": 250}], "year": 2017, "abstractText": "We consider the problem of translating high-level textual descriptions to formal representations in technical documentation as part of an effort to model the meaning of such documentation. We focus specifically on the problem of learning translational correspondences between text descriptions and grounded representations in the target documentation, such as formal representation of functions or code templates. Our approach exploits the parallel nature of such documentation, or the tight coupling between high-level text and the low-level representations we aim to learn. Data is collected by mining technical documents for such parallel text-representation pairs, which we use to train a simple semantic parsing model. We report new baseline results on sixteen novel datasets, including the standard library documentation for nine popular programming languages across seven natural languages, and a small collection of Unix utility manuals.", "creator": "LaTeX with hyperref package"}}}