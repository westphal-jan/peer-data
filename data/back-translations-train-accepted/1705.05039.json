{"id": "1705.05039", "review": {"conference": "ACL", "VERSION": "v1", "DATE_OF_SUBMISSION": "14-May-2017", "title": "Joint Modeling of Content and Discourse Relations in Dialogues", "abstract": "We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns. A variation of our model is also discussed when discourse relations are treated as latent variables. Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrase-based content selection and discourse relation prediction tasks. We also evaluate our model on predicting the consistency among team members' understanding of their group decisions. Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.", "histories": [["v1", "Sun, 14 May 2017 23:45:49 GMT  (104kb,D)", "http://arxiv.org/abs/1705.05039v1", "Accepted by ACL 2017. 11 pages"]], "COMMENTS": "Accepted by ACL 2017. 11 pages", "reviews": [], "SUBJECTS": "cs.CL", "authors": ["kechen qin", "lu wang", "joseph kim"], "accepted": true, "id": "1705.05039"}, "pdf": {"name": "1705.05039.pdf", "metadata": {"source": "CRF", "title": "Joint Modeling of Content and Discourse Relations in Dialogues", "authors": ["Kechen Qin", "Lu Wang", "Joseph Kim"], "emails": ["qin.ke@husky.neu.edu,", "luwang@ccs.neu.edu", "kim@csail.mit.edu"], "sections": [{"heading": "1 Introduction", "text": "This year, we have reached the point where we feel we are in a position to live in a country where people are able to move around in order to flourish."}, {"heading": "2 Related Work", "text": "Our model is inspired by research that uses discourse structures to identify distinctive content in conversations that are still largely based on features derived from gold standard discourse labels (McKeown et al., 2007; Murray et al., 2010; Bokaei et al., 2016). For example, adjacent pairs paired with question-answer or offer-acceptance relationships are often found together in meeting summaries and are therefore used to extract summary statements from Galley (2006). There is much less work that collectively predicts the meaning of content along with the discourse structure in dialogue. Oya and Carenini (2014) use Dynamic Conditional Random Field to identify sentences in email threads for use in summaries and their dialog acts. Only local discourse structures from adjacent discourse structures are considered."}, {"heading": "3 The Joint Model of Content and Discourse Relations", "text": "In this section, we first present our common model in Section 3.1. Algorithms for learning and deduction are described in Section 3.2 and 3.3, followed by a description of the characteristics (Section 3.4)."}, {"heading": "3.1 Model Description", "text": "We assume that a discussion discussion is called x, where x of a sequence of discourse units x = {x1}, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7"}, {"heading": "3.2 Joint Learning for Parameter Estimation", "text": "To learn the model parameters w, we first use an algorithm based on SampleRank (Rohanimanesh et al., 2011), which is a stochastic structure learning method. In general, the learning algorithm constructs a sequence of configurations for sample names as a Markov chain Monte Carlo (MCMC) chain based on a task-specific loss function in which stochastic gradients are distributed throughout the chain. The complete learning process is described in Algorithm 1. Initially, the property weights w are initialized with each value randomly drawn from [\u2212 1, 1]. Multiple epochs are passed through all samples. For each sample, we initialize the mapping of candidate phrases with the designations c and discourse relationships. Then, an MCMC chain is built with a series of configurations, which we use a series of configurations d): (c, d): In each step, we first try a discourse structure based on the distribution (xd)."}, {"heading": "3.3 Joint Inference for Prediction", "text": "Given a new sample x and learned parameters w, we predict phrase names and discourse relations as arg maxc, d p (c, d | x, w). Dynamic programming can be used to perform common conclusions, but it would be time consuming, since our objective function has a large search space for both content and discourse names. Therefore, we propose an alternating optimization algorithm to search for c and d iteratively. Specifically, for each iteration, we optimize d first by maximizing n i = 1, < xi, x \u2032 i >. In the second step, we look for c that max imitates = 1, < ci, j, di, x). Message transmission (Smith and Eisner, 2008) is used to find the best d."}, {"heading": "3.4 Features", "text": "To model the emphasis of the content, we calculate the minimum, maximum and average of the TF-IDF scores of words and the number of substantive words in each sentence based on the intuition that important phrases tend to have more substantive words with high TF-IDF scores (Ferna \u0301 ndez et al., 2008). We also consider whether the headword of the phrase was mentioned in a previous round, which implies the focus of a discussion. Thus, we identify the absolute and relative position of the unit containing the candidate phrase in the discussion. Finally, we record whether the candidate phrase x is expressed, who speaks the most words in the discussion, we Hakak."}, {"heading": "4 Datasets and Experimental Setup", "text": "In fact, it is the case that most of them are able to move into the world, and that they are able to move into the world where they want to. \"(S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S. S."}, {"heading": "5 Experimental Results", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "5.1 Phrase Selection and Discourse Labeling", "text": "Here we present the experimental results on phrase selection and prediction of discourse relationships. In addition, we experiment with two variants of our common model: one is trained on gold standard discourse relationships, the other is on 4There are 9 types of relationships in TAS: POSITIVE, NEGATIVE, UNCERTAIN, REQUEST, SPECIALIZATION, ELABORATION, OPTION EXCLUSION and SUBJECT-TO.5 Multi-level classifier has also been experimented, but gave inferior performance. Treatment of discourse relationships as latent models as described in Section 3.1. Remember that we have gold standard argument diagrams on the AMISUB dataset, we can therefore conduct experiments by adopting the true attachment structure for latents."}, {"heading": "5.2 Phrase-Based Extractive Summarization", "text": "We also evaluate whether the prediction of the content selection component can be used to summarize the most important points at the discussion level. For each discussion, distinctive phrases identified by our model are linked in order for use as a summary. We consider two types of gold standard summaries. We calculate the results at the level of extraction that consists of the popular summary utterances, the others are abstract summaries, where we collect human abstraction with at least one link from summary utterances. We calculate the results based on RUGE (Lin and Hovy, 2003), which is a popular tool for evaluating text summaries (Gillick et al, 2009; Liu and Liu, 2010)."}, {"heading": "5.3 Further Analysis and Discussions", "text": "Higher TF-IDF values also indicate important phrases. However, if a phrase is mentioned in the previous round and repeated in the current round, it is likely to be a key point. Structural characteristics play the biggest role in the discourse characteristics. For example, joint modelling of the parent node's discourse relationship with the current node leads to better conclusions. An example is that giving more details about the proposal (ELABORATION) tends to lead to positive feedback. In addition, the requirement usually appears close to the root of the argument tree, while POSITIVE feedback is usually observed on sheets. Adjacence pairs also play an important role in predicting the discourse. For common characteristics, features that are composed of \"phrase mentioned in the previous round\" and the relationship with the main POSITREIVE or QUIVE are also higher."}, {"heading": "6 Predicting Consistency of Understanding", "text": "In this section, we will test whether our common model can be used to predict the consistency of group decisions, which are defined as the consistency of understanding (COU) in Kim and Shah (2016). Discussion is identified as inconsistent, and its consistency extends to part of the AMI discussions by summarizing the participants to determine whether the participants are making the same decisions. If all the decision points are consistent, the associated topic is called consistent."}, {"heading": "7 Conclusion", "text": "We presented a common model for the selection of phrases and prediction of discourse relationships in spoken meetings. Experimental results on AMI and ICSI meeting corpora showed that our model can outperform state-of-the-art methods in both tasks. Further evaluations to the task of predicting consistency of understanding in meetings showed that classifiers trained with features constructed from our model output performed better than the modern model. This is evidence that our model is successfully applied to other prediction tasks in spoken meetings."}, {"heading": "Acknowledgments", "text": "This work was partially supported by the National Science Foundation grant IIS-1566382 and a GPU gift from Nvidia. We thank three anonymous reviewers for their valuable suggestions on various aspects of this work. 6We also experiment with other popular classifiers, such as logistic regression or decision tree, and a similar trend is respected."}], "references": [{"title": "Extractive Summarization of Multi-party Meetings Through Discourse Segmentation", "author": ["Mohammad Hadi Bokaei", "Hossein Sameti", "Yang Liu."], "venue": "Natural Language Engineering 22(01):41\u201372.", "citeRegEx": "Bokaei et al\\.,? 2016", "shortCiteRegEx": "Bokaei et al\\.", "year": 2016}, {"title": "Extracting Decisions from Multi-party Dialogue Using Directed Graphical Models and Semantic Similarity", "author": ["Trung H. Bui", "Matthew Frampton", "John Dowding", "Stanley Peters."], "venue": "Proceedings of the SIGDIAL 2009 Conference: The 10th", "citeRegEx": "Bui et al\\.,? 2009", "shortCiteRegEx": "Bui et al\\.", "year": 2009}, {"title": "The AMI Meeting Corpus: A Pre-announcement", "author": ["Dennis Reidsma", "Pierre Wellner."], "venue": "Proceedings of the Second International Conference on Machine Learning for Multimodal Interaction. Springer-Verlag, Berlin, Heidelberg, MLMI\u201905,", "citeRegEx": "Reidsma and Wellner.,? 2006", "shortCiteRegEx": "Reidsma and Wellner.", "year": 2006}, {"title": "Learning to Classify Email into \u201cSpeech Acts", "author": ["William W. Cohen", "Vitor R. Carvalho", "Tom M. Mitchell."], "venue": "Dekang Lin and Dekai Wu, editors, Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing. As-", "citeRegEx": "Cohen et al\\.,? 2004", "shortCiteRegEx": "Cohen et al\\.", "year": 2004}, {"title": "Recognition of Dialogue Acts in Multiparty Meetings Using a Switching DBN", "author": ["Alfred Dielmann", "Steve Renals."], "venue": "IEEE transactions on audio, speech, and language processing 16(7):1303\u20131314.", "citeRegEx": "Dielmann and Renals.,? 2008", "shortCiteRegEx": "Dielmann and Renals.", "year": 2008}, {"title": "Identifying Relevant Phrases to Summarize Decisions in Spoken Meetings", "author": ["Raquel Fern\u00e1ndez", "Matthew Frampton", "John Dowding", "Anish Adukuzhiyil", "Patrick Ehlen", "Stanley Peters."], "venue": "INTERSPEECH. pages 78\u201381.", "citeRegEx": "Fern\u00e1ndez et al\\.,? 2008", "shortCiteRegEx": "Fern\u00e1ndez et al\\.", "year": 2008}, {"title": "A Skip-chain Conditional Random Field for Ranking Meeting Utterances by Importance", "author": ["Michel Galley."], "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics,", "citeRegEx": "Galley.,? 2006", "shortCiteRegEx": "Galley.", "year": 2006}, {"title": "Analyzing Argumentative Discourse Units in Online Interactions", "author": ["Debanjan Ghosh", "Smaranda Muresan", "Nina Wacholder", "Mark Aakhus", "Matthew Mitsui."], "venue": "Proceedings of the First Workshop on Argumentation Mining. pages 39\u201348.", "citeRegEx": "Ghosh et al\\.,? 2014", "shortCiteRegEx": "Ghosh et al\\.", "year": 2014}, {"title": "A Global Optimization Framework for Meeting Summarization", "author": ["Dan Gillick", "Korbinian Riedhammer", "Benoit Favre", "Dilek Hakkani-Tur."], "venue": "Acoustics, Speech and Signal Processing, 2009.", "citeRegEx": "Gillick et al\\.,? 2009", "shortCiteRegEx": "Gillick et al\\.", "year": 2009}, {"title": "IEEE International Conference on", "author": ["ICASSP"], "venue": "IEEE, pages 4769\u20134772.", "citeRegEx": "ICASSP,? 2009", "shortCiteRegEx": "ICASSP", "year": 2009}, {"title": "Towards Automatic Argument Diagramming of Multiparity Meetings", "author": ["Dilek Hakkani-Tur."], "venue": "Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on. IEEE, pages 4753\u20134756.", "citeRegEx": "Hakkani.Tur.,? 2009", "shortCiteRegEx": "Hakkani.Tur.", "year": 2009}, {"title": "HILDA: A Discourse Parser Using Support Vector Machine Classification", "author": ["Hugo Hernault", "Helmut Prendinger", "David A. duVerle", "Mitsuru Ishizuka."], "venue": "Dialogue & Discourse 1(3):1\u201333.", "citeRegEx": "Hernault et al\\.,? 2010", "shortCiteRegEx": "Hernault et al\\.", "year": 2010}, {"title": "The ICSI Meeting Corpus", "author": ["Adam Janin", "Don Baron", "Jane Edwards", "Dan Ellis", "David Gelbart", "Nelson Morgan", "Barbara Peskin", "Thilo Pfau", "Elizabeth Shriberg", "Andreas Stolcke"], "venue": "In Acoustics, Speech, and Signal Processing,", "citeRegEx": "Janin et al\\.,? \\Q2003\\E", "shortCiteRegEx": "Janin et al\\.", "year": 2003}, {"title": "A Latent Variable Recurrent Neural Network for Discourse-Driven Language Models", "author": ["Yangfeng Ji", "Gholamreza Haffari", "Jacob Eisenstein."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for", "citeRegEx": "Ji et al\\.,? 2016", "shortCiteRegEx": "Ji et al\\.", "year": 2016}, {"title": "Recurrent Convolutional Neural Networks for Discourse Compositionality", "author": ["Nal Kalchbrenner", "Phil Blunsom."], "venue": "Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality. Association for Computational Linguis-", "citeRegEx": "Kalchbrenner and Blunsom.,? 2013", "shortCiteRegEx": "Kalchbrenner and Blunsom.", "year": 2013}, {"title": "Improving Team\u2019s Consistency of Understanding in Meetings", "author": ["Joseph Kim", "Julie A Shah."], "venue": "IEEE Transactions on Human-Machine Systems 46(5):625\u2013637.", "citeRegEx": "Kim and Shah.,? 2016", "shortCiteRegEx": "Kim and Shah.", "year": 2016}, {"title": "Visualizing Argumentation: Software Tools for Collaborative and Educational Sense-making", "author": ["Paul A Kirschner", "Simon J Buckingham-Shum", "Chad S Carr."], "venue": "Springer Science & Business Media.", "citeRegEx": "Kirschner et al\\.,? 2012", "shortCiteRegEx": "Kirschner et al\\.", "year": 2012}, {"title": "Accurate Unlexicalized Parsing", "author": ["Dan Klein", "Christopher D. Manning."], "venue": "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1. Association for Computational Linguistics, Stroudsburg, PA, USA, ACL", "citeRegEx": "Klein and Manning.,? 2003", "shortCiteRegEx": "Klein and Manning.", "year": 2003}, {"title": "Automatic Evaluation of Summaries Using N-gram Cooccurrence Statistics", "author": ["Chin-Yew Lin", "Eduard Hovy."], "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Hu-", "citeRegEx": "Lin and Hovy.,? 2003", "shortCiteRegEx": "Lin and Hovy.", "year": 2003}, {"title": "Using Spoken Utterance Compression for Meeting Summarization: A Pilot Study", "author": ["Fei Liu", "Yang Liu."], "venue": "Spoken Language Technology Workshop (SLT), 2010 IEEE. IEEE, pages 37\u201342.", "citeRegEx": "Liu and Liu.,? 2010", "shortCiteRegEx": "Liu and Liu.", "year": 2010}, {"title": "Unsupervised Approaches for Automatic Keyword Extraction Using Meeting Transcripts", "author": ["Feifan Liu", "Deana Pennell", "Fei Liu", "Yang Liu."], "venue": "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American", "citeRegEx": "Liu et al\\.,? 2009", "shortCiteRegEx": "Liu et al\\.", "year": 2009}, {"title": "Mining quality phrases from massive text corpora", "author": ["Jialu Liu", "Jingbo Shang", "Chi Wang", "Xiang Ren", "Jiawei Han."], "venue": "Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data. ACM, pages 1729\u20131744.", "citeRegEx": "Liu et al\\.,? 2015", "shortCiteRegEx": "Liu et al\\.", "year": 2015}, {"title": "Building a Dataset for Summarization and Keyword Extraction from Emails", "author": ["Vanessa Loza", "Shibamouli Lahiri", "Rada Mihalcea", "Po-Hsiang Lai."], "venue": "LREC. pages 2441\u20132446.", "citeRegEx": "Loza et al\\.,? 2014", "shortCiteRegEx": "Loza et al\\.", "year": 2014}, {"title": "Using Question-answer Pairs in Extractive Summarization of Email Conversations", "author": ["Kathleen McKeown", "Lokesh Shrestha", "Owen Rambow."], "venue": "International Conference on Intelligent Text Processing and Computational Linguistics. Springer, pages", "citeRegEx": "McKeown et al\\.,? 2007", "shortCiteRegEx": "McKeown et al\\.", "year": 2007}, {"title": "Abstractive Summarization of Spoken and Written Conversations Based on Phrasal Queries", "author": ["Yashar Mehdad", "Giuseppe Carenini", "Raymond T. Ng."], "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguis-", "citeRegEx": "Mehdad et al\\.,? 2014", "shortCiteRegEx": "Mehdad et al\\.", "year": 2014}, {"title": "Sociocultural Discourse Analysis", "author": ["Neil Mercer."], "venue": "Journal of applied linguistics 1(2):137\u2013168.", "citeRegEx": "Mercer.,? 2004", "shortCiteRegEx": "Mercer.", "year": 2004}, {"title": "Assessing Group Learning and Shared Understanding in Technology-mediated Interaction", "author": ["Ingrid Mulder", "Janine Swaak", "Joseph Kessels."], "venue": "Educational Technology & Society 5(1):35\u201347.", "citeRegEx": "Mulder et al\\.,? 2002", "shortCiteRegEx": "Mulder et al\\.", "year": 2002}, {"title": "Generating and Validating Abstracts of Meeting Conversations: A User Study", "author": ["Gabriel Murray", "Giuseppe Carenini", "Raymond Ng."], "venue": "Proceedings of the 6th International Natural Language Generation Conference. Association for Computational Linguis-", "citeRegEx": "Murray et al\\.,? 2010", "shortCiteRegEx": "Murray et al\\.", "year": 2010}, {"title": "Incorporating Speaker and Discourse Features into Speech Summarization", "author": ["Gabriel Murray", "Steve Renals", "Jean Carletta", "Johanna Moore."], "venue": "Proceedings of the main conference on Human Language Technology Conference of the North Amer-", "citeRegEx": "Murray et al\\.,? 2006", "shortCiteRegEx": "Murray et al\\.", "year": 2006}, {"title": "High Frequency Word Entrainment in Spoken Dialogue", "author": ["Ani Nenkova", "Agustin Gravano", "Julia Hirschberg."], "venue": "Proceedings of the 46th annual meeting of the association for computational linguistics", "citeRegEx": "Nenkova et al\\.,? 2008", "shortCiteRegEx": "Nenkova et al\\.", "year": 2008}, {"title": "Extractive Summarization and Dialogue Act Modeling on Email Threads: An Integrated Probabilistic Approach", "author": ["Tatsuro Oya", "Giuseppe Carenini."], "venue": "15th Annual Meeting of the Special Interest Group on Discourse and Dialogue. page 133.", "citeRegEx": "Oya and Carenini.,? 2014", "shortCiteRegEx": "Oya and Carenini.", "year": 2014}, {"title": "Integer Linear Programming for Discourse Parsing", "author": ["J\u00e9r\u00e9my Perret", "Stergos Afantenos", "Nicholas Asher", "Mathieu Morey."], "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human", "citeRegEx": "Perret et al\\.,? 2016", "shortCiteRegEx": "Perret et al\\.", "year": 2016}, {"title": "Long Story Short - Global Unsupervised Models for Keyphrase Based Meeting Summarization", "author": ["Korbinian Riedhammer", "Benoit Favre", "Dilek Hakkani-T\u00fcr."], "venue": "Speech Commun. 52(10):801\u2013815.", "citeRegEx": "Riedhammer et al\\.,? 2010", "shortCiteRegEx": "Riedhammer et al\\.", "year": 2010}, {"title": "Argument Diagramming of Meeting Conversations", "author": ["Rutger Rienks", "Dirk Heylen", "E. van der Weijden."], "venue": "A. Vinciarelli and J-M. Odobez, editors, International Workshop on Multimodal Multiparty Meeting Processing, MMMP 2005, part of the 7th", "citeRegEx": "Rienks et al\\.,? 2005", "shortCiteRegEx": "Rienks et al\\.", "year": 2005}, {"title": "Samplerank: Training Factor Graphs with Atomic Gradients", "author": ["Khashayar Rohanimanesh", "Kedar Bellare", "Aron Culotta", "Andrew McCallum", "Michael L Wick."], "venue": "Proceedings of the 28th International Conference on Machine Learning (ICML-", "citeRegEx": "Rohanimanesh et al\\.,? 2011", "shortCiteRegEx": "Rohanimanesh et al\\.", "year": 2011}, {"title": "Dependency Parsing by Belief Propagation", "author": ["David A Smith", "Jason Eisner."], "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, pages 145\u2013156.", "citeRegEx": "Smith and Eisner.,? 2008", "shortCiteRegEx": "Smith and Eisner.", "year": 2008}, {"title": "Dialogue Act Modeling for Automatic Tagging and Recognition", "author": ["Andreas Stolcke", "Klaus Ries", "Noah Coccaro", "Elizabeth Shriberg", "Rebecca Bates", "Daniel Jurafsky", "Paul Taylor", "Rachel Martin", "Carol Van Ess-Dykema", "Marie Meteer"], "venue": null, "citeRegEx": "Stolcke et al\\.,? \\Q2000\\E", "shortCiteRegEx": "Stolcke et al\\.", "year": 2000}, {"title": "Focused Meeting Summarization via Unsupervised Relation Extraction", "author": ["Lu Wang", "Claire Cardie."], "venue": "Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue. Association for Computational Linguistics,", "citeRegEx": "Wang and Cardie.,? 2012", "shortCiteRegEx": "Wang and Cardie.", "year": 2012}, {"title": "DomainIndependent Abstract Generation for Focused Meeting Summarization", "author": ["Lu Wang", "Claire Cardie."], "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). Associ-", "citeRegEx": "Wang and Cardie.,? 2013", "shortCiteRegEx": "Wang and Cardie.", "year": 2013}], "referenceMentions": [{"referenceID": 16, "context": "Previous work (Kirschner et al., 2012) has shown that discourse structure can be used to capture the main discussion points and arguments put forward during problem-solving and decision-making processes in meetings.", "startOffset": 14, "endOffset": 38}, {"referenceID": 33, "context": "course structure based on the Twente Argumentation Schema (TAS) by Rienks et al. (2005), which focuses on argumentative discourse information.", "startOffset": 67, "endOffset": 88}, {"referenceID": 28, "context": "To date, most efforts to leverage discourse information to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier training (Murray et al., 2006; Galley, 2006; McKeown et al., 2007; Bui et al., 2009).", "startOffset": 199, "endOffset": 274}, {"referenceID": 6, "context": "To date, most efforts to leverage discourse information to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier training (Murray et al., 2006; Galley, 2006; McKeown et al., 2007; Bui et al., 2009).", "startOffset": 199, "endOffset": 274}, {"referenceID": 23, "context": "To date, most efforts to leverage discourse information to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier training (Murray et al., 2006; Galley, 2006; McKeown et al., 2007; Bui et al., 2009).", "startOffset": 199, "endOffset": 274}, {"referenceID": 1, "context": "To date, most efforts to leverage discourse information to detect salient content from dialogues have focused on encoding gold-standard discourse relations as features for use in classifier training (Murray et al., 2006; Galley, 2006; McKeown et al., 2007; Bui et al., 2009).", "startOffset": 199, "endOffset": 274}, {"referenceID": 31, "context": "However, automatic discourse parsing in dialogues is still a challenging problem (Perret et al., 2016).", "startOffset": 81, "endOffset": 102}, {"referenceID": 33, "context": "Specifically, we utilize argumentative discourse relations as defined in Twente Argument Schema (TAS) (Rienks et al., 2005),", "startOffset": 102, "endOffset": 123}, {"referenceID": 38, "context": "We envision that the extracted salient phrases by our model can be used as input to abstractive meeting summarization systems (Wang and Cardie, 2013; Mehdad et al., 2014).", "startOffset": 126, "endOffset": 170}, {"referenceID": 24, "context": "We envision that the extracted salient phrases by our model can be used as input to abstractive meeting summarization systems (Wang and Cardie, 2013; Mehdad et al., 2014).", "startOffset": 126, "endOffset": 170}, {"referenceID": 12, "context": ", 2006) and the ICSI corpus (Janin et al., 2003).", "startOffset": 28, "endOffset": 48}, {"referenceID": 18, "context": "Results evaluated by ROUGE (Lin and Hovy, 2003) demonstrate that our system summaries obtain a ROUGE-SU4 F1 score of 21.", "startOffset": 27, "endOffset": 47}, {"referenceID": 18, "context": "Results evaluated by ROUGE (Lin and Hovy, 2003) demonstrate that our system summaries obtain a ROUGE-SU4 F1 score of 21.3 on AMI corpus, which outperforms non-trivial extractive summarization baselines and a keyword selection algorithm proposed in Liu et al. (2009).", "startOffset": 28, "endOffset": 266}, {"referenceID": 26, "context": "Moreover, since both content and discourse structure are critical for building shared understanding among participants (Mulder et al., 2002; Mercer, 2004), we further investigate whether our learned model can be utilized to predict the consistency among team members\u2019 understanding of", "startOffset": 119, "endOffset": 154}, {"referenceID": 25, "context": "Moreover, since both content and discourse structure are critical for building shared understanding among participants (Mulder et al., 2002; Mercer, 2004), we further investigate whether our learned model can be utilized to predict the consistency among team members\u2019 understanding of", "startOffset": 119, "endOffset": 154}, {"referenceID": 15, "context": "This task is first defined as consistency of understanding (COU) prediction by Kim and Shah (2016), who have labeled a portion of AMI discussions with consistency or inconsistency labels.", "startOffset": 79, "endOffset": 99}, {"referenceID": 15, "context": "the-art results (Kim and Shah, 2016) (F1: 63.", "startOffset": 16, "endOffset": 36}, {"referenceID": 23, "context": "reliant on features derived from gold-standard discourse labels (McKeown et al., 2007; Murray et al., 2010; Bokaei et al., 2016).", "startOffset": 64, "endOffset": 128}, {"referenceID": 27, "context": "reliant on features derived from gold-standard discourse labels (McKeown et al., 2007; Murray et al., 2010; Bokaei et al., 2016).", "startOffset": 64, "endOffset": 128}, {"referenceID": 0, "context": "reliant on features derived from gold-standard discourse labels (McKeown et al., 2007; Murray et al., 2010; Bokaei et al., 2016).", "startOffset": 64, "endOffset": 128}, {"referenceID": 6, "context": "tions, are found to frequently appear in meeting summaries together and thus are utilized to extract summary-worthy utterances by Galley (2006). There is much less work that jointly predicts the importance of content along with the discourse structure in dialogus.", "startOffset": 130, "endOffset": 144}, {"referenceID": 6, "context": "tions, are found to frequently appear in meeting summaries together and thus are utilized to extract summary-worthy utterances by Galley (2006). There is much less work that jointly predicts the importance of content along with the discourse structure in dialogus. Oya and Carenini (2014) employs Dynamic Conditional Random Field to recognize sentences in email threads for use in summary as well as their dialogue acts.", "startOffset": 130, "endOffset": 289}, {"referenceID": 5, "context": "Due to the noisy nature of dialogues, recent work focuses on identifying summary-worthy phrases from meetings (Fern\u00e1ndez et al., 2008; Riedhammer et al., 2010) or email threads (Loza", "startOffset": 110, "endOffset": 159}, {"referenceID": 32, "context": "Due to the noisy nature of dialogues, recent work focuses on identifying summary-worthy phrases from meetings (Fern\u00e1ndez et al., 2008; Riedhammer et al., 2010) or email threads (Loza", "startOffset": 110, "endOffset": 159}, {"referenceID": 36, "context": "significant amount of work has been done in predicting local discourse structures, such as recognizing dialogue acts or social acts of adjacent utterances from phone conversations (Stolcke et al., 2000; Kalchbrenner and Blunsom, 2013; Ji et al., 2016), spoken meetings (Dielmann and Renals,", "startOffset": 180, "endOffset": 251}, {"referenceID": 14, "context": "significant amount of work has been done in predicting local discourse structures, such as recognizing dialogue acts or social acts of adjacent utterances from phone conversations (Stolcke et al., 2000; Kalchbrenner and Blunsom, 2013; Ji et al., 2016), spoken meetings (Dielmann and Renals,", "startOffset": 180, "endOffset": 251}, {"referenceID": 13, "context": "significant amount of work has been done in predicting local discourse structures, such as recognizing dialogue acts or social acts of adjacent utterances from phone conversations (Stolcke et al., 2000; Kalchbrenner and Blunsom, 2013; Ji et al., 2016), spoken meetings (Dielmann and Renals,", "startOffset": 180, "endOffset": 251}, {"referenceID": 3, "context": "2008), or emails (Cohen et al., 2004).", "startOffset": 17, "endOffset": 37}, {"referenceID": 7, "context": "Although discourse information from non-adjacent turns has been studied in the context of online discussion forums (Ghosh et al., 2014) and meetings (HakkaniTur, 2009), none of them models the effect of dis-", "startOffset": 115, "endOffset": 135}, {"referenceID": 33, "context": "In this work, we consider the argumentative discourse structure by Twente Argument Schema (TAS) (Rienks et al., 2005).", "startOffset": 96, "endOffset": 117}, {"referenceID": 33, "context": "Following previous work on discourse analysis in meetings (Rienks et al., 2005; Hakkani-Tur, 2009), we assume that the attachment structure between discourse units are given during both training and testing.", "startOffset": 58, "endOffset": 98}, {"referenceID": 10, "context": "Following previous work on discourse analysis in meetings (Rienks et al., 2005; Hakkani-Tur, 2009), we assume that the attachment structure between discourse units are given during both training and testing.", "startOffset": 58, "endOffset": 98}, {"referenceID": 17, "context": "obtain constituent and dependency parses for utterances using Stanford parser (Klein and Manning, 2003).", "startOffset": 78, "endOffset": 103}, {"referenceID": 21, "context": "Other methods for mining candidate phrases, such as frequency-based method (Liu et al., 2015), will be studied for future work.", "startOffset": 75, "endOffset": 93}, {"referenceID": 34, "context": "For learning the model parameters w, we employ an algorithm based on SampleRank (Rohanimanesh et al., 2011), which is a stochastic structure learning method.", "startOffset": 80, "endOffset": 107}, {"referenceID": 35, "context": "Message-passing (Smith and Eisner, 2008) is used to find the best d.", "startOffset": 16, "endOffset": 40}, {"referenceID": 5, "context": "based on the intuition that important phrases tend to have more content words with high TF-IDF scores (Fern\u00e1ndez et al., 2008).", "startOffset": 102, "endOffset": 126}, {"referenceID": 37, "context": "work (Wang and Cardie, 2012) has found that a discussion usually ends with decision-relevant information.", "startOffset": 5, "endOffset": 28}, {"referenceID": 10, "context": "whether there is any adjacency pair held between the two nodes (Hakkani-Tur, 2009), and the Jaccard similarity between them.", "startOffset": 63, "endOffset": 82}, {"referenceID": 12, "context": ", 2006) and the ICSI meeting corpus (Janin et al., 2003).", "startOffset": 36, "endOffset": 56}, {"referenceID": 33, "context": "relations based on Twente Argumentation Schema (TAS) by Rienks et al. (2005)4.", "startOffset": 56, "endOffset": 77}, {"referenceID": 5, "context": "ings (Fern\u00e1ndez et al., 2008; Wang and Cardie, 2013) and discourse parsing for formal text (Hernault et al.", "startOffset": 5, "endOffset": 52}, {"referenceID": 38, "context": "ings (Fern\u00e1ndez et al., 2008; Wang and Cardie, 2013) and discourse parsing for formal text (Hernault et al.", "startOffset": 5, "endOffset": 52}, {"referenceID": 11, "context": ", 2008; Wang and Cardie, 2013) and discourse parsing for formal text (Hernault et al., 2010).", "startOffset": 69, "endOffset": 92}, {"referenceID": 13, "context": "5 We also compare with a state-of-the-art discourse parser (Ji et al., 2016), which employs neural language model to predict discourse relations.", "startOffset": 59, "endOffset": 76}, {"referenceID": 13, "context": "8 Ji et al. (2016) 54.", "startOffset": 2, "endOffset": 19}, {"referenceID": 13, "context": "Our models that significantly outperform SVM-based model and Ji et al. (2016) are highlighted with \u2217 (p < 0.", "startOffset": 61, "endOffset": 78}, {"referenceID": 13, "context": "Our joint learning model with separate inference also outperforms neural network-based discourse parsing model (Ji et al., 2016) in Table 2.", "startOffset": 111, "endOffset": 128}, {"referenceID": 20, "context": "8 Liu et al. (2009) 62.", "startOffset": 2, "endOffset": 20}, {"referenceID": 20, "context": "4 Liu et al. (2009) 62.", "startOffset": 2, "endOffset": 20}, {"referenceID": 20, "context": "Our models that statistically significantly outperform SVM and Liu et al. (2009) are highlighted with \u2217 (p < 0.", "startOffset": 63, "endOffset": 81}, {"referenceID": 18, "context": "We calculate scores based on ROUGE (Lin and Hovy, 2003), which is a popular tool for evaluating text summarization (Gillick et al.", "startOffset": 35, "endOffset": 55}, {"referenceID": 8, "context": "We calculate scores based on ROUGE (Lin and Hovy, 2003), which is a popular tool for evaluating text summarization (Gillick et al., 2009; Liu and Liu, 2010).", "startOffset": 115, "endOffset": 156}, {"referenceID": 19, "context": "We calculate scores based on ROUGE (Lin and Hovy, 2003), which is a popular tool for evaluating text summarization (Gillick et al., 2009; Liu and Liu, 2010).", "startOffset": 115, "endOffset": 156}, {"referenceID": 32, "context": "Following previous work on meeting summarization (Riedhammer et al., 2010; Wang and Cardie, 2013), we consider two dialogue act-level summarization baselines: (1)", "startOffset": 49, "endOffset": 97}, {"referenceID": 38, "context": "Following previous work on meeting summarization (Riedhammer et al., 2010; Wang and Cardie, 2013), we consider two dialogue act-level summarization baselines: (1)", "startOffset": 49, "endOffset": 97}, {"referenceID": 20, "context": "We also compare with an unsupervised keyword extraction approach by Liu et al. (2009),", "startOffset": 68, "endOffset": 86}, {"referenceID": 20, "context": "With the same candidate phrases as in our model, we extend Liu et al. (2009) by scoring each phrase based on its average score of", "startOffset": 59, "endOffset": 77}, {"referenceID": 20, "context": "Compared to Liu et al. (2009), our system also yields better results on all metrics.", "startOffset": 12, "endOffset": 30}, {"referenceID": 26, "context": "As discussed in previous work (Mulder et al., 2002; Mercer, 2004), both content and discourse structure are critical for building shared understanding among discussants.", "startOffset": 30, "endOffset": 65}, {"referenceID": 25, "context": "As discussed in previous work (Mulder et al., 2002; Mercer, 2004), both content and discourse structure are critical for building shared understanding among discussants.", "startOffset": 30, "endOffset": 65}, {"referenceID": 15, "context": "as consistency of understanding (COU) in Kim and Shah (2016).", "startOffset": 41, "endOffset": 61}, {"referenceID": 29, "context": "The third feature is based on word entrainment, which has been shown to correlate with task success for groups (Nenkova et al., 2008).", "startOffset": 111, "endOffset": 133}, {"referenceID": 29, "context": "The third feature is based on word entrainment, which has been shown to correlate with task success for groups (Nenkova et al., 2008). Using the formula in Nenkova et al. (2008), we compute the average word entrainment between the main speaker who utters the most words and all the other participants.", "startOffset": 112, "endOffset": 178}, {"referenceID": 15, "context": "Finally, we compare with the state-of-the-art method in Kim and Shah (2016),", "startOffset": 56, "endOffset": 76}, {"referenceID": 15, "context": "6 Kim and Shah (2016) 60.", "startOffset": 2, "endOffset": 22}, {"referenceID": 15, "context": "Results that statistically significantly outperform ngrams-based baseline and Kim and Shah (2016) are highlighted with \u2217 (p < 0.", "startOffset": 78, "endOffset": 98}, {"referenceID": 15, "context": "Especially, the discourse features, word entrainment feature, and the combination of the three, all significantly outperform the state-of-theart system by Kim and Shah (2016).6", "startOffset": 155, "endOffset": 175}], "year": 2017, "abstractText": "We present a joint modeling approach to identify salient discussion points in spoken meetings as well as to label the discourse relations between speaker turns. A variation of our model is also discussed when discourse relations are treated as latent variables. Experimental results on two popular meeting corpora show that our joint model can outperform state-of-the-art approaches for both phrasebased content selection and discourse relation prediction tasks. We also evaluate our model on predicting the consistency among team members\u2019 understanding of their group decisions. Classifiers trained with features constructed from our model achieve significant better predictive performance than the state-of-the-art.", "creator": "LaTeX with hyperref package"}}}