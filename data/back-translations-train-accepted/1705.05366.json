{"id": "1705.05366", "review": {"conference": "ICML", "VERSION": "v1", "DATE_OF_SUBMISSION": "15-May-2017", "title": "Maximum Selection and Ranking under Noisy Comparisons", "abstract": "We consider $(\\epsilon,\\delta)$-PAC maximum-selection and ranking for general probabilistic models whose comparisons probabilities satisfy strong stochastic transitivity and stochastic triangle inequality. Modifying the popular knockout tournament, we propose a maximum-selection algorithm that uses $\\mathcal{O}\\left(\\frac{n}{\\epsilon^2}\\log \\frac{1}{\\delta}\\right)$ comparisons, a number tight up to a constant factor. We then derive a general framework that improves the performance of many ranking algorithms, and combine it with merge sort and binary search to obtain a ranking algorithm that uses $\\mathcal{O}\\left(\\frac{n\\log n (\\log \\log n)^3}{\\epsilon^2}\\right)$ comparisons for any $\\delta\\ge\\frac1n$, a number optimal up to a $(\\log \\log n)^3$ factor.", "histories": [["v1", "Mon, 15 May 2017 17:59:17 GMT  (49kb)", "http://arxiv.org/abs/1705.05366v1", null]], "reviews": [], "SUBJECTS": "cs.LG", "authors": ["moein falahatgar", "alon orlitsky", "venkatadheeraj pichapati", "ananda theertha suresh"], "accepted": true, "id": "1705.05366"}, "pdf": {"name": "1705.05366.pdf", "metadata": {"source": "CRF", "title": "Maximum Selection and Ranking under Noisy Comparisons", "authors": ["Moein Falahatgar", "Alon Orlitsky", "Venkatadheeraj Pichapati", "Ananda Theertha Suresh"], "emails": ["moein@ucsd.edu", "alon@ucsd.edu", "dheerajpv7@ucsd.edu", "theertha@google.com"], "sections": [{"heading": null, "text": "ar Xiv: 170 5.05 366v 1 [cs.L G] 1 (n \u0445 2 log 1 \u03b4) comparisons, a number that is narrow up to a constant factor. We then derive a general framework that improves the performance of many ranking algorithms, and combine it with joint sorting and binary search to obtain a ranking algorithm that uses O (n logn (log logn) 3\u0445 2) comparisons for all \u03b4 \u2265 1 n, a number that is optimal up to a factor (log logn) 3."}, {"heading": "1 Introduction", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "1.1 Background", "text": "In fact, it is claimed that sorting, also known as ranking, uses 25% of computer cycles worldwide [2011].In many applications, the pairwise comparisons only lead to random results. Another important application is online advertising. Prominent websites devote precious little space to advertising, limiting companies such as Google, Microsoft or Yahoo! to present a typical user with only a few ads, of which the user selects at most one. Based on these small random comparisons, the company wants to rank the ads according to their appeal."}, {"heading": "1.2 Notation", "text": "The noiseless comparison assumes an unknown underlying ranking r (1),.., r (n) of the elements in such a way that, when comparing two elements, the higher ranked element is selected. Similarly, in noisy comparisons, we assume an unknown ranking of the n elements, but now, when comparing two elements i and j, i is chosen with an unknown probability p (i, j) and j with a probability p (j, i) = 1 \u2212 p (i, j), with the higher ranked element having a probability. Repeated comparisons are independent of each other. Let the maximum ranking p (i, j) = p (i, j) \u2212 12 reflect the additional probability with which i \u2212 p is preferred. Note that p (j) = \u2212 p (i, j) and p (i, j) and p (i, j) and p (i, j) reflect the additional probability with which i \u2212 p is preferred."}, {"heading": "1.3 Paper outline", "text": "In section 2 we mention somersaults. In section 3 we highlight our most important contributions. In section 4 we propose the maximum selection algorithm. In section 5 we propose the ranking algorithm. In section 6 we offer experiments. In section 7 we discuss the results and mention some future directions."}, {"heading": "2 Related work", "text": "Heckel et al. [2016], Urvoy et al. [2013], Busa-Fekete et al. [2014b, b] do not assume any underlying ranking or limitation of probabilities and find a ranking based on Copeland, Borda count and Random Walk procedures. Urvoy et al. [2013], Busa-Fekete et al. [2014b] showed that if the probabilities p (i, j) are not limited, both maximum selection and ranking problems require comparisons. Therefore, several models were taken into account to further limit the probabilities. Under the assumptions of strong stochastic transitivity and triangle inequality, Yue & Joachims [2011] derived a PAC maximum selection algorithm that usesO (n, 2 log n, n) comparisons problems. Szo re, nyi et al al. [2014b] derived a PAC ranking algorithm for the PO-request model."}, {"heading": "3 New results", "text": "Remember that we are studying the PAC model for the problems of maximum online selection and ranking using pair-by-pair comparisons under strong stochastic transitivity and stochastic triangular inequalities assumptions. The goal is to find algorithms that use a small number of comparisons. Our most important contributions are: \u2022 A maximum selection algorithm that uses comparisons with O (n (logn) 3o (logn) 3o (logn) 2o (logn) 2o (logn) 2o (logn) 2o (logn) 2), so that our algorithm is optimal up to constants. \u2022 A frame that provides any ranking algorithm with O (n (logn) xn (logn) 2o (log logn) 2o (log logn) 2o (log logn) 2o (log) 2o (log) Samplexxxxn). \u2022 Using the above frame, we present an algorithm that compares at most logn (O) 3o (log) 3o (and 3n) numbers."}, {"heading": "4 Maximum selection", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "4.1 Algorithm outline", "text": "We propose a simple maximum selection algorithm based on knockout tournaments. Knockout tournaments are often used to find a maximum element among non-noisy comparisons. Knockout tournaments of n elements run in \"log n\" rounds, in which they randomly pair the remaining elements in each round and advance the winners to the next round. Our algorithm, which is specified in \"Knockout,\" uses O (n) comparisons and O (n) memory to find a maximum number of comparisons. Yue & Joachims [2011] uses O (n) comparisons and O (n2) memory to find a maximum number of comparisons. Therefore, we get log n factor improvement in the number of comparisons, and also we get linear memory compared to square memory. Using the lower limit in \"fig et al.\" [1994] one can conclude that the best PAC selection algorithm requires maximum comparisons, i.e. comparisons to a constant factor."}, {"heading": "4.2 Algorithm", "text": "We start with a subroutine that compares two elements. It compares two elements i, j and gets empirical probabilities p, i, j, a proxy for p (i, j). It also keeps a confidential c, s.t., w.h.p, p, i (p (i, j) \u2212 c, p (i, j) + c). We show that the subroutine comparison always returns the correct winner if the elements are well separated from each other. Algorithm 1 ComprareInput: element i, element j, bias, confidence. Starting point: p, i = 1 2, c, c, c = 2, m = 2 log 2, p = 0, wi = 0,1. while (p, i \u2212 1,.c, bias, confidence.) ComprareInput: element i = 1, c, bias, confidence."}, {"heading": "4.2.1 Knockout-Round", "text": "Knockout-Round takes a set S and prints a set size | S | / 2. It pairs random elements, compares each pair with comparisons and returns the set of winners. We will show later that the maximum element in the output set is comparable to the maximum element in the input set. Algorithm 2 Knockout-Round Input: Set S, Bias, Confidence \u03b4. Initialize: Set O = \u2205 1. Pair elements in S random. 2. for each pair (a, b): (a) Add Compare (a, b, B, B) to O."}, {"heading": "Output: O", "text": "Note that comparisons between the individual pairs can be made by another processor, and therefore this algorithm can be easily parallelized. Note that a set of S can have several maximum elements. Comparison probabilities corresponding to all maximum elements will be essentially the same due to triangular inequality. We define max (S) as the maximum element with the lowest index, namely max (S) def = S (min {i: p (S (i), S (j)) \u2265 0-j}). Lemma 2. Knockout Round (S, B, E) uses | S | 4,000 2 log 2 \u03b4 Comparisons and with a probability of \u2265 1 \u2212 \u043c, p (max (S), max (Knockout Round (S, E, E)) \u2264)."}, {"heading": "4.2.2 Knockout", "text": "Now we introduce the main Knockout algorithm. Knockout takes an input quantity S and performs logs of knockout rounds that halve the size of S at the end of each round. Remember that Knockout Round ensures that the maximum element in the output quantity is comparable to the maximum element in the input quantity, thereby ensuring that the output element is comparable to the maximum element in the output quantity in the last rounds. As the size of S is halved after each round, Knockout compares each pair several times in the last rounds. Therefore, the bias between the maximum element in the input quantity and the maximum element in the output quantity in the last rounds is low. Algorithm 3 Knockout Round: Set S, Bias, Confidence, Confidence, Stochasticity. Starting point: i = 1, S = Set of all elements, c = 21 / 3 \u2212 1. during | S | > 11. S = Knockout Round (cample, 2nd: 2i / 2i, 2i) and the Knockout (the edition of Knockout 3)."}, {"heading": "5 Ranking", "text": "We propose a ranking algorithm that makes comparisons with O (n logn (log logn) 3 > 2) with a probability of at least 1 \u2212 1n and prints a ranking order. Note that we only use comparisons with O (n logn) 2 for \u03b4 = 1n, these guarantees being only available under the Plackett Luce model, which is more restrictive than ours. Also, your algorithm uses O (n) memory compared to O (n) storage requirements of our time. Our main binary search ranking algorithm then assumes the existence of a ranking algorithm Rank-x that works with a probability of at least 1 \u2212 3."}, {"heading": "5.1 Merge Ranking", "text": "We present a simple ranking algorithm, Merge-Rank, which uses O (n (logn) 3,000 errors, O (n) memory, and with a probability \u2265 1 \u2212 \u03b4 a ranking. Therefore, Merge-Rank is a rank x algorithm for x = 3. Similar to Merge-Rank, Merge-Rank splits the elements into two sets of the same size, classifies them separately, and combines the sorted arrays. Due to the noisy nature of the comparisons, Merge-Rank compares two elements i, j sufficiently often, so that the comparison output is highly likely correct when the merge-Rank is merged with a high probability. In other words, Merge-Rank is the same as the typical merge sort, unless it uses Compare as a comparison function. Let's define the error of an ordered group S as the maximum distance between two wrongly ordered elements in S, err (S) def = max.1."}, {"heading": "5.2 Binary-Search-Ranking", "text": "We first sketch the sketch of the algorithm below and then provide a sketch of the evidence."}, {"heading": "5.2.1 Algorithm outline", "text": "Our algorithm is listed in Binary Search Ranking. It can be summarized in three broad parts: (Steps 1 to 3) Binary Search Ranking first selects a series of n (logn) x random elements (anchors) and ranks them by rank x. (Step 4) At the end of this part there are (logn) x ranked anchors. (Step 4) After forming the bins, the algorithm uses a random walk on a binary search tree to find out which element belongs to Interval Binary Search. (Interval Binary Search is similar to the noisy binary search algorithms in Fig et al. (1994) It builds a binary search tree with the bins and does a random walk over that tree."}, {"heading": "5.2.2 Analysis of Binary-Search-Ranking", "text": "In step 1 of the algorithm, we select n / (log n) x x random elements. As they are chosen equally, they are almost uniformly in line S. This intuition is formalized in the next round when we select a series of n elements. If we select a series of n elements that are all equal, and build an ordered series of S elements that are all equal. (i), S element (i), S element (i), S element (j), then with a probability of 1-1 n4, for each case of 0 and all. (e) S: p (k) >, S \"s,\" S, \"S,\" S. \"(e) > Element 5 (log n) x + 1. In step 2, we use rank x to rank S.\" Lemma 6 shows the guarantee of ranking S. \"Lemma 6.\""}, {"heading": "6 Experiments", "text": "We compare the performance of our algorithms with that of others using simulated data. Similar to Yue-out & Joachims [2011], we look at the stochastic model in which p (i, j) = 0.6% i < j = 0.5%. Note that this model fulfills both the strong stochastic transitivity and the triangular inequality. We find 0.05-maximum with error probability \u03b4 = 0.1%. Note that i = 1 is the only maximum effect of Knockout with that of BTM-PAC Yue & Joachims [2011], MallowsMPI-Fekete et al. [2014a], and AR Heckel et al. [2016], BTM-PAC is an analogy of PAC algorithms for the same model considered in this paper. MallowsMPI finds a Condorcet winner that exists under our general model. AR finds the maximum results by Borda Scores."}, {"heading": "7 Conclusion", "text": "For maximum selection, we presented a simple algorithm with linear, i.e. optimal sample complexity. For ranking, we presented a framework that improves the performance of many ranking algorithms and applies it to ranking to derive a near-optimal ranking algorithm. We conducted several experiments and showed that our algorithms work well not only in theory, but also in practice. Furthermore, they exceeded all existing algorithms. Maximum selection experiments suggest that our algorithm works well even without the assumption of triangular inequality. It would be interesting to extend our theoretical guarantees to this case. For ranking, it would be interesting to conclude the (log n) 3 ratio between the upper and lower complexity limits."}, {"heading": "A Merge Ranking", "text": "We first introduce a subroutine used by Merge-Rank. It merges two ordered groups in the presence of loud comparisons."}, {"heading": "A.1 Merge", "text": "Merge takes two ordered sets S1 and S2 and outputs an ordered set Q by merging them. Merge begins by comparing the first elements in each set S1 and S2 and putting the loser in the first place of Q. It compares the two elements sufficiently often to ensure that the output is approximately accurate. Then it compares the winner and the element directly with the loser in the corresponding set. It continues this process until we run out of one of the sentences and then adds the remaining elements to the end of Q and the output of Q.Algorithm 6 MergeInput: sentences S1, S2, Default, Trust. Initialize: i = 1, j = 1 and O =.1. while i \u2264 | S1 | and j \u2264 | S2 |. (a), if S1 (i) = Compare (S1 (i), S2 (j), and at the end of S1 (i), then at the end of S1 (i)."}, {"heading": "Output: O.", "text": "We show that when we merge two ordered sentences with merge, the error of the resulting ordered set is not high compared to the maximum error of individual ordered sets. Lemma 16. With probability \u2265 1 \u2212 (| S1 | + | S2 |) \u03b4, the error of the merge (S1, S2,, \u03b4) is at best greater than the maximum error of S1 and S2. Namely, with probability \u2265 1 \u2212 (| S1 | + | S2 |) \u043c, err (merge (S1, S2, \u03b4) \u2264 max (err (S1), err (S2)) + \u0432."}, {"heading": "A.2 Merge-Rank", "text": "Now we introduce the algorithm Merge-Rank. Merge-Rank splits the input set S into two groups of size S1 and S2. It then orders S1 and S2 separately using Merge-Rank and combines the ordered records using Merge. Note that Merge-Rank is a recursive algorithm. Singleton records, each containing a unique element in S. First, merge two singleton records into a set of two elements, then merge the records containing two elements into a group of four elements, and henceforth. By Lemma 16, each merge with bound parameters adds the error at most. Since the error of singleton sets is 0 and each element participates in log n merges, the error of the output set is at most a log with four elements, and henceforth. Thus, the error of the output set is at most a log."}, {"heading": "B Algorithms for Ranking", "text": "Algorithm 8 Interval Binary Search Input: Arranged array S = search element e, search element e, default 1. T = Build Binary Search Tree (| S |).2. Set Q = \u2205, node \u03b1 = root (T) and count c = 0.3. Repeat 30 log n times (a) if \u03b12 \u2212 \u03b11 > 1, i. Add \u03b11, \u03b12 and \u03b11 + \u2032 2 to Q.ii. If you (S (\u03b11), e, 10 2) > 1 / 2 or Compare (e, S (\u03b12), 10 2) > 1 / 2 then return to parent \u03b1 = parent (\u03b1).iiii. Otherwise \u2022 if Compare (S (\u03b11 + \u03b12), e, 10 2 or Compare (\u03b1) > 1 / 2 i. \u2022 Binding goes back to parent \u03b1 = parent (\u03b1).ii."}, {"heading": "Output: T .", "text": "Algorithm 10 Binary search input: Ordered array S, ordered array Q, search element e, bias. Initialize: l = 1, h = | Q |.1. while h \u2212 l > 0 (a) t = Comapre (e, S (Q (l + h 2), 10 logn2). (b) if t [1 2 \u2212 3c, 1 2 + 3c], then output: Q (l + h 2). (c) Otherwise, if t < 12 \u2212 3c, then move to the right.l = l + h2. (d) Otherwise, move to the left. h = l + h2.Output: Q (h)."}, {"heading": "C Some tools for proving lemmas", "text": "s consider W = Compare (i, j,) and L as the other element. Then, with probability \u2265 1 \u2212 \u03b4, p (W, L) \u2265 12 \u2212 \u0432. Prove that if | p (i, j) | < then p (i, j) > 12 \u2212 \u0432 and p (j, i) > 1 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2 \u00b2."}, {"heading": "D Proofs of Section 4", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Lemma 1", "text": "Proof. Let p-ri and c-r p-i and c-r according to the number of comparisons respectively p-i and c-t. The output of the comparison (i, j, c-r) will not be only i if p-ri < 1 2 + c-r for any r < m = 1 2.02 log 2\u03b4 or if p-i < 1 2 for r = m. We will show that the probability of each of these events is limited by \u03b42. Therefore, Lemma follows union tie. After r-comparisons follows Pr (p-ri < 12 + c-r) \u2264 e-2r (c-r) 2 = e-log 4r2 \u043c = \u04324r2."}, {"heading": "Proof of Lemma 2", "text": "Proof. Each of the | S | 2 pairs is compared at most 1 2 x 2 x 2 x 2, so the total comparison is \u2264 | S | 4x 2 x 2 x 2. Leave k = max (knockout round (S, E, E) and s = max (S). Let a be the element paired with s *. There are two cases: p (s, A) and p (s, A) < If p (s, A). If p (s, A) of Lemma 1 is with a probability of 1 x 1, s * will win and therefore by definitions of s (s) and k (s), p (s, K) = 0. Alternatively, if p (s), a) < Let the winner (i, J) specify the winner (i, J) between i and j if he is for 12x 2 x (a) (s, k) = 1 x (s, a) (b) (n) (n), c), n (n), n ()."}, {"heading": "Proof of Theorem 3", "text": "The proof: We show first that the output of Knockout with a probability of \u2265 1 \u2212 \u03b4 is a maximum element in the sentence S before round i. then of Lemma 2, with the probability \u2265 1 \u2212 \u03b4i, p \u00b2 (bi, bi + 1) \u2264 c2 i / 3. (1) The probability that Equation 1 does not apply to some rounds is equation 1 \u2264 i \u2264 log | S | p \u00b2 i = 1\u03b4i = log | S | p \u00b2 i = 1\u043c 2i \u2264. With the probability 1 \u2212 \u03b4 equation 1 applies to all i and to stochastic triangular inequality p \u00b2 (b1, blog | S | + 1) \u2264 log | S | p \u00b2 i = 1p \u00b2 (bi, bi + 1) \u2264. Equation 1 applies to all i and to stochastic triangular inequality p \u00b2 (b1, blog | S | 1) \u2264 log | S | p \u00b2 i = 1p \u00b2 (bi, bi + 1)."}, {"heading": "E Proofs of Section 5.1", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Lemma 16", "text": "Proof: Leave Q = Merge (S1, S2, err (S2), err (S2), err (S2)), err (S2), err (S2), err (S2), err (S2), and err (S2). Note that if this property applies to each element, then err (Q) \u2264 max (err (S1), err (S2) + err (S2). Since there are elements in the final merged group S1 (i) and S2 (j), the lemma follows the composite boundary. If S1 (i) and S2 (j) are compared in the merge algorithm, without loss of universality, assume that S1 (i) loses, i.e. S1 (i) appears before S2 (j) in T. The elements to the right of S1 (i) and right of S1 (i), are in {Q (2), erk (S1) and Si (Sp)."}, {"heading": "Proof of Lemma 4", "text": "The proof: We first determined the total number of comparisons. Let C (Q, Q, E, E, E, E) determine the number of comparisons that the merge rank uses on a specified Q. Since merge rank is a recursive algorithm, C (Q, E, E, E, E, E) \u2264 C (Q, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E,"}, {"heading": "F Proofs for Section 5.2", "text": "It is not the first time that the EU Commission has taken such a step."}, {"heading": "Proof of Lemma 5", "text": "Proof. Let's set S so that the probability that none of the elements in S \u2032 \u2032 k will be selected for a given k is \u2264 (1 \u2212 5 (log n) x + 1n) n / (logn) x < 1n5. Therefore, the probability that none of the elements in S \u2032 \u2032 k will be selected for a given k is due to the bond \u2264 n \u00b7 1n5 = 1n4."}, {"heading": "Proof of Lemma 7", "text": "We prove Lemma 7 by dividing it into other smaller Lemmas. We divide all elements into two groups based on the distance from the anchors. The first group contains all elements that are far away from all the anchors, and the second group contains all elements that are close to at least one of the anchors. Interval binary search behaves differently on both levels. We first show that for the elements in the first group, the interval binary search places them between the right anchors by using only the random gear subroutine.For elements in the second group, interval binary search might not succeed in finding the right anchors by using the random gear subroutine. But we show that the interval binary search visits a nearby anchor and the binary search finds a narrow anchor from the group of visited anchors."}, {"heading": "Proof of Lemma 10", "text": "Evidence that the combination of Lemmas 6, 9 and the use of union bound, at the end of step 5a, w.p > 1 \u2212 2 n3, S. \"in the ranking and order of Lemma 18, j, j, e Bj, p (e, S (j)), p (S (j + 1), e) > 5. In the sequence of Lemma 18, j, k < j, e Bj, p (e, S (k)) > 5 (n) > 4 (k). Likewise, in the order of j, k > j, e Bj, p (k), p (S k), p (n) > Bj 0, then p (e, S (k) > 4 (k)."}, {"heading": "Proof of Theorem 12", "text": "We first set the runtime of the binary search ranking algorithm. \u2022 Theorem 24. Binary search ranking ends after O (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x (log logn) x) x (log logn) x x (log logn) x (log logn) x) x (log logn) x) x (log logn) x (log logn) x (log logn) x (log logn) x) x (log logn) x) x (log) x (log) x) x (log) x) x (log) x (log) x (log) x)."}, {"heading": "Proof Sketch for Theorem 15", "text": "Suppose there is a mind that knows the true ranking r up to the sentences {r (2i \u2212 1), r (2i)} for all i, i.e. for each i, the mind knows {r (2i \u2212 1), r (2i)}, but it does not know the ranking between these two elements. Since successive elements for all i (i, i + 1) = 2i > must be found in order to find such a ranking, the mind must correctly identify the ranking within all n / 2 pairs. Using the inequality of Fano from information theory, it can be shown that the genius needs at least comparisons to identify the ranking of the successive elements with the probability of 1 \u2212 2."}, {"heading": "G Additional Experiments", "text": "As we mentioned in Section 6, BTM-PAC allows the comparison of an element with itself. It is not advantageous if the goal is to find maximum performance, so we modify its algorithm by not allowing such comparisons. We refer to this limited version as R-BTM-PAC. As shown in the figure, the performance of BTM-PAC does not increase by much by limiting the comparisons. We reduce the constants in R-BTM-PAC. We change the equations (7) and (8) in Yue & Joachims [2011] to c3 (t) = 1 t log n3N \u03b4 and N = 1 log n3N. We believe that the same guarantees also apply to the updated constants. We refer to this improved limited version as IR-BTM-PAC. Again, we consider the stochastic model where p (i) = 0.6 nlog < and we find maximum error 0.5."}], "references": [{"title": "Sorting with adversarial comparators and application to density estimation", "author": ["Acharya", "Jayadev", "Jafarpour", "Ashkan", "Orlitsky", "Alon", "Suresh", "Ananda Theertha"], "venue": "In ISIT, pp. 1682\u20131686", "citeRegEx": "Acharya et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Acharya et al\\.", "year": 2014}, {"title": "Near-optimalsample estimators for spherical gaussian mixtures", "author": ["Acharya", "Jayadev", "Jafarpour", "Ashkan", "Orlitsky", "Alon", "Suresh", "Ananda Theertha"], "venue": null, "citeRegEx": "Acharya et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Acharya et al\\.", "year": 2014}, {"title": "Maximum selection and sorting with adversarial comparators and an application to density estimation", "author": ["Acharya", "Jayadev", "Falahatgar", "Moein", "Jafarpour", "Ashkan", "Orlitsky", "Alon", "Suresh", "Ananda Theertha"], "venue": "arXiv preprint arXiv:1606.02786,", "citeRegEx": "Acharya et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Acharya et al\\.", "year": 2016}, {"title": "Sorting and selection with imprecise comparisons", "author": ["Ajtai", "Mikl\u00f3s", "Feldman", "Vitaly", "Hassidim", "Avinatan", "Nelson", "Jelani"], "venue": "ACM Transactions on Algorithms (TALG),", "citeRegEx": "Ajtai et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Ajtai et al\\.", "year": 2015}, {"title": "Noisy sorting without resampling", "author": ["Braverman", "Mark", "Mossel", "Elchanan"], "venue": "In Proceedings of the nineteenth annual ACM-SIAM SODA,", "citeRegEx": "Braverman et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Braverman et al\\.", "year": 2008}, {"title": "Sorting from noisy information", "author": ["Braverman", "Mark", "Mossel", "Elchanan"], "venue": "arXiv preprint arXiv:0910.1191,", "citeRegEx": "Braverman et al\\.,? \\Q2009\\E", "shortCiteRegEx": "Braverman et al\\.", "year": 2009}, {"title": "Top-k selection based on adaptive sampling of noisy preferences", "author": ["Busa-Fekete", "R\u00f3bert", "Szorenyi", "Balazs", "Cheng", "Weiwei", "Weng", "Paul", "H\u00fcllermeier", "Eyke"], "venue": "In Proc. of The ICML,", "citeRegEx": "Busa.Fekete et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Busa.Fekete et al\\.", "year": 2013}, {"title": "Preference-based rank elicitation using statistical models: The case of mallows", "author": ["Busa-Fekete", "R\u00f3bert", "H\u00fcllermeier", "Eyke", "Sz\u00f6r\u00e9nyi", "Bal\u00e1zs"], "venue": "In Proc. of the ICML, pp. 1071\u20131079,", "citeRegEx": "Busa.Fekete et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Busa.Fekete et al\\.", "year": 2014}, {"title": "Pac rank elicitation through adaptive sampling of stochastic pairwise preferences", "author": ["Busa-Fekete", "R\u00f3bert", "Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", "H\u00fcllermeier", "Eyke"], "venue": "In AAAI,", "citeRegEx": "Busa.Fekete et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Busa.Fekete et al\\.", "year": 2014}, {"title": "Computing with noisy information", "author": ["Feige", "Uriel", "Raghavan", "Prabhakar", "Peleg", "David", "Upfal", "Eli"], "venue": "SIAM Journal on Computing,", "citeRegEx": "Feige et al\\.,? \\Q1994\\E", "shortCiteRegEx": "Feige et al\\.", "year": 1994}, {"title": "Active ranking from pairwise comparisons and when parametric assumptions don\u2019t help", "author": ["Heckel", "Reinhard", "Shah", "Nihar B", "Ramchandran", "Kannan", "Wainwright", "Martin J"], "venue": "arXiv preprint arXiv:1606.08842,", "citeRegEx": "Heckel et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Heckel et al\\.", "year": 2016}, {"title": "Trueskill: a bayesian skill rating system", "author": ["Herbrich", "Ralf", "Minka", "Tom", "Graepel", "Thore"], "venue": "In Proceedings of the 19th International Conference on Neural Information Processing Systems,", "citeRegEx": "Herbrich et al\\.,? \\Q2006\\E", "shortCiteRegEx": "Herbrich et al\\.", "year": 2006}, {"title": "Top-k ranking from pairwise comparisons: When spectral ranking is optimal", "author": ["Jang", "Minje", "Kim", "Sunghyun", "Suh", "Changho", "Oh", "Sewoong"], "venue": "arXiv preprint arXiv:1603.04153,", "citeRegEx": "Jang et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Jang et al\\.", "year": 2016}, {"title": "Individual choice behavior: A theoretical analysis", "author": ["Luce", "R Duncan"], "venue": "Courier Corporation,", "citeRegEx": "Luce and Duncan.,? \\Q2005\\E", "shortCiteRegEx": "Luce and Duncan.", "year": 2005}, {"title": "Data structures using C : 1000 problems and solutions", "author": ["Mukherjee", "Sudipta"], "venue": null, "citeRegEx": "Mukherjee and Sudipta.,? \\Q2011\\E", "shortCiteRegEx": "Mukherjee and Sudipta.", "year": 2011}, {"title": "Rank centrality: Ranking from pairwise", "author": ["Negahban", "Sahand", "Oh", "Sewoong", "Shah", "Devavrat"], "venue": "isons. In NIPS,", "citeRegEx": "Negahban et al\\.,? \\Q2012\\E", "shortCiteRegEx": "Negahban et al\\.", "year": 2012}, {"title": "Active exploration for learning rankings from clickthrough", "author": ["Radlinski", "Filip", "Joachims", "Thorsten"], "venue": "comparisons. Operations Research,", "citeRegEx": "Radlinski et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Radlinski et al\\.", "year": 2016}, {"title": "How does clickthrough data", "author": ["Radlinski", "Filip", "Kurup", "Madhu", "Joachims", "Thorsten"], "venue": "Proceedings of the 13th ACM SIGKDD,", "citeRegEx": "Radlinski et al\\.,? \\Q2007\\E", "shortCiteRegEx": "Radlinski et al\\.", "year": 2007}, {"title": "A statistical convergence perspective of algorithms for rank", "author": ["Rajkumar", "Arun", "Agarwal", "Shivani"], "venue": null, "citeRegEx": "Rajkumar et al\\.,? \\Q2008\\E", "shortCiteRegEx": "Rajkumar et al\\.", "year": 2008}, {"title": "Efficient algorithms for adver", "author": ["Syrgkanis", "Vasilis", "Krishnamurthy", "Akshay", "Schapire", "Robert E"], "venue": "Proc. of the ICML,", "citeRegEx": "Syrgkanis et al\\.,? \\Q2014\\E", "shortCiteRegEx": "Syrgkanis et al\\.", "year": 2014}, {"title": "Online rank elicitation", "author": ["Sz\u00f6r\u00e9nyi", "Bal\u00e1zs", "Busa-Fekete", "R\u00f3bert", "Paul", "Adil", "H\u00fcllermeier", "Eyke"], "venue": "sarial contextual learning. arXiv preprint arXiv:1602.02454,", "citeRegEx": "Sz\u00f6r\u00e9nyi et al\\.,? \\Q2016\\E", "shortCiteRegEx": "Sz\u00f6r\u00e9nyi et al\\.", "year": 2016}, {"title": "plackett-luce: A dueling bandits approach", "author": ["Urvoy", "Tanguy", "Clerot", "Fabrice", "F\u00e9raud", "Raphael", "Naamane", "Sami"], "venue": "In NIPS,", "citeRegEx": "Urvoy et al\\.,? \\Q2015\\E", "shortCiteRegEx": "Urvoy et al\\.", "year": 2015}, {"title": "k-armed voting bandits", "author": ["Yue", "Yisong", "Joachims", "Thorsten"], "venue": "In Proc. of the ICML, pp. 91\u201399,", "citeRegEx": "Yue et al\\.,? \\Q2013\\E", "shortCiteRegEx": "Yue et al\\.", "year": 2013}], "referenceMentions": [{"referenceID": 11, "context": "Patented by Microsoft, TrueSkill Herbrich et al. [2006] is such a ranking system for Xbox gamers.", "startOffset": 33, "endOffset": 56}, {"referenceID": 11, "context": "Patented by Microsoft, TrueSkill Herbrich et al. [2006] is such a ranking system for Xbox gamers. Another important application is online advertising. Prominent web pages devote precious little space to advertisements, limiting companies like Google, Microsoft, or Yahoo! to present a typical user with just a couple of ads, of which the user selects at most one. Based on these small random comparisons, the company would like to rank the ads according to their appeal Radlinski & Joachims [2007], Radlinski et al.", "startOffset": 33, "endOffset": 498}, {"referenceID": 11, "context": "Patented by Microsoft, TrueSkill Herbrich et al. [2006] is such a ranking system for Xbox gamers. Another important application is online advertising. Prominent web pages devote precious little space to advertisements, limiting companies like Google, Microsoft, or Yahoo! to present a typical user with just a couple of ads, of which the user selects at most one. Based on these small random comparisons, the company would like to rank the ads according to their appeal Radlinski & Joachims [2007], Radlinski et al. [2008]. This and related applications have brought about a resurgence of interest in maximum selection and ranking using noisy comparisons.", "startOffset": 33, "endOffset": 523}, {"referenceID": 11, "context": "Patented by Microsoft, TrueSkill Herbrich et al. [2006] is such a ranking system for Xbox gamers. Another important application is online advertising. Prominent web pages devote precious little space to advertisements, limiting companies like Google, Microsoft, or Yahoo! to present a typical user with just a couple of ads, of which the user selects at most one. Based on these small random comparisons, the company would like to rank the ads according to their appeal Radlinski & Joachims [2007], Radlinski et al. [2008]. This and related applications have brought about a resurgence of interest in maximum selection and ranking using noisy comparisons. Several noise models were considered, including the popular Plackett-Luce model Plackett [1975], Luce [2005].", "startOffset": 33, "endOffset": 752}, {"referenceID": 11, "context": "Patented by Microsoft, TrueSkill Herbrich et al. [2006] is such a ranking system for Xbox gamers. Another important application is online advertising. Prominent web pages devote precious little space to advertisements, limiting companies like Google, Microsoft, or Yahoo! to present a typical user with just a couple of ads, of which the user selects at most one. Based on these small random comparisons, the company would like to rank the ads according to their appeal Radlinski & Joachims [2007], Radlinski et al. [2008]. This and related applications have brought about a resurgence of interest in maximum selection and ranking using noisy comparisons. Several noise models were considered, including the popular Plackett-Luce model Plackett [1975], Luce [2005]. Yet even for such specific models, the complexity of maximum selection was known only up to a log n factor and the complexity of ranking was known", "startOffset": 33, "endOffset": 765}, {"referenceID": 9, "context": "[2012, 2016], Jang et al. [2016] where we cannot choose the comparison pairs, and adaptive or online where the comparison pairs are selected sequentially based on previous results.", "startOffset": 14, "endOffset": 33}, {"referenceID": 9, "context": "[2012, 2016], Jang et al. [2016] where we cannot choose the comparison pairs, and adaptive or online where the comparison pairs are selected sequentially based on previous results. In this paper we focus on the latter. We specify the desired output via the (\u01eb, \u03b4)-PAC paradigm Yue & Joachims [2011], Busa-Fekete et al.", "startOffset": 14, "endOffset": 299}, {"referenceID": 6, "context": "We specify the desired output via the (\u01eb, \u03b4)-PAC paradigm Yue & Joachims [2011], Busa-Fekete et al. [2014b] that requires the output to likely closely approximate the intended value.", "startOffset": 81, "endOffset": 108}, {"referenceID": 6, "context": "[2013], Busa-Fekete et al. [2014b,b] assume no underlying ranking or constraints on probabilities and find ranking based on Copeland, Borda count and Random Walk procedures. Urvoy et al. [2013], Busa-Fekete et al.", "startOffset": 8, "endOffset": 194}, {"referenceID": 6, "context": "[2013], Busa-Fekete et al. [2014b,b] assume no underlying ranking or constraints on probabilities and find ranking based on Copeland, Borda count and Random Walk procedures. Urvoy et al. [2013], Busa-Fekete et al. [2014b] showed that if the probabilities p(i, j) are not constrained, both maximum selection and ranking problems require \u0398(n2) comparisons.", "startOffset": 8, "endOffset": 222}, {"referenceID": 6, "context": "[2013], Busa-Fekete et al. [2014b,b] assume no underlying ranking or constraints on probabilities and find ranking based on Copeland, Borda count and Random Walk procedures. Urvoy et al. [2013], Busa-Fekete et al. [2014b] showed that if the probabilities p(i, j) are not constrained, both maximum selection and ranking problems require \u0398(n2) comparisons. Several models have therefore been considered to further constrain the probabilities. Under the assumptions of strong stochastic transitivity and triangle inequality , Yue & Joachims [2011] derived a PACmaximum selection algorithm that usesO ( n \u01eb2 log n \u01eb\u03b4 )", "startOffset": 8, "endOffset": 545}, {"referenceID": 11, "context": "Sz\u00f6r\u00e9nyi et al. [2015] derived a PAC ranking algorithm for PL-model distributions that requires O( n \u01eb2 log n log n \u03b4\u01eb ) comparisons.", "startOffset": 0, "endOffset": 23}, {"referenceID": 11, "context": "Sz\u00f6r\u00e9nyi et al. [2015] derived a PAC ranking algorithm for PL-model distributions that requires O( n \u01eb2 log n log n \u03b4\u01eb ) comparisons. In addition to PAC paradigm, Yue & Joachims [2011] also considered this problem under the bandit setting and bounded the regret of the resulting dueling bandits problem.", "startOffset": 0, "endOffset": 185}, {"referenceID": 11, "context": "Syrgkanis et al. [2016] looked at similar formulation.", "startOffset": 0, "endOffset": 24}, {"referenceID": 2, "context": "Another non-PAC approach by Busa-Fekete et al. [2014a], Feige et al.", "startOffset": 28, "endOffset": 55}, {"referenceID": 2, "context": "Another non-PAC approach by Busa-Fekete et al. [2014a], Feige et al. [1994] solves the maximum selection and ranking problems.", "startOffset": 28, "endOffset": 76}, {"referenceID": 0, "context": "For example, Acharya et al. [2014a, 2016, 2014b] considered adversarial sorting with applications to density estimation and Ajtai et al. [2015] considered the same with deterministic algorithms.", "startOffset": 13, "endOffset": 144}, {"referenceID": 0, "context": "For example, Acharya et al. [2014a, 2016, 2014b] considered adversarial sorting with applications to density estimation and Ajtai et al. [2015] considered the same with deterministic algorithms. Mallows stochastic model Busa-Fekete et al. [2014a] does not satisfy the stochastic triangle inequality and hence our theoretical guarantees do not hold under this model.", "startOffset": 13, "endOffset": 247}, {"referenceID": 9, "context": "Using the lower bound in Feige et al. [1994], it can be inferred that the best PAC maximum selection algorithm requires \u03a9 ( n \u01eb2 log 1\u03b4 )", "startOffset": 25, "endOffset": 45}, {"referenceID": 20, "context": "comparisons for \u03b4 = 1 n where as Sz\u00f6r\u00e9nyi et al. [2015] uses O ( n(log n)2/\u01eb2 )", "startOffset": 33, "endOffset": 56}, {"referenceID": 20, "context": "Furthermore Sz\u00f6r\u00e9nyi et al. [2015] provided these guarantees only under Plackett-Luce model which is more restrictive compared to ours.", "startOffset": 12, "endOffset": 35}, {"referenceID": 20, "context": "Sz\u00f6r\u00e9nyi et al. [2015] showed that their algorithm", "startOffset": 0, "endOffset": 23}, {"referenceID": 9, "context": "Interval-Binary-Search is similar to the noisy binary search algorithm in Feige et al. [1994]. It builds a binary search tree with the bins as the leaves and it does a random walk over this tree.", "startOffset": 74, "endOffset": 94}, {"referenceID": 20, "context": "Using PALPAC-AMPRR Sz\u00f6r\u00e9nyi et al. [2015] as a Rank-x algorithm with x = 1 leads to the following corollary over PL model.", "startOffset": 19, "endOffset": 42}, {"referenceID": 6, "context": "We compare the sample complexity of Knockout with that of BTM-PAC Yue & Joachims [2011], MallowsMPI Busa-Fekete et al. [2014a], and AR Heckel et al.", "startOffset": 100, "endOffset": 127}, {"referenceID": 6, "context": "We compare the sample complexity of Knockout with that of BTM-PAC Yue & Joachims [2011], MallowsMPI Busa-Fekete et al. [2014a], and AR Heckel et al. [2016]. BTM-PAC is an (\u01eb, \u03b4)PAC algorithm for the same model considered in this paper.", "startOffset": 100, "endOffset": 156}, {"referenceID": 6, "context": "We compare the sample complexity of Knockout with that of BTM-PAC Yue & Joachims [2011], MallowsMPI Busa-Fekete et al. [2014a], and AR Heckel et al. [2016]. BTM-PAC is an (\u01eb, \u03b4)PAC algorithm for the same model considered in this paper. MallowsMPI finds a Condorcet winner which exists under our general model. AR finds the maximum according to Borda scores. We also tried PLPAC Sz\u00f6r\u00e9nyi et al. [2015], developed originally for PL model but the algorithm could not meet guarantees of \u03b4 = 0.", "startOffset": 100, "endOffset": 401}, {"referenceID": 20, "context": "As noted in Sz\u00f6r\u00e9nyi et al. [2015], sample complexity of MallowsMPI gets worse as p\u0303(i, j) gets close to 0.", "startOffset": 12, "endOffset": 35}, {"referenceID": 6, "context": "As in Busa-Fekete et al. [2014a], we consider n = 10 elements and various values for \u03c6: 0.", "startOffset": 6, "endOffset": 33}], "year": 2017, "abstractText": "We consider (\u01eb, \u03b4)-PAC maximum-selection and ranking for general probabilistic models whose comparisons probabilities satisfy strong stochastic transitivity and stochastic triangle inequality. Modifying the popular knockout tournament, we propose a maximum-selection algorithm that uses O (", "creator": "LaTeX with hyperref package"}}}